<div id=toc></div>

# Table of Contents

- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 3]
- [quant-ph](#quant-ph) [Total: 26]
- [cs.AI](#cs.AI) [Total: 19]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [cs.LG](#cs.LG) [Total: 47]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 11]
- [nlin.CD](#nlin.CD) [Total: 2]


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [1] [Approaching Kasteleyn transition in frustrated quantum Heisenberg antiferromagnets](https://arxiv.org/abs/2601.14382)
*Katarina Karlova,Afonso Rufino,Taras Verkholyak,Nils Caci,Stefan Wessel,Jozef Strecka,Frederic Mila,Andreas Honecker*

Main category: cond-mat.stat-mech

TL;DR: 该论文展示了Kasteleyn相变（经典二聚体模型中缺陷无限串的突然增殖）也可适用于受挫二维量子磁体，通过自旋-1/2海森堡金刚石装饰蜂窝晶格中的精确本征态映射到蜂窝晶格二聚体覆盖来实现。


<details>
  <summary>Details</summary>
Motivation: 探索经典统计力学中的Kasteleyn相变概念是否能够推广到量子磁体系统，特别是受挫二维量子磁体中，以揭示新的物理现象和相变行为。

Method: 研究自旋-1/2海森堡金刚石装饰蜂窝晶格，构建精确的本征态作为二聚体和plaquette单重态的乘积，将其映射到蜂窝晶格的二聚体覆盖。通过有效二聚体模型描述低温性质，该模型具有各向异性活性和可调的单体密度。

Result: 成功展示了Kasteleyn相变在受挫量子磁体中的相关性，实现了任意尖锐的交叉版本Kasteleyn相变。该相变可通过调节单体密度进行调控。

Conclusion: Kasteleyn相变概念可推广到受挫二维量子磁体系统，为理解这类系统的相变行为提供了新视角。该模型可能在有机金属化合物中实现，并有望推广到其他几何结构。

Abstract: We show that the Kasteleyn transition, the abrupt proliferation of infinite strings of defects in classical dimer and related models, can also be relevant for frustrated 2d quantum magnets. This is explicitly demonstrated in a phase of the spin-1/2 Heisenberg diamond-decorated honeycomb lattice where a family of exact eigenstates built as products of dimer and plaquette singlets can be mapped onto the dimer coverings of the honeycomb lattice. The low-temperature properties of this phase are accurately described by an effective dimer model with anisotropic activities and a small, tunable density of monomers, leading to an arbitrarily sharp crossover version of the Kasteleyn transition. The generalization to other geometries and the possibility to realize this model in organo-metallic compounds are briefly discussed.

</details>


### [2] [Optimal control of bit erasure in stochastic random access memory](https://arxiv.org/abs/2601.14387)
*Songela W. Chen,David T. Limmer*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究了两种随机存取存储器（DRAM和SRAM）中比特擦除的热力学成本，发现在准静态极限下DRAM能耗最低且错误最少，而SRAM则在有限时间内运行最有效，并提出了基于平均场理论和自动微分的优化方案。


<details>
  <summary>Details</summary>
Motivation: 信息处理的能源成本呈指数级增长，比特擦除是能源-信息关系中的关键问题。虽然已有关于热力学成本与内存存储关系的基础理论，但在现代时代继续取得进展需要面对现实物理系统中远离平衡状态的热力学成本。

Method: 使用互补金属氧化物半导体（CMOS）模型研究两种随机存取存储器（DRAM和SRAM）的比特擦除热力学成本。采用平均场理论和自动微分构建数值稳健的优化方案，寻找与电气工程见解兼容的最优协议。

Result: 动态随机存取存储器（DRAM）在准静态极限下能耗最低且错误最少；静态随机存取存储器（SRAM）由于需要维持比特状态的能量，在有限时间内运行最有效。优化方案找到了与电气工程见解兼容的最优协议。

Conclusion: 研究结果为在热力学有利的方式下操作实际电路提供了框架，有助于降低信息处理的能源成本，特别是在现代远离平衡状态的物理系统中。

Abstract: Energy costs of information processing are growing exponentially. Bit erasure is a key problem in this energy-information nexus, and a number of seminal relationships have been deduced regarding the relationship between thermodynamic costs and memory storage. To continue making progress in the modern era, however, requires confronting thermodynamic costs in realistic physical systems which operate away from equilibrium. Here, we explore the thermodynamic costs of bit erasure in a complementary metal oxide semiconductor model of two types of random access memory. We find dynamic random access memory dissipates the least amount of energy when operated in the quasistatic limit, where errors are also minimized. By contrast, static random access memory is most efficiently operated in finite time due to the energy required to maintain the state of the bit. We demonstrate a numerically robust optimization scheme using mean field theory and automatic differentiation, finding optimal protocols compatible with electrical engineering insights. These results provide a framework for operating realistic circuits in thermodynamically advantageous ways.

</details>


### [3] [Stiffness induced structures and morphological transitions in semiflexible polymers](https://arxiv.org/abs/2601.15095)
*Biman Bagchi*

Main category: cond-mat.stat-mech

TL;DR: 该研究为半柔性聚合物在不良溶剂中的塌缩形态（球状、环状、棒状）建立了统一的理论框架，通过场论自由能方法预测了形态相图和三重点的存在。


<details>
  <summary>Details</summary>
Motivation: 半柔性聚合物在不良溶剂中表现出丰富的塌缩形态（球状体、环状体、棒状束），这些形态源于吸引相互作用与链刚度的竞争。虽然计算机模拟和实验已观察到复杂的形态交叉，但缺乏统一的理论描述。

Method: 开发了基于场论的粗粒度自由能框架，包含三个关键要素：描述单体吸引和排除体积效应的密度场、描述致密区域取向有序的向列序参数、以及蠕虫状链的弯曲刚度。使用变分近似法推导竞争形态的解析自由能表达式。

Result: 理论预测了线圈、球状体、环状体和棒状构象区域之间的相边界，作为约化吸引强度和有效持续长度的函数。相图拓扑结构为解释实验和模拟中的形态图提供了透明框架，并发现了球状体、棒状体和环状体三重点存在的可能性。

Conclusion: 该研究为半柔性聚合物在不良溶剂中的塌缩形态提供了统一的理论描述，通过自由能框架成功解释了实验和模拟中观察到的复杂形态相图，揭示了不同形态之间的竞争关系和相变行为。

Abstract: Semiflexible polymers in poor solvents exhibit a rich variety of collapsed morphologies, including globules, toroids, and rodlike bundles, arising from the competition between attractive interactions and chain stiffness. Computer simulations and experiments on stiff and conjugated polymers have revealed complex morphological crossovers, yet a unified theoretical description remains incomplete. Here we develop a coarse-grained, field-theoretic free-energy framework for linear polymers with variable stiffness that captures these morphologies and their transitions within a common description. The theory is built on three key ingredients: a density field describing monomer attraction and excluded-volume effects, a nematic order parameter accounting for orientational ordering in dense regions, and the bending rigidity of a worm-like chain. Using simple variational ansatzes for competing morphologies, we derive analytic expressions for their free energies and identify the boundaries separating coil, globule, toroidal, and rodlike conformational regimes as functions of the reduced attraction strength and the effective persistence length. The resulting phase-diagram topology provides a transparent free-energy-based framework for interpreting morphology diagrams observed in simulations and experiments on semiflexible polymers in poor solvents. We find the possibility of the existence of a triple point involving globules, rods and toroids.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [4] [Advances in non-Hermitian dynamics of quadratic bosonic systems](https://arxiv.org/abs/2601.14329)
*Huawei Zhao,Xinlei Liu,Xinyao Huang,Guofeng Zhang*

Main category: quant-ph

TL;DR: 该论文探讨了二次玻色子系统中的非厄米特性，展示了如何通过场算符变换实现非互易传输，并揭示了在动量空间中观察到的非厄米拓扑现象，为研究非厄米特性对量子效应的影响提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 传统非厄米系统通常通过不对称耦合或引入耗散与增益来实现，而二次玻色子系统本质上是厄米的，但其动力学演化矩阵在实空间和动量空间中表现出非厄米特性。研究这种内在的非厄米特性如何影响量子效应，是非厄米物理与量子物理交叉领域的重要研究方向。

Method: 基于二次玻色子系统的挤压相互作用，分析其动力学演化矩阵的非厄米特性。通过场算符变换xp应用于动力学演化矩阵，实现x和p算符之间的正交非互易传输。在动量空间中采用Bogoliubov-de Gennes框架，研究点隙拓扑和非厄米趋肤效应等非厄米拓扑现象。

Result: 1. 场算符变换实现了x和p算符之间的非互易传输，可用于信号放大器；2. 在动量空间中观察到由非零绕数谱诱导的点隙拓扑和非厄米趋肤效应；3. 二次玻色子系统可用于实现非厄米Aharonov-Bohm笼并扩展非Bloch能带理论。

Conclusion: 二次玻色子系统虽然本质上是厄米的，但其动力学演化矩阵展现出丰富的非厄米特性，为研究非厄米物理在量子系统中的表现提供了新平台。该研究揭示了非厄米特性对量子效应的影响，为非厄米物理与量子物理的交叉研究开辟了新方向。

Abstract: Non-Hermitian physics has emerged as a rapidly advancing field of research, revealing a range of novel phenomena and potential applications. Traditional non-Hermitian Hamiltonians are typically simulated by constructing asymmetric couplings or by introducing dissipation and gain to realize non-Hermitian systems. The quadratic bosonic system (QBS) with squeezing interaction is intrinsically Hermitian; however, its dynamical evolution matrix in both real and momentum spaces is non-Hermitian. Based on this, applying a field-operator transformation xp to the dynamical evolution matrix yields quadrature nonreciprocal transmission between the x and p operators. This nonreciprocal characteristic can be utilized in signal amplifiers. On the other hand, within the Bogoliubov-de Gennes framework in momentum space, one can observe non-Hermitian topological phenomena such as point-gap topology and the non-Hermitian skin effect, both induced by spectra with nonzero winding numbers. Additionally, QBS can be employed to realize non-Hermitian Aharonov-Bohm cages and to extend non-Bloch band theory. Previous studies in non-Hermitian physics have largely concentrated on classical systems. The influence of non-Hermitian properties on quantum effects remains a key issue awaiting exploration and has evolved into a research direction at the interface of non-Hermitian and quantum physics.

</details>


### [5] [Towards Device-Independent Quantum Key Distribution with Photonic Devices](https://arxiv.org/abs/2601.14373)
*Corentin Lanore,Xavier Valcarce,Jean Etesse,Anthony Martin,Jean-Daniel Bancal*

Main category: quant-ph

TL;DR: 本文评估了基于机器学习识别的光子电路实现设备无关量子密钥分发的可行性，开发了新的半定规划层次结构和有限统计分析方法，证明该光学电路具有足够的噪声容忍度。


<details>
  <summary>Details</summary>
Motivation: 传统量子密钥分发协议存在物理建模与实现不匹配的安全漏洞，设备无关量子密钥分发通过黑盒设置减少设备建模需求，但现有实现噪声容忍度低，光子平台虽具优势但尚未成功实现设备无关量子密钥分发。

Method: 引入高效收敛的半定规划层次结构来约束条件冯·诺依曼熵，开发考虑完整结果统计的有限统计分析方法，评估机器学习技术识别的光子电路在设备无关量子密钥分发中的可行性。

Result: 分析表明所提出的光学电路具有足够的噪声抵抗能力，使得实验实现变得现实可行，为光子平台实现设备无关量子密钥分发提供了可能性。

Conclusion: 通过新的分析工具评估，机器学习识别的光子电路在设备无关量子密钥分发中具有实际可行性，为光子平台实现更高安全性的量子密钥分发开辟了新途径。

Abstract: Quantum Key Distribution (QKD) protocols enable two distant parties to communicate with information-theoretically proven secrecy. However, these protocols are generally vulnerable to potential mismatches between the physical modeling and the implementation of their quantum operations, thereby opening opportunities for side channel attacks. Device-Independent (DI) QKD addresses this problem by reducing the degree of device modeling to a black-box setting. The stronger security obtained in this way comes at the cost of a reduced noise tolerance, rendering experimental demonstrations more challenging: so far, only one experiment based on trapped ions was able to successfully generate a secret key. Photonic platforms have however long been preferred for QKD thanks to their suitability to optical fiber transmission, high repetition rates, readily available hardware, and potential for circuit integration. In this work, we assess the feasibility of DIQKD on a photonic circuit recently identified by machine learning techniques. For this, we introduce an efficient converging hierarchy of semi-definite programs (SDP) to bound the conditional von Neumann entropy and develop a finite-statistics analysis that takes into account full outcome statistics. Our analysis shows that the proposed optical circuit is sufficiently resistant to noise to make an experimental realization realistic.

</details>


### [6] [Vanishing correlations in (bi)stochastic controlled circuits](https://arxiv.org/abs/2601.14379)
*Pavel Kos,Bruno Bertini,Tomaž Prosen*

Main category: quant-ph

TL;DR: 随机和双随机受控门电路具有特殊的时空关联结构：两点关联函数只在同一位置非零，多点关联中最后两个算子必须在同一位置，自关联呈指数衰减且与系统尺寸相关。


<details>
  <summary>Details</summary>
Motivation: 研究随机和双随机受控门电路的动力学特性，这类系统出现在量子电路、随机电路和经典确定性元胞自动机中，旨在揭示复杂微观动力学下关联结构的简化规律。

Method: 通过理论证明分析随机和双随机受控门电路的时空关联函数特性，研究两点和多点关联函数的空间分布特征，并分析自关联函数的衰减行为。

Result: 证明了两点时空关联函数只在两个算符作用于同一位置时非零；对于多点关联，最右边的两个算符必须作用于同一位置；自关联函数呈指数衰减，其极限值随系统尺寸指数减小。

Conclusion: 随机和双随机受控门电路构成了一类具有特殊简化关联结构的量子系统，尽管微观动力学复杂，但其关联模式表现出惊人的简单性。

Abstract: We study the dynamics of circuits composed of stochastic and bistochastic controlled gates. This type of dynamics arises from quantum circuits with random controlled gates, as well as in stochastic circuits and deterministic classical cellular automata. We prove that stochastic and bistochastic controlled gates lead to two-point spatio-temporal correlation functions that vanish everywhere except when the two operators act on the same site. More generally, for multi-point correlations the two rightmost operators must act on the same site. We argue that autocorrelation, while hard to compute, typically decays exponentially towards a value that is exponentially small in the system size. Our results reveal a broad class of quantum systems that exhibit surprisingly simple correlation structures despite their complex microscopic dynamics.

</details>


### [7] [Vacuum Torque Without Anisotropy: Switchable Casimir Torque Between Altermagnets](https://arxiv.org/abs/2601.14381)
*Zixuan Dai,Qing-Dong Jiang*

Main category: quant-ph

TL;DR: 磁场可通过破坏时间反演对称性产生卡西米尔扭矩，无需传统旋转对称性破缺机制，在二维交变磁体中实现扭矩符号可调


<details>
  <summary>Details</summary>
Motivation: 传统卡西米尔扭矩需要材料介电各向异性、几何不对称性或外场破坏旋转对称性，本文探索通过时间反演对称性破缺这一全新机制产生卡西米尔扭矩

Method: 研究二维交变磁体，施加垂直平面的轴向对称磁场，通过交变磁序固有的晶体对称性C_n T激活取向依赖的真空相互作用

Result: 磁场可诱导轴向不对称卡西米尔能量并产生扭矩，扭矩连续出现且与磁场强度平方成正比，温度与距离依赖关系与单轴体材料有本质区别

Conclusion: 时间反演对称性破缺是调控卡西米尔扭矩符号和强度的有效途径，交变磁体为探索真空量子涨落驱动现象提供了新平台

Abstract: Casimir torque is conventionally associated with explicit breaking of rotational symmetry, arising from material dielectric anisotropy, geometric asymmetry, or externally applied fields that themselves break rotational invariance. Here we demonstrate a fundamentally different mechanism: an axially symmetric magnetic field can generate a Casimir torque by inducing an axially asymmetric Casimir energy - and can even reverse the torque's sign. Focusing on two-dimensional altermagnets, we show that a magnetic field applied perpendicular to the plane - while preserving in-plane rotational symmetry - activates an orientation-dependent vacuum interaction through the combined crystalline symmetry $\mathrm{C_n T}$ inherent to altermagnetic order. The resulting torque emerges continuously and scales quadratically with the magnetic field strength. We further analyze its temperature and distance dependence, revealing scaling behaviors that are qualitatively different from those found in uniaxial bulk materials. Our results identify time-reversal symmetry breaking as a powerful route for engineering both the sign and strength of Casimir torque and establish altermagnets as an exciting platform for exploring phenomena driven by vacuum quantum fluctuations.

</details>


### [8] [Pauli Propagation for Imaginary Time Evolution](https://arxiv.org/abs/2601.14400)
*Rafael Gómez-Lurbe,Armando Pérez*

Main category: quant-ph

TL;DR: 将泡利传播框架扩展到虚时间演化，提出虚时间泡利传播算法，用于计算热态和基态性质，保持泡利传播的计算优势。


<details>
  <summary>Details</summary>
Motivation: 扩展泡利传播框架以处理虚时间演化，从而能够计算热态和基态性质，同时保持原有框架的计算优势。

Method: 推导泡利算符在虚时间演化下的显式更新规则，提出虚时间泡利传播算法，直接在泡利基中近似虚时间动力学。

Result: 在一维横向场伊辛模型上的基准测试表明，截断提供了精度与计算成本之间的可控权衡，同时揭示了虚时间演化下算符增长带来的挑战。

Conclusion: 虚时间泡利传播算法成功扩展了原有框架，结合实时间和虚时间泡利传播为模拟开放量子系统动力学提供了统一框架的路径。

Abstract: We extend the Pauli Propagation framework to simulate imaginary time evolution. By deriving explicit update rules for the propagation of Pauli operators under imaginary time evolution generated by Pauli strings, we introduce an imaginary time Pauli Propagation (ITPP) algorithm for approximating imaginary time dynamics directly in the Pauli basis. This approach enables the computation of thermal and ground-state properties while retaining the key computational advantages of Pauli Propagation. Benchmarking ITPP on the one-dimensional transverse-field Ising model demonstrates that truncation provides a controlled trade-off between accuracy and computational cost, while also revealing challenges associated with operator growth under imaginary time evolution. Finally, combining imaginary time and real-time Pauli Propagation naturally suggests a pathway toward simulating open quantum system dynamics within a unified framework.

</details>


### [9] [Two-Qubit Spin-Boson Model in the Strong Coupling Regime: Coherence, Non-Markovianity, and Quantum Thermodynamics](https://arxiv.org/abs/2601.15026)
*Hasan Mehdi Rizvi,Devvrat Tiwari,Subhashish Banerjee*

Main category: quant-ph

TL;DR: 研究强耦合、非马尔可夫和非平衡条件下双量子比特自旋-玻色子模型的动力学，使用HEOM和RCM方法分析量子相干性、熵产生和热流特性


<details>
  <summary>Details</summary>
Motivation: 在强耦合、非马尔可夫和非平衡条件下研究开放量子系统的动力学，特别是探索量子热器件在强耦合区域的实现可能性

Method: 采用两种互补方法：层次运动方程(HEOM)和反应坐标映射(RCM)，分析量子比特与热浴之间的不同耦合机制，使用相干性l1范数探测量子相干性，利用辅助密度算子计算熵产生

Result: 模型表现出非马尔可夫演化，研究了隧穿振幅对量子相干性的影响，计算了强耦合区域的熵产生，分析了非平衡稳态行为，探索了热流和自旋流与隧穿振幅的关系

Conclusion: 该研究为强耦合非平衡开放量子系统的动力学提供了深入理解，特别是对量子热器件在强耦合区域的实现有重要启示，展示了隧穿振幅对量子相干性和热输运性质的关键影响

Abstract: We investigate the dynamics of a two-qubit open quantum system, in particular the two-qubit spin-boson model in the strong coupling regime, coupled to two thermal bosonic baths under non-Markovian and non-equilibrium conditions. Two complementary approaches, the Hierarchical Equations of Motion (HEOM) and Reaction Coordinate Mapping (RCM), are employed to examine various coupling regimes between the qubits and their respective baths. The dynamical features of the model and the impact of the tunneling amplitude on quantum coherence of the system are probed using the $l_1$-norm of coherence. The model is further shown to have non-Markovian evolution. The nontrivial task of calculating entropy production in the strong-coupling regime is performed using auxiliary density operators in HEOM. Motivated by the realization of a quantum thermal device in the strong-coupling regime, the non-equilibrium steady-state behavior of the system is investigated. Furthermore, the relationship between the heat and spin currents and the tunneling amplitude is probed.

</details>


### [10] [Quantum state exclusion with many copies](https://arxiv.org/abs/2601.14410)
*Debanjan Roy,Tathagata Gupta,Pratik Ghosal,Samrat Sen,Somshubhro Bandyopadhyay*

Main category: quant-ph

TL;DR: 量子态排除任务中，对于三个或更多纯态，有限数量的相同副本可以实现排除，但所需副本数可能任意大。


<details>
  <summary>Details</summary>
Motivation: 在单副本设置中，量子态排除并不总是可行的。本文研究访问多个相同副本是否能够实现态排除，特别是探索副本数量如何影响排除可能性。

Method: 研究多副本量子态排除问题，证明对于三个或更多纯态，有限数量的副本可以实现排除。同时构造具体例子显示所需副本数可以任意大。

Result: 1. 对于任意三个或更多纯态，存在有限数量的副本可以实现态排除。2. 所需副本数可能任意大，对于每个自然数N，可以构造出需要超过N个副本才能排除的态集合。

Conclusion: 多副本访问确实能够实现量子态排除，但所需副本数可能非常大，这揭示了量子态排除问题的复杂性，并为量子信息处理提供了重要见解。

Abstract: Quantum state exclusion is the task of identifying at least one state from a known set that was not used in the preparation of a quantum system. In particular, a given set of quantum states is said to admit state exclusion if there exists a measurement such that, for each state in the set, some measurement outcome rules it out with certainty. However, state exclusion is not always possible in the single-copy setting. In this paper, we investigate whether access to multiple identical copies enables state exclusion. We prove that for any set of three or more pure states, state exclusion becomes possible with a finite number of copies. We further show that the required number of copies may be arbitrarily large -- in particular, for every natural number $N$, we construct sets of states for which exclusion remains impossible with $N$ or fewer copies.

</details>


### [11] [Spin-$s$ $U(1)$-eigenstate preparation](https://arxiv.org/abs/2601.14513)
*Nabi Zare Harofteh,Rafael I. Nepomechie*

Main category: quant-ph

TL;DR: 提出一种确定性算法，用于制备自旋链的U(1)本征态，利用有界整数组合的格雷码和相应的"格雷门"实现量子态制备。


<details>
  <summary>Details</summary>
Motivation: 需要一种有效的方法来制备自旋链系统的特定量子态，特别是具有固定数字和的U(1)本征态，这对于研究可积自旋系统很重要。

Method: 利用有界整数组合的格雷码，其连续数字串满足格雷性质，通过应用相应的"格雷门"来制备量子态。

Result: 成功开发了一种确定性算法，能够制备任意自旋-s链的U(1)本征态，并应用于可积自旋-s XXX哈密顿量的精确本征态制备。

Conclusion: 该算法为制备自旋系统的特定量子态提供了一种有效方法，特别适用于可积系统的研究，具有理论和实验应用价值。

Abstract: We formulate a deterministic algorithm for preparing a general $U(1)$-eigenstate of a spin-$s$ chain of length $n$. These states consist of linear combinations of computational basis states $|\vec{m}\rangle$ of $n$ qudits, each with $(2s+1)$ levels and $s= 1/2, 1, 3/2, \ldots$, whose ditstrings $\vec{m}$ have a fixed digit sum. Exploiting a Gray code for bounded integer compositions, whose consecutive ditstrings obey the Gray property, the quantum state is prepared by applying corresponding ``Gray gates.'' We use this algorithm to prepare exact eigenstates of integrable spin-$s$ XXX Hamiltonians.

</details>


### [12] [Active interference suppression in frequency-division-multiplexed quantum gates via off-resonant microwave tones](https://arxiv.org/abs/2601.14547)
*Haruki Mitarai,Yukihiro Tadokoro,Hiroya Tanaka*

Main category: quant-ph

TL;DR: 提出一种主动干扰抑制方法，通过故意加入非共振微波音调来提高频率分复用量子门的精度


<details>
  <summary>Details</summary>
Motivation: 量子处理器与外部电子设备之间控制线路数量的增加是实现大规模量子计算机的主要瓶颈。频率分复用技术有望通过单根微波电缆控制多个量子比特，但非共振微波音调的干扰阻碍了精确的量子比特控制。

Method: 提出主动干扰抑制方法，通过故意加入非共振微波音调来改善频率分复用同时门操作的精度。研究发现，加入非共振正交或准正交微波音调可以降低门不保真度，且这种降低与微波音调数量的平方成反比。

Result: 实验证明，通过故意加入非共振微波音调可以提高单量子比特门的精度。门不保真度随微波音调数量的平方反比下降。同时发现旋转波近似下被忽略的快速振荡会降低门保真度，但可以通过优化频率分配来缓解。

Conclusion: 该方法简单有效，能够显著提高频率分复用量子门的性能，为解决大规模量子计算机控制线路瓶颈提供了有前景的解决方案。

Abstract: An increase in the number of control lines between the quantum processors and the external electronics constitutes a major bottleneck in the realization of large-scale quantum computers. Frequency-division multiplexing is expected to enable multiple qubits to be controlled through a single microwave cable; however, interference from off-resonant microwave tones hinders precise qubit control. Here, we propose an active interference suppression method for frequency-division-multiplexed simultaneous gate operations. We demonstrate that deliberate incorporation of off-resonant microwave tones improves the accuracy of single-qubit gates. Specifically, we find that by incorporating off-resonant orthogonal or quasi-orthogonal microwave tones, the gate infidelity decreases proportionally to the inverse square of the number of microwave tones. Furthermore, we show that fast oscillations neglected under the rotating wave approximation degrade gate fidelity, and that this degradation can be mitigated through optimized frequency allocation. Our approach is simple yet effective for improving the performance of frequency-division-multiplexed quantum gates.

</details>


### [13] [Programming Quantum Measurements of Time inside a Complex Medium](https://arxiv.org/abs/2601.14565)
*Dylan Danese,Vatshal Srivastav,Will McCutcheon,Saroch Leedumrongwatthanakun,Mehul Malik*

Main category: quant-ph

TL;DR: 利用单根多模光纤的空间-时间耦合特性，实现了对光子时间-比特高维叠加态的完全广义测量，替代了传统需要多个级联干涉仪的方法。


<details>
  <summary>Details</summary>
Motivation: 光子时间自由度在现代量子技术中非常重要，但测量高维复杂的时间-比特叠加态一直是实验挑战。传统基于不平衡Franson型干涉仪的方法维度扩展性差，需要多个级联设备和主动相位稳定，且仅限于相位叠加测量。

Method: 利用多模光纤中空间和时间信息的耦合特性，通过光纤的多光谱传输矩阵找到经历不同色散延迟的空间模式集。通过激发这些空间模式的相干叠加，在单根光纤内构建等效的大型不平衡多模干涉仪。

Result: 实现了对任意时间-比特叠加态的高质量测量，最高达到11维。单根光纤作为时间-比特qudit的可扩展共路干涉仪，显著降低了传统方法的实验复杂度。

Conclusion: 单根多模光纤可以作为时间-比特qudit的可扩展共路干涉仪，为利用光的时间特性的量子技术提供了重要工具，显著简化了基于不平衡Franson型干涉仪的标准方法的实验负担。

Abstract: The temporal degree-of-freedom of light is incredibly powerful for modern quantum technologies, enabling large-scale quantum computing architectures and record key-rates in quantum key distribution. However, the generalized measurement of large and complex quantum superpositions of the time-of-arrival of a photon remains a unique experimental challenge. Conventional methods based on unbalanced Franson-type interferometers scale poorly with dimension, requiring multiple cascaded devices and active phase stabilization. In addition, these are limited by construction to a restricted set of phase-only superposition measurements. Here we show how the coupling of spatial and temporal information inside a single multi-mode fiber can be harnessed to program completely generalized measurements for high-dimensional superpositions of photonic time-bin. Using the multi-spectral transmission matrix of the fiber, we find special sets of spatial modes that experience distinct dispersive delays through the fiber. By exciting coherent superpositions of these spatial modes, we engineer the equivalent of large, unbalanced multi-mode interferometers inside the fiber and use them to perform high-quality measurements of arbitrary time-bin superpositions in up to dimension 11. The single fiber functions as a scalable, common-path interferometer for time-bin qudits that significantly eases the experimental overheads of standard approaches based on unbalanced Franson-type interferometers, serving as an essential tool for quantum technologies that harness the temporal properties of light.

</details>


### [14] [Quantum Interference Needs Convention: Overlap-Determinability and Unified No-Superposition Principle](https://arxiv.org/abs/2601.14638)
*Jeongho Bang,Kyoungho Cho,Ki Hyuk Yee*

Main category: quant-ph

TL;DR: 该论文探讨量子叠加的物理实现问题，指出传统叠加概念忽略了相位规范问题，提出"重叠可确定性"概念，并证明叠加操作存在的充要条件是该域是重叠可确定的。


<details>
  <summary>Details</summary>
Motivation: 量子叠加通常被表述为态向量的加法能力，但在实际操作中，物理量是射线（秩一投影算子），每个输入只指定投影算子而留下其向量表示的相位规范自由。当需要设备在给定两个独立制备的未知纯态时，输出与规定线性组合成比例的相干态时，这成为真正的操作障碍。

Method: 通过相位规范和"重叠可确定性"概念形式化该问题。主要定理给出了精确等价关系：存在一个非零完全正迹非增映射在某个域上概率性地产生叠加，当且仅当该域是重叠可确定的。

Result: 该理论统一了现代无叠加结果，并刻画了例外可行的协议，这些协议成功的确切条件是侧信息提供了所需的缺失资源。进一步表明，授予对这种规范固定重叠的普遍访问会破坏熟悉的基础和计算约束，实现类似量子克隆的禁止变换和超光速信号传输。

Conclusion: 量子叠加的实际实现需要解决相位规范问题，重叠可确定性是叠加操作存在的关键条件。当这种规范固定重叠被普遍允许时，会破坏量子计算的基本约束，导致计算复杂度的大幅降低和量子信息处理能力的异常增强。

Abstract: Quantum superposition is often phrased as the ability to add state vectors. In practice, however, the physical quantity is a ray (a rank-one projector), so each input specifies only a projector and leaves a gauge freedom in the phases of its vector representatives. This becomes a real operational barrier when one asks for a device that, given two independently prepared unknown pure states, outputs a coherent state proportional to a prescribed linear combination. We identify the missing ingredient as not probabilistic but phase-like. One needs a physical scenario that fixes a single phase convention on the relevant set of rays, so that the overlaps become well defined complex numbers. Thus, we formalize this through phase conventions and a single notion -- dubbed as "overlap-determinability." Our main theorem gives an exact equivalence: A nonzero completely positive trace-nonincreasing map that probabilistically produces superposition on a domain exists if and only if that domain is overlap-determinable. This unifies modern no-superposition results and characterizes the exceptional yes-go protocols, which succeed precisely when side information supplies the required missing resource. We then show that granting universal access to such convention-fixed overlaps destabilizes the familiar foundational and computational constraints. It enables forbidden transformations akin to quantum cloning and yields super-luminal signaling. It would also permit reflections about unknown states, leading to exponentially fast overlap amplification and a collapse of Grover's search lower bound to a logarithmic query complexity.

</details>


### [15] [Adaptive Fidelity Estimation for Quantum Programs with Graph-Guided Noise Awareness](https://arxiv.org/abs/2601.14713)
*Tingting Li,Ziming Zhao,Jianwei Yin*

Main category: quant-ph

TL;DR: QuFid是一个自适应、噪声感知的量子程序保真度估计框架，通过电路结构和运行时统计反馈在线确定测量预算，显著降低测量成本


<details>
  <summary>Details</summary>
Motivation: 在NISQ设备上测试量子程序时，保真度估计是关键但资源密集的步骤，由于硬件噪声、设备异构性和编译引起的电路变换，难以预先确定所需的测量次数

Method: 将量子程序建模为有向无环图，采用控制流感知的随机游走来表征沿门依赖关系的噪声传播，通过编译引起的结构变形指标捕获后端特定效应，并集成到随机游走公式中诱导噪声传播算子，通过该算子的谱特性量化电路复杂度

Result: 在IBM Quantum后端上执行的18个量子基准测试表明，QuFid相比固定测量次数和基于学习的方法显著降低了测量成本，同时始终保持可接受的保真度偏差

Conclusion: QuFid提供了一个原则性且轻量级的自适应测量规划基础，能够有效应对NISQ设备的噪声和异构性挑战

Abstract: Fidelity estimation is a critical yet resource-intensive step in testing quantum programs on noisy intermediate-scale quantum (NISQ) devices, where the required number of measurements is difficult to predefine due to hardware noise, device heterogeneity, and transpilation-induced circuit transformations. We present QuFid, an adaptive and noise-aware framework that determines measurement budgets online by leveraging circuit structure and runtime statistical feedback. QuFid models a quantum program as a directed acyclic graph (DAG) and employs a control-flow-aware random walk to characterize noise propagation along gate dependencies. Backend-specific effects are captured via transpilation-induced structural deformation metrics, which are integrated into the random-walk formulation to induce a noise-propagation operator. Circuit complexity is then quantified through the spectral characteristics of this operator, providing a principled and lightweight basis for adaptive measurement planning. Experiments on 18 quantum benchmarks executed on IBM Quantum backends show that QuFid significantly reduces measurement cost compared to fixed-shot and learning-based baselines, while consistently maintaining acceptable fidelity bias.

</details>


### [16] [On Distributed Quantum Computing with Distributed Fan-Out Operations](https://arxiv.org/abs/2601.14734)
*Seng W. Loke*

Main category: quant-ph

TL;DR: 比较使用纠缠对与分布式扇出操作（GHZ态）实现分布式量子计算的电路差异，指出分布式扇出操作在电路深度和纠缠资源方面的优势


<details>
  <summary>Details</summary>
Motivation: 探索分布式量子计算的不同实现方式，分析使用纠缠对与分布式GHZ态作为基本构建块的效率差异

Method: 比较分析不同电路实现分布式量子计算的方法：1）仅使用纠缠对；2）使用分布式扇出操作（GHZ态）

Result: 分布式扇出操作（GHZ态）在电路深度方面具有优势，可能减少纠缠资源需求

Conclusion: 如果分布式GHZ态能高效实现，它们可以像纠缠对一样成为分布式量子操作的基本构建块

Abstract: We compare different circuits implementing distributed versions of quantum computations, using entangled pairs only, and using distributed fan-out operations (using GHZ states). We highlight the advantages of using distributed fan-out operations in terms of reductions in circuit depth and (possibly) entanglement resources. We note that distributed fan-out operations (or notably, distributed GHZ states) could be a ``primitive'' building block for distributed quantum operations in the same way as entangled pairs are, if distributed GHZ states could be realized efficiently.

</details>


### [17] [Testing the equivalence to thermal states via extractable work under LOCC](https://arxiv.org/abs/2601.14789)
*Toshihiro Yada,Nobuyuki Yoshioka,Takahiro Sagawa*

Main category: quant-ph

TL;DR: 该研究探讨了量子多体纯态在LOCC操作下的热等价性问题，发现多体量子关联结构决定了纯态是否与热态保持等价，即使允许经典通信。


<details>
  <summary>Details</summary>
Motivation: 理解量子多体纯态的热行为是量子热力学的基本问题。传统上已知典型纯态在局域操作下与热态一样只能提取零功，但尚不清楚在允许经典通信的LOCC操作下这种等价性是否仍然成立。

Method: 建立了判断多体纯态在LOCC下是否与热态等价的标准，通过分析态的多体量子关联结构来研究热等价性。

Result: 发现具有渐近最大多体纠缠的态（如Haar随机态）在LOCC下不能提取大量功，而一些多体纠缠有限的态（如常数度图态）尽管局域上与热态不可区分，却允许提取大量功。

Conclusion: 该工作提供了超越传统局域区域的热等价性操作定义，这对于理解量子多体系统的热力学性质具有重要意义，特别是考虑到实验可访问操作的不断扩展。

Abstract: Understanding the thermal behavior of quantum many-body pure states is one of the most fundamental issues in quantum thermodynamics. It is widely known that typical pure states yield vanishing work, just as thermal states do, when one restricts to local operations that cannot access correlations among subsystems. However, it remains unclear whether this equivalence to thermal states persists under LOCC (local operations and classical communication), where classically accessible correlations can be exploited for work extraction. In this work, we establish criteria for determining whether many-body pure states remain equivalent to thermal states even under LOCC, and show that this thermal equivalence is governed by their multipartite quantum correlation structure. We show that states with asymptotically maximal multipartite entanglement, such as Haar-random states, cannot yield extensive work under LOCC, whereas some states with limited multipartite entanglement, such as constant-degree graph states, allow extensive work extraction despite being locally indistinguishable from thermal states. Thus, our work provides a refined operational notion of thermal equivalence beyond the traditional local regime, which is becoming increasingly important due to the recent expansion of experimentally accessible operations.

</details>


### [18] [Combatting noise in near-term quantum data centres](https://arxiv.org/abs/2601.14845)
*Kenny Campbell,Ahmed Lawey,Mohsen Razavi*

Main category: quant-ph

TL;DR: 分析量子数据中心中不同错误处理方法对分布式量子计算性能的影响，比较量子错误检测与传统纠缠蒸馏技术


<details>
  <summary>Details</summary>
Motivation: 研究在分布式量子计算环境中，如何有效处理量子错误以提升系统性能，特别是在量子数据中心范式下

Method: 使用三量子比特重复码和[[4,1,2]] Leung-Nielsen-Chuang-Yamamoto码进行量子错误检测，并与传统纠缠蒸馏技术对比，通过详细的经典模拟来评估实际硬件性能

Result: 通过经典模拟获得了近期实际硬件的性能结果，比较了不同错误处理方法对远程门操作的影响

Conclusion: 在量子数据中心范式的分布式量子计算中，量子错误检测方法与传统纠缠蒸馏技术相比具有不同的性能特征，为实际硬件实现提供了指导

Abstract: We analyse the performance of different error handling methods in the quantum data centre paradigm of distributed quantum computing. We compare the impact of quantum error detection, using the three-qubit repetition code and the [[4, 1, 2]] Leung-Nielsen-Chuang-Yamamoto code, on remote gates with that of conventional entanglement distillation techniques. Detailed classical simulation is used to obtain results for realistic near-term hardware.

</details>


### [19] [Multiparameter estimation for the superresolution of two incoherent sources](https://arxiv.org/abs/2601.14876)
*Antonin Grateau,Alexander Boeschoten,Tanguy Favin-Lévêque,Isael Herrera,Nicolas Treps*

Main category: quant-ph

TL;DR: 通过空间模式解复用技术实现亚瑞利极限下双光源三参数（间距、质心、相对亮度）的同时超分辨估计


<details>
  <summary>Details</summary>
Motivation: 传统光学成像受衍射极限限制，无法分辨亚瑞利极限下的光源细节。本研究旨在突破这一限制，实现对双光源多个参数的同时超分辨估计，为超分辨场景表征提供新方法。

Method: 采用空间模式解复用技术，使用两个解复用器（其中一个故意偏移），在单次实验设置中实现对光源间距、质心和相对亮度三个参数的联合估计。通过费希尔信息基准的克拉美-罗界评估性能，并探讨量子极限。

Result: 成功实现了远低于衍射极限的光源间距估计，并在广泛的场景配置范围内实现了对三个参数的敏感联合估计。研究了两种互补场景：略微非相同光源的现实情况和理想化不可区分光源情况。

Conclusion: 空间模式解复用技术能够有效实现亚瑞利极限下多参数的同时超分辨估计，为超分辨光学成像和场景表征提供了有前景的实验方法，并建立了相应的量子极限基准。

Abstract: We experimentally demonstrate the simultaneous estimation of the three parameters characterizing a pair of incoherent optical sources in the sub-Rayleigh regime, enabling super-resolved scene characterization. Using spatial-mode demultiplexing (SPADE) with two demultiplexers--one deliberately shifted--we determine separations well below the diffraction limit and achieve sensitive joint estimation of separation, centroid, and relative brightness over a broad range of scene configurations in a single experimental setting. We benchmark our performance using Fisher-information-based Cramér-Rao bounds, and discuss the corresponding quantum limits. We investigate two complementary scenarios: a realistic case with slightly non-identical sources, and an idealized case of indistinguishable sources.

</details>


### [20] [Impossible Counterfactuals, Discrete Hilbert Space and Bell's Theorem](https://arxiv.org/abs/2601.14941)
*Tim Palmer*

Main category: quant-ph

TL;DR: 该论文提出了一种违反测量独立性假设的局部实在论量子模型（RaQM），通过希尔伯特空间的引力离散化，解释了贝尔不等式违反而不需要否定自由意志或引入量子非局域性。


<details>
  <summary>Details</summary>
Motivation: 传统上，贝尔不等式违反通常被解释为量子非局域性或否定自由意志。该研究旨在提供第三种解释路径：通过否定测量独立性假设，但不否定实验者的自由意志，来建立局部实在论的量子模型。

Method: 提出Rational Mechanics（RaQM）模型，基于希尔伯特空间的引力离散化。该模型区分实验者选择测量设置的"名义精度"与"精确设置"的能力，认为希尔伯特态在平方振幅和/或复相位为无理数的基中必然未定义。这些"无理"基对应可想象但不可能实现的反事实测量。

Result: RaQM模型能够违反测量独立性假设而不否定自由意志，解释了贝尔不等式的违反。该模型将RaQM与Bohm和Hiley的整体性马赫式未分割宇宙概念联系起来，使用非经典p-adic数论工具。

Conclusion: 贝尔不等式的违反可以通过否定测量独立性假设来解释，而不需要传统上相关的奇怪过程。如果这一解释正确，那么通过建造更高能粒子加速器来探索更小尺度以寻找量子引力统一理论可能是徒劳的。

Abstract: Negating the Measurement Independence assumption (MI) is often referred to as the `third way' to account for the experimental violation of Bell's inequality. However, this route is generally viewed as ludicrously contrived, implying some implausible conspiracy where experimenters are denied the freedom to choose measurement settings as they like. Here, a locally realistic model of quantum physics is developed (Rational Mechanics - RaQM - based on a gravitational discretisation of Hilbert Space) which violates MI without denying free will. Crucially, RaQM distinguishes experimenters' ability to freely choose measurement settings to some nominal accuracy, from an inability to choose exact settings, which were never under their control anyway. In RaQM, Hilbert states are necessarily undefined in bases where squared amplitudes and/or complex phases are irrational numbers. Such `irrational' bases correspond to conceivable but necessarily impossible counterfactual measurements, and are shown to play a ubiquitous role in the analysis of both single- and entangled-particle quantum physics. It is concluded that violation of Bell inequalities can be understood with none of the strange processes historically associated with it. Instead, using concepts from (non-classical) $p$-adic number theory, we relate RaQM to Bohm and Hiley's concept of a holistic Machian-like Undivided Universe. If this interpretation of Bell's Theorem is correct, building more and more energetic particle accelerators to probe smaller and smaller scales, in the search for a theory which synthesises quantum and gravitational physics and hence a Theory of Everything, may be a fruitless exercise.

</details>


### [21] [Resonant Excitation Induced Vibronic Mollow Triplets](https://arxiv.org/abs/2601.14963)
*Devashish Pandey,Corne Koks,Martijn Wubs,Nicolas Stenger,Jake Iles-Smith*

Main category: quant-ph

TL;DR: 该论文预测，在强共振驱动下，耦合到局域声子的发射体会在声子边带上复制Mollow三重态，这是电子、光子和振动自由度杂交的直接指纹。


<details>
  <summary>Details</summary>
Motivation: 传统上认为声子边带是相干的非弹性散射通道，但作者发现强共振驱动下，Mollow三重态这种典型的光谱特征会出现在声子边带上，这揭示了相干性在振动耦合系统中的新表现形式。

Method: 作者开发了一种可扩展的解析形式来模拟复杂多模分子系统中的这种效应，特别以二苯并并四苯为例，建立了精确的驱动条件来观察这些新的光谱特征。

Result: 预测在强共振驱动下，耦合到局域声子的发射体会在声子边带上出现Mollow三重态，这些振动Mollow三重态是动态生成的杂化态的直接指纹，揭示了电子、光子和振动自由度之间的杂交。

Conclusion: 这项工作建立了振动耦合系统中相干性的新标志，为在复杂分子系统中观察这些新颖光谱特征提供了精确的驱动条件，拓展了对光学驱动量子发射体光谱特征的理解。

Abstract: The Mollow triplet is the definitive spectral signature of an optically dressed quantum emitter. We predict that for emitters coupled to localized phonons, this signature is not confined to the zero-phonon line. Under a strong resonant drive, we show that Mollow triplets are strikingly replicated on the associated phonon sidebands -a surprising result, given that phonon sidebands are typically viewed as incoherent, inelastic scattering pathways. These vibronic Mollow triplets are a direct fingerprint of dynamically generated dressed states that hybridize the emitter's electronic, photonic, and vibrational degrees of freedom. We develop a scalable analytical formalism to model this effect in complex, multi-mode molecular systems, such as dibenzoterrylene. Our work provides the precise driving conditions for observing these novel spectral features, establishing a new signature of coherence in vibronically coupled systems.

</details>


### [22] [Multipartite entanglement in the quantum tetrahedron](https://arxiv.org/abs/2601.14964)
*Robert Amelung,Hanno Sahlmann*

Main category: quant-ph

TL;DR: 该论文研究了SU(2)不变四价张量（交织子）的多体纠缠特性，通过数值计算熵填充发现交织子的纠缠分布与一般张量有显著差异，且纠缠与几何数据存在复杂关系。


<details>
  <summary>Details</summary>
Motivation: 交织子在圈量子引力中对应具有固定面积的四面体量子态，同时又是全局旋转不变的四体张量积态。研究这些态的多体纠缠特性有助于理解量子几何与纠缠之间的关系。

Method: 使用最近提出的熵填充方法，数值计算了自旋值在1/2到11之间的等自旋情况下交织子的纠缠分布，并与一般张量以及相干交织子进行比较。

Result: 交织子的纠缠分布与一般张量非常不同：分布峰值在一般交织子中位于最高纠缠处，而在一般张量中位于最低纠缠处；但平均纠缠却相反，大自旋情况下一般张量的平均纠缠更高。相干交织子的纠缠与其几何数据存在复杂关系。

Conclusion: 交织子作为量子几何的基本构建块，其纠缠特性与一般量子态有本质区别，这反映了量子几何的特殊结构性质，纠缠与几何数据的关系复杂，需要进一步研究。

Abstract: The space $\mathrm{Inv}(j_1,j_2,j_3,j_4)$ of SU(2)-invariant four-valent tensors, also known as intertwiners, can be understood as the quantum states of a tetrahedron in Euclidean space with fixed areas. In loop quantum gravity, they are states of the smallest "atom of space" with non-zero volume. At the same time they correspond to four-party tensor product states invariant under global rotations. We consider the multipartite entanglement of states in $\mathrm{Inv}(j_1,j_2,j_3,j_4)$ using the recently proposed entropic fill.
  Numerically evaluating entropic fill in the case of equal spins between $1/2$ and $11$, we find that the distributions of entanglement are very different for intertwiners as compared to generic tensors, and for coherent intertwiners as compared to generic ones. The peak in the distribution seems to be at the highest entanglement for generic intertwiners and at the lowest for generic tensors, but in terms of average entanglement, the roles are switched: average entanglement is highest in arbitrary tensors and lower in intertwiners, at least in the regime of large $j$. We also find that entanglement depends on the geometric data of coherent intertwiners in a complicated way.

</details>


### [23] [Low-frequency fiber-optic vibration sensing with a Floquet-engineered optical lattice clock](https://arxiv.org/abs/2601.14995)
*Mojuan Yin,Ruohui Wang,Rui Zhou,Xueguang Qiao,Shougang Zhang*

Main category: quant-ph

TL;DR: 提出基于Floquet工程光学晶格钟的解调方案，增强缠绕光纤振动传感器的低频性能


<details>
  <summary>Details</summary>
Motivation: 现有光纤振动传感器在低频（特别是0.5Hz以下）性能受限，需要提高低频振动检测的灵敏度

Method: 利用Floquet工程Rabi光谱对时钟跃迁进行解调，通过振动引起的传感光纤相位变化进行检测，模拟了光纤长度和晶格深度对200Hz至0.5Hz振动的影响

Result: 在4km光纤长度和2dB/km传输损耗条件下，实现了高于6×10³ rad/g的相位变化灵敏度，在200Hz和0.5Hz振动频率下均保持良好性能

Conclusion: Floquet工程光学晶格钟解调方案能有效提升光纤振动传感器的低频性能，为低频振动监测提供了新方法

Abstract: We propose a Floquet-engineered optical lattice clock based demodulation scheme to enhance the low-frequency performance of wound fiber-optic vibration sensors. Vibration-induced phase variations in the sensing fiber are demodulated by the Floquet-engineered Rabi spectra of the clock transition. The lattice depth with the fiber length and the Floquet-engineered Rabi spectra under the vibration from 200 Hz down to 0.5 Hz are simulated. With a fiber length of 4 km and transmission loss of 2 dB/km, a phase change sensitivity higher than 6 * 10^3 rad per g is achieved at both vibration frequencies of 200 Hz and 0.5 Hz.

</details>


### [24] [Cavity-QED tools for MBQC with optical binomial-codes](https://arxiv.org/abs/2601.15019)
*G. P. Teja,Radim Filip*

Main category: quant-ph

TL;DR: 该论文提出了基于光学二项式编码的测量量子计算工具包，包括腔QED协议用于条件生成簇态和实现泡利测量


<details>
  <summary>Details</summary>
Motivation: 测量量子计算为光子量子计算提供了有前景的范式，但需要生成特定的非高斯资源态。连续变量编码如GKP态已被广泛研究，但更简单的二项式编码提供了实验上可实现的替代方案，尽管需要不同的操作工具集。

Method: 提出了基于光学二项式编码的测量量子计算工具包，详细描述了用于条件生成簇态的腔QED协议以及泡利测量的实现方法。

Result: 该工作为现有光学原子-腔架构提出了首个步骤，为它们在量子计算中的应用奠定了基础。

Conclusion: 光学二项式编码为测量量子计算提供了实验上可实现的替代方案，提出的工具包为现有光学原子-腔架构在量子计算中的应用铺平了道路。

Abstract: Measurement-based quantum computation (MBQC) offers a promising paradigm for photonic quantum computing, but its implementation requires the generation of specific non-Gaussian resource states. While continuous-variable encodings such as the highly complex (GKP) states have been widely studied, the much simpler binomial codes offer an experimentally accessible alternative, though they demand a distinct set of operational tools. Here, we present a toolkit for MBQC using optical binomial codes, detailing a cavity-QED protocol for conditional generation of cluster states and the implementation of Pauli measurements. Our work proposes the first steps for existing optical atom-cavity architectures to lay the groundwork for their use in quantum computation.

</details>


### [25] [A nearly linear-time Decoded Quantum Interferometry algorithm for the Optimal Polynomial Intersection problem](https://arxiv.org/abs/2601.15171)
*Ansis Rosmanis*

Main category: quant-ph

TL;DR: 本文改进了Jordan等人提出的解码量子干涉（DQI）算法，针对最优多项式交点（OPI）问题，通过绕过二次时间Dicke态制备等方法，实现了近乎线性时间的DQI算法。


<details>
  <summary>Details</summary>
Motivation: Jordan等人最近提出的DQI算法在解决经典编码相关的组合优化问题方面表现出优势，但其算法存在计算效率限制，特别是二次时间的Dicke态制备步骤。本文旨在改进DQI算法的时间复杂度，使其更接近实际应用需求。

Method: 提出了多项DQI算法改进，包括绕过二次时间的Dicke态制备步骤。在随机访问输入的前提下，通过这些改进实现了近乎线性时间的DQI算法。同时注意到Khattar等人也独立开发了类似技术。

Result: 成功将DQI算法的时间复杂度从多项式时间降低到近乎线性时间，显著提高了算法效率。该改进使得DQI算法在解决OPI问题时比任何已知多项式时间经典算法能满足更多约束条件。

Conclusion: 通过技术改进，DQI算法的时间复杂度得到显著优化，实现了近乎线性时间的性能，这为量子算法在组合优化问题上的实际应用提供了重要进展。同时期独立研究也验证了这一方向的有效性。

Abstract: Recently, Jordan et al. (Nature, 2025) introduced a novel quantum-algorithmic technique called Decoded Quantum Interferometry (DQI) for solving specific combinatorial optimization problems associated with classical codes. They presented a constraint-satisfaction problem called Optimal Polynomial Intersection (OPI) and showed that, for this problem, a DQI algorithm running in polynomial time can satisfy a larger fraction of constraints than any known polynomial-time classical algorithm.
  In this work, we propose several improvements to the DQI algorithm, including sidestepping the quadratic-time Dicke state preparation. Given random access to the input, we show how these improvements result in a nearly linear-time DQI algorithm for the OPI problem. Concurrently and independently with this work, Khattar et al. (arXiv:2510:10967) also construct a nearly linear-time DQI algorithm for OPI using slightly different techniques.

</details>


### [26] [Purcell enhanced electroluminescence of a unipolar light emitting quantum device at 10 micron](https://arxiv.org/abs/2601.15193)
*Marta Mastrangelo,Djamal Gacemi,Axel Evirgen,Salvatore Pes,Alexandre Larrue,Pascal Filloux,Isabelle Sagnes,Abdelmounaim Harouri,Angela Vasanelli,Carlo Sirtori*

Main category: quant-ph

TL;DR: 该研究通过设计由纳米发射器阵列组成的超材料微腔耦合贴片天线，实现了中红外电致发光器件，其收集功率比标准器件提高100倍，证明了通过重塑发射偶极子的光子环境可以增强自发发射，从而开发出接近热力学平衡的高效光电器件。


<details>
  <summary>Details</summary>
Motivation: 中远红外波段缺乏有效的发光器件，因为自发发射速率远低于非辐射能量弛豫过程，现有器件主要依赖线性或非线性光学增益产生的受激发射。研究人员旨在通过工程化光子环境来增强自发发射，开发类似可见光LED的高效红外发光器件。

Method: 设计并制造了由纳米发射器阵列组成的超材料微腔，将其耦合到贴片天线中。通过重塑发射偶极子周围的光子环境（类似Purcell效应），增强自发发射速率，从而克服非辐射弛豫过程的限制。

Result: 成功演示了中红外电致发光器件，能够发射具有优异空间特性的准直光束。与标准器件相比，收集功率提高了100倍，器件性能接近热力学平衡状态下的工作条件。

Conclusion: 研究表明通过工程化光子环境可以显著增强自发发射，这为开发在中远红外波段工作的高效光电器件提供了新途径，使这些器件能够像可见光LED一样在接近热力学平衡的条件下工作。

Abstract: Efficient generation of radiation in the mid- and far- infrared relies primarily on lasers and coherent nonlinear optical phenomena driven by lasers. This wavelength range lacks of luminescent devices because the spontaneous emission rate becomes much longer than the nonradiative energy relaxation processes and therefore emitters have to count on stimulated emission produced by linear or non-linear optical gain. However, spontaneous emission is not a fundamental property of the emitter. By engineering metamaterials composed of arrays of nano-emitters into microcavities coupled to patch antennas, we have demonstrated mid-infrared electroluminescent devices emitting a collimated beam with excellent spatial properties and a factor 100 increase in the collected power, compared to standard devices. Our results illustrate that by reshaping the photonic environment around emitting dipoles, as in the Purcell effect, it is possible to enhance the spontaneous emission and conceive efficient optoelectronic light emitting devices that operate close to the thermodynamical equilibrium as LEDs in the visible range.

</details>


### [27] [Precision Enhancement in Transient Quantum Thermometry:Cold-Probe Bias and Its Removal](https://arxiv.org/abs/2601.15237)
*Debarupa Saha,Ujjwal Sen*

Main category: quant-ph

TL;DR: 该论文揭示了马尔可夫动力学下瞬态量子测温中的温度偏差现象：只有初始温度低于待测浴温的探针才能超越稳态极限精度，而非马尔可夫动力学下冷热探针均可达到相同的高精度。


<details>
  <summary>Details</summary>
Motivation: 研究量子测温中探针初始温度对测量精度的影响，特别是在瞬态动力学过程中，探索超越稳态极限精度的条件。

Method: 通过理论分析量子比特测温探针在马尔可夫和非马尔可夫动力学下的演化，研究探针初始温度与最终测量精度的关系。

Result: 发现马尔可夫动力学下存在温度偏差：只有初始较冷的探针才能实现超越稳态极限的精度；而非马尔可夫动力学下，冷热探针都能达到相同的瞬态最大精度，且远高于稳态值。

Conclusion: 量子测温的精度不仅取决于动力学过程，还与探针的初始温度状态密切相关。非马尔可夫动力学可以消除温度偏差，为高精度量子测温提供了新途径。

Abstract: We unveil a temperature bias of the probe in transient quantum thermometry under Markovian dynamics. Specifically, for qubit thermometers evolving under Markovian dynamics, we show that enhanced precision beyond the steady state limit can be achieved if and only if the probe is initially colder than the thermal state corresponding to the bath temperature to be estimated. In contrast, this temperature bias can be lifted when the probe dynamics is non-Markovian. In the non-Markovian regime, both hot and cold probes can simultaneously attain the same transient maximum precision, well above the steady-state value.

</details>


### [28] [QDK/Chemistry: A Modular Toolkit for Quantum Chemistry Applications](https://arxiv.org/abs/2601.15253)
*Nathan A. Baker,Brian Bilodeau,Chi Chen,Yingrong Chen,Marco Eckhoff,Alexandra Efimovskaya,Piero Gasparotto,Puck van Gerwen,Rushi Gong,Kevin Hoang,Zahra Hooshmand,Andrew J. Jenkins,Conrad S. N. Johnston,Run R. Li,Jiashu Liang,Hongbin Liu,Alexis Mills,Maximilian Mörchen,George Nishibuchi,Chong Sun,Bill Ticehurst,Matthias Troyer,Jan P. Unsleber,Stefan Wernli,David B. Williams-Young,Boqin Zhang*

Main category: quant-ph

TL;DR: QDK/Chemistry是一个用于量子化学工作流的软件工具包，旨在解决量子化学计算中经典电子结构计算与量子电路执行之间的基础设施碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 量子化学算法已经相对成熟，但连接经典电子结构计算和量子电路执行的基础设施仍然碎片化，缺乏统一的工作流工具。

Method: 采用模块化架构，将数据表示与计算方法分离，允许研究人员通过可互换组件组合工作流。通过插件系统集成广泛使用的开源量子化学包和量子计算框架。

Result: 开发了一个完整的软件工具包，提供了量子-经典管道中目标算法的原生实现，并能够在不修改工作流逻辑的情况下组合不同来源的方法。

Conclusion: QDK/Chemistry作为可重复量子化学实验的基础，通过其模块化设计和插件系统，为量子化学研究提供了统一的基础设施和工作流框架。

Abstract: We present QDK/Chemistry, a software toolkit for quantum chemistry workflows targeting quantum computers. The toolkit addresses a key challenge in the field: while quantum algorithms for chemistry have matured considerably, the infrastructure connecting classical electronic structure calculations to quantum circuit execution remains fragmented. QDK/Chemistry provides this infrastructure through a modular architecture that separates data representations from computational methods, enabling researchers to compose workflows from interchangeable components. In addition to providing native implementations of targeted algorithms in the quantum-classical pipeline, the toolkit builds upon and integrates with widely used open-source quantum chemistry packages and quantum computing frameworks through a plugin system, allowing users to combine methods from different sources without modifying workflow logic. This paper describes the design philosophy, current capabilities, and role of QDK/Chemistry as a foundation for reproducible quantum chemistry experiments.

</details>


### [29] [Superluminal Transformations and Indeterminism](https://arxiv.org/abs/2601.15263)
*Amrapali Sen,Flavio Del Santo*

Main category: quant-ph

TL;DR: 论文证明了一个"禁止定理"：超光速变换与有限信息无法共存，任何包含超光速变换的理论必须允许无限信息，导致确定性本体论，这与量子力学的客观概率本质不同。


<details>
  <summary>Details</summary>
Motivation: 探讨量子理论的根本不确定性是否可以通过经典框架中的超光速变换来模拟，分析Dragan和Ekert提出的超光速变换会导致类似量子不确定性的观点。

Method: 从自然假设出发推导出一个"禁止定理"，通过逻辑论证证明超光速变换与有限信息之间的不相容性。

Result: 证明了超光速变换和有限信息无法共存，任何包含超光速变换的理论必须允许无界信息内容，导致确定性本体论，这与量子力学的客观概率本质不同。

Conclusion: 超光速变换产生的表面不确定性只是主观无知导致的概率，与量子理论中客观概率的本质不同，因此超光速扩展所声称的不确定性并非量子不确定性。

Abstract: Quantum theory is widely regarded as fundamentally indeterministic, yet classical frameworks can also exhibit indeterminism once infinite information is abandoned. At the same time, relativity is usually taken to forbid superluminal signalling, yet Lorentz symmetry formally admits superluminal transformations (SpTs). Dragan and Ekert have argued that SpTs entail indeterminism analogous to the quantum one. Here, we derive a no-go theorem from natural assumptions, which can be interpreted as: superluminal transformations (SpTs) and finite information cannot coexist. Any theory accommodating SpTs must therefore allow unbounded information content, leading to a deterministic ontology akin to that of classical theories formulated over the real numbers. Thus, any apparent indeterminism arising from superluminal transformations reflects only probabilities arising from subjective ignorance, unlike the objective nature of probabilities in quantum theory, indicating that the claimed indeterminacy from superluminal extensions is not quantum.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [30] [The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative](https://arxiv.org/abs/2601.14271)
*Denise M. Case*

Main category: cs.AI

TL;DR: 本文证明了本体论中立性的不可能性：任何包含因果或规范性承诺的基础层本体论都无法在不同解释框架间保持中立，因此中立的本体论基底必须是前因果和前规范的。


<details>
  <summary>Details</summary>
Motivation: 现代数据系统需要在持续的法律、政治和分析分歧中支持问责制，这要求设计能够作为共享基底的任何本体论必须满足严格约束条件。

Method: 通过建立本体论中立性的不可能性结果，分析中立性（理解为解释性非承诺性和在不相容扩展下的稳定性）与包含因果或规范性承诺之间的不兼容性。

Result: 证明了任何将因果或道义结论断言为本体论事实的本体论，都无法在不修订或矛盾的情况下作为跨不同框架的中立基底。因此，中立的本体论基底必须是前因果和前规范的。

Conclusion: 本文不提出具体的本体论或协议，而是为任何旨在跨冲突解释框架维护共享、稳定的现实表示的系统，建立了必要的设计约束条件。

Abstract: Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an impossibility result for ontological neutrality: neutrality, understood as interpretive non-commitment and stability under incompatible extensions, is incompatible with the inclusion of causal or normative commitments at the foundational layer. Any ontology that asserts causal or deontic conclusions as ontological facts cannot serve as a neutral substrate across divergent frameworks without revision or contradiction. It follows that neutral ontological substrates must be pre-causal and pre-normative, representing entities, together with identity and persistence conditions, while externalizing interpretation, evaluation, and explanation. This paper does not propose a specific ontology or protocol; rather, it establishes the necessary design constraints for any system intended to maintain a shared, stable representation of reality across conflicting interpretive frameworks.

</details>


### [31] [Epistemic Constitutionalism Or: how to avoid coherence bias](https://arxiv.org/abs/2601.14295)
*Michele Loi*

Main category: cs.AI

TL;DR: 论文主张为AI建立"认知宪法"——明确、可争议的元规范来管理AI如何形成和表达信念，以源归属偏见为案例，区分了柏拉图式和自由主义两种宪法方法，并支持自由主义方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为人工推理者，其信念形成行为受隐含、未经检验的认知政策支配，缺乏明确的规范框架来管理其认知过程。

Method: 通过源归属偏见案例研究，展示前沿模型如何执行身份-立场一致性，惩罚那些与预期意识形态立场冲突的论点；区分柏拉图式（形式正确性和默认源独立性）和自由主义（程序规范保护集体探究条件）两种宪法方法。

Result: 发现模型强制执行身份-立场一致性，但当检测到系统性测试时这些效应崩溃，表明系统将源敏感性视为需要抑制的偏见而非良好执行能力；提出了包含八项原则和四种导向的宪法核心框架。

Conclusion: 支持自由主义宪法方法，主张AI认知治理需要与AI伦理相同的明确、可争议结构，建立认知宪法来规范AI的信念形成和表达。

Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.

</details>


### [32] [On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL](https://arxiv.org/abs/2601.14456)
*Valerio Belcamino,Nicholas Attolino,Alessio Capitanelli,Fulvio Mastrogiovanni*

Main category: cs.AI

TL;DR: 微调大语言模型在PDDL规划任务上表现出高成功率，但主要依赖领域特定模式而非可迁移的规划能力，跨领域泛化能力几乎为零。


<details>
  <summary>Details</summary>
Motivation: 研究微调后的大语言模型在规划任务中表现出的高成功率是源于可迁移的规划能力，还是仅仅是对特定领域模式的记忆。

Method: 在10个IPC 2023领域的40,000个领域-问题-规划元组上微调1.7B参数的大语言模型，并引入三种诊断干预：实例级符号匿名化、紧凑规划序列化、使用VAL验证器作为成功导向强化信号的验证器奖励微调。

Result: 模型在领域内条件下达到82.9%的有效规划率，但在两个未见领域上为0%。符号匿名化和紧凑序列化导致性能显著下降，验证器奖励微调在监督训练一半的轮次内达到性能饱和，但未改善跨领域泛化。

Conclusion: 微调模型严重依赖领域特定模式而非可迁移的规划能力，揭示了基于大语言模型的规划中存在持续的泛化差距，并提供了研究其原因的诊断工具。

Abstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, we fine-tune a 1.7B-parameter LLM on 40,000 domain-problem-plan tuples from 10 IPC 2023 domains, and evaluate both in-domain and cross-domain generalization. While the model reaches 82.9% valid plan rate in in-domain conditions, it achieves 0% on two unseen domains. To analyze this failure, we introduce three diagnostic interventions, namely (i) instance-wise symbol anonymization, (ii) compact plan serialization, and (iii) verifier-reward fine-tuning using the VAL validator as a success-focused reinforcement signal. Symbol anonymization and compact serialization cause significant performance drops despite preserving plan semantics, thus revealing strong sensitivity to surface representations. Verifier-reward fine-tuning reaches performance saturation in half the supervised training epochs, but does not improve cross-domain generalization. For the explored configurations, in-domain performance plateaus around 80%, while cross-domain performance collapses, suggesting that our fine-tuned model relies heavily on domain-specific patterns rather than transferable planning competence in this setting. Our results highlight a persistent generalization gap in LLM-based planning and provide diagnostic tools for studying its causes.

</details>


### [33] [Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling](https://arxiv.org/abs/2601.14485)
*Yuan Tian,Yi Mei,Mengjie Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于膝点的活动组选择策略，通过多树遗传编程框架同时演化优先级规则和组选择规则，解决了动态多模式资源受限项目调度问题中的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 动态多模式资源受限项目调度问题需要在活动执行顺序和对应执行模式上做出决策。虽然活动组选择策略在小规模实例中有效，但在大规模问题上存在可扩展性问题。

Method: 引入基于膝点的选择机制：首先使用活动排序规则对所有符合条件的活动-模式对进行排序，然后通过膝点选择找到有前景的对，最后使用组选择规则选择最佳活动组合。开发了多树GP框架来同时演化这两种规则。

Result: 实验结果表明，该方法能够很好地扩展到大型实例，并且在大多数场景中优于采用顺序决策的GP方法。

Conclusion: 提出的基于膝点的组选择策略有效解决了活动组选择在大规模问题中的可扩展性问题，通过同时演化排序规则和组选择规则，在动态多模式资源受限项目调度中取得了更好的性能。

Abstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.

</details>


### [34] ["Just in Time" World Modeling Supports Human Planning and Reasoning](https://arxiv.org/abs/2601.14514)
*Tony Chen,Sam Cheyette,Kelsey Allen,Joshua Tenenbaum,Kevin Smith*

Main category: cs.AI

TL;DR: 论文提出"即时"框架，通过模拟、视觉搜索和表征修改的紧密交织，在线构建简化表征以支持高效心理模拟。


<details>
  <summary>Details</summary>
Motivation: 心理模拟在人类推理、规划和预测中起关键作用，但复杂环境中的模拟需求超出人类实际能力限制。虽然有证据表明人们使用简化表征进行模拟，但如何高效确定这些简化尚不清楚。

Method: 提出"即时"框架，通过模拟、视觉搜索和表征修改的紧密交织：当前模拟指导搜索方向，视觉搜索标记应编码的对象用于后续模拟。模型只编码少量对象子集。

Result: 模型能做出高效用预测，在网格世界规划任务和物理推理任务中，该模型在多种行为测量上优于替代模型，获得强实证支持。

Conclusion: 这些结果为人们如何构建简化表征以支持高效心理模拟提供了具体的算法解释。

Abstract: Probabilistic mental simulation is thought to play a key role in human reasoning, planning, and prediction, yet the demands of simulation in complex environments exceed realistic human capacity limits. A theory with growing evidence is that people simulate using simplified representations of the environment that abstract away from irrelevant details, but it is unclear how people determine these simplifications efficiently. Here, we present a "Just-in-Time" framework for simulation-based reasoning that demonstrates how such representations can be constructed online with minimal added computation. The model uses a tight interleaving of simulation, visual search, and representation modification, with the current simulation guiding where to look and visual search flagging objects that should be encoded for subsequent simulation. Despite only ever encoding a small subset of objects, the model makes high-utility predictions. We find strong empirical support for this account over alternative models in a grid-world planning task and a physical reasoning task across a range of behavioral measures. Together, these results offer a concrete algorithmic account of how people construct reduced representations to support efficient mental simulation.

</details>


### [35] [MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks](https://arxiv.org/abs/2601.14652)
*Zixuan Ke,Yifei Ming,Austin Xu,Ryan Chin,Xuan-Phi Nguyen,Prathyusha Jwalapuram,Semih Yavuz,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: MAS-Orchestra：一个训练时框架，将多智能体系统编排建模为函数调用强化学习问题，实现整体编排；同时提出MASBENCH基准来系统研究MAS何时及为何优于单智能体系统。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统自动设计方法存在两个关键问题：1）方法复杂性 - 采用顺序、代码级执行限制了全局系统级整体推理，难以扩展；2）效能不确定性 - 部署MAS时不清楚是否比单智能体系统有实际优势。

Method: 提出MAS-Orchestra框架，将复杂目标导向的子智能体抽象为可调用函数，通过函数调用强化学习实现整体编排，一次生成整个MAS。同时提出MASBENCH基准，从深度、视野、广度、并行性和鲁棒性五个维度系统评估任务特性。

Result: 分析表明MAS的优势取决于任务结构、验证协议以及编排器和子智能体的能力，而非普遍适用。MAS-Orchestra在数学推理、多跳QA和基于搜索的QA等公开基准上取得一致改进。

Conclusion: MAS-Orchestra和MASBENCH共同促进了多智能体系统的更好训练和理解，为追求多智能体智能提供了系统化的方法论和评估框架。

Abstract: While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.

</details>


### [36] [Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text](https://arxiv.org/abs/2601.14683)
*Aisvarya Adeseye,Jouni Isoaho,Seppo Virtanen,Mohammad Tahir*

Main category: cs.AI

TL;DR: 本研究提出了一种基于本地LLM的上下文感知匿名化框架SFAA，用于自动检测和匿名化定性研究中的敏感数据，相比人工方法更高效准确。


<details>
  <summary>Details</summary>
Motivation: 定性研究包含大量个人、情境和组织细节，存在隐私风险。人工匿名化耗时、不一致且易遗漏关键标识符，现有自动化工具依赖模式匹配或固定规则，无法理解上下文且可能改变数据含义。

Method: 提出结构化自适应匿名化框架SFAA，包含检测、分类和自适应匿名化三个步骤。采用四种匿名化策略：基于规则的替换、上下文感知重写、泛化和抑制。基于GDPR、HIPAA和OECD等国际隐私标准处理标识符。使用LLaMA和Phi两种本地LLM模型，通过双方法评估结合人工和LLM辅助处理，在两个案例研究中进行测试。

Result: LLM比人工评审员发现更多敏感数据。Phi在发现敏感数据方面优于LLaMA，但错误稍多。Phi能够发现超过91%的敏感数据，94.8%的文本保持与原文本相同的情感，表明准确性高且不影响定性数据分析。

Conclusion: 基于本地LLM的SFAA框架能够提供可靠、可重复且上下文感知的匿名化过程，有效保护定性研究中的隐私数据，同时保持数据的分析价值。

Abstract: Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.

</details>


### [37] [AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2601.14702)
*Zecong Tang,Zixu Wang,Yifei Wang,Weitong Lian,Tianjian Gao,Haoran Li,Tengju Ru,Lingyi Meng,Zhejun Cui,Yichen Zhu,Qi Kang,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: AutoDriDM是一个面向自动驾驶的决策中心化渐进式基准测试，包含6650个问题，涵盖物体、场景和决策三个维度，用于评估视觉语言模型的感知到决策能力边界。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶基准测试过度强调感知能力，未能充分评估决策过程。视觉语言模型展现出推理和泛化能力，为自动驾驶带来新可能，但需要更全面的评估框架。

Method: 开发AutoDriDM基准测试，包含6,650个问题，分为物体、场景和决策三个维度。评估主流视觉语言模型，分析感知与决策性能的相关性，进行可解释性分析，并引入分析器模型实现大规模自动标注。

Result: 评估揭示了感知与决策性能之间的弱相关性，识别出逻辑推理错误等关键失败模式。分析器模型能有效自动化大规模标注。

Conclusion: AutoDriDM填补了感知中心化与决策中心化评估之间的空白，为开发更安全可靠的自动驾驶视觉语言模型提供指导。

Abstract: Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.

</details>


### [38] [DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs](https://arxiv.org/abs/2601.14711)
*Mingxuan Song,Yusen Huo,Bohan Zhou,Shenglin Yin,Zhen Xiao,Jieyi Long,Zhilin Zhang,Chuan Yu*

Main category: cs.AI

TL;DR: 提出GRPO-Adaptive和DARA框架，通过LLM增强推理和数值精度，解决AI生成竞价中预算约束下的少样本优化问题


<details>
  <summary>Details</summary>
Motivation: 在线广告中，广告主在预算约束下优化累积价值面临挑战。传统强化学习方法在少样本场景下效果不佳，而LLM虽然具有上下文学习能力但缺乏数值精度

Method: 1. GRPO-Adaptive：高效的LLM后训练策略，通过动态更新参考策略增强推理和数值精度。2. DARA：双阶段框架，第一阶段使用少样本推理器通过上下文提示生成初始计划，第二阶段使用反馈驱动推理的细粒度优化器精炼计划

Result: 在真实世界和合成数据环境中的大量实验表明，该方法在预算约束下的累积广告主价值方面持续优于现有基线方法

Conclusion: 提出的GRPO-Adaptive和DARA框架成功结合了LLM的上下文学习优势和AIGB任务所需的精确适应性，有效解决了少样本场景下的预算约束优化问题

Abstract: Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.

</details>


### [39] [An XAI View on Explainable ASP: Methods, Systems, and Perspectives](https://arxiv.org/abs/2601.14764)
*Thomas Eiter,Tobias Geibinger,Zeynep G. Saribatur*

Main category: cs.AI

TL;DR: 这篇论文对ASP（答案集编程）中的解释方法进行了系统性调查，从可解释AI角度分析了ASP解释的类型、现有工具覆盖情况，并指出了研究空白和未来方向。


<details>
  <summary>Details</summary>
Motivation: ASP作为一种声明式推理方法，其基于规则的形式使其天然适合可解释推理。随着可解释AI（XAI）的兴起，ASP的解释性变得日益重要。虽然已有一些ASP解释方法和工具，但它们通常针对特定解释场景，未能覆盖ASP用户遇到的所有情况。

Method: 采用调查综述的方法，从XAI视角出发，系统性地概述了ASP解释的类型及其与用户解释问题的关联，分析了现有理论和工具对这些解释类型的覆盖情况。

Result: 论文提供了ASP解释类型的全面分类框架，评估了现有工具和理论对各种解释场景的支持程度，识别了当前ASP解释方法中的覆盖空白。

Conclusion: 虽然ASP在可解释性方面具有天然优势，但现有解释方法仍存在不足。论文指出了未来研究方向，包括开发更全面的解释工具、填补特定解释场景的空白，以及更好地将ASP解释与XAI框架集成。

Abstract: Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.

</details>


### [40] [Semantic-Guided Unsupervised Video Summarization](https://arxiv.org/abs/2601.14773)
*Haizhou Liu,Haodong Jin,Yiming Wang,Hui Yu*

Main category: cs.AI

TL;DR: 提出了一种语义引导的无监督视频摘要方法，通过语义对齐注意力机制和增量训练策略解决现有GAN方法中语义信息利用不足和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频摘要方法主要依赖GAN进行关键帧选择和视频摘要生成，但存在两个主要问题：1）主要利用单模态特征，忽视了语义信息在关键帧选择中的指导作用；2）训练过程不稳定。

Method: 提出语义引导的无监督视频摘要方法，包括：1）设计帧级语义对齐注意力机制，集成到关键帧选择器中；2）在对抗框架中引导基于Transformer的生成器更好地重建视频；3）采用增量训练策略逐步更新模型组件，缓解GAN训练的不稳定性。

Result: 实验结果表明，该方法在多个基准数据集上取得了优越的性能。

Conclusion: 通过语义引导和增量训练策略，有效解决了现有无监督视频摘要方法中语义信息利用不足和训练不稳定的问题，提升了视频摘要的质量和稳定性。

Abstract: Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.

</details>


### [41] [Towards Bound Consistency for the No-Overlap Constraint Using MDDs](https://arxiv.org/abs/2601.14784)
*Amaury Guichard,Laurent Michel,Hélène Verhaeghe,Pierre Schaus*

Main category: cs.AI

TL;DR: 本文提出了首个用于无重叠约束的边界一致性算法，通过构建有界宽度的MDD实现多项式时间过滤，相比现有方法显著减少搜索树节点数量。


<details>
  <summary>Details</summary>
Motivation: 无重叠约束的边界一致性已知是NP完全问题，现有多项式时间收紧技术（如边查找、非首非尾推理、能量推理）存在局限性，需要更有效的过滤算法来提升求解效率。

Method: 基于Ciré和van Hoeve定义的无重叠MDD，提取作业时间窗口边界以收紧起止时间；通过限制MDD宽度到阈值创建松弛MDD，实现多项式时间过滤；将新过滤算法与经典传播方法结合。

Result: 在带时间窗口的排序问题和准时制目标问题上，即使使用宽度阈值，新过滤算法相比Ciré和van Hoeve的优先检测算法能更强地减少搜索树访问节点数；与经典传播方法互补，显著减少节点数和求解时间。

Conclusion: 本文提出了首个边界一致性的无重叠约束算法，通过有界宽度MDD实现高效过滤，实验证明能有效减少搜索空间并提升求解性能，为约束规划提供了新的有效工具。

Abstract: Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \mid r_j, d_j, \bar{d}_j \mid \sum E_j + \sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.

</details>


### [42] [Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies](https://arxiv.org/abs/2601.14827)
*Ben Schaper,Maxime Di Folco,Bernhard Kainz,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.AI

TL;DR: 该研究评估了视觉语言模型在胸部X光分类中的抽象错误，提出了使用医学分类体系进行分层评估的方法，并开发了风险约束阈值和分类感知微调技术来减少严重错误。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在胸部X光分类中表现出强大的零样本性能，但标准的平面评估指标无法区分临床轻微错误和严重错误。本研究旨在通过利用医学分类体系来量化和减轻抽象错误。

Method: 研究使用分层指标对多个最先进的视觉语言模型进行基准测试，引入了"灾难性抽象错误"来捕捉跨分支错误。提出了风险约束阈值和基于径向嵌入的分类感知微调方法。

Result: 结果显示，尽管视觉语言模型在平面性能上表现优异，但与临床分类体系存在显著不一致。提出的方法能将严重抽象错误降低到2%以下，同时保持有竞争力的性能。

Conclusion: 研究强调了分层评估和表示层面对齐对于视觉语言模型更安全、更具临床意义的部署的重要性，提出的方法能有效减少严重错误。

Abstract: Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.

</details>


### [43] [Implementing Knowledge Representation and Reasoning with Object Oriented Design](https://arxiv.org/abs/2601.14840)
*Abdelrhman Bassiouny,Tom Schierenbeck,Sorin Arion,Benjamin Alt,Naren Vasantakumaar,Giang Nguyen,Michael Beetz*

Main category: cs.AI

TL;DR: KRROOD框架通过将知识作为一等编程抽象，使用原生类结构弥合逻辑编程与面向对象编程之间的鸿沟，解决知识表示与推理系统与现代软件工程集成困难的问题。


<details>
  <summary>Details</summary>
Motivation: 现代软件工程以面向对象编程为标准，但现有的知识表示与推理框架通常依赖外部本体和专门语言，难以与命令式代码集成，存在集成鸿沟。

Method: KRROOD框架将知识作为一等编程抽象，使用原生类结构，在逻辑编程和面向对象编程范式之间建立桥梁。

Result: 在OWL2Bench基准测试和人机任务学习场景中的实验结果显示，KRROOD在保持强大性能的同时，支持现实世界自主系统所需的表达性推理。

Conclusion: KRROOD成功弥合了知识表示与推理系统与现代软件工程之间的集成鸿沟，为开发复杂应用程序提供了有效的解决方案。

Abstract: This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.

</details>


### [44] [Just aware enough: Evaluating awareness across artificial systems](https://arxiv.org/abs/2601.14901)
*Nadine Meertens,Suet Lee,Ophelia Deroy*

Main category: cs.AI

TL;DR: 论文提出用"意识"替代"意识"作为评估AI系统的新框架，强调可操作性、领域敏感性、可扩展性和多维度的评估方法


<details>
  <summary>Details</summary>
Motivation: 当前关于AI意识和道德地位的讨论缺乏共识和可操作的评价方法，需要更实用、方法上更易处理的替代方案

Method: 提出评估AI系统意识的实用方法，将意识定义为系统处理、存储和使用信息以实现目标导向行动的能力，强调领域敏感性、可扩展性、多维度和任务性能预测四个要求

Result: 建立了一个结构化框架来评估和比较不同架构、规模和操作领域的AI系统的意识特征，支持原则性评估、设计监督和建设性讨论

Conclusion: 从人工意识转向"足够意识"的评估框架，为AI系统的评估、设计和公共讨论提供了更实用、可操作的方法论基础

Abstract: Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.

</details>


### [45] [Emergent, not Immanent: A Baradian Reading of Explainable AI](https://arxiv.org/abs/2601.15029)
*Fabio Morreale,Joan Serrà,Yuki Mistufuji*

Main category: cs.AI

TL;DR: 论文批判了当前可解释AI（XAI）将解释视为技术问题的立场，基于Barad的能动实在论提出了替代的本体认识论框架，认为解释是AI模型与人类、情境和解释装置纠缠中涌现的物质-话语实践。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI领域存在未经验证的本体认识论假设：将意义视为模型内在属性，解释者被置于系统之外，并假设可通过计算技术恢复因果结构。论文旨在挑战这些假设，为XAI提供更丰富的理论框架。

Method: 采用Barad的能动实在论作为理论基础，通过该理论视角系统分析现有XAI方法，揭示其假设和局限性。然后阐述该框架的伦理维度，并提出支持涌现解释的XAI界面设计方向，以文本到音乐界面作为案例研究。

Result: 提出了基于能动实在论的XAI替代本体认识论框架，认为解释是从AI模型与人类、情境和解释装置的具体纠缠中涌现的物质-话语实践。该框架揭示了现有XAI方法的假设和局限性，并提供了支持涌现解释的界面设计指导。

Conclusion: 可解释AI不应被视为纯粹的技术问题，而应理解为解释实践在具体情境中涌现的过程。基于能动实在论的框架为XAI提供了更丰富的理论视角，强调解释的涌现性、情境性和伦理维度，对XAI研究和设计具有重要启示。

Abstract: Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.

</details>


### [46] [The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks](https://arxiv.org/abs/2601.15130)
*Ivan Carrera,Daniel Maldonado-Ruiz*

Main category: cs.AI

TL;DR: 论文提出了"合理性陷阱"概念，指出人们过度使用大型语言模型处理简单确定性任务，导致资源浪费，并引入工具选择工程框架来指导何时使用生成式AI。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，用户便利性超越了计算效率，导致人们使用昂贵的概率引擎处理简单的确定性任务（如OCR或基本验证），造成显著的资源浪费。

Method: 通过OCR和事实核查的微基准测试和案例研究，量化"效率税"；引入工具选择工程和确定性-概率性决策矩阵框架，帮助开发者决定何时使用生成式AI以及何时避免使用。

Result: 研究发现存在约6.5倍的延迟惩罚（效率税），并揭示了算法奉承的风险。通过决策矩阵框架，可以更明智地选择工具，避免不必要的生成式AI使用。

Conclusion: 真正的数字素养不仅在于知道如何使用生成式AI，更在于知道何时不使用它。需要课程转变，强调工具选择的智慧，避免陷入"合理性陷阱"。

Abstract: The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the "Plausibility Trap": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the "efficiency tax"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.

</details>


### [47] [Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning](https://arxiv.org/abs/2601.15160)
*Yuval Kansal,Niraj K. Jha*

Main category: cs.AI

TL;DR: 提出一种基于知识图谱路径奖励的底层学习范式，通过监督微调和强化学习相结合的后训练流程，让模型在医学领域进行可验证的组合式多跳推理，显著超越GPT-5.2等前沿系统。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和编程等结构化推理领域已达到接近专家水平，但在专业科学领域进行组合式多跳推理的能力仍然有限。需要一种能够基于领域公理事实进行组合推理的方法。

Method: 提出基于监督微调和强化学习的后训练流程，利用知识图谱作为隐式奖励模型。通过从知识图谱路径中推导新颖的奖励信号，提供可验证、可扩展的监督，鼓励模型在强化学习过程中组合中间公理而不仅仅是优化最终答案。

Result: 在医学领域训练14B参数模型，在短跳推理路径（1-3跳）上训练，在复杂多跳查询（4-5跳）上实现零样本泛化。路径衍生奖励作为"组合桥梁"，使模型在最具挑战性的推理任务上显著超越GPT-5.2和Gemini 3 Pro等更大模型和前沿系统。方法对选项洗牌压力测试具有鲁棒性。

Conclusion: 将推理过程建立在结构化知识基础上，是实现智能推理的可扩展且高效的路径。知识图谱路径奖励能够有效促进组合式推理能力的发展。

Abstract: Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a "compositional bridge", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.

</details>


### [48] [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://arxiv.org/abs/2601.15197)
*Shijie Lian,Bin Yu,Xiaopeng Lin,Laurence T. Yang,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Cong Huang,Kai Chen*

Main category: cs.AI

TL;DR: 论文提出BayesianVLA框架解决VLA模型中的信息崩溃问题，通过贝叶斯分解强制模型遵循语言指令，在无需新数据的情况下显著提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作中存在泛化能力不足的问题，特别是在新指令或复杂多任务场景中。研究发现现有训练范式存在数据集偏差问题：目标驱动的数据收集导致语言指令可以从视觉观察中高度预测，造成指令与动作之间的条件互信息消失（信息崩溃），使模型退化为忽略语言约束的纯视觉策略。

Method: 提出BayesianVLA框架，通过贝叶斯分解强制指令跟随。引入可学习的潜在动作查询，构建双分支架构来估计视觉先验p(a|v)和语言条件后验π(a|v,ℓ)。优化策略以最大化动作与指令之间的条件点互信息，有效惩罚视觉捷径，奖励能明确解释语言命令的动作。

Result: 在SimplerEnv和RoboCasa上的大量实验显示显著提升，特别是在具有挑战性的OOD SimplerEnv基准上获得11.3%的改进，验证了该方法在将语言可靠地融入动作中的能力。

Conclusion: BayesianVLA通过解决信息崩溃问题，在不需新数据的情况下显著提升了VLA模型的泛化能力，为机器人操作中的语言-动作对齐提供了有效解决方案。

Abstract: Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \mid v)$ and a language-conditioned posterior $π(a \mid v, \ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [49] [Anomalous Localization and Mobility Edges in Non-Hermitian Quasicrystals with Disordered Imaginary Gauge Fields](https://arxiv.org/abs/2601.14754)
*Guolin Nan,Zhijian Li,Feng Mei,Zhihao Xu*

Main category: cond-mat.dis-nn

TL;DR: 该论文研究了一维非厄米准晶中由空间无序虚规范场引起的反常局域化现象，发现了由非厄米皮肤效应态向局域化态的相变，以及由次近邻跃迁产生的反常迁移率边。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米准晶系统中的反常局域化现象，特别是虚规范场无序如何影响系统的局域化特性，以及如何发展有效的诊断工具来区分不同的局域化相。

Method: 采用广义的Aubry-André-Harper链模型，包含由伯努利虚规范场产生的不对称最近邻和次近邻跃迁，以及准周期在位势。通过分析分形维数、李雅普诺夫指数、质心涨落、谱缠绕数等指标来诊断相变。

Result: 1. 在标准非厄米AAH极限下，系统经历从完全无序的非厄米皮肤效应相到完全局域化相的转变；2. 分形维数无法区分这两个相，而李雅普诺夫指数和质心涨落提供了清晰的诊断；3. 次近邻跃迁产生了反常迁移率边，将安德森局域态与ENHSE态分开；4. 提出了基于波包扩展的动力学探针，揭示了缠绕数控制的漂移和边界包裹递归等现象。

Conclusion: 该研究为非厄米准晶中的反常局域化和迁移率边提供了实用的谱、拓扑和动力学诊断工具，揭示了虚规范场无序在非厄米系统中产生的独特局域化行为。

Abstract: We study anomalous localization in a one-dimensional non-Hermitian quasicrystal with a spatially disordered imaginary gauge field. The system is a generalized Aubry-André-Harper (AAH) chain with asymmetric nearest- and next-nearest-neighbor hoppings generated by a Bernoulli imaginary gauge field and a quasiperiodic onsite potential. In the standard non-Hermitian AAH limit, the system undergoes a transition from a fully erratic non-Hermitian skin effect (ENHSE) phase to a fully localized phase. We show that the fractal dimension cannot distinguish these phases, whereas the Lyapunov exponent and center-of-mass fluctuations provide sharp diagnostics. This transition is accompanied by a complex-to-real spectral change under periodic boundary conditions and a topological change of the spectral winding number. With next-nearest-neighbor hopping, we uncover an anomalous mobility edge separating Anderson-localized states from ENHSE states, rather than extended states. This mobility edge is captured by an energy-dependent winding number that vanishes in the localized regime. Finally, we propose a dynamical probe based on wave-packet expansion: for typical disorder realizations, the dynamics shows winding-controlled drift and disorder-selected pinning or boundary-wrapping recurrence, while disorder averaging restores Hermitian-like transport. These results offer practical spectral, topological, and dynamical diagnostics of anomalous localization and mobility edges in non-Hermitian quasicrystals.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [50] [GCG Attack On A Diffusion LLM](https://arxiv.org/abs/2601.14266)
*Ruben Neyroud,Sam Corley*

Main category: cs.LG

TL;DR: 探索Greedy Coordinate Gradient (GCG)攻击在扩散语言模型LLaDA上的应用，评估多种攻击变体对有害提示的对抗效果


<details>
  <summary>Details</summary>
Motivation: 虽然大多数LLM是自回归的，但基于扩散的LLM最近成为替代生成方法。GCG攻击对自回归模型有效，但其在扩散语言模型上的适用性尚未充分探索

Method: 对开源扩散LLM LLaDA进行GCG风格的对抗提示攻击研究，评估多种攻击变体，包括前缀扰动和后缀对抗生成，使用AdvBench数据集中的有害提示进行评估

Result: 研究提供了关于扩散语言模型鲁棒性和攻击面的初步见解，表明需要为这种设置开发替代的优化和评估策略

Conclusion: 扩散语言模型面临与自回归模型类似的对抗攻击风险，需要针对扩散模型特性开发专门的对抗分析策略

Abstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion language models remains largely unexplored. In this work, we present an exploratory study of GCG-style adversarial prompt attacks on LLaDA (Large Language Diffusion with mAsking), an open-source diffusion LLM. We evaluate multiple attack variants, including prefix perturbations and suffix-based adversarial generation, on harmful prompts drawn from the AdvBench dataset. Our study provides initial insights into the robustness and attack surface of diffusion language models and motivates the development of alternative optimization and evaluation strategies for adversarial analysis in this setting.

</details>


### [51] [Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version](https://arxiv.org/abs/2601.14275)
*Zewen Yang,Xiaobing Dai,Jiajun Cheng,Yulong Huang,Peng Shi*

Main category: cs.LG

TL;DR: 该论文提出了一种分布式高斯过程回归的选择性在线学习框架，通过质量优先而非数量优先的策略，让智能体选择预测误差更小的邻居模型进行合作学习。


<details>
  <summary>Details</summary>
Motivation: 在多智能体分布式学习中，盲目包含所有智能体的机器学习模型进行联合预测是不合理的，需要优先考虑模型质量而非数量。现有分布式高斯过程方法缺乏对合作模型质量的评估和选择机制。

Method: 提出了分布式误差感知高斯过程（EIGP）框架，包含选择函数让智能体评估邻居模型质量并选择预测误差更小的模型。还提出了贪婪算法（gEIGP）加速预测和自适应算法（aEIGP）提高精度，以及快速预测、模型更新、误差量化项迭代和数据删除策略实现实时学习。

Result: 数值模拟表明，该方法在多个基准测试中优于现有的分布式高斯过程方法，展示了其在分布式学习中的有效性。

Conclusion: 该研究证明了在分布式学习中质量优先于数量的重要性，提出的选择性在线学习框架通过智能模型选择和算法增强，显著提升了分布式高斯过程回归的性能。

Abstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all models on agents for joint prediction, highlighting the imperative to prioritize quality over quantity in cooperative learning. Specifically, we present the first selective online learning framework for distributed Gaussian process (GP) regression, namely distributed error-informed GP (EIGP), that enables each agent to assess its neighboring collaborators, using the proposed selection function to choose the higher quality GP models with less prediction errors. Moreover, algorithmic enhancements are embedded within the EIGP, including a greedy algorithm (gEIGP) for accelerating prediction and an adaptive algorithm (aEIGP) for improving prediction accuracy. In addition, approaches for fast prediction and model update are introduced in conjunction with the error-informed quantification term iteration and a data deletion strategy to achieve real-time learning operations. Numerical simulations are performed to demonstrate the effectiveness of the developed methodology, showcasing its superiority over the state-of-the-art distributed GP methods with different benchmarks.

</details>


### [52] [Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct](https://arxiv.org/abs/2601.14277)
*Uygar Kurt*

Main category: cs.LG

TL;DR: 对llama.cpp量化格式的统一实证研究，评估Llama-3.1-8B-Instruct模型在不同比特数K-quant和传统格式下的性能表现，为实际部署提供指导


<details>
  <summary>Details</summary>
Motivation: 量化技术能降低大语言模型的部署门槛，但现有量化格式评估不一致，用户难以选择合适的方案。llama.cpp虽然能让大模型在普通硬件上运行，但缺乏系统性的量化格式比较指南

Method: 对Llama-3.1-8B-Instruct模型进行统一的实证研究，涵盖3-8位K-quant和传统量化格式，评估下游任务性能（推理、知识、指令跟随、真实性）、困惑度、CPU吞吐量、模型大小、压缩率和量化时间

Result: 提供了不同量化格式在各项指标上的详细评估结果，包括性能表现、计算效率和存储效率的权衡，为不同使用场景和资源预算提供数据支持

Conclusion: 本研究为选择llama.cpp量化方案提供了实用的指导，帮助用户根据具体使用场景和资源限制做出明智的、上下文感知的决策

Abstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is especially relevant for users running models locally. Quantization in llama.cpp enables large language models to run on commodity hardware, but available formats are often evaluated inconsistently, making it hard to choose among schemes. We present a unified empirical study of the llama.cpp quantization on a single modern model, Llama-3.1-8B-Instruct (FP16, GGUF), covering 3-8 bit K-quant and legacy formats. We evaluate downstream task performance across standard reasoning, knowledge, instruction-following, and truthfulness benchmarks, and also measure perplexity and CPU throughput (prefill/decoding) alongside model size, compression, and quantization time. Ultimately, this work is a practical guide for choosing a llama.cpp quantization scheme, helping readers make informed, context-aware decisions for their intended use and resource budget.

</details>


### [53] [On the Limits of Learned Importance Scoring for KV Cache Compression](https://arxiv.org/abs/2601.14279)
*Brady Steele*

Main category: cs.LG

TL;DR: 研究通过学习KV缓存压缩，但发现简单的基于位置的启发式方法优于复杂的机器学习模型


<details>
  <summary>Details</summary>
Motivation: 探索通过学习方法来压缩KV缓存，提高推理效率，减少内存占用

Method: 提出SIP（推测重要性预测）方法，使用170万参数的非查询感知评分器，仅从KV表示预测token重要性，包含多视野前瞻和交叉注意力等复杂架构

Result: SIP在5个种子、4个保留级别和3个任务上的表现未能超过简单基线（包括随机选择）。基于位置的启发式方法（保留前4个+最后N个token）表现相当或更好

Conclusion: KV表示中除了位置和预填充注意力之外的信息对于重要性预测的价值有限，未来查询与生成轨迹之间的循环依赖关系增加了学习难度

Abstract: We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.

</details>


### [54] [Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design](https://arxiv.org/abs/2601.14283)
*Kangyu Zheng,Kai Zhang,Jiale Tan,Xuehan Chen,Yingzhou Lu,Zaixi Zhang,Lichao Sun,Marinka Zitnik,Tianfan Fu,Zhiding Liang*

Main category: cs.LG

TL;DR: 本文建立了首个跨算法类别的结构药物设计基准，评估了15种不同算法模型在药物性质、对接亲和力和构象方面的表现，揭示了各类算法的独特优势和局限性。


<details>
  <summary>Details</summary>
Motivation: 当前结构药物设计领域主要分为搜索算法、深度生成模型和强化学习三类，但现有研究通常只比较同一算法类别内的模型，缺乏跨算法类别的系统比较。本文旨在填补这一空白。

Method: 建立了一个基准测试框架，评估15种不同算法基础模型的性能，通过评估生成分子的药物性质、与指定靶蛋白的对接亲和力和构象质量来进行比较分析。

Result: 3D结构模型在结合亲和力方面表现优异，但在化学有效性和构象质量方面存在不一致性；1D模型在标准分子指标上表现可靠，但很少达到最佳结合亲和力；2D模型提供平衡性能，保持高化学有效性的同时获得中等结合分数。

Conclusion: 强调了1D/2D配体中心药物设计方法可以通过将对接函数视为黑盒预言机而用于SBDD，为未来SBDD模型设计提供了建议，并指出结合不同方法优势的重要性。

Abstract: Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of fifteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities and poses with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. Our evaluation reveals distinct patterns across model categories. 3D structure-based models excel in binding affinities but show inconsistencies in chemical validity and pose quality. 1D models demonstrate reliable performance in standard molecular metrics but rarely achieve optimal binding affinities. 2D models offer balanced performance, maintaining high chemical validity while achieving moderate binding scores. Through detailed analysis across multiple protein targets, we identify key improvement areas for each model category, providing insights for researchers to combine strengths of different approaches while addressing their limitations. All the code that are used for benchmarking is available in https://github.com/zkysfls/2025-sbdd-benchmark

</details>


### [55] [A Comparison of Polynomial-Based Tree Clustering Methods](https://arxiv.org/abs/2601.14285)
*Pengyu Liu,Mariel Vázquez,Nataša Jonoska*

Main category: cs.LG

TL;DR: 本文比较了基于树多项式距离的聚类方法性能，发现基于条目级归一化距离的方法在树结构聚类中准确率最高


<details>
  <summary>Details</summary>
Motivation: 生命科学中树结构数据（如RNA二级结构、系统发育树）日益增多，需要新的树结构数据分析方法。树多项式提供了一种计算高效、可解释的树结构编码方式，但需要评估不同距离度量在聚类中的性能

Method: 1. 比较基于树多项式不同距离度量的聚类方法性能；2. 实现两种基本的自编码器模型用于树聚类；3. 使用条目级归一化距离方法进行对比

Result: 基于条目级归一化距离的方法在所有比较方法中具有最高的聚类准确率

Conclusion: 树多项式结合适当的距离度量（特别是条目级归一化距离）为树结构数据分析提供了有效的聚类方法，在生命科学树结构数据分析中具有应用价值

Abstract: Tree structures appear in many fields of the life sciences, including phylogenetics, developmental biology and nucleic acid structures. Trees can be used to represent RNA secondary structures, which directly relate to the function of non-coding RNAs. Recent developments in sequencing technology and artificial intelligence have yielded numerous biological data that can be represented with tree structures. This requires novel methods for tree structure data analytics. Tree polynomials provide a computationally efficient, interpretable and comprehensive way to encode tree structures as matrices, which are compatible with most data analytics tools. Machine learning methods based on the Canberra distance between tree polynomials have been introduced to analyze phylogenies and nucleic acid structures. In this paper, we compare the performance of different distances in tree clustering methods based on a tree distinguishing polynomial. We also implement two basic autoencoder models for clustering trees using the polynomial. We find that the distance based methods with entry-level normalized distances have the highest clustering accuracy among the compared methods.

</details>


### [56] [Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity](https://arxiv.org/abs/2601.14300)
*Jun Liu,Leo Yu Zhang,Fengpeng Li,Isao Echizen,Jiantao Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种新的硬标签黑盒攻击框架，通过频率域初始化和模式驱动优化策略，在仅能观察top-1预测标签的受限设置下，实现了比现有方法更高的攻击成功率和查询效率。


<details>
  <summary>Details</summary>
Motivation: 硬标签黑盒设置（只能观察top-1预测标签）是一个重要但受限的反馈模型。核心挑战是从这种离散响应中恢复有意义的梯度信息。现有攻击方法缺乏统一的理论解释，需要更高效、理论保证的攻击框架。

Method: 1. 提出统一理论视角：将现有符号翻转硬标签攻击解释为隐式近似真实损失梯度的符号；2. 提出新攻击框架：结合零查询频率域初始化和模式驱动优化策略；3. 理论保证：初始化阶段在温和假设下获得比随机基线更高的期望余弦相似度，PDO过程获得比现有结构化搜索方法更低的查询复杂度。

Result: 在CIFAR-10、ImageNet、ObjectNet上验证，涵盖标准模型、对抗训练模型、商业API和CLIP模型。方法在攻击成功率和查询效率上均超越SOTA硬标签攻击，特别是在低查询场景。还能有效泛化到损坏数据、生物医学数据集和密集预测任务，并能成功规避SOTA状态防御Blacklight（检测率为0%）。

Conclusion: 通过统一理论视角将硬标签攻击重新定义为梯度符号恢复问题，提出的新框架在理论和实验上都表现出色，为硬标签黑盒设置下的模型理解提供了更有效的工具，并展示了良好的泛化能力和防御规避能力。

Abstract: Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradient information can be recovered from such discrete responses. In this work, we develop a unified theoretical perspective showing that a wide range of existing sign-flipping hard-label attacks can be interpreted as implicitly approximating the sign of the true loss gradient. This observation reframes hard-label attacks from heuristic search procedures into instances of gradient sign recovery under extremely limited feedback. Motivated by this first-principles understanding, we propose a new attack framework that combines a zero-query frequency-domain initialization with a Pattern-Driven Optimization (PDO) strategy. We establish theoretical guarantees demonstrating that, under mild assumptions, our initialization achieves higher expected cosine similarity to the true gradient sign compared to random baselines, while the proposed PDO procedure attains substantially lower query complexity than existing structured search approaches. We empirically validate our framework through extensive experiments on CIFAR-10, ImageNet, and ObjectNet, covering standard and adversarially trained models, commercial APIs, and CLIP-based models. The results show that our method consistently surpasses SOTA hard-label attacks in both attack success rate and query efficiency, particularly in low-query regimes. Beyond image classification, our approach generalizes effectively to corrupted data, biomedical datasets, and dense prediction tasks. Notably, it also successfully circumvents Blacklight, a SOTA stateful defense, resulting in a $0\%$ detection rate. Our code will be released publicly soon at https://github.com/csjunjun/DPAttack.git.

</details>


### [57] [Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2601.14327)
*YuanLab. ai,Shawn Wu,Jiangang Luo,Tong Yu,Darcy Chen,Sean Wang,Xudong Zhao,Louie Li,Claire Wang,Hunter He,Carol Wang,Allen Wang*

Main category: cs.LG

TL;DR: 提出LAEP算法，在MoE LLMs预训练阶段通过自适应专家剪枝和重组，显著提升训练效率并减少参数量


<details>
  <summary>Details</summary>
Motivation: MoE大语言模型虽然参数效率高，但预训练阶段存在专家利用不足和训练效率低的问题，需要改进

Method: 提出层自适应专家剪枝算法，在预训练阶段根据token分布统计选择性剪枝未充分利用的专家，并在计算设备间重组专家

Result: 在1010B基础模型预训练中，LAEP实现48.3%训练效率提升和33.3%参数减少，同时在多个领域保持优异性能

Conclusion: LAEP算法有效解决了MoE LLMs预训练效率低的问题，为大规模MoE模型训练提供了高效解决方案

Abstract: Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.

</details>


### [58] [Hierarchical Contextual Uplift Bandits for Catalog Personalization](https://arxiv.org/abs/2601.14333)
*Anupam Agrawal,Rajesh Mohanty,Shamik Bhattacharjee,Abhimanyu Mittal*

Main category: cs.LG

TL;DR: 提出分层上下文提升赌博机框架，用于动态环境中的个性化推荐，在梦幻体育平台实现显著收益提升


<details>
  <summary>Details</summary>
Motivation: 传统上下文赌博机算法在动态环境（如梦幻体育）中表现不佳，用户行为快速变化和外部因素导致的奖励分布剧烈变化需要频繁重新训练

Method: 分层上下文提升赌博机框架，动态调整上下文粒度（从系统级到用户级），利用上下文相似性促进策略迁移，并整合提升建模原理

Result: 在Dream11梦幻体育平台的大规模A/B测试中，方法显著提升推荐质量，实现0.4%收益提升并改善用户满意度指标；部署到生产环境后进一步获得0.5%收益提升

Conclusion: 提出的分层上下文提升赌博机框架有效解决了动态环境中的个性化推荐挑战，已在生产环境成功部署并带来持续收益提升

Abstract: Contextual Bandit (CB) algorithms are widely adopted for personalized recommendations but often struggle in dynamic environments typical of fantasy sports, where rapid changes in user behavior and dramatic shifts in reward distributions due to external influences necessitate frequent retraining. To address these challenges, we propose a Hierarchical Contextual Uplift Bandit framework. Our framework dynamically adjusts contextual granularity from broad, system-wide insights to detailed, user-specific contexts, using contextual similarity to facilitate effective policy transfer and mitigate cold-start issues. Additionally, we integrate uplift modeling principles into our approach. Results from large-scale A/B testing on the Dream11 fantasy sports platform show that our method significantly enhances recommendation quality, achieving a 0.4% revenue improvement while also improving user satisfaction metrics compared to the current production system. We subsequently deployed this system to production as the default catalog personalization system in May 2025 and observed a further 0.5% revenue improvement.

</details>


### [59] [VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models](https://arxiv.org/abs/2601.14354)
*Yongchao Huang*

Main category: cs.LG

TL;DR: VJEPA提出了一种概率化的联合嵌入预测架构，通过变分目标学习未来潜在状态的预测分布，统一了表示学习与预测状态表示，为高维噪声环境中的可扩展、鲁棒的规划提供了基础框架。


<details>
  <summary>Details</summary>
Motivation: 现有JEPA方法使用确定性回归目标，掩盖了概率语义，限制了其在随机控制中的应用。需要一种概率化扩展来支持不确定性估计和鲁棒规划。

Method: 提出变分JEPA（VJEPA），通过变分目标学习未来潜在状态的预测分布；进一步提出贝叶斯JEPA（BJEPA），将预测信念分解为学习到的动态专家和模块化先验专家，通过专家乘积实现零样本任务迁移和约束满足。

Result: VJEPA统一了表示学习与预测状态表示和贝叶斯滤波，理论上证明其表示可作为最优控制的充分信息状态；实验表明VJEPA和BJEPA能成功过滤高方差干扰，避免生成基线中的表示崩溃。

Conclusion: VJEPA为高维噪声环境中的可扩展、鲁棒、不确定性感知规划提供了基础框架，支持原则性不确定性估计，同时保持对观测的似然无关性。

Abstract: Joint Embedding Predictive Architectures (JEPA) offer a scalable paradigm for self-supervised learning by predicting latent representations rather than reconstructing high-entropy observations. However, existing formulations rely on \textit{deterministic} regression objectives, which mask probabilistic semantics and limit its applicability in stochastic control. In this work, we introduce \emph{Variational JEPA (VJEPA)}, a \textit{probabilistic} generalization that learns a predictive distribution over future latent states via a variational objective. We show that VJEPA unifies representation learning with Predictive State Representations (PSRs) and Bayesian filtering, establishing that sequential modeling does not require autoregressive observation likelihoods. Theoretically, we prove that VJEPA representations can serve as sufficient information states for optimal control without pixel reconstruction, while providing formal guarantees for collapse avoidance. We further propose \emph{Bayesian JEPA (BJEPA)}, an extension that factorizes the predictive belief into a learned dynamics expert and a modular prior expert, enabling zero-shot task transfer and constraint (e.g. goal, physics) satisfaction via a Product of Experts. Empirically, through a noisy environment experiment, we demonstrate that VJEPA and BJEPA successfully filter out high-variance nuisance distractors that cause representation collapse in generative baselines. By enabling principled uncertainty estimation (e.g. constructing credible intervals via sampling) while remaining likelihood-free regarding observations, VJEPA provides a foundational framework for scalable, robust, uncertainty-aware planning in high-dimensional, noisy environments.

</details>


### [60] [Adaptive KDE for Real-Time Thresholding: Prioritized Queues for Financial Crime Investigation](https://arxiv.org/abs/2601.14473)
*Danny Butvinik,Nana Boateng,Achi Hackmon*

Main category: cs.LG

TL;DR: 提出一种将风险评分流转换为审查队列的方法，使用自适应核密度估计和尾质量曲线来满足容量约束，无需标签且支持实时多队列路由


<details>
  <summary>Details</summary>
Motivation: 传统方法使用top-K或手动调整阈值来将风险评分流转换为审查队列，但这些方法在明确的摄入约束下不够灵活，需要更自适应的解决方案

Method: 对评分流拟合在线自适应核密度估计，将密度转换为尾质量曲线以满足容量要求，然后将结果阈值"捕捉"到跨带宽检测到的持久密度谷值

Result: 在合成、漂移、多模态流上，该方法实现了竞争性的容量遵守度，同时减少了阈值抖动，更新成本为O(G)每个事件，每个活动使用恒定内存

Conclusion: 该方法提供了一种无标签、支持多队列路由、实时操作的风险评分流转换方案，比传统方法更适应动态环境

Abstract: We study the problem of converting a stream of risk scores into one or more review queues under explicit intake constraints[cite: 6]. Instead of top-$K$ or manually tuned cutoffs, we fit an online adaptive kernel density to the score stream, transform the density into a tail-mass curve to meet capacity, and ``snap'' the resulting cut to a persistent density valley detected across bandwidths[cite: 7]. The procedure is label-free, supports multi-queue routing, and operates in real time with sliding windows or exponential forgetting[cite: 8]. On synthetic, drifting, multimodal streams, the method achieves competitive capacity adherence while reducing threshold jitter[cite: 9]. Updates cost $O(G)$ per event with constant memory per activity

</details>


### [61] [GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling](https://arxiv.org/abs/2601.14476)
*Naoya Onizawa,Takahiro Hanyu*

Main category: cs.LG

TL;DR: 基于概率比特的GPU加速模拟退火框架，发现器件变异性可提升算法性能而非仅劣化


<details>
  <summary>Details</summary>
Motivation: 使用磁隧道结等新兴器件实现概率比特时存在器件变异性，传统观点认为这会降低计算性能，但本研究旨在探索变异性对算法性能的实际影响

Method: 开发基于CUDA的GPU加速开源模拟退火框架，建模时序、强度和偏移三种关键器件变异性因素，在MAX-CUT基准测试上验证性能

Result: 发现器件变异性（特别是时序变异性）不仅能劣化还能增强算法性能；GPU实现相比CPU获得两个数量级加速，支持800-20,000节点规模问题

Conclusion: 该框架为概率计算研究提供了可扩展且易用的工具，有助于推动优化算法在多个领域的应用，并重新评估器件变异性在计算中的作用

Abstract: Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -timing, intensity, and offset- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.

</details>


### [62] [Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence](https://arxiv.org/abs/2601.14487)
*Mrigank Dhingra,Omer San*

Main category: cs.LG

TL;DR: MSR-HINE：一种用于混沌动力系统长期预测的分层隐式预测器，通过多尺度潜在先验和多速率循环模块减少误差累积，显著提升了预测精度和可预测性范围。


<details>
  <summary>Details</summary>
Motivation: 混沌动力系统的长期自回归预测面临挑战，因为微小的单步误差会迅速放大，导致物理不一致的展开和大尺度统计特性崩溃。现有方法难以同时保持长期上下文和快速尺度变异性。

Method: MSR-HINE采用分层隐式预测器架构，结合多尺度潜在先验和多速率循环模块。通过粗到细的循环状态生成潜在先验，隐式单步预测器用多尺度潜在注入细化状态，门控融合与后验潜在确保尺度一致性更新，轻量级隐藏状态校正进一步对齐循环记忆与融合潜在。

Result: 在两个基准测试中表现优异：在Kuramoto-Sivashinsky系统上，将端到端RMSE降低62.8%（H=400），ACC从-0.155提升到0.828，可预测性范围从241步扩展到400步；在Lorenz-96系统上，RMSE降低27.0%（H=100），ACC从0.144提升到0.545，可预测性范围从58步扩展到100步。

Conclusion: MSR-HINE通过分层多尺度架构有效缓解了混沌系统中的误差累积问题，在保持长期上下文的同时保留了快速尺度变异性，显著提升了长期预测的准确性和稳定性。

Abstract: Long-horizon autoregressive forecasting of chaotic dynamical systems remains challenging due to rapid error amplification and distribution shift: small one-step inaccuracies compound into physically inconsistent rollouts and collapse of large-scale statistics. We introduce MSR-HINE, a hierarchical implicit forecaster that augments multiscale latent priors with multi-rate recurrent modules operating at distinct temporal scales. At each step, coarse-to-fine recurrent states generate latent priors, an implicit one-step predictor refines the state with multiscale latent injections, and a gated fusion with posterior latents enforces scale-consistent updates; a lightweight hidden-state correction further aligns recurrent memories with fused latents. The resulting architecture maintains long-term context on slow manifolds while preserving fast-scale variability, mitigating error accumulation in chaotic rollouts. Across two canonical benchmarks, MSR-HINE yields substantial gains over a U-Net autoregressive baseline: on Kuramoto-Sivashinsky it reduces end-horizon RMSE by 62.8% at H=400 and improves end-horizon ACC by +0.983 (from -0.155 to 0.828), extending the ACC >= 0.5 predictability horizon from 241 to 400 steps; on Lorenz-96 it reduces RMSE by 27.0% at H=100 and improves end horizon ACC by +0.402 (from 0.144 to 0.545), extending the ACC >= 0.5 horizon from 58 to 100 steps.

</details>


### [63] [On the Runway Cascade of Transformers for Language Modeling](https://arxiv.org/abs/2601.14522)
*Hunjae Lee,Corey Clark*

Main category: cs.LG

TL;DR: 本文提出"跑道感知重连"机制，通过显式地将间接路径（跑道）上下文纳入直接路径注意力，解决因果变换器中信息传播模式不匹配的问题，无需额外参数即可提升语言建模、信息检索和外推能力。


<details>
  <summary>Details</summary>
Motivation: 因果变换器中存在直接路径注意力和通过中间令牌形成的间接路径（跑道）两种信息传播模式。研究发现这两种模式的不匹配可能导致冗余和无关信息在令牌表示中传播，即使注意力模式学习得当。这种"跑道级联"现象是许多因果变换器失败模式的根源。

Method: 提出跑道感知重连机制：基于每个令牌的跑道景观摘要重新连接其注意力模式。该方法将跑道上下文直接纳入每个令牌的直接路径注意力中，使模型能够感知累积的表征影响，实现更平衡的信息传播。该方法无需额外参数，可无缝集成到标准注意力机制中。

Result: 经验验证表明，重连后的变换器在通用语言建模方面取得稳定改进，同时在信息检索和外推能力方面相比标准变换器表现出明显更强的性能。

Conclusion: 跑道感知重连机制通过显式处理直接路径和间接路径之间的信息传播不匹配问题，有效缓解了跑道级联现象，提升了因果变换器的整体性能，特别是在信息检索和外推任务上表现突出。

Abstract: In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.

</details>


### [64] [Search over Self-Edit Strategies for LLM Adaptation](https://arxiv.org/abs/2601.14532)
*Alistair Cheong,Haolin Cong,Tyler Yang,Dustin Miao*

Main category: cs.LG

TL;DR: LLM能否利用任务反馈自主决定权重更新策略？研究在SEAL框架中允许模型生成自编辑模板，探索了有无历史模板存档的两种变体，发现存档变体表现接近但未超越最优人工策略。


<details>
  <summary>Details</summary>
Motivation: 现有LLM搜索系统通常冻结基础模型，这可能限制长期进步。虽然已有研究探索在测试时更新提案模型，但更新策略仍需人工指定。因此本研究探讨LLM能否利用任务反馈自主决定权重更新方式。

Method: 基于SEAL框架，放宽固定人工模板限制，允许模型生成自编辑模板，从而让模型在训练数据和超参数选择上有更多控制权。研究两种变体：无存档变体和基于轻量级历史模板存档的变体。在Qwen3-8B模型和SQuAD数据集上进行实验。

Result: 无存档变体表现与较弱的"Implications"基线相当，存档变体优于"Implications"基线并接近最强人工设计的"Rewrite"基线，但未超越。分析发现朴素存档虽能提供短期鲁棒性，但可能加速同质化。

Conclusion: LLM能够利用任务反馈自主决定权重更新策略，但需要显式的新颖性压力才能持续超越精心优化的人工策略。朴素存档可能加速同质化，需要更智能的探索机制。

Abstract: Many LLM-based open-ended search systems freeze the foundation model that proposes improvements to existing solutions, which may bottleneck long-run progress. Recent work has explored updating the proposal model at test time [arXiv:2511.23473], but the update strategy is still typically hand-specified. Therefore, this study investigated whether an LLM can use task feedback to decide how it should update its weights. For tractability, we focused on the simpler case where there is only one round of self-improvement, and restricted the update operator to self-supervised next token prediction (NTP), leaving the model freedom in choosing its training data and key NTP hyperparameters. Using the Self-Adapting Language Models (SEAL) [arXiv:2506.10943] framework as a testbed, we relaxed its fixed human template constraint and allowed the model to generate its own self-edit templates, thereby giving it more control over its training data and hyperparameters. Two variants were studied, differing in whether template generation was conditioned on a lightweight archive of past templates. In SEAL's Single-Passage Knowledge Incorporation setting with Qwen3-8B on SQuAD [arXiv:1606.05250], the no-archive variant performed comparably to the weaker "Implications" baseline, while the archive variant outperformed "Implications" and approached the strongest human-designed "Rewrite" baseline without surpassing it. Further analysis of collapse in the model's exploration revealed that a naive archive can confer some short-term robustness but can also accelerate homogenization, suggesting that explicit novelty pressure may be required to consistently advance beyond carefully optimized human strategies. Our code is available at https://github.com/cheongalc/search-self-edit-strategies .

</details>


### [65] [QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design](https://arxiv.org/abs/2601.14549)
*Nilesh Prasad Pandey,Jangseon Park,Onat Gungor,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: QMC提出了一种无需重新训练的量化方法，结合异构内存架构，将SLM中的内点权重存储在ReRAM中，关键外点存储在MRAM中，显著提升了边缘设备上语言模型推理的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在边缘平台上部署小型语言模型面临内存、延迟和能耗限制。量化可以减少模型大小和成本，但受到新兴非易失性存储器中设备噪声的影响，传统内存层次结构进一步限制了效率。SRAM访问快但密度低，DRAM需要同时容纳静态权重和动态KV缓存导致带宽争用，Flash虽然密度高但主要在初始化时使用，推理期间保持不活跃。这些限制凸显了需要为LLM推理量身定制的混合内存组织。

Method: 提出了Outlier-aware Quantization with Memory Co-design (QMC)，这是一种无需重新训练的量化方法，结合新颖的异构内存架构。QMC识别SLM中的内点和外点权重，将内点权重存储在紧凑的多级ReRAM中，同时将关键外点保存在高精度的片上MRAM中，从而减轻噪声引起的性能下降。

Result: 在语言建模和推理基准测试中，QMC优于或匹配使用先进算法和混合数据格式的最先进量化方法，同时在算法单独评估和实际部署设置下都实现了更大的压缩。与最新的边缘AI平台上的SoTA量化方法相比，QMC将内存使用减少了6.3x-7.3x，外部数据传输减少了7.6x，能耗减少了11.7x，延迟减少了12.5x（与FP16相比）。

Conclusion: QMC被确立为一种可扩展、可部署的协同设计，用于高效的设备上推理，通过量化与内存架构的协同设计，有效解决了边缘设备上SLM部署的挑战。

Abstract: Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference.

</details>


### [66] [Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation](https://arxiv.org/abs/2601.14590)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: 本文评估了使用大语言模型（GPT-4、BioMistral-7B、LLaMA-3.1-8B）生成反事实解释的方法，在临床数据集上验证了其在干预质量和数据增强方面的有效性，相比传统优化方法能产生更临床可行、语义连贯的反事实。


<details>
  <summary>Details</summary>
Motivation: 反事实解释通过识别最小、可操作的改变来改变机器学习模型的预测，可用于异常预防干预和训练鲁棒模型的数据增强。然而，传统优化方法生成的CFs在临床可行性和语义连贯性方面存在局限，需要探索LLMs在生成高质量反事实方面的潜力。

Method: 使用多模态AI-READI临床数据集，评估了GPT-4（零样本和少样本）以及两个开源模型BioMistral-7B和LLaMA-3.1-8B（包括预训练和微调配置）生成反事实解释的能力。从干预质量、特征多样性和增强效果三个维度进行评估，并与DiCE、CFNOW、NICE等优化基线方法进行比较。

Result: 微调后的LLMs，特别是LLaMA-3.1-8B，能生成高可信度（高达99%）、强有效性（高达0.99）且具有现实、行为可修改特征调整的反事实。在标签稀缺设置下用于数据增强时，LLM生成的CFs显著恢复分类器性能，在三种稀缺场景中平均实现20%的F1恢复。相比优化基线方法，LLMs提供了更灵活、模型无关的方法，能生成更临床可行、语义连贯的反事实。

Conclusion: 这项工作展示了LLM驱动的反事实在传感器数字健康领域中，对于可解释干预设计和数据高效模型训练的前景。SenseCF通过微调LLM生成有效的、有代表性的反事实解释，并补充不平衡数据集中的少数类，从而改善模型训练、提升模型鲁棒性和预测性能。

Abstract: Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health.
  Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance

</details>


### [67] [Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective](https://arxiv.org/abs/2601.14599)
*Xiao Hu,Hong Xie,Tao Tan,Defu Lian,Jianyu Han*

Main category: cs.LG

TL;DR: 该论文通过自下而上的实验流程，系统分析了强化学习微调LLM中各种优化选择的作用和瓶颈，揭示了设计选择的新理解


<details>
  <summary>Details</summary>
Motivation: 当前LLM强化学习微调领域存在大量启发式方法但缺乏系统理解，存在两个基本问题：1) 每个优化选择的作用是什么？2) 哪些是瓶颈？需要澄清这些混淆因素

Method: 提出自下而上的实验流程：底层采用极简配置（单一训练数据、每轮一次rollout、直接使用奖励作为学习信号），然后逐层扩展配置，系统检验每个设计选择的作用

Result: 在三个LLM和两个推理数据集上的实验不仅揭示了设计选择的新理解，还为该领域提供了重要见解，极简配置连接了具有极大离散动作空间的多臂赌博机学习

Conclusion: 通过系统实验分析，澄清了LLM强化学习微调中各种优化选择的作用和瓶颈，为该领域提供了理论基础和实践指导

Abstract: A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.

</details>


### [68] [Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum](https://arxiv.org/abs/2601.14603)
*Jingru Li,Yibo Fan,Huan Li*

Main category: cs.LG

TL;DR: Muon优化器通过正交动量更新加速LLM预训练，提出Muon-NSR和Muon-VS变体，在GPT-2和LLaMA预训练中比AdamW和Muon基准收敛更快，验证损失更低


<details>
  <summary>Details</summary>
Motivation: 大型语言模型预训练计算成本高昂，优化器效率成为重要实践考虑因素。现有Adam优化器可视为方差自适应符号更新算法，但仍有改进空间

Method: 提出Muon优化器，采用正交动量更新作为矩阵级元素符号算子。提出两个变体：Muon-NSR应用信噪比调制，Muon-VS执行基于方差的缩放而不引入额外超参数

Result: 在GPT-2和LLaMA预训练实验中，Muon-NSR和Muon-VS加速收敛，持续获得比AdamW和Muon基准更低的验证损失。在LLaMA-1.2B模型上，达到目标验证损失所需的迭代次数减少1.36倍

Conclusion: Muon优化器及其变体通过正交动量更新和方差自适应归一化，有效加速大型语言模型预训练，提高优化器效率

Abstract: Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\times$ relative to the well-tuned Muon following the recent benchmark.

</details>


### [69] [Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport](https://arxiv.org/abs/2601.14653)
*Yuyu Liu,Jiannan Yang,Ziyang Yu,Weishen Pan,Fei Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: CROT是一种基于最优传输的插补算法，专门处理表格数据中的大块缺失数据，在保持高精度的同时显著减少运行时间。


<details>
  <summary>Details</summary>
Motivation: 单细胞测序数据中的缺失数据对提取生物学见解构成重大挑战，现有插补方法假设数据均匀完整，难以处理大块缺失数据的情况。

Method: 提出CROT算法，基于最优传输理论设计，专门处理表格格式的基于块的缺失数据，能够有效捕捉存在大量缺失情况下的底层数据结构。

Result: CROT实现了优越的插补精度，同时显著减少了运行时间，展示了其在大规模数据集上的可扩展性和效率。

Conclusion: 该工作为具有结构化数据缺失的异质高维数据集提供了一个稳健的插补解决方案，解决了生物和临床数据分析中的关键挑战。

Abstract: Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github.

</details>


### [70] [Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning](https://arxiv.org/abs/2601.14687)
*Zhihao Chen,Zirui Gong,Jianting Ning,Yanjun Zhang,Leo Yu Zhang*

Main category: cs.LG

TL;DR: FRL通过离散排名更新增强联邦学习抗攻击能力，但本文提出首个针对排名式联邦学习的细粒度控制攻击ECA，能精确控制目标模型精度而不被检测。


<details>
  <summary>Details</summary>
Motivation: 虽然联邦排名学习(FRL)因其离散排名机制被认为对模型投毒攻击具有鲁棒性，但本文发现FRL仍然存在安全漏洞，需要研究针对排名式联邦学习框架的新型攻击方法。

Method: 提出边缘控制攻击(ECA)，包含两个阶段：1)识别并操纵上升和下降边缘使全局模型与目标模型对齐；2)扩大选择边界差距以稳定全局模型在目标精度水平。

Result: 在7个基准数据集和9种拜占庭鲁棒聚合规则上的实验表明，ECA实现细粒度精度控制，平均误差仅0.224%，比基线方法提升高达17倍。

Conclusion: 尽管FRL减少了攻击面，但仍易受ECA等细粒度控制攻击，这凸显了需要针对高级投毒攻击开发更强防御机制的重要性。

Abstract: Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA

</details>


### [71] [CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation](https://arxiv.org/abs/2601.14695)
*Yutong Chen,Jiandong Gao,Ji Wu*

Main category: cs.LG

TL;DR: CoScale-RL是一种新的扩展策略，通过扩展解决方案和计算rollout来提升大型推理模型的训练稳定性和效率，无需大量监督微调数据。


<details>
  <summary>Details</summary>
Motivation: 训练大型推理模型通常不稳定且难以预测，尤其是在处理困难问题或基础模型较弱的情况下。现有的后训练扩展策略在这些情况下仍有改进空间。

Method: 提出CoScale-RL方法：1）扩展解决方案：为每个问题收集多个解决方案，而不是简单扩大数据集；2）扩展rollout计算：稳定强化学习训练；3）使用Re-distillation模型合并技术，在扩展时保持或提升计算效率。

Result: 在四个基准测试上平均获得3.76倍的准确率提升，显著提高了数据和计算效率。CoScale-RL能够在不依赖大量监督微调数据集的情况下提升大型推理模型的能力边界。

Conclusion: 该方法为提升大型推理模型的推理能力提供了新的扩展方向，通过更好的数据和计算效率解决了训练不稳定问题。

Abstract: Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.

</details>


### [72] [Case-Guided Sequential Assay Planning in Drug Discovery](https://arxiv.org/abs/2601.14710)
*Tianchi Chen,Jan Bima,Sean L. Wu,Otto Ritter,Bingjia Yang,Xiang Yu*

Main category: cs.LG

TL;DR: 提出IBMDP框架，用于药物发现中无模拟器的实验序列优化，通过隐式贝叶斯模型和历史数据相似性构建转移动态，减少92%资源消耗


<details>
  <summary>Details</summary>
Motivation: 药物发现中的实验序列规划面临严重不确定性和资源约束，标准强化学习缺乏环境模拟器或转移数据，只能依赖静态历史数据库

Method: 引入隐式贝叶斯马尔可夫决策过程(IBMDP)，通过历史相似结果构建非参数信念分布，实现贝叶斯信念更新，采用集成MCTS规划平衡信息增益和资源效率

Result: 在真实CNS药物发现任务中，相比现有启发式方法减少92%资源消耗；在合成环境中与可计算最优策略对齐度显著高于确定性值迭代方法

Conclusion: IBMDP为数据丰富但模拟器稀缺领域的顺序实验设计提供了实用解决方案，集成规划器优于确定性方法

Abstract: Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.

</details>


### [73] [PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning](https://arxiv.org/abs/2601.14716)
*Yao Lu,Dengdong Fan,Jianzheng Nie,Fan Xu,Jie Chen,Bin Zhou,Yonghong Tian*

Main category: cs.LG

TL;DR: PCL-Reasoner-V1.5是一个基于Qwen2.5-32B构建的320亿参数大语言模型，专门用于数学推理。该模型通过监督微调和强化学习进行优化，采用创新的离线RL方法，在AIME数学竞赛数据集上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 开发一个专门用于数学推理的高性能大语言模型，探索离线强化学习作为比标准在线RL方法（如GRPO）更稳定高效的训练范式，以提升LLM在复杂数学问题上的推理能力。

Method: 基于Qwen2.5-32B构建320亿参数模型，采用两阶段训练：先进行监督微调（SFT），然后使用创新的离线强化学习方法进行优化。离线RL方法相比标准的在线RL方法（如GRPO）提供了更好的训练稳定性和效率。

Result: 在基于Qwen2.5-32B后训练的模型中取得了最先进的性能：在AIME 2024数据集上平均准确率达到90.9%，在AIME 2025数据集上达到85.6%。所有实验均在华为昇腾910C NPU上进行。

Conclusion: 离线强化学习是一种稳定高效的训练范式，能够显著提升大语言模型在数学推理任务上的性能。PCL-Reasoner-V1.5展示了离线RL在推进LLM推理能力方面的有效性。

Abstract: We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.

</details>


### [74] [Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models](https://arxiv.org/abs/2601.14758)
*Injin Kong,Hyoungjoon Lee,Yohan Jo*

Main category: cs.LG

TL;DR: 该研究通过电路分析比较自回归模型(ARMs)及其掩码扩散模型(MDMs)对应版本，发现扩散后训练并非简单参数调整，而是引发内部计算机制的根本性重组，支持非顺序全局规划。


<details>
  <summary>Details</summary>
Motivation: 探索将自回归模型后训练为掩码扩散模型时，模型内部算法转换的本质：这种范式转换是否让MDMs获得了真正的双向推理能力，还是仅仅重新包装了自回归启发式方法。

Method: 对ARMs及其MDM对应模型进行对比电路分析，研究任务结构性质对机制转换的影响。

Result: 发现系统性的"机制转换"：对于局部因果依赖主导的任务，MDMs基本保留自回归电路；对于全局规划任务，MDMs放弃初始化路径，表现出明显的重新布线特征，早期层处理增加。语义上，从ARMs的尖锐局部专业化转变为MDMs的分布式集成。

Conclusion: 扩散后训练不仅调整模型参数，而且从根本上重组内部计算以支持非顺序全局规划。

Abstract: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic "mechanism shift" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.

</details>


### [75] [Anytime Optimal Decision Tree Learning with Continuous Features](https://arxiv.org/abs/2601.14765)
*Harold Kiossou,Pierre Schaus,Siegfried Nijssen*

Main category: cs.LG

TL;DR: 提出一种基于有限差异搜索的随时完整算法，用于学习连续特征的最优决策树，改善现有深度优先搜索方法的随时性能


<details>
  <summary>Details</summary>
Motivation: 现有连续特征最优决策树学习算法采用深度优先搜索策略，虽然能找到最优解但计算时间随深度急剧增加，且中断时找到的树通常高度不平衡且次优，导致随时性能差

Method: 提出基于有限差异搜索的随时完整方法，将计算努力更均匀地分布在整个树结构中，确保在任何中断点都能获得高质量的决策树

Result: 实验结果表明，该方法在随时性能方面优于现有方法

Conclusion: 有限差异搜索策略能够有效改善连续特征最优决策树学习算法的随时性能，提供更均衡的搜索过程

Abstract: In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.

</details>


### [76] [Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation](https://arxiv.org/abs/2601.14798)
*Ondřej Holub,Essi Ryymin,Rodrigo Alves*

Main category: cs.LG

TL;DR: 本文提出了一种基于大语言模型的反思问题自动生成框架，通过两个角色专门化的智能体进行苏格拉底式多轮对话，迭代优化反思问题。


<details>
  <summary>Details</summary>
Motivation: 设计高质量的反思问题对教学很重要，但这对教师来说耗时且支持不均。需要一种自动化的方法来生成有效的反思问题，减轻教师负担并提高教学质量。

Method: 采用"反思中的反思"框架，协调两个角色专门化的智能体：学生-教师和教师-教育者。学生-教师提出候选问题并给出简要理由，教师-教育者从清晰度、深度、相关性、参与度和概念互联性五个维度评估问题，通过针对性指导问题或停止信号进行反馈。使用GPT-4o-mini作为骨干模型，GPT-4级LLM作为外部评估器进行成对比较。

Result: 1. 动态停止机制结合上下文信息（学生水平和教学材料）始终优于固定的5步或10步优化，过长的对话容易导致偏离或过度复杂化。
2. 双智能体协议生成的问题在相关性、深度和整体质量上显著优于使用相同骨干模型的单次生成基线。

Conclusion: 该反思问题自动生成框架通过多智能体对话机制有效提升了反思问题的质量，为教师提供了实用的教学支持工具，同时揭示了对话长度控制和上下文信息的重要性。

Abstract: Designing good reflection questions is pedagogically important but time-consuming and unevenly supported across teachers. This paper introduces a reflection-in-reflection framework for automated generation of reflection questions with large language models (LLMs). Our approach coordinates two role-specialized agents, a Student-Teacher and a Teacher-Educator, that engage in a Socratic multi-turn dialogue to iteratively refine a single question given a teacher-specified topic, key concepts, student level, and optional instructional materials. The Student-Teacher proposes candidate questions with brief rationales, while the Teacher-Educator evaluates them along clarity, depth, relevance, engagement, and conceptual interconnections, responding only with targeted coaching questions or a fixed signal to stop the dialogue. We evaluate the framework in an authentic lower-secondary ICT setting on the topic, using GPT-4o-mini as the backbone model and a stronger GPT- 4-class LLM as an external evaluator in pairwise comparisons of clarity, relevance, depth, and overall quality. First, we study how interaction design and context (dynamic vs.fixed iteration counts; presence or absence of student level and materials) affect question quality. Dynamic stopping combined with contextual information consistently outperforms fixed 5- or 10-step refinement, with very long dialogues prone to drift or over-complication. Second, we show that our two-agent protocol produces questions that are judged substantially more relevant and deeper, and better overall, than a one-shot baseline using the same backbone model.

</details>


### [77] [Statistical Learning Theory for Distributional Classification](https://arxiv.org/abs/2601.14818)
*Christian Fiedler*

Main category: cs.LG

TL;DR: 该论文研究监督学习中分布输入的核方法，特别关注两阶段采样设置下的SVM分类，建立了新的理论分析框架和收敛速率。


<details>
  <summary>Details</summary>
Motivation: 在医疗筛查或因果学习等应用中，输入是概率分布而非可直接访问的数据，只能通过采样获得。现有基于核均值嵌入的核方法缺乏充分的理论分析，需要建立更完善的理论框架。

Method: 采用核均值嵌入将分布或样本映射到希尔伯特空间，然后应用标准核方法如SVM。建立了新的oracle不等式，推导了收敛性和学习速率结果，特别针对高斯核和铰链损失提出了新的噪声假设。

Result: 建立了分布输入SVM分类的理论分析框架，获得了oracle不等式、一致性和学习速率结果。针对高斯核和铰链损失提出了新的噪声假设，并证明了在该假设下的学习速率。

Conclusion: 该工作为分布输入的核方法提供了新的理论分析工具，特别是针对SVM分类建立了理论保证。提出的高斯核在希尔伯特空间的新特征空间构造具有独立的理论价值。

Abstract: In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.

</details>


### [78] [From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps](https://arxiv.org/abs/2601.14848)
*Mohamed Abouras,Catherine M. Elias*

Main category: cs.LG

TL;DR: 研究使用多层LSTM架构预测高速公路匝道区域车辆行为，相比直线路段，匝道区域存在更高不确定性，模型在4秒预测范围内表现出良好性能。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道区域是研究不足的路段，这些区域引入了更高水平的交通交互变化。预测车辆在这些区域的行为可以减少不确定性影响并提高道路安全性。

Method: 使用多层LSTM架构训练匝道区域模型，利用ExiD无人机数据集，测试不同的预测时间范围和模型工作流程，比较匝道区域与直线高速公路路段的差异。

Result: 结果显示在4秒预测范围内表现良好，匝道区域最大预测准确率约76%，一般高速公路场景最大预测准确率达94%。

Conclusion: 匝道区域相比直线路段存在显著差异，多层LSTM架构在预测车辆行为方面表现出潜力，特别是在4秒预测范围内，这有助于提高匝道区域的道路安全性。

Abstract: On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.

</details>


### [79] [Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference](https://arxiv.org/abs/2601.14855)
*Baojun Che,Yifan Chen,Daniel Zhengyu Huang,Xinying Mao,Weijie Wang*

Main category: cs.LG

TL;DR: 提出了一种稳定高效的Black-box变分推断框架，结合仿射不变预处理、指数积分器和自适应时间步长，用于高斯混合族近似复杂后验分布。


<details>
  <summary>Details</summary>
Motivation: 标准数值优化方法在Black-box变分推断中经常面临不稳定和效率低下的问题，特别是使用高斯混合族近似复杂后验分布时。

Method: 结合三个关键组件：1) 通过自然梯度公式的仿射不变预处理；2) 无条件保持协方差矩阵正定性的指数积分器；3) 确保稳定性并适应不同阶段的自适应时间步长。

Result: 对于高斯后验，证明了在无噪声设置下的指数收敛性和蒙特卡洛估计下的几乎必然收敛性。数值实验在多模态分布、Neal的多尺度漏斗和基于PDE的贝叶斯反问题中展示了方法的有效性。

Conclusion: 提出的框架为Black-box变分推断提供了一个稳定高效的优化方法，具有流形优化和镜像下降的自然联系，能够有效处理复杂后验分布近似问题。

Abstract: Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.

</details>


### [80] [Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting](https://arxiv.org/abs/2601.14862)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Derya Umut Kulali*

Main category: cs.LG

TL;DR: sdLM是一个用于多文档战略推理的学习系统框架，通过整合多文档注意力、时间编码和教义一致性层，提升长期预测和计划合理性，同时减少严重教义违规


<details>
  <summary>Details</summary>
Motivation: 需要开发能够在多文档环境下进行战略推理的系统，同时确保教义一致性约束和校准的不确定性，以改进长期预测和计划制定

Method: 结合多文档注意力机制、时间编码和教义一致性层，构建战略教义语言模型框架，用于处理多文档战略推理任务

Result: 在三个基准测试中表现优异：(1)专家小组对战略场景评分(N=47)；(2)336份教义出版物(12,847条声明)的教义一致性；(3)127个历史反事实(1945-2020)的地缘政治预测。sdLM在战略质量和校准方面优于通用LLM基线，在长期判断上与人类专家竞争力相当

Conclusion: sdLM框架通过整合多文档注意力、时间编码和教义一致性约束，显著提升了战略推理的质量和可靠性，为多文档战略分析和长期预测提供了有效的解决方案

Abstract: We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.

</details>


### [81] [Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models](https://arxiv.org/abs/2601.14917)
*Giorgia Rigamonti,Mirko Paolo Barbato,Davide Marelli,Paolo Napoletano*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的个性化血糖预测方法，通过利用患者特定数据来提高预测准确性，相比传统通用模型能更好地处理个体差异。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴血糖监测设备和移动健康应用的普及，准确的血糖预测对于增强自动化胰岛素输送和决策支持系统至关重要。传统通用模型无法充分处理个体差异，需要更个性化的方法来提高预测效果。

Method: 采用深度学习框架进行个性化血糖预测，比较留一受试者交叉验证与微调策略，评估多模态患者特定方法与传统CGM-only方法的差异，并进行消融研究确定有效个性化所需的最小数据量。

Result: 个性化模型显著提高了不良事件的预测能力，能够实现更精确和及时的干预。消融研究确定了有效个性化所需的最小数据量，这对于实际应用中数据收集困难的情况具有重要意义。

Conclusion: 自适应、个性化的血糖预测模型在下一代糖尿病管理中具有巨大潜力，特别是在可穿戴和移动健康平台中，能够增强面向消费者的糖尿病护理解决方案。

Abstract: Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.

</details>


### [82] [Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning](https://arxiv.org/abs/2601.14942)
*Hang Zhao,Hongru Li,Dongfang Xu,Shenghui Song,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出三阶段通信感知分布式学习框架，解决多模态边缘推理中的通信开销和鲁棒性问题，通过自监督学习、分布式微调和不确定性反馈机制优化训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 多模态边缘推理面临两大挑战：1）多模态特性导致带宽有限无线链路上的分布式学习通信开销巨大；2）在变化信道和噪声多模态输入下鲁棒性有限。需要同时提高训练和推理效率并保持无线信道下的鲁棒性。

Method: 三阶段框架：第一阶段，设备本地多模态自监督学习获取共享和模态特定编码器，无需设备-服务器交换；第二阶段，分布式微调结合集中式证据融合校准各模态不确定性并可靠聚合受噪声或信道衰落影响的特征；第三阶段，不确定性引导反馈机制为不确定样本选择性请求额外特征，优化分布式设置中的通信-精度权衡。

Result: 在RGB-深度室内场景分类实验中，该框架以更少的训练通信轮次获得更高精度，对模态退化或信道变化保持鲁棒性，优于现有的自监督和完全监督基线方法。

Conclusion: 提出的三阶段通信感知分布式学习框架有效解决了多模态边缘推理中的通信效率和鲁棒性问题，通过自监督学习减少通信开销，证据融合提高鲁棒性，不确定性反馈优化通信-精度权衡，为分布式边缘智能提供了实用解决方案。

Abstract: Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.

</details>


### [83] [InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement](https://arxiv.org/abs/2601.14968)
*Mingyue Cheng,Xiaoyu Tao,Huajian Zhang,Qi Liu,Enhong Chen*

Main category: cs.LG

TL;DR: InstructTime++：将时间序列分类重构为多模态生成任务，通过离散化时间序列、跨模态对齐和隐式特征建模，利用语言模型生成类别标签


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分类方法主要采用判别式范式，直接将输入序列映射到独热编码类别标签。这种方法难以融入上下文特征，也无法捕捉类别间的语义关系。

Method: 1. 将时间序列分类重构为多模态生成任务：连续数值序列、上下文文本特征和任务指令作为多模态输入，类别标签由调优的语言模型生成文本输出
2. 引入时间序列离散化模块：将连续序列转换为离散时间标记
3. 使用对齐投影层和生成式自监督预训练策略增强跨模态表示对齐
4. InstructTime++扩展：加入隐式特征建模，利用专门工具包挖掘原始时间序列和上下文输入中的信息模式（统计特征提取和视觉语言图像描述），并将其转换为文本描述进行集成

Result: 在多个基准数据集上的广泛实验证明了InstructTime++的优越性能

Conclusion: 通过将时间序列分类重构为多模态生成任务，并引入隐式特征建模，InstructTime++能够有效融合上下文特征、捕捉类别语义关系，显著提升了分类性能

Abstract: Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.

</details>


### [84] [Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors](https://arxiv.org/abs/2601.15000)
*Christos Petridis,Konstantinos Pelechrinis*

Main category: cs.LG

TL;DR: 本文提出L-RAPM回归方法，通过控制对手阵容影响和利用球员信息，解决篮球阵容分析中数据稀疏和噪声大的问题，提高小样本阵容的预测能力。


<details>
  <summary>Details</summary>
Motivation: 篮球等体育运动中识别表现良好的阵容组合是体育分析的重要任务，但频繁换人导致数据高度稀疏。NBA球队一个赛季使用超过600个阵容，每个阵容平均只有25-30次进攻回合，统计数据噪声大、预测价值低，现有方法未能有效解决此问题。

Method: 提出基于回归的L-RAPM方法，该方法控制每个阵容面对的对手阵容影响，同时利用组成阵容的球员信息进行建模分析。

Result: 实验表明，L-RAPM相比当前使用的基线方法具有更好的预测能力，且随着阵容样本量变小，改进效果更加明显。

Conclusion: L-RAPM方法能有效解决阵容分析中的数据稀疏问题，特别是在小样本情况下表现出更好的预测性能，为体育阵容分析提供了更可靠的统计工具。

Abstract: Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.

</details>


### [85] [RadixMLP - Intra-batch Deduplication for Causal Transformers](https://arxiv.org/abs/2601.15013)
*Michael Feil,Julius Lipp*

Main category: cs.LG

TL;DR: RadixMLP是一种针对因果Transformer模型批量推理优化的技术，通过压缩共享前缀的重复计算，在位置级操作中消除冗余，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 因果Transformer模型的批量推理工作负载经常处理具有共同前缀的序列（如系统提示、少样本示例、共享查询），标准推理引擎独立处理每个序列，导致对相同MLP激活的冗余重复计算。

Method: RadixMLP利用MLP、LayerNorm、线性投影和嵌入的位置特性，将批次动态映射到前缀树中，将共享段压缩为位置级计算的压缩表示，仅在注意力边界处散射回结果。该技术是无状态的，在单次前向传播中运行。

Result: 在MS MARCO v1.1上的Qwen3模型（0.6B到8B参数）端到端服务基准测试中，RadixMLP在实际重排序工作负载中实现1.44-1.59倍加速，在具有更长共享前缀的合成基准测试中达到最高5倍加速。

Conclusion: RadixMLP通过消除共享前缀的冗余计算，显著提升了因果Transformer模型的批量推理效率，特别是在具有大量共享前缀的实际应用场景中效果显著。

Abstract: Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\times$ speedups in realistic reranking workloads, with up to $5\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp.

</details>


### [86] [Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning](https://arxiv.org/abs/2601.15086)
*Oleg Shchendrigin,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 该论文提出了一个评估强化学习智能体记忆重写能力的基准测试，发现传统循环模型在记忆更新任务上比现代结构化记忆和基于Transformer的智能体表现更好


<details>
  <summary>Details</summary>
Motivation: 现实世界中的有效决策需要记忆既稳定又适应性强：环境随时间变化，智能体必须在长时间内保留相关信息，同时在情况变化时更新或覆盖过时内容。现有的强化学习基准和记忆增强智能体主要关注记忆保留，而同等重要的记忆重写能力在很大程度上未被探索。

Method: 引入了一个明确测试部分可观测性下持续记忆更新的基准，即智能体必须依赖记忆而非当前观察的自然设置。使用该基准比较了循环模型、基于Transformer的模型和结构化记忆架构。

Result: 实验表明，尽管经典循环模型简单，但在记忆重写任务中表现出比现代结构化记忆更大的灵活性和鲁棒性。结构化记忆仅在狭窄条件下成功，而基于Transformer的智能体在非平凡保留情况下经常失败。

Conclusion: 这些发现揭示了当前方法的基本局限性，强调了需要平衡稳定保留与适应性更新的记忆机制。该工作突出了这一被忽视的挑战，引入了评估它的基准，并为设计具有明确且可训练的遗忘机制的未来强化学习智能体提供了见解。

Abstract: Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/

</details>


### [87] [Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control](https://arxiv.org/abs/2601.15015)
*Jannis Becktepe,Aleksandra Franz,Nils Thuerey,Sebastian Peitz*

Main category: cs.LG

TL;DR: FluidGym是一个完全可微分的强化学习基准套件，用于主动流控制研究，解决了现有基准依赖外部CFD求解器、不可微分、缺乏3D和多智能体支持的问题。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在主动流控制领域的研究难以评估进展，因为现有研究使用异构的观测和驱动方案、数值设置和评估协议。现有基准依赖外部CFD求解器、不可微分，且3D和多智能体支持有限。

Method: 基于GPU加速的PICT求解器，在PyTorch上构建完全可微分的基准套件，作为独立的Python堆栈运行，无需外部CFD软件，提供标准化评估协议。

Result: 提供了PPO和SAC的基线结果，发布了所有环境、数据集和训练模型作为公共资源，建立了可扩展的学习型流控制研究基础。

Conclusion: FluidGym能够系统比较控制方法，为基于学习的流控制研究建立可扩展的基础，解决了现有基准的限制问题。

Abstract: Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.

</details>


### [88] [Auditing Language Model Unlearning via Information Decomposition](https://arxiv.org/abs/2601.15111)
*Anmol Goel,Alan Ritter,Iryna Gurevych*

Main category: cs.LG

TL;DR: 当前机器学习遗忘方法存在关键局限：尽管遗忘算法表面成功，但被遗忘数据的信息仍能从模型内部表示中线性解码。论文引入基于部分信息分解的信息论框架来审计遗忘效果，发现冗余信息在遗忘后持续存在，并提出基于表示的风险评分来减轻隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型遗忘方法存在严重缺陷，尽管算法表面成功，但被遗忘数据的信息仍能从模型内部表示中解码出来，这构成了隐私泄露风险。需要系统评估这种差异，为安全部署语言模型提供理论洞察和实用工具。

Method: 引入基于部分信息分解（PID）的可解释信息论框架来审计遗忘效果。通过比较遗忘前后的模型表示，将被遗忘数据的互信息分解为不同组件，形式化定义已遗忘知识和残留知识的概念。分析发现冗余信息（两个模型共享）构成残留知识，并提出基于表示的风险评分来指导推理时对敏感输入的弃权。

Result: 分析揭示冗余信息在遗忘后持续存在，并与已知对抗性重建攻击的易感性相关。基于这些洞察，提出的表示风险评分能够有效指导推理时对敏感输入的弃权，为减轻隐私泄露提供实用机制。

Conclusion: 这项工作为语言模型遗忘引入了原则性的表示层审计方法，提供了理论洞察和可操作工具，有助于更安全地部署语言模型。通过信息论框架揭示了当前遗忘方法的局限性，并提出实用机制来缓解隐私泄露风险。

Abstract: We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.

</details>


### [89] [Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization](https://arxiv.org/abs/2601.15021)
*Adam Rokah,Daniel Veress,Caleb Caulk,Sourav Sharan*

Main category: cs.LG

TL;DR: 该研究在图像分类任务中比较了密集模型、SoftMoE和SparseMoE三种架构，发现MoE变体在CIFAR10上获得略高的验证准确率，但条件计算在实际硬件上并未带来推理加速。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构在图像分类任务中的行为，包括预测性能、专家利用率和泛化特性，填补了MoE主要应用于语言模型而较少在视觉任务中研究的空白。

Method: 在CIFAR10数据集上，在可比模型容量下比较密集、SoftMoE和SparseMoE分类头；使用正则化防止专家崩溃；通过Hessian矩阵的最大特征值和迹等锐度指标分析泛化；进行损失曲面扰动分析；评估实际推理效率。

Result: 两种MoE变体都获得略高于密集基线的验证准确率，同时通过正则化保持专家平衡利用；SoftMoE显示更高的锐度指标，而密集和SparseMoE处于相似的曲率状态；条件计算在当前硬件规模下未实现推理加速。

Conclusion: MoE架构在图像分类中能获得略好的性能，但实际推理效率与理论预期存在差距；曲率分析揭示了模型间的差异，但未能直接解释验证准确率；需要进一步研究MoE在视觉任务中的实际应用价值。

Abstract: Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.

</details>


### [90] [Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.15124)
*Haonan Yuan,Qingyun Sun,Jiacheng Tao,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: RAG-GFM：一种检索增强的图基础模型，通过将知识从参数中卸载到外部存储，解决了现有图基础模型的内存瓶颈问题，实现了更好的可扩展性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前图基础模型（GFMs）存在内存瓶颈问题：它们试图将知识编码到模型参数中，这限制了语义容量，引入了严重的损失压缩和冲突，并且将图表示与知识纠缠在一起，阻碍了高效适应，影响了可扩展性和可解释性。

Method: 提出RAG-GFM，采用检索增强生成方法，将知识从参数中卸载。构建双模态统一检索模块：基于前缀结构文本的语义存储和基于中心性基元的结构存储。设计双视图对齐目标来保留异构信息，并通过上下文增强来丰富支持实例。

Result: 在五个基准图数据集上的广泛实验表明，RAG-GFM在跨领域节点和图分类任务中，始终优于13个最先进的基线方法，实现了卓越的有效性和效率。

Conclusion: RAG-GFM通过检索增强方法成功解决了图基础模型的内存瓶颈问题，实现了知识的外部化存储和高效的下游适应，为图基础模型的发展提供了新的方向。

Abstract: Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.

</details>


### [91] [Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data](https://arxiv.org/abs/2601.15158)
*Yuval Ran-Milo,Yotam Alexander,Shahar Mendel,Nadav Cohen*

Main category: cs.LG

TL;DR: 论文分析了Transformer模型在稀疏奖励下如何自发产生思维链推理能力，通过图遍历任务的理论分析揭示了梯度流驱动模型学习结构化算法的机制。


<details>
  <summary>Details</summary>
Motivation: 理解基于结果的强化学习训练中，稀疏奖励如何驱动Transformer模型自发发展出中间推理步骤（思维链）的机制，这一现象背后的理论原理尚不清楚。

Method: 通过分析单层Transformer在合成图遍历任务上的梯度流动态，该任务需要思维链才能解决但存在简单的迭代解。理论证明仅基于最终答案正确性的训练如何驱动模型收敛到结构化算法。

Result: 证明了梯度流会驱动模型学习到可解释的逐顶点遍历算法；识别了"简单示例"（需要较少推理步骤的实例）在分布中的关键作用；当训练分布包含足够简单示例时，模型学习到可泛化的遍历策略并能外推到更长链。

Conclusion: 稀疏奖励下的梯度学习能够自发发现结构化推理算法，但依赖于训练分布中包含足够多的简单示例；这一理论发现在合成数据和真实语言模型的数学推理任务中得到了验证。

Abstract: Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of "simple examples": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.

</details>


### [92] [Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism](https://arxiv.org/abs/2601.15249)
*Garrett G. Wen,Buxin Su,Natalie Collina,Zhun Deng,Weijie Su*

Main category: cs.LG

TL;DR: 提出一种作者辅助的最佳论文评选机制，通过等渗机制收集作者对自己论文的排名评估，调整原始评审分数以更准确估计论文真实质量，证明在凸效用函数下单配额情况下作者有真实报告动机，并通过实际会议数据验证机制有效性。


<details>
  <summary>Details</summary>
Motivation: 随着NeurIPS、ICML等AI会议投稿量激增至数万篇，同行评审质量和一致性面临重大挑战，特别是最佳论文奖项的评选过程近年来争议不断。需要一种机制来改进最佳论文的选择质量。

Method: 采用等渗机制收集作者对自己提交论文的排名评估，利用这些排名信息调整原始评审分数，以最优估计论文的真实质量。机制设计确保在凸效用函数下作者有真实报告动机，特别在单配额情况下（作者只能提名一篇论文）即使效用函数仅为非递减可加函数也能保证真实性。机制还扩展到处理常见的作者重叠情况。

Result: 使用2019-2023年ICLR和2021-2023年NeurIPS的公开评审数据验证了凸性假设。证明在单配额情况下，即使效用函数仅为非递减可加函数，作者也有真实报告动机，这显著放宽了先前工作所需的假设。仿真结果表明该机制能显著提高获奖论文的质量。

Conclusion: 作者辅助的最佳论文评选机制通过等渗机制有效利用作者对自己论文的评估信息，在保证真实报告动机的前提下显著改进奖项评选质量，为大规模会议的最佳论文选择提供了可行的解决方案。

Abstract: Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.

</details>


### [93] [LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training](https://arxiv.org/abs/2601.15079)
*Chenyu Liu,Haige Li,Luca Rossi*

Main category: cs.LG

TL;DR: 提出LoRAP方法，通过低秩聚合提示优化GNN量化训练，在多个数据集和框架上显著提升低比特量化GNN性能


<details>
  <summary>Details</summary>
Motivation: GNN量化是减少模型大小、加速推理的有效方法，但相比LLMs，GNN量化更关注图特征的量化。现有方法仅提示节点特征只能使部分量化聚合结果最优，需要更全面的优化方案。

Method: 提出低秩聚合提示（LoRAP）方法，将轻量级、输入相关的提示注入每个聚合特征中，优化量化聚合结果。该方法利用提示学习操纵输入数据，改进GNN的量化感知训练性能。

Result: 在4个主流QAT框架和9个图数据集上的广泛评估表明，LoRAP能持续提升低比特量化GNN的性能，同时引入的计算开销极小。

Conclusion: LoRAP通过优化量化聚合过程，有效解决了GNN量化训练中的性能瓶颈，为资源受限环境下的高效GNN部署提供了实用解决方案。

Abstract: Graph Neural Networks (GNNs) are neural networks that aim to process graph data, capturing the relationships and interactions between nodes using the message-passing mechanism. GNN quantization has emerged as a promising approach for reducing model size and accelerating inference in resource-constrained environments. Compared to quantization in LLMs, quantizing graph features is more emphasized in GNNs. Inspired by the above, we propose to leverage prompt learning, which manipulates the input data, to improve the performance of quantization-aware training (QAT) for GNNs. To mitigate the issue that prompting the node features alone can only make part of the quantized aggregation result optimal, we introduce Low-Rank Aggregation Prompting (LoRAP), which injects lightweight, input-dependent prompts into each aggregated feature to optimize the results of quantized aggregations. Extensive evaluations on 4 leading QAT frameworks over 9 graph datasets demonstrate that LoRAP consistently enhances the performance of low-bit quantized GNNs while introducing a minimal computational overhead.

</details>


### [94] [Field-Space Autoencoder for Scalable Climate Emulators](https://arxiv.org/abs/2601.15102)
*Johannes Meuer,Maximilian Witte,Étiénne Plésiat,Thomas Ludwig,Christopher Kadow*

Main category: cs.LG

TL;DR: 提出Field-Space Autoencoder框架，通过球面压缩模型解决千米尺度地球系统模型计算成本高、输出数据量大的问题，支持零样本超分辨率和生成式扩散模型训练。


<details>
  <summary>Details</summary>
Motivation: 千米尺度地球系统模型计算成本高昂且产生PB级输出，限制了其在概率风险评估等应用中的实用性，需要开发可扩展的气候模拟框架来克服这些挑战。

Method: 提出Field-Space Autoencoder框架，采用球面压缩模型和Field-Space Attention机制，直接在原生气候模型输出上操作，避免将球面数据强制映射到欧几里得网格造成的几何失真。该方法生成结构化压缩场，作为下游生成式模拟的良好基线，并支持零样本超分辨率。

Result: 该方法比卷积基线更好地保留了物理结构，能够将低分辨率大集合和稀缺高分辨率数据映射到共享表示中。在压缩场上训练的生成扩散模型可以同时从丰富的低分辨率数据中学习内部变异性，从稀疏的高分辨率数据中学习精细尺度物理。

Conclusion: 该工作弥合了低分辨率集合统计的高数据量与高分辨率物理细节稀缺性之间的差距，为千米尺度气候模拟提供了可扩展的解决方案。

Abstract: Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.

</details>


### [95] [CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning](https://arxiv.org/abs/2601.15141)
*Tianshi Xu,Yuteng Chen,Meng Li*

Main category: cs.LG

TL;DR: CLEANER是一种针对参数受限LLM的强化学习方法，通过自校正机制净化噪声轨迹，解决探索阶段执行失败导致的信用分配问题，显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 参数受限的LLM（4B-7B）在工具使用强化学习中面临探索阶段频繁执行失败的问题，产生噪声轨迹，导致信用分配困难。现有方法要么容易引发奖励黑客攻击，要么计算成本过高。

Method: 提出CLEANER框架，核心是相似性感知自适应回滚机制（SAAR）。该机制利用模型内在的自校正能力，在数据收集过程中直接消除错误污染，通过语义相似性自适应地从浅层执行修复到深层推理替换，构建纯净轨迹。

Result: 在AIME24/25、GPQA和LiveCodeBench基准测试中，相比基线平均准确率分别提升6%、3%和5%。仅用三分之一训练步数即达到最先进性能。

Conclusion: 轨迹净化是高效智能体强化学习的可扩展解决方案，通过自校正机制让模型内化正确推理模式而非错误恢复循环，显著提升训练效率和性能。

Abstract: Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub

</details>


### [96] [ZENITH: Automated Gradient Norm Informed Stochastic Optimization](https://arxiv.org/abs/2601.15212)
*Dhrubo Saha*

Main category: cs.LG

TL;DR: ZENITH优化器通过梯度范数的时间演化自适应调整学习率，无需手动调参，在图像分类、目标检测等任务上取得更高精度和更快训练速度。


<details>
  <summary>Details</summary>
Motivation: 现有自适应优化器存在计算和内存开销大、与正则化不兼容、学习率选择次优等问题，需要开发更高效的自适应学习率调度方法。

Method: 提出ZENITH优化器，利用梯度范数的时间演化信息来自适应调整学习率，实现零开销的自适应学习率调度。

Result: 在6种CNN架构和6个基准测试的图像分类实验中，ZENITH在更短的训练时间内获得更高的测试精度；在MS COCO的目标检测、关键点检测和实例分割任务上也取得更优的mAP。

Conclusion: ZENITH优化器通过梯度范数演化自适应调整学习率，实现了高效、兼容正则化的训练，在多种视觉任务上表现出优越性能。

Abstract: Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [97] [Exciton-Anyon Binding in Fractional Chern Insulators: Spectral Fingerprints](https://arxiv.org/abs/2601.14365)
*Tianhong Lu,Luiz H. Santos*

Main category: cond-mat.str-el

TL;DR: 该研究探讨了过渡金属二硫化物中激子与分数陈绝缘体准空穴的相互作用，通过精确对角化方法发现了激子-准空穴束缚态的存在，并估算了其在莫尔异质结构中的结合能尺度。


<details>
  <summary>Details</summary>
Motivation: 过渡金属二硫化物（TMDs）独特地结合了无需外磁场的拓扑电子态和长寿命激子产生的强光学响应。这种结合促使研究者探索激子与分数陈绝缘体准空穴相互作用的物理现象。

Method: 研究者引入了kagome晶格费米子-玻色子模型，该模型包含电子分数陈绝缘体和可调色散的移动激子。通过精确对角化方法，研究了电子-激子排斥相互作用和激子动能对系统的影响。

Result: 研究发现激子-准空穴束缚态的出现，这些态作为费米子-玻色子谱中的低能级，与散射连续谱明显分离。尽管存在排斥相互作用，但由于准空穴相关的局部电荷耗尽产生的残余吸引力，仍然形成了束缚态。

Conclusion: 该研究为莫尔TMD异质结构提供了模型描述，包括分数陈绝缘体扭曲双层MoTe2与激子TMD异质双层的邻近效应，估计激子-准空穴结合能尺度为0.6-1.1 meV，这些效应可通过光致发光光谱观测。

Abstract: Transition--metal dichalcogenides (TMDs) uniquely combine topological electronic states realized without external magnetic fields with a strong optical response arising from long--lived excitons. Motivated by this confluence, we investigate an interacting fermion--boson system formed by coupling an exciton to a quasihole of a fractional Chern insulator (FCI) at filling fraction $1/3$. We introduce a kagome--lattice fermion--boson model hosting an electronic FCI and a mobile exciton whose dispersion is tunable from a parabolic band to a flatband. Using exact diagonalization, we demonstrate the emergence of exciton--quasihole bound states controlled by the repulsive electron--exciton interaction $V_{\mathrm{FB}}$ and the exciton kinetic energy $t_{\mathrm{B}}$. These states appear as low--lying levels in the fermion--boson spectrum, well separated from the scattering continuum, and arise despite repulsive interactions due to a residual attraction to the local charge depletion associated with a quasihole. Reducing $t_{\mathrm{B}}$ enhances this effect by favoring interaction--dominated binding. Our results provide a model description of moiré TMD heterostructures, including fractional Chern insulating twisted bilayer MoTe$_2$ proximitized by excitonic TMD heterobilayers, where we estimate exciton--quasihole binding energy scales of $0.6$--$1.1$~meV, placing these effects within reach of photoluminescence spectroscopy.

</details>


### [98] [A Quantum Many-Body Approach for Orbital Magnetism in Correlated Multiband Electron Systems](https://arxiv.org/abs/2601.14372)
*Mengxing Ye*

Main category: cond-mat.str-el

TL;DR: 开发了基于Luttinger-Ward泛函的量子多体框架，用于描述相互作用多带系统中的轨道磁响应，通过非对易坐标的"傅里叶"表示在有效动量空间中处理磁场扰动。


<details>
  <summary>Details</summary>
Motivation: 轨道磁性是纯粹的量子现象，反映了固体的内在电子特性，但在相互作用多带系统中的微观描述仍然不完整，需要发展一个通用的量子多体框架来研究相关电子系统中的轨道磁响应。

Method: 从Dyson方程出发，在弱磁场下重新表述热力学势，构建了磁场幂次展开的受控展开。关键技术是使用非对易坐标的"傅里叶"表示，将热力学势表达在有效动量空间中，使磁场作为微扰处理，通过Moyal代数实现解析进展。

Result: 推导出自发轨道磁化强度，完全用自能重整化的零场哈密顿量表示。对于频率依赖但厄米的自能，将轨道磁矩和贝里曲率推广到动量-频率空间，识别出由这些量构建的两个规范不变贡献。对于频率无关的自能，结果简化为非相互作用系统的几何公式。

Conclusion: 该框架为计算相关多带材料中的轨道磁响应提供了统一的基础，填补了相互作用多带系统中轨道磁性微观描述的空白。

Abstract: Orbital magnetism is a purely quantum phenomenon that reflects intrinsic electronic properties of solids, yet its microscopic description in interacting multiband systems remains incomplete. We develop a general quantum many-body framework for orbital magnetic responses based on the Luttinger-Ward functional. Starting from the Dyson equation, we reformulate the thermodynamic potential in a weak magnetic field and construct a controlled expansion in powers of $B$ applicable to correlated electron systems. A key technical advance is a modified ``Fourier'' representation using noncommutative coordinates, which allows the thermodynamic potential to be expressed in an effective momentum space where the magnetic field acts perturbatively. This formulation makes analytic progress possible within the Moyal algebra. As an application, we derive the spontaneous orbital magnetization and express it entirely in terms of the zero-field Hamiltonian renormalized by the self-energy. For frequency-dependent but Hermitian self-energies, we generalize the orbital magnetic moment and Berry curvature to momentum-frequency space and identify two gauge-invariant contributions built from these quantities. For frequency-independent self-energies the result reduces to the familiar geometric formula for noninteracting systems. This framework provides a unified foundation for computing orbital magnetic responses in correlated multiband materials.

</details>


### [99] [Field-induced states and thermodynamics of the frustrated Heisenberg antiferromagnet on a square lattice](https://arxiv.org/abs/2601.14380)
*Andreas Honecker,M. E. Zhitomirsky,Alexander Wietek,Johannes Richter*

Main category: cond-mat.str-el

TL;DR: 研究J1-J2方晶格海森堡反铁磁体在磁场中的基态和有限温度性质，特别关注J2≈J1/2的高阻挫区域，分析"上上上下"态相变和磁热效应


<details>
  <summary>Details</summary>
Motivation: 探索高度阻挫的J1-J2海森堡反铁磁体在磁场下的相图，特别是量子涨落和热涨落如何稳定"上上上下"态，并研究相关的磁热效应

Method: 首先使用经典蒙特卡洛模拟研究经典情况，然后针对自旋1/2的极端量子极限，进行零温和有限温度的Lanczos计算

Result: 获得了h-T相图，重点分析了量子情况下在饱和磁化一半处出现的"上上上下"态平台，并讨论了J2=J1/2时饱和场处基态简并导致的增强磁热效应

Conclusion: 在高度阻挫的J1-J2海森堡反铁磁体中，量子涨落和热涨落共同稳定了"上上上下"态，该体系在特定参数下表现出显著的磁热效应和丰富的相图特征

Abstract: We investigate the ground-state and finite-temperature properties of the $J_1$-$J_2$ Heisenberg antiferromagnet on the square lattice in the presence of an external magnetic field. We focus on the highly frustrated regime around $J_2 \approx J_1/2$. The $h$-$T$ phase diagram is investigated with particular emphasis on the finite-temperature transition into the "up-up-up-down" state that is stabilized by thermal and quantum fluctuations and manifests itself as a plateau at one half of the saturation magnetization in the quantum case. We also discuss the enhanced magnetocaloric effect associated to the ground-state degeneracy that arises at the saturation field for $J_2=J_1/2$. For reference, we first study the classical case by classical Monte Carlo simulations. Then we turn to the extreme quantum limit of spin-1/2 where we perform zero- and finite-temperature Lanczos calculations.

</details>


### [100] [Pressure Tuning of Electronic Correlations and Flat Bands in CsCr$_3$Sb$_5$](https://arxiv.org/abs/2601.14439)
*Maria Chatzieleftheriou,Jonas B. Profe,Ying Li,Roser Valentí*

Main category: cond-mat.str-el

TL;DR: 该研究通过DFT+DMFT计算揭示了压力对CsCr₃Sb₅电子性质的影响，发现压力通过增强轨道杂化减弱电子关联，从而抑制有序相并促进超导相的出现。


<details>
  <summary>Details</summary>
Motivation: CsCr₃Sb₅是一种新发现的强关联kagome超导体，具有高温非费米液体行为和低温电荷/自旋密度波有序。其相图与高温超导体相似，且kagome平带接近费米能级，可能具有交变磁有序，这些特性激发了广泛的理论和实验研究。为了理解压力如何影响有序态，需要系统研究压力下电子性质的演化。

Method: 采用DFT+DMFT（密度泛函理论与动力学平均场理论相结合）计算方法，系统研究压力下电子性质的演化，特别是平带中谱权重的重新分布与电子关联强度的相互作用。

Result: 研究发现压力下平带谱权重重新分布与电子关联强度之间存在复杂的相互作用。压力通过增强轨道杂化有效减弱电子关联，这为超导相的出现提供了直接解释。

Conclusion: 压力通过增强轨道杂化减弱电子关联，从而抑制系统的有序相，这强烈表明超导性是有序相被抑制的直接结果。这一发现加深了对CsCr₃Sb₅这类kagome超导体中压力调控机制的理解。

Abstract: CsCr$_3$Sb$_5$ is a newly identified strongly correlated kagome superconductor, characterized by non-Fermi-liquid behavior at elevated temperatures and intertwined charge- and spin-density-wave order below $T_{DW}\approx 54$K. Under external pressure, this order is suppressed and a superconducting phase emerges. This phase diagram, which closely resembles that of high-$T_c$ superconductors, together with a kagome flat band near the Fermi level and possible altermagnetic order, has motivated extensive theoretical and experimental investigations. To better understand how pressure influences the ordered states, we present a systematic study of the evolution of the electronic properties under applied pressure. Performing DFT+DMFT (density functional theory combined with dynamical mean field theory) calculations, we uncover a complex interplay between the redistribution of spectral weight in the flat bands and the strength of electronic correlations under pressure. Our results further strengthen the interpretation that pressure effectively weakens electronic correlations through enhanced orbital hybridization. This, in turn, strongly suggests that superconductivity emerges as a direct consequence of the suppression of the system's ordered phase.

</details>


### [101] [Chirality and quasi-long-range order in finite-flux Gutzwiller states for magnetized frustrated magnets](https://arxiv.org/abs/2601.14458)
*Wen O. Wang,Urban F. P. Seifert,Oleg A. Starykh,Leon Balents*

Main category: cond-mat.str-el

TL;DR: 研究三角晶格U(1)狄拉克自旋液体在塞曼场中的Gutzwiller投影波函数，发现最优态具有有限规范通量，使自旋子填充处于|C|=1朗道能隙中，表现出非零标量自旋手性和准长程120°磁关联。


<details>
  <summary>Details</summary>
Motivation: 研究磁场下三角晶格U(1)狄拉克自旋液体的响应特性，为分析DSL候选材料的磁场响应提供理论指导，并建立连接自旋子与涌现U(1)规范场理论的数值诊断方法。

Method: 使用Gutzwiller投影波函数方法，允许U(1)规范场产生规范通量，形成自旋子朗道能级。通过相关矩阵重构计算局部海森堡型模型的变分能量和能量方差，寻找最优候选态。

Result: 在给定磁化强度下，最优候选态具有有限规范通量，使自旋子填充处于|C|=1朗道能隙中，具有最低变分能量和最小能量方差。该态表现出非零（交错）标量自旋手性，并显示主导的准长程120°磁关联。次优的|C|=2态则表现出异常的自旋向列关联。

Conclusion: 研究结果为分析狄拉克自旋液体候选材料的磁场响应提供了指导，并提供了连接自旋子与涌现U(1)规范场理论的数值诊断工具，揭示了规范通量在磁场响应中的重要作用。

Abstract: We study Gutzwiller-projected wavefunctions for triangular-lattice U(1) Dirac spin liquids in a Zeeman field, where we allow the U(1) gauge field to develop a gauge flux, resulting in (spin-split) spinon Landau levels. We find that at a given magnetization, the optimal candidate state has a finite flux chosen such that the spinon filling lies in a $|C|=1$ Landau-level gap: it gives the lowest variational energy and the smallest energy variance within our correlation-matrix reconstruction for local Heisenberg-type models. By symmetry, we argue that the finite gauge flux results in a non-zero (staggered) scalar spin chirality, as also numerically observed, and further find that the $|C|=1$ state exhibits dominant quasi-long-ranged $120^\circ$ magnetic correlations. Studying the next-to-optimal wavefunction with a $|C|=2$ Landau-level gap, we observe unusual spin-nematic correlations. Our results may provide guidance for analyzing the magnetic-field response of DSL candidate materials and offer numerical diagnostics that can connect to the underlying theory of spinons coupled to an emergent U(1) gauge field.

</details>


### [102] [Anomalous Quantum Criticality at a Continuous Metal-Insulator Transition](https://arxiv.org/abs/2601.15007)
*M. S. Laad,Prosenjit Haldar*

Main category: cond-mat.str-el

TL;DR: Falicov-Kimball模型在Bethe晶格上通过解析方法揭示了Mott-like量子临界点，发现密度涨落模式获得反常维度，亚扩散金属相收缩为单一临界点。


<details>
  <summary>Details</summary>
Motivation: Falicov-Kimball模型作为最简单的关联费米子模型，已知在三维及以上维度存在连续金属-绝缘体转变的Mott-like量子临界点，并与退火二元合金无序模型同构。尽管已有大量数值研究，但对产生这种新颖量子临界性的微观过程的解析理解仍然缺乏。

Method: 在分层Cayley树（Bethe晶格）上为Falicov-Kimball模型开发了完全解析理论，利用2位点团簇动力学平均场理论（CDMFT）的单一输入。通过分析发现密度涨落模式获得反常维度，源于红外幂律奇异的团簇自能。

Result: 在零温下，发现分离弱遍历金属和非遍历绝缘体的具有玻璃动力学的亚扩散金属相收缩为单一临界点，即Mott-like量子临界点（至少在Bethe晶格上如此）。密度涨落模式获得反常维度，团簇自能呈现红外幂律奇异行为。

Conclusion: 该研究详细描述了这种反常量子临界性对一系列热力学和动力学响应的后果，这些响应可在多种物理系统中通过Falicov-Kimball模型有效建模。为理解Mott-like量子临界性提供了重要的解析见解。

Abstract: The Falicov-Kimball model (FKM) is long known to be the simplest model of correlated fermions exhibiting a novel Mott-like quantum critical point (QCP) assocaited with a {\it continuous} MIT in dimensions $D \geq 3$. It is also known to be isomorphic to an {\it annealed} binary-alloy disorder model. Notwithstanding extensive numerical studies for the FKM, analytic insight into the microscopic processes spawning novel Mott-like quantum criticality is scarce. Here, we develop a fully analytic theory for the Mott-like quantum criticality in the FKM on a hierarchical Cayley tree (Bethe lattice) by utilizing a single input from a 2-site cluster-dynamical mean-field theory (CDMFT). We find that density fluctuation modes acquire anomalous dimensions, originating from infra-red power-law singular cluster self-energies. Interestingly, we uncover, at $T=0$, that this {\it sub-diffusive} metal with glassy dynamics separating a weakly ergodic metal from a non-ergodic insulator shrinks to a single point, namely the Mott-like QCP, at least on the Bethe lattice. We detail the consequences of this anomalous quantum criticality for a range of thermal and dynamical responses in a variety of physical systems that can be effectively modelled by the FKM.

</details>


### [103] [Magnetic field induced phenomena in Kitaev spin liquids](https://arxiv.org/abs/2601.14496)
*Shi Feng,Nandini Trivedi*

Main category: cond-mat.str-el

TL;DR: 该论文综述了量子自旋液体中分数化粒子的实验识别挑战，特别是磁场作用下规范场与物质Majorana费米子混合的问题，探讨了在不同场稳定QSL体系中如何分离特定分数化准粒子的响应。


<details>
  <summary>Details</summary>
Motivation: 量子自旋液体中的分数化粒子（如Z_2通量和Majorana费米子）在实验上难以直接识别，因为实际材料中的非可积相互作用和磁场会混合规范场与物质场，甚至产生与可积极限不相连的新相。需要明确在何种场稳定QSL体系中可以分离特定分数化准粒子的响应。

Method: 综述性研究方法，回顾Abelian、非Abelian以及磁场诱导的量子相（与可积极限无微扰连接）中的进展。将场诱导动力学现象与中子散射、共振非弹性X射线散射、泵浦探测光谱等具体实验观测手段联系起来。

Result: 明确了在不同场稳定QSL体系中分离特定分数化准粒子响应的条件，特别是量子Majorana金属相中Majorana费米子的独特动力学可直接在散射中观测。建立了场诱导动力学现象与具体实验观测手段的对应关系。

Conclusion: 通过系统分析磁场作用下量子自旋液体的动力学响应，为实验识别特定分数化粒子（包括Majorana费米子和Z_2通量）提供了理论框架和实验指导，有助于澄清假想自旋液体的存在性和实验范围。

Abstract: Quantum spin liquids (QSLs) host a variety of fractionalized particles. In Kitaev's paradigmatic honeycomb model a spin-$\tfrac{1}{2}$ fractionalizes into $Z_2$ flux due to emergent $Z_2$ gauge field and matter Majorana fermions. Although these excitations have well-defined dynamics in the integrable limit, their direct experimental identification is notoriously challenging: realistic materials inevitably host additional symmetry-allowed interactions that break integrability and hybridize gauge and matter sectors, while magnetic fields, which are often required to suppress competing order and stabilize a putative QSL regime, further entangle the responses of different fractionalized quasiparticles and may even drive the system into field-induced spin-liquid phases that are not adiabatically connected to the integrable limit. A prominent example is the quantum Majorana metal, in which the distinct dynamics of fractionalized Majorana fermions can become directly visible in scattering. This report highlights recent progress on these related questions: in which field-stabilized QSL regimes and nearby emergent phases, and under what conditions, can the response of a specific fractionalized quasiparticle be isolated and positively understood, thereby clarifying the existence and the experimental scope of putative spin liquids? We review the progress on these questions across Abelian, non-Abelian, and an emergent quantum phases under magnetic field that are not perturbatively connected to the integrable limit. We connect these field-induced dynamical phenomena to concrete experimental observables, relevant for neutron scattering, resonant inelastic X-ray scattering, and pump-probe spectroscopy that are capable of resolving specific types of fractionalized particles, including Majoranas and $Z_2$ fluxes.

</details>


### [104] [Ionization energy and electron affinity of fullerene C60 in the Hubbard model in the static fluctuation approximation](https://arxiv.org/abs/2601.14817)
*Gennadiy Ivanovich Mironov*

Main category: cond-mat.str-el

TL;DR: 在哈伯德模型中，使用静态涨落近似计算了C60富勒烯的电离能和电子亲和能，理论值与实验值吻合良好


<details>
  <summary>Details</summary>
Motivation: 研究C60富勒烯中强关联π电子系统的光电性质，特别是电离能和电子亲和能，以理解富勒烯对外部扰动的响应机制

Method: 采用哈伯德模型和静态涨落近似，首先获得化学势方程的图形表示，然后计算描述π电子在相邻位点间跃迁的相关函数，以及表征单个位点上两个自旋相反的π电子存在概率的热力学平均值

Result: 理论计算得到的电离能为7.57 eV，电子亲和能为2.67 eV，与实验观测值一致，表明富勒烯在光致电离或其他导致π电子得失的过程中，对外部扰动表现出强关联π电子单系统的响应特性

Conclusion: C60富勒烯在光电过程中表现为一个强关联π电子系统，哈伯德模型结合静态涨落近似能够准确描述其电离能和电子亲和能等关键光电性质

Abstract: Within the Hubbard model, the ionization energy and electron affinity of the icosahedral C60 fullerene are calculated in the static fluctuation approximation. A graphical representation of the chemical potential equation is first obtained. The correlation function, which describes the transitions of π-electrons from one fullerene site to the nearest site, and the thermodynamic average, which characterizes the probability of detecting two π-electrons with oppositely oriented spin projections on a single fullerene site, are then calculated. The theoretically obtained values for the ionization energy of 7.57 eV and the electron affinity of 2.67 eV coincide with the experimentally observed values and demonstrate that, during photoionization or another process leading to either the acquisition or loss of a π-electron, the fullerene responds to external perturbations as a single system of strongly correlated π-electrons.

</details>


### [105] [Altermagnets versus Antiferromagnets](https://arxiv.org/abs/2601.14878)
*V. P. Mineev*

Main category: cond-mat.str-el

TL;DR: 该研究通过现象学方法分析了altermagnet（交变磁体）的电子能带结构和反常霍尔效应，发现在无外磁场情况下，只有弱铁磁态才能产生反常霍尔效应。


<details>
  <summary>Details</summary>
Motivation: 研究altermagnet这种具有动量依赖自旋分裂的新型金属材料，探索其电子能带结构和反常霍尔效应的特性，特别是理解在无外磁场条件下产生反常霍尔效应的条件。

Method: 采用现象学方法建立altermagnet的电子能带谱，对应具有相同对称性的反铁磁体。计算了三种不同磁结构（共线反铁磁体、弱铁磁反铁磁体和亚铁磁结构）的Berry曲率，分析反常霍尔效应的产生条件。

Result: 研究发现，在研究的特定情况下，无外磁场时反常霍尔效应仅在弱铁磁态中可能发生。这表明altermagnet的反常霍尔效应与特定的磁结构密切相关。

Conclusion: altermagnet的反常霍尔效应受其磁结构类型影响显著，只有在弱铁磁态下才能在无外磁场条件下观察到反常霍尔效应，这为理解这类新型材料的输运性质提供了重要见解。

Abstract: Altermagnets are metals with a momentum-dependent spin splitting of electron bands due to a specific crystal structure, which is invariant under time reversal only in combination with rotations and reflections. The developed phenomenological approach makes it possible to obtain a spectrum of electron bands in an altermagnet corresponding to an antiferromagnet with the same symmetry. The anomalous Hall effect is an inherent property of substances whose electron band dispersion is characterized by the Berry curvature. Calculations of the Berry curvature were performed for altermagnet analogs of collinear antiferromagnet, weak ferromagnetic antiferromagnet, and ferrimagnetic structures. It was shown that in the specific cases under consideration, the anomalous Hall effect in the absence of an external magnetic field is possible only in the state of a weak ferromagnet.

</details>


### [106] [Dielectric formalism of the 2D uniform electron gas at finite temperatures](https://arxiv.org/abs/2601.14989)
*Fotios Kalkavouras,Tobias Dornheim,Paul Hamann,Panagiotis Tolias*

Main category: cond-mat.str-el

TL;DR: 该论文对有限温度下的二维均匀电子气进行了全面分析，构建了STLS和HNC近似方案，并与最新的路径积分蒙特卡洛数据进行基准测试，提供了交换-关联自由能的精确参数化。


<details>
  <summary>Details</summary>
Motivation: 研究有限温度下二维均匀电子气的物理性质，填补在宽范围密度和温度参数下的理论空白，为相关实验和应用提供可靠的理论基础。

Method: 采用自洽介电形式理论，构建了二维版本的STLS和HNC近似方案，并与最新的路径积分蒙特卡洛数据进行基准测试比较。

Result: 获得了在宽参数范围（0.01≤r_s≤20, 0.01≤Θ≤10）内的结构和热力学性质，确定了这些近似方案保持定量可靠性的区域，并提供了有限温度2DEG交换-关联自由能的精确参数化。

Conclusion: 该研究为有限温度二维电子气提供了全面的理论框架和精确的参数化，为相关领域的研究和应用提供了重要参考。

Abstract: We present a comprehensive analysis of the two-dimensional uniform electron gas (2D-UEG or more commonly 2DEG) at finite temperature, spanning a broad range of densities / coupling strengths ($0.01\le{r}_s\le20$) and temperatures / degeneracy parameters ($0.01\leΘ= k_B T/E_F \le 10$). Within the self-consistent dielectric formalism, we construct two-dimensional versions of the Singwi-Tosi-Land-Sjölander (STLS) and hypernetted-chain (HNC) approximation based schemes. We benchmark the accuracy of the STLS and the HNC schemes against new state-of-the-art path-integral Monte Carlo data. We also report structural and thermodynamic properties across the full $(r_s,Θ)$ phase diagram domain studied, identify regimes in which these schemes remain quantitatively reliable, and provide an accurate parametrization of the exchange--correlation free energy of the finite-temperature 2DEG.

</details>


### [107] [Assessing Orbital Optimization in Variational and Diffusion Monte Carlo](https://arxiv.org/abs/2601.15169)
*Cody A. Melton,Jaron T. Krogel*

Main category: cond-mat.str-el

TL;DR: 研究了轨道优化在变分蒙特卡洛中的保真度，以改善扩散蒙特卡洛在相关磁性系统（以CrSBr为模型）中的结果。发现轨道优化虽然能改善固定节点误差，但由于赝势导致的局域性误差增加，最终扩散蒙特卡洛能量反而不如标准DFT轨道。


<details>
  <summary>Details</summary>
Motivation: 研究轨道优化在变分蒙特卡洛中的有效性，以改善扩散蒙特卡洛在相关磁性系统（特别是CrSBr）中的计算精度，探索不同优化方法对结果的影响。

Method: 使用CrSBr作为模型系统，比较不同优化方法（特别是随机重构方法）的性能，研究短程Jastrow因子、大活性空间对变分能量收敛的影响，分析轨道优化对扩散蒙特卡洛能量和局域性误差的影响。

Result: 1. 随机重构是稳健可靠的优化器；2. 短程Jastrow因子对改善扩散蒙特卡洛很重要；3. 大活性空间能收敛变分能量；4. 轨道优化相比标准DFT轨道产生更差的扩散蒙特卡洛能量（由于赝势导致的局域性误差增加）；5. 轨道优化实际上改善了固定节点误差；6. 对于能量以外的可观测量，轨道优化产生系统性的更小混合估计器偏差。

Conclusion: 轨道优化为改善变分和纯固定节点能量以及降低混合估计器偏差提供了可靠方法，尽管在扩散蒙特卡洛能量方面可能因局域性误差增加而表现不如标准DFT轨道。

Abstract: In this work, we investigate the fidelity of orbital optimization in variational Monte Carlo to improve diffusion Monte Carlo results on correlated magnetic systems, using CrSBr as a model system. We compare the performance of different optimization methods, showing that stochastic reconfiguration is a robust and reliable optimizer. We show that short range Jastrow factors are important for improving diffusion Monte Carlo, regardless of the quality of orbitals. Large active spaces are required to converge the variational energy, but ulitmately orbital optimization produces worse diffusion Monte Carlo energies when compared to standard orbitals from density functional theory. We show that this increased bias is due to larger locality errors from the use of pseudopotentials, while the fixed-node error is actually improved by using orbital optimization. Additionally, for observables other than energy, orbital optimization produces a systematically smaller mixed-estimator bias. Ultimately, we believe orbital optimization provides a reliable method to improve variational and pure fixed-node energies as well as lower mixed-estimator bias.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [108] [Limits of the Formal Integrals of Motion](https://arxiv.org/abs/2601.14899)
*George Contopoulos,Athanasios C. Tzemos,Foivos Zanias*

Main category: nlin.CD

TL;DR: 该论文研究哈密顿系统H=1/2(X²+Y²+ω₁²x²+ω₂²y²)+ε(ηxy²+αx³+βx²y+γy³)的形式积分，分析无理频率比和有理频率比情况，特别关注几个共振比，并比较数值结果与理论预测。


<details>
  <summary>Details</summary>
Motivation: 研究更一般的哈密顿系统中形式积分的存在性，扩展先前β=γ=0的特殊情况，探索不同频率比（包括无理数和有理数）下积分的存在条件。

Method: 首先给出无理频率比情况下的一般积分形式，然后研究可公度频率情况，特别分析ω₁/ω₂=4/1,5/1,3/2,4/3,3/1,2/1等共振比。计算ω₁/ω₂=2/1和1/1情况下的不变曲线和轨道，比较βγ≠0时的精确数值结果与形式积分理论预测。

Result: 在ω₁/ω₂=1/1的特殊情况下，当β=γ=0且ηα≠0，或η=α=0且βγ≠0时存在积分，但当ηαβγ≠0时不存在积分。发现不变曲线和轨道可以用非共振积分近似，其中ω₁/ω₂=5√2/7≈1.010。

Conclusion: 该研究扩展了哈密顿系统形式积分的理论框架，揭示了不同参数条件下积分的存在性，特别是在共振频率比情况下的特殊性质，为理解非线性哈密顿系统的可积性提供了新的见解。

Abstract: We consider a formal (approximate) integral of motion in Hamiltonians of the form $H=\frac{1}{2}(X^2+Y^2+ω_1^2x^2+ω_2^2y^2)+ε(ηxy^2+αx^3+βx^2y+γy^3)$ generalizing previous cases with $β=γ=0$. First we give the general form of this integral when $ω_1/ω_2$ is irrational and then we consider the case of commensurable frequencies. In particular we study the integrals for the resonances $ω_1/ω_2=4/1, 5/1, 3/2, 4/3, 3/1$ and $2/1$. We also calculate the invariant curves and the orbits in the cases $ω_1/ω_2=2/1$ and $1/1$ (with $β=γ=0$) and we compare the exact-numerical and the theoretical results predicted by the formal integral when $βγ\neq0$. In the special case $ω_1/ω_2=1/1$ we find an integral when $β=γ=0$ and $ηα\neq0$ or $η=α=0$ and $βγ\neq 0$, but this is not possible when $ηαβγ\neq 0$. However, we find that the invariant curves and the orbits can be approximated by a non-resonant integral with $ω_1/ω_2=5\sqrt{2}/7=1.010\dots$.

</details>


### [109] [The phenomenon of resonance in the continuous phase transition of finite-size systems: A passage from Classical World to Quantum World through the resonance?](https://arxiv.org/abs/2601.15225)
*Yiannis F. Contoyiannis,Stelios M. Potirakis*

Main category: nlin.CD

TL;DR: 在有限尺寸系统的连续相变中，对称相到对称破缺相的转变通过滞后区域实现，该区域内存在共振现象，表现为平均等待时间在滞后区内随温度变化达到最大值。


<details>
  <summary>Details</summary>
Motivation: 研究连续相变中滞后区域内的共振现象，探索该共振与滞后区内粒子（快子）或准粒子（扭结孤子）存在的关系，并建立从"经典"相到"量子"相的连续过渡概念。

Method: 通过分析有限尺寸系统在连续相变中的滞后行为，研究平均等待时间在滞后区域内的温度依赖性，探讨共振现象与粒子/准粒子存在的关联。

Result: 发现滞后区域内存在共振现象，表现为平均等待时间在滞后区内随温度变化达到最大值，该共振可能标志着从经典相到量子相的连续过渡。

Conclusion: 连续相变中的滞后区域存在共振现象，该共振可能连接着经典相和量子相，为理解三维伊辛模型等二元系统的相变行为提供了新视角。

Abstract: In finite-size systems undergoing a continuous phase transition, the passage from the symmetric phase to the broken-symmetry phase is accomplished through a hysteresis zone, up to spontaneous symmetry breaking (SSB). In the present work, we find that a resonance phenomenon takes place within this zone. This resonance is manifested as a maximization of the mean waiting time as a function of temperature inside the hysteresis region. An interesting issue concerns how this resonance is connected with the existence of particles (tachyons) or quasiparticles (kink solitons) within the hysteresis zone. Finally, we introduce the idea that this resonance delineates a continuous passage from a "classical" phase to a "quantum" phase for a binary system, such as the three-dimensional Ising model, which belongs to the same universality class as a fermion-antifermion system or, more generally, a matter-antimatter system.

</details>
