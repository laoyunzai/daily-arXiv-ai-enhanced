<div id=toc></div>

# Table of Contents

- [physics.data-an](#physics.data-an) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 12]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 5]
- [quant-ph](#quant-ph) [Total: 49]
- [cs.LG](#cs.LG) [Total: 34]
- [cs.AI](#cs.AI) [Total: 11]


<div id='physics.data-an'></div>

# physics.data-an [[Back]](#toc)

### [1] [Machine Learning](https://arxiv.org/abs/2512.11133)
*Javier M. Duarte,Uros Seljak,Kazu Terao*

Main category: physics.data-an

TL;DR: 本章概述了机器学习在粒子物理中的核心概念和应用，涵盖能量、强度、宇宙和加速器前沿


<details>
  <summary>Details</summary>
Motivation: 介绍机器学习在粒子物理领域的相关性和重要性，展示如何利用算法从数据中学习、识别模式并做出预测或决策

Method: 概述机器学习的基本概念，包括使用算法从数据中学习、识别模式、进行预测和决策，无需显式编程

Result: 提供了机器学习在粒子物理多个前沿领域的应用示例，包括能量前沿、强度前沿、宇宙前沿和加速器前沿

Conclusion: 机器学习为粒子物理研究提供了强大的工具，能够处理复杂数据并提取有价值的信息，在各个前沿领域都有重要应用

Abstract: This chapter gives an overview of the core concepts of machine learning (ML) -- the use of algorithms that learn from data, identify patterns, and make predictions or decisions without being explicitly programmed -- that are relevant to particle physics with some examples of applications to the energy, intensity, cosmic, and accelerator frontiers.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [2] [Site Preference and Possible Coexistence of Antiferromagnetic Order and Magnetic Frustration in (Co1-xMgx)10Ge3O16 (0 <= x <= 30%)](https://arxiv.org/abs/2512.11132)
*Gina Angelo,Qiang Zhang,Dylan Correll,Xin Gui*

Main category: cond-mat.str-el

TL;DR: 通过掺杂非磁性Mg²⁺到Co₁₀Ge₃O₁₆中，研究了该复杂磁性系统的磁结构，发现Mg²⁺优先占据Co1和Co3位点，抑制了高温磁结构相变和低温宽峰，并揭示了Co1位点负责长程反铁磁有序。


<details>
  <summary>Details</summary>
Motivation: 研究几何阻挫磁性系统Co₁₀Ge₃O₁₆的复杂磁性行为，该体系包含三个阻挫亚晶格（三角Co1、Kagome Co2和Co3亚晶格），通过非磁性Mg²⁺掺杂作为探针来揭示其磁结构和磁阻挫特性。

Method: 生长(Co₁₋ₓMgₓ)₁₀Ge₃O₁₆ (0 < x ≤ 30%)单晶，通过粉末X射线衍射、温度依赖磁化率测量、单晶X射线衍射、热容和中子粉末衍射等方法进行系统表征。

Result: Mg²⁺优先占据Co1和Co3位点；高温磁结构相变和低温宽峰被Mg²⁺掺杂抑制；高Mg²⁺掺杂水平下出现两个新的磁特征；反铁磁有序温度处不存在从R-3m到C2/m的结构相变；Co1位点负责长程反铁磁有序，其他两个位点呈现短程关联和Mg²⁺诱导的自旋玻璃态。

Conclusion: 非磁性Mg²⁺掺杂为研究Co₁₀Ge₃O₁₆的复杂磁性提供了重要见解，揭示了不同Co位点在磁有序中的作用，但要获得详细的磁结构仍需生长更大的单晶进行进一步研究。

Abstract: Geometrically frustrated magnetism has attracted tremendous attention while chemical doping has been utilized as an important tool to probe frustrated magnetism in various systems. Here we perform a systematic study by doping non-magnetic Mg2+ into a magnetically complicated system, Co10Ge3O16, which contains three frustrated sublattices of Co2+, e.g., triangular Co1, Kagome Co2 and Co3 sublattices. By growing crystals for (Co1-xMgx)10Ge3O16 (0 < x <= 30%), we observed obvious site preference of Mg2+ on Co1 and Co3 sites over the Co2 site. Powder X-ray diffraction (XRD) patterns confirm the high purity of the samples and indicate systematic peak shift, consistent with the loading compositions. Although previously investigated, the magnetic structure and expected magnetic frustration in this system are not fully uncovered. Our temperature-dependent magnetic susceptibility measurements suggest that the high-temperature magnetostructural phase transition with antiferromagnetic ordering and a low-temperature broad peak are suppressed with Mg2+ doping, while two new magnetic features emerge at high Mg2+ level. Moreover, the structural phase transition from high-temperature R-3m to low-temperature C2/m space group is absent at the antiferromagnetic ordering temperature, as confirmed by single-crystal XRD. By analyzing the heat capacity and neutron powder diffraction results of the highest doped sample, (Co0.7Mg0.3)10Ge3O16, we speculate that the Co1 site is responsible for the long-range antiferromagnetic ordering, while the other two sites are short-range correlated in addition to a Mg2+-induced spin-glass state. This study provides more insights into the complex magnetism in Co10Ge3O16 by using the non-magnetic Mg2+ as a probe. However, detailed magnetic structure requires further efforts on growing large single crystals.

</details>


### [3] [Multiloop functional renormalization group from single bosons](https://arxiv.org/abs/2512.11190)
*Kilian Fraboulet,Aiman Al-Eryani,Sarah Heinzelmann,Anna Kauch,Sabine Andergassen*

Main category: cond-mat.str-el

TL;DR: 该论文将多环函数重整化群与单玻色子交换分解相结合，应用于二维Hubbard模型弱耦合区域，验证了该方法的准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 函数重整化群是处理关联电子系统的有效工具，但传统单环截断精度有限。单玻色子交换分解提供了计算和解释优势，两者结合有望提高计算精度和效率。

Method: 采用多环SBE fRG方法，结合多环函数重整化群和单玻色子交换分解，应用于二维Hubbard模型的弱耦合区域，详细分析了物理通道中的形式体系。

Result: SBE近似（不显式计算多玻色子交换贡献）在环收敛时能准确再现parquet近似的结果，验证了该方法的准确性。

Conclusion: 多环SBE fRG方法为处理更复杂参数区域和更现实模型提供了有效的算法改进路径。

Abstract: The functional renormalization group (fRG) is an established tool in the treatment of correlated electron systems, notably for the description of competing instabilities. In recent years, methodological advancements led to the multiloop extension of the fRG, which systematically includes loop corrections beyond the conventional one-loop truncation and yields a quantitatively accurate description of two-dimensional lattice systems. At the same time, the single-boson exchange (SBE) decomposition of the two-particle vertex has been shown to offer both computational and interpretative advantages paving the way to more affordable approximation schemes. We here apply their combination coined as multiloop SBE fRG to the two-dimensional Hubbard model at weak coupling. After providing a detailed account of the underlying formalism in physical channels, we analyze the results for the frequency- and momentum-dependent vertex functions. We find that the SBE approximation, i.e., without calculating explicitly multi-boson exchange contributions, accurately reproduces the parquet approximation at loop convergence. The presented algorithmic improvement opens the route for the treatment of more challenging parameter regimes and more realistic models.

</details>


### [4] [Theory of Out-of-Time-Ordered Transport](https://arxiv.org/abs/2512.11198)
*Ruchira Mishra,Jiaozi Wang,Silvia Pappalardi,Luca V. Delacrétaz*

Main category: cond-mat.str-el

TL;DR: 构建了一个有效场论来描述具有守恒律的量子多体系统中时序关联函数在晚期的普适行为，该理论将传统的涨落流体动力学推广到时序关联函数，并解释了不同的幂律行为。


<details>
  <summary>Details</summary>
Motivation: 研究具有守恒律的量子多体系统中时序关联函数在晚期的普适行为，建立能够统一描述这些行为的理论框架，并探索时序关联函数与传统输运数据之间的关系。

Method: 构建了一个有效场论，该理论基于从强到弱的自发对称破缺模式的推广，适用于时序关联函数；当应用于时序关联函数时，该理论简化为传统的涨落流体动力学；在一维哈密顿量和Floquet自旋链中测试了理论预测。

Result: 该有效场论成功解释了时序关联函数在晚期观察到的不同幂律行为，表明许多时序关联函数完全由传统的输运数据决定；然而，发现特定的时序关联函数组合对传统时序关联函数中不可见的新型输运参数敏感。

Conclusion: 构建了一个统一的框架来描述具有守恒律的量子多体系统中时序关联函数的晚期行为，揭示了时序关联函数与传统输运数据之间的深刻联系，同时发现了时序关联函数能够探测传统方法无法观测的新型输运参数。

Abstract: We construct an effective field theory (EFT) that captures the universal behavior of out-of-time-order correlators (OTOCs) at late times in generic quantum many-body systems with conservation laws. The EFT hinges on a generalization of the strong-to-weak spontaneous symmetry breaking pattern adapted to out-of-time-order observables, and reduces to conventional fluctuating hydrodynamics when time-ordered observables are probed. We use the EFT to explain different power-law behavior observed in OTOCs at late times, and show that many OTOCs are entirely fixed by conventional transport data. Nevertheless, we show that a specific combination of OTOCs is sensitive to novel transport parameters, not visible in regular time-ordered correlators. We test our predictions in Hamiltonian and Floquet spin chains in one dimension.

</details>


### [5] [Symmetry-protected topological scar subspaces](https://arxiv.org/abs/2512.11216)
*Chihiro Matsui,Thomas Quella,Naoto Tsuji*

Main category: cond-mat.str-el

TL;DR: 该论文提出将对称性保护拓扑性质的概念从基态扩展到由量子多体疤痕态形成的动力学隔离子空间，引入了对称性保护拓扑疤痕子空间的概念，并在AKLT模型中验证了疤痕子空间可以继承基态的拓扑特性。


<details>
  <summary>Details</summary>
Motivation: 传统对称性保护拓扑性质主要研究基态，而量子多体疤痕态作为非热本征态形成的动力学隔离子空间，是否也能展现拓扑特性尚未被系统研究。作者希望将对称性保护拓扑的概念扩展到疤痕子空间，探索拓扑性质在非基态体系中的表现。

Method: 提出对称性保护拓扑疤痕子空间的概念，该子空间由受限谱生成代数稳定，并受到在位、反演和时间反演对称性保护。使用自旋1 AKLT模型作为具体实例，通过键空间对称性表示、拓扑响应和数值验证的长程弦序来证明其双磁子疤痕子空间反映了SPT基态的拓扑性质。

Result: 证明了疤痕子空间可以继承对称性保护拓扑基态的拓扑特性，在AKLT模型中观察到一致的拓扑性质在整个疤痕子空间中涌现。在非均匀情况下，疤痕子空间还能系统性地修改基态的拓扑特征。

Conclusion: 疤痕子空间可以作为超越基态体系研究对称性保护拓扑的新平台，为实验探测非基态拓扑性质提供了新的可访问途径，扩展了拓扑物理的研究范围。

Abstract: We propose a framework that extends the notion of symmetry-protected topological properties beyond the ground-state paradigm to dynamically isolated subspaces formed by exceptional non-thermal energy eigenstates of non-integrable systems, known as quantum many-body scars (QMBS). We introduce the concept of a symmetry-protected topological (SPT) scar subspace -- a Hilbert subspace stabilized by a restricted spectrum-generating algebra (rSGA) while being protected by on-site, inversion, and time-reversal symmetries. QMBS often admit a non-interacting quasiparticle description, which enables matrix-product representations with small bond dimension. Although individual QMBS do not necessarily retain the protecting symmetries of the Hamiltonian, we show that the subspace formed by the symmetry-connected QMBS does retain them, giving rise to consistently emerging topological properties across the entire scar subspace. Using the spin-$1$ Affleck--Kennedy--Lieb--Tasaki (AKLT) model, we demonstrate that its bimagnon scar subspace reflects the topological properties of the SPT ground state, as evidenced by the appropriate bond-space symmetry representations, the expected topological response, and the numerically verified long-range string order. Our findings indicate that scar subspaces can inherit -- and in inhomogeneous cases systematically modify -- the topological character of the SPT ground state, offering a new and experimentally accessible platform for probing symmetry-protected topology beyond the ground-state regime.

</details>


### [6] [Spectroscopic evidences for the spontaneous symmetry breaking at the $SO(5)$ deconfined critical point of $J$-$Q_3$ model](https://arxiv.org/abs/2512.11329)
*Shutao Liu,Yan Liu,Chengkang Zhou,Zhe Wang,Jie Lou,Changle Liu,Zheng Yan,Yan Chen*

Main category: cond-mat.str-el

TL;DR: 该研究通过量子蒙特卡洛模拟分析J-Q₃模型的自旋和键算符动力学谱，发现四个无能隙横向模式，结合纠缠熵结果，为解禁闭量子临界点具有自发破缺的SO(5)对称性提供了直接证据。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要依赖纠缠熵的有限尺寸标度分析，认为解禁闭量子临界点实际上是SO(5)对称性增强的一级相变，但缺乏物理可观测量直接证据。本研究旨在通过动力学谱分析提供更直接的证据。

Method: 使用大规模量子蒙特卡洛模拟，研究J-Q₃模型中自旋和键算符在解禁闭临界点的动力学谱，并与J₁-J₂海森堡模型中已确立的O(3)威尔逊-费米临界性进行对比分析。

Result: 在J-Q₃模型临界点两侧观察到四个无能隙横向模式，这与J₁-J₂模型中观察到的三个无能隙模式（反映O(3)对称性完全恢复）形成鲜明对比。这一谱特征与纠缠熵结果一致。

Conclusion: 动力学谱特征为解禁闭量子临界点具有自发破缺的SO(5)对称性提供了直接证据，支持该临界点实际上是SO(5)对称性增强的一级相变这一结论。

Abstract: Recent numerical and theoretical studies on the two-dimensional $J$-$Q_3$ model suggests that the deconfined quantum critical point is actually a $SO(5)$-symmetry-enhanced first-order phase transition that is spontaneously broken to $O(4)$. However, this conclusion has mainly relied on finite-size scaling of the entanglement entropy, lacking direct evidence from physical observables.} Here, we investigate the dynamical spectra of spin and bond operators at the deconfined critical point of the $J$-$Q_3$ model using large-scale quantum Monte Carlo simulations, and contrasting them with the well-established $\mathrm{O(3)}$ Wilson-Fisher criticality in the $J_1$-$J_2$ Heisenberg model. Although both models exhibit two gapless magnon modes in the Néel phase, their critical behaviors diverge strikingly. At the $J_1$-$J_2$ critical point, the Higgs mode becomes gapless, yielding three gapless modes that reflect the full restoration of the $\mathrm{O(3)}$ symmetry. {In the $J$-$Q_3$ model, we instead observe four gapless transverse modes at the either side of the transition. This spectral feature, together with the entanglement entropy results, provides direct evidence for the weakly first-order scenario that the deconfined quantum critical point exhibits an emergent $\mathrm{SO(5)}$ symmetry that spontaneously breaks to $\mathrm{O(4)}$.

</details>


### [7] [Magnetic-field induced momentum-dependent symmetry breaking in CsV$_3$Sb$_5$ revealed by magneto-ARPES](https://arxiv.org/abs/2512.11341)
*Jianwei Huang,Zheng Ren,Hengxin Tan,Jounghoon Hyun,Yichen Zhang,Thomas Hulse,Zhaoyu Liu,Jonathan M. DeStefano,Yaofeng Xie,Ziqin Yue,Junichiro Kono,Pengcheng Dai,Yu He,Aki Pulkkinen,Ján Minár,Jiun-Haw Chu,Ziqiang Wang,Binghai Yan,Rafael M. Fernandes,Ming Yi*

Main category: cond-mat.str-el

TL;DR: 该研究使用磁场可调角分辨光电子能谱技术，揭示了CsV₃Sb₅中电子结构对外磁场的动量选择性响应，阐明了电荷密度波序中时间反演对称性破缺的起源，并发现了与锑p轨道相关的场致旋转对称性破缺效应。


<details>
  <summary>Details</summary>
Motivation: 在CsV₃Sb₅等Kagome超导体中，实验观察到与电荷密度波序相关的旋转对称性破缺和时间反演对称性破缺，表明这种CDW序具有奇异性质。需要理解这些对称性破缺的微观起源及其与不同轨道贡献的关系。

Method: 使用磁场可调角分辨光电子能谱技术，在可调磁场下测量CsV₃Sb₅的电子结构，分析不同动量点和轨道成分对外磁场的响应。

Result: 发现电子结构对外磁场呈现动量选择性响应：钒d轨道相关的Van Hove奇点能带表现出选择性谱展宽，破坏C₆旋转对称性且对磁场呈奇性，在CDW转变温度以上消失；而锑p轨道主导的布里渊区中心电子口袋在磁场下伸长，该效应在T_CDW以上仍存在。

Conclusion: 时间反演对称性破缺起源于CDW序开始时钒VHS能带，而场致旋转对称性破缺主要与锑p轨道相关，反映了CDW序温度以上的涨落。磁ARPES为在动量空间解耦量子材料中的交织序提供了新的调控手段。

Abstract: In quantum materials with multiple degrees of freedom with similar energy scales, intertwined electronic orders with distinct broken symmetries often appear in a strongly coupled fashion. Recently, in a class of kagome superconductors represented by CsV$_3$Sb$_5$, experimental reports have suggested rotational symmetry breaking and time reversal symmetry breaking associated with a charge density wave (CDW) order, revealing an exotic nature of this CDW order. Here, utilizing our recently developed capability of performing angle-resolved photoemission spectroscopy in a tunable magnetic field (magneto-ARPES), we reveal momentum-selective response of the electronic structure of CsV$_3$Sb$_5$ to an external magnetic field. While the response in the electronic structure is clearly compatible with piezomagnetism, strong orbital-selectivity is observed. Specifically, bands associated with the vanadium $d$-orbitals contributing to the Van Hove singularities (VHS) near the Brillouin zone (BZ) boundary exhibit selective spectral broadening that breaks C$_6$ rotational symmetry and is odd in magnetic field, disappearing above the CDW transition. Meanwhile, the antimony $p$-orbital dominated electron pocket at the BZ center becomes elongated under an applied field -- an effect that persists above the $T_{\rm CDW}$. Our observations delineate the origin of the time-reversal symmetry breaking associated with the vanadium VHS-bands at the onset of the CDW order, while the field-induced rotational symmetry breaking largely associated with the antimony $p$ orbitals reflects fluctuations beyond the CDW ordering temperature. Our magneto-ARPES work demonstrates a novel tuning knob for disentangling intertwined orders in the momentum space for quantum materials.

</details>


### [8] [Stability and complexity of global iterative solvers for the Kadanoff-Baym equations](https://arxiv.org/abs/2512.11371)
*Jože Gašperlin,Denis Golež,Jason Kaye*

Main category: cond-mat.str-el

TL;DR: 本文研究了Kadanoff-Baym方程全局时间迭代求解器的计算复杂度和稳定性，比较了多种迭代方法在时间依赖动力学平均场理论中的应用表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索全局时间迭代求解器相对于传统时间步进方法的算法优势，特别是在结合双时间对象压缩表示的情况下，寻求更高效的计算方法。

Method: 研究方法包括多种全局时间迭代方法：固定点迭代的多个变体、无雅可比矩阵方法、以及使用自动微分的牛顿-克里洛夫方法。研究在时间依赖动力学平均场理论框架下，对斜坡驱动和周期驱动的Falicov-Kimball模型和Hubbard模型进行了分析。

Result: 研究发现：1）多种迭代方法在大传播时间下能稳定收敛，但标准前向固定点迭代不能；2）在固定时间步长下，达到给定精度所需的迭代次数大致与时间步数呈线性比例；3）这种缩放与残差误差中传播前沿的形成有关，其速度取决于具体方法。

Conclusion: 结论指出，要使全局求解器在竞争力上超越时间步进方法，必须解决几个关键挑战，包括收敛速度与时间步数的线性缩放关系以及残差误差传播前沿的控制问题。

Abstract: Although the Kadanoff-Baym equations are typically solved using time-stepping methods, iterative global-in-time solvers offer potential algorithmic advantages, particularly when combined with compressed representations of two-time objects. We examine the computational complexity and stability of several global-in-time iterative methods, including multiple variants of fixed point iteration, Jacobian-free methods, and a Newton-Krylov method using automatic differentiation. We consider the ramped and periodically-driven Falicov-Kimball and Hubbard models within time-dependent dynamical mean-field theory. Although we observe that several iterative methods yield stable convergence at large propagation times, a standard forward fixed point iteration does not. We find that the number of iterations required to converge to a given accuracy with a fixed time step size scales roughly linearly with the number of time steps. This scaling is associated with the formation of a propagating front in the residual error, whose velocity is method-dependent. We identify key challenges which must be addressed in order to make global solvers competitive with time-stepping methods.

</details>


### [9] [Chirality-induced spin-selective Peierls transition](https://arxiv.org/abs/2512.11417)
*Shun Asano,Youichi Yanase*

Main category: cond-mat.str-el

TL;DR: 该论文预测了具有螺旋对称性的手性晶体中独特的自发结构相变，揭示了电子-声子耦合如何导致手性依赖的声子频率重整化，进而诱导螺旋自旋密度波和手性晶格畸变。


<details>
  <summary>Details</summary>
Motivation: 尽管手性材料在凝聚态物理中已有广泛研究，但电子和声子动力学、自组织手性结构及其相互作用的整合理解仍然缺乏。这种整合框架对于阐明手性结构的自发形成和稳定机制，以及推进手性材料的电子功能至关重要。

Method: 通过理论预测和分析手性晶体中的自发结构相变，研究准一维手性晶体中电子-声子耦合对声子频率的重整化效应，该效应依赖于圆偏振的手性。分析软模编码的本征声子角动量如何诱导电子能带中的自旋选择性Peierls能隙。

Result: 预测了手性晶体中独特的自发结构相变，发现电子-声子耦合重整化的声子频率依赖于圆偏振的手性。软模诱导了电子能带中的自旋选择性Peierls能隙，导致螺旋自旋密度波和手性晶格畸变。同时阐明了集体模式的手性特征。

Conclusion: 研究结果为先进自旋电子学应用提供了新途径，并为理解自然界中手性形成过程的难以捉摸的机制提供了关键见解。揭示了手性晶体中电子-声子耦合与结构手性之间的深刻联系。

Abstract: Chirality, referring to the absence of mirror and inversion symmetries, is a ubiquitous concept in nature. In condensed matter physics, vigorous research has clarified how chiral materials harbour unconventional electronic and vibrational responses. In parallel, recent studies have demonstrated that chiral structures can be engineered or tuned from achiral precursors. Despite these complementary advances, an integrated understanding of electronic and phononic dynamics, self-organized chiral structures, and their interplay is still lacking. Such an integrated framework is crucial both for elucidating the spontaneous formation and stabilization of chiral structures and for advancing the electronic functionalities of chiral materials. Here, we predict novel spontaneous structural phase transitions unique to chiral crystals with screw symmetry. In quasi-one-dimensional chiral crystals, the phonon frequency renormalized by the electron-phonon coupling depends on the handedness of circular polarization. Consequently, the soft mode encoding the intrinsic phonon angular momentum induces spin-selective Peierls gaps in the electronic band, entailing a helical spin density wave and chiral lattice distortion. We also elucidate the chiral signature of collective modes. Our findings offer new avenues for advanced spintronics applications and crucial insights into the elusive mechanisms underlying the formation process of chirality in nature.

</details>


### [10] [$S = 1$ pyrochlore magnets with competing anisotropies: A tale of two Coulomb phases, $Z_2$ flux confinement and $XY$-like transitions](https://arxiv.org/abs/2512.11623)
*Jay Pandey,Kedar Damle*

Main category: cond-mat.str-el

TL;DR: S=1 烧绿石磁体在易轴交换耦合J与易平面单离子各向异性Δ竞争下，在低温极限下出现三个相：短程关联顺磁相和两个拓扑不同的库仑液体相，通过Z2通量禁闭相变分离。


<details>
  <summary>Details</summary>
Motivation: 研究S=1烧绿石磁体中易轴交换耦合J与易平面单离子各向异性Δ之间的竞争如何产生新的物理现象，特别是在低温极限下的相行为。

Method: 通过理论分析S=1烧绿石磁体的哈密顿量，考虑易轴交换耦合J和易平面单离子各向异性Δ=J+μ（|μ|≪J）的竞争，研究T/J→0极限下的低温相行为。

Result: 发现三个低温相：短程关联顺磁相和两个拓扑不同的库仑液体相。两个库仑液体相由无散极化场描述，具有特征性的收缩点奇异性。其中一个库仑相中极化场通量被限制为偶数，另一个则允许所有整数值。预测了μ<0时从通量去禁闭库仑相到通量禁闭库仑相的转变，以及μ>0时从通量去禁闭库仑液体到短程关联顺磁相的XY类连续转变。

Conclusion: S=1烧绿石磁体中J与Δ的竞争导致丰富的低温相行为，包括拓扑不同的库仑液体相和相变，为实验观测提供了明确的预测信号。

Abstract: We argue that the low-temperature physics of $S=1$ pyrochlore magnets with a predominantly Ising-like easy-axis exchange coupling $J$ that favors the local tetrahedral body diagonals, and a comparably large easy-plane single-ion anisotropy $Δ=J + μ$ ($|μ| \ll J$) that favors the plane perpendicular to these local axes will exhibit interesting new phenomena due to the competition between $J$ and $Δ$. In the $T/J \rightarrow 0$ limit, we find three low temperature phases as a function of $μ/T$: a short-range correlated paramagnetic phase, and two topologically-distinct Coulomb liquids separated by a $Z_2$ flux confinement transition. Both Coulomb liquids are described at long-wavelengths by a fluctuating divergence-free polarization field and have characteristic pinch-point singularities in their structure factor. In one Coulomb phase, the flux of this polarization field is confined to {\em even} integers, while it takes on all integer values in the other Coulomb phase. Experimental realizations with $|μ| \ll J$ and negative are predicted to exhibit signatures of a transition from a flux-deconfined Coulomb phase to the flux-confined Coulomb phase as they are cooled below $T_{c_2} \approx 1.57|μ|$, while realizations with positive $μ\ll J$ will show signatures of a transition from a flux-deconfined Coulomb liquid to a short-range correlated paramagnet via a continuous $XY$-like transition at $T_{c_1} \approx 0.98 μ$.

</details>


### [11] [Interplay between antiferromagnetic spin fluctuation and electron-phonon coupling and the origin of the peak-dip-hump structure in the anti-nodal spectrum of high-$T_{c}$ cuprate superconductors](https://arxiv.org/abs/2512.11579)
*Xinyue Liu,Tao Li*

Main category: cond-mat.str-el

TL;DR: 该研究探讨了铜氧化物超导体中反铁磁自旋涨落与电子-声子耦合的相互作用，特别是对反节点区域峰-谷-驼峰结构的影响。


<details>
  <summary>Details</summary>
Motivation: 传统认为B1g弯曲声子模式是铜氧化物超导体中反节点谱峰-谷-驼峰结构的主要原因，但近期实验观测到反节点区域的平坦准粒子色散和赝隙终点附近PDH结构的突然抑制，对这一解释提出了质疑。需要研究反铁磁自旋涨落与电子-声子耦合的相互作用来解释这些现象。

Method: 通过系统研究反铁磁自旋涨落与电子-声子耦合的相互作用，分析顶点修正对B1g弯曲声子模式耦合强度的影响，以及这种修正对PDH结构的增强效应。比较仅由自旋涨落或仅由声子耦合产生PDH结构的情况。

Result: 反铁磁自旋涨落引起的顶点修正强烈抑制了B1g弯曲声子模式在q→0极限下的耦合强度，这是由反铁磁波矢处电子-声子耦合的破坏性干涉导致的。然而，同样的顶点修正却增强了声子对PDH结构的贡献。虽然自旋涨落和声子耦合都能产生相似的PDH结构，但赝隙终点附近该结构的突然抑制主要归因于自旋涨落性质的剧烈变化。

Conclusion: 反节点谱中的PDH结构应被视为赝隙相中涨落局域矩出现的谱学特征，标志着进入了掺杂的莫特绝缘态。赝隙终点附近PDH结构的突然抑制反映了自旋涨落性质的临界变化。

Abstract: Electron-phonon coupling is believed to be responsible for many spectral anomalies in the cuprate superconductors. In particular, the $B_{1g}$ buckling mode of the oxygen ion in the $CuO_{2}$ plane has been proposed to be responsible for the dramatic peak-dip-hump(PDH) structure in the anti-nodal spectrum. The recent observation of the exceptional flat quasiparticle dispersion in the anti-nodal region and the sudden suppression of the PDH structure around the pseudogap end point cast doubts on such a scenario. Instead, a scenario involving the coupling to the antiferromagnetic spin fluctuation seems to resolve both puzzles naturally. Here we present a systematic study on the interplay between antiferromagnetic spin fluctuation and electron-phonon coupling in the cuprate superconductors. We show that the coupling strength to the $B_{1g}$ buckling mode is strongly suppressed by the vertex correction caused by the antiferromagnetic spin fluctuation in the $\mathbf{q}\rightarrow 0$ limit as a result of the destructive interference between electron-phonon coupling at electron momentum differ by the antiferromagnetic wave vector. Counterintuitively, we find that the same vertex correction enhances the phonon contribution to the PDH structure. We also find that while the coupling to either the antiferromagnetic spin fluctuation or the $B_{1g}$ buckling mode can generate a PDH structure in the anti-nodal spectrum with similar phenomenologies, the sudden suppression of such a structure around the pseudogap end point should be mainly attributed to the dramatic change in the nature of the spin fluctuation at such a critical doping. We suggest to take the PDH structure in the anti-nodal spectrum as a spectral signature for the emergence of fluctuating local moment in the pseudogap phase and the entrance of a doped Mott insulating state.

</details>


### [12] [Physical properties of new delafossite triangular-lattice compounds TlErSe$_2$ and TlTmSe$_2$](https://arxiv.org/abs/2512.11627)
*Bastian Rubrecht,Ellen Häußler,Mirtha Pillaca,Pritam Bhattacharyya,Liviu Hozoi,Artem Nosenko,Dmitri V. Efremov,Bernd Büchner,Anja U. B. Wolter,Thomas Doert*

Main category: cond-mat.str-el

TL;DR: 该研究报道了两种三角晶格反铁磁体TlErSe₂和TlTmSe₂的结构、磁性和热力学性质，发现TlErSe₂在0.42K以下出现长程磁有序，而TlTmSe₂未观察到长程磁有序，并通过量子化学计算解释了二者磁行为的显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究三角晶格反铁磁体中的稀土离子化合物，探索其作为量子自旋液体等奇异量子态候选材料的潜力，特别是理解不同稀土离子对磁行为的影响。

Method: 采用粉末X射线衍射分析相纯度，测量磁化率确定有效磁矩，通过³He比热测量探测磁有序转变温度，结合从头算量子化学计算解释磁行为差异。

Result: TlErSe₂和TlTmSe₂均结晶于三角晶系α-NaFeO₂结构，TlErSe₂在0.42K以下出现长程磁有序，而TlTmSe₂未观察到长程磁有序，二者的有效磁矩分别为9.6μB/f.u.和7.5μB/f.u.。

Conclusion: TlErSe₂和TlTmSe₂作为三角晶格反铁磁体表现出不同的磁行为，TlErSe₂在极低温下出现长程磁有序，而TlTmSe₂可能保持无序状态，这种差异源于稀土离子的不同量子特性，为研究量子磁性提供了新平台。

Abstract: Delafossite compounds containing rare-earth ions have been proven to be an ideal platform to investigate frustrated magnetic ground states. Here, we discuss two triangular-lattice antiferromagnets, TlErSe$_2$ and TlTmSe$_2$, as potential candidates for hosting exotic quantum states. Powder X-ray diffraction data analysis of the black-color polycrystalline Tl$RE$Se$_2$ ($RE$: Er and Tm) samples confirms the phase purity. Both materials crystallize in the trigonal $α$-NaFeO$_2$ structure ($R\overline{3}m$) with lattice parameters $a$ = 4.1070(4) Å and $c$ = 23.1472(1) Å for the erbium compound and $a$ = 4.0916(1) Å and $c$ = 23.1483(2) Å for the thulium compound. Magnetic susceptibility measurements show an effective moment of $μ_{\text{eff}} = 9.6(2) μ_B$/f.u. ($7.5(1) μ_B$/f.u.) for TlErSe$_2$ (TlTmSe$_2$) for temperatures above 200 K. While $^3$He specific-heat measurements reveal long-range magnetic order below $T_N = 0.42 $K for TlErSe$_2$, no sign of long-range magnetic order was observed for TlTmSe$_2$. Based on our results, we map out the T-H phase diagram for polycrystalline TlErSe$_2$ and discuss the striking difference in the magnetic behavior of TlTmSe$_2$ based on our ab initio quantum chemical calculations.

</details>


### [13] [Curvilinear magnonic crystal based on 3D hierarchical nanotemplates](https://arxiv.org/abs/2512.11663)
*Gianluca Gubbiotti,Olha Bezsmertna,Oleksandr V. Pylypovskyi,Rui Xu,Stephane Chiroli,Fatih Zighem,Claudia Fernandez Gonzalez,Andrea Sorrentino,David Raftrey,Daniel Wolf,Axel Lubk,Peter Fischer,Damien Faurie,Denys Makarov*

Main category: cond-mat.str-el

TL;DR: 该研究开发了一种基于截断纳米尖峰的曲面磁振子晶体，通过几何曲率和光学探测不对称性实现了磁振子能带的方向依赖性调控。


<details>
  <summary>Details</summary>
Motivation: 曲面磁性纳米结构能够通过几何诱导的各向异性和手性相互作用以及磁场调制来控制磁化动力学。本研究旨在探索基于三维分层模板的曲面磁振子晶体，为曲率工程磁振子学提供新平台。

Method: 采用保形涂覆技术在三维分层模板上沉积坡莫合金薄膜，制备大面积截断纳米尖峰方形阵列。使用布里渊光散射光谱分析磁振子能带结构，并通过有限元微磁模拟研究曲率诱导的去磁化场变化对磁振子响应的影响。

Result: 布里渊光散射揭示了各向异性的能带结构，包含多个色散和折叠的布洛赫型色散自旋波模式以及非色散模式，这些模式沿晶格主轴表现出方向依赖的频率偏移和强度不对称性。模拟表明曲率诱导的去磁化场变化主导磁振子响应，识别出在纳米通道中传播的模式以及在纳米尖峰顶端或相邻尖峰脊线上局域化的模式。

Conclusion: 几何曲率和光学探测不对称性的结合产生了磁振子能带的方向依赖性，确立了三维分层模板作为曲率工程磁振子学的多功能平台。

Abstract: Curvilinear magnetic nanostructures enable control of magnetization dynamics through geometry-induced anisotropy and chiral interactions as well as magnetic field modulation. In this work, we report a curvilinear magnonic crystal based on large-area square arrays of truncated nanospikes fabricated by conformal coating of 3D hierarchical templates with permalloy thin films. Brillouin light scattering spectroscopy reveals anisotropic band structure with multiple dispersive and folded Bloch-type dispersive spin-wave modes as well as non-dispersive modes exhibiting direction-dependent frequency shifts and intensity asymmetries along lattice principal axes. Finite element micromagnetic simulations indicate that curvature-induced variations of the demagnetizing field govern the magnonic response, enabling the identification of modes propagating in nanochannels and other localized on nanospike apexes or along the ridges connecting adjacent nanospikes. The combination of geometric curvature and optical probing asymmetry produces directional dependence of magnonic bands, establishing 3D hierarchical templates as a versatile platform for curvature-engineered magnonics.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [14] [Space-time correlations in the 1D Directed Stochastic Sandpile model](https://arxiv.org/abs/2512.11100)
*Valentin Lallemant*

Main category: cond-mat.stat-mech

TL;DR: 本文针对一维定向随机沙堆模型，推导了粒子填充和雪崩两点关联函数的递推关系，揭示了密度关联为正相关而雪崩为反相关的现象，表明系统在静态和动态可观测量之间存在权衡平衡。


<details>
  <summary>Details</summary>
Motivation: 沙堆模型难以获得精确结果，特别是雪崩的时空关联计算存在困难，主要障碍在于需要系统性地考虑记忆效应。本文旨在填补这一空白。

Method: 针对一维定向随机沙堆模型，推导了粒子填充和雪崩两点关联函数的递推关系表达式，并分析了关联的正负性。

Result: 密度关联显示为正相关，这与局部粒子填充的持续性直接相关；而雪崩则显示为反相关，这是因为雪崩会破坏系统，需要注入足够多的粒子才能完全补偿这种破坏。

Conclusion: 这些结果表明系统在静态和动态可观测量之间存在权衡平衡，这种平衡由雪崩过程中粒子数的守恒控制，系统通过这种平衡达到其稳态。

Abstract: Sandpile models are known to resist exact results. In this direction, space-time correlations between avalanches have proven to be especially difficult to access. One of the main obstacle to do so comes from taking memory effects in a systematic way along the computation. In this paper, we partially fill this gap and derive recursive relations for the particle filling and avalanche 2-points correlation function in the 1D Directed Stochastic Sandpile. These expressions allow to characterize the sign of the correlations and estimates are provided in the particle filling case. In fact, density correlations are shown to be positively correlated. This behavior is directly related to persistence of the local particle filling. On the other hand, we show that avalanches are anticorrelated in the model. This is interpreted by the fact that avalanches disrupt the system and the damage can only be fully compensated after injecting a sufficiently high number of particles. These results indicate an underlying trade off, between static and dynamic observable, for the system to sit in its stationary state. It appears that this balance is controlled by the conservation of the particle number along the avalanches.

</details>


### [15] [Emergence of Nonequilibrium Latent Cycles in Unsupervised Generative Modeling](https://arxiv.org/abs/2512.11415)
*Marco Baiesi,Alberto Rosso*

Main category: cond-mat.stat-mech

TL;DR: 该论文提出一种非平衡动力学驱动的无监督学习模型，通过打破详细平衡条件，在隐变量空间中自发形成概率循环流，从而提升生成性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于平衡统计物理的隐变量模型（如受限玻尔兹曼机）存在性能限制，作者探索非平衡动力学在机器学习中的建设性作用，研究如何通过引入不可逆性来增强生成模型的表现。

Method: 提出一个可见变量和隐变量通过两个独立参数化转移矩阵相互作用的马尔可夫链模型。该模型的稳态本质上是非平衡的，通过似然最大化驱动系统达到具有有限熵产生的非平衡稳态，在隐空间中形成持续的概率流循环。

Result: 训练过程中自发出现隐状态循环，这些循环不是由架构强加的而是从训练中产生的。模型避免了与近乎可逆动力学相关的低对数似然区域，能更准确地再现数据类别的经验分布。相比平衡方法，该模型打破了前向和后向条件转移之间的详细平衡。

Conclusion: 非平衡统计物理与现代机器学习的交叉研究表明，在隐变量模型中引入不可逆性可以增强生成性能，为机器学习模型设计提供了新的物理视角。

Abstract: We show that nonequilibrium dynamics can play a constructive role in unsupervised machine learning by inducing the spontaneous emergence of latent-state cycles. We introduce a model in which visible and hidden variables interact through two independently parametrized transition matrices, defining a Markov chain whose steady state is intrinsically out of equilibrium. Likelihood maximization drives this system toward nonequilibrium steady states with finite entropy production, reduced self-transition probabilities, and persistent probability currents in the latent space. These cycles are not imposed by the architecture but arise from training, and models that develop them avoid the low-log-likelihood regime associated with nearly reversible dynamics while more faithfully reproducing the empirical distribution of data classes. Compared with equilibrium approaches such as restricted Boltzmann machines, our model breaks the detailed balance between the forward and backward conditional transitions and relies on a log-likelihood gradient that depends explicitly on the last two steps of the Markov chain. Hence, this exploration of the interface between nonequilibrium statistical physics and modern machine learning suggests that introducing irreversibility into latent-variable models can enhance generative performance.

</details>


### [16] [A review on combinatorial approach to aggregation](https://arxiv.org/abs/2512.11459)
*Michał Łepek,Agata Fronczak,Piotr Fronczak*

Main category: cond-mat.stat-mech

TL;DR: 本文综述了离散、有限、不可逆聚集系统的组合方法，介绍了其理论基础、计算方法、多种核函数的应用，并与数值结果进行了比较。


<details>
  <summary>Details</summary>
Motivation: 回顾和发展离散有限不可逆聚集系统的组合方法，提供一种基于系统状态直接计数的替代方法，以克服传统Smoluchowski和Marcus-Lushnikov方法的局限性。

Method: 基于系统状态的直接组合计数方法，首先通过常数核的简单示例展示如何获得给定大小簇的平均数量和标准差，然后扩展到加性核、乘积核、线性链核、凝聚核等，并通过递归表达式处理任意核函数。

Result: 该方法成功应用于气溶胶生长和星子形成等实际过程，与数值结果进行了比较验证，并指出了在尘埃聚集和聚合物生长等领域的潜在应用，同时总结了理论预测精度变化的问题。

Conclusion: 组合方法为离散有限不可逆聚集系统提供了有效的分析框架，能够处理多种核函数并应用于实际物理过程，但仍存在一些开放问题需要进一步研究。

Abstract: Recently, a combinatorial approach to discrete, finite, and irreversibly aggregating systems has been progressively developed. In this work, we review its achievements up to the present moment, focusing on the practical aspects and discussing its limitations. First, we present the assumptions and combinatorial foundations of the approach, which are based on direct counting of the system states, in contrast to the previous approaches of Smoluchowski and Marcus--Lushnikov. A method to obtain combinatorial expressions for the average number of clusters of a given size and the corresponding standard deviation is described by solving the simplest example of a constant kernel. Then, we extend consideration to a number of kernels (e.g., additive, product, linear--chain, condensation), which were recently solved by explicitly finding the number of internal states of the cluster of a given size. Next, we show that theoretical predictions for any given kernel may be obtained with no need to find an explicit solution but using a recursive expression. We exploit this opportunity to present the use of combinatorial expressions to solve kernels related to the real processes of aerosol growth and planetesimal formation. At this point, a comparison to numerical results appears. Other potential application fields are indicated, including dust agglomeration and polymer growth. Finally, issues related to the varying precision of the theoretical predictions are summarized. In the last section, we propose open problems.

</details>


### [17] [Exact fluctuation relation for open systems beyond the Zwanzig FEP equation](https://arxiv.org/abs/2512.11570)
*Mohammad Rahbar,Christopher J. Stein*

Main category: cond-mat.stat-mech

TL;DR: 开发了一个涨落框架，用于量化任意动力学和系统-环境耦合下，通过非平衡过程连接的两个平衡态之间的自由能差。基于平均力哈密顿量，建立了自由能差与系统边际分布χ²散度之间的显式关系，并推导出轨迹层面的表示。


<details>
  <summary>Details</summary>
Motivation: 传统Zwanzig自由能微扰方法在系统-环境耦合较强时，由于相空间重叠差和数值收敛慢而效果不佳。需要开发一个更通用的框架来处理任意动力学和耦合协议下的自由能计算问题。

Method: 基于平均力哈密顿量建立涨落框架，将平衡自由能差表示为平均力哈密顿量变化的指数平均，除以初始和最终系统边际分布的χ²散度因子。推导出轨迹层面的表示，并将平均力哈密顿量增量分解为与λ(t)和C(t)变化相关的工作类贡献、与环境交换的热类贡献，以及相对于初始协议的反馈类泛函。

Result: 在过阻尼朗之万动力学下，传统Zwanzig FEP方法在强耦合时表现不佳，而本文提出的轨迹等式在广泛的耦合强度范围内都能准确匹配精确的自由能差。在冻结驱动机制下，等式简化为包含环境泛函和显式重叠校正的新FEP类表达式，Zwanzig公式成为其极限情况。

Conclusion: 该框架为任意动力学和系统-环境耦合下的自由能计算提供了通用方法，克服了传统FEP方法在强耦合时的局限性，在广泛的耦合强度范围内都能准确计算自由能差。

Abstract: We develop a fluctuation framework to quantify the free energy difference between two equilibrium states connected by nonequilibrium processes under arbitrary dynamics and system-environment coupling. For an open system described by the Hamiltonian of mean force (HMF), we show that the equilibrium free energy difference between two canonical endpoints can be written as exponential averages of the HMF shift, divided by an explicit factor built from the chi-squared divergence between the initial and final system marginals. These relations hold at the endpoint level and, under an asymptotic equilibration postulate, admit trajectory representations for general driving and coupling protocols. A decomposition of the HMF increment along each trajectory separates the work-like contributions associated with changes in $λ(t)$ and $C(t)$, the heat-like exchange with the environment, and a feedback-like functional defined with respect to the initial protocol. In the frozen-driving regime with a noninteracting reference, the equalities reduce to new FEP-like expressions involving an environment functional and an explicit overlap correction, with the Zwanzig formula recovered as a limiting case. We validate the approach on an open system coupled to an environment and evolved under overdamped Langevin dynamics, where conventional Zwanzig FEP suffers from poor phase-space overlap and slow numerical convergence, while the present trajectory equality closely matches the exact free energy difference over a broad range of coupling strengths.

</details>


### [18] [A Single-granule Stirling Heat Engine](https://arxiv.org/abs/2512.11591)
*Niloyendu Roy,Pragya Arora,A K Sood,Rajesh Ganapathy*

Main category: cond-mat.stat-mech

TL;DR: 研究人员构建了一个毫米级颗粒的非热斯特林发动机，通过嵌入振动器注入噪声，实现了布朗运动般的动力学，定量再现了有限时间热力学的功率-效率权衡关系。


<details>
  <summary>Details</summary>
Motivation: 将单粒子热机的普遍热力学界限从原子和胶体尺度扩展到宏观尺度，建立可访问的实验平台来研究非热系统中的小系统热力学。

Method: 构建非热斯特林发动机，工作介质为毫米级振动流化颗粒，通过时变磁阱约束；在颗粒内嵌入振动器注入噪声，实现过阻尼的布朗运动动力学；独立控制颗粒的有效温度和空间约束。

Result: 发动机定量再现了有限时间热力学的功率-效率权衡关系，在最大功率时达到Curzon-Ahlborn效率；发现了控制参数依赖的阻尼机制，导致压缩冲程的耗散与膨胀冲程相当甚至更大。

Conclusion: 这项工作建立了一个可访问的实验平台，用于研究固有非热系统中的小系统热力学，揭示了宏观尺度下也能实现单粒子热机的普遍热力学行为。

Abstract: Single-particle heat engines at atomic and colloidal scales obey the universal thermodynamic bounds on work and efficiency. Here, we translate these principles to the macroscale by building an athermal Stirling engine whose working medium is a millimeter-sized, vibrofluidized granule confined in a time-dependent magnetic trap. By embedding a rattler within the granule to inject noise, we engineer overdamped, Brownian-like dynamics in an otherwise inertial particle. This design enables independent control over the granule's effective temperature and spatial confinement. Our engine quantitatively reproduces the universal power-efficiency trade-offs of finite-time thermodynamics, achieving the Curzon-Ahlborn efficiency at maximum power. Strikingly, we uncover a control parameter-dependent damping that leads to an unexpected dissipation mechanism - the losses in the compression stroke rival or even exceed those during expansion. Our work establishes an accessible experimental platform to study small-system thermodynamics in intrinsically athermal systems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [19] [Crystalline Spectral Form Factors](https://arxiv.org/abs/2512.11054)
*Dmitrii A. Trunin,David A. Huse*

Main category: quant-ph

TL;DR: 该研究探讨了具有极强本征值排斥作用的酉量子系统中谱形因子（SFF）的类晶体行为，通过低温度库仑气体模型推导了抑制SFF周期性振荡的德拜-沃勒因子，并利用扰动置换电路和Lax矩阵相关的随机矩阵系综重现了这种类晶体行为。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索具有极强本征值排斥作用的量子系统，这类系统展现出介于标准随机矩阵系综和置换电路之间的中间能级统计特性，为理解量子系统的谱形因子行为提供新视角。

Method: 采用三种方法：1）使用低温度库仑气体作为排斥本征值模型；2）利用扰动置换电路；3）采用与Lax矩阵相关的随机矩阵系综。通过这些方法推导德拜-沃勒因子并分析谱形因子的周期性振荡行为。

Result: 成功推导了抑制谱形因子周期性振荡的德拜-沃勒因子，估计了其在海森堡时间倍数处的奇点阶数，并通过不同方法重现了类晶体行为，验证了理论模型的可靠性。

Conclusion: 该研究为未来研究介于标准随机矩阵系综和置换电路之间的中间能级统计特性的量子系统奠定了基础，揭示了极强本征值排斥作用下谱形因子的类晶体行为特征。

Abstract: We investigate crystalline-like behavior of the spectral form factor (SFF) in unitary quantum systems with extremely strong eigenvalue repulsion. Using a low-temperature Coulomb gas as a model of repulsive eigenvalues, we derive the Debye-Waller factor suppressing periodic oscillations of the SFF and estimate the order of its singularities at multiples of the Heisenberg time. We also reproduce this crystalline-like behavior using perturbed permutation circuits and random matrix ensembles associated with Lax matrices. Our results lay a foundation for future studies of quantum systems that exhibit intermediate level statistics between standard random matrix ensembles and permutation circuits.

</details>


### [20] [Enhancing the Practical Reliability of Shor's Quantum Algorithm via Generalized Period Decomposition: Theory and Large-Scale Empirical Validation](https://arxiv.org/abs/2512.11004)
*Chih-Chen Liao,Chia-Hsin Liu,Yun-Cheng Tsai*

Main category: quant-ph

TL;DR: 提出了一种广义周期分解方法，显著提高了Shor量子因式分解算法的实际可靠性，通过利用任意周期除数来放宽严格条件，在百万级测试中实现了超过99.998%的成功率。


<details>
  <summary>Details</summary>
Motivation: 虽然Shor算法理论上能够在多项式时间内分解整数，但其实际性能严重依赖于量子相位估计获得的周期条件。传统方法对这些条件要求严格，限制了算法的实际应用可靠性。

Method: 提出广义周期分解方法，通过系统性地利用获得的周期的任意除数来放宽条件要求。该方法与现有量子计算框架无缝集成，不改变算法的多项式时间复杂度，同时最小化不必要的重复计算。

Result: 通过超过100万个测试案例（2到8位整数）的经典模拟验证，7位数成功率超过99.998%，8位数超过99.999%，显著超越了传统和改进的Shor算法变体。

Conclusion: 该方法在保持多项式时间复杂度的同时，显著提高了Shor算法的实际可靠性，特别适用于NISQ设备的量子密码分析，为量子算法研究和量子信息处理领域提供了理论和实践贡献。

Abstract: This work presents a generalized period decomposition approach, significantly improving the practical reliability of Shor's quantum factoring algorithm. Although Shor's algorithm theoretically enables polynomial-time integer factorization, its real-world performance heavily depends on stringent conditions related to the period obtained via quantum phase estimation. Our generalized decomposition method relaxes these conditions by systematically exploiting arbitrary divisors of the obtained period, effectively broadening the applicability of each quantum execution. Extensive classical simulations were performed to empirically validate our approach, involving over one million test cases across integers ranging from 2 to 8 digits. The proposed method achieved near-perfect success rates, exceeding 99.998% for 7-digit numbers and 99.999% for 8-digit numbers, significantly surpassing traditional and recently improved variants of Shor's algorithm. Crucially, this improvement is achieved without compromising the algorithm's polynomial-time complexity and integrates seamlessly with existing quantum computational frameworks. Moreover, our method enhances the efficiency of quantum resource usage by minimizing unnecessary repetitions, making it particularly relevant for quantum cryptanalysis with noisy intermediate-scale quantum (NISQ) devices. This study thus provides both theoretical advancements and substantial practical benefits, contributing meaningfully to the field of quantum algorithm research and the broader field of quantum information processing.

</details>


### [21] [Universal and non-universal facets of quantum critical phenomena unveiled along the Schmidt decomposition theorem](https://arxiv.org/abs/2512.11093)
*Samuel M. Soares,Lucas Squillante,Henrique S. Lima,Constantino Tsallis,Mariano de Souza*

Main category: quant-ph

TL;DR: 研究一维横场Ising模型中自旋大小S对量子Grüneisen参数Γ^{0K}_q在临界点的影响，发现S增大时Γ^{0K}_q增加但保持有限，揭示了希尔伯特空间维度增强效应。


<details>
  <summary>Details</summary>
Motivation: 探索量子临界点处自旋大小对量子Grüneisen参数的影响，理解希尔伯特空间维度在量子临界现象中的作用，以及非可加性q-熵的扩展性特征。

Method: 研究一维横场Ising模型，分析不同自旋大小S下的量子Grüneisen参数Γ^{0K}_q，应用Schmidt分解定理研究q-熵的扩展性，并基于对称性分析普适类。

Result: 发现四个主要结果：1) 自旋S增大时Γ^{0K}_q增加但保持有限；2) Schmidt分解定理仅在特定q值下恢复q-熵的扩展性；3) q-熵框架下的普适类仅取决于系统对称性；4) 提出实验方案探索有限尺寸效应与希尔伯特空间占据的关系。

Conclusion: 研究揭示了量子临界性在Γ^{0K}_q和S_q方面的普适和非普适特征，为理解量子临界现象中的希尔伯特空间维度效应提供了新视角。

Abstract: We investigate the influence of the spin magnitude $S$ on the quantum Grüneisen parameter $Γ^{0\text{K}}_q$ right at critical points (CPs) for the 1D Ising model under a transverse magnetic field. Our findings are fourfold: $\textit{i)}$ for higher $S$, $Γ^{0\text{K}}_q$ is increased, but remains finite, reflecting the enhancement of the Hilbert space dimensionality; $\textit{ii)}$ the Schmidt decomposition theorem recovers the extensivity of the nonadditive $q$-entropy $S_q$ only for a $\textit{special}$ value of the entropic index $q$; $\textit{iii)}$ the universality class in the frame of $S_q$ depends only on the symmetry of the system; $\textit{iv)}$ we propose an experimental setup to explore finite size effects in connection with the Hilbert space occupation at CPs. Our findings unveil both universal and non-universal aspects of quantum criticality in terms of $Γ^{0\text{K}}_q$ and $S_q$.

</details>


### [22] [Undecidability of the Unitary Hitting Time Problem: No Universal Time-Step Selector and an Operational No-Go for Finite-Time Decisions](https://arxiv.org/abs/2512.11006)
*Katsufumi Matsuura*

Main category: quant-ph

TL;DR: 论文证明了量子动力学中的幺正击中时间问题（UHTP）是不可判定的，即不存在通用算法能计算所有输入下的击中时间，这源于停机问题的归约。操作上，对于任何固定精度参数，不存在统一的有限资源协议能在有限观测时间和能耗下正确输出所有可计算描述的输入下的击中时间。


<details>
  <summary>Details</summary>
Motivation: 研究量子动力学中的幺正击中时间问题，旨在理解是否存在通用算法或协议能够计算量子系统从初始态演化到目标态所需的时间。这个问题与量子控制和计算理论密切相关，特别是当系统能够嵌入通用计算时。

Method: 通过从停机问题归约来证明UHTP的不可判定性。使用可逆计算嵌入幺正动力学、固定目标信标构造，以及通过分段常数哈密顿量进行连续时间提升。区分逻辑时间（方程内部）和物理/操作时间（准备、演化、测量时间）。

Result: 证明了幺正击中时间问题是不可判定的，不存在能够为所有输入输出击中时间的完全算法。操作上，对于任何固定精度参数，不存在统一的有限资源协议能在有限观测时间和能耗下正确输出所有可计算描述的输入下的击中时间。

Conclusion: 量子动力学中的幺正击中时间问题是不可判定的，这补充了先前关于谱隙和量子控制可达性等不可判定性结果。研究区分了逻辑时间和物理时间，并表明在这两种意义上都不存在通用的时间步选择方法。

Abstract: We study the Unitary Hitting Time Problem (UHTP) in quantum dynamics. Given computably described pure states |a>, |b> and a time-dependent unitary U(t), define the hitting time as the infimum of t > 0 such that the fidelity between U(t)|a> and |b> reaches a fixed threshold (with infinity if the threshold is never reached). We prove that there is no total algorithm that outputs this hitting time for all inputs; equivalently, the total UHTP is undecidable via a reduction from the halting problem. Operationally, we show a no-go theorem: for any fixed accuracy parameters, there is no universal finite-resource protocol that, for all computably described inputs, correctly outputs the hitting time while obeying uniform finite upper bounds on observation time and on dissipation/work. The proofs use reversible computation embedded into unitary dynamics, a fixed-target beacon construction, and a continuous-time lifting via piecewise-constant Hamiltonians. Our results target systems capable of embedding universal computation and complement prior undecidability results such as spectral-gap and quantum-control reachability. We distinguish logical time (inside the equations) from physical/operational time (of preparation, evolution, measurement), and show that universal time-step selection is impossible in both senses.

</details>


### [23] [Choi echo: dynamical irreversibility and local decoherence in quantum many-body chaos](https://arxiv.org/abs/2512.11030)
*Jose Alfredo de Leon,Miguel Gonzalez,Carlos Diaz-Mejia*

Main category: quant-ph

TL;DR: 该论文提出了Choi回波作为量子通道纯度的一种操作解释，用于量化开放量子动力学中的内在不可逆性，并分析局部退相干能否探测多体系统中的量子混沌。


<details>
  <summary>Details</summary>
Motivation: 量化开放量子动力学中的内在不可逆性对于理解多体系统中的退相干和信息损失至关重要。需要开发能够操作性地解释量子通道纯度的方法，并测试局部退相干是否能够探测多体系统中的量子混沌。

Method: 引入Choi回波作为量子通道纯度的一种操作解释，将其作为量子关联对局部信息擦除鲁棒性的量化指标。使用该框架分析子系统的约化动力学，并在典型自旋链模型中测试局部退相干能否探测量子混沌。

Result: Choi回波能够捕捉关键动力学特征，但在某些参数区域存在内在局限性，限制其在谱关联水平上分辨可积到混沌转变的能力。局部退相干可能在可积区域虚假地指示量子混沌，这源于严格局部探针无法区分有效相干传输与真正混洗动力学。

Conclusion: 局部退相干信号由动力学过程中探针与其环境之间生成的纠缠控制，而非由谱关联控制。这澄清了局部动力学诊断的实际适用范围，表明需要更精细的方法来区分真正的量子混沌与相干传输效应。

Abstract: Quantifying intrinsic irreversibility in open quantum dynamics is central to understanding decoherence and information loss in many-body systems. In this work, we introduce the Choi echo, which provides an operational interpretation of the purity of the Choi state, the state representation of a quantum channel, as a quantifier of the robustness of quantum correlations against local information erasure. We employ this framework to analyze the reduced dynamics of a subsystem and to test whether local decoherence probes quantum chaos in many-body systems. Across paradigmatic spin chain models, we show that while the Choi echo captures key dynamical features, it also exhibits intrinsic limitations that, in certain regions of parameter space, restrict its ability to resolve the integrable-to-chaos transition at the level of spectral correlations. In particular, we demonstrate that local decoherence can spuriously signal quantum chaos in integrable regimes, tracing them to the inability of a strictly local probe to distinguish efficient coherent transport from genuinely scrambling dynamics. Our results show that local decoherence signals are controlled by the entanglement generated between the probe and its environment during the dynamics, rather than by spectral correlations, clarifying the practical scope of local dynamical diagnostics.

</details>


### [24] [Information-Theoretic and Operational Measures of Quantum Contextuality](https://arxiv.org/abs/2512.11049)
*Ali Can Günhan,Mehmet Zafer Gedik*

Main category: quant-ph

TL;DR: 提出基于信息论的Kochen-Specker语境性量化框架，包含两种互补度量：状态无关的互信息能量和基于对易子期望值的操作度量，建立了与Robertson不确定关系的层次界限，并在KCBS场景中应用。


<details>
  <summary>Details</summary>
Motivation: 为Kochen-Specker语境性提供信息论量化框架，建立语境性的几何和操作度量，并将其与量子不确定关系联系起来。

Method: 引入两种互补度量：1）互信息能量（状态无关，基于Onicescu信息能量，捕捉语境内联合本征空间的几何重叠）；2）基于对易子期望值的操作度量（反映测量结果层面的语境行为）。建立与Robertson不确定关系的层次界限（谱界限、纯度修正界限、算子范数界限）。在spin-1系统的KCBS场景中应用，使用Majorana-stellar表示进行几何分析。

Result: 在spin-1 KCBS场景中获得了闭式表达式。Majorana-stellar表示提供了三维欧几里得式可视化：位于平面上的态在垂直方向上表现出最大不确定性；在所有KCBS语境中同时优化得到对称轴上的唯一态。实现最优不确定性和积的态表现出零操作语境性，而具有显著操作语境性的态满足非平凡的Robertson界限，这两种极端情况由不同的量子态实现。

Conclusion: 建立了Kochen-Specker语境性的信息论量化框架，揭示了语境性度量与量子不确定关系之间的深层联系，在spin-1系统中展示了语境性与不确定性之间的互补关系，为理解量子语境性提供了新的几何和操作视角。

Abstract: We propose an information -- theoretic framework for quantifying Kochen-Specker contextuality. Two complementary measures are introduced: the mutual information energy, a state-independent quantity inspired by Onicescu's information energy that captures the geometric overlap between joint eigenspaces within a context; and an operational measure based on commutator expectation values that reflects contextual behavior at the level of measurement outcomes. We establish a hierarchy of bounds connecting these measures to the Robertson uncertainty relation, including spectral, purity-corrected, and operator norm estimates. The framework is applied to the Klyachko-Can-Binicioğlu-Shumovsky (KCBS) scenario for spin-1 systems, where all quantities admit closed-form expressions. The Majorana-stellar representation furnishes a common geometric platform on which both the operational measure and the uncertainty products can be analyzed. For spin-1, this representation yields a three-dimensional Euclidean-like visualization of the Hilbert space in which, states lying on a plane exhibit maximum uncertainty for the observable along the perpendicular direction; simultaneous optimization across all KCBS contexts singles out a unique state on the symmetry axis. Notably, states achieving the optimal sum of uncertainty products exhibit vanishing operational contextuality, while states with substantial operational contextuality satisfy a nontrivial Robertson bound -- the two extremes are achieved by distinct quantum states.

</details>


### [25] [Deterministic Equations for Feedback Control of Open Quantum Systems III: Full counting statistics for jump-based feedback](https://arxiv.org/abs/2512.11078)
*Alberto J. B. Rosal,Guilherme Fiusa,Patrick P. Potts,Gabriel T. Landi*

Main category: quant-ph

TL;DR: 该研究提出了一种基于量子跃迁检测的通用反馈协议框架，通过存储最近检测到的跃迁通道信息来实现条件反馈，并建立了混合经典-量子空间中的Lindblad主方程描述方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一个通用的理论框架来描述基于量子跃迁检测的反馈协议，这些协议能够将测量获得的信息转化为对系统的控制，特别是在热力学系统中实现信息到功的转换。

Method: 提出基于量子跃迁检测的通用反馈协议，将最近检测到的跃迁通道存储在内存中，并基于此信息条件性地修改系统哈密顿量。建立了混合经典-量子空间中的Lindblad主方程描述方法，其中经典部分编码存储的测量记录，量子部分表示被监测系统。

Result: 该框架能够完全表征基于跃迁反馈协议系统的计数统计特性，包括平均电流、噪声、相关函数和功率谱等关键统计性质。应用于耦合两个热浴的三能级系统热机时，证明跃迁反馈可以将跃迁检测获得的信息转化为功。

Conclusion: 该研究提供了一个通用的分析框架，能够表征任何基于跃迁反馈协议的计数可观测量，为量子热力学和信息处理中的反馈控制提供了新的理论工具。

Abstract: In this work, we consider a general feedback protocol based on quantum-jump detections, where the last detected jump channel is stored in a memory and subsequently used to implement a feedback action, such as modifying the system Hamiltonian conditioned on the last jump. We show that the time evolution of this general protocol can be described by a Lindblad master equation defined in a hybrid classical-quantum space, where the classical part encodes the stored measurement record (memory) and the quantum part represents the monitored system. Moreover, we show that this new representation can be used to fully characterize the counting statistics of a system subject to a general jump-based feedback protocol. We apply the formalism to a three-level system coupled to two thermal baths operating as a thermal machine, and we show that jump-based feedback can be used to convert the information obtained from the jump detections into work. Our framework provides analytical tools that enable the characterization of key statistical properties of any counting observable under jump-based feedback, such as the average current, noise, correlation functions, and power spectrum.

</details>


### [26] [Digital Coherent-State QRNG Using System-Jitter Entropy via Random Permutation](https://arxiv.org/abs/2512.11107)
*Randy Kuang*

Main category: quant-ph

TL;DR: 提出完全数字化的框架，通过系统时序抖动和随机排列过程复制相干态量子随机数生成的统计行为，无需量子硬件


<details>
  <summary>Details</summary>
Motivation: 传统相干态量子随机数生成需要量子光子硬件，成本高且复杂。本文旨在通过纯计算过程实现相同的统计特性，降低实现门槛

Method: 利用硬件和操作系统的计算时序变化，通过随机排列过程生成泊松分布数字，准确复制光学相干态的光子统计特性。基于均匀收敛定理建立理论框架

Result: 实验验证显示优异性能：香农熵接近7.999998比特/字节，最小熵超过7.99比特/字节，在10^8字节规模上超越理论界限。无需经典密码学后处理

Conclusion: 相干态量子随机数生成功能可以通过纯经典计算过程完全实现，提供数学可证明的均匀性和实际密码学安全性，无需量子光子硬件

Abstract: We present a fully digital framework that replicates the statistical behavior of coherent-state quantum random number generation (QRNG) by harnessing system timing jitter through random permutation processes. Our approach transforms computational timing variations from hardware and operating system sources into permutation dynamics that generate Poisson-distributed numbers, accurately reproducing the photon statistics of optical coherent states. The theoretical foundation is established by the Uniform Convergence Theorem, which provides exponential convergence to uniformity under modular projection with rigorous error bounds. Extensive experimental validation across multiple parameter regimes and sample sizes up to $10^8$ bytes demonstrates exceptional performance: Shannon entropy approaching 7.999998 bits/byte and min-entropy exceeding 7.99 bits/byte, outperforming theoretical bounds at scale. The architecture inherently resists side-channel attacks through compound timing distributions and adaptive permutation behavior, while operating without classical cryptographic post-processing. Our results establish that coherent-state QRNG functionality can be entirely realized through classical computational processes, delivering mathematically provable uniformity and practical cryptographic security without quantum photonic hardware.

</details>


### [27] [Basis dependence of Neural Quantum States for the Transverse Field Ising Model](https://arxiv.org/abs/2512.11632)
*Ronald Santiago Cortes,Aravindh S. Shankar,Marcello Dalmonte,Roberto Verdel,Nils Niggemann*

Main category: quant-ph

TL;DR: 研究神经量子态（NQS）在不同计算基下的性能差异，发现基选择依赖性与多自旋算符的簇展开收敛性相关，为评估NQS适用性和选择最优基提供理论框架。


<details>
  <summary>Details</summary>
Motivation: 神经量子态（NQS）在量子多体问题中应用广泛，但目前对其局限性理解有限。本研究旨在探究NQS性能如何依赖于计算基的选择，特别是针对受限玻尔兹曼机架构。

Method: 采用横场伊辛模型的旋转哈密顿量族，分析基态简并性、振幅和相位的均匀性等性质，研究它们如何影响NQS性能。通过多自旋算符的簇或累积展开的收敛特性来建立物理性质与性能之间的直接联系。

Result: 发现NQS性能的基依赖性确实存在，并且与多自旋算符的簇展开收敛性密切相关。基态简并性和波函数振幅/相位的均匀性对NQS性能有显著影响。

Conclusion: 研究结果为评估NQS在新问题中的适用性提供了理论依据，并能够指导选择最优计算基进行数值计算。建立了物理性质与NQS性能之间的直接联系框架。

Abstract: Neural Quantum States (NQS) are powerful tools used to represent complex quantum many-body states in an increasingly wide range of applications. However, despite their popularity, at present only a rudimentary understanding of their limitations exists. In this work, we investigate the dependence of NQS on the choice of the computational basis, focusing on restricted Boltzmann machines. Considering a family of rotated Hamiltonians corresponding to the paradigmatic transverse-field Ising model, we discuss the properties of ground states responsible for the dependence of NQS performance, namely the presence of ground state degeneracies as well as the uniformity of amplitudes and phases, carefully examining their interplay. We identify that the basis-dependence of the performance is linked to the convergence properties of a cluster or cumulant expansion of multi-spin operators -- providing a framework to directly connect physical, basis-dependent properties, to performance itself. Our results provide insights that may be used to gauge the applicability of NQS to new problems and to identify the optimal basis for numerical computations.

</details>


### [28] [Solutions of Koopman-von Neumann equations, their superpositions, orthogonality and uncertainties](https://arxiv.org/abs/2512.11148)
*Mustafa Amin,Mark A. Walton*

Main category: quant-ph

TL;DR: 该论文探讨了Koopman-von Neumann（KvN）经典力学表述在希尔伯特空间中的扩展，通过规范自由度实现变量分离，构建正交本征态叠加，并发现与经典统计力学和不确定性关系的联系。


<details>
  <summary>Details</summary>
Motivation: KvN表述将经典力学引入希尔伯特空间，但许多量子力学中熟悉的技术仍然缺失。作者希望解决本征值问题、获得厄米算符的正交本征态、解释态的相干叠加等问题。

Method: 研究经典概率幅的一般KvN方程，利用其规范自由度实现变量分离。研究所得KvN解对希尔伯特空间方法的适用性，构建不同规范下刘维尔本征态的叠加，并从中找到正交集合。

Result: 发现一些可分离解描述了正则系综，其温度与分离常数相关。经典不确定性关系在KvN形式中自然出现，特别是动力学时间与刘维尔算符之间的关系，这涉及经典系统的统计描述。

Conclusion: KvN表述通过规范自由度扩展了经典力学在希尔伯特空间中的表述能力，建立了与统计力学的联系，并揭示了经典不确定性关系，为经典系统的量子化描述提供了新视角。

Abstract: The Koopman-von Neumann (KvN) formulation brings classical mechanics to Hilbert space, but many techniques familiar from quantum mechanics remain missing. One would hope to solve eigenvalue problems, obtain orthonormal eigenstates of Hermitian operators and ascribe meaning to a coherent superposition of states, among other things. Here we consider the general KvN equation for a classical probability amplitude and show that its so-called gauge freedom allows the separation of variables. The amenability to Hilbert-space methods of the resulting KvN solutions is investigated. We construct superpositions from differently-gauged Liouvillian eigenstates, and find an orthonormal set among them. We find that some separable solutions describe the canonical ensemble with temperature related to the separation constant. Classical uncertainty relations arise naturally in the KvN formalism. We discuss one between the dynamical time and the Liouvillian in terms of the statistical description of classical systems.

</details>


### [29] [Investigating Different Barren Plateaus Mitigation Strategies in Variational Quantum Eigensolver](https://arxiv.org/abs/2512.11171)
*Mostafa Atallah,Nouhaila Innan,Muhammad Kashif,Muhammad Shafique*

Main category: quant-ph

TL;DR: 该研究系统比较了四种缓解VQE算法中贫瘠高原问题的方法，发现梯度保持效果与迭代次数相关，最佳缓解策略需根据系统规模和计算预算选择，而非仅依赖梯度方差作为性能指标。


<details>
  <summary>Details</summary>
Motivation: VQE算法面临贫瘠高原问题（梯度随系统规模和电路深度消失），现有缓解策略与收敛性能在不同迭代预算下的关系不明确，缺乏对最佳缓解技术在不同场景下性能的系统分析。

Method: 在4到14量子比特的分子系统上，对四种方法（Local-Global、Adiabatic、State Efficient Ansatz (SEA)和Pretrained VQE）与标准VQE进行基准测试，分析梯度方差（最多50层）和收敛性能（最多1000次迭代）。

Result: 梯度保持效果具有迭代依赖性：在14量子比特BeH2系统中，Pretrained VQE在100次迭代时优于SEA（尽管梯度方差较低），但SEA在1000次迭代时精度提高2.2倍。对于较小系统，SEA实现接近精确能量（H2: 10^-5 Ha, LiH: 2x10^-4 Ha），保真度达0.999，而标准方法早期即停滞。

Conclusion: 有效的贫瘠高原缓解策略需要根据系统规模和可用计算预算进行选择，不能仅将梯度方差作为性能的唯一预测指标。最佳策略取决于具体应用场景和计算资源约束。

Abstract: Variational Quantum Eigensolver (VQE) algorithms suffer from barren plateaus, where gradients vanish with system size and circuit depth. Although many mitigation strategies exist, their connection to convergence performance under different iteration budgets remains unclear. Moreover, a systematic analysis identifying which state-of-the-art mitigation techniques perform best under specific scenarios is also lacking. We benchmark four approaches, Local-Global, Adiabatic, State Efficient Ansatz (SEA), and Pretrained VQE, against standard VQE on molecular systems from 4 to 14 qubits, analyzing gradient variance up to 50 layers and convergence over 1000 iterations. Our results show that the impact of gradient preservation is iteration-dependent. In the 14-qubit BeH2 system, Pretrained VQE outperforms SEA at 100 iterations despite lower gradient variance, but SEA becomes 2.2x more accurate at 1000 iterations. For smaller systems, SEA achieves near-exact energies (H2: 10^-5 Ha, LiH: 2x10^-4 Ha) with fidelities 0.999, while standard methods plateau early. The results demonstrate that robust barren plateau mitigation depends on aligning the chosen strategy with both system size and available computational budget, rather than treating gradient variance as the sole predictor of performance.

</details>


### [30] [Negative Marginal Densities in Mixed Quantum-Classical Liouville Dynamics](https://arxiv.org/abs/2512.11174)
*Kai Gu,Jeremy Schofield*

Main category: quant-ph

TL;DR: QCLE虽然能准确描述许多可观测量的期望值，但其相空间分布可能违反正定性，特别是在低能态下，这种违反会随系统初始能量增加而减弱。


<details>
  <summary>Details</summary>
Motivation: 研究混合量子-经典刘维尔方程（QCLE）生成的相空间分布是否保持物理系统应有的正定性，特别是在与精确量子动力学比较时。

Method: 比较精确量子动力学与QCLE演化产生的相空间分布；通过数值和解析方法分析低维模型；进行微扰分析验证普遍性。

Result: QCLE的相空间分布可能违反正定性，特别是低能态下非对角矩阵元素的共振效应存在定性差异；违反程度随初始能量相对于子系统能隙的增加而减弱。

Conclusion: QCLE相空间分布的正定性违反表明其局限性，建议使用负性指数作为评估混合量子-经典描述有效性的度量指标。

Abstract: The mixed quantum-classical Liouville equation (QCLE) provides an approximate perturbative framework for describing the dynamics of systems with coupled quantum and classical degrees of freedom of disparate thermal wavelengths. The evolution governed by the Liouville operator preserves many properties of full quantum dynamics, including the conservation of total population, energy, and purity, and has shown quantitative agreement with exact quantum results for the expectation values of many observables where direct comparisons are feasible. However, since the QCLE density matrix operator is obtained from the partial Wigner transform of the full quantum density matrix, its matrix elements can have negative values, implying that the diagonal matrix elements behave as pseudo-densities rather than densities of classical phase space. Here, we compare phase-space distributions generated by exact quantum dynamics with those produced by QCLE evolution from pure quantum initial states. We show that resonance effects in the off-diagonal matrix elements differ qualitatively, particularly for low-energy states. Furthermore, numerical and analytical results for low-dimensional models reveal that the QCLE can violate the positivity of marginal phase-space densities, a property that should hold at all times for any physical system. A perturbative analysis of a model system confirms that such violations arise generically. We also show that the violations of positivity of the marginal densities vanish as the initial energy of the system increases relative to the energy gap between subsystem states. These findings suggest that a negativity index, quantifying deviations from positivity, may provide a useful metric for assessing the validity of mixed quantum\textendash{}classical descriptions.

</details>


### [31] [Enhancing Long-distance Continuous-variable Quantum-key-distribution with an Error-correcting Relay](https://arxiv.org/abs/2512.11224)
*S. Nibedita Swain,Ryan J. Marshman,Josephine Dias,Alexander S. Solntsev,Timothy C. Ralph*

Main category: quant-ph

TL;DR: 该研究将无噪声线性放大器与酉平均协议结合，同时补偿热损耗效应并抑制相位噪声，实现了超越无中继器界限的长距离连续变量量子密钥分发。


<details>
  <summary>Details</summary>
Motivation: 连续变量量子密钥分发在长距离传输中面临热损耗效应和相位噪声的挑战，现有技术难以同时有效解决这两个问题，限制了通信距离和安全性。

Method: 将无噪声线性放大器与酉平均协议相结合，前者用于补偿热损耗效应，后者用于抑制相位噪声，形成一种复合协议来同时处理两种主要噪声源。

Result: 该复合协议能够实现超越无中继器界限的长距离连续变量量子密钥分发，突破了量子通信系统的基本速率-距离限制。

Conclusion: 通过结合无噪声线性放大器和酉平均协议，可以同时有效补偿热损耗效应和抑制相位噪声，为实现长距离、高性能的连续变量量子密钥分发提供了可行方案。

Abstract: Noiseless linear amplifiers (NLAs) serve as an effective means to enable long-distance continuous-variable (CV) quantum key distribution (QKD), even under realistic conditions with non-unit reconciliation efficiency. Separately, unitary averaging has been suggested to mitigate some stochastic noise, including phase noise in continuous-variable states. In this work, we combine these two protocols to simultaneously compensate for thermal-loss effects and suppress phase noise, thereby enabling long-distance CV QKD that surpasses the repeaterless bound, the fundamental rate-distance limit, for repeaterless quantum communication systems.

</details>


### [32] [On Shor's conjecture on the accessible information of quantum dichotomies](https://arxiv.org/abs/2512.11233)
*Khac Duc An Thai,Michele Dall'Arno*

Main category: quant-ph

TL;DR: 该论文研究量子二分法的可达信息问题，反驳了可达信息在猜测概率上的单调性假设，并提出了量子测量的状态相关极值性理论，改进了量子比特二分法的可达信息结果。


<details>
  <summary>Details</summary>
Motivation: Shor在世纪之交提出的猜想认为，任何量子二分法的可达信息（即从二进制量子编码中可解码的最大经典信息量）都可以通过冯·诺依曼测量实现。25年后，量子主化和统计比较领域关于量子二分法洛伦兹曲线的新发展为解决这一长期开放问题提供了可能。

Method: 首先研究二进制情况下可达信息与猜测概率之间的权衡关系，反驳了前者在后者上的单调性假设。其次提出了量子测量的状态相关极值性推广，表征了量子比特二分法的状态相关极值性，并应用这些结果改进了先前关于量子比特二分法可达信息的结果。

Result: 1. 证明了可达信息在猜测概率上并不单调，这一发现推翻了如果成立就能解决量子比特情况下Shor问题的假设。2. 建立了量子测量的状态相关极值性理论，并应用于量子比特二分法，从而改进了先前关于可达信息的界限。

Conclusion: 该研究通过分析可达信息与猜测概率的权衡关系，以及对量子测量极值性的状态相关推广，为理解量子二分法的可达信息问题提供了新的理论工具，并改进了量子比特情况下的现有结果，为最终解决Shor猜想迈出了重要一步。

Abstract: Around the turn of the century, Shor formulated his well-known and still-open conjecture stating that the accessible information of any quantum dichotomy, that is the maximum amount of classical information that can be decoded from a binary quantum encoding, is attained by a von Neumann measurement. A quarter of a century later, new developments on the Lorenz curves of quantum dichotomies in the field of quantum majorization and statistical comparison may provide the key to unlock such a longstanding open problem. Here, we first investigate the tradeoff relations between accessible information and guessing probability in the binary case, thus disproving the claimed monotonicity of the former quantity in the latter that, if true, would have settled Shor's problem in the qubit case. Our second result is to provide a state-dependent generalization of extremality for quantum measurements, to characterize state-dependent extremality for qubit dichotomies, and to apply such results to tighten previous results on the accessible information of qubit dichotomies.

</details>


### [33] [Quantum Krylov algorithm using unitary decomposition for exact eigenstates of fermionic systems using quantum computers](https://arxiv.org/abs/2512.11788)
*Ayush Asthana*

Main category: quant-ph

TL;DR: 本文提出了一种名为QKUD的量子Krylov算法，它无需时间演化，采用精确的Krylov子空间构建方法，解决了传统量子Krylov算法中时间演化不精确、参数敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 当前量子Krylov算法主要依赖实时间或虚时间演化来构建Krylov向量，这种方法存在三个主要问题：1）不是精确方法；2）需要任意时间步长参数Δt；3）随着Δt增大，Krylov向量质量迅速下降。这些局限性限制了算法的准确性和实用性。

Method: 提出了一种名为"量子Krylov使用酉分解"（QKUD）的新算法。该方法不依赖时间演化，而是通过酉分解精确构建Krylov子空间。算法在误差参数ε→0的极限下是精确的，并且在ε≠0时比传统时间演化方法具有更优的误差缩放特性（O(ε²) vs O(Δt)）。

Result: 通过模拟验证了QKUD的理论优势：1）在小的ε值时提供数值精确结果；2）在广泛的ε值范围内保持稳定，表明参数敏感性低；3）能够解决传统时间演化方法无法处理的问题。

Conclusion: QKUD算法解决了量子Krylov算法的核心限制——不精确性和对时间步长参数的敏感性，为量子计算机开发更强大、更具量子优势前景的量子Krylov算法铺平了道路。

Abstract: Quantum Krylov algorithms have emerged as a useful framework for quantum simulations in quantum chemistry and many-body physics, offering a favorable trade-off between potential quantum speedups and practical resource demands. However, the current primary approach to building Krylov vectors in these algorithms is to use real or imaginary-time evolution, which is not exact, require an arbitrary time-step parameter ($Δt$), and degrade the Krylov vectors quickly with increasing $Δt$. In this paper, we develop a quantum Krylov algorithm without time evolution and with an exact formulation of the Krylov subspace, named ``Quantum Krylov using Unitary Decomposition'' (QKUD), along with implementation proposals for quantum computers. Not only is this algorithm exact in the limit $ε\to 0$ of the error parameter $ε$, but it also produces more accurate Krylov vectors at $ε\neq 0$ than conventional time evolution due to more favorable error scaling (O($ε^2$) vs O($Δt$)). Through simulations, we demonstrate that these theoretical benefits yield numerical advantages: (i) QKUD provides numerically exact results at small $ε$, (ii) it remains stable across a broad range of $ε$ values, indicating low parameter sensitivity, and (iii) it can solve problems unreachable by conventional time evolution. This development resolves a central limitation of quantum Krylov algorithms, namely their inexactness and sensitivity to the time-step parameter, and paves the way for new and powerful quantum Krylov algorithms for quantum computers with a stronger promise of quantum advantage.

</details>


### [34] [Creation of Depth-Confined, Shallow Nitrogen-Vacancy Centers in Diamond With Tunable Density](https://arxiv.org/abs/2512.11242)
*Lillian B. Hughes Wyatt,Shreyas Parthasarathy,Isaac Kantor,Casey K. Kim,Lingjie Chen,Taylor A. Morrison,Jeffrey Ahlers,Kunal Mukherjee,Ania C. Bleszynski Jayich*

Main category: quant-ph

TL;DR: 通过钻石生长过程中的δ掺杂技术创建近表面氮空位中心，实现了对NV深度限制和密度的可调控制，相比低能离子注入有显著改进，并应用于二维磁体CrSBr的磁性成像。


<details>
  <summary>Details</summary>
Motivation: 工程化浅层氮空位中心是解锁纳米级量子传感新进展的关键，需要开发能够精确控制NV深度和密度的方法，以提升传感性能和应用范围。

Method: 采用钻石生长过程中的δ掺杂技术创建近表面NV中心，这种方法相比传统的低能离子注入能提供更好的深度限制和密度控制。

Result: δ掺杂实现了NV深度限制的两倍改进和密度的可调控制，产生了高灵敏度的单缺陷和系综，相干性受限于NV-NV相互作用，并成功应用于二维磁体CrSBr的磁性成像。

Conclusion: 近表面δ掺杂提供的控制能力将推动NV量子传感的新发展，从纳米级NMR到纠缠增强计量学等应用领域。

Abstract: Engineering shallow nitrogen-vacancy (NV) centers in diamond holds the key to unlocking new advances in nanoscale quantum sensing. We find that the creation of near-surface NVs through delta doping during diamond growth allows for tunable control over both NV depth confinement (with a twofold improvement relative to low-energy ion implantation) and NV density, ultimately resulting in highly-sensitive single defects and ensembles with coherence limited by NV-NV interactions. Additionally, we demonstrate the utility of our shallow delta-doped NVs by imaging magnetism in few-layer CrSBr, a two-dimensional magnet. We anticipate that the control afforded by near-surface delta doping will enable new developments in NV quantum sensing from nanoscale NMR to entanglement-enhanced metrology.

</details>


### [35] [A Survey of OAM-Encoded High-Dimensional Quantum Key Distribution: Foundations, Experiments, and Recent Trends](https://arxiv.org/abs/2512.11286)
*Huan Zhang,Zhenyu Cao,Yu Sun,Hu Jin*

Main category: quant-ph

TL;DR: 这篇综述论文系统梳理了基于轨道角动量(OAM)的高维量子密钥分发技术，总结了基本原理、实验进展和系统限制，重点关注了混合编码、模式分选、自适应光学等实用化技术。


<details>
  <summary>Details</summary>
Motivation: 高维量子密钥分发(HD-QKD)通过在大希尔伯特空间中编码数据来提高信息效率和噪声容忍度。光的轨道角动量(OAM)为这种编码提供了可扩展的基础，并支持高维光子通信。然而，基于OAM的实际应用仍然受到状态生成、传输和检测方面的挑战限制。

Method: 本文采用综述研究方法，对OAM编码的HD-QKD技术进行了系统梳理：1) 概述基本原理；2) 总结代表性实验；3) 分析系统级限制；4) 总结混合编码、模式分选、自适应光学等最新进展；5) 评估TF、CV、MDI和DI等框架的实用可行性。

Result: 论文提供了OAM编码HD-QKD的全面概述，明确了该领域的技术现状：OAM为高维编码提供了可扩展基础，但实际应用仍面临状态生成、传输和检测的挑战。混合编码、模式分选和自适应光学等技术正在推动实用化进展。

Conclusion: 基于OAM的高维量子密钥分发技术具有提高信息效率和噪声容忍度的潜力，但需要解决状态生成、传输和检测等实际挑战。混合编码、先进模式分选和自适应光学等技术的发展正在推动该技术向实用化迈进。

Abstract: High-dimensional quantum key distribution (HD-QKD) enhances information efficiency and noise tolerance by encoding data in large Hilbert spaces. The orbital angular momentum (OAM) of light provides a scalable basis for such encoding and supports high-dimensional photonic communication. Practical OAM-based implementations remain constrained by challenges in state generation, transmission, and detection. This survey offers a consolidated overview of OAM-encoded HD-QKD, outlining fundamental principles, representative experiments, and system-level limitations. Recent progress in hybrid encodings, mode sorting, adaptive optics, and TF, CV, MDI, and DI frameworks is summarized with emphasis on practical feasibility.

</details>


### [36] [Distributed Quantum Magnetic Sensing for Infrastructure-free Geo-localization](https://arxiv.org/abs/2512.11300)
*Thinh Le,Shiqian Guo,Jianqing Liu*

Main category: quant-ph

TL;DR: 该研究探索利用量子磁传感（基于NV色心）进行地磁定位，通过理论推导CRLB证明量子优势，并采用分布式量子传感协议实现CRLB饱和，结合梯度空间和角点空间的马氏距离搜索实现亚公里级定位精度。


<details>
  <summary>Details</summary>
Motivation: GNSS系统易受干扰和遮挡，而地磁场包含位置信息且被动物用于导航，但实际应用需要超高灵敏度磁力计。本研究旨在探索量子磁传感如何用于地磁定位。

Method: 1. 理论推导NV色心量子传感的CRLB，证明量子优势；2. 采用分布式量子传感协议饱和CRLB；3. 将地理定位建模为地图匹配问题，引入粗到细的马氏距离搜索，在梯度空间（局部场导数）和角点空间（原始场样本）进行搜索。

Result: 在美国和加拿大四个城市的模拟实验中，高梯度区域梯度空间马氏搜索实现亚公里中值定位误差；在磁场较平滑区域，角点空间搜索提供更好精度，且运行时间减少4-8倍。

Conclusion: 量子磁传感为GNSS脆弱性问题提供了有前景的替代方案，通过量子优势实现高精度地磁定位，不同搜索策略适应不同磁场特征区域，具有实际应用潜力。

Abstract: Modern navigation systems rely heavily on Global Navigation Satellite Systems (GNSS), whose weak spaceborne signals are vulnerable to jamming, spoofing, and line-of-sight blockage. As an alternative, the Earth's magnetic field entails location information and is found critical to many animals' cognitive and navigation behavior. However, the practical use of the Earth's magnetic field for geo-localization hinges on an ultra-sensitive magnetometer. This work investigates how quantum magnetic sensing can be used for this purpose. We theoretically derive the Cramér-Rao lower bound (CRLB) for the estimation error of quantum sensing when using a nitrogen-vacancy (NV) center and prove the quantum advantage over classical magnetometers. Moreover, we employ a practical distributed quantum sensing protocol to saturate CRLB. Based on the estimated magnetic field and the earth's magnetic field map, we formulate geo-localization as a map-matching problem and introduce a coarse-to-fine Mahalanobis distance search in both gradient space (local field derivatives) and corner space (raw field samples). We simulate the proposed quantum sensing-based geo-localization framework over four cities in the United States and Canada. The results report that in high-gradient regions, gradient-space Mahalanobis search achieves sub-kilometer median localization error; while in magnetically smoother areas, corner-space search provides better accuracy and a $4-8\times$ reduction in runtime.

</details>


### [37] [Why cut-and-choose quantum state verification cannot be both efficient and secure](https://arxiv.org/abs/2512.11358)
*Fabian Wiesner,Ziad Chaoui,Diana Kessler,Anna Pappa,Martti Karvonen*

Main category: quant-ph

TL;DR: 该论文证明了对任意量子态进行cut-and-choose验证存在基本限制：无法同时实现高效（轮数少）和安全，这种权衡使得该方法在实际中不可用


<details>
  <summary>Details</summary>
Motivation: 量子态验证在量子密码协议中至关重要，但最常用的cut-and-choose方法是否既能高效又能安全的问题尚未得到全面解答

Method: 通过理论分析证明cut-and-choose量子态验证的基本限制，提供no-go结果，展示效率与安全性之间的权衡

Result: 证明对于任意量子态，cut-and-choose方法无法同时实现高效轮数和安全性，安全参数的下界缩放使得该方法在实际中不可用

Conclusion: cut-and-choose量子态验证存在基本限制，无法同时满足效率和安全性要求，需要探索其他验证方法

Abstract: Quantum state verification plays a vital role in many quantum cryptographic protocols, as it allows the use of quantum states from untrusted sources. While some progress has been made in this direction, the question of whether the most prevalent type of quantum state verification, namely cut-and-choose verification, can be efficient and secure, is still not answered in full generality. In this work, we show a fundamental limit for quantum state verification for all cut-and-choose approaches used to verify arbitrary quantum states. We provide a no-go result showing that the cut-and-choose techniques cannot lead to quantum state verification protocols that are both efficient in the number of rounds and secure. We show this trade-off for stand-alone and composable security, where the scaling of the lower bound for the security parameters renders cut-and-choose quantum state verification effectively unusable.

</details>


### [38] [Maritime object classification with SAR imagery using quantum kernel methods](https://arxiv.org/abs/2512.11367)
*John Tanner,Nicholas Davies,Pascal Elahi,Casey R. Myers,Du Huynh,Wei Liu,Mark Reynolds,Jingbo Wang*

Main category: quant-ph

TL;DR: 该研究首次将量子核方法应用于SAR图像中的海上目标分类，比较了量子核方法与经典核方法在区分船只与非船只、渔船与其他船只两类任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 非法、未报告和无管制捕捞每年造成100-250亿美元的经济损失，破坏海洋可持续性和治理。合成孔径雷达(SAR)可在全天候条件下提供可靠的海上监视，但SAR图像中的小型海上目标分类仍然具有挑战性。研究探索量子机器学习在此任务中的应用潜力。

Method: 使用量子核方法处理从SARFish数据集中提取的实数和复数SAR图像块。研究两个二元分类问题：1)区分船只与非船只；2)区分渔船与其他类型船只。将量子核方法应用于实数和复数SAR数据，并与应用于实数SAR数据的经典拉普拉斯核、RBF核和线性核进行比较。

Result: 在无噪声数值模拟中，量子核方法在最佳情况下能够获得与经典核方法相当或更好的性能，但对于复数SAR数据并未显示出明显优势。量子核方法在某些任务上表现出潜力，但尚未展现出对复杂数据的明确优势。

Conclusion: 这是量子核方法首次应用于SAR图像中的海上分类任务，为量子增强学习在海事监视中的潜力和当前局限性提供了见解。量子方法在特定条件下可能具有优势，但需要进一步研究来充分发挥其潜力。

Abstract: Illegal, unreported, and unregulated (IUU) fishing causes global economic losses of \$10-25 billion annually and undermines marine sustainability and governance. Synthetic Aperture Radar (SAR) provides reliable maritime surveillance under all weather and lighting conditions, but classifying small maritime objects in SAR imagery remains challenging. We investigate quantum machine learning for this task, focusing on Quantum Kernel Methods (QKMs) applied to real and complex SAR chips extracted from the SARFish dataset. We tackle two binary classification problems, the first for distinguishing vessels from non-vessels, and the second for distinguishing fishing vessels from other types of vessels. We compare QKMs applied to real and complex SAR chips against classical Laplacian, RBF, and linear kernels applied to real SAR chips. Using noiseless numerical simulations of the quantum kernels, we find that QKMs are capable of obtaining equal or better performance than the classical kernel on these tasks in the best case, but do not demonstrate a clear advantage for the complex SAR data. This work presents the first application of QKMs to maritime classification in SAR imagery and offers insight into the potential and current limitations of quantum-enhanced learning for maritime surveillance.

</details>


### [39] [Quantum limits of a space-time reference frame](https://arxiv.org/abs/2512.11407)
*Davide Mattei,Esteban Castro Ruiz*

Main category: quant-ph

TL;DR: 单个复合量子系统无法同时作为完美的空间和时间量子参考系，空间定位精度和时间分辨率之间存在海森堡式的不确定关系。


<details>
  <summary>Details</summary>
Motivation: 研究当唯一可用的参考系是单个复合量子系统时的局限性，该系统内部自由度作为时钟，质心自由度作为空间参考（标尺），探索空间和时间测量之间的基本限制。

Method: 结合量子速度极限和狭义相对论的质能等价原理，分析内部能量相干性对质心动力学的影响，从外部视角和纯粹关系性视角（通过时空量子参考系的协变可观测量）研究这种权衡。

Result: 空间局域性和时间分辨率不是独立的：精确化一个必然模糊另一个。内部能量相干性增强时间测量精度的同时，会增强自由演化过程中的位置扩散，导致空间和时间间隔之间存在海森堡式的不确定关系。

Conclusion: 单个复合系统无法同时作为完美的空间和时间量子参考系，存在基本的不确定关系，揭示了时空量子参考系的内在局限性，并发现了与参考系康普顿波长同量级的额外内在不确定性。

Abstract: We study the limitations for defining spatial and temporal intervals when the only available reference frame is a single composite quantum system, whose internal degrees of freedom serve as a temporal reference, a clock, and whose center of mass degrees of freedom act as a spatial reference, a rod. By combining quantum speed limits with the mass energy equivalence of special relativity, we show that spatial localizability and temporal resolution are not independent: sharpening one inevitably blurs the other. Specifically, the internal energy coherence needed for precise timekeeping affects the center of mass dynamics, enhancing position spreading during free evolution. As a result, a single composite system cannot act as a perfect quantum reference frame for both space and time, leading to a Heisenberg like uncertainty relation between spatial and temporal intervals. After analyzing this trade off from an external perspective, we formulate it in a purely relational manner, by means of covariant observables relative to the space time quantum reference frame, uncovering an additional intrinsic uncertainty of order the Compton wavelength of the frame.

</details>


### [40] [Stabilizer-based quantum simulation of fermion dynamics with local qubit encodings](https://arxiv.org/abs/2512.11418)
*Anthony Gandon,Samuele Piccinelli,Max Rossmannek,Francesco Tacchino,Alberto Baiardi,Jannes Nys,Ivano Tavernelli*

Main category: quant-ph

TL;DR: 提出基于流集的新框架，用于实现局部费米子编码的时间演化幺正算符，通过分类流集形式设计低深度量子电路，在二维编码中实现空间-时间权衡。


<details>
  <summary>Details</summary>
Motivation: 大规模多费米子系统的动力学模拟是量子化学、材料科学和凝聚态物理的长期目标。局部费米子到量子比特编码为在数字量子硬件上进行实际费米子模拟提供了新途径，但需要有效实现相应的时间演化幺正算符。

Method: 提出基于流集的新框架，流集是定向费米子相互作用图的一维子集。将局部费米子编码限制在给定流集上，获得可系统分类的简单结构。对每种流集形式，使用稳定子形式主义设计低深度量子比特电路来实现时间演化幺正算符。

Result: 为已知二维编码引入新颖的基于流的分解，实现时间演化幺正算符的高效电路分解。观察到空间-时间权衡：具有较大量子比特-费米子比率的映射产生更浅的时间演化量子电路。

Conclusion: 基于流集的框架为局部费米子编码的时间演化幺正算符实现提供了系统方法，通过分类流集形式和设计相应电路，在二维编码中实现了空间-时间权衡，为大规模费米子系统的量子模拟提供了有效工具。

Abstract: Simulating the dynamical properties of large-scale many-fermion systems is a longstanding goal of quantum chemistry, material science and condensed matter. Local fermion-to-qubit encodings have opened a new path for practical fermionic simulations on digital quantum hardware where fermionic statistics are not enforced at the hardware level. In this paper, we explore these local encodings from the perspective of the corresponding time-evolution unitaries. Specifically, we propose a new framework for digital implementations of these qubit-encoded fermionic time-evolution unitaries based on \emph{flow sets}, which are one-dimensional subsets of the directed fermionic interaction graph. We find that any local fermionic encoding, when restricted to a given flow set, adopts a simple structure that we can classify systematically. For each categorized flow-set form, we propose a low-depth qubit quantum circuit that implements the time evolution unitary using the stabilizer formalism. As an application of our construction, we introduce novel flow-based decompositions for known two-dimensional encodings, leading to efficient circuit decompositions of time-evolution unitaries. We generally observe a space-time trade-off, where mappings with larger qubit-to-fermion ratios yield shallower time-evolution quantum circuits.

</details>


### [41] [Nonreciprocal flow of fluctuations, populations and correlations between doubly coupled bosonic modes](https://arxiv.org/abs/2512.11436)
*Zbigniew Ficek*

Main category: quant-ph

TL;DR: 论文研究了双耦合玻色子模式在环境作用下的新相关性和单向特性，发现哈密顿量虽为厄米但动力学表现出非厄米特性，导致正交分量的不对称耦合，从而产生多种显著现象。


<details>
  <summary>Details</summary>
Motivation: 探索在同时存在线性模式跳跃和非线性压缩相互作用下，两个玻色子模式在环境影响下出现的新相关性和单向特性，特别是研究非厄米动力学如何导致正交分量的不对称耦合及其物理后果。

Method: 通过同时施加线性模式跳跃和非线性压缩相互作用实现双耦合，分析系统的哈密顿量和动力学行为，研究正交分量的不对称耦合特性，探讨异常点对热态转化为压缩态的影响，以及压缩态库中双光子相关性对单向流动的控制。

Result: 发现系统哈密顿量虽为厄米但动力学表现出非厄米特性，导致正交分量的不对称耦合；异常点控制热态向单模经典或量子压缩态的转化；压缩态库中的双光子相关性负责模式间布居和相关性的单向流动，且可通过调整压缩噪声椭圆方向控制；布居流动产生模式间的一阶相干性，但抑制了负责模式纠缠的双光子相关性增强。

Conclusion: 双耦合玻色子模式系统展现出丰富的非厄米动力学特性，为产生单模压缩场提供了新途径，并为控制玻色子链中布居和相关性的单向传输提供了潜在应用前景。

Abstract: Interesting new correlation and unidirectional properties of two bosonic modes under the influence of environment appear when the modes are mutually coupled through the simultaneously applied linear mode-hopping and nonlinear squeezing interactions. Under such double coupling, it is found that while the Hamiltonian of the system is clearly Hermitian the dynamics of the quadrature components of the field operators can be attributed to non-Hermicity of the system. It is manifested in an asymmetric coupling between the quadrature components which then leads to a variety of remarkable features. In particular, we identify how the emerging exceptional point controls the conversion of thermal states of the modes into single-mode classically or quantum squeezed states. Furthermore, for reservoirs being in squeezed states, we find that the two-photon correlations present in these reservoirs are responsible for unidirectional flow of populations and correlations among the modes and the flow can be controlled by appropriate tuning of the mutual orientation of the squeezed noise ellipses. In the course of analyzing these effects we find that the flow of the population creates the first-order coherence between the modes which, on the other hand rules out an enhancement of the two photon correlations responsible for entanglement between the modes. These results suggest new alternatives for the creation of single mode squeezed fields and the potential applications for controlled unidirectional transfer of population and correlations in bosonic chains.

</details>


### [42] [Comment on "Contextuality and quantum discord"](https://arxiv.org/abs/2512.11450)
*Chellasamy Jebarathinam*

Main category: quant-ph

TL;DR: 作者指出Al-Qasimi论文中关于两量子比特Werner态上下文性的论证是错误的，并引用了相关研究


<details>
  <summary>Details</summary>
Motivation: 纠正Al-Qasimi论文中的错误论证，该论文声称只有当discord为零时，两量子比特Werner态系统才是非上下文性的

Method: 通过分析Al-Qasimi的论证逻辑，指出其错误之处，并引用Jebarathinam和Srikanth的相关研究作为支持

Result: Al-Qasimi的论证是错误的，两量子比特Werner态的上下文性不能简单地通过discord是否为零来判断

Conclusion: 需要重新审视两量子比特Werner态的上下文性判断标准，Al-Qasimi的结论不可靠

Abstract: In a paper, Al-Qasimi [Physics Letters A 449 (2022) 128347] studied contextuality of two-qubit states using an argument by Peres [Phys. Lett. A 151 (1990) 107]. For two-qubit system in the Werner state, Al-Qasimi argued that only when discord is zero, the system is noncontextual. Here I point out that this argument is false and the related work in C. Jebarathinam and R. Srikanth [Int. J. Quantum Inf. https://doi.org/10.1142/S0219749925500376 (arXiv:2403.01762v2)].

</details>


### [43] [Processing through encoding: Quantum circuit approaches for point-wise multiplication and convolution](https://arxiv.org/abs/2512.11457)
*Andreas Papageorgiou,Paulo Vitor Itaborai,Kostas Blekos,Karl Jansen*

Main category: quant-ph

TL;DR: 该论文提出了量子电路方法用于复函数的逐点乘法和卷积运算，通过"编码处理"概念实现，并展示了在量子音频处理中的应用。


<details>
  <summary>Details</summary>
Motivation: 开发量子信号处理技术，特别是针对复函数的逐点乘法和卷积运算，为量子增强的音频处理和合成等应用提供新方法。

Method: 采用"编码处理"方法，将多个复函数编码到辅助量子比特上，通过量子电路实现逐点乘法；基于卷积定理，通过编码傅里叶系数、逐点相乘和逆量子傅里叶变换实现卷积运算。

Result: 成功展示了复函数逐点乘积作为量子态系数自然形成的机制，实现了卷积运算的量子构造，并开发了扩展的quantumaudio软件包进行音频信号处理。

Conclusion: 该工作为量子信号处理提供了有前景的新途径，特别是在量子增强音频操作和合成等领域具有潜在应用价值。

Abstract: This paper introduces quantum circuit methodologies for pointwise multiplication and convolution of complex functions, conceptualized as "processing through encoding". Leveraging known techniques, we describe an approach where multiple complex functions are encoded onto auxiliary qubits. Applying the proposed scheme for two functions $f$ and $g$, their pointwise product $f(x)g(x)$ is shown to naturally form as the coefficients of part of the resulting quantum state. Adhering to the convolution theorem, we then demonstrate how the convolution $f*g$ can be constructed. Similarly to related work, this involves the encoding of the Fourier coefficients $\mathcal{F}[f]$ and $\mathcal{F}[g]$, which facilitates their pointwise multiplication, followed by the inverse Quantum Fourier Transform. We discuss the simulation of these techniques, their integration into an extended \verb|quantumaudio| package for audio signal processing, and present initial experimental validations. This work offers a promising avenue for quantum signal processing, with potential applications in areas such as quantum-enhanced audio manipulation and synthesis.

</details>


### [44] [Bell, Spinors, and the Impossibility of a Classical Spin-Vector Model](https://arxiv.org/abs/2512.11476)
*G. A. Koroteev*

Main category: quant-ph

TL;DR: 论文重新审视了Bell-CHSH场景，揭示了Bell矛盾的精确代数根源：量子自旋的非交换代数与经典Kolmogorov概率空间的交换代数之间的不匹配。


<details>
  <summary>Details</summary>
Motivation: 研究Bell-CHSH场景中量子与经典描述的根本差异，从代数角度精确揭示Bell矛盾的起源，澄清量子非定域性与经典概率描述之间的本质冲突。

Method: 采用代数方法分析：量子方面使用自旋1/2的非交换旋量（Clifford）代数，经典方面使用Kolmogorov概率空间的交换代数。证明不存在将旋量代数映射到交换代数并保持自旋分量谱和CHSH表达式中单态相关性的表示。

Result: 证明了在标准Bell假设（定域性和测量独立性）下，不存在将自旋1/2的旋量代数（包含单态态和定域性结构）映射到交换Kolmogorov代数的表示。Bell-CHSH矛盾表现为非交换旋量描述与经典全局概率空间假设之间的代数不匹配。

Conclusion: Bell矛盾的本质是代数结构的不兼容：量子自旋的非交换旋量代数无法嵌入到经典的交换Kolmogorov概率代数中。这为量子非定域性提供了清晰的代数解释，并在作者的量子指标代数框架中给出了具体实现。

Abstract: We revisit the Bell--CHSH scenario for two spin-\(\tfrac{1}{2}\) particles and isolate the precise algebraic origin of the Bell contradiction. On the quantum side, spin-\(\tfrac{1}{2}\) is described by a noncommutative spinor (Clifford) algebra acting on the Hilbert space of two spin-\(\tfrac{1}{2}\) particles, with the singlet state yielding the usual correlation \(E(a,b) = -\,a\cdot b\) and Tsirelson's bound \(2\sqrt{2}\). On the classical side, the standard Bell assumptions amount to describing all measurement outcomes as \(\{\pm1\}\)-valued random variables on a single Kolmogorov probability space, i.e.\ elements of a commutative algebra \(\mathcal{C}(Λ)\).
  We show that there is no representation of the spinor algebra of spin-\(\tfrac{1}{2}\) (with its singlet state and locality structure) into any such commutative Kolmogorov algebra that preserves the \(\{\pm1\}\) spectra of local spin components and the singlet correlations entering the CHSH expression, under the standard Bell assumptions of locality (factorization) and measurement independence. In this sense, the Bell--CHSH contradiction is exhibited as an algebraic mismatch between a noncommutative spinor/Clifford description of spin and the classical assumption of a single global Kolmogorov space supporting all outcomes. In the language of quantum probability, this is a C\(^*\)-algebraic reformulation of the known fact that the singlet correlations admit no local hidden-variable model with jointly distributed outcomes on one probability space.
  We also give an explicit realization of the same spinor structure within the author's Quantum Index Algebra (QIA) framework, where locality appears as disjoint index slots and the singlet state as a simple index cocycle.

</details>


### [45] [Irreducibility of Quantum Markov Semigroups, uniqueness of invariant states and related properties](https://arxiv.org/abs/2512.11517)
*Franco Fagnola,Federico Girotti*

Main category: quant-ph

TL;DR: 本文系统研究了量子马尔可夫半群的不可约性概念，给出了多种刻画方式，并探讨了其与原始性、正性改进、弛豫等动力学特征的关系，特别证明了在存在不变密度时不可约性、原始性和弛豫到忠实不变密度的等价性。


<details>
  <summary>Details</summary>
Motivation: 量子马尔可夫半群的不可约性是量子开放系统动力学中的重要概念，但现有文献中对其定义和性质缺乏系统研究。本文旨在填补这一空白，为不可约性提供清晰的理论框架和实用判据。

Method: 采用自包含的数学分析方法，收集整理相关文献结果并提供初等证明，同时推导新结果。研究基于GKLS形式的生成元算子，考虑有限维和无限维演化，并扩展到施瓦茨映射构成的量子马尔可夫半群。

Result: 建立了不可约性、原始性和弛豫到忠实不变密度的等价关系；提出了基于GKLS形式生成元算子的多种不可约性检验方法；将许多结果推广到仅要求半群由施瓦茨映射构成的情形。

Conclusion: 本文为量子马尔可夫半群的不可约性提供了系统理论框架，建立了与其他动力学特征的重要等价关系，并给出了实用的检验判据，对有限维和无限维系统均有应用价值。

Abstract: We present different characterizations of the notion of irreducibility for Quantum Markov Semigroups (QMSs) and investigate its relationship with other relevant features of the dynamics, such as primitivity, positivity improvement and relaxation; in particular, we show that irreducibility, primitivity and relaxation towards a faithful invariant density are equivalent when the semigroup admits an invariant density. Moreover, in the case of uniformly continuous QMSs, we present several useful ways of checking irreducibility in terms of the operators appearing in the generator in GKLS form. Our exposition is as much self-contained as possible, we present some well known results with elementary proofs (collecting all the relevant literature) and we derive new ones. We study both finite and infinite dimensional evolutions and we remark that many results only require the QMS to be made of Schwarz maps.

</details>


### [46] [Equilibration and the Eigenstate Thermalization Hypothesis as Limits to Observing Macroscopic Quantum Superpositions](https://arxiv.org/abs/2512.11522)
*Gabriel Dias Carvalho,Pedro S. Correia,Thiago R. de Oliveira*

Main category: quant-ph

TL;DR: 即使完美隔离，本征态热化假说下的幺正动力学也会抑制宏观量子叠加的可观测特征，使宏观叠加态在大多数演化时间内与经典混合态无法区分。


<details>
  <summary>Details</summary>
Motivation: 传统认为宏观量子叠加不可观测是因为大系统无法完美隔离环境，但本文研究即使完美隔离下，内在幺正动力学如何抑制宏观相干性的可观测特征。

Method: 使用GHZ态作为代表性例子，分析完全相关测量和一般多体演化，通过可区分性度量和已建立的宏观量子性量化指标进行研究。

Result: 虽然完全相关测量最初能区分宏观叠加态与经典混合态，但一般多体演化使它们在大多数演化时间内操作上无法区分。平衡化不仅隐藏了可观测量的相干性，还抑制了宏观叠加本身。

Conclusion: 幺正热化（独立于环境退相干）是限制宏观量子效应出现的基本机制，即使完美隔离的系统也无法避免这种内在限制。

Abstract: Macroscopic quantum superpositions are widely believed to be unobservable because large systems cannot be perfectly isolated from their environments. Here, we show that even under perfect isolation, intrinsic unitary dynamics with the eigenstate thermalization hypothesis suppress the observable signatures of macroscopic coherence. Using the GHZ state as a representative example, we demonstrate that while fully correlated measurements can initially distinguish a macroscopic superposition from its corresponding classical mixture, generic many-body evolution renders them operationally indistinguishable for most times during the evolution. By analyzing both distinguishability measures and established quantifiers of macroscopic quantumness, we find that equilibration not only hides coherence from accessible observables but also suppresses macroscopic superpositions themselves. These results identify unitary thermalization, independent of environmental decoherence, as a fundamental mechanism that limits the emergence of macroscopic quantum effects.

</details>


### [47] [The Lattice Schwinger Model and Its Quantum Simulation](https://arxiv.org/abs/2512.11533)
*Joao C. Pinto Barros,Pierpaolo Fontana,Pasquale Sodano,Andrea Trombettoni*

Main category: quant-ph

TL;DR: 本章回顾了格点Schwinger模型的研究成果，重点展示了反常效应在格点上的再现，并将其与量子模拟相互作用场论的最新进展联系起来，讨论了Schwinger模型的量子模拟方案。


<details>
  <summary>Details</summary>
Motivation: 探索格点Schwinger模型中反常效应的再现机制，并将这些理论结果与量子模拟相互作用场论的实际应用联系起来，为量子模拟实验提供理论基础。

Method: 通过回顾格点Schwinger模型的研究成果，分析反常效应在格点上的实现方式，并探讨如何将这些理论结果应用于量子模拟方案的设计。

Result: 展示了反常效应可以在格点Schwinger模型中正确再现，建立了格点理论与量子模拟实验之间的连接，提出了可行的Schwinger模型量子模拟方案。

Conclusion: 格点Schwinger模型为理解量子场论中的反常效应提供了重要框架，其研究成果可直接应用于量子模拟实验，推动了相互作用场论量子模拟技术的发展。

Abstract: In this chapter we review results on the lattice Schwinger model. In par-ticular, we show how the effect of the anomaly is reproduced on the lattice. We connect these results to recent developments in the field of quantum simulation of interacting field theories. Schemes for the quantum simulation of (approximations of) Schwinger models are discussed.

</details>


### [48] [A slightly improved upper bound for quantum statistical zero-knowledge](https://arxiv.org/abs/2512.11597)
*François Le Gall,Yupan Liu,Qisheng Wang*

Main category: quant-ph

TL;DR: 该论文将QSZK的上界从QIP(2)∩co-QIP(2)改进为具有量子线性空间诚实证明者的QIP(2)∩co-QIP(2)，类似改进也适用于NIQSZK。


<details>
  <summary>Details</summary>
Motivation: 量子统计零知识类(QSZK)的最佳已知上界是QIP(2)∩co-QIP(2)，但该上界中的诚实证明者通常是计算无界的。本文旨在改进这一上界，使其包含量子线性空间的诚实证明者。

Method: 主要技术包括：1）Holevo-Helstrom测量的算法版本；2）Uhlmann变换。这两种技术都可在量子线性空间中实现，利用Le Gall等人最近提出的空间高效量子奇异值变换，在状态维度上具有多项式时间复杂度。

Result: 成功将QSZK的上界改进为具有量子线性空间诚实证明者的QIP(2)∩co-QIP(2)。类似改进也适用于非交互变体NIQSZK的上界。

Conclusion: 通过算法化的Holevo-Helstrom测量和Uhlmann变换，结合空间高效的量子奇异值变换技术，实现了对QSZK上界的改进，使诚实证明者仅需量子线性空间，而非计算无界。

Abstract: The complexity class Quantum Statistical Zero-Knowledge ($\mathsf{QSZK}$), introduced by Watrous (FOCS 2002) and later refined in Watrous (SICOMP, 2009), has the best known upper bound $\mathsf{QIP(2)} \cap \text{co-}\mathsf{QIP(2)}$, which was simplified following the inclusion $\mathsf{QIP(2)} \subseteq \mathsf{PSPACE}$ established in Jain, Upadhyay, and Watrous (FOCS 2009). Here, $\mathsf{QIP(2)}$ denotes the class of promise problems that admit two-message quantum interactive proof systems in which the honest prover is typically \textit{computationally unbounded}, and $\text{co-}\mathsf{QIP(2)}$ denotes the complement of $\mathsf{QIP(2)}$.
  We slightly improve this upper bound to $\mathsf{QIP(2)} \cap \text{co-}\mathsf{QIP(2)}$ with a quantum linear-space honest prover. A similar improvement also applies to the upper bound for the non-interactive variant $\mathsf{NIQSZK}$. Our main techniques are an algorithmic version of the Holevo-Helstrom measurement and the Uhlmann transform, both implementable in quantum linear space, implying polynomial-time complexity in the state dimension, using the recent space-efficient quantum singular value transformation of Le Gall, Liu, and Wang (CC, to appear).

</details>


### [49] [The Casimir-Polder interaction between atoms and hollow-core fibers](https://arxiv.org/abs/2512.11603)
*Bettina Beverungen,Daniel Reiche,Kurt Busch,Francesco Intravaia*

Main category: quant-ph

TL;DR: 研究圆柱形空心光纤附近原子的卡西米尔-波尔德力，分析几何和材料尺度对相互作用的影响，特别关注壳层厚度作为调控参数的作用。


<details>
  <summary>Details</summary>
Motivation: 圆柱形空心光纤是量子技术实验中操控原子的典型结构，研究其附近的卡西米尔-波尔德相互作用对于基础物理和量子技术应用具有重要意义。

Method: 开发了灵活且快速收敛的数值方案，用于计算零温和有限温度下不同原子-圆柱距离的相互作用；同时进行了详细的解析分析，研究材料特性如何改变卡西米尔-波尔德势。

Result: 壳层厚度成为调控相互作用的有用参数；该几何结构能够区分欧姆和非欧姆导体描述；数值计算与解析渐近表达式吻合良好。

Conclusion: 壳层厚度作为调控卡西米尔-波尔德相互作用的关键参数，为基础物理研究和量子技术应用开辟了新途径。

Abstract: The Casimir-Polder force acts on polarizable particles due to quantum fluctuations of the electromagnetic field that are modified by the presence of material bodies. We investigate the Casimir-Polder interaction for atoms near cylindrical fibers with hollow cores. This geometry represents one of the archetypal configurations encountered in numerous experimental setups designed to control and manipulate atoms in fundamental and quantum technological applications. Specifically, we analyze how the interplay of both geometrical and material-related length scales characterize the interaction, emphasizing the impact of the shell thickness. We develop a flexible and fast-converging numerical scheme for evaluating the interaction over a wide range of atom-cylinder separations at both zero and finite temperature. Furthermore, we provide a detailed analytical investigation of how various material properties modify the Casimir-Polder potential. Finally, we analyze and discuss a number of limiting cases and compare numerical computations with corresponding analytical asymptotic expressions. In particular, in this geometry the Casimir-Polder potential is able to distinguish between an ohmic and non-ohmic description of conductors. One of the most significant outcomes of our work is that the shell thickness emerges as a useful parameter for controlling the interaction, opening avenues for both fundamental physics and applications in quantum technologies.

</details>


### [50] [Tailoring quantum walks in integrated photonic lattices](https://arxiv.org/abs/2512.11608)
*A. Raymond,P. Cathala,M. Morassi,A. Lemaître,F. Raineri,S. Ducci,F. Baboux*

Main category: quant-ph

TL;DR: 本文系统比较了离散光子电路与连续耦合波导阵列两种量子行走方法，通过实验验证非线性波导阵列中量子态的产生，并展示了逆向设计方法生成最大纠缠态。


<details>
  <summary>Details</summary>
Motivation: 为了阐明离散光子电路（分步操作光子）与连续耦合波导阵列（光子在整个结构中连续干涉）这两种量子行走方法的相似性和区别，需要进行系统比较。

Method: 1. 系统比较线性波导阵列（外部注入光子）与非线性波导阵列（通过参量下转换连续产生光子对）；2. 使用III-V半导体非线性波导晶格进行实验验证，通过改变几何结构调节量子行走深度；3. 开发逆向设计方法，优化非周期性波导阵列的耦合分布以生成最大纠缠态。

Result: 1. 实验验证了量子行走深度可调节超过一个数量级，揭示了输出态中非经典性的逐渐出现；2. 成功设计出非周期性波导阵列，其优化的耦合分布能够生成最大纠缠态，如双光子W态。

Conclusion: 连续耦合光子系统在紧凑架构中利用高维纠缠具有巨大潜力，非线性波导阵列能够直接产生量子光态，为量子信息处理提供了新途径。

Abstract: Unlike discrete photonic circuits, which manipulate photons step-by-step using a series of optical elements, arrays of coupled waveguides enable photons to interfere continuously across the entire structure. When composed of a nonlinear material, such arrays can also directly generate quantum states of light within the circuit. To clarify the similarities and distinctions between these two approaches of quantum walks, we conduct here a systematic comparison between linear waveguide arrays, injected with photons produced externally, and nonlinear arrays, where photon pairs are continuously generated via parametric down-conversion. We experimentally validate these predictions using III-V semiconductor nonlinear waveguide lattices with varied geometries, enabling us to tune the depth of the quantum walks over an order of magnitude and reveal the gradual emergence of non-classicality in the output state. Finally, we demonstrate an inverse-design approach to engineer \textit{aperiodic} waveguide arrays, whose optimized coupling profiles generate maximally entangled states such as the biphoton W-state. These results highlight the potential of continuously-coupled photonic systems to harness high-dimensional entanglement within compact architectures.

</details>


### [51] [Boltzmann to Lindblad: Classical and Quantum Approaches to Out-of-Equilibrium Statistical Mechanics](https://arxiv.org/abs/2512.11613)
*Stefano Giordano,Giuseppe Florio,Giuseppe Puglisi,Fabrizio Cleri,Ralf Blossey*

Main category: quant-ph

TL;DR: 该论文开发了一个将经典随机动力学扩展到量子领域的框架，通过广义朗之万方程和广义Klein-Kramers方程，确保与经典热力学一致并满足完全正性条件。


<details>
  <summary>Details</summary>
Motivation: 开放量子系统在现代纳米技术中至关重要，但构建同时符合经典热力学和完全正性的动力学模型是一个主要理论挑战。

Method: 首先构建经典广义朗之万方程，其中摩擦和噪声对称地作用于两个哈密顿方程；然后推导出用泊松括号表示的广义Klein-Kramers方程；最后通过正则量子化得到两种量子主方程（厄米和非厄米摩擦算子）。

Result: 该框架确保玻尔兹曼分布作为稳态解，满足热力学第一和第二定律；完全正性仅在摩擦和噪声同时包含在两个哈密顿方程中时得到保证；摩擦系数在厄米和非厄米表述中需满足相同的正性条件。

Conclusion: 该形式体系为推导量子版本的热力学定律提供了通用工具，可直接应用于广泛的非平衡纳米尺度系统，揭示了超越特定算子表示的普适性。

Abstract: Open quantum systems play a central role in contemporary nanoscale technologies, including molecular electronics, quantum heat engines, quantum computation and information processing. A major theoretical challenge is to construct dynamical models that are simultaneously consistent with classical thermodynamics and complete positivity. In this work, we develop a framework that addresses this issue by extending classical stochastic dynamics to the quantum domain. We begin by formulating a generalized Langevin equation in which both friction and noise act symmetrically on the two Hamiltonian equations. From this, we derive a generalized Klein-Kramers equation expressed in terms of Poisson brackets, and we show that it admits the Boltzmann distribution as its stationary solution while satisfying the first and second laws of thermodynamics along individual trajectories. Applying canonical quantization to this classical framework yields two distinct quantum master equations, depending on whether the friction operators are taken to be Hermitian or non-Hermitian. By analyzing the dynamics of a harmonic oscillator, we determine the conditions under which these equations reduce to a Lindblad-type generator. Our results demonstrate that complete positivity is ensured only when friction and noise are included in both Hamiltonian equations, thus fully justifying the classical construction. Moreover, we find that the friction coefficients must satisfy the same positivity condition in both the Hermitian and non-Hermitian formulations, revealing a form of universality that transcends the specific operator representation. The formalism offers a versatile tool for deriving quantum versions of the thermodynamic laws and is directly applicable to a wide class of nonequilibrium nanoscale systems.

</details>


### [52] [Tight bound for the total time in digital-analog quantum computation](https://arxiv.org/abs/2512.11619)
*Mikel Garcia-de-Andoin,Mikel Sanz*

Main category: quant-ph

TL;DR: 该论文改进了数字-模拟量子计算（DAQC）中实现任意幺正操作所需总时间上界的估计，提出了一个与耦合数量线性相关的紧致上界，为量子模拟和量子算法的时间资源评估提供了更精确的基准。


<details>
  <summary>Details</summary>
Motivation: 数字-模拟量子计算（DAQC）是一种结合纠缠哈密顿量演化和单量子比特门的通用计算范式。先前提出的实现这些演化所需总时间上界不够优化，需要改进这一关键参数的上界估计，以便更精确地评估量子模拟和量子算法的时间资源需求。

Method: 该研究改进了DAQC框架中实现任意幺正操作所需总时间上界的数学分析。通过分析将任意幺正操作分解为两体哈密顿量生成的演化序列的过程，提出了一个与耦合数量线性相关的紧致上界。

Result: 研究得出了一个紧致的总时间上界，该上界与耦合数量呈线性关系。这一改进的上界比先前提出的上界更优，能够更精确地估计在DAQC框架下实现量子模拟和量子算法所需的时间资源。

Conclusion: 该研究为数字-模拟量子计算提供了改进的时间资源上界估计，这一线性依赖关系使得能够更精确地评估DAQC框架下的计算效率，并为其与其他量子计算方法的严格比较提供了基础。

Abstract: Digital-analog quantum computing (DAQC) is a universal computational paradigm that combines the evolution under an entangling Hamiltonian with the application of single-qubit gates. Since any unitary operation can be decomposed into a sequence of evolutions generated by two-body Hamiltonians, DAQC is inherently well-suited for realizing such operations. Suboptimal upper bounds for the total time required to perform these evolutions have been previously proposed. Here, we improve these limits by providing a tight bound for this crucial parameter, which shows a linear dependence with the number of couplings. This result enables a precise estimation of the time resources needed for quantum simulations and quantum algorithms implemented within the DAQC framework, facilitating a rigorous comparison with other approaches.

</details>


### [53] [Shot-to-shot displacement noise in state-expansion protocols with inverted potentials](https://arxiv.org/abs/2512.11633)
*Giuseppe Paolo Seta,Louisiane Devaud,Lorenzo Dania,Lukas Novotny,Martin Frimmer*

Main category: quant-ph

TL;DR: 实验研究了光悬浮纳米粒子在暗反电势状态扩展协议中，由于电势对准的重复性限制导致的相干长度受限问题，识别了电场杂散和机械不稳定性为主要噪声源。


<details>
  <summary>Details</summary>
Motivation: 光悬浮纳米粒子是产生宏观量子态的有前景平台，但实验协议中不同电势对准的有限重复性会引入额外噪声，影响量子态的相干性。

Method: 通过实验研究和建模，分析暗反电势状态扩展协议中，电势对准的重复性限制如何影响悬浮纳米粒子的相干长度，识别主要噪声源。

Result: 识别了电场杂散和机械不稳定性是导致实验间波动的主要来源，这些波动限制了状态扩展协议中的相干长度。

Conclusion: 明确了利用反电势进行状态扩展协议时的实验要求，需要控制电场杂散和机械稳定性以提高相干性。

Abstract: Optically levitated nanoparticles are promising candidates for the generation of macroscopic quantum states of mechanical motion. Protocols to generate such states expose the particle to a succession of different potentials. Limited reproducibility of the alignment of these potentials across experimental realizations introduces additional noise. Here, we experimentally investigate and model how such shot-to-shot noise limits the coherence length of a levitated nanoparticle during a state-expansion protocol using a dark, inverted electrical potential. We identify electric stray fields and mechanical instabilities as major sources of shot-to-shot fluctuations. We discuss the resulting experimental requirements for state expansion protocols exploiting inverted potentials.

</details>


### [54] [Nuclear magnetic resonance on a single atom with a local probe](https://arxiv.org/abs/2512.11652)
*Hester G. Vennema,Cristina Mier,Evert W. Stolte,Leonard Edens,Jinwon Lee,Sander Otte*

Main category: quant-ph

TL;DR: 该研究首次在单个表面原子上实现了核磁共振测量，使用扫描探针技术探测了单个47Ti同位素的核自旋跃迁，为量子信息应用中的核自旋直接控制提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 核自旋因其与环境弱耦合和长相干时间而成为量子信息应用的理想候选，但这种弱耦合也使得核自旋的可寻址性面临挑战。研究旨在开发在原子尺度上直接控制和探测单个核自旋的方法。

Method: 采用局部扫描探针技术，结合电子-核双共振测量方案，在单个表面原子上进行核磁共振测量。利用四极相互作用解析单个47Ti同位素（核自旋I=5/2）的多个核磁共振跃迁，并与本征能计算进行比较验证。

Result: 成功实现了单个表面原子的核磁共振测量，解析了多个核磁共振跃迁，与理论计算一致。实验结果表明，无论核自旋与电子自旋的杂化程度如何，核自旋都能被高效驱动，这对于在长寿命区域内直接控制核自旋至关重要。

Conclusion: 这项研究为在原子尺度平台上实现单个核自旋的核磁共振测量提供了重要进展，对于将核自旋应用于表征技术或量子信息技术具有重要价值，为其他平台部署核自旋技术奠定了基础。

Abstract: The nuclear spin is a prime candidate for quantum information applications due to its weak coupling to the environment and inherently long coherence times. However, this weak coupling also challenges the addressability of the nuclear spin. Here we demonstrate nuclear magnetic resonance (NMR) on a single on-surface atom using a local scanning probe. We employ an electron-nuclear double resonance measurement scheme and resolve nuclear spin transitions of a single 47Ti isotope with a nuclear spin of I = 5/2. The quadrupole interaction enables to resolve multiple NMR transitions, which are consistent with our eigenenergy calculations. Our experimental results indicate that the nuclear spin can be driven efficiently irrespective of its hybridization with the electron spin, which is required for direct control of the nuclear spin in the long-lifetime regime. This investigation of NMR on a single atom in a platform with atomic-scale control is a valuable development for other platforms deploying nuclear spins for characterization techniques or quantum information technology.

</details>


### [55] [Tailored Error Mitigation for Single-Qubit Magnetometry](https://arxiv.org/abs/2512.11671)
*Miriam Resch,Dennis Herb,Mirko Rossini,Joachim Ankerhold,Dominik Maile*

Main category: quant-ph

TL;DR: 提出一种量子传感噪声缓解技术，通过预表征设备噪声特性，自动适应耗散演化复杂性，指示最优传感时间，在单NV中心磁力测量中实现最佳灵敏度。


<details>
  <summary>Details</summary>
Motivation: 量子传感器虽然具有超越经典方法的精度和空间分辨率潜力，但其高灵敏度也使其对环境噪声高度敏感。现有量子误差缓解技术利用噪声信息改善测量结果，但需要更有效的噪声逆转方法。

Method: 提出一种新颖的量子传感器缓解技术，能够高效逆转任何可由完全正定保迹映射描述的噪声效应。方法利用设备预表征步骤获取的知识，自动适应耗散演化的复杂性，并指示实现最准确结果的最优传感时间τ。

Result: 该方法在单NV中心磁力测量中达到了噪声环境下可实现的最佳灵敏度，验证了技术的有效性。

Conclusion: 这项工作是朝着构建更具弹性、具有最小分辨率尺度的量子传感器迈出的重要一步，为量子传感的实际应用提供了有效的噪声缓解方案。

Abstract: Quantum sensing is an emerging field with the potential to outperform classical methods in both precision and spatial resolution. However, the sensitivity of the underlying quantum platform also makes the sensors highly susceptible to their environmental noise. To address this issue, techniques from the field of quantum error mitigation use information about the noise to improve measurement results. We present a novel mitigation technique for quantum sensors to efficiently reverse the effects of any noise that can be described by a completely positive trace preserving map. The method leverages the knowledge acquired by a pre-characterization step of the device to automatically adapt to the complexity of the dissipative evolution and to indicate optimal sensing times $τ$ to achieve the most accurate results. We demonstrate that our method reaches the best achievable sensitivity in noisy single-NV-center magnetometry.
  This work marks a further step toward more resilient quantum sensors with the smallest scale of resolution.

</details>


### [56] [Hardware Efficient Quantum Kernels Using Multimode Bulk Acoustic Resonators](https://arxiv.org/abs/2512.11672)
*Collin C. D. Frink,Chaoyang Ti,Stephen K. Gray,Xu Han,Matthew Otten*

Main category: quant-ph

TL;DR: 该论文提出了一种基于克尔非线性器件的量子核设计方法，通过时间相关模拟展示了量子增强核的计算优势


<details>
  <summary>Details</summary>
Motivation: 传统核技巧在处理高维数据集时面临计算复杂度和数据效率的挑战，需要探索量子计算方法来克服这些限制

Method: 扩展了克尔非线性器件的量子核设计，实现了克尔量子比特与声学谐振器耦合的时间相关模拟，利用克尔非线性诱导多模系统的非经典行为来定义量子增强核

Result: 在实验可行参数下，克尔非线性成功诱导了多模系统的非经典行为，并展示了随着谐振器数量增加，经典模拟该核的计算难度呈指数增长

Conclusion: 基于克尔非线性器件的量子核设计为机器学习中的核计算提供了量子优势，随着系统规模扩大，其经典模拟的不可行性证明了量子增强核的潜在计算优势

Abstract: The kernel trick is a widely applicable technique in machine learning domains that maps datasets that are difficult to classify into a computationally friendly feature space. As the dimension of the dataset scales, these kernel calculations can quickly become computationally intractable or data inefficient. In this work, we extend prior efforts in quantum kernel design for Kerr nonlinear devices by implementing time-dependent simulations of a Kerr-qubit coupled to acoustic resonators. For experimentally feasible parameters, we demonstrate that the Kerr nonlinearity directly induces non-classical behavior in the multimode system, which we use to define and analyze a quantum-enhanced kernel. Finally, we present a brief scaling characterization that demonstrates the computational intractability of classically simulating the kernel as the number of resonators scales.

</details>


### [57] [Optimal Control of Coupled Sensor-Ancilla Qubits for Multiparameter Estimation](https://arxiv.org/abs/2512.11673)
*Ayumi Kanamoto,Takuya Isogawa,Shunsuke Nishimura,Haidong Yuan,Paola Cappellaro*

Main category: quant-ph

TL;DR: 使用GRAPE算法优化两量子比特传感器-辅助系统的控制脉冲，实现多参数量子传感的高精度测量


<details>
  <summary>Details</summary>
Motivation: 多参数量子传感的最优控制设计对接近最终精度极限至关重要，但解析解通常只适用于简单系统，而现实场景常涉及耦合量子比特和含时哈密顿量

Method: 采用梯度上升脉冲工程(GRAPE)算法，通过递归优化策略（从较小耦合强度的解作为初始猜测），优化两量子比特传感器-辅助系统的控制脉冲以最小化目标函数

Result: 该方法在广泛的相互作用强度和场配置范围内实现了稳健收敛和高精度，为高灵敏度、鲁棒的多参数磁强计提供了实用途径

Conclusion: 所提出的方法适用于固态量子传感器（如金刚石氮空位中心）在现实实验环境中的应用，为多参数量子传感提供了有效的数值优化方案

Abstract: Designing optimal control for multiparameter quantum sensing is essential for approaching the ultimate precision limits. However, analytical solutions are generally available only for simple systems, while realistic scenarios often involve coupled qubits and time-dependent Hamiltonians. Here we numerically investigate optimal control of a two-qubit sensor-ancilla system coupled via an Ising term using Gradient Ascent Pulse Engineering (GRAPE) to minimize the objective function. By seeding the optimization recursively with solutions obtained for smaller coupling strengths and selecting a suitable initial guess, we achieve robust convergence and high precision across a wide range of interaction strengths and field configurations. The proposed approach offers a practical route toward high-sensitivity, robust multiparameter magnetometry and it is applicable to solid-state quantum sensors such as nitrogen-vacancy (NV) centers in realistic experimental settings.

</details>


### [58] [Bloch oscillation in a Floquet engineering quadratic potential system](https://arxiv.org/abs/2512.11675)
*J. Cao,H. Shen,R. Wang,X. Z. Zhang*

Main category: quant-ph

TL;DR: 研究一维紧束缚晶格在空间二次型时间周期势驱动下的量子动力学，分析了厄米和非厄米跳跃机制，通过Floquet理论发现临界频率下出现准等间距能级，导致鲁棒的周期性复兴和类Bloch振荡。


<details>
  <summary>Details</summary>
Motivation: 研究周期驱动下量子系统的动力学行为，特别是探索在非厄米系统中如何通过外部驱动实现稳定的相干振荡和能级规律性。

Method: 采用Floquet理论，将含时哈密顿量映射到有效静态Floquet哈密顿量，分析准能谱和本征态局域化，通过数值模拟研究厄米和非厄米跳跃机制下的动力学行为。

Result: 发现临界频率ω_c下出现几乎等间距的准能级阶梯，伴随能级间距归一化方差的最小值和平均逆参与率的峰值，导致鲁棒的周期性复兴和类Bloch振荡，即使在非厄米机制下也能保持相干振荡。

Conclusion: 周期驱动能够在厄米和非厄米系统中诱导出高度规则的准能谱结构，实现稳定的相干动力学行为，为控制量子系统中的输运和相干性提供了新途径。

Abstract: We investigate the quantum dynamics of a one-dimensional tight-binding lattice driven by a spatially quadratic and time-periodic potential. Both Hermitian ($J_1 = J_2$) and non-Hermitian ($J_1 \neq J_2$) hopping regimes are analyzed. Within the framework of Floquet theory, the time-dependent Hamiltonian is mapped onto an effective static Floquet Hamiltonian, enabling a detailed study of the quasi-energy spectrum and eigenstate localization as function of the driving frequency $ω$. We identify critical frequencies $ω_c$ at which nearly equidistant quasi-energy ladders emerge, characterized by a pronounced minimum in the normalized variance of level spacings. This spectral regularity, which coincides with a peak in the mean inverse participation ratio (\textrm{MIPR}), leads to robust periodic revivals and Bloch-like oscillations in the time evolution. Numerical simulations confirm that such coherent oscillations persist even in the non-Hermitian regime, where the periodic driving stabilizes an almost real and uniformly spaced quasi-energy ladder.

</details>


### [59] [Spectral side channels in quantum key distribution under laser damage](https://arxiv.org/abs/2512.11701)
*Binwu Gao,Junxuan Liu,Ekaterina Borisova,Hao Tan,Mingyang Zhong,Zihao Chen,Qingquan Peng,Weixu Shi,Anastasiya Ponosova,Vadim Makarov,Anqi Huang*

Main category: quant-ph

TL;DR: 研究密集波分复用器在量子密钥分发系统中的激光注入攻击下的行为特性，发现特定DWDM样品在高功率激光照射下会出现显著的光谱特征变化，这种侧信道攻击会显著降低量子密钥分发的安全传输距离。


<details>
  <summary>Details</summary>
Motivation: 在量子密钥分发系统的发射端，密集波分复用器通常用于合并量子信号和同步信号，并直接连接到量子信道，因此成为激光注入攻击的首个暴露光学元件。理解DWDM在此类攻击下的行为对于评估QKD系统的实际安全性至关重要。

Method: 系统研究DWDM在高功率激光照射下的特性，通过实验观察特定DWDM样品在注入激光功率超过特定阈值时的光谱特征变化。以特洛伊木马攻击为例，对由此产生的光谱侧信道进行理论分析。

Result: 实验结果显示某些DWDM样品在注入激光功率超过特定阈值时会出现显著的光谱特征变化。理论分析表明，这种光谱侧信道攻击可以将最大安全传输距离降低到原始值的66.9%以下。

Conclusion: 通过结合实验观察和理论建模，本研究增进了对DWDM影响QKD系统实际安全性的理解，揭示了激光注入攻击可能通过DWDM组件创建安全漏洞，显著降低系统的安全性能。

Abstract: In the transmitter of a quantum key distribution (QKD) system, a dense wavelength-division multiplexer (DWDM) is typically used to combine quantum and synchronization signals and is directly connected to the quantum channel. As a result, it becomes the first optical component exposed to laser-injection attacks. Therefore, understanding the behavior of DWDMs under such attacks is essential for assessing the practical security of QKD systems. In this work, we systematically investigate the characteristics of DWDMs under high-power laser illumination. Our experimental results show that certain DWDM samples exhibit pronounced changes in their spectral features once the injected laser power surpasses a specific threshold. Taking the Trojan-horse attack as an illustrative example, we further perform a theoretical analysis of the resulting spectral side channel and show that it can reduce the maximum secure transmission distance to below 66.9% of its original value. By combining experimental observations with theoretical modeling, this study advances the understanding of the influence of DWDMs on the practical security of QKD systems.

</details>


### [60] [Thermal interaction-free ghost imaging](https://arxiv.org/abs/2512.11709)
*Shun Li,Jing-Yang Xiao Feng,Xiu-Qing Yang,Xiaodong Zeng,Xi-Hua Yang,M. Al-Amri,Zheng-Hong Li*

Main category: quant-ph

TL;DR: 提出基于热光源的无相互作用鬼成像方案，利用类量子芝诺效应减少样品吸收的光剂量，避免光-物质相互作用导致的样品损伤，同时无需纠缠光子源和单光子探测器，显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 传统鬼成像技术中光-物质相互作用可能导致光敏感样品损伤，且通常需要昂贵的纠缠光子源和单光子探测器，限制了其在生命科学等领域的应用。

Method: 采用热光源，利用类量子芝诺效应减少样品吸收的光剂量，避免使用纠缠光子源和单光子探测器，通过可控光子损耗主动抑制背景噪声。

Result: 显著减少样品吸收的光剂量，有效防止样品损伤；相比传统鬼成像，能利用更多光子进行图像重建，显著提升图像质量；实现背景噪声的主动抑制。

Conclusion: 该工作为生命科学等领域的光敏感样品提供了一种实用且经济高效的无损高质量成像途径。

Abstract: We propose an interaction-free ghost imaging scheme based on a thermal light source. By utilizing the quantum Zeno-like effect, our approach significantly reduces the light dose absorbed by the sample, thereby effectively preventing sample damage induced by light-matter interactions. Combined with the elimination of entangled photon sources and single-photon detectors, our approach enables significantly more photons to be utilized for image reconstruction, thereby markedly enhancing image quality compared to conventional ghost imaging. We further demonstrate active suppression of background noise via controllable photon loss. Our work offers a practical and cost-effective route to non-destructive, high-quality imaging for light-sensitive samples in fields such as life sciences.

</details>


### [61] [Real-Time Polarization Control for Satellite QKD with Liquid-Crystal Beacon Stabilization](https://arxiv.org/abs/2512.11714)
*Ondrej Klicnik,Alessandro Zannotti,Yannick Folwill,Oliver de Vries,Petr Munster,Tomas Horvath*

Main category: quant-ph

TL;DR: 该论文提出了一种用于卫星量子密钥分发中偏振纠缠态的实时偏振补偿方法，使用液晶可变延迟器来补偿大气效应和平台运动引起的偏振旋转。


<details>
  <summary>Details</summary>
Motivation: 偏振不稳定性是偏振纠缠卫星量子密钥分发面临的关键挑战，大气效应和平台运动会持续扭曲光子偏振态，必须精确识别和补偿这些变换以保持纠缠保真度。

Method: 使用液晶可变延迟器作为紧凑快速的偏振补偿方法，通过表征经典参考信号（信标）的信道诱导偏振旋转，实现卫星量子密钥分发链路的实时偏振跟踪。

Result: 该方法能够实现实时偏振补偿，为卫星量子密钥分发链路提供有效的偏振跟踪解决方案。

Conclusion: 液晶可变延迟器提供了一种紧凑、快速的偏振补偿方法，能够有效应对卫星量子密钥分发中的偏振不稳定性问题，为偏振纠缠态的实时跟踪和补偿提供了可行方案。

Abstract: Polarization instability is a critical challenge for polarization-entangled satellite quantum key distribution (QKD), where atmospheric effects and platform motion continuously distort photon polarization. To maintain entanglement fidelity, these transformations must be precisely identified and compensated before detection. The channel-induced polarization rotation of a classical reference signal (beacon) is characterized using liquidcrystal variable retarders as a compact and fast polarizationcompensation approach, enabling real-time polarization tracking for satellite QKD links.

</details>


### [62] [Qubits in second quantisation in fermionic simulators](https://arxiv.org/abs/2512.11726)
*Ahana Ghoshal,Carlos de Gois,Kiara Hansenne,Otfried Gühne,Hai-Chau Nguyen*

Main category: quant-ph

TL;DR: 该论文提出了一种将费米子模式配对形成"二次量子化量子比特"的方法，使费米子门可以表示为这些二次量子化量子比特的旋转，从而能够将量子比特系统的方法应用于费米子模拟器。


<details>
  <summary>Details</summary>
Motivation: 传统基于量子比特的量子计算机模拟多体费米子系统面临重大挑战，因为需要编码费米子统计特性导致额外开销。虽然原生费米子模拟器能高效模拟费米子问题，但这类模拟器也有特定约束和量子比特系统不熟悉的挑战。

Method: 提出将费米子模式配对形成"二次量子化量子比特"的方法，使费米子门可以表示为这些二次量子化量子比特的旋转。应用此配对方案，将费米子模拟器中二点和四点关联函数的测量表示为其原生门的图问题，并使用各种分析和算法方法优化测量设置。

Result: 该方法能够将量子比特系统的方法适应到费米子模拟器中，通过图问题表示关联函数测量，并提供了测量设置的优化方法。

Conclusion: 提出的费米子模式配对方案为费米子模拟器提供了一种新框架，能够利用量子比特系统的现有方法和技术，特别是在关联函数测量优化方面具有应用价值。

Abstract: Simulating many-body fermionic systems in conventional qubit-based quantum computers poses significant challenges due to the overheads associated with the encoding of fermionic statistics in qubits, leading to the proposal of native fermionic simulators as an alternative. While allowing for fermionic problems to be simulated efficiently, this class of fermionic simulators carries also specific constraints with them and poses other challenges unfamiliar to qubit systems. Here, we propose to pair fermionic modes to form a so-called qubit in second quantisation representation. This allows fermionic gates to be represented as rotations of these second quantised qubits, enabling adaptation of methods for qubit systems. As an application, we use this pairing scheme to represent the measurement of two- and four-point correlators in fermionic simulators with its native gates as a graph problem. Optimising measurement settings is then analysed with various analytical and algorithmic methods.

</details>


### [63] [Entanglement generation in qubit-ADAPT-VQE through four-qubit algebraic classification](https://arxiv.org/abs/2512.11729)
*Diego Tancara,Herbert Díaz-Moraga,Vicente Sepúlveda-Trivelli,Dardo Goyeneche*

Main category: quant-ph

TL;DR: 该研究评估了qubit-ADAPT-VQE算法在具有高纠缠度的自旋模型基态估计中的表现，发现该算法能够准确达到所有纠缠类别的基态。


<details>
  <summary>Details</summary>
Motivation: 虽然ADAPT-VQE算法在分子哈密顿量（基态通常具有低纠缠度）上得到了广泛验证，但其在高纠缠度基态中的性能尚未充分探索。本研究旨在评估qubit-ADAPT-VQE算法在具有显著纠缠度的自旋模型基态估计中的表现。

Method: 研究采用qubit-ADAPT-VQE算法的变体，专注于四量子比特系统。使用代数纠缠分类来识别基态中的不同纠缠类别，并为每个类别选择一个代表性初始状态来评估算法性能。

Result: 研究结果表明qubit-ADAPT-VQE算法具有很好的通用性，能够准确达到所有纠缠类别的基态，无论初始能量值如何。

Conclusion: qubit-ADAPT-VQE算法在具有高纠缠度的自旋模型基态估计中表现出色，能够克服贫瘠高原问题并准确达到各种纠缠类别的基态。

Abstract: While variational quantum algorithms are among the most promising approaches for the noisy intermediate-scale quantum (NISQ) era, their scalability is often hindered by the barren plateau problem. Among the proposals that have demonstrated robustness against this issue, the ADAPT-VQE algorithm stands out for ground state estimation, primarily due to its iterative ansatz construction. Although ADAPT-VQE has been extensively benchmarked on molecular Hamiltonians, where the ground states typically exhibit low entanglement, its performance for highly entangled ground states remains largely unexplored. In this work, we explore a variant of this algorithm known as qubit-ADAPT-VQE, assessing its ability to achieve ground states with substantial entanglement in spin models. We focus on four-qubit systems and employ an algebraic entanglement classification to identify distinct entanglement classes among ground states, and consider a representative of each class as an initial state to evaluate the performance of the algorithm. Our findings highlight the versatility of qubit-ADAPT-VQE, demonstrating that it accurately reaches the ground state across all entanglement classes and initial energy values.

</details>


### [64] [CNOT gates in inductively coupled multi-fluxonium systems](https://arxiv.org/abs/2512.11756)
*Valeria Díaz Moreno,Nikola D. Dimitrov,Vladimir E. Manucharyan,Maxim G. Vavilov*

Main category: quant-ph

TL;DR: 四量子比特fluxonium系统中，旁观量子比特对CNOT门性能影响的研究表明，当旁观量子比特与活跃量子比特频率充分失谐时，旁观诱导误差被强烈抑制，可实现低于10^-4的CNOT门误差。


<details>
  <summary>Details</summary>
Motivation: 虽然双量子比特fluxonium系统已实现高保真度双量子比特门，但构建可扩展量子处理器需要在更大架构中保持低错误率。本研究旨在分析四量子比特耦合系统中旁观量子比特对CNOT门性能的影响。

Method: 分析四个电感耦合的fluxonium量子比特系统，研究旁观量子比特对CNOT门性能的影响。通过识别有利的频率配置，探索在近邻耦合局域性基础上向更长链扩展的可能性。

Result: 当旁观量子比特的跃迁频率与活跃量子比特充分失谐时，旁观诱导误差被强烈抑制。找到了四量子比特链的有利频率配置，可在100纳秒门时间内实现低于10^-4的CNOT门误差。

Conclusion: 利用近邻耦合的局域性，研究结果可外推到更长的fluxonium链，为构建可扩展、低错误的量子信息处理系统提供了可行路径。

Abstract: High-fidelity two-qubit gates have been demonstrated in systems of two fluxonium qubits; however, the realization of scalable quantum processors requires maintaining low error rates in substantially larger architectures. In this work, we analyze a system of four inductively coupled fluxonium qubits to determine the impact of spectator qubits on the performance of a \textsc{cnot} gate. Our results show that spectator-induced errors are strongly suppressed when the transition frequencies of the spectator qubits are sufficiently detuned from those of the active qubits. We identify favorable frequency configurations for the four-qubit chain that yield \textsc{cnot} gate errors below $10^{-4}$ for gate times shorter than 100 ns. Leveraging the locality of the nearest-neighbor coupling, we extrapolate our findings to longer fluxonium chains, suggesting a viable path toward scalable, low-error quantum information processing.

</details>


### [65] [Computing the molecular ground state energy in a restricted active space using quantum annealing](https://arxiv.org/abs/2512.11757)
*Stefano Bruni,Enrico Prati*

Main category: quant-ph

TL;DR: 该研究将水分子基态能量计算映射为伊辛模型，采用XBK方法和改进的量子退火策略，相比先前方法显著提升了求解精度和规模。


<details>
  <summary>Details</summary>
Motivation: 传统量子化学方法（如CASCI）在计算分子基态能量时存在指数级计算复杂度问题，限制了其在大分子体系中的应用。量子计算为这一问题提供了有前景的替代方案，但先前的研究受限于硬件性能和退火技术。

Method: 使用Xian-Bias-Kas (XBK)方法将H₂O分子的基态问题映射到伊辛哈密顿量，利用增强的量子比特连接性和更短的嵌入链，结合先进的退火策略进行求解。

Result: 相比最先进的前代方法，获得Hartree-Fock水平解的概率提高了一倍以上；能够处理比先前最大实例多近2.5倍物理嵌入量子比特的问题；退火结果改善了两个数量级，达到与Hartree-Fock能量差0.120 Hartree的精度。

Conclusion: 这些结果表明在NISQ时代量子退火应用取得了实质性进展，为实际量子化学计算提供了有前景的路径。

Abstract: Calculating the molecular ground-state energy is a central challenge in computational chemistry. Conventional methods such as the Complete Active Space Configuration Interaction scale exponentially with molecular size, limiting their applicability to large molecules. Quantum computing offers a promising alternative by mapping molecular Hamiltonians by qubits, enabling cheaper computational scaling. Previous studies have shown that it is possible to formulate molecular ground state calculations as discrete optimization problems, addressable by quantum annealing. However, these efforts have been limited by previous generations of hardware and suboptimal annealing techniques. Here, the $H_{2}O$ ground-state problem is mapped to an Ising Hamiltonian using the Xian-Bias-Kas (XBK) method. By taking advantage of enhanced qubit connectivity and shorter embedding chains, it is solved with a more than doubled probability of achieving Hartree-Fock-level solutions with respect to the most advanced predecessor. Advanced annealing strategies extend Hartree-Fock-level accuracy to significantly larger problem instances, enabling solutions that use nearly 2.5 times more physically embedded qubits than the largest cases previously reported and allowing to improve annealing results by two orders of magnitude, reaching an energy difference of 0.120~Hartree relative to Hartree-Fock. These results show tangible progress toward practical quantum annealing applications in NISQ era.

</details>


### [66] [A Vlasov-Bohm approach to Quantum Mechanics for statistical systems](https://arxiv.org/abs/2512.11772)
*Pedro Luis Grande,Raul Carlos Fadanelli,Maarten Vos*

Main category: quant-ph

TL;DR: 论文展示了如何将玻姆量子势纳入弗拉索夫框架，建立一种能捕捉物质粒子性的平均场理论，在随机相位近似下与量子力学一致。


<details>
  <summary>Details</summary>
Motivation: 量子力学有多种表述方式，包括玻姆力学。本文旨在探索玻姆量子势作为经典非相对论系统量子化的起点，将其与弗拉索夫框架结合，建立一种新的量子化方法。

Method: 将玻姆量子势纳入弗拉索夫框架，构建平均场理论。该方法利用玻姆力学中的量子势概念，在弗拉索夫方程中引入量子修正，从而实现对经典系统的量子化描述。

Result: 所建立的玻姆-弗拉索夫平均场理论能够捕捉物质的粒子性，在随机相位近似下与标准量子力学结果一致，验证了玻姆量子势作为量子化起点的有效性。

Conclusion: 玻姆力学中的量子势概念可以作为经典非相对论系统量子化的有效起点，通过弗拉索夫框架构建的平均场理论在随机相位近似下与量子力学一致，为量子化提供了新的视角。

Abstract: Quantum mechanics is the most successful theory to describe microscopic phenomena. It was derived in different ways over the past 100 years by Heisenberg, Schrödinger, and Feynman. At the same time, other interpretations have been suggested, including the Bohm-De Broglie interpretation and the so-called Bohmian mechanics. Here, we show that Bohmian mechanics, which utilizes the concept of the Bohm quantum potential, can also serve as a starting point for quantizing classical non-relativistic systems. By incorporating the Bohm quantum potential into the Vlasov framework, we obtain a mean-field theory that captures the corpuscular nature of matter, in agreement with quantum mechanics within the Random Phase Approximation (RPA).

</details>


### [67] [A Room-Temperature Extreme High Vacuum System for Trapped-Ion Quantum Information Processing](https://arxiv.org/abs/2512.11794)
*Lewis Hahn,Nikhil Kotibhaskar,Fabien Lefebvre,Sakshee Patil,Sainath Motlakunta,Mahmood Sabooni,Rajibul Islam*

Main category: quant-ph

TL;DR: 研究人员开发了一种室温极端高真空系统，用于延长囚禁离子量子处理器的连续运行时间，通过优化腔室设计、高温热处理和局部压力测量，将离子位置的碰撞间隔延长至1.9小时/离子。


<details>
  <summary>Details</summary>
Motivation: 背景气体碰撞限制了囚禁离子量子处理器的性能和可扩展性，会中断算法执行甚至将离子弹出阱外。现有系统需要低温设备，研究人员希望开发一种室温系统来延长量子处理器的连续运行时间。

Method: 1. 使用分子流模拟优化腔室几何、传导路径和泵浦配置；2. 对不锈钢真空组件进行高温热处理，将H₂出气率降低至10⁻¹⁵ mbar·l·s⁻¹·cm⁻²水平；3. 通过观察混合同位素Yb⁺离子链中的碰撞诱导重排事件来测量离子位置的局部压力。

Result: 1. 腔室最终压力为1.5×10⁻¹² mbar（达到测量极限）；2. 离子位置碰撞间隔为(1.9±0.1)小时/离子；3. 对应局部压力为(3.9±0.3)×10⁻¹² mbar；4. 实现了量子处理器连续运行时间的显著延长。

Conclusion: 该研究成功开发了一种室温极端高真空系统，无需低温设备即可显著延长囚禁离子量子处理器的连续运行时间，为量子计算系统的可扩展性提供了重要技术支持。

Abstract: We present a room-temperature Extreme High Vacuum (XHV) system engineered to support the long-duration operation of a trapped-ion quantum processor. Background-gas collisions impose limitations on trapped-ion performance and scalability by interrupting algorithmic execution and, in some cases, ejecting ions from the trap. Using molecular-flow simulations, we optimize the chamber geometry, conductance pathways, and pumping configuration to maximize the effective pumping speed at the ion location. We perform high-temperature heat treatment of stainless steel vacuum components to achieve the desired outgassing rate, guided by quantitative relations of bulk diffusive processes, allowing us to reduce the \(\mathrm{H_2}\) outgassing load to the \(10^{-15}\,\mathrm{mbar\,l\,s^{-1}\,cm^{-2}}\) level. The final pressure in our chamber, measured by a hot cathode gauge, is \(1.5\times10^{-12}\,\mathrm{mbar}\), corresponding to the gauge's measurement limit. We measure the local pressure at the ion location by observing collision-induced reordering events in a long ion chain of mixed-isotope Yb\(^+\). From the observed reordering frequency, we extract the average interval between collisions to be \((1.9 \pm 0.1)\,\mathrm{hrs/ion}\). This corresponds to a local pressure of \((3.9 \pm 0.3)\times10^{-12}\,\mathrm{mbar}\) at the ion location, assuming that all collisions arise from background H\(_2\) molecules at room temperature. Our demonstration extends the continuous operation time of a quantum processor while maintaining the simplicity of a room-temperature system that does not require cryogenic apparatus.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [68] [TECM*: A Data-Driven Assessment to Reinforcement Learning Methods and Application to Heparin Treatment Strategy for Surgical Sepsis](https://arxiv.org/abs/2512.10973)
*Jiang Liu,Yujie Li,Chan Zhou,Yihao Xie,Qilong Sun,Xin Shu,Peiwei Li,Chunyong Yang,Yiziting Zhu,Jiaqi Zhu,Yuwen Chen,Bo An,Hao Wu,Bin Yi*

Main category: cs.LG

TL;DR: 该研究提出了一种基于强化学习的框架，通过连续cxSOFA评分和治疗效果比较矩阵来优化外科脓毒症患者的肝素治疗策略，显著降低了死亡率和住院时间。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是一种危及生命的严重感染疾病，需要优化肝素治疗策略。传统离散SOFA评分无法提供连续的状态评估，需要更精细的数据驱动方法来个性化治疗。

Method: 使用MIMIC-IV和eICU数据库数据，提出强化学习框架：1) 将离散SOFA转换为连续cxSOFA评分；2) 基于cxSOFA定义"好/坏"治疗策略；3) 提出治疗效果比较矩阵(TECM)评估策略。应用Q-Learning、DQN、DDQN、BCQ和CQL等算法优化治疗。

Result: cxSOFA-CQL模型表现最佳，将死亡率从1.83%降至0.74%，平均住院时间从11.11天缩短至9.42天。TECM在不同模型中显示一致结果，验证了框架的鲁棒性。

Conclusion: 该强化学习框架为外科脓毒症肝素治疗提供了可解释且鲁棒的优化方法，连续cxSOFA评分和TECM评估为治疗决策提供了更精细的评估，有望改善临床结果和决策支持可靠性。

Abstract: Objective: Sepsis is a life-threatening condition caused by severe infection leading to acute organ dysfunction. This study proposes a data-driven metric and a continuous reward function to optimize personalized heparin therapy in surgical sepsis patients. Methods: Data from the MIMIC-IV v1.0 and eICU v2.0 databases were used for model development and evaluation. The training cohort consisted of abdominal surgery patients receiving unfractionated heparin (UFH) after postoperative sepsis onset. We introduce a new RL-based framework: converting the discrete SOFA score to a continuous cxSOFA for more nuanced state and reward functions; Second, defining "good" or "bad" strategies based on cxSOFA by a stepwise manner; Third, proposing a Treatment Effect Comparison Matrix (TECM), analogous to a confusion matrix for classification tasks, to evaluate the treatment strategies. We applied different RL algorithms, Q-Learning, DQN, DDQN, BCQ and CQL to optimize the treatment and comprehensively evaluated the framework. Results: Among the AI-derived strategies, the cxSOFA-CQL model achieved the best performance, reducing mortality from 1.83% to 0.74% with the average hospital stay from 11.11 to 9.42 days. TECM demonstrated consistent outcomes across models, highlighting robustness. Conclusion: The proposed RL framework enables interpretable and robust optimization of heparin therapy in surgical sepsis. Continuous cxSOFA scoring and TECM-based evaluation provide nuanced treatment assessment, showing promise for improving clinical outcomes and decision-support reliability.

</details>


### [69] [Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems](https://arxiv.org/abs/2512.10975)
*Matvey Nepomnyaschiy,Oleg Pereziabov,Anvar Tliamov,Stanislav Mikhailov,Ilya Afanasyev*

Main category: cs.LG

TL;DR: 提出一种多智能体框架用于训练多模态情感识别系统，通过模块化架构实现模态灵活集成和训练效率提升


<details>
  <summary>Details</summary>
Motivation: 传统多模态深度学习模型虽然情感识别准确率高，但训练和维护计算量大，且对模态变化不灵活，需要更高效、可扩展的解决方案

Method: 采用多智能体框架，每个模态编码器和融合分类器作为自主智能体，由中央监督器协调，支持模块化集成新模态（如emotion2vec音频特征）和组件替换

Result: 通过支持视觉、音频和文本模态的概念验证实现，证明该框架可行，分类器作为共享决策智能体，提高了训练效率

Conclusion: 该框架不仅提升训练效率，还为HAI场景中的具身和虚拟智能体设计更灵活、可扩展、可维护的感知模块做出贡献

Abstract: Effective human-agent interaction (HAI) relies on accurate and adaptive perception of human emotional states. While multimodal deep learning models - leveraging facial expressions, speech, and textual cues - offer high accuracy in emotion recognition, their training and maintenance are often computationally intensive and inflexible to modality changes. In this work, we propose a novel multi-agent framework for training multimodal emotion recognition systems, where each modality encoder and the fusion classifier operate as autonomous agents coordinated by a central supervisor. This architecture enables modular integration of new modalities (e.g., audio features via emotion2vec), seamless replacement of outdated components, and reduced computational overhead during training. We demonstrate the feasibility of our approach through a proof-of-concept implementation supporting vision, audio, and text modalities, with the classifier serving as a shared decision-making agent. Our framework not only improves training efficiency but also contributes to the design of more flexible, scalable, and maintainable perception modules for embodied and virtual agents in HAI scenarios.

</details>


### [70] [MolSculpt: Sculpting 3D Molecular Geometries from Chemical Syntax](https://arxiv.org/abs/2512.10991)
*Zhanpeng Chen,Weihao Gao,Shunyu Wang,Yanan Zhu,Hong Meng,Yuexian Zou*

Main category: cs.LG

TL;DR: MolSculpt是一个新颖的3D分子生成框架，通过将冻结的1D分子基础模型与3D分子扩散模型结合，利用可学习查询提取化学知识并注入扩散模型，实现从化学语法到3D几何结构的"雕刻"式生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽然使用SELFIES等1D表示来确保分子有效性，但未能充分利用1D模型中蕴含的丰富化学知识，导致1D语法生成与3D几何实现之间存在脱节。

Method: 提出MolSculpt框架：1) 基于冻结的1D分子基础模型和3D分子扩散模型；2) 引入可学习查询从基础模型中提取内在化学知识；3) 通过可训练投影器将跨模态信息注入扩散模型的条件空间，指导3D几何生成；4) 通过端到端优化将1D潜在化学知识深度整合到3D生成过程中。

Result: 在GEOM-DRUGS和QM9数据集上，MolSculpt在从头3D分子生成和条件3D分子生成方面实现了最先进的性能，表现出优异的3D保真度和稳定性。

Conclusion: MolSculpt成功弥合了1D化学语法与3D几何生成之间的鸿沟，通过深度整合1D潜在化学知识，为药物发现和材料科学提供了精确的3D分子几何生成解决方案。

Abstract: Generating precise 3D molecular geometries is crucial for drug discovery and material science. While prior efforts leverage 1D representations like SELFIES to ensure molecular validity, they fail to fully exploit the rich chemical knowledge entangled within 1D models, leading to a disconnect between 1D syntactic generation and 3D geometric realization. To bridge this gap, we propose MolSculpt, a novel framework that "sculpts" 3D molecular geometries from chemical syntax. MolSculpt is built upon a frozen 1D molecular foundation model and a 3D molecular diffusion model. We introduce a set of learnable queries to extract inherent chemical knowledge from the foundation model, and a trainable projector then injects this cross-modal information into the conditioning space of the diffusion model to guide the 3D geometry generation. In this way, our model deeply integrates 1D latent chemical knowledge into the 3D generation process through end-to-end optimization. Experiments demonstrate that MolSculpt achieves state-of-the-art (SOTA) performance in \textit{de novo} 3D molecule generation and conditional 3D molecule generation, showing superior 3D fidelity and stability on both the GEOM-DRUGS and QM9 datasets. Code is available at https://github.com/SakuraTroyChen/MolSculpt.

</details>


### [71] [Memoryless Policy Iteration for Episodic POMDPs](https://arxiv.org/abs/2512.11082)
*Roy van Zuijlen,Duarte Antunes*

Main category: cs.LG

TL;DR: 提出一种新的策略迭代算法家族，用于解决部分可观测马尔可夫决策过程（POMDPs），通过交替进行单阶段输出策略改进和周期性策略评估，在输出空间而非高维信念空间中操作，显著提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 无记忆和有限记忆策略为POMDPs提供实用解决方案，但经典方法如策略迭代难以扩展到此设置，因为输出过程是非马尔可夫的，导致策略改进步骤在阶段间相互依赖。

Method: 引入单调改进的策略迭代算法家族，交替进行单阶段基于输出的策略改进和按预定周期模式进行的策略评估。进一步开发了无模型变体，从数据估计价值并直接学习无记忆策略。

Result: 该算法家族允许最大化计算效率指标的最优模式，并识别出具有最小周期的最简单模式。在多个POMDPs示例中，相比策略梯度基线和近期专门算法，在基于模型和无模型设置中都实现了显著的计算加速。

Conclusion: 提出的周期性策略迭代算法为POMDPs提供了高效解决方案，通过直接在输出空间操作避免了高维信念空间的复杂性，在计算效率和性能方面都表现出显著优势。

Abstract: Memoryless and finite-memory policies offer a practical alternative for solving partially observable Markov decision processes (POMDPs), as they operate directly in the output space rather than in the high-dimensional belief space. However, extending classical methods such as policy iteration to this setting remains difficult; the output process is non-Markovian, making policy-improvement steps interdependent across stages. We introduce a new family of monotonically improving policy-iteration algorithms that alternate between single-stage output-based policy improvements and policy evaluations according to a prescribed periodic pattern. We show that this family admits optimal patterns that maximize a natural computational-efficiency index, and we identify the simplest pattern with minimal period. Building on this structure, we further develop a model-free variant that estimates values from data and learns memoryless policies directly. Across several POMDPs examples, our method achieves significant computational speedups over policy-gradient baselines and recent specialized algorithms in both model-based and model-free settings.

</details>


### [72] [Investigating ECG Diagnosis with Ambiguous Labels using Partial Label Learning](https://arxiv.org/abs/2512.11095)
*Sana Rahmani,Javad Hashemi,Ali Etemad*

Main category: cs.LG

TL;DR: 该研究首次系统性地将部分标签学习(PLL)方法应用于ECG诊断，通过多种临床相关的模糊标签生成策略评估了9种PLL算法在ECG多标签诊断中的表现。


<details>
  <summary>Details</summary>
Motivation: 心电图(ECG)诊断中存在固有的标签模糊性问题，源于重叠病症和诊断分歧。然而当前ECG模型训练假设标注是干净无歧义的，这限制了模型在真实临床环境中的发展和评估。虽然部分标签学习(PLL)框架旨在从模糊标签中学习，但其在医疗时间序列领域（特别是ECG）的有效性尚未充分探索。

Method: 研究将9种PLL算法适配到多标签ECG诊断任务中，使用多种临床驱动的模糊生成策略进行评估，包括非结构化（如随机）和结构化模糊（如心脏病专家推导的相似性、治疗关系、诊断分类学）。实验在PTB-XL和Chapman数据集上进行。

Result: 实验表明，不同PLL方法对各种类型和程度的模糊性表现出显著不同的鲁棒性。通过广泛分析，识别了当前PLL方法在临床环境中的关键局限性。

Conclusion: 该研究为ECG诊断中开发鲁棒且临床对齐的模糊感知学习框架指明了未来方向，强调了PLL方法在真实世界ECG诊断中的潜力和挑战。

Abstract: Label ambiguity is an inherent problem in real-world electrocardiogram (ECG) diagnosis, arising from overlapping conditions and diagnostic disagreement. However, current ECG models are trained under the assumption of clean and non-ambiguous annotations, which limits both the development and the meaningful evaluation of models under real-world conditions. Although Partial Label Learning (PLL) frameworks are designed to learn from ambiguous labels, their effectiveness in medical time-series domains, ECG in particular, remains largely unexplored. In this work, we present the first systematic study of PLL methods for ECG diagnosis. We adapt nine PLL algorithms to multi-label ECG diagnosis and evaluate them using a diverse set of clinically motivated ambiguity generation strategies, capturing both unstructured (e.g., random) and structured ambiguities (e.g., cardiologist-derived similarities, treatment relationships, and diagnostic taxonomies). Our experiments on the PTB-XL and Chapman datasets demonstrate that PLL methods vary substantially in their robustness to different types and degrees of ambiguity. Through extensive analysis, we identify key limitations of current PLL approaches in clinical settings and outline future directions for developing robust and clinically aligned ambiguity-aware learning frameworks for ECG diagnosis.

</details>


### [73] [Limits and Gains of Test-Time Scaling in Vision-Language Reasoning](https://arxiv.org/abs/2512.11109)
*Mohammadjavad Ahmadpour,Amirmahdi Meighani,Payam Taebi,Omid Ghahroodi,Amirmohammad Izadi,Mahdieh Soleymani Baghshah*

Main category: cs.LG

TL;DR: 测试时扩展(TTS)在提升大语言模型推理能力方面效果显著，但在视觉语言模型(VLMs)中的应用仍待探索。研究发现闭源模型能从结构化推理和迭代自优化中持续获益，而开源模型表现不一致，外部验证效果最好，迭代优化反而可能降低性能。TTS效果取决于数据集，在多步推理任务上提升明显，但在感知为主的任务上增益有限。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展(TTS)已被证明能有效提升大语言模型的推理能力，但这种方法在视觉语言模型(VLMs)中的应用尚未得到充分探索。研究者希望系统性地研究推理时方法在不同VLMs上的应用效果，了解TTS在视觉语言任务中的适用性和局限性。

Method: 对开源和闭源视觉语言模型进行系统性实证研究，应用不同的推理时方法，包括结构化推理、迭代自优化和外部验证等。在不同基准测试上评估这些方法的有效性，分析模型类型、任务特性对TTS效果的影响。

Result: 闭源模型能持续从结构化推理和迭代自优化中获益；开源模型表现不一致，外部验证提供最可靠的性能提升，而迭代优化常常降低性能；TTS效果具有数据集依赖性，在多步推理任务上带来明显改进，但在感知为主的基准测试上增益有限。

Conclusion: 测试时扩展不是通用解决方案，必须根据模型能力和任务特性进行定制。这为未来研究自适应TTS策略和多模态奖励模型提供了动机，需要开发更智能的方法来匹配推理计算与具体任务需求。

Abstract: Test-time scaling (TTS) has emerged as a powerful paradigm for improving the reasoning ability of Large Language Models (LLMs) by allocating additional computation at inference, yet its application to multimodal systems such as Vision-Language Models (VLMs) remains underexplored. In this work, we present a systematic empirical study of inference time reasoning methods applied across both open-source and closed-source VLMs on different benchmarks. Our results reveal that while closed-source models consistently benefit from structured reasoning and iterative Self-Refinement, open-source VLMs show inconsistent behavior: external verification provides the most reliable gains, whereas iterative refinement often degrades performance. We further find that the effectiveness of TTS is dataset-dependent, yielding clear improvements on multi-step reasoning tasks but offering only limited gains on perception-focused benchmarks. These findings demonstrate that TTS is not a universal solution and must be tailored to both model capabilities and task characteristics, motivating future work on adaptive TTS strategies and multimodal reward models.

</details>


### [74] [Fairness-Regularized Online Optimization with Switching Costs](https://arxiv.org/abs/2512.11131)
*Pengfei Li,Yuelin Han,Adam Wierman,Shaolei Ren*

Main category: cs.LG

TL;DR: 该论文研究公平性与动作平滑性同时考虑的在线优化问题，提出FairOBD算法在公平性正则化平滑在线凸优化中平衡命中成本、切换成本和公平成本。


<details>
  <summary>Details</summary>
Motivation: 公平性和动作平滑性是在线优化中的两个关键考虑因素，但现有研究尚未能同时解决这两个问题。论文旨在研究公平性正则化平滑在线凸优化这一新挑战性场景。

Method: 提出FairOBD算法：1）将长期公平成本分解为一系列在线成本；2）引入辅助变量来正则化在线动作以实现公平结果；3）采用新方法考虑切换成本。

Result: 理论证明：1）无切换成本时，任何在线算法都无法实现次线性遗憾或有限竞争比；2）FairOBD针对参数化约束的最优离线算法提供最坏情况渐近竞争比。实验验证：FairOBD能有效降低总公平正则化成本并促进公平结果。

Conclusion: FairOBD算法成功解决了公平性与动作平滑性同时考虑的在线优化问题，在理论和实验上都证明了其有效性，为动态计算资源配置等应用提供了解决方案。

Abstract: Fairness and action smoothness are two crucial considerations in many online optimization problems, but they have yet to be addressed simultaneously. In this paper, we study a new and challenging setting of fairness-regularized smoothed online convex optimization with switching costs. First, to highlight the fundamental challenges introduced by the long-term fairness regularizer evaluated based on the entire sequence of actions, we prove that even without switching costs, no online algorithms can possibly achieve a sublinear regret or finite competitive ratio compared to the offline optimal algorithm as the problem episode length $T$ increases. Then, we propose FairOBD (Fairness-regularized Online Balanced Descent), which reconciles the tension between minimizing the hitting cost, switching cost, and fairness cost. Concretely, FairOBD decomposes the long-term fairness cost into a sequence of online costs by introducing an auxiliary variable and then leverages the auxiliary variable to regularize the online actions for fair outcomes. Based on a new approach to account for switching costs, we prove that FairOBD offers a worst-case asymptotic competitive ratio against a novel benchmark -- the optimal offline algorithm with parameterized constraints -- by considering $T\to\infty$. Finally, we run trace-driven experiments of dynamic computing resource provisioning for socially responsible AI inference to empirically evaluate FairOBD, showing that FairOBD can effectively reduce the total fairness-regularized cost and better promote fair outcomes compared to existing baseline solutions.

</details>


### [75] [The Vekua Layer: Exact Physical Priors for Implicit Neural Representations via Generalized Analytic Functions](https://arxiv.org/abs/2512.11138)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: Vekua Layer (VL) 是一种基于广义解析函数理论的微分谱方法，通过将假设空间限制在控制微分算子的核中，将隐式神经表示的学习任务从非凸优化转化为严格凸的最小二乘问题，在椭圆PDE上实现了机器精度重建和优越的抗噪性能。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）在参数化物理场方面表现出色，但存在谱偏差和非凸优化的计算开销问题。需要一种更高效、更稳定的方法来学习物理场表示。

Method: 提出Vekua Layer (VL)，基于广义解析函数理论，通过将假设空间限制在控制微分算子的核中（使用调和基和傅里叶-贝塞尔基），将学习任务转化为严格凸的最小二乘问题，通过线性投影求解。

Result: 在齐次椭圆偏微分方程上，VL相比SIRENs实现了机器精度（MSE ≈ 10^{-33}）的精确重建，在非相干传感器噪声下表现出优越的稳定性（MSE ≈ 0.03），并能够从部分边界数据通过解析延拓实现全局场的"全息"外推。

Conclusion: VL提供了一种基于物理信息的谱滤波方法，将隐式神经表示的学习从迭代梯度下降转化为凸优化问题，在精度、稳定性和计算效率方面显著优于传统方法，并具备标准坐标基近似所缺乏的解析延拓能力。

Abstract: Implicit Neural Representations (INRs) have emerged as a powerful paradigm for parameterizing physical fields, yet they often suffer from spectral bias and the computational expense of non-convex optimization. We introduce the Vekua Layer (VL), a differentiable spectral method grounded in the classical theory of Generalized Analytic Functions. By restricting the hypothesis space to the kernel of the governing differential operator -- specifically utilizing Harmonic and Fourier-Bessel bases -- the VL transforms the learning task from iterative gradient descent to a strictly convex least-squares problem solved via linear projection. We evaluate the VL against Sinusoidal Representation Networks (SIRENs) on homogeneous elliptic Partial Differential Equations (PDEs). Our results demonstrate that the VL achieves machine precision ($\text{MSE} \approx 10^{-33}$) on exact reconstruction tasks and exhibits superior stability in the presence of incoherent sensor noise ($\text{MSE} \approx 0.03$), effectively acting as a physics-informed spectral filter. Furthermore, we show that the VL enables "holographic" extrapolation of global fields from partial boundary data via analytic continuation, a capability absent in standard coordinate-based approximations.

</details>


### [76] [Autoencoder-based Semi-Supervised Dimensionality Reduction and Clustering for Scientific Ensembles](https://arxiv.org/abs/2512.11145)
*Lennard Manuel,Hamid Gadirov,Steffen Frey*

Main category: cs.LG

TL;DR: 提出了一种结合聚类损失和对比损失的增强自编码器框架，用于高维科学集合数据集的降维和可视化，通过联合优化重建、聚类和对比目标来改善潜在空间表示。


<details>
  <summary>Details</summary>
Motivation: 科学集合数据集具有高维度和复杂性，传统降维技术和自编码器在处理这类数据时面临挑战，需要改进特征提取和可视化效果。

Method: 使用EfficientNetV2为无标签数据生成伪标签，构建增强自编码器框架，结合基于软轮廓分数的聚类损失和对比损失，联合优化重建、聚类和对比目标，最后用UMAP生成2D投影。

Result: 在两个科学集合数据集（土壤通道结构和液滴撞击薄膜动力学）上的实验表明，结合聚类或对比损失的模型在轮廓分数评估下略微优于基线方法。

Conclusion: 提出的增强自编码器框架能够有效改善高维科学集合数据集的可视化和可解释性，通过聚类和对比损失的结合提升了潜在空间表示的质量。

Abstract: Analyzing and visualizing scientific ensemble datasets with high dimensionality and complexity poses significant challenges. Dimensionality reduction techniques and autoencoders are powerful tools for extracting features, but they often struggle with such high-dimensional data. This paper presents an enhanced autoencoder framework that incorporates a clustering loss, based on the soft silhouette score, alongside a contrastive loss to improve the visualization and interpretability of ensemble datasets. First, EfficientNetV2 is used to generate pseudo-labels for the unlabeled portions of the scientific ensemble datasets. By jointly optimizing the reconstruction, clustering, and contrastive objectives, our method encourages similar data points to group together while separating distinct clusters in the latent space. UMAP is subsequently applied to this latent representation to produce 2D projections, which are evaluated using the silhouette score. Multiple types of autoencoders are evaluated and compared based on their ability to extract meaningful features. Experiments on two scientific ensemble datasets - channel structures in soil derived from Markov chain Monte Carlo, and droplet-on-film impact dynamics - show that models incorporating clustering or contrastive loss marginally outperform the baseline approaches.

</details>


### [77] [Harnessing Rich Multi-Modal Data for Spatial-Temporal Homophily-Embedded Graph Learning Across Domains and Localities](https://arxiv.org/abs/2512.11178)
*Takuya Kurihana,Xiaojian Zhang,Wing Yee Au,Hon Yung Wong*

Main category: cs.LG

TL;DR: 提出一个异构数据管道，用于融合时空变化的多模态城市数据，解决跨域城市问题，在多个城市数据集上验证了框架的通用性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现代城市依赖数据驱动决策，但城市数据存在异构格式、分散收集、标准不一的问题。国家级数据集虽然丰富但存在显著异质性和多模态性，需要有效融合来解决复杂城市问题。

Method: 提出异构数据管道，执行跨域数据融合，处理时空变化的时间序列数据集。数据学习模块将空间变化数据集的同质性整合到图学习中，将不同地区的信息嵌入模型。使用50多个数据源，在多个城市的公开数据集（如拼车、交通事故、犯罪报告）上进行验证。

Result: 框架在五个真实世界观察中展示了强大的预测性能，当转移到新地区或领域时只需最小重新配置。证明了框架的通用性和灵活性。

Conclusion: 该研究推进了以可扩展方式构建数据驱动的城市系统的目标，解决了智慧城市分析中最紧迫的挑战之一，为跨域城市问题提供了有效的异构数据融合解决方案。

Abstract: Modern cities are increasingly reliant on data-driven insights to support decision making in areas such as transportation, public safety and environmental impact. However, city-level data often exists in heterogeneous formats, collected independently by local agencies with diverse objectives and standards. Despite their numerous, wide-ranging, and uniformly consumable nature, national-level datasets exhibit significant heterogeneity and multi-modality. This research proposes a heterogeneous data pipeline that performs cross-domain data fusion over time-varying, spatial-varying and spatial-varying time-series datasets. We aim to address complex urban problems across multiple domains and localities by harnessing the rich information over 50 data sources. Specifically, our data-learning module integrates homophily from spatial-varying dataset into graph-learning, embedding information of various localities into models. We demonstrate the generalizability and flexibility of the framework through five real-world observations using a variety of publicly accessible datasets (e.g., ride-share, traffic crash, and crime reports) collected from multiple cities. The results show that our proposed framework demonstrates strong predictive performance while requiring minimal reconfiguration when transferred to new localities or domains. This research advances the goal of building data-informed urban systems in a scalable way, addressing one of the most pressing challenges in smart city analytics.

</details>


### [78] [Progress over Points: Reframing LM Benchmarks Around Scientific Objectives](https://arxiv.org/abs/2512.11183)
*Alwin Jin,Sean M. Hendryx,Vaskar Nath*

Main category: cs.LG

TL;DR: 论文提出从静态基准测试转向以科学进步为导向的基准测试，通过NanoGPT速度挑战环境实现，旨在推动语言建模堆栈的可复用改进


<details>
  <summary>Details</summary>
Motivation: 当前基于静态已解决问题（如数学应用题）的基准测试虽然能展示基本能力获取，但限制了可衡量和激励的进步类型。需要转向以科学进步本身为目标的基准测试环境

Method: 创建基于NanoGPT速度挑战的进展导向基准测试环境，标准化数据集切片、参考模型和训练工具，提供丰富遥测数据，包含运行时验证和防作弊检查

Result: 在该环境中实现了新的最先进训练时间，比之前记录提高了3秒，并定性观察到新颖算法思想的出现。基准测试促进了语言建模堆栈的可复用改进

Conclusion: 通过将基准测试重新定义为科学进步的工具，论文旨在推动社区从静态问题排行榜转向对开放式但可测量的科学问题进行测试时研究的新范式

Abstract: Current benchmarks that test LLMs on static, already-solved problems (e.g., math word problems) effectively demonstrated basic capability acquisition. The natural progression has been toward larger, more comprehensive and challenging collections of static problems, an approach that inadvertently constrains the kinds of advances we can measure and incentivize. To address this limitation, we argue for progress-oriented benchmarks, problem environments whose objectives are themselves the core targets of scientific progress, so that achieving state of the art on the benchmark advances the field. As a introductory step, we instantiate an environment based on the NanoGPT speedrun. The environment standardizes a dataset slice, a reference model and training harness, and rich telemetry, with run-time verification and anti-gaming checks. Evaluation centers on the scientific delta achieved: best-attained loss and the efficiency frontier. Using this environment, we achieve a new state-of-the-art training time, improving upon the previous record by 3 seconds, and qualitatively observe the emergence of novel algorithmic ideas. Moreover, comparisons between models and agents remain possible, but they are a means, not the end; the benchmark's purpose is to catalyze reusable improvements to the language modeling stack. With this release, the overarching goal is to seed a community shift from static problem leaderboards to test-time research on open-ended yet measurable scientific problems. In this new paradigm, progress on the benchmark is progress on the science, thus reframing "benchmarking" as a vehicle for scientific advancement.

</details>


### [79] [Beyond Memorization: Gradient Projection Enables Selective Learning in Diffusion Models](https://arxiv.org/abs/2512.11194)
*Divya Kothandaraman,Jaclyn Pytlarz*

Main category: cs.LG

TL;DR: 提出梯度投影框架，在扩散模型训练中通过正交投影消除敏感概念特征的影响，实现概念级选择性遗忘，减少记忆化风险


<details>
  <summary>Details</summary>
Motivation: 大规模文生图扩散模型的记忆化问题带来安全和知识产权风险，传统方法只能限制对特定训练样本的过拟合，无法系统防止禁止概念级特征的内化，需要概念级选择性遗忘方法

Method: 梯度投影框架：在反向传播期间识别并切除与禁止属性嵌入对齐的训练信号，将每个梯度更新投影到敏感特征嵌入空间的正交补空间，从而消除其对模型权重的影响

Result: 框架显著减少记忆化，同时严格保持生成质量和语义保真度，可无缝集成到标准扩散模型训练流程中，并与现有防御措施互补

Conclusion: 通过将记忆化控制重新定义为选择性学习，该方法为IP安全和隐私保护的生成式AI建立了新范式

Abstract: Memorization in large-scale text-to-image diffusion models poses significant security and intellectual property risks, enabling adversarial attribute extraction and the unauthorized reproduction of sensitive or proprietary features. While conventional dememorization techniques, such as regularization and data filtering, limit overfitting to specific training examples, they fail to systematically prevent the internalization of prohibited concept-level features. Simply discarding all images containing a sensitive feature wastes invaluable training data, necessitating a method for selective unlearning at the concept level.
  To address this, we introduce a Gradient Projection Framework designed to enforce a stringent requirement of concept-level feature exclusion. Our defense operates during backpropagation by systematically identifying and excising training signals aligned with embeddings of prohibited attributes. Specifically, we project each gradient update onto the orthogonal complement of the sensitive feature's embedding space, thereby zeroing out its influence on the model's weights. Our method integrates seamlessly into standard diffusion model training pipelines and complements existing defenses. We analyze our method against an adversary aiming for feature extraction. In extensive experiments, we demonstrate that our framework drastically reduces memorization while rigorously preserving generation quality and semantic fidelity. By reframing memorization control as selective learning, our approach establishes a new paradigm for IP-safe and privacy-preserving generative AI.

</details>


### [80] [Fast EXP3 Algorithms](https://arxiv.org/abs/2512.11201)
*Ryoma Sato,Shinji Ito*

Main category: cs.LG

TL;DR: EXP3算法可实现每轮常数时间运行，本文提出更实用的算法并分析其遗憾界与时间复杂度的权衡


<details>
  <summary>Details</summary>
Motivation: EXP3算法作为多臂赌博机问题的经典算法，在实际应用中需要考虑计算效率问题。虽然理论上EXP3具有较好的遗憾界，但其实现的时间复杂度可能影响实际部署，因此需要探索更高效的实现方案。

Method: 提出EXP3算法的常数时间实现方案，并设计更实用的算法变体。通过算法优化和数据结构设计，在保持理论保证的同时降低计算复杂度。

Result: 成功实现了EXP3算法的常数时间每轮运行，提出了多个实用算法变体，并在遗憾界和时间复杂度之间建立了明确的权衡关系。

Conclusion: 本文证明了EXP3算法可以在常数时间内实现，为实际应用提供了更高效的算法选择，并通过系统分析为算法设计者在遗憾界与计算效率之间提供了权衡指导。

Abstract: We point out that EXP3 can be implemented in constant time per round, propose more practical algorithms, and analyze the trade-offs between the regret bounds and time complexities of these algorithms.

</details>


### [81] [Latent Variable Causal Discovery under Selection Bias](https://arxiv.org/abs/2512.11219)
*Haoyue Dai,Yiwen Qiu,Ignavier Ng,Xinshuai Dong,Peter Spirtes,Kun Zhang*

Main category: cs.LG

TL;DR: 该论文研究了在存在选择偏差的情况下，利用秩约束进行潜变量因果发现的方法，证明了即使在选择偏差下，协方差子矩阵的秩仍然保留了因果结构和选择机制的有用信息。


<details>
  <summary>Details</summary>
Motivation: 处理潜变量因果发现中的选择偏差是一个重要但尚未充分探索的问题，主要是因为缺乏合适的统计工具。现有的处理潜变量的方法都没有针对选择偏差进行适配。

Method: 研究秩约束作为条件独立性约束的推广，在线性高斯模型中利用协方差子矩阵的秩。提供了这种秩约束的图论特征化，并展示了如何利用这一工具。

Result: 研究发现，尽管选择偏差会显著复杂化联合分布，但偏差协方差矩阵中的秩仍然保留了关于因果结构和选择机制的有意义信息。证明了经典的单因子模型在选择偏差下是可识别的。

Conclusion: 秩约束是处理潜变量因果发现中选择偏差的有效工具，模拟和真实世界实验证实了使用秩约束的有效性，为解决这一重要但未充分探索的问题提供了新的统计工具。

Abstract: Addressing selection bias in latent variable causal discovery is important yet underexplored, largely due to a lack of suitable statistical tools: While various tools beyond basic conditional independencies have been developed to handle latent variables, none have been adapted for selection bias. We make an attempt by studying rank constraints, which, as a generalization to conditional independence constraints, exploits the ranks of covariance submatrices in linear Gaussian models. We show that although selection can significantly complicate the joint distribution, interestingly, the ranks in the biased covariance matrices still preserve meaningful information about both causal structures and selection mechanisms. We provide a graph-theoretic characterization of such rank constraints. Using this tool, we demonstrate that the one-factor model, a classical latent variable model, can be identified under selection bias. Simulations and real-world experiments confirm the effectiveness of using our rank constraints.

</details>


### [82] [Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference](https://arxiv.org/abs/2512.11221)
*Adilet Metinov,Gulida M. Kudakeeva,Bolotbek uulu Nursultan,Gulnara D. Kabaeva*

Main category: cs.LG

TL;DR: 提出ASR-KF-EGR框架，通过可逆软冻结机制在推理时动态管理KV缓存，减少55-67%的活跃KV缓存大小，同时保持生成质量


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长上下文生成时的内存瓶颈问题，特别是KV缓存的内存消耗，为内存受限的部署提供实用解决方案

Method: 1. 引入可逆软冻结机制，在滑动注意力窗口内识别低重要性token并暂时冻结其KV更新；2. 保留所有token在GPU外存储，按需恢复；3. 采用亚线性冻结调度，冻结时长随重复检测次数亚线性增长，避免过度压缩

Result: 在LLaMA-3 8B上的初步实验显示：活跃KV缓存大小减少55-67%，同时保持生成质量，通过needle-in-haystack检索测试

Conclusion: ASR-KF-EGR是一种无需训练、架构无关的推理时框架，为长上下文LLM的内存受限部署提供了实用解决方案

Abstract: We present Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery (ASR-KF-EGR), a training-free inference-time framework for efficient large language model generation. Our method introduces a reversible soft-freeze mechanism that temporarily suspends key-value (KV) updates for low-importance tokens identified within a sliding attention window. Unlike eviction-based approaches that permanently discard context, ASR-KF-EGR preserves all tokens in off-GPU storage and restores them on demand. We extend the framework with sublinear freeze scheduling, where freeze duration grows sublinearly with repeated low-importance detections, preventing over-aggressive compression. Preliminary experiments on LLaMA-3 8B demonstrate 55-67% reduction in active KV cache size while maintaining generation quality and passing needle-in-haystack retrieval tests. The method is architecture-agnostic, requires no fine-tuning, and provides a practical solution for memory-constrained deployment of long-context LLMs.

</details>


### [83] [SRLR: Symbolic Regression based Logic Recovery to Counter Programmable Logic Controller Attacks](https://arxiv.org/abs/2512.11298)
*Hao Zhou,Suman Sourav,Binbin Chen,Ke Yu*

Main category: cs.LG

TL;DR: SRLR是一种基于符号回归的逻辑恢复方案，用于从PLC输入输出中识别控制逻辑，生成可解释的规则来检测控制器逻辑攻击，在工业控制系统环境中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有PLC逻辑攻击检测方法存在局限性：基于规范的方法需要专家手动工作或访问PLC源代码，而基于机器学习的方法缺乏决策解释性。需要一种仅基于输入输出就能恢复PLC逻辑并提供可解释检测规则的方法。

Method: SRLR采用符号回归方法进行逻辑恢复，并针对ICS特定属性进行增强：1) 在频域而非时域表示重要控制逻辑；2) 处理多模式控制器逻辑；3) 过滤异常输入以处理传感器噪声；4) 降低公式复杂度以实现有效搜索。

Result: SRLR在各种ICS设置中始终优于现有方法，在某些挑战性环境中恢复准确率提升高达39%。在包含数百个电压调节器的配电网上评估显示，SRLR能够稳定处理大规模复杂系统。

Conclusion: SRLR通过结合符号回归和ICS特定属性，成功实现了仅基于输入输出的PLC逻辑恢复，生成了可解释的攻击检测规则，在准确性和可扩展性方面表现出色。

Abstract: Programmable Logic Controllers (PLCs) are critical components in Industrial Control Systems (ICSs). Their potential exposure to external world makes them susceptible to cyber-attacks. Existing detection methods against controller logic attacks use either specification-based or learnt models. However, specification-based models require experts' manual efforts or access to PLC's source code, while machine learning-based models often fall short of providing explanation for their decisions. We design SRLR -- a it Symbolic Regression based Logic Recovery} solution to identify the logic of a PLC based only on its inputs and outputs. The recovered logic is used to generate explainable rules for detecting controller logic attacks. SRLR enhances the latest deep symbolic regression methods using the following ICS-specific properties: (1) some important ICS control logic is best represented in frequency domain rather than time domain; (2) an ICS controller can operate in multiple modes, each using different logic, where mode switches usually do not happen frequently; (3) a robust controller usually filters out outlier inputs as ICS sensor data can be noisy; and (4) with the above factors captured, the degree of complexity of the formulas is reduced, making effective search possible. Thanks to these enhancements, SRLR consistently outperforms all existing methods in a variety of ICS settings that we evaluate. In terms of the recovery accuracy, SRLR's gain can be as high as 39% in some challenging environment. We also evaluate SRLR on a distribution grid containing hundreds of voltage regulators, demonstrating its stability in handling large-scale, complex systems with varied configurations.

</details>


### [84] [QGEC : Quantum Golay Code Error Correction](https://arxiv.org/abs/2512.11307)
*Hideo Mukai,Hoshitaro Ohnishi*

Main category: cs.LG

TL;DR: 提出基于Golay码的量子错误校正方法QGEC，使用Transformer进行解码计算，在多种噪声模型下评估性能，发现Golay码比toric码在更少数据量子位下获得更高解码精度。


<details>
  <summary>Details</summary>
Motivation: 量子计算机在特定问题上相比经典计算机具有计算负载优势，但量子比特易受外部噪声影响。量子错误校正(QEC)对于处理量子比特至关重要，其中需要从稳定子生成器的综合测量结果预测实际错误，而不是直接测量数据量子比特。

Method: 提出量子Golay码错误校正(QGEC)方法，使用经典信息论中的高效编码方法Golay码。采用Transformer进行解码计算，在由生成多项式定义的码空间中评估解码器精度，使用三种不同权重集和三种不同比特翻转错误与相位翻转错误相关性的噪声模型。

Result: 噪声模型相关性越小，解码精度越高；生成多项式的权重对解码器精度影响不大。在离散均匀分布的噪声模型下，Golay码（需要23个数据量子位，码距为7）比toric码（需要50个数据量子位，码距为5）获得更高的解码精度。

Conclusion: 使用Transformer实现量子错误校正可能使Golay码更高效地实现容错量子计算，因为Golay码在更少数据量子位下获得了比toric码更好的解码性能。

Abstract: Quantum computers have the possibility of a much reduced calculation load compared with classical computers in specific problems. Quantum error correction (QEC) is vital for handling qubits, which are vulnerable to external noise. In QEC, actual errors are predicted from the results of syndrome measurements by stabilizer generators, in place of making direct measurements of the data qubits. Here, we propose Quantum Golay code Error Correction (QGEC), a QEC method using Golay code, which is an efficient coding method in classical information theory. We investigated our method's ability in decoding calculations with the Transformer. We evaluated the accuracy of the decoder in a code space defined by the generative polynomials with three different weights sets and three noise models with different correlations of bit-flip error and phase-flip error. Furthermore, under a noise model following a discrete uniform distribution, we compared the decoding performance of Transformer decoders with identical architectures trained respectively on Golay and toric codes. The results showed that the noise model with the smaller correlation gave better accuracy, while the weights of the generative polynomials had little effect on the accuracy of the decoder. In addition, they showed that Golay code requiring 23 data qubits and having a code distance of 7 achieved higher decoding accuracy than toric code which requiring 50 data qubits and having a code distance of 5. This suggests that implementing quantum error correction using a Transformer may enable the Golay code to realize fault-tolerant quantum computation more efficiently.

</details>


### [85] [Benchmarking the Generality of Vision-Language-Action Models](https://arxiv.org/abs/2512.11315)
*Pranav Guruprasad,Sudipta Chowdhury,Harsh Sikka,Mridul Sharma,Helen Lu,Sean Rivera,Aryan Khurana,Hangliang Ren,Yangyue Wang*

Main category: cs.LG

TL;DR: MultiNet v1.0是一个统一基准测试，用于评估视觉语言模型和视觉语言动作模型在六个核心能力领域的跨领域泛化能力，发现当前基础模型在未见领域存在显著性能下降。


<details>
  <summary>Details</summary>
Motivation: 当前多模态智能体评估方法分散在孤立基准中，难以判断基础模型是否真正超越了训练分布实现泛化。需要统一基准来测量模型在跨领域任务中的通用性。

Method: 开发MultiNet v1.0基准测试，涵盖六个核心能力领域：视觉基础、空间推理、工具使用、物理常识、多智能体协调和连续机器人控制。使用该基准评估GPT-5、Pi0和Magma等模型。

Result: 所有评估模型都未表现出一致的通用性，在未见领域、不熟悉模态或跨领域任务转移时出现显著性能下降。具体表现为模态不对齐、输出格式不稳定和领域转移下的灾难性知识退化。

Conclusion: 当前基础模型的实际能力与通用智能的期望之间存在持续差距。MultiNet v1.0为诊断这些差距和指导未来通用智能体开发提供了标准化评估基础。

Abstract: Generalist multimodal agents are expected to unify perception, language, and control - operating robustly across diverse real world domains. However, current evaluation practices remain fragmented across isolated benchmarks, making it difficult to assess whether today's foundation models truly generalize beyond their training distributions. We introduce MultiNet v1.0, a unified benchmark for measuring the cross domain generality of vision language models (VLMs) and vision language action models (VLAs) across six foundational capability regimes. Visual grounding, spatial reasoning, tool use, physical commonsense, multi agent coordination, and continuous robot control. Evaluating GPT 5, Pi0, and Magma, we find that no model demonstrates consistent generality. All exhibit substantial degradation on unseen domains, unfamiliar modalities, or cross domain task shifts despite strong performance within their training distributions.These failures manifest as modality misalignment, output format instability, and catastrophic knowledge degradation under domain transfer.Our findings reveal a persistent gap between the aspiration of generalist intelligence and the actual capabilities of current foundation models.MultiNet v1.0 provides a standardized evaluation substrate for diagnosing these gaps and guiding the development of future generalist agents.Code, data, and leaderboards are publicly available.

</details>


### [86] [Contrastive Time Series Forecasting with Anomalies](https://arxiv.org/abs/2512.11526)
*Joel Ekstrand,Zahra Taghiyarrenani,Slawomir Nowaczyk*

Main category: cs.LG

TL;DR: Co-TSFA是一个对比学习框架，通过区分短期异常和持久性分布偏移来提升时间序列预测的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现实世界中的异常事件对预测的影响不同：有些是短期噪声应被忽略，有些是持久性分布偏移需要响应。传统预测模型无法区分这两种情况，要么对噪声过度反应，要么错过重要变化。

Method: 提出Co-TSFA框架，通过输入增强和输入-输出增强分别建模预测无关和预测相关的异常，引入潜在-输出对齐损失将表示变化与预测变化关联，鼓励对无关扰动保持不变性，同时对有意义的分布偏移保持敏感性。

Result: 在Traffic、Electricity基准数据集和真实现金需求数据集上的实验表明，Co-TSFA在异常条件下提升了预测性能，同时在正常数据上保持了准确性。

Conclusion: Co-TSFA通过对比学习框架有效区分了短期异常和持久性分布偏移，提高了时间序列预测在现实异常条件下的鲁棒性。

Abstract: Time series forecasting predicts future values from past data. In real-world settings, some anomalous events have lasting effects and influence the forecast, while others are short-lived and should be ignored. Standard forecasting models fail to make this distinction, often either overreacting to noise or missing persistent shifts. We propose Co-TSFA (Contrastive Time Series Forecasting with Anomalies), a regularization framework that learns when to ignore anomalies and when to respond. Co-TSFA generates input-only and input-output augmentations to model forecast-irrelevant and forecast-relevant anomalies, and introduces a latent-output alignment loss that ties representation changes to forecast changes. This encourages invariance to irrelevant perturbations while preserving sensitivity to meaningful distributional shifts. Experiments on the Traffic and Electricity benchmarks, as well as on a real-world cash-demand dataset, demonstrate that Co-TSFA improves performance under anomalous conditions while maintaining accuracy on normal data. An anonymized GitHub repository with the implementation of Co-TSFA is provided and will be made public upon acceptance.

</details>


### [87] [Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents](https://arxiv.org/abs/2512.11584)
*Stefan Tabakov,Asen Popov,Dimitar Dimitrov,S. Ensiye Kiyamousavi,Vladimir Hristov,Boris Kraychev*

Main category: cs.LG

TL;DR: 该论文提出了原子动作切片（AAS）方法，通过将长时程演示分解为短小的类型化原子动作，提升VLA模型的泛化能力，并在LIBERO数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型在需要新技能或物体组合的任务上泛化能力较差，特别是对于长时程任务。需要一种方法能够更好地分解复杂任务，便于规划器使用和策略学习。

Method: 提出原子动作切片（AAS）方法，将长时程演示分解为短小的类型化原子动作，包含动作类型、时间跨度和置信度标签。使用更强的分割模型（Gemini 2.5 Pro）来匹配规划器定义的方案，并在LIBERO演示上创建了包含2,124个原子片段的验证数据集。

Result: 在LIBERO-Goal数据集上，使用原子数据集微调CLIP-RT+将任务成功率从94.2%提升至95.3%；在LIBERO-Long数据集上从83.8%提升至88.8%。更强的分割模型能紧密匹配规划器定义的方案，并在关键帧抖动下保持鲁棒性。

Conclusion: 原子动作切片方法能有效提升VLA模型的泛化能力，特别是在需要新技能组合的任务上。公开发布的GATE-VLAP数据集为相关研究提供了有价值的资源。

Abstract: Current vision-language-action (VLA) models generalize poorly, particularly when tasks require new compositions of skills or objects. We introduce Atomic Action Slicing (AAS), a planner-aligned approach that decomposes long-horizon demonstrations into short, typed atomic actions that are easier for planners to use and policies to learn. Using LIBERO demonstrations, AAS produces a validated dataset of 2,124 atomic segments labeled with action type, temporal span, and confidence. A stronger segmenter (Gemini 2.5 Pro) closely matches planner-defined plans and remains robust under keyframe jitter, while smaller models perform worse on multi-object tasks. Fine-tuning CLIP-RT+ on our atomic dataset improves task success from 94.2% to 95.3% on LIBERO-Goal and 83.8% to 88.8% on LIBERO-Long. We publicly release the GATE-VLAP dataset on HuggingFace(https://huggingface.co/datasets/gate-institute/GATE-VLAP-datasets)

</details>


### [88] [DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning](https://arxiv.org/abs/2512.11342)
*Jinming Ge,Linfeng Du,Likith Anaparty,Shangkun Li,Tingyuan Liang,Afzal Ahmad,Vivek Chaturvedi,Sharad Sinha,Zhiyao Xie,Jiang Xu,Wei Zhang*

Main category: cs.LG

TL;DR: DAPO框架通过结合程序语义分析、对比学习嵌入、硬件指标估计和强化学习，为FPGA HLS设计自动发现设计特定的优化策略，相比Vitis HLS平均获得2.36倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有HLS工具采用固定的优化策略，这些策略继承自软件编译器，无法针对特定设计进行优化。为特定设计定制优化策略需要深度语义理解、准确的硬件指标估计和高级搜索算法，而当前方法缺乏这些能力。

Method: DAPO框架从控制和数据流图中提取程序语义，使用对比学习生成丰富的嵌入表示，利用分析模型进行准确的硬件指标估计，这些组件共同指导强化学习智能体发现设计特定的优化策略。

Result: 在经典HLS设计上的评估表明，该端到端流程相比Vitis HLS平均实现了2.36倍的加速。

Conclusion: DAPO通过结合程序语义理解、机器学习嵌入和强化学习搜索，能够为特定FPGA设计自动发现优化的编译策略，显著提升了HLS工具的性能。

Abstract: High-Level Synthesis (HLS) tools are widely adopted in FPGA-based domain-specific accelerator design. However, existing tools rely on fixed optimization strategies inherited from software compilations, limiting their effectiveness. Tailoring optimization strategies to specific designs requires deep semantic understanding, accurate hardware metric estimation, and advanced search algorithms -- capabilities that current approaches lack.
  We propose DAPO, a design structure-aware pass ordering framework that extracts program semantics from control and data flow graphs, employs contrastive learning to generate rich embeddings, and leverages an analytical model for accurate hardware metric estimation. These components jointly guide a reinforcement learning agent to discover design-specific optimization strategies. Evaluations on classic HLS designs demonstrate that our end-to-end flow delivers a 2.36 speedup over Vitis HLS on average.

</details>


### [89] [Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits](https://arxiv.org/abs/2512.11345)
*Minwoo Park,Junwoo Chang,Jongeun Choi,Roberto Horowitz*

Main category: cs.LG

TL;DR: 本文提出了一种对称感知的强化学习框架，用于引导等变扩散策略，通过利用几何对称性提高样本效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 等变扩散策略结合了扩散模型的生成表达能力与几何对称性带来的强泛化能力，但直接应用标准（非等变）强化学习进行微调会忽略这些对称性，导致样本效率低下和不稳定。

Method: 首先从理论上证明等变扩散策略的扩散过程是等变的，从而诱导出一个适合等变扩散引导的群不变潜在噪声MDP。基于此理论，提出了一个原则性的对称感知引导框架，并比较了标准、等变和近似等变强化学习策略。

Result: 实验表明，在对称性引导过程中利用对称性能带来显著好处：提高样本效率、防止价值发散，即使在从极有限的演示数据训练等变扩散策略时也能实现强大的策略改进。同时识别了在对称性破坏下严格等变的实际边界。

Conclusion: 对称感知的强化学习框架能够有效引导等变扩散策略，利用几何对称性提高微调过程的效率和稳定性，为从有限演示数据中学习提供了有前景的解决方案。

Abstract: Equivariant diffusion policies (EDPs) combine the generative expressivity of diffusion models with the strong generalization and sample efficiency afforded by geometric symmetries. While steering these policies with reinforcement learning (RL) offers a promising mechanism for fine-tuning beyond demonstration data, directly applying standard (non-equivariant) RL can be sample-inefficient and unstable, as it ignores the symmetries that EDPs are designed to exploit. In this paper, we theoretically establish that the diffusion process of an EDP is equivariant, which in turn induces a group-invariant latent-noise MDP that is well-suited for equivariant diffusion steering. Building on this theory, we introduce a principled symmetry-aware steering framework and compare standard, equivariant, and approximately equivariant RL strategies through comprehensive experiments across tasks with varying degrees of symmetry. While we identify the practical boundaries of strict equivariance under symmetry breaking, we show that exploiting symmetry during the steering process yields substantial benefits-enhancing sample efficiency, preventing value divergence, and achieving strong policy improvements even when EDPs are trained from extremely limited demonstrations.

</details>


### [90] [Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization](https://arxiv.org/abs/2512.11391)
*Yifan Niu,Han Xiao,Dongyi Liu,Nuo Chen,Jia Li*

Main category: cs.LG

TL;DR: NSPO是一种新颖的强化学习框架，通过将安全策略梯度投影到通用任务零空间来减少对齐税，在保持LLM核心能力的同时实现安全对齐。


<details>
  <summary>Details</summary>
Motivation: LLM在现实应用中需要确保其行为符合人类价值观、社会规范和伦理原则，但传统的强化学习安全对齐方法会导致模型遗忘已学习的通用能力（对齐税问题）。

Method: 提出零空间约束策略优化（NSPO）框架，将安全策略梯度几何投影到通用任务的零空间中，从而在实现安全对齐的同时最小化对模型核心能力的影响。

Result: NSPO在实验中大幅优于现有方法，在数学、代码和指令跟随等通用任务上保持准确性的同时，实现了最先进的安全性能。仅需PKU-SafeRLHF中40%的安全标注数据即可获得良好效果，无需大量混合通用任务数据。

Conclusion: NSPO通过零空间投影方法有效解决了LLM安全对齐中的对齐税问题，在保持模型核心能力的同时实现了高效的安全对齐，且具有数据效率优势。

Abstract: As Large Language Models (LLMs) are increasingly deployed in real-world applications, it is important to ensure their behaviors align with human values, societal norms, and ethical principles. However, safety alignment under Reinforcement Learning (RL) often suffers from forgetting learned general abilities, which is also known as the alignment tax. To address this issue, we introduce Null-Space constrained Policy Optimization (NSPO), a novel RL framework for LLM safety alignment while preserving their core abilities. The safety policy gradients are geometrically projected into the null space of general tasks, thereby mitigating the safety alignment tax. In addition, we theoretically prove that NSPO preserves the model's original core capabilities, while still guaranteeing a descent direction for effective safety alignment. Extensive experiments demonstrate that NSPO outperforms existing methods by a large margin, achieving state-of-the-art safety performance without sacrificing accuracy on general tasks, including math, code, and instruction-following tasks. Notably, NSPO is data-efficient and only requires 40% of public human-annotated safety data from PKU-SafeRLHF to achieve promising safety performance, without a large amount of mixed general tasks data in existing alignment methods.

</details>


### [91] [Sliced ReLU attention: Quasi-linear contextual expressivity via sorting](https://arxiv.org/abs/2512.11411)
*Siwan Boufadène,François-Xavier Vialard*

Main category: cs.LG

TL;DR: 提出切片ReLU注意力机制，通过一维投影和排序实现O(n log n)复杂度，适用于长上下文，同时保持理论表达能力


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如softmax和ReLU-based）在长上下文场景下计算复杂度高，需要一种既高效又保持表达能力的注意力机制

Method: 采用一维投影的键-查询差异，通过排序操作实现准线性复杂度，构建可微分的非对称核函数

Result: 切片ReLU注意力在理论表达力方面与softmax注意力相当，能够执行非平凡的序列到序列解耦任务，并满足上下文通用近似性质

Conclusion: 切片ReLU注意力机制在计算效率和理论表达能力之间取得了良好平衡，为长上下文处理提供了有前景的解决方案

Abstract: We introduce sliced ReLU attention, a new attention mechanism that departs structurally from both softmax and ReLU-based alternatives. Instead of applying a nonlinearity to pairwise dot products, we operate on one-dimensional projections of key--query differences and leverage sorting to obtain quasi-linear complexity. This construction yields a differentiable, non-symmetric kernel that can be computed in O(n log(n)) through a sorting procedure, making it suitable for very long contexts. Beyond computational benefits, the model retains strong theoretical expressive power: we establish two in-context expressivity results, previously known for softmax attention, showing that sliced ReLU attention preserves the ability to perform nontrivial sequence-to-sequence disentangling tasks and satisfies a contextual universal approximation property. Finally, we illustrate the potential practical interest of this kernel in small-scale experiments.

</details>


### [92] [Hyperbolic Gaussian Blurring Mean Shift: A Statistical Mode-Seeking Framework for Clustering in Curved Spaces](https://arxiv.org/abs/2512.11448)
*Arghya Pratihar,Arnab Seal,Swagatam Das,Inesh Chattopadhyay*

Main category: cs.LG

TL;DR: HypeGBMS：将高斯模糊均值漂移扩展到双曲空间，用于层次结构数据聚类


<details>
  <summary>Details</summary>
Motivation: 传统高斯模糊均值漂移（GBMS）在欧几里得空间中能有效识别任意形状的聚类，但对于具有层次或树状结构的数据集效果不佳。双曲空间能更好地表示层次结构，因此需要将GBMS扩展到双曲空间。

Method: 提出HypeGBMS方法，将欧几里得计算替换为双曲距离，并使用Möbius加权均值确保所有更新与空间几何保持一致。该方法保留了GBMS的密度追踪特性，同时适应双曲空间几何。

Result: 在11个真实世界数据集上的实验评估表明，HypeGBMS在非欧几里得设置中显著优于传统均值漂移聚类方法。理论分析提供了收敛性和计算复杂度的见解。

Conclusion: HypeGBMS成功将经典均值漂移聚类与双曲表示学习相结合，为弯曲空间中的基于密度的聚类提供了原则性方法，能有效捕捉潜在层次结构。

Abstract: Clustering is a fundamental unsupervised learning task for uncovering patterns in data. While Gaussian Blurring Mean Shift (GBMS) has proven effective for identifying arbitrarily shaped clusters in Euclidean space, it struggles with datasets exhibiting hierarchical or tree-like structures. In this work, we introduce HypeGBMS, a novel extension of GBMS to hyperbolic space. Our method replaces Euclidean computations with hyperbolic distances and employs Möbius-weighted means to ensure that all updates remain consistent with the geometry of the space. HypeGBMS effectively captures latent hierarchies while retaining the density-seeking behavior of GBMS. We provide theoretical insights into convergence and computational complexity, along with empirical results that demonstrate improved clustering quality in hierarchical datasets. This work bridges classical mean-shift clustering and hyperbolic representation learning, offering a principled approach to density-based clustering in curved spaces. Extensive experimental evaluations on $11$ real-world datasets demonstrate that HypeGBMS significantly outperforms conventional mean-shift clustering methods in non-Euclidean settings, underscoring its robustness and effectiveness.

</details>


### [93] [Rethinking Expert Trajectory Utilization in LLM Post-training](https://arxiv.org/abs/2512.11470)
*Bowen Ding,Yuhan Chen,Jiayang Lv,Jiyao Yuan,Qi Zhu,Shuangshuang Tian,Dantong Zhu,Futing Wang,Heyuan Deng,Fei Mi,Lifeng Shang,Tao Lin*

Main category: cs.LG

TL;DR: 本文提出了塑性-天花板框架，通过分解SFT基础性能和后续RL塑性来优化专家轨迹利用，确立了SFT-then-RL流水线为最佳标准，并提供了具体的扩展指导原则。


<details>
  <summary>Details</summary>
Motivation: 当前有效的后训练通常结合监督微调(SFT)和强化学习(RL)，但如何最优利用专家轨迹的问题尚未解决。本文旨在建立理论框架来指导这一领域，最大化专家轨迹的价值。

Method: 提出了塑性-天花板框架，将性能分解为基础SFT性能和后续RL塑性。通过广泛的基准测试，建立了SFT-then-RL顺序流水线作为标准方法。该框架包含三个关键扩展指导原则：1）在SFT稳定或轻度过拟合阶段转向RL；2）数据规模决定后训练潜力，轨迹难度作为性能乘数；3）使用最小SFT验证损失作为选择专家轨迹的指标。

Result: 研究发现SFT-then-RL流水线优于同步方法，克服了稳定性缺陷。确定了最大化最终性能天花板的三个关键原则：在SFT稳定阶段转向RL、数据规模是主要决定因素而非"少即是多"、最小SFT验证损失是有效的轨迹选择指标。

Conclusion: 塑性-天花板框架为优化专家轨迹利用提供了理论基础和实用指导。SFT-then-RL流水线成为后训练的标准方法，三个扩展原则为最大化模型性能提供了可操作的指导方针。

Abstract: While effective post-training integrates Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), the optimal mechanism for utilizing expert trajectories remains unresolved. We propose the Plasticity-Ceiling Framework to theoretically ground this landscape, decomposing performance into foundational SFT performance and the subsequent RL plasticity. Through extensive benchmarking, we establish the Sequential SFT-then-RL pipeline as the superior standard, overcoming the stability deficits of synchronized approaches. Furthermore, we derive precise scaling guidelines: (1) Transitioning to RL at the SFT Stable or Mild Overfitting Sub-phase maximizes the final ceiling by securing foundational SFT performance without compromising RL plasticity; (2) Refuting ``Less is More'' in the context of SFT-then-RL scaling, we demonstrate that Data Scale determines the primary post-training potential, while Trajectory Difficulty acts as a performance multiplier; and (3) Identifying that the Minimum SFT Validation Loss serves as a robust indicator for selecting the expert trajectories that maximize the final performance ceiling. Our findings provide actionable guidelines for maximizing the value extracted from expert trajectories.

</details>


### [94] [xGR: Efficient Generative Recommendation Serving at Scale](https://arxiv.org/abs/2512.11529)
*Qingxiao Sun,Tongxuan Liu,Shen Zhang,Siyu Wu,Peijun Yang,Haotian Liang,Menxin Li,Xiaolong Ma,Zhiwei Liang,Ziyi Ren,Minchao Zhang,Xinyu Liu,Ke Zhang,Depei Qian,Hailong Yang*

Main category: cs.LG

TL;DR: xGR是一个面向生成式推荐系统的服务系统，通过优化计算流程、提前终止排序和重构流水线，在严格延迟约束下实现高并发场景下的高性能服务。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统虽然整合了LLMs来理解长用户-物品序列，但其工作负载与LLM服务有显著差异。GR通常处理长提示但产生短固定长度输出，且由于大beam宽度导致解码阶段计算成本高，同时beam搜索涉及巨大物品空间使得排序开销特别耗时。

Method: 1. 通过分阶段计算和分离的KV缓存统一prefill和decode阶段处理；2. 实现提前排序终止和基于掩码的物品过滤，并重用数据结构；3. 重构整体流水线以利用多级重叠和多流并行。

Result: 在真实世界推荐服务数据集上的实验表明，xGR在严格延迟约束下相比最先进的基线实现了至少3.49倍的吞吐量提升。

Conclusion: xGR是一个专门为生成式推荐系统设计的服务系统，能够满足高并发场景下的严格低延迟要求，通过多项优化技术显著提升了系统性能。

Abstract: Recommendation system delivers substantial economic benefits by providing personalized predictions. Generative recommendation (GR) integrates LLMs to enhance the understanding of long user-item sequences. Despite employing attention-based architectures, GR's workload differs markedly from that of LLM serving. GR typically processes long prompt while producing short, fixed-length outputs, yet the computational cost of each decode phase is especially high due to the large beam width. In addition, since the beam search involves a vast item space, the sorting overhead becomes particularly time-consuming. We propose xGR, a GR-oriented serving system that meets strict low-latency requirements under highconcurrency scenarios. First, xGR unifies the processing of prefill and decode phases through staged computation and separated KV cache. Second, xGR enables early sorting termination and mask-based item filtering with data structure reuse. Third, xGR reconstructs the overall pipeline to exploit multilevel overlap and multi-stream parallelism. Our experiments with real-world recommendation service datasets demonstrate that xGR achieves at least 3.49x throughput compared to the state-of-the-art baseline under strict latency constraints.

</details>


### [95] [Parametric Numerical Integration with (Differential) Machine Learning](https://arxiv.org/abs/2512.11530)
*Álvaro Leitao,Jonatan Ráfales*

Main category: cs.LG

TL;DR: 提出一种结合导数信息的微分机器学习方法，用于求解参数化积分问题，相比传统机器学习方法在精度、可扩展性和样本效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在求解参数化积分问题时存在精度和效率限制，需要一种能够更好地利用数学结构信息的方法来提高性能。

Method: 采用微分学习框架，在训练过程中融入导数信息，针对三类代表性积分问题：统计泛函（矩和累积分布函数）、切比雪夫展开的函数逼近、以及微分方程产生的积分。

Result: 微分机器学习方法在所有测试案例中都优于标准架构，实现了更低的均方误差、更好的可扩展性和更高的样本效率。

Conclusion: 微分机器学习是求解参数化积分问题的有效方法，通过整合导数信息显著提升了性能，适用于从光滑闭式基准到挑战性数值积分的广泛问题。

Abstract: In this work, we introduce a machine/deep learning methodology to solve parametric integrals. Besides classical machine learning approaches, we consider a differential learning framework that incorporates derivative information during training, emphasizing its advantageous properties. Our study covers three representative problem classes: statistical functionals (including moments and cumulative distribution functions), approximation of functions via Chebyshev expansions, and integrals arising directly from differential equations. These examples range from smooth closed-form benchmarks to challenging numerical integrals. Across all cases, the differential machine learning-based approach consistently outperforms standard architectures, achieving lower mean squared error, enhanced scalability, and improved sample efficiency.

</details>


### [96] [Fully Inductive Node Representation Learning via Graph View Transformation](https://arxiv.org/abs/2512.11561)
*Dooho Lee,Myeong Kong,Minho Jeong,Jaemin Yoo*

Main category: cs.LG

TL;DR: 该论文提出了一种名为视图空间的新表示轴，通过图视图变换(GVT)实现完全归纳的图节点表示学习，在27个节点分类基准测试中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在不重新训练的情况下泛化到未见数据集是基础模型的关键步骤。然而，在图结构化数据中，由于特征空间在维度和语义上差异很大，实现这种跨数据集的完全归纳推理很困难。特征空间的任何变换都可能违反对未见数据集的归纳适用性，严格限制了图模型的设计空间。

Method: 提出了视图空间这一新的表示轴，其中任意图都可以以统一方式自然编码。然后提出了图视图变换(GVT)，这是视图空间中节点和特征置换等变的映射。GVT作为循环GVT的构建块，这是一个用于节点表示学习的完全归纳模型。

Result: 在OGBN-Arxiv上预训练并在27个节点分类基准测试中评估，循环GVT比之前的完全归纳图模型GraphAny高出+8.93%，并且比12个单独调优的GNN至少高出+3.30%。

Conclusion: 这些结果表明视图空间是完全归纳节点表示学习的原理性和有效基础。

Abstract: Generalizing a pretrained model to unseen datasets without retraining is an essential step toward a foundation model. However, achieving such cross-dataset, fully inductive inference is difficult in graph-structured data where feature spaces vary widely in both dimensionality and semantics. Any transformation in the feature space can easily violate the inductive applicability to unseen datasets, strictly limiting the design space of a graph model. In this work, we introduce the view space, a novel representational axis in which arbitrary graphs can be naturally encoded in a unified manner. We then propose Graph View Transformation (GVT), a node- and feature-permutation-equivariant mapping in the view space. GVT serves as the building block for Recurrent GVT, a fully inductive model for node representation learning. Pretrained on OGBN-Arxiv and evaluated on 27 node-classification benchmarks, Recurrent GVT outperforms GraphAny, the prior fully inductive graph model, by +8.93% and surpasses 12 individually tuned GNNs by at least +3.30%. These results establish the view space as a principled and effective ground for fully inductive node representation learning.

</details>


### [97] [A Fast Interpretable Fuzzy Tree Learner](https://arxiv.org/abs/2512.11616)
*Javier Fumanal-Idocin,Raquel Fernandez-Peralta,Javier Andreu-Perez*

Main category: cs.LG

TL;DR: 提出一种基于贪婪算法的模糊树方法，将经典决策树分裂算法适配到模糊规则系统，在保持可解释性的同时显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: 模糊规则系统因其可解释性常用于决策，但现有方法难以同时保证合理的语言划分和小规则库规模。进化方法计算成本高，神经方法如ANFIS难以保持语言可解释性

Method: 将经典决策树分裂算法从清晰规则适配到模糊树，结合贪婪算法的计算效率和模糊逻辑的可解释性优势

Result: 相比进化方法显著提升运行时间，保持竞争力的预测性能，在表格分类基准测试中达到与最先进模糊分类器相当的准确率，计算成本显著降低，产生更可解释且复杂度受限的规则库

Conclusion: 该方法成功平衡了模糊系统的可解释性和计算效率，为可解释决策提供了实用解决方案

Abstract: Fuzzy rule-based systems have been mostly used in interpretable decision-making because of their interpretable linguistic rules. However, interpretability requires both sensible linguistic partitions and small rule-base sizes, which are not guaranteed by many existing fuzzy rule-mining algorithms. Evolutionary approaches can produce high-quality models but suffer from prohibitive computational costs, while neural-based methods like ANFIS have problems retaining linguistic interpretations. In this work, we propose an adaptation of classical tree-based splitting algorithms from crisp rules to fuzzy trees, combining the computational efficiency of greedy algoritms with the interpretability advantages of fuzzy logic. This approach achieves interpretable linguistic partitions and substantially improves running time compared to evolutionary-based approaches while maintaining competitive predictive performance. Our experiments on tabular classification benchmarks proof that our method achieves comparable accuracy to state-of-the-art fuzzy classifiers with significantly lower computational cost and produces more interpretable rule bases with constrained complexity. Code is available in: https://github.com/Fuminides/fuzzy_greedy_tree_public

</details>


### [98] [Bridging Streaming Continual Learning via In-Context Large Tabular Models](https://arxiv.org/abs/2512.11668)
*Afonso Lourenço,João Gama,Eric P. Xing,Goreti Marreiros*

Main category: cs.LG

TL;DR: 论文提出使用大型上下文表格模型作为流式持续学习的桥梁，通过将无界数据流实时压缩为紧凑摘要，同时满足流学习的数据压缩需求和持续学习的经验回放需求。


<details>
  <summary>Details</summary>
Motivation: 当前持续学习和流学习研究领域各自独立，缺乏有效结合。持续学习关注长期记忆但缺乏实时约束，流学习强调快速适应但忽略遗忘问题。需要一种方法能同时处理概念漂移和灾难性遗忘。

Method: 提出使用大型上下文表格模型作为桥梁，将无界数据流实时压缩为紧凑摘要。基于两个核心数据选择原则：1）分布匹配（平衡可塑性和稳定性），2）分布压缩（通过多样化和检索机制控制内存大小）。

Result: 论文提出了一个理论框架，将流学习和持续学习统一在流式持续学习范式下，通过大型上下文表格模型实现数据流的实时压缩和知识保留。

Conclusion: 大型上下文表格模型为流式持续学习提供了自然桥梁，通过分布匹配和分布压缩原则，能够同时满足流学习的数据压缩需求和持续学习的经验回放需求，有效管理可塑性-稳定性权衡。

Abstract: In streaming scenarios, models must learn continuously, adapting to concept drifts without erasing previously acquired knowledge. However, existing research communities address these challenges in isolation. Continual Learning (CL) focuses on long-term retention and mitigating catastrophic forgetting, often without strict real-time constraints. Stream Learning (SL) emphasizes rapid, efficient adaptation to high-frequency data streams, but typically neglects forgetting. Recent efforts have tried to combine these paradigms, yet no clear algorithmic overlap exists. We argue that large in-context tabular models (LTMs) provide a natural bridge for Streaming Continual Learning (SCL). In our view, unbounded streams should be summarized on-the-fly into compact sketches that can be consumed by LTMs. This recovers the classical SL motivation of compressing massive streams with fixed-size guarantees, while simultaneously aligning with the experience-replay desiderata of CL. To clarify this bridge, we show how the SL and CL communities implicitly adopt a divide-to-conquer strategy to manage the tension between plasticity (performing well on the current distribution) and stability (retaining past knowledge), while also imposing a minimal complexity constraint that motivates diversification (avoiding redundancy in what is stored) and retrieval (re-prioritizing past information when needed). Within this perspective, we propose structuring SCL with LTMs around two core principles of data selection for in-context learning: (1) distribution matching, which balances plasticity and stability, and (2) distribution compression, which controls memory size through diversification and retrieval mechanisms.

</details>


### [99] [SpectralKrum: A Spectral-Geometric Defense Against Byzantine Attacks in Federated Learning](https://arxiv.org/abs/2512.11760)
*Aditya Tripathi,Karan Sharma,Rahul Mishra,Tapas Kumar Maiti*

Main category: cs.LG

TL;DR: SpectralKrum是一种联邦学习防御方法，通过谱子空间估计结合几何邻居选择来对抗拜占庭攻击，在非IID数据分布下保持有效性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中拜占庭客户端可以注入任意损坏的更新来破坏全局模型，现有鲁棒聚合方法在非IID数据分布下效果显著下降，特别是当攻击者能够观察或近似防御机制时。

Method: SpectralKrum融合谱子空间估计与几何邻居选择：1）从历史聚合中估计低维流形；2）将传入更新投影到学习到的子空间；3）在压缩坐标中应用Krum选择；4）过滤正交残差能量超过数据驱动阈值的候选者。

Result: 在CIFAR-10的Dirichlet分布非IID分区上评估，对抗8种基线防御和7种攻击场景。SpectralKrum在方向性和子空间感知攻击（adaptive-steer, buffer-drift）中表现有竞争力，但在标签翻转和最小-最大攻击中优势有限，因为恶意更新在谱上难以与良性更新区分。

Conclusion: SpectralKrum提供了一种无需辅助数据、完全基于模型更新的联邦学习防御方法，在非IID数据分布下对某些攻击类型有效，但对谱上难以区分的攻击类型效果有限。

Abstract: Federated Learning (FL) distributes model training across clients who retain their data locally, but this architecture exposes a fundamental vulnerability: Byzantine clients can inject arbitrarily corrupted updates that degrade or subvert the global model. While robust aggregation methods (including Krum, Bulyan, and coordinate-wise defenses) offer theoretical guarantees under idealized assumptions, their effectiveness erodes substantially when client data distributions are heterogeneous (non-IID) and adversaries can observe or approximate the defense mechanism.
  This paper introduces SpectralKrum, a defense that fuses spectral subspace estimation with geometric neighbor-based selection. The core insight is that benign optimization trajectories, despite per-client heterogeneity, concentrate near a low-dimensional manifold that can be estimated from historical aggregates. SpectralKrum projects incoming updates into this learned subspace, applies Krum selection in compressed coordinates, and filters candidates whose orthogonal residual energy exceeds a data-driven threshold. The method requires no auxiliary data, operates entirely on model updates, and preserves FL privacy properties.
  We evaluate SpectralKrum against eight robust baselines across seven attack scenarios on CIFAR-10 with Dirichlet-distributed non-IID partitions (alpha = 0.1). Experiments spanning over 56,000 training rounds show that SpectralKrum is competitive against directional and subspace-aware attacks (adaptive-steer, buffer-drift), but offers limited advantage under label-flip and min-max attacks where malicious updates remain spectrally indistinguishable from benign ones.

</details>


### [100] [Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective](https://arxiv.org/abs/2512.11784)
*Etienne Boursier,Claire Boyer*

Main category: cs.LG

TL;DR: 本文为softmax注意力机制建立了统一的测度理论框架，证明了在长提示条件下softmax注意力会收敛到线性注意力，从而可以将线性注意力的优化分析直接应用于softmax注意力。


<details>
  <summary>Details</summary>
Motivation: softmax注意力是transformer架构的核心组件，但其非线性结构给理论分析带来了显著挑战。现有研究缺乏对softmax注意力在有限和无限提示条件下的统一理论框架。

Method: 开发了基于测度的统一框架来研究单层softmax注意力。对于i.i.d.高斯输入，利用softmax算子在无限提示极限下收敛到作用于底层输入标记测度的线性算子这一事实，建立了输出和梯度的非渐近集中界。

Result: 证明了有限提示模型以可量化的速度趋近其无限提示对应物，且这种集中性在整个训练轨迹上保持稳定。在线性回归的上下文学习中，利用可处理的无限提示动态分析了有限提示长度下的训练。

Conclusion: 当提示足够长时，softmax注意力继承了其线性对应物的分析结构，这为研究softmax注意力层在大提示机制下的训练动态和统计行为提供了原则性且广泛适用的工具包。

Abstract: Softmax attention is a central component of transformer architectures, yet its nonlinear structure poses significant challenges for theoretical analysis. We develop a unified, measure-based framework for studying single-layer softmax attention under both finite and infinite prompts. For i.i.d. Gaussian inputs, we lean on the fact that the softmax operator converges in the infinite-prompt limit to a linear operator acting on the underlying input-token measure. Building on this insight, we establish non-asymptotic concentration bounds for the output and gradient of softmax attention, quantifying how rapidly the finite-prompt model approaches its infinite-prompt counterpart, and prove that this concentration remains stable along the entire training trajectory in general in-context learning settings with sub-Gaussian tokens. In the case of in-context linear regression, we use the tractable infinite-prompt dynamics to analyze training at finite prompt length. Our results allow optimization analyses developed for linear attention to transfer directly to softmax attention when prompts are sufficiently long, showing that large-prompt softmax attention inherits the analytical structure of its linear counterpart. This, in turn, provides a principled and broadly applicable toolkit for studying the training dynamics and statistical behavior of softmax attention layers in large prompt regimes.

</details>


### [101] [A General Algorithm for Detecting Higher-Order Interactions via Random Sequential Additions](https://arxiv.org/abs/2512.11793)
*Ahmad Shamail,Claire McWhite*

Main category: cs.LG

TL;DR: 提出一种基于几何模式的L形分析方法，通过随机顺序添加元素并观察贡献变化来发现特征间的相互作用、冗余和独立性。


<details>
  <summary>Details</summary>
Motivation: 许多系统组件之间存在复杂的相互作用关系，包括相互增强、冗余信息和独立贡献等。现有方法难以统一量化这些不同类型的相互作用结构。

Method: 提出L形几何分析方法：在随机顺序添加元素时绘制贡献变化图，通过观察L形模式识别相互作用结构。引入L-score连续度量指标（-1到+1），量化协同、独立和冗余关系。

Result: 方法能够区分三种基本相互作用模式：冗余对形成L形（仅先添加元素贡献）、协同对形成L形（仅共同添加时贡献）、独立元素显示顺序不变分布。通过成对测量自然涌现高阶相互作用。

Conclusion: 该方法提供了一种度量无关的通用几何框架，适用于任何可以按非重复元素序列增量评估性能的领域，为揭示相互作用结构提供了统一的分析方法。

Abstract: Many systems exhibit complex interactions between their components: some features or actions amplify each other's effects, others provide redundant information, and some contribute independently. We present a simple geometric method for discovering interactions and redundancies: when elements are added in random sequential orders and their contributions plotted over many trials, characteristic L-shaped patterns emerge that directly reflect interaction structure. The approach quantifies how the contribution of each element depends on those added before it, revealing patterns that distinguish interaction, independence, and redundancy on a unified scale. When pairwise contributions are visualized as two--dimensional point clouds, redundant pairs form L--shaped patterns where only the first-added element contributes, while synergistic pairs form L--shaped patterns where only elements contribute together. Independent elements show order--invariant distributions. We formalize this with the L--score, a continuous measure ranging from $-1$ (perfect synergy, e.g. $Y=X_1X_2$) to $0$ (independence) to $+1$ (perfect redundancy, $X_1 \approx X_2$). The relative scaling of the L--shaped arms reveals feature dominance in which element consistently provides more information. Although computed only from pairwise measurements, higher--order interactions among three or more elements emerge naturally through consistent cross--pair relationships (e.g. AB, AC, BC). The method is metric--agnostic and broadly applicable to any domain where performance can be evaluated incrementally over non-repeating element sequences, providing a unified geometric approach to uncovering interaction structure.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [102] [FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration](https://arxiv.org/abs/2512.11213)
*Dongwon Jung,Peng Shi,Yi Zhang*

Main category: cs.AI

TL;DR: FutureWeaver是一个在固定预算下规划和优化多智能体系统中测试时计算分配的框架，通过模块化协作和双级规划架构提升多智能体协作性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时计算扩展技术（如重复采样、自我验证、自我反思）虽然能提升单个大语言模型的性能，但在多智能体系统中难以应用。缺乏原则性的机制来分配计算资源以促进智能体间的协作，无法将测试时计算扩展应用于协作交互，也无法在明确预算约束下跨智能体分配计算资源。

Method: 提出FutureWeaver框架：1）引入模块化协作，将可重复使用的多智能体工作流封装为可调用函数；2）通过自我反思抽象历史轨迹中的重复交互模式自动推导这些模块；3）采用双级规划架构，在推理当前任务状态的同时推测未来步骤，优化计算分配。

Result: 在复杂的智能体基准测试中，FutureWeaver在不同预算设置下始终优于基线方法，验证了其在推理时优化中促进多智能体协作的有效性。

Conclusion: FutureWeaver成功解决了多智能体系统中测试时计算分配的挑战，通过模块化协作和前瞻性规划，在固定预算约束下显著提升了多智能体协作的性能，为推理时优化提供了有效的框架。

Abstract: Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.

</details>


### [103] [TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning](https://arxiv.org/abs/2512.11271)
*Yuxing Chen,Basem Suleiman,Qifan Chen*

Main category: cs.AI

TL;DR: TriFlow是一个渐进式多智能体框架，通过检索、规划、治理三阶段流水线，将开放式用户请求转化为可执行的旅行行程，在严格的空间、时间、预算约束下满足用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在约束满足、工具协调和效率方面存在不足，经常产生不可行或成本过高的计划，无法满足现实世界旅行规划的需求。

Method: TriFlow采用渐进式多智能体框架，通过检索、规划、治理三阶段流水线：1)检索阶段逐步缩小搜索空间；2)规划阶段通过规则-LLM协作组装约束一致的行程；3)治理阶段进行有界迭代优化以确保全局可行性和个性化。

Result: 在TravelPlanner和TripTailor基准测试中取得最先进结果，分别达到91.1%和97%的最终通过率，相比当前SOTA实现了超过10倍的运行时效率提升。

Conclusion: TriFlow通过统一结构化推理和基于语言的灵活性，有效解决了现实世界旅行规划中的约束满足、工具协调和效率问题，为开放式用户请求生成可行且个性化的行程计划。

Abstract: Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.

</details>


### [104] [CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving](https://arxiv.org/abs/2512.11323)
*Jianyi Zhang,Ziyin Zhou,Xu Ji,Shizhao Liu,Zhangchi Zhao*

Main category: cs.AI

TL;DR: 本文提出了首个专门针对大型视觉语言模型（LVLMs）的CAPTCHA基准测试CAPTURE，涵盖4种主要类型和25种子类型，来自31个供应商，用于全面评估LVLMs解决验证码的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉验证码的基准测试存在局限性，无法全面覆盖所有验证码类型，且缺乏专门针对LVLMs的基准测试。先前研究根据特定研究目标定制基准，导致评估不够全面。

Method: 引入名为CAPTURE（CAPTCHA for Testing Under Real-world Experiments）的新基准，包含4种主要验证码类型和25种子类型，来自31个供应商。该基准具有广泛的类别多样性、大规模数据以及专门为LVLMs设计的标签。

Result: 使用该基准评估当前LVLMs时，模型在解决验证码方面表现不佳，显示出LVLMs在实际验证码识别任务中的局限性。

Conclusion: CAPTURE基准填补了先前研究在数据全面性和标签针对性方面的空白，为LVLMs提供了多维度的全面评估工具，揭示了当前模型在验证码解决能力上的不足。

Abstract: Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.

</details>


### [105] [Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance](https://arxiv.org/abs/2512.11421)
*Gonca Gürsun*

Main category: cs.AI

TL;DR: 提出了一个任务完成框架，使基于LLM的智能体能够在强化学习形式化的环境中，在明确的行为指导下执行任务，提高可靠性和可验证性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然表现出强大的推理和生成能力，但在多轮任务中的行为往往缺乏可靠性和可验证性。需要一种框架来指导LLM智能体在结构化环境中执行任务。

Method: 框架包含三个组件：轻量级任务分析器（选择推理和生成策略）、推理模块（学习可验证的观察-动作映射）、生成模块（通过验证或确定性合成确保约束合规输出）。这些组件在与环境交互过程中协同演化。

Result: 框架使智能体能够在强化学习形式化的环境中执行任务，各组件协同演化，产生可信赖的行为。

Conclusion: 该框架通过整合任务分析、可验证推理和约束合规生成，为LLM智能体提供了在结构化环境中可靠执行任务的系统性方法，提高了行为的可靠性和可验证性。

Abstract: Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.
  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.

</details>


### [106] [AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints](https://arxiv.org/abs/2512.11426)
*Shuowei Cai,Yansong Ning,Hao Liu*

Main category: cs.AI

TL;DR: AgentBalance是一个在明确token成本和延迟预算下构建成本效益多智能体系统的框架，采用"先骨干后拓扑"设计，相比现有方法在相同预算下性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统在web规模应用中越来越重要，但现有方法很少在明确的token成本和延迟预算下建模和优化，导致预算约束时成本效益不佳。

Method: 采用"先骨干后拓扑"设计：1)骨干导向的智能体生成，通过LLM池构建、池选择和角色-骨干匹配构建异构骨干智能体；2)自适应MAS拓扑生成，通过智能体表示学习、门控和延迟感知拓扑合成指导智能体间通信。

Result: 在14个候选LLM骨干的基准测试中，AgentBalance在匹配的token成本预算下实现高达10%的性能提升，在延迟预算下实现高达22%的性能提升，并在性能-预算曲线上表现出强AUC。

Conclusion: AgentBalance是一个有效的框架，可在明确预算约束下构建成本效益多智能体系统，可作为现有MAS的插件提升性能，并能很好地泛化到未见过的LLM，实现实用的预算感知部署。

Abstract: Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance

</details>


### [107] [Back to the Baseline: Examining Baseline Effects on Explainability Metrics](https://arxiv.org/abs/2512.11433)
*Agustin Martin Picard,Thibaut Boissin,Varshini Subhash,Rémi Cadène,Thomas Fel*

Main category: cs.AI

TL;DR: 该论文指出当前XAI中基于基准线的保真度评估指标存在严重问题，不同基准线会偏向不同的归因方法，甚至线性模型也会得出矛盾结果。作者提出基准线应具备移除信息且不产生过度分布外图像的特性，并开发了一种新的模型依赖基准线来改善这一权衡。


<details>
  <summary>Details</summary>
Motivation: 当前可解释人工智能中广泛使用的归因方法评估指标（如插入和删除指标）依赖于基准线函数来修改输入图像像素。研究发现，不同基准线的选择会不可避免地偏向某些归因方法，甚至导致相互矛盾的结果，这引发了"应该使用哪个基准线"的根本问题。

Method: 作者通过研究基准线的两个理想属性来探讨此问题：1）能够移除信息；2）不产生过度分布外图像。首先测试了现有基准线，发现它们都无法同时满足这两个标准。然后利用特征可视化领域的最新工作，开发了一种新的模型依赖基准线，该基准线能够移除信息而不产生过度分布外图像。

Result: 研究发现现有基准线都存在权衡：要么能移除信息但会产生分布外图像序列，要么不会产生分布外图像但不能有效移除信息。新提出的模型依赖基准线在权衡方面优于现有基准线，能够更好地移除信息同时避免过度分布外问题。

Conclusion: 基准线选择对归因方法评估有重大影响，当前评估指标存在系统性偏差。作者提出的新基准线通过改进信息移除与分布外图像生成的权衡，为更公平的归因方法评估提供了解决方案。

Abstract: Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline

</details>


### [108] [Three methods, one problem: Classical and AI approaches to no-three-in-line](https://arxiv.org/abs/2512.11469)
*Pranav Ramanathan,Thomas Prellberg,Matthew Lewis,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.AI

TL;DR: 本文首次系统比较了经典优化方法与AI方法在"No-Three-In-Line"问题上的表现，发现整数线性规划(ILP)在19×19网格内能获得最优解，而PatternBoost变换器学习在14×14网格内匹配最优性能，PPO强化学习在10×10网格表现完美但在11×11网格失败。


<details>
  <summary>Details</summary>
Motivation: No-Three-In-Line问题作为组合几何中的著名问题，经典方法如整数线性规划(ILP)虽然能保证最优解，但随着网格规模增大会面临指数级计算复杂度。机器学习方法为模式近似提供了有前景的替代方案，但缺乏系统性的比较研究。

Method: 1. 首次将PatternBoost变换器学习和PPO强化学习应用于该问题；2. 与传统的整数线性规划(ILP)方法进行对比；3. 在不同规模的网格上评估各种方法的性能表现。

Result: 1. ILP在19×19网格内获得可证明的最优解；2. PatternBoost在14×14网格内匹配最优性能，测试损失减少96%；3. PPO在10×10网格上获得完美解，但在11×11网格上因约束违反而失败；4. 经典优化方法对精确解仍至关重要，AI方法在小规模实例上具有竞争力。

Conclusion: 经典优化方法对于精确解仍然必不可少，而AI方法在小规模问题上表现出竞争力。混合方法结合了两者的优势，为扩展到更大规模问题提供了最有前景的方向。

Abstract: The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.

</details>


### [109] [BAID: A Benchmark for Bias Assessment of AI Detectors](https://arxiv.org/abs/2512.11505)
*Priyam Basu,Yunfeng Zhang,Vipul Raheja*

Main category: cs.AI

TL;DR: BAID框架系统评估AI文本检测器在人口统计、年龄、教育水平、方言、正式程度、政治倾向和话题等7个维度的偏见，发现检测器对少数群体文本存在系统性偏差，特别是召回率低。


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测器在教育和工作场景中广泛应用，但缺乏对更广泛社会语言因素的系统性偏见评估。先前研究仅发现对英语学习者的孤立偏见案例，需要更全面的评估框架。

Method: 提出BAID评估框架，包含超过20万个样本，涵盖7个主要类别：人口统计、年龄、教育年级水平、方言、正式程度、政治倾向和话题。为每个样本生成合成版本，使用精心设计的提示词保留原始内容同时反映特定子群体的写作风格。使用该框架评估4个开源最先进的AI文本检测器。

Result: 发现检测器在检测性能上存在一致的差异，特别是对来自代表性不足群体的文本召回率较低。检测器在不同社会语言群体间的表现存在系统性偏差。

Conclusion: BAID提供了一个可扩展、透明的AI检测器审计方法，强调在这些工具部署供公众使用之前需要进行偏见感知的评估。研究揭示了当前AI文本检测器存在的系统性偏见问题。

Abstract: AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.

</details>


### [110] [AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives](https://arxiv.org/abs/2512.11544)
*Yuan Shen,Xiaojun Wu,Linghua Yu*

Main category: cs.AI

TL;DR: 研究通过模拟真实临床场景，系统评估主流大语言模型从含噪声和冗余的患者主诉中提取核心医疗信息的能力，发现所有模型均存在不同程度功能缺陷，并提出"AI-代谢功能障碍相关脂肪性肝病"概念。


<details>
  <summary>Details</summary>
Motivation: 验证大语言模型在处理含噪声和冗余的临床信息时是否会出现类似代谢功能障碍相关脂肪性肝病的功能衰退现象，为AI在医疗领域的应用提供安全警示。

Method: 采用基于标准化医疗探针的横断面分析设计，选取GPT-4o、Gemini 2.5、DeepSeek 3.1和Qwen3-Max四种主流LLMs，使用包含20个医疗探针的评估系统模拟真实临床交流环境，由两位独立临床医生进行双盲逆向评分。

Result: 所有测试模型均表现出不同程度功能缺陷，Qwen3-Max整体表现最佳，Gemini 2.5最差；极端噪声条件下多数模型出现功能崩溃；GPT-4o在深静脉血栓继发肺栓塞风险评估中做出严重误判。

Conclusion: 首次实证证实LLMs在处理临床信息时表现出类似代谢功能障碍的特征，提出"AI-MASLD"创新概念；强调当前LLMs必须在人类专家监督下作为辅助工具使用，其理论知识与实际临床应用仍存在显著差距。

Abstract: This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of "AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.

</details>


### [111] [AI Benchmark Democratization and Carpentry](https://arxiv.org/abs/2512.11588)
*Gregor von Laszewski,Wesley Brewer,Jeyan Thiyagalingam,Juri Papay,Armstrong Foundjem,Piotr Luszczek,Murali Emani,Shirley V. Moore,Vijay Janapa Reddi,Matthew D. Sinclair,Sebastian Lobentanzer,Sujata Goswami,Benjamin Hawks,Marco Colombo,Nhan Tran,Christine R. Kirkpatrick,Abdulkareem Alsudais,Gregg Barrett,Tianhao Li,Kirsten Morehouse,Shivaram Venkataraman,Rutwik Jain,Kartik Mathur,Victor Lu,Tejinder Singh,Khojasteh Z. Mirza,Kongtao Chen,Sasidhar Kunapuli,Gavin Farrell,Renato Umeton,Geoffrey C. Fox*

Main category: cs.AI

TL;DR: 论文指出当前AI基准测试存在静态化、资源需求高、与实际应用脱节等问题，提出需要建立动态自适应基准测试框架和AI基准测试工匠技能教育体系。


<details>
  <summary>Details</summary>
Motivation: 传统AI基准测试面临多重挑战：模型架构快速演进、规模扩大、数据集更新、部署环境多样化，导致评估成为移动目标。大型语言模型容易记忆静态基准，造成基准测试结果与实际性能脱节。当前基准测试过于关注顶级硬件上的峰值性能，缺乏对多样化实际场景的指导。

Method: 提出建立动态自适应基准测试框架，包含不断演进的模型、更新的数据和异构平台。倡导AI基准测试工匠技能教育体系，通过技术革新和系统化教育相结合的方式，培养基准测试设计和使用的专业能力。建议社区共同努力建立AI基准测试工匠基础。

Result: 识别出关键障碍包括高资源需求、专用硬件访问受限、基准设计专业知识缺乏、结果与应用领域关联不确定性。通过MLCommons、教育项目和DOE万亿参数联盟等实践经验，发现需要动态、包容的基准测试来确保评估跟上AI发展步伐。

Conclusion: 基准测试必须向动态化转变，纳入演进模型、更新数据和异构平台，同时保持透明度、可重复性和可解释性。动态包容的基准测试将确保评估跟上AI演进步伐，支持负责任、可重复和可访问的AI部署。社区努力可以为AI基准测试工匠技能提供基础。

Abstract: Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.
  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.
  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.

</details>


### [112] [Causal Inference in Energy Demand Prediction](https://arxiv.org/abs/2512.11653)
*Chutian Ma,Grigorii Pomazkin,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.AI

TL;DR: 论文提出了一种基于结构因果模型的能源需求预测方法，利用天气和日历因素的因果关系构建贝叶斯模型，在测试集上达到3.84%的MAPE。


<details>
  <summary>Details</summary>
Motivation: 能源需求预测对电网运营商、工业能源消费者和服务提供商至关重要。能源需求受天气条件（温度、湿度、风速、太阳辐射）和日历信息（小时、月份）等多种因素影响，这些因素之间存在因果依赖关系，使得简单基于相关性的学习方法难以充分处理。

Method: 1. 提出结构因果模型来解释变量间的因果关系；2. 进行完整分析验证因果信念；3. 基于学到的因果洞察作为先验知识构建贝叶斯模型；4. 在未见数据上进行训练和测试。

Result: 1. 因果模型揭示了能源需求对温度波动的响应具有季节依赖性敏感性；2. 发现冬季能源需求方差较低，因为温度变化与日常活动模式之间存在解耦效应；3. 贝叶斯模型在测试集上达到3.84%的MAPE；4. 在两年数据上的交叉验证平均MAPE为3.88%，表现出强鲁棒性。

Conclusion: 通过结构因果模型揭示的因果洞察作为先验知识构建的贝叶斯模型，在能源需求预测任务上实现了最先进的性能，并展现出良好的鲁棒性，为复杂因果依赖关系下的预测问题提供了有效解决方案。

Abstract: Energy demand prediction is critical for grid operators, industrial energy
  consumers, and service providers. Energy demand is influenced by multiple
  factors, including weather conditions (e.g. temperature, humidity, wind
  speed, solar radiation), and calendar information (e.g. hour of day and
  month of year), which further affect daily work and life schedules. These
  factors are causally interdependent, making the problem more complex than
  simple correlation-based learning techniques satisfactorily allow for. We
  propose a structural causal model that explains the causal relationship
  between these variables. A full analysis is performed to validate our causal
  beliefs, also revealing important insights consistent with prior studies.
  For example, our causal model reveals that energy demand responds to
  temperature fluctuations with season-dependent sensitivity. Additionally, we
  find that energy demand exhibits lower variance in winter due to the
  decoupling effect between temperature changes and daily activity patterns.
  We then build a Bayesian model, which takes advantage of the causal insights
  we learned as prior knowledge. The model is trained and tested on unseen
  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on
  the test set. The model also demonstrates strong robustness, as the
  cross-validation across two years of data yields an average MAPE of 3.88 percent.

</details>
