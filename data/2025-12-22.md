<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 44]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 9]
- [cs.AI](#cs.AI) [Total: 17]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 3]
- [cs.LG](#cs.LG) [Total: 40]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Bundling of bipartite entanglement](https://arxiv.org/abs/2512.16979)
*Maike Drieb-Schoen,Florian Dreier,Wolfgang Lechner*

Main category: quant-ph

TL;DR: 研究受限能量子空间中多分划的纠缠谱特性，发现纠缠熵在幺正演化下形成"束"结构，并提出验证纠缠谱一致性的方法


<details>
  <summary>Details</summary>
Motivation: 研究量子多体系统中受限能量子空间内的纠缠特性，特别是多分划下纠缠谱的一致性，这对于理解量子系统的纠缠结构和动力学演化具有重要意义

Method: 在受限能量子空间中分析多分划的纠缠谱特性，利用子空间结构提出验证纠缠谱一致性的方法，针对宇称嵌入子空间设计了多项式时间算法

Result: 证明在受限能量子空间中，多个分划的纠缠谱在整个子空间内相同，纠缠熵在幺正演化下形成"束"结构，并开发出验证纠缠谱一致性的有效方法

Conclusion: 受限能量子空间中的多分划纠缠谱具有一致性，这一发现为理解量子多体系统的纠缠结构和动力学提供了新视角，相关验证方法具有实际应用价值

Abstract: We investigate bipartite entanglement and prove that in constrained energy subspaces, the entanglement spectra of multiple bipartitions are the same across the whole subspace. We show that in quantum many-body systems the bipartite entanglement entropy is affected in such a way that it forms "bundles" under unitary time evolution. Leveraging the structure of the subspace, we present methods to verify whether the entanglement spectrum of two bipartitions is identical throughout the entire subspace. For the subspace defined by the parity embedding, we further provide an algorithm that can determine this in polynomial time.

</details>


### [2] [Subsystems (in)dependence in GIE proposals](https://arxiv.org/abs/2512.17024)
*Nicolas Boulle,Guilherme Franzmann*

Main category: quant-ph

TL;DR: 该论文分析了引力诱导纠缠实验的理论基础，指出子系统独立性假设在规范约束和引力修饰下存在问题，并探讨了微因果性违反如何影响量子引力实验的设计和解释。


<details>
  <summary>Details</summary>
Motivation: 最近提出的引力诱导纠缠实验旨在通过检测两个空间叠加质量之间的纠缠来证明引力的量子性质，但这些实验依赖于子系统独立性的假设。作者旨在通过代数量子场论框架来澄清这些理论基础，揭示在规范约束和引力修饰下子系统独立性的非平凡性。

Method: 使用代数量子场论框架，区分不同的操作性和代数独立性概念。分析引力修饰场下类空间隔可观测量之间的对易关系，探讨当子系统代数不对易时对纠缠见证的影响，特别是Tsirelson界的保持情况。推导引力修饰引起的微因果性违反的估计。

Result: 研究发现，在规范约束和引力修饰下，子系统状态和测量的独立性是非平凡的，类空间隔可观测量之间的对易关系是重要的，这破坏了严格的希尔伯特空间分解。即使子系统代数不对易，对称化的CHSH可观测量仍保持Tsirelson界。作者还推导了引力修饰引起的微因果性违反的估计。

Conclusion: 在线性化协变量子引力中，微因果性违反可能影响量子引力实验室测试的解释、建模和设计，尽管在当前实验体系中可忽略。除了引力诱导纠缠实验外，子系统独立性问题普遍存在于低能（微扰）量子引力中。引力修饰引起的微因果性违反本身可以作为探测引力量子性质的补充途径。

Abstract: Recent proposals suggest that detecting entanglement between two spatially superposed masses would establish the quantum nature of gravity. However, these gravitationally induced entanglement (GIE) experiments rely on assumptions about subsystem independence. We sharpen the theoretical underpinnings of such proposals by examining them through the lens of algebraic quantum field theory (AQFT), distinguishing distinct operational and algebraic notions of independence. We argue that state and measurement independence of subsystems, essential to the experimental logic, is nontrivial in the presence of gauge constraints and gravitational dressing. Using gravitationally dressed fields, we recall that commutation relations between spacelike separated observables are nontrivial, undermining strict Hilbert space factorization. We further explore the implications for entanglement witnesses, investigating the Tsirelson bound when subsystem algebras fail to commute, and showing that the Tsirelson bound persists for a suitably symmetrized CHSH observable even though the operational status of such "joint" observables becomes delicate when commensurability fails. Our analysis highlights how even within linearized covariant quantum gravity, violations of microcausality may affect both the interpretation, modelling, and design of proposed laboratory tests of quantum gravity, despite remaining negligible for current experimental regimes. Although we consider GIE-style protocols as a concrete case study, the subsystem-independence issues we highlight are generic to low-energy (perturbative) quantum gravity. Finally, we derive estimates for dressing-induced microcausality violations, which suggest a complementary avenue to current proposals: in principle, bounding dressing-induced microcausality violations themselves as a probe of the quantum nature of gravity.

</details>


### [3] [Comparing Homodyne and Heterodyne Tomography of Quantum States of Light](https://arxiv.org/abs/2512.17031)
*Rhea P. Fernandes,Andrew J. Pizzimenti,Christos N. Gagatsos,Joseph M. Lukens*

Main category: quant-ph

TL;DR: 该研究比较了零差与外差测量在重构非高斯量子态时的相对效率，发现零差层析在所有测试的非高斯态中都优于外差测量，但两者差距比渐近Cramér-Rao下界所暗示的要小。


<details>
  <summary>Details</summary>
Motivation: 非高斯量子态是光子量子信息处理中的关键资源，其生成和表征在量子光学中日益重要。连续变量层析中一个主要未解决的问题是：零差与外差测量在重构非高斯态时的相对效率比较。

Method: 结合基于Fisher信息的形式化方法与模拟实验，理论分析和数值模拟比较了零差与外差测量在重构非高斯量子态时的性能。

Result: 研究发现零差层析在所有测试的非高斯态中都优于外差测量，但两种测量方式之间的差距比渐近Cramér-Rao下界所暗示的要显著更小。

Conclusion: 该结果对于优化实际连续变量量子系统中的测量策略具有实用价值，为零差测量在非高斯态重构中的优势提供了理论支持。

Abstract: Non-Gaussian quantum states are critical resources in photonic quantum information processing, rendering their generation and characterization of increasing importance in quantum optics. In this work, we theoretically and numerically analyze the relative efficiency of homodyne versus heterodyne measurements for reconstructing non-Gaussian states, a major outstanding question in continuous-variable tomography. Combining a Fisher information-based formalism with simulated experiments, we find homodyne tomography to outperform heterodyne measurements for all non-Gaussian states tested, although the separation between the two modalities proves significantly narrower than suggested by the asymptotic Cramer-Rao lower bound. Our results should find use for optimizing measurement strategies in practical continuous-variable quantum systems.

</details>


### [4] [Attosecond Control of Squeezed Light](https://arxiv.org/abs/2512.17046)
*Russell Zimmerman,Shashank Kumar,Shiva Kant Tiwari,Eric Liu,Francis Walz,Siddhant Pandey,George J. Economou,Hadiseh Alaeian,Chen-Ting Liao,Valentin Walther,Niranjan Shivaram*

Main category: quant-ph

TL;DR: 研究人员通过强超快激光场调制电介质的三阶非线性响应，实现了在阿秒时间尺度上控制压缩光的类型（从振幅压缩到相位压缩），并开发了频率分辨平衡零差检测方案来测量量子噪声压缩。


<details>
  <summary>Details</summary>
Motivation: 压缩光在量子计量学和量子信息科学中具有重要应用，但传统方法主要通过非线性光学相互作用生成，控制压缩程度需要材料工程。本研究旨在开发一种更灵活、更快速的控制方法，实现对压缩光特性的精确调控。

Method: 使用强超快激光场调制电介质的三阶非线性响应，通过控制输入飞秒激光脉冲之间的亚周期相位延迟来调控材料的强场驱动非线性响应。采用频率分辨平衡零差检测方案同时提取不同频率模式的场正交分量。

Result: 成功实现了在阿秒时间尺度上控制压缩光类型的变化（从振幅压缩到相位压缩），并提取了包含飞秒压缩光脉冲不同频率模式间场正交分量量子相关性的完整相干矩阵。

Conclusion: 这项研究为开发具有前所未有的正交压缩控制水平的量子光源开辟了新途径，对多模量子信息处理和通过超快光-物质相互作用测量瞬态量子物质相关性具有重要意义。

Abstract: Squeezed light has revolutionized quantum metrology by enhancing interferometry for sensitive applications such as the detection of gravitational waves. Squeezed light has also played a pivotal role in quantum information science with numerous applications in quantum computing and communication. Previously, squeezed light has been primarily generated using nonlinear optical interactions, where control of the degree of squeezing was possible by tuning the nonlinearity of the generating medium using suitable material engineering. Here, we modulate the third-order nonlinear response in dielectrics with strong ultrafast laser fields to control the degree of squeezing on attosecond time scales. We demonstrate the ability to change the ultrafast squeezed light generated in the nonlinear process from amplitude-squeezed to phase-squeezed by controlling the strong-field-driven nonlinear response of the material through a sub-cycle phase delay between the input femtosecond laser pulses. The squeezing of quantum noise is measured using a frequency-resolved balanced homodyne detection scheme capable of extracting the field quadratures in different frequency modes simultaneously. Using this frequency-resolved measurement we extract the complete coherency matrix containing the quantum correlations between field quadratures across different frequency modes of the femtosecond squeezed light pulse. These results have major implications for the development of quantum light sources with unprecedented levels of control over quadrature squeezing, for applications in multimode quantum information processing, and for measuring transient quantum matter correlations via transduction to quantum field correlations in an ultrafast light-matter interaction.

</details>


### [5] [Molecular Quantum Computations on a Protein](https://arxiv.org/abs/2512.17130)
*Akhil Shajan,Danil Kaliakin,Fangchun Liang,Thaddeus Pellegrini,Hakan Doga,Subhamoy Bhowmik,Susanta Das,Antonio Mezzacapo,Mario Motta,Kenneth M. Merz*

Main category: quant-ph

TL;DR: 该研究实现了基于片段、以量子计算为中心的超级计算工作流，用于计算分子电子结构，并将其应用于预测300原子Trp-cage小蛋白两种构象的相对能量。


<details>
  <summary>Details</summary>
Motivation: 开发一种结合量子与经典计算资源的工作流，实现包含数百甚至数千个原子的蛋白质系统的大规模电子构型相互作用模拟。

Method: 采用基于波函数的嵌入作为碎片化框架，所有原子都明确包含在CI处理中。对单个碎片使用样本量子对角化处理挑战性碎片，使用全构型相互作用处理简单碎片。

Result: 通过比较EWF-(FCI,SQD)与EWF-MP2和EWF-CCSD基准测试，评估了SQD在碎片CI计算中的准确性，证明了该工作流的可行性。

Conclusion: 研究表明，通过量子与经典计算资源的结合使用，可以实现包含数百甚至数千个原子的蛋白质系统的大规模电子构型相互作用模拟。

Abstract: This work presents the implementation of a fragment-based, quantum-centric supercomputing workflow for computing molecular electronic structure using quantum hardware. The workflow is applied to predict the relative energies of two conformers of the 300-atom Trp-cage miniprotein. The methodology employs wave function-based embedding (EWF) as the underlying fragmentation framework, in which all atoms in the system are explicitly included in the CI treatment. CI calculations for individual fragments are performed using either sample-based quantum diagonalization (SQD) for challenging fragments or full configuration interaction (FCI) for trivial fragments. To assess the accuracy of SQD for fragment CI calculations, EWF-(FCI,SQD) results are compared against EWF-MP2 and EWF-CCSD benchmarks. Overall, the results demonstrate that large-scale electronic configuration interaction (CI) simulations of protein systems containing hundreds or even thousands of atoms can be realized through the combined use of quantum and classical computing resources.

</details>


### [6] [Evaluating Sample-Based Krylov Quantum Diagonalization for Heisenberg Models with Applications to Materials Science](https://arxiv.org/abs/2512.17141)
*Roman Firt,Neel Misciasci,Jonathan E. Mueller,Triet Friedhoff,Chinonso Onah,Aaron Schulze,Sarah Mostame*

Main category: quant-ph

TL;DR: SKQD算法在一维和二维海森堡模型上表现良好，能准确计算基态能量和磁化曲线，在量子硬件上成功实现18和30量子比特系统。


<details>
  <summary>Details</summary>
Motivation: 评估SKQD算法在强关联体系中的性能，特别是在基态密集的海森堡模型上，验证其在量子硬件上的实际应用能力。

Method: 使用基于样本的Krylov量子对角化算法，结合问题相关的初始态和磁化扇区扫描，在一维和二维海森堡模型上进行测试。

Result: SKQD能准确再现基态能量和场依赖的磁化曲线，与DMRG和精确对角化结果定性一致，在更各向异性体系中精度系统性提高。在量子硬件上成功实现18和30量子比特海森堡链。

Conclusion: SKQD算法能有效处理强关联海森堡模型，适用于一维和二维几何结构，在量子硬件上具有实际应用潜力。

Abstract: We evaluate the Sample-based Krylov Quantum Diagonalization (SKQD) algorithm on one- and two-dimensional Heisenberg models, including strongly correlated regimes in which the ground state is dense. Using problem-informed initial states and magnetization-sector sweeps, SKQD accurately reproduces ground-state energies and field-dependent magnetization across a range of anisotropies. Benchmarks against DMRG and exact diagonalization show consistent qualitative agreement, with accuracy improving systematically in more anisotropic regimes. We further demonstrate SKQD on quantum hardware by implementing 18- and 30-qubit Heisenberg chains, obtaining magnetization curves that match theoretical expectations. Simulations on small 2D square-lattice systems further demonstrate that the method applies effectively beyond 1D geometries.

</details>


### [7] [fractional-time deformation of quantum coherence in open systems: a non-markovian framework beyond lindblad dynamics](https://arxiv.org/abs/2512.17144)
*Taylan Demir*

Main category: quant-ph

TL;DR: 提出量子主方程的分数时间扩展，引入Caputo型分数时间导数，将分数导数纳入Lindblad框架，扩展指数衰减模型


<details>
  <summary>Details</summary>
Motivation: 传统Lindblad框架中的指数衰减模型无法描述长记忆相干衰减和非马尔可夫性，需要更灵活的模型来捕捉量子系统中的复杂动力学行为

Method: 在量子主方程中引入Caputo型分数时间导数，将分数导数纳入Lindblad框架，建立分数时间量子主方程模型

Result: 分析和数值结果表明，分数动力学自然地产生长记忆相干衰减，为描述非马尔可夫性提供了可解释且灵活的模型

Conclusion: 分数时间量子主方程扩展了传统Lindblad框架，能够更好地描述量子系统中的非马尔可夫动力学和长记忆相干衰减现象

Abstract: In this paper, we propose a fractional time extension of the Quan tum Master Equation. We introduce a Caputo-type fractional derivative in time as an extension of the exponential decay of the Lindblad framework through the incorporation of fractional derivatives into the Lindblad framework. We show that the analytical and numerical results of our analytical and numerical models, demonstrate that fractional dynamics produces long-memory coherence decay naturally and provides an interpretable and flexible model of non-Markovianity.

</details>


### [8] [Zero-added-loss entanglement multiplexing using time-bin spectral shearing](https://arxiv.org/abs/2512.17148)
*Joseph C. Chapman,Muneer Alshowkan,Jack Postlewaite,Saikat Guha,Nageswara Rao*

Main category: quant-ph

TL;DR: 该论文提出了一种基于时间比特纠缠和频谱剪切技术的零附加损耗多路复用光源设计，用于实现高质量量子中继器所需的高速率量子纠缠。


<details>
  <summary>Details</summary>
Motivation: 为了实现量子中继器所需的高速率量子纠缠，需要改进现有的零附加损耗多路复用方案，将其扩展到时间比特纠缠应用场景，并验证频谱剪切技术与时间比特脉冲的兼容性。

Method: 提出了一种使用时间比特纠缠和频谱剪切技术的ZALM光源设计，分析了实验相关的频谱剪切参数以优化频谱多路复用，并通过实验验证了时间比特脉冲与频谱剪切的兼容性。

Result: 实验验证了时间比特脉冲与频谱剪切的兼容性，观察到当相同剪切应用于两个时间比特时没有相位偏移，为频谱剪切技术的更广泛应用铺平了道路。

Conclusion: 该研究将ZALM光源的优势扩展到时间比特纠缠应用场景，证明了时间比特与频谱剪切的兼容性，为频谱剪切技术提供确定性频率偏移的广泛应用开辟了道路。

Abstract: High-quality quantum communications that enable important capabilities, such as distributed quantum computing and sensing, will require quantum repeaters for providing high-quality entanglement. To realize high-rate heralded entanglement for quantum repeaters, Chen et al. [Phys. Rev. Appl. 19, 054209 (2023)] proposed a scheme for heralded-multiplexed generation of quasi-deterministic entangled photon pairs, called zero-added-loss multiplexing (ZALM). Here, we propose a design of ZALM source using time-bin entanglement and spectral shearing. Additionally, we provide an analysis of experimentally relevant spectral-shearing parameters to optimize the spectral multiplexing. Moreover, we experimentally verify the compatibility of time-bin pulses and spectral shearing, as supported by observation of no phase shift when the same shearing is applied to both time bins. These results expand the benefits of applying a ZALM source to time-bin entanglement use cases. Moreover, more fully demonstrating time-bin and spectral shearing compatibility clears a path towards a broader use of spectral shearing that provides a deterministic frequency shift of high utility.

</details>


### [9] [Quantum-enhanced Information Retrieval from Reflective Intelligent Surfaces](https://arxiv.org/abs/2512.17199)
*Shiqian Guo,Tingxiang Ji,Jianqing Liu*

Main category: quant-ph

TL;DR: 提出了一种结合时间分辨量子接收器和多模探测信号的新方法，用于从被动可重构智能表面提取大字母信息，在无需复杂量子资源的情况下实现了超越经典标准量子极限的性能提升。


<details>
  <summary>Details</summary>
Motivation: 被动反向散射系统在能量预算紧张、通信距离短、数据率低的数字应用中广泛使用，但由于经典无线接收器的基本限制，提高数据率会牺牲能量效率或通信距离，阻碍了该技术的更广泛应用。

Method: 开发了一种新颖的时间分辨量子接收器，结合多模探测信号，用于从被动可重构智能表面提取大字母信息。该接收器具有自适应特性，无需依赖复杂或脆弱的量子资源（如纠缠）。

Result: 仿真结果显示，该技术在调制大小达到M=2^8时超越了经典标准量子极限，同时将探测能量减半或将通信距离提高1.41倍。

Conclusion: 提出的时间分辨量子接收器与多模探测信号相结合，能够在无需复杂量子资源的情况下实现显著的量子优势，为被动反向散射系统提供了超越经典限制的性能提升。

Abstract: Information retrieval from passive backscatter systems is widely used in digital applications with tight energy budgets, short communication distances, and low data rates. Due to the fundamental limits of classical wireless receivers, the achievable data rate cannot be increased without compromising either energy efficiency or communication range, thereby hindering the broader adoption of this technology. In this work, we present a novel time-resolving quantum receiver combined with a multi-mode probing signal to extract large-alphabet information modulated by a passive reconfigurable intelligent surface (RIS). The adaptive nature of the proposed receiver yields significant quantum advantages over classical receivers without relying on complex or fragile quantum resources such as entanglement. Simulation results show that the proposed technique surpasses the classical standard quantum limit (SQL) for modulation sizes up to M = 2^8, meanwhile halving the probing energy or increasing the communication distance by a factor of 1.41.

</details>


### [10] [Bound states and decay dynamics in $N$-level Friedrichs model with factorizable interactions](https://arxiv.org/abs/2512.17207)
*Jia-Ming Zhang,Yu Xin,Bing Chen*

Main category: quant-ph

TL;DR: 该论文研究了N能级系统与连续谱相互作用的Friedrichs模型，推导了束缚态和动力学演化的解析表达式，并应用于光子晶体波导中的原子链系统。


<details>
  <summary>Details</summary>
Motivation: 研究N能级系统与连续谱相互作用的单激发Friedrichs模型，旨在理解束缚态的存在条件及其对系统自发衰变的影响，同时探索开放系统的耗散动力学。

Method: 使用投影算符形式推导了束缚态和动力学演化的解析表达式，建立了确定束缚态数量的明确判据，并在马尔可夫极限下得到了能量无关的非厄米哈密顿量描述。

Result: 推导出了束缚态存在的明确判据，发现束缚态的存在抑制了系统的完全自发衰变；获得了开放系统的耗散动力学描述；在光子晶体波导原子链中实现了丰富的衰变动力学和反PT对称哈密顿量。

Conclusion: 该研究为N能级系统与连续谱相互作用的Friedrichs模型提供了完整的解析框架，揭示了束缚态对衰变动力学的关键影响，并在具体物理系统中实现了反PT对称哈密顿量。

Abstract: Considering an $N$-level system interacting factorizably with a continuous spectrum, we derive analytical expressions for the bound states and the dynamical evolution within this single-excitation Friedrichs model by using the projection operator formalism. First, we establish explicit criteria to determine the number of bound states, whose existence suppresses the complete spontaneous decay of the system. Second, we derive the open system's dissipative dynamics, which is naturally described by an energy-independent non-Hermitian Hamiltonian in the Markovian limit. As an example, we apply our framework to an atomic chain embedded in a photonic crystal waveguide, uncovering a rich variety of decay dynamics and realizing an anti-$\mathcal{PT}$-symmetric Hamiltonian in the system's evolution.

</details>


### [11] [Emergent Universality Class in Dissipative Quantum Systems with Dipole Moment Conservation](https://arxiv.org/abs/2512.17210)
*Wenbo Zhou,Yuke Zhang,Pengfei Zhang*

Main category: quant-ph

TL;DR: 该论文研究具有偶极矩守恒的耗散量子系统的非平衡普适动力学，发现了一个新的强相互作用非平衡固定点，揭示了偶极对称性与耗散之间的复杂相互作用。


<details>
  <summary>Details</summary>
Motivation: 理解量子多体系统的非平衡动力学是现代物理学的重大挑战之一。特别是，人们越来越关注那些没有对应平衡态的非平衡普适类的出现。最近实验进展促使研究具有偶极矩守恒的耗散量子系统的普适动力学。

Method: 开发了有效的场论描述，并辅以具体的量子自旋模型来捕捉由此产生的普适行为。分析了强偶极对称性和弱偶极对称性两种情况下的系统动力学。

Result: 揭示了一个新的强相互作用非平衡固定点，该固定点控制着具有强或弱偶极对称性系统的等时相位涨落。在强偶极对称性存在下，电荷输运变为亚扩散，而在弱对称性情况下仍保持扩散性。

Conclusion: 研究结果揭示了量子多体系统中动力学约束与耗散之间复杂的相互作用，为理解非平衡普适类提供了新的视角。

Abstract: Understanding the non-equilibrium dynamics of quantum many-body systems remains one of the grand challenges of modern physics. In particular, increasing attention has been devoted to the emergence of non-equilibrium universality classes that have no equilibrium counterparts. A prominent example is the Kardar-Parisi-Zhang universality class realized in dissipative Bose-Einstein condensates. In this Letter, motivated by recent experimental advances, we investigate the universal dynamics of dissipative quantum systems with dipole moment conservation. We develop an effective field theory description, supported by a concrete quantum spin model, to capture the resulting universal behaviors. Our analysis unveils a novel strongly interacting non-equilibrium fixed point that governs the equal-time phase fluctuations in systems with either strong or weak dipole symmetries. Moreover, charge transport becomes subdiffusive in the presence of strong dipole symmetry, while it remains diffusive in the weakly symmetric case. Our results reveal the intricate interplay between kinetic constraints and dissipation in quantum many-body systems.

</details>


### [12] [An edge-based and subspace reduction encoding scheme to solve the traveling salesman problem in quantum computers](https://arxiv.org/abs/2512.17291)
*Anandu Kalleri Madhu,Chi-Kwong Li,Jami Rönkkö,Mikio Nakahara,Ray-Kuang Lee*

Main category: quant-ph

TL;DR: 本文提出了一种基于边的编码技术，用于在量子计算机上解决旅行商问题，减少了所需的量子比特数量，并在IQM量子计算机上成功求解了4城市TSP实例。


<details>
  <summary>Details</summary>
Motivation: 传统量子计算解决旅行商问题时需要大量量子比特，限制了实际应用。本文旨在开发一种更高效的编码方案，减少量子资源需求，使TSP能在真实量子设备上求解。

Method: 提出基于边的编码技术，结合子空间缩减编码进一步降低TSP解空间的维度。在模拟器和真实量子计算机上测试了4、5、6城市TSP实例，并与传统的基于节点的编码方法进行对比分析。

Result: 在IQM量子计算机上成功获得了4城市TSP实例的最优解。实验表明，提出的编码方案在统计指标、量子资源利用和计算效率方面优于传统方法，特别适用于较小的TSP实例。

Conclusion: 基于边的编码技术为量子计算解决组合优化问题提供了更高效的方案，减少了量子比特需求，在真实量子设备上展现了应用潜力，特别适合小规模TSP实例的求解。

Abstract: This paper introduces a novel edge-based encoding technique for solving the Traveling Salesman Problem (TSP) on a quantum computer, reducing the required number of qubits. For implementation in real quantum devices, we applied the subspace reduction encoding to further reduce the dimension of the TSP solution space. We attack the TSP for 4-, 5-, and 6-city instances in both simulators and real quantum computers across different encoding frameworks. Optimal solutions of the 4-city TSP instance are obtained on state-of-the art IQM quantum computer. Our study presents a comparative analysis between edge-based encoding scheme and the node-based encoding methodology in the literature. Our findings indicate that the proposed encoding scheme outperforms conventional methods in terms of statistical measures, quantum resource utilization, and computational efficiency when applied to smaller TSP instances.

</details>


### [13] [Towards Quantum Advantage in Sparsified Bosonic SYK Models](https://arxiv.org/abs/2512.17294)
*Vaibhav Gautam,Atsushi Matsuo,Masahito Yamazaki*

Main category: quant-ph

TL;DR: 本文提出通过稀疏化玻色子SYK模型来探索量子优势，并研究了该模型的量子模拟，包括经典模拟器和超导量子比特实现，指出了高度混沌系统量子模拟中的微妙问题。


<details>
  <summary>Details</summary>
Motivation: 探索量子优势的实现路径，通过研究玻色子SYK模型的稀疏化来寻找量子计算相对于经典计算的优越性。

Method: 采用稀疏化玻色子SYK模型，在经典模拟器和超导量子比特量子设备上实现量子模拟。

Result: 成功在经典模拟器和量子设备上实现了玻色子SYK模型的量子模拟，并识别了高度混沌系统量子模拟中的微妙技术问题。

Conclusion: 稀疏化玻色子SYK模型是探索量子优势的有前景平台，但需要解决高度混沌系统量子模拟中的技术挑战才能实现真正的量子优势。

Abstract: We advocate the sparsification of bosonic SYK models as a promising arena for the exploration of quantum advantage. We initiate the study of quantum simulations of the models, both in classical simulators and on quantum devices implemented using superconducting qubits. We point out subtleties in the quantum simulations of highly chaotic systems, which should be addressed in the future search for quantum advantage.

</details>


### [14] [Spin minimum uncertainty states for refined uncertainty relations](https://arxiv.org/abs/2512.17307)
*Hao Dai,Yue Zhang*

Main category: quant-ph

TL;DR: 该研究探讨了自旋系统中信息论精炼版海森堡不确定关系的最小不确定态，发现自旋相干态确实达到最小不确定性，同时还识别出相干态家族之外的额外最小不确定态类别。


<details>
  <summary>Details</summary>
Motivation: 传统海森堡不确定关系的最小不确定态已被广泛研究，通常被视为从不确定性角度最经典的量子态。本研究旨在探索自旋系统中信息论精炼版海森堡不确定关系的最小不确定态，以深入了解量子性质及其潜在应用。

Method: 采用两种不同方法：矩阵公式化和维克符号表示，推导出饱和不确定边界的态的显式表达式。研究在一般自旋系统中进行，并与先前研究的玻色子情况进行了比较。

Result: 自旋相干态确实达到最小不确定性，这与它们作为自旋系统经典态的传统认定一致。此外，研究还识别出相干态家族之外的额外最小不确定态类别。通过与玻色子情况的比较，阐明了两种设置之间差异的起源。

Conclusion: 该研究不仅确认了自旋相干态作为信息论精炼版海森堡不确定关系的最小不确定态的地位，还发现了超出相干态家族的新类别最小不确定态，为理解自旋系统中量子经典边界提供了新视角。

Abstract: Minimum uncertainty states of the conventional Heisenberg uncertainty relation have been extensively studied and are often regarded as the most classical quantum states from the perspective of uncertainty, providing valuable insight into the nature of quantumness and its potential applications. In this work, we investigate the minimum uncertainty states associated with an information-theoretic refinement of the Heisenberg uncertainty relation in general spin systems. Using two different approaches, the matrix formulation and the Wick symbol representation, we derive explicit expressions for the states that saturate the uncertainty bound. We show that spin coherent states indeed achieve minimum uncertainty, consistent with their conventional identification as the classical states of spin systems. Moreover, we also identify additional classes of minimum uncertainty states beyond the coherent family. Finally, we compare the spin-system results with the previously studied bosonic case and elucidate the origin of the differences between the two settings.

</details>


### [15] [The Standard Model Symmetry and Qubit Entanglement](https://arxiv.org/abs/2512.17328)
*Jochen Szangolies*

Main category: quant-ph

TL;DR: 该研究将量子引力与量子信息理论结合，通过高维时空的维度约化，从量子纠缠中同时涌现出时空和标准模型规范对称性。


<details>
  <summary>Details</summary>
Motivation: 整合量子引力中时空从量子态纠缠熵涌现的理论与Kaluza-Klein理论中规范对称性从高维引力维度约化产生的思想，探索同时从量子信息中涌现出时空和规范自由度的统一框架。

Method: 将两比特和三比特纠缠系统分别关联到5+1维和9+1维时空，通过选择优先复方向进行维度约化到3+1维。在三比特情况下，约化后保持SU(3)×SU(2)×U(1)/ℤ₆对称性，即标准模型规范群。

Result: 成功展示了从量子纠缠系统可以同时涌现出3+1维时空和标准模型规范对称性。时空从纠缠熵的面积律贡献中涌现，而规范场和物质自由度则来自面积律违反项。还指出了弱力手征性的可能自然起源。

Conclusion: 该构造为从量子信息基础同时涌现出时空和规范自由度提供了统一框架，并可能用于标准模型场的量子模拟，为量子引力与粒子物理的统一提供了新视角。

Abstract: Research at the intersection of quantum gravity and quantum information theory has seen significant success in describing the emergence of spacetime and gravity from quantum states whose entanglement entropy approximately obeys an area law. In a different direction, the Kaluza-Klein proposal aims to recover gauge symmetries by means of dimensional reduction of higher-dimensional gravitational theories. Integrating both, gravitational and gauge degrees of freedom in $3+1$ dimensions may be obtained upon dimensional reduction of higher-dimensional emergent gravity. To this end, we show that entangled systems of two and three qubits can be associated with $5+1$ and $9+1$ dimensional spacetimes respectively, which are reduced to $3+1$ dimensions upon singling out a preferred complex direction. In the latter case, this reduction is invariant under a residual $SU(3) \times SU(2) \times U(1) /\mathbb{Z}_6$ symmetry, the Standard Model gauge group. This motivates a picture in which spacetime emerges from the area law-contribution to the entanglement entropy, while gauge and matter degrees of freedom are due to area law-violating terms. We remark on a possible natural origin of the chirality of the weak force in the given construction. Furthermore, we highlight the possibility of using this construction in quantum simulations of Standard Model fields.

</details>


### [16] [Validating the calibrated creation of heralded single photons](https://arxiv.org/abs/2512.17336)
*Daniel Borrero Landazabal,Kaisa Laiho*

Main category: quant-ph

TL;DR: 该论文实现了一种基于参量下转换的预示单光子源，并开发了通过简单光子关联测量来准确表征光子态特性的方法。


<details>
  <summary>Details</summary>
Motivation: 目前光子对过程和预示单光子的表征主要依赖于符合计数技术，但需要更有效的工具来准确表征光子态的特性，特别是对于低光学模式数的系统。

Method: 在PP-KTP波导中实现电信波长范围的参量下转换预示单光子源，结合传统性能指标开发了损耗容忍的状态表征工具，通过简单光子关联测量获取预示态的平均光子数和光子数奇偶性。

Result: 实验证明仅通过简单光子关联测量就能准确确定光子态特性，该方法可用于校准创建预示单光子和确定表征单量子态的关键可观测量期望值。

Conclusion: 该方法为光子态表征提供了实用工具，特别适用于校准预示单光子源和表征单量子态的关键特性，具有实际应用价值。

Abstract: Coincidence-count discrimination have turned utterly practical in the characterization of photon-pair processes and heralded single photons. Here, we implement a heralded single photon source based on parametric down-conversion (PDC) in a PP-KTP waveguide in the telecom wavelength range involving a low number of optical modes. We extend the toolbox for the loss-tolerant state characterization by combining conventional figures-of-merit in order to access the heralded state's mean photon number and its photon-number parity. Our experiment demonstrates that an accurate determination of these characteristics is possible just through simple photon-correlation measurements. We believe that our results can find usage in the calibrated creation of heralded single photons and in determining the expectation values of observables that are crucial for denoting a single quantum.

</details>


### [17] [Rydberg Atomic RF Sensor-based Quantum Radar](https://arxiv.org/abs/2512.17421)
*Sourav Banerjee,Neel Kanth Kundu*

Main category: quant-ph

TL;DR: 该论文提出了基于里德堡原子的量子雷达系统模型，通过光学读取实现比传统雷达更高的信噪比和更低的测速误差。


<details>
  <summary>Details</summary>
Motivation: 里德堡原子射频传感器在电场检测方面比传统偶极天线具有明显优势，这为开发新型量子雷达提供了理论基础。

Method: 建立了里德堡原子量子雷达的系统模型，采用激光和光子探测器的光学读取方式替代传统电路接收器，推导了信噪比公式，并使用不变函数方法进行多普勒频率估计。

Result: 仿真结果表明，量子雷达相比传统雷达实现了更高的信噪比，并且在速度估计中获得了更低的均方根误差。

Conclusion: 基于里德堡原子的量子雷达系统在性能上优于传统雷达，为量子传感技术在雷达领域的应用提供了有力支持。

Abstract: Rydberg atom-based RF sensors offer distinct advantages over conventional dipole antennas for electric field detection. This paper presents a system model and performance analysis of a Rydberg atom-based quantum radar, which employs optical readout via lasers and photon detectors instead of circuit-based receivers. We derive the signal-to-noise ratio (SNR), compare it with classical radar, and estimate Doppler frequency using an invariant function-based method. Simulations show that the quantum radar achieves higher SNR and lower RMSE in velocity estimation than conventional radar.

</details>


### [18] [Single-Photon Scattering in a Waveguide Coupled to a Lossy or Gain Giant Atom](https://arxiv.org/abs/2512.17456)
*Yu Xin,Jia-Ming Zhang,Bing Chen*

Main category: quant-ph

TL;DR: 研究一维耦合谐振器波导与具有复本征能的巨原子耦合系统中的单光子散射，发现损耗巨原子吸收入射波，增益巨原子放大入射波并在特定能量处产生散射发散，对应谱奇点。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中单光子散射的独特现象，特别是增益巨原子导致的散射发散和谱奇点，探索传统散射理论在非厄米系统中的局限性。

Method: 采用广义投影算符形式，推导散射系数的解析表达式，分析损耗和增益巨原子的散射特性，研究临界散射动力学，并通过高斯波包散射的数值模拟验证理论预测。

Result: 损耗巨原子吸收入射波，增益巨原子放大入射波并在特定能量处产生散射发散（谱奇点）；系统存在连续谱中的束缚态，导致传统时不变散射理论失效；增益系统至少存在一个随时间增长的束缚态，主导长时间动力学。

Conclusion: 非厄米系统中增益巨原子导致散射发散和谱奇点，连续谱中的束缚态使得传统散射理论不适用，系统表现出独特的时变散射动力学特性。

Abstract: This work investigates single-photon scattering in a one-dimensional coupled-resonator waveguide coupled to a giant atom with a complex on-site energy. Within the generalized projection operator formalism, we derive analytical expressions for the scattering coefficients. We find that a lossy giant atom absorbs the incident wave, whereas a gain giant atom not only amplifies the incident wave but also leads to scattering divergence at certain energies, corresponding to spectral singularities. We explore the critical scattering dynamics associated with these singularities, and attribute the persistent wave emission to the existence of a stationary bound state in the continuum. Due to the presence of this bound state, the conventional time-independent scattering theory proves inadequate for such a non-Hermitian system. Furthermore, we show that the system with gain always features at least one time-growing bound state, which dominates the long-time dynamics, and we verify our time-dependent theoretical predictions via numerical simulations of Gaussian wave packet scattering.

</details>


### [19] [Probing an electron spin ensemble with squeezed microwave signals](https://arxiv.org/abs/2512.17490)
*P. Oehrl,F. Fesquet,K. E. Honasoge,M. Handschuh,A. Marx,R. Gross,K. G. Fedorov,H. Huebl*

Main category: quant-ph

TL;DR: 实验研究了压缩微波与电子自旋共振的相互作用，评估自旋系综作为GHz信号量子存储器的潜力，实现了61%的转移效率。


<details>
  <summary>Details</summary>
Motivation: 量子态高效转移到长寿命存储单元（如固态自旋系综）是量子通信、传感和计算应用的关键挑战，需要评估自旋系综作为GHz信号量子存储器的可行性。

Method: 生成高达5dB的压缩微波连续变量态，让信号与自旋系综相互作用，自旋系综通过电感耦合到集总元件超导微波谐振器（合作度C=0.3），使用Wigner层析分析信号。

Result: 观察到压缩微波与自旋激发之间的转移效率约为61%，实验结果与基于量子输入输出形式主义的稳态模型成功匹配。

Conclusion: 研究为自旋基量子存储器的设计参数提供了指导，证明了自旋系综作为GHz信号量子存储器的潜力。

Abstract: The efficient transfer of quantum states into a long-lived storage unit such as solid-state spin ensembles is widely recognized as a critical challenge with significant implications for quantum communication, sensing and computing applications. Here, we experimentally investigate the interaction of propagating squeezed microwaves with an electron spin resonance transition in order to evaluate the use of spin ensembles as quantum memories for GHz signals. We generate continuous variable microwave states with a squeezing of up to 5dB below the vacuum level and let this signal interrogate a spin ensemble, which is inductively coupled to a lumped element superconducting microwave resonator with a cooperativity of C=0.3. Analyzing this signal using Wigner tomography, we observe a transfer efficiency of around 61% between the squeezed microwaves and the spin excitation. We successfully model our experimental results with a dedicated steady-state model based on the quantum input-output formalism and provide guidance for design parameters required to enable spin-based quantum memories.

</details>


### [20] [Bias-Class Discrimination of Universal QRAM Boolean Memories](https://arxiv.org/abs/2512.17503)
*Leonardo Bohac*

Main category: quant-ph

TL;DR: 研究通过固定通用QRAM接口区分布尔内存配置，探讨如何通过相干可寻址查询推断未知布尔函数的偏置类别


<details>
  <summary>Details</summary>
Motivation: 研究在量子内存中存储未知布尔函数的情况下，通过相干可寻址查询能推断出关于函数偏置类别（相对于1/2的不平衡度）的什么信息，这超越了Deutsch-Jozsa的完美区分情况，补充了Bernstein-Vazirani等精确识别设置

Method: 使用固定通用QRAM接口，通过单查询集成状态的两特征空间结构分析，推导出单副本Helstrom最优测量和成功概率的闭式表达式，重点关注相位偏置幅度|μ|（等价于μ²）作为自然判别量

Result: 对于精确权重偏置类别，诱导的单查询集成状态在地址寄存器上具有两特征空间结构，这产生了单副本Helstrom最优测量和成功概率的闭式表达式

Conclusion: 由于补码操作仅改变全局相位，假设p和1-p在信息论上是相同的，因此自然判别量是相位偏置幅度|μ|，这超越了Deutsch-Jozsa的完美区分情况，补充了Bernstein-Vazirani等精确识别设置

Abstract: We study the discrimination of Boolean memory configurations via a fixed Universal QRAM (U-QRAM) interface. Given query access to a quantum memory storing an unknown Boolean function $f:[N]\to\{0,1\}$, we ask: what can be inferred about the bias class of $f$ (its imbalance from $1/2$, up to complement symmetry) using coherent, addressable queries? We show that for exact-weight bias classes, the induced single-query ensemble state on the address register has a two-eigenspace structure that yields closed-form expressions for the single-copy Helstrom-optimal measurement and success probability. Because complementing $f$ changes the state $|ψ\rangle$ only by a global phase, hypotheses $p$ and $1-p$ are information-theoretically identical in this model; thus the natural discriminand is the phase-bias magnitude $|μ|$ (equivalently $μ^2$). This goes beyond the perfect-discrimination case of Deutsch-Jozsa and complements exact-identification settings such as Bernstein-Vazirani.

</details>


### [21] [Refrigeration of a 1D gas of microwave photons](https://arxiv.org/abs/2512.17530)
*Lukas Schamriß,Louis Garbe,Peter Rabl*

Main category: quant-ph

TL;DR: 提出一种通过约瑟夫森非线性元件冷却一维微波光子气体的简单方案，可将光子从高频模式转移到低频模式，实现亚毫开尔文温度的光子气体制备


<details>
  <summary>Details</summary>
Motivation: 研究如何有效冷却微波光子气体，使其温度低于稀释制冷机的典型基温，为量子模拟方案提供新的可能性

Method: 在超导传输线一端并联非线性约瑟夫森元件，设计一种将光子从高频模式转移到低频模式的冷却机制，同时保持光子总数不变

Result: 预测该机制可在实际实验参数下制备亚毫开尔文温度的光子气体，系统展现出平衡场景中不存在的凝聚转变

Conclusion: 该冷却方案为微波光子相互作用的量子模拟提供了新的技术途径，具有重要的应用前景

Abstract: We discuss a conceptually simple scheme for cooling a one dimensional gas of microwave photons in a superconducting transmission line. By shunting one end of the transmission line by a nonlinear Josephson element, we show how a cooling mechanism can be engineered that transfers photons from high- into low-frequency modes, while preserving their total number. We evaluate the resulting nonequilibrium steady state of the photon gas, which arises from a competition between this engineered cooling process and the natural, number non-conserving thermalization with the surrounding bath. Our analysis predicts that for realistic experimental parameters, this mechanism can be used to prepare photonic gases at sub-millikelvin temperatures, considerably below the typical base temperature of a dilution refrigerator. In addition, the system exhibits a new type of condensation transition that does not occur in the corresponding equilibrium scenario. As an outlook, we discuss potential applications of this cooling approach for quantum simulation schemes with interacting microwave photons.

</details>


### [22] [Coherent phase control of orbital-angular-momentum light-induced torque in a double-tripod atom-light coupling scheme](https://arxiv.org/abs/2512.17537)
*Hamid R. Hamedi,Viačeslav Kudriašov,Mažena Mackoit-Sinkevičienė,Julius Ruseckas*

Main category: quant-ph

TL;DR: 五能级双三脚架原子系统在四束强控制光和两束携带轨道角动量的弱涡旋探测光作用下，通过相位可控机制产生光学扭矩，驱动原子在环形几何中旋转流动。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过相位控制机制在原子系统中产生光学扭矩，实现原子流的精确操控，为量子控制、精密测量和量子信息处理提供新方法。

Method: 采用五能级双三脚架原子-光耦合方案，使用四束强相干控制场和两束携带轨道角动量的弱光学涡旋探测光束。通过解析求解稳态条件下的光学布洛赫方程，分析相位变化对扭矩的影响。

Result: 研究表明诱导的扭矩和旋转运动对相位变化高度敏感，双三脚架系统可根据相对相位相干地重构为耦合Λ或双Λ方案，每种构型表现出不同的量子化扭矩特性。

Conclusion: 该相位可控机制能够精确控制原子电流流动，在量子控制、精密测量和量子信息处理领域具有潜在应用价值。

Abstract: We investigate a phase-controllable mechanism for generating optical torque in a five-level double-tripod (DT) atom-light coupling scheme interacting with four strong coherent control fields as well as two weak optical vortex probe beams carrying orbital angular momentum (OAM). The spatial phase gradients of the OAM-carrying probes induce a quantized torque that is transferred to the atoms, rotating them and generating a directed atomic flow within an annular geometry. Analytical solutions of the optical Bloch equations under steady-state conditions show that the induced torque and resulting rotational motion exhibit high sensitivity to phase variations. We show that the DT system coherently reconfigures into either coupled Λ or double-Λ schemes depending on the relative phases, with each configuration exhibiting distinct quantized torque characteristics. This enables precise phase control of the atomic current flow, with potential applications in quantum control, precision measurement, and quantum information processing.

</details>


### [23] [Bloch Motions and Spinning Tops](https://arxiv.org/abs/2512.17549)
*Albert Huber,Paul Schreivogl*

Main category: quant-ph

TL;DR: 该研究将封闭量子系统的动力学用布洛赫矢量表示，通过刚体动力学和可积系统理论建立量子力学与经典力学之间的数学等价性，并推导出量子动力学的稳定性判据和特殊解。


<details>
  <summary>Details</summary>
Motivation: 探索量子系统动力学与经典力学系统之间的数学对应关系，建立统一的框架来分析量子系统的可积性、稳定性和纠缠动力学。

Method: 从冯·诺依曼方程推导布洛赫分量的运动方程，证明其与经典质点分布运动方程的数学等价性；利用海森堡方程推导形成欧拉-泊松系统的布洛赫矢量方程；应用刘维尔可积性理论、诺伊曼模型和哈密顿欧拉-泊松模型识别运动第一积分；推导量子动力学的稳定性判据（劳斯-赫尔维茨判据和能量-卡西米尔方法）。

Result: 证明了量子系统运动方程的刘维尔可积性；推导了量子动力学的稳定性判据；构造了编码复合量子系统复杂动力学的特殊解；推导了中间轴定理的量子类似物；发现了振荡纠缠态（从最大纠缠态到可分态来回变化的动态量子态）。

Conclusion: 该形式主义为量子动力学提供了具体的物理预测，建立了量子力学与经典刚体动力学之间的深刻联系，特别在纠缠动力学分析方面具有重要应用价值。

Abstract: This work investigates the dynamics of closed quantum systems in the Bloch vector representation using methods from rigid body dynamics and the theory of integrable systems. To this end, equations of motion for Bloch components are derived from the von Neumann equation, which are mathematically equivalent to equations of motion for a distribution of point masses from classical mechanics. Furthermore, using the Heisenberg equation, another system of Bloch vector equations is derived, which forms an Euler-Poinsot system, as is commonly encountered in the theory of torque-free spinning tops. This is used to prove the Liouville integrability of the corresponding Hamilton equations of motion, whereby formal connections to the Neumann model of classical Hamiltonian dynamics and the Hamiltonian Euler-Poinsot model are drawn to identify the first integrals of motion. Within the same framework, stability criteria for quantum dynamics are then derived which correspond to the Routh-Hurwitz criterion resp. other criteria following from the Energy-Casimir method of classical Newtonian mechanics. Following that, specific solutions to the equations of motion are constructed that encode the complex dynamics of composite quantum systems. Eventually, to show that this formalism provides concrete physical predictions, an analogue of the intermediate axis theorem is derived and the effect of oscillating entanglement is discussed. As a basis for this, special types of solutions to the equations of motion are derived that constitute oscillating entangled states, i.e., dynamical quantum states that change their entanglement structure from maximally entangled to separable and vice versa.

</details>


### [24] [Group-theoretical analysis of quantum complexity: the oscillator group case](https://arxiv.org/abs/2512.17552)
*K. Andrzejewski,K. Bolonek-Lasoń,P. Kosiński*

Main category: quant-ph

TL;DR: 该论文基于振荡子群的表示理论，完整推导了Nielsen复杂度，通过求解右不变度量下的测地线方程，为振荡子群表示中的任意酉算子复杂度计算提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: 受量子力学过程中复杂性理论快速发展的启发，研究振荡子群表示中酉算子的Nielsen复杂度，旨在建立基于群结构的系统计算方法。

Method: 基于振荡子群的抽象结构，通过考虑相关酉表示将结构提升到算子层面，求解满足自然不变条件的右不变度量下的测地线方程，得到用初等函数表示的显式解。

Result: 获得了振荡子群上测地线方程的显式解，边界条件导致超越方程，测地线长度由该方程的解给出；由于振荡子群的酉不可约表示已分类，理论上可以计算表示中任意酉算子的复杂度。

Conclusion: 建立了基于振荡子群表示的Nielsen复杂度计算完整理论框架，为量子力学过程中酉算子复杂度的系统研究提供了数学基础。

Abstract: Motivated by the recent rapid development of complexity theory applied to quantum mechanical processes we present the complete derivation of Nielsen's complexity of unitaries belonging to the representations of oscillator group. Our approach is based on the observation that the whole problem refers to the structure of the underlying group. The questions concerning the complexity of particular unitaries are solved by lifting the abstract structure to the operator level by considering the relevant unitary representation. For the class of right-invariant metrics obeying natural invariance condition we solve the geodesic equations on oscillator group. The solution is given explicitly in terms of elementary functions. Imposing the boundary conditions yield a transcendental equation and the length of the geodesic is given in terms of the solutions to the latter. Since the unitary irreducible representations of oscillator group are classified this allows us to compute, at least in principle, the complexity of any unitary operator belonging to the representation.

</details>


### [25] [Quantum Mechanics in a Spherical Wedge: Complete Solution and Implications for Angular Momentum Theory](https://arxiv.org/abs/2512.17558)
*Mustafa Bakr,Smain Amari*

Main category: quant-ph

TL;DR: 该论文研究了三维球面楔形区域中粒子的定态薛定谔方程，揭示了对称性破缺边界条件下角动量量子化的新特征，挑战了传统角动量量子数的概念。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在对称性破缺边界条件下角动量量子化的本质，通过精确可解的约束域模型，理解角动量量子数如何从边界条件中产生，以及单值性和极坐标正则性在标准角动量量子化中的不同作用。

Method: 方法是在三维球面楔形区域（0≤r≤R, 0≤θ≤π, 0≤φ≤Φ）中求解具有狄利克雷边界条件的定态薛定谔方程，这是一个精确可解的约束域模型，提供了算子域视角来研究角动量量子化。

Result: 主要结果：1) 定态是方位角坐标的驻波，不是L̂_z的本征态，角动量投影成为具有真正量子不确定性的可观测量；2) 有效方位角量子数μ=n_φπ/Φ通常是非整数，极坐标波函数的平方可积性要求角本征值参数ν满足ν-μ∈ℤ≥0；3) 应用于库仑势表明，氢原子熟悉的整数角动量谱源于定义全球希尔伯特空间域的周期性识别φ∼φ+2π。

Conclusion: 结论是：该模型阐明了单值性（通过方位角拓扑选择整数m）和极坐标正则性（通过解析约束选择整数ℓ≥|m|）在标准轨道角动量量子化中的不同作用，对称性破缺边界条件导致谱重组和非整数有效角动量。

Abstract: We solve the stationary Schrödinger equation for a particle confined to a 3D spherical wedge -- the region $\{(r,θ,φ): 0 \leq r \leq R,\, 0 \leq θ\leq π,\, 0 \leq φ\leq Φ\}$ with Dirichlet BCs on all surfaces. This exactly solvable constrained-domain model exhibits spectral reorganisation under symmetry-breaking BCs and provides an operator-domain viewpoint on angular momentum quantisation. We obtain three main results. First, the stationary states are standing waves in the azimuthal coordinate and consequently are \emph{not} eigenstates of $\hat{L}_z$; we prove $\langle L_z \rangle = 0$ with $ΔL_z = \hbar n_φπ/Φ\neq 0$, demonstrating that angular momentum projection becomes an observable with genuine quantum uncertainty rather than a good quantum number. Second, the effective azimuthal quantum number $μ= n_φπ/Φ$ is generically non-integer, and square-integrability of the polar wavefunctions at both poles requires the angular eigenvalue parameter $ν$ to satisfy $ν- μ\in \mathbb{Z}_{\geq 0}$. This regularity constraint yields a hierarchy: sectoral solutions ($ν= μ$, satisfying the first-order highest-weight condition) exist for any real $μ> 0$, while tesseral and zonal solutions require integer steps, appearing only when $μ$ itself is integer. Third, application to a Coulomb potential shows that the familiar integer angular momentum spectrum of hydrogen arises from the periodic identification $φ\sim φ+ 2π$ that defines the full-sphere Hilbert space domain; modified boundary conditions yield a reorganised spectrum with non-integer effective angular momentum. The model clarifies the distinct roles of single-valuedness (selecting integer $m$ via azimuthal topology) and polar regularity (selecting integer $\ell \geq |m|$ via analytic constraints) in the standard quantisation of orbital angular momentum.

</details>


### [26] [Investigating methods to solve large windfarm optimization problems with a minimum number of qubits using circuit-based quantum computers](https://arxiv.org/abs/2512.17582)
*James Hancock,Matthew Craven,Craig McNeile*

Main category: quant-ph

TL;DR: 研究探讨了使用量子计算解决风电场布局优化问题，将其转化为QUBO问题，测试了两种编码方法（PCE和新型SQOE），在9×9网格上使用最多20个量子比特进行模拟，两种方法表现相当且具有良好的扩展性。


<details>
  <summary>Details</summary>
Motivation: 风电场布局优化是一个复杂的组合优化问题，传统计算方法在处理大规模问题时面临挑战。量子计算为解决这类问题提供了新的可能性，但需要高效的编码方法以减少量子比特需求。

Method: 将风电场布局优化问题转化为二次无约束二进制优化问题，研究并测试了两种编码方法：已有的Pauli相关编码和新型单量子比特算子编码，这些方法每个网格点需要少于一个量子比特。在三个风电场配置上进行测试，包括两个先前研究中的配置和一个基于威尔士实际风电场的模型。

Result: 改进的编码方法使得在量子计算机模拟器上使用最多20个量子比特解决9×9网格的风电场布局优化问题成为可能。两种编码方法表现相当，在测试系统中都显示出良好的扩展特性。

Conclusion: 量子计算方法在解决风电场布局优化问题上具有潜力，两种编码方法都能有效减少量子比特需求并保持良好性能，为未来量子计算在可再生能源优化领域的应用奠定了基础。

Abstract: This study investigates quantum computing approaches for solving the windfarm layout optimization (WFLO) problems formulated as a quadratic unconstrained binary optimization (QUBO) problem. We investigate two encoding methods that require fewer than one qubit per grid point: the previously developed Pauli correlation encoding (PCE) and a novel single-qubit operator encoding (SQOE). These methods are tested on three windfarm configurations - two from prior WFLO scaling studies and a new real-world model based on an existing windfarm in Wales. The improved encoding methods allow us to solve WFLO problems on $9\times 9$ grids using up to 20 qubits on a quantum computer simulator. The results show that both encoding methods perform competitively and demonstrate favorable scaling characteristics across the tested systems.

</details>


### [27] [Frequency-Multiplexed Millimeter-Wave Fault-Tolerant Superconducting Qubits Enabled by an On-Chip Nonreciprocal Control Bus](https://arxiv.org/abs/2512.17588)
*Sajjad Taravati*

Main category: quant-ph

TL;DR: 提出频率复用毫米波超导量子比特概念，通过片上低温非互易时空周期超导频率倍增器作为通用控制总线，用单个低频输入驱动多个不同频率的量子比特，显著抑制Purcell衰减和串扰。


<details>
  <summary>Details</summary>
Motivation: 传统超导量子处理器面临低温布线复杂、微波串扰和Purcell衰减等限制，这些因素阻碍了量子比特规模的扩展。

Method: 设计集成片上低温非互易时空周期超导频率倍增器作为控制总线，将单个低频输入转换为高次谐波梳，每个谐波共振寻址不同频率的量子比特，利用时空调制实现参数频率倍增。

Result: 总线提供信号增益和固有隔离，同时抑制Purcell衰减（提升T1时间），将相干串扰降低两个数量级以上，时空调制产生类似宇宙膨胀的波传播动力学，理论建模证实工程化内存核延长相干时间并重塑噪声谱。

Conclusion: 该架构在超过25个量子比特的阵列中保持门错误低于容错阈值，将串扰主导的错误预算转换为受限于固有材料相干性的预算，为实现前所未有的I/O简化、噪声鲁棒性和可扩展高相干量子处理提供了路径。

Abstract: Scaling superconducting quantum processors is fundamentally limited by the escalating complexity of cryogenic wiring and the debilitating effects of microwave crosstalk and Purcell decay. This paper proposes the concept of frequency-multiplexed millimeter-wave superconducting qubits and demonstrates a novel architecture that integrates an on-chip cryogenic nonreciprocal space-time-periodic superconducting frequency multiplier as a universal control bus for a frequency-multiplexed qubit array. The bus replaces multiple high-frequency XY drive lines with a single low-frequency input tone, which the multiplier converts into a comb of high-order harmonics, each resonantly addressing a distinct qubit. Crucially, the dynamic and nonreciprocal nature of the bus provides signal gain and intrinsic isolation that simultaneously suppresses Purcell decay, enhancing T1 times across all distinct-frequency qubits, and reduces coherent crosstalk by more than two orders of magnitude. The spatiotemporal modulation enables parametric frequency multiplication and creates wave-propagation dynamics analogous to cosmological expansion, with observed redshift-like broadening and deceleration of magnetic-field wavepackets. Theoretical modeling based on a non-Markovian master equation confirms that the engineered memory kernel extends coherence while reshaping the noise spectrum. Full error-budget analysis shows that the architecture maintains gate errors below the fault-tolerance threshold for arrays exceeding 25 qubits, converting a crosstalk-dominated error budget into one limited by intrinsic material coherence. This integrated, frequency-multiplexed, and nonreciprocal control bus therefore offers a path toward unprecedented I/O simplification, noise resilience, and scalable high-coherence quantum processin

</details>


### [28] [The threshold for quantum-classical correspondence is $D \sim \hbar^{\frac43}$](https://arxiv.org/abs/2512.17623)
*Felipe Hernández,Daniel Ranard,C. Jess Riedel*

Main category: quant-ph

TL;DR: 该论文证明了在混沌量子系统中，量子-经典对应关系的阈值是D∼ℏ^{4/3}，而不是之前认为的D≫ℏ^2。当扩散强度D≪ℏ^{4/3}时，即使在Ehrenfest时间后，量子与经典演化也会出现显著差异。


<details>
  <summary>Details</summary>
Motivation: 在混沌量子系统中，量子态在Ehrenfest时间后会显著偏离经典相空间分布，通常用环境退相干来解释量子-经典对应在更长时间尺度上的持续性。之前的研究表明当D≫ℏ^{4/3}时量子与经典演化保持接近，但一些启发式论证认为D≫ℏ^2就足够了。本文旨在澄清这一阈值问题。

Method: 构建了一个显式的Lindblad动力学模型，使用光滑时间依赖的哈密顿量和线性Lindblad算子生成均匀各向同性扩散。通过分析该模型在D∼ℏ^{4/3}阈值附近的行为来验证量子-经典对应关系。

Result: 证明了D∼ℏ^{4/3}确实是量子-经典对应关系超越Ehrenfest时间的阈值。当D≪ℏ^{4/3}时，即使在Ehrenfest时间后，量子与经典演化也会出现与ℏ无关的显著差异，即使对于ℏ无关的"宏观"光滑可观测量也是如此。

Conclusion: 量子-经典对应关系在混沌系统中的阈值是D∼ℏ^{4/3}，而不是更弱的D≫ℏ^2。这一结果澄清了之前关于退相干强度要求的争议，为理解量子混沌系统中的经典极限提供了精确的数学基础。

Abstract: In chaotic quantum systems, an initially localized quantum state can deviate strongly from the corresponding classical phase-space distribution after the Ehrenfest time $t_{\mathrm{E}} \sim \log(\hbar^{-1})$, even in the limit $\hbar \to 0$. Decoherence by the environment is often invoked to explain the persistence of the quantum-classical correspondence at longer timescales. Recent rigorous results for Lindblad dynamics with phase-space diffusion strength $D$ show that quantum and classical evolutions remain close for times that are exponentially longer than the Ehrenfest time whenever $D \gg \hbar^{\frac43}$, in units set by the classical Hamiltonian. At the same time, some heuristic arguments have suggested the weaker condition $D \gg \hbar^{2}$ always suffices. Here we construct an explicit Lindbladian that demonstrates that the scaling $D \sim \hbar^{\frac43}$ is indeed the threshold for quantum-classical correspondence beyond the Ehrenfest time. Our example uses a smooth time-dependent Hamiltonian and linear Lindblad operators generating homogeneous isotropic diffusion. It exhibits an $\hbar$-independent quantum-classical discrepancy at the Ehrenfest time whenever $D \ll \hbar^{\frac43}$, even for $\hbar$-independent "macroscopic" smooth observables.

</details>


### [29] [Fraud detection in credit card transactions using Quantum-Assisted Restricted Boltzmann Machines](https://arxiv.org/abs/2512.17660)
*João Marcos Cavalcanti de Albuquerque Neto,Gustavo Castro do Amaral,Guilherme Penello Temporão*

Main category: quant-ph

TL;DR: 量子计算辅助的受限玻尔兹曼机在信用卡欺诈检测中表现优于经典方法，即使在当前噪声量子退火器上也能实现更好的性能指标。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算处理效率和可用性的提高，新兴量子计算平台的应用案例变得经济相关。研究者希望评估量子计算辅助的受限玻尔兹曼机在真实金融数据集上的性能，特别是用于信用卡欺诈检测。

Method: 使用量子计算辅助的受限玻尔兹曼机方法，在真实量子硬件和模拟器上运行，测试数据集包含巴西金融科技公司Stone提供的1.45亿笔交易数据，用于信用卡欺诈检测。

Result: 量子辅助的RBM方法在大多数性能指标上能够实现优于经典方法的性能，即使使用当前有噪声的量子退火器也能取得良好结果。

Conclusion: 这项研究为在金融系统中实现量子辅助的受限玻尔兹曼机进行一般故障检测铺平了道路，展示了量子计算在金融欺诈检测领域的实际应用潜力。

Abstract: Use cases for emerging quantum computing platforms become economically relevant as the efficiency of processing and availability of quantum computers increase. We assess the performance of Restricted Boltzmann Machines (RBM) assisted by quantum computing, running on real quantum hardware and simulators, using a real dataset containing 145 million transactions provided by Stone, a leading Brazilian fintech, for credit card fraud detection. The results suggest that the quantum-assisted RBM method is able to achieve superior performance in most figures of merit in comparison to classical approaches, even using current noisy quantum annealers. Our study paves the way for implementing quantum-assisted RBMs for general fault detection in financial systems.

</details>


### [30] [Quantum heat current in Terahertz-driven phonon systems](https://arxiv.org/abs/2512.17669)
*Yulong Qiao,Richard. Matthias Geilhufe*

Main category: quant-ph

TL;DR: 研究太赫兹脉冲驱动光学声子模式的超快量子热力学，揭示非马尔可夫耗散效应


<details>
  <summary>Details</summary>
Motivation: 高强度超快激光脉冲为控制和设计量子材料提供了新机遇，太赫兹脉冲可以共振驱动光学声子模式，实现对晶格自由度的动态操控。本研究旨在探索太赫兹脉冲驱动下光学声子模式的超快量子热力学行为。

Method: 采用Caldeira-Leggett型框架，将声子视为与热环境耦合的开放量子系统，推导声子与热浴之间的量子热流，并在实际脉冲协议下分析其行为。

Result: 超快激光驱动可以揭示甚至诱导与常用马尔可夫近似显著偏离的现象，为探测和控制驱动固态系统中的非马尔可夫耗散提供了途径。

Conclusion: 太赫兹脉冲驱动的光学声子模式展现出重要的非马尔可夫热力学效应，这为理解和操控量子材料中的超快能量传递过程提供了新视角。

Abstract: The advent of high-intensity ultrafast laser pulses has opened new opportunities for controlling and designing quantum materials. In particular, terahertz (THz) pulses can resonantly drive optical phonon modes, enabling dynamic manipulation of lattice degrees of freedom. In this work, we investigate the ultrafast quantum thermodynamics of optical phonon mode driven by a THz pulse by treating the phonon as an open quantum system coupled to a thermal environment within a Caldeira-Leggett-type framework. We derive the quantum heat current between the phonon and the bath and analyze its behavior under realistic pulse protocols. Our results demonstrate that ultrafast laser driving can reveal and even induce significant deviations from the commonly adopted Markovian approximation, thereby providing a pathway to probe and control non-Markovian dissipation in driven solid-state systems.

</details>


### [31] [Detecting non-Gaussian entanglement beyond Gaussian criteria](https://arxiv.org/abs/2512.17681)
*Abhinav Verma,Olga Solodovnikova,Jonas S. Neergaard-Nielsen,Ulrik L. Andersen*

Main category: quant-ph

TL;DR: 提出了一种检测非高斯纠缠的新判据，能够识别高斯统计方法无法检测的量子关联


<details>
  <summary>Details</summary>
Motivation: 在连续变量平台中，基于高斯统计的可分性判据（如Duan和Simon判据）无法检测编码在场正交分量高阶矩中的量子关联，这限制了非高斯系统中纠缠的可靠检测

Method: 引入了一种包含高阶正交分量累积量的不可分性判据，扩展了高斯理论，无需完整态层析，可直接从零差和外差数据中评估，并可扩展到两模Fock态任意叠加

Result: 该判据能够揭示基于协方差判据无法检测的非高斯纠缠，为连续变量平台中的非高斯资源识别提供了实验可行的方法

Conclusion: 该工作为解决非高斯系统中纠缠检测的长期挑战提供了新工具，通过利用高阶统计信息扩展了现有纠缠检测框架，具有重要的理论和实验意义

Abstract: Entanglement is central to quantum theory, yet detecting it reliably in non-Gaussian systems remains a long-standing challenge. In continuous-variable platforms, inseparability tests based on Gaussian statistics - such as those of Duan and Simon - fail when quantum correlations are encoded in higher moments of the field quadratures. Here we introduce an inseparability criterion that exposes non-Gaussian entanglement that escapes covariance-based criteria by incorporating higher-order quadrature cumulants. The criterion extends Gaussian theory without requiring full state tomography and can be evaluated directly from homodyne and heterodyne data and is possible to extend to arbitrary superpositions of Fock states in two modes. This provides an experimentally viable approach for identifying non-Gaussian resources in continuous-variable platforms.

</details>


### [32] [Digital-Analog Quantum Computing with Qudits](https://arxiv.org/abs/2512.17697)
*Alatz Alvarez-Ahedo,Mikel Garcia de Andoin,Mikel Sanz*

Main category: quant-ph

TL;DR: 该论文将数字-模拟量子计算框架从两能级系统扩展到d能级系统，通过结合模拟哈密顿量块和单量子比特门实现通用量子计算，并提出了一种最多使用O(d⁴n²)个模拟块来模拟任意两体哈密顿量的协议。


<details>
  <summary>Details</summary>
Motivation: 将数字-模拟量子计算范式从传统的两能级量子比特扩展到多能级量子比特系统，以充分利用量子比特架构的更高维度特性，提高量子计算的表达能力和效率。

Method: 通过将模拟哈密顿量块与从Weyl-Heisenberg基中提取的单量子比特门相结合，扩展数字-模拟量子计算框架到d能级系统，并提出了一种最多使用O(d⁴n²)个模拟块来模拟任意两体哈密顿量的协议。

Result: 成功将数字-模拟量子计算框架扩展到d能级系统，能够模拟包含磁四极矩项的多体量子比特自旋哈密顿量，展示了该方法在处理复杂量子系统模拟方面的强大能力。

Conclusion: 该研究为量子比特架构的数字-模拟量子计算提供了通用框架，通过利用量子比特的更高维度特性，能够更高效地模拟复杂的多体量子系统，为量子计算的实际应用开辟了新途径。

Abstract: Digital-analog quantum computing with two-level systems is a computational paradigm that combines an analog Hamiltonian with single-qubit gates to achieve universality. We extend this framework to $d$-level systems by conjugating an analog Hamiltonian block with single-qudit gates drawn from the Weyl-Heisenberg basis, which provides a natural set of operations for qudit architectures. More specifically, we propose a protocol to simulate arbitrary two-body Hamiltonians with at most $O(d^4 n^2)$ analog blocks. The power of this approach is illustrated by the simulation of many-body qudit spin Hamiltonians including magnetic quadrupolar terms.

</details>


### [33] [Inclusion constants for free spectrahedra with applications to quantum incompatibility](https://arxiv.org/abs/2512.17706)
*Andreas Bluhm,Eric Evert,Igor Klep,Victor Magron,Ion Nechita*

Main category: quant-ph

TL;DR: 该论文研究了自由谱面体包含常数的计算问题，针对笛卡尔积自由单纯形提出了基于非交换多项式优化的计算方法，并应用于量子信息理论中的测量兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 自由谱面体包含问题在硬谱面体包含问题的松弛中具有重要作用，但包含常数的计算在一般情况下缺乏通用方法。虽然在某些高度对称情况下已知最优值，但需要开发更一般的计算方法。

Method: 采用非交换多项式优化方法，结合对相关自由谱面体极点的详细分析，计算笛卡尔积自由单纯形的包含常数。这种方法能够推导出包含常数的闭式解析表达式。

Result: 成功开发了计算笛卡尔积自由单纯形包含常数的一般方法，获得了新的闭式解析表达式。在量子信息理论应用中，证明了不相容测量在变得相容之前能够容忍的白噪声量的新界限，特别研究了一个二值测量和一个k结果测量的情况，以及四个二值量子比特测量的情况。

Conclusion: 该工作为非交换多项式优化在自由谱面体包含常数计算中的应用提供了有效框架，不仅解决了理论计算问题，还在量子信息理论中产生了实际应用价值，为测量兼容性分析提供了新的数学工具。

Abstract: Building on the matrix cube problem, inclusions of free spectrahedra have been used successfully to obtain relaxations of hard spectrahedral inclusion problems. The quality of such a relaxation is quantified by the inclusion constant associated with each free spectrahedron. While optimal values of inclusion constants were known in certain highly symmetric cases, no general method for computing them was available. In this work, we show that inclusion constants for Cartesian products of free simplices can be computed using methods from non-commutative polynomial optimization, together with a detailed analysis of the extreme points of the associated free spectrahedra. This analysis also yields new closed-form analytic expressions for these constants. As an application to quantum information theory, we prove new bounds on the amount of white noise that incompatible measurements can tolerate before they become compatible. In particular, we study the case of one dichotomic and one $k$-outcome measurement, as well as the case of four dichotomic qubit measurements.

</details>


### [34] [Certified bounds on optimization problems in quantum theory](https://arxiv.org/abs/2512.17713)
*Younes Naceur,Jie Wang,Victor Magron,Antonio Acín*

Main category: quant-ph

TL;DR: 提出一种从数值数据中提取精确有理界限的严格框架，用于解决半定松弛方法在量子信息非凸优化中的可认证性问题


<details>
  <summary>Details</summary>
Motivation: 半定松弛方法在量子信息非凸优化中广泛应用，但由于依赖浮点计算，其给出的界限可能超过全局最优解，从而损害结果的可认证性

Method: 引入一个严格框架，从数值数据中提取非交换优化问题的精确有理界限，并扩展到稀疏性和对称性适应的半定松弛方法

Result: 将该方法应用于量子信息理论中的几个典型问题，建立了有理后处理作为可靠认证的实用途径

Conclusion: 有理后处理将半定优化推向量子信息科学中可认证的标准，为解决非凸优化问题的可认证性提供了实用方案

Abstract: Semidefinite relaxations of polynomial optimization have become a central tool for addressing the non-convex optimization problems over non-commutative operators that are ubiquitous in quantum information theory and, more in general, quantum physics. Yet, as these global relaxation methods rely on floating-point methods, the bounds issued by the semidefinite solver can - and often do - exceed the global optimum, undermining their certifiability. To counter this issue, we introduce a rigorous framework for extracting exact rational bounds on non-commutative optimization problems from numerical data, and apply it to several paradigmatic problems in quantum information theory. An extension to sparsity and symmetry-adapted semidefinite relaxations is also provided and compared to the general dense scheme. Our results establish rational post-processing as a practical route to reliable certification, pushing semidefinite optimization toward a certifiable standard for quantum information science.

</details>


### [35] [Continuum Limits of Lazy Open Quantum Walks](https://arxiv.org/abs/2512.17755)
*Lara Janiurek,Viv Kendon*

Main category: quant-ph

TL;DR: 本文推导了一维懒惰离散时间量子行走的连续时空极限，获得了在退相干存在下三态模型的显式宏观演化方程，超越了先前仅有的两态量子行走连续极限研究。


<details>
  <summary>Details</summary>
Motivation: 虽然两态量子行走的连续极限已建立，但包含噪声的懒惰三态行走的显式连续时空公式尚未构建。本文旨在填补这一空白，为理解内部对称性、静止态耦合和不同退相干通道如何影响懒惰开放量子行走的大尺度输运提供理论框架。

Method: 使用SU(3)表示Grover型硬币，结合Lindblad公式描述作用于硬币或空间子空间的退相干，系统地展开离散动力学在空间和时间上的展开，获得控制粗粒度演化的连续主方程。

Result: 得到的生成元产生真正的偏微分方程描述。在幺正极限下，系统由Dirac型SU(3)哈密顿量控制，描述左右移动模式的弹道平流，由局部对称混合耦合，静止态作为额外的内部自由度。硬币退相选择性地阻尼内部相干性而保持相干空间输运，空间退相抑制长程空间干涉并快速驱动动力学趋向经典行为。

Conclusion: 该连续框架阐明了内部对称性、静止态耦合和不同退相干通道如何塑造懒惰开放量子行走的大尺度输运，为未来扩展到多通道量子输运模型和量子启发算法提供了基础。

Abstract: We derive the continuous spacetime limit of the one dimensional lazy discrete time quantum walk, obtaining explicit macroscopic evolution equations for a three state model in the presence of decoherence. While continuum limits of two state quantum walks are well established, an explicit continuous spacetime formulation for the lazy three state walk, particularly including noise, has not previously been constructed. Using an SU(3) representation of a Grover type coin together with a Lindblad formulation of decoherence acting either on the coin or the spatial subspace, we systematically expand the discrete dynamics in both space and time to obtain continuum master equations governing the coarse grained evolution. The resulting generators yield a genuine partial differential equation description of the walk, going beyond purely probabilistic or spectral correspondences. We show that the unitary limit is governed by a Dirac-type SU(3) Hamiltonian describing ballistic advection of left and right moving modes coupled by local symmetric mixing, with the rest state acting as an additional internal degree of freedom. Coin dephasing selectively damps internal coherences while preserving coherent spatial transport, whereas spatial dephasing suppresses long range spatial interference and rapidly drives the dynamics toward classical behaviour. This continuum framework clarifies how internal symmetry, rest state coupling, and distinct decoherence channels shape large scale transport in lazy open quantum walks, and provides a foundation for future extensions toward multichannel quantum transport models and quantum-inspired algorithms.

</details>


### [36] [Demonstration of a quantum comparator on an ion-trap quantum device](https://arxiv.org/abs/2512.17779)
*Tatsuhiko N. Ikeda,Riku Nakama,Shunsuke Saeki,Hiroki Kuwata,Shuhei M. Yoshida,Akira Shimizu,Sho Sugiura*

Main category: quant-ph

TL;DR: 在RIKEN的Reimei量子计算机上成功演示了量子整数比较运算，实现了远超以往实验规模的可靠量子算术电路


<details>
  <summary>Details</summary>
Motivation: 量子计算机被认为能在基于模运算的计算问题上比经典计算机更快，而整数比较是算术运算的基本构建模块，需要在实际量子硬件上验证其可行性

Method: 使用RIKEN的Reimei量子计算机，该计算机采用囚禁离子架构，提供全连接量子比特和高保真度门操作，在不同比特宽度（n=3,5,7,9）上测试量子比较运算

Result: 在n=9时，传统输出成功率标准下达到95%；在更严格标准（要求辅助比特也正确）下达到69%。这些结果远超以往实验规模

Conclusion: 该实验成功演示了远超先前实验规模的可靠量子比较运算，不仅为量子比较器，也为更广泛的量子算术电路发展提供了重要进展

Abstract: Quantum computers are believed to solve a class of computational problems that are based on modular arithmetic faster than classical computers. Among the arithmetic building blocks, comparison of integer pairs is a primitive. Here we report its demonstration in the Reimei quantum computer at RIKEN, whose trapped-ion architecture provides all-to-all qubit connectivity together with high gate fidelities. We observe high success probabilities for bit widths n = 3, 5, 7, and 9: Under a conventional output-only success criterion we obtain 95% at n=9; under a stricter criterion additionally requiring the ancilla to be correct, the success is 69% at n=9. These results demonstrate reliable quantum comparison at scales far beyond those previously achieved experimentally, not only for comparators but also in the broader context of quantum arithmetic circuits.

</details>


### [37] [Adiabatic preparation of many-body quantum states: getting the beginning and ending right](https://arxiv.org/abs/2512.17780)
*Emil T. M. Pedersen,Freek Witteveen,Klaus Mølmer,Matthias Christandl*

Main category: quant-ph

TL;DR: 该研究通过数值计算和里德堡原子量子模拟器实验，展示了在量子相变附近进行绝热演化时，采用平滑的初始和最终调度函数可以抑制端到端转移误差。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统绝热演化中的误差控制问题，特别是在量子相变附近，传统方法可能面临较大误差，需要寻找更有效的调度策略来降低转移误差。

Method: 使用一维混合场伊辛模型和里德堡原子链，通过数值计算和实验对比不同调度函数下的端到端转移误差。特别研究了哈密顿量在初始和最终时刻具有n阶可导且导数消失的情况。

Result: 研究发现，如果时间依赖的哈密顿量在开始和结束时具有n阶可导且1到n阶导数都为零，那么相对于最终绝热本征态的保真度误差随演化时间T按1/T^{n+1}的比例缩放。

Conclusion: 采用平滑的初始和最终调度函数可以有效抑制量子绝热演化过程中的端到端转移误差，这为量子计算和量子模拟中的绝热演化控制提供了重要指导。

Abstract: We present numerical calculations, and simulations performed on a Rydberg atom quantum simulator, of the adiabatic evolution of many-body quantum systems around a quantum phase transition. We demonstrate that the end-to-end transfer error, for a given process duration and dissipative losses, can be suppressed by adopting smooth initial and final scheduling functions for the Hamiltonian. We consider a one-dimensional mixed-field Ising model, as well as a chain of Rydberg atoms, and compare numerical calculations and experimental results for the end-to-end transfer error with different schedule functions. We show, in particular, that if the time dependent Hamiltonian is $n$ times differentiable with vanishing $1^{st}$ to $n^{th}$ order derivatives in the beginning and in the end, the infidelity with respect to the final adiabatic eigenstate scales as $1/T^{n+1}$ when evolving for time $T$.

</details>


### [38] [Kerr-induced non-Gaussianity of ultrafast bright squeezed vacuum](https://arxiv.org/abs/2512.17797)
*Andrei Rasputnyi,Ilya Karuseichyk,Gerd Leuchs,Denis Seletskiy,Maria Chekhova*

Main category: quant-ph

TL;DR: 研究人员通过向亮压缩真空态引入Kerr非线性，实现了确定性生成明亮的非高斯态，并利用单次f-2f干涉仪采样其Husimi函数，观察到从高斯分布到"S"形非高斯轮廓的转变。


<details>
  <summary>Details</summary>
Motivation: 非高斯态是实现容错量子计算和增强计量学的关键资源，但通常很微弱且需要通过后选择获得。本研究旨在通过宏观光态实现确定性生成明亮的非高斯态。

Method: 将Kerr非线性引入亮压缩真空态，使用单次f-2f干涉仪采样其Husimi函数来表征生成的状态，观察非线性相位的统计证据。

Result: 观察到Husimi函数从二维高斯分布转变为"S"形非高斯轮廓，这是强度依赖非线性相位的直接统计证据。虽然Wigner函数的负性无法直接观测，但证明了亮压缩真空态可视为纯压缩相干态的混合，其中一些对损耗具有较好的容忍性。

Conclusion: 这项工作弥合了量子光学和超快非线性光学之间的差距，为需要高光子通量的量子应用开辟了道路，实现了明亮的非高斯态的确定性生成。

Abstract: Non-Gaussian states of light are a critical resource for fault-tolerant quantum computing and enhanced metrology, but are typically faint and often obtained via post-selection. Here, we demonstrate the deterministic generation of a bright non-Gaussian state by introducing a Kerr nonlinearity to a macroscopic state of light called bright squeezed vacuum (BSV). To characterize the resulting state, we use a single-shot f-2f interferometer to sample its Husimi function. We observe a clear transformation from a 2D Gaussian distribution to an 'S'-shaped non-Gaussian profile, which is the direct statistical evidence of the intensity-dependent nonlinear phase. The negativity of the Wigner function, which is an intrinsic property of any pure non-Gaussian state, cannot be observed because BSV is a mixed state even under minute optical loss. However, we show that BSV can be considered as a mixture of pure squeezed coherent states, for some of which Kerr-induced Wigner-function negativity is quite tolerant to loss. This work bridges the gap between quantum optics and ultrafast nonlinear optics, opening a path to quantum applications that require high photon flux.

</details>


### [39] [Domain-Aware Quantum Circuit for QML](https://arxiv.org/abs/2512.17800)
*Gurinder Singh,Thaddeus Pellegrini,Kenneth M. Merz,*

Main category: quant-ph

TL;DR: DAQC是一种利用图像先验知识设计参数化量子电路的方法，通过局部保持的DCT风格编码和纠缠，在NISQ设备上实现高效量子机器学习图像分类。


<details>
  <summary>Details</summary>
Motivation: 解决在噪声中等规模量子设备上设计表达能力强、可训练且对硬件噪声鲁棒的参数化量子电路的挑战，提升量子机器学习在图像分类任务中的性能。

Method: 提出领域感知量子电路，利用图像先验知识，通过非重叠DCT风格之字形窗口进行局部保持编码和纠缠，采用交错编码-纠缠-训练循环，将纠缠应用于承载相邻像素的量子比特，与设备连接性对齐。

Result: 在MNIST、FashionMNIST和PneumoniaMNIST数据集上，DAQC在量子硬件上的性能与强大的经典基线（ResNet-18/50、DenseNet-121、EfficientNet-B0）竞争，并显著优于量子电路搜索基线，是目前量子硬件上QML图像分类任务的最佳报告性能。

Conclusion: DAQC通过局部保持的信息流设计，有效利用有限深度和量子比特，缓解深度诱导和全局纠缠的贫瘠高原效应，为NISQ设备上的量子机器学习图像分类提供了有效的解决方案。

Abstract: Designing parameterized quantum circuits (PQCs) that are expressive, trainable, and robust to hardware noise is a central challenge for quantum machine learning (QML) on noisy intermediate-scale quantum (NISQ) devices. We present a Domain-Aware Quantum Circuit (DAQC) that leverages image priors to guide locality-preserving encoding and entanglement via non-overlapping DCT-style zigzag windows. The design employs interleaved encode-entangle-train cycles, where entanglement is applied among qubits hosting neighboring pixels, aligned to device connectivity. This staged, locality-preserving information flow expands the effective receptive field without deep global mixing, enabling efficient use of limited depth and qubits. The design concentrates representational capacity on short-range correlations, reduces long-range two-qubit operations, and encourages stable optimization, thereby mitigating depth-induced and globally entangled barren-plateau effects. We evaluate DAQC on MNIST, FashionMNIST, and PneumoniaMNIST datasets. On quantum hardware, DAQC achieves performance competitive with strong classical baselines (e.g., ResNet-18/50, DenseNet-121, EfficientNet-B0) and substantially outperforming Quantum Circuit Search (QCS) baselines. To the best of our knowledge, DAQC, which uses a quantum feature extractor with only a linear classical readout (no deep classical backbone), currently achieves the best reported performance on real quantum hardware for QML-based image classification tasks. Code and pretrained models are available at: https://github.com/gurinder-hub/DAQC.

</details>


### [40] [Quantum Wasserstein distance for Gaussian states](https://arxiv.org/abs/2512.17809)
*Anaelle Hertz,Mohammad Ahmadpoor,Oleksandr Dzhenzherov,Augusto Gerolin,Khabat Heshami*

Main category: quant-ph

TL;DR: 该论文提出了计算任意两个单模高斯态之间二阶Wasserstein距离的一般公式，扩展了量子最优传输理论在量子信息处理中的应用。


<details>
  <summary>Details</summary>
Motivation: 量子最优传输和量子Wasserstein距离在量子态区分和量子计量学中具有重要意义，但现有方法主要针对特定量子态，缺乏对一般高斯态距离计算的通用公式。

Method: 基于De Palma和Trevisan引入的量子最优传输形式化方法，推导出任意两个单模高斯态之间二阶Wasserstein距离的一般计算公式。

Result: 获得了单模高斯态二阶Wasserstein距离的封闭形式解，能够从该一般公式中恢复经典高斯分布和热态的已知Wasserstein距离结果。

Conclusion: 该工作为直接比较各种已知距离度量与Wasserstein距离提供了路径，通过封闭形式解促进了量子最优传输理论在量子信息处理中的应用。

Abstract: Optimal transport between classical probability distributions has been proven useful in areas such as machine learning and random combinatorial optimization. Quantum optimal transport, and the quantum Wasserstein distance as the minimal cost associated with transforming one quantum state to another, is expected to have implications in quantum state discrimination and quantum metrology. In this work, following the formalism introduced in [De Palma, G. and Trevisan, D. Ann. Henri Poincaré, {\bf 22} (2021), 3199-3234] to compute the optimal transport plan between two quantum states, we give a general formula for the Wasserstein distance of order 2 between any two one-mode Gaussian states. We discuss how the Wasserstein distance between classical Gaussian distributions and the quantum Wasserstein distance by De Palma and Trevisan for thermal states can be recovered from our general formula for Gaussian states. This opens the path to directly compare various known distance measures with the Wasserstein distance through their closed-form solutions.

</details>


### [41] [Low-loss frequency-tunable Josephson junction array cavities on Ge/SiGe heterostructures with a tapered etching approach](https://arxiv.org/abs/2512.17812)
*Franco De Palma,Elena Acinapura,Wonjin Jang,Fabian Oppliger,Radha Krishnan,Arianna Nigro,Ilaria Zardo,Pasquale Scarlino*

Main category: quant-ph

TL;DR: 通过刻蚀Ge/SiGe异质结构至高阻硅衬底，并在其上直接图案化超导腔，实现了高质量因子微波腔与量子器件的兼容集成。


<details>
  <summary>Details</summary>
Motivation: Ge/SiGe异质结构是量子器件的理想平台，但与高质量因子微波超导腔的兼容性存在挑战，主要由于材料堆叠中的缺陷问题。

Method: 采用反向梯度Ge/SiGe异质结构，将约1.6μm厚的Ge/SiGe堆叠完全刻蚀至高阻硅衬底，直接在其上图案化超导腔。设计锥形台面台阶，使超导腔能够轻松跨越并连接到Ge量子阱中的量子器件。

Result: 实现了高质量因子：约瑟夫森结阵列谐振器的内部质量因子Qi≈10000-20000（受结制备限制），50Ω共面波导Nb剥离谐振器的Qi≈100000。这些质量因子在跨越台面区域时仍能保持，与高阻硅晶圆参考样品相当。

Conclusion: 该工作为超导-半导体混合器件提供了一条实用路径，可直接应用于平面Ge技术中的新兴量子技术。

Abstract: Ge/SiGe heterostructures represent a promising platform for hosting various quantum devices such as hole spin qubits and Andreev spin qubits. However, the compatibility of such heterostructures with high-quality-factor microwave superconducting cavities remains a challenge due to defects in the material stack. In this work, we present an approach to enhance the coherence of cavity modes on a reverse-graded Ge/SiGe heterostructure, which consists of etching the full $\sim 1.6~\mathrm{μm}$-thick Ge/SiGe stack down to its starting high-resistivity Si substrate, in order to pattern superconducting cavities directly on it. We engineer the mesa step to be tapered, so that it can be easily climbed by the superconducting cavities to reach the quantum devices potentially hosted in the Ge quantum well. Using this approach, we observe internal quality factors of $Q_\mathrm{i} \approx 10000-20000$ for high-impedance frequency-tunable Josephson junction array resonators, limited by the junctions' fabrication, and $Q_\mathrm{i} \approx 100000$ for $50~\mathrmΩ$ coplanar waveguide Nb lift-off resonators. These $Q_\mathrm{i}$ are preserved despite the overlap with the mesa structure in the climbing region, and are comparable to the ones obtained for identical resonators fabricated on a high-resistivity Si wafer reference. Thereby, this work paves a practical path toward superconductor-semiconductor hybrid devices, immediately applicable to emerging technologies on planar Ge.

</details>


### [42] [Witnessing Entanglement in Mixed-Particle Quantum Systems](https://arxiv.org/abs/2512.17860)
*Irma Avdic,David A. Mazziotti*

Main category: quant-ph

TL;DR: 该论文提出了一种纠缠见证方法，用于检测混合粒子系统中费米子和玻色子的非对角长程序，量化各粒子类型的纠缠程度，并揭示它们如何共同形成系统的总纠缠。


<details>
  <summary>Details</summary>
Motivation: 研究混合粒子系统中费米子和玻色子纠缠的共存问题，开发能够独立检测和量化两种粒子类型非对角长程序的方法，以理解集体纠缠在多粒子系统中的形成机制。

Method: 通过分析各子系统的粒子-空穴约化密度矩阵，设计纠缠见证方法独立检测费米子和玻色子子系统的非对角长程序，并量化其大小。使用Lipkin-Meshkov-Glick自旋模型进行验证。

Result: 该方法成功检测到混合粒子系统中的非对角长程序，能够区分纠缠局限于单一粒子类型与在两种粒子类型间共享的情况，并量化了费米子和玻色子关联对总纠缠的贡献。

Conclusion: 提出的纠缠见证方法为理解混合粒子系统中的集体纠缠提供了新视角，揭示了费米子和玻色子关联如何协同作用形成非对角长程序，特别是在多体关联驱动的粒子-空穴对玻色凝聚方面。

Abstract: We introduce an entanglement witness that identifies off-diagonal long-range order (ODLRO) -- a distinctive form of entanglement -- in systems containing both fermionic and bosonic particles. By analyzing the particle-hole reduced density matrices of each subsystem, the approach detects ODLRO independently in both fermionic and bosonic sectors and identifies when long-range order develops across the entire mixed-particle system. The witness also quantifies the magnitude of ODLRO within each particle type, revealing how fermionic and bosonic correlations combine to form the total entanglement of the system, including a bosonic condensation of particle-hole pairs driven by many-body correlations rather than particle statistics. Using the Lipkin-Meshkov-Glick spin model, we show how the transition from ODLRO localized to one particle type to ODLRO shared by both particle types captures the onset of collective entanglement in a mixed-particle environment, providing new insight into systems where fermionic and bosonic correlations coexist.

</details>


### [43] [Simulation of topological superconductors and their competing orders using photon-mediated interactions](https://arxiv.org/abs/2512.17889)
*Anjun Chu,Joyce Kwan,Eric Yilun Song,Seth Hew Peng Chew,James K. Thompson,Ana Maria Rey*

Main category: quant-ph

TL;DR: 该论文提出了一种基于腔QED的量子模拟器，用于实现和调控拓扑超导体的非常规配对，特别是竞争性的手性p波和d波配对序。


<details>
  <summary>Details</summary>
Motivation: 实现和控制拓扑超导体的非常规配对是一个核心挑战，特别是在固态和超冷原子系统中这些相仍然难以捉摸。需要一种能够工程化竞争性配对通道并直接观测拓扑相变的平台。

Method: 引入腔QED量子模拟器，通过定制腔介导的原子赝自旋耦合来模拟动量依赖的配对通道。利用腔QED系统中自然存在的不共格腔-晶格波长，在二维光学晶格中工程化所需的空间非均匀腔介导耦合。

Result: 该平台实现了受控态制备和对超导序参数的连续测量，揭示了平衡态和猝灭设置下的相，包括单一主导配对通道的相以及竞争配对通道共存区域。特别重要的是，该实现允许直接观测平衡态和非平衡态下的拓扑相变。

Conclusion: 这种最小化且完全可调的腔QED量子模拟器为量子模拟竞争性拓扑超导相提供了一条强大途径，这些相在固态和超冷原子系统中仍然难以实现，为研究拓扑超导体的非常规配对开辟了新方向。

Abstract: Realizing and controlling the unconventional pairing featured by topological superconductors remains a central challenge. We introduce a cavity QED quantum simulator that engineers competing chiral $p_x+ip_y$ and $d_{x^2-y^2}+id_{xy}$ orders by tailoring cavity-mediated couplings between atomic pseudospins that emulate momentum-dependent pairing channels. The desired spatially inhomogeneous cavity-mediated couplings can be engineered in a 2D optical lattice using incommensurate cavity-lattice wavelengths naturally occurring in cavity QED systems. This minimal and fully tunable platform enables controlled state preparation and continuous measurement of superconducting order parameters, revealing phases in both equilibrium and sudden-quench settings with a single dominant pairing channel, as well as coexistence regimes with competing pairing channels. Crucially, our implementation allows direct observation of topological transitions in and out of equilibrium, providing a powerful route to the quantum simulation of competing topological superconducting phases that remain elusive in solid-state and ultracold-atom systems.

</details>


### [44] [Visualizing Detection Efficiency in Optomechanical Scattering](https://arxiv.org/abs/2512.17894)
*Youssef Tawfik,Shan Hao,Thomas P. Purdy*

Main category: quant-ph

TL;DR: 研究人员开发了一种可视化方法，用于评估光学测量方案如何有效捕获散射光中的信息，并通过实验证明阻挡部分光电探测器区域可以增强对高阶机械模式的检测灵敏度。


<details>
  <summary>Details</summary>
Motivation: 许多光学测量技术（如波长尺度粒子的光散射或光学杠杆检测表面运动）将信息编码在复杂的辐射模式中。提取所有可用信息对于量子增强传感协议至关重要，但通常不切实际，因为需要许多通道来空间解析散射信号。

Method: 提出了一种新方法，通过在探测器表面绘制局部贡献到检测效率的映射，可视化实际测量方案如何有效捕获散射光中的可用信息。使用该工具通过象限光电二极管实验优化了光机械谐振器运动幅度的自由空间测量。

Result: 实验表明，阻挡光电探测器的部分区域可以增强灵敏度，反直觉地显著改善了系统中高阶机械模式的检测。该方法也可应用于小粒子的光散射测量。

Conclusion: 该方法提供了一种实用的工具来优化光学测量方案，通过可视化检测效率的空间分布，能够反直觉地通过阻挡部分探测器区域来提高对高阶模式的检测性能，具有广泛的应用潜力。

Abstract: Many optical measurement techniques, such as light scattering from wavelength-scale particles or detecting motion from a surface with an optical lever, encode information in a complex radiation pattern. Extracting all available information is essential for many quantum-enhanced sensing protocols but is often impractical, as it requires many channels to spatially resolve the scattered signal. We present a new method to visualize how efficiently a practical measurement scheme captures the information available in the scattered light by mapping out the local contribution to the detection efficiency on the detector surface. We use this tool to experimentally optimize the free space measurement of the amplitude of motion of an optomechanical resonator with a quadrant photodiode. We show that blocking sections of the photodetector enhances sensitivity, counterintuitively yielding a significant improvement in detecting higher-order mechanical modes in the system. We also show how our method can be applied to light scattering measurements of small particles.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [45] [A Lindblad-Pauli Framework for Coarse-Grained Chaotic Binary-State Dynamics](https://arxiv.org/abs/2512.17200)
*Yicong Qiu,Qiye Zheng*

Main category: nlin.CD

TL;DR: 该研究为混沌双稳态杜芬振子开发了一个两态密度矩阵框架，将粗粒化的左右统计嵌入2×2密度矩阵表示，用GKSL生成器建模阱间切换，并提供了验证框架的数值管道。


<details>
  <summary>Details</summary>
Motivation: 传统的粗粒化方法将混沌双稳态振荡器简化为二进制符号序列，但这种方法往往掩盖了约化状态空间的几何结构和物理上有意义的随机演化的结构约束。需要一种更好的框架来保留这些重要信息。

Method: 开发了一个两态框架，将驱动杜芬振子的粗粒化左右统计嵌入2×2密度矩阵表示，用两速率GKSL生成器建模阱间切换。对于对角态，GKSL动力学简化为经典两态主方程。采用"Bloch半盘"嵌入，用重叠参数c(ε)量化分区模糊性。通过离散时间Kraus表示构建CPTP映射来扩展框架以处理高阶记忆。

Result: 推导了闭式解、显式Kraus表示（具有退相位和旋转的广义振幅阻尼），以及时间齐次一阶马尔可夫假设的实用诊断方法（阶次检验、Chapman-Kolmogorov一致性、游程统计、平稳性检查）。当出现高阶记忆时，通过增强马尔可夫模型扩展框架。

Conclusion: 密度矩阵形式主义主要是一种组织便利，而非声称量子-经典等价性。该框架为混沌双稳态系统的粗粒化建模提供了更丰富的几何视角和结构约束，并提供了验证框架的数值管道模板。

Abstract: Coarse-graining a chaotic bistable oscillator into a binary symbol sequence is a standard reduction, but it often obscures the geometry of the reduced state space and structural constraints of physically meaningful stochastic evolution. We develop a two-state framework that embeds coarse-grained left/right statistics of the driven Duffing oscillator into a $2\times2$ density-matrix representation and models inter-well switching by a two-rate Gorini--Kossakowski--Sudarshan--Lindblad (GKSL) generator. For diagonal states the GKSL dynamics reduces to the classical two-state master equation.The density-matrix language permits an operational ``Bloch half-disk'' embedding with overlap parameter $c(\varepsilon)$ quantifying partition fuzziness; the GKSL model is fitted to diagonal marginals treating $c(\varepsilon)$ as diagnostic. We derive closed-form solutions, an explicit Kraus representation (generalized amplitude damping with dephasing and rotation), and practical diagnostics for the time-homogeneous first-order Markov assumption (order tests, Chapman--Kolmogorov consistency, run-length statistics, stationarity checks). When higher-order memory appears, we extend the framework via augmented Markov models, constructing CPTP maps through discrete-time Kraus representations; continuous-time GKSL generators may not exist for all empirical transition matrices. We provide a numerical pipeline with templates for validating the framework on Duffing simulations. The density-matrix formalism is an organizational convenience rather than claiming quantum-classical equivalence.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [46] [Exotic coupled spin-charge states in decorated honeycomb magnets: A hybrid-Monte Carlo study](https://arxiv.org/abs/2512.17010)
*Satyabrata Jana,Sahinur Reja*

Main category: cond-mat.str-el

TL;DR: 在受挫装饰蜂窝晶格上的强耦合近藤晶格模型中，发现了四种奇异的自旋-电荷耦合基态，包括超反铁磁、超YK相、铁磁二聚体和三聚体相，这些相通过能带效应稳定


<details>
  <summary>Details</summary>
Motivation: 研究受挫装饰蜂窝晶格上强耦合近藤晶格模型中的奇异自旋-电荷耦合基态，这些基态可能与金属有机框架材料中的电子掺杂自旋系统相关

Method: 采用混合马尔可夫链蒙特卡洛方法，结合经典MCMC处理局域自旋和电子哈密顿量的精确对角化

Result: 发现了四种奇异的自旋-电荷耦合基态：超反铁磁相、超YK相、铁磁二聚体相和铁磁三聚体相，其中磁性纹理将电子限制在碎片化区域，形成平带并打开能隙，通过能带效应稳定这些相

Conclusion: 这些奇异的自旋-电荷耦合基态可能对金属有机框架材料中的电子掺杂自旋系统有重要意义，展示了能带效应在稳定复杂多体态中的作用

Abstract: We uncover four exotic coupled spin-charge ground states in the strong coupling limit of the Kondo lattice model at various electronic fillings on a frustrated decorated honeycomb lattice, where each regular honeycomb sublattice point is occupied by three-site triangular units. We employ a hybrid Markov Chain Monte Carlo (hMCMC) simulation method which combines classical MCMC for localized spins and exact diagonalization of the electronic Hamiltonian. Two of the spin-charge ground states, respectively consists of three-site and six-site ferromagnetic (FM) clusters arranged in anti-FM and $120^{\circ}$ Yafet-Kittel (YK) phase which we label as S-AF (super-antiferromagnet) and S-YK (super-YK) respectively. Two even more interesting coupled spin-charge states, respectively accommodate FM dimers and trimers (as three-site line segment), which we label as FM-D and FM-T. In both cases, the anti-FM aligned dimers and trimers in respective phases, are arranged in stripes along one of three lattice directions: the spontaneously symmetry broken phases giving rise to non-trivial macroscopic degeneracy. These underlying magnetic textures (except S-YK state) restrict electrons in fragmented small regions (e.g, triangular units, two-site dimers, three-site line segments respectively in S-AF, FM-D and FM-T), resulting in flat bands by opening large gaps in electronic density of states, which in turn stabilize these coupled spin-charge states: a "band effect". These exotic spin-charge ground states could be relevant to electron-doped spin-systems resulting from various metal-organic frameworks (MOFs), which have attracted significant attention to condensed matter physics

</details>


### [47] [One-dimensional physics of the frustrated quantum magnet PHCC](https://arxiv.org/abs/2512.17406)
*Alexander A. Tsirlin,Oleg Janson,Ioannis Rousochatzakis*

Main category: cond-mat.str-el

TL;DR: 该研究通过第一性原理计算和量子多体模拟，揭示了PHCC量子磁体的微观机制，建立了描述其磁性的精确一维阻挫自旋链模型，并预测了双三重态束缚态的存在。


<details>
  <summary>Details</summary>
Motivation: 研究PHCC量子磁体的微观磁性机制，建立能够定量描述其磁化率、磁化过程及激发谱的精确模型，并探索其量子多体效应。

Method: 结合密度泛函能带结构计算和数值量子多体模拟，从微观电子结构出发推导出自旋哈密顿量，建立一维阻挫自旋链模型（交替最近邻耦合J1=23.1K、J1'=7.0K和均匀次近邻耦合J2=13.9K）。

Result: 建立的模型成功定量描述了磁化率和磁化过程，解释了单三重态能带的色散关系及其在布里渊区中心附近与连续谱的合并现象，并预测了双三重态束缚态和反束缚态的存在。

Conclusion: PHCC的磁性可以用一维阻挫自旋链模型精确描述，该模型不仅解释了现有实验观测，还预测了新的量子多体激发态，为理解阻挫量子磁体提供了重要理论框架。

Abstract: We report a comprehensive microscopic study of the frustrated quantum magnet PHCC, (C$_4$H$_{12}$N$_2$)Cu$_2$Cl$_6$, using density-functional band-structure calculations combined with numerical quantum many-body simulations of the underlying spin Hamiltonian. We show that the magnetism of PHCC is captured by a one-dimensional model of the frustrated spin chain with alternating nearest-neighbor couplings ($J_1=23.1$ K, $J_1'=7.0$ K) and uniform next-nearest-neighbor couplings ($J_2=13.9$ K). This model, which can also be thought of as a zigzag ladder, provides a quantitative description of the magnetic susceptibility and the magnetization process, and accounts for the observed dispersion of the single-triplet band and its merging into a continuum near the Brillouin zone center. We also make predictions for the existence of sharp bound (anti-bound) states of two triplets, below (above) the bottom (upper) edge of the two-particle scattering continuum.

</details>


### [48] [Altermagnetism and its induced higher-order topology on the Lieb lattice](https://arxiv.org/abs/2512.17415)
*Xingmin Huo,Xingchuan Zhu,Chang-An Li,Shiping Feng,Song-Bo Zhang,Shengyuan A. Yang,Huaiming Guo*

Main category: cond-mat.str-el

TL;DR: 该研究在Lieb晶格上构建了多种交变磁体模型，探索了交变磁性与自旋轨道耦合的相互作用，发现交变磁性能诱导高阶拓扑态，特别是在开放方形几何中产生角态。


<details>
  <summary>Details</summary>
Motivation: 交变磁性的发现重新引起了人们对Lieb晶格的关注。研究旨在扩展Lieb晶格上交变磁性模型的范围，探索交变磁性与自旋轨道耦合的相互作用，以及交变磁性在工程拓扑量子态方面的潜力。

Method: 采用基于自旋簇的通用方案，在Lieb晶格上设计了具有d波和g波对称性的多种交变磁性模型。研究了交变磁性与自旋轨道耦合的相互作用，分析了条带几何中的拓扑边缘态重建和狄拉克点出现，以及开放方形几何中的角态形成。

Result: 交变磁性晶胞在条带几何中重建了拓扑边缘态并导致狄拉克点出现，交变磁性的面内磁矩可以在这些点处诱导能隙。在开放方形几何中，这些能隙内出现了角态，实现了高阶拓扑态。研究发现高阶拓扑的诱导适用于Lieb晶格上构建的所有交变磁性构型，且与铁磁性和亚铁磁性相比，交变磁性的效果最为显著。

Conclusion: 交变磁性展现出奇特的性质，在工程拓扑量子态方面具有潜在应用价值。研究结果突显了交变磁性的独特特性，为拓扑量子态的设计提供了新思路。

Abstract: Altermagnetism (AM) has brought renewed attention to the Lieb lattice. Here, we broaden the scope of altermagnetic models on the Lieb lattice by using a general scheme based on spin clusters. We design various altermagnetic models with d- and g-wave on the Lieb lattice, and investigate its interplay with spin-orbit coupling. While the altermagnetic unit cell reconstructs the topological edge states in the strip geometry and leads to the emergence of Dirac points, the in-plane magnetic moments of AM can induce gaps at these points. In an open square geometry, corner modes emerge within these gaps, realizing higher-order topological states. We further verify that the induction of higher-order topology is applicable to all altermagnetic configurations constructed here on the Lieb lattice, and is most pronounced for AM by comparing with the other types of magnetism such as ferromagnetism and ferrimagnetism. Our results highlight the exotic properties of AM, and suggest its potential applications in engineering topological quantum states.

</details>


### [49] [Emergence of a hidden-order phase well below the charge density wave transition in a topological Weyl semimetal (TaSe$_4$)$_2$I](https://arxiv.org/abs/2512.17433)
*Sk Kalimuddin,Sudipta Chatterjee,Arnab Bera,Satyabrata Bera,Deep Singha Roy,Soham Das,Tuhin Debnath,Ashis K. Nandy,Shishir K. Pandey,Mintu Mondal*

Main category: cond-mat.str-el

TL;DR: 在Weyl半金属(TaSe₄)₂I中，除了已知的263K电荷密度波(CDW)相变外，在约100K处发现了隐藏序相变，该相变伴随电阻噪声增强、塞贝克系数异常和结构对称性降低。


<details>
  <summary>Details</summary>
Motivation: 研究Weyl半金属中相关拓扑相与电荷密度波的相互作用，探索(TaSe₄)₂I材料中可能存在的隐藏相变，以丰富对交织电子和结构序的理解。

Method: 采用低频电阻噪声谱、电输运和热电测量技术，结合第一性原理计算，分析电阻涨落的统计特性、塞贝克系数异常和结构对称性变化。

Result: 在约100K处发现隐藏序相变，表现为电阻噪声指数和方差显著增强，塞贝克系数出现明显异常；第一性原理计算显示结构从高对称性I422相经中间I4对称性转变为低对称性C2相，导致费米面附近电子结构重整化和带隙打开。

Conclusion: 在拓扑CDW-Weyl半金属(TaSe₄)₂I中发现了先前未知的相关相变，丰富了该材料的相图，使其成为研究交织电子和结构序的理想平台。

Abstract: The emergence of a charge density wave (CDW) in a Weyl semimetal -- a correlated topological phase, is exceptionally rare in condensed matter systems. In this context, the quasi-one-dimensional type-III Weyl semimetal (TaSe$_4$)$_2$I undergoes a CDW transition at $T_{\mathrm{CDW}} \approx 263$~K, providing an exceptional platform to investigate correlated topological CDW states. Here, we uncover an additional hidden-order phase transition at $T^* \sim 100$ K, well below the CDW onset, using low-frequency resistance noise spectroscopy, electrical transport, and thermoelectric measurements. This transition is characterized by a sharp enhancement in the noise exponent ($α$) and variance of resistance fluctuations. Analysis of higher-order statistics of resistance fluctuations reveals the correlated dynamics underlying the transition. A pronounced anomaly in the Seebeck coefficient near $T^*$ further suggests a Fermi surface reconstruction. First-principles calculations reveal a structural distortion from the high-symmetry $I422$ phase to a low-symmetry $C2$ phase, via an intermediate $I4$ symmetry. This leads to renormalization of the electronic structure near the Fermi level and opening of a bandgap in the hidden-order phase. These findings demonstrate a previously unidentified correlated phase transition in the topological CDW-Weyl semimetal (TaSe$_4$)$_2$I, enriching the phase diagram of this material and establishing it as an ideal platform for studying intertwined electronic and structural orders.

</details>


### [50] [Comparative Raman study of Ruddlesden-Popper nickelates and the monolayer-trilayer polymorph](https://arxiv.org/abs/2512.17583)
*Vignesh Sundaramurthy,Abhi Suthar,Pascal Puphal,Congcong Le,Yuhao Gu,Hasan Yilmaz,Pablo Sosa-Lizama,Peter A. van Aken,Y. Eren Suyolcu,Masahiko Isobe,Andreas P. Schnyder,Xianxin Wu,Matteo Minola,Bernhard Keimer,Matthias Hepting*

Main category: cond-mat.str-el

TL;DR: 该研究对Ruddlesden-Popper镍酸盐系列进行了拉曼光谱比较分析，重点关注单层-三层（ML-TL）异质结构，揭示了其独特的电子结构和晶格动力学特征。


<details>
  <summary>Details</summary>
Motivation: RP镍酸盐系列在多个成员中发现超导性后引起广泛关注，但由于单晶合成中易形成共生相和氧化学计量比的空间变化，导致对其本征性质的确定存在困难，出现了关于电子相变和晶格动力学的矛盾报告。

Method: 对高质量ML-TL单晶样品进行声子和电子拉曼响应的比较研究，并与优化氧含量的其他RP镍酸盐进行对比，建立可用于明确相鉴别的拉曼光谱特征。

Result: 建立了可用于整个系列明确相鉴别的多个拉曼光谱特征；发现ML-TL在声子和电子拉曼响应中具有纯ML和TL化合物所不具备的特征，这些差异归因于ML单元在ML-TL晶格结构中引起的自掺杂和限制效应所产生的独特电子结构。

Conclusion: ML-TL异质结构具有独特的电子结构特征，这些特征源于其特殊的晶格架构，为理解RP镍酸盐系列的超导机制和材料性质提供了重要见解。

Abstract: Ruddlesden-Popper (RP) nickelates have attracted intense interest following the discovery of superconductivity in several members of the series, including bilayer (BL) La$_3$Ni$_2$O$_7$, trilayer (TL) La$_4$Ni$_3$O$_{10}$, and structural polymorphs composed of monolayer-bilayer or monolayer-trilayer (ML-TL) units. However, an inherent propensity of the RP series to form intergrown phases during single-crystal synthesis, together with spatial variations in oxygen stoichiometry, has complicated the determination of their intrinsic material properties. As a consequence, conflicting reports have emerged on both their electronic phase transitions and lattice dynamics. In this work, we perform a comparative study of the phononic and electronic Raman responses of high-quality ML-TL single crystals and contrast them with those of other RP nickelates, using samples with optimized oxygen content. We establish several Raman spectral features that enable unambiguous phase identification across the series. Moreover, we uncover characteristics in the phononic and electronic Raman response of ML-TL that are not reflected in the pure ML and TL compounds. We attribute these differences to a distinctive electronic structure arising from self-doping and confinement effects induced by the ML unit within the ML-TL lattice architecture.

</details>


### [51] [Charge fluctuations and topological phases in Kitaev-Heisenberg ladders](https://arxiv.org/abs/2512.17596)
*M. G. Sousa,O. Ávalos-Ovando,E. Vernek,S. E. Ulloa*

Main category: cond-mat.str-el

TL;DR: 研究掺杂Kitaev-Heisenberg梯子中拓扑相的稳定性，分析电子带宽增加如何抑制拓扑相，确定拓扑序消失的临界跳跃值


<details>
  <summary>Details</summary>
Motivation: 研究掺杂Kitaev-Heisenberg梯子中拓扑相与巡游电子及电荷涨落之间的竞争关系，探究拓扑相在掺杂和电荷动力学下的鲁棒性

Method: 在蜂窝状带状几何结构上建立Hubbard模型，使用密度矩阵重整化群(DMRG)计算，分析弦序参数、自旋关联和电荷涨落随跳跃振幅和相互作用强度的演化

Result: 增加电子带宽会逐步抑制拓扑相，使相图中的稳定区域发生偏移和变窄；确定了弦序消失的临界跳跃值，表征了磁序与电荷涨落之间的相互作用

Conclusion: 拓扑相对掺杂和电荷动力学具有一定的脆弱性，这些发现对候选Kitaev材料和工程量子系统具有重要启示

Abstract: We investigate the stability of topological phases in doped Kitaev-Heisenberg ladders by studying the competition with itinerant electrons and the associated charge fluctuations in a Hubbard model on a honeycomb ribbon geometry. We analyze the evolution of string order parameters, spin correlations, and charge fluctuations as functions of hopping amplitude and interaction strength in a half-filled band. Our results from density matrix renormalization group (DMRG) calculations show that increasing electron bandwidth progressively suppresses the topological phases, shifting and narrowing their stability regions in the phase diagram. We identify the critical values of hopping where string order vanishes and characterize the interplay between magnetic order and charge fluctuations. These findings provide insight into the robustness of topological phases against doping and charge dynamics, with implications for candidate Kitaev materials and engineered quantum systems.

</details>


### [52] [Non-perturbative effects of short-range spatial correlations at the two-particle level](https://arxiv.org/abs/2512.17716)
*Michael Meixner,Matthias Reitner,Thomas Schäfer,Alessandro Toschi*

Main category: cond-mat.str-el

TL;DR: 通过CDMFT研究二维系统中短程关联如何导致自洽微扰理论失效，发现电荷通道中二粒子不可约顶点的发散比DMFT更早发生，这是由短程反铁磁涨落驱动的，为理解二维Mott相变提供了关键机制。


<details>
  <summary>Details</summary>
Motivation: 研究短程关联如何导致二维系统中自洽微扰理论的失效，以及相关的物理后果，特别是理解二维Hubbard模型中Mott相变的机制。

Method: 使用细胞动力学平均场理论（CDMFT），系统地推导了CDMFT层次上所有物理通道的Bethe-Salpeter方程形式，并考虑了相关的Ward恒等式。对半填充二维Hubbard模型在中等耦合下进行系统计算。

Result: 发现电荷通道中二粒子不可约顶点的发散比纯局域的DMFT情况更早发生，这是由于短程反铁磁涨落导致的。广义电荷敏感度特征值的符号变化被确定为驱动二维Mott相变和相邻相分离不稳定性的关键先决条件。

Conclusion: 短程反铁磁涨落显著影响二维系统的多体物理，导致自洽微扰理论在较低相互作用下失效，这为理解二维Mott相变机制提供了重要见解，揭示了电荷通道中顶点发散与相变物理之间的深刻联系。

Abstract: By means of cellular dynamical mean-field theory (CDMFT) we study how short-range correlations drive the breakdown of the self-consistent perturbation theory in two-dimensional systems and the most relevant physical consequences associated to it. To this aim, we first derive in a structured and consistent way the Bethe-Salpeter equation (BSE) formalism at the CDMFT level in all physical channels, explicitly addressing the important aspect of the related Ward identities. In this context, we perform systematic calculations of the BSE for the two-dimensional Hubbard model at half-filling at intermediate coupling. Our study illustrates how the divergence of a fundamental building block of the BSE in the charge channel, the two-particle irreducible vertex, systematically occurs at lower interactions than in the (purely local) DMFT case, due to short-range antiferromagnetic fluctuations. Further, the change of sign of the eigenvalues of the generalized charge susceptibility associated to the vertex divergences is identified as the essential prerequisite to drive, at larger interaction values, the physics of the Mott transition in two dimensions, as well as of the adjacent phase-separation instabilities.

</details>


### [53] [Fractionalized topological d+id superconductivity in the Yao-Lee-Kondo model](https://arxiv.org/abs/2512.17729)
*Chengzhi Tang,Hong Yao*

Main category: cond-mat.str-el

TL;DR: 该论文理论证明，在弱耦合极限下，通过Kondo晶格模型与Yao-Lee自旋液体耦合，可以涌现出拓扑d+id分数量子化超导相（SC*）。


<details>
  <summary>Details</summary>
Motivation: 二维手性拓扑超导性的实验实现仍然难以捉摸，需要寻找新的理论机制来实现这种拓扑超导相。

Method: 使用重正化群分析研究Yao-Lee-Kondo模型，其中传导电子与六角晶格上的Yao-Lee自旋液体相互作用。通过交换Majorana自旋子产生有效相互作用，驱动Cooper不稳定性。

Result: 在弱Kondo耦合下，诱导出的主要反铁磁相互作用选择拓扑d+id自旋单重态配对（陈数C=±2），同时Majorana费米子保持无能隙且无约束，形成分数量子化拓扑d+id超导体（SC*）。在强Kondo耦合下，系统进入具有分数量子化的重费米液体相（HFL*）。

Conclusion: 该工作为实验实现二维手性拓扑超导性提供了新的理论途径，通过Kondo晶格与拓扑自旋液体的耦合机制，可以在弱耦合极限下涌现出分数量子化拓扑超导相。

Abstract: A conclusive experimental realization of 2D chiral topological superconductivity remains elusive. Here we present a theoretical demonstration that a topological $d+id$ fractionalized superconducting phase (SC*) can emerge in the weak-coupling limit of a Kondo lattice model, where conduction electrons interact with a Yao-Lee spin liquid on the honeycomb lattice (the Yao-Lee-Kondo model). Using a renormalization-group analysis, we show that exchanging Majorana spinons from the Yao-Lee spin liquid generates effective interactions among the conduction electrons and drives a Cooper instability even for arbitrarily weak Kondo coupling. We further find that the induced leading inter-orbital antiferromagnetic interaction selects topological $d+id$ spin-singlet pairing with Chern number $C=\pm 2$. Meanwhile, the Majorana fermions in the Yao-Lee spin liquid remain gapless and deconfined in this regime, so the resulting state is a fractionalized topological $d+id$ superconductor (SC*). For sufficiently strong Kondo coupling, the system instead enters a heavy Fermi liquid phase with fractionalization (HFL*).

</details>


### [54] [Quantum Monte Carlo studies of U(1) lattice gauge models of Kondo breakdown](https://arxiv.org/abs/2512.17801)
*Gaopei Pan,Fakher F. Assaad*

Main category: cond-mat.str-el

TL;DR: 该论文使用紧凑U(1)规范理论研究重费米子体系，通过量子蒙特卡洛模拟发现两种对称等价相：具有尖锐复合费米子共振的重费米子金属相和具有非相干共振的Kondo破缺金属相。


<details>
  <summary>Details</summary>
Motivation: 在局域矩区域，重费米子体系最经济的描述方式是使用紧凑U(1)规范理论。研究希望通过这种Kondo晶格表述，探索自旋链与二维狄拉克传导电子耦合体系的性质，特别是理解规范介导的Kondo破缺现象。

Method: 采用紧凑U(1)规范理论描述Kondo晶格，自旋链由携带自旋和U(1)规范电荷的费米子部分子描述。重费米子准粒子是携带单位电荷和U(1)规范电荷的U(1)物质场与费米子部分子的束缚态。使用无符号问题的行列式量子蒙特卡洛模拟进行研究。

Result: 识别出两种对称等价相：1）重费米子金属相：具有尖锐复合费米子共振和稳健的低频输运；2）Kondo破缺金属相：具有非相干共振和消失的低频输运。Luttinger体积在重费米子相中同时计入复合电子和传导电子，而在Kondo破缺相中仅计入传导电子。

Conclusion: 复合费米子谱、动力学自旋结构因子和光学电导率的演化提供了规范介导Kondo破缺的非微扰证明，并建立了在U(1)规范理论框架下轨道选择性Mott转变的输运指纹。

Abstract: In the local-moment regime, heavy fermions are most economically described by a compact U(1) gauge theory. With this formulation of the Kondo lattice, we study a spin chain coupled to two-dimensional Dirac conduction electrons. The spin chain is described by fermionic partons carrying spin and U(1) gauge charge. The heavy-fermion quasiparticle is a bound state of a U(1) matter field carrying unit electric and U(1) gauge charge, and the fermionic parton. Using sign-problem-free determinant quantum Monte Carlo simulations, we identify two symmetry-equivalent regimes: a heavy-fermion metal with a sharp composite-fermion resonance and robust low-frequency transport, and a Kondo-breakdown metal with an incoherent resonance and vanishing low-frequency transport. For any finite lattice extent in the direction perpendicular to the chain, the Luttinger volume of the heavy-fermion phase counts both composite and conduction electrons, while in the Kondo-breakdown phase it counts only the conduction electrons. The evolution of the composite-fermion spectrum, dynamical spin structure factor, and optical conductivity provides a nonperturbative demonstration of gauge-mediated Kondo breakdown and establishes transport fingerprints of an orbital-selective Mott transition in the context of U(1) gauge theories of heavy fermions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases](https://arxiv.org/abs/2512.16953)
*Pietro Cofone,Giovanni Amendola,Marco Manna,Aldo Ricioppo*

Main category: cs.AI

TL;DR: 本文提出了一种基于逻辑的实体集扩展图框架，支持增量导航而非完全构建，通过高效推理任务实现局部探索。


<details>
  <summary>Details</summary>
Motivation: 传统的线性实体集扩展方法无法揭示知识资源中丰富的分类结构，而完全构建扩展图在实际应用中可能不切实际，因此需要更高效的局部导航方法。

Method: 提出扩展图概念——有根有向无环图，节点表示逻辑公式标记的语义泛化，边编码严格的语义包含关系。定义推理任务来检查两个元组是否属于可比较、不可比较或相同的节点。

Result: 在现实假设下（如限制输入或实体描述），这些推理任务可以高效实现，支持对扩展图的局部增量导航，无需完全构建整个图。

Conclusion: 通过高效的推理任务实现扩展图的局部导航，为实际应用提供了可行的解决方案，避免了完全构建大型扩展图的计算负担。

Abstract: Recognizing similarities among entities is central to both human cognition and computational intelligence. Within this broader landscape, Entity Set Expansion is one prominent task aimed at taking an initial set of (tuples of) entities and identifying additional ones that share relevant semantic properties with the former -- potentially repeating the process to form increasingly broader sets. However, this ``linear'' approach does not unveil the richer ``taxonomic'' structures present in knowledge resources. A recent logic-based framework introduces the notion of an expansion graph: a rooted directed acyclic graph where each node represents a semantic generalization labeled by a logical formula, and edges encode strict semantic inclusion. This structure supports taxonomic expansions of entity sets driven by knowledge bases. Yet, the potentially large size of such graphs may make full materialization impractical in real-world scenarios. To overcome this, we formalize reasoning tasks that check whether two tuples belong to comparable, incomparable, or the same nodes in the graph. Our results show that, under realistic assumptions -- such as bounding the input or limiting entity descriptions -- these tasks can be implemented efficiently. This enables local, incremental navigation of expansion graphs, supporting practical applications without requiring full graph construction.

</details>


### [56] [Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows](https://arxiv.org/abs/2512.16969)
*Wanghan Xu,Yuhao Zhou,Yifan Zhou,Qinglong Cao,Shuo Li,Jia Bu,Bo Liu,Yixin Chen,Xuming He,Xiangyu Zhao,Xiang Zhuang,Fengxiang Wang,Zhiwang Zhou,Qiantai Feng,Wenxuan Huang,Jiaqi Wei,Hao Wu,Yuejin Yang,Guangshuai Wang,Sheng Xu,Ziyan Huang,Xinyao Liu,Jiyao Liu,Cheng Tang,Wei Li,Ying Chen,Junzhi Ning,Pengfei Jiang,Chenglong Ma,Ye Du,Changkai Ji,Huihui Xu,Ming Hu,Jiangbin Zheng,Xin Chen,Yucheng Wu,Feifei Jiang,Xi Chen,Xiangru Tang,Yuchen Fu,Yingzhou Lu,Yuanyuan Zhang,Lihao Sun,Chengbo Li,Jinzhe Ma,Wanhao Liu,Yating Liu,Kuo-Cheng Wu,Shengdu Chai,Yizhou Wang,Ouwen Zhangjin,Chen Tang,Shufei Zhang,Wenbo Cao,Junjie Ren,Taoyong Cui,Zhouheng Yao,Juntao Deng,Yijie Sun,Feng Liu,Wangxu Wei,Jingyi Xu,Zhangrui Li,Junchao Gong,Zijie Guo,Zhiyu Yao,Zaoyu Chen,Tianhao Peng,Fangchen Yu,Bo Zhang,Dongzhan Zhou,Shixiang Tang,Jiaheng Liu,Fenghua Ling,Yan Lu,Yuchen Ren,Ben Fei,Zhen Zhao,Xinyu Gu,Rui Su,Xiao-Ming Wu,Weikang Si,Yang Liu,Hao Chen,Xiangchao Yan,Xue Yang,Junchi Yan,Jiamin Wu,Qihao Zheng,Chenhui Li,Zhiqiang Gao,Hao Kong,Junjun He,Mao Su,Tianfan Fu,Peng Ye,Chunfeng Song,Nanqing Dong,Yuqiang Li,Huazhu Fu,Siqi Sun,Lijing Cheng,Jintai Lin,Wanli Ouyang,Bowen Zhou,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: 该论文提出了科学通用智能(SGI)的操作化定义，基于实践探究模型(PIM)，并创建了包含1000多个跨学科样本的SGI-Bench基准来评估大语言模型。研究发现现有模型在深度研究、想法可行性、实验执行等方面存在显著差距，并提出了测试时强化学习(TTRL)方法来提升假设新颖性。


<details>
  <summary>Details</summary>
Motivation: 尽管科学AI有所进展，但缺乏一个连贯的科学通用智能(SGI)框架，即能够自主构思、调查和跨科学领域推理的能力。需要建立一个操作化的SGI定义和评估基准来推动AI系统真正参与科学发现。

Method: 1. 基于实践探究模型(PIM：审议、构思、行动、感知)提出SGI操作化定义；2. 设计四个科学家对齐任务：深度研究、想法生成、干/湿实验、实验推理；3. 构建SGI-Bench基准，包含1000多个专家策划的跨学科样本，灵感来自《科学》杂志的125个大问题；4. 引入测试时强化学习(TTRL)，在推理时优化检索增强的新颖性奖励。

Result: 评估结果显示：深度研究任务精确匹配率低(10-20%)，尽管步骤层面有对齐；生成的想法缺乏可行性和细节；干实验代码可执行性高但执行结果准确性低；湿实验协议序列保真度低；多模态比较推理存在持续挑战。TTRL方法能在没有参考答案的情况下提升假设新颖性。

Conclusion: 基于PIM的定义、以工作流为中心的基准和实证见解为真正参与科学发现的AI系统奠定了基础。研究揭示了当前LLM在科学任务上的局限性，并提出了改进方向。

Abstract: Despite advances in scientific AI, a coherent framework for Scientific General Intelligence (SGI)-the ability to autonomously conceive, investigate, and reason across scientific domains-remains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberation, Conception, Action, Perception) and operationalize it via four scientist-aligned tasks: deep research, idea generation, dry/wet experiments, and experimental reasoning. SGI-Bench comprises over 1,000 expert-curated, cross-disciplinary samples inspired by Science's 125 Big Questions, enabling systematic evaluation of state-of-the-art LLMs. Results reveal gaps: low exact match (10--20%) in deep research despite step-level alignment; ideas lacking feasibility and detail; high code executability but low execution result accuracy in dry experiments; low sequence fidelity in wet protocols; and persistent multimodal comparative-reasoning challenges. We further introduce Test-Time Reinforcement Learning (TTRL), which optimizes retrieval-augmented novelty rewards at inference, enhancing hypothesis novelty without reference answer. Together, our PIM-grounded definition, workflow-centric benchmark, and empirical insights establish a foundation for AI systems that genuinely participate in scientific discovery.

</details>


### [57] [PAACE: A Plan-Aware Automated Agent Context Engineering Framework](https://arxiv.org/abs/2512.16970)
*Kamer Ali Yuksel*

Main category: cs.AI

TL;DR: PAACE是一个用于优化LLM智能体上下文管理的统一框架，通过计划感知的自动上下文工程，在保持性能的同时显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在复杂多步骤工作流中产生快速扩展的上下文，现有方法忽略了多步骤、计划感知的特性，导致注意力稀释和推理成本增加。

Method: PAACE框架包含：1) PAACE-Syn：生成带压缩监督标注的合成智能体工作流；2) PAACE-FT：从成功教师演示中训练的蒸馏、计划感知压缩器。采用下一k任务相关性建模、计划结构分析、指令协同细化和函数保留压缩。

Result: 在AppWorld上获得比所有基线更高的准确性，同时降低峰值上下文和累积依赖；在OfficeBench和多跳QA上提高准确性和F1，减少步骤数、峰值token和注意力依赖；蒸馏的PAACE-FT保留97%教师性能，推理成本降低超过一个数量级。

Conclusion: PAACE通过计划感知的自动上下文工程，显著提高了LLM智能体的正确性，同时大幅减少了上下文负载，使计划感知压缩在实际部署中变得可行。

Abstract: Large Language Model (LLM) agents are increasingly deployed in complex, multi-step workflows involving planning, tool use, reflection, and interaction with external knowledge systems. These workflows generate rapidly expanding contexts that must be curated, transformed, and compressed to maintain fidelity, avoid attention dilution, and reduce inference cost. Prior work on summarization and query-aware compression largely ignores the multi-step, plan-aware nature of agentic reasoning. In this work, we introduce PAACE (Plan-Aware Automated Context Engineering), a unified framework for optimizing the evolving state of LLM agents through next-k-task relevance modeling, plan-structure analysis, instruction co-refinement, and function-preserving compression. PAACE comprises (1) PAACE-Syn, a large-scale generator of synthetic agent workflows annotated with stepwise compression supervision, and (2) PAACE-FT, a family of distilled, plan-aware compressors trained from successful teacher demonstrations. Experiments on long-horizon benchmarks (AppWorld, OfficeBench, and 8-Objective QA) demonstrate that PAACE consistently improves agent correctness while substantially reducing context load. On AppWorld, PAACE achieves higher accuracy than all baselines while lowering peak context and cumulative dependency. On OfficeBench and multi-hop QA, PAACE improves both accuracy and F1, achieving fewer steps, lower peak tokens, and reduced attention dependency. Distilled PAACE-FT retains 97 percent of the teacher's performance while reducing inference cost by over an order of magnitude, enabling practical deployment of plan-aware compression with compact models.

</details>


### [58] [UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering](https://arxiv.org/abs/2512.17043)
*Yinxu Tang,Chengsong Huang,Jiaxin Huang,William Yeoh*

Main category: cs.AI

TL;DR: 本文提出关系中心的知识图谱问答框架UniRel-R1，专注于返回实体间语义连接的子图而非单个实体，通过集成子图选择、多阶段图剪枝和强化学习微调的LLM来解决候选子图过多的问题。


<details>
  <summary>Details</summary>
Motivation: 传统KGQA主要关注返回单个答案实体的实体中心查询，但现实世界查询通常是关系性的，需要理解实体间的关联。现有方法在处理关系查询时面临候选子图过多、平凡或过于常见的连接掩盖独特信息性答案的挑战。

Method: 提出UniRel-R1统一框架，集成子图选择、多阶段图剪枝和强化学习微调的大语言模型。奖励函数设计鼓励紧凑且特定的子图，包含更多信息性关系和更低度的中间实体。

Result: 大量实验表明，UniRel-R1在连接性和奖励方面相比Vanilla基线取得显著提升，并能有效泛化到未见过的实体和关系。

Conclusion: 关系中心KGQA是传统实体中心KGQA的重要补充，UniRel-R1框架通过集成多种技术有效解决了关系查询中的子图选择挑战，为理解实体间语义连接提供了新方法。

Abstract: Knowledge Graph Question Answering (KGQA) has traditionally focused on entity-centric queries that return a single answer entity. However, real-world queries are often relational, seeking to understand how entities are associated. In this work, we introduce relation-centric KGQA, a complementary setting where the answer is a subgraph capturing the semantic connections among entities rather than an individual entity. The main challenge lies in the abundance of candidate subgraphs, where trivial or overly common connections often obscure the identification of unique and informative answers. To tackle this, we propose UniRel-R1, a unified framework that integrates subgraph selection, multi-stage graph pruning, and an LLM fine-tuned with reinforcement learning. The reward function is designed to encourage compact and specific subgraphs with more informative relations and lower-degree intermediate entities. Extensive experiments show that UniRel-R1 achieves significant gains in connectivity and reward over Vanilla baselines and generalizes effectively to unseen entities and relations.

</details>


### [59] [Realistic threat perception drives intergroup conflict: A causal, dynamic analysis using generative-agent simulations](https://arxiv.org/abs/2512.17066)
*Suhaib Abdurahman,Farzan Karimi-Malekabadi,Chenxiao Yu,Nour S. Kteily,Morteza Dehghani*

Main category: cs.AI

TL;DR: 使用大语言模型驱动的智能体在虚拟社会中模拟威胁与冲突关系，发现现实威胁直接增加敌意，而象征性威胁主要通过内群体偏见间接影响，且只在现实威胁缺失时增加敌意。


<details>
  <summary>Details</summary>
Motivation: 人类冲突常归因于物质条件和象征性价值受到的威胁，但两者如何相互作用以及哪个占主导地位尚不清楚。研究受到因果控制弱、伦理约束和时间数据稀缺的限制。

Method: 使用大语言模型驱动的智能体在虚拟社会中模拟，独立变化现实威胁和象征性威胁，同时追踪行动、语言和态度。通过表征分析验证LLM编码的威胁状态与操纵的对应关系。

Result: LLM将现实威胁、象征性威胁和敌意编码为不同的内部状态；现实威胁直接增加敌意，象征性威胁效应较弱且完全通过内群体偏见中介，只在现实威胁缺失时增加敌意；非敌对群体接触能缓冲冲突升级，结构不对称使敌意集中在多数群体中。

Conclusion: 通过LLM驱动的虚拟社会模拟为威胁驱动的冲突提供了因果解释框架，揭示了现实威胁和象征性威胁的不同作用机制，为理解人类冲突提供了新视角。

Abstract: Human conflict is often attributed to threats against material conditions and symbolic values, yet it remains unclear how they interact and which dominates. Progress is limited by weak causal control, ethical constraints, and scarce temporal data. We address these barriers using simulations of large language model (LLM)-driven agents in virtual societies, independently varying realistic and symbolic threat while tracking actions, language, and attitudes. Representational analyses show that the underlying LLM encodes realistic threat, symbolic threat, and hostility as distinct internal states, that our manipulations map onto them, and that steering these states causally shifts behavior. Our simulations provide a causal account of threat-driven conflict over time: realistic threat directly increases hostility, whereas symbolic threat effects are weaker, fully mediated by ingroup bias, and increase hostility only when realistic threat is absent. Non-hostile intergroup contact buffers escalation, and structural asymmetries concentrate hostility among majority groups.

</details>


### [60] [Value Under Ignorance in Universal Artificial Intelligence](https://arxiv.org/abs/2512.17086)
*Cole Wyeth,Marcus Hutter*

Main category: cs.AI

TL;DR: 将AIXI强化学习智能体推广到更广泛的效用函数类别，通过处理信念分布中只能预测有限历史前缀的假设，探讨了半测度损失的死亡解释和模糊概率分布视角


<details>
  <summary>Details</summary>
Motivation: AIXI智能体需要处理信念分布中只能预测有限历史前缀的假设，这导致半测度损失问题。传统上将其解释为"死亡概率"，但作者认为将其视为模糊概率分布中的完全无知同样自然，这促使研究使用模糊概率理论中的Choquet积分计算期望效用

Method: 将AIXI智能体推广到更广泛的效用函数类别；将信念分布视为模糊概率分布，半测度损失视为完全无知；使用Choquet积分计算期望效用；分析这些方法的可计算性水平

Result: 标准递归值函数可以作为特例恢复；在死亡解释下最一般的期望效用不能表征为Choquet积分；研究了这些方法的可计算性水平

Conclusion: 通过将AIXI智能体推广到更广泛的效用函数，并采用模糊概率理论和Choquet积分框架，为处理半测度损失提供了新的视角，但死亡解释下的最一般期望效用超出了Choquet积分的表征能力

Abstract: We generalize the AIXI reinforcement learning agent to admit a wider class of utility functions. Assigning a utility to each possible interaction history forces us to confront the ambiguity that some hypotheses in the agent's belief distribution only predict a finite prefix of the history, which is sometimes interpreted as implying a chance of death equal to a quantity called the semimeasure loss. This death interpretation suggests one way to assign utilities to such history prefixes. We argue that it is as natural to view the belief distributions as imprecise probability distributions, with the semimeasure loss as total ignorance. This motivates us to consider the consequences of computing expected utilities with Choquet integrals from imprecise probability theory, including an investigation of their computability level. We recover the standard recursive value function as a special case. However, our most general expected utilities under the death interpretation cannot be characterized as such Choquet integrals.

</details>


### [61] [A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving](https://arxiv.org/abs/2512.17093)
*Timo Pierre Schrader,Lukas Lange,Tobias Kaminski,Simon Razniewski,Annemarie Friedrich*

Main category: cs.AI

TL;DR: 本文提出了一种ASP求解器在循环中的方法，通过求解器引导的指令微调来改进LLMs生成答案集编程代码的能力，特别针对逻辑谜题领域。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用编程语言方面表现良好，但在领域特定语言（如答案集编程ASP）的代码生成方面仍然面临挑战。ASP是一种特别有效的组合搜索问题解决方法，但LLMs在ASP代码生成方面的有效性受到预训练阶段示例数量有限的限制。

Method: 提出ASP求解器在循环中的方法，仅需要自然语言问题描述及其解决方案。方法包括：从LLMs中采样ASP语句作为程序延续；利用声明式ASP编程的特性（部分编码逐渐缩小解空间）；基于求解器反馈将实例分类为选择和拒绝；对精选数据进行监督微调；通过求解器引导的搜索（包括最佳N采样）进一步提高鲁棒性。

Result: 实验表明，在两个不同的提示设置和两个数据集上，该方法都带来了持续的改进。

Conclusion: 通过求解器引导的指令微调方法，可以有效提升LLMs在ASP代码生成任务上的性能，特别是在逻辑谜题领域，为解决领域特定语言的代码生成问题提供了新思路。

Abstract: The rise of large language models (LLMs) has sparked interest in coding assistants. While general-purpose programming languages are well supported, generating code for domain-specific languages remains a challenging problem for LLMs. In this paper, we focus on the LLM-based generation of code for Answer Set Programming (ASP), a particularly effective approach for finding solutions to combinatorial search problems. The effectiveness of LLMs in ASP code generation is currently hindered by the limited number of examples seen during their initial pre-training phase.
  In this paper, we introduce a novel ASP-solver-in-the-loop approach for solver-guided instruction-tuning of LLMs to addressing the highly complex semantic parsing task inherent in ASP code generation. Our method only requires problem specifications in natural language and their solutions. Specifically, we sample ASP statements for program continuations from LLMs for unriddling logic puzzles. Leveraging the special property of declarative ASP programming that partial encodings increasingly narrow down the solution space, we categorize them into chosen and rejected instances based on solver feedback. We then apply supervised fine-tuning to train LLMs on the curated data and further improve robustness using a solver-guided search that includes best-of-N sampling. Our experiments demonstrate consistent improvements in two distinct prompting settings on two datasets.

</details>


### [62] [Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty](https://arxiv.org/abs/2512.17145)
*Josh Barber,Rourke Young,Cameron Coombe,Will Browne*

Main category: cs.AI

TL;DR: 提出一种受Solomonoff启发的LLM假设加权方法，在不确定性推理中平衡准确性和简洁性


<details>
  <summary>Details</summary>
Motivation: 现有方法在评估多个候选解决方案时难以平衡准确性和简洁性，特别是在数据稀疏的现实任务中

Method: 采用Solomonoff启发的方法，根据简洁性和预测拟合度对LLM生成的假设进行加权，应用于Mini-ARC基准任务

Result: 与贝叶斯模型平均相比，Solomonoff评分将概率更均匀地分布在竞争假设上，产生保守、不确定性感知的输出

Conclusion: 算法信息论先验对于可解释、可靠的不确定性多假设推理具有重要价值

Abstract: Reasoning under uncertainty is a key challenge in AI, especially for real-world tasks, where problems with sparse data demands systematic generalisation. Existing approaches struggle to balance accuracy and simplicity when evaluating multiple candidate solutions. We propose a Solomonoff-inspired method that weights LLM-generated hypotheses by simplicity and predictive fit. Applied to benchmark (Mini-ARC) tasks, our method produces Solomonoff-weighted mixtures for per-cell predictions, yielding conservative, uncertainty-aware outputs even when hypotheses are noisy or partially incorrect. Compared to Bayesian Model Averaging (BMA), Solomonoff scoring spreads probability more evenly across competing hypotheses, while BMA concentrates weight on the most likely but potentially flawed candidates. Across tasks, this highlights the value of algorithmic information-theoretic priors for interpretable, reliable multi-hypothesis reasoning under uncertainty.

</details>


### [63] [MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation](https://arxiv.org/abs/2512.17194)
*Shengwei Zhao,Jingwen Yao,Sitong Wei,Linhai Xu,Yuying Liu,Dong Zhang,Zhiqiang Tian,Shaoyi Du*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的可解释多模态检索增强生成方法，通过两阶段强化微调框架提升多模态大语言模型的推理能力，在WebQA和MultimodalQA数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有MMRAG方法无法阐明检索和响应生成背后的推理逻辑，限制了结果的可解释性。需要增强多模态大语言模型的推理能力，实现可解释的多模态检索增强生成。

Method: 提出两阶段强化微调框架：第一阶段使用基于规则的强化微调对多模态文档进行粗粒度点式排序，过滤显著不相关文档；第二阶段使用基于推理的强化微调联合优化细粒度列表式排序和答案生成，引导模型输出可解释的推理逻辑。

Result: 在WebQA和MultimodalQA两个多模态检索增强生成基准数据集上取得了最先进的结果，并通过全面的消融实验验证了方法的有效性。

Conclusion: 通过引入强化学习到多模态检索增强生成中，提出的两阶段强化微调框架成功增强了多模态大语言模型的推理能力，实现了可解释的多模态检索增强生成，在基准测试中表现出色。

Abstract: Multi-modal Retrieval-Augmented Generation (MMRAG) enables highly credible generation by integrating external multi-modal knowledge, thus demonstrating impressive performance in complex multi-modal scenarios. However, existing MMRAG methods fail to clarify the reasoning logic behind retrieval and response generation, which limits the explainability of the results. To address this gap, we propose to introduce reinforcement learning into multi-modal retrieval-augmented generation, enhancing the reasoning capabilities of multi-modal large language models through a two-stage reinforcement fine-tuning framework to achieve explainable multi-modal retrieval-augmented generation. Specifically, in the first stage, rule-based reinforcement fine-tuning is employed to perform coarse-grained point-wise ranking of multi-modal documents, effectively filtering out those that are significantly irrelevant. In the second stage, reasoning-based reinforcement fine-tuning is utilized to jointly optimize fine-grained list-wise ranking and answer generation, guiding multi-modal large language models to output explainable reasoning logic in the MMRAG process. Our method achieves state-of-the-art results on WebQA and MultimodalQA, two benchmark datasets for multi-modal retrieval-augmented generation, and its effectiveness is validated through comprehensive ablation experiments.

</details>


### [64] [UmniBench: Unified Understand and Generation Model Oriented Omni-dimensional Benchmark](https://arxiv.org/abs/2512.17196)
*Kai Liu,Leyang Chen,Wenbo Li,Zhikai Chen,Zhixin Wang,Renjing Pei,Linghe Kong,Yulun Zhang*

Main category: cs.AI

TL;DR: UmniBench是一个针对统一多模态模型（UMMs）的全维度评估基准，能够在一个评估过程中同时评估理解、生成和编辑能力，覆盖13个主要领域和200多个概念。


<details>
  <summary>Details</summary>
Motivation: 当前对统一多模态模型的评估是解耦的，分别评估其理解和生成能力，缺乏一个综合的评估框架。需要开发一个能够全面评估UMMs能力的基准。

Method: UmniBench利用UMM自身通过人类检查的提示和问答对来评估其生成和编辑能力，使用其理解能力进行评估。这种简单有效的范式允许对UMMs进行综合评估，同时也能解耦评估各项能力。

Result: 基于UmniBench，作者对24个流行模型进行了基准测试，包括UMMs和单能力大模型。该基准为统一模型提供了更全面客观的评估视角，并为社区模型性能改进提供了支持。

Conclusion: UmniBench是一个全面的多模态模型评估基准，能够在一个框架内评估理解、生成和编辑能力，为统一多模态模型的评估提供了新的标准和方法。

Abstract: Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems. However, evaluations of unified multimodal models (UMMs) remain decoupled, assessing their understanding and generation abilities separately with corresponding datasets. To address this, we propose UmniBench, a benchmark tailored for UMMs with omni-dimensional evaluation. First, UmniBench can assess the understanding, generation, and editing ability within a single evaluation process. Based on human-examined prompts and QA pairs, UmniBench leverages UMM itself to evaluate its generation and editing ability with its understanding ability. This simple but effective paradigm allows comprehensive evaluation of UMMs. Second, UmniBench covers 13 major domains and more than 200 concepts, ensuring a thorough inspection of UMMs. Moreover, UmniBench can also decouple and separately evaluate understanding, generation, and editing abilities, providing a fine-grained assessment. Based on UmniBench, we benchmark 24 popular models, including both UMMs and single-ability large models. We hope this benchmark provides a more comprehensive and objective view of unified models and logistical support for improving the performance of the community model.

</details>


### [65] [ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework](https://arxiv.org/abs/2512.17266)
*Miru Hong,Minho Lee,Geonhee Jo,Jae-Hee So,Pascal Bauer,Sang-Ki Ko*

Main category: cs.AI

TL;DR: EventGPT是一个基于GPT架构的球员条件化、价值感知的下一个事件预测模型，用于评估足球转会适应性，通过反事实模拟分析球员在不同战术环境中的表现变化。


<details>
  <summary>Details</summary>
Motivation: 现有转会评估方法依赖静态统计数据或事后价值模型，无法捕捉球员在新战术环境或不同队友配合下的适应性变化，需要更动态的评估框架。

Method: 基于GPT风格的自回归transformer，将比赛处理为离散token序列，联合预测下一个持球动作的类型、位置、时间及其残差持球价值(rOBV)，通过学习球员嵌入进行反事实模拟。

Result: 在5个赛季的英超事件数据上，EventGPT在下一个事件预测准确性和空间精度方面优于现有序列基线模型，并通过案例研究展示了转会分析的实用价值。

Conclusion: EventGPT提供了一个原则性的方法来评估转会适应性，能够模拟球员在不同球队或战术结构中的行为分布和价值变化，为转会决策提供更科学的依据。

Abstract: Transfers play a pivotal role in shaping a football club's success, yet forecasting whether a transfer will succeed remains difficult due to the strong context-dependence of on-field performance. Existing evaluation practices often rely on static summary statistics or post-hoc value models, which fail to capture how a player's contribution adapts to a new tactical environment or different teammates. To address this gap, we introduce EventGPT, a player-conditioned, value-aware next-event prediction model built on a GPT-style autoregressive transformer. Our model treats match play as a sequence of discrete tokens, jointly learning to predict the next on-ball action's type, location, timing, and its estimated residual On-Ball Value (rOBV) based on the preceding context and player identity. A key contribution of this framework is the ability to perform counterfactual simulations. By substituting learned player embeddings into new event sequences, we can simulate how a player's behavioral distribution and value profile would change when placed in a different team or tactical structure. Evaluated on five seasons of Premier League event data, EventGPT outperforms existing sequence-based baselines in next-event prediction accuracy and spatial precision. Furthermore, we demonstrate the model's practical utility for transfer analysis through case studies-such as comparing striker performance across different systems and identifying stylistic replacements for specific roles-showing that our approach provides a principled method for evaluating transfer fit.

</details>


### [66] [Dialectics for Artificial Intelligence](https://arxiv.org/abs/2512.17373)
*Zhengmian Hu*

Main category: cs.AI

TL;DR: 该论文提出了一种基于算法信息论的概念定义方法，将概念视为与智能体整体经验相关的信息对象，通过可逆一致性关系和冗余信息度量来形式化概念发现过程。


<details>
  <summary>Details</summary>
Motivation: 人类概念本身是流动的，概念边界会随着探究进展而转移、分裂和合并。需要一种不仅仅是字典标签，而是可以修订、比较和在智能体间对齐的概念定义方法。

Method: 采用算法信息论视角，将概念定义为通过其与智能体整体经验的结构关系定义的信息对象。核心约束是确定性：一组部分形成可逆一致性关系，使得任何缺失部分都可以从其他部分恢复。通过冗余信息度量分解的自然性，并在此基础上形式化辩证优化动态。

Result: 提出了一个形式化框架，使得概念存在性成为可检查的结构性主张，防止概念脱离经验而"漂浮"。建立了概念传输和多智能体对齐的形式化方法，允许通过小的基础/种子在共享协议下重建相同概念。

Conclusion: 该研究为人工智能从原始经验中发现概念提供了理论基础，通过算法信息论方法形式化了概念发现、修订和跨智能体对齐的过程，使通信成为具体的计算-比特权衡。

Abstract: Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One challenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of "concept" that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a concept as an information object defined only through its structural relation to an agent's total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents "concepts" from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we define excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descriptions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent alignment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a concrete compute-bits trade-off.

</details>


### [67] [Translating the Rashomon Effect to Sequential Decision-Making Tasks](https://arxiv.org/abs/2512.17470)
*Dennis Gross,Jørn Eirik Betten,Helge Spieker*

Main category: cs.AI

TL;DR: 该论文将Rashomon效应从分类任务扩展到序列决策领域，证明了在相同行为表现下存在内部结构不同的策略，并展示了Rashomon集合在鲁棒性和验证效率方面的优势。


<details>
  <summary>Details</summary>
Motivation: Rashomon效应在分类任务中已被广泛研究，但在序列决策领域尚未被探索。序列决策中的策略学习与分类任务有本质区别，需要新的方法来验证策略行为的等同性，特别是在随机转移的环境中。

Method: 使用形式化验证方法构建和比较每个策略在环境中的完整概率行为，通过对比状态访问和动作选择的概率分布来验证策略行为的等同性。从Rashomon集合构建集成策略和宽松策略。

Result: 实验证明Rashomon效应确实存在于序列决策中。从Rashomon集合构建的集成策略对分布偏移具有更强的鲁棒性，而从Rashomon集合派生的宽松策略在保持最优性能的同时减少了验证的计算需求。

Conclusion: 该研究成功将Rashomon效应扩展到序列决策领域，为理解策略多样性提供了新视角，并展示了Rashomon集合在提高鲁棒性和验证效率方面的实用价值。

Abstract: The Rashomon effect describes the phenomenon where multiple models trained on the same data produce identical predictions while differing in which features they rely on internally. This effect has been studied extensively in classification tasks, but not in sequential decision-making, where an agent learns a policy to achieve an objective by taking actions in an environment. In this paper, we translate the Rashomon effect to sequential decision-making. We define it as multiple policies that exhibit identical behavior, visiting the same states and selecting the same actions, while differing in their internal structure, such as feature attributions. Verifying identical behavior in sequential decision-making differs from classification. In classification, predictions can be directly compared to ground-truth labels. In sequential decision-making with stochastic transitions, the same policy may succeed or fail on any single trajectory due to randomness. We address this using formal verification methods that construct and compare the complete probabilistic behavior of each policy in the environment. Our experiments demonstrate that the Rashomon effect exists in sequential decision-making. We further show that ensembles constructed from the Rashomon set exhibit greater robustness to distribution shifts than individual policies. Additionally, permissive policies derived from the Rashomon set reduce computational requirements for verification while maintaining optimal performance.

</details>


### [68] [Towards Explainable Conversational AI for Early Diagnosis with Large Language Models](https://arxiv.org/abs/2512.17559)
*Maliha Tabassum,M Shamim Kaiser*

Main category: cs.AI

TL;DR: 该研究开发了一个基于GPT-4o的医疗诊断聊天机器人，结合RAG和可解释AI技术，通过动态对话提取症状并优先诊断，在测试中达到90%准确率和100%Top-3准确率。


<details>
  <summary>Details</summary>
Motivation: 全球医疗系统面临诊断效率低、成本上升和专家资源有限等问题，导致治疗延误和不良健康结果。现有AI诊断系统缺乏交互性和透明度，难以在实际患者中心环境中有效应用。

Method: 采用基于GPT-4o的大型语言模型，结合检索增强生成和可解释AI技术，通过动态对话提取和规范化症状，使用相似性匹配和自适应提问优先诊断，并通过思维链提示提供透明推理。

Result: 与传统机器学习模型（朴素贝叶斯、逻辑回归、SVM、随机森林、KNN）相比，LLM系统表现出色，达到90%的准确率和100%的Top-3准确率。

Conclusion: 该研究展示了基于LLM的诊断聊天机器人在医疗领域的潜力，为实现更透明、交互性强且临床相关的AI医疗系统提供了有前景的方向。

Abstract: Healthcare systems around the world are grappling with issues like inefficient diagnostics, rising costs, and limited access to specialists. These problems often lead to delays in treatment and poor health outcomes. Most current AI and deep learning diagnostic systems are not very interactive or transparent, making them less effective in real-world, patient-centered environments. This research introduces a diagnostic chatbot powered by a Large Language Model (LLM), using GPT-4o, Retrieval-Augmented Generation, and explainable AI techniques. The chatbot engages patients in a dynamic conversation, helping to extract and normalize symptoms while prioritizing potential diagnoses through similarity matching and adaptive questioning. With Chain-of-Thought prompting, the system also offers more transparent reasoning behind its diagnoses. When tested against traditional machine learning models like Naive Bayes, Logistic Regression, SVM, Random Forest, and KNN, the LLM-based system delivered impressive results, achieving an accuracy of 90% and Top-3 accuracy of 100%. These findings offer a promising outlook for more transparent, interactive, and clinically relevant AI in healthcare.

</details>


### [69] [About Time: Model-free Reinforcement Learning with Timed Reward Machines](https://arxiv.org/abs/2512.17637)
*Anirban Majumdar,Ritam Raha,Rajarshi Roy,David Parker,Marta Kwiatkowska*

Main category: cs.AI

TL;DR: 提出定时奖励机（TRM）扩展传统奖励机，加入时间约束，用于时间敏感应用，开发了结合定时自动机抽象和反事实想象的模型无关RL算法


<details>
  <summary>Details</summary>
Motivation: 传统奖励机无法建模精确的时间约束，限制了在时间敏感应用中的使用，需要更丰富的奖励规范来表达带时间要求的任务

Method: 提出定时奖励机（TRM）扩展奖励机结构，整合时间约束；开发模型无关RL框架（表格Q学习），通过定时自动机抽象将TRM融入学习过程，并使用反事实想象启发式方法利用TRM结构改进搜索

Result: 实验表明算法能学习到在满足TRM时间约束的同时获得高奖励的策略；比较不同TRM语义下的性能，消融实验验证反事实想象的有效性

Conclusion: TRM提供了更丰富的奖励规范能力，结合定时自动机抽象和反事实想象的RL算法能有效处理带时间约束的任务，为时间敏感应用提供了新方法

Abstract: Reward specification plays a central role in reinforcement learning (RL), guiding the agent's behavior. To express non-Markovian rewards, formalisms such as reward machines have been introduced to capture dependencies on histories. However, traditional reward machines lack the ability to model precise timing constraints, limiting their use in time-sensitive applications. In this paper, we propose timed reward machines (TRMs), which are an extension of reward machines that incorporate timing constraints into the reward structure. TRMs enable more expressive specifications with tunable reward logic, for example, imposing costs for delays and granting rewards for timely actions. We study model-free RL frameworks (i.e., tabular Q-learning) for learning optimal policies with TRMs under digital and real-time semantics. Our algorithms integrate the TRM into learning via abstractions of timed automata, and employ counterfactual-imagining heuristics that exploit the structure of the TRM to improve the search. Experimentally, we demonstrate that our algorithm learns policies that achieve high rewards while satisfying the timing constraints specified by the TRM on popular RL benchmarks. Moreover, we conduct comparative studies of performance under different TRM semantics, along with ablations that highlight the benefits of counterfactual-imagining.

</details>


### [70] [Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally](https://arxiv.org/abs/2512.17898)
*Robin Schimmelpfennig,Mark Díaz,Vinodkumar Prabhakaran,Aida Davani*

Main category: cs.AI

TL;DR: 研究通过跨国实验发现，AI拟人化设计对用户信任和参与度的影响并非普遍一致，而是受到文化因素的调节，挑战了现有AI治理的一刀切方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统日益模仿人类特征，引发了关于拟人化可能导致错误信任或情感依赖的担忧。然而，现有安全框架主要基于西方人群的理论假设，缺乏对全球用户多样性的考虑，且拟人化设计与用户行为之间的因果关系尚未在真实人机交互中得到验证。

Method: 采用两个大规模跨国实验，涉及10个不同国家的3500名参与者，进行实时开放式的人机交互。通过实验方法测试拟人化设计杠杆对用户拟人化感知的因果影响，并比较不同文化背景下用户对AI拟人化设计的反应差异。

Result: 研究发现：1）用户评估AI拟人化时更关注交互性线索（如对话流畅度、理解用户视角），而非政策常引用的理论方面（如感知或意识）；2）拟人化设计确实能因果性地增加用户的拟人化感知；3）但拟人化设计并不普遍增加用户参与度和信任的行为测量；4）拟人化与行为结果之间的联系受到文化调节，某些设计在某些文化中促进信任（如巴西），在其他文化中可能产生相反效果（如日本）。

Conclusion: 研究挑战了拟人化AI设计必然带来风险的普遍叙事，揭示了人机交互的复杂文化调节机制，强调AI治理需要超越一刀切的方法，考虑文化多样性。

Abstract: Over a billion users across the globe interact with AI systems engineered with increasing sophistication to mimic human traits. This shift has triggered urgent debate regarding Anthropomorphism, the attribution of human characteristics to synthetic agents, and its potential to induce misplaced trust or emotional dependency. However, the causal link between more humanlike AI design and subsequent effects on engagement and trust has not been tested in realistic human-AI interactions with a global user pool. Prevailing safety frameworks continue to rely on theoretical assumptions derived from Western populations, overlooking the global diversity of AI users. Here, we address these gaps through two large-scale cross-national experiments (N=3,500) across 10 diverse nations, involving real-time and open-ended interactions with an AI system. We find that when evaluating an AI's human-likeness, users focus less on the kind of theoretical aspects often cited in policy (e.g., sentience or consciousness), but rather applied, interactional cues like conversation flow or understanding the user's perspective. We also experimentally demonstrate that humanlike design levers can causally increase anthropomorphism among users; however, we do not find that humanlike design universally increases behavioral measures for user engagement and trust, as previous theoretical work suggests. Instead, part of the connection between human-likeness and behavioral outcomes is fractured by culture: specific design choices that foster self-reported trust in AI-systems in some populations (e.g., Brazil) may trigger the opposite result in others (e.g., Japan). Our findings challenge prevailing narratives of inherent risk in humanlike AI design. Instead, we identify a nuanced, culturally mediated landscape of human-AI interaction, which demands that we move beyond a one-size-fits-all approach in AI governance.

</details>


### [71] [When Reasoning Meets Its Laws](https://arxiv.org/abs/2512.17901)
*Junyu Zhang,Yifan Sun,Tianang Leng,Jingyan Shen,Liu Ziyin,Paul Pu Liang,Huan Zhang*

Main category: cs.AI

TL;DR: 论文提出了推理定律（LoRe）框架，包含计算定律和准确率定律，通过单调性和组合性两个可测量属性评估大型推理模型，发现现有模型缺乏组合性，并通过微调方法提升模型对计算定律的遵从度，从而改善推理性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（LRMs）性能优越，但其推理行为常常违反直觉，导致推理能力不足。为了从理论上形式化期望的推理行为，需要建立一个统一的框架来刻画LRMs的内在推理模式。

Method: 提出推理定律（LoRe）框架，包含计算定律（推理计算量应与问题复杂度线性缩放）和准确率定律。由于问题复杂度难以量化，通过单调性和组合性两个可测量属性检验这些假设。开发LoRe-Bench基准系统测量这两个属性，并设计有效的微调方法来增强计算定律的组合性。

Result: 评估显示大多数推理模型具有合理的单调性但缺乏组合性。通过微调方法增强计算定律遵从度后，模型在多个基准测试中的推理性能得到一致提升，并揭示了不同属性和定律之间的协同效应。

Conclusion: 推理定律（LoRe）为理解和改进大型推理模型的推理行为提供了理论框架。通过增强模型对计算定律的遵从度，特别是组合性，可以显著提升推理性能，这为未来推理模型的开发和评估提供了重要指导。

Abstract: Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [72] [Optimal active engines obey the thermodynamic Lorentz force law](https://arxiv.org/abs/2512.17087)
*Adrianne Zhong,Adam G. Frim,Michael R. DeWeese*

Main category: cond-mat.stat-mech

TL;DR: 该研究揭示了有限时间内从主动非平衡系统中提取功的基本限制，发现最优协议遵循洛伦兹力定律，并证明F1分子马达实验中的恒定速度角度钳位协议是全局最优的。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索有限时间内从主动非平衡系统中提取功的基本限制，并寻找能够接近这些限制的最优控制协议。这对于理解非平衡热力学系统的性能极限和优化能量转换效率具有重要意义。

Method: 将非保守过阻尼朗之万系统的有限时间功提取重新表述为洛伦兹力拉格朗日作用量，其中动能项对应热力学度量项（概率密度的L2最优输运成本），磁场耦合项对应有效的准静态功提取。证明最优协议通过反绝热方式引导热力学状态轨迹，使其满足热力学状态空间上的洛伦兹力定律。

Result: 发现通过最小化非平衡涨落，可以使管家热任意接近零。证明最近F1分子马达实验中使用的恒定速度角度钳位协议是全局最优协议：它产生零管家热，同时最小化耗散并最大化功转导。

Conclusion: 该研究建立了非平衡热力学系统有限时间功提取的基本理论框架，将电磁学经典概念重新解释并应用于循环非平衡过程，为优化主动非平衡系统的能量转换效率提供了理论基础和实用指导。

Abstract: What are the fundamental limitations for finite-time engines that extract work from active nonequilibrium systems, and what are the optimal protocols that approach them? We show that the finite-time work extraction for nonconservative overdamped Langevin systems may be rewritten as a Lorentz force Lagrangian action, with the kinetic term corresponding to a thermodynamic metric term that is an $L_2$-optimal transport cost for the time-dependent probability density, and the magnetic field coupling term corresponding to an effective quasistatic work extraction, proving that optimal protocols counterdiabatically steer the thermodynamic state trajectory to satisfy a Lorentz force law defined on thermodynamic state space. We utilize and reinterpret classic concepts from electromagnetism in the setting of cyclical nonequilibrium processes. We show that the housekeeping heat can be controlled to be arbitrarily close to zero by minimizing nonequilibrium fluctuations. It immediately follows from our results that the constant-velocity angle clamp protocol applied to the $F_1$ molecular motor in a recent experiment [Mishima et at, 2025] is in fact the globally optimal protocol: it produces zero housekeeping heat and simultaneously minimizes dissipation and maximizes work transduction.

</details>


### [73] [Gutenberg-Richter-like relations in physical systems](https://arxiv.org/abs/2512.17615)
*K. Duplat,G. Varas,O. Ramos*

Main category: cond-mat.stat-mech

TL;DR: 该研究分析了南加州和日本地震目录的区域地震能量统计，发现具有指数τ≈1.67的尺度不变能量分布。通过生成不同τ值的合成能量分布，确定了地震类似行为的τ值范围为1.5-2.0，进一步限制后为1.58-1.76，并识别了不同τ值区间对应的物理机制。


<details>
  <summary>Details</summary>
Motivation: 研究地震能量分布的尺度不变特性，通过分析实际地震数据中的能量分布指数τ，探索不同τ值对应的物理机制，以理解地震动力学的基本特征。

Method: 分析南加州和日本地震目录的区域地震能量统计数据，发现尺度不变能量分布特征。生成不同τ值的合成能量分布，在恒定活动条件下模拟地震行为。通过比较实际地震与合成分布的相似性，确定地震类似行为的τ值范围。

Result: 实际地震数据显示τ≈1.67的尺度不变能量分布。地震类似行为在τ值1.5-2.0范围内出现，当进一步限制能量变化在真实地震的10倍以内时，可接受范围缩小到1.58-1.76。不同τ值区间对应不同的物理机制：地震类似区域（1.5≤τ<2.0）表现为缓慢能量积累与尺度无关事件释放的平衡；τ<1.5对应外部能量供应主导；τ>2对应小事件在能量预算中占主导。

Conclusion: 地震能量分布具有特定的尺度不变特性，τ≈1.67是地震动力学的重要特征参数。不同τ值范围对应不同的物理机制，地震类似行为出现在1.5-2.0范围内，这为理解地震动力学和断层行为提供了重要见解。

Abstract: We analyze regional earthquake energy statistics from the Southern California and Japan seismic catalogs and find scale-invariant energy distributions characterized by an exponent $τ\simeq 1.67$. To quantify how closely scale-invariant dynamics with different exponent values resemble real earthquakes, we generate synthetic energy distributions over a wide range of $τ$ under conditions of constant activity. Earthquake-like behavior, in a broad sense, is obtained for $1.5 \leqslant τ< 2.0$. When energy variations are further restricted to be within a factor of ten relative to real earthquakes, the admissible range narrows to $1.58 \leqslant τ\leqslant 1.76$. We identify the physical mechanisms governing the dynamics in the different regimes: fault dynamics characterized by a balance between slow energy accumulation and release through scale-free events in the earthquake-like regime; externally supplied energy relative to a slowly driven fault for $τ< 1.5$; and dominance of small events in the energy budget for $τ> 2$

</details>


### [74] [Convection Patterns in Nonequilibrium Kawasaki Dynamics at Low Temperature](https://arxiv.org/abs/2512.17827)
*Meander Van den Brande,Kyosuke Adachi,Francois Huveneers*

Main category: cond-mat.stat-mech

TL;DR: 研究保守随机晶格动力学（川崎动力学）在体相各处与热浴接触的系统。粒子通过伊辛哈密顿量相互作用，低温下发生相分离。通过施加空间变化的温度场驱动系统远离平衡，同时保持局部平衡。在这些条件下，通常的低温长程有序被稳健的对流模式取代，在适当几何结构中呈现规则间距的条纹结构。


<details>
  <summary>Details</summary>
Motivation: 研究在空间变化的温度场驱动下，保守随机晶格动力学系统的非平衡行为，探索非平衡条件如何改变相分离系统的有序结构，以及非平衡态与具有相同局部温度分布的平衡态之间的显著差异。

Method: 采用保守随机晶格动力学（Kawasaki动力学），粒子通过伊辛哈密顿量相互作用。系统在体相各处与热浴接触，通过施加空间变化的温度场驱动系统远离平衡，同时保持局部平衡条件。开发宏观描述框架来捕捉观察到的行为。

Result: 在非平衡条件下，通常的低温长程有序被稳健的对流模式取代，在适当几何结构中形成规则间距的条纹结构。这些非平衡态与具有相同局部温度分布的平衡态动力学结果显著不同。建立的宏观描述框架能够统一解释观察到的模式。

Conclusion: 空间变化的温度场可以驱动保守随机晶格动力学系统产生显著不同于平衡态的非平衡有序结构，表现为对流模式和条纹结构。建立的宏观框架为理解这些非平衡模式提供了统一的理论基础。

Abstract: We study a conservative stochastic lattice dynamics (Kawasaki dynamics) in contact everywhere in the bulk with a heat bath. Particles interact via an Ising Hamiltonian and phase separation occurs at low temperature. We drive the system out of equilibrium by imposing a temperature field that varies spatially on macroscopic scales while preserving local equilibrium. Under these conditions, the usual low-temperature long-range order is replaced by robust convection patterns, featuring regularly spaced stripe structures for suitable geometries. These nonequilibrium states differ markedly from those obtained in an equilibrium dynamics with the same local temperature profile. We develop a macroscopic description that captures these behaviors and provides a unified framework for understanding the observed patterns.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [75] [Dion2: A Simple Method to Shrink Matrix in Muon](https://arxiv.org/abs/2512.16928)
*Kwangjun Ahn,Noah Amsel,John Langford*

Main category: cs.LG

TL;DR: Dion2是一种简化Muon优化器正交化步骤的方法，通过采样部分行或列来减少计算和通信成本，提高可扩展性


<details>
  <summary>Details</summary>
Motivation: Muon优化器虽然具有强大的经验性能和理论基础，但其正交化步骤的超线性成本随着规模增加而带来越来越大的开销。已有工作尝试减少进入正交化步骤的矩阵大小，但需要更简单的方法

Method: Dion2在每次迭代中采样一部分行或列，只对这些采样部分进行正交化。这种采样过程使更新变得稀疏，从而减少计算和通信成本

Result: Dion2显著降低了Muon优化器的计算开销，提高了其可扩展性

Conclusion: Dion2提供了一种比先前方法更简单的矩阵缩减方法，通过采样策略有效解决了Muon优化器在大规模应用中的计算瓶颈问题

Abstract: The Muon optimizer enjoys strong empirical performance and theoretical grounding. However, the super-linear cost of its orthonormalization step introduces increasing overhead with scale. To alleviate this cost, several works have attempted to reduce the size of the matrix entering the orthonormalization step. We introduce Dion2, a much simpler method for shrinking the matrix involved in Muon's computation compared to prior approaches. At a high level, Dion2 selects a fraction of rows or columns at each iteration and orthonormalizes only those. This sampling procedure makes the update sparse, reducing both computation and communication costs which in turn improves the scalability of Muon.

</details>


### [76] [BIONIX: A Wireless, Low-Cost Prosthetic Arm with Dual-Signal EEG and EMG Control](https://arxiv.org/abs/2512.16929)
*Pranesh Sathish Kumar*

Main category: cs.LG

TL;DR: 开发低成本双模式神经肌肉控制系统，结合EEG和EMG信号实现假肢的多自由度实时控制，总成本约240美元，适合资源匮乏地区使用。


<details>
  <summary>Details</summary>
Motivation: 传统上肢假肢价格昂贵且控制不直观，限制了截肢者的功能性和可及性，特别是在资源匮乏地区。需要开发低成本、直观的控制系统来提高假肢的可及性和功能性。

Method: 使用NeuroSky MindWave Mobile 2采集EEG信号，通过ThinkGear蓝牙传输到ESP32微控制器运行轻量级分类模型；使用MyoWare 2.0传感器采集EMG信号，通过SparkFun无线模块传输到第二个ESP32进行阈值检测。EEG检测眨眼事件控制手部开合，EMG通过三个激活带（休息、伸展、收缩）控制肘部运动，需要连续8帧确认以提高稳定性。

Result: 成功构建了功能原型，总成本约240美元（主要成本来自商用EEG头戴设备）。EEG系统控制四个手指伺服电机，EMG系统控制两个肘部伺服电机，实现了多自由度实时控制。

Conclusion: 该系统展示了低成本、生物直觉式假肢控制的可行途径，适合服务不足地区和全球健康应用。未来工作包括转向3D打印外壳、集成自回归模型减少EMG延迟、升级伺服扭矩以提高负载能力和抓握力。

Abstract: Affordable upper-limb prostheses often lack intuitive control systems, limiting functionality and accessibility for amputees in low-resource settings. This project presents a low-cost, dual-mode neuro-muscular control system integrating electroencephalography (EEG) and electromyography (EMG) to enable real-time, multi-degree-of-freedom control of a prosthetic arm. EEG signals are acquired using the NeuroSky MindWave Mobile 2 and transmitted via ThinkGear Bluetooth packets to an ESP32 microcontroller running a lightweight classification model. The model was trained on 1500 seconds of recorded EEG data using a 6-frame sliding window with low-pass filtering, excluding poor-signal samples and using a 70/20/10 training--validation--test split. The classifier detects strong blink events, which toggle the hand between open and closed states. EMG signals are acquired using a MyoWare 2.0 sensor and SparkFun wireless shield and transmitted to a second ESP32, which performs threshold-based detection. Three activation bands (rest: 0--T1; extension: T1--T2; contraction: greater than T2) enable intuitive elbow control, with movement triggered only after eight consecutive frames in a movement class to improve stability. The EEG-controlled ESP32 actuates four finger servos, while the EMG-controlled ESP32 drives two elbow servos. A functional prototype was constructed using low-cost materials (total cost approximately 240 dollars), with most expense attributed to the commercial EEG headset. Future work includes transitioning to a 3D-printed chassis, integrating auto-regressive models to reduce EMG latency, and upgrading servo torque for improved load capacity and grip strength. This system demonstrates a feasible pathway to low-cost, biologically intuitive prosthetic control suitable for underserved and global health applications.

</details>


### [77] [Physics-Informed Lightweight Machine Learning for Aviation Visibility Nowcasting Across Multiple Climatic Regimes](https://arxiv.org/abs/2512.16967)
*Marcelo Cerda Castillo*

Main category: cs.LG

TL;DR: 本文提出了一种基于XGBoost的轻量级梯度提升框架，专门用于机场低能见度和降水事件的短期预测（临近预报）。该模型仅使用地面观测数据（METAR），并通过基于热力学原理的物理引导特征工程进行增强，在11个国际机场的评估中表现出优于传统TAF预报的性能。


<details>
  <summary>Details</summary>
Motivation: 当前航空天气预报主要依赖计算密集型的数值天气预报和人工发布的TAF产品，这些方法存在保守偏差和时间分辨率有限的问题。航空安全需要更准确、及时的短期能见度和降水预测，因此需要开发轻量级、高性能的自动化预测系统。

Method: 采用XGBoost梯度提升框架，仅使用METAR地面观测数据，通过物理引导的特征工程（基于热力学原理）增强模型输入。在11个代表不同气候区域的国际机场（包括SCEL、KJFK、KORD、KDEN、SBGR、VIDP等）使用2000-2024年历史数据进行训练和评估。

Result: 在盲对比评估中，该自动化模型在战术时间尺度（3小时）上显著优于传统TAF预报，召回率提高了2.5到4.0倍，同时减少了误报。SHAP分析显示模型能够隐式重建局地物理驱动因素（平流、辐射和下沉），为操作情境感知提供了可解释性。

Conclusion: 该研究证明了基于物理引导的轻量级机器学习框架能够有效捕捉局地物理过程，无需人工配置，在航空临近预报中实现了比传统方法更好的性能，同时提供了可解释的预测结果，适合边缘计算部署。

Abstract: Short-term prediction (nowcasting) of low-visibility and precipitation events is critical for aviation safety and operational efficiency. Current operational approaches rely on computationally intensive numerical weather prediction guidance and human-issued TAF products, which often exhibit conservative biases and limited temporal resolution. This study presents a lightweight gradient boosting framework (XGBoost) trained exclusively on surface observation data (METAR) and enhanced through physics-guided feature engineering based on thermodynamic principles. The framework is evaluated across 11 international airports representing distinct climatic regimes (including SCEL, KJFK, KORD, KDEN, SBGR, and VIDP) using historical data from 2000 to 2024. Results suggest that the model successfully captures underlying local physical processes without manual configuration. In a blind comparative evaluation against operational TAF forecasts, the automated model achieved substantially higher detection rates at tactical horizons (3 hours), with a 2.5 to 4.0 times improvement in recall while reducing false alarms. Furthermore, SHAP analysis reveals that the model performs an implicit reconstruction of local physical drivers (advection, radiation, and subsidence), providing actionable explainability for operational situational awareness.
  Keywords: aviation meteorology; physics-guided machine learning; explainable artificial intelligence; lightweight machine learning; nowcasting; METAR; TAF verification; edge computing

</details>


### [78] [Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs](https://arxiv.org/abs/2512.17008)
*Junbo Li,Peng Zhou,Rui Meng,Meet P. Vadera,Lihong Li,Yang Li*

Main category: cs.LG

TL;DR: 本文针对多轮任务中强化学习训练LLM智能体的局限性，提出了turn-PPO方法，通过转向轮级MDP公式化来增强PPO在多轮场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用的GRPO算法在多轮任务中，特别是在需要长视野推理的场景下存在明显局限性。需要研究更稳定有效的优势估计策略来应对多轮设置中的挑战。

Method: 首先探索PPO作为替代方案，发现其比GRPO更稳健。然后提出turn-PPO变体，该方法基于轮级MDP公式化（而非常用的令牌级MDP），专门针对多轮场景进行优化。

Result: 在WebShop和Sokoban数据集上的实验结果表明，turn-PPO无论是否包含长推理组件都表现出有效性。

Conclusion: turn-PPO通过转向轮级MDP公式化，为多轮任务中的强化学习训练提供了更稳定有效的解决方案，特别是在需要长视野推理的场景下。

Abstract: Reinforcement learning (RL) has re-emerged as a natural approach for training interactive LLM agents in real-world environments. However, directly applying the widely used Group Relative Policy Optimization (GRPO) algorithm to multi-turn tasks exposes notable limitations, particularly in scenarios requiring long-horizon reasoning. To address these challenges, we investigate more stable and effective advantage estimation strategies, especially for multi-turn settings. We first explore Proximal Policy Optimization (PPO) as an alternative and find it to be more robust than GRPO. To further enhance PPO in multi-turn scenarios, we introduce turn-PPO, a variant that operates on a turn-level MDP formulation, as opposed to the commonly used token-level MDP. Our results on the WebShop and Sokoban datasets demonstrate the effectiveness of turn-PPO, both with and without long reasoning components.

</details>


### [79] [SFBD-OMNI: Bridge models for lossy measurement restoration with limited clean samples](https://arxiv.org/abs/2512.17051)
*Haoye Lu,Yaoliang Yu,Darren Ho*

Main category: cs.LG

TL;DR: 该论文提出了一种在仅有噪声样本情况下恢复真实分布的方法，通过将问题建模为单边熵最优传输问题，并引入SFBD-OMNI框架来处理任意测量模型。


<details>
  <summary>Details</summary>
Motivation: 在许多现实场景中，获取完全观测的样本成本极高甚至不可行，而部分和噪声观测相对容易收集。因此需要一种方法能够利用丰富的噪声样本来恢复真实分布。

Method: 将分布恢复任务构建为单边熵最优传输问题，采用EM类算法求解。提出SFBD-OMNI框架，基于桥模型将噪声样本分布映射到真实分布，这是对SFBD方法的推广，能够处理超出高斯噪声的任意测量模型。

Result: 实验在多个基准数据集和多样化测量设置下进行，结果显示该方法在定性和定量性能上都有显著提升。同时提出了测试准则来判断真实分布是否可恢复，并证明在不可恢复情况下，少量干净样本也能实现大部分分布恢复。

Conclusion: 该研究为在仅有噪声观测的情况下恢复真实分布提供了有效的理论框架和实用方法，能够处理广泛的测量模型，并在实际应用中表现出优越性能。

Abstract: In many real-world scenarios, obtaining fully observed samples is prohibitively expensive or even infeasible, while partial and noisy observations are comparatively easy to collect. In this work, we study distribution restoration with abundant noisy samples, assuming the corruption process is available as a black-box generator. We show that this task can be framed as a one-sided entropic optimal transport problem and solved via an EM-like algorithm. We further provide a test criterion to determine whether the true underlying distribution is recoverable under per-sample information loss, and show that in otherwise unrecoverable cases, a small number of clean samples can render the distribution largely recoverable. Building on these insights, we introduce SFBD-OMNI, a bridge model-based framework that maps corrupted sample distributions to the ground-truth distribution. Our method generalizes Stochastic Forward-Backward Deconvolution (SFBD; Lu et al., 2025) to handle arbitrary measurement models beyond Gaussian corruption. Experiments across benchmark datasets and diverse measurement settings demonstrate significant improvements in both qualitative and quantitative performance.

</details>


### [80] [Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. III](https://arxiv.org/abs/2512.17058)
*Vladimir G. Pestov*

Main category: cs.LG

TL;DR: 本文证明了k最近邻分类器在完备可分度量空间中弱普遍一致性、强Lebesgue-Besicovitch微分性质与Nagata意义下的σ有限维性三者之间的等价关系，填补了最后一个缺失的蕴含关系(1)⇒(3)。


<details>
  <summary>Details</summary>
Motivation: 先前的研究已经建立了(2)⇔(3)和(2)⇒(1)的等价关系，但(1)⇒(3)这一关键蕴含关系一直未被证明。本文旨在填补这一理论空白，完成三个条件之间完整的等价性证明，并修正系列文章中先前的一个错误主张。

Method: 通过数学证明的方式，在完备可分度量空间的框架下，建立了k最近邻分类器的弱普遍一致性蕴含Nagata σ有限维性的逻辑关系。这构成了三个条件之间完整等价链的最后一块拼图。

Result: 成功证明了(1)⇒(3)的蕴含关系，从而完整地建立了三个条件之间的等价性：(1)k最近邻分类器弱普遍一致性 ⇔ (2)强Lebesgue-Besicovitch微分性质 ⇔ (3)Nagata σ有限维性。同时修正了系列文章中先前的一个错误主张。

Conclusion: 本文完成了度量空间中k最近邻分类器理论的一个基础性等价关系的完整证明，为理解分类器一致性与空间几何性质之间的关系提供了完整的理论框架，具有重要的理论意义。

Abstract: We prove the last remaining implication allowing to claim the equivalence of the following conditions for a complete separable metric space $X$:
  (1) The $k$-nearest neighbour classifier is (weakly) universally consistent in $X$, (2) The strong Lebesgue--Besicovitch differentiation property holds in $X$ for every locally finite Borel measure, (3) $X$ is sigma-finite dimensional in the sense of Nagata.
  The equivalence (2)$\iff$(3) was announced by Preiss (1983), while a detailed proof of the implication (3)$\Rightarrow$(2) has appeared in Assouad and Quentin de Gromard (2006). The implication (2)$\Rightarrow$(1) was established by Cérou and Guyader (2006). We prove the implication (1)$\Rightarrow$(3). The result was conjectured in the first article in the series (Collins, Kumari, Pestov 2020), and here we also correct a wrong claim made in the second article (Kumari and Pestov 2024).

</details>


### [81] [Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation](https://arxiv.org/abs/2512.17073)
*Zhenyu Liu,Yunzhen Liu,Zehao Fan,Garrett Gagnon,Yayue Hou,Nan Wu,Yangwook Kang,Liu Liu*

Main category: cs.LG

TL;DR: 提出一种带宽高效的自适应混合专家模型，通过低秩补偿实现路由器引导的精度恢复，在GPU卸载系统中提供更好的带宽-精度权衡和吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 混合专家模型通过稀疏激活扩展容量，但给内存和带宽带来压力。卸载技术通过按需获取专家来缓解GPU内存压力，但令牌级路由导致不规则传输，使推理受限于I/O。静态均匀量化减少流量但在激进压缩下会因忽略专家异质性而降低精度。

Method: 提出带宽高效的自适应混合专家模型，通过低秩补偿实现路由器引导的精度恢复。在推理时，该方法传输紧凑的低秩因子与每个令牌的Top-n专家（n<k），并对这些专家应用补偿，同时保持其他专家为低比特。该方法与GPU和GPU-NDP系统的卸载技术集成。

Result: 该方法在带宽-精度权衡方面表现优越，并提高了吞吐量。通过路由器引导的精度恢复和低秩补偿，在保持压缩效率的同时减少了精度损失。

Conclusion: 提出的带宽高效自适应混合专家模型通过低秩补偿机制，有效解决了混合专家模型在卸载系统中的带宽压力和精度损失问题，为大规模模型部署提供了实用的解决方案。

Abstract: Mixture-of-Experts (MoE) models scale capacity via sparse activation but stress memory and bandwidth. Offloading alleviates GPU memory by fetching experts on demand, yet token-level routing causes irregular transfers that make inference I/O-bound. Static uniform quantization reduces traffic but degrades accuracy under aggressive compression by ignoring expert heterogeneity. We present Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation, which performs router-guided precision restoration using precomputed low-rank compensators. At inference time, our method transfers compact low-rank factors with Top-n (n<k) experts per token and applies compensation to them, keeping others low-bit. Integrated with offloading on GPU and GPU-NDP systems, our method delivers a superior bandwidth-accuracy trade-off and improved throughput.

</details>


### [82] [Can Large Reasoning Models Improve Accuracy on Mathematical Tasks Using Flawed Thinking?](https://arxiv.org/abs/2512.17079)
*Saraswathy Amjith,Mihika Dusad,Neha Muramalla,Shweta Shah*

Main category: cs.LG

TL;DR: 该研究探索通过训练模型识别和纠正推理错误来提升大语言模型在数学推理中的鲁棒性，发现混合错误训练能提高模型从错误推理中恢复的能力而不损害标准解题性能。


<details>
  <summary>Details</summary>
Motivation: 虽然思维链提示已成为大语言模型数学推理的核心方法，但模型对早期错误非常脆弱：单个算术错误或不合理推断通常会导致最终答案错误。研究者希望探索是否通过训练模型识别和纠正推理错误，可以提升其鲁棒性而不损害标准解题能力。

Method: 使用MATH-lighteval竞赛级问题，生成包含单一控制错误（计算错误或推理错误）的思维链前缀，使用GRPO方法对Qwen3-4B模型进行微调，采用二元最终答案奖励。比较了不同训练策略：标准RL训练、仅干净问题训练、混合错误训练等。

Result: Mixed-CoT-RL模型在干净问题上与标准RL表现相当（41% vs 41%），但在包含错误推理的问题上显著优于标准RL（24% vs 19%）。仅干净问题训练反而降低了鲁棒性（19% vs 20%）。推理错误训练比计算错误训练带来更大的鲁棒性提升，混合训练效果最佳。

Conclusion: 研究表明，在训练中暴露于有缺陷的推理轨迹可以改善模型的错误恢复行为，而不牺牲准确性，这为构建更鲁棒的数学推理大语言模型提供了一条可行路径。

Abstract: Chain-of-thought (CoT) prompting has become central to mathematical reasoning in large language models, yet models remain brittle to early errors: a single arithmetic slip or unjustified inference typically propagates uncorrected to an incorrect final answer. We investigate whether training on intentionally flawed reasoning traces can teach models to detect and recover from such errors without degrading standard problem-solving ability. Using competition-level problems from MATH-lighteval, we generate CoT prefixes containing exactly one controlled error, either a calculation error (sign flips, dropped terms) or a reasoning error (misapplied rules, unjustified logical steps), and fine-tune Qwen3-4B with GRPO using a binary final-answer reward. Our Mixed-CoT-RL model matches standard RL on clean problems (41% vs 41%) while substantially outperforming it on problems prefilled with flawed reasoning (24% vs 19%). Notably, clean-only RL fine-tuning degrades robustness below the untuned baseline 19% vs. 20%), indicating that conventional training increases susceptibility to misleading prefills. Among error types, training on reasoning errors yields greater robustness gains than calculation errors alone, with mixed training performing best. These findings demonstrate that exposure to flawed traces during training can improve error-recovery behavior without sacrificing accuracy, suggesting a path toward more robust mathematical reasoning in LLMs.

</details>


### [83] [Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making](https://arxiv.org/abs/2512.17091)
*Toshiaki Hori,Jonathan DeCastro,Deepak Gopinath,Avinash Balachandran,Guy Rosman*

Main category: cs.LG

TL;DR: 提出了一种融合强化学习和MPC规划的分层规划新方法，通过自适应采样机制提升规划效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决具有分层结构的规划问题，需要将强化学习和模型预测控制（MPC）两种规划范式紧密结合，以应对复杂规划场景并提升数据效率和性能。

Method: 提出了一种紧密耦合强化学习和MPPI（MPC的一种实现）的新方法：使用强化学习动作指导MPPI采样器，同时自适应地聚合MPPI样本来改进价值估计；在价值估计不确定的区域进行更多MPPI探索。

Result: 在赛车驾驶、改进的Acrobot和添加障碍物的Lunar Lander等多个领域测试，相比现有方法成功率最高提升72%，收敛速度提升2.1倍，数据效率和整体性能均有显著提升。

Conclusion: 该方法能够处理复杂规划问题并易于适应不同应用，通过自适应采样机制实现了更鲁棒的规划方法，在多个领域表现出优越的性能。

Abstract: We propose a new approach for solving planning problems with a hierarchical structure, fusing reinforcement learning and MPC planning. Our formulation tightly and elegantly couples the two planning paradigms. It leverages reinforcement learning actions to inform the MPPI sampler, and adaptively aggregates MPPI samples to inform the value estimation. The resulting adaptive process leverages further MPPI exploration where value estimates are uncertain, and improves training robustness and the overall resulting policies. This results in a robust planning approach that can handle complex planning problems and easily adapts to different applications, as demonstrated over several domains, including race driving, modified Acrobot, and Lunar Lander with added obstacles. Our results in these domains show better data efficiency and overall performance in terms of both rewards and task success, with up to a 72% increase in success rate compared to existing approaches, as well as accelerated convergence (x2.1) compared to non-adaptive sampling.

</details>


### [84] [UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data](https://arxiv.org/abs/2512.17100)
*Justin Li,Efe Sencan,Jasper Zheng Duan,Vitus J. Leung,Stephan Tsaur,Ayse K. Coskun*

Main category: cs.LG

TL;DR: UniCoMTE是一个模型无关的框架，用于为多元时间序列分类器生成反事实解释，通过修改输入样本来识别影响模型预测的关键时间特征，在ECG分类任务中表现出比现有方法更好的可解释性和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在复杂时间序列分类中表现出色，但其黑盒特性限制了在高风险领域（如医疗健康）的信任和采用，需要提高模型的可解释性。

Method: 提出UniCoMTE框架，这是一个模型无关的反事实解释生成方法，通过修改输入时间序列样本并评估对模型预测的影响，识别关键时间特征。框架兼容多种模型架构，可直接处理原始时间序列输入。

Result: 在ECG时间序列分类器上的评估显示，UniCoMTE生成的解释比LIME和SHAP等现有方法更简洁、稳定且与人类认知一致。医学专家问卷评估证实了其临床实用性，在清晰度和适用性方面均优于现有方法。

Conclusion: UniCoMTE通过将模型预测与有意义的信号模式联系起来，提升了深度学习模型在现实世界时间序列应用中的可解释性，有助于在高风险领域建立对AI模型的信任。

Abstract: Machine learning models, particularly deep neural networks, have demonstrated strong performance in classifying complex time series data. However, their black-box nature limits trust and adoption, especially in high-stakes domains such as healthcare. To address this challenge, we introduce UniCoMTE, a model-agnostic framework for generating counterfactual explanations for multivariate time series classifiers. The framework identifies temporal features that most heavily influence a model's prediction by modifying the input sample and assessing its impact on the model's prediction. UniCoMTE is compatible with a wide range of model architectures and operates directly on raw time series inputs. In this study, we evaluate UniCoMTE's explanations on a time series ECG classifier. We quantify explanation quality by comparing our explanations' comprehensibility to comprehensibility of established techniques (LIME and SHAP) and assessing their generalizability to similar samples. Furthermore, clinical utility is assessed through a questionnaire completed by medical experts who review counterfactual explanations presented alongside original ECG samples. Results show that our approach produces concise, stable, and human-aligned explanations that outperform existing methods in both clarity and applicability. By linking model predictions to meaningful signal patterns, the framework advances the interpretability of deep learning models for real-world time series applications.

</details>


### [85] [Atom: Efficient On-Device Video-Language Pipelines Through Modular Reuse](https://arxiv.org/abs/2512.17108)
*Kunjal Panchal,Saayan Mitra,Somdeb Sarkhel,Haoliang Wang,Ishita Dasgupta,Gang Wu,Hui Guan*

Main category: cs.LG

TL;DR: Atom是一个在移动设备上高效执行视频语言处理管道的系统，通过模块重用和并行执行减少延迟，性能损失很小


<details>
  <summary>Details</summary>
Motivation: 当前视频语言模型在移动设备上执行多阶段管道时存在效率问题，包括冗余模型加载和碎片化执行，导致延迟较高

Method: 将十亿参数模型分解为可重用的模块（如视觉编码器和语言解码器），在不同子任务（字幕生成、推理、索引等）中重用这些模块，消除重复模型加载并实现并行执行

Result: 在普通智能手机上，相比非重用基线，Atom实现了27-33%的更快执行速度，性能损失很小（检索任务Recall@1下降≤2.3，字幕生成CIDEr下降≤1.5）

Conclusion: Atom为边缘设备上的高效视频语言理解提供了一个实用、可扩展的方法，能够在保持性能的同时显著提升执行效率

Abstract: Recent advances in video-language models have enabled powerful applications like video retrieval, captioning, and assembly. However, executing such multi-stage pipelines efficiently on mobile devices remains challenging due to redundant model loads and fragmented execution. We introduce Atom, an on-device system that restructures video-language pipelines for fast and efficient execution. Atom decomposes a billion-parameter model into reusable modules, such as the visual encoder and language decoder, and reuses them across subtasks like captioning, reasoning, and indexing. This reuse-centric design eliminates repeated model loading and enables parallel execution, reducing end-to-end latency without sacrificing performance. On commodity smartphones, Atom achieves 27--33% faster execution compared to non-reuse baselines, with only marginal performance drop ($\leq$ 2.3 Recall@1 in retrieval, $\leq$ 1.5 CIDEr in captioning). These results position Atom as a practical, scalable approach for efficient video-language understanding on edge devices.

</details>


### [86] [Digitizing Nepal's Written Heritage: A Comprehensive HTR Pipeline for Old Nepali Manuscripts](https://arxiv.org/abs/2512.17111)
*Anjali Sarawgi,Esteban Garces Arias,Christof Zotter*

Main category: cs.LG

TL;DR: 该论文提出了首个用于古尼泊尔语手写文本识别的端到端流水线，采用行级转录方法，通过编码器-解码器架构和数据中心技术实现了4.9%的字符错误率。


<details>
  <summary>Details</summary>
Motivation: 古尼泊尔语是一种历史上重要但资源匮乏的语言，缺乏有效的手写文本识别系统。该研究旨在填补这一空白，为低资源历史文字的手写识别提供解决方案。

Method: 采用行级转录方法，系统探索编码器-解码器架构，应用数据中心技术提升识别精度，实现解码策略并分析标记级混淆以理解模型行为和错误模式。

Result: 最佳模型实现了4.9%的字符错误率（CER）。虽然评估数据集是保密的，但作者发布了训练代码、模型配置和评估脚本以支持进一步研究。

Conclusion: 该研究成功开发了首个古尼泊尔语手写文本识别端到端流水线，为低资源历史文字的手写识别提供了可行方案，并通过开源代码促进了该领域的进一步研究。

Abstract: This paper presents the first end-to-end pipeline for Handwritten Text Recognition (HTR) for Old Nepali, a historically significant but low-resource language. We adopt a line-level transcription approach and systematically explore encoder-decoder architectures and data-centric techniques to improve recognition accuracy. Our best model achieves a Character Error Rate (CER) of 4.9\%. In addition, we implement and evaluate decoding strategies and analyze token-level confusions to better understand model behaviour and error patterns. While the dataset we used for evaluation is confidential, we release our training code, model configurations, and evaluation scripts to support further research in HTR for low-resource historical scripts.

</details>


### [87] [The Effect of Negation on CLIP in Medical Imaging: Limitations of Contrastive Language-Image Pretraining](https://arxiv.org/abs/2512.17121)
*Jasmine Vu,Shivanand Sheshappanavar*

Main category: cs.LG

TL;DR: 该研究评估了基于CLIP的CheXagent模型在医学影像检索中处理否定语句的能力，通过微调方法改进模型对否定临床语言的解释，同时分析了模型内部行为变化。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型如CLIP在医学影像任务中应用广泛，但存在处理否定语句能力不足的问题，这在医学诊断场景中尤为关键，可能影响模型的可靠性和临床应用。

Method: 研究评估了Stanford AIMI CheXagent模型在胸部X光图像检索任务中处理肯定和否定提示的能力，使用微调方法改进模型，并通过token归因、t-SNE投影和注意力头消融分析模型内部行为变化。

Result: 微调后CLIP模型处理否定语句的能力得到改善，但肯定提示的准确性略有下降。通过内部行为分析发现，不同微调方法重塑了文本编码器对否定临床语言的表示方式。

Conclusion: 该研究通过微调方法改进了CLIP模型处理医学否定语言的能力，并通过内部行为分析加深了对模型工作机制的理解，有助于提高医学AI设备的可靠性。

Abstract: Large vision-language models like CLIP are increasingly used in medical imaging tasks due to their ability to align images and text without the need for extensive labeled data. This makes them particularly useful for applications like image retrieval, report generation, and classification in clinical settings. A potential issue to this approach is that CLIP-based models often under perform when interpreting negated phrases, which is especially problematic in the context of medical diagnosing. In this study, we evaluate the Stanford AIMI CheXagent model on its ability to correctly retrieve chest X-ray images using prompts with and without negation. The goal of this project is to understand where this model fails and then use it as a base model to improve its retrieval accuracy by fine tuning methods outlined in previous work. Results from this study show improvement in handling of negation in the CLIP model with a slight decrease in accuracy of positive prompt evaluation. Alongside retrieval accuracy, we examined internal model behavior through token attribution, t-SNE projection, and attention-head ablation to better characterize how each fine tuning approach reshaped the text encoders representation of negated clinical language. Through this work, we hope to better understand the internal behavior of CLIP and improve its handling of negation using clinically relevant language for improving its reliability in medical AI devices.

</details>


### [88] [Smoothing DiLoCo with Primal Averaging for Faster Training of LLMs](https://arxiv.org/abs/2512.17131)
*Aaron Defazio,Konstantin Mishchenko,Parameswaran Raman,Hao-Jun Michael Shi,Lin Xiao*

Main category: cs.LG

TL;DR: GPA是一种改进的优化算法，通过解耦Nesterov原始平均公式中的插值常数，实现每步平滑平均，解决了单工作者DiLoCo和Schedule-Free等平均优化器的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有平均优化器如单工作者DiLoCo和Schedule-Free存在局限性：DiLoCo的周期性平均引入双循环结构，增加内存需求和超参数数量；Schedule-Free虽然维护均匀平均，但仍有改进空间。需要一种更高效、更简单的平均策略来提升优化器性能。

Method: GPA扩展了Nesterov方法的原始平均公式，通过解耦插值常数实现每步平滑平均。它消除了DiLoCo的双循环结构，减少内存开销到单个额外缓冲区，简化超参数调优，同时保持或超越原始优化器的收敛保证。

Result: 在Llama-160M模型上，GPA相比基线(AdamW)达到相同验证损失的速度提升24.22%。在ImageNet ViT任务中，小批量和大批量设置下分别获得12%和27%的速度提升。理论证明GPA能匹配或超越任何具有O(√T)遗憾界的基优化器的收敛保证。

Conclusion: GPA通过解耦插值常数实现平滑平均，有效解决了现有平均优化器的局限性，在理论和实证上都表现出优越性能，同时简化了实现和调优过程。

Abstract: We propose Generalized Primal Averaging (GPA), an extension of Nesterov's method in its primal averaging formulation that addresses key limitations of recent averaging-based optimizers such as single-worker DiLoCo and Schedule-Free (SF) in the non-distributed setting. These two recent algorithmic approaches improve the performance of base optimizers, such as AdamW, through different iterate averaging strategies. Schedule-Free explicitly maintains a uniform average of past weights, while single-worker DiLoCo performs implicit averaging by periodically aggregating trajectories, called pseudo-gradients, to update the model parameters. However, single-worker DiLoCo's periodic averaging introduces a two-loop structure, increasing its memory requirements and number of hyperparameters. GPA overcomes these limitations by decoupling the interpolation constant in the primal averaging formulation of Nesterov. This decoupling enables GPA to smoothly average iterates at every step, generalizing and improving upon single-worker DiLoCo. Empirically, GPA consistently outperforms single-worker DiLoCo while removing the two-loop structure, simplifying hyperparameter tuning, and reducing its memory overhead to a single additional buffer. On the Llama-160M model, GPA provides a 24.22% speedup in terms of steps to reach the baseline (AdamW's) validation loss. Likewise, GPA achieves speedups of 12% and 27% on small and large batch setups, respectively, to attain AdamW's validation accuracy on the ImageNet ViT workload. Furthermore, we prove that for any base optimizer with regret bounded by $O(\sqrt{T})$, where $T$ is the number of iterations, GPA can match or exceed the convergence guarantee of the original optimizer, depending on the choice of interpolation constants.

</details>


### [89] [Electric Vehicle Charging Load Forecasting: An Experimental Comparison of Machine Learning Methods](https://arxiv.org/abs/2512.17257)
*Iason Kyriakopoulos,Yannis Theodoridis*

Main category: cs.LG

TL;DR: 该研究系统评估了五种时间序列预测模型在不同时间尺度（分钟、小时、天）和空间聚合水平（单个充电站到城市级）下对电动汽车充电需求的预测效果，使用了四个真实数据集。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车普及，其对电网管理的影响日益凸显，预测充电需求成为重要研究问题。目前研究较少系统比较不同预测方法在多样化城市环境、不同时间尺度和空间聚合水平下的表现。

Method: 使用五种时间序列预测模型（传统统计方法、机器学习和深度学习方法），在四个公开真实数据集上评估短、中、长期（分钟、小时、天级）预测，以及从单个充电站到区域和城市级的空间聚合水平。

Result: 研究结果分别报告了四个数据集的预测性能，这是首个使用多个真实数据集系统评估电动汽车充电需求预测在广泛时间尺度和空间聚合水平上的工作。

Conclusion: 该研究填补了电动汽车充电需求预测在系统比较不同方法、时间尺度和空间聚合水平方面的空白，为电网管理和充电基础设施规划提供了重要参考。

Abstract: With the growing popularity of electric vehicles as a means of addressing climate change, concerns have emerged regarding their impact on electric grid management. As a result, predicting EV charging demand has become a timely and important research problem. While substantial research has addressed energy load forecasting in transportation, relatively few studies systematically compare multiple forecasting methods across different temporal horizons and spatial aggregation levels in diverse urban settings. This work investigates the effectiveness of five time series forecasting models, ranging from traditional statistical approaches to machine learning and deep learning methods. Forecasting performance is evaluated for short-, mid-, and long-term horizons (on the order of minutes, hours, and days, respectively), and across spatial scales ranging from individual charging stations to regional and city-level aggregations. The analysis is conducted on four publicly available real-world datasets, with results reported independently for each dataset. To the best of our knowledge, this is the first work to systematically evaluate EV charging demand forecasting across such a wide range of temporal horizons and spatial aggregation levels using multiple real-world datasets.

</details>


### [90] [Understanding Generalization in Role-Playing Models via Information Theory](https://arxiv.org/abs/2512.17270)
*Yongqi Li,Hao Lang,Fei Huang,Tieyun Qian,Yongbin Li*

Main category: cs.LG

TL;DR: 该论文提出了R-EMID信息论指标来量化角色扮演模型在分布偏移下的性能退化，并开发了协同进化强化学习框架来提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 角色扮演模型在实际应用中广泛使用，但在真实部署时性能下降。这种退化源于用户、角色和对话组合的分布偏移，现有方法无法提供细粒度诊断，缺乏形式化框架来表征RPM的泛化行为。

Method: 1. 提出基于推理的有效互信息差异（R-EMID）作为可解释的度量指标；2. 推导R-EMID的上界来预测最坏情况泛化性能；3. 提出协同进化强化学习框架，自适应建模用户、角色和对话上下文之间的联系，提升对话响应生成概率估计。

Result: 评估了多种RPM的泛化性能，发现用户偏移在所有偏移中风险最高，而强化学习是增强RPM泛化能力最有效的方法。

Conclusion: R-EMID提供了量化RPM性能退化的信息论框架，协同进化强化学习能有效提升模型对分布偏移的鲁棒性，为RPM的泛化性能评估和改进提供了系统方法。

Abstract: Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.

</details>


### [91] [MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics](https://arxiv.org/abs/2512.17273)
*Farinaz Mostajeran,Aruzhan Tleubek,Salah A Faroughi*

Main category: cs.LG

TL;DR: MINPO是一个统一的神经伪算子框架，用于建模由长程空间相互作用和/或长期时间记忆引起的非局部动力学，通过学习非局部算子及其逆算子，并显式重构未知解场。


<details>
  <summary>Details</summary>
Motivation: 许多物理系统表现出由积分-微分方程描述的非局部时空行为。经典方法需要重复评估卷积积分，成本随核复杂性和维度快速增加。现有神经求解器可以加速特定计算，但不能泛化到不同的非局部结构。

Method: MINPO使用KANs或MLPs作为编码器，直接学习非局部算子及其逆算子的神经表示，然后显式重构未知解场。通过轻量级非局部一致性损失项来确保学习算子与重构解之间的一致性。

Result: MINPO在精度上表现出色，在处理(i)多样核类型、(ii)不同核维度和(iii)重复核积分评估带来的计算需求方面具有鲁棒性。与经典方法和基于MLP的先进神经策略相比，MINPO提供了更好的性能。

Conclusion: MINPO超越了特定问题公式，为受非局部算子支配的系统提供了一个统一框架，能够自然捕获并高效解决由广泛IDE谱及其子集（包括分数阶PDE）支配的非局部时空依赖关系。

Abstract: Many physical systems exhibit nonlocal spatiotemporal behaviors described by integro-differential equations (IDEs). Classical methods for solving IDEs require repeatedly evaluating convolution integrals, whose cost increases quickly with kernel complexity and dimensionality. Existing neural solvers can accelerate selected instances of these computations, yet they do not generalize across diverse nonlocal structures. In this work, we introduce the Memory-Informed Neural Pseudo-Operator (MINPO), a unified framework for modeling nonlocal dynamics arising from long-range spatial interactions and/or long-term temporal memory. MINPO, employing either Kolmogorov-Arnold Networks (KANs) or multilayer perceptron networks (MLPs) as encoders, learns the nonlocal operator and its inverse directly through neural representations, and then explicitly reconstruct the unknown solution fields. The learning is guarded by a lightweight nonlocal consistency loss term to enforce coherence between the learned operator and reconstructed solution. The MINPO formulation allows to naturally capture and efficiently resolve nonlocal spatiotemporal dependencies governed by a wide spectrum of IDEs and their subsets, including fractional PDEs. We evaluate the efficacy of MINPO in comparison with classical techniques and state-of-the-art neural-based strategies based on MLPs, such as A-PINN and fPINN, along with their newly-developed KAN variants, A-PIKAN and fPIKAN, designed to facilitate a fair comparison. Our study offers compelling evidence of the accuracy of MINPO and demonstrates its robustness in handling (i) diverse kernel types, (ii) different kernel dimensionalities, and (iii) the substantial computational demands arising from repeated evaluations of kernel integrals. MINPO, thus, generalizes beyond problem-specific formulations, providing a unified framework for systems governed by nonlocal operators.

</details>


### [92] [Alzheimer's Disease Brain Network Mining](https://arxiv.org/abs/2512.17276)
*Alireza Moayedikia,Sara Fin*

Main category: cs.LG

TL;DR: MATCH-AD是一个半监督学习框架，通过整合深度表示学习、图标签传播和最优传输理论，在仅有三分之一标注数据的情况下实现了近乎完美的阿尔茨海默病诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病诊断面临标注数据稀缺的挑战，临床评估昂贵且侵入性强，导致神经影像数据集中只有少量样本有真实标签。需要开发能够在有限标注数据下有效工作的诊断方法。

Method: 提出MATCH-AD框架，整合三个关键技术：1) 深度表示学习，2) 基于图的标签传播，利用神经影像数据的流形结构将诊断信息从有限标注样本传播到大量未标注样本，3) 最优传输理论，使用Wasserstein距离量化认知状态间的疾病进展。

Result: 在NACC近5000名受试者数据集上评估，包含结构MRI、脑脊液生物标志物和临床变量。尽管只有不到三分之一的样本有真实标签，MATCH-AD实现了近乎完美的诊断准确率，kappa值表明几乎完全一致，显著优于所有基线方法。即使在严重标签稀缺情况下仍保持临床可用性。

Conclusion: 该研究证明，基于原则的半监督学习方法能够释放全球积累的部分标注神经影像数据的诊断潜力，显著减少标注负担，同时保持适合临床部署的准确性。框架提供理论收敛保证，证明了标签传播误差和传输稳定性的边界。

Abstract: Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneous Alzheimer's Disease (MATCH-AD), a semi supervised framework that integrates deep representation learning, graph-based label propagation, and optimal transport theory to address this limitation. The framework leverages manifold structure in neuroimaging data to propagate diagnostic information from limited labeled samples to larger unlabeled populations, while using Wasserstein distances to quantify disease progression between cognitive states. Evaluated on nearly five thousand subjects from the National Alzheimer's Coordinating Center, encompassing structural MRI measurements from hundreds of brain regions, cerebrospinal fluid biomarkers, and clinical variables MATCHAD achieves near-perfect diagnostic accuracy despite ground truth labels for less than one-third of subjects. The framework substantially outperforms all baseline methods, achieving kappa indicating almost perfect agreement compared to weak agreement for the best baseline, a qualitative transformation in diagnostic reliability. Performance remains clinically useful even under severe label scarcity, and we provide theoretical convergence guarantees with proven bounds on label propagation error and transport stability. These results demonstrate that principled semi-supervised learning can unlock the diagnostic potential of the vast repositories of partially annotated neuroimaging data accumulating worldwide, substantially reducing annotation burden while maintaining accuracy suitable for clinical deployment.

</details>


### [93] [Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.17444)
*Javier Gonzalez-Ruiz,Carlos Rodriguez-Pardo,Iacopo Savelli,Alice Di Bella,Massimo Tavoni*

Main category: cs.LG

TL;DR: 提出基于多智能体强化学习的电力市场模型，用于评估长期市场机制对电力系统脱碳的影响


<details>
  <summary>Details</summary>
Motivation: 电力系统对实现碳中和经济至关重要，但缺乏先进工具支持政策制定者设计和评估长期电力市场机制

Method: 采用独立近端策略优化（PPO）的多智能体强化学习模型，发电公司作为利润最大化智能体在批发电力市场中进行投资决策

Result: 应用于意大利电力系统简化模型，测试不同竞争水平、市场设计和政策情景，结果显示市场设计对脱碳和避免价格波动至关重要

Conclusion: 该框架能够评估多种政策和市场机制同时交互的长期电力市场，市场参与者能够响应和适应脱碳路径

Abstract: Electricity systems are key to transforming today's society into a carbon-free economy. Long-term electricity market mechanisms, including auctions, support schemes, and other policy instruments, are critical in shaping the electricity generation mix. In light of the need for more advanced tools to support policymakers and other stakeholders in designing, testing, and evaluating long-term markets, this work presents a multi-agent reinforcement learning model capable of capturing the key features of decarbonizing energy systems. Profit-maximizing generation companies make investment decisions in the wholesale electricity market, responding to system needs, competitive dynamics, and policy signals. The model employs independent proximal policy optimization, which was selected for suitability to the decentralized and competitive environment. Nevertheless, given the inherent challenges of independent learning in multi-agent settings, an extensive hyperparameter search ensures that decentralized training yields market outcomes consistent with competitive behavior. The model is applied to a stylized version of the Italian electricity system and tested under varying levels of competition, market designs, and policy scenarios. Results highlight the critical role of market design for decarbonizing the electricity sector and avoiding price volatility. The proposed framework allows assessing long-term electricity markets in which multiple policy and market mechanisms interact simultaneously, with market participants responding and adapting to decarbonization pathways.

</details>


### [94] [Learning What to Write: Write-Gated KV for Efficient Long-Context Inference](https://arxiv.org/abs/2512.17452)
*Yen-Chieh Huang,Rui Fang,Ming-Syan Chen,Pi-Cheng Hsiu*

Main category: cs.LG

TL;DR: WG-KV通过写门控机制预测token效用，选择性写入KV缓存，减少46-57%内存使用，提升3.03-3.45倍预填充和1.89-2.56倍解码速度，保持与FlashAttention兼容。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM推理受限于二次注意力复杂度和线性KV缓存增长，现有方法通过后处理选择或淘汰忽略了根本低效问题：无差别写入持久内存。

Method: 将KV缓存管理形式化为三个因果原语：KV准入、选择和淘汰。通过Write-Gated KV实现KV准入，这是一个轻量级机制，在token进入缓存前预测其效用，过滤低效用状态以维持紧凑全局缓存和滑动局部缓存。

Result: 在Llama模型上减少46-57%内存使用，实现3.03-3.45倍预填充加速和1.89-2.56倍解码加速，精度损失可忽略，且与FlashAttention和分页KV系统兼容。

Conclusion: 学习写入什么内容是高效长上下文推理的原则性和实用方法，Write-Gated KV通过早期过滤低效用状态显著提升效率。

Abstract: Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\times$ prefill and 1.89-2.56$\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .

</details>


### [95] [Task Schema and Binding: A Double Dissociation Study of In-Context Learning](https://arxiv.org/abs/2512.17325)
*Chaeha Kim*

Main category: cs.LG

TL;DR: 论文通过因果机制验证发现上下文学习可分解为任务图式和绑定两个独立机制，前者负责抽象任务类型识别，后者处理具体输入输出关联


<details>
  <summary>Details</summary>
Motivation: 先前研究将上下文学习视为单一机制（检索式、梯度下降式或纯贝叶斯式），缺乏对其内部工作机制的因果性理解。本文旨在通过实验验证上下文学习是否由可分离的机制组成

Method: 使用激活修补实验，测试了9个来自7个Transformer家族模型以及Mamba模型（370M-13B参数）。通过晚期MLP修补实现任务图式100%转移，通过残差流修补实现绑定62%转移，证明机制可分离

Result: 1. 双重分离：任务图式与绑定机制可分离；2. 先验-图式权衡：图式依赖与先验知识负相关；3. 架构通用性：机制在所有测试架构中均存在，包括非Transformer的Mamba模型

Conclusion: 上下文学习由任务图式和绑定两个可分离的神经机制组成，这为双过程理论提供了因果证据。模型在先验知识缺乏时依赖任务图式，而先验知识通过注意力误路由而非直接输出竞争产生干扰。这一发现对提示工程有实际意义

Abstract: We provide causal mechanistic validation that in-context learning (ICL) decomposes into two separable mechanisms: Task Schema (abstract task type recognition) and Binding (specific input-output associations). Through activation patching experiments across 9 models from 7 Transformer families plus Mamba (370M-13B parameters), we establish three key findings:
  1. Double dissociation: Task Schema transfers at 100% via late MLP patching; Binding transfers at 62% via residual stream patching -- proving separable mechanisms
  2. Prior-Schema trade-off: Schema reliance inversely correlates with prior knowledge (Spearman rho = -0.596, p < 0.001, N=28 task-model pairs)
  3. Architecture generality: The mechanism operates across all tested architectures including the non-Transformer Mamba
  These findings offer a mechanistic account of the ICL puzzle that contrasts with prior views treating ICL as a monolithic mechanism (whether retrieval-based, gradient descent-like, or purely Bayesian). By establishing that Schema and Binding are neurally dissociable -- not merely behavioral modes -- we provide causal evidence for dual-process theories of ICL. Models rely on Task Schema when prior knowledge is absent, but prior knowledge interferes through attentional mis-routing (72.7% recency bias) rather than direct output competition (0%). This explains why arbitrary mappings succeed (zero prior leads to full Schema reliance) while factual overrides fail -- and reveals that the true bottleneck is attentional, not output-level. Practical implications: Understanding these dual mechanisms enables more efficient prompt engineering -- reliable schema transfer reduces required demonstrations for novel tasks, while prior-aware design can mitigate the 38% binding failure rate in high-prior scenarios, improving ICL system reliability in production deployments.

</details>


### [96] [SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals](https://arxiv.org/abs/2512.17527)
*Muhammad Haris Khan*

Main category: cs.LG

TL;DR: SafeBench-Seq是一个用于蛋白质设计基础模型的生物安全风险评估基准，使用公开数据构建，通过同源性聚类控制评估，在普通CPU上运行，仅发布元数据而不分发危险序列。


<details>
  <summary>Details</summary>
Motivation: 蛋白质设计基础模型存在具体生物安全风险，但社区缺乏简单、可复现的序列级危险筛查基准，该基准需要明确在同源性控制下评估，并能在普通CPU上运行。

Method: 基于公开数据构建基准和基线分类器，使用全局物理化学描述符和氨基酸组成作为可解释特征，通过≤40%同源性聚类进行数据集聚类，执行聚类级留出验证，评估区分能力、筛查操作点，并提供校准概率。

Result: 随机分割显著高估了模型鲁棒性；校准线性模型表现出相对较好的校准性，而树集成模型保留稍高的Brier/ECE分数；基准仅需CPU、可复现，且仅发布元数据。

Conclusion: SafeBench-Seq提供了一个简单、可复现的蛋白质序列危险筛查基准，通过同源性聚类控制评估，避免了危险序列的分发，为生物安全风险评估提供了实用工具。

Abstract: Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate "never-before-seen" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.

</details>


### [97] [GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping](https://arxiv.org/abs/2512.17570)
*Yikang Yue,Yishu Yin,Xuehai Qian*

Main category: cs.LG

TL;DR: GreedySnake是一种新的SSD卸载训练系统，采用垂直调度策略，相比现有水平调度系统，在小批量训练中实现更高吞吐量，接近屋顶线模型预测的理想性能。


<details>
  <summary>Details</summary>
Motivation: SSD卸载训练为LLM训练提供了一种经济实用的方法，但现有系统存在I/O瓶颈和调度效率问题，需要更高效的调度策略来提升训练吞吐量。

Method: 提出GreedySnake系统，采用垂直调度策略：在执行完一个层的所有微批次后再进入下一层，而不是按微批次顺序执行。同时将部分优化步骤与下一轮前向传播重叠，以缓解I/O瓶颈。

Result: 在A100 GPU上的实验结果显示，相比ZeRO-Infinity，GreedySnake在GPT-65B上实现1.96倍（1GPU）和1.93倍（4GPU）的吞吐量提升，在GPT-175B上实现2.53倍（1GPU）的吞吐量提升。

Conclusion: GreedySnake通过垂直调度策略和优化步骤重叠技术，显著提升了SSD卸载训练的吞吐量，使系统更接近屋顶线模型预测的理想性能，为大规模LLM训练提供了更高效的解决方案。

Abstract: SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake

</details>


### [98] [Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach](https://arxiv.org/abs/2512.17367)
*Yidong Chai,Yi Liu,Mohammadreza Ebrahimi,Weifeng Li,Balaji Padmanabhan*

Main category: cs.LG

TL;DR: 该研究提出LLM-SGA框架和ARHOCD检测器，通过识别文本对抗攻击的关键不变性并利用大语言模型生成样本，结合集成学习、动态权重分配和对抗训练策略，提升有害内容检测的对抗鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台存在大量有害内容（仇恨言论、虚假信息、极端言论），机器学习检测模型容易受到对抗攻击，攻击者通过细微修改文本逃避检测。现有研究在同时实现对抗鲁棒性和检测准确性方面存在挑战。

Method: 采用计算设计科学研究范式，提出LLM-SGA框架识别文本对抗攻击的关键不变性；实例化ARHOCD检测器，包含三个创新设计组件：1）利用互补优势的多基检测器集成；2）基于样本可预测性和基检测器能力的动态权重分配方法；3）迭代优化基检测器和权重分配器的对抗训练策略。

Result: 在仇恨言论、谣言和极端内容三个数据集上的实证评估表明，ARHOCD在对抗条件下具有强大的泛化能力，并显著提高了检测准确性。

Conclusion: 该研究提出的LLM-SGA框架和ARHOCD检测器有效解决了现有对抗鲁棒性增强研究的局限性，为社交媒体有害内容检测提供了同时具备高泛化能力和准确性的解决方案。

Abstract: Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evade detection. Enhancing adversarial robustness is therefore essential, requiring detectors that can defend against diverse attacks (generalizability) while maintaining high overall accuracy. However, simultaneously achieving both optimal generalizability and accuracy is challenging. Following the computational design science paradigm, this study takes a sequential approach that first proposes a novel framework (Large Language Model-based Sample Generation and Aggregation, LLM-SGA) by identifying the key invariances of textual adversarial attacks and leveraging them to ensure that a detector instantiated within the framework has strong generalizability. Second, we instantiate our detector (Adversarially Robust Harmful Online Content Detector, ARHOCD) with three novel design components to improve detection accuracy: (1) an ensemble of multiple base detectors that exploits their complementary strengths; (2) a novel weight assignment method that dynamically adjusts weights based on each sample's predictability and each base detector's capability, with weights initialized using domain knowledge and updated via Bayesian inference; and (3) a novel adversarial training strategy that iteratively optimizes both the base detectors and the weight assignor. We addressed several limitations of existing adversarial robustness enhancement research and empirically evaluated ARHOCD across three datasets spanning hate speech, rumor, and extremist content. Results show that ARHOCD offers strong generalizability and improves detection accuracy under adversarial conditions.

</details>


### [99] [AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens](https://arxiv.org/abs/2512.17375)
*Tung-Ling Li,Yuhao Wu,Hongliang Liu*

Main category: cs.LG

TL;DR: 论文揭示了奖励模型和LLM-as-a-Judge系统存在一个重复性漏洞：低困惑度的控制标记序列可以翻转二元评估结果，导致高误报率，这代表了现实中的奖励攻击风险。


<details>
  <summary>Details</summary>
Motivation: 奖励模型和LLM-as-a-Judge系统在现代后训练流程（如RLHF、DPO、RLAIF）中至关重要，它们提供标量反馈和二元决策来指导模型选择和基于RL的微调。然而这些评判系统存在一个重复性漏洞需要被识别和解决。

Method: 提出了AdvJudge-Zero方法，利用模型的下一标记分布和束搜索探索从头发现多样化的控制标记序列。分析显示这些诱导的隐藏状态扰动集中在低秩"软模式"中，与评判者的拒绝方向反对齐。

Result: 这些控制标记在大型开放权重和专用评判模型对数学和推理基准进行评分时，会导致非常高的误报率（错误答案被误判为正确）。

Conclusion: 基于LoRA的对抗训练在小规模控制标记增强示例集上可以显著减少这些误报，同时保持评估质量，为解决奖励攻击风险提供了有效方法。

Abstract: Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.

</details>


### [100] [Trust-Region Adaptive Policy Optimization](https://arxiv.org/abs/2512.17636)
*Mingyu Su,Jian Guan,Yuxian Gu,Minlie Huang,Hongning Wang*

Main category: cs.LG

TL;DR: TRAPO提出了一种混合训练框架，将监督微调(SFT)和强化学习(RL)交织在每个训练实例中，通过信任区域自适应策略优化解决传统两阶段训练的不一致问题，在数学推理任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统SFT-then-RL两阶段训练存在关键不一致性：SFT阶段的刚性模仿抑制了探索并导致遗忘，限制了RL的改进潜力。需要一种更高效的训练框架来统一外部监督和自我探索。

Method: 提出TRAPO框架：1) 在每个训练实例中交织SFT和RL，对专家前缀优化SFT损失，对模型自身补全优化RL损失；2) 引入信任区域SFT(TrSFT)，在信任区域内最小化前向KL散度，在区域外衰减优化，有效转向反向KL；3) 自适应前缀选择机制根据测量效用分配专家指导。

Result: 在五个数学推理基准测试中，TRAPO一致超越了标准SFT、RL、SFT-then-RL流程以及最近的最先进方法，为推理增强的LLMs建立了强大的新范式。

Conclusion: TRAPO通过统一监督微调和强化学习，解决了传统两阶段训练的不一致问题，提供了一种更稳定、高效的训练框架，显著提升了大型语言模型的复杂推理能力。

Abstract: Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\textbf{T}rust-\textbf{R}egion \textbf{A}daptive \textbf{P}olicy \textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.

</details>


### [101] [meval: A Statistical Toolbox for Fine-Grained Model Performance Analysis](https://arxiv.org/abs/2512.17409)
*Dishantkumar Sutariya,Eike Petersen*

Main category: cs.LG

TL;DR: 该论文提出了一个用于分析机器学习模型在不同患者亚组中性能差异的统计工具箱，特别针对医学影像应用，通过两个案例研究展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在医学机器学习模型中，按患者和记录属性分层分析模型性能已成为标准做法，能揭示重要的模型失败模式。然而，以统计严谨的方式进行此类分析具有挑战性：需要选择合适的性能指标、确定指标不确定性、校正多重比较，以及在交集分析中从组合众多的亚组组合中找到最"有趣"的亚组。

Method: 开发了一个统计工具箱，专门设计用于医学影像应用，解决了以下挑战：1) 选择适合不同样本量和基础率组间比较的性能指标；2) 确定指标不确定性；3) 校正多重比较以评估观察到的差异是否纯属偶然；4) 在交集分析中实现机制以找到组合众多亚组中最"有趣"的亚组。

Result: 通过两个案例研究展示了工具箱的应用：1) 在ISIC2020数据集上进行皮肤病变恶性分类；2) 在MIMIC-CXR数据集上进行基于胸部X射线的疾病分类。工具箱使实践者能够轻松而严谨地评估模型在潜在亚组性能差异。

Conclusion: 该统计工具箱为医学机器学习模型的亚组性能差异分析提供了严谨的统计框架，特别适用于医学影像应用，帮助识别和解决模型在不同患者群体中的性能差异问题。

Abstract: Analyzing machine learning model performance stratified by patient and recording properties is becoming the accepted norm and often yields crucial insights about important model failure modes. Performing such analyses in a statistically rigorous manner is non-trivial, however. Appropriate performance metrics must be selected that allow for valid comparisons between groups of different sample sizes and base rates; metric uncertainty must be determined and multiple comparisons be corrected for, in order to assess whether any observed differences may be purely due to chance; and in the case of intersectional analyses, mechanisms must be implemented to find the most `interesting' subgroups within combinatorially many subgroup combinations. We here present a statistical toolbox that addresses these challenges and enables practitioners to easily yet rigorously assess their models for potential subgroup performance disparities. While broadly applicable, the toolbox is specifically designed for medical imaging applications. The analyses provided by the toolbox are illustrated in two case studies, one in skin lesion malignancy classification on the ISIC2020 dataset and one in chest X-ray-based disease classification on the MIMIC-CXR dataset.

</details>


### [102] [You Only Train Once: Differentiable Subset Selection for Omics Data](https://arxiv.org/abs/2512.17678)
*Daphné Chopard,Jorge da Silva Gonçalves,Irene Cannistraci,Thomas M. Sutter,Julia E. Vogt*

Main category: cs.LG

TL;DR: YOTO是一个端到端的单细胞转录组基因选择框架，通过可微分架构联合选择离散基因子集并进行预测，实现选择和预测的强耦合。


<details>
  <summary>Details</summary>
Motivation: 现有特征选择方法多为多阶段流程或依赖事后特征归因，导致选择与预测弱耦合，需要改进以实现更紧凑、信息丰富的基因子集选择。

Method: YOTO采用端到端可微分架构，通过稀疏性约束确保只有被选基因参与推理，无需额外下游分类器；通过多任务学习设计实现跨任务共享表征。

Result: 在两个代表性单细胞RNA-seq数据集上，YOTO持续优于现有最先进基线方法，展现出更好的预测性能和更紧凑有意义的基因子集。

Conclusion: 稀疏、端到端、多任务的基因子集选择能提高预测性能并产生紧凑有意义的基因子集，有助于推进生物标志物发现和单细胞分析。

Abstract: Selecting compact and informative gene subsets from single-cell transcriptomic data is essential for biomarker discovery, improving interpretability, and cost-effective profiling. However, most existing feature selection approaches either operate as multi-stage pipelines or rely on post hoc feature attribution, making selection and prediction weakly coupled. In this work, we present YOTO (you only train once), an end-to-end framework that jointly identifies discrete gene subsets and performs prediction within a single differentiable architecture. In our model, the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation. This closed feedback loop enables the model to iteratively refine both what it selects and how it predicts during training. Unlike existing approaches, YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers. Through a multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another, and discovering gene subsets that generalize across tasks without additional training steps. We evaluate YOTO on two representative single-cell RNA-seq datasets, showing that it consistently outperforms state-of-the-art baselines. These results demonstrate that sparse, end-to-end, multi-task gene subset selection improves predictive performance and yields compact and meaningful gene subsets, advancing biomarker discovery and single-cell analysis.

</details>


### [103] [Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow](https://arxiv.org/abs/2512.17878)
*Herlock Rahimi*

Main category: cs.LG

TL;DR: 该论文提出了一种基于Wasserstein-Fisher-Rao几何的采样方法，通过引入显式校正项和加权随机微分方程来改进传统扩散模型在非凸或多模态分布中的采样效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的扩散模型在处理非凸或多模态分布（如双井势）时，混合速率会指数级恶化。许多实际生成建模任务涉及高度非对数凹的目标分布，需要开发能改善探索能力的采样方案。

Method: 利用信息几何工具，通过Wasserstein-Fisher-Rao几何增强基于扩散的采样器，引入受控的质量重加权机制。通过显式校正项和Feynman-Kac表示的加权随机微分方程来实现重加权机制。

Result: 提出了基于WFR的采样动力学框架，阐明了其几何和算子理论结构，为未来的理论和算法发展奠定了基础。

Conclusion: Wasserstein-Fisher-Rao几何为改进传统扩散模型在非凸分布中的采样效率提供了有前景的途径，通过耦合样本空间中的传输与概率测度空间上的垂直（反应）动力学来实现更好的探索能力。

Abstract: Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.
  A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.

</details>


### [104] [NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks](https://arxiv.org/abs/2512.17531)
*Salar Beigzad*

Main category: cs.LG

TL;DR: CFF算法通过层间协作机制改进Forward-Forward算法，解决了原算法层间隔离问题，在保持前向计算优势的同时提升收敛效率和性能


<details>
  <summary>Details</summary>
Motivation: 传统Forward-Forward算法存在严重的层间隔离问题，各层独立优化goodness函数，缺乏集体学习动态，限制了表示协调和深层架构的收敛效率

Method: 提出协作式Forward-Forward学习框架，包含两种协作范式：固定协作（F-CFF）和自适应协作（A-CFF）。通过协作goodness函数整合所有层的加权贡献，实现协调特征学习

Result: 在MNIST和Fashion-MNIST数据集上的全面评估显示，相比基线Forward-Forward实现有显著性能提升

Conclusion: 层间协作是Forward-Forward学习的基本增强机制，对神经形态计算架构和能源受限AI系统具有直接应用价值

Abstract: The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independently without leveraging collective learning dynamics. This isolation constrains representational coordination and limits convergence efficiency in deeper architectures. This paper introduces Collaborative Forward-Forward (CFF) learning, extending the original algorithm through inter-layer cooperation mechanisms that preserve forward-only computation while enabling global context integration. Our framework implements two collaborative paradigms: Fixed CFF (F-CFF) with constant inter-layer coupling and Adaptive CFF (A-CFF) with learnable collaboration parameters that evolve during training. The collaborative goodness function incorporates weighted contributions from all layers, enabling coordinated feature learning while maintaining memory efficiency and biological plausibility. Comprehensive evaluation on MNIST and Fashion-MNIST demonstrates significant performance improvements over baseline Forward-Forward implementations. These findings establish inter-layer collaboration as a fundamental enhancement to Forward-Forward learning, with immediate applicability to neuromorphic computing architectures and energy-constrained AI systems.

</details>


### [105] [Bayesian Optimisation: Which Constraints Matter?](https://arxiv.org/abs/2512.17569)
*Xietao Wang Lin,Juan Ungredda,Max Butler,James Town,Alma Rahat,Hemant Singh,Juergen Branke*

Main category: cs.LG

TL;DR: 本文提出了针对解耦黑盒约束问题的贝叶斯优化新变体，基于知识梯度采集函数，能够智能选择评估相关约束而非全部约束。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化在处理昂贵的全局黑盒优化问题时表现出色，但对于具有解耦约束的问题，现有方法通常需要评估所有约束函数，而实际上只有少数约束在最优解处是有效的。这导致了不必要的计算开销。

Method: 提出了基于知识梯度采集函数的贝叶斯优化新变体，专门针对解耦黑盒约束问题。该方法能够智能识别哪些约束可能在最优解处起约束作用，从而只评估相关的约束函数，而不是评估所有约束。

Result: 通过实证基准测试，证明了所提方法相对于现有最先进方法的优越性，在解耦约束优化问题上表现更好。

Conclusion: 提出的新贝叶斯优化变体能够有效处理解耦黑盒约束问题，通过智能选择评估相关约束，提高了优化效率，超越了现有方法。

Abstract: Bayesian optimisation has proven to be a powerful tool for expensive global black-box optimisation problems. In this paper, we propose new Bayesian optimisation variants of the popular Knowledge Gradient acquisition functions for problems with \emph{decoupled} black-box constraints, in which subsets of the objective and constraint functions may be evaluated independently. In particular, our methods aim to take into account that often only a handful of the constraints may be binding at the optimum, and hence we should evaluate only relevant constraints when trying to optimise a function. We empirically benchmark these methods against existing methods and demonstrate their superiority over the state-of-the-art.

</details>


### [106] [Learning Safe Autonomous Driving Policies Using Predictive Safety Representations](https://arxiv.org/abs/2512.17586)
*Mahesh Keswani,Raunak Bhattacharyya*

Main category: cs.LG

TL;DR: SRPL框架在真实世界自动驾驶场景中验证有效，能改善奖励-安全权衡，提高成功率并降低成本，同时增强对观测噪声的鲁棒性和跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 安全强化学习在自动驾驶中面临性能优化与安全要求的根本矛盾：过于保守的策略限制驾驶效率，而激进的探索则带来安全风险。SRPL框架通过预测未来约束违规的模型来解决这一挑战，但需要验证其在真实世界自动驾驶场景中的有效性。

Method: 在Waymo Open Motion Dataset和NuPlan数据集上进行系统实验，评估SRPL框架在真实世界自动驾驶场景中的表现。研究包括奖励-安全权衡分析、成功率统计、成本降低效果、对观测噪声的鲁棒性测试，以及零样本跨数据集评估。

Result: SRPL能显著改善奖励-安全权衡，在成功率（效应大小r=0.65-0.86）和成本降低（效应大小r=0.70-0.83）方面实现统计显著改进（p<0.05）。预测安全表示在提高对观测噪声的鲁棒性方面起关键作用，在跨数据集评估中SRPL增强的智能体表现出更好的泛化能力。

Conclusion: 预测安全表示有潜力增强自动驾驶中的安全强化学习，但SRPL的有效性取决于底层策略优化器和数据集分布。研究证实了SRPL在真实世界自动驾驶场景中的适用性和价值。

Abstract: Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p < 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving.

</details>


### [107] [Sharing Knowledge without Sharing Data: Stitches can improve ensembles of disjointly trained models](https://arxiv.org/abs/2512.17592)
*Arthur Guijt,Dirk Thierens,Ellen Kerkhof,Jan Wiersma,Tanja Alderliesten,Peter A. N. Bosman*

Main category: cs.LG

TL;DR: 该研究探讨了在数据分散且无法共享的医疗等领域，如何通过异步协作（仅共享已训练模型）而非传统的联邦学习来实现模型融合。研究发现，使用缝合层技术结合个体训练模型的中间表示，可以在保持各参与方自身数据性能的同时，显著提升对其他方数据的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在医疗等敏感领域，数据通常分散在不同机构且无法共享，传统的联邦学习需要同步训练和权重交换，存在实施难度。本研究旨在探索仅通过共享已训练模型（如发表时）的异步协作方式，能否实现有效的模型融合与性能提升。

Method: 采用多目标视角，将各参与方数据的性能独立评估。提出使用缝合层技术，将个体训练模型的中间表示进行结合。通过对比分析：1）仅在单方数据上训练；2）传统联邦学习；3）个体训练模型的集成；4）缝合层融合方法，评估不同协作方式的性能差异。

Result: 1）仅在单方数据上训练时，与另一方数据合并后，在该方自身数据上的性能相似，但在其他方数据上表现显著较差；2）个体训练模型的集成虽然泛化能力更好，但会损害各参与方自身数据集的性能；3）缝合层融合方法能够将性能恢复到竞争水平，同时保持改进的泛化能力。

Conclusion: 通过缝合层技术结合个体训练模型的中间表示，异步协作（仅共享已训练模型）能够实现与同步协作相竞争的性能，在保持各参与方自身数据性能的同时，显著提升对其他方数据的泛化能力，为数据分散且无法共享的场景提供了可行的解决方案。

Abstract: Deep learning has been shown to be very capable at performing many real-world tasks. However, this performance is often dependent on the presence of large and varied datasets. In some settings, like in the medical domain, data is often fragmented across parties, and cannot be readily shared. While federated learning addresses this situation, it is a solution that requires synchronicity of parties training a single model together, exchanging information about model weights. We investigate how asynchronous collaboration, where only already trained models are shared (e.g. as part of a publication), affects performance, and propose to use stitching as a method for combining models.
  Through taking a multi-objective perspective, where performance on each parties' data is viewed independently, we find that training solely on a single parties' data results in similar performance when merging with another parties' data, when considering performance on that single parties' data, while performance on other parties' data is notably worse. Moreover, while an ensemble of such individually trained networks generalizes better, performance on each parties' own dataset suffers. We find that combining intermediate representations in individually trained models with a well placed pair of stitching layers allows this performance to recover to a competitive degree while maintaining improved generalization, showing that asynchronous collaboration can yield competitive results.

</details>


### [108] [A Systems-Theoretic View on the Convergence of Algorithms under Disturbances](https://arxiv.org/abs/2512.17598)
*Guner Dilsad Er,Sebastian Trimpe,Michael Muehlebach*

Main category: cs.LG

TL;DR: 该论文提出了一种系统分析算法在噪声、扰动和与其他动态系统互连环境下收敛性的统一框架，通过Lyapunov理论量化扰动影响，并应用于分布式学习、机器学习泛化和隐私保护等多个领域。


<details>
  <summary>Details</summary>
Motivation: 随着算法在复杂物理、社会和工程系统中广泛应用，它们经常暴露于扰动、噪声和其他动态系统的互连环境中。现有研究主要关注孤立环境下的算法收敛性，缺乏对扰动环境下算法性能的系统分析框架。

Method: 利用逆Lyapunov定理推导关键不等式，量化扰动对算法收敛性的影响。该方法将孤立环境下的收敛保证扩展到存在扰动的场景，系统推导稳定性边界和收敛速率。

Result: 建立了扰动环境下算法分析的统一理论工具，能够量化噪声和互连对算法性能的影响。该结果可应用于评估分布式学习中的通信约束、机器学习泛化敏感性以及隐私保护中的噪声注入效果。

Conclusion: 该研究为分析噪声、扰动和系统互连环境下的算法性能提供了统一的数学框架，填补了现有理论空白，具有广泛的应用价值，特别是在分布式学习、机器学习泛化和隐私保护等领域。

Abstract: Algorithms increasingly operate within complex physical, social, and engineering systems where they are exposed to disturbances, noise, and interconnections with other dynamical systems. This article extends known convergence guarantees of an algorithm operating in isolation (i.e., without disturbances) and systematically derives stability bounds and convergence rates in the presence of such disturbances. By leveraging converse Lyapunov theorems, we derive key inequalities that quantify the impact of disturbances. We further demonstrate how our result can be utilized to assess the effects of disturbances on algorithmic performance in a wide variety of applications, including communication constraints in distributed learning, sensitivity in machine learning generalization, and intentional noise injection for privacy. This underpins the role of our result as a unifying tool for algorithm analysis in the presence of noise, disturbances, and interconnections with other dynamical systems.

</details>


### [109] [Polyharmonic Cascade](https://arxiv.org/abs/2512.17671)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: 本文提出了一种名为"多谐级联"的深度学习架构，通过随机函数理论和无差别原理推导出多层多谐样条包，能在保持全局平滑性和概率解释的同时逼近任意复杂度的非线性函数。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习架构缺乏严格的数学理论基础，梯度下降训练方法存在收敛慢、容易过拟合等问题。需要一种既能保持理论一致性，又能高效训练且具有概率解释的深度学习架构。

Method: 提出多谐级联架构：由多层多谐样条包组成，每层基于随机函数理论和无差别原理严格推导。采用替代梯度下降的训练方法：在每个批次上求解单个全局线性系统，相对于固定"星座"节点的函数值进行优化，实现所有层的同步更新。

Result: 该方法计算效率高：所有计算简化为可在GPU上高效执行的2D矩阵操作。在MNIST数据集上实现了快速学习且不过拟合，保持了各层的概率解释和与原始模型的理论一致性。

Conclusion: 多谐级联架构提供了一种具有严格数学基础、理论一致、计算高效的深度学习新范式，既能逼近复杂非线性函数，又能保持全局平滑性和概率解释，为深度学习理论发展提供了新方向。

Abstract: This paper presents a deep machine learning architecture, the "polyharmonic cascade" -- a sequence of packages of polyharmonic splines, where each layer is rigorously derived from the theory of random functions and the principles of indifference. This makes it possible to approximate nonlinear functions of arbitrary complexity while preserving global smoothness and a probabilistic interpretation. For the polyharmonic cascade, a training method alternative to gradient descent is proposed: instead of directly optimizing the coefficients, one solves a single global linear system on each batch with respect to the function values at fixed "constellations" of nodes. This yields synchronized updates of all layers, preserves the probabilistic interpretation of individual layers and theoretical consistency with the original model, and scales well: all computations reduce to 2D matrix operations efficiently executed on a GPU. Fast learning without overfitting on MNIST is demonstrated.

</details>


### [110] [Convergence Guarantees for Federated SARSA with Local Training and Heterogeneous Agents](https://arxiv.org/abs/2512.17688)
*Paul Mangold,Eloïse Berthier,Eric Moulines*

Main category: cs.LG

TL;DR: 本文提出了联邦SARSA（FedSARSA）的理论分析，建立了在异构环境下的收敛保证，首次给出了样本和通信复杂度边界，并证明了FedSARSA能够实现与智能体数量成线性加速的效果。


<details>
  <summary>Details</summary>
Motivation: 联邦强化学习中的异构性（包括局部转移和奖励的差异）对算法收敛性提出了挑战，需要建立FedSARSA在异构环境下的理论保证，量化异构性影响，并分析多局部更新下的收敛性能。

Method: 采用线性函数逼近和局部训练的联邦SARSA算法，通过新的精确多步误差展开分析单智能体SARSA，建立FedSARSA在异构环境下的收敛理论框架，量化异构性影响并分析多局部更新策略。

Result: 建立了FedSARSA在异构环境下的收敛保证，首次提供了样本和通信复杂度边界，证明了FedSARSA能够实现与智能体数量成线性加速（除马尔可夫采样引入的高阶项外），数值实验支持理论发现。

Conclusion: FedSARSA在异构联邦强化学习环境中具有理论收敛保证，能够有效处理局部转移和奖励的差异，通过多局部更新实现线性加速，为联邦强化学习的实际应用提供了理论基础。

Abstract: We present a novel theoretical analysis of Federated SARSA (FedSARSA) with linear function approximation and local training. We establish convergence guarantees for FedSARSA in the presence of heterogeneity, both in local transitions and rewards, providing the first sample and communication complexity bounds in this setting. At the core of our analysis is a new, exact multi-step error expansion for single-agent SARSA, which is of independent interest. Our analysis precisely quantifies the impact of heterogeneity, demonstrating the convergence of FedSARSA with multiple local updates. Crucially, we show that FedSARSA achieves linear speed-up with respect to the number of agents, up to higher-order terms due to Markovian sampling. Numerical experiments support our theoretical findings.

</details>


### [111] [Mitigating Forgetting in Low Rank Adaptation](https://arxiv.org/abs/2512.17720)
*Joanna Sliwa,Frank Schneider,Philipp Hennig,Jose Miguel Hernandez-Lobato*

Main category: cs.LG

TL;DR: LaLoRA：一种基于拉普拉斯近化的权重空间正则化方法，应用于LoRA微调，通过估计参数置信度并约束高曲率方向的更新，在保持预训练知识的同时实现高效目标域学习。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调方法（如LoRA）虽然能快速将大型预训练模型适配到下游任务，但常常导致模型遗忘原有的领域知识（灾难性遗忘）。需要一种方法在保持预训练知识的同时实现高效的目标域学习。

Method: LaLoRA是一种权重空间正则化技术，将拉普拉斯近似应用于低秩适配（LoRA）。该方法估计模型对每个参数的置信度，并约束高曲率方向的更新。通过仅对LoRA权重应用拉普拉斯近似，保持方法轻量级。还探索了不同损失景观曲率近似方法来估计参数置信度。

Result: 通过在Llama模型上进行数学推理微调评估，展示了改进的学习-遗忘权衡，这种权衡可以通过方法的正则化强度直接控制。进一步分析了用于拉普拉斯近似的数据效果，并研究了超参数的鲁棒性。

Conclusion: LaLoRA提供了一种有效的方法来解决参数高效微调中的灾难性遗忘问题，通过拉普拉斯近似约束参数更新，在保持预训练知识的同时实现高效的目标域适应，且方法保持轻量级。

Abstract: Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), enable fast specialization of large pre-trained models to different downstream applications. However, this process often leads to catastrophic forgetting of the model's prior domain knowledge. We address this issue with LaLoRA, a weight-space regularization technique that applies a Laplace approximation to Low-Rank Adaptation. Our approach estimates the model's confidence in each parameter and constrains updates in high-curvature directions, preserving prior knowledge while enabling efficient target-domain learning. By applying the Laplace approximation only to the LoRA weights, the method remains lightweight. We evaluate LaLoRA by fine-tuning a Llama model for mathematical reasoning and demonstrate an improved learning-forgetting trade-off, which can be directly controlled via the method's regularization strength. We further explore different loss landscape curvature approximations for estimating parameter confidence, analyze the effect of the data used for the Laplace approximation, and study robustness across hyperparameters.

</details>


### [112] [Calibratable Disambiguation Loss for Multi-Instance Partial-Label Learning](https://arxiv.org/abs/2512.17788)
*Wei Tang,Yin-Fang Yang,Weijia Zhang,Min-Ling Zhang*

Main category: cs.LG

TL;DR: 提出了一种可校准的消歧损失（CDL）来改善多实例部分标签学习中的分类准确性和校准性能，该损失有两种实现形式，可无缝集成到现有框架中。


<details>
  <summary>Details</summary>
Motivation: 现有的多实例部分标签学习方法存在校准性能差的问题，这影响了分类器的可靠性。需要一种能够同时提高分类准确性和校准性能的方法。

Method: 提出了一种即插即用的可校准消歧损失（CDL），该损失有两种实现：第一种基于候选标签集的概率进行校准，第二种整合候选标签集和非候选标签集的概率。该损失可以无缝集成到现有的MIPL和PLL框架中。

Result: 在基准数据集和真实世界数据集上的实验结果表明，CDL显著提高了分类性能和校准性能。理论分析证明了CDL的下界和正则化特性，表明其优于传统的消歧损失。

Conclusion: 提出的可校准消歧损失（CDL）有效解决了多实例部分标签学习中的校准问题，同时提高了分类准确性和模型可靠性，为弱监督学习提供了新的解决方案。

Abstract: Multi-instance partial-label learning (MIPL) is a weakly supervised framework that extends the principles of multi-instance learning (MIL) and partial-label learning (PLL) to address the challenges of inexact supervision in both instance and label spaces. However, existing MIPL approaches often suffer from poor calibration, undermining classifier reliability. In this work, we propose a plug-and-play calibratable disambiguation loss (CDL) that simultaneously improves classification accuracy and calibration performance. The loss has two instantiations: the first one calibrates predictions based on probabilities from the candidate label set, while the second one integrates probabilities from both candidate and non-candidate label sets. The proposed CDL can be seamlessly incorporated into existing MIPL and PLL frameworks. We provide a theoretical analysis that establishes the lower bound and regularization properties of CDL, demonstrating its superiority over conventional disambiguation losses. Experimental results on benchmark and real-world datasets confirm that our CDL significantly enhances both classification and calibration performance.

</details>


### [113] [Exploiting ID-Text Complementarity via Ensembling for Sequential Recommendation](https://arxiv.org/abs/2512.17820)
*Liam Collins,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Donald Loveland,Leonardo Neves,Neil Shah*

Main category: cs.LG

TL;DR: 本文研究发现ID嵌入和文本模态嵌入在序列推荐中具有互补性，提出了一种简单的集成方法，无需复杂融合架构就能超越现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐模型对ID特征和模态特征的互补性缺乏理解：一些工作完全用模态嵌入替代ID嵌入，认为模态嵌入可以替代ID嵌入；另一些工作联合使用两者但认为需要复杂的融合策略。本文旨在填补这一理解空白。

Method: 提出新的序列推荐方法：通过独立训练ID模型和文本模型来保持两者的互补性，然后使用简单的集成策略来利用这种互补性。

Result: 该方法虽然简单，但超越了多个竞争性的序列推荐基线模型，表明ID和文本特征对于实现最先进的序列推荐性能都是必要的。

Conclusion: ID和文本特征在序列推荐中具有互补性，两者结合对于达到最佳性能是必要的，但不需要复杂的融合架构，简单的集成策略就足够了。

Abstract: Modern Sequential Recommendation (SR) models commonly utilize modality features to represent items, motivated in large part by recent advancements in language and vision modeling. To do so, several works completely replace ID embeddings with modality embeddings, claiming that modality embeddings render ID embeddings unnecessary because they can match or even exceed ID embedding performance. On the other hand, many works jointly utilize ID and modality features, but posit that complex fusion strategies, such as multi-stage training and/or intricate alignment architectures, are necessary for this joint utilization. However, underlying both these lines of work is a lack of understanding of the complementarity of ID and modality features. In this work, we address this gap by studying the complementarity of ID- and text-based SR models. We show that these models do learn complementary signals, meaning that either should provide performance gain when used properly alongside the other. Motivated by this, we propose a new SR method that preserves ID-text complementarity through independent model training, then harnesses it through a simple ensembling strategy. Despite this method's simplicity, we show it outperforms several competitive SR baselines, implying that both ID and text features are necessary to achieve state-of-the-art SR performance but complex fusion architectures are not.

</details>


### [114] [Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space](https://arxiv.org/abs/2512.17884)
*Xinyue Yu,Hayden Schaeffer*

Main category: cs.LG

TL;DR: 提出RRFF-FEM方法，结合正则化随机傅里叶特征和有限元重建映射，用于从噪声数据中学习算子，具有噪声鲁棒性和计算效率


<details>
  <summary>Details</summary>
Motivation: 传统核方法算子学习虽然准确且理论完备，但对大规模训练集计算代价高，且对噪声敏感，需要更鲁棒高效的替代方案

Method: 使用多元学生t分布生成随机特征，结合频率加权Tikhonov正则化抑制高频噪声，并与有限元重建映射结合形成RRFF-FEM方法

Result: 理论证明当特征数N按m log m缩放时系统条件良好，数值实验显示对噪声鲁棒，训练时间减少，在多个PDE问题上保持与核方法和神经算子相当的精度

Conclusion: RRFF和RRFF-FEM方法在噪声鲁棒性、计算效率和准确性方面优于未正则化随机特征模型，为算子学习提供了实用解决方案

Abstract: Operator learning is a data-driven approximation of mappings between infinite-dimensional function spaces, such as the solution operators of partial differential equations. Kernel-based operator learning can offer accurate, theoretically justified approximations that require less training than standard methods. However, they can become computationally prohibitive for large training sets and can be sensitive to noise. We propose a regularized random Fourier feature (RRFF) approach, coupled with a finite element reconstruction map (RRFF-FEM), for learning operators from noisy data. The method uses random features drawn from multivariate Student's $t$ distributions, together with frequency-weighted Tikhonov regularization that suppresses high-frequency noise. We establish high-probability bounds on the extreme singular values of the associated random feature matrix and show that when the number of features $N$ scales like $m \log m$ with the number of training samples $m$, the system is well-conditioned, which yields estimation and generalization guarantees. Detailed numerical experiments on benchmark PDE problems, including advection, Burgers', Darcy flow, Helmholtz, Navier-Stokes, and structural mechanics, demonstrate that RRFF and RRFF-FEM are robust to noise and achieve improved performance with reduced training time compared to the unregularized random feature model, while maintaining competitive accuracy relative to kernel and neural operator tests.

</details>
