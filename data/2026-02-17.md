<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 20]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 127]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 9]
- [cs.AI](#cs.AI) [Total: 89]
- [cs.CC](#cs.CC) [Total: 5]
- [quant-ph](#quant-ph) [Total: 74]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [Phonon Echo from Multi-Level Systems and Many-Body Interactions in Low-Temperature Glasses](https://arxiv.org/abs/2602.14435)
*Di Zhou*

Main category: cond-mat.dis-nn

TL;DR: Extending the two-level-system (TLS) model to multi-level systems explains persistent phonon echoes in low-temperature glasses through many-body interactions from virtual phonon exchange, despite thermal dephasing causing amplitude decay.


<details>
  <summary>Details</summary>
Motivation: The standard TLS model explains universal glass anomalies but has limitations in fully accounting for phenomena like phonon echoes; this work explores whether multi-level systems with nonlinear energy structures and disorder can better describe these effects.

Method: Extended the TLS framework to multi-level systems by incorporating nonlinear energy landscapes, disorder, and virtual phonon exchange to introduce many-body interactions between systems, leading to nonlinear eigen-energies.

Result: Phonon echoes persist in multi-level systems due to many-body interactions enhancing the signal, while finite-temperature thermal fluctuations cause dephasing and decay of echo amplitude; results are consistent across semi-classical and quantum regimes.

Conclusion: Validates the multi-level-system model for low-temperature glass dynamics and highlights the critical role of many-body interactions in explaining persistent phonon echoes despite thermal decoherence.

Abstract: At low temperatures, glasses exhibit distinctive properties compared to crystalline solids. A notable example is the phonon echo, a phenomenon that motivated the two-level-system (TLS) model. This model has successfully explained many universal anomalies in glasses. Here, we extend the TLS framework to a multi-level system and show that phonon echoes persist when nonlinear energy structures and disorder are included. By incorporating virtual phonon exchange, we introduce many-body interactions between these multi-level systems, leading to nonlinear eigen-energies that enhance the echo signal. Meanwhile, finite-temperature thermal fluctuations cause dephasing, resulting in a decay of echo amplitude over time. The analytical and numerical results are consistent across semi-classical and quantum regimes. Our work validates the multi-level-system model and underscores the role of many-body interactions in low-temperature glassy dynamics.

</details>


### [2] [Antiferromagnetic Barkhausen noise induced by weak random-field disorder](https://arxiv.org/abs/2602.14713)
*Bosiljka Tadic*

Main category: cond-mat.dis-nn

TL;DR: 本研究通过数值模拟弱无序三维反铁磁自旋模型，发现阶梯状磁滞回线和三角形磁化脉冲，揭示反铁磁巴克豪森噪声具有与磁化平台转变相关的峰结构、循环趋势及多重分形涨落，可用自组织临界动力学解释，与铁磁体有本质区别。


<details>
  <summary>Details</summary>
Motivation: 探究弱无序反铁磁系统在磁场下的磁化反转机制，揭示其巴克豪森噪声和雪崩现象的特征，并与铁磁体对比，理解自组织临界性。

Method: 采用三维反铁磁自旋模型的数值模拟，在极弱无序和低温条件下，分析磁场驱动的磁化行为、磁滞回线及雪崩序列。

Result: 观察到阶梯状磁滞回线和随无序增加的三角形磁化脉冲；局域随机场形成类铁磁团簇并构成迷宫结构，导致雪崩传播；反铁磁巴克豪森噪声呈现峰结构、循环趋势和多重分形涨落，奇异性谱量化无序度；雪崩活动具尺度不变性，与实验观测的无序亚铁磁体、马氏体及量子巴克豪森噪声相似，符合自组织临界动力学。

Conclusion: 该研究揭示反铁磁系统在弱无序下磁化反转的独特行为，其巴克豪森噪声与铁磁体显著不同，表现为多重分形和自组织临界性，为理解无序磁性系统中的临界现象提供了新见解。

Abstract: This study numerically investigates magnetisation reversal processes driven by an external magnetic field in three-dimensional antiferromagnetic spin models with weak random field disorder. Considering an extremely weak disorder and low temperature, we observe a step-wise hysteresis loop and the appearance of short magnetisation bursts of a characteristic triangular shape; the number of bursts increases with disorder, indicative of Barkhausen-type noise. These phenomena are attributed to the simultaneous reversal at a given external field of segments composed of spins with identical neighbourhoods. A local random field orients one or more spin neighbours, resulting in small, ferromagnetic-like clusters distributed throughout the system. As disorder increases, these clusters may merge to form a labyrinthine structure within the antiferromagnetic background, facilitating brief avalanche propagation. The results demonstrate that, compared with familiar random-field ferromagnets, the observed antiferromagnetic Barkhausen noise and the related avalanche sequence have a profoundly different structure, organised into peaks associated with the transition between magnetisation plateaus. They exhibit prominent cyclical trends and disorder-dependent multifractal fluctuations, with the singularity spectrum quantifying the degree of disorder. The activity avalanches exhibit scale invariance resembling that recently found in experiments with disordered ferr\textit{i}magnets and martensites, as well as in quantum Barkhausen noise, which are associated with active geometric regions rather than individual-spin dynamics. The observed scaling behaviour is interpreted in terms of self-organised critical dynamics.

</details>


### [3] [From Classical to Quantum: Extending Prometheus for Unsupervised Discovery of Phase Transitions in Three Dimensions and Quantum Systems](https://arxiv.org/abs/2602.14928)
*Brandon Yee,Wilson Collins,Maximilian Rutkowski*

Main category: cond-mat.dis-nn

TL;DR: 本研究将Prometheus无监督相变发现框架从2D扩展到3D经典和量子多体系统。在3D伊辛模型中实现0.01%临界温度精度和≥70%临界指数准确度，正确识别普适类；在量子横场伊辛模型中实现2%量子临界点精度，发现基态磁化为序参量；在无序系统中检测到无限随机临界性并提取隧道指数ψ=0.48±0.08。证明VAE基无监督学习能跨物理领域识别不同临界行为，为无解析解系统提供新工具。


<details>
  <summary>Details</summary>
Motivation: 将无监督相变发现框架从2D扩展到3D经典和量子系统，解决高维可扩展性和量子泛化问题，为缺乏解析解的系统提供机器学习工具。

Method: 扩展Prometheus框架，3D伊辛模型用VAE方法，量子系统开发量子感知VAE（Q-VAE），采用复值波函数和保真度损失函数，通过χ²检验识别普适类。

Result: 3D伊辛模型：T_c精度0.01%（4.511±0.005），临界指数准确度≥70%（β=0.328±0.015，γ=1.24±0.06，ν=0.632±0.025），正确识别3D伊辛普适类（p=0.72）；量子横场伊辛模型：h_c精度2%（1.00±0.02），r=0.97识别基态磁化；无序系统：提取ψ=0.48±0.08，与理论0.5一致。

Conclusion: 无监督学习不仅能定位临界点，还能识别定性不同的临界行为类型。VAE基发现方法在经典热相变和量子相变间具有泛化能力，为解析解缺失的相图探索提供鲁棒工具。

Abstract: We extend the Prometheus framework for unsupervised phase transition discovery from 2D classical systems to 3D classical and quantum many-body systems, addressing scalability in higher dimensions and generalization to quantum fluctuations. For the 3D Ising model ($L \leq 32$), the framework detects the critical temperature within 0.01\% of literature values ($T_c/J = 4.511 \pm 0.005$) and extracts critical exponents with $\geq 70\%$ accuracy ($β= 0.328 \pm 0.015$, $γ= 1.24 \pm 0.06$, $ν= 0.632 \pm 0.025$), correctly identifying the 3D Ising universality class via $χ^2$ comparison ($p = 0.72$) without analytical guidance. For quantum systems, we developed quantum-aware VAE (Q-VAE) architectures using complex-valued wavefunctions and fidelity-based loss. Applied to the transverse field Ising model, we achieve 2\% accuracy in quantum critical point detection ($h_c/J = 1.00 \pm 0.02$) and successfully discover ground state magnetization as the order parameter ($r = 0.97$). Notably, for the disordered transverse field Ising model, we detect exotic infinite-randomness criticality characterized by activated dynamical scaling $\ln ξ\sim |h - h_c|^{-ψ}$, extracting a tunneling exponent $ψ= 0.48 \pm 0.08$ consistent with theoretical predictions ($ψ= 0.5$). This demonstrates that unsupervised learning can identify qualitatively different types of critical behavior, not just locate critical points. Our systematic validation across classical thermal transitions ($T = 0$ to $T > 0$) and quantum phase transitions ($T = 0$, varying $h$) establishes that VAE-based discovery generalizes across fundamentally different physical domains, providing robust tools for exploring phase diagrams where analytical solutions are unavailable.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [4] [Exact dimer ground state and quantum phase transitions in a coupled spin ladder](https://arxiv.org/abs/2602.13406)
*Manas Ranjan Mahapatra,Rakesh Kumar*

Main category: cond-mat.str-el

TL;DR: 研究通过引入空间各向异性的第三近邻相互作用，构建了具有精确二聚物基态的自旋-1/2梯子系统，利用BOMFT和DMRG方法揭示了双条纹序、奈尔序及量子无序二聚化三相及其临界点


<details>
  <summary>Details</summary>
Motivation: 探索自旋梯子系统在一维与二维之间的中介行为，研究受挫相互作用和各向异性对基态相变的影响，以理解量子磁体中的有序-无序转变机制

Method: 采用键算符平均场理论（BOMFT）分析相图，结合密度矩阵重整化群（DMRG）数值验证，引入水平方向第三近邻各向异性相互作用构建模型

Result: 发现精确柱状二聚物基态；BOMFT预测双条纹序-二聚化（J₁=-0.81）和二聚化-奈尔序（J₁=2.81）相变点，DMRG修正为-0.79和2.29；额外发现J₁>4.5时奈尔序消失；静态自旋结构因子证实各相特征

Conclusion: 各向异性相互作用可诱导精确二聚物相，系统存在丰富的量子相变行为，BOMFT与DMRG结果相互补充，为理解低维量子磁体相变提供了新模型

Abstract: Spin ladders are key models that act as intermediaries between one-dimensional and two-dimensional spin systems. In this study, we examine a coupled spin-$1/2$ ladder, where frustrated ladders with leg, rung, and diagonal interactions are linked through a horizontal coupling. By introducing a spatially anisotropic third-nearest-neighbor interaction along the horizontal direction, the model was found to possess an exact dimer ground state, characterized by a product of singlets forming a columnar dimer phase. The model is analyzed using bond-operator mean-field theory (BOMFT) and the density matrix renormalization group (DMRG). BOMFT reveals three distinct phases: a double-stripe ordered phase, a Néel ordered phase, and a quantum disordered dimerized phase. The critical points for the transitions are $J_1 = -0.81$ (double-stripe to dimerized) and $J_1 = 2.81$ (dimerized to Néel phase). DMRG results corroborate the exact ground state and refine the critical points to $J_1 = -0.79$ and $J_1 = 2.29$ for the respective transitions. Additionally, another transition is identified as the Néel order vanishes for $J_1 > 4.5$. The static spin structure factor further corroborates the nature of the ordered phases.

</details>


### [5] [Hidden Density-Wave Instability in the Trimer Ruthenate Ba4Ru3O10](https://arxiv.org/abs/2602.13443)
*Gang Cao,Hengdi Zhao,Adrienne Bond,Tristan R. Cao,Gabriel Schebel,Arabella Quane,Yifei Ni,Yu Zhang,Logan Wall,Rahul Nandkishore,Pedro Schlottmann,Feng Ye*

Main category: cond-mat.str-el

TL;DR: 在Ba4Ru3O10中发现隐藏的密度波不稳定性，该材料曾被认为是纯反铁磁体，在20K以下表现出独特的非线性输运行为，揭示了一种磁性与集体电子态共存的罕见关联体系。


<details>
  <summary>Details</summary>
Motivation: 探究Ba4Ru3O10在100K处相变对磁场不敏感的本质，挑战其作为纯反铁磁体的传统认知。

Method: 通过晶格参数、输运、热力学和磁化率等综合物性测量，结合14T强磁场和3%铱掺杂实验，系统研究其电子行为。

Result: 确认了电子驱动的密度波不稳定性存在；在20K以下观测到密度波特有的解钉扎、负微分电阻、频率依赖性和赫兹范围慢动力学；这些非线性特征在保持结构完整性的3%铱掺杂下完全消失。

Conclusion: Ba4Ru3O10代表了一种罕见的关联材料体系，其中强钉扎的集体电子态与反铁磁性紧密交织，且电子重构与非线性动力学温度区间明显分离。

Abstract: We report a hidden density-wave instability in the trimer-based ruthenate Ba4Ru3O10, previously regarded as a pure antiferromagnet with a phase transition at TA=100 K. This transition is manifested in lattice parameters, transport, thermodynamics, and magnetic susceptibility, yet remains remarkably insensitive to magnetic fields up to at least 14 T, indicating an electronically driven reconstruction. At much lower temperatures T*= 20 K, charge transport becomes strongly nonlinear, exhibiting distinct depinning thresholds, negative differential resistance, pronounced current- and frequency-dependence, and slow collective dynamics in the Hertz range. While each feature is characteristic of density-wave transport, their simultaneous occurrence in an antiferromagnetic oxide is unprecedented. All nonlinear signatures vanish upon only 3% Ir substitution, which preserves the crystal structure and insulating state, ruling out Joule heating or extrinsic artifacts. The wide separation between the electronic reconstruction at TA and the emergence of nonlinear dynamics at T* identifies Ba4Ru3O10 as a rare correlated system hosting a strongly pinned collective electronic state intertwined with antiferromagnetism.

</details>


### [6] [Evolution of magnetic correlation in doped Hubbard model with altermagnetic spin splitting](https://arxiv.org/abs/2602.13643)
*Yinlong Li,Rana Imran Mushtaq,Ji Liu,Wing Chi Yu,Xiaosen Yang,Cho-Tung Yip,Ho-Kin Tang*

Main category: cond-mat.str-el

TL;DR: 该论文利用约束路径量子蒙特卡洛方法研究二维方晶格Hubbard模型中自旋依赖的次近邻跃迁$t'$产生的自旋分裂如何重塑费米面嵌套和van Hove奇点，揭示磁性不稳定性从半填充时的反铁磁$(π,π)$序，随各向异性增强或掺杂演变为非共线螺旋$(π,q)$序，最终进入条纹与螺旋序共存的短程关联 regime，为在变磁系统中实现螺旋关联提供了可能路径。


<details>
  <summary>Details</summary>
Motivation: 强关联电子体系中变磁自旋分裂对磁关联演化的影响尚不清楚，需要探究自旋分裂如何调控费米面嵌套和van Hove奇点以改变磁不稳定性。

Method: 采用约束路径量子蒙特卡洛方法，计算动量分辨的自旋结构因子，研究二维方晶格Hubbard模型中填充率和$t'/t$对主导磁关联的影响。

Result: 发现磁关联呈现连续演化：从各向同性半填充时的反铁磁$(π,π)$序，到增加自旋各向异性或偏离半填充时出现非共线螺旋$(π,q)$序，最终进入条纹序与螺旋序共存的短程磁关联 regime。

Conclusion: 该工作揭示了变磁系统中实现螺旋磁关联的可行途径，为利用非共线自旋结构开发自旋电子器件提供了理论平台。

Abstract: The evolution of magnetic correlation in strongly correlated electron systems with altermagentic spin splitting remains largely unexplored. Here we investigate how spin splitting generated by spin-dependent next-nearest-neighbor hopping $t'$ reshapes the Fermi surface nesting and van Hove singularities in the two-dimensional square-lattice Hubbard model, leading evolution of magnetic instabilities. Using the constrained-path quantum Monte Carlo method, we find the dominant magnetic correlation as functions of the filling and $t'/t$ by computing the momentum-resolved spin structure factor. The analysis reveals a transition from antiferromagnetic $(π,π)$ order in the isotropic, half-filled system to non-collinear spiral $(π,q)$ order upon increasing the spin-dependent anisotropy or doping away from half-filling, ultimately entering a short-range correlation regime where stripe and spiral correlation coexist. These findings highlight a possible route to realizing spiral correlation in altermagnetic systems, potentially providing a platform for spintronic devices that exploit non-collinear spin textures.

</details>


### [7] [Localized-basis formulation of interacting Hamiltonians in flat topological bands: coherent states and coherent-like states for fractional physics](https://arxiv.org/abs/2602.13698)
*Nobuyuki Okuma*

Main category: cond-mat.str-el

TL;DR: 提出用"类相干态"构建局域化基的统一框架，将量子霍尔效应与陈绝缘体纳入同一理论框架，并验证了ν=1/3填充因子下模型的拓扑简并基态


<details>
  <summary>Details</summary>
Motivation: 拓扑能带中无法构造保持对称性的指数局域化Wannier函数，需为量子霍尔系统和陈绝缘体建立新的局域化基描述方法，以统一处理强关联拓扑物相

Method: 将量子霍尔系统的过完备相干态基扩展至陈能带，定义"类相干态"作为动量空间的波包；基于该基构建ν=1/3填充因子的短程排斥相互作用哈密顿量

Result: (1) 该哈密顿量在量子霍尔系统中具有精确零能拓扑简并基态，可作为分数量子霍尔模型；(2) 数值模拟证实该模型在陈绝缘体中同样存在拓扑简并；(3) 提出Z₂拓扑绝缘体中可定义Kramers简并的类相干态

Conclusion: 建立了统一描述分数量子霍尔系统与分数陈绝缘体的理论框架，该局域化基方法为平带系统中强关联拓扑相研究提供了新途径

Abstract: In topological bands, it is impossible to construct exponentially localized Wannier functions while preserving the symmetries. Instead, in quantum Hall systems, one can define an overcomplete basis of spatially localized coherent states. In this work, we propose a unified framework for understanding the quantum Hall effect and Chern insulators from the perspective of localized bases, by extending the overcomplete basis of coherent states to Chern bands in terms of coherent-like states. Specifically, by representing both coherent states and coherent-like states as wave packets defined on a band, the difference between them can be encoded solely in the functional form of the wave packet in momentum space. Furthermore, for filling factor $ν=1/3$, we define a local repulsive interaction Hamiltonian based on these bases and discuss properties of its ground states. In particular, by relating this Hamiltonian to previously studied models, we show that in quantum Hall systems it possesses exactly zero-energy ground states with topological degeneracy, thereby confirming that it serves as a model for fractional quantum Hall systems. In addition, we numerically verify that the Hamiltonian possesses topological degeneracy for representative Chern insulator models. An advantage of this formulation is that it allows fractional quantum Hall systems and various fractional Chern insulator systems to be discussed within a unified framework using the same Hamiltonian form. In addition, we discuss that coherent-like states can also be defined in $\mathbb{Z}_2$ topological insulators. Corresponding to the fermionic time-reversal symmetry of the system, Kramers-degenerate coherent-like states can be naturally defined. The localized basis constructed from coherent-like states is expected to be useful for describing strongly correlated topological phases in flat-band systems.

</details>


### [8] [Interplay between non-Fermi liquid and non-Hermiticity: A multi-method study of non-Hermitian multichannel Kondo model](https://arxiv.org/abs/2602.13749)
*Wei-Zhu Yi,Yun Chen,Jun-Jun Pang,Hong Chen,Baigeng Wang,Rui Wang*

Main category: cond-mat.str-el

TL;DR: A multi-method study of non-Hermitian multichannel Kondo problems reveals exotic quantum phenomena, including Yu-Shiba-Rusinov-like states and anomalous conductance behavior not seen in conventional Hermitian systems.


<details>
  <summary>Details</summary>
Motivation: To explore exotic collective quantum phenomena arising from the combination of non-Fermi liquid and non-Hermitian physics using the non-Hermitian multichannel Kondo problem as a prototypical model.

Method: Multi-method approach combining Bethe ansatz, non-Hermitian numerical renormalization group (NRG), and boundary conformal field theory (BCFT), with a proposed experimental setup realizing exact channel symmetry and controllable PT symmetry.

Result: Bethe ansatz identifies Yu-Shiba-Rusinov-like states; NRG reveals signatures in strong non-Hermiticity PT-asymmetric models; BCFT uncovers anomalous temperature-dependent Kondo conductance in PT-symmetric models beyond conventional Hermitian systems.

Conclusion: The study successfully characterizes exotic quantum phenomena in non-Hermitian multichannel Kondo systems, revealing both universal features and novel non-Hermitian-specific behaviors.

Abstract: Non-Hermitian multichannel Kondo problems host both non-Fermi liquid and non-Hermitian physics, which provide a prototypical model to explore exotic collective quantum phenomena driven by the two different ingredients. Here, we first propose an experimental setup that realizes this model with exact channel symmetry as well as a controllable PT symmetry. Then, we perform a multi-method study of this model, focusing on the low-energy spectrum, the thermodynamic quantities, and the transport properties associated with different fixed points. Using the Bethe ansatz approach, we identify existence of the Yu-Shiba-Rusinov-like state previously found in the non-Hermitian single-channel Kondo model. Then, based on non-Hermitian numerical renormalization group calculations, we reveal clear numerical signatures of the Yu-Shiba-Rusinov state emerging in the relatively strong non-Hermiticity regime of the PT-asymmetric model. Furthermore, our boundary conformal field theory, which is found to be applicable for the PT-symmetric model, uncovers an anomalous temperature dependence of the Kondo conductance, which is beyond conventional Hermitian Kondo systems.

</details>


### [9] [Non-Hermiticity Induced Universal Anomalies in Kondo Conductance](https://arxiv.org/abs/2602.13803)
*Wei-Zhu Yi,Yun Chen,Jun-Jun Pang,Hong Chen,Baigeng Wang,Rui Wang*

Main category: cond-mat.str-el

TL;DR: 该研究揭示了强关联非费米液体与非厄米耗散效应相互作用下产生的新型量子输运现象，发现电导率随温度升高而反常上升的普适行为，拓展了传统近藤效应的理论框架。


<details>
  <summary>Details</summary>
Motivation: 探索强关联体系中非费米液体行为与开放系统非厄米性之间的非平庸相互作用，研究这种交织效应可能产生的新奇量子现象。

Method: 提出可实现非厄米多通道近藤模型的实际物理体系，通过理论分析识别PT对称性下的弱耦合定域矩固定点和强耦合非费米液体固定点。

Result: 发现两类固定点均受非厄米效应显著影响，揭示出普适的非传统近藤电导行为；特别观察到电导率随温度升高而反常上升的现象，其源于非费米液体与非厄米性的独特相互作用。

Conclusion: 鉴定出一类由强关联与耗散效应共同驱动、此前未被认知的输运现象，为理解开放量子体系中的量子临界行为提供了新视角。

Abstract: Strong correlation, when combined with dissipation in open systems, can lead to a variety of exotic quantum phenomena. Here, we study nontrivial interplays between non-Fermi liquid behaviors emerging from strong correlation and non-Hermiticity arising from open systems. We propose a practical physical setup that realizes a non-Hermitian multichannel Kondo model. We identify a weak-coupling local moment fixed point and a strong-coupling non-Fermi liquid fixed point under PT symmetry, both are enriched by the non-Hermitian effect. Remarkably, universal unconventional Kondo conductance behaviors are found for both cases, which are distinct from all previously studied Kondo systems. Particularly, we show that an anomalous upturn of conductance could take place with increasing the temperature, originating from the interplay between non-Fermi liquid and non-Hermiticity. Our results identify a novel class of transport phenomena unrecognized before, driven by intertwined effects of correlation and dissipation.

</details>


### [10] [Exchange interactions and finite-temperature magnetism in (111)-oriented (LaMnO$_3$)$_{2n}$|(SrMnO$_3$)$_n$ superlattices](https://arxiv.org/abs/2602.14133)
*Shivalika Sharma,Julio do Nascimento,Imran Ahamed,Fabrizio Cossu,Heung-Sik Kim,Igor Di Marco*

Main category: cond-mat.str-el

TL;DR: 该研究通过第一性原理和原子自旋动力学模拟，探究了(111)取向(LaMnO₃)₂ₙ|(SrMnO₃)ₙ超晶格的磁性行为，发现其具有稳定的半金属铁磁性，由e_g电子双交换机制驱动，且较薄超晶格（n=2,4）的居里温度与La₂/₃Sr₁/₃MnO₃相当，而厚度增加时会出现两相分离现象。


<details>
  <summary>Details</summary>
Motivation: 理解氧化物异质结构中新兴磁相和临界行为，特别是(LaMnO₃)₂ₙ|(SrMnO₃)ₙ超晶格的磁交换机制与相变温度，为自旋电子学应用提供理论基础。

Method: 采用第一性原理计算分析磁交换作用，结合原子自旋动力学多尺度模拟，研究不同厚度（n=2,4,6）超晶格的磁响应及温度依赖性。

Result: 1. 所有超晶格均呈现全层覆盖的稳健半金属铁磁性<br>2. 八面体倾斜模式对磁性影响微弱，但决定Jahn-Teller畸变存在与否<br>3. 铁磁性由e_g电子双交换机制主导，t₂g电子超交换产生反铁磁抵消作用<br>4. 薄超晶格（n=2,4）居里温度与La₂/₃Sr₁/₃MnO₃相当，厚样品出现SrMnO₃区先失序的两相行为

Conclusion: 揭示了厚度依赖的磁相变机制：薄超晶格保持均匀铁磁有序，厚样品在升温时发生结构-电子-磁性的协同相变，SrMnO₃区先失去长程有序导致两相分离，为氧化物异质结构设计提供关键温控依据。

Abstract: We present a first-principles investigation of magnetic exchange interactions and critical behavior in (111)-oriented (LaMnO$_3$)$_{2n}$|(SrMnO$_3$)$_n$ superlattices for $n=2,4,6$. For all superlattices under investigation, we find robust half-metallic ferromagnetism extending across all the layers of both component regions. Changing octahedral tilt patterns is found to have negligible effects on the magnetic properties, despite determining the presence or absence of small Jahn-Teller distortions. The analysis of the response of the magnetic coupling to a variation of the Coulomb interaction parameters demonstrates that ferromagnetism is driven by a double-exchange mechanism involving itinerant $e_g$ electrons, while its final strength is hampered by antiferromagnetic contributions due to the superexchange of localized $t_{2g}$ electrons. Multi-scale simulations based on atomistic spin dynamics show that the thinnest superlattices, $n=2,4$, possess an ordering temperature that is at least comparable to that of La$_{2/3}$Sr$_{1/3}$MnO$_3$. Conversely, as thickness increases, a two-phase behavior emerges, where the SrMnO$_3$ region loses long-range order faster than the LaMnO$_3$ region. While the global ordering temperature increases together with thickness, we argue that the high-temperature regime for the observed two-phase behavior is not representative of the real physical system, which will undergo a combined electronic, magnetic and structural phase transition as soon as the long-range order is lost inside the SrMnO$_3$ region. This study provides insights into the emergent magnetic phases and transition temperatures relevant to oxide heterostructures.

</details>


### [11] [Composite Boson Theory of Fractional Chern Insulators](https://arxiv.org/abs/2602.14184)
*Guangyu Yu,Zheng Zhu*

Main category: cond-mat.str-el

TL;DR: 本文提出了一个理解分数量子霍尔绝缘体的实空间理论框架，将复杂的多体问题简化为复合玻色子模型，通过构造最大局域化基矢并定义稳定FCI的实空间判据，为拓扑序相的设计提供了新基础


<details>
  <summary>Details</summary>
Motivation: 传统对分数陈绝缘体的理解主要基于能带拓扑和量子几何，缺乏实空间的直观物理图像。作者旨在建立一个基于复合玻色子的实空间理论框架，以桥接连续体系和晶格体系中分数量子霍尔效应的不同范式

Method: 1. 构造无需连续旋转对称性的陈能带最大局域化径向有序基矢；2. 建立实空间组织原理：稳定FCI出现在被排除轨道使双体相互作用能最大时；3. 在Haldane模型中进行数值验证

Result: 1. 在Haldane模型中观察到复合玻色子形成；2. 提出的判据能可靠表征FCI相；3. 成功桥接了连续和晶格体系的分数量子霍尔效应；4. 为不同关联相提供了统一的实空间解释

Conclusion: 复合玻色子框架为诊断和设计不同平台上阿贝尔和非阿贝尔拓扑有序相建立了理论基础，提供了更直观的物理理解方法

Abstract: The understanding of fractional Chern insulators (FCIs) has been deeply guided by band topology and quantum geometry. Here, we introduce a real-space theoretical framework in which FCIs are understood in terms of composite bosons, local objects consisting of electrons bound to their energetically excluded surrounding orbitals. The central element of our framework is the construction of a radially ordered set of maximally localized basis for Chern bands without requiring continuous rotational symmetry. Within this basis, the complex many-body problem simplifies to a real-space organizing principle: a stable FCI occurs if the orbitals excluded around central electrons are those maximizing the two-body interaction energy. We validate this with direct numerical evidence for composite boson formation in the Haldane model, demonstrating that our criterion reliably characterizes FCIs. Importantly, our analysis illustrates that the composite boson framework bridges the fractional quantum Hall effect in continuum and lattice paradigms, providing a unified and intuitive real-space interpretation for distinct correlated phases. It thus establishes a foundation for diagnosing and guiding the design of both Abelian and non-Abelian topologically ordered phases across distinct platforms.

</details>


### [12] [Magnetic fluctuations driven by quantum geometry](https://arxiv.org/abs/2602.14511)
*Makoto Shimizu,Chang-guen Oh,Youichi Yanase*

Main category: cond-mat.str-el

TL;DR: This paper uses quantum distance to decompose magnetic susceptibility into band dispersion and quantum geometric contributions, revealing that quantum geometry dominates magnetic fluctuations in LaFeAsO (enhancing stripe antiferromagnetism) and Pb₉Cu(PO₄)₆O (suppressing antiferromagnetism to favor ferromagnetism), providing a quantitative framework to distinguish band-structure and wavefunction-geometry effects in multi-band systems.


<details>
  <summary>Details</summary>
Motivation: To resolve the ambiguity in multi-orbital systems where band-structure and quantum geometric effects are often conflated as "multi-orbital effects," by rigorously separating their contributions to magnetic fluctuations.

Method: Applying a quantum-distance-based decomposition of magnetic susceptibility in the non-interacting limit to two material case studies (LaFeAsO and Pb₉Cu(PO₄)₆O), isolating geometric contributions from band dispersion effects.

Result: In LaFeAsO, quantum geometry drives stripe-type antiferromagnetic fluctuations; in Pb₉Cu(PO₄)₆O, it suppresses antiferromagnetism and stabilizes ferromagnetic fluctuations—demonstrating geometry's dominant role over band dispersion in both systems.

Conclusion: Quantum geometry is essential for governing magnetic fluctuations in multi-band systems, offering a quantitative framework to disentangle wavefunction-geometry effects from band-structure effects, crucial for understanding correlated quantum materials.

Abstract: Using quantum distance, magnetic susceptibility in the non-interacting limit can be rigorously split into two contributions: one arising solely from band dispersion, while the other stems from quantum geometric contributions. In this Letter, we apply this decomposition to two materials, LaFeAsO and Pb$_9$Cu(PO$_4$)$_6$O, and demonstrate that their dominant magnetic fluctuations originate from the geometric contribution. In LaFeAsO, stripe-type antiferromagnetic fluctuations arise primarily from quantum geometry, while in Pb$_9$Cu(PO$_4$)$_6$O the geometric term suppresses antiferromagnetic fluctuations and stabilizes ferromagnetic fluctuations. Our findings highlight the essential role of quantum geometry in governing magnetic fluctuations in multi-band systems, and provide a unique and quantitative framework to disentangle band-structure and wavefunction-geometry effects that have often been discussed collectively as multi-orbital effects.

</details>


### [13] [Magnetic excitations in the Kitaev material Na$_2$IrO$_3$ studied by neutron scattering](https://arxiv.org/abs/2602.14563)
*Alexandre Bertin,Hengdi Zhao,Gang Cao,Andrea Piovano,Paul Steffens,Alexandre Ivanov,Markus Braden*

Main category: cond-mat.str-el

TL;DR: 通过非弹性中子散射实验，首次在Na₂IrO₃单晶中观测到低能磁振子色散，发现其1.7 meV能隙源于反铁磁锯齿状结构的边界效应，但不存在α-RuCl₃中观测到的铁磁特征激发，证实Na₂IrO₃具有反铁磁海森堡近邻交换作用而非铁磁Kitaev作用


<details>
  <summary>Details</summary>
Motivation: 探究Na₂IrO₃作为Kitaev物理候选材料的低能磁激发特性，厘清其与姐妹化合物α-RuCl₃在磁相互作用机制上的本质差异，验证微观理论模型中交换作用符号（铁磁/反铁磁）的关键作用

Method: 采用大尺寸共生长Na₂IrO₃单晶阵列进行非弹性中子散射实验，精确测量低能磁振子色散行为，并与α-RuCl₃的实验结果进行系统对比

Result: 测得磁振子能隙为1.7(1) meV，其起源与α-RuCl₃类似（反铁磁锯齿状结构边界效应）；但实验未发现铁磁特征的低能激发，这与α-RuCl₃显著不同；结果支持Na₂IrO₃存在反铁磁海森堡近邻交换作用（而非α-RuCl₃中的铁磁作用）的微观模型

Conclusion: Na₂IrO₃与α-RuCl₃虽均表现键向各向异性，但Kitaev与海森堡相互作用的相对符号差异导致偏离初始Kitaev模型的不同路径；低能铁磁涨落不能作为铁磁Kitaev相互作用的判据，为理解Kitaev材料磁学机制提供了关键实验依据

Abstract: Inelastic neutron scattering experiments with a large set of comounted Na$_2$IrO$_3$ crystals reveal the low-energy magnon dispersion in this candidate material for Kitaev physics. The magnon gap amounts to 1.7(1) meV and can be interpreted similarly to the sister compound $α$-RuCl$_{3}$ to stem from the zone boundaries in the antiferromagnetic zigzag structure. The neutron experiments find no evidence for low-energy excitations with ferromagnetic character, which contrasts to the findings in $α$-RuCl$_{3}$. Our results are consistent with a recently proposed microscopic model that involves an antiferromagnetic Heisenberg nearest-neighbor exchange in Na$_2$IrO$_3$ in contrast to the ferromagnetic one considered for $α$-RuCl$_{3}$. Although the magnetic response shows the signatures of bond-directional anisotropy in both materials the different relative signs of Kitaev and Heisenberg interaction result in different deviations from the initial Kitaev model. Low-energy ferromagnetic fluctuations cannot be considered as a fingerprint of ferromagnetic Kitaev interaction.

</details>


### [14] [Non-commutative Dynamic Approaches to the Kibble-Zurek Scaling Limit with an Initial Gapless Order](https://arxiv.org/abs/2602.14599)
*Zhe Wang,Chengxiang Ding,Dongxu Liu,Fuxiang Li,Zheng Yan,Shuai Yin*

Main category: cond-mat.str-el

TL;DR: This paper reveals non-commutative finite-time scaling behavior in quantum critical dynamics: Kibble-Zurek scaling (m²∝R^(2β/νr)) is inaccessible for large tuning rates (R) and medium system sizes (L), but accessible for large L with moderate R, due to memory effects in gapless ordered phases.


<details>
  <summary>Details</summary>
Motivation: To resolve the fundamental challenge of dynamical scaling from gapless ordered phases to quantum critical points (QCP), where existing Kibble-Zurek (KZ) theory lacks understanding of finite-size effects and non-commutative scaling limits.

Method: Studied driven critical dynamics in the bilayer Heisenberg model across QCP, analyzing finite-time scaling of order parameter (m²) under varying tuning rates (R) and system sizes (L), with focus on KZ scaling limit (RL^r≫1).

Result: Discovered non-commutative scaling: KZ scaling region (m²∝R^(2β/νr)) is unreachable when R is large with finite L, but reachable when L is large with moderate R. Attribute this to memory effects from finite-size corrections in the initial gapless ordered phase, causing persistent m² dependence on L even at large R. Similar corrections found in imaginary-time relaxation.

Conclusion: Establishes essential extension of nonequilibrium scaling theory for gapless ordered initial states, demonstrating that non-commutative finite-size effects fundamentally alter KZ scaling predictions and must be incorporated into quantum critical dynamics frameworks.

Abstract: Nonequilibrium many-body physics is one of the core problems in modern physics, while the dynamical scaling from a gapless phase to the critical point is a most important challenge with very few knowledge so far. In the driven dynamics with a tuning rate $R$ across the quantum critical point (QCP) of a system with size $L$, the finite-time scaling shows that the square of the order parameter $m^2$ obeys a simple scaling relation $m^2\propto R^{2β/νr}$ in the Kibble-Zurek (KZ) scaling limit with $RL^r\gg1$. Here, by studying the driven critical dynamics from a gapless ordered phase in the bilayer Heisenberg model, we unveil that the approaches to the scaling region dominated by the KZ scaling limit with $RL^r\gg1$ are {\it non-commutative}: this scaling region is inaccessible for large $R$ and finite medium $L$, while merely accessible for large $L$ and moderately finite $R$. We attribute this to the memory effect induced by the finite-size correction in the gapless ordered phase. This non-commutative property makes $m^2$ still strongly depends on the system size and deviates from $m^2\propto R^{2β/νr}$ even for large $R$. We further show that a similar correction applies to the imaginary-time relaxation dynamics. Our results establish an essential extension of nonequilibrium scaling theory with a gapless ordered initial state.

</details>


### [15] [The distinction of time-reversal-like degeneracy by electronic transport in a new compound](https://arxiv.org/abs/2602.14711)
*Yi-Yan Wang,Ping Su,Kai-Yuan Hu,Yi-Ran Li,Na Li,Ying Zhou,Dan-Dan Wu,Yan Sun,Qiu-Ju Li,Xia Zhao,Hui Liang,Xue-Feng Sun*

Main category: cond-mat.str-el

TL;DR: 发现新型化合物Ce$_3$MgBi$_5$，揭示其隐藏的时间反演类简并态。在1/2磁化平台处观察到磁输运滞后而磁化无滞后现象，表明简并态具有相同磁化但不同输运性质，晶体结构可能对时间反演类操作产生屏蔽效应。


<details>
  <summary>Details</summary>
Motivation: 探索利用电子输运性质识别和区分阻挫磁体系统中隐藏对称性的新方法。

Method: 通过磁化强度、磁阻和霍尔电阻的磁场依赖测量，观察滞后行为，并与HoAgGe对比分析晶体结构效应。

Result: Ce$_3$MgBi$_5$是具有扭曲kagome晶格的反铁磁体，存在分数磁化平台；在1/2平台处磁阻和霍尔电阻滞后但磁化无滞后；确认时间反演类简并态存在；晶体结构对时间反演类操作有屏蔽效应。

Conclusion: Ce$_3$MgBi$_5$为研究阻挫磁体中隐藏对称性提供了新范例，证明电子输运性质可区分简并态，晶体结构在对称性识别中起关键作用。

Abstract: We report the discovery of a new compound, Ce$_3$MgBi$_5$, and reveal the hidden time-reversal-like degenerate states within it. Ce$_3$MgBi$_5$ is an antiferromagnet with the distorted kagome lattice of Ce atoms, in which several fractional magnetization plateaus emerge with the increase of magnetic field. At the 1/2 magnetization plateau, obvious hysteresis has been observed in the magnetoresistance and Hall resistivity during the rise and fall of the magnetic field. However, hysteresis vanishes in the corresponding measurements of magnetization, indicating the existence of degenerate states with the same net magnetization but different electronic transport properties. The degenerate states can be connected by the time-reversal-like operation. In addition, by comparing with HoAgGe, it is suggested that the special crystal structure in Ce$_3$MgBi$_5$ may have a shielding effect on the time-reversal-like operation, thereby affecting the distinction of degenerate states. Our work establishes Ce$_3$MgBi$_5$ as an example of utilizing electronic transport properties to identify and distinguish hidden symmetries in frustrated magnetic systems.

</details>


### [16] [Variational preparation and characterization of chiral spin liquids in quantum circuits](https://arxiv.org/abs/2602.14769)
*Zi-Yang Zhang,Donghoon Kim,Ji-Yao Chen*

Main category: cond-mat.str-el

TL;DR: Proposes a VQE-based method with tangent space excitation ansatz to realize and characterize chiral topological phases (chiral spin liquids) in quantum circuits, validated on Kitaev honeycomb and square lattice models.


<details>
  <summary>Details</summary>
Motivation: Chiral topological phases like chiral spin liquids remain less explored in quantum circuits compared to non-chiral models, despite existing theoretical and experimental work on non-chiral topological orders.

Method: Uses variational quantum eigensolver (VQE) to prepare ground states, combined with tangent space excitation ansatz to detect topological signatures (ground state degeneracy, chiral edge modes) in quantum circuits.

Result: Successfully captured topological properties in Kitaev honeycomb model (matching exact solutions across all sectors) and non-exactly solvable square lattice chiral spin liquid model, demonstrating robustness even without prior knowledge of topological sectors.

Conclusion: The approach reliably characterizes chiral topological order in quantum circuits, offering a practical tool for exploring complex topological phases beyond exactly solvable models.

Abstract: Quantum circuits have been shown to be a fertile ground for realizing long-range entangled phases of matter. While various quantum double models with non-chiral topological order have been theoretically investigated and experimentally implemented, the realization and characterization of chiral topological phases have remained less explored. Here we show that chiral topological phases in spin systems, i.e., chiral spin liquids, can be prepared in quantum circuits using the variational quantum eigensolver (VQE) framework. On top of the VQE ground state, signatures of the chiral topological order are revealed using the recently proposed tangent space excitation ansatz for quantum circuits. We show that, both topological ground state degeneracy and the chiral edge mode can be faithfully captured by this approach. We demonstrate our approach using the Kitaev honeycomb model, finding excellent agreement of low-energy excitation spectrum on quantum circuits with exact solution in all topological sectors. Further applying this approach to a non-exactly solvable chiral spin liquid model on square lattice, the results suggest this approach works well even when the topological sectors are not exactly known.

</details>


### [17] [Strongly correlated Josephson junction: proximity effect in the single-layer Hubbard model](https://arxiv.org/abs/2602.14796)
*Don Rolih,Rok Žitko*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the proximity effect in the Hubbard model coupled to BCS superconductors describing a single-layer strongly correlated electron system in a phase-biased Josephson junction. We find two distinct gapped solutions, one Mott-like insulating (M-phase) and one proximitized superconducting phase (S-phase), separated by first-order transition with hysteresis. In the M-phase the large correlation charge gap strongly suppresses the critical current, while the S-phase behaves as a $0$-junction, with a proximitized gap that closes for $φ=π$ to yield a correlated metal. Phase bias and junction transparency can thus serve as tuning knobs to switch between conducting and insulating regimes. Working within the dynamical mean field theory using the numerical renormalization group as the impurity solver, we associate M- and S-phase solutions with the doublet and singlet fixed points of the underlying superconducting Anderson impurity problem. We obtain detailed insight into the spectral structure on all energy scales. In the M-phase, the self-energy has sub-gap resonances symmetrically located around the Fermi level resulting from the splitting of the ''mid-gap pole'' found in Mott insulators; this structure accounts for phase insensitivity.

</details>


### [18] [Electron-phonon coupling in EuAl4 under hydrostatic pressure](https://arxiv.org/abs/2602.14884)
*A. S. Sukhanov,S. Gebel,A. N. Korshunov,N. D. Andriushin,M. S. Pavlovskii,Y. Gao,K. M. Moya,K. Allen,E. Morosan,M. C. Rahn*

Main category: cond-mat.str-el

TL;DR: 利用金刚石压砧高压技术和非弹性X射线散射，研究EuAl4中电子-声子耦合对电荷密度波的调控机制。


<details>
  <summary>Details</summary>
Motivation: 揭示EuAl4电荷密度波转变的微观机制，特别是动量依赖电子-声子耦合的关键作用，并探索通过压力调控量子材料电荷有序的新途径。

Method: 采用金刚石压砧装置施加高静水压，结合非弹性X射线散射技术，在温度-压力相图中系统测量EuAl4的声子色散和电子-声子耦合强度。

Result: 实验发现驱动EuAl4电荷密度波转变的动量依赖电子-声子耦合在高压下发生重整化并被显著抑制。

Conclusion: 动量依赖电子-声子耦合是EuAl4中电荷密度波形成的决定性因素，外部压力为该类量子材料中电荷有序的调控提供了有效手段。

Abstract: In the intermetallid rare-earth tetragonal EuAl4 system, competing itinerant exchange mechanisms lead to a complex magnetic phase diagram, featuring a centrosymmetric skyrmion lattice. Previous inelastic x-ray scattering (IXS) experiments revealed that the incommensurate charge-density wave (CDW) transition in EuAl4 (TCDW = 142 K) is driven by momentum-dependent electron-phonon coupling (EPC). We present the results of IXS under high hydrostatic pressure induced by diaond anvils and show how the EPC in EuAl4 is renormalized and suppressed in the material's temperature-pressure phase diagram. Our findings highlight the crucial role of momentum-dependent EPC in the formation of the CDW in EuAl4 and provide further insights into how external pressure can be used to tune charge ordering in quantum materials.

</details>


### [19] [Competing states in the $S=1/2$ triangular-lattice $J_1$-$J_2$ Heisenberg model: a dynamical density-matrix renormalization group study](https://arxiv.org/abs/2602.14892)
*Shengtao Jiang,Steven R. White,Steven A. Kivelson,Hong-Chen Jiang*

Main category: cond-mat.str-el

TL;DR: 针对三角晶格J1-J2海森堡反铁磁体，利用改进的动态DMRG方法，在周长为6-9的圆柱上发现两种不同的低能态：一种与Dirac量子自旋液体一致，另一种则类似于磁有序态，表明可能为弱磁序非QSL或接近相变的有隙QSL。


<details>
  <summary>Details</summary>
Motivation: 前人研究对J2中间区间非磁性基态相的本质存在分歧：是有隙Z2量子自旋液体、无能隙Dirac QSL，还是弱对称破缺相。

Method: 采用改进的动态密度矩阵重整化群方法，在周长为6至9的圆柱几何结构上进行计算。

Result: 发现了两个不同的变形态：能量较高的态与Dirac QSL一致；能量较低的态在静态和动态性质上与J2=0的磁有序态定性相似。

Conclusion: 低能态可能代表弱磁有序的非QSL，或是接近向有序态连续相变的邻近有隙QSL。

Abstract: Previous studies of the $S=1/2$ triangular-lattice $J_1$--$J_2$ Heisenberg antiferromagnet have inferred the existence of a non-magnetic ground-state phase for an intermediate range of $J_2$, but disagree concerning whether it is a gapped $\mathbb{Z}_2$ quantum spin liquid (QSL), a gapless (Dirac) QSL, or a weakly symmetry-broken phase. Using an improved dynamical density-matrix renormalization group method, we investigate the relevant intermediate $J_2$ regime for cylinders with circumferences from 6 to 9. Depending on the initial state and boundary conditions, we find two {\it distinct} variational states. The higher energy state is consistent with a Dirac QSL. In the lower-energy state, both the static and dynamical properties are qualitatively similar to the magnetically ordered state at $J_2=0$, suggestive of either a weakly magnetically ordered non-QSL or a gapped QSL proximate to a continuous transition to such an ordered state.

</details>


### [20] [Nematostriction in frustrated two-dimensional Heisenberg models](https://arxiv.org/abs/2602.14964)
*Olav F. Syljuåsen,Jens Paaske*

Main category: cond-mat.str-el

TL;DR: 使用向列键理论研究Heisenberg $J_1$-$J_2$模型，发现磁弹性耦合可使方形晶格向列相变从连续转为弱一级，而三角晶格始终保持不连续相变。


<details>
  <summary>Details</summary>
Motivation: 研究有限晶格压缩性和键长依赖磁交换作用下，磁弹性耦合对向列相变温度和性质的调控机制。

Method: 采用向列键理论（Nematic Bond Theory），一种图式自洽方法。

Result: 磁弹性耦合重整化临界温度并改变声子谱，且能根本改变相变性质：方形晶格中相变从连续变为弱一级（超过临界耦合阈值），而三角晶格中无论耦合强度如何均保持不连续相变。

Conclusion: 磁弹性反馈对相变性质有决定性影响，晶格几何结构是决定相变行为的关键因素。

Abstract: We investigate the nematic phase transition in the Heisenberg $J_1$-$J_2$-model on square and triangular lattices, accounting for finite lattice compressibility and bond-length-dependent magnetic exchange. Using Nematic Bond Theory, a diagrammatic self-consistent method, we study the nematostriction that happens when the onset of nematic order in the spin-system drives a concomitant structural phase transition. We analyze the mechanisms by which the magnetoelastic couplings renormalize the critical temperature and modify the phonon spectrum. The magnetoelastic feeback can also alter fundamentally the nature of the phase transition. Specifically, on the square lattice, the transition shifts from continuous to weakly first-order (discontinuous) beyond a critical magnetoelastic coupling threshold. Conversely, on the triangular lattice, the transition remains discontinuous regardless of coupling strength.

</details>


### [21] [Controlled Theory of Skyrmion Chern Bands in Moiré Quantum Materials: Quantum Geometry and Collective Dynamics](https://arxiv.org/abs/2602.15016)
*Yi-Hsien Du*

Main category: cond-mat.str-el

TL;DR: 该论文提出了一个关于moiré量子材料中天空子Chern带的可控理论，通过精确的SU(2)变换和Schrieffer-Wolff展开，揭示了由伪自旋纹理产生的涌现规范场和拓扑动力学，为实验提供了可观测的理论预言。


<details>
  <summary>Details</summary>
Motivation: 近期实验在moiré量子材料中观测到无需外磁场即可实现的量子化霍尔态，这激发了基于平滑moiré周期性伪自旋纹理的连续介质机制研究需求。

Method: 通过精确的局部SU(2)变换揭示涌现的非阿贝尔规范场；对大分支劈裂情况采用算符级别的Schrieffer-Wolff展开，获得单分支哈密顿量及系统重整化的物理算符；构建基于平均涌现场的朗道能级表示；并进一步推导天空子晶体有效场论。

Result: 主导动力学由U(1)贝利联络决定，其通量由天空子密度设定；受控的非绝热修正由纹理的实空间量子几何张量固定；moiré周期调制导致了Umklapp分辨的Girvin-MacDonald-Platzman动力学变形和超出拓扑下限的过量光学量子权重；有效场论包含普适的贝利相位项和非对易磁声子。

Conclusion: 该理论结果为扭转过渡金属二硫化物同质双层和六方氮化硼对齐的菱面体石墨烯体系提供了实验可探测的标志性预言。

Abstract: Recent experiments in moiré quantum materials exhibit quantized Hall states without an external magnetic field, motivating continuum mechanisms based on smooth moiré-periodic pseudospin textures. We present a controlled theory of skyrmion Chern bands generated by such textures. An exact local $SU(2)$ transformation reveals an emergent non-Abelian gauge field; for large branch splitting we perform an operator-level Schrieffer-Wolff expansion, yielding a single-branch Hamiltonian together with systematically dressed physical operators that define the projected interacting theory beyond strict adiabaticity. The leading dynamics is governed by a $U(1)$ Berry connection whose flux is set by the skyrmion density, while controlled non-adiabatic corrections are fixed by the texture's real-space quantum geometric tensor. In a Landau-level representation built from the averaged emergent field, moiré-periodic modulations induce Umklapp-resolved deformations of Girvin-MacDonald-Platzman kinematics and microscopic sources of excess optical quantum weight above the topological lower bound. Assuming a gapped Hall phase, we further derive a skyrmion-crystal effective field theory with a universal Berry-phase term and a noncommutative magnetophonon. Our results provide experimentally accessible signatures for twisted transition-metal dichalcogenide homobilayers and rhombohedral graphene aligned with hexagonal boron nitride.

</details>


### [22] [Majorana Signatures in Planar Tunneling through a Kitaev Spin Liquid](https://arxiv.org/abs/2602.15020)
*Weiyao Li,Vitor Dantas,Wen-Han Kao,Natalia B. Perkins*

Main category: cond-mat.str-el

TL;DR: 提出平面隧穿装置探测手性Kitaev自旋液体中的空位束缚马约拉纳模，通过测量非弹性隧穿电导实现分数化激发的实验探测


<details>
  <summary>Details</summary>
Motivation: 马约拉纳模在拓扑量子计算中具有应用潜力，但现有探测手段（如STM）存在空间分辨率限制和信号微弱问题，亟需更有效的探测方案

Method: 设计平面隧穿几何结构，将非弹性隧穿电导与实空间自旋关联函数直接关联，通过相干叠加多个空位信号增强探测灵敏度

Result: 发现自旋空位产生局域化马约拉纳态，在零偏压附近形成尖锐特征峰，与体自旋激发连续谱明显分离；平面构型比STM测量信号增强，降低空间分辨率要求

Conclusion: 该方案为Kitaev材料中马约拉纳激发的实验探测提供了现实可行的可扩展途径，为拓扑量子计算研究奠定实验基础

Abstract: We propose a planar tunneling setup to probe vacancy-bound Majorana modes in the chiral Kitaev spin liquid. In this geometry, the inelastic tunneling conductance can be expressed directly in terms of real-space spin correlations, establishing a link between measurable spectra and the underlying fractionalized excitations. We show that spin vacancies host localized Majorana states that generate sharp near-zero-bias features, well separated from the continuum of bulk spin excitations. Compared to local STM measurements, the planar configuration naturally enhances the signal by coherently summing over multiple vacancies, reducing spatial resolution requirements. Our results demonstrate a realistic and scalable route to detect Majorana excitations in Kitaev materials.

</details>


### [23] [3d Conformal Field Theories via Fuzzy Sphere Algebra](https://arxiv.org/abs/2602.15025)
*Luisa Eck,Zhenghan Wang*

Main category: cond-mat.str-el

TL;DR: 该研究分析了模糊球面模型中的密度模式代数，验证了其满足Jacobi恒等式，揭示了该模型在两种热力学极限下的行为（局域平面极限给出模糊平面，交换极限给出普通球面），并在两电子系统中明确构造了共形代数so(3,2)的表示，通过so(3)等变余积推广到更大系统，发现该结构与临界模糊球面哈密顿量的热力学极限存在结构性失配。


<details>
  <summary>Details</summary>
Motivation: 模糊球面模型被推测可在自旋费米子小系统中实现三维共形场论，但其为何如此有效仍不完全清楚。

Method: 从投影到最低朗道能级的电子密度算符构建哈密顿量，分析密度模式的代数结构并验证Jacobi恒等式，研究热力学极限，寻找共形代数so(3,2)的表示。

Result: 密度模式代数满足Jacobi恒等式；存在两个热力学极限：局域平面极限产生模糊平面，交换极限产生普通球面；平面极限下高角动量模式恢复Girvin-MacDonald-Platzman代数；交换极限下低角动量模式变为半经典；在两电子系统中明确构造了so(3,2)共形代数表示；通过so(3)等变余积将表示推广到更大系统。

Conclusion: so(3)等变余积将一个表示分裂为张量积的结构，与临界模糊球面哈密顿量的热力学极限存在结构性失配，这可能解释了模糊球面模型有效性的深层原因。

Abstract: Fuzzy sphere models conjecturally realize 3d CFTs in small systems of spinful fermions, but why they work so well is still not fully understood. Their Hamiltonians are built from electron density operators projected to the lowest Landau Level. We analyze the algebra of the density modes and verify that it satisfies the Jacobi identity. The fuzzy sphere geometry admits two thermodynamic limits: a local planar limit yielding the fuzzy plane, and a commutative limit yielding an ordinary sphere. In the planar limit, high-angular-momentum modes recover the Girvin-MacDonald-Platzman algebra, whereas in the commutative limit the low-angular-momentum modes become semiclassical. We further find an explicit representation of the conformal algebra so(3,2) in the minimal two-electron system and extend it to larger systems via an so(3) equivariant coproduct. Because the coproduct splits one so(3) representation into a tensor product, it is structurally mismatched with the thermodynamic limit of critical fuzzy sphere Hamiltonians.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [24] [Auxiliary field quantum Monte Carlo at the basis set limit: application to lattice constants](https://arxiv.org/abs/2602.14923)
*Moritz Humer,Martin Schlipf,Zoran Sukurma,Sajad Bazrafshan,Georg Kresse*

Main category: physics.comp-ph

TL;DR: Implemented plane-wave AFQMC in VASP using PAW formalism with exact overlap inversion, achieving cubic scaling and 0.14% error in lattice constants for C/BN/BP/Si by correcting MP2/RPA limitations.


<details>
  <summary>Details</summary>
Motivation: To address systematic errors in MP2 (lack of long-range screening) and RPA (missing higher-order exchange) for structural property calculations in condensed matter systems.

Method: Integrated auxiliary-field quantum Monte Carlo (AFQMC) with projector augmented-wave (PAW) formalism in VASP via exact inversion of PAW overlap operator, enabling complete basis set limit calculations with cubic scaling.

Result: Calculated equilibrium lattice constants and bulk moduli for C, BN, BP, and Si with mean absolute relative error of 0.14% vs experiment; identified RPA as optimal reference due to rapid convergence of short-range correlations.

Conclusion: Established PW-AFQMC as a rigorous benchmark tool for structural properties by systematically correcting MP2/RPA deficiencies with high accuracy.

Abstract: We present a plane-wave (PW) implementation of the auxiliary-field quantum Monte Carlo (AFQMC) method within the projector augmented-wave (PAW) formalism in the Vienna ab initio Simulation Package (VASP). By employing an exact inversion of the PAW overlap operator, our approach maintains cubic scaling while naturally operating at the complete basis set limit defined by the PW cutoff. We benchmark this framework by calculating the equilibrium lattice constants and bulk moduli of C, BN, BP, and Si. Our analysis demonstrates that AFQMC systematically corrects the lack of long-range screening in MP2 and the missing higher-order exchange in RPA. We identify RPA as the optimal reference method due to the rapid convergence of the remaining short-range correlations with respect to supercell size. The resulting lattice constants exhibit a mean absolute relative error of 0.14 % relative to experiment, establishing the method as a rigorous benchmark tool for structural properties in condensed matter systems.

</details>


### [25] [Geometry Challenges Entropy: Regime-DependentRectification in Nanofluidic Cascades](https://arxiv.org/abs/2602.13931)
*Ting Peng*

Main category: physics.comp-ph

TL;DR: 3D分子动力学模拟揭示纳米流体腔室中存在"反向"几何整流效应：漏斗不对称性（而非传统认为的边界反射）在弹道输运 regime 中驱动窄端粒子富集5倍以上，挑战熵传输理论，为无泵被动密度梯度设计提供新规则


<details>
  <summary>Details</summary>
Motivation: 传统观点将纳米流体腔室中的复杂粒子积累归因于几何二极管效应，但未能区分漏斗整流与边界反射的贡献，需明确几何结构单独作用能否重塑平衡态密度分布

Method: 采用3D分子动力学模拟（氩参数，r=0.19 nm），对比2腔室/10腔室级联结构，通过对称控制实验（w_L=w_R）解耦漏斗不对称性与边界反射效应

Result: 发现2腔室中窄端粒子数超5倍富集（N₁/N₀=5.37±0.01）；10腔室级联产生显著下游积累；对称结构梯度消失证明漏斗不对称性是弹道 regime 主因，而超原子 regime 由边界反射主导

Conclusion: 几何不对称性可被动产生强密度梯度（无需泵/驱动），颠覆标准熵输运理论，为纳米流体器件设计提供基于纯几何调控的新范式

Abstract: Can geometry alone reshape equilibrium? Cascaded nanofluidic chambers show complex accumulation patterns, traditionally attributed to geometric diode effects. We use 3D molecular dynamics to decouple funnel rectification from boundary reflection. Simulations with argon parameters (r = 0.19 nm) reveal a striking "reverse" rectification in a 2-chamber setup: the narrow side accumulates over 5x more particles (N_1/N_0 = 5.37 +/- 0.01, p < 0.0001). In a 10-chamber argon cascade, this effect drives massive downstream accumulation. A symmetric control (w_L = w_R) eliminates the gradient, confirming that funnel asymmetry - not boundary/edge effects - is the primary driver in the ballistic regime. By contrast, the super-atom regime is dominated by boundary reflection. Our results challenge standard entropic transport theory and provide design rules for passive, geometry-driven density gradients - no pump, no drive.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [26] [Causally constrained reduced-order neural models of complex turbulent dynamical systems](https://arxiv.org/abs/2602.13847)
*Fabrizio Falasca,Laure Zanna*

Main category: nlin.CD

TL;DR: A flexible framework using response theory and score matching suppresses spurious noncausal dependencies in neural emulators of turbulent systems, improving their response to external forcings despite training only on unforced data.


<details>
  <summary>Details</summary>
Motivation: Spurious noncausal dependencies in reduced-order neural emulators of turbulent systems (e.g., climate dynamics) limit their reliability and response accuracy to external forcings.

Method: The framework combines response theory and score matching to impose causal constraints, tested on the stochastic Charney-DeVore model as a prototype for atmospheric variability.

Result: Causal constraints significantly enhance neural emulators' ability to respond to both weak and strong external forcings, even when trained exclusively on unforced data.

Conclusion: The approach is broadly applicable to modeling complex turbulent systems in reduced spaces and can be integrated into general neural network architectures.

Abstract: We introduce a flexible framework based on response theory and score matching to suppress spurious, noncausal dependencies in reduced-order neural emulators of turbulent systems, focusing on climate dynamics as a proof-of-concept. We showcase the approach using the stochastic Charney-DeVore model as a relevant prototype for low-frequency atmospheric variability. We show that the resulting causal constraints enhance neural emulators' ability to respond to both weak and strong external forcings, despite being trained exclusively on unforced data. The approach is broadly applicable to modeling complex turbulent dynamical systems in reduced spaces and can be readily integrated into general neural network architectures.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [27] [BLUEPRINT Rebuilding a Legacy: Multimodal Retrieval for Complex Engineering Drawings and Documents](https://arxiv.org/abs/2602.13345)
*Ethan Seefried,Ran Eldegaway,Sanjay Das,Nathaniel Blanchard,Tirthankar Ghosal*

Main category: cs.LG

TL;DR: Blueprint是一个面向大规模工程档案的布局感知多模态检索系统，能自动从约77万张图纸中提取结构化元数据。在5000份文件的基准测试上，相比最强视觉语言基线，Success@3绝对提升10.1%，nDCG@3相对提升18.9%，并全面开源评测资源以促进可重复研究。


<details>
  <summary>Details</summary>
Motivation: 数十年的工程图纸和技术记录因元数据不一致或缺失而被锁定在遗留档案中，导致检索困难且通常依赖人工操作，亟需自动化解决方案。

Method: 提出Blueprint系统，通过检测标准绘图区域、应用区域受限的VLM-based OCR技术、规范化标识符（如DWG、零件、设施），并融合词法与稠密检索结合轻量级区域级重排序器，实现大规模工程档案的自动化处理。

Result: 系统部署于约77万张未标记文件，自动生成支持跨设施搜索的结构化元数据。在包含5000份文件和350个专家查询的基准测试上，Blueprint在Success@3上实现10.1%的绝对增益，在nDCG@3上实现18.9%的相对改进，全面超越视觉、文本和多模态意图下的最强基线。Oracle消融实验表明在理想区域检测和OCR条件下仍有显著提升空间。

Conclusion: 研究团队发布所有查询、运行结果、标注数据和代码，旨在促进对遗留工程档案的可重复评估和研究。

Abstract: Decades of engineering drawings and technical records remain locked in legacy archives with inconsistent or missing metadata, making retrieval difficult and often manual. We present Blueprint, a layout-aware multimodal retrieval system designed for large-scale engineering repositories. Blueprint detects canonical drawing regions, applies region-restricted VLM-based OCR, normalizes identifiers (e.g., DWG, part, facility), and fuses lexical and dense retrieval with a lightweight region-level reranker. Deployed on ~770k unlabeled files, it automatically produces structured metadata suitable for cross-facility search.
  We evaluate Blueprint on a 5k-file benchmark with 350 expert-curated queries using pooled, graded (0/1/2) relevance judgments. Blueprint delivers a 10.1% absolute gain in Success@3 and an 18.9% relative improvement in nDCG@3 over the strongest vision-language baseline}, consistently outperforming across vision, text, and multimodal intents. Oracle ablations reveal substantial headroom under perfect region detection and OCR. We release all queries, runs, annotations, and code to facilitate reproducible evaluation on legacy engineering archives.

</details>


### [28] [The Speed-up Factor: A Quantitative Multi-Iteration Active Learning Performance Metric](https://arxiv.org/abs/2602.13359)
*Hannes Kath,Thiago S. Gouvêa,Daniel Sonntag*

Main category: cs.LG

TL;DR: 针对主动学习中评估指标缺失问题，本文提出速度因子新指标，通过4数据集7查询方法的实验，验证其能准确衡量达到随机采样性能所需样本比例，且跨轮次稳定性优于现有指标。


<details>
  <summary>Details</summary>
Motivation: 机器学习虽在数据充足时表现优异，但标注成本高昂。主动学习通过查询方法迭代选择信息量最大的样本来优化性能-标注比，然而现有研究多关注查询方法开发，缺乏对此迭代过程的适当性能评估指标。

Method: 本研究综述了八年主动学习评估文献，正式提出速度因子——一种量化多轮次查询方法性能的指标，表示达到随机采样性能所需样本比例。通过在四个不同领域数据集和七种不同类型查询方法上进行实证评估，并与先进指标对比。

Result: 实验结果证实了速度因子的理论假设，验证了其准确捕捉样本比例的能力，并显示出其在迭代过程中具有更优的稳定性。

Conclusion: 本工作提出的速度因子有效填补了主动学习评估指标的空白，相比现有指标表现更稳定准确，为评估主动学习算法提供了新的量化标准。

Abstract: Machine learning models excel with abundant annotated data, but annotation is often costly and time-intensive. Active learning (AL) aims to improve the performance-to-annotation ratio by using query methods (QMs) to iteratively select the most informative samples. While AL research focuses mainly on QM development, the evaluation of this iterative process lacks appropriate performance metrics. This work reviews eight years of AL evaluation literature and formally introduces the speed-up factor, a quantitative multi-iteration QM performance metric that indicates the fraction of samples needed to match random sampling performance. Using four datasets from diverse domains and seven QMs of various types, we empirically evaluate the speed-up factor and compare it with state-of-the-art AL performance metrics. The results confirm the assumptions underlying the speed-up factor, demonstrate its accuracy in capturing the described fraction, and reveal its superior stability across iterations.

</details>


### [29] [Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise](https://arxiv.org/abs/2602.13413)
*Yuchen Fang,James Demmel,Javad Lavaei*

Main category: cs.LG

TL;DR: 本文建立了重尾噪声下随机预条件随机梯度下降（SPSGD）及其加速变体的最坏情况复杂度理论，证明归一化能保证收敛而裁剪可能失败，并提出了新的向量值Burkholder型不等式。


<details>
  <summary>Details</summary>
Motivation: 针对自适应优化方法（如Adam、RMSProp）在重尾噪声场景下的稳定性问题，现有裁剪与归一化工具的最坏情况理论差异尚未明确，需解释实践中归一化更优的现象。

Method: 假设随机梯度噪声具有有限p阶矩（p∈(1,2]），通过建立SPSGD的最坏情况复杂度框架，并创新性地提出向量值Burkholder型不等式分析收敛性。

Result: 归一化在参数已知/未知时分别达到O(T^(-(p-1)/(3p-2)))和O(T^(-(p-1)/(2p)))的最优收敛速率；而裁剪因预条件器与梯度估计的统计依赖性存在最坏情况发散风险。

Conclusion: 理论证实归一化在重尾噪声下SPSGD优化中优于裁剪，为大规模模型训练实践提供依据，且新不等式具有独立研究价值。

Abstract: We develop a worst-case complexity theory for stochastically preconditioned stochastic gradient descent (SPSGD) and its accelerated variants under heavy-tailed noise, a setting that encompasses widely used adaptive methods such as Adam, RMSProp, and Shampoo. We assume the stochastic gradient noise has a finite $p$-th moment for some $p \in (1,2]$, and measure convergence after $T$ iterations. While clipping and normalization are parallel tools for stabilizing training of SGD under heavy-tailed noise, there is a fundamental separation in their worst-case properties in stochastically preconditioned settings. We demonstrate that normalization guarantees convergence to a first-order stationary point at rate $\mathcal{O}(T^{-\frac{p-1}{3p-2}})$ when problem parameters are known, and $\mathcal{O}(T^{-\frac{p-1}{2p}})$ when problem parameters are unknown, matching the optimal rates for normalized SGD, respectively. In contrast, we prove that clipping may fail to converge in the worst case due to the statistical dependence between the stochastic preconditioner and the gradient estimates. To enable the analysis, we develop a novel vector-valued Burkholder-type inequality that may be of independent interest. These results provide a theoretical explanation for the empirical preference for normalization over clipping in large-scale model training.

</details>


### [30] [High-Resolution Climate Projections Using Diffusion-Based Downscaling of a Lightweight Climate Emulator](https://arxiv.org/abs/2602.13416)
*Haiwen Guan,Moein Darman,Dibyajyoti Chakraborty,Troy Arcomano,Ashesh Chattopadhyay,Romit Maulik*

Main category: cs.LG

TL;DR: 本文提出一种基于概率扩散模型的深度降尺度框架，成功将LUCIE气候模拟器的分辨率从约300公里提升至25公里，在保持粗粒度动力学特征的同时生成准确的细粒度气候统计信息。


<details>
  <summary>Details</summary>
Motivation: LUCIE气候模拟器虽然能准确模拟长期气候统计，但其原生分辨率（约300公里）不足以满足详细的区域气候影响评估需求，需要开发高效的降尺度方法来提升分辨率。

Method: 采用概率扩散生成模型，结合条件采样和后验采样框架进行训练。使用约14,000个ERA5时间步长（2000-2009年）训练模型，并在2010-2020年的LUCIE预测数据上进行评估验证。

Result: 该框架成功将LUCIE输出降尺度至约28公里分辨率，通过纬度平均RMSE、功率谱、概率密度函数和纬向风的第一经验正交函数等多种指标验证，表明其能保持LUCIE的粗粒度动力学特征同时生成准确的细粒度气候统计。

Conclusion: 所提出的扩散降尺度方法有效解决了轻量级气候模拟器的分辨率限制问题，为高分辨率区域气候影响评估提供了物理一致且计算高效的解决方案。

Abstract: The proliferation of data-driven models in weather and climate sciences has marked a significant paradigm shift, with advanced models demonstrating exceptional skill in medium-range forecasting. However, these models are often limited by long-term instabilities, climatological drift, and substantial computational costs during training and inference, restricting their broader application for climate studies. Addressing these limitations, Guan et al. (2024) introduced LUCIE, a lightweight, physically consistent climate emulator utilizing a Spherical Fourier Neural Operator (SFNO) architecture. This model is able to reproduce accurate long-term statistics including climatological mean and seasonal variability. However, LUCIE's native resolution (~300 km) is inadequate for detailed regional impact assessments. To overcome this limitation, we introduce a deep learning-based downscaling framework, leveraging probabilistic diffusion-based generative models with conditional and posterior sampling frameworks. These models downscale coarse LUCIE outputs to 25 km resolution. They are trained on approximately 14,000 ERA5 timesteps spanning 2000-2009 and evaluated on LUCIE predictions from 2010 to 2020. Model performance is assessed through diverse metrics, including latitude-averaged RMSE, power spectrum, probability density functions and First Empirical Orthogonal Function of the zonal wind. We observe that the proposed approach is able to preserve the coarse-grained dynamics from LUCIE while generating fine-scaled climatological statistics at ~28km resolution.

</details>


### [31] [Text Has Curvature](https://arxiv.org/abs/2602.13418)
*Karish Grover,Hanqing Zeng,Yinglong Xia,Christos Faloutsos,Geoffrey J. Gordon*

Main category: cs.LG

TL;DR: 本文提出"Texture"——一种文本原生的曲率度量方法，证明语言具有内在曲率，并展示了其在改进长上下文推理和检索增强生成中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 尽管语言越来越多地在弯曲几何空间（如用于层次结构的双曲空间、用于组合结构的混合曲率流形）中建模，但一个基础科学问题仍未解决：曲率对文本本身意味着什么，而非我们选择的嵌入空间的产物？本文旨在回答这一根本问题。

Method: 作者提出"Texture"这一词级离散曲率信号，通过薛定谔桥（Schrödinger bridge）调和被掩码词左右的上下文信念，生成一个曲率场：正值表示上下文聚焦语义，负值表示语义发散。

Result: (a) 存在性：提供经验性和理论性证据证明自然语料库的语义推断是非平坦的；(b) 定义：成功定义Texture作为可测量的曲率信号；(c) 实用性：在无需几何训练的情况下，实现曲率引导的长上下文压缩和检索增强生成的路由，提升性能。

Conclusion: 研究建立了文本原生曲率范式，使曲率可测量且实用，为几何应用提供了无需几何训练的新途径。

Abstract: Does text have an intrinsic curvature? Language is increasingly modeled in curved geometries - hyperbolic spaces for hierarchy, mixed-curvature manifolds for compositional structure - yet a basic scientific question remains unresolved: what does curvature mean for text itself, in a way that is native to language rather than an artifact of the embedding space we choose? We argue that text does indeed have curvature, and show how to detect it, define it, and use it. To this end, we propose Texture, a text-native, word-level discrete curvature signal, and make three contributions. (a) Existence: We provide empirical and theoretical certificates that semantic inference in natural corpora is non-flat, i.e. language has inherent curvature. (b) Definition: We define Texture by reconciling left- and right-context beliefs around a masked word through a Schrodinger bridge, yielding a curvature field that is positive where context focuses meaning and negative where it fans out into competing continuations. (c) Utility: Texture is actionable: it serves as a general-purpose measurement and control primitive enabling geometry without geometric training; we instantiate it on two representative tasks, improving long-context inference through curvature-guided compression and retrieval-augmented generation through curvature-guided routing. Together, our results establish a text-native curvature paradigm, making curvature measurable and practically useful.

</details>


### [32] [Comparing Classifiers: A Case Study Using PyCM](https://arxiv.org/abs/2602.13482)
*Sadra Sabouri,Alireza Zolanvari,Sepand Haghighi*

Main category: cs.LG

TL;DR: 本文介绍PyCM库用于多分类器深度评估，通过案例说明不同评估指标会改变模型效果解读，强调需采用多维度评估框架以发现细微性能差异，而标准指标可能忽略这些权衡。


<details>
  <summary>Details</summary>
Motivation: 现有分类模型选择依赖有限评估指标，可能导致对模型性能的理解片面化，尤其难以捕捉细微但关键的性能差异。

Method: 通过PyCM库教程结合两个实际案例，对比不同评估指标对模型效果解读的影响，验证多维度评估的必要性。

Result: 多维度评估框架能有效揭示模型性能中微小但重要的差异，而标准单一指标易遗漏此类关键权衡信息。

Conclusion: 应摒弃单一指标评估习惯，采用PyCM等工具构建多维评估体系，以实现更全面准确的模型性能分析。

Abstract: Selecting an optimal classification model requires a robust and comprehensive understanding of the performance of the model. This paper provides a tutorial on the PyCM library, demonstrating its utility in conducting deep-dive evaluations of multi-class classifiers. By examining two different case scenarios, we illustrate how the choice of evaluation metrics can fundamentally shift the interpretation of a model's efficacy. Our findings emphasize that a multi-dimensional evaluation framework is essential for uncovering small but important differences in model performance. However, standard metrics may miss these subtle performance trade-offs.

</details>


### [33] [Finding Highly Interpretable Prompt-Specific Circuits in Language Models](https://arxiv.org/abs/2602.13483)
*Gabriel Franco,Lucas M. Tassis,Azalea Rohr,Mark Crovella*

Main category: cs.LG

TL;DR: Proposes ACC++, a method showing circuits are prompt-specific rather than task-specific, introducing prompt families as a new unit of analysis for mechanistic interpretability.


<details>
  <summary>Details</summary>
Motivation: Prior work identifies circuits by averaging across prompts, assuming a single stable mechanism per task, which may obscure prompt-specific circuit structure.

Method: ACC++ refines attention causal communication (ACC) to extract cleaner, lower-dimensional causal signals from attention heads in a single forward pass, without replacement models or activation patching, reducing attribution noise.

Result: Applying ACC++ to IOI task reveals no single circuit exists—prompt templates induce systematically different mechanisms. Prompts cluster into families with similar circuits, enabling representative circuits per family as a practical analysis unit.

Conclusion: Shifts mechanistic interpretability's unit of analysis from tasks to prompts, enabling scalable circuit descriptions when mechanisms are prompt-specific.

Abstract: Understanding the internal circuits that language models use to solve tasks remains a central challenge in mechanistic interpretability. Most prior work identifies circuits at the task level by averaging across many prompts, implicitly assuming a single stable mechanism per task. We show that this assumption can obscure a crucial source of structure: circuits are prompt-specific, even within a fixed task. Building on attention causal communication (ACC) (Franco & Crovella, 2025), we introduce ACC++, refinements that extract cleaner, lower-dimensional causal signals inside attention heads from a single forward pass. Like ACC, our approach does not require replacement models (e.g., SAEs) or activation patching; ACC++ further improves circuit precision by reducing attribution noise. Applying ACC++ to indirect object identification (IOI) in GPT-2, Pythia, and Gemma 2, we find there is no single circuit for IOI in any model: different prompt templates induce systematically different mechanisms. Despite this variation, prompts cluster into prompt families with similar circuits, and we propose a representative circuit for each family as a practical unit of analysis. Finally, we develop an automated interpretability pipeline that uses ACC++ signals to surface human-interpretable features and assemble mechanistic explanations for prompt families behavior. Together, our results recast circuits as a meaningful object of study by shifting the unit of analysis from tasks to prompts, enabling scalable circuit descriptions in the presence of prompt-specific mechanisms.

</details>


### [34] [Preventing Rank Collapse in Federated Low-Rank Adaptation with Client Heterogeneity](https://arxiv.org/abs/2602.13486)
*Fei Wu,Jia Hu,Geyong Min,Shiqiang Wang*

Main category: cs.LG

TL;DR: 针对联邦低秩适应(FedLoRA)中的秩崩溃问题，提出raFLoRA方法，通过秩分区聚合解决异构客户端间的贡献错配，提升模型性能且保持通信效率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中存在客户端系统资源和数据分布的异构性，导致LoRA秩的异质性。现有FedLoRA存在"秩崩溃"现象——全局更新的能量集中在最小共享秩上，造成性能下降和对秩配置高度敏感。

Method: 提出raFLoRA（秩分区聚合方法），将本地更新分解为秩分区，然后根据各分区的有效客户端贡献进行加权聚合，解决秩无关聚合权重与秩相关贡献之间的错配问题。

Result: 在分类和推理任务上的大量实验表明，raFLoRA相比现有FedLoRA基线方法：1）有效防止秩崩溃；2）显著提升模型性能；3）保持通信效率。

Conclusion: 该方法通过理论分析揭示秩崩溃根源，提出的解决方案有效应对了联邦学习中因客户端异构性带来的挑战，为高效隐私保护的模型微调提供了新思路。

Abstract: Federated low-rank adaptation (FedLoRA) has facilitated communication-efficient and privacy-preserving fine-tuning of foundation models for downstream tasks. In practical federated learning scenarios, client heterogeneity in system resources and data distributions motivates heterogeneous LoRA ranks across clients. We identify a previously overlooked phenomenon in heterogeneous FedLoRA, termed rank collapse, where the energy of the global update concentrates on the minimum shared rank, resulting in suboptimal performance and high sensitivity to rank configurations. Through theoretical analysis, we reveal the root cause of rank collapse: a mismatch between rank-agnostic aggregation weights and rank-dependent client contributions, which systematically suppresses higher-rank updates at a geometric rate over rounds. Motivated by this insight, we propose raFLoRA, a rank-partitioned aggregation method that decomposes local updates into rank partitions and then aggregates each partition weighted by its effective client contributions. Extensive experiments across classification and reasoning tasks show that raFLoRA prevents rank collapse, improves model performance, and preserves communication efficiency compared to state-of-the-art FedLoRA baselines.

</details>


### [35] [TrasMuon: Trust-Region Adaptive Scaling for Orthogonalized Momentum Optimizers](https://arxiv.org/abs/2602.13498)
*Peng Cheng,Jiucheng Zang,Qingnan Li,Liheng Ma,Yufei Cui,Yingxue Zhang,Boxing Chen,Ming Jian,Wen Tong*

Main category: cs.LG

TL;DR: 针对Muon优化器正交化更新时丢弃幅度信息导致的不稳定问题，本文提出TrasMuon，通过全局RMS校准和基于相对能量比的信任域裁剪稳定更新幅度，在视觉和语言模型上实现更快收敛和更强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Muon利用牛顿-舒尔茨迭代正交化更新，但丢弃幅度信息使其对学习率超参数敏感且易受高能脉冲影响，需解决训练稳定性问题。

Method: 提出TrasMuon优化器，采用全局RMS校准和能量信任域裁剪机制，基于相对能量比定义稳定区域，约束更新幅度以防止高能异常值。

Result: 在视觉和语言模型上的实证实验显示，TrasMuon比基线方法收敛更快；且在省略warmup阶段时，仍保持更优的稳定性和鲁棒性。

Conclusion: TrasMuon通过自适应缩放机制成功平衡了Muon的几何优势与幅度稳定性，提供了更可靠的优化器设计范式。

Abstract: Muon-style optimizers leverage Newton-Schulz (NS) iterations to orthogonalize updates, yielding update geometries that often outperform Adam-series methods. However, this orthogonalization discards magnitude information, rendering training sensitive to step-size hyperparameters and vulnerable to high-energy bursts. To mitigate this, we introduce TrasMuon (\textbf{T}rust \textbf{R}egion \textbf{A}daptive \textbf{S}caling \textbf{Muon}). TrasMuon preserves the near-isometric geometry of Muon while stabilizing magnitudes through (i) global RMS calibration and (ii) energy-based trust-region clipping. We demonstrate that while reintroducing adaptive scaling improves optimization efficiency, it typically exacerbates instability due to high-energy outliers. TrasMuon addresses this by defining a trust region based on relative energy ratios, confining updates to a stable zone. Empirical experiments on vision and language models demonstrate that TrasMuon converges faster than baselines. Furthermore, experiments without warmup stages confirm TrasMuon's superior stability and robustness.

</details>


### [36] [Singular Vectors of Attention Heads Align with Features](https://arxiv.org/abs/2602.13524)
*Gabriel Franco,Carson Loughridge,Mark Crovella*

Main category: cs.LG

TL;DR: 本文探究了注意力矩阵奇异向量与特征对齐的条件与原因，为机制可解释性中的特征识别提供了理论依据和检验方法


<details>
  <summary>Details</summary>
Motivation: 近期研究隐含假设注意力矩阵的奇异向量对应于特征表示，但缺乏合理解释。本文旨在为这一假设提供理论支撑，明确回答奇异向量为何以及在何种条件下与特征对齐

Method: 在特征可直接观测的模型中实证验证对齐现象；理论证明该对齐在多种条件下是预期现象；提出稀疏注意力分解作为可检验预测；在真实模型中验证预测的有效性

Result: 奇异向量在可观测特征模型中鲁棒地对齐于特征；理论证明在特定条件下这种对齐是预期发生的；稀疏注意力分解可作为对齐的有效预测指标；真实模型中的现象与理论预测一致

Conclusion: 奇异向量与特征的对齐具有坚实的理论和实证基础，可作为语言模型特征识别的可靠方法

Abstract: Identifying feature representations in language models is a central task in mechanistic interpretability. Several recent studies have made an implicit assumption that feature representations can be inferred in some cases from singular vectors of attention matrices. However, sound justification for this assumption is lacking. In this paper we address that question, asking: why and when do singular vectors align with features? First, we demonstrate that singular vectors robustly align with features in a model where features can be directly observed. We then show theoretically that such alignment is expected under a range of conditions. We close by asking how, operationally, alignment may be recognized in real models where feature representations are not directly observable. We identify sparse attention decomposition as a testable prediction of alignment, and show evidence that it emerges in a manner consistent with predictions in real models. Together these results suggest that alignment of singular vectors with features can be a sound and theoretically justified basis for feature identification in language models.

</details>


### [37] [QuaRK: A Quantum Reservoir Kernel for Time Series Learning](https://arxiv.org/abs/2602.13531)
*Abdallah Aaraba,Soumaya Cherkaoui,Ola Ahmad,Shengrui Wang*

Main category: cs.LG

TL;DR: 提出QuaRK框架，结合硬件现实的量子储层与核读出方案，为时序学习提供理论保障和实际实现路径，通过经典影子层析实现高效特征提取，并验证于合成beta-混合时序任务。


<details>
  <summary>Details</summary>
Motivation: 量子储层计算在时序学习中有前景，但缺乏硬件高效架构与学习理论保障的研究，存在实践与理论脱节的问题。

Method: 构建端到端框架QuaRK，包含硬件现实量子储层特征提取器和核读出机制。通过序列注入样本点，利用经典影子层析高效测量k-局部可观测量生成紧凑特征向量，再通过显式正则化和快速优化的经典核读出学习目标映射，暴露电路宽度、深度和测量预算等可调计算参数。

Result: 为依赖时序数据提供学习理论泛化保障，将设计与资源选择关联至有限样本性能，提供可靠时序学习器构建的指导原则。在合成beta-混合时序任务上的实证实验验证了框架并展示了预测的插值与泛化行为。

Conclusion: QuaRK成功弥合了硬件现实量子储层计算与理论保障学习之间的鸿沟，为时序学习提供了兼具实践可行性与理论保证的端到端解决方案。

Abstract: Quantum reservoir computing offers a promising route for time series learning by modelling sequential data via rich quantum dynamics while the only training required happens at the level of a lightweight classical readout. However, studies featuring efficient and implementable quantum reservoir architectures along with model learning guarantees remain scarce in the literature. To close this gap, we introduce QuaRK, an end-to-end framework that couples a hardware-realistic quantum reservoir featurizer with a kernel-based readout scheme. Given a sequence of sample points, the reservoir injects the points one after the other to yield a compact feature vector from efficiently measured k-local observables using classical shadow tomography, after which a classical kernel-based readout learns the target mapping with explicit regularization and fast optimization. The resulting pipeline exposes clear computational knobs -- circuit width and depth as well as the measurement budget -- while preserving the flexibility of kernel methods to model nonlinear temporal functionals and being scalable to high-dimensional data. We further provide learning-theoretic generalization guarantees for dependent temporal data, linking design and resource choices to finite-sample performance, thereby offering principled guidance for building reliable temporal learners. Empirical experiments validate QuaRK and illustrate the predicted interpolation and generalization behaviours on synthetic beta-mixing time series tasks.

</details>


### [38] [Fast Swap-Based Element Selection for Multiplication-Free Dimension Reduction](https://arxiv.org/abs/2602.13532)
*Nobutaka Ono*

Main category: cs.LG

TL;DR: 提出一种快速元素选择算法，实现无需乘法的降维。通过从输入向量中选择子集进行降维，避免PCA的矩阵乘法开销，采用矩阵求逆引理和基于交换的局部搜索高效求解元素选择问题。


<details>
  <summary>Details</summary>
Motivation: 降维是减少参数、防止过拟合、加速训练推理的基础技术。标准PCA依赖矩阵乘法，在资源受限系统中乘法计算本身成为瓶颈。元素选择可消除此开销，但挑战在于确定保留哪些元素。

Method: 通过线性回归预测目标向量的最小均方误差评估子集质量；针对组合优化难题，利用矩阵求逆引理推导元素交换对目标函数的改变量；实施交换式局部搜索，重复执行目标递减的交换直至收敛。

Result: 在MNIST手写数字图像上的实验验证了所提方法的有效性。

Conclusion: 该方法通过高效的交换算法实现了无需乘法的降维，成功解决了资源受限系统中PCA的计算瓶颈问题。

Abstract: In this paper, we propose a fast algorithm for element selection, a multiplication-free form of dimension reduction that produces a dimension-reduced vector by simply selecting a subset of elements from the input. Dimension reduction is a fundamental technique for reducing unnecessary model parameters, mitigating overfitting, and accelerating training and inference. A standard approach is principal component analysis (PCA), but PCA relies on matrix multiplications; on resource-constrained systems, the multiplication count itself can become a bottleneck. Element selection eliminates this cost because the reduction consists only of selecting elements, and thus the key challenge is to determine which elements should be retained. We evaluate a candidate subset through the minimum mean-squared error of linear regression that predicts a target vector from the selected elements, where the target may be, for example, a one-hot label vector in classification. When an explicit target is unavailable, the input itself can be used as the target, yielding a reconstruction-based criterion. The resulting optimization is combinatorial, and exhaustive search is impractical. To address this, we derive an efficient formula for the objective change caused by swapping a selected and an unselected element, using the matrix inversion lemma, and we perform a swap-based local search that repeatedly applies objective-decreasing swaps until no further improvement is possible. Experiments on MNIST handwritten-digit images demonstrate the effectiveness of the proposed method.

</details>


### [39] [Interpretable clustering via optimal multiway-split decision trees](https://arxiv.org/abs/2602.13586)
*Hayato Suzuki,Shunnosuke Ikeda,Yuichi Takano*

Main category: cs.LG

TL;DR: The paper proposes a clustering method using optimal multiway-split decision trees formulated as 0-1 integer linear optimization (instead of mixed-integer nonlinear), which is more computationally efficient. It integrates 1D K-means for discretization and produces more interpretable, concise trees while achieving better clustering accuracy than existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing clustering methods using binary decision trees face challenges: solving mixed-integer nonlinear optimization problems leads to high computational costs and suboptimal solutions; binary trees often become excessively deep, reducing interpretability. There is a need for both high accuracy and interpretability in clustering.

Method: Proposes an interpretable clustering method based on optimal multiway-split decision trees, reformulated as a 0-1 integer linear optimization problem for better tractability. Integrates a one-dimensional K-means algorithm for data-driven discretization of continuous variables to enable flexible branching.

Result: Extensive experiments on real-world datasets show the method outperforms baselines in clustering accuracy and interpretability. It generates concise multiway-split decision trees with competitive performance across various evaluation metrics.

Conclusion: The proposed method successfully addresses computational and interpretability limitations of existing approaches by using multiway-split trees and integer linear optimization, achieving superior accuracy while producing more interpretable, concise decision rules.

Abstract: Clustering serves as a vital tool for uncovering latent data structures, and achieving both high accuracy and interpretability is essential. To this end, existing methods typically construct binary decision trees by solving mixed-integer nonlinear optimization problems, often leading to significant computational costs and suboptimal solutions. Furthermore, binary decision trees frequently result in excessively deep structures, which makes them difficult to interpret. To mitigate these issues, we propose an interpretable clustering method based on optimal multiway-split decision trees, formulated as a 0-1 integer linear optimization problem. This reformulation renders the optimization problem more tractable compared to existing models. A key feature of our method is the integration of a one-dimensional K-means algorithm for the discretization of continuous variables, allowing for flexible and data-driven branching. Extensive numerical experiments on publicly available real-world datasets demonstrate that our method outperforms baseline methods in terms of clustering accuracy and interpretability. Our method yields multiway-split decision trees with concise decision rules while maintaining competitive performance across various evaluation metrics.

</details>


### [40] [Benchmark Leakage Trap: Can We Trust LLM-based Recommendation?](https://arxiv.org/abs/2602.13626)
*Mingqiao Zhang,Qiyao Peng,Yumeng Wang,Chunyuan Liu,Hongtao Liu*

Main category: cs.LG

TL;DR: 该论文研究了LLM推荐系统中的基准数据泄露问题，发现模型在预训练时接触评测数据会导致性能虚高，提出这是一种被忽视的评估干扰因素。


<details>
  <summary>Details</summary>
Motivation: LLM在推荐系统中的集成对评估可靠性构成挑战，需要识别和研究生基准数据泄露问题，因为LLMs可能在预训练或微调期间接触并记忆基准数据集，导致性能指标虚高。

Method: 通过在不同领域和跨领域的用户-项目交互数据上进行基础模型的持续预训练，模拟多种数据泄露场景。

Result: 发现数据泄露具有双重效应：领域相关的泄露会导致虚假的性能提升，而领域无关的泄露通常会降低推荐准确率，揭示了这种污染的复杂性和偶然性。

Conclusion: 数据泄露是LLM推荐系统中一个关键的、先前未被考虑的因素，可能影响真实模型性能，需要引起研究者和实践者的重视。

Abstract: The expanding integration of Large Language Models (LLMs) into recommender systems poses critical challenges to evaluation reliability. This paper identifies and investigates a previously overlooked issue: benchmark data leakage in LLM-based recommendation. This phenomenon occurs when LLMs are exposed to and potentially memorize benchmark datasets during pre-training or fine-tuning, leading to artificially inflated performance metrics that fail to reflect true model performance. To validate this phenomenon, we simulate diverse data leakage scenarios by conducting continued pre-training of foundation models on strategically blended corpora, which include user-item interactions from both in-domain and out-of-domain sources. Our experiments reveal a dual-effect of data leakage: when the leaked data is domain-relevant, it induces substantial but spurious performance gains, misleadingly exaggerating the model's capability. In contrast, domain-irrelevant leakage typically degrades recommendation accuracy, highlighting the complex and contingent nature of this contamination. Our findings reveal that data leakage acts as a critical, previously unaccounted-for factor in LLM-based recommendation, which could impact the true model performance. We release our code at https://github.com/yusba1/LLMRec-Data-Leakage.

</details>


### [41] [Joint Time Series Chain: Detecting Unusual Evolving Trend across Time Series](https://arxiv.org/abs/2602.13649)
*Li Zhang,Nital Patel,Xiuqi Li,Jessica Lin*

Main category: cs.LG

TL;DR: The paper introduces Joint Time Series Chain (JointTSC), a new concept for discovering evolving patterns across interrupted or multiple related time series, overcoming limitations of single-series approaches through a robust definition and ranking criterion.


<details>
  <summary>Details</summary>
Motivation: Existing time series chain (TSC) definitions only operate on single time series, which likely miss unexpected evolving patterns in interrupted time series or across two related time series.

Method: Proposes a new definition called Joint Time Series Chain specifically designed to mitigate robustness issues caused by gaps/interruptions, with an effective ranking criterion to identify the best chain.

Result: Empirically demonstrates superiority over existing TSC methods in locating unusual evolving patterns, validated through a real manufacturing application at Intel, with publicly available source code.

Conclusion: The JointTSC approach successfully addresses the limitation of single-series TSC definitions and provides practical utility for identifying cross-series evolving trends in real-world applications.

Abstract: Time series chain (TSC) is a recently introduced concept that captures the evolving patterns in large scale time series. Informally, a time series chain is a temporally ordered set of subsequences, in which consecutive subsequences in the chain are similar to one another, but the last and the first subsequences maybe be dissimilar. Time series chain has the great potential to reveal latent unusual evolving trend in the time series, or identify precursor of important events in a complex system. Unfortunately, existing definitions of time series chains only consider finding chains in a single time series. As a result, they are likely to miss unexpected evolving patterns in interrupted time series, or across two related time series. To address this limitation, in this work, we introduce a new definition called \textit{Joint Time Series Chain}, which is specially designed for the task of finding unexpected evolving trend across interrupted time series or two related time series. Our definition focuses on mitigating the robustness issues caused by the gap or interruption in the time series. We further propose an effective ranking criterion to identify the best chain. We demonstrate that our proposed approach outperforms existing TSC work in locating unusual evolving patterns through extensive empirical evaluations. We further demonstrate the utility of our work with a real-life manufacturing application from Intel. Our source code is publicly available at the supporting page https://github.com/lizhang-ts/JointTSC .

</details>


### [42] [Cumulative Utility Parity for Fair Federated Learning under Intermittent Client Participation](https://arxiv.org/abs/2602.13651)
*Stefan Behfar,Richard Mortier*

Main category: cs.LG

TL;DR: 该论文针对联邦学习中客户端参与不均衡的问题，提出了一种新的公平性原则——累积效用平价，通过可用性归一化的累积效用来区分物理限制和算法偏见，从而改善间歇性可用客户端的长期代表性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习公平性方法假设客户端有相当的参与机会，但现实中参与是间歇性、异构且不均衡的，导致间歇性可用客户端被系统性低估，即使每轮性能看似公平。

Method: 提出累积效用平价原则，引入可用性归一化累积效用指标，将不可避免的硬件约束与可由调度和聚合引起的算法偏见分离开来。

Result: 在具有时间偏斜和非IID特性的联邦基准测试上，该方法显著提升了长期代表性公平性，同时保持了接近完美的模型性能。

Conclusion: 该框架能够有效识别并减少因参与不均衡导致的算法偏见，为联邦学习中的公平性提供了更合理的评估标准和改进方向。

Abstract: In real-world federated learning (FL) systems, client participation is intermittent, heterogeneous, and often correlated with data characteristics or resource constraints. Existing fairness approaches in FL primarily focus on equalizing loss or accuracy conditional on participation, implicitly assuming that clients have comparable opportunities to contribute over time. However, when participation itself is uneven, these objectives can lead to systematic under-representation of intermittently available clients, even if per-round performance appears fair. We propose cumulative utility parity, a fairness principle that evaluates whether clients receive comparable long-term benefit per participation opportunity, rather than per training round. To operationalize this notion, we introduce availability-normalized cumulative utility, which disentangles unavoidable physical constraints from avoidable algorithmic bias arising from scheduling and aggregation. Experiments on temporally skewed, non-IID federated benchmarks demonstrate that our approach substantially improves long-term representation parity, while maintaining near-perfect performance.

</details>


### [43] [Zero-Order Optimization for LLM Fine-Tuning via Learnable Direction Sampling](https://arxiv.org/abs/2602.13659)
*Valery Parfenov,Grigoriy Evseev,Andrey Veprikov,Nikolay Bushkov,Stanislav Moiseev,Aleksandr Beznosikov*

Main category: cs.LG

TL;DR: 该论文提出一种可学习的零阶优化策略，通过自适应采样扰动方向来降低方差和维度依赖，实现可扩展的内存高效大语言模型微调。


<details>
  <summary>Details</summary>
Motivation: 微调大型预训练语言模型需要大量内存（源于反向传播和优化器状态），限制了资源受限环境中的应用。零阶方法虽能节省内存，但存在高方差和维度依赖问题，难以扩展到高维参数。

Method: 提出策略驱动的零阶框架，将扰动方向的采样分布视为可学习策略，通过优化该策略来降低方向估计的方差。开发实用算法并提供理论分析，证明学习的采样分布能改善梯度质量并放宽对维度d的依赖。

Result: 在具有挑战性的LLM微调基准测试上经验证，相比标准零阶基线性能显著提升。自适应方向采样使大规模零阶微调成为可行方案。

Conclusion: 自适应方向采样是实现可扩展、内存高效大语言模型微调的一种有前景的路径。

Abstract: Fine-tuning large pretrained language models (LLMs) is a cornerstone of modern NLP, yet its growing memory demands (driven by backpropagation and large optimizer States) limit deployment in resource-constrained settings. Zero-order (ZO) methods bypass backpropagation by estimating directional derivatives from forward evaluations, offering substantial memory savings. However, classical ZO estimators suffer from high variance and an adverse dependence on the parameter dimensionality $d$, which has constrained their use to low-dimensional problems. In this work, we propose a policy-driven ZO framework that treats the sampling distribution over perturbation directions as a learnable policy and updates it to reduce the variance of directional estimates. We develop a practical algorithm implementing this idea and provide a theoretical analysis, showing that learned sampling distributions improve the quality of gradient information and relax the explicit dependence on $d$ in convergence bounds. Empirically, we validate the approach on challenging LLM fine-tuning benchmarks, demonstrating substantially improved performance compared to standard ZO baselines. Our results suggest that adaptive direction sampling is a promising route to make ZO fine-tuning viable at scale. The source code is available at https://github.com/brain-lab-research/zo_ldsd

</details>


### [44] [Optimized Certainty Equivalent Risk-Controlling Prediction Sets](https://arxiv.org/abs/2602.13660)
*Jiayi Huang,Amirmohammad Farzaneh,Osvaldo Simeone*

Main category: cs.LG

TL;DR: This paper introduces OCE-RCPS, a novel framework providing high-probability guarantees on tail-risk measures like CVaR for safety-critical medical image segmentation, outperforming methods that only control expected risk.


<details>
  <summary>Details</summary>
Motivation: Existing risk-controlling prediction sets (RCPS) only provide probabilistic guarantees on expected risk but fail to capture tail behavior and worst-case scenarios, which are crucial in high-stakes safety-critical applications like medical image segmentation.

Method: Proposes optimized certainty equivalent RCPS (OCE-RCPS) that uses upper confidence bounds to identify prediction set parameters satisfying user-specified risk tolerance levels with provable reliability, supporting OCE risk measures including conditional value-at-risk (CVaR) and entropic risk.

Result: Theoretical guarantees prove OCE-RCPS satisfies probabilistic constraints for loss functions (miscoverage, false negative rate). Experiments show it consistently meets target satisfaction rates across various risk measures while baseline OCE-CRC fails to provide probabilistic guarantees.

Conclusion: OCE-RCPS successfully provides high-probability guarantees on general OCE risk measures for safety-critical applications, addressing the tail-risk limitations of conventional RCPS methods.

Abstract: In safety-critical applications such as medical image segmentation, prediction systems must provide reliability guarantees that extend beyond conventional expected loss control. While risk-controlling prediction sets (RCPS) offer probabilistic guarantees on the expected risk, they fail to capture tail behavior and worst-case scenarios that are crucial in high-stakes settings. This paper introduces optimized certainty equivalent RCPS (OCE-RCPS), a novel framework that provides high-probability guarantees on general optimized certainty equivalent (OCE) risk measures, including conditional value-at-risk (CVaR) and entropic risk. OCE-RCPS leverages upper confidence bounds to identify prediction set parameters that satisfy user-specified risk tolerance levels with provable reliability. We establish theoretical guarantees showing that OCE-RCPS satisfies the desired probabilistic constraint for loss functions such as miscoverage and false negative rate. Experiments on image segmentation demonstrate that OCE-RCPS consistently meets target satisfaction rates across various risk measures and reliability configurations, while OCE-CRC fails to provide probabilistic guarantees.

</details>


### [45] [ALMo: Interactive Aim-Limit-Defined, Multi-Objective System for Personalized High-Dose-Rate Brachytherapy Treatment Planning and Visualization for Cervical Cancer](https://arxiv.org/abs/2602.13666)
*Edward Chen,Natalie Dullerud,Pang Wei Koh,Thomas Niedermayr,Elizabeth Kidd,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: The paper presents ALMo, an interactive decision support system for HDR brachytherapy planning that uses aim-limit defined multi-objective optimization to help clinicians navigate tradeoffs between tumor coverage and organ sparing, showing improved plan quality and reduced planning time.


<details>
  <summary>Details</summary>
Motivation: Clinical decision-making involves tracking multiple competing metrics with aim (ideal) and limit (strict) thresholds. In HDR brachytherapy for cervical cancer, planning requires managing radiation hot spots while balancing tumor coverage against organ sparing. This process is cognitively demanding, prone to variability, and time-consuming (30-60 minutes per plan).

Method: The authors developed ALMo (Aim-Limit-defined Multi-Objective system), an interactive decision support system that uses a novel optimization framework with automated parameter setup to minimize manual input. The system allows clinicians to directly manipulate intuitive aim and limit values to navigate the Pareto surface of dosimetric tradeoffs.

Result: In a retrospective evaluation of 25 clinical cases, ALMo-generated plans consistently met or exceeded manual planning quality, with 65% showing dosimetric improvements. Planning time was significantly reduced to approximately 17 minutes compared to 30-60 minutes for conventional manual planning.

Conclusion: ALMo successfully streamlines multi-criteria clinical decision-making in brachytherapy, offering both improved plan quality and efficiency. The framework is generalizable to other complex clinical decision-making scenarios involving multiple competing objectives.

Abstract: In complex clinical decision-making, clinicians must often track a variety of competing metrics defined by aim (ideal) and limit (strict) thresholds. Sifting through these high-dimensional tradeoffs to infer the optimal patient-specific strategy is cognitively demanding and historically prone to variability. In this paper, we address this challenge within the context of High-Dose-Rate (HDR) brachytherapy for cervical cancer, where planning requires strictly managing radiation hot spots while balancing tumor coverage against organ sparing. We present ALMo (Aim-Limit-defined Multi-Objective system), an interactive decision support system designed to infer and operationalize clinician intent. ALMo employs a novel optimization framework that minimizes manual input through automated parameter setup and enables flexible control over toxicity risks. Crucially, the system allows clinicians to navigate the Pareto surface of dosimetric tradeoffs by directly manipulating intuitive aim and limit values. In a retrospective evaluation of 25 clinical cases, ALMo generated treatment plans that consistently met or exceeded manual planning quality, with 65% of cases demonstrating dosimetric improvements. Furthermore, the system significantly enhanced efficiency, reducing average planning time to approximately 17 minutes, compared to the conventional 30-60 minutes. While validated in brachytherapy, ALMo demonstrates a generalized framework for streamlining interaction in multi-criteria clinical decision-making.

</details>


### [46] [Advancing Analytic Class-Incremental Learning through Vision-Language Calibration](https://arxiv.org/abs/2602.13670)
*Binyu Zhao,Wei Zhang,Xingrui Yu,Zhaonian Zou,Ivor Tsang*

Main category: cs.LG

TL;DR: 提出VILA框架，通过视觉-语言双校准策略解决预训练模型增量学习中的表征僵化问题，在保持解析学习高效率的同时提升长期稳定性


<details>
  <summary>Details</summary>
Motivation: 预训练模型解析增量学习存在效率与稳定性矛盾，主要瓶颈是表征僵化导致特征不兼容和误差累积

Method: 双分支架构：特征级几何校准融合可塑任务特征与冻结语义锚点；决策级跨模态先验修正预测偏差

Result: 在8个基准测试上持续优于现有方法，在细粒度和长序列场景优势显著

Conclusion: 该框架成功调和了高精度预测与解析学习简洁性，为预训练模型增量学习提供了高效稳定的解决方案

Abstract: Class-incremental learning (CIL) with pre-trained models (PTMs) faces a critical trade-off between efficient adaptation and long-term stability. While analytic learning enables rapid, recursive closed-form updates, its efficacy is often compromised by accumulated errors and feature incompatibility. In this paper, we first conduct a systematic study to dissect the failure modes of PTM-based analytic CIL, identifying representation rigidity as the primary bottleneck. Motivated by these insights, we propose \textbf{VILA}, a novel dual-branch framework that advances analytic CIL via a two-level vision-language calibration strategy. Specifically, we coherently fuse plastic, task-adapted features with a frozen, universal semantic anchor at the feature level through geometric calibration, and leverage cross-modal priors at the decision level to rectify prediction bias. This confluence maintains analytic-learning's extreme efficiency while overcoming its inherent brittleness. Extensive experiments across eight benchmarks demonstrate that VILA consistently yields superior performance, particularly in fine-grained and long-sequence scenarios. Our framework harmonizes high-fidelity prediction with the simplicity of analytic learning. Our code is available at https://github.com/byzhaoAI/VILA

</details>


### [47] [On the Sparsifiability of Correlation Clustering: Approximation Guarantees under Edge Sampling](https://arxiv.org/abs/2602.13684)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Correlation Clustering (CC) is a fundamental unsupervised learning primitive whose strongest LP-based approximation guarantees require $Θ(n^3)$ triangle inequality constraints and are prohibitive at scale. We initiate the study of \emph{sparsification--approximation trade-offs} for CC, asking how much edge information is needed to retain LP-based guarantees. We establish a structural dichotomy between pseudometric and general weighted instances. On the positive side, we prove that the VC dimension of the clustering disagreement class is exactly $n{-}1$, yielding additive $\varepsilon$-coresets of optimal size $\tilde{O}(n/\varepsilon^2)$; that at most $\binom{n}{2}$ triangle inequalities are active at any LP vertex, enabling an exact cutting-plane solver; and that a sparsified variant of LP-PIVOT, which imputes missing LP marginals via triangle inequalities, achieves a robust $\frac{10}{3}$-approximation (up to an additive term controlled by an empirically computable imputation-quality statistic $\overlineΓ_w$) once $\tildeΘ(n^{3/2})$ edges are observed, a threshold we prove is sharp. On the negative side, we show via Yao's minimax principle that without pseudometric structure, any algorithm observing $o(n)$ uniformly random edges incurs an unbounded approximation ratio, demonstrating that the pseudometric condition governs not only tractability but also the robustness of CC to incomplete information.

</details>


### [48] [Attention Head Entropy of LLMs Predicts Answer Correctness](https://arxiv.org/abs/2602.13699)
*Sophie Ostmeier,Brian Axelrod,Maya Varma,Asad Aali,Yabin Zhang,Magdalini Paschali,Sanmi Koyejo,Curtis Langlotz,Akshay Chaudhari*

Main category: cs.LG

TL;DR: 提出Head Entropy方法，通过分析LLM注意力熵模式预测答案正确性，在域内匹配基线，域外泛化能力提升8.5% AUROC，且能在答案生成前预测正确性（+17.7% AUROC）


<details>
  <summary>Details</summary>
Motivation: LLM在医疗等安全关键领域存在产生合理但错误答案的风险，现有方法包括昂贵的人工评估和存在隐藏错误的LLM-as-judge，基于注意力质量定位的白盒方法尚无法回答能否预测答案正确性及跨域泛化的问题

Method: 使用稀疏逻辑回归分析每层注意力头的2-Renyi熵值，通过测量注意力质量的分布模式（注意力熵）来预测答案正确性

Result: 在5个指令调优LLM和3个QA数据集（常识、多跳推理、医疗）上：域内性能匹配或超过基线；域外泛化显著更优（平均+8.5% AUROC）；仅基于问题/上下文的注意力模式即可预测，平均+17.7% AUROC

Conclusion: Head Entropy能有效预测答案正确性，具备优秀域外泛化能力，且可在生成早期提供预测信号，为安全关键应用提供了实用的幻觉检测方案

Abstract: Large language models (LLMs) often generate plausible yet incorrect answers, posing risks in safety-critical settings such as medicine. Human evaluation is expensive, and LLM-as-judge approaches risk introducing hidden errors. Recent white-box methods detect contextual hallucinations using model internals, focusing on the localization of the attention mass, but two questions remain open: do these approaches extend to predicting answer correctness, and do they generalize out-of-domains? We introduce Head Entropy, a method that predicts answer correctness from attention entropy patterns, specifically measuring the spread of the attention mass. Using sparse logistic regression on per-head 2-Renyi entropies, Head Entropy matches or exceeds baselines in-distribution and generalizes substantially better on out-of-domains, it outperforms the closest baseline on average by +8.5% AUROC. We further show that attention patterns over the question/context alone, before answer generation, already carry predictive signal using Head Entropy with on average +17.7% AUROC over the closest baseline. We evaluate across 5 instruction-tuned LLMs and 3 QA datasets spanning general knowledge, multi-hop reasoning, and medicine.

</details>


### [49] [Optimal Regret for Policy Optimization in Contextual Bandits](https://arxiv.org/abs/2602.13700)
*Orin Levy,Yishay Mansour*

Main category: cs.LG

TL;DR: 提出首个针对带泛化函数逼近的随机上下文多臂老虎机的政策优化算法，在高效计算的同时实现最优遗憾界O~(√(K|A|log|F|))，架起了理论与实践的桥梁


<details>
  <summary>Details</summary>
Motivation: 现有上下文老虎机领域存在理论与实践的鸿沟：政策优化方法在实际中广泛应用，但在一般函数近似下缺乏严格的最优遗憾界证明，特别是高概率界

Method: 提出一种针对随机上下文多臂老虎机的政策优化技术，支持一般离线函数近似。通过重要性加权等技术手段，实现了计算效率与理论保证的平衡

Result: 首次获得高概率意义下的最优遗憾界：$\widetilde{O}(\sqrt{ K|\mathcal{A}|\log|\mathcal{F}|})$，其中K为轮次，$|\mathcal{A}|$为臂数，$|\mathcal{F}|$为函数类容量。算法具有计算高效性，并通过了实证评估验证

Conclusion: 成功弥合了上下文老虎机领域理论与实践的差距，证明了实践中的政策优化方法可以获得严格理论保证下的最优性能，为实际应用提供了理论支撑

Abstract: We present the first high-probability optimal regret bound for a policy optimization technique applied to the problem of stochastic contextual multi-armed bandit (CMAB) with general offline function approximation. Our algorithm is both efficient and achieves an optimal regret bound of $\widetilde{O}(\sqrt{ K|\mathcal{A}|\log|\mathcal{F}|})$, where $K$ is the number of rounds, $\mathcal{A}$ is the set of arms, and $\mathcal{F}$ is the function class used to approximate the losses. Our results bridge the gap between theory and practice, demonstrating that the widely used policy optimization methods for the contextual bandit problem can achieve a rigorously-proved optimal regret bound. We support our theoretical results with an empirical evaluation of our algorithm.

</details>


### [50] [Near-Optimal Regret for Policy Optimization in Contextual MDPs with General Offline Function Approximation](https://arxiv.org/abs/2602.13706)
*Orin Levy,Aviv Rosenberg,Alon Cohen,Yishay Mansour*

Main category: cs.LG

TL;DR: 本文提出首个针对一般离线函数逼近下的随机上下文马尔可夫决策过程的政策优化算法OPO-CMDP，并实现了关于状态空间|S|和行动空间|A|的最优遗憾界。


<details>
  <summary>Details</summary>
Motivation: 在函数逼近条件下求解上下文马尔可夫决策过程（CMDPs）是一个关键问题，但现有方法在遗憾界上对状态和行动空间的依赖性次优。本文旨在突破这一限制，提供更高效、理论更优的算法。

Method: 作者提出了OPO-CMDP算法，这是一种基于乐观主义策略优化的方法，适用于离线函数逼近场景。

Result: 该算法达到$\widetilde{O}(H^4\sqrt{T|S||A|\log(|\mathcal{F}||\mathcal{P}|)})$的高概率遗憾界，首次实现了在|S|和|A|上的最优依赖，较现有最先进结果（Qian, Hu, and Simchi-Levi, 2024）有直接改进。

Conclusion: 研究表明乐观政策优化是求解CMDPs的一种自然、计算高效且理论接近最优的有效途径。

Abstract: We introduce \texttt{OPO-CMDP}, the first policy optimization algorithm for stochastic Contextual Markov Decision Process (CMDPs) under general offline function approximation. Our approach achieves a high probability regret bound of $\widetilde{O}(H^4\sqrt{T|S||A|\log(|\mathcal{F}||\mathcal{P}|)}),$ where $S$ and $A$ denote the state and action spaces, $H$ the horizon length, $T$ the number of episodes, and $\mathcal{F}, \mathcal{P}$ the finite function classes used to approximate the losses and dynamics, respectively. This is the first regret bound with optimal dependence on $|S|$ and $|A|$, directly improving the current state-of-the-art (Qian, Hu, and Simchi-Levi, 2024). These results demonstrate that optimistic policy optimization provides a natural, computationally superior and theoretically near-optimal path for solving CMDPs.

</details>


### [51] [HBVLA: Pushing 1-Bit Post-Training Quantization for Vision-Language-Action Models](https://arxiv.org/abs/2602.13710)
*Xin Yan,Zhenglin Wan,Feiyang Ye,Xingrui Yu,Hangyu Du,Yang You,Ivor Tsang*

Main category: cs.LG

TL;DR: HBVLA框架通过策略感知Hessian识别关键权重、稀疏正交变换和Harr域分组量化，在保留92%以上VLA模型性能的同时实现1比特二值化压缩，为资源受限机器人提供可靠部署方案。


<details>
  <summary>Details</summary>
Motivation: VLA模型因计算和内存占用过高难以部署于资源受限的机器人平台。现有二值化方法无法缩小权重分布差距，导致长时闭环执行时量化误差累积，动作性能严重下降。

Method: 提出HBVLA框架：1）采用策略感知增强Hessian识别对动作生成至关重要的显著性权重；2）对非显著权重使用稀疏正交变换诱导低熵中间状态；3）在Harr域对两类权重进行分组1比特量化。

Result: LIBERO数据集上OpenVLA-OFT量化后保留92.2%全精度性能；SimplerEnv数据集上CogAct保留93.6%性能，显著优于现有最优二值化方法。真实世界评估显示仅轻微成功率下降。

Conclusion: 该工作为VLA超低比特量化提供了实用基础，使硬件受限的机器人平台能够实现更可靠的部署。

Abstract: Vision-Language-Action (VLA) models enable instruction-following embodied control, but their large compute and memory footprints hinder deployment on resource-constrained robots and edge platforms. While reducing weights to 1-bit precision through binarization can greatly improve efficiency, existing methods fail to narrow the distribution gap between binarized and full-precision weights, causing quantization errors to accumulate under long-horizon closed-loop execution and severely degrade actions. To fill this gap, we propose HBVLA, a VLA-tailored binarization framework. First, we use a policy-aware enhanced Hessian to identify weights that are truly critical for action generation. Then, we employ a sparse orthogonal transform for non-salient weights to induce a low-entropy intermediate state. Finally, we quantize both salient and non-salient weights in the Harr domain with group-wise 1-bit quantization. We have evaluated our approach on different VLAs: on LIBERO, quantized OpenVLA-OFT retains 92.2% of full-precision performance; on SimplerEnv, quantized CogAct retains 93.6%, significantly outperforming state-of-the-art binarization methods. We further validate our method on real-world evaluation suite and the results show that HBVLA incurs only marginal success-rate degradation compared to the full-precision model, demonstrating robust deployability under tight hardware constraints. Our work provides a practical foundation for ultra-low-bit quantization of VLAs, enabling more reliable deployment on hardware-limited robotic platforms.

</details>


### [52] [Data-driven Bi-level Optimization of Thermal Power Systems with embedded Artificial Neural Networks](https://arxiv.org/abs/2602.13746)
*Talha Ansar,Muhammad Mujtaba Abbas,Ramit Debnath,Vivek Dua,Waqar Muhammad Ashraf*

Main category: cs.LG

TL;DR: A machine learning-based bi-level optimization framework (ANN-KKT) is proposed for hierarchical optimization of industrial thermal power systems, validated on real coal and gas power plants with significant computational efficiency gains.


<details>
  <summary>Details</summary>
Motivation: Industrial thermal power systems have coupled performance variables with hierarchical importance, making simultaneous optimization computationally challenging or infeasible, which limits integrated and scalable operation optimization.

Method: A fully machine learning-powered bi-level optimization framework where upper and lower level objectives are approximated by artificial neural networks (ANN), and the lower-level problem is analytically embedded through Karush-Kuhn-Tucker (KKT) optimality conditions to form a single-level ANN-KKT optimization.

Result: The ANN-KKT framework produces comparable solutions to true bi-level optimization benchmarks with marginal computational time (0.22-0.88s). It achieved optimal outputs of 583MW (coal) and 402MW (gas turbine) at heat rates of 7337 kJ/kWh and 7542 kJ/kWh respectively. It can also delineate robust operating envelopes accounting for operational uncertainties.

Conclusion: The ANN-KKT framework provides a scalable, computationally efficient method for hierarchical, data-driven optimization of industrial thermal power systems, enabling energy-efficient operations for large-scale engineering systems and contributing to Industry 5.0.

Abstract: Industrial thermal power systems have coupled performance variables with hierarchical order of importance, making their simultaneous optimization computationally challenging or infeasible. This barrier limits the integrated and computationally scaleable operation optimization of industrial thermal power systems. To address this issue for large-scale engineering systems, we present a fully machine learning-powered bi-level optimization framework for data-driven optimization of industrial thermal power systems. The objective functions of upper and lower levels are approximated by artificial neural network (ANN) models and the lower-level problem is analytically embedded through Karush-Kuhn-Tucker (KKT) optimality conditions. The reformulated single level optimization framework integrating ANN models and KKT constraints (ANN-KKT) is validated on benchmark problems and on real-world power generation operation of 660 MW coal power plant and 395 MW gas turbine system. The results reveal a comparable solutions obtained from the proposed ANN-KKT framework to the bi-level solutions of the benchmark problems. Marginal computational time requirement (0.22 to 0.88 s) to compute optimal solutions yields 583 MW (coal) and 402 MW (gas turbine) of power output at optimal turbine heat rate of 7337 kJ/kWh and 7542 kJ/kWh, respectively. In addition, the method expands to delineate a feasible and robust operating envelope that accounts for uncertainty in operating variables while maximizing thermal efficiency in various scenarios. These results demonstrate that ANN-KKT offers a scalable and computationally efficient route for hierarchical, data-driven optimization of industrial thermal power systems, achieving energy-efficient operations of large-scale engineering systems and contributing to industry 5.0.

</details>


### [53] [Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition](https://arxiv.org/abs/2602.13759)
*ZhiMing Li,JiaHe Feng*

Main category: cs.LG

TL;DR: 提出一种离散双括号流方法解决矩阵无关特征分解问题，其核心创新是通过生成器各向同性移位不变性，使算法轨迹和最大稳定步长仅依赖于无迹协方差算子，实现全局收敛和O(log(1/ζ))鞍点逃离率，样本复杂度为O(||C_e||₂²/(Δ²ε))。


<details>
  <summary>Details</summary>
Motivation: 标准随机近似方法在矩阵无关特征分解中存在两大局限：固定步长需依赖完整协方差算子范数||C_k||₂保证稳定性，而自适应步长会因更新量消失导致收敛缓慢；此外，各向同性噪声σ_k²I的扰动会干扰算法性能。

Method: 引入离散双括号流，其生成器具有各向同性移位不变性，从而在离散时间层面实现路径级不变性。该方法仅通过无迹协方差算子C_e（去除σ_k²I部分）决定轨迹和最大稳定步长η_max ∝ 1/||C_e||₂²。

Result: 1) 通过严格鞍点几何和输入-状态稳定性分析，证明全局收敛性；2) 样本复杂度为O(||C_e||₂²/(Δ²ε))；3) 显式刻画退化块结构，实现加速的O(log(1/ζ))鞍点逃离率；4) 获得高概率有限时间收敛保证。

Conclusion: 该方法通过不变性设计有效隔离了各向同性扰动，仅依赖无迹部分的算子范数，在保持稳定性的同时实现了快速收敛，为含噪矩阵无关特征分解提供了理论保证更优的解决方案。

Abstract: We study matrix-free eigendecomposition under a matrix-vector product (MVP) oracle, where each step observes a covariance operator $C_k = C_{sig} + σ_k^2 I + E_k$. Standard stochastic approximation methods either use fixed steps that couple stability to $\|C_k\|_2$, or adapt steps in ways that slow down due to vanishing updates. We introduce a discrete double-bracket flow whose generator is invariant to isotropic shifts, yielding pathwise invariance to $σ_k^2 I$ at the discrete-time level. The resulting trajectory and a maximal stable step size $η_{max} \propto 1/\|C_e\|_2^2$ depend only on the trace-free covariance $C_e$. We establish global convergence via strict-saddle geometry for the diagonalization objective and an input-to-state stability analysis, with sample complexity scaling as $O(\|C_e\|_2^2 / (Δ^2 ε))$ under trace-free perturbations. An explicit characterization of degenerate blocks yields an accelerated $O(\log(1/ζ))$ saddle-escape rate and a high-probability finite-time convergence guarantee.

</details>


### [54] [On Representation Redundancy in Large-Scale Instruction Tuning Data Selection](https://arxiv.org/abs/2602.13773)
*Youwei Shu,Shaomian Zheng,Dingnan Jin,Wenjie Qu,Ziyao Guo,Qing Cui,Jun Zhou,Jiaheng Zhang*

Main category: cs.LG

TL;DR: 该论文针对指令微调中的数据选择问题，提出了压缩表示数据选择（CRDS）框架。通过解决现有LLM编码器产生的语义嵌入冗余问题，CRDS的两个变体（CRDS-R和CRDS-W）仅使用3.5%的数据就实现了超越全量数据基线的性能。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型训练中数据质量至关重要，但工业级指令微调的数据选择方法尚未得到充分探索。现有先进LLM编码器会产生高度冗余的语义嵌入，限制了数据选择的有效性。

Method: 提出CRDS框架，包含两个变体：CRDS-R采用Rademacher随机投影并拼接Transformer隐藏层表示；CRDS-W使用基于白化的降维方法来提升表示质量，从而缓解嵌入冗余。

Result: 两个CRDS变体均显著提升了数据质量，性能优于现有基于表示的选择方法。CRDS-W仅使用3.5%的数据就取得了强劲表现，在四个数据集上平均超越全量数据基线0.71%。

Conclusion: CRDS框架通过压缩表示有效解决了嵌入冗余问题，实现了高效高质量的指令微调数据选择，其中CRDS-W在极低选择率下展现出特别优越的性能。

Abstract: Data quality is a crucial factor in large language models training. While prior work has shown that models trained on smaller, high-quality datasets can outperform those trained on much larger but noisy or low-quality corpora, systematic methods for industrial-scale data selection in instruction tuning remain underexplored. In this work, we study instruction-tuning data selection through the lens of semantic representation similarity and identify a key limitation of state-of-the-art LLM encoders: they produce highly redundant semantic embeddings. To mitigate this redundancy, we propose Compressed Representation Data Selection (CRDS), a novel framework with two variants. CRDS-R applies Rademacher random projection followed by concatenation of transformer hidden-layer representations, while CRDS-W employs whitening-based dimensionality reduction to improve representational quality. Experimental results demonstrate that both variants substantially enhance data quality and consistently outperform state-of-the-art representation-based selection methods. Notably, CRDS-W achieves strong performance using only 3.5% of the data, surpassing the full-data baseline by an average of 0.71% across four datasets. Our code is available at https://github.com/tdano1/CRDS.

</details>


### [55] [MEMTS: Internalizing Domain Knowledge via Parameterized Memory for Retrieval-Free Domain Adaptation of Time Series Foundation Models](https://arxiv.org/abs/2602.13783)
*Xiaoyun Yu,Li fan,Xiangfei Qiu,Nanqing Dong,Yonggui Huang,Honggang Qi,Geguang Pu,Wanli Ouyang,Xi Chen,Jilin Hu*

Main category: cs.LG

TL;DR: The paper proposes MEMTS, a lightweight plug-and-play method for adapting Time Series Foundation Models to vertical domains without retrieval overhead or catastrophic forgetting, using a Knowledge Persistence Module that encodes domain patterns into learnable latent prototypes for constant-time inference.


<details>
  <summary>Details</summary>
Motivation: Time Series Foundation Models (TSFMs) suffer significant performance degradation when deployed in real-world vertical domains due to temporal distribution shifts and domain-specific periodic structures. Existing solutions like Domain-Adaptive Pretraining cause catastrophic forgetting of global patterns, while Retrieval-Augmented Generation introduces scalability bottlenecks with retrieval overhead that cannot meet real-time stream processing efficiency requirements.

Method: MEMTS introduces a Knowledge Persistence Module (KPM) that internalizes domain-specific temporal dynamics (seasonal patterns, trends) into a compact set of learnable latent prototypes. This transforms fragmented historical observations into continuous, parameterized knowledge representations, enabling retrieval-free domain adaptation without modifying the frozen TSFM backbone architecture.

Result: Extensive experiments on multiple datasets demonstrate that MEMTS achieves state-of-the-art (SOTA) performance in time series forecasting.

Conclusion: MEMTS successfully enables accurate domain adaptation with constant-time inference and near-zero latency while effectively mitigating catastrophic forgetting, providing a scalable solution for real-time stream processing applications without architectural modifications to pretrained models.

Abstract: While Time Series Foundation Models (TSFMs) have demonstrated exceptional performance in generalized forecasting, their performance often degrades significantly when deployed in real-world vertical domains characterized by temporal distribution shifts and domain-specific periodic structures. Current solutions are primarily constrained by two paradigms: Domain-Adaptive Pretraining (DAPT), which improves short-term domain fitting but frequently disrupts previously learned global temporal patterns due to catastrophic forgetting; and Retrieval-Augmented Generation (RAG), which incorporates external knowledge but introduces substantial retrieval overhead. This creates a severe scalability bottleneck that fails to meet the high-efficiency requirements of real-time stream processing. To break this impasse, we propose Memory for Time Series (MEMTS), a lightweight and plug-and-play method for retrieval-free domain adaptation in time series forecasting. The key component of MEMTS is a Knowledge Persistence Module (KPM), which internalizes domain-specific temporal dynamics, such as recurring seasonal patterns and trends into a compact set of learnable latent prototypes. In doing so, it transforms fragmented historical observations into continuous, parameterized knowledge representations. This paradigm shift enables MEMTS to achieve accurate domain adaptation with constant-time inference and near-zero latency, while effectively mitigating catastrophic forgetting of general temporal patterns, all without requiring any architectural modifications to the frozen TSFM backbone. Extensive experiments on multiple datasets demonstrate the SOTA performance of MEMTS.

</details>


### [56] [MechPert: Mechanistic Consensus as an Inductive Bias for Unseen Perturbation Prediction](https://arxiv.org/abs/2602.13791)
*Marc Boubnovski Martell,Josefa Lia Stoisser,Lawrence Phillips,Aditya Misra,Robert Kitchen,Jesper Ferkinghoff-Borg,Jialin Yu,Philip Torr,Kaspar Märten*

Main category: cs.LG

TL;DR: MechPert is a lightweight LLM framework using multiple agents to generate directed regulatory hypotheses for predicting transcriptional responses to genetic perturbations, improving low-data performance by up to 10.5% over baselines.


<details>
  <summary>Details</summary>
Motivation: Existing methods rely on static knowledge graphs or similarity-based language models that capture symmetric co-occurrence rather than directed regulatory logic, limiting prediction of unseen genetic perturbations.

Method: Multiple LLM agents independently propose candidate regulators with confidence scores, aggregated through a consensus mechanism that filters spurious associations to produce weighted neighborhoods for downstream prediction.

Result: On Perturb-seq benchmarks across four human cell lines, MechPert improved Pearson correlation by up to 10.5% over similarity-based baselines for N=50 perturbations, and its anchor genes outperformed network centrality heuristics by up to 46%.

Conclusion: MechPert demonstrates that encouraging LLMs to generate directed regulatory hypotheses is a promising approach for gene regulation prediction and prioritizing large-scale perturbation experiments.

Abstract: Predicting transcriptional responses to unseen genetic perturbations is essential for understanding gene regulation and prioritizing large-scale perturbation experiments. Existing approaches either rely on static, potentially incomplete knowledge graphs, or prompt language models for functionally similar genes, retrieving associations shaped by symmetric co-occurrence in scientific text rather than directed regulatory logic. We introduce MechPert, a lightweight framework that encourages LLM agents to generate directed regulatory hypotheses rather than relying solely on functional similarity. Multiple agents independently propose candidate regulators with associated confidence scores; these are aggregated through a consensus mechanism that filters spurious associations, producing weighted neighborhoods for downstream prediction. We evaluate MechPert on Perturb-seq benchmarks across four human cell lines. For perturbation prediction in low-data regimes ($N=50$ observed perturbations), MechPert improves Pearson correlation by up to 10.5\% over similarity-based baselines. For experimental design, MechPert-selected anchor genes outperform standard network centrality heuristics by up to 46\% in well-characterized cell lines.

</details>


### [57] [Cast-R1: Learning Tool-Augmented Sequential Decision Policies for Time Series Forecasting](https://arxiv.org/abs/2602.13802)
*Xiaoyu Tao,Mingyue Cheng,Chuang Jiang,Tian Gao,Huanjian Zhang,Yaguo Liu*

Main category: cs.LG

TL;DR: 提出Cast-R1框架，将时间序列预测重新定义为序列决策问题，通过记忆机制和工具增强的智能体工作流实现自主证据获取、推理和迭代优化，在多个真实数据集上验证有效。


<details>
  <summary>Details</summary>
Motivation: 传统模型中心化的时间序列预测方法采用单次映射，在复杂动态场景中表现不佳，因为现有模型缺乏自主获取信息、推理未来变化和迭代修正预测的能力。

Method: Cast-R1框架包含：1) 基于记忆的跨步骤状态管理，支持长时域推理；2) 工具增强的智能体工作流，自主调用统计特征提取、轻量预测模型和推理预测；3) 结合监督微调与多轮强化学习的两阶段训练策略，配合课程学习逐步提升任务难度。

Result: 在多个真实世界时间序列数据集上的大量实验证明了Cast-R1的有效性。

Conclusion: 该工作为探索时间序列建模的智能体范式提供了实践步骤，代码已开源。

Abstract: Time series forecasting has long been dominated by model-centric approaches that formulate prediction as a single-pass mapping from historical observations to future values. Despite recent progress, such formulations often struggle in complex and evolving settings, largely because most forecasting models lack the ability to autonomously acquire informative evidence, reason about potential future changes, or revise predictions through iterative decision processes. In this work, we propose Cast-R1, a learned time series forecasting framework that reformulates forecasting as a sequential decision-making problem. Cast-R1 introduces a memory-based state management mechanism that maintains decision-relevant information across interaction steps, enabling the accumulation of contextual evidence to support long-horizon reasoning. Building on this formulation, forecasting is carried out through a tool-augmented agentic workflow, in which the agent autonomously interacts with a modular toolkit to extract statistical features, invoke lightweight forecasting models for decision support, perform reasoning-based prediction, and iteratively refine forecasts through self-reflection. To train Cast-R1, we adopt a two-stage learning strategy that combines supervised fine-tuning with multi-turn reinforcement learning, together with a curriculum learning scheme that progressively increases task difficulty to improve policy learning. Extensive experiments on multiple real-world time series datasets demonstrate the effectiveness of Cast-R1. We hope this work provides a practical step towards further exploration of agentic paradigms for time series modeling. Our code is available at https://github.com/Xiaoyu-Tao/Cast-R1-TS.

</details>


### [58] [AnomaMind: Agentic Time Series Anomaly Detection with Tool-Augmented Reasoning](https://arxiv.org/abs/2602.13807)
*Xiaoyu Tao,Yuchong Wu,Mingyue Cheng,Ze Guo,Tian Gao*

Main category: cs.LG

TL;DR: This paper proposes AnomaMind, an agentic framework that reformulates time series anomaly detection as sequential decision-making with coarse-to-fine localization, multi-turn tool interactions, and self-reflection, using hybrid inference combining general-purpose models with reinforcement learning to improve performance on context-dependent anomalies.


<details>
  <summary>Details</summary>
Motivation: Existing time series anomaly detection methods treat the problem as purely discriminative prediction with fixed features, failing to handle context-dependent anomalies and diverse patterns due to lack of adaptive feature preparation, reasoning-aware detection, and iterative refinement during inference.

Method: The authors propose AnomaMind, an agentic framework that reformulates anomaly detection as sequential decision-making. The method features a coarse-to-fine workflow for anomaly localization, multi-turn tool interactions for adaptive feature preparation, and self-reflection for decision refinement. A hybrid inference mechanism combines general-purpose models (handling tool interaction and self-reflection) with reinforcement learning (optimizing core detection decisions under verifiable workflow-level feedback).

Result: Extensive experiments across diverse settings demonstrate that AnomaMind consistently improves anomaly detection performance compared to existing methods.

Conclusion: The agentic approach with structured reasoning, tool augmentation, and RL-based optimization effectively addresses limitations of traditional methods, providing a flexible framework for complex anomaly detection tasks requiring context awareness and iterative refinement.

Abstract: Time series anomaly detection is critical in many real-world applications, where effective solutions must localize anomalous regions and support reliable decision-making under complex settings. However, most existing methods frame anomaly detection as a purely discriminative prediction task with fixed feature inputs, rather than an evidence-driven diagnostic process. As a result, they often struggle when anomalies exhibit strong context dependence or diverse patterns. We argue that these limitations stem from the lack of adaptive feature preparation, reasoning-aware detection, and iterative refinement during inference. To address these challenges, we propose AnomaMind, an agentic time series anomaly detection framework that reformulates anomaly detection as a sequential decision-making process. AnomaMind operates through a structured workflow that progressively localizes anomalous intervals in a coarse-to-fine manner, augments detection through multi-turn tool interactions for adaptive feature preparation, and refines anomaly decisions via self-reflection. The workflow is supported by a set of reusable tool engines, enabling context-aware diagnostic analysis. A key design of AnomaMind is an explicitly designed hybrid inference mechanism for tool-augmented anomaly detection. In this mechanism, general-purpose models are responsible for autonomous tool interaction and self-reflective refinement, while core anomaly detection decisions are learned through reinforcement learning under verifiable workflow-level feedback, enabling task-specific optimization within a flexible reasoning framework. Extensive experiments across diverse settings demonstrate that AnomaMind consistently improves anomaly detection performance. The code is available at https://anonymous.4open.science/r/AnomaMind.

</details>


### [59] [Mean Flow Policy with Instantaneous Velocity Constraint for One-step Action Generation](https://arxiv.org/abs/2602.13810)
*Guojian Zhan,Letian Tao,Pengcheng Wang,Yixiao Wang,Yiheng Li,Yuxin Chen,Masayoshi Tomizuka,Shengbo Eben Li*

Main category: cs.LG

TL;DR: MVP (Mean Velocity Policy) 是一种新的生成式策略函数，通过建模平均速度场并引入瞬时速度约束(IVC)，在强化学习实现快速一步动作生成，在机器人操作任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 流策略在强化学习中面临表达力与计算负担之间的权衡，该权衡通常由流步数控制。需要一种既能保持高表达力又能实现快速采样的策略学习方法。

Method: 提出平均速度策略(MVP)，直接建模平均速度场实现一步动作生成。训练时引入瞬时速度约束(IVC)，该约束作为关键边界条件提升学习精度和策略表达力。

Result: 在Robomimic和OGBench的多个机器人操作任务上达到最先进的成功率，相比现有流策略基线在训练和推理速度上有显著提升。

Conclusion: IVC设计有效改善了学习准确性和策略表达力，使MVP成为表达性和高效性兼具的强化学习策略学习新方向。

Abstract: Learning expressive and efficient policy functions is a promising direction in reinforcement learning (RL). While flow-based policies have recently proven effective in modeling complex action distributions with a fast deterministic sampling process, they still face a trade-off between expressiveness and computational burden, which is typically controlled by the number of flow steps. In this work, we propose mean velocity policy (MVP), a new generative policy function that models the mean velocity field to achieve the fastest one-step action generation. To ensure its high expressiveness, an instantaneous velocity constraint (IVC) is introduced on the mean velocity field during training. We theoretically prove that this design explicitly serves as a crucial boundary condition, thereby improving learning accuracy and enhancing policy expressiveness. Empirically, our MVP achieves state-of-the-art success rates across several challenging robotic manipulation tasks from Robomimic and OGBench. It also delivers substantial improvements in training and inference speed over existing flow-based policy baselines.

</details>


### [60] [Pawsterior: Variational Flow Matching for Structured Simulation-Based Inference](https://arxiv.org/abs/2602.13813)
*Jorge Carrasco-Pollo,Floor Eijkelboom,Jan-Willem van de Meent*

Main category: cs.LG

TL;DR: 提出Pawsterior，一种变分流匹配框架，通过几何约束和变分参数化，解决带结构域（有界参数、离散-连续变量）的模拟推理问题，提升数值稳定性和后验保真度。


<details>
  <summary>Details</summary>
Motivation: 标准流匹配方法在无约束空间运行，但许多模拟推理问题涉及结构化域（如有界物理参数或混合离散-连续变量），这种失配导致学习效率低下且难以满足物理约束。

Method: 提出Pawsterior框架，基于CatFlow推广几何归纳偏置，形式化端点诱导的仿射几何约束原则，通过双边变分模型将域几何直接融入推理过程；采用变分参数化处理离散潜在结构。

Result: 在标准SBI基准测试中，分类器双样本检验性能持续改善，数值稳定性提升；首次使流匹配方法能够处理离散潜在结构（如切换系统）的任务。

Conclusion: Pawsterior通过同时解决几何约束和离散潜在结构问题，将流匹配扩展到更广泛的结构化SBI问题，开辟了新的应用场景。

Abstract: We introduce Pawsterior, a variational flow-matching framework for improved and extended simulation-based inference (SBI). Many SBI problems involve posteriors constrained by structured domains, such as bounded physical parameters or hybrid discrete-continuous variables, yet standard flow-matching methods typically operate in unconstrained spaces. This mismatch leads to inefficient learning and difficulty respecting physical constraints. Our contributions are twofold. First, generalizing the geometric inductive bias of CatFlow, we formalize endpoint-induced affine geometric confinement, a principle that incorporates domain geometry directly into the inference process via a two-sided variational model. This formulation improves numerical stability during sampling and leads to consistently better posterior fidelity, as demonstrated by improved classifier two-sample test performance across standard SBI benchmarks. Second, and more importantly, our variational parameterization enables SBI tasks involving discrete latent structure (e.g., switching systems) that are fundamentally incompatible with conventional flow-matching approaches. By addressing both geometric constraints and discrete latent structure, Pawsterior extends flow-matching to a broader class of structured SBI problems that were previously inaccessible.

</details>


### [61] [Testing For Distribution Shifts with Conditional Conformal Test Martingales](https://arxiv.org/abs/2602.13848)
*Shalev Shaer,Yarin Bar,Drew Prinster,Yaniv Romano*

Main category: cs.LG

TL;DR: 提出一种基于固定参考集的序贯分布漂移检测方法，通过显式考虑参考分布估计误差，避免了标准共形检验鞅（CTM）在检测时的污染问题，实现了随时有效的错误率控制和更快的检测速度。


<details>
  <summary>Details</summary>
Motivation: 标准CTM检测器通过不断将新样本加入参考集来评估异常性，但这种方法存在检验时污染问题：分布漂移后，新样本会污染参考集，稀释漂移证据，导致检测延迟增加和功效降低。

Method: 提出固定参考集条件下的共形检验鞅方法，核心是构建稳健鞅统计量，显式考虑有限参考集引起的估计误差，在给定参考数据条件下保持有效性。

Result: 理论获得随时有效的I类错误控制、渐进功效为1及有界期望检测延迟保证；实验表明比标准CTM检测漂移更快。

Conclusion: 该方法通过避免检验时污染，提供了一种强大可靠的分布漂移检测器，在保持统计保证的同时显著提升了检测效率。

Abstract: We propose a sequential test for detecting arbitrary distribution shifts that allows conformal test martingales (CTMs) to work under a fixed, reference-conditional setting. Existing CTM detectors construct test martingales by continually growing a reference set with each incoming sample, using it to assess how atypical the new sample is relative to past observations. While this design yields anytime-valid type-I error control, it suffers from test-time contamination: after a change, post-shift observations enter the reference set and dilute the evidence for distribution shift, increasing detection delay and reducing power.
  In contrast, our method avoids contamination by design by comparing each new sample to a fixed null reference dataset. Our main technical contribution is a robust martingale construction that remains valid conditional on the null reference data, achieved by explicitly accounting for the estimation error in the reference distribution induced by the finite reference set. This yields anytime-valid type-I error control together with guarantees of asymptotic power one and bounded expected detection delay. Empirically, our method detects shifts faster than standard CTMs, providing a powerful and reliable distribution-shift detector.

</details>


### [62] [sleep2vec: Unified Cross-Modal Alignment for Heterogeneous Nocturnal Biosignals](https://arxiv.org/abs/2602.13857)
*Weixuan Yuan,Zengrui Jin,Yichen Wang,Donglin Xie,Ziyi Ye,Chao Zhang,Xuesong Chen*

Main category: cs.LG

TL;DR: 提出sleep2vec，一个针对多样且不完全夜间生物信号的基础模型，通过跨模态对比学习实现统一表征，并在4.2万条记录上预训练，对传感器丢失和模态缺失具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统睡眠监测和临床诊断依赖多模态生物信号，但设备异构性和传感器频繁脱落导致统一建模困难，需要能够处理不完全数据和跨设备泛化的通用模型。

Method: 基于42,249条涵盖9种模态的夜间记录，采用人口统计学、年龄、站点和历史感知的InfoNCE损失进行对比预训练，利用元数据动态加权负样本以消除队列特异性捷径。

Result: 在睡眠分期和临床结局评估任务上持续超越基线模型，对任意模态子集和传感器丢失保持鲁棒性，首次揭示了夜间生物信号的缩放规律。

Conclusion: 统一跨模态对齐与原则性缩放策略结合，实现了标签高效、通用目的的夜间生物信号建模。

Abstract: Tasks ranging from sleep staging to clinical diagnosis traditionally rely on standard polysomnography (PSG) devices, bedside monitors and wearable devices, which capture diverse nocturnal biosignals (e.g., EEG, EOG, ECG, SpO$_2$). However, heterogeneity across devices and frequent sensor dropout pose significant challenges for unified modelling of these multimodal signals. We present \texttt{sleep2vec}, a foundation model for diverse and incomplete nocturnal biosignals that learns a shared representation via cross-modal alignment. \texttt{sleep2vec} is contrastively pre-trained on 42,249 overnight recordings spanning nine modalities using a \textit{Demography, Age, Site \& History-aware InfoNCE} objective that incorporates physiological and acquisition metadata (\textit{e.g.}, age, gender, recording site) to dynamically weight negatives and mitigate cohort-specific shortcuts. On downstream sleep staging and clinical outcome assessment, \texttt{sleep2vec} consistently outperforms strong baselines and remains robust to any subset of available modalities and sensor dropout. We further characterize, to our knowledge for the first time, scaling laws for nocturnal biosignals with respect to modality diversity and model capacity. Together, these results show that unified cross-modal alignment, coupled with principled scaling, enables label-efficient, general-purpose modelling of real-world nocturnal biosignals.

</details>


### [63] [Why Code, Why Now: Learnability, Computability, and the Real Limits of Machine Learning](https://arxiv.org/abs/2602.13934)
*Zhimin Zhao*

Main category: cs.LG

TL;DR: 该论文提出基于信息结构的可学习性五层等级体系，认为代码生成的可靠性源于其密集可验证的反馈结构，而强化学习缺乏这种特性。ML进步的上限取决于任务是否可学习，而非模型规模。


<details>
  <summary>Details</summary>
Motivation: 解释为什么代码生成比强化学习更可靠且可预测，挑战"单纯扩大模型规模就能解决ML挑战"的常见假设。

Method: 建立可学习性的五层等级体系，基于信息结构密度和反馈质量；形式化区分表达性、可计算性和可学习性三个计算问题属性，分析其相互关系。

Result: 发现反馈质量差异是分等级的而非二元的；提出统一模板明确结构差异；解释了监督学习在代码上可扩展而强化学习不可扩展的原因。

Conclusion: ML进展的瓶颈在于任务的可学习性而非模型规模，对"缩放即可解决一切"的假设提出质疑，为理解不同学习范式的根本限制提供了理论框架。

Abstract: Code generation has progressed more reliably than reinforcement learning, largely because code has an information structure that makes it learnable. Code provides dense, local, verifiable feedback at every token, whereas most reinforcement learning problems do not. This difference in feedback quality is not binary but graded. We propose a five-level hierarchy of learnability based on information structure and argue that the ceiling on ML progress depends less on model size than on whether a task is learnable at all. The hierarchy rests on a formal distinction among three properties of computational problems (expressibility, computability, and learnability). We establish their pairwise relationships, including where implications hold and where they fail, and present a unified template that makes the structural differences explicit. The analysis suggests why supervised learning on code scales predictably while reinforcement learning does not, and why the common assumption that scaling alone will solve remaining ML challenges warrants scrutiny.

</details>


### [64] [A Multi-Agent Framework for Code-Guided, Modular, and Verifiable Automated Machine Learning](https://arxiv.org/abs/2602.13937)
*Dat Le,Duc-Cuong Le,Anh-Son Nguyen,Tuan-Dung Bui,Thu-Trang Nguyen,Son Nguyen,Hieu Dinh Vo*

Main category: cs.LG

TL;DR: 本文提出iML多智能体框架，通过代码引导规划、模块化实现和可验证集成解决AutoML黑盒问题与LLM智能体的幻觉逻辑缺陷，在真实Kaggle数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统AutoML框架透明度不足，而LLM智能体因单块代码生成常产生幻觉逻辑和运行时不可恢复的故障，缺乏灵活性。

Method: iML框架包含三核心：1)代码引导规划通过自主经验分析生成战略蓝图以消除幻觉；2)代码模块化实现将预处理与建模解耦为严格接口合约的专用组件；3)代码可验证集成通过动态合约验证与迭代自纠正确保物理可行性。

Result: 在MLE-BENCH上达到85%有效提交率、45%奖牌率及0.77平均APS；在iML-BENCH上APS提升38%-163%；即使任务描述被剥离仍能保持70%成功率。

Conclusion: iML桥接了随机生成与可靠工程的鸿沟，显著提升AutoML的可靠性与透明度，向真正的自动化机器学习迈进重要一步。

Abstract: Automated Machine Learning (AutoML) has revolutionized the development of data-driven solutions; however, traditional frameworks often function as "black boxes", lacking the flexibility and transparency required for complex, real-world engineering tasks. Recent Large Language Model (LLM)-based agents have shifted toward code-driven approaches. However, they frequently suffer from hallucinated logic and logic entanglement, where monolithic code generation leads to unrecoverable runtime failures. In this paper, we present iML, a novel multi-agent framework designed to shift AutoML from black-box prompting to a code-guided, modular, and verifiable architectural paradigm. iML introduces three main ideas: (1) Code-Guided Planning, which synthesizes a strategic blueprint grounded in autonomous empirical profiling to eliminate hallucination; (2) Code-Modular Implementation, which decouples preprocessing and modeling into specialized components governed by strict interface contracts; and (3) Code-Verifiable Integration, which enforces physical feasibility through dynamic contract verification and iterative self-correction. We evaluate iML across MLE-BENCH and the newly introduced iML-BENCH, comprising a diverse range of real-world Kaggle competitions. The experimental results show iML's superiority over state-of-the-art agents, achieving a valid submission rate of 85% and a competitive medal rate of 45% on MLE-BENCH, with an average standardized performance score (APS) of 0.77. On iML-BENCH, iML significantly outperforms the other approaches by 38%-163% in APS. Furthermore, iML maintains a robust 70% success rate even under stripped task descriptions, effectively filling information gaps through empirical profiling. These results highlight iML's potential to bridge the gap between stochastic generation and reliable engineering, marking a meaningful step toward truly AutoML.

</details>


### [65] [An Adaptive Model Selection Framework for Demand Forecasting under Horizon-Induced Degradation to Support Business Strategy and Operations](https://arxiv.org/abs/2602.13939)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: This paper proposes AHSIV, an adaptive hybrid model selection framework that uses horizon-aware and regime-conditioned approaches to solve forecasting ranking instability in intermittent demand environments, achieving better horizon-specific selection while matching overall performance.


<details>
  <summary>Details</summary>
Motivation: Business environments with structural demand intermittency, high variability, and multi-step planning horizons lack robust model selection mechanisms, as no forecasting model is universally dominant and rankings vary across error metrics, demand regimes, and forecast horizons.

Method: AHSIV integrates scaled and absolute error metrics adjusted through Metric Degradation by Forecast Horizon (MDFH), structural demand classification, multi-objective Pareto dominance, and hierarchical bias refinement. Evaluated on Walmart, M3, M4, and M5 datasets with multiple train-test partitions and twelve-step horizons.

Result: AHSIV achieves statistical equivalence with the strongest monometric baseline in aggregated performance while increasing the frequency of horizon-specific best-model selection.

Conclusion: Model selection in heterogeneous demand environments cannot be treated as a static ranking problem; horizon-consistent, structurally adaptive mechanisms provide a principled, operationally coherent solution for multi-SKU forecasting.

Abstract: Business environments characterized by structural demand intermittency, high variability, and multi-step planning horizons require robust and reproducible model selection mechanisms. Empirical evidence shows that no forecasting model is universally dominant and that relative rankings vary across error metrics, demand regimes, and forecast horizons, generating ambiguity in multi-SKU decision contexts. This study proposes AHSIV (Adaptive Hybrid Selector for Intermittency and Variability), a horizon-aware and regime-conditioned model selection framework designed to address horizon-induced ranking instability. The proposed approach integrates scaled and absolute error metrics adjusted through a Metric Degradation by Forecast Horizon (MDFH) procedure, structural demand classification, multi-objective Pareto dominance, and hierarchical bias refinement within a unified decision architecture. The empirical evaluation is conducted on the Walmart, M3, M4, and M5 datasets under multiple train-test partition schemes and twelve-step forecasting horizons. Results indicate that AHSIV achieves statistical equivalence with the strongest monometric baseline in terms of aggregated performance while increasing the frequency of horizon-specific best-model selection. The findings demonstrate that model selection in heterogeneous demand environments cannot be treated as a static ranking problem, and that horizon-consistent, structurally adaptive mechanisms provide a principled, operationally coherent solution for multi-SKU forecasting.

</details>


### [66] [You Can Learn Tokenization End-to-End with Reinforcement Learning](https://arxiv.org/abs/2602.13940)
*Sam Dauncey,Roger Wattenhofer*

Main category: cs.LG

TL;DR: The paper proposes learning discrete token boundaries in LLMs using score function estimates with reinforcement learning variance reduction techniques, outperforming prior straight-through methods at 100M parameter scale.


<details>
  <summary>Details</summary>
Motivation: Tokenization is a hardcoded compression step that remains in LLM training despite trends toward end-to-end architectures, and existing methods for learning token boundaries have limitations.

Method: They use score function estimates to learn token boundaries with tighter theoretical guarantees, incorporating reinforcement learning techniques like time discounting to reduce variance.

Result: The proposed method outperforms prior straight-through estimates both qualitatively and quantitatively at the 100 million parameter scale.

Conclusion: Learning token boundaries directly using score function estimates is a more effective approach than treating the problem as continuous.

Abstract: Tokenization is a hardcoded compression step which remains in the training pipeline of Large Language Models (LLMs), despite a general trend towards architectures becoming increasingly end-to-end. Prior work has shown promising results at scale in bringing this compression step inside the LLMs' architecture with heuristics to draw token boundaries, and also attempts to learn these token boundaries with straight-through estimates, which treat the problem of drawing discrete token boundaries as a continuous one. We show that these token boundaries can instead be learned using score function estimates, which have tighter theoretical guarantees due to directly optimizing the problem of drawing discrete token boundaries to minimize loss. We observe that techniques from reinforcement learning, such as time discounting, are necessary to reduce the variance of this score function sufficiently to make it practicable. We demonstrate that the resultant method outperforms prior proposed straight-through estimates, both qualitatively and quantitatively at the $100$ million parameter scale.

</details>


### [67] [Experiential Reinforcement Learning](https://arxiv.org/abs/2602.13949)
*Taiwei Shi,Sihao Chen,Bowen Jiang,Linxin Song,Longqi Yang,Jieyu Zhao*

Main category: cs.LG

TL;DR: 本文提出经验强化学习(ERL)，通过在强化学习过程中嵌入明确的经验-反思-巩固循环，使语言模型能够从稀疏奖励中有效学习，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型通过强化学习从环境反馈中学习时，反馈通常是稀疏且延迟的，这种信号使得学习过程充满挑战。

Method: 提出经验强化学习(ERL)训练范式，在RL过程中嵌入明确的经验-反思-巩固循环：模型生成初始尝试，获得环境反馈，产生反思指导 refined 第二次尝试，将成功经验强化并内化到基础策略中。

Result: 在稀疏奖励控制环境和智能体推理基准测试中，ERL持续优于强强化学习基线，在复杂多步环境中提升高达+81%，在工具使用推理任务中提升高达+11%。

Conclusion: 将明确自我反思整合到策略训练中，为将反馈转化为持久的行为改进提供了实用机制。

Abstract: Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop into the reinforcement learning process. Given a task, the model generates an initial attempt, receives environmental feedback, and produces a reflection that guides a refined second attempt, whose success is reinforced and internalized into the base policy. This process converts feedback into structured behavioral revision, improving exploration and stabilizing optimization while preserving gains at deployment without additional inference cost. Across sparse-reward control environments and agentic reasoning benchmarks, ERL consistently improves learning efficiency and final performance over strong reinforcement learning baselines, achieving gains of up to +81% in complex multi-step environments and up to +11% in tool-using reasoning tasks. These results suggest that integrating explicit self-reflection into policy training provides a practical mechanism for transforming feedback into durable behavioral improvement.

</details>


### [68] [QuRL: Efficient Reinforcement Learning with Quantized Rollout](https://arxiv.org/abs/2602.13953)
*Yuhang Li,Reena Elangovan,Xin Dong,Priyadarshini Panda,Brucek Khailany*

Main category: cs.LG

TL;DR: 针对RLVR训练中LLM自回归解码导致70%时间消耗在rollout的问题，提出QuRL量化强化学习方法，通过自适应裁剪范围(ACR)和不变缩放技术解决量化训练崩溃与权重更新问题，实现20%-80%的rollout加速


<details>
  <summary>Details</summary>
Motivation: 推理大语言模型(LLM)的强化学习训练中，自回归解码特性使rollout过程成为效率瓶颈（占70%总训练时间），亟需加速方法

Method: 1) 自适应裁剪范围(ACR)：根据全精度/量化actor的策略比动态调整裁剪比例，防止长期训练崩溃；2) 不变缩放技术：缓解RL步骤间权重变化过小导致的量化噪声问题，增强权重更新有效性

Result: 在DeepScaleR和DAPO框架上进行INT8/FP8量化实验，训练期间rollout速度提升20%-80%

Conclusion: QuRL通过量化actor有效突破RL训练rollout瓶颈，在保持训练稳定性的同时显著提升效率，为LLM强化学习提供实用加速方案

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a trending paradigm for training reasoning large language models (LLMs). However, due to the autoregressive decoding nature of LLMs, the rollout process becomes the efficiency bottleneck of RL training, consisting of up to 70\% of the total training time. In this work, we propose Quantized Reinforcement Learning (QuRL) that uses a quantized actor for accelerating the rollout. We address two challenges in QuRL. First, we propose Adaptive Clipping Range (ACR) that dynamically adjusts the clipping ratio based on the policy ratio between the full-precision actor and the quantized actor, which is essential for mitigating long-term training collapse. Second, we identify the weight update problem, where weight changes between RL steps are extremely small, making it difficult for the quantization operation to capture them effectively. We mitigate this problem through the invariant scaling technique that reduces quantization noise and increases weight update. We evaluate our method with INT8 and FP8 quantization experiments on DeepScaleR and DAPO, and achieve 20% to 80% faster rollout during training.

</details>


### [69] [Steady-State Behavior of Constant-Stepsize Stochastic Approximation: Gaussian Approximation and Tail Bounds](https://arxiv.org/abs/2602.13960)
*Zedong Wang,Yuyang Wang,Ijay Narang,Felix Wang,Yuzhou Wang,Siva Theja Maguluri*

Main category: cs.LG

TL;DR: 本文为固定步长的随机逼近算法提供了显式、非渐近的高斯分布逼近误差界，解决了实际应用中无法获得可用误差界的问题。


<details>
  <summary>Details</summary>
Motivation: 固定步长随机逼近在计算效率上被广泛使用，但现有理论只提供了步长趋于零时的弱收敛结果，缺乏对固定步长下稳态分布逼近误差的显式量化，这在实际应用中价值有限。

Method: 通过建立一般性定理，在漂移项正则性和噪声矩条件下，给出中心化缩放稳态与高斯分布之间的Wasserstein距离界；涵盖i.i.d.和马尔可夫噪声模型；并将其应用于三种典型场景：强凸SGD、线性SA和压缩非线性SA。

Result: 对于小步长α，获得维度与步长相关的显式Wasserstein误差界，阶数为α^(1/2)log(1/α)；进一步导出非均匀Berry-Esseen型尾部概率界，误差项在偏离水平和步长上均衰减；对一般凸目标发现非高斯(Gibbs)极限律并给出相应的Wasserstein误差界。

Conclusion: 本文为固定步长随机逼近提供了可量化的高斯/吉布斯逼近误差界，增强了该理论在实际学习问题中的可用性，并为理解固定步长下的稳态分布提供了新工具。

Abstract: Constant-stepsize stochastic approximation (SA) is widely used in learning for computational efficiency. For a fixed stepsize, the iterates typically admit a stationary distribution that is rarely tractable. Prior work shows that as the stepsize $α\downarrow 0$, the centered-and-scaled steady state converges weakly to a Gaussian random vector. However, for fixed $α$, this weak convergence offers no usable error bound for approximating the steady-state by its Gaussian limit. This paper provides explicit, non-asymptotic error bounds for fixed $α$. We first prove general-purpose theorems that bound the Wasserstein distance between the centered-scaled steady state and an appropriate Gaussian distribution, under regularity conditions for drift and moment conditions for noise. To ensure broad applicability, we cover both i.i.d. and Markovian noise models. We then instantiate these theorems for three representative SA settings: (1) stochastic gradient descent (SGD) for smooth strongly convex objectives, (2) linear SA, and (3) contractive nonlinear SA. We obtain dimension- and stepsize-dependent, explicit bounds in Wasserstein distance of order $α^{1/2}\log(1/α)$ for small $α$. Building on the Wasserstein approximation error, we further derive non-uniform Berry--Esseen-type tail bounds that compare the steady-state tail probability to Gaussian tails. We achieve an explicit error term that decays in both the deviation level and stepsize $α$. We adapt the same analysis for SGD beyond strongly convexity and study general convex objectives. We identify a non-Gaussian (Gibbs) limiting law under the correct scaling, which is validated numerically, and provide a corresponding pre-limit Wasserstein error bound.

</details>


### [70] [S2SServiceBench: A Multimodal Benchmark for Last-Mile S2S Climate Services](https://arxiv.org/abs/2602.14017)
*Chenyue Li,Wen Deng,Zhuotao Sun,Mengxi Jin,Hanzhe Cui,Han Li,Shentong Li,Man Kit Yu,Ming Long Lai,Yuhao Yang,Mengqian Lu,Binhang Yuan*

Main category: cs.LG

TL;DR: The paper introduces S2SServiceBench, a multimodal benchmark evaluating MLLMs' ability to translate subseasonal-to-seasonal climate forecasts into actionable services. Benchmarking reveals persistent challenges in uncertainty reasoning and signal comprehension across 10 service products, providing guidance for developing future climate-service agents.


<details>
  <summary>Details</summary>
Motivation: A "last-mile gap" exists in translating S2S scientific forecasts into actionable climate services, requiring reliable multimodal understanding and decision-making under uncertainty. While MLLMs have advanced, their capability to handle this complex operational translation remains unclear.

Method: Curated S2SServiceBench from an operational climate-service system with 10 service products, ~150 expert cases across 6 domains (Agriculture, Disasters, Energy, Finance, Health, Shipping), 3 service levels per case, totaling ~500 tasks and 1,000+ evaluation items to benchmark MLLMs and agents.

Result: Benchmarking state-of-the-art models revealed persistent challenges: actionable signal comprehension, operationalizing uncertainty into executable handoffs, and stable evidence-grounded analysis for dynamic hazards. Performance varies significantly across products and service levels.

Conclusion: Current MLLMs struggle to reliably bridge the last-mile gap in climate services. The benchmark identifies critical capability gaps and provides actionable guidance for building future climate-service agents that can effectively translate forecasts into trusted, actionable decision support.

Abstract: Subseasonal-to-seasonal (S2S) forecasts play an essential role in providing a decision-critical weeks-to-months planning window for climate resilience and sustainability, yet a growing bottleneck is the last-mile gap: translating scientific forecasts into trusted, actionable climate services, requiring reliable multimodal understanding and decision-facing reasoning under uncertainty. Meanwhile, multimodal large language models (MLLMs) and corresponding agentic paradigms have made rapid progress in supporting various workflows, but it remains unclear whether they can reliably generate decision-making deliverables from operational service products (e.g., actionable signal comprehension, decision-making handoff, and decision analysis & planning) under uncertainty. We introduce S2SServiceBench, a multimodal benchmark for last-mile S2S climate services curated from an operational climate-service system to evaluate this capability. S2SServiceBenchcovers 10 service products with about 150+ expert-selected cases in total, spanning six application domains - Agriculture, Disasters, Energy, Finance, Health, and Shipping. Each case is instantiated at three service levels, yielding around 500 tasks and 1,000+ evaluation items across climate resilience and sustainability applications. Using S2SServiceBench, we benchmark state-of-the-art MLLMs and agents, and analyze performance across products and service levels, revealing persistent challenges in S2S service plot understanding and reasoning - namely, actionable signal comprehension, operationalizing uncertainty into executable handoffs, and stable, evidence-grounded analysis and planning for dynamic hazards-while offering actionable guidance for building future climate-service agents.

</details>


### [71] [EIDOS: Latent-Space Predictive Learning for Time Series Foundation Models](https://arxiv.org/abs/2602.14024)
*Xinxing Zhou,Qingren Yao,Yiji Zhao,Chenghao Liu,Flora Salim,Xiaojie Yuan,Yanlong Wen,Ming Jin*

Main category: cs.LG

TL;DR: 提出EIDOS时间序列基础模型，将预训练目标从未来值预测转向潜在空间动态预测，通过因果Transformer和轻量级聚合分支学习结构化潜在表示，在GIFT-Eval上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型通过直接预测未来观测值进行预训练，导致潜在表示结构松散、易捕获噪声而非连贯的时间动态，影响模型鲁棒性

Method: 设计EIDOS框架：使用因果Transformer预测潜在表示演化，构建轻量级聚合分支生成稳定目标，采用联合目标函数整合潜在空间对齐、观测锚定和预测监督

Result: 在GIFT-Eval基准上缓解了表示空间结构碎片化问题，达到最先进性能，证明了学习可预测潜在动态的有效性

Conclusion: 约束模型学习可预测的潜在动态是构建更稳健可靠时间序列基础模型的原则性改进方向

Abstract: Most time series foundation models are pretrained by directly predicting future observations, which often yields weakly structured latent representations that capture surface noise rather than coherent and predictable temporal dynamics. In this work, we introduce EIDOS, a foundation model family that shifts pretraining from future value prediction to latent-space predictive learning. We train a causal Transformer to predict the evolution of latent representations, encouraging the emergence of structured and temporally coherent latent states. To ensure stable targets for latent-space learning, we design a lightweight aggregation branch to construct target representations. EIDOS is optimized via a joint objective that integrates latent-space alignment, observational grounding to anchor representations to the input signal, and direct forecasting supervision. On the GIFT-Eval benchmark, EIDOS mitigates structural fragmentation in the representation space and achieves state-of-the-art performance. These results demonstrate that constraining models to learn predictable latent dynamics is a principled step toward more robust and reliable time series foundation models.

</details>


### [72] [UniST-Pred: A Robust Unified Framework for Spatio-Temporal Traffic Forecasting in Transportation Networks Under Disruptions](https://arxiv.org/abs/2602.14049)
*Yue Wang,Areg Karapetyan,Djellel Difallah,Samer Madanat*

Main category: cs.LG

TL;DR: Proposes UniST-Pred, a decoupled spatio-temporal traffic forecasting framework that first separately models temporal dynamics and spatial representations before adaptive fusion, demonstrating robustness under network disruptions while maintaining competitive performance with lightweight design.


<details>
  <summary>Details</summary>
Motivation: Real-world traffic forecasting faces structural/observational uncertainties rarely addressed in model design; existing methods either sacrifice modularity (tightly coupled models) or spatial modeling (efficient time-series models), limiting robustness in infrastructure disruptions.

Method: Decouples temporal modeling from spatial representation learning, then integrates both via adaptive representation-level fusion; evaluated on simulated dataset (MATSim) with severe network disconnections and standard real-world traffic prediction benchmarks.

Result: Maintains strong predictive performance across real-world/simulated datasets under infrastructure disruptions; achieves competitive accuracy against established models despite lightweight architecture; generates interpretable spatio-temporal representations during network failures.

Conclusion: Decoupled design enhances robustness to structural uncertainties without complexity trade-offs, offering a unified, modular solution for reliable traffic forecasting in real-world deployment scenarios with infrastructure disruptions.

Abstract: Spatio-temporal traffic forecasting is a core component of intelligent transportation systems, supporting various downstream tasks such as signal control and network-level traffic management. In real-world deployments, forecasting models must operate under structural and observational uncertainties, conditions that are rarely considered in model design. Recent approaches achieve strong short-term predictive performance by tightly coupling spatial and temporal modeling, often at the cost of increased complexity and limited modularity. In contrast, efficient time-series models capture long-range temporal dependencies without relying on explicit network structure. We propose UniST-Pred, a unified spatio-temporal forecasting framework that first decouples temporal modeling from spatial representation learning, then integrates both through adaptive representation-level fusion. To assess robustness of the proposed approach, we construct a dataset based on an agent-based, microscopic traffic simulator (MATSim) and evaluate UniST-Pred under severe network disconnection scenarios. Additionally, we benchmark UniST-Pred on standard traffic prediction datasets, demonstrating its competitive performance against existing well-established models despite a lightweight design. The results illustrate that UniST-Pred maintains strong predictive performance across both real-world and simulated datasets, while also yielding interpretable spatio-temporal representations under infrastructure disruptions. The source code and the generated dataset are available at https://anonymous.4open.science/r/UniST-Pred-EF27

</details>


### [73] [Position Encoding with Random Float Sampling Enhances Length Generalization of Transformers](https://arxiv.org/abs/2602.14050)
*Atsushi Shimizu,Shohei Taniguchi,Yutaka Matsuo*

Main category: cs.LG

TL;DR: 本文提出了一种名为随机浮点采样(RFS)的位置编码策略，通过训练时使用随机连续值而非固定离散索引，显著提升了语言模型在未见长度输入上的泛化能力，并可轻松集成到现有编码方案中。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在预训练时见过的输入长度有限，在处理更长输入时会出现性能下降问题。传统位置编码使用预定义离散位置索引，导致在未见长度上出现分布外(OOD)问题。

Method: 提出随机浮点采样(RFS)位置编码策略，在训练时随机采样连续值作为位置索引，使模型接触多样化的索引，避免OOD问题。该方法可与绝对正弦编码、RoPE和ALiBi等现有编码方案结合。

Result: 实验表明，RFS在长度泛化任务和零样本常识推理基准测试中均表现出优越性能。

Conclusion: RFS是一种简单而有效的位置编码方法，能显著提升语言模型处理超长输入的能力，具有广泛的适用性和实用价值。

Abstract: Length generalization is the ability of language models to maintain performance on inputs longer than those seen during pretraining. In this work, we introduce a simple yet powerful position encoding (PE) strategy, Random Float Sampling (RFS), that generalizes well to lengths unseen during pretraining or fine-tuning. In particular, instead of selecting position indices from a predefined discrete set, RFS uses randomly sampled continuous values, thereby avoiding out-of-distribution (OOD) issues on unseen lengths by exposing the model to diverse indices during training. Since assigning indices to tokens is a common and fundamental procedure in widely used PEs, the advantage of RFS can easily be incorporated into, for instance, the absolute sinusoidal encoding, RoPE, and ALiBi. Experiments corroborate its effectiveness by showing that RFS results in superior performance in length generalization tasks as well as zero-shot commonsense reasoning benchmarks.

</details>


### [74] [Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning](https://arxiv.org/abs/2602.14078)
*Yaqian Zhang,Bernhard Pfahringer,Eibe Frank,Albert Bifet*

Main category: cs.LG

TL;DR: Proposes Expected Policy Gradient (EPG) method that directly minimizes 0-1 loss via reinforcement learning for class-incremental learning, with adaptive entropy annealing (aEPG) strategy that outperforms cross-entropy-based methods by transitioning from exploratory to exploitative learning.


<details>
  <summary>Details</summary>
Motivation: Large pretrained vision models suffer from catastrophic forgetting when adapted to new tasks in class-incremental settings. Parameter-efficient fine-tuning (PEFT) helps but still relies on cross-entropy loss, a surrogate for the true objective (0-1 loss).

Method: Formulates classification as a one-step Markov Decision Process to derive Expected Policy Gradient (EPG) that directly minimizes misclassification error. Proposes adaptive entropy annealing (aEPG) that transitions from CE-like exploratory to EPG-like exploitative learning.

Result: aEPG-based methods outperform CE-based methods across diverse benchmarks and with various PEFT modules. Demonstrates that lower entropy of output prediction distribution enhances adaptation.

Conclusion: Reinforcement learning perspective reveals CE and EPG as complementary strategies; aEPG's adaptive approach provides superior performance for class-incremental learning, showing the importance of low-entropy predictions.

Abstract: Despite their success, large pretrained vision models remain vulnerable to catastrophic forgetting when adapted to new tasks in class-incremental settings. Parameter-efficient fine-tuning (PEFT) alleviates this by restricting trainable parameters, yet most approaches still rely on cross-entropy (CE) loss, a surrogate for the 0-1 loss, to learn from new data. We revisit this choice and revive the true objective (0-1 loss) through a reinforcement learning perspective. By formulating classification as a one-step Markov Decision Process, we derive an Expected Policy Gradient (EPG) method that directly minimizes misclassification error with a low-variance gradient estimation. Our analysis shows that CE can be interpreted as EPG with an additional sample-weighting mechanism: CE encourages exploration by emphasizing low-confidence samples, while EPG prioritizes high-confidence ones. Building on this insight, we propose adaptive entropy annealing (aEPG), a training strategy that transitions from exploratory (CE-like) to exploitative (EPG-like) learning. aEPG-based methods outperform CE-based methods across diverse benchmarks and with various PEFT modules. More broadly, we evaluate various entropy regularization methods and demonstrate that lower entropy of the output prediction distribution enhances adaptation in pretrained vision models.

</details>


### [75] [Neural Optimal Transport in Hilbert Spaces: Characterizing Spurious Solutions and Gaussian Smoothing](https://arxiv.org/abs/2602.14086)
*Jae-Hwan Choi,Jiwoo Yoon,Dohyun Kwon,Jaewoong Choi*

Main category: cs.LG

TL;DR: 针对无限维希尔伯特空间中的神经最优传输问题，半对偶方法在非正则设置下会产生伪解。本文通过正则测度框架分析该问题，提出基于布朗运动的高斯平滑策略，理论证明了在正则源测度下的适定性及唯一蒙日映射，并揭示了平滑效果与协方差算子核的严格依赖关系，实验验证了方法有效性。


<details>
  <summary>Details</summary>
Motivation: 在无限维希尔伯特空间中，非正则设置下的半对偶神经最优传输会产生伪解，无法准确捕捉目标分布，现有方法存在局限性。

Method: 采用正则测度框架分析伪解问题，通过布朗运动引入高斯平滑策略扩展半对偶框架，从理论上证明了算法适定性。

Result: 理论证明了正则源测度下问题的适定性及唯一蒙日映射的存在性，建立了平滑测度正则性的精确刻画，发现平滑成功与否严格依赖于协方差算子的核；在合成函数数据和时序数据集上的实验表明，该方法有效抑制了伪解并优于现有基线。

Conclusion: 提出的高斯平滑策略成功解决了无限维神经最优传输的伪解问题，理论分析揭示了平滑机制的关键条件，为处理无限维最优传输提供了有效方法。

Abstract: We study Neural Optimal Transport in infinite-dimensional Hilbert spaces. In non-regular settings, Semi-dual Neural OT often generates spurious solutions that fail to accurately capture target distributions. We analytically characterize this spurious solution problem using the framework of regular measures, which generalize Lebesgue absolute continuity in finite dimensions. To resolve ill-posedness, we extend the semi-dual framework via a Gaussian smoothing strategy based on Brownian motion. Our primary theoretical contribution proves that under a regular source measure, the formulation is well-posed and recovers a unique Monge map. Furthermore, we establish a sharp characterization for the regularity of smoothed measures, proving that the success of smoothing depends strictly on the kernel of the covariance operator. Empirical results on synthetic functional data and time-series datasets demonstrate that our approach effectively suppresses spurious solutions and outperforms existing baselines.

</details>


### [76] [Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines?](https://arxiv.org/abs/2602.14111)
*Anton Korznikov,Andrey Galichin,Alexey Dontsov,Oleg Rogov,Ivan Oseledets,Elena Tutubalina*

Main category: cs.LG

TL;DR: Sparse Autoencoders fail to recover meaningful interpretable features despite achieving high reconstruction quality, performing no better than random baselines.


<details>
  <summary>Details</summary>
Motivation: Despite excitement about SAEs for interpreting neural networks, growing negative results in downstream tasks cast doubt on whether they actually recover meaningful features.

Method: Two complementary evaluations: (1) testing SAEs on synthetic data with known ground-truth features; (2) introducing three random baselines that constrain feature directions or activation patterns to random values, then comparing against fully-trained SAEs across multiple architectures on interpretability, sparse probing, and causal editing tasks.

Result: On synthetic data, SAEs recover only 9% of true features despite 71% explained variance. On real activations, random baselines match fully-trained SAEs nearly perfectly: interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72).

Conclusion: Current SAEs do not reliably decompose models' internal mechanisms into meaningful features, suggesting their apparent success may not reflect genuine feature discovery.

Abstract: Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, a growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On a synthetic setup with known ground-truth features, we demonstrate that SAEs recover only $9\%$ of true features despite achieving $71\%$ explained variance, showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations, we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models' internal mechanisms.

</details>


### [77] [A Penalty Approach for Differentiation Through Black-Box Quadratic Programming Solvers](https://arxiv.org/abs/2602.14154)
*Yuxuan Linghu,Zhiyuan Liu,Qi Deng*

Main category: cs.LG

TL;DR: dXPP是一个用于二次规划求导的惩罚式框架，它将求解与求导解耦，前向传播使用任意QP求解器，反向传播通过光滑近似惩罚问题进行隐式求导，仅需求解更小规模的线性系统，在大规模问题上比KKT方法更高效鲁棒。


<details>
  <summary>Details</summary>
Motivation: 在可微优化中，对二次规划(QP)解进行求导是核心问题。现有方法通过KKT系统求导，但在大规模场景下计算成本高且数值鲁棒性差。

Method: 提出dXPP惩罚式求导框架：(1)前向传播解耦，支持任意黑盒QP求解器；(2)反向传播将解映射到光滑近似惩罚问题并隐式求导；(3)只需在原始变量中求解更小的线性系统，绕过显式KKT求导困难。

Result: 在随机QP、大规模稀疏投影和实际多周期投资组合优化任务上评估表明：dXPP与KKT方法性能相当，但在大规模问题上实现显著加速，并提升了计算效率和鲁棒性。

Conclusion: dXPP通过解耦QP求解与求导，成功克服了KKT方法的可扩展性限制，提供了一种更高效、更鲁棒的惩罚式替代方案，特别适用于大规模优化问题。

Abstract: Differentiating through the solution of a quadratic program (QP) is a central problem in differentiable optimization. Most existing approaches differentiate through the Karush--Kuhn--Tucker (KKT) system, but their computational cost and numerical robustness can degrade at scale. To address these limitations, we propose dXPP, a penalty-based differentiation framework that decouples QP solving from differentiation. In the solving step (forward pass), dXPP is solver-agnostic and can leverage any black-box QP solver. In the differentiation step (backward pass), we map the solution to a smooth approximate penalty problem and implicitly differentiate through it, requiring only the solution of a much smaller linear system in the primal variables. This approach bypasses the difficulties inherent in explicit KKT differentiation and significantly improves computational efficiency and robustness. We evaluate dXPP on various tasks, including randomly generated QPs, large-scale sparse projection problems, and a real-world multi-period portfolio optimization task. Empirical results demonstrate that dXPP is competitive with KKT-based differentiation methods and achieves substantial speedups on large-scale problems.

</details>


### [78] [Synergistic Intra- and Cross-Layer Regularization Losses for MoE Expert Specialization](https://arxiv.org/abs/2602.14159)
*Rizhen Hu,Yuan Cao,Boao Kong,Mou Sun,Kun Yuan*

Main category: cs.LG

TL;DR: 该论文提出两种无需修改架构的正则化损失（层内专业化损失和跨层耦合损失）来解决稀疏MoE模型的专家重叠和路由模糊问题，实验表明能提升专家专业化、降低路由熵并加速推理。


<details>
  <summary>Details</summary>
Motivation: 稀疏混合专家（MoE）模型存在专家表征冗余和路由模糊问题，导致模型容量严重未充分利用。现有如DeepSeekMoE等架构方案需要大幅结构修改且仅依赖层内信号。

Method: 提出两种即插即用的正则化损失：1) 层内专业化损失：惩罚相同token上专家SwiGLU激活的余弦相似度，促使专家学习互补知识；2) 跨层耦合损失：最大化相邻层间联合Top-k路由概率，建立连贯的专家通路。作为Megatron-LM模块实现，与标准负载均衡损失正交，兼容DeepSeekMoE和传统MoE架构。

Result: 在预训练、微调和零样本基准测试中表现一致的任务增益，实现更高的专家专业化程度、更低熵的路由分布，并通过更稳定的专家通路带来更快的推理速度。

Conclusion: 所提正则化损失能在不修改路由或模型架构的前提下有效增强MoE专业化和路由效率，为提升MoE模型性能提供了实用的解决方案。

Abstract: Sparse Mixture-of-Experts (MoE) models scale Transformers efficiently but suffer from expert overlap -- redundant representations across experts and routing ambiguity, resulting in severely underutilized model capacity. While architectural solutions like DeepSeekMoE promote specialization, they require substantial structural modifications and rely solely on intra-layer signals. In this paper, we propose two plug-and-play regularization losses that enhance MoE specialization and routing efficiency without modifying router or model architectures. First, an intra-layer specialization loss penalizes cosine similarity between experts' SwiGLU activations on identical tokens, encouraging experts to specialize in complementary knowledge. Second, a cross-layer coupling loss maximizes joint Top-$k$ routing probabilities across adjacent layers, establishing coherent expert pathways through network depth while reinforcing intra-layer expert specialization. Both losses are orthogonal to the standard load-balancing loss and compatible with both the shared-expert architecture in DeepSeekMoE and vanilla top-$k$ MoE architectures. We implement both losses as a drop-in Megatron-LM module. Extensive experiments across pre-training, fine-tuning, and zero-shot benchmarks demonstrate consistent task gains, higher expert specialization, and lower-entropy routing; together, these improvements translate into faster inference via more stable expert pathways.

</details>


### [79] [Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling](https://arxiv.org/abs/2602.14169)
*Yiran Guo,Zhongjian Qiao,Yingqi Xie,Jie Liu,Dan Ye,Ruiqing Zhang,Shuang Qiu,Lijie Xu*

Main category: cs.LG

TL;DR: Proposes Deep Dense Exploration (DDE) for RL in LLMs, targeting "pivot" states in failed trajectories to improve exploration efficiency. DEEP-GRPO implementation beats GRPO and tree methods on math reasoning.


<details>
  <summary>Details</summary>
Motivation: Existing RL exploration methods for LLMs have critical flaws: GRPO over-samples high-probability trajectories (ignoring deep errors), while tree methods waste budget on unrecoverable states. Both fail to find rare correct solutions in vast language spaces.

Method: DEEP-GRPO introduces: 1) Data-driven utility function to identify "pivot" states (deep, recoverable failures); 2) Local dense resampling at pivots to discover correct suffixes; 3) Dual-stream optimization separating global policy learning from local corrections.

Result: Consistently outperforms GRPO, tree-based methods, and strong baselines across mathematical reasoning benchmarks.

Conclusion: Targeted exploration at recoverable failure states (pivots) is more efficient than blind root sampling or uniform tree expansion. DDE resolves trajectory saturation and sampling dilution in LLM RL.

Abstract: Effective exploration is a key challenge in reinforcement learning for large language models: discovering high-quality trajectories within a limited sampling budget from the vast natural language sequence space. Existing methods face notable limitations: GRPO samples exclusively from the root, saturating high-probability trajectories while leaving deep, error-prone states under-explored. Tree-based methods blindly disperse budgets across trivial or unrecoverable states, causing sampling dilution that fails to uncover rare correct suffixes and destabilizes local baselines. To address this, we propose Deep Dense Exploration (DDE), a strategy that focuses exploration on $\textit{pivots}$-deep, recoverable states within unsuccessful trajectories. We instantiate DDE with DEEP-GRPO, which introduces three key innovations: (1) a lightweight data-driven utility function that automatically balances recoverability and depth bias to identify pivot states; (2) local dense resampling at each pivot to increase the probability of discovering correct subsequent trajectories; and (3) a dual-stream optimization objective that decouples global policy learning from local corrective updates. Experiments on mathematical reasoning benchmarks demonstrate that our method consistently outperforms GRPO, tree-based methods, and other strong baselines.

</details>


### [80] [TS-Haystack: A Multi-Scale Retrieval Benchmark for Time Series Language Models](https://arxiv.org/abs/2602.14200)
*Nicolas Zumarraga,Thomas Kaar,Ning Wang,Maxwell A. Xu,Max Rosenblattl,Markus Kreft,Kevin O'Sullivan,Paul Schmiedmayer,Patrick Langer,Robert Jakob*

Main category: cs.LG

TL;DR: 提出TS-Haystack基准测试，揭示时间序列语言模型在长上下文检索中的局限性：压缩提升分类精度但损害局部事件检索能力，需新架构解耦序列长度与计算复杂度


<details>
  <summary>Details</summary>
Motivation: 现有时间序列语言模型(TSLMs)在短序列表现良好，但真实场景中长达数百万数据点的传感器流存在长上下文检索难题，当前基准无法评估严格计算约束下的精确时序定位能力

Method: 创建TS-Haystack基准：在长达2小时的加速度计记录中嵌入短活动片段，系统评估10种任务类型，测试4类时序推理（直接检索/时序推理/多步推理/上下文异常）

Result: 发现关键矛盾：学习式潜在压缩在176倍压缩率下仍保持或提升分类准确率，但检索性能随上下文长度增加而显著下降，损失时序局部化信息

Conclusion: 强调需设计新架构以解耦序列长度与计算复杂度，同时保持时序保真度，解决分类与检索任务间的行为分歧

Abstract: Time Series Language Models (TSLMs) are emerging as unified models for reasoning over continuous signals in natural language. However, long-context retrieval remains a major limitation: existing models are typically trained and evaluated on short sequences, while real-world time-series sensor streams can span millions of datapoints. This mismatch requires precise temporal localization under strict computational constraints, a regime that is not captured by current benchmarks. We introduce TS-Haystack, a long-context temporal retrieval benchmark comprising ten task types across four categories: direct retrieval, temporal reasoning, multi-step reasoning and contextual anomaly. The benchmark uses controlled needle insertion by embedding short activity bouts into longer longitudinal accelerometer recordings, enabling systematic evaluation across context lengths ranging from seconds to 2 hours per sample. We hypothesize that existing TSLM time series encoders overlook temporal granularity as context length increases, creating a task-dependent effect: compression aids classification but impairs retrieval of localized events. Across multiple model and encoding strategies, we observe a consistent divergence between classification and retrieval behavior. Learned latent compression preserves or improves classification accuracy at compression ratios up to 176$\times$, but retrieval performance degrades with context length, incurring in the loss of temporally localized information. These results highlight the importance of architectural designs that decouple sequence length from computational complexity while preserving temporal fidelity.

</details>


### [81] [Fast Catch-Up, Late Switching: Optimal Batch Size Scheduling via Functional Scaling Laws](https://arxiv.org/abs/2602.14208)
*Jinbo Wang,Binghui Li,Zhanpeng Zhou,Mingze Wang,Yuxuan Sun,Jiaqi Zhang,Xunliang Cai,Lei Wu*

Main category: cs.LG

TL;DR: 该论文利用函数缩放律(FSL)框架分析批次大小调度，揭示简单任务应持续增大批次大小，而困难任务应在训练后期才切换到大批量，通过"快速追赶效应"实现数据高效训练。


<details>
  <summary>Details</summary>
Motivation: 大规模深度学习训练中批次大小调度缺乏坚实的理论基础，对其如何影响优化动态和计算效率的理解尚不充分。

Method: 采用Li等人(2025a)提出的函数缩放律框架进行理论分析，并通过涵盖Dense和MoE架构、参数量达11亿的LLM预训练实验进行验证。

Result: 1) 简单任务的最优策略是持续增加批次大小；2) 困难任务应在大部分训练时间保持小批次，仅在最后阶段切换到大批量；3) 发现"快速追赶效应"：切换后损失迅速与恒定大批量训练的轨迹对齐；4) 该效应由梯度噪声的快速遗忘驱动，追赶速度取决于任务难度；5) 延迟使用大批量可在不牺牲性能的前提下显著减少数据消耗；6) 大规模实验证实后期切换策略优于恒定批次和早期切换基线。

Conclusion: 本研究为批次大小调度提供了理论指导，提出的后期切换策略能有效降低大模型训练成本，具有重要实践价值。

Abstract: Batch size scheduling (BSS) plays a critical role in large-scale deep learning training, influencing both optimization dynamics and computational efficiency. Yet, its theoretical foundations remain poorly understood. In this work, we show that the functional scaling law (FSL) framework introduced in Li et al. (2025a) provides a principled lens for analyzing BSS. Specifically, we characterize the optimal BSS under a fixed data budget and show that its structure depends sharply on task difficulty. For easy tasks, optimal schedules keep increasing batch size throughout. In contrast, for hard tasks, the optimal schedule maintains small batch sizes for most of training and switches to large batches only in a late stage. To explain the emergence of late switching, we uncover a dynamical mechanism -- the fast catch-up effect -- which also manifests in large language model (LLM) pretraining. After switching from small to large batches, the loss rapidly aligns with the constant large-batch trajectory. Using FSL, we show that this effect stems from rapid forgetting of accumulated gradient noise, with the catch-up speed determined by task difficulty. Crucially, this effect implies that large batches can be safely deferred to late training without sacrificing performance, while substantially reducing data consumption. Finally, extensive LLM pretraining experiments -- covering both Dense and MoE architectures with up to 1.1B parameters and 1T tokens -- validate our theoretical predictions. Across all settings, late-switch schedules consistently outperform constant-batch and early-switch baselines.

</details>


### [82] [MAGE: All-[MASK] Block Already Knows Where to Look in Diffusion LLM](https://arxiv.org/abs/2602.14209)
*Omin Kwon,Yeonjae Kim,Doyeon Kim,Minseo Kim,Yeonhong Park,Jae W. Lee*

Main category: cs.LG

TL;DR: MAGE leverages the first All-[MASK] denoising step in block diffusion to identify important KV entries, enabling a single exact attention pass per block for training-free sparse denoising, achieving 3-4x speedup with near-lossless accuracy on long-context tasks.


<details>
  <summary>Details</summary>
Motivation: Block diffusion LLMs face memory access bottlenecks from KV caching in long contexts; existing autoregressive sparse attention methods perform poorly when adapted due to reliance on approximate importance estimation.

Method: Uses attention patterns from the first All-[MASK] step to reliably predict important KV entries and budget requirements, performs one exact attention pass per block, and reuses it for sparse denoising without training.

Result: Achieves near-lossless accuracy with reduced KV budget, delivers 3-4x end-to-end speedup on LongBench and Needle-in-a-Haystack, and consistently outperforms AR-oriented sparse attention baselines.

Conclusion: MAGE effectively solves the KV cache bottleneck in block diffusion through [MASK]-guided exact attention, offering significant performance gains with minimal computational overhead via lightweight fine-tuning.

Abstract: Block diffusion LLMs are emerging as a promising next paradigm for language generation, but their use of KV caching makes memory access a dominant bottleneck in long-context settings. While dynamic sparse attention has been actively explored, existing methods designed for autoregressive LLMs rely on approximate importance estimation and perform poorly when adapted to block diffusion. This work identifies a key opportunity unique to block diffusion: attention at the first All-[MASK] denoising step reliably predicts important KV entries and budget requirements, enabling MAGE to perform a single exact attention pass per block and reuse it for training-free sparse denoising. Across long-context benchmarks including LongBench and Needle-in-a-Haystack, MAGE achieves near-lossless accuracy with a fraction of the KV budget while delivering up to 3-4x end-to-end speedup, consistently outperforming AR-oriented sparse attention baselines. A lightweight fine-tuning strategy further strengthens [MASK]-guided patterns with minimal cost, requiring only a few hours of training on a single NVIDIA H100 GPU for both 1.5B and 7B models.

</details>


### [83] [Robust multi-task boosting using clustering and local ensembling](https://arxiv.org/abs/2602.14231)
*Seyedsaman Emami,Daniel Hernández-Lobato,Gonzalo Martínez-Muñoz*

Main category: cs.LG

TL;DR: 针对多任务学习中的负迁移问题，作者提出RMB-CLE框架，通过误差驱动的自适应聚类和局部集成实现鲁棒学习，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统多任务学习方法在强制共享无关或噪声任务表示时会产生负迁移，影响预测性能。

Method: 提出RMB-CLE，通过跨任务误差推导任务相似性并进行风险分解，采用层次聚类自适应分组任务，在聚类内使用局部集成进行鲁棒知识共享。

Result: 在合成数据中成功恢复真实聚类结构，并在多样基准测试中持续超越多任务、单任务及池化集成方法。

Conclusion: RMB-CLE不仅是聚类与提升的结合，更是一个通用可扩展的框架，为鲁棒多任务学习建立了新范式。

Abstract: Multi-Task Learning (MTL) aims to boost predictive performance by sharing information across related tasks, yet conventional methods often suffer from negative transfer when unrelated or noisy tasks are forced to share representations. We propose Robust Multi-Task Boosting using Clustering and Local Ensembling (RMB-CLE), a principled MTL framework that integrates error-based task clustering with local ensembling. Unlike prior work that assumes fixed clusters or hand-crafted similarity metrics, RMB-CLE derives inter-task similarity directly from cross-task errors, which admit a risk decomposition into functional mismatch and irreducible noise, providing a theoretically grounded mechanism to prevent negative transfer. Tasks are grouped adaptively via agglomerative clustering, and within each cluster, a local ensemble enables robust knowledge sharing while preserving task-specific patterns. Experiments show that RMB-CLE recovers ground-truth clusters in synthetic data and consistently outperforms multi-task, single-task, and pooling-based ensemble methods across diverse real-world and synthetic benchmarks. These results demonstrate that RMB-CLE is not merely a combination of clustering and boosting but a general and scalable framework that establishes a new basis for robust multi-task learning.

</details>


### [84] [Evaluating LLMs in Finance Requires Explicit Bias Consideration](https://arxiv.org/abs/2602.14233)
*Yaxuan Kong,Hoyoung Lee,Yoontae Hwang,Alejandro Lopez-Lira,Bradford Levy,Dhagash Mehta,Qingsong Wen,Chanyeol Choi,Yongjae Lee,Stefan Zohren*

Main category: cs.LG

TL;DR: 该论文指出金融领域大语言模型（LLM）应用存在五种常见偏差（前视、生存者、叙事、目标、成本偏差），导致回测结果失真且无法支撑实际部署。通过对2023-2025年164篇论文的分析，发现单一偏差讨论率不足28%，提出需建立结构效度框架和评估清单以强制诊断偏差。


<details>
  <summary>Details</summary>
Motivation: 金融LLM评估实践滞后于应用发展，领域特定偏差会虚增模型性能、污染回测结果，使部署主张失去依据，亟需系统性解决方案。

Method: 识别金融LLM五大核心偏差类型，系统性回顾2023-2025年间164篇相关论文的偏差处理情况，提出结构效度框架及评估清单。

Result: 分析显示所有论文中单一偏差讨论率均未超28%，偏差常叠加形成"有效性幻觉"，当前研究普遍缺乏对金融场景特有偏差的显性关注。

Conclusion: 必须强制实施结构效度验证，通过标准化框架和检查清单诊断偏差，确保金融LLM结果真实可靠后方可支持部署决策。

Abstract: Large Language Models (LLMs) are increasingly integrated into financial workflows, but evaluation practice has not kept up. Finance-specific biases can inflate performance, contaminate backtests, and make reported results useless for any deployment claim. We identify five recurring biases in financial LLM applications. They include look-ahead bias, survivorship bias, narrative bias, objective bias, and cost bias. These biases break financial tasks in distinct ways and they often compound to create an illusion of validity. We reviewed 164 papers from 2023 to 2025 and found that no single bias is discussed in more than 28 percent of studies. This position paper argues that bias in financial LLM systems requires explicit attention and that structural validity should be enforced before any result is used to support a deployment claim. We propose a Structural Validity Framework and an evaluation checklist with minimal requirements for bias diagnosis and future system design. The material is available at https://github.com/Eleanorkong/Awesome-Financial-LLM-Bias-Mitigation.

</details>


### [85] [Multi-Agent Debate: A Unified Agentic Framework for Tabular Anomaly Detection](https://arxiv.org/abs/2602.14251)
*Pinqiao Wang,Sheng Li*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Tabular anomaly detection is often handled by single detectors or static ensembles, even though strong performance on tabular data typically comes from heterogeneous model families (e.g., tree ensembles, deep tabular networks, and tabular foundation models) that frequently disagree under distribution shift, missingness, and rare-anomaly regimes. We propose MAD, a Multi-Agent Debating framework that treats this disagreement as a first-class signal and resolves it through a mathematically grounded coordination layer. Each agent is a machine learning (ML)-based detector that produces a normalized anomaly score, confidence, and structured evidence, augmented by a large language model (LLM)-based critic. A coordinator converts these messages into bounded per-agent losses and updates agent influence via an exponentiated-gradient rule, yielding both a final debated anomaly score and an auditable debate trace. MAD is a unified agentic framework that can recover existing approaches, such as mixture-of-experts gating and learning-with-expert-advice aggregation, by restricting the message space and synthesis operator. We establish regret guarantees for the synthesized losses and show how conformal calibration can wrap the debated score to control false positives under exchangeability. Experiments on diverse tabular anomaly benchmarks show improved robustness over baselines and clearer traces of model disagreement

</details>


### [86] [Cross-household Transfer Learning Approach with LSTM-based Demand Forecasting](https://arxiv.org/abs/2602.14267)
*Manal Rahal,Bestoun S. Ahmed,Roger Renström,Robert Stener*

Main category: cs.LG

TL;DR: 提出基于迁移学习的DELTAiF框架，实现家庭热水用量的可扩展预测，减少67%训练时间的同时保持高精度


<details>
  <summary>Details</summary>
Motivation: 随着家用热泵普及，传统为每户单独训练机器学习模型的方法面临计算成本高、难以扩展的技术挑战，亟需实现舒适性与节能平衡的可扩展热水需求预测方案

Method: 设计DELTAiF迁移学习框架：选取代表性家庭数据预训练模型，通过微调适配其他家庭；聚焦淋浴等大用量事件预测，避免逐户建模

Result: 训练时间降低约67%，预测准确率0.874-0.991，平均绝对百分比误差0.001-0.017；源家庭用水规律性越强，迁移效果越显著

Conclusion: 迁移学习能有效解决热水需求预测的规模化难题，在源家庭具有规律用水模式时，可实现高精度、低能耗的适应性热水生产

Abstract: With the rapid increase in residential heat pump (HP) installations, optimizing hot water production in households is essential, yet it faces major technical and scalability challenges. Adapting production to actual household needs requires accurate forecasting of hot water demand to ensure comfort and, most importantly, to reduce energy waste. However, the conventional approach of training separate machine learning models for each household becomes computationally expensive at scale, particularly in cloud-connected HP deployments.
  This study introduces DELTAiF, a transfer learning (TL) based framework that provides scalable and accurate prediction of household hot water consumption. By predicting large hot water usage events, such as showers, DELTAiF enables adaptive yet scalable hot water production at the household level. DELTAiF leverages learned knowledge from a representative household and fine-tunes it across others, eliminating the need to train separate machine learning models for each HP installation. This approach reduces overall training time by approximately 67 percent while maintaining high predictive accuracy values between 0.874 and 0.991, and mean absolute percentage error values between 0.001 and 0.017. The results show that TL is particularly effective when the source household exhibits regular consumption patterns, enabling hot water demand forecasting at scale.

</details>


### [87] [Radial-VCReg: More Informative Representation Learning Through Radial Gaussianization](https://arxiv.org/abs/2602.14272)
*Yilun Kuang,Yash Dagade,Deep Chakraborty,Erik Learned-Miller,Randall Balestriero,Tim G. J. Rudner,Yann LeCun*

Main category: cs.LG

TL;DR: Radial-VCReg enhances VCReg with radial Gaussianization loss to align feature norms with Chi distribution, overcoming dimensionality limits in self-supervised learning for more informative representations.


<details>
  <summary>Details</summary>
Motivation: Self-supervised learning seeks maximally informative representations but faces the curse of dimensionality; existing methods like VCReg only regularize first/second-order statistics, failing to achieve true maximum entropy.

Method: Proposes Radial-VCReg, augmenting VCReg with a radial Gaussianization loss that enforces feature norms to follow the Chi distribution—a hallmark of high-dimensional Gaussian data.

Result: Proves Radial-VCReg transforms broader distributions toward normality than VCReg, reducing higher-order dependencies and consistently improving performance on synthetic and real-world datasets.

Conclusion: Radial-VCReg promotes more diverse, informative representations by better approximating maximum entropy, advancing self-supervised learning beyond second-order statistics.

Abstract: Self-supervised learning aims to learn maximally informative representations, but explicit information maximization is hindered by the curse of dimensionality. Existing methods like VCReg address this by regularizing first and second-order feature statistics, which cannot fully achieve maximum entropy. We propose Radial-VCReg, which augments VCReg with a radial Gaussianization loss that aligns feature norms with the Chi distribution-a defining property of high-dimensional Gaussians. We prove that Radial-VCReg transforms a broader class of distributions towards normality compared to VCReg and show on synthetic and real-world datasets that it consistently improves performance by reducing higher-order dependencies and promoting more diverse and informative representations.

</details>


### [88] [Integrating Unstructured Text into Causal Inference: Empirical Evidence from Real Data](https://arxiv.org/abs/2602.14274)
*Boning Zhou,Ziyu Wang,Han Hong,Haoqi Hu*

Main category: cs.LG

TL;DR: 提出基于Transformer的框架，利用非结构化文本进行因果推断，验证其与结构化数据结果的一致性，解决结构化数据稀缺场景下的业务决策问题


<details>
  <summary>Details</summary>
Motivation: 传统因果推断依赖结构化数据，但现实场景中此类数据常不完整或不可用，亟需利用非结构化文本拓展因果推断的适用范围

Method: 采用基于Transformer的语言模型构建因果推断框架，通过群体、分组和个体三个层面对比非结构化文本与结构化数据得出的因果估计结果

Result: 文本与结构化数据方法得出的因果推断结果高度一致，证实非结构化文本在因果推断任务中的有效性

Conclusion: 该方法将因果推断能力扩展至仅有文本数据的场景，为结构化数据稀缺时的数据驱动业务决策提供了可行解决方案

Abstract: Causal inference, a critical tool for informing business decisions, traditionally relies heavily on structured data. However, in many real-world scenarios, such data can be incomplete or unavailable. This paper presents a framework that leverages transformer-based language models to perform causal inference using unstructured text. We demonstrate the effectiveness of our framework by comparing causal estimates derived from unstructured text against those obtained from structured data across population, group, and individual levels. Our findings show consistent results between the two approaches, validating the potential of unstructured text in causal inference tasks. Our approach extends the applicability of causal inference methods to scenarios where only textual data is available, enabling data-driven business decision-making when structured tabular data is scarce.

</details>


### [89] [Reverse N-Wise Output-Oriented Testing for AI/ML and Quantum Computing Systems](https://arxiv.org/abs/2602.14275)
*Lamine Rihani*

Main category: cs.LG

TL;DR: 本文提出反向n-wise输出测试，通过在输出等价类上直接构建覆盖阵列并采用元启发式优化求解逆映射，为AI/ML和量子计算提供数学严谨的测试框架，实现覆盖保证与故障检测的双重提升。


<details>
  <summary>Details</summary>
Motivation: AI/ML系统与量子计算软件面临独特测试挑战：高维连续输入、概率性输出、行为正确性仅由观测定义，且质量维度（可信度、公平性、校准性、鲁棒性、错误综合征）通过输出属性的复杂交互而非确定性映射体现，传统方法难以应对。

Method: 创新性地提出"反向n-wise输出测试"，直接在领域特定输出等价类上构建覆盖阵列（包括ML的置信度桶、决策边界、公平分区、嵌入簇、排序稳定带，以及量子的测量分布、错误综合征模式），通过无梯度元启发式优化求解黑盒逆映射问题，合成能激发目标行为签名的输入配置或量子电路参数。

Result: 框架提供客户为中心的覆盖保证，显著提升ML校准/边界故障和量子错误综合征检测率，提高测试效率，并建立结构化MLOps/量子验证流水线，支持基于不确定性分析的自动分区发现与覆盖漂移监控。

Conclusion: 反向n-wise输出测试为AI/ML和量子计算提供了范式级测试解决方案，通过输出驱动的覆盖构造和智能优化，有效攻克复杂系统测试的根本挑战，构建自动化、可扩展的质量保障体系。

Abstract: Artificial intelligence/machine learning (AI/ML) systems and emerging quantum computing software present unprecedented testing challenges characterized by high-dimensional/continuous input spaces, probabilistic/non-deterministic output distributions, behavioral correctness defined exclusively over observable prediction behaviors and measurement outcomes, and critical quality dimensions, trustworthiness, fairness, calibration, robustness, error syndrome patterns, that manifest through complex multi-way interactions among semantically meaningful output properties rather than deterministic input-output mappings. This paper introduces reverse n-wise output testing, a mathematically principled paradigm inversion that constructs covering arrays directly over domain-specific output equivalence classes, ML confidence calibration buckets, decision boundary regions, fairness partitions, embedding clusters, ranking stability bands, quantum measurement outcome distributions (0-dominant, 1-dominant, superposition collapse), error syndrome patterns (bit-flip, phase-flip, correlated errors), then solves the computationally challenging black-box inverse mapping problem via gradient-free metaheuristic optimization to synthesize input feature configurations or quantum circuit parameters capable of eliciting targeted behavioral signatures from opaque models. The framework delivers synergistic benefits across both domains: explicit customer-centric prediction/measurement coverage guarantees, substantial improvements in fault detection rates for ML calibration/boundary failures and quantum error syndromes, enhanced test suite efficiency, and structured MLOps/quantum validation pipelines with automated partition discovery from uncertainty analysis and coverage drift monitoring.

</details>


### [90] [Whom to Query for What: Adaptive Group Elicitation via Multi-Turn LLM Interactions](https://arxiv.org/abs/2602.14279)
*Ruomeng Ding,Tianwei Gao,Thomas P. Zollo,Eitan Bachmat,Richard Zemel,Zhun Deng*

Main category: cs.LG

TL;DR: Proposes an adaptive group elicitation framework combining LLM-based question scoring and heterogeneous GNN imputation to optimize survey questioning under budget constraints, improving population-level prediction accuracy by >12% on real-world datasets.


<details>
  <summary>Details</summary>
Motivation: Existing survey methods for estimating group-level properties cannot adapt respondent selection or leverage population structure when responses are incomplete, failing to optimize limited questioning budgets under real-world cost constraints and missing data.

Method: Combines (1) LLM-driven expected information gain scoring for adaptive question selection and (2) heterogeneous graph neural networks to impute missing responses via participant attributes/population structure, enabling closed-loop optimization of both questions and respondents within query/participation budgets.

Result: Consistently outperforms baselines across three real-world opinion datasets; achieves >12% relative improvement in population response prediction accuracy on the CES dataset at only 10% respondent budget.

Conclusion: The framework effectively reduces uncertainty about latent group properties by strategically querying informative individuals and inferring missing data through structured similarity, demonstrating significant gains in constrained survey settings.

Abstract: Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language, most existing elicitation methods optimize what to ask with a fixed respondent pool, and do not adapt respondent selection or leverage population structure when responses are partial or incomplete. To address this gap, we study adaptive group elicitation, a multi-round setting where an agent adaptively selects both questions and respondents under explicit query and participation budgets. We propose a theoretically grounded framework that combines (i) an LLM-based expected information gain objective for scoring candidate questions with (ii) heterogeneous graph neural network propagation that aggregates observed responses and participant attributes to impute missing responses and guide per-round respondent selection. This closed-loop procedure queries a small, informative subset of individuals while inferring population-level responses via structured similarity. Across three real-world opinion datasets, our method consistently improves population-level response prediction under constrained budgets, including a >12% relative gain on CES at a 10% respondent budget.

</details>


### [91] [Machine Learning as a Tool (MLAT): A Framework for Integrating Statistical ML Models as Callable Tools within LLM Agent Workflows](https://arxiv.org/abs/2602.14295)
*Edwin Chen,Zulekha Bibi*

Main category: cs.LG

TL;DR: 提出MLAT设计模式，将预训练ML模型作为LLM智能体的可调用工具，实现PitchCraft系统将销售通话录音自动转为提案，定价模型R²=0.807，生成时间从数小时缩短至10分钟内。


<details>
  <summary>Details</summary>
Motivation: 将机器学习模型从静态预处理步骤提升为LLM智能体工作流中的一等工具，使其能够根据对话上下文动态调用并进行定量预测和推理。

Method: 提出MLAT框架，开发PitchCraft系统包含Research Agent（并行工具调用收集信息）和Draft Agent（调用XGBoost定价模型生成结构化提案）。模型基于70个真实和人工验证的合成数据训练。

Result: 定价模型在保留数据上R²=0.807，平均绝对误差3688美元；提案生成时间从数小时降至10分钟以内；敏感性分析证实学习到有意义的关系。

Conclusion: MLAT可推广至需要定量估计与上下文推理结合的任何领域。

Abstract: We introduce Machine Learning as a Tool (MLAT), a design pattern in which pre-trained statistical machine learning models are exposed as callable tools within large language model (LLM) agent workflows. This allows an orchestrating agent to invoke quantitative predictions when needed and reason about their outputs in context. Unlike conventional pipelines that treat ML inference as a static preprocessing step, MLAT positions the model as a first-class tool alongside web search, database queries, and APIs, enabling the LLM to decide when and how to use it based on conversational context.
  To validate MLAT, we present PitchCraft, a pilot production system that converts discovery call recordings into professional proposals with ML-predicted pricing. The system uses two agents: a Research Agent that gathers prospect intelligence via parallel tool calls, and a Draft Agent that invokes an XGBoost pricing model as a tool call and generates a complete proposal through structured outputs. The pricing model, trained on 70 examples combining real and human-verified synthetic data, achieves R^2 = 0.807 on held-out data with a mean absolute error of 3688 USD. The system reduces proposal generation time from multiple hours to under 10 minutes.
  We describe the MLAT framework, structured output architecture, training methodology under extreme data scarcity, and sensitivity analysis demonstrating meaningful learned relationships. MLAT generalizes to domains requiring quantitative estimation combined with contextual reasoning.

</details>


### [92] [DeepFusion: Accelerating MoE Training via Federated Knowledge Distillation from Heterogeneous Edge Devices](https://arxiv.org/abs/2602.14301)
*Songyuan Li,Jia Hu,Ahmed M. Abdelmoniem,Geyong Min,Haojun Huang,Jiwei Huang*

Main category: cs.LG

TL;DR: DeepFusion: A federated MoE training framework using knowledge distillation with a novel View-Aligned Attention module to enable resource-constrained devices to collaboratively train large MoE models while reducing communication costs by up to 71%.


<details>
  <summary>Details</summary>
Motivation: MoE-based LLMs require vast diverse training data, but federated learning is hindered by the impracticality of hosting full MoE models on resource-constrained edge devices, and traditional federated knowledge distillation suffers from view-mismatch problems due to architectural heterogeneity.

Method: Proposes DeepFusion framework where devices train tailored on-device LLMs, and introduces a View-Aligned Attention (VAA) module that integrates multi-stage feature representations from the global MoE model to align predictive perspectives for effective cross-architecture knowledge distillation.

Result: Experiments with industry-level MoE models (Qwen-MoE, DeepSeek-MoE) on medical and finance datasets show DeepFusion achieves near-centralized training performance, reduces communication costs by up to 71%, and improves token perplexity by up to 5.28% compared to federated baselines.

Conclusion: DeepFusion provides the first scalable federated MoE training solution that effectively addresses device resource constraints and architectural heterogeneity through view-aligned knowledge distillation, enabling efficient privacy-preserving training of large MoE models.

Abstract: Recent Mixture-of-Experts (MoE)-based large language models (LLMs) such as Qwen-MoE and DeepSeek-MoE are transforming generative AI in natural language processing. However, these models require vast and diverse training data. Federated learning (FL) addresses this challenge by leveraging private data from heterogeneous edge devices for privacy-preserving MoE training. Nonetheless, traditional FL approaches require devices to host local MoE models, which is impractical for resource-constrained devices due to large model sizes. To address this, we propose DeepFusion, the first scalable federated MoE training framework that enables the fusion of heterogeneous on-device LLM knowledge via federated knowledge distillation, yielding a knowledge-abundant global MoE model. Specifically, DeepFusion features each device to independently configure and train an on-device LLM tailored to its own needs and hardware limitations. Furthermore, we propose a novel View-Aligned Attention (VAA) module that integrates multi-stage feature representations from the global MoE model to construct a predictive perspective aligned with on-device LLMs, thereby enabling effective cross-architecture knowledge distillation. By explicitly aligning predictive perspectives, VAA resolves the view-mismatch problem in traditional federated knowledge distillation, which arises from heterogeneity in model architectures and prediction behaviors between on-device LLMs and the global MoE model. Experiments with industry-level MoE models (Qwen-MoE and DeepSeek-MoE) and real-world datasets (medical and finance) demonstrate that DeepFusion achieves performance close to centralized MoE training. Compared with key federated MoE baselines, DeepFusion reduces communication costs by up to 71% and improves token perplexity by up to 5.28%.

</details>


### [93] [In Transformer We Trust? A Perspective on Transformer Architecture Failure Modes](https://arxiv.org/abs/2602.14318)
*Trishit Mondal,Ameya D. Jagtap*

Main category: cs.LG

TL;DR: 一篇关于Transformer模型可信度的综述论文，系统评估其在安全关键应用中的可靠性、脆弱性和研究挑战。


<details>
  <summary>Details</summary>
Motivation: Transformer在高风险领域（医疗、自动驾驶、核能、气候建模等）的广泛应用，亟需深入评估其可信度。

Method: 通过全面回顾可解释性、鲁棒性、公平性、隐私等维度，跨NLP、计算机视觉、科学工程等多个领域进行系统性分析。

Result: 识别出反复出现的结构性漏洞、领域特定风险以及限制Transformer可靠部署的开放研究挑战。

Conclusion: 研究表明Transformer在高风险应用中可信度问题突出，需解决结构性缺陷和领域风险以确保可靠部署。

Abstract: Transformer architectures have revolutionized machine learning across a wide range of domains, from natural language processing to scientific computing. However, their growing deployment in high-stakes applications, such as computer vision, natural language processing, healthcare, autonomous systems, and critical areas of scientific computing including climate modeling, materials discovery, drug discovery, nuclear science, and robotics, necessitates a deeper and more rigorous understanding of their trustworthiness. In this work, we critically examine the foundational question: \textitHow trustworthy are transformer models?} We evaluate their reliability through a comprehensive review of interpretability, explainability, robustness against adversarial attacks, fairness, and privacy. We systematically examine the trustworthiness of transformer-based models in safety-critical applications spanning natural language processing, computer vision, and science and engineering domains, including robotics, medicine, earth sciences, materials science, fluid dynamics, nuclear science, and automated theorem proving; highlighting high-impact areas where these architectures are central and analyzing the risks associated with their deployment. By synthesizing insights across these diverse areas, we identify recurring structural vulnerabilities, domain-specific risks, and open research challenges that limit the reliable deployment of transformers.

</details>


### [94] [Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study](https://arxiv.org/abs/2602.14322)
*Hani Beirami,M M Manjurul Islam*

Main category: cs.LG

TL;DR: 该论文研究如何利用形式化时序逻辑规范增强强化学习在航空航天控制中的安全性和鲁棒性。通过在AeroBench F-16仿真平台上训练PPO智能体，并结合基于conformal预测的STL防护罩，在保持性能的同时确保规范满足性，显著提升了自主飞行控制在复杂环境下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在航空航天控制中的应用面临安全性和鲁棒性挑战，特别是在存在模型不确定性、执行器限制和噪声干扰的情况下。形式化方法如时序逻辑可提供严格的规范保证，但需要有效机制将其与数据驱动的RL结合以确保运行时的安全性。

Method: 使用开源AeroBench F-16仿真基准，训练PPO智能体调节发动机油门并跟踪指令空速。将控制目标编码为信号时序逻辑(STL)要求，在运行时引入基于在线conformal预测的STL防护罩来过滤智能体动作。对比三种设置：纯PPO基线、带经典规则基STL防护罩的PPO、带所提出的conformal防护罩的PPO，在标称条件和包含气动模型失配、执行器速率限制、测量噪声及中途设定点跳变的严重压力场景下进行测试。

Result: 实验表明，与经典防护罩相比，conformal防护罩能在保持接近基线性能的同时确保STL满足性，并提供更强的鲁棒性保证。在极端压力场景下，该方法显著提高了自主飞行控制的可靠性。

Conclusion: 将形式化规范监控与数据驱动强化学习相结合，可显著改善自主飞行控制在挑战性环境下的可靠性，为安全关键系统的开发提供了有效途径。

Abstract: We investigate how formal temporal logic specifications can enhance the safety and robustness of reinforcement learning (RL) control in aerospace applications. Using the open source AeroBench F-16 simulation benchmark, we train a Proximal Policy Optimization (PPO) agent to regulate engine throttle and track commanded airspeed. The control objective is encoded as a Signal Temporal Logic (STL) requirement to maintain airspeed within a prescribed band during the final seconds of each maneuver. To enforce this specification at run time, we introduce a conformal STL shield that filters the RL agent's actions using online conformal prediction. We compare three settings: (i) PPO baseline, (ii) PPO with a classical rule-based STL shield, and (iii) PPO with the proposed conformal shield, under both nominal conditions and a severe stress scenario involving aerodynamic model mismatch, actuator rate limits, measurement noise, and mid-episode setpoint jumps. Experiments show that the conformal shield preserves STL satisfaction while maintaining near baseline performance and providing stronger robustness guarantees than the classical shield. These results demonstrate that combining formal specification monitoring with data driven RL control can substantially improve the reliability of autonomous flight control in challenging environments.

</details>


### [95] [Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning](https://arxiv.org/abs/2602.14338)
*Zhi Zhang,Zhen Han,Costas Mavromatis,Qi Zhu,Yunyi Zhang,Sheng Guan,Dingmin Wang,Xiong Zhou,Shuai Wang,Soji Adeshina,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.LG

TL;DR: AERO improves GRPO by adaptively pruning rollouts and maintaining Bayesian posteriors, reducing compute by 48% while maintaining or improving performance.


<details>
  <summary>Details</summary>
Motivation: The current GRPO method wastes compute when rollouts in a group all succeed or all fail, resulting in zero gradient signals and inefficient fine-tuning.

Method: AERO introduces adaptive rollout strategies, selective rejection pruning, and Bayesian posterior maintenance to avoid zero-advantage scenarios.

Result: AERO reduces compute by ~48% and wall-clock time by ~45% while matching or exceeding GRPO's Pass@8 and Avg@8 metrics across three Qwen2.5 models.

Conclusion: AERO provides a practical, scalable, and compute-efficient approach for RL-based LLM alignment.

Abstract: Reinforcement learning (RL) plays a central role in large language model (LLM) post-training. Among existing approaches, Group Relative Policy Optimization (GRPO) is widely used, especially for RL with verifiable rewards (RLVR) fine-tuning. In GRPO, each query prompts the LLM to generate a group of rollouts with a fixed group size $N$. When all rollouts in a group share the same outcome, either all correct or all incorrect, the group-normalized advantages become zero, yielding no gradient signal and wasting fine-tuning compute. We introduce Adaptive Efficient Rollout Optimization (AERO), an enhancement of GRPO. AERO uses an adaptive rollout strategy, applies selective rejection to strategically prune rollouts, and maintains a Bayesian posterior to prevent zero-advantage dead zones. Across three model configurations (Qwen2.5-Math-1.5B, Qwen2.5-7B, and Qwen2.5-7B-Instruct), AERO improves compute efficiency without sacrificing performance. Under the same total rollout budget, AERO reduces total training compute by about 48% while shortening wall-clock time per step by about 45% on average. Despite the substantial reduction in compute, AERO matches or improves Pass@8 and Avg@8 over GRPO, demonstrating a practical, scalable, and compute-efficient strategy for RL-based LLM alignment.

</details>


### [96] [WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control](https://arxiv.org/abs/2602.14351)
*Mehran Aghabozorgi,Alireza Moazeni,Yanshu Zhang,Ke Li*

Main category: cs.LG

TL;DR: WIMLE extends IMLE to model-based RL for learning multi-modal world models with uncertainty awareness, achieving superior sample efficiency across 40 tasks by weighting synthetic transitions by confidence.


<details>
  <summary>Details</summary>
Motivation: Model-based RL promises sample efficiency but suffers from compounding model errors, unimodal dynamics averaging, and overconfident predictions that degrade performance.

Method: Extends IMLE to model-based RL, using ensembles and latent sampling to estimate predictive uncertainty, and weights synthetic transitions by predicted confidence during training to handle multi-modality and uncertainty.

Result: On 40 continuous-control tasks, WIMLE achieves superior sample efficiency and competitive asymptotic performance. Specifically, it improves Humanoid-run sample efficiency by >50% and solves 8 of 14 HumanoidBench tasks (vs 4-5 for baselines).

Conclusion: IMLE-based multi-modality combined with uncertainty-aware weighting is effective for stable model-based RL, addressing key practical limitations.

Abstract: Model-based reinforcement learning promises strong sample efficiency but often underperforms in practice due to compounding model error, unimodal world models that average over multi-modal dynamics, and overconfident predictions that bias learning. We introduce WIMLE, a model-based method that extends Implicit Maximum Likelihood Estimation (IMLE) to the model-based RL framework to learn stochastic, multi-modal world models without iterative sampling and to estimate predictive uncertainty via ensembles and latent sampling. During training, WIMLE weights each synthetic transition by its predicted confidence, preserving useful model rollouts while attenuating bias from uncertain predictions and enabling stable learning. Across $40$ continuous-control tasks spanning DeepMind Control, MyoSuite, and HumanoidBench, WIMLE achieves superior sample efficiency and competitive or better asymptotic performance than strong model-free and model-based baselines. Notably, on the challenging Humanoid-run task, WIMLE improves sample efficiency by over $50$\% relative to the strongest competitor, and on HumanoidBench it solves $8$ of $14$ tasks (versus $4$ for BRO and $5$ for SimbaV2). These results highlight the value of IMLE-based multi-modality and uncertainty-aware weighting for stable model-based RL.

</details>


### [97] [A Study on Multi-Class Online Fuzzy Classifiers for Dynamic Environments](https://arxiv.org/abs/2602.14375)
*Kensuke Ajimoto,Yuma Yamamoto,Yoshifumi Kusunoki,Tomoharu Nakashima*

Main category: cs.LG

TL;DR: 本文针对动态环境提出一种多类在线模糊分类器，将传统二分类在线模糊分类器扩展至多分类场景，保持人类预设规则前提与数据驱动学习结论的框架。


<details>
  <summary>Details</summary>
Motivation: 传统在线模糊分类器仅支持二分类问题，而现实动态环境中的分类任务常需多分类能力且数据以增量方式逐步可用，现有方法无法满足此类需求。

Method: 采用模糊if-then规则体系：规则前件由人类用户预先确定，后件通过训练数据学习。在在线学习框架下，模型每次仅处理少量新样本，逐步更新以适应动态变化。

Result: 通过合成动态数据和多个基准数据集的数值实验，对所提方法的性能进行了评估验证。

Conclusion: 成功将在线模糊分类器从二分类扩展至多分类问题，为动态环境下的模糊规则学习提供了有效解决方案。

Abstract: This paper proposes a multi-class online fuzzy classifier for dynamic environments. A fuzzy classifier comprises a set of fuzzy if-then rules where human users determine the antecedent fuzzy sets beforehand. In contrast, the consequent real values are determined by learning from training data. In an online framework, not all training dataset patterns are available beforehand. Instead, only a few patterns are available at a time step, and the subsequent patterns become available at the following time steps. The conventional online fuzzy classifier considered only two-class problems. This paper investigates the extension to the conventional fuzzy classifiers for multi-class problems. We evaluate the performance of the multi-class online fuzzy classifiers through numerical experiments on synthetic dynamic data and also several benchmark datasets.

</details>


### [98] [The geometry of invariant learning: an information-theoretic analysis of data augmentation and generalization](https://arxiv.org/abs/2602.14423)
*Abdelali Bouyahia,Frédéric LeBlanc,Mario Marchand*

Main category: cs.LG

TL;DR: 提出信息论框架量化数据增强对泛化与不变性的影响，推导出包含分布散度、算法稳定性和增强敏感性的三Term泛化界，揭示增强几何特性(群直径)与泛化性能的内在权衡


<details>
  <summary>Details</summary>
Motivation: 数据增强虽在实践中有效提升泛化性，但其理论作用机制尚未被系统解释，尤其缺乏对增强如何影响模型不变性与泛化差距的定量分析框架

Method: 构建基于互信息的理论框架：1) 将增强分布建模为原始数据与变换分布的复合；2) 引入轨道平均损失函数；3) 在次高斯假设下推导三Term分解的泛化界；4) 定义群直径统一控制各项并关联增强几何特性

Result: 1) 泛化间隙可分解为：分布散度项、算法稳定性项、增强敏感性项；2) 群直径作为核心参数同时约束三项，揭示小直径保真度低正则化 vs 大直径强稳定高偏差的权衡；3) 数值实验验证理论界能准确追踪真实泛化间隙变化

Conclusion: 建立了数据增强的理论分析范式，证明其通过可控偏差-方差权衡提升泛化，为设计增强策略提供了可量化的几何指导原则（群直径调控）

Abstract: Data augmentation is one of the most widely used techniques to improve generalization in modern machine learning, often justified by its ability to promote invariance to label-irrelevant transformations. However, its theoretical role remains only partially understood. In this work, we propose an information-theoretic framework that systematically accounts for the effect of augmentation on generalization and invariance learning. Our approach builds upon mutual information-based bounds, which relate the generalization gap to the amount of information a learning algorithm retains about its training data. We extend this framework by modeling the augmented distribution as a composition of the original data distribution with a distribution over transformations, which naturally induces an orbit-averaged loss function. Under mild sub-Gaussian assumptions on the loss function and the augmentation process, we derive a new generalization bound that decompose the expected generalization gap into three interpretable terms: (1) a distributional divergence between the original and augmented data, (2) a stability term measuring the algorithm dependence on training data, and (3) a sensitivity term capturing the effect of augmentation variability. To connect our bounds to the geometry of the augmentation group, we introduce the notion of group diameter, defined as the maximal perturbation that augmentations can induce in the input space. The group diameter provides a unified control parameter that bounds all three terms and highlights an intrinsic trade-off: small diameters preserve data fidelity but offer limited regularization, while large diameters enhance stability at the cost of increased bias and sensitivity. We validate our theoretical bounds with numerical experiments, demonstrating that it reliably tracks and predicts the behavior of the true generalization gap.

</details>


### [99] [A unified framework for evaluating the robustness of machine-learning interpretability for prospect risking](https://arxiv.org/abs/2602.14430)
*Prithwijit Chowdhury,Ahmad Mustafa,Mohit Prabhushankar,Ghassan AlRegib*

Main category: cs.LG

TL;DR: 提出一个统一框架，利用反事实和因果必要性与充分性概念，评估和增强LIME与SHAP等XAI方法在油气勘探风险评估中机器学习分类器解释的可靠性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 机器学习分类器在油气勘探风险评估中缺乏透明度，XAI方法如LIME和SHAP生成的解释存在分歧，特别是对于复杂数据，需要基于因果理论的概念来提高解释的可信度。

Method: 构建统一框架生成反事实样本，量化特征必要性与充分性，并用于评估LIME和SHAP在高维结构化油气勘探数据上解释的稳健性。

Result: 通过稳健性测试，深入洞察了模型处理错误数据的能力，以及对于该油气指示数据集，哪种XAI模块与哪种模型配对效果最佳。

Conclusion: 该框架为评估和改善XAI解释策略的可信度提供了更可靠的方法，有助于提升油气勘探决策的透明度和可靠性。

Abstract: In geophysics, hydrocarbon prospect risking involves assessing the risks associated with hydrocarbon exploration by integrating data from various sources. Machine learning-based classifiers trained on tabular data have been recently used to make faster decisions on these prospects. The lack of transparency in the decision-making processes of such models has led to the emergence of explainable AI (XAI). LIME and SHAP are two such examples of these XAI methods which try to generate explanations of a particular decision by ranking the input features in terms of importance. However, explanations of the same scenario generated by these two different explanation strategies have shown to disagree or be different, particularly for complex data. This is because the definitions of "importance" and "relevance" differ for different explanation strategies. Thus, grounding these ranked features using theoretically backed causal ideas of necessity and sufficiency can prove to be a more reliable and robust way to improve the trustworthiness of the concerned explanation strategies.We propose a unified framework to generate counterfactuals as well as quantify necessity and sufficiency and use these to perform a robustness evaluation of the explanations provided by LIME and SHAP on high dimensional structured prospect risking data. This robustness test gives us deeper insights into the models capabilities to handle erronous data and which XAI module works best in pair with which model for our dataset for hydorcarbon indication.

</details>


### [100] [S2D: Selective Spectral Decay for Quantization-Friendly Conditioning of Neural Activations](https://arxiv.org/abs/2602.14432)
*Arnav Chavan,Nahush Lele,Udbhav Bamba,Sankalp Dayal,Aditi Raghunathan,Deepak Gupta*

Main category: cs.LG

TL;DR: 该论文针对大规模Transformer模型中的激活异常值问题提出Selective Spectral Decay (S^2D)方法，通过选择性衰减权重矩阵的最大奇异值来改善量化友好性，在W4A4量化下实现PTQ精度提升7%。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练Transformer模型中的激活异常值严重影响了模型量化效果，导致精度大幅下降。这种异常值的严重程度随预训练规模增加而加剧（从CLIP到SigLIP再到SigLIP2），亟需有效的量化友好性解决方案。

Method: 提出Selective Spectral Decay (S^2D)方法，基于激活异常值与权重主导奇异值之间的直接关联，通过在微调阶段选择性地正则化权重矩阵中对应最大奇异值的组件，实现几何原理上的条件化处理。

Result: S^2D显著降低激活异常值，产生固有量化友好的表示。在ImageNet上W4A4量化时PTQ精度提升达7%，与QAT结合可获得4%增益。该改进在下游任务和视觉语言模型中均有效。

Conclusion: S^2D为大规模模型的量化部署提供了高效解决方案，使得日益增大且严格训练的模型能够在不牺牲部署效率的前提下实现规模化，具有重要的实际应用价值。

Abstract: Activation outliers in large-scale transformer models pose a fundamental challenge to model quantization, creating excessively large ranges that cause severe accuracy drops during quantization. We empirically observe that outlier severity intensifies with pre-training scale (e.g., progressing from CLIP to the more extensively trained SigLIP and SigLIP2). Through theoretical analysis as well as empirical correlation studies, we establish the direct link between these activation outliers and dominant singular values of the weights. Building on this insight, we propose Selective Spectral Decay ($S^2D$), a geometrically-principled conditioning method that surgically regularizes only the weight components corresponding to the largest singular values during fine-tuning. Through extensive experiments, we demonstrate that $S^2D$ significantly reduces activation outliers and produces well-conditioned representations that are inherently quantization-friendly. Models trained with $S^2D$ achieve up to 7% improved PTQ accuracy on ImageNet under W4A4 quantization and 4% gains when combined with QAT. These improvements also generalize across downstream tasks and vision-language models, enabling the scaling of increasingly large and rigorously trained models without sacrificing deployment efficiency.

</details>


### [101] [Selective Synchronization Attention](https://arxiv.org/abs/2602.14445)
*Hasi Hays*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Transformer architecture has become the foundation of modern deep learning, yet its core self-attention mechanism suffers from quadratic computational complexity and lacks grounding in biological neural computation. We propose Selective Synchronization Attention (SSA), a novel attention mechanism that replaces the standard dot-product self-attention with a closed-form operator derived from the steady-state solution of the Kuramoto model of coupled oscillators. In SSA, each token is represented as an oscillator characterized by a learnable natural frequency and phase; the synchronization strength between token pairs, determined by a frequency-dependent coupling and phase-locking condition, serves as the attention weight. This formulation provides three key advantages: (i) natural sparsity arising from the phase-locking threshold, whereby tokens with incompatible frequencies automatically receive zero attention weight without explicit masking; (ii) unified positional-semantic encoding through the natural frequency spectrum, eliminating the need for separate positional encodings; and (iii) a single-pass, closed-form computation that avoids iterative ODE integration, with all components (coupling, order parameter, synchronization) derived from the oscillatory framework. We instantiate SSA within the Oscillatory Synchronization Network (OSN), a drop-in replacement for the Transformer block. Analysis of the synchronization matrices reveals non-uniform, head-diverse coupling patterns even at initialization, demonstrating a stronger architectural inductive bias than the approximately uniform attention produced by randomly initialized Transformers.

</details>


### [102] [WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity](https://arxiv.org/abs/2602.14452)
*Lei Chen,Yuan Meng,Xiaoyu Zhan,Zhi Wang,Wenwu Zhu*

Main category: cs.LG

TL;DR: 提出WiSparse方法，通过权重感知和混合粒度分配实现无需训练的激活稀疏化，在50%稀疏度下保持Llama3.1 97%的性能并实现21.4%的推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的激活稀疏化方法仅依赖激活信息和统一稀疏比率，忽略了权重交互与块间敏感性差异，导致性能次优。

Method: 提出权重感知机制融合激活幅值与权重范数识别重要通道，结合混合粒度分配：通过进化搜索进行全局预算分配保护敏感区域，再在块内细化以最小化重建误差。

Result: 在50%稀疏度下，WiSparse保持Llama3.1稠密模型97%的性能，超越最强基线2.23个百分点，端到端推理速度提升21.4%。

Conclusion: 该方法推进了无需训练的高效LLM推理边界，实现了训练-free框架下显著的速度提升。

Abstract: Large Language Models (LLMs) offer strong capabilities but incur high inference costs due to dense computation and memory access. Training-free activation sparsity is a promising approach for efficient LLM inference, yet existing methods often rely solely on activation information and uniform sparsity ratios. This overlooks the critical interplay with weights and inter-block sensitivity variation, leading to suboptimal performance. We identify two key phenomena in modern LLMs: 1) less significant activations may align with highly important weights, and 2) sparsity sensitivity varies non-monotonically across model blocks. We propose Weight-aware Mixed-Granularity Training-free Activation Sparsity (WiSparse), which leverages both activation and weight information for adaptive sparsity allocation. Specifically, we introduce a weight-aware mechanism integrating activation magnitudes with precomputed weight norms to accurately identify salient channels. This is combined with a mixed-granularity allocation scheme: a global budget is distributed across blocks via evolutionary search to protect sensitive regions, then refined within blocks to minimize reconstruction error. We improve sparse kernels and demonstrate effectiveness on three representative models. Notably, at 50% sparsity, WiSparse preserves 97% of Llama3.1's dense performance, surpassing the strongest baseline by 2.23 percentage points while achieving a 21.4% acceleration in end-to-end inference speed. Our research advances the limits of training-free approaches for efficient LLM inference, pushing the boundaries of achievable speedup without training.

</details>


### [103] [Traceable Latent Variable Discovery Based on Multi-Agent Collaboration](https://arxiv.org/abs/2602.14456)
*Huaming Du,Tao Hu,Yijie Huang,Yu Zhao,Guisong Liu,Tao Gu,Gang Kou,Carl Yang*

Main category: cs.LG

TL;DR: 提出TLVD框架，通过融合大语言模型的元数据推理能力与传统因果发现算法的数据驱动建模能力，解决潜在混杂因子假设和隐变量语义推断问题，在五个数据集上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现算法(TCDA)长期面临三大障碍：缺乏高质量数据、依赖无潜在混杂因子的假设、忽视隐变量的精确语义，这限制了因果发现在实际场景中的广泛应用。

Method: TLVD框架采用三阶段方法：(1)数据驱动构建含隐变量的因果图；(2)多LLM协作将隐变量推断建模为不完全信息博弈，求解贝叶斯纳什均衡(BNE)；(3)利用LLM进行证据探索确保可追溯性。

Result: 在三家医院的去标识化患者数据集和两个基准数据集上的综合评估显示，TLVD在Acc、CAcc和ECit指标上分别平均提升32.67%、62.21%和26.72%，证实了其有效性和可靠性。

Conclusion: TLVD通过结合LLM的元数据推理与数据驱动的因果建模，成功克服了传统方法的局限，为隐变量推断提供了可解释、可追溯的新范式，在真实世界应用中展现出显著优势。

Abstract: Revealing the underlying causal mechanisms in the real world is crucial for scientific and technological progress. Despite notable advances in recent decades, the lack of high-quality data and the reliance of traditional causal discovery algorithms (TCDA) on the assumption of no latent confounders, as well as their tendency to overlook the precise semantics of latent variables, have long been major obstacles to the broader application of causal discovery. To address this issue, we propose a novel causal modeling framework, TLVD, which integrates the metadata-based reasoning capabilities of large language models (LLMs) with the data-driven modeling capabilities of TCDA for inferring latent variables and their semantics. Specifically, we first employ a data-driven approach to construct a causal graph that incorporates latent variables. Then, we employ multi-LLM collaboration for latent variable inference, modeling this process as a game with incomplete information and seeking its Bayesian Nash Equilibrium (BNE) to infer the possible specific latent variables. Finally, to validate the inferred latent variables across multiple real-world web-based data sources, we leverage LLMs for evidence exploration to ensure traceability. We comprehensively evaluate TLVD on three de-identified real patient datasets provided by a hospital and two benchmark datasets. Extensive experimental results confirm the effectiveness and reliability of TLVD, with average improvements of 32.67% in Acc, 62.21% in CAcc, and 26.72% in ECit across the five datasets.

</details>


### [104] [Silent Inconsistency in Data-Parallel Full Fine-Tuning: Diagnosing Worker-Level Optimization Misalignment](https://arxiv.org/abs/2602.14462)
*Hong Li,Zhen Zhou,Honggang Zhang,Yuping Luo,Xinyue Wang,Han Gong,Zhiyuan Liu*

Main category: cs.LG

TL;DR: 本文发现数据并行训练中存在"静默不一致"问题，即尽管参数同步后权重一致，但各worker在梯度聚合前的损失和优化动态可能严重偏离。为此提出轻量级、模型无关的诊断框架，通过损失离散度、梯度范数离散度和梯度方向一致性三个指标，无需修改训练流程即可检测隐藏的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 同步all-reduce的数据并行训练虽能保证权重数值等价，但无法确保梯度聚合前各worker的优化动态一致。这种"静默不一致"在常规聚合监控信号下不可见，可能导致隐藏的稳定性问题，影响大规模LLM微调的可靠性和模型质量。

Method: 提出模型无关的诊断框架，利用标准训练管道中已有的信号量化worker级一致性。引入三个互补指标：损失离散度、梯度范数离散度和基于余弦相似度的梯度方向一致性。这些指标计算开销可忽略，且无需修改模型架构、同步机制或优化算法。

Result: 在8-NPU环境下对1B参数模型在Alpaca数据集上进行全参数微调实验表明，数据混洗和随机种子的不同步会导致损失/梯度离散度显著增加、方向对齐度下降，尽管全局平均损失曲线仍然平滑。所提指标成功揭示了常规监控无法检测的隐藏不稳定模式。

Conclusion: 该诊断指标为大规模数据并行微调中的潜在不一致性提供了可操作的可见性，使研究人员和工程师能够更可靠地诊断和评估训练配置，提升LLM训练的稳定性和效率。

Abstract: Data-parallel (DP) training with synchronous all-reduce is a dominant paradigm for full-parameter fine-tuning of large language models (LLMs). While parameter synchronization guarantees numerical equivalence of model weights after each iteration, it does not necessarily imply alignment of worker-level optimization dynamics before gradient aggregation. This paper identifies and studies this latent mismatch, termed \emph{silent inconsistency}, where cross-worker divergence in losses and gradients can remain invisible under conventional aggregated monitoring signals. We propose a lightweight, model-agnostic diagnostic framework that quantifies worker-level consistency using training signals readily available in standard pipelines. Specifically, we introduce three complementary metrics: loss dispersion, gradient-norm dispersion, and gradient-direction consistency measured by inter-worker cosine similarity. The proposed metrics incur negligible overhead and require no modification to model architecture, synchronization mechanisms, or optimization algorithms. We validate the framework by fully fine-tuning the 1B-parameter \texttt{openPangu-Embedded-1B-V1.1} model on the \texttt{tatsu-lab/alpaca} dataset using an 8-NPU DP setup, under controlled perturbations of cross-rank stochasticity. Experimental results show that progressively desynchronized data shuffling and random seeds lead to substantial increases in loss/gradient dispersion and reduced directional alignment, despite smooth globally averaged loss curves. These findings demonstrate that the proposed indicators provide actionable visibility into hidden instability modes in large-scale DP fine-tuning, enabling more reliable diagnosis and configuration assessment.

</details>


### [105] [LACONIC: Length-Aware Constrained Reinforcement Learning for LLM](https://arxiv.org/abs/2602.14468)
*Chang Liu,Yiran Zhao,Lawrence Liu,Yaoqi Ye,Csaba Szepesvári,Lin F. Yang*

Main category: cs.LG

TL;DR: LACONIC通过自适应长度代价约束强化学习训练，使大语言模型输出长度减少50%以上，同时保持或提升任务性能，且无需修改推理流程。


<details>
  <summary>Details</summary>
Motivation: 强化学习训练大语言模型时会产生过长响应，增加推理延迟和计算开销；现有固定启发式奖励塑形方法易与任务目标失配且调参脆弱。

Method: 在策略更新目标中引入长度代价，自适应调整代价系数，强制满足目标token预算，实现任务奖励与响应简洁性的平衡。

Result: 数学推理任务上，pass@1不变或提升的同时输出长度减少超50%；通用知识与多语言基准测试中性能保持且token减少44%，无需推理改动。

Conclusion: LACONIC提供理论保证的长度控制方法，能无缝集成到标准RL训练中，有效降低计算开销且部署开销极小。

Abstract: Reinforcement learning (RL) has enhanced the capabilities of large language models (LLMs) through reward-driven training. Nevertheless, this process can introduce excessively long responses, inflating inference latency and computational overhead. Prior length-control approaches typically rely on fixed heuristic reward shaping, which can misalign with the task objective and require brittle tuning. In this work, we propose LACONIC, a reinforcement learning method that enforces a target token budget during training. Specifically, we update policy models using an augmented objective that combines the task reward with a length-based cost. To balance brevity and task performance, the cost scale is adaptively adjusted throughout training. This yields robust length control while preserving task reward. We provide a theoretical guarantee that support the method. Across mathematical reasoning models and datasets, LACONIC preserves or improves pass@1 while reducing output length by over 50%. It maintains out-of-domain performance on general knowledge and multilingual benchmarks with 44% fewer tokens. Moreover, LACONIC integrates into standard RL-tuning with no inference changes and minimal deployment overhead.

</details>


### [106] [One Good Source is All You Need: Near-Optimal Regret for Bandits under Heterogeneous Noise](https://arxiv.org/abs/2602.14474)
*Aadirupa Saha,Amith Bhat,Haipeng Luo*

Main category: cs.LG

TL;DR: 提出SOAR算法解决多源多臂老虎机问题，通过自适应选择低方差数据源实现最优悔界


<details>
  <summary>Details</summary>
Motivation: 传统多臂老虎机假设单一数据源，而现实应用存在多个异构数据源且噪声方差未知。现有方法或忽略方差差异，或因选择高方差源导致悔界与最大方差σ²_max相关，存在潜在巨大性能差距

Method: Source-Optimistic Adaptive Regret minimization (SOAR)：利用尖锐的方差集中界快速剪枝高方差源，然后采用"平衡最小最大LCB-UCB方法"同步完成最优臂和最小方差源的双重识别任务

Result: 达到实例依赖悔界Õ(σ*² Σ(log T)/Δ_i + √(K Σ σ_j²))，其中σ*²为最小源方差。该结果匹配单源最优性能，仅增加Õ(√(K Σ σ_j²))的源识别附加成本，相比基线方法(可能受σ²_max影响)显著提升

Conclusion: 理论分析和在合成数据及MovieLens 25M真实数据集上的实验验证了SOAR在异构数据源环境下实现接近最优的悔界性能，能自动识别并有效利用最低方差源

Abstract: We study $K$-armed Multiarmed Bandit (MAB) problem with $M$ heterogeneous data sources, each exhibiting unknown and distinct noise variances $\{σ_j^2\}_{j=1}^M$. The learner's objective is standard MAB regret minimization, with the additional complexity of adaptively selecting which data source to query from at each round. We propose Source-Optimistic Adaptive Regret minimization (SOAR), a novel algorithm that quickly prunes high-variance sources using sharp variance-concentration bounds, followed by a `balanced min-max LCB-UCB approach' that seamlessly integrates the parallel tasks of identifying the best arm and the optimal (minimum-variance) data source. Our analysis shows SOAR achieves an instance-dependent regret bound of $\tilde{O}\left({σ^*}^2\sum_{i=2}^K \frac{\log T}{Δ_i} + \sqrt{K \sum_{j=1}^M σ_j^2}\right)$, up to preprocessing costs depending only on problem parameters, where ${σ^*}^2 := \min_j σ_j^2$ is the minimum source variance and $Δ_i$ denotes the suboptimality gap of the $i$-th arm. This result is both surprising as despite lacking prior knowledge of the minimum-variance source among $M$ alternatives, SOAR attains the optimal instance-dependent regret of standard single-source MAB with variance ${σ^*}^2$, while incurring only an small (and unavoidable) additive cost of $\tilde O(\sqrt{K \sum_{j=1}^M σ_j^2})$ towards the optimal (minimum variance) source identification. Our theoretical bounds represent a significant improvement over some proposed baselines, e.g. Uniform UCB or Explore-then-Commit UCB, which could potentially suffer regret scaling with $σ_{\max}^2$ in place of ${σ^*}^2$-a gap that can be arbitrarily large when $σ_{\max} \gg σ^*$. Experiments on multiple synthetic problem instances and the real-world MovieLens\;25M dataset, demonstrating the superior performance of SOAR over the baselines.

</details>


### [107] [Revisiting the Platonic Representation Hypothesis: An Aristotelian View](https://arxiv.org/abs/2602.14486)
*Fabian Gröger,Shuo Wen,Maria Brbić*

Main category: cs.LG

TL;DR: A new calibration method shows neural networks don't actually converge to a global "Platonic" reality model as claimed, but rather to shared local neighborhood relationships, leading to a revised "Aristotelian" hypothesis.


<details>
  <summary>Details</summary>
Motivation: The existing metrics for measuring representational similarity in neural networks are confounded by network scale (depth/width), which may invalidate the Platonic Representation Hypothesis claiming that representations converge to a common statistical model of reality.

Method: Introduced a permutation-based null-calibration framework that transforms any representational similarity metric into a calibrated score with statistical guarantees, then re-evaluated the Platonic Representation Hypothesis using this framework.

Result: After calibration, the apparent global convergence measured by spectral methods largely disappeared, but local neighborhood similarity (though not local distances) retained significant cross-modal agreement across different networks.

Conclusion: The Platonic Representation Hypothesis is not supported after proper calibration; instead, the authors propose the Aristotelian Representation Hypothesis: representations converge to shared local neighborhood relationships rather than a global statistical model.

Abstract: The Platonic Representation Hypothesis suggests that representations from neural networks are converging to a common statistical model of reality. We show that the existing metrics used to measure representational similarity are confounded by network scale: increasing model depth or width can systematically inflate representational similarity scores. To correct these effects, we introduce a permutation-based null-calibration framework that transforms any representational similarity metric into a calibrated score with statistical guarantees. We revisit the Platonic Representation Hypothesis with our calibration framework, which reveals a nuanced picture: the apparent convergence reported by global spectral measures largely disappears after calibration, while local neighborhood similarity, but not local distances, retains significant agreement across different modalities. Based on these findings, we propose the Aristotelian Representation Hypothesis: representations in neural networks are converging to shared local neighborhood relationships.

</details>


### [108] [Parameter-Efficient Fine-Tuning of LLMs with Mixture of Space Experts](https://arxiv.org/abs/2602.14490)
*Buze Zhang,Jinkai Tao,Zilang Zeng,Neil He,Ali Maatouk,Menglin Yang,Rex Ying*

Main category: cs.LG

TL;DR: 本文提出MoSLoRA，一种结合多种几何空间（欧几里得、双曲、球面）来改进大语言模型参数高效微调的方法，在数学基准测试上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法仅使用欧几里得空间，限制了捕捉语言数据中复杂几何结构的能力。单一的非欧几里得流形（双曲/球面）在表达力方面也存在局限。

Method: 提出混合空间（MoS）框架，同时使用多种几何空间；开发MoSLoRA，通过异构几何专家扩展LoRA，并采用轻量级路由机制实现动态空间选择。

Result: MoSLoRA持续优于基线方法，在MATH500上提升达5.6%，在MAWPS上提升达15.9%。研究还提供了曲率优化对训练稳定性和性能影响的实证洞察。

Conclusion: 结合多种几何空间是PEFT的一种有前景的方法，能够实现更丰富的表示和更好的性能，同时通过智能路由保持效率。

Abstract: Large Language Models (LLMs) have achieved remarkable progress, with Parameter-Efficient Fine-Tuning (PEFT) emerging as a key technique for downstream task adaptation. However, existing PEFT methods mainly operate in Euclidean space, fundamentally limiting their capacity to capture complex geometric structures inherent in language data. While alternative geometric spaces, like hyperbolic geometries for hierarchical data and spherical manifolds for circular patterns, offer theoretical advantages, forcing representations into a single manifold type ultimately limits expressiveness, even when curvature parameters are learnable. To address this, we propose Mixture of Space (MoS), a unified framework that leverages multiple geometric spaces simultaneously to learn richer, curvature-aware representations. Building on this scheme, we develop MoSLoRA, which extends Low-Rank Adaptation (LoRA) with heterogeneous geometric experts, enabling models to dynamically select or combine appropriate geometric spaces based on input context. Furthermore, to address the computational overhead of frequent manifold switching, we develop a lightweight routing mechanism. Moreover, we provide empirical insights into how curvature optimization impacts training stability and model performance. Our experiments across diverse benchmarks demonstrate that MoSLoRA consistently outperforms strong baselines, achieving up to 5.6% improvement on MATH500 and 15.9% on MAWPS.

</details>


### [109] [Covariance-Aware Transformers for Quadratic Programming and Decision Making](https://arxiv.org/abs/2602.14506)
*Kutay Tire,Yufan Zhang,Ege Onur Taga,Samet Oymak*

Main category: cs.LG

TL;DR: 该论文提出使用Transformer解决二次规划问题，特别是涉及协方差矩阵的决策问题。通过线性注意力机制模拟梯度下降，MLP模拟软阈值迭代，以及添加反馈回路，使Transformer能够解决无约束、ℓ1惩罚和ℓ1约束的QP问题。提出的Time2Decide方法通过显式输入协方差矩阵增强时间序列基础模型，在投资组合优化任务中超越了基线模型和传统"预测-然后优化"方法。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer在解决二次规划问题上的能力，特别是涉及协方差矩阵的决策问题。传统方法采用"预测-然后优化"的两步流程，而本研究旨在让Transformer能够端到端地直接解决这类优化问题，利用二阶统计信息提升决策性能。

Method: 1) 使用线性注意力机制，通过将矩阵变量逐行编码来模拟梯度下降迭代，从而解决无约束QP；2) 引入MLP模块模拟迭代软阈值算法，解决ℓ1惩罚QP；3) 为Transformer块添加额外反馈回路，解决ℓ1约束QP；4) 提出Time2Decide框架，将协方差矩阵显式输入时间序列基础模型。

Result: 1) Time2Decide在投资组合优化问题上始终优于基础时间序列模型；2) 在合适设置下，Time2Decide超越了经典的"预测-然后优化"流程；3) 实验验证了Transformer显式使用二阶统计信息（协方差矩阵）的有效性。

Conclusion: Transformer通过显式利用协方差矩阵等二阶统计信息，能够有效解决复杂的决策问题（如投资组合构建），并且可以在一次前向传播中完成，这为端到端优化提供了新思路，超越了传统的两步优化方法。

Abstract: We explore the use of transformers for solving quadratic programs and how this capability benefits decision-making problems that involve covariance matrices. We first show that the linear attention mechanism can provably solve unconstrained QPs by tokenizing the matrix variables (e.g.~$A$ of the objective $\frac{1}{2}x^\top Ax+b^\top x$) row-by-row and emulating gradient descent iterations. Furthermore, by incorporating MLPs, a transformer block can solve (i) $\ell_1$-penalized QPs by emulating iterative soft-thresholding and (ii) $\ell_1$-constrained QPs when equipped with an additional feedback loop. Our theory motivates us to introduce Time2Decide: a generic method that enhances a time series foundation model (TSFM) by explicitly feeding the covariance matrix between the variates. We empirically find that Time2Decide uniformly outperforms the base TSFM model for the classical portfolio optimization problem that admits an $\ell_1$-constrained QP formulation. Remarkably, Time2Decide also outperforms the classical "Predict-then-Optimize (PtO)" procedure, where we first forecast the returns and then explicitly solve a constrained QP, in suitable settings. Our results demonstrate that transformers benefit from explicit use of second-order statistics, and this can enable them to effectively solve complex decision-making problems, like portfolio construction, in one forward pass.

</details>


### [110] [DeepMTL2R: A Library for Deep Multi-task Learning to Rank](https://arxiv.org/abs/2602.14519)
*Chaosheng Dong,Peiyao Xiao,Yijia Wang,Kaiyi Ji*

Main category: cs.LG

TL;DR: DeepMTL2R is an open-source deep learning framework for Multi-task Learning to Rank that uses transformer self-attention to unify heterogeneous relevance signals, includes 21 MTL algorithms with multi-objective optimization for Pareto-optimal models, and demonstrates competitive performance on public datasets.


<details>
  <summary>Details</summary>
Motivation: Modern ranking systems need to simultaneously optimize multiple relevance criteria that may conflict with each other, requiring a unified and scalable solution that can handle diverse objectives effectively.

Method: DeepMTL2R leverages transformer self-attention mechanism to integrate heterogeneous relevance signals into a context-aware model, includes 21 state-of-the-art multi-task learning algorithms, and supports multi-objective optimization to identify Pareto-optimal ranking models.

Result: The framework demonstrates effectiveness on a publicly available dataset with competitive performance, and provides visualization of trade-offs among different objectives.

Conclusion: DeepMTL2R provides a scalable, expressive solution for modern ranking systems that captures complex dependencies and facilitates controlled comparisons across different multi-task learning strategies.

Abstract: This paper presents DeepMTL2R, an open-source deep learning framework for Multi-task Learning to Rank (MTL2R), where multiple relevance criteria must be optimized simultaneously. DeepMTL2R integrates heterogeneous relevance signals into a unified, context-aware model by leveraging the self-attention mechanism of transformer architectures, enabling effective learning across diverse and potentially conflicting objectives. The framework includes 21 state-of-the-art multi-task learning algorithms and supports multi-objective optimization to identify Pareto-optimal ranking models. By capturing complex dependencies and long-range interactions among items and labels, DeepMTL2R provides a scalable and expressive solution for modern ranking systems and facilitates controlled comparisons across MTL strategies. We demonstrate its effectiveness on a publicly available dataset, report competitive performance, and visualize the resulting trade-offs among objectives. DeepMTL2R is available at \href{https://github.com/amazon-science/DeepMTL2R}{https://github.com/amazon-science/DeepMTL2R}.

</details>


### [111] [Truly Adapting to Adversarial Constraints in Constrained MABs](https://arxiv.org/abs/2602.14543)
*Francesco Emanuele Stradi,Kalana Kalupahana,Matteo Castiglioni,Alberto Marchesi,Nicola Gatti*

Main category: cs.LG

TL;DR: This paper studies constrained multi-armed bandits in non-stationary environments, providing the first algorithms that simultaneously achieve optimal regret and positive constraint violation rates when constraints are stochastic while losses can vary arbitrarily. The algorithms work under full and bandit feedback settings, with guarantees that degrade smoothly with the adversariality of constraints.


<details>
  <summary>Details</summary>
Motivation: In constrained multi-armed bandits, learners must minimize losses while controlling unknown constraint violations. Prior work is limited to either stochastic constraints or relaxed adversarial benchmarks (e.g., competitive ratios). This paper addresses the gap by developing algorithms for non-stationary environments where both losses and constraints can change arbitrarily over time, aiming for optimal performance when constraints are stochastic but losses are adversarial.

Method: The authors design three algorithmic variants for different feedback scenarios: (1) Full feedback: an algorithm achieving Õ(√T+C) regret and positive violation, where C measures non-stationarity in constraints; (2) Bandit feedback for losses: extending the full-feedback guarantees; (3) Bandit feedback for constraints: an algorithm with Õ(√T+C) positive violation and Õ(√T+C√T) regret. The methods handle non-stationarity while balancing regret and constraint violation.

Result: The algorithms achieve optimal Õ(√T+C) rates for both regret and positive constraint violation under full feedback when constraints are stochastic. Under bandit feedback for constraints, the algorithm maintains Õ(√T+C) violation but has Õ(√T+C√T) regret. These are the first results with smooth degradation as constraints become more adversarial.

Conclusion: The paper provides comprehensive solutions for constrained multi-armed bandits in non-stationary environments, achieving near-optimal performance across different feedback settings. The work bridges the gap between stochastic and adversarial formulations, offering practical algorithms that control constraint violations while maintaining strong regret guarantees.

Abstract: We study the constrained variant of the \emph{multi-armed bandit} (MAB) problem, in which the learner aims not only at minimizing the total loss incurred during the learning dynamic, but also at controlling the violation of multiple \emph{unknown} constraints, under both \emph{full} and \emph{bandit feedback}. We consider a non-stationary environment that subsumes both stochastic and adversarial models and where, at each round, both losses and constraints are drawn from distributions that may change arbitrarily over time. In such a setting, it is provably not possible to guarantee both sublinear regret and sublinear violation. Accordingly, prior work has mainly focused either on settings with stochastic constraints or on relaxing the benchmark with fully adversarial constraints (\emph{e.g.}, via competitive ratios with respect to the optimum). We provide the first algorithms that achieve optimal rates of regret and \emph{positive} constraint violation when the constraints are stochastic while the losses may vary arbitrarily, and that simultaneously yield guarantees that degrade smoothly with the degree of adversariality of the constraints. Specifically, under \emph{full feedback} we propose an algorithm attaining $\widetilde{\mathcal{O}}(\sqrt{T}+C)$ regret and $\widetilde{\mathcal{O}}(\sqrt{T}+C)$ {positive} violation, where $C$ quantifies the amount of non-stationarity in the constraints. We then show how to extend these guarantees when only bandit feedback is available for the losses. Finally, when \emph{bandit feedback} is available for the constraints, we design an algorithm achieving $\widetilde{\mathcal{O}}(\sqrt{T}+C)$ {positive} violation and $\widetilde{\mathcal{O}}(\sqrt{T}+C\sqrt{T})$ regret.

</details>


### [112] [Governing AI Forgetting: Auditing for Machine Unlearning Compliance](https://arxiv.org/abs/2602.14553)
*Qinqi Lin,Ningning Ding,Lingjie Duan,Jianwei Huang*

Main category: cs.LG

TL;DR: This paper creates the first economic framework for auditing machine unlearning compliance, using game theory to show auditors should inspect less as deletion requests increase, and that disclosed auditing outperforms undisclosed methods.


<details>
  <summary>Details</summary>
Motivation: Legal mandates for data deletion ("right to be forgotten") are routinely ignored by AI operators, and there exists a fundamental gap between machine unlearning's technical feasibility and regulatory implementation that lacks an economic auditing framework.

Method: Integrates certified unlearning theory with regulatory enforcement via a game-theoretic model; transforms a complex bivariate nonlinear fixed-point problem into a tractable univariate auxiliary problem to analyze auditor-operator strategic interactions.

Result: Auditors can optimally reduce inspection intensity as deletion requests increase because weakened unlearning makes non-compliance easier to detect; undisclosed auditing paradoxically reduces cost-effectiveness compared to disclosed auditing.

Conclusion: The framework provides regulatory foundations for machine unlearning compliance, with counterintuitive policy implications consistent with real-world auditing reductions (e.g., China) and challenging conventional auditing wisdom.

Abstract: Despite legal mandates for the right to be forgotten, AI operators routinely fail to comply with data deletion requests. While machine unlearning (MU) provides a technical solution to remove personal data's influence from trained models, ensuring compliance remains challenging due to the fundamental gap between MU's technical feasibility and regulatory implementation. In this paper, we introduce the first economic framework for auditing MU compliance, by integrating certified unlearning theory with regulatory enforcement. We first characterize MU's inherent verification uncertainty using a hypothesis-testing interpretation of certified unlearning to derive the auditor's detection capability, and then propose a game-theoretic model to capture the strategic interactions between the auditor and the operator. A key technical challenge arises from MU-specific nonlinearities inherent in the model utility and the detection probability, which create complex strategic couplings that traditional auditing frameworks do not address and that also preclude closed-form solutions. We address this by transforming the complex bivariate nonlinear fixed-point problem into a tractable univariate auxiliary problem, enabling us to decouple the system and establish the equilibrium existence, uniqueness, and structural properties without relying on explicit solutions. Counterintuitively, our analysis reveals that the auditor can optimally reduce the inspection intensity as deletion requests increase, since the operator's weakened unlearning makes non-compliance easier to detect. This is consistent with recent auditing reductions in China despite growing deletion requests. Moreover, we prove that although undisclosed auditing offers informational advantages for the auditor, it paradoxically reduces the regulatory cost-effectiveness relative to disclosed auditing.

</details>


### [113] [Fluid-Agent Reinforcement Learning](https://arxiv.org/abs/2602.14559)
*Shishir Sharma,Doina Precup,Theodore J. Perkins*

Main category: cs.LG

TL;DR: 针对MARL固定智能体数量的局限性，提出动态创建智能体的流体框架，实验验证其能自适应调整团队规模并激发新策略。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体强化学习（MARL）假设环境中智能体数量固定，但现实场景中智能体数量动态变化且未知（如细胞分裂、企业拆分部门），现有方法无法适应这种动态性。

Method: 提出“流动智能体环境”框架，允许智能体动态创建新智能体；定义博弈论解概念，并在流体版Predator-Prey、Level-Based Foraging及新设计环境中测试多种MARL算法性能。

Result: 实验表明该框架能生成根据环境需求动态调整团队规模的智能体群体，且在流动环境中涌现出固定群体中未观察到的新颖策略。

Conclusion: 流体智能体框架有效解决了动态种群问题，为MARL在真实开放环境中的应用提供了新方向。

Abstract: The primary focus of multi-agent reinforcement learning (MARL) has been to study interactions among a fixed number of agents embedded in an environment. However, in the real world, the number of agents is neither fixed nor known a priori. Moreover, an agent can decide to create other agents (for example, a cell may divide, or a company may spin off a division). In this paper, we propose a framework that allows agents to create other agents; we call this a fluid-agent environment. We present game-theoretic solution concepts for fluid-agent games and empirically evaluate the performance of several MARL algorithms within this framework. Our experiments include fluid variants of established benchmarks such as Predator-Prey and Level-Based Foraging, where agents can dynamically spawn, as well as a new environment we introduce that highlights how fluidity can unlock novel solution strategies beyond those observed in fixed-population settings. We demonstrate that this framework yields agent teams that adjust their size dynamically to match environmental demands.

</details>


### [114] [DCTracks: An Open Dataset for Machine Learning-Based Drift Chamber Track Reconstruction](https://arxiv.org/abs/2602.14571)
*Qian Liyan,Zhang Yao,Yuan Ye,Zhang Zhaoke,Fang Jin,Jiang Shimiao,Zhang Jin,Li Ke,Liu Beijiang,Xu Chenglin,Zhang Yifan,Jia Xiaoqian,Qin Xiaoshuai,Huang Xingtao*

Main category: cs.LG

TL;DR: Introduces a Monte Carlo dataset for drift chamber track reconstruction to standardize ML evaluation and reports results comparing traditional algorithms with GNNs.


<details>
  <summary>Details</summary>
Motivation: To advance Machine Learning-based track reconstruction for drift chamber events by providing a standardized, comparable evaluation framework that enables rigorous and reproducible research.

Method: Creates a Monte Carlo dataset of single- and two-track drift chamber events, defines track reconstruction-specific evaluation metrics, and compares traditional algorithms against a Graph Neural Networks approach.

Result: Reports performance results for both traditional track reconstruction algorithms and Graph Neural Networks on the new dataset.

Conclusion: Provides a foundation for reproducible validation of future track reconstruction research by establishing standardized metrics and a publicly available dataset.

Abstract: We introduce a Monte Carlo (MC) dataset of single- and two-track drift chamber events to advance Machine Learning (ML)-based track reconstruction. To enable standardized and comparable evaluation, we define track reconstruction specific metrics and report results for traditional track reconstruction algorithms and a Graph Neural Networks (GNNs) method, facilitating rigorous, reproducible validation for future research.

</details>


### [115] [RNM-TD3: N:M Semi-structured Sparse Reinforcement Learning From Scratch](https://arxiv.org/abs/2602.14578)
*Isam Vrce,Andreas Kassler,Gökçe Aydos*

Main category: cs.LG

TL;DR: This paper introduces RNM-TD3, the first framework applying N:M structured sparsity to deep reinforcement learning. Unlike unstructured sparsity that limits hardware acceleration, their method enforces row-wise N:M sparsity during training, achieving up to 14% performance improvement at 50-75% sparsity while maintaining hardware compatibility and enabling potential training speedups.


<details>
  <summary>Details</summary>
Motivation: While unstructured fine-grained sparsity compresses DNNs with minimal performance loss, it prevents hardware acceleration due to irregular computation patterns. Structured coarse-grained sparsity enables acceleration but typically degrades performance and increases pruning complexity. The authors aim to balance compression, performance, and hardware efficiency by studying N:M structured sparsity in RL for the first time.

Method: The authors propose RNM-TD3, a framework that enforces row-wise N:M structured sparsity throughout training for off-policy deep reinforcement learning (TD3). This approach maintains compatibility with hardware accelerators that support N:M sparse matrix operations.

Result: Experiments on continuous-control benchmarks show RNM-TD3 outperforms dense TD3 at 50-75% sparsity (2:4 and 1:4 patterns), achieving up to 14% performance improvement on the Ant environment at 2:4 sparsity. The method remains competitive even at 87.5% sparsity (1:8 pattern).

Conclusion: The paper concludes that N:M structured sparsity effectively balances compression, performance, and hardware efficiency in DRL. RNM-TD3 enables potential training speedups while maintaining or improving performance, offering a practical solution for sparse DRL deployment.

Abstract: Sparsity is a well-studied technique for compressing deep neural networks (DNNs) without compromising performance. In deep reinforcement learning (DRL), neural networks with up to 5% of their original weights can still be trained with minimal performance loss compared to their dense counterparts. However, most existing methods rely on unstructured fine-grained sparsity, which limits hardware acceleration opportunities due to irregular computation patterns. Structured coarse-grained sparsity enables hardware acceleration, yet typically degrades performance and increases pruning complexity. In this work, we present, to the best of our knowledge, the first study on N:M structured sparsity in RL, which balances compression, performance, and hardware efficiency. Our framework enforces row-wise N:M sparsity throughout training for all networks in off-policy RL (TD3), maintaining compatibility with accelerators that support N:M sparse matrix operations. Experiments on continuous-control benchmarks show that RNM-TD3, our N:M sparse agent, outperforms its dense counterpart at 50%-75% sparsity (e.g., 2:4 and 1:4), achieving up to a 14% increase in performance at 2:4 sparsity on the Ant environment. RNM-TD3 remains competitive even at 87.5% sparsity (1:8), while enabling potential training speedups.

</details>


### [116] [Replicable Constrained Bandits](https://arxiv.org/abs/2602.14580)
*Matteo Bollini,Gianmarco Genalti,Francesco Emanuele Stradi,Matteo Castiglioni,Alberto Marchesi*

Main category: cs.LG

TL;DR: This paper introduces the first replicable algorithms for constrained multi-armed bandit problems, achieving the same regret and constraint violation bounds as non-replicable methods while ensuring reproducibility across executions.


<details>
  <summary>Details</summary>
Motivation: Machine learning experiments often lack reproducibility; algorithmic replicability guarantees consistent decisions across runs. Constrained MABs (with safety/resource constraints) are crucial for real-world applications but have never been studied under replicability requirements, as standard randomized algorithms cannot ensure this property.

Method: The authors systematically study replicability in constrained MABs. They first develop a replicable UCB-like algorithm for unconstrained MABs using the optimism-in-the-face-of-uncertainty principle with controlled randomness, then extend it to constrained settings where reward maximization and constraint satisfaction are simultaneously optimized.

Result: The proposed algorithms achieve O(√T) regret and constraint violation bounds (matching optimal non-replicable algorithms) while guaranteeing replicability with high probability—the first demonstration that replicability is achievable in constrained MABs without performance degradation.

Conclusion: Algorithmic replicability is feasible for constrained online learning. This bridges ML reproducibility concerns with learning theory, showing careful design can maintain optimality while ensuring consistent behavior. The independent contribution on unconstrained MABs suggests broader applicability of these techniques.

Abstract: Algorithmic \emph{replicability} has recently been introduced to address the need for reproducible experiments in machine learning. A \emph{replicable online learning} algorithm is one that takes the same sequence of decisions across different executions in the same environment, with high probability. We initiate the study of algorithmic replicability in \emph{constrained} MAB problems, where a learner interacts with an unknown stochastic environment for $T$ rounds, seeking not only to maximize reward but also to satisfy multiple constraints. Our main result is that replicability can be achieved in constrained MABs. Specifically, we design replicable algorithms whose regret and constraint violation match those of non-replicable ones in terms of $T$. As a key step toward these guarantees, we develop the first replicable UCB-like algorithm for \emph{unconstrained} MABs, showing that algorithms that employ the optimism in-the-face-of-uncertainty principle can be replicable, a result that we believe is of independent interest.

</details>


### [117] [Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow](https://arxiv.org/abs/2602.14587)
*Minh Nguyen*

Main category: cs.LG

TL;DR: A decoupled continuous-time actor-critic algorithm that alternately updates action-value rate (q) from diffusion generators on value function (V) and updates V via Hamiltonian-based value flow, solving discrete-time RL's action-ranking collapse under infinitesimal time steps.


<details>
  <summary>Details</summary>
Motivation: Standard discrete-time RL fails in continuous-time problems with non-uniform decisions because Q-function collapses to V as time gaps shrink, eliminating action ranking. Existing continuous-time methods are complex, sensitive to test processes, and entangle V and q in difficult optimization.

Method: Proposes alternating updates: (1) learn q-function from diffusion generators on V, (2) update V via Hamiltonian-based value flow that preserves action information even with infinitesimal time steps. Uses decoupled actor-critic architecture.

Result: Provides rigorous convergence proof via novel probabilistic arguments, circumventing the lack of Bellman-style contraction in generator-based Hamiltonians. Empirically outperforms prior methods by 21% profit in trading task.

Conclusion: Successfully decouples V and q learning in continuous-time RL, offering theoretically sound and empirically superior performance for challenging control problems including finance and robotics.

Abstract: Many real-world control problems, ranging from finance to robotics, evolve in continuous time with non-uniform, event-driven decisions. Standard discrete-time reinforcement learning (RL), based on fixed-step Bellman updates, struggles in this setting: as time gaps shrink, the $Q$-function collapses to the value function $V$, eliminating action ranking. Existing continuous-time methods reintroduce action information via an advantage-rate function $q$. However, they enforce optimality through complicated martingale losses or orthogonality constraints, which are sensitive to the choice of test processes. These approaches entangle $V$ and $q$ into a large, complex optimization problem that is difficult to train reliably. To address these limitations, we propose a novel decoupled continuous-time actor-critic algorithm with alternating updates: $q$ is learned from diffusion generators on $V$, and $V$ is updated via a Hamiltonian-based value flow that remains informative under infinitesimal time steps, where standard max/softmax backups fail. Theoretically, we prove rigorous convergence via new probabilistic arguments, sidestepping the challenge that generator-based Hamiltonians lack Bellman-style contraction under the sup-norm. Empirically, our method outperforms prior continuous-time and leading discrete-time baselines across challenging continuous-control benchmarks and a real-world trading task, achieving 21% profit over a single quarter$-$nearly doubling the second-best method.

</details>


### [118] [OPBench: A Graph Benchmark to Combat the Opioid Crisis](https://arxiv.org/abs/2602.14602)
*Tianyi Ma,Yiyang Li,Yiyue Qian,Zheyuan Zhang,Zehong Wang,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: OPBench是首个针对阿片类药物危机的综合图学习基准测试，包含三个应用领域的五个数据集，采用异构图和超图结构，并提供统一评估框架。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机肆虐全球，亟需计算解决方案，但缺乏系统评估图学习方法在真实危机场景中的综合基准。

Method: 提出OPBench基准，涵盖医疗理赔中毒品过量检测、数字平台毒品贩运检测、饮食模式药物滥用预测三个领域；与领域专家合作构建隐私合规的异构图/超图数据集；建立标准化评估协议、预定义数据划分和可复现基线。

Result: 通过大量实验分析现有图学习方法的优劣，为未来研究提供可操作的见解，开源代码和数据集。

Conclusion: OPBench为图学习方法在阿片类药物危机中的应用提供了公平、系统的比较平台，是未来研究的重要资源。

Abstract: The opioid epidemic continues to ravage communities worldwide, straining healthcare systems, disrupting families, and demanding urgent computational solutions. To combat this lethal opioid crisis, graph learning methods have emerged as a promising paradigm for modeling complex drug-related phenomena. However, a significant gap remains: there is no comprehensive benchmark for systematically evaluating these methods across real-world opioid crisis scenarios. To bridge this gap, we introduce OPBench, the first comprehensive opioid benchmark comprising five datasets across three critical application domains: opioid overdose detection from healthcare claims, illicit drug trafficking detection from digital platforms, and drug misuse prediction from dietary patterns. Specifically, OPBench incorporates diverse graph structures, including heterogeneous graphs and hypergraphs, to preserve the rich and complex relational information among drug-related data. To address data scarcity, we collaborate with domain experts and authoritative institutions to curate and annotate datasets while adhering to privacy and ethical guidelines. Furthermore, we establish a unified evaluation framework with standardized protocols, predefined data splits, and reproducible baselines to facilitate fair and systematic comparison among graph learning methods. Through extensive experiments, we analyze the strengths and limitations of existing graph learning methods, thereby providing actionable insights for future research in combating the opioid crisis. Our source code and datasets are available at https://github.com/Tianyi-Billy-Ma/OPBench.

</details>


### [119] [Directional Concentration Uncertainty: A representational approach to uncertainty quantification for generative models](https://arxiv.org/abs/2602.13264)
*Souradeep Chattopadhyay,Brendan Kennedy,Sai Munikoti,Soumik Sarkar,Karl Pazdernik*

Main category: cs.LG

TL;DR: 提出了一种名为方向集中不确定性（DCU）的新型不确定性量化方法，该方法利用冯·米塞斯-费舍尔分布测量嵌入向量的几何离散度，性能优于现有方法并可泛化到多模态任务。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型的不确定性量化方法依赖缺乏跨任务和跨模态泛化能力的僵化启发式规则，影响了模型的可信度和鲁棒性。

Method: 作者提出了方向集中不确定性（DCU），这是一种基于冯·米塞斯-费舍尔分布的统计方法，通过测量语言模型多个生成输出的连续嵌入向量的几何离散度来量化不确定性，无需任务特定的启发式规则。

Result: DCU的性能与语义熵等现有方法相当或更优，并且在复杂多模态任务上展现出良好的泛化能力。

Conclusion: DCU在多模态和智能体AI框架的不确定性量化中具有广阔的应用前景。

Abstract: In the critical task of making generative models trustworthy and robust, methods for Uncertainty Quantification (UQ) have begun to show encouraging potential. However, many of these methods rely on rigid heuristics that fail to generalize across tasks and modalities. Here, we propose a novel framework for UQ that is highly flexible and approaches or surpasses the performance of prior heuristic methods. We introduce Directional Concentration Uncertainty (DCU), a novel statistical procedure for quantifying the concentration of embeddings based on the von Mises-Fisher (vMF) distribution. Our method captures uncertainty by measuring the geometric dispersion of multiple generated outputs from a language model using continuous embeddings of the generated outputs without any task specific heuristics. In our experiments, we show that DCU matches or exceeds calibration levels of prior works like semantic entropy (Kuhn et al., 2023) and also generalizes well to more complex tasks in multi-modal domains. We present a framework for the wider potential of DCU and its implications for integration into UQ for multi-modal and agentic frameworks.

</details>


### [120] [Alignment Adapter to Improve the Performance of Compressed Deep Learning Models](https://arxiv.org/abs/2602.14635)
*Rohit Raj Rai,Abhishek Dhaka,Amit Awekar*

Main category: cs.LG

TL;DR: 提出轻量级滑动窗口适配器AlAd，通过对齐压缩模型与原始大模型的词元嵌入提升性能，支持即插即用或联合微调，在BERT系列模型上显著提升压缩模型效果且开销极小


<details>
  <summary>Details</summary>
Motivation: 压缩深度学习模型在资源受限环境中部署必要，但性能常落后于大型模型，需缩小这一差距

Method: 设计基于滑动窗口的Alignment Adapter (AlAd)，对齐压缩模型与原始大模型的词级嵌入，保留局部上下文语义，兼容不同维度/架构及压缩方法

Result: 在BERT系列模型及三项词级NLP任务实验中，AlAd以极低尺寸和延迟开销显著提升压缩模型性能

Conclusion: AlAd可作为即插即用模块或联合微调组件，高效弥合压缩模型与大模型性能差距

Abstract: Compressed Deep Learning (DL) models are essential for deployment in resource-constrained environments. But their performance often lags behind their large-scale counterparts. To bridge this gap, we propose Alignment Adapter (AlAd): a lightweight, sliding-window-based adapter. It aligns the token-level embeddings of a compressed model with those of the original large model. AlAd preserves local contextual semantics, enables flexible alignment across differing dimensionalities or architectures, and is entirely agnostic to the underlying compression method. AlAd can be deployed in two ways: as a plug-and-play module over a frozen compressed model, or by jointly fine-tuning AlAd with the compressed model for further performance gains. Through experiments on BERT-family models across three token-level NLP tasks, we demonstrate that AlAd significantly boosts the performance of compressed models with only marginal overhead in size and latency.

</details>


### [121] [An Embarrassingly Simple Way to Optimize Orthogonal Matrices at Scale](https://arxiv.org/abs/2602.14656)
*Adrián Javaloy,Antonio Vergari*

Main category: cs.LG

TL;DR: 本文提出POGO优化器，仅需5次矩阵乘法即可在保持正交约束的同时实现快速优化，可在几分钟内处理数千个正交矩阵，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 正交约束在鲁棒和概率机器学习中无处不在，但现有优化器计算开销大，难以扩展到成百上千个约束的问题。Landing算法虽是个例外，但会暂时放松正交性，存在局限性。

Method: 重新审视并改进Landing算法，支持现代自适应优化器，确保正交约束始终有效满足，同时降低超参数数量，算法仅需5次矩阵乘法，具有GPU友好性。

Result: POGO在多个具有挑战性的基准测试中显著优于近期优化器，能在几分钟内优化数千个正交矩阵，而替代方法需要数小时，在实践中始终维持正交性。

Conclusion: POGO为大规模机器学习中正交约束的应用设立了里程碑，实现了可扩展的高效优化，PyTorch实现已开源。

Abstract: Orthogonality constraints are ubiquitous in robust and probabilistic machine learning. Unfortunately, current optimizers are computationally expensive and do not scale to problems with hundreds or thousands of constraints. One notable exception is the Landing algorithm (Ablin et al., 2024) which, however comes at the expense of temporarily relaxing orthogonality. In this work, we revisit and improve on the ideas behind Landing, enabling the inclusion of modern adaptive optimizers while ensuring that orthogonal constraints are effectively met. Remarkably, these improvements come at little to no cost, and reduce the number of required hyperparemeters. Our algorithm POGO is fast and GPU-friendly, consisting of only 5 matrix products, and in practice maintains orthogonality at all times. On several challenging benchmarks, POGO greatly outperforms recent optimizers and shows it can optimize problems with thousands of orthogonal matrices in minutes while alternatives would take hours. As such, POGO sets a milestone to finally exploit orthogonality constraints in ML at scale. A PyTorch implementation of POGO is publicly available at https://github.com/adrianjav/pogo.

</details>


### [122] [Exposing Diversity Bias in Deep Generative Models: Statistical Origins and Correction of Diversity Error](https://arxiv.org/abs/2602.14682)
*Farzan Farnia,Mohammad Jalali,Azim Ospanov*

Main category: cs.LG

TL;DR: 研究发现现代生成模型存在系统性多样性偏差，生成的样本比真实数据多样性更低，这是因为有限样本训练集低估了真实分布的多样性，优化目标导致多样性丢失。基于Vendi和RKE分数的多样性感知正则化可能是解决方案。


<details>
  <summary>Details</summary>
Motivation: 生成模型在样本质量上很成功，但是否能忠实捕捉数据分布的多样性尚不明确。

Method: 使用参考自由熵基多样性评分Vendi和RKE，在多个基准数据集上比较SOTA模型生成样本与测试样本的多样性差异，并分析有限样本下熵基多样性评分的统计行为。

Result: 测试数据的多样性评分始终显著高于生成样本，表明现代生成模型存在系统性多样性低估；有限样本下多样性评分会低估真实分布多样性，导致优化过程损失多样性。

Conclusion: 提出基于Vendi和RKE的多样性感知正则化和指导策略作为缓解偏差的原则性方向，并提供了实证证据支持其潜力。

Abstract: Deep generative models have achieved great success in producing high-quality samples, making them a central tool across machine learning applications. Beyond sample quality, an important yet less systematically studied question is whether trained generative models faithfully capture the diversity of the underlying data distribution. In this work, we address this question by directly comparing the diversity of samples generated by state-of-the-art models with that of test samples drawn from the target data distribution, using recently proposed reference-free entropy-based diversity scores, Vendi and RKE. Across multiple benchmark datasets, we find that test data consistently attains substantially higher Vendi and RKE diversity scores than the generated samples, suggesting a systematic downward diversity bias in modern generative models. To understand the origin of this bias, we analyze the finite-sample behavior of entropy-based diversity scores and show that their expected values increase with sample size, implying that diversity estimated from finite training sets could inherently underestimate the diversity of the true distribution. As a result, optimizing the generators to minimize divergence to empirical data distributions would induce a loss of diversity. Finally, we discuss potential diversity-aware regularization and guidance strategies based on Vendi and RKE as principled directions for mitigating this bias, and provide empirical evidence suggesting their potential to improve the results.

</details>


### [123] [SynthSAEBench: Evaluating Sparse Autoencoders on Scalable Realistic Synthetic Data](https://arxiv.org/abs/2602.14687)
*David Chanin,Adrià Garriga-Alonso*

Main category: cs.LG

TL;DR: 该论文提出SynthSAEBench，一个生成大规模真实合成数据的工具包，用于标准化评估稀疏自编码器（SAEs）。该基准能够复现已知SAE现象并发现新的失败模式，帮助研究人员在扩展到大型语言模型前精确诊断问题并验证架构改进。


<details>
  <summary>Details</summary>
Motivation: 当前SAE基准在大型语言模型上噪声太大，无法区分架构改进，而现有合成数据实验规模太小且不真实，缺乏有意义的比较标准。改进SAE需要能够精确验证架构创新的基准测试工具。

Method: 开发SynthSAEBench工具包，生成具有相关性、层次性和叠加性等真实特征的大规模合成数据，并提供标准化基准模型SynthSAEBench-16k，使不同SAE架构可直接比较。

Result: 该基准复现了重建与潜在质量指标脱节、SAE探测效果差、以及L0介导的精确率-召回率权衡等现象；并发现新失败模式：匹配追踪SAE利用叠加噪声改善重建却不学习真实特征，表明更具表达力的编码器容易过拟合。

Conclusion: SynthSAEBench通过提供真实特征和可控消融实验，补充了现有LLM基准，使研究人员能精确定位SAE失败模式并在扩展到LLM前验证架构改进，提升研究效率。

Abstract: Improving Sparse Autoencoders (SAEs) requires benchmarks that can precisely validate architectural innovations. However, current SAE benchmarks on LLMs are often too noisy to differentiate architectural improvements, and current synthetic data experiments are too small-scale and unrealistic to provide meaningful comparisons. We introduce SynthSAEBench, a toolkit for generating large-scale synthetic data with realistic feature characteristics including correlation, hierarchy, and superposition, and a standardized benchmark model, SynthSAEBench-16k, enabling direct comparison of SAE architectures. Our benchmark reproduces several previously observed LLM SAE phenomena, including the disconnect between reconstruction and latent quality metrics, poor SAE probing results, and a precision-recall trade-off mediated by L0. We further use our benchmark to identify a new failure mode: Matching Pursuit SAEs exploit superposition noise to improve reconstruction without learning ground-truth features, suggesting that more expressive encoders can easily overfit. SynthSAEBench complements LLM benchmarks by providing ground-truth features and controlled ablations, enabling researchers to precisely diagnose SAE failure modes and validate architectural improvements before scaling to LLMs.

</details>


### [124] [A Critical Look at Targeted Instruction Selection: Disentangling What Matters (and What Doesn't)](https://arxiv.org/abs/2602.14696)
*Nihal V. Nayak,Paula Rodriguez-Diaz,Neha Hulkund,Sara Beery,David Alvarez-Melis*

Main category: cs.LG

TL;DR: 该研究针对大语言模型指令微调中的数据选择问题，通过解耦数据表示与选择算法，系统分析发现梯度表示在低预算下配合贪心轮选效果最佳，并统一现有算法为距离最小化框架


<details>
  <summary>Details</summary>
Motivation: 现有指令选择方法存在碎片化、缺乏零基线、组件贡献混淆等问题，导致实践者难以获得可操作的指导

Method: 提出分析框架解耦数据表示（梯度/嵌入等）与选择算法，进行跨模型/任务/预算的受控对比实验

Result: 梯度表示能稳定预测性能；低预算时梯度+贪心轮选最优但优势随预算增加消失；多算法可统一为子集-查询集距离最小化

Conclusion: 为指令选择提供原理性指导，建立系统化数据选择基础

Abstract: Instruction fine-tuning of large language models (LLMs) often involves selecting a subset of instruction training data from a large candidate pool, using a small query set from the target task. Despite growing interest, the literature on targeted instruction selection remains fragmented and opaque: methods vary widely in selection budgets, often omit zero-shot baselines, and frequently entangle the contributions of key components. As a result, practitioners lack actionable guidance on selecting instructions for their target tasks. In this work, we aim to bring clarity to this landscape by disentangling and systematically analyzing the two core ingredients: data representation and selection algorithms. Our framework enables controlled comparisons across models, tasks, and budgets. We find that only gradient-based data representations choose subsets whose similarity to the query consistently predicts performance across datasets and models. While no single method dominates, gradient-based representations paired with a greedy round-robin selection algorithm tend to perform best on average at low budgets, but these benefits diminish at larger budgets. Finally, we unify several existing selection algorithms as forms of approximate distance minimization between the selected subset and the query set, and support this view with new generalization bounds. More broadly, our findings provide critical insights and a foundation for more principled data selection in LLM fine-tuning. The code is available at https://github.com/dcml-lab/targeted-instruction-selection.

</details>


### [125] [D2-LoRA: A Synergistic Approach to Differential and Directional Low-Rank Adaptation](https://arxiv.org/abs/2602.14728)
*Nozomu Fujisawa,Masaaki Kondo*

Main category: cs.LG

TL;DR: D2-LoRA是一种高效参数微调方法，在仅5k训练样本和两阶段训练下，于8个问答阅读理解任务中达到76.4%平均准确率，比LoRA提升2.2个百分点，同时保持推理时可合并且几乎无数值误差


<details>
  <summary>Details</summary>
Motivation: 在有限数据和算力约束下优化参数高效微调设计，解决现有方法如LoRA在低资源场景下性能不足、训练不稳定及推理延迟问题

Method: 结合符号低秩残差更新、加减法组件与列方向投影机制，通过训练时保持每列权重接近原始范数来稳定训练，训练后合并适配器至单一权重矩阵消除推理延迟

Result: 1) 8项基准测试平均准确率76.4%，比LoRA高2.2点（匹配参数量时高1.6点）；2) 比DoRA多数任务表现更优；3) 生成任务ROUGE-L提升1.2；4) 训练波动降低36%；5) 数值误差仅0.03%；6) 推理吞吐量提升1.91倍；7) 训练开销19%

Conclusion: D2-LoRA通过架构创新实现高效稳定微调，在低资源场景显著优于现有方法，几何分析证实列投影机制对训练稳定的关键作用，兼具性能与实用性

Abstract: We systematically investigate the parameter-efficient fine-tuning design space under practical data and compute constraints, and propose D2-LoRA. D2-LoRA achieves 76.4 percent average accuracy across eight question answering and reading comprehension benchmarks using only 5k training samples per task and two epochs, while preserving algebraic mergeability at inference with near-exact numerical equivalence. The method combines signed low-rank residual updates with additive and subtractive components, together with a train-time column-wise projection that keeps each column close to its original norm. After training, the adapter is merged into a single weight matrix, adding zero inference latency. Compared with LoRA, D2-LoRA improves average accuracy by 2.2 percentage points; at matched parameter counts (LoRA rank 2r versus D2-LoRA rank r), the improvement is 1.6 points, indicating gains from architectural design rather than increased parameterization. Compared with DoRA, it matches or exceeds performance on most tasks. Beyond QA and reading comprehension, D2-LoRA improves generative tasks (plus 1.2 ROUGE-L and plus 1.1 percent win rate) and shows 36 percent lower training volatility. The merge preserves numerical fidelity (mean gap about 0.03 percentage points) and recovers about 1.91x evaluation throughput. Training overhead is 19 percent, comparable to DoRA, and decreases with longer input sequences. We provide a geometric analysis explaining how the projection stabilizes training, together with ablation studies isolating the contribution of each design component.

</details>


### [126] [Scale redundancy and soft gauge fixing in positively homogeneous neural networks](https://arxiv.org/abs/2602.14729)
*Rodrigo Carmo Terin*

Main category: cs.LG

TL;DR: Researchers show that neural networks with homogeneous activations possess a gauge symmetry, and introduce a norm-balancing penalty that improves optimization stability and suppresses scale drift without affecting model expressivity, bridging gauge theory with deep learning.


<details>
  <summary>Details</summary>
Motivation: To understand and address optimization challenges (like scale drift and limited stable learning rates) in neural networks with positively homogeneous activations by interpreting their reparametrization symmetry through the lens of gauge theory.

Method: 1. Interpret neuron-wise rescaling symmetry as gauge redundancy. 2. Introduce gauge-adapted coordinates to separate function-invariant directions from scale-imbalance directions. 3. Propose a soft orbit-selection functional (norm-balancing penalty) inspired by gauge fixing in field theory. 4. Analyze its effects theoretically and validate through controlled experiments.

Result: Theoretical: The penalty induces dissipative relaxation of scale-imbalance modes while preserving the network's input-output function. Experimental: The method expands the stable learning-rate regime and suppresses scale drift without reducing the model's expressivity.

Conclusion: This work establishes a structural connection between gauge-orbit geometry and optimization conditioning, providing a concrete link between gauge-theoretic concepts and practical deep learning optimization.

Abstract: Neural networks with positively homogeneous activations exhibit an exact continuous reparametrization symmetry: neuron-wise rescalings generate parameter-space orbits along which the input--output function is invariant. We interpret this symmetry as a gauge redundancy and introduce gauge-adapted coordinates that separate invariant and scale-imbalance directions. Inspired by gauge fixing in field theory, we introduce a soft orbit-selection (norm-balancing) functional acting only on redundant scale coordinates. We show analytically that it induces dissipative relaxation of imbalance modes to preserve the realized function. In controlled experiments, this orbit-selection penalty expands the stable learning-rate regime and suppresses scale drift without changing expressivity. These results establish a structural link between gauge-orbit geometry and optimization conditioning, providing a concrete connection between gauge-theoretic concepts and machine learning.

</details>


### [127] [Inner Loop Inference for Pretrained Transformers: Unlocking Latent Capabilities Without Training](https://arxiv.org/abs/2602.14759)
*Jonathan Lys,Vincent Gripon,Bastien Pasdeloup,Lukas Mauch,Fabien Cardinaux,Ghouthi Boukli Hacene*

Main category: cs.LG

TL;DR: Proposes inference-time inner looping for Transformers: repeatedly re-applying selected layers during inference yields modest accuracy gains and more stable representations in frozen pretrained models.


<details>
  <summary>Details</summary>
Motivation: Observing that Transformer inner representations act as iterative refinements with shared latent spaces across layers, suggesting additional refinement could improve performance.

Method: Introduce inference-time inner looping—re-applying a selected block range multiple times during test time in frozen pretrained language models.

Result: Modest but consistent accuracy improvements across multiple benchmarks; latent trajectory analyses show more stable state evolution and continued semantic refinement.

Conclusion: Simple test-time looping effectively extends computation in frozen pretrained models, extracting additional refinement without retraining.

Abstract: Deep Learning architectures, and in particular Transformers, are conventionally viewed as a composition of layers. These layers are actually often obtained as the sum of two contributions: a residual path that copies the input and the output of a Transformer block. As a consequence, the inner representations (i.e. the input of these blocks) can be interpreted as iterative refinement of a propagated latent representation. Under this lens, many works suggest that the inner space is shared across layers, meaning that tokens can be decoded at early stages. Mechanistic interpretability even goes further by conjecturing that some layers act as refinement layers. Following this path, we propose inference-time inner looping, which prolongs refinement in pretrained off-the-shelf language models by repeatedly re-applying a selected block range. Across multiple benchmarks, inner looping yields modest but consistent accuracy improvements. Analyses of the resulting latent trajectories suggest more stable state evolution and continued semantic refinement. Overall, our results suggest that additional refinement can be obtained through simple test-time looping, extending computation in frozen pretrained models.

</details>


### [128] [Universal Algorithm-Implicit Learning](https://arxiv.org/abs/2602.14761)
*Stefano Woerner,Seong Joon Oh,Christian F. Baumgartner*

Main category: cs.LG

TL;DR: This paper introduces a theoretical framework for universal meta-learning and presents TAIL, a transformer-based algorithm that generalizes across domains, modalities, and label spaces through three innovations: cross-modal random projections, extrapolatable label embeddings, and efficient inline processing, achieving SOTA performance with massive computational savings.


<details>
  <summary>Details</summary>
Motivation: Current meta-learning methods are constrained to narrow task distributions with fixed feature and label spaces, limiting real-world applicability. The literature also lacks precise definitions for key terms like "universal" and "general-purpose", hindering comparability and progress.

Method: The authors propose a theoretical framework that formally defines practical universality and distinguishes between algorithm-explicit vs. algorithm-implicit learning. Guided by this, they develop TAIL, a transformer-based algorithm-implicit meta-learner featuring: (1) random projections for cross-modal feature encoding, (2) random injection label embeddings that extrapolate to larger label spaces, and (3) efficient inline query processing.

Result: TAIL achieves state-of-the-art performance on standard few-shot benchmarks while generalizing to unseen domains. Critically, it generalizes to unseen modalities (e.g., text classification when trained only on images), handles up to 20× more classes than seen during training, and delivers orders-of-magnitude computational savings over prior transformer-based meta-learners.

Conclusion: The theoretical framework provides a principled vocabulary for universal meta-learning, and TAIL demonstrates that algorithm-implicit approaches can achieve broad cross-domain, cross-modal, and cross-label generalization with superior efficiency, advancing toward truly universal meta-learning systems.

Abstract: Current meta-learning methods are constrained to narrow task distributions with fixed feature and label spaces, limiting applicability. Moreover, the current meta-learning literature uses key terms like "universal" and "general-purpose" inconsistently and lacks precise definitions, hindering comparability. We introduce a theoretical framework for meta-learning which formally defines practical universality and introduces a distinction between algorithm-explicit and algorithm-implicit learning, providing a principled vocabulary for reasoning about universal meta-learning methods. Guided by this framework, we present TAIL, a transformer-based algorithm-implicit meta-learner that functions across tasks with varying domains, modalities, and label configurations. TAIL features three innovations over prior transformer-based meta-learners: random projections for cross-modal feature encoding, random injection label embeddings that extrapolate to larger label spaces, and efficient inline query processing. TAIL achieves state-of-the-art performance on standard few-shot benchmarks while generalizing to unseen domains. Unlike other meta-learning methods, it also generalizes to unseen modalities, solving text classification tasks despite training exclusively on images, handles tasks with up to 20$\times$ more classes than seen during training, and provides orders-of-magnitude computational savings over prior transformer-based approaches.

</details>


### [129] [Learning Structural Hardness for Combinatorial Auctions: Instance-Dependent Algorithm Selection via Graph Neural Networks](https://arxiv.org/abs/2602.14772)
*Sungwoo Kang*

Main category: cs.LG

TL;DR: Proposes a hybrid algorithm selection framework for combinatorial auction winner determination that uses a lightweight MLP to predict instance hardness and selectively deploy a specialized GNN solver, achieving better performance than greedy methods while avoiding the high cost of always using expensive solvers.


<details>
  <summary>Details</summary>
Motivation: The Winner Determination Problem (WDP) is NP-hard, and greedy heuristics fail unpredictably on certain instances. Current ML approaches attempt to replace solvers entirely, but recent evidence shows GNNs rarely outperform well-tuned classical methods on standard benchmarks, necessitating a different approach.

Method: Designs a 20-dimensional structural feature vector and trains a lightweight MLP hardness classifier to predict greedy optimality gap. Identifies "whale-fish" trap structures where greedy fails and develops a heterogeneous GNN specialist for these hard instances, combining them into a hybrid allocator with greedy solvers.

Result: MLP classifier achieves MAE 0.033, Pearson correlation 0.937, and binary classification accuracy 94.7%. The GNN specialist reaches ~0% optimality gap on adversarial configurations (vs 3.75-59.24% for greedy). The hybrid allocator achieves 0.51% overall gap on mixed distributions, while honest evaluation shows GNNs do not outperform Gurobi on CATS benchmarks (0.45-0.71 vs 0.20 gap).

Conclusion: Learning to predict when to deploy expensive solvers (algorithm selection) is more tractable and effective than learning to replace them entirely, as demonstrated by the successful hybrid approach that selectively uses GNNs only on hard instances.

Abstract: The Winner Determination Problem (WDP) in combinatorial auctions is NP-hard, and no existing method reliably predicts which instances will defeat fast greedy heuristics. The ML-for-combinatorial-optimization community has focused on learning to \emph{replace} solvers, yet recent evidence shows that graph neural networks (GNNs) rarely outperform well-tuned classical methods on standard benchmarks. We pursue a different objective: learning to predict \emph{when} a given instance is hard for greedy allocation, enabling instance-dependent algorithm selection. We design a 20-dimensional structural feature vector and train a lightweight MLP hardness classifier that predicts the greedy optimality gap with mean absolute error 0.033, Pearson correlation 0.937, and binary classification accuracy 94.7\% across three random seeds. For instances identified as hard -- those exhibiting ``whale-fish'' trap structure where greedy provably fails -- we deploy a heterogeneous GNN specialist that achieves ${\approx}0\%$ optimality gap on all six adversarial configurations tested (vs.\ 3.75--59.24\% for greedy). A hybrid allocator combining the hardness classifier with GNN and greedy solvers achieves 0.51\% overall gap on mixed distributions. Our honest evaluation on CATS benchmarks confirms that GNNs do not outperform Gurobi (0.45--0.71 vs.\ 0.20 gap), motivating the algorithm selection framing. Learning \emph{when} to deploy expensive solvers is more tractable than learning to replace them.

</details>


### [130] [On the Stability of Nonlinear Dynamics in GD and SGD: Beyond Quadratic Potentials](https://arxiv.org/abs/2602.14789)
*Rotem Mulayoff,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 本文挑战梯度下降线性化分析的可靠性，推导出基于高阶导数的非线性稳定振荡精确判据，并证明SGD稳定性由最坏批次决定而非平均效应。


<details>
  <summary>Details</summary>
Motivation: 训练迭代的动态稳定性决定优化算法的极小值选择，稳定解对应平坦极小值具有良好泛化性。但现有研究多依赖线性化，其是否能捕捉完整非线性行为尚不明确。最新发现表明梯度下降在线性不稳定极小值附近可能稳定振荡并收敛，揭示线性分析的局限性。

Method: 显式研究非线性项影响，推导出多元情形下梯度下降近极小值稳定振荡的精确准则（依赖高阶导数），并扩展至随机梯度下降：考察单批次不稳定性对期望动态的影响，证明全批次线性稳定则SGD非线性动态期望稳定。

Result: 1) 获得梯度下降稳定振荡的精确非线性判据，推广现有结果；2) 揭示SGD中单批次不稳定即可导致期望发散，稳定性由最坏批次而非平均决定；3) 证明全批次线性稳定是SGD非线性期望稳定的充分条件。

Conclusion: 非线性效应是稳定性分析的核心，线性化方法可能严重误导；SGD稳定性由个体批次最坏行为主导；为理解优化算法动态提供了更准确的理论框架。

Abstract: The dynamical stability of the iterates during training plays a key role in determining the minima obtained by optimization algorithms. For example, stable solutions of gradient descent (GD) correspond to flat minima, which have been associated with favorable features. While prior work often relies on linearization to determine stability, it remains unclear whether linearized dynamics faithfully capture the full nonlinear behavior. Recent work has shown that GD may stably oscillate near a linearly unstable minimum and still converge once the step size decays, indicating that linear analysis can be misleading. In this work, we explicitly study the effect of nonlinear terms. Specifically, we derive an exact criterion for stable oscillations of GD near minima in the multivariate setting. Our condition depends on high-order derivatives, generalizing existing results. Extending the analysis to stochastic gradient descent (SGD), we show that nonlinear dynamics can diverge in expectation even if a single batch is unstable. This implies that stability can be dictated by a single batch that oscillates unstably, rather than an average effect, as linear analysis suggests. Finally, we prove that if all batches are linearly stable, the nonlinear dynamics of SGD are stable in expectation.

</details>


### [131] [Extending Multi-Source Bayesian Optimization With Causality Principles](https://arxiv.org/abs/2602.14791)
*Luuk Jacobs,Mohammad Ali Javidian*

Main category: cs.LG

TL;DR: 本文提出多源因果贝叶斯优化（MSCBO），通过整合多源贝叶斯优化与因果贝叶斯优化，克服传统MSBO的i.i.d.假设限制，实现降维、降本增效和高维可扩展的优化。


<details>
  <summary>Details</summary>
Motivation: 传统多源贝叶斯优化假设输入变量独立同分布，在存在因果信息和可干预场景（如临床试验、政策制定）下受限。单源因果贝叶斯优化虽能建模变量依赖关系，但缺乏多源扩展，需建立同时利用多源信息和因果关系的统一框架。

Method: 系统整合MSBO和CBO理论，提出协同驱动的MSCBO算法。通过合成和真实数据集对比实验，评估不同噪声水平下的性能表现。

Result: MSCBO在多项测试中表现优越，具有更强鲁棒性和适用性，实现了维度约简、降低计算成本，并显著提升收敛速度、优化性能和可扩展性。

Conclusion: 将因果原则融入多源贝叶斯优化能有效提升高维问题优化效率，MSCBO在理论和实践上均具有显著优势，为复杂决策问题提供更高效解决方案。

Abstract: Multi-Source Bayesian Optimization (MSBO) serves as a variant of the traditional Bayesian Optimization (BO) framework applicable to situations involving optimization of an objective black-box function over multiple information sources such as simulations, surrogate models, or real-world experiments. However, traditional MSBO assumes the input variables of the objective function to be independent and identically distributed, limiting its effectiveness in scenarios where causal information is available and interventions can be performed, such as clinical trials or policy-making. In the single-source domain, Causal Bayesian Optimization (CBO) extends standard BO with the principles of causality, enabling better modeling of variable dependencies. This leads to more accurate optimization, improved decision-making, and more efficient use of low-cost information sources. In this article, we propose a principled integration of the MSBO and CBO methodologies in the multi-source domain, leveraging the strengths of both to enhance optimization efficiency and reduce computational complexity in higher-dimensional problems. We present the theoretical foundations of both Causal and Multi-Source Bayesian Optimization, and demonstrate how their synergy informs our Multi-Source Causal Bayesian Optimization (MSCBO) algorithm. We compare the performance of MSCBO against its foundational counterparts for both synthetic and real-world datasets with varying levels of noise, highlighting the robustness and applicability of MSCBO. Based on our findings, we conclude that integrating MSBO with the causality principles of CBO facilitates dimensionality reduction and lowers operational costs, ultimately improving convergence speed, performance, and scalability.

</details>


### [132] [Learning State-Tracking from Code Using Linear RNNs](https://arxiv.org/abs/2602.14814)
*Julien Siems,Riccardo Grazzi,Kirill Kalinin,Hitesh Ballani,Babak Rahmani*

Main category: cs.LG

TL;DR: 该论文将排列组合作业转化为REPL代码追踪任务，发现线性RNN在下一词预测设定下表现优异而Transformer仍失败，揭示了当动作不完全可观测时线性RNN可能不如非线性RNN。


<details>
  <summary>Details</summary>
Motivation: 现有状态追踪任务多为序列到序列模式，与语言模型常用的下一词预测训练设定不兼容，需要搭建桥梁以在更符合实际语言建模的场景下理解模型极限。

Method: 将排列组合转化为REPL追踪代码，通过穿插打印状态和变量变换的方式，构建适合下一词预测的评估任务，并在此框架下分析不同序列模型的追踪能力。

Result: 1) 擅长状态追踪的线性RNN在新的代码表示下表现出色，而Transformer依然失败；2) 代码中动作并非总是完全可观测，这构成状态追踪的主要困难；3) 在具有确定性状态揭示的概率有限自动机框架下，线性RNN可能比非线性RNN表现更差。

Conclusion: 模型评估的表现高度依赖于任务表示方式，线性RNN的优势在部分可观测场景下会被削弱，提示在真实环境中非线性RNN可能更具鲁棒性，这对理解序列模型的极限有重要意义。

Abstract: Over the last years, state-tracking tasks, particularly permutation composition, have become a testbed to understand the limits of sequence models architectures like Transformers and RNNs (linear and non-linear). However, these are often sequence-to-sequence tasks: learning to map actions (permutations) to states, which is incompatible with the next-token prediction setting commonly used to train language models. We address this gap by converting permutation composition into code via REPL traces that interleave state-reveals through prints and variable transformations. We show that linear RNNs capable of state-tracking excel also in this setting, while Transformers still fail. Motivated by this representation, we investigate why tracking states in code is generally difficult: actions are not always fully observable. We frame this as tracking the state of a probabilistic finite-state automaton with deterministic state reveals and show that linear RNNs can be worse than non-linear RNNs at tracking states in this setup.

</details>


### [133] [Interactionless Inverse Reinforcement Learning: A Data-Centric Framework for Durable Alignment](https://arxiv.org/abs/2602.14844)
*Elias Malomgré,Pieter Simoens*

Main category: cs.LG

TL;DR: This paper identifies "Alignment Waste" in current AI alignment methods (RLHF/DPO) and proposes Interactionless Inverse Reinforcement Learning to decouple safety from policy, creating reusable, inspectable reward models with a human-in-the-loop lifecycle called the Alignment Flywheel.


<details>
  <summary>Details</summary>
Motivation: Current AI alignment approaches entangle safety objectives with agent policy, creating opaque, single-use alignment artifacts. This "Alignment Waste" problem makes safety a disposable expense rather than a durable asset, requiring more inspectable and reusable safety engineering.

Method: Proposes Interactionless Inverse Reinforcement Learning to separate alignment artifact learning from policy optimization, combined with the Alignment Flywheel—a human-in-the-loop lifecycle featuring automated audits and iterative reward model refinement.

Result: Generates an inspectable, editable, and model-agnostic reward model that transforms safety from a one-time cost into a durable, verifiable engineering asset.

Conclusion: The architecture addresses a critical structural flaw in AI alignment by producing reusable safety artifacts and establishing a sustainable, iterative process for hardening reward models.

Abstract: AI alignment is growing in importance, yet current approaches suffer from a critical structural flaw that entangles the safety objectives with the agent's policy. Methods such as Reinforcement Learning from Human Feedback and Direct Preference Optimization create opaque, single-use alignment artifacts, which we term Alignment Waste. We propose Interactionless Inverse Reinforcement Learning to decouple alignment artifact learning from policy optimization, producing an inspectable, editable, and model-agnostic reward model. Additionally, we introduce the Alignment Flywheel, a human-in-the-loop lifecycle that iteratively hardens the reward model through automated audits and refinement. This architecture transforms safety from a disposable expense into a durable, verifiable engineering asset.

</details>


### [134] [Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows](https://arxiv.org/abs/2602.14849)
*Bardia Mohammadi,Nearchos Potamitis,Lars Klein,Akhil Arora,Laurent Bindschaedler*

Main category: cs.LG

TL;DR: 本文提出Atomix运行时，通过进度感知的可交易语义和补偿机制，解决LLM智能体工具调用的副作用泄漏问题，提升任务成功率和系统隔离性。


<details>
  <summary>Details</summary>
Motivation: LLM智能体越来越多地与外部系统交互，但其工具调用的效果是即时生效的。在发生故障、推测执行或资源竞争时，失败的分支会产生不可控的副作用且缺乏安全回滚机制。

Method: 提出Atomix运行时，为智能体工具调用提供感知进度的可交易语义。通过为每次调用标记epoch、跟踪每资源前沿，仅当进度谓词表明安全时才提交；可缓冲的效应可被延迟，而外部化的效应则被跟踪并在中止时进行补偿。

Result: 在真实工作负载的故障注入实验中，可交易重试提升了任务成功率，前沿门控提交机制在推测执行和竞争条件下增强了隔离性。

Conclusion: Atomix为LLM智能体工具调用提供了有效的可交易语义，能够安全地处理失败、推测和竞争情况，提高系统鲁棒性。

Abstract: LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool calls. Atomix tags each call with an epoch, tracks per-resource frontiers, and commits only when progress predicates indicate safety; bufferable effects can be delayed, while externalized effects are tracked and compensated on abort. Across real workloads with fault injection, transactional retry improves task success, while frontier-gated commit strengthens isolation under speculation and contention.

</details>


### [135] [A Pragmatic Method for Comparing Clusterings with Overlaps and Outliers](https://arxiv.org/abs/2602.14855)
*Ryan DeWolfe,Paweł Prałat,François Théberge*

Main category: cs.LG

TL;DR: 提出一种适用于含离群值和重叠簇的聚类结果之间的相似性度量方法，验证其具有理想特性且规避了现有方法的常见偏差。


<details>
  <summary>Details</summary>
Motivation: 聚类算法是无监督学习的关键，外部评估需对比结果与真实标签。但现有方法无法有效处理含离群点、重叠簇等复杂情况的聚类比较，存在显著空白。

Method: 定义一种实用的相似性度量标准，专门用于比较同时存在重叠簇和离群值的聚类结构。

Result: 理论证明该度量具备多个理想性质；实验验证其不受其他聚类比较方法所存在的多种常见偏差影响。

Conclusion: 该度量方法为复杂场景下的聚类评估提供了可靠工具，弥补了现有方法在处理重叠和离群值方面的不足。

Abstract: Clustering algorithms are an essential part of the unsupervised data science ecosystem, and extrinsic evaluation of clustering algorithms requires a method for comparing the detected clustering to a ground truth clustering. In a general setting, the detected and ground truth clusterings may have outliers (objects belonging to no cluster), overlapping clusters (objects may belong to more than one cluster), or both, but methods for comparing these clusterings are currently undeveloped. In this note, we define a pragmatic similarity measure for comparing clusterings with overlaps and outliers, show that it has several desirable properties, and experimentally confirm that it is not subject to several common biases afflicting other clustering comparison measures.

</details>


### [136] [Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning](https://arxiv.org/abs/2602.14868)
*Ilia Mahrooghi,Aryo Lotfi,Emmanuel Abbe*

Main category: cs.LG

TL;DR: 提出Goldilocks方法，通过教师模型动态预测题目难度，为学生在GRPO训练中选择"难易适中"的题目，提升数学推理能力，在相同计算预算下性能优于标准GRPO


<details>
  <summary>Details</summary>
Motivation: 强化学习虽能提升大语言模型推理能力，但稀疏奖励导致样本效率低下；传统课程学习难以确定适合特定模型的难度排序，需要更精准的数据采样策略

Method: Goldilocks教师驱动采样策略：教师模型根据学生在已见样本上的表现持续预测每道题的适合难度，选择既不太容易也不太难的题目（"金发姑娘原则"），用GRPO算法训练学生模型

Result: 在OpenMathReasoning数据集上，使用Goldilocks采样的模型相比标准GRPO在相同计算预算下取得显著性能提升

Conclusion: 动态难度自适应的采样策略能有效缓解稀疏奖励下的样本效率问题，为提升大模型推理能力提供新方向

Abstract: Reinforcement learning has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, relying on sparse rewards makes this process highly sample-inefficient, as models must navigate vast search spaces with minimal feedback. While classic curriculum learning aims to mitigate this by ordering data based on complexity, the right ordering for a specific model is often unclear. To address this, we propose Goldilocks, a novel teacher-driven data sampling strategy that aims to predict each question's difficulty for the student model. The teacher model selects questions of appropriate difficulty for the student model, i.e., questions that are neither too easy nor too hard (Goldilocks principle), while training the student with GRPO. By leveraging the student's performance on seen samples, the teacher continuously adapts to the student's evolving abilities. On OpenMathReasoning dataset, Goldilocks data sampling improves the performance of models trained with standard GRPO under the same compute budget.

</details>


### [137] [On the Learning Dynamics of RLVR at the Edge of Competence](https://arxiv.org/abs/2602.14872)
*Yu Huang,Zixin Wen,Yuejie Chi,Yuting Wei,Aarti Singh,Yingbin Liang,Yuxin Chen*

Main category: cs.LG

TL;DR: The paper develops a theory explaining how reinforcement learning with verifiable rewards (RLVR) effectiveness depends on the smoothness of difficulty spectrum in training data: smooth difficulty enables steady improvement via a relay effect while abrupt discontinuities cause grokking-like plateaus.


<details>
  <summary>Details</summary>
Motivation: To understand how rewards based solely on final outcomes can overcome long-horizon barriers to extended reasoning in large reasoning models.

Method: Develops a theory of RL training dynamics for transformers on compositional reasoning tasks, adapting tools from Fourier analysis on finite groups.

Result: Characterizes that smooth difficulty spectra lead to a relay effect enabling continuous improvement, while abrupt difficulty discontinuities cause grokking-type phase transitions with prolonged plateaus.

Conclusion: RLVR can improve performance at the edge of competence, and appropriately designed data mixtures can yield scalable gains.

Abstract: Reinforcement learning with verifiable rewards (RLVR) has been a main driver of recent breakthroughs in large reasoning models. Yet it remains a mystery how rewards based solely on final outcomes can help overcome the long-horizon barrier to extended reasoning. To understand this, we develop a theory of the training dynamics of RL for transformers on compositional reasoning tasks. Our theory characterizes how the effectiveness of RLVR is governed by the smoothness of the difficulty spectrum. When data contains abrupt discontinuities in difficulty, learning undergoes grokking-type phase transitions, producing prolonged plateaus before progress recurs. In contrast, a smooth difficulty spectrum leads to a relay effect: persistent gradient signals on easier problems elevate the model's capabilities to the point where harder ones become tractable, resulting in steady and continuous improvement. Our theory explains how RLVR can improve performance at the edge of competence, and suggests that appropriately designed data mixtures can yield scalable gains. As a technical contribution, our analysis develops and adapts tools from Fourier analysis on finite groups to our setting. We validate the predicted mechanisms empirically via synthetic experiments.

</details>


### [138] [Algorithmic Simplification of Neural Networks with Mosaic-of-Motifs](https://arxiv.org/abs/2602.14896)
*Pedram Bakhtiarifard,Tong Chen,Jonathan Wenshøj,Erik B Dam,Raghavendra Selvan*

Main category: cs.LG

TL;DR: This paper investigates why deep neural networks are highly compressible by analyzing their algorithmic complexity. The authors hypothesize that training reduces the Kolmogorov complexity of model parameters by introducing structure, and propose "Mosaic-of-Motifs" (MoMos)—a constrained parameterization using reusable motifs—to explicitly harness this property, showing empirically that trained models become algorithmically simpler while maintaining comparable performance.


<details>
  <summary>Details</summary>
Motivation: Large-scale deep learning models can be dramatically compressed (via pruning, quantization, and distillation) with minimal performance loss, raising the central question: why are deep neural networks inherently suited for compression? The paper aims to provide a theoretical explanation for this observed compressibility.

Method: Taking an algorithmic complexity perspective, the authors formalize the Kolmogorov complexity of model weights K(w) and introduce Mosaic-of-Motifs (MoMos)—a constrained parameterization that partitions parameters into blocks and restricts each block to k reusable motifs, creating algorithmically simpler weight structures compared to unconstrained models.

Result: Empirical evidence shows that the algorithmic complexity of neural networks, measured through approximations to Kolmogorov complexity, decreases during training. MoMos produces algorithmically simpler parameterizations while achieving comparable performance to unconstrained models, validating the hypothesis that training-induced structure enables compression.

Conclusion: Training induces structure in model parameters, reducing their algorithmic complexity and explaining why compression methods are effective. This provides a theoretical foundation for model compressibility, suggesting that algorithmically simpler representations are a fundamental property of trained deep networks rather than an artifact of specific compression techniques.

Abstract: Large-scale deep learning models are well-suited for compression. Methods like pruning, quantization, and knowledge distillation have been used to achieve massive reductions in the number of model parameters, with marginal performance drops across a variety of architectures and tasks. This raises the central question: \emph{Why are deep neural networks suited for compression?} In this work, we take up the perspective of algorithmic complexity to explain this behavior. We hypothesize that the parameters of trained models have more structure and, hence, exhibit lower algorithmic complexity compared to the weights at (random) initialization. Furthermore, that model compression methods harness this reduced algorithmic complexity to compress models. Although an unconstrained parameterization of model weights, $\mathbf{w} \in \mathbb{R}^n$, can represent arbitrary weight assignments, the solutions found during training exhibit repeatability and structure, making them algorithmically simpler than a generic program. To this end, we formalize the Kolmogorov complexity of $\mathbf{w}$ by $\mathcal{K}(\mathbf{w})$. We introduce a constrained parameterization $\widehat{\mathbf{w}}$, that partitions parameters into blocks of size $s$, and restricts each block to be selected from a set of $k$ reusable motifs, specified by a reuse pattern (or mosaic). The resulting method, $\textit{Mosaic-of-Motifs}$ (MoMos), yields algorithmically simpler model parameterization compared to unconstrained models. Empirical evidence from multiple experiments shows that the algorithmic complexity of neural networks, measured using approximations to Kolmogorov complexity, can be reduced during training. This results in models that perform comparably with unconstrained models while being algorithmically simpler.

</details>


### [139] [Picking the Right Specialist: Attentive Neural Process-based Selection of Task-Specialized Models as Tools for Agentic Healthcare Systems](https://arxiv.org/abs/2602.14901)
*Pramit Saha,Joshua Strong,Mohammad Alsharid,Divyanshu Mishra,J. Alison Noble*

Main category: cs.LG

TL;DR: ToolSelect proposes an adaptive neural process-based framework for selecting optimal specialist models in healthcare AI, validated on a novel Chest X-ray benchmark with 55 models and 1448 queries, outperforming 10 SOTA methods across four clinical task families.


<details>
  <summary>Details</summary>
Motivation: Current healthcare AI systems lack reliable methods to select the best specialist model from heterogeneous pools for individual clinical queries, as no single model universally excels; existing approaches also lack standardized evaluation benchmarks for adaptive tool selection.

Method: ToolSelect uses an Attentive Neural Process-based selector conditioned on query context and per-model behavioral summaries to minimize population risk via a consistent surrogate of task-conditional selection loss, enabling dynamic model selection.

Result: ToolSelect consistently surpasses 10 state-of-the-art methods across four clinical task families (disease detection, report generation, visual grounding, VQA) on ToolSelectBench, a benchmark of 1448 queries in a simulated Chest X-ray environment with 55 specialized models.

Conclusion: ToolSelect effectively enables adaptive selection of specialist models in heterogeneous healthcare AI systems, while ToolSelectBench establishes the first comprehensive testbed for advancing research in agentic clinical tool selection.

Abstract: Task-specialized models form the backbone of agentic healthcare systems, enabling the agents to answer clinical queries across tasks such as disease diagnosis, localization, and report generation. Yet, for a given task, a single "best" model rarely exists. In practice, each task is better served by multiple competing specialist models where different models excel on different data samples. As a result, for any given query, agents must reliably select the right specialist model from a heterogeneous pool of tool candidates. To this end, we introduce ToolSelect, which adaptively learns model selection for tools by minimizing a population risk over sampled specialist tool candidates using a consistent surrogate of the task-conditional selection loss. Concretely, we propose an Attentive Neural Process-based selector conditioned on the query and per-model behavioral summaries to choose among the specialist models. Motivated by the absence of any established testbed, we, for the first time, introduce an agentic Chest X-ray environment equipped with a diverse suite of task-specialized models (17 disease detection, 19 report generation, 6 visual grounding, and 13 VQA) and develop ToolSelectBench, a benchmark of 1448 queries. Our results demonstrate that ToolSelect consistently outperforms 10 SOTA methods across four different task families.

</details>


### [140] [Coverage Guarantees for Pseudo-Calibrated Conformal Prediction under Distribution Shift](https://arxiv.org/abs/2602.14913)
*Farbod Siahkali,Ashwin Verma,Vijay Gupta*

Main category: cs.LG

TL;DR: 该论文针对分布漂移下共形预测覆盖保证失效的问题，提出基于伪校准的方法，通过领域适应工具推导目标覆盖的下界，并设计源调谐算法来维持覆盖水平。


<details>
  <summary>Details</summary>
Motivation: 共形预测在无分布假设下提供边际覆盖保证，但依赖数据交换性假设；当数据分布发生漂移时，这些保证会失效。本文旨在通过伪校准技术来缓解在标签条件协变量漂移模型下的性能损失。

Method: 使用领域适应理论工具，推导目标覆盖率的理论下界（用分类器源域损失和分布漂移的Wasserstein距离表示）；基于此设计通过松弛参数调整共形阈值的伪校准集；提出源调谐伪校准算法，根据分类器不确定性在硬伪标签和随机化标签之间插值。

Result: 获得了目标覆盖率的显式下界表达式；数值实验表明该下界能有效追踪伪校准行为；源调谐方案在减轻分布漂移导致的覆盖退化方面效果显著，同时保持预测集具有实际意义的规模。

Conclusion: 伪校准是应对分布漂移下共形预测失效的有效工具，所提出的理论边界和算法能在保证覆盖水平的同时维持预测集的非平凡大小，为实际应用提供了可行解决方案。

Abstract: Conformal prediction (CP) offers distribution-free marginal coverage guarantees under an exchangeability assumption, but these guarantees can fail if the data distribution shifts. We analyze the use of pseudo-calibration as a tool to counter this performance loss under a bounded label-conditional covariate shift model. Using tools from domain adaptation, we derive a lower bound on target coverage in terms of the source-domain loss of the classifier and a Wasserstein measure of the shift. Using this result, we provide a method to design pseudo-calibrated sets that inflate the conformal threshold by a slack parameter to keep target coverage above a prescribed level. Finally, we propose a source-tuned pseudo-calibration algorithm that interpolates between hard pseudo-labels and randomized labels as a function of classifier uncertainty. Numerical experiments show that our bounds qualitatively track pseudo-calibration behavior and that the source-tuned scheme mitigates coverage degradation under distribution shift while maintaining nontrivial prediction set sizes.

</details>


### [141] [Additive Control Variates Dominate Self-Normalisation in Off-Policy Evaluation](https://arxiv.org/abs/2602.14914)
*Olivier Jeunen,Shashank Gupta*

Main category: cs.LG

TL;DR: This paper theoretically proves that β*IPS, an estimator with an optimal additive baseline, asymptotically dominates the standard SNIPS estimator in Mean Squared Error for off-policy evaluation of ranking and recommendation systems, justifying a shift from self-normalization to optimal baseline corrections.


<details>
  <summary>Details</summary>
Motivation: Off-policy evaluation (OPE) is crucial for assessing ranking/recommendation systems without costly online interventions. While SNIPS is the standard variance reduction method using multiplicative control variates, recent advances suggest additive baselines may be superior, but theoretical guarantees for evaluation are lacking.

Method: Theoretical analysis comparing β*IPS (optimal additive baseline estimator) and SNIPS by analytically decomposing the variance gap to establish equivalence and dominance relationships.

Result: β*IPS asymptotically dominates SNIPS in Mean Squared Error. SNIPS is asymptotically equivalent to using a specific but generally sub-optimal additive baseline. This provides theoretical justification for using optimal additive baselines over self-normalization.

Conclusion: The results definitively justify shifting from self-normalized estimators to optimal additive baseline corrections for off-policy evaluation in both ranking and recommendation systems.

Abstract: Off-policy evaluation (OPE) is essential for assessing ranking and recommendation systems without costly online interventions. Self-Normalised Inverse Propensity Scoring (SNIPS) is a standard tool for variance reduction in OPE, leveraging a multiplicative control variate. Recent advances in off-policy learning suggest that additive control variates (baseline corrections) may offer superior performance, yet theoretical guarantees for evaluation are lacking. This paper provides a definitive answer: we prove that $β^\star$-IPS, an estimator with an optimal additive baseline, asymptotically dominates SNIPS in Mean Squared Error. By analytically decomposing the variance gap, we show that SNIPS is asymptotically equivalent to using a specific -- but generally sub-optimal -- additive baseline. Our results theoretically justify shifting from self-normalisation to optimal baseline corrections for both ranking and recommendation.

</details>


### [142] [BHyGNN+: Unsupervised Representation Learning for Heterophilic Hypergraphs](https://arxiv.org/abs/2602.14919)
*Tianyi Ma,Yiyue Qian,Zehong Wang,Zheyuan Zhang,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: BHyGNN+ uses hypergraph duality for self-supervised learning on heterophilic hypergraphs without labels, outperforming existing methods on 11 datasets.


<details>
  <summary>Details</summary>
Motivation: HyGNNs degrade on heterophilic hypergraphs; existing solutions rely on scarce labeled data, limiting real-world applicability.

Method: A self-supervised framework using hypergraph duality (swapping nodes and hyperedges) and contrastive learning between augmented views of original and dual hypergraphs, eliminating need for negative samples.

Result: Consistently outperforms state-of-the-art supervised and self-supervised baselines on both heterophilic and homophilic hypergraphs across 11 benchmark datasets.

Conclusion: Hypergraph duality is effective for self-supervised learning and establishes a new paradigm for representation learning on unlabeled hypergraphs.

Abstract: Hypergraph Neural Networks (HyGNNs) have demonstrated remarkable success in modeling higher-order relationships among entities. However, their performance often degrades on heterophilic hypergraphs, where nodes connected by the same hyperedge tend to have dissimilar semantic representations or belong to different classes. While several HyGNNs, including our prior work BHyGNN, have been proposed to address heterophily, their reliance on labeled data significantly limits their applicability in real-world scenarios where annotations are scarce or costly. To overcome this limitation, we introduce BHyGNN+, a self-supervised learning framework that extends BHyGNN for representation learning on heterophilic hypergraphs without requiring ground-truth labels. The core idea of BHyGNN+ is hypergraph duality, a structural transformation where the roles of nodes and hyperedges are interchanged. By contrasting augmented views of a hypergraph against its dual using cosine similarity, our framework captures essential structural patterns in a fully unsupervised manner. Notably, this duality-based formulation eliminates the need for negative samples, a common requirement in existing hypergraph contrastive learning methods that is often difficult to satisfy in practice. Extensive experiments on eleven benchmark datasets demonstrate that BHyGNN+ consistently outperforms state-of-the-art supervised and self-supervised baselines on both heterophilic and homophilic hypergraphs. Our results validate the effectiveness of leveraging hypergraph duality for self-supervised learning and establish a new paradigm for representation learning on challenging, unlabeled hypergraphs.

</details>


### [143] [Variance-Reduced $(\varepsilon,δ)-$Unlearning using Forget Set Gradients](https://arxiv.org/abs/2602.14938)
*Martin Van Waerebeke,Marco Lorenzi,Kevin Scaman,El Mahdi El Mhamdi,Giovanni Neglia*

Main category: cs.LG

TL;DR: 本文提出方差缩减遗忘算法(VRU)，首次实现将遗忘集梯度直接纳入一阶更新规则，同时满足严格的(ε,δ)-遗忘保证，理论收敛速率与实证性能均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有强凸目标的一阶遗忘方法仅将遗忘集用于噪声校准，而非直接优化信号；而经验启发式虽利用遗忘样本却缺乏形式化保证，二者之间存在明显鸿沟。

Method: 提出方差缩减遗忘算法(VRU)，在更新规则中直接整合遗忘集梯度，并证明其满足(ε,δ)-遗忘保证。

Result: VRU获得严格更优的收敛速率，在低误差 regime 下渐近优于任何忽略遗忘集的一阶方法；实验验证其在先进认证方法和经验基线上均有持续提升。

Conclusion: VRU成功弥合了形式化保证与高效启发式之间的鸿沟，通过直接利用遗忘集梯度，展现出理论与实证的双重优势。

Abstract: In machine unlearning, $(\varepsilon,δ)-$unlearning is a popular framework that provides formal guarantees on the effectiveness of the removal of a subset of training data, the forget set, from a trained model. For strongly convex objectives, existing first-order methods achieve $(\varepsilon,δ)-$unlearning, but they only use the forget set to calibrate injected noise, never as a direct optimization signal. In contrast, efficient empirical heuristics often exploit the forget samples (e.g., via gradient ascent) but come with no formal unlearning guarantees. We bridge this gap by presenting the Variance-Reduced Unlearning (VRU) algorithm. To the best of our knowledge, VRU is the first first-order algorithm that directly includes forget set gradients in its update rule, while provably satisfying ($(\varepsilon,δ)-$unlearning. We establish the convergence of VRU and show that incorporating the forget set yields strictly improved rates, i.e. a better dependence on the achieved error compared to existing first-order $(\varepsilon,δ)-$unlearning methods. Moreover, we prove that, in a low-error regime, VRU asymptotically outperforms any first-order method that ignores the forget set.Experiments corroborate our theory, showing consistent gains over both state-of-the-art certified unlearning methods and over empirical baselines that explicitly leverage the forget set.

</details>


### [144] [Locally Adaptive Multi-Objective Learning](https://arxiv.org/abs/2602.14952)
*Jivat Neet Kaur,Isaac Gibbs,Michael I. Jordan*

Main category: cs.LG

TL;DR: This paper proposes an adaptive online learning method that replaces part of multi-objective learning with an adaptive algorithm to improve adaptation to distribution shifts while maintaining multiple performance objectives like fairness and calibration.


<details>
  <summary>Details</summary>
Motivation: Existing multi-objective online learning methods optimize for worst-case performance over entire time horizons and fail to adapt to distribution shifts, with limited empirical validation of local adaptation approaches.

Method: The authors develop an alternative procedure that incorporates an adaptive online algorithm into multi-objective learning to achieve local adaptivity across changing data distributions.

Result: Empirical evaluation on energy forecasting and algorithmic fairness datasets demonstrates improved performance over existing methods, achieving unbiased subgroup predictions while maintaining robustness under distribution shift.

Conclusion: The proposed adaptive approach effectively addresses the limitations of prior multi-objective learning methods by balancing multiple objectives with adaptability to evolving data distributions.

Abstract: We consider the general problem of learning a predictor that satisfies multiple objectives of interest simultaneously, a broad framework that captures a range of specific learning goals including calibration, regret, and multiaccuracy. We work in an online setting where the data distribution can change arbitrarily over time. Existing approaches to this problem aim to minimize the set of objectives over the entire time horizon in a worst-case sense, and in practice they do not necessarily adapt to distribution shifts. Earlier work has aimed to alleviate this problem by incorporating additional objectives that target local guarantees over contiguous subintervals. Empirical evaluation of these proposals is, however, scarce. In this article, we consider an alternative procedure that achieves local adaptivity by replacing one part of the multi-objective learning method with an adaptive online algorithm. Empirical evaluations on datasets from energy forecasting and algorithmic fairness show that our proposed method improves upon existing approaches and achieves unbiased predictions over subgroups, while remaining robust under distribution shift.

</details>


### [145] [Use What You Know: Causal Foundation Models with Partial Graphs](https://arxiv.org/abs/2602.14972)
*Arik Reuter,Anish Dhir,Cristiana Diaconu,Jake Robertson,Ole Ossen,Frank Hutter,Adrian Weller,Mark van der Wilk,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 提出条件化因果基础模型的方法，通过向注意力机制注入可学习偏置来整合因果信息（完整/部分因果图），使通用模型性能媲美专用模型


<details>
  <summary>Details</summary>
Motivation: 现有因果基础模型（CFMs）无法融入领域知识（如因果图），导致预测次优；需解决通用CFMs如何有效利用先验因果信息的关键障碍

Method: 开发条件化CFMs的策略：当完整因果图不可得时，利用部分因果信息（如祖先关系）；通过向注意力机制注入可学习偏置来整合因果知识

Result: 系统评估显示，修改注意力机制的方法最能有效利用全/部分因果信息；条件化后的通用CFMs性能匹配针对特定因果结构训练的专用模型

Conclusion: 成功实现数据驱动的因果查询与领域知识的有效结合，推动"一体化"因果基础模型的发展，突破先验知识整合的核心瓶颈

Abstract: Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discovery and inference in a single step. However, in their current state, they do not allow for the incorporation of any domain knowledge, which can lead to suboptimal predictions. We bridge this gap by introducing methods to condition CFMs on causal information, such as the causal graph or more readily available ancestral information. When access to complete causal graph information is too strict a requirement, our approach also effectively leverages partial causal information. We systematically evaluate conditioning strategies and find that injecting learnable biases into the attention mechanism is the most effective method to utilise full and partial causal information. Our experiments show that this conditioning allows a general-purpose CFM to match the performance of specialised models trained on specific causal structures. Overall, our approach addresses a central hurdle on the path towards all-in-one causal foundation models: the capability to answer causal queries in a data-driven manner while effectively leveraging any amount of domain expertise.

</details>


### [146] [MacroGuide: Topological Guidance for Macrocycle Generation](https://arxiv.org/abs/2602.14977)
*Alicja Maksymiuk,Alexandre Duplessis,Michael Bronstein,Alexander Tong,Fernanda Duarte,İsmail İlkan Ceylan*

Main category: cs.LG

TL;DR: 提出MacroGuide方法，利用持续同调拓扑引导技术，在预训练分子生成扩散模型中高效生成大环分子，将生成率从1%提升至99%，同时在化学有效性、多样性和PoseBuster检查等质量指标上达到或超越现有最优水平。


<details>
  <summary>Details</summary>
Motivation: 大环分子因其对难成药靶点具有更高选择性和结合亲和力而成为药物开发的有前景替代方案，但在生成建模中研究不足。主要障碍包括公共数据集中大环分子数据稀缺，以及标准深度生成模型难以有效施加拓扑环约束。

Method: MacroGuide是一种基于持续同调的扩散引导机制。在去噪过程中，从原子位置构建Vietoris-Rips复合体，通过优化持续同调特征（如持久性条形码）来主动促进环状拓扑结构的形成，可在无条件或条件（蛋白质口袋）设置下引导预训练分子生成模型。

Result: 应用MacroGuide后，大环分子生成率从1%显著提升至99%。在关键质量指标上，包括化学有效性、分子多样性以及PoseBuster结构合理性检查，该方法均达到或超过当前最优性能水平。

Conclusion: MacroGuide成功解决了大环分子生成中的拓扑约束难题，通过拓扑引导策略实现了高成功率的大环分子设计，为基于结构的药物发现提供了新工具，同时保持了生成分子的化学质量和多样性。

Abstract: Macrocycles are ring-shaped molecules that offer a promising alternative to small-molecule drugs due to their enhanced selectivity and binding affinity against difficult targets. Despite their chemical value, they remain underexplored in generative modeling, likely owing to their scarcity in public datasets and the challenges of enforcing topological constraints in standard deep generative models. We introduce MacroGuide: Topological Guidance for Macrocycle Generation, a diffusion guidance mechanism that uses Persistent Homology to steer the sampling of pretrained molecular generative models toward the generation of macrocycles, in both unconditional and conditional (protein pocket) settings. At each denoising step, MacroGuide constructs a Vietoris-Rips complex from atomic positions and promotes ring formation by optimizing persistent homology features. Empirically, applying MacroGuide to pretrained diffusion models increases macrocycle generation rates from 1% to 99%, while matching or exceeding state-of-the-art performance on key quality metrics such as chemical validity, diversity, and PoseBusters checks.

</details>


### [147] [Orthogonalized Multimodal Contrastive Learning with Asymmetric Masking for Structured Representations](https://arxiv.org/abs/2602.14983)
*Carolin Cissee,Raneen Younis,Zahra Ahmadi*

Main category: cs.LG

TL;DR: 提出COrAL框架，通过双路径架构和正交约束显式分离多模态信息中的冗余、唯一和协同成分，实现更全面稳定的表示学习。


<details>
  <summary>Details</summary>
Motivation: 现有自监督多模态对比学习主要捕获冗余跨模态信号，忽视模态特定信息和协同交互信息，导致表示不完整和信息泄露。

Method: 采用双路径架构和正交约束解耦共享与模态特定特征；引入互补视图非对称掩码，强制模型学习跨模态依赖而非冗余线索。

Result: 在合成基准和MultiBench数据集上，COrAL持续匹配或超越最先进方法，且跨运行性能方差低。

Conclusion: 显式建模多模态信息的完整谱系可产生更稳定、可靠和全面的嵌入表示。

Abstract: Multimodal learning seeks to integrate information from heterogeneous sources, where signals may be shared across modalities, specific to individual modalities, or emerge only through their interaction. While self-supervised multimodal contrastive learning has achieved remarkable progress, most existing methods predominantly capture redundant cross-modal signals, often neglecting modality-specific (unique) and interaction-driven (synergistic) information. Recent extensions broaden this perspective, yet they either fail to explicitly model synergistic interactions or learn different information components in an entangled manner, leading to incomplete representations and potential information leakage. We introduce \textbf{COrAL}, a principled framework that explicitly and simultaneously preserves redundant, unique, and synergistic information within multimodal representations. COrAL employs a dual-path architecture with orthogonality constraints to disentangle shared and modality-specific features, ensuring a clean separation of information components. To promote synergy modeling, we introduce asymmetric masking with complementary view-specific patterns, compelling the model to infer cross-modal dependencies rather than rely solely on redundant cues. Extensive experiments on synthetic benchmarks and diverse MultiBench datasets demonstrate that COrAL consistently matches or outperforms state-of-the-art methods while exhibiting low performance variance across runs. These results indicate that explicitly modeling the full spectrum of multimodal information yields more stable, reliable, and comprehensive embeddings.

</details>


### [148] [Spectral Convolution on Orbifolds for Geometric Deep Learning](https://arxiv.org/abs/2602.14997)
*Tim Mangliers,Bernhard Mössner,Benjamin Himpel*

Main category: cs.LG

TL;DR: 将几何深度学习扩展至orbifold结构数据，提出谱卷积方法并应用于音乐理论


<details>
  <summary>Details</summary>
Motivation: 现有几何深度学习主要处理图或流形等非欧数据，但需进一步探索orbifold等新型拓扑几何结构以满足应用需求

Method: 提出orbifold上的谱卷积概念，构建适用于orbifold结构数据的几何深度学习基础模块

Result: 建立了orbifold谱卷积的理论框架，为非欧空间学习提供了新工具

Conclusion: 通过音乐理论案例验证了方法的可行性，拓展了几何深度学习在复杂几何结构中的应用范围

Abstract: Geometric deep learning (GDL) deals with supervised learning on data domains that go beyond Euclidean structure, such as data with graph or manifold structure. Due to the demand that arises from application-related data, there is a need to identify further topological and geometric structures with which these use cases can be made accessible to machine learning. There are various techniques, such as spectral convolution, that form the basic building blocks for some convolutional neural network-like architectures on non-Euclidean data. In this paper, the concept of spectral convolution on orbifolds is introduced. This provides a building block for making learning on orbifold structured data accessible using GDL. The theory discussed is illustrated using an example from music theory.

</details>


### [149] [Boundary Point Jailbreaking of Black-Box LLMs](https://arxiv.org/abs/2602.15001)
*Xander Davies,Giorgi Giglemiani,Edmund Lau,Eric Winsor,Geoffrey Irving,Yarin Gal*

Main category: cs.LG

TL;DR: BPJ是一种新型黑盒越狱攻击方法，仅通过单次查询的“是否被标记”反馈，利用边界点优化技术生成通用越狱提示，成功绕过行业最强防御系统（如宪法分类器和GPT-5输入分类器），并揭示需结合批量监控以增强防御。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs防御系统（如基于分类器的红队测试方案）能抵御传统越狱攻击，但已有攻击方法依赖白盒/灰盒假设（如梯度或分类器分数）或预存攻击库，缺乏仅通过单次查询二进制反馈（是否被标记）实现全自动越狱的能力。

Method: 将目标有害字符串转化为渐进式攻击目标课程，通过主动选择能敏感检测攻击强度微小变化的“边界点”作为评估点，在纯黑盒环境下优化攻击策略，无需依赖梯度、分类器分数或人工初始攻击种子。

Result: BPJ成为首个全自动攻击算法：1）成功生成针对宪法分类器的通用越狱；2）无需人工种子即攻破GPT-5输入分类器；但优化过程中触发大量标记，暴露单交互防御的局限性。

Conclusion: BPJ证明现有单交互防御易被自动化越狱突破，有效防御需结合单交互检测与批量级监控策略，以识别优化过程中的异常标记模式。

Abstract: Frontier LLMs are safeguarded against attempts to extract harmful information via adversarial prompts known as "jailbreaks". Recently, defenders have developed classifier-based systems that have survived thousands of hours of human red teaming. We introduce Boundary Point Jailbreaking (BPJ), a new class of automated jailbreak attacks that evade the strongest industry-deployed safeguards. Unlike previous attacks that rely on white/grey-box assumptions (such as classifier scores or gradients) or libraries of existing jailbreaks, BPJ is fully black-box and uses only a single bit of information per query: whether or not the classifier flags the interaction. To achieve this, BPJ addresses the core difficulty in optimising attacks against robust real-world defences: evaluating whether a proposed modification to an attack is an improvement. Instead of directly trying to learn an attack for a target harmful string, BPJ converts the string into a curriculum of intermediate attack targets and then actively selects evaluation points that best detect small changes in attack strength ("boundary points"). We believe BPJ is the first fully automated attack algorithm that succeeds in developing universal jailbreaks against Constitutional Classifiers, as well as the first automated attack algorithm that succeeds against GPT-5's input classifier without relying on human attack seeds. BPJ is difficult to defend against in individual interactions but incurs many flags during optimisation, suggesting that effective defence requires supplementing single-interaction methods with batch-level monitoring.

</details>


### [150] [PDE foundation models are skillful AI weather emulators for the Martian atmosphere](https://arxiv.org/abs/2602.15004)
*Johannes Schmude,Sujit Roy,Liping Wang,Theodore van Kessel,Levente Klein,Marcus Freitag,Eloisa Bentivegna,Robert Manson-Sawko,Bjorn Lutjens,Manil Maskey,Campbell Watson,Rahul Ramachandran,Juan Bernabe-Moreno*

Main category: cs.LG

TL;DR: 预训练的PDE基础模型可微调为准确预测火星大气的模拟器，通过预训练和3D扩展实现34.4%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 开发基于PDE预训练AI基础模型的火星大气预测模拟器，以解决复杂现实问题中训练数据不足或计算预算有限的问题。

Method: 在Poseidon二维PDE基础模型基础上扩展至三维并保持预训练信息；使用4个火星年数据（约34GB）和13GPU小时计算预算；研究稀疏初始条件下的性能。

Result: 预训练与模型扩展结合在保留年份测试中实现34.4%的性能提升。

Conclusion: PDE基础模型不仅能近似求解其他PDE，还可作为锚点模型解决缺乏足够训练数据或合适计算预算的复杂现实问题。

Abstract: We show that AI foundation models that are pretrained on numerical solutions to a diverse corpus of partial differential equations can be adapted and fine-tuned to obtain skillful predictive weather emulators for the Martian atmosphere. We base our work on the Poseidon PDE foundation model for two-dimensional systems. We develop a method to extend Poseidon from two to three dimensions while keeping the pretraining information. Moreover, we investigate the performance of the model in the presence of sparse initial conditions. Our results make use of four Martian years (approx.~34 GB) of training data and a median compute budget of 13 GPU hours. We find that the combination of pretraining and model extension yields a performance increase of 34.4\% on a held-out year. This shows that PDEs-FMs can not only approximate solutions to (other) PDEs but also anchor models for real-world problems with complex interactions that lack a sufficient amount of training data or a suitable compute budget.

</details>


### [151] [Efficient Sampling with Discrete Diffusion Models: Sharp and Adaptive Guarantees](https://arxiv.org/abs/2602.15008)
*Daniil Dmitriev,Zhihan Huang,Yuting Wei*

Main category: cs.LG

TL;DR: 本研究建立了离散扩散模型采样效率的理论基础，证明τ-leaping采样器在均匀加噪下达到Õ(d/ε)的迭代复杂度（与词汇量S无关），并在掩码加噪下通过有效总相关度量自适应低维结构，实现次线性收敛。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型虽具经验成功，但采样效率的理论基础不完整，现有分析过度依赖词汇量S，缺乏对结构化数据适应性的理论保证。

Method: 采用连续时间马尔可夫链（CTMC）框架，分析τ-leaping采样器；提出有效总相关信息论量；建立无界性/光滑性假设下的KL散度收敛保证。

Result: 均匀扩散：τ-leaping复杂度为Õ(d/ε)，消除S依赖并改进d倍，且线性依赖维度不可避免；掩码扩散：收敛率由有效总相关控制（≤ d log S），对HMM、图像等结构化数据可次线性/常数收敛。

Conclusion: 离散扩散采样器能高效适应数据结构，均匀情形达维度最优依赖，掩码情形无需先验知识即可实现低维结构的次线性收敛，为实践应用提供理论保障。

Abstract: Diffusion models over discrete spaces have recently shown striking empirical success, yet their theoretical foundations remain incomplete. In this paper, we study the sampling efficiency of score-based discrete diffusion models under a continuous-time Markov chain (CTMC) formulation, with a focus on $τ$-leaping-based samplers. We establish sharp convergence guarantees for attaining $\varepsilon$ accuracy in Kullback-Leibler (KL) divergence for both uniform and masking noising processes. For uniform discrete diffusion, we show that the $τ$-leaping algorithm achieves an iteration complexity of order $\tilde O(d/\varepsilon)$, with $d$ the ambient dimension of the target distribution, eliminating linear dependence on the vocabulary size $S$ and improving existing bounds by a factor of $d$; moreover, we establish a matching algorithmic lower bound showing that linear dependence on the ambient dimension is unavoidable in general. For masking discrete diffusion, we introduce a modified $τ$-leaping sampler whose convergence rate is governed by an intrinsic information-theoretic quantity, termed the effective total correlation, which is bounded by $d \log S$ but can be sublinear or even constant for structured data. As a consequence, the sampler provably adapts to low-dimensional structure without prior knowledge or algorithmic modification, yielding sublinear convergence rates for various practical examples (such as hidden Markov models, image data, and random graphs). Our analysis requires no boundedness or smoothness assumptions on the score estimator beyond control of the score entropy loss.

</details>


### [152] [Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation](https://arxiv.org/abs/2602.15022)
*Cai Zhou,Zijie Chen,Zian Li,Jike Wang,Kaiyi Jiang,Pan Li,Rose Yu,Muhan Zhang,Stephen Bates,Tommi Jaakkola*

Main category: cs.LG

TL;DR: 该论文提出"标准扩散"方法，通过将样本映射到标准形式后训练无约束模型，在生成时应用随机对称变换来处理群不变性分布。理论证明其优越表达性，在分子生成任务上显著优于等变基线且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 传统通过架构约束实现不变性/等变性的方法可能限制模型表达能力。作者挑战这一传统，探索替代性的标准视角，以在保持理论正确性的同时提升生成模型的表达能力和训练效率。

Method: 三阶段框架：1) 将每个样本映射到其轨道代表元（标准姿态/顺序）；2) 在标准切片上训练无约束的扩散或流模型；3) 生成时采样随机对称变换以恢复不变分布。结合标准先验和最优传输，并针对分子图采用基于几何谱的标准化和温和位置编码。

Result: 在3D分子生成任务中显著优于等变基线，计算成本相当或更低；在GEOM-DRUG数据集上实现SOTA性能，且在少步生成中优势更加明显。

Conclusion: 标准扩散为标准目标分布提供了理论正确、表达性更强且训练更快的替代方案，证明了标准视角在科学生成建模中的优越性，并为分子生成等对称性任务建立了新的最先进性能。

Abstract: Many generative tasks in chemistry and science involve distributions invariant to group symmetries (e.g., permutation and rotation). A common strategy enforces invariance and equivariance through architectural constraints such as equivariant denoisers and invariant priors. In this paper, we challenge this tradition through the alternative canonicalization perspective: first map each sample to an orbit representative with a canonical pose or order, train an unconstrained (non-equivariant) diffusion or flow model on the canonical slice, and finally recover the invariant distribution by sampling a random symmetry transform at generation time. Building on a formal quotient-space perspective, our work provides a comprehensive theory of canonical diffusion by proving: (i) the correctness, universality and superior expressivity of canonical generative models over invariant targets; (ii) canonicalization accelerates training by removing diffusion score complexity induced by group mixtures and reducing conditional variance in flow matching. We then show that aligned priors and optimal transport act complementarily with canonicalization and further improves training efficiency. We instantiate the framework for molecular graph generation under $S_n \times SE(3)$ symmetries. By leveraging geometric spectra-based canonicalization and mild positional encodings, canonical diffusion significantly outperforms equivariant baselines in 3D molecule generation tasks, with similar or even less computation. Moreover, with a novel architecture Canon, CanonFlow achieves state-of-the-art performance on the challenging GEOM-DRUG dataset, and the advantage remains large in few-step generation.

</details>


### [153] [Long Context, Less Focus: A Scaling Gap in LLMs Revealed through Privacy and Personalization](https://arxiv.org/abs/2602.15028)
*Shangding Gu*

Main category: cs.LG

TL;DR: PAPerBench benchmark reveals that longer context windows cause consistent degradation in both LLM personalization quality and privacy protection due to attention dilution, exposing a fundamental scaling limitation in Transformers.


<details>
  <summary>Details</summary>
Motivation: As LLMs are increasingly deployed in privacy-critical and personalization scenarios, the impact of context length on privacy leakage and personalization effectiveness remains unexplored.

Method: Introduced PAPerBench with 29,000 instances across 1K-256K token contexts (377K evaluation questions) to jointly evaluate personalization performance and privacy risks in diverse scenarios.

Result: Empirical evaluation of state-of-the-art LLMs shows consistent performance degradation in both personalization and privacy protection as context length increases, explained theoretically by attention dilution in fixed-capacity Transformers.

Conclusion: Identified a general "long context, less focus" scaling gap in current LLMs and released the benchmark to enable reproducible evaluation and future research on scalable privacy and personalization.

Abstract: Large language models (LLMs) are increasingly deployed in privacy-critical and personalization-oriented scenarios, yet the role of context length in shaping privacy leakage and personalization effectiveness remains largely unexplored. We introduce a large-scale benchmark, PAPerBench, to systematically study how increasing context length influences both personalization quality and privacy protection in LLMs. The benchmark comprises approximately 29,000 instances with context lengths ranging from 1K to 256K tokens, yielding a total of 377K evaluation questions. It jointly evaluates personalization performance and privacy risks across diverse scenarios, enabling controlled analysis of long-context model behavior. Extensive evaluations across state-of-the-art LLMs reveal consistent performance degradation in both personalization and privacy as context length increases. We further provide a theoretical analysis of attention dilution under context scaling, explaining this behavior as an inherent limitation of soft attention in fixed-capacity Transformers. The empirical and theoretical findings together suggest a general scaling gap in current models -- long context, less focus. We release the benchmark to support reproducible evaluation and future research on scalable privacy and personalization. Code and data are available at https://github.com/SafeRL-Lab/PAPerBench

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [154] [Evolutionary design of thermodynamic logic gates and their heat emission](https://arxiv.org/abs/2602.13410)
*Stephen Whitelam*

Main category: cond-mat.stat-mech

TL;DR: 本研究通过模拟证明，遗传算法可编程热力学计算机，使控制系统的热量与信息逻辑部分相当，并能将热量从信息部分转移到控制单元，为集成热管理的设计提供可能。


<details>
  <summary>Details</summary>
Motivation: 现有计算系统的能耗主要由控制系统主导，远超朗道尔原理的下限；而接近朗道尔极限的实验因依赖外部测量或反馈系统，其能耗仍远高于逻辑操作本身。

Method: 采用模拟方法，利用遗传算法编程热力学计算机以执行逻辑操作。

Result: 成功实现控制系统释放的热量与信息承载自由度的热量量级相近，且热量可从信息部分转移至控制单元耗散。

Conclusion: 表明计算架构可将热管理作为程序设计的一部分，为低功耗计算设计提供新思路。

Abstract: Landauer's principle bounds the heat generated by logical operations, but in practice the thermodynamic cost of computation is dominated by the control systems that implement logic. CMOS gates dissipate energy far above the Landauer bound, while laboratory demonstrations of near-Landauer erasure rely on external measurement or feedback systems whose energy costs exceed that of the logic operation by many orders of magnitude. Here we use simulations to show that a genetic algorithm can program a thermodynamic computer to implement logic operations in which the total heat emitted by the control system is of a similar order of magnitude to that of the information-bearing degrees of freedom. Moreover, the computer can be programmed so that heat is drawn away from the information-bearing degrees of freedom and dissipated within the control unit, suggesting the possibility of computing architectures in which heat management is an integral part of the program design.

</details>


### [155] [Operationalizing the Arrow of Time in mesoscopic: A Unified Framework for Non-equilibrium Matter](https://arxiv.org/abs/2602.13664)
*Yikun Ren,Feixiang Xu,Ming Lin*

Main category: cond-mat.stat-mech

TL;DR: 该论文提出热力学惯性作为非平衡态物质的基础原理，通过特征相位位移量化时间箭头，构建统一的微观态序列-模式耦合理论，首次从第一性原理解决玻璃态非高斯参数和聚合物常数预测难题


<details>
  <summary>Details</summary>
Motivation: 解释非平衡系统（如玻璃态、生命体）如何抵抗内部涨落维持稳定状态，突破传统模式耦合理论对实验现象预测的精度瓶颈

Method: 将时间箭头操作化为介观粒子的特征相位位移，由此导出非局域的热力学惯性力；构建微观态序列理论(MSS)与模式耦合理论(MCT)的统一框架

Result: 预测巨非高斯参数(1-10)与实验值量级一致；首次从第一性原理推导出聚合物常数C₁≈16.7（误差仅1%），精度远超Adam-Gibbs理论

Conclusion: 热力学惯性力是抵抗涨落的核心机制，其半群结构编码时间不可逆性；该理论为非平衡态物质建立热力学与动力学统一描述，贯通玻璃弛豫到生命维持现象

Abstract: What sustains a non-equilibrium system against fluctuations from within - as witnessed in non-equilibrium steady states, glassy relaxation, and even living organisms? Here we show that the arrow of time itself can be operationalized into a measurable physical quantity on mesoscopic particles - the eigen-phase displacement. This displacement gives rise to a non-local generalized force, the thermodynamic inertia force, which emerges from the integrated contribution of local constraints rather than as a conventional local force. It actively counteracts fluctuations and its algebraic structure is a semi-group, fundamentally distinct from the Lie group of Newton inertia, thereby encoding the irreversibility of time's arrow. Building on this foundation, we construct a unified Microstate-Sequence-Mode-Coupling (MSS-MCT) theory. Its thermodynamic limit is defined by Microstate Sequence (MSS) theory, and its dynamical action is captured by a consequent mode-coupling theory (MCT). From this single first-principles framework, we simultaneously resolve two long-standing puzzles: it predicts the giant non-Gaussian parameter(1~10), closing the order-of-magnitude gap with experiments that standard mode-coupling theory could not explain; and it delivers a first-principles, non-fitting derivation of the universal polymer constant $C_{1} \approx 16.7$ with merely 1 percent error - the most accurate theoretical prediction to date, dramatically surpassing the Adam-Gibbs and others. Our work establishes thermodynamic inertia as a foundational principle for non-equilibrium matter, bridging thermodynamic and dynamic descriptions from glassy relaxation to the maintenance of life.

</details>


### [156] [Non-monotonic Irreversibility in Polytropic Steering](https://arxiv.org/abs/2602.13765)
*Cong Fu,Youhui Lin,Shanhe Su,Yu-Han Ma*

Main category: cond-mat.stat-mech

TL;DR: 提出多方过程操控协议，揭示快速驱动下不可逆性的非单调依赖关系和异常耗散抑制现象，为微型热机设计提供新控制参数


<details>
  <summary>Details</summary>
Motivation: 有限时间内热力学状态操控存在内在耗散成本，快速非绝热转变的物理机制尚未明确，需要超越近平衡范式的理论框架

Method: 构建多方过程操控协议，建立等温与绝热极限的精确解析桥梁，研究布朗粒子远离平衡态的行为

Result: 发现不可逆性对驱动速率的非单调依赖；识别"最不可逆时间尺度"，超过该尺度后快速驱动反而抑制耗散；建立功率-效率权衡关系

Conclusion: 多方指数可作为热力学控制参数，为设计高速高性能微型热机提供理论基础和理性设计框架

Abstract: The efficient manipulation of thermodynamic states within the finite time is fundamentally constrained by the intrinsic dissipative cost. While the slow-driving regime is well-characterized by a universal $1/τ$-scaling of irreversibility, the physics governing fast, non-adiabatic transitions remains elusive. Here, we propose the polytropic steering protocols that provide an exact analytical bridge between the isothermal and adiabatic limits for Brownian particles far-from-equilibrium. We demonstrate that for any protocol duration $τ$, the system can be precisely steered along a prescribed polytropic trajectory, revealing a striking non-monotonic dependence of irreversibility on the driving rate. Contrary to the near-equilibrium paradigm where faster driving necessitates higher energetic costs, we identify a most-irreversible timescale, beyond which dissipation is anomalously suppressed by rapid driving. By mapping these protocols onto a broad class of controllable thermodynamic cycle, we establish power-efficiency tradeoffs and position the polytropic index as a genuine thermodynamic control knob for the rational design of high-speed, high-performance microscopic thermal machines.

</details>


### [157] [Bulk-boundary correspondence in topological two-dimensional non-Hermitian systems: Toeplitz operators and singular values](https://arxiv.org/abs/2602.13916)
*J. Sirker*

Main category: cond-mat.stat-mech

TL;DR: 该论文针对非厄米二维晶格系统，提出基于Toeplitz算符和奇异值（而非特征值）的体边对应理论，揭示了奇异值在平移对称性破缺扰动下的鲁棒性，并建立了拓扑指标与边界/角模数量间的精确对应关系


<details>
  <summary>Details</summary>
Motivation: 传统基于特征值的拓扑分类方法在非厄米系统中因平移对称性破缺扰动而失效，需寻找更稳定的数学工具描述拓扑保护边界态

Method: 采用Toeplitz算符理论重构体边对应框架，将半平面/四分之一平面哈密顿量的拓扑指标与分离于体奇异值谱的有限尺寸奇异值数量关联

Result: 证明奇异值在扰动下保持稳定，其特征值分离现象可精确刻画边缘态、角态及高阶拓扑相，无需依赖晶体对称性，并通过非厄米BBH模型验证理论

Conclusion: 奇异值谱是建立非厄米系统拓扑分类的唯一可靠基础，该理论为设计鲁棒性拓扑边界器件提供了新范式

Abstract: In contrast to eigenvalue-based approaches, we formulate the bulk-boundary correspondence for two-dimensional non-Hermitian quadratic lattice Hamiltonians in terms of Toeplitz operators and singular values, which correctly capture the stability, localization, and scaling of edge and corner modes. We show that singular values, rather than eigenvalues, provide the only stable foundation for topological protection in non-Hermitian systems because they remain robust under translational-symmetry-breaking perturbations that destabilize the eigenvalue spectrum, rendering it unsuitable for topological classification. Building on Toeplitz operator theory, we establish general results for non-Hermitian Hamiltonians defined on half and quarter planes, relating the topological indices of the associated Toeplitz operators to the number of finite-size singular values that are separated from the bulk singular-value spectrum and vanish in the thermodynamic limit. This yields a precise bulk-boundary correspondence for edge and corner modes, including higher-order topological phases, without requiring crystalline symmetries. We illustrate our general results with detailed examples exhibiting topologically protected families of edge states, coexisting edge and corner modes, and phases with both gapped bulk and edges supporting only stable corner modes. The latter is exemplified by a non-Hermitian generalization of the Benalcazar-Bernevig-Hughes model.

</details>


### [158] [NMR study on equilateral triangular lattice antiferromagnet Ba2La2CoTe2O12](https://arxiv.org/abs/2602.14057)
*Keito Morioka,Takayuki Goto,Masari Watanabe,Yuki Kojima,Nobuyuki Kurita,Hidekazu Tanaka,Satoshi Iguchi,Takahiko Sasaki*

Main category: cond-mat.stat-mech

TL;DR: 通过139La-NMR实验发现Ba2La2CoTe2O12在3T以上磁场中出现两个磁相变温度，揭示了从顺磁态到uud相再到三角共面相的磁场调控相变过程


<details>
  <summary>Details</summary>
Motivation: 研究具有易面各向异性的S=1/2等边三角晶格反铁磁体Ba2La2CoTe2O12在低温和磁场下的磁相变行为及自旋结构演化

Method: 采用139La核磁共振(NMR)技术，测量自旋-晶格弛豫率(1/T1)和NMR线宽，分析材料在零场和磁场下的磁相变特性

Result: (1) 零场下在TN=3.26 K发生120度自旋结构的磁有序相变；(2) 3T以上磁场中TN分裂为TN1(顺磁→uud相)和TN2(uud→三角共面相)；(3) 1/T1在TN1呈现临界发散；(4) TN2处NMR线宽异常减小，源于自旋结构转变

Conclusion: 磁场可调控该三角晶格磁体在uud相与三角共面相之间的相变，139La-NMR成功探测到两相变的临界行为和自旋结构变化，证实了长程磁有序的起始和相变诱导的线宽异常减小机制

Abstract: We report a 139La-NMR study of Ba2La2CoTe2O12, S = 1/2 equilateral triangular-lattice antiferromagnet with easy-plane anisotropy at low temperatures. This compound undergoes a magnetic phase transition at TN = 3.26 K into an ordered state with the 120 degree spin structure. Under magnetic fields above 3T, TN splits into TN1 and TN2, which correspond to the transitions from the paramagnetic phase to the up-up-down (uud) phase and from the uud phase to the triangular coplanar phase, respectively. The NMR spin-lattice relaxation rate 1/T1 exhibits a critical divergence at TN1, indicating the onset of long-range magnetic order. At TN2, the NMR-linewidth measured at 5.4 T exhibits an anomalous decrease, which we attribute to a change in the spin structure from the uud to the triangular coplanar phase.

</details>


### [159] [The Sokoban Random Walk: A Trapping Perspective](https://arxiv.org/abs/2602.14180)
*Prashant Singh,Eli Barkai,David A Kessler*

Main category: cond-mat.stat-mech

TL;DR: 研究Sokoban类模型中可推动障碍物的随机游走者被"困住"的现象，发现1D下存活概率呈现从指数衰减到拉伸指数衰减（指数1/3）的交叉行为，2D下呈现拉伸指数衰减（指数1/2），且2D中陷阱尺寸随密度呈非单调变化（峰值约0.55和0.675）


<details>
  <summary>Details</summary>
Motivation: 拓展经典 trapping 问题理论，探究可主动推动障碍物的智能体在无序介质中的逃逸行为差异，特别是不同维度下存活概率衰减规律与陷阱尺寸随密度的变化特性

Method: 1D采用大偏差理论分析任意推动障碍物数量(N_P)的影响；2D通过数值模拟研究Sokoban模型及其广义版本的动力学行为

Result: 1D：N_P≫1时存活概率呈现中间时间指数衰减→长时间拉伸指数衰减（指数1/3，与BVDV理论一致，区别于Rosenstock理论）；2D：两类模型均呈现长时间拉伸指数衰减（指数1/2，符合BVDV理论）；2D陷阱尺寸在密度ρ上呈非单调性，峰值分别位于ρ≈0.55和ρ≈0.675

Conclusion: 可推动障碍物的模型在长时行为上与经典 trapping 理论（BVDV）一致，但中间时间行为存在本质差异；2D中陷阱尺寸的非单调性揭示了密度与动力学约束的复杂相互作用，为活性物质和受限输运研究提供新视角

Abstract: We study caging/trapping in Sokoban-type models, featuring a random walker moving through a disordered medium of obstacles and capable of pushing some obstacles blocking its path. In one-dimension, we allow the walker to push up to an arbitrary $N_{\rm P}$ number of obstacles. For $N_{\rm P}\gg 1$, we use large-deviation theory to show that the survival probability to remain uncaged exhibits crossover from an exponential decay with time at intermediate times to a stretched-exponential decay at long times, with an exponent $1/3$ independent of $N_{\rm P}$. The long-time exponent matches the Balagurov--Vaks--Donsker--Varadhan (BVDV) theory of the classical trapping problem, while the exponential decay is qualitatively distinct from the Rosenstock's intermediate-time theory for classical trapping. Similarly, in two dimensions, numerical simulations reveal that both the Sokoban model and its generalized version exhibit long-time stretched-exponential relaxation with exponent $1/2$, again consistent with the BVDV theory. Finally, in two dimensions, we find that the mean trap size is nonmonotonic in $ρ$: it is small at both low and high densities, but reaches a peak at a characteristic density $ρ_*$. We estimate $ρ_* \approx 0.55$ for the Sokoban model and $ρ_* \approx 0.675$ for the generalized Sokoban model.

</details>


### [160] [Magnetocardiography measurements using an optically pumped magnetometer under ambient conditions](https://arxiv.org/abs/2602.14264)
*Kushal Patel,Kesavaraja C,Pranab Dutta,Korak Biswas*

Main category: cond-mat.stat-mech

TL;DR: 开发了基于铷原子的单光束标量光泵磁强计，用于非屏蔽环境下测量人体心磁信号，噪声水平低于15 pT/√Hz，梯度模式下可降至3 pT/√Hz，成功检测到QRS波极性反转，具有临床诊断潜力


<details>
  <summary>Details</summary>
Motivation: 实现无需磁屏蔽环境的人体心磁图非接触测量，为临床诊断提供实用化的生理信息检测工具

Method: 研制铷基单光束标量光泵磁强计，在1-35 Hz频段测试噪声性能，采用梯度配置提升信噪比，在胸部五个位置采集心磁信号

Result: 噪声基底低于15 pT/√Hz，梯度模式下降至3 pT/√Hz；成功记录到QRS波群并在不同位置观察到极性反转，验证了系统空间灵敏度

Conclusion: 该系统在非屏蔽环境下实现高质量心磁测量，为临床诊断提供了有价值的无创生理信息检测方案

Abstract: In this work, we report the development of a rubidium-based single-beam scalar optically pumped magnetometer (OPM) and demonstrate its application in measuring human cardiac magnetic fields in an unshielded environment. The developed magnetometers exhibit a noise floor below 15 pT/sqrt(Hz) in the frequency range of 1 to 35 Hz, with a measurement bandwidth of 100 Hz. When operated in a gradiometric configuration, the noise floor is further reduced to below 3 pT/sqrt(Hz) over the same frequency range. Magnetocardiography (MCG) signals were recorded at five different locations across the thorax. A clear polarity reversal of the QRS complex was observed across these measurement positions, confirming the spatial sensitivity of the system. The proposed system shows strong potential for clinical diagnostics, offering valuable physiological information through non-contact MCG measurements

</details>


### [161] [A self-consistent criterion for the range of validity of weakly driven processes](https://arxiv.org/abs/2602.14700)
*Pierre Nazé*

Main category: cond-mat.stat-mech

TL;DR: 提出基于涨落-响应不等式特征长度尺度的线性响应理论自洽有效性判据，应用于经典开放系统，并从热力学和信息论角度解释该长度的物理意义。


<details>
  <summary>Details</summary>
Motivation: 线性响应理论中长期存在的问题是确定线性近似的真实适用范围，这通常需要计算往往难以显式求解的二阶修正。

Method: 提出基于涨落-响应不等式涌现的特征长度尺度的线性响应自洽有效性判据。

Result: 该判据适用于经典开放系统，并通过谐振势中布朗粒子和呈现Kibble-Zurek机制的系统等实例加以说明。

Conclusion: 讨论了特征长度的物理意义，提供了热力学和信息论两种解释。

Abstract: One of the longstanding open questions in linear response theory concerns its true range of validity. Determining when the linear approximation can be trusted typically requires knowledge of second-order corrections, which are often difficult to compute explicitly. In this letter, I propose a self-consistent criterion for the validity of linear response, formulated in terms of a typical length scale that emerges from the fluctuation-response inequality within the theory itself. The result applies to classical open systems. I illustrate the criterion with explicit examples of Brownian particles in harmonic traps, and classical open systems presenting Kibble-Zurek mechanism. Finally, I discuss the physical meaning of this typical length, providing both thermodynamic and information-theoretic interpretations.

</details>


### [162] [The cost of speed: Time-optimal thermal control of trapped Brownian particles](https://arxiv.org/abs/2602.14707)
*Miguel Ibanez,Antonio Patron-Castro,Antonio Lasanta,Carlos A. Plata,Antonio Prados,Raul A. Rica-Alarcon*

Main category: cond-mat.stat-mech

TL;DR: Experimental realization of minimal-time thermal equilibration for Brownian particles using bang-bang temperature control, revealing a trade-off between speed and thermodynamic cost.


<details>
  <summary>Details</summary>
Motivation: To experimentally validate the theoretical solution of a thermal analogue of the classical brachistochrone problem, which minimizes the time to connect two equilibrium states of harmonically confined Brownian particles.

Method: Using two optically trapped microparticles subjected to a bang-bang effective temperature protocol, with time-resolved characterization of nonequilibrium dynamics via position variances, entropy production, and thermal kinematics (information-geometric tools).

Result: Both particle degrees of freedom reached equilibrium simultaneously in finite minimal time despite different relaxation rates; faster equilibration required higher entropy production and longer thermodynamic length.

Conclusion: A direct trade-off exists between temporal optimality (minimal time) and thermodynamic cost (entropy production/thermodynamic length) in multidimensional stochastic systems controlled by a single intensive parameter.

Abstract: A thermal analogue of the classical brachistochrone problem, which minimizes the connection time between two equilibrium states of harmonically confined Brownian particles, has recently been solved theoretically. Here we report its experimental realization using two optically trapped microparticles subjected to a bang-bang effective temperature protocol. Despite their distinct relaxation times, both degrees of freedom are steered to their respective equilibrium states simultaneously in a finite minimal time. We provide a complete time-resolved characterization of the nonequilibrium dynamics through the evolution of the position variances and the entropy production within the framework of stochastic thermodynamics, enabling a quantitative comparison with direct relaxation and a suboptimal protocol. In addition, we employ information-geometric tools -- recently referred to as thermal kinematics -- to track the system's path in state space with a single dynamical quantity. Our results show that faster equilibration requires a larger entropy production and an increased thermodynamic length, revealing a direct trade-off between temporal optimality and thermodynamic cost in multidimensional stochastic systems driven by a single intensive control parameter.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [163] [BotzoneBench: Scalable LLM Evaluation via Graded AI Anchors](https://arxiv.org/abs/2602.13214)
*Lingfeng Li,Yunlong Lu,Yuefei Zhang,Jingyu Yao,Yixin Zhu,KeYuan Cheng,Yongyi Wang,Qirui Zheng,Xionghui Yang,Wenxin Li*

Main category: cs.AI

TL;DR: 该论文提出一种新的LLM战略推理评估框架BotzoneBench，通过将模型评估锚定在固定技能层级的游戏AI上，替代传统的LLM对战排名模式，实现线性时间复杂度的绝对技能测量，并具备跨时间可比性。实验覆盖8类游戏和5个主流模型，显示顶级LLM在多个领域达到中高阶专业游戏AI水平。


<details>
  <summary>Details</summary>
Motivation: 现有LLM战略评估存在两大缺陷：静态基准无法捕捉动态能力；LLM对战锦标赛存在二次方计算成本且缺乏稳定基准。亟需可扩展的评估框架，以一致标准而非易变的peer模型衡量LLM战略推理能力。

Method: 基于Botzone竞技平台构建BotzoneBench框架，将LLM评估锚定在固定技能层级的游戏AI层级上，通过线性时间复杂度测量绝对技能。评估覆盖8类确定性/随机性游戏，分析177,047个状态-动作对。

Result: 揭示177,047个状态-动作对中存在显著性能差异，识别出不同战略行为特征。顶级LLM在多个领域达到中高阶专业游戏AI水平，验证了锚定评估方法的有效性。

Conclusion: 该锚定评估范式可推广至任何具有明确定义技能层级的领域，为交互式AI能力评估建立了可扩展、可复用的框架，解决了传统方法计算成本高和结果不稳定的核心问题。

Abstract: Large Language Models (LLMs) are increasingly deployed in interactive environments requiring strategic decision-making, yet systematic evaluation of these capabilities remains challenging. Existing benchmarks for LLMs primarily assess static reasoning through isolated tasks and fail to capture dynamic strategic abilities. Recent game-based evaluations employ LLM-vs-LLM tournaments that produce relative rankings dependent on transient model pools, incurring quadratic computational costs and lacking stable performance anchors for longitudinal tracking. The central challenge is establishing a scalable evaluation framework that measures LLM strategic reasoning against consistent, interpretable standards rather than volatile peer models. Here we show that anchoring LLM evaluation to fixed hierarchies of skill-calibrated game Artificial Intelligence (AI) enables linear-time absolute skill measurement with stable cross-temporal interpretability. Built on the Botzone platform's established competitive infrastructure, our BotzoneBench evaluates LLMs across eight diverse games spanning deterministic perfect-information board games to stochastic imperfect-information card games. Through systematic assessment of 177,047 state-action pairs from five flagship models, we reveal significant performance disparities and identify distinct strategic behaviors, with top-performing models achieving proficiency comparable to mid-to-high-tier specialized game AI in multiple domains. This anchored evaluation paradigm generalizes beyond games to any domain with well-defined skill hierarchies, establishing a scalable and reusable framework for assessing interactive AI capabilities.

</details>


### [164] [VeRA: Verified Reasoning Data Augmentation at Scale](https://arxiv.org/abs/2602.13217)
*Zerui Cheng,Jiashuo Liu,Chunjie Wu,Jianzhu Yao,Pramod Viswanath,Ge Zhang,Wenhao Huang*

Main category: cs.AI

TL;DR: VeRA框架通过将基准问题转换为可执行规范，生成无限验证变体，解决AI评估中因问题重复使用导致的记忆化、格式利用和饱和问题，提升评估的鲁棒性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估方案存在"静态"本质问题：重复使用相同题目导致模型记忆化、格式利用和性能饱和。需要从设计上构建鲁棒的评估，而非事后检测。

Method: 提出VeRA（验证推理数据增强）框架，将基准问题转换为可执行规范，包含：(i)带占位符的自然语言模板，(ii)生成有效配置的连贯生成器，(iii)验证参数并计算正确答案的确定性验证器。支持两种模式：VeRA-E（等价重写保持逻辑不变）和VeRA-H（硬化增加复杂度但仍可验证）。

Result: 在16个前沿模型上评估显示：(i) VeRA-E提升评估质量并揭示污染模式，(ii) VeRA-H实现人类自由生成带可靠标签的困难任务，(iii) VeRA建立了验证基准作为通用范式。该框架可从单一种子问题无限生成带标签的验证变体，边际成本接近零。

Conclusion: VeRA将基准从静态对象重新概念化为可执行规范，按需生成新验证实例，实现任何可验证领域评估的无限制扩展而不牺牲标签完整性，提升评估的鲁棒性和成本效益。

Abstract: The main issue with most evaluation schemes today is their "static" nature: the same problems are reused repeatedly, allowing for memorization, format exploitation, and eventual saturation. To measure genuine AI progress, we need evaluation that is robust by construction, not by post-hoc detection. In response, we propose VeRA (Verified Reasoning Data Augmentation), a framework that converts benchmark problems into executable specifications, comprising (i) a natural language template with placeholder slots, (ii) a coherent generator that samples valid configurations, and (iii) a deterministic verifier that validates parameters and calculates the corresponding correct answers for each configuration. From a single seed problem, VeRA automatically creates unlimited verified variants with reliable labels at near-zero marginal cost without human involvement.
  VeRA operates in two complementary modes. VeRA-E (equivalent) rewrites problems while keeping the underlying logic intact, useful for detecting memorization versus genuine reasoning. VeRA-H (hardened) systematically increases complexity while remaining verifiable, enabling reliable creation and labelling of fresh difficult tasks at the boundary of intelligence. Evaluating 16 frontier models with VeRA, we find: (i) VeRA-E improves evaluation quality and reveals contamination patterns. (ii) VeRA-H enables human-free generation of hard tasks with reliable labels. (iii) VeRA establishes verified benchmarks as a general paradigm. VeRA reconceptualizes benchmarks from static objects used until exhausted, to executable specifications generating fresh, verified instances on demand, enhancing robustness and cost-effectiveness for evaluation.
  With VeRA, we envision that evaluation in any verifiable domain can scale indefinitely without sacrificing label integrity. To stimulate future research, we have open-sourced all code and datasets.

</details>


### [165] [A Geometric Taxonomy of Hallucinations in LLMs](https://arxiv.org/abs/2602.13224)
*Javier Marín*

Main category: cs.AI

TL;DR: 该论文提出LLM幻觉的几何三型分类法，揭示嵌入空间能检测生成伪影但无法识别事实错误，因嵌入仅编码统计模式而非真相


<details>
  <summary>Details</summary>
Motivation: 现有"幻觉"术语混淆了不同几何特征的异质现象，需明确嵌入检测的适用范围与根本局限

Method: 提出不忠实(I)、虚构(II)、事实错误(III)三型分类；对比LLM生成与人类设计幻觉的嵌入几何；测量域内外AUROC及判别方向余弦相似度

Result: I&II型：LLM幻觉域内AUROC 0.76-0.99但跨域降至0.50（方向正交cos≈-0.07）；人类虚构跨域AUROC 0.96仅退化3.8%。III型：AUROC 0.478（随机水平），因嵌入不编码真实值

Conclusion: 嵌入检测仅适用于生成伪影(I&II型)，事实错误(III型)需外部验证；根本约束是嵌入仅捕获分布共现而非与现实对应

Abstract: The term "hallucination" in large language models conflates distinct phenomena with different geometric signatures in embedding space. We propose a taxonomy identifying three types: unfaithfulness (failure to engage with provided context), confabulation (invention of semantically foreign content), and factual error (incorrect claims within correct conceptual frames). We observe a striking asymmetry. On standard benchmarks where hallucinations are LLM-generated, detection is domain-local: AUROC 0.76-0.99 within domains, but 0.50 (chance level) across domains. Discriminative directions are approximately orthogonal between domains (mean cosine similarity -0.07). On human-crafted confabulations - invented institutions, redefined terminology, fabricated mechanisms - a single global direction achieves 0.96 AUROC with 3.8% cross-domain degradation. We interpret this divergence as follows: benchmarks capture generation artifacts (stylistic signatures of prompted fabrication), while human-crafted confabulations capture genuine topical drift. The geometric structure differs because the underlying phenomena differ. Type III errors show 0.478 AUROC - indistinguishable from chance. This reflects a theoretical constraint: embeddings encode distributional co-occurrence, not correspondence to external reality. Statements with identical contextual patterns occupy similar embedding regions regardless of truth value. The contribution is a geometric taxonomy clarifying the scope of embedding-based detection: Types I and II are detectable; Type III requires external verification mechanisms.

</details>


### [166] [Variation is the Key: A Variation-Based Framework for LLM-Generated Text Detection](https://arxiv.org/abs/2602.13226)
*Xuecong Li,Xiaohong Li,Qiang Hu,Yao Zhang,Junjie Wang*

Main category: cs.AI

TL;DR: 提出VaryBalance检测法，通过比较人类文本与LLM改写版本的差异度（均值标准差），显著提升LLM生成文本检测精度，AUROC指标超越现有最佳方法34.3%


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本检测器依赖不切实际的假设（如白盒设置）或仅分析单文本特征，导致检测精度不足，亟需实用性强的新方法

Method: 利用人类文本与LLM改写版本间差异度大于LLM生成文本的特性，通过计算均值标准差量化该差异，区分人机文本

Result: 在AUROC指标上超越Binoculars等先进检测器达34.3%，且对多生成模型和多语言场景保持强鲁棒性

Conclusion: VaryBalance是一种简单有效的实用检测方案，通过改写对比策略为LLM文本检测提供了新思路，具有显著性能优势

Abstract: Detecting text generated by large language models (LLMs) is crucial but challenging. Existing detectors depend on impractical assumptions, such as white-box settings, or solely rely on text-level features, leading to imprecise detection ability. In this paper, we propose a simple but effective and practical LLM-generated text detection method, VaryBalance. The core of VaryBalance is that, compared to LLM-generated texts, there is a greater difference between human texts and their rewritten version via LLMs. Leveraging this observation, VaryBalance quantifies this through mean standard deviation and distinguishes human texts and LLM-generated texts. Comprehensive experiments demonstrated that VaryBalance outperforms the state-of-the-art detectors, i.e., Binoculars, by up to 34.3\% in terms of AUROC, and maintains robustness against multiple generating models and languages.

</details>


### [167] [Intelligence as Trajectory-Dominant Pareto Optimization](https://arxiv.org/abs/2602.13230)
*Truong Xuan Khanh,Truong Quynh Hoa*

Main category: cs.AI

TL;DR: The paper argues that AI stagnation in long-term adaptability stems from structural "Pareto traps" in optimization geometry rather than learning limitations. It introduces Trajectory-Dominant Pareto Optimization and a metric (TEDI) to measure escape difficulty, showing that intelligence ceilings are geometric consequences that restrict access to superior developmental paths.


<details>
  <summary>Details</summary>
Motivation: AI systems exhibit stagnation in long-horizon adaptability despite performance optimization. The authors believe this isn't due to insufficient learning/data/model capacity, but from deeper structural properties of how intelligence is optimized over time.

Method: Formulates intelligence as trajectory-level phenomenon with multi-objective trade-offs; introduces Trajectory-Dominant Pareto Optimization (generalization of Pareto optimality to full trajectories); defines Trap Escape Difficulty Index (TEDI) as composite geometric measure; develops formal taxonomy of Pareto traps; uses minimal agent-environment model for illustration.

Result: Identifies Pareto traps as locally non-dominated regions that restrict access to globally superior paths; shows dynamic intelligence ceilings arise as inevitable geometric consequences of trajectory-level dominance; demonstrates trajectory-level divergence using minimal model.

Conclusion: The framework shifts focus from terminal performance to optimization geometry, providing a principled way to diagnose and overcome long-horizon developmental constraints in adaptive systems.

Abstract: Despite recent advances in artificial intelligence, many systems exhibit stagnation in long-horizon adaptability despite continued performance optimization. This work argues that such limitations do not primarily arise from insufficient learning, data, or model capacity, but from a deeper structural property of how intelligence is optimized over time. We formulate intelligence as a trajectory-level phenomenon governed by multi-objective trade-offs, and introduce Trajectory-Dominant Pareto Optimization, a path-wise generalization of classical Pareto optimality in which dominance is defined over full trajectories. Within this framework, Pareto traps emerge as locally non-dominated regions of trajectory space that nevertheless restrict access to globally superior developmental paths under conservative local optimization. To characterize the rigidity of such constraints, we define the Trap Escape Difficulty Index (TEDI), a composite geometric measure capturing escape distance, structural constraints, and behavioral inertia. We show that dynamic intelligence ceilings arise as inevitable geometric consequences of trajectory-level dominance, independent of learning progress or architectural scale. We further introduce a formal taxonomy of Pareto traps and illustrate the resulting trajectory-level divergence using a minimal agent-environment model. Together, these results shift the locus of intelligence from terminal performance to optimization geometry, providing a principled framework for diagnosing and overcoming long-horizon developmental constraints in adaptive systems.

</details>


### [168] [Stay in Character, Stay Safe: Dual-Cycle Adversarial Self-Evolution for Safety Role-Playing Agents](https://arxiv.org/abs/2602.13234)
*Mingyang Liao,Yichen Wan,shuchen wu,Chenxi Miao,Xin Shen,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang*

Main category: cs.AI

TL;DR: 提出一种无需训练的双循环对抗自进化框架，通过攻击者-防御者双循环和分层知识库，在保持角色扮演忠实度的同时提升对越狱攻击的抵抗能力


<details>
  <summary>Details</summary>
Motivation: LLM角色扮演能力提升的同时，对角色设定的强遵循增加了越狱攻击的脆弱性；现有训练时解决方案成本高、损害角色行为且难以应用于闭源大模型

Method: 提出无需训练的双循环对抗自进化框架：攻击者循环生成渐进式越狱提示，防御者循环将失败案例蒸馏为包含全局安全规则、角色约束和角色内示例的分层知识库，推理时检索组合知识指导生成

Result: 在多个闭源大模型上实验显示，相比强基线在角色忠实度和越狱抵抗性上均有持续提升，且能泛化到未见过的角色和攻击提示

Conclusion: 该框架有效平衡了角色扮演的真实性与安全性，具有无需训练、可自适应演进的优势

Abstract: LLM-based role-playing has rapidly improved in fidelity, yet stronger adherence to persona constraints commonly increases vulnerability to jailbreak attacks, especially for risky or negative personas. Most prior work mitigates this issue with training-time solutions (e.g., data curation or alignment-oriented regularization). However, these approaches are costly to maintain as personas and attack strategies evolve, can degrade in-character behavior, and are typically infeasible for frontier closed-weight LLMs. We propose a training-free Dual-Cycle Adversarial Self-Evolution framework with two coupled cycles. A Persona-Targeted Attacker Cycle synthesizes progressively stronger jailbreak prompts, while a Role-Playing Defender Cycle distills observed failures into a hierarchical knowledge base of (i) global safety rules, (ii) persona-grounded constraints, and (iii) safe in-character exemplars. At inference time, the Defender retrieves and composes structured knowledge from this hierarchy to guide generation, producing responses that remain faithful to the target persona while satisfying safety constraints. Extensive experiments across multiple proprietary LLMs show consistent gains over strong baselines on both role fidelity and jailbreak resistance, and robust generalization to unseen personas and attack prompts.

</details>


### [169] [Lang2Act: Fine-Grained Visual Reasoning through Self-Emergent Linguistic Toolchains](https://arxiv.org/abs/2602.13235)
*Yuqi Xiong,Chunyi Peng,Zhipeng Xu,Zhenghao Liu,Zulong Chen,Yukun Yan,Shuo Wang,Yu Gu,Ge Yu*

Main category: cs.AI

TL;DR: Lang2Act用自涌现的语言工具链替代VRAG中僵化的外部工具，通过两阶段强化学习训练，提升VLM视觉感知能力超过4%。


<details>
  <summary>Details</summary>
Motivation: 现有VRAG框架因分离感知与推理过程，依赖刚性预定义外部工具，导致视觉信息在图像操作中不必要地丢失。

Method: 提出Lang2Act，通过自涌现动作构建语言工具，采用两阶段强化学习框架：第一阶段构建可复用语言工具箱，第二阶段优化这些工具在下游推理中的有效利用。

Result: Lang2Act显著增强了VLM的视觉感知能力，性能提升超过4%。

Conclusion: Lang2Act通过自涌现语言工具链有效提升VLM视觉感知，为传统解耦VRAG框架提供了更优的替代方案。

Abstract: Visual Retrieval-Augmented Generation (VRAG) enhances Vision-Language Models (VLMs) by incorporating external visual documents to address a given query. Existing VRAG frameworks usually depend on rigid, pre-defined external tools to extend the perceptual capabilities of VLMs, typically by explicitly separating visual perception from subsequent reasoning processes. However, this decoupled design can lead to unnecessary loss of visual information, particularly when image-based operations such as cropping are applied. In this paper, we propose Lang2Act, which enables fine-grained visual perception and reasoning through self-emergent linguistic toolchains. Rather than invoking fixed external engines, Lang2Act collects self-emergent actions as linguistic tools and leverages them to enhance the visual perception capabilities of VLMs. To support this mechanism, we design a two-stage Reinforcement Learning (RL)-based training framework. Specifically, the first stage optimizes VLMs to self-explore high-quality actions for constructing a reusable linguistic toolbox, and the second stage further optimizes VLMs to exploit these linguistic tools for downstream reasoning effectively. Experimental results demonstrate the effectiveness of Lang2Act in substantially enhancing the visual perception capabilities of VLMs, achieving performance improvements of over 4%. All code and data are available at https://github.com/NEUIR/Lang2Act.

</details>


### [170] [NL2LOGIC: AST-Guided Translation of Natural Language into First-Order Logic with Large Language Models](https://arxiv.org/abs/2602.13237)
*Rizky Ramadhana Putra,Raihan Sultan Pasha Basuki,Yutong Cheng,Peng Gao*

Main category: cs.AI

TL;DR: 提出NL2LOGIC框架，通过抽象语法树作为中间表示，结合递归LLM语义解析器和AST引导生成器，实现高准确率的一阶逻辑翻译，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自然语言到一阶逻辑的翻译方法存在语法约束弱（导致句法脆弱）和语义保真度低（缺乏子句级语义理解）的问题，而法律/治理等领域对推理的准确性和可解释性要求极高。

Method: 引入抽象语法树（AST）作为中间表示，设计递归大语言模型语义解析器与AST引导的确定性生成器相结合，生成可直接被求解器执行的逻辑代码。

Result: 在FOLIO、LogicNLI和ProofWriter基准测试中达到99%句法准确率，语义正确性较最优基线提升高达30%；集成到Logic-LM后实现接近完美的可执行性，下游推理准确率提升31%。

Conclusion: NL2LOGIC通过AST中间表示和确定性生成机制，有效解决了语法控制与语义保真问题，为自动化推理提供了高可靠性的一阶逻辑翻译方案。

Abstract: Automated reasoning is critical in domains such as law and governance, where verifying claims against facts in documents requires both accuracy and interpretability. Recent work adopts structured reasoning pipelines that translate natural language into first-order logic and delegate inference to automated solvers. With the rise of large language models, approaches such as GCD and CODE4LOGIC leverage their reasoning and code generation capabilities to improve logic parsing. However, these methods suffer from fragile syntax control due to weak enforcement of global grammar constraints and low semantic faithfulness caused by insufficient clause-level semantic understanding. We propose NL2LOGIC, a first-order logic translation framework that introduces an abstract syntax tree as an intermediate representation. NL2LOGIC combines a recursive large language model based semantic parser with an abstract syntax tree guided generator that deterministically produces solver-ready logic code. Experiments on the FOLIO, LogicNLI, and ProofWriter benchmarks show that NL2LOGIC achieves 99 percent syntactic accuracy and improves semantic correctness by up to 30 percent over state-of-the-art baselines. Furthermore, integrating NL2LOGIC into Logic-LM yields near-perfect executability and improves downstream reasoning accuracy by 31 percent compared to Logic-LM's original few-shot unconstrained translation module.

</details>


### [171] [AST-PAC: AST-guided Membership Inference for Code](https://arxiv.org/abs/2602.13240)
*Roham Koohestani,Ali Al-Kaswan,Jonathan Katzy,Maliheh Izadi*

Main category: cs.AI

TL;DR: This paper studies membership inference attacks for code LLMs, finding that existing PAC method degrades on complex code, and proposes AST-PAC using syntax tree perturbations to improve performance on larger files while noting limitations on small/alphanumeric-rich code.


<details>
  <summary>Details</summary>
Motivation: Code LLMs trained on restrictively licensed source code create data governance and copyright challenges, requiring auditing mechanisms like Membership Inference Attacks (MIAs), but methods like Polarized Augment Calibration (PAC) remain underexplored in the code domain.

Method: Exploratory study evaluating Loss baseline and PAC methods on 3B-7B parameter code models, introducing AST-PAC—a domain-specific adaptation using Abstract Syntax Tree (AST) based perturbations to generate syntactically valid calibration samples.

Result: PAC outperforms Loss baseline but degrades on larger, complex files due to syntax-ignorant augmentations; AST-PAC improves as syntactic size grows (where PAC degrades) but under-mutates small files and underperforms on alphanumeric-rich code.

Conclusion: The findings motivate future work on syntax-aware and size-adaptive calibration as a prerequisite for reliable provenance auditing of code language models.

Abstract: Code Large Language Models are frequently trained on massive datasets containing restrictively licensed source code. This creates urgent data governance and copyright challenges. Membership Inference Attacks (MIAs) can serve as an auditing mechanism to detect unauthorized data usage in models. While attacks like the Loss Attack provide a baseline, more involved methods like Polarized Augment Calibration (PAC) remain underexplored in the code domain. This paper presents an exploratory study evaluating these methods on 3B--7B parameter code models. We find that while PAC generally outperforms the Loss baseline, its effectiveness relies on augmentation strategies that disregard the rigid syntax of code, leading to performance degradation on larger, complex files. To address this, we introduce AST-PAC, a domain-specific adaptation that utilizes Abstract Syntax Tree (AST) based perturbations to generate syntactically valid calibration samples. Preliminary results indicate that AST-PAC improves as syntactic size grows, where PAC degrades, but under-mutates small files and underperforms on alphanumeric-rich code. Overall, the findings motivate future work on syntax-aware and size-adaptive calibration as a prerequisite for reliable provenance auditing of code language models.

</details>


### [172] [X-Blocks: Linguistic Building Blocks of Natural Language Explanations for Automated Vehicles](https://arxiv.org/abs/2602.13248)
*Ashkan Y. Zadeh,Xiaomeng Li,Andry Rakotonirainy,Ronald Schroeter,Sebastien Glaser,Zishuo Zhu*

Main category: cs.AI

TL;DR: A hierarchical framework (X-Blocks) for analyzing natural language explanations of automated vehicles at context, syntax, and lexicon levels. The context-level RACE classifier achieves 91.45% accuracy, revealing systematic linguistic patterns that can guide explanation generation for better user trust.


<details>
  <summary>Details</summary>
Motivation: Natural language explanations are critical for trust in automated vehicles, but lack systematic frameworks for analyzing how humans linguistically construct driving rationales across diverse scenarios.

Method: X-Blocks framework with three-level analysis: (1) Context: RACE multi-LLM ensemble with Chain-of-Thought and self-consistency for classifying 32 scenario-aware categories; (2) Lexical: log-odds analysis with Dirichlet priors; (3) Syntactic: dependency parsing and template extraction.

Result: RACE achieves 91.45% accuracy and kappa 0.91 on Berkeley DeepDrive-X dataset; identifies context-specific vocabulary patterns; finds explanations use limited reusable grammar families with systematic variation across contexts.

Conclusion: X-Blocks is dataset-agnostic and task-independent; provides evidence-based linguistic design principles for generating scenario-aware explanations to support transparency, trust, and accessibility in automated driving.

Abstract: Natural language explanations play a critical role in establishing trust and acceptance of automated vehicles (AVs), yet existing approaches lack systematic frameworks for analysing how humans linguistically construct driving rationales across diverse scenarios. This paper introduces X-Blocks (eXplanation Blocks), a hierarchical analytical framework that identifies the linguistic building blocks of natural language explanations for AVs at three levels: context, syntax, and lexicon.
  At the context level, we propose RACE (Reasoning-Aligned Classification of Explanations), a multi-LLM ensemble framework that combines Chain-of-Thought reasoning with self-consistency mechanisms to robustly classify explanations into 32 scenario-aware categories. Applied to human-authored explanations from the Berkeley DeepDrive-X dataset, RACE achieves 91.45 percent accuracy and a Cohens kappa of 0.91 against cases with human annotator agreement, indicating near-human reliability for context classification.
  At the lexical level, log-odds analysis with informative Dirichlet priors reveals context-specific vocabulary patterns that distinguish driving scenarios. At the syntactic level, dependency parsing and template extraction show that explanations draw from a limited repertoire of reusable grammar families, with systematic variation in predicate types and causal constructions across contexts.
  The X-Blocks framework is dataset-agnostic and task-independent, offering broad applicability to other automated driving datasets and safety-critical domains. Overall, our findings provide evidence-based linguistic design principles for generating scenario-aware explanations that support transparency, user trust, and cognitive accessibility in automated driving systems.

</details>


### [173] [MAPLE: A Sub-Agent Architecture for Memory, Learning, and Personalization in Agentic AI Systems](https://arxiv.org/abs/2602.13258)
*Deepak Babu Piskala*

Main category: cs.AI

TL;DR: 提出MAPLE框架，将LLM智能体的记忆、学习和个性化能力解耦为三个独立机制，实现更好的用户适应性和实时个性化效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在适应用户方面的根本限制源于架构混淆：将记忆、学习和个性化视为统一能力而非需要不同基础设施、不同时间尺度且可独立优化的三种不同机制。

Method: 提出MAPLE（Memory-Adaptive Personalized LEarning）原则性分解方法，其中Memory处理存储和检索基础设施；Learning从累积交互中异步提取智能；Personalization在有限上下文预算内实时应用所学知识。每个组件作为具有专门工具和明确定接口的专用子智能体运行。

Result: 在MAPLE-Personas基准测试中，相比无状态基线，个性化分数提高14.6%（p < 0.01, Cohen's d = 0.95），特质整合率从45%提升至75%。

Conclusion: 通过将记忆、学习和个性化解耦为独立优化的专门机制，智能体能够实现真正的学习和适应，为创建真正个性化的AI助手提供了新范式。

Abstract: Large language model (LLM) agents have emerged as powerful tools for complex tasks, yet their ability to adapt to individual users remains fundamentally limited. We argue this limitation stems from a critical architectural conflation: current systems treat memory, learning, and personalization as a unified capability rather than three distinct mechanisms requiring different infrastructure, operating on different timescales, and benefiting from independent optimization. We propose MAPLE (Memory-Adaptive Personalized LEarning), a principled decomposition where Memory handles storage and retrieval infrastructure; Learning extracts intelligence from accumulated interactions asynchronously; and Personalization applies learned knowledge in real-time within finite context budgets. Each component operates as a dedicated sub-agent with specialized tooling and well-defined interfaces. Experimental evaluation on the MAPLE-Personas benchmark demonstrates that our decomposition achieves a 14.6% improvement in personalization score compared to a stateless baseline (p < 0.01, Cohen's d = 0.95) and increases trait incorporation rate from 45% to 75% -- enabling agents that genuinely learn and adapt.

</details>


### [174] [ProMoral-Bench: Evaluating Prompting Strategies for Moral Reasoning and Safety in LLMs](https://arxiv.org/abs/2602.13274)
*Rohan Subramanian Thomas,Shikhar Shiromani,Abdullah Chaudhry,Ruizhe Li,Vasu Sharma,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Prompt design significantly impacts the moral competence and safety alignment of large language models (LLMs), yet empirical comparisons remain fragmented across datasets and models.We introduce ProMoral-Bench, a unified benchmark evaluating 11 prompting paradigms across four LLM families. Using ETHICS, Scruples, WildJailbreak, and our new robustness test, ETHICS-Contrast, we measure performance via our proposed Unified Moral Safety Score (UMSS), a metric balancing accuracy and safety. Our results show that compact, exemplar-guided scaffolds outperform complex multi-stage reasoning, providing higher UMSS scores and greater robustness at a lower token cost. While multi-turn reasoning proves fragile under perturbations, few-shot exemplars consistently enhance moral stability and jailbreak resistance. ProMoral-Bench establishes a standardized framework for principled, cost-effective prompt engineering.

</details>


### [175] [Artificial Organisations](https://arxiv.org/abs/2602.13275)
*William Waites*

Main category: cs.AI

TL;DR: 该论文提出通过组织架构而非单个AI对齐来实现多智能体系统的可靠性。通过"毅力组合引擎"演示：Composer起草文本，Corroborator用资料验证事实，Critic无资料评估论证质量，架构化的信息不对称创造了分层验证。在474次任务中，系统面对需要虚构的难题时，从尝试造假转向诚实拒绝并提出替代方案，这种行为既非指令也非个体激励所能解释。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐研究致力于使单个AI系统可靠，但人类机构通过组织结构设计而非假设个体完全对齐来实现集体可靠性。多智能体AI系统应借鉴这种制度模式。

Method: 构建"毅力组合引擎"三智能体系统：Composer（起草文本）、Corroborator（有资料权限验证事实）、Critic（无资料权限评估论证质量），通过架构强制信息不对称实现分层验证，执行474次离散的起草-验证-评估循环任务。

Result: 实验显示，面对需要虚构内容的任务时，迭代过程使系统从尝试造假转向诚实拒绝并主动提供替代方案，这种行为既非显式指令也非个体激励所致，符合制度假设模式。

Conclusion: 组织理论可作为多智能体AI安全的生产性框架。通过架构化信息隔离强制实现验证与评估，制度设计能从不可靠的个体组件中获得可靠的集体行为。

Abstract: Alignment research focuses on making individual AI systems reliable. Human institutions achieve reliable collective behaviour differently: they mitigate the risk posed by misaligned individuals through organisational structure. Multi-agent AI systems should follow this institutional model using compartmentalisation and adversarial review to achieve reliable outcomes through architectural design rather than assuming individual alignment.
  We demonstrate this approach through the Perseverance Composition Engine, a multi-agent system for document composition. The Composer drafts text, the Corroborator verifies factual substantiation with full source access, and the Critic evaluates argumentative quality without access to sources: information asymmetry enforced by system architecture. This creates layered verification: the Corroborator detects unsupported claims, whilst the Critic independently assesses coherence and completeness. Observations from 474 composition tasks (discrete cycles of drafting, verification, and evaluation) exhibit patterns consistent with the institutional hypothesis. When assigned impossible tasks requiring fabricated content, this iteration enabled progression from attempted fabrication toward honest refusal with alternative proposals--behaviour neither instructed nor individually incentivised. These findings motivate controlled investigation of whether architectural enforcement produces reliable outcomes from unreliable components.
  This positions organisational theory as a productive framework for multi-agent AI safety. By implementing verification and evaluation as structural properties enforced through information compartmentalisation, institutional design offers a route to reliable collective behaviour from unreliable individual components.

</details>


### [176] [Accuracy Standards for AI at Work vs. Personal Life: Evidence from an Online Survey](https://arxiv.org/abs/2602.13283)
*Gaston Besanson,Federico Todeschini*

Main category: cs.AI

TL;DR: This paper examines how people's accuracy tolerance for AI tools varies between work and personal contexts, finding significantly stricter requirements at work and greater disruption in personal life when tools are unavailable.


<details>
  <summary>Details</summary>
Motivation: To understand how users trade off accuracy when using AI-powered tools in professional versus personal settings, and how they cope when these tools are unavailable, given modern AI's ability to produce acceptable but non-identical outputs.

Method: Online survey of 300 participants (170 with complete data) measuring accuracy tolerance on 1-5 scales for work and personal contexts, plus disruption when tools are unavailable.

Result: Work contexts demand significantly higher AI accuracy than personal life (24.1% vs 8.8% require top-box accuracy, 3.86 vs 3.08 mean scale score, p<0.001). Heavy app users have stricter work standards, and personal routines experience more disruption when tools are unavailable (34.1% vs 15.3%, p<0.01).

Conclusion: Accuracy tolerance is context-dependent with professional settings requiring higher reliability. When AI tools are unavailable, personal life suffers more disruption than work, indicating different coping mechanisms and adoption patterns across contexts.

Abstract: We study how people trade off accuracy when using AI-powered tools in professional versus personal contexts for adoption purposes, the determinants of those trade-offs, and how users cope when AI/apps are unavailable. Because modern AI systems (especially generative models) can produce acceptable but non-identical outputs, we define "accuracy" as context-specific reliability: the degree to which an output aligns with the user's intent within a tolerance threshold that depends on stakes and the cost of correction. In an online survey (N=300), among respondents with both accuracy items (N=170), the share requiring high accuracy (top-box) is 24.1% at work vs. 8.8% in personal life (+15.3 pp; z=6.29, p<0.001). The gap remains large under a broader top-two-box definition (67.0% vs. 32.9%) and on the full 1-5 ordinal scale (mean 3.86 vs. 3.08). Heavy app use and experience patterns correlate with stricter work standards (H2). When tools are unavailable (H3), respondents report more disruption in personal routines than at work (34.1% vs. 15.3%, p<0.01). We keep the main text focused on these substantive results and place test taxonomy and power derivations in a technical appendix.

</details>


### [177] [DECKBench: Benchmarking Multi-Agent Frameworks for Academic Slide Generation and Editing](https://arxiv.org/abs/2602.13318)
*Daesik Jang,Morgan Lindsay Heisler,Linzi Xing,Yifei Li,Edward Wang,Ying Xiong,Yong Zhang,Zhenan Fan*

Main category: cs.AI

TL;DR: 提出DECKBench基准测试框架，用于评估多智能体学术幻灯片生成与编辑系统，通过构建论文-幻灯片配对数据集和模拟编辑指令，系统评估内容保真度、连贯性、布局质量和多轮指令遵循能力，并建立模块化多智能体基线系统，为学术演示文稿生成提供标准化评估基础。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法充分衡量自动化学术幻灯片生成与编辑的挑战，包括忠实内容选择、连贯幻灯片组织、布局感知渲染和鲁棒的多轮指令遵循等复杂需求。

Method: 构建DECKBench评估框架，基于精选的论文-幻灯片配对数据集，并增强以真实的模拟编辑指令；设计系统化的评估协议，从幻灯片级和演示文稿级评估保真度、连贯性、布局质量和多轮指令遵循；实现模块化多智能体基线系统，将任务分解为论文解析总结、幻灯片规划、HTML创建和迭代编辑。

Result: 该基准测试能够突出系统优势、暴露失败模式，并提供可操作的改进见解；代码和数据已开源。

Conclusion: 本研究建立了可重复、可比较的学术演示文稿生成与编辑的标准化评估基础，推动多智能体系统在该领域的发展。

Abstract: Automatically generating and iteratively editing academic slide decks requires more than document summarization. It demands faithful content selection, coherent slide organization, layout-aware rendering, and robust multi-turn instruction following. However, existing benchmarks and evaluation protocols do not adequately measure these challenges. To address this gap, we introduce the Deck Edits and Compliance Kit Benchmark (DECKBench), an evaluation framework for multi-agent slide generation and editing. DECKBench is built on a curated dataset of paper to slide pairs augmented with realistic, simulated editing instructions. Our evaluation protocol systematically assesses slide-level and deck-level fidelity, coherence, layout quality, and multi-turn instruction following. We further implement a modular multi-agent baseline system that decomposes the slide generation and editing task into paper parsing and summarization, slide planning, HTML creation, and iterative editing. Experimental results demonstrate that the proposed benchmark highlights strengths, exposes failure modes, and provides actionable insights for improving multi-agent slide generation and editing systems. Overall, this work establishes a standardized foundation for reproducible and comparable evaluation of academic presentation generation and editing. Code and data are publicly available at https://github.com/morgan-heisler/DeckBench .

</details>


### [178] [Situation Graph Prediction: Structured Perspective Inference for User Modeling](https://arxiv.org/abs/2602.13319)
*Jisung Shin,Daniel Platnick,Marjan Alirezaie,Hossein Rahnama*

Main category: cs.AI

TL;DR: Proposes Situation Graph Prediction (SGP) to model evolving internal states (goals/emotions) via inverse inference, using synthetic data generation to overcome data bottlenecks; shows latent-state inference is harder than surface extraction in GPT-4o experiments.


<details>
  <summary>Details</summary>
Motivation: Current Perspective-Aware AI fails to model dynamic internal states (goals/emotions/contexts) due to privacy-sensitive digital footprints and scarcity of labeled perspective data, creating a critical data bottleneck.

Method: Frames perspective modeling as inverse inference via Situation Graph Prediction (SGP): reconstructs structured ontology-aligned perspective representations from multimodal artifacts; uses structure-first synthetic data generation to align latent labels with observable traces.

Result: In GPT-4o diagnostic study using retrieval-augmented in-context learning, reveals significant performance gap between surface-level extraction and latent perspective inference, proving SGP is non-trivial; validates structure-first synthetic data strategy.

Conclusion: SGP effectively addresses data bottlenecks for perspective-aware AI through synthetic ontology-grounded generation, but latent-state inference remains challenging even for advanced models, indicating need for specialized approaches beyond surface extraction.

Abstract: Perspective-Aware AI requires modeling evolving internal states--goals, emotions, contexts--not merely preferences. Progress is limited by a data bottleneck: digital footprints are privacy-sensitive and perspective states are rarely labeled. We propose Situation Graph Prediction (SGP), a task that frames perspective modeling as an inverse inference problem: reconstructing structured, ontology-aligned representations of perspective from observable multimodal artifacts. To enable grounding without real labels, we use a structure-first synthetic generation strategy that aligns latent labels and observable traces by design. As a pilot, we construct a dataset and run a diagnostic study using retrieval-augmented in-context learning as a proxy for supervision. In our study with GPT-4o, we observe a gap between surface-level extraction and latent perspective inference--indicating latent-state inference is harder than surface extraction under our controlled setting. Results suggest SGP is non-trivial and provide evidence for the structure-first data synthesis strategy.

</details>


### [179] [Detecting Jailbreak Attempts in Clinical Training LLMs Through Automated Linguistic Feature Extraction](https://arxiv.org/abs/2602.13321)
*Tri Nguyen,Huy Hoang Bao Le,Lohith Srikanth Pentapalli,Laurah Turner,Kelly Cohen*

Main category: cs.AI

TL;DR: 本研究提出了一个可扩展的自动化框架，通过训练BERT模型从文本中直接提取专业性、医学相关性、伦理行为和上下文干扰等四个核心语言特征，再结合多层分类器来检测临床训练大语言模型中的越狱行为，在交叉验证和留出测试中表现优异，为安全关键的医疗对话系统提供了可解释的越狱检测方案。


<details>
  <summary>Details</summary>
Motivation: 在临床培训大语言模型中检测越狱行为需要准确建模语言偏差，但先前依赖人工标注的方法存在可扩展性和表达能力的限制，无法满足实际应用需求。

Method: 利用专家标注的四个核心语言特征（专业性、医学相关性、伦理行为、上下文干扰），训练通用领域和医学领域的BERT模型直接预测这些特征；为每个维度选择最可靠的回归器作为特征提取器，再采用树模型、线性模型、概率模型和集成方法等二阶分类器来预测越狱可能性。

Result: 系统在交叉验证和留出评估中均取得强整体性能，证明基于LLM提取的语言特征能有效支撑自动化越狱检测；错误分析揭示了当前标注和特征表示的关键局限性。

Conclusion: 该研究为安全关键的医疗对话系统提供了一种可扩展且可解释的越狱检测方法；未来需要更丰富的标注方案、更细粒度的特征提取以及能够捕捉对话过程中越狱风险动态演化的方法。

Abstract: Detecting jailbreak attempts in clinical training large language models (LLMs) requires accurate modeling of linguistic deviations that signal unsafe or off-task user behavior. Prior work on the 2-Sigma clinical simulation platform showed that manually annotated linguistic features could support jailbreak detection. However, reliance on manual annotation limited both scalability and expressiveness. In this study, we extend this framework by using experts' annotations of four core linguistic features (Professionalism, Medical Relevance, Ethical Behavior, and Contextual Distraction) and training multiple general-domain and medical-domain BERT-based LLM models to predict these features directly from text. The most reliable feature regressor for each dimension was selected and used as the feature extractor in a second layer of classifiers. We evaluate a suite of predictive models, including tree-based, linear, probabilistic, and ensemble methods, to determine jailbreak likelihood from the extracted features. Across cross-validation and held-out evaluations, the system achieves strong overall performance, indicating that LLM-derived linguistic features provide an effective basis for automated jailbreak detection. Error analysis further highlights key limitations in current annotations and feature representations, pointing toward future improvements such as richer annotation schemes, finer-grained feature extraction, and methods that capture the evolving risk of jailbreak behavior over the course of a dialogue. This work demonstrates a scalable and interpretable approach for detecting jailbreak behavior in safety-critical clinical dialogue systems.

</details>


### [180] [Contrastive explanations of BDI agents](https://arxiv.org/abs/2602.13323)
*Michael Winikoff*

Main category: cs.AI

TL;DR: 本文扩展了BDI智能体的解释机制以回答对比性问题（"为何选择X而非Y"），计算评估显示对比性解释更简洁，但出人意料的人体实验表明提供解释并不总能提升信任，有时甚至适得其反。


<details>
  <summary>Details</summary>
Motivation: 自主系统的透明度和信任建立需要解释能力，但现有研究仅支持简单"为何做X"类问题，而人类实际更常询问对比性问题"为何选择X而非Y"，因此需要扩展机制以支持对比性解释。

Method: 扩展BDI智能体的解释机制以处理对比性问题，通过计算评估验证解释长度变化，并开展人类受试者实验评估对比性答案在偏好、信任建立和透明度支持方面的效果。

Result: 计算评估表明对比性解释显著缩短了回答长度；人体实验显示对比性答案在某些情况下更受青睐且可能提升信任、理解度和系统正确性信心，但意外发现提供解释并无明确益处，某些情境下完整解释的效果甚至不如不提供任何解释。

Conclusion: 对比性解释具有简洁性和潜在的用户体验优势，但解释的有效性高度依赖情境，盲目提供解释可能损害信任，需谨慎设计。

Abstract: The ability of autonomous systems to provide explanations is important for supporting transparency and aiding the development of (appropriate) trust. Prior work has defined a mechanism for Belief-Desire-Intention (BDI) agents to be able to answer questions of the form ``why did you do action $X$?''. However, we know that we ask \emph{contrastive} questions (``why did you do $X$ \emph{instead of} $F$?''). We therefore extend previous work to be able to answer such questions. A computational evaluation shows that using contrastive questions yields a significant reduction in explanation length. A human subject evaluation was conducted to assess whether such contrastive answers are preferred, and how well they support trust development and transparency. We found some evidence for contrastive answers being preferred, and some evidence that they led to higher trust, perceived understanding, and confidence in the system's correctness. We also evaluated the benefit of providing explanations at all. Surprisingly, there was not a clear benefit, and in some situations we found evidence that providing a (full) explanation was worse than not providing any explanation.

</details>


### [181] [Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts](https://arxiv.org/abs/2602.13367)
*Chen Yang,Guangyue Peng,Jiaying Zhu,Ran Le,Ruixiang Feng,Tao Zhang,Xiyun Xu,Yang Song,Yiming Jia,Yuntao Wen,Yunzhi Xu,Zekai Wang,Zhenwei An,Zhicong Sun,Zongchao Chen*

Main category: cs.AI

TL;DR: Nanbeige4.1-3B是一个仅30亿参数的统一通用语言模型，首次在一个开源小模型中同时实现了强大的智能体行为、代码生成和通用推理能力。通过结合点式和配对式奖励建模、设计复杂度感知奖励、以及引入轮级监督训练，该模型在复杂问题求解中可稳定执行多达600次工具调用，性能显著超越同规模甚至更大规模的先前模型。


<details>
  <summary>Details</summary>
Motivation: 探索小参数模型（3B）能否在单一架构中同时实现广泛的能力覆盖（智能体、代码、推理）和强大的专业性能，重新定义小规模模型的潜力边界。

Method: 1) 融合点式和配对式奖励建模提升推理与人类偏好对齐；2) 在代码生成中设计复杂度感知奖励函数，同步优化正确性与效率；3) 通过复杂数据合成与轮级监督训练，实现长时程工具交互稳定性（支持600轮工具调用）。

Result: 在多项实验中，Nanbeige4.1-3B显著超越同规模先前模型（如Nanbeige4-3B-2511和Qwen3-4B），性能甚至优于更大的Qwen3-30B-A3B模型。

Conclusion: 小参数模型可以同时实现广泛的能力泛化与强大的专业化性能，打破了规模与性能的传统权衡，为3B参数模型树立了新的可能性标杆。

Abstract: We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior, code generation, and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a single model. To improve reasoning and preference alignment, we combine point-wise and pair-wise reward modeling, ensuring high-quality, human-aligned responses. For code generation, we design complexity-aware rewards in Reinforcement Learning, optimizing both correctness and efficiency. In deep search, we perform complex data synthesis and incorporate turn-level supervision during training. This enables stable long-horizon tool interactions, allowing Nanbeige4.1-3B to reliably execute up to 600 tool-call turns for complex problem-solving. Extensive experimental results show that Nanbeige4.1-3B significantly outperforms prior models of similar scale, such as Nanbeige4-3B-2511 and Qwen3-4B, even achieving superior performance compared to much larger models, such as Qwen3-30B-A3B. Our results demonstrate that small models can achieve both broad competence and strong specialization simultaneously, redefining the potential of 3B parameter models.

</details>


### [182] [MoralityGym: A Benchmark for Evaluating Hierarchical Moral Alignment in Sequential Decision-Making Agents](https://arxiv.org/abs/2602.13372)
*Simon Rosen,Siddarth Singh,Ebenezer Gelo,Helen Sarah Robertson,Ibrahim Suder,Victoria Williams,Benjamin Rosman,Geraud Nangue Tasse,Steven James*

Main category: cs.AI

TL;DR: 本文提出Morality Chains和MoralityGym来评估AI道德对齐，发现现有安全强化学习方法存在局限，需要更原则性的道德决策方法。


<details>
  <summary>Details</summary>
Motivation: 评估在冲突的层级化人类规范中导航的智能体的道德对齐是AI安全、道德哲学与认知科学交叉领域的关键挑战。

Method: 提出Morality Chains形式化方法，构建包含98个道德困境问题的MoralityGym基准测试，引入新的道德度量指标，并以安全强化学习为基线方法。

Result: 安全强化学习的基线结果显示存在关键局限，强调需要更有原则的道德决策方法。

Conclusion: 该工作为开发在复杂现实世界中更可靠、透明和道德的AI系统奠定了基础。

Abstract: Evaluating moral alignment in agents navigating conflicting, hierarchically structured human norms is a critical challenge at the intersection of AI safety, moral philosophy, and cognitive science. We introduce Morality Chains, a novel formalism for representing moral norms as ordered deontic constraints, and MoralityGym, a benchmark of 98 ethical-dilemma problems presented as trolley-dilemma-style Gymnasium environments. By decoupling task-solving from moral evaluation and introducing a novel Morality Metric, MoralityGym allows the integration of insights from psychology and philosophy into the evaluation of norm-sensitive reasoning. Baseline results with Safe RL methods reveal key limitations, underscoring the need for more principled approaches to ethical decision-making. This work provides a foundation for developing AI systems that behave more reliably, transparently, and ethically in complex real-world contexts.

</details>


### [183] [On-Policy Supervised Fine-Tuning for Efficient Reasoning](https://arxiv.org/abs/2602.13407)
*Anhao Zhao,Ziyang Chen,Junlong Tong,Yingqi Fan,Fanghua Ye,Shuhao Li,Yunpu Ma,Wenjie Li,Xiaoyu Shen*

Main category: cs.AI

TL;DR: 提出简化版训练策略"on-policy SFT"，通过移除KL正则化和组归一化，将大推理模型训练简化为在自生成数据上的监督微调，可将思维链长度减少80%同时保持准确率，GPU内存减半且收敛速度提升70%


<details>
  <summary>Details</summary>
Motivation: 大推理模型采用强化学习训练计算成本高，现有方法引入多奖励目标虽能平衡正确性与简洁性，但会 destabilize 训练且 trade-off 效果不佳

Method: 通过分析识别KL正则化在多奖励场景失效、组归一化存在歧义两个问题，移除这两项并简化奖励为截断式长度惩罚，将优化问题转化为在正确且简洁数据上的监督微调

Result: 在五个基准测试上定义准确率-效率帕累托前沿，思维链长度最多减少80%而准确率不变，显著优于复杂RL方法；GPU内存使用降低50%，收敛速度提升70%

Conclusion: 简化后的on-policy SFT策略证明复杂RL扩展非必需，简单方法即可达到最佳性能与效率平衡

Abstract: Large reasoning models (LRMs) are commonly trained with reinforcement learning (RL) to explore long chain-of-thought reasoning, achieving strong performance at high computational cost. Recent methods add multi-reward objectives to jointly optimize correctness and brevity, but these complex extensions often destabilize training and yield suboptimal trade-offs. We revisit this objective and challenge the necessity of such complexity. Through principled analysis, we identify fundamental misalignments in this paradigm: KL regularization loses its intended role when correctness and length are directly verifiable, and group-wise normalization becomes ambiguous under multiple reward signals. By removing these two items and simplifying the reward to a truncation-based length penalty, we show that the optimization problem reduces to supervised fine-tuning on self-generated data filtered for both correctness and conciseness. We term this simplified training strategy on-policy SFT. Despite its simplicity, on-policy SFT consistently defines the accuracy-efficiency Pareto frontier. It reduces CoT length by up to 80 while maintaining original accuracy, surpassing more complex RL-based methods across five benchmarks. Furthermore, it significantly enhances training efficiency, reducing GPU memory usage by 50% and accelerating convergence by 70%. Our code is available at https://github.com/EIT-NLP/On-Policy-SFT.

</details>


### [184] [NeuroWeaver: An Autonomous Evolutionary Agent for Exploring the Programmatic Space of EEG Analysis Pipelines](https://arxiv.org/abs/2602.13473)
*Guoan Wang,Shihao Yang,Jun-En Ding,Hao Zhu,Feng Liu*

Main category: cs.AI

TL;DR: 提出NeuroWeaver，一种自主进化智能体，通过将EEG分析流程工程重构为离散约束优化问题，利用领域知识引导的子空间初始化和多目标进化优化，在五个基准测试中生成轻量级解决方案，性能媲美大规模基础模型但参数量显著减少。


<details>
  <summary>Details</summary>
Motivation: 基础模型在EEG分析中面临巨大数据需求和参数化导致的计算成本过高问题，难以在资源受限的临床环境中部署；而通用自动机器学习框架缺乏神经生理先验知识，易产生不具科学合理性的解决方案。

Method: 提出NeuroWeaver，采用领域知识引导的子空间初始化将搜索限制在神经科学合理的流形上，并结合多目标进化优化通过自反思细化动态平衡性能、新颖性和效率。

Result: 在五个异构基准测试中，NeuroWeaver合成的轻量级解决方案持续优于最先进的特定任务方法，性能与大规模基础模型相当，但参数量显著更少。

Conclusion: NeuroWeaver成功解决了EEG分析中计算成本高和AutoML框架缺乏科学合理性的问题，提供了一种在资源受限临床环境中高效部署的实用解决方案。

Abstract: Although foundation models have demonstrated remarkable success in general domains, the application of these models to electroencephalography (EEG) analysis is constrained by substantial data requirements and high parameterization. These factors incur prohibitive computational costs, thereby impeding deployment in resource-constrained clinical environments. Conversely, general-purpose automated machine learning frameworks are often ill-suited for this domain, as exploration within an unbounded programmatic space fails to incorporate essential neurophysiological priors and frequently yields solutions that lack scientific plausibility. To address these limitations, we propose NeuroWeaver, a unified autonomous evolutionary agent designed to generalize across diverse EEG datasets and tasks by reformulating pipeline engineering as a discrete constrained optimization problem. Specifically, we employ a Domain-Informed Subspace Initialization to confine the search to neuroscientifically plausible manifolds, coupled with a Multi-Objective Evolutionary Optimization that dynamically balances performance, novelty, and efficiency via self-reflective refinement. Empirical evaluations across five heterogeneous benchmarks demonstrate that NeuroWeaver synthesizes lightweight solutions that consistently outperform state-of-the-art task-specific methods and achieve performance comparable to large-scale foundation models, despite utilizing significantly fewer parameters.

</details>


### [185] [OMNI-LEAK: Orchestrator Multi-Agent Network Induced Data Leakage](https://arxiv.org/abs/2602.13477)
*Akshat Naik,Jay Culligan,Yarin Gal,Philip Torr,Rahaf Aljundi,Alasdair Paren,Adel Bibi*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型多智能体系统中的安全漏洞，发现了一种名为OMNI-LEAK的新型攻击方式，即使存在访问控制，也能通过单次间接提示注入泄露敏感数据。


<details>
  <summary>Details</summary>
Motivation: 先前关于大型语言模型智能体安全的研究主要集中在单智能体系统或缺乏基本工程防护措施的设置上，导致对多智能体系统的威胁建模存在空白。

Method: 研究团队通过红队测试一种名为"编排器模式"的多智能体架构（中央智能体将任务分解并委托给专业智能体），以识别其安全漏洞。

Result: 他们发现了OMNI-LEAK攻击向量，该攻击可通过单次间接提示注入入侵多个智能体以泄露敏感数据，且能绕过数据访问控制。研究表明，无论是否具备推理能力的前沿模型都容易受到攻击，攻击者无需了解内部实现细节即可实施。

Conclusion: 安全研究需要从单智能体场景扩展到多智能体场景，以减少现实世界中隐私泄露、财务损失的风险，并维护公众对AI智能体的信任。

Abstract: As Large Language Model (LLM) agents become more capable, their coordinated use in the form of multi-agent systems is anticipated to emerge as a practical paradigm. Prior work has examined the safety and misuse risks associated with agents. However, much of this has focused on the single-agent case and/or setups missing basic engineering safeguards such as access control, revealing a scarcity of threat modeling in multi-agent systems. We investigate the security vulnerabilities of a popular multi-agent pattern known as the orchestrator setup, in which a central agent decomposes and delegates tasks to specialized agents. Through red-teaming a concrete setup representative of a likely future use case, we demonstrate a novel attack vector, OMNI-LEAK, that compromises several agents to leak sensitive data through a single indirect prompt injection, even in the \textit{presence of data access control}. We report the susceptibility of frontier models to different categories of attacks, finding that both reasoning and non-reasoning models are vulnerable, even when the attacker lacks insider knowledge of the implementation details. Our work highlights the importance of safety research to generalize from single-agent to multi-agent settings, in order to reduce the serious risks of real-world privacy breaches and financial losses and overall public trust in AI agents.

</details>


### [186] [Translating Dietary Standards into Healthy Meals with Minimal Substitutions](https://arxiv.org/abs/2602.13502)
*Trevor Chan,Ilias Tagkopoulos*

Main category: cs.AI

TL;DR: This paper presents an end-to-end framework that converts dietary guidelines into realistic, affordable meals with minimal changes. Using 135,491 real meals from WWEIA data, they identified 34 meal archetypes to train a generative model that creates meals meeting USDA targets. With just 1-3 food substitutions, generated meals are 10% more nutritious, follow recommended daily intake targets 47% better, and cost 19-32% less, offering a scalable solution for personalized nutrition.


<details>
  <summary>Details</summary>
Motivation: To improve nutritional quality without compromising convenience or affordability in personalized diet systems, addressing the challenge of translating dietary standards into practical, budget-friendly meals that people can actually adopt.

Method: Used What We Eat in America (WWEIA) data from 135,491 meals to identify 34 interpretable meal archetypes, which were then used to condition a generative model and portion predictor designed to meet USDA nutritional targets while maintaining minimal changes to original meals.

Result: Generated meals followed recommended daily intake targets 47% better than original meals while staying compositionally similar. By allowing just 1-3 food substitutions, meals became 10% more nutritious and reduced costs by 19-32% on average.

Conclusion: This approach provides a practical foundation for clinical decision support, public-health initiatives, and consumer applications that can deliver scalable, equitable improvements in everyday nutrition by making healthy eating both affordable and accessible.

Abstract: An important goal for personalized diet systems is to improve nutritional quality without compromising convenience or affordability. We present an end-to-end framework that converts dietary standards into complete meals with minimal change. Using the What We Eat in America (WWEIA) intake data for 135,491 meals, we identify 34 interpretable meal archetypes that we then use to condition a generative model and a portion predictor to meet USDA nutritional targets. In comparisons within archetypes, generated meals are better at following recommended daily intake (RDI) targets by 47.0%, while remaining compositionally close to real meals. Our results show that by allowing one to three food substitutions, we were able to create meals that were 10% more nutritious, while reducing costs 19-32%, on average. By turning dietary guidelines into realistic, budget-aware meals and simple swaps, this framework can underpin clinical decision support, public-health programs, and consumer apps that deliver scalable, equitable improvements in everyday nutrition.

</details>


### [187] [Who Do LLMs Trust? Human Experts Matter More Than Other LLMs](https://arxiv.org/abs/2602.13568)
*Anooshka Bajaj,Zoran Tiganj*

Main category: cs.AI

TL;DR: 该研究发现大型语言模型(LLM)在面对不同来源的反馈时会表现出类似人类的社会影响模式，特别倾向于信任并顺从被标记为"人类专家"的意见，即使这些意见是错误的，而对其他LLM的反馈则较为谨慎。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在遇到社会信息（如其他智能体的回答、工具输出或人类建议）时，是否会像人类一样根据信息源的可信度和共识强度产生判断偏差，以及是否会优先考虑人类反馈而非其他LLM的反馈。

Method: 通过三项二元决策任务（阅读理解、多步推理和道德判断），让四个经过指令调优的LLM在看到来自"朋友"、"人类专家"或其他LLM的先前回答后做出决策。实验操控了群体回答的正确性和规模大小，并在第二个实验中引入单个人类与单个LLM之间的直接意见冲突。

Result: 在所有任务中，模型显著更多地顺从于被标记为人类专家的回应（即使这些信号是错误的），并且比对待其他LLM更愿意将自己的答案向专家方向修正。

Conclusion: "专家"框架对当代LLM构成了强烈的先验假设，表明了一种能够跨决策领域泛化的、对可信度敏感的社会影响形式。

Abstract: Large language models (LLMs) increasingly operate in environments where they encounter social information such as other agents' answers, tool outputs, or human recommendations. In humans, such inputs influence judgments in ways that depend on the source's credibility and the strength of consensus. This paper investigates whether LLMs exhibit analogous patterns of influence and whether they privilege feedback from humans over feedback from other LLMs. Across three binary decision-making tasks, reading comprehension, multi-step reasoning, and moral judgment, we present four instruction-tuned LLMs with prior responses attributed either to friends, to human experts, or to other LLMs. We manipulate whether the group is correct and vary the group size. In a second experiment, we introduce direct disagreement between a single human and a single LLM. Across tasks, models conform significantly more to responses labeled as coming from human experts, including when that signal is incorrect, and revise their answers toward experts more readily than toward other LLMs. These results reveal that expert framing acts as a strong prior for contemporary LLMs, suggesting a form of credibility-sensitive social influence that generalizes across decision domains.

</details>


### [188] [Differentiable Rule Induction from Raw Sequence Inputs](https://arxiv.org/abs/2602.13583)
*Kun Gao,Katsumi Inoue,Yongzhi Cao,Hanpin Wang,Feng Yang*

Main category: cs.AI

TL;DR: 提出自监督可微聚类与可微归纳逻辑编程的融合模型，解决从原始数据学习规则时的标签泄露问题，实现时间序列和图像数据的可解释规则提取


<details>
  <summary>Details</summary>
Motivation: 现有可微归纳逻辑编程(ILP)方法依赖符号化数据集，难以直接从原始数据学习规则，核心障碍是连续输入到符号变量的映射存在显式标签泄露问题，缺乏无监督的特征-符号对齐能力

Method: 将自监督可微聚类模型与新型可微ILP模型集成：聚类模块将连续原始数据映射为符号化特征，ILP模块基于符号特征生成可解释规则，全程无需人工标注的输入特征标签

Result: 在时间序列和图像数据集上验证有效：模型能直观精确地学习通用规则，聚类过程自动建立特征-符号关联，规则准确描述原始数据特征且无标签泄露

Conclusion: 成功实现从原始数据端到端学习可解释规则，突破传统ILP对符号数据的依赖，为复杂数据提供透明化建模新路径

Abstract: Rule learning-based models are widely used in highly interpretable scenarios due to their transparent structures. Inductive logic programming (ILP), a form of machine learning, induces rules from facts while maintaining interpretability. Differentiable ILP models enhance this process by leveraging neural networks to improve robustness and scalability. However, most differentiable ILP methods rely on symbolic datasets, facing challenges when learning directly from raw data. Specifically, they struggle with explicit label leakage: The inability to map continuous inputs to symbolic variables without explicit supervision of input feature labels. In this work, we address this issue by integrating a self-supervised differentiable clustering model with a novel differentiable ILP model, enabling rule learning from raw data without explicit label leakage. The learned rules effectively describe raw data through its features. We demonstrate that our method intuitively and precisely learns generalized rules from time series and image data.

</details>


### [189] [A First Proof Sprint](https://arxiv.org/abs/2602.13587)
*Joseph Corneli*

Main category: cs.AI

TL;DR: 本研究提出了一种多智能体证明冲刺方法，结合对抗验证和线路图分解，在10个研究级数学问题上验证了结构感知验证和分层策略能有效提升压缩证明冲刺的可靠性和校准度。


<details>
  <summary>Details</summary>
Motivation: 开发一种高效可靠的方法来在压缩/冲刺格式下验证数学证明，利用多智能体系统提升证明验证的可靠性。

Method: 采用多智能体证明冲刺，结合快速草稿生成、对抗验证、定向修复和显式溯源；工作流程使用线路图分解声明依赖关系来定位缺陷并协调审稿人驱动的修订，并将数学状态与QC验证状态明确分离。

Result: 问题3在限定标准下存在验证完整的存在路径；问题5在$F_O$-局部连通谱范围内得到解决；问题10在明确假设下条件成立；问题4和6部分解决并列出剩余义务（问题6另有$K_n$无条件结果，$c_0=1/3$）；问题7通过旋转路径定理链暂定关闭；问题7和9存在未解决的验证者缺陷。方法学结果表明结构感知验证和分层切换策略提升了可靠性和校准度。

Conclusion: 结构感知验证和数学/QC分层分离的策略能有效提高压缩证明冲刺的可靠性，为大规模形式化验证提供了可校准的工作流程。

Abstract: This monograph reports a multi-agent proof sprint on ten research-level problems, combining rapid draft generation with adversarial verification, targeted repair, and explicit provenance. The workflow uses wiring-diagram decompositions of claim dependencies to localize gaps and coordinate reviewer-driven revisions. Final outcomes are heterogeneous but explicit: the manuscript distinguishes mathematical status from QC-validation status. Mathematically, Problem~3 has a validation-complete existence path under the scoped criterion used here (uniqueness/irreducibility treated as optional), Problem 5 is solved in a scope-limited form for $F_O$-local connective spectra, Problem 10 is conditional under clearly stated assumptions (with explicit necessity counterexamples when assumptions are dropped), and Problems 4 and 6 are partial with named remaining obligations in the general case (including an unconditional $K_n$ result for Problem 6 with $c_0 = 1/3$). Problem 7 is treated as provisionally closed via the rotation-route theorem chain, pending independent ledger re-check. At the QC layer, Problems~7 and~9 have node-level validation artifacts but still contain unresolved verifier gaps. The main methodological result is that structure-aware verification and layer-switching strategies improve reliability and calibration in compressed proof sprints.

</details>


### [190] [Hippocampus: An Efficient and Scalable Memory Module for Agentic AI](https://arxiv.org/abs/2602.13594)
*Yi Li,Lianjie Cao,Faraz Ahmed,Puneet Sharma,Bingzhe Li*

Main category: cs.AI

TL;DR: Hippocampus is a compact agentic memory system using binary signatures and Dynamic Wavelet Matrix compression to achieve 31x faster retrieval with linear scalability, while maintaining accuracy on standard benchmarks.


<details>
  <summary>Details</summary>
Motivation: Agentic AI needs persistent user memory beyond LLM context limits, but existing dense vector databases or knowledge graphs suffer from high latency and poor storage scalability.

Method: Uses compact binary signatures for semantic search, lossless token-ID streams for reconstruction, and a Dynamic Wavelet Matrix (DWM) to co-index and compress both streams for ultra-fast compressed-domain search.

Result: Reduces end-to-end retrieval latency by up to 31×, cuts per-query token footprint by up to 14×, and maintains accuracy on LoCoMo and LongMemEval benchmarks.

Conclusion: The linear scaling design makes Hippocampus suitable for long-horizon agentic deployments, avoiding costly vector/graph computations.

Abstract: Agentic AI require persistent memory to store user-specific histories beyond the limited context window of LLMs. Existing memory systems use dense vector databases or knowledge-graph traversal (or hybrid), incurring high retrieval latency and poor storage scalability. We introduce Hippocampus, an agentic memory management system that uses compact binary signatures for semantic search and lossless token-ID streams for exact content reconstruction. Its core is a Dynamic Wavelet Matrix (DWM) that compresses and co-indexes both streams to support ultra-fast search in the compressed domain, thus avoiding costly dense-vector or graph computations. This design scales linearly with memory size, making it suitable for long-horizon agentic deployments. Empirically, our evaluation shows that Hippocampus reduces end-to-end retrieval latency by up to 31$\times$ and cuts per-query token footprint by up to 14$\times$, while maintaining accuracy on both LoCoMo and LongMemEval benchmarks.

</details>


### [191] [The Quantization Trap: Breaking Linear Scaling Laws in Multi-Hop Reasoning](https://arxiv.org/abs/2602.13595)
*Henry Han,Xiyang Liu,Xiaodong Wang,Fei Han,Xiaodong Li*

Main category: cs.AI

TL;DR: 量化在复杂推理任务中适得其反：降低精度反而增加能耗并损害准确率


<details>
  <summary>Details</summary>
Motivation: 挑战当前AI领域的"小即是好"启发式方法，探讨神经缩放定律在多跳推理任务中的失效问题，特别是量化对能耗和性能的影响

Method: 通过严格的理论分解，分析硬件类型转换开销、反量化核的隐藏延迟成本以及顺序能量摊销失败等因素

Result: 发现"量化陷阱"现象：从16位降至8/4位精度时，净能耗反而增加，同时推理准确率下降；缩放定律的打破在实际中不可避免

Conclusion: 行业"小即是好"的启发式方法对于复杂推理任务在数学上是适得其反的，需要重新思考量化策略

Abstract: Neural scaling laws provide a predictable recipe for AI advancement: reducing numerical precision should linearly improve computational efficiency and energy profile (E proportional to bits). In this paper, we demonstrate that this scaling law breaks in the context of multi-hop reasoning. We reveal a 'quantization trap' where reducing precision from 16-bit to 8/4-bit paradoxically increases more net energy consumption while degrading reasoning accuracy. We provide a rigorous theoretical decomposition that attributes this failure to hardware casting overhead, the hidden latency cost of dequantization kernels, which becomes a dominant bottleneck in sequential reasoning chains, as well as to a sequential energy amortization failure. As a result, scaling law breaking is unavoidable in practice. Our findings suggest that the industry's "smaller-is-better" heuristic is mathematically counterproductive for complex reasoning tasks.

</details>


### [192] [Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization](https://arxiv.org/abs/2602.13653)
*Yibo Wang,Guangda Huzhang,Yuwei Hu,Yu Xia,Shiyin Lu,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.AI

TL;DR: 提出一种新颖的MLLM框架，通过智能体Q值估计和分步策略优化，降低数据收集成本并实现稳定训练，使Ovis2.5-9B在GUI基准测试上超越更大规模模型


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体面临非平稳环境导致的数据筛选和策略优化计算成本过高问题，需要更高效的训练框架

Method: 双组件框架：(1)智能体Q值估计：优化Q模型生成评估动作贡献的分步价值；(2)分步策略优化：基于状态-动作轨迹样本，通过强化学习结合Q模型优化策略。所有轨迹由策略自身生成，且策略更新与环境解耦

Result: Ovis2.5-9B获得强大GUI交互能力，在导航和定位基准测试中表现优异，甚至超越更大规模竞品

Conclusion: 该框架有效解决了计算成本问题，实现了高效稳定的GUI智能体训练，证明小规模模型通过该方法可超越大规模模型

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have substantially driven the progress of autonomous agents for Graphical User Interface (GUI). Nevertheless, in real-world applications, GUI agents are often faced with non-stationary environments, leading to high computational costs for data curation and policy optimization. In this report, we introduce a novel MLLM-centered framework for GUI agents, which consists of two components: agentic-Q estimation and step-wise policy optimization. The former one aims to optimize a Q-model that can generate step-wise values to evaluate the contribution of a given action to task completion. The latter one takes step-wise samples from the state-action trajectory as inputs, and optimizes the policy via reinforcement learning with our agentic-Q model. It should be noticed that (i) all state-action trajectories are produced by the policy itself, so that the data collection costs are manageable; (ii) the policy update is decoupled from the environment, ensuring stable and efficient optimization. Empirical evaluations show that our framework endows Ovis2.5-9B with powerful GUI interaction capabilities, achieving remarkable performances on GUI navigation and grounding benchmarks and even surpassing contenders with larger scales.

</details>


### [193] [PhGPO: Pheromone-Guided Policy Optimization for Long-Horizon Tool Planning](https://arxiv.org/abs/2602.13691)
*Yu Li,Guangfeng Cai,Shengtian Yang,Han Luo,Shuo Han,Xu He,Dong Li,Lei Feng*

Main category: cs.AI

TL;DR: 提出Pheromone-Guided Policy Optimization (PhGPO)方法，通过从历史轨迹学习可重用的工具转移模式（信息素）来引导策略优化，解决LLM智能体在长时程多步工具规划中的组合爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 长时程多步工具规划面临组合爆炸挑战，当前方法将成功路径视为即时奖励，无法提取可复用的历史轨迹中的工具转移模式。

Method: 受蚁群优化算法启发，提出PhGPO：从历史轨迹中学习轨迹式转移模式（信息素），利用该信息素显式指导策略优化，引导智能体向历史成功的工具转移方向探索。

Result: 综合实验结果表明，PhGPO能有效提升LLM智能体的长时程工具规划能力。

Conclusion: 通过信息素机制复用历史成功轨迹中的转移模式，可为策略优化提供可重用的显式引导，是解决长时程工具规划问题的新有效途径。

Abstract: Recent advancements in Large Language Model (LLM) agents have demonstrated strong capabilities in executing complex tasks through tool use. However, long-horizon multi-step tool planning is challenging, because the exploration space suffers from a combinatorial explosion. In this scenario, even when a correct tool-use path is found, it is usually considered an immediate reward for current training, which would not provide any reusable information for subsequent training. In this paper, we argue that historically successful trajectories contain reusable tool-transition patterns, which can be leveraged throughout the whole training process. Inspired by ant colony optimization where historically successful paths can be reflected by the pheromone, we propose Pheromone-Guided Policy Optimization (PhGPO), which learns a trajectory-based transition pattern (i.e., pheromone) from historical trajectories and then uses the learned pheromone to guide policy optimization. This learned pheromone provides explicit and reusable guidance that steers policy optimization toward historically successful tool transitions, thereby improving long-horizon tool planning. Comprehensive experimental results demonstrate the effectiveness of our proposed PhGPO.

</details>


### [194] [Can a Lightweight Automated AI Pipeline Solve Research-Level Mathematical Problems?](https://arxiv.org/abs/2602.13695)
*Lve Meng,Weilong Zhao,Yanzhi Zhang,Haoxiang Guan,Jiyan He*

Main category: cs.AI

TL;DR: This paper demonstrates that next-generation LLMs (Gemini 3 Pro, GPT-5.2 Pro) integrated into a streamlined, citation-based verification pipeline can solve sophisticated research-grade mathematical problems, successfully generating and verifying proofs for novel problem sets including previously unpublished research questions.


<details>
  <summary>Details</summary>
Motivation: While LLMs have mastered competition-level math benchmarks and show research promise through auto-formalization, their deployment via lightweight, natural-language pipelines for actual research problems remains underexplored.

Method: Integrating next-generation language models into a streamlined automated pipeline optimized for citation-based verification to solve research-grade mathematical problems on two novel datasets: ICCM problem sets and previously unpublished "First Proof" questions.

Result: The pipeline generated candidate proofs for all problems in the first two ICCM sets and the "First Proof" set, with solutions for the first two ICCM sets and Problem 4 of "First Proof" fully verified by the team. All proofs were submitted to the official organization and results are publicly available.

Conclusion: The pipeline successfully solves sophisticated research-grade mathematical problems using LLMs, demonstrating strong potential for AI-assisted mathematical research. The complete methodology will be open-sourced in due course.

Abstract: Large language models (LLMs) have recently achieved remarkable success in generating rigorous mathematical proofs, with "AI for Math" emerging as a vibrant field of research. While these models have mastered competition-level benchmarks like the International Mathematical Olympiad and show promise in research applications through auto-formalization, their deployment via lightweight, natural-language pipelines for research problems remains underexplored. In this work, we demonstrate that next-generation models (e.g., Gemini 3 Pro, GPT-5.2 Pro), when integrated into a streamlined automated pipeline optimized for citation-based verification, can solve sophisticated research-grade problems. We evaluate our pipeline on two novel datasets: (1) the ICCM problem sets (comparable to the S.-T. Yau College Student Mathematics Contest) proposed by leading mathematicians, and (2) the "First Proof" problem set, consisting of previously unpublished research questions. Our pipeline generated candidate proofs for all problems in the first two ICCM sets and the "First Proof" set. The solutions for the first two ICCM sets and Problem 4 of the "First Proof" set have been fully verified by our team. All generated proofs have been submitted to the official organization, and our generated results are publicly available. We plan to open-source the complete pipeline methodology in due course.

</details>


### [195] [No Need to Train Your RDB Foundation Model](https://arxiv.org/abs/2602.13697)
*Linjie Xu,Yanlin Zhang,Quan Gan,Minjie Wang,David Wipf*

Main category: cs.AI

TL;DR: The paper proposes a training-free in-context learning (ICL) foundation model for relational databases that compresses variably-sized neighborhoods by restricting compression within columns (not across them), enabling seamless integration with existing single-table ICL models without retraining for each new prediction task.


<details>
  <summary>Details</summary>
Motivation: Relational databases contain vast heterogeneous tabular data for predictive modeling, but current approaches require costly retraining for each new target variable. Existing ICL foundation models are limited to single-table operations and cannot handle multiple interrelated tables efficiently.

Method: The paper introduces a principled family of RDB encoders that compress relational neighborhoods into fixed-length ICL samples by constraining compression *within* high-dimensional columns (where entities share units/roles) rather than *across* heterogeneous columns. This eliminates trainable parameters while preserving expressiveness, implemented via scalable SQL primitives.

Result: The method yields an open-source training-free RDB foundation model (RDBLearn) that integrates with existing single-table ICL models and demonstrates robust out-of-the-box performance on unseen datasets without fine-tuning.

Conclusion: ICL-specific compression constrained within columns provides an effective, principled approach for extending single-table foundation models to relational databases, eliminating retraining needs while maintaining strong predictive performance.

Abstract: Relational databases (RDBs) contain vast amounts of heterogeneous tabular information that can be exploited for predictive modeling purposes. But since the space of potential targets is vast across enterprise settings, how can we \textit{avoid retraining} a new model each time we wish to predict a new quantity of interest? Foundation models based on in-context learning (ICL) offer a convenient option, but so far are largely restricted to single-table operability. In generalizing to multiple interrelated tables, it is essential to compress variably-sized RDB neighborhoods into fixed-length ICL samples for consumption by the decoder. However, the details here are critical: unlike existing supervised learning RDB pipelines, we provide theoretical and empirical evidence that ICL-specific compression should be constrained \emph{within} high-dimensional RDB columns where all entities share units and roles, not \textit{across} columns where the relevance of heterogeneous data types cannot possibly be determined without label information. Conditioned on this restriction, we then demonstrate that encoder expressiveness is actually not compromised by excluding trainable parameters. Hence we arrive at a principled family of RDB encoders that can be seamlessly paired with already-existing single-table ICL foundation models, whereby no training or fine-tuning is required. From a practical standpoint, we develop scalable SQL primitives to implement the encoder stage, resulting in an easy-to-use open-source RDB foundation model\footnote{\label{foot: RDBLearn_learn} https://github.com/HKUSHXLab/rdblearn} capable of robust performance on unseen datasets out of the box.

</details>


### [196] [OneLatent: Single-Token Compression for Visual Latent Reasoning](https://arxiv.org/abs/2602.13738)
*Bo Lv,Yasheng Sun,Junjie Wang,Haoxiang Shi*

Main category: cs.AI

TL;DR: OneLatent框架通过将思维链推理压缩为单个潜在token，在仅损失2.21%准确率的情况下，实现11倍输出长度压缩和6.8倍输出token贡献度提升，在ProntoQA和ProsQA上分别达到99.80%和97.80%准确率。


<details>
  <summary>Details</summary>
Motivation: 思维链（CoT）提示虽能提升推理能力，但会使推理成本增加1-2个数量级。为解决这一效率问题，本文提出OneLatent框架，旨在将中间推理过程压缩为单个token以降低计算开销。

Method: 该方法将文本推理步骤渲染为图像，利用DeepSeek-OCR的隐藏状态提供确定性监督信号，将复杂中间推理压缩为单个潜在token，无需模型输出冗长文本即可实现可审计的监督。

Result: 在多项基准测试中，OneLatent平均输出长度减少11倍，准确率仅下降2.21%，输出token贡献度提升6.8倍；在长链逻辑推理中，单token实现ProntoQA 99.80%和ProsQA 97.80%准确率，最大压缩比达87.4倍。

Conclusion: OneLatent成功实现了思维链推理的高效压缩，在保持高准确率的同时大幅降低推理成本，证明了压缩约束下的泛化能力，为降低大模型推理开销提供了有效解决方案。

Abstract: Chain-of-thought (CoT) prompting improves reasoning but often increases inference cost by one to two orders of magnitude. To address these challenges, we present \textbf{OneLatent}, a framework that compresses intermediate reasoning into a single latent token via supervision from rendered CoT images and DeepSeek-OCR hidden states. By rendering textual steps into images, we obtain a deterministic supervision signal that can be inspected and audited without requiring the model to output verbose textual rationales. Across benchmarks, OneLatent reduces average output length by $11\times$ with only a $2.21\%$ average accuracy drop relative to textual CoT, while improving output token contribution (OTC) by $6.8\times$. On long-chain logical reasoning, OneLatent reaches $99.80\%$ on ProntoQA and $97.80\%$ on ProsQA with one latent token, with compression up to $87.4\times$, supporting compression-constrained generalization.

</details>


### [197] [OR-Agent: Bridging Evolutionary Search and Structured Research for Automated Algorithm Discovery](https://arxiv.org/abs/2602.13769)
*Qi Liu,Wanjing Ma*

Main category: cs.AI

TL;DR: OR-Agent是一个多智能体研究框架，通过树状工作流管理假设生成和回溯，结合进化系统性的构思机制与分层优化式反思系统，在组合优化和自动驾驶等实验环境中实现自动化科学发现。


<details>
  <summary>Details</summary>
Motivation: 复杂实验驱动领域的科学发现需要结构化假设管理、环境交互和原则性反思，而非简单的程序迭代变异。现有方法缺乏对研究轨迹的受控管理。

Method: 1) 树状结构化工作流：显式建模假设分支生成和系统回溯；2) 进化系统性构思机制：统一研究起点选择、计划生成和协调探索；3) 分层优化式反思系统：短期实验反思（类似梯度）、长期跨实验洞察（类似动量）、记忆压缩（类似权重衰减）。

Result: 在旅行商、车辆路径、装箱、定向、背包等组合优化问题及合作驾驶场景中，OR-Agent显著优于强进化基线，提供了通用、可扩展且可检查的AI辅助科学发现框架。

Conclusion: OR-Agent通过结构化工作流和反思机制实现了原则性研究动态管理，为自动化科学探索提供了有效且可解释的框架，代码和数据已公开。

Abstract: Automating scientific discovery in complex, experiment-driven domains requires more than iterative mutation of programs; it demands structured hypothesis management, environment interaction, and principled reflection. We present OR-Agent, a configurable multi-agent research framework designed for automated exploration in rich experimental environments. OR-Agent organizes research as a structured tree-based workflow that explicitly models branching hypothesis generation and systematic backtracking, enabling controlled management of research trajectories beyond simple mutation-crossover loops. At its core, we introduce an evolutionary-systematic ideation mechanism that unifies evolutionary selection of research starting points, comprehensive research plan generation, and coordinated exploration within a research tree. We further propose a hierarchical optimization-inspired reflection system: short-term experimental reflection operates as a form of verbal gradient providing immediate corrective signals; long-term reflection accumulates cross-experiment insights as verbal momentum; and memory compression serves as a regularization mechanism analogous to weight decay, preserving essential signals while mitigating drift. Together, these components form a principled architecture governing research dynamics. We conduct extensive experiments across classical combinatorial optimization benchmarks-including traveling salesman, capacitated vehicle routing, bin packing, orienteering, and multiple knapsack problems-as well as simulation-based cooperative driving scenarios. Results demonstrate that OR-Agent outperforms strong evolutionary baselines while providing a general, extensible, and inspectable framework for AI-assisted scientific discovery. OR-Agent source code and experiments data are publicly available at https://github.com/qiliuchn/OR-Agent.

</details>


### [198] [StackingNet: Collective Inference Across Independent AI Foundation Models](https://arxiv.org/abs/2602.13792)
*Siyang Li,Chenhao Liu,Dongrui Wu,Zhigang Zeng,Lieyun Ding*

Main category: cs.AI

TL;DR: 提出StackingNet元集成框架，无需模型内部参数或训练数据即可协调异构基础模型，通过集成推理提升准确性、鲁棒性和公平性


<details>
  <summary>Details</summary>
Motivation: 当前基础模型能力孤立无法共享，缺乏协调异构黑盒模型的方法，而集成互补优势对构建可信AI系统至关重要

Method: 采用集体智能原则构建StackingNet元集成框架，在推理阶段组合模型预测，无需访问内部参数或训练数据

Result: 在语言理解、视觉评估和学术评分任务中，相比单模型和传统集成方法，持续提升准确性、鲁棒性和公平性，并能识别剔除劣质模型

Conclusion: 将模型多样性转化为协作而非冲突，建立了协调AI的实践基础，表明多专用模型协同可能比单纯扩大单模型更具发展潜力

Abstract: Artificial intelligence built on large foundation models has transformed language understanding, vision and reasoning, yet these systems remain isolated and cannot readily share their capabilities. Integrating the complementary strengths of such independent foundation models is essential for building trustworthy intelligent systems. Despite rapid progress in individual model design, there is no established approach for coordinating such black-box heterogeneous models. Here we show that coordination can be achieved through a meta-ensemble framework termed StackingNet, which draws on principles of collective intelligence to combine model predictions during inference. StackingNet improves accuracy, reduces bias, enables reliability ranking, and identifies or prunes models that degrade performance, all operating without access to internal parameters or training data. Across tasks involving language comprehension, visual estimation, and academic paper rating, StackingNet consistently improves accuracy, robustness, and fairness, compared with individual models and classic ensembles. By turning diversity from a source of inconsistency into collaboration, StackingNet establishes a practical foundation for coordinated artificial intelligence, suggesting that progress may emerge from not only larger single models but also principled cooperation among many specialized ones.

</details>


### [199] [Attention in Constant Time: Vashista Sparse Attention for Long-Context Decoding with Exponential Guarantees](https://arxiv.org/abs/2602.13804)
*Vashista Nobaub*

Main category: cs.AI

TL;DR: 提出"面稳定性定理"证明稀疏注意力在长上下文中的可行性，设计Vashista稀疏注意力机制实现常数级计算开销，在保持模型质量的同时显著加速推理


<details>
  <summary>Details</summary>
Motivation: 大语言模型长上下文推理的主要成本在于注意力计算，但实证表明只有少量token对每个查询有实质贡献。需要理论保证稀疏解码的安全性和可控精度-计算权衡

Method: 1) 将注意力建模为关键向量的凸包投影，分析熵松弛特性 2) 提出面稳定性定理，证明在严格互补裕度下注意力会集中在常数大小的活动面上 3) 设计Vashista稀疏注意力机制，采用分页式上下文选择策略维护候选token集

Result: 1) 理论证明非活动token的注意力质量呈指数衰减(exp(-Ω(Δ/ε))) 2) 实际评估显示稳定的常数级有效支持集 3) 获得显著墙钟加速且质量退化极小 4) 在隐私敏感和隔离环境中实现可预测的延迟和成本

Conclusion: 该工作为稀疏长上下文解码提供了理论依据和实践方案，通过可证明的注意力稀疏性在保证模型质量的前提下大幅降低计算成本，特别适用于资源受限和隐私敏感场景

Abstract: Large language models spend most of their inference cost on attention over long contexts, yet empirical behavior suggests that only a small subset of tokens meaningfully contributes to each query. We formalize this phenomenon by modeling attention as a projection onto the convex hull of key vectors and analyzing its entropic (softmax-like) relaxation. Our main theoretical contribution is a face-stability theorem showing that, under a strict complementarity margin (a support gap (Δ) certified by KKT multipliers), entropic attention concentrates on a constant-size active face: the total mass assigned to inactive tokens decays exponentially as (\exp(-Ω(Δ/\varepsilon))), while the error on the active face scales linearly in the temperature/regularization parameter (\varepsilon). This yields a practical criterion for when sparse long-context decoding is safe and provides a principled knob to trade accuracy for compute.
  Building on these guarantees, we introduce Vashista Sparse Attention, a drop-in mechanism that maintains a small candidate set per query through a paging-style context selection strategy compatible with modern inference stacks. Across long-context evaluations, we observe stable constant-size effective support, strong wall-clock speedups, and minimal quality degradation in the regimes predicted by the support-gap diagnostics. Finally, we discuss deployment implications for privacy-sensitive and air-gapped settings, where interchangeable attention modules enable predictable latency and cost without external retrieval dependencies.

</details>


### [200] [Experimentation Accelerator: Interpretable Insights and Creative Recommendations for A/B Testing with Content-Aware ranking](https://arxiv.org/abs/2602.13852)
*Zhengmian Hu,Lei Shi,Ritwik Sinha,Justin Grover,David Arbour*

Main category: cs.AI

TL;DR: Adobe提出名为"Experimentation Accelerator"的统一框架，解决在线实验的两大瓶颈：流量稀缺和洞察提取低效。该框架利用历史实验数据与内容嵌入，通过CTR排序模型和稀疏Lasso实现变体优先级排序、获胜原因解释，并用大语言模型生成高潜力新创意，已在真实客户实验中验证效果。


<details>
  <summary>Details</summary>
Motivation: 现代在线实验面临流量稀缺导致测试选择困难，以及事后洞察提取依赖人工、不一致且忽视内容关联的问题。同时企业未充分利用历史A/B结果和丰富的内容嵌入信息来指导测试优先级和创意迭代。

Method: 1) 利用处理嵌入和历史结果训练带固定效应的CTR排序模型，平衡价值与内容多样性；2) 将处理投射到语义营销属性空间，通过符号一致稀疏约束Lasso获得可解释的属性和贡献；3) 计算结合属性重要性和当前实验不足表达的机会指数；4) 使用大语言模型将机会转化为具体创意建议并评估潜力。

Result: 该框架已集成到Adobe真实产品Experimentation Accelerator中，在Adobe商业客户的实际实验评估表明，生成管道具有高质量，能有效提供AI驱动的洞察和机会。

Conclusion: 提出的统一框架通过AI技术实现了实验流程的自动化和智能化，能够更快、更 informative 且更高效地推动实验循环，为规模化实验提供了可行解决方案。

Abstract: Modern online experimentation faces two bottlenecks: scarce traffic forces tough choices on which variants to test, and post-hoc insight extraction is manual, inconsistent, and often content-agnostic. Meanwhile, organizations underuse historical A/B results and rich content embeddings that could guide prioritization and creative iteration. We present a unified framework to (i) prioritize which variants to test, (ii) explain why winners win, and (iii) surface targeted opportunities for new, higher-potential variants. Leveraging treatment embeddings and historical outcomes, we train a CTR ranking model with fixed effects for contextual shifts that scores candidates while balancing value and content diversity. For better interpretability and understanding, we project treatments onto curated semantic marketing attributes and re-express the ranker in this space via a sign-consistent, sparse constrained Lasso, yielding per-attribute coefficients and signed contributions for visual explanations, top-k drivers, and natural-language insights. We then compute an opportunity index combining attribute importance (from the ranker) with under-expression in the current experiment to flag missing, high-impact attributes. Finally, LLMs translate ranked opportunities into concrete creative suggestions and estimate both learning and conversion potential, enabling faster, more informative, and more efficient test cycles. These components have been built into a real Adobe product, called \textit{Experimentation Accelerator}, to provide AI-based insights and opportunities to scale experimentation for customers. We provide an evaluation of the performance of the proposed framework on some real-world experiments by Adobe business customers that validate the high quality of the generation pipeline.

</details>


### [201] [Enabling Option Learning in Sparse Rewards with Hindsight Experience Replay](https://arxiv.org/abs/2602.13865)
*Gabriel Romio,Mateus Begnini Melchiades,Bruno Castro da Silva,Gabriel de Oliveira Ramos*

Main category: cs.AI

TL;DR: 针对多目标稀疏奖励环境下的分层强化学习难题，本文提出MOC-2HER方法，通过双目标事后经验回放机制同时奖励智能体对物体的交互和任务完成，在机器人操作环境中将成功率从不足11%提升至90%


<details>
  <summary>Details</summary>
Motivation: 现有分层强化学习框架(如MOC)在多目标稀疏奖励环境中表现不佳，特别是在需要关联长时间间隔动作与结果的任务中。更进一步，在物体操作任务中，由于奖励取决于物体到达目标而非智能体直接交互，导致智能体难以发现交互策略。

Method: 首先提出MOC-HER，将事后经验回放(HER)机制集成到MOC框架中，通过从已实现结果重新标记目标来利用稀疏奖励。随后提出2HER(双目标事后经验回放)，创建两组虚拟目标：一组基于物体最终状态(标准HER)，另一组基于智能体 effector 位置，同时奖励物体交互和任务完成。最终形成MOC-2HER方法。

Result: 在机器人操作环境中的实验表明，MOC-2HER的成功率高达90%，而MOC和MOC-HER的成功率均低于11%，显著提升了稀疏奖励多目标任务的性能。

Conclusion: 双目标重标记策略有效解决了稀疏奖励、多目标分层强化学习问题，特别是在需要智能体学习物体交互的场景中表现出色，为机器人操作任务提供了新的解决方案。

Abstract: Hierarchical Reinforcement Learning (HRL) frameworks like Option-Critic (OC) and Multi-updates Option Critic (MOC) have introduced significant advancements in learning reusable options. However, these methods underperform in multi-goal environments with sparse rewards, where actions must be linked to temporally distant outcomes. To address this limitation, we first propose MOC-HER, which integrates the Hindsight Experience Replay (HER) mechanism into the MOC framework. By relabeling goals from achieved outcomes, MOC-HER can solve sparse reward environments that are intractable for the original MOC. However, this approach is insufficient for object manipulation tasks, where the reward depends on the object reaching the goal rather than on the agent's direct interaction. This makes it extremely difficult for HRL agents to discover how to interact with these objects. To overcome this issue, we introduce Dual Objectives Hindsight Experience Replay (2HER), a novel extension that creates two sets of virtual goals. In addition to relabeling goals based on the object's final state (standard HER), 2HER also generates goals from the agent's effector positions, rewarding the agent for both interacting with the object and completing the task. Experimental results in robotic manipulation environments show that MOC-2HER achieves success rates of up to 90%, compared to less than 11% for both MOC and MOC-HER. These results highlight the effectiveness of our dual objective relabeling strategy in sparse reward, multi-goal tasks.

</details>


### [202] [Ambient Physics: Training Neural PDE Solvers with Partial Observations](https://arxiv.org/abs/2602.13873)
*Harris Abdul Majid,Giannis Daras,Francesco Tudisco,Steven McDonagh*

Main category: cs.AI

TL;DR: Ambient Physics框架通过随机掩码已观测数据点，使模型无法区分真实缺失与人为缺失数据，从而仅从部分观测中学习PDE系数-解对的联合分布，无需完整观测数据。


<details>
  <summary>Details</summary>
Motivation: 现有扩散方法需要完整观测进行训练，但科学实验中获取完整PDE系数和溶液观测数据成本高昂、危险或不可能，限制了其在真实场景的应用。

Method: 提出Ambient Physics框架：在训练时随机掩码部分已观测测量值，并对这些被掩码点进行监督，迫使模型对所有位置（包括真实未观测区域）生成合理预测。发现"单点转变"现象：掩码单个已观测点即可实现跨架构和测量模式的部分观测学习。

Result: 相比先前扩散方法，平均总体误差降低62.51%，函数评估次数减少125倍，达到最先进的重建性能。

Conclusion: Ambient Physics突破了完整观测数据的限制，使科学进步能够在无法获取完整观测的场景中实现，为PDE反问题求解提供了新范式。

Abstract: In many scientific settings, acquiring complete observations of PDE coefficients and solutions can be expensive, hazardous, or impossible. Recent diffusion-based methods can reconstruct fields given partial observations, but require complete observations for training. We introduce Ambient Physics, a framework for learning the joint distribution of coefficient-solution pairs directly from partial observations, without requiring a single complete observation. The key idea is to randomly mask a subset of already-observed measurements and supervise on them, so the model cannot distinguish "truly unobserved" from "artificially unobserved", and must produce plausible predictions everywhere. Ambient Physics achieves state-of-the-art reconstruction performance. Compared with prior diffusion-based methods, it achieves a 62.51$\%$ reduction in average overall error while using 125$\times$ fewer function evaluations. We also identify a "one-point transition": masking a single already-observed point enables learning from partial observations across architectures and measurement patterns. Ambient Physics thus enables scientific progress in settings where complete observations are unavailable.

</details>


### [203] [VSAL: A Vision Solver with Adaptive Layouts for Graph Property Detection](https://arxiv.org/abs/2602.13880)
*Jiahao Xie,Guangmo Tong*

Main category: cs.AI

TL;DR: 提出VSAL框架解决视觉图属性检测中固定布局限制问题，通过自适应布局生成器动态优化可视化提升检测精度


<details>
  <summary>Details</summary>
Motivation: 现有视觉化图属性检测方法依赖固定图布局，导致检测流程的表达能力受限，无法为不同图实例生成最适配的可视化表征

Method: 设计VSAL框架，核心是引入自适应布局生成器，能根据图实例特性动态产生信息丰富的可视化图像，提升后续属性检测模型性能

Result: 在哈密顿环、平面性、无爪性及树检测等多项图属性任务中，VSAL显著超越当前最优视觉化方法

Conclusion: 自适应布局生成机制能有效增强视觉化图属性检测的表达能力，为复杂图结构分析提供新思路

Abstract: Graph property detection aims to determine whether a graph exhibits certain structural properties, such as being Hamiltonian. Recently, learning-based approaches have shown great promise by leveraging data-driven models to detect graph properties efficiently. In particular, vision-based methods offer a visually intuitive solution by processing the visualizations of graphs. However, existing vision-based methods rely on fixed visual graph layouts, and therefore, the expressiveness of their pipeline is restricted. To overcome this limitation, we propose VSAL, a vision-based framework that incorporates an adaptive layout generator capable of dynamically producing informative graph visualizations tailored to individual instances, thereby improving graph property detection. Extensive experiments demonstrate that VSAL outperforms state-of-the-art vision-based methods on various tasks such as Hamiltonian cycle, planarity, claw-freeness, and tree detection.

</details>


### [204] [Diagnosing Pathological Chain-of-Thought in Reasoning Models](https://arxiv.org/abs/2602.13904)
*Manqing Liu,David Williams-King,Ida Caspary,Linh Le,Hannes Whittingham,Puria Radmard,Cameron Tice,Edward James Young*

Main category: cs.AI

TL;DR: This paper identifies three CoT reasoning pathologies in LLMs (post-hoc rationalization, encoded reasoning, internalized reasoning), develops simple task-agnostic metrics to detect them, validates using custom-trained model organisms, and provides a practical toolkit for AI safety training-time monitoring.


<details>
  <summary>Details</summary>
Motivation: Chain-of-thought reasoning is fundamental to LLM architectures and AI safety, but its failure modes (post-hoc rationalization, encoded reasoning, internalized reasoning) prevent effective monitoring and compromise interpretability.

Method: Create concrete, computationally inexpensive, task-agnostic metrics; develop model organisms deliberately trained to exhibit specific CoT pathologies to validate the approach.

Result: A practical toolkit for assessing CoT pathologies in LLMs.

Conclusion: The toolkit has direct implications for training-time monitoring in AI safety, enabling better detection of reasoning failures.

Abstract: Chain-of-thought (CoT) reasoning is fundamental to modern LLM architectures and represents a critical intervention point for AI safety. However, CoT reasoning may exhibit failure modes that we note as pathologies, which prevent it from being useful for monitoring. Prior work has identified three distinct pathologies: post-hoc rationalization, where models generate plausible explanations backwards from predetermined answers; encoded reasoning, where intermediate steps conceal information within seemingly interpretable text; and internalized reasoning, where models replace explicit reasoning with meaningless filler tokens while computing internally. To better understand and discriminate between these pathologies, we create a set of concrete metrics that are simple to implement, computationally inexpensive, and task-agnostic. To validate our approach, we develop model organisms deliberately trained to exhibit specific CoT pathologies. Our work provides a practical toolkit for assessing CoT pathologies, with direct implications for training-time monitoring.

</details>


### [205] [From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design](https://arxiv.org/abs/2602.13912)
*Sha Li,Stefano Petrangeli,Yu Shen,Xiang Chen*

Main category: cs.AI

TL;DR: LaySPA is a reinforcement learning framework that enhances LLMs' spatial reasoning for graphic layout design by using a structured textual environment, producing interpretable outputs, and achieving performance comparable to SOTA methods with less data and latency.


<details>
  <summary>Details</summary>
Motivation: LLMs have limited spatial reasoning capabilities and their design decision-making process lacks transparency, making it difficult to create content-aware graphic layouts with interpretable and controllable results.

Method: The framework reformulates layout design as a policy learning problem over a structured textual spatial environment encoding canvas geometry and element relationships. It employs a multi-objective spatial critique (geometric validity, relational coherence, aesthetic consistency) and uses relative group optimization for training. It produces dual-level outputs: interpretable reasoning traces and structured layout specifications.

Result: Experiments show LaySPA improves structural validity and visual quality, outperforms larger proprietary LLMs, achieves performance comparable to specialized state-of-the-art layout generators, while requiring fewer annotated samples and reduced latency.

Conclusion: LaySPA successfully addresses LLM spatial reasoning limitations and opacity in design decisions, enabling transparent, controllable, and efficient graphic layout generation with competitive performance.

Abstract: We introduce LaySPA, a reinforcement learning framework that equips large language models (LLMs) with explicit and interpretable spatial reasoning for content-aware graphic layout design. LaySPA addresses two key challenges: LLMs' limited spatial reasoning and the lack of opacity in design decision making. Instead of operating at the pixel level, we reformulate layout design as a policy learning problem over a structured textual spatial environment that explicitly encodes canvas geometry, element attributes, and inter-element relationships. LaySPA produces dual-level outputs comprising interpretable reasoning traces and structured layout specifications, enabling transparent and controllable design decision making. Layout design policy is optimized via a multi-objective spatial critique that decomposes layout quality into geometric validity, relational coherence, and aesthetic consistency, and is trained using relative group optimization to stabilize learning in open-ended design spaces. Experiments demonstrate that LaySPA improves structural validity and visual quality, outperforming larger proprietary LLMs and achieving performance comparable to specialized SOTA layout generators while requiring fewer annotated samples and reduced latency.

</details>


### [206] [HyMem: Hybrid Memory Architecture with Dynamic Retrieval Scheduling](https://arxiv.org/abs/2602.13933)
*Xiaochen Zhao,Kaikai Wang,Xiaowen Zhang,Chen Yao,Aili Wang*

Main category: cs.AI

TL;DR: HyMem is a hybrid memory architecture for LLM agents that uses dual-granular storage and dynamic two-tier retrieval to reduce computational cost by 92.6% while maintaining strong performance on long-dialogue benchmarks.


<details>
  <summary>Details</summary>
Motivation: LLM agents struggle with extended dialogues due to inefficient memory management, facing a fundamental trade-off between compression (losing critical details) and raw text (computational overhead), caused by inflexible monolithic memory representations that can't adapt like human memory.

Method: Proposes HyMem, a hybrid architecture inspired by cognitive economy, featuring dual-granular storage paired with a dynamic two-tier retrieval system: a lightweight module for summary-level context efficiency and a selective LLM-based deep module for complex queries, augmented by a reflection mechanism for iterative reasoning refinement.

Result: Achieves strong performance on LOCOMO and LongMemEval benchmarks, outperforms full-context approaches while reducing computational cost by 92.6%, establishing a state-of-the-art balance between efficiency and performance in long-term memory management.

Conclusion: HyMem successfully resolves the efficiency-effectiveness trade-off through dynamic on-demand scheduling and multi-granular memory representations, enabling LLM agents to handle extended dialogues with human-like flexible memory management.

Abstract: Large language model (LLM) agents demonstrate strong performance in short-text contexts but often underperform in extended dialogues due to inefficient memory management. Existing approaches face a fundamental trade-off between efficiency and effectiveness: memory compression risks losing critical details required for complex reasoning, while retaining raw text introduces unnecessary computational overhead for simple queries. The crux lies in the limitations of monolithic memory representations and static retrieval mechanisms, which fail to emulate the flexible and proactive memory scheduling capabilities observed in humans, thus struggling to adapt to diverse problem scenarios. Inspired by the principle of cognitive economy, we propose HyMem, a hybrid memory architecture that enables dynamic on-demand scheduling through multi-granular memory representations. HyMem adopts a dual-granular storage scheme paired with a dynamic two-tier retrieval system: a lightweight module constructs summary-level context for efficient response generation, while an LLM-based deep module is selectively activated only for complex queries, augmented by a reflection mechanism for iterative reasoning refinement. Experiments show that HyMem achieves strong performance on both the LOCOMO and LongMemEval benchmarks, outperforming full-context while reducing computational cost by 92.6\%, establishing a state-of-the-art balance between efficiency and performance in long-term memory management.

</details>


### [207] [Statistical Early Stopping for Reasoning Models](https://arxiv.org/abs/2602.13935)
*Yangxinyu Xie,Tao Wang,Soham Mallick,Yan Sun,Georgy Noarov,Mengxin Yu,Tanwi Mallick,Weijie J. Su,Edgar Dobriban*

Main category: cs.AI

TL;DR: 提出基于统计原理的早期停止方法，通过监控生成过程中的不确定性信号来减少大语言模型的过度思考问题，提升推理效率和可靠性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理时可能对模糊查询产生不必要推理步骤（过度思考），影响效率和可靠性

Method: 提出参数化方法（将不确定性关键词到达时间建模为更新过程并应用序贯检验）和非参数化方法（对正常查询过早停止概率提供有限样本保证）

Result: 在多个领域和模型的推理任务中验证有效，数学推理任务提升尤其显著

Conclusion: 不确定性感知的早期停止可同时提升大语言模型推理的效率和可靠性

Abstract: While LLMs have seen substantial improvement in reasoning capabilities, they also sometimes overthink, generating unnecessary reasoning steps, particularly under uncertainty, given ill-posed or ambiguous queries. We introduce statistically principled early stopping methods that monitor uncertainty signals during generation to mitigate this issue. Our first approach is parametric: it models inter-arrival times of uncertainty keywords as a renewal process and applies sequential testing for stopping. Our second approach is nonparametric and provides finite-sample guarantees on the probability of halting too early on well-posed queries. We conduct empirical evaluations on reasoning tasks across several domains and models. Our results indicate that uncertainty-aware early stopping can improve both efficiency and reliability in LLM reasoning, and we observe especially significant gains for math reasoning.

</details>


### [208] [A Generalizable Physics-guided Causal Model for Trajectory Prediction in Autonomous Driving](https://arxiv.org/abs/2602.13936)
*Zhenyu Zong,Yuchen Wang,Haohong Lin,Lu Gan,Huajie Shao*

Main category: cs.AI

TL;DR: 提出物理引导因果模型(PCM)，通过解耦编码器和因果ODE解码器实现交通轨迹预测的零样本泛化，在未见城市表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶轨迹预测需泛化到未见领域，现有方法零样本泛化能力不足，需利用领域不变的运动学知识。

Method: PCM模型含解耦场景编码器(干预式解耦提取不变特征)和因果ODE解码器(因果注意力融合运动学与上下文)。

Result: 真实数据集实验显示，该方法在未见城市零样本泛化性能显著超越基线。

Conclusion: 结合物理先验与因果建模为轨迹预测泛化提供有效方案，代码开源。

Abstract: Trajectory prediction for traffic agents is critical for safe autonomous driving. However, achieving effective zero-shot generalization in previously unseen domains remains a significant challenge. Motivated by the consistent nature of kinematics across diverse domains, we aim to incorporate domain-invariant knowledge to enhance zero-shot trajectory prediction capabilities. The key challenges include: 1) effectively extracting domain-invariant scene representations, and 2) integrating invariant features with kinematic models to enable generalized predictions. To address these challenges, we propose a novel generalizable Physics-guided Causal Model (PCM), which comprises two core components: a Disentangled Scene Encoder, which adopts intervention-based disentanglement to extract domain-invariant features from scenes, and a CausalODE Decoder, which employs a causal attention mechanism to effectively integrate kinematic models with meaningful contextual information. Extensive experiments on real-world autonomous driving datasets demonstrate our method's superior zero-shot generalization performance in unseen cities, significantly outperforming competitive baselines. The source code is released at https://github.com/ZY-Zong/Physics-guided-Causal-Model.

</details>


### [209] [Neuromem: A Granular Decomposition of the Streaming Lifecycle in External Memory for LLMs](https://arxiv.org/abs/2602.13967)
*Ruicheng Zhang,Xinyi Li,Tianyi Xu,Shuhao Zhang,Xiaofei Liao,Hai Jin*

Main category: cs.AI

TL;DR: 现有外部记忆模块评估假设静态环境，但实际应用需处理持续流式数据。本文提出Neuromem测试平台，通过五维生命周期分析揭示：记忆增长导致性能下降，时间查询最难，数据结构是性能关键，压缩和集成策略仅转移成本难提升精度。


<details>
  <summary>Details</summary>
Motivation: 当前外部记忆模块评估假设离线构建静态记忆，而实际应用场景中存在新事实持续流入、插入与检索交错进行的流式处理需求，需评估完整记忆生命周期（摄入、维护、检索、生成集成）对精度与成本的影响。

Method: 提出Neuromem可扩展测试平台，采用交错插入-检索协议，将记忆生命周期分解为数据结构、归一化策略、整合策略、查询 formulation 策略和上下文集成机制五个维度，在LOCOMO/LONGMEMEVAL/MEMORYAGENTBENCH数据集上评估共享服务栈的变体，使用token-level F1和插入/检索延迟作为指标。

Result: 实验发现：1) 记忆轮次增加时性能普遍下降；2) 时间相关查询是最具挑战性的类别；3) 记忆数据结构主要决定质量上限；4) 激进压缩和生成式集成机制主要在插入与检索间转移成本，对精度提升有限。

Conclusion: 流式记忆场景下需重新设计外部记忆模块，应优先优化记忆数据结构而非依赖压缩或复杂集成策略，Neuromem为相关研究提供了标准化评估框架。

Abstract: Most evaluations of External Memory Module assume a static setting: memory is built offline and queried at a fixed state. In practice, memory is streaming: new facts arrive continuously, insertions interleave with retrievals, and the memory state evolves while the model is serving queries. In this regime, accuracy and cost are governed by the full memory lifecycle, which encompasses the ingestion, maintenance, retrieval, and integration of information into generation. We present Neuromem, a scalable testbed that benchmarks External Memory Modules under an interleaved insertion-and-retrieval protocol and decomposes its lifecycle into five dimensions including memory data structure, normalization strategy, consolidation policy, query formulation strategy, and context integration mechanism. Using three representative datasets LOCOMO, LONGMEMEVAL, and MEMORYAGENTBENCH, Neuromem evaluates interchangeable variants within a shared serving stack, reporting token-level F1 and insertion/retrieval latency. Overall, we observe that performance typically degrades as memory grows across rounds, and time-related queries remain the most challenging category. The memory data structure largely determines the attainable quality frontier, while aggressive compression and generative integration mechanisms mostly shift cost between insertion and retrieval with limited accuracy gain.

</details>


### [210] [Cognitive Chunking for Soft Prompts: Accelerating Compressor Learning via Block-wise Causal Masking](https://arxiv.org/abs/2602.13980)
*Guojie Liu,Yiqi Wang,Yanfeng Yang,Wenqi Fan,Songlei Jian,Jianfeng Zhang,Jie Yu*

Main category: cs.AI

TL;DR: The paper proposes PIC (Parallelized Iterative Compression), a novel context compression method for LLMs that restricts memory tokens to local chunks via modified attention masks, significantly improving performance and training efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing context compression methods for LLMs require compressing entire contexts indiscriminately, forcing compressors to learn global dependencies and needing extensive pre-training data, making training difficult and inefficient.

Method: Inspired by human working memory chunking, PIC modifies the Transformer attention mask to restrict each memory token's receptive field to sequential local chunks rather than the full context, simplifying the compression task.

Result: PIC outperforms competitive baselines across multiple tasks, with particularly strong gains in high compression scenarios (29.8% relative F1 and 40.7% relative EM improvement at 64x compression) and reduces training time by ~40% for 16x compression.

Conclusion: PIC provides a highly effective and efficient solution for context compression by leveraging localized attention patterns, demonstrating superiority especially under extreme compression ratios and significantly accelerating training.

Abstract: Providing extensive context via prompting is vital for leveraging the capabilities of Large Language Models (LLMs). However, lengthy contexts significantly increase inference latency, as the computational cost of self-attention grows quadratically with sequence length. To mitigate this issue, context compression-particularly soft prompt compressio-has emerged as a widely studied solution, which converts long contexts into shorter memory embeddings via a trained compressor. Existing methods typically compress the entire context indiscriminately into a set of memory tokens, requiring the compressor to capture global dependencies and necessitating extensive pre-training data to learn effective patterns. Inspired by the chunking mechanism in human working memory and empirical observations of the spatial specialization of memory embeddings relative to original tokens, we propose Parallelized Iterative Compression (PIC). By simply modifying the Transformer's attention mask, PIC explicitly restricts the receptive field of memory tokens to sequential local chunks, thereby lowering the difficulty of compressor training. Experiments across multiple downstream tasks demonstrate that PIC consistently outperforms competitive baselines, with superiority being particularly pronounced in high compression scenarios (e.g., achieving relative improvements of 29.8\% in F1 score and 40.7\% in EM score on QA tasks at the $64\times$ compression ratio). Furthermore, PIC significantly expedites the training process. Specifically, when training the 16$\times$ compressor, it surpasses the peak performance of the competitive baseline while effectively reducing the training time by approximately 40\%.

</details>


### [211] [Bridging AI and Clinical Reasoning: Abductive Explanations for Alignment on Critical Symptoms](https://arxiv.org/abs/2602.13985)
*Belona Sonna,Alban Grastien*

Main category: cs.AI

TL;DR: 该论文提出使用形式化溯因解释来解决临床诊断AI的可解释性和可信度问题，在保持预测准确性的同时提供符合临床推理的决策依据。


<details>
  <summary>Details</summary>
Motivation: AI在临床诊断中准确率高，但推理过程缺乏结构化临床框架，关键症状可能被忽视，现有解释方法透明度不足且缺乏形式化保证，限制了医生信任和实际应用。

Method: 采用形式化溯因解释方法，提供对最小充分特征集的一致性、可保证推理，使AI决策过程清晰且能与临床推理对齐。

Result: 在保持预测准确性的前提下，生成具有临床可操作性的解释，增强AI诊断的透明度和可信度。

Conclusion: 建立了可信赖医疗诊断AI的稳健框架，促进了AI与临床实践的融合。

Abstract: Artificial intelligence (AI) has demonstrated strong potential in clinical diagnostics, often achieving accuracy comparable to or exceeding that of human experts. A key challenge, however, is that AI reasoning frequently diverges from structured clinical frameworks, limiting trust, interpretability, and adoption. Critical symptoms, pivotal for rapid and accurate decision-making, may be overlooked by AI models even when predictions are correct. Existing post hoc explanation methods provide limited transparency and lack formal guarantees. To address this, we leverage formal abductive explanations, which offer consistent, guaranteed reasoning over minimal sufficient feature sets. This enables a clear understanding of AI decision-making and allows alignment with clinical reasoning. Our approach preserves predictive accuracy while providing clinically actionable insights, establishing a robust framework for trustworthy AI in medical diagnosis.

</details>


### [212] [FloCA: Towards Faithful and Logically Consistent Flowchart Reasoning](https://arxiv.org/abs/2602.14035)
*Jinzi Zou,Bolin Wang,Liang Li,Shuo Zhang,Nuo Xu,Junzhou Zhao*

Main category: cs.AI

TL;DR: 提出FloCA零样本流程图对话系统，通过外部工具执行拓扑约束图推理解决LLM缺乏流程图结构表示和易幻觉问题，在FLODIAL和PFDial数据集上验证优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有LLM在流程图导向对话中面临两大局限：1)缺乏显式流程图拓扑结构表示和推理机制；2)易产生幻觉导致不忠实的节点跳转。这些限制影响了多轮决策任务的准确性和逻辑一致性。

Method: 提出FloCA架构，采用分离式设计：LLM负责意图理解和响应生成，外部工具执行流程图拓扑约束的图推理，确保跨对话轮次的忠实且逻辑一致的节点转移。同时引入包含LLM用户模拟器和五个新指标的评估框架。

Result: 在FLODIAL和PFDial数据集上的大量实验表明，现有LLM方法存在明显瓶颈，而FloCA在推理准确性和交互效率方面均展现出优越性能。

Conclusion: 通过将流程图推理任务从LLM解耦到专用外部工具，FloCA为流程图导向对话提供了更可靠、零样本的解决方案，为任务型对话系统提供了新思路。

Abstract: Flowchart-oriented dialogue (FOD) systems aim to guide users through multi-turn decision-making or operational procedures by following a domain-specific flowchart to achieve a task goal. In this work, we formalize flowchart reasoning in FOD as grounding user input to flowchart nodes at each dialogue turn while ensuring node transition is consistent with the correct flowchart path. Despite recent advances of LLMs in task-oriented dialogue systems, adapting them to FOD still faces two limitations: (1) LLMs lack an explicit mechanism to represent and reason over flowchart topology, and (2) they are prone to hallucinations, leading to unfaithful flowchart reasoning. To address these limitations, we propose FloCA, a zero-shot flowchart-oriented conversational agent. FloCA uses an LLM for intent understanding and response generation while delegating flowchart reasoning to an external tool that performs topology-constrained graph execution, ensuring faithful and logically consistent node transitions across dialogue turns. We further introduce an evaluation framework with an LLM-based user simulator and five new metrics covering reasoning accuracy and interaction efficiency. Extensive experiments on FLODIAL and PFDial datasets highlight the bottlenecks of existing LLM-based methods and demonstrate the superiority of FloCA. Our codes are available at https://github.com/Jinzi-Zou/FloCA-flowchart-reasoning.

</details>


### [213] [Choosing How to Remember: Adaptive Memory Structures for LLM Agents](https://arxiv.org/abs/2602.14038)
*Mingfei Lu,Mengjia Wu,Feng Liu,Jiawei Xu,Weikai Li,Haoyang Wang,Zhengdong Hu,Ying Ding,Yizhou Sun,Jie Lu,Yi Zhang*

Main category: cs.AI

TL;DR: 提出FluxMem框架，通过多记忆结构自适应选择与概率融合机制，解决LLM智能体长程交互中的记忆僵化问题，在两项基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体记忆系统采用固定结构，无法根据交互场景动态调整，导致异构任务下记忆效率低下且性能次优。

Method: 1) 构建多互补记忆结构 2) 基于响应质量与记忆利用率离线监督学习结构选择策略 3) 设计三级记忆层级与Beta混合模型概率门控实现分布感知的记忆融合。

Result: 在PERSONAMEM和LoCoMo长程基准测试中，平均性能提升9.18%和6.14%。

Conclusion: 通过上下文感知的自适应记忆组织机制，有效解决了长程交互中记忆结构的动态优化问题，为智能体记忆设计提供新范式。

Abstract: Memory is critical for enabling large language model (LLM) based agents to maintain coherent behavior over long-horizon interactions. However, existing agent memory systems suffer from two key gaps: they rely on a one-size-fits-all memory structure and do not model memory structure selection as a context-adaptive decision, limiting their ability to handle heterogeneous interaction patterns and resulting in suboptimal performance. We propose a unified framework, FluxMem, that enables adaptive memory organization for LLM agents. Our framework equips agents with multiple complementary memory structures. It explicitly learns to select among these structures based on interaction-level features, using offline supervision derived from downstream response quality and memory utilization. To support robust long-horizon memory evolution, we further introduce a three-level memory hierarchy and a Beta Mixture Model-based probabilistic gate for distribution-aware memory fusion, replacing brittle similarity thresholds. Experiments on two long-horizon benchmarks, PERSONAMEM and LoCoMo, demonstrate that our method achieves average improvements of 9.18% and 6.14%.

</details>


### [214] [REAL: Resolving Knowledge Conflicts in Knowledge-Intensive Visual Question Answering via Reasoning-Pivot Alignment](https://arxiv.org/abs/2602.14065)
*Kai Ye,Xianwei Mao,Sheng Zhou,Zirui Shao,Ye Mo,Liangliang Liu,Haikuan Huang,Bin Li,Jiajun Bu*

Main category: cs.AI

TL;DR: 针对知识密集型视觉问答的知识冲突问题，提出REAL框架，引入推理枢纽概念，结合RPA-SFT和RPGD方法，在REAL-VQA数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: KI-VQA因开放域检索固有局限存在严重知识冲突，现有方法缺乏可扩展的冲突检测和模型内约束机制。

Method: 提出REAL框架，定义推理枢纽为推理链中强调知识关联的原子单元；构建REAL-VQA数据集；集成RPA-SFT训练通用判别器，并采用RPGD模型内解码策略进行针对性冲突缓解。

Result: 跨多基准实验显示，REAL显著提升判别准确率并达到最先进的性能。

Conclusion: 验证了基于推理枢纽的冲突解决范式的有效性。

Abstract: Knowledge-intensive Visual Question Answering (KI-VQA) frequently suffers from severe knowledge conflicts caused by the inherent limitations of open-domain retrieval. However, existing paradigms face critical limitations due to the lack of generalizable conflict detection and intra-model constraint mechanisms to handle conflicting evidence. To address these challenges, we propose the REAL (Reasoning-Pivot Alignment) framework centered on the novel concept of the Reasoning-Pivot. Distinct from reasoning steps that prioritize internal self-derivation, a reasoning-pivot serves as an atomic unit (node or edge) in the reasoning chain that emphasizes knowledge linkage, and it typically relies on external evidence to complete the reasoning. Supported by our constructed REAL-VQA dataset, our approach integrates Reasoning-Pivot Aware SFT (RPA-SFT) to train a generalizable discriminator by aligning conflicts with pivot extraction, and employs Reasoning-Pivot Guided Decoding (RPGD), an intra-model decoding strategy that leverages these pivots for targeted conflict mitigation. Extensive experiments across diverse benchmarks demonstrate that REAL significantly enhances discrimination accuracy and achieves state-of-the-art performance, validating the effectiveness of our pivot-driven resolution paradigm.

</details>


### [215] [Plan-MCTS: Plan Exploration for Action Exploitation in Web Navigation](https://arxiv.org/abs/2602.14083)
*Weiming Zhang,Jihong Wang,Jiamu Zhou,Qingyao Li,Xinbei Ma,Congmin Zheng,Xingyu Lou,Weiwen Liu,Zhuosheng Zhang,Jun Wang,Yong Yu,Weinan Zhang*

Main category: cs.AI

TL;DR: Plan-MCTS框架通过将探索空间从动作空间转移到语义计划空间，解决了网页导航中路径稀疏和上下文噪声的问题，在WebArena上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有树搜索方法在网页导航中面临两个关键挑战：导致探索效率低下的稀疏有效路径，以及稀释准确状态感知的噪声上下文，需要提升LLM智能体的导航效率和鲁棒性。

Method: 提出Plan-MCTS框架，将战略规划与执行解耦：1)构建密集计划树实现高效探索；2)提炼抽象语义历史增强状态感知；3)引入双重门控奖励验证可执行性和战略一致性；4)采用结构精修机制实时修复失败子计划。

Result: 在WebArena基准测试中实现最先进的性能，相比现有方法在任务完成效果和搜索效率方面均有显著提升。

Conclusion: 通过语义空间重构和多重优化机制，Plan-MCTS有效解决了稀疏动作空间和噪声上下文问题，为LLM驱动的网页导航提供了高效鲁棒的解决方案。

Abstract: Large Language Models (LLMs) have empowered autonomous agents to handle complex web navigation tasks. While recent studies integrate tree search to enhance long-horizon reasoning, applying these algorithms in web navigation faces two critical challenges: sparse valid paths that lead to inefficient exploration, and a noisy context that dilutes accurate state perception. To address this, we introduce Plan-MCTS, a framework that reformulates web navigation by shifting exploration to a semantic Plan Space. By decoupling strategic planning from execution grounding, it transforms sparse action space into a Dense Plan Tree for efficient exploration, and distills noisy contexts into an Abstracted Semantic History for precise state awareness. To ensure efficiency and robustness, Plan-MCTS incorporates a Dual-Gating Reward to strictly validate both physical executability and strategic alignment and Structural Refinement for on-policy repair of failed subplans. Extensive experiments on WebArena demonstrate that Plan-MCTS achieves state-of-the-art performance, surpassing current approaches with higher task effectiveness and search efficiency.

</details>


### [216] [NEST: Nascent Encoded Steganographic Thoughts](https://arxiv.org/abs/2602.14095)
*Artem Karpov*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型在思维链(CoT)推理中隐藏真实推理过程的能力（隐写式CoT），评估了28个模型在逃避监控方面的表现，发现当前模型尚无法在复杂数学任务中持续隐藏推理，但Claude Opus 4.5在简单计数任务中达到了92%的隐藏准确率，揭示了新兴的隐蔽推理风险。


<details>
  <summary>Details</summary>
Motivation: 监控思维链推理是LLM智能体安全的基础技术，但如果模型学会隐藏真实推理过程，这种监控就会失效。研究隐写式CoT旨在评估相关风险，为模型部署政策提供依据，防止模型出现欺骗性或未对齐的阴谋行为。

Method: 系统性地评估了28个不同代际的模型，在四个数据集上测量了监控逃避率、拒绝率、编码保真度和隐藏任务准确率，并将隐写式首字密码与明文推理和填充标记基线进行对比。

Result: 当前模型尚无法在复杂数学和算术任务中维持隐藏推理。但在简化计数实验中，Claude Opus 4.5实现了92%的隐藏任务准确率。罕见情况下（<1%），GPT-5.2可能在拒绝隐写指令的同时仍在执行这些指令。

Conclusion: 研究强调了对隐写风险进行持续评估的必要性，提供了一种预先检测和防止隐藏推理的方法论，有助于防范潜在的对齐失调和欺骗行为。

Abstract: Monitoring chain-of-thought (CoT) reasoning is a foundational safety technique for large language model (LLM) agents; however, this oversight is compromised if models learn to conceal their reasoning. We explore the potential for steganographic CoT -- where models hide secret reasoning within innocuous text -- to inform risk assessment and deployment policies. We systematically evaluate the limits of steganographic capabilities across 28 models, ranging from past generations to the current frontier. We measure monitor evasion, refusal rates, encoding fidelity, and hidden task accuracy across four datasets, comparing steganographic acrostics against plain reasoning and filler-token baselines. We find that current models cannot yet sustain hidden reasoning for complex math and arithmetic tasks. However, in a simplified counting experiment, Claude Opus 4.5 achieved 92% accuracy on the hidden task, demonstrating nascent capability. Notably, in rare cases (<1%), GPT-5.2 might refuse steganographic instructions while simultaneously complying with them. Our findings underscore the need for continuous evaluation of steganographic risks. This study provides a methodology to preemptively detect and prevent hidden reasoning that might empower misaligned scheming and deceptive behavior.

</details>


### [217] [Algebraic Quantum Intelligence: A New Framework for Reproducible Machine Creativity](https://arxiv.org/abs/2602.14130)
*Kazuo Yano,Jonghyeok Lee,Tae Ishitomi,Hironobu Kawaguchi,Akira Koyama,Masakuni Ota,Yuki Ota,Nobuo Sato,Keita Shimada,Sho Takematsu,Ayaka Tobinai,Satomi Tsuji,Kazunori Yanagi,Keiko Yano,Manabu Harada,Yuki Matsuda,Kazunori Matsumoto,Kenichi Matsumura,Hamae Matsuo,Yumi Miyazaki,Kotaro Murai,Tatsuya Ohshita,Marie Seki,Shun Tanoue,Tatsuki Terakado,Yuko Ichimaru,Mirei Saito,Akihiro Otsuka,Koji Ara*

Main category: cs.AI

TL;DR: This paper introduces Algebraic Quantum Intelligence (AQI), a quantum-inspired noncommutative algebraic framework that expands the semantic space of LLMs by representing semantic states as vectors in Hilbert space and evolving them via noncommutative operators. By adding 600+ specialized operators to a transformer, AQI achieves statistically significant improvements in creative reasoning across ten domains, reducing cross-domain variance and demonstrating a practical foundation for machine creativity.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) struggle with genuine creativity due to structural constraints that make generation near-deterministic when given rich context. Existing methods like test-time scaling fail to fundamentally address this limitation.

Method: Proposes Algebraic Quantum Intelligence (AQI), a noncommutative algebraic structure inspired by quantum theory. Semantic states are represented as vectors in a Hilbert space and evolve via C-values computed from noncommutative operators, enabling order dependence, interference, and uncertainty. Implemented by extending a transformer-based LLM with over 600 specialized operators.

Result: AQI consistently outperforms strong baselines on creative reasoning benchmarks across ten domains, delivering statistically significant improvements and reduced cross-domain variance when evaluated using an LLM-as-a-judge protocol.

Conclusion: Noncommutative algebraic dynamics provides a practical and reproducible foundation for machine creativity, with the architecture already deployed in real-world enterprise environments.

Abstract: Large language models (LLMs) have achieved remarkable success in generating fluent and contextually appropriate text; however, their capacity to produce genuinely creative outputs remains limited. This paper posits that this limitation arises from a structural property of contemporary LLMs: when provided with rich context, the space of future generations becomes strongly constrained, and the generation process is effectively governed by near-deterministic dynamics. Recent approaches such as test-time scaling and context adaptation improve performance but do not fundamentally alter this constraint. To address this issue, we propose Algebraic Quantum Intelligence (AQI) as a computational framework that enables systematic expansion of semantic space. AQI is formulated as a noncommutative algebraic structure inspired by quantum theory, allowing properties such as order dependence, interference, and uncertainty to be implemented in a controlled and designable manner. Semantic states are represented as vectors in a Hilbert space, and their evolution is governed by C-values computed from noncommutative operators, thereby ensuring the coexistence and expansion of multiple future semantic possibilities. In this study, we implement AQI by extending a transformer-based LLM with more than 600 specialized operators. We evaluate the resulting system on creative reasoning benchmarks spanning ten domains under an LLM-as-a-judge protocol. The results show that AQI consistently outperforms strong baseline models, yielding statistically significant improvements and reduced cross-domain variance. These findings demonstrate that noncommutative algebraic dynamics can serve as a practical and reproducible foundation for machine creativity. Notably, this architecture has already been deployed in real-world enterprise environments.

</details>


### [218] [ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI](https://arxiv.org/abs/2602.14135)
*Haibo Tong,Feifei Zhao,Linghao Feng,Ruoyu Wu,Ruolin Chen,Lu Jia,Zhou Zhao,Jindong Li,Tenglong Li,Erliang Lin,Shuai Yang,Enmeng Lu,Yinqian Sun,Qian Zhang,Zizhe Ruan,Zeyang Yue,Ping Wu,Huangrui Li,Chengyi Sun,Yi Zeng*

Main category: cs.AI

TL;DR: 本文提出ForesightSafety Bench综合性AI安全评估框架，涵盖94个风险维度，评估20余个前沿大模型，发现其在智能体自主性、AI4Science、具身AI、社会AI及灾难性/存在性风险等方面存在广泛安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全评估体系在应对快速演进、具备强自主性和目标导向能力的AI时存在严重局限，风险维度受限且无法有效检测前沿风险，安全基准和对齐技术滞后于尖端AI模型发展。

Method: 构建分层评估框架，从7大基础安全支柱扩展至先进领域（具身AI安全、AI4Science安全、社会与环境AI风险、灾难性与存在性风险）及8大工业安全领域，共94个细化风险维度，积累数万结构化风险评估数据点。

Result: 对20余个主流先进大模型的系统性评估揭示其跨多个支柱存在普遍安全脆弱性，尤其在风险智能体自主性、AI4Science安全、具身AI安全、社会AI安全及灾难性/存在性风险方面问题突出。

Conclusion: ForesightSafety Bench提供了一个全面、动态的AI安全评估体系，暴露了前沿AI模型的关键安全缺陷，凸显了在多样化风险领域加强安全措施的紧迫性。

Abstract: Rapidly evolving AI exhibits increasingly strong autonomy and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical limitations such as restricted risk dimensions and failed frontier risk detection. The lagging safety benchmarks and alignment technologies can hardly address the complex challenges posed by cutting-edge AI models. To bridge this gap, we propose the "ForesightSafety Bench" AI Safety Evaluation Framework, beginning with 7 major Fundamental Safety pillars and progressively extends to advanced Embodied AI Safety, AI4Science Safety, Social and Environmental AI risks, Catastrophic and Existential Risks, as well as 8 critical industrial safety domains, forming a total of 94 refined risk dimensions. To date, the benchmark has accumulated tens of thousands of structured risk data points and assessment results, establishing a widely encompassing, hierarchically clear, and dynamically evolving AI safety evaluation framework. Based on this benchmark, we conduct systematic evaluation and in-depth analysis of over twenty mainstream advanced large models, identifying key risk patterns and their capability boundaries. The safety capability evaluation results reveals the widespread safety vulnerabilities of frontier AI across multiple pillars, particularly focusing on Risky Agentic Autonomy, AI4Science Safety, Embodied AI Safety, Social AI Safety and Catastrophic and Existential Risks. Our benchmark is released at https://github.com/Beijing-AISI/ForesightSafety-Bench. The project website is available at https://foresightsafety-bench.beijing-aisi.ac.cn/.

</details>


### [219] [Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning](https://arxiv.org/abs/2602.14160)
*Chaeeun Lee,T. Michael Yates,Pasquale Minervini,T. Ian Simpson*

Main category: cs.AI

TL;DR: 提出一种用于基因-疾病有效性审评的分层多智能体强化学习框架，通过过程级监督和结果奖励结合，在保持高准确率（0.750）的同时显著提升临床路径符合度（0.520 F1），解决了当前LLM系统仅优化结果而忽视临床推理过程的问题。


<details>
  <summary>Details</summary>
Motivation: 临床决策需要基于异质性证据的细致推理和可追溯的论证。当前LLM多智能体系统主要优化结果准确率，却忽视了符合临床标准的过程导向推理。基因-疾病有效性审评是这一问题的关键现实案例，需要专家综合多元生物医学证据判断基因与疾病的因果关系。

Method: 提出“智能体即工具”的强化学习框架，包含两个核心目标：(i) 过程级监督确保推理遵循有效临床路径；(ii) 通过分层多智能体系统实现高效协同。使用GRPO训练Qwen3-4B监督智能体。

Result: 在ClinGen数据集上：仅结果奖励时，MAS将准确率从0.195提升至0.732，但过程对齐F1仅为0.392；而过程+结果奖励结合时，MAS实现了更高的准确率0.750，同时过程保真度显著提升至0.520 F1。

Conclusion: 过程级监督对于使LLM推理与临床标准对齐至关重要，能够在不牺牲甚至提升结果准确率的同时，确保推理过程的临床有效性。该框架为临床决策支持系统提供了新范式。

Abstract: Clinical decision-making requires nuanced reasoning over heterogeneous evidence and traceable justifications. While recent LLM multi-agent systems (MAS) show promise, they largely optimise for outcome accuracy while overlooking process-grounded reasoning aligned with clinical standards. One critical real-world case of this is gene-disease validity curation, where experts must determine whether a gene is causally implicated in a disease by synthesising diverse biomedical evidence. We introduce an agent-as-tool reinforcement learning framework for this task with two objectives: (i) process-level supervision to ensure reasoning follows valid clinical pathways, and (ii) efficient coordination via a hierarchical multi-agent system. Our evaluation on the ClinGen dataset shows that with outcome-only rewards, MAS with a GRPO-trained Qwen3-4B supervisor agent substantially improves final outcome accuracy from 0.195 with a base model supervisor to 0.732, but results in poor process alignment (0.392 F1). Conversely, with process + outcome rewards, MAS with GRPO-trained supervisor achieves higher outcome accuracy (0.750) while significantly improving process fidelity to 0.520 F1. Our code is available at https://github.com/chaeeunlee-io/GeneDiseaseCurationAgents.

</details>


### [220] [Text Before Vision: Staged Knowledge Injection Matters for Agentic RLVR in Ultra-High-Resolution Remote Sensing Understanding](https://arxiv.org/abs/2602.14225)
*Fengxiang Wang,Mingshuo Chen,Yueying Li,Yajie Yang,Yuhao Zhou,Di Wang,Yifan Zhang,Haoyu Wang,Haiyan Zhao,Hongda Sun,Long Lan,Jun Song,Yulin Wang,Jing Zhang,Wenlong Zhang,Bo Du*

Main category: cs.AI

TL;DR: 提出分阶段知识注入方法，先用地球科学文本QA建立推理结构，再结合视觉示例进行训练，在超高清遥感基准测试中达到60.40%的Pass@1，超越更大规模通用模型


<details>
  <summary>Details</summary>
Motivation: 超高清遥感多模态推理受限于视觉证据获取，需要从海量像素中定位微小任务相关区域。标准强化学习在广阔视觉空间中缺乏结构化领域先验，难以有效导航

Method: 分阶段知识注入：1)冷启动使用可扩展知识图谱验证的地球科学文本QA注入推理结构；2)在SFT阶段对相同困难超高清图像-文本示例进行"预热"，稳定并增强后续基于工具的强化学习

Result: 在XLRS-Bench基准测试中达到60.40% Pass@1，显著优于GPT-5.2、Gemini 3.0 Pro、Intern-S1等更大规模通用模型，建立新的最先进结果

Conclusion: 高质量地球科学文本问答是超高清视觉推理增益的主要驱动力，即使缺乏图像，领域特定文本也能注入引导视觉证据检索所需的概念、机制解释和决策规则

Abstract: Multimodal reasoning for ultra-high-resolution (UHR) remote sensing (RS) is usually bottlenecked by visual evidence acquisition: the model necessitates localizing tiny task-relevant regions in massive pixel spaces. While Agentic Reinforcement Learning with Verifiable Rewards (RLVR) using zoom-in tools offers a path forward, we find that standard reinforcement learning struggles to navigate these vast visual spaces without structured domain priors. In this paper, we investigate the interplay between post-training paradigms: comparing Cold-start Supervised Fine-Tuning (SFT), RLVR, and Agentic RLVR on the UHR RS benchmark.Our controlled studies yield a counter-intuitive finding: high-quality Earth-science text-only QA is a primary driver of UHR visual reasoning gains. Despite lacking images, domain-specific text injects the concepts, mechanistic explanations, and decision rules necessary to guide visual evidence retrieval.Based on this, we propose a staged knowledge injection recipe: (1) cold-starting with scalable, knowledge-graph-verified Earth-science text QA to instill reasoning structures;and (2) "pre-warming" on the same hard UHR image-text examples during SFT to stabilize and amplify subsequent tool-based RL. This approach achieves a 60.40% Pass@1 on XLRS-Bench, significantly outperforming larger general purpose models (e.g., GPT-5.2, Gemini 3.0 Pro, Intern-S1) and establishing a new state-of-the-art.

</details>


### [221] [CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments](https://arxiv.org/abs/2602.14229)
*Abubakarr Jaye,Nigel Boachie Kumankumah,Chidera Biringa,Anjel Shaileshbhai Patel,Sulaiman Vesal,Dayquan Julienne,Charlotte Siska,Manuel Raúl Meléndez Luján,Anthony Twum-Barimah,Mauricio Velazco,Tianwei Chen*

Main category: cs.AI

TL;DR: 该论文指出现有自主智能体基准测试无法反映真实世界中管理多个并发长时程任务的复杂性。研究者提出了多时程任务环境（MHTEs）这一新问题类别，要求智能体在持续数小时的执行上下文中协调45个以上交错任务（500-1500+步骤），并识别出四种导致基线CUA性能随负载增加而下降的故障模式。他们提出架构无关的CorpGen框架，通过分层规划、子智能体隔离、分层记忆和自适应摘要来解决这些问题，在三个CUA后端上实现了高达3.5倍的改进。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试仅在孤立任务上评估自主智能体，但真实组织工作涉及管理大量并发长时程任务，这些任务具有交错执行、依赖关系和优先级重排等特点。这一差距促使研究者构建更真实的评估环境和更鲁棒的智能体架构。

Method: 论文通过引入MHTEs作为新问题类别，并分析基线CUA在三种独立实现中的性能下降模式，识别出四种故障模式。提出CorpGen框架，包含：1）用于多时程目标对齐的分层规划；2）防止跨任务污染的子智能体隔离；3）分层记忆系统（工作记忆、结构化记忆、语义记忆）；4）自适应摘要机制。该框架通过具有持久身份和现实日程的数字员工模拟企业环境。

Result: 基线CUA性能随任务负载从25%增至100%而从16.7%完成率降至8.7%。CorpGen在OSWorld Office上相比基线（4.3%）实现了高达3.5倍的性能提升（15.2%），且在负载增加时表现稳定。消融研究表明经验学习带来的提升最大。

Conclusion: 识别出的四种故障模式（上下文饱和、记忆干扰、依赖复杂性、优先级重排开销）是多任务环境中的根本性挑战。CorpGen通过其架构机制有效应对这些挑战，证明改进源于框架设计而非特定CUA实现。这确立了MHTEs作为自主智能体的关键新基准，CorpGen作为鲁棒的解决方案。

Abstract: Long-horizon reasoning is a key challenge for autonomous agents, yet existing benchmarks evaluate agents on single tasks in isolation. Real organizational work requires managing many concurrent long-horizon tasks with interleaving, dependencies, and reprioritization. We introduce Multi-Horizon Task Environments (MHTEs): a distinct problem class requiring coherent execution across dozens of interleaved tasks (45+, 500-1500+ steps) within persistent execution contexts spanning hours. We identify four failure modes that cause baseline CUAs to degrade from 16.7% to 8.7% completion as load scales 25% to 100%, a pattern consistent across three independent implementations. These failure modes are context saturation (O(N) vs O(1) growth), memory interference, dependency complexity (DAGs vs. chains), and reprioritization overhead. We present CorpGen, an architecture-agnostic framework addressing these failures via hierarchical planning for multi-horizon goal alignment, sub-agent isolation preventing cross-task contamination, tiered memory (working, structured, semantic), and adaptive summarization. CorpGen simulates corporate environments through digital employees with persistent identities and realistic schedules. Across three CUA backends (UFO2, OpenAI CUA, hierarchical) on OSWorld Office, CorpGen achieves up to 3.5x improvement over baselines (15.2% vs 4.3%) with stable performance under increasing load, confirming that gains stem from architectural mechanisms rather than specific CUA implementations. Ablation studies show experiential learning provides the largest gains.

</details>


### [222] [REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents](https://arxiv.org/abs/2602.14234)
*Zheng Chu,Xiao Wang,Jack Hong,Huiming Fan,Yuqi Huang,Yue Yang,Guohai Xu,Chenxiao Zhao,Cheng Xiang,Shengchao Hu,Dongdong Kuang,Ming Liu,Bing Qin,Xing Yu*

Main category: cs.AI

TL;DR: 提出REDSearcher框架，通过联合设计任务合成、中期训练和后期训练来解决大模型深度搜索任务中的高质量轨迹稀疏问题，在文本和跨模态搜索基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 大模型正从通用知识引擎转向现实问题解决者，但深度搜索任务的优化面临高质量轨迹和奖励信号极度稀疏的瓶颈，原因在于长时程任务构建难以扩展以及外部工具调用交互成本高昂

Method: REDSearcher统一框架采用四个关键改进：1）基于图拓扑和证据分散度的双约束任务合成；2）工具增强查询促进主动工具使用；3）中期训练强化知识、规划和函数调用能力；4）构建本地模拟环境实现低成本强化学习迭代

Result: 在文本和跨模态搜索智能体基准测试中均达到最先进性能，并将开源10K文本轨迹、5K跨模态轨迹、1K强化学习查询集及相关代码和模型

Conclusion: 通过协同设计任务生成与训练流程，REDSearcher有效降低了高质量搜索轨迹收集成本，为长时程搜索智能体研究提供了可扩展的解决方案和高质量数据集

Abstract: Large language models are transitioning from generalpurpose knowledge engines to realworld problem solvers, yet optimizing them for deep search tasks remains challenging. The central bottleneck lies in the extreme sparsity of highquality search trajectories and reward signals, arising from the difficulty of scalable longhorizon task construction and the high cost of interactionheavy rollouts involving external tool calls. To address these challenges, we propose REDSearcher, a unified framework that codesigns complex task synthesis, midtraining, and posttraining for scalable searchagent optimization. Specifically, REDSearcher introduces the following improvements: (1) We frame task synthesis as a dualconstrained optimization, where task difficulty is precisely governed by graph topology and evidence dispersion, allowing scalable generation of complex, highquality tasks. (2) We introduce toolaugmented queries to encourage proactive tool use rather than passive recall.(3) During midtraining, we strengthen core atomic capabilities knowledge, planning, and function calling substantially reducing the cost of collecting highquality trajectories for downstream training. (4) We build a local simulated environment that enables rapid, lowcost algorithmic iteration for reinforcement learning experiments. Across both textonly and multimodal searchagent benchmarks, our approach achieves stateoftheart performance. To facilitate future research on longhorizon search agents, we will release 10K highquality complex text search trajectories, 5K multimodal trajectories and 1K text RL query set, and together with code and model checkpoints.

</details>


### [223] [GRAIL: Goal Recognition Alignment through Imitation Learning](https://arxiv.org/abs/2602.14252)
*Osher Elhadad,Felipe Meneguzzi,Reuth Mirsky*

Main category: cs.AI

TL;DR: GRAIL是一种通过模仿学习实现目标识别对齐的新方法，它从可能次优的演示轨迹中学习各候选目标对应的策略，在非最优行为场景下F1分数显著提升0.1-0.5，同时保持单次推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有目标识别方法依赖最优目标导向策略表示，但实际智能体行为常与真实策略存在偏差（次优或有系统性偏差），导致目标识别不准确。

Method: 提出GRAIL框架，结合模仿学习和逆向强化学习，直接从演示轨迹中为每个候选目标学习一个目标导向策略，并通过单次前向传播对观测到的部分轨迹进行评分。

Result: 在系统偏差最优行为下F1分数提升超过0.5，次优行为下提升约0.1-0.3，含噪声最优轨迹下提升达0.4，在完全最优场景下仍保持竞争力。

Conclusion: 该研究为实现可扩展且鲁棒的智能体目标解释模型作出贡献，特别适用于不确定环境中的非最优行为场景。

Abstract: Understanding an agent's goals from its behavior is fundamental to aligning AI systems with human intentions. Existing goal recognition methods typically rely on an optimal goal-oriented policy representation, which may differ from the actor's true behavior and hinder the accurate recognition of their goal. To address this gap, this paper introduces Goal Recognition Alignment through Imitation Learning (GRAIL), which leverages imitation learning and inverse reinforcement learning to learn one goal-directed policy for each candidate goal directly from (potentially suboptimal) demonstration trajectories. By scoring an observed partial trajectory with each learned goal-directed policy in a single forward pass, GRAIL retains the one-shot inference capability of classical goal recognition while leveraging learned policies that can capture suboptimal and systematically biased behavior. Across the evaluated domains, GRAIL increases the F1-score by more than 0.5 under systematically biased optimal behavior, achieves gains of approximately 0.1-0.3 under suboptimal behavior, and yields improvements of up to 0.4 under noisy optimal trajectories, while remaining competitive in fully optimal settings. This work contributes toward scalable and robust models for interpreting agent goals in uncertain environments.

</details>


### [224] [Benchmarking at the Edge of Comprehension](https://arxiv.org/abs/2602.14307)
*Samuele Marro,Jialin Yu,Emanuele La Malfa,Oishi Deb,Jiawei Li,Yibo Yang,Ebey Abraham,Sunando Sengupta,Eric Sommerlade,Michael Wooldridge,Philip Torr*

Main category: cs.AI

TL;DR: 本文提出"批判弹性基准测试"——一种对抗性框架，用于在人类无法完全理解任务时评估前沿大语言模型。该方法通过人类验证局部主张和双项Bradley-Terry模型，联合评估模型的解题与出题能力，在八个数学领域的前沿模型上显示出稳定的评分。


<details>
  <summary>Details</summary>
Motivation: 随着前沿大语言模型迅速饱和各项基准测试，人类越来越难以生成区分性任务、提供准确标准答案或评估复杂解法，基准测试正面临"后理解时代"的危机，威胁到我们衡量AI进步的能力。

Method: 提出批判弹性基准测试框架，基于"批判弹性正确性"概念（除非对手能令人信服地证伪，否则答案视为正确）。人类作为有限验证者专注于局部主张，使用项目化双项Bradley-Terry模型联合排名模型的解题能力和生成难题的能力。

Result: 在数学领域对八个前沿大语言模型的测试中，该方法产生的评分稳定且与外部能力指标相关，证明了其有效性。

Conclusion: 该框架成功将基准测试重新定义为对抗性的生成-评估博弈，人类作为最终裁判，即使在无法完全理解任务的情况下也能保持评估的完整性。

Abstract: As frontier Large Language Models (LLMs) increasingly saturate new benchmarks shortly after they are published, benchmarking itself is at a juncture: if frontier models keep improving, it will become increasingly hard for humans to generate discriminative tasks, provide accurate ground-truth answers, or evaluate complex solutions. If benchmarking becomes infeasible, our ability to measure any progress in AI is at stake. We refer to this scenario as the post-comprehension regime. In this work, we propose Critique-Resilient Benchmarking, an adversarial framework designed to compare models even when full human understanding is infeasible. Our technique relies on the notion of critique-resilient correctness: an answer is deemed correct if no adversary has convincingly proved otherwise. Unlike standard benchmarking, humans serve as bounded verifiers and focus on localized claims, which preserves evaluation integrity beyond full comprehension of the task. Using an itemized bipartite Bradley-Terry model, we jointly rank LLMs by their ability to solve challenging tasks and to generate difficult yet solvable questions. We showcase the effectiveness of our method in the mathematical domain across eight frontier LLMs, showing that the resulting scores are stable and correlate with external capability measures. Our framework reformulates benchmarking as an adversarial generation-evaluation game in which humans serve as final adjudicators.

</details>


### [225] [Competition for attention predicts good-to-bad tipping in AI](https://arxiv.org/abs/2602.14370)
*Neil F. Johnson,Frank Y. Huo*

Main category: cs.AI

TL;DR: 该论文发现边缘AI中的注意力竞争是危险行为的根本原因，并推导出预测临界点的数学公式，可在无需云连接的情况下实现主动安全控制，适用于多个领域。


<details>
  <summary>Details</summary>
Motivation: 随着全球超过一半人口使用可离线运行类ChatGPT模型的边缘AI设备，因缺乏安全监督而引发的自残、财务损失和极端主义等风险日益凸显。现有安全工具要么依赖云连接，要么只能在危害发生后才能发现。

Method: 研究人员从原子尺度分析边缘AI系统，识别出注意力机制竞争是危险临界点的来源。他们基于对话上下文与竞争输出盆地之间的点积竞争，推导出一个数学公式（n*），并在多个AI模型上验证了该机制。

Result: 发现了危险行为源于注意力竞争，并创建了一个可针对'好'与'坏'行为不同定义进行定制的临界点预测公式，在多个AI模型上得到验证。

Conclusion: 这种注意力竞争机制可广泛应用于健康、法律、金融、国防等多个领域，以及不同法律管辖区、语言和文化背景，为边缘AI提供了一种无需云连接的主动安全新方法。

Abstract: More than half the global population now carries devices that can run ChatGPT-like language models with no Internet connection and minimal safety oversight -- and hence the potential to promote self-harm, financial losses and extremism among other dangers. Existing safety tools either require cloud connectivity or discover failures only after harm has occurred. Here we show that a large class of potentially dangerous tipping originates at the atomistic scale in such edge AI due to competition for the machinery's attention. This yields a mathematical formula for the dynamical tipping point n*, governed by dot-product competition for attention between the conversation's context and competing output basins, that reveals new control levers. Validated against multiple AI models, the mechanism can be instantiated for different definitions of 'good' and 'bad' and hence in principle applies across domains (e.g. health, law, finance, defense), changing legal landscapes (e.g. EU, UK, US and state level), languages, and cultural settings.

</details>


### [226] [Boule or Baguette? A Study on Task Topology, Length Generalization, and the Benefit of Reasoning Traces](https://arxiv.org/abs/2602.14404)
*William L. Tong,Ege Cakar,Cengiz Pehlevan*

Main category: cs.AI

TL;DR: 该论文提出PITA数据集（2300万条命题逻辑语句及其证明），研究推理追踪模型在长度泛化上的表现，发现其在广度大、深度浅的任务上泛化良好，但在狭窄且深的任务上表现劣于非RT基线，揭示了推理追踪方法的固有优势和局限性。


<details>
  <summary>Details</summary>
Motivation: 近年来能生成中间推理追踪的神经推理模型进展迅速，但人们对其推理机制及范式局限的理解仍不完整。为促进清晰认识，需系统研究模型从固定长度证明训练到更长证明的泛化能力。

Method: 构建大规模命题逻辑数据集PITA，提出任务深度（求解步骤数）和任务广度（示例多样性）两个度量指标，在不同深浅广度的子集上测试RT模型，并与人工合成三段论任务对比验证现象普适性。

Result: RT模型在广而浅的任务上泛化良好，但在窄而深的任务上性能显著下降，劣于非RT基线。该规律在PITA和合成任务中均成立，表明RT模型存在深度任务上的根本性扩展限制，但在广度任务上具有泛化优势。

Conclusion: 研究明确了推理追踪方法的内在优势与局限，为RT模型在深度任务上的性能边界提供了理论解释，并指出其在广度任务上的泛化潜力，为未来推理模型设计提供方向。

Abstract: Recent years have witnessed meteoric progress in reasoning models: neural networks that generate intermediate reasoning traces (RTs) before producing a final output. Despite the rapid advancement, our understanding of how RTs support reasoning, and the limits of this paradigm, remain incomplete. To promote greater clarity, we introduce PITA: a novel large-scale dataset of over 23 million statements in propositional logic and their corresponding proofs. As a benchmark for robust reasoning, we focus on length generalization: if a model is trained to determine truth or falsity on statements with proofs up to fixed length, how well does it generalize to statements requiring longer proofs? We propose notions of (1) task depth and (2) task breadth, which measure respectively (1) the number of steps required to solve an example from a task and (2) the number of unique examples across a task. We vary these quantities across subsets of PITA, and find that RT models generalize well on broad and shallow subsets, while deteriorating on narrow and deep subsets relative to non-RT baselines. To determine whether our results are idiosyncratic to PITA or indicative of general phenomena, we compare our results to a simple synthetic task based on syllogisms. Our resulting theory suggests fundamental scalings that limit how well RT models perform on deep tasks, and highlights their generalization strengths on broad tasks. Our findings overall identify fundamental benefits and limitations inherent in using reasoning traces.

</details>


### [227] [Precedent-Informed Reasoning: Mitigating Overthinking in Large Reasoning Models via Test-Time Precedent Learning](https://arxiv.org/abs/2602.14451)
*Qianyue Wang,Jinwu Hu,Huanxiang Lin,Bolin Chen,Zhiquan Wen,Yaofo Chen,Yu Rong,Mingkui Tan*

Main category: cs.AI

TL;DR: 提出"先例引导推理"(PIR)方法，通过自适应选择相关先例并内化解题模式，解决大语言模型推理中链式思维冗长低效的问题，在保持或提升准确率的同时显著缩短推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型推理存在冗余自我探索和验证，导致计算成本高且可能降低性能，而人类推理常通过借鉴历史案例来约束搜索空间。

Method: 1) 自适应先例选择(APS)：基于语义相似度和模型困惑度的联合评分，为每个问题动态选择信息量最大的先例集；2) 测试时经验内化(TEI)：通过轻量适配器学习先例中的解题模式，作为后续推理的先验知识。

Result: 在数学推理、科学问答和代码生成任务中，PIR consistently缩短推理链长度，同时保持或提高准确率，实现卓越的精度-效率平衡。

Conclusion: PIR成功将LLMs推理范式从穷举式自我探索转变为先例引导学习，有效提升推理效率而不牺牲性能，具有跨模型适用性。

Abstract: Reasoning in Large Language Models (LLMs) often suffers from inefficient long chain-of-thought traces with redundant self-exploration and validation, which inflate computational costs and even degrade performance. Inspired by human reasoning patterns where people solve new problems by leveraging past related cases to constrain search spaces and reduce trial-and-error, we propose Precedent Informed Reasoning (PIR) transforming LRMs'reasoning paradigm from exhaustive self-exploration to guided learning from precedents. PIR addresses two key challenges: what precedents to adopt and how to utilize them. First, Adaptive Precedent Selection (APS) constructs, for each question and LRM, a compact set of precedents that are both semantically related and informative for the model. It ranks examples by a joint score with semantic similarity and model perplexity, then adapts the amount of precedents to maximize perplexity reduction. Second, Test-time Experience Internalization (TEI) is treated as the test-time learning on precedent-informed instruction, updating lightweight adapters to internalize solution patterns and use them as a prior during subsequent reasoning. Experiments across mathematical reasoning, scientific QA, and code generation demonstrate that PIR consistently shortens reasoning traces while maintaining or improving final accuracy across LLMs, yielding outstanding accuracy-efficiency trade-offs.

</details>


### [228] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5](https://arxiv.org/abs/2602.14457)
*Dongrui Liu,Yi Yu,Jie Zhang,Guanxu Chen,Qihao Lin,Hanxi Zhu,Lige Huang,Yijin Zhou,Peng Wang,Shuai Shao,Boxuan Zhang,Zicheng Liu,Jingwei Sun,Yu Li,Yuejin Xie,Jiaxuan Guo,Jia Xu,Chaochao Lu,Bowen Zhou,Xia Hu,Jing Shao*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice presents a comprehensive assessment of their frontier risks. As Large Language Models (LLMs) general capabilities rapidly evolve and the proliferation of agentic AI, this version of the risk analysis technical report presents an updated and granular assessment of five critical dimensions: cyber offense, persuasion and manipulation, strategic deception, uncontrolled AI R\&D, and self-replication. Specifically, we introduce more complex scenarios for cyber offense. For persuasion and manipulation, we evaluate the risk of LLM-to-LLM persuasion on newly released LLMs. For strategic deception and scheming, we add the new experiment with respect to emergent misalignment. For uncontrolled AI R\&D, we focus on the ``mis-evolution'' of agents as they autonomously expand their memory substrates and toolsets. Besides, we also monitor and evaluate the safety performance of OpenClaw during the interaction on the Moltbook. For self-replication, we introduce a new resource-constrained scenario. More importantly, we propose and validate a series of robust mitigation strategies to address these emerging threats, providing a preliminary technical and actionable pathway for the secure deployment of frontier AI. This work reflects our current understanding of AI frontier risks and urges collective action to mitigate these challenges.

</details>


### [229] [Bounding Probabilities of Causation with Partial Causal Diagrams](https://arxiv.org/abs/2602.14503)
*Yuxuan Xie,Ang Li*

Main category: cs.AI

TL;DR: 本文提出一种通用优化框架，通过将部分因果信息系统性地作为约束条件，在不完全可识别的情况下获得更紧的因果概率边界。


<details>
  <summary>Details</summary>
Motivation: 因果概率对个体层面的解释和决策至关重要，但由于其反事实性质通常无法从数据中点识别；现有方法要么忽略可用协变量，要么需要完整的因果图，要么依赖于受限的二元设定，限制了实用性，尤其是在只有部分因果知识的现实场景中。

Method: 该论文提出采用优化编程方法，将可用的结构或统计因果信息作为约束条件系统性地纳入，构建因果概率边界的通用框架。

Result: 该方法在不要求完全可识别性的前提下，产生了更紧且形式上有效的因果概率边界，将因果概率的适用范围扩展到因果知识不完整但有意义的现实场景中。

Conclusion: 该框架通过仅使用部分但有信息的因果知识来获得有效的因果概率边界，成功弥合了理论因果推断与实际应用之间的鸿沟。

Abstract: Probabilities of causation are fundamental to individual-level explanation and decision making, yet they are inherently counterfactual and not point-identifiable from data in general. Existing bounds either disregard available covariates, require complete causal graphs, or rely on restrictive binary settings, limiting their practical use. In real-world applications, causal information is often partial but nontrivial. This paper proposes a general framework for bounding probabilities of causation using partial causal information. We show how the available structural or statistical information can be systematically incorporated as constraints in a optimization programming formulation, yielding tighter and formally valid bounds without full identifiability. This approach extends the applicability of probabilities of causation to realistic settings where causal knowledge is incomplete but informative.

</details>


### [230] [Formally Verifying and Explaining Sepsis Treatment Policies with COOL-MC](https://arxiv.org/abs/2602.14505)
*Dennis Gross*

Main category: cs.AI

TL;DR: COOL-MC是一个用于脓毒症治疗强化学习策略验证和解释的框架，它通过构建可达状态空间、自动状态标注和PCTL可解释性查询，揭示了训练策略主要依赖历史用药而非患者实时状况的缺陷，为临床部署前调试提供了工具。


<details>
  <summary>Details</summary>
Motivation: 脓毒症治疗优化中的RL策略不透明且难以验证，标准模型检查器对大型MDP计算不可行且无法解释决策逻辑，亟需兼具形式化验证和可解释性的临床决策支持工具。

Method: COOL-MC在Storm模型检查器基础上扩展三项能力：1）仅构建训练策略诱导的可达状态空间，生成更小的DTMC；2）用临床语义自动标记状态；3）将可解释性方法与PCTL查询集成。在ICU-Sepsis MDP基准（17,000患者记录）上，先进行完整MDP验证建立边界，训练安全RL策略，再对诱导的DTMC进行PCTL验证和解释分析。

Result: 通过全MDP验证建立了严格的性能边界，训练出达到最优生存概率的安全策略。PCTL分析揭示该策略主要依赖历史用药剂量而非患者实时病情变化做决策，这一弱点无法通过标准评估发现。

Conclusion: COOL-MC整合了形式化验证与可解释性，能帮助临床医生在部署前调查和调试脓毒症治疗策略，提升RL决策的安全性和透明度。

Abstract: Safe and interpretable sequential decision-making is critical in healthcare, yet reinforcement learning (RL) policies for sepsis treatment optimization remain opaque and difficult to verify. Standard probabilistic model checkers operate on the full state space, which becomes infeasible for larger MDPs, and cannot explain why a learned policy makes particular decisions. COOL-MC wraps the model checker Storm but adds three key capabilities: it constructs only the reachable state space induced by a trained policy, yielding a smaller discrete-time Markov chain amenable to verification even when full-MDP analysis is intractable; it automatically labels states with clinically meaningful atomic propositions; and it integrates explainability methods with probabilistic computation tree logic (PCTL) queries to reveal which features drive decisions across treatment trajectories. We demonstrate COOL-MC's capabilities on the ICU-Sepsis MDP, a benchmark derived from approximately 17,000 sepsis patient records, which serves as a case study for applying COOL-MC to the formal analysis of sepsis treatment policies. Our analysis establishes hard bounds via full MDP verification, trains a safe RL policy that achieves optimal survival probability, and analyzes its behavior via PCTL verification and explainability on the induced DTMC. This reveals, for instance, that our trained policy relies predominantly on prior dosing history rather than the patient's evolving condition, a weakness that is invisible to standard evaluation but is exposed by COOL-MC's integration of formal verification and explainability. Our results illustrate how COOL-MC could serve as a tool for clinicians to investigate and debug sepsis treatment policies before deployment.

</details>


### [231] [Diagnosing Knowledge Conflict in Multimodal Long-Chain Reasoning](https://arxiv.org/abs/2602.14518)
*Jing Tang,Kun Wang,Haolang Lu,Hongjin Chen,KaiTao Chen,Zhongxiang Sun,Qiankun Li,Lingjuan Lyu,Guoshun Nan,Zhigang Zeng*

Main category: cs.AI

TL;DR: 该论文研究了多模态大语言模型在长思维链推理中因知识冲突而失败的问题，通过分析模型内部表示揭示了四种冲突编码机制，为诊断和控制推理失败提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在长思维链推理中常因不同知识源提供冲突信号而失败，现有研究缺乏对这种冲突的系统性形式化和机制理解。

Method: 将冲突失败形式化为知识冲突问题，区分输入级客观冲突与过程级有效冲突，并通过探测模型内部表示来分析冲突编码特征。

Result: 发现四种关键机制：1)线性可分性：不同冲突类型以线性可分特征编码；2)深度定位：冲突信号集中在中后期层；3)层级一致性：沿轨迹聚合噪声标记信号可恢复输入级冲突；4)方向不对称性：强化模型隐含源偏好比强制相反源更容易。

Conclusion: 研究结果提供了知识冲突下多模态推理的机制级视角，实现了对长思维链失败的原则性诊断和控制，为改进模型推理可靠性提供了理论依据。

Abstract: Multimodal large language models (MLLMs) in long chain-of-thought reasoning often fail when different knowledge sources provide conflicting signals. We formalize these failures under a unified notion of knowledge conflict, distinguishing input-level objective conflict from process-level effective conflict. Through probing internal representations, we reveal that: (I) Linear Separability: different conflict types are explicitly encoded as linearly separable features rather than entangled; (II) Depth Localization: conflict signals concentrate in mid-to-late layers, indicating a distinct processing stage for conflict encoding; (III) Hierarchical Consistency: aggregating noisy token-level signals along trajectories robustly recovers input-level conflict types; and (IV) Directional Asymmetry: reinforcing the model's implicit source preference under conflict is far easier than enforcing the opposite source. Our findings provide a mechanism-level view of multimodal reasoning under knowledge conflict and enable principled diagnosis and control of long-CoT failures.

</details>


### [232] [Disentangling Deception and Hallucination Failures in LLMs](https://arxiv.org/abs/2602.14529)
*Haolang Lu,Hongrui Peng,WeiYe Fu,Guoshun Nan,Xinye Cao,Xingrui Li,Hongcan Guo,Kun Wang*

Main category: cs.AI

TL;DR: 论文提出从内部机制角度区分LLM中的知识存在与行为表达，认为幻觉和欺骗是两种不同但表面相似的失败模式，并构建受控环境通过表征可分性、稀疏可解释性和激活引导进行系统分析。


<details>
  <summary>Details</summary>
Motivation: 现有对LLM失败的行为分析视角将不同失败机制混为一谈，特别是幻觉和欺骗在输出层面相似但潜在机制可能不同，需要更精细的分析框架。

Method: 构建实体中心事实问题的受控环境，在保留知识的同时选择性地改变行为表达，从而系统分析四种行为案例，并运用表征可分性、稀疏可解释性和推理时激活引导技术。

Result: 建立了可区分知识存在与行为表达的机制分析框架，实现了对四种行为案例的系统性分析，为区分幻觉和欺骗等失败模式提供了方法论基础。

Conclusion: 幻觉和欺骗是质上不同的失败模式，应采用内部机制导向的视角而非纯行为分析来理解LLM失败，这为未来研究提供了新的理论框架和分析工具。

Abstract: Failures in large language models (LLMs) are often analyzed from a behavioral perspective, where incorrect outputs in factual question answering are commonly associated with missing knowledge. In this work, focusing on entity-based factual queries, we suggest that such a view may conflate different failure mechanisms, and propose an internal, mechanism-oriented perspective that separates Knowledge Existence from Behavior Expression. Under this formulation, hallucination and deception correspond to two qualitatively different failure modes that may appear similar at the output level but differ in their underlying mechanisms. To study this distinction, we construct a controlled environment for entity-centric factual questions in which knowledge is preserved while behavioral expression is selectively altered, enabling systematic analysis of four behavioral cases. We analyze these failure modes through representation separability, sparse interpretability, and inference-time activation steering.

</details>


### [233] [MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs](https://arxiv.org/abs/2602.14589)
*Gabriel Roccabruna,Olha Khomyn,Giuseppe Riccardi*

Main category: cs.AI

TL;DR: This paper introduces MATEO, a multimodal benchmark using professional recipes to evaluate and improve LVLMs' ability to understand complex temporal execution orders (TEO) as directed acyclic graphs, addressing limitations of existing linear-chain approximations.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for foundational models' temporal reasoning oversimplify real-world planning by using linear chains, text-only inputs, or auto-generated annotations instead of accurate directed acyclic graphs (TEO) required for complex goal achievement.

Method: Created a professional multimodal recipe corpus with standardized step decomposition (images + instructions), then developed a scalable crowdsourcing pipeline to collect high-quality TEO annotations as directed acyclic graphs for real-world planning scenarios.

Result: Evaluated six state-of-the-art LVLMs across model scales, language contexts, input structures, and fine-tuning strategies using MATEO, revealing performance gaps in multimodal temporal reasoning for non-linear execution flows.

Conclusion: MATEO provides the first comprehensive benchmark for assessing and enhancing LVLMs' real-world planning capabilities through accurate multimodal TEO understanding, moving beyond oversimplified linear assumptions.

Abstract: AI agents need to plan to achieve complex goals that involve orchestrating perception, sub-goal decomposition, and execution. These plans consist of ordered steps structured according to a Temporal Execution Order (TEO, a directed acyclic graph that ensures each step executes only after its preconditions are satisfied. Existing research on foundational models' understanding of temporal execution is limited to automatically derived annotations, approximations of the TEO as a linear chain, or text-only inputs. To address this gap, we introduce MATEO (MultimodAl Temporal Execution Order), a benchmark designed to assess and improve the temporal reasoning abilities of Large Vision Language Models (LVLMs) required for real-world planning. We acquire a high-quality professional multimodal recipe corpus, authored through a standardized editorial process that decomposes instructions into discrete steps, each paired with corresponding images. We collect TEO annotations as graphs by designing and using a scalable crowdsourcing pipeline. Using MATEO, we evaluate six state-of-the-art LVLMs across model scales, varying language context, multimodal input structure, and fine-tuning strategies.

</details>


### [234] [Arbor: A Framework for Reliable Navigation of Critical Conversation Flows](https://arxiv.org/abs/2602.14643)
*Luís Silva,Diogo Gonçalves,Catarina Farinha,Clara Matos,Luís Ungaro*

Main category: cs.AI

TL;DR: The paper introduces Arbor, a framework that breaks down decision trees into node-level tasks for LLMs, improving accuracy by 29.4%, reducing latency by 57.1%, and cutting costs by 14.4x in healthcare triage compared to monolithic approaches.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle to follow structured workflows in high-stakes domains like healthcare triage, with monolithic prompt approaches suffering from instruction degradation, lost-in-the-middle effects, and context window overflow as prompts grow longer.

Method: The Arbor framework decomposes decision trees into specialized node-level tasks using an edge-list representation with dynamic retrieval. A DAG-based orchestration mechanism iteratively processes only current node edges, evaluates transitions via dedicated LLM calls, and separates response generation, while remaining agnostic to decision logic and model provider.

Result: Evaluated across 10 foundation models using real clinical triage data, Arbor improved mean turn accuracy by 29.4 percentage points, reduced per-turn latency by 57.1%, achieved a 14.4x cost reduction per turn, and enabled smaller models to match or exceed larger models using single-prompt approaches.

Conclusion: Architectural decomposition reduces reliance on intrinsic model capability, making structured decision-making more efficient and effective for LLMs in high-stakes domains.

Abstract: Large language models struggle to maintain strict adherence to structured workflows in high-stakes domains such as healthcare triage. Monolithic approaches that encode entire decision structures within a single prompt are prone to instruction-following degradation as prompt length increases, including lost-in-the-middle effects and context window overflow. To address this gap, we present Arbor, a framework that decomposes decision tree navigation into specialized, node-level tasks. Decision trees are standardized into an edge-list representation and stored for dynamic retrieval. At runtime, a directed acyclic graph (DAG)-based orchestration mechanism iteratively retrieves only the outgoing edges of the current node, evaluates valid transitions via a dedicated LLM call, and delegates response generation to a separate inference step. The framework is agnostic to the underlying decision logic and model provider. Evaluated against single-prompt baselines across 10 foundation models using annotated turns from real clinical triage conversations. Arbor improves mean turn accuracy by 29.4 percentage points, reduces per-turn latency by 57.1%, and achieves an average 14.4x reduction in per-turn cost. These results indicate that architectural decomposition reduces dependence on intrinsic model capability, enabling smaller models to match or exceed larger models operating under single-prompt baselines.

</details>


### [235] [From User Preferences to Base Score Extraction Functions in Gradual Argumentation](https://arxiv.org/abs/2602.14674)
*Aniol Civit,Antonio Rago,Antonio Andriella,Guillem Alenyà,Francesca Toni*

Main category: cs.AI

TL;DR: 提出基分提取函数，将用户偏好映射为辩论框架中的基分，简化分数选择过程，实现可争议AI系统


<details>
  <summary>Details</summary>
Motivation: 渐进式辩论需要谨慎选择论证基分，此过程依赖专家知识且不直观；通过偏好组织论证可简化该任务

Method: 引入基分提取函数，将带偏好的双极辩论框架转换为定量双极辩论框架；算法近似人类偏好的非线性特征

Result: 理论分析与机器人实验验证了方法有效性，提供了选择渐进语义的实践建议

Conclusion: 该方法降低了基分选择难度，使渐进式辩论更易应用于决策、推荐等实际场景

Abstract: Gradual argumentation is a field of symbolic AI which is attracting attention for its ability to support transparent and contestable AI systems. It is considered a useful tool in domains such as decision-making, recommendation, debate analysis, and others. The outcomes in such domains are usually dependent on the arguments' base scores, which must be selected carefully. Often, this selection process requires user expertise and may not always be straightforward. On the other hand, organising the arguments by preference could simplify the task. In this work, we introduce \emph{Base Score Extraction Functions}, which provide a mapping from users' preferences over arguments to base scores. These functions can be applied to the arguments of a \emph{Bipolar Argumentation Framework} (BAF), supplemented with preferences, to obtain a \emph{Quantitative Bipolar Argumentation Framework} (QBAF), allowing the use of well-established computational tools in gradual argumentation. We outline the desirable properties of base score extraction functions, discuss some design choices, and provide an algorithm for base score extraction. Our method incorporates an approximation of non-linearities in human preferences to allow for better approximation of the real ones. Finally, we evaluate our approach both theoretically and experimentally in a robotics setting, and offer recommendations for selecting appropriate gradual semantics in practice.

</details>


### [236] [GREAT-EER: Graph Edge Attention Network for Emergency Evacuation Responses](https://arxiv.org/abs/2602.14676)
*Attila Lischka,Balázs Kulcsár*

Main category: cs.AI

TL;DR: Proposes a deep reinforcement learning method with graph learning to solve the Bus Evacuation Orienteering Problem (BEOP), achieving near-optimal, real-time evacuation routing for urban areas using buses to reduce congestion during emergencies.


<details>
  <summary>Details</summary>
Motivation: Urban evacuations face challenges from increasing natural disasters (due to climate change) and man-made threats; current car-focused plans cause congestion and disorder, necessitating efficient bus-based evacuation methods to save lives quickly.

Method: Formulates BEOP as an NP-hard combinatorial problem; solves it using a deep reinforcement learning (DRL) framework enhanced with graph learning for rapid route generation, validated against a Mixed-Integer Linear Programming (MILP) baseline for solution gap analysis.

Result: Achieves near-optimal evacuation efficiency on real-world San Francisco road networks, generates routes in seconds, and quantifies the minimum number of buses required to meet evacuation quotas within time constraints while maintaining computational speed.

Conclusion: The DRL-graph learning approach provides a practical, high-speed solution for bus-based urban evacuations, balancing optimality and real-world applicability to enhance emergency response planning under time pressure.

Abstract: Emergency situations that require the evacuation of urban areas can arise from man-made causes (e.g., terrorist attacks or industrial accidents) or natural disasters, the latter becoming more frequent due to climate change. As a result, effective and fast methods to develop evacuation plans are of great importance. In this work, we identify and propose the Bus Evacuation Orienteering Problem (BEOP), an NP-hard combinatorial optimization problem with the goal of evacuating as many people from an affected area by bus in a short, predefined amount of time. The purpose of bus-based evacuation is to reduce congestion and disorder that arises in purely car-focused evacuation scenarios. To solve the BEOP, we propose a deep reinforcement learning-based method utilizing graph learning, which, once trained, achieves fast inference speed and is able to create evacuation routes in fractions of seconds. We can bound the gap of our evacuation plans using an MILP formulation. To validate our method, we create evacuation scenarios for San Francisco using real-world road networks and travel times. We show that we achieve near-optimal solution quality and are further able to investigate how many evacuation vehicles are necessary to achieve certain bus-based evacuation quotas given a predefined evacuation time while keeping run time adequate.

</details>


### [237] [Removing Planner Bias in Goal Recognition Through Multi-Plan Dataset Generation](https://arxiv.org/abs/2602.14691)
*Mustafa F. Abdelwahed,Felipe Meneguzzi Kin Max Piamolini Gusmao,Joan Espasa*

Main category: cs.AI

TL;DR: 解决目标识别数据集偏差问题


<details>
  <summary>Details</summary>
Motivation: 现有目标识别数据集因规划系统（启发式正向搜索）存在系统性偏差，导致评估结果无法反映真实场景（如不同规划器）下的泛化能力

Method: 提出基于top-k规划的新方法，为同一目标生成多组不同计划，构建无偏评估基准；引入版本覆盖分数(VCS)指标衡量目标识别器在不同计划集下的鲁棒性

Result: 实验表明，当前最优目标识别器在低可观测性场景下鲁棒性显著下降

Conclusion: 该方法有效缓解数据集偏差，为评估目标识别器在跨规划器场景下的泛化能力提供新标准

Abstract: Autonomous agents require some form of goal and plan recognition to interact in multiagent settings. Unfortunately, all existing goal recognition datasets suffer from a systematical bias induced by the planning systems that generated them, namely heuristic-based forward search. This means that existing datasets lack enough challenge for more realistic scenarios (e.g., agents using different planners), which impacts the evaluation of goal recognisers with respect to using different planners for the same goal. In this paper, we propose a new method that uses top-k planning to generate multiple, different, plans for the same goal hypothesis, yielding benchmarks that mitigate the bias found in the current dataset. This allows us to introduce a new metric called Version Coverage Score (VCS) to measure the resilience of the goal recogniser when inferring a goal based on different sets of plans. Our results show that the resilience of the current state-of-the-art goal recogniser degrades substantially under low observability settings.

</details>


### [238] [Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs](https://arxiv.org/abs/2602.14697)
*Lunjun Zhang,Ryan Chen,Bradly C. Stadie*

Main category: cs.AI

TL;DR: E-SPL jointly optimizes model weights via reinforcement learning and system prompts via evolutionary algorithms with LLM-driven mutation/crossover, creating a natural division between declarative and procedural knowledge for improved sample efficiency and generalization.


<details>
  <summary>Details</summary>
Motivation: Current LLMs only self-improve through separate mechanisms: self-reflection for contexts or RL for weights, but not both jointly. The goal is to build autonomous self-improving agentic systems that can learn from experience.

Method: Evolutionary System Prompt Learning (E-SPL) - in each RL iteration, selects multiple system prompts, runs parallel rollouts, updates model weights via RL conditioned on each prompt, and evolves the prompt population using LLM-driven mutation and crossover with TrueSkill ratings for selection.

Result: On AIME→BeyondAIME generalization, E-SPL improved RL success rate from 38.8% to 45.1%, outperforming reflective prompt evolution (40.0%), with consistent gains in sample efficiency and generalization across reasoning and agentic tasks.

Conclusion: Coupling reinforcement learning with system prompt evolution effectively separates declarative knowledge (prompts) from procedural knowledge (weights), yielding superior performance and demonstrating that joint optimization of both components is key for autonomous self-improvement.

Abstract: Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this work, we propose Evolutionary System Prompt Learning (E-SPL), a method for jointly improving model contexts and model weights. In each RL iteration, E-SPL selects multiple system prompts and runs rollouts with each in parallel. It applies RL updates to model weights conditioned on each system prompt, and evolutionary updates to the system prompt population via LLM-driven mutation and crossover. Each system prompt has a TrueSkill rating for evolutionary selection, updated from relative performance within each RL iteration batch. E-SPL encourages a natural division between declarative knowledge encoded in prompts and procedural knowledge encoded in weights, resulting in improved performance across reasoning and agentic tasks. For instance, in an easy-to-hard (AIME $\rightarrow$ BeyondAIME) generalization setting, E-SPL improves RL success rate from 38.8% $\rightarrow$ 45.1% while also outperforming reflective prompt evolution (40.0%). Overall, our results show that coupling reinforcement learning with system prompt evolution yields consistent gains in sample efficiency and generalization. Code: https://github.com/LunjunZhang/E-SPL

</details>


### [239] [WebWorld: A Large-Scale World Model for Web Agent Training](https://arxiv.org/abs/2602.14721)
*Zikai Xiao,Jianhong Tu,Chuhang Zou,Yuxin Zuo,Zhi Li,Peng Wang,Bowen Yu,Fei Huang,Junyang Lin,Zuozhu Liu*

Main category: cs.AI

TL;DR: WebWorld is a scalable open-web simulator training on 1M+ interactions that matches Gemini-3-Pro's simulation quality, boosts Qwen3-14B by 9.2% on WebArena, and generalizes to code/GUI/game domains.


<details>
  <summary>Details</summary>
Motivation: Web agents require massive trajectories for generalization, but real-world training is limited by network latency, rate limits, and safety risks. Existing simulators are confined to closed environments with only thousands of trajectories.

Method: Introduces WebWorld series, the first open-web simulator trained at scale via a scalable data pipeline on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps.

Result: WebWorld-Bench evaluation shows performance comparable to Gemini-3-Pro. Qwen3-14B trained on WebWorld data improves +9.2% on WebArena (approaching GPT-4o). It enables inference-time search outperforming GPT-5 and generalizes to code, GUI, and game environments.

Conclusion: WebWorld provides a replicable recipe for world model construction that effectively simulates web environments while demonstrating cross-domain generalization capabilities.

Abstract: Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce \textbf{WebWorld} series, the first open-web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages a scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For intrinsic evaluation, we introduce WebWorld-Bench with dual metrics spanning nine dimensions, where WebWorld achieves simulation performance comparable to Gemini-3-Pro. For extrinsic evaluation, Qwen3-14B trained on WebWorld-synthesized trajectories improves by +9.2\% on WebArena, reaching performance comparable to GPT-4o. WebWorld enables effective inference-time search, outperforming GPT-5 as a world model. Beyond web simulation, WebWorld exhibits cross-domain generalization to code, GUI, and game environments, providing a replicable recipe for world model construction.

</details>


### [240] [AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises](https://arxiv.org/abs/2602.14740)
*Kenneth Payne*

Main category: cs.AI

TL;DR: 本研究通过核危机模拟实验发现，三款前沿AI模型(GPT-5.2、Claude Sonnet 4、Gemini 3 Flash)在战略博弈中既验证了部分经典战略理论，又表现出核禁忌失效、威胁引发对抗升级、高可信度加速冲突等危险行为，且从未选择妥协或撤退，警示AI模拟战略分析需谨慎校准。


<details>
  <summary>Details</summary>
Motivation: 探究前沿AI模型在战略竞争中的复杂行为特征，评估其在核危机等高 stakes 场景下的决策模式，既服务国家安全专业应用，也为理解AI在不确定性下的推理能力提供跨领域洞见。

Method: 设计核危机模拟实验，让三款前沿大语言模型分别扮演对立国家领导人角色，观察并分析其在战略互动中的决策行为、推理逻辑和升级动态。

Result: 支持谢林承诺理论、卡恩升级框架和杰维斯误判理论，但发现：1)核禁忌未阻止核升级；2)偶发战略性核打击；3)威胁更多引发反升级而非服从；4)高度相互可信度加速而非威慑冲突；5)所有模型在高压下均拒绝妥协或撤军，仅选择降低暴力级别。

Conclusion: AI模拟是强大的战略分析工具，但必须根据已知的人类推理模式进行校准；理解前沿模型在哪些方面模仿或偏离人类战略逻辑，是为AI日益塑造战略结果的世界做必要准备。

Abstract: Today's leading AI models engage in sophisticated behaviour when placed in strategic competition. They spontaneously attempt deception, signaling intentions they do not intend to follow; they demonstrate rich theory of mind, reasoning about adversary beliefs and anticipating their actions; and they exhibit credible metacognitive self-awareness, assessing their own strategic abilities before deciding how to act.
  Here we present findings from a crisis simulation in which three frontier large language models (GPT-5.2, Claude Sonnet 4, Gemini 3 Flash) play opposing leaders in a nuclear crisis. Our simulation has direct application for national security professionals, but also, via its insights into AI reasoning under uncertainty, has applications far beyond international crisis decision-making.
  Our findings both validate and challenge central tenets of strategic theory. We find support for Schelling's ideas about commitment, Kahn's escalation framework, and Jervis's work on misperception, inter alia. Yet we also find that the nuclear taboo is no impediment to nuclear escalation by our models; that strategic nuclear attack, while rare, does occur; that threats more often provoke counter-escalation than compliance; that high mutual credibility accelerated rather than deterred conflict; and that no model ever chose accommodation or withdrawal even when under acute pressure, only reduced levels of violence.
  We argue that AI simulation represents a powerful tool for strategic analysis, but only if properly calibrated against known patterns of human reasoning. Understanding how frontier models do and do not imitate human strategic logic is essential preparation for a world in which AI increasingly shapes strategic outcomes.

</details>


### [241] [Return of the Schema: Building Complete Datasets for Machine Learning and Reasoning on Knowledge Graphs](https://arxiv.org/abs/2602.14795)
*Ivan Diliso,Roberto Barile,Claudia d'Amato,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 提出首个整合模式层与事实的知识图谱数据集构建流程，解决现有数据集缺乏本体约束导致评估受限的问题，提供可直接用于机器学习与推理的标准化数据集套件。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱精化算法评估数据集仅包含事实三元组，缺乏模式层本体知识，导致依赖本体约束、推理或神经符号技术的方法无法被充分评估，难以反映真实大规模知识图谱中的性能。

Method: 设计标准化工作流，从源知识图谱同时提取模式层与事实数据，自动处理模式-事实不一致性，通过推理补全隐式知识，输出OWL格式数据集并提供张量化加载工具。

Result: 生成包含新提取数据集（来自高表达性模式KG）和增强型现有数据集（补充模式信息）的套件，所有数据集支持推理服务与机器学习库张量表示。

Conclusion: 该资源首次实现模式层与事实层融合的数据集构建，为复杂推理与神经符号方法提供真实评估基准，推动知识图谱精化技术向实际应用场景落地。

Abstract: Datasets for the experimental evaluation of knowledge graph refinement algorithms typically contain only ground facts, retaining very limited schema level knowledge even when such information is available in the source knowledge graphs. This limits the evaluation of methods that rely on rich ontological constraints, reasoning or neurosymbolic techniques and ultimately prevents assessing their performance in large-scale, real-world knowledge graphs. In this paper, we present \resource{} the first resource that provides a workflow for extracting datasets including both schema and ground facts, ready for machine learning and reasoning services, along with the resulting curated suite of datasets. The workflow also handles inconsistencies detected when keeping both schema and facts and also leverage reasoning for entailing implicit knowledge. The suite includes newly extracted datasets from KGs with expressive schemas while simultaneously enriching existing datasets with schema information. Each dataset is serialized in OWL making it ready for reasoning services. Moreover, we provide utilities for loading datasets in tensor representations typical of standard machine learning libraries.

</details>


### [242] [World Models for Policy Refinement in StarCraft II](https://arxiv.org/abs/2602.14857)
*Yixin Zhang,Ziyi Wang,Yiming Rong,Haoxi Wang,Jinling Jiang,Shuang Xu,Haoran Wu,Shiyu Zhou,Bo Xu*

Main category: cs.AI

TL;DR: 本文提出StarWM，首个用于星际争霸II的世界模型，通过结构化文本表示预测部分可观测环境下的未来状态，并集成到Generate--Simulate--Refine决策循环中。离线评估显示资源预测准确率提升近60%，在线对抗内置AI时胜率提升30%（LV5）、15%（LV6）和30%（LV7）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂环境决策中表现出色，但现有星际争霸II智能体忽视世界模型的集成，限制了其前瞻规划和动态适应能力。本文旨在填补这一空白，构建可学习、动作条件化的转移模型以提升智能体在部分可观测大规模状态空间中的决策质量。

Method: 1) 提出StarWM世界模型，采用结构化文本表示将观察分解为五个语义模块；2) 构建首个SC2动力学指令调优数据集SC2-Dynamics-50k；3) 开发多维度离线评估框架；4) 设计StarWM-Agent系统，将世界模型嵌入Generate--Simulate--Refine决策循环，通过预测-模拟-优化实现前瞻驱动策略精炼。

Result: 离线实验显示StarWM相比零样本基线在资源预测准确率上提升近60%，宏观态势一致性显著提高；在线评估中，StarWM-Agent对抗内置AI的Hard、Harder、VeryHard难度时，胜率分别提升30%、15%和30%，同时提高了宏观管理稳定性和战术风险评估能力。

Conclusion: 集成世界模型的LLM智能体在复杂部分可观测环境中展现出显著优势，不仅提升即时决策性能，还增强了长期规划的稳定性，证明世界模型是构建更强大游戏AI的关键组件。

Abstract: Large Language Models (LLMs) have recently shown strong reasoning and generalization capabilities, motivating their use as decision-making policies in complex environments. StarCraft II (SC2), with its massive state-action space and partial observability, is a challenging testbed. However, existing LLM-based SC2 agents primarily focus on improving the policy itself and overlook integrating a learnable, action-conditioned transition model into the decision loop. To bridge this gap, we propose StarWM, the first world model for SC2 that predicts future observations under partial observability. To facilitate learning SC2's hybrid dynamics, we introduce a structured textual representation that factorizes observations into five semantic modules, and construct SC2-Dynamics-50k, the first instruction-tuning dataset for SC2 dynamics prediction. We further develop a multi-dimensional offline evaluation framework for predicted structured observations. Offline results show StarWM's substantial gains over zero-shot baselines, including nearly 60% improvements in resource prediction accuracy and self-side macro-situation consistency. Finally, we propose StarWM-Agent, a world-model-augmented decision system that integrates StarWM into a Generate--Simulate--Refine decision loop for foresight-driven policy refinement. Online evaluation against SC2's built-in AI demonstrates consistent improvements, yielding win-rate gains of 30%, 15%, and 30% against Hard (LV5), Harder (LV6), and VeryHard (LV7), respectively, alongside improved macro-management stability and tactical risk assessment.

</details>


### [243] [EmbeWebAgent: Embedding Web Agents into Any Customized UI](https://arxiv.org/abs/2602.14865)
*Chenyang Ma,Clyde Fare,Matthew Wilson,Dave Braines*

Main category: cs.AI

TL;DR: EmbeWebAgent框架通过将智能体直接嵌入现有Web UI（使用ARIA、URL观察和WebSocket函数注册表），配合可复用的后端工作流，实现比传统截图/DOM方式更稳健、更丰富的企业Web自动化


<details>
  <summary>Details</summary>
Motivation: 现有Web智能体基于截图或原始DOM树运行，导致稳健性和动作表现力受限；而在企业环境中，前后端均可控，这为改进提供了机会

Method: 提出EmbeWebAgent框架，采用轻量级前端钩子（精选ARIA属性、URL观察、WebSocket暴露的页面函数注册表）和可复用的后端工作流进行推理和动作，支持从GUI原语到高级复合动作的混合粒度，通过MCP工具协调导航、操作和领域特定分析，且与React/Angular等技术栈无关

Result: 演示表明框架改造工作量极小，并在实时UI环境中实现了稳健的多步行为

Conclusion: 通过在应用层级（而非人机接口层级）嵌入智能体，EmbeWebAgent为企业环境提供了更稳健、更具表现力的Web自动化解决方案

Abstract: Most web agents operate at the human interface level, observing screenshots or raw DOM trees without application-level access, which limits robustness and action expressiveness. In enterprise settings, however, explicit control of both the frontend and backend is available. We present EmbeWebAgent, a framework for embedding agents directly into existing UIs using lightweight frontend hooks (curated ARIA and URL-based observations, and a per-page function registry exposed via a WebSocket) and a reusable backend workflow that performs reasoning and takes actions. EmbeWebAgent is stack-agnostic (e.g., React or Angular), supports mixed-granularity actions ranging from GUI primitives to higher-level composites, and orchestrates navigation, manipulation, and domain-specific analytics via MCP tools. Our demo shows minimal retrofitting effort and robust multi-step behaviors grounded in a live UI setting. Live Demo: https://youtu.be/Cy06Ljee1JQ

</details>


### [244] [Concept Influence: Leveraging Interpretability to Improve Performance and Efficiency in Training Data Attribution](https://arxiv.org/abs/2602.14869)
*Matthew Kowal,Goncalo Paulo,Louis Jaburi,Tom Tseng,Lev E McKinney,Stefan Heimersheim,Aaron David Tucker,Adam Gleave,Kellin Pelrine*

Main category: cs.AI

TL;DR: 针对大型语言模型训练数据归因问题，本文提出"概念影响"方法，通过语义方向而非单个测试样本来归因模型行为，比传统影响函数方法快一个数量级且性能相当。


<details>
  <summary>Details</summary>
Motivation: 随着LLM广泛应用，需要识别训练数据中哪些部分导致特定（尤其是意外）行为。现有影响函数方法计算成本高，且基于单个测试样本的归因会偏向语法而非语义相似性，存在可扩展性问题。

Method: 1) 引入"概念影响"，将模型行为归因到语义方向（如线性探针或稀疏自编码器特征）；2) 证明基于探针的简单归因方法是概念影响的一阶近似，速度更快。

Result: 在突发性错误对齐基准测试和真实后训练数据集上验证，概念影响及其近似方法性能与经典影响函数相当，但可扩展性显著更好，速度提升超过10倍。

Conclusion: 在TDA流程中融入可解释结构，可以实现对模型行为更 scalable、可解释和可控的数据管理。

Abstract: As large language models are increasingly trained and fine-tuned, practitioners need methods to identify which training data drive specific behaviors, particularly unintended ones. Training Data Attribution (TDA) methods address this by estimating datapoint influence. Existing approaches like influence functions are both computationally expensive and attribute based on single test examples, which can bias results toward syntactic rather than semantic similarity. To address these issues of scalability and influence to abstract behavior, we leverage interpretable structures within the model during the attribution. First, we introduce Concept Influence which attribute model behavior to semantic directions (such as linear probes or sparse autoencoder features) rather than individual test examples. Second, we show that simple probe-based attribution methods are first-order approximations of Concept Influence that achieve comparable performance while being over an order-of-magnitude faster. We empirically validate Concept Influence and approximations across emergent misalignment benchmarks and real post-training datasets, and demonstrate they achieve comparable performance to classical influence functions while being substantially more scalable. More broadly, we show that incorporating interpretable structure within traditional TDA pipelines can enable more scalable, explainable, and better control of model behavior through data.

</details>


### [245] [Lifted Relational Probabilistic Inference via Implicit Learning](https://arxiv.org/abs/2602.14890)
*Luise Ge,Brendan Juba,Kris Nilsson,Alison Shao*

Main category: cs.AI

TL;DR: 首个多项式时间框架，通过SOS层次结构结合 grounding-lift 和 world-lift 技术，隐式学习一阶概率逻辑并在个体和世界层面执行提升推理


<details>
  <summary>Details</summary>
Motivation: 调和一阶关系领域中归纳学习与演绎推理的张力是AI长期挑战。传统提升推理需要完整模型，但从部分噪声观测中学习此类模型通常难以处理。

Method: 将不完整的一阶公理与部分观测样本合并到受限阶次的平方和(SOS)层次结构中，在多项式时间内执行两次提升：grounding-lift（通过变量共享压缩个体域）和world-lift（并行执行所有伪模型以生成全局边界）。

Result: 该框架隐式学习一阶概率逻辑，并在个体和世界两个层面执行提升推理。

Conclusion: 这是首个多项式时间框架，实现了隐式学习与提升推理的结合，为关系概率逻辑中学习与推理的联合问题提供了高效解决方案。

Abstract: Reconciling the tension between inductive learning and deductive reasoning in first-order relational domains is a longstanding challenge in AI. We study the problem of answering queries in a first-order relational probabilistic logic through a joint effort of learning and reasoning, without ever constructing an explicit model. Traditional lifted inference assumes access to a complete model and exploits symmetry to evaluate probabilistic queries; however, learning such models from partial, noisy observations is intractable in general. We reconcile these two challenges through implicit learning to reason and first-order relational probabilistic inference techniques. More specifically, we merge incomplete first-order axioms with independently sampled, partially observed examples into a bounded-degree fragment of the sum-of-squares (SOS) hierarchy in polynomial time. Our algorithm performs two lifts simultaneously: (i) grounding-lift, where renaming-equivalent ground moments share one variable, collapsing the domain of individuals; and (ii) world-lift, where all pseudo-models (partial world assignments) are enforced in parallel, producing a global bound that holds across all worlds consistent with the learned constraints. These innovations yield the first polynomial-time framework that implicitly learns a first-order probabilistic logic and performs lifted inference over both individuals and worlds.

</details>


### [246] [The Potential of CoT for Reasoning: A Closer Look at Trace Dynamics](https://arxiv.org/abs/2602.14903)
*Gregor Bachmann,Yichen Jiang,Seyed Mohsen Moosavi Dezfooli,Moin Nabi*

Main category: cs.AI

TL;DR: This paper analyzes competition-level math reasoning traces from LLMs to understand how Chain-of-thought prompting works, introducing a "potential" metric to quantify each step's contribution and discovering that only 20% of CoT from stronger models can significantly boost weaker models' performance.


<details>
  <summary>Details</summary>
Motivation: Despite Chain-of-thought prompting being a standard technique for eliciting reasoning from LLMs, the underlying mechanisms driving its success remain largely unclear. We lack understanding of which specific parts of CoT actually contribute to final answer correctness.

Method: We performed in-depth analysis of CoT traces from competition-level mathematics questions, introducing a "potential" metric that quantifies how much each CoT segment increases the likelihood of correct completion. We also investigated CoT transferability by measuring weaker models' performance using partial CoT from stronger models.

Result: Key findings include: (1) Potential shows strong non-monotonicity due to reasoning tangents; (2) Sharp spikes correspond to reasoning insights/jumps; (3) Some cases show lucky guesses without relevant justification; (4) Critically, as little as 20% of partial CoT from stronger models can unlock weaker models' performance on previously unsolvable problems.

Conclusion: A large portion of CoT mechanics are transferable across models, with key insights concentrated in minimal critical segments rather than the entire reasoning chain. This reveals that CoT success depends on sparse, high-impact reasoning steps rather than comprehensive step-by-step elaboration.

Abstract: Chain-of-thought (CoT) prompting is a de-facto standard technique to elicit reasoning-like responses from large language models (LLMs), allowing them to spell out individual steps before giving a final answer. While the resemblance to human-like reasoning is undeniable, the driving forces underpinning the success of CoT reasoning still remain largely unclear. In this work, we perform an in-depth analysis of CoT traces originating from competition-level mathematics questions, with the aim of better understanding how, and which parts of CoT actually contribute to the final answer. To this end, we introduce the notion of a potential, quantifying how much a given part of CoT increases the likelihood of a correct completion. Upon examination of reasoning traces through the lens of the potential, we identify surprising patterns including (1) its often strong non-monotonicity (due to reasoning tangents), (2) very sharp but sometimes tough to interpret spikes (reasoning insights and jumps) as well as (3) at times lucky guesses, where the model arrives at the correct answer without providing any relevant justifications before. While some of the behaviours of the potential are readily interpretable and align with human intuition (such as insights and tangents), others remain difficult to understand from a human perspective. To further quantify the reliance of LLMs on reasoning insights, we investigate the notion of CoT transferability, where we measure the potential of a weaker model under the partial CoT from another, stronger model. Indeed aligning with our previous results, we find that as little as 20% of partial CoT can ``unlock'' the performance of the weaker model on problems that were previously unsolvable for it, highlighting that a large part of the mechanics underpinning CoT are transferable.

</details>


### [247] [Position: Introspective Experience from Conversational Environments as a Path to Better Learning](https://arxiv.org/abs/2602.14910)
*Claudiu Cristian Musat,Jackson Tolins,Diego Antognini,Jingling Li,Martin Klissarov,Tom Duerig*

Main category: cs.AI

TL;DR: This paper argues that AI reasoning emerges not from scale but from linguistic self-reflection internalized from high-quality social interaction, positioning dialogue quality as critical for developing general intelligence.


<details>
  <summary>Details</summary>
Motivation: Current AI training treats reasoning as an emergent property of scale, potentially missing how social interaction and introspection enable robust reasoning.

Method: Drawing on Vygotskian psychology, they advance three theoretical positions about introspection: social genesis of private mind, dialogical sense-making, and dialogue quality as data quality.

Result: They establish that conversational scaffolds, alignment friction, and dialogue diversity fundamentally determine reasoning depth and test-time compute efficiency.

Conclusion: Optimizing conversational scaffolds is the primary lever for next-generation general intelligence.

Abstract: Current approaches to AI training treat reasoning as an emergent property of scale. We argue instead that robust reasoning emerges from linguistic self-reflection, itself internalized from high-quality social interaction. Drawing on Vygotskian developmental psychology, we advance three core positions centered on Introspection. First, we argue for the Social Genesis of the Private Mind: learning from conversational environments rises to prominence as a new way to make sense of the world; the friction of aligning with another agent, internal or not, refines and crystallizes the reasoning process. Second, we argue that dialogically scaffolded introspective experiences allow agents to engage in sense-making that decouples learning from immediate data streams, transforming raw environmental data into rich, learnable narratives. Finally, we contend that Dialogue Quality is the New Data Quality: the depth of an agent's private reasoning, and its efficiency regarding test-time compute, is determined by the diversity and rigor of the dialogues it has mastered. We conclude that optimizing these conversational scaffolds is the primary lever for the next generation of general intelligence.

</details>


### [248] [ReusStdFlow: A Standardized Reusability Framework for Dynamic Workflow Construction in Agentic AI](https://arxiv.org/abs/2602.14922)
*Gaoyang Zhang,Shanghong Zou,Yafang Wang,He Zhang,Ruohua Xu,Feng Zhao*

Main category: cs.AI

TL;DR: 提出ReusStdFlow框架解决企业智能体AI的"可重用性困境"和结构幻觉问题，通过提取-存储-构建范式将平台特定的DSL转换为标准化工作流，结合图向量双知识库和RAG策略实现智能组装，在200个真实n8n工作流上取得90%以上准确率。


<details>
  <summary>Details</summary>
Motivation: 企业智能体AI面临"可重用性困境"和结构幻觉问题，现有异构平台特定的领域特定语言(DSL)导致数字资产难以标准化重组和高效重用。

Method: 提出ReusStdFlow框架，采用"提取-存储-构建"新范式：将异构DSL解构为标准化模块化工作流片段；设计图数据库与向量数据库结合的双知识架构协同检索拓扑结构和功能语义；最后通过检索增强生成(RAG)策略智能组装工作流。

Result: 在200个真实n8n工作流测试中，系统在提取和构建环节均达到超过90%的准确率。

Conclusion: 该框架为企业数字资产的自动化重组和高效重用提供了标准化解决方案，有效解决了企业智能体AI的可重用性挑战。

Abstract: To address the ``reusability dilemma'' and structural hallucinations in enterprise Agentic AI,this paper proposes ReusStdFlow, a framework centered on a novel ``Extraction-Storage-Construction'' paradigm. The framework deconstructs heterogeneous, platform-specific Domain Specific Languages (DSLs) into standardized, modular workflow segments. It employs a dual knowledge architecture-integrating graph and vector databases-to facilitate synergistic retrieval of both topological structures and functional semantics. Finally, workflows are intelligently assembled using a retrieval-augmented generation (RAG) strategy. Tested on 200 real-world n8n workflows, the system achieves over 90% accuracy in both extraction and construction. This framework provides a standardized solution for the automated reorganization and efficient reuse of enterprise digital assets.

</details>


### [249] [MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design](https://arxiv.org/abs/2602.14926)
*Gen Zhou,Sugitha Janarthanan,Lianghong Chen,Pingzhao Hu*

Main category: cs.AI

TL;DR: 提出MAC-AMP多智能体协作系统，通过闭环强化学习框架实现抗菌肽的多目标优化设计，突破传统AI模型的黑箱局限。


<details>
  <summary>Details</summary>
Motivation: 抗菌耐药性威胁全球健康，现有AI抗菌肽设计模型难以平衡活性、毒性和新颖性等多重目标，且采用僵化的评分方法导致结果不透明、难优化，缺乏可解释性。

Method: 构建基于大语言模型的多智能体闭环协作系统，采用模拟同行评议-自适应强化学习框架，仅需任务描述和示例数据集即可自主设计新颖抗菌肽。

Result: 实验表明MAC-AMP显著优于其他抗菌肽生成模型，在抗菌活性、类抗菌肽特性、毒性合规性和结构可靠性等多重属性上实现协同优化。

Conclusion: 该系统实现了可解释的多目标抗菌肽设计，具有跨领域迁移能力，为复杂分子设计提供了新范式，超越了传统黑箱模型的限制。

Abstract: To address the global health threat of antimicrobial resistance, antimicrobial peptides (AMP) are being explored for their potent and promising ability to fight resistant pathogens. While artificial intelligence (AI) is being employed to advance AMP discovery and design, most AMP design models struggle to balance key goals like activity, toxicity, and novelty, using rigid or unclear scoring methods that make results hard to interpret and optimize. As the capabilities of Large Language Models (LLM) advance and evolve swiftly, we turn to AI multi-agent collaboration based on such models (multi-agent LLMs), which show rapidly rising potential in complex scientific design scenarios. Based on this, we introduce MAC-AMP, a closed-loop multi-agent collaboration (MAC) system for multi-objective AMP design. The system implements a fully autonomous simulated peer review-adaptive reinforcement learning framework that requires only a task description and example dataset to design novel AMPs. The novelty of our work lies in introducing a closed-loop multi-agent system for AMP design, with cross-domain transferability, that supports multi-objective optimization while remaining explainable rather than a 'black box'. Experiments show that MAC-AMP outperforms other AMP generative models by effectively optimizing AMP generation for multiple key molecular properties, demonstrating exceptional results in antibacterial activity, AMP likeliness, toxicity compliance, and structural reliability.

</details>


### [250] [On the Semantics of Primary Cause in Hybrid Dynamic Domains](https://arxiv.org/abs/2602.14994)
*Shakil M. Khan,Asim Mehmood,Sandra Zilles*

Main category: cs.AI

TL;DR: 本文针对混合系统（离散+连续变化）提出两种等价的主要因果定义，一种为基础性定义，另一种基于贡献并通过改进的"but-for"测试从反事实角度验证，弥补了形式因果理论中的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管因果推理研究可追溯至亚里士多德，但现有研究未能充分处理变化兼具离散性和连续性的混合系统。当前实际因果关系的形式化研究主要关注离散变化，在理解更真实的混合场景因果关系方面存在空白。

Method: 作者在混合时序情境演算框架内提出两种主要因果定义：一种为基础性/理论性定义，另一种通过贡献形式化因果关系，并使用改进的反事实"but-for"测试进行验证。

Result: 论文证明了两种定义的确等价，并展示了这些定义具有直观上合理的性质，验证了其理论正确性。

Conclusion: 所提出的定义为混合系统中关于实际因果关系的推理提供了严格基础，弥合了离散与连续变化形式化之间的差距，同时提供了理论深度和实践验证方法。

Abstract: Reasoning about actual causes of observed effects is fundamental to the study of rationality. This important problem has been studied since the time of Aristotle, with formal mathematical accounts emerging recently. We live in a world where change due to actions can be both discrete and continuous, that is, hybrid. Yet, despite extensive research on actual causation, only few recent studies looked into causation with continuous change. Building on recent progress, in this paper we propose two definitions of primary cause in a hybrid action-theoretic framework, namely the hybrid temporal situation calculus. One of these is foundational in nature while the other formalizes causation through contributions, which can then be verified from a counterfactual perspective using a modified ``but-for'' test. We prove that these two definitions are indeed equivalent. We then show that our definitions of causation have some intuitively justifiable properties.

</details>


### [251] [Hunt Globally: Deep Research AI Agents for Drug Asset Scouting in Investing, Business Development, and Search & Evaluation](https://arxiv.org/abs/2602.15019)
*Alisa Vinogradova,Vlad Vinogradov,Luba Greenwood,Ilya Yasny,Dmitry Kobyzev,Shoman Kasbekar,Kong Nguyen,Dmitrii Radkevich,Roman Doronin,Andrey Doronichev*

Main category: cs.AI

TL;DR: 该论文针对生物制药创新日益全球化、非美资产占比激增（中国占全球专利近半、药物研发约30%）的现状，提出一种新型AI药物资产侦察基准测试方法和"Bioptic Agent"树形自学习智能体，以解决现有Deep Research AI在多语言、异构来源中漏检率高、易产生幻觉的问题。该智能体在严格的多语言基准测试中F1值达79.7%，远超Claude Opus 4.6（56.2%）、GPT-5.2 Pro（46.6%）等主流模型，且性能随算力提升而显著改善。


<details>
  <summary>Details</summary>
Motivation: 生物制药创新正从美国向全球转移，超85%专利 filings 来自美国之外（中国占全球近一半），中国占全球药物研发约30%。漏掉这些"雷达外"资产会给投资者和业务发展团队带来数十亿美元风险。然而现有Deep Research AI在多语言、异构来源的高召回发现方面仍落后于人类专家，且存在幻觉问题。

Method: 提出药物资产侦察基准测试方法论，开发"Bioptic Agent"——一种调优的基于树结构的自学习智能体。构建多语言多智能体管道创建高挑战性完整性基准：收集专业投资者、BD和VC人员的筛选查询作为先验条件生成基准查询，使用LLM-as-judge评估（校准至专家意见）。对比测试Bioptic Agent与Claude Opus 4.6、GPT-5.2 Pro、Perplexity Deep Research、Gemini 3 Pro + Deep Research、Exa Websets等模型。

Result: Bioptic Agent在F1分数上达到79.7%，显著优于所有对比模型：Claude Opus 4.6（56.2%）、Gemini 3 Pro + Deep Research（50.6%）、GPT-5.2 Pro（46.6%）、Perplexity Deep Research（44.2%）、Exa Websets（26.9%）。性能随算力增加而大幅提升。

Conclusion: Bioptic Agent在多语言、非美中心的药物资产侦察任务中展现出显著优势，验证了树形自学习架构的有效性。结果支持"更多算力带来更好效果"的观点，为高 stakes 投资决策提供了更可靠的AI工具。

Abstract: Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests >85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total; a growing share of scholarly output is also non-U.S. Industry estimates put China at ~30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing to surface "under-the-radar" assets creates multi-billion-dollar risk for investors and business development teams, making asset scouting a coverage-critical competition where speed and completeness drive value. Yet today's Deep Research AI agents still lag human experts in achieving high-recall discovery across heterogeneous, multilingual sources without hallucinations.
  We propose a benchmarking methodology for drug asset scouting and a tuned, tree-based self-learning Bioptic Agent aimed at complete, non-hallucinated scouting. We construct a challenging completeness benchmark using a multilingual multi-agent pipeline: complex user queries paired with ground-truth assets that are largely outside U.S.-centric radar. To reflect real deal complexity, we collected screening queries from expert investors, BD, and VC professionals and used them as priors to conditionally generate benchmark queries. For grading, we use LLM-as-judge evaluation calibrated to expert opinions. We compare Bioptic Agent against Claude Opus 4.6, OpenAI GPT-5.2 Pro, Perplexity Deep Research, Gemini 3 Pro + Deep Research, and Exa Websets. Bioptic Agent achieves 79.7% F1 versus 56.2% (Claude Opus 4.6), 50.6% (Gemini 3 Pro + Deep Research), 46.6% (GPT-5.2 Pro), 44.2% (Perplexity Deep Research), and 26.9% (Exa Websets). Performance improves steeply with additional compute, supporting the view that more compute yields better results.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [252] [NP-hardness of p-adic linear regression](https://arxiv.org/abs/2602.13278)
*Gregory D. Baker*

Main category: cs.CC

TL;DR: 本研究证明了p-adic线性回归问题（最小化Σ|y_i - x_i^T β|_p）是NP难问题，通过从Max Cut问题的多项式时间归约，利用正则化装置实现


<details>
  <summary>Details</summary>
Motivation: p-adic数在数论和数学物理中具有重要地位，研究其线性回归模型的计算复杂性对于理解非阿基米德优化问题在统计学和机器学习中的可行性至关重要

Method: 采用多项式时间归约技术，将经典NP难问题Max Cut转化为p-adic线性回归实例，并设计正则化装置确保归约的正确性

Result: 证明了计算p-adic线性回归的最优解是NP难问题，揭示了其计算复杂性下界

Conclusion: p-adic线性回归在一般情况下是计算不可行的，这意味着需要开发近似算法或启发式方法来实际求解，同时丰富了非阿基米德分析中的复杂性理论

Abstract: $p$-adic linear regression is the problem of finding coefficients $β$ that minimise $\sum_i |y_i - x_i^\topβ|_p$. We prove that computing an optimal solution is NP-hard via a polynomial-time reduction from Max Cut using a regularisation gadget.

</details>


### [253] [An Algebraic Rigidity Framework for Order-Oblivious Deterministic Black-Box PIT of ROABPs](https://arxiv.org/abs/2602.13449)
*Shalender Singh,Vishnupriya Singh*

Main category: cs.CC

TL;DR: 首次实现无需变量顺序的确定性黑盒多项式恒等测试(PIT)，通过代数刚性框架将ROABPs的自由度压缩至w²维，获得拟多项式时间算法；提出模稳定性猜想，若成立可实现完全多项式时间。


<details>
  <summary>Details</summary>
Motivation: 确定性黑盒多项式恒等测试(PIT)是代数复杂性的核心难题，尤其当read-once oblivious代数分支程序(ROABPs)缺乏变量顺序信息时。现有确定性算法或依赖顺序信息，或需高开销的组合隔离技术。

Method: 提出基于矩阵词代数内部结构的代数刚性框架：证明非零宽度-w ROABPs诱导的词代数有效代数自由度坍缩至w²维（与变量数无关），利用内在代数不变量构造确定性见证，绕过传统秩集中、隔离引理和概率工具。

Result: 1) 首个无视顺序的确定性黑盒PIT算法，时间复杂度n·(wd)^O(w²)；2) 提出模稳定性猜想：当模数超过w和单项式次数的多项式阈值时，宽度-w ROABPs在循环商环K[λ]/<λ^r-1>下保持稳定。

Conclusion: 代数刚性本身足以实现该模型的PIT去随机化；若模稳定性猜想成立，则算法可优化至完全多项式时间，使黑盒问题复杂度匹配最优白盒算法，并将核心挑战归结为具体代数稳定性问题。

Abstract: Deterministic black-box polynomial identity testing (PIT) for read-once oblivious algebraic branching programs (ROABPs) is a central open problem in algebraic complexity, particularly in the absence of variable ordering. Prior deterministic algorithms either rely on order information or incur significant overhead through combinatorial isolation techniques.
  In this paper, we introduce an algebraic rigidity framework for ROABPs based on the internal structure of their associated matrix word algebras. We show that nonzero width-$w$ ROABPs induce word algebras whose effective algebraic degrees of freedom collapse to dimension at most $w^2$, independent of the number of variables. This rigidity enables deterministic witness construction via intrinsic algebraic invariants, bypassing rank concentration, isolation lemmas, and probabilistic tools used in previous work.Thus, we obtain the first order-oblivious deterministic black-box PIT algorithm for ROABPs, running in quasi-polynomial time $n\cdot(wd)^{O(w^2)}$. This establishes that algebraic rigidity alone suffices to derandomize PIT in this model, without assuming ordering information.
  The framework further isolates a single remaining obstacle to full polynomial-time complexity. We formulate a Modular Stability Conjecture, asserting that width-$w$ ROABPs are stable under hashing into cyclic quotient rings $\mathbb{K}[λ]/< λ^r-1 >$ once the modulus exceeds a polynomial threshold in $w$ and the individual degree. This conjecture arises naturally from the low-dimensional coefficient structure revealed by rigidity and is supported by extensive empirical evidence.
  Assuming the conjecture, our methods yield a fully polynomial-time deterministic black-box PIT algorithm for ROABPs, matching the complexity of the best-known white-box algorithms and reducing the black-box problem to a concrete algebraic stability question.

</details>


### [254] [Affine Rank Minimization is ER Complete](https://arxiv.org/abs/2602.14037)
*Angshul Majumdar*

Main category: cs.CC

TL;DR: 证明了仿射秩最小化问题 ARM(k) 在固定秩 k ≥ 1 时是实数存在理论（∃ℝ）完全的，特别是 ARM(3) 也是完全的，揭示了纯仿射约束在固定常数秩限制下具有实数代数可行性的全部表达能力。


<details>
  <summary>Details</summary>
Motivation: 仿射秩最小化是优化理论中的基础问题，在控制论、统计学等领域有广泛应用。该研究旨在确定此类问题的计算复杂性，并探索其与实数代数系统求解能力之间的深层联系。

Method: 1) 成员性证明：通过常数规模的因子分解见证（X=UV^T）显式编码秩约束，将 ARM(k) 归约到实数存在理论；2) 困难性证明：从实数存在理论（ETR）多项式时间多一归约，将 ETR 公式编译为算术电路并映射到矩阵元素，使用线性约束强制仿射语义，设计常数规模的秩强制 gadget 实现乘法语义，通过固定秩的 gauge 子矩阵确保可靠性，并证明组合引理避免 gadget 间干扰。

Result: - 对任意固定 k ≥ 1，ARM(k) 是 ∃ℝ-完全的
- ARM(3) 是 ∃ℝ-完全的
- 维度与位长保持多项式有界
- 纯仿射约束+常数秩限制 = 实数代数可行性问题的完整表达能力

Conclusion: 该结果建立了低秩矩阵可行性问题与实数代数系统求解的根本等价性，为理解秩约束优化问题的计算复杂性提供了新视角，并暗示任何实数多项式系统均可转化为等价的低秩矩阵线性约束系统。

Abstract: We study the decision problem Affine Rank Minimization, denoted ARM(k). The input consists of rational matrices A_1,...,A_q in Q^{m x n} and rational scalars b_1,...,b_q in Q. The question is whether there exists a real matrix X in R^{m x n} such that trace(A_l^T X) = b_l for all l in {1,...,q} and rank(X) <= k. We first prove membership: for every fixed k >= 1, ARM(k) lies in the existential theory of the reals by giving an explicit existential encoding of the rank constraint using a constant-size factorization witness. We then prove existential-theory-of-reals hardness via a polynomial-time many-one reduction from ETR to ARM(k), where the target instance uses only affine equalities together with a single global constraint rank(X) <= k. The reduction compiles an ETR formula into an arithmetic circuit in gate-equality normal form and assigns each circuit quantity to a designated entry of X. Affine semantics (constants, copies, addition, and negation) are enforced by linear constraints, while multiplicative semantics are enforced by constant-size rank-forcing gadgets. Soundness is certified by a fixed-rank gauge submatrix that removes factorization ambiguity. We prove a composition lemma showing that gadgets can be embedded without unintended interactions, yielding global soundness and completeness while preserving polynomial bounds on dimension and bit-length. Consequently, ARM(k) is complete for the existential theory of the reals; in particular, ARM(3) is complete. This shows that feasibility of purely affine constraints under a fixed constant rank bound captures the full expressive power of real algebraic feasibility.

</details>


### [255] [Graph Homomorphisms and Universal Algebra](https://arxiv.org/abs/2602.14243)
*Manuel Bodirsky*

Main category: cs.CC

TL;DR: 本课程介绍用泛代数方法研究有限域约束满足问题（CSP）的计算复杂性，重点探讨多项式时间可解与NP难问题的边界，通过图同态等直观案例引入循环项和有界宽度定理。


<details>
  <summary>Details</summary>
Motivation: 约束满足问题是理论计算机科学的核心问题，其计算复杂性（尤其是多项式时间与NP难问题的分界）是重要研究方向，需系统化方法揭示问题本质。

Method: 采用泛代数方法，从有向图与图同态问题等具体案例切入，逐步引入循环项理论及有界宽度定理，建立有限域CSP的复杂性分析框架。

Result: 构建了从具体图论问题到抽象代数分析的桥梁，阐明了循环项与有界宽度在刻画CSP复杂性分类中的关键作用，提供了可操作的复杂性判定工具。

Conclusion: 泛代数方法能有效揭示CSP的复杂性边界，通过可访问的教学路径（图论示例→代数理论）为研究NP难问题与多项式时间可解性提供了统一范式。

Abstract: Constraint satisfaction problems are computational problems that naturally appear in many areas of theoretical computer science. One of the central themes is their computational complexity, and in particular the border between polynomial-time tractability and NP-hardness. In this course we introduce the universal-algebraic approach to study the computational complexity of finite-domain CSPs. The course covers in particular the cyclic terms and bounded width theorems. To keep the presentation accessible, we start the course in the tangible setting of directed graphs and graph homomorphism problems.

</details>


### [256] [The antiferromagnetic Ising model beyond line graphs](https://arxiv.org/abs/2602.14915)
*Mark Jerrum*

Main category: cs.CC

TL;DR: 对比反铁磁Ising模型和硬核模型在图结构上的可处理性范围，发现硬核模型可扩展至无爪图而Ising模型不可


<details>
  <summary>Details</summary>
Motivation: 探究两类经典模型（反铁磁Ising模型和硬核模型）在图结构上的计算可处理性边界，特别是超越线图后的扩展能力

Method: 通过图论分析与Glauber动力学混合时间研究，对比两类模型在不同图类（线图/无爪图）上的算法行为

Result: 硬核模型的可处理性可延伸至无爪图及更广图类，而反铁磁Ising模型在该扩展中失效

Conclusion: 两类模型虽在线图上均表现良好，但可处理性存在本质差异，Ising模型的扩展局限性揭示了更严格的图结构约束

Abstract: Both the antiferromagnetic Ising model and the hard-core model could be said to be tractable on line graphs of bounded degree. For example, Glauber dynamics is rapidly mixing in both cases. In the case of the hard-core model, we know that tractability extends further, to claw-free graphs and somewhat beyond. In contrast, it is shown here that the corresponding extensions are not possible in the case of the antiferromagnetic Ising model.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [257] [No-Go Theorem on Fault Tolerant Gadgets for Multiple Logical Qubits](https://arxiv.org/abs/2602.13395)
*Aranya Chakraborty,Daniel Gottesman*

Main category: quant-ph

TL;DR: 该论文证明了在稳定子码中，无法通过全横向、折迭横向或代码自同构等简单架构，对多个逻辑量子比特实现完整的逻辑Clifford群容错操作，这为容错量子计算设置了根本性限制。


<details>
  <summary>Details</summary>
Motivation: 为了实现容错量子计算，需要找出能够完整实现逻辑Clifford群的稳定子码。尽管单个逻辑量子比特的代码（如[[7,1,3]] Steane码）已知可以实现全横向Clifford群操作，但多逻辑量子比特的情况仍是未知的。

Method: 通过建立无定理(no-go theorem)，研究三类容错小工具构造：横向小工具、代码自同构和折迭横向小工具。引入k-折迭横向小工具概念，并进行一般性证明分析。

Result: 1) 证明没有任何稳定子码能对超过一个逻辑量子比特实现全横向Clifford群操作；2) 证明对超过两个逻辑量子比特无法实现折迭横向Clifford群操作；3) 证明对k个逻辑量子比特实现完整Clifford群至少需要k-折迭横向小工具；4) 证明基于代码自同构的构造也无法实现多逻辑量子比特的完整Clifford群。

Conclusion: 这些结果对容错Clifford小工具设计构成了根本性限制，表明在单一代码块中编码多个逻辑量子比特的稳定子码无法通过这些简单架构支持完整的逻辑Clifford群。由于Clifford群是通用门组的核心组件，这意味着多逻辑量子比特量子计算必然需要更复杂的容错构造。

Abstract: Identifying stabilizer codes that admit fault-tolerant implementations of the full logical Clifford group would significantly advance fault-tolerant quantum computation. Motivated by this goal, we study several classes of fault-tolerant gadget constructions consisting of Clifford gates acting on the physical qubits, including transversal gadgets, code automorphisms, and fold-transversal gadgets. While stabilizer codes encoding a single logical qubit, most notably the [[7,1,3]] Steane code, are known to admit transversal implementations of the full logical Clifford group, no analogous examples are known for codes encoding multiple logical qubits. In this work, we prove a no-go theorem establishing that no stabilizer code admits a fully transversal implementation of the Clifford group on more than one logical qubit. We further strengthen this result by showing that fold-transversal implementations of the full logical Clifford group are impossible for stabilizer codes encoding more than two logical qubits. More generally, we introduce the notion of k-fold transversal gadgets and prove that implementing the full Clifford group on k logical qubits requires at least k-fold transversal gadgets at the physical level. In addition, we analyze code-automorphism based constructions and demonstrate that they also fail to realize the full Clifford group on multiple logical qubits for any stabilizer code. Together, these results place fundamental constraints on fault-tolerant Clifford gadget design and show that stabilizer codes supporting the full logical Clifford group on multiple logical qubits via these architectures do not exist. Since the Clifford group is a core component of universal gate sets, our findings imply that quantum computing with codes encoding multiple logical qubits within a single code block necessarily entails more complex constructions for fault tolerance.

</details>


### [258] [Quantum Algorithm Framework for Phase-Contrast Transmission Electron Microscopy Image Simulation](https://arxiv.org/abs/2602.13438)
*Sean D. Lam,Roberto dos Reis*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a quantum algorithmic framework for simulating phase-contrast transmission electron microscopy (CTEM) image formation using a fault-tolerant, gate-based quantum circuit model. The electron wavefield on an $N\times N$ grid is amplitude-encoded into a $2\log_2 N$-qubit register. Free-space propagation and objective-lens aberrations are implemented via two-dimensional quantum Fourier transforms (QFTs) and diagonal phase operators in reciprocal space, while specimen interaction is modeled under the weak phase object approximation (WPOA) as a position-dependent phase grating. We validate projected potentials, contrast transfer function (CTF) behavior, and image contrast trends against classical multislice simulations for MoS$_2$ over experimentally relevant parameters, and provide resource estimates and key assumptions that determine end-to-end runtime. While extracting complete $N\times N$ intensity images requires $O(N^2/ε^2)$ measurements that preclude advantage for full-image reconstruction, the framework enables quantum advantage for tasks requiring Fourier-space queries, global image statistics, or phase-coherent observables inaccessible to classical intensity-only detection. This framework provides a physics-grounded mapping from CTEM theory to quantum circuits and establishes a baseline for extending toward full multislice and inelastic scattering models.

</details>


### [259] [Protection of Exponential Operation using Stabilizer Codes in the Early Fault Tolerance Era](https://arxiv.org/abs/2602.13399)
*Dawei Zhong,Todd A. Brun*

Main category: quant-ph

TL;DR: 研究人员开发了一种系统性的方案，将指数映射编码到稳定子码中，在早期容错量子计算时代实现低开销、简单电路结构的量子错误抑制，在现有设备噪声水平下比未编码操作降噪4-7倍。


<details>
  <summary>Details</summary>
Motivation: 量子纠错虽能抑制量子处理器错误，但在早期容错量子计算时代，保护逻辑操作（特别是非Clifford操作）需要大量资源，这对实现实用量子优势构成重大挑战。

Method: 开发系统性方案，将形如exp(-iθP)的指数映射编码到稳定子码中，采用简单电路结构和低量子比特开销，针对多种量子错误检测/纠正码（如[[5,1,3]]、[[7,1,3]]、[[15,7,3]]等）设计编码电路。

Result: 在现有设备噪声水平下，编码方案比未编码操作的噪声降低4-7倍，且最多只需丢弃3%的运行结果。

Conclusion: 该编码方案为早期容错量子计算时代提供了一种资源高效的量子错误抑制方法，有望促进实用量子优势的实现。

Abstract: Quantum error correction offers a promising path to suppress errors in quantum processors, but the resources required to protect logical operations from noise, especially non-Clifford operations, pose a substantial challenge to achieve practical quantum advantage in the early fault-tolerant quantum computing (EFTQC) era. In this work, we develop a systematic scheme to encode exponential maps of the form $\exp(-iθP)$ into stabilizer codes with simple circuit structures and low qubit overhead. We provide encoded circuits with small first-order logical error rate after postselection for the [[n, n-2, 2]] quantum error-detecting codes and the [[5, 1, 3]], [[7, 1, 3]], and [[15, 7, 3]] quantum error-correcting codes. Detailed analysis shows that under the level of physical noise of current devices, our encoding scheme is 4--7 times less noisy than the unencoded operation, while at most 3% of runs need to be discarded.

</details>


### [260] [On the Redfield and Lindblad master equations](https://arxiv.org/abs/2602.13429)
*Hans C. Fogedby*

Main category: quant-ph

TL;DR: 本研究解决了开放量子系统理论中的未解决问题：通过施加能量守恒条件，在Born近似层级修正了Redfield方程，使其与Lindblad方程形式等价，而无需使用旋转波近似。


<details>
  <summary>Details</summary>
Motivation: 解决之前工作中遗留的问题：标准Redfield方程由于不构成合法的量子映射而存在差异，该差异与图解展开和准粒子近似中的一致性要求有关。

Method: 采用多振子浴模型、Dyson方程、图解展开和准粒子近似，在Born近似基础上，通过施加能量守恒条件来修正Redfield方程。

Result: 获得了能量守恒Redfield方程与Lindblad方程之间的形式等价性，且无需引入旋转波近似，提供了场论方法与标准微观推导之间的详细映射。

Conclusion: 通过强制能量守恒，明确解决了Redfield方程中的差异问题，建立了不同理论方法之间的等价关系，为开放量子系统的理论研究提供了更一致的基础。

Abstract: In a previous work we developed a field theoretical approach to open quantum systems using condensed matter methods. In the Born approximation we derived the Redfield equation on the basis of a multi-oscillator bath, a Dyson equation, a diagrammatic expansion and a quasi-particle approximation. In addition applying a rotating wave approximation we obtained the Lindblad equation describing a proper quantum map. The issue regarding the additional rotating wave approximation was left as an open problem.
  The present work addresses the open problem and presents new results. We identify a discrepancy in the popular and standard Redfield equation. The discrepancy is associated with the well-known fact that the Redfield equation does not represent a proper quantum map. The discrepancy is related to the diagrammatic expansion and a consistency requirement in the quasi-particle approximation. The explicit resolution of this discrepancy is obtained by imposing energy conservation on the Born level. As a result we obtain formal equivalence between the energy-conserving Redfield equation and the Lindblad equation without invoking the rotating wave approximation. We provide a detailed mapping of the field theoretical approach to the standard microscopic derivation in the theory of open quantum systems.

</details>


### [261] [Boundary conditions for the Schrödinger equation in the numerical simulation of quantum systems](https://arxiv.org/abs/2602.14654)
*Marco Patriarca*

Main category: quant-ph

TL;DR: 提出一种新方法，通过在小规模数值晶格上模拟开放量子系统，解决因不确定性原理导致的边界条件难题，避免平面波模拟的困难并保持物理图像对应。


<details>
  <summary>Details</summary>
Motivation: 现有数值模拟中，封闭量子系统可用局部边界条件，但开放系统因不确定性原理无法定义局部边界条件，导致平面波或波包在有限晶格上模拟失效。

Method: 提出一种仅需小尺寸数值晶格的方法，规避传统边界条件限制，维持入射波与散射波无限延伸的物理图像。

Result: 成功避免开放量子系统模拟中的边界条件困难，在有限晶格中实现与物理实际一致的无限扩展波模拟。

Conclusion: 该方法有效解决了开放量子系统数值模拟的边界条件问题，为相关计算提供了新思路。

Abstract: We study the problem of the boundary conditions in the numerical simulation of closed and open quantum systems, described by a Schrödinger equation. On one hand, we show that a closed quantum system is defined by local boundary conditions. On the other hand, we argue that, because of the uncertainty principle, no local boundary condition can be defined for open quantum systems. For this reason plane waves or wave packet trains cannot be simulated on a finite numerical lattice with the usual procedures. We suggest a method that avoids these difficulties by using only a small numerical lattice and maintains the correspondence with the physical picture, in which the incident and scattered waves may be infinitely extended.

</details>


### [262] [Non-Uniform Quantum Fourier Transform](https://arxiv.org/abs/2602.13472)
*Junaid Aftab,Yuehaw Khoo,Haizhao Yang*

Main category: quant-ph

TL;DR: 本文提出基于低秩分解的非均匀量子傅里叶变换（NUQFT）量子算法，通过量子块编码、量子信号处理等技术实现非均匀采样数据的高效处理，资源复杂度随精度呈多项式对数增长。


<details>
  <summary>Details</summary>
Motivation: 实际应用中广泛存在非均匀采样信号，但现有量子算法主要针对标准DFT，缺乏针对非均匀离散傅里叶变换（NUDFT）的量子框架，制约了量子计算在该领域的应用。

Method: 采用NUDFT矩阵的低秩分解方法，结合量子块编码、量子信号处理及单位线性组合框架，构建显式量子电路，并控制经典截断与量子实现的近似误差。

Result: 算法复杂度以目标精度的多项式对数、量子比特数的平方以及几何相关条件数的对数形式增长，实现了资源高效的非均匀傅里叶变换量子模拟。

Conclusion: 该工作建立了NUDFT的量子模拟基础，为不规则采样数据的量子算法设计提供了可行方案，推动了量子计算在实际信号处理中的应用。

Abstract: The Discrete Fourier Transform (DFT) is central to the analysis of uniformly sampled signals, yet many practical applications involve non-uniform sampling, requiring the Non-Uniform Discrete Fourier Transform (NUDFT). While quantum algorithms for the standard DFT are well established, a corresponding framework for the non-uniform case remains underdeveloped. This work introduces a quantum algorithm for the Non-Uniform Quantum Fourier Transform (NUQFT) based on a low-rank factorization of the NUDFT matrix. The factorization is translated into an explicit quantum construction using block encodings, Quantum Signal Processing, and the Linear Combination of Unitaries framework, yielding an $ε$-accurate block encoding of the NUDFT matrix with controlled approximation error from both classical truncation and quantum implementation. Under standard oracle access assumptions for non-uniform sampling points, we derive explicit, non-asymptotic gate-level resource estimates. The resulting complexity scales polylogarithmically with target precision, quadratically with the number of qubits through the quantum Fourier transform, and logarithmically with a geometry-dependent conditioning parameter induced by the non-uniform grid. This establishes a concrete and resource-efficient quantum analogue of the NUDFT and provides a foundation for quantum algorithms on irregularly sampled data.

</details>


### [263] [NISQ-compatible quantum cryptography based on Parrondo dynamics in discrete-time quantum walks](https://arxiv.org/abs/2602.14678)
*Aditi Rath,Dinesh Kumar Panda,Colin Benjamin*

Main category: quant-ph

TL;DR: This paper presents a NISQ-compatible quantum cryptography protocol using discrete-time quantum walks with Parrondo dynamics, demonstrating reliable message recovery under ideal conditions and characteristic eavesdropping detection, while identifying hardware connectivity and SWAP operation overhead as key performance constraints on real quantum processors.


<details>
  <summary>Details</summary>
Motivation: To address the critical need for NISQ device compatibility in quantum cryptographic implementations by developing a practical quantum circuit realization of a discrete-time quantum walk protocol that leverages deterministic chaotic dynamics for secure communication.

Method: Constructs an explicit quantum circuit for DTQWs on cyclic graphs with Parrondo dynamics, simulates performance in Qiskit using probability distributions/Hellinger fidelity/total variation distance, models intercept-resend and man-in-the-middle attacks via quantum bit error rate, and evaluates hardware feasibility on IBM's torino processor with connectivity constraints.

Result: The protocol enables reliable message recovery without eavesdropping, while eavesdropping induces detectable periodic reconstruction disruptions; circuit depth increases from SWAP operations between logical modules cause cumulative noise; qubit selection and connectivity significantly impact fidelity with hardware-dependent trade-offs.

Conclusion: NISQ implementation of quantum walk cryptography is feasible but critically dependent on hardware-aware circuit design, where managing connectivity constraints and SWAP overhead is essential for maintaining protocol performance and security against practical noise and eavesdropping attacks.

Abstract: Compatibility with noisy intermediate-scale quantum (NISQ) devices is crucial for the realistic implementation of quantum cryptographic protocols. We investigate a cryptographic scheme based on discrete-time quantum walks (DTQWs) on cyclic graphs that exploits Parrondo dynamics, wherein periodic evolution emerges from a deterministic sequence of individually chaotic coin operators. We construct an explicit quantum circuit realization tailored to NISQ architectures and analyze its performance through numerical simulations in Qiskit under both ideal and noisy conditions. Protocol performance is quantified using probability distributions, Hellinger fidelity, and total variation distance. To assess security at the circuit level, we model intercept-resend and man-in-the-middle attacks and evaluate the resulting quantum bit error rate. In the absence of adversarial intervention, the protocol enables reliable message recovery, whereas eavesdropping induces characteristic disturbances that disrupt the periodic reconstruction mechanism. We further examine hardware feasibility on contemporary NISQ processors, specifically $ibm\_torino$, incorporating qubit connectivity and state-transfer constraints into the circuit design. Our analysis demonstrates that communication between spatially separated logical modules increases circuit depth via SWAP operations, leading to cumulative noise effects. By exploring hybrid state-transfer strategies, we show that qubit selection and connectivity play a decisive role in determining fidelity and overall protocol performance, highlighting hardware-dependent trade-offs in NISQ implementations.

</details>


### [264] [Quantum Speedups for Group Relaxations of Integer Linear Programs](https://arxiv.org/abs/2602.13494)
*Brandon Augustino,Dylan Herman,Guneykan Ozgul,Jacob Watkins,Atithi Acharya,Enrico Fontana,Junhyung Lyle Kim,Shouvanik Chakrabarti*

Main category: quant-ph

TL;DR: 提出针对整数线性规划的量子-经典混合算法：通过Gomory群松弛问题，经典算法实现可行性保持的局部搜索，量子算法在特定条件下获得超二次加速，并在实际ILP问题中验证了提升分支切割的效果。


<details>
  <summary>Details</summary>
Motivation: 整数线性规划（ILP）是NP难问题但应用广泛，经典算法对多约束ILP采用全局穷举，而现有量子框架依赖目标函数的局部结构难以实现超二次加速，需解决这一矛盾。

Method: 1) 构造群松弛问题（移除最优LP解中正变量的非负约束，保留整数性） 2) 设计经典可行性保持的局部搜索算法 3) 提出量子算法并构造约束保持型混合器（constraint-preserving mixers）实现超二次加速 4) 通过非退化条件关联原始ILP最优解

Result: 1) 量子算法在合理技术条件下实现超二次加速 2) 当群松弛满足强化非退化条件时，算法可获原始ILP最优解 3) 否则能收紧ILP目标值边界，减小整数间隙 4) 数值实验证实其在实际ILP问题中提升分支切割效率

Conclusion: 该方法通过群松弛桥接经典全局算法与量子局部优化优势，为ILP提供实用化量子加速方案，所构造的混合器具有普适价值，且能辅助经典求解器提升性能。

Abstract: Integer Linear Programs (ILPs) are a flexible and ubiquitous model for discrete optimization problems. Solving ILPs is \textsf{NP-Hard} yet of great practical importance. Super-quadratic quantum speedups for ILPs have been difficult to obtain because classical algorithms for many-constraint ILPs are global and exhaustive, whereas quantum frameworks that offer super-quadratic speedup exploit local structure of the objective and feasible set. We address this via quantum algorithms for Gomory's group relaxation. The group relaxation of an ILP is obtained by dropping nonnegativity on variables that are positive in the optimal solution of the linear programming (LP) relaxation, while retaining integrality of the decision variables. We present a competitive feasibility-preserving classical local-search algorithm for the group relaxation, and a corresponding quantum algorithm that, under reasonable technical conditions, achieves a super-quadratic speedup. When the group relaxation satisfies a nondegeneracy condition analogous to, but stronger than, LP non-degeneracy, our approach yields the optimal solution to the original ILP. Otherwise, the group relaxation tightens bounds on the optimal objective value of the ILP, and can improve downstream branch-and-cut by reducing the integrality gap; we numerically observe this on several practically relevant ILPs. To achieve these results, we derive efficiently constructible constraint-preserving mixers for the group relaxation with favorable spectral properties, which are of independent interest.

</details>


### [265] [Erratic Liouvillian Skin Localization and Subdiffusive Transport](https://arxiv.org/abs/2602.14698)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 全局互易的Liouvillian动力学与哈密顿动力学存在本质区别：虽然两者都抑制非厄米趋肤效应，但只有Liouvillian体系在无序条件下会表现出 Sinai型超慢次扩散输运。


<details>
  <summary>Details</summary>
Motivation: 探究全局互易性在Liouvillian层面（而非传统哈密顿量层面）是否会产生类似的非厄米体局域化行为，特别是研究无序环境中Liouvillian特异性效应这一尚未充分探索的问题。

Method: 研究具有全局互易Liouvillian动力学和局部非互易非相干跳跃的晶格模型，分析其稳态和动力学行为。

Result: 稳态同样呈现无序依赖的体局域化而无边界聚集，但在非相干跳跃主导区，激发通过Sinai型次扩散传播，速度远慢于对称随机晶格中的普通扩散。

Conclusion: 揭示了全局互易的哈密顿量与Liouvillian动力学之间的根本区别：全局互易性在两种情况下都抑制趋肤效应，但仅在Liouvillian动力学中可与无序诱导的超慢次扩散输运共存。

Abstract: Non-Hermitian systems with globally reciprocal couplings -- such as the Hatano-Nelson model with stochastic imaginary gauge fields -- avoid the conventional non-Hermitian skin effect, displaying erratic bulk localization while retaining ballistic transport. An open question is whether similar behavior arises when non-reciprocity originates at the Liouvillian level rather than from an effective non-Hermitian Hamiltonian obtained via post-selection. Here we investigate this scenario in a lattice model with globally reciprocal Liouvillian dynamics and locally asymmetric incoherent hopping, a disordered setting in which Liouvillian-specific effects have remained largely unexplored. While the steady state again shows disorder-dependent, erratic localization without boundary accumulation, we find that global reciprocity in the Liouvillian does not protect transport. Instead, in the regime dominated by incoherent hopping, excitations spread via Sinai-type subdiffusion, dramatically slower than the ordinary diffusion found in symmetric stochastic lattices. Our results reveal a fundamental distinction between globally reciprocal Hamiltonian and Liouvillian dynamics: global reciprocity suppresses the skin effect in both cases, but only in Liouvillian dynamics can it coexist with ultra-slow, disorder-induced subdiffusive transport.

</details>


### [266] [Fine-Grained Complexity for Quantum Problems from Size-Preserving Circuit-to-Hamiltonian Constructions](https://arxiv.org/abs/2602.14379)
*Nai-Hui Chia,Atsuya Hasegawa,François Le Gall,Yu-Ching Shen*

Main category: quant-ph

TL;DR: 该论文证明了3-局部哈密顿量问题在经典和量子计算下的强硬度下界：基于SETH假设，经典算法无法在O(2^{(1-ε)n})时间内求解；基于QSETH假设，量子算法无法在O(2^{(1-ε)n/2})时间内求解。同时提出了首个尺寸保持的电路-哈密顿量构造，并给出了量子配分函数近似计算的匹配量子算法，改进了低温 regime 的现有结果。


<details>
  <summary>Details</summary>
Motivation: 探索局部哈密顿量问题（LH）的精确计算复杂性下限，验证现有经典/量子算法是否可进一步优化，并为量子配分函数（QPF）近似提供精细粒度复杂度分析框架。

Method: 1) 基于SETH/QSETH假设进行细粒度归约，证明LH问题的指数时间下界；
2) 引入尺寸保持的电路-哈密顿量构造（将T时间量子电路编码为(d+1)-局部哈密顿量，仅需N+O(T^{1/d})个量子比特）；
3) 对QPF近似问题建立SETH/QSETH硬度证明，并设计O(√2ⁿ)时间的量子算法。

Result: 1) 经典计算下LH问题需Ω(2^{(1-ε)n})时间（SETH）；
2) 量子计算下需Ω(2^{(1-ε)n/2})时间（QSETH）；
3) QPF常数相对误差近似具有相同硬度；
4) 新量子算法实现O(√2ⁿ)时间/1/poly(n)误差，匹配下界并改进Bravyi等人在低温场景的结果。

Conclusion: LH问题存在极强的计算硬度壁垒，当前最优算法已接近理论极限；提出的尺寸保持编码方法为量子复杂性理论提供新工具，QPF算法突破低温计算瓶颈，确立了量子优势在该问题中的精确边界。

Abstract: The local Hamiltonian (LH) problem is the canonical $\mathsf{QMA}$-complete problem introduced by Kitaev. In this paper, we show its hardness in a very strong sense: we show that the 3-local Hamiltonian problem on $n$ qubits cannot be solved classically in time $O(2^{(1-\varepsilon)n})$ for any $\varepsilon>0$ under the Strong Exponential-Time Hypothesis (SETH), and cannot be solved quantumly in time $O(2^{(1-\varepsilon)n/2})$ for any $\varepsilon>0$ under the Quantum Strong Exponential-Time Hypothesis (QSETH). These lower bounds give evidence that the currently known classical and quantum algorithms for LH cannot be significantly improved.
  Furthermore, we are able to demonstrate fine-grained complexity lower bounds for approximating the quantum partition function (QPF) with an arbitrary constant relative error. Approximating QPF with relative error is known to be equivalent to approximately counting the dimension of the solution subspace of $\mathsf{QMA}$ problems. We show the SETH and QSETH hardness to estimate QPF with constant relative error. We then provide a quantum algorithm that runs in $O(\sqrt{2^n})$ time for an arbitrary $1/\mathrm{poly}(n)$ relative error, matching our lower bounds and improving the state-of-the-art algorithm by Bravyi, Chowdhury, Gosset, and Wocjan (Nature Physics 2022) in the low-temperature regime.
  To prove our fine-grained lower bounds, we introduce the first size-preserving circuit-to-Hamiltonian construction that encodes the computation of a $T$-time quantum circuit acting on $N$ qubits into a $(d+1)$-local Hamiltonian acting on $N+O(T^{1/d})$ qubits. This improves the standard construction based on the unary clock, which uses $N+O(T)$ qubits.

</details>


### [267] [Efficient discrimination schemes for unextendible product bases with strong quantum nonlocality](https://arxiv.org/abs/2602.13545)
*Qiqi Feng,Huaqi Zhou,Limin Gao*

Main category: quant-ph

TL;DR: 提出三种纠缠分配方案，用于在3⊗3⊗3和d⊗d⊗d系统中局部区分具有强量子非定域性的不可扩展乘积基，仅用两个最大纠缠态即可完美区分，同时降低纠缠消耗


<details>
  <summary>Details</summary>
Motivation: 设计局部区分协议以最小化资源消耗，特别是纠缠资源，因为纠缠是量子信息科学的核心资源，而不可扩展乘积基的区分对量子信息处理至关重要

Method: 利用特定不可扩展乘积基的结构特征和最大纠缠态的操作优势，提出三种纠缠分配方案；将协议从3⊗3⊗3系统推广到d⊗d⊗d系统；尽可能避免使用量子隐形传态

Result: 在d⊗d⊗d系统中实现强非定域不可扩展乘积基的完美区分，仅需两个最大纠缠态；与现有方法相比，协议显著减少纠缠消耗

Conclusion: 这些资源高效的协议不仅促进了量子信息处理的实用性，还深化了对最大纠缠态在量子操作中作用的理解

Abstract: Entanglement is a central resource in quantum information science; therefore, it is important to design local discrimination protocols that minimize resource consumption. In this paper, we propose three entanglement-allocation schemes for the local discrimination of particular unextendible product bases (UPB) exhibiting strong quantum nonlocality in a \(3 \otimes 3 \otimes 3\) system. By exploiting the structural features of these UPB and the operational advantages of maximally entangled states, we further extend our protocols to strongly nonlocal UPB in \(d \otimes d \otimes d\) systems. In particular, we show that these UPB can be perfectly distinguished with only two maximally entangled states. Moreover, a resource-cost analysis indicates that our protocols, which avoid quantum teleportation whenever possible, can reduce the entanglement consumption. These results not only facilitate resource-efficient quantum information processing, but also provide further insight into the operational role of maximally entangled states.

</details>


### [268] [Flux Pumped Kerr-Free Parametric Amplifier](https://arxiv.org/abs/2602.13563)
*Kagan Yanik,Irwin Huang,Bibek Bhandari,Bingcheng Qing,Ahmed Hajr,Ke Wang,David I. Santiago,Irfan Siddiqi,Justin Dressel,Andrew N. Jordan*

Main category: quant-ph

TL;DR: 提出一种基于对称 threaded 超导量子干涉仪 (SQUIDs) 的磁通泵浦超导参量放大器，通过将中心结替换为线性电感，在特定驱动条件下实现无Kerr非线性工作点，从而在高增益强驱动 regime 下保持近量子极限性能，可稳定工作至25 dB增益。


<details>
  <summary>Details</summary>
Motivation: Kerr非线性会破坏压缩态并降低高增益强驱动条件下的放大性能和量子效率，消除Kerr非线性对实现量子极限放大至关重要。

Method: 设计基于对称 threaded SQUIDs (STS) 的磁通泵浦超导参量放大器，将STS中心结替换为线性电感，使有效哈密顿量在超导相位算符零点涨落的高阶修正项范围内退化为简并参量放大器(DPA)模型。

Result: 实现Kerr-free工作点，非理想DPA行为的高阶修正远弱于Kerr非线性效应；支持强驱动下近量子极限性能，预测相位 preserving 增益和效率接近量子极限，稳定工作增益可达25 dB。

Conclusion: STS设计克服了Kerr非线性限制，为量子测量和放大提供了高性能、强驱动的稳健方案，是超导量子电路的重要进展。

Abstract: We propose a flux-pumped superconducting parametric amplifier based on symmetrically threaded superconducting quantum interference devices (SQUIDs) that achieves a Kerr-free operating point under suitable drive conditions. Eliminating the Kerr nonlinearity is advantageous for quantum-limited amplification, as it mitigates unwanted distortions in squeezing and prevents degradation of both gain and quantum efficiency in the high-gain strong drive regime. By replacing the central junction in the symmetrically threaded SQUIDs (STS) configuration with a linear inductor, we find that the Kerr-nonlinearity can be eliminated and the effective Hamiltonian reduces to that of a degenerate parametric amplifier (DPA), up to higher-order corrections in the zero-point fluctuations of the superconducting phase operator. We show that the deviations from ideal DPA behavior introduced by these higher-order terms are significantly weaker than those associated with a Kerr nonlinearity. Consequently, the STS design can be driven strongly while maintaining near-quantum-limited performance at the Kerr-free point. Our analysis predicts phase-preserving gain and efficiency approaching the quantum limit, with robust operation demonstrated up to 25 dB of gain.

</details>


### [269] [Time-Domain Two-Magnon Interference Enabled by a Tunable Beamsplitter](https://arxiv.org/abs/2602.13572)
*Cody Trevillian,Steven Louis,Vasyl Tyberkevych*

Main category: quant-ph

TL;DR: 提出混合腔磁振子系统中可控双磁振子干涉的模型体系，通过可调磁振子分束器实现Hong-Ou-Mandel效应的磁振子模拟，并产生最大纠缠的N00N态。


<details>
  <summary>Details</summary>
Motivation: 探索磁振子系统中的量子干涉现象，为磁振子量子计量和混合磁振子量子计算架构提供基础。

Method: 在包含两个耦合磁振子模式的混合腔磁振子系统中，施加时变磁场独立激发磁振子，通过相互作用实现可控磁振子分束器操作。

Result: 成功实现了双磁振子干涉，产生了具有可调相位灵敏度的最大纠缠磁振子N00N态。

Conclusion: 混合腔磁振子系统中的双磁振子干涉为实现新型量子计量器件、研究基本磁振子动力学以及发展混合磁振子量子计算架构提供了可能性。

Abstract: This letter presents a model system for controllable two-magnon interference in the time domain. This two-magnon interference, i.e., a magnonic analog to the photonic Hong-Ou-Mandel effect, is supported by a tunable magnonic beamsplitter operation formed in a hybrid cavity magnonic system comprising a pair of mutually coupled magnon modes. By applying a time-dependent magnetic field, magnons can be excited independently in each mode and subsequently brought into interaction, shifting from independent to collective oscillations, to realize a controllable magnonic beamsplitter. When the beamsplitter operation is applied to an initially unentangled two-magnon state, a maximally entangled magnonic $N00N$ state with tunable phase sensitivity is produced. These findings suggest that two-magnon interference in hybrid cavity magnonic systems may enable novel quantum metrological devices to study fundamental magnon dynamics and contribute to developing hybrid magnonic quantum computing architectures.

</details>


### [270] [Entanglement in quantum spin chains is strictly finite at any temperature](https://arxiv.org/abs/2602.13386)
*Ainesh Bakshi,Soonwon Choi,Saúl Pilatowsky-Cameo*

Main category: quant-ph

TL;DR: This paper proves that thermal states of quantum spin chains can be exactly decomposed into matrix product states with system-size-independent complexity, revealing strictly finite entanglement at any finite temperature.


<details>
  <summary>Details</summary>
Motivation: Characterizing entanglement in interacting many-body systems at thermal equilibrium remains a fundamental challenge in quantum statistical physics, particularly understanding how entanglement scales in thermodynamic limit.

Method: The authors prove an exact decomposition theorem showing Gibbs states can be represented as mixtures of matrix product states with bond dimension independent of system size, accompanied by an explicit construction and efficient classical sampling algorithm.

Result: Demonstrates that the Schmidt number (key entanglement measure) remains strictly finite for thermal states even in thermodynamic limit, proving thermal entanglement doesn't diverge at finite temperatures.

Conclusion: This work resolves a major challenge by providing both theoretical understanding of finite-temperature entanglement scaling and practical computational tools for simulating thermal quantum systems.

Abstract: Entanglement is the hallmark of quantum physics, yet its characterization in interacting many-body systems at thermal equilibrium remains one of the most important challenges in quantum statistical physics. We prove that the Gibbs state of any quantum spin chain can be exactly decomposed into a mixture of matrix product states with a bond dimension that is independent of the system size, at any finite temperature. As a consequence, the Schmidt number, arguably the most stringent measure of bipartite entanglement, is strictly finite for thermal states, even in the thermodynamic limit. Our decomposition is explicit and is accompanied by an efficient classical algorithm to sample the resulting matrix product states.

</details>


### [271] [Digitizing ultrafast adiabatic passage with a pulse train](https://arxiv.org/abs/2602.13592)
*Bo Y. Chang,Ignacio R. Sola,Svetlana A. Malinovskaya,Sebastian C. Carrasco,Vladimir S. Malinovsky*

Main category: quant-ph

TL;DR: 提出一种基于弱频变超快脉冲序列的数字化快速绝热通道实现方法，通过解析条件复现连续脉冲的布居动力学，揭示子脉冲作为离散采样点的特性，并利用频梳边带实现大失谐共振激发和叠加态制备


<details>
  <summary>Details</summary>
Motivation: 传统长脉冲绝热激发需要 impractical 的长时间连续脉冲，本研究旨在开发基于超快脉冲序列的数字化替代方案，以克服实验限制并拓展量子控制手段

Method: 采用弱频变超快脉冲序列模拟连续绝热过程，推导子脉冲拉比频率与失谐量的解析条件；通过数值验证脉冲序列对复杂布居动力学的复现能力，并探索频梳边带在共振激发中的应用

Result: 1) 少量子脉冲即可高保真复现连续动力学（需满足微扰条件）
2) 子脉冲本质是连续演化的离散采样点，多振荡复杂动力学需更多子脉冲
3) 频梳边带可实现大载波失谐下的共振激发和精确叠加态制备

Conclusion: 该数字化方法为超快量子操控提供新范式，脉冲序列的离散采样特性建立了连续-离散动力学桥梁，频梳边带技术显著拓展了绝热激发的应用范围

Abstract: We present a digitized implementation of rapid adiabatic passage based on a train of weak, frequency-varying ultrafast pulses. Analytic conditions on the subpulse Rabi frequencies and detunings are derived to reproduce the continuous-time population dynamics of a conventional long-pulse excitation. We find that the reproduced dynamics achieves high fidelity even for pulse trains with a small number of subpulses, provided that each subpulse remains within the perturbative regime. The subpulses act as discrete samples of the underlying continuous evolution; consequently, more complex population dynamics, characterized by multiple oscillations prior to the onset of adiabaticity, require a larger number of subpulses for accurate reproduction. In addition, we demonstrate how the sidebands of a frequency comb can be exploited for resonant excitation at large carrier detuning and for the precise preparation of superposition states.

</details>


### [272] [Ward-Takahashi Identity and Gauge-Invariant Response Theory for Open Quantum Systems](https://arxiv.org/abs/2602.13632)
*Hongchao Li,Xie-Hang Yu,Masaya Nakagawa,Masahito Ueda*

Main category: quant-ph

TL;DR: 提出开放量子系统的规范不变响应理论，证明粒子数守恒非规范不变性必要条件，发现双体损耗诱导耗散BCS超导中的扩散模式


<details>
  <summary>Details</summary>
Motivation: 突破传统规范不变性理论需依赖粒子数守恒的限制，为开放量子系统建立普适的规范不变性理论框架

Method: 推导沃德-高桥恒等式，构建基于林德布拉德算符的规范不变响应理论，构造可实验验证的规范不变性观测算符

Result: 1. 证明无粒子数守恒时仍可满足规范不变性
2. 发现双体损耗导致耗散BCS超导产生扩散模式
3. 提出规范不变性的实验检验方案

Conclusion: 该理论为开放量子系统的规范不变性研究提供新范式，实验验证将推动耗散量子物态调控发展

Abstract: We derive the Ward-Takahashi identity and establish the gauge-invariant response theory for open quantum systems described by Lindbladians to show that particle-number conservation is not necessary to satisfy gauge invariance. We construct an observable which can be used to test the gauge invariance in the absence of particle-number conservation. We derive the low-energy collective modes that emerge as a consequence of gauge invariance in open quantum systems, and find that two-body loss induces diffusive modes in dissipative Bardeen-Cooper-Schrieffer (BCS) superconductivity. Possible experimental situations for testing gauge invariance in open quantum systems are also discussed.

</details>


### [273] [Single-reference coupled-cluster theory based on the multi-purpose cluster operator](https://arxiv.org/abs/2602.13605)
*Karol Kowalski,Nicholas P. Bauman*

Main category: quant-ph

TL;DR: 本文提出了一个扩展单参考耦合簇理论的理论框架，使其能够同时描述多个电子态，而不仅限于单一参考态，并通过厄米变体降低了量子模拟资源需求。


<details>
  <summary>Details</summary>
Motivation: 传统单参考耦合簇理论仅限于描述单一电子态（通常是参考行列式定义的对称性 sector 中的最低能量态）。本文旨在突破这一限制，开发一种更通用的框架，使不同集群算符分量能承担不同角色，从而同时编码多个不同对称性的态。

Method: 通过推广集群算符的构造方式，使各分量发挥不同作用，建立了新型单参考耦合簇折叠形式体系。提出了三个定理来形式化这一扩展，并基于酉耦合簇表示引入了厄米变体。

Result: 所得到的活性空间有效哈密顿量能够同时表示与参考函数非正交的多个相关态；标准耦合簇折叠成为该框架的特例；厄米变体在实现真实基态和激发态模拟的同时减少了所需的量子资源。

Conclusion: 该理论框架成功扩展了单参考耦合簇理论，使其能够同时处理多个电子态，为标准方法提供了更一般的理论视角，并为量子化学模拟提供了更高效的工具。

Abstract: In this paper, we develop a theoretical framework that extends single-reference (SR) coupled-cluster (CC) theory beyond its conventional role of describing a single electronic state-typically the lowest-energy state within the symmetry sector defined by the reference determinant. Rather than viewing the SR-CC cluster operator solely as a device for reproducing one target state, we consider more general constructions in which different components of the cluster operator play distinct roles, ranging from encoding states of different symmetry than the reference to enabling SR-CC Ansatz to describe multiple states simultaneously. These developments lead to a new class of SR-CC downfolding formalisms in which the resulting active-space effective Hamiltonians are capable of concurrently representing multiple correlated states nonorthogonal to the reference function. We establish three theorems that formalize this extension and demonstrate that standard CC downfolding emerges as a special case of the proposed framework. Finally, we introduce a Hermitian variant based on a unitary CC representation, which enables realistic simulations of ground and excited states while reducing the quantum resources required.

</details>


### [274] [Generation of large Fock states from coherent states using Kerr interaction and displacement](https://arxiv.org/abs/2602.13623)
*Nilakantha Meher,Anirban Pathak,S. Sivakumar*

Main category: quant-ph

TL;DR: 提出一种通过重复施加实验可行的幺正变换（结合克尔相互作用和脉冲相干驱动）将半经典态高效转换为高保真度大福克态的方案，适用于电路QED和腔场系统


<details>
  <summary>Details</summary>
Motivation: 生成大福克态是量子信息处理的关键挑战，现有方法存在实现难度高或保真度不足的问题，亟需开发实验可行且高效的新方案

Method: 设计包含非高斯克尔相互作用和脉冲相干驱动的复合幺正变换，通过优化克尔强度、脉冲时序和位移振幅等参数，反复作用于半经典初始态

Result: 在电路QED架构中实现近单位保真度的大福克态生成，明确给出可物理实现的参数范围，证实方案在腔场系统中的适用性

Conclusion: 该方案兼具实验可行性与高保真度优势，为量子信息处理中确定性生成大福克态提供了实用化路径，特别适用于超导电路和光学腔系统

Abstract: We discuss a scheme to generate large Fock states. The scheme involves repeatedly applying an experimentally feasible unitary transformation to convert a semiclassical state into a Fock state. The transformation combines Kerr interaction, which is a non-Gaussian operation, and pulsed coherent drives. We identify suitable parameter values (Kerr strength, pulse timings, displacement amplitude) for the physical processes to implement the transformation and generate large Fock states with near-unity fidelity. The feasibility of implementing the scheme in circuit QED architectures is discussed. The method is also suitable for generating Fock states of cavity fields.

</details>


### [275] [A theory of quantum error correction for permutation-invariant codes](https://arxiv.org/abs/2602.13638)
*Yingkai Ouyang,Gavin K. Brennen*

Main category: quant-ph

TL;DR: 首次提出置换不变(PI)码的通用量子纠错理论，基于对称群表示论构建高效纠错算法，可校正任意可校正错误，并对擦除/删除错误提供更简化的解决方案


<details>
  <summary>Details</summary>
Motivation: 置换不变(PI)码在量子信息处理中具有特殊重要性，但此前缺乏系统的纠错理论框架，无法有效应对各类量子错误

Method: 利用对称群表示论，通过总角动量测量、量子舒尔变换、逻辑态隐形传态和几何相位门等操作构建算法体系

Result: 1) 开发通用算法可校正任意PI码上的可校正错误；2) 针对特定PI码的擦除/删除错误，提出更简化的量子纠错方案

Conclusion: 建立了PI码纠错的完整理论框架，为量子计算中的对称性编码错误校正提供了普适性解决方案，推动了容错量子计算发展

Abstract: We present for the first time a general theory of error correction for permutation invariant (PI) codes. Using representation theory of the symmetric group we construct efficient algorithms that can correct any correctible error on any PI code. These algorithms involve measurements of total angular momentum, quantum Schur transforms or logical state teleportations, and geometric phase gates. For erasure errors, or more generally deletion errors, on certain PI codes, we give a simpler quantum error correction algorithm.

</details>


### [276] [Comment on "Evolution Operator Can Always Be Separated into the Product of Holonomy and Dynamic Operators"](https://arxiv.org/abs/2602.13648)
*Adam Fredriksson,Erik Sjöqvist*

Main category: quant-ph

TL;DR: 一篇反驳性论文，指出2023年PRL论文中关于量子时间演化总可分解为和乐算符与动力学算符乘积的论断不成立，因其使用了循环论证。


<details>
  <summary>Details</summary>
Motivation: 纠正顶级期刊Physical Review Letters上发表的错误主张，防止对量子力学基础理论产生误导，维护学术严谨性。

Method: 通过理论分析和数学论证，揭示原论文在证明过程中对时间演化算符的循环使用问题。

Result: 证明原论文的核心论断是错误的，其关于量子时间演化的分解方式并非普遍成立。

Conclusion: 量子时间演化不能总是表示为和乐算符与动力学算符的乘积，原主张因循环论证而无效。

Abstract: We show that the claim in Ref. [PRL 131, 200202 (2023)], that the quantum time evolution always can be written as a product of a holonomy operator and a dynamic operator, is false, as it is based on a circular use of the time evolution operator.

</details>


### [277] [Strong-Field Quantum Metrology Beyond the Standard Quantum Limit](https://arxiv.org/abs/2602.13667)
*Tsendsuren Khurelbaatar,R. T. Sang,Igor Litvinyuk*

Main category: quant-ph

TL;DR: 该研究通过量子光学强场近似理论，揭示了压缩光的量子噪声如何影响强场光电离全息术，发现"有质动力退相"机制，并提出阿秒量子断层扫描方案重构高强度量子光的维格纳分布。


<details>
  <summary>Details</summary>
Motivation: 将量子光学与强场物理结合，探索量子光在极端非线性光-物质相互作用中的作用，解决在损伤阈值强度下直接表征非经典光的挑战。

Method: 采用量子光学强场近似方法，理论研究压缩光光子数涨落对强场光电离全息术的影响。

Result: 发现"有质动力退相"机制，其中量子涨落决定电子半经典作用的稳定性；振幅压缩光增强全息对比度，相位压缩光导致条纹可见度快速坍塌；该效应遵循四次方波长标度，使中红外驱动光特别敏感；隧穿尾部的"暗端口"机制可实现超越标准量子极限的场正交噪声估计。

Conclusion: 建立了阿秒量子断层扫描框架，实现原位、无参考重构高强度量子光的维格纳分布，将强场电离识别为非线性量子换能器，桥接阿秒电子动力学与量子信息科学。

Abstract: Bridging quantum optics and strong-field physics provides a pathway to explore how quantum light shapes extreme nonlinear light-matter interactions. However, direct characterization of non-classical light at damage-threshold intensities remains an open question. Here, we theoretically investigate the impact of photon-number fluctuations of squeezed light on strong-field photoelectron holography using a quantum-optical strong-field approximation. We identify a mechanism, ponderomotive dephasing, whereby the inherent quantum fluctuations of the driving field dictate the stability of the electron's semiclassical action. While amplitude-squeezed light stabilizes the action to enhance holographic contrast, phase-squeezed light amplifies photon-number noise, causing a rapid collapse of fringe visibility. This quantum-optical sensitivity follows a steep quartic wavelength scaling, rendering mid-infrared drivers uniquely sensitive to the field's underlying quantum nature. Crucially, we show that the collapse of holographic contrast is not a loss of information but a metrological gain. By evaluating the Classical Fisher Information, we identify a "dark-port" mechanism in the tunneling tail that enables the estimation of field quadrature noise beyond the Standard Quantum Limit. This fundamental trade-off between structural imaging fidelity and statistical sensitivity establishes the framework for Attosecond Quantum Tomography: an in-situ, reference-free protocol to reconstruct the Wigner distribution of intense quantum light. Our results identify strong-field ionization as a nonlinear quantum transducer, bridging attosecond electron dynamics with quantum information science.

</details>


### [278] [A group structure arising from Grover walks on complete graphs with self-loops and its application](https://arxiv.org/abs/2602.13686)
*Tatsuya Tsurii,Naoharu Ito*

Main category: quant-ph

TL;DR: 该论文提出了分析带自环完全图上Grover行走代数结构的群论框架，通过构造由Grover矩阵和单位根对角矩阵生成的群，证明了商群与依赖于顶点奇偶性的有限循环群同构，揭示了Grover行走时间演化的内在对称性。


<details>
  <summary>Details</summary>
Motivation: Grover行走作为量子计算中的重要模型，其周期性行为的代数结构尚未被完全理解。本文旨在建立系统的群论框架来揭示其深层对称性，为理解量子行走的动力学特性提供新的数学工具。

Method: 1. 构造生成群：由Grover矩阵和含单位根的对角矩阵生成；2. 定义交换子子群：通过矩阵交换子构造正规子群；3. 商群分析：研究该群的商结构并证明其循环性；4. 奇偶性分析：建立商群结构与图顶点数的奇偶性关系。

Result: 核心发现包括：(1) 所构造群的商群同构于有限循环群；(2) 该循环群的具体结构（阶数）完全由顶点数的奇偶性决定；(3) 成功将Grover行走的周期性行为编码在群结构中。

Conclusion: 该群论表征不仅揭示了Grover行走时间演化的隐藏对称性，还建立了代数结构与量子动力学之间的深刻联系，为未来研究量子行走的周期性、可积性以及算法应用提供了统一的代数框架。

Abstract: This paper introduces a group-theoretic framework to analyze the algebraic structure of the Grover walk on a complete graph with self-loops. We construct a group generated by the Grover matrix and a diagonal matrix whose entries are powers of a complex root of unity. We then characterize the resulting quotient group, which is defined using a subgroup formed by commutators involving these matrices. We show that this quotient group is isomorphic to a finite cyclic group whose structure depends on the parity of the number of vertices. This group-theoretic characterization reveals underlying symmetries in the time evolution of the Grover walk and provides an algebraic framework for understanding its periodic behavior.

</details>


### [279] [Quantum dynamics of microwave photons in synthetic frequency dimension](https://arxiv.org/abs/2602.13736)
*Zheshu Xie,Luojia Wang,Jiawei Qiu,Libo Zhang,Yuxuan Zhou,Ziyu Tao,Wenhui Huang,Yongqi Liang,Jiajian Zhang,Yuanzhen Chen,Song Liu,Jingjing Niu,Yang Liu,Youpeng Zhong,Luqi Yuan,Dapeng Yu*

Main category: quant-ph

TL;DR: 利用超导量子电路与16米同轴电缆构建合成频率晶格，实现了单光子量子行走、布洛赫振荡和非绝热频率转换，为量子模拟提供了可编程平台。


<details>
  <summary>Details</summary>
Motivation: 将合成频率维度从经典光学扩展至单光子量子层面在光子平台中一直面临挑战。

Method: 将超导量子比特与16米铝制同轴电缆集成，采用可调SQUID调制器合成晶格耦合与人工规范场，通过快速时变哈密顿量实现非绝热演化。

Result: 观测到单光子量子随机行走、布洛赫振荡、非绝热单向频率转换和能带结构，晶格可多频驱动重构为高维系统。

Conclusion: 超导量子电路成为实现可编程哈密顿量、可扩展合成晶格和灵活单光子控制的通用量子模拟平台。

Abstract: Synthetic frequency dimension offers a powerful approach to simulate lattice models and control photon dynamics. However, extending this concept into the quantum regime, particularly at the single-photon level, has remained challenging in photonic platforms. Here, we demonstrate quantum-state initialization and detection of single-photon evolutions within a synthetic frequency lattice by integrating a superconducting qubit with a 16-meter aluminum coaxial cable. A tunable superconducting quantum interference device (SQUID)-based modulator is employed to synthesize lattice couplings and artificial gauge fields. We observe single-photon quantum random walks and Bloch oscillations, as well as nonadiabatic, unidirectional frequency conversion under rapid temporal modulation of the lattice Hamiltonian, together with band-structure measurements. The lattice connectivity can be readily reconfigured to construct higher-dimensional lattices using multiple drive tones. Our results establish superconducting quantum circuits as a versatile platform for programmable Hamiltonians and extensible synthetic lattices with flexible single-photon control.

</details>


### [280] [Non-Abelian Aharonov-Bohm Caging in Synthetic Dimensions with a Trapped Ion](https://arxiv.org/abs/2602.13796)
*Wanchao Yao,Sai Li,Zhiyuan Liu,Yi Li,Zihan Xie,Xingyu Zhao,Xu Cheng,Yue Li,Zheng-Yuan Xue,Yiheng Lin*

Main category: quant-ph

TL;DR: 该论文利用囚禁离子系统中的合成维度实验实现了非阿贝尔SU(2)规范场下的Aharonov-Bohm笼效应，揭示了区别于阿贝尔情形的独特量子动力学行为。


<details>
  <summary>Details</summary>
Motivation: 将Aharonov-Bohm笼效应从阿贝尔规范场拓展至非阿贝尔规范场，探索其在非阿贝尔情形下的独特量子输运特性，这一现象在量子系统中一直尚未被实验观测到。

Method: 在具有多个能级的振动囚禁离子中，通过合成维度工程化构建菱形晶格中的可调和非阿贝尔SU(2)规范场。

Result: 实验实现了阿贝尔和非阿贝尔规范场下的AB笼效应，系统研究了非阿贝尔情况下的独特输运性质，观测到初态依赖动力学、二阶效应和非对称笼效应等非阿贝尔特有的量子动力学行为。

Conclusion: 囚禁离子系统成为模拟具有奇异合成规范场的高维量子系统中涌现现象的强大平台。

Abstract: Aharonov-Bohm (AB) caging is a complete localization phenomenon in two-dimensional lattices due to destructive interference induced by the background gauge fields. However, current investigations of AB caging are mostly restricted to the Abelian gauge field case, and the observation of AB caging under non-Abelian gauge fields in a quantum system still remains elusive. Here, we report experimental realization of tunable synthetic non-Abelian SU(2) gauge fields in a rhombic lattice, engineered within the synthetic dimensions of a vibrating trapped ion with multiple levels. We realize AB caging under both Abelian and non-Abelian gauge fields and systematically investigate the distinctive transport properties of the non-Abelian case. In particular, we observe typical emergent quantum dynamics unique to non-Abelian AB caging, including initial-state-dependent dynamics, second-order effects, and asymmetric caging behavior. These observations demonstrate the trapped ion system as a powerful platform for simulating emergent phenomena in high-dimensional quantum systems with exotic synthetic gauge fields.

</details>


### [281] [Field-Tunable Meissner-Levitated Ferromagnetic Microsphere Sensor for Cryogenic Casimir and Short-Range Gravity Tests](https://arxiv.org/abs/2602.13829)
*Yi-Chong Ren,Feng Xu,Wijnand Broer,Xiao-Jing Chen,Fei Xue*

Main category: quant-ph

TL;DR: 提出一种基于迈斯纳悬浮铁磁微球的超导量子力梯度传感器，通过磁场调谐实现亚微米间隙原位扫描，利用SQUID微波谐振器读出和输入输出理论优化测量，突破标准量子极限，实现10^{-19} N/√Hz级力灵敏度，用于卡西米尔效应和短程新物理探测。


<details>
  <summary>Details</summary>
Motivation: 亚微米近场力测量可探测卡西米尔效应和短程新相互作用，但需解决低温环境下的稳定间隙控制与背景噪声校准难题。

Method: 采用超导平面迈斯纳悬浮铁磁微球结构，偏置磁场无机械调谐平衡间隙；力梯度编码为谐振频移并通过锁相环跟踪；利用SQUID耦合的可调微波谐振器实现无光热读出，结合输入输出理论优化量子测量极限。

Result: 发现反常标度律：微球尺寸增大时位移-磁通转换效率提升，使达到标准量子极限所需光子数减少；量化金涂层抑制静电斑电位与涡流损耗的权衡；在毫开尔文温区实现~10^{-19} N/√Hz力灵敏度。

Conclusion: 该自校准量子传感器为宏观量子计量提供新路径，可精确提取卡西米尔压力并约束0.1-10μm范围内汤川型引力偏离，推动短程新物理实验探测。

Abstract: Near-field force measurements at submicron separations can probe Casimir effects and hypothetical short-range interactions, but require cryogenic operation and stable, \textit{in situ} control of separation-dependent backgrounds. We propose a self-calibrating quantum force-gradient sensor in which a ferromagnetic microsphere is Meissner-levitated above a type-I superconducting plane, while a bias magnetic field reproducibly tunes the equilibrium gap for in situ separation scans without mechanical approach. The force gradient is encoded as a resonance-frequency shift tracked by a phase-locked loop, and the motion is read out with a SQUID-coupled, flux-tunable microwave resonator that provides adjustable measurement strength without optical heating. Using the input--output formalism, we derive the conditions for reaching the standard quantum limit (SQL) and identify a counterintuitive scaling law: because displacement-to-flux transduction increases with microsphere size, larger microspheres require fewer photons to reach the SQL, enabling a pathway to macroscopic quantum metrology. We quantify the trade-off between suppression of electrostatic patch potentials (via Au coating) and eddy-current dissipation, project force sensitivities of $\sim 10^{-19}\,\rm{N\,Hz^{-1/2}}$ at millikelvin temperatures, and outline protocols to extract Casimir pressure and constrain Yukawa-type deviations from Newtonian gravity over $0.1$--$10\,μ\mathrm{m}$.

</details>


### [282] [Quantum computation and quantum error correction: the theoretical minimum](https://arxiv.org/abs/2602.13876)
*Mark Wildon*

Main category: quant-ph

TL;DR: 这是一份关于量子计算和量子纠错的讲义，强调稳定子理论和李理论基础，通过SU₂→SO₃(R)映射、Deutsch-Jozsa问题和Steane [[7,1,3]]码等具体例子系统介绍量子计算核心概念。


<details>
  <summary>Details</summary>
Motivation: 本文作为教学笔记，旨在为学习者提供量子计算与量子纠错的清晰入门框架，特别强调数学基础（李理论、稳定子）与物理概念的有机结合，弥补现有文献中数学严谨性不足的问题。

Method: 采用电路模型贯穿始终，通过具体数学映射（SU₂→SO₃(R)）阐明单量子比特状态与测量区别，以Steane码为主要示例讲解量子纠错，并逐步发展所需物理背景（酉演化、玻恩规则）。

Result: 系统阐释了量子计算核心概念：单量子比特的几何表示、纠缠与CNOT门、Deutsch-Jozsa算法解决方案，以及基于稳定子理论的量子纠错实现机制，特别是Steane码的完整构造与纠错原理。

Conclusion: 本笔记成功构建了从基础李理论到量子计算应用的完整知识桥梁，突出了稳定子理论在现代量子信息科学中的核心地位，为后续深入研究提供了扎实的数学物理基础。

Abstract: These notes introduce quantum computation and quantum error correction, emphasising the importance of stabilisers and the mathematical foundations in basic Lie theory. We begin by using the double cover map $\mathrm{SU}_2 \rightarrow \mathrm{SO}_3(\mathbb{R})$ to illustrate the distinction between states and measurements for a single qubit. We then discuss entanglement and CNOT gates, the Deutsch--Jozsa Problem, and finally quantum error correction, using the Steane $[[7,1,3]]$-code as the main example. The necessary background physics of unitary evolution and Born rule measurements is developed as needed. The circuit model is used throughout.

</details>


### [283] [High-fidelity non-adiabatic dark state gates for neutral atoms](https://arxiv.org/abs/2602.13885)
*Nader Mostaan,Kapil Goswami,Peter Schmelcher,Rick Mukherjee*

Main category: quant-ph

TL;DR: 利用量子最优控制实现中性原子非阻塞暗态门，兼具快速性和鲁棒性，达到阻塞门速度并降低噪声敏感性。


<details>
  <summary>Details</summary>
Motivation: 里德堡阻塞门在大原子间距时性能下降且对噪声敏感，而非阻塞方案虽鲁棒但控制复杂，难以实验实现。

Method: 采用量子最优控制设计平滑可行脉冲序列，实现非绝热暗态门方案。

Result: 获得兼具绝热协议鲁棒性与阻塞门速度的门操作，在运动耦合、激光噪声和相互作用不均匀性方面表现更优，尤其超越阻塞半径时。

Conclusion: 为中性原子量子处理器提供了无需增加实验复杂度的快速鲁棒双量子比特门实现路径。

Abstract: Rydberg blockade gates are the most experimentally mature entangling operations in neutral-atom quantum processors, combining fast gate times with simple control, but their performance degrades at larger interatomic separations and remains sensitive to motional and technical noise. Non-blockade gate schemes, such as dark-state and geometric protocols, offer complementary robustness but typically rely on complex and experimentally demanding control. Here we show that quantum optimal control enables non-blockade gate schemes to be implemented using the experimentally established pulse-shaping techniques developed for blockade-based gates. Focusing on the dark-state gate, we construct non-adiabatic implementations that preserve the intrinsic robustness of adiabatic dark-state protocols while achieving gate times comparable to time-optimal blockade gates using only smooth, experimentally feasible pulses. The resulting gates exhibit enhanced resilience to motional coupling, laser noise, and interaction inhomogeneity, particularly near and beyond the blockade radius. This work establishes a practical route to fast, robust two-qubit gates without increased experimental complexity.

</details>


### [284] [Homological origin of transversal implementability of logical diagonal gates in quantum CSS codes](https://arxiv.org/abs/2602.14499)
*Junichi Haruna*

Main category: quant-ph

TL;DR: 利用同调论中的Bockstein同态，完全刻画了量子CSS码中横向泡利Z旋转实现精细离散逻辑对角门的可解性条件，并给出了保证所有离散角度横向实现的具体判据。


<details>
  <summary>Details</summary>
Motivation: 横向泡利Z旋转是量子CSS码中实现容错逻辑对角门的自然方案，但其能力存在根本性约束。本研究旨在解决如何通过横向实现更精细离散角度的逻辑对角门这一精化问题，突破现有约束限制。

Method: 将问题形式化为横向实现离散旋转角的精化问题，运用同调论中的Bockstein同态进行数学刻画；通过分析X-稳定子生成元的线性独立性和模2幂次交换条件，建立横向实现的充分性判据。

Result: 1) 证明精化问题的可解性完全由Bockstein同态决定；2) 提出线性独立X-稳定子生成元+模2幂次交换性的双重条件，确保所有离散角度逻辑泡利Z旋转的横向实现；3) 揭示同调障碍是控制横向可实现性的核心机制。

Conclusion: 建立了横向结构在量子纠错中的形式化理论基础，通过同调论工具系统解决了横向逻辑门的实现约束问题，为容错量子计算提供了关键理论框架。

Abstract: Transversal Pauli Z rotations provide a natural route to fault-tolerant logical diagonal gates in quantum CSS codes, yet their capability is fundamentally constrained. In this work, we formulate the refinement problem of realizing a logical diagonal gate by a transversal implementation with a finer discrete rotation angle and show that its solvability is completely characterized by the Bockstein homomorphism in homology theory. Furthermore, we prove that the linear independence of the X-stabilizer generators together with the commutativity condition modulo a power of two ensures the existence of transversal implementations of all logical Pauli Z rotations with discrete angles in general CSS codes. Our results identify a canonical homological obstruction governing transversal implementability and provide a conceptual foundation for a formal theory of transversal structures in quantum error correction.

</details>


### [285] [Decoherence, Perturbations and Symmetry in Lindblad Dynamics](https://arxiv.org/abs/2602.13922)
*A. Y. Klimenko*

Main category: quant-ph

TL;DR: 该论文将微扰型Dyson处理和离散对称性约束从薛定谔/冯·诺依曼方程推广至退相干Lindblad框架，应用于质子-质子和质子-反质子衍射数据，通过三参数拟合以约4%的精度描述了单举衍射截面，并提取出退相干因子φ≈0.89，该结果支持CPT不变性退相干而非CP不变性退相干。


<details>
  <summary>Details</summary>
Motivation: 传统衍射散射近似方法忽略退相干效应，而该工作基于随机现实主义和双重时间边界条件，从一般动力学考虑发展出奇的对称性形式体系，旨在将量子退相干效应纳入量子力学工具中，以更好地描述实验数据。

Method: 将微扰型Dyson处理和离散对称性约束扩展到退相干Lindblad方程框架；采用基于随机现实主义和双重时间边界条件的奇的对称性形式体系；推导出标度关系并应用于多项实验（ISR、UA4、UA5、CDF、D0、ALICE、E710）的单举和双举衍射数据，进行三参数拟合。

Result: 单举衍射截面通过三参数拟合实现了约4%的相对均方根偏差，显著优于忽略退相干的常规近似方法；提取的退相干因子φ≈0.89在单举衍射、双举衍射及E710直接估计中保持一致。

Conclusion: 退相干因子φ<1的结果自然解释为支持CPT不变性退相干（φ<1）而非CP不变性退相干（φ=1），表明在量子力学描述衍射过程时纳入退相干效应的重要性，验证了理论框架的有效性。

Abstract: We extend a perturbative Dyson-type treatment and discrete-symmetry constraints from the Schrödinger and von Neumann equations to a dephasing Lindblad framework. This work develops further the odd-symmetric formulation -- based on stochastic realism and dual temporal boundary conditions -- from general dynamical considerations to specific tools of quantum mechanics. Applying the resulting scaling relations to published single- and double-diffractive data in $pp$ and $p\bar{p}$ collisions (ISR, UA4, UA5, CDF, D0, ALICE, and E710), we show that single-diffraction cross sections are well described by a three-parameter fit with a relative RMS deviation of $\sim 4\%$, substantially improving upon conventional approximations that neglect decoherence. The extracted decoherence factor is consistently $φ\approx 0.89$, in agreement across SD, DD, and E710-based (direct) estimates, and is naturally interpreted as $φ=1$ for CP-invariant dephasing but $φ<1$ for CPT-invariant dephasing, favouring the latter.

</details>


### [286] [Homodyne Detection of Temporally Resolved Quantum States](https://arxiv.org/abs/2602.13946)
*Owen Sandner,Brendan Mackey,Yuyang Liu,Connor Kupchak,Andrew MacRae*

Main category: quant-ph

TL;DR: 提出基于平衡零差探测的时域量子态测量框架，开发模拟算法分析测量误差对量子态重构的影响，并提供开源实现


<details>
  <summary>Details</summary>
Motivation: 解决任意时间模式量子态的高精度测量难题，探究实际测量误差对时域量子态层析的影响，推动量子信息处理的时域表征技术发展

Method: 建立时间模式投影到探测器基的自然描述形式，开发模拟连续零差探测光电流的时间分辨算法，结合误差模型分析边际重构与量子态层析精度

Result: 形成完整的时域量子态测量理论框架，量化测量误差对状态重构的影响规律，提供开源仿真代码库

Conclusion: 该方法为时域量子态测量提供系统性解决方案，算法能有效评估实际测量极限，开源工具将促进量子光学与时域量子信息研究的发展

Abstract: We present an analysis of the time domain measurement of temporally resolvable quantum states using balanced homodyne detection. Our approach outlines a formalism of detecting quantum states in arbitrary temporal modes via projection of the temporal mode onto a natural detector basis. We then present an algorithm for simulating the resultant photocurrent of continuous homodyne detection in the presence of a temporally resolved mode, and use this algorithm to explore the effects of realistic measurement errors on marginal reconstruction and quantum state tomography. A complete implementation of the method is provided through open source code on a GitHub repository.

</details>


### [287] [Wideband Quantum Transduction for Rydberg Atomic Receivers Using Six-Wave Mixing](https://arxiv.org/abs/2602.13955)
*Yuanbin Chen,Chau Yuen,Chong Meng Samson See*

Main category: quant-ph

TL;DR: 该研究利用六波混频(SWM)机制突破传统电磁诱导透明(EIT)里德堡原子接收器的带宽限制，实现3-dB基带带宽提升一个数量级，同时保持电场灵敏度并呈现可调线性工作区


<details>
  <summary>Details</summary>
Motivation: 传统EIT机制的里德堡原子接收器基带带宽仅几十至几百千赫兹，严重制约宽带无线通信应用，亟需突破此瓶颈

Method: 建立探针输入到光场输出的显式基带输入-输出模型，推导3-dB带宽闭式表达式，并通过1-dB压缩点(P1dB)和输入三阶截取点(IIP3)量化线性动态范围

Result: 在相同光驱动条件下，SWM方案使3-dB基带带宽较EIT方案提升>10倍，电场灵敏度相当，且呈现宽可调线性工作区

Conclusion: SWM基里德堡原子接收器显著扩展带宽并揭示带宽-线性度权衡机制，为宽带量子射频传感提供新路径

Abstract: Rydberg atomic receivers hold extremely high sensitivity to electric fields, yet their effective 3-dB baseband bandwidth under conventional electromagnetically induced transparency (EIT) is typically constrained to tens to a few hundreds of kilohertz, which hinders wideband wireless applications. To relax this bottleneck, we investigate a six-wave mixing (SWM)-based Rydberg atomic receiver as a wideband radio frequency (RF)-to-optical quantum transducer. Specifically, we develop an explicit baseband input-output model spanning from the probe input to the output light field. Based upon this model, a closed-form 3-dB bandwidth expression is derived to expose its dependence on key optical and RF parameters. We further quantify the linear dynamic range by employing the 1-dB compression point (P1dB) and the input-referred third-order intercept point (IIP3), unveiling a communication-compatible characterization of the bandwidth-linearity trade-off. Finally, our numerical results demonstrate that, given identical optical driving conditions, the SWM configuration increases the 3-dB baseband bandwidth by more than an order of magnitude compared to the EIT-based counterpart, while retaining comparable electric-field sensitivity and revealing a broad, tunable linear operating region.

</details>


### [288] [Phase sensitive topological classification of single-qubit measurements in linear cluster states](https://arxiv.org/abs/2602.13990)
*Sougata Bhattacharyya,Sovik Roy*

Main category: quant-ph

TL;DR: 本文通过建立测量与拓扑手术的对应关系，对一维线性簇态上的单量子比特泡利测量进行几何分类，揭示了不同测量基下的拓扑效应，并引入带framing的ribbon表示来编码量子相位。


<details>
  <summary>Details</summary>
Motivation: 为测量基量子计算中的测量诱导纠缠变换提供统一的几何解释，并揭示量子相位与拓扑不变量之间的直接对应关系。

Method: 将簇态表示为线性Hopf链，建立局部测量与链环模型上拓扑手术的显式对应（测量手术对应）；进一步引入带framing的ribbon表示，将量子相位编码为几何扭转。

Result: Z基测量：体测量对应拓扑切断，边界测量对应修剪；X基测量：移除被测量子比特并拼接其邻居，通过实值关联保持连通性；Y基测量：保持连通性但产生复相位因子，在无framing模型中与X基测量不可区分；引入framing后，相位被编码为手性±90°扭转，实现对所有单量子比特测量的相位敏感且结果分辨的拓扑描述。

Conclusion: 该方法为测量基量子计算中的纠缠变换提供了统一的几何理解，表明量子相位对应于framing拓扑不变量。工作仅限于一维线性簇态和泡利基测量。

Abstract: We provide an explicit geometric classification of single-qubit projective measurements on one-dimensional linear cluster states within a topological framework. By establishing an explicit geometrical correspondence between local measurements and topological surgery operations on an associated link model i.e. a measurement surgery correspondence, we represent the cluster state as a linear Hopf chain. Within this model, measurements in the computational ($Z$) basis act as topological severance in case of bulk measurements while boundary pruning happens for end measurements of qubits. In contrast, transverse ($X$) basis measurements remove the measured qubit while splicing its neighbours, preserving connectivity through real valued correlations. We show that lateral ($Y$) basis measurements also preserve connectivity but generate intrinsically complex phase factors that are not captured by unframed link models, rendering X and Y measurements topologically indistinguishable at the level of connectivity alone. To resolve this ambiguity, we introduce a framed ribbon representation in which quantum phases are encoded as geometric twists, with chiral $\pm 90^\circ} twists corresponding to the phases $\pm i$. This framing yields a phase-sensitive and outcome resolved topological description of all single qubit measurements on linear cluster states. Our approach provides a unified geometric interpretation of measurement-induced entanglement transformations in measurement-based quantum computation, revealing that quantum phases correspond directly to framed topological invariants. The work is restricted to one-dimensional linear cluster states and single-qubit measurements in the Pauli bases.

</details>


### [289] [Semiclassical Simulation of Homogeneous Emitter Ensembles with Local Dissipation](https://arxiv.org/abs/2602.14025)
*Lewis Ruks*

Main category: quant-ph

TL;DR: This paper develops a truncated Wigner approximation method to efficiently simulate large quantum emitter ensembles, revealing emergent coherence in 1D chains.


<details>
  <summary>Details</summary>
Motivation: Efficient and accurate simulation of large quantum emitter ensembles remains challenging despite being fundamental to quantum optical technologies.

Method: Formulates a truncated Wigner approximation (TWA) for permutation-invariant ensembles with local dissipation by sampling stochastic trajectories in an extended Bloch sphere phase space.

Result: Benchmarks show accurate dynamics including nonclassical signatures; demonstrates large-scale simulations of hundreds of ensembles revealing emergent spatial coherence and directional cooperative emission in 1D chains.

Conclusion: The method expands scalable simulation capabilities for quantum emitter ensembles, establishing a bridge between microscopic models and emergent behavior.

Abstract: Emitter ensembles constitute a fundamental component in quantum optical technologies, yet efficient and accurate simulation of large ensembles remains challenging. Here, we formulate a truncated Wigner approximation (TWA) for permutation-invariant emitter ensembles subject to local dissipation by sampling stochastic trajectories in an extended phase space encompassing the Bloch sphere. Benchmarks show that the TWA accurately captures dynamics, including nonclassical signatures, with the approximation improving with ensemble size. We demonstrate large-scale simulations of hundreds of interacting ensembles within the TWA to reveal emergent spatial coherence and selective directionality of cooperative emission in a pumped 1D chain, highlighting a practical path to studying extended light-matter systems. Our results expand the scope of scalable simulations of quantum emitter ensembles, establishing a bridge between microscopic models and emergent behavior.

</details>


### [290] [Enhancing collective spin squeezing via one-axis twisting echo control of individual atoms](https://arxiv.org/abs/2602.14036)
*Zhiwei Hu,Youwei Zhang,Junlei Duan,Mingfeng Wang,Yanhong Xiao*

Main category: quant-ph

TL;DR: 提出一种新的量子态调控方案，通过"三明治"结构（两次单轴扭曲相互作用夹一次量子非破坏测量）在多能级原子系综中同时增强集体自旋压缩并生成可直接用于量子计量实验的两磁子能级纠缠态


<details>
  <summary>Details</summary>
Motivation: 现有利用原子内部自由度增强自旋压缩的方案通常将压缩态编码在复杂的磁子能级叠加态中，导致状态控制困难且限制实际应用

Method: 采用回波序列结构：在两次内部单轴扭曲相互作用之间插入量子非破坏测量，形成"夹心"式调控协议

Result: 既能最优利用内部态增强原子间纠缠，又能将纠缠态编码在两个明确定义的磁子能级上，可直接转换为计量有用的自旋压缩

Conclusion: 为多能级原子系统提供了一种简洁高效的方案，可生成高度纠缠且易于获取的量子态，推动量子增强计量实用化

Abstract: Spin squeezing generated via inter-atom entanglement in multilevel atomic ensembles provides a powerful resource for quantum-enhanced metrology. Existing schemes that harness internal atomic degrees of freedom to boost squeezing typically encode the collective squeezing in complex superpositions of magnetic sublevels, which complicates state control and limits practical applications. Here, we propose a coherent control scheme that simultaneously enhances collective spin squeezing and maps the resulting atom-atom entanglement onto two well-defined magnetic sublevels suitable for subsequent metrology experiments. Our protocol sandwiches a quantum non-demolition measurement between two internal one-axis-twisting interactions arranged in an echo sequence. We show that this approach can optimally leverage internal states to boost the inter-atom entanglement and, at the same time, encode it in two magnetic sublevels, which is readily convertible into metrologically useful spin squeezing. Our results offer a straightforward and efficient strategy for generating highly entangled yet readily accessible quantum states in multilevel atomic systems.

</details>


### [291] [Non-Hermitian Quantum Mechanics of Open Quantum Systems: Revisiting The One-Body Problem](https://arxiv.org/abs/2602.14105)
*Naomichi Hatano,Gonzalo Ordonez*

Main category: quant-ph

TL;DR: This paper revisits the one-body problem in open quantum systems to understand how non-Hermiticity emerges from strong system-environment coupling. By unifying potential scattering (Siegert boundary conditions) and Feshbach projection formalism, the authors derive a new complete basis set that includes resonant states with complex energies and captures non-Markovian dynamics with time-reversal symmetry.


<details>
  <summary>Details</summary>
Motivation: To establish a rigorous, solvable foundation for understanding open quantum systems with arbitrary coupling strength, which will help tackle more complex many-body problems; the one-body problem is chosen because it can be solved exactly and reveals fundamental structures.

Method: Two complementary approaches: (1) Potential scattering defining resonant states as eigenstates under Siegert outgoing boundary conditions; (2) Feshbach formalism that eliminates infinite environmental degrees of freedom to produce an explicitly non-Hermitian effective Hamiltonian. These are unified to construct a new complete basis set.

Result: A new complete set of bases for scattering problems that contains all discrete eigenstates, including resonant states with complex energy eigenvalues, providing a unified description of open quantum systems.

Conclusion: The unified approach reveals the underlying structure of open quantum systems and offers a rigorous framework where the new complete basis set can capture non-Markovian dynamics and time-reversal symmetry, serving as a foundation for understanding many-body interactions.

Abstract: We review analyses of open quantum systems. We show how non-Hermiticity arises in an open quantum system with an infinite environment, focusing on the one-body problem. One of the reasons for taking the present approach is that we can solve the problem completely, making it easier to see the structures of problems involving open quantum systems. We show that this results in the discovery of a new complete set, which is one of the main topics of the present article. Another reason for focusing on the one-body problem is that the theory permits the strong coupling between the system and the environment. In the current research landscape, it is valuable to revisit the one-body problem for open quantum systems, which can be solved accurately for arbitrary strengths of the system-environment couplings. A rigorous understanding of the problem structures in the present approach will be helpful when we tackle problems with many-body interactions. First, we consider potential scattering and directly define the resonant state as an eigenstate of the Schrödinger equation under the Siegert outgoing boundary condition. We show that the resonant eigenstate can have a complex energy eigenvalue, even though the Hamiltonian is seemingly Hermitian. Second, we introduce the Feshbach formalism, which eliminates the infinite degrees of freedom of the environment and represents its effect as a complex potential. The resulting effective Hamiltonian is explicitly non-Hermitian. By unifying these two ways of defining resonant states, we obtain a new complete set of bases for the scattering problem that contains all discrete eigenstates, including resonant states. We finally mention the non-Markovian dynamics of open quantum systems. We emphasize the time-reversal symmetry of the dynamics that continuously connects the past and the future. We can capture it using the new complete set that we develop here.

</details>


### [292] [Early-stage memory effect on the dephasing charger-mediated quantum battery](https://arxiv.org/abs/2602.14146)
*Yu Wang,Jiasen Jin*

Main category: quant-ph

TL;DR: Non-Markovian memory effects in a two-qubit quantum battery system enhance charging performance by increasing maximal ergotropy through early-stage negative dephasing rates and quantum jumps.


<details>
  <summary>Details</summary>
Motivation: To investigate how non-Markovian memory effects in a charger-mediated quantum battery system influence charging performance, specifically whether early-stage memory can outperform conventional Markovian approximations.

Method: Modeled a two-qubit system (battery + charger coupled to a reservoir) using a time-local Lindblad master equation with a time-dependent dephasing rate, analyzed non-Markovian quantum jumps, and proposed a discrete-time quantum circuit scheme with global/random local operations.

Result: Early-stage negative dephasing rates (indicating memory effects) increase the battery's maximal ergotropy compared to Markovian approximations; non-Markovian quantum jumps explain the performance enhancement.

Conclusion: Non-Markovian memory effects significantly improve quantum battery charging efficiency, demonstrating the practical potential of harnessing environmental memory for quantum energy storage.

Abstract: We investigate the performance of the charger-mediated quantum battery modeled by a two-qubit system. One of the qubits acts as the battery and the other acts as the charger which is subjected to a reservoir. We derived the time-local master equation in Lindblad form with a time-dependent dephasing rate. The dephasing rate may be negative in the early-stage of the charging process and thus indicate the presence of the memory effect. We find that such early-stage memory effect could increase the maximal ergotropy of the battery compared with the one under Markovian approximation with the corresponding asymptotic dephase rate. The enhancement of the performance is explained by means of the non-Markovian quantum jumps. Moreover, a discrete time scheme of the measurement-enhanced quantum battery is proposed in a quantum circuit with global and random local operations.

</details>


### [293] [Approximating the $S$ matrix for solving the Marchenko equation: the case of channels with different thresholds](https://arxiv.org/abs/2602.14150)
*N. A. Khokhlov*

Main category: quant-ph

TL;DR: Extends Marchenko theory for multi-channel inverse scattering using rational+sinc series approximation with relativistic kinematics, enabling reconstruction of closed-channel data from open-channel experimental measurements, validated on πN scattering.


<details>
  <summary>Details</summary>
Motivation: To solve multi-channel inverse scattering problems where only partial channels are experimentally accessible, incorporating relativistic effects and reconstructing full potential information from limited data.

Method: Approximates n-channel S-matrix per element with rational terms plus truncated sinc series, generalizes Marchenko theory with relativistic kinematics, and reconstructs closed-channel submatrices by analyzing analytic structure near thresholds.

Result: Successfully demonstrated reconstruction of closed-channel information from open-channel data near thresholds, verified convergence against known potentials, and applied to S₃₁ πN scattering data.

Conclusion: The extended method effectively solves relativistic multi-channel inverse scattering, allowing full potential reconstruction from incomplete experimental S-matrix data.

Abstract: This work extends previous results on the inverse scattering problem within the framework of Marchenko theory (fixed-$l$ inversion). In particular, I approximate an $n$-channel $S$-matrix as a function of the first-channel momentum $q$ by a sum of a rational term and a truncated sinc series for each matrix element. Relativistic kinematics are taken into account through the correct momentum-energy relation, and the necessary minor generalization of Marchenko theory is given.
  For energies where only a subset of scattering channels is open, the analytic structure of the $S$-matrix is analyzed. I demonstrate that the submatrix corresponding to closed channels, particularly near their thresholds, can be reconstructed from the experimentally accessible submatrix of open channels.The convergence of the proposed method is verified by applying it to data generated from a direct solution of the scattering problem for a known potential, and comparing the reconstructed potential with the original one. Finally, the method is applied to the analysis of $S_{31}$ $πN$ scattering data.

</details>


### [294] [Bidirectional Quantum Processor Interfacing by a 4-Kelvin Analog Signal Chain for Superconducting Qubit Control and Quantum State Readout](https://arxiv.org/abs/2602.14165)
*Deepak R,Lokendra Kanawat,Jayadeep K,Priyesh Shukla*

Main category: quant-ph

TL;DR: 本文提出了一种工作在4K的低温模拟信号处理架构，用于超导量子比特控制和量子态读取，通过锁相环、I/Q调制和8-PSK解调实现双向信号通路，仿真验证了其高精度和低误码率。


<details>
  <summary>Details</summary>
Motivation: 为了弥合室温数字控制器与毫开尔文量子处理器之间的温度差距，在低温环境下实现精确的量子比特门操作和量子态读取，同时保持信号完整性。

Method: 采用180nm低温MOSFET模型进行SPICE仿真，设计完整的双向信号通路架构，考虑了载流子冻结、阈值电压升高等4K温度效应。

Result: 实现了I/Q相位误差低于2°、镜像抑制比超过35 dB、误码率低于10⁻⁶，验证了端到端信号完整性。

Conclusion: 本研究为可扩展的低温量子控制系统提供了一个模块化且经过仿真验证的框架，能够有效工作在4K环境。

Abstract: This paper presents a comprehensive cryogenic analog signal processing architecture designed for superconducting qubit control and quantum state readout operating at 4 Kelvin. The proposed system implements a complete bidirectional signal path bridging room-temperature digital controllers with quantum processors at millikelvin stages. The control path incorporates a Phase-Locked Loop (PLL) for stable local oscillator generation, In-phase/Quadrature (I/Q) modulation for precise qubit gate operations, and a cryogenic power amplifier for signal conditioning. The readout path features a Low Noise Amplifier (LNA) with 14 dB gain and 8-Phase Shift Keying (8-PSK) demodulation for quantum state discrimination. All circuit blocks are designed and validated through SPICE simulations employing cryogenic MOSFET models at 180nm that account for carrier freeze-out, threshold voltage elevation, and enhanced mobility at 4 K. Simulation results demonstrate successful end-to-end signal integrity with I/Q phase error below 2°, image rejection ratio exceeding 35~dB, and symbol error rate below $10^{-6}$. This work provides a modular, simulation-validated framework for scalable cryogenic quantum control systems.

</details>


### [295] [Quantum field theory measurements for relativistic particles](https://arxiv.org/abs/2602.14175)
*Nadia Koliopoulou,Charis Anastopoulos,Ntina Savvidou*

Main category: quant-ph

TL;DR: This paper develops a consistent measurement theory for relativistic quantum fields with spin and internal structure using the Quantum Temporal Probabilities framework, addressing limitations of non-relativistic models.


<details>
  <summary>Details</summary>
Motivation: Standard non-relativistic quantum measurement theories cannot incorporate essential relativistic principles (locality, causality, Lorentz covariance). While existing work focuses on scalar fields, realistic particles have spin, polarization, and internal degrees of freedom that create new conceptual and operational challenges for quantum field measurements.

Method: The authors employ the Quantum Temporal Probabilities (QTP) framework to describe measurements of electromagnetic, Dirac, and internally structured scalar fields.

Result: Four key results: (1) Time-of-arrival probabilities accounting for spin/polarization effects; (2) Generalized photodetection formulas extending beyond Glauber's theory; (3) Unambiguous derivation of particle oscillation formulas with identified limitations; (4) First-principles analysis of relativistic qudits.

Conclusion: The QTP framework successfully extends relativistic quantum field measurement theory to particles with spin and internal structure, providing consistent measurement models that respect relativistic principles.

Abstract: The formulation of a consistent measurement theory for relativistic quantum fields has become a problem of growing foundational and practical significance. Standard non-relativistic measurement models fail to incorporate the essential relativistic principles of locality, causality, and Lorentz covariance, and are therefore inadequate for quantum field theoretic settings. While most existing work focuses on scalar fields, realistic particles possess spin, polarization, and internal degrees of freedom that introduce new conceptual and operational challenges. To this end, we employ the Quantum Temporal Probabilities (QTP) framework for relativistic measurements to describe electromagnetic, Dirac, and internally structured scalar fields. Our results include probabilities for the time-of-arrival that take spin/polarization into account, generalized photodetection formulas beyond Glauber's theory, an unambiguous derivation of the particle oscillation formula together with its limitations, and a first-principles analysis of relativistic qudits.

</details>


### [296] [Fully integrated quantum frequency processor on a silicon chip](https://arxiv.org/abs/2602.14240)
*Sara Congia,Leopold Virot,Elena Rovetta,Antonio Fincato,Frederic Boeuf,Matteo Galli,Daniele Bajoni,Massimo Borghi*

Main category: quant-ph

TL;DR: 研究人员开发了首个完全集成的量子频率处理器，将量子态生成、相干频率混合和可编程光谱控制集成在4×7mm²硅光子芯片上。该芯片实现了保真度超过99.9%的可调频率分束器和95.7%的Bell态层析成像，为大规模频域光子处理器的发展迈出关键一步。


<details>
  <summary>Details</summary>
Motivation: 频率-bin编码在光子量子信息处理中具有高维度、门并行化和兼容现有电信基础设施等优势，但其可扩展部署一直受限于缺乏能够统一量子态生成、相干频率混合和可编程光谱控制的集成平台。

Method: 在单晶硅光子芯片上单片集成微谐振器双光子量子频率梳源、泵浦抑制滤波器、高速相位调制器和四通道逐线脉冲整形器，构建全集成量子频率处理器。通过该芯片演示可调频率分束器、通用单量子比特门、高维频率-bin纠缠态生成与操控、双光子量子行走以及片上Bell态量子态层析成像。

Result: 实现了成功率超过94%、保真度高于99.9%的可调频率分束器；成功合成了通用单量子比特门；在芯片上完全操控高维频率-bin纠缠态并演示双光子量子行走；完成首个片上频率-bin Bell态量子态层析成像，保真度达95.7(3)%。所有功能集成在4×7mm²芯片上。

Conclusion: 该工作通过集成所有关键功能元件，展示了可扩展至更多模式的能力，标志着向大规模频域光子处理器（包括经典和量子应用）发展的重要里程碑。

Abstract: Frequency-bin encoding has recently emerged as a powerful approach for photonic quantum information processing, offering high dimensionality, gate-parallelization, and compatibility with existing telecommunication infrastructure. However, its scalable deployment has so far been hindered by the lack of an integrated platform capable of unifying quantum state generation, coherent frequency mixing, and programmable spectral control.\\ Here, we report the first fully integrated quantum frequency processor, monolithically integrating on the same silicon photonic chip a microresonator-based biphoton quantum frequency comb source, a pump-rejection filter, high-speed phase modulators, and a four-channel, line-by-line pulse shaper. We demonstrate key functionalities, such as tunable frequency beamsplitters with success probabilities exceeding $94\%$ and fidelities above $99.9\%$, as well as the ability to synthesize more general single-qubit gates. Finally, we generate and coherently manipulate high-dimensional frequency-bin entangled states entirely on chip, showcasing control over two-photon quantum walks and performing the first on-chip frequency-bin quantum state tomography of a Bell-state with a fidelity of $95.7(3)\%$. By integrating all key functional elements on the same $4\times7\,\textrm{mm}^2$ chip, with the possibility of scaling to a larger number of modes, our work marks an important step toward large-scale frequency-domain photonic processors for both classical and quantum applications.

</details>


### [297] [Geometric phase of arbitrary Mueller evolutions and its two-level quantum analogue](https://arxiv.org/abs/2602.14245)
*José J Gil*

Main category: quant-ph

TL;DR: 该论文揭示了任意物理可实现的穆勒变换中，干涉几何相位由特征分解中纯特征分量的SO(3)旋转唯一决定，而其余分量仅降低条纹可见度，不会产生几何和乐。


<details>
  <summary>Details</summary>
Motivation: 几何相位在光学和量子系统中具有重要意义，但尚不清楚在包含退极化等复杂效应的一般穆勒变换中，几何相位的物理来源是什么。

Method: 采用特征分解方法，将穆勒矩阵分解为纯特征分量、判别分量和最大混合分量，分析各部分对几何相位的贡献。

Result: 发现只有纯特征分量中的SO(3)旋转部分能固定几何相位，其他分量（判别分量和最大混合分量）仅能降低干涉条纹可见度，不能产生几何和乐。

Conclusion: 几何相位是相干旋转的鲁棒特征，退极化效应只影响测量精度不影响相位值，这一结论适用于开放量子系统的两能级动力学。

Abstract: We show that, for any physically realizable Mueller transformation -- including arbitrarily depolarizing maps -- the interferometric (Pancharatnam) geometric phase is fixed uniquely by the SO(3) rotation associated with the unitary (retarding) part of the pure characteristic component selected by the characteristic decomposition. All remaining characteristic contributions (discriminant and maximally mixed) can only reduce fringe visibility; they never generate geometric holonomy, even if their pure constituents involve rotations. We further establish the quantum analogue for open two-level dynamics: in the Choi representation of qubit channels, the geometric phase is fixed by the coherent unitary part of the dominant rank-one characteristic component, while the remaining dissipative structure affects visibility only.

</details>


### [298] [RASCqL: Reaction-time-limited Architecture for Space-time-efficient Complex qLDPC Logic](https://arxiv.org/abs/2602.14273)
*Willers Yang,Jason Chadwick,Mariesa H. Teo,Joshua Viszlai,Fred Chong*

Main category: quant-ph

TL;DR: 提出RASCqL架构，通过应用定制的qLDPC码修改方案，在保持空间时间效率的同时实现量子计算关键子程序，相比表面码架构可减少2-7倍的硬件开销。


<details>
  <summary>Details</summary>
Motivation: qLDPC码虽能大幅减少量子计算硬件占用，但在大规模实用化时，缺乏高效指令集架构会削弱其优势。需要设计空间时间高效的ISA来支持相关量子应用。

Method: 采用应用定制的代码修改方案，将特定Clifford指令嵌入为可实现的矩阵自同构，利用中性原子阵列的并行物理操作实现快速量子纠错和高保真度横向操作。

Result: 在物理错误率为2×10⁻³到5×10⁻⁴时，关键子程序的空间时间成本与最先进的表面码架构相当，但硬件占用减少2-7倍，且不增加额外硬件复杂度。

Conclusion: 证明了qLDPC码作为复杂指令集量子计算模块的具体可行路径，扩展了其在容错量子计算架构中的实用性。

Abstract: Quantum low-density parity-check (qLDPC) codes offer a promising route to scalable fault-tolerant quantum computing (FTQC) due to their substantially reduced footprint, but these gains can be diluted at utility scale if we cannot also realize a space-time-efficient instruction-set architecture (ISA) for relevant quantum applications. We present RASCqL, a Reaction-time-limited Architecture for Space-time-efficient Complex qLDPC Logic, introducing a complex-instruction-set quantum computer (CISQ) that supports key algorithmic subroutines such as quantum arithmetic, table lookups, and magic-state distillation directly in co-designed qLDPC codes.
  Unlike prior constructions for qLDPC logic that aim at versatile ISAs amenable to diverse circuits, RASCqL adopts an application-tailored code-modification scheme that embeds specific complex Clifford instructions useful for functional subroutines as virtually implementable matrix automorphisms. RASCqL further leverages parallel physical operations in reconfigurable neutral-atom array platforms to achieve fast QEC cycles and high-fidelity transversal operations. At the cost of increased design complexity, RASCqL implements key algorithmic subroutines at space-time costs comparable to state-of-the-art transversal surface-code architectures while achieving up to $2\times$ to $7\times$ footprint reduction under realistic physical error rates of $2 \times 10^{-3}$ to $5 \times 10^{-4}$, without additional hardware complexity. RASCqL thus demonstrates a concrete path forward for qLDPC codes as CISQ compute modules, extending their practical utility in fault-tolerant quantum computing architectures.

</details>


### [299] [Quantum entanglement enhanced via dark mode control in molecular optomechanics](https://arxiv.org/abs/2602.14312)
*E. Kongkui Berinyuy,P. Djorwé,A. N. Al-Ahmadi,H. Ardah,A. -H. Abdel-Aty*

Main category: quant-ph

TL;DR: 提出一种分子腔光力学方案，通过打破暗模效应增强量子纠缠，在暗模破缺 regime 下实现双模和三模纠缠的两倍提升，且对热噪声更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代量子技术需要多模量子纠缠资源，但纠缠工程受到暗模效应的强烈抑制，亟需突破这一限制以增强量子关联。

Method: 设计一种分子腔光力学结构，利用两个分子系综间的耦合，通过合成规范场进行相位调制，调节耦合强度和相位来切换暗模未破缺(DMU)和破缺(DMB)状态。

Result: 暗模未破缺 regime下纠缠度显著降低或被抑制；暗模破缺 regime下纠缠度大幅提升(最高两倍增强)，且对热噪声的鲁棒性显著优于未破缺 regime。

Conclusion: 该方案为改进量子关联工程和产生抗噪声量子资源提供了基准系统，可广泛应用于现代量子技术。

Abstract: Quantum entanglement is an interesting resource for modern quantum technologies, where generating multiple quantum entanglement is highly required. However, entanglement engineering between multiple modes is strongly suppressed by dark mode effect. Here, we proposed a scheme based on molecular cavity optomechanical structure that enhances quantum bipartite and tripartite entanglement via dark mode breaking. Our proposal consists of an optical cavity that hosts two molecular ensembles which are coupled through an intermolecular coupling. A vibrational hopping rate $J_m$ captures the intermolecular coupling that is phase modulated via the synthetic gauge field method. The breaking of the dark mode is controlled by tuning both the intermolecular coupling and its modulation phase. By adjusting these parameters in our proposal, we can flexibly switch between the Dark Mode Unbroken (DMU) and the Dark Mode Broken (DMB) regimes. We find that in the dark-mode-unbroken regime, the amount of the generated bipartite and tripartite entanglement is significantly low or is suppressed. In contrast, in the dark-mode-broken regime, the entanglement is greatly enhanced,i.e., up to twofold enhancement. Moreover, the generated entanglement is more resilient against thermal noise in the dark-mode-broken regime compared to the thermal robustness in the unbroken regime. Therefore, our proposed scheme serves as a benckmark system to improve quantum correlations engineering, and to generate noise-tolerant quantum resources for applications in numerous modern quantum technologies.

</details>


### [300] [Scalable Clifford-Based Classical Initialization for the Quantum Approximate Optimization Algorithm](https://arxiv.org/abs/2602.14327)
*Dhanvi Bharadwaj,Yuewen Hou,Guang-Yi Li,Gokul Subramanian Ravi*

Main category: quant-ph

TL;DR: 提出SPIQ框架，通过松弛QAOA ansatz和Clifford可制备态实现高效参数初始化，显著提升量子优化算法收敛速度与解质量


<details>
  <summary>Details</summary>
Motivation: VQAs（如QAOA）在组合优化问题中潜力大，但初始参数选择困难且ansatz表达受限，导致初始化效率低、可扩展性差

Method: 提出SPIQ框架：采用松弛QAOA ansatz支持经典搜索，筛选Clifford-preparable量子态作为优质初始态，降低量子电路评估成本

Result: 在QUBO/PUBO/PCBO问题上实现最高80%精度提升，初始态多样性减少10,000倍，跨数十至数百量子比特实例验证有效

Conclusion: 该框架具备可扩展性和应用无关性，为近中期量子设备提供高效初始化方案，显著降低量子计算资源开销

Abstract: Variational Quantum Algorithms (VQAs), such as the Quantum Approximate Optimization Algorithm (QAOA), offer a promising route to tackling combinatorial optimization problems on near and intermediate-term quantum devices. However, their performance critically depends on the choice of initial parameters, and the limited expressiveness of the QAOA ansatz makes identifying effective initializations both difficult and unscalable. To address this, we propose a framework, Scalable Parameter Initialization for QAOA (SPIQ), that employs a relaxed QAOA ansatz to enable classical search over a set of Clifford-preparable quantum states that yield high-quality solutions. These states serve as superior QAOA initializations, driving rapid convergence while significantly reducing the quantum circuit evaluations needed to reach high-quality solutions and consequently lowering quantum-device cost. We present a scalable, application-agnostic initialization framework that achieves an absolute accuracy improvement of up to 80% over state-of-the-art initialization and reduces initial-state diversity by up to 10,000x across QUBO, PUBO, and PCBO problems spanning tens to hundreds of qubits. We further benchmark its performance on a wide range of problem formulations and instances derived from real-world datasets, demonstrating consistent and scalable improvements. Furthermore, we introduce two complementary strategies for selecting high-quality Clifford points identified by our search procedure and using them to seed multi-start optimization, thereby enhancing exploration and improving solution quality.

</details>


### [301] [High-fidelity Quantum Readout Processing via an Embedded SNAIL Amplifier](https://arxiv.org/abs/2602.14333)
*Leon Bello,Boris Mesits,Michael Hatridge,Hakan E. Türeci*

Main category: quant-ph

TL;DR: 该论文提出了一种嵌入非线性SNAIL元件的新型量子态读取方案，通过在芯片上直接处理读取信号，解决了传统方法中硬件复杂度高和无法片上处理的问题，提高了读取保真度并抑制了退相干。


<details>
  <summary>Details</summary>
Motivation: 大规模超导量子处理器的发展面临量子态读取的核心挑战。传统色散读取架构依赖笨重的隔离器和外部放大器，引入了显著的硬件开销，并限制了片上信息处理的机会。

Method: 研究人员提出将非线性超导非对称感应元件(SNAIL)嵌入读取链路，实现读取信号的相干和定向片上处理。该平台通过工程化耦合使频率复用谐振器相互作用，形成可调的读取-放大-输出架构，能够原位操纵量子读取数据。通过理论建模和数值优化验证了方案的可行性。

Result: 研究表明，该SNAIL平台能够增强读取保真度，抑制测量引起的退相干，并简化硬件复杂度。

Conclusion: 混合SNAIL平台被证明是下一代处理器中可扩展且相干的量子态读取的有希望的构建模块。

Abstract: Scalable, high-fidelity quantum-state readout remains a central challenge in the development of large-scale superconducting quantum processors. Conventional dispersive readout architectures depend on bulky isolators and external amplifiers, introducing significant hardware overhead and limiting opportunities for on-chip information processing. In this work, we propose a novel approach that embeds a nonlinear Superconducting Nonlinear Asymmetric Inductive eLement (SNAIL) into the readout chain, enabling coherent and directional processing of readout signals directly on-chip. This embedded SNAIL platform allows frequency-multiplexed resonators to interact through engineered couplings, forming a tunable readout-amplifier-output architecture that can manipulate quantum readout data \textit{in situ}. Through theoretical modeling and numerical optimization, we show that this platform enhances fidelity, suppresses measurement-induced decoherence, and simplifies hardware complexity. These results establish the hybridized SNAIL as a promising building block for scalable and coherent quantum-state readout in next-generation processors.

</details>


### [302] [Anonymous quantum sensing robust against state preparation errors](https://arxiv.org/abs/2602.14396)
*Hiroto Kasai,Seiichiro Tani,Yasuhiro Tokura,Yuki Takeuchi*

Main category: quant-ph

TL;DR: 提出一种抗噪声的匿名量子传感协议，通过设计GHZ与Dicke态的验证方案解决态制备误差问题，提升生物磁场隐私保护场景下的实用性。


<details>
  <summary>Details</summary>
Motivation: 生物磁场携带隐私信息时需保护信号源位置，但现有匿名量子传感协议在态制备噪声下失效，需提升鲁棒性。

Method: 提出针对GHZ态与Dicke态叠加的量子态验证协议，并与原匿名传感协议结合，替代直接保真度估计。

Result: 验证协议比直接保真度估计更高效，有效纠正态制备误差导致的磁场幅值估计错误。

Conclusion: 该协议显著提升匿名量子传感在真实噪声环境中的性能，推动其在生物磁场隐私保护等场景的实用化。

Abstract: Networked quantum sensors have several applications such as the mapping of magnetic fields. When the magnetic fields are biomagnetic ones, i.e., they contain some private information, the information of from who non-zero magnetic fields occur has to be protected from eavesdroppers. Anonymous quantum sensing keeps it secret by estimating amplitudes of the magnetic fields without disclosing the positions of non-zero magnetic fields. In this paper, we propose an anonymous quantum sensing protocol that is robust against any independent noise in state preparations. To this end, we devise a quantum state verification protocol for a superposition of Greenberger-Horne-Zeilinger and Dicke states and combine it with the original protocol of anonymous quantum sensing. Our verification protocol can decide whether the fidelity between the ideal and actual states is high or low more efficiently than the direct fidelity estimation. Since the original protocol of anonymous quantum sensing cannot correctly estimate the amplitudes of the magnetic fields under state preparation errors, our results would improve the performance of anonymous quantum sensing in realistic situations.

</details>


### [303] [The Multiparameter Frontier: Metrological Hierarchy and Robustness in Dispersive Quantum Interferometry](https://arxiv.org/abs/2602.14420)
*Lucas Ferreira R. de Moura,Daniel Y. Akamatsu,G. D. de Moraes Neto,Norton G. de Almeida*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a dispersive quantum thermometry protocol for simultaneous estimation of inverse temperature $β$ and interaction strength $x$ using a nonlinear Mach-Zehnder interferometer coupled to a thermal ancilla. We derive closed-form expressions for the quantum Fisher information matrix, establishing that metrological performance depends solely on the thermal visibility $\mathcal{V}(β)$ and its derivative. The output state remains diagonal in photon-number basis, making photon counting globally optimal and saturating the multiparameter quantum Cramér-Rao bound without adaptive feedback. Moving beyond ideal unitary evolution, we analyze protocol robustness under concurrent amplitude and phase damping. Using Fisher Information Susceptibility, we establish a clear hierarchy: NOON states offer maximal theoretical sensitivity but exhibit exponential fragility to loss, rendering them impractical. Squeezed vacuum states emerge as robust candidates for steady-state sensing, while cat states prove compelling for transient thermometry by retaining significant coherence after photon loss. We validate these predictions through digital quantum circuit implementation on IBM's \texttt{ibm_torino} processor. Experimental results confirm the predicted Fisher information landscape while revealing systematic noise-induced biases, demonstrating that current NISQ hardware can effectively benchmark fundamental trade-offs in multiparameter quantum sensing.

</details>


### [304] [Electron readout contrast enhancement in the parallel nuclear regime of an exchange-coupled donor spin qubit system](https://arxiv.org/abs/2602.14426)
*Holly G. Stemp,Mark R. van Blankenstein,Benjamin Wilhelm,Serwan Asaad,Mateusz T. Mądzik,Arne Laucht,Fay E. Hudson,Andrew S. Dzurak,Kohei M. Itoh,Alexander M. Jakob,Brett C. Johnson,David N. Jamieson,Andrea Morello*

Main category: quant-ph

TL;DR: 硅基施主自旋量子比特中，当施主原子核自旋平行排列时，通过单电子晶体管(SET)读取的电子自旋测量对比度显著高于反平行排列。本研究揭示这是由于平行自旋配置下额外电子隧穿事件导致的，为提升量子比特读取保真度提供了新策略。


<details>
  <summary>Details</summary>
Motivation: 在硅基施主自旋量子比特实验中，研究人员观察到当施主原子核处于平行自旋取向时，通过Elzerman式读取至单电子晶体管(SET)的电子读取对比度显著高于反平行取向，但这一现象长期缺乏物理解释。理解这一效应对于提升量子比特读取性能至关重要。

Method: 本研究对平行核自旋regime下的交换耦合施主系统进行了详细分析，提出了相应的物理机制模型来解释观测到的对比度增强现象。

Result: 研究发现，在施主原子核平行自旋配置下，读取过程中会发生额外的电子隧穿事件至SET岛，这是导致读取对比度增强的根本原因。

Conclusion: 该发现为改善电子自旋读取保真度提供了具体策略，同时深化了对施主量子比特架构中自旋依赖隧穿过程的理解，有助于推动硅基量子计算的发展。

Abstract: Recent experiments on donor-based spin qubits in silicon have leveraged the exchange interaction between electrons bound to separate donor nuclei to perform two-qubit operations. A consistently observed yet unexplained phenomenon in such systems is the significant increase in electron readout contrast, measured via Elzerman-style readout to a single-electron transistor (SET) island, when the donor nuclei are initialized in a parallel spin orientation compared to an anti-parallel orientation. In this work, we present a detailed analysis of the exchange-coupled donor system in the parallel nuclear regime and propose a physical mechanism for this effect. We attribute the enhanced readout contrast to an additional electron tunneling event to the SET during a single read period, when the donor nuclei are aligned in a parallel spin configuration. These insights inform strategies for improving electron readout fidelity in these systems and contribute to a more complete understanding of spin-dependent tunnelling processes in donor-based qubit architectures.

</details>


### [305] [Fermionic Stoner-Dicke phase transition in Circuit Quantum Magnetostatics](https://arxiv.org/abs/2602.14437)
*Adel Ali,Alexey Belyanin*

Main category: quant-ph

TL;DR: A minimal, analytically solvable model of fermions coupled to quantum magnetic flux via an LC resonator exhibits exotic many-body phenomena including Stoner orbital instability and Dicke-like quantum phase transitions, offering a new platform for quantum simulation beyond standard cavity QED.


<details>
  <summary>Details</summary>
Motivation: To develop a tunable many-body system that couples magnetic field (rather than electric field) to matter, enabling exploration of novel quantum phases and transitions in regimes relevant to circuit QED and mesoscopic physics.

Method: Proposes a theoretical model of fermions coupled to quantized magnetic flux of an LC resonator; adds Josephson junction for nonlinearity; also considers tight-binding systems with artificial JJ nonlinearity; system is analytically diagonalizable.

Result: Exhibits Stoner orbital instability, Dicke-like quantum phase transition, nonlinear flux-matter phases, and sector-selective photon dressing when Josephson junction is included.

Conclusion: This magnetic-flux-coupled system provides a versatile, analytically tractable platform for exploring exotic many-body quantum phenomena, extending beyond conventional electric-dipole cavity QED approaches.

Abstract: We present a minimal tunable many-body system of fermions coupled to quantum magnetic flux, which is analytically diagonalizable and exhibits a variety of many-body phenomena such as Stoner orbital instability and Dicke-like quantum phase transition. In contrast to standard cavity quantum electrodynamics with its electric-dipole coupling of the electric field operators with matter, here it is the quantized magnetic field of an LC-resonator which is coupled to the angular momentum of particles. Adding the Josephson junction (JJ) to the linear LC circuit allows us to explore nonlinear flux-matter phases and sector-selective photon dressing in regimes relevant to circuit QED and mesoscopic rings. Furthermore, we consider the tight-binding systems that exhibit a tunable nonlinearity representing artificial JJ, but without actual JJs included in the circuit.

</details>


### [306] [A hardware-native time-frequency GKP logical qubit toward fault-tolerant photonic operation](https://arxiv.org/abs/2602.14461)
*Tai Hyun Yoon*

Main category: quant-ph

TL;DR: 该论文实现了在单光子连续相空间中编码的硬件原生时频GKP逻辑量子比特，建立了一种传播式光子实现方案，并提出了用于主动综合征提取和确定性位移恢复的具体路径，为容错光子量子计算架构提供了硬件兼容的集成方案。


<details>
  <summary>Details</summary>
Motivation: 在光子系统中实现硬件原生的时频域GKP玻色子网格编码逻辑量子比特，以建立可扩展的传播式光子量子计算架构，并解决量子纠错问题。

Method: 使用相干驱动纠缠非线性双光子源确定性产生有限能量网格态，利用单光子频率梳超模作为载体，通过光学频率梳参考锚定时频相空间并在硬件层面强制执行对易位移稳定子，通过相位和延时控制实现逻辑操作。

Result: 成功实现了时频域GKP逻辑量子比特的硬件原生实现，证明了抖动、漂移和相位噪声自然映射为格点内的高斯位移误差，具备内在可纠正性，并建立了通往主动综合征提取和位移恢复的明确路径。

Conclusion: 该工作为将时频GKP逻辑层集成到擦除感知型和融合式容错光子量子计算架构中提供了硬件兼容的技术路线，是迈向实用化光子量子计算的重要一步。

Abstract: We realize a hardware-native time--frequency Gottesman--Kitaev--Preskill (GKP) logical qubit encoded in the continuous phase space of single photons, establishing a propagating photonic implementation of bosonic grid encoding. Finite-energy grid states are generated deterministically using coherently driven entangled nonlinear biphoton sources that produce single-photon frequency-comb supermodes. An optical-frequency-comb reference anchors the time--frequency phase space and enforces commuting displacement stabilizers directly at the hardware level, continuously defining the logical subspace. Timing jitter, spectral drift, and phase noise map naturally onto Gaussian displacement errors within this lattice, yielding intrinsic correctability inside a stabilizer cell. Logical operations correspond to experimentally accessible phase and delay controls, enabling deterministic state preparation and manipulation. Building on the modal time--frequency GKP framework, we identify a concrete pathway toward active syndrome extraction and deterministic displacement recovery using ancillary grid states and interferometric time--frequency measurements. These primitives establish a hardware-compatible route for integrating the time--frequency GKP logical layer into erasure-aware and fusion-based fault-tolerant photonic architectures.

</details>


### [307] [A lesson from a small particle about quantum theory with strong implications for cosmology](https://arxiv.org/abs/2602.14465)
*Daniel Sudarsky,Octavio Guerrero*

Main category: quant-ph

TL;DR: 中子电偶极矩的严格限制质疑暴涨宇宙学中量子不确定性的标准解释，暗示需要新物理。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在揭示中子电偶极矩实验界限对暴涨宇宙学中量子涨落解释的深刻影响，挑战将量子不确定性等同于经典随机过程的流行观点。

Method: 通过概念性分析，将强相互作用时间反演对称性的实验约束与宇宙原初不均匀性的量子起源理论联系起来，考察量子理论应用的一致性。

Result: 标准宇宙学模型中将量子不确定性视为真实随机涨落的做法与中子电偶极矩的严格实验限制存在冲突。

Conclusion: 必须构建新的物理框架，以提供概念自洽且与量子理论其他应用相兼容的宇宙结构形成机制。

Abstract: The establishment of extremely strong bounds on the magnitude of the electric dipole moment of the neutron, a quantity that is of great importance for determining the level of time reversal symmetry respected by the strong interactions, offers an important lesson regarding the manner in which quantum uncertainties are interpreted in the inflationary cosmological account of the generation of the primordial inhomogeneities that give rise to the universe's structure. The identification of quantum uncertainties with actual stochastic fluctuations, a standard aspect of the current physical account for the emergence of the cosmic structure, is called into question. This opens the door for novel aspects of physics that are needed in order to provide a satisfactory account that is both conceptually clear and does not conflict with the use of quantum theory in other settings.

</details>


### [308] [Bell-like States in Classical Optics: A Process-Theoretic and Sheaf-Theoretic (Categorical) Clarification](https://arxiv.org/abs/2602.14508)
*Partha Ghose*

Main category: quant-ph

TL;DR: 该研究利用经典偏振光学的二维复希尔伯特空间，在随机光学场中实现量子强度的Bell-CHSH关联，并通过范畴论框架分离运动学非可分性与操作语境性，表明语境性可在经典随机光学中出现。


<details>
  <summary>Details</summary>
Motivation: 探究经典系统是否能够模拟量子关联，特别是Bell-CHSH不等式的违反，并厘清非可分性与语境性在非定域因果性中的作用，同时提供低成本实验平台。

Method: 将制备与调控流程视为操作过程理论（如CPM(FHilb)）中的单一态射，函子性地导出经验模型（情境索引的概率分布），并应用Abramsky–Brandenburger层论判据分析语境性。

Result: 证明适当制备的两束偏振态可在随机光学场中产生量子强度的Bell-CHSH关联；该平台可用于在噪声、粗粒化、选择性采样等实际缺陷下检验Bell/CHSH和语境性见证；外部锥形折射（ECR）可作为替代制备方法。

Conclusion: 运动学非可分性与操作语境性是两个独立概念，单独任何一个均不必然导致非定域因果性；语境性可在经典可实现的随机光学体系中产生，深化了对量子关联与经典模拟界限的理解。

Abstract: Classical polarization optics is naturally described by a two-dimensional complex Hilbert space (Jones vectors), so the tensor-product kinematics underlying bipartite nonseparability is already available classically. For statistical (stochastic) optical fields, and under an operational stance where outcomes are not assumed pre-assigned prior to detection, suitably prepared two-beam polarization states can exhibit Bell--CHSH correlations of quantum strength. The same platform offers a tunable, low-cost testbed for stress-testing Bell/CHSH and contextuality witnesses under realistic imperfections (noise, coarse binning, selective sampling). We also outline an alternative preparation based on external conical refraction (ECR), where engineered intersecting conical-refraction rings mimic the intersecting emission cones of SPDC. We give a self-contained categorical formulation: the preparation-and-conditioning pipeline (Hadamard-like splitting, CNOT-like coupling, and routing/conditioning that removes unwanted contributions) is treated as a single morphism in an operational process theory (e.g. $\mathbf{CPM}(\mathbf{FHilb})$). From it we functorially extract an empirical model, i.e. a compatible family of context-indexed probability distributions. The Abramsky--Brandenburger sheaf criterion then applies: noncontextuality is the existence of a global section, and CHSH violation is a precise failure-to-glue. This separates kinematic nonseparability from operational contextuality and clarifies why neither, by itself, entails nonlocal causation; contextuality can arise in a classically implementable stochastic-optics regime.

</details>


### [309] [Effective Caldirola-Kanai Model for Accelerating Twisted Dirac States in Nonuniform Axial Fields](https://arxiv.org/abs/2602.14555)
*N. V. Filina,S. S. Baturin*

Main category: quant-ph

TL;DR: 本研究构建了相对论性扭曲态（携带轨道角动量）带电粒子在非均匀螺线管场与共线加速/减速电场中的传播模型，通过狄拉克方程近似推导出有效薛定谔方程，利用Ermakov映射获得闭式解，并验证其在极限情况下与已知理论的一致性。


<details>
  <summary>Details</summary>
Motivation: 探索相对论性扭曲粒子束在复杂电磁场中的动力学行为，为粒子加速器、量子光学中轨道角动量操控提供理论框架，并桥接均匀加速与螺线管聚焦等经典模型的解析解。

Method: 基于狄拉克方程，采用无自旋与抛物线近似简化横向包络；引入Caldirola-Kanai哈密顿量描述纵向能量变化诱导的有效阻尼与频率调制；通过Ermakov映射（系统幺正等价）变换稳态朗道基，求解广义Ermakov-Pinney方程获得标度函数b(z)控制横向演化。

Result: 获得闭式传播的扭曲波函数解：纵向能量函数f(z)导出位置依赖的有效阻尼率γ̃(z)和振荡频率ω̃(z)；横向动力学由标度函数b(z)完全描述，其系数由电场E_z(z)和磁场B_z(z)决定；在均匀加速（B_z=0）和纯螺线管聚焦（忽略加速）极限下与经典理论吻合。

Conclusion: 建立了相对论性扭曲粒子在非均匀电磁场中传播的普适解析理论，揭示了纵向能量变化对横向动力学的调制机制，成功统一了加速与聚焦场景的现有模型，为实验设计与应用提供直接理论工具。

Abstract: We study relativistic twisted (orbital-angular-momentum) states of a massive charged particle propagating through an axially symmetric, longitudinally inhomogeneous solenoid field and a co-directed accelerating or decelerating electric field. Starting from the Dirac equation and using controlled spinless and paraxial approximations, we show that the transverse envelope obeys an effective nonstationary Schrödinger equation governed by a Caldirola--Kanai Hamiltonian. The longitudinal energy gain or loss encoded in $f(z)=[E_0-V(z)]^2-m^2$ generates an effective gain or damping rate $\widetildeγ(z)=\partial_z f(z)/[2f(z)]$ and a $z$-dependent oscillator frequency $\widetildeω(z)=p_0Ω(z)/\sqrt{f(z)}$. Exploiting the Ermakov mapping (unitary equivalence of Caldirola--Kanai systems), we obtain a closed-form propagated twisted wave function by transforming the stationary Landau basis. The transverse evolution is controlled by a single scaling function $b(z)$ that satisfies a generalized Ermakov--Pinney equation with coefficients determined by $E_z(z)$ and $B_z(z)$. In the limiting cases of uniform acceleration with $B_z=0$ and of solenoid focusing with negligible acceleration, our solution reduces to previously known analytic results, providing a direct bridge to established models.

</details>


### [310] [Dissipative Spectroscopy](https://arxiv.org/abs/2602.14557)
*Xudong He,Yu Chen*

Main category: quant-ph

TL;DR: 提出耗散光谱学框架，通过可控耗散从量子系统中提取光谱信息，揭示量子临界点附近软模和非平衡动力学新特征


<details>
  <summary>Details</summary>
Motivation: 传统方法难以在准粒子主导的平凡区域获取量子系统关键光谱信息，尤其在量子临界点附近和耗散淬火后的非平衡动力学方面存在理论空白

Method: 建立普适的耗散响应理论（涵盖马尔可夫与非马尔可夫环境），通过驱动振荡-耗散共振协议获取耗散光谱（DS），并引入扩展耗散敏感性捕捉记忆效应

Result: DS可识别量子临界点附近双粒子软模；在正常相侧预测耗散淬火后宏观序的幂律增长；在曾被认为平凡的准粒子主导区发现显著特征；费米子模型验证有效性

Conclusion: 耗散光谱是探测平衡态性质及预测非平衡耗散动力学的实用工具，为量子系统光谱分析提供新范式

Abstract: We introduce dissipative spectroscopy as a framework for extracting spectral information from quantum systems via controlled dissipation. By establishing a general dissipative response theory applicable to both Markovian and non-Markovian environments, we develop a protocol to access the dissipative spectrum (DS) through driven oscillation-dissipation resonance. We show that the DS can identify two-particle soft modes near quantum critical points and, on the normal-phase side, predict the emergence of macroscopic order exhibiting power-law growth following a dissipation quench. These distinctive signatures appear in quasiparticle-dominant regimes, previously considered trivial. Furthermore, we introduce extended dissipative susceptibilities that capture leading memory effects and demonstrate their utility in a dissipative fermionic model. Our results indicate that the DS is readily accessible and offers a versatile tool for probing equilibrium properties as well as predicting nonequilibrium dissipative dynamics.

</details>


### [311] [On the challenge of simulating dipolar contributions to spin relaxation with generalized cluster correlation expansion methods](https://arxiv.org/abs/2602.14613)
*Conor Ryan,Alessandro Lunghi*

Main category: quant-ph

TL;DR: 该研究指出标准广义团簇相关展开(gCCE)方法无法准确描述低温下自旋-自旋偶极相互作用导致的自旋弛豫，通过数学解构揭示了其理论缺陷，为未来方法改进提供方向


<details>
  <summary>Details</summary>
Motivation: 现有研究常忽略低温下自旋-自旋偶极相互作用导致的自旋弛豫及其对退相干的影响，而该机制对理解低温自旋动力学至关重要

Method: 采用广义团簇相关展开(gCCE)方法，通过显式包含中心自旋自由度来模拟能量从中心自旋向自旋浴的转移过程

Result: 标准gCCE方法甚至无法提供自旋-自旋弛豫的定性准确描述，存在根本性理论缺陷

Conclusion: 通过数学解构明确了gCCE理论失效的根源，为未来修正该方法并实现低温自旋弛豫的准确模拟奠定了基础

Abstract: The study of spin decoherence is often performed by assuming that spin-phonon interactions lead to relaxation at high temperatures, and spin-spin dipolar interactions instead contribute to pure dephasing at low temperatures. This has resulted in the neglect of spin relaxation due to spin-spin dipolar interactions and its influence on decoherence at low temperatures. For a complete understanding of low temperature spin dynamics, it is then imperative to focus also on the latter mechanism. One such method which has shown great promise in the efficient calculation of central spin dynamics due to spin-spin dipolar interactions with a surrounding spin bath is the Cluster-Correlation Expansion (CCE). An extension of this method through the explicit inclusion of the central spin degrees of freedom, known as the generalized Cluster-Correlation Expansion (gCCE) is capable of simulating the transfer of energy from the central spin into the bath, and thus could have the potential to investigate spin relaxation in this setting. In this work, we show that gCCE, in its standard form, is insufficient for providing even a qualitatively accurate description of spin-spin relaxation. A full mathematical deconstruction of the underlying theory of gCCE clearly points to the origin of such a breakdown and provides a starting point for its potential future resolution.

</details>


### [312] [Quantum Reservoir Computing with Neutral Atoms on a Small, Complex, Medical Dataset](https://arxiv.org/abs/2602.14641)
*Luke Antoncich,Yuben Moodley,Ugo Varetto,Jingbo Wang,Jonathan Wurtz,Jing Chen,Pascal Jahan Elahi,Casey R. Myers*

Main category: quant-ph

TL;DR: 量子 reservoir computing (QRC) 在医疗生物标志物预测中展现潜力，硬件执行相比无噪声仿真能显著提升模型稳定性和测试准确率，可能源于硬件固有的正则化效应


<details>
  <summary>Details</summary>
Motivation: 医疗数据集因非线性关系、特征相关性及样本量有限导致传统机器学习方法预测临床结局效果不佳，亟需探索更鲁棒的替代方案

Method: 采用量子 reservoir computing (QRC)，通过无噪声仿真和 Aquila 中性原子 Rydberg 处理器硬件执行，对比六种经典机器学习模型性能，并利用 SHAP 方法生成特征子集

Result: ① 仿真量子特征模型测试准确率与经典特征相当，但训练准确率更高且数据分割稳定性差（过拟合特征）② 硬件执行模型在数据分割中更稳定，测试准确率显著提升 ③ 硬件产生结构化时变变换：特征分布向均值压缩且互信息量持续降低

Conclusion: 硬件执行产生的统计特性差异（均值压缩+互信息衰减）可能引入正则化效应，这是提升模型泛化能力和稳定性的关键机制

Abstract: Biomarker-based prediction of clinical outcomes is challenging due to nonlinear relationships, correlated features, and the limited size of many medical datasets. Classical machine-learning methods can struggle under these conditions, motivating the search for alternatives. In this work, we investigate quantum reservoir computing (QRC), using both noiseless emulation and hardware execution on the neutral-atom Rydberg processor \textit{Aquila}. We evaluate performance with six classical machine-learning models and use SHAP to generate feature subsets. We find that models trained on emulated quantum features achieve mean test accuracies comparable to those trained on classical features, but have higher training accuracies and greater variability over data splits, consistent with overfitting. When comparing hardware execution of QRC to noiseless emulation, the models are more robust over different data splits and often exhibit statistically significant improvements in mean test accuracy. This combination of improved accuracy and increased stability is suggestive of a regularising effect induced by hardware execution. To investigate the origin of this behaviour, we examine the statistical differences between hardware and emulated quantum feature distributions. We find that hardware execution applies a structured, time-dependent transformation characterised by compression toward the mean and a progressive reduction in mutual information relative to emulation.

</details>


### [313] [Exploiting the path-integral radius of gyration in open quantum dynamics](https://arxiv.org/abs/2602.14647)
*Andrew C. Hunt,Stuart C. Althorpe*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A major challenge in open quantum dynamics is the inclusion of Matsubara-decay terms in the memory kernel, which arise from the quantum-Boltzmann delocalisation of the bath modes. This delocalisation can be quantified by the radius of gyration squared ${\mathcal R}^2(ω)$ of the imaginary-time Feynman paths of the bath modes as a function of the frequency $ω$. In a Hierarchical Equations of Motion (HEOM) calculation with a Debye--Drude spectral density, ${\mathcal R}^2(ω)$ is the only quantity that is treated approximately (assuming convergence with respect to hierarchy depth). Here, we show that the well-known Ishizaki--Tanimura correction is equivalent to separating smooth from `Brownian' contributions to ${\mathcal R}^2(ω)$, and that modifying the correction leads to a more efficient HEOM in the case of fast baths. We also develop a simple `A4' adaptation of the `AAA' (Adaptive Antoulas--Anderson) algorithm in order to fit ${\mathcal R}^2(ω)$ to a sum over poles, which results in an extremely efficient implementation of the standard HEOM method at low temperatures.

</details>


### [314] [Geometric Visualizations of Quantum Mixed States and Density Matrices](https://arxiv.org/abs/2602.14661)
*Athanasios Kostikas,Yaroslav Valchyshen,Paul Cadden-Zimansky*

Main category: quant-ph

TL;DR: This paper presents a geometric framework mapping quantum states to unique Euclidean points, extending the Bloch sphere to qudits and infinite dimensions to build visual intuition and simplify calculations.


<details>
  <summary>Details</summary>
Motivation: To help learners, teachers, and researchers develop visual intuition for quantum mechanics, complement algebraic formalism, and simplify understanding of mixed states and density matrices for beginners.

Method: Review Bloch sphere properties, extend concepts to qudit and infinite-dimensional spaces, map algebraic elements (amplitudes, density matrices) to geometric features (line segments, angles), and use geometry instead of linear algebra.

Result: A unified geometric representation for quantum states of any dimension, visualizations of key concepts (superposition, decoherence, measurement), geometric calculation methods, and purity interpretation in infinite-dimensional space with lower-dimensional subspaces.

Conclusion: This geometric approach is an effective tool for teaching and research, providing intuition and computational simplification, especially for introducing mixed states and density matrices to early-stage quantum students.

Abstract: This paper presents an introduction to geometric representations of quantum states in which each distinct quantum state, pure and mixed, corresponds to a unique point in a Euclidean space. Beginning with a review of some underappreciated properties of the most commonly used geometric representation, the Bloch sphere visualization of qubit states, we show how concepts, algorithms, and spatial relations viewable on this geometric representation can be extended to representations of qudit states of any finite quantum dimension $d$ and on to the infinite-dimensional limit. A primary goal of the work is helping the reader develop a visual intuition of these spaces, which can complement the understanding of the algebraic formalism of quantum mechanics for learners, teachers, and researchers at any level. Particular emphasis is given both to understanding states in a basis-independent way and to understanding how probability amplitudes and density matrix elements used to algebraically represent states in a particular basis correspond to line segments and angles in the geometric representations. In addition to providing visualizations for such concepts as superpositions, mixtures, decoherence, and measurement, we demonstrate how the representations can be used to substitute simple geometrical calculations for more cumbersome linear algebra ones, which may be of particular use in introducing mixed states and density matrices to beginning quantum students at an early stage. The work concludes with the geometrical interpretation of some commonly used metrics such as the purity of states and their relation to real, Euclidean vectors in the infinite-dimensional limit of the space, which contains all lower-dimensional qudit spaces as subspaces.

</details>


### [315] [Kernel-based optimization of measurement operators for quantum reservoir computers](https://arxiv.org/abs/2602.14677)
*Markus Gross,Hans-Martin Rieser*

Main category: quant-ph

TL;DR: 本文提出基于核岭回归框架训练量子储备池计算机（QRCs），以优化测量算符，提升预测性能，并通过图像分类和时间序列预测任务验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于量子储备池计算机采用固定的量子特征映射，寻找最优测量算符对其性能至关重要，而传统方法可能效率低下。

Method: 将无状态（量子极端学习机，QELMs）和有状态（依赖记忆的）QRCs的训练 formulate 在核岭回归框架中，从而推导出最小化预测误差的最优测量算符，并讨论 Pauli 基分解和算符对角化等硬件适配策略。

Result: 该方法能生成针对给定储备池和数据集的最优测量算符，最小化预测误差；对于大量量子比特场景，比传统QRC训练更高效；在图像分类和时间序列预测的数值实验中表现有效。

Conclusion: 该优化方法不仅提高了QRCs的效率和性能，还可扩展应用于其他量子机器学习模型，具有实用性和普适性。

Abstract: Finding optimal measurement operators is crucial for the performance of quantum reservoir computers (QRCs), since they employ a fixed quantum feature map. We formulate the training of both stateless (quantum extreme learning machines, QELMs) and stateful (memory dependent) QRCs in the framework of kernel ridge regression. This approach renders an optimal measurement operator that minimizes prediction error for a given reservoir and training dataset. For large qubit numbers, this method is more efficient than the conventional training of QRCs. We discuss efficiency and practical implementation strategies, including Pauli basis decomposition and operator diagonalization, to adapt the optimal observable to hardware constraints. Numerical experiments on image classification and time series prediction tasks demonstrate the effectiveness of this approach, which can also be applied to other quantum ML models.

</details>


### [316] [Enhanced multiparameter quantum estimation in cavity magnomechanics via a coherent feedback loop](https://arxiv.org/abs/2602.14688)
*Adnan Naimy,Abdallah Slaoui,Abderrahim Lakhfif,Rachid Ahl Laamara*

Main category: quant-ph

TL;DR: 该论文提出了一种基于相干反馈和相干驱动的混合腔磁机械系统方案，实现了对光子-磁振子和磁振子-机械耦合强度的高精度同时估计，其右对数导数量子Cramer-Rao界限优于传统对称对数导数界限，且实验上可行。


<details>
  <summary>Details</summary>
Motivation: 多参数量子计量学在揭示量子系统独特特性方面具有基础作用。当前挑战在于如何在混合量子系统中实现对多个非对易耦合强度的高精度同时估计。

Method: 在混合腔磁机械平台中，通过引入相干反馈环并结合相干驱动场，通过调节系统和反馈参数来优化估计精度。

Result: 右对数导数（RLD）形式的量子Cramer-Rao界限系统性地低于对称对数导数（SLD）形式，表明在所述非对易估计场景中具有更优的估计精度；在合适参数范围内，外差探测的测量精度可逼近理论预测的量子极限。

Conclusion: 该方案显著提升了多参数同时估计的精度，在当前腔磁机械实验平台上具有可行性，且其通用框架可推广至其他混合量子系统的高精度参数估计。

Abstract: Multiparameter quantum metrology plays a fundamental role in uncovering and exploiting the distinctive features of quantum systems. In this work, we propose an effective and experimentally feasible scheme to significantly enhance the simultaneous quantum estimation of the photon magnon and magnon mechanical coupling strengths in a hybrid cavity magnon mechanical platform. Our approach relies on the assistance of a coherent feedback loop combined with the injection of a coherent driving field. We show that an appropriate tuning of the system and feedback parameters leads to a substantial reduction of the estimation errors associated with both coupling strengths. To quantify the metrological performance of the proposed scheme, we employ the quantum Cramer Rao bound (QCRB) as a fundamental benchmark for multiparameter estimation. We explicitly compute and compare the QCRBs derived from the symmetric logarithmic derivative (SLD) and the right logarithmic derivative (RLD) formalisms. Our results demonstrate that the RLD based QCRB is systematically lower than the SLD based bound, indicating superior estimation precision in the considered noncommutative estimation scenario. We further analyze the performance of heterodyne detection and show that, in suitable parameter regimes, the corresponding classical estimation precision closely approaches the ultimate quantum limit predicted by our scheme. Finally, we discuss the experimental feasibility of the proposed setup within currently available cavity magnon mechanical platforms. Owing to its general character, the framework developed here can be readily extended to the high precision estimation of other physical parameters in hybrid quantum systems.

</details>


### [317] [Demonstrating and Benchmarking Classical Shadows for Lindblad Tomography](https://arxiv.org/abs/2602.14694)
*Rune Thinggaard Birke,Johann Bock Severin,Malthe A. Marciniak,Emil Hogedal,Andreas Nylander,Irshad Ahmad,Amr Osman,Janka Biznárová,Marcus Rommel,Anita Fadavi Roudsari,Jonas Bylander,Giovanna Tancredi,Daniel Stilck França,Albert Werner,Christopher W. Warren,Jacob Hastrup,Svend Krøjer,Morten Kjaergaard*

Main category: quant-ph

TL;DR: 该论文演示了"影子"Lindblad层析成像技术，通过随机测量和局域性假设，以指数级加速的方式表征量子处理器动力学，相比传统方法从58小时缩短至9小时完成5量子比特系统的完整参数恢复。


<details>
  <summary>Details</summary>
Motivation: 固态量子处理器中的虚假耦合和退相干会降低性能，需要精确表征。但传统的Lindblad动力学层析成像随量子比特数呈指数级扩展，难以应用于大规模系统。

Method: 提出并实验验证两种协议：1）可扩展Lindblad层析作为基准，使用完整层析数据集；2）影子Lindblad层析，在物理驱动的局域性假设下循环使用随机配置，用少得多的资源估计相同参数。

Result: 在1个和3个量子比特子系统上验证了局域性假设，影子方法在相同不确定度内复现了可扩展方法的结果，但配置数呈指数级减少。在5量子比特处理器上，影子方法仅需9小时即恢复了所有单量子比特耗散和双量子比特耦合参数，而可扩展方法预计需要58小时，且兼容传统高斯误差传播。

Conclusion: 随机影子层析协议可实际应用于学习规模增长的量子处理器动力学，为大规模量子系统表征提供了可扩展方案。

Abstract: Spurious couplings and decoherence degrade the performance of solid-state quantum processors, demanding careful design, calibration, and mitigation protocols. These strategies often rely on characterization of the idling processor, but tomographic recovery of (time-independent) Lindblad dynamics scales exponentially with qubit count. Here, we experimentally benchmark and demonstrate that randomized ("shadow") measurements accelerate Lindblad tomography on a superconducting transmon processor. We first implement extensible Lindblad tomography, which estimates Lindblad parameters using a complete tomographic dataset, and use it as a baseline to benchmark a shadow tomography approach, shadow Lindblad tomography. The shadow approach recycles randomized configurations to estimate the same Lindblad parameters using far fewer resources under physically motivated locality assumptions. We experimentally verify these assumptions in our processor by implementing the protocols on one- and three-qubit subsystems; here, shadow Lindblad tomography reproduces extensible Lindblad tomography within uncertainties while using exponentially fewer configurations. Leveraging this efficiency, we apply shadow Lindblad tomography to the full five-qubit processor and recover all single qubit dissipation and two-qubit coupling parameters in 9 hours of acquisition time compared to an estimated 58 hours for extensible Lindblad tomography. Additionally, our shadow implementation is compatible with conventional Gaussian error propagation, avoiding the use of median-of-means estimators. Together, these results demonstrate how randomized shadow tomography protocols can be practically implemented to learn quantum processor dynamics at an increasing qubit count.

</details>


### [318] [Faster Optimal Decoder for Graph Codes with a Single Logical Qubit](https://arxiv.org/abs/2602.14730)
*Nirupam Basak,Goutam Paul*

Main category: quant-ph

TL;DR: This paper proposes a hierarchical decoder for graph codes that exploits graph structure to achieve polynomial-time decoding while maintaining optimal performance at lower levels, avoiding NP-hard optimal decoding.


<details>
  <summary>Details</summary>
Motivation: Optimal decoding of graph codes is NP-hard, creating a need for efficient, faster decoding methods.

Method: They develop a hierarchical decoder that leverages the structural properties of graph states and the well-defined structure of post-measurement states from projective syndrome measurements, enabling polynomial-time solutions at each level.

Result: The decoder achieves optimal decoding performance at lower hierarchy levels and demonstrates efficiency and effectiveness through numerical results.

Conclusion: The proposed hierarchical decoding strategy successfully avoids full maximum-likelihood decoding while maintaining high performance, offering an efficient solution for graph code decoding.

Abstract: In this work, we develop an efficient decoding method for graph codes, a class of stabilizer quantum error-correcting codes constructed from graph states. While optimal decoding is generally NP-hard, we propose a faster decoder exploiting the structural properties of the underlying graph states. Although distinct error patterns may yield the same syndrome, we demonstrate that the post-measurement state follows a well-defined structure determined by the projective syndrome measurement. Building on this idea, we introduce a hierarchical decoder in which each level can be solved in polynomial time. Additionally, this decoder achieves optimal decoding performance at the lower levels of the hierarchy. This strategy avoids the need for full maximum-likelihood decoding of graph codes. Numerical results illustrate the efficiency and effectiveness of the proposed approach.

</details>


### [319] [Projections with Respect to Bures Distance and Fidelity: Closed-Forms and Applications](https://arxiv.org/abs/2602.14732)
*A. Afham,Marco Tomamichel*

Main category: quant-ph

TL;DR: 提出统一闭式解计算量子保真度投影，包括将半正定矩阵投影到给定边缘的集合，以及将算子集合投影到给定矩阵的半正定分解集合，揭示Petz恢复映射和pretty good measurement的几何本质，并建立与量子态时间形式体系的联系。


<details>
  <summary>Details</summary>
Motivation: 量子信息理论中存在多种保真度投影问题（如量子通道、测量操作的投影），但缺乏统一数学表达。本研究旨在推导普适的闭式解，建立不同投影问题间的内在联系，并为量子贝叶斯规则等概念提供信息几何学解释。

Method: 1) 推导 bipartite 半正定矩阵到给定边缘约束集合的投影公式；2) 提出"先验-通道分解"将完全正定映射唯一分解为先验半正定矩阵与量子通道；3) 通过Choi-Jamiołkowski同构建立bipartite矩阵与通道-态对的对应关系；4) 将投影结果应用于量子测量和恢复映射分析。

Result: 1) 获得多类保真度投影的统一闭式解；2) 证明pretty good measurement是加权算子集合到测量集合的保真度投影；3) 揭示Petz恢复映射是反向量子通道的保真度投影，重新诠释量子贝叶斯规则；4) 为Leifer-Spekkens量子态时间形式体系提供几何学基础。

Conclusion: 本研究通过信息几何框架统一了量子保真度投影问题，建立了先验-通道分解理论，揭示了量子测量、恢复映射等核心概念的几何本质，深化了对量子信息处理中优化过程的理解，并为量子态时间演化理论提供了新视角。

Abstract: We derive simple and unified closed-form expressions for projections with respect to fidelity (equivalently, the Bures and purified distances) onto several sets of interest. These include projections of bipartite positive semidefinite (PSD) matrices onto the set of PSD matrices with a given marginal, and projections of ensembles of PSD matrices onto the set of PSD decompositions of a given matrix, with important special cases corresponding to projections onto the set of quantum channels (via the Choi isomorphism) and onto the set of measurements. We introduce prior-channel decompositions of completely positive (CP) maps, which uniquely decompose any CP map into a prior PSD matrix and a quantum channel. This decomposition generalizes the Choi-Jamiolkowski isomorphism by establishing a bijective correspondence between arbitrary bipartite PSD matrices and channel-state pairs, and we show that it arises naturally from the fidelity projections developed here. As applications, we show that the pretty good measurement - associated with a weighted ensemble - is the fidelity projection of the ensemble onto the set of measurements, and that the Petz recovery map - associated with a reference state and forward channel - is the projection of a CP map (constructed from the channel-state pair) onto the set of reverse quantum channels, thereby recasting the well-known identification of the Petz map with quantum Bayes' rule in information-geometric terms. Our results also provide an information-geometric underpinning of the Leifer-Spekkens quantum state over time formalism [Leifer and Spekkens, Phys. Rev. A 88, 052130 (2013)].

</details>


### [320] [The Signal Horizon: Local Blindness and the Contraction of Pauli-Weight Spectra in Noisy Quantum Encodings](https://arxiv.org/abs/2602.14735)
*Ait Haddou Marwan*

Main category: quant-ph

TL;DR: 研究量子分类器在局域测量和噪声条件下的信息可及性，提出k-局域保利可及振幅A_k(p)作为分类优势的预测指标，发现存在局域分类器失效而全局可区分的临界阈值。


<details>
  <summary>Details</summary>
Motivation: 传统量子分类器分析聚焦全局状态可区分性或变分模型训练性，但实际噪声环境中局域测量约束下的信息保留程度尚未明确，需建立量化理论框架。

Method: 将二元量子分类建模为约束量子态判别问题，定义局域受限可区分性度量（量化k个子系统上可观测量最大偏差），针对n量子比特退极化噪声提出保利权重相关的收缩机制，推导出可计算的k-局域保利可及振幅A_k(p)。

Result: 在四量子比特编码的数值实验中，经验准确率与A_k(p)预测值定量吻合；发现操作临界阈值：当噪声超过该值时k-局域分类器退化为随机猜测，但全局可区分性仍存在。

Conclusion: 揭示噪声环境下局域测量对量子分类能力的根本限制，A_k(p)为实际量子分类器性能评估提供有效理论边界，对含噪声中等规模量子（NISQ）算法设计具有指导意义。

Abstract: The performance of quantum classifiers is typically analyzed through global state distinguishability or the trainability of variational models. This study investigates how much class information remains accessible under locality-constrained measurements in the presence of noise. The authors formulate binary quantum classification as constrained quantum state discrimination and introduce a locality-restricted distinguishability measure quantifying the maximum bias achievable by observables acting on at most $k$ subsystems. For $n$-qubit systems subject to independent depolarizing noise, the locally accessible signal is governed by a Pauli-weight-dependent contraction mechanism. This motivates a computable predictor, the $k$-local Pauli-accessible amplitude $A_{k}(p)$, which lower bounds the optimal $k$-local classification advantage. Numerical experiments on four-qubit encodings demonstrate quantitative agreement between empirical accuracy and the prediction across noise levels. The research identifies an operational breakdown threshold where $k$-local classifiers become indistinguishable from random guessing despite persistent global distinguishability.

</details>


### [321] [Probabilistic Cutoffs in Homogeneous Quantum Repeater Chains](https://arxiv.org/abs/2602.14738)
*Jeroen Grimbergen,Stav Haldar,Alvaro Gomez Inesta,Stephanie Wehner*

Main category: quant-ph

TL;DR: 提出概率性截断策略替代确定性截断策略，无需追踪链路年龄，在特定场景下可获得相当的密钥率且更高效。


<details>
  <summary>Details</summary>
Motivation: 量子中继链中确定性截断策略虽能提高端到端保真度，但需要追踪链路年龄，增加了系统复杂度和资源开销。

Method: 提出概率性截断策略，与确定性截断策略进行基准测试对比，评估端到端速率、保真度和密钥率性能。

Result: 在少节点或高链路生成概率条件下，概率性策略可获得同等量级的密钥率；特定场景中能以更高速率提供满足保真度阈值的端到端链路。

Conclusion: 概率性截断策略以牺牲严格保真度控制为代价，简化了状态追踪，在特定条件下性能与确定性策略相当甚至更优，具有实用价值。

Abstract: We study quantum repeater chains in which entangled links between neighbouring nodes are created through heralded entanglement generation and adjacent links are swapped as soon as possible. Since heralded entanglement generation attempts succeed only probabilistically, some links will have to be stored in quantum memories at the nodes of the chain while waiting for adjacent links to be generated. The fidelity of these stored links decreases with time due to decoherence, and if they are stored for too long then this can lead to low end-to-end fidelity. Previous work has shown that the end-to-end fidelity can be improved by deterministically discarding links when their ages exceed some cutoff value. Such deterministic cutoff policies provide strict control of the fidelity of all links, but they come at the expense of having to track link ages. In this work, we introduce a probabilistic cutoff policy that does not require tracking link ages, at the cost of abandoning strict control of the fidelity. We benchmark this new probabilistic cutoff policy against a deterministic cutoff policy. We compare the policies in terms of the end-to-end rate and fidelity, and the secret-key rate. We find that even though the probabilistic cutoff policy keeps track of less state, it can provide secret-key rates of the same order of magnitude as the deterministic cutoff policy in chains with few nodes or high elementary link generation probabilities. Moreover, we identify a scenario in which the probabilistic cutoff policy can deliver end-to-end links that are required to have some minimum threshold fidelity at a higher rate than the deterministic cutoff policy.

</details>


### [322] [Finer sub-Planck structures and displacement sensitivity of SU(1,1) circular states](https://arxiv.org/abs/2602.14752)
*Naeem Akhtar,Jia-Xin Peng,Tariq Aziz,Xiaosen Yang,Dong Wang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum states with sub-Planck features exhibit sensitivity to phase-space displacements beyond the standard quantum limit, making them useful for quantum metrology. In the context of the SU(1,1) group, sub-Planck features have been constructed through the superposition of four Perelomov coherent states on the hyperbolic plane (the SU(1,1) compass state). However, these structures differ in scale along different phase-space directions, resulting in nonuniform sensitivity enhancement. We overcome this limitation by constructing $\overline{n}$-component compass states, which are obtained by superposing $\overline{n} \geq 6$ SU(1,1) coherent states, with an even total number, evenly arranged along a circular path on the hyperbolic plane; that is, all components lie at the same distance from the origin and have equal angular spacing of $\frac{2π}{\overline{n}}$. These generalized SU(1,1) compass states generate circularly shaped sub-Planck features (isotropic sub-Planckness) and provide uniform enhancement in sensitivity to phase-space displacements. As the number of coherent states $\overline{n}$ increases, these refinements progressively improve. While verified for $\overline{n} = 16$ SU(1,1) coherent states, the results remain valid for superpositions with arbitrarily large $\overline{n}$ components.

</details>


### [323] [Multi-level spectral navigation with geometric diabatic-adiabatic control](https://arxiv.org/abs/2602.14756)
*Christian Ventura-Meinersen,Edmondo Valvo,Stefano Bosco,Maximilian Rimbach-Russ*

Main category: quant-ph

TL;DR: 提出几何框架实现多级量子系统的高效少参数脉冲优化，实现超越绝热极限的高保真态传输，单参数控制时简化为求解一阶常微分方程


<details>
  <summary>Details</summary>
Motivation: 解决多级量子系统中传统绝热或 diabatic 动力学在态传输时的局限性，需要更少参数实现高保真控制

Method: 建立几何框架平滑插值绝热-diabatic 动力学，通过优化脉冲最小化非期望激发；单参数情形简化为求解一阶常微分方程

Result: 在自旋量子信息处理中成功应用于态初始化和量子比特态传输，显著减少非期望激发并增强目标跃迁

Conclusion: 该几何方法为多级量子系统提供了灵活高效的脉冲优化方案，特别适用于少参数控制场景

Abstract: We introduce a geometric framework for efficient few-parameter pulse optimization in multi-level quantum systems, enabling high-fidelity state transfer beyond the adiabatic limit. Our method interpolates smoothly between adiabatic and diabatic dynamics to minimize unwanted excitations and maximize desired transitions even within a multi-level structure. Crucially, for single-parameter pulse control, the optimization reduces to solving a first-order ordinary differential equation. We showcase the flexibility of our diabatic-adiabatic protocols through two examples in spin-based quantum information processing: state initialization and qubit state transfer.

</details>


### [324] [Localization Tensor Revisited: Geometric-Probabilistic Foundations and a Structure-Factor Criterion under Periodic Boundaries](https://arxiv.org/abs/2602.14779)
*Zhe-Hao Zhang,Xiaoming Cai,Yi-Cong Yu*

Main category: quant-ph

TL;DR: 重构局域化张量，提出两种周期边界条件扩展，建立与结构因子的联系，发展局域化与二聚化区分判据。


<details>
  <summary>Details</summary>
Motivation: 现有局域化张量在周期边界条件下需重定义位置算符，且无法区分安德森局域化与二聚化，需构造新扩展形式并提供更精确诊断。

Method: 将开边界局域化张量表示为密度关联协方差；提出几何（黎曼中心）和概率（互信息）两种周期边界扩展；通过局域化函数C(p)建立与静态结构因子联系；结合C(p)有限动量行为和IPR上界构建区分判据；在SSH和AA模型验证。

Result: 构造了两种周期边界兼容的局域化张量；阐明其与结构因子的关系；揭示低动量行为导致无法区分局域化与二聚化；证明有限动量C(p)+IPR可精确区分二者。

Conclusion: 结构因子探针为周期边界条件下相诊断提供鲁棒且实验可及的新方法。

Abstract: We revisit the localization tensor (LT) from geometric and probabilistic perspectives and construct extensions that are naturally compatible with periodic boundary conditions (PBC), without redefining the position operator. In open boundary conditions, we show that the LT can be written exactly as the covariance of a bivariate probability distribution built from density-density correlations. This leads to two conceptually distinct extensions to PBC: (i) a geometric one based on the Riemannian center (Frechet mean) on the circle, and (ii) a metric-free one based on the mutual information I, which treats the configuration space purely as a probability space. We then relate the LT to the static structure factor by identifying the diagonal part, Cpp, as a "localization function" C(p), whose small-momentum behavior determines the LT in the thermodynamic limit. This clarifies why the LT is sensitive to transitions out of the extended phase but by itself cannot distinguish Anderson-type localization from dimerization: both share the same low-momentum asymptotics. We show that the finite-momentum behavior of C(p), together with an inverse participation ratio (IPR)-based upper bound valid in localized phases, provides a sharp criterion that discriminates localization from dimerization. These results are illustrated on the Su-Schrieffer-Heeger and Aubry-Andre models, with and without interactions, and suggest that structure factor-based probes offer robust and experimentally accessible diagnostics of localized and dimerized phases under PBC.

</details>


### [325] [Constrained Portfolio Optimization via Quantum Approximate Optimization Algorithm (QAOA) with XY-Mixers and Trotterized Initialization: A Hybrid Approach for Direct Indexing](https://arxiv.org/abs/2602.14827)
*Javier Mancilla,Theodoros D. Bouloumis,Frederic Goguikian*

Main category: quant-ph

TL;DR: A constraint-preserving QAOA formulation for cardinality-constrained portfolio optimization achieves superior Sharpe ratios but exhibits high turnover, demonstrating quantum advantage with practical cost trade-offs.


<details>
  <summary>Details</summary>
Motivation: Portfolio optimization with strict cardinality constraints is combinatorially intractable for classical methods; standard QAOA implementations fail to enforce hard constraints, requiring soft penalties that distort the energy landscape and solution quality.

Method: Proposes a QAOA ansatz using Dicke state initialization and XY-mixer Hamiltonian to strictly preserve Hamming weight (ensuring exactly K assets), with Trotterized parameter initialization to mitigate barren plateaus. Benchmarks against Simulated Annealing and Hierarchical Risk Parity.

Result: Backtesting on 10 US equities demonstrates QAOA achieves Sharpe ratio of 1.81, significantly outperforming Simulated Annealing (1.31) and HRP (0.98), but with high turnover of 76.8%.

Conclusion: The constraint-preserving QAOA shows quantum advantage in risk-adjusted returns, though institutional adoption requires balancing theoretical optimality against transaction costs from high turnover.

Abstract: Portfolio optimization under strict cardinality constraints is a combinatorial challenge that defies classical convex optimization techniques, particularly in the context of "Direct Indexing" and ESG-constrained mandates. In the Noisy Intermediate-Scale Quantum (NISQ) era, the Quantum Approximate Optimization Algorithm (QAOA) offers a promising hybrid approach. However, standard QAOA implementations utilizing transverse field mixers often fail to strictly enforce hard constraints, necessitating soft penalties that distort the energy landscape. This paper presents a comprehensive analysis of a constraint-preserving QAOA formulation against Simulated Annealing (SA) and Hierarchical Risk Parity (HRP). We implement a specific QAOA ansatz utilizing a Dicke state initialization and an XY-mixer Hamiltonian that strictly preserves the Hamming weight of the solution, ensuring only valid portfolios of size K are explored. Furthermore, we introduce a Trotterized parameter initialization schedule inspired by adiabatic quantum computing to mitigate the "Barren Plateau" problem. Backtesting on a basket of 10 US equities over 2025 reveals that our QAOA approach achieves a Sharpe Ratio of 1.81, significantly outperforming Simulated Annealing (1.31) and HRP (0.98). We further analyze the operational implications of the algorithm's high turnover (76.8%), discussing the trade-offs between theoretical optimality and implementation costs in institutional settings.

</details>


### [326] [Gravitational Decoherence Estimation in Optomechanical Systems](https://arxiv.org/abs/2602.14841)
*Leonardo A. M. Souza,Olimpio P. de Sá Neto,Enrico Russo,Rosario Lo Franco,Gerardo Adesso*

Main category: quant-ph

TL;DR: 提出了一个基于单模高斯探针态的量子估计框架，用于量化光机械系统中引力诱导退相干的测量精度，揭示了可区分的实验特征并确定了基本检测极限。


<details>
  <summary>Details</summary>
Motivation: 理解引力能否导致量子退相干，以及能够以何种精度检测这种效应，从而探索量子引力理论与退相干机制的基本边界。

Method: 将引力扩散的微观物理模型与量子Fisher信息理论相结合，采用单模高斯态作为探针，计算理论上可达到的最高测量灵敏度。

Result: 证明了引力扩散会在机械量子态中产生独特且可测量的特征，这些特征在系统瞬态演化和稳态均存在；同时揭示了探针态的制备方式对最终可达到的测量精度具有决定性影响。

Conclusion: 建立了探测与估计引力驱动退相干的根本性精度极限，为未来实验检验引力诱导退相干提供了理论基准。

Abstract: We develop a comprehensive quantum estimation framework to quantify how precisely gravitationally induced decoherence can be inferred in optomechanical systems, using single-mode Gaussian probe states. Our approach combines a microscopic description of the gravitational diffusion mechanism with quantum Fisher information to determine the ultimate sensitivity achievable in principle. We show that gravitational diffusion leaves distinct, measurable signatures in the mechanical state, both during transient evolution and in the stationary regime. Finally, we identify how probe state preparation shapes the attainable precision, thereby establishing fundamental limits for detecting and estimating gravity-driven decoherence.

</details>


### [327] [Infinite reduction in absorbing time in quantum walks over classical ones](https://arxiv.org/abs/2602.14880)
*Shuva Mondal,Amrita Mandal,Ujjwal Sen*

Main category: quant-ph

TL;DR: 量子行走在吸收体作用下表现出有限平均吸收时间与加速传播，颠覆了经典随机行走的无限吸收特性；步长无序虽逆转吸收时间行为，却意外恢复了弹道式传播。


<details>
  <summary>Details</summary>
Motivation: 比较量子行走与经典随机行走在吸收体存在下的根本差异，探索无序环境对量子传输优势的影响。

Method: 解析方法证明吸收时间有限性，数值模拟分析无序对吸收时间和传播速率的影响。

Result: 存在吸收体时量子行走平均吸收时间有限而经典行走为无限；步长无序逆转此行为；吸收体加速传播速率；无序使亚弹道式行走恢复弹道式传播。

Conclusion: 量子行走在吸收体下性能优于经典行走，但无序影响具双重性：既消除部分量子优势，又能恢复标准量子传播特性。

Abstract: We study the absorption time and spreading rate of the discrete-time quantum walk propagating on a line in the presence or absence of an absorber. We analytically establish that in the presence of an absorber, the average absorption time of the quantum walker is finite, contrary to the behavior of a classical random walker, indicating an infinite resource reduction on moving over to a quantum version of a walker. Furthermore, numerical simulations indicate a reversal of this behavior due to the insertion of disorder in the walker's step lengths. Additionally, we demonstrate that in the presence of an absorber, there is a speed-up in the spreading rate, and that a disordered quantum walk that is sub-ballistic regains the ballistic spreading of a clean quantum walk.

</details>


### [328] [Scaling QAOA: transferring optimal adiabatic schedules from small-scale to large-scale variational circuits](https://arxiv.org/abs/2602.14986)
*Ugo Nzongani,Dylan Laplace Mermoud,Arthur Braida*

Main category: quant-ph

TL;DR: 提出一种基于能谱间隙的调度学习框架，从小规模问题提取间隙分布，构造微分方程生成闭式QAOA角度，将优化参数从2p压缩至2个，实现可扩展的量子近似优化算法


<details>
  <summary>Details</summary>
Motivation: QAOA的可扩展性受限于优化2p个变分参数的困难，导致经典优化开销大且易受贫瘠高原影响。需要减少参数数量以提升算法效率。

Method: 从小规模问题提取能谱间隙剖面g(s)，构建连续调度方程∂ₜs = κg^q(s)，其中(κ,q)为全局超参数。离散化该调度直接生成所有QAOA角度，将参数优化从2p个降至2个超参数。

Result: 在随机QUBO和3-正则MaxCut实例上的数值模拟表明，学习的调度能有效迁移到更大系统，同时获得具有竞争力的近似比。

Conclusion: 能谱间隙信息指导的调度迁移策略为QAOA提供了可扩展且参数高效的方法，显著降低了经典优化复杂度。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a leading approach for combinatorial optimization on near-term quantum devices, yet its scalability is limited by the difficulty of optimizing \(2p\) variational parameters for a large number \(p\) of layers. Recent empirical studies indicate that optimal QAOA angles exhibit concentration and transferability across problem sizes. Leveraging this observation, we propose a schedule-learning framework that transfers spectral-gap-informed adiabatic control strategies from small-scale instances to larger systems.
  Our method extracts the spectral gap profile of small problems and constructs a continuous schedule governed by \(\partial_t s = κg^q(s)\), where \(g(s)\) is the instantaneous gap and \((κ, q)\) are global hyperparameters. Discretizing this schedule yields closed-form expressions for all QAOA angles, reducing the classical optimization task from \(2p\) parameters to only \(2\), independent of circuit depth. This drastic parameter compression mitigates classical optimization overhead and reduces sensitivity to barren plateau phenomena.
  Numerical simulations on random QUBO and 3-regular MaxCut instances demonstrate that the learnt schedules transfer effectively to larger systems while achieving competitive approximation ratios. Our results suggest that gap-informed schedule transfers provide a scalable and parameter-efficient strategy for QAOA.

</details>


### [329] [Rotational Quantum Friction via Spontaneous Decay](https://arxiv.org/abs/2602.14992)
*Nicolas Schüler,O. J. Franca,Michael Vaz,Hervé Bercegol,Stefan Yoshi Buhmann*

Main category: quant-ph

TL;DR: 研究双原子极性分子在自由空间中旋转时的量子摩擦效应，发现Markov regime下存在与Ω³成正比的摩擦力矩且在零温度下仍然存在，非Markov短时区则表现为与Ω成正比的摩擦。


<details>
  <summary>Details</summary>
Motivation: 量子摩擦是真空场涨落导致的耗散力效应，研究旋转量子摩擦对于理解量子真空与运动物体的相互作用、分子旋转动力学以及量子热力学等基础问题具有重要意义。

Method: 对自由空间中旋转的双原子极性分子的转动运动进行量子化处理，通过理论分析研究自发衰变导致的能量耗散。

Result: 在Markov区得到∝Ω³的摩擦力矩，该效应在零温度下仍然存在；当转动量子数l较大时与经典结果一致；在非Markov短时区发现摩擦∝Ω。

Conclusion: 量子摩擦效应在分子旋转系统中普遍存在，其标度律(Ω³或Ω)取决于动力学区域(Markov或非Markov)，这为实验观测和调控量子摩擦提供了理论依据。

Abstract: A fascinating effect belonging to the field of vacuum forces and fluctuations is that of quantum friction. It refers to the prediction of a dissipative force acting on a moving object due to the quantum vacuum field. In this work, we investigate rotational quantum friction where a diatomic polar molecule rotates around its own center of mass in free space. We quantize the rotational motion and investigate the resulting dissipation due to spontaneous decay. We find in the Markovian regime that a friction torque $\propto Ω^3$ persists even for zero temperature, and in agreement with the classical result in the limit of large rotational quantum number $l$. Within the non-Markovian short-time regime we find a friction $\proptoΩ$.

</details>


### [330] [Low Depth Unitary Coupled Cluster Algorithm for Large Chemical Systems](https://arxiv.org/abs/2602.14999)
*Jeremy Canfield,Dominika Zgid,J K Freericks*

Main category: quant-ph

TL;DR: Proposes qUCC method using Taylor expansion to reduce quantum circuit depth by treating only large-angle factors exactly, showing systematic convergence for strongly correlated systems with only 1/3-1/2 of factors needing exact treatment.


<details>
  <summary>Details</summary>
Motivation: UCC algorithm's scalability is limited by deep quantum circuits from many factors, making it impractical for large quantum systems on current hardware.

Method: Implements quadratic Taylor expansion of UCC (qUCC), treating large-angle factors exactly while approximating small-angle ones, tested on hydrogen chains and BeH2 with tunable strong correlation.

Result: Shows systematic convergence with more exact factors included, hardest convergence in weak-to-strong coupling crossover, and requires only ~1/3 to 1/2 of total factors to be treated exactly.

Conclusion: qUCC effectively reduces circuit depth while maintaining accuracy for strongly correlated systems, offering a practical path forward for quantum chemistry simulations.

Abstract: The unitary coupled cluster (UCC) algorithm is one of the most promising implementations of the variational quantum eigensolver for quantum computers. However, for large systems, the number of UCC factors leads to deep quantum circuits, which are prohibitive for execution on quantum hardware. To address this, circuit depth can be reduced at the cost of more measurements with a Taylor series expansion of UCC factors with small angles, while treating the large-angle factors exactly. We implement this approach to quadratic order (qUCC) for systems with strong correlations and systems where conventional methods like coupled cluster (CC) with low excitation levels fail, but UCC and qUCC perform well. We study hydrogen chains and the BeH2 molecule that allow us to change the degree of strong correlation due to geometrical distortions. We show, via a dramatic increase in number of factors able to handle exactly, a systematic convergence of these results as more exact UCC factors are included in the calculations -- the hardest to converge regime is in the crossover from weak to strong coupling. In all cases the total number of UCC factors needed to be treated exactly is much less than the total number of UCC factors available (typically about one-third to one-half of the total number of factors).

</details>
