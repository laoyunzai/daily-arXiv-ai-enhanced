<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 59]
- [cs.AI](#cs.AI) [Total: 26]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 13]
- [cs.CC](#cs.CC) [Total: 4]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 4]
- [nlin.CD](#nlin.CD) [Total: 1]
- [quant-ph](#quant-ph) [Total: 27]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Detoxifying LLMs via Representation Erasure-Based Preference Optimization](https://arxiv.org/abs/2602.23391)
*Nazanin Mohammadi Sepahvand,Eleni Triantafillou,Hugo Larochelle,Doina Precup,Daniel M. Roy,Gintare Karolina Dziugaite*

Main category: cs.LG

TL;DR: 针对大型语言模型产生有害输出的问题，现有防御方法（如DPO、NPO）存在脆弱性，易受对抗性提示和重新学习攻击影响。本研究提出REPO方法，通过令牌级偏好优化使有毒表示向良性表示收敛，在保持模型效用的同时实现对毒性编码神经元的深度本地化编辑，在抵御高级威胁方面达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在部署中存在生成有毒内容的风险，现有基于DPO、NPO等算法的防御措施存在根本性缺陷：它们无法抵御对抗性提示，且易通过微调重新学习攻击而失效。研究表明这些编辑只是表层修改，有害的"方向"仍然存在于模型表示中，因此需要更鲁棒、更深层次的解决方案。

Method: 提出表示擦除偏好优化（REPO），将去毒化重新表述为令牌级偏好问题。通过新颖的偏好目标函数，强制有毒续体的表示向其良性对应体收敛。该方法采用细粒度策略，针对性地修改编码毒性的神经元，同时保留模型的通用效用。

Result: REPO在全面评估中实现了最先进的鲁棒性，成功抵御了现有表示级和输出级方法无法处理的复杂威胁，包括重新学习攻击和增强的GCG越狱攻击。机制分析表明，与基线方法不同，REPO能够诱导对毒性编码神经元的深度、本地化编辑。

Conclusion: REPO代表了LLM安全微调的重要突破，证明通过表示空间中的细粒度干预可实现深层、持久的去毒化效果。该方法为构建更安全、更可靠的语言模型部署提供了有效途径，特别适用于需要抵御高级对抗性攻击的应用场景。

Abstract: Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful "directions" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail.

</details>


### [2] [U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation](https://arxiv.org/abs/2602.23400)
*Zezheng Wu,Rui Wang,Xinghe Cheng,Yang Shao,Qing Yang,Jiapu Wang,Jingwei Zhang*

Main category: cs.LG

TL;DR: 提出U-CAN框架解决生成式推荐中的隐私遗忘与效用保留矛盾，通过低秩适配器上的对比衰减实现精准机器遗忘


<details>
  <summary>Details</summary>
Motivation: 生成式推荐（GenRec）通过LLM实现个性化序列生成，但用户日志微调会意外编码敏感属性到模型参数中引发隐私风险，而现有机器遗忘技术因多义性困境导致效用严重损失

Method: 提出效用感知对比衰减（U-CAN）框架：在低秩适配器上量化风险，识别对遗忘集敏感但对保留集抑制的非对称响应神经元；结合权重幅值与保留集激活范数设计效用感知校准机制；采用可微分衰减函数实现自适应软衰减，选择性下调高风险参数

Result: 在两个公开数据集上的七项指标实验表明，U-CAN在隐私遗忘、效用保留和计算效率方面均表现优异

Conclusion: U-CAN通过精准抑制敏感检索路径同时保持推理电路拓扑连接，实现了强隐私遗忘与高效用保留的平衡

Abstract: Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency.

</details>


### [3] [Long Range Frequency Tuning for QML](https://arxiv.org/abs/2602.23409)
*Michael Poppel,Jonas Stein,Sebastian Wölckert,Markus Baumann,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 可训练频率量子机器学习在实际中因频率预因子训练受限而失败；三元网格初始化用O(log₃(ω_max))门解决此问题，在合成数据上达到0.997 R²，真实数据上达到0.967 R²。


<details>
  <summary>Details</summary>
Motivation: 可训练频率编码的理论效率假设梯度下降可任意优化频率预因子，但这一假设未经检验且可能错误，限制了实际应用。

Method: 通过系统性实验识别训练限制（约±1单位范围），然后提出三元网格初始化，生成密集整数频率谱，确保目标频率在局部可达范围内。

Result: 三元网格初始化在含三个高频的合成目标上中位R²达0.9969（对比基线0.1841），在Flight Passengers真实数据集上中位R²达0.9671（对比基线0.7876，提升22.8%）。

Conclusion: 频率可达性问题真实存在且可通过网格初始化克服，使可训练频率编码以仅O(log₃(ω_max))门数实现实际可行性。

Abstract: Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876).

</details>


### [4] [Neuro-Symbolic AI for Analytical Solutions of Differential Equations](https://arxiv.org/abs/2502.01476)
*Orestis Oikonomou,Levi Lingsch,Dana Grund,Siddhartha Mishra,Georgios Kissas*

Main category: cs.LG

TL;DR: SIGS是一个神经符号框架，通过形式化语法生成有效表达式块，在连续空间中搜索并优化候选解，首次实现耦合非线性PDEs的解析求解、语法误设下的解发现，以及对无闭式解PDEs的符号近似，在精度和效率上显著优于现有符号方法。


<details>
  <summary>Details</summary>
Motivation: 解析求解微分方程能提供精确可解释的洞见，但传统方法依赖专家直觉或组合空间穷举搜索，效率低下且难以自动化。

Method: SIGS采用形式化语法生成语法正确的表达式块，将其嵌入连续空间，通过最小化物理残差搜索、组装并优化候选闭式解，统一符号推理与数值优化。

Result: SIGS首次实现：(i) 耦合非线性PDEs的解析求解；(ii) 语法误设下的解发现；(iii) 无已知闭式解PDEs的符号近似，并在标准基准测试中精度与效率比现有方法提升数个数量级。

Conclusion: SIGS通过语法约束与潜空间搜索的结合，成功自动化了微分方程解析解的构建过程，为复杂系统建模提供了高效精确的神经符号解决方案。

Abstract: Analytical solutions to differential equations offer exact, interpretable insight but are rarely available because discovering them requires expert intuition or exhaustive search in combinatorial spaces. We introduce SIGS, a neuro-symbolic framework that automates this process. SIGS uses a formal grammar to generate only syntactically valid building blocks, embeds these expressions into a continuous space, and then searches this space to assemble, score, and refine candidate closed-form solutions by minimizing a physics-based residual. This design unifies symbolic reasoning with numerical optimization; the grammar constrains candidate solution blocks to be proper by construction, while the latent search makes exploration tractable and data-free. SIGS is the first neuro-symbolic method to (i) analytically solve coupled systems of nonlinear PDEs, (ii) discover solutions under grammar misspecification, and (iii) produce accurate symbolic approximations for PDEs lacking known closed-form solutions. Overall, SIGS achieves orders-of-magnitude improvements in accuracy and efficiency over existing symbolic methods on standard benchmarks.

</details>


### [5] [Brain-OF: An Omnifunctional Foundation Model for fMRI, EEG and MEG](https://arxiv.org/abs/2602.23410)
*Hanning Guo,Farah Abdellatif,Hanwen Bi,Andrei Galbenus,Jon. N. Shah,Abigail Morrison,Jürgen Dammers*

Main category: cs.LG

TL;DR: 提出首个多模态脑基础模型Brain-OF，通过融合fMRI/EEG/MEG数据并采用双域预训练策略，显著提升神经科学任务性能


<details>
  <summary>Details</summary>
Motivation: 现有脑基础模型局限于单一功能模态，无法利用多成像技术的互补时空动态特征和集体数据规模

Method: 1) 采用任意分辨率神经信号采样器统一不同时空分辨率的脑信号 2) 集成DINT注意力与稀疏专家混合架构分离模态不变/特定表征 3) 设计时频掩码建模双域预训练目标

Result: 在包含约40个数据集的大规模语料库上预训练，在多类下游任务中表现优异，验证了多模态联合训练优势

Conclusion: 首次实现fMRI/EEG/MEG的通用框架建模，为开发更全面的脑基础模型提供新范式

Abstract: Brain foundation models have achieved remarkable advances across a wide range of neuroscience tasks. However, most existing models are limited to a single functional modality, restricting their ability to exploit complementary spatiotemporal dynamics and the collective data scale across imaging techniques. To address this limitation, we propose Brain-OF, the first omnifunctional brain foundation model jointly pretrained on fMRI, EEG and MEG, capable of handling both unimodal and multimodal inputs within a unified framework. To reconcile heterogeneous spatiotemporal resolutions, we introduce the Any-Resolution Neural Signal Sampler, which projects diverse brain signals into a shared semantic space.To further manage semantic shifts, the Brain-OF backbone integrates DINT attention with a Sparse Mixture of Experts, where shared experts capture modality-invariant representations and routed experts specialize in modality-specific semantics. Furthermore, we propose Masked Temporal-Frequency Modeling, a dual-domain pretraining objective that jointly reconstructs brain signals in both the time and frequency domains. Brain-OF is pretrained on a large-scale corpus comprising around 40 datasets and demonstrates superior performance across diverse downstream tasks, highlighting the benefits of joint multimodal integration and dual-domain pretraining.

</details>


### [6] [EvoX: Meta-Evolution for Automated Discovery](https://arxiv.org/abs/2602.23413)
*Shu Liu,Shubham Agarwal,Monishwaran Maheswaran,Mert Cemri,Zhifei Li,Qiuyang Mang,Ashwin Naren,Ethan Boneh,Audrey Cheng,Melissa Z. Pan,Alexander Du,Kurt Keutzer,Alexandros G. Dimakis,Koushik Sen,Matei Zaharia,Ion Stoica*

Main category: cs.LG

TL;DR: EvoJ is an adaptive evolutionary method that co-evolves solutions and search strategies, achieving superior performance across 200+ real-world optimization tasks.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-driven evolutionary optimization methods rely on static search strategies with fixed parameters, limiting their adaptability across tasks and within tasks as the search space evolves.

Method: EvoJ jointly evolves both candidate solutions and the search strategies themselves, continuously adapting solution selection and variation mechanisms based on real-time optimization progress.

Result: Across nearly 200 real-world optimization tasks, EvoJ outperformed state-of-the-art baselines including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.

Conclusion: The adaptive optimization of evolution strategies is superior to fixed strategies, demonstrating that evolving the search process itself significantly enhances performance.

Abstract: Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.

</details>


### [7] [Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension](https://arxiv.org/abs/2602.24178)
*Adam R. Klivans,Konstantinos Stavropoulos,Arsen Vasilyan*

Main category: cs.LG

TL;DR: 提出构造低次夹逼多项式的新方法，显著降低函数类的近似次数，对k半空间高斯函数实现poly(k)次，较先前2^O(k)次指数级提升


<details>
  <summary>Details</summary>
Motivation: 针对分布偏移、可测试学习及污染数据等挑战性学习场景，改进低次夹逼多项式对基础函数类的近似次数边界

Method: 利用目标函数边界的平滑性直接构造夹逼Lipschitz函数，避免复杂技巧（如FT-磨光法），结合高维逼近理论

Result: 高斯分布下k半空间函数：次数从2^O(k)降至poly(k)；低维多项式阈值函数实现双指数级提升

Conclusion: 平滑边界特性使简单构造法有效，为低维光滑边界函数类提供普适性优化框架

Abstract: Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.
  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result.

</details>


### [8] [Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning](https://arxiv.org/abs/2602.23446)
*Alejandro Rodriguez Dominguez*

Main category: cs.LG

TL;DR: The paper argues that persistent errors in large language models stem from fundamental limitations in human supervision channels, not model scale, creating an unavoidable "excess-risk floor" that can only be overcome with non-human auxiliary signals.


<details>
  <summary>Details</summary>
Motivation: Large language models exhibit persistent errors despite training on human data/feedback. The authors hypothesize these errors arise from structural properties of the human supervision channel itself (annotation noise, subjective preferences, limited language bandwidth), not model scale or optimization.

Method: Develops a unified theory called "Human-Bounded Intelligence limit" and validates it through six complementary frameworks: operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic RLHF analysis. Uses experiments on real preference data, synthetic tasks, and verifiable benchmarks.

Result: Confirms that insufficient human supervision creates a strictly positive lower bound (excess-risk floor) for errors. Non-human auxiliary signals (retrieval, program execution, tools) can collapse this floor by providing missing information about the latent evaluation target.

Conclusion: Scaling alone cannot eliminate persistent human-aligned errors due to information-reducing properties of human supervision. Progress requires augmenting supervision with sufficiently informative non-human channels to increase effective supervision capacity.

Abstract: Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error.

</details>


### [9] [Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires](https://arxiv.org/abs/2602.23459)
*Eric V. Strobl*

Main category: cs.LG

TL;DR: 提出REFINE方法，通过非线性预处理稳定问卷条目+线性预测模型，解决精神疾病预后预测中准确性与可解释性的矛盾


<details>
  <summary>Details</summary>
Motivation: 精神疾病问卷预测症状严重程度时存在上下文敏感性高、预测力弱的问题；非线性模型虽提升精度但缺乏临床信任所需的解释性

Method: 两阶段方法：1) 用非线性模块估计稳定基线条目值（REFINE预处理） 2) 用线性模型映射到未来严重程度，将非线性限制在预处理阶段，保持预测关系全局可解释

Result: 在多项精神及非精神纵向预测任务中，REFINE超越其他可解释方法，同时提供清晰的预后因素全局归因（通过系数矩阵）

Conclusion: 该方法通过解耦预处理与预测，在提升预测性能的同时保持透明线性关系，为临床可信赖的预后模型提供新范式

Abstract: Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks.

</details>


### [10] [Uncertainty-aware Language Guidance for Concept Bottleneck Models](https://arxiv.org/abs/2602.23495)
*Yangyi Li,Mengdi Huai*

Main category: cs.LG

TL;DR: A novel uncertainty-aware Concept Bottleneck Model that quantifies and incorporates LLM annotation uncertainty into training to improve reliability and interpretability.


<details>
  <summary>Details</summary>
Motivation: Manual concept annotation for CBMs is labor-intensive and requires expert knowledge. While LLMs can automate this, their outputs suffer from hallucinations and uncertainty that existing methods fail to properly quantify and account for during training.

Method: Proposes an uncertainty-aware CBM that rigorously quantifies LLM-annotated concept uncertainty with distribution-free guarantees, then incorporates this uncertainty into the CBM training procedure to handle varying reliability levels across concepts.

Result: Provides theoretical analysis of the method and validates its desired properties through extensive experiments on real-world datasets.

Conclusion: The proposed method successfully addresses key limitations of LLM-based concept annotation by explicitly handling uncertainty, leading to more robust and reliable interpretable models with theoretical guarantees.

Abstract: Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods.

</details>


### [11] [FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments](https://arxiv.org/abs/2602.23504)
*Anik Pramanik,Murat Kantarcioglu,Vincent Oria,Shantanu Sharma*

Main category: cs.LG

TL;DR: FedDAG通过结合数据和梯度相似性度量来改进聚类联邦学习，采用双编码器架构实现跨集群知识迁移，同时在保持集群特定专业化的同时提升模型准确性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在数据异构性下性能下降。现有聚类联邦学习方法仅依赖数据或梯度相似性，导致评估不全面，且限制知识共享于集群内部，无法利用跨集群的多样性信息。

Method: 该论文提出FedDAG框架，引入：(1)加权类级相似性度量，整合数据和梯度信息以进行更全面客户端聚类；(2)双编码器架构，主编码器在本地客户端数据上训练，次编码器利用互补集群的梯度进行优化，实现跨集群特征迁移。

Result: 在不同基准测试和数据异构性设置上的实验表明，FedDAG在准确性方面持续优于最先进的聚类联邦学习基线。

Conclusion: FedDAG提供了更全面的客户端聚类方法，并实现了有益的跨集群知识迁移，在异构联邦学习场景中表现出卓越性能。

Abstract: Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy.

</details>


### [12] [Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package](https://arxiv.org/abs/2602.23507)
*Diana Shamsutdinova,Felix Zimmer,Oyebayo Ridwan Olaniran,Sarah Markham,Daniel Stahl,Gordon Forbes,Ewan Carr*

Main category: cs.LG

TL;DR: 本文针对临床预测模型的最小样本量确定难题，提出了一种结合学习曲线、高斯过程优化和保证原则的模拟方法，并开发了开源R包pmsims，相比现有方法提供了更灵活高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 临床预测模型的样本量不足会导致过拟合、泛化能力差和预测偏差。现有方法（启发式规则、闭式公式、模拟方法）在复杂数据结构和机器学习模型方面缺乏灵活性和准确性。

Method: 综述现有方法并建立均值型与保证型准则的概念框架。提出新颖的模拟方法，整合学习曲线、高斯过程优化和保证原则，以确定能以高概率达到目标性能的样本量。该方法在开源、模型无关的R包pmsims中实现。

Result: 样本量估计在不同方法、性能指标和建模策略间差异显著。pmsims提供灵活、高效、可解释的解决方案，能适应不同模型和用户定义指标，并明确考虑模型性能的变异性。

Conclusion: 该框架和软件通过结合灵活性与计算效率，推进了临床预测模型的样本量方法学。未来需扩展到层次化和多模态数据，纳入公平性和稳定性指标，并解决缺失数据和复杂依赖结构等挑战。

Abstract: Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures.

</details>


### [13] [Neural Operators Can Discover Functional Clusters](https://arxiv.org/abs/2602.23528)
*Yicen Li,Jose Antonio Lara Benitez,Ruiyang Hong,Anastasis Kratsios,Paul David McNicholas,Maarten Valentijn de Hoop*

Main category: cs.LG

TL;DR: This paper proves neural operators can universally learn classification and clustering of infinite-dimensional functional data, even for non-convex and disconnected classes, and demonstrates this with an ODE trajectory clustering pipeline that outperforms classical methods.


<details>
  <summary>Details</summary>
Motivation: While neural operators excel at regression tasks in scientific computing, their theoretical foundations and practical applications for classification and unsupervised clustering of functional data remain underexplored, particularly for complex dynamical systems like ODE trajectories where traditional methods fail.

Method: The authors establish universal approximation theorems in reproducing kernel Hilbert spaces, then build a pipeline that lifts discretized ODE trajectories via a pre-trained encoder into continuous feature maps, which are clustered by a lightweight trainable head parameterized as a neural operator.

Result: (1) Universal classification theorem: sample-based neural operators can learn any finite class collection in infinite-dimensional RKHS; (2) Universal clustering theorem: any K closed classes are approximable in Kuratowski topology, disallowing false positives; (3) Empirical validation shows their approach recovers latent dynamical structure where classical methods fail on synthetic ODE benchmarks.

Conclusion: Neural operators provide a theoretically-grounded, powerful framework for functional data clustering that handles pathological class geometries and reveals hidden structures in scientific computing applications.

Abstract: Operator learning is reshaping scientific computing by amortizing inference across infinite families of problems. While neural operators (NOs) are increasingly well understood for regression, far less is known for classification and its unsupervised analogue: clustering. We prove that sample-based neural operators can learn any finite collection of classes in an infinite-dimensional reproducing kernel Hilbert space, even when the classes are neither convex nor connected, under mild kernel sampling assumptions. Our universal clustering theorem shows that any $K$ closed classes can be approximated to arbitrary precision by NO-parameterized classes in the upper Kuratowski topology on closed sets, a notion that can be interpreted as disallowing false-positive misclassifications.
  Building on this, we develop an NO-powered clustering pipeline for functional data and apply it to unlabeled families of ordinary differential equation (ODE) trajectories. Discretized trajectories are lifted by a fixed pre-trained encoder into a continuous feature map and mapped to soft assignments by a lightweight trainable head. Experiments on diverse synthetic ODE benchmarks show that the resulting practical SNO recovers latent dynamical structure in regimes where classical methods fail, providing evidence consistent with our universal clustering theory.

</details>


### [14] [Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning](https://arxiv.org/abs/2602.23529)
*Martin Černý,David Sychrovský,Filip Úradník,Jakub Černý*

Main category: cs.LG

TL;DR: 针对含缺失值的子模集函数，提出基于加性误差的近似方法，通过离线和在线查询策略最小化最小/最大补全间的距离，并在实际场景中验证有效性


<details>
  <summary>Details</summary>
Motivation: 子模集函数在组合优化和机器学习中应用广泛，但完整定义需指数级子集估值，实际中常因外部数据（如模型重训练）导致估值缺失，引发优化歧义；已有研究证明基于确定性查询的乘法误差近似存在不可近似性，故转向加性误差框架

Method: 1) 系统分析不同类别集函数缺失值的最小/最大补全及其距离；2) 结合先验知识设计离线和在线子集查询策略以压缩补全距离；3) 通过实际场景实验验证算法性能

Result: 理论层面揭示各类集函数补全距离的特性；实践层面开发出能有效降低歧义的查询方法，实验显示在组合拍卖和机器学习等场景中性能良好

Conclusion: 通过加性误差框架和主动查询机制，显著缓解了缺失值导致的优化歧义问题，为子模函数在资源受限场景下的应用提供新解决方案

Abstract: Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios.

</details>


### [15] [Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing](https://arxiv.org/abs/2602.23565)
*Adhyyan Narang,Sarah Dean,Lillian J Ratliff,Maryam Fazel*

Main category: cs.LG

TL;DR: Multiple platforms learning from self-selecting users can fall into an "overspecialization trap" with arbitrarily poor global performance; the authors propose a knowledge-distillation-inspired probing algorithm that learns from peer models to achieve bounded global risk when peers are sufficiently informative.


<details>
  <summary>Details</summary>
Motivation: In multi-platform settings where users self-select their preferred platform, prior work only optimizes local losses on observed data, which can create feedback loops where platforms become overspecialized to their existing user base, leading to arbitrarily poor global performance despite the existence of good models.

Method: Inspired by knowledge distillation, the proposed algorithm allows platforms to "probe" predictions of peer models (e.g., market leaders or high-performing peers) to learn about users who don't select them, thereby escaping the data restriction caused by self-selection bias.

Result: Theoretically, probing converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative; experimentally verified on MovieLens, Census, and Amazon Sentiment datasets showing the algorithm effectively mitigates overspecialization.

Conclusion: The overspecialization trap is a fundamental limitation of local learning in multi-platform user selection settings, but can be resolved through strategic probing of informative peer models, enabling platforms to achieve bounded global risk and avoid arbitrarily poor performance.

Abstract: In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the "local" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to "probe" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets.

</details>


### [16] [Hybrid Quantum Temporal Convolutional Networks](https://arxiv.org/abs/2602.23578)
*Junghoon Justin Park,Maria Pak,Sebin Lee,Samuel Yen-Chi Chen,Shinjae Yoo,Huan-Hsin Tseng,Jiook Cha*

Main category: cs.LG

TL;DR: Proposes HQTCN: a hybrid quantum-classical model for multivariate time-series analysis that uses shared quantum circuits across temporal windows to reduce parameters while outperforming classical baselines.


<details>
  <summary>Details</summary>
Motivation: Quantum machine learning models struggle with scalability when processing complex multivariate sequential signals.

Method: Hybrid Quantum Temporal Convolutional Network (HQTCN) combining classical temporal windowing with a quantum convolutional neural network core, applying shared quantum circuits across windows.

Result: Competitive on univariate tasks, outperforms classical baselines on multivariate EEG and NARMA data, maintains high performance with substantially fewer parameters, especially effective in data-limited scenarios.

Conclusion: HQTCN establishes a parameter-efficient quantum approach for multivariate time-series analysis.

Abstract: Quantum machine learning models for sequential data face scalability challenges with complex multivariate signals. We introduce the Hybrid Quantum Temporal Convolutional Network (HQTCN), which combines classical temporal windowing with a quantum convolutional neural network core. By applying a shared quantum circuit across temporal windows, HQTCN captures long-range dependencies while achieving significant parameter reduction. Evaluated on synthetic NARMA sequences and high-dimensional EEG time-series, HQTCN performs competitively with classical baselines on univariate data and outperforms all baselines on multivariate tasks. The model demonstrates particular strength under data-limited conditions, maintaining high performance with substantially fewer parameters than conventional approaches. These results establish HQTCN as a parameter-efficient approach for multivariate time-series analysis.

</details>


### [17] [SDMixer: Sparse Dual-Mixer for Time Series Forecasting](https://arxiv.org/abs/2602.23581)
*Xiang Ao*

Main category: cs.LG

TL;DR: Dual-stream sparse Mixer framework for multivariate time series forecasting using frequency/time domains and sparsity to improve accuracy


<details>
  <summary>Details</summary>
Motivation: Existing models underperform due to multi-scale characteristics, weak correlations, and noise interference in real-world multivariate time series data

Method: Proposes a dual-stream sparse Mixer framework extracting global trends (frequency domain) and local dynamics (time domain) with sparsity-based noise filtering

Result: Achieves state-of-the-art performance across multiple real-world datasets (transportation, energy, finance)

Conclusion: Effectively enhances cross-variable dependency modeling and demonstrates strong generality for practical forecasting applications

Abstract: Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer

</details>


### [18] [Normalisation and Initialisation Strategies for Graph Neural Networks in Blockchain Anomaly Detection](https://arxiv.org/abs/2602.23599)
*Dang Sy Duy,Nguyen Duy Chien,Kapil Dev,Jeff Nijsse*

Main category: cs.LG

TL;DR: This paper systematically studies how weight initialization and normalization affect three GNN architectures for Bitcoin anti-money laundering detection, finding that optimal strategies are architecture-specific and releasing a reproducible framework.


<details>
  <summary>Details</summary>
Motivation: GNNs show promise for financial fraud detection but their performance on real-world AML benchmarks heavily depends on underexplored training practices like weight initialization and normalization, especially given severe class imbalance in transaction data.

Method: Conducted a systematic ablation study comparing initialization (Xavier) and normalization (GraphNorm) strategies across three GNN architectures (GCN, GAT, GraphSAGE) using the Elliptic Bitcoin dataset with temporal splits and seeded runs for reproducibility.

Result: Found that performance is architecture-dependent: GraphSAGE achieves best results with Xavier initialization alone, GAT benefits most from combining GraphNorm with Xavier initialization, and GCN shows minimal sensitivity to these changes.

Conclusion: Provides practical architecture-specific guidance for GNN deployment in AML pipelines, addressing class imbalance challenges, and releases a reproducible experimental framework with full results.

Abstract: Graph neural networks (GNNs) offer a principled approach to financial fraud detection by jointly learning from node features and transaction graph topology. However, their effectiveness on real-world anti-money laundering (AML) benchmarks depends critically on training practices such as specifically weight initialisation and normalisation that remain underexplored. We present a systematic ablation of initialisation and normalisation strategies across three GNN architectures (GCN, GAT, and GraphSAGE) on the Elliptic Bitcoin dataset. Our experiments reveal that initialisation and normalisation are architecture-dependent: GraphSAGE achieves the strongest performance with Xavier initialisation alone, GAT benefits most from combining GraphNorm with Xavier initialisation, while GCN shows limited sensitivity to these modifications. These findings offer practical, architecture-specific guidance for deploying GNNs in AML pipelines for datasets with severe class imbalance. We release a reproducible experimental framework with temporal data splits, seeded runs, and full ablation results.

</details>


### [19] [When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion](https://arxiv.org/abs/2602.23614)
*Kejing Yin,Haizhou Xu,Wenfang Yao,Chen Liu,Zijie Chen,Yui Haang Cheung,William K. Cheung,Jing Qin*

Main category: cs.LG

TL;DR: This paper benchmarks multimodal fusion of EHR and chest X-rays for clinical prediction, finding that benefits are limited to diseases needing both data types, degrade under missing modalities, and don't automatically improve fairness.


<details>
  <summary>Details</summary>
Motivation: Unclear when multimodal learning truly helps in clinical decision support, especially under modality missingness and fairness constraints.

Method: Systematic benchmark of EHR-CXR fusion on MIMIC-IV/CXR cohorts to answer four questions about performance improvement, strategy comparison, missingness robustness, and algorithmic fairness.

Result: Fusion helps only for diseases requiring complementary info; cross-modal learning captures dependencies but EHR temporal structure causes imbalance; benefits rapidly degrade under missingness without explicit design; fusion doesn't inherently improve fairness. Released CareBench toolkit.

Conclusion: Provides actionable guidance on when multimodal learning helps/fails for developing clinically deployable systems.

Abstract: Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench.

</details>


### [20] [On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation](https://arxiv.org/abs/2602.23633)
*Yubo Zhou,Luo Luo,Guang Dai,Haishan Ye*

Main category: cs.LG

TL;DR: 该论文针对随机双层优化中单循环算法理论分析不足的问题，改进了SSAID算法的收敛性分析，证明其达到O(κ⁷ε⁻²)的oracle复杂度，首次显式刻画了条件数κ的依赖关系，且收敛速率与多循环方法最优水平一致。


<details>
  <summary>Details</summary>
Motivation: 随机双层优化是元学习和超参数优化的基础框架，但单循环算法（同时更新上下层变量）在随机场景下的理论理解远落后于多循环算法，现有分析存在收敛速率次优或隐藏关键条件数κ依赖的问题。

Method: 对单循环随机近似隐式微分算法（SSAID）进行精细化收敛分析，重点揭示下层条件数κ对收敛速率的显式影响。

Result: 证明SSAID以O(κ⁷ε⁻²)的oracle复杂度达到ε-驻点，该结果（i）与多循环方法（如stocBiO）的最优O(ε⁻²)速率一致；（ii）首次给出随机AID单循环方法中κ依赖的显式刻画。

Conclusion: SSAID不仅具有计算效率优势，更具备与主流多循环框架相竞争的严格理论保证，确立了单循环方法在随机双层优化中的理论合理性。

Abstract: Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $κ$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $ε$-stationary point with an oracle complexity of $\mathcal{O}(κ^7 ε^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\mathcal{O}(ε^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $κ$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks.

</details>


### [21] [FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation](https://arxiv.org/abs/2602.23636)
*Zhihao Ding,Jinming Li,Ze Lu,Jieming Shi*

Main category: cs.LG

TL;DR: The paper introduces FlexBench, a benchmark for evaluating LLM moderators across varying safety strictness levels, and proposes FlexGuard, a continuous risk score-based moderator that adapts to different strictness requirements via thresholding, demonstrating superior robustness over binary classification approaches.


<details>
  <summary>Details</summary>
Motivation: Existing LLM moderation models use fixed binary classification assuming static harmfulness definitions, but real-world deployment requires adapting to varying enforcement strictness across platforms and over time, making binary moderators brittle under shifting requirements.

Method: They created FlexBench for controlled multi-strictness evaluation and developed FlexGuard that outputs calibrated continuous risk scores, trained via risk-alignment optimization with practical threshold selection strategies for strictness adaptation.

Result: Experiments revealed substantial cross-strictness inconsistency in existing moderators. FlexGuard achieved higher moderation accuracy and substantially improved robustness under varying strictness regimes on both FlexBench and public benchmarks.

Conclusion: Continuous risk score-based moderation with strictness-adaptive thresholding is more practical and robust than binary classification for real-world LLM safety applications.

Abstract: Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility.

</details>


### [22] [FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA](https://arxiv.org/abs/2602.23638)
*Haoran Zhang,Dongjun Kim,Seohyeon Cha,Haris Vikalo*

Main category: cs.LG

TL;DR: FedRot-LoRA通过正交变换对齐客户端低秩更新，解决旋转不变性导致的聚合误差问题，提升联邦大模型微调性能。


<details>
  <summary>Details</summary>
Motivation: 联邦LoRA存在旋转失配问题：因低秩分解的旋转不变性，不同客户端对相同语义更新的表示可能处于不同子空间，直接平均会导致破坏性干扰和训练不稳定。

Method: 在聚合前使用正交变换对齐客户端更新因子，保持语义更新不变的同时减少跨客户端子空间不匹配，不增加通信开销。

Result: 理论证明旋转对齐能收紧聚合误差上界；NLU和生成任务的实验表明，FedRot-LoRA在各种异构程度和LoRA秩下均优于现有基线。

Conclusion: FedRot-LoRA有效解决了联邦LoRA的聚合误差问题，为去中心化数据上的高效大模型微调提供了可靠方案。

Abstract: Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks.

</details>


### [23] [Selective Denoising Diffusion Model for Time Series Anomaly Detection](https://arxiv.org/abs/2602.23662)
*Kohei Obata,Zheng Chen,Yasuko Matsubara,Lingwei Zhu,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 提出AnomalyFilter，一种基于扩散模型的时间序列异常检测方法，通过掩码高斯噪声训练和去噪过程不添加噪声的创新噪声设计，实现仅对异常部分去噪并保留正常部分，在五个数据集上显著降低了正常部分的重构误差。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的时间序列异常检测方法采用条件策略从白噪声重构输入，但在准确重构正常部分时面临挑战，导致检测性能不佳。

Method: 提出AnomalyFilter作为选择性滤波器，通过在训练阶段掩码高斯噪声并在去噪过程中不对实例添加噪声，仅对实例的异常部分进行去噪而保留正常部分。

Result: 在五个数据集上的大量实验表明，AnomalyFilter在正常部分上实现了显著降低的重构误差，为其异常检测有效性提供了实证支持。

Conclusion: AnomalyFilter代表了针对TSAD专门定制的扩散模型噪声设计的开创性方法。

Abstract: Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD.

</details>


### [24] [Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning](https://arxiv.org/abs/2602.23663)
*Kohei Obata,Taichi Murayama,Zheng Chen,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: MoST提出张量切片与对比学习结合的方法，解耦多模态时间序列的模式特异性/不变特征，显著提升分类预测精度


<details>
  <summary>Details</summary>
Motivation: 多模态张量时间序列（如搜索引擎、环境监测数据）因高维复杂性导致表征学习困难，影响下游任务性能

Method: 采用张量切片降维，通过对比学习框架解耦表征：① 模式特异性特征（同模态变量关系）② 模式不变特征（跨模态共性），双路径损失函数联合优化

Result: 在真实数据集上分类与预测任务中，MoST全面超越现有最优方法，精度提升显著

Conclusion: 通过解耦表征作为数据增强手段，MoST有效利用多模态特性，为张量时序分析提供新范式

Abstract: Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities inherent in the tensor hinder the realization of rich representations. In this paper, we propose a novel representation learning method designed specifically for TTS, namely MoST. Specifically, MoST uses a tensor slicing approach to reduce the complexity of the TTS structure and learns representations that can be disentangled into individual non-temporal modes. Each representation captures mode-specific features, which are the relationship between variables within the same mode, and mode-invariant features, which are in common in representations of different modes. We employ a contrastive learning framework to learn parameters; the loss function comprises two parts intended to learn representation in a mode-specific way and mode-invariant way, effectively exploiting disentangled representations as augmentations. Extensive experiments on real-world datasets show that MoST consistently outperforms the state-of-the-art methods in terms of classification and forecasting accuracy. Code is available at https://github.com/KoheiObata/MoST.

</details>


### [25] [Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training](https://arxiv.org/abs/2602.23696)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 研究小型Transformer训练轨迹的几何结构，发现参数更新形成主导漂移方向与横向残余动力学，揭示AdamW与SGD在轨迹维度上的本质差异，表明优化器选择以超越损失值的方式塑造学习轨迹的有效维度。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer模型训练过程中参数的演化规律，以及不同优化器如何影响训练轨迹的几何结构，理解优化器选择对学习动力学的影响机制。

Method: 采用非中心化、行归一化的轨迹主成分分析，对比AdamW与SGD变体在匹配损失水平下的表现，分析参数更新、瞬时梯度与辅助探针性能的关系。

Result: 发现参数更新在训练早期由单一主导方向捕获大部分累积运动，其余分量编码振荡性探针性能；瞬时梯度与主导方向对齐度低；AdamW产生多维漂移结构，而SGD族优化器产生近乎共线的参数演化；重加热选择性地扰动横向分量。

Conclusion: 优化器选择塑造了学习轨迹的有效维度和结构，这种影响无法仅从损失值中观察到，揭示了不同优化算法在参数空间探索方式的本质差异。

Abstract: We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone.

</details>


### [26] [Bridging Dynamics Gaps via Diffusion Schrödinger Bridge for Cross-Domain Reinforcement Learning](https://arxiv.org/abs/2602.23737)
*Hanping Zhang,Yuhong Guo*

Main category: cs.LG

TL;DR: BDGxRL uses Diffusion Schrödinger Bridge and reward modulation to align source and target domain dynamics with offline demos, enabling cross-domain RL without target environment interaction, outperforming baselines on MuJoCo benchmarks.


<details>
  <summary>Details</summary>
Motivation: Cross-domain RL struggles with dynamics shifts between source and target domains due to lack of target environment interaction and reward supervision, preventing direct policy learning.

Method: Proposes BDGxRL: (1) Uses Diffusion Schrödinger Bridge (DSB) to align source transitions with target dynamics from offline demos; (2) Introduces reward modulation to estimate rewards via state transitions for DSB-aligned samples; (3) Performs target-oriented policy learning entirely in source domain.

Result: Outperforms state-of-the-art baselines on MuJoCo cross-domain benchmarks and demonstrates strong adaptability under transition dynamics shifts.

Conclusion: BDGxRL effectively bridges domain dynamics gaps without target environment access, enabling efficient cross-domain policy transfer through dynamics alignment and reward modulation.

Abstract: Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schrödinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.

</details>


### [27] [OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design](https://arxiv.org/abs/2602.23761)
*Yuyu Geng,Lei Sun,Yao Gao,Xinxin Hu,Zhonghua Yi,Xiaolong Qian,Weijian Hu,Jian Bai,Kaiwei Wang*

Main category: cs.LG

TL;DR: 该论文首次将大语言模型应用于光学设计领域，通过构建专用数据集OptiDesignQA、注入领域知识的混合训练目标和基于物理的奖励系统，使非光学专业用户能够成功设计功能性镜头系统，性能优于传统优化算法。


<details>
  <summary>Details</summary>
Motivation: 光学设计是一个高度非凸的优化问题，严重依赖人类启发式专业知识和领域特定知识。虽然大语言模型具备丰富的光学知识，但在镜头系统设计中的应用能力仍严重受限，需要填补专业知识鸿沟。

Method: 1. 构建包含经典和新颖镜头系统的OptiDesignQA数据集；2. 通过全系统合成和镜头补全的混合目标注入领域专业知识；3. 采用基于Group Relative Policy Optimization Done Right (DrGRPO)的光学词典奖励机制，实现物理驱动的优化；4. 集成专业光学优化工具进行端到端微调和精度优化。

Result: 在基准测试中，该方法相比传统基于优化的自动化设计算法和LLM基线模型均表现出优越性能。

Conclusion: 成功实现了首个LLM驱动的光学设计框架，使未经正式光学培训的用户也能开发功能性镜头系统，为光学设计民主化提供了新方向。

Abstract: Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method.

</details>


### [28] [MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23770)
*Chenxing Lin,Xinhui Gao,Haipeng Zhang,Xinran Li,Haitao Wang,Songzhu Mei,Chenglu Wen,Weiquan Liu,Siqi Shen,Cheng Wang*

Main category: cs.LG

TL;DR: 提出了MAGE方法，通过多尺度自回归生成框架解决离线强化学习中长期稀疏奖励任务的挑战。该方法结合多尺度自动编码器和Transformer，从粗到细生成轨迹，并通过条件引导实现精确控制，在五个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成的离线强化学习方法在长视野稀疏奖励任务中表现不佳，层次化生成方法未能充分利用轨迹中的多尺度时间结构，导致性能次优。

Method: MAGE采用条件引导的多尺度自动编码器学习层次化轨迹表示，使用多尺度Transformer从粗到细自回归生成轨迹表示，并引入条件引导解码器精确控制短期行为。

Result: 在五个离线强化学习基准测试中与15种基线算法对比，MAGE成功融合了多尺度轨迹建模与条件引导，生成了连贯且可控的轨迹。

Conclusion: MAGE有效捕捉了多分辨率下的轨迹时间依赖关系，在长视野稀疏奖励场景中实现了高性能的轨迹生成和控制。

Abstract: Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings.

</details>


### [29] [Provable Subspace Identification of Nonlinear Multi-view CCA](https://arxiv.org/abs/2602.23785)
*Zhiwei Han,Stefan Matthes,Hao Shen*

Main category: cs.LG

TL;DR: 本文解决了非线性多视角CCA的可识别性问题，证明在适当条件下，该方法能在正交歧义性范围内恢复共享潜在子空间，≥3视角时可分离所有视角共享的联合子空间，并获得有限样本理论保证。


<details>
  <summary>Details</summary>
Motivation: 非线性多视角CCA中，每个视角由未知非线性映射生成，精确解混被证明是不适定问题，需要新的可识别性理论。

Method: 将问题重新框架为基不变子空间识别，利用谱扰动理论将经验互协方差浓度转化为子空间误差界。

Result: 在潜在先验和谱分离条件下，方法以视角正交歧义性恢复相关子空间；N≥3视角时可分离共享联合子空间并消除私有变化，获得有限样本一致性保证。

Conclusion: 理论结果在合成和图像数据上得到验证，证实假设条件的必要性和方法的有效性。

Abstract: We investigate the identifiability of nonlinear Canonical Correlation Analysis (CCA) in a multi-view setup, where each view is generated by an unknown nonlinear map applied to a linear mixture of shared latents and view-private noise. Rather than attempting exact unmixing, a problem proven to be ill-posed, we instead reframe multi-view CCA as a basis-invariant subspace identification problem. We prove that, under suitable latent priors and spectral separation conditions, multi-view CCA recovers the pairwise correlated signal subspaces up to view-wise orthogonal ambiguity. For $N \geq 3$ views, the objective provably isolates the jointly correlated subspaces shared across all views while eliminating view-private variations. We further establish finite-sample consistency guarantees by translating the concentration of empirical cross-covariances into explicit subspace error bounds via spectral perturbation theory. Experiments on synthetic and rendered image datasets validate our theoretical findings and confirm the necessity of the assumed conditions.

</details>


### [30] [UPath: Universal Planner Across Topological Heterogeneity For Grid-Based Pathfinding](https://arxiv.org/abs/2602.23789)
*Aleksandr Ananikian,Daniil Drozdov,Konstantin Yakovlev*

Main category: cs.LG

TL;DR: This paper proposes a universal heuristic predictor for grid-based pathfinding that generalizes across different map distributions, reducing A* computation by 2.2x while staying within 3% of optimal cost.


<details>
  <summary>Details</summary>
Motivation: Existing learning-based heuristics for A* pathfinding fail on out-of-distribution maps, requiring retraining for each map type and limiting practical deployment where a universal solver is needed.

Method: Design a universal heuristic predictor: a deep neural network trained once to generalize across diverse unseen tasks by learning obstacle-aware heuristics that work beyond the i.i.d. distribution assumption.

Result: Reduces A* computational effort by up to 2.2x while maintaining solutions within 3% of optimal cost on completely unseen map distributions, achieving the first successful generalization for learnable solvers.

Conclusion: Successfully creates a learnable universal heuristic that bridges the generalization gap, marking a milestone for practical pathfinding applications requiring robust cross-distribution performance.

Abstract: The performance of search algorithms for grid-based pathfinding, e.g. A*, critically depends on the heuristic function that is used to focus the search. Recent studies have shown that informed heuristics that take the positions/shapes of the obstacles into account can be approximated with the deep neural networks. Unfortunately, the existing learning-based approaches mostly rely on the assumption that training and test grid maps are drawn from the same distribution (e.g., city maps, indoor maps, etc.) and perform poorly on out-of-distribution tasks. This naturally limits their application in practice when often a universal solver is needed that is capable of efficiently handling any problem instance. In this work, we close this gap by designing an universal heuristic predictor: a model trained once, but capable of generalizing across a full spectrum of unseen tasks. Our extensive empirical evaluation shows that the suggested approach halves the computational effort of A* by up to a factor of 2.2, while still providing solutions within 3% of the optimal cost on average altogether on the tasks that are completely different from the ones used for training $\unicode{x2013}$ a milestone reached for the first time by a learnable solver.

</details>


### [31] [GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks](https://arxiv.org/abs/2602.23795)
*Wenwu Tang,Dong Wang,Lothar Thiele,Olga Saukh*

Main category: cs.LG

TL;DR: 该论文提出GRAIL，一种无需微调的块级后补偿方法，通过在小规模校准集上使用格拉姆矩阵和岭回归来恢复压缩模型的精度。


<details>
  <summary>Details</summary>
Motivation: 激进的模型压缩会导致精度显著下降，通常需要微调来恢复性能，但微调在实际中往往不可行——要么缺乏标注数据，要么训练成本过高。因此需要开发无需或低代价的后压缩恢复方法。

Method: GRAIL在压缩后应用零微调步骤。对每个块，使用小规模校准集计算隐藏激活的格拉姆矩阵，然后通过岭回归学习从压缩表示到原始表示的线性重构映射。该映射被吸收到下游投影权重中。该方法对选择器不可知（支持幅度、Wanda、Gram-based或折叠），仅需前向传播且无需梯度或标签。

Result: 在ResNet、ViT和解码器-only大语言模型上的实验表明，GRAIL在实用压缩 regime 下持续优于现有无数据和含数据剪枝/折叠基线，精度或困惑度得到提升，开销可控且无需反向传播。

Conclusion: GRAIL是一种有效且实用的后压缩补偿方法，无需微调即可恢复模型性能，使激进压缩在实际应用中更加可行。

Abstract: Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL.

</details>


### [32] [MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models](https://arxiv.org/abs/2602.23798)
*Tiantong Wang,Xinyu Yan,Tiantong Wu,Yurong Hao,Yong Jiang,Fei Huang,Wei Yang Bryan Lim*

Main category: cs.LG

TL;DR: MPU是一种隐私保护的大型语言模型机器遗忘框架，通过多个扰动模型副本实现无需共享服务器参数或客户端遗忘集的本地遗忘，性能接近无噪声基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的机器遗忘面临隐私困境：严格限制禁止共享服务器参数或客户端遗忘集（双重非披露约束）。

Method: 提出MPU算法无关的隐私保护多扰动副本遗忘框架，包含两个服务器端模块：预处理（随机化副本生成，分发多个扰动且重参数化的模型实例）和后续处理（重参数化逆变换与谐波去噪聚合更新）。

Result: 七个遗忘算法的实验表明，MPU性能与无噪声基线相当，在10%噪声下大多数算法平均退化低于1%，在1%噪声下某些算法甚至优于无噪声基线。

Conclusion: 该框架在成功解决双重非披露隐私约束的同时，保持了优异的遗忘性能。

Abstract: Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.

</details>


### [33] [Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies](https://arxiv.org/abs/2602.23811)
*Xiang Li,Nan Jiang,Yuheng Zhang*

Main category: cs.LG

TL;DR: This paper extends offline RL theory to parameterized policies in large/continuous action spaces by connecting mirror descent to natural policy gradient, revealing a novel unification between offline RL and imitation learning while overcoming prior limitations.


<details>
  <summary>Details</summary>
Motivation: Existing offline RL algorithms (like PSPI) only work for finite/small action spaces and fail to accommodate practical standalone policy parameterization. The core challenge is extending theoretical guarantees to parameterized policy classes over large or continuous action spaces.

Method: The authors extend mirror descent to parameterized policies, identify contextual coupling as the key difficulty, and connect mirror descent to natural policy gradient to derive novel analyses, guarantees, and algorithms.

Result: The work provides theoretical guarantees for offline RL with parameterized policies in large/continuous action spaces, offers novel algorithmic insights, and discovers a surprising unification between offline RL and imitation learning.

Conclusion: This research bridges the gap between theoretical offline RL foundations and practical implementations with parameterized policies, enabling broader applicability while revealing fundamental connections between offline RL and imitation learning.

Abstract: We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.

</details>


### [34] [Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective](https://arxiv.org/abs/2602.23816)
*George Papadopoulos,George A. Vouros*

Main category: cs.LG

TL;DR: 提出SafeQIL算法，通过安全Q学习解决约束逆向强化学习问题，从演示轨迹中学习兼顾奖励最大化和安全性的策略


<details>
  <summary>Details</summary>
Motivation: 在未知约束和部分可观代价的受限MDP中，从安全演示轨迹学习策略，需平衡保守性与高回报但可能不安全的动作，最大化"有前景"轨迹的概率

Method: 基于Q值定义状态-动作对的"前景"，融合任务奖励和状态安全评估，提出Safe Q Inverse Constrained Reinforcement Learning (SafeQIL)算法

Result: 在具有挑战性的基准任务上，与先进逆向约束强化学习算法相比展现出优势

Conclusion: SafeQIL算法能有效从演示中学习安全且高性能的策略，在约束未知环境下具有显著优势

Abstract: Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.

</details>


### [35] [Comparing Classical and Quantum Variational Classifiers on the XOR Problem](https://arxiv.org/abs/2602.24220)
*Miras Seilkhan,Adilbek Taizhanov*

Main category: cs.LG

TL;DR: This paper compares variational quantum classifiers (with circuit depths 1 and 2) against classical models (logistic regression and MLP) on the XOR problem. While depth-2 quantum circuits match MLP's perfect accuracy under ideal conditions, they show higher loss values, longer training times, and no robustness/efficiency advantages over classical methods. Circuit depth is critical for quantum performance, but no empirical quantum advantage is observed.


<details>
  <summary>Details</summary>
Motivation: To evaluate whether variational quantum models can match or surpass classical neural networks in expressivity and robustness on the fundamental non-linear XOR problem, testing quantum machine learning's practical potential against established classical baselines.

Method: Systematic comparison of logistic regression, one-hidden-layer MLP, and two-qubit variational quantum classifiers (depths 1/2) on synthetic XOR datasets. Models are evaluated across varying Gaussian noise levels, sample sizes, and random seeds using accuracy and binary cross-entropy metrics, with hardware execution validation.

Result: Depth-2 quantum circuits achieve perfect test accuracy matching MLP, while logistic regression and depth-1 quantum circuits fail. However, MLP exhibits lower binary cross-entropy and significantly faster training. Quantum hardware preserves XOR structure but introduces structured decision function deviations. No quantum advantage in robustness or efficiency is observed.

Conclusion: Deeper variational quantum classifiers can match classical neural networks in accuracy on low-dimensional XOR tasks, but they do not demonstrate superior robustness, efficiency, or loss performance. Circuit depth is essential for quantum expressivity, yet classical methods remain more practical for this benchmark.

Abstract: Quantum machine learning applies principles such as superposition and entanglement to data processing and optimization. Variational quantum models operate on qubits in high-dimensional Hilbert spaces and provide an alternative approach to model expressivity. We compare classical models and a variational quantum classifier on the XOR problem. Logistic regression, a one-hidden-layer multilayer perceptron, and a two-qubit variational quantum classifier with circuit depths 1 and 2 are evaluated on synthetic XOR datasets with varying Gaussian noise and sample sizes using accuracy and binary cross-entropy.
  Performance is determined primarily by model expressivity. Logistic regression and the depth-1 quantum circuit fail to represent XOR reliably, whereas the multilayer perceptron and the depth-2 quantum circuit achieve perfect test accuracy under representative conditions. Robustness analyses across noise levels, dataset sizes, and random seeds confirm that circuit depth is decisive for quantum performance on this task. Despite matching accuracy, the multilayer perceptron achieves lower binary cross-entropy and substantially shorter training time. Hardware execution preserves the global XOR structure but introduces structured deviations in the decision function. Overall, deeper variational quantum classifiers can match classical neural networks in accuracy on low-dimensional XOR benchmarks, but no clear empirical advantage in robustness or efficiency is observed in the examined settings.

</details>


### [36] [Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach](https://arxiv.org/abs/2602.23824)
*Pavlin G. Poličar,Dalibor Stanimirović,Blaž Zupan*

Main category: cs.LG

TL;DR: 针对EHR数据左删失问题，本研究利用门诊处方续期轨迹，提出基于续期过程和变点检测的概率框架来推断慢性治疗起始时间。在240万人数据上验证，该方法比传统规则方法更准确，性能受处方密度影响。


<details>
  <summary>Details</summary>
Motivation: 纵向电子健康记录(EHR)数据通常存在左删失问题，导致诊断记录不完整且不可靠，难以准确判断疾病发病时间。相比之下，门诊处方形成基于续期的轨迹，提供了疾病管理的连续信号，但需要更好的分析方法。

Method: 提出一种概率框架，通过将处方动态建模为续期过程，并采用变点检测方法在基线泊松分布（零星处方）和特定威布尔分布（持续治疗）续期模型之间检测从零星到持续治疗的转变，从而推断慢性治疗起始时间。

Result: 使用240万人的全国性电子处方数据集验证显示，该方法比简单的基于规则的触发方法产生更合理的时间起始估计，在强左删失情况下显著减少了不合理早期检测。检测性能因疾病而异，且与处方密度密切相关。

Conclusion: 该方法突出了基于治疗的发病推断的优势和局限性，表明其有效性在很大程度上取决于处方数据的密度。

Abstract: Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference.

</details>


### [37] [FedNSAM:Consistency of Local and Global Flatness for Federated Learning](https://arxiv.org/abs/2602.23827)
*Junkang Liu,Fanhua Shang,Yuxuan Tian,Hongying Liu,Yuanyuan Liu*

Main category: cs.LG

TL;DR: 针对联邦学习中数据异质性导致全局模型尖锐最小值的问题，本文提出FedNSAM算法，通过引入全局Nesterov动量来协调全局与局部平坦度的一致性，在理论上获得更紧的收敛界，在实验上展现出更优的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，多步本地更新和数据异质性通常会导致更尖锐的全局最小值，从而降低全局模型的性能。虽然现有算法将锐度感知最小化（SAM）集成到本地训练中，但在高数据异质性设置下，局部训练的平坦度并不意味着全局模型的平坦度，因此无法有效提升全局模型的泛化能力。

Method: 提出一种新颖的FedNSAM算法，通过将全局Nesterov动量引入本地更新来协调全局与局部平坦度的一致性。该算法使用全局Nesterov动量作为客户端全局扰动和 extrapolation 的局部估计方向。

Result: 理论方面，通过Nesterov外推法证明了比FedSAM更紧的收敛界；实证方面，在CNN和Transformer模型上的综合实验验证了FedNSAM的优越性能和效率。

Conclusion: FedNSAM算法通过协调全局与局部平坦度的一致性，有效解决了高数据异质性下的联邦学习优化问题，相比现有方法具有更紧的理论保证和更好的实际表现。代码已开源。

Abstract: In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \textbf{flatness distance}, we propose a novel \textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.

</details>


### [38] [ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring](https://arxiv.org/abs/2602.23852)
*Zhaowen Wang,Dongdong Zhou,Qi Xu,Fengyu Cong,Mohammad Al-Sa'd,Jenni Raitoharju*

Main category: cs.LG

TL;DR: 提出ULW-SleepNet超轻量多模态睡眠分期框架，通过创新DSSC模块和参数优化技术，在保持高准确率（86.9%/81.4%）的同时将参数量压缩至13.3K，较SOTA减少98.6%，适用于可穿戴设备实时监测


<details>
  <summary>Details</summary>
Motivation: 现有深度学习睡眠分期模型计算复杂度高且仅支持单通道EEG，难以处理多模态PSG数据并部署于资源受限的 wearable/IoT 设备

Method: 设计ULW-SleepNet框架：采用双通道可分离卷积(DSSC)模块、深度可分离卷积、通道级参数共享和全局平均池化技术，实现多生理信号高效融合与计算开销优化

Result: 在Sleep-EDF-20和Sleep-EDF-78数据集上分别达到86.9%和81.4%准确率，仅含13.3K参数和7.89M FLOPs，较SOTA方法参数减少98.6%且精度损失极小

Conclusion: 该模型显著平衡了精度与效率，为可穿戴设备实时睡眠监测提供可行方案，开源代码将促进临床应用落地

Abstract: Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET.

</details>


### [39] [A Theory of Random Graph Shift in Truncated-Spectrum vRKHS](https://arxiv.org/abs/2602.23880)
*Zhang Wan,Tingting Mu,Samuel Kaski*

Main category: cs.LG

TL;DR: 提出基于随机图模型(RGM)的图分类域偏移理论框架，推导出可分解为域差异、谱几何和幅度三项的泛化界


<details>
  <summary>Details</summary>
Motivation: 经典域适应理论未充分利用图样本的结构信息，且图的Non-Euclidean特性使细粒度分析复杂化

Method: 假设RGM为数据生成过程，基于向量值再生核希尔伯特空间(vRKHS)建立理论，推导泛化界

Result: 泛化界的偏移惩罚可分解为：(i)域差异项(ii)可及截断谱总结的谱几何项(iii)收敛与构造稳定性幅度项

Conclusion: 该理论实现了对图分布偏移的细粒度分析，并通过真实数据和模拟实验验证了理论洞察

Abstract: This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations.

</details>


### [40] [Intrinsic Lorentz Neural Network](https://arxiv.org/abs/2602.23981)
*Xianglong Shi,Ziheng Chen,Yunhan Jiang,Nicu Sebe*

Main category: cs.LG

TL;DR: The paper proposes ILNN, a fully intrinsic hyperbolic neural network architecture using the Lorentz model that introduces novel components like point-to-hyperplane layers and GyroLBN, achieving state-of-the-art performance on CIFAR and genomic benchmarks.


<details>
  <summary>Details</summary>
Motivation: Real-world data exhibits hierarchical structures naturally represented by hyperbolic geometry, but existing hyperbolic networks are only partially intrinsic by mixing Euclidean/hyperbolic operations or using extrinsic parameterizations.

Method: ILNN is a fully intrinsic hyperbolic architecture conducting all computations in the Lorentz model. Key innovations: 1) point-to-hyperplane FC layer using hyperbolic distances to Lorentz hyperplanes, 2) GyroLBN batch normalization coupling gyro-centering/scaling, 3) gyro-additive bias, 4) Lorentz patch-concatenation with digamma-based scaling, and 5) Lorentz dropout.

Result: Experiments on CIFAR-10/100 and genomic benchmarks (TEB/GUE) show ILNN achieves state-of-the-art performance among hyperbolic models, consistently surpasses Euclidean baselines, and improves computational efficiency while reducing training time.

Conclusion: ILNN successfully creates a fully intrinsic hyperbolic neural network that respects geometric curvature, demonstrating superior performance and efficiency across multiple domains compared to existing hyperbolic and Euclidean approaches.

Abstract: Real-world data frequently exhibit latent hierarchical structures, which can be naturally represented by hyperbolic geometry. Although recent hyperbolic neural networks have demonstrated promising results, many existing architectures remain partially intrinsic, mixing Euclidean operations with hyperbolic ones or relying on extrinsic parameterizations. To address it, we propose the \emph{Intrinsic Lorentz Neural Network} (ILNN), a fully intrinsic hyperbolic architecture that conducts all computations within the Lorentz model. At its core, the network introduces a novel \emph{point-to-hyperplane} fully connected layer (FC), replacing traditional Euclidean affine logits with closed-form hyperbolic distances from features to learned Lorentz hyperplanes, thereby ensuring that the resulting geometric decision functions respect the inherent curvature. Around this fundamental layer, we design intrinsic modules: GyroLBN, a Lorentz batch normalization that couples gyro-centering with gyro-scaling, consistently outperforming both LBN and GyroBN while reducing training time. We additionally proposed a gyro-additive bias for the FC output, a Lorentz patch-concatenation operator that aligns the expected log-radius across feature blocks via a digamma-based scale, and a Lorentz dropout layer. Extensive experiments conducted on CIFAR-10/100 and two genomic benchmarks (TEB and GUE) illustrate that ILNN achieves state-of-the-art performance and computational cost among hyperbolic models and consistently surpasses strong Euclidean baselines. The code is available at \href{https://github.com/Longchentong/ILNN}{\textcolor{magenta}{this url}}.

</details>


### [41] [MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening](https://arxiv.org/abs/2602.23994)
*Vrushank Ahire,Yogesh Kumar,Anouck Girard,M. A. Ganaie*

Main category: cs.LG

TL;DR: 提出MINT框架，通过将MRI生物标志物结构转移到语音编码器，实现无需扫描的阿尔茨海默病早期筛查，性能媲美纯语音方法


<details>
  <summary>Details</summary>
Motivation: 现有神经影像学方法（如MRI）成本高且基础设施要求严格，难以大规模部署；而纯语音分析缺乏生物学依据，在区分认知正常与轻度认知障碍时可靠性有限

Method: 三阶段跨模态框架：1) 训练MRI教师模型建立神经影像嵌入空间；2) 通过残差投影头和几何损失将语音表征对齐到冻结的影像流形；3) 推理时直接应用冻结的MRI分类器到对齐后的语音嵌入

Result: 在ADNI-4数据集上，对齐后的语音达到与纯语音基线相当的性能(AUC 0.720 vs 0.711)，多模态融合超越单独MRI(0.973 vs 0.958)；消融实验证实dropout正则化和自监督预训练是关键设计

Conclusion: 首次实现MRI到语音的知识转移，为阿尔茨海默病早期筛查建立了生物学基础的群体级认知分诊路径，推理阶段无需神经影像设备

Abstract: Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.

</details>


### [42] [Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments](https://arxiv.org/abs/2602.23997)
*Florent Delgrange*

Main category: cs.LG

TL;DR: 该论文提出"基础世界模型"的概念框架，旨在解决现有自主智能体在开放世界中无法适应新环境的缺陷。通过整合可学习奖励模型、自适应形式化验证、在线抽象校准和测试时合成四大组件，实现智能体既能高效学习，又能可靠行动并解释其行为。


<details>
  <summary>Details</summary>
Motivation: 标准方法假设任务和环境固定、缺乏新意，限制了世界模型支持智能体随条件变化而演化的能力。下一代自主智能体不仅需要高效学习，还必须在开放世界中可靠行动并适应新情况。

Method: 提出包含四个组件的研究议程：(i) 从规约学习可学习的奖励模型以支持目标优化；(ii) 将自适应形式化验证贯穿于学习过程；(iii) 在线抽象校准以量化模型预测的可靠性；(iv) 由验证器引导的测试时合成与世界模型生成。统一强化学习、程序合成和抽象机制。

Result: 构建的框架使智能体能够：合成可验证程序、从少量交互中推导新策略、在适应新环境时保持正确性，并能解释和证明其行为。但本文主要提出研究愿景而非实证结果。

Conclusion: 基础世界模型可作为学习、推理和适应的底层架构，为下一代自主智能体奠定基础——这些智能体不仅表现良好，还能在开放世界中可靠适应并解释其行为决策。

Abstract: The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt.

</details>


### [43] [InfoNCE Induces Gaussian Distribution](https://arxiv.org/abs/2602.24012)
*Roy Betser,Eyal Gofer,Meir Yossef Levi,Guy Gilboa*

Main category: cs.LG

TL;DR: 该论文证明了InfoNCE对比学习目标会在表征中诱导出高斯结构，为观察到的对比表征高斯性提供了理论解释，并支持了后续的分析应用。


<details>
  <summary>Details</summary>
Motivation: 对比学习已成为现代表征学习的基石，但其学习到的表征为何常表现出高斯分布特性仍缺乏系统性理论解释。理解这一现象对于分析和改进对比学习模型至关重要。

Method: 研究通过两种互补的理论框架进行分析：1）在特定对齐和集中假设下，证明高维表征的投影渐近趋于多元高斯分布；2）在较弱假设下，通过添加微小的渐消正则项（促进低特征范数和高特征熵）获得类似渐近结果。并在合成数据和CIFAR-10数据集上进行了多架构、多尺寸的实验验证。

Result: 理论证明了InfoNCE目标诱导出的高斯结构特性，实验在不同条件下观察到了稳定的一致性高斯行为。该发现揭示了对比表征的内在统计规律。

Conclusion: 研究为对比表征中的高斯现象提供了原理性解释，建立的高斯模型使表征的解析处理成为可能，预计将支持对比学习在广泛领域的应用。

Abstract: Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning.

</details>


### [44] [RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models](https://arxiv.org/abs/2602.24040)
*Daniel Yang,Samuel Stante,Florian Redhardt,Lena Libon,Parnian Kassraie,Ido Hakimi,Barna Pásztor,Andreas Krause*

Main category: cs.LG

TL;DR: 提出RewardUQ框架系统评估奖励模型的不确定性量化方法，发现模型尺寸和初始化对性能影响最大，并开源代码促进后续研究


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型忽略人类反馈有限性导致的认知不确定性，且缺乏系统比较方法，影响LLM对齐效果与成本效益

Method: 构建统一框架RewardUQ，通过标准指标（准确性/校准性）和新颖双维度排序策略对比常见不确定性量化方法

Result: 实验表明模型尺寸和初始化对性能影响最显著，多数先前研究可通过改进设计选择获得更好效果

Conclusion: 开源Python框架以促进新方法开发，助力下游应用部署，代码已发布于GitHub

Abstract: Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.

</details>


### [45] [pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures](https://arxiv.org/abs/2602.24066)
*Tobias Nygaard*

Main category: cs.LG

TL;DR: The paper introduces pathsig, a PyTorch-native library that efficiently computes path signatures using CUDA kernels in the word basis, achieving 10-30x speedups for truncated signatures and 4-10x speedups in gradient-based training while supporting flexible projection and truncation methods.


<details>
  <summary>Details</summary>
Motivation: Existing path signature libraries lack the scalability required for large-scale gradient-based learning, limiting their integration into modern machine learning pipelines despite their theoretical promise and empirical performance.

Method: The authors developed pathsig, a PyTorch-native library that computes path signatures directly in the word basis using custom CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, optimizing for GPU throughput and memory efficiency.

Result: Compared to other libraries, pathsig achieves 10-30x speedups for truncated signature computation and 4-10x speedups during backpropagation training, with near-minimal peak memory usage, while supporting word set projections and anisotropic truncation for compact representations.

Conclusion: Pathsig enables scalable gradient-based learning with path signatures and provides flexible truncation schemes that reduce dimensionality and computational cost, making it practical for large-scale machine learning applications involving sequential data.

Abstract: Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost.

</details>


### [46] [Leveraging Non-linear Dimension Reduction and Random Walk Co-occurrence for Node Embedding](https://arxiv.org/abs/2602.24069)
*Ryan DeWolfe*

Main category: cs.LG

TL;DR: 提出COVE——一种可解释的高维节点嵌入方法，通过UMAP降维后轻微提升聚类与链接预测性能，且COVE+UMAP+HDBSCAN流程在社区检测上可媲美Louvain算法。


<details>
  <summary>Details</summary>
Motivation: 传统节点嵌入受限于低维表示，可能限制下游任务性能。

Method: 基于随机游走共现和扩散过程的高维嵌入，利用UMAP进行非线性降维。

Result: 降维后聚类与链接预测性能小幅提升；完整流程在社区检测基准测试中与Louvain算法性能相当。

Conclusion: 高维嵌入配合非线性降维为图挖掘任务提供了一种可解释且具竞争力的解决方案。

Abstract: Leveraging non-linear dimension reduction techniques, we remove the low dimension constraint from node embedding and propose COVE, an explainable high dimensional embedding that, when reduced to low dimension with UMAP, slightly increases performance on clustering and link prediction tasks. The embedding is inspired by neural embedding methods that use co-occurrence on a random walk as an indication of similarity, and is closely related to a diffusion process. Extending on recent community detection benchmarks, we find that a COVE UMAP HDBSCAN pipeline performs similarly to the popular Louvain algorithm.

</details>


### [47] [Neural Diffusion Intensity Models for Point Process Data](https://arxiv.org/abs/2602.24083)
*Xinlong Du,Harsha Honnappa,Vinayak Rao*

Main category: cs.LG

TL;DR: The paper proposes Neural Diffusion Intensity Models, a variational framework for Cox processes using neural SDEs, with a theoretical guarantee that the variational family contains the true posterior, enabling efficient amortized inference that replaces MCMC with a single forward pass.


<details>
  <summary>Details</summary>
Motivation: Cox processes model overdispersed point process data via latent stochastic intensity, but nonparametric estimation and posterior inference are computationally intractable and rely on expensive MCMC methods.

Method: They introduce a variational framework based on neural SDEs, with a key theoretical result using enlargement of filtrations showing that conditioning on observations preserves diffusion structure with an explicit drift correction. They design an amortized encoder architecture that maps event sequences to posterior paths by simulating the drift-corrected SDE.

Result: Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.

Conclusion: The proposed Neural Diffusion Intensity Models provide a theoretically-grounded, computationally efficient alternative to MCMC for Cox process inference, achieving accurate results with dramatically reduced computational cost.

Abstract: Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.

</details>


### [48] [Learning with a Budget: Identifying the Best Arm with Resource Constraints](https://arxiv.org/abs/2602.24146)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 该论文研究资源约束下的最佳臂识别问题，提出基于资源配给的连续减半算法(SH-RR)，通过新的有效消耗度量统一了随机和确定性资源消耗的理论分析框架。


<details>
  <summary>Details</summary>
Motivation: 实际应用中的备选方案评估存在异质性成本与资源消耗，传统最佳臂识别模型未考虑有限资源约束，导致算法在资源受限场景下无法直接应用。

Method: 提出"连续减半+资源配给"(SH-RR)算法，将资源感知分配机制融入经典连续减半框架，引入创新的有效消耗度量来处理多类型资源约束，支持随机与确定性两种消耗模型。

Result: 该算法统一了不同资源消耗设置下的理论分析，在随机和确定性消耗场景下均提供可证明的性能保证（具体边界见原文完整证明）。

Conclusion: SH-RR为资源约束下的最佳臂识别提供了通用且理论坚实的解决方案，拓展了传统方法的适用范围。

Abstract: In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \textit{effective consumption measure

</details>


### [49] [An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks](https://arxiv.org/abs/2602.24209)
*Mohsen Tajgardan,Atena Shiranzaei,Mahdi Rabbani,Reza Khoshkangini,Mahtab Jamali*

Main category: cs.LG

TL;DR: 提出了一种高效的联邦学习框架，通过融合两个物联网数据集（异常检测与设备识别）的共享特征，在保护数据隐私的同时显著提升了分布式物联网环境下的异常检测准确率。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的异构性导致数据特征分布差异大，传统联邦学习在异常检测任务中面临模型性能下降和隐私保护的双重挑战，需要解决特征异质性带来的训练难题。

Method: 提出无监督联邦学习框架，利用两个互补物联网数据集（异常检测数据集和设备识别数据集）的共享特征进行联合训练，保留数据集特有特征；采用SHAP等可解释AI技术识别影响本地模型决策的关键特征。

Result: 在真实物联网数据集上的实验表明，所提方法在异常检测准确率方面显著优于传统联邦学习方案。

Conclusion: 通过利用互补数据集的共享特征优化无监督联邦学习，可在去中心化的物联网环境中实现更优的异常检测效果，验证了该方法的有效性和应用潜力。

Abstract: Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.

</details>


### [50] [Memory Caching: RNNs with Growing Memory](https://arxiv.org/abs/2602.24281)
*Ali Behrouz,Zeman Li,Yuan Deng,Peilin Zhong,Meisam Razaviyayn,Vahab Mirrokni*

Main category: cs.LG

TL;DR: Proposes Memory Caching (MC) to enhance recurrent models by caching hidden states, enabling flexible memory scaling between RNNs' O(L) and Transformers' O(L²) complexity, closing performance gap in recall tasks.


<details>
  <summary>Details</summary>
Motivation: Transformers suffer quadratic complexity from growing memory, while subquadratic recurrent alternatives underperform in recall-intensive tasks due to fixed-size memory, creating a need for scalable recurrent architectures.

Method: Introduces Memory Caching (MC)—caching checkpoints of RNN hidden states—with four variants (gated aggregation, sparse selection) to flexibly expand effective memory capacity proportionally to sequence length.

Result: MC-enhanced recurrent models improve language modeling and long-context tasks; in recall tasks, MC variants achieve near-Transformer accuracy (though Transformers lead) and outperform state-of-the-art recurrent models.

Conclusion: MC provides an effective trade-off between RNNs' efficiency and Transformers' memory capacity, making recurrent models competitive for long-context and recall-intensive applications.

Abstract: Transformers have been established as the de-facto backbones for most recent advances in sequence modeling, mainly due to their growing memory capacity that scales with the context length. While plausible for retrieval tasks, it causes quadratic complexity and so has motivated recent studies to explore viable subquadratic recurrent alternatives. Despite showing promising preliminary results in diverse domains, such recurrent architectures underperform Transformers in recall-intensive tasks, often attributed to their fixed-size memory. In this paper, we introduce Memory Caching (MC), a simple yet effective technique that enhances recurrent models by caching checkpoints of their memory states (a.k.a. hidden states). Memory Caching allows the effective memory capacity of RNNs to grow with sequence length, offering a flexible trade-off that interpolates between the fixed memory (i.e., $O(L)$ complexity) of RNNs and the growing memory (i.e., $O(L^2)$ complexity) of Transformers. We propose four variants of MC, including gated aggregation and sparse selective mechanisms, and discuss their implications on both linear and deep memory modules. Our experimental results on language modeling, and long-context understanding tasks show that MC enhances the performance of recurrent models, supporting its effectiveness. The results of in-context recall tasks indicate that while Transformers achieve the best accuracy, our MC variants show competitive performance, close the gap with Transformers, and performs better than state-of-the-art recurrent models.

</details>


### [51] [Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers](https://arxiv.org/abs/2602.24182)
*Sikata Sengupta,Guangyi Liu,Omer Gottesman,Joseph W Durham,Michael Kearns,Aaron Roth,Michael Caldara*

Main category: cs.LG

TL;DR: 将容器化履约中心的货物整合问题建模为多目标强化学习任务，通过零和博弈中的无遗憾动态理论实现约束优化，在仓库仿真中有效平衡多个目标并满足约束。


<details>
  <summary>Details</summary>
Motivation: 容器化履约中心需要通过人机协同工作站移动货物来优化空间利用率和处理速度，同时面临资源使用等多目标权衡和现实运营约束，传统方法难以有效处理这种大规模、高维度的动态决策问题。

Method: 将问题形式化为大规模多目标强化学习任务，基于零和博弈中的最佳响应和无遗憾动态理论实现约束RL求解，提出极小极大策略学习方法，并构建误差抵消理论框架来解决时间平均解的振荡问题。

Result: 在真实仓库仿真环境中，该方法能有效权衡多个竞争目标，学习出能同时满足所有约束的单一策略；误差抵消框架返回的单一迭代值其拉格朗日值接近博弈的极小极大值，避免了振荡行为。

Conclusion: 该工作展示了多目标强化学习在解决大规模工业系统复杂决策问题中的巨大潜力，为容器化履约中心的智能优化提供了有前景的理论框架和实践方法。

Abstract: Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems.

</details>


### [52] [Taming Momentum: Rethinking Optimizer States Through Low-Rank Approximation](https://arxiv.org/abs/2602.24283)
*Zhengbo Wang,Jian Liang,Ran He,Zilei Wang,Tieniu Tan*

Main category: cs.LG

TL;DR: 提出LoRA-Pre低秩优化器，通过分解动量矩阵为低秩子空间，显著降低内存开销，在预训练和微调中均超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 现代优化器如Adam和Muon依赖动量造成显著内存开销，限制了大规模模型训练的可扩展性和计算效率。

Method: 将指数移动平均(EMA)重新建模为在线梯度流训练的线性回归器，并在此基础上设计低秩优化器LoRA-Pre，通过低秩分解压缩动量矩阵。

Result: 在60M-1B参数的Llama模型预训练中全面领先；仅用基线1/8的秩即达到相当或更优性能；微调时相比标准LoRA在Llama-3.1-8B提升3.14分，Llama-2-7B提升6.17分。

Conclusion: LoRA-Pre是一种高效的新型优化器，在保持优化性能的同时大幅降低内存占用，适用于预训练和微调场景，代码已开源。

Abstract: Modern optimizers like Adam and Muon are central to training large language models, but their reliance on first- and second-order momenta introduces significant memory overhead, which constrains scalability and computational efficiency. In this work, we reframe the exponential moving average (EMA) used in these momenta as the training of a linear regressor via online gradient flow. Building on this equivalence, we introduce LoRA-Pre, a novel low-rank optimizer designed for efficient pre-training. Specifically, LoRA-Pre reduces the optimizer's memory footprint by decomposing the full momentum matrix into a compact low-rank subspace within the online linear learner, thereby maintaining optimization performance while improving memory efficiency. We empirically validate LoRA-Pre's efficacy by pre-training models from the Llama architecture family, scaling from 60M to 1B parameters. LoRA-Pre achieves the highest performance across all model sizes. Notably, LoRA-Pre demonstrates remarkable rank efficiency, achieving comparable or superior results using only 1/8 the rank of baseline methods. Beyond pre-training, we evaluate LoRA-Pre's effectiveness in fine-tuning scenarios. With the same rank, LoRA-Pre consistently outperforms all efficient fine-tuning baselines. Specifically, compared to standard LoRA, LoRA-Pre achieves substantial improvements of 3.14 points on Llama-3.1-8B and 6.17 points on Llama-2-7B, validating our approach's effectiveness across both pre-training and fine-tuning paradigms. Our code is publicly available at https://github.com/mrflogs/LoRA-Pre.

</details>


### [53] [Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics](https://arxiv.org/abs/2602.24201)
*Egor Antipov,Alessandro Palma,Lorenzo Consoli,Stephan Günnemann,Andrea Dittadi,Fabian J. Theis*

Main category: cs.LG

TL;DR: 提出一种基于条件感知流匹配的密度比估计方法，通过单一动态公式追踪生成轨迹中的密度比，显著降低计算成本，并在模拟基准测试和单细胞基因组学分析中展现竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有密度比估计方法（如归一化流）需为每个分布单独模拟高成本似然积分，计算效率低；需支持跨条件/协变量的样本似然对比，尤其在单细胞基因组学中需高效比较细胞状态以评估处理效应和批次校正。

Method: 利用条件感知流匹配技术，推导出可沿生成轨迹跟踪密度比的统一动力学公式，避免为每个分布独立计算似然积分，实现单次模拟完成多分布对比。

Result: 在闭式密度比估计的模拟基准测试中表现具有竞争力；成功应用于单细胞基因组学，支持跨实验条件的细胞状态似然对比，实现处理效应估计和批次校正评估。

Conclusion: 该方法通过单一动态建模显著提升计算效率，为复杂领域（如基因组学）中的概率分布对比提供可扩展工具，平衡了计算成本与性能。

Abstract: Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation.

</details>


### [54] [CUDA Agent: Large-Scale Agentic RL for High-Performance CUDA Kernel Generation](https://arxiv.org/abs/2602.24286)
*Weinan Dai,Hanlin Wu,Qiying Yu,Huan-ang Gao,Jiahao Li,Chengquan Jiang,Weiqiang Lou,Yufan Song,Hongli Yu,Jiaze Chen,Wei-Ying Ma,Ya-Qin Zhang,Jingjing Liu,Mingxuan Wang,Xin Liu,Hao Zhou*

Main category: cs.LG

TL;DR: CUDA Agent uses large-scale reinforcement learning to automatically optimize CUDA kernels, achieving up to 100% speedup over torch.compile and outperforming top proprietary models like Claude Opus 4.5 by ~40% on the hardest tasks.


<details>
  <summary>Details</summary>
Motivation: GPU kernel optimization requires deep hardware expertise, and existing LLM approaches fail to fundamentally improve intrinsic CUDA optimization ability, remaining uncompetitive with compiler-based systems like torch.compile.

Method: A three-component agentic RL system: (1) scalable data synthesis pipeline, (2) skill-augmented CUDA environment with automated verification/profiling for reward signals, and (3) RL algorithms for stable training.

Result: State-of-the-art performance on KernelBench: 100%, 100%, and 92% faster than torch.compile on Level-1/2/3 splits, outperforming Claude Opus 4.5 and Gemini 3 Pro by ~40% on hardest Level-3 tasks.

Conclusion: CUDA Agent successfully develops CUDA kernel expertise through reinforcement learning, demonstrating that systematic RL training can bridge the performance gap between LLMs and specialized compiler systems for hardware optimization.

Abstract: GPU kernel optimization is fundamental to modern deep learning but remains a highly specialized task requiring deep hardware expertise. Despite strong performance in general programming, large language models (LLMs) remain uncompetitive with compiler-based systems such as torch.compile for CUDA kernel generation. Existing CUDA code generation approaches either rely on training-free refinement or fine-tune models within fixed multi-turn execution-feedback loops, but both paradigms fail to fundamentally improve the model's intrinsic CUDA optimization ability, resulting in limited performance gains. We present CUDA Agent, a large-scale agentic reinforcement learning system that develops CUDA kernel expertise through three components: a scalable data synthesis pipeline, a skill-augmented CUDA development environment with automated verification and profiling to provide reliable reward signals, and reinforcement learning algorithmic techniques enabling stable training. CUDA Agent achieves state-of-the-art results on KernelBench, delivering 100\%, 100\%, and 92\% faster rate over torch.compile on KernelBench Level-1, Level-2, and Level-3 splits, outperforming the strongest proprietary models such as Claude Opus 4.5 and Gemini 3 Pro by about 40\% on the hardest Level-3 setting.

</details>


### [55] [The Stability of Online Algorithms in Performative Prediction](https://arxiv.org/abs/2602.24207)
*Gabriele Farina,Juan Carlos Perdomo*

Main category: cs.LG

TL;DR: 该论文证明了任意无悔算法在感性决策环境中都会收敛至一个（混合）感性稳定均衡，通过鞅论论证和随机化方法突破以往限制，并解释了为何梯度下降等常见算法天然具有稳定特性，防止反馈失控。


<details>
  <summary>Details</summary>
Motivation: 算法预测在决策中使用时会形成反馈循环，部署的模型会影响所见的数据分布，进而影响后续训练。这一动态由Perdomo等人2020年在感性预测研究中形式化。此前所有正面结果都对该模型如何影响分布施加了强限制。

Method: 通过鞅论论证并允许随机化，建立无条件归约，避免了任何此类假设，绕过了寻找稳定模型的近期困难结果。

Result: 证明了在感性环境中，任何无悔算法都会收敛到一个（混合）感性稳定均衡：模型主动塑造数据分布，使其自身预测在事后看来是最佳的解决方案。

Conclusion: 这一联系阐明了为何梯度下降等常见算法天然具有稳定特性，能防止失控反馈循环。期望该工作能促进在线优化与感性决策两个领域之间的技术思想转移。

Abstract: The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity.

</details>


### [56] [Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference](https://arxiv.org/abs/2602.24231)
*Hongrui Xie,Junyu Cao,Kan Xu*

Main category: cs.LG

TL;DR: 该论文首次研究自适应组合实验设计，在组合多臂老虎机中建立遗憾最小化与统计功效之间的帕累托最优权衡框架，提出两种算法并证明其理论优越性。


<details>
  <summary>Details</summary>
Motivation: 传统组合实验设计面临核心矛盾：最小化遗憾需重复利用高回报策略，而准确推断奖励差距需充分探索次优策略。现有研究未系统解决这一多目标权衡问题。

Method: 1) 通过帕累托最优性形式化权衡关系；2) 针对全臂反馈和半臂反馈两种信息结构，分别提出MixCombKL和MixCombUCB算法；3) 建立有限时间理论保证。

Result: 1) 证明两种算法均达到帕累托最优；2) 揭示更丰富的反馈能显著收紧帕累托前沿；3) 核心改进源于所提方法在估计精度上的提升。

Conclusion: 建立了自适应组合实验的多目标决策理论框架，为平衡探索-利用与统计推断需求提供了原则性解决方案。

Abstract: In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making.

</details>


### [57] [Time Series Foundation Models as Strong Baselines in Transportation Forecasting: A Large-Scale Benchmark Analysis](https://arxiv.org/abs/2602.24238)
*Javier Pulido,Filipe Rodrigues*

Main category: cs.LG

TL;DR: 本文评估了时间序列基础模型Chronos-2在交通预测任务中的零样本性能，发现无需任务特定微调，该模型在10个真实世界数据集上即可达到顶尖或极具竞争力的精度，支持将其作为交通预测研究的基准方法。


<details>
  <summary>Details</summary>
Motivation: 交通动态的精准预测对城市出行和基础设施规划至关重要。现有深度学习模型虽表现优异，但需要针对每个数据集进行专门训练、架构设计和超参数调优，缺乏通用性。

Method: 在一致的评估协议下，对Chronos-2模型进行零样本基准测试，涵盖10个真实世界数据集（包括高速公路交通量/流量、城市交通速度、共享单车需求和电动汽车充电站数据），并评估其点预测和概率预测能力。

Result: Chronos-2在大多数数据集上无需微调即可达到顶尖或具竞争力的精度，常优于经典统计基线和专用深度学习架构，尤其在更长预测视界表现突出；同时提供了有效的本地不确定性量化。

Conclusion: 该研究支持将时间序列基础模型作为交通预测研究的关键基准，为其在交通领域的应用提供了实证依据。

Abstract: Accurate forecasting of transportation dynamics is essential for urban mobility and infrastructure planning. Although recent work has achieved strong performance with deep learning models, these methods typically require dataset-specific training, architecture design and hyper-parameter tuning. This paper evaluates whether general-purpose time-series foundation models can serve as forecasters for transportation tasks by benchmarking the zero-shot performance of the state-of-the-art model, Chronos-2, across ten real-world datasets covering highway traffic volume and flow, urban traffic speed, bike-sharing demand, and electric vehicle charging station data. Under a consistent evaluation protocol, we find that, even without any task-specific fine-tuning, Chronos-2 delivers state-of-the-art or competitive accuracy across most datasets, frequently outperforming classical statistical baselines and specialized deep learning architectures, particularly at longer horizons. Beyond point forecasting, we evaluate its native probabilistic outputs using prediction-interval coverage and sharpness, demonstrating that Chronos-2 also provides useful uncertainty quantification without dataset-specific training. In general, this study supports the adoption of time-series foundation models as a key baseline for transportation forecasting research.

</details>


### [58] [Chunk-wise Attention Transducers for Fast and Accurate Streaming Speech-to-Text](https://arxiv.org/abs/2602.24245)
*Hainan Xu,Vladimir Bataev,Travis M. Bartley,Jagadeesh Balam*

Main category: cs.LG

TL;DR: CHAT is a novel extension to RNN-T models that processes audio in fixed-size chunks with cross-attention, achieving significant efficiency gains (up to 46.2% less memory, 1.69X faster inference) and accuracy improvements (up to 6.3% WER reduction for ASR, 18.0% BLEU gain for translation) while maintaining streaming capability.


<details>
  <summary>Details</summary>
Motivation: RNN-T's strict monotonic alignment limits performance for speech translation, and the model's computational demands are high. The paper aims to maintain streaming capability while introducing controlled flexibility for local alignment modeling to improve both efficiency and accuracy.

Method: Chunk-wise Attention Transducer (CHAT): processes audio in fixed-size chunks with cross-attention within each chunk. This hybrid approach reduces temporal dimension that RNN-T must handle, combining streaming capability with local alignment flexibility.

Result: Up to 46.2% reduction in peak training memory, 1.36X faster training, 1.69X faster inference. Up to 6.3% relative WER reduction for speech recognition and 18.0% BLEU improvement for speech translation across multiple languages/tasks.

Conclusion: CHAT provides a practical solution for deploying more capable streaming speech models without sacrificing real-time constraints, particularly effective for speech translation where monotonic alignment is limiting.

Abstract: We propose Chunk-wise Attention Transducer (CHAT), a novel extension to RNN-T models that processes audio in fixed-size chunks while employing cross-attention within each chunk. This hybrid approach maintains RNN-T's streaming capability while introducing controlled flexibility for local alignment modeling. CHAT significantly reduces the temporal dimension that RNN-T must handle, yielding substantial efficiency improvements: up to 46.2% reduction in peak training memory, up to 1.36X faster training, and up to 1.69X faster inference. Alongside these efficiency gains, CHAT achieves consistent accuracy improvements over RNN-T across multiple languages and tasks -- up to 6.3% relative WER reduction for speech recognition and up to 18.0% BLEU improvement for speech translation. The method proves particularly effective for speech translation, where RNN-T's strict monotonic alignment hurts performance. Our results demonstrate that the CHAT model offers a practical solution for deploying more capable streaming speech models without sacrificing real-time constraints.

</details>


### [59] [Who Guards the Guardians? The Challenges of Evaluating Identifiability of Learned Representations](https://arxiv.org/abs/2602.24278)
*Shruti Joshi,Théo Saulus,Wieland Brendel,Philippe Brouillard,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: Standard metrics for evaluating identifiability in representation learning (e.g., MCC, DCI, R²) are unreliable because they rely on hidden assumptions about data generation and encoder structure; when violated, they produce systematic errors. The authors introduce a taxonomy to clarify these assumptions, map the validity domains of existing metrics, and release a stress-testing suite.


<details>
  <summary>Details</summary>
Motivation: Existing evaluation metrics for identifiability are assumed to correctly measure factor recovery up to theoretical equivalence classes, but this assumption lacks rigorous justification. The paper seeks to uncover the implicit assumptions behind these metrics and demonstrate that they can fail systematically, especially in post-hoc evaluation settings where identifiability is most critical.

Method: The authors develop a taxonomy that disentangles two types of assumptions: those about the data-generating process (DGP) and those about the encoder geometry. Using this framework, they systematically analyze and characterize the conditions under which standard metrics (MCC, DCI, R²) remain valid, revealing hidden failure modes. They also create an open-source evaluation suite for reproducible stress testing.

Result: The study reveals that standard metrics produce systematic false positives and false negatives when their implicit assumptions are violated, even within classical identifiability regimes. This demonstrates that metric validity is not universal but depends on specific structural conditions. The evaluation suite quantifies these failures across diverse settings.

Conclusion: Evaluation of identifiability using standard metrics is more fragile than previously recognized. Researchers must explicitly verify metric assumptions rather than treating them as black boxes. The proposed taxonomy clarifies validity domains, and the released evaluation suite enables more rigorous, reproducible assessment of identifiability in representation learning.

Abstract: Identifiability in representation learning is commonly evaluated using standard metrics (e.g., MCC, DCI, R^2) on synthetic benchmarks with known ground-truth factors. These metrics are assumed to reflect recovery up to the equivalence class guaranteed by identifiability theory. We show that this assumption holds only under specific structural conditions: each metric implicitly encodes assumptions about both the data-generating process (DGP) and the encoder. When these assumptions are violated, metrics become misspecified and can produce systematic false positives and false negatives. Such failures occur both within classical identifiability regimes and in post-hoc settings where identifiability is most needed. We introduce a taxonomy separating DGP assumptions from encoder geometry, use it to characterise the validity domains of existing metrics, and release an evaluation suite for reproducible stress testing and comparison.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [60] [HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance](https://arxiv.org/abs/2602.23367)
*Shubh Laddha,Lucas Changbencharoen,Win Kuptivej,Surya Shringla,Archana Vaidheeswaran,Yash Bhaskar*

Main category: cs.AI

TL;DR: This paper introduces the first large-scale MCP dataset with diverse, realistic user queries across 2,800 tools from 308 servers to address the gap in evaluating LLM tool usage.


<details>
  <summary>Details</summary>
Motivation: Existing MCP datasets lack realistic, human-like user queries, leading to poor generalization and inflated benchmark reliability for evaluating tool usage and ecosystems.

Method: Developed a large-scale dataset building on MCP Zero, pairing 2,800 tools from 308 MCP servers with multiple unique user personas that generate diverse queries ranging from precise tasks to ambiguous, exploratory commands.

Result: Created the first MCP dataset with diverse, high-quality user queries that better reflect real-world interaction patterns across a wide range of tools and servers.

Conclusion: This dataset addresses a critical gap in MCP evaluation by providing realistic user queries that enable more accurate assessment of LLM tool usage capabilities and ecosystem performance.

Abstract: Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.

</details>


### [61] [Causal Identification from Counterfactual Data: Completeness and Bounding Results](https://arxiv.org/abs/2602.23541)
*Arvind Raghavan,Elias Bareinboim*

Main category: cs.AI

TL;DR: This paper extends counterfactual identification beyond observational/interventional data by introducing CTFIDU+ algorithm that uses experimentally realizable Layer 3 counterfactual distributions, proving its completeness, establishing theoretical limits for causal inference, and deriving practical bounds for non-identifiable quantities.


<details>
  <summary>Details</summary>
Motivation: Previous work on counterfactual identification was limited to Layers 1 and 2 of Pearl's Causal Hierarchy (observational/interventional data). Recent work introduced "counterfactual realizability" - some Layer 3 distributions can be experimentally estimated. This opens the question: what additional counterfactual quantities become identifiable with Layer 3 data access?

Method: Developed CTFIDU+ algorithm for identifying counterfactual queries from arbitrary Layer 3 distributions, and derived novel analytic bounds for non-identifiable quantities using realizable counterfactual data.

Result: CTFIDU+ is proven complete for this task. The paper establishes theoretical limits of counterfactual identification from physically realizable distributions (fundamental limit to exact causal inference). Simulations confirm counterfactual data tightens bounds for non-identifiable quantities in practice.

Conclusion: There exists a fundamental limit to exact causal inference in the non-parametric setting, but access to realizable counterfactual distributions enables identification of additional quantities and provides tighter bounds for those that remain non-identifiable.

Abstract: Previous work establishing completeness results for $\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\textit{counterfactual realizabilty}$. This leaves open the question of what $\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.

</details>


### [62] [Planning under Distribution Shifts with Causal POMDPs](https://arxiv.org/abs/2602.23545)
*Matteo Ceriscioli,Karthika Mohan*

Main category: cs.AI

TL;DR: The paper proposes a causal POMDP framework to handle distribution shifts in planning by representing shifts as interventions, maintaining beliefs over both state and domain changes, and proving the value function remains tractable (PWLC) under these shifts.


<details>
  <summary>Details</summary>
Motivation: Real-world planning is challenged by distribution shifts where models become invalid as environment conditions change, causing previously learned strategies to fail.

Method: Proposes a theoretical framework using causal Partially Observable Markov Decision Processes (POMDPs) where distribution shifts are represented as interventions. The method maintains and updates beliefs over both latent state and underlying domain, and proves the value function remains piecewise linear and convex (PWLC) in this augmented belief space.

Result: Shows how to maintain beliefs over state and domain simultaneously, and proves that PWLC property is preserved under distribution shifts, enabling tractable planning with α-vector-based POMDP methods.

Conclusion: The framework enables evaluating plans under hypothesized changes and actively identifying altered environment components while maintaining computational tractability.

Abstract: In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $α$-vector-based POMDP methods.

</details>


### [63] [Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem](https://arxiv.org/abs/2602.23579)
*Guillem Rodríguez-Corominas,Maria J. Blesa,Christian Blum*

Main category: cs.AI

TL;DR: A hybrid RL-CMSA method combining reinforcement learning with exact optimization effectively solves min-max mTSP by balancing exploration-exploitation, outperforming genetic algorithms especially for large-scale instances.


<details>
  <summary>Details</summary>
Motivation: Address workload imbalance in multi-salesman routing by minimizing the longest tour (min-max objective) rather than total distance, crucial for fair resource allocation in logistics and scheduling.

Method: RL-CMSA framework: (1) Probabilistically clusters cities using learned q-values to build diverse solutions; (2) Merges routes into a pool; (3) Solves restricted set-covering MILP; (4) Refines via inter-route moves; (5) Updates q-values by reinforcing city-pair co-occurrences in high-quality solutions; (6) Adapts pool via aging/pruning.

Result: Outperforms state-of-the-art hybrid genetic algorithm on random and TSPLIB instances, achieving (near-)optimal solutions with significant advantages as problem size and salesman count increase.

Conclusion: The integration of reinforcement-guided construction with exact optimization successfully balances exploration of diverse solutions and exploitation of high-quality patterns, establishing RL-CMSA as a superior approach for min-max mTSP.

Abstract: The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.

</details>


### [64] [SleepLM: Natural-Language Intelligence for Human Sleep](https://arxiv.org/abs/2602.23605)
*Zongzhe Xu,Zitao Shuai,Eideen Mozaffari,Ravi S. Aysola,Rajesh Kumar,Yuzhe Yang*

Main category: cs.AI

TL;DR: 提出SleepLM睡眠语言基础模型系列，通过自然语言实现睡眠对齐、解读与交互，构建首个超10万小时的大规模睡眠-文本数据集，在多任务上超越现有技术


<details>
  <summary>Details</summary>
Motivation: 现有学习式睡眠分析系统局限于封闭标签空间（如预设阶段或事件），无法描述、查询或泛化到新睡眠现象，缺乏与生理信号对齐的自然语言接口

Method: 1) 开发多级睡眠字幕生成流程，构建含10万+小时数据的大规模睡眠-文本数据集；2) 设计统一预训练目标，结合对比对齐、字幕生成与信号重建；3) 训练多模态睡眠-语言基础模型

Result: 在零样本/少样本学习、跨模态检索、睡眠字幕生成任务上均超越最先进方法，并展现出语言引导事件定位、定向洞察生成及对未见任务的零样本泛化等新兴能力

Conclusion: SleepLM成功桥接自然语言与多模态多导睡眠图，为睡眠生理提供语言接地表示，代码与数据将开源，推动睡眠研究的可解释性与可交互性发展

Abstract: We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.

</details>


### [65] [MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs](https://arxiv.org/abs/2602.23632)
*Lun Zhan,Feng Xiong,Huanyong Liu,Feng Zhang,Yuhui Yin*

Main category: cs.AI

TL;DR: 本文提出MMKG-RDS框架，利用多模态知识图谱合成高质量推理训练数据，解决了现有方法在长尾知识覆盖、效果验证和可解释性方面的局限。实验表明使用少量合成数据微调Qwen3模型即可提升9.2%推理准确率，并发布涵盖5个领域、14,950个样本的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有训练数据合成方法在长尾知识覆盖、有效性验证和解释性方面存在限制；基于知识图谱的方法在功能性、颗粒度、可定制性和评估方面仍有不足，亟需更灵活的解决方案来提升领域模型的推理能力。

Method: 提出MMKG-RDS框架，采用多模态知识图谱作为基础，支持细粒度知识抽取、可定制路径采样和多维度数据质量评分。构建MMKG-RDS-Bench基准数据集，涵盖5个领域、17种任务类型和14,950个样本进行验证。

Result: 在Qwen3系列模型(0.6B/8B/32B)上使用少量合成样本进行微调，推理准确率平均提升9.2%。生成的数据对表格和公式任务构成挑战，能够有效评估模型在复杂场景下的表现。

Conclusion: MMKG-RDS框架为推理数据合成提供了灵活的解决方案，生成的数据质量高且多样化，有助于构建更复杂的基准测试，推动领域模型推理能力的提升。

Abstract: Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS

</details>


### [66] [AI Must Embrace Specialization via Superhuman Adaptable Intelligence](https://arxiv.org/abs/2602.23643)
*Judah Goldfeder,Philippe Wyder,Yann LeCun,Ravid Shwartz Ziv*

Main category: cs.AI

TL;DR: 该论文批判了AGI（通用人工智能）概念的缺陷，提出SAI（超人类适应智能）作为更合适的未来AI发展方向，强调专业化而非通用性，并追求超人类性能。


<details>
  <summary>Details</summary>
Motivation: 当前对AGI的定义缺乏共识，且其核心理念存在问题；人类本身并非真正的通用智能，而AGI这一模糊概念已混淆了AI讨论，无法有效指导未来发展。

Method: 通过批判性分析现有AGI定义的合理性、实用性和真正通用性，指出其概念缺陷；进而提出SAI框架作为替代方案，并推演其应用价值。

Result: 论证了AGI即使在最连贯的表述下仍是一个描述AI未来的有缺陷概念；SAI被定义为能够学习并超越人类完成任何重要事务，并能填补人类能力空白的智能形式。

Conclusion: AI发展应拥抱专业化而非追求通用性，在专业化中追求超人类性能；SAI框架有助于澄清被AGI过载定义模糊的AI讨论，并为未来AI发展提供更清晰的指导方向。

Abstract: Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.

</details>


### [67] [ODAR: Principled Adaptive Routing for LLM Reasoning via Active Inference](https://arxiv.org/abs/2602.23681)
*Siyuan Ma,Bo Gao,Xiaojun Jia,Simeng Qin,Tianlin Li,Ke Ma,Xiaoshuang Jia,Wenqi Ren,Yang Liu*

Main category: cs.AI

TL;DR: 提出ODAR-Expert自适应路由框架，通过难度估计和基于自由能的融合机制，在快慢智能体间动态分配计算资源，在保持高精度的同时降低82%的计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理方法依赖均匀暴力采样（如best-of-N、自洽性），存在成本高、难以归因、随着测试时计算扩展会出现收益递减的过度思考问题。

Method: ODAR-Expert采用基于摊销主动推理的难度估计器，动态路由查询至启发式快智能体和深思熟虑慢智能体，并引入基于自由能的融合机制，通过最小化变分自由能目标来平衡对数似然与认知不确定性。

Result: 在23个基准测试中表现优异，MATH达到98.2%准确率，HLE达到54.8%，在开源技术栈（Llama 4 + DeepSeek）上超越均匀采样策略，计算成本降低82%。

Conclusion: 最优推理扩展需要基于自由能的决策自适应资源分配，而非简单地增加测试时计算量。

Abstract: The paradigm of large language model (LLM) reasoning is shifting from parameter scaling to test-time compute scaling, yet many existing approaches still rely on uniform brute-force sampling (for example, fixed best-of-N or self-consistency) that is costly, hard to attribute, and can trigger overthinking with diminishing returns. We propose ODAR-Expert, an adaptive routing framework that optimizes the accuracy-efficiency trade-off via principled resource allocation. ODAR uses a difficulty estimator grounded in amortized active inference to dynamically route queries between a heuristic Fast Agent and a deliberative Slow Agent. We further introduce a free-energy-principled, risk-sensitive fusion mechanism that selects answers by minimizing a variational free energy objective, balancing log-likelihood with epistemic uncertainty (varentropy) as a principled alternative to ad hoc voting over heterogeneous candidates. Extensive evaluation across 23 benchmarks shows strong and consistent gains, including 98.2% accuracy on MATH and 54.8% on Humanity's Last Exam (HLE), while improving the compute-accuracy frontier under compute-matched settings. We also validate reproducibility on a fully open-source stack (Llama 4 + DeepSeek), where ODAR surpasses homogeneous sampling strategies while reducing computational costs by 82%. Overall, our results suggest that thinking-optimal scaling requires adaptive resource allocation with free-energy-based decision-making rather than simply increasing test-time compute.

</details>


### [68] [From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems](https://arxiv.org/abs/2602.23701)
*Yawen Wang,Wenjie Wu,Junjie Wang,Qing Wang*

Main category: cs.AI

TL;DR: 提出CHIEF框架，通过构建分层因果图、层级化引导回溯和反事实归因，解决LLM多智能体系统的故障根因定位问题，在Who&When基准测试上优于8种先进方法


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统(MAS)虽能力强但存在脆弱性和不透明故障机制。现有归因方法将执行日志视为线性序列，无法揭示MAS内在的复杂因果联系，导致可观测性弱、责任边界模糊，难以定位真实根因

Method: CHIEF框架采用三阶段方法：(1)将混沌轨迹转化为结构化分层因果图；(2)通过层级化oracle引导回溯，利用合成虚拟oracle高效剪枝搜索空间；(3)实施基于渐进因果筛选的反事实归因，严格区分根因与传播症状

Result: 在Who&When基准测试上，CHIEF在智能体级和步骤级准确率均超越8种强基线方法；消融研究证实每个模块的关键作用

Conclusion: CHIEF通过结构化因果建模和分层推理机制，显著提升了MAS故障归因的准确性和可解释性，为构建更健壮的多智能体系统提供了有效方案

Abstract: LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.

</details>


### [69] [ProductResearch: Training E-Commerce Deep Research Agents via Multi-Agent Synthetic Trajectory Distillation](https://arxiv.org/abs/2602.23716)
*Jiangyuan Wang,Kejun Xiao,Huaipeng Zhao,Tao Luo,Xiaoyi Zeng*

Main category: cs.AI

TL;DR: 提出ProductResearch多智能体框架，通过合成高质量工具使用轨迹训练电商购物智能体，使微调后的紧凑模型在响应全面性、研究深度和用户效用上接近前沿专有系统


<details>
  <summary>Details</summary>
Motivation: 现有LLM电商购物智能体缺乏复杂产品研究所需的交互深度和上下文广度，而Deep Research范式在迁移到电商领域时存在领域鸿沟

Method: 构建多智能体框架：User Agent从行为历史推断购物意图，Supervisor Agent协调Research Agent进行迭代协作生成合成轨迹，再通过反思内化过程将多智能体交互转化为单角色训练示例

Result: 在合成数据上微调的紧凑MoE模型在响应全面性、研究深度和用户感知效用方面显著优于基线模型，性能接近前沿专有深度研究系统

Conclusion: 多智能体合成轨迹训练是提升LLM购物助手能力的有效且可扩展范式

Abstract: Large Language Model (LLM)-based agents show promise for e-commerce conversational shopping, yet existing implementations lack the interaction depth and contextual breadth required for complex product research. Meanwhile, the Deep Research paradigm, despite advancing information synthesis in web search, suffers from domain gaps when transferred to e-commerce. We propose ProductResearch, a multi-agent framework that synthesizes high-fidelity, long-horizon tool-use trajectories for training robust e-commerce shopping agents. The framework employs a User Agent to infer nuanced shopping intents from behavioral histories, and a Supervisor Agent that orchestrates iterative collaboration with a Research Agent to generate synthetic trajectories culminating in comprehensive, insightful product research reports. These trajectories are rigorously filtered and distilled through a reflective internalization process that consolidates multi-agent supervisory interactions into coherent single-role training examples, enabling effective fine-tuning of LLM agents for complex shopping inquiries. Extensive experiments show that a compact MoE model fine-tuned on our synthetic data achieves substantial improvements over its base model in response comprehensiveness, research depth, and user-perceived utility, approaching the performance of frontier proprietary deep research systems and establishing multi-agent synthetic trajectory training as an effective and scalable paradigm for enhancing LLM-based shopping assistance.

</details>


### [70] [The Auton Agentic AI Framework](https://arxiv.org/abs/2602.23720)
*Sheng Cao,Zhao Chang,Chang Li,Hannan Li,Liyao Fu,Ji Tang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The field of Artificial Intelligence is undergoing a transition from Generative AI -- probabilistic generation of text and images -- to Agentic AI, in which autonomous systems execute actions within external environments on behalf of users. This transition exposes a fundamental architectural mismatch: Large Language Models (LLMs) produce stochastic, unstructured outputs, whereas the backend infrastructure they must control -- databases, APIs, cloud services -- requires deterministic, schema-conformant inputs. The present paper describes the Auton Agentic AI Framework, a principled architecture for standardizing the creation, execution, and governance of autonomous agent systems. The framework is organized around a strict separation between the Cognitive Blueprint, a declarative, language-agnostic specification of agent identity and capabilities, and the Runtime Engine, the platform-specific execution substrate that instantiates and runs the agent. This separation enables cross-language portability, formal auditability, and modular tool integration via the Model Context Protocol (MCP). The paper formalizes the agent execution model as an augmented Partially Observable Markov Decision Process (POMDP) with a latent reasoning space, introduces a hierarchical memory consolidation architecture inspired by biological episodic memory systems, defines a constraint manifold formalism for safety enforcement via policy projection rather than post-hoc filtering, presents a three-level self-evolution framework spanning in-context adaptation through reinforcement learning, and describes runtime optimizations -- including parallel graph execution, speculative inference, and dynamic context pruning -- that reduce end-to-end latency for multi-step agent workflows.

</details>


### [71] [Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off](https://arxiv.org/abs/2602.23730)
*Longyin Zhang,Shuo Sun,Yingxu He,Won Cheng Yi Lewis,Muhammad Huzaifah Bin Md Shahrin,Hardik Bhupendra Sailor,Heng Meng Jeremy Wong,Tarun Kumar Vangani,Yi Ma,Qiongqiong Wang,Minh Duc Pham,Ridong Jiang,Jingtao Li,Jingyi Liao,Zhuohan Liu,Yanfeng Lu,Manas Gupta,Ai Ti Aw*

Main category: cs.AI

TL;DR: 本文推出面向东南亚的10B参数多语言全知模型MERaLiON2-Omni (Alpha)，揭示推理能力虽能放大抽象任务性能，却会引发低层次感官处理不稳定性的效率-稳定性悖论。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在整合稳健感官接地与复杂推理方面存在挑战，尤其在资源不足的东南亚地区。本研究旨在开发适合该区域的10B参数多语言全知感知模型。

Method: 采用解耦与融合"系统1"感知和"系统2"推理的渐进式训练流程。先通过正交模态适配构建感知骨干，对齐区域音视频线索；再通过生成-评判-精炼管道，利用超级大模型合成高质量伪数据，实现文本链式推理向多模态迁移。

Result: 在SEA-Omni基准测试中发现效率-稳定性悖论：推理显著提升数学和指令遵循等抽象任务性能，但导致长音频时间漂移和视觉过度解读等低层次感知不稳定问题。

Conclusion: 报告详述了模型架构、数据高效训练方案，并对稳健感知与结构化推理间的权衡进行了诊断分析。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates "System 1" (Perception) and "System 2" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.
  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.

</details>


### [72] [Reasoning-Driven Multimodal LLM for Domain Generalization](https://arxiv.org/abs/2602.23777)
*Zhipeng Xu,Zilong Wang,Xinyang Jiang,Dongsheng Li,De Cheng,Nannan Wang*

Main category: cs.AI

TL;DR: 本文提出RD-MLDG框架，利用多模态大语言模型的推理能力解决领域泛化问题，通过多任务交叉训练和自对齐推理正则化实现更鲁棒的跨领域预测。


<details>
  <summary>Details</summary>
Motivation: 现有领域泛化方法主要关注视觉特征不变性，而忽略了多模态大语言模型的推理能力。本文探索利用推理链来提升模型在领域偏移下的鲁棒性，并系统研究推理在领域泛化中的作用。

Method: 提出RD-MLDG框架，包含两个组件：1) MTCT（多任务交叉训练），引入额外分类路径指导推理监督；2) SARR（自对齐推理正则化），通过迭代自标注在保持推理语义丰富性的同时缓解推理模式不匹配。在自建数据集DomainBed-Reasoning上进行系统研究。

Result: 在标准DomainBed数据集（PACS、VLCS、OfficeHome、TerraInc）上实现最优性能，验证了推理作为互补信号对领域外泛化的有效性。

Conclusion: 利用多模态大语言模型的推理能力是领域泛化的有前景的方向，推理链可以作为有效的监督信号提升模型鲁棒性。

Abstract: This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.

</details>


### [73] [EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2602.23802)
*Yiyang Fang,Wenke Huang,Pei Fu,Yihao Yang,Kehua Su,Zhenbo Luo,Jian Luan,Mang Ye*

Main category: cs.AI

TL;DR: 提出EMO-R3框架，通过结构化情感思考和反思性情感奖励提升多模态大语言模型的情感推理能力和可解释性


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在情感理解上存在局限，监督微调泛化性差且缺乏可解释性，强化学习方法不符合情感认知内在特征

Method: 提出反思性强化学习框架EMO-R3，包含结构化情感思考（指导逐步推理）和反思性情感奖励（基于视觉-文本一致性和情感一致性进行重评估）

Result: 显著提升MLLMs的可解释性和情感智能，在多个视觉情感理解基准测试中表现优异

Conclusion: EMO-R3框架有效增强了MLLMs的情感推理能力，为情感认知建模提供了新思路

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.

</details>


### [74] [RF-Agent: Automated Reward Function Design via Language Agent Tree Search](https://arxiv.org/abs/2602.23876)
*Ning Gao,Xiuhui Zhang,Xingyu Jiang,Mukang You,Mohan Zhang,Yue Deng*

Main category: cs.AI

TL;DR: 提出RF-Agent框架，利用大语言模型和蒙特卡洛树搜索优化低阶控制任务的奖励函数设计，在17项任务中验证有效


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型生成奖励函数的方法存在历史反馈利用率低、搜索效率差的问题，难以应对复杂控制任务

Method: 将大语言模型作为语言智能体，采用蒙特卡洛树搜索管理奖励函数设计与优化流程，利用大模型的多阶段上下文推理能力提升搜索效率

Result: 在17个多样化低阶控制任务中取得优异实验结果

Conclusion: 该方法通过改进历史信息利用和搜索策略，有效提升了复杂控制任务中奖励函数的设计效率

Abstract: Designing efficient reward functions for low-level control tasks is a challenging problem. Recent research aims to reduce reliance on expert experience by using Large Language Models (LLMs) with task information to generate dense reward functions. These methods typically rely on training results as feedback, iteratively generating new reward functions with greedy or evolutionary algorithms. However, they suffer from poor utilization of historical feedback and inefficient search, resulting in limited improvements in complex control tasks. To address this challenge, we propose RF-Agent, a framework that treats LLMs as language agents and frames reward function design as a sequential decision-making process, enhancing optimization through better contextual reasoning. RF-Agent integrates Monte Carlo Tree Search (MCTS) to manage the reward design and optimization process, leveraging the multi-stage contextual reasoning ability of LLMs. This approach better utilizes historical information and improves search efficiency to identify promising reward functions. Outstanding experimental results in 17 diverse low-level control tasks demonstrate the effectiveness of our method. The source code is available at https://github.com/deng-ai-lab/RF-Agent.

</details>


### [75] [Pessimistic Auxiliary Policy for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23974)
*Fan Zhang,Baoru Huang,Xin Zhang*

Main category: cs.AI

TL;DR: 针对离线强化学习中分布外动作导致的误差累积问题，本文提出一种悲观辅助策略，通过最大化Q函数的下置信界来采样可靠动作，有效提升离线RL性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习虽避免了实时交互的安全风险，但学习过程中不可避免地会访问分布外动作，引入近似误差并造成误差累积与过度估计，限制了学习效果。

Method: 构建悲观辅助策略，通过最大化Q函数的下置信界来选择动作。该策略在已学习策略附近表现出高值低不确定性的特点，避免采样高价值但潜在高误差的动作。

Result: 在多个离线强化学习基准测试上的广泛实验表明，采用该悲观辅助策略能显著提升其他离线RL方法的有效性。

Conclusion: 该方法通过减少近似误差和缓解误差累积问题，为提升离线强化学习性能提供了有效解决方案。

Abstract: Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.

</details>


### [76] [Portfolio Reinforcement Learning with Scenario-Context Rollout](https://arxiv.org/abs/2602.24037)
*Vanya Priscillia Bendatu,Yao Lu*

Main category: cs.AI

TL;DR: A macro-conditioned scenario rollout method with counterfactual state augmentation stabilizes RL for portfolio rebalancing, improving Sharpe ratio by up to 76% and reducing drawdown by up to 53%.


<details>
  <summary>Details</summary>
Motivation: Market regime shifts cause distribution shifts that degrade portfolio rebalancing performance, and incorporating scenario-based rewards from rollouts creates a reward-transition mismatch that destabilizes RL critic training.

Method: Propose macro-conditioned scenario-context rollout (SCR) to generate stress-event scenarios, analyze the reward-transition mismatch inconsistency, construct counterfactual next states using rollout-implied continuations, and augment critic bootstrap targets to stabilize learning.

Result: Out-of-sample testing across 31 U.S. equity/ETF portfolio universes shows up to 76% Sharpe ratio improvement and 53% maximum drawdown reduction compared to classic and RL-based baselines.

Conclusion: The counterfactual augmentation approach stabilizes RL training while providing an effective bias-variance tradeoff, delivering significant performance gains for portfolio rebalancing under market stress.

Abstract: Market regime shifts induce distribution shifts that can degrade the performance of portfolio rebalancing policies. We propose macro-conditioned scenario-context rollout (SCR) that generates plausible next-day multivariate return scenarios under stress events. However, doing so faces new challenges, as history will never tell what would have happened differently. As a result, incorporating scenario-based rewards from rollouts introduces a reward--transition mismatch in temporal-difference learning, destabilizing RL critic training.
  We analyze this inconsistency and show it leads to a mixed evaluation target. Guided by this analysis, we construct a counterfactual next state using the rollout-implied continuations and augment the critic agent's bootstrap target. Doing so stabilizes the learning and provides a viable bias-variance tradeoff.
  In out-of-sample evaluations across 31 distinct universes of U.S. equity and ETF portfolios, our method improves Sharpe ratio by up to 76% and reduces maximum drawdown by up to 53% compared with classic and RL-based portfolio rebalancing baselines.

</details>


### [77] [CIRCLE: A Framework for Evaluating AI from a Real-World Lens](https://arxiv.org/abs/2602.24055)
*Reva Schwartz,Carina Westling,Morgan Briggs,Marzieh Fadaee,Isar Nejadgholi,Matthew Holmes,Fariza Rashid,Maya Carlyle,Afaf Taïk,Kyra Wilson,Peter Douglas,Theodora Skeadas,Gabriella Waters,Rumman Chowdhury,Thiago Lacerda*

Main category: cs.AI

TL;DR: 本文提出CIRCLE框架，这是一个六阶段生命周期框架，通过整合现场测试、红队测试和纵向研究等方法，将利益相关者关注点转化为可测量信号，从而弥合模型中心性能指标与AI实际部署效果之间的差距，为治理提供可比较且符合本地语境的证据。


<details>
  <summary>Details</summary>
Motivation: 现有AI框架（如MLOps）关注系统稳定性，基准测试衡量抽象能力，但AI栈外的决策者缺乏关于AI在真实世界用户变化和约束下行为的系统性证据，需要结构化、前瞻性的协议将定性洞察与定量指标联系起来。

Method: CIRCLE是一个六阶段生命周期框架，通过将利益相关者关注点形式化转化为可测量信号，实施TEVV（测试、评估、验证和确认）的验证阶段。它整合了现场测试、红队测试和纵向研究方法，形成协调一致的流程。

Result: 该框架产生系统性知识，其证据在不同部署地点间具有可比性，同时对本地语境保持敏感，使治理能够基于实际下游影响而非理论能力进行决策。

Conclusion: CIRCLE提供了结构化、前瞻性的协议，可弥合模型中心指标与实际部署结果之间的鸿沟，从而支持基于AI在真实世界中实际影响的治理方式。

Abstract: This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.

</details>


### [78] [Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction](https://arxiv.org/abs/2602.24080)
*Xiang Li,Jiabao Gao,Sipei Lin,Xuan Zhou,Chi Zhang,Bo Cheng,Jiale Han,Benyou Wang*

Main category: cs.AI

TL;DR: 该研究首次对语音到语音(S2S)系统进行了图灵测试，发现现有系统均未通过测试，主要差距在于副语言特征、情感表达和对话个性，而非语义理解。研究还提出了可解释的自动评估模型。


<details>
  <summary>Details</summary>
Motivation: 现代语音到语音系统能否像人类一样对话仍是未解之谜。传统图灵测试为评估人机对话相似性提供了框架，但此前尚未有针对S2S系统的系统性测试。

Method: 收集2,968条人类对9个先进S2S系统和28名人类参与者对话的评判；建立包含18个维度的细粒度人类相似性分类体系并进行众包标注；开发可解释模型用于自动评估。

Result: 1) 所有被评估的S2S系统均未通过图灵测试；2) 瓶颈在于副语言特征、情感表达和对话个性，而非语义理解；3) 现有AI模型作为评判者不可靠；4) 新模型能准确区分人机对话。

Conclusion: 建立了首个S2S系统人类相似性评估基准，超越了二元结果提供诊断性洞察，为开发类人对话AI系统指明改进方向。

Abstract: The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.

</details>


### [79] [Bi-level RL-Heuristic Optimization for Real-world Winter Road Maintenance](https://arxiv.org/abs/2602.24097)
*Yue Xie,Zizhen Xu,William Beazley,Fumiya Iida*

Main category: cs.AI

TL;DR: 提出了一种结合强化学习和多目标车辆路径问题的双层优化框架，用于大规模冬季道路维护路线规划，在英国真实路网数据上验证可实现负载均衡、降低碳排放和成本节约。


<details>
  <summary>Details</summary>
Motivation: 现有冬季道路维护方法难以有效处理大规模路径规划问题且过度依赖人工决策，无法兼顾公共安全和环境影响的平衡。

Method: 上层采用强化学习智能体对路网进行分区与多仓库资源分配；下层在每个集群内求解多目标车辆路径问题，同时最小化最大车辆行驶时间和总碳排放量，并纳入车辆约束、仓库容量和路段需求。

Result: 在M25、M6、A1等英国战略路网验证显示：工作负载显著均衡，最大行驶时间降至2小时阈值以下，碳排放降低，并实现可观成本节约。

Conclusion: 该AI驱动的双层优化框架为实际交通物流运营决策提供了高效解决方案，展示了先进优化技术在真实场景中的应用价值。

Abstract: Winter road maintenance is critical for ensuring public safety and reducing environmental impacts, yet existing methods struggle to manage large-scale routing problems effectively and mostly reply on human decision. This study presents a novel, scalable bi-level optimization framework, validated on real operational data on UK strategic road networks (M25, M6, A1), including interconnected local road networks in surrounding areas for vehicle traversing, as part of the highway operator's efforts to solve existing planning challenges. At the upper level, a reinforcement learning (RL) agent strategically partitions the road network into manageable clusters and optimally allocates resources from multiple depots. At the lower level, a multi-objective vehicle routing problem (VRP) is solved within each cluster, minimizing the maximum vehicle travel time and total carbon emissions. Unlike existing approaches, our method handles large-scale, real-world networks efficiently, explicitly incorporating vehicle-specific constraints, depot capacities, and road segment requirements. Results demonstrate significant improvements, including balanced workloads, reduced maximum travel times below the targeted two-hour threshold, lower emissions, and substantial cost savings. This study illustrates how advanced AI-driven bi-level optimization can directly enhance operational decision-making in real-world transportation and logistics.

</details>


### [80] [Artificial Agency Program: Curiosity, compression, and communication in agents](https://arxiv.org/abs/2602.24100)
*Richard Csaky*

Main category: cs.AI

TL;DR: 本文提出人工智能体计划（AAP），主张将AI构建为嵌入现实、资源受限的智能体，其发展由好奇心驱动的学习进展决定。核心论点是AI作为人机工具系统的延伸最有用，能增强感知、理解与执行能力并减少交互摩擦。该计划将预测压缩、内在动机、授权控制、接口质量及语言/自我沟通统一为选择性信息瓶颈，通过可证伪程序、明确成本、分阶段实验和多模态标记化测试床进行验证，旨在建立连接内在动机、信息论、热力学、有限理性与现代推理系统的概念与实验框架。


<details>
  <summary>Details</summary>
Motivation: 现有AI研究缺乏对物理与计算约束下嵌入式智能体的统一考量，且未能充分将其定位为人机协作系统的延伸。本研究旨在通过构建资源受限、好奇心驱动的智能体，最大化AI作为人类认知与行动延伸的效用，减少人与工具及环境间的交互摩擦，提升整体系统的感知、理解和执行能力。

Method: 提出可证伪的研究计划，将预测压缩、内在动机、授权控制、接口质量、语言/自我沟通等概念统一建模为选择性信息瓶颈；设定明确成本函数；规划分阶段实验；开发多模态标记化测试环境，其中智能体需在观察、行动与 deliberation 间分配有限预算。

Result: 提出了AAP的完整研究议程，包括核心理论框架、统一的概念模型、可证伪的研究计划、分阶段实验方案以及具体的多模态测试床设计，为连接内在动机、信息论、热力学、有限理性与现代推理系统提供了系统性的概念与实验蓝图。

Conclusion: 该研究计划通过整合多个AI核心概念并提供可验证的框架，为开发更实用、高效的嵌入式AI智能体指明了方向，有望推动AI从孤立系统向人类认知与行动的延伸工具转变，建立跨学科的理论基础。

Abstract: This paper presents the Artificial Agency Program (AAP), a position and research agenda for building AI systems as reality embedded, resource-bounded agents whose development is driven by curiosity-as-learning-progress under physical and computational constraints. The central thesis is that AI is most useful when treated as part of an extended human--tool system that increases sensing, understanding, and actuation capability while reducing friction at the interface between people, tools, and environments. The agenda unifies predictive compression, intrinsic motivation, empowerment and control, interface quality (unification), and language/self-communication as selective information bottlenecks. We formulate these ideas as a falsifiable program with explicit costs, staged experiments, and a concrete multimodal tokenized testbed in which an agent allocates limited budget among observation, action, and deliberation. The aim is to provide a conceptual and experimental framework that connects intrinsic motivation, information theory, thermodynamics, bounded rationality, and modern reasoning systems

</details>


### [81] [Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance](https://arxiv.org/abs/2602.24110)
*Yanwei Ren,Haotian Zhang,Likang Xiao,Xikai Zhang,Jiaxing Huang,Jiayan Qiu,Baosheng Yu,Quan Chen,Liu Liu*

Main category: cs.AI

TL;DR: 针对RLVR中结果监督对"基本正确但有小错"轨迹惩罚过重导致探索空间过早缩小的问题，提出SCOPE框架，利用过程奖励模型定位首个错误步骤并逐步修正，挽救部分正确轨迹，多样性提升13.5%，在数学推理和分布外泛化上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 标准结果监督将基本正确但存在少数错误的轨迹与完全错误轨迹同等重罚，导致模型丢弃大量有价值的部分正确轨迹，造成探索多样性严重下降并过早缩小搜索空间。现有方法简单集成过程奖励无效，或采用离策略整条轨迹替换但超出策略分布且未利用模型自身生成的部分正确轨迹。

Method: 提出SCOPE（Step-wise Correction for On-Policy Exploration）框架：利用过程奖励模型精准识别次优轨迹中的首个错误步骤，然后对该步骤进行细粒度的离策略修正，生成修正后轨迹并保留至训练集，从而有效挽救部分正确轨迹并保持广泛探索空间。

Result: 多样性分数提升13.5%；在数学推理任务上实现46.6%的平均准确率（新SOTA）；在分布外推理任务上展现强大泛化能力，达到53.4%准确率。

Conclusion: SCOPE通过细粒度的步骤级修正有效缓解了探索空间过早缩小问题，显著提升了大型推理模型的复杂推理能力和泛化性能，为RLVR训练提供了更高效的范式。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.

</details>


### [82] [LemmaBench: A Live, Research-Level Benchmark to Evaluate LLM Capabilities in Mathematics](https://arxiv.org/abs/2602.24173)
*Antoine Peyronnet,Fabian Gloeckle,Amaury Hayat*

Main category: cs.AI

TL;DR: 提出一种基于arXiv最新数学研究论文的动态基准测试方法，用于评估大语言模型在真实研究级数学任务中的定理证明能力，当前模型准确率仅10-15%


<details>
  <summary>Details</summary>
Motivation: 现有数学基准测试依赖静态的竞赛/教科书题目，无法反映真实研究场景；需要建立能随数学研究进展持续更新的评估体系

Method: 开发自动流水线从arXiv提取数学引理，重写为包含所有显式假设和定义的独立命题，实现基准测试的持续更新与训练/评估数据隔离

Result: 当前SOTA大语言模型在定理证明任务中准确率仅10-15%（pass@1），与人类研究级证明能力存在显著差距

Conclusion: 新基准更真实反映LLM在数学研究中的实际水平，显示其距人类级研究能力仍有巨大提升空间

Abstract: We present a new approach for benchmarking Large Language Model (LLM) capabilities on research-level mathematics. Existing benchmarks largely rely on static, hand-curated sets of contest or textbook-style problems as proxies for mathematical research. Instead, we establish an updatable benchmark evaluating models directly on the latest research results in mathematics. This consists of an automatic pipeline that extracts lemmas from arXiv and rewrites them into self-contained statements by making all assumptions and required definitions explicit. It results in a benchmark that can be updated regularly with new problems taken directly from human mathematical research, while previous instances can be used for training without compromising future evaluations. We benchmark current state-of-the-art LLMs, which obtain around 10-15$\%$ accuracy in theorem proving (pass@1) depending on the model, showing that there is currently a large margin of progression for LLMs to reach human-level proving capabilities in a research context.

</details>


### [83] [Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume](https://arxiv.org/abs/2602.24195)
*Gregory Kang Ruey Lau,Hieu Dao,Nicole Kan Hui Lin,Bryan Kian Hsiang Low*

Main category: cs.AI

TL;DR: UMPIRE是一个无需训练的多模态大语言模型不确定性量化框架，仅利用模型内部特征计算采样响应的不连贯调整语义体积，在各类任务和模态上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型能力强大，但其可能产生看似合理却错误的输出，阻碍可靠部署。现有不确定性量化方法存在局限：仅适用于特定模态、依赖外部工具或计算成本高昂。

Method: 作者提出UMPIRE框架，通过计算给定任务实例的采样MLLM响应的不连贯调整语义体积，仅利用模型内部模态特征来捕获采样结果的全局语义多样性和基于模型置信度的局部不连贯性。

Result: 大量实验表明，UMPIRE在图像、音频和视频文本基准测试的错误检测和不确定性校准方面持续优于基线指标，包括对抗性和分布外场景。该框架还成功推广到图像和音频生成等非文本输出任务。

Conclusion: UMPIRE为MLLMs的不确定性量化提供了一种高效、无需训练的解决方案，无需外部依赖即可跨多种模态和任务工作，提升了模型部署的可靠性。

Abstract: Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.

</details>


### [84] [A Minimal Agent for Automated Theorem Proving](https://arxiv.org/abs/2602.24273)
*Borja Requena Pozo,Austin Letson,Krystian Nowakowski,Izan Beltran Ferreiro,Leopoldo Sarra*

Main category: cs.AI

TL;DR: 提出了一个最小化的AI定理证明智能体基线，通过实现核心功能（迭代证明优化、库搜索和上下文管理），在保持简单架构的同时达到与顶尖系统相当的竞争性能，并证明了迭代方法在样本效率和成本效益上的优势。


<details>
  <summary>Details</summary>
Motivation: 为了在不同AI定理证明器架构之间实现系统性比较，需要建立一个最小化的基准系统来评估和对比各种设计选择。

Method: 设计实现了一个包含三大核心功能的基线系统：迭代证明优化、库搜索和上下文管理，并对不同模型和设计方案进行了比较评估。

Result: 在定性不同的基准测试中表现具有竞争力，虽然架构更简单但性能接近顶尖方法；证明了迭代方法相比单次生成在样本效率和成本效益上具有一致性优势。

Conclusion: 开源发布实现作为未来研究的候选参考基准和社区可访问的证明器，为AI定理证明领域提供标准化评估工具。

Abstract: We propose a minimal agentic baseline that enables systematic comparison across different AI-based theorem prover architectures. This design implements the core features shared among state-of-the-art systems: iterative proof refinement, library search and context management. We evaluate our baseline using qualitatively different benchmarks and compare various popular models and design choices, and demonstrate competitive performance compared to state-of-the-art approaches, while using a significantly simpler architecture. Our results demonstrate consistent advantages of an iterative approach over multiple single-shot generations, especially in terms of sample efficiency and cost effectiveness. The implementation is released open-source as a candidate reference for future research and as an accessible prover for the community.

</details>


### [85] [DARE-bench: Evaluating Modeling and Instruction Fidelity of LLMs in Data Science](https://arxiv.org/abs/2602.24288)
*Fan Shu,Yite Wang,Ruofan Wu,Boyi Liu,Zhewei Yao,Yuxiong He,Feng Yan*

Main category: cs.AI

TL;DR: DARE-bench是一个面向数据科学指令遵循的新基准，通过6,300个Kaggle任务提供可验证ground truth，解决了现有基准缺乏过程感知评估和训练数据稀缺的问题，实验显示该基准既能有效评估模型（即使是gpt-o4-mini也表现不佳），又能作为关键训练数据使模型性能获得高达8倍的提升。


<details>
  <summary>Details</summary>
Motivation: LLM处理复杂多步数据科学任务的需求快速增长，但现有基准存在两大缺陷：(i)缺乏标准化的过程感知评估，无法准确衡量指令遵循和过程保真度；(ii)准确标记的训练数据稀缺。

Method: 提出DARE-bench基准，专为机器学习建模和数据科学指令遵循设计。所有任务均具有可验证的ground truth，确保客观可重复的评估。基准包含6,300个Kaggle衍生任务，同时提供大规模训练数据和评估集。

Result: 广泛评估显示，即使gpt-o4-mini等高能力模型在机器学习建模任务上也表现不佳。使用DARE-bench训练任务进行微调可显著提升性能：监督微调使Qwen3-32B准确率提升1.83倍，强化学习使Qwen3-4B准确率提升超过8倍。

Conclusion: 这些显著改进验证了DARE-bench作为准确评估基准和重要训练数据的关键价值，填补了现有基准的空白。

Abstract: The fast-growing demands in using Large Language Models (LLMs) to tackle complex multi-step data science tasks create an emergent need for accurate benchmarking. There are two major gaps in existing benchmarks: (i) the lack of standardized, process-aware evaluation that captures instruction adherence and process fidelity, and (ii) the scarcity of accurately labeled training data. To bridge these gaps, we introduce DARE-bench, a benchmark designed for machine learning modeling and data science instruction following. Unlike many existing benchmarks that rely on human- or model-based judges, all tasks in DARE-bench have verifiable ground truth, ensuring objective and reproducible evaluation. To cover a broad range of tasks and support agentic tools, DARE-bench consists of 6,300 Kaggle-derived tasks and provides both large-scale training data and evaluation sets. Extensive evaluations show that even highly capable models such as gpt-o4-mini struggle to achieve good performance, especially in machine learning modeling tasks. Using DARE-bench training tasks for fine-tuning can substantially improve model performance. For example, supervised fine-tuning boosts Qwen3-32B's accuracy by 1.83x and reinforcement learning boosts Qwen3-4B's accuracy by more than 8x. These significant improvements verify the importance of DARE-bench both as an accurate evaluation benchmark and critical training data.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [86] [From QED$_3$ to Self-Dual Multicriticality in the Fradkin-Shenker Model](https://arxiv.org/abs/2602.23420)
*Thomas T. Dumitrescu,Pierluigi Niro,Ryan Thorngren*

Main category: cond-mat.str-el

TL;DR: This paper studies a staggered generalization of the Fradkin-Shenker Z₂ gauge-Higgs model in 2+1 dimensions, introducing global U(1) symmetries for electric and magnetic charges. It proposes a continuum field theory (Higgs-Yukawa-QED₃) and establishes a duality to the easy-plane CP¹ model, revealing a multicritical conformal field theory (CFT) with O(2)ₑ × O(2)ₘ symmetry that describes deconfined quantum critical points in antiferromagnets.


<details>
  <summary>Details</summary>
Motivation: To generalize the original Fradkin-Shenker model (toric code with in-plane magnetic field) by incorporating continuous U(1) symmetries for electric/magnetic particles, enabling a richer phase diagram and connections to continuum field theories. This aims to bridge lattice gauge models with deconfined quantum critical phenomena in condensed matter systems, particularly spin-1/2 antiferromagnets.

Method: 1. Introduces a staggered lattice model with explicit U(1)ₑ and U(1)ₘ global symmetries.  
2. Proposes Higgs-Yukawa-QED₃ (QED₃ with N_f=2 Dirac fermions and a charge-2 Higgs field with Yukawa couplings) as the continuum description.  
3. Uses large-N_f expansion to compute operator scaling dimensions.  
4. Deforms the staggered model to recover the original Fradkin-Shenker model via monopole operators.  
5. Constructs a duality between Higgs-Yukawa-QED₃ and the easy-plane CP¹ model (scalar QED₃ with a potential).

Result: 1. Identifies a multicritical CFT with emergent (O(2)ₑ × O(2)ₘ) ⋊ Z₂ᴰ symmetry in the staggered model.  
2. Confirms scaling dimensions from large-N_f expansion match emergent symmetry selection rules.  
3. Shows deformation to Fradkin-Shenker model via monopoles reproduces its full phase diagram.  
4. Proposes duality revealing a first-order Néel-VBS transition line ending at a deconfined quantum multicritical point (same CFT as staggered model), separating these phases from a Z₂ spin liquid.

Conclusion: The staggered generalization successfully links discrete gauge models to continuum QFTs with continuous symmetries, providing a unified framework for multicritical phenomena. The duality to CP¹ model offers new insights into deconfined quantum criticality in antiferromagnets, confirming the universality of the O(2)ₑ × O(2)ₘ CFT across different physical systems.

Abstract: We consider the Fradkin-Shenker ${\mathbb Z}_2$ gauge-Higgs lattice model in 2+1 dimensions, i.e. the toric code deformed by an in-plane magnetic field. Its phase diagram contains a multicritical CFT with gapless, mutually non-local electric and magnetic particles, exchanged by a ${\mathbb Z}_2^{\mathsf{D}}$ self-duality symmetry. We introduce a staggered generalization of the model in which these particles carry global $U(1)_e$ and $U(1)_m$ charges, respectively, and we propose a continuum QFT description in terms of QED$_3$ with $N_f = 2$ Dirac fermion flavors and a charge-two Higgs field with Yukawa couplings. The conjectured phase diagram harbors a multicritical CFT with $(O(2)_e \times O(2)_m)\rtimes\mathbb{Z}_2^\mathsf{D}$ symmetry, some of which is emergent in the QFT description. We compute the scaling dimensions of some operators using a large-$N_f$ expansion and find agreement with the emergent selection rules. The staggered model admits a deformation to the original Fradkin-Shenker model, which maps to unit-charge monopole operators in Higgs-Yukawa-QED$_3$ that break the $U(1)_e \times U(1)_m$ symmetry. We show explicitly that this deformation reproduces all features of the Fradkin-Shenker phase diagram. Finally, we propose a multicritical duality between Higgs-Yukawa-QED$_3$ and the easy-plane $\mathbb{ CP}^1$ model (i.e. two-flavor scalar QED$_3$ with a suitable potential), which describes spin-1/2 anti-ferromagnets on a square lattice. This duality implies a first-order line of Néel-VBS transitions ending in a deconfined quantum multicritical point, described by the same $O(2)_e \times O(2)_m$ symmetric CFT that arises in the staggered Fradkin-Shenker model, which separates it from a gapped ${\mathbb Z}_2$ spin liquid phase.

</details>


### [87] [Signatures of Green's function zeros and their topology using impurity spectroscopy](https://arxiv.org/abs/2602.23477)
*Sayan Mitra,Fang Xie,Marek Kolmer,Qimiao Si,Chandan Setty*

Main category: cond-mat.str-el

TL;DR: 该研究通过精确对角化一维Hubbard模型，发现格林函数零点在幺正散射 regime 中表现为可观测的"zeron"激发态，其谱权重随塞曼场增强而消失，为实验探测拓扑结构提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 在非相互作用体系中拓扑结构由能带表征，但Mott绝缘体中的拓扑性质由格林函数零点编码，而实验上直接探测这些零点存在巨大挑战。

Method: 采用精确对角化方法研究含杂质和塞曼场的一维Hubard模型，结合解析分析，将杂质问题映射到掺杂Mott绝缘体体系。

Result: 在幺正散射极限下，格林函数零点表现为隙间谱权重（称为"zeron"激发）：吸引势对应局域双占据态，排斥势对应空穴态；该态在临界塞曼场以上消失。

Conclusion: 格林函数零点可能已在实验中被观测到，通过调控杂质和磁场可操纵其拓扑结构，为研究Mott绝缘体拓扑性质提供了可行实验方案。

Abstract: Topology without quasiparticles has emerged as a key framework for understanding Mott insulators, where Green's-function zeros encode nontrivial topological structure. Yet, experimental detection of these zeros represents a challenge. Using exact diagonalization of the one-dimensional Hubbard model with an impurity and Zeeman field, supported by exact analytic results, we show that Green's-function zeros manifest as an in-gap spectral weight in the unitary scattering regime. In this limit, we map the impurity problem onto a doped Mott insulator and identify the resulting in-gap state as a "zeron" excitation which is a localized doublon (holon) for an attractive (repulsive) potential. The zeron spectral weight and its associated zero vanish above a critical Zeeman field. Our results imply that Green's function zeros have in fact already been observed in experiments, and establish impurity and magnetic-field tuning as practical tools for controlling their topology.

</details>


### [88] [Nonequilibrium topological response under charge dephasing](https://arxiv.org/abs/2602.23484)
*Shuangyuan Lu,Lucas Q Silveira,Yizhi You*

Main category: cond-mat.str-el

TL;DR: 该论文研究了开放量子系统中对称保护拓扑态在退相干作用下的非平衡拓扑响应，发现局域退相位会引发强对称性到弱对称性的自发破缺，并证明该机制适用于更广泛的对称性类型。


<details>
  <summary>Details</summary>
Motivation: 探索开放量子系统（受退相干影响）中对称保护拓扑态的非平衡拓扑响应特性，特别是超越传统平衡态线性响应的内在响应机制。

Method: 针对由乘积对称性G×S保护的拓扑波函数，分析S电荷密度的局域退相位如何导致混合态系综中的强-弱对称性自发破缺（SWSSB），并将机制推广至高形式对称性、空间调制对称性及无能隙拓扑态。

Result: 证实局域退相位会普遍诱导G对称性的强-弱对称性自发破缺；该机制不仅限于传统有隙0-form对称性体系，还适用于高形式对称性、空间调制对称性及无能隙对称保护拓扑态。

Conclusion: 提出了基于量子通道定义的对称保护拓扑序的定性指纹，该指纹内生于开放系统动力学，超越了平衡态线性响应理论，为实验检测拓扑序提供了新视角。

Abstract: We explore nonequilibrium topological responses of symmetry-protected topological (SPT) states in open quantum systems subject to decoherence. For SPT wavefunctions protected by a product symmetry G $\times$ S , where G defects are decorated with S charge, we show that local dephasing of the S charge density generically induces spontaneous strong-to-weak symmetry breaking (SWSSB) of G in the resulting mixed-state ensemble. We extend this mechanism to SPT phases protected by higher-form and spatially modulated symmetries, and further to gapless SPT states, demonstrating that dephasing-induced SWSSB persists well beyond conventional gapped 0-form settings. Our results provide a qualitative, channel-defined fingerprint of SPT order that is intrinsic to open-system dynamics and goes beyond equilibrium linear response.

</details>


### [89] [Spontaneous altermagnetism in multi-orbital correlated electron systems](https://arxiv.org/abs/2602.23522)
*Nitin Kaushal,Adarsh S. Patri,Marcel Franz*

Main category: cond-mat.str-el

TL;DR: 提出三轨道系统可实现自发反铁磁莫特绝缘体，通过规避古德里奇-金森规则，首次揭示手性分裂磁振子及磁场诱导的轨道-磁振子混合模式


<details>
  <summary>Details</summary>
Motivation: 现有两轨道模型中自发反铁磁态违背古德里奇-金森(GK)规则，需寻找更合理的强关联体系实现该拓扑磁态

Method: 采用无偏平均场和密度矩阵重正化群计算，分析二维t₂g²电子系统，突破传统GK规则限制

Result: 1) 证实三轨道系统可稳定形成反铁磁莫特绝缘体 2) 首次发现手性分裂磁振子及其自旋电导特征 3) 预测弱磁场下产生非零轨道极化的杂化手性磁振子-轨道子模式

Conclusion: 为强关联体系中的反铁磁拓扑态提供新实现路径，预言的可观测轨道输运效应将推动多铁性器件与轨道电子学研究

Abstract: Altermagnets have attracted considerable attention in recent years owing to their potential technological applications in spintronics and magnonics. Recently, a new class of spontaneous altermagnets has been theoretically predicted in a correlated two orbital model, driven by the coexistence of antiferromagnetic spin and staggered orbital ordering, thus broadening the scope of altermagnetic phenomena to systems with strong correlations. It has been noted, however, that the required spin and orbital order violates the well-established Goodenough-Kanamori (GK) rules, which underlie much of our understanding of magnetism in complex systems. Here we show that materials with three active orbitals may offer a more realistic route to this exotic state. Specifically, we consider a two-dimensional system with $t_{2g}^{2}$ electrons and identify a novel microscopic mechanism that allows the formation of a spontaneous altermagnetic Mott insulator. We explain how the GK rules are circumvented and provide the stability criteria by employing unbiased mean-field and density matrix renormalization group calculations. In addition, for the first time, we uncover the presence and microscopic origin of chirally split magnons in these spontaneous altermagnets, with experimentally measurable spin conductivities. Finally, we predict that the application of a small in-plane magnetic field induces, in the presence of weak atomic spin-orbit coupling, an as-yet unreported hybrid chiral magnon-orbiton mode with a non-zero orbital polarization giving rise to finite longitudinal and transverse orbital conductivities under a thermal gradient.

</details>


### [90] [Generic Long-Range Order-Parameter Correlations in Metallic Quantum Magnets](https://arxiv.org/abs/2602.23554)
*T. R. Kirkpatrick,D. Belitz*

Main category: cond-mat.str-el

TL;DR: 该论文揭示所有金属磁体中序参量与电子的耦合在零温下产生长程磁化率，并系统研究了其对磁量子相变的影响：在多数三维均匀磁体、磁向列相和交错磁体中，相变从二级变为一级；在非中心对称铁磁体中，仅在二维体系改变相变级数；在具有大有序波矢的螺旋磁体、自旋波体系和奈尔反铁磁体中效应较弱且不改变相变级数；存在淬火无序时相变保持二级但临界行为被修正。


<details>
  <summary>Details</summary>
Motivation: 探究序参量与导电电子的耦合是否以及如何影响各类金属磁体的量子相变性质。

Method: 基于非磁相单粒子激发及其对共轭外场的响应进行理论分析，并结合重正化群方法。

Result: 发现长程序参量磁化率的普适存在；建立了不同磁体类型中相变级数改变的分类规律；确定了维度、对称性和有序波矢对相变行为的关键影响；揭示了无序体系中临界行为的修正。

Conclusion: 序参量-电子耦合是影响金属磁体量子相变的关键因素，其效应具有普适性但具体表现高度依赖于体系的结构和对称性特征，为理解复杂磁体的相变行为提供了统一的理论框架。

Abstract: It is shown that in all types of metallic magnets the coupling of the order parameter to the conduction electrons leads to an order-parameter susceptibility that is long-ranged at zero temperature. This is true for all known classes of ferromagnets, and also for antiferromagnets and spin-density wave systems, helimagnets, magnetic nematics, and altermagnets. The consequences for the magnetic quantum phase transition vary between different classes of magnets. In almost all 3-d systems with a homogeneous magnetization, as well as in magnetic nematics and in altermagnets, the long-ranged correlations generically modify the nature of the magnetic quantum phase transition from second order to first order. The only exception are non-centrosymmetric ferromagnets with a strong spin-orbit interaction, where the correlations change the order of the transition in 2-d systems, but not in 3-d ones. In helimagnets, spin-wave systems, and N{é}el antiferromagnets their effect is even weaker and does not change the order of the transition if the ordering wave number is sufficiently large. In systems with quenched disorder the transition generically is of second order, but the correlations modify the critical behavior. These conclusions are reached by very simple considerations that are based entirely on the single-particle excitations in the nonmagnetic phase and their modifications by a field conjugate to the order parameter, augmented by renormalization-group considerations.

</details>


### [91] [Second-quantized approach to the study of Halperin state in fractional quantum Hall effect](https://arxiv.org/abs/2602.23600)
*Li Chen,Zhiping Yao*

Main category: cond-mat.str-el

TL;DR: 提出一种针对二次量子化费米（玻色）Halperin态的递推关系，避免对其双分量一次量子化父哈密顿量进行精确对角化，并通过证明该递推定义的状态是父哈密顿量的零模且具有正确填充因子来验证公式。


<details>
  <summary>Details</summary>
Motivation: 解决传统精确对角化方法在处理双分量一次量子化父哈密顿量时计算复杂度高的问题，寻求更高效的数学描述方式。

Method: 构建二次量子化框架下的递推关系，通过递归方式生成Halperin态，绕开直接对角化父哈密顿量。

Result: 验证了递推定义的Halperin态是父哈密顿量的零模（能量本征值为零），并确认其满足理论预期的填充因子。

Conclusion: 所提递推公式有效规避了精确对角化的计算瓶颈，为Halperin态的解析研究提供了新途径，同时保持了物理特性的准确性。

Abstract: We give a recursion relation for the second-quantized fermionic (bosonic) Halperin state, which avoids exact diagonalization of its two-component first-quantized parent Hamiltonian. We validate this formula by proving that the second-quantized Halperin state, as recursively defined in this formula, is indeed a zero mode of the corresponding second-quantized parent Hamiltonian and that it has the correct filling factor.

</details>


### [92] [Phonon-Assisted Photoluminescence and Ultrafast Exciton Dynamics in Two-Dimensional Silicon Carbide](https://arxiv.org/abs/2602.23925)
*Afreen Anamul Haque,Rishabh Saraswat,Aniket Singha,Rekha Verma,Sitangshu Bhattacharya*

Main category: cond-mat.str-el

TL;DR: 该研究通过第一性原理计算揭示单层六方碳化硅（h-SiC）具有显著声子辅助发光边带，其超快激子动力学（10K下亮激子寿命仅300飞秒）源于对称性允许的光学声子耦合，为宽禁带二维半导体提供了定量理论框架


<details>
  <summary>Details</summary>
Motivation: 探究低维半导体中激子-声子相互作用机制，突破传统光谱技术对声子辅助发光边带微观起源的认知局限，为二维宽禁带材料的光电应用提供理论基础

Method: 采用全 ab initio 多体微扰理论结合有限动量 Bethe-Salpeter 方程，显式解析激子-声子矩阵元，对比分析 h-SiC 与 h-BN 的声子辅助发射动力学

Result: 1) 高能量 TO/LO 光学声子是边带形成主导因素；2) h-SiC 虽激子-声子能隙更小、声子复制峰更少，但边带强度与 h-BN 相当；3) K-K 亮激子主导近紫外零声子发射，谷间激子通过对称性允许的光学声子耦合获得辐射特性；4) 10K 时亮激子寿命仅 300 飞秒

Conclusion: 单层 h-SiC 是对称性激活的高效无应变声子辅助发光平台，建立的定量框架为超快激子动力学研究提供新方法，推动宽禁带二维半导体在光电器件中的应用

Abstract: Phonon assisted photoluminescence provides a direct window into exciton phonon interactions in low dimensional semiconductors. Using fully ab initio many body perturbation theory, including finite momentum Bethe Salpeter calculations, we investigate phonon assisted emission and exciton dynamics in two dimensional hexagonal silicon carbide and benchmark its response against 2D hexagonal boron nitride. By explicitly resolving exciton phonon matrix elements, we identify high energy optical TO LO phonons as the dominant contributors to sideband formation and quantify their spectral weights. h SiC exhibits pronounced phonon assisted sidebands comparable to h BN, despite a smaller exciton phonon energy separation and fewer resolved replicas. The bright K K exciton governs near UV zero phonon emission, while intervalley excitons acquire radiative character through symmetry allowed optical-phonon coupling. Temperature dependent scattering rates reveal an ultrashort bright exciton lifetime of approximately 300 fs at 10 K, highlighting rapid exciton relaxation driven by intrinsic phonon channels. These results establish monolayer SiC as a symmetry-activated platform for efficient, strain-free phonon-assisted emission and provide a quantitative framework for ultrafast exciton dynamics in wide bandgap 2D semiconductors.

</details>


### [93] [Quantum spin models of commensurate $p$-wave magnets](https://arxiv.org/abs/2602.23986)
*GiBaik Sim,Stephan Rachel*

Main category: cond-mat.str-el

TL;DR: 本研究通过构建微观相互作用模型，揭示了p波磁体的稳定机制：量子涨落使其从经典简并态中成为独特基态，并证实其具备自旋电子学应用潜力。


<details>
  <summary>Details</summary>
Motivation: p波磁体作为新型磁性相，虽在自旋电子学中潜力显著，但其稳定机制的理论理解仍不充分，限制了应用探索。

Method: 引入哈伯德模型并推导低能有效自旋哈密顿量，通过经典与量子层面分析，探究p波磁体的基态稳定机制。

Result: 经典层面p波磁体与其他非共线态能量简并，量子涨落解除简并并使其成为唯一基态；同时观察到埃德斯坦效应导致的自旋积累。

Conclusion: 首次从微观模型证实自发p波磁性的存在，理论框架可解释Ni₂Mo₃O₈等准二维蜂窝晶格磁体，为新型自旋电子器件设计提供基础。

Abstract: The $p$-wave magnet has emerged as a new type of magnetism exhibiting odd-parity, time-reversal-symmetric spin splitting in momentum space, and has attracted considerable interest as a promising platform for spintronic applications. However, the theoretical understanding of the fundamental mechanism responsible for stabilizing this phase remains limited. In this work, we identify a microscopic interacting model that realizes the $p$-wave magnet as its ground state. We first introduce a Hubbard model and derive the corresponding low-energy spin Hamiltonian. At the classical level, we find that the $p$-wave magnet is stabilized but remains energetically degenerate with competing noncoplanar states. Quantum fluctuations lift this degeneracy, selecting the $p$-wave magnet as the unique ground state. The resulting electronic structure exhibits finite spin accumulation via the Edelstein effect, highlighting the potential of $p$-wave magnetism for spintronic applications. We further discuss the relevance of our theory to quasi-two-dimensional honeycomb magnets such as Ni$_2$Mo$_3$O$_8$. Our findings establish the possibility of spontaneous $p$-wave magnetism.

</details>


### [94] [Triplon-mediated pairing and the superconducting gap structure in bilayer nickelates](https://arxiv.org/abs/2602.23989)
*Huimei Liu,Giniyat Khaliullin*

Main category: cond-mat.str-el

TL;DR: 提出双镍酸盐中三重态激发媒介的s+-波配对机制，解释α能带更大能隙及强各向异性实验现象


<details>
  <summary>Details</summary>
Motivation: 揭示双镍酸盐超导体中配对相互作用的微观起源，解释实验观测到的能隙反常特征

Method: 建立dx²-y²传导带与局域d³z²-r²自旋共存模型，通过强层间耦合使局域矩形成单态基态，其虚激发（三重态）媒介电子配对

Result: 预言层间s+-波配对（成键β与反键α能带序参量符号相反），α能带虽态密度更低却呈现更大能隙，且非局域Kondo耦合导致强动量依赖的各向异性

Conclusion: 三重态激发媒介的配对机制可合理解释双镍酸盐超导体的关键实验特征，支持其作为该类材料超导微观起源的理论框架

Abstract: We investigate the superconducting gap structure in bilayer nickelates within a model where conduction bands of dx2-y2 symmetry coexist with localized d3z2-r2 spins. Strong interlayer coupling drives the local moments into a singlet ground state, whose virtual singlet-triplet excitations ("triplons") mediate the pairing interaction between conduction electrons. This yields interband s+- pairing, with opposite signs of the order parameter on the bonding beta and antibonding alpha bands. Our theory naturally explains two key experimental features: a larger gap on the alpha band despite its smaller density of states, and pronounced gap anisotropy arising from momentum-dependent nonlocal Kondo coupling. These results support triplon-mediated pairing as the microscopic origin of superconductivity in bilayer nickelates.

</details>


### [95] [Emergence of geometric order from topological constraints in a three-dimensional Coulomb phase](https://arxiv.org/abs/2602.24051)
*Benjamin Canals*

Main category: cond-mat.str-el

TL;DR: 该论文研究了三维库仑相在域壁边界条件下的几何极限形状和有序现象，首次证实三维体系中也存在类似二维"北极圈"的极限形状，揭示了拓扑约束与高维涌现几何之间的联系。


<details>
  <summary>Details</summary>
Motivation: 二维六顶点模型（方格冰）中已确立"北极圈"现象（空间分离冻结与涨落自由度），但该现象向三维的拓展尚未被充分探索，存在理论空白。

Method: 采用三维立方晶格模型，边位点设置Ising自旋，施加散度为零的局部3-in/3-out约束；通过域壁边界条件部分解除基态简并，结合顶点极化密度映射进行数值模拟。

Result: 1) 域壁边界诱导热力学极限下的长程磁序；2) 体系保留库仑相涨落特征（代数关联与倒空间针尖奇点）；3) 获得三维"北极极限形状"的数值证据。

Conclusion: 成功建立三维库仑相中拓扑约束与涌现几何的桥梁，证实了高维体系中几何极限形状的存在性，为理解高维自旋液体提供了新视角。

Abstract: The emergence of order and geometric limit shapes in a three-dimensional (3D) Coulomb phase subject to domain wall boundary conditions (DWBC) is investigated. While the arctic circle phenomenon -- the spatial segregation of frozen and fluctuating degrees of freedom -- is well-established in the two-dimensional six-vertex model (square ice), its extension to 3D remains largely unexplored. A cubic lattice model with Ising degrees of freedom living on the edges, whose ground state manifold is governed by a divergence-free (3-in/3-out) local constraint, is considered. In the bulk, this model realizes a classical spin liquid characterized by algebraic correlations and pinch-point singularities in reciprocal space. It is demonstrated that applying DWBC partially lifts the extensive ground state degeneracy, inducing long-range magnetic order in the thermodynamic limit. Despite this ordering, it is found that the system retains a fluctuating component that exhibits the signature of a Coulomb phase. Finally, by mapping the local vertex polarization density, compelling numerical support is provided for a 3D generalization of the arctic limit shape, bridging the gap between topological constraints and emergent geometry in higher dimensions.

</details>


### [96] [Spontaneous Fully Compensated Ferrimagnetism](https://arxiv.org/abs/2602.24135)
*Bingbing Wang,Yongpan Li,Yichen Liu,Cheng-Cheng Liu*

Main category: cond-mat.str-el

TL;DR: 该论文提出了一种自发产生完全补偿铁磁性的通用机制，这种磁性态具有零净磁化强度但类似铁磁体的自旋劈裂能带结构，在石墨烯等材料中可通过缺陷工程实现，为自旋电子学和谷电子学应用提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 寻找具有零净磁化强度但保留自旋相关特性的新型磁性态，以解决传统铁磁体在自旋电子器件中因净磁化带来的稳定性和集成度问题。

Method: 采用哈特里-福克平均场方法对哈伯德模型进行计算，系统研究了相互作用强度和交错势参数空间中自发fFIM的稳定性区域。

Result: 揭示了fFIM独特的量子几何光学选择规则，预言了丰富的谷自旋相关的电子光学特性，证明了通过缺陷工程可在石墨烯中实现该磁性态。

Conclusion: 建立了自发fFIM的机制、物性表征与材料实现相统一的理论框架，为开发新型自旋电子、谷电子和光电器件开辟了新途径。

Abstract: We propose a general mechanism for the spontaneous emergence of filling-enforced fully compensated ferrimagnetism (fFIM), characterized by zero net magnetization yet ferromagnetic-like spin-split band structures. Using Hartree-Fock mean-field calculations of the Hubbard model, we map out the stability regime of spontaneous fFIM over a broad parameter space of interaction strength and staggered potential. We show the unique quantum-geometry-governed optical selection rules and the abundant valley- and spin-related physics of electronics and optics arising from the emergence of fFIM order, with tunable spin-polarized and valley-contrasting charge and spin currents. Furthermore, based on our theory, we demonstrate that spontaneous fFIM can be realized in nominally nonmagnetic graphene via defect engineering. Our results establish a unified framework for the mechanism, emergent properties, and materials realization of spontaneous fFIM, opening new opportunities for spintronic, valleytronic, and optoelectronic applications.

</details>


### [97] [A Unified Approach to Strong Local Correlations and Collective Fluctuations: Eliminating Divergence in the Spin Channel](https://arxiv.org/abs/2602.24145)
*S. D. Semenov,A. I. Lichtenstein,A. N. Rubtsov*

Main category: cond-mat.str-el

TL;DR: The paper proposes fDMFT, a novel extension of DMFT that incorporates long-range correlations via functional integration of collective fluctuations across sites, demonstrating superior performance for the nearly half-filled Hubbard model.


<details>
  <summary>Details</summary>
Motivation: Standard DMFT provides an optimal local approximation for correlated lattice systems but fails to capture missing long-range correlations, necessitating an extended approach.

Method: Proposes fluctuating DMFT (fDMFT) which incorporates collective fluctuations of auxiliary impurity models across different sites via functional integration, technically implemented by obtaining a family of DMFT solutions on a grid for a self-consistent auxiliary classical field.

Result: The minimal version of fDMFT already yields accurate results with only minor improvements from lowest-order diagrammatic corrections, showing superior performance for the nearly half-filled Hubbard model.

Conclusion: The fDMFT framework based on the fluctuating local field concept outperforms other known diagrammatic extensions of DMFT for the nearly half-filled Hubbard model.

Abstract: Dynamical mean-field theory (DMFT) provides an optimal local approximation for correlated lattice systems by mapping the lattice onto a self-consistent effective impurity model. To account for the missing long-range correlations, we propose a novel extended approach, which we term fluctuating dynamical mean-field theory (fDMFT). It incorporates collective fluctuations of auxiliary impurity models across different sites via functional integration. Technically, this method involves obtaining a family of DMFT solutions on a grid for a self-consistent auxiliary classical field applied to the lattice. While the result can, in principle, be improved diagrammatically, we find that the minimal version of the theory already yields accurate results, with lowest-order diagrammatic corrections offering only minor improvements. This consistent framework, based on our fluctuating local field concept, demonstrates superior performance for the nearly half-filled Hubbard model compared to other known diagrammatic extensions of DMFT.

</details>


### [98] [Vacancy-induced local moments in quantum paramagnetic phases: An SU($N$) designer Hamiltonian study](https://arxiv.org/abs/2602.24203)
*Md Zahid Ansari,Souvik Kundu,Kedar Damle*

Main category: cond-mat.str-el

TL;DR: Using quantum Monte Carlo simulations, we find that non-magnetic vacancies induce emergent spin-1/2 moments in valence bond solid phases but not in spin liquid phases; instead, moments in spin liquids arise from monomers in maximum-density dimer packings of the diluted lattice.


<details>
  <summary>Details</summary>
Motivation: To understand the effects of non-magnetic impurity (vacancy) disorder on quantum paramagnetic phases stabilized by SU(N) designer Hamiltonians on bipartite lattices, and to test a recent argument about vacancy disorder effects in low-temperature spin liquids.

Method: Quantum Monte Carlo simulations (finite-temperature and zero-temperature projector Monte Carlo) on SU(N) designer Hamiltonians on bipartite and Lieb lattices, analyzing low-temperature susceptibility and ground-state wavefunction in valence bond basis.

Result: In valence bond solid ordered phases, isolated vacancies seed emergent S=1/2 moments, evidenced by Curie tails in susceptibility and ground-state wavefunction analysis. In the spin liquid-like regime on the Lieb lattice, vacancies do not seed local moments; emergent moments are instead associated with monomers in maximum-density dimer packings of the diluted lattice.

Conclusion: The impact of vacancy disorder depends on the nature of the low-temperature phase: in ordered phases (VBS) vacancies create local moments, while in spin liquids they do not, supporting the recent argument and highlighting the role of lattice geometry and dimer coverings.

Abstract: We explore the effects of non-magnetic impurities (vacancy disorder) on the quantum paramagnetic phases stabilized by SU($N$) designer Hamiltonians on bipartite lattices. Using the results of our quantum Monte Carlo simulations, we demonstrate that isolated vacancies seed emergent spin $S=1/2$ moments in their vicinity when the low-temperature state has valence bond solid order. Indeed, our quantum Monte Carlo results for the low-temperature susceptibility in such regimes shows clear evidence of the vacancy-induced Curie tails associated with these emergent moments, and our zero-temperature projector Monte Carlo results on the ground-state wavefunction in the valence bond basis provide additional evidence in support of this picture. Further, for such designer Hamiltonians on the Lieb lattice with two additional sites on each bond of a square lattice, we identify a low-temperature spin liquid-like regime with no sign of spin or valence bond order. This liquid-like regime serves as a test bed for validating a recently-developed argument concerning the effects of vacancy disorder in such low temperature regimes. Consistent with this argument, we find that isolated vacancies do not seed emergent local moments in such spin liquids. Instead, in the presence of vacancy disorder, emergent local moments are associated with the presence of monomers in maximum-density dimer packings of the corresponding diluted lattice.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [99] [Microscopic Structure of Random 3-SAT: A Discrete Geometric Approach to Phase Transitions and Algorithmic Complexity](https://arxiv.org/abs/2602.23411)
*Yongjian Zhan*

Main category: cs.CC

TL;DR: A discrete geometric model mapping 3-SAT to Boolean hypercube topology reveals absolute structural limits (minimal unsatisfiability at α=8/N, maximal satisfiability at α=(7/6)(N-1)(N-2)), explains why satisfiability thresholds hold "almost surely," and bridges phase transitions with algorithmic complexity through combinatorial geometry of vertex elimination and Hamming distance bridges.


<details>
  <summary>Details</summary>
Motivation: Traditional statistical physics analogies for random 3-SAT lack a discrete microscopic structure to describe phase transitions and computational complexity.

Method: Proposing a strictly discrete geometric model that maps 3-SAT phenomena to combinatorial topology of N-dimensional Boolean hypercube, defining problem space through valid solutions and establishing deterministic mechanics via progressive vertex elimination and Hamming distance bridges.

Result: Deriving absolute structural boundaries: minimal unsatisfiability limit at constraint density α=8/N with at least N(N-1)(N-2)/6 unsatisfiable cores; maximal satisfiability limit at α=(7/6)(N-1)(N-2) with 2^N maximal satisfiable instances; explaining the "easy-hard-easy" algorithmic complexity curve through geometric transitions in Depth-First Search path availability.

Conclusion: This topological framework provides a microscopic perspective that mathematically elucidates phase transitions and bridges theoretical complexity with concrete search algorithm mechanics.

Abstract: The structural phase transitions and computational complexity of random 3-SAT instances are traditionally described using thermodynamic analogies from statistical physics, such as Replica Symmetry Breaking and energy landscapes. While providing profound macroscopic insights, these theories lack a discrete microscopic structure. In this paper, we propose a complementary, strictly discrete geometric model that maps these phenomena directly to the combinatorial topology of an $N$-dimensional Boolean hypercube. By defining the problem space purely through valid solutions rather than abstract energy states, we establish deterministic mechanics for clustering and freezing, driven by the progressive elimination of vertices and Hamming distance bridges. Furthermore, we derive absolute structural boundaries for 3-SAT, identifying a minimal unsatisfiability limit at constraint density $α= \frac{8}{N}$ populated by at least $\frac{N(N-1)(N-2)}{6}$ distinct unsatisfiable cores, and a maximal satisfiability limit at $α= \frac{7}{6}(N-1)(N-2)$ populated by $2^N$ maximal satisfiable instances. These combinatorial extremes mathematically elucidate why the average-case Satisfiability Threshold Conjecture holds only ``almost surely.'' Finally, we apply this topological framework to explain the ``easy-hard-easy'' algorithmic complexity curve. We demonstrate that the efficiency of Depth-First Search is governed by the geometric transition from an abundance of valid search paths (the under-constrained easy phase) to a high density of structurally ``removed variables'' that force immediate contradictions (the over-constrained easy phase). This microscopic perspective bridges theoretical phase transitions with the concrete mechanics of complete search algorithms.

</details>


### [100] [Spiky Rank and Its Applications to Rigidity and Circuits](https://arxiv.org/abs/2602.23503)
*Lianna Hambardzumyan,Konstantin Myasnikov,Artur Riazanov,Morgan Shirley,Adi Shraibman*

Main category: cs.CC

TL;DR: 本文提出spiky rank，一种新的矩阵复杂度度量，它通过结合blocky rank的组合结构和线性代数灵活性来增强后者，并应用于矩阵刚性和深度-2 ReLU电路下界。


<details>
  <summary>Details</summary>
Motivation: 为了处理同时具有组合和代数特性的问题，需要更鲁棒的矩阵复杂度度量。Spiky rank旨在扩展blocky rank至实矩阵，并提供更好的理论性质。

Method: 定义spiky rank为用对角块为任意秩-1矩阵的分块矩阵表示目标矩阵所需的最少项数；建立与矩阵刚性和电路复杂度的理论联系；推导随机矩阵的紧界；开发显式下界框架并应用于Hamming距离矩阵和谱扩展器；比较spiky rank与其他矩阵参数。

Result: 1) 高spiky rank蕴含高矩阵刚性；2) spiky rank下界给出深度-2 ReLU电路规模下界；3) 获得随机矩阵的紧spiky rank界；4) 对Hamming距离矩阵和谱扩展器建立显式下界；5) 揭示spiky rank与blocky rank、稀疏性、γ₂-范数的关系。

Conclusion: Spiky rank作为矩阵复杂度度量是有效的，它在理论计算机科学（特别是电路复杂度和矩阵刚性）中具有应用价值，并为相关问题提供了新的分析工具。

Abstract: We introduce spiky rank, a new matrix parameter that enhances blocky rank by combining the combinatorial structure of the latter with linear-algebraic flexibility. A spiky matrix is block-structured with diagonal blocks that are arbitrary rank-one matrices, and the spiky rank of a matrix is the minimum number of such matrices required to express it as a sum. This measure extends blocky rank to real matrices and is more robust for problems with both combinatorial and algebraic character.
  Our conceptual contribution is as follows: we propose spiky rank as a well-behaved candidate matrix complexity measure and demonstrate its potential through applications. We show that large spiky rank implies high matrix rigidity, and that spiky rank lower bounds yield lower bounds for depth-2 ReLU circuits, the basic building blocks of neural networks. On the technical side, we establish tight bounds for random matrices and develop a framework for explicit lower bounds, applying it to Hamming distance matrices and spectral expanders. Finally, we relate spiky rank to other matrix parameters, including blocky rank, sparsity, and the $γ_2$-norm.

</details>


### [101] [On the Need for (Quantum) Memory with Short Outputs](https://arxiv.org/abs/2602.23763)
*Zihan Hao,Zikuan Huang,Qipeng Liu*

Main category: cs.CC

TL;DR: 该论文首次在有界空间与无界空间之间对短输出问题（工作内存可指数倍于输出大小）进行了分离，经典与量子设置均成立。通过嵌套碰撞发现问题，证明最优查询复杂度需指数内存，并提出“双预言记录”技术，将短输出问题的时间‑空间权衡归约为长输出问题。


<details>
  <summary>Details</summary>
Motivation: 短输出问题的时间‑空间权衡在经典和量子计算中研究较少，建立有界与无界空间的分离有助于理解计算资源的极限，并为量子算法下界提供新视角。

Method: 引入嵌套碰撞发现问题，使用“双预言记录”技术，让一个预言记录另一个预言的长输出，从而将短输出问题的时间‑空间权衡转化为长输出问题的权衡。

Result: 证明嵌套碰撞找问题的最优查询复杂度必须依赖指数级内存，从而实现了有界与无界空间之间的分离，且在经典和量子设置下均成立。

Conclusion: “双预言记录”技术为短输出问题的时间‑空间权衡分析提供了新工具，预计将在其他相关研究中发挥重要作用。

Abstract: In this work, we establish the first separation between computation with bounded and unbounded space, for problems with short outputs (i.e., working memory can be exponentially larger than output size), both in the classical and the quantum setting. Towards that, we introduce a problem called nested collision finding, and show that optimal query complexity can not be achieved without exponential memory. Our result is based on a novel ``two-oracle recording'' technique, where one oracle ``records'' the computation's long outputs under the other oracle, effectively reducing the time-space trade-off for short-output problems to that of long-output problems. We believe this technique will be of independent interest for establishing time-space tradeoffs in other short-output settings.

</details>


### [102] [Black-Box PWPP Is Not Turing-Closed](https://arxiv.org/abs/2602.23809)
*Pavel Hubáček*

Main category: cs.CC

TL;DR: 证明自适应碰撞查找查询比非自适应查询更强大，通过证明 PWPP 复杂度类在随机预言机下不对自适应图灵归约封闭


<details>
  <summary>Details</summary>
Motivation: 建立自适应碰撞查找查询严格强于非自适应查询的证据，因为 PWPP 已知对非自适应图灵归约封闭，但自适应情况未知

Method: 引入 NESTED-COLLISION 问题，证明该问题可通过两次自适应 PWPP 预言机调用求解，但随机实例无法通过黑盒非自适应归约到标准 PWPP-完全问题 COLLISION

Result: 实现了首个黑盒分离，表明 PWPP 在随机预言机下不对自适应图灵归约封闭，证实自适应查询的优越性

Conclusion: 自适应碰撞查找查询确实严格比非自适应查询更强大，这对密码学基础理论和复杂性类理解有重要意义

Abstract: We establish that adaptive collision-finding queries are strictly more powerful than non-adaptive ones by proving that the complexity class PWPP (Polynomial Weak Pigeonhole Principle) is not closed under adaptive Turing reductions relative to a random oracle. Previously, PWPP was known to be closed under non-adaptive Turing reductions (Jeřábek 2016). We demonstrate this black-box separation by introducing the NESTED-COLLISION problem, a natural collision-finding problem defined on a pair of shrinking functions. We show that while this problem is solvable via two adaptive calls to a PWPP oracle, its random instances cannot be solved via a black-box non-adaptive reduction to the canonical PWPP-complete problem COLLISION.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [103] [Random batch sum-of-Gaussians method for molecular dynamics simulation of particle systems in the NPT ensemble](https://arxiv.org/abs/2602.23582)
*Zhen Jiang,Jiuyang Liang,Qi Zhou*

Main category: physics.comp-ph

TL;DR: 提出随机批量高斯叠加(RBSOG)方法用于NPT系综带电体系分子动力学模拟，通过压力核SOG分裂和测度重校准策略，在保持O(N)复杂度的同时实现10倍加速和4倍方差降低，可扩展至千万原子规模。


<details>
  <summary>Details</summary>
Motivation: 传统Ewald方法在NPT模拟中存在截断不连续导致的压力伪影，且计算通信成本高；现有随机批量方法在径向/非径向压力分量采样中存在方差与计算开销的权衡问题。

Method: 提出RBSOG方法：(1)对1/r^3压力核进行SOG分裂，实现光滑的短程/长程分解；(2)用随机批量重要性采样处理长程部分；(3)引入测度重校准策略，重用径向提案的傅里叶模并校正非径向目标，获得无偏且低方差的压力估计器。

Result: 获得近最优O(N)复杂度；在体相水、离子液体和DPPC膜体系中准确重现关键观测量；千万原子规模下实现比粒子网格法10倍加速；相比随机批量Ewald方差降低4倍；在2048核上展现优异弱/强扩展性。

Conclusion: RBSOG为大规模NPT模拟提供了实用可扩展的解决方案，在保持精度的同时显著降低求解时间和通信成本，有效缓解了压力伪影问题。

Abstract: In this work, we develop a random batch sum-of-Gaussians (RBSOG) method for molecular dynamics simulations of charged systems in the isothermal-isobaric (NPT) ensemble. We introduce an SOG splitting of the pressure-related $1/r^3$ kernel, yielding a smooth short-/long-range decomposition for instantaneous pressure evaluation. The long-range part is treated in Fourier space by random-batch importance sampling. Because the radial and non-radial pressure components favor different proposals, direct sampling either increases structure-factor evaluations and communication or leads to substantial variance inflation. To address this tradeoff, we introduce a measure-recalibration strategy that reuses Fourier modes drawn from the radial proposal and corrects them for the non-radial target, producing an unbiased pressure estimator with significantly reduced variance and negligible extra cost. The resulting method mitigates pressure artifacts caused by cutoff discontinuities in traditional Ewald-based treatments while preserving near-optimal $O(N)$ complexity. We provide theoretical evidence on pressure decomposition error, consistency of stochastic approximation, and convergence of RBSOG-based MD. Numerical experiments on bulk water, LiTFSI ionic liquids, and DPPC membranes show that RBSOG accurately reproduces key structural and dynamical observables with small batch sizes ($P\sim 100$). In large-scale benchmarks up to $10^7$ atoms on $2048$ CPU cores, RBSOG achieves about an order-of-magnitude speedup over particle-particle particle-mesh in electrostatic calculations for NPT simulations, together with a consistent $4\times$ variance reduction relative to random batch Ewald and excellent weak/strong scalability. Overall, RBSOG provides a practical and scalable route to reduce time-to-solution and communication cost in large-scale NPT simulations.

</details>


### [104] [Shaping the Digital Future of ErUM Research: Sustainability & Ethics](https://arxiv.org/abs/2602.24087)
*Luca Di Bella,Jan Bürger,Markus Demleitner,Torsten Enßlin,Johannes Erdmann,Martin Erdmann,Benjamin Fischer,Martin Gasthuber,Gabriele Gramelsberger,Wolfgang Gründinger,Prateek Gupta,Johannes Hartl,Maximilian Horzela,Vijay Kartik,Stefan Krischer,Eva Kröll,Thomas Kuhr,Katharina Kürschner,Inga Lakomiec,Valerie Lang,Kristin Lohwasser,Thomas Metcalf,Martin Möller,Saskia Nagel,Susanne Pfalzner,Rebecca Redlin,Christopher Schrader,Kathrin Schulz,Markus Schumacher,Kilian Schwarz,Fabian Sigler,Dwayne Spiteri,Achim Stahl,Judith Steinfeld,Wim Vanderbauwhede,Cyrus Walther,Angela Warkentin,Peter Wissmann,Eoin Woods*

Main category: physics.comp-ph

TL;DR: 2025年埃朗根研讨会报告回顾自2023年资源感知研究倡议以来，数据密集型ErUM研究的可持续进展，评估了减少CO2排放、提高数据软件FAIR性、优化计算基础设施、AI伦理等短中长期行动，强调需通过培训、资金机制和社区倡议将可持续性与伦理嵌入日常科研实践。


<details>
  <summary>Details</summary>
Motivation: 评估数据密集型ErUM研究在可持续性和伦理方面的进展，解决资源消耗、AI应用带来的伦理挑战，推动科研实践从意识到行动的转变。

Method: 通过研讨会形式，系统评估短、中、长期行动方案，涵盖CO2监测与减排、FAIR原则实施、工作流与基础设施优化、低能耗计算中心("呼吸"中心)、软件效率认证、AI伦理框架等维度。

Result: 提出需建立系统性教学与培训体系，开发专项指导与资助工具，推广"呼吸式"计算中心和软件效率认证，明确AI应用中的人类问责制，并强调技术措施与激励、传播策略相结合。

Conclusion: 实现科研可持续转型需技术、教育和社区三管齐下，通过目标明确的意识建设、沟通策略、激励机制和社区驱动倡议，将可持续性与伦理原则深度融入日常科研实践。

Abstract: This workshop report from "Shaping the Digital Future of ErUM Research: Sustainability & Ethics" (Aachen, 2025) reviews progress on sustainability measures in data-intensive ErUM-Data research since the 2023 call-to-action on resource-aware research. It evaluates short-, medium-, and long-term actions around monitoring and reducing CO2 emissions, improving data and software FAIRness, optimizing workflows and computing infrastructures, and aligning operations with low-carbon energy availability, including concepts such as "breathing" computing centers, long-term data storage strategies, and software efficiency certification. The report stresses the need for systematic teaching, training, mentoring, and new support formats to establish sustainable coding and computing practices, particularly among students and early-career researchers, and highlights the importance of dedicated steering and funding instruments to embed sustainability in project planning. Ethical discussions focus on the transformative use of AI in ErUM-Data, addressing autonomy, bias, transparency, explainability, attribution of responsibility, and the risk of deskilling, while reaffirming that accountability for scientific outcomes remains with human researchers. Finally, the report emphasizes that sustainable transformation requires not only technical measures but also targeted awareness-building, communication strategies, incentives, and community-driven initiatives to move from awareness to action and to integrate sustainability and ethics into everyday scientific practice.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [105] [Information bound on navigation speed in smart active matter](https://arxiv.org/abs/2602.23988)
*Kristian Stølevik Olsen,Mitsusuke Tarama,Hartmut Löwen*

Main category: cond-mat.stat-mech

TL;DR: 提出一种自适应活性粒子模型，结合信息处理与运动控制，推导出通用导航速度边界，揭示认知系统特征（最优感知时长、速度-精度权衡），发现记忆衰减对导航影响有限。


<details>
  <summary>Details</summary>
Motivation: 传统活性物质模型缺乏内部信息处理与决策能力，而生命系统的智能行为依赖于信息感知、处理和响应。本研究旨在建立连接活性物质与认知系统的理论框架。

Method: 结合基于更新的间歇运动模型与克拉美-拉奥不等式，推导适用于广泛信息处理策略的导航速度边界。通过允许存储信息退化来模拟记忆衰减效应。

Result: 1) 推导出导航速度的普适边界；2) 重现认知系统核心特征：最优感知时长、速度-精度权衡；3) 发现导航过程主要受外部方向噪声支配，对记忆衰减不敏感。

Conclusion: 该框架成功将信息处理机制整合到活性物质系统中，揭示了生物导航的基本原理，表明记忆衰退虽会轻微减慢导航，但核心权衡关系仍由外部环境噪声主导。

Abstract: Intelligent behavior in life-like systems often arises from the ability to gather, process, and act on information. While active matter provides a framework for studying life-like dynamics, it typically omits internal information-processing and decision-making. Here we introduce an adaptive active particle model that uses minimal information processing capabilities in order to navigate towards a distant target. By combining renewal-based intermittent motion with the Cramér-Rao inequality, we derive a bound on the navigation speed valid for a wide range of information processing strategies. The framework captures hallmark features of cognitive systems, including optimal sensing durations and a speed-accuracy trade-off that balances noise and reliability. Allowing stored information to degrade before action reveals that although deterioration slows navigation, the trade-off remains governed primarily by external orientational noise and is remarkably insensitive to memory decay.

</details>


### [106] [Exact Anomalous Current Fluctuations in Quantum Many-Body Dynamics](https://arxiv.org/abs/2602.24008)
*Kazuya Fujimoto,Taiki Ishiyama,Taiga Kurose,Takato Yoshimura,Tomohiro Sasamoto*

Main category: cond-mat.stat-mech

TL;DR: 首次在量子多体系统中精确推导出描述反常电流涨落的M-Wright函数，为研究量子多体输运反常现象奠定基础


<details>
  <summary>Details</summary>
Motivation: 一维多体输运中存在普适性反常电流涨落现象（由M-Wright函数描述），但此前仅在经典系统中精确求解，量子多体系统中的精确推导仍属难题

Method: 通过分析无限强排斥相互作用一维费米-哈伯德模型中的积分自旋电流，进行微观推导

Result: 在量子多体动力学中首次获得M-Wright函数的精确微观推导，证实该反常行为在量子体系中同样存在

Conclusion: 该结果为在各类量子多体系统中探索反常积分电流现象提供了理论基础

Abstract: Fluctuations of integrated currents have attracted considerable interest over the past decades in the context of statistical mechanics. Recently, anomalous current fluctuations, characterized by the M-Wright function, were obtained exactly in a classical automaton [$Ž$. Krajnik et al., Phys. Rev. Lett. 128, 160601 (2022)], and previous studies have shown that the anomalous behavior can arise in a variety of classical systems. Despite the rapidly growing interest in such anomalous behaviors, which capture a universal aspect of one-dimensional many-body transport, the exact derivation of the M-Wright function in quantum many-body systems has remained elusive. In this Letter, we present the first exact microscopic derivation of the M-Wright function in quantum many-body dynamics by analyzing the integrated spin current in a one-dimensional Fermi-Hubbard model with infinitely strong repulsive interactions. Our results lay the groundwork for exploring anomalous integrated currents in a broad class of quantum many-body systems.

</details>


### [107] [Anomalous hydrodynamic fluctuations in the quantum XXZ spin chain](https://arxiv.org/abs/2602.24242)
*Takato Yoshimura,Žiga Krajnik,Alvise Bastianello,Enej Ilievski*

Main category: cond-mat.stat-mech

TL;DR: 量子XXZ自旋-1/2链在易轴各向异性区域呈现非高斯自旋流异常涨落，其分布为嵌套高斯型，方差与自旋扩散常数和静态自旋磁化率相关，揭示了与单列系统电荷流涨落的普适流体力学起源。


<details>
  <summary>Details</summary>
Motivation: 研究量子XXZ自旋-1/2链在易轴各向异性下的非高斯自旋流涨落现象，阐明其物理起源，并与单列系统中的异常电荷流涨落建立联系。

Method: 应用弹道宏观涨落理论推导热平衡态下典型自旋流涨落的精确概率分布。

Result: 获得嵌套高斯分布，其方差可解析地与自旋扩散常数和静态自旋磁化率相关联，并与数值模拟结果相符。

Conclusion: 该研究揭示了XXZ链中观察到的异常涨落与单列系统电荷流异常涨落具有相同的流体力学机制，确立了其普适性流体力学起源。

Abstract: The quantum XXZ spin-1/2 chain features non-Gaussian spin current fluctuations in the regime of easy-axis anisotropy. Using ballistic macroscopic fluctuation theory, we derive the exact probability distribution of typical spin-current fluctuations in thermal equilibrium. The obtained nested Gaussian distribution is fully characterized by its variance which we analytically relate to the spin diffusion constant and static spin susceptibility, and compare our with numerical simulations. By unveiling how the same mechanism which leads to anomalous charge current fluctuations in single-file systems manifests in the XXZ chain, our approach establishes the universal hydrodynamic origin of the observed anomalous fluctuations.

</details>


### [108] [Asymptotically Solvable Quantum Circuits](https://arxiv.org/abs/2602.24276)
*Samuel H. Pickering,Bruno Bertini*

Main category: cond-mat.stat-mech

TL;DR: 提出"渐近可解"量子电路模型，通过调节阈值尺度，在早期表现出一般混沌行为，在后期才呈现可解特性，为研究一般非平衡量子系统提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 理解一般混沌量子系统的困难性，以及可解性带来的非平凡约束，旨在建立可解模型与一般混沌系统之间的桥梁，探索在难以直接研究的普遍情况下获取洞见的方法。

Method: 引入一类"渐近可解"量子电路家族，其可解性约束仅作用于超过可调阈值的关联尺度。通过计算平衡态（无穷温度）下的动力学关联函数和量子猝灭后的热化动力学，并结合非相互作用点上的精确解析结果与数值实验进行互补研究。

Result: 该电路类具有普遍遍历性，但包含一个非相互作用点，可在不可解的早期时间区域提供精确解析结果，补充了数值实验的不足。

Conclusion: 渐近可解量子电路为研究一般混沌量子系统提供了有效框架，通过在早期时间保持一般性而在后期呈现可解性，成功连接了可解模型与一般混沌动力学，深化了对非平衡量子物质的理解。

Abstract: The discovery of chaotic quantum circuits with (partially) solvable dynamics has played a key role in our understanding of non-equilibrium quantum matter and, at the same time, has helped the development of concrete platforms for quantum computation. It was shown that solvability does not prevent the generation of chaotic dynamics, however, it imposes non-trivial constraints on the generated correlations. A natural question is then whether it is possible to gain insight into the generic case despite the latter being very hard to access. To address this question here we introduce a family of 'asymptotically solvable' quantum circuits where the solvability constraints only affect correlations on length scales beyond a tuneable threshold. This means that their dynamics are only solvable for long enough times: for times shorter than the threshold they are generic. We show this by computing both their dynamical correlations on the equilibrium (infinite temperature) state and their thermalisation dynamics following quantum quenches from compatible (asymptotically solvable) non-equilibrium initial states. The class of systems we introduce is generically ergodic but contains a non-interacting point, which we use to provide exact analytical results, complementing those of numerical experiments, on the non-solvable early time regime.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [109] [Renormalization-group perspective on spontaneous stochasticity](https://arxiv.org/abs/2602.24221)
*Alexei A. Mailybaev,Luca Moriconi*

Main category: nlin.CD

TL;DR: This paper develops a renormalization-group framework to show that spontaneous stochasticity in hydrodynamic turbulence is a universal fixed point phenomenon, analogous to other universality classes in physics.


<details>
  <summary>Details</summary>
Motivation: To provide a theoretical perspective on spontaneous stochasticity in hydrodynamic turbulence by connecting it to multiscale dynamical systems and universality phenomena through renormalization-group methods.

Method: Uses renormalization-group (RG) transformations acting on Markov kernels within a multiscale dynamical systems framework, building on previous results from Arnold's cat model.

Result: Demonstrates that spontaneous stochasticity emerges as a universal fixed point of the RG transformation, independent of microscopic details. Reinterprets classical examples (Feigenbaum equation, central limit theorem, hierarchical spin models) within this unified framework.

Conclusion: Spontaneous stochasticity belongs to the same category of universal phenomena as other well-established physics universality classes, providing a broader theoretical context for understanding turbulence and stochastic dynamics.

Abstract: We present a renormalization-group perspective on spontaneous stochasticity in hydrodynamic turbulence, viewed through the lens of multiscale dynamical systems. Building on previously established results for a solvable multiscale Arnold's cat model, we show that spontaneous stochasticity emerges as a universal fixed point of an RG transformation acting on Markov kernels, independent of the microscopic regularization. Classical examples - including the Feigenbaum equation, the central limit theorem, and hierarchical spin models - are reinterpreted within the same framework, placing spontaneous stochasticity alongside other universality phenomena.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [110] [Ground state and persistent oscillations in the quantum East model](https://arxiv.org/abs/2602.23422)
*Adway Kumar Das,Achilleas Lazarides*

Main category: quant-ph

TL;DR: 在1D量子East模型中，当参数s→-∞时，系统的基态和激发态均可由简单的自旋相干态准确描述，边界自旋的π旋转导致低纠缠激发态；当-∞<s<0时，这种边界相干性导致系统出现持续的全局与局域观测量的相干振荡，其物理机制不同于传统多体疤痕或Fock空间超立方体机制。


<details>
  <summary>Details</summary>
Motivation: 理解量子多体系统在特定极限下的低能物理行为，特别是边界效应导致的非平凡动力学现象，并区分其与已知机制（如多体疤痕）的差异。

Method: 解析研究1D量子East模型在开放边界条件下的本征态结构，分析s→-∞极限下的基态和低激发态性质，并考察有限s值下边缘相干态与两个本征态的重叠及能隙行为。

Result: 1. s→-∞时基态可用自旋相干乘积态精确近似；2. 存在由边界自旋π旋转导致的低纠缠激发态，同样可用自旋相干态描述；3. -∞<s<0区间内，边缘相干态与两个分离的本征态重叠，其间能隙与系统尺寸无关；4. 热力学极限下出现持续相干振荡；5. 该机制源于边界物理，不同于多体疤痕或Fock空间超立方体机制。

Conclusion: 1D量子East模型的边界自由度在特定参数区间的相干演化导致了可观测的持续振荡现象，这一发现揭示了一种新的非平衡动力学机制，为研究量子多体边界物理提供了新视角。

Abstract: For the 1D quantum East model with open boundaries, we show that in the limit $s \to -\infty$, the ground state is accurately captured by a simple spin-coherent product state. We further identify a low-entanglement excited eigenstate that differs from the ground state only by a $π$-rotation of the boundary spin, remaining well approximated by a spin-coherent state. For a range of $-\infty<s<0$, the edge-coherent product state overlaps with two eigenstates separated by a size-independent energy gap, leading to persistent coherent oscillations of both global and local observables in the thermodynamic limit. These oscillations originate from boundary physics and are distinct from quantum many-body scars or hypercube-like Fock-space mechanisms.

</details>


### [111] [Trajectory of Probabilities, Probability on Trajectories, and the Stochastic-Quantum Correspondence](https://arxiv.org/abs/2602.23491)
*Győző Egri,Marton Gomori,Balazs Gyenis,Gábor Hofer-Szabó*

Main category: quant-ph

TL;DR: This paper systematically clarifies the distinction between two probabilistic descriptions of physical systems (probability trajectories vs. probability on trajectories) by defining probability dynamics and stochastic implementations, showing implementations are generically non-unique, every dynamics admits a Markovian implementation, and exposing fallacies in common arguments for linearity.


<details>
  <summary>Details</summary>
Motivation: The lack of clear distinction between probability trajectories and probability on trajectories has caused conceptual difficulties, particularly in stochastic-quantum correspondence. A systematic account of their relationship is needed to resolve these issues.

Method: Defines probability dynamics and stochastic process families with a precise notion of implementation connecting them. Distinguishes dynamics-level maps from conditional probability matrices. Introduces decomposability as general stepwise evolution and relates it to divisibility in linear cases.

Result: Shows implementations are generically non-unique; every probability dynamics admits a Markovian implementation; characterizes when non-Markovian implementations exist; exposes fallacies in linearity arguments based on total probability; clarifies transition matrix interpretation; demonstrates decomposability and divisibility can diverge; disentangles both from Markovianity and time-homogeneity.

Conclusion: The framework resolves conceptual difficulties in stochastic-quantum correspondence by clarifying the relationship between probabilistic descriptions, distinguishing key concepts, and offering proper interpretation of transition matrices, while contrasting with quantum mechanics where linearity is physically motivated.

Abstract: The probabilistic description of the time evolution of a physical system can take two conceptually distinct forms: a trajectory of probabilities, which specifies how probabilities evolve over time, and a probability on trajectories, which assigns probabilities to possible histories. A lack of a clear distinction between these two probabilistic descriptions has given rise to a number of conceptual difficulties, particularly in recent analyses of stochastic-quantum correspondence. This paper provides a systematic account of their relationship. We define probability dynamics and stochastic process families together with a precise notion of implementation that connects the two descriptions. We show that implementations are generically non-unique, that every probability dynamics admits a Markovian implementation, and characterize when non-Markovian implementations are possible. We expose fallacies in common arguments for the linearity of probability dynamics based on the law of total probability and clarify the proper interpretation of ``transition matrices'' by distinguishing dynamics-level maps from the conditional probability matrices of implementing processes. We further introduce decomposability as the appropriate general notion of stepwise evolution for (possibly nonlinear) probability dynamics, relate it to divisibility in the linear case -- showing that the two can come apart -- and disentangle both notions from Markovianity and time-homogeneity. Finally, we connect these results to what we call statistical dynamics, in which linearity is indeed physically motivated, and contrast the framework with quantum mechanics.

</details>


### [112] [Continuous variable quantum key distribution channel emulator for the SPOQC mission](https://arxiv.org/abs/2602.23510)
*Emma Tien Hwai Medlock,Vinod N. Rao,Ry Render,Timothy Spiller,Rupesh Kumar*

Main category: quant-ph

TL;DR: 开发新型光学信道仿真器，用于在实验室环境下精确模拟低轨卫星到地面的自由空间光通信信道动态特性，特别是针对立方星量子通信载荷的性能测试


<details>
  <summary>Details</summary>
Motivation: 卫星对地自由空间光通信信道存在动态损耗，准确表征信道特性对评估卫星载荷实际性能至关重要，需在实验室实现高保真信道仿真

Method: 设计新型光学信道仿真器，可模拟不同大气湍流强度、卫星轨道轨迹及地面站参数下的卫星对地光信道特性，工作于特定光学波长

Result: 成功构建可精确复现低地球轨道立方星对地量子通信信道动态的仿真系统，支持连续变量量子密钥分发载荷的性能测试与基准评估

Conclusion: 该仿真器将为2026年英国量子通信中心"光学量子通信卫星平台"任务的有效载荷提供关键测试验证，推动天基量子通信技术发展

Abstract: In a free space optical (FSO) communication link from satellite to ground, the losses in the channel will be dynamic. Thus, the characterization of the FSO channel is of great importance and this can be emulated in the lab to evaluate the realistic performance of a satellite payload. In this work, we introduce a novel optical channel emulator capable of replicating these dynamics, especially for Low Earth Orbit based CubeSats. We demonstrate its ability to accurately emulate a satellite-to-ground optical communications channel under various atmospheric turbulence strengths, satellite trajectories, and optical ground station parameters at a given optical wavelength of interest. Our satellite channel emulator was designed to test and benchmark the performance of the continuous variable quantum key distribution payload for the Satellite Platform for Optical Quantum Communications mission - an in-orbit demonstrator for the UK's Quantum Communication Hub, to be launched in early 2026.

</details>


### [113] [High-Temporal-Resolution Measurements of the Impacts of Ionizing Radiation on Superconducting Qubits](https://arxiv.org/abs/2602.23544)
*Jihee Yang,Thomas J. Carroll,Philip Mason,Robert Schwartz,Kenneth M. O'Hara,Jennifer Lund,Michael Gottschalk,Timothy Stephenson,Lawrence H. Friedman,Francisco Yumiceva,Justin Hackley,Aurelius L. Graninger,Chris Rotella,Pat Warner,Jonathan M. Cochran,Adam V. Bruce,Melody Wagner,James Wenner,Stan Steers,Christopher Moore,Alex Marakov,Bradley G. Christensen*

Main category: quant-ph

TL;DR: 利用与超导量子比特同基底的微波动能感应探测器（MKID），以1微秒时间分辨率研究电离辐射对量子比特的影响，发现TLS scrambling事件与辐射事件无相关性，且量子比特在辐射后约13微秒快速恢复。


<details>
  <summary>Details</summary>
Motivation: 探究电离辐射是否直接导致超导量子比特中的二能级系统（TLS）scrambling现象，以澄清先前研究中观察到的表观相关性是否真实存在。

Method: 在相同基底上集成微波动能感应探测器（MKID）与超导量子比特，利用MKID以1微秒时间分辨率同步监测电离辐射事件与量子比特状态变化。

Result: 1. 未观测到TLS scrambling事件与电离辐射事件的关联性；
2. 辐射后量子比特弛豫与激发恢复过程符合指数衰减模型，特征恢复时间13±1微秒；
3. 每个沉积能量单位（MeV）在结区产生240/μm³的准粒子峰值密度；
4. 快速恢复现象与铌材料靠近结区的器件文献值一致。

Conclusion: TLS scrambling可能并非由电离辐射直接引发，先前报道的相关性或源于能量不足触发探测器的低能事件；量子比特恢复速度强烈依赖于铌与结区的 proximity（邻近性）。

Abstract: We measure the effect of ionizing radiation on superconducting qubits with a timing resolution of 1 $μs$ using microwave kinetic inductance detectors (MKIDs) fabricated on the same substrate. We observe no correlation between two-level system (TLS) scrambling events and ionizing radiation events detected with the MKIDs, suggesting TLS scrambling events may not arise from ionizing radiation and instead the previously reported apparent correlation may be due to events without sufficient energy to trigger our MKIDs. We characterize the fast-time system recovery of transmons following a radiation event, where we observe the recovery of the enhanced qubit relaxation and excitation to be well-described by an exponential recovery to the baseline quasiparticle density, with a characteristic time of $13\pm1\ μ$s, and a peak quasiparticle density at the junction per deposited energy of $240/μm^3/MeV$. The fast recovery is consistent with literature reported values for Nb-based devices with direct injection of 2$Δ_{\text{Al}}$ phonons, demonstrating the recovery is strongly dependent on the proximity of niobium to the junction.

</details>


### [114] [Spin stiffness and resilience phase transition in a noisy toric-rotor code](https://arxiv.org/abs/2602.23751)
*Morteza Zarei,Mohammad Hossein Zarei*

Main category: quant-ph

TL;DR: This paper establishes a quantum formalism linking the partition function of the classical XY model to the resilience phase transition in toric-rotor codes under phase-shift noise, identifying a critical noise width σ_c≈0.89 where partial resilience is lost.


<details>
  <summary>Details</summary>
Motivation: To develop a mathematically rigorous framework for studying correctability in continuous-variable quantum codes by leveraging connections between quantum error correction and statistical physics models.

Method: Maps the toric-rotor code's noise-induced fidelity decay to the XY model's partition function, equating noise width σ to temperature T; quantifies resilience via a quantum spin stiffness formalism mapped to logical gate fidelity.

Result: Identifies a Kosterlitz-Thouless-like phase transition at σ_c≈0.89: the logical subspace shows near-complete resilience (order parameter ≈1) for σ<σ_c but loses all resilience at σ_c, proving toric-rotor codes lack full correctability.

Conclusion: The XY model partition function framework rigorously characterizes partial resilience in continuous-variable codes; toric-rotor codes exhibit correctability limits in 2D but may inform higher-dimensional (d>2) code analysis.

Abstract: We use a quantum formalism for the partition function of the classical $XY$ model to identify a resilience phase transition in a noisy toric-rotor code. Specifically, we consider the toric-rotor code under phase-shift noise described by a von Mises probability distribution and show that the fidelity between the final state after noise and the initial state is proportional to the partition function of the $XY$ model. We map the temperature of the $XY$ model to the width of the noise in the toric-rotor code, such that a Kosterlitz--Thouless phase transition at a critical temperature $T_{c}$ corresponds to a mixed-state phase transition at a critical width $σ_c$. To characterize this phase transition, we develop a quantum formalism for the spin stiffness in the $XY$ model and show that it is mapped to the gate fidelity in the logical subspace of the toric-rotor code. In particular, we introduce a topological order parameter that characterizes the resilience of the toric-rotor code to decoherence within the logical subspace. We show that the logical subspace does not exhibit complete resilience to noise, which is a necessary condition for correctability. However, it exhibits partial resilience to noise for widths less than $σ_c\approx 0.89$, where the resilience order parameter takes values near $1$ and then drops to zero at $σ_c$. We also use our results to shed light on the correctability of toric-rotor codes in higher dimensions $d > 2$. Our work shows that the quantum formalism for partition functions provides a mathematically rigorous framework for studying correctability in continuous-variable quantum codes.

</details>


### [115] [From quantum time to manifestly covariant QFT: on the need for a quantum-action-based quantization](https://arxiv.org/abs/2602.23625)
*N. L. Diaz*

Main category: quant-ph

TL;DR: 将量子时间方案扩展到量子场论以实现明显的洛伦兹协变性，通过新的量子化方法克服无法定理


<details>
  <summary>Details</summary>
Motivation: 标准量子场论中洛伦兹协变性被隐藏，而量子时间方案使单粒子协变性显式，因此希望推广到量子场论层面，使协变性在希尔伯特空间级别显式

Method: 提出二次量子化方法，以量子时间粒子为基本单元；引入时空经典力学作为经典对应；证明狄拉克量子化的无法定理；开发基于量子作用的量子化方案

Result: 朴素多体构造存在不一致性；狄拉克量子化时空经典力学退化为标准量子场论；而基于量子作用的量子化能产生时空量子力学，使相互作用量子场论具有显式协变性

Conclusion: 这需要时空量子态的推广，与因果性和“时间上的态”等概念相关，在dS/CFT背景下涉及时空纠缠和涌现时间

Abstract: In quantum time (QT) schemes, time is promoted to a degree of freedom, allowing Lorentz covariance to be made explicit for single particles. We ask whether this can be lifted to QFT, so that Lorentz covariance becomes manifest at the Hilbert-space level, rather than being hidden as in the standard canonical formulation. We address this question by proposing a second-quantized approach in which the elementary particle is the QT particle itself, leading naturally to the notion of spacetime field algebras and of quantum action. We show, however, that a naive many-body construction runs into inconsistencies. To pinpoint their origin we introduce a classical counterpart of the second-quantized formalism, spacetime classical mechanics (SCM), and prove a no-go theorem: Dirac quantization of SCM collapses back to standard QFT and therefore hides covariance. We circumvent this problem by presenting a quantum-action--based quantization that yields a spacetime version of quantum mechanics (SQM), making covariance manifest for (interacting) QFTs. Finally, we show that this resolution is tied to a genuine spacetime generalization of the notion of quantum state, required by causality and closely connected to recent ``states over time'' proposals and, in dS/CFT-motivated settings, to microscopic notions of timelike entanglement and emergent time.

</details>


### [116] [Perfect transmission of a Dirac particle in one-dimension double square barrier](https://arxiv.org/abs/2602.23650)
*Xu Zhang,Qiang Gu*

Main category: quant-ph

TL;DR: 该研究揭示相对论性双势垒模型中完美Klein隧穿与共振透射存在连续过渡，且Klein区在亚临界势垒高度下仍可实现完美透射，挑战了二者机制根本不同的传统观点。


<details>
  <summary>Details</summary>
Motivation: 传统理论认为Klein隧穿（克莱因悖论）与非相对论性共振透射机制存在本质区别，但二者均表现为势垒上的完美透射现象，其内在关联性尚未被充分探索。

Method: 采用相对论性双势垒模型，结合束缚态分析与波包动力学模拟，系统研究透射特性随势垒参数的演化规律。

Result: 发现完美透射频谱曲線可从"above-barrier"区连续过渡至Klein区；在Klein区中，即使势垒高度低于临界值（subcritical），仍可实现完美透射。

Conclusion: 证实Klein隧穿与共振透射存在物理机制上的关联性，为理解克莱因悖论的本质提供了新视角，表明其可能源于相同的量子干涉效应。

Abstract: Dirac particles can undergo perfect transmission through a sufficiently high potential barrier in the Klein zone. Although the perfect Klein tunneling (often referred to as the Klein paradox) is similar to the non-relativistic resonant transmission which occurs only when the kinetic energy exceeds the barrier, the underlying mechanism is believed to be fundamentally distinct. In this work, we show that for the relativistic double-barrier model the perfect-transmission curve can pass continuously from the above-barrier zone to the Klein zone. Additionally, in the Klein zone, perfect transmission occurs even for subcritical barrier heights, supported by both bound-state analysis and wave-packet dynamics. These findings suggest a connection between perfect Klein tunneling and resonant transmission, and provide new insights into the physical nature of the Klein paradox.

</details>


### [117] [Harmonic sequence state-preparation](https://arxiv.org/abs/2602.23664)
*Benjamin Rempfer,Parker Kuklinski,Justin Elenewski,Kevin Obenland*

Main category: quant-ph

TL;DR: 该论文提出了一种高效量子电路，通过先制备线性振幅量子态再应用量子傅里叶变换（QFT），实现振幅正比于调和序列的量子态制备，并将其扩展至对角线为调和序列的矩阵块编码，电路成本主要由QFT决定。


<details>
  <summary>Details</summary>
Motivation: 调和序列振幅量子态在量子算法中具有重要应用价值，例如与经典信号处理中的锯齿波傅里叶系数类比，需高效制备方法以支持相关量子计算任务。

Method: 采用两步法：1）制备具有线性相关振幅的初始量子态；2）应用量子傅里叶变换将线性振幅转换为调和序列振幅。进一步将对角线为调和序列的矩阵通过块编码技术嵌入量子电路。

Result: 成功实现调和序列振幅量子态的高效制备及矩阵块编码，电路整体资源消耗主要由量子傅里叶变换的复杂度主导，验证了方法的有效性。

Conclusion: 该方法为调和序列相关量子态制备提供了可扩展方案，其效率取决于QFT实现，为量子算法中特定振幅结构的构建开辟了新途径。

Abstract: We demonstrate an efficient circuit to prepare a quantum state with amplitudes proportional to a harmonic sequence. We do this by first preparing a large quantum state with linearly related amplitudes and then applying a quantum Fourier transform; this has a direct analogy to the fact that the Fourier coefficients of a sawtooth wave follow a harmonic sequence. We then consider an extension of this problem by block-encoding a matrix with a harmonic sequence along its diagonal. The cost of both circuits is dominated by the costs associated with the quantum Fourier transform.

</details>


### [118] [Stabilizer Rényi entropy of 3-uniform hypergraph states](https://arxiv.org/abs/2602.23687)
*Daichi Kagamihara,Shunji Tsuchiya*

Main category: quant-ph

TL;DR: 研究3-一致超图态的非稳定子性（魔性），利用稳定子雷尼熵(SRE)度量，发现其可通过矩阵秩表达，大幅降低计算复杂度，并计算了一维和大规模超图态的SRE。


<details>
  <summary>Details</summary>
Motivation: 非稳定子性是实现通用量子计算的核心资源。超图态是图态的非稳定子推广，在量子优势、测量型量子计算和拓扑相研究中至关重要。然而，如何高效量化超图态的非稳定子性仍是开放问题。

Method: 采用稳定子雷尼熵(SRE)作为度量工具，针对仅由CCZ门生成的3-一致超图态，建立SRE与矩阵秩的解析关系。

Result: 发现3-一致超图态的SRE可用矩阵秩精确表达，将计算复杂度从O(2^(3N))降至O(N^3 * 2^N)；解析计算了一维超图态的SRE；给出了多种大规模3-一致超图态的数值结果。

Conclusion: 该工作为理解超图态非稳定子性提供了高效计算方法，将促进其在量子计算、量子优势和拓扑物态等领域的应用研究。

Abstract: Nonstabilizerness, also known as magic, plays a central role in universal quantum computation. Hypergraph states are nonstabilizer generalizations of graph states and constitute a key class of quantum states in various areas of quantum physics, such as the demonstration of quantum advantage, measurement-based quantum computation, and the study of topological phases. In this work, we investigate nonstabilizerness of 3-uniform hypergraph states, which are solely generated by controlled-controlled-Z gates, in terms of the stabilizer Rényi entropy (SRE). We find that the SRE of 3-uniform hypergraph states can be expressed using the matrix rank, which reduces computational cost from $\mathcal{O}(2^{3N})$ to $\mathcal{O}(N^3 2^{N})$ for $N$-qubit states. Based on this result, we exactly evaluate SREs of one-dimensional hypergraph states. We also present numerical results of SREs of several large-scale 3-uniform hypergraph states. Our results would contribute to an understanding of the role of nonstabilizerness in a wide range of physical settings where hypergraph states are employed.

</details>


### [119] [A new class of coherent states involving Fox-Wright functions and their generalization in the bicomplex framework](https://arxiv.org/abs/2602.23764)
*Snehasis Bera,Sourav Das,Abhijit Banerjee*

Main category: quant-ph

TL;DR: 该论文构建了一个基于Fox Wright函数的相干态完整理论框架，通过将该函数作为归一化函数，系统性地发展了离散谱和连续谱相干态，并成功将其推广到双复数领域，验证了这些态满足连续性、可归一化和单位分解性等核心数学要求。


<details>
  <summary>Details</summary>
Motivation: 推广相干态理论，探索Fox Wright函数作为归一化函数的可行性，并将理论框架扩展到双复数域以拓展其数学应用范围。

Method: 采用Fox Wright函数作为核心数学工具，通过离散谱到连续谱的极限过程构建连续谱相干态，并引入双复数参数化方法实现理论的全域推广。

Result: 成功构造出满足基本物理要求的Fox Wright相干态；推导出适用于连续谱的FW广义多参数ν函数；建立了双复数Fox Wright函数理论并验证其存在性；实现了相干态理论从实数域到双复数域的完整推广。

Conclusion: Fox Wright函数为相干态提供了强有力的数学基础，双复数扩展不仅保持了原有理论的全部核心性质，还为量子力学和数学物理开辟了新的研究方向。

Abstract: In this work, an extensive class of coherent states is introduced by taking the Fox Wright function as the normalization function. It is demonstrated that these states satisfy the key requirements of continuity, normalizability and resolution of unity. Furthermore, coherent states associated with the continuous spectrum are obtained through a discrete to continuous limiting procedure. Moreover, FW generalized multi parameter nu function is introduced and shown to act as the normalization function for the Fox Wright coherent states in the continuous spectrum. Later the Fox Wright function with bicomplex arguments has been introduced and its existence has been investigated. Bicomplex Fox Wright coherent states are also developed for the discrete spectrum based on this new function and their properties are analyzed. Subsequently, the results regarding Fox Wright coherent states are generalized to the bicomplex setting. In addition, a bicomplex FW generalized multi-parameter nu function is defined to demonstrate that it provides the normalization for these states in the continuous spectrum.

</details>


### [120] [Entanglement dynamics for atoms near a reflecting boundary: enhancement and suppression by environment-induced interactions](https://arxiv.org/abs/2602.23773)
*Ying Chen,Hongwei Yu,Jiawei Hu*

Main category: quant-ph

TL;DR: 研究反射边界附近两原子的纠缠动力学，发现环境诱导相互作用可增强或抑制纠缠，与自由空间情况截然不同。


<details>
  <summary>Details</summary>
Motivation: 探究反射边界诱导的环境相互作用如何影响两静态原子的纠缠动力学，揭示其与自由空间预测的本质差异。

Method: 理论分析两静态原子在理想反射边界附近的系统，计入原子-边界相互作用（位置依赖的Lamb位移）和场介导的原子-原子相互作用。

Result: 无论初始态如何，纠缠动力学与忽略能量移动效应的预测存在质和量的差异；几何参数决定环境相互作用是增强（提升最大并发度和纠缠寿命）还是抑制纠缠。

Conclusion: 与自由空间仅在某些初态下辅助纠缠不同，边界诱导的相互作用可在任意初态下增强或抑制纠缠，表现出全新的物理行为。

Abstract: We investigate how environment-induced interactions influence the entanglement dynamics of two static atoms placed near a perfectly reflecting boundary. In this setting, the environment-induced interactions include both atom-boundary contributions (position-dependent Lamb shifts) and the induced atom-atom interaction mediated by the field. We show that, regardless of the initial two-atom state, the entanglement dynamics differs qualitatively and quantitatively from predictions that neglect these energy-shift effects. Depending on the geometry and parameter regime, the environment-induced interactions can either enhance entanglement generation -- yielding a larger maximum concurrence and a longer entanglement lifetime -- or suppress it, reducing both the peak concurrence and the survival time. This behavior contrasts sharply with the free-space case, where the environment-induced atom-atom interaction affects entanglement generation only for a restricted class of initial states and does so in an exclusively assisting manner.

</details>


### [121] [MAFFT-inspired Quantum Shift-based Sequence Alignment and its Efficient Simulation on Decision Diagrams](https://arxiv.org/abs/2602.23848)
*Yusuke Kimura,Yutaka Takita*

Main category: quant-ph

TL;DR: 提出量子算法QShift-SA，利用Grover搜索加速多序列比对中的位移计算瓶颈，通过量子电路实现汉明距离计算，DD模拟器比传统模拟器快1000倍


<details>
  <summary>Details</summary>
Motivation: 经典MAFFT工具在多序列比对中需计算所有序列对的位移，计算量随序列数呈二次增长成为性能瓶颈

Method: 设计量子位移序列对齐(QShift-SA)算法：构建量子Oracle电路计算序列间汉明距离，结合Grover算法搜索最小距离的位移组合

Result: 决策图(DD)量子电路模拟器比状态向量和MPS模拟器快1000倍以上，可处理更大规模电路

Conclusion: 该方案针对性加速MAFFT的耗时效步骤而非整个流程，为量子计算在生物信息学中的实用化提供可行路径

Abstract: Multiple sequence alignment (MSA) is a core operation for comparing genome sequences and is widely used in bio-informatics. MAFFT, a practical MSA tool, repeatedly shifts a pair of sequences and computes a distance. Because the number of sequence pairs grows quadratically with the number of sequences, this procedure can become a bottleneck.
  We propose Quantum Shift-based Sequence Alignment (QShift-SA), which implements this ``shift-wise score computation'' as a gate-based quantum circuit and searches over shift amounts and sequence pairs using Grover algorithm. QShift-SA constructs an oracle circuit that compute the Hamming distance (the number of mismatches) between two sequences with data encoding, controlled shift, comparison, and addition. This oracle can search for candidates with small distances. QShift-SA does not aim to replace the full MSA workflow; instead, it targets the screening steps that often dominate the runtime in classical MAFFT as stated above.
  We evaluate circuit resources (number of qubits, gate count, and depth) and benchmark simulation time across multiple quantum circuit simulators. We find that a decision diagram (DD)-based quantum circuit simulator runs more than 1,000$\times$ faster than state-vector and MPS simulators and can handle larger circuits.

</details>


### [122] [Supermaps on generalised theories](https://arxiv.org/abs/2602.23865)
*Matt Wilson,James Hefford,Timothée Hoffreumon*

Main category: quant-ph

TL;DR: 本研究通过Yoneda引理为范畴超图建立了系统化的数学框架，将任意物理理论中的高阶操作定义为通道-态对偶性的具体表示，消除了定义模糊性，并成功应用于盒世界和高阶实量子理论。


<details>
  <summary>Details</summary>
Motivation: 在任意电路理论中定义合适的高阶超图操作存在猜测性和模糊性，缺乏系统化的数学基础。

Method: 运用范畴论中的Yoneda引理，将范畴超图通过通道-态对偶性进行具体化表示。

Result: 建立了Yoneda引理与范畴超图的关系；证明了盒世界的高阶过程是其特例；提出了稳定高阶实量子理论的定义。

Conclusion: 该框架为各类物理理论中的超图提供了无歧义、系统化的定义方法，统一了不同理论间的高阶操作描述。

Abstract: Categorical supermaps generalise higher-order quantum operations from finite-dimensional quantum theory to arbitrary circuit theories. In this paper, we establish the Yoneda lemma for categorical supermaps, which states that whenever a physical theory has a suitable notion of channel-state duality, then categorical supermaps on that theory can be concretely represented in terms of that duality. This lemma eliminates any guesswork or ambiguity when defining the appropriate notion of supermap for these theories. As a concrete application, we show that the recently proposed higher-order processes on boxworld can be obtained as a particular instance of categorical supermaps, and put forward a stable definition of higher-order real quantum theory.

</details>


### [123] [Non-commutative Index of Measurement-only Entanglement Phase Transition](https://arxiv.org/abs/2602.23868)
*Zhichen Huang,Chunxiao Du,Yang Zhou,Zhisong Xiao*

Main category: quant-ph

TL;DR: This paper develops a quantitative non-commutative index to explain entanglement phase transitions in measurement-only models, revealing universal scaling laws between critical non-commutativity and measurement range.


<details>
  <summary>Details</summary>
Motivation: While measurement-only models show clear entanglement phase transitions, the fundamental mechanism of non-commutativity among multi-site measurements has only been qualitatively understood, lacking a quantitative framework.

Method: The authors introduce a quantitative non-commutative index and apply it to three representative measurement-only models to systematically analyze the role of non-commutativity in entanglement dynamics.

Result: The volume-law phase emergence is governed by non-commutative structure; transition points are determined by critical non-commutativity levels; universal linear scaling exists between critical non-commutativity and measurement range, independent of microscopic details.

Conclusion: This work provides a quantitative foundation for understanding measurement-only entanglement phase transitions, revealing the universal role of non-commutativity across different models.

Abstract: Measurement-only models offer an ideal platform for exploring entanglement dynamics in the absence of unitary evolution. Despite extensive numerical evidence for entanglement phase transitions in measurement-only dynamics, the underlying mechanism attributed to non-commutativity among multi-site projective measurements has remained qualitative and coarse-grained. In this work, we identify a quantitative non-commutative index. By applying this index into three representative measurement-only models, we elucidate the role of non-commutativity in measurement-only dynamics: the emergence of a volume-law phase is governed by the non-commutative structure of the measurement ensemble, while the transition point is quantitatively determined by the amount of critical non-commutativity. More strikingly, the critical non-commutativity exhibits a universal linear scaling with the measurement range, independent of the microscopic details of the measurement ensembles. Our findings deepen the understanding of the fundamental mechanism behind the measurement-only entanglement phase transition.

</details>


### [124] [Four Party Absolutely Maximal Contextual Correlations](https://arxiv.org/abs/2602.23883)
*Nripendra Majumdar*

Main category: quant-ph

TL;DR: 该论文将量子非局域性拓展至上下文性框架，提出"绝对最大上下文关联"（AMCC）概念以类比最大纠缠态，揭示多体系统中关联性的新分类。通过层论与约束满足方法，发现四体系统中上下文关联与纠缠态存在本质差异，并构造出首个"最大上下文但非最大边缘"的关联实例。


<details>
  <summary>Details</summary>
Motivation: 传统研究聚焦于量子纠缠，但Kochen-Specker定理表明上下文性才是更基础的非经典特性。现有文献对多体系统中"最大关联"的定义缺乏上下文视角，且未解决四体以上系统的关联分类问题。

Method: 采用层论（sheaf theory）框架形式化上下文关联，定义上下文分数（CF）量化语境性程度；结合约束满足问题（CSP）与奇偶校验方法，构建多体关联模型并分析其极值特性。

Result: 1) 提出AMCC概念（兼具最大上下文性与最大边缘性）\n2) 发现四体系统中AMCC与AME态不存在对应关系\n3) 通过CSP框架构造出新型关联：最大上下文但非最大边缘的实例。

Conclusion: 该工作建立了多体上下文关联的理论框架，揭示了上下文性与纠缠的本质差异，为量子信息处理提供了新的资源分类标准，同时表明约束满足方法是研究复杂量子关联的有效工具。

Abstract: The Kochen Specker theorem revealed contextuality as a fundamental nonclassical feature of nature. Nonlocality arises as a special case of contextuality, where entangled states shared by space like separated parties exhibit nonlocal correlations. The notion of maximality in correlations, analogous to maximal entanglement, is less explored in multipartite systems. In our work, we have defined maximal correlations in terms of contextual models, which are analogous to absolutely maximally entangled (AME) states. Employing the sheaf theoretic framework, we introduce maximal contextual correlations associated with the corresponding maximal contextual model. The formalism introduces the contextual fraction CF as a measure of contextuality, taking values from 0 (noncontextual) to 1 (fully contextual). This enables the formulation of a new class of correlations termed absolutely maximal contextual correlations (AMCC), which are both maximally contextual and maximal marginals. In the bipartite setting, the canonical example is the Popescu Rohrlich (PR) box, while in the tripartite case, it includes Greenberger Horne Zeilinger (GHZ) correlations and three way nonlocal correlations. In this work, we extend these findings to four party correlations. Notably, no AME state exists for four qubits, which introduces a subtle difference between AMCC and AME. The construction follows the constraint satisfaction problem (CSP) and parity check methods. In particular, the explicit realization of a non AMCC correlation that is maximally contextual yet not maximal marginal is obtained within the CSP framework.

</details>


### [125] [Characterization of Josephson Junction Aging and Annealing Under Different Environments](https://arxiv.org/abs/2602.23888)
*Rangga P. Budoyo,Rasanayagam S. Kajen,Bing Wen Cheah,Long H. Nguyen,Rainer Dumke*

Main category: quant-ph

TL;DR: 约瑟夫森结的电阻老化遵循对数规律，存储环境显著影响老化速度，氮气环境中退火可降低电阻而空气环境在200°C时电阻反常升高，且电阻无法降至初始值以下。


<details>
  <summary>Details</summary>
Motivation: 理解约瑟夫森结的老化行为及退火对结电阻的影响，对构建大规模超导量子处理器至关重要。

Method: 对比研究不同存储条件（空气/氮气/真空）下结电阻在2-3个月内的老化规律，并测试氮气与空气环境中250°C以内的热退火对电阻的调控效果。

Result: 1) 老化曲线呈对数关系，老化幅度由制备条件决定，老化速度由存储条件决定；空气存储老化最快；2) 氮气退火在所有测试温度下均降低电阻，空气退火在200°C时电阻升高而在250°C时降低；3) 电阻无法降至初始值以下，存在调控下限。

Conclusion: 存储条件是控制老化速度的关键，退火环境显著影响电阻调控方向，且结电阻存在不可突破的下限，这对量子处理器制备工艺优化具有重要指导意义。

Abstract: Understanding the aging behavior of Josephson junctions and the effect of annealing on junction resistances is important in building large-scale superconducting quantum processors. Here we study the effects of aging of Josephson junctions under different storage conditions from immediately after fabrication up to 2 to 3 months. We find that the aging curve follows a logarithmic curve, with the aging amplitude mainly determined by fabrication conditions and the aging speed determined by storage conditions. Junctions stored at ambient laboratory conditions aged faster compared to junctions stored in a nitrogen atmosphere or vacuum, with the aging speed appreciably changes when the storage condition changed. We also compared the effect of thermal annealing under nitrogen environment with annealing under ambient conditions up to 250$^\circ$ C. We find that under nitrogen environment, the resistances decreased at all temperatures tested, while under ambient environment the resistances increased at 200$^\circ$ C and decreased at 250$^\circ$ C instead. We were unable to decrease the resistance below the initial-time resistance, suggesting a lower limit on the range of resistance tuning.

</details>


### [126] [Continuous-Time Quantum Walk on Locally Infinite Graph](https://arxiv.org/abs/2602.23970)
*Ce Wang*

Main category: quant-ph

TL;DR: 研究连续时间量子行走模型的时间反演对称性，发现其可由酉算子而非经典的反酉算子描述


<details>
  <summary>Details</summary>
Motivation: 时间反演对称性是物理学基本概念，经典理论中量子系统的时间反演对称性由反酉算子描述。本论文旨在探索特殊局部无穷图上连续时间量子行走模型是否遵循这一经典理论。

Method: 构建一个特殊局部无穷图上的连续时间量子行走模型，分析其谱性质，并研究该模型的时间反演对称性。

Result: 发现该模型的时间反演对称性可直接用酉算子描述，与经典理论中的反酉算子形成鲜明对比，并证明了其他相关结论。

Conclusion: 特定量子行走模型的时间反演对称性可由酉算子描述，这一反直觉结果揭示了时间反演对称性在量子行走系统中的新表现形式，拓展了对称性理论的适用范围。

Abstract: Time-reversal symmetry is of fundamental importance to physics. In the classical theory of time-reversal symmetry, the time-reversal symmetry of a quantum system is described by an anti-unitary operator, which is known as the time-reversal operator of the system. In this paper, we introduce and study a model of continuous-time quantum walk on a special locally infinite graph. After examining its spectral property, we investigate the time-reversal symmetry of the model. To our surprise, we find that its time-reversal symmetry can be described directly by a unitary operator, which contrasts sharply with that in the classical theory of time-reversal symmetry. Some other related results are also proven.

</details>


### [127] [Coherent Control of Population and Quantum Coherence in Superconducting Circuits](https://arxiv.org/abs/2602.23975)
*Madan Mohan Mahana,Gunjan Yadav,Tarak Nath Dey*

Main category: quant-ph

TL;DR: 宏观量子系统研究进展


<details>
  <summary>Details</summary>
Motivation: 突破量子力学仅限微观领域的传统认知，探索宏观尺度下量子相干控制的可行性

Method: 综述近年来在大型量子系统中实现粒子数分布相干调控及吸收/折射率操控的研究进展

Result: 证实了宏观可见物体中实现多能级量子态相干控制及光学性质调控的技术突破

Conclusion: 宏观量子系统操控已从理论设想进入实验实现阶段，为量子技术向宏观尺度拓展奠定基础

Abstract: Quantum mechanics, with its counterintuitive principles and probabilistic nature, has long been confined to the microscopic realm of atoms and photons. Yet, recent breakthroughs have pushed the boundaries of quantum behavior into the macroscopic world, where objects are visible to the naked eye and governed by classical physics. This review article traces the extraordinary progress toward achieving coherent control of population distributions among multiple quantum levels, as well as manipulation of absorption and refractive index, in such large-scale quantum systems, a feat once considered beyond reach.

</details>


### [128] [Large-scale portfolio optimization on a trapped-ion quantum computer](https://arxiv.org/abs/2602.23976)
*Alejandro Gomez Cadavid,Ananth Kaushik,Pranav Chandarana,Miguel Angel Lopez-Ruiz,Gaurav Dev,Willie Aboumrad,Qi Zhang,Claudio Girotto,Sebastián V. Romero,Martin Roetteler,Enrique Solano,Marco Pistoia,Narendra N. Hegade*

Main category: quant-ph

TL;DR: 本文提出了一种硬件感知分解的量子计算方法，用于解决大规模带基数约束的投资组合选择问题，通过相关性引导的聚类和BF-DCQO算法在64量子比特trapped-ion处理器上实现了优于随机基线的风险收益权衡


<details>
  <summary>Details</summary>
Motivation: 大规模带基数约束的投资组合优化是计算难题，经典方法扩展性有限。量子计算虽具潜力，但需适配硬件量子比特限制，通过分解方法实现规模化求解

Method: 端到端流程：RMT去噪与社区检测识别资产组→相关性引导贪心分割控制集群规模→BF-DCQO量子算法求解QUBO子问题→两阶段后处理（快速修复+基数保持交换搜索）。在250个S&P 500资产上实验，64量子比特Barium系统执行

Result: 更大可执行子问题规模降低分解误差，系统性提升目标函数值和风险收益比，显著优于相同后处理下的随机基线

Conclusion: 建立了硬件验证的量子金融优化扩展路径，揭示了问题规模、电路成本与解质量之间的核心权衡关系

Abstract: We present an end-to-end pipeline for large-scale portfolio selection with cardinality constraints and experimentally demonstrate it on trapped-ion quantum processors using hardware-aware decomposition. Building on RMT-based correlation-matrix denoising and community detection, we identify correlated asset groups and introduce a correlation-guided greedy splitting scheme that caps each cluster by the executable qubit budget. Each cluster defines a hardware-embeddable QUBO subproblem that we solve using bias-field digitized counterdiabatic quantum optimization (BF-DCQO), a non-variational method that avoids classical parameter-training loops. We recombine low-energy candidates into global portfolios and enforce feasibility with a two-stage post-processing routine: fast repair followed by a cardinality-preserving swap local search. We benchmark the workflow on a 250-asset universe taken from the S&P 500 and execute subproblems on a 64-qubit Barium development system similar to the forthcoming IonQ Tempo line. We observe that larger executable subproblem sizes reduce decomposition error and systematically improve final objective values and risk-return trade-offs relative to randomized baselines under identical post-processing. Overall, the results establish a hardware-tested route for scaling financial optimization problems, defined by a trade space in which executable problem size and circuit cost are balanced against the resulting solution quality.

</details>


### [129] [3D Integrated Embedded Filters for Superconducting Quantum Circuits](https://arxiv.org/abs/2602.24003)
*Waqas Ahmad,Gioele Consani,Mohammad Tasnimul Haque,Jacob Dunstan,Brian Vlastakis*

Main category: quant-ph

TL;DR: This paper presents a novel off-chip microwave Purcell filter integrated into a multilayer PCB for superconducting qubits, which removes filters from the qubit substrate, improves scalability, and achieves 1000x better qubit isolation while maintaining high coherence (T1 of 84 μs) in a 35-qubit device.


<details>
  <summary>Details</summary>
Motivation: Microwave filtering is crucial for superconducting qubits to achieve high coherence and fast state detection. Existing on-chip filters limit scalability and increase device complexity. There's a need for off-chip solutions that can support large-scale quantum processors with multiplexed readout capabilities.

Method: The researchers designed and implemented an embedded microwave Purcell filter in a multilayer printed circuit board (PCB) that is separate from the qubit substrate. They used electromagnetic simulations to predict performance and experimentally validated the design under cryogenic conditions with a 35-qubit superconducting quantum processor.

Result: The PCB-based filter successfully coupled up to nine readout resonators for multiplexed readout. Simulations predicted a thousand-fold improvement in qubit isolation. Experimental results showed a median qubit T1 coherence time of 84 μs, which matched the expected radiative limit, confirming effective Purcell filtering and compatibility with high-coherence qubits.

Conclusion: The off-chip PCB integration approach successfully addresses scalability challenges in superconducting quantum computing by reducing qubit substrate complexity while maintaining high coherence through effective Purcell filtering, demonstrating a viable path toward large-scale quantum processors.

Abstract: Microwave filtering for superconducting qubits is a key element of quantum computing technology, enabling high coherence and fast state detection. This work presents the design and implementation of novel microwave Purcell filters for superconducting quantum circuits, integrated within a multilayer printed circuit board (PCB). The off-chip design removes all filter components from the qubit substrate, reducing device complexity, improving layout footprint and allowing better scalability to large qubit counts. Each embedded filter can couple up to nine readout resonators, enabling efficient multiplexed readout. Electromagnetic simulations of the filter predict a thousand-fold improvement in qubit isolation from the readout port. The design was experimentally validated under cryogenic conditions in conjunction with a 35-qubit device, demonstrating compatibility of the PCB-based filter with high-coherence superconducting qubits. The comparison of the measured qubit median T1 of 84 $μ$s with the expected radiative limit from electromagnetic simulations validated the presence of Purcell filtering in the system.

</details>


### [130] [Saturable nonlinearities in a driven-dissipative bosonic quantum battery](https://arxiv.org/abs/2602.24048)
*João P. R. Leonel,Paulo A. Brandão*

Main category: quant-ph

TL;DR: This paper studies how saturable nonlinearity affects quantum battery performance, finding it enhances maximum stored energy and provides controllable tuning of work extraction despite dissipation losses.


<details>
  <summary>Details</summary>
Motivation: To understand how saturable nonlinearity (distinct from Kerr-type) impacts charging dynamics and ergotropy in a realistic quantum battery with dissipation.

Method: Solving a Lindblad master equation to analyze time evolution of energy and ergotropy in a single bosonic mode quantum battery with saturable nonlinearity, coherent driving, and dissipation.

Result: The saturable nonlinearity creates a bounded, nonlinear energy spectrum with increased level density, enhancing maximum stored energy and modifying ergotropy generation in the presence of losses. It significantly affects both transient charging behavior and steady-state properties across a broad parameter range.

Conclusion: The interplay between dissipation and bounded spectral nonlinearity offers a controllable mechanism to tune energy storage and work extraction in bosonic quantum batteries, demonstrating the beneficial role of saturable nonlinearities for quantum energy storage design.

Abstract: We investigate the charging of a nonlinear quantum battery consisting of a single bosonic mode subject to a saturable nonlinearity, coherent driving, and dissipation. In contrast to Kerr-type anharmonicities, the saturable interaction induces a bounded and nonlinear distortion of the energy spectrum, leading to a progressive increase in the density of energy levels. We analyze the time evolution of the energy and ergotropy of the battery by solving a Lindblad master equation and show that the nonlinear spectral structure significantly affects both transient charging behavior and steady-state properties. Our results reveal that, for a broad range of parameters, the saturable nonlinearity enhances the maximum stored energy and modifies the ergotropy generation in the presence of losses. The interplay between dissipation and bounded spectral nonlinearity provides a controllable mechanism to tune energy storage and work extraction in bosonic quantum batteries.

</details>


### [131] [Experimental implementation of a discrete-time quantum walk on biological networks](https://arxiv.org/abs/2602.24053)
*Viacheslav Dubovitskii,Filippo Utro,Aritra Bose,Laxmi Parida,Sabrina Maniscalco,Sergey N. Filippov*

Main category: quant-ph

TL;DR: This paper introduces a symmetry-sector encoding algorithm with noise mitigation that enables quantum walk experiments on biological networks using current quantum hardware, achieving the largest such implementation to date.


<details>
  <summary>Details</summary>
Motivation: Current noisy quantum computers cannot run conventional quantum walk algorithms due to decoherence and prohibitively deep circuits required for dense graph encodings.

Method: Leverages symmetry-sector encoding to trade circuit depth for qubits, combined with symmetry-respecting postselection as a noise-mitigation strategy.

Result: Executed quantum walks on graphs up to 17 nodes/20 edges using 40 qubits with 87% Hellinger fidelity over 7 steps - the largest superconducting quantum walk experiment. Demonstrated application in prioritizing disease-associated genes via protein interaction networks.

Conclusion: The framework offers a scalable approach for near-term quantum study of biological networks, with potential for investigating larger networks in the pre-fault-tolerant quantum computing era.

Abstract: Quantum walks provide a versatile framework for probing the structural and dynamical properties of complex systems ranging from biological networks to synthetic materials. However, their realization on current noisy pre-fault-tolerant quantum computers is fundamentally limited by decoherence. Conventional dense encodings of graph structures require prohibitively deep circuits, making them incompatible with existing hardware. Here we introduce an algorithm that leverages symmetry-sector encoding and trades circuit depth for qubits, while integrating symmetry-respecting postselection as an effective noise-mitigation strategy. This combination enables us to execute practical quantum-walk circuits for biological networks on actual quantum hardware. We benchmark the proposed methodology against known state-of-the-art circuit architectures, highlighting significant reduction of circuit depth in our approach at the cost of moderate qubit overhead. Utilizing 40 qubits, we implement quantum walks on complex graphs containing up to 17 nodes and 20 edges -- the largest experiment on superconducting hardware to date, with the Hellinger fidelity exceeding 87% throughout 7 steps. We present a case study that illustrates how experimentally obtained quantum-walk dynamics on a protein-protein-interaction network can be applied to prioritizing disease-associated genes. We discuss the framework scalability in the pre-fault-tolerant era and its potential for studying larger biological networks.

</details>


### [132] [Optimized Compilation for Distributed Quantum Computing](https://arxiv.org/abs/2602.24062)
*Michele Bandini,Davide Ferrari,Stefano Carretta,Michele Amoretti*

Main category: quant-ph

TL;DR: This paper proposes a greedy algorithm for distributed quantum computing (DQC) that minimizes EPR pair usage by grouping non-local gates to share TeleGate operations and reordering commutative gates, significantly reducing circuit depth and EPR consumption even under low EPR pair lifetime conditions.


<details>
  <summary>Details</summary>
Motivation: Current quantum processors have limited qubits, while many practical quantum algorithms require more qubits. Distributed quantum computing (DQC) is a scalable solution, but optimizing EPR pair consumption (critical for inter-processor communication) is essential due to their rapid quality deterioration.

Method: A greedy algorithm that: (1) explores circuit structure to group non-local gates sharing a single TeleGate operation (reducing EPR pairs), and (2) dynamically reorders commutative gates to maximize EPR sharing opportunities.

Result: Compiled circuits show reduced depth and EPR usage. The approach delivers optimization benefits even under low EPR pair lifetime assumptions, and allows adjustable optimization levels based on target quantum network characteristics.

Conclusion: The proposed greedy grouping method effectively minimizes EPR consumption in DQC, making it practical for near-term quantum networks with limited entanglement resources. This compiler optimization is crucial for scaling quantum computations beyond single-processor limits.

Abstract: In many practical applications, quantum algorithms require several qubits, significantly more than those available with current noisy intermediate-scale quantum processors. Distributed quantum computing (DQC) is considered a scalable approach to increasing the number of available qubits for computational tasks. In the DQC setting, a quantum compiler must find the best partitioning for the quantum algorithm and then perform smart non-local operations scheduling to optimize the consumption of Einstein-Podolsky-Rosen (EPR) pairs. In this work, the focus is on minimizing the use of EPR pairs when the circuit structure allows for multiple non-local gates to utilize a single TeleGate operation. This is achieved by using a greedy algorithm that explores the circuit and groups together the gates that could share an EPR pair while also changing the order of commutative gates when necessary. With this preliminary pass, the compiled circuits show reduced depth and EPR usage. Since the quality of each EPR pair quickly deteriorates, the number of non-local gates using the same EPR pair should also be bounded. This means that, depending on the features of the target quantum network, the user can achieve different levels of optimization. Here, it is shown that this approach brings benefits even while assuming a low EPR pair lifetime.

</details>


### [133] [Gaussian resource based heralded entangled state generation enhanced by photon addition and subtraction](https://arxiv.org/abs/2602.24077)
*Yun-Long Cao,Xiao-Ye Xu,Chuan-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: 提出一种基于高斯源并结合光子增减操作的信 heralded 纠缠生成方案。通过单模压缩、线性干涉仪和辅助模式条件光子数测量，概率性生成双轨编码的Bell、GHZ和W态。光子增减显著增强了输出态的非经典性，提高了生成性能，同时对参数扰动具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 利用高斯资源结合非高斯操作，实现可扩展、实验可行的高保真度纠缠生成，解决传统方案在成功概率、计算效率和抗噪声性能之间的权衡问题。

Method: 结合单模压缩、线性干涉仪和辅助模式条件光子数测量，通过光子增减操作增强高斯源的量子特性，系统优化压缩参数和干涉仪设置以最大化成功概率和保真度。

Result: 光子增减操作显著提升输出态非经典性，纠缠生成性能优于纯高斯方案，同时保持与单光子源模型相当的计算效率；方案对实验参数扰动具有稳定鲁棒性。

Conclusion: 该工作为利用高斯资源和非高斯操作实现可扩展、高效、鲁棒的多粒子纠缠生成提供了通用且实验可行的框架。

Abstract: We propose a heralded entanglement generation scheme based on Gaussian sources augmented with photon addition and subtraction operations. By combining single-mode squeezing, linear interferometers, and conditional photon-number measurements on ancillary modes, our model probabilistically generates dual-rail encoded Bell, GHZ, and W states. We systematically optimize the squeezing parameters and interferometer settings to maximize both the heralding success probability and the fidelity with the target states. Our results show that the inclusion of photon addition and subtraction significantly enhances the non-classicality of the output states, leading to improved generation performance, while maintaining computational efficiency comparable to single-photon source models. We further analyze the robustness of the scheme under parameter perturbations, demonstrating stable performance against realistic experimental imperfections. This work provides a versatile and experimentally feasible framework for scalable heralded entanglement generation using Gaussian resources with non-Gaussian operations.

</details>


### [134] [Estimating the performance boundary of Gottesman-Kitaev-Preskill codes and number-phase codes](https://arxiv.org/abs/2602.24102)
*Kai-Xuan Wen,Dong-Long Hu,Shengyong Li,Ze-Liang Xiang*

Main category: quant-ph

TL;DR: 该研究量化比较了GKP和NP玻色量子纠错码在光子损耗-退相位噪声下的性能边界，发现当退相位强度比损耗强度低约两个数量级时存在明显性能交叉点，并提出了可扩展的玻色码基准测试方法。


<details>
  <summary>Details</summary>
Motivation: 尽管GKP和NP码两种玻色量子纠错编码已被广泛研究，但在实际物理噪声（如光子损耗和退相位）条件下，何种编码具有本质性能优势仍不明确，缺乏定量性能边界评估。

Method: 通过优化两类编码的参数，在一般光子损耗-退相位噪声模型下进行定量性能比较，建立性能边界分析框架。

Result: 发现退相位强度约为光子损耗强度的1/100时出现性能交叉点，两类编码在不同噪声 regime 中展现出明确的分界优势：损耗主导时GKP更优，退相位相对显著时NP更优。

Conclusion: 工作不仅揭示了两种编码的本质适用边界，更建立了实用的玻色码基准测试与参数优化方法论，为实验中选择和部署抗噪声玻色编码提供了具体指导。

Abstract: Bosonic quantum error-correcting codes encode logical information in a harmonic oscillator, with the Gottesman-Kitaev-Preskill (GKP) and number-phase (NP) codes representing two fundamentally different encoding paradigms. Although both have been extensively studied, it remains unclear under what physical noise conditions (including photon loss and dephasing) one encoding intrinsically outperforms the other. Here we estimate a quantitative performance boundary between GKP and NP codes under general photon loss-dephasing noise. By optimizing code parameters within each encoding family, we identify the noise regimes in which each code exhibits a fundamental advantage. In particular, we find that the crossover occurs when the dephasing strength is approximately two orders of magnitude smaller than the loss strength, revealing a sharp separation between operational regimes. Beyond this specific comparison, our work establishes a practical and extensible methodology for benchmarking bosonic codes and optimizing their parameters, providing concrete guidance for the experimental selection and deployment of bosonic encodings in realistic noise environments.

</details>


### [135] [Complexity of Satisfiability in Kochen-Specker Partial Boolean Algebras](https://arxiv.org/abs/2602.24164)
*Anuj Dawar,Nihil Shah*

Main category: quant-ph

TL;DR: 本文研究量子力学中部分布尔代数的命题可满足性问题的计算复杂度，证明其复杂度随希尔伯特空间维度和类型不同，从NP完全到实数存在理论完全，直至不可判定。


<details>
  <summary>Details</summary>
Motivation: Kochen-Specker定理通过希尔伯特空间投影算符的部分布尔代数结构确立了量子隐变量理论中的语境性。本文旨在探究这些量子逻辑结构的命题可满足性问题所面临的计算复杂性。

Method: 分析三类部分布尔代数的可满足性问题：非平凡部分布尔代数、有限维希尔伯特空间投影算符生成的部分布尔代数（实数和复数情形），并在证明中使用Kochen-Specker集合作为计算归约的装置。

Result: 主要结果：1) 非平凡部分布尔代数的可满足性是NP完全的。2) 实数域上维数>2且复数域上维数>3的希尔伯特空间，其可满足性问题是实数存在理论完全的。3) 相应维度下的量子同态判定问题也具有相同的复杂度。4) 所有希尔伯特空间和所有有限维希尔伯特空间的可满足性问题不可判定。

Conclusion: 量子命题逻辑的可满足性复杂度呈现出丰富的层次结构，揭示了量子语境性与计算逻辑基础问题之间的深刻联系。该问题在低维时是多项式时间可解的，但在稍高维度就跃升至实数存在理论层级，而一般情形下则是不可判定的。

Abstract: The Kochen-Specker no-go theorem established that hidden-variable theories in quantum mechanics necessarily admit contextuality. This theorem is formally stated in terms of the partial Boolean algebra structure of projectors on a Hilbert space. Each partial Boolean algebra provides a semantics for interpreting propositional logic. In this paper, we examine the complexity of propositional satisfiablity for various classes of partial Boolean algebras. We first show that the satisfiability problem for the class of non-trivial partial Boolean algebras is NP-complete. Next, we consider the satisfiability problem for the class of partial Boolean algebras arising from projectors on finite dimensional Hilbert spaces. For real Hilbert spaces of dimension greater 2 and any complex Hilbert spaces of dimension greater than 3, we demonstrate that the satisfiablity problem is complete for the existential theory of the reals. Interestingly, the proofs of these results make use of Kochen-Specker sets as gadgets. As a corollary, we conclude that deciding quantum homomorphism in these fixed dimensions are also complete for the existential theory of the reals. Finally, we show that the satisfiability problems for the class of all Hilbert spaces and all finite-dimensional Hilbert spaces is undecidable.

</details>


### [136] [Geometric Resilience of Quantum LiDAR in Turbulent Media: A Wasserstein Distance Approach](https://arxiv.org/abs/2602.24280)
*Arnaud Coatanhay,Angélique Drémeau*

Main category: quant-ph

TL;DR: 提出量子瓦瑟斯坦距离(W₂)作为高损耗量子传感的新度量标准，解决传统保真度指标在湍流环境中快速饱和失效的问题，推导出量子优势临界阈值并验证其在衰落信道中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有量子LiDAR在真实高损耗/湍流场景中，标准量子度量(如保真度、Chernoff界)会快速饱和，无法提供系统优化所需的梯度信号。

Method: 采用量子最优传输理论，提出基于相位空间传输成本的W₂距离度量；通过解析推导确定量子优势临界阈值；利用蒙特卡洛模拟验证其在衰落信道中的动态范围优势。

Result: 1) W₂保持对信道透射率的线性响应(即使在量子态接近热噪声时)；2) 推导出透射率临界阈值公式(由环境噪声/信号比决定)；3) 在蒙特卡洛模拟中展现宽动态范围且无保真度指标的数值不稳定性。

Conclusion: W₂为散射介质中的自适应传感提供几何框架，连接量子最优传输理论与实际接收机设计，推动量子传感在真实环境中的应用。

Abstract: Quantum-enhanced LiDAR, exploiting squeezed states of light, promises significant sensitivity gains over classical protocols. However, in realistic scenarios characterized by high optical losses and atmospheric turbulence, standard figures of merit, such as quantum fidelity or the quantum Chernoff bound, saturate rapidly, failing to provide a usable gradient for system optimization. In this work, we propose the Quantum Wasserstein Distance of order 2 ($W_2$) as a robust geometric metric for lossy quantum sensing. Unlike overlap-based measures, $W_2$ quantifies the transport cost in phase space and maintains a linear response to channel transmissivity, even in regimes where the quantum state is virtually indistinguishable from thermal noise. We derive an analytical threshold for the quantum advantage, demonstrating that squeezing is only beneficial when the transmissivity exceeds a critical value determined by the environmental noise-to-signal ratio. Furthermore, using Monte-Carlo simulations of a fading channel, we show that $W_2$ acts as a high-fidelity estimator of instantaneous link quality, exhibiting a wide dynamic range immune to the numerical instabilities of fidelity-based metrics. This geometric framework bridges the gap between quantum optimal transport and practical receiver design, paving the way for adaptive sensing in scattering media.

</details>
