<div id=toc></div>

# Table of Contents

- [nlin.CD](#nlin.CD) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 11]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 4]
- [quant-ph](#quant-ph) [Total: 58]
- [cs.AI](#cs.AI) [Total: 20]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [cs.LG](#cs.LG) [Total: 51]


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [1] [The relation between classical and quantum Lyapunov exponent and the bound on chaos in classically chaotic quantum systems](https://arxiv.org/abs/2512.19869)
*Fabian Haneder,Gerrit Caspari,Juan Diego Urbina,Klaus Richter*

Main category: nlin.CD

TL;DR: 该论文研究了量子混沌系统中无序时间顺序对易子（OTOC）的增长速率，通过Wigner-Moyal展开和统计物理的系综等价性，揭示了OTOC增长速率与自由度数和温度的关系，在深量子区域发现了最大快速混沌现象。


<details>
  <summary>Details</summary>
Motivation: OTOC作为量子混沌和量子引力研究的关键诊断工具，其增长速率与经典李雅普诺夫指数和量子态密度的关系尚未得到充分理解。作者旨在为具有混沌经典极限的多体系统提供一致的OTOC增长速率理论框架。

Method: 采用Wigner-Moyal展开和统计物理的系综等价性，构建了OTOC增长速率的理论框架。将该方法应用于量子化的高维双曲运动系统，计算了OTOC增长速率Λ作为自由度f和逆温度β的函数。

Result: 发现标度化增长速率Λ/f可以用fβ的普适函数描述，并显示出从经典行为到量子行为的交叉转变。在深量子区域（无限f），发现了Maldacena-Shenker-Stanford混沌界限的最大快速混沌现象。

Conclusion: 该研究阐明了通过量子贡献到平均态密度的非微扰机制导致混沌界限饱和，为该系统作为二维量子引力的对偶提供了进一步支持，首次展示了在具有明确定义经典哈密顿极限的量子混沌系统中实现最大快速混沌，无需依赖外部机制如无序平均。

Abstract: Out-of-Time-Ordered Commutators (OTOCs), representing a key diagnostic for scrambling as a facet of short-time quantum chaos, have attracted wide-ranging interest, from many-body physics to quantum gravity. By means of a suitable form of the Wigner-Moyal expansion, and invoking ensemble equivalence in statistical physics, we provide a consistent approach to the growth rate of the OTOC for many-body systems with chaotic classical limit where both the classical Lyapunov exponent and the quantum nature of the density of states enter. Applying this construction to quantized high-dimensional hyperbolic motion, i.e., a quantum chaotic system that exhibits gravity-like correlation functions in the late-time regime, we compute the OTOC growth rate $Λ$ as a function of the number of degrees of freedom, $f$, and inverse temperature, $β$.
  We show that the scaled growth rate, $Λ/f$, can be described by a universal function of $f β$ and displays a cross-over from classical to quantum behavior as we increase $f$ and/or lower the temperature. In the deep quantum regime of infinite $f$, we find maximally fast scrambling in the sense of the Maldacena-Shenker-Stanford bound on chaos. This elucidates the non-perturbative mechanism underlying the saturation of the bound via quantum contributions to the mean density of states, and it provides further support for this dynamical system as a dual to two-dimensional quantum gravity. In this way, we present first evidence of maximally fast scrambling in a quantum chaotic system with a well-defined classical Hamiltonian limit, without invoking any external mechanism such as (disorder) averaging.

</details>


### [2] [Systematic Classification of History-Dependent Invariants in the Lorenz System: Regularization Classes and Dynamical Signatures](https://arxiv.org/abs/2512.20390)
*B. A. Toledo*

Main category: nlin.CD

TL;DR: 该研究系统分类了洛伦兹系统中的历史依赖动力学不变量，识别出18个不同不变量，分为三类正则化类别，并揭示了各类别在动力学特征上的差异。


<details>
  <summary>Details</summary>
Motivation: 基于最近在洛伦兹系统中发现的历史依赖动力学不变量，本研究旨在系统分类完整的此类守恒量家族，理解它们如何约束轨迹历史并揭示不同的动力学特征。

Method: 在增广相空间中分析所有24种排列，识别出18个不同的不变量(K₁-K₁₈)，分为三类正则化类别：I类(1abc)、II类(2abc)和III类(3abc)。通过正则化变量vₙ = p·uₙ消除奇点，并分析其演化方程。使用统计方法分析各类不变量的动力学特征。

Result: 发现三类不变量具有不同的动力学特征：III类不变量显示更高的间歇性(峰度~15 vs I类~8)和更强的非对称性(偏度~2.7 vs I类~1.6)，与瓣切换事件相关。不同类别的守恒原理对轨迹历史施加了不相容的要求。高精度数值验证确认了所有识别量的守恒性。

Conclusion: 三类不变量提供了对洛伦兹系统动力学的不同视角：III类不变量探测拓扑转变，I类不变量追踪连续动力学。任何三个来自不同类别的不变量构成独立约束的规范三元组，能够表征轨道结构。类别相关的发散量化了不同守恒原理对轨迹历史的不相容要求。

Abstract: Building upon the recent discovery of history-dependent dynamical invariants in the Lorenz system, this work presents a systematic classification of a complete family of such conserved quantities. Analysis of all 24 permutations in the augmented phase space identifies eighteen distinct invariants ($K_1-K_{18}$) organized into three regularization classes: Class I (permutations $1abc$), Class II ($2abc$), and Class III ($3abc$). Six permutations ($4abc$) yield null results due to Schwarz integrability conditions. Each class is characterized by a distinct polynomial factor that removes singularities at nullcline crossings. The regularized variable $v_n = p\, u_n$ evolves according to $dv_n/dt = Q_n(x,y,z)$, independent of $v_n$ itself; different conservation laws thereby impose distinct measures of trajectory history. Any three invariants from different classes provide independent constraints, defining a canonical Triad that characterizes orbit structure. Statistical analysis reveals class-dependent dynamical signatures: Class III invariants display higher intermittency (kurtosis ~15 versus ~8 for Class I) and stronger asymmetry (skewness ~2.7 versus ~1.6), correlating with lobe-switching events where the product $xy$ undergoes rapid sign reversal. This geometric sensitivity establishes Class III invariants as probes of topological transitions, while Class I invariants track continuous dynamics. The class-dependent divergence quantifies how different conservation principles impose incompatible demands on trajectory history. High-precision numerical validation confirms conservation of all identified quantities.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [3] [All-to-All interactions via multifractal wavefunction geometry](https://arxiv.org/abs/2512.19798)
*YouYoung Joung,Jemin Park,SungBin Lee*

Main category: cond-mat.str-el

TL;DR: 多分形量子波函数的本征几何结构在多体系统中产生有效的全对全相互作用，导致快速信息扰乱和强混沌量子动力学


<details>
  <summary>Details</summary>
Motivation: 探索多分形量子波函数的内在几何结构如何影响多体系统的相互作用和动力学行为，为在固态平台实现强混沌量子动力学提供新途径

Method: 通过分析多分形谱，证明广泛分离的长度尺度同时参与产生全局连通性，绕过局部相互作用约束，研究量子Fisher信息和二分互信息的淬火动力学

Result: 多分形状态系统表现出快速信息扰乱，量子Fisher信息和二分互信息的淬火动力学发生急剧变化，出现负的三分互信息，表明强混沌量子动力学特征

Conclusion: 多分形量子波函数的复杂多尺度结构内在生成长程连通性，为实现强关联量子材料中的非局域行为提供了自然途径，是多体系统中实现强混沌动力学的有前景固态平台

Abstract: We uncover a generic mechanism through which the intrinsic geometry of multifractal quantum wavefunctions generates effective all-to-all interactions in many-body systems. By analyzing the multifractal spectrum, we demonstrate that the simultaneous participation of widely separated length scales creates a global connectivity that bypasses local interaction constraints. This nonlocality leads to fast information scrambling, evidenced by sharp changes in the quenched dynamics of the quantum Fisher information and bipartite mutual information with the onset of negative tripartite mutual information. Such rapid scrambling is a defining feature of strongly chaotic quantum dynamics, and our results identify the systems with multifractal states as a promising solid-state platform for realizing this regime. More broadly, they reveal a new paradigm in which complex, multiscale wavefunction structure intrinsically generates long-range connectivity, providing a natural route to achieving nonlocal behavior in strongly correlated quantum materials.

</details>


### [4] [Preparation of a Quantum Spin Liquid in Non-Hermitian Quantum Dimer Models and Rydberg Arrays](https://arxiv.org/abs/2512.19809)
*Shashwat Chakraborty,Taylor L. Hughes*

Main category: cond-mat.str-el

TL;DR: 论文发现了一种新型非厄米趋肤效应，发生在多体福克空间而非实空间，称为福克空间趋肤效应（FSSE）。通过量子二聚体模型分析该效应，并提出在里德堡原子阵列中实现的方案，可用于制备拓扑自旋液体态。


<details>
  <summary>Details</summary>
Motivation: 传统非厄米趋肤效应发生在实空间，本文探索在福克空间中的类似现象，为量子态工程提供新原理，特别是用于制备拓扑量子相。

Method: 使用量子二聚体模型分析福克空间趋肤效应；提出利用里德堡原子阵列实现方案，通过阻塞机制实施二聚体约束，非厄米翻转振幅由定向耗散产生；具体设计实现具有次近邻二聚体的方晶格量子二聚体模型的里德堡几何结构。

Result: 理论分析和数值模拟证实了福克空间趋肤效应的存在；展示了如何通过非厄米性驱动系统进入精确的自旋液体基态；证明了该效应可用于制备有能隙的自旋液体态。

Conclusion: 福克空间非厄米性成为工程奇异量子相和动力学态制备协议的有力原理，为量子模拟和拓扑量子计算提供了新途径。

Abstract: We identify an unconventional form of the non-Hermitian skin effect that occurs not in position space but in many-body Fock space, which we call the Fock space skin effect (FSSE). Using quantum dimer models, we characterize FSSE analytically and numerically, and propose a concrete route toward its realization in Rydberg atom arrays. The dimer constraint is enforced through Rydberg gadgets employing the blockade mechanism, while directional reservoirs generate non-Hermitian flipping amplitudes. We show that FSSE enables the preparation of gapped spin liquid states, and in particular, we demonstrate how a Rydberg geometry realizing a square lattice quantum dimer model with next-nearest neighbor dimers can be driven by non-Hermiticity into an exact spin liquid ground state. Our results establish Fock-space non-Hermiticity as a powerful principle for engineering exotic quantum phases and dynamical state-preparation protocols.

</details>


### [5] [Bosonization solution of the Kondo lattice in a Luttinger liquid](https://arxiv.org/abs/2512.19844)
*Tomás Bortolin,C. J. Bolech,Nayana Shah,Aníbal Iucci*

Main category: cond-mat.str-el

TL;DR: 该研究探讨了一维Luttinger液体中规则排列的磁性杂质与相互作用电子之间的物理，通过可解极限揭示了电子相互作用如何调控Kondo和RKKY物理的竞争。


<details>
  <summary>Details</summary>
Motivation: 研究一维相互作用电子体系中规则排列的磁性杂质的物理行为，特别是电子相互作用如何影响Kondo效应和RKKY相互作用的竞争机制。

Method: 采用玻色化方法处理一维Luttinger液体，通过磁交换相互作用描述杂质自旋与电子的耦合，在特定相互作用参数下将模型重新费米化为非相互作用电子带与规则排列共振能级的杂化系统。

Result: 在特定相互作用参数下获得可解极限，能够计算杂质关联函数，发现系统可呈现扩展代数序或局域屏蔽两种不同物理相，揭示了电子相互作用的符号决定系统稳定Kondo物理还是RKKY物理。

Conclusion: 一维相互作用电子体系中，电子相互作用的符号是决定磁性杂质呈现Kondo屏蔽还是RKKY有序的关键因素，为理解低维强关联体系中杂质物理提供了新的理论框架。

Abstract: We address the physics of a regular arrangement of independent magnetic impurities embedded in a band of interacting electrons. We focus on the one-dimensional case that can be studied using bosonization and in which the electron bulk is described by a Luttinger liquid. The impurity spins interact with the electrons via magnetic exchange that introduces the possibility of Kondo and RKKY physics. We find that for two special values of the interactions, the model can be refermionized as a non-interacting electron band hybridized with a regular array of resonant levels. These solvable limits provide access to impurity correlators that correspond to either extended algebraic order or local screening. A physical picture emerges of how the interelectron interactions can stabilize either Kondo or RKKY physics depending on the sign of the interaction.

</details>


### [6] [Semi-automated estimation of hydrogenic initial states for localized Wannier functions](https://arxiv.org/abs/2512.19900)
*Tatsuki Oikawa,Kota Ido,Takahiro Misawa,Takashi Koretsune,Kazuyoshi Yoshimi*

Main category: cond-mat.str-el

TL;DR: 提出了一种半自动化的Wannier函数初始估计方法，通过Γ点布洛赫波函数信息自动确定氢原子投影轨道和Wannier函数中心，集成到cif2qewan工具中，为复杂材料的高通量计算提供支持。


<details>
  <summary>Details</summary>
Motivation: 为了简化固体低能有效模型中Wannier函数的构建过程，特别是在强关联电子系统中，需要一种能够自动提供良好初始估计的方法，以促进复杂材料的高通量计算研究。

Method: 开发了半自动化方法，利用Γ点布洛赫波函数信息自动确定氢原子投影轨道和Wannier函数中心，该方法集成到cif2qewan工具中，能够无缝生成Quantum ESPRESSO和Wannier90的输入文件。

Result: 通过对Si、SrVO₃、FeSe、Na₈Al₆Si₆O₂₄和(TMTTF)₂PF₆等无机和有机化合物的应用验证，表明该方法提供的半自动投影能够给出Wannier函数的良好初始估计。与SCDM等其他初始状态估计方法的比较也显示了该方法的有效性。

Conclusion: 该方法为构建Wannier函数提供了一种高效途径，为复杂材料研究中的高通量计算铺平了道路，特别是在强关联电子系统的低能有效模型描述中具有重要应用价值。

Abstract: We present a semi-automated method for obtaining an initial estimate of Wannier functions, designed to facilitate the construction of Wannier functions for describing low-energy effective models of solids, particularly those relevant to strongly correlated electron systems. Our approach automatically determines the hydrogenic projections orbitals and the center of the Wannier functions from information on Bloch wavefunctions at the $Γ$ point. This method is integrated into cif2qewan, enabling seamless generation of input files for Quantum ESPRESSO and Wannier90. We validate our method through applications to both inorganic and organic compounds, such as Si, SrVO$_3$, FeSe, Na$_8$Al$_6$Si$_6$O$_{24}$, and (TMTTF)$_2$PF$_6$. The obtained results demonstrate that our semi-automated projections give a good initial estimate of the Wannier functions. We also show the comparisons with other methods for estimating the initial states of the Wannier functions, such as the Selected Columns of the Density Matrix (SCDM). Our methodology shows an efficient way to construct Wannier functions, paving the way for high-throughput calculations in the study of complex materials.

</details>


### [7] [Jordan-Wigner Transformation for the Description of Strong Correlation in Fermionic Systems](https://arxiv.org/abs/2512.19938)
*Thomas M. Henderson,Guo P. Chen,Gustavo E. Scuseria*

Main category: cond-mat.str-el

TL;DR: 通过Jordan-Wigner近似将seniority零问题转化为费米子问题，实现了多项式成本下获得DOCI质量的结果，包括能量和密度矩阵。


<details>
  <summary>Details</summary>
Motivation: DOCI（双占据构型相互作用）虽然能为强关联电子系统提供精确结果，但具有组合计算成本；而PCCD（对耦合簇双激发）虽然成本低但有时失效且密度矩阵质量不佳。

Method: 使用Jordan-Wigner近似将seniority零问题转化为费米子问题，从而在多项式成本下获得DOCI质量的变分结果。

Result: 该方法在Hubbard模型和几个小分子解离示例中，以多项式成本获得了与DOCI相当的能量和密度矩阵结果，且避免了崩溃问题。

Conclusion: 通过Jordan-Wigner近似转化seniority零问题，成功实现了多项式成本下获得DOCI质量的结果，为强关联系统的计算提供了高效准确的方法。

Abstract: Seniority is a useful way of organizing Hilbert space for strongly correlated systems. The exact zero-seniority wave function, doubly-occupied configuration interaction (DOCI), provides accurate results (given the right orbitals) for many strongly-correlated electronic systems, but has combinatorial computational cost. In many cases, pair coupled cluster doubles provides a polynomial-cost approximation that closely reproduces the energies of DOCI, but it breaks down in some cases and, as shown herein, it does not provide particularly good density matrices. In this work, we demonstrate that by using the Jordan-Wigner approximation to turn the seniority zero problem back into a fermionic one, we can provide variational results of DOCI quality for the Hubbard model and a few small molecular dissociation examples, with polynomial cost, both for the energies and for density matrices, all while being protected from collapse.

</details>


### [8] [Unveiling the Phase Diagram and Nonlinear Optical Responses of a Twisted Kitaev Chain](https://arxiv.org/abs/2512.20209)
*Ya-Min Quan,Shi-Qing Jia,Xiang-Long Yu,Hai-Qing Lin,Liang-Jian Zou*

Main category: cond-mat.str-el

TL;DR: 该研究通过二维相干光谱技术检测量子材料中的Kitaev相互作用，建立了CoNb2O6的扭曲Kitaev模型，发现二维相干光谱中的非重相位对角和重相位反对角信号可用于识别Kitaev相互作用。


<details>
  <summary>Details</summary>
Motivation: 检测真实材料中的Kitaev相互作用具有挑战性，因为传统实验技术难以区分分数化激发与其他正常贡献。二维相干光谱为探测量子磁体中的奇异激发提供了新方法。

Method: 为CoNb2O6提出扭曲Kitaev模型，根据实验比热相图确定精确扭曲角度，使用校准模型分析二维相干光谱非线性响应，通过数值投影方法分析信号来源。

Result: 发现非重相位对角和重相位反对角信号出现在二维相干光谱非线性响应中；自旋超交换相互作用的x和y分量将重相位信号分裂为离散峰网格；对角和离散重相位信号主要来源于双自旋子和四自旋子激发过程。

Conclusion: 二维相干光谱可以有效检测量子材料中即使很弱的Kitaev相互作用，为识别Kitaev量子自旋液体中的分数化激发提供了有力工具。

Abstract: Detecting Kitaev interactions in real materials remains challenge, as conventional experimental techniques often have difficulty distinguishing fractionalized excitations from other normal contributions. Terahertz two-dimensional coherent spectroscopy (2DCS) offers a novel approach for probing many-body phenomena, such as exotic excitations in quantum magnets. Motivated by recent experiments on CoNb$_2$O$_6$ and the development of the terahertz spectroscopy in Kitaev quantum spin liquid, we proposed a twisted Kitaev model for CoNb$_2$O$_6$ and determined the precise twist angle according to experimental specific-heat phase diagram. With this calibrated model, we found that non-rephasing diagonal and rephasing anti-diagonal signals appear in the 2DCS nonlinear response. The $x$ and $y$ components of the spin superexchange interactions split the rephasing signals into a grid of discrete peaks. We further demonstrate that the diagonal and the discrete rephasing signals primarily originate from two-spinon and four-spinon excitation processes based on numerical projection method. These findings indicate that even weak Kitaev interactions in quantum materials can be effectively detected via two-dimensional coherent spectroscopy .

</details>


### [9] [Multiple topological phases of magnons induced by Dzyaloshinskii-Moriya and pseudodipolar anisotropic exchange interactions in Kagome ferromagnets](https://arxiv.org/abs/2512.20297)
*Jin-Yu Ni,Xia-Ming Zheng,Peng-Tao Wei,Da-Yong Liu,Liang-Jian Zou*

Main category: cond-mat.str-el

TL;DR: 该研究探讨了具有多种磁各向异性相互作用（DMI和PDI）的二维Kagome铁磁体中的拓扑磁振子相，发现了高陈数的拓扑相、多种拓扑相变，以及温度诱导的热霍尔和能斯特电导率符号反转现象。


<details>
  <summary>Details</summary>
Motivation: Kagome磁体具有狄拉克点和平带等拓扑特性，但二维磁体中多种磁相互作用共存给拓扑磁振子操控带来了挑战。研究旨在探索多种磁各向异性相互作用如何影响Kagome铁磁体的拓扑磁振子相。

Method: 研究二维Kagome铁磁体，考虑多种磁各向异性相互作用，包括Dzyaloshinskii-Moriya相互作用（DMI）和赝偶极相互作用（PDI）。分析这些相互作用对拓扑相图、拓扑态和相变的影响。

Result: 发现不同磁各向异性相互作用产生完全不同的拓扑相图和拓扑态；多种相互作用导致高陈数拓扑磁振子相的出现；DMI和PDI相互作用与狄拉克点和平带的相互作用控制多种拓扑相变；在特定拓扑相区域观察到温度诱导的热霍尔和能斯特电导率符号反转。

Conclusion: 具有多种磁各向异性相互作用的Kagome磁体展现出新颖的拓扑磁振子特性，为磁振子器件和量子计算提供了潜在平台。

Abstract: Kagome magnets naturally hosting Dirac points and flat bands exhibit novel topological phases, enabling rich interplays between interactions and topologies. The discovery of two-dimensional (2D) magnets generally coexisting with different types of magnetic interactions poses a challenge for topological magnonic manipulation. Here we investigate the topological magnon phases of 2D Kagome ferromagnet with multiple magnetic anisotropic interactions, i.e. Dzyaloshinskii-Moriya interaction (DMI) and pseudo-dipolar interaction (PDI). It is found that the different sole magnetic anisotropic interactions introduce completely distinct topological phase diagrams and topological states. The multiple topological magnon phases with high Chern number emerge due to the distinct anisotropic interactions. Moreover, the interplay of the multiple anisotropic DMI and PDI interactions involved with Dirac and flat bands controls a variety of topological phase transitions, implying greater manipulation potential. In addition, the sign reversal of thermal Hall and Nernst conductivities induced by temperature is found in particular topological phase regions, namely topological origin, relating to the energy gap and Berry curvature (Chern number) in the vicinity of magnetic phase transition from the thermal fluctuations, providing a possible explanation for the experimental puzzles. All these results demonstrate that the novel topological magnonic properties in Kagome magnet with multiple magnetic anisotropic interactions can realize a potential platform for magnonic devices and quantum computing.

</details>


### [10] [Tensor-network study of the ground state of maple-leaf Heisenberg antiferromagnet](https://arxiv.org/abs/2512.20466)
*Samuel Nyckees,Pratyay Ghosh,Frédéric Mila*

Main category: cond-mat.str-el

TL;DR: 使用iPEPS方法研究枫叶晶格上自旋-1/2最近邻海森堡模型的量子相图，发现系统只存在两个相：磁有序倾斜120°相和精确二聚体单重态乘积相，两者之间存在一级相变。


<details>
  <summary>Details</summary>
Motivation: 研究枫叶晶格上自旋-1/2最近邻海森堡模型的量子相图，探索该系统中可能存在的量子相和相变行为，特别是磁有序相与二聚体单重态相之间的竞争关系。

Method: 采用无限投影纠缠对态（iPEPS）结合角转移矩阵重整化群方案，该方法专门适应于具有C3对称性的晶格结构，研究完全反铁磁J-Jd模型。

Result: 系统只存在两个相：磁有序倾斜120°相和精确二聚体单重态乘积相；两者之间存在一级相变，相变点位于Jd/J ≈ 1.45；在磁有序相中观察到小而有限的磁矩；发现倾斜角的量子重整化在整个磁有序相中都与经典预测存在偏差。

Conclusion: 枫叶晶格上的自旋-1/2海森堡模型表现出丰富的量子相行为，磁有序相与二聚体单重态相之间存在明确的一级相变，量子效应显著影响了系统的磁有序特性。

Abstract: We study the quantum phase diagram of the spin-$1/2$ nearest-neighbor Heisenberg model on the maple-leaf lattice using infinite projected entangled pair states (iPEPS) combined with a corner transfer matrix renormalization group scheme adapted to $C_3$-symmetric lattices. Focusing on the fully antiferromagnetic $J$-$J_d$ model with $J_h = J_t := J$, we map out the ground-state phase diagram as a function of the dimer coupling $J_d$. Our results show that the system hosts only two phases: a magnetically ordered canted-$120^\circ$ phase and an exact dimer singlet product phase. We identify a first-order transition between these two phases at $J_d/J \approx 1.45$. Within the magnetically ordered phase, we observe small but finite magnetic moments. We also resolve the quantum renormalization of the canting angle, which deviates from the classical prediction over almost the entire magnetically ordered phase.

</details>


### [11] [Quantum vs thermal fluctuations in phase transitions of two-dimensional superconductors](https://arxiv.org/abs/2512.20476)
*Andrea Ponticelli,Francesco Giuseppe Capone,Vittorio Cataudella,Giulio De Filippis,Antonio De Candia,Carmine Antonio Perroni*

Main category: cond-mat.str-el

TL;DR: 研究二维系统中量子与热相位涨落对超导序的抑制效应，通过量子蒙特卡洛模拟揭示相图、临界行为和绝缘交叉现象


<details>
  <summary>Details</summary>
Motivation: 探究二维超导系统中量子相位涨落和热相位涨落如何共同抑制超导序参数，理解这些涨落对超导-绝缘转变的影响机制

Method: 采用二维量子XY模型的相位表示，通过路径积分量子蒙特卡洛模拟，计算温度-相互作用相图，并分析电流-电流关联函数获取频率依赖电导率

Result: 建立了明确的临界线，终止于零温量子临界点，无重入行为；强相互作用下系统在低温出现绝缘交叉；量子相位涨落导致有限频率响应

Conclusion: 量子相位涨落在二维超导系统中起关键作用，导致超导序抑制和绝缘行为，为理解二维超导-绝缘转变提供了重要理论框架

Abstract: We investigate the impact of quantum and thermal phase fluctuations on the suppression of superconducting order in two-dimensional systems. Within the two-dimensional quantum XY model in the phase representation, where on-site interaction terms govern quantum phase fluctuations, we perform extensive path-integral quantum Monte Carlo simulations. The resulting temperature-interaction phase diagram establishes the presence of a well-defined critical line ending at a quantum critical point at vanishing temperature with no indication of reentrant behavior. We further demonstrate that the resistance above the critical line reproduces the two expected different critical behaviors. For stronger interactions, above the quantum critical point, the system exhibits a crossover to an insulating regime at low temperatures. Finally, Monte Carlo calculations of current-current correlation functions enable us to extract the frequency-dependent conductivity in both superconducting and normal regimes, revealing a finite-frequency response that we attribute to quantum phase fluctuations.

</details>


### [12] [Shear viscosity at finite magnetic field for graphene, non-relativistic and ultra-relativistic cases](https://arxiv.org/abs/2512.20499)
*Cho Win Aung,Thandar Zaw Win,Subhalaxmi Nayak,Sabyasachi Ghosh*

Main category: cond-mat.str-el

TL;DR: 该论文研究了石墨烯系统中电子流体在有限磁场下的剪切粘度，基于弛豫时间近似的动力学理论方法，发现磁场会诱导各向异性，产生五个独立的剪切粘度系数。


<details>
  <summary>Details</summary>
Motivation: 扩展Cho等人先前在无磁场条件下对石墨烯电子流体剪切粘度的微观计算工作，研究有限磁场对剪切粘度的影响，探索磁场诱导的各向异性效应。

Method: 采用弛豫时间近似的动力学理论方法，计算有限磁场下石墨烯系统中电子流体的剪切粘度系数。

Result: 磁场引入各向异性，产生五个独立的剪切粘度系数（垂直、平行和霍尔分量）。当散射时间等于回旋时间时，垂直分量被抑制80%，平行分量被抑制50%，霍尔效应达到最大。石墨烯电子流体的相应磁场强度约为0.01-0.1特斯拉。

Conclusion: 磁场显著影响电子流体的剪切粘度，产生各向异性效应。不同流体系统（石墨烯电子流体、非相对论电子流体、超相对论夸克流体）需要不同的磁场强度才能观察到明显的粘度响应。

Abstract: Present article has addressed finite magnetic field extension of previous work by Cho et al. (Phys. Rev. B 108, 235172, 2023) on microscopic calculation of shear viscosity for electron fluid in graphene system. Our calculation is based on the kinetic theory approach in the relaxation time approximation. In the absence of magnetic field, transport is governed by a single shear viscosity coefficient, whereas the application of a finite magnetic field induces anisotropy, give rise to the five independent shear viscosity coefficients associated with distinct velocity gradient tensors. These coefficient can be physically categorized into perpendicular, parallel and Hall components relative to the magnetic field direction. When the scattering time equals to the cyclotron time, the perpendicular component is suppressed by 80% and parallel component by 50%, and Hall effect can reach maximum. Corresponding magnetic field strength for electron fluid in graphene is around 0.01-0.1 Tesla and the same for non-relativistic electron fluid and ultra-relativistic quark fluid are around 10 Tesla and 10^14 Tesla respectively. They may be considered as required magnetic field strength in three different fluid systems to observe noticeable magnetic field response in their shear viscosity coefficients.

</details>


### [13] [Rényi-like entanglement probe of the chiral central charge](https://arxiv.org/abs/2512.20608)
*Julian Gass,Michael Levin*

Main category: cond-mat.str-el

TL;DR: 提出了一种用于探测二维有能隙量子多体系统基态纠缠的新方法ω_{α,β}，该量是模交换子的"Rényi类"推广，可用于计算手征中心荷。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的纠缠探针，能够从体波函数中计算手征中心荷，为理解二维有能隙量子多体系统的拓扑性质提供新工具。

Method: 通过特定几何构型中约化密度矩阵的幂次定义ω_{α,β}，该量由两个正实数α,β参数化。对于整数α,β，ω_{α,β}可表示为适当复制系统中置换算符的期望值。

Result: 对无相互作用费米子哈密顿量和弦网模型的有能隙基态，ω_{α,β}取与手征中心荷相关的普适值。整数α,β情况下的表达式为数值模拟和实验测量提供了自然途径。

Conclusion: ω_{α,β}作为模交换子的推广，是一种有效的纠缠探针，能够表征二维有能隙量子多体系统的拓扑性质，特别是手征中心荷，并具有实验可测量性。

Abstract: We propose a ground state entanglement probe for gapped, two-dimensional quantum many-body systems that involves taking powers of reduced density matrices in a particular geometric configuration. This quantity, which we denote by $ω_{α,β}$, is parameterized by two positive real numbers $α, β$, and can be seen as a ``Rényi-like" generalization of the modular commutator -- another entanglement probe proposed as a way to compute the chiral central charge from a bulk wave function. We obtain analytic expressions for $ω_{α,β}$ for gapped ground states of non-interacting fermion Hamiltonians as well as ground states of string-net models. In both cases, we find that $ω_{α,β}$ takes a universal value related to the chiral central charge. For integer values of $α$ and $β$, our quantity $ω_{α,β}$ can be expressed as an expectation value of permutation operators acting on an appropriate replica system, providing a natural route to measuring $ω_{α,β}$ in numerical simulations and potentially, experiments.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [14] [An introduction to monitored quantum systems and quantum trajectories: spectrum, typicality, and phases](https://arxiv.org/abs/2512.19922)
*Ryusuke Hamazaki,Ken Mochizuki,Hisanori Oshima,Yohei Fuji*

Main category: cond-mat.stat-mech

TL;DR: 本文是一篇关于被监测量子系统动力学理论综述，介绍了量子测量理论、量子轨迹概念，以及谱性质与典型行为、李雅普诺夫指数与测量诱导相变的关系。


<details>
  <summary>Details</summary>
Motivation: 近年来实验技术的进步使得量子动力学模拟和检测精度大幅提升，加深了对被监测量子系统物理的理解，需要系统梳理相关理论框架和最新进展。

Method: 首先回顾量子测量理论，引入量子轨迹概念（由测量结果塑造的条件动力学），然后讨论描述测量结果平均演化的动力学映射的谱性质，分析这些谱特征与量子轨迹典型行为的关系，最后引入典型量子轨迹的李雅普诺夫指数。

Result: 揭示了谱性质与量子轨迹典型行为（如遍历性和纯化）的密切联系，李雅普诺夫指数可作为监测量子多体系统中测量诱导相变的指标。

Conclusion: 该综述系统介绍了被监测量子系统动力学的基本形式体系，阐明了谱性质、典型行为与相变之间的理论联系，为理解测量对量子系统演化的影响提供了统一框架。

Abstract: Thanks to recent experimental advances in simulating and detecting quantum dynamics with high precision and controllability, our understanding of the physics of monitored quantum systems has considerably deepened over the past decades. In this article, we provide an introductory theoretical review on the basic formalisms governing open quantum dynamics under measurement, along with recent developments in their spectral and typical aspects. After reviewing quantum measurement theory, we introduce the concept of quantum trajectories, which are the conditional dynamics of monitored states shaped by a set of measurement outcomes. We then discuss the spectral properties of the dynamical map describing the evolution averaged over measurement outcomes. As has recently been recognized, these spectral features are intimately connected to whether quantum trajectories exhibit typical behaviors, such as the ergodicity and purification. Moreover, we introduce Lyapunov exponents of typical quantum trajectories and discuss how these quantities serve as indicators of measurement-induced phase transitions in monitored quantum many-body systems.

</details>


### [15] [Critical Temperature(s) of Sierpiński Carpet(s)](https://arxiv.org/abs/2512.20295)
*Riccardo Ben Alì Zinati,Giacomo Gori,Alessandro Codello*

Main category: cond-mat.stat-mech

TL;DR: 对计算Sierpiński地毯上伊辛模型临界温度的广义组合Feynman-Vdovichenko方法进行关键算法改进，通过纯实值转移矩阵大幅降低维度，实现k=10代计算，获得迄今最精确的临界温度估计。


<details>
  <summary>Details</summary>
Motivation: 改进现有方法以更精确地计算Sierpiński地毯上伊辛模型的临界温度，特别是针对SC_k(3,1)地毯，突破之前计算代数的限制。

Method: 将广义组合Feynman-Vdovichenko方法重新表述为纯实值转移矩阵，显著降低矩阵维度，结合现代计算资源实现更高代数的计算。

Result: 成功计算到SC_k(3,1)地毯的第10代，通过外推获得迄今最精确的临界温度估计：T_c^{(3,1)} = 1.4782927(26)。同时扩展到SC_k(a,b)家族其他成员并报告其临界温度。

Conclusion: 算法改进显著提升了计算效率和精度，为研究分形结构上的相变提供了更强大的工具，获得了Sierpiński地毯上伊辛模型临界温度的最精确估计。

Abstract: We present a key algorithmic improvement to the generalized combinatorial Feynman--Vdovichenko method for calculating the critical temperature of the Ising model on Sierpiński carpets $SC_k(a,b)$, originally introduced in {\tt arxiv:1505.02699}. By reformulating the method in terms of purely real-valued transfer matrices, we substantially reduce their dimension. This optimization, together with modern computational resources, enables us to reach generation $k=10$ for the canonical $SC_k(3,1)$ carpet. Extrapolation from these data yields the most accurate estimate to date of the critical temperature $T_c^{(3,1)} = 1.4782927(26)$. We further extend the analysis to additional members of the $SC_k(a,b)$ family and report their corresponding critical temperatures.

</details>


### [16] [Optimal navigation in a noisy environment](https://arxiv.org/abs/2512.20336)
*Abhijit Sinha,Sandeep Jangid,Tridib Sadhu,Shankar Ghosh*

Main category: cond-mat.stat-mech

TL;DR: 该研究证明，在噪声环境中，通过自然游走加间歇性航向修正的简单策略，比连续精细反馈更高效，且存在最优修正频率的普适权衡。


<details>
  <summary>Details</summary>
Motivation: 在噪声环境中导航是生物、物理和工程系统的共同问题。传统方法依赖连续精细反馈，但本研究探索更简单的导航原则。

Method: 使用受控机器人平台、活性布朗粒子模拟和标度理论，研究噪声引起的偏差与有限重定向成本之间的权衡。

Result: 发现了由少数系统参数决定的最优航向修正频率，实验和理论在首次通过时间分布和非高斯角色散等定量特征上一致。

Conclusion: 间歇性航向修正是比连续反馈更简单、鲁棒的导航策略，为复杂环境中的点对点导航提供了统一的指导原则。

Abstract: Navigating toward a known target in a noisy environment is a fundamental problem shared across biological, physical, and engineered systems. Although optimal strategies are often framed in terms of continuous, fine-grained feedback, we show that efficient navigation emerges from a far simpler principle: natural wandering punctuated by intermittent course corrections. Using a controlled robotic platform, active Brownian particle simulations, and scaling theory, we identify a universal trade-off between noise-induced deviation and the finite cost of reorientation, yielding an optimal course correction frequency governed by only a few system parameters. Despite their differing levels of complexity, our experiment and theory collapse onto common quantitative signatures, including first-passage time distribution and non-Gaussian angular dispersion. Our results establish intermittent course-correction as a minimal and robust alternative to continuous feedback, offering a unifying guiding principle for point-to-point navigation in complex environments.

</details>


### [17] [Run and Tumble Dynamics of Biased Quantum Trajectories in a Monitored Qubit](https://arxiv.org/abs/2512.20519)
*Aritra Kundu*

Main category: cond-mat.stat-mech

TL;DR: 该研究将连续测量和反馈控制下的量子比特随机动力学映射到经典持续跑-翻滚粒子模型，利用活性物质理论推导量子系统的非平衡稳态分布，揭示了Zeno-反Zeno相变与活性粒子受限行为的统计等价性。


<details>
  <summary>Details</summary>
Motivation: 研究量子比特在连续测量和条件反馈下的主动随机动力学，探索量子系统与经典活性物质系统之间的深刻联系，理解测量反馈与相干驱动竞争导致的非平衡相变现象。

Method: 将量子比特的随机状态演化方程在高扩散极限下映射到一维有界域中的经典持续跑-翻滚粒子模型，利用经典活性物质的分析结果推导量子系统的近似非平衡稳态分布。

Result: 发现相干Rabi驱动与测量诱导反馈之间的竞争导致丰富的非平衡稳态相，表现出Zeno-反Zeno相变，这在统计上等价于受限活性粒子中的推进诱导捕获现象。

Conclusion: 量子测量反馈系统与经典活性物质系统之间存在深刻的统计等价性，这种映射为理解量子非平衡稳态提供了新的理论框架，揭示了量子Zeno效应与活性粒子受限行为的统一物理机制。

Abstract: We investigate the active stochastic dynamics of a qubit subjected to continuous measurement and conditional feedback. The stochastic equation governing the state vector trajectory of the qubit can be mapped, in the high-diffusion limit, to the dynamics of a classical persistent Run-and-Tumble Particle (p-RTP) in a bounded one-dimensional domain. The mapping enables us to use analytical results from classical active matter to derive an approximate non-equilibrium steady-state (NESS) distribution for the monitored quantum system. The competition between the coherent Rabi drive and the measurement-induced feedback leads to a rich NESS phase displaying Zeno--anti-Zeno transition--which is statistically equivalent to the propulsion-induced trapping observed in confined active particles.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [18] [Observation of flat-band skin effect](https://arxiv.org/abs/2512.19745)
*Xulong Wang,Dongyi Wang,Congwei Lu,Ruo-Yang Zhang,Ching Hua Lee,Kun Ding,Guancong Ma*

Main category: quant-ph

TL;DR: 该研究发现非厄米趋肤效应（NHSE）可以出现在平带中，称为平带趋肤效应（FBSE）。与色散带不同，平带在复能面上是一个点，总是拓扑平凡的，但FBSE与包围平带的色散带的非平凡谱拓扑相关，只在有限非厄米参数范围内出现，并在强非厄米性下消失。


<details>
  <summary>Details</summary>
Motivation: 传统上认为非厄米趋肤效应（NHSE）只出现在色散带中，由非平凡点隙拓扑保护。本研究旨在探索平带中是否也能出现趋肤效应，以及这种效应的拓扑起源和独特性质。

Method: 通过理论分析一维非厄米晶格中的平带系统，研究平带趋肤效应的出现条件、拓扑机制和能隙闭合特性。在周期性边界条件和开放边界条件下分析高阶异常点，并通过非厄米机械晶格进行实验验证。

Result: 发现平带趋肤效应（FBSE）确实存在，但与色散带的NHSE不同：1）FBSE与包围平带的色散带的谱拓扑相关；2）只在有限非厄米参数范围内出现，在强非厄米性下消失；3）平带与色散带之间的能隙可在高阶异常点闭合；4）平带波函数在这些异常点处量子距离不连续。

Conclusion: 该工作揭示了非厄米系统中独特的平带现象，表明平带趋肤效应由色散带的谱拓扑驱动而非平带本身的拓扑性质。这为非厄米系统中的量子几何和局域化控制提供了新的可能性。

Abstract: Symmetry-protected ideal flat bands in one-dimensional (1D) Hermitian lattices are populated by compact localized states (CLS) - a special class of localization with wavefunctions confined within a small region. In this work, we discover that the non-Hermitian skin effect (NHSE) can appear in a flat band. Unlike conventional NHSEs for dispersive bands that are protected by nontrivial point-gap topology, the flat band remains a point on the complex-energy plane and is therefore always topologically trivial. We found that, intriguingly, the flat-band skin effect (FBSE) is associated with the non-trivial spectral topology of the dispersive bands enclosing the flat band on the complex-energy plane, so it only emerges within a finite range of non-Hermitian parameters and can counterintuitively disappear at large non-Hermiticity. Moreover, the gaps between the flat and the dispersive bands can close at higher-order exceptional points under both periodic and open boundary conditions. The flat-band wavefunctions are discontinuous in quantum distance across these exceptional points, signifying that the gap-closing is singular. The FBSE was experimentally observed in a non-Hermitian mechanical lattice. Our work reveals flat-band phenomena unique to non-Hermitian systems and highlights new possibilities in quantum geometry and localization control.

</details>


### [19] [Composable, unconditional security without a Quantum secret key: public broadcast channels and their conceptualizations, adaptive bit transmission rates, fidelity pruning under wiretaps](https://arxiv.org/abs/2512.19759)
*Pete Rigas*

Main category: quant-ph

TL;DR: 该论文研究了无密钥通信协议中的量子信道，探讨了如何在不依赖秘密密钥的情况下实现无条件安全，并分析了窃听者错误概率和Holevo信息的关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索无密钥量子通信协议的可能性，特别是如何在不使用秘密密钥的情况下实现无条件安全，以及量子信道在提升量子-经典性能差距方面的潜力。

Method: 通过分析公共广播信道、前向概念信道和后向概念信道，使用级联方法增加窃听者的错误接受概率，并利用Holevo信息和最优解码器分析窃听者错误概率，通过CPTP映射的后处理减少Holevo和量。

Result: 证明了存在合适的协议能使Alice和Bob以高概率映射到认证的比特码字空间，前向概念信道通过级联能显著增加Eve的错误接受概率，并展示了如何通过数据处理和熵连续性界限减少Holevo和量。

Conclusion: 该研究为无密钥量子通信协议的安全性分析提供了理论框架，展示了在不依赖秘密密钥的情况下实现保密和认证的可能性，为量子优势的探索提供了新的方向。

Abstract: We examine public broadcast, forward conceptual, and backward conceptual, Quantum channels in the context of communication protocols that are independent of secret keys. Given research directions of interest previously identified in arXiv: 1804.01797, besides converse upper bounds on the bit transmission rate obtained by the author in recent work (arXiv: 2507.03035), additional possibilities remain, including: (1) determining whether aspects of QKD dependent protocols can be incorporated into steps of QKD independent protocols; (2) whether there would be any amplification to the Quantum-classical performance gap that Alice and Bob can exploit towards prospective Quantum advantage; (3) formulating the conditions under which secrecy and authentication can be simultaneously achieved. To characterize the conditions for which secrecy can be achieved with high probability, we argue that there not only exists suitable protocols which enable Alice and Bob to map into the authenticated space of bit codewords with high probability, but also that forward conceptual channels, through cascading, can significantly increase Eve's probability of false acceptance. Albeit the fact that secrecy, along with conceputalizations of the public broadcast channel, were initially discussed by Maurer for QKD dependent protocols, determining whether aspects of such protocols can be adapted for unconditional security without the use of a secret key is of great interest to explore. We demonstrate that Eve's error probability, through the cascading procedure, can be analyzed with the Holevo information under an optimal decoder. Furthermore, through post-processing of the outputs of a Completely Positive Trace Preserving (CPTP) map, we also demonstrate how to decrease Holevo sum quantities with data-processing and entropy-continuity bounds.

</details>


### [20] [Theory of Scalable Spin Squeezing with Disordered Quantum Dipoles](https://arxiv.org/abs/2512.19781)
*Avi Kaplan-Lipkin,Philip J. D. Crowley,Jonathan N. Hallén,Zilin Wang,Weijie Wu,Sabrina Chern,Chris R. Laumann,Lode Pollet,Norman Y. Yao*

Main category: quant-ph

TL;DR: 该研究开发了二维随机稀释晶格中量子偶极子的可扩展自旋压缩理论，通过量子蒙特卡洛模拟发现，随着无序度增加，可扩展自旋压缩仅在接近海森堡点附近存在，并提出通过解耦紧密耦合二聚体来实现实验可行的自旋压缩。


<details>
  <summary>Details</summary>
Motivation: 虽然偶极自旋系统通过淬火动力学能够产生自旋压缩，但现有理论主要关注晶格系统，而实际系统（如超冷分子、核自旋系综和固态色心）通常存在显著的位置无序性。需要理解无序如何影响可扩展自旋压缩的产生。

Method: 开发了二维随机稀释晶格中量子偶极子的理论模型（偶极XXZ模型），通过广泛的量子蒙特卡洛模拟绘制了有限温度XY序（以及可扩展自旋压缩）的相图，分析了无序度和伊辛各向异性的影响。

Result: 随着无序度增加，可扩展自旋压缩仅在接近海森堡点附近存在。这种行为归因于罕见的紧密耦合二聚体在淬火后有效地加热系统。对于金刚石中的氮空位中心，通过解耦问题二聚体与动力学的实验可行策略足以实现可扩展自旋压缩。

Conclusion: 无序偶极系统中的可扩展自旋压缩对无序敏感，但通过有针对性的解耦策略可以在实验条件下实现。这为实际无序系统中实现超越经典极限的计量精度提供了理论指导。

Abstract: Spin squeezed entanglement enables metrological precision beyond the classical limit. Understood through the lens of continuous symmetry breaking, dipolar spin systems exhibit the remarkable ability to generate spin squeezing via their intrinsic quench dynamics. To date, this understanding has primarily focused on lattice spin systems; in practice however, dipolar spin systems$\unicode{x2014}$ranging from ultracold molecules to nuclear spin ensembles and solid-state color centers$\unicode{x2014}$often exhibit significant amounts of positional disorder. Here, we develop a theory for scalable spin squeezing in a two-dimensional randomly diluted lattice of quantum dipoles, which naturally realize a dipolar XXZ model. Via extensive quantum Monte Carlo simulations, we map out the phase diagram for finite-temperature XY order, and by extension scalable spin squeezing, as a function of both disorder and Ising anisotropy. As the disorder increases, we find that scalable spin squeezing survives only near the Heisenberg point. We show that this behavior is due to the presence of rare tightly-coupled dimers, which effectively heat the system post-quench. In the case of strongly-interacting nitrogen-vacancy centers in diamond, we demonstrate that an experimentally feasible strategy to decouple the problematic dimers from the dynamics is sufficient to enable scalable spin squeezing.

</details>


### [21] [Passive quantum reference frame transformations cannot create entanglement between physical systems](https://arxiv.org/abs/2512.19790)
*T. Rick Perche,Natália Salomé Móller,Guilherme Franzmann*

Main category: quant-ph

TL;DR: 量子参考系变换中子系统纠缠的必要条件：被动量子参考系变换不能产生物理系统间的纠缠


<details>
  <summary>Details</summary>
Motivation: 研究量子参考系变换如何影响子系统间的纠缠关系，区分参考系系统和物理系统，探讨纠缠产生的条件

Method: 区分适合作为参考系的量子系统和相对于这些参考系描述的物理系统，定义被动量子参考系，分析其变换特性

Result: 发现被动量子参考系之间的变换不能产生物理系统间的纠缠，为子系统纠缠提供了必要条件

Conclusion: 量子参考系变换对纠缠产生有重要限制，被动参考系变换无法创造物理系统间的纠缠，这一结果也适用于没有区分物理和参考系统的视角框架

Abstract: We find a necessary condition for subsystems to become entangled after a quantum reference frame transformation. By distinguishing between quantum systems suitable to act as reference frames and physical systems described relative to these frames, we define passive quantum reference frames and show that transformations between these cannot produce entanglement between physical systems. Our results also apply to the study of entanglement between subsystems in the perspectival framework even when there is no distinction between physical and reference systems.

</details>


### [22] [Quantum information scrambling in strongly disordered Rydberg spin systems](https://arxiv.org/abs/2512.19856)
*Maximilian Müllenbach,Sebastian Geier,Adrian Braemer,Eduard Braun,Titus Franz,Gerhard Zürn,Matthias Weidemüller,Martin Gärttner*

Main category: quant-ph

TL;DR: 该研究通过数值模拟和实验方案探讨了幂律相互作用自旋系统中的信息扰乱现象，发现其与最近邻相互作用系统存在显著差异，并提出了基于里德堡原子阵列的实验测量方案。


<details>
  <summary>Details</summary>
Motivation: 尽管幂律相互作用在众多物理系统中普遍存在，但其多体动力学特性远不如最近邻相互作用系统被充分理解。研究者希望探究强无序幂律相互作用自旋系统中的信息扰乱现象。

Method: 通过数值计算研究无序幂律相互作用系统中的时序关联函数（OTOCs）动力学传播，并设计基于里德堡原子镊子阵列的实验方案来测量XXZ海森堡自旋系统中的OTOCs。

Result: 数值模拟显示幂律相互作用系统与最近邻相互作用系统在OTOCs动力学传播上存在显著差异，即使对于短程相互作用也是如此，这与传统认为短程相互作用等价于最近邻相互作用的观点相悖。

Conclusion: 幂律相互作用系统的信息扰乱动力学特性与最近邻相互作用系统存在本质差异，提出的实验方案为在可编程无序系统中研究这类现象提供了可行途径。

Abstract: Despite the fact that power-law interactions occur in a plethora of physical systems, their many-body dynamics is far less understood than that of nearest-neighbor interacting systems. Here, we study information scrambling in strongly disordered spin systems with power-law interactions via out-of-time-order correlators (OTOCs). Numerically, we find pronounced differences in the dynamical spreading of OTOCs between nearest-neighbor and power-law interacting systems. This deviation persists even for short-range interactions, opposing the common view that these interactions produce dynamics equivalent to the nearest-neighbor case. In a detailed experimental proposal, tailored but not limited to Rydberg tweezer setups, we present a protocol to extract OTOCs in XXZ Heisenberg spin systems with tunable anisotropy and programmable disorder based on currently available techniques.

</details>


### [23] [High-efficiency loading of 2,400 Ytterbium atoms in optical tweezer arrays](https://arxiv.org/abs/2512.19795)
*Jiawen Zhu,Changfeng Chen,Li Zhou,Xiangru Xie,Chenyang Jiang,Zhuoli Ding,Fan Wu,Fan Yang,Guoqing Wang,Qihuang Gong,Peng Zhang,Sheng Zhang,Pai Peng*

Main category: quant-ph

TL;DR: 该研究实现了2400个镱-174原子的光镊阵列，单原子装载效率达83.5%，并展示了从几十到几千原子规模的良好可扩展性，为碱土类原子的大规模量子计算奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 碱土类原子（如镱）在量子计算中具有长相干时间和高保真度里德堡门等优势，但其可扩展性一直落后于碱金属原子。研究旨在解决碱土类原子阵列的可扩展性问题。

Method: 开发了增强型单原子装载方法，在光镊阵列中实现了2400个镱-174原子的装载，装载效率达83.5%。该方法在不同原子间势能范围内都保持稳定，展示了广泛适用性。

Result: 实现了大规模镱原子阵列（2400个原子），单原子装载效率高达83.5%，且从几十到几千原子规模都保持高效装载，展示了优异的可扩展性。提出了基于基态-时钟态编码的量子比特方案。

Conclusion: 该工作显著推进了使用碱土类原子实现大规模量子计算机的前景，通过增强装载效率和可扩展性，为基于镱原子阵列的通用量子计算奠定了基础。

Abstract: Neutral atom arrays have emerged as a powerful platform for quantum computation, simulation, and metrology. Among them, alkaline-earth-like atoms exhibit distinct advantages, including long coherence time and high-fidelity Rydberg gates. However, their scalability has lagged behind that of the alkali atoms. Here, we report 2,400 Ytterbium-174 atoms trapped in an optical tweezer array with enhanced single-atom loading efficiency of 83.5(1)%. Notably, the loading efficiency is largely maintained for array sizes ranging from dozens to thousands, exhibiting excellent scalability. We demonstrate the broad applicability of the enhanced loading method by showing that the enhancement exists robustly across a range of interatomic potentials, suggesting its utility for other atomic species. To establish the capability of the 174Yb arrays toward universal quantum computation, we propose to encode the qubit in the ground-clock state manifold and estimate a 99.9% two-qubit gate fidelity with experimentally feasible parameters. Our work advances the prospects for realizing large-scale quantum computers using alkaline-earth-like atoms.

</details>


### [24] [Ergotropy of quantum many-body scars](https://arxiv.org/abs/2512.19801)
*Zhaohui Zhi,Qingyun Qian,Jin-Guo Liu,Guo-Yi Zhu*

Main category: quant-ph

TL;DR: 量子多体疤痕态具有非遍历性和逃避热化的特性，即使在能量密度较高时仍保持面积律纠缠熵。本文研究了PXP模型中疤痕态与热态之间插值态的可提取能量（ergotropy），发现了ergotropy与纠缠之间的现象学关系，并提出了通过全局相干旋转为量子"电池"充电的动力学协议。


<details>
  <summary>Details</summary>
Motivation: 量子多体疤痕态打破了遍历性并逃避热化，即使在高能量密度下仍保持面积律纠缠熵。虽然其量子关联和纠缠已有研究，但其存储可提取能量的能力（通过ergotropy量化）仍是一个未解决的问题。本文旨在探索量子多体疤痕态在存储可提取能量方面的潜力。

Method: 以代表性的PXP模型为研究对象，分析了一族在量子多体疤痕态和热态之间插值的态。研究了这些态的ergotropy标度行为，揭示了ergotropy与纠缠之间的现象学关系。提出了一个动力学协议，通过全局均匀相干旋转来注入可提取能量，作为量子"电池"充电的原理验证。

Result: 发现了插值态具有广泛的ergotropy标度行为，而热态则是被动的且ergotropy为零。揭示了ergotropy与纠缠之间的现象学关系，将现有的自由费米子可积结果推广到相互作用场景。动力学协议表明，全局相干旋转可以有效地为量子"电池"注入可提取能量。

Conclusion: 量子多体疤痕态虽然只占据希尔伯特空间的微小部分，但可以被有效地用于存储可提取能量。"疤痕化"多体系统是工程化量子多体电池的有前景途径。该协议特别适用于里德堡中性原子阵列，也可在其他量子处理器上实现。

Abstract: Quantum many-body scars break ergodicity and evade thermalization, resulting in area law entanglement entropy even with high energy density. While their quantum correlations and entanglement have been elaborated previously, their capacity in storing extractable energy, quantified by the notion ergotropy, remains an open question. Here we focus on the representative PXP model, and unveil the extensive ergotropy scaling of a family of states interpolating between quantum many-body scars and thermal states, the latter of which are known to be passive with vanishing ergotropy. A phenomenological relation between ergotropy and entanglement is uncovered, which generalizes the existing free fermion integrable results to an interacting scenario. The ergotropy in a dynamical protocol shows that a reset with a global uniform coherent rotation can inject extractable energy, as a proof of principle way to charge a quantum "battery". Our protocol is tailored for near term Rydberg neutral atoms array, while also being feasible for other quantum processors. Our results establish that quantum many-body scars, despite the tiny fraction of the Hilbert space they occupy, can be efficiently exploited for storing extractable energy, and "scarring" a many-body system as a promising route for engineering quantum many-body battery.

</details>


### [25] [Local Operations and Field Mediated Entanglement without a Local Tensor Product Structure](https://arxiv.org/abs/2512.19806)
*Alberto Spalvieri,Sébastien Christophe Garmier,Flaminia Giacomini*

Main category: quant-ph

TL;DR: 该研究为规范场论构建了规范不变局部代数，在缺乏局部张量积结构的规范理论中建立了操作一致的局域性概念，并证明了离散化电磁学满足LOCC定理的类似物。


<details>
  <summary>Details</summary>
Motivation: 量子信息理论假设子系统局域性（总希尔伯特空间分解为子系统），但规范约束阻止总希尔伯特空间分解为时空局域张量积结构。由于规范理论的希尔伯特空间结构无法容纳量子信息理论中使用的子系统分解，标准信息论结果（如LOCC定理）不能直接应用于规范理论。

Method: 研究二维晶格规范模型，构建规范不变局部代数，推导希尔伯特空间的物理意义分解，在缺乏局部张量积结构的情况下提供操作一致的局域性概念。将该框架应用于与量子引力测试相关的场介导纠缠协议。

Result: 离散化版本的电磁学满足LOCC定理的类似物：即使在没有希尔伯特空间的时空局域张量积分解的情况下，没有真正的量子场相互作用也无法产生纠缠。这为规范理论定义子系统结构提供了操作性的方法。

Conclusion: 该研究在规范理论与量子信息理论之间架起了桥梁，为规范理论建立了操作一致的局域性概念，并证明了即使在缺乏传统张量积结构的情况下，规范理论仍然满足量子信息的基本原理，这为定义规范理论的子系统结构提供了新途径。

Abstract: Quantum information has become a powerful tool for probing the structure of quantum field theories, yet its application to gauge theories remains subtle. On the one hand, quantum information theory assumes subsystem locality, i.e.~the factorization of the total Hilbert space into subsystems. On the other hand, gauge constraints prevent the total Hilbert space to decompose into a spacetime-local tensor product structure. Because the Hilbert space structure of gauge theories does not accommodate the subsystem decomposition used in quantum information theory, standard information-theoretic results, such as the Local Operations and Classical Communication (LOCC) theorem, cannot be used straightforwardly in the context of gauge theories. In this work, we bridge this gap in the case of a two-dimensional lattice gauge model that captures key features of electromagnetism. In particular, we construct gauge-invariant local algebras and derive a physically meaningful decomposition of the Hilbert space, providing an operationally consistent notion of locality in the absence of a local tensor-product structure. We apply this framework to field-mediated entanglement protocols relevant to proposed tests of the quantum nature of gravity. We show that the discretized version of electromagnetism satisfies an analogue of the LOCC theorem: entanglement cannot be generated without genuine quantum field interactions, even in the absence of a spacetime-local tensor product factorization of the Hilbert space. This may point towards an operational way to define a subsystem structure for gauge theories.

</details>


### [26] [Fundamentals of quantum Boltzmann machine learning with visible and hidden units](https://arxiv.org/abs/2512.19819)
*Mark M. Wilde*

Main category: quant-ph

TL;DR: 该论文推导了量子玻尔兹曼机中可见单元与隐藏单元情况下量子相对熵梯度的解析表达式，并提出了相应的量子估计算法。


<details>
  <summary>Details</summary>
Motivation: 经典玻尔兹曼机在生成建模中已有成熟应用，但将其推广到具有可见和隐藏单元的量子玻尔兹曼机进行量子态学习一直存在障碍。需要解决量子相对熵梯度的计算问题。

Method: 推导了量子玻尔兹曼机中可见单元约化态与目标量子态之间量子相对熵梯度的解析表达式，该表达式可通过量子计算机估计。使用了模流生成的幺正旋转技术，类似于先前关于旋转Petz恢复映射的工作。针对量子可见单元-经典隐藏单元和经典可见单元-量子隐藏单元两种特殊情况提供了梯度表达式和量子算法。还将目标函数扩展到Petz-Tsallis相对熵。

Result: 获得了量子相对熵梯度的解析表达式，该表达式适合量子计算机估计。提出了相应的量子梯度估计算法。针对特殊情况提供了专门的梯度表达式和算法。还推导了Petz-Tsallis相对熵梯度的表达式并设计了估计算法。

Conclusion: 该论文在训练具有可见和隐藏单元的量子玻尔兹曼机方面取得了重要进展，为生成建模和量子态学习提供了理论基础和实用算法。

Abstract: One of the primary applications of classical Boltzmann machines is generative modeling, wherein the goal is to tune the parameters of a model distribution so that it closely approximates a target distribution. Training relies on estimating the gradient of the relative entropy between the target and model distributions, a task that is well understood when the classical Boltzmann machine has both visible and hidden units. For some years now, it has been an obstacle to generalize this finding to quantum state learning with quantum Boltzmann machines that have both visible and hidden units. In this paper, I derive an analytical expression for the gradient of the quantum relative entropy between a target quantum state and the reduced state of the visible units of a quantum Boltzmann machine. Crucially, this expression is amenable to estimation on a quantum computer, as it involves modular-flow-generated unitary rotations reminiscent of those appearing in my prior work on rotated Petz recovery maps. This leads to a quantum algorithm for gradient estimation in this setting. I then specialize the setting to quantum visible units and classical hidden units, and vice versa, and provide analytical expressions for the gradients, along with quantum algorithms for estimating them. Finally, I replace the quantum relative entropy objective function with the Petz-Tsallis relative entropy; here I develop an analytical expression for the gradient and sketch a quantum algorithm for estimating it, as an application of a novel formula for the derivative of the matrix power function, which also involves modular-flow-generated unitary rotations. Ultimately, this paper demarcates progress in training quantum Boltzmann machines with visible and hidden units for generative modeling and quantum state learning.

</details>


### [27] [Disorder-induced broadening of quantum momentum distribution](https://arxiv.org/abs/2512.20170)
*Vili Heinonen,Jani Lukkarinen*

Main category: quant-ph

TL;DR: 研究二维量子气体在长程关联弱随机势中的长时间行为，发现初始动量分布会变得各向同性并展宽，推导了动量分布的长时间平均值表达式并通过模拟验证


<details>
  <summary>Details</summary>
Motivation: 研究非相互作用二维量子气体在具有长程关联的弱随机势中的长时间动力学行为，特别是动量分布如何随时间演化

Method: 理论推导动量分布的长时间平均值表达式，并通过计算机模拟进行验证，同时讨论动量各向同性和空间扩散过程

Result: 任何峰值的初始动量分布最终都会因与随机势的散射事件而变得各向同性并展宽，推导的理论表达式与计算机模拟结果一致

Conclusion: 在长程关联弱随机势中，二维量子气体的动量分布会经历各向同性化和展宽过程，理论推导的长时间平均值表达式能够准确描述这一行为

Abstract: We study the long-time behavior of a non-interacting two-dimensional quantum gas in a weak random potential with long-range correlations. Any peaked initial momentum distribution will eventually become isotropic and broaden due to scattering events with the random potential. We derive an expression for the long-time average of the momentum distribution and test it against computer simulations. We also discuss momentum isotropization and spatial diffusion.

</details>


### [28] [Quantum Mechanics on Lie Groups: I. Noncommutative Fourier Transforms](https://arxiv.org/abs/2512.19840)
*Mathieu Beauvillain,Blagoje Oblak,Marios Petropoulos*

Main category: quant-ph

TL;DR: 该论文构建了从李群上的平方可积波函数到李代数对偶空间上波函数的可逆傅里叶变换，建立了非对易傅里叶级数理论，并推导了紧李群的非对易泊松求和公式。


<details>
  <summary>Details</summary>
Motivation: 研究动机是建立李群上量子系统的傅里叶分析框架，解决非对易动量空间带来的数学挑战，为计算群流形上量子系统的维格纳函数和路径积分奠定基础。

Method: 方法是从李群上的平方可积波函数出发，构建可逆傅里叶变换映射到李代数对偶空间，处理非对易动量导致的星积乘法，建立希尔伯特空间的等距映射。

Result: 结果证明了该形式主义提供了希尔伯特空间的等距性，并推导出了适用于任何紧李群的非对易泊松求和公式。

Conclusion: 结论是该框架为群流形上量子系统的维格纳函数和路径积分计算提供了关键的数学基础，是非对易傅里叶分析的重要进展。

Abstract: Starting from square-integrable wave functions on a Lie group, we build an invertible Fourier transform mapping them on wave functions on the dual of the Lie algebra. This is a group-theoretic version of the map from position space to momentum space, with generally noncommuting momenta owing to the group structure. As a result, the multiplication of momentum-dependent functions involves star products, which makes the construction of noncommutative Fourier series much more involved than that of their commutative cousin. We show that our formalism provides an isometry of Hilbert spaces, and use it to derive a noncommutative Poisson summation formula for any compact Lie group. This is a key preliminary for the computation of Wigner functions and path integrals for quantum systems on group manifolds.

</details>


### [29] [Profusion of Symmetry-Protected Qubits from Stable Ergodicity Breaking](https://arxiv.org/abs/2512.20393)
*Thomas Iadecola,Rahul Nandkishore*

Main category: quant-ph

TL;DR: 论文展示了如何通过结合离散对称性和拓扑希尔伯特空间碎片化来产生指数级数量的拓扑稳定量子比特，这些量子比特受到单一离散对称性的保护。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索如何增强量子比特的鲁棒性，特别是通过结合离散对称性和拓扑希尔伯特空间碎片化来创建对对称性保持扰动具有参数长时间稳定性的量子比特。

Method: 使用CZ_p模型作为具体示例，该模型结合了离散对称性和拓扑希尔伯特空间碎片化，创建了成对出现的编码量子比特，这些量子比特具有横向逻辑门操作能力。

Result: 该模型产生了指数级数量的拓扑稳定量子比特，这些量子比特对任意对称性保持扰动具有参数长时间的稳定性，显著增强了基于非拓扑碎片化构造的鲁棒性。

Conclusion: 虽然这种构造产生了高度稳定的量子比特，但由于Eastin-Knill定理的限制，它们不能用于量子纠错。论文还讨论了对称性富集和拓扑碎片化的一般组合及其对使用希尔伯特空间碎片化系统作为量子存储器的影响。

Abstract: We show how combining a discrete symmetry with topological Hilbert space fragmentation can give rise to exponentially many topologically stable qubits protected by a single discrete symmetry. We illustrate this explicitly with the example of the $\mathsf{CZ}_p$ model, where the encoded qubits are stable to arbitrary symmetry-respecting perturbations for parametrically long times, substantially enhancing the robustness of a recently proposed construction based on nontopological fragmentation. In this model, the encoded qubits naturally come in pairs for which a universal set of transversal logical gates can be performed, ruling out (by the Eastin-Knill theorem) the possibility of using them for quantum error correction. We also comment on the combination of symmetry enrichment and topological fragmentation more generally, and the implications for use of systems exhibiting Hilbert space fragmentation as quantum memories.

</details>


### [30] [Complexity and Information in Quantum and Classical Trajectories](https://arxiv.org/abs/2512.19848)
*Hira Ali,Naeem Shahid*

Main category: quant-ph

TL;DR: 量子轨迹与经典模型在耦合增强时都会从独立转向同步，但只有量子轨迹在大驱动-衰减比下展现出增强的复杂性和持续的信息共享，形成独特的复杂性-信息相关性特征。


<details>
  <summary>Details</summary>
Motivation: 研究开放系统中量子与经典动力学的区别，探索直接从跃迁记录中提取的复杂性和信息度量能否有效区分量子与经典行为。

Method: 分析驱动-耗散双量子比特系统和匹配速率的经典电报模型的发射轨迹，使用Lempel-Ziv复杂性、互信息和时间相关性等度量方法。

Result: 两种模型都随耦合增强从独立转向同步，但只有量子轨迹在大驱动-衰减比下展现出增强的复杂性和持续的信息共享。经典相关性短暂且被强驱动抑制，量子情况出现独特的复杂性-信息相关性。

Conclusion: 直接从跃迁记录中提取的复杂性和信息度量提供了区分开放系统中量子与经典动力学的有效方法，量子轨迹展现出独特的复杂性-信息相关性特征。

Abstract: We analyze emission trajectories from a driven-dissipative two-qubit system and a classical telegraph model with matched rates. Using Lempel-Ziv complexity, mutual information, and temporal correlations, we show that both models undergo a transition from independent to synchronized dynamics as coupling increases, but only the quantum trajectories develop enhanced complexity and sustained information sharing at large drive-to-decay ratio. Classical correlations are short-lived and quickly suppressed by strong drive. A strong complexity-information correlation appears uniquely in the quantum case, providing a clear trajectory-level signature of quantum effects. These results show that complexity and information measures extracted directly from jump records provide an efficient way to distinguish quantum and classical dynamics in open systems.

</details>


### [31] [Coexistence of distinct Discrete Time-Crystalline orders in the Floquet Lipkin-Meshkov-Glick model](https://arxiv.org/abs/2512.20603)
*Shashank Mishra,Sayan Choudhury*

Main category: quant-ph

TL;DR: 该研究展示了在空间非均匀周期性驱动下，Lipkin-Meshkov-Glick模型中可以出现不同的离散时间晶体，并且通过定制驱动协议，可以在系统的不同空间区域实现不同的DTC序，从而产生空间变化的亚谐响应。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过空间结构化的驱动来工程新型时间晶体序，研究在非均匀周期性驱动下，不同空间区域能否实现不同的离散时间晶体序。

Method: 使用Lipkin-Meshkov-Glick模型，施加空间非均匀周期性驱动，通过半经典分析来研究不同DTC序在热力学极限下的稳定性，并考虑量子涨落的影响。

Result: 通过适当定制驱动协议，可以在系统的不同空间区域实现不同的DTC序，系统表现出具有不同频率的空间变化亚谐响应。这些共存的DTC序在热力学极限下是稳定的，并且在量子涨落存在下也保持稳定。

Conclusion: 空间结构化驱动是实现新型时间晶体序的有效途径，为工程具有空间变化特性的时间晶体提供了新思路。

Abstract: We examine the distinct discrete time crystals (DTCs) that emerge in the Lipkin-Meshkov-Glick model, subjected to spatially nonuniform periodic driving. Intriguingly, we demonstrate that by appropriately tailoring the drive protocol, distinct DTC orders can be realized in different spatial regions of the system. Consequently, the system exhibits spatially varying sub-harmonic responses with distinct frequencies. We employ a semi-classical analysis to establish the stability of these co-existing DTC orders in the thermodynamic limit. Furthermore, we establish the stability of the stability of these co-existing DTCs in the presence of quantum fluctuations. Our results establish spatially structured driving as a powerful route to engineer novel forms of time-crystalline order.

</details>


### [32] [Tunably realizing flat-bands and exceptional points in kinetically frustrated systems: An example on the non-Hermitian Creutz ladder](https://arxiv.org/abs/2512.20614)
*Debashish Dutta,Sayan Choudhury*

Main category: quant-ph

TL;DR: 该论文研究具有非互易跃迁的非厄米Creutz梯子模型，通过映射到两个解耦的非厄米SSH链，揭示了不同边界条件下参数空间的丰富结构。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中边界条件对谱结构和相图的影响，探索非厄米Creutz梯子模型中的实-复谱转变、例外点和特殊能带结构。

Method: 将非厄米Creutz梯子映射到两个解耦的非厄米SSH链，在周期边界条件下分析谱结构，在开放边界条件下进行精确解析对角化。

Result: 周期边界条件下存在精细调谐线产生全实本征值，偏离该线导致实-复谱转变；开放边界条件下存在纯实谱、纯虚谱和复谱区域，由例外线分隔，交点形成三连接点；发现平带既可作为厄米简并点也可作为非厄米例外平带出现。

Conclusion: 边界条件显著影响非厄米Creutz梯子的谱结构和相图，开放边界条件产生更丰富的相结构，非厄米平带具有比厄米情况更严格的动力学约束和独特的谱特征。

Abstract: We study a non-Hermitian extension of the Creutz ladder with generic non-reciprocal hopping. By mapping the ladder onto two decoupled non-Hermitian Su--Schrieffer--Heeger (SSH) chains, we uncover a rich structure in parameter space under different boundary conditions. Under periodic boundary conditions, the spectrum admits a fine-tuned line in parameter space with entirely real eigenvalues, while deviations from this line induce a real--complex spectral transition without crossing exceptional points. In contrast, an exact analytical diagonalization under open boundary conditions reveals extended regions in parameter space with purely real or purely imaginary spectra, separated from complex spectral domains by exceptional lines. The intersections of these exceptional lines define triple-junction points where distinct spectral regimes meet, giving rise to a structured phase diagram that is absent under periodic boundary conditions. We further show that flat bands in this system can occur both as Hermitian diabolical points and as non-Hermitian exceptional points, known as exceptional flat bands, where the dynamics is more stringent than in the Hermitian case, leading to distinct spectral and dynamical signatures.

</details>


### [33] [Dissipative quantum algorithms for excited-state quantum chemistry](https://arxiv.org/abs/2512.19870)
*Hao-En Li,Lin Lin*

Main category: quant-ph

TL;DR: 提出了一种通用的耗散算法，用于在量子设备上选择性制备从头算电子激发态，通过修改Lindblad动力学将激发态制备转化为有效的基态问题。


<details>
  <summary>Details</summary>
Motivation: 电子激发态在物理和化学现象中至关重要，但在量子设备上准确高效地制备激发态仍然具有挑战性且研究相对不足。

Method: 将激发态制备重新构建为有效的基态问题，通过适当修改Lindblad动力学，使目标激发态成为设计量子通道的唯一稳态。开发了三种互补策略，针对不同类型的先验信息（如对称性和近似能量）。

Result: 通过原子和分子光谱的数值模拟验证了方案的有效性和通用性，包括原型平面共轭分子和过渡金属配合物的价电子激发。

Conclusion: 这些结果为推进真实强关联电子系统的量子模拟方法提供了新途径。

Abstract: Electronic excited states are central to a vast array of physical and chemical phenomena, yet accurate and efficient methods for preparing them on quantum devices remain challenging and comparatively underexplored. We introduce a general dissipative algorithm for selectively preparing ab initio electronic excited states. The key idea is to recast excited-state preparation as an effective ground-state problem by suitably modifying the underlying Lindblad dynamics so that the target excited state becomes the unique steady state of a designed quantum channel. We develop three complementary strategies, tailored to different types of prior information about the excited state, such as symmetry and approximate energy. We demonstrate the effectiveness and versatility of these schemes through numerical simulations of atomic and molecular spectra, including valence excitations in prototypical planar conjugated molecules and transition-metal complexes. Taken together, these results provide a new pathway for advancing quantum simulation methods for realistic strongly correlated electronic systems.

</details>


### [34] [Generalized coherent states in thermal field dynamics in the frame of diagonal ordering operator technique](https://arxiv.org/abs/2512.19880)
*Dušan Popov*

Main category: quant-ph

TL;DR: 论文展示了热场动力学方法可扩展到变形玻色子系统，构建了温度相关的相干态，并应用了DOOT技术处理算符计算。


<details>
  <summary>Details</summary>
Motivation: 传统热场动力学主要应用于具有标准升降算符的系统，本文旨在将该方法扩展到变形玻色子系统，探索其在更广泛量子系统中的应用可能性。

Method: 为变形玻色子系统构建温度相关的相干态（包括Barut-Girardello型和Klauder-Perelomov型），应用对角算符排序技术（DOOT）处理变形升降算符的计算，并建立热场动力学与热力学量的联系。

Result: 成功将热场动力学框架扩展到变形玻色子系统，建立了两种对偶的温度相关相干态，验证了DOOT技术在变形算符计算中的适用性。

Conclusion: 热场动力学方法可有效应用于变形玻色子系统，为研究这类系统的热力学性质提供了新的理论工具，扩展了热场动力学的适用范围。

Abstract: Although the thermofield dynamics (TFD) was developed specifically for systems to which the ladder canonical operators and are associated, in the paper we showed that this approach can also be formulated for systems of deformed bosons, associated with a pair of deformed operators and . In this context we built sets of temperature dependent coherent states, both of the Barut-Girardello and of the Klauder-Perelomov type, these two types being dual to each other. In calculations involving ladder operators, both independent and temperature-dependent, we used the Diagonal Operator Ordering Technique (DOOT), which is a generalization of the Integration Within an Ordered Product technique (IWOP) applicable to canonical operators associated with the one-dimensional harmonic oscillator. We also refer to the connection between TFD and thermodynamic quantities.

</details>


### [35] [Gate-Based Microwave Quantum Repeater Via Grid-State Encoding](https://arxiv.org/abs/2512.19896)
*Hany Khalifa,Matti Silveri*

Main category: quant-ph

TL;DR: 该论文提出了一种基于微波量子中继器的第二代门控方案，使用编码的玻色网格态和自主量子纠错技术，实现了确定性纠缠生成和全玻色纠缠交换测量，显著提高了纠缠生成和交换的成功概率。


<details>
  <summary>Details</summary>
Motivation: 传统量子中继器使用概率性光束分束器进行纠缠生成和贝尔态测量，存在模式失配损耗和成功率限制（理想情况下最高1/2）。需要开发一种确定性、高成功率的量子中继器方案，适用于芯片间安全通信和分布式量子计算。

Method: 采用自主量子纠错编码的玻色网格态作为量子存储器，每个中继站包含一个transmon和两个玻色谐振器：一个作为使用自主纠错的静态量子存储器，另一个作为纠缠生成的信息总线。通过微波光子波包的成功吸收实现确定性纠缠生成，使用全玻色纠缠交换贝尔态测量，通过玻色控制-Z门和两个独立的X基投影零差测量实现。

Result: 在静态阻尼率κ_damp^{-1}=40毫秒的条件下，该方案可以实现约0.75的纠缠生成成功概率和约0.58的纠缠交换成功概率，超过了理想线性光束分束器贝尔态测量的1/2标志性成功率。该设备可使用现有超导微波技术实现。

Conclusion: 提出的门控微波量子中继器方案通过自主量子纠错和确定性纠缠生成机制，显著提高了量子中继器的性能，避免了传统光束分束器方案的模式失配损耗，为芯片间安全通信和分布式量子计算提供了实用化解决方案。

Abstract: In autonomous quantum error correction the lifetime of a logical bosonic qubit can be extended beyond its physical constituents without feedback measurements. Leveraging autonomous error correction, we propose a second-generation gate-based microwave quantum repeater (GBMQR) with encoded bosonic grid states. Each repeater station comprises a transmon and two bosonic resonators: one resonator serving as a stationary quantum memory utilizing autonomous error correction, and the other as an information bus for entanglement generation. Entanglement is generated sequentially through the successful absorption of a microwave photon wavepacket. This method enables deterministic entanglement generation, in contrast to a probabilistic mixing of two heralding signals on a balanced beamsplitter. Furthermore, our GBMQR employs an all-bosonic entanglement swapping Bell-state measurement. This is implemented via a bosonic controlled-Z gate and two separate X-basis projective homodyne measurements on the stationary stored codewords. Our approach circumvents mode-mismatch losses associated with routing and interfering of heralding modes on a beamsplitter, and confines losses to those arising from stationary storage. We evaluate the performance of the proposed quantum repeater by calculating its secret key rate under realistic lab environments. Moreover, we explicitly demonstrate that at stationary damping rate of $κ^{-1}_{\text{damp}}=$~\SI{40}{\milli\second}, GBMQR can achieve entanglement generation and swapping success probabilities approx.~$0.75$, and $0.58$ respectively, surpassing the hallmark success probability of $1/2$ set by ideal linear beamsplitter-based Bell-state measurements. The proposed device can be implemented using currently available superconducting microwave technology and is suited for secure chip-to-chip communication and distributed quantum computing.

</details>


### [36] [DC-powered broadband quantum-limited microwave amplifier](https://arxiv.org/abs/2512.19902)
*N. Nehra,N. Bourlet,A. H. Esmaeili,B. Monge,F. Cyrenne-Bergeron,A. Paquette,M. Arabmohammadi,A. Rogalle,Y. Lapointe,M. Hofheinz*

Main category: quant-ph

TL;DR: 首次展示了直流供电的宽带放大器，在量子极限0.2个光子内工作，无需传统参量放大所需的泵浦音基础设施，显著简化超导量子处理器中的量子极限放大硬件。


<details>
  <summary>Details</summary>
Motivation: 超导量子比特的单次读取需要量子极限放大器以保持最佳信噪比，但传统的参量下转换放大需要强泵浦音，硬件开销大且严重限制可扩展性。

Method: 开发了阻抗工程化的非弹性库珀对隧穿放大器（ICTA），这是一种电压偏置的SQUID，其中库珀对通过发射信号-闲频光子对进行非弹性隧穿，工作在反射模式。

Result: ICTA在单级中提供13 dB的平均增益，带宽3.5 GHz，工作在量子极限0.2个光子内，半经典模拟能准确预测增益和饱和功率。

Conclusion: 通过消除泵浦音基础设施，宽带ICTA有望显著降低超导量子处理器中量子极限放大的硬件复杂性，提高可扩展性。

Abstract: Fast, high-fidelity, single-shot readout of superconducting qubits in quantum processors demands quantum-limited amplifiers to preserve the optimal signal-to-noise ratio. Typically, quantum-limited amplification is achieved with parametric down-conversion of a strong pump tone, which imposes significant hardware overhead and severely limits scalability. Here, we demonstrate the first DC-powered broadband amplifier operating within 0.2 photons of the quantum limit. Our impedance-engineered Inelastic Cooper-pair Tunneling Amplifier (ICTA)-a voltage-biased SQUID in which Cooper pairs tunnel inelastically by emitting signal-idler photon pairs-operates in reflection, delivering 13 dB of average gain across a 3.5 GHz bandwidth in a single stage. Semiclassical simulations accurately predict the gain and saturation power, enabling further design improvements. By eliminating the pump-tone infrastructure, the broadband ICTA promises to dramatically reduce the hardware complexity of quantum-limited amplification in superconducting quantum processors.

</details>


### [37] [Analytical blueprint for 99.999% fidelity X-gates on present superconducting hardware under strong driving](https://arxiv.org/abs/2512.19919)
*José Diogo Da Costa Jesus,Boxi Li,Yuan Gao,Rami Barends,Francisco Andrés Cárdenas-López,Felix Motzoi*

Main category: quant-ph

TL;DR: 该论文研究了超导量子比特在强驱动下的快速门操作，通过抑制多光子跃迁和泄漏误差，实现了低于10^-5的栅极保真度。


<details>
  <summary>Details</summary>
Motivation: 在超导量子计算平台中，实现超越半经典时变模型预测的单量子比特控制尚未实验实现。强驱动下，传统的三能级动力学模型失效，新的量子误差通道随门时间缩短而急剧增长，需要系统识别和抑制这些误差过程。

Method: 系统计算了计算空间外的多光子跃迁效应，推导了抑制这些效应以及量子比特空间振幅和相位误差的解析公式（R1D抑制|0⟩-|2⟩跃迁，R2D同时抑制|1⟩-|3⟩泄漏）。确定了考虑时间顺序时DRAG预因子和恒定失谐的最优值，并展示了如何校准其他预因子以进一步提升性能。

Result: 在纠正各种误差源后，结合现有的退相干率，数值模拟显示7ns π旋转的栅极保真度低于10^-5。

Conclusion: 通过系统识别和抑制强驱动下的多光子跃迁误差，实现了超导量子比特的高保真快速门操作，为超越传统模型的量子控制提供了理论框架和实验指导。

Abstract: Achieving very fast gates that undercut the natural limits set by decoherence requires going into the strong driving limit. Realizing single-qubit control predicted beyond semi-classical, time-dependent modeling has yet to be experimentally realized on superconducting and most other computing platforms. In this regime, the common model of dynamics within a three-level manifold breaks down, and instead, we see new quantum error channels growing abruptly with decreasing time. To identify these error processes we systematically calculate the effect of multi-photon transitions that occur out of the computational space. We then derive analytical formulas to suppress these effects, as well as amplitude and phase errors on the qubit space; we term these R1D for suppressing the $|0\rangle-|2\rangle$ transition and R2D when also suppressing $|1\rangle-|3\rangle$ leakage. We also answer long-standing questions about the optimal values of the DRAG prefactor as well as constant detuning, when accounting for time-ordering, and also show how to calibrate other prefactors for further performance improvement. Upon correcting these varied sources of error, we numerically demonstrate gate infidelities below $10^{-5}$ for a 7ns $π$-rotation when incorporating existing decoherence rates.

</details>


### [38] [Nonclassicality of Mixed States with Photon Number Coherence](https://arxiv.org/abs/2512.19953)
*Spencer Rogers,Salman Shahid,Wenchao Ge*

Main category: quant-ph

TL;DR: ORT非经典性度量在混合态中的计算：针对具有光子数相干的混合态，给出了秩二混合态的精确公式和高秩态的数值解，并比较了非经典性与计量能力的关系。


<details>
  <summary>Details</summary>
Motivation: ORT度量虽然具有资源理论性质和计量学联系，但对混合态的计算困难，需要解决优化问题。本文旨在首次计算具有光子数相干的混合态的ORT度量。

Method: 针对具有光子数相干的混合态，推导了秩二混合态的ORT度量精确公式，并对高秩态提供数值解。同时分析了相干性在非经典性和计量能力中的作用。

Result: 获得了秩二混合态的精确ORT公式和高秩态的数值解。发现非经典性和计量能力在玻色子退相干下不会增加，但可能像纠缠突然死亡一样达到平台期。降低光子数相干有时能产生更具非经典性和计量价值的态。

Conclusion: 首次实现了具有光子数相干的混合态的ORT度量计算，揭示了相干性在非经典性和计量能力中的复杂作用，并确定了计量能力达到ORT界限的条件。

Abstract: The operational resource theory (ORT) measure is a nonclassicality measure for bosonic states, notable for its resource-theoretic properties and connection to metrology. However, it can be difficult to evaluate, being linked to an optimization problem for mixed states. Here, we present the first ORT measure calculations for mixed states with photon number coherence. We give exact formulas governing the ORT measure of a broad class of rank-two mixed states, and numerical solutions for some higher-rank states. We also compare the nonclassicality of these states to their metrological power, thus showing in what regimes the metrological power manages to saturate the ORT bound. Throughout, we consider the role of coherence. In particular, we show that nonclassicality and metrological power never increase under bosonic dephasing, but may plateau in a manner similar to entanglement sudden death. Nevertheless, lowering photon number coherence more freely can sometimes yield more nonclassical and metrologically useful states.

</details>


### [39] [Solving Segment Display Problems Using Quantum Grover's Search Algorithm](https://arxiv.org/abs/2512.19969)
*Shanyan Chen,Ali Al-Bayaty,Xiaoyu Song,Marek Perkowski*

Main category: quant-ph

TL;DR: 本文提出了一种基于布尔逻辑的新方法，用于在量子领域构建段显示问题(SDPs)，并使用Grover量子搜索算法求解。


<details>
  <summary>Details</summary>
Motivation: 传统SDPs通常通过人工推理、启发式搜索、布尔可满足性(SAT)和约束满足问题(CSP)等方法解决。本文旨在探索量子计算在解决此类问题上的潜力，特别是利用Grover算法加速搜索过程。

Method: 提出了一种基于量子计算的新方法：1) 使用二进制可逆电路构建SDPs的量子预言机；2) 应用先前提出的步减结构形状算子(Stesso)；3) 通过Grover量子搜索算法求解；4) 在Qiskit中实现噪声模拟量子计算机进行实验验证。

Result: 通过实验成功解决了火柴棒问题的SDP实例，验证了所提方法在量子计算环境中的可行性，展示了量子算法在解决段显示问题上的应用潜力。

Conclusion: 本文提出的布尔基量子方法为SDPs的求解提供了新的量子计算途径，通过构建量子预言机和利用Grover算法，展示了量子计算在解决此类组合优化问题上的优势。

Abstract: This paper introduces a new Boolean-based methodology for constructing Segment Display Problems (SDPs) in the quantum domain and solving them using Grover's quantum search algorithm. In the classical domain, the SDPs are typically solved using various techniques, such as human deduction, heuristic search, and methods for solving Boolean satisfiability (SAT) and constraint satisfaction problems (CSPs) that are based on different problem design models. In this paper, our newly introduced methodology proposes a quantum-based approach for solving such SDPs, by building their quantum oracle using binary reversible circuits and our previously proposed step-decreasing structures shaped operators (Stesso). To demonstrate the usability of this proposed method, we experimentally solve an SDP instance of the matchstick problem using Grover's algorithm with a noisy simulated quantum computer implemented in Qiskit.

</details>


### [40] [Real Matrix Representations of Quantum Operators: An Introduction to Quantum Index Algebra](https://arxiv.org/abs/2512.19977)
*A. Yu. Volkov,G. A. Koroteev,Yu. S. Volkov*

Main category: quant-ph

TL;DR: QIA是一种基于布尔码索引的有限代数框架，用于表示和操作量子算子，通过离散索引规则而非密集矩阵运算进行计算，并重新表述了Bernstein-Vazirani问题。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的代数框架来统一量子算子的组合索引结构、显式矩阵实现和变换性质，旨在分离真正的量子资源与代数组合结构，为结构化量子电路的经典可模拟性提供新视角。

Method: 引入量子索引代数(QIA)作为有限维希尔伯特空间上的索引代数框架，使用布尔码索引的基元素结构化组合表示算子，通过有限离散索引规则计算乘积、对易子和共轭，并应用块矩阵实现重新表述Bernstein-Vazirani问题。

Result: QIA能够精确重现Bernstein-Vazirani算法，达到相同的渐近查询复杂度和电路深度，通过稀疏代数表示的符号操作而非量子振幅的数值模拟恢复隐藏字符串，证明该场景中的量子加速源于算子结构而非希尔伯特空间维度。

Conclusion: QIA提供了一种精确语言来区分真正的量子资源与代数组合结构产生的资源，为结构化量子电路的经典可模拟性提供了新视角，表明某些量子加速效应可以完全在有限维代数框架中捕获。

Abstract: We introduce Quantum Index Algebra (QIA) as a finite, index-based algebraic framework for representing and manipulating quantum operators on Hilbert spaces of dimension $2^m$. In QIA, operators are expressed as structured combinations of basis elements indexed by Boolean codes, allowing products, commutators, and conjugations to be computed through finite rules on discrete indices rather than through dense matrix arithmetic. This representation unifies combinatorial index structure, explicit matrix realization, and transformation properties under Walsh-Hadamard-type transforms within a single formalism. Using QIA and its associated block-matrix realization, we reformulate the Bernstein-Vazirani hidden-string problem in its phase-oracle form entirely within a real, finite-dimensional algebraic setting. We show that, under structured oracle access, the QIA procedure reproduces the Bernstein-Vazirani algorithm exactly and achieves the same asymptotic query complexity and circuit depth as the standard quantum algorithm. In particular, the hidden string is recovered by symbolic manipulation of a sparse algebraic representation of the oracle rather than by numerical simulation of quantum amplitudes. Our results demonstrate that the apparent quantum speed-up in this setting is a consequence of operator structure rather than Hilbert-space dimensionality alone. QIA thus provides a precise language for separating genuinely quantum resources from those arising from algebraic and combinatorial structures and offers a new perspective on the classical simulability of structured quantum circuits.

</details>


### [41] [$\mathscr{H}_2$ Model Reduction for Augmented Model of Linear Non-Markovian Quantum Systems](https://arxiv.org/abs/2512.20040)
*Guangpu Wu,Shibei Xue,Guofeng Zhang,Rebing Wu,Min Jiang,Ian R. Petersen*

Main category: quant-ph

TL;DR: 本文提出了一种用于线性非马尔可夫量子系统增广模型的H2模型降阶方法，解决了因环境内部模式过多导致的计算负担问题。


<details>
  <summary>Details</summary>
Motivation: 增广系统模型能有效建模非马尔可夫量子系统，但由于大量代表环境内部模式的量子振荡器直接与主系统相互作用，增广系统维度可能非常大，导致滤波器和控制器的设计计算负担沉重。

Method: 首先建立线性非马尔可夫量子系统增广模型物理可实现性的充要条件；针对模型降阶优化问题中的非凸约束，推导确定降阶模型输入矩阵的必要条件，并证明降阶系统中辅助系统矩阵的设计定理；将非线性等式约束转化为不等式约束，开发半定规划算法求解模型降阶优化问题。

Result: 通过一个由非马尔可夫环境三个内部模式驱动的双模线性量子系统的数值示例，验证了所提方法的有效性。

Conclusion: 本文提出的H2模型降阶方法能有效降低非马尔可夫量子系统增广模型的维度，减轻计算负担，同时保持物理可实现性约束，为这类系统的滤波和控制设计提供了实用工具。

Abstract: An augmented system model provides an effective way to model non-Markovian quantum systems, which is useful in filtering and control for this class of systems. However, since a large number of ancillary quantum oscillators representing internal modes of a non-Markovian environment directly interact with the principal system in these models, the dimension of the augmented system may be very large causing significant computational burden in designing filters and controllers. In this context, this paper proposes an $\mathscr{H}_2$ model reduction method for the augmented model of linear non-Markovian quantum systems. We first establish necessary and sufficient conditions for the physical realizability of the augmented model of linear non-Markovian quantum systems, which are more stringent than those for Markovian quantum systems. However, these physical realizability conditions of augmented system model pose non-convex constrains in the optimization problem of model reduction, which makes the problem different from the corresponding classical model reduction problem. To solve the problem, we derive necessary conditions for determining the input matrix in the reduced model, with which a theorem for designing the system matrix of the ancillary system in the reduced system is proved. Building on this, we convert the nonlinear equality constraints into inequality constraints so that a semidefinite programming algorithm can be developed to solve the optimization problem for model reduction.
  A numerical example of a two-mode linear quantum system driven by three internal modes of a non-Markovian environment validates the effectiveness of our method.

</details>


### [42] [Fault Injection Attacks on Machine Learning-based Quantum Computer Readout Error Correction](https://arxiv.org/abs/2512.20077)
*Anthony Etim,Jakub Szefer*

Main category: quant-ph

TL;DR: 该研究首次分析了量子计算系统中机器学习分类器对物理故障注入的脆弱性，发现通过电压毛刺攻击可以导致量子计算机产生错误的读出结果，且故障易感性具有层次依赖性。


<details>
  <summary>Details</summary>
Motivation: 机器学习分类器在量子计算系统中被广泛用于改进多量子比特读出识别和缓解相关读出错误，已成为量子计算机控制和读出堆栈的关键组成部分。然而，这些ML分类器对物理故障注入的脆弱性尚未被研究，这可能影响量子计算机的可靠性和安全性。

Method: 针对5量子比特（32类）读出纠错模型，使用ChipWhisperer Husky进行物理电压毛刺注入。开发自动化算法扫描故障注入参数搜索空间，在目标ML模型的所有层次中寻找成功的故障注入点。通过重复试验分析故障易感性，并使用汉明距离和每比特翻转统计来表征故障导致的读出失败。

Result: 研究发现故障易感性具有强烈的层次依赖性：早期层次在触发故障时表现出更高的错误预测率，而后期层次的错误预测率较小。单次毛刺注入可以导致结构化的读出损坏，而非纯粹的随机噪声。故障注入能够成功影响ML模型的所有层次。

Conclusion: 基于机器学习的量子计算机读出和读出纠错应被视为量子系统的安全关键组件。需要在量子计算机读出管道中实施轻量级、易于部署的故障检测和冗余机制，以提高系统的可靠性和安全性。

Abstract: Machine-learning (ML) classifiers are increasingly used in quantum computing systems to improve multi-qubit readout discrimination and to mitigate correlated readout errors. These ML classifiers are an integral component of today's quantum computer's control and readout stacks. This paper is the first to analyze the susceptibility of such ML classifiers to physical fault-injection which can result in generation of incorrect readout results from quantum computers. The study targets 5-qubit (thus 32-class) readout error-correction model. Using the ChipWhisperer Husky for physical voltage glitching, this work leverages an automated algorithm for scanning the fault injection parameter search space to find various successful faults in all the layers of the target ML model. Across repeated trials, this work finds that fault susceptibility is strongly layer-dependent: early-layers demonstrate higher rates of misprediction when faults are triggered in them, whereas later layers have smaller misprediction rates. This work further characterizes the resulting readout failures at the bitstring level using Hamming-distance and per-bit flip statistics, showing that single-shot glitches can induce structured readout corruption rather than purely random noise. These results motivate treating ML-based quantum computer readout and readout correction as a security-critical component of quantum systems and highlight the need for lightweight, deployment-friendly fault detection and redundancy mechanisms in the quantum computer readout pipelines.

</details>


### [43] [Force Sensing Beyond the Standard Quantum Limit in a Hybrid Optomechanical Platform](https://arxiv.org/abs/2512.20081)
*Alolika Roy,Amarendra K. Sarma*

Main category: quant-ph

TL;DR: 该研究通过理论分析混合光力学系统中的量子测量噪声，展示了量子点响应与系统非线性如何改善力测量灵敏度，实现了超越标准量子极限的弱力传感。


<details>
  <summary>Details</summary>
Motivation: 研究混合光力学系统中的量子测量噪声，特别是辐射压力反作用对力传感的影响，旨在探索如何通过量子噪声消除技术提高力测量灵敏度并超越标准量子极限。

Method: 构建包含可移动镜面、固定半透明镜面、量子点系综和腔内光学参量放大器的混合光力学系统模型，理论分析量子点诱导响应和系统非线性对噪声谱密度的影响。

Result: 量子点响应与系统非线性共同修改噪声谱密度，相干量子噪声消除技术可完全消除反作用噪声，增加OPA泵浦增益可在降低激光功率条件下实现超越标准量子极限的灵敏度。

Conclusion: 混合光力学系统结合量子点响应、系统非线性和相干量子噪声消除技术，能够实现超越标准量子极限的弱力传感，为高精度力测量提供了新途径。

Abstract: We theoretically investigate quantum measurement noise in a hybrid optomechanical system, focusing on radiation pressure back action and its impact on force sensing. The setup consists of an optomechanical cavity with a movable mirror, a fixed semi transparent mirror, an ensemble of quantum dots (QD) coupled to the cavity mode, and an intracavity optical parametric amplifier (OPA). We show how the QD induced response, together with the system nonlinearity, modifies the noise spectral density and thereby improves the force measurement sensitivity. In this setup, coherent quantum noise cancellation (CQNC) can completely remove the back action noise. In addition, increasing the OPA pump gain enables sensitivity beyond the standard quantum limit (SQL) at reduced laser power. These combined effects allow weak force sensing beyond the SQL.

</details>


### [44] [Precision Bounds for Characterising Quantum Measurements](https://arxiv.org/abs/2512.20091)
*Aritra Das,Simon K. Yung,Lorcan O. Conlon,Ozlem Erkilic,Angus Walsh,Yong-Su Kim,Ping K. Lam,Syed M. Assad,Jie Zhao*

Main category: quant-ph

TL;DR: 论文提出了一个用于高效探测器估计的框架，引入了探测器量子费舍尔信息的概念，解决了量子测量表征相对于量子态和过程表征发展不足的问题。


<details>
  <summary>Details</summary>
Motivation: 量子测量与量子态和过程一样是量子信息处理的基石，但相比后两者，其高效表征方法相对未被充分探索。当前量子技术需要精确校准的测量，因此需要建立系统的探测器表征理论框架。

Method: 引入了一个全面的高效探测器估计框架，提出了"探测器量子费舍尔信息"的概念，该框架消除了优化最佳探测态的需求，并揭示了探测器分析与量子态估计的根本差异。

Result: 通过理论证明、实例分析和实验验证，展示了该框架在当前量子探测器技术中的相关性和鲁棒性，完成了高效态、过程和探测器层析的三位一体理论体系。

Conclusion: 该框架形式化了与态估计对偶的视角，完善并连接了高效态、过程和探测器层析的三元体系，推动了量子信息理论的发展，对依赖精确校准测量的新兴技术具有广泛意义。

Abstract: Quantum measurements, alongside quantum states and processes, form a cornerstone of quantum information processing. However, unlike states and processes, their efficient characterisation remains relatively unexplored. We resolve this asymmetry by introducing a comprehensive framework for efficient detector estimation that reveals the fundamental limits to extractable parameter information and errors arising in detector analysis - the \emph{detector quantum Fisher information}. Our development eliminates the need to optimise for the best probe state, while highlighting aspects of detector analysis that fundamentally differ from quantum state estimation. Through proofs, examples and experimental validation, we demonstrate the relevance and robustness of our proposal for current quantum detector technologies. By formalising a dual perspective to state estimation, our framework completes and connects the triad of efficient state, process, and detector tomography, advancing quantum information theory with broader implications for emerging technologies reliant on precisely calibrated measurements.

</details>


### [45] [Finite-size Effects on The Edge Loss Probability in Non-Hermitian Quantum Walks](https://arxiv.org/abs/2512.20106)
*Shuaixian Liu,Yulan Dong,Bowen Zeng,Mengqiu Long*

Main category: quant-ph

TL;DR: 该论文研究了量子行走中的动力学体边关系，发现在有限尺寸链中边界散射会抑制边缘爆发，而虚能隙打开与非厄米趋肤效应也能诱导边缘大损失概率。


<details>
  <summary>Details</summary>
Motivation: 先前研究在无限极限下证明了虚能隙闭合和非厄米趋肤效应导致边缘爆发，但实际量子系统都是有限尺寸的，需要研究边界效应如何影响这种体边关系。

Method: 研究有限尺寸量子链中的动力学行为，分析边界散射对边缘爆发的影响，同时探讨虚能隙打开与非厄米趋肤效应共同作用下的边缘损失概率。

Result: 发现边界散射会抑制边缘爆发，而虚能隙打开与非厄米趋肤效应也能诱导边缘大损失概率，这些结果与无限极限下的理论预测有所不同。

Conclusion: 有限尺寸量子系统的动力学行为与无限极限下的理论存在显著差异，边界效应在量子动力学中起着重要作用，为理解实际量子系统的有限尺寸效应提供了新见解。

Abstract: A dynamical bulk-edge relation in quantum walks has been theoretically proposed and experimentally observed, in which a power-law dependence of the bulk loss probability is associated with a pronounced peak of loss probability at the edge. This behavior has been proven to arise from imaginary gap closing and the non-Hermitian skin effect in the infinite limit without boundary effects. However, in a finite-size chain, we find that boundary scattering can suppress this edge burst. Meanwhile, imaginary gap opening together with the non-Hermitian skin effect, can also induce a large loss probability at the edge. Our results provide insights into finite-size quantum dynamics.

</details>


### [46] [Optimal control of population transfer in multi-level systems by dynamical quantum geometric tensor](https://arxiv.org/abs/2512.20131)
*Guan-Qiang Li,Yu-Qi Zhang,Hao Guo,You-Jiao Dong,Zhi-Yu Lin,Ping Peng*

Main category: quant-ph

TL;DR: 该研究从量子几何角度优化多能级系统的粒子数转移控制，基于动力学量子几何张量优化STIRAP方案，在三能级和四能级系统中实现高效转移和叠加态制备。


<details>
  <summary>Details</summary>
Motivation: 传统STIRAP方案在粒子数转移效率上存在限制（约72%），需要从量子几何角度发展更高效、更快速的优化控制方法。

Method: 基于动力学量子几何张量建立优化STIRAP的理论框架，应用于失谐Λ型三能级系统和三脚架型四能级系统，计算几何张量和非绝热跃迁速率。

Result: 优化STIRAP方案在三能级系统中转移效率超过98%（传统为72%）；四能级系统可高效制备任意比例的叠加态；发现绝热共振转移现象，共振窗口参数可将保真度提升至10^-3以下。

Conclusion: 基于动力学量子几何张量的优化STIRAP方案比传统方案更快、更高效，为多能级系统的量子控制提供了有效的几何优化方法。

Abstract: The optimal control of population transfer for multi-level systems is investigated from the perspective of quantum geometry. Firstly, the general theoretical framework of optimizing the stimulated Raman adiabatic passage (STIRAP) scheme based on the dynamical quantum geometric tensor is given, and then the dynamical quantum geometric tensor and the nonadiabatic transition rate are calculated by taking the detuned $Λ$-type three-level system and tripod-type four-level system for example. Secondly, the transfer dynamics of the particle population of the system are investigated in detail. For a three-level system, the optimal STIRAP scheme has an efficiency of over 98\% in transferring the population to the final state, while the transfer efficiency of traditional STIRAP is about 72\%. The superposition states with arbitrary proportions can be efficiently prepared for a four-level system due to the decoupling of the degenerate dark states. Finally, the influences of system parameters, such as the operation time of the Rabi pulses, the amplitude fluctuation and the single-photon detuning, on the transfer process are discussed. Especially, the phenomenon of the adiabatic resonance transfer is revealed. Choosing the pulse parameters in the resonance window can reduce the infidelity of the population transfer to below $10^{-3}$. It is found that the optimal STIRAP scheme by the dynamical quantum geometric tensor provides faster and more efficient transfer than the traditional STIRAP scheme.

</details>


### [47] [On the mixed UDA states and additivity](https://arxiv.org/abs/2512.20133)
*Xinyu Qiu,Lin Chen,Genwei Li,Delin Chu*

Main category: quant-ph

TL;DR: 该论文研究了多体混合态中唯一确定态（UDA）的条件，重点关注通过k-体约化密度矩阵确定UDA态，特别研究了k=2的情况，建立了系统方法并分析了UDA态在量子层析和其他任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 混合态中唯一确定态（UDA）在高效量子层析中至关重要，但如何通过局部信息（约化密度矩阵）确定多体混合态是否为UDA态仍缺乏系统研究。

Method: 提出了通过k-体约化密度矩阵确定多体混合态是否为UDA态的充要条件，重点研究了k=2的情况（需要最少局部信息），建立了系统方法来确定UDA态，并完整刻画了UDA二体和三量子比特乘积态的可加性。

Result: 获得了通过k-体约化密度矩阵确定UDA态的充要条件，建立了确定UDA态的系统方法，完整刻画了UDA二体和三量子比特乘积态的可加性，展示了混合UDA态在层析和其他任务中的应用。

Conclusion: 该研究为通过局部信息确定多体混合态的唯一性提供了理论基础，建立了系统方法，展示了UDA态在量子层析和其他量子信息任务中的实际应用价值。

Abstract: Mixed states that are uniquely determined among all (UDA) states are vital in efficient quantum tomography. We show the necessary and sufficient conditions by which some multipartite mixed states are UDA by their $k$-partite reduced density matrices. The case for $k=2$ is mostly studied, which requires minimal local information and shows practical benefits. Based on that, we establish a systematic method for determining UDA states and provide a complete characterization of the additivity of UDA bipartite and three-qubit product states. We show the application of mixed UDA states and their characterization from the perspectives of tomography and other tasks.

</details>


### [48] [Highly Tunable Two-Qubit Interactions in Si/SiGe Quantum Dots by Interchanging the Roles of Qubit-Defining Gates](https://arxiv.org/abs/2512.20142)
*Jaemin Park,Hyeongyu Jang,Hanseo Sohn,Younguk Song,Lucas E. A. Stehouwer,Davide Degli Esposti,Giordano Scappucci,Dohun Kim*

Main category: quant-ph

TL;DR: 硅量子点自旋量子比特通过交换重叠纳米栅极角色，显著提高交换耦合可调性，减少单量子位相位偏移，简化多量子位控制


<details>
  <summary>Details</summary>
Motivation: 硅量子点自旋量子比特虽然具有小型化和兼容半导体制造的优势，但Si/SiGe异质结构中的SiGe间隔层会在量子比特与控制电极之间产生间隙，限制了交换耦合的可调性，导致残余耦合引起不必要的单量子位相位偏移，使多量子位控制更加困难

Method: 通过交换重叠纳米栅极的角色，重新配置栅极电压，实现原位角色切换，同时保持多量子位控制能力

Result: 该方法将交换耦合的可调性提高了几个数量级，显著减少了意外的单量子位相位偏移，并最小化了多量子位控制的复杂性

Conclusion: 这种策略支持硅量子点自旋量子比特的可扩展性增长，同时最小化实验开销，为可扩展量子计算提供了有效的解决方案

Abstract: Silicon quantum dot spin qubits have become a promising platform for scalable quantum computing because of their small size and compatibility with industrial semiconductor manufacturing processes. Although Si/SiGe heterostructures are commonly used to host spin qubits due to their high mobility and low percolation density, the SiGe spacer creates a gap between the qubits and control electrodes, which limits the ability to tune exchange coupling. As a result, residual coupling leads to unwanted single-qubit phase shifts, making multi-qubit control more difficult. In this work, we explore swapping the roles of overlapping nanogates to overcome this issue. By reconfiguring the gate voltages, we demonstrate in situ role switching while maintaining multi-qubit control. Additionally, this method significantly improves the tunability of exchange coupling by several orders of magnitude over the traditional approach. This strategy reduces unintended single-qubit phase shifts and minimizes the complexity of multi-qubit control, supporting scalable growth with minimal experimental overhead.

</details>


### [49] [Waveguide-integrated colour centres in silicon carbide with broadband photonic crystal reflectors for efficient readout](https://arxiv.org/abs/2512.20200)
*Marcel Krumrein,Julian M. Bopp,Timo Steidl,Wolfgang Knolle,Jawad Ul-Hassan,Vadim Vorobyov,Tim Schröder,Jörg Wrachtrup*

Main category: quant-ph

TL;DR: 该研究在4H碳化硅中设计并制造了带有恐龙光子晶体反射器的波导结构，用于增强自旋活性色心在低温下的光子计数率，实现了宽带反射和高效收集，理论上可实现超过98%保真度的光学单次读出。


<details>
  <summary>Details</summary>
Motivation: 4H碳化硅中的自旋活性色心是量子信息应用的有前景的构建模块，但在低温下需要提高光子计数率，这需要将色心集成到纳米光子结构中并在低温条件下进行表征。

Method: 设计并制造了带有高效恐龙光子晶体反射器的波导结构，将色心集成到这些结构中，在低温条件下进行表征，使用锥形波导-锥形光纤接口收集发射光，并采用电荷共振检查测量方案进一步提高计数率。

Result: 器件显示出超过60 THz范围的宽带反射，峰值反射率超过80%；标准PLE测量的饱和强度约为104 kcps，通过电荷共振检查测量方案可进一步提高到约125 kcps；理论上这些计数率可实现超过98%保真度的光学单次读出。

Conclusion: 该研究成功开发了用于增强4H碳化硅色心光子计数率的纳米光子结构，虽然发射器的光谱稳定性在高激发功率下仍需改进，但已实现的理论计数率足以支持高保真度的光学单次读出，为量子信息应用提供了有前景的平台。

Abstract: Spin-active colour centres in 4H silicon carbide are promising candidates as building blocks for quantum information applications. To increase the photon count rate of the emitters at low temperatures, the colour centres must be integrated into nanophotonic structures and characterised under cryogenic conditions. Here, we design and fabricate waveguide structures attached with an efficient Dinosaur photonic crystal reflector at one side. The devices show broadband reflection over a range of 60 THz with a peak reflectance above 80 %. Additionally, colour centres were integrated into these structures and characterised at cryogenic conditions. The emission was collected by a tapered-waveguide-tapered-fibre interface. Although the spectral stability of the emitters must be further improved for high excitation powers, the saturation intensity in standard PLE measurements is about 104 kcps. The count rate can be further improved to about 125 kcps with a charge-resonance check measurement scheme. To highlight the relevance of our devices, we theoretically show that these count rates enable optical single-shot readout with a fidelity exceeding 98 %.

</details>


### [50] [A resource-efficient and noise-robust entanglement witness based on the swap test](https://arxiv.org/abs/2512.20235)
*Sebastiano Guaraldo,Sonia Mazzucchi,Alessio Baldazzi,Stefano Azzini,Lorenzo Pavesi*

Main category: quant-ph

TL;DR: 提出基于SWAP测试的纠缠见证方法，适用于任意两量子比特态，能提供纠缠度的下界，方法资源高效、抗噪声且平台无关。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子技术的关键资源，需要高效可靠的检测和量化工具。现有方法在资源效率、噪声鲁棒性和平台通用性方面存在局限。

Method: 提出基于受控SWAP测试的纠缠见证方法，适用于任意两量子比特态（纯态和混合态）。该方法使用线性集成光学组件实现，在室温光子芯片上验证。

Result: 成功在室温光子芯片上验证了该方法，分析了其对光子硬件噪声的鲁棒性。该方法能提供纠缠度（concurrence）的下界。

Conclusion: 建立了一个简单可靠的纠缠见证工具，具有资源高效、抗噪声和平台无关的优点，为量子纠缠检测提供了实用解决方案。

Abstract: Quantum entanglement is an essential resource for quantum technologies, and the controlled swap test provides a versatile tool for its detection and quantification. Here, we propose a SWAP-based entanglement witness that applies to arbitrary two-qubit states - both pure and mixed - and provides a lower bound on the concurrence. The method is resource-efficient, robust to noise, and platform-independent. As an example, we validate the approach on a room-temperature photonic chip, where the swap test is carried out using only linear and well-established integrated optical components. The robustness of the method against photonic-hardware noise is also analysed. Our results establish a simple and reliable tool for entanglement witnessing.

</details>


### [51] [Quantum Geometric Tensor in the Wild: Resolving Stokes Phenomena via Floquet-Monodromy Spectroscopy](https://arxiv.org/abs/2512.20253)
*Prasoon Saurabh*

Main category: quant-ph

TL;DR: 传统拓扑不变量在含本质奇点的开放、驱动、非厄米系统中失效，作者提出FMS协议通过提取Stokes现象来重建非微扰物理


<details>
  <summary>Details</summary>
Motivation: 标准拓扑不变量（如陈数和贝里相位）在存在本质奇点的系统中会灾难性失效，这些奇点在开放、驱动、非厄米系统中普遍存在，导致局部几何张量发散，传统不变量无定义

Method: 提出Floquet-Monodromy Spectroscopy (FMS)协议，这是一种脉冲级控制序列，通过将奇点的Stokes乘子映射到时域可观测量，提取隐藏的Stokes现象

Result: FMS协议为复现理论提供了严格的实验桥梁，允许从发散渐近级数精确重建非微扰物理，在超导qudit模型上验证了该框架

Conclusion: "Stokes不变量"可作为下一代量子数，用于分类超出传统拓扑范围的物质相，解决了本质奇点存在时拓扑分类的危机

Abstract: Standard topological invariants, such as the Chern number and Berry phase, form the bedrock of modern quantum matter classification. However, we demonstrate that this framework undergoes a \textbf{catastrophic failure} in the presence of essential singularities -- ubiquitous in open, driven, and non-Hermitian systems ("Wild" regime). In these settings, the local geometric tensor diverges, rendering standard invariants ill-defined and causing perturbative predictions to deviate from reality by order unity ($\sim 100\%$). We resolve this crisis by introducing the \textbf{Floquet-Monodromy Spectroscopy (FMS)} protocol, a pulse-level control sequence, which experimentally extracts the hidden \textit{Stokes Phenomenon} -- the "missing" geometric data that completes the topological description. By mapping the singularity's Stokes multipliers to time-domain observables, FMS provides a rigorous experimental bridge to \textbf{Resurgence Theory}, allowing for the exact reconstruction of non-perturbative physics from divergent asymptotic series. We validate this framework on a superconducting qudit model, demonstrating that the "Stokes Invariant" serves as the next-generation quantum number for classifying phases of matter beyond the reach of conventional topology.

</details>


### [52] [$\mathcal{PT}$-Symmetric Spin--Boson Model with a Continuous Bosonic Spectrum: Exceptional Points and Dynamics](https://arxiv.org/abs/2512.20277)
*Yong-Xin Zhang,Qing-Hu Chen*

Main category: quant-ph

TL;DR: 研究PT对称非厄米自旋-玻色子模型，发现连续玻色子浴导致单一例外点，与有限模式多例外点不同，且PT对称保护相干光-物质相互作用


<details>
  <summary>Details</summary>
Motivation: 研究PT对称非厄米量子系统中光-物质相互作用的特性，探索连续玻色子浴对例外点结构和系统动力学的影响，理解PT对称如何保护相干相互作用

Method: 采用基于位移算符的投影方法分析静态性质，通过Dirac-Frenkel含时变分原理研究可观测量时间演化，比较非厄米模型与厄米对应物的差异

Result: 连续玻色子浴仅产生单一例外点，而非有限模式的多例外点；EP前仅发现单个实本征值；非厄米模型表现出周期性放大振幅振荡；PT未破缺相中系统呈现持续振荡动力学且抑制退相干，PT破缺相中额外耗散通道加速退相干并驱动快速收敛到稳定稳态

Conclusion: PT对称在非厄米量子系统中保护相干光-物质相互作用，连续玻色子浴显著改变例外点结构和系统动力学特性，为理解非厄米量子系统中的相干控制提供新见解

Abstract: This work studies a $\mathcal{PT}$-symmetric non-Hermitian spin--boson model, consisting of a non-Hermitian two-level system coupled to a continuous bosonic bath. The static properties of the system are analyzed through a projection method derived from the displacement operator. We find that only a single exceptional point (EP) emerges, in contrast to non-Hermitian spin--boson models with finite modes, which typically exhibit multiple EPs. Notably, only a single real eigenvalue is found before the EP, which differs markedly from typical non-Hermitian systems where a pair of real eigenvalues precedes the EP. The time evolution of observables is further investigated via the Dirac--Frenkel time-dependent variational principle. Compared to its Hermitian counterpart, the non-Hermitian model exhibits distinct dynamical signatures, most notably the emergence of oscillations with periodic amplified amplitude. In the $\mathcal{PT}$-unbroken phase, the system exhibits sustained oscillatory dynamics with suppressed decoherence, whereas in the $\mathcal{PT}$-broken phase, additional dissipative channels accelerate decoherence and drive rapid convergence toward a stable steady state. These results shed light on how $\mathcal{PT}$ symmetry protects coherent light--matter interactions in non-Hermitian quantum systems.

</details>


### [53] [Krylov complexity in ergodically constrained nonintegrable transverse-field Ising model](https://arxiv.org/abs/2512.20285)
*Gaurav Rudra Malik,Jeet Sharma,Rohit Kumar Shukla,S. Aravinda,Sunil Kumar Mishra*

Main category: quant-ph

TL;DR: 在横向场伊辛模型中引入空间不均匀性（将链分为两段，每段具有不同的耦合强度）可以抑制量子系统的遍历行为，提供了一种无需无序的自由度来打破遍历性的方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何在非可积的横向场伊辛模型中抑制遍历量子动力学行为。传统方法通常引入无序，但本文探索一种无无序的替代方案——通过引入宏观的空间不均匀性来约束系统动力学。

Method: 将自旋链分为两个相等段，每段具有不同的耦合强度，通过不均匀性参数（耦合强度比）控制系统的非均匀程度。使用多种诊断工具分析：长时间饱和的时序无序关联函数、能级间距统计、谱形因子，并进一步考察Krylov空间中的算符增长和本征态中的纠缠生成。

Result: 随着不均匀性参数偏离1（均匀情况），系统表现出约束动力学行为。多种诊断工具一致显示遍历性被打破，包括时序无序关联函数的饱和行为变化、能级间距统计从Wigner-Dyson分布向Poisson分布的转变、谱形因子的特征变化，以及算符增长和纠缠生成的受限。

Conclusion: 在横向场伊辛模型中引入宏观的空间不均匀性（耦合强度分段变化）提供了一种最小化、无无序的途径来打破遍历性。这种简单的模型变体为研究非遍历量子动力学提供了新的平台。

Abstract: The nonintegrable transverse-field Ising model is a common platform for studying ergodic quantum dynamics. In this work, we introduce a simple variant of the model in which this ergodic behaviour is suppressed by introducing a spatial inhomogeneity in the interaction strengths. For this we partition the chain into two equal segments within which the spins interact with different coupling strengths. The ratio of these couplings defines an inhomogeneity parameter, whose variation away from unity leads to constrained dynamics. We characterize this crossover using multiple diagnostics, such as the long-time saturation of out-of-time-ordered correlators, level-spacing statistics, and the spectral form factor. We further examine the consequences for operator growth in Krylov space and for entanglement generation in the system's eigenstates. Together, these results demonstrate that introducing a macroscopic inhomogeneity in coupling strengths provides a minimal, disorder-free route to breaking ergodicity in this specific model of interacting spins.

</details>


### [54] [Exact Solution of Schrödinger equation for Complex Mass Quantum System under Complex Morse Potential to study emergent matter types and its phases](https://arxiv.org/abs/2512.20318)
*Partha Sarathi,Bhaskar Singh Rawat*

Main category: quant-ph

TL;DR: 该研究在扩展复相空间中求解了具有复质量的量子系统在复Morse势下的薛定谔方程，推导出归一化本征函数和本征谱，建立了谱为实数的条件，并识别出由复质量、Morse参数和本征值相互作用产生的五种内在物质类型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是在非厄米框架下探索具有复质量的量子系统在复Morse势中的精确解，分析复参数如何影响量子系统的谱特性和物质分类，特别是探索暗物质的理论类比。

Method: 在扩展复相空间中求解具有复质量的薛定谔方程，推导归一化本征函数和本征谱，建立谱为实数的条件，分析本征值行为对势参数的依赖关系，通过分析能量本征谱、归一化条件和概率密度分布识别不同参数区域的特征。

Result: 识别出五种内在物质类型：实谱厄米类物质、准稳态或共振态、纯复数量子物质、非物理不可归一化态、以及概率密度空间静态的准经典确定区域。其中一种系统表现出非耗散、无碰撞状态，具有长程引力特性，为暗物质提供了理论类比。

Conclusion: 该研究阐明了复量子系统中物理与非物理区域之间的边界，为解释由复参数产生的稳定性、共振和涌现经典性提供了统一框架，五种物质类型可解释为由复质量和Morse参数支配的单一量子系统的不同相。

Abstract: We present exact solutions of the Schrödinger equation for a quantum system with complex mass subjected to a complex Morse potential in the extended complex phase space. The normalized eigenfunctions and corresponding eigenspectra are derived within a non-Hermitian framework, ensuring consistent probability densities. Conditions for the reality of the spectra are established and used to analyze the dependence of eigenvalue behaviour on potential parameters. The study reveals distinct regimes of spectral characteristics arising from the interplay of complex mass, the Morse parameter, and eigenvalues, leading to the emergence of five intrinsic matter types. By analysing the energy eigenspectra, normalization conditions, and probability density profiles across parameter space, we identify regimes corresponding to real-spectrum Hermitian-like matter, quasi-stable or resonant states, purely complex quantum matter, non-physical, non-normalizable states, and a quasi-classical determinate regime in which the probability density becomes spatially static. One of these system exhibits a non-dissipative, collisionless state with long-range gravitational-like characteristics, suggesting a theoretical analogue for dark matter within a non-Hermitian quantum framework. Further, the five identified classes of matter may be interpreted as distinct phases of a single quantum system governed by complex mass and Morse parameters This classification elucidates the boundary between physical and non-physical regimes in complex quantum systems and provides a unified approach for interpreting stability, resonance, and emergent classicality arising from complex parameters.

</details>


### [55] [Macroscopic quantum states, quantum phase transition for $N$ three-level atoms in an optical cavity -- Gauge principle and non-Hermitian Hamiltonian](https://arxiv.org/abs/2512.20321)
*Ni Liu,Xinyu Jia,J. -Q. Liang*

Main category: quant-ph

TL;DR: 该论文研究了N个三能级原子在单模光学腔中从正常相到超辐射相的量子相变，解决了规范选择模糊性问题，揭示了不同规范在共振条件下的等价性及失谐条件下的差异，并分析了非厄米相互作用下的异常点和稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 解决量子光学中长期存在的规范选择模糊性问题（库仑规范与偶极规范），建立统一的规范框架，研究三能级原子在光学腔中的量子相变特性，并探讨非厄米相互作用对系统稳定性的影响。

Method: 采用自旋相干态变分方法分析量子相变，通过含时规范变换解决薛定谔方程的规范选择问题，将A·p和d·E相互作用纳入统一规范框架，研究共振和失谐条件下的规范等价性，并分析非厄米相互作用下的异常点和稳定性。

Result: 建立了统一的规范框架，证明库仑和偶极规范只是统一规范的特殊情况；在共振条件下三种相互作用给出相同结果，但在红蓝失谐时出现显著差异；揭示了量子相变临界点处能谱、平均光子数和原子布居的突变；发现对初始光学相位的敏感依赖性可用于实验验证规范有效性；非厄米相互作用导致异常点，超辐射态不稳定，非厄米Dicke模型中只存在正常相。

Conclusion: 通过统一规范框架解决了长期存在的规范选择模糊性问题，为量子光学中的规范等价性提供了理论依据；揭示了不同规范在共振条件下的等价性和失谐条件下的差异；非厄米相互作用导致系统不稳定，限制了超辐射相的存在；初始光学相位的敏感性为实验验证规范有效性提供了新途径。

Abstract: We study in this paper the quantum phase transition (QPT) from normal phase (NP) to superradiant phase (SP) for $N$ three-level atoms in a single-mode optical cavity for both Hermitian and non Hermitian Hamiltonians, where the $Ξ$-type three-level atom is described by spin-$1$ pseudo-spin operators. The long standing gauge-choice ambiguity of $\mathbf{A\cdot p}$ and $\mathbf{d\cdot E}$ called respectively the Coulomb and dipole gauges is resolved by the time-dependent gauge transformation on the Schrödinger equation. Both $\mathbf{A\cdot p}$ and $\mathbf{d\cdot E}$ interactions are included in the unified gauge, which is truly gauge equivalent to the minimum coupling principle. The Coulomb and dipole interactions are just the special cases of unified gauge. Remarkably three interactions lead to the same results under the resonant condition of field-atom frequencies, while significant difference appears in red and blue detunings. The QPT is analyzed in terms of spin coherent-state variational method, which indicates the abrupt changes of energy spectrum, average photon number as well as the atomic population at the critical point of interaction constant. Crucially, we reveal the sensitive dependence on the initial optical-phase, which is particularly useful to test the validity of three gauges experimentally. The non-Hermitian atom-field interaction results in the exceptional point (EP), beyond which the semiclassical energy function becomes complex. However the energy spectrum of variational ground state is real in the absence of EP, and does not become complex. The superradiant state is unstable due to the non-Hermitian interaction induced photon-number loss. Thus only the NP exists in the non-Hermitian Dicke Model Hamiltonian.

</details>


### [56] [A Lovász theta lower bound on Quantum Max Cut](https://arxiv.org/abs/2512.20326)
*Felix Huber*

Main category: quant-ph

TL;DR: 该论文证明了量子最大割的下界与图补图的Lovász theta函数相关，对于有m条边的图，qmc(G) ≥ m/4(1 + 8/(3π)(1/(ϑ(Ḡ)-1)))，且该下界可由乘积态实现。


<details>
  <summary>Details</summary>
Motivation: 研究量子最大割问题的下界，扩展经典最大割的结果到量子领域，改进量子最大割的经典界限。

Method: 扩展Balla、Janzer和Sudakov关于经典最大割的结果，并受到Gharibian和Parekh随机舍入方法的启发，通过Lovász theta函数建立量子最大割的下界。

Result: 证明了量子最大割的下界：对于有m条边的图G，qmc(G) ≥ m/4(1 + 8/(3π)(1/(ϑ(Ḡ)-1)))，该下界可由乘积态实现，且优于经典界限。

Conclusion: 成功建立了量子最大割与图补图Lovász theta函数之间的下界关系，该结果扩展了经典最大割理论到量子领域，并为量子最大割提供了改进的界限。

Abstract: We prove a lower bound to quantum Max Cut of a graph in terms of the Lovász theta function of its complement. For a graph with $m$ edges, $\text{qmc}(G) \geq \tfrac{m}{4}\big( 1 + \tfrac{8}{3π}\tfrac{1}{\vartheta(\bar{G}) -1} \big)$, with the bound achieved by a product state. The proof extends a result by Balla, Janzer, and Sudakov on classical Max Cut and is also inspired by the randomized rounding method of Gharibian and Parekh. The bound outperforms the classical bound when applied to quantum Max Cut.

</details>


### [57] [Lie algebra-assisted quantum simulation and quantum optimal control via high-order Magnus expansions](https://arxiv.org/abs/2512.20357)
*R. F. dos Santos,S. J. J. M. F. Kokkelmans*

Main category: quant-ph

TL;DR: 提出了一种可扩展的方法，显著降低了计算量子系统中马格努斯展开高阶项的计算成本，使计算复杂度仅依赖于时间相关控制函数的自由度，而非系统维度。


<details>
  <summary>Details</summary>
Motivation: 量子系统在时间相关驱动下的演化展现出静态系统所没有的现象，但由于量子动力学的高维性和非交换性，这成为一个具有挑战性的问题。现有的马格努斯展开方法计算高阶项时计算成本过高。

Method: 引入了一种可扩展的方法，专注于由恒定漂移项和可控项组成的哈密顿量。该方法将马格努斯展开表示为多项式表达式，计算复杂度仅依赖于时间相关控制函数的自由度。

Result: 该方法能够比现有技术快几个数量级地评估马格努斯展开，在量子模拟和量子最优控制领域具有广泛应用前景。通过在基于里德堡原子的中性原子平台上设计5量子位相位门的控制脉冲，展示了该方法的应用。

Conclusion: 提出的可扩展方法显著降低了计算马格努斯展开的计算成本，为量子模拟和量子最优控制提供了强大的工具，特别是在设计复杂量子门控制脉冲方面具有实际应用价值。

Abstract: The evolution of a quantum system under time-dependent driving exhibits phenomena that are absent in its stationary counterpart. However, the high dimensionality and non-commutative nature of quantum dynamics make this a challenging problem. The Magnus expansion provides an analytic framework to approximate the effective dynamics on short time-scales, but computing high-order terms with existing methods is computationally expensive. We introduce a scalable approach that reduces the computational effort to depend only on the degrees of freedom defining the time-dependent control function. We focus specifically on Hamiltonians consisting of a constant drift term and a controllable term. Our method provides a polynomial expression for the Magnus expansion which can be evaluated several orders of magnitude faster than previous techniques, enabling broad applications in the realms of quantum simulation and quantum optimal control. We showcase an application of the method by designing control pulses for the 5-qubit phase gate on a neutral-atom platform utilizing Rydberg atoms.

</details>


### [58] [The Exact Uncertainty Relation and Geometric Speed Limits in Krylov Space](https://arxiv.org/abs/2512.20359)
*Mohsen Alishahiha,Souvik Banerjee*

Main category: quant-ph

TL;DR: 论文展示了Hall精确不确定性关系在Liouvillian生成的Krylov基中具有简单几何形式，算子振幅向量在单位Krylov球面上以恒定速度演化，速度仅由第一Lanczos系数决定，这为算子增长和量子速度极限提供了统一的几何解释。


<details>
  <summary>Details</summary>
Motivation: 研究Hall精确不确定性关系在量子动力学中的几何表现形式，探索算子增长与量子速度极限之间的统一几何解释，理解量子动力学内在速度尺度的几何本质。

Method: 使用Liouvillian生成的Krylov基作为规范算子框架，将Hall精确不确定性关系重新表述为几何形式，分析算子振幅向量在Krylov球面上的演化特性，推导出与高阶Lanczos系数无关的线性几何边界。

Result: 发现算子振幅向量在单位Krylov球面上以恒定速度演化，速度仅由第一Lanczos系数决定；得到了独立于高阶Lanczos系数且适用于任意哈密顿量（可积或混沌）的精确线性几何边界；首次为精确量子速度极限和算子增长提供了统一的几何解释。

Conclusion: Hall精确不确定性关系在Krylov基中呈现简洁几何形式，第一Lanczos系数是量子动力学的内在速度尺度，这为理解算子增长和量子速度极限提供了统一的几何框架，具有普适性。

Abstract: We show that Hall's exact uncertainty relation acquires a simple geometric form in the Krylov basis generated by the Liouvillian. In this canonical operator frame, the uncertainty equality implies that the operator amplitude vector evolves on the unit Krylov sphere with constant speed fixed solely by the first Lanczos coefficient. This yields an exact linear bound on geometric operator evolution, independent of higher Lanczos coefficients and valid for arbitrary Hamiltonians, integrable or chaotic. Our results provide the first unified geometric interpretation of exact quantum speed limits and operator growth, identifying the first Lanczos coefficient as the intrinsic speed scale of quantum dynamics.

</details>


### [59] [Storage and retrieval of optical skyrmions with topological characteristics](https://arxiv.org/abs/2512.20378)
*Jinwen Wang,Xin Yang,Yun Chen,Zhujun Ye,Xinji Zeng,Yongkun Zhou,Shuya Zhang,Claire Marie Cisowski,Chengyuan Wang,Katsuya Inoue,Yijie Shen,Sonja Franke-Arnold,Hong Gao*

Main category: quant-ph

TL;DR: 首次在冷铷原子蒸气中实验演示了光学斯格明子的存储与检索，证明其拓扑不变量在量子存储中保持稳定


<details>
  <summary>Details</summary>
Motivation: 光学斯格明子具有拓扑结构，其斯格明子数对扰动具有鲁棒性，这使得它们在量子信息存储中具有吸引力。然而，在相干存储过程中其保持性尚未被探索。

Method: 使用双路径电磁诱导透明存储器在冷$^{87}$Rb蒸气中存储和检索光学斯格明子

Result: 斯格明子数在长达数微秒的存储时间内保持不变，即使在两条路径存在不平衡损耗和控制光束功率发生显著扰动的情况下也是如此

Conclusion: 这项工作首次展示了非平凡拓扑不变量在量子存储器中的存活，标志着向拓扑保护光子技术迈出了重要一步

Abstract: Optical skyrmions are topological structures of light whose defining property, the skyrmion number, is robust against perturbations. This makes them attractive for applications in quantum information storage, where resilience to decoherence is paramount. However, their preservation during coherent storage remains unexplored. We report the first experimental demonstration of storing and retrieving optical skyrmions in a cold $^{87}$Rb vapor using a dual-path electromagnetically induced transparency memory. Crucially, we show that the skyrmion number remains invariant for storage times up to several microseconds, even when subjected to imbalanced loss between the two paths and substantial perturbations in control beam power. Our work demonstrates the survival of a non-trivial topological invariant in a quantum memory, marking a significant step towards topologically protected photonic technologies.

</details>


### [60] [Metrologically advantageous states: long-range entanglement and asymmetric error correction](https://arxiv.org/abs/2512.20426)
*Junjie Chen,Rui Luo,Yuxuan Yan,You Zhou,Xiongfeng Ma*

Main category: quant-ph

TL;DR: 该研究建立了量子计量学性能与长程纠缠、状态制备复杂性和量子纠错特性之间的理论框架，证明了超线性量子Fisher信息缩放需要长程纠缠，并揭示了计量灵敏度与局部噪声保护之间的基本不相容性。


<details>
  <summary>Details</summary>
Motivation: 尽管量子计量学取得了广泛进展，但对于哪些多体量子态能够展现超线性参数估计精度增强的系统性理解仍然缺乏。研究旨在建立量子计量性能与量子态基本特性之间的理论联系。

Method: 开发了一个连接计量性能与长程纠缠、状态制备复杂性和量子纠错特性的通用理论框架。通过推导量子Fisher信息的复杂性相关上界来证明超线性缩放需要长程纠缠。分析了两类量子纠错码（非退化码和CSS量子LDPC码）的计量性能。

Result: 证明了超线性QFI缩放必然需要长程纠缠。对于非退化码和CSS量子LDPC码，非恒定码距排除了对广泛类别的局部哈密顿量的超线性QFI缩放，揭示了计量灵敏度与局部噪声保护之间的基本不相容性。发现了通过利用非对称码结构规避这一障碍的构造性途径。

Conclusion: 长程纠缠和非对称纠错是量子计量学的基本资源。研究阐明了状态复杂性、纠错能力和计量性能之间的相互作用，为设计具有计量优势的量子态提供了理论指导。

Abstract: Quantum metrology aims to exploit many-body quantum states to achieve parameter-estimation precision beyond the standard quantum limit. For unitary parameter encoding generated by local Hamiltonians, such enhancement is characterized by superlinear scaling of the quantum Fisher information (QFI) with system size. Despite extensive progress, a systematic understanding of which many-body quantum states can exhibit this scaling has remained elusive. Here, we develop a general framework that connects metrological performance to long-range entanglement, state-preparation complexity, and quantum error-correction properties. We prove that super-linear QFI scaling necessarily requires long-range entanglement by deriving rigorous complexity-dependent upper bounds on the QFI. We further show that, for two broad classes of quantum error-correcting codes, nondegenerate codes and Calderbank--Shor--Steane quantum low-density parity-check codes, a nonconstant code distance precludes super-linear QFI scaling for a wide class of local Hamiltonians, revealing a fundamental incompatibility between metrological sensitivity and protection against local noise. Finally, we identify constructive routes that evade this obstruction by exploiting asymmetric code structures. In particular, we show that states associated with classical low-density parity-check codes, as well as asymmetric toric code states, both having asymmetric logical distances, can achieve Heisenberg-limited scaling. Together, our results establish long-range entanglement and asymmetric error correction as the essential resource underlying quantum metrology and clarify the interplay among state complexity, error correction, and metrological power.

</details>


### [61] [Exploring the nature of gravity with quantum information methods](https://arxiv.org/abs/2512.20429)
*Bruna Sahdo,Natália Salomé Móller*

Main category: quant-ph

TL;DR: 本文介绍了量子信息方法在研究量子理论与引力界面中的应用，重点讨论了两个研究方向：引力诱导纠缠和因果结构分析，以探索引力场的量子性质和时空的非经典行为。


<details>
  <summary>Details</summary>
Motivation: 本文旨在介绍量子信息方法在研究量子理论与引力界面中的应用，为理解引力场的量子性质和时空的非经典行为提供新的研究视角和方法论。

Method: 文章采用综述方法，首先回顾量子信息理论的基本概念和实验（如马赫-曾德尔干涉仪、斯特恩-盖拉赫实验、贝尔不等式和量子电路语言），然后系统介绍两个主要研究方向：1）引力诱导纠缠现象，用于推断引力场是否需要量子化；2）因果结构分析，为时空可能表现出的非经典行为提供间接证据。

Result: 文章系统梳理了量子信息方法在量子引力研究中的应用框架，明确了引力诱导纠缠和因果结构分析这两个关键研究方向的理论基础和实验前景，为后续研究提供了方法论指导。

Conclusion: 量子信息方法为研究量子理论与引力界面提供了有力的工具，引力诱导纠缠和因果结构分析是两个有前景的研究方向，有助于深入理解引力场的量子性质和时空的基本结构。

Abstract: The aim of this article is to provide an introduction to the use of quantum information methods for investigating the interface between quantum theory and gravity. To this end, we discuss the basic principles of two current research streams that use this approach. The first one explores a phenomenon known as gravitationally induced entanglement, which aims to infer whether the gravitational field responsible for the interaction between two massive bodies must be quantized or not. The second stream investigates causal structures, thereby providing indirect evidence that spacetime may exhibit non-classical behavior. Before presenting these topics, we briefly review some fundamental concepts and experiments from quantum information theory, such as the Mach-Zehnder interferometer, the Stern-Gerlach experiment, Bell inequalities and entanglement, and the language of quantum circuits.

</details>


### [62] [Scaling roadmap for modular trapped-ion QEC and lattice-surgery teleportation](https://arxiv.org/abs/2512.20435)
*César Benito,Alfredo Ricci Vasquez,Jonathan Home,Karan K. Mehta,Thomas Monz,Markus Müller,Alejandro Bermudez*

Main category: quant-ph

TL;DR: 该研究分析了基于囚禁离子的模块化量子纠错协议（特别是三角色码）的扩展性，比较了不同架构的性能，并确定集成光子学连接是最有前景的长期扩展路径。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估基于囚禁离子的模块化量子纠错协议在实际硬件上的可扩展性和性能，特别关注不同连接技术对量子纠错协议实施的影响。

Method: 方法包括：1）将量子纠错小工具编译为原生囚禁离子原语；2）详细分析特定激光寻址和离子传输导致的串扰误差、运动激发和空闲量子比特误差；3）结合微观噪声模型、高效泡利框架模拟器和可扩展解码器；4）评估色码存储和隐形传态协议在不同架构上的近期性能。

Result: 分析结果表明：1）模块化色码隐形传态在这些近期囚禁离子架构中是可实现的；2）集成光子学连接被确定为长期扩展中最有前景的技术路线。

Conclusion: 结论是模块化量子纠错协议在囚禁离子系统中具有可行性，集成光子学连接技术为长期扩展提供了最优路径，为基于囚禁离子的可扩展量子计算架构设计提供了重要指导。

Abstract: We present a footprint study for the scaling of modular quantum error correction (QEC) protocols designed for triangular color codes, including a lattice-surgery-based logical teleportation gadget, and compare the performance of various possible architectures based on trapped ions. The differences in these architectures arise from the technology that enables the connectivity between physical qubits and the modularity required for the QEC gadgets, which is either based on laser-beam deflectors focused to independent modules hosting mid-size ion crystals, or integrated photonics guided to segmented modules of the trap and allowing for the manipulation of smaller ion crystals. Our approach integrates the transpilation of the QEC gadgets into native trapped-ion primitives and a detailed account of the specific laser addressing and ion transport leading to different amounts of crosstalk errors, motional excitation and idle qubit errors. Combining a microscopically-informed noise model with an efficient Pauli-frame simulator and different scalable decoders, we assess the near-term performance of the color-code memory and teleportation protocols on these architectures. Our analysis demonstrates that modular color-code teleportation is achievable in these near-term trapped-ion architectures, and identifies the integrated-photonics connectivity as the most promising route for longer-term scaling.

</details>


### [63] [Enriching Earth Observation labeled data with Quantum Conditioned Diffusion Models](https://arxiv.org/abs/2512.20448)
*Francesco Mauro,Francesca De Falco,Lorenzo Papa,Andrea Ceschini,Alessandro Sebastianelli,Paolo Gamba,Massimo Panella,Silvia Ullo*

Main category: quant-ph

TL;DR: 该论文提出了一种混合量子-经典架构QCU-Net，用于生成合成的地球观测图像，通过量子卷积特征提取方法在条件扩散框架中应用量子操作，显著提升了生成质量并减少了计算需求。


<details>
  <summary>Details</summary>
Motivation: 地球观测领域扩散模型面临计算成本高（需要数百到数千次推理步骤）和难以捕捉EO数据复杂空间光谱相关性的挑战。量子机器学习提供了从根本上克服这些限制的新途径，特别是量子生成模型的发展为改进EO图像合成提供了可能性。

Method: 提出了Quanvolutional Conditioned U-Net (QCU-Net)混合量子-经典架构，在条件扩散框架中采用新颖的量子卷积特征提取方法，将量子操作集成到生成模型中。通过战略性地定位量子层和使用纠缠变分电路来增强模型性能。

Result: 在EuroSAT RGB数据集上的实验表明，QCU-Net显著优于传统方法：Fréchet Inception Distance降低64%，Kernel Inception Distance降低76%，并获得更高的语义准确性。消融研究证实量子层的战略定位和纠缠变分电路能提升模型性能和收敛速度。

Conclusion: 这是首次成功将类别条件量子扩散模型应用于地球观测领域，为量子增强的遥感图像合成开辟了新途径，展示了量子机器学习在解决EO数据生成挑战方面的潜力。

Abstract: The rapid adoption of diffusion models (DMs) in the Earth Observation (EO) domain has unlocked new generative capabilities aimed at producing new samples, whose statistical properties closely match real imagery, for tasks such as synthesizing missing data, augmenting scarce labeled datasets, and improving image reconstruction. This is particularly relevant in EO, where labeled data are often costly to obtain and limited in availability. However, classical DMs still face significant computational limitations, requiring hundreds to thousands of inference steps, as well as difficulties in capturing the intricate spatial and spectral correlations characteristic of EO data. Recent research in Quantum Machine Learning (QML), including initial attempts of Quantum Generative Models, offers a fundamentally different approach to overcome these challenges. Motivated by these considerations, we introduce the Quanvolutional Conditioned U-Net (QCU-Net), a hybrid quantum--classical architecture that applies quantum operations within a conditioned diffusion framework using a novel quanvolutional feature-extraction approach, for generating synthetic labeled EO imagery. Extensive experiments on the EuroSAT RGB dataset demonstrate that our QCU-Net achieves superior results. Notably, it reduces the Fréchet Inception Distance by 64%, lowers the Kernel Inception Distance by 76%, and yields higher semantic accuracy. Ablation studies further reveal that strategically positioning quantum layers and employing entangling variational circuits enhance model performance and convergence. This work represents the first successful adaptation of class-conditioned quantum diffusion modeling in the EO domain, paving the way for quantum-enhanced remote sensing imagery synthesis.

</details>


### [64] [End-to-end Optimization of Single-Shot Quantum Machine Learning for Bayesian Inference](https://arxiv.org/abs/2512.20492)
*Theodoros Ilias,Fangjun Hu,Marti Vives,Hakan E. Türeci*

Main category: quant-ph

TL;DR: 本文提出了一种针对有限测量资源的量子机器学习端到端优化策略，将学习目标直接定义为任务性能。应用于贝叶斯量子计量学任务，在32量子比特下实现了接近理论极限的性能。将贝叶斯框架从参数估计扩展到全局函数推断，展示了直接函数推断相对于间接重建的计算感知优势。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在有限测量资源下的性能优化是一个关键挑战。传统方法通常优化中间指标而非最终任务性能，导致在实际测量资源受限时性能下降。需要开发能够直接针对有限测量资源下任务性能进行优化的端到端策略。

Method: 提出采样感知的混合算法，将学习目标直接定义为有限测量资源下的任务性能。应用于贝叶斯量子计量学任务，该任务具有已知的基本极限和系统尺寸缩放特性。将贝叶斯框架从参数估计扩展到全局函数推断，引入可解析表达能力作为单次测量可访问函数空间的自然度量，通过特征任务分析识别噪声鲁棒的特征组合。

Result: 在32量子比特的贝叶斯量子计量任务中，单次风险达到-19 dB，距离-20 dB的贝叶斯极限仅差1 dB。展示了直接函数推断相对于间接重建的计算感知优势。特征任务分析产生了紧凑的估计器，在资源受限或实时设备设置中提高了准确性并降低了优化成本。

Conclusion: 端到端优化策略能够有效针对有限测量资源下的量子机器学习任务性能进行优化。将贝叶斯框架扩展到函数推断为量子传感提供了新的视角，直接函数推断比间接重建具有计算优势。特征任务分析为噪声鲁棒特征组合的识别提供了系统方法，有助于开发资源高效的量子机器学习算法。

Abstract: We introduce an end-to-end optimization strategy for quantum machine learning that directly targets performance under finite measurement resources, where learning objectives are defined directly at the level of task performance. The method is applied on a Bayesian quantum metrology task since it provides a natural testbed with known fundamental limits and scaling with system size. The sampling-aware hybrid algorithm achieves a single-shot risk within 1 dB of the -20 dB Bayesian limit using 32 qubits. We extend the Bayesian framework from parameter estimation to global function inference, where the task is to infer a target function of the sensor input drawn from an arbitrary prior, and we demonstrate a clear computational-sensing advantage for direct functional inference over indirect reconstruction. We relate the corresponding Bayesian risk to the Capacity metric and argue that the Resolvable Expressive Capacity provides a natural measure of the space of functions accessible in a single shot. The resulting eigentask analysis identifies noise-robust feature combinations that yield compact estimators with improved accuracy and reduced optimization cost in resource-limited or real-time on-device settings.

</details>


### [65] [Macroscopically distinguishable superposition in infinitely many degrees of freedom](https://arxiv.org/abs/2512.20512)
*J. Fransson,B. C. Sanders,A. P. Sowa*

Main category: quant-ph

TL;DR: 该论文研究了无限玻色子阵列中宏观可区分叠加态的概念，证明了非局域相干态可以在非局域哈密顿量作用下演化为非局域猫态，且这种动力学无法分解为局域因子。


<details>
  <summary>Details</summary>
Motivation: 研究无限玻色子阵列中宏观可区分叠加态的概念，区分局域和非局域状态及动力学，探索非局域相干态在非局域哈密顿量作用下的演化行为。

Method: 在希尔伯特空间理论框架内进行严格分析，区分局域（有限自由度）和非局域状态，研究非局域相干态在总粒子数算符平方这一非局域哈密顿量作用下的动力学演化。

Result: 证明了非局域相干态可以在非局域哈密顿量作用下演化为非局域猫态，且这种动力学无法分解为局域因子；发现相干态和非局域猫态的概念并非固有绑定，它们的融合是标准玻色子的独特特征。

Conclusion: 在广义玻色子框架下，如果能够在工程量子系统中物理实现，这些现象可能对物理学和材料科学具有重要意义，揭示了非局域量子态演化的新特性。

Abstract: We investigate the concept of macroscopically distinguishable superpositions within an infinite array of boson sites. Our approach is rigorous within the frame of Hilbert space theory. In this context, it is natural to differentiate between states -- and corresponding dynamics -- that involve only finitely many degrees of freedom, referred to as local, and those that are inherently nonlocal. Previous studies have shown that such systems can support nonlocal coherent states (NCS). In this work, we demonstrate that NCS can dynamically evolve into nonlocal cat states under the influence of a nonlocal Hamiltonian -- specifically, the square of the total number operator. Crucially, the resulting dynamics cannot be decomposed into local factors. Furthermore, we explore broader mathematical implications of these phenomena within the framework of generalized bosons. Our findings highlight that the concepts of coherent states and nonlocal cat states are not inherently bound together; rather, their fusion is a distinctive feature of standard bosons. Finally, we propose that if the generalized boson framework can be physically realized in engineered quantum systems, the phenomena described here may hold significant relevance for both physics and materials science.

</details>


### [66] [Small quantum Tanner codes from left--right Cayley complexes](https://arxiv.org/abs/2512.20532)
*Anthony Leverrier,Wouter Rozendaal,Gilles Zémor*

Main category: quant-ph

TL;DR: 量子Tanner码是一类量子低密度奇偶校验码，在渐近极限下具有线性最小距离和恒定编码率。论文研究了基于左右Cayley复形的构造方法，计算了右度为2时的维度，并通过小群搜索发现了多个具体参数实例。


<details>
  <summary>Details</summary>
Motivation: 研究量子Tanner码的构造和特性，特别是基于左右Cayley复形的具体实现方法，以找到具有良好参数的实际量子纠错码实例。

Method: 1. 使用左右Cayley复形描述量子Tanner码的构造；2. 通过提升过程和基码进行表征；3. 计算右度为2时的码维度；4. 在小群上进行广泛搜索以识别具体参数实例。

Result: 1. 建立了量子Tanner码的构造框架；2. 计算了右度为2时的维度特性；3. 发现了多个具体参数实例：[[144,12,11]]、[[432,20,≤22]]和[[576,28,≤24]]，生成元权重为9。

Conclusion: 量子Tanner码是一类有前景的量子纠错码，通过基于左右Cayley复形的构造方法可以获得具有良好参数的实例，为实际量子计算应用提供了潜在的纠错方案。

Abstract: Quantum Tanner codes are a class of quantum low-density parity-check codes that provably display a linear minimum distance and a constant encoding rate in the asymptotic limit. When built from left--right Cayley complexes, they can be described through a lifting procedure and a base code, which we characterize. We also compute the dimension of quantum Tanner codes when the right degree of the complex is 2. Finally, we perform an extensive search over small groups and identify instances of quantum Tanner codes with parameters $[[144,12,11]]$, $[[432,20,\leq 22]]$ and $[[576,28,\leq 24]]$ for generators of weight 9.

</details>


### [67] [On super additivity of Fisher information in fully Gaussian metrology](https://arxiv.org/abs/2512.20534)
*Javier Navarro,Simon Morelli,Mikel Sanz,Mohammad Mehboudi*

Main category: quant-ph

TL;DR: 论文研究了在仅允许高斯测量的约束条件下，量子费希尔信息的可加性问题。发现在位移或协方差矩阵中编码信息时，最优高斯测量保持局域性；但当信息同时编码在两者中时，全局高斯测量可实现超可加性，提升参数估计性能。


<details>
  <summary>Details</summary>
Motivation: 研究在实验限制下（仅允许高斯测量）量子费希尔信息的可加性问题。量子费希尔信息在无约束时对独立系统副本具有可加性且最优测量是局域的，但实际实验中测量受到约束，需要探究在仅允许高斯测量的高斯场景下这一性质是否仍然成立。

Method: 采用完全高斯场景，仅考虑高斯测量。分析信息编码在位移、协方差矩阵或两者同时的情况。构造简单的全局高斯测量方案，证明在某些情况下可实现超可加性。在量子光学平台中，提出的全局操作仅需被动全局操作和单模高斯测量。

Result: 1) 当信息仅编码在位移或协方差矩阵时，最优高斯测量保持局域性；2) 当信息同时编码在位移和协方差矩阵时，全局高斯测量可实现费希尔信息的超可加性；3) 在估计压缩和损耗的示例中，全局高斯测量能显著缩小与量子费希尔信息的差距，并在多副本渐近极限下闭合该差距。

Conclusion: 在仅允许高斯测量的约束条件下，量子费希尔信息的可加性性质取决于信息编码方式。全局高斯测量在某些情况下能实现超可加性，提升参数估计性能，这为实际量子光学实验中的参数估计任务提供了可行的改进方案。

Abstract: Famously, the quantum Fisher information -- the maximum Fisher information over all physical measurements -- is additive for independent copies of a system and the optimal measurement acts locally. We are left to wonder: does the same hold when the set of accessible measurements is constrained? Such constraints are necessary to account for realistic experimental restrictions. Here, we consider a fully Gaussian scenario focusing on only Gaussian measurements. We prove that the optimal Gaussian measurement protocol remains local, if the information is encoded in either the displacement or the covariance matrix. However, when the information is imprinted on both, this no longer holds true: we construct a simple global Gaussian measurement where the Fisher information becomes super additive. These results can improve parameter estimation tasks via feasible tools. Namely, in quantum optical platforms our proposed global operation requires only passive global operations and single mode Gaussian measurements. We demonstrate this in two examples where we estimate squeezing and losses. While in the former case there is a significant gap between the Fisher information of the optimal Gaussian measurement and the quantum Fisher information for a single copy, this gap can be reduced with joint Gaussian measurements and closed in the asymptotic limit of many copies.

</details>


### [68] [Quantum State Preparation via Schmidt Spectrum Optimisation](https://arxiv.org/abs/2512.20537)
*Josh Green,Joshua Snow,Jingbo B Wang*

Main category: quant-ph

TL;DR: 提出一种基于Schmidt谱优化的浅层量子电路设计算法，用于高效制备矩阵乘积态，通过优化局部幺正操作序列来解纠缠目标态，然后反转该过程获得状态制备电路。


<details>
  <summary>Details</summary>
Motivation: 为在近期量子硬件上实现可扩展的多体量子态制备，需要设计浅层深度的量子电路来准备矩阵乘积态，同时保持其固有的纠缠结构。

Method: 利用Schmidt谱优化方法，通过自动微分优化中间态的Schmidt谱损失函数，学习解纠缠序列，然后将优化后的幺正操作取伴随得到从计算基态重构目标MPS的浅层电路。

Result: 在局部哈密顿量基态的MPS近似上测试，SSO实现了最先进的浅层深度性能，相比现有方法精度提高了一个数量级，并缓解了先前解纠缠方法中观察到的时间复杂度缩放问题。

Conclusion: SSO算法为在近期量子硬件上高效制备多体量子态提供了一种系统化的浅层电路设计方法，通过优化Schmidt谱来保持纠缠结构，显著提高了状态制备的精度和可扩展性。

Abstract: We introduce an efficient algorithm for the systematic design of shallow-depth quantum circuits capable of preparing many-body quantum states represented as Matrix Product States (MPS). The proposed method leverages Schmidt spectrum optimization (SSO) to minimize circuit depth while preserving the entanglement structure inherent to MPS representations, thereby enabling scalable state preparation on near-term quantum hardware. The core idea is to \textit{disentangle} the target MPS using a sequence of optimised local unitaries, and then reverse this process to obtain a state preparation circuit. Specifically, we define a loss function directly on the Schmidt spectra of intermediate states and use automatic differentiation to optimise each circuit layer so as to systematically reduce entanglement entropy. Once a disentangling sequence has been learned, we take the adjoints of the optimised unitaries to obtain a shallow-depth circuit that approximately reconstructs the target MPS from the computational all-zero state. We benchmark SSO across a range of MPS approximations to the ground states of local Hamiltonians and demonstrate state-of-the-art shallow-depth performance, improving accuracy by up to an order of magnitude over existing methods. Finally, we provide numerical evidence that SSO mitigates the adverse time-complexity scaling observed in previous disentangling-based approaches.

</details>


### [69] [Experimental characterization of the Toffoli gate via channel spectrum benchmarking](https://arxiv.org/abs/2512.20545)
*D. K. Korliakov,B. I. Bantysh,A. S. Borisenko,I. V. Zalivako,E. O. Kiktenko*

Main category: quant-ph

TL;DR: 本文提出扩展的通道谱基准测试(CSB)模型和保真度估计区间(FEI)，以解决传统CSB在强噪声下重构噪声特征值的问题，并在离子阱量子处理器上验证了该协议对三量子比特Toffoli门的基准测试效果。


<details>
  <summary>Details</summary>
Motivation: 当前通道谱基准测试(CSB)在重构噪声特征值时面临基本挑战，特别是在存在谱简并和目标门特征基中的非对角噪声分量时。这些问题在门保真度约90%的强噪声区域尤为突出，需要改进方法来准确评估量子门性能。

Method: 提出扩展的CSB模型，引入保真度估计区间(FEI)作为目标门保真度的区间值估计。该方法通过数值模拟验证，并在离子阱量子处理器上对三量子比特Toffoli门的两种实现进行基准测试。

Result: 数值模拟显示FEI保持足够窄的区间，其中点可靠地逼近真实保真度。实验结果表明，基于qutrit的Toffoli门实现明显优于基于qubit的实现。

Conclusion: 扩展的CSB模型和FEI方法有效解决了传统CSB在强噪声下的局限性，为量子门性能评估提供了更可靠的基准测试工具，并揭示了qutrit实现方案的优势。

Abstract: Channel spectrum benchmarking (CSB) provides a robust framework for characterizing quantum gate fidelities while remaining insensitive to state preparation and measurement (SPAM) errors. Yet, current CSB implementations encounter fundamental challenges when reconstructing noisy eigenvalues, particularly in the presence of spectral degeneracies and off-diagonal noise components in the target gate's eigenbasis. These issues become especially pronounced in the strong noise regime for gates with fidelities around $90\%$. To address these limitations, we introduce an extended CSB model together with a fidelity estimate interval (FEI) -- an interval-valued estimate of the target gate fidelity. Numerical simulation demonstrates that FEI remains sufficiently narrow, with its midpoint reliably approximating the true fidelity. We further validate the protocol on a trapped-ion quantum processor by benchmarking two implementations of the three-qubit Toffoli gate. The results reveal a clear advantage of the qutrit-based implementation over its qubit-based counterpart.

</details>


### [70] [Hardware-aware and Resource-efficient Circuit Packing and Scheduling on Trapped-Ion Quantum Computers](https://arxiv.org/abs/2512.20554)
*Miguel Palma,Shuwen Kan,Wenqi Wei,Juntao Chen,Kaixun Hua,Sara Mouradian,Ying Mao*

Main category: quant-ph

TL;DR: CircPack是一个针对量子电荷耦合器件架构的硬件感知电路打包框架，通过将静态电路调度建模为二维打包问题，在囚禁离子系统中实现量子多编程，相比超导系统显著提升保真度、利用率和层数减少。


<details>
  <summary>Details</summary>
Motivation: 量子云服务的快速扩展导致作业队列过长，单租户执行模型硬件资源利用率低。现有量子多编程方法主要针对超导系统，但存在连接性有限、串扰高、门保真度低等问题。囚禁离子架构具有全连接、长相干时间和高保真度中电路测量特性，更适合可扩展的量子多编程。

Method: CircPack是一个针对基于量子电荷耦合器件架构的模块化囚禁离子设备的硬件感知电路打包框架。它将静态电路调度建模为具有硬件特定穿梭约束的二维打包问题，能够实现跨独立QCCD模块的可扩展、平衡调度。

Result: 与基于超导的量子多编程方法相比，CircPack实现了高达70.72%的保真度提升、62.67%的利用率提高和32.80%的层数减少改进。该框架还能在独立的QCCD模块集群上实现可扩展的平衡调度。

Conclusion: CircPack展示了囚禁离子系统在提高量子云计算吞吐量方面的潜力，为量子云服务的资源利用和作业排队问题提供了有效的解决方案，特别是在量子电荷耦合器件架构上实现了显著的性能提升。

Abstract: The rapid expansion of quantum cloud services has led to long job queues due to single-tenant execution models that underutilize hardware resources. Quantum multi-programming (QMP) mitigates this by executing multiple circuits in parallel on a single device, but existing methods target superconducting systems with limited connectivity, high crosstalk, and lower gate fidelity. Trapped-ion architectures, with all-to-all connectivity, long coherence times, and high-fidelity mid-circuit measurement properties, presents itself as a more suitable platform for scalable QMP. We present CircPack, a hardware-aware circuit packing framework designed for modular trapped-ion devices based on the Quantum Charge-Coupled Device (QCCD) architecture. CircPack formulates static circuit scheduling as a two-dimensional packing problem with hardware-specific shuttling constraints. Compared to superconducting-based QMP approaches, CircPack achieves up to 70.72% better fidelity, 62.67% higher utilization, and 32.80% improved layer reduction. This framework is also capable of scalable, balanced scheduling across a cluster of independent QCCD modules, highlighting trapped-ion systems' potential in improving the throughput of quantum cloud computing in the near future.

</details>


### [71] [Quantum Gates from Wolfram Model Multiway Rewriting Systems](https://arxiv.org/abs/2512.20587)
*Furkan Semih Dündar,Xerxes D. Arsiwalla,Hatem Elshatlawy*

Main category: quant-ph

TL;DR: 该论文展示了如何使用非确定性重写系统构建有限维量子算子的表示，特别是基于字符串替换的Wolfram模型多路重写系统。通过研究具有邻域约束的循环字符串（莱布尼茨字符串），发现其字符邻域占据数的期望值呈现费米-狄拉克分布，可作为N-费米子系统的抽象。多路系统编码了重写事件间的因果关系，实现了具有对称双线性形式的ℤ-模，从而得到离散路径积分和S矩阵，最终可表示量子门和量子电路。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索非确定性重写系统作为量子算子表示的基础框架。Wolfram提出的多路系统作为多计算过程的通用模型，特别适合建模复杂性、非确定性和测量结果的分支结构。本文旨在展示这类系统如何自然地编码量子计算结构，为量子信息处理提供新的形式化基础。

Method: 方法基于Wolfram模型多路重写系统，特别关注具有邻域约束的循环字符串（莱布尼茨字符串）。分析这些字符串的统计特性，发现其字符邻域占据数期望值服从费米-狄拉克分布。将莱布尼茨字符串抽象为N-费米子系统，多路系统编码重写事件间的因果结构。构建ℤ-模和对称双线性形式，推广离散空间中的内积概念，从而定义离散路径积分和多路系统的S矩阵。

Result: 研究发现莱布尼茨字符串的字符邻域占据数期望值呈现费米-狄拉克分布，表明其可作为费米子系统的抽象。多路系统实现了具有对称双线性形式的ℤ-模，允许定义离散路径积分和S矩阵。这些S矩阵能够明确表示量子门（如CNOT、π/8、Hadamard门）和量子电路。作为非确定性计算的形式模型，具有因果结构的莱布尼茨字符串重写系统能够编码量子比特和qudit的量子门表示。

Conclusion: 结论表明，基于Wolfram模型多路重写系统的莱布尼茨字符串能够构建有限维量子算子的表示。这种框架为量子计算提供了新的形式化基础，将非确定性重写系统与量子信息处理联系起来。通过多路系统可以表示量子门和量子电路，为量子计算的建模和实现提供了新的理论工具。

Abstract: We show how representations of finite-dimensional quantum operators can be constructed using nondeterministic rewriting systems. In particular, we investigate Wolfram model multiway rewriting systems based on string substitutions. Multiway systems were proposed by S. Wolfram as generic model systems for multicomputational processes, emphasizing their significance as a foundation for modeling complexity, nondeterminism, and branching structures of measurement outcomes. Here, we investigate a specific class of multiway systems based on cyclic character strings with a neighborhood constraint - the latter called Leibnizian strings. We show that such strings exhibit a Fermi-Dirac distribution for expectation values of occupation numbers of character neighborhoods. A Leibnizian string serves as an abstraction of a $N$-fermion system. A multiway system of these strings encodes causal relations between rewriting events in a nondeterministic manner. The collection of character strings realizes a $\mathbb{Z}$-module with a symmetric $\mathbb{Z}$-bilinear form. For discrete spaces, this generalizes the notion of an inner product over a vector field. This admits a discrete analogue of the path integral and a $S$-matrix for multiway systems of Leibnizian strings. The elements of this $S$-matrix yield transition amplitudes between states of the multiway system based on an action defined over a sequence of Leibnizian strings. We then show that these $S$-matrices give explicit representations of quantum gates for qubits and qudits, and also circuits composed of such gates. We find that, as formal models of nondeterministic computation, rewriting systems of Leibnizian strings with causal structure encode representations of the CNOT, $π/8$, and Hadamard gates. Hence, using multiway systems one can represent quantum circuits for qubits.

</details>


### [72] [Certified Lower Bounds and Efficient Estimation of Minimum Accuracy in Quantum Kernel Methods](https://arxiv.org/abs/2512.20588)
*Demerson N. Gonçalves,Tharso D. Fernandes,Andrias M. M. Cordeiro,Pedro H. G. Lugao,João T. Dias*

Main category: quant-ph

TL;DR: 该研究改进了量子特征图的最小准确率启发式评估方法，使其适用于任意二分类数据集，提供理论保证，并引入蒙特卡洛策略提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 原始的最小准确率启发式方法存在计算成本高、仅适用于平衡数据集、缺乏理论支撑等局限性，需要改进以使其成为实用的量子特征图预筛选工具。

Method: 1. 将最小准确率度量推广到任意二分类数据集；2. 形式化证明该度量构成相同特征空间中任何线性分类器最优经验准确率的认证下界；3. 引入基于随机泡利方向的蒙特卡洛策略来高效估计该下界。

Result: 建立了最小准确率作为可扩展、理论可靠的工具，可用于在近期量子设备上预筛选特征图，并提供严格的概率保证。

Conclusion: 该研究解决了原始最小准确率启发式方法的局限性，使其成为评估量子特征图的有效工具，特别适合在资源受限的近期量子设备上使用。

Abstract: The minimum accuracy heuristic evaluates quantum feature maps without requiring full quantum support vector machine (QSVM) training. However, the original formulation is computationally expensive, restricted to balanced datasets, and lacks theoretical backing. This work generalizes the metric to arbitrary binary datasets and formally proves it constitutes a certified lower bound on the optimal empirical accuracy of any linear classifier in the same feature space. Furthermore, we introduce Monte Carlo strategies to efficiently estimate this bound using a random subset of Pauli directions, accompanied by rigorous probabilistic guarantees. These contributions establish minimum accuracy as a scalable, theoretically sound tool for pre-screening feature maps on near-term quantum devices.

</details>


### [73] [Random Stinespring superchannel: converting channel queries into dilation isometry queries](https://arxiv.org/abs/2512.20599)
*Filippo Girardi,Francesco Anna Mele,Haimeng Zhao,Marco Fanizza,Ludovico Lami*

Main category: quant-ph

TL;DR: 本文引入随机Stinespring超信道，将任意量子信道的n次并行查询转换为相同均匀随机Stinespring等距的n次查询，建立了信道学习与等距学习之间的等价关系，完全确定了量子信道学习的最优查询复杂度为Θ(d_A d_B r)。


<details>
  <summary>Details</summary>
Motivation: 受最近引入的随机纯化信道启发，该信道将任意混合量子态的n个副本转换为相同均匀随机纯化的n个副本。作者希望建立信道层面的类似工具，将量子信道学习问题简化为等距学习问题。

Method: 引入随机Stinespring超信道，通过通用编码和解码操作，将任意量子信道的n次并行查询转换为相同均匀随机Stinespring等距的n次并行查询。当信道承诺Choi秩不超过r时，该过程可调整为产生维度为r的Stinespring环境。

Result: 量子信道学习可简化为等距学习，基于现有等距学习协议的信道学习算法性能与最近提出的两种信道层析算法相当。通过从下界中移除对数因子，完全确定了量子信道学习的最优查询复杂度为Θ(d_A d_B r)。

Conclusion: 随机Stinespring超信道建立了信道学习与等距学习之间的等价关系，完全确立了最近引入的信道学习算法的最优性，为量子信道学习提供了理论基础和实用工具。

Abstract: The recently introduced random purification channel, which converts $n$ copies of an arbitrary mixed quantum state into $n$ copies of the same uniformly random purification, has emerged as a powerful tool in quantum information theory. Motivated by this development, we introduce a channel-level analogue, which we call the random Stinespring superchannel. This consists in a procedure to transform $n$ parallel queries of an arbitrary quantum channel into $n$ parallel queries of the same uniformly random Stinespring isometry, via universal encoding and decoding operations that are efficiently implementable. When the channel is promised to have Choi rank at most $r$, the procedure can be tailored to yield a Stinespring environment of dimension $r$. As a consequence, quantum channel learning reduces to isometry learning, yielding a simple channel learning algorithm, based on existing isometry learning protocols, that matches the performance of the two recently proposed channel tomography algorithms. Complementarily, whereas the optimality of these algorithms had previously been established only up to a logarithmic factor in the dimension, we close this gap by removing this logarithmic factor from the lower bound. Taken together, our results fully establish the optimality of these recently introduced channel learning algorithms, showing that the optimal query complexity of learning a quantum channel with input dimension $d_A$, output dimension $d_B$, and Choi rank $r$ is $Θ(d_A d_B r)$.

</details>


### [74] [Single-LED-pumped, room-temperature, solid-state maser](https://arxiv.org/abs/2512.20611)
*Michael Newns,Shirley Xu,Mingyang Liu,Zike Cheng,Zike Cheng,Ziqiu Huang,Max Attwood,Mark Oxborrow*

Main category: quant-ph

TL;DR: 研究人员通过使用芯片级LED和嵌入式波导实现了小型化OPSS微波激射器，相比端面光激发将合作性提高了至少2倍


<details>
  <summary>Details</summary>
Motivation: 传统光学泵浦微波激射器（OPSS maser）的泵浦源尺寸通常主导整个系统尺寸，限制了其小型化和实际应用潜力

Method: 使用单个芯片级LED作为泵浦源，通过嵌入式波导将光直接注入pentacene掺杂的对三联苯晶体中，结合实验测量和光线追踪分析

Result: 成功实现了微波激射器振荡，系统尺寸显著减小，嵌入式波导方法相比端面光激发将合作性提高了至少2倍

Conclusion: 嵌入式波导泵浦方法为OPSS微波激射器的小型化提供了有效途径，有望推动其在量子传感器、振荡器和放大器等领域的应用

Abstract: Through their ability to achieve `cryogenic' levels of noise performance while operating at room temperature, optically-pumped, solid-state (OPSS) masers show great promise as quantum sensors, oscillators, and amplifiers. We here demonstrate maser oscillation in a microwave cavity containing a crystal of pentacene-doped \textit{para}-terphenyl (ptc:ptp) pumped by a single, chip-scale LED. Here, unlike previous work, the size of the pump source no longer dominates the size of the maser system as a whole. This miniaturization is achieved through invasive optical pumping in the form of a waveguide, the tip of which is embedded into the maser crystal. Combining experimental measurements with ray-tracing analysis, we find that our approach offers at least a factor of 2 enhancement in the cooperativity over end-on optical excitation.

</details>


### [75] [Variational (matrix) product states for combinatorial optimization](https://arxiv.org/abs/2512.20613)
*Guillermo Preisser,Conor Mc Keever,Michael Lubasch*

Main category: quant-ph

TL;DR: 提出基于产品态和矩阵产品态变分方法的量子启发式迭代局部搜索算法，用于组合优化问题近似求解，在最大割问题上表现优于传统方法


<details>
  <summary>Details</summary>
Motivation: 为了解决组合优化问题的近似求解，需要开发能够超越传统变分量子方法、经典启发式算法和量子近似优化算法性能的新方法

Method: 结合产品态和矩阵产品态变分方法，基于量子退火哈密顿量进行变分能量最小化，并嵌入迭代局部搜索元启发式算法中引入随机性

Result: 在最多50000个变量的最大割问题上进行基准测试，结果显示该方法能够超越传统(M)PS方法、经典ILS、量子近似优化算法和其他变分量子启发式求解器

Conclusion: 量子启发式迭代局部搜索算法是解决大规模组合优化问题的有效方法，结合了量子变分方法和经典启发式算法的优势

Abstract: To compute approximate solutions for combinatorial optimization problems, we describe variational methods based on the product state (PS) and matrix product state (MPS) ansatzes. We perform variational energy minimization with respect to a quantum annealing Hamiltonian and utilize randomness by embedding the approaches in the metaheuristic iterated local search (ILS). The resulting quantum-inspired ILS algorithms are benchmarked on maximum cut problems of up to 50000 variables. We show that they can outperform traditional (M)PS methods, classical ILS, the quantum approximate optimization algorithm and other variational quantum-inspired solvers.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [76] [A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution](https://arxiv.org/abs/2512.19882)
*Mahdi Mostajabdaveh,F. Sibel Salman,Walter J. Gutjahr*

Main category: cs.AI

TL;DR: 本文提出了一种双目标优化模型，用于灾后救援物资配送，同时考虑效率（最小化总旅行时间）和公平性（基于基尼系数最小化未满足需求的不平等），并开发了分支定价算法求解。


<details>
  <summary>Details</summary>
Motivation: 重大灾害中，预置物资往往无法满足所有需求，需要从配送中心向避难所分配有限救援物资。如何在效率和公平性之间取得平衡是灾后人道主义物流的关键挑战。

Method: 建立混合整数规划模型，采用ε-约束方法处理双目标优化。通过推导最优解的数学性质，引入有效不等式，并设计给定可行车辆路径下的最优配送分配算法。开发分支定价算法高效求解问题。

Result: 在土耳其范省地震和伊斯坦布尔卡塔尔地区的实际数据集上测试，分支定价算法显著优于商业MIP求解器。双目标方法在不牺牲效率的情况下将援助分配不平等降低了34%。

Conclusion: 当时间约束非常宽松或紧张时，优先考虑需求覆盖的词典序优化是有效的；对于中等限制的时间约束，平衡方法对避免不公平结果至关重要。

Abstract: The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and equity, we formulate a bi-objective problem: minimizing a Gini-index-based measure of inequity in unsatisfied demand for fair distribution and minimizing total travel time for timely delivery. We propose a Mixed Integer Programming (MIP) model and use the $ε$-constraint method to handle the bi-objective nature. By deriving mathematical properties of the optimal solution, we introduce valid inequalities and design an algorithm for optimal delivery allocations given feasible vehicle routes. A branch-and-price (B&P) algorithm is developed to solve the problem efficiently. Computational tests on realistic datasets from a past earthquake in Van, Turkey, and predicted data for Istanbul's Kartal region show that the B&P algorithm significantly outperforms commercial MIP solvers. Our bi-objective approach reduces aid distribution inequity by 34% without compromising efficiency. Results indicate that when time constraints are very loose or tight, lexicographic optimization prioritizing demand coverage over fairness is effective. For moderately restrictive time constraints, a balanced approach is essential to avoid inequitable outcomes.

</details>


### [77] [Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification](https://arxiv.org/abs/2512.19957)
*Luciano Araujo Dourado Filho,Almir Moreira da Silva Neto,Rodrigo Pereira David,Rodrigo Tripodi Calumby*

Main category: cs.AI

TL;DR: 该论文提出了一种针对PlantClef 2025挑战赛的解决方案，通过使用训练数据集中的类别原型作为指导，训练分割Vision Transformer模型进行细粒度多标签物种识别。


<details>
  <summary>Details</summary>
Motivation: PlantClef 2025挑战赛需要从高分辨率图像中进行细粒度多标签物种识别。传统方法可能难以处理高分辨率植被图像中的复杂场景，需要一种能够适应从单物种多类别识别到多标签分类的域适应方法。

Method: 方法包括：1）从训练数据集中提取特征并应用K-Means聚类创建类别原型；2）构建定制化的窄Vision Transformer模型，用冻结的DinoV2替换patch embedding层；3）训练模型从测试数据集图像重建训练数据集的类别原型；4）利用注意力分数识别和定位感兴趣区域以指导分类过程。

Result: 该方法在PlantCLEF 2025挑战赛的私有排行榜上获得第五名，F1分数为0.33331。与最佳提交结果仅相差0.03，表明在基准任务中具有竞争力。

Conclusion: 提出的方法成功实现了从单物种多类别识别到高分辨率植被图像多标签分类的域适应，在PlantCLEF 2025挑战赛中取得了有竞争力的表现，证明了原型引导的分割ViT方法在细粒度植物识别任务中的有效性。

Abstract: This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test set images. To obtain these representations, the proposed method extracts features from training dataset images and create clusters, by applying K-Means, with $K$ equals to the number of classes in the dataset. The segmentation model is a customized narrow ViT, built by replacing the patch embedding layer with a frozen DinoV2, pre-trained on the training dataset for individual species classification. This model is trained to reconstruct the class prototypes of the training dataset from the test dataset images. We then use this model to obtain attention scores that enable to identify and localize areas of interest and consequently guide the classification process. The proposed approach enabled a domain-adaptation from multi-class identification with individual species, into multi-label classification from high-resolution vegetation plots. Our method achieved fifth place in the PlantCLEF 2025 challenge on the private leaderboard, with an F1 score of 0.33331. Besides that, in absolute terms our method scored 0.03 lower than the top-performing submission, suggesting that it may achieved competitive performance in the benchmark task. Our code is available at \href{https://github.com/ADAM-UEFS/PlantCLEF2025}{https://github.com/ADAM-UEFS/PlantCLEF2025}.

</details>


### [78] [FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification](https://arxiv.org/abs/2512.19960)
*Luciano Araujo Dourado Filho,Rodrigo Tripodi Calumby*

Main category: cs.AI

TL;DR: 提出一种通过类内聚类生成伪标签进行层次分类的方法，以缓解细粒度视觉分类任务中的类内变异问题，在PlantNet300k数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 细粒度视觉分类任务中，类内变异（同一类别内图像间的差异程度）会阻碍深度学习模型的学习过程，特别是当这些类别同时存在样本不足的问题时。需要一种方法来缓解类内变异问题，学习更精细的视觉特征。

Method: 提出一种新颖方法：通过对每个类别单独进行聚类，发现编码图像间相似度的伪标签，然后将这些标签用于层次分类过程，从而学习更精细的视觉特征并缓解类内变异问题。

Result: 在PlantNet300k数据集上的初步实验揭示了未来工作需要发展的关键点，尽管方法中的某些组件尚未完全优化，但仍在该数据集上达到了最先进的性能。

Conclusion: 通过类内聚类生成伪标签进行层次分类的方法能够有效缓解细粒度视觉分类中的类内变异问题，提升分类性能，为未来相关研究提供了有价值的思路。

Abstract: Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.

</details>


### [79] [Discovering Lie Groups with Flow Matching](https://arxiv.org/abs/2512.20043)
*Jung Yeon Park,Yuxuan Chen,Floor Eijkelboom,Jan-Willem van de Meent,Lawson L. S. Wong,Robin Walters*

Main category: cs.AI

TL;DR: 提出LieFlow方法，通过李群上的流匹配直接从数据中学习对称性，无需先验知识，能发现离散群等复杂对称结构


<details>
  <summary>Details</summary>
Motivation: 对称性对理解物理系统和提升机器学习性能都很重要，但通常需要先验知识。现有方法在发现对称性方面存在局限，需要更灵活、假设更少的方法来直接从数据中学习对称性

Method: 提出LieFlow方法，将对称性发现定义为在李群上学习分布，使学习到的分布与数据中观察到的对称性匹配。使用流匹配技术，并针对对称性发现中的"最后一刻收敛"问题提出了新的插值方案

Result: 在2D和3D点云数据上的实验表明，该方法能成功发现离散群，包括通过复域上的流匹配发现反射对称性。解决了对称目标模式排列导致的"最后一刻收敛"问题

Conclusion: LieFlow提供了一种灵活、假设少的对称性发现方法，能直接从数据中学习各种类型的对称群，为物理系统理解和机器学习应用提供了有效工具

Abstract: Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.

</details>


### [80] [Learning Skills from Action-Free Videos](https://arxiv.org/abs/2512.20052)
*Hung-Chieh Fang,Kuo-Han Hung,Chu-Rong Chen,Po-Jung Chou,Chun-Kai Yang,Po-Chen Ko,Yu-Chiang Wang,Yueh-Hua Wu,Min-Hung Chen,Shao-Hua Sun*

Main category: cs.AI

TL;DR: SOF框架从无动作视频中学习基于光流的潜在技能表示，将视频生成模型与机器人动作执行桥接起来，实现高层次规划


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型难以转化为低级动作，而潜在动作模型缺乏高层次规划能力，需要一种能从视频中学习技能并支持规划的方法

Method: 提出SOF框架，通过光流作为中间表示学习潜在技能空间，该空间同时捕捉视频动态和机器人动作信息，支持技能组合和规划

Result: 实验表明SOF在多任务和长时程设置中性能持续提升，能够直接从原始视觉数据中获取和组合技能

Conclusion: SOF通过光流表示的技能抽象成功桥接了视频生成与机器人动作执行，为从视频学习通用机器人技能提供了有效途径

Abstract: Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.

</details>


### [81] [Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach](https://arxiv.org/abs/2512.20056)
*Hao Li,Fabian Deuser,Wenping Yin,Steffen Knoblauch,Wufan Zhao,Filip Biljecki,Yong Xue,Wei Huang*

Main category: cs.AI

TL;DR: 提出ProbGLC概率交叉视图地理定位方法，结合概率和确定性模型，提高灾害响应中的定位准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 气候变化导致灾害事件频发加剧，快速准确的灾害位置识别对气候韧性和可持续发展至关重要，需要解决灾害响应中的地理定位挑战

Method: 提出ProbGLC概率交叉视图地理定位方法，将概率性和确定性地理定位模型结合到统一框架中，通过不确定性量化增强模型可解释性，同时实现最先进的地理定位性能

Result: 在两个交叉视图灾害数据集上的实验显示，ProbGLC在1公里精度达到0.86，25公里精度达到0.97，同时通过概率分布和可定位性分数提供模型可解释性

Conclusion: ProbGLC方法在灾害地理定位方面表现出优越性能，展示了生成式交叉视图方法在提高位置感知能力、支持更好更快灾害响应方面的巨大潜力

Abstract: As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC

</details>


### [82] [Scaling Reinforcement Learning for Content Moderation with Large Language Models](https://arxiv.org/abs/2512.20061)
*Hamed Firooz,Rui Liu,Yuchen Lu,Zhenyu Hou,Fangzhou Xiong,Xiaoyang Zhang,Changshu Jian,Zhicheng Zhu,Jiayuan Ma,Jacob Tao,Chaitali Gupta,Xiaochang Peng,Shike Mei,Hang Cui,Yang Qin,Shuo Tang,Jason Gaedtke,Arpit Mittal*

Main category: cs.AI

TL;DR: 论文系统研究了使用强化学习进行内容审核分类，发现RL在数据稀缺、政策复杂的场景下比监督微调更高效，性能随训练规模呈S型增长


<details>
  <summary>Details</summary>
Motivation: 大规模内容审核是数字生态系统中最紧迫的挑战之一，现有基于大语言模型的审核系统在实际应用中面临标签稀疏、政策定义不断演变、需要超越浅层模式匹配的细致推理等挑战，这些实际困难尚未得到充分探索

Method: 采用全面的实证研究方法，系统评估多种RL训练方案和奖励塑造策略，包括可验证奖励和LLM-as-judge框架，将通用语言模型转化为专门的政策对齐分类器，在三个真实世界内容审核任务上进行测试

Result: RL表现出S型扩展行为，性能随训练数据、rollouts和优化步骤的增加而平稳提升后逐渐饱和；在需要复杂政策推理的任务上性能显著提升，数据效率比监督微调高100倍，特别适用于专家标注稀缺或成本高的领域

Conclusion: 强化学习为工业级内容审核系统提供了可行的解决方案，在数据稀缺和政策复杂的场景下具有显著优势，为实际应用提供了可操作的见解

Abstract: Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.

</details>


### [83] [Reason2Decide: Rationale-Driven Multi-Task Learning](https://arxiv.org/abs/2512.20074)
*H M Quamran Hasan,Housam Khalifa Bashier,Jiayi Dai,Mi-Young Kim,Randy Goebel*

Main category: cs.AI

TL;DR: Reason2Decide是一个两阶段训练框架，通过解决自解释中的暴露偏差和任务分离问题，在临床决策支持系统中实现高预测准确性和解释对齐。


<details>
  <summary>Details</summary>
Motivation: 当前临床决策支持系统面临关键挑战：在实现高预测准确性的同时，生成与预测一致的解释。现有方法存在暴露偏差问题，导致解释与预测不一致。

Method: 提出Reason2Decide两阶段训练框架：第一阶段训练模型生成解释；第二阶段联合训练标签预测和解释生成，应用计划采样从基于黄金标签逐步过渡到基于模型预测。

Result: 在三个医疗数据集上评估，Reason2Decide在预测准确性和解释保真度方面优于其他微调基线方法和一些零样本LLM。在分诊任务中，对LLM生成、护士撰写和护士后处理的解释都具有鲁棒性。

Conclusion: Reason2Decide仅使用LLM生成解释进行预训练就能取得优异表现，减少对人类标注的依赖。该框架使用比当代基础模型小40倍的模型实现这些增益，使临床推理在资源受限环境中更加可访问。

Abstract: Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.

</details>


### [84] [Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches](https://arxiv.org/abs/2512.20082)
*Chaithra,Kamesh Kadimisetty,Biju R Mohan*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型与股市反馈的自适应金融情感分析框架，通过指令微调、检索增强生成和强化学习优化，在印度股市数据上显著提升了情感分类的准确性和市场对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有金融情感分析研究未考虑股价或市场反馈对情感分析的影响，需要开发能够适应市场动态变化的情感分析系统。

Method: 1. 使用指令学习在SentiFin数据集上微调LLaMA 3.2 3B模型；2. 采用检索增强生成(RAG)管道动态选择多源上下文信息；3. 引入反馈驱动模块，通过比较预测情感与实际次日股票收益来调整源可靠性；4. 集成基于近端策略优化(PPO)的强化学习智能体，学习优化源权重策略。

Result: 在2024-2025年NIFTY 50新闻标题数据集上的实验表明，该系统在分类准确率、F1分数和市场对齐度方面显著优于基线模型和静态检索方法。

Conclusion: 结合指令微调大语言模型、动态反馈和强化学习的方法能够实现稳健、市场感知的金融情感建模，验证了该框架在金融情感分析中的潜力。

Abstract: Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.

</details>


### [85] [MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization](https://arxiv.org/abs/2512.20135)
*Zhuo Yang,Yeyun chen,Jiaqing Xie,Ben Gao,Shuaike Shen,Wanhao Liu,Liujia Yang,Beilun Wang,Tianfan Fu,Yuqiang Li*

Main category: cs.AI

TL;DR: MolAct是一个基于智能体强化学习的分子编辑与优化框架，通过两阶段训练（先学编辑能力，再学优化）实现多步骤分子设计，在编辑任务中达到接近100%的有效性，在优化任务中超越闭源基线模型。


<details>
  <summary>Details</summary>
Motivation: 分子编辑和优化是多步骤问题，需要迭代改进性质同时保持化学有效性和结构相似性。现有方法缺乏将分子设计形式化为智能体强化学习问题的框架，无法有效结合推理、工具使用和分子优化。

Method: 提出MolAct框架，将分子设计形式化为序列化、工具引导的决策过程。采用两阶段训练范式：第一阶段建立编辑能力，第二阶段重用学习到的编辑行为进行性质优化。智能体可以多轮交互，调用化学工具进行有效性检查、性质评估和相似性控制。

Result: MolEditAgent-7B在分子编辑任务中实现100%、95%和98%的有效添加、删除和替换编辑，优于DeepSeek-R1等闭源"思考"基线；MolEditAgent-3B接近Qwen3-32B-think等更大开源模型性能。MolOptAgent-7B在LogP优化上超越Claude 3.7等闭源基线，在溶解度上保持竞争力。

Conclusion: 将分子设计视为多步骤、工具增强的过程是实现可靠和可解释改进的关键。MolAct框架首次将分子设计形式化为智能体强化学习问题，展示了结合推理、工具使用和优化的有效性。

Abstract: Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed "thinking" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open "thinking" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed "thinking" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.

</details>


### [86] [Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection](https://arxiv.org/abs/2512.20140)
*Xingyou Yin,Ceyao Zhang,Min Hu,Kai Chen*

Main category: cs.AI

TL;DR: 该论文提出了一种简单有效的策略：在时间序列数据token化前注入噪声，以提升冻结大语言模型在零样本时间序列预测中的性能，无需微调即可增强模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖微调专门模块来弥合时间序列数据与大语言模型预训练知识之间的差距，但完全冻结的模型性能对输入数据的文本表示非常敏感。论文旨在探索无需任何微调、仅通过策略性token化来直接利用现成大语言模型进行时间序列预测的方法。

Method: 在原始时间序列数据token化前注入噪声，作为一种推理时增强技术。这种非侵入式干预迫使冻结的大语言模型基于鲁棒的时间模式而非表面数值伪影进行外推。同时引入了两个新时间序列数据集，完全排除大语言模型预训练数据污染的可能性。

Result: 理论分析和实证验证表明，噪声注入策略在多个基准测试中有效提升了性能。在新引入的两个时间序列数据集上，该方法始终表现出改进的性能，证明了其有效性。

Conclusion: 噪声注入是一种简单而高效的策略，能够克服冻结大语言模型在时间序列预测中的脆弱性，为直接利用现成大语言模型进行时间序列预测提供了进一步的技术支持。

Abstract: Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.

</details>


### [87] [A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers](https://arxiv.org/abs/2512.20161)
*Dhivya Dharshini Kannan,Anupam Trivedi,Dipti Srinivasan*

Main category: cs.AI

TL;DR: 本文提出基于双向门控循环单元(BiGRU)的数据中心能耗效率(PUE)预测模型，通过特征选择和超参数优化，相比传统GRU模型在预测精度上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 数据中心能耗占全球能源消耗和碳足迹的很大比例，随着边缘计算和AI发展，数据中心存储容量不断增长。提高能源效率是应对气候变化、降低能源成本、提升商业竞争力和促进IT与环境可持续发展的有效途径。优化数据中心能源管理对全球可持续发展至关重要。

Method: 1. 使用EnergyPlus模拟新加坡数据中心，获得包含52,560个样本和117个特征的数据集
2. 采用递归特征消除与交叉验证(RFECV)算法选择最相关特征集
3. 开发基于双向门控循环单元(BiGRU)的PUE预测模型
4. 通过超参数优化找到最优配置
5. 与传统的GRU模型进行性能对比

Result: 使用均方误差(MSE)、平均绝对误差(MAE)和R平方指标评估模型性能。优化后的BiGRU模型在PUE预测方面表现出比传统GRU模型更好的性能，能够更准确地理解各特征对能耗的影响，从而为有针对性的能效改进提供依据。

Conclusion: BiGRU模型在数据中心PUE预测方面优于传统GRU模型，通过特征选择和超参数优化可以显著提高预测精度。该研究为数据中心能源管理优化提供了有效的预测工具，有助于实现更可持续的数据中心运营。

Abstract: Data centers account for significant global energy consumption and a carbon footprint. The recent increasing demand for edge computing and AI advancements drives the growth of data center storage capacity. Energy efficiency is a cost-effective way to combat climate change, cut energy costs, improve business competitiveness, and promote IT and environmental sustainability. Thus, optimizing data center energy management is the most important factor in the sustainability of the world. Power Usage Effectiveness (PUE) is used to represent the operational efficiency of the data center. Predicting PUE using Neural Networks provides an understanding of the effect of each feature on energy consumption, thus enabling targeted modifications of those key features to improve energy efficiency. In this paper, we have developed Bidirectional Gated Recurrent Unit (BiGRU) based PUE prediction model and compared the model performance with GRU. The data set comprises 52,560 samples with 117 features using EnergyPlus, simulating a DC in Singapore. Sets of the most relevant features are selected using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm for different parameter settings. These feature sets are used to find the optimal hyperparameter configuration and train the BiGRU model. The performance of the optimized BiGRU-based PUE prediction model is then compared with that of GRU using mean squared error (MSE), mean absolute error (MAE), and R-squared metrics.

</details>


### [88] [Concept Generalization in Humans and Large Language Models: Insights from the Number Game](https://arxiv.org/abs/2512.20162)
*Arghavan Bazigaran,Hansem Sohn*

Main category: cs.AI

TL;DR: 比较人类与大型语言模型在数字游戏概念推理任务中的泛化能力差异，发现人类更灵活地结合规则与相似性推理，而LLM更依赖数学规则，且人类具有更强的少样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 研究人类与大型语言模型在概念推理任务中的泛化能力差异，探索两者在归纳偏置和推理策略上的根本区别

Method: 使用贝叶斯模型作为分析框架，在数字游戏概念推理任务中比较人类和LLM的归纳偏置和推理策略

Result: 贝叶斯模型能更好地捕捉人类行为：人类灵活推断基于规则和基于相似性的概念，而LLM更依赖数学规则；人类能从单个示例进行少样本泛化，LLM需要更多样本

Conclusion: 人类与LLM在数学概念推理和泛化方面存在根本差异，人类具有更灵活的推理能力和更强的少样本学习能力

Abstract: We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.

</details>


### [89] [Offline Safe Policy Optimization From Heterogeneous Feedback](https://arxiv.org/abs/2512.20173)
*Ze Gong,Pradeep Varakantham,Akshat Kumar*

Main category: cs.AI

TL;DR: 本文提出PreSa方法，通过直接学习策略而非间接学习奖励和成本模型，解决离线偏好强化学习中安全策略学习问题，在连续控制任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 离线偏好强化学习（PbRL）无需人工标注者直接交互即可学习符合人类偏好的奖励和策略，但确保安全仍是关键挑战。现有基于人类反馈的安全RL方法先学习奖励和成本模型，再用约束RL优化安全策略，在长时域连续控制任务中，奖励和成本的误差会累积，导致性能下降。

Method: 提出PreSa（偏好与安全对齐）框架：1）直接基于成对偏好（关于奖励）和轨迹段安全性的二元标签学习策略；2）将偏好学习模块与安全对齐结合为约束优化问题；3）在拉格朗日范式下求解，直接学习奖励最大化且安全的策略，无需显式学习奖励和成本模型，避免使用约束RL。

Result: 在具有合成和真实人类反馈的连续控制任务中评估，PreSa成功学习到高奖励的安全策略，优于最先进的基线方法，甚至优于使用真实奖励和成本的离线安全RL方法。

Conclusion: PreSa通过直接学习策略而非间接学习奖励和成本模型，有效解决了离线偏好强化学习中的安全对齐问题，在连续控制任务中表现出色，避免了传统方法中误差累积的问题。

Abstract: Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.

</details>


### [90] [TongSIM: A General Platform for Simulating Intelligent Machines](https://arxiv.org/abs/2512.20206)
*Zhe Sun,Kunlun Wu,Chuanjian Fu,Zeming Song,Langyong Shi,Zihe Xue,Bohan Jing,Ying Yang,Xiaomeng Gao,Aijia Li,Tianyu Guo,Huiying Li,Xueyuan Yang,Rongkai Liu,Xinyi He,Yuxi Wang,Yue Li,Mingyuan Liu,Yujie Lu,Hongzhao Xie,Shiyun Zhao,Bo Dai,Wei Wang,Tao Yuan,Song-Chun Zhu,Yujia Peng,Zhenliang Zhang*

Main category: cs.AI

TL;DR: TongSIM是一个高保真、通用型平台，用于训练和评估具身智能体，提供100多个多样化的室内场景和开放式的户外城镇模拟，支持从低级导航到高级复合活动的广泛研究需求。


<details>
  <summary>Details</summary>
Motivation: 随着AI特别是多模态大语言模型的快速发展，研究重点正从单模态文本处理转向更复杂的多模态和具身AI领域。现有仿真平台大多设计狭隘，针对特定任务，缺乏一个能够支持从低级具身导航到高级复合活动（如多智能体社会模拟和人机协作）的通用训练环境。

Method: 提出TongSIM平台，提供100多个多样化的多房间室内场景和开放式、交互丰富的户外城镇模拟。平台具有定制化场景、任务自适应保真度、多样化智能体类型和动态环境模拟等特性，提供全面的评估框架和基准测试。

Result: TongSIM为研究人员提供了灵活可扩展的统一平台，能够精确评估智能体的感知、认知、决策、人机协作以及空间和社会推理等能力，加速向通用具身智能的发展。

Conclusion: TongSIM填补了现有仿真平台的不足，作为一个高保真、通用型平台，能够支持广泛的具身智能研究需求，促进训练、评估和通用具身智能的进步。

Abstract: As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.

</details>


### [91] [ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge](https://arxiv.org/abs/2512.20276)
*Yuntao Dai,Hang Gu,Teng Wang,Qianyu Cheng,Yifei Zheng,Zhiyong Qiu,Lei Gong,Wenqi Lou,Xuehai Zhou*

Main category: cs.AI

TL;DR: ActionFlow是一个针对边缘设备的VLA模型推理框架，通过跨请求流水线调度和内存优化技术，将推理速度提升2.55倍，实现实时动态操作


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在边缘设备上的推理延迟高（3-5Hz），无法满足机器人交互所需的20-30Hz实时控制要求，现有优化方法需要大量重新训练或会降低模型精度

Method: 提出ActionFlow系统级推理框架：1）跨请求流水线策略，将VLA推理重新定义为微请求的宏流水线，智能批处理内存绑定的解码阶段和计算绑定的预填充阶段；2）跨请求状态打包前向算子；3）统一KV环形缓冲区，将碎片化内存操作融合为高效密集计算

Result: 在OpenVLA-7B模型上实现了2.55倍的FPS提升，无需重新训练即可在边缘硬件上实现实时动态操作

Conclusion: ActionFlow通过系统级优化有效解决了VLA模型在边缘设备上的高延迟问题，为实时机器人控制提供了可行的解决方案

Abstract: Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.

</details>


### [92] [A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice](https://arxiv.org/abs/2512.20344)
*Yaowei Bai,Ruiheng Zhang,Yu Lei,Xuhua Duan,Jingfeng Yao,Shuguang Ju,Chaoyang Wang,Wei Yao,Yiwan Guo,Guilin Zhang,Chao Wan,Qian Yuan,Lei Chen,Wenjuan Tang,Biqiang Zhu,Xinggang Wang,Tao Sun,Wei Zhou,Dacheng Tao,Yongchao Xu,Chuansheng Zheng,Huangxuan Zhao,Bo Du*

Main category: cs.AI

TL;DR: Janus-Pro-CXR是一个基于DeepSeek Janus-Pro的胸部X光解读系统，通过多中心前瞻性临床试验验证，在报告生成质量、关键放射学发现检测方面优于现有模型，并能显著提高临床工作流程效率。


<details>
  <summary>Details</summary>
Motivation: 全球放射科医生短缺问题因胸部X光工作量巨大而加剧，特别是在初级医疗中。现有多模态大语言模型的评估主要依赖自动化指标或回顾性分析，缺乏严格的前瞻性临床验证。

Method: 开发了基于DeepSeek Janus-Pro模型的Janus-Pro-CXR胸部X光解读系统，通过多中心前瞻性临床试验(NCT07117266)进行严格验证，采用轻量级架构和领域特定优化。

Result: 系统在自动报告生成方面优于最先进的X光报告生成模型，甚至超过包括ChatGPT 4o(200B参数)在内的更大规模模型；可靠检测六种临床关键放射学发现；前瞻性临床部署中，AI辅助显著提高报告质量评分，减少18.3%的解读时间(P<0.001)，54.3%的病例中专家更倾向于AI辅助结果。

Conclusion: Janus-Pro-CXR通过轻量级架构和领域特定优化，提高了诊断可靠性和工作流程效率，特别是在资源受限环境中。模型架构和实施框架将开源，以促进AI辅助放射学解决方案的临床转化。

Abstract: A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.

</details>


### [93] [Benchmarking LLMs for Predictive Applications in the Intensive Care Units](https://arxiv.org/abs/2512.20520)
*Chehak Malhotra,Mehak Gopal,Akshaya Devadiga,Pradeep Singh,Ridam Pal,Ritwik Kashyap,Tavpritesh Sethi*

Main category: cs.AI

TL;DR: 该研究比较了大型语言模型（LLMs）与小型语言模型（SLMs）在预测危重患者休克方面的表现，发现尽管GatorTron-Base取得了最高加权召回率80.5%，但LLMs在预测临床事件方面并不天然优于SLMs。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的发展，它们在自然语言处理领域的各种任务中表现出色，但在预测任务中的应用研究较少。及时预测休克可以促进早期干预，从而改善患者预后。本研究旨在比较LLMs与传统SLMs在预测危重患者休克方面的性能。

Method: 研究使用MIMIC III数据库中17,294例ICU住院患者的文本数据，筛选出住院时间>24小时且休克指数(SI)>0.7的患者，得到355例正常SI和87例异常SI患者。比较了GatorTron-Base（临床数据训练）、Llama 8B、Mistral 7B等LLMs与BioBERT、DocBERT、BioClinicalBERT、Word2Vec、Doc2Vec等SLMs。在微调过程中使用focal loss和交叉熵损失来处理类别不平衡问题。

Result: GatorTron-Base取得了最高的加权召回率80.5%，但总体性能指标显示LLMs和SLMs之间表现相当。这表明尽管LLMs在文本任务上表现出色，但在预测未来临床事件方面并不天然优于SLMs。

Conclusion: 为了实现有意义的临床结果，未来训练LLMs的努力应优先开发能够预测临床轨迹的模型，而不是专注于命名实体识别或表型分析等较简单的任务。LLMs在预测临床事件方面并不比SLMs有固有优势。

Abstract: With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.

</details>


### [94] [Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model](https://arxiv.org/abs/2512.20548)
*Zhiyi Duan,Xiangren Wang,Hongyu Yuan,Qianli Xing*

Main category: cs.AI

TL;DR: 该研究构建了首个大规模教师多模态情感分析数据集T-MED，并提出了一种基于非对称注意力的多模态教师情感分析模型AAM-TSA，显著提升了教师情感分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 教师的情感状态在教育场景中至关重要，深刻影响教学效果、学生参与度和学习成果。然而，现有研究往往由于教师情感的表演性质而无法准确捕捉，并且忽视了教学信息对情感表达的关键影响。

Method: 1. 构建T-MED数据集：包含14,938个教师情感数据实例，来自250个真实课堂，涵盖11个学科，整合了多模态文本、音频、视频和教学信息，采用人机协作标注流程确保标注准确性。
2. 提出AAM-TSA模型：引入非对称注意力机制和分层门控单元，实现差异化的跨模态特征融合和精确的情感分类。

Result: 实验结果表明，AAM-TSA模型在T-MED数据集上的准确性和可解释性方面显著优于现有的最先进方法。

Conclusion: 该研究通过构建首个大规模教师多模态情感分析数据集和提出创新的非对称注意力模型，为教师情感分析提供了系统性的解决方案，能够更准确地捕捉教师情感状态，对提升教学质量和教育效果具有重要意义。

Abstract: Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.

</details>


### [95] [LongVideoAgent: Multi-Agent Reasoning with Long Videos](https://arxiv.org/abs/2512.20618)
*Runtao Liu,Ziyi Liu,Jiaqi Tang,Yue Ma,Renjie Pi,Jipeng Zhang,Qifeng Chen*

Main category: cs.AI

TL;DR: 提出多智能体框架解决长视频问答问题，通过主LLM协调定位智能体和视觉智能体，结合强化学习训练，在长视频QA数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态LLM和长视频问答系统通常将内容压缩为有损摘要或依赖有限工具集，这会削弱时间定位能力并遗漏细粒度线索。需要更好的方法来处理小时级视频的推理任务。

Method: 提出多智能体框架：主LLM协调两个智能体——定位智能体负责定位问题相关片段，视觉智能体提取针对性文本观察。主智能体有步骤限制，通过强化学习训练以促进简洁、正确、高效的多智能体协作。

Result: 在提出的LongTVQA和LongTVQA+数据集（从TVQA/TVQA+聚合的剧集级数据集）上，多智能体系统显著优于强非智能体基线。实验显示强化学习进一步增强了训练智能体的推理和规划能力。

Conclusion: 多智能体框架通过定位智能体帮助主智能体关注相关片段，用视觉细节补充字幕，并产生可解释的轨迹，有效解决了长视频问答中的时间定位和细粒度推理问题。

Abstract: Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [96] [Isotropic conductivity of two-dimensional three- and four-phase symmetric composites: duality and universal bounds](https://arxiv.org/abs/2512.20401)
*Leonid Fel*

Main category: cond-mat.dis-nn

TL;DR: 该研究通过代数方法推导了二维三、四相对称复合材料各向同性有效电导率的上界Ω和下界ω，这些界具有普适性且满足所有物理要求的代数性质。


<details>
  <summary>Details</summary>
Motivation: 研究二维多相复合材料有效电导率的精确界限问题，特别是三、四相对称复合材料，需要建立与微结构无关的普适性界限，同时满足从物理推导出的所有代数性质。

Method: 采用代数方法推导有效电导率的上界Ω(σ₁,...,σₙ)和下界ω(σ₁,...,σₙ)，这些界限具有一阶齐次性、完全置换不变性、Keller自对偶性、正性和单调性等物理要求的代数性质。

Result: 推导出的界限与已知数值计算、渐近分析和精确结果完全一致，且比当前已知的变分界限更强。界限满足Dykhne假设和平凡解条件σₑ(σ,...,σ)=σ。

Conclusion: 通过代数方法成功建立了二维三、四相对称复合材料有效电导率的普适性上下界，这些界限具有所有必要的物理性质，比现有变分界限更优，为复合材料电导率分析提供了更精确的理论框架。

Abstract: We consider the problem of isotropic effective conductivity $σ_e(σ_1,\ldots,σ_n)$ in two-dimensional three- and four-phase symmetric composites with a partial isotropic conductivity $σ_j$ of the $j$-th phase. The upper $Ω(σ_1,\ldots,σ_n)$ and lower $ω(σ_1,\ldots,σ_n)$, $n=3,4$, bounds for effective conductivity, found by the algebraic approach, are universal (independent of the composite micro-structure) and possess all algebraic properties of $σ_e(σ_1,\ldots,σ_n)$ that follow from physics: first-order homogeneity, full permutation invariance, Keller's self-duality, positivity, and monotony. The bounds are compatible with the trivial solution $σ_e(σ,\ldots,σ)=σ$ and satisfy Dykhne's ansatz. Their comparison with previously known numerical calculations, asymptotic analysis, and exact results for isotropic effective conductivity $σ_e(σ_1,\ldots,σ_n)$ of two-dimensional three- and four-phase composites showed complete agreement. The bounds $Ω(σ_1,\ldots,σ_n)$ and $ω(σ_1,\ldots,σ_n)$ in both cases $n=3,4$ are stronger than the currently known variational bounds.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [97] [Large Language Models for EDA Cloud Job Resource and Lifetime Prediction](https://arxiv.org/abs/2512.19701)
*Yuxuan Yin,Shengke Zhou,Yunjie Zhang,Ajay Mohindra,Boxun Xu,Peng Li*

Main category: cs.LG

TL;DR: 提出基于大语言模型微调的文本到文本回归框架，用于EDA云工作负载的资源与作业生命周期预测，通过科学记数法和前缀填充提升输出格式可靠性，全注意力微调提升滑动窗口注意力LLM的预测精度。


<details>
  <summary>Details</summary>
Motivation: EDA行业云计算快速增长，需要准确的资源和作业生命周期预测以实现最优调度。传统机器学习方法难以处理EDA工作负载的复杂性和异构性，需要大量特征工程和领域专业知识。

Method: 提出新颖框架，通过文本到文本回归微调大语言模型。引入科学记数法和前缀填充来约束LLM输出格式，提高可靠性。采用全注意力微调和推理来提升滑动窗口注意力LLM的预测准确性。

Result: 在真实世界云数据集上验证了所提框架的有效性，为EDA领域的性能预测设立了新的基准。

Conclusion: 微调大语言模型的方法能够有效解决EDA云工作负载预测问题，通过文本到文本回归框架显著提升了预测精度和输出可靠性。

Abstract: The rapid growth of cloud computing in the Electronic Design Automation (EDA) industry has created a critical need for resource and job lifetime prediction to achieve optimal scheduling. Traditional machine learning methods often struggle with the complexity and heterogeneity of EDA workloads, requiring extensive feature engineering and domain expertise. We propose a novel framework that fine-tunes Large Language Models (LLMs) to address this challenge through text-to-text regression. We introduce the scientific notation and prefix filling to constrain the LLM, significantly improving output format reliability. Moreover, we found that full-attention finetuning and inference improves the prediction accuracy of sliding-window-attention LLMs. We demonstrate the effectiveness of our proposed framework on real-world cloud datasets, setting a new baseline for performance prediction in the EDA domain.

</details>


### [98] [Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches](https://arxiv.org/abs/2512.19713)
*Taoran Sheng,Manfred Huber*

Main category: cs.LG

TL;DR: 本文系统研究了可穿戴设备人体活动识别的监督学习谱系，提出了多种减少标注需求的方法，特别是新颖的弱自监督学习框架，在仅需10%标注数据的情况下仍能保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 可穿戴传感器的人体活动识别中，完全监督方法需要大量标注数据成本高昂，而无监督方法性能不佳。需要探索在标注需求与性能之间取得更好平衡的学习范式。

Method: 开发并比较了六种方法：1)传统完全监督学习；2)基本无监督学习；3)带约束的弱监督学习；4)知识共享的多任务学习；5)基于领域知识的自监督学习；6)新颖的弱自监督学习框架，结合领域知识和少量标注数据。

Result: 实验表明：1)弱监督方法性能接近完全监督但显著减少监督需求；2)多任务框架通过任务间知识共享提升性能；3)弱自监督方法仅需10%标注数据就表现出显著效率。

Conclusion: 不同学习范式具有互补优势，可根据标注数据可用性定制HAR解决方案。提出的弱自监督框架为标注数据有限的实用HAR应用提供了有前景的解决方案。

Abstract: Human activity recognition (HAR) using wearable sensors has advanced through various machine learning paradigms, each with inherent trade-offs between performance and labeling requirements. While fully supervised techniques achieve high accuracy, they demand extensive labeled datasets that are costly to obtain. Conversely, unsupervised methods eliminate labeling needs but often deliver suboptimal performance. This paper presents a comprehensive investigation across the supervision spectrum for wearable-based HAR, with particular focus on novel approaches that minimize labeling requirements while maintaining competitive accuracy. We develop and empirically compare: (1) traditional fully supervised learning, (2) basic unsupervised learning, (3) a weakly supervised learning approach with constraints, (4) a multi-task learning approach with knowledge sharing, (5) a self-supervised approach based on domain expertise, and (6) a novel weakly self-supervised learning framework that leverages domain knowledge and minimal labeled data. Experiments across benchmark datasets demonstrate that: (i) our weakly supervised methods achieve performance comparable to fully supervised approaches while significantly reducing supervision requirements; (ii) the proposed multi-task framework enhances performance through knowledge sharing between related tasks; (iii) our weakly self-supervised approach demonstrates remarkable efficiency with just 10\% of labeled data. These results not only highlight the complementary strengths of different learning paradigms, offering insights into tailoring HAR solutions based on the availability of labeled data, but also establish that our novel weakly self-supervised framework offers a promising solution for practical HAR applications where labeled data are limited.

</details>


### [99] [Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data](https://arxiv.org/abs/2512.19716)
*Behrooz Mamandipoor,Chun-Nan Hsu,Martin Krause,Ulrich H. Schmidt,Rodney A. Gabriel*

Main category: cs.LG

TL;DR: 开发多模态深度学习模型，整合结构化数据、临床文本和胸部X光图像，预测ICU患者入院24小时后的院内死亡风险，在多个外部数据集上验证表现良好。


<details>
  <summary>Details</summary>
Motivation: 早期预测危重患者的院内死亡率有助于临床医生优化治疗方案。目前需要整合多种临床数据源来提高预测准确性。

Method: 使用MIMIC-III、MIMIC-IV、eICU和HiRID数据集，开发多模态深度学习模型。输入包括时间不变变量、时间变化变量、临床笔记和胸部X光图像。模型基于ICU入院后24小时内的数据预测后续住院死亡率。

Result: 包含203,434例ICU入院数据，死亡率5.2%-7.9%。整合结构化数据的模型AUROC为0.92，AUPRC为0.53，Brier分数0.19。在eICU的8个机构外部验证中AUROC为0.84-0.92。加入临床笔记和影像数据后，AUROC从0.87提升至0.89，AUPRC从0.43提升至0.48，Brier分数从0.37改善至0.17。

Conclusion: 研究强调了整合多种患者信息源对死亡率预测的重要性，以及外部验证的关键作用。多模态方法显著提升了预测性能。

Abstract: Early prediction of in-hospital mortality in critically ill patients can aid clinicians in optimizing treatment. The objective was to develop a multimodal deep learning model, using structured and unstructured clinical data, to predict in-hospital mortality risk among critically ill patients after their initial 24 hour intensive care unit (ICU) admission. We used data from MIMIC-III, MIMIC-IV, eICU, and HiRID. A multimodal model was developed on the MIMIC datasets, featuring time series components occurring within the first 24 hours of ICU admission and predicting risk of subsequent inpatient mortality. Inputs included time-invariant variables, time-variant variables, clinical notes, and chest X-ray images. External validation occurred in a temporally separated MIMIC population, HiRID, and eICU datasets. A total of 203,434 ICU admissions from more than 200 hospitals between 2001 to 2022 were included, in which mortality rate ranged from 5.2% to 7.9% across the four datasets. The model integrating structured data points had AUROC, AUPRC, and Brier scores of 0.92, 0.53, and 0.19, respectively. We externally validated the model on eight different institutions within the eICU dataset, demonstrating AUROCs ranging from 0.84-0.92. When including only patients with available clinical notes and imaging data, inclusion of notes and imaging into the model, the AUROC, AUPRC, and Brier score improved from 0.87 to 0.89, 0.43 to 0.48, and 0.37 to 0.17, respectively. Our findings highlight the importance of incorporating multiple sources of patient information for mortality prediction and the importance of external validation.

</details>


### [100] [Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference](https://arxiv.org/abs/2512.19717)
*Zhan Zhang*

Main category: cs.LG

TL;DR: ICFA是一个用于在大搜索空间中寻找稀有但有用解的反向因果聚焦算法，通过目标条件重加权过程实现聚焦采样，避免退化，并展示了在约束语言生成和稀疏奖励导航中的应用。


<details>
  <summary>Details</summary>
Motivation: 在语言生成、规划和强化学习等领域，从巨大的候选空间中寻找稀有但有用的解决方案是一个实际挑战。现有方法往往效率低下，需要大量样本才能找到高质量解。

Method: 提出了反向因果聚焦算法（ICFA），将搜索视为目标条件重加权过程。该方法重用现有的提议采样器和任务特定的相似性函数来形成聚焦采样分布，同时自适应控制聚焦强度以避免退化。

Result: 提供了清晰的实施方法、基于有效样本大小的稳定性诊断、理论分析说明ICFA何时能减少样本需求，以及两个可复现实验：约束语言生成和稀疏奖励导航。还展示了结构化提示如何实现近似语言级的ICFA。

Conclusion: ICFA提供了一个实用的框架，用于在大搜索空间中高效寻找稀有解，结合了算法重加权和提示推理的混合架构，在多个领域具有应用潜力。

Abstract: Finding rare but useful solutions in very large candidate spaces is a recurring practical challenge across language generation, planning, and reinforcement learning. We present a practical framework, \emph{Inverted Causality Focusing Algorithm} (ICFA), that treats search as a target-conditioned reweighting process. ICFA reuses an available proposal sampler and a task-specific similarity function to form a focused sampling distribution, while adaptively controlling focusing strength to avoid degeneracy. We provide a clear recipe, a stability diagnostic based on effective sample size, a compact theoretical sketch explaining when ICFA can reduce sample needs, and two reproducible experiments: constrained language generation and sparse-reward navigation. We further show how structured prompts instantiate an approximate, language-level form of ICFA and describe a hybrid architecture combining prompted inference with algorithmic reweighting.

</details>


### [101] [Per-Axis Weight Deltas for Frequent Model Updates](https://arxiv.org/abs/2512.19720)
*Stefan Kuyumdzhiev,Radostin Cholakov*

Main category: cs.LG

TL;DR: 提出一种1位权重差异压缩方案，仅存储权重差异的符号和轻量级每轴缩放因子，显著减少微调模型存储和冷启动延迟


<details>
  <summary>Details</summary>
Motivation: 针对任务专用LLM变体部署时面临的大规模微调检查点存储问题和冷启动延迟问题，提出压缩权重差异的方案

Method: 使用1位差异方案，仅存储权重差异的符号，配合每轴（行/列）FP16缩放因子，通过小型校准集学习，避免密集重建

Result: 相比标量替代方案，该方法能更准确地捕捉权重维度变化，提高重建质量，存储开销远小于完整FP16检查点

Conclusion: 该方法简单易用，需要最小校准数据，保持推理效率，显著减少模型存储和冷启动延迟

Abstract: Serving many task-specialized LLM variants is often limited by the large size of fine-tuned checkpoints and the resulting cold-start latency. Since fine-tuned weights differ from their base model by relatively small structured residuals, a natural approach is to represent them as compressed deltas. We propose a simple 1-bit delta scheme that stores only the sign of the weight difference together with lightweight per-axis (row/column) FP16 scaling factors, learned from a small calibration set. This design preserves the compactness of 1-bit deltas while more accurately capturing variation across weight dimensions, leading to improved reconstruction quality over scalar alternatives. From a systems perspective, a streamlined loader that transfers packed deltas in a single operation per module reduces cold-start latency and storage overhead, with artifacts several times smaller than a full FP16 checkpoint. The method is drop-in, requires minimal calibration data, and maintains inference efficiency by avoiding dense reconstruction. Our experimental setup and source code are available at https://github.com/kuiumdjiev/Per-Axis-Weight-Deltas-for-Frequent-Model-Updates.

</details>


### [102] [Sign-Aware Multistate Jaccard Kernels and Geometry for Real and Complex-Valued Signals](https://arxiv.org/abs/2512.19721)
*Vineet Yadav*

Main category: cs.LG

TL;DR: 本文提出了一种符号感知的多状态Jaccard/Tanimoto框架，将基于重叠的距离从非负向量扩展到任意实值和复值信号，同时保持有界度量结构和正半定核。


<details>
  <summary>Details</summary>
Motivation: 现有Jaccard/Tanimoto相似度主要适用于非负数据，无法处理包含正负符号的实值信号和复值信号。需要一种统一的框架来扩展这些度量，使其能够处理更广泛的数据类型，同时保持数学上的良好性质。

Method: 1. 将信号表示为带符号状态空间上的原子测度；2. 使用正负分割处理实信号，笛卡尔和极坐标分解处理复信号；3. 将信号嵌入到非负多状态表示中；4. 应用Tanimoto构造得到[0,1]范围内的距离；5. 通过Möbius反演进行联盟分析；6. 归一化嵌入产生概率测度。

Result: 提出的框架产生了有界度量距离，满足三角不等式，定义了正半定核，可直接用于核方法和基于图的学习。同时提供了概率语义、透明预算核算和机制解释性，支持科学和金融应用中的相关图、特征工程和相似性图等工具。

Conclusion: 该研究成功扩展了Jaccard/Tanimoto框架，使其能够处理带符号的实值和复值信号，同时保持了数学上的良好性质。提出的单一框架同时提供了有界度量结构、正半定核、概率语义和透明预算核算，为科学和金融应用提供了强大的分析工具。

Abstract: We introduce a sign-aware, multistate Jaccard/Tanimoto framework that extends overlap-based distances from nonnegative vectors and measures to arbitrary real- and complex-valued signals while retaining bounded metric and positive-semidefinite kernel structure. Formally, the construction is a set- and measure-theoretic geometry: signals are represented as atomic measures on a signed state space, and similarity is given by a generalized Jaccard overlap of these measures. Each signal is embedded into a nonnegative multistate representation, using positive/negative splits for real signals, Cartesian and polar decompositions for complex signals, and user-defined state partitions for refined regime analysis. Applying the Tanimoto construction to these embeddings yields a family of $[0,1]$ distances that satisfy the triangle inequality and define positive-semidefinite kernels usable directly in kernel methods and graph-based learning. Beyond pairwise distances, we develop coalition analysis via Möbius inversion, which decomposes signal magnitude into nonnegative, additive contributions with exact budget closure across coalitions of signals. Normalizing the same embeddings produces probability measures on coordinate -- state configurations, so that the distance becomes a monotone transform of total variation and admits a regime -- intensity decomposition. The resulting construction yields a single, mechanistically interpretable distance that simultaneously provides bounded metric structure, positive-semidefinite kernels, probabilistic semantics, and transparent budget accounting within one sign-aware framework, supporting correlograms, feature engineering, similarity graphs, and other analytical tools in scientific and financial applications.

</details>


### [103] [Node-Level Financial Optimization in Demand Forecasting Through Dynamic Cost Asymmetry and Feedback Mechanism](https://arxiv.org/abs/2512.19722)
*Alessandro Casadei,Clemens Grupp,Sreyoshi Bhaduri,Lu Guo,Wilson Fung,Rohit Malshe,Raj Ratan,Ankush Pole,Arkajit Rakshit*

Main category: cs.LG

TL;DR: 提出一种基于节点特定成本函数不对称性的预测调整方法，通过动态将成本不对称性纳入预测误差概率分布来优化最便宜情景，实现年度510万美元的节约


<details>
  <summary>Details</summary>
Motivation: 传统预测模型通常假设对称的误差成本，但实际应用中不同方向的预测误差可能带来不同的成本影响。需要开发能够考虑节点特定成本不对称性的预测调整方法，以优化决策并实现成本节约。

Method: 提出一种动态调整预测的方法：1）将成本不对称性纳入预测误差概率分布，偏向成本最低的情景；2）计算实际节约；3）引入自调节机制，根据观察到的节约动态调整调整幅度，以适应站点特定条件和未建模因素（如校准误差或宏观经济动态变化）。

Result: 实证结果表明，该模型能够实现510万美元的年度节约，证明了方法在实际应用中的有效性。

Conclusion: 通过动态整合成本不对称性并引入自调节机制，该方法能够有效优化预测决策，适应不同站点条件和外部因素变化，实现显著的成本节约。

Abstract: This work introduces a methodology to adjust forecasts based on node-specific cost function asymmetry. The proposed model generates savings by dynamically incorporating the cost asymmetry into the forecasting error probability distribution to favor the least expensive scenario. Savings are calculated and a self-regulation mechanism modulates the adjustments magnitude based on the observed savings, enabling the model to adapt to station-specific conditions and unmodeled factors such as calibration errors or shifting macroeconomic dynamics. Finally, empirical results demonstrate the model's ability to achieve \$5.1M annual savings.

</details>


### [104] [End-to-End Data Quality-Driven Framework for Machine Learning in Production Environment](https://arxiv.org/abs/2512.19723)
*Firas Bayram,Bestoun S. Ahmed,Erik Hallin*

Main category: cs.LG

TL;DR: 提出了一种将数据质量评估与机器学习模型操作实时集成的端到端框架，在钢铁制造ESR真空泵过程中验证，模型性能提升12%，预测延迟减少4倍。


<details>
  <summary>Details</summary>
Motivation: 现有方法将数据质量评估和ML系统作为孤立流程处理，存在理论方法与实际实施之间的关键差距。需要解决动态工业环境中实时、质量驱动的ML决策需求。

Method: 开发了一个结合动态漂移检测、自适应数据质量指标和MLOps的轻量级系统框架，实现实时数据质量评估与ML模型操作的无缝集成。

Result: 在钢铁制造公司的电渣重熔真空泵过程中验证，模型性能提升12%（R2达到94%），预测延迟减少4倍，展示了框架在实际工业应用中的有效性。

Conclusion: 该框架代表了MLOps的重要进展，为动态工业环境中时间敏感的数据驱动决策提供了稳健解决方案，并通过数据质量可接受性阈值研究提供了平衡数据质量标准与预测性能的可行见解。

Abstract: This paper introduces a novel end-to-end framework that efficiently integrates data quality assessment with machine learning (ML) model operations in real-time production environments. While existing approaches treat data quality assessment and ML systems as isolated processes, our framework addresses the critical gap between theoretical methods and practical implementation by combining dynamic drift detection, adaptive data quality metrics, and MLOps into a cohesive, lightweight system. The key innovation lies in its operational efficiency, enabling real-time, quality-driven ML decision-making with minimal computational overhead. We validate the framework in a steel manufacturing company's Electroslag Remelting (ESR) vacuum pumping process, demonstrating a 12% improvement in model performance (R2 = 94%) and a fourfold reduction in prediction latency. By exploring the impact of data quality acceptability thresholds, we provide actionable insights into balancing data quality standards and predictive performance in industrial applications. This framework represents a significant advancement in MLOps, offering a robust solution for time-sensitive, data-driven decision-making in dynamic industrial environments.

</details>


### [105] [Out-of-Distribution Detection for Continual Learning: Design Principles and Benchmarking](https://arxiv.org/abs/2512.19725)
*Srishti Gupta,Riccardo Balia,Daniele Angioni,Fabio Brau,Maura Pintor,Ambra Demontis,Alessandro Sebastian,Salvatore Mario Carta,Fabio Roli,Battista Biggio*

Main category: cs.LG

TL;DR: 论文探讨了机器学习模型在现实世界部署中面临的两个关键挑战：持续学习和分布外检测，强调需要开发能够适应数据变化并识别新颖输入的鲁棒AI系统。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器学习模型部署面临数据分布变化和新型输入的问题。传统模型基于i.i.d.假设开发，但在实际应用中数据会随时间变化，新数据不断出现，从头重新训练模型计算成本高且不切实际。

Method: 论文提出需要联合解决持续学习（CL）和分布外（OOD）检测两个挑战。持续学习使模型能够从不断变化的数据流中增量学习而不遗忘过去知识，OOD检测使系统能够识别和响应新颖或异常输入。

Result: 论文没有提供具体的实验结果，而是从理论层面分析了当前机器学习模型在现实部署中的局限性，并指出了持续学习和OOD检测作为解决方案的重要性。

Conclusion: 联合解决持续学习和分布外检测对于开发鲁棒、高效和自适应的AI系统至关重要，这些系统能够在不断变化的现实世界环境中保持可靠性和适应性。

Abstract: Recent years have witnessed significant progress in the development of machine learning models across a wide range of fields, fueled by increased computational resources, large-scale datasets, and the rise of deep learning architectures. From malware detection to enabling autonomous navigation, modern machine learning systems have demonstrated remarkable capabilities. However, as these models are deployed in ever-changing real-world scenarios, their ability to remain reliable and adaptive over time becomes increasingly important. For example, in the real world, new malware families are continuously developed, whereas autonomous driving cars are employed in many different cities and weather conditions. Models trained in fixed settings can not respond effectively to novel conditions encountered post-deployment. In fact, most machine learning models are still developed under the assumption that training and test data are independent and identically distributed (i.i.d.), i.e., sampled from the same underlying (unknown) distribution. While this assumption simplifies model development and evaluation, it does not hold in many real-world applications, where data changes over time and unexpected inputs frequently occur. Retraining models from scratch whenever new data appears is computationally expensive, time-consuming, and impractical in resource-constrained environments. These limitations underscore the need for Continual Learning (CL), which enables models to incrementally learn from evolving data streams without forgetting past knowledge, and Out-of-Distribution (OOD) detection, which allows systems to identify and respond to novel or anomalous inputs. Jointly addressing both challenges is critical to developing robust, efficient, and adaptive AI systems.

</details>


### [106] [Hard Negative Sample-Augmented DPO Post-Training for Small Language Models](https://arxiv.org/abs/2512.19728)
*Haocheng Lu,Minjun Zhu,Henry Yu*

Main category: cs.LG

TL;DR: 提出一个轻量级后训练流程，使用小型数学验证器分析解题错误模式，通过加权DPO提升大语言模型的数学推理能力


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学推理上仍有困难，传统后训练方法将解题结果简化为二元判断（正确/错误），忽略了结构化错误模式。同时，基于人类反馈的强化学习方法成本高、难以扩展且不稳定。

Method: 1. 在MetaMathQA风格的思维链数据上进行监督微调；2. 引入紧凑的MathVerifier，将候选解分解为六维错误特征并聚合为可解释的错误程度和荒谬程度分数；3. 利用验证器信号挖掘近似正确但有结构缺陷的困难负样本，并定义每个样本的重要性权重；4. 通过验证器引导的加权公式将两者整合到离线直接偏好优化目标中。

Result: 在15亿参数的Qwen2.5模型上的实验表明，验证器引导的加权DPO比传统的监督微调和非加权DPO带来更有针对性的改进，特别是在解在数值上接近正确但逻辑不一致的问题上表现更好，同时避免了训练大型奖励模型或依赖外部评判的开销。

Conclusion: 提出的轻量级后训练流程能够有效识别和纠正数学推理中的结构化错误，在有限计算预算下实现更精准的模型改进，为提升大语言模型的数学推理能力提供了一种实用且可扩展的方法。

Abstract: Large language models (LLMs) continue to struggle with mathematical reasoning, and common post-training pipelines often reduce each generated solution to a binary outcome: correct or incorrect. This perspective is limiting in practice, as failures in chain-of-thought (CoT) reasoning are frequently structured; solutions may appear convincing while containing subtle logical, algebraic, or numerical flaws. Meanwhile, reinforcement learning from human feedback (RLHF) variants that rely on large reward models or LLM-as-a-judge signals are often expensive, difficult to scale, and unstable to iterate. We propose a lightweight and pragmatic post-training pipeline that targets such structured errors under realistic compute budgets. Starting from supervised fine-tuning (SFT) on MetaMathQA-style CoT data, we introduce a compact MathVerifier that decomposes a candidate solution into a six-dimensional error profile and aggregates it into interpretable wrongness and absurdity scores. These verifier signals serve two roles: (i) mining hard negatives that are near-correct yet structurally flawed, and (ii) defining per-sample importance weights that emphasize the most informative preference pairs. We integrate both into an offline Direct Preference Optimization (DPO) objective via a verifier-guided weighted formulation. Experiments on a 1.5B-parameter Qwen2.5 model show that verifier-guided, weighted DPO yields more targeted improvements than vanilla SFT and unweighted DPO, particularly on problems where solutions are numerically close to correct but logically inconsistent, while avoiding the overhead of training large reward models or relying on external judges.

</details>


### [107] [High-Performance Self-Supervised Learning by Joint Training of Flow Matching](https://arxiv.org/abs/2512.19729)
*Kosuke Ukita,Tsuyoshi Okita*

Main category: cs.LG

TL;DR: FlowFM是一种基于流匹配的基础模型，通过联合训练表示编码器和条件流匹配生成器，在可穿戴传感器数据上实现了高质量生成和有效识别，相比扩散模型训练时间减少50.4%，推理速度提升51倍。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在自监督学习中面临生成质量与判别性能的权衡问题，且迭代采样过程计算和能耗成本高，限制了工业和边缘AI应用。需要一种既能保持高质量生成又能高效进行表示学习的方法。

Method: 提出FlowFM模型，采用解耦设计联合训练表示编码器和条件流匹配生成器。使用流匹配学习更简单的速度场，加速和稳定训练过程，提高表示学习效率。

Result: 在可穿戴传感器数据上，FlowFM相比基于扩散的方法减少50.4%的训练时间。在下游任务中，FlowFM在五个数据集上均超越了最先进的SSL方法（SSL-Wearables），推理速度提升高达51倍，同时保持高生成质量。

Conclusion: FlowFM通过流匹配技术解决了扩散模型在自监督学习中的效率问题，实现了高质量生成和高效表示学习的平衡，为工业和边缘AI应用提供了可行的解决方案。

Abstract: Diffusion models can learn rich representations during data generation, showing potential for Self-Supervised Learning (SSL), but they face a trade-off between generative quality and discriminative performance. Their iterative sampling also incurs substantial computational and energy costs, hindering industrial and edge AI applications. To address these issues, we propose the Flow Matching-based Foundation Model (FlowFM), which jointly trains a representation encoder and a conditional flow matching generator. This decoupled design achieves both high-fidelity generation and effective recognition. By using flow matching to learn a simpler velocity field, FlowFM accelerates and stabilizes training, improving its efficiency for representation learning. Experiments on wearable sensor data show FlowFM reduces training time by 50.4\% compared to a diffusion-based approach. On downstream tasks, FlowFM surpassed the state-of-the-art SSL method (SSL-Wearables) on all five datasets while achieving up to a 51.0x inference speedup and maintaining high generative quality. The implementation code is available at https://github.com/Okita-Laboratory/jointOptimizationFlowMatching.

</details>


### [108] [Leakage-Aware Bandgap Prediction on the JARVIS-DFT Dataset: A Phase-Wise Feature Analysis](https://arxiv.org/abs/2512.19732)
*Gaurav Kumar Sharma*

Main category: cs.LG

TL;DR: 该研究对JARVIS-DFT带隙数据集进行系统分析，移除可能编码能带结构信息的描述符，创建了2280个材料的泄漏控制数据集，并建立三阶段建模框架评估描述符对预测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有带隙预测研究中，描述符可能无意中编码了能带结构信息（如有效质量），导致预测性能被高估。需要创建泄漏控制的数据集来评估描述符的真实预测能力。

Method: 1. 对JARVIS-DFT带隙数据集进行系统分析，识别并移除可能编码能带结构信息的描述符；2. 创建包含2280个材料的泄漏控制数据集；3. 实施三阶段建模框架：逐步加入基本物理描述符、工程特征和成分属性；4. 使用树模型进行预测，并通过SHAP分析识别重要特征。

Result: 1. 树模型在所有三个阶段都达到R²约0.88-0.90的预测精度；2. 扩展描述符空间在控制泄漏后并未显著改善预测准确性；3. SHAP分析一致显示介电张量分量是最重要的贡献特征。

Conclusion: 该研究提供了泄漏控制的带隙预测数据集和基准性能指标，表明在控制数据泄漏的情况下，扩展描述符空间对预测性能提升有限，介电张量分量是带隙预测的关键特征。

Abstract: In this study, we perform a systematic analysis of the JARVIS-DFT bandgap dataset and identify and remove descriptors that may inadvertently encode band-structure information, such as effective masses. This process yields a curated, leakage-controlled subset of 2280 materials. Using this dataset, a three-phase modeling framework is implemented that incrementally incorporates basic physical descriptors, engineered features, and compositional attributes. The results show that tree-based models achieve R2 values of approximately 0.88 to 0.90 across all phases, indicating that expanding the descriptor space does not substantially improve predictive accuracy when leakage is controlled. SHAP analysis consistently identifies the dielectric tensor components as the dominant contributors. This work provides a curated dataset and baseline performance metrics for future leakage-aware bandgap prediction studies.

</details>


### [109] [Case Prompting to Mitigate Large Language Model Bias for ICU Mortality Prediction](https://arxiv.org/abs/2512.19735)
*Gangxiong Zhang,Yongchao Long*

Main category: cs.LG

TL;DR: 提出CAP框架，通过训练无关的临床自适应提示方法，在ICU死亡率预测中同时提升LLM的公平性和预测性能。


<details>
  <summary>Details</summary>
Motivation: LLM在ICU死亡率预测中表现出人口统计学偏见（性别、年龄、种族），现有去偏方法往往降低预测性能，难以同时优化公平性和准确性。

Method: 开发多维度偏见评估方案，提出CAP（案例提示）框架，结合传统去偏提示和基于案例的推理，引导模型从类似历史误判案例中学习纠正偏见推理模式。

Result: 在MIMIC-IV数据集上，CAP将AUROC从0.806提升至0.873，AUPRC从0.497提升至0.694，同时将性别和种族相关差异减少90%以上，特征依赖分析显示跨人口群体注意力模式高度一致（相似度>0.98）。

Conclusion: LLM在ICU死亡率预测中存在可测量的偏见，精心设计的提示框架可以在不重新训练的情况下有效协同优化公平性和性能，为公平临床决策支持提供可转移的范式。

Abstract: Accurate mortality risk prediction for intensive care unit (ICU) patients is essential for clinical decision-making. Although large language models (LLMs) show promise in predicting outcomes from structured medical data, their predictions may exhibit demographic biases related to sex, age, and race, limiting their trustworthy use in clinical practice. Existing debiasing methods often reduce predictive performance, making it difficult to jointly optimize fairness and accuracy. In this study, we systematically examine bias in LLM-based ICU mortality prediction and propose a training-free, clinically adaptive prompting framework to simultaneously improve fairness and performance. We first develop a multi-dimensional bias assessment scheme for comprehensive model diagnosis. Building on this analysis, we introduce CAse Prompting (CAP), a novel prompting framework that integrates conventional debiasing prompts with case-based reasoning. CAP guides the model to learn from similar historical misprediction cases and their correct outcomes, enabling correction of biased reasoning patterns. Experiments on the MIMIC-IV dataset show that CAP substantially improves both predictive accuracy and fairness. CAP increases AUROC from 0.806 to 0.873 and AUPRC from 0.497 to 0.694, while reducing sex- and race-related disparities by over 90%. Feature reliance analysis further indicates highly consistent attention patterns across demographic groups, with similarity scores exceeding 0.98. These results demonstrate that LLMs exhibit measurable bias in ICU mortality prediction, and that a carefully designed prompting framework can effectively co-optimize fairness and performance without retraining, offering a transferable paradigm for equitable clinical decision support.

</details>


### [110] [OASI: Objective-Aware Surrogate Initialization for Multi-Objective Bayesian Optimization in TinyML Keyword Spotting](https://arxiv.org/abs/2512.19739)
*Soumen Garai,Suman Samui*

Main category: cs.LG

TL;DR: 提出OASI初始化策略，使用多目标模拟退火生成种子Pareto集，在TinyML关键词检测任务中优于传统初始化方法


<details>
  <summary>Details</summary>
Motivation: 在超低功耗TinyML设备上实现准确的关键词检测模型需要在精度和资源约束之间取得平衡。多目标贝叶斯优化是理想方法但高度依赖初始化，现有方法使用简单采样策略，既不针对Pareto前沿也没有严格的统计比较。

Method: 提出Objective-Aware Surrogate Initialization (OASI)初始化策略，利用Multi-Objective Simulated Annealing (MOSA)生成高性能且多样化的种子Pareto配置集，明确平衡精度和模型大小。

Result: 在TinyML关键词检测设置中，OASI优于LHS、Sobol和随机初始化，获得最高超体积(0.0627)和最低代际距离(0.0)，计算时间仅适度增加(1934秒 vs. ~1500秒)。非参数统计分析确认OASI具有更优的一致性。

Conclusion: OASI是一种有效的初始化策略，能够在TinyML关键词检测任务中生成高质量、多样化的初始配置，为多目标贝叶斯优化提供更好的起点。

Abstract: Voice assistants utilize Keyword Spotting (KWS) to enable efficient, privacy-friendly activation. However, realizing accurate KWS models on ultra-low-power TinyML devices (often with less than $<2$ MB of flash memory) necessitates a delicate balance between accuracy with strict resource constraints. Multi-objective Bayesian Optimization (MOBO) is an ideal candidate for managing such a trade-off but is highly initialization-dependent, especially under the budgeted black-box setting. Existing methods typically fall back to naive, ad-hoc sampling routines (e.g., Latin Hypercube Sampling (LHS), Sobol sequences, or Random search) that are adapted to neither the Pareto front nor undergo rigorous statistical comparison. To address this, we propose Objective-Aware Surrogate Initialization (OASI), a novel initialization strategy that leverages Multi-Objective Simulated Annealing (MOSA) to generate a seed Pareto set of high-performing and diverse configurations that explicitly balance accuracy and model size. Evaluated in a TinyML KWS setting, OASI outperforms LHS, Sobol, and Random initialization, achieving the highest hypervolume (0.0627) and the lowest generational distance (0.0) across multiple runs, with only a modest increase in computation time (1934 s vs. $\sim$1500 s). A non-parametric statistical analysis using the Kruskal-Wallis test ($H = 5.40$, $p = 0.144$, $η^2 = 0.0007$) and Dunn's post-hoc test confirms OASI's superior consistency despite the non-significant overall difference with respect to the $α=0.05$ threshold.

</details>


### [111] [Asia Cup 2025: A Structured T20 Match-Level Dataset and Exploratory Analysis for Cricket Analytics](https://arxiv.org/abs/2512.19740)
*Kousar Raza,Faizan Ali*

Main category: cs.LG

TL;DR: 本文创建了一个2025年亚洲杯T20板球锦标赛的全面数据集，包含19场比赛的61个变量，用于支持体育分析研究。


<details>
  <summary>Details</summary>
Motivation: 为促进板球运动的数据驱动研究和体育分析，需要提供结构化、全面的数据集来支持分析、预测建模和战略决策。

Method: 收集整理了2025年亚洲杯T20锦标赛所有19场比赛的数据，包含61个变量，涵盖球队得分、三柱门、强力击球统计、边界数、抛硬币决定、场地和球员亮点等。通过Zenodo平台以CC-BY 4.0许可公开发布数据集。

Result: 创建了一个包含19场比赛、61个变量的全面数据集，进行了探索性数据分析，重点关注球队表现指标、边界分布和得分模式。数据集已公开发布，支持板球分析研究的可重复性。

Conclusion: 这项工作为推进板球分析研究提供了一个开放、机器可读的基准数据集，支持数据驱动的板球研究、预测建模和战略决策制定。

Abstract: This paper presents a structured and comprehensive dataset corresponding to the 2025 Asia Cup T20 cricket tournament, designed to facilitate data-driven research in sports analytics. The dataset comprises records from all 19 matches of the tournament and includes 61 variables covering team scores, wickets, powerplay statistics, boundary counts, toss decisions, venues, and player-specific highlights. To demonstrate its analytical value, we conduct an exploratory data analysis focusing on team performance indicators, boundary distributions, and scoring patterns. The dataset is publicly released through Zenodo under a CC-BY 4.0 license to support reproducibility and further research in cricket analytics, predictive modeling, and strategic decision-making. This work contributes an open, machine-readable benchmark dataset for advancing cricket analytics research.

</details>


### [112] [EdgeFlex-Transformer: Transformer Inference for Edge Devices](https://arxiv.org/abs/2512.19741)
*Shoaib Mohammad,Guanqun Song,Ting Zhu*

Main category: cs.LG

TL;DR: 提出一个轻量级多阶段优化流程，用于压缩和加速Vision Transformers在边缘设备上的部署，通过激活分析、内存感知剪枝、混合精度执行和激活感知量化，在CIFAR-10上实现76%内存减少和6倍延迟降低。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署大规模Transformer模型面临内存、计算和延迟的严格约束，需要有效的压缩和加速方案。

Method: 结合激活分析、内存感知剪枝、选择性混合精度执行和激活感知量化(AWQ)，通过多阶段优化流程压缩Vision Transformers，无需昂贵的重新训练或任务特定微调。

Result: 从632M参数的ViT-Huge模型出发，在CIFAR-10上实现76%峰值内存使用减少和超过6倍延迟降低，同时保持甚至提高了相对于原始FP32基线的准确率。

Conclusion: 该框架为边缘平台上的高效Transformer推理提供了实用路径，并为集成动态稀疏性和MoE架构以进一步扩展性能开辟了未来方向。

Abstract: Deploying large-scale transformer models on edge devices presents significant challenges due to strict constraints on memory, compute, and latency. In this work, we propose a lightweight yet effective multi-stage optimization pipeline designed to compress and accelerate Vision Transformers (ViTs) for deployment in resource-constrained environments. Our methodology combines activation profiling, memory-aware pruning, selective mixed-precision execution, and activation-aware quantization (AWQ) to reduce the model's memory footprint without requiring costly retraining or task-specific fine-tuning. Starting from a ViT-Huge backbone with 632 million parameters, we first identify low-importance channels using activation statistics collected via forward hooks, followed by structured pruning to shrink the MLP layers under a target memory budget. We further apply FP16 conversion to selected components and leverage AWQ to quantize the remaining model weights and activations to INT8 with minimal accuracy degradation. Our experiments on CIFAR-10 demonstrate that the fully optimized model achieves a 76% reduction in peak memory usage and over 6x lower latency, while retaining or even improving accuracy compared to the original FP32 baseline. This framework offers a practical path toward efficient transformer inference on edge platforms, and opens future avenues for integrating dynamic sparsity and Mixture-of-Experts (MoE) architectures to further scale performance across diverse tasks.

</details>


### [113] [On-device Large Multi-modal Agent for Human Activity Recognition](https://arxiv.org/abs/2512.19742)
*Md Shakhrul Iman Siam,Ishtiaque Ahmed Showmik,Guanqun Song,Ting Zhu*

Main category: cs.LG

TL;DR: 提出一个用于人类活动识别的大规模多模态智能体，利用大语言模型提升分类性能和可解释性，同时具备推理和问答能力。


<details>
  <summary>Details</summary>
Motivation: 人类活动识别在医疗保健和智能环境中有广泛应用，但现有方法缺乏可解释性和人机交互能力。大语言模型的发展为HAR带来了新机遇，可以同时提升分类性能和用户体验。

Method: 设计了一个大规模多模态智能体框架，整合大语言模型的能力，不仅进行活动分类，还提供推理和问答功能，将技术输出转化为用户友好的见解。

Result: 在HHAR、Shoaib、Motionsense等广泛使用的HAR数据集上进行评估，模型达到了与最先进方法相当的高分类准确率，同时通过推理和问答能力显著提升了可解释性。

Conclusion: 该大规模多模态智能体框架成功地将大语言模型应用于人类活动识别，在保持高分类性能的同时，显著改善了系统的可解释性和用户参与度。

Abstract: Human Activity Recognition (HAR) has been an active area of research, with applications ranging from healthcare to smart environments. The recent advancements in Large Language Models (LLMs) have opened new possibilities to leverage their capabilities in HAR, enabling not just activity classification but also interpretability and human-like interaction. In this paper, we present a Large Multi-Modal Agent designed for HAR, which integrates the power of LLMs to enhance both performance and user engagement. The proposed framework not only delivers activity classification but also bridges the gap between technical outputs and user-friendly insights through its reasoning and question-answering capabilities. We conduct extensive evaluations using widely adopted HAR datasets, including HHAR, Shoaib, Motionsense to assess the performance of our framework. The results demonstrate that our model achieves high classification accuracy comparable to state-of-the-art methods while significantly improving interpretability through its reasoning and Q&A capabilities.

</details>


### [114] [From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning](https://arxiv.org/abs/2512.19743)
*Sasan Sharifipour,Constantino Álvarez Casado,Manuel Lage Cañellas,Miguel Bordallo López*

Main category: cs.LG

TL;DR: CUDA-APML：一种稀疏GPU实现的3D点云损失函数，通过阈值化可忽略的分配和自适应softmax，在保持梯度的情况下将峰值GPU内存减少99.9%


<details>
  <summary>Details</summary>
Motivation: 现有3D点云损失函数存在权衡：Chamfer距离计算高效但允许多对一对应关系，Earth Mover距离能更好反映一对一传输但计算成本高，APML通过可微Sinkhorn迭代近似传输但密集形式内存呈二次方增长

Method: 提出CUDA-APML稀疏GPU实现：1）阈值化可忽略的分配；2）在COO格式中直接运行自适应softmax、双向对称化和Sinkhorn归一化；3）保持存储支持上的梯度

Result: 在ShapeNet和MM-Fi数据集上，CUDA-APML在微小容差范围内匹配密集APML性能，同时将峰值GPU内存减少99.9%，实现接近线性的内存缩放

Conclusion: CUDA-APML通过稀疏GPU实现解决了APML内存二次方增长的问题，在保持几何保真度的同时大幅降低计算成本，为3D点云学习提供了高效实用的损失函数

Abstract: Loss functions are fundamental to learning accurate 3D point cloud models, yet common choices trade geometric fidelity for computational cost. Chamfer Distance is efficient but permits many-to-one correspondences, while Earth Mover Distance better reflects one-to-one transport at high computational cost. APML approximates transport with differentiable Sinkhorn iterations and an analytically derived temperature, but its dense formulation scales quadratically in memory. We present CUDA-APML, a sparse GPU implementation that thresholds negligible assignments and runs adaptive softmax, bidirectional symmetrization, and Sinkhorn normalization directly in COO form. This yields near-linear memory scaling and preserves gradients on the stored support, while pairwise distance evaluation remains quadratic in the current implementation. On ShapeNet and MM-Fi, CUDA-APML matches dense APML within a small tolerance while reducing peak GPU memory by 99.9%. Code available at: https://github.com/Multimodal-Sensing-Lab/apml

</details>


### [115] [A K-Means, Ward and DBSCAN repeatability study](https://arxiv.org/abs/2512.19772)
*Anthony Bertrand,Engelbert Mephu Nguifo,Violaine Antoine,David Hill*

Main category: cs.LG

TL;DR: 论文分析了K-Means、DBSCAN和Ward聚类算法的可重复性，发现K-Means在OpenMP线程数超过2时会产生不一致结果，旨在提高用户和开发者对这一问题的认识。


<details>
  <summary>Details</summary>
Motivation: 机器学习中的可重复性对于确保模型或实验得出相同科学结论至关重要，特定算法的可重复性（比特级相同结果）对科学完整性也很关键，因为它允许调试。

Method: 将K-Means、DBSCAN和Ward聚类算法分解为基本步骤，识别每个阶段实现可重复性所需的条件，使用scikit-learn库进行实现示例来检查每种方法的可重复性方面。

Result: 发现K-Means在OpenMP线程数超过2时会产生不一致的结果，而DBSCAN和Ward算法在不同条件下表现出不同的可重复性特征。

Conclusion: 这项工作旨在提高用户和开发者对聚类算法可重复性问题的认识，鼓励进一步调查和潜在修复，特别是针对K-Means在多线程环境下的不一致性问题。

Abstract: Reproducibility is essential in machine learning because it ensures that a model or experiment yields the same scientific conclusion. For specific algorithms repeatability with bitwise identical results is also a key for scientific integrity because it allows debugging. We decomposed several very popular clustering algorithms: K-Means, DBSCAN and Ward into their fundamental steps, and we identify the conditions required to achieve repeatability at each stage. We use an implementation example with the Python library scikit-learn to examine the repeatable aspects of each method. Our results reveal inconsistent results with K-Means when the number of OpenMP threads exceeds two. This work aims to raise awareness of this issue among both users and developers, encouraging further investigation and potential fixes.

</details>


### [116] [Guardrailed Uplift Targeting: A Causal Optimization Playbook for Marketing Strategy](https://arxiv.org/abs/2512.19805)
*Deepit Sapru*

Main category: cs.LG

TL;DR: 本文提出了一个营销决策框架，将异质处理效应转化为约束性目标策略，在遵守业务护栏的同时最大化收入和留存率。


<details>
  <summary>Details</summary>
Motivation: 传统营销策略往往缺乏对异质处理效应的考虑，且难以在最大化业务指标的同时遵守预算、客户体验等业务约束。需要一种能够将因果推断与约束优化相结合的框架。

Method: 使用提升学习器估计条件平均处理效应(CATE)，然后通过约束分配优化决定目标人群和优惠策略，在预算、销售下降容忍度等限制条件下进行决策。

Result: 在留存消息、活动奖励和消费阈值分配等应用中，该框架在离线评估中持续优于倾向性评分和静态基线方法。在线A/B测试进一步验证了其在提升收入和完成率方面的战略效果，同时保持了客户体验约束。

Conclusion: 该框架为营销人员提供了一个可重复使用的操作手册，能够在规模化运营中实施因果目标定位，设置业务护栏，并使营销活动与战略关键绩效指标保持一致。

Abstract: This paper introduces a marketing decision framework that converts heterogeneous-treatment uplift into constrained targeting strategies to maximize revenue and retention while honoring business guardrails. The approach estimates Conditional Average Treatment Effects (CATE) with uplift learners and then solves a constrained allocation to decide who to target and which offer to deploy under limits such as budget or acceptable sales deterioration. Applied to retention messaging, event rewards, and spend-threshold assignment, the framework consistently outperforms propensity and static baselines in offline evaluations using uplift AUC, Inverse Propensity Scoring (IPS), and Self-Normalized IPS (SNIPS). A production-scale online A/B test further validates strategic lift on revenue and completion while preserving customer-experience constraints. The result is a reusable playbook for marketers to operationalize causal targeting at scale, set guardrails, and align campaigns with strategic KPIs.

</details>


### [117] [Fine-Tuned In-Context Learners for Efficient Adaptation](https://arxiv.org/abs/2512.19879)
*Jorg Bornschein,Clare Lyle,Yazhe Li,Amal Rannen-Triki,Xu Owen He,Razvan Pascanu*

Main category: cs.LG

TL;DR: 本文提出了一种将上下文学习与微调相结合的统一方法，通过在微调数据中加入上下文示例，结合了上下文学习的样本效率和微调的性能优势。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型适应下游任务的方法主要有两种：提示工程（上下文学习）和微调。提示工程在少样本场景表现好但数据增多时效果会饱和，而微调在数据充足时效果好但在少样本时可能表现不佳。需要一种能结合两者优势的方法。

Method: 提出统一方法：在微调过程中直接融入上下文学习，将任务特定数据与上下文示例结合进行微调，模拟k-shot提示的结构。同时提出使用prequential评估进行超参数选择，避免昂贵的交叉验证。

Result: 该方法在多个下游任务上进行了广泛的实证研究，结果显示该方法不仅匹配而且经常显著超过单独的微调或上下文学习基线方法。

Conclusion: 提出的统一方法成功结合了上下文学习的样本效率和微调的性能优势，为LLM适应下游任务提供了一种更有效的范式，特别是在数据有限的情况下。

Abstract: When adapting large language models (LLMs) to a specific downstream task, two primary approaches are commonly employed: (1) prompt engineering, often with in-context few-shot learning, leveraging the model's inherent generalization abilities, and (2) fine-tuning on task-specific data, directly optimizing the model's parameters. While prompt-based methods excel in few-shot scenarios, their effectiveness often plateaus as more data becomes available. Conversely, fine-tuning scales well with data but may underperform when training examples are scarce. We investigate a unified approach that bridges these two paradigms by incorporating in-context learning directly into the fine-tuning process. Specifically, we fine-tune the model on task-specific data augmented with in-context examples, mimicking the structure of k-shot prompts. This approach, while requiring per-task fine-tuning, combines the sample efficiency of in-context learning with the performance gains of fine-tuning, leading to a method that consistently matches and often significantly exceeds both these baselines. To perform hyperparameter selection in the low-data regime, we propose to use prequential evaluation, which eliminates the need for expensive cross-validation and leverages all available data for training while simultaneously providing a robust validation signal. We conduct an extensive empirical study to determine which adaptation paradigm - fine-tuning, in-context learning, or our proposed unified approach offers the best predictive performance on a concrete data downstream-tasks.

</details>


### [118] [Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling](https://arxiv.org/abs/2512.19905)
*Indranil Halder,Cengiz Pehlevan*

Main category: cs.LG

TL;DR: 该论文研究了大型语言模型推理时间扩展的理论基础，通过贝叶斯线性回归模型分析推理时间采样对泛化误差的影响，发现适当奖励下增加推理样本可降低误差，但奖励失配时存在最优采样数量限制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展将计算资源从训练时间重新分配到推理时间，但推理时间扩展的原理尚不明确。本文旨在建立可分析的推理时间扩展模型，理解推理时间采样如何影响模型性能。

Method: 提出贝叶斯线性回归与奖励加权采样器的分析模型，在高维状态下研究后验预测均值和方差。分析训练数据来自教师模型时的泛化误差，通过softmax温度选择推理样本，研究不同奖励条件下的误差变化。

Result: 当奖励与教师模型差异不大时，泛化误差随推理样本数k增加单调下降；但奖励失配时存在最优k值，超过后更多采样反而增加误差。固定k时存在最优采样温度。实验验证了这些结论，并证明在"best-of-k"极限下泛化误差以Θ(1/k²)衰减。

Conclusion: 推理时间计算扩展在某些条件下优于收集更多数据，但任务难度增加时这种优势会减弱。研究为推理时间扩展提供了理论框架，并确定了推理计算扩展的有效边界。

Abstract: Recent developments in large language models have shown advantages in reallocating a notable share of computational resource from training time to inference time. However, the principles behind inference time scaling are not well understood. In this paper, we introduce an analytically tractable model of inference-time scaling: Bayesian linear regression with a reward-weighted sampler, where the reward is determined from a linear model, modeling LLM-as-a-judge scenario. We study this problem in the high-dimensional regime, where the deterministic equivalents dictate a closed-form expression for the posterior predictive mean and variance. We analyze the generalization error when training data are sampled from a teacher model. We draw $k$ inference-time samples and select via softmax at a temperature applied to a quadratic reward. When the reward is not too different from the teacher, the generalization error decreases monotonically with increasing inference time samples $k$. However, the specific reward that optimizes inference-time selection generally differs from the teacher. In contrast, substantial reward misspecification induces a finite optimal $k$ beyond which more sampling can increase the generalization error. For fixed $k$, there exists an optimal sampling temperature. We experimentally verify these facts in large language model inference with an additional large language model as a judge. In the "best-of-$k$" limit with the teacher as reward, we theoretically show that the generalization error decays as $Θ(1/k^2)$ and determine the leading coefficient via extreme value theory. These formulas delineate domains where scaling inference-time computation is provably preferable to collecting more data. Finally, we demonstrate that when task difficulty increases, the previously mentioned advantage of inference-time compute degrades.

</details>


### [119] [Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra](https://arxiv.org/abs/2512.19909)
*Maxime Lacour,Pu Ren,Rie Nakata,Nori Nakata,Michael Mahoney*

Main category: cs.LG

TL;DR: 提出CGM-FAS深度学习方法替代传统GP方法，用于非遍历性地震动模型中的路径效应建模，实现高效多频率大空间域预测。


<details>
  <summary>Details</summary>
Motivation: 当前非遍历性地震动模型依赖高斯过程方法，存在计算限制，难以进行大规模预测，需要更高效的方法来建模非遍历性路径效应。

Method: 使用条件变分自编码器架构，以地震和台站的地理坐标为条件变量，直接从数据中学习空间模式和频率间相关性。

Result: CGM-FAS与GP方法预测结果一致，但具有无需预设相关函数、能捕捉频率间相关性、计算高效等优势，可在10秒内生成10,000个站点在1,000个频率上的地图。

Conclusion: CGM-FAS为非遍历性地震动预测提供了有前景的高效方法，适用于多频率和大空间域场景。

Abstract: Recent developments in non-ergodic ground-motion models (GMMs) explicitly model systematic spatial variations in source, site, and path effects, reducing standard deviation to 30-40% of ergodic models and enabling more accurate site-specific seismic hazard analysis. Current non-ergodic GMMs rely on Gaussian Process (GP) methods with prescribed correlation functions and thus have computational limitations for large-scale predictions. This study proposes a deep-learning approach called Conditional Generative Modeling for Fourier Amplitude Spectra (CGM-FAS) as an alternative to GP-based methods for modeling non-ergodic path effects in Fourier Amplitude Spectra (FAS). CGM-FAS uses a Conditional Variational Autoencoder architecture to learn spatial patterns and interfrequency correlation directly from data by using geographical coordinates of earthquakes and stations as conditional variables. Using San Francisco Bay Area earthquake data, we compare CGM-FAS against a recent GP-based GMM for the region and demonstrate consistent predictions of non-ergodic path effects. Additionally, CGM-FAS offers advantages compared to GP-based approaches in learning spatial patterns without prescribed correlation functions, capturing interfrequency correlations, and enabling rapid predictions, generating maps for 10,000 sites across 1,000 frequencies within 10 seconds using a few GB of memory. CGM-FAS hyperparameters can be tuned to ensure generated path effects exhibit variability consistent with the GP-based empirical GMM. This work demonstrates a promising direction for efficient non-ergodic ground-motion prediction across multiple frequencies and large spatial domains.

</details>


### [120] [Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning](https://arxiv.org/abs/2512.19920)
*Jiayun Wu,Jiashuo Liu,Zhiyuan Zeng,Tianyang Zhan,Wenhao Huang*

Main category: cs.LG

TL;DR: 该论文研究了通过行为校准减少LLM幻觉的方法，通过训练模型在不确定时主动弃权，使小模型在不确定性量化方面超越前沿大模型。


<details>
  <summary>Details</summary>
Motivation: LLM在关键领域部署受到幻觉问题的阻碍，现有训练目标优先模仿数据分布而非追求认知诚实，标准强化学习范式鼓励模型猜测而非诚实沟通。

Method: 提出行为校准方法，通过训练干预优化严格适当评分规则，使模型输出校准后的正确概率，能够在不确定时弃权或标记不确定声明。

Result: 使用Qwen3-4B-Instruct的实验显示，行为校准的小模型在不确定性量化方面超越前沿模型，在数学推理任务中Accuracy-to-Hallucination Ratio增益(0.806)超过GPT-5(0.207)，在事实QA中校准误差与前沿模型相当。

Conclusion: 行为校准强化学习使小模型在不确定性量化方面超越前沿大模型，这种可转移的元技能与原始预测准确性解耦，为减少LLM幻觉提供了有效方法。

Abstract: LLM deployment in critical domains is currently impeded by persistent hallucinations--generating plausible but factually incorrect assertions. While scaling laws drove significant improvements in general capabilities, theoretical frameworks suggest hallucination is not merely stochastic error but a predictable statistical consequence of training objectives prioritizing mimicking data distribution over epistemic honesty. Standard RLVR paradigms, utilizing binary reward signals, inadvertently incentivize models as good test-takers rather than honest communicators, encouraging guessing whenever correctness probability exceeds zero. This paper presents an exhaustive investigation into behavioral calibration, which incentivizes models to stochastically admit uncertainty by abstaining when not confident, aligning model behavior with accuracy. Synthesizing recent advances, we propose and evaluate training interventions optimizing strictly proper scoring rules for models to output a calibrated probability of correctness. Our methods enable models to either abstain from producing a complete response or flag individual claims where uncertainty remains. Utilizing Qwen3-4B-Instruct, empirical analysis reveals behavior-calibrated reinforcement learning allows smaller models to surpass frontier models in uncertainty quantification--a transferable meta-skill decouplable from raw predictive accuracy. Trained on math reasoning tasks, our model's log-scale Accuracy-to-Hallucination Ratio gain (0.806) exceeds GPT-5's (0.207) in a challenging in-domain evaluation (BeyondAIME). Moreover, in cross-domain factual QA (SimpleQA), our 4B LLM achieves zero-shot calibration error on par with frontier models including Grok-4 and Gemini-2.5-Pro, even though its factual accuracy is much lower.

</details>


### [121] [The Seismic Wavefield Common Task Framework](https://arxiv.org/abs/2512.19927)
*Alexey Yermakov,Yue Zhao,Marine Denolle,Yiyu Ni,Philippe M. Wyder,Judah Goldfeder,Stefano Riva,Jan Williams,David Zoro,Amy Sara Rude,Matteo Tomasetto,Joe Germany,Joseph Bakarji,Georg Maierhofer,Miles Cranmer,J. Nathan Kutz*

Main category: cs.LG

TL;DR: 论文提出了地震学机器学习研究的通用任务框架（CTF），旨在解决当前研究中缺乏标准化评估、公平比较和严格验证的问题，通过三个不同尺度的波场数据集和特定任务指标来规范算法评估。


<details>
  <summary>Details</summary>
Motivation: 地震学在状态预测和重建（如地震早期预警和地面运动预测）以及管理参数变异性方面面临根本挑战。现有模拟方法受限于大规模计算复杂度，而实际数据方法则受限于模型对地球复杂性的反映不足和稀疏传感器测量。机器学习方法虽有前景，但缺乏适当的表征、公平报告和严格比较。

Method: 引入地震波场机器学习的通用任务框架（CTF），包含三个不同尺度的波场数据集（全球、地壳和局部），以及针对预测、重建和泛化能力的特定任务指标。该框架受自然语言处理等领域CTF的启发，提供结构化和严格的基础用于算法头对头评估。

Result: 展示了在两个数据集上的评估过程，报告了各种方法和基础模型在从模拟和真实世界传感器测量重建地震波场方面的性能得分。CTF得分揭示了不同方法在特定问题类别中的优势、局限性和适用性。

Conclusion: 该框架旨在用标准化评估取代临时比较，通过隐藏测试集提高科学机器学习的严谨性和可重复性，为地震学机器学习研究建立更严格的基础。

Abstract: Seismology faces fundamental challenges in state forecasting and reconstruction (e.g., earthquake early warning and ground motion prediction) and managing the parametric variability of source locations, mechanisms, and Earth models (e.g., subsurface structure and topography effects). Addressing these with simulations is hindered by their massive scale, both in synthetic data volumes and numerical complexity, while real-data efforts are constrained by models that inadequately reflect the Earth's complexity and by sparse sensor measurements from the field. Recent machine learning (ML) efforts offer promise, but progress is obscured by a lack of proper characterization, fair reporting, and rigorous comparisons. To address this, we introduce a Common Task Framework (CTF) for ML for seismic wavefields, starting with three distinct wavefield datasets. Our CTF features a curated set of datasets at various scales (global, crustal, and local) and task-specific metrics spanning forecasting, reconstruction, and generalization under realistic constraints such as noise and limited data. Inspired by CTFs in fields like natural language processing, this framework provides a structured and rigorous foundation for head-to-head algorithm evaluation. We illustrate the evaluation procedure with scores reported for two of the datasets, showcasing the performance of various methods and foundation models for reconstructing seismic wavefields from both simulated and real-world sensor measurements. The CTF scores reveal the strengths, limitations, and suitability for specific problem classes. Our vision is to replace ad hoc comparisons with standardized evaluations on hidden test sets, raising the bar for rigor and reproducibility in scientific ML.

</details>


### [122] [LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models](https://arxiv.org/abs/2512.20002)
*Jiacheng You,Jingcheng Yang,Yuhang Xie,Zhongxuan Wu,Xiucheng Li,Feng Li,Pengjie Wang,Jian Xu,Bo Zheng,Xinyang Chen*

Main category: cs.LG

TL;DR: LoFT-LLM是一个结合低频学习和大语言模型的时间序列预测框架，通过提取低频趋势、建模高频残差，并利用LLM整合辅助信息，在金融和能源数据集上取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度预测模型通常使用完整时间窗口进行监督，其中包含大量高频噪声，会掩盖长期趋势。同时，包含丰富领域特定信息的辅助变量在少样本设置下往往未被充分利用。

Method: 提出LoFT-LLM框架：1) 补丁低频预测模块(PLFM)从局部频谱补丁中提取稳定的低频趋势；2) 残差学习器建模高频变化；3) 微调的LLM通过结构化自然语言提示整合辅助上下文和领域知识来优化预测。

Result: 在金融和能源数据集上的大量实验表明，LoFT-LLM在全数据和少样本情况下都显著优于强基线模型，提供了优越的准确性、鲁棒性和可解释性。

Conclusion: LoFT-LLM通过频率感知的预测流程，有效解决了时间序列预测中的噪声干扰和辅助信息利用不足的问题，特别是在少样本场景下表现出色。

Abstract: Time-series forecasting in real-world applications such as finance and energy often faces challenges due to limited training data and complex, noisy temporal dynamics. Existing deep forecasting models typically supervise predictions using full-length temporal windows, which include substantial high-frequency noise and obscure long-term trends. Moreover, auxiliary variables containing rich domain-specific information are often underutilized, especially in few-shot settings. To address these challenges, we propose LoFT-LLM, a frequency-aware forecasting pipeline that integrates low-frequency learning with semantic calibration via a large language model (LLM). Firstly, a Patch Low-Frequency forecasting Module (PLFM) extracts stable low-frequency trends from localized spectral patches. Secondly, a residual learner then models high-frequency variations. Finally, a fine-tuned LLM refines the predictions by incorporating auxiliary context and domain knowledge through structured natural language prompts. Extensive experiments on financial and energy datasets demonstrate that LoFT-LLM significantly outperforms strong baselines under both full-data and few-shot regimes, delivering superior accuracy, robustness, and interpretability.

</details>


### [123] [Control Variate Score Matching for Diffusion Models](https://arxiv.org/abs/2512.20003)
*Khaled Kahouli,Romuald Elie,Klaus-Robert Müller,Quentin Berthet,Oliver T. Unke,Arnaud Doucet*

Main category: cs.LG

TL;DR: 提出Control Variate Score Identity (CVSI)，通过控制变量法统一DSI和TSI两种分数估计器，实现全噪声谱方差最小化


<details>
  <summary>Details</summary>
Motivation: 扩散模型需要准确估计噪声扰动目标分布的分数。DSI依赖数据样本，TSI利用目标能量函数，但两者存在方差权衡：DSI在低噪声区域方差高，TSI在高噪声区域方差高。需要一种在全噪声谱上都能保持低方差的分数估计器。

Method: 在控制变量法框架下统一DSI和TSI，提出CVSI（Control Variate Score Identity），推导出最优的时间依赖控制系数，理论上保证在整个噪声谱上的方差最小化。

Result: CVSI作为稳健的低方差插件估计器，显著提高了无数据采样器学习和推理时扩散采样的样本效率。

Conclusion: 通过控制变量法统一DSI和TSI的CVSI方法，解决了两种传统分数估计器的方差权衡问题，为扩散模型提供了全噪声谱上的低方差分数估计解决方案。

Abstract: Diffusion models offer a robust framework for sampling from unnormalized probability densities, which requires accurately estimating the score of the noise-perturbed target distribution. While the standard Denoising Score Identity (DSI) relies on data samples, access to the target energy function enables an alternative formulation via the Target Score Identity (TSI). However, these estimators face a fundamental variance trade-off: DSI exhibits high variance in low-noise regimes, whereas TSI suffers from high variance at high noise levels. In this work, we reconcile these approaches by unifying both estimators within the principled framework of control variates. We introduce the Control Variate Score Identity (CVSI), deriving an optimal, time-dependent control coefficient that theoretically guarantees variance minimization across the entire noise spectrum. We demonstrate that CVSI serves as a robust, low-variance plug-in estimator that significantly enhances sample efficiency in both data-free sampler learning and inference-time diffusion sampling.

</details>


### [124] [Orthogonal Activation with Implicit Group-Aware Bias Learning for Class Imbalance](https://arxiv.org/abs/2512.20006)
*Sukumar Kishanthan,Asela Hevapathige*

Main category: cs.LG

TL;DR: 提出名为OGAB的新型激活函数，通过正交性和组感知偏置学习缓解深度学习中的类别不平衡问题，无需显式标签信息即可增强特征可区分性。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是机器学习和数据挖掘中的常见挑战，会导致分类器性能下降。虽然深度学习在特征提取方面表现出色，但在不平衡数据下性能仍然会恶化。现有方法通常通过预处理数据修改或后处理校正来解决类别不平衡，而本文希望在训练阶段嵌入学习层面直接解决这一问题。

Method: 提出OGAB激活函数，结合正交变换和组感知偏置学习机制。正交变换通过保持特征独立性来保护少数类信息，防止多数类在嵌入空间中的主导地位。组感知偏置机制自动识别数据聚类并调整嵌入以增强类别可分性，无需显式监督。

Result: 在真实世界和合成不平衡数据集上验证了OGAB的有效性，相比传统和可学习激活函数都取得了持续的性能改进。表明激活函数可以引入强大的归纳偏置来解决复杂数据挑战，超越传统的非线性功能。

Conclusion: OGAB激活函数通过在训练阶段嵌入学习层面解决类别不平衡问题，提供了一种无需显式标签信息即可增强特征可区分性的有效方法。正交变换保护少数类信息，组感知偏置机制自动增强类别可分性，为深度学习在不平衡数据场景下的应用提供了新思路。

Abstract: Class imbalance is a common challenge in machine learning and data mining, often leading to suboptimal performance in classifiers. While deep learning excels in feature extraction, its performance still deteriorates under imbalanced data. In this work, we propose a novel activation function, named OGAB, designed to alleviate class imbalance in deep learning classifiers. OGAB incorporates orthogonality and group-aware bias learning to enhance feature distinguishability in imbalanced scenarios without explicitly requiring label information. Our key insight is that activation functions can be used to introduce strong inductive biases that can address complex data challenges beyond traditional non-linearity. Our work demonstrates that orthogonal transformations can preserve information about minority classes by maintaining feature independence, thereby preventing the dominance of majority classes in the embedding space. Further, the proposed group-aware bias mechanism automatically identifies data clusters and adjusts embeddings to enhance class separability without the need for explicit supervision. Unlike existing approaches that address class imbalance through preprocessing data modifications or post-processing corrections, our proposed approach tackles class imbalance during the training phase at the embedding learning level, enabling direct integration with the learning process. We demonstrate the effectiveness of our solution on both real-world and synthetic imbalanced datasets, showing consistent performance improvements over both traditional and learnable activation functions.

</details>


### [125] [An Optimal Policy for Learning Controllable Dynamics by Exploration](https://arxiv.org/abs/2512.20053)
*Peter N. Loxley*

Main category: cs.LG

TL;DR: 本文提出了一种用于在未知环境中学习可控马尔可夫链的最优探索策略，该策略通过有限时间范围内的贪婪信息增益最大化来实现"边探索边学习"。


<details>
  <summary>Details</summary>
Motivation: 可控马尔可夫链是顺序决策任务的核心，但在未知环境中如何最优地探索以学习系统动态是一个关键问题。现有方法可能无法处理某些特殊状态类型（如瞬态、吸收态、非回溯状态）对探索的限制。

Method: 提出了一个简单易实现、计算高效的最优探索策略，通过随时间变化的约束集选择控制动作来贪婪地最大化信息增益。给出了控制集的简单参数化方法，并提供了寻找最优策略的算法。

Result: 证明了该策略的最优性，展示了为什么存在瞬态、吸收态和非回溯状态时，非平稳策略对于实现最优探索是必要的。通过六个可控动态的详细示例验证了策略的有效性。

Conclusion: 该研究为在未知环境中学习可控动态提供了一种理论上有保证的最优探索策略，解决了特殊状态类型对探索的限制问题，为最优控制和强化学习中的探索策略设计提供了新思路。

Abstract: Controllable Markov chains describe the dynamics of sequential decision making tasks and are the central component in optimal control and reinforcement learning. In this work, we give the general form of an optimal policy for learning controllable dynamics in an unknown environment by exploring over a limited time horizon. This policy is simple to implement and efficient to compute, and allows an agent to ``learn by exploring" as it maximizes its information gain in a greedy fashion by selecting controls from a constraint set that changes over time during exploration. We give a simple parameterization for the set of controls, and present an algorithm for finding an optimal policy. The reason for this policy is due to the existence of certain types of states that restrict control of the dynamics; such as transient states, absorbing states, and non-backtracking states. We show why the occurrence of these states makes a non-stationary policy essential for achieving optimal exploration. Six interesting examples of controllable dynamics are treated in detail. Policy optimality is demonstrated using counting arguments, comparing with suboptimal policies, and by making use of a sequential improvement property from dynamic programming.

</details>


### [126] [PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models](https://arxiv.org/abs/2512.20063)
*Mingue Park,Jisung Hwang,Seungwoo Yoo,Kyeongmin Yeo,Minhyuk Sung*

Main category: cs.LG

TL;DR: PairFlow是一种轻量级预处理方法，用于训练离散流模型，实现少步采样而无需预训练教师模型，计算成本仅为完整训练的1.7%


<details>
  <summary>Details</summary>
Motivation: 离散流模型在离散数据生成方面表现优异，但迭代采样速度慢。现有加速方法依赖微调，带来大量额外训练开销，需要更高效的加速方案

Method: 提出PairFlow预处理步骤，基于离散流模型的闭式反演，从源分布和目标分布的耦合样本中训练模型，无需预训练教师模型

Result: PairFlow仅需完整训练1.7%的计算成本，性能匹配甚至超越两阶段微调方法，并为后续蒸馏提供更强基础模型，在分子数据、二值和RGB图像上验证有效

Conclusion: PairFlow是一种高效、通用的离散流模型加速方法，通过轻量级预处理实现少步采样，为离散数据生成提供了实用的解决方案

Abstract: We introduce $\texttt{PairFlow}$, a lightweight preprocessing step for training Discrete Flow Models (DFMs) to achieve few-step sampling without requiring a pretrained teacher. DFMs have recently emerged as a new class of generative models for discrete data, offering strong performance. However, they suffer from slow sampling due to their iterative nature. Existing acceleration methods largely depend on finetuning, which introduces substantial additional training overhead. $\texttt{PairFlow}$ addresses this issue with a lightweight preprocessing step. Inspired by ReFlow and its extension to DFMs, we train DFMs from coupled samples of source and target distributions, without requiring any pretrained teacher. At the core of our approach is a closed-form inversion for DFMs, which allows efficient construction of paired source-target samples. Despite its extremely low cost, taking only up to 1.7% of the compute needed for full model training, $\texttt{PairFlow}$ matches or even surpasses the performance of two-stage training involving finetuning. Furthermore, models trained with our framework provide stronger base models for subsequent distillation, yielding further acceleration after finetuning. Experiments on molecular data as well as binary and RGB images demonstrate the broad applicability and effectiveness of our approach.

</details>


### [127] [Information-directed sampling for bandits: a primer](https://arxiv.org/abs/2512.20096)
*Annika Hirling,Giorgio Nicoletti,Antonio Celani*

Main category: cs.LG

TL;DR: 该论文在双状态伯努利多臂老虎机环境中研究信息导向采样策略，通过引入修改的信息度量和调优参数，在对称老虎机和单公平硬币场景中分析其遗憾性能。


<details>
  <summary>Details</summary>
Motivation: 研究多臂老虎机问题中探索与利用的权衡，为统计物理学家群体搭建强化学习与信息理论之间的桥梁，提供一个教学性的综合框架。

Method: 扩展信息导向采样框架到折扣无限时域设置，引入修改的信息度量和调优参数来调节决策行为，专注于双状态伯努利老虎机这一可处理的最小模型。

Result: 在对称老虎机情况下，IDS实现有界累积遗憾；在单公平硬币场景中，IDS策略产生的遗憾随时域对数增长，与经典渐近下界一致。

Conclusion: 这项工作作为教学性综合研究，成功将强化学习和信息理论概念联系起来，为统计物理学家提供了理解多臂老虎机中探索-利用权衡的框架。

Abstract: The Multi-Armed Bandit problem provides a fundamental framework for analyzing the tension between exploration and exploitation in sequential learning. This paper explores Information Directed Sampling (IDS) policies, a class of heuristics that balance immediate regret against information gain. We focus on the tractable environment of two-state Bernoulli bandits as a minimal model to rigorously compare heuristic strategies against the optimal policy. We extend the IDS framework to the discounted infinite-horizon setting by introducing a modified information measure and a tuning parameter to modulate the decision-making behavior. We examine two specific problem classes: symmetric bandits and the scenario involving one fair coin. In the symmetric case we show that IDS achieves bounded cumulative regret, whereas in the one-fair-coin scenario the IDS policy yields a regret that scales logarithmically with the horizon, in agreement with classical asymptotic lower bounds. This work serves as a pedagogical synthesis, aiming to bridge concepts from reinforcement learning and information theory for an audience of statistical physicists.

</details>


### [128] [Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering](https://arxiv.org/abs/2512.20115)
*Yuanhao Chen,Qi Liu,Pengbin Chen,Zhongjian Qiao,Yanjie Li*

Main category: cs.LG

TL;DR: 本文提出了一种用于策略约束离线强化学习的简单高效样本过滤方法，通过筛选高质量样本来提升学习效率和最终性能。


<details>
  <summary>Details</summary>
Motivation: 现有策略约束离线强化学习方法存在一个问题：如果数据集中包含大量低奖励的转移样本，学习策略会被次优参考策略所限制，导致学习速度慢、样本效率低和性能不佳。因此需要改进现有的采样方法。

Method: 提出一种样本过滤方法：1）通过平均奖励和平均折扣奖励评估数据集中转移样本的得分；2）提取高得分的转移样本；3）使用这些高质量样本训练离线强化学习算法。

Result: 在一系列离线强化学习算法和基准任务上的实验结果表明，所提出的方法优于基线方法。

Conclusion: 通过简单的样本过滤机制，可以有效提升策略约束离线强化学习的样本效率和最终性能，解决了现有方法对低质量样本敏感的问题。

Abstract: Offline reinforcement learning (RL) aims to learn a policy that maximizes the expected return using a given static dataset of transitions. However, offline RL faces the distribution shift problem. The policy constraint offline RL method is proposed to solve the distribution shift problem. During the policy constraint offline RL training, it is important to ensure the difference between the learned policy and behavior policy within a given threshold. Thus, the learned policy heavily relies on the quality of the behavior policy. However, a problem exists in existing policy constraint methods: if the dataset contains many low-reward transitions, the learned will be contained with a suboptimal reference policy, leading to slow learning speed, low sample efficiency, and inferior performances. This paper shows that the sampling method in policy constraint offline RL that uses all the transitions in the dataset can be improved. A simple but efficient sample filtering method is proposed to improve the sample efficiency and the final performance. First, we evaluate the score of the transitions by average reward and average discounted reward of episodes in the dataset and extract the transition samples of high scores. Second, the high-score transition samples are used to train the offline RL algorithms. We verify the proposed method in a series of offline RL algorithms and benchmark tasks. Experimental results show that the proposed method outperforms baselines.

</details>


### [129] [Learning to Reason in LLMs by Expectation Maximization](https://arxiv.org/abs/2512.20169)
*Junghyun Lee,Branislav Kveton,Sunav Choudhary,Subhojyoti Mukherjee,Anup Rao,Ryan A. Rossi,Alexa Siu*

Main category: cs.LG

TL;DR: 该论文提出将推理建模为隐变量模型，使用EM算法优化推理学习，比较了多种采样方案，发现简单的提示后验采样(PPS)性能最佳


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过先生成推理过程再给出答案的方式解决问题，但如何有效学习推理能力仍是一个挑战。研究者希望形式化推理过程并找到更有效的优化方法

Method: 将推理形式化为隐变量模型，推导出EM优化目标，比较了三种采样方案：带预算的拒绝采样、自教推理器(STaR)和提示后验采样(PPS)。PPS只保留STaR的合理化阶段

Result: 在ARC、MMLU和OpenBookQA数据集上使用Llama和Qwen模型的实验表明，采样方案显著影响学习推理模型的准确性。尽管简单，PPS在性能上优于其他采样方案

Conclusion: 将推理建模为隐变量模型并应用EM优化是有效的，采样方案设计是推理学习的关键挑战，简单的提示后验采样(PPS)表现最佳，为推理学习提供了新的优化视角

Abstract: Large language models (LLMs) solve reasoning problems by first generating a rationale and then answering. We formalize reasoning as a latent variable model and derive an expectation-maximization (EM) objective for learning to reason. This view connects EM and modern reward-based optimization, and shows that the main challenge lies in designing a sampling distribution that generates rationales that justify correct answers. We instantiate and compare several sampling schemes: rejection sampling with a budget, self-taught reasoner (STaR), and prompt posterior sampling (PPS), which only keeps the rationalization stage of STaR. Our experiments on the ARC, MMLU, and OpenBookQA datasets with the Llama and Qwen models show that the sampling scheme can significantly affect the accuracy of learned reasoning models. Despite its simplicity, we observe that PPS outperforms the other sampling schemes.

</details>


### [130] [Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning](https://arxiv.org/abs/2512.20363)
*Daniel M. Jimenez-Gutierrez,Mehrdad Hassanzadeh,Aris Anagnostopoulos,Ioannis Chatzigiannakis,Andrea Vitaletti*

Main category: cs.LG

TL;DR: 提出Clust-PSI-PFL框架，使用PSI指标量化非IID数据，通过聚类形成分布相似的客户端组，显著提升联邦学习在标签偏斜下的性能和公平性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据的非独立同分布特性会导致模型更新偏差和性能下降，特别是在标签偏斜情况下。现有方法对非IID数据的量化不够有效，需要更准确的度量来指导个性化联邦学习。

Method: 提出Clust-PSI-PFL框架：1) 使用加权PSI指标(WPSI^L)量化非IID程度，比传统度量更有效；2) 基于PSI特征使用K-means++聚类形成分布相似的客户端组；3) 通过轮廓系数法自动选择最优聚类数量；4) 在聚类组内进行个性化联邦学习。

Result: 在6个数据集(表格、图像、文本)、2种数据划分协议(Dirichlet和Similarity)和多种客户端规模下，相比现有方法：1) 全局准确率提升最高达18%；2) 客户端公平性相对改善37%；3) 聚类数量少且开销小。

Conclusion: PSI引导的聚类是一种原则性、轻量级的机制，能有效提升个性化联邦学习在标签偏斜下的鲁棒性，为处理非IID数据提供了系统解决方案。

Abstract: Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices. However, non-independent and identically distributed (non-IID) data across clients biases updates and degrades performance. To alleviate these issues, we propose Clust-PSI-PFL, a clustering-based personalized FL framework that uses the Population Stability Index (PSI) to quantify the level of non-IID data. We compute a weighted PSI metric, $WPSI^L$, which we show to be more informative than common non-IID metrics (Hellinger, Jensen-Shannon, and Earth Mover's distance). Using PSI features, we form distributionally homogeneous groups of clients via K-means++; the number of optimal clusters is chosen by a systematic silhouette-based procedure, typically yielding few clusters with modest overhead. Across six datasets (tabular, image, and text modalities), two partition protocols (Dirichlet with parameter $α$ and Similarity with parameter S), and multiple client sizes, Clust-PSI-PFL delivers up to 18% higher global accuracy than state-of-the-art baselines and markedly improves client fairness by a relative improvement of 37% under severe non-IID data. These results establish PSI-guided clustering as a principled, lightweight mechanism for robust PFL under label skew.

</details>


### [131] [NeuralCrop: Combining physics and machine learning for improved crop yield predictions](https://arxiv.org/abs/2512.20177)
*Yunan Lin,Sebastian Bathiany,Maha Badri,Maximilian Gelbrecht,Philipp Hess,Brian Groenke,Jens Heinke,Christoph Müller,Niklas Boers*

Main category: cs.LG

TL;DR: NeuralCrop是一种混合型全球网格作物模型，将先进的基于过程的GGCM与数据驱动的机器学习组件相结合，在作物产量预测方面优于现有GGCM，特别是在极端干旱条件下表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统GGCM由于过程理解有限，在模拟复杂生物物理过程时存在较大不确定性；纯机器学习模型虽然显示潜力，但在训练分布外泛化能力差，不适用于气候变化条件下的产量模拟。

Method: 开发NeuralCrop混合模型，先训练模拟竞争性GGCM，再在观测数据上进行微调，结合过程模型的明确过程解析能力和数据驱动模型的优势。

Result: NeuralCrop在站点和大尺度种植区域均优于最先进的GGCM；在2000-2019年间，能更准确地再现欧洲小麦区和美国玉米带的年际产量异常，在极端干旱条件下改进尤为显著；在训练未见条件下仍能做出稳健预测。

Conclusion: 混合作物建模方法提供了整体改进的作物建模能力，在气候变化和极端天气加剧条件下能提供更可靠的产量预测。

Abstract: Global gridded crop models (GGCMs) simulate daily crop growth by explicitly representing key biophysical processes and project end-of-season yield time series. They are a primary tool to quantify the impacts of climate change on agricultural productivity and assess associated risks for food security. Despite decades of development, state-of-the-art GGCMs still have substantial uncertainties in simulating complex biophysical processes due to limited process understanding. Recently, machine learning approaches trained on observational data have shown great potential in crop yield predictions. However, these models have not demonstrated improved performance over classical GGCMs and are not suitable for simulating crop yields under changing climate conditions due to problems in generalizing outside their training distributions. Here we introduce NeuralCrop, a hybrid GGCM that combines the strengths of an advanced process-based GGCM, resolving important processes explicitly, with data-driven machine learning components. The model is first trained to emulate a competitive GGCM before it is fine-tuned on observational data. We show that NeuralCrop outperforms state-of-the-art GGCMs across site-level and large-scale cropping regions. Across moisture conditions, NeuralCrop reproduces the interannual yield anomalies in European wheat regions and the US Corn Belt more accurately during the period from 2000 to 2019 with particularly strong improvements under drought extremes. When generalizing to conditions unseen during training, NeuralCrop continues to make robust projections, while pure machine learning models exhibit substantial performance degradation. Our results show that our hybrid crop modelling approach offers overall improved crop modeling and more reliable yield projections under climate change and intensifying extreme weather conditions.

</details>


### [132] [Cost-TrustFL: Cost-Aware Hierarchical Federated Learning with Lightweight Reputation Evaluation across Multi-Cloud](https://arxiv.org/abs/2512.20218)
*Jixiao Yang,Jinyu Chen,Zixiao Huang,Chengda Xu,Chi Zhang,Sijia Li*

Main category: cs.LG

TL;DR: Cost-TrustFL：一个分层联邦学习框架，在多云环境中联合优化模型性能和通信成本，同时防御投毒攻击，通过梯度近似Shapley值计算和成本感知聚合策略，在CIFAR-10和FEMNIST上达到86.7%准确率并减少32%通信成本。


<details>
  <summary>Details</summary>
Motivation: 多云环境下的联邦学习面临非独立同分布数据分布、恶意参与者检测以及跨云通信成本（出口费用）等关键挑战。现有拜占庭鲁棒方法主要关注模型准确性，而忽略了跨云数据传输的经济影响。

Method: 提出Cost-TrustFL分层联邦学习框架，包含：1）基于梯度的近似Shapley值计算方法，将复杂度从指数级降低到线性级，实现轻量级声誉评估；2）成本感知聚合策略，优先进行云内通信以最小化昂贵的跨云数据传输。

Result: 在CIFAR-10和FEMNIST数据集上的实验表明，Cost-TrustFL在30%恶意客户端情况下达到86.7%准确率，同时相比基线方法减少32%通信成本。该框架在不同非独立同分布程度和攻击强度下保持稳定性能。

Conclusion: Cost-TrustFL为现实世界多云部署提供了一个实用的解决方案，能够联合优化模型性能和通信成本，同时提供对投毒攻击的鲁棒防御，在多云联邦学习环境中具有实际应用价值。

Abstract: Federated learning across multi-cloud environments faces critical challenges, including non-IID data distributions, malicious participant detection, and substantial cross-cloud communication costs (egress fees). Existing Byzantine-robust methods focus primarily on model accuracy while overlooking the economic implications of data transfer across cloud providers. This paper presents Cost-TrustFL, a hierarchical federated learning framework that jointly optimizes model performance and communication costs while providing robust defense against poisoning attacks. We propose a gradient-based approximate Shapley value computation method that reduces the complexity from exponential to linear, enabling lightweight reputation evaluation. Our cost-aware aggregation strategy prioritizes intra-cloud communication to minimize expensive cross-cloud data transfers. Experiments on CIFAR-10 and FEMNIST datasets demonstrate that Cost-TrustFL achieves 86.7% accuracy under 30% malicious clients while reducing communication costs by 32% compared to baseline methods. The framework maintains stable performance across varying non-IID degrees and attack intensities, making it practical for real-world multi-cloud deployments.

</details>


### [133] [Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs](https://arxiv.org/abs/2512.20573)
*Rui Pan,Zhuofu Chen,Ravi Netravali*

Main category: cs.LG

TL;DR: FailFast是一个基于扩散大语言模型的推测解码框架，通过动态调整推测长度实现高效加速，在简单区域激进扩展推测长度，在困难区域快速失败以减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（dLLMs）虽然提供快速并行token生成，但单独使用时存在效率与质量的权衡问题。作者发现，如果精心应用，dLLMs的特性实际上可以成为推测解码中草稿生成器的优势。

Method: 提出FailFast框架，核心洞察是利用dLLM并行解码的速度优势降低高成本拒绝的风险，通过动态适应推测长度实现"快速失败"和"大获全胜"策略：在难以推测的区域最小化计算开销，在容易推测的区域激进扩展草稿长度。

Result: 无需微调即可实现AR LLMs的无损加速，相比原始解码达到4.9倍加速，相比最佳朴素dLLM草稿生成器达到1.7倍加速，相比EAGLE-3达到1.4倍加速，在多种模型和工作负载上表现优异，有时能一次推测并接受70个token。

Conclusion: FailFast成功将dLLMs的并行解码特性转化为推测解码的优势，通过动态长度适应策略实现了显著的加速效果，为LLM推理优化提供了新的有效方法。

Abstract: Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It "fails fast" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and "wins big" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\times$ speedup over vanilla decoding, 1.7$\times$ over the best naive dLLM drafter, and 1.4$\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.

</details>


### [134] [Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning](https://arxiv.org/abs/2512.20220)
*Kausthubh Manda,Raghuram Bharadwaj Diddigi*

Main category: cs.LG

TL;DR: 该论文研究了离线多任务强化学习，其中多个任务共享其动作价值函数的低秩表示。作者分析了通过贝尔曼误差最小化联合学习共享表示和任务特定价值函数的方法，建立了有限样本泛化保证，并展示了跨任务数据池化如何提高估计精度。


<details>
  <summary>Details</summary>
Motivation: 研究离线多任务强化学习的动机在于：在多个相关任务共享动作价值函数低秩表示的场景下，如何利用固定数据集（无在线交互）来利用共享结构以提高统计效率和泛化能力。这解决了传统离线RL中数据有限的问题。

Method: 采用多任务版本的拟合Q迭代方法，通过贝尔曼误差最小化在离线数据上联合学习共享表示和任务特定的价值函数。该方法在标准可实现性和覆盖性假设下进行分析。

Result: 建立了学习价值函数的有限样本泛化保证，明确表征了跨任务数据池化如何提高估计精度，得到了1/√(nT)的样本依赖关系（n为任务数，T为样本总数）。同时分析了在下游新任务中重用上游学习表示的效果，显示可以降低下游学习的有效复杂度。

Conclusion: 研究阐明了共享表示在多任务离线Q学习中的作用，为理解多任务结构何时以及如何能在无模型、基于价值的强化学习中改善泛化提供了理论见解。结果表明，通过利用任务间的共享结构，可以显著提高离线强化学习的统计效率。

Abstract: We study offline multitask reinforcement learning in settings where multiple tasks share a low-rank representation of their action-value functions. In this regime, a learner is provided with fixed datasets collected from several related tasks, without access to further online interaction, and seeks to exploit shared structure to improve statistical efficiency and generalization. We analyze a multitask variant of fitted Q-iteration that jointly learns a shared representation and task-specific value functions via Bellman error minimization on offline data. Under standard realizability and coverage assumptions commonly used in offline reinforcement learning, we establish finite-sample generalization guarantees for the learned value functions. Our analysis explicitly characterizes how pooling data across tasks improves estimation accuracy, yielding a $1/\sqrt{nT}$ dependence on the total number of samples across tasks, while retaining the usual dependence on the horizon and concentrability coefficients arising from distribution shift. In addition, we consider a downstream offline setting in which a new task shares the same underlying representation as the upstream tasks. We study how reusing the representation learned during the multitask phase affects value estimation for this new task, and show that it can reduce the effective complexity of downstream learning relative to learning from scratch. Together, our results clarify the role of shared representations in multitask offline Q-learning and provide theoretical insight into when and how multitask structure can improve generalization in model-free, value-based reinforcement learning.

</details>


### [135] [Performative Policy Gradient: Optimality in Performative Reinforcement Learning](https://arxiv.org/abs/2512.20576)
*Debabrota Basu,Udvas Das,Brahim Driss,Uddalak Mukherjee*

Main category: cs.LG

TL;DR: 本文提出了Performative Policy Gradient (PePG)算法，这是第一个考虑强化学习中执行性影响的策略梯度算法，能够收敛到在执行性分布偏移下保持最优的策略。


<details>
  <summary>Details</summary>
Motivation: 部署后的机器学习算法会影响其作用的环境，从而改变标准强化学习方法忽略的底层动态。虽然监督学习中的执行性设置已有研究，但强化学习中的对应问题尚未充分探索。

Method: 证明了强化学习中执行性版本的性能差异引理和策略梯度定理，并提出了Performative Policy Gradient (PePG)算法。在softmax参数化和有无熵正则化的情况下，证明了PePG收敛到执行性最优策略。

Result: PePG是第一个考虑执行性影响的策略梯度算法，能够收敛到在执行性分布偏移下保持最优的策略。在标准执行性RL环境中的实证分析表明，PePG优于标准策略梯度算法和现有的追求稳定性的执行性RL算法。

Conclusion: PePG算法显著扩展了先前执行性RL的研究，不仅实现了执行性稳定性，还实现了执行性最优性，为处理强化学习中的执行性分布偏移问题提供了有效的解决方案。

Abstract: Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms standard policy gradient algorithms and the existing performative RL algorithms aiming for stability.

</details>


### [136] [Adaptive Multi-task Learning for Probabilistic Load Forecasting](https://arxiv.org/abs/2512.20232)
*Onintze Zaballa,Verónica Álvarez,Santiago Mazuelas*

Main category: cs.LG

TL;DR: 本文提出了一种基于向量值隐马尔可夫模型的自适应多任务学习方法，用于多实体概率负荷预测，能够动态适应消费模式变化和实体间相关性。


<details>
  <summary>Details</summary>
Motivation: 多实体同时负荷预测对电力系统高效可靠运行至关重要，但现有方法多为离线学习，无法捕捉消费模式变化，且多任务学习在负荷预测中的应用仍待探索。

Method: 基于向量值隐马尔可夫模型，采用递归过程更新模型参数，提供自适应多任务学习框架，实现动态适应消费模式变化和实体间相关性。

Result: 在包含多实体负荷需求且具有多样动态消费模式的数据集上评估，实验结果表明该方法在预测性能和不确定性评估方面均优于现有方法。

Conclusion: 提出的自适应多任务学习方法能够有效处理多实体负荷预测问题，动态适应消费模式变化，提供可靠的概率预测和不确定性评估。

Abstract: Simultaneous load forecasting across multiple entities (e.g., regions, buildings) is crucial for the efficient, reliable, and cost-effective operation of power systems. Accurate load forecasting is a challenging problem due to the inherent uncertainties in load demand, dynamic changes in consumption patterns, and correlations among entities. Multi-task learning has emerged as a powerful machine learning approach that enables the simultaneous learning across multiple related problems. However, its application to load forecasting remains underexplored and is limited to offline learning-based methods, which cannot capture changes in consumption patterns. This paper presents an adaptive multi-task learning method for probabilistic load forecasting. The proposed method can dynamically adapt to changes in consumption patterns and correlations among entities. In addition, the techniques presented provide reliable probabilistic predictions for loads of multiples entities and assess load uncertainties. Specifically, the method is based on vectorvalued hidden Markov models and uses a recursive process to update the model parameters and provide predictions with the most recent parameters. The performance of the proposed method is evaluated using datasets that contain the load demand of multiple entities and exhibit diverse and dynamic consumption patterns. The experimental results show that the presented techniques outperform existing methods both in terms of forecasting performance and uncertainty assessment.

</details>


### [137] [Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning](https://arxiv.org/abs/2512.20605)
*Seijin Kobayashi,Yanick Schimpf,Maximilian Schlegel,Angelika Steger,Maciej Wolczyk,Johannes von Oswald,Nino Scherre,Kaitlin Maile,Guillaume Lajoie,Blake A. Richards,Rif A. Saurous,James Manyika,Blaise Agüera y Arcas,Alexander Meulemans,João Sacramento*

Main category: cs.LG

TL;DR: 本文提出了一种在自回归模型内部表示中进行探索的"内部强化学习"方法，通过高阶非因果序列模型学习控制自回归模型激活流的内部控制器，实现时间抽象动作和高效探索。


<details>
  <summary>Details</summary>
Motivation: 传统基于token-by-token采样的强化学习方法在稀疏奖励任务中学习效率低下，因为需要逐个token探索。本文旨在克服这一问题，通过在自回归模型的内部表示中进行探索和行动。

Method: 引入高阶非因果序列模型，其输出控制基础自回归模型的残差流激活。该模型学习将长激活序列块压缩到内部控制器上，每个控制器执行行为上有意义的长时程动作序列，并包含学习到的终止条件。

Result: 在具有层次结构的网格世界和MuJoCo任务上，高阶模型成功学习到压缩长激活序列到内部控制器。内部控制器强化学习（内部RL）能够在标准RL微调失败的情况下从稀疏奖励中学习，实现高效探索。

Conclusion: 内部RL展示了在自回归模型中潜在动作生成和强化的优势，为实现基础模型中的层次强化学习提供了有前景的途径。

Abstract: Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term "internal RL", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.

</details>


### [138] [How I Met Your Bias: Investigating Bias Amplification in Diffusion Models](https://arxiv.org/abs/2512.20233)
*Nathan Roos,Ekaterina Iakovleva,Ani Gjergji,Vito Paolo Pastore,Enzo Tartaglione*

Main category: cs.LG

TL;DR: 扩散模型采样算法及其超参数对偏差放大的影响分析：采样器不仅影响生成质量和速度，还能显著调控模型偏差的放大或减小


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像合成任务中表现出色，但倾向于复制和放大数据集偏差的问题尚未得到充分理解。先前研究将偏差放大视为扩散模型的固有特性，而本研究首次探讨采样算法及其超参数如何影响偏差放大

Method: 通过控制实验，使用在Biased MNIST、Multi-Color MNIST和BFFHQ上训练的模型以及Stable Diffusion，实证研究不同采样器及其超参数对偏差放大的影响

Result: 实验表明，扩散模型的采样器（通常为样本质量和速度优化）对偏差放大有显著且可测量的影响。采样超参数可以在固定训练模型的情况下诱导偏差减小或放大

Conclusion: 偏差放大不是扩散模型的固有特性，而是受采样算法和超参数调控的可控因素。这为通过调整采样过程来减轻模型偏差提供了新的可能性

Abstract: Diffusion-based generative models demonstrate state-of-the-art performance across various image synthesis tasks, yet their tendency to replicate and amplify dataset biases remains poorly understood. Although previous research has viewed bias amplification as an inherent characteristic of diffusion models, this work provides the first analysis of how sampling algorithms and their hyperparameters influence bias amplification. We empirically demonstrate that samplers for diffusion models -- commonly optimized for sample quality and speed -- have a significant and measurable effect on bias amplification. Through controlled studies with models trained on Biased MNIST, Multi-Color MNIST and BFFHQ, and with Stable Diffusion, we show that sampling hyperparameters can induce both bias reduction and amplification, even when the trained model is fixed. Source code is available at https://github.com/How-I-met-your-bias/how_i_met_your_bias.

</details>


### [139] [Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion](https://arxiv.org/abs/2512.20249)
*Xuanyu Hu*

Main category: cs.LG

TL;DR: BrainROI模型通过软功能分区编码器、可解释提示优化和参数化解码约束，在多模态脑解码中实现了跨被试泛化和可解释性的突破，在NSD数据集上取得了领先的脑-字幕生成效果。


<details>
  <summary>Details</summary>
Motivation: 多模态脑解码面临跨被试泛化和可解释性两大关键挑战：不同被试间功能脑拓扑结构的异质性，以及现有提示方法在稳定性和透明度上的局限性。

Method: 1. 设计新的fMRI编码器：使用多图谱软功能分区作为共享空间，将离散ROI拼接扩展为体素门控融合机制，通过全局标签对齐确保ROI映射一致性；2. 引入可解释提示优化：在小样本闭环中使用本地部署的Qwen模型迭代生成和选择人类可读提示；3. 推理时施加参数化解码约束。

Result: 在NSD数据集跨被试设置下，相比现有SOTA方法和代表性基线，BLEU-4和CIDEr等指标均有明显提升，达到了领先水平的脑-字幕生成效果。

Conclusion: BrainROI模型通过创新的编码器设计、可解释提示优化和解码约束，有效解决了多模态脑解码中的跨被试泛化和可解释性问题，为脑活动信号到语义信息的重建提供了更稳定、透明的解决方案。

Abstract: Multimodal brain decoding aims to reconstruct semantic information that is consistent with visual stimuli from brain activity signals such as fMRI, and then generate readable natural language descriptions. However, multimodal brain decoding still faces key challenges in cross-subject generalization and interpretability. We propose a BrainROI model and achieve leading-level results in brain-captioning evaluation on the NSD dataset. Under the cross-subject setting, compared with recent state-of-the-art methods and representative baselines, metrics such as BLEU-4 and CIDEr show clear improvements. Firstly, to address the heterogeneity of functional brain topology across subjects, we design a new fMRI encoder. We use multi-atlas soft functional parcellations (soft-ROI) as a shared space. We extend the discrete ROI Concatenation strategy in MINDLLM to a voxel-wise gated fusion mechanism (Voxel-gate). We also ensure consistent ROI mapping through global label alignment, which enhances cross-subject transferability. Secondly, to overcome the limitations of manual and black-box prompting methods in stability and transparency, we introduce an interpretable prompt optimization process. In a small-sample closed loop, we use a locally deployed Qwen model to iteratively generate and select human-readable prompts. This process improves the stability of prompt design and preserves an auditable optimization trajectory. Finally, we impose parameterized decoding constraints during inference to further improve the stability and quality of the generated descriptions.

</details>


### [140] [HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training](https://arxiv.org/abs/2512.20272)
*Yuanjian Xu,Yuan Shuai,Jianing Hao,Guang Zhang*

Main category: cs.LG

TL;DR: HGAN-SDEs：基于GAN的神经随机微分方程框架，利用Hermite函数构建高效判别器，提升SDE路径分布建模的样本质量和训练效率


<details>
  <summary>Details</summary>
Motivation: 现有基于神经控制微分方程的判别器虽然能建模连续时间动态，但计算成本高且加剧对抗训练的不稳定性，需要设计既能捕捉时间依赖又计算高效的判别器

Method: 提出HGAN-SDEs框架，利用神经Hermite函数构建结构化高效判别器，Hermite函数为路径级动态提供表达力强且轻量级的近似基础

Result: 在合成和真实世界系统中广泛评估，HGAN-SDEs相比现有SDE生成模型获得更优的样本质量和学习效率，建立了框架的通用逼近性质并理论分析了收敛行为

Conclusion: HGAN-SDEs通过Hermite函数判别器有效解决了SDE建模中的计算效率和训练稳定性问题，为连续时间随机过程建模提供了更优的生成对抗框架

Abstract: Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic processes and have been widely adopted in fields ranging from physics to finance. Recent advances suggest that Generative Adversarial Networks (GANs) offer a promising solution to learning the complex path distributions induced by SDEs. However, a critical bottleneck lies in designing a discriminator that faithfully captures temporal dependencies while remaining computationally efficient. Prior works have explored Neural Controlled Differential Equations (CDEs) as discriminators due to their ability to model continuous-time dynamics, but such architectures suffer from high computational costs and exacerbate the instability of adversarial training. To address these limitations, we introduce HGAN-SDEs, a novel GAN-based framework that leverages Neural Hermite functions to construct a structured and efficient discriminator. Hermite functions provide an expressive yet lightweight basis for approximating path-level dynamics, enabling both reduced runtime complexity and improved training stability. We establish the universal approximation property of our framework for a broad class of SDE-driven distributions and theoretically characterize its convergence behavior. Extensive empirical evaluations on synthetic and real-world systems demonstrate that HGAN-SDEs achieve superior sample quality and learning efficiency compared to existing generative models for SDEs

</details>


### [141] [Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity](https://arxiv.org/abs/2512.20291)
*Yuxing Gan,Ziyu Lei*

Main category: cs.LG

TL;DR: CDSP-MoE通过冲突驱动的子空间剪枝方法，从共享物理子空间中动态实例化专家，解决了传统MoE架构中的参数隔离和指令过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构存在两个根本性限制：1) 结构参数隔离导致灾难性遗忘；2) 指令过拟合在无指令场景下性能下降。需要一种新范式来解决这些问题。

Method: 基于通用权重子空间假设，CDSP-MoE维护一个超完备参数骨干，通过可学习的拓扑掩码从共享物理子空间中"雕刻"出逻辑专家。使用滞后梯度博弈作为结构监督信号，惩罚共享流形中的干扰连接，使拓扑能够自发剪除冲突路径并演化出可解释的模块化结构。

Result: 实验结果表明，CDSP-MoE在没有人工定义任务标签的情况下实现了鲁棒的内容驱动路由，即使在严格的无指令盲推理协议下也能保持语义专业化。

Conclusion: CDSP-MoE通过从隔离专家容器到共享物理子空间中动态专家实例化的范式转变，有效解决了传统MoE架构的结构参数隔离和指令过拟合问题，实现了更灵活和鲁棒的专家混合架构。

Abstract: Mixture-of-Experts (MoE) architectures achieve parameter efficiency through conditional computation, yet contemporary designs suffer from two fundamental limitations: structural parameter isolation that causes catastrophic forgetting, and instruction-overfitting that degrades performance in instruction-free scenarios. We propose CDSP-MoE (Conflict-Driven Subspace Pruning MoE), a framework that addresses these issues through a paradigm shift from isolated expert containers to dynamic expert instantiation within a shared physical subspace. Grounded in the Universal Weight Subspace Hypothesis, CDSP-MoE maintains a super-complete parameter backbone where logical experts are carved out via learnable topology masks. Unlike prior work that uses gradient conflict for token reassignment or optimization surgery, we leverage it as a structural supervisory signal: a Lagged Gradient Game penalizes interfering connections in the shared manifold, enabling the topology to spontaneously prune conflicting pathways and evolve interpretable modular structures. Experimental results demonstrate that CDSP-MoE achieves robust content-driven routing without human-defined task labels, maintaining semantic specialization even under strict blind inference protocols where explicit instructions are absent. Code is available at: https://github.com/konodiodaaaaa1/Conflict-Driven-Subspace-Pruning-Mixture-of-Experts

</details>


### [142] [FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning](https://arxiv.org/abs/2512.20329)
*Mrinmay Sen,Subhrajit Nag*

Main category: cs.LG

TL;DR: FedDPC是一种新的联邦学习方法，通过将本地更新投影到先前全局更新上来同时缓解数据异构性和部分客户端参与问题，从而提高训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现代联邦学习中，数据异构性导致本地模型更新方差增大，使聚合的全局模型偏离全局最优解。部分客户端参与进一步加剧了这一问题，使聚合偏向参与客户端的数据分布，导致全局模型更新方差增大，训练不稳定，性能下降。现有研究主要关注数据异构性，对部分客户端参与的影响关注较少。

Method: FedDPC通过将每个本地更新投影到先前的全局更新上来控制本地和全局更新的方差。为加速训练，FedDPC在聚合前对每个本地更新采用自适应缩放。

Result: 在多个异构划分数据集上的图像分类任务实验表明，FedDPC在训练损失下降速度和测试准确率方面均优于最先进的联邦学习算法。

Conclusion: FedDPC通过同时缓解数据异构性和部分客户端参与问题，有效提高了联邦学习的训练稳定性和全局模型性能。

Abstract: Data heterogeneity is a significant challenge in modern federated learning (FL) as it creates variance in local model updates, causing the aggregated global model to shift away from the true global optimum. Partial client participation in FL further exacerbates this issue by skewing the aggregation of local models towards the data distribution of participating clients. This creates additional variance in the global model updates, causing the global model to converge away from the optima of the global objective. These variances lead to instability in FL training, which degrades global model performance and slows down FL training. While existing literature primarily focuses on addressing data heterogeneity, the impact of partial client participation has received less attention. In this paper, we propose FedDPC, a novel FL method, designed to improve FL training and global model performance by mitigating both data heterogeneity and partial client participation. FedDPC addresses these issues by projecting each local update onto the previous global update, thereby controlling variance in both local and global updates. To further accelerate FL training, FedDPC employs adaptive scaling for each local update before aggregation. Extensive experiments on image classification tasks with multiple heterogeneously partitioned datasets validate the effectiveness of FedDPC. The results demonstrate that FedDPC outperforms state-of-the-art FL algorithms by achieving faster reduction in training loss and improved test accuracy across communication rounds.

</details>


### [143] [Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation](https://arxiv.org/abs/2512.20346)
*Emilia Majerz,Witold Dzwinel,Jacek Kitowski*

Main category: cs.LG

TL;DR: 该论文提出了一种基于物理的机器学习方法，用于加速CERN ALICE实验中零度量热器的粒子簇射模拟，通过新颖的损失函数和输出变异性缩放机制，在教师-学生生成框架中使用归一化流，实现了比传统方法更准确且快421倍的模拟。


<details>
  <summary>Details</summary>
Motivation: 加速CERN ALICE实验中零度量热器的粒子簇射模拟，传统模拟方法计算成本高，需要更高效且准确的替代方案。物理驱动的机器学习方法能够结合领域知识，提高模型的准确性和鲁棒性。

Method: 采用基于物理的机器学习范式，结合归一化流在教师-学生生成框架中。引入新颖的损失函数和输出变异性缩放机制，以准确表示探测器输出中粒子簇射的空间分布和形态，同时减少罕见伪影对训练的影响。

Result: 该方法不仅超越了经典的数据驱动模型同化，而且比现有ZDC模拟文献中的归一化流实现快421倍，同时提高了模拟的准确性和鲁棒性。

Conclusion: 物理驱动的机器学习方法能够有效加速高能物理实验中的探测器模拟，通过结合领域知识和创新的训练机制，实现了既快速又准确的模拟解决方案。

Abstract: Physics-based machine learning blends traditional science with modern data-driven techniques. Rather than relying exclusively on empirical data or predefined equations, this methodology embeds domain knowledge directly into the learning process, resulting in models that are both more accurate and robust. We leverage this paradigm to accelerate simulations of the Zero Degree Calorimeter (ZDC) of the ALICE experiment at CERN. Our method introduces a novel loss function and an output variability-based scaling mechanism, which enhance the model's capability to accurately represent the spatial distribution and morphology of particle showers in detector outputs while mitigating the influence of rare artefacts on the training. Leveraging Normalizing Flows (NFs) in a teacher-student generative framework, we demonstrate that our approach not only outperforms classic data-driven model assimilation but also yields models that are 421 times faster than existing NF implementations in ZDC simulation literature.

</details>


### [144] [BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples](https://arxiv.org/abs/2512.20403)
*Xuan-An Le,Minh-Nam Tran,Son Nguyen*

Main category: cs.LG

TL;DR: BRIDGE框架通过两阶段知识蒸馏解决大模型到小模型的知识迁移问题，使用中间教师助理在有限预算下提升小模型性能


<details>
  <summary>Details</summary>
Motivation: 解决从大型专有模型（如GPT-4）向极小可部署模型（小于10亿参数）进行知识蒸馏时面临的容量预算陷阱：1000倍的容量差距阻碍直接知识转移，而API成本又限制了数据收集

Method: 两阶段框架：第一阶段，中等规模的教师助理在严格限制的数据子集（3-5%）上从黑盒教师学习，使用零API成本管道平衡熵难度和语义多样性；第二阶段，利用教师查询昂贵而TA推理免费的不对称性，TA为完整数据集生成合成推理过程来训练小模型，并应用指令调优课程建立行为对齐

Result: 在医疗、法律和金融基准测试中，BRIDGE使小模型性能提升28-41%，将能力差距缩小12-16%，同时使用10倍更少的教师查询；超越使用100%预算的直接蒸馏基线，仅消耗5%资源

Conclusion: BRIDGE框架通过战略中间化和预算不对称性，突破了传统的成本-性能边界，为在有限预算下实现高效知识蒸馏提供了可行方案

Abstract: Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection. We introduce BRIDGE (Budget-Aware Reasoning via Intermediate Distillation), a two-phase framework that resolves these constraints through strategic intermediation and budget asymmetry. In Phase 1, a mid-sized Teacher Assistant (TA; e.g., about 7B) learns from the black-box teacher on a strictly limited subset of data (e.g., 3-5%), selected via a zero-API-cost pipeline that balances entropic difficulty and semantic diversity using only local TA inference. In Phase 2, we exploit this asymmetry-teacher queries are expensive, whereas TA inference is free to amplify supervision: the refined TA generates synthetic rationales for the full dataset to train the tiny student. Crucially, we apply an instruction-tuning curriculum to establish behavioral alignment in the tiny student before transferring reasoning. Our theoretical analysis shows that BRIDGE yields tighter generalization bounds than direct distillation when data is abundant. Experiments across medical, legal, and financial benchmarks demonstrate consistent improvements: BRIDGE delivers student performance gains of 28-41%, closing the capability gap with proprietary teachers by 12-16% while using 10x fewer teacher queries. Notably, BRIDGE defies the conventional cost-performance frontier, surpassing direct distillation baselines that use 100% of the budget while consuming only 5% of the resources.

</details>


### [145] [Machine Learning to Predict Digital Frustration from Clickstream Data](https://arxiv.org/abs/2512.20438)
*Jibin Joseph*

Main category: cs.LG

TL;DR: 使用电子商务网站点击流数据预测用户会话是否受挫，XGBoost准确率约90%，LSTM准确率约91%，且仅需前20-30次交互即可可靠预测


<details>
  <summary>Details</summary>
Motivation: 移动应用和网站的用户受挫会导致销售损失和投诉，需要预测用户会话是否受挫以改善用户体验

Method: 基于点击流数据定义受挫规则（愤怒爆发、来回导航、购物车流失、搜索困难、长时间徘徊），从304,881个会话中提取表格特征训练标准分类器，同时使用完整事件序列训练判别式LSTM分类器

Result: XGBoost达到约90%准确率和0.9579 ROC AUC，LSTM表现最佳，达到约91%准确率和0.9705 ROC AUC，且仅需前20-30次交互即可可靠预测受挫

Conclusion: 点击流数据可用于有效预测用户受挫，LSTM模型在序列数据处理方面表现优异，早期预测能力有助于及时干预改善用户体验

Abstract: Many businesses depend on their mobile apps and websites, so user frustration while trying to complete a task on these channels can cause lost sales and complaints. In this research, I use clickstream data from a real e-commerce site to predict whether a session is frustrated or not. Frustration is defined using certain rules based on rage bursts, back and forth navigation (U turns), cart churn, search struggle, and long wandering sessions, and applies these rules to 5.4 million raw clickstream events (304,881 sessions). From each session, I build tabular features and train standard classifier models. I also use the full event sequence to train a discriminative LSTM classifier. XGBoost reaches about 90% accuracy, ROC AUC of 0.9579, while the LSTM performs best with about 91% accuracy and a ROC AUC of 0.9705. Finally, the research shows that with only the first 20 to 30 interactions, the LSTM already predicts frustration reliably.

</details>


### [146] [Explainable time-series forecasting with sampling-free SHAP for Transformers](https://arxiv.org/abs/2512.20514)
*Matthias Hertel,Sebastian Pütz,Ralf Mikut,Veit Hagenmeyer,Benjamin Schäfer*

Main category: cs.LG

TL;DR: SHAPformer：基于Transformer架构的快速、免采样的可解释时间序列预测模型，通过注意力机制操作实现特征子集预测，比SHAP排列解释器快几个数量级。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测对规划和决策至关重要，可解释性是建立用户信任和满足透明度要求的关键。现有的SHAP框架缺乏针对时间序列的高效实现，且采样反事实时通常假设特征独立性。

Method: 提出SHAPformer模型，基于Transformer架构，通过注意力操作使预测基于特征子集，实现免采样的可解释时间序列预测。

Result: 在具有真实解释的合成数据上，SHAPformer提供符合数据的准确解释；在真实世界电力负荷数据上，达到有竞争力的预测性能，并在1秒内生成解释，比SHAP排列解释器快几个数量级。

Conclusion: SHAPformer是一个准确、快速且免采样的可解释时间序列预测模型，能够提供有意义的局部和全局洞察，如识别过去负荷为关键预测因子，并揭示圣诞节期间的独特模型行为。

Abstract: Time-series forecasts are essential for planning and decision-making in many domains. Explainability is key to building user trust and meeting transparency requirements. Shapley Additive Explanations (SHAP) is a popular explainable AI framework, but it lacks efficient implementations for time series and often assumes feature independence when sampling counterfactuals. We introduce SHAPformer, an accurate, fast and sampling-free explainable time-series forecasting model based on the Transformer architecture. It leverages attention manipulation to make predictions based on feature subsets. SHAPformer generates explanations in under one second, several orders of magnitude faster than the SHAP Permutation Explainer. On synthetic data with ground truth explanations, SHAPformer provides explanations that are true to the data. Applied to real-world electrical load data, it achieves competitive predictive performance and delivers meaningful local and global insights, such as identifying the past load as the key predictor and revealing a distinct model behavior during the Christmas period.

</details>


### [147] [Improving ML Training Data with Gold-Standard Quality Metrics](https://arxiv.org/abs/2512.20577)
*Leslie Barrett,Michael W. Sherman*

Main category: cs.LG

TL;DR: 该论文提出使用统计方法评估和提升人工标注训练数据的质量，通过测量标注一致性和一致性指标，发现多轮标注能提供更可靠的结果，并展示了一种无需每个项目多次标注即可收集高质量数据的方法。


<details>
  <summary>Details</summary>
Motivation: 人工标注的训练数据对机器学习任务至关重要，但文献中对训练数据质量控制关注不足，而实际标注质量在不同标注任务中差异很大。需要建立系统方法来评估和提升标注数据的质量。

Method: 提出使用统计方法测量标注一致性和一致性指标，通过多轮标注记录一致性指标，观察方差下降作为数据质量提升的指标。同时提出一种无需每个项目多次标注即可收集高质量训练数据的方法。

Result: 一致性指标在多轮标注中能提供更可靠的结果，方差下降表明数据质量提升。研究发现标注员适应期可能不足以最小化标注错误，并展示了如何有效收集高质量标注数据。

Conclusion: 需要系统的方法来评估和提升人工标注训练数据的质量，多轮标注和统计一致性测量是有效的质量控制手段，能够在不增加过多标注成本的情况下获得高质量的训练数据。

Abstract: Hand-tagged training data is essential to many machine learning tasks. However, training data quality control has received little attention in the literature, despite data quality varying considerably with the tagging exercise. We propose methods to evaluate and enhance the quality of hand-tagged training data using statistical approaches to measure tagging consistency and agreement. We show that agreement metrics give more reliable results if recorded over multiple iterations of tagging, where declining variance in such recordings is an indicator of increasing data quality. We also show one way a tagging project can collect high-quality training data without requiring multiple tags for every work item, and that a tagger burn-in period may not be sufficient for minimizing tagger errors.

</details>
