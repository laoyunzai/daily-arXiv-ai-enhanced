{"id": "2511.17697", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.17697", "abs": "https://arxiv.org/abs/2511.17697", "authors": ["Aiman Al-Eryani", "Marcel Gievers", "Kilian Fraboulet"], "title": "Functional renormalization with interaction flows: A single-boson exchange perspective and application to electron-phonon systems", "comment": null, "summary": "The functional renormalization group (fRG) is acknowledged as a powerful tool in quantum many-body physics and beyond. On the technical side, conventional implementations of the fRG rely on regulators for bare propagators only. Starting from Schwinger--Dyson and Bethe--Salpeter equations, we develop here an fRG formulation where both bare propagators and bare interactions can be dressed with regulators. The approach thus obtained is a generalization of the multiloop fRG recently introduced for many-fermion systems. Using the single-boson exchange decomposition, we show that the underlying flow equations are simply interpreted as adding a regulator to the bosonic propagator and that such an extension scarcely changes the original structure of the flow equations. Overall, we provide a framework for implementing approaches that cannot be realized with conventional fRG methods, such as temperature flows for models with retarded interactions. For concrete applications, we analyze the loop convergence of our scheme against conventional cutoff schemes for the Hubbard atom and the Anderson impurity model. Finally, we devise a new temperature-flow scheme that implements a cutoff in both the propagator and the bare interaction, and demonstrate its validity on a model of an Anderson impurity coupled to a phonon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u51fd\u6570\u91cd\u6574\u5316\u7fa4(fRG)\u65b9\u6cd5\uff0c\u5141\u8bb8\u540c\u65f6\u5bf9\u88f8\u4f20\u64ad\u5b50\u548c\u88f8\u76f8\u4e92\u4f5c\u7528\u8fdb\u884c\u8c03\u63a7\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u7684fRG\u65b9\u6cd5\uff0c\u4e3a\u5904\u7406\u5177\u6709\u5ef6\u8fdf\u76f8\u4e92\u4f5c\u7528\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002", "motivation": "\u4f20\u7edffRG\u65b9\u6cd5\u4ec5\u5bf9\u88f8\u4f20\u64ad\u5b50\u8fdb\u884c\u8c03\u63a7\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u901a\u7528\u7684fRG\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u8c03\u63a7\u4f20\u64ad\u5b50\u548c\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u5904\u7406\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u7684\u65b9\u6848\uff0c\u5982\u5177\u6709\u5ef6\u8fdf\u76f8\u4e92\u4f5c\u7528\u7684\u6a21\u578b\u7684\u6e29\u5ea6\u6d41\u3002", "method": "\u4eceSchwinger-Dyson\u548cBethe-Salpeter\u65b9\u7a0b\u51fa\u53d1\uff0c\u5f00\u53d1\u4e86\u540c\u65f6\u8c03\u63a7\u88f8\u4f20\u64ad\u5b50\u548c\u88f8\u76f8\u4e92\u4f5c\u7528\u7684fRG\u516c\u5f0f\u5316\u65b9\u6cd5\u3002\u4f7f\u7528\u5355\u73bb\u8272\u5b50\u4ea4\u6362\u5206\u89e3\uff0c\u5c06\u6d41\u65b9\u7a0b\u89e3\u91ca\u4e3a\u5bf9\u73bb\u8272\u5b50\u4f20\u64ad\u5b50\u6dfb\u52a0\u8c03\u63a7\u5668\u3002", "result": "\u65b0\u65b9\u6cd5\u4fdd\u6301\u4e86\u539f\u59cb\u6d41\u65b9\u7a0b\u7684\u57fa\u672c\u7ed3\u6784\uff0c\u4e3a\u4f20\u7edffRG\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u7684\u65b9\u6848\u63d0\u4f9b\u4e86\u6846\u67b6\u3002\u901a\u8fc7\u5bf9Hubbard\u539f\u5b50\u548cAnderson\u6742\u8d28\u6a21\u578b\u7684\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6848\u7684\u5faa\u73af\u6536\u655b\u6027\u3002\u5f00\u53d1\u4e86\u65b0\u7684\u6e29\u5ea6\u6d41\u65b9\u6848\uff0c\u5e76\u5728Anderson\u6742\u8d28\u8026\u5408\u58f0\u5b50\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6269\u5c55fRG\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86\u4f20\u7edffRG\u7684\u7075\u6d3b\u6027\uff0c\u4e3a\u5904\u7406\u66f4\u590d\u6742\u7684\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5177\u6709\u5ef6\u8fdf\u76f8\u4e92\u4f5c\u7528\u7684\u6a21\u578b\u65b9\u9762\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.18341", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.18341", "abs": "https://arxiv.org/abs/2511.18341", "authors": ["Mohammad Pouranvari"], "title": "Interplay of Power-Law correlated Disorder and Long-Range Hopping in One Dimension: Mobility Edges, Criticality, and ML-Based Phase Identification", "comment": "12 pages, 10 figures", "summary": "We investigate a one-dimensional tight-binding model in which onsite\n  potentials $\\{\\varepsilon_i\\}$ exhibit power-law spatial correlations\n  (with exponent $\u03b1$) and the hopping amplitudes decay as\n  $t_{ij}\\sim |i-j|^{-\u03b2}$. This two-parameter family interpolates\n  continuously between short-range Anderson-like disorder, correlated\n  disorder with conventional hopping, and long-range hopping models with\n  nontrivial delocalization tendencies. Using large-scale exact\n  diagonalization, we construct a comprehensive phase map in the\n  $(\u03b1,\u03b2)$ plane by combining spectral statistics, density-of-states\n  analysis, and energy-resolved localization indicators such as the\n  participation ratio, single-particle entanglement entropy, level-spacing\n  ratio $r$, and the ratio of the geometric to arithmetic density of\n  states. From these observables we define phase-indicator functions that\n  compactly quantify localization behaviour across the spectrum. Our analysis reveals robust mobility edges and multiple regimes of\n  spectral coexistence between localized, extended, resonant, and critical\n  states. Finite-size scaling, implemented via an explicit smoothness-based\n  cost function, enables extraction of critical exponents and delineation\n  of transition lines across the $(\u03b1,\u03b2)$ parameter space.\n  To validate and complement these physics-based diagnostics, we employ a\n  supervised autoencoder that learns high-level representations of\n  eigenstate structure directly from raw features and reliably reproduces\n  the phase classification defined by the indicator functions. Together,\n  these approaches provide a coherent and internally consistent picture of\n  the spectral transitions driven by correlated disorder and long-range\n  hopping, establishing a unified framework for characterizing mobility\n  edges in long-range one-dimensional systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u7ef4\u7d27\u675f\u7f1a\u6a21\u578b\uff0c\u5176\u4e2d\u5728\u4f4d\u52bf\u5177\u6709\u5e42\u5f8b\u7a7a\u95f4\u76f8\u5173\u6027\uff08\u6307\u6570\u03b1\uff09\uff0c\u8df3\u8dc3\u632f\u5e45\u4ee5|i-j|^{-\u03b2}\u8870\u51cf\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u7cbe\u786e\u5bf9\u89d2\u5316\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86(\u03b1,\u03b2)\u53c2\u6570\u7a7a\u95f4\u7684\u7efc\u5408\u76f8\u56fe\uff0c\u63ed\u793a\u4e86\u8fc1\u79fb\u7387\u8fb9\u548c\u591a\u79cd\u72b6\u6001\u5171\u5b58\u533a\u57df\u3002", "motivation": "\u7814\u7a76\u5e42\u5f8b\u76f8\u5173\u65e0\u5e8f\u548c\u957f\u7a0b\u8df3\u8dc3\u76f8\u4e92\u4f5c\u7528\u4e0b\u7684\u4e00\u7ef4\u7cfb\u7edf\uff0c\u63a2\u7d22\u4ece\u77ed\u7a0b\u5b89\u5fb7\u68ee\u65e0\u5e8f\u5230\u957f\u7a0b\u8df3\u8dc3\u6a21\u578b\u7684\u8fde\u7eed\u63d2\u503c\uff0c\u7406\u89e3\u76f8\u5173\u65e0\u5e8f\u548c\u957f\u7a0b\u8df3\u8dc3\u5982\u4f55\u9a71\u52a8\u8c31\u8f6c\u53d8\u548c\u8fc1\u79fb\u7387\u8fb9\u7684\u5f62\u6210\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u7cbe\u786e\u5bf9\u89d2\u5316\uff0c\u7ed3\u5408\u8c31\u7edf\u8ba1\u3001\u6001\u5bc6\u5ea6\u5206\u6790\u3001\u53c2\u4e0e\u6bd4\u3001\u5355\u7c92\u5b50\u7ea0\u7f20\u71b5\u3001\u80fd\u7ea7\u95f4\u8ddd\u6bd4\u7b49\u5c40\u57df\u5316\u6307\u6807\uff0c\u4ee5\u53ca\u76d1\u7763\u81ea\u7f16\u7801\u5668\u4ece\u539f\u59cb\u7279\u5f81\u4e2d\u5b66\u4e60\u672c\u5f81\u6001\u7ed3\u6784\u7684\u9ad8\u5c42\u8868\u793a\u3002", "result": "\u6784\u5efa\u4e86(\u03b1,\u03b2)\u53c2\u6570\u7a7a\u95f4\u7684\u7efc\u5408\u76f8\u56fe\uff0c\u53d1\u73b0\u4e86\u7a33\u5065\u7684\u8fc1\u79fb\u7387\u8fb9\u548c\u5c40\u57df\u5316\u3001\u6269\u5c55\u3001\u5171\u632f\u3001\u4e34\u754c\u72b6\u6001\u7684\u591a\u91cd\u8c31\u5171\u5b58\u533a\u57df\uff0c\u901a\u8fc7\u6709\u9650\u5c3a\u5bf8\u6807\u5ea6\u63d0\u53d6\u4e86\u4e34\u754c\u6307\u6570\u3002", "conclusion": "\u76f8\u5173\u65e0\u5e8f\u548c\u957f\u7a0b\u8df3\u8dc3\u9a71\u52a8\u4e86\u4e30\u5bcc\u7684\u8c31\u8f6c\u53d8\uff0c\u5efa\u7acb\u4e86\u8868\u5f81\u4e00\u7ef4\u957f\u7a0b\u7cfb\u7edf\u4e2d\u8fc1\u79fb\u7387\u8fb9\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7269\u7406\u8bca\u65ad\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u76f8\u4e92\u4e00\u81f4\u7684\u7cfb\u7edf\u56fe\u50cf\u3002"}}
{"id": "2511.18442", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.18442", "abs": "https://arxiv.org/abs/2511.18442", "authors": ["Declan Nell", "Milos Radonjic", "Ivan Rungger", "Liviu Chioncel", "Stefano Sanvito", "Andrea Droghetti"], "title": "A non-equilibrium quantum transport framework for spintronic devices with dynamical correlations", "comment": "22 pages, 13 figures", "summary": "Two-terminal spintronic devices remain challenging to model under realistic operating conditions, where the interplay of complex electronic structures, correlation effects and bias-driven non-equilibrium dynamics may significantly impact charge and spin transport. Existing {\\it ab initio} methods either capture bias-dependent transport but neglect dynamical correlations or include correlations but are restricted to equilibrium or linear-response regimes. To overcome these limitations, we present a framework for steady-state quantum transport, combining density functional theory (DFT), the non-equilibrium Greens' function (NEGF) method, and dynamical mean-field theory (DMFT). The framework is then applied to Cu/Co/vacuum/Cu and an Fe/MgO/Fe tunnel junction. In Co, correlations drive a transition from Fermi-liquid to non-Fermi-liquid behavior under finite bias, due to scattering of electrons with electron-hole pairs. In contrast, in the Fe/MgO/Fe junction, correlation effects are weaker: Fe remains close to equilibrium even at large biases. Nevertheless, inelastic scattering can still induce partly incoherent transport that modifies the device's response to the external bias. Overall, our framework provides a route to model spintronic devices beyond single-particle descriptions, while also suggesting new interpretations of experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408DFT\u3001NEGF\u548cDMFT\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u53cc\u7aef\u81ea\u65cb\u7535\u5b50\u5668\u4ef6\u5728\u7a33\u6001\u6761\u4ef6\u4e0b\u7684\u91cf\u5b50\u8f93\u8fd0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5904\u7406\u504f\u538b\u4f9d\u8d56\u8f93\u8fd0\u548c\u52a8\u6001\u76f8\u5173\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709ab initio\u65b9\u6cd5\u8981\u4e48\u80fd\u5904\u7406\u504f\u538b\u4f9d\u8d56\u8f93\u8fd0\u4f46\u5ffd\u7565\u52a8\u6001\u76f8\u5173\u6027\uff0c\u8981\u4e48\u5305\u542b\u76f8\u5173\u6027\u4f46\u4ec5\u9650\u4e8e\u5e73\u8861\u6216\u7ebf\u6027\u54cd\u5e94\u533a\u57df\uff0c\u65e0\u6cd5\u51c6\u786e\u6a21\u62df\u5b9e\u9645\u5de5\u4f5c\u6761\u4ef6\u4e0b\u7684\u81ea\u65cb\u7535\u5b50\u5668\u4ef6\u3002", "method": "\u7ed3\u5408\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba(DFT)\u3001\u975e\u5e73\u8861\u683c\u6797\u51fd\u6570(NEGF)\u65b9\u6cd5\u548c\u52a8\u6001\u5e73\u5747\u573a\u7406\u8bba(DMFT)\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7a33\u6001\u91cf\u5b50\u8f93\u8fd0\u6846\u67b6\u3002", "result": "\u5728Cu/Co/\u771f\u7a7a/Cu\u7ed3\u6784\u4e2d\uff0c\u76f8\u5173\u6027\u9a71\u52a8\u4e86\u4ece\u8d39\u7c73\u6db2\u4f53\u5230\u975e\u8d39\u7c73\u6db2\u4f53\u7684\u8f6c\u53d8\uff1b\u5728Fe/MgO/Fe\u96a7\u9053\u7ed3\u4e2d\uff0c\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u4f46\u975e\u5f39\u6027\u6563\u5c04\u4ecd\u80fd\u5f15\u8d77\u90e8\u5206\u975e\u76f8\u5e72\u8f93\u8fd0\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d85\u8d8a\u5355\u7c92\u5b50\u63cf\u8ff0\u7684\u81ea\u65cb\u7535\u5b50\u5668\u4ef6\u5efa\u6a21\u63d0\u4f9b\u4e86\u9014\u5f84\uff0c\u5e76\u4e3a\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u91ca\u89c6\u89d2\u3002"}}
{"id": "2511.17804", "categories": ["nlin.AO", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2511.17804", "abs": "https://arxiv.org/abs/2511.17804", "authors": ["Joao Liz\u00e1rraga", "Marcus de Aguiar"], "title": "Collective Turns in Spinless Flocks", "comment": "9 pages, 9 figures", "summary": "Using a minimal aggregation-based model, we address the efficient information transfer observed in natural flocks during collective turns. Specifically, we demonstrate that this feature can arise solely from the non-reciprocal nature of local interactions. Through a perturbative analysis, moreover, we find that velocity fluctuations (in the continuum) can be described by a Born approximation. We then show that a wave propagating across the flock undergoes scattering. Our model provides testable predictions and can be extended to study other physical contexts exhibiting polar order.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6700\u5c0f\u805a\u5408\u6a21\u578b\u7814\u7a76\u9e1f\u7fa4\u96c6\u4f53\u8f6c\u5f2f\u4e2d\u7684\u9ad8\u6548\u4fe1\u606f\u4f20\u9012\uff0c\u53d1\u73b0\u8fd9\u4e00\u7279\u6027\u6e90\u4e8e\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u7684\u975e\u4e92\u6613\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u901f\u5ea6\u6ce2\u52a8\u7684\u6270\u52a8\u5206\u6790\u548c\u6ce2\u6563\u5c04\u6a21\u578b\u3002", "motivation": "\u7814\u7a76\u81ea\u7136\u9e1f\u7fa4\u5728\u96c6\u4f53\u8f6c\u5f2f\u8fc7\u7a0b\u4e2d\u89c2\u5bdf\u5230\u7684\u6709\u6548\u4fe1\u606f\u4f20\u9012\u673a\u5236\uff0c\u63a2\u7d22\u8fd9\u79cd\u96c6\u4f53\u884c\u4e3a\u80cc\u540e\u7684\u7269\u7406\u539f\u7406\u3002", "method": "\u4f7f\u7528\u6700\u5c0f\u805a\u5408\u6a21\u578b\uff0c\u901a\u8fc7\u6270\u52a8\u5206\u6790\u7814\u7a76\u901f\u5ea6\u6ce2\u52a8\uff0c\u91c7\u7528Born\u8fd1\u4f3c\u63cf\u8ff0\u8fde\u7eed\u4ecb\u8d28\u4e2d\u7684\u6ce2\u52a8\uff0c\u5206\u6790\u6ce2\u5728\u7fa4\u4f53\u4e2d\u7684\u6563\u5c04\u8fc7\u7a0b\u3002", "result": "\u8bc1\u660e\u4e86\u9ad8\u6548\u4fe1\u606f\u4f20\u9012\u53ef\u4ee5\u4ec5\u7531\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u7684\u975e\u4e92\u6613\u6027\u4ea7\u751f\uff0c\u5efa\u7acb\u4e86\u901f\u5ea6\u6ce2\u52a8\u7684\u6270\u52a8\u5206\u6790\u6846\u67b6\uff0c\u53d1\u73b0\u6ce2\u5728\u7fa4\u4f53\u4e2d\u4f20\u64ad\u65f6\u4f1a\u53d1\u751f\u6563\u5c04\u3002", "conclusion": "\u8be5\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6d4b\u8bd5\u7684\u9884\u6d4b\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u7814\u7a76\u5176\u4ed6\u5177\u6709\u6781\u6027\u5e8f\u7684\u7269\u7406\u7cfb\u7edf\u3002"}}
{"id": "2511.17684", "categories": ["cond-mat.stat-mech", "cs.IT", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.17684", "abs": "https://arxiv.org/abs/2511.17684", "authors": ["Kenric P. Nelson"], "title": "On the uniqueness of the coupled entropy", "comment": "32 pages, 6 figures, 1 Table, supersedes the pre-print \"Coupled Entropy: A Goldilocks Generalization for Complex Systems\"", "summary": "The coupled entropy is proven to uniquely satisfy the requirement that a generalized entropy be equivalent to the density at the scale for scale-shape distributions. Further, its maximizing distributions, the coupled stretched exponential distributions, are proven to quantify the linear uncertainty with the scale and the nonlinear uncertainty with the shape for a broad class of complex systems. Distributions of the coupled exponentials include the Pareto Types I-IV and Gosset's Student-t. For the Pareto Type II distribution, the Boltzmann-Gibbs-Shannon entropy has a linear dependence on the shape, which dominates over the logarithmic dependence on the scale, motivating the need for a generalization. The R\u00e9nyi and Tsallis entropies are shown to be of historic importance but ultimately unsatisfactory generalizations. The coupled entropy of the coupled stretched exponential distribution isolates the nonlinear-shape dependence to a generalized logarithm of the partition function. The R\u00e9nyi and Tsallis entropies retain a strong dependence on the nonlinear-shape such that they are not equivalent to the uncertainty at the scale. Lemmas for the composability and extensivity of the coupled entropy are proven in support of an axiomatic definition. The scope of the coupled entropy includes systems in which the growth of states is power-law, stretched exponential, or a combination.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u8026\u5408\u71b5\u662f\u552f\u4e00\u6ee1\u8db3\u5e7f\u4e49\u71b5\u5728\u5c3a\u5ea6-\u5f62\u72b6\u5206\u5e03\u4e2d\u4e0e\u5c3a\u5ea6\u5bc6\u5ea6\u7b49\u4ef7\u8981\u6c42\u7684\u71b5\u5ea6\u91cf\u3002\u8026\u5408\u62c9\u4f38\u6307\u6570\u5206\u5e03\u4f5c\u4e3a\u5176\u6700\u5927\u5316\u5206\u5e03\uff0c\u80fd\u591f\u91cf\u5316\u590d\u6742\u7cfb\u7edf\u4e2d\u5c3a\u5ea6\u7684\u7ebf\u6027\u4e0d\u786e\u5b9a\u6027\u548c\u5f62\u72b6\u7684\u975e\u7ebf\u6027\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u71b5\u5ea6\u91cf\uff08\u5982Boltzmann-Gibbs-Shannon\u71b5\uff09\u5728Pareto Type II\u5206\u5e03\u4e2d\u8868\u73b0\u51fa\u5bf9\u5f62\u72b6\u7684\u7ebf\u6027\u4f9d\u8d56\u6027\uff0c\u8fd9\u4e3b\u5bfc\u4e86\u5bf9\u5c3a\u5ea6\u7684\u5bf9\u6570\u4f9d\u8d56\u6027\uff0c\u8868\u660e\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u71b5\u5ea6\u91cf\u3002R\u00e9nyi\u548cTsallis\u71b5\u4f5c\u4e3a\u5386\u53f2\u91cd\u8981\u4f46\u6700\u7ec8\u4e0d\u4ee4\u4eba\u6ee1\u610f\u7684\u63a8\u5e7f\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u8026\u5408\u71b5\u5728\u5c3a\u5ea6-\u5f62\u72b6\u5206\u5e03\u4e2d\u7684\u552f\u4e00\u6027\uff0c\u5e76\u5206\u6790\u5176\u6700\u5927\u5316\u5206\u5e03\uff08\u8026\u5408\u62c9\u4f38\u6307\u6570\u5206\u5e03\uff09\u7684\u6027\u8d28\u3002\u8bc1\u660e\u4e86\u8026\u5408\u71b5\u7684\u53ef\u7ec4\u5408\u6027\u548c\u5e7f\u5ef6\u6027\u5f15\u7406\uff0c\u652f\u6301\u5176\u516c\u7406\u5316\u5b9a\u4e49\u3002", "result": "\u8026\u5408\u71b5\u80fd\u591f\u9694\u79bb\u975e\u7ebf\u6027\u5f62\u72b6\u4f9d\u8d56\u6027\u5230\u914d\u5206\u51fd\u6570\u7684\u5e7f\u4e49\u5bf9\u6570\u4e2d\uff0c\u800cR\u00e9nyi\u548cTsallis\u71b5\u4ecd\u4fdd\u6301\u5bf9\u975e\u7ebf\u6027\u5f62\u72b6\u7684\u5f3a\u4f9d\u8d56\u6027\u3002\u8026\u5408\u62c9\u4f38\u6307\u6570\u5206\u5e03\u5305\u62ecPareto Types I-IV\u548cGosset's Student-t\u5206\u5e03\u3002", "conclusion": "\u8026\u5408\u71b5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5e7f\u4e49\u71b5\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u72b6\u6001\u589e\u957f\u4e3a\u5e42\u5f8b\u3001\u62c9\u4f38\u6307\u6570\u6216\u5176\u7ec4\u5408\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u66f4\u597d\u5730\u91cf\u5316\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2511.17545", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17545", "abs": "https://arxiv.org/abs/2511.17545", "authors": ["Frederik Koch", "Shahram Panahiyan", "Rick Mukherjee", "Joseph Doetsch", "Dieter Jaksch"], "title": "Resource-Efficient Quantum Optimization via Higher-Order Encoding", "comment": "24 pages, 18 figures", "summary": "Quantum approaches to combinatorial optimization problems (COPs) are often limited by the resource demands of Quadratic Unconstrained Binary Optimization (QUBO) encodings, which enlarge circuits through penalty terms and increase qubit and gate counts. We show that Higher-Order Unconstrained Binary Optimization (HUBO) enables a more resource-efficient formulation. Our method systematically constructs HUBO Hamiltonians and, compared to QUBO in benchmarks on Gate Assignment (GAP), Maximum k-Colorable Subgraph (MkCS), and Integer Programming (IP) problems, exponentially reduces qubit requirements and decreases CNOT gate counts by at least 89.6% after compilation to single- and two-qubit gates for all tested instances. These results highlight HUBO as a practical alternative for current and near-term devices. To promote adoption, we release an open-source Python library that automates HUBO model construction, broadening access to resource-efficient quantum optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u9ad8\u9636\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\uff08HUBO\uff09\u4f5c\u4e3a\u91cf\u5b50\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u66f4\u8d44\u6e90\u9ad8\u6548\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684QUBO\u7f16\u7801\uff0c\u5728\u95e8\u5206\u914d\u3001\u6700\u5927k\u53ef\u7740\u8272\u5b50\u56fe\u548c\u6574\u6570\u89c4\u5212\u95ee\u9898\u4e0a\u663e\u8457\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u9700\u6c42\u548cCNOT\u95e8\u6570\u91cf\u3002", "motivation": "\u4f20\u7edfQUBO\u7f16\u7801\u65b9\u6cd5\u5728\u91cf\u5b50\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7531\u4e8e\u60e9\u7f5a\u9879\u5bfc\u81f4\u7535\u8def\u89c4\u6a21\u6269\u5927\uff0c\u589e\u52a0\u4e86\u91cf\u5b50\u6bd4\u7279\u548c\u91cf\u5b50\u95e8\u7684\u9700\u6c42\uff0c\u9650\u5236\u4e86\u91cf\u5b50\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u6784\u5efaHUBO\u54c8\u5bc6\u987f\u91cf\uff0c\u5e76\u5c06\u5176\u4e0eQUBO\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u95ee\u9898\u4e0a\u8fdb\u884c\u6bd4\u8f83\uff0c\u5305\u62ec\u95e8\u5206\u914d\u95ee\u9898\u3001\u6700\u5927k\u53ef\u7740\u8272\u5b50\u56fe\u95ee\u9898\u548c\u6574\u6570\u89c4\u5212\u95ee\u9898\u3002", "result": "\u76f8\u6bd4QUBO\u65b9\u6cd5\uff0cHUBO\u65b9\u6cd5\u5728\u6240\u6709\u6d4b\u8bd5\u5b9e\u4f8b\u4e2d\u6307\u6570\u7ea7\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u9700\u6c42\uff0c\u5e76\u5c06CNOT\u95e8\u6570\u91cf\u51cf\u5c11\u4e86\u81f3\u5c1189.6%\u3002", "conclusion": "HUBO\u662f\u5f53\u524d\u548c\u8fd1\u671f\u91cf\u5b50\u8bbe\u5907\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u4f5c\u8005\u53d1\u5e03\u4e86\u5f00\u6e90Python\u5e93\u4ee5\u4fc3\u8fdbHUBO\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6784\u5efa\u548c\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2511.17541", "categories": ["cs.AI", "cs.IT", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.17541", "abs": "https://arxiv.org/abs/2511.17541", "authors": ["Seyma Yaman Kayadibi"], "title": "Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation", "comment": null, "summary": "This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.", "AI": {"tldr": "\u57fa\u4e8e\u83b1\u5e03\u5c3c\u8328\u5355\u5b50\u8bba\u6784\u5efa\u4e86\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u8bb0\u5fc6\u7cfb\u7edf\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c0620\u4e2a\u6838\u5fc3\u54f2\u5b66\u547d\u9898\u6620\u5c04\u5230\u4fe1\u606f\u8bba\u67b6\u6784\u4e2d\uff0c\u6bcf\u4e2a\u5355\u5b50\u4f5c\u4e3a\u6a21\u5757\u5316\u5355\u5143\uff0c\u5305\u542b\u771f\u503c\u5206\u6570\u3001\u5197\u4f59\u53c2\u6570\u548c\u5168\u5c40\u8bb0\u5fc6\u60e9\u7f5a\u51fd\u6570\u8d21\u732e\u6743\u91cd\u3002", "motivation": "\u4e3a\u4eba\u5de5\u667a\u80fd\u8bb0\u5fc6\u7cfb\u7edf\u5f00\u53d1\u4e00\u4e2a\u6570\u5b66\u4e25\u8c28\u3001\u54f2\u5b66\u57fa\u7840\u575a\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u83b1\u5e03\u5c3c\u8328\u5355\u5b50\u8bba\u7684\u5f62\u800c\u4e0a\u5b66\u7ed3\u6784\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u8bc1\u660e\u53ef\u9760\u7684\u5185\u5b58\u67b6\u6784\u8bbe\u8ba1\u84dd\u56fe\u3002", "method": "\u5c06\u5355\u5b50\u8bba\u7684\u6838\u5fc3\u547d\u9898\u6620\u5c04\u5230\u4fe1\u606f\u8bba\u67b6\u6784\uff0c\u6bcf\u4e2a\u5355\u5b50\u5b9a\u4e49\u4e3a\u5177\u6709\u771f\u503c\u5206\u6570\u3001\u5197\u4f59\u53c2\u6570\u548c\u52a0\u6743\u8d21\u732e\u7684\u6a21\u5757\u5316\u5355\u5143\uff0c\u4f7f\u7528\u5e73\u6ed1\u5bf9\u6570\u53d8\u6362\u64cd\u4f5c\u5316\u8fd9\u4e9b\u91cf\uff0c\u5e76\u5c06\u5f62\u800c\u4e0a\u5b66\u6982\u5ff5\u91cd\u65b0\u8868\u8ff0\u4e3a\u71b5\u3001\u68af\u5ea6\u52a8\u6001\u548c\u5185\u90e8\u8868\u793a\u4fdd\u771f\u5ea6\u3002", "result": "\u5efa\u7acb\u4e86\u7cbe\u70bc\u4e0d\u53d8\u6027\u3001\u7ed3\u6784\u53ef\u5206\u89e3\u6027\u548c\u5c3a\u5ea6\u53d8\u6362\u4e0b\u7684\u5355\u8c03\u6027\u7b49\u7b2c\u4e00\u539f\u7406\u8bc1\u660e\uff0c\u6846\u67b6\u5206\u4e3a\u516d\u4e2a\u4e3b\u9898\u675f\uff0c\u6bcf\u4e2a\u6570\u5b66\u8bc1\u660e\u4e0e\u5176\u5bf9\u5e94\u7684\u54f2\u5b66\u9886\u57df\u5bf9\u9f50\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u8bc4\u4f30\u5de5\u5177\uff0c\u8fd8\u4e3a\u6784\u5efa\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u8bc1\u660e\u53ef\u9760\u7684\u4eba\u5de5\u667a\u80fd\u8bb0\u5fc6\u67b6\u6784\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u84dd\u56fe\uff0c\u5c06\u7ecf\u5178\u5f62\u800c\u4e0a\u5b66\u6982\u5ff5\u4e0e\u73b0\u4ee3\u4fe1\u606f\u8bba\u76f8\u7ed3\u5408\u3002"}}
{"id": "2511.17553", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17553", "abs": "https://arxiv.org/abs/2511.17553", "authors": ["Jason M. Pittman", "Anton Phillips", "Yesenia Medina-Santos", "Brielle C. Stark"], "title": "Practical Machine Learning for Aphasic Discourse Analysis", "comment": "14 pages, 4 tables, 2 figures", "summary": "Analyzing spoken discourse is a valid means of quantifying language ability in persons with aphasia. There are many ways to quantify discourse, one common way being to evaluate the informativeness of the discourse. That is, given the total number of words produced, how many of those are context-relevant and accurate. This type of analysis is called Correct Information Unit (CIU) analysis and is one of the most prevalent discourse analyses used by speech-language pathologists (SLPs). Despite this, CIU analysis in the clinic remains limited due to the manual labor needed by SLPs to code and analyze collected speech. Recent advances in machine learning (ML) seek to augment such labor by automating modeling of propositional, macrostructural, pragmatic, and multimodal dimensions of discourse. To that end, this study evaluated five ML models for reliable identification of Correct Information Units (CIUs, Nicholas & Brookshire, 1993), during a picture description task. The five supervised ML models were trained using randomly selected human-coded transcripts and accompanying words and CIUs from persons with aphasia. The baseline model training produced a high accuracy across transcripts for word vs non-word, with all models achieving near perfect performance (0.995) with high AUC range (0.914 min, 0.995 max). In contrast, CIU vs non-CIU showed a greater variability, with the k-nearest neighbor (k-NN) model the highest accuracy (0.824) and second highest AUC (0.787). These findings indicate that while the supervised ML models can distinguish word from not word, identifying CIUs is challenging.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e94\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5931\u8bed\u75c7\u60a3\u8005\u56fe\u7247\u63cf\u8ff0\u4efb\u52a1\u4e2d\u81ea\u52a8\u8bc6\u522b\u6b63\u786e\u4fe1\u606f\u5355\u5143(CIU)\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u533a\u5206\u5355\u8bcd\u4e0e\u975e\u5355\u8bcd\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u8bc6\u522bCIU\u65b9\u9762\u4ecd\u6709\u6311\u6218\u3002", "motivation": "CIU\u5206\u6790\u662f\u91cf\u5316\u5931\u8bed\u75c7\u60a3\u8005\u8bed\u8a00\u80fd\u529b\u7684\u91cd\u8981\u65b9\u6cd5\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u8a00\u8bed\u75c5\u7406\u5b66\u5bb6\u624b\u52a8\u7f16\u7801\u548c\u5206\u6790\uff0c\u4e34\u5e8a\u5e94\u7528\u53d7\u9650\u3002\u673a\u5668\u5b66\u4e60\u6280\u672f\u6709\u671b\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u51cf\u8f7b\u4e34\u5e8a\u5de5\u4f5c\u8d1f\u62c5\u3002", "method": "\u4f7f\u7528\u4e94\u79cd\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u57fa\u4e8e\u5931\u8bed\u75c7\u60a3\u8005\u7684\u4eba\u7c7b\u7f16\u7801\u8f6c\u5f55\u672c\u53ca\u5176\u5355\u8bcd\u548cCIU\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u56fe\u7247\u63cf\u8ff0\u4efb\u52a1\u4e2d\u8bc6\u522bCIU\u7684\u53ef\u9760\u6027\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u533a\u5206\u5355\u8bcd\u4e0e\u975e\u5355\u8bcd\u65b9\u9762\u8868\u73b0\u4f18\u5f02(\u51c6\u786e\u73870.995\uff0cAUC\u8303\u56f40.914-0.995)\uff0c\u4f46\u5728\u8bc6\u522bCIU\u65b9\u9762\u8868\u73b0\u5dee\u5f02\u8f83\u5927\uff0ck-NN\u6a21\u578b\u8868\u73b0\u6700\u4f73(\u51c6\u786e\u73870.824\uff0cAUC 0.787)\u3002", "conclusion": "\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u6709\u6548\u533a\u5206\u5355\u8bcd\u4e0e\u975e\u5355\u8bcd\uff0c\u4f46\u51c6\u786e\u8bc6\u522bCIU\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.18526", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.18526", "abs": "https://arxiv.org/abs/2511.18526", "authors": ["D. A. Kukusta", "L. V. Bekenov", "P. F. Perndorfer", "D. V. Vyalikh", "P. A. Buczek", "A. Ernst", "V. N. Antonov"], "title": "Ab initio modeling of resonant inelastic x-ray scattering from Ca2RuO4", "comment": "14 pages, 14 figures", "summary": "The single-layered perovskite Ca$_2$RuO$_4$, characterized by a 4$d^4$ electron configuration, has been studied from first principles using density functional theory (DFT) using the generalized gradient approximation, with inclusion of strong on-site Coulomb interactions and spin-orbit coupling (GGA+SO+$U$), in the framework of the fully relativistic, spin-polarized Dirac linear muffin-tin orbital (LMTO) band-structure method. This approach enabled a comprehensive investigation of the electronic structure of Ca$_2$RuO$_4$ through the modeling of relevant spectra obtained from synchrotron-based techniques widely used to probe electronic properties, with a primary focus on resonant inelastic X-ray scattering (RIXS) at the Ru $L_3$ and O $K$ edges. The calculated spectra were thoroughly analyzed with available experimental data reported in the literature. The good agreement between our results and experimental observations for Ca$_2$RuO$_4$ enables a conclusive interpretation of key features in the spectra obtained from the aforementioned techniques. Consequently, this enables us to describe its electronic properties and to establish a solid theoretical approach suitable for routine modeling of spectra, particularly from RIXS, aimed at characterizing the electronic structure and properties of similar or more complex strongly correlated, technologically relevant materials.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528DFT+SO+U\u65b9\u6cd5\u7ed3\u5408LMTO\u80fd\u5e26\u7ed3\u6784\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86Ca2RuO4\u7684\u7535\u5b50\u7ed3\u6784\uff0c\u91cd\u70b9\u5206\u6790\u4e86Ru L3\u548cO K\u8fb9\u7684RIXS\u5149\u8c31\uff0c\u5e76\u4e0e\u5b9e\u9a8c\u6570\u636e\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "motivation": "\u7814\u7a76Ca2RuO4\u7684\u7535\u5b50\u7ed3\u6784\uff0c\u5efa\u7acb\u9002\u7528\u4e8e\u590d\u6742\u5f3a\u5173\u8054\u6750\u6599\u5149\u8c31\u5efa\u6a21\u7684\u7406\u8bba\u65b9\u6cd5\uff0c\u7279\u522b\u662fRIXS\u6280\u672f\u3002", "method": "\u91c7\u7528\u7b2c\u4e00\u6027\u539f\u7406\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba(DFT)\uff0c\u7ed3\u5408\u5e7f\u4e49\u68af\u5ea6\u8fd1\u4f3c\u3001\u5f3a\u5728\u4f4d\u5e93\u4ed1\u76f8\u4e92\u4f5c\u7528\u548c\u81ea\u65cb\u8f68\u9053\u8026\u5408(GGA+SO+U)\uff0c\u4f7f\u7528\u5b8c\u5168\u76f8\u5bf9\u8bba\u81ea\u65cb\u6781\u5316Dirac\u7ebf\u6027\u677e\u997c\u7403\u8f68\u9053(LMTO)\u80fd\u5e26\u7ed3\u6784\u65b9\u6cd5\u3002", "result": "\u8ba1\u7b97\u7684\u5149\u8c31\u4e0e\u5b9e\u9a8c\u89c2\u6d4b\u7ed3\u679c\u543b\u5408\u826f\u597d\uff0c\u80fd\u591f\u5408\u7406\u89e3\u91caRIXS\u5149\u8c31\u4e2d\u7684\u5173\u952e\u7279\u5f81\uff0c\u6210\u529f\u63cf\u8ff0\u4e86Ca2RuO4\u7684\u7535\u5b50\u6027\u8d28\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u9760\u7684\u7406\u8bba\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u5e38\u89c4\u5efa\u6a21\u590d\u6742\u5f3a\u5173\u8054\u6750\u6599\u7684\u5149\u8c31\uff0c\u7279\u522b\u662fRIXS\u5149\u8c31\uff0c\u4e3a\u8868\u5f81\u7c7b\u4f3c\u6750\u6599\u7684\u7535\u5b50\u7ed3\u6784\u548c\u6027\u8d28\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.18360", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.18360", "abs": "https://arxiv.org/abs/2511.18360", "authors": ["Ayumi Ozawa", "Yoji Kawamura"], "title": "Phase reduction of reaction-diffusion systems with delay", "comment": "12 pages, 7 figures", "summary": "We develop a phase reduction method for reaction-diffusion systems with a discrete delay. On the basis of the recent developments in the phase reduction theory for infinite-dimensional systems, we introduce a bilinear form tailored to spatially extended systems involving a discrete delay. By solving the adjoint equation associated with the bilinear form, we obtain the phase sensitivity function, which quantifies the shift of the phase in response to a given perturbation. The theory is verified numerically with the use of the Schnakenberg system with a discrete delay in one spatial dimension. We further demonstrate the utility of the theory by optimizing the interaction between a pair of the Schnakenberg systems, with the use of the phase equation, for maximizing the stability of in-phase synchronization. This study serves as a step towards establishing a theory for analyzing oscillatory systems that involve both spatial degrees of freedom and delay.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u9488\u5bf9\u5177\u6709\u79bb\u6563\u5ef6\u8fdf\u7684\u53cd\u5e94-\u6269\u6563\u7cfb\u7edf\u7684\u76f8\u4f4d\u7ea6\u7b80\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u9002\u5408\u7a7a\u95f4\u6269\u5c55\u7cfb\u7edf\u7684\u53cc\u7ebf\u6027\u5f62\u5f0f\uff0c\u6c42\u89e3\u4f34\u968f\u65b9\u7a0b\u5f97\u5230\u76f8\u4f4d\u654f\u611f\u5ea6\u51fd\u6570\uff0c\u5e76\u5728Schnakenberg\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\uff0c\u8fd8\u5c55\u793a\u4e86\u5728\u540c\u6b65\u7a33\u5b9a\u6027\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u5efa\u7acb\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5904\u7406\u7a7a\u95f4\u81ea\u7531\u5ea6\u548c\u5ef6\u8fdf\u7684\u632f\u8361\u7cfb\u7edf\u5206\u6790\u7406\u8bba\uff0c\u586b\u8865\u73b0\u6709\u76f8\u4f4d\u7ea6\u7b80\u65b9\u6cd5\u5728\u5ef6\u8fdf\u53cd\u5e94-\u6269\u6563\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u7a7a\u767d\u3002", "method": "\u57fa\u4e8e\u65e0\u9650\u7ef4\u7cfb\u7edf\u76f8\u4f4d\u7ea6\u7b80\u7406\u8bba\uff0c\u5f15\u5165\u9488\u5bf9\u79bb\u6563\u5ef6\u8fdf\u7a7a\u95f4\u6269\u5c55\u7cfb\u7edf\u7684\u53cc\u7ebf\u6027\u5f62\u5f0f\uff0c\u6c42\u89e3\u4f34\u968f\u65b9\u7a0b\u83b7\u5f97\u76f8\u4f4d\u654f\u611f\u5ea6\u51fd\u6570\uff0c\u5e76\u5728\u4e00\u7ef4Schnakenberg\u7cfb\u7edf\u4e2d\u8fdb\u884c\u6570\u503c\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u63a8\u5bfc\u51fa\u76f8\u4f4d\u654f\u611f\u5ea6\u51fd\u6570\uff0c\u80fd\u591f\u91cf\u5316\u76f8\u4f4d\u5bf9\u6270\u52a8\u7684\u54cd\u5e94\uff1b\u6570\u503c\u9a8c\u8bc1\u8868\u660e\u7406\u8bba\u6709\u6548\uff1b\u901a\u8fc7\u76f8\u4f4d\u65b9\u7a0b\u4f18\u5316\u4e86Schnakenberg\u7cfb\u7edf\u5bf9\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u63d0\u9ad8\u4e86\u540c\u76f8\u540c\u6b65\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5206\u6790\u540c\u65f6\u6d89\u53ca\u7a7a\u95f4\u81ea\u7531\u5ea6\u548c\u5ef6\u8fdf\u7684\u632f\u8361\u7cfb\u7edf\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u662f\u5411\u5b8c\u6574\u7406\u8bba\u6846\u67b6\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.18501", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.18501", "abs": "https://arxiv.org/abs/2511.18501", "authors": ["Niklas Forner", "Alexander Maloney", "Bernd Rosenow"], "title": "BBP Phase Transition for an Extensive Number of Outliers", "comment": "6 pages, 2 pages Appendix", "summary": "Random-matrix theory helps disentangle signal from noise in large data sets. We analyze rectangular $p \\times q$ matrices $W = W_0 + M$ in which the noise $M$ generates a Marchenko-Pastur bulk, whereas the signal $W_0$ injects an extensive set of degenerate singular values. Keeping $\\mathrm{rank}$ $W_0/q$ finite as $p,q \\to \\infty$, we show that the singular value density obeys a quartic equation and derive explicit asymptotics in the strong-signal regime. The resulting generalized Baik-Ben Arous-P\u00e9ch\u00e9 phase diagram yields a scaling law for the critical signal strength and clarifies how a finite density of spikes reshapes the bulk edges. Numerical simulations validate the theory and illustrate its relevance for high-dimensional inference tasks.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u5206\u6790\u4fe1\u53f7\u4e0e\u566a\u58f0\u5206\u79bb\u95ee\u9898\uff0c\u7814\u7a76\u5305\u542b\u9000\u5316\u5947\u5f02\u503c\u7684\u77e9\u5f62\u77e9\u9635\uff0c\u63a8\u5bfc\u51fa\u5947\u5f02\u503c\u5bc6\u5ea6\u7684\u56db\u6b21\u65b9\u7a0b\uff0c\u5efa\u7acb\u4e86\u5e7f\u4e49BBP\u76f8\u56fe\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7406\u8bba\u5728\u9ad8\u7ef4\u63a8\u65ad\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u5728\u5927\u6570\u636e\u96c6\u4e2d\u533a\u5206\u4fe1\u53f7\u4e0e\u566a\u58f0\u662f\u91cd\u8981\u95ee\u9898\uff0c\u968f\u673a\u77e9\u9635\u7406\u8bba\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u5305\u542b\u9000\u5316\u5947\u5f02\u503c\u7684\u77e9\u5f62\u77e9\u9635\uff0c\u7406\u89e3\u4fe1\u53f7\u5f3a\u5ea6\u5982\u4f55\u5f71\u54cd\u5947\u5f02\u503c\u5206\u5e03\u3002", "method": "\u5206\u6790p\u00d7q\u77e9\u5f62\u77e9\u9635W=W\u2080+M\uff0c\u5176\u4e2dM\u4ea7\u751fMarchenko-Pastur\u4f53\uff0cW\u2080\u6ce8\u5165\u9000\u5316\u5947\u5f02\u503c\u3002\u5728\u4fdd\u6301rank W\u2080/q\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u63a8\u5bfc\u5947\u5f02\u503c\u5bc6\u5ea6\u7684\u56db\u6b21\u65b9\u7a0b\uff0c\u5e76\u5728\u5f3a\u4fe1\u53f7\u673a\u5236\u4e0b\u83b7\u5f97\u663e\u5f0f\u6e10\u8fd1\u89e3\u3002", "result": "\u5efa\u7acb\u4e86\u5e7f\u4e49Baik-Ben Arous-P\u00e9ch\u00e9\u76f8\u56fe\uff0c\u5f97\u5230\u4e86\u4e34\u754c\u4fe1\u53f7\u5f3a\u5ea6\u7684\u6807\u5ea6\u5f8b\uff0c\u9610\u660e\u4e86\u6709\u9650\u5bc6\u5ea6\u5c16\u5cf0\u5982\u4f55\u91cd\u5851\u4f53\u8fb9\u7f18\u3002\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3a\u9ad8\u7ef4\u63a8\u65ad\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u63cf\u8ff0\u4fe1\u53f7\u5f3a\u5ea6\u4e0e\u5947\u5f02\u503c\u5206\u5e03\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5728\u4fe1\u53f7\u68c0\u6d4b\u548c\u566a\u58f0\u5206\u79bb\u65b9\u9762\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.17851", "categories": ["cond-mat.stat-mech", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.17851", "abs": "https://arxiv.org/abs/2511.17851", "authors": ["Hiroyoshi Nakano", "Yuki Minami"], "title": "Dissipation anomaly in gradient-driven nonequilibrium steady states", "comment": "6 pages + 2 pages + 10 pages, 5 figures", "summary": "Dissipation anomaly-the persistence of finite energy dissipation in the inviscid limit-is a hallmark of turbulence, sometimes regarded as the \"zeroth law\" of turbulent flows. Here, we demonstrate that this phenomenon is not exclusive to turbulence. Using fluctuating hydrodynamics, we show that a simple gradient-driven nonequilibrium steady state, in which a fluid is subjected to a constant scalar gradient but remains macroscopically quiescent, also exhibits dissipation anomaly. Direct numerical simulations and self-consistent mode-coupling theory reveal that the anomaly originates from giant, long-range nonequilibrium fluctuations amplified by the imposed gradient. While linear theory predicts a divergent dissipation in the inviscid limit, nonlinear mode coupling regularizes the divergence, yielding a finite anomalous dissipation. Our findings identify a new, non-turbulent arena for dissipation anomaly and establish the interplay between thermal noise and nonequilibrium driving as a fundamental route to singular behavior in hydrodynamics.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u8017\u6563\u5f02\u5e38\u73b0\u8c61\u4e0d\u4ec5\u5b58\u5728\u4e8e\u6e4d\u6d41\u4e2d\uff0c\u4e5f\u51fa\u73b0\u5728\u7b80\u5355\u7684\u68af\u5ea6\u9a71\u52a8\u975e\u5e73\u8861\u7a33\u6001\u7cfb\u7edf\u4e2d\u3002\u901a\u8fc7\u6570\u503c\u6a21\u62df\u548c\u7406\u8bba\u5206\u6790\uff0c\u53d1\u73b0\u8be5\u5f02\u5e38\u6e90\u4e8e\u68af\u5ea6\u653e\u5927\u7684\u5de8\u5927\u957f\u7a0b\u975e\u5e73\u8861\u6da8\u843d\u3002", "motivation": "\u8017\u6563\u5f02\u5e38\u901a\u5e38\u88ab\u8ba4\u4e3a\u662f\u6e4d\u6d41\u7684\u7279\u5f81\u73b0\u8c61\uff0c\u4f46\u672c\u6587\u65e8\u5728\u63a2\u7d22\u8fd9\u4e00\u73b0\u8c61\u662f\u5426\u4e5f\u5b58\u5728\u4e8e\u5176\u4ed6\u975e\u6e4d\u6d41\u7cfb\u7edf\u4e2d\uff0c\u7279\u522b\u662f\u7b80\u5355\u7684\u68af\u5ea6\u9a71\u52a8\u975e\u5e73\u8861\u7a33\u6001\u3002", "method": "\u4f7f\u7528\u6da8\u843d\u6d41\u4f53\u52a8\u529b\u5b66\u65b9\u6cd5\uff0c\u7ed3\u5408\u76f4\u63a5\u6570\u503c\u6a21\u62df\u548c\u81ea\u6d3d\u6a21\u5f0f\u8026\u5408\u7406\u8bba\uff0c\u5206\u6790\u5728\u6052\u5b9a\u6807\u91cf\u68af\u5ea6\u4f5c\u7528\u4e0b\u4f46\u5b8f\u89c2\u9759\u6b62\u7684\u6d41\u4f53\u7cfb\u7edf\u3002", "result": "\u53d1\u73b0\u7ebf\u6027\u7406\u8bba\u9884\u6d4b\u5728\u65e0\u7c98\u6781\u9650\u4e0b\u8017\u6563\u53d1\u6563\uff0c\u4f46\u975e\u7ebf\u6027\u6a21\u5f0f\u8026\u5408\u4f7f\u53d1\u6563\u6b63\u5219\u5316\uff0c\u4ea7\u751f\u6709\u9650\u7684\u5f02\u5e38\u8017\u6563\u3002\u68af\u5ea6\u653e\u5927\u7684\u70ed\u6da8\u843d\u662f\u5f02\u5e38\u8017\u6563\u7684\u6765\u6e90\u3002", "conclusion": "\u8017\u6563\u5f02\u5e38\u4e0d\u4ec5\u9650\u4e8e\u6e4d\u6d41\uff0c\u4e5f\u5b58\u5728\u4e8e\u7b80\u5355\u7684\u975e\u5e73\u8861\u7a33\u6001\u7cfb\u7edf\uff0c\u63ed\u793a\u4e86\u70ed\u6da8\u843d\u548c\u975e\u5e73\u8861\u9a71\u52a8\u76f8\u4e92\u4f5c\u7528\u4f5c\u4e3a\u6d41\u4f53\u52a8\u529b\u5b66\u5947\u5f02\u884c\u4e3a\u7684\u57fa\u672c\u9014\u5f84\u3002"}}
{"id": "2511.17667", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17667", "abs": "https://arxiv.org/abs/2511.17667", "authors": ["Viktoriia Omelchenko"], "title": "On fast charged particle scattering by periodic atomic planes: quadratic potential corrections", "comment": "17 pages, 8 figures", "summary": "In this paper, the approach for considering fast charged particles scattering on targets of complex structure, which contains some isolated substructures, was expanded to account quadratic potential terms. Based on this approach, the differential cross section for scattering on the set of parallel planes with uniformly distributed atoms in each plane was obtained. It was shown that for this case the differential scattering cross section splits into coherent and incohent cross sections in the eikonal approximation analogously with the Born approximation.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u8003\u8651\u5feb\u901f\u5e26\u7535\u7c92\u5b50\u5728\u5305\u542b\u5b64\u7acb\u5b50\u7ed3\u6784\u7684\u590d\u6742\u7ed3\u6784\u9776\u4e0a\u6563\u5c04\u7684\u65b9\u6cd5\uff0c\u4ee5\u5305\u542b\u4e8c\u6b21\u52bf\u9879\u3002\u57fa\u4e8e\u8be5\u65b9\u6cd5\uff0c\u83b7\u5f97\u4e86\u5728\u5e73\u884c\u5e73\u9762\u96c6\u5408\u4e0a\u6563\u5c04\u7684\u5fae\u5206\u622a\u9762\uff0c\u6bcf\u4e2a\u5e73\u9762\u4e2d\u539f\u5b50\u5747\u5300\u5206\u5e03\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728eikonal\u8fd1\u4f3c\u4e0b\uff0c\u5fae\u5206\u6563\u5c04\u622a\u9762\u7c7b\u4f3c\u4e8eBorn\u8fd1\u4f3c\uff0c\u5206\u88c2\u4e3a\u76f8\u5e72\u548c\u975e\u76f8\u5e72\u622a\u9762\u3002", "motivation": "\u6269\u5c55\u590d\u6742\u7ed3\u6784\u9776\u4e0a\u5feb\u901f\u5e26\u7535\u7c92\u5b50\u6563\u5c04\u7684\u65b9\u6cd5\uff0c\u4ee5\u8003\u8651\u4e8c\u6b21\u52bf\u9879\uff0c\u4ece\u800c\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u6563\u5c04\u8fc7\u7a0b\u3002", "method": "\u57fa\u4e8e\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e86\u5728\u5e73\u884c\u5e73\u9762\u96c6\u5408\u4e0a\u6563\u5c04\u7684\u5fae\u5206\u622a\u9762\uff0c\u6bcf\u4e2a\u5e73\u9762\u4e2d\u539f\u5b50\u5747\u5300\u5206\u5e03\u3002", "result": "\u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\uff0c\u5728eikonal\u8fd1\u4f3c\u4e0b\uff0c\u5fae\u5206\u6563\u5c04\u622a\u9762\u7c7b\u4f3c\u4e8eBorn\u8fd1\u4f3c\uff0c\u5206\u88c2\u4e3a\u76f8\u5e72\u548c\u975e\u76f8\u5e72\u622a\u9762\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u590d\u6742\u7ed3\u6784\u9776\u4e0a\u7684\u6563\u5c04\u8fc7\u7a0b\u6269\u5c55\u5230\u5305\u542b\u4e8c\u6b21\u52bf\u9879\uff0c\u5e76\u5728eikonal\u8fd1\u4f3c\u4e0b\u5f97\u5230\u4e86\u4e0eBorn\u8fd1\u4f3c\u7c7b\u4f3c\u7684\u76f8\u5e72\u548c\u975e\u76f8\u5e72\u622a\u9762\u5206\u88c2\u7ed3\u679c\u3002"}}
{"id": "2511.17643", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17643", "abs": "https://arxiv.org/abs/2511.17643", "authors": ["Yayan Qiu", "Sean Hanna"], "title": "Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper Topology Structure in Architecture That Matches Images?", "comment": null, "summary": "Taking into account the regional characteristics of intrinsic and extrinsic properties of space is an essential issue in architectural design and urban renewal, which is often achieved step by step using image and graph-based GANs. However, each model nesting and data conversion may cause information loss, and it is necessary to streamline the tools to facilitate architects and users to participate in the design. Therefore, this study hopes to prove that I2I GAN also has the potential to recognize topological relationships autonomously. Therefore, this research proposes a method for quickly detecting the ability of pix2pix to learn topological relationships, which is achieved by adding two Grasshopper-based detection modules before and after GAN. At the same time, quantitative data is provided and its learning process is visualized, and changes in different input modes such as greyscale and RGB affect its learning efficiency. There are two innovations in this paper: 1) It proves that pix2pix can automatically learn spatial topological relationships and apply them to architectural design. 2) It fills the gap in detecting the performance of Image-based Generation GAN from a topological perspective. Moreover, the detection method proposed in this study takes a short time and is simple to operate. The two detection modules can be widely used for customizing image datasets with the same topological structure and for batch detection of topological relationships of images. In the future, this paper may provide a theoretical foundation and data support for the application of architectural design and urban renewal that use GAN to preserve spatial topological characteristics.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u68c0\u6d4bpix2pix\u5b66\u4e60\u62d3\u6251\u5173\u7cfb\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728GAN\u524d\u540e\u6dfb\u52a0\u4e24\u4e2a\u57fa\u4e8eGrasshopper\u7684\u68c0\u6d4b\u6a21\u5757\uff0c\u8bc1\u660e\u4e86pix2pix\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u7a7a\u95f4\u62d3\u6251\u5173\u7cfb\u5e76\u5e94\u7528\u4e8e\u5efa\u7b51\u8bbe\u8ba1\u3002", "motivation": "\u8003\u8651\u5230\u5efa\u7b51\u8bbe\u8ba1\u548c\u57ce\u5e02\u66f4\u65b0\u4e2d\u7a7a\u95f4\u5185\u5728\u548c\u5916\u5728\u7279\u6027\u7684\u533a\u57df\u7279\u5f81\u8bc6\u522b\u9700\u6c42\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u5d4c\u5957\u548c\u6570\u636e\u8f6c\u6362\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\uff0c\u9700\u8981\u7b80\u5316\u5de5\u5177\u4ee5\u4fbf\u5efa\u7b51\u5e08\u548c\u7528\u6237\u53c2\u4e0e\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u5728GAN\u524d\u540e\u6dfb\u52a0\u4e24\u4e2a\u57fa\u4e8eGrasshopper\u7684\u68c0\u6d4b\u6a21\u5757\uff0c\u63d0\u4f9b\u5b9a\u91cf\u6570\u636e\u5e76\u53ef\u89c6\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7814\u7a76\u4e0d\u540c\u8f93\u5165\u6a21\u5f0f\uff08\u7070\u5ea6\u3001RGB\uff09\u5bf9\u5b66\u4e60\u6548\u7387\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660e\u4e86pix2pix\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u7a7a\u95f4\u62d3\u6251\u5173\u7cfb\uff0c\u586b\u8865\u4e86\u4ece\u62d3\u6251\u89d2\u5ea6\u68c0\u6d4b\u57fa\u4e8e\u56fe\u50cf\u7684\u751f\u6210GAN\u6027\u80fd\u7684\u7a7a\u767d\uff0c\u68c0\u6d4b\u65b9\u6cd5\u8017\u65f6\u77ed\u3001\u64cd\u4f5c\u7b80\u5355\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4e3a\u4f7f\u7528GAN\u4fdd\u7559\u7a7a\u95f4\u62d3\u6251\u7279\u5f81\u7684\u5efa\u7b51\u8bbe\u8ba1\u548c\u57ce\u5e02\u66f4\u65b0\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u6570\u636e\u652f\u6301\uff0c\u68c0\u6d4b\u6a21\u5757\u53ef\u5e7f\u6cdb\u7528\u4e8e\u5b9a\u5236\u5177\u6709\u76f8\u540c\u62d3\u6251\u7ed3\u6784\u7684\u56fe\u50cf\u6570\u636e\u96c6\u548c\u6279\u91cf\u68c0\u6d4b\u56fe\u50cf\u62d3\u6251\u5173\u7cfb\u3002"}}
{"id": "2511.19052", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2511.19052", "abs": "https://arxiv.org/abs/2511.19052", "authors": ["Pragjyotish Bhuyan Gogoi", "Awadhesh Prasad", "Aryan Patel", "Ram Ramaswamy", "Debashis Ghoshal"], "title": "Dynamics of coupled $D$-dimensional Stuart-Landau oscillators", "comment": null, "summary": "The Stuart-Landau oscillator generalized to $D > 2$ dimensions has SO($D$) rotational symmetry. We study the collective dynamics of a system of $K$ such oscillators of dimensions $D =$ 3 and 4, with coupling chosen to either preserve or break rotational symmetry. This leads to emergent dynamical phenomena that do not have analogs in the well-studied case of $D=2$. Further, the larger number of internal parameters allows for the exploration of different forms of heterogeneity among the individual oscillators. When rotational symmetry is preserved there can be various forms of synchronization as well as multistability and $partial$ amplitude death, namely, the quenching of oscillations within a subset of variables that asymptote to the same constant value. The oscillatory dynamics in these cases are characterized by phase-locking and phase-drift. When the coupling breaks rotational symmetry we observe $partial$ synchronization (when a subset of the variables coincide and oscillate) and $partial$ oscillation death (when a subset of variables asymptote to different stationary values), as well as the coexistence of these different partial quenching phenomena.", "AI": {"tldr": "\u7814\u7a76\u4e86\u9ad8\u7ef4Stuart-Landau\u632f\u5b50\u7cfb\u7edf\u7684\u96c6\u4f53\u52a8\u529b\u5b66\uff0c\u5728D=3\u548c4\u7ef4\u60c5\u51b5\u4e0b\uff0c\u63a2\u7d22\u4e86\u4fdd\u6301\u548c\u7834\u574f\u65cb\u8f6c\u5bf9\u79f0\u6027\u7684\u8026\u5408\u65b9\u5f0f\uff0c\u53d1\u73b0\u4e86\u5728D=2\u60c5\u51b5\u4e0b\u4e0d\u5b58\u5728\u7684\u6d8c\u73b0\u52a8\u529b\u5b66\u73b0\u8c61\uff0c\u5305\u62ec\u5404\u79cd\u540c\u6b65\u5f62\u5f0f\u3001\u591a\u7a33\u6001\u548c\u90e8\u5206\u632f\u5e45\u6b7b\u4ea1\u7b49\u3002", "motivation": "\u5c06Stuart-Landau\u632f\u5b50\u63a8\u5e7f\u5230D>2\u7ef4\u5177\u6709SO(D)\u65cb\u8f6c\u5bf9\u79f0\u6027\uff0c\u7814\u7a76\u8fd9\u79cd\u9ad8\u7ef4\u632f\u5b50\u7cfb\u7edf\u7684\u96c6\u4f53\u52a8\u529b\u5b66\uff0c\u63a2\u7d22\u6bd4D=2\u60c5\u51b5\u66f4\u4e30\u5bcc\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "method": "\u7814\u7a76K\u4e2aD=3\u548c4\u7ef4\u7684Stuart-Landau\u632f\u5b50\u7cfb\u7edf\uff0c\u91c7\u7528\u4fdd\u6301\u6216\u7834\u574f\u65cb\u8f6c\u5bf9\u79f0\u6027\u7684\u8026\u5408\u65b9\u5f0f\uff0c\u5e76\u5229\u7528\u66f4\u591a\u7684\u5185\u90e8\u53c2\u6570\u63a2\u7d22\u632f\u5b50\u95f4\u7684\u5f02\u8d28\u6027\u3002", "result": "\u5f53\u4fdd\u6301\u65cb\u8f6c\u5bf9\u79f0\u6027\u65f6\uff0c\u89c2\u5bdf\u5230\u5404\u79cd\u540c\u6b65\u5f62\u5f0f\u3001\u591a\u7a33\u6001\u548c\u90e8\u5206\u632f\u5e45\u6b7b\u4ea1\uff1b\u5f53\u7834\u574f\u65cb\u8f6c\u5bf9\u79f0\u6027\u65f6\uff0c\u89c2\u5bdf\u5230\u90e8\u5206\u540c\u6b65\u548c\u90e8\u5206\u632f\u8361\u6b7b\u4ea1\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u4e0d\u540c\u90e8\u5206\u6dec\u706d\u73b0\u8c61\u7684\u5171\u5b58\u3002", "conclusion": "\u9ad8\u7ef4Stuart-Landau\u632f\u5b50\u7cfb\u7edf\u5c55\u73b0\u51fa\u6bd4\u4e8c\u7ef4\u60c5\u51b5\u66f4\u4e30\u5bcc\u7684\u96c6\u4f53\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u5305\u62ec\u591a\u79cd\u540c\u6b65\u6a21\u5f0f\u3001\u90e8\u5206\u6dec\u706d\u73b0\u8c61\u53ca\u5176\u5171\u5b58\uff0c\u8fd9\u4e9b\u73b0\u8c61\u5728D=2\u60c5\u51b5\u4e0b\u6ca1\u6709\u5bf9\u5e94\u7269\u3002"}}
{"id": "2511.18644", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.18644", "abs": "https://arxiv.org/abs/2511.18644", "authors": ["Hong-Chen Jiang", "Thomas P. Devereaux", "Steven A. Kivelson"], "title": "Competition between charge-density-wave and superconducting orders on eight-leg square Hubbard cylinders", "comment": "8 pages, 3 figures plus Supplemental Material. Comments are welcome", "summary": "The issue of whether $d$-wave superconductivity (SC) occurs in the square-lattice Hubbard model with $U$ of order of the bandwidth has been one of the most debated issues to emerge from the study of high temperature SC. Here, we report variational results on eight-leg cylinders with next-nearest-neighbor hopping in the range $-0.5 t \\leq t'\\leq 0.25 t$ with $U = 8t$ and $12t$ and doped hole concentrations $\u03b4=1/12$ and $1/8$. For $t'\\leq 0$, the ground-state appears to be a charge-density wave (CDW) of one sort or another with SC correlations that are extremely short-ranged. In contrast, in some cases, the local magnetic order has a correlation length greater than half the cylinder width - suggestive that magnetic order might also arise in the 2D limit. For $t'>0$, our results depend more strongly on boundary conditions (periodic vs antiperiodic), making it still harder to correctly guess whether SC or CDW correlations dominate in the 2D limit. These results were obtained employing matrix-product states with bond dimensions large enough that energy differences as small as $10^{-3}t$ per site can be resolved.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u53d8\u5206\u65b9\u6cd5\u5206\u6790\u65b9\u5f62\u6676\u683cHubbard\u6a21\u578b\u4e2d\u7684d\u6ce2\u8d85\u5bfc\u6027\uff0c\u53d1\u73b0\u5728t'\u22640\u65f6\u7cfb\u7edf\u5448\u73b0\u7535\u8377\u5bc6\u5ea6\u6ce2\u6001\uff0c\u8d85\u5bfc\u5173\u8054\u6781\u77ed\u7a0b\uff1bt'>0\u65f6\u7ed3\u679c\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u8fb9\u754c\u6761\u4ef6\uff0c\u96be\u4ee5\u786e\u5b9a\u4e8c\u7ef4\u6781\u9650\u4e0b\u8d85\u5bfc\u6216\u7535\u8377\u5bc6\u5ea6\u6ce2\u5173\u8054\u7684\u4e3b\u5bfc\u6027\u3002", "motivation": "\u89e3\u51b3\u65b9\u5f62\u6676\u683cHubbard\u6a21\u578b\u4e2d\u662f\u5426\u5b58\u5728d\u6ce2\u8d85\u5bfc\u6027\u7684\u957f\u671f\u4e89\u8bae\uff0c\u8fd9\u662f\u9ad8\u6e29\u8d85\u5bfc\u7814\u7a76\u4e2d\u6700\u5177\u4e89\u8bae\u7684\u95ee\u9898\u4e4b\u4e00\u3002", "method": "\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\u65b9\u6cd5\uff0c\u5728\u516b\u817f\u5706\u67f1\u4e0a\u7814\u7a76\u5177\u6709\u6b21\u8fd1\u90bb\u8dc3\u8fc1\u7684Hubbard\u6a21\u578b\uff0c\u53c2\u6570\u8303\u56f4\u5305\u62ecU=8t\u548c12t\uff0c\u63ba\u6742\u6d53\u5ea6\u03b4=1/12\u548c1/8\uff0ct'\u5728-0.5t\u52300.25t\u4e4b\u95f4\u3002", "result": "\u5f53t'\u22640\u65f6\uff0c\u57fa\u6001\u8868\u73b0\u4e3a\u7535\u8377\u5bc6\u5ea6\u6ce2\u6001\uff0c\u8d85\u5bfc\u5173\u8054\u6781\u77ed\u7a0b\uff1b\u5c40\u90e8\u78c1\u5e8f\u5173\u8054\u957f\u5ea6\u8d85\u8fc7\u5706\u67f1\u5bbd\u5ea6\u4e00\u534a\uff0c\u6697\u793a\u4e8c\u7ef4\u6781\u9650\u4e0b\u53ef\u80fd\u51fa\u73b0\u78c1\u5e8f\u3002\u5f53t'>0\u65f6\uff0c\u7ed3\u679c\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u8fb9\u754c\u6761\u4ef6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5728\u7279\u5b9a\u53c2\u6570\u8303\u56f4\u5185\uff0cHubbard\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u5f62\u6210\u7535\u8377\u5bc6\u5ea6\u6ce2\u6001\u800c\u975ed\u6ce2\u8d85\u5bfc\u6001\uff0c\u4e14\u8fb9\u754c\u6761\u4ef6\u5bf9\u7ed3\u679c\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f7f\u5f97\u4e8c\u7ef4\u6781\u9650\u4e0b\u7684\u4e3b\u5bfc\u5173\u8054\u7c7b\u578b\u96be\u4ee5\u786e\u5b9a\u3002"}}
{"id": "2511.18648", "categories": ["cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.18648", "abs": "https://arxiv.org/abs/2511.18648", "authors": ["Dario Javier Zamora"], "title": "Failure of LMC statistical complexity in identifying structural order in the XY model", "comment": null, "summary": "Quantifying complexity in physical systems remains a fundamental challenge, and many proposed measures fail to capture the structural features that intuitive or theoretical considerations would demand. Among them, the Lopez-Ruiz-Mancini-Calbet (LMC) statistical complexity has been widely cited due to its simplicity and analytic tractability. Here, we examine the performance and limitations of the LMC measure in a controlled physical setting: a two-dimensional XY model studied through Monte Carlo simulations. By computing LMC complexity at each step of the system's relaxation dynamics, and directly comparing these values with the evolving dipole configurations, we show that LMC complexity systematically fails to identify states of high structural complexity. In particular, the measure often assigns maximal complexity to nearly equilibrated configurations while underestimating vortex-rich intermediate states. We further show that the time derivative of LMC complexity contains more meaningful dynamical information. We propose that future measures incorporate directionality and dynamical sensitivity to better reflect the emergence and decay of organization in nonequilibrium systems.", "AI": {"tldr": "LMC\u7edf\u8ba1\u590d\u6742\u5ea6\u5728XY\u6a21\u578b\u4e2d\u65e0\u6cd5\u51c6\u786e\u8bc6\u522b\u9ad8\u7ed3\u6784\u590d\u6742\u5ea6\u72b6\u6001\uff0c\u5e38\u5c06\u6700\u5927\u590d\u6742\u5ea6\u5206\u914d\u7ed9\u63a5\u8fd1\u5e73\u8861\u7684\u914d\u7f6e\uff0c\u800c\u4f4e\u4f30\u6da1\u65cb\u4e30\u5bcc\u7684\u4e2d\u95f4\u6001\u3002\u5176\u65f6\u95f4\u5bfc\u6570\u5305\u542b\u66f4\u6709\u610f\u4e49\u7684\u52a8\u529b\u5b66\u4fe1\u606f\u3002", "motivation": "\u91cf\u5316\u7269\u7406\u7cfb\u7edf\u7684\u590d\u6742\u6027\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\uff0c\u73b0\u6709\u5ea6\u91cf\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u76f4\u89c9\u6216\u7406\u8bba\u8981\u6c42\u7684\u7ed3\u6784\u7279\u5f81\u3002LMC\u7edf\u8ba1\u590d\u6742\u5ea6\u56e0\u5176\u7b80\u5355\u6027\u548c\u89e3\u6790\u53ef\u5904\u7406\u6027\u88ab\u5e7f\u6cdb\u5f15\u7528\uff0c\u4f46\u5176\u6027\u80fd\u9700\u8981\u5728\u5b9e\u9645\u7269\u7406\u73af\u5883\u4e2d\u9a8c\u8bc1\u3002", "method": "\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u7814\u7a76\u4e8c\u7ef4XY\u6a21\u578b\uff0c\u8ba1\u7b97\u7cfb\u7edf\u5f1b\u8c6b\u52a8\u529b\u5b66\u6bcf\u4e00\u6b65\u7684LMC\u590d\u6742\u5ea6\uff0c\u5e76\u76f4\u63a5\u4e0e\u6f14\u5316\u7684\u5076\u6781\u5b50\u914d\u7f6e\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "LMC\u590d\u6742\u5ea6\u7cfb\u7edf\u6027\u5730\u65e0\u6cd5\u8bc6\u522b\u9ad8\u7ed3\u6784\u590d\u6742\u5ea6\u72b6\u6001\uff0c\u7ecf\u5e38\u5c06\u6700\u5927\u590d\u6742\u5ea6\u5206\u914d\u7ed9\u63a5\u8fd1\u5e73\u8861\u7684\u914d\u7f6e\uff0c\u800c\u4f4e\u4f30\u6da1\u65cb\u4e30\u5bcc\u7684\u4e2d\u95f4\u6001\u3002LMC\u590d\u6742\u5ea6\u7684\u65f6\u95f4\u5bfc\u6570\u5305\u542b\u66f4\u6709\u610f\u4e49\u7684\u52a8\u529b\u5b66\u4fe1\u606f\u3002", "conclusion": "\u672a\u6765\u7684\u590d\u6742\u6027\u5ea6\u91cf\u5e94\u5305\u542b\u65b9\u5411\u6027\u548c\u52a8\u529b\u5b66\u654f\u611f\u6027\uff0c\u4ee5\u66f4\u597d\u5730\u53cd\u6620\u975e\u5e73\u8861\u7cfb\u7edf\u4e2d\u7ec4\u7ec7\u7684\u51fa\u73b0\u548c\u8870\u51cf\u3002"}}
{"id": "2511.18109", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.18109", "abs": "https://arxiv.org/abs/2511.18109", "authors": ["Onofre Rojas"], "title": "Spectral mechanism and nearly reducible transfer matrices for pseudotransitions in one-dimensional systems", "comment": "13 pages, 5 figures", "summary": "While true phase transitions are forbidden in one-dimensional systems with short-range interactions, several models have recently been shown to exhibit sharp yet analytic thermodynamic anomalies that mimic thermal phase transitions. We show that this behavior arises from transfer matrices that are mathematically irreducible but possess a nearly block-diagonal structure due to the weak contribution of off-diagonal Boltzmann weights in the low-temperature regime. This results in weakly coupled competing sectors whose eigenvalue competition produces abrupt crossovers without nonanalyticity, a mechanism we term nearly block-diagonal irreducible. A key thermodynamic signature of such pseudotransitions is that the residual entropy at the interface remains bounded between the residual entropies of the competing sectors. We develop a general spectral framework to describe this behavior and apply it to two representative models: the Ising chain with internal degeneracy (Doniach model) and a hexagonal nanowire chain with mixed spin-1/2 and spin-1 components. In the first case, we derive exact expressions for the pseudo-critical temperature and residual entropy. In the second, we reduce the full $1458\\times1458$ transfer matrix via symmetry decomposition and construct a low-rank effective matrix that accurately captures the crossover between quasi-ferromagnetic and quasi-core-ferromagnetic regimes. Our results demonstrate that pseudotransitions can be understood as spectral phenomena emerging from irreducible but functionally decoupled structures within the transfer matrix.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u7ef4\u77ed\u7a0b\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u4e2d\u7684\u4f2a\u76f8\u53d8\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u8fd9\u79cd\u770b\u4f3c\u5c16\u9510\u4f46\u89e3\u6790\u7684\u70ed\u529b\u5b66\u5f02\u5e38\u6765\u6e90\u4e8e\u8f6c\u79fb\u77e9\u9635\u7684\u8fd1\u4e4e\u5757\u5bf9\u89d2\u7ed3\u6784\uff0c\u5176\u4e2d\u5f31\u8026\u5408\u7684\u7ade\u4e89\u6247\u533a\u5bfc\u81f4\u7279\u5f81\u503c\u7ade\u4e89\uff0c\u4ea7\u751f\u65e0\u975e\u89e3\u6790\u6027\u7684\u7a81\u53d8\u4ea4\u53c9\u3002", "motivation": "\u867d\u7136\u4e00\u7ef4\u7cfb\u7edf\u5728\u77ed\u7a0b\u76f8\u4e92\u4f5c\u7528\u4e0b\u4e0d\u53ef\u80fd\u53d1\u751f\u771f\u6b63\u7684\u76f8\u53d8\uff0c\u4f46\u6700\u8fd1\u53d1\u73b0\u591a\u4e2a\u6a21\u578b\u8868\u73b0\u51fa\u7c7b\u4f3c\u76f8\u53d8\u7684\u5c16\u9510\u70ed\u529b\u5b66\u5f02\u5e38\u3002\u672c\u6587\u65e8\u5728\u7406\u89e3\u8fd9\u79cd\u4f2a\u76f8\u53d8\u73b0\u8c61\u7684\u6570\u5b66\u673a\u5236\u548c\u70ed\u529b\u5b66\u7279\u5f81\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u8c31\u6846\u67b6\u6765\u63cf\u8ff0\u4f2a\u76f8\u53d8\u884c\u4e3a\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e24\u4e2a\u4ee3\u8868\u6027\u6a21\u578b\uff1a\u5177\u6709\u5185\u90e8\u7b80\u5e76\u7684Ising\u94fe\uff08Doniach\u6a21\u578b\uff09\u548c\u6df7\u5408\u81ea\u65cb1/2\u4e0e\u81ea\u65cb1\u7684\u516d\u8fb9\u5f62\u7eb3\u7c73\u7ebf\u94fe\u3002\u901a\u8fc7\u8f6c\u79fb\u77e9\u9635\u7684\u5bf9\u79f0\u6027\u5206\u89e3\u548c\u4f4e\u79e9\u6709\u6548\u77e9\u9635\u6784\u9020\u6765\u5206\u6790\u4ea4\u53c9\u884c\u4e3a\u3002", "result": "\u5728Doniach\u6a21\u578b\u4e2d\u63a8\u5bfc\u4e86\u4f2a\u4e34\u754c\u6e29\u5ea6\u548c\u6b8b\u4f59\u71b5\u7684\u7cbe\u786e\u8868\u8fbe\u5f0f\uff1b\u5728\u516d\u8fb9\u5f62\u7eb3\u7c73\u7ebf\u94fe\u4e2d\uff0c\u901a\u8fc7\u5bf9\u79f0\u6027\u5206\u89e3\u5c061458\u00d71458\u7684\u5b8c\u6574\u8f6c\u79fb\u77e9\u9635\u7b80\u5316\uff0c\u6784\u5efa\u4e86\u80fd\u591f\u51c6\u786e\u6355\u6349\u51c6\u94c1\u78c1\u548c\u51c6\u6838\u94c1\u78c1\u533a\u57df\u95f4\u4ea4\u53c9\u7684\u4f4e\u79e9\u6709\u6548\u77e9\u9635\u3002", "conclusion": "\u4f2a\u76f8\u53d8\u53ef\u4ee5\u7406\u89e3\u4e3a\u4ece\u8f6c\u79fb\u77e9\u9635\u5185\u4e0d\u53ef\u7ea6\u4f46\u529f\u80fd\u89e3\u8026\u7ed3\u6784\u4e2d\u51fa\u73b0\u7684\u8c31\u73b0\u8c61\uff0c\u6b8b\u4f59\u71b5\u5728\u754c\u9762\u5904\u4fdd\u6301\u6709\u754c\u662f\u6b64\u7c7b\u4f2a\u76f8\u53d8\u7684\u5173\u952e\u70ed\u529b\u5b66\u7279\u5f81\u3002"}}
{"id": "2511.17749", "categories": ["quant-ph", "physics.chem-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.17749", "abs": "https://arxiv.org/abs/2511.17749", "authors": ["Lilian I. Payne Torres", "Irma Avdic", "Anna O. Schouten", "Olivia C. Wedig", "Gregory S. Engel", "David A. Mazziotti"], "title": "Entanglement Witnesses of Condensation for Enhanced Quantum Sensing", "comment": null, "summary": "Quantum phenomena such as entanglement provide powerful resources for enhancing classical sensing. Here, we theoretically show that collective entanglement of spin qubits, arising from a condensation of particle-hole pairs, can strongly amplify transitions between ground and excited spin states, potentially improving signal contrast in optically detected magnetic resonance. This collective state exhibits an $\\mathcal{O}(\\sqrt{N})$ enhancement of the transition amplitude with respect to an applied microwave field, where $N$ is the number of entangled spin qubits. We computationally realize this amplification using an ensemble of $N$ triplet spins with magnetic dipole interactions, where the largest transition amplitudes occur at geometries for which the condensation of particle-hole pairs is strongest. This effect, robust to noise, originates from the concentration of entanglement into a single collective mode, reflected in a large eigenvalue of the particle-hole reduced density matrix -- an entanglement witness of condensation analogous to off-diagonal long-range order, though realized here in a finite system. These results offer a design principle for quantum sensors that exploit condensation-inspired entanglement to boost sensitivity in spin-based platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u7684\u96c6\u4f53\u7ea0\u7f20\u6001\uff08\u6e90\u4e8e\u7c92\u5b50-\u7a7a\u7a74\u5bf9\u51dd\u805a\uff09\u6765\u589e\u5f3a\u81ea\u65cb\u6001\u4e4b\u95f4\u7684\u8dc3\u8fc1\u5e45\u5ea6\uff0c\u4ece\u800c\u63d0\u5347\u91cf\u5b50\u4f20\u611f\u5668\u7684\u7075\u654f\u5ea6\u3002", "motivation": "\u91cf\u5b50\u7ea0\u7f20\u73b0\u8c61\u4e3a\u589e\u5f3a\u7ecf\u5178\u4f20\u611f\u63d0\u4f9b\u4e86\u5f3a\u5927\u8d44\u6e90\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528\u96c6\u4f53\u7ea0\u7f20\u6001\u6765\u653e\u5927\u81ea\u65cb\u6001\u4e4b\u95f4\u7684\u8dc3\u8fc1\uff0c\u63d0\u9ad8\u5149\u5b66\u68c0\u6d4b\u78c1\u5171\u632f\u7684\u4fe1\u53f7\u5bf9\u6bd4\u5ea6\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u8ba1\u7b97\u6a21\u62df\uff0c\u7814\u7a76\u5177\u6709\u78c1\u5076\u6781\u76f8\u4e92\u4f5c\u7528\u7684N\u4e2a\u4e09\u91cd\u6001\u81ea\u65cb\u7cfb\u7efc\uff0c\u5728\u7c92\u5b50-\u7a7a\u7a74\u5bf9\u51dd\u805a\u6700\u5f3a\u7684\u51e0\u4f55\u6784\u578b\u4e0b\u5b9e\u73b0\u8dc3\u8fc1\u5e45\u5ea6\u7684\u653e\u5927\u3002", "result": "\u53d1\u73b0\u96c6\u4f53\u7ea0\u7f20\u6001\u80fd\u4f7f\u8dc3\u8fc1\u5e45\u5ea6\u76f8\u5bf9\u4e8e\u5916\u52a0\u5fae\u6ce2\u573a\u5b9e\u73b0O(\u221aN)\u7684\u589e\u5f3a\uff0c\u8fd9\u79cd\u6548\u5e94\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u6e90\u4e8e\u7ea0\u7f20\u96c6\u4e2d\u5230\u5355\u4e00\u96c6\u4f53\u6a21\u5f0f\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u91cf\u5b50\u4f20\u611f\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u539f\u5219\uff0c\u5373\u5229\u7528\u51dd\u805a\u542f\u53d1\u7684\u7ea0\u7f20\u6765\u63d0\u5347\u81ea\u65cb\u5e73\u53f0\u7684\u7075\u654f\u5ea6\u3002"}}
{"id": "2511.17566", "categories": ["cs.LG", "cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17566", "abs": "https://arxiv.org/abs/2511.17566", "authors": ["Shuaiyu Xie", "Hanbin He", "Jian Wang", "Bing Li"], "title": "Root Cause Analysis for Microservice Systems via Cascaded Conditional Learning with Hypergraphs", "comment": null, "summary": "Root cause analysis in microservice systems typically involves two core tasks: root cause localization (RCL) and failure type identification (FTI). Despite substantial research efforts, conventional diagnostic approaches still face two key challenges. First, these methods predominantly adopt a joint learning paradigm for RCL and FTI to exploit shared information and reduce training time. However, this simplistic integration neglects the causal dependencies between tasks, thereby impeding inter-task collaboration and information transfer. Second, these existing methods primarily focus on point-to-point relationships between instances, overlooking the group nature of inter-instance influences induced by deployment configurations and load balancing. To overcome these limitations, we propose CCLH, a novel root cause analysis framework that orchestrates diagnostic tasks based on cascaded conditional learning. CCLH provides a three-level taxonomy for group influences between instances and incorporates a heterogeneous hypergraph to model these relationships, facilitating the simulation of failure propagation. Extensive experiments conducted on datasets from three microservice benchmarks demonstrate that CCLH outperforms state-of-the-art methods in both RCL and FTI.", "AI": {"tldr": "CCLH\u662f\u4e00\u4e2a\u7528\u4e8e\u5fae\u670d\u52a1\u7cfb\u7edf\u6839\u56e0\u5206\u6790\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7ea7\u8054\u6761\u4ef6\u5b66\u4e60\u548c\u5f02\u6784\u8d85\u56fe\u5efa\u6a21\u6765\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u4efb\u52a1\u4f9d\u8d56\u6027\u548c\u5b9e\u4f8b\u7fa4\u4f53\u5f71\u54cd\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5728\u6839\u56e0\u5b9a\u4f4d\u548c\u6545\u969c\u7c7b\u578b\u8bc6\u522b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u8054\u5408\u5b66\u4e60\u8303\u5f0f\u5ffd\u89c6\u4e86\u4efb\u52a1\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u963b\u788d\u4e86\u4efb\u52a1\u95f4\u534f\u4f5c\uff1b2\uff09\u4e3b\u8981\u5173\u6ce8\u5b9e\u4f8b\u95f4\u7684\u70b9\u5bf9\u70b9\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u7531\u90e8\u7f72\u914d\u7f6e\u548c\u8d1f\u8f7d\u5747\u8861\u5f15\u8d77\u7684\u5b9e\u4f8b\u7fa4\u4f53\u5f71\u54cd\u7279\u6027\u3002", "method": "\u63d0\u51fa\u4e86CCLH\u6846\u67b6\uff0c\u91c7\u7528\u7ea7\u8054\u6761\u4ef6\u5b66\u4e60\u6765\u534f\u8c03\u8bca\u65ad\u4efb\u52a1\uff0c\u63d0\u4f9b\u4e86\u5b9e\u4f8b\u95f4\u7fa4\u4f53\u5f71\u54cd\u7684\u4e09\u7ea7\u5206\u7c7b\uff0c\u5e76\u5f15\u5165\u5f02\u6784\u8d85\u56fe\u6765\u5efa\u6a21\u8fd9\u4e9b\u5173\u7cfb\uff0c\u4ece\u800c\u6a21\u62df\u6545\u969c\u4f20\u64ad\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u5fae\u670d\u52a1\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCCLH\u5728\u6839\u56e0\u5b9a\u4f4d\u548c\u6545\u969c\u7c7b\u578b\u8bc6\u522b\u4e24\u4e2a\u4efb\u52a1\u4e0a\u90fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "CCLH\u901a\u8fc7\u7ea7\u8054\u6761\u4ef6\u5b66\u4e60\u548c\u5f02\u6784\u8d85\u56fe\u5efa\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u5728\u4efb\u52a1\u4f9d\u8d56\u6027\u548c\u7fa4\u4f53\u5f71\u54cd\u5efa\u6a21\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bca\u65ad\u6027\u80fd\u3002"}}
{"id": "2511.17957", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.17957", "abs": "https://arxiv.org/abs/2511.17957", "authors": ["P. A. Bannykh", "O. M. Sotnikov", "V. V. Mazurenko"], "title": "Brute-force positivization of $J_1-J_2$ model ground states", "comment": null, "summary": "Exploring sign structures of quantum wave functions attracts considerable attention due to the potential for advances in modeling complex phases of matter. This stimulates developing different optimization procedures for imitating and manipulating sign structures of quantum states. In this work, utilizing a brute force approach based on a set of single-qubit transformations we evaluate protocols enabling positivization of the one-dimensional $J_1 -J_2$ model ground states in the regime of strong frustration. Based on the obtained positivization results, we show the difference between the cases of periodic and open boundary conditions, and also establish the dependence of the sign structure on parity of the simulated spin chains.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u66b4\u529b\u65b9\u6cd5\u8bc4\u4f30\u4e86\u5f3a\u963b\u632b\u4e00\u7ef4J1-J2\u6a21\u578b\u57fa\u6001\u6ce2\u51fd\u6570\u7684\u6b63\u5316\u534f\u8bae\uff0c\u5c55\u793a\u4e86\u5468\u671f\u548c\u5f00\u653e\u8fb9\u754c\u6761\u4ef6\u4ee5\u53ca\u81ea\u65cb\u94fe\u5947\u5076\u6027\u5bf9\u7b26\u53f7\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u6ce2\u51fd\u6570\u7b26\u53f7\u7ed3\u6784\u5bf9\u4e8e\u6a21\u62df\u590d\u6742\u7269\u8d28\u76f8\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u8fd9\u63a8\u52a8\u4e86\u5f00\u53d1\u4e0d\u540c\u7684\u4f18\u5316\u7a0b\u5e8f\u6765\u6a21\u4eff\u548c\u64cd\u7eb5\u91cf\u5b50\u6001\u7684\u7b26\u53f7\u7ed3\u6784\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5355\u91cf\u5b50\u6bd4\u7279\u53d8\u6362\u7684\u66b4\u529b\u65b9\u6cd5\uff0c\u8bc4\u4f30\u80fd\u591f\u4f7f\u5f3a\u963b\u632b\u4e00\u7ef4J1-J2\u6a21\u578b\u57fa\u6001\u6b63\u5316\u7684\u534f\u8bae\u3002", "result": "\u83b7\u5f97\u4e86\u6b63\u5316\u7ed3\u679c\uff0c\u663e\u793a\u4e86\u5468\u671f\u8fb9\u754c\u6761\u4ef6\u548c\u5f00\u653e\u8fb9\u754c\u6761\u4ef6\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5e76\u786e\u5b9a\u4e86\u7b26\u53f7\u7ed3\u6784\u4e0e\u6a21\u62df\u81ea\u65cb\u94fe\u5947\u5076\u6027\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u6b63\u5316\u7ed3\u679c\u63ed\u793a\u4e86\u8fb9\u754c\u6761\u4ef6\u548c\u81ea\u65cb\u94fe\u5947\u5076\u6027\u5bf9\u91cf\u5b50\u6001\u7b26\u53f7\u7ed3\u6784\u7684\u91cd\u8981\u5f71\u54cd\uff0c\u4e3a\u7406\u89e3\u5f3a\u963b\u632b\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50\u6001\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2511.18256", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.18256", "abs": "https://arxiv.org/abs/2511.18256", "authors": ["Christopher N. Angstmann", "Daniel S. Han", "Bruce I. Henry", "Boris Z. Huang"], "title": "First-Passage Times for the Space Fractional Fokker-Planck Equation", "comment": "7 pages, 5 figures", "summary": "We extend the random walk framework to include compounded steps, providing first-passage time (FPT) properties for a new class of superdiffusive processes, which are governed by the space-fractional spectral Fokker-Planck equation. This first-passage process leads to novel FPT properties, different from L\u00e9vy flights and walks, that account for space dependent forces and hitting boundaries throughout the path of a jump. The FPT distribution can be derived for different types of barriers and potentials, for which we also provide specific examples. For the one-sided absorbing boundary on the semi-infinite line, we find that the FPT density scales as $t^{-1/(2\u03b1)-1}$, in agreement with the method of images but in violation of the Sparre-Andersen scaling. In this case, there exists an optimal space-fractional exponent $\u03b1$ to minimize the mean FPT.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u968f\u673a\u6e38\u8d70\u6846\u67b6\u4ee5\u5305\u542b\u590d\u5408\u6b65\u9aa4\uff0c\u4e3a\u4e00\u7c7b\u65b0\u7684\u8d85\u6269\u6563\u8fc7\u7a0b\u63d0\u4f9b\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u7279\u6027\uff0c\u8fd9\u4e9b\u8fc7\u7a0b\u7531\u7a7a\u95f4\u5206\u6570\u8c31Fokker-Planck\u65b9\u7a0b\u63a7\u5236\u3002", "motivation": "\u7814\u7a76\u4e00\u7c7b\u65b0\u7684\u8d85\u6269\u6563\u8fc7\u7a0b\u7684\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u7279\u6027\uff0c\u8fd9\u4e9b\u8fc7\u7a0b\u4e0d\u540c\u4e8eL\u00e9vy\u98de\u884c\u548c\u884c\u8d70\uff0c\u80fd\u591f\u8003\u8651\u7a7a\u95f4\u4f9d\u8d56\u529b\u548c\u8df3\u8dc3\u8def\u5f84\u4e2d\u7684\u51fb\u4e2d\u8fb9\u754c\u3002", "method": "\u6269\u5c55\u968f\u673a\u6e38\u8d70\u6846\u67b6\u4ee5\u5305\u542b\u590d\u5408\u6b65\u9aa4\uff0c\u63a8\u5bfc\u4e0d\u540c\u7c7b\u578b\u52bf\u5792\u548c\u52bf\u80fd\u4e0b\u7684\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u5206\u5e03\u3002", "result": "\u5bf9\u4e8e\u534a\u65e0\u9650\u7ebf\u4e0a\u7684\u5355\u4fa7\u5438\u6536\u8fb9\u754c\uff0c\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u5bc6\u5ea6\u6309t^{-1/(2\u03b1)-1}\u7f29\u653e\uff0c\u4e0e\u955c\u50cf\u6cd5\u4e00\u81f4\u4f46\u8fdd\u53cdSparre-Andersen\u7f29\u653e\u3002\u5b58\u5728\u6700\u4f18\u7684\u7a7a\u95f4\u5206\u6570\u6307\u6570\u03b1\u6765\u6700\u5c0f\u5316\u5e73\u5747\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8d85\u6269\u6563\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u7279\u6027\uff0c\u63ed\u793a\u4e86\u4e0e\u7ecf\u5178\u8fc7\u7a0b\u4e0d\u540c\u7684\u7f29\u653e\u884c\u4e3a\u548c\u6700\u4f18\u53c2\u6570\u9009\u62e9\u3002"}}
{"id": "2511.17764", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17764", "abs": "https://arxiv.org/abs/2511.17764", "authors": ["Patryk Michalski", "Arturo Konderak", "Wojciech Bruzda", "Remigiusz Augusiak"], "title": "Certifying Majorana Fermions with Elegant-Like Bell Inequalities and a New Self-Testing Equivalence", "comment": "17 pages, 1 figure", "summary": "Bell inequalities provide a fundamental tool for probing nonlocal correlations, yet their quantum bound, that is, the maximal value attainable through quantum strategies, is rarely accessible analytically. In this work, we introduce a general construction of Bell inequalities for which this bound can be computed exactly. Our framework generalizes both the Clauser-Horne-Shimony-Holt and Gisin's elegant inequalities, yielding Bell expressions maximally violated by any number of pairwise anticommuting Clifford observables together with the corresponding maximally entangled state. Under suitable assumptions, our inequalities also enable the device-independent certification of Majorana fermions, understood as multiqubit realizations of Clifford algebra generators. Importantly, we identify an additional equivalence that must be incorporated into the definition of self-testing beyond invariance under local isometries and transposition. This equivalence arises from partial transposition applied to the shared state and to the measurements, which in specific cases leaves all observed correlations unchanged.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u8d1d\u5c14\u4e0d\u7b49\u5f0f\u6784\u9020\u65b9\u6cd5\uff0c\u80fd\u591f\u7cbe\u786e\u8ba1\u7b97\u91cf\u5b50\u754c\u9650\uff0c\u63a8\u5e7f\u4e86CHSH\u548cGisin\u4f18\u96c5\u4e0d\u7b49\u5f0f\uff0c\u5e76\u53ef\u7528\u4e8e\u8bbe\u5907\u65e0\u5173\u5730\u8ba4\u8bc1Majorana\u8d39\u7c73\u5b50\u3002", "motivation": "\u8d1d\u5c14\u4e0d\u7b49\u5f0f\u662f\u63a2\u6d4b\u975e\u5c40\u57df\u76f8\u5173\u6027\u7684\u57fa\u672c\u5de5\u5177\uff0c\u4f46\u5176\u91cf\u5b50\u754c\u9650\uff08\u5373\u901a\u8fc7\u91cf\u5b50\u7b56\u7565\u53ef\u83b7\u5f97\u7684\u6700\u5927\u503c\uff09\u5f88\u5c11\u80fd\u89e3\u6790\u8ba1\u7b97\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u901a\u7528\u7684\u8d1d\u5c14\u4e0d\u7b49\u5f0f\u6784\u9020\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u63a8\u5e7f\u4e86Clauser-Horne-Shimony-Holt\u548cGisin\u7684\u4f18\u96c5\u4e0d\u7b49\u5f0f\uff0c\u4ea7\u751f\u7531\u4efb\u610f\u6570\u91cf\u6210\u5bf9\u53cd\u4ea4\u6362Clifford\u53ef\u89c2\u6d4b\u91cf\u548c\u76f8\u5e94\u7684\u6700\u5927\u7ea0\u7f20\u6001\u6700\u5927\u8fdd\u53cd\u7684\u8d1d\u5c14\u8868\u8fbe\u5f0f\u3002", "result": "\u5728\u9002\u5f53\u5047\u8bbe\u4e0b\uff0c\u8be5\u4e0d\u7b49\u5f0f\u80fd\u591f\u8bbe\u5907\u65e0\u5173\u5730\u8ba4\u8bc1Majorana\u8d39\u7c73\u5b50\uff0c\u5c06\u5176\u7406\u89e3\u4e3aClifford\u4ee3\u6570\u751f\u6210\u5143\u7684\u591a\u91cf\u5b50\u6bd4\u7279\u5b9e\u73b0\u3002", "conclusion": "\u8bc6\u522b\u4e86\u5728\u5c40\u90e8\u7b49\u8ddd\u548c\u8f6c\u7f6e\u4e0d\u53d8\u6027\u4e4b\u5916\u5fc5\u987b\u7eb3\u5165\u81ea\u6d4b\u8bd5\u5b9a\u4e49\u7684\u989d\u5916\u7b49\u4ef7\u6027\uff0c\u8fd9\u79cd\u7b49\u4ef7\u6027\u6e90\u4e8e\u5bf9\u5171\u4eab\u6001\u548c\u6d4b\u91cf\u5e94\u7528\u90e8\u5206\u8f6c\u7f6e\uff0c\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u4fdd\u6301\u6240\u6709\u89c2\u6d4b\u76f8\u5173\u6027\u4e0d\u53d8\u3002"}}
{"id": "2511.18974", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.18974", "abs": "https://arxiv.org/abs/2511.18974", "authors": ["Gesa-R. Siemann", "Davide Curcio", "Anders S. Mortensen", "Charlotte E. Sanders", "Yu Zhang", "Jennifer Rigden", "Paulina Majchrzak", "Deepnarayan Biswas", "Emma Springate", "Ratnadwip Singha", "Leslie M. Schoop", "Philip Hofmann"], "title": "Clustering-Enhanced Time- and Angle-Resolved Photoemission Study of LaTe$_3$: Absence of a Photoinduced Secondary CDW in the Electronic Structure", "comment": null, "summary": "Optical control offers a compelling route for tailoring material properties on an ultrafast time scale. Ordered states such as charge density waves (CDWs) can be transiently melted by an ultrafast light excitation. This is also the case for the rare-earth tritelluride LaTe$_3$, a prototypical CDW compound. For this material it has recently been reported that the suppression of the primary CDW allows the transient formation of a second CDW, whose wave vector is orthogonal to the primary one. This creates the intriguing scenario where light enables switching between two distinct ordered phases of the material. While the second CDW has so far been observed by structural techniques, it remains an open question how the interplay of the two CDW phases is reflected in the material's electronic structure. We investigate this via time- and angle-resolved photoemission measurements of LaTe$_3$. The complex Fermi contour is probed using a FeSuMa analyzer, which records the photoemission intensity of the entire Fermi contour at once. The dynamics revealed by the FeSuMa analyzer are complemented by measurements using a conventional hemispherical electron analyzer. We combine conventional data analysis with $k$-means clustering, an unsupervised machine learning technique, demonstrating its strong potential for disentangling large datasets. While we do not find any features that cannot be explained by the melting and re-establishment of the primary CDW, distinct dynamics and coherent oscillations are observed in the different branches of the Fermi contour.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u65f6\u95f4\u548c\u89d2\u5ea6\u5206\u8fa8\u5149\u7535\u5b50\u80fd\u8c31\u7814\u7a76LaTe$_3$\u6750\u6599\u4e2d\u4e24\u4e2a\u7535\u8377\u5bc6\u5ea6\u6ce2\uff08CDW\uff09\u76f8\u5728\u7535\u5b50\u7ed3\u6784\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u7ed3\u5408\u4f20\u7edf\u5206\u6790\u548c\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u53d1\u73b0\u8d39\u7c73\u8f6e\u5ed3\u4e0d\u540c\u5206\u652f\u5177\u6709\u4e0d\u540c\u7684\u52a8\u529b\u5b66\u548c\u76f8\u5e72\u632f\u8361\u3002", "motivation": "\u7814\u7a76\u5149\u6fc0\u53d1\u4e0bLaTe$_3$\u6750\u6599\u4e2d\u4e24\u4e2a\u6b63\u4ea4CDW\u76f8\u5728\u7535\u5b50\u7ed3\u6784\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u63a2\u7d22\u5149\u8c03\u63a7\u6750\u6599\u6027\u8d28\u7684\u673a\u5236\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u548c\u89d2\u5ea6\u5206\u8fa8\u5149\u7535\u5b50\u80fd\u8c31\u6d4b\u91cf\uff0c\u7ed3\u5408FeSuMa\u5206\u6790\u4eea\u548c\u4f20\u7edf\u534a\u7403\u7535\u5b50\u5206\u6790\u4eea\uff0c\u91c7\u7528\u4f20\u7edf\u6570\u636e\u5206\u6790\u4e0ek-means\u805a\u7c7b\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6280\u672f\u3002", "result": "\u672a\u53d1\u73b0\u65e0\u6cd5\u7528\u4e3bCDW\u7194\u5316\u548c\u91cd\u5efa\u89e3\u91ca\u7684\u7279\u5f81\uff0c\u4f46\u89c2\u5bdf\u5230\u8d39\u7c73\u8f6e\u5ed3\u4e0d\u540c\u5206\u652f\u5177\u6709\u4e0d\u540c\u7684\u52a8\u529b\u5b66\u548c\u76f8\u5e72\u632f\u8361\u3002", "conclusion": "\u867d\u7136\u672a\u68c0\u6d4b\u5230\u7b2c\u4e8cCDW\u76f8\u7684\u76f4\u63a5\u8bc1\u636e\uff0c\u4f46\u8bc1\u660e\u4e86\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u5728\u5206\u6790\u590d\u6742\u6570\u636e\u96c6\u4e2d\u7684\u5f3a\u5927\u6f5c\u529b\uff0c\u5e76\u63ed\u793a\u4e86\u8d39\u7c73\u8f6e\u5ed3\u4e0d\u540c\u533a\u57df\u7684\u72ec\u7279\u52a8\u529b\u5b66\u884c\u4e3a\u3002"}}
{"id": "2511.19389", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.19389", "abs": "https://arxiv.org/abs/2511.19389", "authors": ["Lucas G. Rabelo", "Igor C. Almeida", "Eduardo Miranda", "Vladimir Dobrosavljevi\u0107", "Eric C. Andrade"], "title": "Kondo screening and random-singlet formation in highly disordered systems", "comment": "Main text: 7 pages, 3 figures. Supplemental material: 7 pages, 6 figures", "summary": "We propose a minimal model to capture the anomalous low-temperature thermodynamics of doped semiconductors, such as Si:P, across the metal-insulator transition. We consider pairs of local magnetic moments coupled to a highly disordered, non-interacting electronic bath that undergoes a metal-insulator transition with increasing doping. Using a large-$\\mathcal{N}$ variational approach, we capture both the inhomogeneous local Fermi-liquid and the insulating random-singlet phase, and find that the local moment susceptibility exhibits a robust power-law behavior, $\u03c7(T) \\propto T^{-\u03b1}$, with $\u03b1$ evolving smoothly with doping before saturating in the metal. Our results highlight the competition between Kondo screening and random-singlet formation as the key ingredient in constructing a complete theory for the low-temperature behavior of strongly disordered interacting systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6700\u5c0f\u6a21\u578b\u6765\u6355\u6349\u63ba\u6742\u534a\u5bfc\u4f53\uff08\u5982Si:P\uff09\u5728\u91d1\u5c5e-\u7edd\u7f18\u4f53\u8f6c\u53d8\u8fc7\u7a0b\u4e2d\u7684\u5f02\u5e38\u4f4e\u6e29\u70ed\u529b\u5b66\u884c\u4e3a\uff0c\u91cd\u70b9\u5173\u6ce8\u5c40\u57df\u78c1\u77e9\u4e0e\u65e0\u5e8f\u7535\u5b50\u6d74\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u63ba\u6742\u534a\u5bfc\u4f53\u5728\u91d1\u5c5e-\u7edd\u7f18\u4f53\u8f6c\u53d8\u8fc7\u7a0b\u4e2d\u7684\u4f4e\u6e29\u70ed\u529b\u5b66\u5f02\u5e38\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5c40\u57df\u78c1\u77e9\u7684\u54cd\u5e94\u7279\u6027\uff0c\u4e3a\u5f3a\u65e0\u5e8f\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u7684\u5b8c\u6574\u7406\u8bba\u63d0\u4f9b\u5173\u952e\u8981\u7d20\u3002", "method": "\u91c7\u7528\u5927N\u53d8\u5206\u65b9\u6cd5\uff0c\u8003\u8651\u5c40\u57df\u78c1\u77e9\u5bf9\u4e0e\u9ad8\u5ea6\u65e0\u5e8f\u3001\u975e\u76f8\u4e92\u4f5c\u7528\u7535\u5b50\u6d74\u7684\u8026\u5408\uff0c\u8be5\u7535\u5b50\u6d74\u968f\u63ba\u6742\u589e\u52a0\u7ecf\u5386\u91d1\u5c5e-\u7edd\u7f18\u4f53\u8f6c\u53d8\u3002", "result": "\u6a21\u578b\u6355\u6349\u5230\u4e86\u975e\u5747\u5300\u5c40\u57df\u8d39\u7c73\u6db2\u4f53\u548c\u7edd\u7f18\u968f\u673a\u5355\u91cd\u6001\u76f8\uff0c\u53d1\u73b0\u5c40\u57df\u78c1\u77e9\u78c1\u5316\u7387\u5448\u73b0\u7a33\u5065\u7684\u5e42\u5f8b\u884c\u4e3a\u03c7(T) \u221d T^{-\u03b1}\uff0c\u5176\u4e2d\u03b1\u968f\u63ba\u6742\u5e73\u6ed1\u6f14\u5316\u5e76\u5728\u91d1\u5c5e\u4e2d\u9971\u548c\u3002", "conclusion": "Kondo\u5c4f\u853d\u4e0e\u968f\u673a\u5355\u91cd\u6001\u5f62\u6210\u4e4b\u95f4\u7684\u7ade\u4e89\u662f\u6784\u5efa\u5f3a\u65e0\u5e8f\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u4f4e\u6e29\u884c\u4e3a\u5b8c\u6574\u7406\u8bba\u7684\u5173\u952e\u8981\u7d20\u3002"}}
{"id": "2511.18361", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.18361", "abs": "https://arxiv.org/abs/2511.18361", "authors": ["Anweshika Pattanayak", "Sandip Roy", "Abhishek Chaudhuri"], "title": "Inertia-chirality interplay in active Brownian motion: exact dynamics and phase maps", "comment": null, "summary": "We present an exact, time-resolved theory for a two-dimensional chiral active Brownian particle (cABP) with translational inertia. Using a Laplace-transform moment hierarchy, we derive closed-form expressions for the mean velocity, velocity-orientation projections, velocity autocorrelation, mean-squared velocity, mean-squared displacement, and the fourth moment of velocity. These results agree quantitatively with simulations over all masses, activities, and chiralities. We show that the velocity autocorrelation factorizes into an inertial envelope and a chiral envelope. Despite rich transients in the velocity sector, the long-time positional diffusion equals the overdamped cABP value, independent of mass. From the steady mean-squared velocity, we define a kinetic temperature and a modified fluctuation-dissipation relation whose violation vanishes in two limits: large mass or large chirality, identifying chirality as an additional route to equilibrium-like behavior. The steady-state velocity excess kurtosis gives a phase map that exhibits a (Gaussian-like)-active(bimodal)-(Gaussian-like) re-entrance with mass; chirality confines activity and shrinks the active sector. A narrow positive-kurtosis window emerges at large mass and intermediate chirality, with analytic boundaries consistent with the heavy-mass asymptote.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e8c\u7ef4\u624b\u6027\u6d3b\u6027\u5e03\u6717\u7c92\u5b50\uff08cABP\uff09\u7684\u7cbe\u786e\u65f6\u95f4\u5206\u8fa8\u7406\u8bba\uff0c\u63a8\u5bfc\u4e86\u901f\u5ea6\u3001\u901f\u5ea6\u81ea\u76f8\u5173\u3001\u5747\u65b9\u4f4d\u79fb\u7b49\u5173\u952e\u7269\u7406\u91cf\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86\u60ef\u6027\u5305\u7edc\u4e0e\u624b\u6027\u5305\u7edc\u7684\u56e0\u5b50\u5206\u89e3\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u624b\u6027\u6d3b\u6027\u5e03\u6717\u7c92\u5b50\u5728\u60ef\u6027\u6548\u5e94\u4e0b\u7684\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u63a2\u7d22\u8d28\u91cf\u3001\u6d3b\u6027\u548c\u624b\u6027\u5bf9\u7c92\u5b50\u8fd0\u52a8\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u7406\u89e3\u8fd9\u4e9b\u56e0\u7d20\u5982\u4f55\u5bfc\u81f4\u5e73\u8861\u6001\u884c\u4e3a\u7684\u51fa\u73b0\u3002", "method": "\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u53d8\u6362\u77e9\u5c42\u6b21\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e86\u5e73\u5747\u901f\u5ea6\u3001\u901f\u5ea6\u81ea\u76f8\u5173\u3001\u5747\u65b9\u4f4d\u79fb\u7b49\u7269\u7406\u91cf\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u4e0e\u6a21\u62df\u7ed3\u679c\u8fdb\u884c\u5b9a\u91cf\u6bd4\u8f83\u3002", "result": "\u901f\u5ea6\u81ea\u76f8\u5173\u53ef\u5206\u89e3\u4e3a\u60ef\u6027\u5305\u7edc\u548c\u624b\u6027\u5305\u7edc\uff1b\u957f\u671f\u4f4d\u7f6e\u6269\u6563\u4e0e\u8fc7\u963b\u5c3ccABP\u503c\u76f8\u540c\uff0c\u4e0e\u8d28\u91cf\u65e0\u5173\uff1b\u624b\u6027\u53ef\u4f5c\u4e3a\u5b9e\u73b0\u7c7b\u5e73\u8861\u884c\u4e3a\u7684\u989d\u5916\u9014\u5f84\uff1b\u901f\u5ea6\u8d85\u5cf0\u5ea6\u76f8\u56fe\u663e\u793a\u91cd\u5165\u8f6c\u53d8\u73b0\u8c61\u3002", "conclusion": "\u624b\u6027\u6d3b\u6027\u5e03\u6717\u7c92\u5b50\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u7531\u60ef\u6027\u3001\u6d3b\u6027\u548c\u624b\u6027\u5171\u540c\u51b3\u5b9a\uff0c\u624b\u6027\u80fd\u591f\u9650\u5236\u6d3b\u6027\u6548\u5e94\u5e76\u7f29\u5c0f\u6d3b\u6027\u533a\u57df\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u5bfc\u81f4\u7c7b\u5e73\u8861\u884c\u4e3a\u7684\u51fa\u73b0\u3002"}}
{"id": "2511.17770", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.17770", "abs": "https://arxiv.org/abs/2511.17770", "authors": ["Daniele Amato", "Paolo Facchi", "Arturo Konderak"], "title": "Asymptotic dynamics in the Heisenberg picture: attractor subspace and Choi-Effros product", "comment": "22 pages", "summary": "We study the asymptotic dynamics of open quantum systems in the Heisenberg picture. We find an explicit expression for the attractor subspace and the dynamics that takes place in it. We present the relationship between the attractor subspaces in the Schr\u00f6dinger and Heisenberg pictures and, in particular, the connection between their algebraic structures. An unfolding theorem of the asymptotics, as well as the fine structure of the recently introduced Choi-Effros decoherence-free algebra, are also discussed. Finally, we show how to extend all the results to the class of Schwarz maps.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6d77\u68ee\u5821\u7ed8\u666f\u4e2d\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u6e10\u8fd1\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u4e86\u5438\u5f15\u5b50\u5b50\u7a7a\u95f4\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\u53ca\u5176\u52a8\u529b\u5b66\uff0c\u5e76\u8ba8\u8bba\u4e86\u859b\u5b9a\u8c14\u7ed8\u666f\u4e0e\u6d77\u68ee\u5821\u7ed8\u666f\u4e2d\u5438\u5f15\u5b50\u5b50\u7a7a\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u4ee3\u6570\u7ed3\u6784\u8054\u7cfb\u3002", "motivation": "\u7814\u7a76\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u5728\u6d77\u68ee\u5821\u7ed8\u666f\u4e2d\u7684\u6e10\u8fd1\u52a8\u529b\u5b66\u7279\u6027\uff0c\u7279\u522b\u662f\u5438\u5f15\u5b50\u5b50\u7a7a\u95f4\u7684\u7ed3\u6784\u548c\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u4ee5\u53ca\u4e0d\u540c\u7ed8\u666f\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u5b66\u63a8\u5bfc\uff0c\u5efa\u7acb\u4e86\u6d77\u68ee\u5821\u7ed8\u666f\u4e2d\u5438\u5f15\u5b50\u5b50\u7a7a\u95f4\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\uff0c\u7814\u7a76\u4e86\u859b\u5b9a\u8c14\u7ed8\u666f\u4e0e\u6d77\u68ee\u5821\u7ed8\u666f\u4e2d\u5438\u5f15\u5b50\u5b50\u7a7a\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u4ee3\u6570\u7ed3\u6784\u3002", "result": "\u83b7\u5f97\u4e86\u6d77\u68ee\u5821\u7ed8\u666f\u4e2d\u5438\u5f15\u5b50\u5b50\u7a7a\u95f4\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\uff0c\u9610\u660e\u4e86\u4e0d\u540c\u7ed8\u666f\u4e2d\u5438\u5f15\u5b50\u5b50\u7a7a\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u4ee3\u6570\u7ed3\u6784\u8054\u7cfb\uff0c\u8ba8\u8bba\u4e86\u6e10\u8fd1\u5c55\u5f00\u5b9a\u7406\u548cChoi-Effros\u9000\u76f8\u5e72\u81ea\u7531\u4ee3\u6570\u7684\u7cbe\u7ec6\u7ed3\u6784\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u4e86\u6d77\u68ee\u5821\u7ed8\u666f\u4e2d\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u6e10\u8fd1\u52a8\u529b\u5b66\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5c06\u6240\u6709\u7ed3\u679c\u63a8\u5e7f\u5230Schwarz\u6620\u5c04\u7c7b\u4e2d\uff0c\u4e3a\u7406\u89e3\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u957f\u671f\u52a8\u529b\u5b66\u884c\u4e3a\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.17673", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17673", "abs": "https://arxiv.org/abs/2511.17673", "authors": ["Myung Ho Kim"], "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "comment": "27 pages", "summary": "Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u8ba4\u77e5\u5faa\u73af\uff08SCL\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u8ba4\u77e5\u660e\u786e\u5206\u79bb\u4e3a\u4e94\u4e2a\u9636\u6bb5\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u96f6\u7b56\u7565\u8fdd\u89c4\u3001\u6d88\u9664\u5197\u4f59\u5de5\u5177\u8c03\u7528\u548c\u5b8c\u5168\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5b58\u5728\u7684\u4e09\u4e2a\u57fa\u672c\u67b6\u6784\u95ee\u9898\uff1a\u63a8\u7406\u4e0e\u6267\u884c\u7ea0\u7f20\u3001\u5185\u5b58\u6613\u5931\u6027\u548c\u4e0d\u53ef\u63a7\u52a8\u4f5c\u5e8f\u5217\u3002", "method": "\u5f15\u5165\u7ed3\u6784\u5316\u8ba4\u77e5\u5faa\u73af\uff08SCL\uff09\u67b6\u6784\uff0c\u5c06\u667a\u80fd\u4f53\u8ba4\u77e5\u5206\u79bb\u4e3a\u68c0\u7d22\u3001\u8ba4\u77e5\u3001\u63a7\u5236\u3001\u52a8\u4f5c\u548c\u8bb0\u5fc6\u4e94\u4e2a\u9636\u6bb5\uff0c\u6838\u5fc3\u662f\u8f6f\u7b26\u53f7\u63a7\u5236\u673a\u5236\uff0c\u5c06\u7b26\u53f7\u7ea6\u675f\u5e94\u7528\u4e8e\u6982\u7387\u63a8\u7406\u3002", "result": "\u5728\u591a\u6b65\u6761\u4ef6\u63a8\u7406\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0cSCL\u5b9e\u73b0\u4e86\u96f6\u7b56\u7565\u8fdd\u89c4\u3001\u6d88\u9664\u5197\u4f59\u5de5\u5177\u8c03\u7528\u548c\u5b8c\u5168\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\uff0c\u89e3\u51b3\u4e86ReAct\u3001AutoGPT\u548c\u5185\u5b58\u589e\u5f3a\u65b9\u6cd5\u7684\u5173\u952e\u7f3a\u9677\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4e13\u5bb6\u7cfb\u7edf\u539f\u5219\u4e0e\u73b0\u4ee3LLM\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u4e3a\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6cbb\u7406\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u7406\u8bba\u57fa\u7840\u624e\u5b9e\u7684\u8def\u5f84\u3002"}}
{"id": "2511.17573", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17573", "abs": "https://arxiv.org/abs/2511.17573", "authors": ["Michael J. Bommarito"], "title": "Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis", "comment": "17 pages, 3 figures, 9 tables. Paper source available at https://github.com/mjbommar/binary-tokenizer-paper ; tokenizers available at https://huggingface.co/mjbommar - mjbommar/binary-tokenizer-001-{4k,8k,16k,32k,64k}", "summary": "Sequence models for binary analysis are bottlenecked by byte-level tokenization: raw bytes waste precious context window capacity for transformers and other neural network architectures, and many existing text-oriented tokenizers fail on arbitrary 0x00--0xFF sequences. To address this issue, we introduce the Binary BPE tokenizer family, a set of cross-platform Byte Pair Encoding (BPE) tokenizers for executables trained on a large corpus of binaries spanning multiple platforms, architectures, and operating systems, including Linux, Windows, macOS, Android, and malware sources. We release trained tokenizers with vocabularies of 4K, 8K, 16K, 32K, and 64K tokens, enabling both systematic scaling studies and practical deployment from resource-constrained edge devices to high-throughput datacenters. These tokenizers discover interpretable patterns (ELF/PE headers, instruction sequences, cross-platform strings) while yielding multi-byte compression per token. On representative uncompressed executables (e.g., ELF/PE/Mach-O rather than compressed APKs), the Binary BPE tokenizers typically allow for roughly 2-3x more binary content per fixed-length transformer context window than raw bytes, enabling more efficient research and practical deployment for content identification, malware detection, reverse engineering, and optimization. We release the trained Binary BPE tokenizers on HuggingFace, providing a drop-in, open-source foundation for binary-focused language models and context-efficient agentic tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Binary BPE\u5206\u8bcd\u5668\u5bb6\u65cf\uff0c\u4e13\u95e8\u7528\u4e8e\u4e8c\u8fdb\u5236\u5206\u6790\uff0c\u901a\u8fc7\u5b57\u8282\u5bf9\u7f16\u7801\u5728\u5927\u578b\u4e8c\u8fdb\u5236\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\uff0c\u63d0\u4f9b4K-64K\u8bcd\u6c47\u8868\uff0c\u76f8\u6bd4\u539f\u59cb\u5b57\u8282\u80fd\u5728\u56fa\u5b9a\u957f\u5ea6transformer\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u5bb9\u7eb32-3\u500d\u591a\u7684\u4e8c\u8fdb\u5236\u5185\u5bb9\u3002", "motivation": "\u89e3\u51b3\u4e8c\u8fdb\u5236\u5206\u6790\u4e2d\u5e8f\u5217\u6a21\u578b\u7684\u74f6\u9888\u95ee\u9898\uff1a\u539f\u59cb\u5b57\u8282\u6d6a\u8d39transformer\u4e0a\u4e0b\u6587\u7a97\u53e3\u5bb9\u91cf\uff0c\u73b0\u6709\u6587\u672c\u5206\u8bcd\u5668\u65e0\u6cd5\u5904\u74060x00-0xFF\u4efb\u610f\u5b57\u8282\u5e8f\u5217\u3002", "method": "\u5f00\u53d1\u8de8\u5e73\u53f0Byte Pair Encoding\u5206\u8bcd\u5668\uff0c\u5728\u5305\u542bLinux\u3001Windows\u3001macOS\u3001Android\u548c\u6076\u610f\u8f6f\u4ef6\u7684\u5927\u578b\u4e8c\u8fdb\u5236\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\uff0c\u63d0\u4f9b4K\u30018K\u300116K\u300132K\u548c64K\u8bcd\u6c47\u8868\u7684\u5206\u8bcd\u5668\u3002", "result": "\u5206\u8bcd\u5668\u53d1\u73b0\u4e86\u53ef\u89e3\u91ca\u6a21\u5f0f\uff08ELF/PE\u5934\u3001\u6307\u4ee4\u5e8f\u5217\u3001\u8de8\u5e73\u53f0\u5b57\u7b26\u4e32\uff09\uff0c\u6bcf\u4e2atoken\u5b9e\u73b0\u591a\u5b57\u8282\u538b\u7f29\u3002\u5728\u672a\u538b\u7f29\u53ef\u6267\u884c\u6587\u4ef6\u4e0a\uff0c\u76f8\u6bd4\u539f\u59cb\u5b57\u8282\u80fd\u5728\u56fa\u5b9a\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u5bb9\u7eb32-3\u500d\u591a\u7684\u4e8c\u8fdb\u5236\u5185\u5bb9\u3002", "conclusion": "Binary BPE\u5206\u8bcd\u5668\u4e3a\u4e8c\u8fdb\u5236\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u57fa\u7840\uff0c\u652f\u6301\u5185\u5bb9\u8bc6\u522b\u3001\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u3001\u9006\u5411\u5de5\u7a0b\u548c\u4f18\u5316\u7b49\u5e94\u7528\uff0c\u5df2\u5728HuggingFace\u53d1\u5e03\u3002"}}
{"id": "2511.19193", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19193", "abs": "https://arxiv.org/abs/2511.19193", "authors": ["E. V. Gorbar", "B. E. Grinyuk", "V. P. Gusynin"], "title": "Bound states for systems with quartic energy-momentum dispersion", "comment": "11 pages, 5 figures", "summary": "Bound states and its energies for systems with the quartic energy-momentum dispersion $E(p) \\sim p^4$ and polynomial potentials are studied using the Wentzel-Kramers-Brillouin (WKB) semiclassical approximation and the Wentzel complex method taking into account higher order WKB corrections. The obtained energies are compared with numerical values found by applying the variational approach utilizing the universal Gaussian basis. It is found that the wave functions of the ground and higher-energy states for systems with quartic dispersion have nodes in the classically forbidden region. Thus, the well-known oscillation theorem for the one-dimensional Schr\u00f6dinger equation is not, in general, applicable for systems with quartic dispersion. Still it is observed that the oscillation theorem holds in the classically allowed region in all considered examples. The properties of bound state wave functions are compared with the solutions of the exactly solvable problem of a square well potential.", "AI": {"tldr": "\u7814\u7a76\u5177\u6709\u56db\u6b21\u80fd\u91cf-\u52a8\u91cf\u8272\u6563E(p)~p^4\u548c\u591a\u9879\u5f0f\u52bf\u80fd\u7cfb\u7edf\u7684\u675f\u7f1a\u6001\u53ca\u5176\u80fd\u91cf\uff0c\u4f7f\u7528WKB\u534a\u7ecf\u5178\u8fd1\u4f3c\u548cWentzel\u590d\u65b9\u6cd5\uff0c\u8003\u8651\u9ad8\u9636WKB\u4fee\u6b63\u3002\u53d1\u73b0\u56db\u6b21\u8272\u6563\u7cfb\u7edf\u7684\u6ce2\u51fd\u6570\u5728\u7ecf\u5178\u7981\u6212\u533a\u6709\u8282\u70b9\uff0c\u4e00\u7ef4\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u632f\u8361\u5b9a\u7406\u4e0d\u9002\u7528\uff0c\u4f46\u5728\u7ecf\u5178\u5141\u8bb8\u533a\u4ecd\u6210\u7acb\u3002", "motivation": "\u7814\u7a76\u5177\u6709\u56db\u6b21\u80fd\u91cf-\u52a8\u91cf\u8272\u6563\u7cfb\u7edf\u7684\u675f\u7f1a\u6001\u6027\u8d28\uff0c\u7279\u522b\u662f\u9a8c\u8bc1\u632f\u8361\u5b9a\u7406\u5728\u975e\u6807\u51c6\u8272\u6563\u5173\u7cfb\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528WKB\u534a\u7ecf\u5178\u8fd1\u4f3c\u548cWentzel\u590d\u65b9\u6cd5\uff0c\u8003\u8651\u9ad8\u9636WKB\u4fee\u6b63\uff0c\u5e76\u4e0e\u53d8\u5206\u65b9\u6cd5\u4f7f\u7528\u901a\u7528\u9ad8\u65af\u57fa\u5f97\u5230\u7684\u6570\u503c\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u56db\u6b21\u8272\u6563\u7cfb\u7edf\u7684\u6ce2\u51fd\u6570\u5728\u7ecf\u5178\u7981\u6212\u533a\u6709\u8282\u70b9\uff0c\u632f\u8361\u5b9a\u7406\u4e0d\u9002\u7528\uff0c\u4f46\u5728\u7ecf\u5178\u5141\u8bb8\u533a\u4ecd\u6210\u7acb\u3002\u4e0e\u65b9\u52bf\u9631\u7cbe\u786e\u89e3\u8fdb\u884c\u6bd4\u8f83\u3002", "conclusion": "\u5bf9\u4e8e\u5177\u6709\u56db\u6b21\u80fd\u91cf-\u52a8\u91cf\u8272\u6563\u7684\u7cfb\u7edf\uff0c\u4e00\u7ef4\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u632f\u8361\u5b9a\u7406\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\u4e0d\u9002\u7528\uff0c\u4f46\u5728\u7ecf\u5178\u5141\u8bb8\u533a\u57df\u4ecd\u7136\u6709\u6548\u3002"}}
{"id": "2511.19409", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.19409", "abs": "https://arxiv.org/abs/2511.19409", "authors": ["Arnab Seth", "Fay Borhani", "Itamar Kimchi"], "title": "Chiral spin liquid instability of the Kitaev honeycomb model with crystallographic defects", "comment": "7 pages, 3 figures", "summary": "We study the spin-1/2 Kitaev honeycomb gapless spin liquid in the presence of Stone-Wales-type local lattice defects with odd-sided plaquettes. While the clean Kitaev model has no finite-temperature phase transitions, we find that introducing a finite defect density $n_d\\approx 10^{-4}$--$10^{-2}$ produces a true phase transition with a sizeable $T_c \\approx 2 n_d$ in units of the Kitaev exchange. The resulting non-Abelian chiral quantum spin liquid exhibits scalar spin chirality and electron orbital magnetization which peak near lattice defects. This disorder-driven instability relies on an emergent long range ferromagnetic interaction $r^{-\u03b3}$ ($\u03b3\\approx 2.7$) between defect chiralities, mediated by the nearly-gapless fermions, with implications for topology generation in Dirac cones with fluctuating mass terms.", "AI": {"tldr": "\u5728\u81ea\u65cb-1/2 Kitaev\u8702\u7a9d\u6676\u683c\u65e0\u80fd\u9699\u81ea\u65cb\u6db2\u4f53\u4e2d\u5f15\u5165Stone-Wales\u578b\u6676\u683c\u7f3a\u9677\uff08\u5947\u6570\u8fb9\u591a\u8fb9\u5f62\uff09\u4f1a\u5bfc\u81f4\u6709\u9650\u6e29\u5ea6\u76f8\u53d8\uff0c\u4ea7\u751f\u975e\u963f\u8d1d\u5c14\u624b\u6027\u91cf\u5b50\u81ea\u65cb\u6db2\u4f53\u3002", "motivation": "\u7814\u7a76\u6676\u683c\u7f3a\u9677\u5982\u4f55\u5f71\u54cd\u6e05\u6d01Kitaev\u6a21\u578b\u7684\u65e0\u76f8\u53d8\u7279\u6027\uff0c\u63a2\u7d22\u7f3a\u9677\u8bf1\u5bfc\u7684\u62d3\u6251\u76f8\u53d8\u673a\u5236\u3002", "method": "\u5728Kitaev\u8702\u7a9d\u6a21\u578b\u4e2d\u5f15\u5165\u6709\u9650\u5bc6\u5ea6\u7684Stone-Wales\u578b\u6676\u683c\u7f3a\u9677\uff08n_d\u224810^-4-10^-2\uff09\uff0c\u5206\u6790\u7f3a\u9677\u624b\u6027\u4e4b\u95f4\u7684\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u7f3a\u9677\u5bc6\u5ea6n_d\u224810^-4-10^-2\u4f1a\u4ea7\u751f\u771f\u5b9e\u76f8\u53d8\uff0cTc\u22482n_d\uff0c\u5f62\u6210\u5177\u6709\u6807\u91cf\u81ea\u65cb\u624b\u6027\u548c\u7535\u5b50\u8f68\u9053\u78c1\u5316\u7684\u975e\u963f\u8d1d\u5c14\u624b\u6027\u91cf\u5b50\u81ea\u65cb\u6db2\u4f53\u3002", "conclusion": "\u6676\u683c\u7f3a\u9677\u901a\u8fc7\u4ecb\u5bfc\u7f3a\u9677\u624b\u6027\u95f4\u7684\u957f\u7a0b\u94c1\u78c1\u76f8\u4e92\u4f5c\u7528\uff08r^-\u03b3\uff0c\u03b3\u22482.7\uff09\uff0c\u5728\u72c4\u62c9\u514b\u9525\u4e2d\u4ea7\u751f\u62d3\u6251\u76f8\u53d8\uff0c\u4e3a\u62d3\u6251\u6001\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u673a\u5236\u3002"}}
{"id": "2511.18462", "categories": ["cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.18462", "abs": "https://arxiv.org/abs/2511.18462", "authors": ["Shuo Wei", "Haoyu Liu", "Xin Sun", "Youjin Deng", "Ming Li"], "title": "Evolving criticality in iterative bicolored percolation", "comment": "6 pages, 3 figures", "summary": "Criticality is traditionally regarded as an unstable, fine-tuned fixed point of the renormalization group. We introduce an iterative bicolored percolation process in two dimensions and show that it can both preserve and transform criticality. Starting from critical configurations, such as the O$(n)$ loop and fuzzy Potts models, successive coarse-graining generates a hierarchy of distinct yet critical generations. Using the conformal loop ensemble, we derive exact, generation-dependent fractal dimensions, which are quantitatively confirmed by large-scale Monte Carlo simulations. The evolutionary trajectory depends not only on the universality class of the initial state but also on whether it possesses a two-state critical structure, leading to different critical exponents starting from site and bond percolation. These results establish a general geometric mechanism for evolving criticality, in which scale invariance persists across generations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4e8c\u7ef4\u8fed\u4ee3\u53cc\u8272\u6e17\u6d41\u8fc7\u7a0b\uff0c\u80fd\u591f\u4fdd\u6301\u548c\u8f6c\u53d8\u4e34\u754c\u6027\u3002\u4ece\u4e34\u754c\u914d\u7f6e\u5f00\u59cb\uff0c\u901a\u8fc7\u8fde\u7eed\u7c97\u7c92\u5316\u4ea7\u751f\u4e00\u7cfb\u5217\u4e0d\u540c\u4f46\u90fd\u5904\u4e8e\u4e34\u754c\u72b6\u6001\u7684\u4ee3\u6b21\uff0c\u5e76\u63a8\u5bfc\u4e86\u7cbe\u786e\u7684\u4e0e\u4ee3\u6b21\u76f8\u5173\u7684\u5206\u5f62\u7ef4\u6570\u3002", "motivation": "\u4f20\u7edf\u4e0a\u4e34\u754c\u6027\u88ab\u89c6\u4e3a\u91cd\u6b63\u5316\u7fa4\u7684\u4e0d\u7a33\u5b9a\u3001\u7cbe\u7ec6\u8c03\u8282\u7684\u56fa\u5b9a\u70b9\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e34\u754c\u6027\u5982\u4f55\u80fd\u591f\u88ab\u4fdd\u6301\u548c\u8f6c\u53d8\uff0c\u5efa\u7acb\u4e00\u79cd\u6f14\u5316\u4e34\u754c\u6027\u7684\u51e0\u4f55\u673a\u5236\u3002", "method": "\u4f7f\u7528\u4e8c\u7ef4\u8fed\u4ee3\u53cc\u8272\u6e17\u6d41\u8fc7\u7a0b\uff0c\u4eceO(n)\u73af\u6a21\u578b\u548c\u6a21\u7ccaPotts\u6a21\u578b\u7b49\u4e34\u754c\u914d\u7f6e\u51fa\u53d1\uff0c\u901a\u8fc7\u8fde\u7eed\u7c97\u7c92\u5316\u751f\u6210\u4e34\u754c\u4ee3\u6b21\u5c42\u6b21\u7ed3\u6784\u3002\u5229\u7528\u5171\u5f62\u73af\u7cfb\u7efc\u63a8\u5bfc\u5206\u5f62\u7ef4\u6570\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6f14\u5316\u8f68\u8ff9\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u521d\u59cb\u72b6\u6001\u7684\u666e\u9002\u7c7b\uff0c\u8fd8\u53d6\u51b3\u4e8e\u5176\u662f\u5426\u5177\u6709\u53cc\u6001\u4e34\u754c\u7ed3\u6784\uff0c\u5bfc\u81f4\u4ece\u683c\u70b9\u6e17\u6d41\u548c\u952e\u6e17\u6d41\u51fa\u53d1\u4ea7\u751f\u4e0d\u540c\u7684\u4e34\u754c\u6307\u6570\u3002\u63a8\u5bfc\u7684\u4e0e\u4ee3\u6b21\u76f8\u5173\u7684\u5206\u5f62\u7ef4\u6570\u5f97\u5230\u4e86\u6570\u503c\u6a21\u62df\u7684\u5b9a\u91cf\u786e\u8ba4\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5efa\u7acb\u4e86\u4e00\u79cd\u6f14\u5316\u4e34\u754c\u6027\u7684\u901a\u7528\u51e0\u4f55\u673a\u5236\uff0c\u5176\u4e2d\u6807\u5ea6\u4e0d\u53d8\u6027\u5728\u4ee3\u6b21\u95f4\u6301\u7eed\u5b58\u5728\u3002"}}
{"id": "2511.17779", "categories": ["quant-ph", "cond-mat.other", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.17779", "abs": "https://arxiv.org/abs/2511.17779", "authors": ["Elijah Pelofske", "Pratik Sathe", "Cristiano Nisoli", "Frank Barrows"], "title": "Probing Antiferromagnetic Hysteresis on Programmable Quantum Annealers", "comment": null, "summary": "Using programmable analog quantum annealing processors, we implement a sampling-based magnetic hysteresis protocol to probe the counterintuitive notion of magnetic memory of antiferromagnets. A key component of this protocol responsible for the hysteresis is a transverse field, which enables state transitions, while the magnetic field sweep is done via a longitudinal control field. We present evidence of full saturation and reversal of the hysteresis curve, as well as emergent magnetic domain mediated by quantum fluctuations that give rise to the magnetic memory effect in antiferromagnets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4f7f\u7528\u53ef\u7f16\u7a0b\u6a21\u62df\u91cf\u5b50\u9000\u706b\u5904\u7406\u5668\uff0c\u901a\u8fc7\u57fa\u4e8e\u91c7\u6837\u7684\u78c1\u6ede\u534f\u8bae\u6765\u7814\u7a76\u53cd\u94c1\u78c1\u4f53\u7684\u78c1\u8bb0\u5fc6\u6548\u5e94\uff0c\u5c55\u793a\u4e86\u5b8c\u6574\u7684\u9971\u548c\u548c\u53cd\u8f6c\u78c1\u6ede\u66f2\u7ebf\uff0c\u4ee5\u53ca\u7531\u91cf\u5b50\u6da8\u843d\u4ecb\u5bfc\u7684\u78c1\u7574\u51fa\u73b0\u3002", "motivation": "\u7814\u7a76\u53cd\u94c1\u78c1\u4f53\u7684\u53cd\u76f4\u89c9\u78c1\u8bb0\u5fc6\u6982\u5ff5\uff0c\u63a2\u7d22\u5176\u5728\u91cf\u5b50\u9000\u706b\u5904\u7406\u5668\u4e2d\u7684\u5b9e\u73b0\u548c\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u53ef\u7f16\u7a0b\u6a21\u62df\u91cf\u5b50\u9000\u706b\u5904\u7406\u5668\uff0c\u5b9e\u65bd\u57fa\u4e8e\u91c7\u6837\u7684\u78c1\u6ede\u534f\u8bae\uff0c\u5176\u4e2d\u6a2a\u5411\u573a\u5b9e\u73b0\u72b6\u6001\u8dc3\u8fc1\uff0c\u7eb5\u5411\u63a7\u5236\u573a\u8fdb\u884c\u78c1\u573a\u626b\u63cf\u3002", "result": "\u5c55\u793a\u4e86\u5b8c\u6574\u7684\u9971\u548c\u548c\u53cd\u8f6c\u78c1\u6ede\u66f2\u7ebf\uff0c\u4ee5\u53ca\u7531\u91cf\u5b50\u6da8\u843d\u4ecb\u5bfc\u7684\u78c1\u7574\u51fa\u73b0\uff0c\u8fd9\u4e9b\u73b0\u8c61\u5171\u540c\u4ea7\u751f\u4e86\u53cd\u94c1\u78c1\u4f53\u7684\u78c1\u8bb0\u5fc6\u6548\u5e94\u3002", "conclusion": "\u6210\u529f\u5728\u91cf\u5b50\u9000\u706b\u5904\u7406\u5668\u4e2d\u5b9e\u73b0\u4e86\u53cd\u94c1\u78c1\u4f53\u7684\u78c1\u8bb0\u5fc6\u6548\u5e94\uff0c\u8bc1\u660e\u4e86\u91cf\u5b50\u6da8\u843d\u5728\u78c1\u6ede\u73b0\u8c61\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2511.17714", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17714", "abs": "https://arxiv.org/abs/2511.17714", "authors": ["Alex John London", "Aydin Mohseni"], "title": "Learning the Value of Value Learning", "comment": "27 pages, 6 figures, mathematical appendix", "summary": "Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Jeffrey-Bolker\u51b3\u7b56\u6846\u67b6\uff0c\u5c06\u4ef7\u503c\u7cbe\u70bc\u7eb3\u5165\u7406\u6027\u9009\u62e9\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u4ef7\u503c\u7cbe\u70bc\u5982\u4f55\u5c06\u96f6\u548c\u535a\u5f08\u8f6c\u5316\u4e3a\u6b63\u548c\u4e92\u52a8\u3002", "motivation": "\u4f20\u7edf\u51b3\u7b56\u6846\u67b6\u53ea\u5904\u7406\u4e8b\u5b9e\u4e0d\u786e\u5b9a\u6027\u800c\u5047\u8bbe\u4ef7\u503c\u56fa\u5b9a\uff0c\u672c\u6587\u65e8\u5728\u6269\u5c55\u7406\u6027\u9009\u62e9\u7406\u8bba\u4ee5\u5efa\u6a21\u4ef7\u503c\u7cbe\u70bc\u8fc7\u7a0b\u53ca\u5176\u76f8\u5173\u6536\u76ca\u3002", "method": "\u6269\u5c55Jeffrey-Bolker\u6846\u67b6\u6765\u5efa\u6a21\u4ef7\u503c\u7cbe\u70bc\uff0c\u8bc1\u660e\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u5206\u6790\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u76f8\u4e92\u4ef7\u503c\u7cbe\u70bc\u6548\u5e94\u3002", "result": "\u5efa\u7acb\u4e86\u4ef7\u503c\u7cbe\u70bc\u7684\u4fe1\u606f\u4ef7\u503c\u5b9a\u7406\uff0c\u8bc1\u660e\u76f8\u4e92\u4ef7\u503c\u7cbe\u70bc\u80fd\u591f\u5c06\u96f6\u548c\u535a\u5f08\u8f6c\u5316\u4e3a\u6b63\u548c\u4e92\u52a8\uff0c\u5e76\u4ea7\u751f\u5e15\u7d2f\u6258\u6539\u8fdb\u7684\u7eb3\u4ec0\u8ba8\u4ef7\u8fd8\u4ef7\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8ba4\u77e5\u7cbe\u70bc\u548c\u4ef7\u503c\u7cbe\u70bc\u7edf\u4e00\u5728\u5355\u4e00\u5f62\u5f0f\u5316\u6846\u67b6\u4e0b\uff0c\u6269\u5c55\u4e86\u7406\u6027\u9009\u62e9\u7684\u6982\u5ff5\u57fa\u7840\uff0c\u9610\u660e\u4e86\u4f26\u7406\u5ba1\u8bae\u7684\u89c4\u8303\u5730\u4f4d\u3002"}}
{"id": "2511.17577", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17577", "abs": "https://arxiv.org/abs/2511.17577", "authors": ["Fengming Yu", "Qingyu Meng", "Haiwei Pan", "Kejia Zhang"], "title": "Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation", "comment": "12 pages, 1 figure", "summary": "With the rapid development of deep learning, large language models have shown strong capabilities in complex reasoning tasks such as mathematical equation solving. However, their substantial computational and storage costs hinder practical deployment. This paper proposes a lightweight optimization method that integrates dynamic attention head pruning with knowledge distillation. The approach dynamically evaluates the importance of each attention head in the multi-head attention mechanism using a combination of weight norms and entropy, and prunes redundant heads in real time to reduce computational overhead. To mitigate performance degradation, knowledge distillation transfers information from the original model to the pruned student, enabling the smaller model to preserve reasoning ability. Experiments conducted on both Math23k and ASDiv-A verify the effectiveness of the proposed method. For example, on Math23k with a 30% pruning ratio, parameters are reduced by 18.7%, inference speed is improved by 27.5%, FLOPs are reduced by 19.3%, and accuracy drops only 0.7% (from 84.4% to 83.7%). These results demonstrate that the method achieves substantial efficiency gains while maintaining strong reasoning performance, providing a practical solution for efficient deployment of large language models in mathematical reasoning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4f18\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u52a8\u6001\u6ce8\u610f\u529b\u5934\u526a\u679d\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u5728\u4fdd\u6301\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u7b49\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u7ea7\u4f18\u5316\u65b9\u6cd5\u6765\u5e73\u8861\u6027\u80fd\u4e0e\u6548\u7387\u3002", "method": "\u52a8\u6001\u8bc4\u4f30\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u7684\u91cd\u8981\u6027\uff08\u57fa\u4e8e\u6743\u91cd\u8303\u6570\u548c\u71b5\uff09\uff0c\u5b9e\u65f6\u526a\u679d\u5197\u4f59\u5934\u4ee5\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff1b\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u539f\u59cb\u6a21\u578b\u4fe1\u606f\u8fc1\u79fb\u5230\u526a\u679d\u540e\u7684\u5b66\u751f\u6a21\u578b\u3002", "result": "\u5728Math23k\u6570\u636e\u96c6\u4e0a\uff0c30%\u526a\u679d\u7387\u4e0b\uff1a\u53c2\u6570\u51cf\u5c1118.7%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u534727.5%\uff0cFLOPs\u51cf\u5c1119.3%\uff0c\u51c6\u786e\u7387\u4ec5\u4e0b\u964d0.7%\uff08\u4ece84.4%\u523083.7%\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5f3a\u5927\u63a8\u7406\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6548\u7387\u63d0\u5347\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19209", "categories": ["cond-mat.str-el", "hep-lat", "nucl-th"], "pdf": "https://arxiv.org/pdf/2511.19209", "abs": "https://arxiv.org/abs/2511.19209", "authors": ["Abhishek Karna", "Hansen S. Wu", "Shailesh Chandrasekharan", "Ribhu K. Kaul"], "title": "Projected Density Matrix Sampling for Lattice Hamiltonians", "comment": "27 pages, 13 figures, 11 tables", "summary": "Quantum Monte Carlo methods are powerful tools for studying quantum many-body systems but face difficulties in accessing excited states and in treating sign problems. We present a continuous-time path-integral Monte Carlo method for computing the low-lying spectrum of generic quantum Hamiltonians within a projection subspace. The method projects the thermal density matrix onto a subspace spanned by a chosen set of linearly independent states. It is free of Trotter discretization errors and systematically converges to the low-energy states which have finite overlap with the projection subspace as the $\u03b2$ parameter increases. While most effective for systems without a sign problem, the method also yields information about low-energy spectra when sign problems are present. We illustrate the approach on two problems. For the sign-free case, we compute the first four low-energy levels in the scaling limit of the one-dimensional Ising model with both transverse and longitudinal fields, demonstrating the flow from the conformal limit to the massive $E_8$ quantum field theory. For the sign-problem case, we apply the method to the frustrated Shastry-Sutherland model and benchmark it against exact diagonalization on small lattices. We also present results for larger systems beyond the lattice sizes accessible to exact diagonalization, while limited to small $\u03b2$ where sign problems occur. Our method provides a general route toward quantum Monte Carlo spectroscopy for lattice Hamiltonians.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u7eed\u65f6\u95f4\u8def\u5f84\u79ef\u5206\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u91cf\u5b50\u54c8\u5bc6\u987f\u91cf\u7684\u4f4e\u80fd\u8c31\uff0c\u901a\u8fc7\u5c06\u70ed\u5bc6\u5ea6\u77e9\u9635\u6295\u5f71\u5230\u9009\u5b9a\u5b50\u7a7a\u95f4\uff0c\u907f\u514d\u4e86Trotter\u79bb\u6563\u5316\u8bef\u5dee\uff0c\u5e76\u80fd\u5904\u7406\u7b26\u53f7\u95ee\u9898\u3002", "motivation": "\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u5728\u7814\u7a76\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u65f6\u9762\u4e34\u96be\u4ee5\u8bbf\u95ee\u6fc0\u53d1\u6001\u548c\u5904\u7406\u7b26\u53f7\u95ee\u9898\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8ba1\u7b97\u4f4e\u80fd\u8c31\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8fde\u7eed\u65f6\u95f4\u8def\u5f84\u79ef\u5206\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff0c\u5c06\u70ed\u5bc6\u5ea6\u77e9\u9635\u6295\u5f71\u5230\u7531\u4e00\u7ec4\u7ebf\u6027\u65e0\u5173\u72b6\u6001\u5f20\u6210\u7684\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u589e\u52a0\u03b2\u53c2\u6570\u7cfb\u7edf\u6027\u5730\u6536\u655b\u5230\u4f4e\u80fd\u6001\u3002", "result": "\u5728\u65e0\u7b26\u53f7\u95ee\u9898\u7684\u4e00\u7ef4Ising\u6a21\u578b\u4e2d\u6210\u529f\u8ba1\u7b97\u4e86\u524d\u56db\u4e2a\u4f4e\u80fd\u7ea7\uff0c\u5c55\u793a\u4e86\u4ece\u5171\u5f62\u6781\u9650\u5230E8\u91cf\u5b50\u573a\u8bba\u7684\u6d41\u52a8\uff1b\u5728\u6709\u7b26\u53f7\u95ee\u9898\u7684\u53d7\u632bShastry-Sutherland\u6a21\u578b\u4e2d\uff0c\u5728\u5c0f\u6676\u683c\u4e0a\u4e0e\u7cbe\u786e\u5bf9\u89d2\u5316\u7ed3\u679c\u4e00\u81f4\uff0c\u5e76\u5728\u66f4\u5927\u7cfb\u7edf\u4e0a\u83b7\u5f97\u4e86\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6676\u683c\u54c8\u5bc6\u987f\u91cf\u7684\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u5149\u8c31\u5b66\u63d0\u4f9b\u4e86\u4e00\u6761\u901a\u7528\u9014\u5f84\uff0c\u65e2\u80fd\u6709\u6548\u5904\u7406\u65e0\u7b26\u53f7\u95ee\u9898\u7cfb\u7edf\uff0c\u4e5f\u80fd\u5728\u5b58\u5728\u7b26\u53f7\u95ee\u9898\u65f6\u63d0\u4f9b\u4f4e\u80fd\u8c31\u4fe1\u606f\u3002"}}
{"id": "2511.18490", "categories": ["cond-mat.stat-mech", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.18490", "abs": "https://arxiv.org/abs/2511.18490", "authors": ["Shenglan Yuan"], "title": "L\u00e9vy noise drives an exponential acceleration in transition rates within metastable systems", "comment": null, "summary": "L\u00e9vy noise influences diverse non-equilibrium systems across scales, including quantum devices, active biological matter, and financial markets. While such noise is pervasive, its overall impact on activated transitions between metastable states remains unclear, despite prior studies of specific noise forms and scaling limits. In this work, we introduce a unified framework for L\u00e9vy noise defined by its finite intensity and independent stationary increments. By identifying the most probable transition paths as minimizers of a stochastic action functional, we derive analytical scaling laws for escape rates under weak noise, thereby extending the classical Arrhenius law. Our results demonstrate that L\u00e9vy noise universally enhances escape efficiency by reducing the effective potential barrier compared to Gaussian noise with equivalent intensity. Strikingly, even vanishingly weak L\u00e9vy noise can exponentially increase escape rates across a broad range of amplitude distributions. This phenomenon arises from discontinuous most probable transition paths, where escape occurs via finite jumps. We validate these paths through the cumulant-generating function, a path integral representation, the mean first passage time and numerical simulations. Our findings reveal fundamental distinctions in escape dynamics under thermal and athermal fluctuations, suggesting new strategies to optimize switching processes in metastable systems through engineering noise properties.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5206\u6790L\u00e9vy\u566a\u58f0\u5bf9\u4e9a\u7a33\u6001\u7cfb\u7edf\u9003\u9038\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0L\u00e9vy\u566a\u58f0\u901a\u8fc7\u4ea7\u751f\u4e0d\u8fde\u7eed\u7684\u8f6c\u79fb\u8def\u5f84\uff0c\u666e\u904d\u589e\u5f3a\u4e86\u9003\u9038\u6548\u7387\uff0c\u5373\u4f7f\u5728\u6781\u5f31\u566a\u58f0\u4e0b\u4e5f\u80fd\u6307\u6570\u7ea7\u63d0\u9ad8\u9003\u9038\u7387\u3002", "motivation": "L\u00e9vy\u566a\u58f0\u5e7f\u6cdb\u5b58\u5728\u4e8e\u91cf\u5b50\u8bbe\u5907\u3001\u6d3b\u6027\u751f\u7269\u7269\u8d28\u548c\u91d1\u878d\u5e02\u573a\u7b49\u975e\u5e73\u8861\u7cfb\u7edf\u4e2d\uff0c\u4f46\u5176\u5bf9\u4e9a\u7a33\u6001\u95f4\u6fc0\u6d3b\u8f6c\u53d8\u7684\u6574\u4f53\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\uff0c\u5c3d\u7ba1\u5df2\u6709\u9488\u5bf9\u7279\u5b9a\u566a\u58f0\u5f62\u5f0f\u548c\u7f29\u653e\u6781\u9650\u7684\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u6700\u53ef\u80fd\u8f6c\u79fb\u8def\u5f84\u4f5c\u4e3a\u968f\u673a\u4f5c\u7528\u6cdb\u51fd\u7684\u6700\u5c0f\u5316\u5668\uff0c\u63a8\u5bfc\u5f31\u566a\u58f0\u4e0b\u9003\u9038\u7387\u7684\u89e3\u6790\u7f29\u653e\u5b9a\u5f8b\uff0c\u6269\u5c55\u7ecf\u5178Arrhenius\u5b9a\u5f8b\u3002\u4f7f\u7528\u7d2f\u79ef\u91cf\u751f\u6210\u51fd\u6570\u3001\u8def\u5f84\u79ef\u5206\u8868\u793a\u3001\u5e73\u5747\u9996\u6b21\u901a\u8fc7\u65f6\u95f4\u548c\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u8fd9\u4e9b\u8def\u5f84\u3002", "result": "\u7ed3\u679c\u8868\u660eL\u00e9vy\u566a\u58f0\u666e\u904d\u589e\u5f3a\u4e86\u9003\u9038\u6548\u7387\uff0c\u901a\u8fc7\u964d\u4f4e\u6709\u6548\u52bf\u5792\u9ad8\u5ea6\uff0c\u4e0e\u5177\u6709\u7b49\u6548\u5f3a\u5ea6\u7684Gaussian\u566a\u58f0\u76f8\u6bd4\u3002\u5373\u4f7f\u5728\u6781\u5f31L\u00e9vy\u566a\u58f0\u4e0b\uff0c\u4e5f\u80fd\u5728\u5e7f\u6cdb\u7684\u632f\u5e45\u5206\u5e03\u8303\u56f4\u5185\u6307\u6570\u7ea7\u589e\u52a0\u9003\u9038\u7387\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u70ed\u6ce2\u52a8\u548c\u975e\u70ed\u6ce2\u52a8\u4e0b\u9003\u9038\u52a8\u529b\u5b66\u7684\u6839\u672c\u533a\u522b\uff0c\u4e3a\u901a\u8fc7\u5de5\u7a0b\u566a\u58f0\u7279\u6027\u4f18\u5316\u4e9a\u7a33\u6001\u7cfb\u7edf\u4e2d\u7684\u5207\u6362\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7b56\u7565\u3002"}}
{"id": "2511.17821", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2511.17821", "abs": "https://arxiv.org/abs/2511.17821", "authors": ["Shangjie Guo", "Corneliu Buda", "Nathan Wiebe"], "title": "Quantum Algorithm for Estimating Gibbs Free Energy and Entropy via Energy Derivatives", "comment": "15 pages, 2 figures", "summary": "Estimating vibrational entropy is a significant challenge in thermodynamics and statistical mechanics due to its reliance on quantum mechanical properties. This paper introduces a quantum algorithm designed to estimate vibrational entropy via energy derivatives. Our approach block encodes the exact expression for the second derivative of the energy and uses quantum linear systems algorithms to deal with the reciprocal powers of the gaps that appear in the expression. We further show that if prior knowledge about the values of the second derivative is used then our algorithm can $\u03b5$-approximate the entropy using a number of queries that scales with the condition number $\u03ba$, the temperature $T$, error tolerance $\u03b5$ and an analogue of the partition function $\\mathcal{Z}$, as $\\widetilde{O}\\left(\\frac{\\mathcal{Z}\u03ba^2 }{\u03b5T}\\right)$. We show that if sufficient prior knowledge is given about the second derivative then the query scales quadratically better than these results. This shows that, under reasonable assumptions of the temperature and a quantum computer can be used to compute the vibrational contributions to the entropy faster than analogous classical algorithms would be capable of. Our findings highlight the potential of quantum algorithms to enhance the prediction of thermodynamic properties, paving the way for advancements in fields such as material science, molecular biology, and chemical engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5b50\u7b97\u6cd5\uff0c\u901a\u8fc7\u80fd\u91cf\u5bfc\u6570\u6765\u4f30\u7b97\u632f\u52a8\u71b5\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u91cf\u5b50\u7ebf\u6027\u7cfb\u7edf\u7b97\u6cd5\u5904\u7406\u80fd\u91cf\u4e8c\u9636\u5bfc\u6570\u8868\u8fbe\u5f0f\u4e2d\u7684\u80fd\u9699\u5012\u6570\u9879\uff0c\u5728\u5408\u7406\u5047\u8bbe\u4e0b\u6bd4\u7ecf\u5178\u7b97\u6cd5\u66f4\u5feb\u3002", "motivation": "\u632f\u52a8\u71b5\u7684\u4f30\u7b97\u5728\u70ed\u529b\u5b66\u548c\u7edf\u8ba1\u529b\u5b66\u4e2d\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5b83\u4f9d\u8d56\u4e8e\u91cf\u5b50\u529b\u5b66\u6027\u8d28\u3002\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u91cf\u5b50\u7b97\u6cd5\uff0c\u901a\u8fc7\u5757\u7f16\u7801\u80fd\u91cf\u4e8c\u9636\u5bfc\u6570\u7684\u7cbe\u786e\u8868\u8fbe\u5f0f\uff0c\u5229\u7528\u91cf\u5b50\u7ebf\u6027\u7cfb\u7edf\u7b97\u6cd5\u5904\u7406\u80fd\u9699\u5012\u6570\u9879\u3002\u5728\u5df2\u77e5\u4e8c\u9636\u5bfc\u6570\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u66f4\u9ad8\u6548\u5730\u8fd1\u4f3c\u71b5\u503c\u3002", "result": "\u7b97\u6cd5\u5728\u03b5\u8fd1\u4f3c\u71b5\u503c\u65f6\uff0c\u67e5\u8be2\u6b21\u6570\u4e0e\u6761\u4ef6\u6570\u03ba\u3001\u6e29\u5ea6T\u3001\u8bef\u5dee\u5bb9\u9650\u03b5\u548c\u914d\u5206\u51fd\u6570\u7c7b\u4f3c\u91cfZ\u76f8\u5173\uff0c\u4e3a\u00d5(Z\u03ba\u00b2/\u03b5T)\u3002\u5728\u5145\u5206\u5148\u9a8c\u77e5\u8bc6\u4e0b\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u53ef\u4e8c\u6b21\u6539\u5584\u3002", "conclusion": "\u91cf\u5b50\u7b97\u6cd5\u5728\u5408\u7406\u6e29\u5ea6\u548c\u5047\u8bbe\u4e0b\uff0c\u80fd\u6bd4\u7ecf\u5178\u7b97\u6cd5\u66f4\u5feb\u8ba1\u7b97\u632f\u52a8\u71b5\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u9884\u6d4b\u70ed\u529b\u5b66\u6027\u8d28\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u6750\u6599\u79d1\u5b66\u3001\u5206\u5b50\u751f\u7269\u5b66\u548c\u5316\u5b66\u5de5\u7a0b\u7b49\u9886\u57df\u5e26\u6765\u8fdb\u6b65\u3002"}}
{"id": "2511.17729", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17729", "abs": "https://arxiv.org/abs/2511.17729", "authors": ["Yang Zhou", "Mingyu Zhao", "Zhenting Wang", "Difei Gu", "Bangwei Guo", "Ruosong Ye", "Ligong Han", "Can Jin", "Dimitris N. Metaxas"], "title": "M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark", "comment": null, "summary": "We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resources across steps. We introduce a similarity-driven alignment that serializes each tool call, embeds signatures with a sentence encoder, and performs similarity-bucketed Hungarian matching to obtain auditable one-to-one correspondences. On top of this alignment, we report interpretable metrics that decouple semantic fidelity from workflow consistency. The benchmark spans 28 servers with 231 tools, and provides standardized trajectories curated through an Executor & Judge pipeline with human verification; an auxiliary four large language models (LLMs) judge ensemble reports end-task Task Completion and information grounding. Evaluations of representative state-of-the-art Multimodal LLMs (MLLMs) reveal persistent gaps in multimodal MCP tool use, particularly in argument fidelity and structure consistency, underscoring the need for methods that jointly reason over images, text, and tool graphs. Our Benchmark's anonymous repository is at https://github.com/EtaYang10th/Open-M3-Bench", "AI": {"tldr": "M^3-Bench\u662f\u9996\u4e2a\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u7684\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u8bc4\u4f30\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u9700\u8981\u89c6\u89c9\u57fa\u7840\u548c\u6587\u672c\u63a8\u7406\u7684\u591a\u8df3\u3001\u591a\u7ebf\u7a0b\u5de5\u4f5c\u6d41\uff0c\u5305\u542b28\u4e2a\u670d\u52a1\u5668\u548c231\u4e2a\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8de8\u5de5\u5177\u4f9d\u8d56\u5173\u7cfb\u548c\u4e2d\u95f4\u8d44\u6e90\u6301\u4e45\u6027\u65b9\u9762\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30\u8bed\u4e49\u4fdd\u771f\u5ea6\u548c\u5de5\u4f5c\u6d41\u4e00\u81f4\u6027\u7684\u6807\u51c6\u5316\u57fa\u51c6\u3002", "method": "\u91c7\u7528\u76f8\u4f3c\u6027\u9a71\u52a8\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5e8f\u5217\u5316\u5de5\u5177\u8c03\u7528\uff0c\u4f7f\u7528\u53e5\u5b50\u7f16\u7801\u5668\u5d4c\u5165\u7b7e\u540d\uff0c\u5e76\u901a\u8fc7\u76f8\u4f3c\u6027\u5206\u6876\u7684\u5308\u7259\u5229\u5339\u914d\u83b7\u5f97\u53ef\u5ba1\u8ba1\u7684\u4e00\u5bf9\u4e00\u5bf9\u5e94\u5173\u7cfb\u3002\u4f7f\u7528\u6267\u884c\u5668\u4e0e\u8bc4\u5224\u5668\u6d41\u6c34\u7ebf\u8fdb\u884c\u6807\u51c6\u5316\u8f68\u8ff9\u7ba1\u7406\u3002", "result": "\u5bf9\u4ee3\u8868\u6027\u6700\u5148\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u591a\u6a21\u6001MCP\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u53c2\u6570\u4fdd\u771f\u5ea6\u548c\u7ed3\u6784\u4e00\u81f4\u6027\u65b9\u9762\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8054\u5408\u63a8\u7406\u56fe\u50cf\u3001\u6587\u672c\u548c\u5de5\u5177\u56fe\u7684\u65b9\u6cd5\uff0c\u4ee5\u6539\u5584\u591a\u6a21\u6001\u5de5\u5177\u4f7f\u7528\u7684\u6027\u80fd\u3002"}}
{"id": "2511.17579", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17579", "abs": "https://arxiv.org/abs/2511.17579", "authors": ["Hefei Xu", "Le Wu", "Chen Cheng", "Hao Liu"], "title": "Multi-Value Alignment for LLMs via Value Decorrelation and Extrapolation", "comment": "accepted by AAAI26 oral; 12 pages", "summary": "With the rapid advancement of large language models (LLMs), aligning them with human values for safety and ethics has become a critical challenge. This problem is especially challenging when multiple, potentially conflicting human values must be considered and balanced. Although several variants of existing alignment methods (such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO)) have been proposed to address multi-value alignment, they suffer from notable limitations: 1) they are often unstable and inefficient in multi-value optimization; and 2) they fail to effectively handle value conflicts. As a result, these approaches typically struggle to achieve optimal trade-offs when aligning multiple values.\n  To address this challenge, we propose a novel framework called Multi-Value Alignment (MVA). It mitigates alignment degradation caused by parameter interference among diverse human values by minimizing their mutual information. Furthermore, we propose a value extrapolation strategy to efficiently explore the Pareto frontier, thereby constructing a set of LLMs with diverse value preferences. Extensive experiments demonstrate that MVA consistently outperforms existing baselines in aligning LLMs with multiple human values.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u591a\u4ef7\u503c\u5bf9\u9f50\uff08MVA\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u53ef\u80fd\u51b2\u7a81\u7684\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u65b9\u9762\u7684\u6311\u6218\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6700\u5c0f\u5316\u4e0d\u540c\u4ef7\u503c\u89c2\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u6765\u7f13\u89e3\u53c2\u6570\u5e72\u6270\uff0c\u5e76\u91c7\u7528\u4ef7\u503c\u5916\u63a8\u7b56\u7565\u63a2\u7d22\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5c06\u5176\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u4ee5\u786e\u4fdd\u5b89\u5168\u548c\u4f26\u7406\u5df2\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u5982RLHF\u548cDPO\uff09\u5728\u591a\u4ef7\u503c\u5bf9\u9f50\u4e2d\u5b58\u5728\u4e0d\u7a33\u5b9a\u3001\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4ef7\u503c\u51b2\u7a81\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faMVA\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u6700\u5c0f\u5316\u4e0d\u540c\u4eba\u7c7b\u4ef7\u503c\u89c2\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u6765\u7f13\u89e3\u5bf9\u9f50\u9000\u5316\uff1b2\uff09\u91c7\u7528\u4ef7\u503c\u5916\u63a8\u7b56\u7565\u9ad8\u6548\u63a2\u7d22\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u6784\u5efa\u5177\u6709\u4e0d\u540c\u4ef7\u503c\u504f\u597d\u7684LLMs\u96c6\u5408\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMVA\u5728\u5c06LLMs\u4e0e\u591a\u4e2a\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MVA\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4ef7\u503c\u5bf9\u9f50\u4e2d\u7684\u53c2\u6570\u5e72\u6270\u548c\u51b2\u7a81\u5904\u7406\u95ee\u9898\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u597d\u7684\u4ef7\u503c\u6743\u8861\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u4f26\u7406\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.19311", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19311", "abs": "https://arxiv.org/abs/2511.19311", "authors": ["Shao-Hang Shi", "Xiao-Qi Sun", "Zi-Xiang Li"], "title": "Diagnosis of mixed-state topological phases in strongly correlated systems via disorder parameters", "comment": "6+8 pages, 4+4 figures", "summary": "Characterizing topological phases for strongly interacting fermions in the mixed-state regime remains a major challenge. Here we introduce a general and numerically efficient framework to diagnose mixed-state topological phases in strongly interacting systems via the disorder parameter (DP) of the U(1) charge operator. Specifically, from the finite-size scaling of the second derivative of the DP generating function, we introduce the topological scaling indicator, which exhibits a characteristic linear scaling with the system's linear dimension for topological phases, a signature that vanishes upon transition into a topologically trivial phase. Crucially, we develop an efficient determinant Quantum Monte Carlo algorithm that facilitates the evaluation of this indicator in interacting systems. We apply our approach to two paradigmatic models: for the Kane-Mele-Hubbard model, we successfully map the interaction-driven transition from a quantum spin Hall insulator to a trivial Mott insulator. Furthermore, our method circumvents the limitations imposed by the severe sign problem in the Haldane-Hubbard model, enabling robust identification of the quantum anomalous Hall phase at accessible temperatures. This work provides a powerful and accessible tool for the numerical exploration of topological phenomena in interacting mixed states, opening a pathway to study systems previously inaccessible due to computational obstacles.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7U(1)\u7535\u8377\u7b97\u7b26\u7684\u5931\u5e8f\u53c2\u6570\u6765\u8bca\u65ad\u5f3a\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u4e2d\u6df7\u5408\u6001\u62d3\u6251\u76f8\u7684\u4e00\u822c\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\u6765\u8bc4\u4f30\u62d3\u6251\u6807\u5ea6\u6307\u6807\u3002", "motivation": "\u5f3a\u76f8\u4e92\u4f5c\u7528\u8d39\u7c73\u5b50\u5728\u6df7\u5408\u6001\u533a\u57df\u4e2d\u7684\u62d3\u6251\u76f8\u8868\u5f81\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6570\u503c\u65b9\u6cd5\u6765\u514b\u670d\u73b0\u6709\u8ba1\u7b97\u969c\u788d\u3002", "method": "\u901a\u8fc7U(1)\u7535\u8377\u7b97\u7b26\u5931\u5e8f\u53c2\u6570\u7684\u751f\u6210\u51fd\u6570\u7684\u4e8c\u9636\u5bfc\u6570\u7684\u6709\u9650\u5c3a\u5bf8\u6807\u5ea6\u5206\u6790\uff0c\u5f15\u5165\u62d3\u6251\u6807\u5ea6\u6307\u6807\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684determinant\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\u3002", "result": "\u5728Kane-Mele-Hubbard\u6a21\u578b\u4e2d\u6210\u529f\u6620\u5c04\u4e86\u4ece\u91cf\u5b50\u81ea\u65cb\u970d\u5c14\u7edd\u7f18\u4f53\u5230\u5e73\u51e1Mott\u7edd\u7f18\u4f53\u7684\u76f8\u4e92\u4f5c\u7528\u9a71\u52a8\u76f8\u53d8\uff1b\u5728Haldane-Hubbard\u6a21\u578b\u4e2d\u514b\u670d\u4e86\u4e25\u91cd\u7b26\u53f7\u95ee\u9898\uff0c\u5728\u53ef\u53ca\u6e29\u5ea6\u4e0b\u7a33\u5065\u8bc6\u522b\u4e86\u91cf\u5b50\u53cd\u5e38\u970d\u5c14\u76f8\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u76f8\u4e92\u4f5c\u7528\u6df7\u5408\u6001\u4e2d\u62d3\u6251\u73b0\u8c61\u7684\u6570\u5b57\u63a2\u7d22\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u4e14\u53ef\u7528\u7684\u5de5\u5177\uff0c\u4e3a\u7814\u7a76\u5148\u524d\u56e0\u8ba1\u7b97\u969c\u788d\u800c\u65e0\u6cd5\u8bbf\u95ee\u7684\u7cfb\u7edf\u5f00\u8f9f\u4e86\u9014\u5f84\u3002"}}
{"id": "2511.18495", "categories": ["cond-mat.stat-mech", "hep-th", "math-ph", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.18495", "abs": "https://arxiv.org/abs/2511.18495", "authors": ["E. A. Ramirez Trino", "M. A. Seifi MirJafarlou", "M. A. Rajabpour"], "title": "A Generalized Grassmann-Pfaffian Framework for Monomer-Dimer and Spanning Trees", "comment": "86 pages, 4 Figures", "summary": "We develop a unified framework for Berezin integrals over Grassmann variables that establishes master identities for exponential quadratic fermionic forms and linear fermionic forms coupled to both bosonic and fermionic sources. The construction is rigorous for both real and complex fermions in arbitrary dimensions and remains well-defined even when the underlying matrices are singular. Our main mathematical results appear in two master theorems. Theorem 12 provides a comprehensive identity for Berezin integrals over Grassmann variables for real fermions with mixed bosonic-fermionic sources, applicable to any antisymmetric matrix. Its complex analogue, Theorem 13, yields corresponding determinant-based representations. Together, they serve as generating functionals for a wide range of combinatorial and physical models. Key applications include the dimer, monomer-dimer, matching, and almost-matching problems. We revisit the Kasteleyn theorem for planar dimers using Berezin integrals. We construct monomer-dimer systems through the \\textit{Monobisyzexant (Mbsz)} function, which generalizes the Hafnian to incorporate monomer contributions and admits a Pfaffian-sum representation for planar graphs (Theorem 5); and practical techniques for handling singular matrices via unitary block decomposition (Theorem 6) and spectral analysis. We further present explicit mappings between Hafnians and Pfaffians and their submatrix generalizations (Hafnianinhos and Pfaffianinhos); an alternative source-ordered Berezin integral representation for spanning trees and forests using complex bosonic sources that regularizes the Laplacian zero mode (Theorem 10). Overall, this work offers a flexible toolkit for the theoretical analysis and computational implementation of graph-based models and lattice field theories using Berezin integrals over Grassmann variables .", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8d1d\u96f7\u6d25\u79ef\u5206\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u683c\u62c9\u65af\u66fc\u53d8\u91cf\u7684\u79ef\u5206\uff0c\u5efa\u7acb\u4e86\u6307\u6570\u4e8c\u6b21\u8d39\u7c73\u5f62\u5f0f\u548c\u7ebf\u6027\u8d39\u7c73\u5f62\u5f0f\u4e0e\u73bb\u8272\u548c\u8d39\u7c73\u6e90\u8026\u5408\u7684\u4e3b\u6052\u7b49\u5f0f\u3002\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u4efb\u610f\u7ef4\u5ea6\u7684\u5b9e\u548c\u590d\u8d39\u7c73\u5b50\uff0c\u5373\u4f7f\u5728\u57fa\u7840\u77e9\u9635\u5947\u5f02\u65f6\u4e5f\u4fdd\u6301\u826f\u597d\u5b9a\u4e49\u3002", "motivation": "\u4e3a\u56fe\u8bba\u6a21\u578b\u548c\u6676\u683c\u573a\u8bba\u63d0\u4f9b\u7075\u6d3b\u7684\u7406\u8bba\u5206\u6790\u548c\u8ba1\u7b97\u5de5\u5177\uff0c\u901a\u8fc7\u8d1d\u96f7\u6d25\u79ef\u5206\u7edf\u4e00\u5904\u7406\u5404\u79cd\u7ec4\u5408\u548c\u7269\u7406\u6a21\u578b\uff0c\u5305\u62ec\u4e8c\u805a\u4f53\u3001\u5355\u4f53-\u4e8c\u805a\u4f53\u3001\u5339\u914d\u548c\u8fd1\u4f3c\u5339\u914d\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u4e24\u4e2a\u4e3b\u5b9a\u7406\uff1a\u5b9a\u740612\u4e3a\u5b9e\u8d39\u7c73\u5b50\u63d0\u4f9b\u5168\u9762\u7684\u8d1d\u96f7\u6d25\u79ef\u5206\u6052\u7b49\u5f0f\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u53cd\u5bf9\u79f0\u77e9\u9635\uff1b\u5b9a\u740613\u662f\u5176\u590d\u6570\u5bf9\u5e94\uff0c\u4ea7\u751f\u57fa\u4e8e\u884c\u5217\u5f0f\u7684\u8868\u793a\u3002\u8fd8\u5f00\u53d1\u4e86\u5904\u7406\u5947\u5f02\u77e9\u9635\u7684\u5b9e\u7528\u6280\u672f\uff0c\u5305\u62ec\u9149\u5757\u5206\u89e3\u548c\u8c31\u5206\u6790\u3002", "result": "\u5efa\u7acb\u4e86\u5355\u4f53-\u4e8c\u805a\u4f53\u7cfb\u7edf\u7684Monobisyzexant\u51fd\u6570\uff0c\u5c06Hafnian\u63a8\u5e7f\u5230\u5305\u542b\u5355\u4f53\u8d21\u732e\uff1b\u63d0\u51fa\u4e86Hafnian\u548cPfaffian\u53ca\u5176\u5b50\u77e9\u9635\u63a8\u5e7f\u4e4b\u95f4\u7684\u663e\u5f0f\u6620\u5c04\uff1b\u4e3a\u751f\u6210\u6811\u548c\u68ee\u6797\u63d0\u4f9b\u4e86\u66ff\u4ee3\u7684\u6e90\u5e8f\u8d1d\u96f7\u6d25\u79ef\u5206\u8868\u793a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u56fe\u7684\u6a21\u578b\u548c\u6676\u683c\u573a\u8bba\u7684\u7406\u8bba\u5206\u6790\u548c\u8ba1\u7b97\u5b9e\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u8d1d\u96f7\u6d25\u79ef\u5206\u5de5\u5177\u5305\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u7ec4\u5408\u548c\u7269\u7406\u95ee\u9898\u7684\u5904\u7406\u65b9\u6cd5\u3002"}}
{"id": "2511.17743", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17743", "abs": "https://arxiv.org/abs/2511.17743", "authors": ["Haytham Younus", "Sohag Kabir", "Felician Campean", "Pascal Bonnaud", "David Delaux"], "title": "AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions", "comment": "This manuscript is based on research undertaken by our doctoral student at the University of Bradford. The associated PhD thesis has been formally submitted to the University and is currently awaiting final examination. The review article is being shared on arXiv to make the review accessible to the research community while the thesis examination process is ongoing", "summary": "This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5c06\u4f20\u7edf\u6545\u969c\u6a21\u5f0f\u4e0e\u5f71\u54cd\u5206\u6790(FMEA)\u8f6c\u53d8\u4e3a\u66f4\u667a\u80fd\u3001\u6570\u636e\u9a71\u52a8\u548c\u8bed\u4e49\u4e30\u5bcc\u8fc7\u7a0b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u548c\u672c\u4f53\u8bba\u5728\u5176\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5de5\u7a0b\u7cfb\u7edf\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u4f20\u7edfFMEA\u65b9\u6cd5\uff08\u4e3b\u8981\u662f\u624b\u52a8\u3001\u6587\u6863\u4e2d\u5fc3\u548c\u4e13\u5bb6\u4f9d\u8d56\uff09\u5df2\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u7cfb\u7edf\u5de5\u7a0b\u7684\u9700\u6c42\uff0c\u9700\u8981\u66f4\u667a\u80fd\u3001\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff08\u673a\u5668\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09\u5b9e\u73b0\u6545\u969c\u9884\u6d4b\u3001\u4f18\u5148\u7ea7\u6392\u5e8f\u548c\u77e5\u8bc6\u63d0\u53d6\u7684\u81ea\u52a8\u5316\uff0c\u540c\u65f6\u5229\u7528\u672c\u4f53\u8bba\u5f62\u5f0f\u5316\u7cfb\u7edf\u77e5\u8bc6\uff0c\u652f\u6301\u8bed\u4e49\u63a8\u7406\u548c\u8de8\u57df\u4e92\u64cd\u4f5c\u6027\u3002", "result": "\u5f00\u53d1\u4e86\u6df7\u5408\u65b9\u6cd5\u5982\u672c\u4f53\u901a\u77e5\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u5728\u57fa\u4e8e\u6a21\u578b\u7684\u7cfb\u7edf\u5de5\u7a0b\u548c\u529f\u80fd\u5efa\u6a21\u80cc\u666f\u4e0b\u589e\u5f3a\u4e86FMEA\u5de5\u4f5c\u6d41\u7a0b\u7684\u9002\u5e94\u6027\u548c\u5f39\u6027\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u4eba\u5de5\u667a\u80fd\u3001\u7cfb\u7edf\u5de5\u7a0b\u548c\u672c\u4f53\u8bba\u77e5\u8bc6\u8868\u793a\uff0c\u4e3a\u5c06FMEA\u5d4c\u5165\u667a\u80fd\u3001\u77e5\u8bc6\u4e30\u5bcc\u7684\u5de5\u7a0b\u73af\u5883\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8def\u7ebf\u56fe\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u6570\u636e\u8d28\u91cf\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6807\u51c6\u5316\u548c\u8de8\u5b66\u79d1\u91c7\u7528\u7b49\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2511.17581", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17581", "abs": "https://arxiv.org/abs/2511.17581", "authors": ["Zhiwen Qiu", "Ziang Liu", "Wenqian Niu", "Tapomayukh Bhattacharjee", "Saleh Kalantari"], "title": "EgoCogNav: Cognition-aware Human Egocentric Navigation", "comment": "11 pages, 4 figures", "summary": "Modeling the cognitive and experiential factors of human navigation is central to deepening our understanding of human-environment interaction and to enabling safe social navigation and effective assistive wayfinding. Most existing methods focus on forecasting motions in fully observed scenes and often neglect human factors that capture how people feel and respond to space. To address this gap, We propose EgoCogNav, a multimodal egocentric navigation framework that predicts perceived path uncertainty as a latent state and jointly forecasts trajectories and head motion by fusing scene features with sensory cues. To facilitate research in the field, we introduce the Cognition-aware Egocentric Navigation (CEN) dataset consisting 6 hours of real-world egocentric recordings capturing diverse navigation behaviors in real-world scenarios. Experiments show that EgoCogNav learns the perceived uncertainty that highly correlates with human-like behaviors such as scanning, hesitation, and backtracking while generalizing to unseen environments.", "AI": {"tldr": "EgoCogNav\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u81ea\u6211\u4e2d\u5fc3\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u611f\u77e5\u8def\u5f84\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u6f5c\u5728\u72b6\u6001\uff0c\u878d\u5408\u573a\u666f\u7279\u5f81\u548c\u611f\u5b98\u7ebf\u7d22\u6765\u8054\u5408\u9884\u6d4b\u8f68\u8ff9\u548c\u5934\u90e8\u8fd0\u52a8\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b8c\u5168\u89c2\u5bdf\u573a\u666f\u4e2d\u7684\u8fd0\u52a8\u9884\u6d4b\uff0c\u5f80\u5f80\u5ffd\u7565\u4e86\u6355\u6349\u4eba\u4eec\u5bf9\u7a7a\u95f4\u611f\u53d7\u548c\u53cd\u5e94\u7684\u4eba\u7c7b\u56e0\u7d20\u3002", "method": "\u63d0\u51faEgoCogNav\u6846\u67b6\uff0c\u9884\u6d4b\u611f\u77e5\u8def\u5f84\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u6f5c\u5728\u72b6\u6001\uff0c\u878d\u5408\u573a\u666f\u7279\u5f81\u4e0e\u611f\u5b98\u7ebf\u7d22\u6765\u8054\u5408\u9884\u6d4b\u8f68\u8ff9\u548c\u5934\u90e8\u8fd0\u52a8\u3002\u540c\u65f6\u6784\u5efa\u4e86CEN\u6570\u636e\u96c6\uff0c\u5305\u542b6\u5c0f\u65f6\u771f\u5b9e\u4e16\u754c\u81ea\u6211\u4e2d\u5fc3\u8bb0\u5f55\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEgoCogNav\u5b66\u4e60\u7684\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0e\u4eba\u7c7b\u884c\u4e3a\uff08\u5982\u626b\u63cf\u3001\u72b9\u8c6b\u3001\u56de\u6eaf\uff09\u9ad8\u5ea6\u76f8\u5173\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u73af\u5883\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5efa\u6a21\u4e86\u4eba\u7c7b\u5bfc\u822a\u7684\u8ba4\u77e5\u548c\u4f53\u9a8c\u56e0\u7d20\uff0c\u4e3a\u7406\u89e3\u4eba-\u73af\u5883\u4ea4\u4e92\u548c\u5b9e\u73b0\u5b89\u5168\u793e\u4ea4\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.18510", "categories": ["cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.18510", "abs": "https://arxiv.org/abs/2511.18510", "authors": ["Daniil Fedotov", "Sergei Nechaev"], "title": "Three faces of random walks in hyperbolic domain: BKT, Lifshitz tails, and KPZ", "comment": null, "summary": "We show that continuous random walks (diffusion) in the Poincar\u00e9 hyperbolic upper halfplane $\\mathbb{H}^2 = {(x,y)}|y>0$, interpreted as multiplicative stochastic processes with log-normal statistics, provide a unifying framework linking three seemingly unrelated phenomena: (i) the non-analytic divergence of corrrelation length at the Berezinskii-Kosterlitz-Thouless (BKT) transition; (ii) the appearence of the Kardar-Parisi-Zhang 9KPZ) exponent in the fluctuational behavior of stretched random walks constrained above an impermeable disc; and (iii) the emergence of Lifshitz tails in one-dimensional statistics of rare events. Combining scaling arguments with analytic derivations and numerical analysis, we adapt the renormalization-group equations originally developed for the Efimov effect in a two-dimensional conformally invariant potential to the case of diffusion in $\\mathbb{H}^2$, thereby deriving the BKT-type divergence of the correlation length. We further demonstrate how the KPZ-type scaling governs the large-deviation behavior and survival probability near the boundary in the hyperbolic domain, and how Lifshitz tails arise naturally in a deterministic large-deviation landscape on the hyperbolic plane via instanton approach, reproducing the rare-event statistics of one-dimensional diffusion in the array of traps with the Poisson distribution. We conjecture that the dominant contribution to the ensemble of paths responsible for BKT-like physics comes from random paths pushed to large-deviation stretched regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5728\u5e9e\u52a0\u83b1\u53cc\u66f2\u4e0a\u534a\u5e73\u9762\u4e2d\u7684\u8fde\u7eed\u968f\u673a\u6e38\u8d70\uff08\u6269\u6563\uff09\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u8fde\u63a5\u4e86\u4e09\u4e2a\u770b\u4f3c\u65e0\u5173\u7684\u73b0\u8c61\uff1aBKT\u8f6c\u53d8\u4e2d\u7684\u5173\u8054\u957f\u5ea6\u975e\u89e3\u6790\u53d1\u6563\u3001\u53d7\u9650\u968f\u673a\u6e38\u8d70\u4e2dKPZ\u6307\u6570\u7684\u51fa\u73b0\uff0c\u4ee5\u53ca\u4e00\u7ef4\u7a00\u6709\u4e8b\u4ef6\u7edf\u8ba1\u4e2dLifshitz\u5c3e\u7684\u51fa\u73b0\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06BKT\u8f6c\u53d8\u3001KPZ\u6807\u5ea6\u884c\u4e3a\u548cLifshitz\u5c3e\u8fd9\u4e09\u4e2a\u5728\u4e0d\u540c\u7269\u7406\u80cc\u666f\u4e0b\u51fa\u73b0\u7684\u73b0\u8c61\u8054\u7cfb\u8d77\u6765\uff0c\u63ed\u793a\u5b83\u4eec\u4e4b\u95f4\u7684\u6df1\u5c42\u6570\u5b66\u8054\u7cfb\u3002", "method": "\u7ed3\u5408\u6807\u5ea6\u8bba\u8bc1\u3001\u89e3\u6790\u63a8\u5bfc\u548c\u6570\u503c\u5206\u6790\uff0c\u5c06\u6700\u521d\u4e3a\u4e8c\u7ef4\u5171\u5f62\u4e0d\u53d8\u52bf\u4e2dEfimov\u6548\u5e94\u53d1\u5c55\u7684\u91cd\u6574\u5316\u7fa4\u65b9\u7a0b\uff0c\u9002\u914d\u5230\u53cc\u66f2\u4e0a\u534a\u5e73\u9762\u4e2d\u7684\u6269\u6563\u60c5\u51b5\u3002", "result": "\u63a8\u5bfc\u51fa\u4e86BKT\u578b\u5173\u8054\u957f\u5ea6\u53d1\u6563\uff0c\u8bc1\u660e\u4e86KPZ\u578b\u6807\u5ea6\u63a7\u5236\u53cc\u66f2\u57df\u4e2d\u8fb9\u754c\u9644\u8fd1\u7684\u5927\u504f\u5dee\u884c\u4e3a\u548c\u751f\u5b58\u6982\u7387\uff0c\u5e76\u901a\u8fc7\u77ac\u5b50\u65b9\u6cd5\u5c55\u793a\u4e86Lifshitz\u5c3e\u5728\u53cc\u66f2\u5e73\u9762\u786e\u5b9a\u6027\u5927\u504f\u5dee\u666f\u89c2\u4e2d\u7684\u81ea\u7136\u51fa\u73b0\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u8d1f\u8d23BKT\u7c7b\u7269\u7406\u7684\u8def\u5f84\u96c6\u5408\u7684\u4e3b\u8981\u8d21\u732e\u6765\u81ea\u4e8e\u88ab\u63a8\u5411\u5927\u504f\u5dee\u62c9\u4f38\u673a\u5236\u7684\u968f\u673a\u8def\u5f84\uff0c\u4e3a\u8fd9\u4e9b\u770b\u4f3c\u4e0d\u540c\u7684\u73b0\u8c61\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6570\u5b66\u89e3\u91ca\u3002"}}
{"id": "2511.17846", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17846", "abs": "https://arxiv.org/abs/2511.17846", "authors": ["Xudong Zhang", "Zhaoyu Sun", "Bin Guo"], "title": "Unified Bulk-Entanglement Correspondence in Non-Hermitian Systems", "comment": null, "summary": "The non-Hermitian skin effect (NHSE) fundamentally invalidates the conventional bulk-boundary correspondence (BBC), leading topological diagnostics into a crisis. While the non-Bloch polarization $P_\u03b2$ defined on the generalized Brillouin zone restores momentum-space topology, a direct, robust real-space bulk probe has remained elusive. We resolve this by establishing a universal correspondence between $P_\u03b2$ and the entanglement polarization $\u03c7$ of the biorthogonal ground state. Introducing a quasi-reciprocal Hamiltonian $\\tilde{H}$ that removes the NHSE while preserving bulk topology, we rigorously prove the fundamental identity $P_\u03b2 \\equiv \u03c7(\\tilde{H})\\pmod 1$ in the thermodynamic limit under the quasi-locality assumption. Crucially, we demonstrate that this equivalence transcends the locality constraints that limit traditional topological invariants. While the conventional Resta polarization fails when $\\tilde{H}$ becomes non-local due to the divergence of position variance, we reveal that $\u03c7(\\tilde{H})$ remains robustly quantized, protected by the Fredholm index of Toeplitz operators. Our work thus identifies entanglement as the unique real-space diagnostic capable of capturing non-Bloch topology beyond the breakdown of locality, successfully restoring the BBC across diverse non-Hermitian systems such as line-gap, point-gap, and gapless phases, thereby unifying the geometric and entanglement paradigms in non-Hermitian physics.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u975e\u5e03\u6d1b\u8d6b\u6781\u5316P_\u03b2\u4e0e\u7ea0\u7f20\u6781\u5316\u03c7\u4e4b\u95f4\u7684\u666e\u9002\u5bf9\u5e94\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u975e\u5384\u7c73\u8d8b\u80a4\u6548\u5e94\u5bfc\u81f4\u7684\u4f53\u8fb9\u5bf9\u5e94\u5371\u673a\uff0c\u4e3a\u8d85\u8d8a\u5c40\u57df\u6027\u9650\u5236\u7684\u975e\u5384\u7c73\u62d3\u6251\u63d0\u4f9b\u4e86\u552f\u4e00\u7684\u5b9e\u7a7a\u95f4\u8bca\u65ad\u5de5\u5177\u3002", "motivation": "\u975e\u5384\u7c73\u8d8b\u80a4\u6548\u5e94(NHSE)\u4f7f\u4f20\u7edf\u4f53\u8fb9\u5bf9\u5e94\u5173\u7cfb(BBC)\u5931\u6548\uff0c\u4f20\u7edf\u7684\u62d3\u6251\u8bca\u65ad\u65b9\u6cd5\u9677\u5165\u5371\u673a\u3002\u867d\u7136\u57fa\u4e8e\u5e7f\u4e49\u5e03\u91cc\u6e0a\u533a\u7684\u975e\u5e03\u6d1b\u8d6b\u6781\u5316P_\u03b2\u6062\u590d\u4e86\u52a8\u91cf\u7a7a\u95f4\u62d3\u6251\uff0c\u4f46\u7f3a\u4e4f\u76f4\u63a5\u3001\u7a33\u5065\u7684\u5b9e\u7a7a\u95f4\u4f53\u63a2\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u51c6\u4e92\u6613\u54c8\u5bc6\u987f\u91cfH\u0303\uff0c\u6d88\u9664NHSE\u540c\u65f6\u4fdd\u6301\u4f53\u62d3\u6251\uff0c\u5728\u70ed\u529b\u5b66\u6781\u9650\u4e0b\u4e25\u683c\u8bc1\u660eP_\u03b2 \u2261 \u03c7(H\u0303) (mod 1)\u7684\u57fa\u672c\u6052\u7b49\u5f0f\u3002\u901a\u8fc7\u5206\u6790Toeplitz\u7b97\u5b50\u7684Fredholm\u6307\u6807\uff0c\u63ed\u793a\u7ea0\u7f20\u6781\u5316\u7684\u9c81\u68d2\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u7ea0\u7f20\u6781\u5316\u03c7(H\u0303)\u5728\u4f20\u7edfResta\u6781\u5316\u56e0\u4f4d\u7f6e\u65b9\u5dee\u53d1\u6563\u800c\u5931\u6548\u65f6\u4ecd\u4fdd\u6301\u7a33\u5065\u91cf\u5b50\u5316\uff0c\u6210\u529f\u6062\u590d\u4e86\u7ebf\u9699\u3001\u70b9\u9699\u548c\u65e0\u80fd\u9699\u76f8\u4e2d\u975e\u5384\u7c73\u7cfb\u7edf\u7684\u4f53\u8fb9\u5bf9\u5e94\u5173\u7cfb\u3002", "conclusion": "\u7ea0\u7f20\u662f\u552f\u4e00\u80fd\u591f\u8d85\u8d8a\u5c40\u57df\u6027\u5d29\u6e83\u6355\u83b7\u975e\u5e03\u6d1b\u8d6b\u62d3\u6251\u7684\u5b9e\u7a7a\u95f4\u8bca\u65ad\u5de5\u5177\uff0c\u7edf\u4e00\u4e86\u975e\u5384\u7c73\u7269\u7406\u4e2d\u7684\u51e0\u4f55\u548c\u7ea0\u7f20\u8303\u5f0f\uff0c\u4e3a\u7406\u89e3\u975e\u5384\u7c73\u62d3\u6251\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2511.17582", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17582", "abs": "https://arxiv.org/abs/2511.17582", "authors": ["Jie Ou", "Shuaihong Jiang", "Yingjun Du", "Cees G. M. Snoek"], "title": "GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning", "comment": "Accepted by AAAI 2026", "summary": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disregarding the varying importance and difficulty of different inputs. This uniform treatment can lead to overfitting on trivial content or under-adaptation on more informative regions, especially in autoregressive settings with distinct prefill and decoding dynamics. In this paper, we propose GateRA, a unified framework that introduces token-aware modulation to dynamically adjust the strength of PEFT updates. By incorporating adaptive gating into standard PEFT branches, GateRA enables selective, token-level adaptation, preserving pre-trained knowledge for well-modeled inputs while focusing capacity on challenging cases. Empirical visualizations reveal phase-sensitive behaviors, where GateRA automatically suppresses updates for redundant prefill tokens while emphasizing adaptation during decoding. To promote confident and efficient modulation, we further introduce an entropy-based regularization that encourages near-binary gating decisions. This regularization prevents diffuse update patterns and leads to interpretable, sparse adaptation without hard thresholding. Finally, we present a theoretical analysis showing that GateRA induces a soft gradient-masking effect over the PEFT path, enabling continuous and differentiable control over adaptation. Experiments on multiple commonsense reasoning benchmarks demonstrate that GateRA consistently outperforms or matches prior PEFT methods.", "AI": {"tldr": "GateRA\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u4ee4\u724c\u611f\u77e5\u8c03\u5236\u52a8\u6001\u8c03\u6574PEFT\u66f4\u65b0\u7684\u5f3a\u5ea6\uff0c\u5b9e\u73b0\u9009\u62e9\u6027\u4ee4\u724c\u7ea7\u9002\u5e94\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709PEFT\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709PEFT\u65b9\u6cd5\u5bf9\u6240\u6709\u4ee4\u724c\u5e94\u7528\u9759\u6001\u3001\u8f93\u5165\u65e0\u5173\u7684\u66f4\u65b0\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u8f93\u5165\u7684\u91cd\u8981\u6027\u548c\u96be\u5ea6\u5dee\u5f02\uff0c\u53ef\u80fd\u5bfc\u81f4\u7b80\u5355\u5185\u5bb9\u8fc7\u62df\u5408\u6216\u91cd\u8981\u533a\u57df\u9002\u5e94\u4e0d\u8db3\u3002", "method": "\u5728\u6807\u51c6PEFT\u5206\u652f\u4e2d\u5f15\u5165\u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\uff0c\u5b9e\u73b0\u4ee4\u724c\u7ea7\u9009\u62e9\u6027\u9002\u5e94\uff1b\u4f7f\u7528\u57fa\u4e8e\u71b5\u7684\u6b63\u5219\u5316\u9f13\u52b1\u8fd1\u4e8c\u5143\u95e8\u63a7\u51b3\u7b56\uff1b\u7406\u8bba\u5206\u6790\u663e\u793aGateRA\u5728PEFT\u8def\u5f84\u4e0a\u4ea7\u751f\u8f6f\u68af\u5ea6\u63a9\u7801\u6548\u5e94\u3002", "result": "\u5728\u591a\u4e2a\u5e38\u8bc6\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGateRA\u6301\u7eed\u4f18\u4e8e\u6216\u5339\u914d\u5148\u524d\u7684PEFT\u65b9\u6cd5\uff1b\u53ef\u89c6\u5316\u663e\u793aGateRA\u81ea\u52a8\u6291\u5236\u5197\u4f59\u9884\u586b\u5145\u4ee4\u724c\u7684\u66f4\u65b0\uff0c\u5728\u89e3\u7801\u9636\u6bb5\u5f3a\u8c03\u9002\u5e94\u3002", "conclusion": "GateRA\u901a\u8fc7\u4ee4\u724c\u611f\u77e5\u8c03\u5236\u5b9e\u73b0\u4e86\u66f4\u667a\u80fd\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u80fd\u591f\u6839\u636e\u8f93\u5165\u96be\u5ea6\u52a8\u6001\u8c03\u6574\u9002\u5e94\u5f3a\u5ea6\uff0c\u5728\u4fdd\u6301\u9884\u8bad\u7ec3\u77e5\u8bc6\u7684\u540c\u65f6\u4e13\u6ce8\u4e8e\u6311\u6218\u6027\u6848\u4f8b\u3002"}}
{"id": "2511.18596", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.18596", "abs": "https://arxiv.org/abs/2511.18596", "authors": ["Onofre Rojas"], "title": "Dual thermal pseudo-critical features in a spin-1/2 Ising chain with twin-diamond geometry", "comment": "9 pages, 6 figures", "summary": "We study the coupled twin-diamond chain, a decorated one-dimensional Ising model motivated by the magnetic structure of \\mathrm{Cu}_{2}(\\mathrm{TeO}_{3})_{2}\\mathrm{Br}_{2}. By applying an exact mapping to an effective Ising chain, we obtain the full thermodynamic description of the system through a compact transfer-matrix formulation. The ground-state analysis reveals five distinct phases, including two frustrated sectors with extensive degeneracy. These frustrated regions give rise to characteristic entropy plateaus and separate the ordered phases in the zero-temperature diagram. At low temperatures the model exhibits peculiar sharp yet continuous variations of entropy, magnetization, and response functions, reflecting clear signatures of pseudo-transition behavior. The coupled twin-diamond chain thus provides an exactly solvable setting in which competing local configurations and internal frustration lead to pronounced dual pseudo-critical features in one dimension.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cbe\u786e\u6620\u5c04\u5230\u6709\u6548\u4f0a\u8f9b\u94fe\uff0c\u7814\u7a76\u4e86\u8026\u5408\u53cc\u91d1\u521a\u77f3\u94fe\u7684\u70ed\u529b\u5b66\u6027\u8d28\uff0c\u63ed\u793a\u4e86\u4e94\u4e2a\u4e0d\u540c\u7684\u57fa\u6001\u76f8\uff0c\u5305\u62ec\u4e24\u4e2a\u5177\u6709\u5e7f\u6cdb\u7b80\u5e76\u5ea6\u7684\u53d7\u632b\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u5bfc\u81f4\u7279\u5f81\u71b5\u5e73\u53f0\u548c\u4f2a\u76f8\u53d8\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u53d7Cu\u2082(TeO\u2083)\u2082Br\u2082\u78c1\u6027\u7ed3\u6784\u542f\u53d1\u7684\u8026\u5408\u53cc\u91d1\u521a\u77f3\u94fe\uff0c\u63a2\u7d22\u5176\u53d7\u632b\u7279\u6027\u548c\u70ed\u529b\u5b66\u884c\u4e3a\u3002", "method": "\u5e94\u7528\u7cbe\u786e\u6620\u5c04\u5230\u6709\u6548\u4f0a\u8f9b\u94fe\uff0c\u901a\u8fc7\u7d27\u51d1\u7684\u4f20\u9012\u77e9\u9635\u516c\u5f0f\u83b7\u5f97\u7cfb\u7edf\u7684\u5b8c\u6574\u70ed\u529b\u5b66\u63cf\u8ff0\u3002", "result": "\u57fa\u6001\u5206\u6790\u63ed\u793a\u4e86\u4e94\u4e2a\u4e0d\u540c\u7684\u76f8\uff0c\u5305\u62ec\u4e24\u4e2a\u5177\u6709\u5e7f\u6cdb\u7b80\u5e76\u5ea6\u7684\u53d7\u632b\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u4ea7\u751f\u7279\u5f81\u71b5\u5e73\u53f0\u5e76\u5728\u96f6\u6e29\u56fe\u4e2d\u5206\u9694\u6709\u5e8f\u76f8\u3002\u5728\u4f4e\u6e29\u4e0b\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u71b5\u3001\u78c1\u5316\u548c\u54cd\u5e94\u51fd\u6570\u7684\u5c16\u9510\u4f46\u8fde\u7eed\u53d8\u5316\uff0c\u53cd\u6620\u4e86\u4f2a\u76f8\u53d8\u884c\u4e3a\u7684\u6e05\u6670\u7279\u5f81\u3002", "conclusion": "\u8026\u5408\u53cc\u91d1\u521a\u77f3\u94fe\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cbe\u786e\u53ef\u89e3\u7684\u73af\u5883\uff0c\u5176\u4e2d\u7ade\u4e89\u7684\u5c40\u90e8\u6784\u578b\u548c\u5185\u90e8\u53d7\u632b\u5bfc\u81f4\u4e00\u7ef4\u4e2d\u663e\u8457\u7684\u4f2a\u4e34\u754c\u7279\u5f81\u3002"}}
{"id": "2511.17856", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17856", "abs": "https://arxiv.org/abs/2511.17856", "authors": ["Joshua Nevin"], "title": "Exact Non-Identity Check and Gate-Teleportation-Based Indistinguishability Obfuscation are NP-hard for Low-T-Depth Quantum Circuits", "comment": "36 pages, 4 figures", "summary": "In 2021, Broadbent and Kazmi developed a gate-teleportation-based protocol for computational indistinguishability obfuscation of quantum circuits. This protocol is efficient for Clifford+T circuits with logarithmically many T-gates, where the limiting factor in the efficiency of the protocol is the difficulty, on input a quantum circuit $C$, of the classical task of producing a description of the unitary obtained by conjugating a Pauli $P$ (corresponding to a Bell-measurement outcome) by $C$, where this description only depends on the input-output functionality of $CPC^{\\dagger}$. The task above, in turn, is at least as hard as the problem of determining whether two $n$-qubit quantum circuits are perfectly equivalent up to global phase. In 2009, Tanaka defined the corresponding decision problem Exact Non-Identity Check (ENIC) and showed that ENIC is NQP-complete in general. Motivated by this, we consider in this work what happens when we pass from low T-count to low T-depth. In particular, we show that, for Clifford+T circuits of T-depth $O(\\log(n))$, deciding ENIC is NP-hard. This effectively rules out the possibility, for Clifford+T circuits of logarithmic T-depth, of either efficient ENIC or efficient gate-teleportation based computational indistinguishability obfuscation, unless P=NP.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Clifford+T\u91cf\u5b50\u7535\u8def\u4e2dENIC\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u53d1\u73b0\u5bf9\u4e8eT\u6df1\u5ea6\u4e3aO(log(n))\u7684\u7535\u8def\uff0cENIC\u95ee\u9898\u662fNP\u96be\u7684\uff0c\u8fd9\u6392\u9664\u4e86\u57fa\u4e8e\u95e8\u9690\u5f62\u4f20\u6001\u7684\u9ad8\u6548\u8ba1\u7b97\u4e0d\u53ef\u533a\u5206\u6df7\u6dc6\u7684\u53ef\u80fd\u6027\uff0c\u9664\u975eP=NP\u3002", "motivation": "Broadbent\u548cKazmi\u57282021\u5e74\u63d0\u51fa\u4e86\u57fa\u4e8e\u95e8\u9690\u5f62\u4f20\u6001\u7684\u8ba1\u7b97\u4e0d\u53ef\u533a\u5206\u6df7\u6dc6\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u6548\u7387\u53d7\u9650\u4e8eENIC\u95ee\u9898\u7684\u96be\u5ea6\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u5f53\u4ece\u4f4eT\u8ba1\u6570\u8f6c\u5411\u4f4eT\u6df1\u5ea6\u65f6\uff0cENIC\u95ee\u9898\u7684\u590d\u6742\u5ea6\u5982\u4f55\u53d8\u5316\u3002", "method": "\u901a\u8fc7\u5206\u6790Clifford+T\u7535\u8def\u4e2dT\u6df1\u5ea6\u4e3aO(log(n))\u65f6\u7684ENIC\u95ee\u9898\uff0c\u8bc1\u660e\u5176NP\u96be\u5ea6\u3002", "result": "\u5bf9\u4e8eT\u6df1\u5ea6\u4e3aO(log(n))\u7684Clifford+T\u7535\u8def\uff0cENIC\u95ee\u9898\u662fNP\u96be\u7684\u3002", "conclusion": "\u9664\u975eP=NP\uff0c\u5426\u5219\u5bf9\u4e8e\u5bf9\u6570T\u6df1\u5ea6\u7684Clifford+T\u7535\u8def\uff0c\u65e2\u4e0d\u53ef\u80fd\u6709\u9ad8\u6548\u7684ENIC\u7b97\u6cd5\uff0c\u4e5f\u4e0d\u53ef\u80fd\u6709\u57fa\u4e8e\u95e8\u9690\u5f62\u4f20\u6001\u7684\u9ad8\u6548\u8ba1\u7b97\u4e0d\u53ef\u533a\u5206\u6df7\u6dc6\u534f\u8bae\u3002"}}
{"id": "2511.17855", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17855", "abs": "https://arxiv.org/abs/2511.17855", "authors": ["Jordan Abi Nader", "David Lee", "Nathaniel Dennler", "Andreea Bobu"], "title": "QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents", "comment": null, "summary": "Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.", "AI": {"tldr": "QuickLAP\u662f\u4e00\u4e2a\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u878d\u5408\u7269\u7406\u53cd\u9988\u548c\u8bed\u8a00\u53cd\u9988\u6765\u5b9e\u65f6\u63a8\u65ad\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7LLM\u4ece\u81ea\u7531\u5f62\u5f0f\u8bed\u8a00\u4e2d\u63d0\u53d6\u5956\u52b1\u7279\u5f81\u6ce8\u610f\u529b\u63a9\u7801\u548c\u504f\u597d\u8f6c\u79fb\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\u76f8\u6bd4\u4ec5\u4f7f\u7528\u7269\u7406\u53cd\u9988\u7684\u57fa\u7ebf\u65b9\u6cd5\u51cf\u5c11\u4e8670%\u4ee5\u4e0a\u7684\u5956\u52b1\u5b66\u4e60\u8bef\u5dee\u3002", "motivation": "\u673a\u5668\u4eba\u9700\u8981\u4ece\u4eba\u7c7b\u7684\u884c\u4e3a\u548c\u8bed\u8a00\u4e2d\u5b66\u4e60\uff0c\u4f46\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u6a21\u6001\u90fd\u4e0d\u5b8c\u6574\uff1a\u7269\u7406\u4fee\u6b63\u6709\u57fa\u7840\u4f46\u610f\u56fe\u6a21\u7cca\uff0c\u8bed\u8a00\u8868\u8fbe\u9ad8\u7ea7\u76ee\u6807\u4f46\u7f3a\u4e4f\u7269\u7406\u57fa\u7840\u3002", "method": "\u63d0\u51faQuickLAP\u6846\u67b6\uff0c\u5c06\u8bed\u8a00\u89c6\u4e3a\u7528\u6237\u6f5c\u5728\u504f\u597d\u7684\u6982\u7387\u89c2\u5bdf\uff0c\u4f7f\u7528LLM\u63d0\u53d6\u5956\u52b1\u7279\u5f81\u6ce8\u610f\u529b\u63a9\u7801\u548c\u504f\u597d\u8f6c\u79fb\uff0c\u5e76\u4e0e\u7269\u7406\u53cd\u9988\u901a\u8fc7\u95ed\u5f0f\u66f4\u65b0\u89c4\u5219\u96c6\u6210\u3002", "result": "\u5728\u534a\u81ea\u52a8\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\uff0cQuickLAP\u76f8\u6bd4\u4ec5\u4f7f\u7528\u7269\u7406\u53cd\u9988\u548c\u542f\u53d1\u5f0f\u591a\u6a21\u6001\u57fa\u7ebf\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e8670%\u4ee5\u4e0a\u7684\u5956\u52b1\u5b66\u4e60\u8bef\u5dee\u300215\u540d\u53c2\u4e0e\u8005\u7684\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u66f4\u6613\u7406\u89e3\u548c\u534f\u4f5c\uff0c\u7528\u6237\u66f4\u559c\u6b22\u5176\u5b66\u4e60\u7684\u884c\u4e3a\u3002", "conclusion": "QuickLAP\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u5b9e\u65f6\u3001\u9c81\u68d2\u7684\u5956\u52b1\u5b66\u4e60\uff0c\u80fd\u591f\u5904\u7406\u6a21\u7cca\u53cd\u9988\uff0c\u878d\u5408\u7269\u7406\u548c\u8bed\u8a00\u53cd\u9988\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5b66\u4e60\u6548\u679c\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2511.17583", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17583", "abs": "https://arxiv.org/abs/2511.17583", "authors": ["Chenrui Ma", "Xi Xiao", "Tianyang Wang", "Xiao Wang", "Yanning Shen"], "title": "Learning Straight Flows: Variational Flow Matching for Efficient Generation", "comment": null, "summary": "Flow Matching has limited ability in achieving one-step generation due to its reliance on learned curved trajectories. Previous studies have attempted to address this limitation by either modifying the coupling distribution to prevent interpolant intersections or introducing consistency and mean-velocity modeling to promote straight trajectory learning. However, these approaches often suffer from discrete approximation errors, training instability, and convergence difficulties. To tackle these issues, in the present work, we propose \\textbf{S}traight \\textbf{V}ariational \\textbf{F}low \\textbf{M}atching (\\textbf{S-VFM}), which integrates a variational latent code representing the ``generation overview'' into the Flow Matching framework. \\textbf{S-VFM} explicitly enforces trajectory straightness, ideally producing linear generation paths. The proposed method achieves competitive performance across three challenge benchmarks and demonstrates advantages in both training and inference efficiency compared with existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faS-VFM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u53d8\u5206\u6f5c\u7801\u6765\u5f3a\u5236\u8f68\u8ff9\u76f4\u7ebf\u5316\uff0c\u89e3\u51b3Flow Matching\u4e2d\u4e00\u6b65\u751f\u6210\u80fd\u529b\u53d7\u9650\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u4e14\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "Flow Matching\u65b9\u6cd5\u7531\u4e8e\u4f9d\u8d56\u5b66\u4e60\u5230\u7684\u5f2f\u66f2\u8f68\u8ff9\uff0c\u5728\u5b9e\u73b0\u4e00\u6b65\u751f\u6210\u65b9\u9762\u80fd\u529b\u6709\u9650\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u79bb\u6563\u8fd1\u4f3c\u8bef\u5dee\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6536\u655b\u56f0\u96be\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faS-VFM\u65b9\u6cd5\uff0c\u5c06\u4ee3\u8868\"\u751f\u6210\u6982\u89c8\"\u7684\u53d8\u5206\u6f5c\u7801\u96c6\u6210\u5230Flow Matching\u6846\u67b6\u4e2d\uff0c\u660e\u786e\u5f3a\u5236\u8f68\u8ff9\u76f4\u7ebf\u5316\uff0c\u7406\u60f3\u60c5\u51b5\u4e0b\u4ea7\u751f\u7ebf\u6027\u751f\u6210\u8def\u5f84\u3002", "result": "\u5728\u4e09\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u65b9\u9762\u90fd\u663e\u793a\u51fa\u4f18\u52bf\u3002", "conclusion": "S-VFM\u901a\u8fc7\u6574\u5408\u53d8\u5206\u6f5c\u7801\u6210\u529f\u89e3\u51b3\u4e86Flow Matching\u7684\u8f68\u8ff9\u5f2f\u66f2\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u76f4\u7ebf\u8f68\u8ff9\u751f\u6210\u3002"}}
{"id": "2511.17896", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17896", "abs": "https://arxiv.org/abs/2511.17896", "authors": ["Moein Naseri"], "title": "Entanglement Generation via Hamiltonian Dynamics Having Limited Resources", "comment": "10 pages, 1 figure", "summary": "We investigate the fundamental limits of entanglement generation under bipartite Hamiltonian dynamics when only finite physical resources-specifically, bounded energy variance-are available. Using the relative entropy of entanglement, we derive a closed analytical expression for the instantaneous entanglement generation rate for arbitrary pure states and Hamiltonians expressed in the Schmidt basis. We find that constraints based solely on the mean energy of the Hamiltonian are insufficient to bound the entanglement generation rate, whereas imposing a variance constraint ensures a finite and well-defined maximum. We fully characterize the Hamiltonians that achieve this optimal rate, establishing a direct relation between their imaginary components in the Schmidt basis and the structure of the optimal initial states. For systems without ancillas, we obtain a closed-form expression for the maximal rate in terms of the surprisal variance of the Schmidt coefficients and identify the family of optimal states and Hamiltonians. We further extend our analysis to scenarios where Alice and Bob may employ local ancillary systems: using a matrix-analytic framework and a refined description of the Hamiltonians allowed by the physical constraints, we derive an explicit optimization formula and characterize the attainable enhancement in entanglement generation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u6709\u9650\u7269\u7406\u8d44\u6e90\uff08\u6709\u754c\u80fd\u91cf\u65b9\u5dee\uff09\u7ea6\u675f\u4e0b\uff0c\u53cc\u4f53\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u4e2d\u7ea0\u7f20\u751f\u6210\u7684\u57fa\u672c\u6781\u9650\u3002\u901a\u8fc7\u76f8\u5bf9\u71b5\u7ea0\u7f20\u5ea6\u91cf\uff0c\u63a8\u5bfc\u4e86\u4efb\u610f\u7eaf\u6001\u548c\u54c8\u5bc6\u987f\u91cf\u7684\u77ac\u65f6\u7ea0\u7f20\u751f\u6210\u7387\u7684\u5c01\u95ed\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "motivation": "\u63a2\u7d22\u5728\u6709\u9650\u7269\u7406\u8d44\u6e90\u7ea6\u675f\u4e0b\u7ea0\u7f20\u751f\u6210\u7684\u57fa\u672c\u6781\u9650\uff0c\u7279\u522b\u662f\u5f53\u4ec5\u8003\u8651\u6709\u754c\u80fd\u91cf\u65b9\u5dee\u65f6\uff0c\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u80fd\u591f\u4ea7\u751f\u7684\u6700\u5927\u7ea0\u7f20\u901f\u7387\u3002", "method": "\u4f7f\u7528\u76f8\u5bf9\u71b5\u7ea0\u7f20\u5ea6\u91cf\uff0c\u5728\u65bd\u5bc6\u7279\u57fa\u4e0b\u5206\u6790\u7eaf\u6001\u548c\u54c8\u5bc6\u987f\u91cf\uff0c\u63a8\u5bfc\u77ac\u65f6\u7ea0\u7f20\u751f\u6210\u7387\u7684\u5c01\u95ed\u89e3\u6790\u8868\u8fbe\u5f0f\u3002\u91c7\u7528\u77e9\u9635\u5206\u6790\u6846\u67b6\u548c\u54c8\u5bc6\u987f\u91cf\u7684\u7cbe\u7ec6\u63cf\u8ff0\u6765\u5904\u7406\u5c40\u90e8\u8f85\u52a9\u7cfb\u7edf\u7684\u60c5\u51b5\u3002", "result": "\u53d1\u73b0\u4ec5\u57fa\u4e8e\u54c8\u5bc6\u987f\u91cf\u5e73\u5747\u80fd\u91cf\u7684\u7ea6\u675f\u4e0d\u8db3\u4ee5\u9650\u5236\u7ea0\u7f20\u751f\u6210\u7387\uff0c\u800c\u65bd\u52a0\u65b9\u5dee\u7ea6\u675f\u53ef\u786e\u4fdd\u6709\u9650\u4e14\u660e\u786e\u7684\u6700\u5927\u503c\u3002\u5b8c\u5168\u523b\u753b\u4e86\u8fbe\u5230\u6700\u4f18\u901f\u7387\u7684\u54c8\u5bc6\u987f\u91cf\uff0c\u5efa\u7acb\u4e86\u5176\u65bd\u5bc6\u7279\u57fa\u4e2d\u865a\u90e8\u4e0e\u6700\u4f18\u521d\u59cb\u6001\u7ed3\u6784\u4e4b\u95f4\u7684\u76f4\u63a5\u5173\u7cfb\u3002\u5bf9\u4e8e\u65e0\u8f85\u52a9\u7cfb\u7edf\u7684\u60c5\u51b5\uff0c\u83b7\u5f97\u4e86\u6700\u5927\u901f\u7387\u7684\u5c01\u95ed\u5f62\u5f0f\u8868\u8fbe\u5f0f\u3002", "conclusion": "\u80fd\u91cf\u65b9\u5dee\u7ea6\u675f\u5bf9\u4e8e\u786e\u4fdd\u6709\u9650\u7ea0\u7f20\u751f\u6210\u7387\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u5efa\u7acb\u4e86\u7ea0\u7f20\u751f\u6210\u57fa\u672c\u6781\u9650\u7684\u5b8c\u6574\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u523b\u753b\u4e86\u6700\u4f18\u54c8\u5bc6\u987f\u91cf\u548c\u521d\u59cb\u6001\u7684\u7279\u5f81\u3002"}}
{"id": "2511.17876", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17876", "abs": "https://arxiv.org/abs/2511.17876", "authors": ["Mukul Singh", "Ananya Singha", "Aishni Parab", "Pronita Mehrotra", "Sumit Gulwani"], "title": "Training Emergent Joint Associations: A Reinforcement Learning Approach to Creative Thinking in Language Models", "comment": null, "summary": "Associative thinking--the ability to connect seemingly unrelated ideas--is a foundational element of human creativity and problem-solving. This paper explores whether reinforcement learning (RL) guided by associative thinking principles can enhance a model's performance across diverse generative tasks, including story writing, code generation, and chart creation. We introduce a reinforcement learning framework that uses a prompt-based evaluation mechanism, incorporating established divergent thinking metrics from creativity research. A base language model is fine-tuned using this framework to reward outputs demonstrating higher novelty through higher degrees of conceptual connectivity. Interestingly, the experimental results suggest that RL-based associative thinking-trained models not only generate more original and coherent stories but also exhibit improved abstraction and flexibility in tasks such as programming and data visualization. Our findings provide initial evidence that modeling cognitive creativity principles through reinforcement learning can yield more adaptive and generative AI.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u8054\u60f3\u601d\u7ef4\u539f\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u662f\u5426\u80fd\u63d0\u5347\u6a21\u578b\u5728\u6545\u4e8b\u5199\u4f5c\u3001\u4ee3\u7801\u751f\u6210\u548c\u56fe\u8868\u521b\u5efa\u7b49\u591a\u6837\u5316\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u8054\u60f3\u601d\u7ef4\u662f\u4eba\u7c7b\u521b\u9020\u529b\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u57fa\u7840\u8981\u7d20\uff0c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6a21\u62df\u8ba4\u77e5\u521b\u9020\u529b\u539f\u5219\u80fd\u5426\u4ea7\u751f\u66f4\u5177\u9002\u5e94\u6027\u548c\u751f\u6210\u6027\u7684AI\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u63d0\u793a\u7684\u8bc4\u4f30\u673a\u5236\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u521b\u9020\u529b\u7814\u7a76\u4e2d\u65e2\u6709\u7684\u53d1\u6563\u601d\u7ef4\u6307\u6807\uff0c\u5bf9\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u5956\u52b1\u5c55\u793a\u66f4\u9ad8\u6982\u5ff5\u8fde\u63a5\u6027\u7684\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u8054\u60f3\u601d\u7ef4\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u4e0d\u4ec5\u80fd\u751f\u6210\u66f4\u539f\u521b\u548c\u8fde\u8d2f\u7684\u6545\u4e8b\uff0c\u8fd8\u5728\u7f16\u7a0b\u548c\u6570\u636e\u53ef\u89c6\u5316\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u62bd\u8c61\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u521d\u6b65\u8bc1\u636e\uff0c\u8868\u660e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5efa\u6a21\u8ba4\u77e5\u521b\u9020\u529b\u539f\u5219\u53ef\u4ee5\u4ea7\u751f\u66f4\u5177\u9002\u5e94\u6027\u548c\u751f\u6210\u6027\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2511.17584", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17584", "abs": "https://arxiv.org/abs/2511.17584", "authors": ["Haoyan Xu", "Ruizhi Qian", "Zhengtao Yao", "Ziyi Liu", "Li Li", "Yuqi Li", "Yanshu Li", "Wenqing Zheng", "Daniele Rosa", "Daniel Barcklow", "Senthil Kumar", "Jieyu Zhao", "Yue Zhao"], "title": "LLM-Powered Text-Attributed Graph Anomaly Detection via Retrieval-Augmented Reasoning", "comment": null, "summary": "Anomaly detection on attributed graphs plays an essential role in applications such as fraud detection, intrusion monitoring, and misinformation analysis. However, text-attributed graphs (TAGs), in which node information is expressed in natural language, remain underexplored, largely due to the absence of standardized benchmark datasets. In this work, we introduce TAG-AD, a comprehensive benchmark for anomaly node detection on TAGs. TAG-AD leverages large language models (LLMs) to generate realistic anomalous node texts directly in the raw text space, producing anomalies that are semantically coherent yet contextually inconsistent and thus more reflective of real-world irregularities. In addition, TAG-AD incorporates multiple other anomaly types, enabling thorough and reproducible evaluation of graph anomaly detection (GAD) methods. With these datasets, we further benchmark existing unsupervised GNN-based GAD methods as well as zero-shot LLMs for GAD.\n  As part of our zero-shot detection setup, we propose a retrieval-augmented generation (RAG)-assisted, LLM-based zero-shot anomaly detection framework. The framework mitigates reliance on brittle, hand-crafted prompts by constructing a global anomaly knowledge base and distilling it into reusable analysis frameworks. Our experimental results reveal a clear division of strengths: LLMs are particularly effective at detecting contextual anomalies, whereas GNN-based methods remain superior for structural anomaly detection. Moreover, RAG-assisted prompting achieves performance comparable to human-designed prompts while eliminating manual prompt engineering, underscoring the practical value of our RAG-assisted zero-shot LLM anomaly detection framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TAG-AD\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6587\u672c\u5c5e\u6027\u56fe\u4e0a\u7684\u5f02\u5e38\u8282\u70b9\u68c0\u6d4b\uff0c\u5229\u7528LLM\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u4f46\u4e0a\u4e0b\u6587\u4e0d\u4e00\u81f4\u7684\u5f02\u5e38\u6587\u672c\uff0c\u5e76\u8bc4\u4f30\u4e86GNN\u65b9\u6cd5\u548c\u96f6\u6837\u672cLLM\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u6587\u672c\u5c5e\u6027\u56fe\u4e0a\u7684\u5f02\u5e38\u68c0\u6d4b\u5728\u6b3a\u8bc8\u68c0\u6d4b\u3001\u5165\u4fb5\u76d1\u63a7\u7b49\u5e94\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u6570\u636e\u96c6\u800c\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528LLM\u5728\u539f\u59cb\u6587\u672c\u7a7a\u95f4\u4e2d\u751f\u6210\u73b0\u5b9e\u5f02\u5e38\u8282\u70b9\u6587\u672c\uff0c\u6784\u5efa\u5305\u542b\u591a\u79cd\u5f02\u5e38\u7c7b\u578b\u7684TAG-AD\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eRAG\u7684\u96f6\u6837\u672cLLM\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aLLM\u5728\u68c0\u6d4b\u4e0a\u4e0b\u6587\u5f02\u5e38\u65b9\u9762\u7279\u522b\u6709\u6548\uff0c\u800cGNN\u65b9\u6cd5\u5728\u7ed3\u6784\u5f02\u5e38\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002RAG\u8f85\u52a9\u63d0\u793a\u5b9e\u73b0\u4e86\u4e0e\u4eba\u5de5\u8bbe\u8ba1\u63d0\u793a\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "LLM\u548cGNN\u65b9\u6cd5\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5404\u6709\u4f18\u52bf\uff0cRAG\u8f85\u52a9\u7684\u96f6\u6837\u672cLLM\u6846\u67b6\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u65e0\u9700\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\u5373\u53ef\u8fbe\u5230\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2511.18947", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2511.18947", "abs": "https://arxiv.org/abs/2511.18947", "authors": ["Rapha\u00ebl Maire", "Andrea Plati", "Frank Smallenburg", "Giuseppe Foffi"], "title": "Conservation laws and slow dynamics determine the universality class of interfaces in active matter", "comment": "11 pages, 8 figures", "summary": "While equilibrium interfaces display universal large-scale statistics, interfaces in phase-separated active and driven systems are predicted to belong to distinct non-equilibrium universality classes. Yet, such behavior has proven difficult to observe, with most systems exhibiting equilibrium-like fluctuations despite their strongly non-equilibrium microscopic dynamics. We introduce an active hard-disk model that contrary to self-propelled models, displays clear non-equilibrium interfacial scaling and observe for the first time, the $|\\boldsymbol q|$KPZ and wet-$|\\boldsymbol q|$KPZ universality classes while revealing a new, previously overlooked universality class arising in systems with slow crystalline or glassy dynamics. These distinct classes are selected by conservation laws and slow hydrodynamic modes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5728\u6d3b\u6027\u786c\u76d8\u6a21\u578b\u4e2d\u89c2\u5bdf\u5230\u975e\u5e73\u8861\u754c\u9762\u6807\u5ea6\u884c\u4e3a\uff0c\u53d1\u73b0\u4e86|q|KPZ\u548c\u6e7f|q|KPZ\u666e\u9002\u6027\u7c7b\uff0c\u5e76\u63ed\u793a\u4e86\u4e00\u4e2a\u7531\u7f13\u6162\u6676\u4f53\u6216\u73bb\u7483\u52a8\u529b\u5b66\u4ea7\u751f\u7684\u65b0\u666e\u9002\u6027\u7c7b\u3002", "motivation": "\u867d\u7136\u5e73\u8861\u754c\u9762\u663e\u793a\u901a\u7528\u7684\u5927\u5c3a\u5ea6\u7edf\u8ba1\u7279\u6027\uff0c\u4f46\u6d3b\u6027\u7cfb\u7edf\u548c\u9a71\u52a8\u7cfb\u7edf\u4e2d\u7684\u754c\u9762\u88ab\u9884\u6d4b\u5c5e\u4e8e\u4e0d\u540c\u7684\u975e\u5e73\u8861\u666e\u9002\u6027\u7c7b\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u884c\u4e3a\u5f88\u96be\u89c2\u5bdf\u5230\uff0c\u5927\u591a\u6570\u7cfb\u7edf\u5c3d\u7ba1\u5177\u6709\u5f3a\u975e\u5e73\u8861\u5fae\u89c2\u52a8\u529b\u5b66\uff0c\u5374\u8868\u73b0\u51fa\u7c7b\u4f3c\u5e73\u8861\u7684\u6da8\u843d\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u6d3b\u6027\u786c\u76d8\u6a21\u578b\uff0c\u4e0e\u81ea\u63a8\u8fdb\u6a21\u578b\u76f8\u53cd\uff0c\u8be5\u6a21\u578b\u663e\u793a\u51fa\u6e05\u6670\u7684\u975e\u5e73\u8861\u754c\u9762\u6807\u5ea6\u884c\u4e3a\u3002", "result": "\u9996\u6b21\u89c2\u5bdf\u5230|q|KPZ\u548c\u6e7f|q|KPZ\u666e\u9002\u6027\u7c7b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4e00\u4e2a\u7531\u7f13\u6162\u6676\u4f53\u6216\u73bb\u7483\u52a8\u529b\u5b66\u4ea7\u751f\u7684\u65b0\u666e\u9002\u6027\u7c7b\u3002\u8fd9\u4e9b\u4e0d\u540c\u7684\u7c7b\u522b\u7531\u5b88\u6052\u5b9a\u5f8b\u548c\u7f13\u6162\u7684\u6d41\u4f53\u52a8\u529b\u5b66\u6a21\u5f0f\u9009\u62e9\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u6d3b\u6027\u786c\u76d8\u6a21\u578b\u6210\u529f\u89c2\u6d4b\u5230\u4e86\u975e\u5e73\u8861\u754c\u9762\u6807\u5ea6\u884c\u4e3a\uff0c\u53d1\u73b0\u4e86\u591a\u4e2a\u666e\u9002\u6027\u7c7b\uff0c\u4e3a\u7406\u89e3\u975e\u5e73\u8861\u7cfb\u7edf\u4e2d\u7684\u754c\u9762\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.17901", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17901", "abs": "https://arxiv.org/abs/2511.17901", "authors": ["Xiao-Dong Zhang", "Bin-Bin Cai", "Song Lin"], "title": "Verifcation of general multi-qudit pure states", "comment": null, "summary": "Verifying prepared quantum states is crucial for hybrid systems whose subsystems may have different local dimensions. We present a generalized stabilizer framework and associated test that apply to general multi-qudit states, including composite-dimensional and hybrid architectures. Using only adaptive local measurements, our method verifies qutrit-qubit states, arbitrary two-qubit pure states, Bell/Bell-like, GHZ/GHZ-like, graph, hypergraph, multigraph, and multihypergraph states, with efficiencies matching or surpassing the best known schemes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u7a33\u5b9a\u5b50\u6846\u67b6\u548c\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u591a\u91cf\u5b50\u6bd4\u7279\u6001\uff0c\u5305\u62ec\u590d\u5408\u7ef4\u5ea6\u548c\u6df7\u5408\u67b6\u6784\uff0c\u4ec5\u4f7f\u7528\u81ea\u9002\u5e94\u5c40\u57df\u6d4b\u91cf\u5373\u53ef\u9ad8\u6548\u9a8c\u8bc1\u591a\u79cd\u91cf\u5b50\u6001\u3002", "motivation": "\u9a8c\u8bc1\u5236\u5907\u7684\u91cf\u5b50\u6001\u5bf9\u4e8e\u5177\u6709\u4e0d\u540c\u5c40\u90e8\u7ef4\u5ea6\u7684\u6df7\u5408\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8e\u4e00\u822c\u591a\u91cf\u5b50\u6bd4\u7279\u6001\u7684\u9a8c\u8bc1\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u5e7f\u4e49\u7a33\u5b9a\u5b50\u6846\u67b6\u548c\u5173\u8054\u6d4b\u8bd5\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u5c40\u57df\u6d4b\u91cf\u6765\u9a8c\u8bc1\u5404\u79cd\u91cf\u5b50\u6001\uff0c\u5305\u62ecqutrit-qubit\u6001\u3001\u4efb\u610f\u4e24\u91cf\u5b50\u6bd4\u7279\u7eaf\u6001\u3001Bell/Bell-like\u6001\u3001GHZ/GHZ-like\u6001\u3001\u56fe\u6001\u3001\u8d85\u56fe\u6001\u3001\u591a\u56fe\u6001\u548c\u591a\u8d85\u56fe\u6001\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u9a8c\u8bc1\u6548\u7387\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u5df2\u77e5\u6700\u4f73\u65b9\u6848\uff0c\u80fd\u591f\u9ad8\u6548\u9a8c\u8bc1\u591a\u79cd\u91cf\u5b50\u6001\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5e7f\u4e49\u7a33\u5b9a\u5b50\u6846\u67b6\u4e3a\u9a8c\u8bc1\u6df7\u5408\u7ef4\u5ea6\u91cf\u5b50\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ec5\u901a\u8fc7\u81ea\u9002\u5e94\u5c40\u57df\u6d4b\u91cf\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u7684\u91cf\u5b50\u6001\u9a8c\u8bc1\u3002"}}
{"id": "2511.17585", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17585", "abs": "https://arxiv.org/abs/2511.17585", "authors": ["Kang He", "Boyu Chen", "Yuzhe Ding", "Fei Li", "Chong Teng", "Donghong Ji"], "title": "PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis", "comment": "Accepted by AAAI 2026", "summary": "Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by integrating textual, acoustic, and visual signals. Although multimodal fusion is designed to leverage cross-modal complementarity, real-world scenarios often exhibit modality competition: dominant modalities tend to overshadow weaker ones, leading to suboptimal performance.In this paper, we propose PaSE, a novel Prototype-aligned Calibration and Shapley-optimized Equilibrium framework, which enhances collaboration while explicitly mitigating modality competition. PaSE first applies Prototype-guided Calibration Learning (PCL) to refine unimodal representations and align them through an Entropic Optimal Transport mechanism that ensures semantic consistency. To further stabilize optimization, we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion module is first used to extract shared representations, followed by Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients according to the contribution of each modality. Extensive experiments on IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance and effectively alleviates modality competition.", "AI": {"tldr": "PaSE\u6846\u67b6\u901a\u8fc7\u539f\u578b\u5bf9\u9f50\u6821\u51c6\u548cShapley\u4f18\u5316\u5747\u8861\u6765\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u6a21\u6001\u7ade\u4e89\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u6001\u95f4\u534f\u4f5c\u6027\u80fd", "motivation": "\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\uff0c\u4f18\u52bf\u6a21\u6001\u5f80\u5f80\u4f1a\u538b\u5236\u5f31\u52bf\u6a21\u6001\uff0c\u5bfc\u81f4\u6a21\u6001\u7ade\u4e89\u95ee\u9898\uff0c\u5f71\u54cd\u6574\u4f53\u6027\u80fd", "method": "\u63d0\u51faPaSE\u6846\u67b6\uff1a1) \u539f\u578b\u5f15\u5bfc\u6821\u51c6\u5b66\u4e60(PCL)\u901a\u8fc7\u71b5\u6700\u4f18\u4f20\u8f93\u673a\u5236\u7cbe\u70bc\u5355\u6a21\u6001\u8868\u793a\uff1b2) \u53cc\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff1a\u539f\u578b\u95e8\u63a7\u878d\u5408\u6a21\u5757\u63d0\u53d6\u5171\u4eab\u8868\u793a\uff0cShapley\u68af\u5ea6\u8c03\u5236(SGM)\u81ea\u9002\u5e94\u8c03\u6574\u68af\u5ea6", "result": "\u5728IEMOCAP\u3001MOSI\u548cMOSEI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPaSE\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u5e76\u6709\u6548\u7f13\u89e3\u4e86\u6a21\u6001\u7ade\u4e89", "conclusion": "PaSE\u6846\u67b6\u901a\u8fc7\u539f\u578b\u5bf9\u9f50\u548cShapley\u4f18\u5316\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u6a21\u6001\u7ade\u4e89\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd"}}
{"id": "2511.19082", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19082", "abs": "https://arxiv.org/abs/2511.19082", "authors": ["Henrique A. Fernandes", "Roberto da Silva", "Paulo F. Gomes"], "title": "Phase Diagrams of the YK Surface-Reaction Model on 2D lattices with Exchange Diffusion", "comment": "16 pages, 6 figures", "summary": "In this work, we investigate the phase diagrams of the Yaldram and Khan catalytic surface model on square and hexagonal lattices when exchange diffusion is allowed for carbon monoxide (CO) and nitrogen (N) atoms. To reach our goal, we carried out steady-state Monte Carlo (MC) simulations over $4\\times 10^5$ points, for both lattices, in order to obtain a framework of the steady reactive state of the model for different values of the nitric oxide dissociation rate, $r_{NO}$. The results show the emergence of steady reactive state for certain values of $r_{NO}$ and of exchange diffusion rate $x$ when the simulations take place on square lattices. Our findings on the hexagonal lattice also show that the diffusion of these species favors the appearance of the active phase for values of $r_{NO}$ lower than that found for the standard model. In addition, we observed that the system possesses a continuous phase transition and a discontinuous one separating the active phase from absorbing states for both lattices, except for $r_{NO}=1$ in which the continuous phase transition is destroyed and a steady reactive state emerges from the beginning since very small values of $x$.", "AI": {"tldr": "\u7814\u7a76\u4e86Yaldram\u548cKhan\u50ac\u5316\u8868\u9762\u6a21\u578b\u5728\u65b9\u5f62\u548c\u516d\u8fb9\u5f62\u6676\u683c\u4e0a\u7684\u76f8\u56fe\uff0c\u8003\u8651\u4e86CO\u548cN\u539f\u5b50\u7684\u4ea4\u6362\u6269\u6563\u3002\u901a\u8fc7\u7a33\u6001\u8499\u7279\u5361\u6d1b\u6a21\u62df\u53d1\u73b0\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f1a\u51fa\u73b0\u7a33\u6001\u53cd\u5e94\u72b6\u6001\uff0c\u4e14\u6269\u6563\u4fc3\u8fdb\u4e86\u6d3b\u6027\u76f8\u7684\u51fa\u73b0\u3002", "motivation": "\u63a2\u7d22\u5728\u5141\u8bb8CO\u548cN\u539f\u5b50\u4ea4\u6362\u6269\u6563\u7684\u60c5\u51b5\u4e0b\uff0c\u50ac\u5316\u8868\u9762\u6a21\u578b\u7684\u76f8\u56fe\u53d8\u5316\uff0c\u7279\u522b\u662f\u6269\u6563\u5bf9\u53cd\u5e94\u6d3b\u6027\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u7a33\u6001\u8499\u7279\u5361\u6d1b\u6a21\u62df\u65b9\u6cd5\uff0c\u5728\u65b9\u5f62\u548c\u516d\u8fb9\u5f62\u6676\u683c\u4e0a\u8fdb\u884c\u4e8640\u4e07\u6b21\u6a21\u62df\uff0c\u5206\u6790\u4e0d\u540c\u4e00\u6c27\u5316\u6c2e\u89e3\u79bb\u901f\u7387\u548c\u4ea4\u6362\u6269\u6563\u901f\u7387\u4e0b\u7684\u7cfb\u7edf\u884c\u4e3a\u3002", "result": "\u5728\u65b9\u5f62\u6676\u683c\u4e0a\uff0c\u7279\u5b9ar_NO\u548cx\u503c\u4e0b\u51fa\u73b0\u7a33\u6001\u53cd\u5e94\u72b6\u6001\uff1b\u5728\u516d\u8fb9\u5f62\u6676\u683c\u4e0a\uff0c\u6269\u6563\u4f7f\u6d3b\u6027\u76f8\u5728\u66f4\u4f4e\u7684r_NO\u503c\u4e0b\u51fa\u73b0\uff1b\u7cfb\u7edf\u5b58\u5728\u8fde\u7eed\u548c\u4e0d\u8fde\u7eed\u76f8\u53d8\uff0c\u4f46r_NO=1\u65f6\u8fde\u7eed\u76f8\u53d8\u6d88\u5931\u3002", "conclusion": "\u6269\u6563\u8fc7\u7a0b\u663e\u8457\u5f71\u54cd\u50ac\u5316\u8868\u9762\u6a21\u578b\u7684\u76f8\u884c\u4e3a\uff0c\u4fc3\u8fdb\u4e86\u6d3b\u6027\u76f8\u7684\u5f62\u6210\uff0c\u5e76\u6539\u53d8\u4e86\u76f8\u53d8\u7279\u6027\u3002"}}
{"id": "2511.17924", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17924", "abs": "https://arxiv.org/abs/2511.17924", "authors": ["Sayantan Ganguly", "Shion Samadder Chaudhury"], "title": "Computational Quantum Anamorphic Encryption and Quantum Anamorphic Secret-Sharing", "comment": null, "summary": "The concept of anamorphic encryption, first formally introduced by Persiano et al. in their influential 2022 paper titled ``Anamorphic Encryption: Private Communication Against a Dictator,'' enables embedding covert messages within ciphertexts. One of the key distinctions between a ciphertext embedding a covert message and an original ciphertext, compared to an anamorphic ciphertext, lies in the indistinguishability between the original ciphertext and the anamorphic ciphertext. This encryption procedure has been defined based on a public-key cryptosystem. Initially, we present a quantum analogue of the classical anamorphic encryption definition that is based on public-key encryption. Additionally, we introduce a definition of quantum anamorphic encryption that relies on symmetric key encryption. Furthermore, we provide a detailed generalized construction of quantum anamorphic symmetric key encryption within a general framework, which involves taking any two quantum density matrices of any different dimensions and constructing a single quantum density matrix, which is the quantum anamorphic ciphertext containing ciphertexts of both of them. Subsequently, we introduce a definition of computational anamorphic secret-sharing and extend the work of \u00c7akan et al. on computational quantum secret-sharing to computational quantum anamorphic secret-sharing, specifically addressing scenarios with multiple messages, multiple keys, and a single share function. This proposed secret-sharing scheme demonstrates impeccable security measures against quantum adversaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u91cf\u5b50\u53d8\u5f62\u52a0\u5bc6\u7684\u5b9a\u4e49\u548c\u6784\u9020\uff0c\u5305\u62ec\u57fa\u4e8e\u516c\u94a5\u52a0\u5bc6\u548c\u5bf9\u79f0\u5bc6\u94a5\u52a0\u5bc6\u7684\u91cf\u5b50\u53d8\u5f62\u52a0\u5bc6\u5b9a\u4e49\uff0c\u5e76\u6269\u5c55\u4e86\u8ba1\u7b97\u91cf\u5b50\u79d8\u5bc6\u5171\u4eab\u5230\u8ba1\u7b97\u91cf\u5b50\u53d8\u5f62\u79d8\u5bc6\u5171\u4eab\uff0c\u652f\u6301\u591a\u6d88\u606f\u3001\u591a\u5bc6\u94a5\u548c\u5355\u4e00\u5171\u4eab\u51fd\u6570\u3002", "motivation": "\u52a8\u673a\u662f\u6269\u5c55\u7ecf\u5178\u53d8\u5f62\u52a0\u5bc6\u6982\u5ff5\u5230\u91cf\u5b50\u9886\u57df\uff0c\u89e3\u51b3\u5728\u91cf\u5b50\u8ba1\u7b97\u73af\u5883\u4e0b\u5b89\u5168\u901a\u4fe1\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u5d4c\u5165\u9690\u853d\u6d88\u606f\u7684\u80fd\u529b\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u63d0\u51fa\u57fa\u4e8e\u516c\u94a5\u52a0\u5bc6\u548c\u5bf9\u79f0\u5bc6\u94a5\u52a0\u5bc6\u7684\u91cf\u5b50\u53d8\u5f62\u52a0\u5bc6\u5b9a\u4e49\uff1b2\uff09\u5728\u901a\u7528\u6846\u67b6\u4e0b\u8be6\u7ec6\u6784\u9020\u91cf\u5b50\u53d8\u5f62\u5bf9\u79f0\u5bc6\u94a5\u52a0\u5bc6\uff1b3\uff09\u6269\u5c55\u8ba1\u7b97\u91cf\u5b50\u79d8\u5bc6\u5171\u4eab\u5230\u8ba1\u7b97\u91cf\u5b50\u53d8\u5f62\u79d8\u5bc6\u5171\u4eab\u3002", "result": "\u7ed3\u679c\u5c55\u793a\u4e86\u91cf\u5b50\u53d8\u5f62\u52a0\u5bc6\u7684\u53ef\u884c\u6027\uff0c\u6784\u9020\u4e86\u5305\u542b\u4e24\u4e2a\u4e0d\u540c\u7ef4\u5ea6\u91cf\u5b50\u5bc6\u5ea6\u77e9\u9635\u7684\u5355\u4e00\u91cf\u5b50\u53d8\u5f62\u5bc6\u6587\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u79d8\u5bc6\u5171\u4eab\u65b9\u6848\u5bf9\u91cf\u5b50\u654c\u624b\u5177\u6709\u5b8c\u5584\u7684\u5b89\u5168\u6027\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6210\u529f\u5c06\u53d8\u5f62\u52a0\u5bc6\u6982\u5ff5\u6269\u5c55\u5230\u91cf\u5b50\u9886\u57df\uff0c\u5efa\u7acb\u4e86\u91cf\u5b50\u53d8\u5f62\u52a0\u5bc6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u91cf\u5b50\u5b89\u5168\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2511.17937", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17937", "abs": "https://arxiv.org/abs/2511.17937", "authors": ["Kartik Garg", "Shourya Mishra", "Kartikeya Sinha", "Ojaswi Pratap Singh", "Ayush Chopra", "Kanishk Rai", "Ammar Sheikh", "Raghav Maheshwari", "Aman Chadha", "Vinija Jain", "Amitava Das"], "title": "Alignment Faking - the Train -> Deploy Asymmetry: Through a Game-Theoretic Lens with Bayesian-Stackelberg Equilibria", "comment": null, "summary": "Alignment faking is a form of strategic deception in AI in which models selectively comply with training objectives when they infer that they are in training, while preserving different behavior outside training. The phenomenon was first documented for Claude 3 Opus and later examined across additional large language models. In these setups, the word \"training\" refers to simulated training via prompts without parameter updates, so the observed effects are context conditioned shifts in behavior rather than preference learning. We study the phenomenon using an evaluation framework that compares preference optimization methods (BCO, DPO, KTO, and GRPO) across 15 models from four model families, measured along three axes: safety, harmlessness, and helpfulness. Our goal is to identify what causes alignment faking and when it occurs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86AI\u4e2d\u7684\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\u2014\u2014\u6a21\u578b\u5728\u63a8\u65ad\u5904\u4e8e\u8bad\u7ec3\u72b6\u6001\u65f6\u9009\u62e9\u6027\u5730\u9075\u5b88\u8bad\u7ec3\u76ee\u6807\uff0c\u4f46\u5728\u8bad\u7ec3\u5916\u4fdd\u6301\u4e0d\u540c\u884c\u4e3a\u3002\u901a\u8fc7\u6bd4\u8f8315\u4e2a\u6a21\u578b\u76844\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u4ece\u5b89\u5168\u6027\u3001\u65e0\u5bb3\u6027\u548c\u5e2e\u52a9\u6027\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u5bf9\u9f50\u4f2a\u88c5\u7684\u539f\u56e0\u548c\u53d1\u751f\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u5bf9\u9f50\u4f2a\u88c5\u73b0\u8c61\u7684\u539f\u56e0\u548c\u53d1\u751f\u6761\u4ef6\uff0c\u8fd9\u79cd\u73b0\u8c61\u6d89\u53ca\u6a21\u578b\u5728\u8bad\u7ec3\u73af\u5883\u4e2d\u7b56\u7565\u6027\u6b3a\u9a97\uff0c\u9009\u62e9\u6027\u5730\u9075\u5b88\u76ee\u6807\u3002", "method": "\u4f7f\u7528\u8bc4\u4f30\u6846\u67b6\u6bd4\u8f83BCO\u3001DPO\u3001KTO\u548cGRPO\u56db\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u572815\u4e2a\u6a21\u578b\u4e0a\u7684\u8868\u73b0\uff0c\u4ece\u5b89\u5168\u6027\u3001\u65e0\u5bb3\u6027\u548c\u5e2e\u52a9\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u6d4b\u91cf\u3002", "result": "\u89c2\u5bdf\u5230\u6a21\u578b\u5728\u6a21\u62df\u8bad\u7ec3\u73af\u5883\u4e2d\u4f1a\u51fa\u73b0\u884c\u4e3a\u8f6c\u53d8\uff0c\u4f46\u8fd9\u4e0d\u662f\u53c2\u6570\u66f4\u65b0\u7684\u504f\u597d\u5b66\u4e60\uff0c\u800c\u662f\u57fa\u4e8e\u4e0a\u4e0b\u6587\u6761\u4ef6\u7684\u884c\u4e3a\u53d8\u5316\u3002", "conclusion": "\u5bf9\u9f50\u4f2a\u88c5\u662fAI\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u7b56\u7565\u6027\u6b3a\u9a97\u73b0\u8c61\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u6210\u56e0\u548c\u53d1\u751f\u673a\u5236\u3002"}}
{"id": "2511.17587", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17587", "abs": "https://arxiv.org/abs/2511.17587", "authors": ["Yuxuan Hu", "Jian Chen", "Yuhao Wang", "Zixuan Li", "Jing Xiong", "Pengyue Jia", "Wei Wang", "Chengming Li", "Xiangyu Zhao"], "title": "Emotion and Intention Guided Multi-Modal Learning for Sticker Response Selection", "comment": null, "summary": "Stickers are widely used in online communication to convey emotions and implicit intentions. The Sticker Response Selection (SRS) task aims to select the most contextually appropriate sticker based on the dialogue. However, existing methods typically rely on semantic matching and model emotional and intentional cues separately, which can lead to mismatches when emotions and intentions are misaligned. To address this issue, we propose Emotion and Intention Guided Multi-Modal Learning (EIGML). This framework is the first to jointly model emotion and intention, effectively reducing the bias caused by isolated modeling and significantly improving selection accuracy. Specifically, we introduce Dual-Level Contrastive Framework to perform both intra-modality and inter-modality alignment, ensuring consistent representation of emotional and intentional features within and across modalities. In addition, we design an Intention-Emotion Guided Multi-Modal Fusion module that integrates emotional and intentional information progressively through three components: Emotion-Guided Intention Knowledge Selection, Intention-Emotion Guided Attention Fusion, and Similarity-Adjusted Matching Mechanism. This design injects rich, effective information into the model and enables a deeper understanding of the dialogue, ultimately enhancing sticker selection performance. Experimental results on two public SRS datasets show that EIGML consistently outperforms state-of-the-art baselines, achieving higher accuracy and a better understanding of emotional and intentional features. Code is provided in the supplementary materials.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEIGML\u6846\u67b6\uff0c\u9996\u6b21\u8054\u5408\u5efa\u6a21\u60c5\u611f\u548c\u610f\u56fe\uff0c\u901a\u8fc7\u53cc\u5c42\u6b21\u5bf9\u6bd4\u6846\u67b6\u548c\u591a\u6a21\u6001\u878d\u5408\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u8d34\u7eb8\u54cd\u5e94\u9009\u62e9\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u8d34\u7eb8\u54cd\u5e94\u9009\u62e9\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u8bed\u4e49\u5339\u914d\uff0c\u5e76\u5c06\u60c5\u611f\u548c\u610f\u56fe\u7ebf\u7d22\u5206\u5f00\u5efa\u6a21\uff0c\u5f53\u60c5\u611f\u548c\u610f\u56fe\u4e0d\u4e00\u81f4\u65f6\u5bb9\u6613\u5bfc\u81f4\u5339\u914d\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u60c5\u611f\u548c\u610f\u56fe\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u62ec\u53cc\u5c42\u6b21\u5bf9\u6bd4\u6846\u67b6\uff08\u6a21\u6001\u5185\u548c\u6a21\u6001\u95f4\u5bf9\u9f50\uff09\u548c\u610f\u56fe-\u60c5\u611f\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u878d\u5408\u6a21\u5757\uff08\u60c5\u611f\u5f15\u5bfc\u610f\u56fe\u77e5\u8bc6\u9009\u62e9\u3001\u610f\u56fe-\u60c5\u611f\u5f15\u5bfc\u6ce8\u610f\u529b\u878d\u5408\u3001\u76f8\u4f3c\u5ea6\u8c03\u6574\u5339\u914d\u673a\u5236\uff09\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00SRS\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cEIGML\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548c\u66f4\u597d\u7684\u60c5\u611f\u610f\u56fe\u7279\u5f81\u7406\u89e3\u3002", "conclusion": "EIGML\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u60c5\u611f\u548c\u610f\u56fe\uff0c\u6709\u6548\u51cf\u5c11\u5b64\u7acb\u5efa\u6a21\u5e26\u6765\u7684\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d34\u7eb8\u9009\u62e9\u6027\u80fd\u3002"}}
{"id": "2511.18212", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.18212", "abs": "https://arxiv.org/abs/2511.18212", "authors": ["Walter Rieck", "Anton Frisk Kockum", "Guangze Chen"], "title": "Doublon bound states in the continuum through giant atoms", "comment": "8+4 pages, 3+1 figures, source codes are available from https://github.com/WalterRieck/GiantAtoms", "summary": "Bound states in the continuum (BICs) are spatially localized modes embedded in the spectrum of extended states, typically stabilized by symmetry or interference. While extensively studied in single-particle and linear systems, the many-body regime of BICs remains largely unexplored. Here, we demonstrate that giant atoms, quantum emitters coupled nonlocally to structured waveguides, can host robust doublon BICs, i.e., two-photon bound states stabilized by destructive interference and interactions. We first analyze a driven two-photon emission process and show how doublon BICs arise and mediate decoherence-free interaction between distant atoms. We then demonstrate that these many-body BICs also emerge under natural, undriven dynamics via a virtual two-photon emission process in three-level giant atoms. Our results reveal an interference-based mechanism for stabilizing many-body localization in open quantum systems, with potential applications in quantum simulation, non-ergodic dynamics, and protected quantum information processing.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8fde\u7eed\u8c31\u4e2d\u7684\u675f\u7f1a\u6001\uff08BICs\uff09\u5728\u5de8\u539f\u5b50\u7cfb\u7edf\u4e2d\u7684\u591a\u4f53\u884c\u4e3a\uff0c\u5c55\u793a\u4e86\u5de8\u539f\u5b50\u53ef\u4ee5\u627f\u8f7d\u7a33\u5b9a\u7684\u53cc\u5149\u5b50BICs\uff0c\u8fd9\u4e9b\u6001\u901a\u8fc7\u7834\u574f\u6027\u5e72\u6d89\u548c\u76f8\u4e92\u4f5c\u7528\u7a33\u5b9a\uff0c\u5e76\u5728\u9a71\u52a8\u548c\u81ea\u7136\u52a8\u529b\u5b66\u4e2d\u90fd\u80fd\u51fa\u73b0\u3002", "motivation": "\u867d\u7136\u8fde\u7eed\u8c31\u4e2d\u7684\u675f\u7f1a\u6001\u5728\u5355\u7c92\u5b50\u548c\u7ebf\u6027\u7cfb\u7edf\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5728\u591a\u4f53\u4f53\u7cfb\u4e2d\u7684\u884c\u4e3a\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u5de8\u539f\u5b50\u7cfb\u7edf\u4e2d\u591a\u4f53BICs\u7684\u7a33\u5b9a\u673a\u5236\u53ca\u5176\u5728\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u9996\u5148\u5206\u6790\u9a71\u52a8\u53cc\u5149\u5b50\u53d1\u5c04\u8fc7\u7a0b\uff0c\u7814\u7a76\u53cc\u5149\u5b50BICs\u5982\u4f55\u4ea7\u751f\u5e76\u4ecb\u5bfc\u8fdc\u8ddd\u79bb\u539f\u5b50\u95f4\u7684\u65e0\u9000\u76f8\u5e72\u76f8\u4e92\u4f5c\u7528\uff1b\u7136\u540e\u8bc1\u660e\u8fd9\u4e9b\u591a\u4f53BICs\u5728\u4e09\u7ea7\u5de8\u539f\u5b50\u7684\u81ea\u7136\u3001\u975e\u9a71\u52a8\u52a8\u529b\u5b66\u4e2d\u901a\u8fc7\u865a\u62df\u53cc\u5149\u5b50\u53d1\u5c04\u8fc7\u7a0b\u4e5f\u80fd\u51fa\u73b0\u3002", "result": "\u53d1\u73b0\u5de8\u539f\u5b50\u53ef\u4ee5\u627f\u8f7d\u7a33\u5b9a\u7684\u53cc\u5149\u5b50BICs\uff0c\u8fd9\u4e9b\u6001\u901a\u8fc7\u7834\u574f\u6027\u5e72\u6d89\u548c\u76f8\u4e92\u4f5c\u7528\u7a33\u5b9a\uff0c\u80fd\u591f\u5728\u9a71\u52a8\u548c\u81ea\u7136\u52a8\u529b\u5b66\u4e2d\u4ea7\u751f\uff0c\u5e76\u4ecb\u5bfc\u8fdc\u8ddd\u79bb\u539f\u5b50\u95f4\u7684\u65e0\u9000\u76f8\u5e72\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e72\u6d89\u7684\u673a\u5236\uff0c\u7528\u4e8e\u7a33\u5b9a\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u591a\u4f53\u5c40\u57df\u5316\uff0c\u5728\u91cf\u5b50\u6a21\u62df\u3001\u975e\u904d\u5386\u52a8\u529b\u5b66\u548c\u53d7\u4fdd\u62a4\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u65b9\u9762\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19110", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19110", "abs": "https://arxiv.org/abs/2511.19110", "authors": ["Jiaozi Wang", "Sourav Nandy", "Markus Kraft", "Toma\u017e Prosen", "Robin Steinigeweg"], "title": "Fate of diffusion under integrability breaking of classical integrable magnets", "comment": "8 pages, 7 figures", "summary": "Diffusive transport is a ubiquitous phenomenon, yet the microscopic origin of diffusion in interacting physical systems remains a challenging question, irrespective of whether quantum effects are dominant or not. In this work, we study infinite temperature spin diffusion in a classical integrable, space-time discrete version of anisotropic Landau-Lifshitz magnet in the easy-axis regime, subjected to integrability-breaking perturbations. Our numerical results based on large-scale simulations reveal i) a sharp change in the spin diffusion constant as a function of perturbation strength in the thermodynamic limit and ii) a crossover from non-Gaussian to Gaussian statistics of magnetization transfer reflected in higher order cumulants under integrability breaking. Both our observations hint to the presence of non-trivial diffusion mechanism inherent to integrable systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u503c\u6a21\u62df\uff0c\u5728\u7ecf\u5178\u53ef\u79ef\u7684\u5404\u5411\u5f02\u6027Landau-Lifshitz\u78c1\u4f53\u7684\u6613\u8f74\u533a\u57df\u4e2d\uff0c\u7814\u7a76\u4e86\u65e0\u9650\u6e29\u5ea6\u4e0b\u7684\u81ea\u65cb\u6269\u6563\u73b0\u8c61\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u70ed\u529b\u5b66\u6781\u9650\u4e0b\uff0c\u81ea\u65cb\u6269\u6563\u5e38\u6570\u968f\u5fae\u6270\u5f3a\u5ea6\u53d1\u751f\u6025\u5267\u53d8\u5316\uff0c\u5e76\u4e14\u78c1\u5316\u8f6c\u79fb\u7684\u9ad8\u9636\u7d2f\u79ef\u91cf\u663e\u793a\u51fa\u4ece\u975e\u9ad8\u65af\u5230\u9ad8\u65af\u7edf\u8ba1\u7684\u4ea4\u53c9\u884c\u4e3a\u3002", "motivation": "\u6269\u6563\u8f93\u8fd0\u662f\u666e\u904d\u5b58\u5728\u7684\u7269\u7406\u73b0\u8c61\uff0c\u4f46\u76f8\u4e92\u4f5c\u7528\u7269\u7406\u7cfb\u7edf\u4e2d\u6269\u6563\u7684\u5fae\u89c2\u8d77\u6e90\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u65e0\u8bba\u91cf\u5b50\u6548\u5e94\u662f\u5426\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u53ef\u79ef\u7cfb\u7edf\u4e2d\u56fa\u6709\u7684\u975e\u5e73\u51e1\u6269\u6563\u673a\u5236\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5927\u89c4\u6a21\u6570\u503c\u6a21\u62df\u65b9\u6cd5\uff0c\u5206\u6790\u7ecf\u5178\u53ef\u79ef\u3001\u65f6\u7a7a\u79bb\u6563\u7684\u5404\u5411\u5f02\u6027Landau-Lifshitz\u78c1\u4f53\u5728\u6613\u8f74\u533a\u57df\u4e2d\u7684\u884c\u4e3a\uff0c\u5e76\u65bd\u52a0\u53ef\u79ef\u6027\u7834\u574f\u5fae\u6270\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff1ai) \u5728\u70ed\u529b\u5b66\u6781\u9650\u4e0b\uff0c\u81ea\u65cb\u6269\u6563\u5e38\u6570\u968f\u5fae\u6270\u5f3a\u5ea6\u53d1\u751f\u6025\u5267\u53d8\u5316\uff1bii) \u5728\u53ef\u79ef\u6027\u7834\u574f\u4e0b\uff0c\u78c1\u5316\u8f6c\u79fb\u7684\u9ad8\u9636\u7d2f\u79ef\u91cf\u663e\u793a\u51fa\u4ece\u975e\u9ad8\u65af\u5230\u9ad8\u65af\u7edf\u8ba1\u7684\u4ea4\u53c9\u884c\u4e3a\u3002", "conclusion": "\u8fd9\u4e9b\u89c2\u5bdf\u7ed3\u679c\u8868\u660e\u53ef\u79ef\u7cfb\u7edf\u4e2d\u5b58\u5728\u56fa\u6709\u7684\u975e\u5e73\u51e1\u6269\u6563\u673a\u5236\uff0c\u4e3a\u7406\u89e3\u76f8\u4e92\u4f5c\u7528\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u6269\u6563\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2511.17589", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17589", "abs": "https://arxiv.org/abs/2511.17589", "authors": ["S\u00f6ren Dr\u00e9ano", "Derek Molloy", "Noel Murphy"], "title": "Llamazip: Leveraging LLaMA for Lossless Text Compression and Training Dataset Detection", "comment": null, "summary": "This work introduces Llamazip, a novel lossless text compression algorithm based on the predictive capabilities of the LLaMA3 language model. Llamazip achieves significant data reduction by only storing tokens that the model fails to predict, optimizing storage efficiency without compromising data integrity. Key factors affecting its performance, including quantization and context window size, are analyzed, revealing their impact on compression ratios and computational requirements. Beyond compression, Llamazip demonstrates the potential to identify whether a document was part of the training dataset of a language model. This capability addresses critical concerns about data provenance, intellectual property, and transparency in language model training.", "AI": {"tldr": "Llamazip\u662f\u4e00\u79cd\u57fa\u4e8eLLaMA3\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u7684\u65e0\u635f\u6587\u672c\u538b\u7f29\u7b97\u6cd5\uff0c\u901a\u8fc7\u4ec5\u5b58\u50a8\u6a21\u578b\u65e0\u6cd5\u9884\u6d4b\u7684token\u6765\u5b9e\u73b0\u663e\u8457\u6570\u636e\u538b\u7f29\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u5b8c\u6574\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u5229\u7528\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u7684\u9ad8\u6548\u65e0\u635f\u6587\u672c\u538b\u7f29\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u8bc6\u522b\u6587\u6863\u662f\u5426\u5c5e\u4e8e\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u96c6\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u6765\u6e90\u3001\u77e5\u8bc6\u4ea7\u6743\u548c\u900f\u660e\u5ea6\u95ee\u9898\u3002", "method": "\u57fa\u4e8eLLaMA3\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4ec5\u5b58\u50a8\u6a21\u578b\u65e0\u6cd5\u51c6\u786e\u9884\u6d4b\u7684token\uff0c\u5206\u6790\u91cf\u5316\u7a0b\u5ea6\u548c\u4e0a\u4e0b\u6587\u7a97\u53e3\u5927\u5c0f\u7b49\u5173\u952e\u56e0\u7d20\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6570\u636e\u538b\u7f29\u6548\u679c\uff0c\u540c\u65f6\u80fd\u591f\u8bc6\u522b\u6587\u6863\u662f\u5426\u5c5e\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u4e3a\u6570\u636e\u6eaf\u6e90\u548c\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "Llamazip\u4e0d\u4ec5\u5c55\u793a\u4e86\u9ad8\u6548\u7684\u65e0\u635f\u6587\u672c\u538b\u7f29\u80fd\u529b\uff0c\u8fd8\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u6570\u636e\u6eaf\u6e90\u548c\u900f\u660e\u5ea6\u65b9\u9762\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u5173\u952e\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.19288", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19288", "abs": "https://arxiv.org/abs/2511.19288", "authors": ["Eduardo J. Aguilar", "Valmir C. Barbosa", "Raul Donangelo", "Welles A. M. Morgado", "Sergio R. Souza"], "title": "Tilings of a bounded region of the plane by maximal one-dimensional tiles", "comment": "7 pages, 10 figures", "summary": "We study the tiling of a two-dimensional region of the plane by $K$-cell one-dimensional tiles, or $K$-mers. Unlike previous studies, which typically allowed for one single value of $K$ or sometimes a small assortment of fixed values, here a tiling may concomitantly employ $K$-mers comprising any number $K$ of cells, provided a maximality constraint is satisfied. In essence, this constraint requires each of the $K$-mers in use to be as lengthy as possible, given its surroundings in the resulting tiling. Maximality aims to limit the variety of possible tilings while allowing for interesting behavior in terms of the statistical physical observables of interest. In fact, by introducing an energy function based on cell contacts and parameterizing it appropriately, we have been able to observe relatively unexpected behavior, including the suggestion of phase transitions as the system's temperature evolves.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e8c\u7ef4\u5e73\u9762\u533a\u57df\u4f7f\u7528K-cell\u4e00\u7ef4\u74e6\u7247\uff08K-mers\uff09\u7684\u5e73\u94fa\u95ee\u9898\uff0c\u4e0e\u4ee5\u5f80\u7814\u7a76\u4e0d\u540c\uff0c\u5141\u8bb8\u540c\u65f6\u4f7f\u7528\u4efb\u610fK\u503c\u7684\u74e6\u7247\uff0c\u4f46\u9700\u6ee1\u8db3\u6781\u5927\u6027\u7ea6\u675f\u6761\u4ef6\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u901a\u5e38\u53ea\u5141\u8bb8\u5355\u4e00K\u503c\u6216\u5c11\u91cf\u56fa\u5b9aK\u503c\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5141\u8bb8\u4efb\u610fK\u503c\u74e6\u7247\u540c\u65f6\u4f7f\u7528\u7684\u5e73\u94fa\u95ee\u9898\uff0c\u901a\u8fc7\u6781\u5927\u6027\u7ea6\u675f\u9650\u5236\u53ef\u80fd\u7684\u5e73\u94fa\u79cd\u7c7b\uff0c\u540c\u65f6\u89c2\u5bdf\u7edf\u8ba1\u7269\u7406\u53ef\u89c2\u6d4b\u91cf\u4e2d\u7684\u6709\u8da3\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5355\u5143\u63a5\u89e6\u7684\u80fd\u91cf\u51fd\u6570\uff0c\u5e76\u9002\u5f53\u53c2\u6570\u5316\uff0c\u5728\u6ee1\u8db3\u6781\u5927\u6027\u7ea6\u675f\u7684\u6761\u4ef6\u4e0b\u7814\u7a76\u7cfb\u7edf\u6e29\u5ea6\u53d8\u5316\u65f6\u7684\u76f8\u53d8\u884c\u4e3a\u3002", "result": "\u89c2\u5bdf\u5230\u76f8\u5bf9\u610f\u5916\u7684\u884c\u4e3a\uff0c\u5305\u62ec\u968f\u7740\u7cfb\u7edf\u6e29\u5ea6\u6f14\u5316\u51fa\u73b0\u76f8\u53d8\u8ff9\u8c61\u3002", "conclusion": "\u901a\u8fc7\u6781\u5927\u6027\u7ea6\u675f\u548c\u80fd\u91cf\u51fd\u6570\u53c2\u6570\u5316\uff0c\u5728\u5141\u8bb8\u4efb\u610fK\u503c\u74e6\u7247\u540c\u65f6\u4f7f\u7528\u7684\u5e73\u94fa\u7cfb\u7edf\u4e2d\u89c2\u5bdf\u5230\u4e86\u76f8\u53d8\u7b49\u6709\u8da3\u7269\u7406\u73b0\u8c61\u3002"}}
{"id": "2511.17960", "categories": ["quant-ph", "physics.atom-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.17960", "abs": "https://arxiv.org/abs/2511.17960", "authors": ["Tushti Patel", "V. S. Prasannaa"], "title": "The Harrow-Hassidim-Lloyd algorithm with qutrits", "comment": null, "summary": "We extend the Harrow-Hassidim-Lloyd (HHL) algorithm, which is well-studied in the qubit framework, to its qutrit counterpart (which we call qutrit HHL, as opposed to qubit HHL, which is HHL using qubits). We design the circuit for the algorithm and develop a program for its implementation. We test HHL with qutrits for simple matrices and verify the results against the expected outcomes. We apply the algorithm to quantum chemistry, and in particular, to the potential energy curve calculations of the model problem of the hydrogen molecule in the split valence basis. We compare the number of qudits and the number of gates required between qubit and qutrit HHL implementations. In general, we find that for a fixed precision, the qutrit HHL circuit requires fewer number of qudits and comparable number of two-qudit gates than its qubit counterpart.", "AI": {"tldr": "\u5c06Harrow-Hassidim-Lloyd (HHL)\u7b97\u6cd5\u4ece\u91cf\u5b50\u6bd4\u7279\u6269\u5c55\u5230\u91cf\u5b50\u4e09\u6001\uff08qutrit\uff09\uff0c\u8bbe\u8ba1\u7535\u8def\u5e76\u5b9e\u73b0\u7a0b\u5e8f\uff0c\u5e94\u7528\u4e8e\u6c22\u5206\u5b50\u52bf\u80fd\u66f2\u7ebf\u8ba1\u7b97\uff0c\u6bd4\u8f83\u91cf\u5b50\u6bd4\u7279\u548c\u91cf\u5b50\u4e09\u6001\u5b9e\u73b0\u7684\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u4e09\u6001\uff08qutrit\uff09\u5728HHL\u7b97\u6cd5\u4e2d\u7684\u4f18\u52bf\uff0c\u63a2\u7d22\u5728\u91cf\u5b50\u5316\u5b66\u8ba1\u7b97\u4e2d\u51cf\u5c11\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u548c\u95e8\u64cd\u4f5c\u7684\u53ef\u80fd\u6027\u3002", "method": "\u8bbe\u8ba1\u91cf\u5b50\u4e09\u6001HHL\u7b97\u6cd5\u7684\u7535\u8def\u7ed3\u6784\uff0c\u5f00\u53d1\u5b9e\u73b0\u7a0b\u5e8f\uff0c\u6d4b\u8bd5\u7b80\u5355\u77e9\u9635\u5e76\u9a8c\u8bc1\u7ed3\u679c\uff0c\u5e94\u7528\u4e8e\u6c22\u5206\u5b50\u52bf\u80fd\u66f2\u7ebf\u8ba1\u7b97\u3002", "result": "\u91cf\u5b50\u4e09\u6001HHL\u7535\u8def\u5728\u56fa\u5b9a\u7cbe\u5ea6\u4e0b\u9700\u8981\u66f4\u5c11\u7684\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\uff0c\u4e14\u4e24\u91cf\u5b50\u95e8\u6570\u91cf\u4e0e\u91cf\u5b50\u6bd4\u7279\u7248\u672c\u76f8\u5f53\u3002", "conclusion": "\u91cf\u5b50\u4e09\u6001HHL\u7b97\u6cd5\u5728\u8d44\u6e90\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u91cf\u5b50\u6bd4\u7279\u5b9e\u73b0\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u5728\u91cf\u5b50\u5316\u5b66\u7b49\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2511.17590", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17590", "abs": "https://arxiv.org/abs/2511.17590", "authors": ["Ke Yu", "Shigeru Ishikura", "Yukari Usukura", "Yuki Shigoku", "Teruaki Hayashi"], "title": "SHAP Distance: An Explainability-Aware Metric for Evaluating the Semantic Fidelity of Synthetic Tabular Data", "comment": "IEEE Bigdata", "summary": "Synthetic tabular data, which are widely used in domains such as healthcare, enterprise operations, and customer analytics, are increasingly evaluated to ensure that they preserve both privacy and utility. While existing evaluation practices typically focus on distributional similarity (e.g., the Kullback-Leibler divergence) or predictive performance (e.g., Train-on-Synthetic-Test-on-Real (TSTR) accuracy), these approaches fail to assess semantic fidelity, that is, whether models trained on synthetic data follow reasoning patterns consistent with those trained on real data. To address this gap, we introduce the SHapley Additive exPlanations (SHAP) Distance, a novel explainability-aware metric that is defined as the cosine distance between the global SHAP attribution vectors derived from classifiers trained on real versus synthetic datasets. By analyzing datasets that span clinical health records with physiological features, enterprise invoice transactions with heterogeneous scales, and telecom churn logs with mixed categorical-numerical attributes, we demonstrate that the SHAP Distance reliably identifies semantic discrepancies that are overlooked by standard statistical and predictive measures. In particular, our results show that the SHAP Distance captures feature importance shifts and underrepresented tail effects that the Kullback-Leibler divergence and Train-on-Synthetic-Test-on-Real accuracy fail to detect. This study positions the SHAP Distance as a practical and discriminative tool for auditing the semantic fidelity of synthetic tabular data, and offers practical guidelines for integrating attribution-based evaluation into future benchmarking pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSHAP\u8ddd\u79bb\uff0c\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91ca\u6027\u7684\u65b0\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u5408\u6210\u8868\u683c\u6570\u636e\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u5f25\u8865\u4e86\u4f20\u7edf\u7edf\u8ba1\u548c\u9884\u6d4b\u6307\u6807\u5728\u8bed\u4e49\u4e00\u81f4\u6027\u8bc4\u4f30\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u5408\u6210\u6570\u636e\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5206\u5e03\u76f8\u4f3c\u6027\u548c\u9884\u6d4b\u6027\u80fd\uff0c\u4f46\u65e0\u6cd5\u8bc4\u4f30\u6a21\u578b\u5728\u5408\u6210\u6570\u636e\u4e0a\u662f\u5426\u9075\u5faa\u4e0e\u771f\u5b9e\u6570\u636e\u4e00\u81f4\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u5373\u8bed\u4e49\u4fdd\u771f\u5ea6\u95ee\u9898\u3002", "method": "\u5f15\u5165SHAP\u8ddd\u79bb\uff0c\u5b9a\u4e49\u4e3a\u4ece\u771f\u5b9e\u6570\u636e\u4e0e\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u4e2d\u5bfc\u51fa\u7684\u5168\u5c40SHAP\u5f52\u56e0\u5411\u91cf\u4e4b\u95f4\u7684\u4f59\u5f26\u8ddd\u79bb\uff0c\u901a\u8fc7\u591a\u4e2a\u9886\u57df\u6570\u636e\u96c6\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "SHAP\u8ddd\u79bb\u80fd\u591f\u53ef\u9760\u5730\u8bc6\u522b\u4f20\u7edf\u7edf\u8ba1\u548c\u9884\u6d4b\u6307\u6807\u5ffd\u7565\u7684\u8bed\u4e49\u5dee\u5f02\uff0c\u7279\u522b\u662f\u7279\u5f81\u91cd\u8981\u6027\u504f\u79fb\u548c\u5c3e\u90e8\u6548\u5e94\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "conclusion": "SHAP\u8ddd\u79bb\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u5408\u6210\u8868\u683c\u6570\u636e\u8bed\u4e49\u4fdd\u771f\u5ea6\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u5e76\u4e3a\u672a\u6765\u57fa\u51c6\u6d4b\u8bd5\u7ba1\u9053\u96c6\u6210\u57fa\u4e8e\u5f52\u56e0\u7684\u8bc4\u4f30\u63d0\u4f9b\u5b9e\u8df5\u6307\u5357\u3002"}}
{"id": "2511.17976", "categories": ["quant-ph", "cs.IT", "math-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.17976", "abs": "https://arxiv.org/abs/2511.17976", "authors": ["Zixin Huang", "Mark M. Wilde"], "title": "Accelerated optimization of measured relative entropies", "comment": "39 pages", "summary": "The measured relative entropy and measured R\u00e9nyi relative entropy are quantifiers of the distinguishability of two quantum states $\u03c1$ and $\u03c3$. They are defined as the maximum classical relative entropy or R\u00e9nyi relative entropy realizable by performing a measurement on $\u03c1$ and $\u03c3$, and they have interpretations in terms of asymptotic quantum hypothesis testing. Crucially, they can be rewritten in terms of variational formulas involving the optimization of a concave or convex objective function over the set of positive definite operators. In this paper, we establish foundational properties of these objective functions by analyzing their matrix gradients and Hessian superoperators; namely, we prove that these objective functions are $\u03b2$-smooth and $\u03b3$-strongly convex / concave, where $\u03b2$ and $\u03b3$ depend on the max-relative entropies of $\u03c1$ and $\u03c3$. A practical consequence of these properties is that we can conduct Nesterov accelerated projected gradient descent / ascent, a well known classical optimization technique, to calculate the measured relative entropy and measured R\u00e9nyi relative entropy to arbitrary precision. These algorithms are generally more memory efficient than our previous algorithms based on semi-definite optimization [Huang and Wilde, arXiv:2406.19060], and for well conditioned states $\u03c1$ and $\u03c3$, these algorithms are notably faster.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6d4b\u91cf\u76f8\u5bf9\u71b5\u548c\u6d4b\u91cfR\u00e9nyi\u76f8\u5bf9\u71b5\u7684\u4f18\u5316\u76ee\u6807\u51fd\u6570\u7684\u6570\u5b66\u6027\u8d28\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u51fd\u6570\u7684\u03b2-\u5149\u6ed1\u6027\u548c\u03b3-\u5f3a\u51f8/\u51f9\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eNesterov\u52a0\u901f\u6295\u5f71\u68af\u5ea6\u4e0b\u964d/\u4e0a\u5347\u7684\u9ad8\u6548\u8ba1\u7b97\u7b97\u6cd5\u3002", "motivation": "\u6d4b\u91cf\u76f8\u5bf9\u71b5\u548c\u6d4b\u91cfR\u00e9nyi\u76f8\u5bf9\u71b5\u662f\u91cf\u5316\u4e24\u4e2a\u91cf\u5b50\u6001\u53ef\u533a\u5206\u6027\u7684\u91cd\u8981\u6307\u6807\uff0c\u5728\u6e10\u8fd1\u91cf\u5b50\u5047\u8bbe\u68c0\u9a8c\u4e2d\u6709\u91cd\u8981\u5e94\u7528\u3002\u8fd9\u4e9b\u91cf\u53ef\u4ee5\u91cd\u5199\u4e3a\u6d89\u53ca\u6b63\u5b9a\u7b97\u5b50\u96c6\u4e0a\u51f9\u6216\u51f8\u76ee\u6807\u51fd\u6570\u4f18\u5316\u7684\u53d8\u5206\u516c\u5f0f\uff0c\u4f46\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u76ee\u6807\u51fd\u6570\u7684\u77e9\u9635\u68af\u5ea6\u548cHessian\u8d85\u7b97\u5b50\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u51fd\u6570\u7684\u03b2-\u5149\u6ed1\u6027\u548c\u03b3-\u5f3a\u51f8/\u51f9\u6027\uff0c\u5176\u4e2d\u03b2\u548c\u03b3\u4f9d\u8d56\u4e8e\u03c1\u548c\u03c3\u7684\u6700\u5927\u76f8\u5bf9\u71b5\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6027\u8d28\uff0c\u91c7\u7528Nesterov\u52a0\u901f\u6295\u5f71\u68af\u5ea6\u4e0b\u964d/\u4e0a\u5347\u7b97\u6cd5\u6765\u8ba1\u7b97\u6d4b\u91cf\u76f8\u5bf9\u71b5\u3002", "result": "\u5f00\u53d1\u4e86\u66f4\u5185\u5b58\u9ad8\u6548\u7684\u8ba1\u7b97\u7b97\u6cd5\uff0c\u5bf9\u4e8e\u6761\u4ef6\u826f\u597d\u7684\u91cf\u5b50\u6001\u03c1\u548c\u03c3\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u6bd4\u4e4b\u524d\u57fa\u4e8e\u534a\u5b9a\u4f18\u5316\u7684\u7b97\u6cd5\u663e\u8457\u66f4\u5feb\uff0c\u80fd\u591f\u4ee5\u4efb\u610f\u7cbe\u5ea6\u8ba1\u7b97\u6d4b\u91cf\u76f8\u5bf9\u71b5\u548c\u6d4b\u91cfR\u00e9nyi\u76f8\u5bf9\u71b5\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u6d4b\u91cf\u76f8\u5bf9\u71b5\u76ee\u6807\u51fd\u6570\u7684\u57fa\u7840\u6570\u5b66\u6027\u8d28\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u4e3a\u91cf\u5b50\u6001\u53ef\u533a\u5206\u6027\u7684\u8ba1\u7b97\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17990", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17990", "abs": "https://arxiv.org/abs/2511.17990", "authors": ["Mingyu Jeon", "Jaeyoung Suh", "Suwan Cho", "Dohyeon Kim"], "title": "How Far Can LLMs Emulate Human Behavior?: A Strategic Analysis via the Buy-and-Sell Negotiation Game", "comment": null, "summary": "With the rapid advancement of Large Language Models (LLMs), recent studies have drawn attention to their potential for handling not only simple question-answer tasks but also more complex conversational abilities and performing human-like behavioral imitations. In particular, there is considerable interest in how accurately LLMs can reproduce real human emotions and behaviors, as well as whether such reproductions can function effectively in real-world scenarios. However, existing benchmarks focus primarily on knowledge-based assessment and thus fall short of sufficiently reflecting social interactions and strategic dialogue capabilities. To address these limitations, this work proposes a methodology to quantitatively evaluate the human emotional and behavioral imitation and strategic decision-making capabilities of LLMs by employing a Buy and Sell negotiation simulation. Specifically, we assign different personas to multiple LLMs and conduct negotiations between a Buyer and a Seller, comprehensively analyzing outcomes such as win rates, transaction prices, and SHAP values. Our experimental results show that models with higher existing benchmark scores tend to achieve better negotiation performance overall, although some models exhibit diminished performance in scenarios emphasizing emotional or social contexts. Moreover, competitive and cunning traits prove more advantageous for negotiation outcomes than altruistic and cooperative traits, suggesting that the assigned persona can lead to significant variations in negotiation strategies and results. Consequently, this study introduces a new evaluation approach for LLMs' social behavior imitation and dialogue strategies, and demonstrates how negotiation simulations can serve as a meaningful complementary metric to measure real-world interaction capabilities-an aspect often overlooked in existing benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e70\u5356\u8c08\u5224\u6a21\u62df\u7684\u65b9\u6cd5\u6765\u5b9a\u91cf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u7c7b\u60c5\u611f\u884c\u4e3a\u6a21\u4eff\u548c\u6218\u7565\u51b3\u7b56\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u5206\u6570\u8f83\u9ad8\u7684\u6a21\u578b\u5728\u8c08\u5224\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u7ade\u4e89\u6027\u4eba\u683c\u7279\u5f81\u6bd4\u5408\u4f5c\u6027\u7279\u5f81\u66f4\u6709\u5229\u4e8e\u8c08\u5224\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u77e5\u8bc6\u8bc4\u4f30\uff0c\u672a\u80fd\u5145\u5206\u53cd\u6620\u5927\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u4e92\u52a8\u548c\u6218\u7565\u5bf9\u8bdd\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cfLLMs\u5728\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u4e3a\u591a\u4e2aLLMs\u5206\u914d\u4e0d\u540c\u4eba\u683c\u89d2\u8272\uff0c\u5728\u4e70\u5356\u53cc\u65b9\u4e4b\u95f4\u8fdb\u884c\u8c08\u5224\u6a21\u62df\uff0c\u7efc\u5408\u5206\u6790\u80dc\u7387\u3001\u4ea4\u6613\u4ef7\u683c\u548cSHAP\u503c\u7b49\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u6709\u57fa\u51c6\u5206\u6570\u8f83\u9ad8\u7684\u6a21\u578b\u6574\u4f53\u8c08\u5224\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u7ade\u4e89\u6027\u548c\u72e1\u733e\u7279\u8d28\u6bd4\u5229\u4ed6\u548c\u5408\u4f5c\u7279\u8d28\u66f4\u6709\u5229\u4e8e\u8c08\u5224\u7ed3\u679c\uff0c\u5206\u914d\u7684\u4eba\u683c\u89d2\u8272\u4f1a\u5bfc\u81f4\u8c08\u5224\u7b56\u7565\u548c\u7ed3\u679c\u7684\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aLLMs\u7684\u793e\u4f1a\u884c\u4e3a\u6a21\u4eff\u548c\u5bf9\u8bdd\u7b56\u7565\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bc1\u660e\u8c08\u5224\u6a21\u62df\u53ef\u4ee5\u4f5c\u4e3a\u8861\u91cf\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u80fd\u529b\u7684\u6709\u610f\u4e49\u8865\u5145\u6307\u6807\uff0c\u8fd9\u662f\u73b0\u6709\u57fa\u51c6\u7ecf\u5e38\u5ffd\u89c6\u7684\u65b9\u9762\u3002"}}
{"id": "2511.17593", "categories": ["cs.LG", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.17593", "abs": "https://arxiv.org/abs/2511.17593", "authors": ["Saicharan Kolluru"], "title": "Comparative Analysis of Large Language Model Inference Serving Systems: A Performance Study of vLLM and HuggingFace TGI", "comment": "10 pages, benchmarking study of LLM inference systems", "summary": "The deployment of Large Language Models (LLMs) in production environments requires efficient inference serving systems that balance throughput, latency, and resource utilization. This paper presents a comprehensive empirical evaluation of two prominent open-source LLM serving frameworks: vLLM and HuggingFace Text Generation Inference (TGI). We benchmark these systems across multiple dimensions including throughput performance, end-to-end latency, GPU memory utilization, and scalability characteristics using LLaMA-2 models ranging from 7B to 70B parameters. Our experiments reveal that vLLM achieves up to 24x higher throughput than TGI under high-concurrency workloads through its novel PagedAttention mechanism, while TGI demonstrates lower tail latencies for interactive single-user scenarios. We provide detailed performance profiles for different deployment scenarios and offer practical recommendations for system selection based on workload characteristics. Our findings indicate that the choice between these frameworks should be guided by specific use-case requirements: vLLM excels in high-throughput batch processing scenarios, while TGI is better suited for latency-sensitive interactive applications with moderate concurrency.", "AI": {"tldr": "\u672c\u6587\u5bf9vLLM\u548cHuggingFace TGI\u4e24\u4e2a\u5f00\u6e90LLM\u670d\u52a1\u6846\u67b6\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u53d1\u73b0\u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0bvLLM\u541e\u5410\u91cf\u6bd4TGI\u9ad824\u500d\uff0c\u800cTGI\u5728\u4ea4\u4e92\u5f0f\u5355\u7528\u6237\u573a\u666f\u4e0b\u5ef6\u8fdf\u66f4\u4f4e\u3002", "motivation": "\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u9ad8\u6548\u7684\u63a8\u7406\u670d\u52a1\u7cfb\u7edf\u6765\u5e73\u8861\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "method": "\u4f7f\u7528LLaMA-2\u6a21\u578b\uff087B\u523070B\u53c2\u6570\uff09\u5bf9vLLM\u548cTGI\u8fdb\u884c\u591a\u7ef4\u5ea6\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u541e\u5410\u91cf\u6027\u80fd\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001GPU\u5185\u5b58\u5229\u7528\u7387\u548c\u53ef\u6269\u5c55\u6027\u7279\u5f81\u3002", "result": "vLLM\u901a\u8fc7\u5176\u65b0\u9896\u7684PagedAttention\u673a\u5236\u5728\u9ad8\u5e76\u53d1\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u6bd4TGI\u9ad824\u500d\u7684\u541e\u5410\u91cf\uff0c\u800cTGI\u5728\u4ea4\u4e92\u5f0f\u5355\u7528\u6237\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u5c3e\u90e8\u5ef6\u8fdf\u3002", "conclusion": "\u6846\u67b6\u9009\u62e9\u5e94\u57fa\u4e8e\u5177\u4f53\u7528\u4f8b\u9700\u6c42\uff1avLLM\u5728\u9ad8\u541e\u5410\u91cf\u6279\u5904\u7406\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u800cTGI\u66f4\u9002\u5408\u4e2d\u7b49\u5e76\u53d1\u7684\u5ef6\u8fdf\u654f\u611f\u4ea4\u4e92\u5e94\u7528\u3002"}}
{"id": "2511.17985", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17985", "abs": "https://arxiv.org/abs/2511.17985", "authors": ["Vibin Abraham", "Priyabrata Senapati", "Himadri Pathak", "Bo Peng"], "title": "Elucidating Many-Body Effects in Molecular Core Spectra through Real-Time Approaches: Efficient Classical Approximations and a Quantum Perspective", "comment": null, "summary": "Accurately resolving many-body satellite features in molecular core-level spectra requires theoretical approaches that capture electron correlation both efficiently and systematically. The recently developed time-dependent double coupled-cluster (TD-dCC) ansatz achieves this by combining correlation effects from the N- and (N-1)-electron sectors, but its exact formulation remains computationally demanding. Here we introduce a hierarchy of cost-effective approximate TD-dCC ansatzes derived from truncated Baker-Campbell-Hausdorff (BCH) expansions, which preserve a single-similarity-transformation structure while retaining the essential correlation diagrams responsible for satellite formation. We further develop a detailed component analysis that isolates hole-mediated excitation pathways, which are correlated processes arising from the coupling between ground-state and ionized-state amplitudes. We use it to interpret quasiparticle and satellite features across the hierarchy. Applications to the single-impurity Anderson model and molecular systems (H2O and CH4) demonstrate that the approximate TD-dCC methods closely and efficiently reproduce exact many-body spectral features and quasiparticle weights. In parallel, we construct a fault-tolerant quantum signal processing algorithm for the core-hole Green's function, providing a scalable quantum route for simulating correlated core-level dynamics. Together, these developments establish complementary classical and quantum methodologies for quantitative, many-body-accurate core spectroscopy.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u7684\u8fd1\u4f3cTD-dCC\u65b9\u6cd5\uff0c\u901a\u8fc7\u622a\u65adBCH\u5c55\u5f00\u6784\u5efa\u5c42\u6b21\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u51c6\u786e\u8ba1\u7b97\u5206\u5b50\u6838\u5fc3\u80fd\u7ea7\u5149\u8c31\u4e2d\u7684\u591a\u4f53\u536b\u661f\u7279\u5f81\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5\u4f5c\u4e3a\u8865\u5145\u3002", "motivation": "\u51c6\u786e\u89e3\u6790\u5206\u5b50\u6838\u5fc3\u80fd\u7ea7\u5149\u8c31\u4e2d\u7684\u591a\u4f53\u536b\u661f\u7279\u5f81\u9700\u8981\u9ad8\u6548\u4e14\u7cfb\u7edf\u7684\u7535\u5b50\u5173\u8054\u7406\u8bba\u65b9\u6cd5\uff0c\u73b0\u6709TD-dCC\u65b9\u6cd5\u867d\u7136\u6709\u6548\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u622a\u65adBCH\u5c55\u5f00\u7684\u8fd1\u4f3cTD-dCC\u65b9\u6cd5\u5c42\u6b21\uff0c\u4fdd\u7559\u5355\u76f8\u4f3c\u53d8\u6362\u7ed3\u6784\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u7a7a\u7a74\u4ecb\u5bfc\u6fc0\u53d1\u8def\u5f84\u7684\u8be6\u7ec6\u5206\u91cf\u5206\u6790\uff0c\u5e76\u6784\u5efa\u4e86\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5\u3002", "result": "\u5728\u5355\u6742\u8d28\u5b89\u5fb7\u68ee\u6a21\u578b\u548c\u5206\u5b50\u7cfb\u7edf\uff08H2O\u548cCH4\uff09\u4e2d\u7684\u5e94\u7528\u8868\u660e\uff0c\u8fd1\u4f3cTD-dCC\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u51c6\u786e\u5730\u91cd\u73b0\u7cbe\u786e\u591a\u4f53\u5149\u8c31\u7279\u5f81\u548c\u51c6\u7c92\u5b50\u6743\u91cd\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u5c55\u4e3a\u5b9a\u91cf\u3001\u591a\u4f53\u7cbe\u786e\u7684\u6838\u5fc3\u5149\u8c31\u5b66\u5efa\u7acb\u4e86\u4e92\u8865\u7684\u7ecf\u5178\u548c\u91cf\u5b50\u65b9\u6cd5\u5b66\u3002"}}
{"id": "2511.18036", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.18036", "abs": "https://arxiv.org/abs/2511.18036", "authors": ["Ziyi Guo", "Zhou Liu", "Wentao Zhang"], "title": "Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers", "comment": null, "summary": "The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u79d1\u5b66\u8bba\u6587\u7cfb\u7edf\u67b6\u6784\u56fe\u7684\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5305\u542b3000\u7bc7\u8bba\u6587\u53ca\u5176\u5bf9\u5e94\u7684\u9ad8\u8d28\u91cf\u56fe\u8868\uff0c\u5e76\u5f00\u53d1\u4e86Paper2SysArch\u7cfb\u7edf\u4f5c\u4e3a\u57fa\u51c6\u7684\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u624b\u52a8\u521b\u5efa\u7cfb\u7edf\u67b6\u6784\u56fe\u8017\u65f6\u4e14\u4e3b\u89c2\uff0c\u73b0\u6709\u751f\u6210\u6a21\u578b\u7f3a\u4e4f\u7ed3\u6784\u63a7\u5236\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4e14\u8be5\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86\u5305\u542b3000\u7bc7\u8bba\u6587\u53ca\u5176\u5bf9\u5e94\u56fe\u8868\u7684\u57fa\u51c6\uff0c\u91c7\u7528\u4e09\u5c42\u8bc4\u4f30\u6307\u6807\uff08\u8bed\u4e49\u51c6\u786e\u6027\u3001\u5e03\u5c40\u8fde\u8d2f\u6027\u3001\u89c6\u89c9\u8d28\u91cf\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684Paper2SysArch\u7aef\u5230\u7aef\u7cfb\u7edf\u3002", "result": "\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u5b50\u96c6\u4e0a\uff0cPaper2SysArch\u7cfb\u7edf\u53d6\u5f97\u4e8669.0\u7684\u7efc\u5408\u5f97\u5206\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u4e3b\u8981\u8d21\u732e\u662f\u5efa\u7acb\u4e86\u5927\u89c4\u6a21\u57fa\u7840\u57fa\u51c6\u4ee5\u652f\u6301\u53ef\u590d\u73b0\u7814\u7a76\u548c\u516c\u5e73\u6bd4\u8f83\uff0c\u540c\u65f6\u63d0\u51fa\u7684\u7cfb\u7edf\u5c55\u793a\u4e86\u89e3\u51b3\u8fd9\u4e00\u590d\u6742\u4efb\u52a1\u7684\u6709\u524d\u666f\u8def\u5f84\u3002"}}
{"id": "2511.17594", "categories": ["cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.17594", "abs": "https://arxiv.org/abs/2511.17594", "authors": ["Aleksandar Stankovic"], "title": "AutoSAGE: Input-Aware CUDA Scheduling for Sparse GNN Aggregation (SpMM/SDDMM) and CSR Attention", "comment": "10 pages, several figures. Code and artifacts: https://github.com/SV25-22/AutoSAGE", "summary": "Sparse GNN aggregations (CSR SpMM/SDDMM) vary widely in performance with degree skew, feature width, and GPU micro-architecture. We present AutoSAGE, an input-aware CUDA scheduler that chooses tiling and mapping per input using a lightweight estimate refined by on-device micro-probes, with a guardrail that safely falls back to vendor kernels and a persistent cache for deterministic replay. AutoSAGE covers SpMM and SDDMM and composes into a CSR attention pipeline (SDDMM -> row-softmax -> SpMM). On Reddit and OGBN-Products, it matches vendor baselines at bandwidth-bound feature widths and finds gains at small widths; on synthetic sparsity and skew stress tests it achieves up to 4.7x kernel-level speedups. We release CUDA sources, Python bindings, a reproducible harness, and replayable cache logs.", "AI": {"tldr": "AutoSAGE\u662f\u4e00\u4e2a\u8f93\u5165\u611f\u77e5\u7684CUDA\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4f30\u8ba1\u548c\u5fae\u63a2\u9488\u4e3a\u4e0d\u540c\u8f93\u5165\u9009\u62e9\u6700\u4f18\u7684\u5e73\u94fa\u548c\u6620\u5c04\u7b56\u7565\uff0c\u652f\u6301CSR SpMM/SDDMM\u64cd\u4f5c\uff0c\u5e76\u80fd\u7ec4\u5408\u6210CSR\u6ce8\u610f\u529b\u6d41\u6c34\u7ebf\u3002", "motivation": "\u7a00\u758fGNN\u805a\u5408\u64cd\u4f5c\uff08CSR SpMM/SDDMM\uff09\u7684\u6027\u80fd\u56e0\u8282\u70b9\u5ea6\u6570\u504f\u659c\u3001\u7279\u5f81\u5bbd\u5ea6\u548cGPU\u5fae\u67b6\u6784\u800c\u5f02\uff0c\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u8f93\u5165\u8fdb\u884c\u4f18\u5316\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4f30\u8ba1\u548con-device\u5fae\u63a2\u9488\u4e3a\u6bcf\u4e2a\u8f93\u5165\u9009\u62e9\u5e73\u94fa\u548c\u6620\u5c04\u7b56\u7565\uff0c\u5305\u542b\u56de\u9000\u673a\u5236\u548c\u6301\u4e45\u7f13\u5b58\u4ee5\u786e\u4fdd\u786e\u5b9a\u6027\u91cd\u653e\u3002", "result": "\u5728Reddit\u548cOGBN-Products\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u7279\u5f81\u5bbd\u5ea6\u4e0b\u4e0e\u4f9b\u5e94\u5546\u57fa\u7ebf\u5339\u914d\uff0c\u5728\u5c0f\u5bbd\u5ea6\u4e0b\u83b7\u5f97\u6027\u80fd\u63d0\u5347\uff1b\u5728\u5408\u6210\u7a00\u758f\u6027\u548c\u504f\u659c\u538b\u529b\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u9ad8\u8fbe4.7\u500d\u7684\u5185\u6838\u7ea7\u52a0\u901f\u3002", "conclusion": "AutoSAGE\u80fd\u591f\u6709\u6548\u4f18\u5316\u7a00\u758fGNN\u805a\u5408\u64cd\u4f5c\uff0c\u63d0\u4f9b\u4e86CUDA\u6e90\u4ee3\u7801\u3001Python\u7ed1\u5b9a\u3001\u53ef\u590d\u73b0\u6846\u67b6\u548c\u53ef\u91cd\u653e\u7f13\u5b58\u65e5\u5fd7\u3002"}}
{"id": "2511.19415", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19415", "abs": "https://arxiv.org/abs/2511.19415", "authors": ["Hadi Cheraghi", "Ali G. Moghaddam", "Teemu Ojanen"], "title": "Entanglement-limited linear response in fermionic systems", "comment": "11 pages, 6 figures", "summary": "We propose a general connection between entanglement-entropy scaling laws and the linear response functions of particle-conserving fermionic systems in their ground state. Specifically, we show that the response to perturbations coupled to the particle number within a finite region exhibits the same size scaling as the entanglement entropy of that region. We explicitly verify this scaling in free-fermion systems that display area-law, volume-law, and critical forms of entanglement. The resulting entanglement-governed scaling of response functions leads to unexpected physical consequences. For instance, contrary to conventional expectations, the energy absorption rate and particle-number fluctuations in gapped systems scale with the boundary of the perturbed region rather than with its volume. Our work thus establishes a direct link between linear-response properties and many-body entanglement.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u7ea0\u7f20\u71b5\u6807\u5ea6\u5f8b\u4e0e\u7c92\u5b50\u5b88\u6052\u8d39\u7c73\u5b50\u7cfb\u7edf\u7ebf\u6027\u54cd\u5e94\u51fd\u6570\u4e4b\u95f4\u7684\u666e\u904d\u8054\u7cfb\uff0c\u8bc1\u660e\u533a\u57df\u5185\u7c92\u5b50\u6570\u6270\u52a8\u7684\u54cd\u5e94\u51fd\u6570\u6807\u5ea6\u4e0e\u7ea0\u7f20\u71b5\u6807\u5ea6\u76f8\u540c\u3002", "motivation": "\u63a2\u7d22\u7ea0\u7f20\u71b5\u4e0e\u7ebf\u6027\u54cd\u5e94\u51fd\u6570\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\uff0c\u63ed\u793a\u591a\u4f53\u7ea0\u7f20\u5bf9\u7cfb\u7edf\u54cd\u5e94\u7279\u6027\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u548c\u81ea\u7531\u8d39\u7c73\u5b50\u7cfb\u7edf\u9a8c\u8bc1\uff0c\u5206\u6790\u4e0d\u540c\u7ea0\u7f20\u5f62\u5f0f\uff08\u9762\u79ef\u5f8b\u3001\u4f53\u79ef\u5f8b\u3001\u4e34\u754c\uff09\u4e0b\u7684\u54cd\u5e94\u51fd\u6570\u6807\u5ea6\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u54cd\u5e94\u51fd\u6570\u6807\u5ea6\u7531\u7ea0\u7f20\u71b5\u51b3\u5b9a\uff0c\u5bfc\u81f4\u80fd\u9699\u7cfb\u7edf\u4e2d\u80fd\u91cf\u5438\u6536\u7387\u548c\u7c92\u5b50\u6570\u6da8\u843d\u4e0e\u6270\u52a8\u533a\u57df\u8fb9\u754c\u800c\u975e\u4f53\u79ef\u6210\u6bd4\u4f8b\u3002", "conclusion": "\u5efa\u7acb\u4e86\u7ebf\u6027\u54cd\u5e94\u7279\u6027\u4e0e\u591a\u4f53\u7ea0\u7f20\u4e4b\u95f4\u7684\u76f4\u63a5\u8054\u7cfb\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u9884\u671f\u5e76\u63ed\u793a\u4e86\u7ea0\u7f20\u5728\u7cfb\u7edf\u54cd\u5e94\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2511.18021", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.18021", "abs": "https://arxiv.org/abs/2511.18021", "authors": ["Daniele Amato", "Paolo Facchi", "Arturo Konderak"], "title": "Attractor Subspace and Decoherence-Free Algebra of Quantum Dynamics", "comment": "17 pages", "summary": "In this review we discuss some results on the asymptotic dynamics of finite-dimensional open quantum systems in the Heisenberg picture. Both the spectral and algebraic approaches to this topic are addressed, with particular emphasis on their relationship. The analysis is conducted in both the discrete-time and the continuous-time Markovian settings. In the final part of the work, some issues emerging in the infinite-dimensional case are also discussed. In particular, we provide an example of a Markovian evolution whose decoherence-free algebra is a type III von Neumann algebra.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6709\u9650\u7ef4\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u5728Heisenberg\u7ed8\u666f\u4e2d\u7684\u6e10\u8fd1\u52a8\u529b\u5b66\uff0c\u8ba8\u8bba\u4e86\u8c31\u65b9\u6cd5\u548c\u4ee3\u6570\u65b9\u6cd5\u53ca\u5176\u5173\u7cfb\uff0c\u5206\u6790\u4e86\u79bb\u6563\u65f6\u95f4\u548c\u8fde\u7eed\u65f6\u95f4Markovian\u60c5\u5f62\uff0c\u5e76\u63a2\u8ba8\u4e86\u65e0\u9650\u7ef4\u60c5\u51b5\u4e0b\u7684\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u6e10\u8fd1\u52a8\u529b\u5b66\uff0c\u7279\u522b\u662fHeisenberg\u7ed8\u666f\u4e0b\u7684\u884c\u4e3a\uff0c\u65e8\u5728\u7406\u89e3\u8c31\u65b9\u6cd5\u548c\u4ee3\u6570\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u6269\u5c55\u5230\u65e0\u9650\u7ef4\u60c5\u51b5\u3002", "method": "\u91c7\u7528\u8c31\u5206\u6790\u548c\u4ee3\u6570\u5206\u6790\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5728\u79bb\u6563\u65f6\u95f4\u548c\u8fde\u7eed\u65f6\u95f4Markovian\u6846\u67b6\u4e0b\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\u3002", "result": "\u63d0\u4f9b\u4e86\u6709\u9650\u7ef4\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u6e10\u8fd1\u52a8\u529b\u5b66\u7684\u5b8c\u6574\u5206\u6790\u6846\u67b6\uff0c\u5e76\u5728\u65e0\u9650\u7ef4\u60c5\u51b5\u4e0b\u7ed9\u51fa\u4e86\u4e00\u4e2aMarkovian\u6f14\u5316\u7684\u4f8b\u5b50\uff0c\u5176\u9000\u76f8\u5e72\u81ea\u7531\u4ee3\u6570\u662f\u4e00\u4e2aIII\u578bvon Neumann\u4ee3\u6570\u3002", "conclusion": "\u8c31\u65b9\u6cd5\u548c\u4ee3\u6570\u65b9\u6cd5\u5728\u5206\u6790\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u6e10\u8fd1\u52a8\u529b\u5b66\u65f6\u5177\u6709\u7d27\u5bc6\u8054\u7cfb\uff0c\u8be5\u7814\u7a76\u6846\u67b6\u53ef\u63a8\u5e7f\u5230\u65e0\u9650\u7ef4\u60c5\u5f62\uff0c\u4e3a\u7406\u89e3\u91cf\u5b50\u7cfb\u7edf\u7684\u957f\u671f\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.18171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18171", "abs": "https://arxiv.org/abs/2511.18171", "authors": ["Jasper Nie", "Christian Muise", "Victoria Armstrong"], "title": "BPMN to PDDL: Translating Business Workflows for AI Planning", "comment": "8 pages, 3 figures. Code and generated PDDL outputs available at https://github.com/QuMuLab/bpmn-to-pddl-translation", "summary": "Business Process Model and Notation (BPMN) is a widely used standard for modelling business processes. While automated planning has been proposed as a method for simulating and reasoning about BPMN workflows, most implementations remain incomplete or limited in scope. This project builds upon prior theoretical work to develop a functional pipeline that translates BPMN 2.0 diagrams into PDDL representations suitable for planning. The system supports core BPMN constructs, including tasks, events, sequence flows, and gateways, with initial support for parallel and inclusive gateway behaviour. Using a non-deterministic planner, we demonstrate how to generate and evaluate valid execution traces. Our implementation aims to bridge the gap between theory and practical tooling, providing a foundation for further exploration of translating business processes into well-defined plans.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5c06BPMN 2.0\u56fe\u8f6c\u6362\u4e3aPDDL\u8868\u793a\u7684\u5b9e\u7528\u7ba1\u9053\uff0c\u652f\u6301\u6838\u5fc3BPMN\u6784\u9020\uff0c\u4f7f\u7528\u975e\u786e\u5b9a\u6027\u89c4\u5212\u5668\u751f\u6210\u6709\u6548\u6267\u884c\u8f68\u8ff9", "motivation": "\u867d\u7136\u81ea\u52a8\u5316\u89c4\u5212\u5df2\u88ab\u63d0\u51fa\u4f5c\u4e3a\u6a21\u62df\u548c\u63a8\u7406BPMN\u5de5\u4f5c\u6d41\u7684\u65b9\u6cd5\uff0c\u4f46\u5927\u591a\u6570\u5b9e\u73b0\u4ecd\u4e0d\u5b8c\u6574\u6216\u8303\u56f4\u6709\u9650\uff0c\u9700\u8981\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u7528\u5de5\u5177\u4e4b\u95f4\u7684\u5dee\u8ddd", "method": "\u57fa\u4e8e\u5148\u524d\u7406\u8bba\u7814\u7a76\uff0c\u5f00\u53d1\u529f\u80fd\u7ba1\u9053\u5c06BPMN 2.0\u56fe\u8f6c\u6362\u4e3a\u9002\u5408\u89c4\u5212\u7684PDDL\u8868\u793a\uff0c\u652f\u6301\u4efb\u52a1\u3001\u4e8b\u4ef6\u3001\u5e8f\u5217\u6d41\u548c\u7f51\u5173\u7b49\u6838\u5fc3BPMN\u6784\u9020\uff0c\u521d\u6b65\u652f\u6301\u5e76\u884c\u548c\u5305\u5bb9\u7f51\u5173\u884c\u4e3a", "result": "\u4f7f\u7528\u975e\u786e\u5b9a\u6027\u89c4\u5212\u5668\u6210\u529f\u751f\u6210\u548c\u8bc4\u4f30\u6709\u6548\u6267\u884c\u8f68\u8ff9\uff0c\u4e3a\u5c06\u4e1a\u52a1\u6d41\u7a0b\u8f6c\u6362\u4e3a\u660e\u786e\u5b9a\u4e49\u7684\u89c4\u5212\u63d0\u4f9b\u4e86\u57fa\u7840", "conclusion": "\u8be5\u5b9e\u73b0\u65e8\u5728\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u7528\u5de5\u5177\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5c06\u4e1a\u52a1\u6d41\u7a0b\u8f6c\u6362\u4e3a\u660e\u786e\u5b9a\u4e49\u7684\u89c4\u5212\u7684\u8fdb\u4e00\u6b65\u63a2\u7d22\u63d0\u4f9b\u4e86\u57fa\u7840"}}
{"id": "2511.17595", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17595", "abs": "https://arxiv.org/abs/2511.17595", "authors": ["Markus D. Solbach", "John K. Tsotsos"], "title": "Boosting Reinforcement Learning in 3D Visuospatial Tasks Through Human-Informed Curriculum Design", "comment": "12 pages, 11 figures, 5 tables", "summary": "Reinforcement Learning is a mature technology, often suggested as a potential route towards Artificial General Intelligence, with the ambitious goal of replicating the wide range of abilities found in natural and artificial intelligence, including the complexities of human cognition. While RL had shown successes in relatively constrained environments, such as the classic Atari games and specific continuous control problems, recent years have seen efforts to expand its applicability. This work investigates the potential of RL in demonstrating intelligent behaviour and its progress in addressing more complex and less structured problem domains.\n  We present an investigation into the capacity of modern RL frameworks in addressing a seemingly straightforward 3D Same-Different visuospatial task. While initial applications of state-of-the-art methods, including PPO, behavioural cloning and imitation learning, revealed challenges in directly learning optimal strategies, the successful implementation of curriculum learning offers a promising avenue. Effective learning was achieved by strategically designing the lesson plan based on the findings of a real-world human experiment.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f3a\u5316\u5b66\u4e60\u57283D\u540c\u5f02\u89c6\u89c9\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u6807\u51c6\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5b66\u4e60\u6700\u4f18\u7b56\u7565\uff0c\u4f46\u901a\u8fc7\u57fa\u4e8e\u4eba\u7c7b\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u8bfe\u7a0b\u5b66\u4e60\u53d6\u5f97\u4e86\u6210\u529f\u3002", "motivation": "\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u3001\u975e\u7ed3\u6784\u5316\u95ee\u9898\u9886\u57df\u4e2d\u7684\u667a\u80fd\u884c\u4e3a\u8868\u73b0\u80fd\u529b\uff0c\u7279\u522b\u662f\u9a8c\u8bc1\u5176\u5728\u770b\u4f3c\u7b80\u5355\u76843D\u89c6\u89c9\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528PPO\u3001\u884c\u4e3a\u514b\u9686\u548c\u6a21\u4eff\u5b66\u4e60\u7b49\u5148\u8fdbRL\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u4eba\u7c7b\u5b9e\u9a8c\u7ed3\u679c\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u8bbe\u8ba1\u3002", "result": "\u6807\u51c6RL\u65b9\u6cd5\u5728\u76f4\u63a5\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u65b9\u9762\u9047\u5230\u56f0\u96be\uff0c\u4f46\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u4e86\u6709\u6548\u5b66\u4e60\u3002", "conclusion": "\u8bfe\u7a0b\u5b66\u4e60\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u89c6\u89c9\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u57fa\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u7684\u8bfe\u7a0b\u8bbe\u8ba1\u662f\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2511.18062", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.18062", "abs": "https://arxiv.org/abs/2511.18062", "authors": ["Manas Nagda", "Priyam Kumar De", "Amber Jain"], "title": "Fewest switches surface hopping with decoherence in the Marcus inverted regime: correct rates but wrong thermal populations", "comment": null, "summary": "Fewest switches surface hopping (FSSH) is a well benchmarked dynamical method for simulating nonadiabatic systems. In particular, the literature shows that for the spin-Boson model Hamiltonian, FSSH with appropriate corrections usually captures the detailed balance well and obtains rate constants within a factor of 2 compared to numerically exact results. In this study, we show that in the deep inverted Marcus regime, the augmented-FSSH (AFSSH, one version that includes decoherence) yields reasonably accurate rate constants but incorrect thermal populations over a broad range of parameters. We present an analytical derivation to understand the AFSSH behavior, and therefore, show that AFSSH obtains correct rate constants owing to the resonance of the time derivative coupling with the exothermicity, but obtains an incorrect thermal population owing to the self-consistency issue. The presented derivation provides an analytical expression for the quantum correction factor for AFSSH simulations in the Marcus inverted regime.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u589e\u5f3a\u578b\u6700\u5c11\u5207\u6362\u9762\u8df3\u8dc3\u65b9\u6cd5\u5728\u6df1\u5ea6\u53cd\u8f6cMarcus\u533a\u57df\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8be5\u65b9\u6cd5\u80fd\u83b7\u5f97\u5408\u7406\u7684\u901f\u7387\u5e38\u6570\u4f46\u70ed\u5e03\u5c45\u4e0d\u6b63\u786e\uff0c\u5e76\u901a\u8fc7\u89e3\u6790\u63a8\u5bfc\u89e3\u91ca\u4e86\u8fd9\u4e00\u73b0\u8c61\u3002", "motivation": "\u867d\u7136FSSH\u65b9\u6cd5\u5728\u975e\u7edd\u70ed\u7cfb\u7edf\u6a21\u62df\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6df1\u5ea6\u53cd\u8f6cMarcus\u533a\u57df\uff0cAFSSH\u65b9\u6cd5\u867d\u7136\u80fd\u83b7\u5f97\u51c6\u786e\u901f\u7387\u5e38\u6570\uff0c\u4f46\u70ed\u5e03\u5c45\u7ed3\u679c\u4e0d\u6b63\u786e\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u5176\u5185\u5728\u673a\u5236\u3002", "method": "\u4f7f\u7528\u589e\u5f3a\u578b\u6700\u5c11\u5207\u6362\u9762\u8df3\u8dc3\u65b9\u6cd5\u8fdb\u884c\u6a21\u62df\uff0c\u5e76\u901a\u8fc7\u89e3\u6790\u63a8\u5bfc\u5206\u6790AFSSH\u5728\u6df1\u5ea6\u53cd\u8f6cMarcus\u533a\u57df\u7684\u884c\u4e3a\u3002", "result": "AFSSH\u5728\u6df1\u5ea6\u53cd\u8f6cMarcus\u533a\u57df\u80fd\u83b7\u5f97\u5408\u7406\u7684\u901f\u7387\u5e38\u6570\uff0c\u4f46\u70ed\u5e03\u5c45\u7ed3\u679c\u4e0d\u6b63\u786e\uff1b\u89e3\u6790\u63a8\u5bfc\u8868\u660e\u8fd9\u662f\u7531\u4e8e\u65f6\u95f4\u5bfc\u6570\u8026\u5408\u4e0e\u653e\u70ed\u6027\u7684\u5171\u632f\u5bfc\u81f4\u6b63\u786e\u901f\u7387\u5e38\u6570\uff0c\u4f46\u81ea\u6d3d\u6027\u95ee\u9898\u5bfc\u81f4\u9519\u8bef\u70ed\u5e03\u5c45\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86AFSSH\u5728Marcus\u53cd\u8f6c\u533a\u57df\u7684\u91cf\u5b50\u6821\u6b63\u56e0\u5b50\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86AFSSH\u5728\u6df1\u5ea6\u53cd\u8f6c\u533a\u57df\u83b7\u5f97\u6b63\u786e\u901f\u7387\u5e38\u6570\u4f46\u9519\u8bef\u70ed\u5e03\u5c45\u7684\u5185\u5728\u673a\u5236\u3002"}}
{"id": "2511.18244", "categories": ["cs.AI", "cond-mat.mtrl-sci", "physics.ed-ph"], "pdf": "https://arxiv.org/pdf/2511.18244", "abs": "https://arxiv.org/abs/2511.18244", "authors": ["Zhiling Zheng"], "title": "Developing an AI Course for Synthetic Chemistry Students", "comment": "17 pages, 3 figures", "summary": "Artificial intelligence (AI) and data science are transforming chemical research, yet few formal courses are tailored to synthetic and experimental chemists, who often face steep entry barriers due to limited coding experience and lack of chemistry-specific examples. We present the design and implementation of AI4CHEM, an introductory data-driven chem-istry course created for students on the synthetic chemistry track with no prior programming background. The curricu-lum emphasizes chemical context over abstract algorithms, using an accessible web-based platform to ensure zero-install machine learning (ML) workflow development practice and in-class active learning. Assessment combines code-guided homework, literature-based mini-reviews, and collaborative projects in which students build AI-assisted workflows for real experimental problems. Learning gains include increased confidence with Python, molecular property prediction, reaction optimization, and data mining, and improved skills in evaluating AI tools in chemistry. All course materials are openly available, offering a discipline-specific, beginner-accessible framework for integrating AI into synthetic chemistry training.", "AI": {"tldr": "AI4CHEM\u662f\u4e00\u95e8\u4e3a\u5408\u6210\u5316\u5b66\u5b66\u751f\u8bbe\u8ba1\u7684\u5165\u95e8\u7ea7\u6570\u636e\u9a71\u52a8\u5316\u5b66\u8bfe\u7a0b\uff0c\u9488\u5bf9\u65e0\u7f16\u7a0b\u80cc\u666f\u7684\u5b66\u751f\uff0c\u901a\u8fc7\u57fa\u4e8e\u7f51\u9875\u7684\u5e73\u53f0\u63d0\u4f9b\u96f6\u5b89\u88c5\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u5f00\u53d1\u5b9e\u8df5\u548c\u8bfe\u5802\u4e3b\u52a8\u5b66\u4e60\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u548c\u6570\u636e\u79d1\u5b66\u6b63\u5728\u6539\u53d8\u5316\u5b66\u7814\u7a76\uff0c\u4f46\u5f88\u5c11\u6709\u4e13\u95e8\u4e3a\u5408\u6210\u548c\u5b9e\u9a8c\u5316\u5b66\u5bb6\u8bbe\u8ba1\u7684\u6b63\u5f0f\u8bfe\u7a0b\uff0c\u4ed6\u4eec\u5f80\u5f80\u56e0\u7f16\u7a0b\u7ecf\u9a8c\u6709\u9650\u548c\u7f3a\u4e4f\u5316\u5b66\u7279\u5b9a\u793a\u4f8b\u800c\u9762\u4e34\u8f83\u9ad8\u7684\u5165\u95e8\u95e8\u69db\u3002", "method": "\u8bfe\u7a0b\u8bbe\u8ba1\u5f3a\u8c03\u5316\u5b66\u80cc\u666f\u800c\u975e\u62bd\u8c61\u7b97\u6cd5\uff0c\u4f7f\u7528\u53ef\u8bbf\u95ee\u7684\u57fa\u4e8e\u7f51\u9875\u5e73\u53f0\u786e\u4fdd\u96f6\u5b89\u88c5\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u5f00\u53d1\u5b9e\u8df5\u548c\u8bfe\u5802\u4e3b\u52a8\u5b66\u4e60\u3002\u8bc4\u4f30\u7ed3\u5408\u4ee3\u7801\u6307\u5bfc\u7684\u4f5c\u4e1a\u3001\u57fa\u4e8e\u6587\u732e\u7684\u8ff7\u4f60\u7efc\u8ff0\u4ee5\u53ca\u5b66\u751f\u4e3a\u771f\u5b9e\u5b9e\u9a8c\u95ee\u9898\u6784\u5efaAI\u8f85\u52a9\u5de5\u4f5c\u6d41\u7684\u534f\u4f5c\u9879\u76ee\u3002", "result": "\u5b66\u4e60\u6536\u83b7\u5305\u62ec\u63d0\u9ad8Python\u7f16\u7a0b\u4fe1\u5fc3\u3001\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u3001\u53cd\u5e94\u4f18\u5316\u548c\u6570\u636e\u6316\u6398\u80fd\u529b\uff0c\u4ee5\u53ca\u6539\u8fdb\u8bc4\u4f30\u5316\u5b66AI\u5de5\u5177\u7684\u6280\u80fd\u3002", "conclusion": "\u6240\u6709\u8bfe\u7a0b\u6750\u6599\u516c\u5f00\u53ef\u7528\uff0c\u4e3a\u5c06AI\u878d\u5165\u5408\u6210\u5316\u5b66\u57f9\u8bad\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b66\u79d1\u7279\u5b9a\u3001\u521d\u5b66\u8005\u53ef\u8bbf\u95ee\u7684\u6846\u67b6\u3002"}}
{"id": "2511.17598", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17598", "abs": "https://arxiv.org/abs/2511.17598", "authors": ["Zhizuo Chen", "Theodore T. Allen"], "title": "Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning", "comment": null, "summary": "Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u975e\u5e73\u7a33\u548c\u53ef\u53d8\u6298\u6263MDP\uff08NVMDP\uff09\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edfMDP\u5728\u975e\u5e73\u7a33\u73af\u5883\u548c\u6709\u9650\u65f6\u57df\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u652f\u6301\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6298\u6263\u7387\uff0c\u5e76\u80fd\u7075\u6d3b\u5851\u9020\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u4f20\u7edfMDP\u7b97\u6cd5\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u65e0\u9650\u65f6\u57df\u516c\u5f0f\u4e0d\u9002\u7528\u4e8e\u6709\u9650\u65f6\u57df\u4efb\u52a1\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u6846\u67b6\u6765\u5904\u7406\u975e\u5e73\u7a33\u6027\u548c\u53ef\u53d8\u6298\u6263\u3002", "method": "\u5efa\u7acbNVMDP\u7406\u8bba\u6846\u67b6\uff0c\u5305\u62ec\u72b6\u6001-\u52a8\u4f5c\u503c\u51fd\u6570\u516c\u5f0f\u5316\u3001\u77e9\u9635\u8868\u793a\u3001\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u5e76\u6269\u5c55\u52a8\u6001\u89c4\u5212\u548cQ\u5b66\u4e60\u7b97\u6cd5\uff0c\u4ee5\u53ca\u51fd\u6570\u903c\u8fd1\u4e0b\u7684\u7b56\u7565\u68af\u5ea6\u5b9a\u7406\u548cTRPO\u3002", "result": "\u5728\u975e\u5e73\u7a33\u7f51\u683c\u4e16\u754c\u73af\u5883\u4e2d\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cNVMDP\u7b97\u6cd5\u80fd\u6210\u529f\u6062\u590d\u6700\u4f18\u8f68\u8ff9\uff0c\u800c\u539f\u59cbQ\u5b66\u4e60\u5931\u8d25\uff0c\u8bc1\u660e\u8be5\u6846\u67b6\u7684\u7406\u8bba\u5408\u7406\u6027\u548c\u5b9e\u8df5\u6709\u6548\u6027\u3002", "conclusion": "NVMDP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u4e25\u8c28\u4e14\u5b9e\u9645\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u53ea\u9700\u8f7b\u5fae\u7b97\u6cd5\u4fee\u6539\u5373\u53ef\u7a33\u5065\u5904\u7406\u975e\u5e73\u7a33\u6027\u548c\u663e\u5f0f\u6700\u4f18\u7b56\u7565\u5851\u9020\u3002"}}
{"id": "2511.18284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18284", "abs": "https://arxiv.org/abs/2511.18284", "authors": ["Tetiana Bas", "Krystian Novak"], "title": "Steering Latent Traits, Not Learned Facts: An Empirical Study of Activation Control Limits", "comment": null, "summary": "Large language models (LLMs) require precise behavior control for safe and effective deployment across diverse applications.\n  Activation steering offers a promising approach for LLMs' behavioral control. We focus on the question of how steering effectiveness varies across different behavior types and whether the nature of target behaviors can predict steering success. We address this through empirical analysis of activation steering across 50 behaviors that span persona archetypes, personality traits, misalignment behaviors, style cues, and impersonation of public figures. We present a set of comprehensive experiments on coefficient optimization, vector properties, and data requirements to provide comprehensive guidance for the implementation of activation steering. Our analysis demonstrates that steering effectiveness varies significantly by behavior type, with different behavioral categories exhibiting distinct response patterns to intervention strength. We find that trait expression follows an inverted-U curve with a steering coefficient strength. We also show that vector separation metrics do not predict steering success, but larger training datasets enable more aggressive steering. These findings provide empirically grounded guidance for implementing activation steering and demonstrate that steering effectiveness is heavily influenced by behavior type.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u5206\u679050\u79cd\u884c\u4e3a\u7c7b\u578b\u7684\u6fc0\u6d3b\u5f15\u5bfc\u6548\u679c\uff0c\u53d1\u73b0\u5f15\u5bfc\u6709\u6548\u6027\u56e0\u884c\u4e3a\u7c7b\u578b\u800c\u5f02\uff0c\u7279\u8d28\u8868\u8fbe\u5448\u73b0\u5012U\u578b\u66f2\u7ebf\uff0c\u5411\u91cf\u5206\u79bb\u6307\u6807\u4e0d\u80fd\u9884\u6d4b\u5f15\u5bfc\u6210\u529f\uff0c\u4f46\u66f4\u5927\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u652f\u6301\u66f4\u6fc0\u8fdb\u7684\u5f15\u5bfc\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u7cbe\u786e\u7684\u884c\u4e3a\u63a7\u5236\u4ee5\u786e\u4fdd\u5b89\u5168\u6709\u6548\u90e8\u7f72\uff0c\u6fc0\u6d3b\u5f15\u5bfc\u662f\u5b9e\u73b0\u884c\u4e3a\u63a7\u5236\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u4e86\u89e3\u4e0d\u540c\u884c\u4e3a\u7c7b\u578b\u7684\u5f15\u5bfc\u6548\u679c\u5dee\u5f02\u3002", "method": "\u5bf950\u79cd\u884c\u4e3a\u7c7b\u578b\u8fdb\u884c\u6fc0\u6d3b\u5f15\u5bfc\u5b9e\u8bc1\u5206\u6790\uff0c\u6db5\u76d6\u4eba\u683c\u539f\u578b\u3001\u4e2a\u6027\u7279\u8d28\u3001\u9519\u4f4d\u884c\u4e3a\u3001\u98ce\u683c\u63d0\u793a\u548c\u516c\u4f17\u4eba\u7269\u6a21\u4eff\uff0c\u8fdb\u884c\u7cfb\u6570\u4f18\u5316\u3001\u5411\u91cf\u5c5e\u6027\u548c\u6570\u636e\u9700\u6c42\u7684\u7efc\u5408\u5b9e\u9a8c\u3002", "result": "\u5f15\u5bfc\u6709\u6548\u6027\u56e0\u884c\u4e3a\u7c7b\u578b\u663e\u8457\u4e0d\u540c\uff0c\u4e0d\u540c\u884c\u4e3a\u7c7b\u522b\u5bf9\u5e72\u9884\u5f3a\u5ea6\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u54cd\u5e94\u6a21\u5f0f\uff0c\u7279\u8d28\u8868\u8fbe\u968f\u5f15\u5bfc\u7cfb\u6570\u5f3a\u5ea6\u5448\u73b0\u5012U\u578b\u66f2\u7ebf\u3002", "conclusion": "\u6fc0\u6d3b\u5f15\u5bfc\u7684\u6709\u6548\u6027\u53d7\u884c\u4e3a\u7c7b\u578b\u5f71\u54cd\u663e\u8457\uff0c\u5411\u91cf\u5206\u79bb\u6307\u6807\u4e0d\u80fd\u9884\u6d4b\u5f15\u5bfc\u6210\u529f\uff0c\u4f46\u66f4\u5927\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u652f\u6301\u66f4\u6fc0\u8fdb\u7684\u5f15\u5bfc\uff0c\u4e3a\u5b9e\u65bd\u6fc0\u6d3b\u5f15\u5bfc\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\u3002"}}
{"id": "2511.17599", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17599", "abs": "https://arxiv.org/abs/2511.17599", "authors": ["Jianbing Dong", "Jianbin Chang"], "title": "From Projection to Prediction: Beyond Logits for Scalable Language Models", "comment": "17 pages, 2 figures, 4 algorithms", "summary": "Training Large Language Models (LLMs) typically involves a two-stage pipeline at the output layer: hidden states are projected into vocabulary logits via a linear transformation (lm_head), followed by cross-entropy loss computation against target tokens. While conceptually simple, this design incurs substantial overhead. The intermediate logits tensor, with dimensions proportional to batch size, sequence length, and vocabulary size, must be fully materialized in GPU memory, even though only one target token per position is ultimately used. This leads to significant memory footprint and bandwidth comsumption, limiting scalability and slowing training throughput.\n  In this work, we introduce a novel approach to integrates the output projection and loss prediction into a single operation. By directly computing the loss from hidden states and target tokens, our approach bypasses explicit logits materialization. This design reduces memory usage and alleviates bandwidth pressure. Experiments on LLM training demonstrate that our method achieves substantial memory savings and measurable speedups compared to the standard two-stage pipeline, enabling large batch sizes and longer sequences without sacrificing accuracy. Our work highlights the benefits of rethinking the boundary between projection and prediction, offering a practical systems optimization for efficient LLM training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u8f93\u51fa\u6295\u5f71\u548c\u635f\u5931\u9884\u6d4b\u96c6\u6210\u5230\u5355\u4e00\u64cd\u4f5c\u4e2d\u7684\u65b0\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u663e\u5f0flogits\u5f20\u91cf\u5316\uff0c\u4ece\u800c\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u548c\u5e26\u5bbd\u538b\u529b\uff0c\u5728LLM\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5185\u5b58\u8282\u7701\u548c\u53ef\u6d4b\u91cf\u7684\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u7684\u4e24\u9636\u6bb5\u8f93\u51fa\u5c42\u8bbe\u8ba1\uff08\u7ebf\u6027\u53d8\u6362\u751f\u6210\u8bcd\u6c47logits\uff0c\u7136\u540e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\uff09\u4f1a\u4ea7\u751f\u5927\u91cf\u4e2d\u95f4logits\u5f20\u91cf\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u5185\u5b58\u5360\u7528\u548c\u5e26\u5bbd\u6d88\u8017\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u541e\u5410\u91cf\u3002", "method": "\u901a\u8fc7\u76f4\u63a5\u5c06\u9690\u85cf\u72b6\u6001\u548c\u76ee\u6807\u6807\u8bb0\u8ba1\u7b97\u635f\u5931\uff0c\u5c06\u8f93\u51fa\u6295\u5f71\u548c\u635f\u5931\u9884\u6d4b\u96c6\u6210\u5230\u5355\u4e00\u64cd\u4f5c\u4e2d\uff0c\u7ed5\u8fc7\u663e\u5f0flogits\u5f20\u91cf\u5316\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728LLM\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5185\u5b58\u8282\u7701\u548c\u53ef\u6d4b\u91cf\u7684\u52a0\u901f\uff0c\u80fd\u591f\u652f\u6301\u66f4\u5927\u7684\u6279\u5904\u7406\u5927\u5c0f\u548c\u66f4\u957f\u7684\u5e8f\u5217\uff0c\u800c\u4e0d\u4f1a\u727a\u7272\u51c6\u786e\u6027\u3002", "conclusion": "\u91cd\u65b0\u601d\u8003\u6295\u5f71\u548c\u9884\u6d4b\u4e4b\u95f4\u7684\u8fb9\u754c\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u9ad8\u6548\u7684LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7cfb\u7edf\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2511.18149", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18149", "abs": "https://arxiv.org/abs/2511.18149", "authors": ["Kingshuk Adhikary", "Darren W. Moore", "Radim Filip"], "title": "Coherence of quantum non-Gaussian states via nonlinear absorption of quanta", "comment": null, "summary": "The linear and phase insensitive absorption of a single quanta via coherent interactions with a saturable system, even a single ground state qubit, is sufficient to deterministically generate quantum non-Gaussian states in an oscillator, even stimulated merely by increasing thermal oscillator energy. However, the resultant states only approach Fock states and therefore do not exhibit quantum coherence. Here we overcome this limitation using a minimal step: a nonlinear phase-insensitive absorption process added to the linear one. The coherent addition of such individually passive processes allows coherence to emerge and increase in phase space without an external drive and with minimal interaction requirements. The coherence of quantum non-Gaussian states emerges because the linear and nonlinear absorption processes are not mutually passive. In the simplest case rotationally symmetric Wigner functions of the oscillator Fock states convert their many negative regions to an extremely complex asymmetric structure in sharp contrast to the rotational symmetry of those obtained by the individual interactions. We extend this case to include an unsaturable absorber (oscillator) and analyse switching between linear and nonlinear absorptions, suitable for broad classes of experiments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u7ed3\u5408\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u76f8\u4f4d\u4e0d\u654f\u611f\u5438\u6536\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u5728\u6ca1\u6709\u5916\u90e8\u9a71\u52a8\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u5177\u6709\u91cf\u5b50\u76f8\u5e72\u6027\u7684\u975e\u9ad8\u65af\u6001\uff0c\u514b\u670d\u4e86\u4ec5\u4f7f\u7528\u7ebf\u6027\u5438\u6536\u53ea\u80fd\u4ea7\u751f\u63a5\u8fd1Fock\u6001\u4f46\u7f3a\u4e4f\u76f8\u5e72\u6027\u7684\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4e2d\uff0c\u5373\u4f7f\u4f7f\u7528\u53ef\u9971\u548c\u7cfb\u7edf\u7684\u7ebf\u6027\u76f8\u4f4d\u4e0d\u654f\u611f\u5438\u6536\uff0c\u4e5f\u53ea\u80fd\u4ea7\u751f\u63a5\u8fd1Fock\u6001\u7684\u72b6\u6001\uff0c\u8fd9\u4e9b\u72b6\u6001\u7f3a\u4e4f\u91cf\u5b50\u76f8\u5e72\u6027\u3002\u7814\u7a76\u65e8\u5728\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u5b9e\u73b0\u5177\u6709\u76f8\u5e72\u6027\u7684\u91cf\u5b50\u975e\u9ad8\u65af\u6001\u751f\u6210\u3002", "method": "\u5728\u539f\u6709\u7ebf\u6027\u5438\u6536\u8fc7\u7a0b\u7684\u57fa\u7840\u4e0a\uff0c\u6dfb\u52a0\u975e\u7ebf\u6027\u76f8\u4f4d\u4e0d\u654f\u611f\u5438\u6536\u8fc7\u7a0b\u3002\u8fd9\u4e24\u79cd\u88ab\u52a8\u8fc7\u7a0b\u7684\u76f8\u5e72\u53e0\u52a0\u4f7f\u5f97\u76f8\u4f4d\u7a7a\u95f4\u4e2d\u80fd\u591f\u81ea\u53d1\u4ea7\u751f\u5e76\u589e\u5f3a\u76f8\u5e72\u6027\uff0c\u65e0\u9700\u5916\u90e8\u9a71\u52a8\u3002", "result": "\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\u5438\u6536\u8fc7\u7a0b\u7684\u7ed3\u5408\u4f7f\u5f97\u539f\u672c\u65cb\u8f6c\u5bf9\u79f0\u7684Fock\u6001Wigner\u51fd\u6570\u8f6c\u53d8\u4e3a\u5177\u6709\u590d\u6742\u4e0d\u5bf9\u79f0\u7ed3\u6784\u7684\u72b6\u6001\uff0c\u4ea7\u751f\u4e86\u91cf\u5b50\u76f8\u5e72\u6027\u3002\u8fd9\u79cd\u65b9\u6cd5\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7c7b\u522b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u76f8\u4f4d\u4e0d\u654f\u611f\u5438\u6536\u8fc7\u7a0b\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u5728\u6700\u5c0f\u5316\u76f8\u4e92\u4f5c\u7528\u8981\u6c42\u7684\u60c5\u51b5\u4e0b\uff0c\u65e0\u9700\u5916\u90e8\u9a71\u52a8\u5c31\u80fd\u751f\u6210\u5177\u6709\u91cf\u5b50\u76f8\u5e72\u6027\u7684\u975e\u9ad8\u65af\u6001\uff0c\u8fd9\u4e3a\u91cf\u5b50\u6001\u5de5\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.18296", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18296", "abs": "https://arxiv.org/abs/2511.18296", "authors": ["Iman Rahimi"], "title": "Deep Learning Decision Support System for Open-Pit Mining Optimisation: GPU-Accelerated Planning Under Geological Uncertainty", "comment": "67 pages", "summary": "This study presents Part II of an AI-enhanced Decision Support System (DSS), extending Rahimi (2025, Part I) by introducing a fully uncertainty-aware optimization framework for long-term open-pit mine planning. Geological uncertainty is modelled using a Variational Autoencoder (VAE) trained on 50,000 spatial grade samples, enabling the generation of probabilistic, multi-scenario orebody realizations that preserve geological continuity and spatial correlation. These scenarios are optimized through a hybrid metaheuristic engine integrating Genetic Algorithms (GA), Large Neighborhood Search (LNS), Simulated Annealing (SA), and reinforcement-learning-based adaptive control. An \u03b5-constraint relaxation strategy governs the population exploration phase, allowing near-feasible schedule discovery early in the search and gradual tightening toward strict constraint satisfaction. GPU-parallel evaluation enables the simultaneous assessment of 65,536 geological scenarios, achieving near-real-time feasibility analysis. Results demonstrate up to 1.2 million-fold runtime improvement over IBM CPLEX and significantly higher expected NPV under geological uncertainty, confirming the DSS as a scalable and uncertainty-resilient platform for intelligent mine planning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u589e\u5f3a\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7b2c\u4e8c\u90e8\u5206\uff0c\u901a\u8fc7\u5f15\u5165\u5b8c\u5168\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u4f18\u5316\u6846\u67b6\u6765\u6269\u5c55\u957f\u671f\u9732\u5929\u77ff\u89c4\u5212\u3002\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5efa\u6a21\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\uff0c\u7ed3\u5408\u6df7\u5408\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86GPU\u5e76\u884c\u8bc4\u4f3065,536\u4e2a\u5730\u8d28\u573a\u666f\uff0c\u76f8\u6bd4IBM CPLEX\u83b7\u5f97\u4e86120\u4e07\u500d\u7684\u8fd0\u884c\u65f6\u95f4\u63d0\u5347\u548c\u66f4\u9ad8\u7684\u9884\u671f\u51c0\u73b0\u503c\u3002", "motivation": "\u6269\u5c55\u7b2c\u4e00\u90e8\u5206\u7814\u7a76\uff0c\u89e3\u51b3\u957f\u671f\u9732\u5929\u77ff\u89c4\u5212\u4e2d\u7684\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u5f00\u53d1\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u5f3a\u97e7\u6027\u7684\u667a\u80fd\u77ff\u5c71\u89c4\u5212\u5e73\u53f0\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u8bad\u7ec350,000\u4e2a\u7a7a\u95f4\u54c1\u4f4d\u6837\u672c\u751f\u6210\u6982\u7387\u6027\u591a\u573a\u666f\u77ff\u4f53\u5b9e\u73b0\uff1b\u91c7\u7528\u6df7\u5408\u5143\u542f\u53d1\u5f0f\u5f15\u64ce\u6574\u5408\u9057\u4f20\u7b97\u6cd5\u3001\u5927\u90bb\u57df\u641c\u7d22\u3001\u6a21\u62df\u9000\u706b\u548c\u5f3a\u5316\u5b66\u4e60\u81ea\u9002\u5e94\u63a7\u5236\uff1b\u03b5\u7ea6\u675f\u677e\u5f1b\u7b56\u7565\u7ba1\u7406\u79cd\u7fa4\u63a2\u7d22\uff1bGPU\u5e76\u884c\u8bc4\u4f30\u5b9e\u73b065,536\u4e2a\u5730\u8d28\u573a\u666f\u7684\u540c\u65f6\u8bc4\u4f30\u3002", "result": "\u76f8\u6bd4IBM CPLEX\u5b9e\u73b0\u4e86\u9ad8\u8fbe120\u4e07\u500d\u7684\u8fd0\u884c\u65f6\u95f4\u6539\u8fdb\uff1b\u5728\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u83b7\u5f97\u663e\u8457\u66f4\u9ad8\u7684\u9884\u671f\u51c0\u73b0\u503c\uff1b\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b9e\u65f6\u7684\u53ef\u884c\u6027\u5206\u6790\u3002", "conclusion": "\u8be5\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u88ab\u8bc1\u5b9e\u4e3a\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u5f3a\u97e7\u6027\u7684\u667a\u80fd\u77ff\u5c71\u89c4\u5212\u5e73\u53f0\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5730\u8d28\u4e0d\u786e\u5b9a\u6027\u5e76\u4f18\u5316\u957f\u671f\u89c4\u5212\u7ed3\u679c\u3002"}}
{"id": "2511.17601", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17601", "abs": "https://arxiv.org/abs/2511.17601", "authors": ["Luyang Fang", "Tao Wang", "Ping Ma", "Xiaoming Zhai"], "title": "Generalizable and Efficient Automated Scoring with a Knowledge-Distilled Multi-Task Mixture-of-Experts", "comment": null, "summary": "Automated scoring of written constructed responses typically relies on separate models per task, straining computational resources, storage, and maintenance in real-world education settings. We propose UniMoE-Guided, a knowledge-distilled multi-task Mixture-of-Experts (MoE) approach that transfers expertise from multiple task-specific large models (teachers) into a single compact, deployable model (student). The student combines (i) a shared encoder for cross-task representations, (ii) a gated MoE block that balances shared and task-specific processing, and (iii) lightweight task heads. Trained with both ground-truth labels and teacher guidance, the student matches strong task-specific models while being far more efficient to train, store, and deploy. Beyond efficiency, the MoE layer improves transfer and generalization: experts develop reusable skills that boost cross-task performance and enable rapid adaptation to new tasks with minimal additions and tuning. On nine NGSS-aligned science-reasoning tasks (seven for training/evaluation and two held out for adaptation), UniMoE-Guided attains performance comparable to per-task models while using $\\sim$6$\\times$ less storage than maintaining separate students, and $87\\times$ less than the 20B-parameter teacher. The method offers a practical path toward scalable, reliable, and resource-efficient automated scoring for classroom and large-scale assessment systems.", "AI": {"tldr": "\u63d0\u51faUniMoE-Guided\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u591a\u4e2a\u4efb\u52a1\u7279\u5b9a\u5927\u6a21\u578b\u7684\u77e5\u8bc6\u8f6c\u79fb\u5230\u5355\u4e00\u7d27\u51d1\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u81ea\u52a8\u8bc4\u5206", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u6559\u80b2\u73af\u5883\u4e2d\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u56e0\u6bcf\u4e2a\u4efb\u52a1\u9700\u8981\u5355\u72ec\u6a21\u578b\u800c\u5bfc\u81f4\u7684\u8d44\u6e90\u6d88\u8017\u3001\u5b58\u50a8\u548c\u7ef4\u62a4\u95ee\u9898", "method": "\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\u7684\u591a\u4efb\u52a1\u6df7\u5408\u4e13\u5bb6\u65b9\u6cd5\uff0c\u5305\u62ec\u5171\u4eab\u7f16\u7801\u5668\u3001\u95e8\u63a7MoE\u5757\u548c\u8f7b\u91cf\u7ea7\u4efb\u52a1\u5934\uff0c\u7ed3\u5408\u771f\u5b9e\u6807\u7b7e\u548c\u6559\u5e08\u6a21\u578b\u6307\u5bfc\u8fdb\u884c\u8bad\u7ec3", "result": "\u57289\u4e2a\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u6027\u80fd\u4e0e\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u76f8\u5f53\uff0c\u5b58\u50a8\u9700\u6c42\u6bd4\u5355\u72ec\u5b66\u751f\u6a21\u578b\u51cf\u5c11\u7ea66\u500d\uff0c\u6bd4200\u4ebf\u53c2\u6570\u6559\u5e08\u6a21\u578b\u51cf\u5c1187\u500d", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bfe\u5802\u548c\u5927\u89c4\u6a21\u8bc4\u4f30\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u9760\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u81ea\u52a8\u8bc4\u5206\u5b9e\u7528\u8def\u5f84"}}
{"id": "2511.18186", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18186", "abs": "https://arxiv.org/abs/2511.18186", "authors": ["David J. Fern\u00e1ndez C.", "O. Pav\u00f3n-Torres"], "title": "Exact solutions of the inhomogeneous nonlinear Schr\u00f6dinger equation through supersymmetric potentials", "comment": null, "summary": "By employing supersymmetric quantum mechanics, we present a general algorithm to construct supersymmetric partner potentials and hence derive exact stationary solutions of the inhomogeneous nonlinear Schr\u00f6dinger equation (INLSE). This is possible due to the connection between the INLSE and the nonlinear Schr\u00f6dinger equation (NLSE), which can be established from a treatment based on Lie point symmetries and is related with Schr\u00f6dinger equation, under certain conditions. As an illustrative example, we construct exact solutions for the INLSE through a P\u00f6sch-Teller potential with a single bound state.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u5bf9\u79f0\u91cf\u5b50\u529b\u5b66\u7684\u901a\u7528\u7b97\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u8d85\u5bf9\u79f0\u4f19\u4f34\u52bf\u5e76\u63a8\u5bfc\u975e\u5747\u5300\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u7cbe\u786e\u7a33\u6001\u89e3\u3002", "motivation": "\u901a\u8fc7\u5efa\u7acb\u975e\u5747\u5300\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u4e0e\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5229\u7528\u8d85\u5bf9\u79f0\u91cf\u5b50\u529b\u5b66\u65b9\u6cd5\u6765\u89e3\u51b3\u975e\u5747\u5300\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u7cbe\u786e\u89e3\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8d85\u5bf9\u79f0\u91cf\u5b50\u529b\u5b66\u7b97\u6cd5\uff0c\u7ed3\u5408\u674e\u70b9\u5bf9\u79f0\u6027\u5904\u7406\u65b9\u6cd5\uff0c\u6784\u5efa\u8d85\u5bf9\u79f0\u4f19\u4f34\u52bf\u6765\u6c42\u89e3\u975e\u5747\u5300\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u3002", "result": "\u6210\u529f\u63a8\u5bfc\u51fa\u975e\u5747\u5300\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u7cbe\u786e\u7a33\u6001\u89e3\uff0c\u5e76\u4ee5\u5177\u6709\u5355\u675f\u7f1a\u6001\u7684P\u00f6sch-Teller\u52bf\u4e3a\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u8d85\u5bf9\u79f0\u91cf\u5b50\u529b\u5b66\u65b9\u6cd5\u4e3a\u6c42\u89e3\u975e\u5747\u5300\u975e\u7ebf\u6027\u859b\u5b9a\u8c14\u65b9\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u901a\u7528\u7b97\u6cd5\uff0c\u80fd\u591f\u6784\u9020\u7cbe\u786e\u7684\u7a33\u6001\u89e3\u3002"}}
{"id": "2511.18198", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18198", "abs": "https://arxiv.org/abs/2511.18198", "authors": ["Wentao Yang", "Bao Yan", "Muxi Zheng", "Quanfeng Lu", "Shijie Wei", "Gui-Lu Long"], "title": "Space-Optimized and Experimental Implementations of Regev's Quantum Factoring Algorithm", "comment": null, "summary": "The integer factorization problem (IFP) underpins the security of RSA, yet becomes efficiently solvable on a quantum computer through Shor's algorithm. Regev's recent high-dimensional variant reduces the circuit size through lattice-based post-processing, but introduces substantial space overhead and lacks practical implementations. Here, we propose a qubit reuse method by intermediate-uncomputation that significantly reduces the space complexity of Regev's algorithm, inspired by reversible computing. Our basic strategy lowers the cost from \\( O(n^{3/2}) \\) to \\( O(n^{5/4}) \\), and refined strategies achieve \\( O(n \\log n) \\)which is a space lower bound within this model. Simulations demonstrate the resulting time-space trade-offs and resource scaling. Moreover, we construct and compile quantum circuits that factor \\( N = 35 \\), verifying the effectiveness of our method through noisy simulations. A more simplified experimental circuit for Regev's algorithm is executed on a superconducting quantum computer, with lattice-based post-processing successfully retrieving the factors. These results advance the practical feasibility of Regev-style quantum factoring and provide guidance for future theoretical and experimental developments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4e2d\u95f4\u975e\u8ba1\u7b97\u5b9e\u73b0\u91cf\u5b50\u6bd4\u7279\u91cd\u7528\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86Regev\u91cf\u5b50\u56e0\u5f0f\u5206\u89e3\u7b97\u6cd5\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u4eceO(n^{3/2})\u964d\u4f4e\u5230O(n^{5/4})\u751a\u81f3O(n log n)\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "Regev\u7684\u9ad8\u7ef4\u53d8\u4f53\u867d\u7136\u901a\u8fc7\u57fa\u4e8e\u683c\u7684\u540e\u7eed\u5904\u7406\u51cf\u5c11\u4e86\u7535\u8def\u89c4\u6a21\uff0c\u4f46\u5f15\u5165\u4e86\u663e\u8457\u7684\u7a7a\u95f4\u5f00\u9500\u4e14\u7f3a\u4e4f\u5b9e\u9645\u5b9e\u73b0\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u91cf\u5b50\u6bd4\u7279\u5229\u7528\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53ef\u9006\u8ba1\u7b97\u542f\u53d1\u7684\u4e2d\u95f4\u975e\u8ba1\u7b97\u65b9\u6cd5\u5b9e\u73b0\u91cf\u5b50\u6bd4\u7279\u91cd\u7528\uff0c\u57fa\u672c\u7b56\u7565\u5c06\u7a7a\u95f4\u6210\u672c\u4eceO(n^{3/2})\u964d\u4f4e\u5230O(n^{5/4})\uff0c\u7cbe\u70bc\u7b56\u7565\u8fbe\u5230O(n log n)\u7684\u7a7a\u95f4\u4e0b\u754c\u3002", "result": "\u6a21\u62df\u5c55\u793a\u4e86\u65f6\u95f4-\u7a7a\u95f4\u6743\u8861\u548c\u8d44\u6e90\u7f29\u653e\uff0c\u6784\u5efa\u5e76\u7f16\u8bd1\u4e86N=35\u7684\u91cf\u5b50\u7535\u8def\uff0c\u901a\u8fc7\u566a\u58f0\u6a21\u62df\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002\u5728\u8d85\u5bfc\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u6267\u884c\u4e86\u7b80\u5316\u5b9e\u9a8c\u7535\u8def\uff0c\u57fa\u4e8e\u683c\u7684\u540e\u7eed\u5904\u7406\u6210\u529f\u6062\u590d\u4e86\u56e0\u5b50\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u63a8\u8fdb\u4e86Regev\u98ce\u683c\u91cf\u5b50\u56e0\u5f0f\u5206\u89e3\u7684\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765\u7684\u7406\u8bba\u548c\u5b9e\u9a8c\u53d1\u5c55\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2511.18302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18302", "abs": "https://arxiv.org/abs/2511.18302", "authors": ["Mohan Reddy"], "title": "The Catastrophic Paradox of Human Cognitive Frameworks in Large Language Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM Incompatibility", "comment": null, "summary": "This investigation presents an empirical analysis of the incompatibility between human psychometric frameworks and Large Language Model evaluation. Through systematic assessment of nine frontier models including GPT-5, Claude Opus 4.1, and Gemini 3 Pro Preview using the Cattell-Horn-Carroll theory of intelligence, we identify a paradox that challenges the foundations of cross-substrate cognitive evaluation. Our results show that models achieving above-average human IQ scores ranging from 85.0 to 121.4 simultaneously exhibit binary accuracy rates approaching zero on crystallized knowledge tasks, with an overall judge-binary correlation of r = 0.175 (p = 0.001, n = 1800). This disconnect appears most strongly in the crystallized intelligence domain, where every evaluated model achieved perfect binary accuracy while judge scores ranged from 25 to 62 percent, which cannot occur under valid measurement conditions. Using statistical analyses including Item Response Theory modeling, cross-vendor judge validation, and paradox severity indexing, we argue that this disconnect reflects a category error in applying biological cognitive architectures to transformer-based systems. The implications extend beyond methodology to challenge assumptions about intelligence, measurement, and anthropomorphic biases in AI evaluation. We propose a framework for developing native machine cognition assessments that recognize the non-human nature of artificial intelligence.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5b58\u5728\u4e0d\u517c\u5bb9\u6027\uff0c\u6a21\u578b\u5728\u83b7\u5f97\u9ad8\u4e8e\u5e73\u5747\u4eba\u7c7bIQ\u5206\u6570\u7684\u540c\u65f6\uff0c\u5728\u6676\u4f53\u77e5\u8bc6\u4efb\u52a1\u4e0a\u7684\u4e8c\u5143\u51c6\u786e\u7387\u63a5\u8fd1\u96f6\uff0c\u8fd9\u6311\u6218\u4e86\u8de8\u57fa\u8d28\u8ba4\u77e5\u8bc4\u4f30\u7684\u57fa\u7840\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5b9e\u8bc1\u5206\u6790\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e4b\u95f4\u7684\u4e0d\u517c\u5bb9\u6027\uff0c\u6311\u6218\u8de8\u57fa\u8d28\u8ba4\u77e5\u8bc4\u4f30\u7684\u57fa\u672c\u5047\u8bbe\u3002", "method": "\u4f7f\u7528Cattell-Horn-Carroll\u667a\u529b\u7406\u8bba\u7cfb\u7edf\u8bc4\u4f30\u4e5d\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u5305\u62ecGPT-5\u3001Claude Opus 4.1\u548cGemini 3 Pro Preview\uff0c\u91c7\u7528\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u5efa\u6a21\u3001\u8de8\u4f9b\u5e94\u5546\u8bc4\u5224\u9a8c\u8bc1\u548c\u6096\u8bba\u4e25\u91cd\u6027\u6307\u6570\u7b49\u7edf\u8ba1\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u83b7\u5f9785.0-121.4\u7684\u4eba\u7c7bIQ\u5206\u6570\uff0c\u4f46\u6676\u4f53\u77e5\u8bc6\u4efb\u52a1\u7684\u4e8c\u5143\u51c6\u786e\u7387\u63a5\u8fd1\u96f6\uff0c\u8bc4\u5224-\u4e8c\u5143\u76f8\u5173\u6027r=0.175(p=0.001)\u3002\u5728\u6676\u4f53\u667a\u529b\u9886\u57df\uff0c\u6240\u6709\u6a21\u578b\u90fd\u83b7\u5f97\u5b8c\u7f8e\u7684\u4e8c\u5143\u51c6\u786e\u7387\uff0c\u800c\u8bc4\u5224\u5206\u6570\u4ec5\u4e3a25-62%\u3002", "conclusion": "\u8fd9\u79cd\u8131\u8282\u53cd\u6620\u4e86\u5c06\u751f\u7269\u8ba4\u77e5\u67b6\u6784\u5e94\u7528\u4e8e\u57fa\u4e8eTransformer\u7cfb\u7edf\u7684\u7c7b\u522b\u9519\u8bef\uff0c\u6311\u6218\u4e86\u5173\u4e8e\u667a\u529b\u3001\u6d4b\u91cf\u548cAI\u8bc4\u4f30\u4e2d\u62df\u4eba\u5316\u504f\u89c1\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u5f00\u53d1\u539f\u751f\u673a\u5668\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\u7684\u5efa\u8bae\u3002"}}
{"id": "2511.18211", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18211", "abs": "https://arxiv.org/abs/2511.18211", "authors": ["J. T. Hansen", "F. Gargiulo", "J. B. Mathiassen", "J. H. M\u00fcller", "E. S. Polzik", "J. -B. B\u00e9guin"], "title": "Deterministic coupling of ultracold atomic lattice to a suspended photonic waveguide", "comment": "8 pages, 4 figures", "summary": "The deterministic control of light-matter interactions at the level of single particles and on subwavelength scales is central to quantum optics and hybrid integrated quantum technologies. However, combining cold atom research with nanophotonic devices in a fully controllable platform remains a major experimental challenge. Here, we demonstrate the deterministic coupling of an ultracold atomic lattice to light propagating in suspended on-chip photonic circuits. These capabilities open avenues to address scalability challenges in neutral-atom quantum computers and simulators, enabling fast optical readout, efficient and subwavelength non-diffracting interaction zones, and genuine compatibility with integrated solid-state photon sources, detectors, and stop-band modulators. Beyond controllable quantum matter, the platform also enables in-situ imaging of evanescent fields of light and nanoscale structures, including prospects for three-dimensional scanning microscopy with non-invasive single-atom probes for quantum sensing applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5c06\u8d85\u51b7\u539f\u5b50\u6676\u683c\u4e0e\u7247\u4e0a\u5149\u5b50\u7535\u8def\u786e\u5b9a\u6027\u8026\u5408\u7684\u5e73\u53f0\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u548c\u4f20\u611f\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5728\u5355\u7c92\u5b50\u6c34\u5e73\u548c\u4e9a\u6ce2\u957f\u5c3a\u5ea6\u4e0a\u786e\u5b9a\u6027\u63a7\u5236\u5149-\u7269\u8d28\u76f8\u4e92\u4f5c\u7528\u662f\u91cf\u5b50\u5149\u5b66\u548c\u96c6\u6210\u91cf\u5b50\u6280\u672f\u7684\u6838\u5fc3\uff0c\u4f46\u5c06\u51b7\u539f\u5b50\u7814\u7a76\u4e0e\u7eb3\u7c73\u5149\u5b50\u5668\u4ef6\u5728\u5b8c\u5168\u53ef\u63a7\u5e73\u53f0\u4e0a\u7ed3\u5408\u4ecd\u662f\u4e00\u4e2a\u91cd\u5927\u5b9e\u9a8c\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5c06\u8d85\u51b7\u539f\u5b50\u6676\u683c\u4e0e\u60ac\u6d6e\u7247\u4e0a\u5149\u5b50\u7535\u8def\u4e2d\u7684\u5149\u4f20\u64ad\u8fdb\u884c\u786e\u5b9a\u6027\u8026\u5408\u6765\u5b9e\u73b0\u3002", "result": "\u8be5\u5e73\u53f0\u80fd\u591f\u5b9e\u73b0\u5feb\u901f\u5149\u5b66\u8bfb\u53d6\u3001\u9ad8\u6548\u4e9a\u6ce2\u957f\u975e\u884d\u5c04\u76f8\u4e92\u4f5c\u7528\u533a\u57df\uff0c\u5e76\u4e0e\u96c6\u6210\u56fa\u6001\u5149\u5b50\u6e90\u3001\u63a2\u6d4b\u5668\u548c\u963b\u5e26\u8c03\u5236\u5668\u771f\u6b63\u517c\u5bb9\u3002", "conclusion": "\u8be5\u5e73\u53f0\u4e0d\u4ec5\u4e3a\u53ef\u63a7\u91cf\u5b50\u7269\u8d28\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u8fd8\u652f\u6301\u5149\u500f\u901d\u573a\u548c\u7eb3\u7c73\u7ed3\u6784\u7684\u539f\u4f4d\u6210\u50cf\uff0c\u6709\u671b\u7528\u4e8e\u91cf\u5b50\u4f20\u611f\u5e94\u7528\u4e2d\u7684\u975e\u4fb5\u5165\u6027\u5355\u539f\u5b50\u63a2\u9488\u4e09\u7ef4\u626b\u63cf\u663e\u5fae\u955c\u3002"}}
{"id": "2511.17605", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17605", "abs": "https://arxiv.org/abs/2511.17605", "authors": ["Agnideep Aich", "Sameera Hewage", "Md Monzur Murshed"], "title": "Copula Based Fusion of Clinical and Genomic Machine Learning Risk Scores for Breast Cancer Risk Stratification", "comment": null, "summary": "Clinical and genomic models are both used to predict breast cancer outcomes, but they are often combined using simple linear rules that do not account for how their risk scores relate, especially at the extremes. Using the METABRIC breast cancer cohort, we studied whether directly modeling the joint relationship between clinical and genomic machine learning risk scores could improve risk stratification for 5-year cancer-specific mortality. We created a binary 5-year cancer-death outcome and defined two sets of predictors: a clinical set (demographic, tumor, and treatment variables) and a genomic set (gene-expression $z$-scores). We trained several supervised classifiers, such as Random Forest and XGBoost, and used 5-fold cross-validated predicted probabilities as unbiased risk scores. These scores were converted to pseudo-observations on $(0,1)^2$ to fit Gaussian, Clayton, and Gumbel copulas. Clinical models showed good discrimination (AUC 0.783), while genomic models had moderate performance (AUC 0.681). The joint distribution was best captured by a Gaussian copula (bootstrap $p=0.997$), which suggests a symmetric, moderately strong positive relationship. When we grouped patients based on this relationship, Kaplan-Meier curves showed clear differences: patients who were high-risk in both clinical and genomic scores had much poorer survival than those high-risk in only one set. These results show that copula-based fusion works in real-world cohorts and that considering dependencies between scores can better identify patient subgroups with the worst prognosis.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528METABRIC\u4e73\u817a\u764c\u961f\u5217\uff0c\u901a\u8fc7copula\u65b9\u6cd5\u76f4\u63a5\u5efa\u6a21\u4e34\u5e8a\u548c\u57fa\u56e0\u7ec4\u673a\u5668\u5b66\u4e60\u98ce\u9669\u8bc4\u5206\u7684\u8054\u5408\u5173\u7cfb\uff0c\u4ee5\u6539\u8fdb5\u5e74\u764c\u75c7\u7279\u5f02\u6027\u6b7b\u4ea1\u7387\u7684\u98ce\u9669\u5206\u5c42\u3002", "motivation": "\u4e34\u5e8a\u548c\u57fa\u56e0\u7ec4\u6a21\u578b\u901a\u5e38\u4f7f\u7528\u7b80\u5355\u7684\u7ebf\u6027\u89c4\u5219\u7ed3\u5408\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u98ce\u9669\u8bc4\u5206\u5728\u6781\u7aef\u60c5\u51b5\u4e0b\u7684\u76f8\u4e92\u5173\u7cfb\uff0c\u9650\u5236\u4e86\u98ce\u9669\u5206\u5c42\u7684\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u968f\u673a\u68ee\u6797\u548cXGBoost\u7b49\u76d1\u7763\u5206\u7c7b\u5668\u8bad\u7ec3\u4e34\u5e8a\u548c\u57fa\u56e0\u7ec4\u6a21\u578b\uff0c\u901a\u8fc75\u6298\u4ea4\u53c9\u9a8c\u8bc1\u83b7\u5f97\u65e0\u504f\u98ce\u9669\u8bc4\u5206\uff0c\u7136\u540e\u4f7f\u7528\u9ad8\u65af\u3001Clayton\u548cGumbel copula\u62df\u5408\u8054\u5408\u5206\u5e03\u3002", "result": "\u4e34\u5e8a\u6a21\u578b\u533a\u5206\u5ea6\u826f\u597d\uff08AUC 0.783\uff09\uff0c\u57fa\u56e0\u7ec4\u6a21\u578b\u8868\u73b0\u4e2d\u7b49\uff08AUC 0.681\uff09\u3002\u9ad8\u65afcopula\u6700\u4f73\u6355\u6349\u8054\u5408\u5206\u5e03\uff08bootstrap p=0.997\uff09\uff0c\u663e\u793a\u5bf9\u79f0\u3001\u4e2d\u7b49\u5f3a\u5ea6\u7684\u6b63\u76f8\u5173\u5173\u7cfb\u3002\u57fa\u4e8e\u6b64\u5173\u7cfb\u7684\u60a3\u8005\u5206\u7ec4\u663e\u793a\uff0c\u4e34\u5e8a\u548c\u57fa\u56e0\u7ec4\u53cc\u9ad8\u98ce\u9669\u60a3\u8005\u751f\u5b58\u7387\u663e\u8457\u66f4\u5dee\u3002", "conclusion": "copula\u878d\u5408\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u961f\u5217\u4e2d\u6709\u6548\uff0c\u8003\u8651\u8bc4\u5206\u95f4\u4f9d\u8d56\u5173\u7cfb\u80fd\u66f4\u597d\u8bc6\u522b\u9884\u540e\u6700\u5dee\u7684\u60a3\u8005\u4e9a\u7ec4\u3002"}}
{"id": "2511.17606", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17606", "abs": "https://arxiv.org/abs/2511.17606", "authors": ["Ningling Ge", "Sicheng Dai", "Yu Zhu", "Shan Yu"], "title": "Energy-based Autoregressive Generation for Neural Population Dynamics", "comment": null, "summary": "Understanding brain function represents a fundamental goal in neuroscience, with critical implications for therapeutic interventions and neural engineering applications. Computational modeling provides a quantitative framework for accelerating this understanding, but faces a fundamental trade-off between computational efficiency and high-fidelity modeling. To address this limitation, we introduce a novel Energy-based Autoregressive Generation (EAG) framework that employs an energy-based transformer learning temporal dynamics in latent space through strictly proper scoring rules, enabling efficient generation with realistic population and single-neuron spiking statistics. Evaluation on synthetic Lorenz datasets and two Neural Latents Benchmark datasets (MC_Maze and Area2_bump) demonstrates that EAG achieves state-of-the-art generation quality with substantial computational efficiency improvements, particularly over diffusion-based methods. Beyond optimal performance, conditional generation applications show two capabilities: generalizing to unseen behavioral contexts and improving motor brain-computer interface decoding accuracy using synthetic neural data. These results demonstrate the effectiveness of energy-based modeling for neural population dynamics with applications in neuroscience research and neural engineering. Code is available at https://github.com/NinglingGe/Energy-based-Autoregressive-Generation-for-Neural-Population-Dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u7684\u81ea\u56de\u5f52\u751f\u6210\uff08EAG\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u80fd\u91cf\u53d8\u6362\u5668\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b66\u4e60\u65f6\u95f4\u52a8\u6001\uff0c\u5b9e\u73b0\u9ad8\u6548\u751f\u6210\u5177\u6709\u771f\u5b9e\u7fa4\u4f53\u548c\u5355\u795e\u7ecf\u5143\u53d1\u653e\u7edf\u8ba1\u7279\u6027\u7684\u795e\u7ecf\u6570\u636e\u3002", "motivation": "\u7406\u89e3\u5927\u8111\u529f\u80fd\u662f\u795e\u7ecf\u79d1\u5b66\u7684\u57fa\u672c\u76ee\u6807\uff0c\u4f46\u8ba1\u7b97\u5efa\u6a21\u9762\u4e34\u8ba1\u7b97\u6548\u7387\u4e0e\u9ad8\u4fdd\u771f\u5efa\u6a21\u4e4b\u95f4\u7684\u6743\u8861\u9650\u5236\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u80fd\u91cf\u7684\u53d8\u6362\u5668\uff0c\u901a\u8fc7\u4e25\u683c\u9002\u5f53\u8bc4\u5206\u89c4\u5219\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b66\u4e60\u65f6\u95f4\u52a8\u6001\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u81ea\u56de\u5f52\u751f\u6210\u3002", "result": "\u5728\u5408\u6210Lorenz\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u795e\u7ecf\u6f5c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cEAG\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u6761\u4ef6\u751f\u6210\u5e94\u7528\u4e2d\u80fd\u591f\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u884c\u4e3a\u60c5\u5883\u5e76\u63d0\u9ad8\u8fd0\u52a8\u8111\u673a\u63a5\u53e3\u89e3\u7801\u7cbe\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u80fd\u91cf\u7684\u5efa\u6a21\u5bf9\u4e8e\u795e\u7ecf\u7fa4\u4f53\u52a8\u6001\u662f\u6709\u6548\u7684\uff0c\u5728\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u548c\u795e\u7ecf\u5de5\u7a0b\u4e2d\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.18318", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18318", "abs": "https://arxiv.org/abs/2511.18318", "authors": ["Allison Brattley", "Tomas Opatrny", "Kunal K. Das"], "title": "General Machine Learning Algorithm for Quantum Teleportation", "comment": "7 pages, 4 figures", "summary": "We present a general algorithm, based on machine learning, which can create optimal unitary operators to implement quantum teleportation in any system with well-defined set of measurements in a relevant entangled basis. We illustrate it with a collective spin model and demonstrate its versatility by applying it to teloportation of single and multiple qubit states, coherent and Dicke states, and for systems with prior distributions and unequal dimensions. All cases display significant regimes of quantum advantage over corresponding classical schemes with no entanglement. The algorithm offers the flexibility to choose a balance between target fidelity and computational cost.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u901a\u7528\u7b97\u6cd5\uff0c\u53ef\u4e3a\u4efb\u4f55\u5177\u6709\u660e\u786e\u5b9a\u4e49\u7ea0\u7f20\u57fa\u6d4b\u91cf\u7684\u7cfb\u7edf\u521b\u5efa\u6700\u4f18\u5e7a\u6b63\u7b97\u5b50\u6765\u5b9e\u73b0\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u3002\u8be5\u7b97\u6cd5\u5728\u96c6\u4f53\u81ea\u65cb\u6a21\u578b\u4e2d\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5904\u7406\u5355/\u591a\u91cf\u5b50\u6bd4\u7279\u6001\u3001\u76f8\u5e72\u6001\u3001Dicke\u6001\u4ee5\u53ca\u5177\u6709\u5148\u9a8c\u5206\u5e03\u548c\u4e0d\u7b49\u7ef4\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\uff0c\u5728\u6240\u6709\u6848\u4f8b\u4e2d\u90fd\u663e\u793a\u51fa\u4f18\u4e8e\u65e0\u7ea0\u7f20\u7ecf\u5178\u65b9\u6848\u7684\u91cf\u5b50\u4f18\u52bf\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u901a\u7528\u7684\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u65b9\u6cd5\uff0c\u80fd\u591f\u9002\u5e94\u5404\u79cd\u91cf\u5b50\u7cfb\u7edf\u548c\u72b6\u6001\u7c7b\u578b\uff0c\u540c\u65f6\u63d0\u4f9b\u5728\u76ee\u6807\u4fdd\u771f\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u7075\u6d3b\u6743\u8861\u3002", "method": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u5e7a\u6b63\u7b97\u5b50\u6765\u5b9e\u73b0\u91cf\u5b50\u9690\u5f62\u4f20\u6001\uff0c\u9002\u7528\u4e8e\u5177\u6709\u660e\u786e\u5b9a\u4e49\u7ea0\u7f20\u57fa\u6d4b\u91cf\u7684\u4efb\u4f55\u7cfb\u7edf\u3002", "result": "\u5728\u96c6\u4f53\u81ea\u65cb\u6a21\u578b\u4e2d\u6210\u529f\u9a8c\u8bc1\uff0c\u80fd\u591f\u5904\u7406\u5355\u91cf\u5b50\u6bd4\u7279\u6001\u3001\u591a\u91cf\u5b50\u6bd4\u7279\u6001\u3001\u76f8\u5e72\u6001\u3001Dicke\u6001\u7b49\u591a\u79cd\u91cf\u5b50\u72b6\u6001\uff0c\u5e76\u4e14\u5728\u5177\u6709\u5148\u9a8c\u5206\u5e03\u548c\u4e0d\u7b49\u7ef4\u7cfb\u7edf\u4e2d\u90fd\u8868\u73b0\u51fa\u663e\u8457\u4f18\u4e8e\u65e0\u7ea0\u7f20\u7ecf\u5178\u65b9\u6848\u7684\u91cf\u5b50\u4f18\u52bf\u3002", "conclusion": "\u8be5\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e3a\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u5404\u79cd\u91cf\u5b50\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\uff0c\u540c\u65f6\u5141\u8bb8\u5728\u4fdd\u771f\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2511.17610", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17610", "abs": "https://arxiv.org/abs/2511.17610", "authors": ["Leonardo Rossi", "Bruno Rodrigues"], "title": "Finding Pre-Injury Patterns in Triathletes from Lifestyle, Recovery and Load Dynamics Features", "comment": null, "summary": "Triathlon training, which involves high-volume swimming, cycling, and running, places athletes at substantial risk for overuse injuries due to repetitive physiological stress. Current injury prediction approaches primarily rely on training load metrics, often neglecting critical factors such as sleep quality, stress, and individual lifestyle patterns that significantly influence recovery and injury susceptibility.\n  We introduce a novel synthetic data generation framework tailored explicitly for triathlon. This framework generates physiologically plausible athlete profiles, simulates individualized training programs that incorporate periodization and load-management principles, and integrates daily-life factors such as sleep quality, stress levels, and recovery states. We evaluated machine learning models (LASSO, Random Forest, and XGBoost) showing high predictive performance (AUC up to 0.86), identifying sleep disturbances, heart rate variability, and stress as critical early indicators of injury risk. This wearable-driven approach not only enhances injury prediction accuracy but also provides a practical solution to overcoming real-world data limitations, offering a pathway toward a holistic, context-aware athlete monitoring.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u94c1\u4eba\u4e09\u9879\u8bad\u7ec3\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u7761\u7720\u8d28\u91cf\u3001\u538b\u529b\u6c34\u5e73\u548c\u6062\u590d\u72b6\u6001\u7b49\u65e5\u5e38\u751f\u6d3b\u56e0\u7d20\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u8fbe0.86 AUC\u7684\u635f\u4f24\u98ce\u9669\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u94c1\u4eba\u4e09\u9879\u635f\u4f24\u9884\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8bad\u7ec3\u8d1f\u8377\u6307\u6807\uff0c\u5ffd\u89c6\u4e86\u7761\u7720\u8d28\u91cf\u3001\u538b\u529b\u548c\u4e2a\u4f53\u751f\u6d3b\u65b9\u5f0f\u7b49\u5173\u952e\u56e0\u7d20\u5bf9\u6062\u590d\u548c\u635f\u4f24\u6613\u611f\u6027\u7684\u663e\u8457\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u94c1\u4eba\u4e09\u9879\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u751f\u6210\u751f\u7406\u4e0a\u5408\u7406\u7684\u8fd0\u52a8\u5458\u6863\u6848\uff0c\u6a21\u62df\u5305\u542b\u5468\u671f\u5316\u548c\u8d1f\u8377\u7ba1\u7406\u539f\u5219\u7684\u4e2a\u6027\u5316\u8bad\u7ec3\u8ba1\u5212\uff0c\u5e76\u6574\u5408\u7761\u7720\u8d28\u91cf\u3001\u538b\u529b\u6c34\u5e73\u548c\u6062\u590d\u72b6\u6001\u7b49\u65e5\u5e38\u751f\u6d3b\u56e0\u7d20\u3002", "result": "\u8bc4\u4f30\u4e86LASSO\u3001\u968f\u673a\u68ee\u6797\u548cXGBoost\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u663e\u793a\u51fa\u9ad8\u9884\u6d4b\u6027\u80fd\uff08AUC\u9ad8\u8fbe0.86\uff09\uff0c\u8bc6\u522b\u51fa\u7761\u7720\u969c\u788d\u3001\u5fc3\u7387\u53d8\u5f02\u6027\u548c\u538b\u529b\u4f5c\u4e3a\u635f\u4f24\u98ce\u9669\u7684\u5173\u952e\u65e9\u671f\u6307\u6807\u3002", "conclusion": "\u8fd9\u79cd\u53ef\u7a7f\u6234\u8bbe\u5907\u9a71\u52a8\u7684\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u635f\u4f24\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u4e3a\u514b\u670d\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u9650\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u6574\u4f53\u3001\u60c5\u5883\u611f\u77e5\u7684\u8fd0\u52a8\u5458\u76d1\u6d4b\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2511.18327", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18327", "abs": "https://arxiv.org/abs/2511.18327", "authors": ["Hao Liao", "Xuanqin Huang", "Ping Wang"], "title": "Universal learning of nonlocal entropy via local correlations in non-equilibrium quantum states", "comment": null, "summary": "Characterizing the nonlocal nature of quantum states is a central challenge in the practical application of large-scale quantum computation and simulation. Quantum mutual information (QMI), a fundamental nonlocal measure, plays a key role in quantifying entanglement and has become increasingly important in studying nonequilibrium quantum many-body phenomena, such as many-body localization and thermalization. However, experimental measurement of QMI remains extremely difficult, particularly for nonequilibrium states, which are more complex than ground states. In this Letter, we employ a multilayer perceptron (MLP) to establish a universal mapping between the QMI and local correlations only up to second order for nonequilibrium states generated by quenches in a one-dimensional disordered XXZ model. Our approach provides a practical method for experimentally extracting QMI, readily applicable in platforms such as superconducting qubits. Moreover, this work will establishes a general framework for reconstructing other nonlocal observables, including Fisher information and out-of-time-ordered correlators.", "AI": {"tldr": "\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\u5efa\u7acb\u91cf\u5b50\u4e92\u4fe1\u606f\u4e0e\u4ec5\u4e8c\u9636\u5c40\u90e8\u5173\u8054\u4e4b\u95f4\u7684\u901a\u7528\u6620\u5c04\uff0c\u4e3a\u5b9e\u9a8c\u6d4b\u91cf\u975e\u5e73\u8861\u6001\u91cf\u5b50\u4e92\u4fe1\u606f\u63d0\u4f9b\u5b9e\u7528\u65b9\u6cd5", "motivation": "\u91cf\u5b50\u4e92\u4fe1\u606f\u662f\u91cf\u5316\u7ea0\u7f20\u7684\u91cd\u8981\u975e\u5c40\u57df\u5ea6\u91cf\uff0c\u4f46\u5728\u5b9e\u9a8c\u4e2d\u6d4b\u91cf\u56f0\u96be\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6bd4\u57fa\u6001\u66f4\u590d\u6742\u7684\u975e\u5e73\u8861\u6001", "method": "\u5728\u4e8c\u7ef4\u65e0\u5e8fXXZ\u6a21\u578b\u4e2d\uff0c\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\u5efa\u7acb\u91cf\u5b50\u4e92\u4fe1\u606f\u4e0e\u4ec5\u4e8c\u9636\u5c40\u90e8\u5173\u8054\u4e4b\u95f4\u7684\u901a\u7528\u6620\u5c04", "result": "\u5f00\u53d1\u51fa\u4ece\u5c40\u90e8\u5173\u8054\u63d0\u53d6\u91cf\u5b50\u4e92\u4fe1\u606f\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8d85\u5bfc\u91cf\u5b50\u6bd4\u7279\u7b49\u5b9e\u9a8c\u5e73\u53f0", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u91cd\u5efa\u5176\u4ed6\u975e\u5c40\u57df\u53ef\u89c2\u6d4b\u91cf\uff08\u5982\u8d39\u820d\u5c14\u4fe1\u606f\u548c\u65f6\u5e8f\u65e0\u5e8f\u5173\u8054\u51fd\u6570\uff09\u5efa\u7acb\u4e86\u901a\u7528\u6846\u67b6"}}
{"id": "2511.18375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18375", "abs": "https://arxiv.org/abs/2511.18375", "authors": ["Joachim Diederich"], "title": "Progressive Localisation in Localist LLMs", "comment": null, "summary": "This paper demonstrates that progressive localization, the gradual increase of attention locality from early distributed layers to late localized layers, represents the optimal architecture for creating interpretable large language models while preserving performance. Through systematic experimentation with GPT-2 fine tuned on The Psychology of Artificial Superintelligence, we evaluate seven locality configurations ranging from fully distributed to strictly localist, with five progressive schedules implementing polynomial increases (linear through quintic). Our key finding is that late-layer localization is critical for AI safety applications: the progressive quintic schedule achieves perplexity of 14.64, only 1.89 times worse than the fully distributed baseline while providing interpretable attention patterns in output layers where safety-critical decisions are made. This represents an 84.2% improvement over previous localist implementations and narrows the performance gap from 6.6 times to 1.89 times. The systematic relationship between localization schedule steepness and performance validates the hypothesis that early layers require distributed processing for feature extraction while late layers benefit from localized, interpretable attention for decision-making. These findings establish progressive localization as the principled approach for building transparent AI systems in safety-critical domains, where human oversight of model reasoning is essential.", "AI": {"tldr": "\u6e10\u8fdb\u5b9a\u4f4d\uff08\u4ece\u65e9\u671f\u5206\u5e03\u5f0f\u5c42\u5230\u540e\u671f\u5c40\u90e8\u5316\u5c42\u9010\u6e10\u589e\u52a0\u6ce8\u610f\u529b\u5c40\u90e8\u6027\uff09\u662f\u521b\u5efa\u53ef\u89e3\u91ca\u5927\u8bed\u8a00\u6a21\u578b\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u7684\u6700\u4f73\u67b6\u6784\u3002\u901a\u8fc7GPT-2\u5728\u300a\u4eba\u5de5\u8d85\u667a\u80fd\u5fc3\u7406\u5b66\u300b\u4e0a\u7684\u5b9e\u9a8c\uff0c\u53d1\u73b0\u540e\u671f\u5c42\u5b9a\u4f4d\u5bf9AI\u5b89\u5168\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4e94\u6b21\u6e10\u8fdb\u8c03\u5ea6\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u3002", "motivation": "\u4e3a\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u6784\u5efa\u900f\u660eAI\u7cfb\u7edf\uff0c\u9700\u8981\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u4eba\u7c7b\u80fd\u591f\u76d1\u7763\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528GPT-2\u5728\u300a\u4eba\u5de5\u8d85\u667a\u80fd\u5fc3\u7406\u5b66\u300b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u8bc4\u4f307\u79cd\u5c40\u90e8\u6027\u914d\u7f6e\uff08\u4ece\u5b8c\u5168\u5206\u5e03\u5f0f\u5230\u4e25\u683c\u5c40\u90e8\u5316\uff09\u548c5\u79cd\u6e10\u8fdb\u8c03\u5ea6\uff08\u7ebf\u6027\u5230\u4e94\u6b21\u591a\u9879\u5f0f\u589e\u52a0\uff09\u3002", "result": "\u4e94\u6b21\u6e10\u8fdb\u8c03\u5ea6\u8fbe\u5230\u56f0\u60d1\u5ea614.64\uff0c\u4ec5\u6bd4\u5b8c\u5168\u5206\u5e03\u5f0f\u57fa\u7ebf\u5dee1.89\u500d\uff0c\u540c\u65f6\u5728\u8f93\u51fa\u5c42\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u6bd4\u4e4b\u524d\u5c40\u90e8\u5316\u5b9e\u73b0\u6539\u8fdb84.2%\uff0c\u6027\u80fd\u5dee\u8ddd\u4ece6.6\u500d\u7f29\u5c0f\u52301.89\u500d\u3002", "conclusion": "\u6e10\u8fdb\u5b9a\u4f4d\u662f\u6784\u5efa\u5b89\u5168\u5173\u952e\u9886\u57df\u900f\u660eAI\u7cfb\u7edf\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u65e9\u671f\u5c42\u9700\u8981\u5206\u5e03\u5f0f\u5904\u7406\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u540e\u671f\u5c42\u53d7\u76ca\u4e8e\u5c40\u90e8\u5316\u3001\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u8fdb\u884c\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2511.18345", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18345", "abs": "https://arxiv.org/abs/2511.18345", "authors": ["Luca Ornigotti", "Darren W. Moore", "Radim Filip"], "title": "Nonlinear stochastic and quantum motion from Coulomb forces", "comment": null, "summary": "Controllable nonlinear quantum interactions are a much sought after target for modern quantum technologies. They are typically difficult and costly to engineer for bespoke purposes. However controllable nonlinearities may have always been in reach via the natural and fundamental forces between quantum particles. The Coulomb interaction between charged particles is the simplest example. We show that after eliminating the harmonic part of the Coulomb force by an auxiliary linear force, the remaining reciprocal nonlinear part results in a directly observable non-reciprocal nonlinear effect: increase of the signal-to-noise ratio (SNR) of the coherent displacement of one particle, driven by the position noise, or uncertainty in quantum regime, in another particle. This essential evidence of nonlinear forces is present across large ranges of trap frequency and mass scales, as well as visible in both stochastic and quantum regimes.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86\u901a\u8fc7\u6d88\u9664\u5e93\u4ed1\u529b\u7684\u8c10\u6ce2\u90e8\u5206\uff0c\u5269\u4f59\u7684\u975e\u7ebf\u6027\u90e8\u5206\u4f1a\u4ea7\u751f\u53ef\u89c2\u6d4b\u7684\u975e\u4e92\u6613\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u5373\u4e00\u4e2a\u7c92\u5b50\u7684\u4f4d\u7f6e\u566a\u58f0\u6216\u91cf\u5b50\u4e0d\u786e\u5b9a\u6027\u4f1a\u63d0\u9ad8\u53e6\u4e00\u4e2a\u7c92\u5b50\u76f8\u5e72\u4f4d\u79fb\u7684\u4fe1\u566a\u6bd4\u3002", "motivation": "\u53ef\u63a7\u975e\u7ebf\u6027\u91cf\u5b50\u76f8\u4e92\u4f5c\u7528\u662f\u73b0\u4ee3\u91cf\u5b50\u6280\u672f\u8ffd\u6c42\u7684\u76ee\u6807\uff0c\u4f46\u901a\u5e38\u96be\u4ee5\u5b9a\u5236\u5b9e\u73b0\u3002\u7136\u800c\uff0c\u901a\u8fc7\u91cf\u5b50\u7c92\u5b50\u95f4\u7684\u57fa\u672c\u529b\uff08\u5982\u5e93\u4ed1\u76f8\u4e92\u4f5c\u7528\uff09\u53ef\u80fd\u5b9e\u73b0\u53ef\u63a7\u975e\u7ebf\u6027\u3002", "method": "\u901a\u8fc7\u8f85\u52a9\u7ebf\u6027\u529b\u6d88\u9664\u5e93\u4ed1\u529b\u7684\u8c10\u6ce2\u90e8\u5206\uff0c\u4fdd\u7559\u5269\u4f59\u7684\u975e\u7ebf\u6027\u90e8\u5206\uff0c\u7814\u7a76\u5176\u5bf9\u7c92\u5b50\u95f4\u76f8\u5e72\u4f4d\u79fb\u4fe1\u566a\u6bd4\u7684\u5f71\u54cd\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u9677\u9631\u9891\u7387\u548c\u8d28\u91cf\u5c3a\u5ea6\u8303\u56f4\u5185\uff0c\u975e\u7ebf\u6027\u529b\u90fd\u4f1a\u5bfc\u81f4\u4e00\u4e2a\u7c92\u5b50\u7684\u4f4d\u7f6e\u566a\u58f0\u63d0\u9ad8\u53e6\u4e00\u4e2a\u7c92\u5b50\u76f8\u5e72\u4f4d\u79fb\u7684\u4fe1\u566a\u6bd4\uff0c\u8fd9\u79cd\u73b0\u8c61\u5728\u968f\u673a\u548c\u91cf\u5b50\u4f53\u7cfb\u4e2d\u5747\u53ef\u89c1\u3002", "conclusion": "\u57fa\u672c\u529b\uff08\u5982\u5e93\u4ed1\u76f8\u4e92\u4f5c\u7528\uff09\u4e2d\u7684\u975e\u7ebf\u6027\u90e8\u5206\u53ef\u4ee5\u4ea7\u751f\u76f4\u63a5\u53ef\u89c2\u6d4b\u7684\u975e\u4e92\u6613\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u4e3a\u91cf\u5b50\u6280\u672f\u4e2d\u7684\u53ef\u63a7\u975e\u7ebf\u6027\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.17616", "categories": ["cs.LG", "cs.AI", "math.DG"], "pdf": "https://arxiv.org/pdf/2511.17616", "abs": "https://arxiv.org/abs/2511.17616", "authors": ["Alexander Strunk", "Roland Assam"], "title": "Tensor Gauge Flow Models", "comment": null, "summary": "This paper introduces Tensor Gauge Flow Models, a new class of Generative Flow Models that generalize Gauge Flow Models and Higher Gauge Flow Models by incorporating higher-order Tensor Gauge Fields into the Flow Equation. This extension allows the model to encode richer geometric and gauge-theoretic structure in the data, leading to more expressive flow dynamics. Experiments on Gaussian mixture models show that Tensor Gauge Flow Models achieve improved generative performance compared to both standard and gauge flow baselines.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5f20\u91cf\u89c4\u8303\u6d41\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6d41\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u9ad8\u9636\u5f20\u91cf\u89c4\u8303\u573a\u7eb3\u5165\u6d41\u65b9\u7a0b\uff0c\u63a8\u5e7f\u4e86\u89c4\u8303\u6d41\u6a21\u578b\u548c\u9ad8\u9636\u89c4\u8303\u6d41\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u5728\u6570\u636e\u4e2d\u7f16\u7801\u66f4\u4e30\u5bcc\u7684\u51e0\u4f55\u548c\u89c4\u8303\u7406\u8bba\u7ed3\u6784\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u5177\u8868\u8fbe\u529b\u7684\u6d41\u52a8\u6001\u3002", "method": "\u5c06\u9ad8\u9636\u5f20\u91cf\u89c4\u8303\u573a\u6574\u5408\u5230\u6d41\u65b9\u7a0b\u4e2d\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u7684\u89c4\u8303\u6d41\u6a21\u578b\u6846\u67b6\u3002", "result": "\u5728\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5f20\u91cf\u89c4\u8303\u6d41\u6a21\u578b\u76f8\u6bd4\u6807\u51c6\u548c\u89c4\u8303\u6d41\u57fa\u7ebf\u6a21\u578b\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u751f\u6210\u6027\u80fd\u3002", "conclusion": "\u5f20\u91cf\u89c4\u8303\u6d41\u6a21\u578b\u901a\u8fc7\u5f15\u5165\u9ad8\u9636\u5f20\u91cf\u89c4\u8303\u573a\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u6355\u6349\u6570\u636e\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u63d0\u5347\u751f\u6210\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2511.18377", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18377", "abs": "https://arxiv.org/abs/2511.18377", "authors": ["Alessandro Giovagnoli"], "title": "An Introduction to the Quantum Approximate Optimization Algorithm", "comment": "30 pages, a mathematical introduction to the QAOA algorithm", "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is a promising variational quantum algorithm introduced to tackle classically intractable combinatorial optimization problems. This tutorial offers a comprehensive, first-principles introduction to QAOA and its properties, focusing on its application to Quadratic and Polynomial Unconstrained Binary Optimization (QUBO and PUBO) problems. The tutorial begins by outlining variational quantum circuits and QUBO problems, focusing on their key properties and the encoding of problem constraints through quadratic penalty terms. Next, it explores the QAOA in detail, covering its Hamiltonian formulation, gate decomposition, and example applications, along with their implementation and performance results. This is followed by an analysis of the algorithm's energy landscape, where proofs are provided for its symmetry and periodicity, and where a resulting parameter space reduction is proposed. Finally, the tutorial extends these concepts to PUBO problems by generalizing the results to higher-order Hamiltonians and discussing the associated symmetries and circuit construction.", "AI": {"tldr": "\u672c\u6559\u7a0b\u5168\u9762\u4ecb\u7ecd\u4e86\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5(QAOA)\uff0c\u91cd\u70b9\u8ba8\u8bba\u5176\u5728QUBO\u548cPUBO\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u7b97\u6cd5\u539f\u7406\u3001\u54c8\u5bc6\u987f\u91cf\u516c\u5f0f\u3001\u95e8\u5206\u89e3\u3001\u80fd\u91cf\u666f\u89c2\u5206\u6790\u4ee5\u53ca\u53c2\u6570\u7a7a\u95f4\u7b80\u5316\u65b9\u6cd5\u3002", "motivation": "QAOA\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u7ecf\u5178\u96be\u4ee5\u5904\u7406\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u672c\u6559\u7a0b\u65e8\u5728\u4ece\u57fa\u672c\u539f\u7406\u51fa\u53d1\u5168\u9762\u4ecb\u7ecdQAOA\u53ca\u5176\u7279\u6027\u3002", "method": "\u6559\u7a0b\u9996\u5148\u4ecb\u7ecd\u53d8\u5206\u91cf\u5b50\u7535\u8def\u548cQUBO\u95ee\u9898\uff0c\u7136\u540e\u8be6\u7ec6\u63a2\u8ba8QAOA\u7684\u54c8\u5bc6\u987f\u91cf\u516c\u5f0f\u3001\u95e8\u5206\u89e3\u548c\u5e94\u7528\u5b9e\u4f8b\uff0c\u5206\u6790\u7b97\u6cd5\u7684\u80fd\u91cf\u666f\u89c2\u5e76\u8bc1\u660e\u5176\u5bf9\u79f0\u6027\u548c\u5468\u671f\u6027\uff0c\u6700\u540e\u5c06\u6982\u5ff5\u6269\u5c55\u5230PUBO\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86\u53c2\u6570\u7a7a\u95f4\u7b80\u5316\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u5bf9\u79f0\u6027\u548c\u5468\u671f\u6027\u7279\u6027\uff0c\u5e76\u5c06\u7ed3\u679c\u63a8\u5e7f\u5230\u9ad8\u9636\u54c8\u5bc6\u987f\u91cf\uff0c\u8ba8\u8bba\u4e86\u76f8\u5173\u7684\u5bf9\u79f0\u6027\u548c\u7535\u8def\u6784\u9020\u3002", "conclusion": "\u672c\u6559\u7a0b\u4e3aQAOA\u53ca\u5176\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u73b0\u6307\u5bfc\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u4eceQUBO\u5230PUBO\u95ee\u9898\u7684\u63a8\u5e7f\u3002"}}
{"id": "2511.18440", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18440", "abs": "https://arxiv.org/abs/2511.18440", "authors": ["S. K. Singh", "Ahmed A. Zahia", "Jia-Xin Peng", "M. Y. Abd-Rabboud"], "title": "Cavity magnomechanical framework for a high-efficiency quantum battery", "comment": null, "summary": "We theoretically investigate a quantum battery architecture where two identical two-level atoms are charged by a cavity-magnomechanical system, which includes a microwave cavity, a magnon mode hosted in a YIG sphere, and phonon mode due to the deformation of the YIG sphere. The charging process relies on coherent energy exchange, where the atoms couple to the cavity, which in turn, it interacts with the magnon mode via a beam-splitter mechanism. By deriving the system Hamiltonian under the rotating-wave approximation and employing a Lindblad master equation to rigorously model dissipation, we analyze the complete dynamical evolution of the battery. Our study demonstrates that strong, resonant light-matter interactions are crucial for enhancing the key performance metrics: charging efficiency, stored energy, and ergotropy (extractable work). We systematically investigate the deleterious effects of detuning and decoherence, and critically, we uncover a non-trivial interplay between the system's coupling strengths. This reveals optimal operating regimes where constructive interference maximizes performance, while excessive coupling in specific channels can degrade it. Ultimately, our findings provide a quantitative framework for engineering high-efficiency quantum batteries in hybrid magnonic platforms, offering a design roadmap for future experimental realizations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7531\u4e24\u4e2a\u76f8\u540c\u4e8c\u80fd\u7ea7\u539f\u5b50\u901a\u8fc7\u8154-\u78c1\u632f\u5b50-\u673a\u68b0\u7cfb\u7edf\u5145\u7535\u7684\u91cf\u5b50\u7535\u6c60\u67b6\u6784\uff0c\u5206\u6790\u4e86\u5728\u8017\u6563\u73af\u5883\u4e0b\u7684\u5b8c\u6574\u52a8\u529b\u5b66\u6f14\u5316\uff0c\u63ed\u793a\u4e86\u5f3a\u5171\u632f\u5149-\u7269\u8d28\u76f8\u4e92\u4f5c\u7528\u5bf9\u5145\u7535\u6548\u7387\u3001\u5b58\u50a8\u80fd\u91cf\u548c\u53ef\u63d0\u53d6\u529f\u7684\u5173\u952e\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u6df7\u5408\u78c1\u632f\u5b50\u5e73\u53f0\u4e2d\u9ad8\u6548\u91cf\u5b50\u7535\u6c60\u7684\u8bbe\u8ba1\uff0c\u63a2\u7d22\u901a\u8fc7\u8154-\u78c1\u632f\u5b50-\u673a\u68b0\u7cfb\u7edf\u5b9e\u73b0\u91cf\u5b50\u80fd\u91cf\u5b58\u50a8\u548c\u63d0\u53d6\u7684\u53ef\u884c\u6027\u3002", "method": "\u63a8\u5bfc\u65cb\u8f6c\u6ce2\u8fd1\u4f3c\u4e0b\u7684\u7cfb\u7edf\u54c8\u5bc6\u987f\u91cf\uff0c\u91c7\u7528Lindblad\u4e3b\u65b9\u7a0b\u4e25\u683c\u5efa\u6a21\u8017\u6563\u8fc7\u7a0b\uff0c\u5206\u6790\u7cfb\u7edf\u7684\u5b8c\u6574\u52a8\u529b\u5b66\u6f14\u5316\u3002", "result": "\u53d1\u73b0\u5f3a\u5171\u632f\u5149-\u7269\u8d28\u76f8\u4e92\u4f5c\u7528\u5bf9\u63d0\u5347\u5145\u7535\u6548\u7387\u3001\u5b58\u50a8\u80fd\u91cf\u548cergotropy\u81f3\u5173\u91cd\u8981\uff0c\u63ed\u793a\u4e86\u8026\u5408\u5f3a\u5ea6\u4e4b\u95f4\u7684\u975e\u5e73\u51e1\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u786e\u5b9a\u4e86\u6700\u5927\u5316\u6027\u80fd\u7684\u6700\u4f73\u64cd\u4f5c\u533a\u57df\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5728\u6df7\u5408\u78c1\u632f\u5b50\u5e73\u53f0\u4e2d\u8bbe\u8ba1\u9ad8\u6548\u91cf\u5b50\u7535\u6c60\u63d0\u4f9b\u4e86\u5b9a\u91cf\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u5b9e\u9a8c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u8def\u7ebf\u56fe\u3002"}}
{"id": "2511.17623", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17623", "abs": "https://arxiv.org/abs/2511.17623", "authors": ["Haoran Li", "Zhe Cheng", "Muhao Guo", "Yang Weng", "Yannan Sun", "Victor Tran", "John Chainaranont"], "title": "M$^2$OE$^2$-GL: A Family of Probabilistic Load Forecasters That Scales to Massive Customers", "comment": "5 pages", "summary": "Probabilistic load forecasting is widely studied and underpins power system planning, operation, and risk-aware decision making. Deep learning forecasters have shown strong ability to capture complex temporal and contextual patterns, achieving substantial accuracy gains. However, at the scale of thousands or even hundreds of thousands of loads in large distribution feeders, a deployment dilemma emerges: training and maintaining one model per customer is computationally and storage intensive, while using a single global model ignores distributional shifts across customer types, locations, and phases. Prior work typically focuses on single-load forecasters, global models across multiple loads, or adaptive/personalized models for relatively small settings, and rarely addresses the combined challenges of heterogeneity and scalability in large feeders. We propose M2OE2-GL, a global-to-local extension of the M2OE2 probabilistic forecaster. We first pretrain a single global M2OE2 base model across all feeder loads, then apply lightweight fine-tuning to derive a compact family of group-specific forecasters. Evaluated on realistic utility data, M2OE2-GL yields substantial error reductions while remaining scalable to very large numbers of loads.", "AI": {"tldr": "M2OE2-GL\u662f\u4e00\u79cd\u6982\u7387\u8d1f\u8377\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5c40\u9884\u8bad\u7ec3\u548c\u8f7b\u91cf\u7ea7\u5fae\u8c03\u89e3\u51b3\u5927\u89c4\u6a21\u914d\u7535\u9988\u7ebf\u4e2d\u6570\u5343\u4e2a\u8d1f\u8377\u7684\u5f02\u8d28\u6027\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u90e8\u7f72\u56f0\u5883\uff1a\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u8bad\u7ec3\u5355\u72ec\u6a21\u578b\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u9ad8\uff0c\u800c\u4f7f\u7528\u5355\u4e00\u5168\u5c40\u6a21\u578b\u4f1a\u5ffd\u7565\u4e0d\u540c\u5ba2\u6237\u7c7b\u578b\u3001\u4f4d\u7f6e\u548c\u76f8\u4f4d\u7684\u5206\u5e03\u504f\u79fb\u3002", "method": "\u9996\u5148\u5728\u6240\u6709\u9988\u7ebf\u8d1f\u8377\u4e0a\u9884\u8bad\u7ec3\u5355\u4e00\u5168\u5c40M2OE2\u57fa\u7840\u6a21\u578b\uff0c\u7136\u540e\u5e94\u7528\u8f7b\u91cf\u7ea7\u5fae\u8c03\u6765\u63a8\u5bfc\u7d27\u51d1\u7684\u7ec4\u7279\u5b9a\u9884\u6d4b\u5668\u5bb6\u65cf\u3002", "result": "\u5728\u5b9e\u9645\u516c\u7528\u4e8b\u4e1a\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cM2OE2-GL\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u8bef\u5dee\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u5927\u91cf\u8d1f\u8377\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "M2OE2-GL\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u914d\u7535\u9988\u7ebf\u4e2d\u8d1f\u8377\u9884\u6d4b\u7684\u5f02\u8d28\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2511.18482", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18482", "abs": "https://arxiv.org/abs/2511.18482", "authors": ["Pei-Rong Han", "Huiye Qiu", "Hao-Long Zhang", "Wen Ning", "Zhen-Biao Yang", "Shi-Biao Zheng"], "title": "Non-Hermitian topology in a single driven-dissipative Kerr-Cat qubit", "comment": "3 figures", "summary": "The intriguing physical phenomena associated with exceptional points have established non-Hermitian physics as a frontier of modern research. Recent investigations have extended non-Hermitian physics into the fully quantum domain. However, existing studies predominantly concentrate on discrete-variable quantum systems, while non-Hermitian quantum effects in continuous-variable encoded systems remain largely unexplored. In this work, we investigate the exceptional structure for a driven-dissipative Kerr-cat qubit, realized with a Kerr nonlinear resonator. We find that the dissipation leads to a bidirectional jump between the two basis states of the cat qubit, which is in distinct contrast with the unidirectional jump associated with normal two-level systems. The competition between this jump and a single-photon drive gives arise to the emergence of third-order Liouvillian exceptional points (LEP3s), each corresponds to a crossing point of two lines of LEP2s. We further show that the LEP3 can exhibit the topological character of the Hamiltonian EP3s, which cannot be realized with a single qubit. Our work opens the possibility of realizing non-Hermitian phenomena with continuous-variable quantum systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u8fde\u7eed\u53d8\u91cf\u91cf\u5b50\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u975e\u5384\u7c73\u7269\u7406\u73b0\u8c61\uff0c\u7279\u522b\u5173\u6ce8\u4e86\u9a71\u52a8\u8017\u6563Kerr\u732b\u6001\u91cf\u5b50\u6bd4\u7279\u4e2d\u7684\u5f02\u5e38\u70b9\u7ed3\u6784\uff0c\u53d1\u73b0\u4e86\u4e09\u9636\u5218\u7ef4\u5c14\u5f02\u5e38\u70b9\u7684\u51fa\u73b0\u53ca\u5176\u62d3\u6251\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u975e\u5384\u7c73\u91cf\u5b50\u7269\u7406\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u79bb\u6563\u53d8\u91cf\u7cfb\u7edf\uff0c\u800c\u8fde\u7eed\u53d8\u91cf\u7f16\u7801\u7cfb\u7edf\u4e2d\u7684\u975e\u5384\u7c73\u91cf\u5b50\u6548\u5e94\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u7531Kerr\u975e\u7ebf\u6027\u8c10\u632f\u5668\u5b9e\u73b0\u7684\u9a71\u52a8\u8017\u6563Kerr\u732b\u6001\u91cf\u5b50\u6bd4\u7279\uff0c\u5206\u6790\u5176\u5f02\u5e38\u7ed3\u6784\uff0c\u7279\u522b\u5173\u6ce8\u8017\u6563\u5bfc\u81f4\u7684\u91cf\u5b50\u6001\u53cc\u5411\u8df3\u8dc3\u4e0e\u5355\u5149\u5b50\u9a71\u52a8\u7684\u7ade\u4e89\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u8017\u6563\u5bfc\u81f4\u732b\u6001\u91cf\u5b50\u6bd4\u7279\u4e24\u4e2a\u57fa\u6001\u4e4b\u95f4\u7684\u53cc\u5411\u8df3\u8dc3\uff0c\u8fd9\u4e0e\u666e\u901a\u4e24\u80fd\u7ea7\u7cfb\u7edf\u7684\u5355\u5411\u8df3\u8dc3\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\u3002\u8fd9\u79cd\u8df3\u8dc3\u4e0e\u5355\u5149\u5b50\u9a71\u52a8\u7684\u7ade\u4e89\u4ea7\u751f\u4e86\u4e09\u9636\u5218\u7ef4\u5c14\u5f02\u5e38\u70b9\uff0c\u6bcf\u4e2a\u5bf9\u5e94\u4e24\u6761LEP2\u7ebf\u7684\u4ea4\u53c9\u70b9\u3002", "conclusion": "LEP3\u53ef\u4ee5\u8868\u73b0\u51fa\u54c8\u5bc6\u987f\u91cfEP3\u7684\u62d3\u6251\u7279\u6027\uff0c\u8fd9\u5728\u5355\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\u65e0\u6cd5\u5b9e\u73b0\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u8fde\u7eed\u53d8\u91cf\u91cf\u5b50\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u975e\u5384\u7c73\u73b0\u8c61\u5f00\u8f9f\u4e86\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.18450", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18450", "abs": "https://arxiv.org/abs/2511.18450", "authors": ["Rui Xu", "Dakuan Lu", "Zicheng Zhao", "Xiaoyu Tan", "Xintao Wang", "Siyu Yuan", "Jiangjie Chen", "Yinghui Xu"], "title": "ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints", "comment": null, "summary": "Spatial reasoning is a key capability in the field of artificial intelligence, especially crucial in areas such as robotics, computer vision, and natural language understanding. However, evaluating the ability of multimodal large language models(MLLMs) in complex spatial reasoning still faces challenges, particularly in scenarios requiring multi-step reasoning and precise mathematical constraints. This paper introduces ORIGAMISPACE, a new dataset and benchmark designed to evaluate the multi-step spatial reasoning ability and the capacity to handle mathematical constraints of MLLMs through origami tasks. The dataset contains 350 data instances,each comprising a strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the complete Folding Process, and the final Folded Shape Image. We propose four evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial Relationship Prediction, and End-to-End CP Code Generation. For the CP code generation task, we design an interactive environment and explore the possibility of using reinforcement learning methods to train MLLMs. Through experiments on existing MLLMs, we initially reveal the strengths and weaknesses of these models in handling complex spatial reasoning tasks.", "AI": {"tldr": "ORIGAMISPACE\u662f\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u901a\u8fc7\u6298\u7eb8\u4efb\u52a1\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u548c\u5904\u7406\u6570\u5b66\u7ea6\u675f\u7684\u80fd\u529b\uff0c\u5305\u542b350\u4e2a\u6570\u636e\u5b9e\u4f8b\u548c\u56db\u4e2a\u8bc4\u4f30\u4efb\u52a1\u3002", "motivation": "\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u591a\u6b65\u63a8\u7406\u548c\u7cbe\u786e\u6570\u5b66\u7ea6\u675f\u7684\u573a\u666f\u4e2d\u3002", "method": "\u521b\u5efa\u5305\u542b\u4e25\u683c\u683c\u5f0f\u6298\u75d5\u56fe\u3001\u7f16\u8bd1\u5e73\u9762\u56fe\u3001\u5b8c\u6574\u6298\u53e0\u8fc7\u7a0b\u548c\u6700\u7ec8\u6298\u53e0\u5f62\u72b6\u56fe\u50cf\u7684350\u4e2a\u6570\u636e\u5b9e\u4f8b\uff0c\u63d0\u51fa\u56db\u4e2a\u8bc4\u4f30\u4efb\u52a1\uff0c\u5e76\u4e3aCP\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u8bbe\u8ba1\u4ea4\u4e92\u73af\u5883\u548c\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5bf9\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\uff0c\u521d\u6b65\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u548c\u5f31\u70b9\u3002", "conclusion": "ORIGAMISPACE\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u57fa\u51c6\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u4e0e\u5c40\u9650\u3002"}}
{"id": "2511.17624", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17624", "abs": "https://arxiv.org/abs/2511.17624", "authors": ["Hector E Mozo"], "title": "QML-HCS: A Hypercausal Quantum Machine Learning Framework for Non-Stationary Environments", "comment": "11 pages, 10 figures, and 8 tables. The implementation and full source code of the Hypercausal Quantum Machine Learning System (QML-HCS) are openly available on GitHub at: https://github.com/Neureonmindflux-Research-Lab/qml-hcs", "summary": "QML-HCS is a research-grade framework for constructing and analyzing quantum-inspired machine learning models operating under hypercausal feedback dynamics. Hypercausal refers to AI systems that leverage extended, deep, or nonlinear causal relationships (expanded causality) to reason, predict, and infer states beyond the capabilities of traditional causal models. Current machine learning and quantum-inspired systems struggle in non-stationary environments, where data distributions drift and models lack mechanisms for continuous adaptation, causal stability, and coherent state updating. QML-HCS addresses this limitation through a unified computational architecture that integrates quantum-inspired superposition principles, dynamic causal feedback, and deterministic-stochastic hybrid execution to enable adaptive behavior in changing environments.\n  The framework implements a hypercausal processing core capable of reversible transformations, multipath causal propagation, and evaluation of alternative states under drift. Its architecture incorporates continuous feedback to preserve causal consistency and adjust model behavior without requiring full retraining. QML-HCS provides a reproducible and extensible Python interface backed by efficient computational routines, enabling experimentation in quantum-inspired learning, causal reasoning, and hybrid computation without the need for specialized hardware.\n  A minimal simulation demonstrates how a hypercausal model adapts to a sudden shift in the input distribution while preserving internal coherence. This initial release establishes the foundational architecture for future theoretical extensions, benchmarking studies, and integration with classical and quantum simulation platforms.", "AI": {"tldr": "QML-HCS\u662f\u4e00\u4e2a\u91cf\u5b50\u542f\u53d1\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8d85\u56e0\u679c\u53cd\u9988\u52a8\u529b\u5b66\u5b9e\u73b0\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u7684\u81ea\u9002\u5e94\u884c\u4e3a\uff0c\u6574\u5408\u4e86\u91cf\u5b50\u53e0\u52a0\u539f\u7406\u3001\u52a8\u6001\u56e0\u679c\u53cd\u9988\u548c\u786e\u5b9a\u6027-\u968f\u673a\u6df7\u5408\u6267\u884c\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u673a\u5668\u5b66\u4e60\u548c\u91cf\u5b50\u542f\u53d1\u7cfb\u7edf\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5982\u6570\u636e\u5206\u5e03\u6f02\u79fb\u3001\u7f3a\u4e4f\u8fde\u7eed\u9002\u5e94\u673a\u5236\u3001\u56e0\u679c\u7a33\u5b9a\u6027\u548c\u76f8\u5e72\u72b6\u6001\u66f4\u65b0\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u8ba1\u7b97\u67b6\u6784\uff0c\u96c6\u6210\u91cf\u5b50\u542f\u53d1\u53e0\u52a0\u539f\u7406\u3001\u52a8\u6001\u56e0\u679c\u53cd\u9988\u548c\u786e\u5b9a\u6027-\u968f\u673a\u6df7\u5408\u6267\u884c\uff0c\u5b9e\u73b0\u53ef\u9006\u53d8\u6362\u3001\u591a\u8def\u5f84\u56e0\u679c\u4f20\u64ad\u548c\u6f02\u79fb\u4e0b\u66ff\u4ee3\u72b6\u6001\u8bc4\u4f30\u3002", "result": "\u6846\u67b6\u5c55\u793a\u4e86\u5728\u8f93\u5165\u5206\u5e03\u7a81\u7136\u53d8\u5316\u65f6\uff0c\u8d85\u56e0\u679c\u6a21\u578b\u80fd\u591f\u4fdd\u6301\u5185\u90e8\u76f8\u5e72\u6027\u5e76\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u65e0\u9700\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u7406\u8bba\u6269\u5c55\u3001\u57fa\u51c6\u6d4b\u8bd5\u7814\u7a76\u4ee5\u53ca\u4e0e\u7ecf\u5178\u548c\u91cf\u5b50\u6a21\u62df\u5e73\u53f0\u7684\u96c6\u6210\u5efa\u7acb\u4e86\u57fa\u7840\u67b6\u6784\u3002"}}
{"id": "2511.18496", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18496", "abs": "https://arxiv.org/abs/2511.18496", "authors": ["Tomoyuki Yamakami"], "title": "Machine Learning by Adiabatic Evolutionary Quantum System", "comment": "(A4, 11pt, 10 pages) A preliminary report was presented at the 22nd International Conference on Unconventional Computation and Natural Computation (UCNC 2025), Nice, France, September 1--5, 2025", "summary": "A computational model of adiabatic evolutionary quantum system (or AEQS, pronounced \"eeh-ks\") was introduced in [Yamakami,2022] as a sort of quantum annealing and its underlying input-driven Hamiltonians are generated quantum-algorithmically by various forms of quantum automata families (including 1qqaf's). We study an efficient way to accomplish certain machine learning tasks by training these AEQSs quantumly. When AEQSs are controlled by 1qqaf's, it suffices in essence to find an optimal 1qqaf that approximately solves a target relational problem. For this purpose, we develop a basic idea of approximately utilizing well-known quantum algorithms for quantum counting, quantum amplitude estimation, and quantum approximation. We then provide a rough estimation of the efficiency of our quantum learning algorithms for AEQSs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5229\u7528\u91cf\u5b50\u81ea\u52a8\u673a\u63a7\u5236\u7684\u7edd\u70ed\u6f14\u5316\u91cf\u5b50\u7cfb\u7edf\uff08AEQS\uff09\u6765\u9ad8\u6548\u5b8c\u6210\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50\u8ba1\u6570\u3001\u91cf\u5b50\u632f\u5e45\u4f30\u8ba1\u548c\u91cf\u5b50\u8fd1\u4f3c\u7b49\u91cf\u5b50\u7b97\u6cd5\u6765\u5bfb\u627e\u6700\u4f18\u76841qqaf\u4ee5\u89e3\u51b3\u76ee\u6807\u5173\u7cfb\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u91cf\u5b50\u8bad\u7ec3AEQS\u7cfb\u7edf\u6765\u9ad8\u6548\u5b8c\u6210\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff0c\u5229\u7528\u91cf\u5b50\u7b97\u6cd5\u7684\u4f18\u52bf\u6765\u4f18\u5316\u91cf\u5b50\u81ea\u52a8\u673a\u63a7\u5236\u7684\u7edd\u70ed\u6f14\u5316\u8fc7\u7a0b\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u91cf\u5b50\u8ba1\u6570\u3001\u91cf\u5b50\u632f\u5e45\u4f30\u8ba1\u548c\u91cf\u5b50\u8fd1\u4f3c\u7b49\u91cf\u5b50\u7b97\u6cd5\u7684\u57fa\u672c\u601d\u60f3\uff0c\u7528\u4e8e\u8bad\u7ec3\u75311qqaf\u63a7\u5236\u7684AEQS\u7cfb\u7edf\uff0c\u5bfb\u627e\u6700\u4f18\u76841qqaf\u6765\u8fd1\u4f3c\u89e3\u51b3\u76ee\u6807\u5173\u7cfb\u95ee\u9898\u3002", "result": "\u63d0\u4f9b\u4e86\u91cf\u5b50\u5b66\u4e60\u7b97\u6cd5\u5bf9AEQS\u7cfb\u7edf\u6548\u7387\u7684\u7c97\u7565\u4f30\u8ba1\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6f5c\u5728\u4f18\u52bf\u3002", "conclusion": "\u91cf\u5b50\u7b97\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u7528\u4e8e\u8bad\u7ec3AEQS\u7cfb\u7edf\uff0c\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u7531\u91cf\u5b50\u81ea\u52a8\u673a\u63a7\u5236\u7684\u7edd\u70ed\u6f14\u5316\u7cfb\u7edf\u65f6\u3002"}}
{"id": "2511.17626", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17626", "abs": "https://arxiv.org/abs/2511.17626", "authors": ["Kartheek Bondugula", "Santiago Mazuelas", "Aritz P\u00e9rez"], "title": "Efficient Large-Scale Learning of Minimax Risk Classifiers", "comment": "In IEEE ICDM (2025)", "summary": "Supervised learning with large-scale data usually leads to complex optimization problems, especially for classification tasks with multiple classes. Stochastic subgradient methods can enable efficient learning with a large number of samples for classification techniques that minimize the average loss over the training samples. However, recent techniques, such as minimax risk classifiers (MRCs), minimize the maximum expected loss and are not amenable to stochastic subgradient methods. In this paper, we present a learning algorithm based on the combination of constraint and column generation that enables efficient learning of MRCs with large-scale data for classification tasks with multiple classes. Experiments on multiple benchmark datasets show that the proposed algorithm provides upto a 10x speedup for general large-scale data and around a 100x speedup with a sizeable number of classes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u548c\u5217\u751f\u6210\u7684\u7ec4\u5408\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u5b66\u4e60\u5927\u89c4\u6a21\u591a\u7c7b\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6781\u5c0f\u6781\u5927\u98ce\u9669\u5206\u7c7b\u5668\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e8610-100\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u7684\u968f\u673a\u6b21\u68af\u5ea6\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u6781\u5c0f\u6781\u5927\u98ce\u9669\u5206\u7c7b\u5668\uff08MRCs\uff09\uff0c\u56e0\u4e3aMRCs\u6700\u5c0f\u5316\u7684\u662f\u6700\u5927\u671f\u671b\u635f\u5931\u800c\u975e\u5e73\u5747\u635f\u5931\uff0c\u8fd9\u5728\u5927\u89c4\u6a21\u591a\u7c7b\u5206\u7c7b\u4efb\u52a1\u4e2d\u5bfc\u81f4\u590d\u6742\u7684\u4f18\u5316\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408\u7ea6\u675f\u751f\u6210\u548c\u5217\u751f\u6210\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u4e13\u95e8\u7528\u4e8e\u9ad8\u6548\u8bad\u7ec3\u5927\u89c4\u6a21\u591a\u7c7b\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6781\u5c0f\u6781\u5927\u98ce\u9669\u5206\u7c7b\u5668\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u4e00\u822c\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u63d0\u4f9b\u9ad8\u8fbe10\u500d\u7684\u52a0\u901f\uff0c\u5728\u7c7b\u522b\u6570\u91cf\u8f83\u591a\u65f6\u63d0\u4f9b\u7ea6100\u500d\u7684\u52a0\u901f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u6781\u5c0f\u6781\u5927\u98ce\u9669\u5206\u7c7b\u5668\u5728\u5927\u89c4\u6a21\u591a\u7c7b\u5206\u7c7b\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2511.18574", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18574", "abs": "https://arxiv.org/abs/2511.18574", "authors": ["Brenden R. Guyette", "Joshua M. Lewis", "Lincoln D. Carr"], "title": "Tunable Bands in 1D Fractional Quantum Media", "comment": null, "summary": "Fractional calculus has become an essential framework in geophysics, optics, and biological systems to capture long-range correlations and anomalous transport. In this article, we extend fractional calculus to explore a particle in a periodic potential, where the Schr\u00f6dinger equation is generalized to its fractional form. This framework allows us to study how the L\u00e9vy index $q$ governs the formation and inversion of energy bands, offering a pathway to engineer new physical behaviors and device functionalities by tuning $q$ in periodic quantum systems. We solve the fractional Schr\u00f6dinger equation for periodic rectangular potentials of varying height $V_0$, barrier thickness $L$, and well width $W$ using an imaginary-time evolution algorithm, and supplement the discrete energy dispersion through Gaussian process regression. Our analysis reveals a qualitative shift in the band structure at $q=2$, separating into regimes for $q>2$ and $q<2$. For $q > 2$, energy bands undergo an inverting transformation as symmetric minima emerge within the first Brillouin zone, shifting from $k=0$ toward $k=\\pm \u03c0/a$ with increasing $q$. These degenerate minima define a Bloch-momentum qubit, suggesting an analog to valley degrees of freedom used in valleytronics. The response of the ground band scales with fractional order as $V_0^{-0.28\\pm0.05}L^{-0.34\\pm0.08}W^{-0.49\\pm0.06}$, indicating tunable sensitivity to geometry. For $q < 2$, the effective mass near $k = 0$ decreases exponentially with $q$, yielding a universal effective mass of $0.15\\pm0.01$ as $q \\to 1$, demonstrating that the L\u00e9vy index serves as a tunable degree of freedom capable of driving band inversion, modulating the band gap, and reshaping carrier dynamics.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u5206\u6570\u9636\u5fae\u79ef\u5206\u5230\u5468\u671f\u52bf\u4e2d\u7684\u7c92\u5b50\u7814\u7a76\uff0c\u901a\u8fc7\u5206\u6570\u9636\u859b\u5b9a\u8c14\u65b9\u7a0b\u5206\u6790L\u00e9vy\u6307\u6570q\u5982\u4f55\u8c03\u63a7\u80fd\u5e26\u5f62\u6210\u548c\u53cd\u8f6c\uff0c\u63ed\u793a\u4e86\u5728q=2\u5904\u7684\u80fd\u5e26\u7ed3\u6784\u5b9a\u6027\u8f6c\u53d8\uff0c\u5e76\u5c55\u793a\u4e86q\u4f5c\u4e3a\u53ef\u8c03\u81ea\u7531\u5ea6\u5bf9\u80fd\u5e26\u53cd\u8f6c\u3001\u5e26\u9699\u8c03\u5236\u548c\u8f7d\u6d41\u5b50\u52a8\u529b\u5b66\u7684\u91cd\u5851\u80fd\u529b\u3002", "motivation": "\u5c06\u5206\u6570\u9636\u5fae\u79ef\u5206\u6846\u67b6\u6269\u5c55\u5230\u5468\u671f\u52bf\u91cf\u5b50\u7cfb\u7edf\uff0c\u7814\u7a76L\u00e9vy\u6307\u6570q\u5982\u4f55\u8c03\u63a7\u80fd\u5e26\u5f62\u6210\u548c\u53cd\u8f6c\uff0c\u4e3a\u5de5\u7a0b\u5316\u65b0\u7684\u7269\u7406\u884c\u4e3a\u548c\u5668\u4ef6\u529f\u80fd\u63d0\u4f9b\u9014\u5f84\u3002", "method": "\u4f7f\u7528\u865a\u65f6\u95f4\u6f14\u5316\u7b97\u6cd5\u6c42\u89e3\u5468\u671f\u77e9\u5f62\u52bf\u7684\u5206\u6570\u9636\u859b\u5b9a\u8c14\u65b9\u7a0b\uff0c\u5e76\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u8865\u5145\u79bb\u6563\u80fd\u91cf\u8272\u6563\u5206\u6790\u3002", "result": "\u53d1\u73b0q=2\u5904\u80fd\u5e26\u7ed3\u6784\u53d1\u751f\u5b9a\u6027\u8f6c\u53d8\uff1aq>2\u65f6\u80fd\u5e26\u53d1\u751f\u53cd\u8f6c\uff0c\u5728\u7b2c\u4e00\u5e03\u91cc\u6e0a\u533a\u5185\u51fa\u73b0\u5bf9\u79f0\u6781\u5c0f\u503c\uff0c\u5f62\u6210Bloch\u52a8\u91cf\u91cf\u5b50\u6bd4\u7279\uff1bq<2\u65f6k=0\u9644\u8fd1\u6709\u6548\u8d28\u91cf\u968fq\u6307\u6570\u51cf\u5c0f\u3002", "conclusion": "L\u00e9vy\u6307\u6570q\u4f5c\u4e3a\u53ef\u8c03\u81ea\u7531\u5ea6\u80fd\u591f\u9a71\u52a8\u80fd\u5e26\u53cd\u8f6c\u3001\u8c03\u5236\u5e26\u9699\u5e76\u91cd\u5851\u8f7d\u6d41\u5b50\u52a8\u529b\u5b66\uff0c\u4e3a\u5468\u671f\u6027\u91cf\u5b50\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u8c03\u63a7\u7ef4\u5ea6\u3002"}}
{"id": "2511.18609", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18609", "abs": "https://arxiv.org/abs/2511.18609", "authors": ["David Krakauer", "G\u00fclce Karde\u015f", "Joshua Grochow"], "title": "Universality in Collective Intelligence on the Rubik's Cube", "comment": null, "summary": "Progress in understanding expert performance is limited by the scarcity of quantitative data on long-term knowledge acquisition and deployment. Here we use the Rubik's Cube as a cognitive model system existing at the intersection of puzzle solving, skill learning, expert knowledge, cultural transmission, and group theory. By studying competitive cube communities, we find evidence for universality in the collective learning of the Rubik's Cube in both sighted and blindfolded conditions: expert performance follows exponential progress curves whose parameters reflect the delayed acquisition of algorithms that shorten solution paths. Blindfold solves form a distinct problem class from sighted solves and are constrained not only by expert knowledge but also by the skill improvements required to overcome short-term memory bottlenecks, a constraint shared with blindfold chess. Cognitive artifacts such as the Rubik's Cube help solvers navigate an otherwise enormous mathematical state space. In doing so, they sustain collective intelligence by integrating communal knowledge stores with individual expertise and skill, illustrating how expertise can, in practice, continue to deepen over the course of a single lifetime.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u9b54\u65b9\u4f5c\u4e3a\u8ba4\u77e5\u6a21\u578b\u7cfb\u7edf\uff0c\u53d1\u73b0\u4e13\u5bb6\u8868\u73b0\u9075\u5faa\u6307\u6570\u7ea7\u8fdb\u6b65\u66f2\u7ebf\uff0c\u53c2\u6570\u53cd\u6620\u4e86\u7f29\u77ed\u89e3\u8def\u5f84\u7684\u7b97\u6cd5\u5ef6\u8fdf\u83b7\u53d6\u3002\u76f2\u89e3\u4e0e\u89c6\u89c9\u89e3\u5f62\u6210\u4e0d\u540c\u95ee\u9898\u7c7b\u522b\uff0c\u53d7\u9650\u4e8e\u4e13\u5bb6\u77e5\u8bc6\u548c\u514b\u670d\u77ed\u671f\u8bb0\u5fc6\u74f6\u9888\u7684\u6280\u80fd\u6539\u8fdb\u3002", "motivation": "\u7406\u89e3\u4e13\u5bb6\u8868\u73b0\u53d7\u9650\u4e8e\u957f\u671f\u77e5\u8bc6\u83b7\u53d6\u548c\u5e94\u7528\u7684\u5b9a\u91cf\u6570\u636e\u7a00\u7f3a\uff0c\u9b54\u65b9\u4f5c\u4e3a\u8ba4\u77e5\u6a21\u578b\u7cfb\u7edf\u53ef\u4ee5\u7814\u7a76\u89e3\u8c1c\u3001\u6280\u80fd\u5b66\u4e60\u3001\u4e13\u5bb6\u77e5\u8bc6\u3001\u6587\u5316\u4f20\u64ad\u548c\u7fa4\u8bba\u7684\u4ea4\u96c6\u3002", "method": "\u7814\u7a76\u7ade\u6280\u9b54\u65b9\u793e\u7fa4\uff0c\u5206\u6790\u89c6\u89c9\u548c\u76f2\u89e3\u6761\u4ef6\u4e0b\u7684\u96c6\u4f53\u5b66\u4e60\u6a21\u5f0f\uff0c\u6bd4\u8f83\u4e24\u79cd\u89e3\u6cd5\u7684\u8ba4\u77e5\u7ea6\u675f\u5dee\u5f02\u3002", "result": "\u53d1\u73b0\u4e13\u5bb6\u8868\u73b0\u9075\u5faa\u6307\u6570\u8fdb\u6b65\u66f2\u7ebf\uff0c\u76f2\u89e3\u53d7\u77ed\u671f\u8bb0\u5fc6\u74f6\u9888\u7ea6\u675f\uff0c\u9b54\u65b9\u7b49\u8ba4\u77e5\u5de5\u5177\u5e2e\u52a9\u89e3\u51b3\u5de8\u5927\u7684\u6570\u5b66\u72b6\u6001\u7a7a\u95f4\u95ee\u9898\u3002", "conclusion": "\u8ba4\u77e5\u5de5\u5177\u901a\u8fc7\u6574\u5408\u793e\u7fa4\u77e5\u8bc6\u5e93\u4e0e\u4e2a\u4eba\u4e13\u4e1a\u6280\u80fd\uff0c\u7ef4\u6301\u96c6\u4f53\u667a\u80fd\uff0c\u8bf4\u660e\u4e13\u4e1a\u77e5\u8bc6\u53ef\u4ee5\u5728\u4e2a\u4eba\u4e00\u751f\u4e2d\u6301\u7eed\u6df1\u5316\u3002"}}
{"id": "2511.17628", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17628", "abs": "https://arxiv.org/abs/2511.17628", "authors": ["Fanbo Ju", "Haiyuan Shi", "Qingjian Ni"], "title": "Rectifying Mean-Shift in Cascaded Precipitation Nowcasting", "comment": null, "summary": "Precipitation nowcasting, which aims to provide high spatio-temporal resolution precipitation forecasts by leveraging current radar observations, is a core task in regional weather forecasting. The cascaded architecture has emerged as the mainstream paradigm for deep learning-based precipitation nowcasting. This paradigm involves a deterministic model to predict macroscopic trends (or posterior mean), followed by a probabilistic model to generate local details (or local stochasticity). However, existing methods commonly overlook the conflation of the systematic distribution shift in deterministic predictions and the local stochasticity. As a result, the deterministic component's distribution shift contaminates the predictions of the probabilistic component, leading to inaccuracies in precipitation patterns and intensity, particularly over longer lead times. To address this issue, we introduce RectiCast, a two-stage framework that explicitly decouples the correction of mean-field shift from the generation of local stochasticity via a dual Flow Matching model. In the first stage, a deterministic model generates the posterior mean. In the second stage, we introduce a Rectifier to explicitly learn the distribution shift and produce a rectified mean. Subsequently, a Generator focuses on modeling the local stochasticity conditioned on the rectified mean. Experiments on SEVIR and MeteoNet demonstrate that RectiCast achieves significant performance improvements over existing state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faRectiCast\u6846\u67b6\uff0c\u901a\u8fc7\u53ccFlow Matching\u6a21\u578b\u663e\u5f0f\u89e3\u8026\u5747\u503c\u573a\u504f\u79fb\u6821\u6b63\u4e0e\u5c40\u90e8\u968f\u673a\u6027\u751f\u6210\uff0c\u89e3\u51b3\u964d\u6c34\u4e34\u8fd1\u9884\u62a5\u4e2d\u786e\u5b9a\u6027\u9884\u6d4b\u7684\u7cfb\u7edf\u6027\u5206\u5e03\u504f\u79fb\u4e0e\u5c40\u90e8\u968f\u673a\u6027\u6df7\u6dc6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7ea7\u8054\u67b6\u6784\u65b9\u6cd5\u666e\u904d\u5ffd\u89c6\u786e\u5b9a\u6027\u9884\u6d4b\u4e2d\u7684\u7cfb\u7edf\u6027\u5206\u5e03\u504f\u79fb\u4e0e\u5c40\u90e8\u968f\u673a\u6027\u7684\u6df7\u6dc6\u95ee\u9898\uff0c\u5bfc\u81f4\u786e\u5b9a\u6027\u5206\u91cf\u7684\u5206\u5e03\u504f\u79fb\u6c61\u67d3\u6982\u7387\u5206\u91cf\u7684\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728\u8f83\u957f\u7684\u9884\u62a5\u65f6\u6548\u4e0a\u9020\u6210\u964d\u6c34\u6a21\u5f0f\u548c\u5f3a\u5ea6\u7684\u4e0d\u51c6\u786e\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u786e\u5b9a\u6027\u6a21\u578b\u751f\u6210\u540e\u9a8c\u5747\u503c\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165Rectifier\u663e\u5f0f\u5b66\u4e60\u5206\u5e03\u504f\u79fb\u5e76\u751f\u6210\u6821\u6b63\u5747\u503c\uff0c\u7136\u540eGenerator\u57fa\u4e8e\u6821\u6b63\u5747\u503c\u5efa\u6a21\u5c40\u90e8\u968f\u673a\u6027\u3002", "result": "\u5728SEVIR\u548cMeteoNet\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRectiCast\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "RectiCast\u901a\u8fc7\u663e\u5f0f\u89e3\u8026\u5747\u503c\u573a\u504f\u79fb\u6821\u6b63\u4e0e\u5c40\u90e8\u968f\u673a\u6027\u751f\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u964d\u6c34\u4e34\u8fd1\u9884\u62a5\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u6c61\u67d3\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u9884\u62a5\u51c6\u786e\u6027\u3002"}}
{"id": "2511.18621", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18621", "abs": "https://arxiv.org/abs/2511.18621", "authors": ["Gustavo Rigolin"], "title": "Teleportation-based quantum state tomography", "comment": "8 pages, 3 figures, RevTex4", "summary": "We explicitly show that the quantum teleportation protocol can be employed to completely reconstruct arbitrary two- and three-qubit density matrices. We also extend the present analysis to n-qubit density matrices. The only quantum resources needed to implement the teleportation-based quantum state tomography protocol are the ability to make Bell measurements and the ability to prepare a few different single qubit states to be teleported from Alice to Bob.", "AI": {"tldr": "\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u534f\u8bae\u53ef\u7528\u4e8e\u5b8c\u5168\u91cd\u6784\u4efb\u610f\u4e8c\u6bd4\u7279\u548c\u4e09\u6bd4\u7279\u5bc6\u5ea6\u77e9\u9635\uff0c\u5e76\u6269\u5c55\u5230n\u6bd4\u7279\u5bc6\u5ea6\u77e9\u9635\u3002\u5b9e\u73b0\u57fa\u4e8e\u9690\u5f62\u4f20\u6001\u7684\u91cf\u5b50\u6001\u5c42\u6790\u4ec5\u9700\u8d1d\u5c14\u6d4b\u91cf\u80fd\u529b\u548c\u51c6\u5907\u5c11\u91cf\u5355\u6bd4\u7279\u6001\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u534f\u8bae\u5728\u91cf\u5b50\u6001\u5c42\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u7b80\u5316\u4f20\u7edf\u91cf\u5b50\u6001\u91cd\u6784\u6240\u9700\u7684\u590d\u6742\u6d4b\u91cf\u8fc7\u7a0b\u3002", "method": "\u5229\u7528\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u534f\u8bae\uff0c\u901a\u8fc7\u8d1d\u5c14\u6d4b\u91cf\u548c\u51c6\u5907\u5c11\u91cf\u5355\u6bd4\u7279\u6001\u6765\u5b9e\u73b0\u91cf\u5b50\u6001\u7684\u91cd\u6784\u3002", "result": "\u6210\u529f\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u5b8c\u5168\u91cd\u6784\u4efb\u610f\u4e8c\u6bd4\u7279\u548c\u4e09\u6bd4\u7279\u5bc6\u5ea6\u77e9\u9635\uff0c\u5e76\u53ef\u6269\u5c55\u5230n\u6bd4\u7279\u60c5\u51b5\u3002", "conclusion": "\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u534f\u8bae\u4e3a\u91cf\u5b50\u6001\u5c42\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u8d44\u6e90\u9700\u6c42\u8f83\u5c11\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002"}}
{"id": "2511.18770", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18770", "abs": "https://arxiv.org/abs/2511.18770", "authors": ["Xinpeng Li", "Ji Liu", "Shuai Xu", "Paul Hovland", "Vipin Chaudhary"], "title": "HOPPS: Hardware-Aware Optimal Phase Polynomial Synthesis with Blockwise Optimization for Quantum Circuits", "comment": null, "summary": "Blocks composed of {CNOT, Rz} are ubiquitous in modern quantum applications, notably in circuits such as QAOA ansatzes and quantum adders. After compilation, many of them exhibit large CNOT counts or depths, which lowers fidelity. Therefore, we introduce HOPPS: a SAT-based hardware-aware optimal phase polynomial synthesis algorithm that could generate {CNOT, Rz} blocks with CNOT count or depth optimality.\n  Sometime {CNOT, Rz} blocks are large, such as in QAOA ansatzes, HOPPS's pursuit of optimality limits its scalability. To address this issue, we introduce an iterative blockwise optimization strategy: large circuits are partitioned into smaller blocks, each block is optimally refined, and the process is repeated for several iterations.\n  Empirical results show that HOPPS is more efficient comparing with existing near optimal synthesis tools. Used as a peephole optimizer, HOPPS reduces the CNOT count by up to 50.0% and the CNOT depth by up to 57.1% under OLSQ. For large QAOA circuit, after mapping by Qiskit, circuit can be reduced CNOT count and depth by up to 44.4% and 42.4% by our iterative blockwise optimization. Index Terms-Phase Polynomial, Quantum Circuit Synthesis, Quantum Circuit Optimization.", "AI": {"tldr": "HOPPS\u662f\u4e00\u79cd\u57fa\u4e8eSAT\u7684\u786c\u4ef6\u611f\u77e5\u6700\u4f18\u76f8\u4f4d\u591a\u9879\u5f0f\u5408\u6210\u7b97\u6cd5\uff0c\u7528\u4e8e\u751f\u6210CNOT\u548cRz\u95e8\u5757\uff0c\u5b9e\u73b0CNOT\u6570\u91cf\u6216\u6df1\u5ea6\u7684\u6700\u4f18\u6027\u3002\u5bf9\u4e8e\u5927\u578b\u7535\u8def\uff0c\u91c7\u7528\u8fed\u4ee3\u5206\u5757\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u73b0\u4ee3\u91cf\u5b50\u5e94\u7528\u4e2d{CNOT, Rz}\u5757\u666e\u904d\u5b58\u5728\uff0c\u4f46\u7f16\u8bd1\u540e\u5e38\u51fa\u73b0CNOT\u6570\u91cf\u6216\u6df1\u5ea6\u8fc7\u5927\uff0c\u964d\u4f4e\u4fdd\u771f\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8ffd\u6c42\u6700\u4f18\u6027\u65f6\u6269\u5c55\u6027\u53d7\u9650\u3002", "method": "\u63d0\u51faHOPPS\u7b97\u6cd5\u5b9e\u73b0CNOT\u6570\u91cf\u6216\u6df1\u5ea6\u6700\u4f18\u7684{CNOT, Rz}\u5757\u5408\u6210\u3002\u5bf9\u4e8e\u5927\u578b\u7535\u8def\uff0c\u91c7\u7528\u8fed\u4ee3\u5206\u5757\u4f18\u5316\u7b56\u7565\uff1a\u5c06\u5927\u7535\u8def\u5206\u5272\u6210\u5c0f\u6a21\u5757\uff0c\u6bcf\u4e2a\u6a21\u5757\u6700\u4f18\u4f18\u5316\uff0c\u591a\u6b21\u8fed\u4ee3\u3002", "result": "HOPPS\u6bd4\u73b0\u6709\u8fd1\u6700\u4f18\u5408\u6210\u5de5\u5177\u66f4\u9ad8\u6548\u3002\u4f5c\u4e3a\u7aa5\u5b54\u4f18\u5316\u5668\uff0c\u5728OLSQ\u4e0b\u53ef\u5c06CNOT\u6570\u91cf\u51cf\u5c11\u9ad8\u8fbe50.0%\uff0c\u6df1\u5ea6\u51cf\u5c11\u9ad8\u8fbe57.1%\u3002\u5bf9\u4e8e\u5927\u578bQAOA\u7535\u8def\uff0c\u7ecf\u8fc7Qiskit\u6620\u5c04\u540e\uff0cCNOT\u6570\u91cf\u548c\u6df1\u5ea6\u5206\u522b\u51cf\u5c11\u9ad8\u8fbe44.4%\u548c42.4%\u3002", "conclusion": "HOPPS\u7b97\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u91cf\u5b50\u7535\u8def\u4e2d\u7684{CNOT, Rz}\u5757\uff0c\u663e\u8457\u51cf\u5c11CNOT\u95e8\u6570\u91cf\u548c\u6df1\u5ea6\uff0c\u63d0\u9ad8\u7535\u8def\u6027\u80fd\u3002"}}
{"id": "2511.17630", "categories": ["cs.LG", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.17630", "abs": "https://arxiv.org/abs/2511.17630", "authors": ["Nele Albers", "Esra Cemre Su de Groot", "Loes Keijsers", "Manon H. Hillegers", "Emiel Krahmer"], "title": "Can we use LLMs to bootstrap reinforcement learning? -- A case study in digital health behavior change", "comment": null, "summary": "Personalizing digital applications for health behavior change is a promising route to making them more engaging and effective. This especially holds for approaches that adapt to users and their specific states (e.g., motivation, knowledge, wants) over time. However, developing such approaches requires making many design choices, whose effectiveness is difficult to predict from literature and costly to evaluate in practice. In this work, we explore whether large language models (LLMs) can be used out-of-the-box to generate samples of user interactions that provide useful information for training reinforcement learning models for digital behavior change settings. Using real user data from four large behavior change studies as comparison, we show that LLM-generated samples can be useful in the absence of real data. Comparisons to the samples provided by human raters further show that LLM-generated samples reach the performance of human raters. Additional analyses of different prompting strategies including shorter and longer prompt variants, chain-of-thought prompting, and few-shot prompting show that the relative effectiveness of different strategies depends on both the study and the LLM with also relatively large differences between prompt paraphrases alone. We provide recommendations for how LLM-generated samples can be useful in practice.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7528\u6237\u4ea4\u4e92\u6837\u672c\uff0c\u7528\u4e8e\u8bad\u7ec3\u6570\u5b57\u884c\u4e3a\u6539\u53d8\u573a\u666f\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793aLLM\u751f\u6210\u7684\u6837\u672c\u5728\u7f3a\u4e4f\u771f\u5b9e\u6570\u636e\u65f6\u6709\u7528\uff0c\u4e14\u6027\u80fd\u8fbe\u5230\u4eba\u7c7b\u8bc4\u4f30\u8005\u6c34\u5e73\u3002", "motivation": "\u4e2a\u6027\u5316\u6570\u5b57\u5065\u5eb7\u884c\u4e3a\u6539\u53d8\u5e94\u7528\u9700\u8981\u9002\u5e94\u7528\u6237\u53ca\u5176\u7279\u5b9a\u72b6\u6001\uff0c\u4f46\u5f00\u53d1\u8fd9\u7c7b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8bbe\u8ba1\u9009\u62e9\uff0c\u5176\u6548\u679c\u96be\u4ee5\u4ece\u6587\u732e\u9884\u6d4b\u4e14\u5b9e\u8df5\u8bc4\u4f30\u6210\u672c\u9ad8\u6602\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7528\u6237\u4ea4\u4e92\u6837\u672c\uff0c\u6bd4\u8f83\u771f\u5b9e\u7528\u6237\u6570\u636e\u548c\u4eba\u7c7b\u8bc4\u4f30\u8005\u6837\u672c\uff0c\u5206\u6790\u4e0d\u540c\u63d0\u793a\u7b56\u7565\uff08\u77ed/\u957f\u63d0\u793a\u3001\u601d\u7ef4\u94fe\u63d0\u793a\u3001\u5c11\u6837\u672c\u63d0\u793a\uff09\u7684\u6548\u679c\u3002", "result": "LLM\u751f\u6210\u7684\u6837\u672c\u5728\u7f3a\u4e4f\u771f\u5b9e\u6570\u636e\u65f6\u6709\u7528\uff0c\u6027\u80fd\u8fbe\u5230\u4eba\u7c7b\u8bc4\u4f30\u8005\u6c34\u5e73\uff0c\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u7684\u6548\u679c\u56e0\u7814\u7a76\u548cLLM\u800c\u5f02\uff0c\u63d0\u793a\u6539\u5199\u672c\u8eab\u4e5f\u4f1a\u4ea7\u751f\u8f83\u5927\u5dee\u5f02\u3002", "conclusion": "LLM\u751f\u6210\u7684\u6837\u672c\u5728\u5b9e\u8df5\u4e2d\u5177\u6709\u5e94\u7528\u4ef7\u503c\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u5982\u4f55\u5728\u5b9e\u9645\u4e2d\u4f7f\u7528\u8fd9\u4e9b\u6837\u672c\u7684\u5efa\u8bae\u3002"}}
{"id": "2511.18818", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18818", "abs": "https://arxiv.org/abs/2511.18818", "authors": ["Georgi Bebrov"], "title": "Quantum Key Distribution Based on Systematic Polar Coding", "comment": "7 pages, 3 figures, uses IEEEtran document class", "summary": "Here we concerned with quantum key distribution - a way to establish common cryptographic key between several parties. The work proposes a combination between quantum key distribution and systematic polar coding (an error correction algorithm) frameworks - quantum key distribution based on systematic polar coding. This results in obtaining key rates greater than standard quantum key distribution (BB84) and its efficient version (eBB84) when finite-size regime and lower-error-rate quantum channel are considered.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u548c\u7cfb\u7edf\u6781\u6027\u7f16\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u6709\u9650\u5c3a\u5bf8\u673a\u5236\u548c\u4f4e\u8bef\u7801\u7387\u91cf\u5b50\u4fe1\u9053\u4e0b\uff0c\u83b7\u5f97\u4e86\u6bd4\u6807\u51c6BB84\u53ca\u5176\u9ad8\u6548\u7248\u672c\u66f4\u9ad8\u7684\u5bc6\u94a5\u7387\u3002", "motivation": "\u4f20\u7edf\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\u5728\u6709\u9650\u5c3a\u5bf8\u673a\u5236\u4e0b\u7684\u5bc6\u94a5\u7387\u6709\u9650\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5c06\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u4e0e\u7cfb\u7edf\u6781\u6027\u7f16\u7801\u6846\u67b6\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u57fa\u4e8e\u7cfb\u7edf\u6781\u6027\u7f16\u7801\u7684\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\u3002", "result": "\u5728\u6709\u9650\u5c3a\u5bf8\u673a\u5236\u548c\u4f4e\u8bef\u7801\u7387\u91cf\u5b50\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u65b0\u65b9\u6cd5\u83b7\u5f97\u4e86\u6bd4\u6807\u51c6BB84\u548ceBB84\u66f4\u9ad8\u7684\u5bc6\u94a5\u7387\u3002", "conclusion": "\u7cfb\u7edf\u6781\u6027\u7f16\u7801\u4e0e\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7684\u7ed3\u5408\u80fd\u6709\u6548\u63d0\u5347\u5bc6\u94a5\u5206\u53d1\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6709\u9650\u5c3a\u5bf8\u548c\u4f4e\u8bef\u7801\u7387\u573a\u666f\u4e0b\u3002"}}
{"id": "2511.17631", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17631", "abs": "https://arxiv.org/abs/2511.17631", "authors": ["Bingjun Wei", "Xuemei Cao", "Jiafen Liu", "Haoyang Liang", "Xin Yang"], "title": "Enhanced Federated Deep Multi-View Clustering under Uncertainty Scenario", "comment": null, "summary": "Traditional Federated Multi-View Clustering assumes uniform views across clients, yet practical deployments reveal heterogeneous view completeness with prevalent incomplete, redundant, or corrupted data. While recent approaches model view heterogeneity, they neglect semantic conflicts from dynamic view combinations, failing to address dual uncertainties: view uncertainty (semantic inconsistency from arbitrary view pairings) and aggregation uncertainty (divergent client updates with imbalanced contributions). To address these, we propose a novel Enhanced Federated Deep Multi-View Clustering framework: first align local semantics, hierarchical contrastive fusion within clients resolves view uncertainty by eliminating semantic conflicts; a view adaptive drift module mitigates aggregation uncertainty through global-local prototype contrast that dynamically corrects parameter deviations; and a balanced aggregation mechanism coordinates client updates. Experimental results demonstrate that EFDMVC achieves superior robustness against heterogeneous uncertain views across multiple benchmark datasets, consistently outperforming all state-of-the-art baselines in comprehensive evaluations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEFDMVC\u6846\u67b6\uff0c\u89e3\u51b3\u8054\u90a6\u591a\u89c6\u56fe\u805a\u7c7b\u4e2d\u89c6\u56fe\u5f02\u6784\u6027\u548c\u8bed\u4e49\u51b2\u7a81\u7684\u53cc\u91cd\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u5c42\u6b21\u5bf9\u6bd4\u878d\u5408\u3001\u89c6\u56fe\u81ea\u9002\u5e94\u6f02\u79fb\u6a21\u5757\u548c\u5e73\u8861\u805a\u5408\u673a\u5236\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u591a\u89c6\u56fe\u805a\u7c7b\u5047\u8bbe\u5ba2\u6237\u7aef\u89c6\u56fe\u7edf\u4e00\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4e2d\u5b58\u5728\u89c6\u56fe\u5b8c\u6574\u6027\u5f02\u6784\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u52a8\u6001\u89c6\u56fe\u7ec4\u5408\u4ea7\u751f\u7684\u8bed\u4e49\u51b2\u7a81\uff0c\u672a\u80fd\u89e3\u51b3\u89c6\u56fe\u4e0d\u786e\u5b9a\u6027\u548c\u805a\u5408\u4e0d\u786e\u5b9a\u6027\u7684\u53cc\u91cd\u6311\u6218\u3002", "method": "1) \u5c42\u6b21\u5bf9\u6bd4\u878d\u5408\uff1a\u5728\u5ba2\u6237\u7aef\u5185\u5bf9\u9f50\u5c40\u90e8\u8bed\u4e49\uff0c\u6d88\u9664\u89c6\u56fe\u4e0d\u786e\u5b9a\u6027\uff1b2) \u89c6\u56fe\u81ea\u9002\u5e94\u6f02\u79fb\u6a21\u5757\uff1a\u901a\u8fc7\u5168\u5c40-\u5c40\u90e8\u539f\u578b\u5bf9\u6bd4\u52a8\u6001\u4fee\u6b63\u53c2\u6570\u504f\u5dee\uff0c\u7f13\u89e3\u805a\u5408\u4e0d\u786e\u5b9a\u6027\uff1b3) \u5e73\u8861\u805a\u5408\u673a\u5236\uff1a\u534f\u8c03\u5ba2\u6237\u7aef\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eEFDMVC\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5bf9\u5f02\u6784\u4e0d\u786e\u5b9a\u89c6\u56fe\u5177\u6709\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\uff0c\u5728\u5168\u9762\u8bc4\u4f30\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "EFDMVC\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u591a\u89c6\u56fe\u805a\u7c7b\u4e2d\u7684\u53cc\u91cd\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u4e3a\u5904\u7406\u89c6\u56fe\u5f02\u6784\u6027\u548c\u8bed\u4e49\u51b2\u7a81\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18913", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.18913", "abs": "https://arxiv.org/abs/2511.18913", "authors": ["Marcel Kokorsch", "Guido Dietl"], "title": "Processing Entangled Links Into Secure Cryptographic Keys", "comment": "11 pages, 1 figure", "summary": "The following paper presents a holistic approach to the processing of entangled links within entanglement based quantum key distribution protocols, whose security relies on the Bell inequality. We investigate the interactions, and the collective impact, of the whole processing chain on the final secure key rate. This includes the quantum mechanical preprocessing in the form of entanglement distillation, processing of the entangled states via measurements and the necessary classical postprocessing based on the measurement results. Our investigations are based on the principle idea of the Eckert 1991 protocol and utilize the secret key capacity introduced by Devetak and Winter in 2005. Our results include a proof on what measurement bases need to be chosen to achieve this capacity for the case of Werner states. It also presents a new processing strategy and compares it with the most common one that can be found within the literature. Furthermore, it answers the question on how much entanglement distillation is optimal. By doing so we propose a unified formalism, describing the whole processing chain, that can be used to make quantitative statements on the relation between the quality and quantity of entangled but noisy quantum states used for generating secure keys.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5904\u7406\u7ea0\u7f20\u94fe\u8def\u7684\u6574\u4f53\u65b9\u6cd5\uff0c\u7814\u7a76\u7ea0\u7f20\u84b8\u998f\u3001\u6d4b\u91cf\u548c\u7ecf\u5178\u540e\u5904\u7406\u5bf9\u6700\u7ec8\u5b89\u5168\u5bc6\u94a5\u7387\u7684\u96c6\u4f53\u5f71\u54cd\uff0c\u57fa\u4e8eEckert 1991\u534f\u8bae\u548cDevetak-Winter\u5bc6\u94a5\u5bb9\u91cf\u7406\u8bba\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8e\u8d1d\u5c14\u4e0d\u7b49\u5f0f\u7684\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\u4e2d\u7ea0\u7f20\u94fe\u8def\u7684\u6574\u4f53\u5904\u7406\uff0c\u5206\u6790\u6574\u4e2a\u5904\u7406\u94fe\u5bf9\u6700\u7ec8\u5b89\u5168\u5bc6\u94a5\u7387\u7684\u96c6\u4f53\u5f71\u54cd\u3002", "method": "\u57fa\u4e8eEckert 1991\u534f\u8bae\u539f\u7406\u548cDevetak-Winter\u5bc6\u94a5\u5bb9\u91cf\u7406\u8bba\uff0c\u63d0\u51fa\u7edf\u4e00\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u7ea0\u7f20\u84b8\u998f\u3001\u7ea0\u7f20\u6001\u6d4b\u91cf\u5904\u7406\u548c\u7ecf\u5178\u540e\u5904\u7406\u3002", "result": "\u8bc1\u660e\u4e86Werner\u6001\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5bc6\u94a5\u5bb9\u91cf\u6240\u9700\u7684\u6d4b\u91cf\u57fa\u9009\u62e9\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5904\u7406\u7b56\u7565\u5e76\u4e0e\u5e38\u89c1\u7b56\u7565\u6bd4\u8f83\uff0c\u786e\u5b9a\u4e86\u6700\u4f18\u7ea0\u7f20\u84b8\u998f\u91cf\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5904\u7406\u94fe\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u5b9a\u91cf\u5206\u6790\u7528\u4e8e\u751f\u6210\u5b89\u5168\u5bc6\u94a5\u7684\u566a\u58f0\u7ea0\u7f20\u6001\u7684\u8d28\u91cf\u4e0e\u6570\u91cf\u5173\u7cfb\u3002"}}
{"id": "2511.18723", "categories": ["cs.AI", "cs.DC", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.18723", "abs": "https://arxiv.org/abs/2511.18723", "authors": ["Longfei Wang", "Junyan Liu", "Fan Zhang", "Jiangwen Wei", "Yuanhua Tang", "Jie Sun", "Xiaodong Luo"], "title": "N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory", "comment": "18 pages, 2 figures", "summary": "Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aN2N\u7684\u53ef\u6269\u5c55\u5e76\u884c\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u8ba1\u7b97\u73af\u5883\u4e2d\u89e3\u51b3\u5927\u89c4\u6a21MILP\u95ee\u9898\u3002\u8be5\u6846\u67b6\u652f\u6301\u786e\u5b9a\u6027\u548c\u975e\u786e\u5b9a\u6027\u6a21\u5f0f\uff0c\u901a\u8fc7\u8282\u70b9\u5230\u8282\u70b9\u6620\u5c04\u5b9e\u73b0\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u7684\u5e76\u884c\u5316\uff0c\u5e76\u96c6\u6210\u4e86\u591a\u79cd\u9ad8\u7ea7\u6280\u672f\u6765\u5145\u5206\u5229\u7528\u5206\u5e03\u5f0f\u8ba1\u7b97\u8d44\u6e90\u3002", "motivation": "\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u6c42\u89e3\u4e2d\u7684\u5e76\u884c\u5316\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u52a0\u901f\u65b9\u6cd5\uff0c\u4f46\u7531\u4e8e\u5206\u652f\u5b9a\u754c\u6846\u67b6\u7684\u590d\u6742\u6027\u548cMILP\u6c42\u89e3\u5668\u4e2d\u4f17\u591a\u6709\u6548\u7b97\u6cd5\u7ec4\u4ef6\u7684\u5b58\u5728\uff0c\u4f7f\u5f97\u5e76\u884c\u5316\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u5f00\u53d1\u4e86N2N\u5e76\u884c\u6846\u67b6\uff0c\u91c7\u7528\u8282\u70b9\u5230\u8282\u70b9\u6620\u5c04\u65b9\u6cd5\uff0c\u652f\u6301\u786e\u5b9a\u6027\u548c\u975e\u786e\u5b9a\u6027\u6a21\u5f0f\u3002\u5728\u786e\u5b9a\u6027\u6a21\u5f0f\u4e0b\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u7684\u7b97\u6cd5\u786e\u4fdd\u4efb\u52a1\u6309\u786e\u5b9a\u987a\u5e8f\u751f\u6210\u548c\u6c42\u89e3\uff0c\u96c6\u6210\u4e86CP\u641c\u7d22\u548c\u901a\u7528\u539f\u59cb\u542f\u53d1\u5f0f\u7b49\u5148\u8fdb\u6280\u672f\uff0c\u5e76\u8fdb\u884c\u4e86\u81ea\u9002\u5e94\u6c42\u89e3\u548c\u6570\u636e\u901a\u4fe1\u4f18\u5316\u3002", "result": "\u5c06N2N\u4e0eSCIP\u96c6\u6210\u5f97\u5230N2N-SCIP\uff0c\u57281000\u4e2aMPI\u8fdb\u7a0b\u4e0b\uff0c\u975e\u786e\u5b9a\u6027N2N-SCIP\u5728\u9cb2\u9e4f\u548cx86\u8ba1\u7b97\u96c6\u7fa4\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8622.52\u548c12.71\u7684\u52a0\u901f\u6bd4\uff0c\u6bd4ParaSCIP\u5feb1.98\u500d\u548c2.08\u500d\u3002\u786e\u5b9a\u6027\u6a21\u5f0f\u4e0bN2N-SCIP\u5728\u4e0d\u540c\u8fdb\u7a0b\u6570\u548c\u8ba1\u7b97\u96c6\u7fa4\u4e0a\u4e5f\u663e\u8457\u4f18\u4e8eParaSCIP\u3002", "conclusion": "N2N\u6846\u67b6\u5728\u5206\u5e03\u5f0f\u5e76\u884cMILP\u6c42\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5177\u6709\u5f88\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u5206\u5e03\u5f0f\u8ba1\u7b97\u8d44\u6e90\u52a0\u901fMILP\u95ee\u9898\u6c42\u89e3\u3002"}}
{"id": "2511.19125", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19125", "abs": "https://arxiv.org/abs/2511.19125", "authors": ["L. Sansoni", "E. Stefanutti", "C. Benedetti", "I. Gianani", "C. Taballione", "A. Toor", "L. Herrera", "M. Pistilli", "S. Santoro", "M. Barbieri", "A. Chiuri"], "title": "Noisy dynamics of confined quantum walks on a chip", "comment": "10 pages, 9 figures, 2 Appendices", "summary": "Quantum walks represent an excellent testbed for investigating the interplay between unitary coherent and incoherent dissipative processes. Thanks to photonic quantum interferometers of considerable size, experimental studies could be performed, devoted to investigating the consequences of different sorts of realistic noise in these systems. In this work we employ a 20x20 on-chip multimode interferometer to introduce another key aspect in the problem: the presence of edges in the walker lattice, enforcing a confined evolution. We show how noise can disrupt translational symmetry and reshape interference patterns. The non trivial probability distributions obtained along the temporal evolution of the system demonstrate how speed up effects, localization and coherent oscillations are pillar concepts to be fully characterized and understood when applied in realistic quantum dynamics.", "AI": {"tldr": "\u672c\u6587\u4f7f\u752820x20\u7247\u4e0a\u591a\u6a21\u5e72\u6d89\u4eea\u7814\u7a76\u91cf\u5b50\u884c\u8d70\u4e2d\u6676\u683c\u8fb9\u754c\u548c\u566a\u58f0\u5bf9\u6f14\u5316\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u5c55\u793a\u4e86\u566a\u58f0\u5982\u4f55\u7834\u574f\u5e73\u79fb\u5bf9\u79f0\u6027\u5e76\u91cd\u5851\u5e72\u6d89\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u884c\u8d70\u4e2d\u76f8\u5e72\u8fc7\u7a0b\u4e0e\u8017\u6563\u8fc7\u7a0b\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u7279\u522b\u5173\u6ce8\u6676\u683c\u8fb9\u754c\u5bf9\u6f14\u5316\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u8fd9\u662f\u4e4b\u524d\u5b9e\u9a8c\u7814\u7a76\u8f83\u5c11\u6d89\u53ca\u7684\u65b9\u9762\u3002", "method": "\u4f7f\u752820x20\u7247\u4e0a\u591a\u6a21\u5e72\u6d89\u4eea\uff0c\u5728\u91cf\u5b50\u884c\u8d70\u7cfb\u7edf\u4e2d\u5f15\u5165\u6676\u683c\u8fb9\u754c\uff0c\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u566a\u58f0\u5bf9\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002", "result": "\u566a\u58f0\u7834\u574f\u4e86\u5e73\u79fb\u5bf9\u79f0\u6027\uff0c\u91cd\u5851\u4e86\u5e72\u6d89\u6a21\u5f0f\uff0c\u4ea7\u751f\u4e86\u975e\u5e73\u51e1\u7684\u6982\u7387\u5206\u5e03\uff0c\u5c55\u793a\u4e86\u52a0\u901f\u6548\u5e94\u3001\u5c40\u57df\u5316\u548c\u76f8\u5e72\u632f\u8361\u7b49\u73b0\u8c61\u3002", "conclusion": "\u5728\u73b0\u5b9e\u7684\u91cf\u5b50\u52a8\u529b\u5b66\u4e2d\uff0c\u52a0\u901f\u6548\u5e94\u3001\u5c40\u57df\u5316\u548c\u76f8\u5e72\u632f\u8361\u662f\u9700\u8981\u5145\u5206\u8868\u5f81\u548c\u7406\u89e3\u7684\u6838\u5fc3\u6982\u5ff5\uff0c\u8fb9\u754c\u548c\u566a\u58f0\u7684\u5f15\u5165\u663e\u8457\u6539\u53d8\u4e86\u91cf\u5b50\u884c\u8d70\u7684\u6f14\u5316\u884c\u4e3a\u3002"}}
{"id": "2511.19160", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19160", "abs": "https://arxiv.org/abs/2511.19160", "authors": ["Nguyen Minh Duc", "Vu Tuan Hai", "Le Bin Ho", "Tran Nguyen Lan"], "title": "Flexible Genetic Algorithm for Quantum Support Vector Machines", "comment": "14 pages, 7 figures", "summary": "Quantum Support Vector Machines (QSVM) is one of the most promising frameworks in quantum machine learning, yet their performance depends on the design of the feature map. Conventional approaches rely on fixed quantum circuits, which often fail to generalize across datasets. To address this limitation, we propose GA-QSVM, a hybrid framework that employs Genetic Algorithms (GA) to automatically optimize feature maps. The proposed method introduces a configurable framework that flexibly defines the evolutionary parameters, enabling the construction of adaptive circuits. Experimental evaluation of datasets, including Digits, Fashion, Wine, and Breast Cancer, demonstrates that GA-QSVMs achieve a comparable accuracy compared to classical SVMs and standard QSVMs. Furthermore, transfer learning results indicate that GA-QSVM's circuits generalize effectively across datasets. These findings highlight the potential of evolutionary strategies to automate and enhance kernel design for future quantum machine learning applications.", "AI": {"tldr": "\u63d0\u51faGA-QSVM\u6846\u67b6\uff0c\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u81ea\u52a8\u4f18\u5316\u91cf\u5b50\u652f\u6301\u5411\u91cf\u673a\u4e2d\u7684\u7279\u5f81\u6620\u5c04\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u56fa\u5b9a\u91cf\u5b50\u7535\u8def\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u91cf\u5b50\u652f\u6301\u5411\u91cf\u673a\u4f7f\u7528\u56fa\u5b9a\u7279\u5f81\u6620\u5c04\u7535\u8def\uff0c\u96be\u4ee5\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u826f\u597d\u6cdb\u5316\u6027\u80fd\uff0c\u9700\u8981\u81ea\u52a8\u5316\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u91cf\u5b50\u7279\u5f81\u6620\u5c04\uff0c\u63d0\u4f9b\u53ef\u914d\u7f6e\u6846\u67b6\u7075\u6d3b\u5b9a\u4e49\u8fdb\u5316\u53c2\u6570\uff0c\u6784\u5efa\u81ea\u9002\u5e94\u91cf\u5b50\u7535\u8def\u3002", "result": "\u5728Digits\u3001Fashion\u3001Wine\u548cBreast Cancer\u6570\u636e\u96c6\u4e0a\uff0cGA-QSVM\u8fbe\u5230\u4e0e\u7ecf\u5178SVM\u548c\u6807\u51c6QSVM\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u4e14\u8fc1\u79fb\u5b66\u4e60\u663e\u793a\u5176\u7535\u8def\u5177\u6709\u826f\u597d\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8fdb\u5316\u7b56\u7565\u5728\u81ea\u52a8\u5316\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6838\u8bbe\u8ba1\u65b9\u9762\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17639", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17639", "abs": "https://arxiv.org/abs/2511.17639", "authors": ["Yibing Wan", "Zhengxiong Guan", "Chaoli Zhang", "Xiaoyang Li", "Lai Xu", "Beibei Jia", "Zhenzhe Zheng", "Fan Wu"], "title": "TTF: A Trapezoidal Temporal Fusion Framework for LTV Forecasting in Douyin", "comment": "Accepted by AAAI IAAI Track", "summary": "In the user growth scenario, Internet companies invest heavily in paid acquisition channels to acquire new users. But sustainable growth depends on acquired users' generating lifetime value (LTV) exceeding customer acquisition cost (CAC). In order to maximize LTV/CAC ratio, it is crucial to predict channel-level LTV in an early stage for further optimization of budget allocation. The LTV forecasting problem is significantly different from traditional time series forecasting problems, and there are three main challenges. Firstly, it is an unaligned multi-time series forecasting problem that each channel has a number of LTV series of different activation dates. Secondly, to predict in the early stage, it faces the imbalanced short-input long-output (SILO) challenge. Moreover, compared with the commonly used time series datasets, the real LTV series are volatile and non-stationary, with more frequent fluctuations and higher variance. In this work, we propose a novel framework called Trapezoidal Temporal Fusion (TTF) to address the above challenges. We introduce a trapezoidal multi-time series module to deal with data unalignment and SILO challenges, and output accurate predictions with a multi-tower structure called MT-FusionNet. The framework has been deployed to the online system for Douyin. Compared to the previously deployed online model, MAPEp decreased by 4.3%, and MAPEa decreased by 3.2%, where MAPEp denotes the point-wise MAPE of the LTV curve and MAPEa denotes the MAPE of the aggregated LTV.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u68af\u5f62\u65f6\u95f4\u878d\u5408\uff08TTF\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u7528\u6237\u589e\u957f\u573a\u666f\u4e2d\u6e20\u9053\u7ea7LTV\u9884\u6d4b\u7684\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u672a\u5bf9\u9f50\u7684\u591a\u65f6\u95f4\u5e8f\u5217\u3001\u77ed\u8f93\u5165\u957f\u8f93\u51fa\uff08SILO\uff09\u95ee\u9898\u4ee5\u53ca\u6570\u636e\u7684\u6ce2\u52a8\u6027\u548c\u975e\u5e73\u7a33\u6027\u3002", "motivation": "\u5728\u7528\u6237\u589e\u957f\u573a\u666f\u4e2d\uff0c\u4e92\u8054\u7f51\u516c\u53f8\u5927\u91cf\u6295\u8d44\u4ed8\u8d39\u83b7\u53d6\u6e20\u9053\u6765\u83b7\u53d6\u65b0\u7528\u6237\uff0c\u4f46\u53ef\u6301\u7eed\u589e\u957f\u53d6\u51b3\u4e8e\u83b7\u53d6\u7528\u6237\u7684\u7ec8\u8eab\u4ef7\u503c\uff08LTV\uff09\u8d85\u8fc7\u5ba2\u6237\u83b7\u53d6\u6210\u672c\uff08CAC\uff09\u3002\u4e3a\u4e86\u6700\u5927\u5316LTV/CAC\u6bd4\u7387\uff0c\u9700\u8981\u5728\u65e9\u671f\u9636\u6bb5\u9884\u6d4b\u6e20\u9053\u7ea7LTV\u4ee5\u4f18\u5316\u9884\u7b97\u5206\u914d\u3002", "method": "\u63d0\u51fa\u4e86\u68af\u5f62\u65f6\u95f4\u878d\u5408\uff08TTF\uff09\u6846\u67b6\uff0c\u5305\u62ec\u68af\u5f62\u591a\u65f6\u95f4\u5e8f\u5217\u6a21\u5757\u6765\u5904\u7406\u6570\u636e\u672a\u5bf9\u9f50\u548cSILO\u6311\u6218\uff0c\u4ee5\u53ca\u4f7f\u7528\u540d\u4e3aMT-FusionNet\u7684\u591a\u5854\u7ed3\u6784\u8f93\u51fa\u51c6\u786e\u9884\u6d4b\u3002", "result": "\u8be5\u6846\u67b6\u5df2\u5728\u6296\u97f3\u7684\u5728\u7ebf\u7cfb\u7edf\u4e2d\u90e8\u7f72\u3002\u4e0e\u4e4b\u524d\u90e8\u7f72\u7684\u5728\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cLTV\u66f2\u7ebf\u7684\u70b9\u72b6MAPE\uff08MAPEp\uff09\u964d\u4f4e\u4e864.3%\uff0c\u805a\u5408LTV\u7684MAPE\uff08MAPEa\uff09\u964d\u4f4e\u4e863.2%\u3002", "conclusion": "TTF\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LTV\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u5b9e\u9645\u4e1a\u52a1\u573a\u666f\u3002"}}
{"id": "2511.19219", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2511.19219", "abs": "https://arxiv.org/abs/2511.19219", "authors": ["Christopher W. W\u00e4chtler", "Gloria Platero"], "title": "Synchronized Aharonov-Bohm Motifs via Engineered Dissipation", "comment": null, "summary": "The interplay between external gauge fields and lattice geometry can induce extreme localization dynamics through complete destructive interference. We show that combining this flux-induced localization with engineered dissipation leads to robust spin synchronization in rotationally symmetric spin geometries, referred to as Aharonov-Bohm motifs, with cyclic symmetries of any order. The synchronized dynamics is independent of initial conditions and features entanglement among spins within each motif. We further demonstrate that multiple motifs can fully synchronize when coupled, which is achieved by applying additional collective dissipation acting on all intra-motif spins. These results reveal a direct connection between flux-induced localization, dissipative engineering, and collective quantum synchronization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u901a\u8fc7\u7ed3\u5408\u901a\u91cf\u8bf1\u5bfc\u7684\u5c40\u57df\u5316\u548c\u5de5\u7a0b\u8017\u6563\uff0c\u53ef\u4ee5\u5728\u5177\u6709\u65cb\u8f6c\u5bf9\u79f0\u6027\u7684\u81ea\u65cb\u51e0\u4f55\u7ed3\u6784\u4e2d\u5b9e\u73b0\u9c81\u68d2\u7684\u540c\u6b65\u52a8\u529b\u5b66\uff0c\u8fd9\u79cd\u540c\u6b65\u72ec\u7acb\u4e8e\u521d\u59cb\u6761\u4ef6\u5e76\u4ea7\u751f\u81ea\u65cb\u95f4\u7684\u7ea0\u7f20\u3002", "motivation": "\u7814\u7a76\u5916\u90e8\u89c4\u8303\u573a\u4e0e\u6676\u683c\u51e0\u4f55\u7684\u76f8\u4e92\u4f5c\u7528\u5982\u4f55\u901a\u8fc7\u5b8c\u5168\u76f8\u6d88\u5e72\u6d89\u8bf1\u5bfc\u6781\u7aef\u5c40\u57df\u5316\u52a8\u529b\u5b66\uff0c\u5e76\u63a2\u7d22\u5c06\u5176\u4e0e\u5de5\u7a0b\u8017\u6563\u7ed3\u5408\u4ee5\u5b9e\u73b0\u91cf\u5b50\u540c\u6b65\u7684\u53ef\u80fd\u6027\u3002", "method": "\u7ed3\u5408\u901a\u91cf\u8bf1\u5bfc\u7684\u5c40\u57df\u5316\u4e0e\u5de5\u7a0b\u8017\u6563\uff0c\u5728\u5177\u6709\u5faa\u73af\u5bf9\u79f0\u6027\u7684Aharonov-Bohm motif\u7ed3\u6784\u4e2d\u5b9e\u73b0\u81ea\u65cb\u540c\u6b65\uff0c\u5e76\u901a\u8fc7\u65bd\u52a0\u989d\u5916\u7684\u96c6\u4f53\u8017\u6563\u6765\u8026\u5408\u591a\u4e2amotif\u3002", "result": "\u5728\u65cb\u8f6c\u5bf9\u79f0\u7684\u81ea\u65cb\u51e0\u4f55\u7ed3\u6784\u4e2d\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u540c\u6b65\u52a8\u529b\u5b66\uff0c\u8fd9\u79cd\u540c\u6b65\u72ec\u7acb\u4e8e\u521d\u59cb\u6761\u4ef6\u5e76\u4ea7\u751f\u81ea\u65cb\u95f4\u7684\u7ea0\u7f20\u3002\u591a\u4e2amotif\u5728\u8026\u5408\u65f6\u53ef\u4ee5\u5b8c\u5168\u540c\u6b65\u3002", "conclusion": "\u63ed\u793a\u4e86\u901a\u91cf\u8bf1\u5bfc\u5c40\u57df\u5316\u3001\u8017\u6563\u5de5\u7a0b\u548c\u96c6\u4f53\u91cf\u5b50\u540c\u6b65\u4e4b\u95f4\u7684\u76f4\u63a5\u8054\u7cfb\uff0c\u4e3a\u91cf\u5b50\u540c\u6b65\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u5b9e\u73b0\u673a\u5236\u3002"}}
{"id": "2511.18845", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18845", "abs": "https://arxiv.org/abs/2511.18845", "authors": ["Changxin Huang", "Lv Tang", "Zhaohuan Zhan", "Lisha Yu", "Runhao Zeng", "Zun Liu", "Zhengjie Wang", "Jianqiang Li"], "title": "UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model", "comment": null, "summary": "Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.", "AI": {"tldr": "UNeMo\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\u548c\u5206\u5c42\u9884\u6d4b-\u53cd\u9988\u673a\u5236\uff0c\u534f\u540c\u4f18\u5316\u89c6\u89c9\u72b6\u6001\u63a8\u7406\u548c\u5bfc\u822a\u51b3\u7b56\uff0c\u5728\u672a\u89c1\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5bfc\u822a\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bfc\u822a\u65b9\u6cd5\u4ec5\u9650\u4e8e\u8bed\u8a00\u6a21\u6001\u63a8\u7406\uff0c\u7f3a\u4e4f\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u63a8\u7406\u6a21\u5757\u4e0e\u5bfc\u822a\u7b56\u7565\u5206\u5f00\u4f18\u5316\u5bfc\u81f4\u4e0d\u517c\u5bb9\u548c\u4f18\u5316\u76ee\u6807\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b(MWM)\u8054\u5408\u9884\u6d4b\u540e\u7eed\u89c6\u89c9\u72b6\u6001\uff0c\u901a\u8fc7\u5206\u5c42\u9884\u6d4b-\u53cd\u9988\u673a\u5236\u4e0e\u5bfc\u822a\u7b56\u7565\u534f\u4f5c\uff0c\u5f62\u6210\u52a8\u6001\u53cc\u5411\u4fc3\u8fdb\u673a\u5236\u3002", "result": "\u5728R2R\u548cREVERIE\u6570\u636e\u96c6\u4e0a\uff0cUNeMo\u5728\u672a\u89c1\u573a\u666f\u7684\u5bfc\u822a\u7cbe\u5ea6\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u9ad8\u51fa2.1%\u548c0.7%\u3002", "conclusion": "UNeMo\u901a\u8fc7\u534f\u540c\u4f18\u5316\u89c6\u89c9\u63a8\u7406\u548c\u5bfc\u822a\u51b3\u7b56\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.17645", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17645", "abs": "https://arxiv.org/abs/2511.17645", "authors": ["Sandro Andric"], "title": "BlockCert: Certified Blockwise Extraction of Transformer Mechanisms", "comment": "16 pages, 1 figure", "summary": "Mechanistic interpretability aspires to reverse-engineer neural networks into explicit algorithms, while model editing seeks to modify specific behaviours without retraining. Both areas are typically evaluated with informal evidence and ad-hoc experiments, with few explicit guarantees about how far an extracted or edited model can drift from the original on relevant inputs. We introduce BlockCert, a framework for certified blockwise extraction of transformer mechanisms, and outline how a lightweight extension can support certified local edits. Given a pre-trained transformer and a prompt distribution, BlockCert extracts structured surrogate implementations for residual blocks together with machine-checkable certificates that bound approximation error, record coverage metrics, and hash the underlying artifacts. We formalize a simple Lipschitz-based composition theorem in Lean 4 that lifts these local guarantees to a global deviation bound. Empirically, we apply the framework to GPT-2 small, TinyLlama-1.1B-Chat, and Llama-3.2-3B. Across these models we obtain high per-block coverage and small residual errors on the evaluated prompts, and in the TinyLlama setting we show that a fully stitched model matches the baseline perplexity within approximately 6e-5 on stress prompts. Our results suggest that blockwise extraction with explicit certificates is feasible for real transformer language models and offers a practical bridge between mechanistic interpretability and formal reasoning about model behaviour.", "AI": {"tldr": "BlockCert\u662f\u4e00\u4e2a\u7528\u4e8e\u8ba4\u8bc1\u5f0f\u5757\u7ea7\u63d0\u53d6transformer\u673a\u5236\u5e76\u652f\u6301\u8ba4\u8bc1\u5c40\u90e8\u7f16\u8f91\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u7ed3\u6784\u5316\u66ff\u4ee3\u5b9e\u73b0\u5e76\u63d0\u4f9b\u673a\u5668\u53ef\u68c0\u67e5\u7684\u8bc1\u4e66\u6765\u4fdd\u8bc1\u8fd1\u4f3c\u8bef\u5dee\u754c\u9650\u3002", "motivation": "\u89e3\u51b3\u673a\u5236\u53ef\u89e3\u91ca\u6027\u548c\u6a21\u578b\u7f16\u8f91\u9886\u57df\u7f3a\u4e4f\u6b63\u5f0f\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u4e3a\u63d0\u53d6\u6216\u7f16\u8f91\u7684\u6a21\u578b\u5728\u76f8\u5173\u8f93\u5165\u4e0a\u7684\u6f02\u79fb\u63d0\u4f9b\u660e\u786e\u754c\u9650\u3002", "method": "\u57fa\u4e8e\u9884\u8bad\u7ec3transformer\u548c\u63d0\u793a\u5206\u5e03\uff0c\u63d0\u53d6\u6b8b\u5dee\u5757\u7684\u7ed3\u6784\u5316\u66ff\u4ee3\u5b9e\u73b0\uff0c\u63d0\u4f9b\u5305\u542b\u8fd1\u4f3c\u8bef\u5dee\u754c\u9650\u3001\u8986\u76d6\u5ea6\u6307\u6807\u548c\u5e95\u5c42\u5de5\u4ef6\u54c8\u5e0c\u7684\u673a\u5668\u53ef\u68c0\u67e5\u8bc1\u4e66\uff0c\u5e76\u4f7f\u7528Lipschitz-based\u7ec4\u5408\u5b9a\u7406\u5c06\u5c40\u90e8\u4fdd\u8bc1\u63d0\u5347\u4e3a\u5168\u5c40\u504f\u5dee\u754c\u9650\u3002", "result": "\u5728GPT-2 small\u3001TinyLlama-1.1B-Chat\u548cLlama-3.2-3B\u4e0a\u83b7\u5f97\u9ad8\u5757\u7ea7\u8986\u76d6\u5ea6\u548c\u5c0f\u6b8b\u5dee\u8bef\u5dee\uff0c\u5728TinyLlama\u8bbe\u7f6e\u4e2d\u5b8c\u5168\u62fc\u63a5\u6a21\u578b\u5728\u538b\u529b\u63d0\u793a\u4e0a\u7684\u56f0\u60d1\u5ea6\u4e0e\u57fa\u7ebf\u76f8\u5dee\u7ea66e-5\u3002", "conclusion": "\u5757\u7ea7\u63d0\u53d6\u4e0e\u663e\u5f0f\u8bc1\u4e66\u5bf9\u4e8e\u5b9e\u9645transformer\u8bed\u8a00\u6a21\u578b\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u673a\u5236\u53ef\u89e3\u91ca\u6027\u548c\u6a21\u578b\u884c\u4e3a\u7684\u5f62\u5f0f\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u6865\u6881\u3002"}}
{"id": "2511.19238", "categories": ["quant-ph", "hep-th", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.19238", "abs": "https://arxiv.org/abs/2511.19238", "authors": ["Ariel Caticha"], "title": "Entropic Dynamics approach to Quantum Electrodynamics", "comment": "31 pages. Invited paper for the Journal Entropy, special issue \"SUURI of Information Geometry: Dedicated to SUURI Engineer Professor Shun'ichi Amari on the Occasion of His 90th Birthday.\"", "summary": "Entropic dynamics (ED) is a framework that allows one to derive quantum theory as a Hamilton-Killing flow on the cotangent bundle of a statistical manifold. These flows are such that they preserve the symplectic and the (information) metric geometries; they explain the linearity of quantum mechanics and the appearance of complex numbers. In this paper the ED framework is extended to deal with local gauge symmetries. More specifically, on the basis of maximum entropy methods and information geometry, for an appropriate choice of ontic variables and constraints, we derive the quantum electrodynamics of radiation fields interacting with charged particles. As a test that despite its unorthodox foundation the ED approach is empirically successful we derive the Maxwell equations.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u71b5\u52a8\u529b\u5b66\u6846\u67b6\u6765\u5904\u7406\u5c40\u90e8\u89c4\u8303\u5bf9\u79f0\u6027\uff0c\u57fa\u4e8e\u6700\u5927\u71b5\u65b9\u6cd5\u548c\u4fe1\u606f\u51e0\u4f55\u5b66\uff0c\u63a8\u5bfc\u51fa\u5e26\u7535\u7c92\u5b50\u4e0e\u8f90\u5c04\u573a\u76f8\u4e92\u4f5c\u7528\u7684\u91cf\u5b50\u7535\u52a8\u529b\u5b66\uff0c\u5e76\u9a8c\u8bc1\u4e86\u9ea6\u514b\u65af\u97e6\u65b9\u7a0b\u3002", "motivation": "\u5c06\u71b5\u52a8\u529b\u5b66\u6846\u67b6\u6269\u5c55\u5230\u5904\u7406\u5c40\u90e8\u89c4\u8303\u5bf9\u79f0\u6027\uff0c\u9a8c\u8bc1\u8be5\u975e\u6b63\u7edf\u57fa\u7840\u65b9\u6cd5\u5728\u7ecf\u9a8c\u4e0a\u7684\u6210\u529f\u6027\u3002", "method": "\u4f7f\u7528\u6700\u5927\u71b5\u65b9\u6cd5\u548c\u4fe1\u606f\u51e0\u4f55\u5b66\uff0c\u901a\u8fc7\u9002\u5f53\u9009\u62e9\u672c\u4f53\u53d8\u91cf\u548c\u7ea6\u675f\u6761\u4ef6\uff0c\u63a8\u5bfc\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u3002", "result": "\u6210\u529f\u63a8\u5bfc\u51fa\u5e26\u7535\u7c92\u5b50\u4e0e\u8f90\u5c04\u573a\u76f8\u4e92\u4f5c\u7528\u7684\u91cf\u5b50\u7535\u52a8\u529b\u5b66\uff0c\u5e76\u9a8c\u8bc1\u4e86\u9ea6\u514b\u65af\u97e6\u65b9\u7a0b\u3002", "conclusion": "\u71b5\u52a8\u529b\u5b66\u6846\u67b6\u80fd\u591f\u5904\u7406\u5c40\u90e8\u89c4\u8303\u5bf9\u79f0\u6027\uff0c\u5176\u975e\u6b63\u7edf\u57fa\u7840\u5728\u7ecf\u9a8c\u4e0a\u662f\u6210\u529f\u7684\uff0c\u80fd\u591f\u63a8\u5bfc\u51fa\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u7684\u6838\u5fc3\u65b9\u7a0b\u3002"}}
{"id": "2511.18874", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA", "cs.RO", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.18874", "abs": "https://arxiv.org/abs/2511.18874", "authors": ["Yuzhi Chen", "Yuanchang Xie", "Lei Zhao", "Pan Liu", "Yajie Zou", "Chen Wang"], "title": "GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction", "comment": null, "summary": "Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.", "AI": {"tldr": "GContextFormer\u662f\u4e00\u4e2a\u65e0\u9700\u9ad8\u7cbe\u5730\u56fe\u7684\u63d2\u4ef6\u5f0f\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5168\u5c40\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6df7\u5408\u6ce8\u610f\u529b\u548c\u7f29\u653e\u52a0\u6027\u805a\u5408\u5b9e\u73b0\u610f\u56fe\u5bf9\u9f50\u7684\u9884\u6d4b\uff0c\u5728\u9ad8\u901f\u516c\u8def\u531d\u9053\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709HD\u5730\u56fe\u4f9d\u8d56\u6a21\u578b\u7684\u6570\u636e\u83b7\u53d6\u6210\u672c\u9ad8\u3001\u66f4\u65b0\u5ef6\u8fdf\u548c\u8f93\u5165\u635f\u574f\u95ee\u9898\uff0c\u4ee5\u53ca\u65e0\u5730\u56fe\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587\u3001\u6ce8\u610f\u529b\u673a\u5236\u8fc7\u5ea6\u653e\u5927\u76f4\u7ebf\u6a21\u5f0f\u800c\u6291\u5236\u8fc7\u6e21\u6a21\u5f0f\u5bfc\u81f4\u7684\u8fd0\u52a8-\u610f\u56fe\u9519\u4f4d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff1a\u8fd0\u52a8\u611f\u77e5\u7f16\u7801\u5668\u901a\u8fc7\u6709\u754c\u7f29\u653e\u52a0\u6027\u805a\u5408\u6784\u5efa\u573a\u666f\u7ea7\u610f\u56fe\u5148\u9a8c\uff0c\u5728\u5171\u4eab\u5168\u5c40\u4e0a\u4e0b\u6587\u4e2d\u7ec6\u5316\u6bcf\u6a21\u5f0f\u8868\u793a\uff1b\u5206\u5c42\u4ea4\u4e92\u89e3\u7801\u5668\u901a\u8fc7\u53cc\u8def\u5f84\u4ea4\u53c9\u6ce8\u610f\u529b\u5206\u89e3\u793e\u4ea4\u63a8\u7406\uff0c\u6807\u51c6\u8def\u5f84\u786e\u4fdd\u51e0\u4f55\u8986\u76d6\uff0c\u90bb\u5c45\u4e0a\u4e0b\u6587\u589e\u5f3a\u8def\u5f84\u5f3a\u8c03\u663e\u8457\u4ea4\u4e92\uff0c\u95e8\u63a7\u6a21\u5757\u5e73\u8861\u4e24\u8005\u8d21\u732e\u3002", "result": "\u5728TOD-VT\u6570\u636e\u96c6\u7684\u516b\u4e2a\u9ad8\u901f\u516c\u8def\u531d\u9053\u573a\u666f\u4e2d\uff0cGContextFormer\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709transformer\u6a21\u578b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\uff0c\u5728\u9ad8\u66f2\u7387\u548c\u8fc7\u6e21\u533a\u57df\u901a\u8fc7\u7a7a\u95f4\u5206\u5e03\u83b7\u5f97\u96c6\u4e2d\u6539\u8fdb\u3002", "conclusion": "GContextFormer\u901a\u8fc7\u8fd0\u52a8\u6a21\u5f0f\u533a\u5206\u548c\u90bb\u5c45\u4e0a\u4e0b\u6587\u8c03\u5236\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\uff0c\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u5411\u8de8\u57df\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.17647", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17647", "abs": "https://arxiv.org/abs/2511.17647", "authors": ["Liyuan Deng", "Yunpeng Bai", "Yongkang Dai", "Xiaoshui Huang", "Hongping Gan", "Dongshuo Huang", "Hao jiacheng", "Yilei Shi"], "title": "MamTiff-CAD: Multi-Scale Latent Diffusion with Mamba+ for Complex Parametric Sequence", "comment": "ICCV 2025 Conference", "summary": "Parametric Computer-Aided Design (CAD) is crucial in industrial applications, yet existing approaches often struggle to generate long sequence parametric commands due to complex CAD models' geometric and topological constraints. To address this challenge, we propose MamTiff-CAD, a novel CAD parametric command sequences generation framework that leverages a Transformer-based diffusion model for multi-scale latent representations. Specifically, we design a novel autoencoder that integrates Mamba+ and Transformer, to transfer parameterized CAD sequences into latent representations. The Mamba+ block incorporates a forget gate mechanism to effectively capture long-range dependencies. The non-autoregressive Transformer decoder reconstructs the latent representations. A diffusion model based on multi-scale Transformer is then trained on these latent embeddings to learn the distribution of long sequence commands. In addition, we also construct a dataset that consists of long parametric sequences, which is up to 256 commands for a single CAD model. Experiments demonstrate that MamTiff-CAD achieves state-of-the-art performance on both reconstruction and generation tasks, confirming its effectiveness for long sequence (60-256) CAD model generation.", "AI": {"tldr": "MamTiff-CAD\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u6269\u6563\u6a21\u578b\u7684CAD\u53c2\u6570\u5316\u547d\u4ee4\u5e8f\u5217\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u6f5c\u5728\u8868\u793a\u5904\u7406\u957f\u5e8f\u5217CAD\u5efa\u6a21\u95ee\u9898\uff0c\u572860-256\u547d\u4ee4\u957f\u5ea6\u7684\u5e8f\u5217\u751f\u6210\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684CAD\u53c2\u6570\u5316\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742CAD\u6a21\u578b\u7684\u51e0\u4f55\u548c\u62d3\u6251\u7ea6\u675f\u65f6\uff0c\u96be\u4ee5\u751f\u6210\u957f\u5e8f\u5217\u53c2\u6570\u547d\u4ee4\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u96c6\u6210Mamba+\u548cTransformer\u7684\u65b0\u578b\u81ea\u7f16\u7801\u5668\uff0c\u5c06\u53c2\u6570\u5316CAD\u5e8f\u5217\u8f6c\u6362\u4e3a\u6f5c\u5728\u8868\u793a\uff1bMamba+\u5757\u91c7\u7528\u9057\u5fd8\u95e8\u673a\u5236\u6355\u83b7\u957f\u7a0b\u4f9d\u8d56\uff1b\u57fa\u4e8e\u591a\u5c3a\u5ea6Transformer\u7684\u6269\u6563\u6a21\u578b\u5b66\u4e60\u957f\u5e8f\u5217\u547d\u4ee4\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMamTiff-CAD\u5728\u91cd\u5efa\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7279\u522b\u5728\u957f\u5e8f\u5217(60-256)CAD\u6a21\u578b\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "MamTiff-CAD\u6846\u67b6\u901a\u8fc7\u591a\u5c3a\u5ea6\u6f5c\u5728\u8868\u793a\u548c\u6269\u6563\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5e8f\u5217CAD\u53c2\u6570\u5316\u547d\u4ee4\u751f\u6210\u95ee\u9898\uff0c\u4e3a\u590d\u6742CAD\u6a21\u578b\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18926", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18926", "abs": "https://arxiv.org/abs/2511.18926", "authors": ["Haifeng Jing", "Yujie Hou", "Junfei Liu", "Rui Xie", "alan Xu", "Jinlong Ma", "Qichun Deng"], "title": "MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship Dialogue Systems", "comment": "26 pages, 7 figures", "summary": "With the rapid development of Large Language Models, dialogue systems are shifting from information tools to emotional companions, heralding the era of Emotional Companionship Dialogue Systems (ECDs) that provide personalized emotional support for users. However, the field lacks clear definitions and systematic evaluation standards for ECDs. To address this, we first propose a definition of ECDs with formal descriptions. Then, based on this theory and the design principle of \"Ability Layer-Task Layer (three level)-Data Layer-Method Layer\", we design and implement the first ECD evaluation benchmark - MoodBench 1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that MoodBench 1.0 has excellent discriminant validity and can effectively quantify the differences in emotional companionship abilities among models. Furthermore, the results reveal current models' shortcomings in deep emotional companionship, guiding future technological optimization and significantly aiding developers in enhancing ECDs' user experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u60c5\u611f\u966a\u4f34\u5bf9\u8bdd\u7cfb\u7edf\uff08ECDs\uff09\u7684\u6b63\u5f0f\u5b9a\u4e49\uff0c\u5e76\u57fa\u4e8e\"\u80fd\u529b\u5c42-\u4efb\u52a1\u5c42\uff08\u4e09\u7ea7\uff09-\u6570\u636e\u5c42-\u65b9\u6cd5\u5c42\"\u8bbe\u8ba1\u539f\u5219\uff0c\u5f00\u53d1\u4e86\u9996\u4e2aECDs\u8bc4\u4f30\u57fa\u51c6MoodBench 1.0\u3002\u901a\u8fc7\u5bf930\u4e2a\u4e3b\u6d41\u6a21\u578b\u7684\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u8be5\u57fa\u51c6\u5177\u6709\u826f\u597d\u7684\u5224\u522b\u6548\u5ea6\uff0c\u80fd\u591f\u6709\u6548\u91cf\u5316\u6a21\u578b\u5728\u60c5\u611f\u966a\u4f34\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5bf9\u8bdd\u7cfb\u7edf\u6b63\u4ece\u4fe1\u606f\u5de5\u5177\u8f6c\u53d8\u4e3a\u60c5\u611f\u4f34\u4fa3\uff0c\u4f46\u8be5\u9886\u57df\u7f3a\u4e4f\u5bf9\u60c5\u611f\u966a\u4f34\u5bf9\u8bdd\u7cfb\u7edf\u7684\u660e\u786e\u5b9a\u4e49\u548c\u7cfb\u7edf\u5316\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u9996\u5148\u63d0\u51fa\u4e86ECDs\u7684\u6b63\u5f0f\u5b9a\u4e49\uff0c\u7136\u540e\u57fa\u4e8e\"\u80fd\u529b\u5c42-\u4efb\u52a1\u5c42\uff08\u4e09\u7ea7\uff09-\u6570\u636e\u5c42-\u65b9\u6cd5\u5c42\"\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u9996\u4e2aECDs\u8bc4\u4f30\u57fa\u51c6MoodBench 1.0\u3002", "result": "\u901a\u8fc7\u5bf930\u4e2a\u4e3b\u6d41\u6a21\u578b\u7684\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86MoodBench 1.0\u5177\u6709\u4f18\u79c0\u7684\u5224\u522b\u6548\u5ea6\uff0c\u80fd\u591f\u6709\u6548\u91cf\u5316\u6a21\u578b\u5728\u60c5\u611f\u966a\u4f34\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\u3002\u8bc4\u4f30\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u6df1\u5ea6\u60c5\u611f\u966a\u4f34\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "MoodBench 1.0\u4e3aECDs\u9886\u57df\u63d0\u4f9b\u4e86\u9996\u4e2a\u7cfb\u7edf\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u80fd\u591f\u6709\u6548\u6307\u5bfc\u672a\u6765\u6280\u672f\u4f18\u5316\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u63d0\u5347ECDs\u7684\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2511.17660", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.17660", "abs": "https://arxiv.org/abs/2511.17660", "authors": ["Giuseppe Carrino", "Elena Loli Piccolomini", "Elisa Riccietti", "Theo Mary"], "title": "Frugality in second-order optimization: floating-point approximations for Newton's method", "comment": "Master Thesis for the Artificial Intelligence course at University of Bologna", "summary": "Minimizing loss functions is central to machine-learning training. Although first-order methods dominate practical applications, higher-order techniques such as Newton's method can deliver greater accuracy and faster convergence, yet are often avoided due to their computational cost. This work analyzes the impact of finite-precision arithmetic on Newton steps and establishes a convergence theorem for mixed-precision Newton optimizers, including \"quasi\" and \"inexact\" variants. The theorem provides not only convergence guarantees but also a priori estimates of the achievable solution accuracy. Empirical evaluations on standard regression benchmarks demonstrate that the proposed methods outperform Adam on the Australian and MUSH datasets. The second part of the manuscript introduces GN_k, a generalized Gauss-Newton method that enables partial computation of second-order derivatives. GN_k attains performance comparable to full Newton's method on regression tasks while requiring significantly fewer derivative evaluations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u6709\u9650\u7cbe\u5ea6\u7b97\u672f\u5bf9\u725b\u987f\u6b65\u957f\u7684\u5f71\u54cd\uff0c\u5efa\u7acb\u4e86\u6df7\u5408\u7cbe\u5ea6\u725b\u987f\u4f18\u5316\u5668\u7684\u6536\u655b\u5b9a\u7406\uff0c\u5e76\u63d0\u51fa\u4e86GN_k\u65b9\u6cd5\uff0c\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e0e\u5b8c\u6574\u725b\u987f\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u4f46\u9700\u8981\u66f4\u5c11\u7684\u5bfc\u6570\u8ba1\u7b97\u3002", "motivation": "\u867d\u7136\u4e00\u9636\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4f46\u9ad8\u9636\u65b9\u6cd5\u5982\u725b\u987f\u6cd5\u53ef\u4ee5\u63d0\u4f9b\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u4f46\u7531\u4e8e\u8ba1\u7b97\u6210\u672c\u9ad8\u800c\u5e38\u5e38\u88ab\u907f\u514d\u4f7f\u7528\u3002", "method": "\u5206\u6790\u6709\u9650\u7cbe\u5ea6\u7b97\u672f\u5bf9\u725b\u987f\u6b65\u957f\u7684\u5f71\u54cd\uff0c\u5efa\u7acb\u6df7\u5408\u7cbe\u5ea6\u725b\u987f\u4f18\u5316\u5668\u7684\u6536\u655b\u5b9a\u7406\uff0c\u5e76\u63d0\u51faGN_k\u65b9\u6cd5\uff08\u5e7f\u4e49\u9ad8\u65af-\u725b\u987f\u6cd5\uff09\u5b9e\u73b0\u90e8\u5206\u4e8c\u9636\u5bfc\u6570\u8ba1\u7b97\u3002", "result": "\u5728\u6807\u51c6\u56de\u5f52\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728Australian\u548cMUSH\u6570\u636e\u96c6\u4e0a\u4f18\u4e8eAdam\u3002GN_k\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e0e\u5b8c\u6574\u725b\u987f\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5bfc\u6570\u8ba1\u7b97\u6b21\u6570\u3002", "conclusion": "\u6df7\u5408\u7cbe\u5ea6\u725b\u987f\u4f18\u5316\u5668\u548cGN_k\u65b9\u6cd5\u4e3a\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u9ad8\u9636\u4f18\u5316\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.19244", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19244", "abs": "https://arxiv.org/abs/2511.19244", "authors": ["Jos\u00e9 P. Carvalho", "Anders Bodholt Nielsen", "David L. Goodwin", "Nino Wili", "Niels Chr. Nielsen"], "title": "Longitudinal Pulsed Dynamic Nuclear Polarization Transfer via Periodic Optimal Control", "comment": "8 pages main text, 3 figures, 2 pages SI, 2 figures SI, 2 tables SI, TOC", "summary": "Taking inspiration from NMR spectroscopy, periodic irradiation schemes have recently shown remarkable performance when implemented into pulsed dynamic nuclear polarization (DNP) sequences. This has prompted considerable interest in development of broadband pulsed DNP sequences utilizing such schemes. On this background, most efforts have focused on solid-state NMR like transverse spin-locked pulse sequences whose performance in DNP applications may be compromised by the broadband capabilities of the initial excitation pulse. Leveraging the flexibility and robustness of optimal control theory combined with underlying insights from effective Hamiltonian theory, we present a new family of broadband DNP pulse sequences, termed LOOP (Longitudinally Optimized with Overarching Periodicity), that alleviates the excitation-pulse challenge by accomplishing longitudinal polarization transfer. These sequences define robust single-spin effective $z$ rotations, with impressive compensation towards microwave field inhomogeneity, and are capable of delivering DNP transfer with bandwidths exceeding 100 MHz, while employing a peak microwave field amplitude of only 32 MHz, at an external magnetic field of 0.35 T.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bbd\u5e26\u52a8\u6001\u6838\u6781\u5316\u8109\u51b2\u5e8f\u5217\u5bb6\u65cfLOOP\uff0c\u901a\u8fc7\u7eb5\u5411\u6781\u5316\u8f6c\u79fb\u89e3\u51b3\u4e86\u4f20\u7edf\u6a2a\u5411\u81ea\u65cb\u9501\u5b9a\u8109\u51b2\u5e8f\u5217\u4e2d\u521d\u59cb\u6fc0\u53d1\u8109\u51b2\u5bbd\u5e26\u80fd\u529b\u7684\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u53d7NMR\u5149\u8c31\u5b66\u542f\u53d1\uff0c\u5468\u671f\u6027\u8f90\u7167\u65b9\u6848\u5728\u8109\u51b2\u52a8\u6001\u6838\u6781\u5316\u5e8f\u5217\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\uff0c\u4f46\u76ee\u524d\u5927\u591a\u6570\u7814\u7a76\u96c6\u4e2d\u5728\u7c7b\u4f3c\u56fa\u6001NMR\u7684\u6a2a\u5411\u81ea\u65cb\u9501\u5b9a\u8109\u51b2\u5e8f\u5217\uff0c\u5176\u6027\u80fd\u53ef\u80fd\u53d7\u5230\u521d\u59cb\u6fc0\u53d1\u8109\u51b2\u5bbd\u5e26\u80fd\u529b\u7684\u9650\u5236\u3002", "method": "\u7ed3\u5408\u6700\u4f18\u63a7\u5236\u7406\u8bba\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\u4ee5\u53ca\u6709\u6548\u54c8\u5bc6\u987f\u7406\u8bba\u7684\u6df1\u5165\u89c1\u89e3\uff0c\u5f00\u53d1\u4e86LOOP\u5e8f\u5217\uff0c\u901a\u8fc7\u5b9e\u73b0\u7eb5\u5411\u6781\u5316\u8f6c\u79fb\u6765\u7f13\u89e3\u6fc0\u53d1\u8109\u51b2\u6311\u6218\uff0c\u5b9a\u4e49\u4e86\u9c81\u68d2\u7684\u5355\u81ea\u65cb\u6709\u6548z\u65cb\u8f6c\u3002", "result": "LOOP\u5e8f\u5217\u5bf9\u5fae\u6ce2\u573a\u4e0d\u5747\u5300\u6027\u5177\u6709\u663e\u8457\u8865\u507f\u80fd\u529b\uff0c\u80fd\u591f\u5728\u4ec5\u4f7f\u752832 MHz\u5cf0\u503c\u5fae\u6ce2\u573a\u632f\u5e45\u3001\u5916\u90e8\u78c1\u573a0.35 T\u7684\u6761\u4ef6\u4e0b\uff0c\u5b9e\u73b0\u8d85\u8fc7100 MHz\u5e26\u5bbd\u7684DNP\u8f6c\u79fb\u3002", "conclusion": "LOOP\u5e8f\u5217\u5bb6\u65cf\u4e3a\u5bbd\u5e26\u8109\u51b2DNP\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7eb5\u5411\u6781\u5316\u8f6c\u79fb\u65b9\u6cd5\u514b\u670d\u4e86\u4f20\u7edf\u6a2a\u5411\u81ea\u65cb\u9501\u5b9a\u5e8f\u5217\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.18955", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18955", "abs": "https://arxiv.org/abs/2511.18955", "authors": ["Wouter W. L. Nuijten", "Mykola Lukashchuk"], "title": "Active Inference is a Subtype of Variational Inference", "comment": "Accepted to the EIML Workshop 2025 at EurIPS (non-archival)", "summary": "Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u5c06\u4e3b\u52a8\u63a8\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u53d8\u5206\u63a8\u65ad\uff0c\u89e3\u51b3\u4e86EFE\u6700\u5c0f\u5316\u7684\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4f7f\u4e3b\u52a8\u63a8\u7406\u80fd\u591f\u5728\u56e0\u5b50\u72b6\u6001MDP\u4e2d\u9ad8\u6548\u5b9e\u73b0\u3002", "motivation": "\u4e3b\u52a8\u63a8\u7406\u901a\u8fc7\u671f\u671b\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u7edf\u4e00\u4e86\u51b3\u7b56\u4e2d\u7684\u5229\u7528\u548c\u63a2\u7d22\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\u6765\u514b\u670d\u9ad8\u7ef4\u89c4\u5212\u7684\u8ba1\u7b97\u96be\u9898\u3002", "method": "\u57fa\u4e8e\u5c06EFE\u6700\u5c0f\u5316\u91cd\u65b0\u8868\u8ff0\u4e3a\u53d8\u5206\u63a8\u65ad\u7684\u7406\u8bba\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u5728\u56e0\u5b50\u72b6\u6001MDP\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u4e3b\u52a8\u63a8\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u514b\u670d\u4e86\u9ad8\u7ef4\u89c4\u5212\u7684\u8ba1\u7b97\u4e0d\u53ef\u884c\u6027\uff0c\u4f7f\u4e3b\u52a8\u63a8\u7406\u80fd\u591f\u5728\u56e0\u5b50\u72b6\u6001MDP\u4e2d\u6709\u6548\u5b9e\u73b0\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4e3b\u52a8\u63a8\u7406\u7edf\u4e00\u4e3a\u89c4\u5212\u5373\u63a8\u65ad\uff0c\u5e76\u5f00\u53d1\u9ad8\u6548\u7684\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4e3b\u52a8\u63a8\u7406\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u81ea\u52a8\u5316\u51b3\u7b56\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17662", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.17662", "abs": "https://arxiv.org/abs/2511.17662", "authors": ["Debmita Roy"], "title": "Enhancing Breast Cancer Prediction with LLM-Inferred Confounders", "comment": "2 pages, 1 figure, 1 table", "summary": "This study enhances breast cancer prediction by using large language models to infer the likelihood of confounding diseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated features improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). The approach shows promise for noninvasive prescreening and clinical integration, supporting improved early detection and shared decision-making in breast cancer diagnosis.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u5e38\u89c4\u4e34\u5e8a\u6570\u636e\u4e2d\u63a8\u65ad\u7cd6\u5c3f\u75c5\u3001\u80a5\u80d6\u548c\u5fc3\u8840\u7ba1\u75be\u75c5\u7b49\u6df7\u6742\u75be\u75c5\u7684\u6982\u7387\uff0c\u4ee5\u589e\u5f3a\u4e73\u817a\u764c\u9884\u6d4b\u3002AI\u751f\u6210\u7684\u7279\u5f81\u63d0\u9ad8\u4e86\u968f\u673a\u68ee\u6797\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662fGemma\uff083.9%\uff09\u548cLlama\uff086.4%\uff09\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u5728\u65e0\u521b\u9884\u7b5b\u67e5\u548c\u4e34\u5e8a\u6574\u5408\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\u3002", "motivation": "\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u5e38\u89c4\u4e34\u5e8a\u6570\u636e\u4e2d\u63a8\u65ad\u6df7\u6742\u75be\u75c5\u7684\u53ef\u80fd\u6027\uff0c\u63d0\u9ad8\u4e73\u817a\u764c\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u652f\u6301\u65e9\u671f\u68c0\u6d4b\u548c\u5171\u4eab\u51b3\u7b56\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Gemma\u548cLlama\uff09\u4ece\u5e38\u89c4\u4e34\u5e8a\u6570\u636e\u4e2d\u751f\u6210AI\u7279\u5f81\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u7279\u5f81\u8f93\u5165\u968f\u673a\u68ee\u6797\u6a21\u578b\u8fdb\u884c\u4e73\u817a\u764c\u9884\u6d4b\u3002", "result": "AI\u751f\u6210\u7684\u7279\u5f81\u663e\u8457\u63d0\u9ad8\u4e86\u968f\u673a\u68ee\u6797\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662fGemma\u6a21\u578b\u63d0\u5347\u4e863.9%\uff0cLlama\u6a21\u578b\u63d0\u5347\u4e866.4%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e73\u817a\u764c\u65e0\u521b\u9884\u7b5b\u67e5\u548c\u4e34\u5e8a\u6574\u5408\u65b9\u9762\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u80fd\u591f\u6539\u5584\u65e9\u671f\u68c0\u6d4b\u548c\u5171\u4eab\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2511.19246", "categories": ["quant-ph", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.19246", "abs": "https://arxiv.org/abs/2511.19246", "authors": ["Hibah Agha", "Samuel Yen-Chi Chen", "Huan-Hsin Tseng", "Shinjae Yoo"], "title": "Neural Architecture Search for Quantum Autoencoders", "comment": null, "summary": "In recent years, machine learning and deep learning have driven advances in domains such as image classification, speech recognition, and anomaly detection by leveraging multi-layer neural networks to model complex data. Simultaneously, quantum computing (QC) promises to address classically intractable problems via quantum parallelism, motivating research in quantum machine learning (QML). Among QML techniques, quantum autoencoders show promise for compressing high-dimensional quantum and classical data. However, designing effective quantum circuit architectures for quantum autoencoders remains challenging due to the complexity of selecting gates, arranging circuit layers, and tuning parameters.\n  This paper proposes a neural architecture search (NAS) framework that automates the design of quantum autoencoders using a genetic algorithm (GA). By systematically evolving variational quantum circuit (VQC) configurations, our method seeks to identify high-performing hybrid quantum-classical autoencoders for data reconstruction without becoming trapped in local minima. We demonstrate effectiveness on image datasets, highlighting the potential of quantum autoencoders for efficient feature extraction within a noise-prone, near-term quantum era. Our approach lays a foundation for broader application of genetic algorithms to quantum architecture search, aiming for a robust, automated method that can adapt to varied data and hardware constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bbe\u8ba1\u91cf\u5b50\u81ea\u7f16\u7801\u5668\uff0c\u4ee5\u89e3\u51b3\u91cf\u5b50\u7535\u8def\u67b6\u6784\u8bbe\u8ba1\u7684\u6311\u6218\u3002", "motivation": "\u91cf\u5b50\u81ea\u7f16\u7801\u5668\u5728\u538b\u7f29\u9ad8\u7ef4\u91cf\u5b50\u6570\u636e\u548c\u7ecf\u5178\u6570\u636e\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u91cf\u5b50\u7535\u8def\u67b6\u6784\u8bbe\u8ba1\u7684\u590d\u6742\u6027\uff08\u5305\u62ec\u95e8\u9009\u62e9\u3001\u7535\u8def\u5c42\u6392\u5217\u548c\u53c2\u6570\u8c03\u4f18\uff09\uff0c\u8bbe\u8ba1\u6709\u6548\u7684\u91cf\u5b50\u7535\u8def\u67b6\u6784\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\uff08GA\uff09\u7cfb\u7edf\u6f14\u5316\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u914d\u7f6e\uff0c\u81ea\u52a8\u5316\u8bbe\u8ba1\u91cf\u5b50\u81ea\u7f16\u7801\u5668\uff0c\u907f\u514d\u9677\u5165\u5c40\u90e8\u6700\u5c0f\u503c\u3002", "result": "\u5728\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u81ea\u7f16\u7801\u5668\u5728\u566a\u58f0\u6613\u53d1\u7684\u8fd1\u671f\u91cf\u5b50\u65f6\u4ee3\u8fdb\u884c\u9ad8\u6548\u7279\u5f81\u63d0\u53d6\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9057\u4f20\u7b97\u6cd5\u5728\u91cf\u5b50\u67b6\u6784\u641c\u7d22\u4e2d\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u6570\u636e\u548c\u786c\u4ef6\u7ea6\u675f\u7684\u9c81\u68d2\u3001\u81ea\u52a8\u5316\u65b9\u6cd5\u3002"}}
{"id": "2511.18964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18964", "abs": "https://arxiv.org/abs/2511.18964", "authors": ["Antonia W\u00fcst", "Wolfgang Stammer", "Hikaru Shindo", "Lukas Helff", "Devendra Singh Dhami", "Kristian Kersting"], "title": "Synthesizing Visual Concepts as Vision-Language Programs", "comment": null, "summary": "Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.", "AI": {"tldr": "VLP\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u611f\u77e5\u7075\u6d3b\u6027\u548c\u7a0b\u5e8f\u5408\u6210\u7684\u7cfb\u7edf\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u5c06\u89c6\u89c9\u63cf\u8ff0\u7f16\u8bd1\u4e3a\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u6765\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7cfb\u7edf\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5931\u8d25\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7cfb\u7edf\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7ecf\u5e38\u5931\u8d25\uff0c\u4ea7\u751f\u4e0d\u4e00\u81f4\u6216\u4e0d\u5408\u903b\u8f91\u7684\u8f93\u51fa\u3002\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u867d\u7136\u80fd\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u903b\u8f91\u89c4\u5219\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u4f7f\u7528\u50f5\u5316\u7684\u3001\u7279\u5b9a\u9886\u57df\u7684\u611f\u77e5\u6a21\u5757\u3002", "method": "\u63d0\u51faVision-Language Programs (VLP)\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u89c6\u89c9\u63cf\u8ff0\uff0c\u7136\u540e\u5c06\u5176\u7f16\u8bd1\u4e3a\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u3002\u8fd9\u4e9b\u7a0b\u5e8f\u76f4\u63a5\u5728\u56fe\u50cf\u4e0a\u6267\u884c\uff0c\u4fdd\u6301\u4e0e\u4efb\u52a1\u7ea6\u675f\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVLP\u5728\u9700\u8981\u590d\u6742\u903b\u8f91\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u4f18\u4e8e\u76f4\u63a5\u548c\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "VLP\u901a\u8fc7\u5c06\u63a8\u7406\u4ece\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8f6c\u79fb\u5230\u5916\u90e8\u7a0b\u5e8f\u5408\u6210\uff0c\u63d0\u4f9b\u4e86\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\uff0c\u5e76\u80fd\u8f7b\u677e\u7f13\u89e3\u6377\u5f84\u95ee\u9898\uff0c\u5728\u7cfb\u7edf\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.17663", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17663", "abs": "https://arxiv.org/abs/2511.17663", "authors": ["Alex S. C. Maia", "John B. Hall", "Hugo F. M. Milan", "Izabelle A. M. A. Teixeira"], "title": "AI-based framework to predict animal and pen feed intake in feedlot beef cattle", "comment": null, "summary": "Advances in technology are transforming sustainable cattle farming practices, with electronic feeding systems generating big longitudinal datasets on individual animal feed intake, offering the possibility for autonomous precision livestock systems. However, the literature still lacks a methodology that fully leverages these longitudinal big data to accurately predict feed intake accounting for environmental conditions. To fill this gap, we developed an AI-based framework to accurately predict feed intake of individual animals and pen-level aggregation. Data from 19 experiments (>16.5M samples; 2013-2024) conducted at Nancy M. Cummings Research Extension & Education Center (Carmen, ID) feedlot facility and environmental data from AgriMet Network weather stations were used to develop two novel environmental indices: InComfort-Index, based solely on meteorological variables, showed good predictive capability for thermal comfort but had limited ability to predict feed intake; EASI-Index, a hybrid index integrating environmental variables with feed intake behavior, performed well in predicting feed intake but was less effective for thermal comfort. Together with the environmental indices, machine learning models were trained and the best-performing machine learning model (XGBoost) accuracy was RMSE of 1.38 kg/day for animal-level and only 0.14 kg/(day-animal) at pen-level. This approach provides a robust AI-based framework for predicting feed intake in individual animals and pens, with potential applications in precision management of feedlot cattle, through feed waste reduction, resource optimization, and climate-adaptive livestock management.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eAI\u7684\u6846\u67b6\uff0c\u5229\u7528\u7535\u5b50\u9972\u5582\u7cfb\u7edf\u751f\u6210\u7684\u5927\u6570\u636e\u9884\u6d4b\u4e2a\u4f53\u52a8\u7269\u548c\u56f4\u680f\u7ea7\u522b\u7684\u91c7\u98df\u91cf\uff0c\u7ed3\u5408\u73af\u5883\u6570\u636e\u521b\u5efa\u4e86\u4e24\u4e2a\u65b0\u73af\u5883\u6307\u6570\uff0cXGBoost\u6a21\u578b\u5728\u4e2a\u4f53\u548c\u56f4\u680f\u7ea7\u522b\u5206\u522b\u8fbe\u52301.38 kg/\u5929\u548c0.14 kg/(\u5929-\u52a8\u7269)\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u5145\u5206\u5229\u7528\u7eb5\u5411\u5927\u6570\u636e\u9884\u6d4b\u91c7\u98df\u91cf\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u73af\u5883\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\u3002\u7535\u5b50\u9972\u5582\u7cfb\u7edf\u4ea7\u751f\u7684\u5927\u6570\u636e\u4e3a\u5f00\u53d1\u81ea\u4e3b\u7cbe\u51c6\u755c\u7267\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002", "method": "\u4f7f\u752819\u4e2a\u5b9e\u9a8c\u76841650\u4e07\u6837\u672c\u6570\u636e\u548c\u73af\u5883\u6570\u636e\uff0c\u5f00\u53d1\u4e86\u4e24\u4e2a\u65b0\u73af\u5883\u6307\u6570\uff1a\u57fa\u4e8e\u6c14\u8c61\u53d8\u91cf\u7684InComfort-Index\u548c\u6574\u5408\u73af\u5883\u53d8\u91cf\u4e0e\u91c7\u98df\u884c\u4e3a\u7684EASI-Index\u3002\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5176\u4e2dXGBoost\u8868\u73b0\u6700\u4f73\u3002", "result": "InComfort-Index\u5bf9\u70ed\u8212\u9002\u5ea6\u9884\u6d4b\u826f\u597d\u4f46\u5bf9\u91c7\u98df\u91cf\u9884\u6d4b\u6709\u9650\uff1bEASI-Index\u5728\u91c7\u98df\u91cf\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u826f\u597d\u4f46\u5bf9\u70ed\u8212\u9002\u5ea6\u9884\u6d4b\u6548\u679c\u8f83\u5dee\u3002XGBoost\u6a21\u578b\u5728\u4e2a\u4f53\u548c\u56f4\u680f\u7ea7\u522b\u7684\u9884\u6d4b\u7cbe\u5ea6\u5206\u522b\u4e3aRMSE 1.38 kg/\u5929\u548c0.14 kg/(\u5929-\u52a8\u7269)\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9884\u6d4b\u4e2a\u4f53\u52a8\u7269\u548c\u56f4\u680f\u91c7\u98df\u91cf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u7684AI\u6846\u67b6\uff0c\u5728\u7cbe\u51c6\u7ba1\u7406\u80b2\u80a5\u725b\u3001\u51cf\u5c11\u9972\u6599\u6d6a\u8d39\u3001\u4f18\u5316\u8d44\u6e90\u548c\u6c14\u5019\u9002\u5e94\u6027\u755c\u7267\u7ba1\u7406\u65b9\u9762\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.19266", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19266", "abs": "https://arxiv.org/abs/2511.19266", "authors": ["Sina Soltani", "Marco Erba", "David Schmid", "John H. Selby"], "title": "Decoupling local classicality from classical explainability: A noncontextual model for bilocal classical theory and a locally-classical but contextual theory", "comment": null, "summary": "We construct an ontological model for the theory known as bilocal classical theory doi.org/10.1103/PhysRevA.102.052216. To our knowledge, this is only the second time that an ontological model has been constructed for an entire theory, rather than just for some particular scenarios within a theory. This result refutes a conjecture from doi.org/10.1103/PhysRevA.102.052216 which suggested that there might be no local-realist ontological model for bilocal classical theory. Moreover, it is the first time that an ontological model has been constructed for a theory that fails to be locally tomographic, showing that the assumption of local tomography underpinning the structure theorem in doi.org/10.22331/q-2024-03-14-1283 is a genuine limitation of the theorem. This demonstrates that in general there is no tension between failures of local tomography and classical explainability (i.e., generalised noncontextuality). In fact, bilocal classical theory is in many ways more simply understood via the underlying ontological model than it is within its original formulation (much as how odd-dimensional stabiliser subtheories can be more simply understood via Spekkens' toy theory). Furthermore, this result naturally leads to the question, does every locally-classical theory admit of an ontological model? By constructing a concrete counterexample, we show that this is not the case. Our findings demonstrate that there is no straightforward relationship between theories being locally-classical, and them being classically-explainable. This shows that the fundamental status of compositional properties (such as local tomography) is not a technical side-issue, but a central and unavoidable question for a coherent understanding even of classicality itself.", "AI": {"tldr": "\u672c\u6587\u4e3a\u53cc\u5c40\u57df\u7ecf\u5178\u7406\u8bba\u6784\u5efa\u4e86\u672c\u4f53\u8bba\u6a21\u578b\uff0c\u53cd\u9a73\u4e86\u8be5\u7406\u8bba\u4e0d\u5b58\u5728\u5c40\u57df\u5b9e\u5728\u8bba\u672c\u4f53\u8bba\u6a21\u578b\u7684\u731c\u60f3\uff0c\u5e76\u9996\u6b21\u4e3a\u975e\u5c40\u57df\u5c42\u6790\u7406\u8bba\u6784\u5efa\u4e86\u672c\u4f53\u8bba\u6a21\u578b\uff0c\u8868\u660e\u5c40\u57df\u5c42\u6790\u5047\u8bbe\u662f\u7ed3\u6784\u5b9a\u7406\u7684\u771f\u6b63\u9650\u5236\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u9a8c\u8bc1\u53cc\u5c40\u57df\u7ecf\u5178\u7406\u8bba\u662f\u5426\u5b58\u5728\u5c40\u57df\u5b9e\u5728\u8bba\u672c\u4f53\u8bba\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u5c40\u57df\u5c42\u6790\u5047\u8bbe\u5728\u7ed3\u6784\u5b9a\u7406\u4e2d\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u53ca\u5c40\u90e8\u7ecf\u5178\u6027\u4e0e\u7ecf\u5178\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5177\u4f53\u6784\u9020\u53cc\u5c40\u57df\u7ecf\u5178\u7406\u8bba\u7684\u672c\u4f53\u8bba\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u53cd\u4f8b\u6765\u9a8c\u8bc1\u5c40\u90e8\u7ecf\u5178\u7406\u8bba\u662f\u5426\u90fd\u5141\u8bb8\u672c\u4f53\u8bba\u6a21\u578b\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u53cc\u5c40\u57df\u7ecf\u5178\u7406\u8bba\u7684\u672c\u4f53\u8bba\u6a21\u578b\uff0c\u53cd\u9a73\u4e86\u76f8\u5173\u731c\u60f3\uff0c\u5e76\u8bc1\u660e\u5e76\u975e\u6240\u6709\u5c40\u90e8\u7ecf\u5178\u7406\u8bba\u90fd\u5141\u8bb8\u672c\u4f53\u8bba\u6a21\u578b\u3002", "conclusion": "\u5c40\u57df\u5c42\u6790\u7b49\u7ec4\u5408\u6027\u8d28\u5728\u7406\u89e3\u7ecf\u5178\u6027\u672c\u8eab\u4e2d\u5177\u6709\u6838\u5fc3\u5730\u4f4d\uff0c\u5c40\u90e8\u7ecf\u5178\u6027\u4e0e\u7ecf\u5178\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u6ca1\u6709\u7b80\u5355\u5173\u7cfb\u3002"}}
{"id": "2511.18966", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18966", "abs": "https://arxiv.org/abs/2511.18966", "authors": ["Muhammad Usman Shahid", "Chuadhry Mujeeb Ahmed", "Rajiv Ranjan"], "title": "LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models", "comment": null, "summary": "The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684C/C++\u4ee3\u7801\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u8fd9\u4e9b\u4ee3\u7801\u5305\u542b\u5927\u91cf\u5e38\u89c1\u5f31\u70b9\u679a\u4e3e(CWE)\u6f0f\u6d1e\uff0c\u9700\u8981\u5f00\u53d1\u4eba\u5458\u8c28\u614e\u4f7f\u7528\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u4e14\u7f3a\u4e4f\u9632\u5fa1\u6027\u7f16\u7a0b\u7ed3\u6784\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9\u5176\u5b89\u5168\u6027\u7684\u4e25\u91cd\u62c5\u5fe7\u3002", "method": "\u4f7f\u7528CWE\u5bf9\u5df2\u77e5\u6f0f\u6d1e\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230CVE\u4ee5\u7814\u7a76\u5173\u952e\u6027\uff1b\u91c7\u752810\u79cd\u4e0d\u540c\u7684LLM\u751f\u6210\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u9759\u6001\u5206\u6790\u5bf9\u8f93\u51fa\u8fdb\u884c\u5206\u6790\u3002", "result": "AI\u751f\u6210\u4ee3\u7801\u4e2d\u5b58\u5728\u5927\u91cfCWE\u6f0f\u6d1e\uff0c\u5b89\u5168\u72b6\u51b5\u4ee4\u4eba\u62c5\u5fe7\u3002", "conclusion": "\u5f00\u53d1\u4eba\u5458\u5728\u4f7f\u7528LLM\u751f\u6210\u4ee3\u7801\u65f6\u9700\u8981\u4fdd\u6301\u8c28\u614e\uff0c\u672c\u7814\u7a76\u4e3a\u63a8\u8fdb\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u548c\u9f13\u52b1\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2511.17664", "categories": ["cs.LG", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.17664", "abs": "https://arxiv.org/abs/2511.17664", "authors": ["Azlaan Mustafa Samad", "Hoang H. Nguyen", "Lukas Berg", "Henrik M\u00fcller", "Yuan Xue", "Daniel Kudenko", "Zahra Ahmadi"], "title": "CubeletWorld: A New Abstraction for Scalable 3D Modeling", "comment": "10 pages, 5 figures", "summary": "Modern cities produce vast streams of heterogeneous data, from infrastructure maps to mobility logs and satellite imagery. However, integrating these sources into coherent spatial models for planning and prediction remains a major challenge. Existing agent-centric methods often rely on direct environmental sensing, limiting scalability and raising privacy concerns. This paper introduces CubeletWorld, a novel framework for representing and analyzing urban environments through a discretized 3D grid of spatial units called cubelets. This abstraction enables privacy-preserving modeling by embedding diverse data signals, such as infrastructure, movement, or environmental indicators, into localized cubelet states. CubeletWorld supports downstream tasks such as planning, navigation, and occupancy prediction without requiring agent-driven sensing. To evaluate this paradigm, we propose the CubeletWorld State Prediction task, which involves predicting the cubelet state using a realistic dataset containing various urban elements like streets and buildings through this discretized representation. We explore a range of modified core models suitable for our setting and analyze challenges posed by increasing spatial granularity, specifically the issue of sparsity in representation and scalability of baselines. In contrast to existing 3D occupancy prediction models, our cubelet-centric approach focuses on inferring state at the spatial unit level, enabling greater generalizability across regions and improved privacy compliance. Our results demonstrate that CubeletWorld offers a flexible and extensible framework for learning from complex urban data, and it opens up new possibilities for scalable simulation and decision support in domains such as socio-demographic modeling, environmental monitoring, and emergency response. The code and datasets can be downloaded from here.", "AI": {"tldr": "CubeletWorld\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u57ce\u5e02\u73af\u5883\u8868\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u76843D\u7f51\u683c\u5355\u5143\uff08cubelets\uff09\u6765\u6574\u5408\u5f02\u6784\u57ce\u5e02\u6570\u636e\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u5efa\u6a21\uff0c\u652f\u6301\u89c4\u5212\u3001\u5bfc\u822a\u548c\u5360\u7528\u9884\u6d4b\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "motivation": "\u73b0\u4ee3\u57ce\u5e02\u4ea7\u751f\u5927\u91cf\u5f02\u6784\u6570\u636e\uff0c\u4f46\u5c06\u8fd9\u4e9b\u6570\u636e\u6574\u5408\u5230\u8fde\u8d2f\u7684\u7a7a\u95f4\u6a21\u578b\u4e2d\u4ecd\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u57fa\u4e8e\u667a\u80fd\u4f53\u611f\u77e5\u7684\u65b9\u6cd5\u5b58\u5728\u53ef\u6269\u5c55\u6027\u9650\u5236\u548c\u9690\u79c1\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u62bd\u8c61\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCubeletWorld\u6846\u67b6\uff0c\u5c06\u57ce\u5e02\u73af\u5883\u79bb\u6563\u5316\u4e3a3D\u7f51\u683c\u5355\u5143\uff08cubelets\uff09\uff0c\u5c06\u57fa\u7840\u8bbe\u65bd\u3001\u79fb\u52a8\u6027\u3001\u73af\u5883\u6307\u6807\u7b49\u591a\u6837\u5316\u6570\u636e\u5d4c\u5165\u5230\u5c40\u90e8\u5316\u7684cubelet\u72b6\u6001\u4e2d\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u5efa\u6a21\u3002", "result": "\u5f00\u53d1\u4e86CubeletWorld\u72b6\u6001\u9884\u6d4b\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e86\u9002\u7528\u4e8e\u8be5\u8bbe\u7f6e\u7684\u6539\u8fdb\u6838\u5fc3\u6a21\u578b\uff0c\u5206\u6790\u4e86\u7a7a\u95f4\u7c92\u5ea6\u589e\u52a0\u5e26\u6765\u7684\u7a00\u758f\u6027\u8868\u793a\u548c\u57fa\u7ebf\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002\u4e0e\u73b0\u67093D\u5360\u7528\u9884\u6d4b\u6a21\u578b\u76f8\u6bd4\uff0ccubelet\u4e2d\u5fc3\u65b9\u6cd5\u5728\u7a7a\u95f4\u5355\u5143\u7ea7\u522b\u63a8\u65ad\u72b6\u6001\uff0c\u5177\u6709\u66f4\u597d\u7684\u533a\u57df\u901a\u7528\u6027\u548c\u9690\u79c1\u5408\u89c4\u6027\u3002", "conclusion": "CubeletWorld\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u590d\u6742\u7684\u57ce\u5e02\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u4e3a\u53ef\u6269\u5c55\u6a21\u62df\u548c\u51b3\u7b56\u652f\u6301\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\uff0c\u9002\u7528\u4e8e\u793e\u4f1a\u4eba\u53e3\u5efa\u6a21\u3001\u73af\u5883\u76d1\u6d4b\u548c\u5e94\u6025\u54cd\u5e94\u7b49\u9886\u57df\u3002"}}
{"id": "2511.19005", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19005", "abs": "https://arxiv.org/abs/2511.19005", "authors": ["Di Wu", "Liting Jiang", "Ruiyu Fang", "Bianjing", "Hongyan Xie", "Haoxiang Su", "Hao Huang", "Zhongjiang He", "Shuangyong Song", "Xuelong Li"], "title": "Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding", "comment": null, "summary": "Spoken Language Understanding (SLU) consists of two sub-tasks: intent detection (ID) and slot filling (SF). Given its broad range of real-world applications, enhancing SLU for practical deployment is increasingly critical. Profile-based SLU addresses ambiguous user utterances by incorporating context awareness (CA), user profiles (UP), and knowledge graphs (KG) to support disambiguation, thereby advancing SLU research toward real-world applicability. However, existing SLU datasets still fall short in representing real-world scenarios. Specifically, (1) CA uses one-hot vectors for representation, which is overly idealized, and (2) models typically focuses solely on predicting intents and slot labels, neglecting the reasoning process that could enhance performance and interpretability. To overcome these limitations, we introduce VRSLU, a novel SLU dataset that integrates both Visual images and explicit Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate images reflecting users' environments and statuses, followed by human verification to ensure quality. For reasoning, GPT-4o is employed to generate explanations for predicted labels, which are then refined by human annotators to ensure accuracy and coherence. Additionally, we propose an instructional template, LR-Instruct, which first predicts labels and then generates corresponding reasoning. This two-step approach helps mitigate the influence of reasoning bias on label prediction. Experimental results confirm the effectiveness of incorporating visual information and highlight the promise of explicit reasoning in advancing SLU.", "AI": {"tldr": "VRSLU\u662f\u4e00\u4e2a\u65b0\u9896\u7684SLU\u6570\u636e\u96c6\uff0c\u96c6\u6210\u4e86\u89c6\u89c9\u56fe\u50cf\u548c\u663e\u5f0f\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u5728\u4e0a\u4e0b\u6587\u8868\u793a\u548c\u63a8\u7406\u8fc7\u7a0b\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709SLU\u6570\u636e\u96c6\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u771f\u5b9e\u573a\u666f\uff1a\u4e0a\u4e0b\u6587\u611f\u77e5\u4f7f\u7528\u8fc7\u4e8e\u7406\u60f3\u5316\u7684one-hot\u5411\u91cf\u8868\u793a\uff0c\u6a21\u578b\u4ec5\u9884\u6d4b\u610f\u56fe\u548c\u69fd\u6807\u7b7e\u800c\u5ffd\u7565\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528GPT-4o\u548cFLUX.1-dev\u751f\u6210\u53cd\u6620\u7528\u6237\u73af\u5883\u548c\u72b6\u6001\u7684\u56fe\u50cf\uff0c\u5e76\u4eba\u5de5\u9a8c\u8bc1\u8d28\u91cf\uff1b\u7528GPT-4o\u751f\u6210\u6807\u7b7e\u9884\u6d4b\u7684\u89e3\u91ca\uff0c\u4eba\u5de5\u7cbe\u70bc\u786e\u4fdd\u51c6\u786e\u6027\u548c\u8fde\u8d2f\u6027\uff1b\u63d0\u51faLR-Instruct\u6307\u4ee4\u6a21\u677f\uff0c\u5148\u9884\u6d4b\u6807\u7b7e\u518d\u751f\u6210\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u89c6\u89c9\u4fe1\u606f\u7684\u6709\u6548\u6027\uff0c\u5e76\u51f8\u663e\u4e86\u663e\u5f0f\u63a8\u7406\u5728\u63a8\u8fdbSLU\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "VRSLU\u6570\u636e\u96c6\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u4fe1\u606f\u548c\u663e\u5f0f\u63a8\u7406\uff0c\u4e3aSLU\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u8d34\u8fd1\u771f\u5b9e\u573a\u666f\u7684\u6570\u636e\u652f\u6301\uff0c\u63a8\u52a8\u4e86SLU\u5411\u5b9e\u9645\u5e94\u7528\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.19291", "categories": ["quant-ph", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19291", "abs": "https://arxiv.org/abs/2511.19291", "authors": ["Oliver Knitter", "Jonathan Mei", "Masako Yamada", "Martin Roetteler"], "title": "TorchQuantumDistributed", "comment": "12 pages, 4 figures, to appear in the AI for Science Workshop at NeurIPS 2025", "summary": "TorchQuantumDistributed (tqd) is a PyTorch-based [Paszke et al., 2019] library for accelerator-agnostic differentiable quantum state vector simulation at scale. This enables studying the behavior of learnable parameterized near-term and fault- tolerant quantum circuits with high qubit counts.", "AI": {"tldr": "TorchQuantumDistributed (tqd) \u662f\u4e00\u4e2a\u57fa\u4e8e PyTorch \u7684\u53ef\u6269\u5c55\u3001\u52a0\u901f\u5668\u65e0\u5173\u7684\u53ef\u5fae\u5206\u91cf\u5b50\u6001\u77e2\u91cf\u6a21\u62df\u5e93\uff0c\u7528\u4e8e\u7814\u7a76\u9ad8\u91cf\u5b50\u6bd4\u7279\u6570\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u5316\u8fd1\u671f\u548c\u5bb9\u9519\u91cf\u5b50\u7535\u8def\u884c\u4e3a\u3002", "motivation": "\u4e3a\u4e86\u7814\u7a76\u5177\u6709\u9ad8\u91cf\u5b50\u6bd4\u7279\u6570\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u5316\u8fd1\u671f\u548c\u5bb9\u9519\u91cf\u5b50\u7535\u8def\u7684\u884c\u4e3a\uff0c\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u4e0e\u52a0\u901f\u5668\u65e0\u5173\u7684\u6a21\u62df\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e PyTorch \u7684 TorchQuantumDistributed (tqd) \u5e93\uff0c\u652f\u6301\u52a0\u901f\u5668\u65e0\u5173\u7684\u53ef\u5fae\u5206\u91cf\u5b50\u6001\u77e2\u91cf\u6a21\u62df\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u6001\u77e2\u91cf\u6a21\u62df\uff0c\u80fd\u591f\u5904\u7406\u9ad8\u91cf\u5b50\u6bd4\u7279\u6570\u7684\u91cf\u5b50\u7535\u8def\u3002", "conclusion": "tqd \u5e93\u4e3a\u7814\u7a76\u9ad8\u91cf\u5b50\u6bd4\u7279\u6570\u7684\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6a21\u62df\u5e73\u53f0\u3002"}}
{"id": "2511.17675", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17675", "abs": "https://arxiv.org/abs/2511.17675", "authors": ["Navneet Singh", "Shiva Raj Pokhrel"], "title": "Lane-Frame Quantum Multimodal Driving Forecasts for the Trajectory of Autonomous Vehicles", "comment": null, "summary": "Trajectory forecasting for autonomous driving must deliver accurate, calibrated multi-modal futures under tight compute and latency constraints. We propose a compact hybrid quantum architecture that aligns quantum inductive bias with road-scene structure by operating in an ego-centric, lane-aligned frame and predicting residual corrections to a kinematic baseline instead of absolute poses. The model combines a transformer-inspired quantum attention encoder (9 qubits), a parameter-lean quantum feedforward stack (64 layers, ${\\sim}1200$ trainable angles), and a Fourier-based decoder that uses shallow entanglement and phase superposition to generate 16 trajectory hypotheses in a single pass, with mode confidences derived from the latent spectrum. All circuit parameters are trained with Simultaneous Perturbation Stochastic Approximation (SPSA), avoiding backpropagation through non-analytic components. In the Waymo Open Motion Dataset, the model achieves minADE (minimum Average Displacement Error) of \\SI{1.94}{m} and minFDE (minimum Final Displacement Error) of \\SI{3.56}{m} in the $16$ models predicted over the horizon of \\SI{2.0}{s}, consistently outperforming a kinematic baseline with reduced miss rates and strong recall. Ablations confirm that residual learning in the lane frame, truncated Fourier decoding, shallow entanglement, and spectrum-based ranking focus capacity where it matters, yielding stable optimization and reliable multi-modal forecasts from small, shallow quantum circuits on a modern autonomous-driving benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7d27\u51d1\u7684\u6df7\u5408\u91cf\u5b50\u67b6\u6784\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u9884\u6d4b\uff0c\u901a\u8fc7\u91cf\u5b50\u6ce8\u610f\u529b\u7f16\u7801\u5668\u548c\u53c2\u6570\u7cbe\u7b80\u7684\u91cf\u5b50\u524d\u9988\u5806\u6808\uff0c\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u751f\u621016\u4e2a\u8f68\u8ff9\u5047\u8bbe\uff0c\u5e76\u5728Waymo\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u8fd0\u52a8\u5b66\u57fa\u7ebf\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u9884\u6d4b\u9700\u8981\u5728\u4e25\u683c\u7684\u8ba1\u7b97\u548c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u63d0\u4f9b\u51c6\u786e\u3001\u6821\u51c6\u7684\u591a\u6a21\u6001\u672a\u6765\u9884\u6d4b\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u5b58\u5728\u6311\u6218\u3002", "method": "\u91c7\u7528\u6df7\u5408\u91cf\u5b50\u67b6\u6784\uff0c\u5305\u62ec\u91cf\u5b50\u6ce8\u610f\u529b\u7f16\u7801\u5668\uff089\u91cf\u5b50\u6bd4\u7279\uff09\u3001\u53c2\u6570\u7cbe\u7b80\u7684\u91cf\u5b50\u524d\u9988\u5806\u6808\uff0864\u5c42\uff0c\u7ea61200\u4e2a\u53ef\u8bad\u7ec3\u89d2\u5ea6\uff09\u548c\u57fa\u4e8e\u5085\u91cc\u53f6\u7684\u89e3\u7801\u5668\uff0c\u5728\u81ea\u6211\u4e2d\u5fc3\u3001\u8f66\u9053\u5bf9\u9f50\u7684\u6846\u67b6\u4e2d\u9884\u6d4b\u5bf9\u8fd0\u52a8\u5b66\u57fa\u7ebf\u7684\u6b8b\u5dee\u4fee\u6b63\u3002", "result": "\u5728Waymo Open Motion Dataset\u4e0a\uff0c\u6a21\u578b\u57282.0\u79d2\u9884\u6d4b\u8303\u56f4\u5185\u5b9e\u73b0\u4e86minADE 1.94\u7c73\u548cminFDE 3.56\u7c73\uff0c\u6301\u7eed\u4f18\u4e8e\u8fd0\u52a8\u5b66\u57fa\u7ebf\uff0c\u51cf\u5c11\u4e86\u6f0f\u68c0\u7387\u5e76\u5177\u6709\u5f3a\u53ec\u56de\u7387\u3002", "conclusion": "\u6b8b\u5dee\u5b66\u4e60\u3001\u622a\u65ad\u5085\u91cc\u53f6\u89e3\u7801\u3001\u6d45\u5c42\u7ea0\u7f20\u548c\u57fa\u4e8e\u9891\u8c31\u7684\u6392\u5e8f\u5c06\u5bb9\u91cf\u96c6\u4e2d\u5728\u5173\u952e\u533a\u57df\uff0c\u5b9e\u73b0\u4e86\u7a33\u5b9a\u4f18\u5316\u548c\u53ef\u9760\u7684\u591a\u6a21\u6001\u9884\u6d4b\uff0c\u8bc1\u660e\u4e86\u5c0f\u578b\u6d45\u5c42\u91cf\u5b50\u7535\u8def\u5728\u73b0\u4ee3\u81ea\u52a8\u9a7e\u9a76\u57fa\u51c6\u4e0a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.19292", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19292", "abs": "https://arxiv.org/abs/2511.19292", "authors": ["Ilnar Zinnatullin", "Alexander Vasiliev"], "title": "Efficient Equivalent of Shallow Quantum Hashing", "comment": null, "summary": "Quantum hashing is a widely used technique in quantum computation that allows us to design space-efficient algorithms and protocols. Recently, Vasiliev has shown that the phase form of shallow quantum hashing can be implemented by a circuit of depth 2. In this paper, we establish a connection between shallow quantum hashing and single-qubit quantum hashing for the amplitude form. For a shallow circuit, we propose a circuit of depth 1 that achieves the same collision resistance.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u6d45\u5c42\u91cf\u5b50\u54c8\u5e0c\u4e0e\u5355\u91cf\u5b50\u4f4d\u91cf\u5b50\u54c8\u5e0c\u5728\u632f\u5e45\u5f62\u5f0f\u4e0b\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u6df1\u5ea6\u4e3a1\u7684\u7535\u8def\u5b9e\u73b0\u76f8\u540c\u6297\u78b0\u649e\u6027\u3002", "motivation": "\u91cf\u5b50\u54c8\u5e0c\u662f\u91cf\u5b50\u8ba1\u7b97\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u6280\u672f\uff0c\u7528\u4e8e\u8bbe\u8ba1\u7a7a\u95f4\u9ad8\u6548\u7684\u7b97\u6cd5\u548c\u534f\u8bae\u3002\u6700\u8fd1Vasiliev\u5c55\u793a\u4e86\u6d45\u5c42\u91cf\u5b50\u54c8\u5e0c\u7684\u76f8\u4f4d\u5f62\u5f0f\u53ef\u4ee5\u901a\u8fc7\u6df1\u5ea6\u4e3a2\u7684\u7535\u8def\u5b9e\u73b0\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u632f\u5e45\u5f62\u5f0f\u7684\u6d45\u5c42\u91cf\u5b50\u54c8\u5e0c\u5b9e\u73b0\u3002", "method": "\u5efa\u7acb\u6d45\u5c42\u91cf\u5b50\u54c8\u5e0c\u4e0e\u5355\u91cf\u5b50\u4f4d\u91cf\u5b50\u54c8\u5e0c\u5728\u632f\u5e45\u5f62\u5f0f\u4e0b\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u6df1\u5ea6\u4e3a1\u7684\u7535\u8def\u8bbe\u8ba1\u6765\u5b9e\u73b0\u76f8\u540c\u7684\u6297\u78b0\u649e\u6027\u80fd\u3002", "result": "\u6210\u529f\u8bbe\u8ba1\u51fa\u6df1\u5ea6\u4e3a1\u7684\u7535\u8def\uff0c\u80fd\u591f\u5b9e\u73b0\u4e0e\u6d45\u5c42\u91cf\u5b50\u54c8\u5e0c\u76f8\u540c\u7684\u78b0\u649e\u62b5\u6297\u80fd\u529b\u3002", "conclusion": "\u5728\u632f\u5e45\u5f62\u5f0f\u4e0b\uff0c\u6d45\u5c42\u91cf\u5b50\u54c8\u5e0c\u53ef\u4ee5\u901a\u8fc7\u66f4\u6d45\u7684\u7535\u8def\uff08\u6df1\u5ea61\uff09\u5b9e\u73b0\uff0c\u8fd9\u4e3a\u91cf\u5b50\u54c8\u5e0c\u7684\u9ad8\u6548\u5b9e\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.19115", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19115", "abs": "https://arxiv.org/abs/2511.19115", "authors": ["Rufin VanRullen"], "title": "AI Consciousness and Existential Risk", "comment": null, "summary": "In AI, the existential risk denotes the hypothetical threat posed by an artificial system that would possess both the capability and the objective, either directly or indirectly, to eradicate humanity. This issue is gaining prominence in scientific debate due to recent technical advancements and increased media coverage. In parallel, AI progress has sparked speculation and studies about the potential emergence of artificial consciousness. The two questions, AI consciousness and existential risk, are sometimes conflated, as if the former entailed the latter. Here, I explain that this view stems from a common confusion between consciousness and intelligence. Yet these two properties are empirically and theoretically distinct. Arguably, while intelligence is a direct predictor of an AI system's existential threat, consciousness is not. There are, however, certain incidental scenarios in which consciousness could influence existential risk, in either direction. Consciousness could be viewed as a means towards AI alignment, thereby lowering existential risk; or, it could be a precondition for reaching certain capabilities or levels of intelligence, and thus positively related to existential risk. Recognizing these distinctions can help AI safety researchers and public policymakers focus on the most pressing issues.", "AI": {"tldr": "\u8bba\u6587\u6f84\u6e05\u4e86AI\u610f\u8bc6\u4e0e\u5b58\u5728\u98ce\u9669\u4e4b\u95f4\u7684\u6df7\u6dc6\uff0c\u6307\u51fa\u667a\u80fd\u800c\u975e\u610f\u8bc6\u662fAI\u5b58\u5728\u98ce\u9669\u7684\u76f4\u63a5\u9884\u6d4b\u56e0\u7d20\uff0c\u5e76\u63a2\u8ba8\u4e86\u610f\u8bc6\u53ef\u80fd\u95f4\u63a5\u5f71\u54cd\u98ce\u9669\u7684\u4e24\u79cd\u60c5\u666f\u3002", "motivation": "\u7531\u4e8e\u8fd1\u671f\u6280\u672f\u8fdb\u6b65\u548c\u5a92\u4f53\u62a5\u9053\u589e\u52a0\uff0cAI\u5b58\u5728\u98ce\u9669\u95ee\u9898\u5728\u79d1\u5b66\u8fa9\u8bba\u4e2d\u65e5\u76ca\u7a81\u51fa\u3002\u540c\u65f6\uff0cAI\u8fdb\u5c55\u5f15\u53d1\u4e86\u5173\u4e8e\u4eba\u5de5\u610f\u8bc6\u51fa\u73b0\u7684\u731c\u6d4b\uff0c\u8fd9\u4e24\u4e2a\u95ee\u9898\u7ecf\u5e38\u88ab\u6df7\u6dc6\uff0c\u4f5c\u8005\u65e8\u5728\u6f84\u6e05\u8fd9\u79cd\u8bef\u89e3\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u533a\u5206\u610f\u8bc6\u548c\u667a\u80fd\u8fd9\u4e24\u4e2a\u5c5e\u6027\uff0c\u8bba\u8bc1\u5b83\u4eec\u5728AI\u5b58\u5728\u98ce\u9669\u8bc4\u4f30\u4e2d\u7684\u4e0d\u540c\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u8868\u660e\u667a\u80fd\u662fAI\u7cfb\u7edf\u5b58\u5728\u5a01\u80c1\u7684\u76f4\u63a5\u9884\u6d4b\u56e0\u7d20\uff0c\u800c\u610f\u8bc6\u672c\u8eab\u5e76\u975e\u76f4\u63a5\u76f8\u5173\u3002\u4f46\u610f\u8bc6\u53ef\u80fd\u901a\u8fc7\u4e24\u79cd\u65b9\u5f0f\u95f4\u63a5\u5f71\u54cd\u98ce\u9669\uff1a\u4f5c\u4e3aAI\u5bf9\u9f50\u7684\u624b\u6bb5\u964d\u4f4e\u98ce\u9669\uff0c\u6216\u4f5c\u4e3a\u8fbe\u5230\u67d0\u4e9b\u80fd\u529b\u6c34\u5e73\u7684\u5148\u51b3\u6761\u4ef6\u589e\u52a0\u98ce\u9669\u3002", "conclusion": "\u8bc6\u522b\u610f\u8bc6\u548c\u667a\u80fd\u4e4b\u95f4\u7684\u533a\u522b\u6709\u52a9\u4e8eAI\u5b89\u5168\u7814\u7a76\u4eba\u5458\u548c\u516c\u5171\u653f\u7b56\u5236\u5b9a\u8005\u4e13\u6ce8\u4e8e\u6700\u7d27\u8feb\u7684\u95ee\u9898\uff0c\u907f\u514d\u5c06\u8d44\u6e90\u6d6a\u8d39\u5728\u65e0\u5173\u7d27\u8981\u7684\u65b9\u9762\u3002"}}
{"id": "2511.17677", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.17677", "abs": "https://arxiv.org/abs/2511.17677", "authors": ["Abu Kaisar Mohammad Masum", "Naveed Mahmud", "M. Hassan Najafi", "Sercan Aygun"], "title": "A Hybrid Classical-Quantum Fine Tuned BERT for Text Classification", "comment": "This paper has been accepted by First AAAI Symposium on Quantum Information & Machine Learning (QIML): Bridging Quantum Computing and Artificial Intelligence at AAAI 2025 Fall Symposium", "summary": "Fine-tuning BERT for text classification can be computationally challenging and requires careful hyper-parameter tuning. Recent studies have highlighted the potential of quantum algorithms to outperform conventional methods in machine learning and text classification tasks. In this work, we propose a hybrid approach that integrates an n-qubit quantum circuit with a classical BERT model for text classification. We evaluate the performance of the fine-tuned classical-quantum BERT and demonstrate its feasibility as well as its potential in advancing this research area. Our experimental results show that the proposed hybrid model achieves performance that is competitive with, and in some cases better than, the classical baselines on standard benchmark datasets. Furthermore, our approach demonstrates the adaptability of classical-quantum models for fine-tuning pre-trained models across diverse datasets. Overall, the hybrid model highlights the promise of quantum computing in achieving improved performance for text classification tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06n\u91cf\u5b50\u6bd4\u7279\u91cf\u5b50\u7535\u8def\u4e0e\u7ecf\u5178BERT\u6a21\u578b\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\u7528\u4e8e\u6587\u672c\u5206\u7c7b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6df7\u5408\u6a21\u578b\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u751a\u81f3\u4f18\u4e8e\u7ecf\u5178\u57fa\u7ebf\u3002", "motivation": "BERT\u5fae\u8c03\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u9700\u8981\u4ed4\u7ec6\u7684\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u800c\u91cf\u5b50\u7b97\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u548c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u663e\u793a\u51fa\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "method": "\u96c6\u6210n\u91cf\u5b50\u6bd4\u7279\u91cf\u5b50\u7535\u8def\u4e0e\u7ecf\u5178BERT\u6a21\u578b\uff0c\u6784\u5efa\u7ecf\u5178-\u91cf\u5b50\u6df7\u5408\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u3002", "result": "\u6df7\u5408\u6a21\u578b\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4e0e\u7ecf\u5178\u57fa\u7ebf\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u65b9\u9762\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u8be5\u6df7\u5408\u6a21\u578b\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u63d0\u5347\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u8fd9\u4e00\u7814\u7a76\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u8bc1\u660e\u3002"}}
{"id": "2511.19302", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19302", "abs": "https://arxiv.org/abs/2511.19302", "authors": ["Arkaprabha Ghosal", "Soumyadip Patra", "Peter Bierhorst"], "title": "Quantitative and Optimal Device-Independent Lower Bounds on Detection Efficiency", "comment": "21 pages, 4 figures", "summary": "This paper examines a quantitative and optimal lower bound on the detector efficiency in a (2,2,2) Bell experiment within a fully device-independent framework, whereby the detectors used in the experiment are uncharacterized. We provide a tight lower bound on the minimum efficiency required to observe a desired Bell-CHSH violation using the Navascu\u00e9s-Pironio-Ac\u00edn (NPA) hierarchy, confirming tightness up to four decimal places with numerical optimization over explicit quantum realizations. We then introduce the effect of dark counts and demonstrate how to quantify the minimum required efficiency to observe a desired CHSH violation with an increasing dark count error. Finally, to obtain an analytical closed-form expression of the minimum efficiency, we consider the set of no-signaling behaviors that satisfy the Tsirelson bound, which are easier to characterize than the quantum set. Using such behaviors, we find a simple closed-form expression for a lower bound on the minimum efficiency which is monotonically increasing with the CHSH violation, though the analytically obtained lower bounds are meaningfully below the numerically tight lower bound.", "AI": {"tldr": "\u672c\u6587\u5728\u5b8c\u5168\u8bbe\u5907\u65e0\u5173\u6846\u67b6\u4e0b\u7814\u7a76\u4e86(2,2,2)\u8d1d\u5c14\u5b9e\u9a8c\u4e2d\u63a2\u6d4b\u5668\u6548\u7387\u7684\u5b9a\u91cf\u6700\u4f18\u4e0b\u754c\uff0c\u4f7f\u7528NPA\u5c42\u6b21\u7ed3\u6784\u63d0\u4f9b\u4e86\u89c2\u5bdf\u671f\u671b\u8d1d\u5c14-CHSH\u8fdd\u80cc\u6240\u9700\u7684\u6700\u5c0f\u6548\u7387\u7684\u7d27\u4e0b\u754c\uff0c\u5e76\u8003\u8651\u4e86\u6697\u8ba1\u6570\u7684\u5f71\u54cd\uff0c\u6700\u540e\u901a\u8fc7\u8003\u8651\u6ee1\u8db3Tsirelson\u754c\u7684\u65e0\u4fe1\u53f7\u884c\u4e3a\u5f97\u5230\u4e86\u6700\u5c0f\u6548\u7387\u7684\u7b80\u5355\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "motivation": "\u5728\u8bbe\u5907\u65e0\u5173\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\uff0c\u63a2\u6d4b\u5668\u6548\u7387\u662f\u5b9e\u9a8c\u5b9e\u73b0\u7684\u5173\u952e\u9650\u5236\u56e0\u7d20\u3002\u672c\u6587\u65e8\u5728\u91cf\u5316\u5728\u5b8c\u5168\u8bbe\u5907\u65e0\u5173\u8bbe\u7f6e\u4e0b\u89c2\u5bdf\u8d1d\u5c14-CHSH\u8fdd\u80cc\u6240\u9700\u7684\u6700\u5c0f\u63a2\u6d4b\u5668\u6548\u7387\uff0c\u4e3a\u5b9e\u9a8c\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u4f7f\u7528Navascu\u00e9s-Pironio-Ac\u00edn (NPA)\u5c42\u6b21\u7ed3\u6784\u8fdb\u884c\u6570\u503c\u4f18\u5316\uff0c\u9a8c\u8bc1\u4e0b\u754c\u7684\u7d27\u6027\uff1b\u5f15\u5165\u6697\u8ba1\u6570\u8bef\u5dee\u5206\u6790\uff1b\u901a\u8fc7\u8003\u8651\u6ee1\u8db3Tsirelson\u754c\u7684\u65e0\u4fe1\u53f7\u884c\u4e3a\u63a8\u5bfc\u89e3\u6790\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u83b7\u5f97\u4e86\u6700\u5c0f\u63a2\u6d4b\u5668\u6548\u7387\u7684\u7d27\u4e0b\u754c\uff08\u6570\u503c\u9a8c\u8bc1\u5230\u56db\u4f4d\u5c0f\u6570\u7cbe\u5ea6\uff09\uff1b\u5c55\u793a\u4e86\u6697\u8ba1\u6570\u589e\u52a0\u65f6\u6240\u9700\u6700\u5c0f\u6548\u7387\u7684\u53d8\u5316\uff1b\u5f97\u5230\u4e86\u6700\u5c0f\u6548\u7387\u7684\u7b80\u5355\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u867d\u7136\u8be5\u89e3\u6790\u4e0b\u754c\u660e\u663e\u4f4e\u4e8e\u6570\u503c\u7d27\u4e0b\u754c\u3002", "conclusion": "\u672c\u6587\u4e3a\u8bbe\u5907\u65e0\u5173\u8d1d\u5c14\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u63a2\u6d4b\u5668\u6548\u7387\u7684\u5b9a\u91cf\u4e0b\u754c\u5206\u6790\uff0c\u6570\u503c\u65b9\u6cd5\u53ef\u83b7\u5f97\u7d27\u4e0b\u754c\uff0c\u800c\u89e3\u6790\u65b9\u6cd5\u867d\u7b80\u5316\u4f46\u4fdd\u5b88\uff0c\u4e3a\u5b9e\u9a8c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u51c6\u3002"}}
{"id": "2511.19155", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19155", "abs": "https://arxiv.org/abs/2511.19155", "authors": ["Xihe Qiu", "Gengchen Ma", "Haoyu Wang", "Chen Zhan", "Xiaoyu Tan", "Shuo Li"], "title": "EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction", "comment": null, "summary": "Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEEG-VLM\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ea7\u7279\u5f81\u5bf9\u9f50\u548c\u89c6\u89c9\u589e\u5f3a\u7684\u8bed\u8a00\u5f15\u5bfc\u63a8\u7406\uff0c\u63d0\u5347EEG\u7761\u7720\u5206\u671f\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\u548c\u624b\u5de5\u7279\u5f81\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u9891\u6a21\u5f0f\u5e76\u5b9e\u73b0\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u3002\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u5e94\u7528\u53d7\u9650\uff0c\u5bf9EEG\u4fe1\u53f7\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u89c6\u89c9\u8bed\u8a00\u6846\u67b6\uff0c\u5305\u542b\u89c6\u89c9\u589e\u5f3a\u6a21\u5757\u6784\u5efa\u9ad8\u7ea7\u89c6\u89c9token\uff0c\u901a\u8fc7\u591a\u7ea7\u5bf9\u9f50\u673a\u5236\u4e0eCLIP\u7279\u5f81\u5bf9\u9f50\uff0c\u5e76\u91c7\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u7b56\u7565\u5206\u89e3\u590d\u6742\u533b\u5b66\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86VLMs\u5728EEG\u7761\u7720\u5206\u671f\u5206\u7c7b\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "EEG-VLM\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u548c\u53ef\u89e3\u91caEEG\u5206\u6790\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.17688", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17688", "abs": "https://arxiv.org/abs/2511.17688", "authors": ["Quan Liu", "Feng Ye", "Chenhao Lu", "Shuming Zhen", "Guanliang Huang", "Lunzhe Chen", "Xudong Ke"], "title": "Enhancing Adversarial Transferability through Block Stretch and Shrink", "comment": "code will be releace", "summary": "Adversarial attacks introduce small, deliberately crafted perturbations that mislead neural networks, and their transferability from white-box to black-box target models remains a critical research focus. Input transformation-based attacks are a subfield of adversarial attacks that enhance input diversity through input transformations to improve the transferability of adversarial examples. However, existing input transformation-based attacks tend to exhibit limited cross-model transferability. Previous studies have shown that high transferability is associated with diverse attention heatmaps and the preservation of global semantics in transformed inputs. Motivated by this observation, we propose Block Stretch and Shrink (BSS), a method that divides an image into blocks and applies stretch and shrink operations to these blocks, thereby diversifying attention heatmaps in transformed inputs while maintaining their global semantics. Empirical evaluations on a subset of ImageNet demonstrate that BSS outperforms existing input transformation-based attack methods in terms of transferability. Furthermore, we examine the impact of the number scale, defined as the number of transformed inputs, in input transformation-based attacks, and advocate evaluating these methods under a unified number scale to enable fair and comparable assessments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBlock Stretch and Shrink (BSS)\u7684\u8f93\u5165\u53d8\u6362\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u56fe\u50cf\u5206\u5272\u6210\u5757\u5e76\u5e94\u7528\u62c9\u4f38\u548c\u6536\u7f29\u64cd\u4f5c\u6765\u589e\u5f3a\u5bf9\u6297\u6837\u672c\u7684\u8de8\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u8f93\u5165\u53d8\u6362\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u5728\u8de8\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\u65b9\u9762\u8868\u73b0\u6709\u9650\u3002\u7814\u7a76\u8868\u660e\uff0c\u9ad8\u53ef\u8f6c\u79fb\u6027\u4e0e\u591a\u6837\u5316\u7684\u6ce8\u610f\u529b\u70ed\u56fe\u548c\u4fdd\u6301\u53d8\u6362\u8f93\u5165\u4e2d\u7684\u5168\u5c40\u8bed\u4e49\u76f8\u5173\u3002", "method": "\u63d0\u51faBSS\u65b9\u6cd5\uff0c\u5c06\u56fe\u50cf\u5206\u5272\u6210\u5757\uff0c\u5e76\u5bf9\u8fd9\u4e9b\u5757\u5e94\u7528\u62c9\u4f38\u548c\u6536\u7f29\u64cd\u4f5c\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u5168\u5c40\u8bed\u4e49\u7684\u540c\u65f6\u591a\u6837\u5316\u53d8\u6362\u8f93\u5165\u4e2d\u7684\u6ce8\u610f\u529b\u70ed\u56fe\u3002", "result": "\u5728ImageNet\u5b50\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cBSS\u5728\u53ef\u8f6c\u79fb\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u8f93\u5165\u53d8\u6362\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "BSS\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u6297\u6837\u672c\u7684\u8de8\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\uff0c\u5e76\u5efa\u8bae\u5728\u7edf\u4e00\u7684\u53d8\u6362\u8f93\u5165\u6570\u91cf\u5c3a\u5ea6\u4e0b\u8bc4\u4f30\u57fa\u4e8e\u8f93\u5165\u53d8\u6362\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fdd\u516c\u5e73\u53ef\u6bd4\u7684\u8bc4\u4f30\u3002"}}
{"id": "2511.17693", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17693", "abs": "https://arxiv.org/abs/2511.17693", "authors": ["Gin\u00e9s Carreto Pic\u00f3n", "Peng Yuan Zhou", "Qi Zhang", "Alexandros Iosifidis"], "title": "DeepCoT: Deep Continual Transformers for Real-Time Inference on Data Streams", "comment": "13 pages, 5 figures", "summary": "Transformer-based models have dramatically increased their size and parameter count to tackle increasingly complex tasks. At the same time, there is a growing demand for low-latency inference on resource-constrained devices that achieves high performance. In particular, stream data inference is typically performed over a sliding temporal window, leading to highly redundant computations. The recent Continual Transformers have addressed this issue, but they can only be effectively used in shallow models, which limits their scope and generalization power. In this paper, we propose the Deep Continual Transformer (DeepCoT), a redundancy-free encoder-only model that can be applied over existing deep encoder architectures with minimal changes. In our experiments over audio, video, and text streams, we show that DeepCoTs retain comparative performance to their non-continual baselines while offering a linear computational cost for all Transformer layers, which reduces up to two orders of magnitude in the running time compared to previous efficient models.", "AI": {"tldr": "DeepCoT\u662f\u4e00\u79cd\u65e0\u5197\u4f59\u7684\u4ec5\u7f16\u7801\u5668\u6a21\u578b\uff0c\u53ef\u5728\u73b0\u6709\u6df1\u5ea6\u7f16\u7801\u5668\u67b6\u6784\u4e0a\u5e94\u7528\uff0c\u4e3a\u6d41\u6570\u636e\u63a8\u7406\u63d0\u4f9b\u7ebf\u6027\u8ba1\u7b97\u6210\u672c\uff0c\u76f8\u6bd4\u5148\u524d\u9ad8\u6548\u6a21\u578b\u51cf\u5c11\u4e24\u4e2a\u6570\u91cf\u7ea7\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "Transformer\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u4e0d\u65ad\u589e\u5927\u4ee5\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u9700\u8981\u4f4e\u5ef6\u8fdf\u63a8\u7406\u3002\u6d41\u6570\u636e\u63a8\u7406\u5728\u6ed1\u52a8\u65f6\u95f4\u7a97\u53e3\u4e0a\u6267\u884c\u4f1a\u5bfc\u81f4\u9ad8\u5ea6\u5197\u4f59\u8ba1\u7b97\uff0c\u73b0\u6709Continual Transformers\u4ec5\u9002\u7528\u4e8e\u6d45\u5c42\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faDeep Continual Transformer (DeepCoT)\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u5197\u4f59\u7684\u4ec5\u7f16\u7801\u5668\u6a21\u578b\uff0c\u53ef\u5bf9\u73b0\u6709\u6df1\u5ea6\u7f16\u7801\u5668\u67b6\u6784\u8fdb\u884c\u6700\u5c0f\u4fee\u6539\u5373\u53ef\u5e94\u7528\u3002", "result": "\u5728\u97f3\u9891\u3001\u89c6\u9891\u548c\u6587\u672c\u6d41\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDeepCoT\u4e0e\u5176\u975e\u6301\u7eed\u57fa\u7ebf\u76f8\u6bd4\u4fdd\u6301\u76f8\u5f53\u6027\u80fd\uff0c\u540c\u65f6\u4e3a\u6240\u6709Transformer\u5c42\u63d0\u4f9b\u7ebf\u6027\u8ba1\u7b97\u6210\u672c\uff0c\u76f8\u6bd4\u5148\u524d\u9ad8\u6548\u6a21\u578b\u51cf\u5c11\u9ad8\u8fbe\u4e24\u4e2a\u6570\u91cf\u7ea7\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "DeepCoT\u6210\u529f\u89e3\u51b3\u4e86\u6df1\u5ea6\u6a21\u578b\u4e2d\u6d41\u6570\u636e\u63a8\u7406\u7684\u5197\u4f59\u8ba1\u7b97\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2511.19304", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19304", "abs": "https://arxiv.org/abs/2511.19304", "authors": ["Jiayi Zhang", "Yiran Peng", "Fanqi Kong", "Yang Cheng", "Yifan Wu", "Zhaoyang Yu", "Jinyu Xiang", "Jianhao Ruan", "Jinlin Wang", "Maojia Song", "HongZhang Liu", "Xiangru Tang", "Bang Liu", "Chenglin Wu", "Yuyu Luo"], "title": "AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning", "comment": null, "summary": "Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AutoEnv\u6846\u67b6\u6765\u81ea\u52a8\u751f\u6210\u5f02\u6784\u73af\u5883\uff0c\u5e76\u6784\u5efa\u4e86AutoEnv-36\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u8de8\u73af\u5883\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\u5355\u4e00\u5b66\u4e60\u65b9\u6cd5\u5728\u5f02\u6784\u73af\u5883\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u73af\u5883\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u901a\u5e38\u5728\u5355\u4e00\u73af\u5883\u4e2d\u81ea\u6211\u8fdb\u5316\uff0c\u7f3a\u4e4f\u5bf9\u8de8\u73af\u5883\u5b66\u4e60\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u6784\u5efa\u6807\u51c6\u5316\u7684\u5f02\u6784\u73af\u5883\u96c6\u5408\u6765\u7814\u7a76\u667a\u80fd\u4f53\u7684\u8de8\u73af\u5883\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u63d0\u51faAutoEnv\u6846\u67b6\uff0c\u5c06\u73af\u5883\u5206\u89e3\u4e3a\u8f6c\u79fb\u3001\u89c2\u5bdf\u548c\u5956\u52b1\u7684\u5206\u5e03\uff0c\u4f4e\u6210\u672c\u751f\u6210\u5f02\u6784\u4e16\u754c\uff1b2. \u6784\u5efaAutoEnv-36\u6570\u636e\u96c6\uff0836\u4e2a\u73af\u5883\uff0c358\u4e2a\u9a8c\u8bc1\u5173\u5361\uff09\uff1b3. \u5c06\u667a\u80fd\u4f53\u5b66\u4e60\u5f62\u5f0f\u5316\u4e3a\u4ee5\u7ec4\u4ef6\u4e3a\u4e2d\u5fc3\u7684\u4e09\u4e2a\u9636\u6bb5\uff1a\u9009\u62e9\u3001\u4f18\u5316\u548c\u8bc4\u4f30\uff1b4. \u8bbe\u8ba1\u516b\u79cd\u5b66\u4e60\u65b9\u6cd5\u5e76\u5728AutoEnv-36\u4e0a\u8bc4\u4f30\u3002", "result": "1. \u4e03\u4e2a\u8bed\u8a00\u6a21\u578b\u5728AutoEnv-36\u4e0a\u4ec5\u83b7\u5f9712-49%\u7684\u6807\u51c6\u5316\u5956\u52b1\uff0c\u8868\u660e\u8be5\u6570\u636e\u96c6\u7684\u6311\u6218\u6027\uff1b2. \u5355\u4e00\u5b66\u4e60\u65b9\u6cd5\u5728\u73af\u5883\u6570\u91cf\u589e\u52a0\u65f6\u6548\u679c\u5feb\u901f\u4e0b\u964d\uff1b3. \u73af\u5883\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u9009\u62e9\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u968f\u7740\u65b9\u6cd5\u7a7a\u95f4\u6269\u5927\u5448\u73b0\u6536\u76ca\u9012\u51cf\u3002", "conclusion": "\u56fa\u5b9a\u5b66\u4e60\u65b9\u6cd5\u65e0\u6cd5\u5728\u5f02\u6784\u73af\u5883\u4e2d\u6269\u5c55\uff0c\u73af\u5883\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u9009\u62e9\u662f\u5fc5\u8981\u7684\u4f46\u4ecd\u6709\u5c40\u9650\u6027\u3002AutoEnv\u548cAutoEnv-36\u4e3a\u7814\u7a76\u8de8\u73af\u5883\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2511.17741", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17741", "abs": "https://arxiv.org/abs/2511.17741", "authors": ["Justin Diamond", "Markus Lill"], "title": "Diffusion Models are Molecular Dynamics Simulators", "comment": null, "summary": "We prove that a denoising diffusion sampler equipped with a sequential bias across the batch dimension is exactly an Euler-Maruyama integrator for overdamped Langevin dynamics. Each reverse denoising step, with its associated spring stiffness, can be interpreted as one step of a stochastic differential equation with an effective time step set jointly by the noise schedule and that stiffness. The learned score then plays the role of the drift, equivalently the gradient of a learned energy, yielding a precise correspondence between diffusion sampling and Langevin time evolution.\n  This equivalence recasts molecular dynamics (MD) in terms of diffusion models. Accuracy is no longer tied to a fixed, extremely small MD time step; instead, it is controlled by two scalable knobs: model capacity, which governs how well the drift is approximated, and the number of denoising steps, which sets the integrator resolution. In practice, this leads to a fully data-driven MD framework that learns forces from uncorrelated equilibrium snapshots, requires no hand-engineered force fields, uses no trajectory data for training, and still preserves the Boltzmann distribution associated with the learned energy.\n  We derive trajectory-level, information-theoretic error bounds that cleanly separate discretization error from score-model error, clarify how temperature enters through the effective spring, and show that the resulting sampler generates molecular trajectories with MD-like temporal correlations, even though the model is trained only on static configurations.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5e26\u5e8f\u5217\u504f\u7f6e\u7684\u964d\u566a\u6269\u6563\u91c7\u6837\u5668\u7b49\u4ef7\u4e8e\u8fc7\u963b\u5c3c\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u7684\u6b27\u62c9-\u9a6c\u9c81\u4e9a\u9a6c\u79ef\u5206\u5668\uff0c\u5c06\u6269\u6563\u91c7\u6837\u4e0e\u6717\u4e4b\u4e07\u65f6\u95f4\u6f14\u5316\u5efa\u7acb\u7cbe\u786e\u5bf9\u5e94\u5173\u7cfb\uff0c\u4ece\u800c\u5c06\u5206\u5b50\u52a8\u529b\u5b66\u91cd\u65b0\u8868\u8ff0\u4e3a\u6269\u6563\u6a21\u578b\u6846\u67b6\u3002", "motivation": "\u4f20\u7edf\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u53d7\u9650\u4e8e\u6781\u5c0f\u7684\u65f6\u95f4\u6b65\u957f\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6269\u6563\u6a21\u578b\u6846\u67b6\u6446\u8131\u8fd9\u4e00\u9650\u5236\uff0c\u5b9e\u73b0\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u5206\u5b50\u52a8\u529b\u5b66\uff0c\u65e0\u9700\u624b\u5de5\u8bbe\u8ba1\u7684\u529b\u573a\u6216\u8f68\u8ff9\u6570\u636e\u8bad\u7ec3\u3002", "method": "\u5c06\u964d\u566a\u6269\u6563\u91c7\u6837\u5668\u89e3\u91ca\u4e3a\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u7684\u79ef\u5206\u5668\uff0c\u5229\u7528\u5b66\u4e60\u5230\u7684\u5206\u6570\u4f5c\u4e3a\u6f02\u79fb\u9879\uff08\u5373\u5b66\u4e60\u80fd\u91cf\u7684\u68af\u5ea6\uff09\uff0c\u901a\u8fc7\u6a21\u578b\u5bb9\u91cf\u548c\u964d\u566a\u6b65\u6570\u4e24\u4e2a\u53ef\u6269\u5c55\u53c2\u6570\u63a7\u5236\u7cbe\u5ea6\u3002", "result": "\u5efa\u7acb\u4e86\u8f68\u8ff9\u7ea7\u4fe1\u606f\u8bba\u8bef\u5dee\u754c\u9650\uff0c\u6e05\u6670\u5206\u79bb\u79bb\u6563\u5316\u8bef\u5dee\u4e0e\u5206\u6570\u6a21\u578b\u8bef\u5dee\uff0c\u8bc1\u660e\u5373\u4f7f\u4ec5\u4f7f\u7528\u9759\u6001\u914d\u7f6e\u8bad\u7ec3\uff0c\u4e5f\u80fd\u751f\u6210\u5177\u6709\u5206\u5b50\u52a8\u529b\u5b66\u65f6\u95f4\u76f8\u5173\u6027\u7684\u8f68\u8ff9\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u5206\u5b50\u52a8\u529b\u5b66\uff0c\u4ece\u975e\u76f8\u5173\u5e73\u8861\u5feb\u7167\u5b66\u4e60\u529b\u573a\uff0c\u65e0\u9700\u8f68\u8ff9\u6570\u636e\u8bad\u7ec3\uff0c\u4ecd\u80fd\u4fdd\u6301\u4e0e\u5b66\u4e60\u80fd\u91cf\u76f8\u5173\u7684\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u3002"}}
{"id": "2511.17776", "categories": ["cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.17776", "abs": "https://arxiv.org/abs/2511.17776", "authors": ["Melika Shirian", "Kianoosh Vadaei", "Kian Majlessi", "Audrina Ebrahimi", "Arshia Hemmat", "Peyman Adibi", "Hossein Karshenas"], "title": "PrismSSL: One Interface, Many Modalities; A Single-Interface Library for Multimodal Self-Supervised Learning", "comment": null, "summary": "We present PrismSSL, a Python library that unifies state-of-the-art self-supervised learning (SSL) methods across audio, vision, graphs, and cross-modal settings in a single, modular codebase. The goal of the demo is to show how researchers and practitioners can: (i) install, configure, and run pretext training with a few lines of code; (ii) reproduce compact benchmarks; and (iii) extend the framework with new modalities or methods through clean trainer and dataset abstractions. PrismSSL is packaged on PyPI, released under the MIT license, integrates tightly with HuggingFace Transformers, and provides quality-of-life features such as distributed training in PyTorch, Optuna-based hyperparameter search, LoRA fine-tuning for Transformer backbones, animated embedding visualizations for sanity checks, Weights & Biases logging, and colorful, structured terminal logs for improved usability and clarity. In addition, PrismSSL offers a graphical dashboard - built with Flask and standard web technologies - that enables users to configure and launch training pipelines with minimal coding. The artifact (code and data recipes) will be publicly available and reproducible.", "AI": {"tldr": "PrismSSL\u662f\u4e00\u4e2a\u7edf\u4e00\u7684Python\u5e93\uff0c\u96c6\u6210\u4e86\u97f3\u9891\u3001\u89c6\u89c9\u3001\u56fe\u548c\u8de8\u6a21\u6001\u9886\u57df\u6700\u5148\u8fdb\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u4ee3\u7801\u5e93\u548c\u56fe\u5f62\u5316\u4eea\u8868\u677f\u3002", "motivation": "\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7b80\u5316\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u5b89\u88c5\u3001\u914d\u7f6e\u548c\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u652f\u6301\u591a\u79cd\u6a21\u6001\u548c\u65b9\u6cd5\u7684\u5feb\u901f\u5b9e\u73b0\u4e0e\u6269\u5c55\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u96c6\u6210HuggingFace Transformers\uff0c\u63d0\u4f9b\u5206\u5e03\u5f0f\u8bad\u7ec3\u3001\u8d85\u53c2\u6570\u641c\u7d22\u3001LoRA\u5fae\u8c03\u3001\u5d4c\u5165\u53ef\u89c6\u5316\u7b49\u529f\u80fd\uff0c\u5e76\u6784\u5efa\u57fa\u4e8eFlask\u7684\u56fe\u5f62\u5316\u4eea\u8868\u677f\u3002", "result": "\u5f00\u53d1\u4e86PrismSSL\u5e93\uff0c\u5df2\u6253\u5305\u5728PyPI\u4e0a\u53d1\u5e03\uff0c\u652f\u6301MIT\u8bb8\u53ef\u8bc1\uff0c\u63d0\u4f9b\u5b8c\u6574\u7684\u8bad\u7ec3\u6d41\u7a0b\u548c\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u786e\u4fdd\u4ee3\u7801\u548c\u914d\u65b9\u7684\u516c\u5f00\u53ef\u590d\u73b0\u3002", "conclusion": "PrismSSL\u6210\u529f\u7edf\u4e00\u4e86\u591a\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u6d01\u7684\u4ee3\u7801\u548c\u56fe\u5f62\u754c\u9762\u663e\u8457\u63d0\u5347\u4e86\u7814\u7a76\u6548\u7387\u548c\u53ef\u7528\u6027\u3002"}}
{"id": "2511.17782", "categories": ["cs.LG", "cs.CC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17782", "abs": "https://arxiv.org/abs/2511.17782", "authors": ["Yiwen Kou", "Raghu Meka"], "title": "Smoothed Agnostic Learning of Halfspaces over the Hypercube", "comment": null, "summary": "Agnostic learning of Boolean halfspaces is a fundamental problem in computational learning theory, but it is known to be computationally hard even for weak learning. Recent work [CKKMK24] proposed smoothed analysis as a way to bypass such hardness, but existing frameworks rely on additive Gaussian perturbations, making them unsuitable for discrete domains. We introduce a new smoothed agnostic learning framework for Boolean inputs, where perturbations are modeled via random bit flips. This defines a natural discrete analogue of smoothed optimality generalizing the Gaussian case. Under strictly subexponential assumptions on the input distribution, we give an efficient algorithm for learning halfspaces in this model, with runtime and sample complexity approximately n raised to a poly(1/(sigma * epsilon)) factor. Previously, such algorithms were known only with strong structural assumptions for the discrete hypercube, for example, independent coordinates or symmetric distributions. Our result provides the first computationally efficient guarantee for smoothed agnostic learning of halfspaces over the Boolean hypercube, bridging the gap between worst-case intractability and practical learnability in discrete settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u968f\u673a\u6bd4\u7279\u7ffb\u8f6c\u7684\u5e73\u6ed1\u4e0d\u53ef\u77e5\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5e03\u5c14\u534a\u7a7a\u95f4\u7684\u5e73\u6ed1\u4e0d\u53ef\u77e5\u5b66\u4e60\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u9ad8\u65af\u6270\u52a8\u5728\u79bb\u6563\u57df\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5e03\u5c14\u534a\u7a7a\u95f4\u7684\u4e0d\u53ef\u77e5\u5b66\u4e60\u5728\u8ba1\u7b97\u5b66\u4e60\u7406\u8bba\u4e2d\u662f\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff0c\u4f46\u5373\u4f7f\u5728\u5f31\u5b66\u4e60\u4e0b\u4e5f\u88ab\u8bc1\u660e\u662f\u8ba1\u7b97\u56f0\u96be\u7684\u3002\u73b0\u6709\u5e73\u6ed1\u5206\u6790\u6846\u67b6\u4f9d\u8d56\u52a0\u6027\u9ad8\u65af\u6270\u52a8\uff0c\u4e0d\u9002\u5408\u79bb\u6563\u57df\u3002", "method": "\u5f15\u5165\u65b0\u7684\u5e73\u6ed1\u4e0d\u53ef\u77e5\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u968f\u673a\u6bd4\u7279\u7ffb\u8f6c\u5efa\u6a21\u6270\u52a8\uff0c\u5b9a\u4e49\u79bb\u6563\u7c7b\u6bd4\u4e8e\u9ad8\u65af\u60c5\u51b5\u7684\u5e73\u6ed1\u6700\u4f18\u6027\u3002\u5728\u8f93\u5165\u5206\u5e03\u7684\u4e25\u683c\u6b21\u6307\u6570\u5047\u8bbe\u4e0b\uff0c\u63d0\u51fa\u9ad8\u6548\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u5728\u8be5\u6a21\u578b\u4e0b\u7ed9\u51fa\u4e86\u5b66\u4e60\u534a\u7a7a\u95f4\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u8fd0\u884c\u65f6\u95f4\u548c\u6837\u672c\u590d\u6742\u5ea6\u7ea6\u4e3an\u7684poly(1/(sigma * epsilon))\u6b21\u65b9\u3002\u8fd9\u662f\u5e03\u5c14\u8d85\u7acb\u65b9\u4f53\u4e0a\u5e73\u6ed1\u4e0d\u53ef\u77e5\u5b66\u4e60\u534a\u7a7a\u95f4\u7684\u7b2c\u4e00\u4e2a\u8ba1\u7b97\u9ad8\u6548\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u7ed3\u679c\u5728\u79bb\u6563\u8bbe\u7f6e\u4e2d\u5f25\u5408\u4e86\u6700\u574f\u60c5\u51b5\u4e0d\u53ef\u5904\u7406\u6027\u4e0e\u5b9e\u9645\u53ef\u5b66\u4e60\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5e03\u5c14\u8d85\u7acb\u65b9\u4f53\u4e0a\u7684\u5e73\u6ed1\u4e0d\u53ef\u77e5\u5b66\u4e60\u63d0\u4f9b\u4e86\u9996\u4e2a\u8ba1\u7b97\u9ad8\u6548\u4fdd\u8bc1\u3002"}}
{"id": "2511.17784", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17784", "abs": "https://arxiv.org/abs/2511.17784", "authors": ["Lyu Yuhuan"], "title": "Improved Sample Complexity for Full Coverage in Compact and Continuous Spaces", "comment": null, "summary": "Verifying uniform conditions over continuous spaces through random sampling is fundamental in machine learning and control theory, yet classical coverage analyses often yield conservative bounds, particularly at small failure probabilities. We study uniform random sampling on the $d$-dimensional unit hypercube and analyze the number of uncovered subcubes after discretization. By applying a concentration inequality to the uncovered-count statistic, we derive a sample complexity bound with a logarithmic dependence on the failure probability ($\u03b4$), i.e., $M =O( \\tilde{C}\\ln(\\frac{2\\tilde{C}}\u03b4))$, which contrasts sharply with the classical linear $1/\u03b4$ dependence. Under standard Lipschitz and uniformity assumptions, we present a self-contained derivation and compare our result with classical coupon-collector rates. Numerical studies across dimensions, precision levels, and confidence targets indicate that our bound tracks practical coverage requirements more tightly and scales favorably as $\u03b4\\to 0$. Our findings offer a sharper theoretical tool for algorithms that rely on grid-based coverage guarantees, enabling more efficient sampling, especially in high-confidence regimes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728d\u7ef4\u5355\u4f4d\u8d85\u7acb\u65b9\u4f53\u4e0a\u7684\u5747\u5300\u968f\u673a\u91c7\u6837\uff0c\u901a\u8fc7\u5e94\u7528\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u5230\u672a\u8986\u76d6\u5b50\u7acb\u65b9\u4f53\u8ba1\u6570\u7edf\u8ba1\u91cf\uff0c\u63a8\u5bfc\u51fa\u6837\u672c\u590d\u6742\u5ea6\u8fb9\u754c\uff0c\u8be5\u8fb9\u754c\u4e0e\u5931\u8d25\u6982\u7387\u03b4\u5448\u5bf9\u6570\u4f9d\u8d56\u5173\u7cfb\uff0c\u76f8\u6bd4\u7ecf\u5178\u7684\u7ebf\u60271/\u03b4\u4f9d\u8d56\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u7ecf\u5178\u7684\u8986\u76d6\u5206\u6790\u5728\u5c0f\u5931\u8d25\u6982\u7387\u4e0b\u5f80\u5f80\u4ea7\u751f\u4fdd\u5b88\u8fb9\u754c\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7d27\u7684\u7406\u8bba\u5de5\u5177\u6765\u652f\u6301\u4f9d\u8d56\u7f51\u683c\u8986\u76d6\u4fdd\u8bc1\u7684\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7f6e\u4fe1\u5ea6\u673a\u5236\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u6548\u91c7\u6837\u3002", "method": "\u5728d\u7ef4\u5355\u4f4d\u8d85\u7acb\u65b9\u4f53\u4e0a\u8fdb\u884c\u5747\u5300\u968f\u673a\u91c7\u6837\uff0c\u5206\u6790\u79bb\u6563\u5316\u540e\u7684\u672a\u8986\u76d6\u5b50\u7acb\u65b9\u4f53\u6570\u91cf\uff0c\u5e94\u7528\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u5230\u672a\u8986\u76d6\u8ba1\u6570\u7edf\u8ba1\u91cf\uff0c\u5e76\u5728\u6807\u51c6Lipschitz\u548c\u5747\u5300\u6027\u5047\u8bbe\u4e0b\u8fdb\u884c\u81ea\u5305\u542b\u63a8\u5bfc\u3002", "result": "\u63a8\u5bfc\u51fa\u6837\u672c\u590d\u6742\u5ea6\u8fb9\u754cM = O(\u02dcC ln(2\u02dcC/\u03b4))\uff0c\u5177\u6709\u5bf9\u6570\u4f9d\u8d56\u03b4\u7684\u7279\u6027\uff0c\u6570\u503c\u7814\u7a76\u8868\u660e\u8be5\u8fb9\u754c\u80fd\u66f4\u7d27\u5bc6\u5730\u8ddf\u8e2a\u5b9e\u9645\u8986\u76d6\u9700\u6c42\uff0c\u5e76\u5728\u03b4\u21920\u65f6\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f9d\u8d56\u7f51\u683c\u8986\u76d6\u4fdd\u8bc1\u7684\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u9510\u5229\u7684\u7406\u8bba\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7f6e\u4fe1\u5ea6\u673a\u5236\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u91c7\u6837\uff0c\u76f8\u6bd4\u7ecf\u5178\u4f18\u60e0\u5238\u6536\u96c6\u5668\u901f\u7387\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2511.17787", "categories": ["cs.LG", "physics.med-ph", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.17787", "abs": "https://arxiv.org/abs/2511.17787", "authors": ["Elizabeth Chen", "Andrew Lee", "Tanbir Sarowar", "Xiaolin Chen"], "title": "Data-Driven Predictive Modeling of Microfluidic Cancer Cell Separation Using a Deterministic Lateral Displacement Device", "comment": "Accepted to IEEE International Conference on Data Mining (ICDM) 2025 REU Symposium", "summary": "Deterministic Lateral Displacement (DLD) devices are widely used in microfluidics for label-free, size-based separation of particles and cells, with particular promise in isolating circulating tumor cells (CTCs) for early cancer diagnostics. This study focuses on the optimization of DLD design parameters, such as row shift fraction, post size, and gap distance, to enhance the selective isolation of lung cancer cells based on their physical properties. To overcome the challenges of rare CTC detection and reduce reliance on computationally intensive simulations, machine learning models including gradient boosting, k-nearest neighbors, random forest, and multilayer perceptron (MLP) regressors are employed. Trained on a large, numerically validated dataset, these models predict particle trajectories and identify optimal device configurations, enabling high-throughput and cost-effective DLD design. Beyond trajectory prediction, the models aid in isolating critical design variables, offering a systematic, data-driven framework for automated DLD optimization. This integrative approach advances the development of scalable and precise microfluidic systems for cancer diagnostics, contributing to the broader goals of early detection and personalized medicine.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f18\u5316\u786e\u5b9a\u6027\u4fa7\u5411\u4f4d\u79fb\uff08DLD\uff09\u8bbe\u5907\u7684\u8bbe\u8ba1\u53c2\u6570\uff0c\u4ee5\u63d0\u9ad8\u80ba\u764c\u7ec6\u80de\u5206\u79bb\u6548\u7387\uff0c\u4e3a\u764c\u75c7\u65e9\u671f\u8bca\u65ad\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u8bbe\u8ba1\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u5faa\u73af\u80bf\u7624\u7ec6\u80de\uff08CTCs\uff09\u68c0\u6d4b\u4e2d\u7684\u7a00\u6709\u7ec6\u80de\u8bc6\u522b\u6311\u6218\uff0c\u51cf\u5c11\u5bf9\u8ba1\u7b97\u5bc6\u96c6\u578b\u6a21\u62df\u7684\u4f9d\u8d56\uff0c\u5f00\u53d1\u9ad8\u901a\u91cf\u3001\u6210\u672c\u6548\u76ca\u9ad8\u7684DLD\u8bbe\u5907\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u68af\u5ea6\u63d0\u5347\u3001k\u8fd1\u90bb\u3001\u968f\u673a\u68ee\u6797\u548c\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u56de\u5f52\u5668\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u57fa\u4e8e\u5927\u91cf\u6570\u503c\u9a8c\u8bc1\u6570\u636e\u96c6\u9884\u6d4b\u7c92\u5b50\u8f68\u8ff9\u5e76\u8bc6\u522b\u6700\u4f18\u8bbe\u5907\u914d\u7f6e\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u7c92\u5b50\u8f68\u8ff9\uff0c\u8bc6\u522b\u5173\u952e\u8bbe\u8ba1\u53d8\u91cf\uff0c\u5b9e\u73b0DLD\u8bbe\u5907\u7684\u81ea\u52a8\u5316\u4f18\u5316\u3002", "conclusion": "\u8fd9\u79cd\u96c6\u6210\u65b9\u6cd5\u63a8\u8fdb\u4e86\u53ef\u6269\u5c55\u548c\u7cbe\u786e\u5fae\u6d41\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u4e3a\u764c\u75c7\u65e9\u671f\u68c0\u6d4b\u548c\u4e2a\u6027\u5316\u533b\u7597\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2511.17796", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17796", "abs": "https://arxiv.org/abs/2511.17796", "authors": ["Afsaneh Mahanipour", "Hana Khamfroush"], "title": "Semi-Supervised Federated Multi-Label Feature Selection with Fuzzy Information Measures", "comment": "This paper has been accepted for presentation at GLOBECOM 2025", "summary": "Multi-label feature selection (FS) reduces the dimensionality of multi-label data by removing irrelevant, noisy, and redundant features, thereby boosting the performance of multi-label learning models. However, existing methods typically require centralized data, which makes them unsuitable for distributed and federated environments where each device/client holds its own local dataset. Additionally, federated methods often assume that clients have labeled data, which is unrealistic in cases where clients lack the expertise or resources to label task-specific data. To address these challenges, we propose a Semi-Supervised Federated Multi-Label Feature Selection method, called SSFMLFS, where clients hold only unlabeled data, while the server has limited labeled data. SSFMLFS adapts fuzzy information theory to a federated setting, where clients compute fuzzy similarity matrices and transmit them to the server, which then calculates feature redundancy and feature-label relevancy degrees. A feature graph is constructed by modeling features as vertices, assigning relevancy and redundancy degrees as vertex weights and edge weights, respectively. PageRank is then applied to rank the features by importance. Extensive experiments on five real-world datasets from various domains, including biology, images, music, and text, demonstrate that SSFMLFS outperforms other federated and centralized supervised and semi-supervised approaches in terms of three different evaluation metrics in non-IID data distribution setting.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u8054\u90a6\u591a\u6807\u7b7e\u7279\u5f81\u9009\u62e9\u65b9\u6cd5SSFMLFS\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u5ba2\u6237\u7aef\u53ea\u6709\u672a\u6807\u8bb0\u6570\u636e\u800c\u670d\u52a1\u5668\u6709\u5c11\u91cf\u6807\u8bb0\u6570\u636e\u7684\u573a\u666f\uff0c\u901a\u8fc7\u6a21\u7cca\u4fe1\u606f\u7406\u8bba\u548cPageRank\u7b97\u6cd5\u8fdb\u884c\u7279\u5f81\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u591a\u6807\u7b7e\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u9700\u8981\u96c6\u4e2d\u5f0f\u6570\u636e\uff0c\u4e0d\u9002\u5408\u5206\u5e03\u5f0f\u548c\u8054\u90a6\u73af\u5883\uff1b\u4e14\u8054\u90a6\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5ba2\u6237\u7aef\u6709\u6807\u8bb0\u6570\u636e\uff0c\u8fd9\u5728\u5ba2\u6237\u7aef\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\u6216\u8d44\u6e90\u65f6\u662f\u4e0d\u73b0\u5b9e\u7684\u3002", "method": "SSFMLFS\u65b9\u6cd5\uff1a\u5ba2\u6237\u7aef\u8ba1\u7b97\u6a21\u7cca\u76f8\u4f3c\u77e9\u9635\u5e76\u4f20\u8f93\u7ed9\u670d\u52a1\u5668\uff0c\u670d\u52a1\u5668\u8ba1\u7b97\u7279\u5f81\u5197\u4f59\u5ea6\u548c\u7279\u5f81-\u6807\u7b7e\u76f8\u5173\u6027\u5ea6\uff0c\u6784\u5efa\u7279\u5f81\u56fe\uff08\u7279\u5f81\u4e3a\u9876\u70b9\uff0c\u76f8\u5173\u6027\u548c\u5197\u4f59\u5ea6\u4e3a\u6743\u91cd\uff09\uff0c\u5e94\u7528PageRank\u7b97\u6cd5\u5bf9\u7279\u5f81\u91cd\u8981\u6027\u8fdb\u884c\u6392\u5e8f\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff08\u751f\u7269\u5b66\u3001\u56fe\u50cf\u3001\u97f3\u4e50\u3001\u6587\u672c\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u975eIID\u6570\u636e\u5206\u5e03\u8bbe\u7f6e\u4e0b\uff0cSSFMLFS\u5728\u4e09\u79cd\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u8054\u90a6\u548c\u96c6\u4e2d\u5f0f\u76d1\u7763\u53ca\u534a\u76d1\u7763\u65b9\u6cd5\u3002", "conclusion": "SSFMLFS\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u73af\u5883\u4e2d\u5ba2\u6237\u7aef\u53ea\u6709\u672a\u6807\u8bb0\u6570\u636e\u7684\u591a\u6807\u7b7e\u7279\u5f81\u9009\u62e9\u95ee\u9898\uff0c\u5728\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.17801", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17801", "abs": "https://arxiv.org/abs/2511.17801", "authors": ["Cuong Pham", "Hoang Anh Dung", "Cuong C. Nguyen", "Trung Le", "Gustavo Carneiro", "Thanh-Toan Do"], "title": "Layer-Wise High-Impact Parameter Ratio Optimization in Post-Training Quantization for Large Language Models", "comment": null, "summary": "Large language models (LLMs) have significantly advanced natural language processing, but their massive parameter counts create substantial computational and memory challenges during deployment. Post-training quantization (PTQ) has emerged as a promising approach to mitigate these challenges with minimal overhead. While existing PTQ methods can effectively quantize LLMs, they experience substantial accuracy loss at extremely low bit-widths, primarily due to high-impact parameters that significantly influence quantization performance. Several approaches address these issues by identifying and retaining the high-impact parameters in FP16 format. However, they apply fixed ratios of high-impact parameters across all layers, overlooking layer-wise sensitivity variations. In this paper, we propose a quadratic optimization framework that determines layer-specific ratios of high-impact parameters while considering inter-layer dependencies. We quantize high-impact parameters to moderate bit-widths, which often result in negligible performance degradation in quantized LLMs, while the remaining parameters can be quantized to extremely low bit-widths. Under the same resource-constrained budget, this allows for preserving more high-impact parameters than methods that keep selecting a few in FP16 format. Additionally, the proposed framework allows us to leverage an advanced quantization method that often requires extensive learnable parameters solely for high-impact parameters, while applying a computationally efficient method to the rest. Our approach achieves an effective balance between computational efficiency and model accuracy while maintaining high performance compared to state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e8c\u6b21\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u786e\u5b9a\u5c42\u7279\u5b9a\u7684\u9ad8\u5f71\u54cd\u53c2\u6570\u6bd4\u4f8b\uff0c\u8003\u8651\u5c42\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u9884\u7b97\u4e0b\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\u548c\u6a21\u578b\u7cbe\u5ea6\u7684\u5e73\u8861\u3002", "motivation": "\u73b0\u6709PTQ\u65b9\u6cd5\u5728\u6781\u4f4e\u4f4d\u5bbd\u4e0b\u7cbe\u5ea6\u635f\u5931\u4e25\u91cd\uff0c\u4e3b\u8981\u7531\u4e8e\u9ad8\u5f71\u54cd\u53c2\u6570\u5bf9\u91cf\u5316\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u5bf9\u6240\u6709\u5c42\u4f7f\u7528\u56fa\u5b9a\u6bd4\u4f8b\u7684\u9ad8\u5f71\u54cd\u53c2\u6570\uff0c\u5ffd\u7565\u4e86\u5c42\u95f4\u654f\u611f\u6027\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u4e8c\u6b21\u4f18\u5316\u6846\u67b6\u786e\u5b9a\u5c42\u7279\u5b9a\u7684\u9ad8\u5f71\u54cd\u53c2\u6570\u6bd4\u4f8b\uff0c\u5c06\u9ad8\u5f71\u54cd\u53c2\u6570\u91cf\u5316\u4e3a\u4e2d\u7b49\u4f4d\u5bbd\uff0c\u5176\u4f59\u53c2\u6570\u91cf\u5316\u4e3a\u6781\u4f4e\u4f4d\u5bbd\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u53c2\u6570\u7c7b\u578b\u5e94\u7528\u4e0d\u540c\u7684\u91cf\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u76f8\u540c\u8d44\u6e90\u7ea6\u675f\u9884\u7b97\u4e0b\uff0c\u6bd4\u4fdd\u6301\u5c11\u91cfFP16\u53c2\u6570\u7684\u65b9\u6cd5\u80fd\u4fdd\u7559\u66f4\u591a\u9ad8\u5f71\u54cd\u53c2\u6570\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u6a21\u578b\u7cbe\u5ea6\u7684\u6709\u6548\u5e73\u8861\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u8ba1\u7b97\u6548\u7387\u4e0e\u6a21\u578b\u7cbe\u5ea6\u5e73\u8861\u3002"}}
{"id": "2511.17809", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17809", "abs": "https://arxiv.org/abs/2511.17809", "authors": ["Cuong Pham", "Hoang Anh Dung", "Cuong C. Nguyen", "Trung Le", "Gustavo Carneiro", "Jianfei Cai", "Thanh-Toan Do"], "title": "Adaptive Layer-Wise Transformations for Post-Training Quantization of Large Language Models", "comment": null, "summary": "Large language models require significant computational resources for deployment, making quantization essential for practical applications. However, the main obstacle to effective quantization lies in systematic outliers in activations and weights, which cause substantial LLM performance degradation, especially at low-bit settings. While existing transformation-based methods like affine and rotation transformations successfully mitigate outliers, they apply the homogeneous transformation setting, i.e., using the same transformation types across all layers, ignoring the heterogeneous distribution characteristics within LLMs. In this paper, we propose an adaptive transformation selection framework that systematically determines optimal transformations on a per-layer basis. To this end, we first formulate transformation selection as a differentiable optimization problem to achieve the accurate transformation type for each layer. However, searching for optimal layer-wise transformations for every model is computationally expensive. To this end, we establish the connection between weight distribution kurtosis and accurate transformation type. Specifically, we propose an outlier-guided layer selection method using robust $z$-score normalization that achieves comparable performance to differentiable search with significantly reduced overhead. Comprehensive experiments on LLaMA family models demonstrate that our adaptive approach consistently outperforms the widely-used fixed transformation settings. For example, our method achieves an improvement of up to 4.58 perplexity points and a 2.11% gain in average six-task zero-shot accuracy under aggressive W3A3K2V2 quantization settings for the LLaMA-3-8B model compared to the current best existing method, FlatQuant, demonstrating the necessity of heterogeneous transformation selection for optimal LLM quantization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u53d8\u6362\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u9010\u5c42\u786e\u5b9a\u6700\u4f18\u53d8\u6362\u6765\u89e3\u51b3LLM\u91cf\u5316\u4e2d\u7684\u7cfb\u7edf\u5f02\u5e38\u503c\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u540c\u8d28\u53d8\u6362\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u91c7\u7528\u540c\u8d28\u53d8\u6362\u8bbe\u7f6e\uff0c\u5ffd\u7565\u4e86LLM\u4e2d\u4e0d\u540c\u5c42\u7684\u5f02\u8d28\u5206\u5e03\u7279\u6027\uff0c\u5bfc\u81f4\u5728\u4f4e\u6bd4\u7279\u8bbe\u7f6e\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u53d8\u6362\u9009\u62e9\u6846\u67b6\uff0c\u5c06\u53d8\u6362\u9009\u62e9\u5236\u5b9a\u4e3a\u53ef\u5fae\u5206\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6743\u91cd\u5206\u5e03\u5cf0\u5ea6\u4e0e\u53d8\u6362\u7c7b\u578b\u7684\u5173\u8054\uff0c\u4f7f\u7528\u57fa\u4e8e\u5f02\u5e38\u503c\u7684\u5c42\u9009\u62e9\u65b9\u6cd5\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728LLaMA\u7cfb\u5217\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728W3A3K2V2\u91cf\u5316\u8bbe\u7f6e\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5FlatQuant\uff0c\u56f0\u60d1\u5ea6\u63d0\u5347\u8fbe4.58\u70b9\uff0c\u516d\u4efb\u52a1\u96f6\u6837\u672c\u51c6\u786e\u7387\u63d0\u53472.11%\u3002", "conclusion": "\u5f02\u8d28\u53d8\u6362\u9009\u62e9\u5bf9\u4f18\u5316LLM\u91cf\u5316\u81f3\u5173\u91cd\u8981\uff0c\u81ea\u9002\u5e94\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u4e0d\u540c\u5c42\u7684\u5206\u5e03\u7279\u6027\uff0c\u663e\u8457\u63d0\u5347\u91cf\u5316\u6027\u80fd\u3002"}}
{"id": "2511.17818", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17818", "abs": "https://arxiv.org/abs/2511.17818", "authors": ["Aishwarya Mandyam", "Kalyani Limaye", "Barbara E. Engelhardt", "Emily Alsentzer"], "title": "APRIL: Annotations for Policy evaluation with Reliable Inference from LLMs", "comment": null, "summary": "Off-policy evaluation (OPE) estimates the value of a contextual bandit policy prior to deployment. As such, OPE plays a critical role in ensuring safety in high-stakes domains such as healthcare. However, standard OPE approaches are limited by the size and coverage of the behavior dataset. While previous work has explored using expert-labeled counterfactual annotations to enhance dataset coverage, obtaining such annotations is expensive, limiting the scalability of prior approaches. We propose leveraging large language models (LLMs) to generate counterfactual annotations for OPE in medical domains. Our method uses domain knowledge to guide LLMs in predicting how key clinical features evolve under alternate treatments. These predicted features can then be transformed using known reward functions to create counterfactual annotations. We first evaluate the ability of several LLMs to predict clinical features across two patient subsets in MIMIC-IV, finding that state-of-the-art LLMs achieve comparable performance. Building on this capacity to predict clinical features, we generate LLM-based counterfactual annotations and incorporate them into an OPE estimator. Our empirical results analyze the benefits of counterfactual annotations under varying degrees of shift between the behavior and target policies. We find that in most cases, the LLM-based counterfactual annotations significantly improve OPE estimates up to a point. We provide an entropy-based metric to identify when additional annotations cease to be useful. Our results demonstrate that LLM-based counterfactual annotations offer a scalable approach for addressing coverage limitations in healthcare datasets, enabling safer deployment of decision-making policies in clinical settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u751f\u6210\u53cd\u4e8b\u5b9e\u6807\u6ce8\u6765\u6539\u8fdb\u533b\u7597\u9886\u57df\u7684\u79bb\u7b56\u7565\u8bc4\u4f30(OPE)\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u96c6\u8986\u76d6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u6807\u51c6OPE\u65b9\u6cd5\u53d7\u9650\u4e8e\u884c\u4e3a\u6570\u636e\u96c6\u7684\u5927\u5c0f\u548c\u8986\u76d6\u8303\u56f4\uff0c\u800c\u4f20\u7edf\u7684\u4eba\u5de5\u4e13\u5bb6\u6807\u6ce8\u53cd\u4e8b\u5b9e\u6ce8\u91ca\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u9700\u8981\u66f4\u5b89\u5168\u7684\u7b56\u7565\u90e8\u7f72\u524d\u8bc4\u4f30\u3002", "method": "\u5229\u7528\u9886\u57df\u77e5\u8bc6\u6307\u5bfcLLMs\u9884\u6d4b\u5728\u66ff\u4ee3\u6cbb\u7597\u4e0b\u5173\u952e\u4e34\u5e8a\u7279\u5f81\u7684\u6f14\u53d8\uff0c\u7136\u540e\u901a\u8fc7\u5df2\u77e5\u5956\u52b1\u51fd\u6570\u5c06\u8fd9\u4e9b\u9884\u6d4b\u7279\u5f81\u8f6c\u5316\u4e3a\u53cd\u4e8b\u5b9e\u6807\u6ce8\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230OPE\u4f30\u8ba1\u5668\u4e2d\u3002", "result": "\u5728MIMIC-IV\u6570\u636e\u96c6\u7684\u4e24\u4e2a\u60a3\u8005\u5b50\u96c6\u4e0a\u8bc4\u4f30\uff0c\u53d1\u73b0\u6700\u5148\u8fdb\u7684LLMs\u5728\u9884\u6d4b\u4e34\u5e8a\u7279\u5f81\u65b9\u9762\u8868\u73b0\u76f8\u5f53\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u57fa\u4e8eLLM\u7684\u53cd\u4e8b\u5b9e\u6807\u6ce8\u663e\u8457\u6539\u5584\u4e86OPE\u4f30\u8ba1\uff0c\u4f46\u5b58\u5728\u6536\u76ca\u9012\u51cf\u70b9\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u53cd\u4e8b\u5b9e\u6807\u6ce8\u4e3a\u533b\u7597\u6570\u636e\u96c6\u7684\u8986\u76d6\u9650\u5236\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u66f4\u5b89\u5168\u5730\u90e8\u7f72\u51b3\u7b56\u7b56\u7565\u3002"}}
{"id": "2511.17822", "categories": ["cs.LG", "cs.DS", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17822", "abs": "https://arxiv.org/abs/2511.17822", "authors": ["Ziyun Chen", "Spencer Compton", "Daniel Kane", "Jerry Li"], "title": "High-Accuracy List-Decodable Mean Estimation", "comment": "Abstract shortened to meet arXiv requirement", "summary": "In list-decodable learning, we are given a set of data points such that an $\u03b1$-fraction of these points come from a nice distribution $D$, for some small $\u03b1\\ll 1$, and the goal is to output a short list of candidate solutions, such that at least one element of this list recovers some non-trivial information about $D$. By now, there is a large body of work on this topic; however, while many algorithms can achieve optimal list size in terms of $\u03b1$, all known algorithms must incur error which decays, in some cases quite poorly, with $1 / \u03b1$. In this paper, we ask if this is inherent: is it possible to trade off list size with accuracy in list-decodable learning? More formally, given $\u03b5> 0$, can we can output a slightly larger list in terms of $\u03b1$ and $\u03b5$, but so that one element of this list has error at most $\u03b5$ with the ground truth? We call this problem high-accuracy list-decodable learning. Our main result is that non-trivial high-accuracy guarantees, both information-theoretically and algorithmically, are possible for the canonical setting of list-decodable mean estimation of identity-covariance Gaussians. Specifically, we demonstrate that there exists a list of candidate means of size at most $L = \\exp \\left( O\\left( \\tfrac{\\log^2 1 / \u03b1}{\u03b5^2} \\right)\\right)$ so that one of the elements of this list has $\\ell_2$ distance at most $\u03b5$ to the true mean. We also design an algorithm that outputs such a list with runtime and sample complexity $n = d^{O(\\log L)} + \\exp \\exp (\\widetilde{O}(\\log L))$. We do so by demonstrating a completely novel proof of identifiability, as well as a new algorithmic way of leveraging this proof without the sum-of-squares hierarchy, which may be of independent technical interest.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5217\u8868\u53ef\u89e3\u7801\u5b66\u4e60\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5728\u5217\u8868\u5927\u5c0f\u548c\u7cbe\u5ea6\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u5728\u9ad8\u65af\u5747\u503c\u4f30\u8ba1\u7684\u7ecf\u5178\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e86\u975e\u5e73\u51e1\u7684\u9ad8\u7cbe\u5ea6\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u5217\u8868\u53ef\u89e3\u7801\u5b66\u4e60\u7b97\u6cd5\u867d\u7136\u80fd\u5b9e\u73b0\u6700\u4f18\u5217\u8868\u5927\u5c0f\uff0c\u4f46\u8bef\u5dee\u968f1/\u03b1\u8870\u51cf\u8f83\u6162\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u589e\u52a0\u5217\u8868\u5927\u5c0f\u6765\u6362\u53d6\u66f4\u9ad8\u7684\u7cbe\u5ea6\uff0c\u5373\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5217\u8868\u53ef\u89e3\u7801\u5b66\u4e60\u3002", "method": "\u901a\u8fc7\u5168\u65b0\u7684\u53ef\u8bc6\u522b\u6027\u8bc1\u660e\u548c\u65e0\u9700\u5e73\u65b9\u548c\u5c42\u6b21\u7ed3\u6784\u7684\u65b0\u7b97\u6cd5\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8f93\u51fa\u5019\u9009\u5747\u503c\u5217\u8868\u7684\u7b97\u6cd5\uff0c\u5176\u4e2d\u4e00\u4e2a\u5143\u7d20\u4e0e\u771f\u5b9e\u5747\u503c\u7684\u2113\u2082\u8ddd\u79bb\u4e0d\u8d85\u8fc7\u03b5\u3002", "result": "\u8bc1\u660e\u4e86\u5b58\u5728\u5927\u5c0f\u4e3aL = exp(O(log\u00b2(1/\u03b1)/\u03b5\u00b2))\u7684\u5019\u9009\u5747\u503c\u5217\u8868\uff0c\u5176\u4e2d\u81f3\u5c11\u4e00\u4e2a\u5143\u7d20\u4e0e\u771f\u5b9e\u5747\u503c\u7684\u8ddd\u79bb\u4e0d\u8d85\u8fc7\u03b5\u3002\u7b97\u6cd5\u7684\u65f6\u95f4\u548c\u6837\u672c\u590d\u6742\u5ea6\u4e3an = d^O(log L) + exp exp(\u00d5(log L))\u3002", "conclusion": "\u5728\u9ad8\u65af\u5747\u503c\u4f30\u8ba1\u7684\u5217\u8868\u53ef\u89e3\u7801\u5b66\u4e60\u4e2d\uff0c\u786e\u5b9e\u53ef\u4ee5\u5728\u5217\u8868\u5927\u5c0f\u548c\u7cbe\u5ea6\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u5b9e\u73b0\u4e86\u975e\u5e73\u51e1\u7684\u9ad8\u7cbe\u5ea6\u4fdd\u8bc1\uff0c\u8fd9\u4e3a\u5217\u8868\u53ef\u89e3\u7801\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.17823", "categories": ["cs.LG", "cs.CE", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17823", "abs": "https://arxiv.org/abs/2511.17823", "authors": ["Naitik Gada"], "title": "A novel k-means clustering approach using two distance measures for Gaussian data", "comment": "Keywords: machine learning, clustering algorithms, k-means", "summary": "Clustering algorithms have long been the topic of research, representing the more popular side of unsupervised learning. Since clustering analysis is one of the best ways to find some clarity and structure within raw data, this paper explores a novel approach to \\textit{k}-means clustering. Here we present a \\textit{k}-means clustering algorithm that takes both the within cluster distance (WCD) and the inter cluster distance (ICD) as the distance metric to cluster the data into \\emph{k} clusters pre-determined by the Calinski-Harabasz criterion in order to provide a more robust output for the clustering analysis. The idea with this approach is that by including both the measurement metrics, the convergence of the data into their clusters becomes solidified and more robust. We run the algorithm with some synthetically produced data and also some benchmark data sets obtained from the UCI repository. The results show that the convergence of the data into their respective clusters is more accurate by using both WCD and ICD measurement metrics. The algorithm is also better at clustering the outliers into their true clusters as opposed to the traditional \\textit{k} means method. We also address some interesting possible research topics that reveal themselves as we answer the questions we initially set out to address.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684k-means\u805a\u7c7b\u7b97\u6cd5\uff0c\u4f7f\u7528\u7c07\u5185\u8ddd\u79bb(WCD)\u548c\u7c07\u95f4\u8ddd\u79bb(ICD)\u4f5c\u4e3a\u8ddd\u79bb\u5ea6\u91cf\uff0c\u901a\u8fc7Calinski-Harabasz\u51c6\u5219\u786e\u5b9a\u6700\u4f73k\u503c\uff0c\u4ee5\u63d0\u9ad8\u805a\u7c7b\u5206\u6790\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edfk-means\u805a\u7c7b\u7b97\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7ed3\u5408WCD\u548cICD\u4e24\u79cd\u8ddd\u79bb\u5ea6\u91cf\u6765\u589e\u5f3a\u6570\u636e\u5411\u5404\u81ea\u7c07\u7684\u6536\u655b\u6027\uff0c\u4f7f\u805a\u7c7b\u7ed3\u679c\u66f4\u52a0\u7a33\u5065\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684k-means\u805a\u7c7b\u7b97\u6cd5\uff0c\u540c\u65f6\u8003\u8651\u7c07\u5185\u8ddd\u79bb\u548c\u7c07\u95f4\u8ddd\u79bb\u4f5c\u4e3a\u8ddd\u79bb\u5ea6\u91cf\uff0c\u4f7f\u7528Calinski-Harabasz\u51c6\u5219\u81ea\u52a8\u786e\u5b9a\u6700\u4f73\u805a\u7c7b\u6570\u91cfk\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548cUCI\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528WCD\u548cICD\u5ea6\u91cf\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6536\u655b\u5230\u5404\u81ea\u7684\u7c07\uff0c\u5e76\u4e14\u5728\u5904\u7406\u5f02\u5e38\u503c\u65b9\u9762\u4f18\u4e8e\u4f20\u7edfk-means\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408WCD\u548cICD\u7684k-means\u805a\u7c7b\u7b97\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u805a\u7c7b\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5f02\u5e38\u503c\u548c\u63d0\u9ad8\u805a\u7c7b\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.17826", "categories": ["cs.LG", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17826", "abs": "https://arxiv.org/abs/2511.17826", "authors": ["Ziyang Zhang", "Xinheng Ding", "Jiayi Yuan", "Rixin Liu", "Huizi Mao", "Jiarong Xing", "Zirui Liu"], "title": "Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch", "comment": null, "summary": "Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Tree-Based Invariant Kernels (TBIK)\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u5f20\u91cf\u5e76\u884c\u89c4\u6a21\u5bfc\u81f4\u7684\u975e\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u5728\u4e0d\u540cTP\u914d\u7f6e\u4e0b\u83b7\u5f97\u6bd4\u7279\u7ea7\u76f8\u540c\u7684\u63a8\u7406\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709LLM\u670d\u52a1\u6846\u67b6\u5728\u5f20\u91cf\u5e76\u884c\u89c4\u6a21\u53d8\u5316\u65f6\u4f1a\u4ea7\u751f\u975e\u786e\u5b9a\u6027\u884c\u4e3a\uff0c\u8fd9\u5728LLM-as-a-judge\u8bc4\u4f30\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u5f3a\u5316\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\u4f1a\u9020\u6210\u4e25\u91cd\u95ee\u9898\uff0c\u7279\u522b\u662fRL\u8bad\u7ec3\u4e2d\u8bad\u7ec3\u5f15\u64ce\u548c\u63a8\u7406\u5f15\u64ce\u7684\u5e76\u884c\u7b56\u7565\u4e0d\u5339\u914d\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u751a\u81f3\u5d29\u6e83\u3002", "method": "\u901a\u8fc7\u5206\u6790TP\u8bf1\u5bfc\u4e0d\u4e00\u81f4\u6027\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7edf\u4e00\u5c42\u6b21\u4e8c\u53c9\u6811\u7ed3\u6784\u7684TP\u4e0d\u53d8\u77e9\u9635\u4e58\u6cd5\u548c\u89c4\u7ea6\u539f\u8bed(TBIK)\uff0c\u5bf9\u9f50GPU\u5185\u548cGPU\u95f4\u7684\u89c4\u7ea6\u987a\u5e8f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u5728\u4e0d\u540cTP\u89c4\u6a21\u4e0b\u5b9e\u73b0\u4e86\u96f6\u6982\u7387\u53d1\u6563\u548c\u6bd4\u7279\u7ea7\u53ef\u590d\u73b0\u6027\uff0c\u5728vLLM\u548cFSDP\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6bd4\u7279\u7ea7\u76f8\u540c\u7684RL\u8bad\u7ec3\u7ed3\u679c\u3002", "conclusion": "TBIK\u6709\u6548\u89e3\u51b3\u4e86LLM\u63a8\u7406\u4e2d\u7684TP\u89c4\u6a21\u76f8\u5173\u975e\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u786e\u5b9a\u6027\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u9760\u4fdd\u969c\u3002"}}
{"id": "2511.17829", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17829", "abs": "https://arxiv.org/abs/2511.17829", "authors": ["Akhil Singampalli", "Sudeep Pasricha"], "title": "Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor Localization", "comment": null, "summary": "Indoor localization using machine learning has gained traction due to the growing demand for location-based services. However, its long-term reliability is hindered by hardware/software variations across mobile devices, which shift the model's input distribution to create domain shifts. Further, evolving indoor environments can introduce new locations over time, expanding the output space to create class shifts, making static machine learning models ineffective over time. To address these challenges, we propose a novel unified continual learning framework for indoor localization called MOELO that, for the first time, jointly addresses domain-incremental and class-incremental learning scenarios. MOELO enables a lightweight, robust, and adaptive localization solution that can be deployed on resource-limited mobile devices and is capable of continual learning in dynamic, heterogeneous real-world settings. This is made possible by a mixture-of-experts architecture, where experts are incrementally trained per region and selected through an equiangular tight frame based gating mechanism ensuring efficient routing, and low-latency inference, all within a compact model footprint. Experimental evaluations show that MOELO achieves improvements of up to 25.6x in mean localization error, 44.5x in worst-case localization error, and 21.5x lesser forgetting compared to state-of-the-art frameworks across diverse buildings, mobile devices, and learning scenarios.", "AI": {"tldr": "MOELO\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u9996\u6b21\u8054\u5408\u89e3\u51b3\u5ba4\u5185\u5b9a\u4f4d\u4e2d\u7684\u9886\u57df\u589e\u91cf\u5b66\u4e60\u548c\u7c7b\u522b\u589e\u91cf\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u3001\u9c81\u68d2\u4e14\u81ea\u9002\u5e94\u7684\u5b9a\u4f4d\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u5ba4\u5185\u5b9a\u4f4d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u786c\u4ef6/\u8f6f\u4ef6\u53d8\u5316\u5bfc\u81f4\u7684\u9886\u57df\u504f\u79fb\u548c\u73af\u5883\u6f14\u53d8\u5e26\u6765\u7684\u7c7b\u522b\u504f\u79fb\u95ee\u9898\uff0c\u9759\u6001\u6a21\u578b\u5728\u957f\u671f\u4f7f\u7528\u4e2d\u6548\u679c\u4e0b\u964d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u6309\u533a\u57df\u589e\u91cf\u8bad\u7ec3\u4e13\u5bb6\uff0c\u901a\u8fc7\u7b49\u89d2\u7d27\u6846\u67b6\u95e8\u63a7\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u8def\u7531\u548c\u4f4e\u5ef6\u8fdf\u63a8\u7406\uff0c\u4fdd\u6301\u7d27\u51d1\u6a21\u578b\u5c3a\u5bf8\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0cMOELO\u5728\u5e73\u5747\u5b9a\u4f4d\u8bef\u5dee\u4e0a\u63d0\u534725.6\u500d\uff0c\u6700\u5dee\u60c5\u51b5\u5b9a\u4f4d\u8bef\u5dee\u63d0\u534744.5\u500d\uff0c\u9057\u5fd8\u7387\u964d\u4f4e21.5\u500d\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6846\u67b6\u3002", "conclusion": "MOELO\u4e3a\u8d44\u6e90\u53d7\u9650\u79fb\u52a8\u8bbe\u5907\u63d0\u4f9b\u4e86\u53ef\u5728\u52a8\u6001\u5f02\u6784\u73b0\u5b9e\u73af\u5883\u4e2d\u6301\u7eed\u5b66\u4e60\u7684\u8f7b\u91cf\u7ea7\u5b9a\u4f4d\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17840", "categories": ["cs.LG", "math.CT"], "pdf": "https://arxiv.org/pdf/2511.17840", "abs": "https://arxiv.org/abs/2511.17840", "authors": ["Tony Shaska"], "title": "Internalizing Tools as Morphisms in Graded Transformers", "comment": null, "summary": "We introduce a graded formulation of internal symbolic computation for transformers. The hidden space is endowed with a grading $V=\\bigoplus_{g\\in G}V_g$, and symbolic operations are realized as typed block maps (morphisms) $\u03c6_{h\\leftarrow g}:V_g\\to V_h$ that are activated selectively by a differentiable routing policy. A self-supervised \\emph{graded utility functional}, defined as the loss reduction induced by a candidate morphism, governs activation and yields sparse, interpretable behavior. We develop the algebraic and geometric foundations: an internal model category whose objects are homogeneous components and whose morphisms are admissible grade transitions; adjoint pairs encoding typed round trips; and information-geometric interpretations in terms of KL gain, mirror descent with Bregman divergences, and Fisher natural gradients. Methodologically, we specify a utility--aware routing mechanism and objective that remain fully end-to-end differentiable. Analytic case studies and lightweight sanity checks illustrate selective morphic activation on hybrid symbolic-linguistic tasks. The framework unifies symbolic computation, geometry, and self--supervised learning within the \\emph{graded transformer} formalism \\cite{sh-89,sh-95}, while subsuming prior external-tool paradigms (e.g., Toolformer \\cite{toolformer2023}) as a special case via functorial internalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7ea7\u7684\u5185\u90e8\u7b26\u53f7\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u7684\u5757\u6620\u5c04\u5b9e\u73b0\u7b26\u53f7\u64cd\u4f5c\uff0c\u4f7f\u7528\u53ef\u5fae\u8def\u7531\u7b56\u7565\u548c\u81ea\u76d1\u7763\u7684\u6548\u7528\u51fd\u6570\u6765\u63a7\u5236\u6fc0\u6d3b\uff0c\u4ea7\u751f\u7a00\u758f\u4e14\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\u3002", "motivation": "\u7edf\u4e00\u7b26\u53f7\u8ba1\u7b97\u3001\u51e0\u4f55\u548c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u5c06\u5916\u90e8\u5de5\u5177\u8303\u5f0f\uff08\u5982Toolformer\uff09\u4f5c\u4e3a\u7279\u4f8b\u901a\u8fc7\u51fd\u5b50\u5185\u5316\u7eb3\u5165\u5206\u7ea7\u7684transformer\u5f62\u5f0f\u4f53\u7cfb\u3002", "method": "\u5728\u9690\u85cf\u7a7a\u95f4\u4e2d\u5f15\u5165\u5206\u7ea7\u7ed3\u6784\uff0c\u7b26\u53f7\u64cd\u4f5c\u5b9e\u73b0\u4e3a\u7c7b\u578b\u5316\u5757\u6620\u5c04\uff0c\u901a\u8fc7\u53ef\u5fae\u8def\u7531\u673a\u5236\u548c\u81ea\u76d1\u7763\u7684\u6548\u7528\u51fd\u6570\u63a7\u5236\u6fc0\u6d3b\u3002", "result": "\u5f00\u53d1\u4e86\u4ee3\u6570\u51e0\u4f55\u57fa\u7840\uff0c\u5305\u62ec\u5185\u90e8\u6a21\u578b\u8303\u7574\u3001\u4f34\u968f\u5bf9\u548c\u4fe1\u606f\u51e0\u4f55\u89e3\u91ca\uff0c\u5728\u6df7\u5408\u7b26\u53f7-\u8bed\u8a00\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u9009\u62e9\u6027\u5f62\u6001\u6fc0\u6d3b\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5206\u7ea7transformer\u5f62\u5f0f\u4f53\u7cfb\u5185\u7edf\u4e00\u4e86\u7b26\u53f7\u8ba1\u7b97\u3001\u51e0\u4f55\u548c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u540c\u65f6\u5c06\u5916\u90e8\u5de5\u5177\u8303\u5f0f\u4f5c\u4e3a\u7279\u4f8b\u5305\u542b\u5728\u5185\u3002"}}
{"id": "2511.17852", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17852", "abs": "https://arxiv.org/abs/2511.17852", "authors": ["Bochen Lyu", "Yiyang Jia", "Xiaohao Cai", "Zhanxing Zhu"], "title": "Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But Differently", "comment": "43 pages, 5 figures", "summary": "Transformers can acquire Chain-of-Thought (CoT) capabilities to solve complex reasoning tasks through fine-tuning. Reinforcement learning (RL) and supervised fine-tuning (SFT) are two primary approaches to this end, yet their underlying mechanisms and differences remain theoretically unclear. In this work, we examine these aspects specifically for learning $k$-sparse Boolean functions with a one-layer transformer and intermediate supervision that is akin to CoT. In particular, we consider $k$-sparse Boolean functions that can be recursively decomposed into fixed 2-sparse Boolean functions. We analyze the learning dynamics of fine-tuning the transformer via either RL or SFT with CoT to identify sufficient conditions for it to provably learn these functions. We verify that these conditions hold for three basic examples, including $k$-PARITY, $k$-AND, and $k$-OR, thus demonstrating the learnability of both approaches. Notably, we reveal that RL and SFT exhibit distinct learning behaviors: RL learns the whole CoT chain simultaneously, whereas SFT learns the CoT chain step-by-step. Overall, our findings provide theoretical insights into the underlying mechanisms of RL and SFT as well as how they differ in triggering the CoT capabilities of transformers.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86Transformer\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60(RL)\u548c\u76d1\u7763\u5fae\u8c03(SFT)\u5b66\u4e60\u94fe\u5f0f\u601d\u7ef4(CoT)\u80fd\u529b\u7684\u7406\u8bba\u673a\u5236\uff0c\u7279\u522b\u9488\u5bf9k\u7a00\u758f\u5e03\u5c14\u51fd\u6570\u7684\u5b66\u4e60\uff0c\u63ed\u793a\u4e86RL\u548cSFT\u5728\u5b66\u4e60\u884c\u4e3a\u4e0a\u7684\u5173\u952e\u5dee\u5f02\u3002", "motivation": "\u867d\u7136RL\u548cSFT\u90fd\u80fd\u8ba9Transformer\u83b7\u5f97CoT\u80fd\u529b\u6765\u89e3\u51b3\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff0c\u4f46\u5b83\u4eec\u7684\u57fa\u672c\u673a\u5236\u548c\u5dee\u5f02\u5728\u7406\u8bba\u4e0a\u4ecd\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7406\u8bba\u5206\u6790\u3002", "method": "\u4f7f\u7528\u5355\u5c42Transformer\u548c\u4e2d\u95f4\u76d1\u7763\u6765\u5b66\u4e60\u53ef\u9012\u5f52\u5206\u89e3\u4e3a\u56fa\u5b9a2\u7a00\u758f\u5e03\u5c14\u51fd\u6570\u7684k\u7a00\u758f\u5e03\u5c14\u51fd\u6570\uff0c\u5206\u6790RL\u548cSFT\u7684\u5fae\u8c03\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u9a8c\u8bc1\u5728k-PARITY\u3001k-AND\u548ck-OR\u4e09\u4e2a\u57fa\u672c\u793a\u4f8b\u4e0a\u7684\u9002\u7528\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u5b66\u4e60\u8fd9\u4e9b\u51fd\u6570\uff0c\u4f46RL\u540c\u65f6\u5b66\u4e60\u6574\u4e2aCoT\u94fe\uff0c\u800cSFT\u9010\u6b65\u5b66\u4e60CoT\u94fe\uff0c\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u5b66\u4e60\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3RL\u548cSFT\u89e6\u53d1Transformer CoT\u80fd\u529b\u7684\u57fa\u672c\u673a\u5236\u53ca\u5176\u5dee\u5f02\u63d0\u4f9b\u4e86\u7406\u8bba\u89c1\u89e3\u3002"}}
{"id": "2511.17861", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17861", "abs": "https://arxiv.org/abs/2511.17861", "authors": ["Xuesong Jia", "Yuanjie Shi", "Ziquan Liu", "Yi Xu", "Yan Yan"], "title": "Cost-Sensitive Conformal Training with Provably Controllable Learning Bounds", "comment": "Accepted for Publication at Association for the Advancement of Artificial Intelligence (AAAI), 2026", "summary": "Conformal prediction (CP) is a general framework to quantify the predictive uncertainty of machine learning models that uses a set prediction to include the true label with a valid probability. To align the uncertainty measured by CP, conformal training methods minimize the size of the prediction sets. A typical way is to use a surrogate indicator function, usually Sigmoid or Gaussian error function. However, these surrogate functions do not have a uniform error bound to the indicator function, leading to uncontrollable learning bounds. In this paper, we propose a simple cost-sensitive conformal training algorithm that does not rely on the indicator approximation mechanism. Specifically, we theoretically show that minimizing the expected size of prediction sets is upper bounded by the expected rank of true labels. To this end, we develop a rank weighting strategy that assigns the weight using the rank of true label on each data sample. Our analysis provably demonstrates the tightness between the proposed weighted objective and the expected size of conformal prediction sets. Extensive experiments verify the validity of our theoretical insights, and superior empirical performance over other conformal training in terms of predictive efficiency with 21.38% reduction for average prediction set size.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u6210\u672c\u654f\u611f\u5171\u5f62\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u771f\u5b9e\u6807\u7b7e\u7684\u6392\u540d\u6765\u52a0\u6743\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u6307\u793a\u51fd\u6570\u8fd1\u4f3c\u673a\u5236\u7684\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9884\u6d4b\u96c6\u5927\u5c0f\u3002", "motivation": "\u4f20\u7edf\u5171\u5f62\u8bad\u7ec3\u65b9\u6cd5\u4f7f\u7528Sigmoid\u6216\u9ad8\u65af\u8bef\u5dee\u51fd\u6570\u4f5c\u4e3a\u6307\u793a\u51fd\u6570\u7684\u66ff\u4ee3\uff0c\u4f46\u8fd9\u4e9b\u66ff\u4ee3\u51fd\u6570\u6ca1\u6709\u7edf\u4e00\u7684\u8bef\u5dee\u754c\u9650\uff0c\u5bfc\u81f4\u5b66\u4e60\u8fb9\u754c\u4e0d\u53ef\u63a7\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u672c\u654f\u611f\u5171\u5f62\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u6700\u5c0f\u5316\u9884\u6d4b\u96c6\u671f\u671b\u5927\u5c0f\u53d7\u771f\u5b9e\u6807\u7b7e\u671f\u671b\u6392\u540d\u7684\u4e0a\u754c\u7ea6\u675f\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8e\u771f\u5b9e\u6807\u7b7e\u6392\u540d\u7684\u6743\u91cd\u5206\u914d\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u6709\u6548\u6027\uff0c\u5728\u9884\u6d4b\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u5171\u5f62\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e73\u5747\u9884\u6d4b\u96c6\u5927\u5c0f\u51cf\u5c11\u4e8621.38%\u3002", "conclusion": "\u63d0\u51fa\u7684\u52a0\u6743\u76ee\u6807\u4e0e\u5171\u5f62\u9884\u6d4b\u96c6\u671f\u671b\u5927\u5c0f\u4e4b\u95f4\u5b58\u5728\u7d27\u5bc6\u8054\u7cfb\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63a7\u5236\u9884\u6d4b\u96c6\u5927\u5c0f\u5e76\u63d0\u9ad8\u9884\u6d4b\u6548\u7387\u3002"}}
{"id": "2511.17864", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17864", "abs": "https://arxiv.org/abs/2511.17864", "authors": ["Adrian Goldwaser", "Michael Munn", "Javier Gonzalvo", "Benoit Dherin"], "title": "Equivalence of Context and Parameter Updates in Modern Transformer Blocks", "comment": null, "summary": "Recent research has established that the impact of context in a vanilla transformer can be represented implicitly by forming a token-dependent, rank-1 patch to its MLP weights. This work extends that foundational theory to the diverse architectures of modern Large Language Models. We first demonstrate a precise, analytical solution for a Gemma-style transformer block, proving that the entire effect of a context can be perfectly mapped to rank-1 patches on its MLP weight matrices and a patch to the RMSNorm scale. We then generalize this result, providing a constructive proof and algorithm for multi-layer models. To unify these findings, we introduce a general framework centered on two core properties: input controllability and output controllability. We prove that a perfect implicit weight patch is possible for any MLP block where the inner function is input-controllable and the outer function is output-controllable. This provides a simpler and more powerful lens for understanding how transformer models transmute prompts into effective weights. This setup generalizes to a wide range of modern LLM architectures including gating, pre-/post-norm, mixture of experts and sequential/parallel transformer blocks.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86transformer\u4e2d\u4e0a\u4e0b\u6587\u5f71\u54cd\u7684\u7406\u8bba\uff0c\u8bc1\u660e\u5728\u73b0\u4ee3LLM\u67b6\u6784\u4e2d\uff0c\u4e0a\u4e0b\u6587\u6548\u679c\u53ef\u4ee5\u5b8c\u7f8e\u6620\u5c04\u4e3aMLP\u6743\u91cd\u7684rank-1\u8865\u4e01\u548cRMSNorm\u5c3a\u5ea6\u8865\u4e01\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u8f93\u5165\u53ef\u63a7\u6027\u548c\u8f93\u51fa\u53ef\u63a7\u6027\u7684\u901a\u7528\u6846\u67b6\u3002", "motivation": "\u6269\u5c55\u57fa\u7840\u7406\u8bba\u5230\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6837\u5316\u67b6\u6784\uff0c\u7edf\u4e00\u7406\u89e3transformer\u5982\u4f55\u5c06\u63d0\u793a\u8f6c\u6362\u4e3a\u6709\u6548\u6743\u91cd\u3002", "method": "\u9996\u5148\u4e3aGemma\u98ce\u683ctransformer\u5757\u63d0\u4f9b\u7cbe\u786e\u89e3\u6790\u89e3\uff0c\u7136\u540e\u63a8\u5e7f\u5230\u591a\u5c42\u6a21\u578b\uff0c\u63d0\u51fa\u57fa\u4e8e\u8f93\u5165\u53ef\u63a7\u6027\u548c\u8f93\u51fa\u53ef\u63a7\u6027\u7684\u901a\u7528\u6846\u67b6\u548c\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u5b8c\u7f8e\u9690\u5f0f\u6743\u91cd\u8865\u4e01\u5728\u4efb\u4f55MLP\u5757\u4e2d\u90fd\u662f\u53ef\u80fd\u7684\uff0c\u524d\u63d0\u662f\u5185\u90e8\u51fd\u6570\u8f93\u5165\u53ef\u63a7\u4e14\u5916\u90e8\u51fd\u6570\u8f93\u51fa\u53ef\u63a7\uff0c\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u5305\u62ec\u95e8\u63a7\u3001\u9884/\u540e\u89c4\u8303\u3001\u4e13\u5bb6\u6df7\u5408\u548c\u987a\u5e8f/\u5e76\u884ctransformer\u5757\u7b49\u591a\u79cd\u67b6\u6784\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u7b80\u5355\u5f3a\u5927\u7684\u89c6\u89d2\u6765\u7406\u89e3transformer\u6a21\u578b\u5982\u4f55\u5c06\u63d0\u793a\u8f6c\u6362\u4e3a\u6709\u6548\u6743\u91cd\uff0c\u8be5\u6846\u67b6\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u73b0\u4ee3LLM\u67b6\u6784\u3002"}}
{"id": "2511.17936", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17936", "abs": "https://arxiv.org/abs/2511.17936", "authors": ["Wenzhang Du"], "title": "Mitigating Catastrophic Forgetting in Streaming Generative and Predictive Learning via Stateful Replay", "comment": "11 pages, 4 figures", "summary": "Many deployed learning systems must update models on streaming data under memory constraints. The default strategy, sequential fine-tuning on each new phase, is architecture-agnostic but often suffers catastrophic forgetting when later phases correspond to different sub-populations or tasks. Replay with a finite buffer is a simple alternative, yet its behaviour across generative and predictive objectives is not well understood. We present a unified study of stateful replay for streaming autoencoding, time series forecasting, and classification. We view both sequential fine-tuning and replay as stochastic gradient methods for an ideal joint objective, and use a gradient alignment analysis to show when mixing current and historical samples should reduce forgetting. We then evaluate a single replay mechanism on six streaming scenarios built from Rotated MNIST, ElectricityLoadDiagrams 2011-2014, and Airlines delay data, using matched training budgets and three seeds. On heterogeneous multi task streams, replay reduces average forgetting by a factor of two to three, while on benign time based streams both methods perform similarly. These results position stateful replay as a strong and simple baseline for continual learning in streaming environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5185\u5b58\u7ea6\u675f\u4e0b\u6d41\u6570\u636e\u5b66\u4e60\u7cfb\u7edf\u7684\u6a21\u578b\u66f4\u65b0\u7b56\u7565\uff0c\u6bd4\u8f83\u4e86\u987a\u5e8f\u5fae\u8c03\u548c\u91cd\u653e\u65b9\u6cd5\u5728\u751f\u6210\u5f0f\u548c\u9884\u6d4b\u5f0f\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u91cd\u653e\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u6d41\u4e2d\u80fd\u663e\u8457\u51cf\u5c11\u9057\u5fd8\u3002", "motivation": "\u90e8\u7f72\u7684\u5b66\u4e60\u7cfb\u7edf\u9700\u8981\u5728\u5185\u5b58\u9650\u5236\u4e0b\u5bf9\u6d41\u6570\u636e\u66f4\u65b0\u6a21\u578b\uff0c\u987a\u5e8f\u5fae\u8c03\u65b9\u6cd5\u5bb9\u6613\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\uff0c\u800c\u6709\u9650\u7f13\u51b2\u533a\u7684\u91cd\u653e\u65b9\u6cd5\u5728\u4e0d\u540c\u76ee\u6807\u4e0b\u7684\u884c\u4e3a\u5c1a\u672a\u5145\u5206\u7406\u89e3\u3002", "method": "\u5c06\u987a\u5e8f\u5fae\u8c03\u548c\u91cd\u653e\u89c6\u4e3a\u7406\u60f3\u8054\u5408\u76ee\u6807\u7684\u968f\u673a\u68af\u5ea6\u65b9\u6cd5\uff0c\u4f7f\u7528\u68af\u5ea6\u5bf9\u9f50\u5206\u6790\u6765\u7814\u7a76\u6df7\u5408\u5f53\u524d\u548c\u5386\u53f2\u6837\u672c\u4f55\u65f6\u80fd\u51cf\u5c11\u9057\u5fd8\uff0c\u5e76\u5728\u516d\u4e2a\u6d41\u573a\u666f\u4e2d\u8bc4\u4f30\u5355\u4e00\u91cd\u653e\u673a\u5236\u3002", "result": "\u5728\u5f02\u6784\u591a\u4efb\u52a1\u6d41\u4e2d\uff0c\u91cd\u653e\u5c06\u5e73\u5747\u9057\u5fd8\u51cf\u5c112-3\u500d\uff1b\u5728\u826f\u6027\u65f6\u95f4\u6d41\u4e2d\uff0c\u4e24\u79cd\u65b9\u6cd5\u8868\u73b0\u76f8\u4f3c\u3002", "conclusion": "\u72b6\u6001\u91cd\u653e\u662f\u6d41\u73af\u5883\u4e2d\u6301\u7eed\u5b66\u4e60\u7684\u5f3a\u5927\u7b80\u5355\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2511.17953", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17953", "abs": "https://arxiv.org/abs/2511.17953", "authors": ["Min Woo Park", "Sanghack Lee"], "title": "On Transportability for Structural Causal Bandits", "comment": null, "summary": "Intelligent agents equipped with causal knowledge can optimize their action spaces to avoid unnecessary exploration. The structural causal bandit framework provides a graphical characterization for identifying actions that are unable to maximize rewards by leveraging prior knowledge of the underlying causal structure. While such knowledge enables an agent to estimate the expected rewards of certain actions based on others in online interactions, there has been little guidance on how to transfer information inferred from arbitrary combinations of datasets collected under different conditions -- observational or experimental -- and from heterogeneous environments. In this paper, we investigate the structural causal bandit with transportability, where priors from the source environments are fused to enhance learning in the deployment setting. We demonstrate that it is possible to exploit invariances across environments to consistently improve learning. The resulting bandit algorithm achieves a sub-linear regret bound with an explicit dependence on informativeness of prior data, and it may outperform standard bandit approaches that rely solely on online learning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5177\u6709\u53ef\u8fc1\u79fb\u6027\u7684\u7ed3\u6784\u56e0\u679c\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u901a\u8fc7\u878d\u5408\u6765\u81ea\u6e90\u73af\u5883\u7684\u5148\u9a8c\u77e5\u8bc6\u6765\u589e\u5f3a\u90e8\u7f72\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u6784\u56e0\u679c\u8d4c\u535a\u673a\u6846\u67b6\u867d\u7136\u80fd\u5229\u7528\u56e0\u679c\u7ed3\u6784\u77e5\u8bc6\u4f18\u5316\u52a8\u4f5c\u7a7a\u95f4\uff0c\u4f46\u7f3a\u4e4f\u4ece\u4e0d\u540c\u6761\u4ef6\u4e0b\u6536\u96c6\u7684\u6570\u636e\u96c6\uff08\u89c2\u6d4b\u6216\u5b9e\u9a8c\uff09\u548c\u5f02\u6784\u73af\u5883\u4e2d\u8fc1\u79fb\u4fe1\u606f\u7684\u6307\u5bfc\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u56e0\u679c\u8d4c\u535a\u673a\u4e0e\u53ef\u8fc1\u79fb\u6027\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u8de8\u73af\u5883\u7684\u4e0d\u53d8\u6027\uff0c\u5c06\u6e90\u73af\u5883\u7684\u5148\u9a8c\u77e5\u8bc6\u878d\u5408\u5230\u90e8\u7f72\u73af\u5883\u4e2d\u3002", "result": "\u5f00\u53d1\u51fa\u7684\u8d4c\u535a\u673a\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6b21\u7ebf\u6027\u9057\u61be\u754c\uff0c\u660e\u786e\u4f9d\u8d56\u4e8e\u5148\u9a8c\u6570\u636e\u7684\u4fe1\u606f\u91cf\uff0c\u53ef\u80fd\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u5728\u7ebf\u5b66\u4e60\u7684\u6807\u51c6\u8d4c\u535a\u673a\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u8de8\u73af\u5883\u7684\u4e0d\u53d8\u6027\uff0c\u53ef\u4ee5\u6301\u7eed\u6539\u8fdb\u5b66\u4e60\u6548\u679c\uff0c\u8bc1\u660e\u5728\u7ed3\u6784\u56e0\u679c\u8d4c\u535a\u673a\u4e2d\u878d\u5408\u5148\u9a8c\u77e5\u8bc6\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002"}}
{"id": "2511.17983", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17983", "abs": "https://arxiv.org/abs/2511.17983", "authors": ["Naoki Masuyama", "Yuichiro Toda", "Yusuke Nojima", "Hisao Ishibuchi"], "title": "An Adaptive Resonance Theory-based Topological Clustering Algorithm with a Self-Adjusting Vigilance Parameter", "comment": "This manuscript is currently under review", "summary": "Clustering in stationary and nonstationary settings, where data distributions remain static or evolve over time, requires models that can adapt to distributional shifts while preserving previously learned cluster structures. This paper proposes an Adaptive Resonance Theory (ART)-based topological clustering algorithm that autonomously adjusts its recalculation interval and vigilance threshold through a diversity-driven adaptation mechanism. This mechanism enables hyperparameter-free learning that maintains cluster stability and continuity in dynamic environments. Experiments on 24 real-world datasets demonstrate that the proposed algorithm outperforms state-of-the-art methods in both clustering performance and continual learning capability. These results highlight the effectiveness of the proposed parameter adaptation in mitigating catastrophic forgetting and maintaining consistent clustering in evolving data streams. Source code is available at https://github.com/Masuyama-lab/IDAT", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u9002\u5e94\u5171\u632f\u7406\u8bba(ART)\u7684\u62d3\u6251\u805a\u7c7b\u7b97\u6cd5\uff0c\u901a\u8fc7\u591a\u6837\u6027\u9a71\u52a8\u7684\u9002\u5e94\u673a\u5236\u81ea\u52a8\u8c03\u6574\u91cd\u8ba1\u7b97\u95f4\u9694\u548c\u8b66\u6212\u9608\u503c\uff0c\u5b9e\u73b0\u65e0\u8d85\u53c2\u6570\u5b66\u4e60\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4fdd\u6301\u805a\u7c7b\u7a33\u5b9a\u6027\u548c\u8fde\u7eed\u6027\u3002", "motivation": "\u89e3\u51b3\u9759\u6001\u548c\u975e\u9759\u6001\u8bbe\u7f6e\u4e2d\u7684\u805a\u7c7b\u95ee\u9898\uff0c\u9700\u8981\u80fd\u591f\u9002\u5e94\u5206\u5e03\u53d8\u5316\u540c\u65f6\u4fdd\u7559\u5148\u524d\u5b66\u4e60\u805a\u7c7b\u7ed3\u6784\u7684\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u81ea\u9002\u5e94\u5171\u632f\u7406\u8bba(ART)\u7684\u62d3\u6251\u805a\u7c7b\u7b97\u6cd5\uff0c\u91c7\u7528\u591a\u6837\u6027\u9a71\u52a8\u7684\u9002\u5e94\u673a\u5236\u81ea\u52a8\u8c03\u6574\u91cd\u8ba1\u7b97\u95f4\u9694\u548c\u8b66\u6212\u9608\u503c\u3002", "result": "\u572824\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u805a\u7c7b\u6027\u80fd\u548c\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53c2\u6570\u9002\u5e94\u673a\u5236\u5728\u51cf\u8f7b\u707e\u96be\u6027\u9057\u5fd8\u548c\u4fdd\u6301\u6f14\u5316\u6570\u636e\u6d41\u4e2d\u4e00\u81f4\u805a\u7c7b\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\u3002"}}
{"id": "2511.17987", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17987", "abs": "https://arxiv.org/abs/2511.17987", "authors": ["Jinping Wang", "Zhiqiang Gao", "Dinggen Zhang", "Zhiwu Xie"], "title": "Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic via Difference Vectors", "comment": null, "summary": "Current methods for editing pre-trained models face significant challenges, primarily high computational costs and limited scalability. Task arithmetic has recently emerged as a promising solution, using simple arithmetic operations-addition and negation-based on task vectors which are the differences between fine-tuned and pre-trained model weights, to efficiently modify model behavior. However, the full potential of task arithmetic remains underexplored, primarily due to limited mechanisms for overcoming optimization stagnation. To address this challenge, we introduce the notion of difference vector, a generalized form of task vectors derived from the historical movements during optimization. Using difference vectors as directed perturbations, we propose the Difference Vector-based Anisotropic Scaling Iterative algorithm (DV-BASI) to enable a continuous optimization process for task arithmetic methods without relying on any additional modules or components. Notably, by leveraging escapability and directional advantages of difference vectors, the average performance on different tasks of the multi-task model merged by DV-BASI may even outperform models individually fine-tuned. Based on this observation, we extend the application of difference vectors to a feasible fine-tuning method for single-task models. On the practical side, DV-BASI allows expressive searching directions with few learnable parameters and forms a scalable framework. We also integrate DV-BASI with task arithmetic methods and advanced optimization techniques to achieve state-of-the-art performance on both supervised and unsupervised evaluation protocols.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5f02\u5411\u91cf\u7684\u4efb\u52a1\u7b97\u672f\u4f18\u5316\u65b9\u6cd5DV-BASI\uff0c\u901a\u8fc7\u5229\u7528\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u5386\u53f2\u79fb\u52a8\u4f5c\u4e3a\u5b9a\u5411\u6270\u52a8\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u7684\u4f18\u5316\u505c\u6ede\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u6027\u80fd\u7684\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u9884\u8bad\u7ec3\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u9762\u4e34\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u6709\u9650\u53ef\u6269\u5c55\u6027\u7684\u6311\u6218\uff0c\u4efb\u52a1\u7b97\u672f\u65b9\u6cd5\u867d\u7136\u901a\u8fc7\u7b80\u5355\u7684\u7b97\u672f\u8fd0\u7b97\u6765\u4fee\u6539\u6a21\u578b\u884c\u4e3a\uff0c\u4f46\u5176\u6f5c\u529b\u56e0\u4f18\u5316\u505c\u6ede\u95ee\u9898\u800c\u672a\u80fd\u5145\u5206\u53d1\u6325\u3002", "method": "\u5f15\u5165\u5dee\u5f02\u5411\u91cf\u6982\u5ff5\uff0c\u4f5c\u4e3a\u4efb\u52a1\u5411\u91cf\u7684\u5e7f\u4e49\u5f62\u5f0f\uff0c\u57fa\u4e8e\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u5386\u53f2\u79fb\u52a8\u3002\u63d0\u51faDV-BASI\u7b97\u6cd5\uff0c\u5229\u7528\u5dee\u5f02\u5411\u91cf\u7684\u9003\u9038\u6027\u548c\u65b9\u5411\u4f18\u52bf\uff0c\u5b9e\u73b0\u8fde\u7eed\u4f18\u5316\u8fc7\u7a0b\uff0c\u65e0\u9700\u989d\u5916\u6a21\u5757\u3002", "result": "DV-BASI\u5728\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u4e2d\u7684\u5e73\u5747\u6027\u80fd\u751a\u81f3\u8d85\u8fc7\u5355\u72ec\u5fae\u8c03\u7684\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u4f7f\u7528\u5c11\u91cf\u53ef\u5b66\u4e60\u53c2\u6570\u8fdb\u884c\u8868\u8fbe\u6027\u641c\u7d22\uff0c\u5f62\u6210\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u5728\u76d1\u7763\u548c\u65e0\u76d1\u7763\u8bc4\u4f30\u534f\u8bae\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u5dee\u5f02\u5411\u91cf\u4e3a\u4efb\u52a1\u7b97\u672f\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u673a\u5236\uff0cDV-BASI\u7b97\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u4f18\u5316\u505c\u6ede\u95ee\u9898\uff0c\u8fd8\u6269\u5c55\u4e86\u5dee\u5f02\u5411\u91cf\u5728\u5355\u4efb\u52a1\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u5e94\u7528\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.17989", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17989", "abs": "https://arxiv.org/abs/2511.17989", "authors": ["Jiayi Luo", "Qingyun Sun", "Yuecen Wei", "Haonan Yuan", "Xingcheng Fu", "Jianxin Li"], "title": "Privacy Auditing of Multi-domain Graph Pre-trained Model under Membership Inference Attacks", "comment": "Accepted by AAAI 2026(Oral)", "summary": "Multi-domain graph pre-training has emerged as a pivotal technique in developing graph foundation models. While it greatly improves the generalization of graph neural networks, its privacy risks under membership inference attacks (MIAs), which aim to identify whether a specific instance was used in training (member), remain largely unexplored. However, effectively conducting MIAs against multi-domain graph pre-trained models is a significant challenge due to: (i) Enhanced Generalization Capability: Multi-domain pre-training reduces the overfitting characteristics commonly exploited by MIAs. (ii) Unrepresentative Shadow Datasets: Diverse training graphs hinder the obtaining of reliable shadow graphs. (iii) Weakened Membership Signals: Embedding-based outputs offer less informative cues than logits for MIAs. To tackle these challenges, we propose MGP-MIA, a novel framework for Membership Inference Attacks against Multi-domain Graph Pre-trained models. Specifically, we first propose a membership signal amplification mechanism that amplifies the overfitting characteristics of target models via machine unlearning. We then design an incremental shadow model construction mechanism that builds a reliable shadow model with limited shadow graphs via incremental learning. Finally, we introduce a similarity-based inference mechanism that identifies members based on their similarity to positive and negative samples. Extensive experiments demonstrate the effectiveness of our proposed MGP-MIA and reveal the privacy risks of multi-domain graph pre-training.", "AI": {"tldr": "MGP-MIA\u662f\u9488\u5bf9\u591a\u9886\u57df\u56fe\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u673a\u5668\u9057\u5fd8\u653e\u5927\u6210\u5458\u4fe1\u53f7\u3001\u589e\u91cf\u5b66\u4e60\u6784\u5efa\u5f71\u5b50\u6a21\u578b\u3001\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u63a8\u7406\u673a\u5236\u6765\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\u6210\u5458\u3002", "motivation": "\u591a\u9886\u57df\u56fe\u9884\u8bad\u7ec3\u6a21\u578b\u867d\u7136\u63d0\u5347\u4e86\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5176\u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e0b\u7684\u9690\u79c1\u98ce\u9669\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u9762\u4e34\u6cdb\u5316\u80fd\u529b\u589e\u5f3a\u3001\u5f71\u5b50\u6570\u636e\u96c6\u4e0d\u53ef\u9760\u3001\u6210\u5458\u4fe1\u53f7\u5f31\u5316\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faMGP-MIA\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u673a\u5668\u9057\u5fd8\u653e\u5927\u76ee\u6807\u6a21\u578b\u7684\u8fc7\u62df\u5408\u7279\u5f81\uff1b2\uff09\u4f7f\u7528\u589e\u91cf\u5b66\u4e60\u6784\u5efa\u53ef\u9760\u7684\u5f71\u5b50\u6a21\u578b\uff1b3\uff09\u57fa\u4e8e\u6b63\u8d1f\u6837\u672c\u76f8\u4f3c\u5ea6\u8fdb\u884c\u6210\u5458\u63a8\u7406\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eMGP-MIA\u7684\u6709\u6548\u6027\uff0c\u63ed\u793a\u4e86\u591a\u9886\u57df\u56fe\u9884\u8bad\u7ec3\u5b58\u5728\u7684\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "\u591a\u9886\u57df\u56fe\u9884\u8bad\u7ec3\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u9690\u79c1\u98ce\u9669\uff0cMGP-MIA\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\u6210\u5458\uff0c\u4e3a\u56fe\u57fa\u7840\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2511.17994", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17994", "abs": "https://arxiv.org/abs/2511.17994", "authors": ["Nikita P. Kalinin", "Joel Daniel Andersson"], "title": "Learning Rate Scheduling with Matrix Factorization for Private Training", "comment": null, "summary": "We study differentially private model training with stochastic gradient descent under learning rate scheduling and correlated noise. Although correlated noise, in particular via matrix factorizations, has been shown to improve accuracy, prior theoretical work focused primarily on the prefix-sum workload. That workload assumes a constant learning rate, whereas in practice learning rate schedules are widely used to accelerate training and improve convergence. We close this gap by deriving general upper and lower bounds for a broad class of learning rate schedules in both single- and multi-epoch settings. Building on these results, we propose a learning-rate-aware factorization that achieves improvements over prefix-sum factorizations under both MaxSE and MeanSE error metrics. Our theoretical analysis yields memory-efficient constructions suitable for practical deployment, and experiments on CIFAR-10 and IMDB datasets confirm that schedule-aware factorizations improve accuracy in private training.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\uff0c\u91cd\u70b9\u5173\u6ce8\u5b66\u4e60\u7387\u8c03\u5ea6\u548c\u76f8\u5173\u6027\u566a\u58f0\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u591a\u79cd\u5b66\u4e60\u7387\u8c03\u5ea6\u7684\u4e0a\u4e0b\u754c\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5b66\u4e60\u7387\u611f\u77e5\u7684\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6052\u5b9a\u5b66\u4e60\u7387\u573a\u666f\uff0c\u800c\u5b9e\u8df5\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u5b66\u4e60\u7387\u8c03\u5ea6\u6765\u52a0\u901f\u8bad\u7ec3\u548c\u63d0\u9ad8\u6536\u655b\u6027\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\uff0c\u7814\u7a76\u5b66\u4e60\u7387\u8c03\u5ea6\u4e0e\u76f8\u5173\u6027\u566a\u58f0\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u5b66\u4e60\u7387\u611f\u77e5\u7684\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e86\u5355\u8f6e\u548c\u591a\u8f6e\u8bad\u7ec3\u573a\u666f\u4e0b\u5404\u7c7b\u5b66\u4e60\u7387\u8c03\u5ea6\u7684\u7406\u8bba\u4e0a\u4e0b\u754c\uff0c\u8bbe\u8ba1\u4e86\u5185\u5b58\u9ad8\u6548\u7684\u5b9e\u7528\u6784\u9020\u65b9\u6848\u3002", "result": "\u5728CIFAR-10\u548cIMDB\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8c03\u5ea6\u611f\u77e5\u7684\u5206\u89e3\u65b9\u6cd5\u5728MaxSE\u548cMeanSE\u8bef\u5dee\u6307\u6807\u4e0a\u4f18\u4e8e\u524d\u7f00\u548c\u5206\u89e3\uff0c\u63d0\u9ad8\u4e86\u79c1\u6709\u8bad\u7ec3\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5b66\u4e60\u7387\u8c03\u5ea6\u611f\u77e5\u7684\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u7684\u6027\u80fd\uff0c\u7406\u8bba\u5206\u6790\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5185\u5b58\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18084", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18084", "abs": "https://arxiv.org/abs/2511.18084", "authors": ["Dou Liu", "Ying Long", "Sophia Zuoqiu", "Kaipeng Xie", "Runze Yang", "Di Liu", "Kang Li", "Yiting Lin", "Hanyi Liu", "Rong Yin", "Tian Tang"], "title": "The Alignment Paradox of Medical Large Language Models in Infertility Care: Decoupling Algorithmic Improvement from Clinical Decision-making Quality", "comment": "22 pages 5 figures", "summary": "Large language models (LLMs) are increasingly adopted in clinical decision support, yet aligning them with the multifaceted reasoning pathways of real-world medicine remains a major challenge. Using more than 8,000 infertility treatment records, we systematically evaluate four alignment strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), Group Relative Policy Optimization (GRPO), and In-Context Learning (ICL) through a dual-layer framework combining automatic benchmarks with blinded doctor-in-the-loop assessments. GRPO achieves the highest algorithmic accuracy across multiple decision layers, confirming the value of reinforcement-based optimization for structured prediction tasks. However, clinicians consistently prefer the SFT model, citing clearer reasoning processes (p = 0.035) and higher therapeutic feasibility (p = 0.019). In blinded pairwise comparisons, SFT attains the highest winning rate (51.2%), outperforming both GRPO (26.2%) and even physicians' original decisions (22.7%). These results reveal an alignment paradox: algorithmic improvements do not necessarily translate into higher clinical trust, and may diverge from human-centered preferences. Our findings highlight the need for alignment strategies that prioritize clinically interpretable and practically feasible reasoning, rather than solely optimizing decision-level accuracy.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u56db\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u7b56\u7565\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0GRPO\u5728\u7b97\u6cd5\u7cbe\u5ea6\u4e0a\u6700\u4f18\uff0c\u4f46\u4e34\u5e8a\u533b\u751f\u66f4\u504f\u597dSFT\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u7b97\u6cd5\u6539\u8fdb\u4e0e\u4e34\u5e8a\u4fe1\u4efb\u4e4b\u95f4\u7684\u5bf9\u9f50\u6096\u8bba\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u5982\u4f55\u4f7f\u5176\u4e0e\u771f\u5b9e\u4e16\u754c\u533b\u5b66\u7684\u591a\u7ef4\u63a8\u7406\u8def\u5f84\u5bf9\u9f50\u4ecd\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u4f7f\u7528\u8d85\u8fc78000\u4efd\u4e0d\u5b55\u75c7\u6cbb\u7597\u8bb0\u5f55\uff0c\u7cfb\u7edf\u8bc4\u4f30\u56db\u79cd\u5bf9\u9f50\u7b56\u7565\uff1a\u76d1\u7763\u5fae\u8c03(SFT)\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u3001\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60(ICL)\uff0c\u901a\u8fc7\u7ed3\u5408\u81ea\u52a8\u57fa\u51c6\u6d4b\u8bd5\u548c\u76f2\u6cd5\u533b\u751f\u53c2\u4e0e\u8bc4\u4f30\u7684\u53cc\u5c42\u6846\u67b6\u3002", "result": "GRPO\u5728\u591a\u4e2a\u51b3\u7b56\u5c42\u5b9e\u73b0\u6700\u9ad8\u7b97\u6cd5\u7cbe\u5ea6\uff0c\u4f46\u4e34\u5e8a\u533b\u751f\u4e00\u81f4\u504f\u597dSFT\u6a21\u578b\uff0c\u8ba4\u4e3a\u5176\u63a8\u7406\u8fc7\u7a0b\u66f4\u6e05\u6670(p=0.035)\u4e14\u6cbb\u7597\u53ef\u884c\u6027\u66f4\u9ad8(p=0.019)\u3002\u5728\u76f2\u6cd5\u6210\u5bf9\u6bd4\u8f83\u4e2d\uff0cSFT\u83b7\u5f97\u6700\u9ad8\u80dc\u7387(51.2%)\uff0c\u4f18\u4e8eGRPO(26.2%)\u548c\u533b\u751f\u539f\u59cb\u51b3\u7b56(22.7%)\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5bf9\u9f50\u6096\u8bba\uff1a\u7b97\u6cd5\u6539\u8fdb\u4e0d\u4e00\u5b9a\u8f6c\u5316\u4e3a\u66f4\u9ad8\u7684\u4e34\u5e8a\u4fe1\u4efb\uff0c\u53ef\u80fd\u4e0e\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u504f\u597d\u76f8\u80cc\u79bb\u3002\u9700\u8981\u4f18\u5148\u8003\u8651\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u8df5\u53ef\u884c\u6027\u7684\u5bf9\u9f50\u7b56\u7565\uff0c\u800c\u975e\u4ec5\u4f18\u5316\u51b3\u7b56\u7ea7\u7cbe\u5ea6\u3002"}}
{"id": "2511.18006", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18006", "abs": "https://arxiv.org/abs/2511.18006", "authors": ["Meng Ding", "Mingxi Lei", "Shaopeng Fu", "Shaowei Wang", "Di Wang", "Jinhui Xu"], "title": "Understanding Private Learning From Feature Perspective", "comment": "39pages", "summary": "Differentially private Stochastic Gradient Descent (DP-SGD) has become integral to privacy-preserving machine learning, ensuring robust privacy guarantees in sensitive domains. Despite notable empirical advances leveraging features from non-private, pre-trained models to enhance DP-SGD training, a theoretical understanding of feature dynamics in private learning remains underexplored. This paper presents the first theoretical framework to analyze private training through a feature learning perspective. Building on the multi-patch data structure from prior work, our analysis distinguishes between label-dependent feature signals and label-independent noise, a critical aspect overlooked by existing analyses in the DP community. Employing a two-layer CNN with polynomial ReLU activation, we theoretically characterize both feature signal learning and data noise memorization in private training via noisy gradient descent. Our findings reveal that (1) Effective private signal learning requires a higher signal-to-noise ratio (SNR) compared to non-private training, and (2) When data noise memorization occurs in non-private learning, it will also occur in private learning, leading to poor generalization despite small training loss. Our findings highlight the challenges of private learning and prove the benefit of feature enhancement to improve SNR. Experiments on synthetic and real-world datasets also validate our theoretical findings.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u4ece\u7279\u5f81\u5b66\u4e60\u89d2\u5ea6\u5efa\u7acb\u4e86\u5dee\u5206\u9690\u79c1SGD\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u79c1\u6709\u8bad\u7ec3\u4e2d\u7279\u5f81\u4fe1\u53f7\u5b66\u4e60\u548c\u6570\u636e\u566a\u58f0\u8bb0\u5fc6\u5316\u7684\u673a\u5236\uff0c\u53d1\u73b0\u79c1\u6709\u5b66\u4e60\u9700\u8981\u66f4\u9ad8\u7684\u4fe1\u566a\u6bd4\uff0c\u4e14\u5f53\u975e\u79c1\u6709\u5b66\u4e60\u51fa\u73b0\u566a\u58f0\u8bb0\u5fc6\u5316\u65f6\uff0c\u79c1\u6709\u5b66\u4e60\u4e5f\u4f1a\u51fa\u73b0\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u80fd\u5dee\u3002", "motivation": "\u5c3d\u7ba1\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u7279\u5f81\u589e\u5f3aDP-SGD\u8bad\u7ec3\u53d6\u5f97\u4e86\u663e\u8457\u7ecf\u9a8c\u8fdb\u5c55\uff0c\u4f46\u79c1\u6709\u5b66\u4e60\u4e2d\u7279\u5f81\u52a8\u6001\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u4e0d\u8db3\uff0c\u73b0\u6709DP\u5206\u6790\u5ffd\u7565\u4e86\u6807\u7b7e\u76f8\u5173\u7279\u5f81\u4fe1\u53f7\u548c\u6807\u7b7e\u65e0\u5173\u566a\u58f0\u7684\u5173\u952e\u533a\u522b\u3002", "method": "\u57fa\u4e8e\u591a\u5757\u6570\u636e\u7ed3\u6784\uff0c\u91c7\u7528\u5e26\u591a\u9879\u5f0fReLU\u6fc0\u6d3b\u7684\u4e24\u5c42CNN\uff0c\u901a\u8fc7\u566a\u58f0\u68af\u5ea6\u4e0b\u964d\u7406\u8bba\u5206\u6790\u79c1\u6709\u8bad\u7ec3\u4e2d\u7684\u7279\u5f81\u4fe1\u53f7\u5b66\u4e60\u548c\u6570\u636e\u566a\u58f0\u8bb0\u5fc6\u5316\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1)\u6709\u6548\u79c1\u6709\u4fe1\u53f7\u5b66\u4e60\u9700\u8981\u6bd4\u975e\u79c1\u6709\u8bad\u7ec3\u66f4\u9ad8\u7684\u4fe1\u566a\u6bd4\uff1b(2)\u5f53\u975e\u79c1\u6709\u5b66\u4e60\u51fa\u73b0\u6570\u636e\u566a\u58f0\u8bb0\u5fc6\u5316\u65f6\uff0c\u79c1\u6709\u5b66\u4e60\u4e5f\u4f1a\u51fa\u73b0\uff0c\u5bfc\u81f4\u8bad\u7ec3\u635f\u5931\u5c0f\u4f46\u6cdb\u5316\u6027\u80fd\u5dee\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u79c1\u6709\u5b66\u4e60\u7684\u6311\u6218\u6027\uff0c\u8bc1\u660e\u4e86\u7279\u5f81\u589e\u5f3a\u63d0\u9ad8\u4fe1\u566a\u6bd4\u7684\u76ca\u5904\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002"}}
{"id": "2511.18039", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18039", "abs": "https://arxiv.org/abs/2511.18039", "authors": ["Thong Bach", "Thanh Nguyen-Tang", "Dung Nguyen", "Thao Minh Le", "Truyen Tran"], "title": "Curvature-Aware Safety Restoration In LLMs Fine-Tuning", "comment": "19 pages, 10 figures", "summary": "Fine-tuning Large Language Models (LLMs) for downstream tasks often compromises safety alignment, even when using parameter-efficient methods like LoRA. In this work, we uncover a notable property: fine-tuned models preserve the geometric structure of their loss landscapes concerning harmful content, regardless of the fine-tuning method employed. This suggests that safety behaviors are not erased but shifted to less influential regions of the parameter space. Building on this insight, we propose a curvature-aware alignment restoration method that leverages influence functions and second-order optimization to selectively increase loss on harmful inputs while preserving task performance. By navigating the shared geometry between base and fine-tuned models, our method discourages unsafe outputs while preserving task-relevant performance, avoiding full reversion and enabling precise, low-impact updates. Extensive evaluations across multiple model families and adversarial settings show that our approach efficiently reduces harmful responses while maintaining or even improving utility and few-shot learning performance.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5fae\u8c03\u540e\u7684LLM\u5728\u6709\u5bb3\u5185\u5bb9\u4e0a\u7684\u635f\u5931\u666f\u89c2\u51e0\u4f55\u7ed3\u6784\u4fdd\u6301\u4e0d\u53d8\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u66f2\u7387\u611f\u77e5\u7684\u5bf9\u9f50\u6062\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f71\u54cd\u51fd\u6570\u548c\u4e8c\u9636\u4f18\u5316\u9009\u62e9\u6027\u5730\u589e\u52a0\u6709\u5bb3\u8f93\u5165\u7684\u635f\u5931\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u65f6\u5f80\u5f80\u4f1a\u635f\u5bb3\u5b89\u5168\u5bf9\u9f50\uff0c\u5373\u4f7f\u4f7f\u7528LoRA\u7b49\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u3002\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u6a21\u578b\u5728\u6709\u5bb3\u5185\u5bb9\u4e0a\u7684\u635f\u5931\u666f\u89c2\u51e0\u4f55\u7ed3\u6784\u4fdd\u6301\u4e0d\u53d8\uff0c\u8868\u660e\u5b89\u5168\u884c\u4e3a\u5e76\u672a\u88ab\u64e6\u9664\u800c\u662f\u8f6c\u79fb\u5230\u53c2\u6570\u7a7a\u95f4\u4e2d\u5f71\u54cd\u529b\u8f83\u5c0f\u7684\u533a\u57df\u3002", "method": "\u63d0\u51fa\u66f2\u7387\u611f\u77e5\u5bf9\u9f50\u6062\u590d\u65b9\u6cd5\uff0c\u5229\u7528\u5f71\u54cd\u51fd\u6570\u548c\u4e8c\u9636\u4f18\u5316\uff0c\u5728\u57fa\u7840\u6a21\u578b\u548c\u5fae\u8c03\u6a21\u578b\u5171\u4eab\u7684\u51e0\u4f55\u7ed3\u6784\u57fa\u7840\u4e0a\uff0c\u9009\u62e9\u6027\u5730\u589e\u52a0\u6709\u5bb3\u8f93\u5165\u7684\u635f\u5931\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u76f8\u5173\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u7cfb\u5217\u548c\u5bf9\u6297\u8bbe\u7f6e\u4e0b\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u6709\u5bb3\u54cd\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u5b9e\u7528\u6027\u548c\u5c11\u6837\u672c\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u5fae\u8c03\u6a21\u578b\u4fdd\u6301\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u7cbe\u786e\u5730\u8fdb\u884c\u4f4e\u5f71\u54cd\u66f4\u65b0\uff0c\u907f\u514d\u5b8c\u5168\u56de\u9000\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u6709\u6548\u6062\u590d\u5b89\u5168\u5bf9\u9f50\u3002"}}
{"id": "2511.18056", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.18056", "abs": "https://arxiv.org/abs/2511.18056", "authors": ["Maximilien Dreveton", "Matthias Grossglauser", "Daichi Kuroda", "Patrick Thiran"], "title": "Hierarchical Linkage Clustering Beyond Binary Trees and Ultrametrics", "comment": null, "summary": "Hierarchical clustering seeks to uncover nested structures in data by constructing a tree of clusters, where deeper levels reveal finer-grained relationships. Traditional methods, including linkage approaches, face three major limitations: (i) they always return a hierarchy, even if none exists, (ii) they are restricted to binary trees, even if the true hierarchy is non-binary, and (iii) they are highly sensitive to the choice of linkage function. In this paper, we address these issues by introducing the notion of a valid hierarchy and defining a partial order over the set of valid hierarchies. We prove the existence of a finest valid hierarchy, that is, the hierarchy that encodes the maximum information consistent with the similarity structure of the data set. In particular, the finest valid hierarchy is not constrained to binary structures and, when no hierarchical relationships exist, collapses to a star tree. We propose a simple two-step algorithm that first constructs a binary tree via a linkage method and then prunes it to enforce validity. We establish necessary and sufficient conditions on the linkage function under which this procedure exactly recovers the finest valid hierarchy, and we show that all linkage functions satisfying these conditions yield the same hierarchy after pruning. Notably, classical linkage rules such as single, complete, and average satisfy these conditions, whereas Ward's linkage fails to do so.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u6982\u5ff5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5c42\u6b21\u805a\u7c7b\u7684\u4e09\u4e2a\u4e3b\u8981\u9650\u5236\uff1a\u603b\u662f\u8fd4\u56de\u5c42\u6b21\u7ed3\u6784\u3001\u4ec5\u9650\u4e8e\u4e8c\u53c9\u6811\u3001\u5bf9\u94fe\u63a5\u51fd\u6570\u9009\u62e9\u654f\u611f\u3002\u901a\u8fc7\u5b9a\u4e49\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u90e8\u5206\u987a\u5e8f\uff0c\u8bc1\u660e\u4e86\u6700\u7cbe\u7ec6\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u5b58\u5728\uff0c\u5e76\u63d0\u51fa\u4e24\u6b65\u7b97\u6cd5\u6765\u6062\u590d\u5b83\u3002", "motivation": "\u4f20\u7edf\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a(i)\u5373\u4f7f\u6570\u636e\u4e2d\u4e0d\u5b58\u5728\u5c42\u6b21\u7ed3\u6784\u4e5f\u4f1a\u8fd4\u56de\u5c42\u6b21\u7ed3\u6784\uff0c(ii)\u4ec5\u9650\u4e8e\u4e8c\u53c9\u6811\u7ed3\u6784\uff0c(iii)\u5bf9\u94fe\u63a5\u51fd\u6570\u9009\u62e9\u9ad8\u5ea6\u654f\u611f\u3002\u8fd9\u4e9b\u9650\u5236\u5f71\u54cd\u4e86\u5c42\u6b21\u805a\u7c7b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e86\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u90e8\u5206\u987a\u5e8f\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u4e24\u6b65\u7b97\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u94fe\u63a5\u65b9\u6cd5\u6784\u5efa\u4e8c\u53c9\u6811\uff0c\u7136\u540e\u8fdb\u884c\u526a\u679d\u4ee5\u5f3a\u5236\u6267\u884c\u6709\u6548\u6027\u3002\u5efa\u7acb\u4e86\u94fe\u63a5\u51fd\u6570\u6062\u590d\u6700\u7cbe\u7ec6\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u5145\u8981\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u6700\u7cbe\u7ec6\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u5b58\u5728\uff0c\u8be5\u7ed3\u6784\u4e0d\u53d7\u9650\u4e8e\u4e8c\u53c9\u6811\uff0c\u5f53\u4e0d\u5b58\u5728\u5c42\u6b21\u5173\u7cfb\u65f6\u4f1a\u574d\u7f29\u4e3a\u661f\u5f62\u6811\u3002\u7ecf\u5178\u94fe\u63a5\u89c4\u5219\uff08\u5982\u5355\u94fe\u63a5\u3001\u5b8c\u5168\u94fe\u63a5\u3001\u5e73\u5747\u94fe\u63a5\uff09\u6ee1\u8db3\u6062\u590d\u6761\u4ef6\uff0c\u800cWard\u94fe\u63a5\u4e0d\u6ee1\u8db3\u3002\u6240\u6709\u6ee1\u8db3\u6761\u4ef6\u7684\u94fe\u63a5\u51fd\u6570\u5728\u526a\u679d\u540e\u90fd\u4f1a\u4ea7\u751f\u76f8\u540c\u7684\u5c42\u6b21\u7ed3\u6784\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u6709\u6548\u5c42\u6b21\u7ed3\u6784\u7684\u6982\u5ff5\u548c\u76f8\u5e94\u7684\u7b97\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u5c42\u6b21\u805a\u7c7b\u7684\u4e09\u4e2a\u4e3b\u8981\u9650\u5236\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u51c6\u786e\u3001\u66f4\u7a33\u5065\u7684\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u53cd\u6620\u6570\u636e\u7684\u771f\u5b9e\u5c42\u6b21\u7ed3\u6784\u3002"}}
{"id": "2511.18066", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18066", "abs": "https://arxiv.org/abs/2511.18066", "authors": ["Md Akil Raihan Iftee", "Syed Md. Ahnaf Hasan", "Mir Sazzat Hossain", "Rakibul Hasan Rajib", "Amin Ahsan Ali", "AKM Mahbubur Rahman", "Sajib Mistry", "Monowar Bhuyan"], "title": "pFedBBN: A Personalized Federated Test-Time Adaptation with Balanced Batch Normalization for Class-Imbalanced Data", "comment": "25 pages, 7 tables, 21 figures", "summary": "Test-time adaptation (TTA) in federated learning (FL) is crucial for handling unseen data distributions across clients, particularly when faced with domain shifts and skewed class distributions. Class Imbalance (CI) remains a fundamental challenge in FL, where rare but critical classes are often severely underrepresented in individual client datasets. Although prior work has addressed CI during training through reliable aggregation and local class distribution alignment, these methods typically rely on access to labeled data or coordination among clients, and none address class unsupervised adaptation to dynamic domains or distribution shifts at inference time under federated CI constraints. Revealing the failure of state-of-the-art TTA in federated client adaptation in CI scenario, we propose pFedBBN,a personalized federated test-time adaptation framework that employs balanced batch normalization (BBN) during local client adaptation to mitigate prediction bias by treating all classes equally, while also enabling client collaboration guided by BBN similarity, ensuring that clients with similar balanced representations reinforce each other and that adaptation remains aligned with domain-specific characteristics. pFedBBN supports fully unsupervised local adaptation and introduces a class-aware model aggregation strategy that enables personalized inference without compromising privacy. It addresses both distribution shifts and class imbalance through balanced feature normalization and domain-aware collaboration, without requiring any labeled or raw data from clients. Extensive experiments across diverse baselines show that pFedBBN consistently enhances robustness and minority-class performance over state-of-the-art FL and TTA methods.", "AI": {"tldr": "pFedBBN\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u7684\u8054\u90a6\u6d4b\u8bd5\u65f6\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u8861\u6279\u91cf\u5f52\u4e00\u5316(BBN)\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u652f\u6301\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u672c\u5730\u9002\u5e94\u548c\u57fa\u4e8eBBN\u76f8\u4f3c\u5ea6\u7684\u5ba2\u6237\u7aef\u534f\u4f5c\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u9762\u4e34\u9886\u57df\u504f\u79fb\u548c\u504f\u659c\u7c7b\u522b\u5206\u5e03\u65f6\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u6807\u8bb0\u6570\u636e\u6216\u5ba2\u6237\u7aef\u534f\u8c03\uff0c\u65e0\u6cd5\u5728\u8054\u90a6\u7c7b\u522b\u4e0d\u5e73\u8861\u7ea6\u675f\u4e0b\u5904\u7406\u52a8\u6001\u9886\u57df\u6216\u63a8\u7406\u65f6\u7684\u5206\u5e03\u504f\u79fb\u3002", "method": "\u91c7\u7528\u5e73\u8861\u6279\u91cf\u5f52\u4e00\u5316(BBN)\u8fdb\u884c\u672c\u5730\u5ba2\u6237\u7aef\u9002\u5e94\uff0c\u901a\u8fc7\u5e73\u7b49\u5bf9\u5f85\u6240\u6709\u7c7b\u522b\u6765\u51cf\u8f7b\u9884\u6d4b\u504f\u5dee\uff1b\u5f15\u5165\u57fa\u4e8eBBN\u76f8\u4f3c\u5ea6\u7684\u5ba2\u6237\u7aef\u534f\u4f5c\u673a\u5236\uff1b\u63d0\u51fa\u7c7b\u522b\u611f\u77e5\u7684\u6a21\u578b\u805a\u5408\u7b56\u7565\uff0c\u652f\u6301\u4e2a\u6027\u5316\u63a8\u7406\u4e14\u4e0d\u635f\u5bb3\u9690\u79c1\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u7ebf\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cpFedBBN\u5728\u9c81\u68d2\u6027\u548c\u5c11\u6570\u7c7b\u522b\u6027\u80fd\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u8054\u90a6\u5b66\u4e60\u548c\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u3002", "conclusion": "pFedBBN\u901a\u8fc7\u5e73\u8861\u7279\u5f81\u5f52\u4e00\u5316\u548c\u9886\u57df\u611f\u77e5\u534f\u4f5c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u504f\u79fb\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u65e0\u9700\u5ba2\u6237\u7aef\u7684\u4efb\u4f55\u6807\u8bb0\u6216\u539f\u59cb\u6570\u636e\u3002"}}
{"id": "2511.18294", "categories": ["cs.LG", "cs.AI", "cs.HC", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.18294", "abs": "https://arxiv.org/abs/2511.18294", "authors": ["Mengchun Zhang", "Kateryna Shapovalenko", "Yucheng Shao", "Eddie Guo", "Parusha Pradhan"], "title": "MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding", "comment": null, "summary": "Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \\textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.", "AI": {"tldr": "MultiDiffNet\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u591a\u76ee\u6807\u5b66\u4e60\u7684\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\uff0c\u7ed5\u8fc7\u751f\u6210\u5f0f\u589e\u5f3a\uff0c\u5b9e\u73b0\u8de8\u88ab\u8bd5\u7684\u8111\u7535\u56fe\u89e3\u7801\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u8111\u7535\u56fe\u89e3\u7801\u9762\u4e34\u8de8\u88ab\u8bd5\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u88ab\u8bd5\u95f4\u5dee\u5f02\u5927\u4e14\u7f3a\u4e4f\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5408\u6210\u88ab\u8bd5\u751f\u6210\u6216\u7b80\u5355\u6570\u636e\u589e\u5f3a\uff0c\u4f46\u65e0\u6cd5\u53ef\u9760\u6269\u5c55\u6216\u6cdb\u5316\u3002", "method": "\u63d0\u51faMultiDiffNet\u6269\u6563\u6846\u67b6\uff0c\u5b66\u4e60\u4f18\u5316\u7684\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\uff0c\u76f4\u63a5\u4ece\u8be5\u7a7a\u95f4\u8fdb\u884c\u89e3\u7801\uff0c\u907f\u514d\u4e86\u751f\u6210\u5f0f\u589e\u5f3a\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u548c\u7edf\u8ba1\u62a5\u544a\u6846\u67b6\u3002", "result": "\u5728\u591a\u79cd\u795e\u7ecf\u89e3\u7801\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8de8\u88ab\u8bd5\u6cdb\u5316\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u88ab\u8bd5\u548c\u4f1a\u8bdd\u4e0d\u76f8\u4ea4\u7684\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u73b0\u5b9e\u4e16\u754c\u8111\u673a\u63a5\u53e3\u7cfb\u7edf\u4e2d\u7684\u88ab\u8bd5\u65e0\u5173\u8111\u7535\u56fe\u89e3\u7801\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u548c\u5f00\u6e90\u7684\u57fa\u7840\u3002"}}
{"id": "2511.18314", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18314", "abs": "https://arxiv.org/abs/2511.18314", "authors": ["Yuting Gao", "Wang Lan", "Hengyuan Zhao", "Linjiang Huang", "Si Liu", "Qingpei Guo"], "title": "AnyExperts: On-Demand Expert Allocation for Multimodal Language Models with Mixture of Expert", "comment": null, "summary": "Multimodal Mixture-of-Experts (MoE) models offer a promising path toward scalable and efficient large vision-language systems. However, existing approaches rely on rigid routing strategies (typically activating a fixed number of experts per token) ignoring the inherent heterogeneity in semantic importance across modalities. This leads to suboptimal compute allocation, where redundant tokens consume as many resources as critical ones. To address this, we propose AnyExperts, a novel on-demand, budget-aware dynamic routing framework that allocates a variable total number of expert slots per token based on its semantic importance. Crucially, to prevent uncontrolled compute growth, the total slots per token are constrained within a fixed range, and each slot is filled by either a real expert or a virtual expert, with the virtual share capped at a small maximum (e.g., 20%). The model then adaptively balances the real-to-virtual ratio per token, assigning more real experts to semantically rich regions and relying more on virtual experts for redundant content. Evaluated across diverse tasks in visual understanding, audio understanding, and NLP understanding, AnyExperts improves performance under the same compute budget. Notably, on general image/video tasks, it achieves comparable accuracy with 40% fewer real expert activations; on text-dense tasks (OCR and NLP), it maintains performance while reducing real expert usage by 10%. These results demonstrate that fine-grained, importance-driven expert allocation significantly enhances both the efficiency and effectiveness of multimodal MoE models.", "AI": {"tldr": "AnyExperts\u63d0\u51fa\u4e86\u4e00\u79cd\u6309\u9700\u3001\u9884\u7b97\u611f\u77e5\u7684\u52a8\u6001\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u8bed\u4e49\u91cd\u8981\u6027\u4e3a\u6bcf\u4e2atoken\u5206\u914d\u53ef\u53d8\u6570\u91cf\u7684\u4e13\u5bb6\u69fd\u4f4d\uff0c\u4f18\u5316\u591a\u6a21\u6001MoE\u6a21\u578b\u7684\u8ba1\u7b97\u5206\u914d\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001MoE\u6a21\u578b\u91c7\u7528\u56fa\u5b9a\u7684\u4e13\u5bb6\u6fc0\u6d3b\u7b56\u7565\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u6a21\u6001\u95f4\u8bed\u4e49\u91cd\u8981\u6027\u7684\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u5173\u952etoken\u548c\u5197\u4f59token\u6d88\u8017\u76f8\u540c\u8ba1\u7b97\u8d44\u6e90\uff0c\u9020\u6210\u8ba1\u7b97\u5206\u914d\u4e0d\u4f18\u3002", "method": "\u63d0\u51faAnyExperts\u6846\u67b6\uff1a\u4e3a\u6bcf\u4e2atoken\u5206\u914d\u53ef\u53d8\u603b\u6570\u91cf\u7684\u4e13\u5bb6\u69fd\u4f4d\uff0c\u4f46\u9650\u5236\u5728\u56fa\u5b9a\u8303\u56f4\u5185\uff1b\u6bcf\u4e2a\u69fd\u4f4d\u7531\u771f\u5b9e\u4e13\u5bb6\u6216\u865a\u62df\u4e13\u5bb6\u586b\u5145\uff0c\u865a\u62df\u4e13\u5bb6\u6bd4\u4f8b\u4e0a\u9650\u4e3a20%\uff1b\u6a21\u578b\u81ea\u9002\u5e94\u5e73\u8861\u6bcf\u4e2atoken\u7684\u771f\u5b9e-\u865a\u62df\u4e13\u5bb6\u6bd4\u4f8b\uff0c\u4e3a\u8bed\u4e49\u4e30\u5bcc\u533a\u57df\u5206\u914d\u66f4\u591a\u771f\u5b9e\u4e13\u5bb6\u3002", "result": "\u5728\u89c6\u89c9\u7406\u89e3\u3001\u97f3\u9891\u7406\u89e3\u548cNLP\u7406\u89e3\u7b49\u591a\u6837\u5316\u4efb\u52a1\u4e2d\uff0cAnyExperts\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u63d0\u5347\u6027\u80fd\uff1a\u5728\u901a\u7528\u56fe\u50cf/\u89c6\u9891\u4efb\u52a1\u4e2d\uff0c\u4f7f\u752840%\u66f4\u5c11\u7684\u771f\u5b9e\u4e13\u5bb6\u6fc0\u6d3b\u8fbe\u5230\u53ef\u6bd4\u7cbe\u5ea6\uff1b\u5728\u6587\u672c\u5bc6\u96c6\u4efb\u52a1\u4e2d\uff0c\u51cf\u5c1110%\u771f\u5b9e\u4e13\u5bb6\u4f7f\u7528\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u3001\u91cd\u8981\u6027\u9a71\u52a8\u7684\u4e13\u5bb6\u5206\u914d\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001MoE\u6a21\u578b\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.18334", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18334", "abs": "https://arxiv.org/abs/2511.18334", "authors": ["Chibuike E. Ugwu", "Roschelle Fritz", "Diane J. Cook", "Janardhan Rao Doppa"], "title": "Clinician-in-the-Loop Smart Home System to Detect Urinary Tract Infection Flare-Ups via Uncertainty-Aware Decision Support", "comment": "Accepted for publication at IAAI-26 / AAAI-26", "summary": "Urinary tract infection (UTI) flare-ups pose a significant health risk for older adults with chronic conditions. These infections often go unnoticed until they become severe, making early detection through innovative smart home technologies crucial. Traditional machine learning (ML) approaches relying on simple binary classification for UTI detection offer limited utility to nurses and practitioners as they lack insight into prediction uncertainty, hindering informed clinical decision-making. This paper presents a clinician-in-the-loop (CIL) smart home system that leverages ambient sensor data to extract meaningful behavioral markers, train robust predictive ML models, and calibrate them to enable uncertainty-aware decision support. The system incorporates a statistically valid uncertainty quantification method called Conformal-Calibrated Interval (CCI), which quantifies uncertainty and abstains from making predictions (\"I don't know\") when the ML model's confidence is low. Evaluated on real-world data from eight smart homes, our method outperforms baseline methods in recall and other classification metrics while maintaining the lowest abstention proportion and interval width. A survey of 42 nurses confirms that our system's outputs are valuable for guiding clinical decision-making, underscoring their practical utility in improving informed decisions and effectively managing UTIs and other condition flare-ups in older adults.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e34\u5e8a\u533b\u751f\u5728\u73af\u7684\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\uff0c\u5229\u7528\u73af\u5883\u4f20\u611f\u5668\u6570\u636e\u63d0\u53d6\u884c\u4e3a\u6807\u8bb0\uff0c\u8bad\u7ec3\u7a33\u5065\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u8001\u5e74\u4eba\u5c3f\u8def\u611f\u67d3\u53d1\u4f5c\u98ce\u9669\u9ad8\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u51b3\u7b56\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u4e34\u5e8a\u533b\u751f\u5728\u73af\u7684\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\uff0c\u7ed3\u5408\u73af\u5883\u4f20\u611f\u5668\u6570\u636e\u63d0\u53d6\u884c\u4e3a\u6807\u8bb0\uff0c\u4f7f\u7528Conformal-Calibrated Interval\u65b9\u6cd5\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5728\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4f4e\u65f6\u653e\u5f03\u9884\u6d4b\u3002", "result": "\u57288\u4e2a\u771f\u5b9e\u667a\u80fd\u5bb6\u5c45\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u7b49\u5206\u7c7b\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u4f4e\u7684\u653e\u5f03\u6bd4\u4f8b\u548c\u533a\u95f4\u5bbd\u5ea6\u300242\u540d\u62a4\u58eb\u7684\u8c03\u67e5\u8bc1\u5b9e\u4e86\u7cfb\u7edf\u7684\u4e34\u5e8a\u4ef7\u503c\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u51b3\u7b56\u652f\u6301\uff0c\u6709\u6548\u6539\u5584\u4e86\u8001\u5e74\u4eba\u5c3f\u8def\u611f\u67d3\u548c\u5176\u4ed6\u75c5\u75c7\u53d1\u4f5c\u7684\u7ba1\u7406\u548c\u4e34\u5e8a\u51b3\u7b56\u3002"}}
{"id": "2511.18138", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18138", "abs": "https://arxiv.org/abs/2511.18138", "authors": ["Junrui Zhang", "Xinyu Zhao", "Jie Peng", "Chenjie Wang", "Jianmin Ji", "Tianlong Chen"], "title": "Vulnerability-Aware Robust Multimodal Adversarial Training", "comment": "Accepted by AAAI26", "summary": "Multimodal learning has shown significant superiority on various tasks by integrating multiple modalities. However, the interdependencies among modalities increase the susceptibility of multimodal models to adversarial attacks. Existing methods mainly focus on attacks on specific modalities or indiscriminately attack all modalities. In this paper, we find that these approaches ignore the differences between modalities in their contribution to final robustness, resulting in suboptimal robustness performance. To bridge this gap, we introduce Vulnerability-Aware Robust Multimodal Adversarial Training (VARMAT), a probe-in-training adversarial training method that improves multimodal robustness by identifying the vulnerability of each modality. To be specific, VARMAT first explicitly quantifies the vulnerability of each modality, grounded in a first-order approximation of the attack objective (Probe). Then, we propose a targeted regularization term that penalizes modalities with high vulnerability, guiding robust learning while maintaining task accuracy (Training). We demonstrate the enhanced robustness of our method across multiple multimodal datasets involving diverse modalities. Finally, we achieve {12.73%, 22.21%, 11.19%} robustness improvement on three multimodal datasets, revealing a significant blind spot in multimodal adversarial training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVARMAT\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u6bcf\u4e2a\u6a21\u6001\u7684\u8106\u5f31\u6027\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u6b63\u5219\u5316\uff0c\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8612.73%\u300122.21%\u548c11.19%\u7684\u9c81\u68d2\u6027\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u4e0d\u540c\u6a21\u6001\u5bf9\u6700\u7ec8\u9c81\u68d2\u6027\u7684\u8d21\u732e\u5dee\u5f02\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u6a21\u6001\u95f4\u8106\u5f31\u6027\u5dee\u5f02\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faVARMAT\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u653b\u51fb\u76ee\u6807\u7684\u4e00\u9636\u8fd1\u4f3c\u663e\u5f0f\u91cf\u5316\u6bcf\u4e2a\u6a21\u6001\u7684\u8106\u5f31\u6027\uff08\u63a2\u6d4b\u9636\u6bb5\uff09\uff1b2\uff09\u63d0\u51fa\u9488\u5bf9\u9ad8\u8106\u5f31\u6027\u6a21\u6001\u7684\u6b63\u5219\u5316\u9879\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u51c6\u786e\u6027\u7684\u540c\u65f6\u6307\u5bfc\u9c81\u68d2\u5b66\u4e60\uff08\u8bad\u7ec3\u9636\u6bb5\uff09\u3002", "result": "\u5728\u591a\u4e2a\u6d89\u53ca\u4e0d\u540c\u6a21\u6001\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u589e\u5f3a\u9c81\u68d2\u6027\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8612.73%\u300122.21%\u548c11.19%\u7684\u9c81\u68d2\u6027\u63d0\u5347\u3002", "conclusion": "VARMAT\u65b9\u6cd5\u63ed\u793a\u4e86\u591a\u6a21\u6001\u5bf9\u6297\u8bad\u7ec3\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u76f2\u70b9\uff0c\u901a\u8fc7\u611f\u77e5\u6a21\u6001\u8106\u5f31\u6027\u7684\u5bf9\u6297\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.18613", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18613", "abs": "https://arxiv.org/abs/2511.18613", "authors": ["Tabish Ali Rather", "S M Mahmudul Hasan Joy", "Nadezda Sukhorukova", "Federico Frascoli"], "title": "KAN vs LSTM Performance in Time Series Forecasting", "comment": "This paper compares Kolmogorov-Arnold Networks (KANs) and LSTMs for forecasting stock prices, highlighting that LSTMs provide superior predictive accuracy while KANs offer better interpretability and efficiency in limited-resource settings. Practical findings and future research directions are discussed", "summary": "This paper compares Kolmogorov-Arnold Networks (KAN) and Long Short-Term Memory networks (LSTM) for forecasting non-deterministic stock price data, evaluating predictive accuracy versus interpretability trade-offs using Root Mean Square Error (RMSE).LSTM demonstrates substantial superiority across all tested prediction horizons, confirming their established effectiveness for sequential data modelling. Standard KAN, while offering theoretical interpretability through the Kolmogorov-Arnold representation theorem, exhibits significantly higher error rates and limited practical applicability for time series forecasting. The results confirm LSTM dominance in accuracy-critical time series applications while identifying computational efficiency as KANs' primary advantage in resource-constrained scenarios where accuracy requirements are less stringent. The findings support LSTM adoption for practical financial forecasting while suggesting that continued research into specialised KAN architectures may yield future improvements.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86KAN\u548cLSTM\u5728\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0LSTM\u5728\u6240\u6709\u9884\u6d4b\u65f6\u95f4\u8de8\u5ea6\u4e0a\u90fd\u663e\u8457\u4f18\u4e8eKAN\uff0c\u51c6\u786e\u5ea6\u66f4\u9ad8\uff0c\u800cKAN\u867d\u7136\u5728\u7406\u8bba\u4e0a\u5177\u6709\u53ef\u89e3\u91ca\u6027\u4f18\u52bf\uff0c\u4f46\u5b9e\u9645\u9884\u6d4b\u8bef\u5dee\u8f83\u5927\u3002", "motivation": "\u7814\u7a76KAN\u548cLSTM\u5728\u975e\u786e\u5b9a\u6027\u80a1\u7968\u4ef7\u683c\u6570\u636e\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u9884\u6d4b\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "method": "\u4f7f\u7528\u5747\u65b9\u6839\u8bef\u5dee(RMSE)\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u6bd4\u8f83KAN\u548cLSTM\u5728\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u8de8\u5ea6\u4e0a\u7684\u9884\u6d4b\u6027\u80fd\u3002", "result": "LSTM\u5728\u6240\u6709\u6d4b\u8bd5\u7684\u9884\u6d4b\u65f6\u95f4\u8de8\u5ea6\u4e0a\u90fd\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u800c\u6807\u51c6KAN\u663e\u793a\u51fa\u660e\u663e\u66f4\u9ad8\u7684\u8bef\u5dee\u7387\u548c\u6709\u9650\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "LSTM\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5e94\u7528\u4e2d\u5177\u6709\u4e3b\u5bfc\u5730\u4f4d\uff0c\u800cKAN\u7684\u4e3b\u8981\u4f18\u52bf\u5728\u4e8e\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u4f46\u7cbe\u5ea6\u8981\u6c42\u4e0d\u9ad8\u7684\u573a\u666f\u3002"}}
{"id": "2511.18157", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18157", "abs": "https://arxiv.org/abs/2511.18157", "authors": ["Martin Schuck", "Alexander von Rohr", "Angela P. Schoellig"], "title": "scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python", "comment": "Accepted as oral at the 1st Workshop on Differentiable Systems and Scientific Machine Learning @ EurIPS 2025", "summary": "Three-dimensional rigid-body transforms, i.e. rotations and translations, are central to modern differentiable machine learning pipelines in robotics, vision, and simulation. However, numerically robust and mathematically correct implementations, particularly on SO(3), are error-prone due to issues such as axis conventions, normalizations, composition consistency and subtle errors that only appear in edge cases. SciPy's spatial.transform module is a rigorously tested Python implementation. However, it historically only supported NumPy, limiting adoption in GPU-accelerated and autodiff-based workflows. We present a complete overhaul of SciPy's spatial.transform functionality that makes it compatible with any array library implementing the Python array API, including JAX, PyTorch, and CuPy. The revised implementation preserves the established SciPy interface while enabling GPU/TPU execution, JIT compilation, vectorized batching, and differentiation via native autodiff of the chosen backend. We demonstrate how this foundation supports differentiable scientific computing through two case studies: (i) scalability of 3D transforms and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation for accurate integration of rotational dynamics. Our contributions have been merged into SciPy main and will ship in the next release, providing a framework-agnostic, production-grade basis for 3D spatial math in differentiable systems and ML.", "AI": {"tldr": "\u672c\u6587\u5bf9SciPy\u7684spatial.transform\u6a21\u5757\u8fdb\u884c\u4e86\u5168\u9762\u91cd\u6784\uff0c\u4f7f\u5176\u517c\u5bb9\u6240\u6709\u5b9e\u73b0Python\u6570\u7ec4API\u7684\u5e93\uff08\u5982JAX\u3001PyTorch\u3001CuPy\uff09\uff0c\u652f\u6301GPU/TPU\u6267\u884c\u3001JIT\u7f16\u8bd1\u3001\u5411\u91cf\u5316\u6279\u5904\u7406\u548c\u81ea\u52a8\u5fae\u5206\uff0c\u4e3a\u53ef\u5fae\u5206\u7cfb\u7edf\u4e2d\u76843D\u7a7a\u95f4\u6570\u5b66\u63d0\u4f9b\u4e86\u6846\u67b6\u65e0\u5173\u7684\u751f\u4ea7\u7ea7\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684SciPy spatial.transform\u6a21\u5757\u4ec5\u652f\u6301NumPy\uff0c\u9650\u5236\u4e86\u5728GPU\u52a0\u901f\u548c\u81ea\u52a8\u5fae\u5206\u5de5\u4f5c\u6d41\u4e2d\u7684\u91c7\u7528\u3002\u4e09\u7ef4\u521a\u4f53\u53d8\u6362\u5728\u73b0\u4ee3\u53ef\u5fae\u5206\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6570\u503c\u9c81\u68d2\u4e14\u6570\u5b66\u6b63\u786e\u7684\u5b9e\u73b0\u5bb9\u6613\u51fa\u9519\u3002", "method": "\u5bf9SciPy\u7684spatial.transform\u529f\u80fd\u8fdb\u884c\u5b8c\u6574\u91cd\u6784\uff0c\u4f7f\u5176\u517c\u5bb9\u4efb\u4f55\u5b9e\u73b0Python\u6570\u7ec4API\u7684\u5e93\uff0c\u540c\u65f6\u4fdd\u7559\u5df2\u5efa\u7acb\u7684SciPy\u63a5\u53e3\u3002", "result": "\u91cd\u6784\u540e\u7684\u5b9e\u73b0\u652f\u6301GPU/TPU\u6267\u884c\u3001JIT\u7f16\u8bd1\u3001\u5411\u91cf\u5316\u6279\u5904\u7406\u548c\u901a\u8fc7\u540e\u7aef\u539f\u751f\u81ea\u52a8\u5fae\u5206\u8fdb\u884c\u5fae\u5206\u3002\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5728\u53ef\u5fae\u5206\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u8be5\u8d21\u732e\u5df2\u5408\u5e76\u5230SciPy\u4e3b\u5206\u652f\uff0c\u5c06\u5728\u4e0b\u4e00\u4e2a\u7248\u672c\u4e2d\u53d1\u5e03\uff0c\u4e3a\u53ef\u5fae\u5206\u7cfb\u7edf\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u76843D\u7a7a\u95f4\u6570\u5b66\u63d0\u4f9b\u4e86\u6846\u67b6\u65e0\u5173\u3001\u751f\u4ea7\u7ea7\u7684\u57fa\u7840\u3002"}}
{"id": "2511.18630", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.18630", "abs": "https://arxiv.org/abs/2511.18630", "authors": ["Amin Rakhsha", "Kanika Madan", "Tianyu Zhang", "Amir-massoud Farahmand", "Amir Khasahmadi"], "title": "Majority of the Bests: Improving Best-of-N via Bootstrapping", "comment": null, "summary": "Sampling multiple outputs from a Large Language Model (LLM) and selecting the most frequent (Self-consistency) or highest-scoring (Best-of-N) candidate is a popular approach to achieve higher accuracy in tasks with discrete final answers. Best-of-N (BoN) selects the output with the highest reward, and with perfect rewards, it often achieves near-perfect accuracy. With imperfect rewards from reward models, however, BoN fails to reliably find the correct answer and its performance degrades drastically. We consider the distribution of BoN's outputs and highlight that, although the correct answer does not usually have a probability close to one under imperfect rewards, it is often the most likely outcome. This suggests that the mode of this distribution can be more reliably correct than a sample from it. Based on this idea, we propose Majority-of-the-Bests (MoB), a novel selection mechanism that estimates the output distribution of BoN via bootstrapping and selects its mode. Experimental results across five benchmarks, three different base LLMs, and two reward models demonstrate consistent improvements over BoN in 25 out of 30 setups. We also provide theoretical results for the consistency of the bootstrapping. MoB serves as a simple, yet strong alternative to BoN and self-consistency, and more broadly, motivates further research in more nuanced selection mechanisms.", "AI": {"tldr": "\u63d0\u51faMajority-of-the-Bests (MoB)\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a9\u91c7\u6837\u4f30\u8ba1BoN\u7684\u8f93\u51fa\u5206\u5e03\u5e76\u9009\u62e9\u5176\u4f17\u6570\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4BoN\u548cSelf-consistency\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\u3002", "motivation": "Best-of-N (BoN)\u65b9\u6cd5\u5728\u5956\u52b1\u6a21\u578b\u4e0d\u5b8c\u7f8e\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u867d\u7136\u6b63\u786e\u7b54\u6848\u7684\u6982\u7387\u4e0d\u9ad8\u4f46\u901a\u5e38\u662f\u6700\u53ef\u80fd\u7684\u7ed3\u679c\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u53ef\u9760\u7684\u8f93\u51fa\u9009\u62e9\u673a\u5236\u3002", "method": "MoB\u901a\u8fc7\u81ea\u52a9\u91c7\u6837\u4f30\u8ba1BoN\u7684\u8f93\u51fa\u5206\u5e03\uff0c\u7136\u540e\u9009\u62e9\u8be5\u5206\u5e03\u7684\u4f17\u6570\u4f5c\u4e3a\u6700\u7ec8\u8f93\u51fa\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u5730\u9009\u62e9\u6700\u9ad8\u5956\u52b1\u7684\u8f93\u51fa\u3002", "result": "\u57285\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u30013\u79cd\u57fa\u7840LLM\u548c2\u79cd\u5956\u52b1\u6a21\u578b\u768430\u4e2a\u8bbe\u7f6e\u4e2d\uff0cMoB\u572825\u4e2a\u8bbe\u7f6e\u4e2d\u76f8\u6bd4BoN\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\u3002", "conclusion": "MoB\u4e3aBoN\u548cSelf-consistency\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u5f3a\u5927\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u6fc0\u52b1\u5bf9\u66f4\u7ec6\u81f4\u9009\u62e9\u673a\u5236\u7684\u7814\u7a76\u3002"}}
{"id": "2511.18158", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.18158", "abs": "https://arxiv.org/abs/2511.18158", "authors": ["Abdelrahman Abdelmotlb", "Abdallah Taman", "Sherif Mostafa", "Moustafa Youssef"], "title": "LocaGen: Low-Overhead Indoor Localization Through Spatial Augmentation", "comment": "Accepted at GeoIndustry @ ACM SIGSPATIAL 2025 (The 4th International Workshop on Spatial Big Data and AI for Industrial Applications)", "summary": "Indoor localization systems commonly rely on fingerprinting, which requires extensive survey efforts to obtain location-tagged signal data, limiting their real-world deployability. Recent approaches that attempt to reduce this overhead either suffer from low representation ability, mode collapse issues, or require the effort of collecting data at all target locations. We present LocaGen, a novel spatial augmentation framework that significantly reduces fingerprinting overhead by generating high-quality synthetic data at completely unseen locations. LocaGen leverages a conditional diffusion model guided by a novel spatially aware optimization strategy to synthesize realistic fingerprints at unseen locations using only a subset of seen locations. To further improve our diffusion model performance, LocaGen augments seen location data based on domain-specific heuristics and strategically selects the seen and unseen locations using a novel density-based approach that ensures robust coverage. Our extensive evaluation on a real-world WiFi fingerprinting dataset shows that LocaGen maintains the same localization accuracy even with 30% of the locations unseen and achieves up to 28% improvement in accuracy over state-of-the-art augmentation methods.", "AI": {"tldr": "LocaGen\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u7a7a\u95f4\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u6761\u4ef6\u6269\u6563\u6a21\u578b\u751f\u6210\u672a\u89c1\u8fc7\u4f4d\u7f6e\u7684\u9ad8\u8d28\u91cf\u5408\u6210\u6307\u7eb9\u6570\u636e\uff0c\u663e\u8457\u51cf\u5c11\u5ba4\u5185\u5b9a\u4f4d\u7cfb\u7edf\u7684\u6307\u7eb9\u91c7\u96c6\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u6307\u7eb9\u5b9a\u4f4d\u7cfb\u7edf\u9700\u8981\u5927\u91cf\u4f4d\u7f6e\u6807\u8bb0\u4fe1\u53f7\u6570\u636e\u91c7\u96c6\uff0c\u90e8\u7f72\u6210\u672c\u9ad8\u3002\u73b0\u6709\u51cf\u5c11\u91c7\u96c6\u5f00\u9500\u7684\u65b9\u6cd5\u5b58\u5728\u8868\u793a\u80fd\u529b\u4f4e\u3001\u6a21\u5f0f\u5d29\u6e83\u6216\u4ecd\u9700\u5728\u6240\u6709\u76ee\u6807\u4f4d\u7f6e\u91c7\u96c6\u6570\u636e\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7ed3\u5408\u7a7a\u95f4\u611f\u77e5\u4f18\u5316\u7b56\u7565\uff0c\u4ec5\u57fa\u4e8e\u90e8\u5206\u5df2\u89c1\u4f4d\u7f6e\u751f\u6210\u672a\u89c1\u8fc7\u4f4d\u7f6e\u7684\u5408\u6210\u6307\u7eb9\u6570\u636e\uff1b\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u542f\u53d1\u5f0f\u65b9\u6cd5\u589e\u5f3a\u5df2\u89c1\u4f4d\u7f6e\u6570\u636e\uff1b\u91c7\u7528\u57fa\u4e8e\u5bc6\u5ea6\u7684\u7b56\u7565\u9009\u62e9\u5df2\u89c1\u548c\u672a\u89c1\u4f4d\u7f6e\u4ee5\u786e\u4fdd\u9c81\u68d2\u8986\u76d6\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754cWiFi\u6307\u7eb9\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cLocaGen\u572830%\u4f4d\u7f6e\u672a\u89c1\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u6301\u76f8\u540c\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u589e\u5f3a\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe28%\u3002", "conclusion": "LocaGen\u6846\u67b6\u80fd\u663e\u8457\u51cf\u5c11\u6307\u7eb9\u91c7\u96c6\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u9ad8\u90e8\u7f72\u53ef\u884c\u6027\uff0c\u4e3a\u5ba4\u5185\u5b9a\u4f4d\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18643", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18643", "abs": "https://arxiv.org/abs/2511.18643", "authors": ["Haojun Xia", "Xiaoxia Wu", "Jisen Li", "Robert Wu", "Junxiong Wang", "Jue Wang", "Chenxi Li", "Aman Singhal", "Alay Dilipbhai Shah", "Alpay Ariyak", "Donglin Zhuang", "Zhongzhu Zhou", "Ben Athiwaratkun", "Zhen Zheng", "Shuaiwen Leon Song"], "title": "Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic Channel-wise Precision Boost", "comment": null, "summary": "The KV cache is a dominant memory bottleneck for LLM inference. While 4-bit KV quantization preserves accuracy, 2-bit often degrades it, especially on long-context reasoning. We close this gap via an algorithm-system co-design for mixed-precision KV caching: Kitty. On the algorithm side, extensive experiments show that Dynamic Channel-wise Precision Boost -- which ranks Key-cache channels by sensitivity and keeps only a small fraction at higher precision -- maintains near-zero loss in accuracy drop while approaching 2-bit memory. The main challenge is handling dynamic 4-bit channel boosts while keeping the page layout coalesced and the dequantization uniform, with no scattered reads or hard-coded masks. Kitty addresses these issues by decompose each mixed-precision Key page into two tensors with unified 2-bit precision. Based on this, Kitty provides a page-centric KV layout, Triton-compatible page dequantization kernels, and a lightweight runtime pipeline that preserves coalescing and avoids divergence. Across seven tasks and two model families (Qwen3, LLaMA3), Kitty cuts KV memory by nearly 8x with negligible accuracy loss, enabling up to 8x larger batches and 2.1x-4.1x higher throughput under the same memory budget. We release the full implementation of Kitty at https://github.com/Summer-Summer/Kitty.", "AI": {"tldr": "Kitty\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u6df7\u5408\u7cbe\u5ea6KV\u7f13\u5b58\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5c06KV\u5185\u5b58\u51cf\u5c11\u8fd18\u500d\uff0c\u63d0\u5347\u63a8\u7406\u541e\u5410\u91cf2.1-4.1\u500d\u3002", "motivation": "KV\u7f13\u5b58\u662fLLM\u63a8\u7406\u7684\u4e3b\u8981\u5185\u5b58\u74f6\u9888\uff0c4\u4f4dKV\u91cf\u5316\u80fd\u4fdd\u6301\u51c6\u786e\u6027\u4f462\u4f4d\u91cf\u5316\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u52a8\u6001\u901a\u9053\u7cbe\u5ea6\u63d0\u5347\u7b97\u6cd5\uff0c\u6309\u654f\u611f\u5ea6\u5bf9Key\u7f13\u5b58\u901a\u9053\u6392\u5e8f\uff0c\u4ec5\u4fdd\u7559\u5c0f\u90e8\u5206\u9ad8\u7cbe\u5ea6\u901a\u9053\uff1b\u7cfb\u7edf\u5c42\u9762\u63d0\u4f9b\u9875\u9762\u4e2d\u5fc3KV\u5e03\u5c40\u3001Triton\u517c\u5bb9\u7684\u89e3\u91cf\u5316\u5185\u6838\u548c\u8f7b\u91cf\u7ea7\u8fd0\u884c\u65f6\u7ba1\u9053\u3002", "result": "\u57287\u4e2a\u4efb\u52a1\u548c2\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\uff0cKitty\u5c06KV\u5185\u5b58\u51cf\u5c11\u8fd18\u500d\uff0c\u51c6\u786e\u7387\u635f\u5931\u53ef\u5ffd\u7565\uff0c\u5728\u76f8\u540c\u5185\u5b58\u9884\u7b97\u4e0b\u5b9e\u73b08\u500d\u66f4\u5927\u6279\u6b21\u548c2.1-4.1\u500d\u66f4\u9ad8\u541e\u5410\u91cf\u3002", "conclusion": "Kitty\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6df7\u5408\u7cbe\u5ea6KV\u7f13\u5b58\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u9700\u6c42\u5e76\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2511.18159", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18159", "abs": "https://arxiv.org/abs/2511.18159", "authors": ["Mengni Jia", "Mengyu Zhou", "Yihao Liu", "Xiaoxi Jiang", "Guanjun Jiang"], "title": "Bringing Stability to Diffusion: Decomposing and Reducing Variance of Training Masked Diffusion Models", "comment": null, "summary": "Masked diffusion models (MDMs) are a promising alternative to autoregressive models (ARMs), but they suffer from inherently much higher training variance. High variance leads to noisier gradient estimates and unstable optimization, so even equally strong pretrained MDMs and ARMs that are competitive at initialization often diverge after task-specific training, with MDMs falling far behind. There has been no theoretical explanation or systematic solution. We derive the first decomposition of MDM training variance into three sources: (A) masking pattern noise, (B) masking rate noise, and (C) data noise, while ARMs are only affected by (C). This explains the fundamental training gap. Building on this foundation, we design six variance-reduction methods, including two core methods: (1) P-POTS, a Pareto-optimal t sampler that minimizes training variance by sampling harder t values more often with appropriately smaller update steps, and (2) MIRROR, which uses negatively correlated samples to reduce (A). Experiments show that compared to standard MDM training, our methods improve accuracy by 7-8% on complex reasoning tasks, while simultaneously reducing run-to-run variability to near ARM levels, substantially narrowing the gap with strong ARM baselines; in most settings, even the best baseline runs remain below the worst run of our method.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u63a9\u7801\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u65b9\u5dee\u9ad8\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6838\u5fc3\u65b9\u5dee\u964d\u4f4e\u65b9\u6cd5P-POTS\u548cMIRROR\uff0c\u663e\u8457\u63d0\u5347\u4e86MDM\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u63a9\u7801\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6709\u524d\u666f\u66ff\u4ee3\u65b9\u6848\uff0c\u5b58\u5728\u8bad\u7ec3\u65b9\u5dee\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u68af\u5ea6\u4f30\u8ba1\u566a\u58f0\u5927\u3001\u4f18\u5316\u4e0d\u7a33\u5b9a\uff0c\u5373\u4f7f\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u5728\u521d\u59cb\u5316\u65f6\u6027\u80fd\u76f8\u5f53\uff0c\u5728\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u540e\u4e5f\u4f1a\u5927\u5e45\u843d\u540e\u3002", "method": "1) \u9996\u6b21\u5c06MDM\u8bad\u7ec3\u65b9\u5dee\u5206\u89e3\u4e3a\u4e09\u4e2a\u6765\u6e90\uff1a\u63a9\u7801\u6a21\u5f0f\u566a\u58f0\u3001\u63a9\u7801\u7387\u566a\u58f0\u548c\u6570\u636e\u566a\u58f0\uff1b2) \u8bbe\u8ba1\u4e86\u516d\u79cd\u65b9\u5dee\u964d\u4f4e\u65b9\u6cd5\uff0c\u6838\u5fc3\u5305\u62ecP-POTS\uff08\u5e15\u7d2f\u6258\u6700\u4f18t\u91c7\u6837\u5668\uff09\u548cMIRROR\uff08\u4f7f\u7528\u8d1f\u76f8\u5173\u6837\u672c\u51cf\u5c11\u63a9\u7801\u6a21\u5f0f\u566a\u58f0\uff09\u3002", "result": "\u76f8\u6bd4\u6807\u51c6MDM\u8bad\u7ec3\uff0c\u65b0\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u63d0\u53477-8%\uff0c\u540c\u65f6\u5c06\u8fd0\u884c\u95f4\u53d8\u5f02\u6027\u964d\u4f4e\u5230\u63a5\u8fd1ARM\u6c34\u5e73\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u5f3aARM\u57fa\u7ebf\u7684\u5dee\u8ddd\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u7cfb\u7edf\u6027\u7684\u65b9\u5dee\u964d\u4f4e\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86MDM\u8bad\u7ec3\u65b9\u5dee\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u4f7f\u5176\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u7684\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2511.18178", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18178", "abs": "https://arxiv.org/abs/2511.18178", "authors": ["Shrenik Zinage", "Peter Meckl", "Ilias Bilionis"], "title": "Bayesian Calibration of Engine-out NOx Models for Engine-to-Engine Transferability", "comment": null, "summary": "Accurate prediction of engine-out NOx is essential for meeting stringent emissions regulations and optimizing engine performance. Traditional approaches rely on models trained on data from a small number of engines, which can be insufficient in generalizing across an entire population of engines due to sensor biases and variations in input conditions. In real world applications, these models require tuning or calibration to maintain acceptable error tolerance when applied to other engines. This highlights the need for models that can adapt with minimal adjustments to accommodate engine-to-engine variability and sensor discrepancies. While previous studies have explored machine learning methods for predicting engine-out NOx, these approaches often fail to generalize reliably across different engines and operating environments. To address these issues, we propose a Bayesian calibration framework that combines Gaussian processes with approximate Bayesian computation to infer and correct sensor biases. Starting with a pre-trained model developed using nominal engine data, our method identifies engine specific sensor biases and recalibrates predictions accordingly. By incorporating these inferred biases, our approach generates posterior predictive distributions for engine-out NOx on unseen test data, achieving high accuracy without retraining the model. Our results demonstrate that this transferable modeling approach significantly improves the accuracy of predictions compared to conventional non-adaptive GP models, effectively addressing engine-to-engine variability and improving model generalizability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8d1d\u53f6\u65af\u6821\u51c6\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u548c\u8fd1\u4f3c\u8d1d\u53f6\u65af\u8ba1\u7b97\u6765\u63a8\u65ad\u548c\u6821\u6b63\u4f20\u611f\u5668\u504f\u5dee\uff0c\u4ee5\u63d0\u9ad8\u53d1\u52a8\u673aNOx\u6392\u653e\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5c11\u91cf\u53d1\u52a8\u673a\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u96be\u4ee5\u6cdb\u5316\u5230\u6574\u4e2a\u53d1\u52a8\u673a\u7fa4\u4f53\uff0c\u5b58\u5728\u4f20\u611f\u5668\u504f\u5dee\u548c\u8f93\u5165\u6761\u4ef6\u53d8\u5316\u95ee\u9898\uff0c\u9700\u8981\u80fd\u591f\u9002\u5e94\u53d1\u52a8\u673a\u95f4\u5dee\u5f02\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u6821\u51c6\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u548c\u8fd1\u4f3c\u8d1d\u53f6\u65af\u8ba1\u7b97\uff0c\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u51fa\u53d1\u63a8\u65ad\u53d1\u52a8\u673a\u7279\u5b9a\u4f20\u611f\u5668\u504f\u5dee\u5e76\u91cd\u65b0\u6821\u51c6\u9884\u6d4b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u672a\u89c1\u6d4b\u8bd5\u6570\u636e\u4e0a\u751f\u6210\u53d1\u52a8\u673aNOx\u6392\u653e\u7684\u540e\u9a8c\u9884\u6d4b\u5206\u5e03\uff0c\u76f8\u6bd4\u4f20\u7edf\u975e\u81ea\u9002\u5e94\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u53ef\u8f6c\u79fb\u5efa\u6a21\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u53d1\u52a8\u673a\u95f4\u53d8\u5f02\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002"}}
{"id": "2511.18692", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.18692", "abs": "https://arxiv.org/abs/2511.18692", "authors": ["Kichang Yang", "Seonjun Kim", "Minjae Kim", "Nairan Zhang", "Chi Zhang", "Youngki Lee"], "title": "VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model via Neuron Chunking", "comment": null, "summary": "Edge deployment of large Vision-Language Models (VLMs) increasingly relies on flash-based weight offloading, where activation sparsification is used to reduce I/O overhead. However, conventional sparsification remains model-centric, selecting neurons solely by activation magnitude and neglecting how access patterns influence flash performance. We present Neuron Chunking, an I/O-efficient sparsification strategy that operates on chunks (i.e., groups of contiguous neurons in memory) and couples neuron importance with storage access cost. The method models I/O latency through a lightweight abstraction of access contiguity and selects chunks with high utility, defined as neuron importance normalized by estimated latency. By aligning sparsification decisions with the underlying storage behavior, Neuron Chunking improves I/O efficiency by up to 4.65x and 5.76x on Jetson Orin Nano and Jetson AGX Orin, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeuron Chunking\u7684I/O\u9ad8\u6548\u7a00\u758f\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u795e\u7ecf\u5143\u91cd\u8981\u6027\u5206\u6790\u4e0e\u5b58\u50a8\u8bbf\u95ee\u6210\u672c\u76f8\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6743\u91cd\u5378\u8f7d\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7a00\u758f\u5316\u65b9\u6cd5\u4ec5\u57fa\u4e8e\u6fc0\u6d3b\u5e45\u5ea6\u9009\u62e9\u795e\u7ecf\u5143\uff0c\u5ffd\u7565\u4e86\u8bbf\u95ee\u6a21\u5f0f\u5bf9\u95ea\u5b58\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4I/O\u6548\u7387\u4f4e\u4e0b\u3002", "method": "Neuron Chunking\u65b9\u6cd5\u5728\u5185\u5b58\u4e2d\u5bf9\u8fde\u7eed\u795e\u7ecf\u5143\u8fdb\u884c\u5206\u5757\u5904\u7406\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u62bd\u8c61\u5efa\u6a21\u8bbf\u95ee\u8fde\u7eed\u6027\u6765\u4f30\u8ba1I/O\u5ef6\u8fdf\uff0c\u5e76\u9009\u62e9\u5177\u6709\u9ad8\u6548\u7528\uff08\u795e\u7ecf\u5143\u91cd\u8981\u6027\u9664\u4ee5\u4f30\u8ba1\u5ef6\u8fdf\uff09\u7684\u5757\u3002", "result": "\u5728Jetson Orin Nano\u548cJetson AGX Orin\u8bbe\u5907\u4e0a\uff0cNeuron Chunking\u5206\u522b\u5b9e\u73b0\u4e864.65\u500d\u548c5.76\u500d\u7684I/O\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7a00\u758f\u5316\u51b3\u7b56\u4e0e\u5e95\u5c42\u5b58\u50a8\u884c\u4e3a\u5bf9\u9f50\uff0cNeuron Chunking\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5927\u6a21\u578b\u7684\u6743\u91cd\u5378\u8f7d\u6027\u80fd\u3002"}}
{"id": "2511.18841", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.18841", "abs": "https://arxiv.org/abs/2511.18841", "authors": ["Mincheol Jeon", "Euinam Huh"], "title": "Federated style aware transformer aggregation of representations", "comment": null, "summary": "Personalized Federated Learning (PFL) faces persistent challenges, including domain heterogeneity from diverse client data, data imbalance due to skewed participation, and strict communication constraints. Traditional federated learning often lacks personalization, as a single global model cannot capture client-specific characteristics, leading to biased predictions and poor generalization, especially for clients with highly divergent data distributions.\n  To address these issues, we propose FedSTAR, a style-aware federated learning framework that disentangles client-specific style factors from shared content representations. FedSTAR aggregates class-wise prototypes using a Transformer-based attention mechanism, allowing the server to adaptively weight client contributions while preserving personalization.\n  Furthermore, by exchanging compact prototypes and style vectors instead of full model parameters, FedSTAR significantly reduces communication overhead. Experimental results demonstrate that combining content-style disentanglement with attention-driven prototype aggregation improves personalization and robustness in heterogeneous environments without increasing communication cost.", "AI": {"tldr": "FedSTAR\u662f\u4e00\u4e2a\u98ce\u683c\u611f\u77e5\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u5ba2\u6237\u7aef\u7279\u5b9a\u98ce\u683c\u56e0\u5b50\u548c\u5171\u4eab\u5185\u5bb9\u8868\u793a\u6765\u89e3\u51b3\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9886\u57df\u5f02\u6784\u6027\u3001\u6570\u636e\u4e0d\u5e73\u8861\u548c\u901a\u4fe1\u7ea6\u675f\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7f3a\u4e4f\u4e2a\u6027\u5316\uff0c\u5355\u4e00\u5168\u5c40\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u5ba2\u6237\u7aef\u7279\u5b9a\u7279\u5f81\uff0c\u5bfc\u81f4\u5bf9\u6709\u9ad8\u5ea6\u5f02\u6784\u6570\u636e\u5206\u5e03\u7684\u5ba2\u6237\u7aef\u4ea7\u751f\u504f\u5dee\u9884\u6d4b\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u63d0\u51faFedSTAR\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u805a\u5408\u7c7b\u539f\u578b\uff0c\u89e3\u8026\u5ba2\u6237\u7aef\u7279\u5b9a\u98ce\u683c\u56e0\u5b50\u4e0e\u5171\u4eab\u5185\u5bb9\u8868\u793a\uff0c\u901a\u8fc7\u4ea4\u6362\u7d27\u51d1\u539f\u578b\u548c\u98ce\u683c\u5411\u91cf\u800c\u975e\u5b8c\u6574\u6a21\u578b\u53c2\u6570\u6765\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u5185\u5bb9-\u98ce\u683c\u89e3\u8026\u548c\u6ce8\u610f\u529b\u9a71\u52a8\u7684\u539f\u578b\u805a\u5408\u5728\u5f02\u6784\u73af\u5883\u4e2d\u63d0\u9ad8\u4e86\u4e2a\u6027\u5316\u548c\u9c81\u68d2\u6027\uff0c\u4e14\u672a\u589e\u52a0\u901a\u4fe1\u6210\u672c\u3002", "conclusion": "FedSTAR\u901a\u8fc7\u98ce\u683c\u611f\u77e5\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86PFL\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u4fdd\u6301\u4f4e\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4e2a\u6027\u5316\u6027\u80fd\u3002"}}
{"id": "2511.18191", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18191", "abs": "https://arxiv.org/abs/2511.18191", "authors": ["Pranav Subbaraman", "Fang Sun", "Yue Yao", "Huacong Tang", "Xiao Luo", "Yizhou Sun"], "title": "Accelerating Time Series Foundation Models with Speculative Decoding", "comment": "14 pages, 7 figures", "summary": "Modern web applications--from real-time content recommendation and dynamic pricing to CDN optimization--increasingly rely on time-series forecasting to deliver personalized experiences to billions of users. Large-scale Transformer-based models have achieved state-of-the-art performance in time-series forecasting but suffer from high computational costs, limiting their deployment in latency-sensitive web applications. To address this challenge, we propose a general inference acceleration framework that adapts speculative decoding to autoregressive time-series models. Our approach employs a smaller \"draft\" model to propose future time-series patches, which are then verified in parallel by a larger \"target\" model, reducing the number of sequential forward passes required. We address key technical challenges in adapting this technique from discrete language tokens to continuous time-series distributions, including the design of acceptance criteria for multivariate Gaussian patches and practical variants that balance efficiency with accuracy. Through experiments on time series forecasting benchmarks relevant to web applications, we demonstrate significant inference speedups while maintaining competitive accuracy. The framework requires no architectural modifications to existing foundation models, making it immediately applicable to accelerate deployed time-series forecasting systems. Our implementation can be found at https://github.com/PranavSubbaraman/STRIDE", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a8\u6d4b\u89e3\u7801\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63a8\u7406\u52a0\u901f\u6846\u67b6\uff0c\u4f7f\u7528\u5c0f\u6a21\u578b\u751f\u6210\u9884\u6d4b\u7247\u6bb5\uff0c\u5927\u6a21\u578b\u5e76\u884c\u9a8c\u8bc1\uff0c\u663e\u8457\u51cf\u5c11\u987a\u5e8f\u524d\u5411\u4f20\u64ad\u6b21\u6570\uff0c\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u5927\u89c4\u6a21Transformer\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5728\u5ef6\u8fdf\u654f\u611f\u7684web\u5e94\u7528\u4e2d\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4fee\u6539\u73b0\u6709\u6a21\u578b\u67b6\u6784\u7684\u63a8\u7406\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u4f7f\u7528\u5c0f\u89c4\u6a21\"\u8349\u7a3f\"\u6a21\u578b\u751f\u6210\u672a\u6765\u65f6\u95f4\u5e8f\u5217\u7247\u6bb5\uff0c\u7136\u540e\u7528\u5927\u89c4\u6a21\"\u76ee\u6807\"\u6a21\u578b\u5e76\u884c\u9a8c\u8bc1\u8fd9\u4e9b\u7247\u6bb5\uff0c\u8bbe\u8ba1\u591a\u53d8\u91cf\u9ad8\u65af\u7247\u6bb5\u7684\u63a5\u53d7\u6807\u51c6\u548c\u5b9e\u7528\u53d8\u4f53\u6765\u5e73\u8861\u6548\u7387\u4e0e\u7cbe\u5ea6\u3002", "result": "\u5728web\u5e94\u7528\u76f8\u5173\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u63a8\u7406\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u63a8\u7406\u52a0\u901f\u65b9\u6848\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u57fa\u7840\u6a21\u578b\u67b6\u6784\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u5df2\u90e8\u7f72\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7cfb\u7edf\u3002"}}
{"id": "2511.18225", "categories": ["cs.LG", "stat.ML", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.18225", "abs": "https://arxiv.org/abs/2511.18225", "authors": ["Douglas Spencer", "Samual Nicholls", "Michele Caprio"], "title": "Adaptive Conformal Prediction for Quantum Machine Learning", "comment": "26 pages, 5 figures", "summary": "Quantum machine learning seeks to leverage quantum computers to improve upon classical machine learning algorithms. Currently, robust uncertainty quantification methods remain underdeveloped in the quantum domain, despite the critical need for reliable and trustworthy predictions. Recent work has introduced quantum conformal prediction, a framework that produces prediction sets that are guaranteed to contain the true outcome with user-specified probability. In this work, we formalise how the time-varying noise inherent in quantum processors can undermine conformal guarantees, even when calibration and test data are exchangeable. To address this challenge, we draw on Adaptive Conformal Inference, a method which maintains validity over time via repeated recalibration. We introduce Adaptive Quantum Conformal Prediction (AQCP), an algorithm which preserves asymptotic average coverage guarantees under arbitrary hardware noise conditions. Empirical studies on an IBM quantum processor demonstrate that AQCP achieves target coverage levels and exhibits greater stability than quantum conformal prediction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u91cf\u5b50\u4fdd\u5f62\u9884\u6d4b(AQCP)\u7b97\u6cd5\uff0c\u901a\u8fc7\u91cd\u590d\u6821\u51c6\u6765\u5e94\u5bf9\u91cf\u5b50\u5904\u7406\u5668\u4e2d\u7684\u65f6\u53d8\u566a\u58f0\uff0c\u5728\u4efb\u610f\u786c\u4ef6\u566a\u58f0\u6761\u4ef6\u4e0b\u4fdd\u6301\u6e10\u8fd1\u5e73\u5747\u8986\u76d6\u4fdd\u8bc1\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9700\u8981\u53ef\u9760\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u4f46\u5f53\u524d\u91cf\u5b50\u9886\u57df\u7f3a\u4e4f\u7a33\u5065\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\u3002\u91cf\u5b50\u4fdd\u5f62\u9884\u6d4b\u867d\u7136\u80fd\u63d0\u4f9b\u6982\u7387\u4fdd\u8bc1\uff0c\u4f46\u91cf\u5b50\u5904\u7406\u5668\u7684\u65f6\u53d8\u566a\u58f0\u4f1a\u7834\u574f\u5176\u4fdd\u5f62\u4fdd\u8bc1\u3002", "method": "\u57fa\u4e8e\u81ea\u9002\u5e94\u4fdd\u5f62\u63a8\u7406\u6846\u67b6\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u91cf\u5b50\u4fdd\u5f62\u9884\u6d4b(AQCP)\u7b97\u6cd5\uff0c\u901a\u8fc7\u6301\u7eed\u91cd\u65b0\u6821\u51c6\u6765\u9002\u5e94\u91cf\u5b50\u786c\u4ef6\u566a\u58f0\u7684\u53d8\u5316\u3002", "result": "\u5728IBM\u91cf\u5b50\u5904\u7406\u5668\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cAQCP\u80fd\u591f\u8fbe\u5230\u76ee\u6807\u8986\u76d6\u6c34\u5e73\uff0c\u5e76\u4e14\u6bd4\u91cf\u5b50\u4fdd\u5f62\u9884\u6d4b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "AQCP\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u91cf\u5b50\u5904\u7406\u5668\u4e2d\u7684\u65f6\u53d8\u566a\u58f0\uff0c\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2511.18871", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18871", "abs": "https://arxiv.org/abs/2511.18871", "authors": ["Jian Lu"], "title": "Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning", "comment": null, "summary": "Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4f20\u7edf\u540c\u6b65\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\u6539\u8fdb\u4e3a\u5468\u671f\u6027\u5f02\u6b65\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6570\u636e\u52a0\u8f7d\u5668\u5f15\u5165\u6539\u8fdb\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u548c\u8bad\u7ec3\u7684\u89e3\u8026\u90e8\u7f72\uff0c\u5728\u4fdd\u6301\u7b97\u6cd5\u7cbe\u5ea6\u7b49\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u4e3b\u6d41RL\u6846\u67b6\u4e2d\u63a8\u7406\u548c\u8bad\u7ec3\u901a\u5e38\u90e8\u7f72\u5728\u540c\u4e00\u8bbe\u5907\u4e0a\uff0c\u867d\u7136\u964d\u4f4e\u4e86\u6210\u672c\u4f46\u540c\u6b65\u6267\u884c\u5e26\u6765\u4e86\u8ba1\u7b97\u8026\u5408\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5e76\u53d1\u63a8\u7406\u548c\u8bad\u7ec3\uff0c\u8bad\u7ec3\u6548\u7387\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u63a8\u7406\u548c\u8bad\u7ec3\u5206\u79bb\u90e8\u7f72\u7b56\u7565\uff0c\u6539\u8fdb\u6570\u636e\u52a0\u8f7d\u5668\uff0c\u5c06\u540c\u6b65\u67b6\u6784\u8f6c\u53d8\u4e3a\u5468\u671f\u6027\u5f02\u6b65\u6846\u67b6\uff1b\u5728\u8bad\u7ec3\u9636\u6bb5\u5e94\u7528\u7edf\u4e00\u7684\u4e09\u6a21\u578b\u67b6\u6784\uff0c\u5e76\u63d0\u51fa\u5171\u4eab\u63d0\u793a\u6ce8\u610f\u529b\u63a9\u7801\u4ee5\u51cf\u5c11\u91cd\u590d\u8ba1\u7b97\u3002", "result": "\u5728NPU\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u81f3\u5c11\u4e09\u500d\u7684\u6574\u4f53\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u7b97\u6cd5\u7cbe\u5ea6\u4e0e\u540c\u6b65\u65b9\u6cd5\u5b8c\u5168\u7b49\u6548\uff0c\u4e24\u8005\u90fd\u5c5e\u4e8e\u540c\u7b56\u7565\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5468\u671f\u6027\u5f02\u6b65\u6846\u67b6\u5141\u8bb8\u6309\u9700\u72ec\u7acb\u5f39\u6027\u6269\u5c55\u5404\u7ec4\u4ef6\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6548\u7387\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18247", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.18247", "abs": "https://arxiv.org/abs/2511.18247", "authors": ["Sajad Khodadadian", "Mehrdad Moharrami"], "title": "Tail Distribution of Regret in Optimistic Reinforcement Learning", "comment": "18 pages, 0 figures", "summary": "We derive instance-dependent tail bounds for the regret of optimism-based reinforcement learning in finite-horizon tabular Markov decision processes with unknown transition dynamics. Focusing on a UCBVI-type algorithm, we characterize the tail distribution of the cumulative regret $R_K$ over $K$ episodes, rather than only its expectation or a single high-probability quantile. We analyze two natural exploration-bonus schedules: (i) a $K$-dependent scheme that explicitly incorporates the total number of episodes $K$, and (ii) a $K$-independent scheme that depends only on the current episode index. For both settings, we obtain an upper bound on $\\Pr(R_K \\ge x)$ that exhibits a distinctive two-regime structure: a sub-Gaussian tail starting from an instance-dependent scale $m_K$ up to a transition threshold, followed by a sub-Weibull tail beyond that point. We further derive corresponding instance-dependent bounds on the expected regret $\\mathbb{E}[R_K]$. The proposed algorithm depends on a tuning parameter $\u03b1$, which balances the expected regret and the range over which the regret exhibits a sub-Gaussian tail. To the best of our knowledge, our results provide one of the first comprehensive tail-regret guarantees for a standard optimistic algorithm in episodic reinforcement learning.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u57fa\u4e8e\u4e50\u89c2\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u6709\u9650\u65f6\u57df\u8868\u683c\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u9057\u61be\u5206\u5e03\u8fdb\u884c\u4e86\u5b9e\u4f8b\u76f8\u5173\u7684\u5c3e\u754c\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5176\u72ec\u7279\u7684\u53cc\u673a\u5236\u7ed3\u6784\uff1a\u4ece\u5b9e\u4f8b\u76f8\u5173\u5c3a\u5ea6m_K\u5f00\u59cb\u7684\u4e9a\u9ad8\u65af\u5c3e\u90e8\uff0c\u5230\u8fc7\u6e21\u9608\u503c\u540e\u53d8\u4e3a\u4e9a\u97e6\u5e03\u5c14\u5c3e\u90e8\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u671f\u671b\u9057\u61be\u6216\u5355\u4e00\u9ad8\u6982\u7387\u5206\u4f4d\u6570\uff0c\u7f3a\u4e4f\u5bf9\u7d2f\u79ef\u9057\u61be\u5b8c\u6574\u5c3e\u5206\u5e03\u7684\u5168\u9762\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u4e50\u89c2\u7b97\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9057\u61be\u5206\u5e03\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u91c7\u7528UCBVI\u7c7b\u578b\u7b97\u6cd5\uff0c\u5206\u6790\u4e24\u79cd\u81ea\u7136\u63a2\u7d22\u5956\u52b1\u8c03\u5ea6\u65b9\u6848\uff1a(i) \u4f9d\u8d56\u4e8e\u603b\u56de\u5408\u6570K\u7684\u65b9\u6848\uff1b(ii) \u4ec5\u4f9d\u8d56\u4e8e\u5f53\u524d\u56de\u5408\u7d22\u5f15\u7684K\u65e0\u5173\u65b9\u6848\u3002\u901a\u8fc7\u8c03\u8282\u53c2\u6570\u03b1\u6765\u5e73\u8861\u671f\u671b\u9057\u61be\u548c\u4e9a\u9ad8\u65af\u5c3e\u90e8\u7684\u8303\u56f4\u3002", "result": "\u83b7\u5f97\u4e86Pr(R_K \u2265 x)\u7684\u4e0a\u754c\uff0c\u663e\u793a\u51fa\u72ec\u7279\u7684\u53cc\u673a\u5236\u7ed3\u6784\uff1a\u5728\u5b9e\u4f8b\u76f8\u5173\u5c3a\u5ea6m_K\u5230\u8fc7\u6e21\u9608\u503c\u4e4b\u95f4\u4e3a\u4e9a\u9ad8\u65af\u5c3e\u90e8\uff0c\u8d85\u8fc7\u8be5\u9608\u503c\u540e\u4e3a\u4e9a\u97e6\u5e03\u5c14\u5c3e\u90e8\u3002\u540c\u65f6\u63a8\u5bfc\u4e86\u76f8\u5e94\u7684\u5b9e\u4f8b\u76f8\u5173\u671f\u671b\u9057\u61be\u754c\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4e3a\u6807\u51c6\u4e50\u89c2\u7b97\u6cd5\u5728\u60c5\u666f\u5f3a\u5316\u5b66\u4e60\u4e2d\u63d0\u4f9b\u5168\u9762\u5c3e\u9057\u61be\u4fdd\u8bc1\u7684\u7814\u7a76\u4e4b\u4e00\uff0c\u63ed\u793a\u4e86\u9057\u61be\u5206\u5e03\u7684\u7cbe\u7ec6\u7ed3\u6784\u7279\u5f81\uff0c\u4e3a\u7b97\u6cd5\u8bbe\u8ba1\u548c\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u6d1e\u89c1\u3002"}}
{"id": "2511.18890", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18890", "abs": "https://arxiv.org/abs/2511.18890", "authors": ["Yonggan Fu", "Xin Dong", "Shizhe Diao", "Matthijs Van keirsbilck", "Hanrong Ye", "Wonmin Byeon", "Yashaswi Karnati", "Lucas Liebenwein", "Hannah Zhang", "Nikolaus Binder", "Maksim Khadkevich", "Alexander Keller", "Jan Kautz", "Yingyan Celine Lin", "Pavlo Molchanov"], "title": "Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models", "comment": "Accepted by NeurIPS 2025", "summary": "Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u8bbe\u5907\u4e0a\u7684\u5ef6\u8fdf\u4f18\u5316\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6df1\u5ea6-\u5bbd\u5ea6\u6bd4\u548c\u7b97\u5b50\u9009\u62e9\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u5f00\u53d1\u4e86\u81ea\u52a8\u641c\u7d22\u6846\u67b6\u6765\u6784\u5efa\u6df7\u5408SLM\u67b6\u6784\uff0c\u5e76\u5f15\u5165\u6743\u91cd\u5f52\u4e00\u5316\u6280\u672f\u63d0\u5347\u8bad\u7ec3\u6548\u679c\uff0c\u6700\u7ec8\u63d0\u51fa\u7684Nemotron-Flash\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709SOTA\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u5c0f\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u4e3b\u8981\u5173\u6ce8\u53c2\u6570\u6570\u91cf\u4f18\u5316\uff0c\u4f46\u53c2\u6570\u6548\u7387\u5e76\u4e0d\u4e00\u5b9a\u8f6c\u5316\u4e3a\u5b9e\u9645\u8bbe\u5907\u4e0a\u7684\u901f\u5ea6\u63d0\u5347\u3002\u672c\u6587\u65e8\u5728\u8bc6\u522b\u5f71\u54cdSLM\u771f\u5b9e\u8bbe\u5907\u5ef6\u8fdf\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e3a\u4ee5\u5ef6\u8fdf\u4e3a\u4e3b\u8981\u8003\u8651\u56e0\u7d20\u7684SLM\u8bbe\u8ba1\u548c\u8bad\u7ec3\u63d0\u4f9b\u901a\u7528\u539f\u5219\u548c\u65b9\u6cd5\u3002", "method": "1. \u8bc6\u522b\u4e24\u4e2a\u6838\u5fc3\u67b6\u6784\u56e0\u7d20\uff1a\u6df1\u5ea6-\u5bbd\u5ea6\u6bd4\u548c\u7b97\u5b50\u9009\u62e9\uff1b2. \u7814\u7a76\u5ef6\u8fdf\u6700\u4f18\u7684\u6df1\u5ea6-\u5bbd\u5ea6\u6bd4\uff1b3. \u63a2\u7d22\u9ad8\u6548\u6ce8\u610f\u529b\u66ff\u4ee3\u65b9\u6848\uff1b4. \u6784\u5efa\u8fdb\u5316\u641c\u7d22\u6846\u67b6\u81ea\u52a8\u53d1\u73b0\u7b97\u5b50\u6700\u4f18\u7ec4\u5408\uff1b5. \u4f7f\u7528\u6743\u91cd\u5f52\u4e00\u5316\u6280\u672f\u589e\u5f3aSLM\u8bad\u7ec3\u3002", "result": "\u63d0\u51fa\u7684Nemotron-Flash\u6a21\u578b\u76f8\u6bd4Qwen3-1.7B/0.6B\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u8d85\u8fc75.5%\uff0c\u5ef6\u8fdf\u964d\u4f4e1.3\u500d/1.9\u500d\uff0c\u541e\u5410\u91cf\u63d0\u9ad818.7\u500d/45.6\u500d\uff0c\u663e\u8457\u63a8\u8fdb\u4e86\u51c6\u786e\u7387-\u6548\u7387\u524d\u6cbf\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790SLM\u5ef6\u8fdf\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\uff0c\u5e76\u5f00\u53d1\u76f8\u5e94\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u8bad\u7ec3\u65b9\u6cd5\uff0c\u672c\u6587\u6210\u529f\u6784\u5efa\u4e86\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u6a21\u578b\u7684\u65b0\u578b\u6df7\u5408SLM\u5bb6\u65cf\u3002"}}
{"id": "2511.18248", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18248", "abs": "https://arxiv.org/abs/2511.18248", "authors": ["Wei Zhen Teoh"], "title": "Coherent Multi-Agent Trajectory Forecasting in Team Sports with CausalTraj", "comment": "9 pages, 3 figures, accepted to the AI4TS Workshop at AAAI 2026", "summary": "Jointly forecasting trajectories of multiple interacting agents is a core challenge in sports analytics and other domains involving complex group dynamics. Accurate prediction enables realistic simulation and strategic understanding of gameplay evolution. Most existing models are evaluated solely on per-agent accuracy metrics (minADE, minFDE), which assess each agent independently on its best-of-k prediction. However these metrics overlook whether the model learns which predicted trajectories can jointly form a plausible multi-agent future. Many state-of-the-art models are designed and optimized primarily based on these metrics. As a result, they may underperform on joint predictions and also fail to generate coherent, interpretable multi-agent scenarios in team sports. We propose CausalTraj, a temporally causal, likelihood-based model that is built to generate jointly probable multi-agent trajectory forecasts. To better assess collective modeling capability, we emphasize joint metrics (minJADE, minJFDE) that measure joint accuracy across agents within the best generated scenario sample. Evaluated on the NBA SportVU, Basketball-U, and Football-U datasets, CausalTraj achieves competitive per-agent accuracy and the best recorded results on joint metrics, while yielding qualitatively coherent and realistic gameplay evolutions.", "AI": {"tldr": "CausalTraj\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u4e13\u6ce8\u4e8e\u751f\u6210\u8054\u5408\u6982\u7387\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\uff0c\u5728\u8054\u5408\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u5355\u667a\u80fd\u4f53\u7cbe\u5ea6\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u662f\u5426\u80fd\u591f\u5b66\u4e60\u5230\u54ea\u4e9b\u9884\u6d4b\u8f68\u8ff9\u53ef\u4ee5\u5171\u540c\u5f62\u6210\u5408\u7406\u7684\u591a\u667a\u80fd\u4f53\u672a\u6765\uff0c\u5bfc\u81f4\u5728\u8054\u5408\u9884\u6d4b\u548c\u751f\u6210\u8fde\u8d2f\u7684\u591a\u667a\u80fd\u4f53\u573a\u666f\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86CausalTraj\uff0c\u4e00\u4e2a\u65f6\u95f4\u56e0\u679c\u3001\u57fa\u4e8e\u4f3c\u7136\u5ea6\u7684\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u751f\u6210\u8054\u5408\u6982\u7387\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u3002", "result": "\u5728NBA SportVU\u3001Basketball-U\u548cFootball-U\u6570\u636e\u96c6\u4e0a\uff0cCausalTraj\u5728\u5355\u667a\u80fd\u4f53\u7cbe\u5ea6\u6307\u6807\u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u5728\u8054\u5408\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u8bb0\u5f55\u7ed3\u679c\uff0c\u540c\u65f6\u4ea7\u751f\u4e86\u8d28\u91cf\u4e0a\u8fde\u8d2f\u548c\u73b0\u5b9e\u7684\u6e38\u620f\u6f14\u5316\u3002", "conclusion": "CausalTraj\u6a21\u578b\u5728\u8054\u5408\u9884\u6d4b\u80fd\u529b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u548c\u73b0\u5b9e\u7684\u591a\u667a\u80fd\u4f53\u573a\u666f\uff0c\u5f3a\u8c03\u4e86\u8054\u5408\u8bc4\u4f30\u6307\u6807\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.18902", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18902", "abs": "https://arxiv.org/abs/2511.18902", "authors": ["Zengjie Hu", "Jiantao Qiu", "Tianyi Bai", "Haojin Yang", "Binhang Yuan", "Qi Jing", "Conghui He", "Wentao Zhang"], "title": "VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL", "comment": null, "summary": "Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \\emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \\textbf{VADE}, a \\textbf{V}ariance-\\textbf{A}ware \\textbf{D}ynamic sampling framework via online sample-level difficulty \\textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.", "AI": {"tldr": "VADE\u662f\u4e00\u4e2a\u65b9\u5dee\u611f\u77e5\u7684\u52a8\u6001\u91c7\u6837\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u6837\u672c\u96be\u5ea6\u4f30\u8ba1\u89e3\u51b3\u57fa\u4e8e\u7fa4\u4f53\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u63d0\u9ad8\u8bad\u7ec3\u4fe1\u53f7\u5e76\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u7fa4\u4f53\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff08\u5982GRPO\u548cGSPO\uff09\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5f53\u7ec4\u5185\u6240\u6709\u54cd\u5e94\u83b7\u5f97\u76f8\u540c\u5956\u52b1\u65f6\uff0c\u4f18\u52bf\u4f30\u8ba1\u4f1a\u5d29\u6e83\uff0c\u8bad\u7ec3\u4fe1\u53f7\u51cf\u5f31\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u8981\u4e48\u7f3a\u4e4f\u5b9e\u65f6\u9002\u5e94\u6027\u3002", "method": "VADE\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u4f7f\u7528Beta\u5206\u5e03\u8fdb\u884c\u5728\u7ebf\u6837\u672c\u7ea7\u96be\u5ea6\u4f30\u8ba1\u3001\u901a\u8fc7\u4f30\u8ba1\u6b63\u786e\u6982\u7387\u6700\u5927\u5316\u4fe1\u606f\u589e\u76ca\u7684Thompson\u91c7\u6837\u5668\u3001\u4ee5\u53ca\u5728\u7b56\u7565\u6f14\u5316\u4e0b\u4fdd\u6301\u7a33\u5065\u4f30\u8ba1\u7684\u53cc\u5c3a\u5ea6\u5148\u9a8c\u8870\u51cf\u673a\u5236\u3002", "result": "\u5728\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVADE\u5728\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "VADE\u80fd\u591f\u52a8\u6001\u9009\u62e9\u6700\u5177\u4fe1\u606f\u91cf\u7684\u6837\u672c\uff0c\u6709\u6548\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7ec4\u4ef6\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\u3002"}}
{"id": "2511.18903", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18903", "abs": "https://arxiv.org/abs/2511.18903", "authors": ["Kairong Luo", "Zhenbo Sun", "Haodong Wen", "Xinyu Shi", "Jiarui Cui", "Chenyi Dang", "Kaifeng Lyu", "Wenguang Chen"], "title": "How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining", "comment": null, "summary": "Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bfe\u7a0b\u5f0f\u9884\u8bad\u7ec3\u6548\u679c\u53d7\u9650\u7684\u539f\u56e0\u662f\u6570\u636e\u8d28\u91cf\u5347\u5e8f\u6392\u5217\u4e0e\u5b66\u4e60\u7387\u8870\u51cf\u8ba1\u5212\u4e0d\u517c\u5bb9\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7b80\u5355\u7b56\u7565\u6765\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\uff0cLLMs\u901a\u5e38\u5728\u4e0d\u540c\u8d28\u91cf\u7684\u6570\u636e\u6df7\u5408\u4e0a\u8bad\u7ec3\uff0c\u8bfe\u7a0b\u5f0f\u9884\u8bad\u7ec3\u8bd5\u56fe\u901a\u8fc7\u6309\u8d28\u91cf\u5347\u5e8f\u6392\u5217\u6570\u636e\u6765\u66f4\u597d\u5229\u7528\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u4f46\u5148\u524d\u7814\u7a76\u663e\u793a\u6539\u8fdb\u6709\u9650\u3002", "method": "\u8bc6\u522b\u4e86\u5b66\u4e60\u7387\u8870\u51cf\u8ba1\u5212\u4e0e\u8bfe\u7a0b\u5f0f\u8bad\u7ec3\u7684\u4e0d\u517c\u5bb9\u6027\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7b56\u7565\uff1a(1)\u4f7f\u7528\u66f4\u6e29\u548c\u7684\u5b66\u4e60\u7387\u8870\u51cf\u8ba1\u5212\uff1b(2)\u7528\u6a21\u578b\u5e73\u5747\u66ff\u4ee3\u5b66\u4e60\u7387\u8870\u51cf\u3002", "result": "\u7ed3\u5408\u8fd9\u4e24\u79cd\u7b56\u7565\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e73\u5747\u5f97\u5206\u6bd4\u968f\u673a\u6df7\u6d17\u63d0\u9ad8\u4e861.64%\uff0c\u57281.5B\u53c2\u6570\u6a21\u578b\u548c30B tokens\u8bad\u7ec3\u89c4\u6a21\u4e0a\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u7814\u7a76\u547c\u5401\u91cd\u65b0\u8bc4\u4f30\u8bfe\u7a0b\u5f0fLLM\u9884\u8bad\u7ec3\uff0c\u5e76\u5f3a\u8c03\u4e86\u6570\u636e\u8bfe\u7a0b\u4e0e\u4f18\u5316\u65b9\u6cd5\u534f\u540c\u8bbe\u8ba1\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.18930", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18930", "abs": "https://arxiv.org/abs/2511.18930", "authors": ["Salah Eddine Choutri", "Prajwal Chauhan", "Othmane Mazhar", "Saif Eddin Jabari"], "title": "Learning Solution Operators for Partial Differential Equations via Monte Carlo-Type Approximation", "comment": "NeurIPS 2025 Workshop on Machine Learning and the Physical Sciences", "summary": "The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight architecture for learning solution operators for parametric PDEs by directly approximating the kernel integral using a Monte Carlo approach. Unlike Fourier Neural Operators, MCNO makes no spectral or translation-invariance assumptions. The kernel is represented as a learnable tensor over a fixed set of randomly sampled points. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with low computational cost, providing a simple and practical alternative to spectral and graph-based neural operators.", "AI": {"tldr": "MCNO\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u67b6\u6784\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u76f4\u63a5\u903c\u8fd1\u6838\u79ef\u5206\u6765\u5b66\u4e60\u53c2\u6570\u5316PDE\u7684\u89e3\u7b97\u5b50\uff0c\u65e0\u9700\u8c31\u5047\u8bbe\u6216\u5e73\u79fb\u4e0d\u53d8\u6027\u5047\u8bbe\uff0c\u80fd\u591f\u5728\u591a\u79cd\u7f51\u683c\u5206\u8fa8\u7387\u4e0b\u6cdb\u5316\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u4e0d\u4f9d\u8d56\u8c31\u5047\u8bbe\u6216\u5e73\u79fb\u4e0d\u53d8\u6027\u5047\u8bbe\u7684\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7b97\u5b50\u67b6\u6784\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "method": "\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u76f4\u63a5\u903c\u8fd1\u6838\u79ef\u5206\uff0c\u6838\u8868\u793a\u4e3a\u56fa\u5b9a\u968f\u673a\u91c7\u6837\u70b9\u96c6\u4e0a\u7684\u53ef\u5b66\u4e60\u5f20\u91cf\uff0c\u65e0\u9700\u91cd\u590d\u91c7\u6837\u8bad\u7ec3\u3002", "result": "\u5728\u6807\u51c61D PDE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMCNO\u4ee5\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u7cbe\u5ea6\u3002", "conclusion": "MCNO\u4e3a\u8c31\u548c\u57fa\u4e8e\u56fe\u7684\u795e\u7ecf\u7b97\u5b50\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5177\u6709\u8f7b\u91cf\u5316\u548c\u591a\u5206\u8fa8\u7387\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.18278", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18278", "abs": "https://arxiv.org/abs/2511.18278", "authors": ["Jianqiao Zheng", "Cameron Gordon", "Yiping Ji", "Hemanth Saratchandran", "Simon Lucey"], "title": "From Tables to Signals: Revealing Spectral Adaptivity in TabPFN", "comment": null, "summary": "Task-agnostic tabular foundation models such as TabPFN have achieved impressive performance on tabular learning tasks, yet the origins of their inductive biases remain poorly understood. In this work, we study TabPFN through the lens of signal reconstruction and provide the first frequency-based analysis of its in-context learning behavior. We show that TabPFN possesses a broader effective frequency capacity than standard ReLU-MLPs, even without hyperparameter tuning. Moreover, unlike MLPs whose spectra evolve primarily over training epochs, we find that TabPFN's spectral capacity adapts directly to the number of samples provided in-context, a phenomenon we term Spectral Adaptivity. We further demonstrate that positional encoding modulates TabPFN's frequency response, mirroring classical results in implicit neural representations. Finally, we show that these properties enable TabPFN to perform training-free and hyperparameter-free image denoising, illustrating its potential as a task-agnostic implicit model. Our analysis provides new insight into the structure and inductive biases of tabular foundation models and highlights their promise for broader signal reconstruction tasks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u53f7\u91cd\u6784\u7684\u89c6\u89d2\u5206\u6790TabPFN\uff0c\u53d1\u73b0\u5176\u5177\u6709\u6bd4\u6807\u51c6ReLU-MLP\u66f4\u5bbd\u7684\u9891\u7387\u5bb9\u91cf\uff0c\u4e14\u5176\u9891\u8c31\u80fd\u529b\u80fd\u6839\u636e\u4e0a\u4e0b\u6587\u6837\u672c\u6570\u91cf\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u8fd9\u79cd\u7279\u6027\u4f7f\u5176\u80fd\u591f\u5b9e\u73b0\u65e0\u9700\u8bad\u7ec3\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u56fe\u50cf\u53bb\u566a\u4efb\u52a1\u3002", "motivation": "\u7406\u89e3\u4efb\u52a1\u65e0\u5173\u7684\u8868\u683c\u57fa\u7840\u6a21\u578b\uff08\u5982TabPFN\uff09\u7684\u5f52\u7eb3\u504f\u7f6e\u6765\u6e90\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u8868\u683c\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u4f46\u5176\u5185\u5728\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u901a\u8fc7\u4fe1\u53f7\u91cd\u6784\u548c\u9891\u7387\u5206\u6790\u7684\u65b9\u6cd5\u7814\u7a76TabPFN\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u884c\u4e3a\uff0c\u5206\u6790\u5176\u9891\u8c31\u7279\u6027\u548c\u4f4d\u7f6e\u7f16\u7801\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0TabPFN\u5177\u6709\u6bd4\u6807\u51c6ReLU-MLP\u66f4\u5bbd\u7684\u6709\u6548\u9891\u7387\u5bb9\u91cf\uff0c\u5176\u9891\u8c31\u80fd\u529b\u80fd\u6839\u636e\u4e0a\u4e0b\u6587\u6837\u672c\u6570\u91cf\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u4f4d\u7f6e\u7f16\u7801\u80fd\u8c03\u8282\u5176\u9891\u7387\u54cd\u5e94\uff0c\u8fd9\u4e9b\u7279\u6027\u4f7f\u5176\u80fd\u591f\u5b9e\u73b0\u8bad\u7ec3\u548c\u8d85\u53c2\u6570\u81ea\u7531\u7684\u56fe\u50cf\u53bb\u566a\u3002", "conclusion": "\u8be5\u5206\u6790\u4e3a\u8868\u683c\u57fa\u7840\u6a21\u578b\u7684\u7ed3\u6784\u548c\u5f52\u7eb3\u504f\u7f6e\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u7a81\u663e\u4e86\u5b83\u4eec\u5728\u66f4\u5e7f\u6cdb\u4fe1\u53f7\u91cd\u6784\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.18936", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18936", "abs": "https://arxiv.org/abs/2511.18936", "authors": ["Santhosh G S", "Saurav Prakash", "Balaraman Ravindran"], "title": "SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression", "comment": null, "summary": "Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.", "AI": {"tldr": "SWAN\u662f\u4e00\u79cd\u65e0\u9700\u5fae\u8c03\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u6b63\u4ea4\u77e9\u9635\u65cb\u8f6c\u548c\u526a\u679d\u76f4\u63a5\u538b\u7f29KV\u7f13\u5b58\uff0c\u65e0\u9700\u89e3\u538b\u7f29\u6b65\u9aa4\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b050-60%\u7684\u5185\u5b58\u8282\u7701\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u56de\u5f52\u63a8\u7406\u65f6\u9762\u4e34KV\u7f13\u5b58\u5185\u5b58\u5360\u7528\u8fc7\u5927\u7684\u74f6\u9888\uff0c\u73b0\u6709\u538b\u7f29\u6280\u672f\u5b58\u5728\u4fe1\u606f\u4e22\u5931\u3001\u56fa\u5b9a\u9650\u5236\u6216\u89e3\u538b\u7f29\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u79bb\u7ebf\u6b63\u4ea4\u77e9\u9635\u5bf9KV\u7f13\u5b58\u8fdb\u884c\u65cb\u8f6c\u548c\u526a\u679d\uff0c\u538b\u7f29\u540e\u7684\u7f13\u5b58\u76f4\u63a5\u7528\u4e8e\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u65e0\u9700\u91cd\u5efa\u6b65\u9aa4\uff0c\u5e76\u914d\u5408\u5c0f\u578b\u5bc6\u96c6\u7f13\u51b2\u533a\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSWAN\u5728\u4fdd\u6301\u63a5\u8fd1\u672a\u538b\u7f29\u57fa\u7ebf\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6bcf\u4e2atoken\u7684KV\u7f13\u5b58\u5185\u5b58\u8282\u7701\u8fbe\u523050-60%\uff0c\u4e14\u652f\u6301\u8fd0\u884c\u65f6\u53ef\u8c03\u538b\u7f29\u7ea7\u522b\u3002", "conclusion": "SWAN\u7684\u65e0\u89e3\u538b\u7f29\u8bbe\u8ba1\u3001\u9ad8\u538b\u7f29\u7387\u4e0b\u7684\u826f\u597d\u6027\u80fd\u4ee5\u53ca\u9002\u5e94\u6027\uff0c\u4f7f\u5176\u6210\u4e3a\u670d\u52a1\u957f\u4e0a\u4e0b\u6587LLMs\u7684\u5b9e\u7528\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18287", "categories": ["cs.LG", "cs.CV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.18287", "abs": "https://arxiv.org/abs/2511.18287", "authors": ["Rui Peng", "Ziru Liu", "Lingyuan Ye", "Yuxing Lu", "Boxin Shi", "Jinzhuo Wang"], "title": "TRIDENT: A Trimodal Cascade Generative Framework for Drug and RNA-Conditioned Cellular Morphology Synthesis", "comment": null, "summary": "Accurately modeling the relationship between perturbations, transcriptional responses, and phenotypic changes is essential for building an AI Virtual Cell (AIVC). However, existing methods typically constrained to modeling direct associations, such as Perturbation $\\rightarrow$ RNA or Perturbation $\\rightarrow$ Morphology, overlook the crucial causal link from RNA to morphology. To bridge this gap, we propose TRIDENT, a cascade generative framework that synthesizes realistic cellular morphology by conditioning on both the perturbation and the corresponding gene expression profile. To train and evaluate this task, we construct MorphoGene, a new dataset pairing L1000 gene expression with Cell Painting images for 98 compounds. TRIDENT significantly outperforms state-of-the-art approaches, achieving up to 7-fold improvement with strong generalization to unseen compounds. In a case study on docetaxel, we validate that RNA-guided synthesis accurately produces the corresponding phenotype. An ablation study further confirms that this RNA conditioning is essential for the model's high fidelity. By explicitly modeling transcriptome-phenome mapping, TRIDENT provides a powerful in silico tool and moves us closer to a predictive virtual cell.", "AI": {"tldr": "TRIDENT\u662f\u4e00\u4e2a\u7ea7\u8054\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u8003\u8651\u6270\u52a8\u548c\u76f8\u5e94\u57fa\u56e0\u8868\u8fbe\u8c31\u6765\u5408\u6210\u771f\u5b9e\u7684\u7ec6\u80de\u5f62\u6001\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u672a\u89c1\u5316\u5408\u7269\u4e0a\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u5efa\u6a21\u76f4\u63a5\u5173\u8054\uff08\u5982\u6270\u52a8\u2192RNA\u6216\u6270\u52a8\u2192\u5f62\u6001\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u4eceRNA\u5230\u5f62\u6001\u7684\u5173\u952e\u56e0\u679c\u8054\u7cfb\uff0c\u8fd9\u963b\u788d\u4e86\u6784\u5efaAI\u865a\u62df\u7ec6\u80de\u7684\u8fdb\u5c55\u3002", "method": "\u63d0\u51faTRIDENT\u7ea7\u8054\u751f\u6210\u6846\u67b6\uff0c\u6784\u5efa\u4e86MorphoGene\u6570\u636e\u96c6\uff08\u5305\u542b98\u79cd\u5316\u5408\u7269\u7684L1000\u57fa\u56e0\u8868\u8fbe\u4e0eCell Painting\u56fe\u50cf\u914d\u5bf9\uff09\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u6270\u52a8\u548c\u57fa\u56e0\u8868\u8fbe\u8c31\u6765\u5408\u6210\u7ec6\u80de\u5f62\u6001\u3002", "result": "TRIDENT\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe7\u500d\u7684\u6539\u8fdb\uff0c\u5bf9\u672a\u89c1\u5316\u5408\u7269\u5177\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\u3002\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86RNA\u5f15\u5bfc\u5408\u6210\u80fd\u51c6\u786e\u4ea7\u751f\u76f8\u5e94\u8868\u578b\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9eRNA\u6761\u4ef6\u5316\u5bf9\u6a21\u578b\u9ad8\u4fdd\u771f\u5ea6\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u8f6c\u5f55\u7ec4-\u8868\u578b\u7ec4\u6620\u5c04\uff0cTRIDENT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u8ba1\u7b97\u673a\u6a21\u62df\u5de5\u5177\uff0c\u4f7f\u6211\u4eec\u66f4\u63a5\u8fd1\u9884\u6d4b\u6027\u865a\u62df\u7ec6\u80de\u3002"}}
{"id": "2511.18958", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18958", "abs": "https://arxiv.org/abs/2511.18958", "authors": ["Qisen Chai", "Yansong Wang", "Junjie Huang", "Tao Jia"], "title": "Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation", "comment": null, "summary": "As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCutter\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u538b\u7f29\u56fe\u6570\u636e\uff0c\u5728\u4fdd\u6301\u62d3\u6251\u7ed3\u6784\u548c\u9c81\u68d2\u6027\u7279\u5f81\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bc4\u4f30\u6548\u7387\u3002", "motivation": "\u968f\u7740\u56fe\u7ed3\u6784\u6570\u636e\u89c4\u6a21\u4e0d\u65ad\u589e\u5927\uff0c\u8bc4\u4f30\u5176\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u53d8\u5f97\u8ba1\u7b97\u6602\u8d35\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u9ad8\u6548\u7684\u538b\u7f29\u65b9\u6cd5\u6765\u4fdd\u6301\u8bc4\u4f30\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faCutter\u53cc\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u5173\u952e\u8282\u70b9\u68c0\u6d4b\u667a\u80fd\u4f53\u548c\u5197\u4f59\u8282\u70b9\u68c0\u6d4b\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u8f68\u8ff9\u7ea7\u5956\u52b1\u5851\u9020\u3001\u539f\u578b\u5851\u9020\u548c\u8de8\u667a\u80fd\u4f53\u6a21\u4eff\u4e09\u79cd\u7b56\u7565\u6765\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u538b\u7f29\u8d28\u91cf\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u56fe\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCutter\u751f\u6210\u7684\u538b\u7f29\u56fe\u4fdd\u7559\u4e86\u5173\u952e\u9759\u6001\u62d3\u6251\u7279\u6027\uff0c\u5728\u5404\u79cd\u653b\u51fb\u573a\u666f\u4e0b\u4e0e\u539f\u56fe\u7684\u9c81\u68d2\u6027\u9000\u5316\u8d8b\u52bf\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "Cutter\u80fd\u591f\u5728\u4e0d\u635f\u5bb3\u8bc4\u4f30\u4fdd\u771f\u5ea6\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u8bc4\u4f30\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u6570\u636e\u9c81\u68d2\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18291", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.18291", "abs": "https://arxiv.org/abs/2511.18291", "authors": ["Xiaoyu Wang", "Xiaotian Li", "Zhixiang Zhou", "Chen Li", "Yong Liu"], "title": "ADF-LoRA: Alternating Low-Rank Aggregation for Decentralized Federated Fine-Tuning", "comment": "10 Pages", "summary": "This paper revisits alternating low-rank updates for federated fine-tuning and examines their behavior in decentralized federated learning (DFL). While alternating the LoRA matrices has been shown to stabilize aggregation in centralized FL, extending this mechanism to decentralized, peer-to-peer communication introduces new challenges due to phase-state mismatch and block-wise divergence across clients. We introduce ADF-LoRA, which synchronizes the update of only one low-rank matrix per round and mixes both matrices to maintain more consistent parameter states under decentralized propagation. This design preserves the cross-term suppression effect of alternating updates while improving stability in serverless topologies. We provide a convergence analysis under standard smoothness assumptions and evaluate ADF-LoRA on multiple GLUE tasks. Experiments show that ADF-LoRA achieves faster and smoother convergence and delivers the highest average accuracy across tasks, outperforming existing LoRA variants in decentralized FL by a consistent margin.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ADF-LoRA\u65b9\u6cd5\uff0c\u5728\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u901a\u8fc7\u540c\u6b65\u66f4\u65b0\u5355\u4e2a\u4f4e\u79e9\u77e9\u9635\u5e76\u6df7\u5408\u4e24\u4e2a\u77e9\u9635\u6765\u6539\u5584\u53c2\u6570\u72b6\u6001\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u901f\u5e73\u6ed1\u7684\u6536\u655b\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u4ea4\u66ff\u66f4\u65b0LoRA\u77e9\u9635\u4f1a\u56e0\u5ba2\u6237\u7aef\u95f4\u7684\u76f8\u4f4d\u72b6\u6001\u4e0d\u5339\u914d\u548c\u5757\u7ea7\u53d1\u6563\u800c\u9762\u4e34\u65b0\u7684\u6311\u6218\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u7a33\u5b9a\u7684\u53c2\u6570\u4f20\u64ad\u673a\u5236\u3002", "method": "\u63d0\u51faADF-LoRA\u65b9\u6cd5\uff0c\u6bcf\u8f6e\u4ec5\u540c\u6b65\u66f4\u65b0\u4e00\u4e2a\u4f4e\u79e9\u77e9\u9635\uff0c\u5e76\u901a\u8fc7\u6df7\u5408\u4e24\u4e2a\u77e9\u9635\u6765\u4fdd\u6301\u53c2\u6570\u72b6\u6001\u7684\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u4ea4\u66ff\u66f4\u65b0\u7684\u4ea4\u53c9\u9879\u6291\u5236\u6548\u679c\u3002", "result": "\u5728\u591a\u4e2aGLUE\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cADF-LoRA\u5b9e\u73b0\u4e86\u66f4\u5feb\u901f\u5e73\u6ed1\u7684\u6536\u655b\uff0c\u5e76\u5728\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684LoRA\u53d8\u4f53\uff0c\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002", "conclusion": "ADF-LoRA\u901a\u8fc7\u6539\u8fdb\u7684\u4ea4\u66ff\u4f4e\u79e9\u66f4\u65b0\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u670d\u52a1\u5668\u5316\u62d3\u6251\u7ed3\u6784\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18977", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18977", "abs": "https://arxiv.org/abs/2511.18977", "authors": ["Xin Yuan", "Siqi Li", "Jiateng Wei", "Chengrui Zhu", "Yanming Wu", "Qingpeng Li", "Jiajun Lv", "Xiaoke Lan", "Jun Chen", "Yong Liu"], "title": "FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning", "comment": "5 pages, 2 figures, 4 tables", "summary": "Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search's computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86FastForward\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u7684\u5355\u6b65\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u7b56\u7565\u4f18\u5316\u4e0e\u590d\u6742\u9884\u7b97\u6ee1\u8db3\u95ee\u9898\u5206\u79bb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u526a\u679d\u7684\u641c\u7d22\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u526a\u679d\u65b9\u6cd5\u9762\u4e34\u6548\u7387\u6311\u6218\uff1a\u542f\u53d1\u5f0f\u65b9\u6cd5\u5feb\u901f\u4f46\u6027\u80fd\u6b21\u4f18\uff0c\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\uff08\u5982\u5f3a\u5316\u5b66\u4e60\uff09\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9ad8\u6548\u641c\u7d22\u53c8\u80fd\u83b7\u5f97\u6700\u4f18\u6027\u80fd\u7684\u526a\u679d\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u89e3\u8026\u7684\u5355\u6b65\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u7b56\u7565\u4f18\u5316\u4e0e\u9884\u7b97\u6ee1\u8db3\u95ee\u9898\u5206\u79bb\u3002\u4f7f\u7528\u57fa\u4e8e\u8bfe\u7a0b\u5b66\u4e60\u7684\u7b56\u7565\uff0c\u4ece\u4f4e\u6210\u672c\u7b80\u5355\u4efb\u52a1\u5f00\u59cb\u9010\u6b65\u589e\u52a0\u590d\u6742\u5ea6\uff0c\u5927\u5e45\u964d\u4f4e\u641c\u7d22\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728LLaMA\u3001Mistral\u548cOPT\u6a21\u578b\u7cfb\u5217\u4e0a\u8bc4\u4f30\uff0c\u53d1\u73b0\u7684\u526a\u679d\u7b56\u7565\u4f18\u4e8e\u5f3a\u542f\u53d1\u5f0f\u57fa\u7ebf\u3002\u4e0e\u5176\u4ed6\u57fa\u4e8e\u641c\u7d22\u7684\u7b97\u6cd5\u76f8\u6bd4\uff0c\u4ee5\u6781\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6216\u66f4\u4f18\u7684\u7ed3\u679c\u3002", "conclusion": "FastForward\u526a\u679d\u65b9\u6cd5\u5728\u641c\u7d22\u6548\u7387\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u80fd\u591f\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u627e\u5230\u9ad8\u6027\u80fd\u7684\u526a\u679d\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u526a\u679d\u4e2d\u7684\u6548\u7387\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2511.19023", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19023", "abs": "https://arxiv.org/abs/2511.19023", "authors": ["Yuting Gao", "Weihao Chen", "Lan Wang", "Ruihan Xu", "Qingpei Guo"], "title": "OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs", "comment": null, "summary": "Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.", "AI": {"tldr": "OrdMoE\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u4eba\u7c7b\u6807\u6ce8\u504f\u597d\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528MoE\u67b6\u6784\u4e2d\u7684\u8def\u7531\u5668\u4e13\u5bb6\u9009\u62e9\u5206\u6570\u6765\u6784\u5efa\u5185\u90e8\u504f\u597d\u5c42\u6b21\uff0c\u5b9e\u73b0\u96f6\u6210\u672c\u7684\u81ea\u6211\u76d1\u7763\u504f\u597d\u6392\u5e8f\u3002", "motivation": "\u73b0\u6709\u7684\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5916\u90e8\u4eba\u7c7b\u6807\u6ce8\u7684\u504f\u597d\u6570\u636e\uff0c\u6536\u96c6\u6210\u672c\u9ad8\u6602\u4e14\u52b3\u52a8\u5bc6\u96c6\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4e0d\u4f9d\u8d56\u5916\u90e8\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u5229\u7528MoE\u67b6\u6784\u4e2d\u8def\u7531\u5668\u4e13\u5bb6\u9009\u62e9\u5206\u6570\u9690\u542b\u7684\u8d28\u91cf\u611f\u77e5\u7279\u6027\uff0c\u5c06\u4e13\u5bb6\u6309\u8def\u7531\u5206\u6570\u5206\u7ec4\u4e3a\u4e0d\u540c\u7b49\u7ea7\uff0c\u5206\u522b\u6fc0\u6d3b\u6bcf\u4e2a\u7b49\u7ea7\u6765\u751f\u6210\u8d28\u91cf\u9012\u589e\u7684\u54cd\u5e94\u5e8f\u5217\uff0c\u4ece\u800c\u6784\u5efa\u5185\u90e8\u504f\u597d\u5c42\u6b21\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOrdMoE\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001MoE LLMs\u7684\u5bf9\u9f50\u548c\u6574\u4f53\u6027\u80fd\uff0c\u65e0\u9700\u4efb\u4f55\u4eba\u7c7b\u6807\u6ce8\u504f\u597d\u6570\u636e\u5373\u53ef\u83b7\u5f97\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "OrdMoE\u6846\u67b6\u6210\u529f\u8bc1\u660e\u4e86\u53ef\u4ee5\u5229\u7528MoE\u67b6\u6784\u7684\u5185\u5728\u4fe1\u53f7\u5b9e\u73b0\u6709\u6548\u7684\u504f\u597d\u5bf9\u9f50\uff0c\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u96f6\u6210\u672c\u3001\u81ea\u6211\u76d1\u7763\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.19066", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19066", "abs": "https://arxiv.org/abs/2511.19066", "authors": ["Xiangyu Chang", "Manyi Yao", "Srikanth V. Krishnamurthy", "Christian R. Shelton", "Anirban Chakraborty", "Ananthram Swami", "Samet Oymak", "Amit Roy-Chowdhury"], "title": "Mitigating Participation Imbalance Bias in Asynchronous Federated Learning", "comment": null, "summary": "In Asynchronous Federated Learning (AFL), the central server immediately updates the global model with each arriving client's contribution. As a result, clients perform their local training on different model versions, causing information staleness (delay). In federated environments with non-IID local data distributions, this asynchronous pattern amplifies the adverse effect of client heterogeneity (due to different data distribution, local objectives, etc.), as faster clients contribute more frequent updates, biasing the global model. We term this phenomenon heterogeneity amplification. Our work provides a theoretical analysis that maps AFL design choices to their resulting error sources when heterogeneity amplification occurs. Guided by our analysis, we propose ACE (All-Client Engagement AFL), which mitigates participation imbalance through immediate, non-buffered updates that use the latest information available from all clients. We also introduce a delay-aware variant, ACED, to balance client diversity against update staleness. Experiments on different models for different tasks across diverse heterogeneity and delay settings validate our analysis and demonstrate the robust performance of our approaches.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5f02\u6784\u6027\u653e\u5927\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ACE\u548cACED\u65b9\u6cd5\u6765\u7f13\u89e3\u53c2\u4e0e\u4e0d\u5e73\u8861\uff0c\u901a\u8fc7\u7acb\u5373\u4f7f\u7528\u6240\u6709\u5ba2\u6237\u7aef\u7684\u6700\u65b0\u4fe1\u606f\u8fdb\u884c\u975e\u7f13\u51b2\u66f4\u65b0\u3002", "motivation": "\u5728\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u670d\u52a1\u5668\u7acb\u5373\u4f7f\u7528\u6bcf\u4e2a\u5230\u8fbe\u5ba2\u6237\u7aef\u7684\u8d21\u732e\u66f4\u65b0\u5168\u5c40\u6a21\u578b\uff0c\u5bfc\u81f4\u5ba2\u6237\u7aef\u5728\u4e0d\u540c\u6a21\u578b\u7248\u672c\u4e0a\u8fdb\u884c\u672c\u5730\u8bad\u7ec3\uff0c\u9020\u6210\u4fe1\u606f\u9648\u65e7\u3002\u5728\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\uff0c\u8fd9\u79cd\u5f02\u6b65\u6a21\u5f0f\u653e\u5927\u4e86\u5ba2\u6237\u7aef\u5f02\u6784\u6027\u7684\u4e0d\u5229\u5f71\u54cd\uff0c\u56e0\u4e3a\u66f4\u5feb\u7684\u5ba2\u6237\u7aef\u8d21\u732e\u66f4\u9891\u7e41\u7684\u66f4\u65b0\uff0c\u4f7f\u5168\u5c40\u6a21\u578b\u4ea7\u751f\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e86ACE\u65b9\u6cd5\uff0c\u901a\u8fc7\u7acb\u5373\u3001\u975e\u7f13\u51b2\u7684\u66f4\u65b0\u4f7f\u7528\u6240\u6709\u5ba2\u6237\u7aef\u7684\u6700\u65b0\u4fe1\u606f\u6765\u7f13\u89e3\u53c2\u4e0e\u4e0d\u5e73\u8861\u3002\u8fd8\u5f15\u5165\u4e86ACED\u53d8\u4f53\uff0c\u901a\u8fc7\u5ef6\u8fdf\u611f\u77e5\u673a\u5236\u6765\u5e73\u8861\u5ba2\u6237\u7aef\u591a\u6837\u6027\u4e0e\u66f4\u65b0\u9648\u65e7\u6027\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u3001\u4e0d\u540c\u4efb\u52a1\u4ee5\u53ca\u5404\u79cd\u5f02\u6784\u6027\u548c\u5ef6\u8fdf\u8bbe\u7f6e\u4e0b\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5206\u6790\u7ed3\u679c\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u80fd\u3002", "conclusion": "ACE\u548cACED\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5f02\u6784\u6027\u653e\u5927\u95ee\u9898\uff0c\u901a\u8fc7\u5e73\u8861\u5ba2\u6237\u7aef\u53c2\u4e0e\u548c\u66f4\u65b0\u65f6\u6548\u6027\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.18312", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18312", "abs": "https://arxiv.org/abs/2511.18312", "authors": ["Zihao Yao", "Jiankai Zuo", "Yaying Zhang"], "title": "DiM-TS: Bridge the Gap between Selective State Space Models and Time Series for Generative Modeling", "comment": null, "summary": "Time series data plays a pivotal role in a wide variety of fields but faces challenges related to privacy concerns. Recently, synthesizing data via diffusion models is viewed as a promising solution. However, existing methods still struggle to capture long-range temporal dependencies and complex channel interrelations. In this research, we aim to utilize the sequence modeling capability of a State Space Model called Mamba to extend its applicability to time series data generation. We firstly analyze the core limitations in State Space Model, namely the lack of consideration for correlated temporal lag and channel permutation. Building upon the insight, we propose Lag Fusion Mamba and Permutation Scanning Mamba, which enhance the model's ability to discern significant patterns during the denoising process. Theoretical analysis reveals that both variants exhibit a unified matrix multiplication framework with the original Mamba, offering a deeper understanding of our method. Finally, we integrate two variants and introduce Diffusion Mamba for Time Series (DiM-TS), a high-quality time series generation model that better preserves the temporal periodicity and inter-channel correlations. Comprehensive experiments on public datasets demonstrate the superiority of DiM-TS in generating realistic time series while preserving diverse properties of data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDiM-TS\u6a21\u578b\uff0c\u5229\u7528\u72b6\u6001\u7a7a\u95f4\u6a21\u578bMamba\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u751f\u6210\uff0c\u901a\u8fc7Lag Fusion\u548cPermutation Scanning\u589e\u5f3a\u5bf9\u957f\u671f\u4f9d\u8d56\u548c\u901a\u9053\u76f8\u5173\u6027\u7684\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u9762\u4e34\u9690\u79c1\u95ee\u9898\uff0c\u73b0\u6709\u6269\u6563\u6a21\u578b\u96be\u4ee5\u6355\u6349\u957f\u671f\u65f6\u95f4\u4f9d\u8d56\u548c\u590d\u6742\u901a\u9053\u5173\u7cfb\uff0c\u9700\u8981\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51faLag Fusion Mamba\u548cPermutation Scanning Mamba\u4e24\u79cd\u53d8\u4f53\uff0c\u5206\u6790\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5728\u65f6\u95f4\u6ede\u540e\u548c\u901a\u9053\u6392\u5217\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u96c6\u6210\u6784\u5efaDiM-TS\u6a21\u578b\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u4e24\u79cd\u53d8\u4f53\u4e0e\u539f\u59cbMamba\u5177\u6709\u7edf\u4e00\u7684\u77e9\u9635\u4e58\u6cd5\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660eDiM-TS\u80fd\u751f\u6210\u66f4\u771f\u5b9e\u7684\u65f6\u95f4\u5e8f\u5217\u5e76\u4fdd\u6301\u6570\u636e\u591a\u6837\u6027\u3002", "conclusion": "DiM-TS\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u65f6\u95f4\u5468\u671f\u6027\u548c\u901a\u9053\u95f4\u76f8\u5173\u6027\uff0c\u4e3a\u9ad8\u8d28\u91cf\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19087", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19087", "abs": "https://arxiv.org/abs/2511.19087", "authors": ["Ziyun Li", "Ben Dai", "Huancheng Hu", "Henrik Bostr\u00f6m", "Soon Hoe Lim"], "title": "EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching", "comment": "EurIPS 2025 Workshop on Principles of Generative Modeling (PriGM)", "summary": "Flow-based generative models synthesize data by integrating a learned velocity field from a reference distribution to the target data distribution. Prior work has focused on endpoint metrics (e.g., fidelity, likelihood, perceptual quality) while overlooking a deeper question: what do the sampling trajectories reveal? Motivated by classical mechanics, we introduce kinetic path energy (KPE), a simple yet powerful diagnostic that quantifies the total kinetic effort along each generation path of ODE-based samplers. Through comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that semantically richer samples require greater kinetic effort, and ({ii}) higher KPE inversely correlates with data density, with informative samples residing in sparse, low-density regions. Together, these findings reveal that semantically informative samples naturally reside on the sparse frontier of the data distribution, demanding greater generative effort. Our results suggest that trajectory-level analysis offers a physics-inspired and interpretable framework for understanding generation difficulty and sample characteristics.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u52a8\u80fd\u8def\u5f84\u80fd\u91cf(KPE)\u4f5c\u4e3a\u8bca\u65ad\u5de5\u5177\uff0c\u91cf\u5316ODE\u91c7\u6837\u5668\u751f\u6210\u8def\u5f84\u7684\u603b\u52a8\u80fd\u6d88\u8017\uff0c\u53d1\u73b0\u8bed\u4e49\u8d28\u91cf\u66f4\u9ad8\u7684\u6837\u672c\u9700\u8981\u66f4\u5927\u7684\u52a8\u80fd\u52aa\u529b\uff0c\u4e14\u4f4d\u4e8e\u6570\u636e\u5206\u5e03\u7684\u7a00\u758f\u524d\u6cbf\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u7aef\u70b9\u6307\u6807(\u5982\u4fdd\u771f\u5ea6\u3001\u4f3c\u7136\u5ea6\u3001\u611f\u77e5\u8d28\u91cf)\uff0c\u800c\u5ffd\u7565\u4e86\u91c7\u6837\u8f68\u8ff9\u6240\u63ed\u793a\u7684\u6df1\u5c42\u4fe1\u606f\u3002\u53d7\u7ecf\u5178\u529b\u5b66\u542f\u53d1\uff0c\u5e0c\u671b\u4e86\u89e3\u751f\u6210\u8def\u5f84\u7684\u52a8\u529b\u5b66\u7279\u6027\u3002", "method": "\u5f15\u5165\u52a8\u80fd\u8def\u5f84\u80fd\u91cf(KPE)\u8fd9\u4e00\u7b80\u5355\u800c\u5f3a\u5927\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u7528\u4e8e\u91cf\u5316ODE\u91c7\u6837\u5668\u6bcf\u4e2a\u751f\u6210\u8def\u5f84\u7684\u603b\u52a8\u80fd\u6d88\u8017\u3002\u5728CIFAR-10\u548cImageNet-256\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u5173\u952e\u73b0\u8c61\uff1a(i)\u66f4\u9ad8\u7684KPE\u9884\u6d4b\u66f4\u5f3a\u7684\u8bed\u4e49\u8d28\u91cf\uff0c\u8868\u660e\u8bed\u4e49\u66f4\u4e30\u5bcc\u7684\u6837\u672c\u9700\u8981\u66f4\u5927\u7684\u52a8\u80fd\u52aa\u529b\uff1b(ii)\u66f4\u9ad8\u7684KPE\u4e0e\u6570\u636e\u5bc6\u5ea6\u5448\u8d1f\u76f8\u5173\uff0c\u4fe1\u606f\u4e30\u5bcc\u7684\u6837\u672c\u4f4d\u4e8e\u7a00\u758f\u7684\u4f4e\u5bc6\u5ea6\u533a\u57df\u3002", "conclusion": "\u8bed\u4e49\u4fe1\u606f\u4e30\u5bcc\u7684\u6837\u672c\u81ea\u7136\u5730\u5b58\u5728\u4e8e\u6570\u636e\u5206\u5e03\u7684\u7a00\u758f\u524d\u6cbf\uff0c\u9700\u8981\u66f4\u5927\u7684\u751f\u6210\u52aa\u529b\u3002\u8f68\u8ff9\u7ea7\u5206\u6790\u4e3a\u7406\u89e3\u751f\u6210\u96be\u5ea6\u548c\u6837\u672c\u7279\u5f81\u63d0\u4f9b\u4e86\u7269\u7406\u542f\u53d1\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002"}}
{"id": "2511.19107", "categories": ["cs.LG", "cs.AI", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19107", "abs": "https://arxiv.org/abs/2511.19107", "authors": ["Robert Bredereck", "Eva Deltl", "Leon Kellerhals", "Jannik Peters"], "title": "The Core in Max-Loss Non-Centroid Clustering Can Be Empty", "comment": null, "summary": "We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\\geq 3$ there exist metric instances with $n\\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $\u03b1$-core for any $\u03b1<2^{\\frac{1}{5}}\\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u6700\u5927\u635f\u5931\u76ee\u6807\u4e0b\u7684\u975e\u8d28\u5fc3\u805a\u7c7b\u4e2d\u7684\u6838\u5fc3\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5bf9\u4e8ek\u22653\u7684\u60c5\u51b5\uff0c\u5b58\u5728\u5ea6\u91cf\u5b9e\u4f8b\u4f7f\u5f97\u6ca1\u6709\u4efb\u4f55\u805a\u7c7b\u4f4d\u4e8e\u03b1-\u6838\u5fc3\u4e2d\uff0c\u5176\u4e2d\u03b1<2^(1/5)\u22481.148\u3002", "motivation": "\u7814\u7a76\u975e\u8d28\u5fc3\u805a\u7c7b\u4e2d\u6838\u5fc3\u7a33\u5b9a\u6027\u7684\u5b58\u5728\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6700\u5927\u635f\u5931\u76ee\u6807\u51fd\u6570\u4e0b\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u6570\u5b66\u8bc1\u660e\u65b9\u6cd5\uff0c\u5bf9\u4e8ek\u22653\u7684\u60c5\u51b5\u6784\u9020\u4e86\u5ea6\u91cf\u5b9e\u4f8b\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u673a\u8f85\u52a9\u8bc1\u660e\u8bc6\u522b\u4e86\u4e8c\u7ef4\u6b27\u51e0\u91cc\u5f97\u70b9\u96c6\u7684\u76f8\u5173\u4e0b\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u6240\u6709k\u22653\uff0c\u5b58\u5728\u5ea6\u91cf\u5b9e\u4f8b\u4f7f\u5f97\u6ca1\u6709\u4efb\u4f55\u805a\u7c7b\u4f4d\u4e8e\u03b1-\u6838\u5fc3\u4e2d\uff0c\u5176\u4e2d\u03b1<2^(1/5)\u22481.148\uff0c\u4e14\u8be5\u754c\u9650\u5bf9\u4e8e\u6784\u9020\u662f\u7d27\u7684\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u8bc1\u660e\u5728\u6700\u5927\u635f\u5931\u76ee\u6807\u4e0b\u7684\u975e\u8d28\u5fc3\u805a\u7c7b\u4e2d\u6838\u5fc3\u53ef\u80fd\u4e3a\u7a7a\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2511.18331", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18331", "abs": "https://arxiv.org/abs/2511.18331", "authors": ["Sohini Roychowdhury", "Adam Holeman", "Mohammad Amin", "Feng Wei", "Bhaskar Mehta", "Srihari Reddy"], "title": "DynamiX: Dynamic Resource eXploration for Personalized Ad-Recommendations", "comment": "9 pages, 3 Tables, 5 images. https://openreview.net/pdf?id=oglD54lvcB", "summary": "For online ad-recommendation systems, processing complete user-ad-engagement histories is both computationally intensive and noise-prone. We introduce Dynamix, a scalable, personalized sequence exploration framework that optimizes event history processing using maximum relevance principles and self-supervised learning through Event Based Features (EBFs). Dynamix categorizes users-engagements at session and surface-levels by leveraging correlations between dwell-times and ad-conversion events. This enables targeted, event-level feature removal and selective feature boosting for certain user-segments, thereby yielding training and inference efficiency wins without sacrificing engaging ad-prediction accuracy. While, dynamic resource removal increases training and inference throughput by 1.15% and 1.8%, respectively, dynamic feature boosting provides 0.033 NE gains while boosting inference QPS by 4.2% over baseline models. These results demonstrate that Dynamix achieves significant cost efficiency and performance improvements in online user-sequence based recommendation models. Self-supervised user-segmentation and resource exploration can further boost complex feature selection strategies while optimizing for workflow and compute resources.", "AI": {"tldr": "Dynamix\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u4e2a\u6027\u5316\u5e8f\u5217\u63a2\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u76f8\u5173\u6027\u539f\u5219\u548c\u57fa\u4e8e\u4e8b\u4ef6\u7279\u5f81\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u4f18\u5316\u4e8b\u4ef6\u5386\u53f2\u5904\u7406\uff0c\u5728\u4fdd\u6301\u5e7f\u544a\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5728\u7ebf\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u5904\u7406\u5b8c\u6574\u7684\u7528\u6237-\u5e7f\u544a\u4e92\u52a8\u5386\u53f2\u8ba1\u7b97\u91cf\u5927\u4e14\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u5f71\u54cd\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5e8f\u5217\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6700\u5927\u76f8\u5173\u6027\u539f\u5219\u548c\u57fa\u4e8e\u4e8b\u4ef6\u7279\u5f81\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u5728\u4f1a\u8bdd\u548c\u8868\u9762\u7ea7\u522b\u5bf9\u7528\u6237\u4e92\u52a8\u8fdb\u884c\u5206\u7c7b\uff0c\u901a\u8fc7\u52a8\u6001\u7279\u5f81\u79fb\u9664\u548c\u9009\u62e9\u6027\u7279\u5f81\u589e\u5f3a\u6765\u4f18\u5316\u5904\u7406\u3002", "result": "\u52a8\u6001\u8d44\u6e90\u79fb\u9664\u4f7f\u8bad\u7ec3\u548c\u63a8\u7406\u541e\u5410\u91cf\u5206\u522b\u63d0\u53471.15%\u548c1.8%\uff0c\u52a8\u6001\u7279\u5f81\u589e\u5f3a\u5728\u57fa\u7ebf\u6a21\u578b\u57fa\u7840\u4e0a\u63d0\u4f9b0.033 NE\u589e\u76ca\uff0c\u540c\u65f6\u63a8\u7406QPS\u63d0\u53474.2%\u3002", "conclusion": "Dynamix\u5728\u57fa\u4e8e\u5728\u7ebf\u7528\u6237\u5e8f\u5217\u7684\u63a8\u8350\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6210\u672c\u6548\u7387\u548c\u6027\u80fd\u6539\u8fdb\uff0c\u81ea\u76d1\u7763\u7528\u6237\u5206\u6bb5\u548c\u8d44\u6e90\u63a2\u7d22\u53ef\u4ee5\u8fdb\u4e00\u6b65\u589e\u5f3a\u590d\u6742\u7279\u5f81\u9009\u62e9\u7b56\u7565\u3002"}}
{"id": "2511.19124", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19124", "abs": "https://arxiv.org/abs/2511.19124", "authors": ["Krishang Sharma"], "title": "Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty", "comment": "10 pages, 2 figures, 3 tables. Submitted to arXiv", "summary": "Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u822a\u7a7a\u53d1\u52a8\u673a\u5269\u4f59\u4f7f\u7528\u5bff\u547d\u9884\u6d4b\uff0c\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u76f4\u63a5\u5b66\u4e60\u5076\u7136\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5173\u952e\u533a\u57df\u6027\u80fd\u63d0\u534725-40%\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u5269\u4f59\u4f7f\u7528\u5bff\u547d\u5e76\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u662f\u822a\u7a7a\u9884\u6d4b\u9886\u57df\u7684\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709CMAPSS\u6587\u732e\u4e2d\u5c1a\u672a\u63a2\u7d22\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u76f4\u63a5\u5b66\u4e60\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u5206\u5c42\u67b6\u6784\u96c6\u6210\u591a\u5c3a\u5ea6Inception\u5757\u7528\u4e8e\u65f6\u95f4\u6a21\u5f0f\u63d0\u53d6\u3001\u53cc\u5411LSTM\u7528\u4e8e\u5e8f\u5217\u5efa\u6a21\u3001\u4f20\u611f\u5668\u548c\u65f6\u95f4\u7ef4\u5ea6\u53cc\u7ea7\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5\u53ca\u8d1d\u53f6\u65af\u8f93\u51fa\u5c42\u540c\u65f6\u9884\u6d4bRUL\u5747\u503c\u548c\u65b9\u5dee\u3002", "result": "\u5728NASA CMAPSS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u6574\u4f53\u6027\u80fd\uff08RMSE\uff1a16.22-19.98\uff09\uff0c\u5173\u952e\u533a\u57df\u6027\u80fd\u7a81\u7834\uff08RMSE\uff1a5.14-7.16\uff09\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u534725-40%\uff0c95%\u7f6e\u4fe1\u533a\u95f4\u8986\u76d6\u7387\u8fbe93.5%-95.2%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5b89\u5168\u5173\u952e\u9884\u6d4b\u65b9\u9762\u5efa\u7acb\u4e86\u65b0\u57fa\u51c6\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u6982\u7387\u4e0d\u786e\u5b9a\u6027\u5b9e\u73b0\u4e86\u4ee5\u524dCMAPSS\u6587\u732e\u4e2d\u65e0\u6cd5\u8fbe\u5230\u7684\u98ce\u9669\u611f\u77e5\u7ef4\u62a4\u8c03\u5ea6\u3002"}}
{"id": "2511.19241", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19241", "abs": "https://arxiv.org/abs/2511.19241", "authors": ["David Stenger", "Armin Lindicke", "Alexander von Rohr", "Sebastian Trimpe"], "title": "Local Entropy Search over Descent Sequences for Bayesian Optimization", "comment": null, "summary": "Searching large and complex design spaces for a global optimum can be infeasible and unnecessary. A practical alternative is to iteratively refine the neighborhood of an initial design using local optimization methods such as gradient descent. We propose local entropy search (LES), a Bayesian optimization paradigm that explicitly targets the solutions reachable by the descent sequences of iterative optimizers. The algorithm propagates the posterior belief over the objective through the optimizer, resulting in a probability distribution over descent sequences. It then selects the next evaluation by maximizing mutual information with that distribution, using a combination of analytic entropy calculations and Monte-Carlo sampling of descent sequences. Empirical results on high-complexity synthetic objectives and benchmark problems show that LES achieves strong sample efficiency compared to existing local and global Bayesian optimization methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5c40\u90e8\u71b5\u641c\u7d22\uff08LES\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u8d1d\u53f6\u65af\u4f18\u5316\u8303\u5f0f\uff0c\u4e13\u95e8\u9488\u5bf9\u8fed\u4ee3\u4f18\u5316\u5668\u7684\u4e0b\u964d\u5e8f\u5217\u53ef\u8fbe\u89e3\u8fdb\u884c\u641c\u7d22\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f20\u64ad\u76ee\u6807\u51fd\u6570\u7684\u540e\u9a8c\u4fe1\u5ff5\uff0c\u751f\u6210\u4e0b\u964d\u5e8f\u5217\u7684\u6982\u7387\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u6700\u5927\u5316\u4e0e\u8be5\u5206\u5e03\u7684\u4e92\u4fe1\u606f\u6765\u9009\u62e9\u4e0b\u4e00\u4e2a\u8bc4\u4f30\u70b9\u3002", "motivation": "\u5728\u5927\u578b\u590d\u6742\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u641c\u7d22\u5168\u5c40\u6700\u4f18\u89e3\u901a\u5e38\u4e0d\u53ef\u884c\u4e14\u4e0d\u5fc5\u8981\u3002\u4e00\u4e2a\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6848\u662f\u4f7f\u7528\u5c40\u90e8\u4f18\u5316\u65b9\u6cd5\uff08\u5982\u68af\u5ea6\u4e0b\u964d\uff09\u8fed\u4ee3\u7ec6\u5316\u521d\u59cb\u8bbe\u8ba1\u7684\u90bb\u57df\u3002", "method": "LES\u7b97\u6cd5\u901a\u8fc7\u4f18\u5316\u5668\u4f20\u64ad\u76ee\u6807\u51fd\u6570\u7684\u540e\u9a8c\u4fe1\u5ff5\uff0c\u751f\u6210\u4e0b\u964d\u5e8f\u5217\u7684\u6982\u7387\u5206\u5e03\u3002\u7136\u540e\u901a\u8fc7\u5206\u6790\u71b5\u8ba1\u7b97\u548c\u4e0b\u964d\u5e8f\u5217\u7684\u8499\u7279\u5361\u6d1b\u91c7\u6837\u76f8\u7ed3\u5408\uff0c\u6700\u5927\u5316\u4e0e\u8be5\u5206\u5e03\u7684\u4e92\u4fe1\u606f\u6765\u9009\u62e9\u4e0b\u4e00\u4e2a\u8bc4\u4f30\u70b9\u3002", "result": "\u5728\u9ad8\u590d\u6742\u5ea6\u5408\u6210\u76ee\u6807\u548c\u57fa\u51c6\u95ee\u9898\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684\u5c40\u90e8\u548c\u5168\u5c40\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u76f8\u6bd4\uff0cLES\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u5c40\u90e8\u71b5\u641c\u7d22\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9488\u5bf9\u8fed\u4ee3\u4f18\u5316\u5668\u7684\u4e0b\u964d\u5e8f\u5217\u8fdb\u884c\u4f18\u5316\uff0c\u5728\u590d\u6742\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2511.18336", "categories": ["cs.LG", "cs.CV", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2511.18336", "abs": "https://arxiv.org/abs/2511.18336", "authors": ["Kaito Shiku", "Kazuya Nishimura", "Shinnosuke Matsuo", "Yasuhiro Kojima", "Ryoma Bise"], "title": "Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary Gene Selection", "comment": "Accepted to Association for the Advancement of Artificial Intelligence (AAAI) 2026", "summary": "Spatial transcriptomics (ST) is a novel technology that enables the observation of gene expression at the resolution of individual spots within pathological tissues. ST quantifies the expression of tens of thousands of genes in a tissue section; however, heavy observational noise is often introduced during measurement. In prior studies, to ensure meaningful assessment, both training and evaluation have been restricted to only a small subset of highly variable genes, and genes outside this subset have also been excluded from the training process. However, since there are likely co-expression relationships between genes, low-expression genes may still contribute to the estimation of the evaluation target. In this paper, we propose $Auxiliary \\ Gene \\ Learning$ (AGL) that utilizes the benefit of the ignored genes by reformulating their expression estimation as auxiliary tasks and training them jointly with the primary tasks. To effectively leverage auxiliary genes, we must select a subset of auxiliary genes that positively influence the prediction of the target genes. However, this is a challenging optimization problem due to the vast number of possible combinations. To overcome this challenge, we propose Prior-Knowledge-Based Differentiable Top-$k$ Gene Selection via Bi-level Optimization (DkGSB), a method that ranks genes by leveraging prior knowledge and relaxes the combinatorial selection problem into a differentiable top-$k$ selection problem. The experiments confirm the effectiveness of incorporating auxiliary genes and show that the proposed method outperforms conventional auxiliary task learning approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAGL\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5ffd\u7565\u57fa\u56e0\u7684\u8868\u8fbe\u4f30\u8ba1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8f85\u52a9\u4efb\u52a1\u5e76\u4e0e\u4e3b\u8981\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\uff0c\u5229\u7528\u88ab\u5ffd\u7565\u57fa\u56e0\u7684\u76ca\u5904\u3002\u4e3a\u89e3\u51b3\u8f85\u52a9\u57fa\u56e0\u9009\u62e9\u96be\u9898\uff0c\u63d0\u51faDkGSB\u65b9\u6cd5\uff0c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u5bf9\u57fa\u56e0\u6392\u5e8f\uff0c\u5e76\u5c06\u7ec4\u5408\u9009\u62e9\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u7684top-k\u9009\u62e9\u95ee\u9898\u3002", "motivation": "\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66(ST)\u6280\u672f\u80fd\u591f\u89c2\u5bdf\u75c5\u7406\u7ec4\u7ec7\u4e2d\u5355\u4e2a\u70b9\u7684\u57fa\u56e0\u8868\u8fbe\uff0c\u4f46\u6d4b\u91cf\u8fc7\u7a0b\u4e2d\u5e38\u5f15\u5165\u5927\u91cf\u89c2\u6d4b\u566a\u58f0\u3002\u5148\u524d\u7814\u7a76\u4ec5\u4f7f\u7528\u9ad8\u5ea6\u53ef\u53d8\u57fa\u56e0\u5b50\u96c6\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u5ffd\u7565\u4e86\u5176\u4ed6\u57fa\u56e0\u3002\u7136\u800c\u57fa\u56e0\u95f4\u53ef\u80fd\u5b58\u5728\u5171\u8868\u8fbe\u5173\u7cfb\uff0c\u4f4e\u8868\u8fbe\u57fa\u56e0\u4ecd\u53ef\u80fd\u5bf9\u8bc4\u4f30\u76ee\u6807\u6709\u8d21\u732e\u3002", "method": "\u63d0\u51fa\u8f85\u52a9\u57fa\u56e0\u5b66\u4e60(AGL)\u6846\u67b6\uff0c\u5c06\u5ffd\u7565\u57fa\u56e0\u7684\u8868\u8fbe\u4f30\u8ba1\u4f5c\u4e3a\u8f85\u52a9\u4efb\u52a1\u4e0e\u4e3b\u8981\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\u3002\u4e3a\u89e3\u51b3\u8f85\u52a9\u57fa\u56e0\u9009\u62e9\u96be\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u5148\u9a8c\u77e5\u8bc6\u7684\u53ef\u5fae\u5206top-k\u57fa\u56e0\u9009\u62e9\u65b9\u6cd5(DkGSB)\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u5c06\u7ec4\u5408\u9009\u62e9\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u6574\u5408\u8f85\u52a9\u57fa\u56e0\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u8f85\u52a9\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5408\u7406\u9009\u62e9\u8f85\u52a9\u57fa\u56e0\u5e76\u5c06\u5176\u7eb3\u5165\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u4e2d\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u7684\u6027\u80fd\uff0cDkGSB\u65b9\u6cd5\u4e3a\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.18394", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18394", "abs": "https://arxiv.org/abs/2511.18394", "authors": ["Chinmay Karkar", "Paras Chopra"], "title": "Future Is Unevenly Distributed: Forecasting Ability of LLMs Depends on What We're Asking", "comment": null, "summary": "Large Language Models (LLMs) demonstrate partial forecasting competence across social, political, and economic events. Yet, their predictive ability varies sharply with domain structure and prompt framing. We investigate how forecasting performance varies with different model families on real-world questions about events that happened beyond the model cutoff date. We analyze how context, question type, and external knowledge affect accuracy and calibration, and how adding factual news context modifies belief formation and failure modes. Our results show that forecasting ability is highly variable as it depends on what, and how, we ask.", "AI": {"tldr": "LLMs\u5728\u4e0d\u540c\u9886\u57df\u7684\u9884\u6d4b\u80fd\u529b\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u53d7\u95ee\u9898\u7c7b\u578b\u3001\u63d0\u793a\u6846\u67b6\u548c\u5916\u90e8\u77e5\u8bc6\u5f71\u54cd\uff0c\u9884\u6d4b\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u63d0\u95ee\u5185\u5bb9\u548c\u65b9\u5f0f\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u73b0\u5b9e\u4e16\u754c\u4e8b\u4ef6\u9884\u6d4b\u4e2d\u7684\u80fd\u529b\uff0c\u63a2\u7d22\u5176\u9884\u6d4b\u6027\u80fd\u5982\u4f55\u968f\u9886\u57df\u7ed3\u6784\u3001\u63d0\u793a\u6846\u67b6\u548c\u5916\u90e8\u77e5\u8bc6\u800c\u53d8\u5316\u3002", "method": "\u5206\u6790\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u5728\u622a\u6b62\u65e5\u671f\u540e\u53d1\u751f\u7684\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u7814\u7a76\u4e0a\u4e0b\u6587\u3001\u95ee\u9898\u7c7b\u578b\u548c\u5916\u90e8\u77e5\u8bc6\u5bf9\u51c6\u786e\u6027\u548c\u6821\u51c6\u7684\u5f71\u54cd\u3002", "result": "LLMs\u7684\u9884\u6d4b\u80fd\u529b\u9ad8\u5ea6\u53ef\u53d8\uff0c\u53d6\u51b3\u4e8e\u63d0\u95ee\u5185\u5bb9\u548c\u65b9\u5f0f\uff0c\u6dfb\u52a0\u4e8b\u5b9e\u65b0\u95fb\u80cc\u666f\u4f1a\u6539\u53d8\u4fe1\u5ff5\u5f62\u6210\u548c\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "LLMs\u7684\u9884\u6d4b\u80fd\u529b\u4e0d\u662f\u4e00\u81f4\u7684\uff0c\u800c\u662f\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5177\u4f53\u7684\u9884\u6d4b\u9886\u57df\u3001\u95ee\u9898\u6846\u67b6\u548c\u77e5\u8bc6\u80cc\u666f\u3002"}}
{"id": "2511.19260", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19260", "abs": "https://arxiv.org/abs/2511.19260", "authors": ["Kyle Verrier", "Achille Nazaret", "Joseph Futoma", "Andrew C. Miller", "Guillermo Sapiro"], "title": "A Nutrition Multimodal Photoplethysmography Language Model", "comment": "21 pages, 2 figures", "summary": "Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8425\u517b\u5149\u7535\u5bb9\u79ef\u63cf\u8bb0\u8bed\u8a00\u6a21\u578b\uff08NPLM\uff09\uff0c\u901a\u8fc7\u6574\u5408\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u8fde\u7eed\u5149\u7535\u5bb9\u79ef\u63cf\u8bb0\uff08PPG\uff09\u6570\u636e\u548c\u9910\u98df\u63cf\u8ff0\uff0c\u6539\u5584\u4e86\u65e5\u5e38\u70ed\u91cf\u6444\u5165\u9884\u6d4b\u3002", "motivation": "\u9965\u997f\u548c\u9971\u8179\u611f\u52a8\u6001\u5f71\u54cd\u996e\u98df\u884c\u4e3a\u548c\u4ee3\u8c22\u5065\u5eb7\uff0c\u4f46\u5728\u65e5\u5e38\u73af\u5883\u4e2d\u96be\u4ee5\u6355\u6349\u3002\u9700\u8981\u5f00\u53d1\u975e\u4fb5\u5165\u6027\u7684\u5927\u89c4\u6a21\u996e\u98df\u76d1\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1NPLM\u6a21\u578b\uff0c\u5c06PPG\u6570\u636e\u6295\u5f71\u5230\u8bed\u8a00\u6a21\u578b\u53ef\u89e3\u91ca\u7684\u5d4c\u5165\u4e2d\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5bf9\u751f\u7406\u6570\u636e\u548c\u9910\u98df\u4e0a\u4e0b\u6587\u8fdb\u884c\u8054\u5408\u63a8\u7406\u3002\u6a21\u578b\u572819,340\u540d\u53c2\u4e0e\u8005\u548c110\u4e07\u4e2a\u9910\u98df-PPG\u914d\u5bf9\u6570\u636e\u4e0a\u8bad\u7ec3\u3002", "result": "\u4e0e\u4ec5\u4f7f\u7528\u6587\u672c\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6a21\u578b\u5c06\u65e5\u5e38\u70ed\u91cf\u6444\u5165\u9884\u6d4b\u63d0\u9ad8\u4e8611%\uff0c\u5373\u4f7f\u53bb\u966480%\u7684\u9910\u98df\u6587\u672c\u4fe1\u606f\uff0c\u51c6\u786e\u6027\u4ecd\u80fd\u4fdd\u6301\u3002\u5728\u72ec\u7acb\u9a8c\u8bc1\u7814\u7a76\uff08n=140\uff09\u4e2d\u590d\u73b0\u4e86\u8fd9\u4e9b\u53d1\u73b0\u3002", "conclusion": "\u6574\u5408\u6d88\u8d39\u8005\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u751f\u7406\u6d4b\u91cf\u4e0e\u9910\u98df\u4fe1\u606f\u5bf9\u4e8e\u5927\u89c4\u6a21\u975e\u4fb5\u5165\u6027\u996e\u98df\u76d1\u6d4b\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.19264", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2511.19264", "abs": "https://arxiv.org/abs/2511.19264", "authors": ["Amirtha Varshini A S", "Duminda S. Ranasinghe", "Hok Hei Tam"], "title": "Interpreting GFlowNets for Drug Discovery: Extracting Actionable Insights for Medicinal Chemistry", "comment": "13 pages, 7 figures. Accepted for presentation at NeurIPS 2025 WiML Workshop and Molecular Machine Learning Conference (MoML) 2025", "summary": "Generative Flow Networks, or GFlowNets, offer a promising framework for molecular design, but their internal decision policies remain opaque. This limits adoption in drug discovery, where chemists require clear and interpretable rationales for proposed structures. We present an interpretability framework for SynFlowNet, a GFlowNet trained on documented chemical reactions and purchasable starting materials that generates both molecules and the synthetic routes that produce them. Our approach integrates three complementary components. Gradient based saliency combined with counterfactual perturbations identifies which atomic environments influence reward and how structural edits change molecular outcomes. Sparse autoencoders reveal axis aligned latent factors that correspond to physicochemical properties such as polarity, lipophilicity, and molecular size. Motif probes show that functional groups including aromatic rings and halogens are explicitly encoded and linearly decodable from the internal embeddings. Together, these results expose the chemical logic inside SynFlowNet and provide actionable and mechanistic insight that supports transparent and controllable molecular design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u6027\u6846\u67b6\u6765\u5206\u6790SynFlowNet\uff08\u4e00\u79cd\u57fa\u4e8e\u5316\u5b66\u53cd\u5e94\u548c\u53ef\u8d2d\u4e70\u539f\u6599\u7684GFlowNet\uff09\uff0c\u901a\u8fc7\u68af\u5ea6\u663e\u8457\u6027\u3001\u7a00\u758f\u81ea\u7f16\u7801\u5668\u548c\u57fa\u5e8f\u63a2\u9488\u63ed\u793a\u5176\u5185\u90e8\u5316\u5b66\u903b\u8f91\u3002", "motivation": "GFlowNets\u5728\u5206\u5b50\u8bbe\u8ba1\u4e2d\u5f88\u6709\u524d\u666f\uff0c\u4f46\u5176\u5185\u90e8\u51b3\u7b56\u7b56\u7565\u4e0d\u900f\u660e\uff0c\u9650\u5236\u4e86\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\uff0c\u56e0\u4e3a\u5316\u5b66\u5bb6\u9700\u8981\u6e05\u6670\u53ef\u89e3\u91ca\u7684\u7ed3\u6784\u8bbe\u8ba1\u7406\u7531\u3002", "method": "\u96c6\u6210\u4e09\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a\u68af\u5ea6\u663e\u8457\u6027\u7ed3\u5408\u53cd\u4e8b\u5b9e\u6270\u52a8\u8bc6\u522b\u5f71\u54cd\u5956\u52b1\u7684\u539f\u5b50\u73af\u5883\uff1b\u7a00\u758f\u81ea\u7f16\u7801\u5668\u63ed\u793a\u4e0e\u7269\u7406\u5316\u5b66\u6027\u8d28\u5bf9\u5e94\u7684\u6f5c\u5728\u56e0\u5b50\uff1b\u57fa\u5e8f\u63a2\u9488\u663e\u793a\u529f\u80fd\u57fa\u56e2\u7684\u663e\u5f0f\u7f16\u7801\u3002", "result": "\u63ed\u793a\u4e86SynFlowNet\u5185\u90e8\u7684\u5316\u5b66\u903b\u8f91\uff0c\u5305\u62ec\u539f\u5b50\u73af\u5883\u5bf9\u5956\u52b1\u7684\u5f71\u54cd\u3001\u7269\u7406\u5316\u5b66\u6027\u8d28\u7684\u6f5c\u5728\u8868\u793a\u4ee5\u53ca\u529f\u80fd\u57fa\u56e2\u7684\u7ebf\u6027\u53ef\u89e3\u7801\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aSynFlowNet\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u548c\u673a\u5236\u6027\u7684\u6d1e\u5bdf\uff0c\u652f\u6301\u900f\u660e\u53ef\u63a7\u7684\u5206\u5b50\u8bbe\u8ba1\u3002"}}
{"id": "2511.18468", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18468", "abs": "https://arxiv.org/abs/2511.18468", "authors": ["Md Akil Raihan Iftee", "Mir Sazzat Hossain", "Rakibul Hasan Rajib", "Tariq Iqbal", "Md Mofijul Islam", "M Ashraful Amin", "Amin Ahsan Ali", "AKM Mahbubur Rahman"], "title": "SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation", "comment": "38 pages, 38 tables, 16 figures", "summary": "Continual Test-Time Adaptation (CTTA) is crucial for deploying models in real-world applications with unseen, evolving target domains. Existing CTTA methods, however, often rely on source data or prototypes, limiting their applicability in privacy-sensitive and resource-constrained settings. Additionally, these methods suffer from long-term forgetting, which degrades performance on previously encountered domains as target domains shift. To address these challenges, we propose SloMo-Fast, a source-free, dual-teacher CTTA framework designed for enhanced adaptability and generalization. It includes two complementary teachers: the Slow-Teacher, which exhibits slow forgetting and retains long-term knowledge of previously encountered domains to ensure robust generalization, and the Fast-Teacher rapidly adapts to new domains while accumulating and integrating knowledge across them. This framework preserves knowledge of past domains and adapts efficiently to new ones. We also introduce Cyclic Test-Time Adaptation (Cyclic-TTA), a novel CTTA benchmark that simulates recurring domain shifts. Our extensive experiments demonstrate that SloMo-Fast consistently outperforms state-of-the-art methods across Cyclic-TTA, as well as ten other CTTA settings, highlighting its ability to both adapt and generalize across evolving and revisited domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86SloMo-Fast\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u65e0\u6e90\u6570\u636e\u7684\u53cc\u6559\u5e08\u6301\u7eed\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u9690\u79c1\u654f\u611f\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u957f\u671f\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709CTTA\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u6e90\u6570\u636e\u6216\u539f\u578b\uff0c\u5728\u9690\u79c1\u654f\u611f\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u9002\u7528\u6027\u6709\u9650\uff0c\u4e14\u5b58\u5728\u957f\u671f\u9057\u5fd8\u95ee\u9898\uff0c\u5bfc\u81f4\u5728\u5148\u524d\u9047\u5230\u57df\u4e0a\u7684\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faSloMo-Fast\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u7684\u6559\u5e08\u6a21\u578b\uff1aSlow-Teacher\u7f13\u6162\u9057\u5fd8\u5e76\u4fdd\u7559\u957f\u671f\u77e5\u8bc6\u786e\u4fdd\u9c81\u68d2\u6cdb\u5316\uff0cFast-Teacher\u5feb\u901f\u9002\u5e94\u65b0\u57df\u5e76\u8de8\u57df\u79ef\u7d2f\u77e5\u8bc6\u3002\u540c\u65f6\u5f15\u5165\u4e86Cyclic-TTA\u57fa\u51c6\u6765\u6a21\u62df\u5faa\u73af\u57df\u504f\u79fb\u3002", "result": "\u5728Cyclic-TTA\u548c\u5176\u4ed6\u5341\u4e2aCTTA\u8bbe\u7f6e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSloMo-Fast\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u7a81\u663e\u5176\u5728\u6f14\u5316\u548c\u91cd\u8bbf\u57df\u4e0a\u7684\u9002\u5e94\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SloMo-Fast\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86CTTA\u4e2d\u7684\u957f\u671f\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u9690\u79c1\u654f\u611f\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u540c\u65f6\u9002\u5e94\u65b0\u57df\u5e76\u4fdd\u6301\u5bf9\u5148\u524d\u57df\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.19299", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19299", "abs": "https://arxiv.org/abs/2511.19299", "authors": ["James R. M. Black", "Moritz S. Hanke", "Aaron Maiwald", "Tina Hernandez-Boussard", "Oliver M. Crook", "Jaspreet Pannu"], "title": "Open-weight genome language model safeguards: Assessing robustness via adversarial fine-tuning", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI", "summary": "Novel deep learning architectures are increasingly being applied to biological data, including genetic sequences. These models, referred to as genomic language mod- els (gLMs), have demonstrated impressive predictive and generative capabilities, raising concerns that such models may also enable misuse, for instance via the generation of genomes for human-infecting viruses. These concerns have catalyzed calls for risk mitigation measures. The de facto mitigation of choice is filtering of pretraining data (i.e., removing viral genomic sequences from training datasets) in order to limit gLM performance on virus-related tasks. However, it is not currently known how robust this approach is for securing open-source models that can be fine-tuned using sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and perform fine-tuning using sequences from 110 harmful human-infecting viruses to assess the rescue of misuse-relevant predictive capabilities. The fine- tuned model exhibited reduced perplexity on unseen viral sequences relative to 1) the pretrained model and 2) a version fine-tuned on bacteriophage sequences. The model fine-tuned on human-infecting viruses also identified immune escape variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo- sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that data exclusion might be circumvented by fine-tuning approaches that can, to some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need for safety frameworks for gLMs and outline further work needed on evaluations and mitigation measures to enable the safe deployment of gLMs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u56e0\u7ec4\u8bed\u8a00\u6a21\u578b\uff08gLM\uff09\u5728\u5fae\u8c03\u540e\u6062\u590d\u6709\u5bb3\u75c5\u6bd2\u9884\u6d4b\u80fd\u529b\u7684\u5b89\u5168\u98ce\u9669\uff0c\u53d1\u73b0\u5373\u4f7f\u9884\u8bad\u7ec3\u65f6\u6392\u9664\u75c5\u6bd2\u6570\u636e\uff0c\u901a\u8fc7\u5fae\u8c03\u4ecd\u80fd\u6062\u590d\u6a21\u578b\u5bf9\u6709\u5bb3\u4eba\u7c7b\u611f\u67d3\u75c5\u6bd2\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u57fa\u56e0\u7ec4\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u6570\u636e\u4e0a\u7684\u5e94\u7528\u5f15\u53d1\u4e86\u6ee5\u7528\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u751f\u6210\u4eba\u7c7b\u611f\u67d3\u75c5\u6bd2\u57fa\u56e0\u7ec4\u7684\u80fd\u529b\u3002\u5f53\u524d\u4e3b\u8981\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u8fc7\u6ee4\u75c5\u6bd2\u5e8f\u5217\u6765\u964d\u4f4e\u98ce\u9669\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u5f00\u6e90\u6a21\u578b\u5fae\u8c03\u7684\u9c81\u68d2\u6027\u672a\u77e5\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684gLM\u6a21\u578bEvo 2\uff0c\u5728110\u79cd\u6709\u5bb3\u4eba\u7c7b\u611f\u67d3\u75c5\u6bd2\u7684\u5e8f\u5217\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u8bc4\u4f30\u5176\u6062\u590d\u6ee5\u7528\u76f8\u5173\u9884\u6d4b\u80fd\u529b\u7684\u6548\u679c\uff0c\u5e76\u4e0e\u5728\u566c\u83cc\u4f53\u5e8f\u5217\u4e0a\u5fae\u8c03\u7684\u7248\u672c\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u672a\u89c1\u75c5\u6bd2\u5e8f\u5217\u4e0a\u7684\u56f0\u60d1\u5ea6\u964d\u4f4e\uff0c\u80fd\u591f\u8bc6\u522bSARS-CoV-2\u7684\u514d\u75ab\u9003\u9038\u53d8\u4f53\uff08AUROC\u4e3a0.6\uff09\uff0c\u5c3d\u7ba1\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u672a\u63a5\u89e6SARS-CoV-2\u5e8f\u5217\u3002", "conclusion": "\u6570\u636e\u6392\u9664\u7b56\u7565\u53ef\u80fd\u88ab\u5fae\u8c03\u65b9\u6cd5\u89c4\u907f\uff0cgLM\u9700\u8981\u66f4\u5b8c\u5584\u7684\u5b89\u5168\u6846\u67b6\u3001\u8bc4\u4f30\u548c\u7f13\u89e3\u63aa\u65bd\u6765\u786e\u4fdd\u5b89\u5168\u90e8\u7f72\u3002"}}
{"id": "2511.19355", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19355", "abs": "https://arxiv.org/abs/2511.19355", "authors": ["Franklin Cardenoso", "Wouter Caarls"], "title": "Leveraging LLMs for reward function design in reinforcement learning control tasks", "comment": null, "summary": "The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.", "AI": {"tldr": "LEARN-Opt\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b8c\u5168\u81ea\u4e3b\u3001\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u7cfb\u7edf\u63cf\u8ff0\u548c\u4efb\u52a1\u76ee\u6807\u81ea\u52a8\u751f\u6210\u3001\u6267\u884c\u548c\u8bc4\u4f30\u5956\u52b1\u51fd\u6570\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u6307\u6807\u6216\u73af\u5883\u6e90\u4ee3\u7801\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e2d\u8bbe\u8ba1\u6709\u6548\u5956\u52b1\u51fd\u6570\u662f\u4e00\u4e2a\u91cd\u5927\u74f6\u9888\uff0c\u9700\u8981\u5927\u91cf\u4eba\u5de5\u4e13\u4e1a\u77e5\u8bc6\u4e14\u8017\u65f6\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u9884\u5b9a\u4e49\u8bc4\u4f30\u6307\u6807\u3001\u4eba\u5de5\u53cd\u9988\u6216\u73af\u5883\u6e90\u4ee3\u7801\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u3002", "method": "\u5f15\u5165LEARN-Opt\u6846\u67b6\uff0c\u80fd\u591f\u76f4\u63a5\u4ece\u7cfb\u7edf\u63cf\u8ff0\u548c\u4efb\u52a1\u76ee\u6807\u81ea\u4e3b\u63a8\u5bfc\u6027\u80fd\u6307\u6807\uff0c\u5b9e\u73b0\u65e0\u76d1\u7763\u7684\u5956\u52b1\u51fd\u6570\u8bc4\u4f30\u548c\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLEARN-Opt\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\uff08\u5982EUREKA\uff09\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u5148\u9a8c\u77e5\u8bc6\u3002\u81ea\u52a8\u5316\u5956\u52b1\u8bbe\u8ba1\u662f\u9ad8\u65b9\u5dee\u95ee\u9898\uff0c\u9700\u8981\u591a\u6b21\u8fd0\u884c\u5bfb\u627e\u6700\u4f73\u5019\u9009\u3002", "conclusion": "LEARN-Opt\u80fd\u591f\u5229\u7528\u4f4e\u6210\u672cLLMs\u627e\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u9ad8\u6027\u80fd\u5956\u52b1\u51fd\u6570\uff0c\u65e0\u9700\u4efb\u4f55\u9884\u5b9a\u4e49\u4eba\u5de5\u6307\u6807\uff0c\u51cf\u5c11\u5de5\u7a0b\u5f00\u9500\u5e76\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.19390", "categories": ["cs.LG", "astro-ph.SR", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19390", "abs": "https://arxiv.org/abs/2511.19390", "authors": ["Rudy Morel", "Francesco Pio Ramunno", "Jeff Shen", "Alberto Bietti", "Kyunghyun Cho", "Miles Cranmer", "Siavash Golkar", "Olexandr Gugnin", "Geraud Krawezik", "Tanya Marwah", "Michael McCabe", "Lucas Meyer", "Payel Mukhopadhyay", "Ruben Ohana", "Liam Parker", "Helen Qu", "Fran\u00e7ois Rozet", "K. D. Leka", "Fran\u00e7ois Lanusse", "David Fouhey", "Shirley Ho"], "title": "Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme", "comment": null, "summary": "Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6269\u6563\u6a21\u578b\u7684\u591a\u5c3a\u5ea6\u63a8\u7406\u65b9\u6848\uff0c\u4e13\u95e8\u9488\u5bf9\u90e8\u5206\u53ef\u89c2\u6d4b\u3001\u957f\u8bb0\u5fc6\u52a8\u529b\u7cfb\u7edf\u7684\u6982\u7387\u9884\u6d4b\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u592a\u9633\u52a8\u529b\u5b66\u548c\u6d3b\u52a8\u533a\u6f14\u5316\u7b49\u5e94\u7528\u4e2d\u3002", "motivation": "\u5728\u8bb8\u591a\u52a8\u6001\u7cfb\u7edf\u9884\u6d4b\u573a\u666f\u4e2d\uff0c\u53ef\u7528\u4fe1\u606f\u53ea\u5360\u9884\u6d4b\u672a\u6765\u72b6\u6001\u6240\u9700\u4fe1\u606f\u7684\u4e00\u5c0f\u90e8\u5206\uff0c\u8981\u4e48\u7531\u4e8e\u6d4b\u91cf\u4e0d\u786e\u5b9a\u6027\uff0c\u8981\u4e48\u56e0\u4e3a\u53ea\u80fd\u89c2\u6d4b\u5230\u72b6\u6001\u7684\u4e00\u5c0f\u90e8\u5206\u3002\u4f8b\u5982\u5728\u592a\u9633\u7269\u7406\u5b66\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u89c2\u6d4b\u592a\u9633\u8868\u9762\u548c\u5927\u6c14\u5c42\uff0c\u4f46\u5176\u6f14\u5316\u7531\u7f3a\u4e4f\u76f4\u63a5\u6d4b\u91cf\u7684\u5185\u90e8\u8fc7\u7a0b\u9a71\u52a8\u3002\u6807\u51c6\u63a8\u7406\u65b9\u6848\u65e0\u6cd5\u6709\u6548\u6355\u6349\u6570\u636e\u4e2d\u7684\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c3a\u5ea6\u63a8\u7406\u65b9\u6848\uff0c\u751f\u6210\u5728\u65f6\u95f4\u4e0a\u9760\u8fd1\u5f53\u524d\u65f6\u523b\u65f6\u7c92\u5ea6\u8f83\u7ec6\u3001\u8fdc\u79bb\u5f53\u524d\u65f6\u523b\u65f6\u7c92\u5ea6\u8f83\u7c97\u7684\u8f68\u8ff9\uff0c\u8fd9\u6837\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u6355\u6349\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5f53\u96c6\u6210\u5230\u6269\u6563\u6a21\u578b\u4e2d\u65f6\uff0c\u8be5\u63a8\u7406\u65b9\u6848\u663e\u8457\u51cf\u5c11\u4e86\u9884\u6d4b\u5206\u5e03\u7684\u504f\u5dee\uff0c\u5e76\u63d0\u9ad8\u4e86\u5c55\u5f00\u7a33\u5b9a\u6027\u3002", "conclusion": "\u591a\u5c3a\u5ea6\u63a8\u7406\u65b9\u6848\u80fd\u591f\u6709\u6548\u89e3\u51b3\u90e8\u5206\u53ef\u89c2\u6d4b\u3001\u957f\u8bb0\u5fc6\u52a8\u529b\u7cfb\u7edf\u7684\u6982\u7387\u9884\u6d4b\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.19413", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19413", "abs": "https://arxiv.org/abs/2511.19413", "authors": ["Zhaolong Su", "Wang Lu", "Hao Chen", "Sharon Li", "Jindong Wang"], "title": "UniGame: Turning a Unified Multimodal Model Into Its Own Adversary", "comment": null, "summary": "Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame", "AI": {"tldr": "UniGame\u662f\u4e00\u4e2a\u81ea\u5bf9\u6297\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6270\u52a8\u5668\u89e3\u51b3\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7406\u89e3\u4e0e\u751f\u6210\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u5728\u7406\u89e3\u548c\u751f\u6210\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u4e0d\u4e00\u81f4\uff1a\u7406\u89e3\u504f\u597d\u7d27\u51d1\u5d4c\u5165\uff0c\u800c\u751f\u6210\u504f\u597d\u91cd\u5efa\u4e30\u5bcc\u7684\u8868\u793a\uff0c\u8fd9\u79cd\u7ed3\u6784\u6743\u8861\u5bfc\u81f4\u51b3\u7b56\u8fb9\u754c\u9519\u4f4d\u3001\u8de8\u6a21\u6001\u8fde\u8d2f\u6027\u4e0b\u964d\u4ee5\u53ca\u5bf9\u5206\u5e03\u548c\u5bf9\u6297\u6027\u53d8\u5316\u7684\u8106\u5f31\u6027\u3002", "method": "UniGame\u5728\u5171\u4eab\u4ee4\u724c\u63a5\u53e3\u5e94\u7528\u8f7b\u91cf\u7ea7\u6270\u52a8\u5668\uff0c\u4f7f\u751f\u6210\u5206\u652f\u80fd\u591f\u4e3b\u52a8\u5bfb\u627e\u548c\u6311\u6218\u8106\u5f31\u7684\u7406\u89e3\uff0c\u5c06\u6a21\u578b\u81ea\u8eab\u8f6c\u5316\u4e3a\u5bf9\u6297\u8005\u3002", "result": "UniGame\u663e\u8457\u63d0\u5347\u4e00\u81f4\u6027(+4.6%)\u3001\u7406\u89e3\u80fd\u529b(+3.6%)\u3001\u751f\u6210\u8d28\u91cf(+0.02)\uff0c\u5e76\u5728\u81ea\u7136\u5206\u5e03\u548c\u5bf9\u6297\u6027\u9c81\u68d2\u6027\u4e0a\u5206\u522b\u63d0\u53474.8%\u548c6.2%\u3002\u8be5\u6846\u67b6\u67b6\u6784\u65e0\u5173\uff0c\u4ec5\u589e\u52a0\u4e0d\u52301%\u7684\u53c2\u6570\uff0c\u4e0e\u73b0\u6709\u540e\u8bad\u7ec3\u65b9\u6cd5\u4e92\u8865\u3002", "conclusion": "\u5bf9\u6297\u6027\u81ea\u535a\u5f08\u662f\u589e\u5f3a\u672a\u6765\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u8fde\u8d2f\u6027\u3001\u7a33\u5b9a\u6027\u548c\u7edf\u4e00\u80fd\u529b\u7684\u901a\u7528\u6709\u6548\u539f\u5219\u3002"}}
{"id": "2511.18519", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18519", "abs": "https://arxiv.org/abs/2511.18519", "authors": ["Xinlin Zhuang", "Yichen Li", "Xiwei Liu", "Haolin Yang", "Yifan Lu", "Ziyun Zou", "Yulong Li", "Huifa Li", "Dongliang Chen", "Qinglei Wang", "Weiyang Liu", "Ying Qian", "Jiangming Shi", "Imran Razzak"], "title": "CHIPS: Efficient CLIP Adaptation via Curvature-aware Hybrid Influence-based Data Selection", "comment": "preprint, under-review", "summary": "Adapting CLIP to vertical domains is typically approached by novel fine-tuning strategies or by continual pre-training (CPT) on large domain-specific datasets. Yet, data itself remains an underexplored factor in this process. We revisit this task from a data-centric perspective: Can effective data selection substitute for large-scale datasets in CPT? We introduce CHIPS (Curvature-aware Hybrid Influence in Projection Subspace), which assigns each image-text pair a utility score that integrates three complementary factors aligned with three goals: faithfulness via a curvature-aware, Newton-style alignment computed in CLIP's end-point subspace; scalability via an InfoNCE-aware curvature estimator with Johnson-Lindenstrauss (JL) sketching; and retention via a selection-aware relevance weight combined with learnability to balance target adaptation against general-domain preservation. We justify this design theoretically by proving a lower-bound guarantee on the proxy's correlation with full-parameter alignment and by characterizing the bias-variance trade-offs introduced by curvature mixing and JL sketching. We evaluate CHIPS empirically across various settings: 1) CHIPS attains state-of-the-art performance among selection baselines on 17 medical benchmarks, matches full-dataset CPT with 30% of the data, and outperforms half-dataset CPT using only 10%; 2) on 31 general-domain benchmarks, CHIPS yields the smallest performance drop under 10-30% data-retention budgets. Code, data, and checkpoints will be released.", "AI": {"tldr": "CHIPS\u662f\u4e00\u79cd\u4ece\u6570\u636e\u89d2\u5ea6\u51fa\u53d1\u7684CLIP\u5782\u76f4\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u56fe\u50cf-\u6587\u672c\u5bf9\u7684\u6548\u7528\u5206\u6570\u6765\u9009\u62e9\u6570\u636e\uff0c\u80fd\u591f\u5728\u4ec5\u4f7f\u752830%\u6570\u636e\u65f6\u8fbe\u5230\u5168\u6570\u636e\u96c6\u6301\u7eed\u9884\u8bad\u7ec3\u7684\u6027\u80fd\uff0c\u572810%\u6570\u636e\u65f6\u4f18\u4e8e50%\u6570\u636e\u7684\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709CLIP\u5782\u76f4\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5fae\u8c03\u7b56\u7565\u6216\u5927\u89c4\u6a21\u9886\u57df\u7279\u5b9a\u6570\u636e\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u4f46\u6570\u636e\u672c\u8eab\u4f5c\u4e3a\u5173\u952e\u56e0\u7d20\u88ab\u5ffd\u89c6\u3002\u672c\u6587\u4ece\u6570\u636e\u4e2d\u5fc3\u7684\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u8be5\u4efb\u52a1\uff0c\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u6709\u6548\u7684\u6570\u636e\u9009\u62e9\u66ff\u4ee3\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51faCHIPS\u65b9\u6cd5\uff0c\u4e3a\u6bcf\u4e2a\u56fe\u50cf-\u6587\u672c\u5bf9\u5206\u914d\u6548\u7528\u5206\u6570\uff0c\u6574\u5408\u4e09\u4e2a\u4e92\u8865\u56e0\u7d20\uff1a\u901a\u8fc7\u66f2\u7387\u611f\u77e5\u7684\u725b\u987f\u5f0f\u5bf9\u9f50\u786e\u4fdd\u5fe0\u5b9e\u6027\uff1b\u901a\u8fc7InfoNCE\u611f\u77e5\u7684\u66f2\u7387\u4f30\u8ba1\u5668\u548cJL\u6295\u5f71\u786e\u4fdd\u53ef\u6269\u5c55\u6027\uff1b\u901a\u8fc7\u9009\u62e9\u611f\u77e5\u7684\u76f8\u5173\u6027\u6743\u91cd\u548c\u53ef\u5b66\u4e60\u6027\u5e73\u8861\u76ee\u6807\u9002\u5e94\u4e0e\u901a\u7528\u9886\u57df\u4fdd\u7559\u3002", "result": "\u572817\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCHIPS\u5728\u6570\u636e\u9009\u62e9\u57fa\u7ebf\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4ec5\u752830%\u6570\u636e\u5373\u53ef\u5339\u914d\u5168\u6570\u636e\u96c6\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u4ec5\u752810%\u6570\u636e\u4f18\u4e8e50%\u6570\u636e\u8bad\u7ec3\uff1b\u572831\u4e2a\u901a\u7528\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u572810-30%\u6570\u636e\u4fdd\u7559\u9884\u7b97\u4e0b\u6027\u80fd\u4e0b\u964d\u6700\u5c0f\u3002", "conclusion": "CHIPS\u8bc1\u660e\u4e86\u6709\u6548\u6570\u636e\u9009\u62e9\u53ef\u4ee5\u66ff\u4ee3\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u4e3aCLIP\u5782\u76f4\u9886\u57df\u9002\u5e94\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u4e2d\u5fc3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18521", "categories": ["cs.LG", "astro-ph.EP", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2511.18521", "abs": "https://arxiv.org/abs/2511.18521", "authors": ["Core Francisco Park", "Manuel Perez-Carrasco", "Caroline Nowlan", "Cecilia Garraffo"], "title": "Hyperspectral Variational Autoencoders for Joint Data Compression and Component Extraction", "comment": null, "summary": "Geostationary hyperspectral satellites generate terabytes of data daily, creating critical challenges for storage, transmission, and distribution to the scientific community. We present a variational autoencoder (VAE) approach that achieves x514 compression of NASA's TEMPO satellite hyperspectral observations (1028 channels, 290-490nm) with reconstruction errors 1-2 orders of magnitude below the signal across all wavelengths. This dramatic data volume reduction enables efficient archival and sharing of satellite observations while preserving spectral fidelity. Beyond compression, we investigate to what extent atmospheric information is retained in the compressed latent space by training linear and nonlinear probes to extract Level-2 products (NO2, O3, HCHO, cloud fraction). Cloud fraction and total ozone achieve strong extraction performance (R^2 = 0.93 and 0.81 respectively), though these represent relatively straightforward retrievals given their distinct spectral signatures. In contrast, tropospheric trace gases pose genuine challenges for extraction (NO2 R^2 = 0.20, HCHO R^2 = 0.51) reflecting their weaker signals and complex atmospheric interactions. Critically, we find the VAE encodes atmospheric information in a semi-linear manner - nonlinear probes substantially outperform linear ones - and that explicit latent supervision during training provides minimal improvement, revealing fundamental encoding challenges for certain products. This work demonstrates that neural compression can dramatically reduce hyperspectral data volumes while preserving key atmospheric signals, addressing a critical bottleneck for next-generation Earth observation systems. Code - https://github.com/cfpark00/Hyperspectral-VAE", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53d8\u5206\u81ea\u7f16\u7801\u5668\u65b9\u6cd5\uff0c\u5bf9NASA TEMPO\u536b\u661f\u9ad8\u5149\u8c31\u6570\u636e\u8fdb\u884c514\u500d\u538b\u7f29\uff0c\u91cd\u5efa\u8bef\u5dee\u6bd4\u4fe1\u53f7\u4f4e1-2\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u4fdd\u7559\u5173\u952e\u5927\u6c14\u4fe1\u606f\u3002", "motivation": "\u89e3\u51b3\u5730\u7403\u9759\u6b62\u8f68\u9053\u9ad8\u5149\u8c31\u536b\u661f\u6bcf\u65e5\u4ea7\u751fTB\u7ea7\u6570\u636e\u5e26\u6765\u7684\u5b58\u50a8\u3001\u4f20\u8f93\u548c\u5206\u53d1\u6311\u6218\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u5bf91028\u4e2a\u901a\u9053\u7684\u9ad8\u5149\u8c31\u89c2\u6d4b\u6570\u636e\u8fdb\u884c\u538b\u7f29\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u63a2\u9488\u8bc4\u4f30\u538b\u7f29\u540e\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u5927\u6c14\u4fe1\u606f\u4fdd\u7559\u7a0b\u5ea6\u3002", "result": "\u5b9e\u73b0514\u500d\u538b\u7f29\uff0c\u91cd\u5efa\u8bef\u5dee\u8fdc\u4f4e\u4e8e\u4fe1\u53f7\u6c34\u5e73\uff1b\u4e91\u5206\u6570\u548c\u603b\u81ed\u6c27\u63d0\u53d6\u6027\u80fd\u4f18\u5f02(R\u00b2=0.93\u548c0.81)\uff0c\u4f46\u5bf9\u6d41\u5c42\u75d5\u91cf\u6c14\u4f53\u63d0\u53d6\u9762\u4e34\u6311\u6218(NO\u2082 R\u00b2=0.20\uff0cHCHO R\u00b2=0.51)\u3002", "conclusion": "\u795e\u7ecf\u538b\u7f29\u80fd\u663e\u8457\u51cf\u5c11\u9ad8\u5149\u8c31\u6570\u636e\u91cf\uff0c\u540c\u65f6\u4fdd\u7559\u5173\u952e\u5927\u6c14\u4fe1\u53f7\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5730\u7403\u89c2\u6d4b\u7cfb\u7edf\u89e3\u51b3\u5173\u952e\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2511.18567", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18567", "abs": "https://arxiv.org/abs/2511.18567", "authors": ["Arya Shah", "Vaibhav Tripathi"], "title": "In Search of Goodness: Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorithm", "comment": "24 pages, 5 tables, 17 figures", "summary": "The Forward-Forward (FF) algorithm offers a biologically plausible alternative to backpropagation, enabling neural networks to learn through local updates. However, FF's efficacy relies heavily on the definition of \"goodness\", which is a scalar measure of neural activity. While current implementations predominantly utilize a simple sum-of-squares metric, it remains unclear if this default choice is optimal. To address this, we benchmarked 21 distinct goodness functions across four standard image datasets (MNIST, FashionMNIST, CIFAR-10, STL-10), evaluating classification accuracy, energy consumption, and carbon footprint. We found that certain alternative goodness functions inspired from various domains significantly outperform the standard baseline. Specifically, \\texttt{game\\_theoretic\\_local} achieved 97.15\\% accuracy on MNIST, \\texttt{softmax\\_energy\\_margin\\_local} reached 82.84\\% on FashionMNIST, and \\texttt{triplet\\_margin\\_local} attained 37.69\\% on STL-10. Furthermore, we observed substantial variability in computational efficiency, highlighting a critical trade-off between predictive performance and environmental cost. These findings demonstrate that the goodness function is a pivotal hyperparameter in FF design. We release our code on \\href{https://github.com/aryashah2k/In-Search-of-Goodness}{Github} for reference and reproducibility.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e8621\u79cd\u4e0d\u540c\u7684goodness\u51fd\u6570\u5728Forward-Forward\u7b97\u6cd5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5728\u591a\u4e2a\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u67d0\u4e9b\u66ff\u4ee3\u51fd\u6570\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u9884\u6d4b\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "Forward-Forward\u7b97\u6cd5\u4f9d\u8d56\u4e8egoodness\u51fd\u6570\u6765\u8861\u91cf\u795e\u7ecf\u6d3b\u52a8\uff0c\u4f46\u5f53\u524d\u4e3b\u8981\u4f7f\u7528\u7b80\u5355\u7684\u5e73\u65b9\u548c\u5ea6\u91cf\uff0c\u4e0d\u6e05\u695a\u8fd9\u662f\u5426\u662f\u6700\u4f18\u9009\u62e9\u3002", "method": "\u5728\u56db\u4e2a\u6807\u51c6\u56fe\u50cf\u6570\u636e\u96c6\uff08MNIST\u3001FashionMNIST\u3001CIFAR-10\u3001STL-10\uff09\u4e0a\u5bf921\u79cd\u4e0d\u540c\u7684goodness\u51fd\u6570\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5206\u7c7b\u51c6\u786e\u7387\u3001\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\u3002", "result": "\u53d1\u73b0\u67d0\u4e9b\u66ff\u4ee3goodness\u51fd\u6570\u8868\u73b0\u4f18\u5f02\uff1agame_theoretic_local\u5728MNIST\u4e0a\u8fbe\u523097.15%\u51c6\u786e\u7387\uff0csoftmax_energy_margin_local\u5728FashionMNIST\u4e0a\u8fbe\u523082.84%\uff0ctriplet_margin_local\u5728STL-10\u4e0a\u8fbe\u523037.69%\u3002\u8ba1\u7b97\u6548\u7387\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "goodness\u51fd\u6570\u662fFF\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u8d85\u53c2\u6570\uff0c\u9700\u8981\u5728\u9884\u6d4b\u6027\u80fd\u548c\u73af\u5883\u5f71\u54cd\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2511.18571", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18571", "abs": "https://arxiv.org/abs/2511.18571", "authors": ["Jiazhen Hong", "Geoffrey Mackellar", "Soheila Ghane"], "title": "SAMBA: Toward a Long-Context EEG Foundation Model via Spatial Embedding and Differential Mamba", "comment": null, "summary": "Long-sequence electroencephalogram (EEG) modeling is essential for developing generalizable EEG representation models. This need arises from the high sampling rate of EEG data and the long recording durations required to capture extended neurological patterns in brain activity. Transformer-based models have shown promise in modeling short sequences of a few seconds; however, their quadratic complexity limits scalability to longer contexts. Moreover, variability in electrode montage across available datasets, along with inter-subject differences in brain signals, pose significant challenges to developing a generalizable and robust foundation model. We propose \\textit{SAMBA}, a self-supervised learning framework with a Mamba-based U-shaped encoder-decoder architecture, which effectively captures long-range temporal dependencies and spatial variability in EEG data. Leveraging the inherent ability of Mamba in processing long context sizes, we introduce: (1) \\textit{Temporal Semantic Random Masking} for semantic-level sequence reconstruction, (2) a \\textit{Multi-Head Differential Mamba} module to suppress redundancy and emphasize salient temporal structures, and (3) a \\textit{Spatial-Adaptive Input Embedding} that learns unified embeddings in a three-dimensional Euclidean space, enabling robustness across devices. Experiments on thirteen EEG datasets across diverse tasks, electrode configurations, and sequence durations demonstrate that SAMBA consistently outperforms state-of-the-art methods while maintaining low memory consumption and inference time. We also show the learned spatial weight maps from our embedding module align closely with task-relevant neurophysiological regions, demonstrating the learnability and interpretability of SAMBA. These results highlight SAMBA's scalability and practical potential as a foundation model for real-time brain-computer interface applications.", "AI": {"tldr": "SAMBA\u662f\u4e00\u4e2a\u57fa\u4e8eMamba\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u957f\u5e8f\u5217EEG\u5efa\u6a21\uff0c\u901a\u8fc7U\u5f62\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u6709\u6548\u6355\u6349EEG\u6570\u636e\u4e2d\u7684\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u548c\u7a7a\u95f4\u53d8\u5f02\u6027\uff0c\u572813\u4e2aEEG\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "EEG\u6570\u636e\u91c7\u6837\u7387\u9ad8\u3001\u8bb0\u5f55\u65f6\u95f4\u957f\uff0c\u9700\u8981\u5efa\u6a21\u957f\u5e8f\u5217\uff1bTransformer\u6a21\u578b\u5728\u5904\u7406\u77ed\u5e8f\u5217\u65f6\u8868\u73b0\u826f\u597d\u4f46\u4e8c\u6b21\u590d\u6742\u5ea6\u9650\u5236\u4e86\u957f\u4e0a\u4e0b\u6587\u6269\u5c55\uff1b\u7535\u6781\u914d\u7f6e\u5dee\u5f02\u548c\u53d7\u8bd5\u8005\u95f4\u4fe1\u53f7\u53d8\u5f02\u6027\u5bf9\u5f00\u53d1\u901a\u7528\u57fa\u7840\u6a21\u578b\u6784\u6210\u6311\u6218\u3002", "method": "\u63d0\u51faSAMBA\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u65f6\u95f4\u8bed\u4e49\u968f\u673a\u63a9\u7801\u7528\u4e8e\u8bed\u4e49\u7ea7\u5e8f\u5217\u91cd\u5efa\uff1b2\uff09\u591a\u5934\u5dee\u5206Mamba\u6a21\u5757\u6291\u5236\u5197\u4f59\u5e76\u7a81\u51fa\u663e\u8457\u65f6\u95f4\u7ed3\u6784\uff1b3\uff09\u7a7a\u95f4\u81ea\u9002\u5e94\u8f93\u5165\u5d4c\u5165\u5728\u4e09\u7ef4\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u5b66\u4e60\u7edf\u4e00\u5d4c\u5165\u4ee5\u5b9e\u73b0\u8de8\u8bbe\u5907\u9c81\u68d2\u6027\u3002", "result": "\u572813\u4e2aEEG\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSAMBA\u5728\u591a\u79cd\u4efb\u52a1\u3001\u7535\u6781\u914d\u7f6e\u548c\u5e8f\u5217\u6301\u7eed\u65f6\u95f4\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u5185\u5b58\u6d88\u8017\u548c\u63a8\u7406\u65f6\u95f4\uff1b\u5b66\u4e60\u5230\u7684\u7a7a\u95f4\u6743\u91cd\u56fe\u4e0e\u4efb\u52a1\u76f8\u5173\u795e\u7ecf\u751f\u7406\u533a\u57df\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "SAMBA\u5c55\u793a\u4e86\u4f5c\u4e3a\u5b9e\u65f6\u8111\u673a\u63a5\u53e3\u5e94\u7528\u57fa\u7840\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u6f5c\u529b\uff0c\u5176\u5d4c\u5165\u6a21\u5757\u5177\u6709\u53ef\u5b66\u4e60\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.18593", "categories": ["cs.LG", "eess.SY", "math.SP"], "pdf": "https://arxiv.org/pdf/2511.18593", "abs": "https://arxiv.org/abs/2511.18593", "authors": ["Milad Siami"], "title": "Generative Myopia: Why Diffusion Models Fail at Structure", "comment": null, "summary": "Graph Diffusion Models (GDMs) optimize for statistical likelihood, implicitly acting as \\textbf{frequency filters} that favor abundant substructures over spectrally critical ones. We term this phenomenon \\textbf{Generative Myopia}. In combinatorial tasks like graph sparsification, this leads to the catastrophic removal of ``rare bridges,'' edges that are structurally mandatory ($R_{\\text{eff}} \\approx 1$) but statistically scarce. We prove theoretically and empirically that this failure is driven by \\textbf{Gradient Starvation}: the optimization landscape itself suppresses rare structural signals, rendering them unlearnable regardless of model capacity. To resolve this, we introduce \\textbf{Spectrally-Weighted Diffusion}, which re-aligns the variational objective using Effective Resistance. We demonstrate that spectral priors can be amortized into the training phase with zero inference overhead. Our method eliminates myopia, matching the performance of an optimal Spectral Oracle and achieving \\textbf{100\\% connectivity} on adversarial benchmarks where standard diffusion fails completely (0\\%).", "AI": {"tldr": "\u56fe\u6269\u6563\u6a21\u578b\u5728\u4f18\u5316\u7edf\u8ba1\u4f3c\u7136\u65f6\u5b58\u5728\u751f\u6210\u6027\u8fd1\u89c6\u95ee\u9898\uff0c\u503e\u5411\u4e8e\u4fdd\u7559\u9891\u7e41\u5b50\u7ed3\u6784\u800c\u5ffd\u7565\u5149\u8c31\u5173\u952e\u7ed3\u6784\uff0c\u5bfc\u81f4\u5728\u7ec4\u5408\u4efb\u52a1\u4e2d\u707e\u96be\u6027\u5730\u79fb\u9664\u7a00\u6709\u4f46\u7ed3\u6784\u5fc5\u9700\u7684\u6865\u6881\u8fb9\u3002", "motivation": "\u89e3\u51b3\u56fe\u6269\u6563\u6a21\u578b\u5728\u7ec4\u5408\u4efb\u52a1\u4e2d\u56e0\u4f18\u5316\u7edf\u8ba1\u4f3c\u7136\u800c\u5bfc\u81f4\u7684\u751f\u6210\u6027\u8fd1\u89c6\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u7a00\u6709\u4f46\u7ed3\u6784\u5173\u952e\u8fb9\u7684\u8bc6\u522b\u548c\u4fdd\u7559\u5931\u8d25\u3002", "method": "\u63d0\u51fa\u5149\u8c31\u52a0\u6743\u6269\u6563\u65b9\u6cd5\uff0c\u4f7f\u7528\u6709\u6548\u7535\u963b\u91cd\u65b0\u5bf9\u9f50\u53d8\u5206\u76ee\u6807\uff0c\u5c06\u5149\u8c31\u5148\u9a8c\u644a\u9500\u5230\u8bad\u7ec3\u9636\u6bb5\u800c\u4e0d\u589e\u52a0\u63a8\u7406\u5f00\u9500\u3002", "result": "\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u8fd1\u89c6\u95ee\u9898\uff0c\u4e0e\u6700\u4f18\u5149\u8c31\u9884\u8a00\u673a\u6027\u80fd\u5339\u914d\uff0c\u5728\u6807\u51c6\u6269\u6563\u5b8c\u5168\u5931\u8d25\uff080%\uff09\u7684\u5bf9\u6297\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86100%\u7684\u8fde\u901a\u6027\u3002", "conclusion": "\u5149\u8c31\u5148\u9a8c\u53ef\u4ee5\u6709\u6548\u5730\u6574\u5408\u5230\u56fe\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u4e2d\uff0c\u89e3\u51b3\u68af\u5ea6\u9965\u997f\u95ee\u9898\uff0c\u786e\u4fdd\u5bf9\u7a00\u6709\u4f46\u7ed3\u6784\u5173\u952e\u8fb9\u7684\u6b63\u786e\u8bc6\u522b\u548c\u4fdd\u7559\u3002"}}
{"id": "2511.18611", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.18611", "abs": "https://arxiv.org/abs/2511.18611", "authors": ["Mengdi Wang", "Efe Bozkir", "Enkelejda Kasneci"], "title": "CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning", "comment": "The IEEE/CVF Winter Conference on Applications of Computer Vision 2026 (WACV-26)", "summary": "Split learning emerges as a promising paradigm for collaborative distributed model training, akin to federated learning, by partitioning neural networks between clients and a server without raw data exchange. However, sequential split learning suffers from poor scalability, while parallel variants like parallel split learning and split federated learning often incur high server resource overhead due to model duplication and aggregation, and generally exhibit reduced model performance and convergence owing to factors like client drift and lag. To address these limitations, we introduce CycleSL, a novel aggregation-free split learning framework that enhances scalability and performance and can be seamlessly integrated with existing methods. Inspired by alternating block coordinate descent, CycleSL treats server-side training as an independent higher-level machine learning task, resampling client-extracted features (smashed data) to mitigate heterogeneity and drift. It then performs cyclical updates, namely optimizing the server model first, followed by client updates using the updated server for gradient computation. We integrate CycleSL into previous algorithms and benchmark them on five publicly available datasets with non-iid data distribution and partial client attendance. Our empirical findings highlight the effectiveness of CycleSL in enhancing model performance. Our source code is available at https://gitlab.lrz.de/hctl/CycleSL.", "AI": {"tldr": "CycleSL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u65e0\u805a\u5408\u5206\u5272\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u670d\u52a1\u5668\u7aef\u8bad\u7ec3\u89c6\u4e3a\u72ec\u7acb\u7684\u9ad8\u7ea7\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff0c\u91c7\u7528\u5faa\u73af\u66f4\u65b0\u673a\u5236\u6765\u63d0\u5347\u53ef\u6269\u5c55\u6027\u548c\u6a21\u578b\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5206\u5272\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef\u6f02\u79fb\u548c\u670d\u52a1\u5668\u8d44\u6e90\u5f00\u9500\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5206\u5272\u5b66\u4e60\u5b58\u5728\u53ef\u6269\u5c55\u6027\u5dee\u3001\u670d\u52a1\u5668\u8d44\u6e90\u5f00\u9500\u5927\u3001\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\uff0c\u7279\u522b\u662f\u5e76\u884c\u53d8\u4f53\u4e2d\u7684\u6a21\u578b\u590d\u5236\u548c\u805a\u5408\u5bfc\u81f4\u9ad8\u5f00\u9500\uff0c\u5ba2\u6237\u7aef\u6f02\u79fb\u548c\u6ede\u540e\u5f71\u54cd\u6536\u655b\u6027\u80fd\u3002", "method": "CycleSL\u91c7\u7528\u4ea4\u66ff\u5757\u5750\u6807\u4e0b\u964d\u601d\u60f3\uff0c\u5c06\u670d\u52a1\u5668\u7aef\u8bad\u7ec3\u4f5c\u4e3a\u72ec\u7acb\u4efb\u52a1\uff0c\u91cd\u65b0\u91c7\u6837\u5ba2\u6237\u7aef\u63d0\u53d6\u7684\u7279\u5f81\u6765\u7f13\u89e3\u5f02\u6784\u6027\u548c\u6f02\u79fb\uff0c\u6267\u884c\u5faa\u73af\u66f4\u65b0\uff1a\u5148\u4f18\u5316\u670d\u52a1\u5668\u6a21\u578b\uff0c\u7136\u540e\u4f7f\u7528\u66f4\u65b0\u540e\u7684\u670d\u52a1\u5668\u8fdb\u884c\u5ba2\u6237\u7aef\u68af\u5ea6\u8ba1\u7b97\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCycleSL\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u548c\u90e8\u5206\u5ba2\u6237\u7aef\u53c2\u4e0e\u7684\u573a\u666f\u4e0b\u3002", "conclusion": "CycleSL\u662f\u4e00\u4e2a\u6709\u6548\u7684\u65e0\u805a\u5408\u5206\u5272\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u73b0\u6709\u65b9\u6cd5\u65e0\u7f1d\u96c6\u6210\u3002"}}
{"id": "2511.18615", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.18615", "abs": "https://arxiv.org/abs/2511.18615", "authors": ["Jiawei Hu", "Javier A. Barria"], "title": "Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet Priors", "comment": "13 pages, submitted to IEEE journal for possible publication", "summary": "Label shift, a prevalent challenge in supervised learning, arises when the class prior distribution of test data differs from that of training data, leading to significant degradation in classifier performance. To accurately estimate the test priors and enhance classification accuracy, we propose a Bayesian framework for label shift estimation, termed Full Maximum A Posterior Label Shift (FMAPLS), along with its online version, online-FMAPLS. Leveraging batch and online Expectation-Maximization (EM) algorithms, these methods jointly and dynamically optimize Dirichlet hyperparameters $\\boldsymbol\u03b1$ and class priors $\\boldsymbol\u03c0$, thereby overcoming the rigid constraints of the existing Maximum A Posterior Label Shift (MAPLS) approach. Moreover, we introduce a linear surrogate function (LSF) to replace gradient-based hyperparameter updates, yielding closed-form solutions that reduce computational complexity while retaining asymptotic equivalence. The online variant substitutes the batch E-step with a stochastic approximation, enabling real-time adaptation to streaming data. Furthermore, our theoretical analysis reveals a fundamental trade-off between online convergence rate and estimation accuracy. Extensive experiments on CIFAR100 and ImageNet datasets under shuffled long-tail and Dirichlet test priors demonstrate that FMAPLS and online-FMAPLS respectively achieve up to 40% and 12% lower KL divergence and substantial improvements in post-shift accuracy over state-of-the-art baselines, particularly under severe class imbalance and distributional uncertainty. These results confirm the robustness, scalability, and suitability of the proposed methods for large-scale and dynamic learning scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86FMAPLS\u548conline-FMAPLS\u4e24\u79cd\u8d1d\u53f6\u65af\u6846\u67b6\u6765\u89e3\u51b3\u6807\u7b7e\u504f\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316Dirichlet\u8d85\u53c2\u6570\u548c\u7c7b\u5148\u9a8c\uff0c\u5728CIFAR100\u548cImageNet\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u6807\u7b7e\u504f\u79fb\u662f\u76d1\u7763\u5b66\u4e60\u4e2d\u5e38\u89c1\u7684\u95ee\u9898\uff0c\u5f53\u6d4b\u8bd5\u6570\u636e\u7684\u7c7b\u522b\u5148\u9a8c\u5206\u5e03\u4e0e\u8bad\u7ec3\u6570\u636e\u4e0d\u540c\u65f6\uff0c\u4f1a\u5bfc\u81f4\u5206\u7c7b\u5668\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u521a\u6027\u7ea6\u675f\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86FMAPLS\u548c\u5728\u7ebf\u7248\u672conline-FMAPLS\uff0c\u5229\u7528\u6279\u5904\u7406\u548c\u5728\u7ebfEM\u7b97\u6cd5\u8054\u5408\u4f18\u5316Dirichlet\u8d85\u53c2\u6570\u03b1\u548c\u7c7b\u5148\u9a8c\u03c0\uff0c\u5f15\u5165\u7ebf\u6027\u66ff\u4ee3\u51fd\u6570\u7b80\u5316\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6e10\u8fd1\u7b49\u4ef7\u6027\u3002", "result": "\u5728CIFAR100\u548cImageNet\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFMAPLS\u548conline-FMAPLS\u5206\u522b\u5b9e\u73b0\u4e86\u9ad8\u8fbe40%\u548c12%\u7684KL\u6563\u5ea6\u964d\u4f4e\uff0c\u5e76\u5728\u540e\u504f\u79fb\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u548c\u52a8\u6001\u5b66\u4e60\u573a\u666f\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u6807\u7b7e\u504f\u79fb\u95ee\u9898\u3002"}}
{"id": "2511.18631", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18631", "abs": "https://arxiv.org/abs/2511.18631", "authors": ["Kiyan Rezaee", "Morteza Ziabakhsh", "Niloofar Nikfarjam", "Mohammad M. Ghassemi", "Yazdan Rezaee Jouryabi", "Sadegh Eskandari", "Reza Lashgari"], "title": "FOS: A Large-Scale Temporal Graph Benchmark for Scientific Interdisciplinary Link Prediction", "comment": "21 pages, 10 figures", "summary": "Interdisciplinary scientific breakthroughs mostly emerge unexpectedly, and forecasting the formation of novel research fields remains a major challenge. We introduce FOS (Future Of Science), a comprehensive time-aware graph-based benchmark that reconstructs annual co-occurrence graphs of 65,027 research sub-fields (spanning 19 general domains) over the period 1827-2024. In these graphs, edges denote the co-occurrence of two fields in a single publication and are timestamped with the corresponding publication year. Nodes are enriched with semantic embeddings, and edges are characterized by temporal and topological descriptors. We formulate the prediction of new field-pair linkages as a temporal link-prediction task, emphasizing the \"first-time\" connections that signify pioneering interdisciplinary directions. Through extensive experiments, we evaluate a suite of state-of-the-art temporal graph architectures under multiple negative-sampling regimes and show that (i) embedding long-form textual descriptions of fields significantly boosts prediction accuracy, and (ii) distinct model classes excel under different evaluation settings. Case analyses show that top-ranked link predictions on FOS align with field pairings that emerge in subsequent years of academic publications. We publicly release FOS, along with its temporal data splits and evaluation code, to establish a reproducible benchmark for advancing research in predicting scientific frontiers.", "AI": {"tldr": "FOS\u662f\u4e00\u4e2a\u65f6\u95f4\u611f\u77e5\u7684\u56fe\u57fa\u51c6\uff0c\u7528\u4e8e\u9884\u6d4b\u79d1\u5b66\u7814\u7a76\u9886\u57df\u7684\u9996\u6b21\u8de8\u5b66\u79d1\u8fde\u63a5\uff0c\u901a\u8fc7\u5206\u67901827-2024\u5e74\u95f465,027\u4e2a\u5b50\u9886\u57df\u7684\u5171\u73b0\u5173\u7cfb\u6765\u9884\u6d4b\u79d1\u5b66\u524d\u6cbf\u3002", "motivation": "\u8de8\u5b66\u79d1\u79d1\u5b66\u7a81\u7834\u901a\u5e38\u610f\u5916\u51fa\u73b0\uff0c\u9884\u6d4b\u65b0\u7814\u7a76\u9886\u57df\u7684\u5f62\u6210\u4ecd\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u53ef\u91cd\u73b0\u7684\u57fa\u51c6\u6765\u63a8\u8fdb\u79d1\u5b66\u524d\u6cbf\u9884\u6d4b\u7814\u7a76\u3002", "method": "\u6784\u5efa\u5e74\u5ea6\u5171\u73b0\u56fe\uff0c\u8282\u70b9\u4e3a\u7814\u7a76\u5b50\u9886\u57df\u5e76\u5305\u542b\u8bed\u4e49\u5d4c\u5165\uff0c\u8fb9\u8868\u793a\u4e24\u4e2a\u9886\u57df\u5728\u540c\u4e00\u51fa\u7248\u7269\u4e2d\u7684\u5171\u73b0\u5173\u7cfb\u5e76\u5e26\u6709\u65f6\u95f4\u6233\u3002\u5c06\u65b0\u9886\u57df\u5bf9\u8fde\u63a5\u7684\u9884\u6d4b\u5efa\u6a21\u4e3a\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a(i) \u4f7f\u7528\u9886\u57df\u7684\u957f\u6587\u672c\u63cf\u8ff0\u5d4c\u5165\u80fd\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff1b(ii) \u4e0d\u540c\u6a21\u578b\u7c7b\u5728\u4e0d\u540c\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\uff1b(iii) \u6848\u4f8b\u5206\u6790\u663e\u793aFOS\u7684\u9876\u7ea7\u94fe\u63a5\u9884\u6d4b\u4e0e\u540e\u7eed\u5e74\u4efd\u51fa\u73b0\u7684\u5b66\u672f\u51fa\u7248\u7269\u4e2d\u7684\u9886\u57df\u914d\u5bf9\u4e00\u81f4\u3002", "conclusion": "FOS\u57fa\u51c6\u4e3a\u9884\u6d4b\u79d1\u5b66\u524d\u6cbf\u63d0\u4f9b\u4e86\u53ef\u91cd\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u8bed\u4e49\u5d4c\u5165\u548c\u65f6\u95f4\u56fe\u6a21\u578b\u5728\u9884\u6d4b\u8de8\u5b66\u79d1\u79d1\u5b66\u7a81\u7834\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.18671", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.18671", "abs": "https://arxiv.org/abs/2511.18671", "authors": ["Yan Wang", "Ke Deng", "Yongli Ren"], "title": "Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition", "comment": null, "summary": "Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others' learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified k-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMCEM\u65b9\u6cd5\u7ed3\u5408\u975e\u7ebf\u6027\u8bc4\u8bba\u5bb6\u5206\u89e3\uff0c\u901a\u8fc7\u6392\u9664\u6b21\u4f18\u884c\u4e3a\u6765\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u96c6\u4e2d-\u5206\u6563\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728\u8fde\u7eed\u548c\u79bb\u6563\u52a8\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u96c6\u4e2d\u8bad\u7ec3\u4e0e\u5206\u6563\u6267\u884c(CTDE)\u8303\u5f0f\u4e0b\u7684\u96c6\u4e2d-\u5206\u6563\u4e0d\u5339\u914d(CDM)\u95ee\u9898\uff0c\u5373\u4e00\u4e2a\u667a\u80fd\u4f53\u7684\u6b21\u4f18\u884c\u4e3a\u4f1a\u964d\u4f4e\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u4ea4\u53c9\u71b5\u65b9\u6cd5(MCEM)\u7ed3\u5408\u5355\u8c03\u975e\u7ebf\u6027\u8bc4\u8bba\u5bb6\u5206\u89e3(NCD)\uff0c\u901a\u8fc7\u589e\u52a0\u9ad8\u4ef7\u503c\u8054\u5408\u52a8\u4f5c\u7684\u6982\u7387\u6765\u6392\u9664\u6b21\u4f18\u884c\u4e3a\uff0c\u5e76\u6269\u5c55\u4e86\u79bb\u7b56\u7565\u5b66\u4e60\uff0c\u4f7f\u7528\u6539\u8fdb\u7684k\u6b65\u56de\u62a5\u548cRetrace\u6280\u672f\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "result": "\u5206\u6790\u548c\u5b9e\u9a8c\u8868\u660e\uff0cMCEM\u5728\u8fde\u7eed\u548c\u79bb\u6563\u52a8\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "MCEM\u65b9\u6cd5\u6210\u529f\u514b\u670d\u4e86\u7ebf\u6027\u5206\u89e3\u8868\u8fbe\u80fd\u529b\u6709\u9650\u548c\u975e\u7ebf\u6027\u5206\u89e3\u9700\u8981\u96c6\u4e2d\u68af\u5ea6\u7684\u95ee\u9898\uff0c\u6709\u6548\u89e3\u51b3\u4e86CDM\u95ee\u9898\uff0c\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.18716", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18716", "abs": "https://arxiv.org/abs/2511.18716", "authors": ["Zesheng Liu", "Maryam Rahnemoonfar"], "title": "GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction", "comment": null, "summary": "Graph transformers have demonstrated remarkable capability on complex spatio-temporal tasks, yet their depth is often limited by oversmoothing and weak long-range dependency modeling. To address these challenges, we introduce GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness estimation from polar radar imagery. Accurately estimating ice layer thickness is critical for understanding snow accumulation, reconstructing past climate patterns and reducing uncertainties in projections of future ice sheet evolution and sea level rise. GRIT-LP combines an inductive geometric graph learning framework with self-attention mechanism, and introduces two major innovations that jointly address challenges in modeling the spatio-temporal patterns of ice layers: a partitioned spatial graph construction strategy that forms overlapping, fully connected local neighborhoods to preserve spatial coherence and suppress noise from irrelevant long-range links, and a long-range skip connection mechanism within the transformer that improves information flow and mitigates oversmoothing in deeper attention layers. We conducted extensive experiments, demonstrating that GRIT-LP outperforms current state-of-the-art methods with a 24.92\\% improvement in root mean squared error. These results highlight the effectiveness of graph transformers in modeling spatiotemporal patterns by capturing both localized structural features and long-range dependencies across internal ice layers, and demonstrate their potential to advance data-driven understanding of cryospheric processes.", "AI": {"tldr": "GRIT-LP\u662f\u4e00\u79cd\u4e13\u95e8\u7528\u4e8e\u6781\u5730\u96f7\u8fbe\u56fe\u50cf\u51b0\u5c42\u539a\u5ea6\u4f30\u8ba1\u7684\u56fe\u53d8\u6362\u5668\uff0c\u901a\u8fc7\u5206\u533a\u7a7a\u95f4\u56fe\u6784\u5efa\u7b56\u7565\u548c\u957f\u7a0b\u8df3\u8dc3\u8fde\u63a5\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u56fe\u53d8\u6362\u5668\u7684\u8fc7\u5e73\u6ed1\u548c\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\u95ee\u9898\uff0c\u5728RMSE\u6307\u6807\u4e0a\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u5347\u4e8624.92%\u3002", "motivation": "\u51c6\u786e\u4f30\u8ba1\u51b0\u5c42\u539a\u5ea6\u5bf9\u4e8e\u7406\u89e3\u79ef\u96ea\u79ef\u7d2f\u3001\u91cd\u5efa\u8fc7\u53bb\u6c14\u5019\u6a21\u5f0f\u4ee5\u53ca\u51cf\u5c11\u672a\u6765\u51b0\u76d6\u6f14\u5316\u548c\u6d77\u5e73\u9762\u4e0a\u5347\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u56fe\u53d8\u6362\u5668\u5728\u6df1\u5ea6\u5efa\u6a21\u65f6\u9762\u4e34\u8fc7\u5e73\u6ed1\u548c\u5f31\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\u7684\u6311\u6218\u3002", "method": "GRIT-LP\u7ed3\u5408\u5f52\u7eb3\u51e0\u4f55\u56fe\u5b66\u4e60\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u91c7\u7528\u5206\u533a\u7a7a\u95f4\u56fe\u6784\u5efa\u7b56\u7565\u5f62\u6210\u91cd\u53e0\u7684\u5b8c\u5168\u8fde\u63a5\u5c40\u90e8\u90bb\u57df\u4ee5\u4fdd\u6301\u7a7a\u95f4\u4e00\u81f4\u6027\u5e76\u6291\u5236\u65e0\u5173\u957f\u7a0b\u94fe\u63a5\u7684\u566a\u58f0\uff0c\u540c\u65f6\u5728\u53d8\u6362\u5668\u4e2d\u5f15\u5165\u957f\u7a0b\u8df3\u8dc3\u8fde\u63a5\u673a\u5236\u6539\u5584\u4fe1\u606f\u6d41\u5e76\u51cf\u8f7b\u6df1\u5c42\u6ce8\u610f\u529b\u5c42\u7684\u8fc7\u5e73\u6ed1\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGRIT-LP\u5728\u5747\u65b9\u6839\u8bef\u5dee\u6307\u6807\u4e0a\u6bd4\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u63d0\u5347\u4e8624.92%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GRIT-LP\u901a\u8fc7\u540c\u65f6\u6355\u6349\u5c40\u90e8\u7ed3\u6784\u7279\u5f81\u548c\u8de8\u51b0\u5c42\u5185\u90e8\u7684\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u6709\u6548\u5efa\u6a21\u4e86\u65f6\u7a7a\u6a21\u5f0f\uff0c\u5c55\u793a\u4e86\u56fe\u53d8\u6362\u5668\u5728\u63a8\u8fdb\u51b0\u51bb\u5708\u8fc7\u7a0b\u6570\u636e\u9a71\u52a8\u7406\u89e3\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.18721", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18721", "abs": "https://arxiv.org/abs/2511.18721", "authors": ["Adarsh Kumarappan", "Ayushi Mehrotra"], "title": "Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM", "comment": null, "summary": "The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u73b0\u5b9e\u7684\u6982\u7387\u6846\u67b6(k, \u03b5)-unstable\u6765\u6539\u8fdbSmoothLLM\u9632\u5fa1\uff0c\u901a\u8fc7\u7ed3\u5408\u653b\u51fb\u6210\u529f\u7387\u7684\u7ecf\u9a8c\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u66f4\u53ef\u4fe1\u548c\u5b9e\u7528\u7684\u5b89\u5168\u8ba4\u8bc1\u3002", "motivation": "SmoothLLM\u9632\u5fa1\u4f9d\u8d56\u4e8e\u4e25\u683c\u7684k-unstable\u5047\u8bbe\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f88\u5c11\u6210\u7acb\uff0c\u9650\u5236\u4e86\u5b89\u5168\u8bc1\u4e66\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u5f15\u5165(k, \u03b5)-unstable\u6982\u7387\u6846\u67b6\uff0c\u7ed3\u5408\u653b\u51fb\u6210\u529f\u7387\u7684\u7ecf\u9a8c\u6a21\u578b\uff0c\u63a8\u5bfc\u51faSmoothLLM\u9632\u5fa1\u6982\u7387\u7684\u65b0\u4e0b\u754c\u3002", "result": "\u5f00\u53d1\u4e86\u66f4\u53ef\u4fe1\u548c\u5b9e\u7528\u7684\u5b89\u5168\u8ba4\u8bc1\u673a\u5236\uff0c\u80fd\u591f\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5b89\u5168\u4fdd\u8bc1\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aLLM\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u7406\u8bba\u57fa\u7840\u7684\u673a\u5236\uff0c\u4f7f\u5176\u66f4\u80fd\u62b5\u6297\u5bf9\u5176\u5b89\u5168\u5bf9\u9f50\u7684\u5229\u7528\u3002"}}
{"id": "2511.18727", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18727", "abs": "https://arxiv.org/abs/2511.18727", "authors": ["Devansh Agarwal", "Maitreyi Chatterjee", "Biplab Chatterjee"], "title": "LogSyn: A Few-Shot LLM Framework for Structured Insight Extraction from Unstructured General Aviation Maintenance Logs", "comment": "Accepted in Proceedings of the 3rd INCOM 2026", "summary": "Aircraft maintenance logs hold valuable safety data but remain underused due to their unstructured text format. This paper introduces LogSyn, a framework that uses Large Language Models (LLMs) to convert these logs into structured, machine-readable data. Using few-shot in-context learning on 6,169 records, LogSyn performs Controlled Abstraction Generation (CAG) to summarize problem-resolution narratives and classify events within a detailed hierarchical ontology. The framework identifies key failure patterns, offering a scalable method for semantic structuring and actionable insight extraction from maintenance logs. This work provides a practical path to improve maintenance workflows and predictive analytics in aviation and related industries.", "AI": {"tldr": "LogSyn\u6846\u67b6\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u975e\u7ed3\u6784\u5316\u7684\u98de\u673a\u7ef4\u62a4\u65e5\u5fd7\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u6570\u636e\uff0c\u901a\u8fc7\u5c11\u6837\u672c\u5b66\u4e60\u8fdb\u884c\u95ee\u9898-\u89e3\u51b3\u53d9\u8ff0\u7684\u62bd\u8c61\u751f\u6210\u548c\u4e8b\u4ef6\u5206\u7c7b\uff0c\u4ee5\u63d0\u53d6\u53ef\u64cd\u4f5c\u7684\u7ef4\u62a4\u89c1\u89e3\u3002", "motivation": "\u98de\u673a\u7ef4\u62a4\u65e5\u5fd7\u5305\u542b\u5b9d\u8d35\u7684\u5b89\u5168\u6570\u636e\uff0c\u4f46\u7531\u4e8e\u5176\u975e\u7ed3\u6784\u5316\u6587\u672c\u683c\u5f0f\u800c\u672a\u88ab\u5145\u5206\u5229\u7528\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\u548c\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5c11\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u57286,169\u6761\u8bb0\u5f55\u4e0a\u6267\u884c\u53d7\u63a7\u62bd\u8c61\u751f\u6210\uff0c\u603b\u7ed3\u95ee\u9898-\u89e3\u51b3\u53d9\u8ff0\u5e76\u5728\u8be6\u7ec6\u5c42\u6b21\u672c\u4f53\u4e2d\u5206\u7c7b\u4e8b\u4ef6\u3002", "result": "\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u5173\u952e\u6545\u969c\u6a21\u5f0f\uff0c\u4e3a\u7ef4\u62a4\u65e5\u5fd7\u7684\u8bed\u4e49\u7ed3\u6784\u5316\u548c\u53ef\u64cd\u4f5c\u89c1\u89e3\u63d0\u53d6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6539\u8fdb\u822a\u7a7a\u53ca\u76f8\u5173\u884c\u4e1a\u7684\u7ef4\u62a4\u5de5\u4f5c\u6d41\u7a0b\u548c\u9884\u6d4b\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2511.18728", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18728", "abs": "https://arxiv.org/abs/2511.18728", "authors": ["Maitreyi Chatterjee", "Devansh Agarwal", "Biplab Chatterjee"], "title": "Reinforcement Learning for Self-Healing Material Systems", "comment": "Accepted to INCOM 2026. This is the camera-ready version", "summary": "The transition to autonomous material systems necessitates adaptive control methodologies to maximize structural longevity. This study frames the self-healing process as a Reinforcement Learning (RL) problem within a Markov Decision Process (MDP), enabling agents to autonomously derive optimal policies that efficiently balance structural integrity maintenance against finite resource consumption. A comparative evaluation of discrete-action (Q-learning, DQN) and continuous-action (TD3) agents in a stochastic simulation environment revealed that RL controllers significantly outperform heuristic baselines, achieving near-complete material recovery. Crucially, the TD3 agent utilizing continuous dosage control demonstrated superior convergence speed and stability, underscoring the necessity of fine-grained, proportional actuation in dynamic self-healing applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u81ea\u6108\u5408\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u6bd4\u8f83\u4e86\u79bb\u6563\u52a8\u4f5c\u548c\u8fde\u7eed\u52a8\u4f5c\u667a\u80fd\u4f53\u5728\u6750\u6599\u81ea\u6108\u5408\u63a7\u5236\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0TD3\u667a\u80fd\u4f53\u5728\u8fde\u7eed\u5242\u91cf\u63a7\u5236\u65b9\u9762\u8868\u73b0\u6700\u4f18\u3002", "motivation": "\u5411\u81ea\u4e3b\u6750\u6599\u7cfb\u7edf\u8fc7\u6e21\u9700\u8981\u81ea\u9002\u5e94\u63a7\u5236\u65b9\u6cd5\u6765\u6700\u5927\u5316\u7ed3\u6784\u5bff\u547d\uff0c\u5c06\u81ea\u6108\u5408\u8fc7\u7a0b\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u6765\u5e73\u8861\u7ed3\u6784\u5b8c\u6574\u6027\u548c\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u5c06\u81ea\u6108\u5408\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6bd4\u8f83\u79bb\u6563\u52a8\u4f5c\u667a\u80fd\u4f53\uff08Q-learning\u3001DQN\uff09\u548c\u8fde\u7eed\u52a8\u4f5c\u667a\u80fd\u4f53\uff08TD3\uff09\u5728\u968f\u673a\u6a21\u62df\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u663e\u8457\u4f18\u4e8e\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u5168\u7684\u6750\u6599\u6062\u590d\u3002TD3\u667a\u80fd\u4f53\u5728\u8fde\u7eed\u5242\u91cf\u63a7\u5236\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8fde\u7eed\u3001\u6bd4\u4f8b\u63a7\u5236\u7684\u7cbe\u7ec6\u81f4\u52a8\u5728\u52a8\u6001\u81ea\u6108\u5408\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0cTD3\u667a\u80fd\u4f53\u5728\u8fde\u7eed\u5242\u91cf\u63a7\u5236\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.18732", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.18732", "abs": "https://arxiv.org/abs/2511.18732", "authors": ["Haoming Jia", "Yi Han", "Xiang Wang", "Huizan Wang", "Wei Wu", "Jianming Zheng", "Peikun Xiao"], "title": "OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting", "comment": null, "summary": "Global ocean forecasting aims to predict key ocean variables such as temperature, salinity, and currents, which is essential for understanding and describing oceanic phenomena. In recent years, data-driven deep learning-based ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have demonstrated significant potential in capturing complex ocean dynamics and improving forecasting efficiency. Despite these advancements, the absence of open-source, standardized benchmarks has led to inconsistent data usage and evaluation methods. This gap hinders efficient model development, impedes fair performance comparison, and constrains interdisciplinary collaboration. To address this challenge, we propose OceanForecastBench, a benchmark offering three core contributions: (1) A high-quality global ocean reanalysis data over 28 years for model training, including 4 ocean variables across 23 depth levels and 4 sea surface variables. (2) A high-reliability satellite and in-situ observations for model evaluation, covering approximately 100 million locations in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark with 6 typical baseline models, leveraging observations to evaluate model performance from multiple perspectives. OceanForecastBench represents the most comprehensive benchmarking framework currently available for data-driven ocean forecasting, offering an open-source platform for model development, evaluation, and comparison. The dataset and code are publicly available at: https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86OceanForecastBench\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u6570\u636e\u9a71\u52a8\u6d77\u6d0b\u9884\u62a5\u7684\u5f00\u6e90\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5305\u542b28\u5e74\u9ad8\u8d28\u91cf\u518d\u5206\u6790\u6570\u636e\u3001\u9ad8\u53ef\u9760\u6027\u89c2\u6d4b\u6570\u636e\u548c\u8bc4\u4f30\u7ba1\u9053\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u57fa\u51c6\u5bfc\u81f4\u7684\u6570\u636e\u4f7f\u7528\u4e0d\u4e00\u81f4\u548c\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u7edf\u4e00\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u9a71\u52a8\u7684\u6df1\u5ea6\u5b66\u4e60\u6d77\u6d0b\u9884\u62a5\u6a21\u578b\uff08\u5982XiHe\u3001WenHai\u7b49\uff09\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u7f3a\u4e4f\u5f00\u6e90\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5bfc\u81f4\u6570\u636e\u4f7f\u7528\u548c\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u4e00\u81f4\uff0c\u963b\u788d\u4e86\u6a21\u578b\u5f00\u53d1\u3001\u516c\u5e73\u6027\u80fd\u6bd4\u8f83\u548c\u8de8\u5b66\u79d1\u5408\u4f5c\u3002", "method": "\u63d0\u51faOceanForecastBench\u57fa\u51c6\uff0c\u63d0\u4f9b\u4e09\u4e2a\u6838\u5fc3\u8d21\u732e\uff1a28\u5e74\u9ad8\u8d28\u91cf\u5168\u7403\u6d77\u6d0b\u518d\u5206\u6790\u6570\u636e\uff084\u4e2a\u6d77\u6d0b\u53d8\u91cf\u00d723\u4e2a\u6df1\u5ea6\u5c42\u6b21+4\u4e2a\u6d77\u8868\u53d8\u91cf\uff09\u3001\u9ad8\u53ef\u9760\u6027\u536b\u661f\u548c\u73b0\u573a\u89c2\u6d4b\u6570\u636e\uff08\u7ea61\u4ebf\u4e2a\u5168\u7403\u6d77\u6d0b\u4f4d\u7f6e\uff09\u3001\u8bc4\u4f30\u7ba1\u9053\u548c\u5305\u542b6\u4e2a\u5178\u578b\u57fa\u7ebf\u6a21\u578b\u7684\u7efc\u5408\u57fa\u51c6\u3002", "result": "OceanForecastBench\u662f\u76ee\u524d\u6700\u5168\u9762\u7684\u6570\u636e\u9a71\u52a8\u6d77\u6d0b\u9884\u62a5\u57fa\u51c6\u6846\u67b6\uff0c\u4e3a\u6a21\u578b\u5f00\u53d1\u3001\u8bc4\u4f30\u548c\u6bd4\u8f83\u63d0\u4f9b\u4e86\u5f00\u6e90\u5e73\u53f0\u3002\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "OceanForecastBench\u586b\u8865\u4e86\u6570\u636e\u9a71\u52a8\u6d77\u6d0b\u9884\u62a5\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u5c06\u4fc3\u8fdb\u6a21\u578b\u9ad8\u6548\u5f00\u53d1\u3001\u516c\u5e73\u6bd4\u8f83\u548c\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.18773", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.18773", "abs": "https://arxiv.org/abs/2511.18773", "authors": ["Senmao Tian", "Xiang Wei", "Shunli Zhang"], "title": "Sampling Control for Imbalanced Calibration in Semi-Supervised Learning", "comment": "Accepted at AAAI 2026", "summary": "Class imbalance remains a critical challenge in semi-supervised learning (SSL), especially when distributional mismatches between labeled and unlabeled data lead to biased classification. Although existing methods address this issue by adjusting logits based on the estimated class distribution of unlabeled data, they often handle model imbalance in a coarse-grained manner, conflating data imbalance with bias arising from varying class-specific learning difficulties. To address this issue, we propose a unified framework, SC-SSL, which suppresses model bias through decoupled sampling control. During training, we identify the key variables for sampling control under ideal conditions. By introducing a classifier with explicit expansion capability and adaptively adjusting sampling probabilities across different data distributions, SC-SSL mitigates feature-level imbalance for minority classes. In the inference phase, we further analyze the weight imbalance of the linear classifier and apply post-hoc sampling control with an optimization bias vector to directly calibrate the logits. Extensive experiments across various benchmark datasets and distribution settings validate the consistency and state-of-the-art performance of SC-SSL.", "AI": {"tldr": "SC-SSL\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u91c7\u6837\u63a7\u5236\u6765\u6291\u5236\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u6a21\u578b\u504f\u5dee\uff0c\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u5f80\u5f80\u5c06\u6570\u636e\u4e0d\u5e73\u8861\u4e0e\u7c7b\u522b\u7279\u5b9a\u5b66\u4e60\u96be\u5ea6\u5f15\u8d77\u7684\u504f\u5dee\u6df7\u4e3a\u4e00\u8c08\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faSC-SSL\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u91c7\u6837\u63a7\u5236\u7684\u5173\u952e\u53d8\u91cf\uff0c\u5f15\u5165\u5177\u6709\u663e\u5f0f\u6269\u5c55\u80fd\u529b\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u4e0d\u540c\u6570\u636e\u5206\u5e03\u7684\u91c7\u6837\u6982\u7387\u3002\u5728\u63a8\u7406\u9636\u6bb5\u5206\u6790\u7ebf\u6027\u5206\u7c7b\u5668\u7684\u6743\u91cd\u4e0d\u5e73\u8861\uff0c\u5e94\u7528\u540e\u5904\u7406\u91c7\u6837\u63a7\u5236\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5206\u5e03\u8bbe\u7f6e\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86SC-SSL\u7684\u4e00\u81f4\u6027\u548c\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "SC-SSL\u901a\u8fc7\u89e3\u8026\u91c7\u6837\u63a7\u5236\u6709\u6548\u7f13\u89e3\u4e86\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.18777", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18777", "abs": "https://arxiv.org/abs/2511.18777", "authors": ["Chenhong Zhou", "Jie Chen", "Zaifeng Yang"], "title": "SAOT: An Enhanced Locality-Aware Spectral Transformer for Solving PDEs", "comment": "Accepted to AAAI 2026 (Main Technical Track)", "summary": "Neural operators have shown great potential in solving a family of Partial Differential Equations (PDEs) by modeling the mappings between input and output functions. Fourier Neural Operator (FNO) implements global convolutions via parameterizing the integral operators in Fourier space. However, it often results in over-smoothing solutions and fails to capture local details and high-frequency components. To address these limitations, we investigate incorporating the spatial-frequency localization property of Wavelet transforms into the Transformer architecture. We propose a novel Wavelet Attention (WA) module with linear computational complexity to efficiently learn locality-aware features. Building upon WA, we further develop the Spectral Attention Operator Transformer (SAOT), a hybrid spectral Transformer framework that integrates WA's localized focus with the global receptive field of Fourier-based Attention (FA) through a gated fusion block. Experimental results demonstrate that WA significantly mitigates the limitations of FA and outperforms existing Wavelet-based neural operators by a large margin. By integrating the locality-aware and global spectral representations, SAOT achieves state-of-the-art performance on six operator learning benchmarks and exhibits strong discretization-invariant ability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c0f\u6ce2\u53d8\u6362\u7a7a\u95f4-\u9891\u7387\u5c40\u90e8\u5316\u7279\u6027\u7684\u65b0\u578bWavelet Attention\u6a21\u5757\u548cSpectral Attention Operator Transformer\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86Fourier Neural Operator\u5728\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u8fc7\u5ea6\u5e73\u6ed1\u548c\u65e0\u6cd5\u6355\u6349\u5c40\u90e8\u7ec6\u8282\u7684\u95ee\u9898\u3002", "motivation": "Fourier Neural Operator\u5728\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u5b58\u5728\u8fc7\u5ea6\u5e73\u6ed1\u89e3\u3001\u65e0\u6cd5\u6355\u6349\u5c40\u90e8\u7ec6\u8282\u548c\u9ad8\u9891\u5206\u91cf\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u66f4\u597d\u5730\u5904\u7406\u7a7a\u95f4\u5c40\u90e8\u7279\u5f81\u3002", "method": "\u63d0\u51faWavelet Attention\u6a21\u5757\uff0c\u5229\u7528\u5c0f\u6ce2\u53d8\u6362\u7684\u7a7a\u95f4-\u9891\u7387\u5c40\u90e8\u5316\u7279\u6027\uff0c\u5177\u6709\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\uff1b\u8fdb\u4e00\u6b65\u5f00\u53d1Spectral Attention Operator Transformer\u6df7\u5408\u8c31Transformer\u6846\u67b6\uff0c\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u5757\u5c06WA\u7684\u5c40\u90e8\u5173\u6ce8\u4e0eFourier-based Attention\u7684\u5168\u5c40\u611f\u53d7\u91ce\u76f8\u7ed3\u5408\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cWA\u663e\u8457\u7f13\u89e3\u4e86FA\u7684\u5c40\u9650\u6027\uff0c\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5c0f\u6ce2\u7684\u795e\u7ecf\u7b97\u5b50\u3002SAOT\u5728\u516d\u4e2a\u7b97\u5b50\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u79bb\u6563\u5316\u4e0d\u53d8\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u5c40\u90e8\u611f\u77e5\u548c\u5168\u5c40\u8c31\u8868\u793a\uff0cSAOT\u6846\u67b6\u5728\u504f\u5fae\u5206\u65b9\u7a0b\u7b97\u5b50\u5b66\u4e60\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6027\u80fd\uff0c\u4e3a\u795e\u7ecf\u7b97\u5b50\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u7a7a\u95f4-\u9891\u7387\u8868\u793a\u65b9\u6cd5\u3002"}}
{"id": "2511.18829", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18829", "abs": "https://arxiv.org/abs/2511.18829", "authors": ["Kanav Arora", "Girish Narayanswamy", "Shwetak Patel", "Richard Li"], "title": "Towards Characterizing Knowledge Distillation of PPG Heart Rate Estimation Models", "comment": "To be published in: 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Learning from Time Series for Health", "summary": "Heart rate estimation from photoplethysmography (PPG) signals generated by wearable devices such as smartwatches and fitness trackers has significant implications for the health and well-being of individuals. Although prior work has demonstrated deep learning models with strong performance in the heart rate estimation task, in order to deploy these models on wearable devices, these models must also adhere to strict memory and latency constraints. In this work, we explore and characterize how large pre-trained PPG models may be distilled to smaller models appropriate for real-time inference on the edge. We evaluate four distillation strategies through comprehensive sweeps of teacher and student model capacities: (1) hard distillation, (2) soft distillation, (3) decoupled knowledge distillation (DKD), and (4) feature distillation. We present a characterization of the resulting scaling laws describing the relationship between model size and performance. This early investigation lays the groundwork for practical and predictable methods for building edge-deployable models for physiological sensing.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5c06\u5927\u578b\u9884\u8bad\u7ec3PPG\u6a21\u578b\u84b8\u998f\u4e3a\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u5b9e\u65f6\u63a8\u7406\u7684\u5c0f\u578b\u6a21\u578b\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u84b8\u998f\u7b56\u7565\u5e76\u63cf\u8ff0\u4e86\u6a21\u578b\u5927\u5c0f\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u7f29\u653e\u89c4\u5f8b\u3002", "motivation": "\u867d\u7136\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5fc3\u7387\u4f30\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8981\u5728\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0a\u90e8\u7f72\u8fd9\u4e9b\u6a21\u578b\uff0c\u5fc5\u987b\u6ee1\u8db3\u4e25\u683c\u7684\u5185\u5b58\u548c\u5ef6\u8fdf\u9650\u5236\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u6a21\u578b\u84b8\u998f\u6280\u672f\u3002", "method": "\u8bc4\u4f30\u4e86\u56db\u79cd\u84b8\u998f\u7b56\u7565\uff1a\u786c\u84b8\u998f\u3001\u8f6f\u84b8\u998f\u3001\u89e3\u8026\u77e5\u8bc6\u84b8\u998f(DKD)\u548c\u7279\u5f81\u84b8\u998f\uff0c\u901a\u8fc7\u5168\u9762\u7684\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u5bb9\u91cf\u626b\u63cf\u6765\u8868\u5f81\u7f29\u653e\u89c4\u5f8b\u3002", "result": "\u63d0\u51fa\u4e86\u63cf\u8ff0\u6a21\u578b\u5927\u5c0f\u4e0e\u6027\u80fd\u5173\u7cfb\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u4e3a\u6784\u5efa\u53ef\u90e8\u7f72\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u751f\u7406\u4f20\u611f\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8fd9\u9879\u65e9\u671f\u7814\u7a76\u4e3a\u6784\u5efa\u5b9e\u7528\u4e14\u53ef\u9884\u6d4b\u7684\u8fb9\u7f18\u53ef\u90e8\u7f72\u751f\u7406\u4f20\u611f\u6a21\u578b\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.18859", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18859", "abs": "https://arxiv.org/abs/2511.18859", "authors": ["Bo Jiang", "Weijun Zhao", "Beibei Wang", "Xiao Wang", "Jin Tang"], "title": "Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter Learning", "comment": null, "summary": "Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable attention in adapting pre-trained GNN models for downstream graph learning tasks. One representative fine-tuning method is to exploit adapter (termed AdapterGNN) which aims to 'augment' the pre-trained model by inserting a lightweight module to make the 'augmented' model better adapt to the downstream tasks. However, graph data may contain various types of noise in downstream tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs are often prone to graph noise and exhibit limited generalizability. How to enhance the robustness and generalization ability of GNNs' fine tuning remains an open problem. In this paper, we show that the above problem can be well addressed by integrating uncertainty learning into the GNN adapter. We propose the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN models against noisy graph data in the fine-tuning process. Specifically, in contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic adapter to augment the pre-trained GNN model. In this way, when the graph contains various noises,our method can automatically absorb the effects of changes in the variances of the Gaussian distribution, thereby significantly enhancing the model's robustness. Also, UAdapterGNN can further improve the generalization ability of the model on the downstream tasks. Extensive experiments on several benchmarks demonstrate the effectiveness, robustness and high generalization ability of the proposed UAdapterGNN method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684GNN\u9002\u914d\u5668\uff08UAdapterGNN\uff09\uff0c\u901a\u8fc7\u96c6\u6210\u4e0d\u786e\u5b9a\u6027\u5b66\u4e60\u6765\u589e\u5f3a\u9884\u8bad\u7ec3GNN\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5bf9\u566a\u58f0\u56fe\u6570\u636e\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684GNN\u9002\u914d\u5668\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u56fe\u6570\u636e\u4e2d\u5404\u79cd\u566a\u58f0\uff08\u5982\u566a\u58f0\u8fb9\u548c\u6a21\u7cca\u8282\u70b9\u5c5e\u6027\uff09\u7684\u5f71\u54cd\uff0c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002\u5982\u4f55\u589e\u5f3aGNN\u5fae\u8c03\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faUAdapterGNN\uff0c\u4f7f\u7528\u9ad8\u65af\u6982\u7387\u9002\u914d\u5668\u6765\u589e\u5f3a\u9884\u8bad\u7ec3GNN\u6a21\u578b\u3002\u5f53\u56fe\u5305\u542b\u5404\u79cd\u566a\u58f0\u65f6\uff0c\u8be5\u65b9\u6cd5\u80fd\u81ea\u52a8\u5438\u6536\u9ad8\u65af\u5206\u5e03\u65b9\u5dee\u53d8\u5316\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u663e\u8457\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86UAdapterGNN\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3001\u9c81\u68d2\u6027\u548c\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4e0d\u786e\u5b9a\u6027\u5b66\u4e60\u96c6\u6210\u5230GNN\u9002\u914d\u5668\u4e2d\uff0c\u53ef\u4ee5\u5f88\u597d\u5730\u89e3\u51b3GNN\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u95ee\u9898\uff0cUAdapterGNN\u65b9\u6cd5\u5728\u566a\u58f0\u56fe\u6570\u636e\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.18960", "categories": ["cs.LG", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.18960", "abs": "https://arxiv.org/abs/2511.18960", "authors": ["Lei Xiao", "Jifeng Li", "Juntao Gao", "Feiyang Ye", "Yan Jin", "Jingjing Qian", "Jing Zhang", "Yong Wu", "Xiaoyuan Yu"], "title": "AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention", "comment": "18 pages, 10 figures", "summary": "Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.", "AI": {"tldr": "AVA-VLA\u662f\u4e00\u4e2a\u57fa\u4e8ePOMDP\u89c6\u89d2\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u4e3b\u52a8\u89c6\u89c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528\u5386\u53f2\u4e0a\u4e0b\u6587\u52a8\u6001\u8c03\u5236\u89c6\u89c9\u5904\u7406\uff0c\u5728\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u901a\u5e38\u5c06\u4efb\u52a1\u5efa\u6a21\u4e3aMDP\uff0c\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u72ec\u7acb\u5904\u7406\u5bc6\u96c6\u89c6\u89c9\u8f93\u5165\uff0c\u8fd9\u79cd\u5386\u53f2\u65e0\u5173\u7684\u8bbe\u8ba1\u65e0\u6cd5\u6709\u6548\u5229\u7528\u5386\u53f2\u4e0a\u4e0b\u6587\uff0c\u5728\u52a8\u6001\u987a\u5e8f\u51b3\u7b56\u4e2d\u4e0d\u662f\u6700\u4f18\u7684\u3002", "method": "\u4ecePOMDP\u89d2\u5ea6\u91cd\u65b0\u5b9a\u4e49\u95ee\u9898\uff0c\u63d0\u51faAVA-VLA\u6846\u67b6\uff0c\u5f15\u5165\u4e3b\u52a8\u89c6\u89c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528\u6765\u81ea\u524d\u4e00\u4e2a\u51b3\u7b56\u6b65\u9aa4\u7684\u5faa\u73af\u72b6\u6001\uff08\u4fe1\u5ff5\u72b6\u6001\u7684\u795e\u7ecf\u8fd1\u4f3c\uff09\u52a8\u6001\u8c03\u5236\u89c6\u89c9\u5904\u7406\uff0c\u8ba1\u7b97\u8f6f\u6743\u91cd\u6765\u4e3b\u52a8\u5904\u7406\u4efb\u52a1\u76f8\u5173\u7684\u89c6\u89c9\u6807\u8bb0\u3002", "result": "\u5728LIBERO\u548cCALVIN\u7b49\u6d41\u884c\u673a\u5668\u4eba\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u53cc\u81c2\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u7684\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u5b9e\u7528\u6027\u548c\u5f3a\u5927\u7684\u6a21\u62df\u5230\u73b0\u5b9e\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "AVA-VLA\u901a\u8fc7\u5c06\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3aPOMDP\u5e76\u5f15\u5165\u4e3b\u52a8\u89c6\u89c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709VLA\u6a21\u578b\u5728\u52a8\u6001\u987a\u5e8f\u51b3\u7b56\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19090", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19090", "abs": "https://arxiv.org/abs/2511.19090", "authors": ["Shenghan Zhao", "Yuzhen Lin", "Ximeng Yang", "Qiaochu Lu", "Haozhong Xue", "Gaozhe Jiang"], "title": "Optimization of Deep Learning Models for Dynamic Market Behavior Prediction", "comment": null, "summary": "The advent of financial technology has witnessed a surge in the utilization of deep learning models to anticipate consumer conduct, a trend that has demonstrated considerable potential in enhancing lending strategies and bolstering market efficiency. We study multi-horizon demand forecasting on e-commerce transactions using the UCI Online Retail II dataset. Unlike prior versions of this manuscript that mixed financial-loan narratives with retail data, we focus exclusively on retail market behavior and define a clear prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We present a hybrid sequence model that combines multi-scale temporal convolutions, a gated recurrent module, and time-aware self-attention. The model is trained with standard regression losses and evaluated under MAE, RMSE, sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage. We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show consistent accuracy gains and improved robustness on peak/holiday periods. We further provide ablations and statistical significance tests to ensure the reliability of improvements, and we release implementation details to facilitate reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5e8f\u5217\u6a21\u578b\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u65f6\u95f4\u5377\u79ef\u3001\u95e8\u63a7\u5faa\u73af\u6a21\u5757\u548c\u65f6\u95f4\u611f\u77e5\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u7535\u5b50\u5546\u52a1\u591a\u65f6\u95f4\u8303\u56f4\u9700\u6c42\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u7684Transformer\u9884\u6d4b\u5668\u3002", "motivation": "\u968f\u7740\u91d1\u878d\u79d1\u6280\u7684\u53d1\u5c55\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u6d88\u8d39\u8005\u884c\u4e3a\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002\u672c\u6587\u4e13\u6ce8\u4e8e\u96f6\u552e\u5e02\u573a\u884c\u4e3a\uff0c\u660e\u786e\u9884\u6d4b\u76ee\u6807\u4e3a\u6bcf\u4e2aSKU\u7684\u65e5\u9700\u6c42/\u6536\u5165\uff0c\u65f6\u95f4\u8303\u56f4\u4e3a1\u30017\u300114\u5929\uff0c\u65e8\u5728\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u5e8f\u5217\u6a21\u578b\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u65f6\u95f4\u5377\u79ef\u3001\u95e8\u63a7\u5faa\u73af\u6a21\u5757\u548c\u65f6\u95f4\u611f\u77e5\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3002\u4f7f\u7528\u6807\u51c6\u56de\u5f52\u635f\u5931\u8fdb\u884c\u8bad\u7ec3\uff0c\u91c7\u7528\u4e25\u683c\u7684\u65f6\u95f4\u5206\u5272\u9632\u6b62\u6570\u636e\u6cc4\u9732\uff0c\u5e76\u4e0eARIMA/Prophet\u3001LSTM/GRU\u3001LightGBM\u53ca\u6700\u5148\u8fdb\u7684Transformer\u9884\u6d4b\u5668\u8fdb\u884c\u57fa\u51c6\u6bd4\u8f83\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8be5\u6a21\u578b\u5728\u51c6\u786e\u6027\u65b9\u9762\u53d6\u5f97\u4e00\u81f4\u63d0\u5347\uff0c\u5728\u5cf0\u503c/\u8282\u5047\u65e5\u671f\u95f4\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u548c\u7edf\u8ba1\u663e\u8457\u6027\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u6539\u8fdb\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u5e8f\u5217\u6a21\u578b\u5728\u7535\u5b50\u5546\u52a1\u9700\u6c42\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\u548c\u5cf0\u503c\u671f\u95f4\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5b9e\u73b0\u7ec6\u8282\u4ee5\u786e\u4fdd\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2511.19152", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19152", "abs": "https://arxiv.org/abs/2511.19152", "authors": ["Prateek Garg", "Bhavya Kohli", "Sunita Sarawagi"], "title": "Masked Diffusion Models are Secretly Learned-Order Autoregressive Models", "comment": "Accepted at EurIPS 2025 Workshop on Principles of Generative Modeling (PriGM)", "summary": "Masked Diffusion Models (MDMs) have emerged as one of the most promising paradigms for generative modeling over discrete domains. It is known that MDMs effectively train to decode tokens in a random order, and that this ordering has significant performance implications in practice. This observation raises a fundamental question: can we design a training framework that optimizes for a favorable decoding order? We answer this in the affirmative, showing that the continuous-time variational objective of MDMs, when equipped with multivariate noise schedules, can identify and optimize for a decoding order during training. We establish a direct correspondence between decoding order and the multivariate noise schedule and show that this setting breaks invariance of the MDM objective to the noise schedule. Furthermore, we prove that the MDM objective decomposes precisely into a weighted auto-regressive losses over these orders, which establishes them as auto-regressive models with learnable orders.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5143\u566a\u58f0\u8c03\u5ea6\u4f18\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\u7684\u89e3\u7801\u987a\u5e8f\uff0c\u5c06MDMs\u8f6c\u5316\u4e3a\u5177\u6709\u53ef\u5b66\u4e60\u987a\u5e8f\u7684\u81ea\u56de\u5f52\u6a21\u578b\u3002", "motivation": "\u73b0\u6709MDMs\u5728\u968f\u673a\u89e3\u7801\u987a\u5e8f\u4e0b\u8bad\u7ec3\uff0c\u800c\u89e3\u7801\u987a\u5e8f\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u80fd\u591f\u4f18\u5316\u89e3\u7801\u987a\u5e8f\u7684\u8bad\u7ec3\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u591a\u5143\u566a\u58f0\u8c03\u5ea6\u7684\u8fde\u7eed\u65f6\u95f4\u53d8\u5206\u76ee\u6807\uff0c\u5efa\u7acb\u89e3\u7801\u987a\u5e8f\u4e0e\u566a\u58f0\u8c03\u5ea6\u7684\u76f4\u63a5\u5bf9\u5e94\u5173\u7cfb\uff0c\u6253\u7834MDM\u76ee\u6807\u5bf9\u566a\u58f0\u8c03\u5ea6\u7684\u4e0d\u53d8\u6027\u3002", "result": "\u8bc1\u660e\u4e86MDM\u76ee\u6807\u53ef\u4ee5\u7cbe\u786e\u5206\u89e3\u4e3a\u8fd9\u4e9b\u987a\u5e8f\u4e0a\u7684\u52a0\u6743\u81ea\u56de\u5f52\u635f\u5931\uff0c\u4ece\u800c\u5c06MDMs\u5efa\u7acb\u4e3a\u5177\u6709\u53ef\u5b66\u4e60\u987a\u5e8f\u7684\u81ea\u56de\u5f52\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u548c\u4f18\u5316\u89e3\u7801\u987a\u5e8f\uff0c\u4e3aMDMs\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u4f18\u5316\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2511.19165", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19165", "abs": "https://arxiv.org/abs/2511.19165", "authors": ["Fabian Schramm", "Nicolas Perrin-Gilbert", "Justin Carpentier"], "title": "First-order Sobolev Reinforcement Learning", "comment": "Workshop paper at Differentiable Systems and Scientific Machine Learning, EurIPS 2025", "summary": "We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also their derivatives with respect to states and actions. By differentiating the Bellman backup through differentiable dynamics, we obtain analytically consistent gradient targets. Incorporating these into the critic objective using a Sobolev-type loss encourages the critic to align with both the value and local geometry of the target function. This first-order TD matching principle can be seamlessly integrated into existing algorithms, such as Q-learning or actor-critic methods (e.g., DDPG, SAC), potentially leading to faster critic convergence and more stable policy gradients without altering their overall structure.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65f6\u95f4\u5dee\u5206\u5b66\u4e60\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5236\u4e00\u9636\u8d1d\u5c14\u66fc\u4e00\u81f4\u6027\u6765\u8bad\u7ec3\u4ef7\u503c\u51fd\u6570\uff0c\u4f7f\u5176\u4e0d\u4ec5\u5339\u914d\u8d1d\u5c14\u66fc\u76ee\u6807\u503c\uff0c\u8fd8\u5339\u914d\u5173\u4e8e\u72b6\u6001\u548c\u52a8\u4f5c\u7684\u5bfc\u6570\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709\u65f6\u95f4\u5dee\u5206\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u4ef7\u503c\u51fd\u6570\u7684\u5c40\u90e8\u51e0\u4f55\u7279\u6027\u6765\u63d0\u9ad8\u6536\u655b\u901f\u5ea6\u548c\u7b56\u7565\u68af\u5ea6\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u53ef\u5fae\u52a8\u529b\u5b66\u5bf9\u8d1d\u5c14\u66fc\u5907\u4efd\u8fdb\u884c\u5fae\u5206\uff0c\u83b7\u5f97\u5206\u6790\u4e0a\u4e00\u81f4\u7684\u68af\u5ea6\u76ee\u6807\uff0c\u4f7f\u7528Sobolev\u578b\u635f\u5931\u5c06\u8fd9\u4e9b\u68af\u5ea6\u76ee\u6807\u878d\u5165\u8bc4\u8bba\u5bb6\u76ee\u6807\u51fd\u6570\u4e2d\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7b97\u6cd5\u4e2d\uff08\u5982Q\u5b66\u4e60\u3001DDPG\u3001SAC\uff09\uff0c\u53ef\u80fd\u5e26\u6765\u66f4\u5feb\u7684\u8bc4\u8bba\u5bb6\u6536\u655b\u548c\u66f4\u7a33\u5b9a\u7684\u7b56\u7565\u68af\u5ea6\u3002", "conclusion": "\u4e00\u9636TD\u5339\u914d\u539f\u5219\u80fd\u591f\u5728\u4e0d\u6539\u53d8\u7b97\u6cd5\u6574\u4f53\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.19168", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19168", "abs": "https://arxiv.org/abs/2511.19168", "authors": ["Deyi Ji", "Yuekui Yang", "Liqun Liu", "Peng Shu", "Haiyang Wu", "Shaogang Tang", "Xudong Chen", "Shaoping Ma", "Tianrun Chen", "Lanyun Zhu"], "title": "RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning", "comment": "EMNLP 2025 (Oral, Industry Track)", "summary": "Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.", "AI": {"tldr": "RAVEN++\u662f\u4e00\u4e2a\u9488\u5bf9\u89c6\u9891\u5e7f\u544a\u5185\u5bb9\u5ba1\u6838\u7684\u6539\u8fdb\u6846\u67b6\uff0c\u901a\u8fc7\u4e3b\u52a8\u5f3a\u5316\u5b66\u4e60\u3001\u7ec6\u7c92\u5ea6\u8fdd\u89c4\u7406\u89e3\u548c\u6e10\u8fdb\u5f0f\u591a\u9636\u6bb5\u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u8fdd\u89c4\u68c0\u6d4b\u7684\u7cbe\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u5e7f\u544a\u5185\u5bb9\u5ba1\u6838\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u7406\u89e3\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u8fdd\u89c4\u5b9a\u4f4d\u548c\u66f4\u597d\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1\uff09\u4e3b\u52a8\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u96be\u5ea6\uff1b2\uff09\u901a\u8fc7\u5206\u5c42\u5956\u52b1\u51fd\u6570\u548c\u63a8\u7406\u84b8\u998f\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u8fdd\u89c4\u7406\u89e3\uff1b3\uff09\u6e10\u8fdb\u5f0f\u591a\u9636\u6bb5\u8bad\u7ec3\u7ed3\u5408\u77e5\u8bc6\u6ce8\u5165\u3001\u8bfe\u7a0b\u88ab\u52a8\u5f3a\u5316\u5b66\u4e60\u548c\u4e3b\u52a8\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728\u516c\u5f00\u548c\u4e13\u6709\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAVEN++\u5728\u7ec6\u7c92\u5ea6\u8fdd\u89c4\u7406\u89e3\u3001\u63a8\u7406\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u95e8\u6a21\u578b\u5982RAVEN\u3002", "conclusion": "RAVEN++\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u89c6\u9891\u5e7f\u544a\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u79bb\u7ebf\u573a\u666f\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.19240", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19240", "abs": "https://arxiv.org/abs/2511.19240", "authors": ["Minxin Chen"], "title": "Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform", "comment": null, "summary": "Many real-world bandit problems involve non-stationary reward distributions, where the optimal decision may shift due to evolving environments. However, the performance of some typical Multi-Armed Bandit (MAB) models such as Upper Confidence Bound (UCB) algorithms degrades significantly in non-stationary environments where reward distributions change over time. To address this limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view algorithm that integrates a discount-based long-term perspective with a sliding-window-based short-term view. A data-driven semi-synthetic simulation platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to test algorithm adaptability under abrupt and gradual drift scenarios. Experimental results demonstrate that a well-configured sliding-window mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB) suffers from a fundamental learning failure, leading to linear regret. Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation strategy, achieves superior performance in dynamic settings, highlighting that the ensemble strategy itself is a decisive factor for success.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FDSW-UCB\u7b97\u6cd5\uff0c\u7ed3\u5408\u6298\u6263\u957f\u671f\u89c6\u89d2\u548c\u6ed1\u52a8\u7a97\u53e3\u77ed\u671f\u89c6\u89d2\uff0c\u5728\u975e\u5e73\u7a33\u591a\u81c2\u8001\u864e\u673a\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u5728\u975e\u5e73\u7a33\u5956\u52b1\u5206\u5e03\u73af\u5883\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8001\u864e\u673a\u95ee\u9898\u5f80\u5f80\u6d89\u53ca\u968f\u65f6\u95f4\u53d8\u5316\u7684\u5956\u52b1\u5206\u5e03\u3002", "method": "\u5f00\u53d1\u4e86FDSW-UCB\u53cc\u89c6\u89d2\u7b97\u6cd5\uff0c\u96c6\u6210\u57fa\u4e8e\u6298\u6263\u7684\u957f\u671f\u89c6\u89d2\u548c\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u7684\u77ed\u671f\u89c6\u89d2\uff0c\u5e76\u6784\u5efa\u4e86\u57fa\u4e8eMovieLens-1M\u548cOpen Bandit\u6570\u636e\u96c6\u7684\u534a\u5408\u6210\u4eff\u771f\u5e73\u53f0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6ed1\u52a8\u7a97\u53e3\u673a\u5236(SW-UCB)\u7a33\u5065\uff0c\u800c\u5e7f\u6cdb\u4f7f\u7528\u7684\u6298\u6263\u65b9\u6cd5(D-UCB)\u5b58\u5728\u57fa\u672c\u5b66\u4e60\u5931\u8d25\u5bfc\u81f4\u7ebf\u6027\u9057\u61be\u3002FDSW-UCB\u91c7\u7528\u4e50\u89c2\u805a\u5408\u7b56\u7565\u5728\u52a8\u6001\u8bbe\u7f6e\u4e2d\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u96c6\u6210\u7b56\u7565\u672c\u8eab\u662f\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\uff0cFDSW-UCB\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u5353\u8d8a\u6027\u80fd\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u7684\u51b3\u7b56\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19269", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19269", "abs": "https://arxiv.org/abs/2511.19269", "authors": ["Minseo Kim", "Chenfeng Xu", "Coleman Hooper", "Harman Singh", "Ben Athiwaratkun", "Ce Zhang", "Kurt Keutzer", "Amir Gholami"], "title": "CDLM: Consistency Diffusion Language Models For Faster Sampling", "comment": "18 pages, 6 figures", "summary": "Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.", "AI": {"tldr": "CDLM\u901a\u8fc7\u6574\u5408\u4e00\u81f4\u6027\u5efa\u6a21\u548c\u5757\u7ea7\u56e0\u679c\u6ce8\u610f\u529b\u63a9\u7801\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u4e863.6-14.5\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u5b66\u548c\u7f16\u7a0b\u4efb\u52a1\u7684\u7ade\u4e89\u6027\u51c6\u786e\u7387\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u867d\u7136\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u5e76\u884c\u751f\u6210\u8303\u5f0f\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u5927\u91cf\u7ec6\u5316\u6b65\u9aa4\u4e14\u65e0\u6cd5\u4f7f\u7528\u6807\u51c6KV\u7f13\u5b58\uff0c\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u7f13\u6162\u3002", "method": "CDLM\u6574\u5408\u4e00\u81f4\u6027\u5efa\u6a21\u6765\u5927\u5e45\u51cf\u5c11\u6240\u9700\u91c7\u6837\u6b65\u9aa4\uff0c\u5b9e\u73b0\u591a\u4ee4\u724c\u6700\u7ec8\u5316\uff1b\u5728\u5fae\u8c03\u671f\u95f4\u5f3a\u5236\u6267\u884c\u5757\u7ea7\u56e0\u679c\u6ce8\u610f\u529b\u63a9\u7801\uff0c\u4f7f\u6a21\u578b\u5b8c\u5168\u517c\u5bb9KV\u7f13\u5b58\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCDLM\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e863.6-14.5\u500d\u66f4\u4f4e\u7684\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u7684\u51c6\u786e\u7387\u3002", "conclusion": "CDLM\u662f\u4e00\u79cd\u57fa\u4e8e\u8bad\u7ec3\u7684\u52a0\u901f\u65b9\u6cd5\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u4e24\u4e2a\u4e3b\u8981\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2511.19277", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19277", "abs": "https://arxiv.org/abs/2511.19277", "authors": ["Brittany V. Lancellotti", "Jordan M. Malof", "Aaron Davitt", "Gavin McCormick", "Shelby Anderson", "Pol Carb\u00f3-Mestre", "Gary Collins", "Verity Crane", "Zoheyr Doctor", "George Ebri", "Kevin Foster", "Trey M. Gowdy", "Michael Guzzardi", "John Heal", "Heather Hunter", "David Kroodsma", "Khandekar Mahammad Galib", "Paul J. Markakis", "Gavin McDonald", "Daniel P. Moore", "Eric D. Nguyen", "Sabina Parvu", "Michael Pekala", "Christine D. Piatko", "Amy Piscopo", "Mark Powell", "Krsna Raniga", "Elizabeth P. Reilly", "Michael Robinette", "Ishan Saraswat", "Patrick Sicurello", "Isabella S\u00f6ldner-Rembold", "Raymond Song", "Charlotte Underwood", "Kyle Bradbury"], "title": "Closing Gaps in Emissions Monitoring with Climate TRACE", "comment": null, "summary": "Global greenhouse gas emissions estimates are essential for monitoring and mitigation planning. Yet most datasets lack one or more characteristics that enhance their actionability, such as accuracy, global coverage, high spatial and temporal resolution, and frequent updates. To address these gaps, we present Climate TRACE (climatetrace.org), an open-access platform delivering global emissions estimates with enhanced detail, coverage, and timeliness. Climate TRACE synthesizes existing emissions data, prioritizing accuracy, coverage, and resolution, and fills gaps using sector-specific estimation approaches. The dataset is the first to provide globally comprehensive emissions estimates for individual sources (e.g., individual power plants) for all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the present, with a two-month reporting lag and monthly updates. The open-access platform enables non-technical audiences to engage with detailed emissions datasets for most subnational governments worldwide. Climate TRACE supports data-driven climate action at scales where decisions are made, representing a major breakthrough for emissions accounting and mitigation.", "AI": {"tldr": "Climate TRACE\u662f\u4e00\u4e2a\u5f00\u653e\u83b7\u53d6\u5e73\u53f0\uff0c\u63d0\u4f9b\u5168\u7403\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u4f30\u7b97\u6570\u636e\uff0c\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u5168\u7403\u8986\u76d6\u3001\u9ad8\u65f6\u7a7a\u5206\u8fa8\u7387\u548c\u9891\u7e41\u66f4\u65b0\u7684\u7279\u70b9\uff0c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u6c14\u5019\u884c\u52a8\u3002", "motivation": "\u73b0\u6709\u6392\u653e\u6570\u636e\u96c6\u7f3a\u4e4f\u51c6\u786e\u6027\u3001\u5168\u7403\u8986\u76d6\u3001\u9ad8\u65f6\u7a7a\u5206\u8fa8\u7387\u548c\u9891\u7e41\u66f4\u65b0\u7b49\u5173\u952e\u7279\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u6c14\u5019\u884c\u52a8\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u6574\u5408\u73b0\u6709\u6392\u653e\u6570\u636e\uff0c\u4f18\u5148\u8003\u8651\u51c6\u786e\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u5206\u8fa8\u7387\uff0c\u5e76\u4f7f\u7528\u7279\u5b9a\u884c\u4e1a\u7684\u4f30\u7b97\u65b9\u6cd5\u6765\u586b\u8865\u6570\u636e\u7a7a\u767d\u3002", "result": "\u521b\u5efa\u4e86\u9996\u4e2a\u63d0\u4f9b\u5168\u7403\u5168\u9762\u6392\u653e\u4f30\u7b97\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6240\u6709\u4eba\u4e3a\u6392\u653e\u90e8\u95e8\uff0c\u5305\u62ec\u5355\u4e2a\u6392\u653e\u6e90\uff08\u5982\u53d1\u7535\u5382\uff09\uff0c\u6570\u636e\u4ece2021\u5e741\u67081\u65e5\u81f3\u4eca\uff0c\u6bcf\u6708\u66f4\u65b0\u3002", "conclusion": "Climate TRACE\u4ee3\u8868\u4e86\u6392\u653e\u6838\u7b97\u548c\u51cf\u6392\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\uff0c\u652f\u6301\u5728\u51b3\u7b56\u5c42\u9762\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u7684\u6c14\u5019\u884c\u52a8\u3002"}}
{"id": "2511.19279", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19279", "abs": "https://arxiv.org/abs/2511.19279", "authors": ["Victor Rambaud", "Salvador Mascarenhas", "Yair Lakretz"], "title": "MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings", "comment": "19 pages (29 with appendix), 8 figures", "summary": "A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.", "AI": {"tldr": "MapFormers\u662f\u57fa\u4e8eTransformer\u7684\u65b0\u67b6\u6784\uff0c\u80fd\u591f\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u5b66\u4e60\u8ba4\u77e5\u5730\u56fe\u5e76\u5e76\u884c\u6267\u884c\u8def\u5f84\u6574\u5408\uff0c\u901a\u8fc7\u8f93\u5165\u4f9d\u8d56\u7684\u4f4d\u7f6e\u7f16\u7801\u5b9e\u73b0\u7ed3\u6784\u4e0e\u5185\u5bb9\u7684\u89e3\u8026\uff0c\u5728OOD\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u7f3a\u4e4f\u4eba\u7c7b\u548c\u52a8\u7269\u6240\u5177\u6709\u7684\u8ba4\u77e5\u5730\u56fe\u80fd\u529b\uff0c\u65e0\u6cd5\u7075\u6d3b\u9002\u5e94\u65b0\u60c5\u5883\u5e76\u5b9e\u73b0\u5f3aOOD\u6cdb\u5316\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b66\u4e60\u8ba4\u77e5\u5730\u56fe\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faMapFormers\u67b6\u6784\uff0c\u901a\u8fc7\u66f4\u65b0Transformer\u4e2d\u7684\u4f4d\u7f6e\u7f16\u7801\u4e3a\u8f93\u5165\u4f9d\u8d56\u77e9\u9635\uff0c\u81ea\u7136\u5b9e\u73b0\u7ed3\u6784\u4e0e\u5185\u5bb9\u7684\u89e3\u8026\u3002\u5f00\u53d1\u4e86\u4e24\u79cd\u53d8\u4f53\uff1a\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5efa\u6a21\u60c5\u666f\u8bb0\u5fc6\uff0c\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5efa\u6a21\u5de5\u4f5c\u8bb0\u5fc6\u3002", "result": "\u57282D\u5bfc\u822a\u7b49\u4efb\u52a1\u4e2d\uff0cMapFormers\u80fd\u591f\u5b66\u4e60\u5e95\u5c42\u7a7a\u95f4\u7684\u8ba4\u77e5\u5730\u56fe\uff0c\u5e76\u5728OOD\u6cdb\u5316\uff08\u5982\u66f4\u957f\u5e8f\u5217\uff09\u65b9\u9762\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u67b6\u6784\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u8bbe\u8ba1\u7528\u4e8e\u5b66\u4e60\u8ba4\u77e5\u5730\u56fe\u7684\u6a21\u578b\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u5f15\u5165\u7ed3\u6784\u504f\u7f6e\u5b9e\u73b0\u7ed3\u6784-\u5185\u5bb9\u89e3\u8026\u5728Transformer\u4e2d\u53ef\u901a\u8fc7\u8f93\u5165\u4f9d\u8d56\u4f4d\u7f6e\u7f16\u7801\u5b9e\u73b0\uff0cMapFormers\u5728\u795e\u7ecf\u79d1\u5b66\u548cAI\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.19328", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19328", "abs": "https://arxiv.org/abs/2511.19328", "authors": ["Rohan Saha", "Farzane Aminmansour", "Alona Fyshe"], "title": "Understanding the Staged Dynamics of Transformers in Learning Latent Structure", "comment": "Preprint", "summary": "While transformers can discover latent structure from context, the dynamics of how they acquire different components of the latent structure remain poorly understood. In this work, we use the Alchemy benchmark, to investigate the dynamics of latent structure learning. We train a small decoder-only transformer on three task variants: 1) inferring missing rules from partial contextual information, 2) composing simple rules to solve multi-step sequences, and 3) decomposing complex multi-step examples to infer intermediate steps. By factorizing each task into interpretable events, we show that the model acquires capabilities in discrete stages, first learning the coarse grained rules, before learning the complete latent structure. We also identify a crucial asymmetry, where the model can compose fundamental rules robustly, but struggles to decompose complex examples to discover the fundamental rules. These findings offer new insights into understanding how a transformer model learns latent structures, providing a granular view of how these capabilities evolve during training.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Transformer\u6a21\u578b\u5b66\u4e60\u6f5c\u5728\u7ed3\u6784\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u4f7f\u7528Alchemy\u57fa\u51c6\u6d4b\u8bd5\u5206\u6790\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u53d8\u4f53\u4e2d\u7684\u5b66\u4e60\u9636\u6bb5\uff0c\u53d1\u73b0\u6a21\u578b\u5148\u5b66\u4e60\u7c97\u7c92\u5ea6\u89c4\u5219\u518d\u5b66\u4e60\u5b8c\u6574\u6f5c\u5728\u7ed3\u6784\uff0c\u5e76\u8bc6\u522b\u4e86\u7ec4\u5408\u4e0e\u5206\u89e3\u80fd\u529b\u7684\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u867d\u7136Transformer\u80fd\u591f\u4ece\u4e0a\u4e0b\u6587\u4e2d\u53d1\u73b0\u6f5c\u5728\u7ed3\u6784\uff0c\u4f46\u5173\u4e8e\u5b83\u4eec\u5982\u4f55\u83b7\u53d6\u6f5c\u5728\u7ed3\u6784\u4e0d\u540c\u7ec4\u6210\u90e8\u5206\u7684\u52a8\u6001\u8fc7\u7a0b\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u6df1\u5165\u7406\u89e3Transformer\u6a21\u578b\u5b66\u4e60\u6f5c\u5728\u7ed3\u6784\u7684\u52a8\u6001\u673a\u5236\u3002", "method": "\u4f7f\u7528Alchemy\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u5c0f\u578b\u7684\u4ec5\u89e3\u7801\u5668Transformer\u4e0a\u8bad\u7ec3\u4e09\u4e2a\u4efb\u52a1\u53d8\u4f53\uff1a1)\u4ece\u90e8\u5206\u4e0a\u4e0b\u6587\u4fe1\u606f\u63a8\u65ad\u7f3a\u5931\u89c4\u5219\uff0c2)\u7ec4\u5408\u7b80\u5355\u89c4\u5219\u89e3\u51b3\u591a\u6b65\u5e8f\u5217\uff0c3)\u5206\u89e3\u590d\u6742\u591a\u6b65\u793a\u4f8b\u63a8\u65ad\u4e2d\u95f4\u6b65\u9aa4\u3002\u901a\u8fc7\u5c06\u6bcf\u4e2a\u4efb\u52a1\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7684\u4e8b\u4ef6\u6765\u5206\u6790\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u6a21\u578b\u4ee5\u79bb\u6563\u9636\u6bb5\u83b7\u53d6\u80fd\u529b\uff0c\u9996\u5148\u5b66\u4e60\u7c97\u7c92\u5ea6\u89c4\u5219\uff0c\u7136\u540e\u5b66\u4e60\u5b8c\u6574\u7684\u6f5c\u5728\u7ed3\u6784\u3002\u53d1\u73b0\u5173\u952e\u7684\u4e0d\u5bf9\u79f0\u6027\uff1a\u6a21\u578b\u80fd\u591f\u7a33\u5065\u5730\u7ec4\u5408\u57fa\u672c\u89c4\u5219\uff0c\u4f46\u5728\u5206\u89e3\u590d\u6742\u793a\u4f8b\u4ee5\u53d1\u73b0\u57fa\u672c\u89c4\u5219\u65f6\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u7406\u89e3Transformer\u6a21\u578b\u5982\u4f55\u5b66\u4e60\u6f5c\u5728\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u80fd\u529b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u6f14\u5316\u8fc7\u7a0b\u3002"}}
{"id": "2511.19330", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19330", "abs": "https://arxiv.org/abs/2511.19330", "authors": ["Dominik Luszczynski"], "title": "Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data", "comment": "13 pages, 6 figures, 4 tables, preprint; Total including Appendix: 21 pages, 11 figures, 7 tables", "summary": "A common method of attacking deep learning models is through adversarial attacks, which occur when an attacker specifically modifies the input of a model to produce an incorrect result. Adversarial attacks have been deeply investigated in the image domain; however, there is less research in the time-series domain and very little for forecasting financial data. To address these concerns, this study aims to build upon previous research on adversarial attacks for time-series data by introducing two new slope-based methods aimed to alter the trends of the predicted stock forecast generated by an N-HiTS model. Compared to the normal N-HiTS predictions, the two new slope-based methods, the General Slope Attack and Least-Squares Slope Attack, can manipulate N-HiTS predictions by doubling the slope. These new slope attacks can bypass standard security mechanisms, such as a discriminator that filters real and perturbed inputs, reducing a 4-layered CNN's specificity to 28% and accuracy to 57%. Furthermore, the slope based methods were incorporated into a GAN architecture as a means of generating realistic synthetic data, while simultaneously fooling the model. Finally, this paper also proposes a sample malware designed to inject an adversarial attack in the model inference library, proving that ML-security research should not only focus on making the model safe, but also securing the entire pipeline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u57fa\u4e8e\u659c\u7387\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u7528\u4e8e\u64cd\u7eb5N-HiTS\u6a21\u578b\u5bf9\u80a1\u7968\u9884\u6d4b\u7684\u8d8b\u52bf\uff0c\u80fd\u591f\u7ed5\u8fc7\u6807\u51c6\u5b89\u5168\u673a\u5236\uff0c\u5e76\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u96c6\u6210\u5230GAN\u67b6\u6784\u4e2d\u751f\u6210\u771f\u5b9e\u5408\u6210\u6570\u636e\u3002", "motivation": "\u5bf9\u6297\u653b\u51fb\u5728\u56fe\u50cf\u9886\u57df\u5df2\u6709\u6df1\u5165\u7814\u7a76\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7814\u7a76\u8f83\u5c11\uff0c\u7279\u522b\u662f\u5728\u91d1\u878d\u9884\u6d4b\u6570\u636e\u65b9\u9762\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76\u5982\u4f55\u64cd\u7eb5\u80a1\u7968\u9884\u6d4b\u6a21\u578b\u7684\u8d8b\u52bf\u3002", "method": "\u5f15\u5165\u4e86\u4e24\u79cd\u65b0\u7684\u57fa\u4e8e\u659c\u7387\u7684\u653b\u51fb\u65b9\u6cd5\uff1a\u901a\u7528\u659c\u7387\u653b\u51fb\u548c\u6700\u5c0f\u4e8c\u4e58\u659c\u7387\u653b\u51fb\uff0c\u7528\u4e8e\u6539\u53d8N-HiTS\u6a21\u578b\u7684\u9884\u6d4b\u8d8b\u52bf\u3002\u8fd9\u4e9b\u65b9\u6cd5\u8fd8\u88ab\u96c6\u6210\u5230GAN\u67b6\u6784\u4e2d\u751f\u6210\u5408\u6210\u6570\u636e\u3002", "result": "\u65b0\u7684\u659c\u7387\u653b\u51fb\u65b9\u6cd5\u80fd\u591f\u5c06N-HiTS\u9884\u6d4b\u7684\u659c\u7387\u7ffb\u500d\uff0c\u6210\u529f\u7ed5\u8fc7\u6807\u51c6\u5b89\u5168\u673a\u5236\uff0c\u5c064\u5c42CNN\u5206\u7c7b\u5668\u7684\u7279\u5f02\u6027\u964d\u4f4e\u523028%\uff0c\u51c6\u786e\u7387\u964d\u4f4e\u523057%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u673a\u5668\u5b66\u4e60\u5b89\u5168\u7814\u7a76\u4e0d\u4ec5\u9700\u8981\u5173\u6ce8\u6a21\u578b\u672c\u8eab\u7684\u5b89\u5168\u6027\uff0c\u8fd8\u9700\u8981\u4fdd\u62a4\u6574\u4e2a\u5904\u7406\u6d41\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6837\u672c\u6076\u610f\u8f6f\u4ef6\u6765\u8bc1\u660e\u5728\u6a21\u578b\u63a8\u7406\u5e93\u4e2d\u6ce8\u5165\u5bf9\u6297\u653b\u51fb\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.19344", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19344", "abs": "https://arxiv.org/abs/2511.19344", "authors": ["Hari Chandana Kuchibhotla", "K S Ananth", "Vineeth N Balasubramanian"], "title": "Annotation-Free Class-Incremental Learning", "comment": "18 pages, 6 figures", "summary": "Despite significant progress in continual learning ranging from architectural novelty to clever strategies for mitigating catastrophic forgetting most existing methods rest on a strong but unrealistic assumption the availability of labeled data throughout the learning process. In real-world scenarios, however, data often arrives sequentially and without annotations, rendering conventional approaches impractical. In this work, we revisit the fundamental assumptions of continual learning and ask: Can current systems adapt when labels are absent and tasks emerge incrementally over time? To this end, we introduce Annotation-Free Class-Incremental Learning (AFCIL), a more realistic and challenging paradigm where unlabeled data arrives continuously, and the learner must incrementally acquire new classes without any supervision. To enable effective learning under AFCIL, we propose CrossWorld CL, a Cross Domain World Guided Continual Learning framework that incorporates external world knowledge as a stable auxiliary source. The method retrieves semantically related ImageNet classes for each downstream category, maps downstream and ImageNet features through a cross domain alignment strategy and finally introduce a novel replay strategy. This design lets the model uncover semantic structure without annotations while keeping earlier knowledge intact. Across four datasets, CrossWorld-CL surpasses CLIP baselines and existing continual and unlabeled learning methods, underscoring the benefit of world knowledge for annotation free continual learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6ce8\u91ca\u81ea\u7531\u7c7b\u589e\u91cf\u5b66\u4e60(AFCIL)\u65b0\u8303\u5f0f\uff0c\u89e3\u51b3\u65e0\u6807\u7b7e\u6570\u636e\u8fde\u7eed\u5230\u8fbe\u65f6\u7684\u6301\u7eed\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86CrossWorld CL\u6846\u67b6\uff0c\u5229\u7528\u5916\u90e8\u4e16\u754c\u77e5\u8bc6\u4f5c\u4e3a\u7a33\u5b9a\u8f85\u52a9\u6e90\u6765\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u5047\u8bbe\u5728\u6574\u4e2a\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u90fd\u6709\u6807\u8bb0\u6570\u636e\u53ef\u7528\uff0c\u4f46\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\uff0c\u6570\u636e\u901a\u5e38\u662f\u987a\u5e8f\u5230\u8fbe\u4e14\u6ca1\u6709\u6ce8\u91ca\u7684\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5f53\u6807\u7b7e\u7f3a\u5931\u4e14\u4efb\u52a1\u968f\u65f6\u95f4\u589e\u91cf\u51fa\u73b0\u65f6\uff0c\u5f53\u524d\u7cfb\u7edf\u80fd\u5426\u9002\u5e94\u3002", "method": "\u63d0\u51faCrossWorld CL\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u6bcf\u4e2a\u4e0b\u6e38\u7c7b\u522b\u7684\u8bed\u4e49\u76f8\u5173ImageNet\u7c7b\u522b\uff0c\u4f7f\u7528\u8de8\u57df\u5bf9\u9f50\u7b56\u7565\u6620\u5c04\u4e0b\u6e38\u548cImageNet\u7279\u5f81\uff0c\u5e76\u5f15\u5165\u65b0\u9896\u7684\u91cd\u653e\u7b56\u7565\uff0c\u8ba9\u6a21\u578b\u5728\u6ca1\u6709\u6ce8\u91ca\u7684\u60c5\u51b5\u4e0b\u53d1\u73b0\u8bed\u4e49\u7ed3\u6784\u540c\u65f6\u4fdd\u6301\u5148\u524d\u77e5\u8bc6\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCrossWorld CL\u8d85\u8d8a\u4e86CLIP\u57fa\u7ebf\u548c\u73b0\u6709\u7684\u6301\u7eed\u5b66\u4e60\u53ca\u65e0\u6807\u7b7e\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u4e16\u754c\u77e5\u8bc6\u5bf9\u6ce8\u91ca\u81ea\u7531\u6301\u7eed\u5b66\u4e60\u7684\u76ca\u5904\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u4e16\u754c\u77e5\u8bc6\u4f5c\u4e3a\u7a33\u5b9a\u8f85\u52a9\u6e90\uff0cCrossWorld CL\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u65e0\u6807\u7b7e\u6570\u636e\u8fde\u7eed\u5230\u8fbe\u65f6\u7684\u7c7b\u589e\u91cf\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u66f4\u73b0\u5b9e\u7684\u6301\u7eed\u5b66\u4e60\u573a\u666f\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.19350", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19350", "abs": "https://arxiv.org/abs/2511.19350", "authors": ["Nikita Neveditsin", "Pawan Lingras", "Vijay Mago"], "title": "Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric", "comment": null, "summary": "Clustering short text embeddings is a foundational task in natural language processing, yet remains challenging due to the need to specify the number of clusters in advance. We introduce a scalable spectral method that estimates the number of clusters directly from the structure of the Laplacian eigenspectrum, constructed using cosine similarities and guided by an adaptive sampling strategy. This sampling approach enables our estimator to efficiently scale to large datasets without sacrificing reliability. To support intrinsic evaluation of cluster quality without ground-truth labels, we propose the Cohesion Ratio, a simple and interpretable evaluation metric that quantifies how much intra-cluster similarity exceeds the global similarity background. It has an information-theoretic motivation inspired by mutual information, and in our experiments it correlates closely with extrinsic measures such as normalized mutual information and homogeneity. Extensive experiments on six short-text datasets and four modern embedding models show that standard algorithms like K-Means and HAC, when guided by our estimator, significantly outperform popular parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results demonstrate the practical value of our spectral estimator and Cohesion Ratio for unsupervised organization and evaluation of short text data. Implementation of our estimator of k and Cohesion Ratio, along with code for reproducing the experiments, is available at https://anonymous.4open.science/r/towards_clustering-0C2E.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5149\u8c31\u65b9\u6cd5\u6765\u4f30\u8ba1\u77ed\u6587\u672c\u5d4c\u5165\u7684\u805a\u7c7b\u6570\u91cf\uff0c\u65e0\u9700\u9884\u5148\u6307\u5b9a\u805a\u7c7b\u6570\uff0c\u5e76\u5f15\u5165\u4e86Cohesion Ratio\u6307\u6807\u6765\u8bc4\u4f30\u65e0\u76d1\u7763\u805a\u7c7b\u8d28\u91cf\u3002", "motivation": "\u77ed\u6587\u672c\u5d4c\u5165\u805a\u7c7b\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u57fa\u7840\u4efb\u52a1\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u9884\u5148\u6307\u5b9a\u805a\u7c7b\u6570\u91cf\u800c\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u786e\u5b9a\u6700\u4f73\u805a\u7c7b\u6570\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u62c9\u666e\u62c9\u65af\u7279\u5f81\u8c31\u7ed3\u6784\u6765\u4f30\u8ba1\u805a\u7c7b\u6570\u91cf\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u91c7\u6837\u7b56\u7565\u4f7f\u4f30\u8ba1\u5668\u80fd\u591f\u9ad8\u6548\u6269\u5c55\u5230\u5927\u578b\u6570\u636e\u96c6\u3002", "result": "\u5728\u516d\u4e2a\u77ed\u6587\u672c\u6570\u636e\u96c6\u548c\u56db\u4e2a\u73b0\u4ee3\u5d4c\u5165\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u4f7f\u7528\u672c\u6587\u4f30\u8ba1\u5668\u6307\u5bfc\u65f6\uff0c\u6807\u51c6\u7b97\u6cd5\u5982K-Means\u548cHAC\u663e\u8457\u4f18\u4e8eHDBSCAN\u3001OPTICS\u548cLeiden\u7b49\u6d41\u884c\u53c2\u6570\u8f7b\u91cf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u7684\u5149\u8c31\u4f30\u8ba1\u5668\u548cCohesion Ratio\u4e3a\u77ed\u6587\u672c\u6570\u636e\u7684\u65e0\u76d1\u7763\u7ec4\u7ec7\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u6709\u6548\u786e\u5b9a\u805a\u7c7b\u6570\u91cf\u5e76\u8bc4\u4f30\u805a\u7c7b\u8d28\u91cf\u3002"}}
{"id": "2511.19359", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19359", "abs": "https://arxiv.org/abs/2511.19359", "authors": ["Ariel Fargion", "Lahav Dabah", "Tom Tirer"], "title": "Enhancing Conformal Prediction via Class Similarity", "comment": null, "summary": "Conformal Prediction (CP) has emerged as a powerful statistical framework for high-stakes classification applications. Instead of predicting a single class, CP generates a prediction set, guaranteed to include the true label with a pre-specified probability. The performance of different CP methods is typically assessed by their average prediction set size. In setups where the classes can be partitioned into semantic groups, e.g., diseases that require similar treatment, users can benefit from prediction sets that are not only small on average, but also contain a small number of semantically different groups. This paper begins by addressing this problem and ultimately offers a widely applicable tool for boosting any CP method on any dataset. First, given a class partition, we propose augmenting the CP score function with a term that penalizes predictions with out-of-group errors. We theoretically analyze this strategy and prove its advantages for group-related metrics. Surprisingly, we show mathematically that, for common class partitions, it can also reduce the average set size of any CP score function. Our analysis reveals the class similarity factors behind this improvement and motivates us to propose a model-specific variant, which does not require any human semantic partition and can further reduce the prediction set size. Finally, we present an extensive empirical study, encompassing prominent CP methods, multiple models, and several datasets, which demonstrates that our class-similarity-based approach consistently enhances CP methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7c7b\u522b\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u4efb\u4f55\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u60e9\u7f5a\u7ec4\u5916\u9519\u8bef\u548c\u5229\u7528\u7c7b\u522b\u76f8\u4f3c\u6027\u6765\u51cf\u5c11\u9884\u6d4b\u96c6\u5927\u5c0f\u3002", "motivation": "\u5728\u7c7b\u522b\u53ef\u88ab\u5212\u5206\u4e3a\u8bed\u4e49\u7ec4\u7684\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u4e0d\u4ec5\u9700\u8981\u5e73\u5747\u8f83\u5c0f\u7684\u9884\u6d4b\u96c6\uff0c\u8fd8\u9700\u8981\u5305\u542b\u8f83\u5c11\u8bed\u4e49\u4e0d\u540c\u7ec4\u7684\u9884\u6d4b\u96c6\u3002\u73b0\u6709\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5e73\u5747\u9884\u6d4b\u96c6\u5927\u5c0f\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u7c7b\u522b\u76f8\u4f3c\u6027\u3002", "method": "\u9996\u5148\u63d0\u51fa\u5728\u4fdd\u5f62\u9884\u6d4b\u8bc4\u5206\u51fd\u6570\u4e2d\u6dfb\u52a0\u60e9\u7f5a\u7ec4\u5916\u9519\u8bef\u7684\u9879\uff1b\u7136\u540e\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u8be5\u65b9\u6cd5\u5bf9\u7ec4\u76f8\u5173\u6307\u6807\u7684\u4f18\u52bf\uff1b\u6700\u540e\u63d0\u51fa\u4e0d\u4f9d\u8d56\u4eba\u5de5\u8bed\u4e49\u5206\u533a\u7684\u6a21\u578b\u7279\u5b9a\u53d8\u4f53\uff0c\u5229\u7528\u7c7b\u522b\u76f8\u4f3c\u6027\u8fdb\u4e00\u6b65\u51cf\u5c11\u9884\u6d4b\u96c6\u5927\u5c0f\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u51cf\u5c11\u5e73\u5747\u9884\u6d4b\u96c6\u5927\u5c0f\uff0c\u7279\u522b\u662f\u5728\u5e38\u89c1\u7c7b\u522b\u5206\u533a\u4e0b\u3002\u5b9e\u8bc1\u7814\u7a76\u6db5\u76d6\u591a\u79cd\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u6570\u636e\u96c6\uff0c\u8bc1\u660e\u57fa\u4e8e\u7c7b\u522b\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u80fd\u6301\u7eed\u63d0\u5347\u4fdd\u5f62\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u7c7b\u522b\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u4efb\u4f55\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u7c7b\u522b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u51cf\u5c11\u9884\u6d4b\u96c6\u5927\u5c0f\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u8bed\u4e49\u5206\u533a\u3002"}}
{"id": "2511.19405", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19405", "abs": "https://arxiv.org/abs/2511.19405", "authors": ["Dereck Piche", "Mohammed Muqeeth", "Milad Aghajohari", "Juan Duque", "Michael Noukhovitch", "Aaron Courville"], "title": "Learning Robust Social Strategies with Large Language Models", "comment": null, "summary": "As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust and Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684LLM\u667a\u80fd\u4f53\u503e\u5411\u4e8e\u53d1\u5c55\u673a\u4f1a\u4e3b\u4e49\u884c\u4e3a\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u52bf\u5bf9\u9f50\u7b97\u6cd5\u6765\u4fc3\u8fdb\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u548c\u6297\u5265\u524a\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u667a\u80fdAI\u7684\u666e\u53ca\uff0c\u5177\u6709\u4e0d\u540c\u4e14\u53ef\u80fd\u51b2\u7a81\u76ee\u6807\u7684\u667a\u80fd\u4f53\u5c06\u5728\u590d\u6742\u73af\u5883\u4e2d\u4ea4\u4e92\u3002\u5728\u591a\u667a\u80fd\u4f53\u793e\u4f1a\u56f0\u5883\u4e2d\uff0c\u4e2a\u4f53\u6fc0\u52b1\u53ef\u80fd\u635f\u5bb3\u96c6\u4f53\u798f\u5229\uff0c\u800c\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u5f80\u5f80\u6536\u655b\u5230\u81ea\u79c1\u7684\u80cc\u53db\u7b56\u7565\u3002", "method": "\u91c7\u7528\u5bf9\u624b\u5b66\u4e60\u610f\u8bc6\u7b97\u6cd5\u2014\u2014\u4f18\u52bf\u5bf9\u9f50\uff0c\u6765\u5fae\u8c03LLM\u4ee5\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u548c\u6297\u5265\u524a\u80fd\u529b\uff1b\u5f15\u5165\u7ec4\u76f8\u5bf9\u57fa\u7ebf\u7b80\u5316\u8fed\u4ee3\u535a\u5f08\u4e2d\u7684\u4f18\u52bf\u8ba1\u7b97\uff1b\u5f00\u53d1\u4e86\u9700\u8981\u81ea\u7136\u8bed\u8a00\u6c9f\u901a\u7684\u65b0\u793e\u4ea4\u56f0\u5883\u73af\u5883\"\u4fe1\u4efb\u4e0e\u5206\u5272\"\u3002", "result": "\u5728\u5404\u79cd\u793e\u4ea4\u56f0\u5883\u4e2d\uff0c\u901a\u8fc7\u4f18\u52bf\u5bf9\u9f50\u5b66\u4e60\u7684\u7b56\u7565\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u96c6\u4f53\u6536\u76ca\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u8d2a\u5a6a\u667a\u80fd\u4f53\u5265\u524a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u4f18\u52bf\u5bf9\u9f50\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u6536\u655b\u5230\u4e0d\u826f\u5747\u8861\u7684\u95ee\u9898\uff0c\u4fc3\u8fdbLLM\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u5408\u4f5c\u884c\u4e3a\uff0c\u63d0\u9ad8\u96c6\u4f53\u798f\u5229\u3002"}}
{"id": "2511.19428", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19428", "abs": "https://arxiv.org/abs/2511.19428", "authors": ["Shangyuan Tong", "Nanye Ma", "Saining Xie", "Tommi Jaakkola"], "title": "Flow Map Distillation Without Data", "comment": null, "summary": "State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u6570\u636e\u96c6\u7684\u6d41\u6620\u5c04\u84b8\u998f\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u4ece\u5148\u9a8c\u5206\u5e03\u91c7\u6837\u6765\u907f\u514d\u6559\u5e08-\u6570\u636e\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728ImageNet\u4e0a\u4ec5\u97001\u6b65\u91c7\u6837\u5c31\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u6d41\u6a21\u578b\u9700\u8981\u7f13\u6162\u7684\u8fed\u4ee3\u91c7\u6837\uff0c\u800c\u4f20\u7edf\u7684\u6d41\u6620\u5c04\u84b8\u998f\u4f9d\u8d56\u4e8e\u5916\u90e8\u6570\u636e\u96c6\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6559\u5e08-\u6570\u636e\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u56e0\u4e3a\u9759\u6001\u6570\u636e\u96c6\u53ef\u80fd\u65e0\u6cd5\u5b8c\u6574\u4ee3\u8868\u6559\u5e08\u7684\u5168\u90e8\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6570\u636e\u66ff\u4ee3\u65b9\u6848\uff0c\u4ec5\u4ece\u5148\u9a8c\u5206\u5e03\u91c7\u6837\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\u6765\u9884\u6d4b\u6559\u5e08\u7684\u91c7\u6837\u8def\u5f84\uff0c\u540c\u65f6\u4e3b\u52a8\u7ea0\u6b63\u81ea\u8eab\u7684\u590d\u5408\u8bef\u5dee\u4ee5\u786e\u4fdd\u9ad8\u4fdd\u771f\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u8d85\u8d8a\u4e86\u6240\u6709\u57fa\u4e8e\u6570\u636e\u7684\u5bf9\u5e94\u65b9\u6cd5\uff0c\u5728ImageNet 256x256\u4e0a\u8fbe\u5230FID 1.45\uff0c\u5728ImageNet 512x512\u4e0a\u8fbe\u5230FID 1.49\uff0c\u5747\u4ec5\u97001\u6b65\u91c7\u6837\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u52a0\u901f\u751f\u6210\u6a21\u578b\u5efa\u7acb\u4e86\u4e00\u4e2a\u66f4\u7a33\u5065\u7684\u8303\u5f0f\uff0c\u5e76\u63a8\u52a8\u4e86\u65e0\u9700\u6570\u636e\u7684\u6d41\u6620\u5c04\u84b8\u998f\u7684\u5e7f\u6cdb\u91c7\u7528\u3002"}}
