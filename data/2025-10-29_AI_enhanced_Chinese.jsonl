{"id": "2510.23654", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23654", "abs": "https://arxiv.org/abs/2510.23654", "authors": ["Yurang", "Kuang"], "title": "Quantum Mechanics of Stochastic Systems", "comment": null, "summary": "We develop a fundamental framework for the quantum mechanics of stochastic\nsystems (QMSS), showing that classical discrete stochastic processes emerge\nnaturally as perturbations of the quantum harmonic oscillator (QHO). By\nconstructing exact perturbation potentials that transform QHO eigenstates into\nstochastic representations, we demonstrate that canonical probability\ndistributions, including Binomial, Negative Binomial, and Poisson, arise from\nspecific modifications of the harmonic potential. Each stochastic system is\ngoverned by a Count Operator (N), with probabilities determined by squared\namplitudes in a Born-rule-like manner.\n  The framework introduces a complete operator algebra for moment generation\nand information-theoretic analysis, together with modular projection operators\n(R_M) that enable finite-dimensional approximations supported by rigorous\nuniform convergence theorems. This mathematical structure underpins True\nUniform Random Number Generation (TURNG) [Kuang, Sci. Rep., 2025], eliminating\nthe need for external whitening processes.\n  Beyond randomness generation, the QMSS framework enables quantum probability\nengineering: the physical realization of classical distributions through\ndesigned quantum perturbations. These results demonstrate that stochastic\nsystems are inherently quantum-mechanical in structure, bridging quantum\ndynamics, statistical physics, and experimental probability realization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u91cf\u5b50\u968f\u673a\u7cfb\u7edf\u529b\u5b66(QMSS)\u6846\u67b6\uff0c\u5c06\u7ecf\u5178\u79bb\u6563\u968f\u673a\u8fc7\u7a0b\u89c6\u4e3a\u91cf\u5b50\u8c10\u632f\u5b50\u7684\u6270\u52a8\uff0c\u901a\u8fc7\u6784\u9020\u7cbe\u786e\u7684\u6270\u52a8\u52bf\u80fd\u5c06\u91cf\u5b50\u6001\u8f6c\u5316\u4e3a\u968f\u673a\u8868\u793a\uff0c\u5e76\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u7b97\u5b50\u4ee3\u6570\u7528\u4e8e\u77e9\u751f\u6210\u548c\u4fe1\u606f\u8bba\u5206\u6790\u3002", "motivation": "\u5efa\u7acb\u91cf\u5b50\u529b\u5b66\u4e0e\u7ecf\u5178\u968f\u673a\u7cfb\u7edf\u4e4b\u95f4\u7684\u6839\u672c\u8054\u7cfb\uff0c\u8bc1\u660e\u7ecf\u5178\u6982\u7387\u5206\u5e03\u53ef\u4ee5\u4ece\u91cf\u5b50\u8c10\u632f\u5b50\u7684\u7279\u5b9a\u6270\u52a8\u4e2d\u81ea\u7136\u4ea7\u751f\uff0c\u4e3a\u91cf\u5b50\u6982\u7387\u5de5\u7a0b\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u6784\u9020\u7cbe\u786e\u7684\u6270\u52a8\u52bf\u80fd\uff0c\u5c06\u91cf\u5b50\u8c10\u632f\u5b50\u672c\u5f81\u6001\u8f6c\u5316\u4e3a\u968f\u673a\u8868\u793a\uff1b\u5f15\u5165\u8ba1\u6570\u7b97\u5b50(N)\u548c\u6a21\u6295\u5f71\u7b97\u5b50(R_M)\u5efa\u7acb\u5b8c\u6574\u7684\u7b97\u5b50\u4ee3\u6570\uff1b\u5f00\u53d1\u4e25\u683c\u7684\u5747\u5300\u6536\u655b\u5b9a\u7406\u652f\u6301\u6709\u9650\u7ef4\u8fd1\u4f3c\u3002", "result": "\u6210\u529f\u4ece\u91cf\u5b50\u8c10\u632f\u5b50\u6270\u52a8\u4e2d\u63a8\u5bfc\u51fa\u4e8c\u9879\u5206\u5e03\u3001\u8d1f\u4e8c\u9879\u5206\u5e03\u548c\u6cca\u677e\u5206\u5e03\u7b49\u7ecf\u5178\u6982\u7387\u5206\u5e03\uff1b\u5efa\u7acb\u4e86\u771f\u5747\u5300\u968f\u673a\u6570\u751f\u6210(TURNG)\u65b9\u6cd5\uff0c\u65e0\u9700\u5916\u90e8\u767d\u5316\u5904\u7406\uff1b\u5b9e\u73b0\u4e86\u91cf\u5b50\u6982\u7387\u5de5\u7a0b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u7684\u91cf\u5b50\u6270\u52a8\u7269\u7406\u5b9e\u73b0\u7ecf\u5178\u5206\u5e03\u3002", "conclusion": "\u968f\u673a\u7cfb\u7edf\u5728\u7ed3\u6784\u4e0a\u672c\u8d28\u4e0a\u662f\u91cf\u5b50\u529b\u5b66\u7684\uff0c\u8be5\u6846\u67b6\u6210\u529f\u8fde\u63a5\u4e86\u91cf\u5b50\u52a8\u529b\u5b66\u3001\u7edf\u8ba1\u7269\u7406\u548c\u5b9e\u9a8c\u6982\u7387\u5b9e\u73b0\uff0c\u4e3a\u91cf\u5b50\u6982\u7387\u5de5\u7a0b\u548c\u968f\u673a\u6570\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.23719", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23719", "abs": "https://arxiv.org/abs/2510.23719", "authors": ["Markus Heinrich", "Jonas Haferkamp", "Ingo Roth", "Jonas Helsen"], "title": "Anti-concentration is (almost) all you need", "comment": "4+2 pages. Comments welcome", "summary": "Until very recently, it was generally believed that the (approximate)\n2-design property is strictly stronger than anti-concentration of random\nquantum circuits, mainly because it was shown that the latter anti-concentrate\nin logarithmic depth, while the former generally need linear depth circuits.\nThis belief was disproven by recent results which show that so-called\nrelative-error approximate unitary designs can in fact be generated in\nlogarithmic depth, implying anti-concentration. Their result does however not\napply to ordinary local random circuits, a gap which we close in this paper, at\nleast for 2-designs. More precisely, we show that anti-concentration of local\nrandom quantum circuits already implies that they form relative-error\napproximate state 2-designs, making them equivalent properties for these\nensembles. Our result holds more generally for any random circuit which is\ninvariant under local (single-qubit) unitaries, independent of the\narchitecture.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u5bf9\u4e8e\u5c40\u90e8\u968f\u673a\u91cf\u5b50\u7535\u8def\uff0c\u53cd\u96c6\u4e2d\u6027\u610f\u5473\u7740\u76f8\u5bf9\u8bef\u5dee\u8fd1\u4f3c\u72b6\u60012-\u8bbe\u8ba1\uff0c\u8868\u660e\u8fd9\u4e24\u4e2a\u6027\u8d28\u5728\u8fd9\u4e9b\u7cfb\u7efc\u4e2d\u662f\u7b49\u4ef7\u7684\u3002", "motivation": "\u5148\u524d\u8ba4\u4e3a\u8fd1\u4f3c2-\u8bbe\u8ba1\u6027\u8d28\u4e25\u683c\u5f3a\u4e8e\u968f\u673a\u91cf\u5b50\u7535\u8def\u7684\u53cd\u96c6\u4e2d\u6027\uff0c\u56e0\u4e3a\u53cd\u96c6\u4e2d\u6027\u5728\u5bf9\u6570\u6df1\u5ea6\u51fa\u73b0\uff0c\u800c2-\u8bbe\u8ba1\u901a\u5e38\u9700\u8981\u7ebf\u6027\u6df1\u5ea6\u3002\u6700\u8fd1\u7814\u7a76\u663e\u793a\u76f8\u5bf9\u8bef\u5dee\u8fd1\u4f3c\u5e7a\u6b63\u8bbe\u8ba1\u53ef\u4ee5\u5728\u5bf9\u6570\u6df1\u5ea6\u751f\u6210\uff0c\u4f46\u8fd9\u4e0d\u9002\u7528\u4e8e\u666e\u901a\u5c40\u90e8\u968f\u673a\u7535\u8def\u3002", "method": "\u8bc1\u660e\u5c40\u90e8\u968f\u673a\u91cf\u5b50\u7535\u8def\u7684\u53cd\u96c6\u4e2d\u6027\u610f\u5473\u7740\u5b83\u4eec\u5f62\u6210\u76f8\u5bf9\u8bef\u5dee\u8fd1\u4f3c\u72b6\u60012-\u8bbe\u8ba1\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u5728\u5c40\u90e8\u5e7a\u6b63\u53d8\u6362\u4e0b\u4e0d\u53d8\u7684\u968f\u673a\u7535\u8def\uff0c\u4e0e\u67b6\u6784\u65e0\u5173\u3002", "result": "\u5efa\u7acb\u4e86\u5c40\u90e8\u968f\u673a\u91cf\u5b50\u7535\u8def\u4e2d\u53cd\u96c6\u4e2d\u6027\u4e0e\u76f8\u5bf9\u8bef\u5dee\u8fd1\u4f3c\u72b6\u60012-\u8bbe\u8ba1\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "conclusion": "\u5bf9\u4e8e\u5c40\u90e8\u968f\u673a\u91cf\u5b50\u7535\u8def\uff0c\u53cd\u96c6\u4e2d\u6027\u548c\u76f8\u5bf9\u8bef\u5dee\u8fd1\u4f3c\u72b6\u60012-\u8bbe\u8ba1\u662f\u7b49\u4ef7\u6027\u8d28\uff0c\u586b\u8865\u4e86\u5148\u524d\u7814\u7a76\u4e2d\u7684\u7a7a\u767d\u3002"}}
{"id": "2510.23726", "categories": ["quant-ph", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.23726", "abs": "https://arxiv.org/abs/2510.23726", "authors": ["Daniel Belkin", "James Allen", "Bryan K. Clark"], "title": "Apparent Universal Behavior in Second Moments of Random Quantum Circuits", "comment": "29 pages, 17 figures", "summary": "Just how fast does the brickwork circuit form an approximate 2-design?\n  Is there any difference between anticoncentration and being a 2-design?\n  Does geometry matter?\n  How deep a circuit will I need in practice?\n  We tell you everything you always wanted to know about second moments of\nrandom quantum circuits, but were too afraid to compute. Our answers generally\ntake the form of numerical results for up to 50 qubits.\n  Our first contribution is a strategy to determine explicitly the optimal\nexperiment which distinguishes any given ensemble from the Haar measure. With\nthis formula and some computational tricks, we are able to compute $t = 2$\nmultiplicative errors exactly out to modest system sizes. As expected, we see\nthat most families of circuits form $\\epsilon$-approximate $2$-designs in depth\nproportional to $\\log n$. For the 1D brickwork, we work out the leading-order\nconstants explicitly.\n  For graphs, we find some exceptions which are much slower, proving that they\nrequire at least $\\Omega(n^2)$ gates. This answers a question asked by ref. 1\nin the negative. We explain these exceptional architectures in terms of\nconnectedness. Based on this intuition we conjecture universal upper and lower\nbounds for graph-sampled circuit ensembles.\n  For many architectures, the optimal experiment which determines the\nmultiplicative error corresponds exactly to the collision probability (i.e.\nanticoncentration). However, we find that the star graph anticoncentrates much\nfaster than it forms an $\\epsilon$-approximate $2$-design. Finally, we show\nthat one needs only ten to twenty layers to construct an approximate $2$-design\nfor realistic parameter ranges. This is a large constant-factor improvement\nover previous constructions. The parallel complete-graph architecture is not\nquite the fastest scrambler, partially resolving a question raised by ref. 2.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u968f\u673a\u91cf\u5b50\u7535\u8def\u5f62\u6210\u8fd1\u4f3c2-design\u7684\u901f\u5ea6\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u67b6\u6784\u4e0b\u7684\u7535\u8def\u6df1\u5ea6\u8981\u6c42\uff0c\u53d1\u73b0\u5927\u591a\u6570\u7535\u8def\u5728\u6df1\u5ea6\u4e0e\u5bf9\u6570n\u6210\u6b63\u6bd4\u65f6\u5f62\u62102-design\uff0c\u4f46\u67d0\u4e9b\u56fe\u7ed3\u6784\u9700\u8981\u03a9(n\u00b2)\u95e8\u6570\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u91cf\u5b50\u7535\u8def\u5f62\u6210\u8fd1\u4f3c2-design\u7684\u901f\u5ea6\u5dee\u5f02\uff0c\u63a2\u8ba8\u53cd\u96c6\u4e2d\u4e0e2-design\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u4e0d\u540c\u51e0\u4f55\u7ed3\u6784\u5bf9\u7535\u8def\u6df1\u5ea6\u7684\u5f71\u54cd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u786e\u5b9a\u6700\u4f18\u5b9e\u9a8c\u7684\u7b56\u7565\u6765\u533a\u5206\u7ed9\u5b9a\u7cfb\u7efc\u4e0eHaar\u6d4b\u5ea6\uff0c\u4f7f\u7528\u8ba1\u7b97\u6280\u5de7\u7cbe\u786e\u8ba1\u7b97t=2\u4e58\u6cd5\u8bef\u5dee\uff0c\u5206\u6790\u4e0d\u540c\u56fe\u67b6\u6784\u7684\u7535\u8def\u6027\u80fd\u3002", "result": "\u5927\u591a\u6570\u7535\u8def\u67b6\u6784\u5728\u6df1\u5ea6\u221dlog n\u65f6\u5f62\u6210\u03b5-\u8fd1\u4f3c2-design\uff0c\u4f46\u67d0\u4e9b\u56fe\u7ed3\u6784\u9700\u8981\u03a9(n\u00b2)\u95e8\u6570\uff1b\u661f\u56fe\u53cd\u96c6\u4e2d\u6bd4\u5f62\u62102-design\u5feb\u5f97\u591a\uff1b\u5b9e\u9645\u5e94\u7528\u4e2d\u4ec5\u970010-20\u5c42\u5373\u53ef\u6784\u5efa\u8fd1\u4f3c2-design\u3002", "conclusion": "\u7535\u8def\u67b6\u6784\u7684\u8fde\u901a\u6027\u5f71\u54cd\u5f62\u62102-design\u7684\u901f\u5ea6\uff0c\u63d0\u51fa\u4e86\u901a\u7528\u4e0a\u4e0b\u754c\u731c\u60f3\uff0c\u5e76\u884c\u5b8c\u5168\u56fe\u67b6\u6784\u4e0d\u662f\u6700\u5feb\u7684\u6df7\u6d17\u5668\uff0c\u4e3a\u5b9e\u9645\u91cf\u5b50\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.23706", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23706", "abs": "https://arxiv.org/abs/2510.23706", "authors": ["Matthew S. Foster", "Haoyu Guo", "Chao-Ming Jian", "Andreas W. W. Ludwig"], "title": "Free-Fermion Measurement-Induced Volume- to Area-Law Entanglement Transition in the Presence of Fermion Interactions", "comment": "9+5 pages, 2 figures", "summary": "At a generic volume- to area-law entanglement transition in a many-body\nsystem, quantum chaos is arrested. We argue that this tends to imply the\nvanishing of a certain \"mass\" term in the field theory of the\nmeasurement-induced phase transition (MIPT) for monitored, interacting\nfermions. To explore this idea, we consider the MIPT with no conserved\nquantities that describes 1D monitored, interacting Majorana fermions in class\nDIII. We conjecture that the MIPT is the noninteracting DIII one in this case;\nthe volume-law phase arises through the dangerously irrelevant mass. We propose\nnumerical tests of our conjecture and analytically identify a candidate\nnoninteracting critical point.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23701", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23701", "abs": "https://arxiv.org/abs/2510.23701", "authors": ["Yitao Feng", "Yu-An Chen", "Po-Shen Hsin", "Ryohei Kobayashi"], "title": "Onsiteability of Higher-Form Symmetries", "comment": "23 pages, 4 figures", "summary": "An internal symmetry in a lattice model is said to be onsiteable if it can be\ndisentangled into an onsite action by introducing ancillas and conjugating with\na finite-depth circuit. A standard lore holds that onsiteability is equivalent\nto being anomaly-free, which is indeed valid for finite 0-form symmetries in\n(1+1)D. However, for higher-form symmetries, these notions become inequivalent:\na symmetry may be onsite while still anomalous. In this work, we clarify the\nconditions for onsiteability of higher-form symmetries by proposing an\nequivalence between onsiteability and the possibility of $higher$ gauging. For\na finite 1-form symmetry in (2+1)D, we show that the symmetry is onsiteable if\nand only if its 't Hooft anomaly satisfies a specific algebraic condition that\nensures the symmetry can be 1-gauged. We further demonstrate that onsiteable\n1-form symmetry in (2+1)D can always be brought into transversal Pauli\noperators by ancillas and circuit conjugation. In generic dimensions, we derive\nnecessary conditions for onsiteability using lattice 't Hooft anomaly of\nhigher-form symmetry, and conjecture a general equivalence between\nonsiteability and possibility of higher gauging on lattices.", "AI": {"tldr": "\u672c\u6587\u6f84\u6e05\u4e86\u9ad8\u5f62\u5f0f\u5bf9\u79f0\u6027\u7684\u5c40\u57df\u5316\u6761\u4ef6\uff0c\u63d0\u51fa\u4e86\u5c40\u57df\u5316\u4e0e\u9ad8\u5f62\u5f0f\u89c4\u8303\u5316\u7684\u7b49\u4ef7\u6027\u3002\u5bf9\u4e8e(2+1)D\u4e2d\u7684\u6709\u96501\u5f62\u5f0f\u5bf9\u79f0\u6027\uff0c\u8bc1\u660e\u4e86\u5bf9\u79f0\u6027\u53ef\u5c40\u57df\u5316\u7684\u5145\u8981\u6761\u4ef6\u662f\u5176't Hooft\u5f02\u5e38\u6ee1\u8db3\u7279\u5b9a\u4ee3\u6570\u6761\u4ef6\uff0c\u786e\u4fdd\u53ef\u4ee5\u8fdb\u884c1-\u89c4\u8303\u5316\u3002", "motivation": "\u6807\u51c6\u89c2\u70b9\u8ba4\u4e3a\u5c40\u57df\u5316\u4e0e\u65e0\u5f02\u5e38\u7b49\u4ef7\uff0c\u4f46\u8fd9\u4ec5\u9002\u7528\u4e8e(1+1)D\u4e2d\u7684\u6709\u96500\u5f62\u5f0f\u5bf9\u79f0\u6027\u3002\u5bf9\u4e8e\u9ad8\u5f62\u5f0f\u5bf9\u79f0\u6027\uff0c\u8fd9\u4e9b\u6982\u5ff5\u53d8\u5f97\u4e0d\u7b49\u4ef7\uff1a\u5bf9\u79f0\u6027\u53ef\u80fd\u65e2\u662f\u5c40\u57df\u7684\u53c8\u662f\u5f02\u5e38\u7684\u3002\u672c\u6587\u65e8\u5728\u6f84\u6e05\u9ad8\u5f62\u5f0f\u5bf9\u79f0\u6027\u7684\u5c40\u57df\u5316\u6761\u4ef6\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u5c40\u57df\u5316\u4e0e\u9ad8\u5f62\u5f0f\u89c4\u8303\u5316\u7684\u7b49\u4ef7\u6027\uff0c\u63a8\u5bfc\u4e86\u9ad8\u5f62\u5f0f\u5bf9\u79f0\u6027\u5c40\u57df\u5316\u7684\u5fc5\u8981\u6761\u4ef6\u3002\u5bf9\u4e8e(2+1)D\u4e2d\u7684\u6709\u96501\u5f62\u5f0f\u5bf9\u79f0\u6027\uff0c\u5206\u6790\u4e86\u5176't Hooft\u5f02\u5e38\u7684\u4ee3\u6570\u6761\u4ef6\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u8f85\u52a9\u7cfb\u7edf\u548c\u7535\u8def\u5171\u8f6d\u5c06\u5176\u8f6c\u5316\u4e3a\u6a2a\u5411\u6ce1\u5229\u7b97\u5b50\u3002", "result": "\u8bc1\u660e\u4e86(2+1)D\u4e2d\u6709\u96501\u5f62\u5f0f\u5bf9\u79f0\u6027\u53ef\u5c40\u57df\u5316\u7684\u5145\u8981\u6761\u4ef6\u662f\u5176't Hooft\u5f02\u5e38\u6ee1\u8db3\u7279\u5b9a\u4ee3\u6570\u6761\u4ef6\uff0c\u786e\u4fdd\u53ef\u4ee5\u8fdb\u884c1-\u89c4\u8303\u5316\u3002\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u53ef\u5c40\u57df\u5316\u76841\u5f62\u5f0f\u5bf9\u79f0\u6027\u603b\u662f\u53ef\u4ee5\u901a\u8fc7\u8f85\u52a9\u7cfb\u7edf\u548c\u7535\u8def\u5171\u8f6d\u8f6c\u5316\u4e3a\u6a2a\u5411\u6ce1\u5229\u7b97\u5b50\u3002", "conclusion": "\u5728\u4e00\u822c\u7ef4\u5ea6\u4e2d\uff0c\u4f7f\u7528\u9ad8\u5f62\u5f0f\u5bf9\u79f0\u6027\u7684\u6676\u683c't Hooft\u5f02\u5e38\u63a8\u5bfc\u4e86\u5c40\u57df\u5316\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u63a8\u6d4b\u4e86\u6676\u683c\u4e0a\u5c40\u57df\u5316\u4e0e\u9ad8\u5f62\u5f0f\u89c4\u8303\u5316\u53ef\u80fd\u6027\u4e4b\u95f4\u7684\u666e\u904d\u7b49\u4ef7\u6027\u3002"}}
{"id": "2510.24100", "categories": ["quant-ph", "math-ph", "math.MP", "nlin.CD", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2510.24100", "abs": "https://arxiv.org/abs/2510.24100", "authors": ["Swetamber Das", "Arghya Dutta"], "title": "Dynamical system analysis of quantum tunneling in an asymmetric double-well potential", "comment": "14 pages, 6 figures; Comments are welcome", "summary": "We study quantum tunneling in an asymmetric double-well potential using a\ndynamical systems--based approach rooted in the Ehrenfest formalism. In this\nframework, the time evolution of a Gaussian wave packet is governed by a\nhierarchy of coupled equations linking lower- and higher-order position\nmoments. An approximate closure, required to render the system tractable,\nyields a reduced dynamical system for the mean and variance, with skewness\nentering explicitly due to the potential's asymmetry. Stability analysis of\nthis system identifies energy thresholds for detectable tunneling across the\nbarrier and reveals regimes where tunneling, though theoretically allowed,\nremains practically undetectable. Comparison with full numerical solutions of\nthe time-dependent Schr\\\"odinger equation shows that, beyond reproducing key\ntunneling features, the dynamical systems approach provides an interpretable\ndescription of quantum transport through tunneling in an effective asymmetric\ntwo-level system.", "AI": {"tldr": "\u4f7f\u7528\u57fa\u4e8eEhrenfest\u5f62\u5f0f\u4f53\u7cfb\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u65b9\u6cd5\u7814\u7a76\u975e\u5bf9\u79f0\u53cc\u52bf\u9631\u4e2d\u7684\u91cf\u5b50\u96a7\u7a7f\uff0c\u901a\u8fc7\u9ad8\u65af\u6ce2\u5305\u6f14\u5316\u65b9\u7a0b\u548c\u8fd1\u4f3c\u95ed\u5408\u5f97\u5230\u53ef\u5904\u7406\u7684\u7b80\u5316\u7cfb\u7edf\uff0c\u8bc6\u522b\u4e86\u53ef\u68c0\u6d4b\u96a7\u7a7f\u7684\u80fd\u91cf\u9608\u503c\u548c\u5b9e\u9645\u4e0d\u53ef\u68c0\u6d4b\u7684\u96a7\u7a7f\u533a\u57df\u3002", "motivation": "\u7814\u7a76\u975e\u5bf9\u79f0\u53cc\u52bf\u9631\u4e2d\u7684\u91cf\u5b50\u96a7\u7a7f\u73b0\u8c61\uff0c\u65e8\u5728\u901a\u8fc7\u52a8\u529b\u5b66\u7cfb\u7edf\u65b9\u6cd5\u63d0\u4f9b\u5bf9\u91cf\u5b50\u96a7\u7a7f\u8fc7\u7a0b\u7684\u7269\u7406\u89e3\u91ca\uff0c\u7279\u522b\u662f\u5728\u975e\u5bf9\u79f0\u52bf\u573a\u4e2d\u7684\u96a7\u7a7f\u884c\u4e3a\u3002", "method": "\u57fa\u4e8eEhrenfest\u5f62\u5f0f\u4f53\u7cfb\uff0c\u5efa\u7acb\u9ad8\u65af\u6ce2\u5305\u6f14\u5316\u7684\u8026\u5408\u65b9\u7a0b\u5c42\u6b21\u7ed3\u6784\uff0c\u91c7\u7528\u8fd1\u4f3c\u95ed\u5408\u5f97\u5230\u7b80\u5316\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\uff0c\u5206\u6790\u5747\u503c\u548c\u65b9\u5dee\u7684\u6f14\u5316\uff0c\u5e76\u8003\u8651\u504f\u5ea6\u5bf9\u975e\u5bf9\u79f0\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7a33\u5b9a\u6027\u5206\u6790\u786e\u5b9a\u4e86\u53ef\u68c0\u6d4b\u96a7\u7a7f\u7684\u80fd\u91cf\u9608\u503c\uff0c\u63ed\u793a\u4e86\u7406\u8bba\u4e0a\u5141\u8bb8\u4f46\u5b9e\u9645\u4e0d\u53ef\u68c0\u6d4b\u7684\u96a7\u7a7f\u533a\u57df\uff0c\u4e0e\u5b8c\u6574\u6570\u503c\u89e3\u6bd4\u8f83\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u91cd\u73b0\u5173\u952e\u96a7\u7a7f\u7279\u5f81\u3002", "conclusion": "\u52a8\u529b\u5b66\u7cfb\u7edf\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u518d\u73b0\u91cf\u5b50\u96a7\u7a7f\u7684\u5173\u952e\u7279\u5f81\uff0c\u8fd8\u4e3a\u975e\u5bf9\u79f0\u53cc\u80fd\u7ea7\u7cfb\u7edf\u4e2d\u7684\u91cf\u5b50\u8f93\u8fd0\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u63cf\u8ff0\u6846\u67b6\u3002"}}
{"id": "2510.23617", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23617", "abs": "https://arxiv.org/abs/2510.23617", "authors": ["Phuong Q. Dao", "Mark Roantree", "Vuong M. Ngo"], "title": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis", "comment": "The paper has been accepted for presentation at the MEDES 2025\n  conference", "summary": "Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by\njointly analyzing data from multiple modalities typically text and images\noffering a richer and more accurate interpretation than unimodal approaches. In\nthis paper, we first propose BERT-ViT-EF, a novel model that combines powerful\nTransformer-based encoders BERT for textual input and ViT for visual input\nthrough an early fusion strategy. This approach facilitates deeper cross-modal\ninteractions and more effective joint representation learning. To further\nenhance the model's capability, we propose an extension called the Dual\nTransformer Contrastive Network (DTCN), which builds upon BERT-ViT-EF. DTCN\nincorporates an additional Transformer encoder layer after BERT to refine\ntextual context (before fusion) and employs contrastive learning to align text\nand image representations, fostering robust multimodal feature learning.\nEmpirical results on two widely used MSA benchmarks MVSA-Single and TumEmo\ndemonstrate the effectiveness of our approach. DTCN achieves best accuracy\n(78.4%) and F1-score (78.3%) on TumEmo, and delivers competitive performance on\nMVSA-Single, with 76.6% accuracy and 75.9% F1-score. These improvements\nhighlight the benefits of early fusion and deeper contextual modeling in\nTransformer-based multimodal sentiment analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BERT-ViT-EF\u6a21\u578b\u548c\u5176\u6269\u5c55DTCN\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\uff0c\u901a\u8fc7\u65e9\u671f\u878d\u5408\u7b56\u7565\u548c\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u6027\u80fd\uff0c\u5728TumEmo\u548cMVSA-Single\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\u3002", "motivation": "\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u901a\u8fc7\u8054\u5408\u5206\u6790\u6587\u672c\u548c\u56fe\u50cf\u6570\u636e\uff0c\u6bd4\u5355\u6a21\u6001\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u4e30\u5bcc\u548c\u51c6\u786e\u7684\u60c5\u611f\u7406\u89e3\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8de8\u6a21\u6001\u4ea4\u4e92\u548c\u8054\u5408\u8868\u793a\u5b66\u4e60\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51faBERT-ViT-EF\u6a21\u578b\uff0c\u4f7f\u7528BERT\u5904\u7406\u6587\u672c\u8f93\u5165\u3001ViT\u5904\u7406\u89c6\u89c9\u8f93\u5165\uff0c\u91c7\u7528\u65e9\u671f\u878d\u5408\u7b56\u7565\u3002\u8fdb\u4e00\u6b65\u63d0\u51faDTCN\u6269\u5c55\uff0c\u5728BERT\u540e\u6dfb\u52a0Transformer\u7f16\u7801\u5668\u5c42\u4f18\u5316\u6587\u672c\u4e0a\u4e0b\u6587\uff0c\u5e76\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u6587\u672c\u548c\u56fe\u50cf\u8868\u793a\u3002", "result": "\u5728TumEmo\u6570\u636e\u96c6\u4e0a\uff0cDTCN\u8fbe\u5230\u6700\u4f73\u51c6\u786e\u738778.4%\u548cF1\u5206\u657078.3%\uff1b\u5728MVSA-Single\u6570\u636e\u96c6\u4e0a\uff0c\u83b7\u5f9776.6%\u51c6\u786e\u7387\u548c75.9% F1\u5206\u6570\uff0c\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u65e9\u671f\u878d\u5408\u548c\u66f4\u6df1\u5c42\u6b21\u7684\u4e0a\u4e0b\u6587\u5efa\u6a21\u5728\u57fa\u4e8eTransformer\u7684\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.23691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23691", "abs": "https://arxiv.org/abs/2510.23691", "authors": ["Zihao Wang", "Xujing Li", "Yining Ye", "Junjie Fang", "Haoming Wang", "Longxiang Liu", "Shihao Liang", "Junting Lu", "Zhiyong Wu", "Jiazhan Feng", "Wanjun Zhong", "Zili Li", "Yu Wang", "Yu Miao", "Bo Zhou", "Yuanfan Li", "Hao Wang", "Zhongkai Zhao", "Faming Wu", "Zhengxuan Jiang", "Weihao Tan", "Heyuan Yao", "Shi Yan", "Xiangyang Li", "Yitao Liang", "Yujia Qin", "Guang Shi"], "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents", "comment": null, "summary": "We present Game-TARS, a generalist game agent trained with a unified,\nscalable action space anchored to human-aligned native keyboard-mouse inputs.\nUnlike API- or GUI-based approaches, this paradigm enables large-scale\ncontinual pre-training across heterogeneous domains, including OS, web, and\nsimulation games. Game-TARS is pre-trained on over 500B tokens with diverse\ntrajectories and multimodal data. Key techniques include a decaying continual\nloss to reduce causal confusion and an efficient Sparse-Thinking strategy that\nbalances reasoning depth and inference cost. Experiments show that Game-TARS\nachieves about 2 times the success rate over the previous sota model on\nopen-world Minecraft tasks, is close to the generality of fresh humans in\nunseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet\nin FPS benchmarks. Scaling results on training-time and test-time confirm that\nthe unified action space sustains improvements when scaled to cross-game and\nmultimodal data. Our results demonstrate that simple, scalable action\nrepresentations combined with large-scale pre-training provide a promising path\ntoward generalist agents with broad computer-use abilities.", "AI": {"tldr": "Game-TARS\u662f\u4e00\u4e2a\u901a\u7528\u6e38\u620f\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u952e\u76d8\u9f20\u6807\u52a8\u4f5c\u7a7a\u95f4\u8fdb\u884c\u8bad\u7ec3\uff0c\u652f\u6301\u8de8\u64cd\u4f5c\u7cfb\u7edf\u3001\u7f51\u9875\u548c\u6a21\u62df\u6e38\u620f\u7684\u5927\u89c4\u6a21\u6301\u7eed\u9884\u8bad\u7ec3\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u8de8\u5f02\u6784\u9886\u57df\uff08\u5305\u62ec\u64cd\u4f5c\u7cfb\u7edf\u3001\u7f51\u9875\u548c\u6a21\u62df\u6e38\u620f\uff09\u8fdb\u884c\u5927\u89c4\u6a21\u6301\u7eed\u9884\u8bad\u7ec3\u7684\u901a\u7528\u6e38\u620f\u667a\u80fd\u4f53\uff0c\u907f\u514dAPI\u6216GUI\u65b9\u6cd5\u7684\u9650\u5236\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u952e\u76d8\u9f20\u6807\u52a8\u4f5c\u7a7a\u95f4\uff0c\u7ed3\u5408500B+ tokens\u7684\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u91c7\u7528\u8870\u51cf\u6301\u7eed\u635f\u5931\u51cf\u5c11\u56e0\u679c\u6df7\u6dc6\uff0c\u4ee5\u53ca\u9ad8\u6548\u7684\u7a00\u758f\u601d\u7ef4\u7b56\u7565\u5e73\u8861\u63a8\u7406\u6df1\u5ea6\u548c\u63a8\u7406\u6210\u672c\u3002", "result": "\u5728\u5f00\u653e\u4e16\u754cMinecraft\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u6bd4\u4e4b\u524d\u6700\u4f73\u6a21\u578b\u63d0\u9ad8\u7ea62\u500d\uff0c\u5728\u672a\u89c1\u8fc7\u7684\u7f51\u98753D\u6e38\u620f\u4e2d\u63a5\u8fd1\u4eba\u7c7b\u65b0\u624b\u6c34\u5e73\uff0c\u5728FPS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aGPT-5\u3001Gemini-2.5-Pro\u548cClaude-4-Sonnet\u3002", "conclusion": "\u7b80\u5355\u3001\u53ef\u6269\u5c55\u7684\u52a8\u4f5c\u8868\u793a\u7ed3\u5408\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u4e3a\u5f00\u53d1\u5177\u6709\u5e7f\u6cdb\u8ba1\u7b97\u673a\u4f7f\u7528\u80fd\u529b\u7684\u901a\u7528\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2510.23731", "categories": ["quant-ph", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.23731", "abs": "https://arxiv.org/abs/2510.23731", "authors": ["Himanshu Badhani", "Dhanuja G S", "Siddhartha Das"], "title": "Thermodynamic work capacity of quantum information processing", "comment": "1 table, 6 pages, see companion work arXiv:2510.12790", "summary": "We introduce the resource-theoretic free energy of a quantum channel as the\nmaximal work extractable from the channel as its output equilibrates to a\nthermal state and its reference system remains locally intact. It is\nproportional to the relative entropy between the given channel and the\nabsolutely thermal channel. It attains a clear operational meaning as twice the\nasymptotic rates of athermality distillation and formation under Gibbs\npreserving superchannels, which map one absolutely thermal channel to another\nfor a given bath, thereby revealing the asymptotic reversibility of the\nresource theory of athermality for quantum channels. Consequently, we establish\nthat the optimal extractable work in converting one channel to another through\nthe asymptotic athermality distillation and formation tasks equals the\ndifference in their free energies. We call this optimal work the thermodynamic\nwork capacity of channel conversion. Quantum information processing and\ncomputing fundamentally concern the manipulation and transformation of quantum\nchannels, which encompass quantum states, their transformations, and\nmeasurements. A quantitative characterization of the optimal thermodynamic work\ngain or expenditure in quantum information processing constitutes a key step\ntoward formulating thermodynamics of quantum processes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u91cf\u5b50\u901a\u9053\u7684\u8d44\u6e90\u7406\u8bba\u81ea\u7531\u80fd\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u5f53\u901a\u9053\u8f93\u51fa\u70ed\u5316\u5230\u70ed\u6001\u4e14\u53c2\u8003\u7cfb\u7edf\u4fdd\u6301\u5c40\u90e8\u5b8c\u6574\u65f6\u53ef\u63d0\u53d6\u7684\u6700\u5927\u529f\u3002\u8be5\u81ea\u7531\u80fd\u4e0e\u7ed9\u5b9a\u901a\u9053\u548c\u7edd\u5bf9\u70ed\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5bf9\u71b5\u6210\u6b63\u6bd4\uff0c\u5e76\u5728\u5409\u5e03\u65af\u4fdd\u6301\u8d85\u901a\u9053\u4e0b\u5177\u6709\u6e05\u6670\u7684\u6e10\u8fd1\u53ef\u9006\u6027\u64cd\u4f5c\u610f\u4e49\u3002", "motivation": "\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u548c\u8ba1\u7b97\u672c\u8d28\u4e0a\u6d89\u53ca\u91cf\u5b50\u901a\u9053\u7684\u64cd\u7eb5\u548c\u8f6c\u6362\uff0c\u5305\u62ec\u91cf\u5b50\u6001\u3001\u5b83\u4eec\u7684\u53d8\u6362\u548c\u6d4b\u91cf\u3002\u5b9a\u91cf\u8868\u5f81\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u6700\u4f73\u70ed\u529b\u5b66\u529f\u589e\u76ca\u6216\u6d88\u8017\u662f\u5236\u5b9a\u91cf\u5b50\u8fc7\u7a0b\u70ed\u529b\u5b66\u7684\u5173\u952e\u6b65\u9aa4\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u91cf\u5b50\u901a\u9053\u7684\u8d44\u6e90\u7406\u8bba\u81ea\u7531\u80fd\uff0c\u5e76\u5c06\u5176\u4e0e\u7edd\u5bf9\u70ed\u901a\u9053\u7684\u76f8\u5bf9\u71b5\u76f8\u5173\u8054\uff0c\u7814\u7a76\u5728\u5409\u5e03\u65af\u4fdd\u6301\u8d85\u901a\u9053\u4e0b\u7684\u6e10\u8fd1\u975e\u70ed\u6027\u84b8\u998f\u548c\u5f62\u6210\u901f\u7387\u3002", "result": "\u53d1\u73b0\u91cf\u5b50\u901a\u9053\u7684\u81ea\u7531\u80fd\u7b49\u4e8e\u5176\u4e0e\u7edd\u5bf9\u70ed\u901a\u9053\u76f8\u5bf9\u71b5\u7684\u4e24\u500d\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u5409\u5e03\u65af\u4fdd\u6301\u8d85\u901a\u9053\u4e0b\u975e\u70ed\u6027\u8d44\u6e90\u7406\u8bba\u7684\u6e10\u8fd1\u53ef\u9006\u6027\u3002\u901a\u9053\u8f6c\u6362\u7684\u6700\u4f73\u53ef\u63d0\u53d6\u529f\u7b49\u4e8e\u5b83\u4eec\u81ea\u7531\u80fd\u7684\u5dee\u5f02\uff0c\u79f0\u4e3a\u901a\u9053\u8f6c\u6362\u7684\u70ed\u529b\u5b66\u529f\u5bb9\u91cf\u3002", "conclusion": "\u5efa\u7acb\u4e86\u91cf\u5b50\u901a\u9053\u70ed\u529b\u5b66\u7684\u57fa\u672c\u6846\u67b6\uff0c\u4e3a\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u8fc7\u7a0b\u7684\u70ed\u529b\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u901a\u9053\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u70ed\u529b\u5b66\u529f\u7684\u5b9a\u91cf\u5173\u7cfb\u3002"}}
{"id": "2510.23716", "categories": ["cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23716", "abs": "https://arxiv.org/abs/2510.23716", "authors": ["Kl\u00e9e Pollock", "Jonathan D. Kroth", "Jonathon Riddell", "Thomas Iadecola"], "title": "Group word dynamics from local random matrix Hamiltonians and beyond", "comment": "20 pages, 17 figures. Comments welcome", "summary": "We study one dimensional quantum spin chains whose nearest neighbor\ninteractions are random matrices that square to one. By employing free\nprobability theory, we establish a mapping from the many-body quantum dynamics\nof energy density in the original chain to a single-particle hopping dynamics\nwhen the local Hilbert space dimension is large. The hopping occurs on the\nCayley graph of an infinite Coxeter reflection group. Adjacency matrices on\nlarge finite clusters of this Cayley graph can be constructed numerically by\nleveraging the automatic structure of the group. The density of states and\ntwo-point functions of the local energy density are approximately computed and\nconsistent with the physics of a generic local Hamiltonian: Gaussian density of\nstates and thermalization of energy density. We then ask what happens to the\nphysics if we modify the group on which the hopping dynamics occurs, and\nconjecture that adding braid relations into the group leads to integrability.\nOur results put into contact ideas in free probability theory, quantum\nmechanics of hyperbolic lattices, and the physics of both generic and\nintegrable Hamiltonian dynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e00\u7ef4\u91cf\u5b50\u81ea\u65cb\u94fe\uff0c\u5176\u6700\u8fd1\u90bb\u76f8\u4e92\u4f5c\u7528\u662f\u5e73\u65b9\u4e3a1\u7684\u968f\u673a\u77e9\u9635\u3002\u901a\u8fc7\u81ea\u7531\u6982\u7387\u7406\u8bba\uff0c\u5c06\u591a\u4f53\u91cf\u5b50\u52a8\u529b\u5b66\u6620\u5c04\u5230\u65e0\u9650Coxeter\u53cd\u5c04\u7fa4Cayley\u56fe\u4e0a\u7684\u5355\u7c92\u5b50\u8dc3\u8fc1\u52a8\u529b\u5b66\uff0c\u5e76\u53d1\u73b0\u80fd\u91cf\u5bc6\u5ea6\u7684\u70ed\u5316\u884c\u4e3a\u3002\u4fee\u6539\u7fa4\u7ed3\u6784\u53ef\u80fd\u5bfc\u81f4\u53ef\u79ef\u6027\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u77e9\u9635\u76f8\u4e92\u4f5c\u7528\u7684\u4e00\u7ef4\u91cf\u5b50\u81ea\u65cb\u94fe\u7684\u591a\u4f53\u91cf\u5b50\u52a8\u529b\u5b66\uff0c\u63a2\u7d22\u4ece\u591a\u4f53\u7cfb\u7edf\u5230\u5355\u7c92\u5b50\u52a8\u529b\u5b66\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u4ee5\u53ca\u7fa4\u7ed3\u6784\u5bf9\u7cfb\u7edf\u7269\u7406\u6027\u8d28\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u81ea\u7531\u6982\u7387\u7406\u8bba\u5efa\u7acb\u6620\u5c04\uff0c\u5c06\u591a\u4f53\u91cf\u5b50\u52a8\u529b\u5b66\u8f6c\u5316\u4e3a\u65e0\u9650Coxeter\u53cd\u5c04\u7fa4Cayley\u56fe\u4e0a\u7684\u5355\u7c92\u5b50\u8dc3\u8fc1\u52a8\u529b\u5b66\uff0c\u5229\u7528\u7fa4\u7684\u81ea\u52a8\u7ed3\u6784\u6570\u503c\u6784\u9020\u5927\u6709\u9650\u7c07\u7684\u90bb\u63a5\u77e9\u9635\u3002", "result": "\u8ba1\u7b97\u5f97\u5230\u9ad8\u65af\u6001\u5bc6\u5ea6\u548c\u80fd\u91cf\u5bc6\u5ea6\u7684\u4e24\u70b9\u51fd\u6570\uff0c\u4e0e\u4e00\u822c\u5c40\u57df\u54c8\u5bc6\u987f\u91cf\u7684\u7269\u7406\u4e00\u81f4\uff1a\u9ad8\u65af\u6001\u5bc6\u5ea6\u548c\u80fd\u91cf\u5bc6\u5ea6\u70ed\u5316\u3002\u4fee\u6539\u7fa4\u7ed3\u6784\u53ef\u80fd\u5f15\u5165\u53ef\u79ef\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u81ea\u7531\u6982\u7387\u7406\u8bba\u3001\u53cc\u66f2\u6676\u683c\u91cf\u5b50\u529b\u5b66\u4ee5\u53ca\u4e00\u822c\u548c\u53ef\u79ef\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u7269\u7406\u8054\u7cfb\u8d77\u6765\uff0c\u5c55\u793a\u4e86\u7fa4\u7ed3\u6784\u5728\u51b3\u5b9a\u91cf\u5b50\u7cfb\u7edf\u52a8\u529b\u5b66\u6027\u8d28\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2510.23704", "categories": ["cond-mat.str-el", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.23704", "abs": "https://arxiv.org/abs/2510.23704", "authors": ["Niccol\u00f2 Francini", "Lukas Schmidt", "Lukas Janssen", "Daniel Lozano-G\u00f3mez"], "title": "Exact nematic and mixed magnetic phases driven by competing orders on the pyrochlore lattice", "comment": "28 pages, 23 figures, 3 tables", "summary": "Pyrochlore magnets are a paradigmatic example of three-dimensional frustrated\nsystems and provide an excellent platform for studying a variety of exotic\nmany-body phenomena, including spin liquids, nematic phases, fragmentation, and\norder by disorder. In recent years, increasing attention has been devoted to\nbilinear spin models on this lattice, where multiple magnetic phases can be\ndegenerate in energy, often stabilizing unconventional magnetic states. In this\nwork, we focus on one such model, parametrized by the interaction coupling\n$J_{z\\pm}$, which defines a line in parameter space corresponding to the phase\nboundary between three distinct magnetic phases. Using a combination of\nanalytical and numerical methods, we show that this model exhibits an\norder-by-disorder mechanism at low temperatures, giving rise to a \\emph{mixed}\nmagnetic phase. This represents the first realization of a $\\mathbf{q}=0$\nlong-range-ordered phase in a pyrochlore magnet characterized by two distinct\norder parameters, which we denote as the $A_2 \\oplus \\psi_2$ phase.\nFurthermore, at $J_{z\\pm} = 1/\\sqrt{2}$, the model acquires a subextensive\nnumber of discrete symmetries, which preclude the stabilization of conventional\nlong-range order and instead lead to the emergence of a novel nematic phase. We\ncharacterize this nematic phase, describe how its ground-state configurations\nare constructed, and analyze its stability at higher temperatures and under\nsmall deviations from $J_{z\\pm} = 1/\\sqrt{2}$.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u7126\u7eff\u77f3\u78c1\u4f53\u4e2d\u53d1\u73b0\u4e86\u6df7\u5408\u78c1\u76f8\u548c\u65b0\u578b\u5411\u5217\u76f8\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5177\u6709\u4e24\u4e2a\u4e0d\u540c\u5e8f\u53c2\u6570\u7684q=0\u957f\u7a0b\u6709\u5e8f\u76f8\uff0c\u5e76\u5728\u7279\u5b9a\u53c2\u6570\u70b9\u63ed\u793a\u4e86\u7531\u79bb\u6563\u5bf9\u79f0\u6027\u5bfc\u81f4\u7684\u5411\u5217\u76f8\u5f62\u6210\u673a\u5236\u3002", "motivation": "\u7126\u7eff\u77f3\u78c1\u4f53\u4f5c\u4e3a\u4e09\u7ef4\u963b\u632b\u7cfb\u7edf\u7684\u8303\u4f8b\uff0c\u4e3a\u7814\u7a76\u5404\u79cd\u5947\u5f02\u591a\u4f53\u73b0\u8c61\u63d0\u4f9b\u4e86\u7406\u60f3\u5e73\u53f0\u3002\u8fd1\u5e74\u6765\uff0c\u53cc\u7ebf\u6027\u81ea\u65cb\u6a21\u578b\u5728\u8be5\u6676\u683c\u4e0a\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u5176\u4e2d\u591a\u4e2a\u78c1\u76f8\u53ef\u80fd\u5728\u80fd\u91cf\u4e0a\u7b80\u5e76\uff0c\u5f80\u5f80\u7a33\u5b9a\u51fa\u975e\u5e38\u89c4\u78c1\u6001\u3002", "method": "\u7ed3\u5408\u89e3\u6790\u548c\u6570\u503c\u65b9\u6cd5\uff0c\u7814\u7a76\u7126\u7eff\u77f3\u6676\u683c\u4e0a\u7531\u76f8\u4e92\u4f5c\u7528\u8026\u5408Jz\u00b1\u53c2\u6570\u5316\u7684\u81ea\u65cb\u6a21\u578b\uff0c\u91cd\u70b9\u5173\u6ce8\u53c2\u6570\u7a7a\u95f4\u4e2d\u5bf9\u5e94\u4e09\u4e2a\u4e0d\u540c\u78c1\u76f8\u76f8\u8fb9\u754c\u7684\u7279\u5b9a\u7ebf\u3002", "result": "\u5728\u4f4e\u6e29\u4e0b\u8be5\u6a21\u578b\u8868\u73b0\u51fa\u6709\u5e8f\u5316\u65e0\u5e8f\u673a\u5236\uff0c\u4ea7\u751f\u6df7\u5408\u78c1\u76f8\uff0c\u8fd9\u662f\u7126\u7eff\u77f3\u78c1\u4f53\u4e2d\u9996\u4e2a\u5177\u6709\u4e24\u4e2a\u4e0d\u540c\u5e8f\u53c2\u6570(q=0\u957f\u7a0b\u6709\u5e8f\u76f8)\u7684\u5b9e\u73b0\u3002\u5728Jz\u00b1=1/\u221a2\u65f6\uff0c\u6a21\u578b\u83b7\u5f97\u4e9a\u6269\u5c55\u6570\u91cf\u7684\u79bb\u6563\u5bf9\u79f0\u6027\uff0c\u963b\u6b62\u4f20\u7edf\u957f\u7a0b\u6709\u5e8f\u7684\u7a33\u5b9a\uff0c\u5bfc\u81f4\u65b0\u578b\u5411\u5217\u76f8\u7684\u51fa\u73b0\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63ed\u793a\u4e86\u7126\u7eff\u77f3\u78c1\u4f53\u4e2d\u6df7\u5408\u78c1\u76f8\u548c\u5411\u5217\u76f8\u7684\u5f62\u6210\u673a\u5236\uff0c\u4e3a\u7406\u89e3\u963b\u632b\u7cfb\u7edf\u4e2d\u7684\u975e\u5e38\u89c4\u78c1\u6001\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u53c2\u6570\u7a7a\u95f4\u7279\u5b9a\u70b9\u5904\u79bb\u6563\u5bf9\u79f0\u6027\u5bf9\u76f8\u884c\u4e3a\u7684\u5173\u952e\u5f71\u54cd\u3002"}}
{"id": "2510.23621", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23621", "abs": "https://arxiv.org/abs/2510.23621", "authors": ["Alexandre Benoit"], "title": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields", "comment": "78 pages, 21 figures", "summary": "Machine-learning force fields can deliver accurate molecular dynamics (MD) at\nhigh computational cost. For SO(3)-equivariant models such as MACE, there is\nlittle systematic evidence on whether reduced-precision arithmetic and\nGPU-optimized kernels can cut this cost without harming physical fidelity. This\nthesis aims to make MACE cheaper and faster while preserving accuracy by\nidentifying computational bottlenecks and evaluating low-precision execution\npolicies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA\ncuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32\naccumulation) for inference, short NVT and long NPT water simulations, and toy\ntraining runs under reproducible, steady-state timing. cuEquivariance reduces\ninference latency by about $3\\times$. Casting only linear layers to BF16/FP16\nwithin an FP32 model yields roughly 4x additional speedups, while energies and\nthermodynamic observables in NVT/NPT MD remain within run-to-run variability.\nHalf-precision weights during training degrade force RMSE. Mixing e3nn and cuEq\nmodules without explicit adapters causes representation mismatches. Fused\nequivariant kernels and mixed-precision inference can substantially accelerate\nstate-of-the-art force fields with negligible impact on downstream MD. A\npractical policy is to use cuEquivariance with FP32 by default and enable\nBF16/FP16 for linear layers (keeping FP32 accumulations) for maximum\nthroughput, while training remains in FP32. Further gains are expected on\nAmpere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and\npipeline fusion.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u901a\u8fc7\u964d\u4f4e\u7cbe\u5ea6\u7b97\u672f\u548cGPU\u4f18\u5316\u5185\u6838\u6765\u52a0\u901fSO(3)-\u7b49\u53d8\u673a\u5668\u5b66\u4e60\u529b\u573aMACE\uff0c\u540c\u65f6\u4fdd\u6301\u7269\u7406\u4fdd\u771f\u5ea6\u3002\u8bc4\u4f30\u4e86cuEquivariance\u540e\u7aef\u548c\u6df7\u5408\u7cbe\u5ea6\u7b56\u7565\uff0c\u53d1\u73b0\u53ef\u663e\u8457\u52a0\u901f\u63a8\u7406\u800c\u51e0\u4e4e\u4e0d\u5f71\u54cd\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u7ed3\u679c\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u529b\u573a\u867d\u7136\u51c6\u786e\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u7f3a\u4e4f\u5173\u4e8e\u964d\u4f4e\u7cbe\u5ea6\u7b97\u672f\u548cGPU\u4f18\u5316\u5185\u6838\u80fd\u5426\u5728\u4e0d\u635f\u5bb3\u7269\u7406\u4fdd\u771f\u5ea6\u7684\u60c5\u51b5\u4e0b\u964d\u4f4e\u6210\u672c\u7684\u7cfb\u7edf\u6027\u8bc1\u636e\u3002", "method": "\u5bf9MACE\u8fdb\u884c\u7aef\u5230\u7aef\u548c\u9010\u5757\u6027\u80fd\u5206\u6790\uff0c\u6bd4\u8f83e3nn\u548cNVIDIA cuEquivariance\u540e\u7aef\uff0c\u8bc4\u4f30FP64/FP32/BF16/FP16\u7cbe\u5ea6\u8bbe\u7f6e\uff0c\u5728\u63a8\u7406\u3001\u77edNVT\u548c\u957fNPT\u6c34\u6a21\u62df\u4ee5\u53ca\u73a9\u5177\u8bad\u7ec3\u8fd0\u884c\u4e2d\u8fdb\u884c\u53ef\u91cd\u73b0\u7684\u7a33\u6001\u8ba1\u65f6\u6d4b\u8bd5\u3002", "result": "cuEquivariance\u5c06\u63a8\u7406\u5ef6\u8fdf\u51cf\u5c11\u7ea63\u500d\uff1b\u5728\u7ebf\u6027\u5c42\u4e2d\u4f7f\u7528BF16/FP16\u6df7\u5408\u7cbe\u5ea6\uff08\u5728FP32\u6a21\u578b\u4e2d\uff09\u53ef\u989d\u5916\u83b7\u5f97\u7ea64\u500d\u52a0\u901f\uff1bNVT/NPT MD\u4e2d\u7684\u80fd\u91cf\u548c\u70ed\u529b\u5b66\u89c2\u6d4b\u91cf\u4fdd\u6301\u5728\u8fd0\u884c\u95f4\u53d8\u5f02\u6027\u8303\u56f4\u5185\uff1b\u8bad\u7ec3\u4e2d\u4f7f\u7528\u534a\u7cbe\u5ea6\u6743\u91cd\u4f1a\u964d\u4f4e\u529bRMSE\u3002", "conclusion": "\u878d\u5408\u7b49\u53d8\u5185\u6838\u548c\u6df7\u5408\u7cbe\u5ea6\u63a8\u7406\u53ef\u4ee5\u663e\u8457\u52a0\u901f\u6700\u5148\u8fdb\u7684\u529b\u573a\uff0c\u5bf9\u4e0b\u6e38\u5206\u5b50\u52a8\u529b\u5b66\u5f71\u54cd\u53ef\u5ffd\u7565\u3002\u5efa\u8bae\u9ed8\u8ba4\u4f7f\u7528cuEquivariance\u4e0eFP32\uff0c\u5e76\u4e3a\u7ebf\u6027\u5c42\u542f\u7528BF16/FP16\uff08\u4fdd\u6301FP32\u7d2f\u52a0\uff09\u4ee5\u83b7\u5f97\u6700\u5927\u541e\u5410\u91cf\uff0c\u8bad\u7ec3\u4ecd\u4f7f\u7528FP32\u3002"}}
{"id": "2510.23734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23734", "abs": "https://arxiv.org/abs/2510.23734", "authors": ["Eamon Duede"], "title": "AI and the Decentering of Disciplinary Creativity", "comment": null, "summary": "This paper examines the role of artificial intelligence in scientific\nproblem-solving, with a focus on its implications for disciplinary creativity.\nDrawing on recent work in the philosophy of creativity, I distinguish between\ncreative approaches and creative products, and introduce the concept of\ndisciplinary creativity -the creative application of discipline-specific\nexpertise to a valued problem within that field. Through two cases in\nmathematics, I show that while computation can extend disciplinary creativity,\ncertain approaches involving AI can serve to displace it. This displacement has\nthe potential to alter (and, perhaps, diminish) the value of scientific\npursuit.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8AI\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u4f5c\u7528\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5bf9\u5b66\u79d1\u521b\u9020\u529b\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u533a\u5206\u521b\u9020\u6027\u65b9\u6cd5\u548c\u521b\u9020\u6027\u4ea7\u54c1\uff0c\u5f15\u5165\u5b66\u79d1\u521b\u9020\u529b\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u6848\u4f8b\u8868\u660eAI\u53ef\u80fd\u53d6\u4ee3\u800c\u975e\u6269\u5c55\u5b66\u79d1\u521b\u9020\u529b\u3002", "motivation": "\u7814\u7a76AI\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u89d2\u8272\uff0c\u7279\u522b\u662f\u5176\u5bf9\u5b66\u79d1\u521b\u9020\u529b\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u65e8\u5728\u7406\u89e3AI\u5982\u4f55\u6539\u53d8\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\u3002", "method": "\u57fa\u4e8e\u521b\u9020\u529b\u54f2\u5b66\u7406\u8bba\uff0c\u533a\u5206\u521b\u9020\u6027\u65b9\u6cd5\u548c\u4ea7\u54c1\uff0c\u5f15\u5165\u5b66\u79d1\u521b\u9020\u529b\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6570\u5b66\u6848\u4f8b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8ba1\u7b97\u53ef\u4ee5\u6269\u5c55\u5b66\u79d1\u521b\u9020\u529b\uff0c\u4f46\u67d0\u4e9bAI\u65b9\u6cd5\u53ef\u80fd\u53d6\u4ee3\u5b66\u79d1\u521b\u9020\u529b\uff0c\u4ece\u800c\u53ef\u80fd\u6539\u53d8\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\u3002", "conclusion": "AI\u5728\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u53ef\u80fd\u901a\u8fc7\u53d6\u4ee3\u5b66\u79d1\u521b\u9020\u529b\u800c\u6539\u53d8\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\uff0c\u9700\u8981\u8c28\u614e\u8003\u8651AI\u5bf9\u79d1\u5b66\u521b\u9020\u529b\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.23736", "categories": ["quant-ph", "math-ph", "math.CO", "math.MP", "81P42, 81P45, 81P73, 05B35"], "pdf": "https://arxiv.org/pdf/2510.23736", "abs": "https://arxiv.org/abs/2510.23736", "authors": ["Stephane Dartois", "Gilles Z\u00e9mor"], "title": "The injective norm of CSS quantum error-correcting codes", "comment": "11 pages", "summary": "In this paper, we compute the injective norm - a.k.a. geometric entanglement\n- of standard basis states of CSS quantum error-correcting codes. The injective\nnorm of a quantum state is a measure of genuine multipartite entanglement.\nComputing this measure is generically NP-hard. However, it has been computed\nexactly in condensed-matter theory - notably in the context of topological\nphases - for the Kitaev code and its extensions, in works by Or\\'us and\ncollaborators. We extend these results to all CSS codes and thereby obtain the\ninjective norm for a nontrivial, infinite family of quantum states. In doing\nso, we uncover an interesting connection to matroid theory and Edmonds'\nintersection theorem.", "AI": {"tldr": "\u672c\u6587\u8ba1\u7b97\u4e86CSS\u91cf\u5b50\u7ea0\u9519\u7801\u6807\u51c6\u57fa\u6001\u7684\u6ce8\u5165\u8303\u6570\uff08\u5373\u51e0\u4f55\u7ea0\u7f20\u5ea6\uff09\uff0c\u8fd9\u662f\u8861\u91cf\u771f\u6b63\u591a\u4f53\u7ea0\u7f20\u7684\u6307\u6807\u3002\u901a\u8fc7\u5c06\u7ed3\u679c\u6269\u5c55\u5230\u6240\u6709CSS\u7801\uff0c\u53d1\u73b0\u4e86\u4e00\u4e2a\u4e0e\u62df\u9635\u7406\u8bba\u548cEdmonds\u4ea4\u96c6\u5b9a\u7406\u7684\u6709\u8da3\u8054\u7cfb\u3002", "motivation": "\u6ce8\u5165\u8303\u6570\u662f\u8861\u91cf\u91cf\u5b50\u6001\u771f\u6b63\u591a\u4f53\u7ea0\u7f20\u7684\u91cd\u8981\u6307\u6807\uff0c\u4f46\u8ba1\u7b97\u8be5\u6307\u6807\u901a\u5e38\u662fNP\u96be\u7684\u3002\u867d\u7136\u4e4b\u524d\u5df2\u5728\u51dd\u805a\u6001\u7269\u7406\u4e2d\u4e3aKitaev\u7801\u53ca\u5176\u6269\u5c55\u8ba1\u7b97\u4e86\u8be5\u503c\uff0c\u4f46\u9700\u8981\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684CSS\u7801\u5bb6\u65cf\u3002", "method": "\u901a\u8fc7\u5c06CSS\u7801\u7684\u6ce8\u5165\u8303\u6570\u8ba1\u7b97\u95ee\u9898\u4e0e\u62df\u9635\u7406\u8bba\u4e2d\u7684Edmonds\u4ea4\u96c6\u5b9a\u7406\u5efa\u7acb\u8054\u7cfb\uff0c\u4ece\u800c\u80fd\u591f\u4e3a\u6240\u6709CSS\u7801\u8ba1\u7b97\u8fd9\u4e00\u7ea0\u7f20\u5ea6\u91cf\u3002", "result": "\u6210\u529f\u8ba1\u7b97\u4e86\u6240\u6709CSS\u7801\u6807\u51c6\u57fa\u6001\u7684\u6ce8\u5165\u8303\u6570\uff0c\u5f97\u5230\u4e86\u4e00\u4e2a\u975e\u5e73\u51e1\u65e0\u9650\u91cf\u5b50\u6001\u5bb6\u65cf\u7684\u7ea0\u7f20\u5ea6\u91cf\u7cbe\u786e\u503c\u3002", "conclusion": "\u672c\u7814\u7a76\u4e0d\u4ec5\u6269\u5c55\u4e86CSS\u7801\u7684\u51e0\u4f55\u7ea0\u7f20\u8ba1\u7b97\uff0c\u8fd8\u63ed\u793a\u4e86\u91cf\u5b50\u4fe1\u606f\u4e0e\u7ec4\u5408\u6570\u5b66\u4e2d\u62df\u9635\u7406\u8bba\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\uff0c\u4e3a\u7406\u89e3\u91cf\u5b50\u7ea0\u7f20\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u5de5\u5177\u3002"}}
{"id": "2510.24169", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2510.24169", "abs": "https://arxiv.org/abs/2510.24169", "authors": ["Vikas", "Rahul Marathe", "Anjan Roy"], "title": "On distinguishability among cell-division models based on population and single-cell-level distributions", "comment": "44 pages, 15 figures", "summary": "It is well known that the different cell-division models, such as Timer,\nSizer, and Adder, can be distinguished based on the correlations between\ndifferent single-cell-level quantities such as birth-size, division-time,\ndivision-size, and division-added-size. Here, we show that other statistical\nproperties of these quantities can also be used to distinguish between them.\nAdditionally, the statistical relationships and different correlation patterns\ncan also differentiate between the different types of single-cell growth, such\nas linear and exponential. Further, we demonstrate that various\npopulation-level distributions, such as age, size, and added-size\ndistributions, are indistinguishable across different models of cell division\ndespite them having different division rules and correlation patterns.\nMoreover, this indistinguishability is robust to stochasticity in growth rate\nand holds for both exponential and linear growth. Finally, we show that our\ntheoretical predictions are corroborated by simulations and supported by\nexisting single-cell experimental data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u7ec6\u80de\u5206\u88c2\u7edf\u8ba1\u7279\u6027\u533a\u5206\u4e0d\u540c\u7684\u7ec6\u80de\u5206\u88c2\u6a21\u578b\uff08Timer\u3001Sizer\u3001Adder\uff09\uff0c\u5e76\u53d1\u73b0\u5c3d\u7ba1\u4e0d\u540c\u6a21\u578b\u5177\u6709\u4e0d\u540c\u7684\u5206\u88c2\u89c4\u5219\u548c\u76f8\u5173\u6027\u6a21\u5f0f\uff0c\u4f46\u7fa4\u4f53\u6c34\u5e73\u7684\u5206\u5e03\uff08\u5982\u5e74\u9f84\u3001\u5927\u5c0f\u3001\u6dfb\u52a0\u5927\u5c0f\u5206\u5e03\uff09\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u65e0\u6cd5\u533a\u5206\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u7ec6\u80de\u5206\u88c2\u6a21\u578b\uff08Timer\u3001Sizer\u3001Adder\uff09\u7684\u533a\u5206\u65b9\u6cd5\uff0c\u63a2\u7d22\u7ec6\u80de\u5206\u88c2\u7edf\u8ba1\u7279\u6027\u4e0e\u751f\u957f\u6a21\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u7fa4\u4f53\u6c34\u5e73\u5206\u5e03\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u76f8\u4f3c\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5355\u7ec6\u80de\u6c34\u5e73\u7684\u7edf\u8ba1\u7279\u6027\uff08\u5982\u51fa\u751f\u5927\u5c0f\u3001\u5206\u88c2\u65f6\u95f4\u3001\u5206\u88c2\u5927\u5c0f\u3001\u5206\u88c2\u6dfb\u52a0\u5927\u5c0f\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff09\u6765\u533a\u5206\u4e0d\u540c\u7ec6\u80de\u5206\u88c2\u6a21\u578b\uff0c\u5e76\u7814\u7a76\u7fa4\u4f53\u6c34\u5e73\u5206\u5e03\u7684\u76f8\u4f3c\u6027\uff0c\u4f7f\u7528\u7406\u8bba\u9884\u6d4b\u3001\u6a21\u62df\u9a8c\u8bc1\u548c\u73b0\u6709\u5b9e\u9a8c\u6570\u636e\u652f\u6301\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u7ec6\u80de\u5206\u88c2\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5355\u7ec6\u80de\u6c34\u5e73\u7684\u7edf\u8ba1\u7279\u6027\u548c\u76f8\u5173\u6027\u6a21\u5f0f\u8fdb\u884c\u533a\u5206\uff1b\u4f46\u7fa4\u4f53\u6c34\u5e73\u7684\u5206\u5e03\uff08\u5e74\u9f84\u3001\u5927\u5c0f\u3001\u6dfb\u52a0\u5927\u5c0f\u5206\u5e03\uff09\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u65e0\u6cd5\u533a\u5206\uff0c\u4e14\u8fd9\u79cd\u4e0d\u53ef\u533a\u5206\u6027\u5bf9\u751f\u957f\u901f\u7387\u7684\u968f\u673a\u6027\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u5355\u7ec6\u80de\u6c34\u5e73\u7684\u7edf\u8ba1\u7279\u6027\u53ef\u4ee5\u6709\u6548\u533a\u5206\u4e0d\u540c\u7ec6\u80de\u5206\u88c2\u6a21\u578b\u548c\u751f\u957f\u6a21\u5f0f\uff0c\u4f46\u7fa4\u4f53\u6c34\u5e73\u5206\u5e03\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5177\u6709\u76f8\u4f3c\u6027\uff0c\u8fd9\u4e3a\u7ec6\u80de\u5206\u88c2\u673a\u5236\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u65b9\u6cd5\u3002"}}
{"id": "2510.23720", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23720", "abs": "https://arxiv.org/abs/2510.23720", "authors": ["Xiang Li", "Ting-Chun Lin", "Yahya Alavirad", "John McGreevy"], "title": "Chiral gapped states are universally non-topological", "comment": "38+14 pages, 39 figures", "summary": "We propose an operator generalization of the Li-Haldane conjecture regarding\nthe entanglement Hamiltonian of a disk in a 2+1D chiral gapped groundstate. The\nlogic applies to regions with sharp corners, from which we derive several\nuniversal properties regarding corner entanglement. These universal properties\nfollow from a set of locally-checkable conditions on the wavefunction. We also\ndefine a quantity $(\\mathfrak{c}_{\\text{tot}})_{\\text{min}}$ that reflects the\nrobustness of corner entanglement contributions, and show that it provides an\nobstruction to a gapped boundary. One reward from our analysis is that we can\nconstruct a local gapped Hamiltonian within the same chiral gapped phase from a\ngiven wavefunction; we conjecture that it is closer to the low-energy\nrenormalization group fixed point than the original parent Hamiltonian. Our\nanalysis of corner entanglement reveals the emergence of a universal conformal\ngeometry encoded in the entanglement structure of bulk regions of chiral gapped\nstates that is not visible in topological field theory.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Li-Haldane\u731c\u60f3\u7684\u7b97\u5b50\u63a8\u5e7f\uff0c\u7814\u7a762+1\u7ef4\u624b\u6027\u6709\u9699\u57fa\u6001\u4e2d\u5706\u76d8\u7684\u7ea0\u7f20\u54c8\u5bc6\u987f\u91cf\u3002\u901a\u8fc7\u5206\u6790\u5177\u6709\u5c16\u9510\u89d2\u7684\u533a\u57df\uff0c\u63a8\u5bfc\u51fa\u5173\u4e8e\u89d2\u7ea0\u7f20\u7684\u82e5\u5e72\u666e\u9002\u6027\u8d28\uff0c\u5e76\u5b9a\u4e49\u4e86\u53cd\u6620\u89d2\u7ea0\u7f20\u8d21\u732e\u9c81\u68d2\u6027\u7684\u91cf\uff0c\u8be5\u91cf\u5bf9\u6709\u9699\u8fb9\u754c\u6784\u6210\u963b\u788d\u3002", "motivation": "\u7814\u7a76\u624b\u6027\u6709\u9699\u6001\u4e2d\u533a\u57df\u7ea0\u7f20\u7684\u666e\u9002\u6027\u8d28\uff0c\u7279\u522b\u662f\u89d2\u7ea0\u7f20\u7684\u8d21\u732e\uff0c\u63ed\u793a\u62d3\u6251\u573a\u8bba\u4e2d\u4e0d\u53ef\u89c1\u7684\u666e\u9002\u5171\u5f62\u51e0\u4f55\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5177\u6709\u5c16\u9510\u89d2\u7684\u533a\u57df\u7ea0\u7f20\u7ed3\u6784\uff0c\u63a8\u5bfc\u51fa\u57fa\u4e8e\u6ce2\u51fd\u6570\u5c40\u90e8\u53ef\u68c0\u9a8c\u6761\u4ef6\u7684\u666e\u9002\u6027\u8d28\uff0c\u5e76\u6784\u9020\u5c40\u90e8\u6709\u9699\u54c8\u5bc6\u987f\u91cf\u3002", "result": "\u53d1\u73b0\u4e86\u89d2\u7ea0\u7f20\u7684\u666e\u9002\u6027\u8d28\uff0c\u5b9a\u4e49\u4e86\u53cd\u6620\u89d2\u7ea0\u7f20\u9c81\u68d2\u6027\u7684\u91cf\uff0c\u5e76\u6210\u529f\u6784\u9020\u4e86\u4e0e\u539f\u59cb\u624b\u6027\u6709\u9699\u76f8\u76f8\u540c\u7684\u5c40\u90e8\u6709\u9699\u54c8\u5bc6\u987f\u91cf\u3002", "conclusion": "\u89d2\u7ea0\u7f20\u5206\u6790\u63ed\u793a\u4e86\u624b\u6027\u6709\u9699\u6001\u4f53\u533a\u57df\u7ea0\u7f20\u7ed3\u6784\u4e2d\u7f16\u7801\u7684\u666e\u9002\u5171\u5f62\u51e0\u4f55\uff0c\u8fd9\u4e9b\u7ed3\u6784\u5728\u62d3\u6251\u573a\u8bba\u4e2d\u4e0d\u53ef\u89c1\uff0c\u4e3a\u7406\u89e3\u624b\u6027\u62d3\u6251\u76f8\u7684\u7ea0\u7f20\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2510.23622", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23622", "abs": "https://arxiv.org/abs/2510.23622", "authors": ["Alyssa Gerhart", "Balaji Iyangar"], "title": "Adversarially-Aware Architecture Design for Robust Medical AI Systems", "comment": null, "summary": "Adversarial attacks pose a severe risk to AI systems used in healthcare,\ncapable of misleading models into dangerous misclassifications that can delay\ntreatments or cause misdiagnoses. These attacks, often imperceptible to human\nperception, threaten patient safety, particularly in underserved populations.\nOur study explores these vulnerabilities through empirical experimentation on a\ndermatological dataset, where adversarial methods significantly reduce\nclassification accuracy. Through detailed threat modeling, experimental\nbenchmarking, and model evaluation, we demonstrate both the severity of the\nthreat and the partial success of defenses like adversarial training and\ndistillation. Our results show that while defenses reduce attack success rates,\nthey must be balanced against model performance on clean data. We conclude with\na call for integrated technical, ethical, and policy-based approaches to build\nmore resilient, equitable AI in healthcare.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u533b\u7597AI\u7cfb\u7edf\u4e2d\u7684\u5bf9\u6297\u6027\u653b\u51fb\u98ce\u9669\uff0c\u901a\u8fc7\u5728\u76ae\u80a4\u75c5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u5bf9\u6297\u6027\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5206\u7c7b\u51c6\u786e\u6027\u7684\u95ee\u9898\uff0c\u5e76\u8bc4\u4f30\u4e86\u9632\u5fa1\u63aa\u65bd\u7684\u6548\u679c\u3002", "motivation": "\u5bf9\u6297\u6027\u653b\u51fb\u5bf9\u533b\u7597AI\u7cfb\u7edf\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u53ef\u80fd\u5bfc\u81f4\u5371\u9669\u7684\u8bef\u5206\u7c7b\uff0c\u5ef6\u8bef\u6cbb\u7597\u6216\u9020\u6210\u8bef\u8bca\uff0c\u7279\u522b\u662f\u5728\u670d\u52a1\u4e0d\u8db3\u7684\u4eba\u7fa4\u4e2d\u5a01\u80c1\u60a3\u8005\u5b89\u5168\u3002", "method": "\u901a\u8fc7\u8be6\u7ec6\u7684\u5a01\u80c1\u5efa\u6a21\u3001\u5b9e\u9a8c\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u8bc4\u4f30\uff0c\u5728\u76ae\u80a4\u75c5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u5bf9\u6297\u6027\u8bad\u7ec3\u548c\u84b8\u998f\u7b49\u9632\u5fa1\u65b9\u6cd5\u3002", "result": "\u9632\u5fa1\u63aa\u65bd\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f46\u9700\u8981\u5728\u6a21\u578b\u5728\u5e72\u51c0\u6570\u636e\u4e0a\u7684\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u5bf9\u6297\u6027\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u3002", "conclusion": "\u9700\u8981\u6574\u5408\u6280\u672f\u3001\u4f26\u7406\u548c\u653f\u7b56\u65b9\u6cd5\uff0c\u6784\u5efa\u66f4\u5177\u97e7\u6027\u3001\u66f4\u516c\u5e73\u7684\u533b\u7597AI\u7cfb\u7edf\u3002"}}
{"id": "2510.23744", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23744", "abs": "https://arxiv.org/abs/2510.23744", "authors": ["Eline M. Bovy", "Caleb Probine", "Marnix Suilen", "Ufuk Topcu", "Nils Jansen"], "title": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability", "comment": "Accepted at NeurIPS 2025", "summary": "Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete\nmodel uncertainty. ME-POMDPs represent a finite set of POMDPs that share the\nsame state, action, and observation spaces, but may arbitrarily vary in their\ntransition, observation, and reward models. Such models arise, for instance,\nwhen multiple domain experts disagree on how to model a problem. The goal is to\nfind a single policy that is robust against any choice of POMDP within the set,\ni.e., a policy that maximizes the worst-case reward across all POMDPs. We\ngeneralize and expand on existing work in the following way. First, we show\nthat ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which\nwe call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any\narbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its\ntransition and reward functions or only in its observation and reward\nfunctions, while preserving (optimal) policies. We then devise exact and\napproximate (point-based) algorithms to compute robust policies for AB-POMDPs,\nand thus ME-POMDPs. We demonstrate that we can compute policies for standard\nPOMDP benchmarks extended to the multi-environment setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u73af\u5883POMDP\uff08ME-POMDP\uff09\u548c\u5bf9\u6297\u4fe1\u5ff5POMDP\uff08AB-POMDP\uff09\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u79bb\u6563\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u5f00\u53d1\u4e86\u7cbe\u786e\u548c\u8fd1\u4f3c\u7b97\u6cd5\u6765\u8ba1\u7b97\u9c81\u68d2\u7b56\u7565\u3002", "motivation": "\u5f53\u591a\u4e2a\u9886\u57df\u4e13\u5bb6\u5bf9\u95ee\u9898\u5efa\u6a21\u5b58\u5728\u5206\u6b67\u65f6\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u6846\u67b6\uff0c\u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u5728\u6240\u6709\u53ef\u80fdPOMDP\u6a21\u578b\u4e2d\u90fd\u80fd\u8868\u73b0\u826f\u597d\u7684\u5355\u4e00\u9c81\u68d2\u7b56\u7565\u3002", "method": "\u5c06ME-POMDP\u63a8\u5e7f\u5230\u5177\u6709\u521d\u59cb\u4fe1\u5ff5\u96c6\u5408\u7684AB-POMDP\uff1b\u8bc1\u660e\u4efb\u610fME-POMDP\u53ef\u4ee5\u7b80\u5316\u4e3a\u4ec5\u5728\u8f6c\u79fb\u548c\u5956\u52b1\u51fd\u6570\u6216\u4ec5\u5728\u89c2\u6d4b\u548c\u5956\u52b1\u51fd\u6570\u4e0a\u53d8\u5316\u7684ME-POMDP\uff1b\u5f00\u53d1\u7cbe\u786e\u548c\u8fd1\u4f3c\uff08\u57fa\u4e8e\u70b9\uff09\u7b97\u6cd5\u6765\u8ba1\u7b97\u9c81\u68d2\u7b56\u7565\u3002", "result": "\u6210\u529f\u4e3a\u6807\u51c6POMDP\u57fa\u51c6\u6d4b\u8bd5\u7684\u591a\u73af\u5883\u6269\u5c55\u7248\u672c\u8ba1\u7b97\u4e86\u7b56\u7565\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "ME-POMDP\u548cAB-POMDP\u4e3a\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u6240\u5f00\u53d1\u7684\u7b97\u6cd5\u80fd\u591f\u8ba1\u7b97\u5728\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u8868\u73b0\u9c81\u68d2\u7684\u7b56\u7565\u3002"}}
{"id": "2510.23796", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.optics"], "pdf": "https://arxiv.org/pdf/2510.23796", "abs": "https://arxiv.org/abs/2510.23796", "authors": ["A. Zecchetto", "J. -R. Coudevylle", "M. Morassi", "A. Lema\u00eetre", "M. I. Amanti", "S. Ducci", "F. Baboux"], "title": "Topological protection of photon-pair generation in nonlinear waveguide arrays", "comment": null, "summary": "Harnessing topological effects offers a promising route to protect quantum\nstates of light from imperfections, potentially enabling more robust platforms\nfor quantum information processing. This capability is particularly relevant\nfor active photonic circuits that generate quantum light directly on-chip.\nHere, we explore topological effects on photon-pair generation via spontaneous\nparametric down-conversion (SPDC) in nonlinear waveguide arrays, both\ntheoretically and experimentally. A systematic comparison of homogeneous,\ntrivial, and topological Su-Schrieffer-Heeger arrays reveals that only the\ntopological configuration preserves a stable SPDC resonance spectrum under\ndisorder in the tunnel couplings, with fluctuations in the resonance position\nreduced by more than one order of magnitude. An analytical model supports our\nexperimental observations by linking this robustness to the band-structure\nproperties of the interacting modes. These findings establish quadratic\nnonlinear waveguide arrays as a promising platform to explore the interplay of\nnonlinearity, topology, and disorder in quantum photonic circuits.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u975e\u7ebf\u6027\u6ce2\u5bfc\u9635\u5217\u4e2d\u62d3\u6251\u6548\u5e94\u5bf9\u81ea\u53d1\u53c2\u91cf\u4e0b\u8f6c\u6362\u5149\u5b50\u5bf9\u751f\u6210\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u62d3\u6251Su-Schrieffer-Heeger\u9635\u5217\u5728\u96a7\u9053\u8026\u5408\u65e0\u5e8f\u6761\u4ef6\u4e0b\u80fd\u4fdd\u6301\u7a33\u5b9a\u7684SPDC\u5171\u632f\u8c31\uff0c\u5171\u632f\u4f4d\u7f6e\u6ce2\u52a8\u51cf\u5c11\u8d85\u8fc7\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u5229\u7528\u62d3\u6251\u6548\u5e94\u4fdd\u62a4\u91cf\u5b50\u5149\u6001\u514d\u53d7\u7f3a\u9677\u5f71\u54cd\uff0c\u4e3a\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u5e73\u53f0\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7247\u4e0a\u751f\u6210\u91cf\u5b50\u5149\u7684\u4e3b\u52a8\u5149\u5b50\u7535\u8def\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u7814\u7a76\u975e\u7ebf\u6027\u6ce2\u5bfc\u9635\u5217\u4e2d\u7684\u81ea\u53d1\u53c2\u91cf\u4e0b\u8f6c\u6362\uff0c\u7cfb\u7edf\u6bd4\u8f83\u5747\u5300\u3001\u5e73\u5eb8\u548c\u62d3\u6251Su-Schrieffer-Heeger\u9635\u5217\u7684\u6027\u80fd\u3002", "result": "\u53ea\u6709\u62d3\u6251\u914d\u7f6e\u5728\u96a7\u9053\u8026\u5408\u65e0\u5e8f\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5b9a\u7684SPDC\u5171\u632f\u8c31\uff0c\u5171\u632f\u4f4d\u7f6e\u6ce2\u52a8\u51cf\u5c11\u8d85\u8fc7\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002\u5206\u6790\u6a21\u578b\u5c06\u8fd9\u79cd\u9c81\u68d2\u6027\u4e0e\u76f8\u4e92\u4f5c\u7528\u6a21\u5f0f\u7684\u80fd\u5e26\u7ed3\u6784\u7279\u6027\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u4e8c\u6b21\u975e\u7ebf\u6027\u6ce2\u5bfc\u9635\u5217\u662f\u63a2\u7d22\u975e\u7ebf\u6027\u3001\u62d3\u6251\u548c\u65e0\u5e8f\u5728\u91cf\u5b50\u5149\u5b50\u7535\u8def\u4e2d\u76f8\u4e92\u4f5c\u7528\u7684\u7406\u60f3\u5e73\u53f0\u3002"}}
{"id": "2510.24237", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.24237", "abs": "https://arxiv.org/abs/2510.24237", "authors": ["Kazuki Ikeuchi", "Yoshiki Matsuda", "Shu Tanaka"], "title": "Evaluating the Performance of Direct Higher-Order Formulations in Combinatorial Optimization Problems", "comment": null, "summary": "Ising machines, including quantum annealing machines, are promising\nnext-generation computers for combinatorial optimization problems. However, due\nto hardware limitations, most Ising-type hardware can only solve objective\nfunctions expressed in linear or quadratic terms of binary variables.\nTherefore, problems with higher-order terms require an order-reduction process,\nwhich increases the number of variables and constraints and may degrade\nsolution quality. In this study, we evaluate the effectiveness of directly\nsolving such problems without order reduction by using a high-performance\nsimulated annealing-based optimization solver capable of handling polynomial\nunconstrained binary optimization (PUBO) formulations. We compare its\nperformance against a conventional quadratic unconstrained binary optimization\n(QUBO) solver on the same hardware platform. As benchmarks, we use the low\nautocorrelation binary sequence (LABS) problem and the vehicle routing problem\nwith distance balancing, both of which naturally include higher-order\ninteractions. Results show that the PUBO solver consistently achieves superior\nsolution quality and stability compared to its QUBO counterpart, while\nmaintaining comparable computational time and requiring no order-reduction\ncompilation indicating potential advantages of directly handling higher-order\nterms in practical optimization problems.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u76f4\u63a5\u4f7f\u7528\u9ad8\u6027\u80fd\u6a21\u62df\u9000\u706b\u4f18\u5316\u6c42\u89e3\u5668\u5904\u7406\u5305\u542b\u9ad8\u9636\u9879\u7684\u4f18\u5316\u95ee\u9898\u7684\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u5728LABS\u95ee\u9898\u548c\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0cPUBO\u6c42\u89e3\u5668\u80fd\u83b7\u5f97\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u7531\u4e8e\u786c\u4ef6\u9650\u5236\uff0c\u5927\u591a\u6570Ising\u7c7b\u578b\u786c\u4ef6\u53ea\u80fd\u5904\u7406\u7ebf\u6027\u6216\u4e8c\u6b21\u9879\u7684\u4f18\u5316\u95ee\u9898\uff0c\u9ad8\u9636\u9879\u95ee\u9898\u9700\u8981\u8fdb\u884c\u9636\u6b21\u964d\u4f4e\u5904\u7406\uff0c\u8fd9\u4f1a\u589e\u52a0\u53d8\u91cf\u6570\u91cf\u548c\u7ea6\u675f\u6761\u4ef6\uff0c\u53ef\u80fd\u964d\u4f4e\u89e3\u7684\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u9ad8\u6027\u80fd\u6a21\u62df\u9000\u706b\u4f18\u5316\u6c42\u89e3\u5668\u76f4\u63a5\u5904\u7406\u591a\u9879\u5f0f\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u4e0e\u4f20\u7edf\u7684\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u6c42\u89e3\u5668\u5728\u540c\u4e00\u786c\u4ef6\u5e73\u53f0\u4e0a\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "PUBO\u6c42\u89e3\u5668\u5728LABS\u95ee\u9898\u548c\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u4f18\u4e8eQUBO\u6c42\u89e3\u5668\uff0c\u83b7\u5f97\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u8ba1\u7b97\u65f6\u95f4\u4e14\u65e0\u9700\u9636\u6b21\u964d\u4f4e\u7f16\u8bd1\u3002", "conclusion": "\u76f4\u63a5\u5904\u7406\u9ad8\u9636\u9879\u5728\u5b9e\u7528\u4f18\u5316\u95ee\u9898\u4e2d\u5177\u6709\u6f5c\u5728\u4f18\u52bf\uff0cPUBO\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u9636\u6b21\u964d\u4f4e\u5904\u7406\u3002"}}
{"id": "2510.23743", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.23743", "abs": "https://arxiv.org/abs/2510.23743", "authors": ["Filippo Pascucci", "Stefania De Palo", "Sara Conti", "David Neilson", "Andrea Perali", "Gaetano Senatore"], "title": "Beyond Random Phase Approximation in electron-hole bilayer superfluidity", "comment": null, "summary": "We derive the normal and anomalous proper polarization functions and the\nscreened Coulomb interactions in a two-dimensional superfluid electron-hole\nbilayer, including all first-order corrections beyond the Random Phase\nApproximation (RPA). This requires a modification of the perturbation method as\nfirst noted by Nozi\\`eres and Schrieffer [1, 2]. We discuss the physical origin\nand magnitude of the first-order corrections in a superfluid system with\nlong-range Coulomb interactions. Unlike conventional superconductivity,\nMigdal's theorem does not apply here, so exchange vertex corrections cannot be\nneglected. The screened electron-electron, hole-hole, and electron-hole\ninteractions in the superfluid state are evaluated as functions of the carrier\ndensity. We find that at low density, the strong cancellations between the\nnormal and anomalous components that make screening of the interactions\nnegligible, apply not only within RPA but also with the first-order corrections\nincluded. As the density is increased, the normal-anomalous cancellation\nweakens and screening becomes increasingly significant. We find that the\nfirst-order corrections amplify the normal-anomalous difference but only at\nlarge momenta exchanged in the two-particle scattering, so their effect on the\ninteractions remains modest. We conclude that the superfluid state RPA is an\nexcellent approximation for the screening and for the effective electron-hole\npairing in this superfluid system over the range of densities up to the maximum\nof the superfluid gap.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e8c\u7ef4\u8d85\u6d41\u4f53\u7535\u5b50-\u7a7a\u7a74\u53cc\u5c42\u7cfb\u7edf\u4e2d\u7684\u6781\u5316\u51fd\u6570\u548c\u5c4f\u853d\u5e93\u4ed1\u76f8\u4e92\u4f5c\u7528\uff0c\u5305\u62ec\u8d85\u8d8a\u968f\u673a\u76f8\u4f4d\u8fd1\u4f3c\uff08RPA\uff09\u7684\u4e00\u9636\u4fee\u6b63\u3002\u91cd\u70b9\u5206\u6790\u4e86\u8d85\u6d41\u4f53\u7cfb\u7edf\u4e2d\u957f\u7a0b\u5e93\u4ed1\u76f8\u4e92\u4f5c\u7528\u7684\u4e00\u9636\u4fee\u6b63\u7684\u7269\u7406\u8d77\u6e90\u548c\u5927\u5c0f\u3002", "motivation": "\u5728\u4e8c\u7ef4\u8d85\u6d41\u4f53\u7535\u5b50-\u7a7a\u7a74\u53cc\u5c42\u7cfb\u7edf\u4e2d\uff0c\u7531\u4e8e\u7c73\u683c\u8fbe\u5c14\u5b9a\u7406\u4e0d\u9002\u7528\uff0c\u4ea4\u6362\u9876\u70b9\u4fee\u6b63\u4e0d\u80fd\u5ffd\u7565\u3002\u9700\u8981\u53d1\u5c55\u8d85\u8d8aRPA\u7684\u5fae\u6270\u65b9\u6cd5\u6765\u51c6\u786e\u63cf\u8ff0\u8fd9\u79cd\u7cfb\u7edf\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u548c\u5c4f\u853d\u6548\u5e94\u3002", "method": "\u4fee\u6539\u4e86Nozi\u00e8res\u548cSchrieffer\u63d0\u51fa\u7684\u5fae\u6270\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e86\u6b63\u5e38\u548c\u53cd\u5e38\u6781\u5316\u51fd\u6570\u4ee5\u53ca\u5c4f\u853d\u5e93\u4ed1\u76f8\u4e92\u4f5c\u7528\uff0c\u5305\u62ec\u6240\u6709\u4e00\u9636\u4fee\u6b63\u3002\u8bc4\u4f30\u4e86\u8d85\u6d41\u4f53\u72b6\u6001\u4e0b\u5c4f\u853d\u7684\u7535\u5b50-\u7535\u5b50\u3001\u7a7a\u7a74-\u7a7a\u7a74\u548c\u7535\u5b50-\u7a7a\u7a74\u76f8\u4e92\u4f5c\u7528\u968f\u8f7d\u6d41\u5b50\u5bc6\u5ea6\u7684\u53d8\u5316\u3002", "result": "\u5728\u4f4e\u5bc6\u5ea6\u4e0b\uff0c\u6b63\u5e38\u548c\u53cd\u5e38\u5206\u91cf\u4e4b\u95f4\u7684\u5f3a\u62b5\u6d88\u4f7f\u5f97\u76f8\u4e92\u4f5c\u7528\u5c4f\u853d\u53ef\u5ffd\u7565\uff0c\u8fd9\u4e00\u7ed3\u8bba\u4e0d\u4ec5\u9002\u7528\u4e8eRPA\uff0c\u4e5f\u9002\u7528\u4e8e\u5305\u542b\u4e00\u9636\u4fee\u6b63\u7684\u60c5\u51b5\u3002\u968f\u7740\u5bc6\u5ea6\u589e\u52a0\uff0c\u6b63\u5e38-\u53cd\u5e38\u62b5\u6d88\u51cf\u5f31\uff0c\u5c4f\u853d\u53d8\u5f97\u663e\u8457\u3002\u4e00\u9636\u4fee\u6b63\u653e\u5927\u4e86\u6b63\u5e38-\u53cd\u5e38\u5dee\u5f02\uff0c\u4f46\u4ec5\u5728\u5927\u52a8\u91cf\u4ea4\u6362\u65f6\u663e\u8457\uff0c\u5bf9\u76f8\u4e92\u4f5c\u7528\u7684\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u5728\u8d85\u6d41\u4f53\u95f4\u9699\u8fbe\u5230\u6700\u5927\u503c\u7684\u5bc6\u5ea6\u8303\u56f4\u5185\uff0c\u8d85\u6d41\u4f53\u72b6\u6001\u7684RPA\u662f\u63cf\u8ff0\u8be5\u8d85\u6d41\u4f53\u7cfb\u7edf\u4e2d\u5c4f\u853d\u548c\u6709\u6548\u7535\u5b50-\u7a7a\u7a74\u914d\u5bf9\u7684\u6781\u597d\u8fd1\u4f3c\u3002"}}
{"id": "2510.23624", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23624", "abs": "https://arxiv.org/abs/2510.23624", "authors": ["Tiago Mendon\u00e7a dos Santos", "Rafael Izbicki", "Lu\u00eds Gustavo Esteves"], "title": "DiNo and RanBu: Lightweight Predictions from Shallow Random Forests", "comment": null, "summary": "Random Forest ensembles are a strong baseline for tabular prediction tasks,\nbut their reliance on hundreds of deep trees often results in high inference\nlatency and memory demands, limiting deployment in latency-sensitive or\nresource-constrained environments. We introduce DiNo (Distance with Nodes) and\nRanBu (Random Bushes), two shallow-forest methods that convert a small set of\ndepth-limited trees into efficient, distance-weighted predictors. DiNo measures\ncophenetic distances via the most recent common ancestor of observation pairs,\nwhile RanBu applies kernel smoothing to Breiman's classical proximity measure.\nBoth approaches operate entirely after forest training: no additional trees are\ngrown, and tuning of the single bandwidth parameter $h$ requires only\nlightweight matrix-vector operations. Across three synthetic benchmarks and 25\npublic datasets, RanBu matches or exceeds the accuracy of full-depth random\nforests-particularly in high-noise settings-while reducing training plus\ninference time by up to 95\\%. DiNo achieves the best bias-variance trade-off in\nlow-noise regimes at a modest computational cost. Both methods extend directly\nto quantile regression, maintaining accuracy with substantial speed gains. The\nimplementation is available as an open-source R/C++ package at\nhttps://github.com/tiagomendonca/dirf. We focus on structured tabular random\nsamples (i.i.d.), leaving extensions to other modalities for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e86DiNo\u548cRanBu\u4e24\u79cd\u6d45\u5c42\u68ee\u6797\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5c11\u91cf\u6df1\u5ea6\u53d7\u9650\u6811\u8f6c\u6362\u4e3a\u9ad8\u6548\u7684\u8ddd\u79bb\u52a0\u6743\u9884\u6d4b\u5668\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u968f\u673a\u68ee\u6797\u7684\u63a8\u7406\u5ef6\u8fdf\u548c\u5185\u5b58\u9700\u6c42\u3002", "motivation": "\u968f\u673a\u68ee\u6797\u96c6\u6210\u5728\u8868\u683c\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4f9d\u8d56\u6570\u767e\u68f5\u6df1\u5ea6\u6811\u5bfc\u81f4\u9ad8\u63a8\u7406\u5ef6\u8fdf\u548c\u5185\u5b58\u9700\u6c42\uff0c\u9650\u5236\u4e86\u5728\u5ef6\u8fdf\u654f\u611f\u6216\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002", "method": "DiNo\u901a\u8fc7\u89c2\u6d4b\u5bf9\u7684\u6700\u8fdc\u516c\u5171\u7956\u5148\u6d4b\u91cf\u540c\u6e90\u8ddd\u79bb\uff0cRanBu\u5bf9Breiman\u7ecf\u5178\u90bb\u8fd1\u5ea6\u6d4b\u91cf\u5e94\u7528\u6838\u5e73\u6ed1\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u5728\u68ee\u6797\u8bad\u7ec3\u540e\u5b8c\u5168\u64cd\u4f5c\uff0c\u65e0\u9700\u989d\u5916\u751f\u957f\u6811\uff0c\u4ec5\u9700\u8f7b\u91cf\u7ea7\u77e9\u9635\u5411\u91cf\u64cd\u4f5c\u8c03\u6574\u5355\u4e2a\u5e26\u5bbd\u53c2\u6570h\u3002", "result": "\u57283\u4e2a\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c25\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\uff0cRanBu\u5339\u914d\u6216\u8d85\u8fc7\u4e86\u5168\u6df1\u5ea6\u968f\u673a\u68ee\u6797\u7684\u51c6\u786e\u6027\uff08\u7279\u522b\u662f\u5728\u9ad8\u566a\u58f0\u8bbe\u7f6e\u4e2d\uff09\uff0c\u540c\u65f6\u5c06\u8bad\u7ec3\u52a0\u63a8\u7406\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe95%\u3002DiNo\u5728\u4f4e\u566a\u58f0\u673a\u5236\u4e2d\u4ee5\u9002\u5ea6\u7684\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u4e86\u6700\u4f73\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u76f4\u63a5\u6269\u5c55\u5230\u5206\u4f4d\u6570\u56de\u5f52\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u83b7\u5f97\u663e\u8457\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "DiNo\u548cRanBu\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u968f\u673a\u68ee\u6797\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u9650\u5236\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u9ad8\u566a\u58f0\u548c\u4f4e\u566a\u58f0\u573a\u666f\u4e0b\u5404\u6709\u4f18\u52bf\u3002"}}
{"id": "2510.23746", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23746", "abs": "https://arxiv.org/abs/2510.23746", "authors": ["Laura Mismetti", "Marvin Alberts", "Andreas Krause", "Mara Graziani"], "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra", "comment": null, "summary": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d4b\u8bd5\u65f6\u8c03\u4f18\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u9884\u8bad\u7ec3transformer\u6a21\u578b\u7684\u5b66\u4e60\u80fd\u529b\uff0c\u76f4\u63a5\u4ece\u4e32\u8054\u8d28\u8c31\u548c\u5206\u5b50\u5f0f\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u4ece\u5934\u5206\u5b50\u7ed3\u6784\u751f\u6210\uff0c\u65e0\u9700\u624b\u52a8\u6ce8\u91ca\u548c\u4e2d\u95f4\u6b65\u9aa4\uff0c\u5728\u4e24\u4e2a\u6d41\u884c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4e32\u8054\u8d28\u8c31\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6570\u636e\u5e93\u5339\u914d\u6216\u9700\u8981\u4e2d\u95f4\u7247\u6bb5/\u6307\u7eb9\u9884\u6d4b\u7684\u591a\u6b65\u9aa4\u6d41\u7a0b\uff0c\u8fd9\u4f7f\u5f97\u8bc6\u522b\u672a\u77e5\u5316\u5408\u7269\uff08\u7279\u522b\u662f\u53c2\u8003\u6570\u636e\u5e93\u4e2d\u4e0d\u5b58\u5728\u7684\u5316\u5408\u7269\uff09\u6781\u5177\u6311\u6218\u6027\u3002", "method": "\u5229\u7528\u6d4b\u8bd5\u65f6\u8c03\u4f18\u589e\u5f3a\u9884\u8bad\u7ec3transformer\u6a21\u578b\uff0c\u5b9e\u73b0\u76f4\u63a5\u4ece\u4e32\u8054\u8d28\u8c31\u548c\u5206\u5b50\u5f0f\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u4ece\u5934\u5206\u5b50\u7ed3\u6784\u751f\u6210\uff0c\u7ed5\u8fc7\u624b\u52a8\u6ce8\u91ca\u548c\u4e2d\u95f4\u6b65\u9aa4\u3002", "result": "\u5728\u4e24\u4e2a\u6d41\u884c\u57fa\u51c6\u6d4b\u8bd5NPLIB1\u548cMassSpecGym\u4e0a\u5206\u522b\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u65b9\u6cd5DiffMS 100%\u548c20%\uff1b\u6d4b\u8bd5\u65f6\u8c03\u4f18\u5728MassSpecGym\u4e0a\u6bd4\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u6027\u80fd\u63d0\u534762%\uff1b\u5373\u4f7f\u9884\u6d4b\u504f\u79bb\u771f\u5b9e\u503c\uff0c\u751f\u6210\u7684\u5206\u5b50\u5019\u9009\u7ed3\u6784\u4ecd\u7136\u51c6\u786e\uff0c\u4e3a\u4eba\u5de5\u89e3\u91ca\u63d0\u4f9b\u6709\u4ef7\u503c\u6307\u5bfc\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6d4b\u8bd5\u65f6\u8c03\u4f18\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4ece\u5934\u5206\u5b50\u7ed3\u6784\u751f\u6210\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u65b0\u8d28\u8c31\uff0c\u63d0\u4f9b\u53ef\u9760\u7684\u5206\u5b50\u8bc6\u522b\u6307\u5bfc\uff0c\u5728\u4ee3\u8c22\u7ec4\u5b66\u3001\u5929\u7136\u4ea7\u7269\u53d1\u73b0\u548c\u73af\u5883\u5206\u6790\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.23797", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23797", "abs": "https://arxiv.org/abs/2510.23797", "authors": ["Evangelia Takou", "Kenneth R. Brown"], "title": "Estimating and decoding coherent errors of QEC experiments with detector error models", "comment": "9 pages, 7 figures", "summary": "Decoders of quantum error correction (QEC) experiments make decisions based\non detected errors and the expected rates of error events, which together\ncomprise a detector error model. Here we show that the syndrome history of QEC\nexperiments is sufficient to detect and estimate coherent errors, removing the\nneed for prior device benchmarking experiments. Importantly, our method shows\nthat experimentally determined detector error models work equally well for both\nstochastic and coherent noise regimes. We model fully-coherent or\nfully-stochastic noise for repetition and surface codes and for various\nphenomenological and circuit-level noise scenarios, by employing Majorana and\nMonte Carlo simulators. We capture the interference of coherent errors, which\nappears as enhanced or suppressed physical error rates compared to the\nstochastic case, and also observe hyperedges that do not appear in the\ncorresponding Pauli-twirled models. Finally, we decode the detector error\nmodels undergoing coherent noise and find different thresholds compared to\ndetector error models built based on the stochastic noise assumption.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u7ea0\u9519\u5b9e\u9a8c\u7684\u7efc\u5408\u5f81\u5386\u53f2\u6765\u68c0\u6d4b\u548c\u4f30\u8ba1\u76f8\u5e72\u8bef\u5dee\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u5148\u524d\u7684\u8bbe\u5907\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u9a8c\u3002\u7814\u7a76\u8868\u660e\u5b9e\u9a8c\u786e\u5b9a\u7684\u68c0\u6d4b\u5668\u8bef\u5dee\u6a21\u578b\u5728\u968f\u673a\u548c\u76f8\u5e72\u566a\u58f0\u673a\u5236\u4e0b\u540c\u6837\u6709\u6548\uff0c\u5e76\u63ed\u793a\u4e86\u76f8\u5e72\u566a\u58f0\u4e0b\u4e0d\u540c\u7684\u89e3\u7801\u9608\u503c\u3002", "motivation": "\u91cf\u5b50\u7ea0\u9519\u5b9e\u9a8c\u7684\u89e3\u7801\u5668\u901a\u5e38\u57fa\u4e8e\u68c0\u6d4b\u5230\u7684\u9519\u8bef\u548c\u9884\u671f\u9519\u8bef\u7387\u505a\u51fa\u51b3\u7b56\uff0c\u8fd9\u4e9b\u6784\u6210\u4e86\u68c0\u6d4b\u5668\u8bef\u5dee\u6a21\u578b\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5148\u8fdb\u884c\u8bbe\u5907\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f46\u672c\u6587\u65e8\u5728\u8bc1\u660e\u4ec5\u4f7f\u7528\u7efc\u5408\u5f81\u5386\u53f2\u5c31\u8db3\u4ee5\u68c0\u6d4b\u548c\u4f30\u8ba1\u76f8\u5e72\u8bef\u5dee\u3002", "method": "\u91c7\u7528Majorana\u548cMonte Carlo\u6a21\u62df\u5668\uff0c\u5bf9\u91cd\u590d\u7801\u548c\u8868\u9762\u7801\u8fdb\u884c\u5efa\u6a21\uff0c\u8003\u8651\u5b8c\u5168\u76f8\u5e72\u6216\u5b8c\u5168\u968f\u673a\u566a\u58f0\uff0c\u4ee5\u53ca\u5404\u79cd\u552f\u8c61\u548c\u7535\u8def\u7ea7\u566a\u58f0\u573a\u666f\u3002\u901a\u8fc7\u6355\u83b7\u76f8\u5e72\u8bef\u5dee\u7684\u5e72\u6d89\u6548\u5e94\uff0c\u89c2\u5bdf\u5230\u4e0e\u968f\u673a\u60c5\u51b5\u76f8\u6bd4\u589e\u5f3a\u6216\u6291\u5236\u7684\u7269\u7406\u9519\u8bef\u7387\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b9e\u9a8c\u786e\u5b9a\u7684\u68c0\u6d4b\u5668\u8bef\u5dee\u6a21\u578b\u5728\u968f\u673a\u548c\u76f8\u5e72\u566a\u58f0\u673a\u5236\u4e0b\u540c\u6837\u6709\u6548\u3002\u89c2\u5bdf\u5230\u5728\u76f8\u5e94Pauli-twirl\u6a21\u578b\u4e2d\u4e0d\u51fa\u73b0\u7684\u8d85\u8fb9\uff0c\u5e76\u53d1\u73b0\u76f8\u5e72\u566a\u58f0\u4e0b\u7684\u89e3\u7801\u9608\u503c\u4e0e\u57fa\u4e8e\u968f\u673a\u566a\u58f0\u5047\u8bbe\u6784\u5efa\u7684\u68c0\u6d4b\u5668\u8bef\u5dee\u6a21\u578b\u4e0d\u540c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u4ec5\u4f7f\u7528\u91cf\u5b50\u7ea0\u9519\u5b9e\u9a8c\u7684\u7efc\u5408\u5f81\u5386\u53f2\u5c31\u8db3\u4ee5\u68c0\u6d4b\u548c\u4f30\u8ba1\u76f8\u5e72\u8bef\u5dee\uff0c\u6d88\u9664\u4e86\u5bf9\u5148\u9a8c\u8bbe\u5907\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u9a8c\u7684\u9700\u6c42\uff0c\u4e3a\u91cf\u5b50\u7ea0\u9519\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u51c6\u786e\u7684\u8bef\u5dee\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2510.24521", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.24521", "abs": "https://arxiv.org/abs/2510.24521", "authors": ["Nicolas Nessi", "Peter Reimann"], "title": "Dynamical typicality in classical lattice systems", "comment": "7 pages, 2 figures", "summary": "Considering deterministic classical lattice systems with continuous\nvariables, we show that, if the initial conditions are sampled according to a\nprobability distribution in which the dynamical variables are statistically\nindependent, the dynamical trajectory of any macroscopic observable is\napproximately the same for the vast majority of the states in the sample. Our\nproof relies on general concentration of measure results which provide tight\nbounds for the deviation from typical behavior in the case of large system\nsizes. The only condition that we assume for the dynamics is that the influence\nof a local perturbation in the initial state decays sufficiently fast with\ndistance at any finite time. Our results are relevant, in particular, to\nclassical Hamiltonian systems on a lattice. We apply our general results to a\nsystem of coupled rotors with long-range interactions, and report dynamical\nsimulations which verify our findings.", "AI": {"tldr": "\u5bf9\u4e8e\u5177\u6709\u8fde\u7eed\u53d8\u91cf\u7684\u786e\u5b9a\u6027\u7ecf\u5178\u6676\u683c\u7cfb\u7edf\uff0c\u7814\u7a76\u8868\u660e\u5f53\u521d\u59cb\u6761\u4ef6\u6309\u7edf\u8ba1\u72ec\u7acb\u5206\u5e03\u91c7\u6837\u65f6\uff0c\u7edd\u5927\u591a\u6570\u72b6\u6001\u7684\u5b8f\u89c2\u53ef\u89c2\u6d4b\u91cf\u8f68\u8ff9\u51e0\u4e4e\u76f8\u540c\uff0c\u524d\u63d0\u662f\u5c40\u90e8\u6270\u52a8\u7684\u5f71\u54cd\u968f\u8ddd\u79bb\u5feb\u901f\u8870\u51cf\u3002", "motivation": "\u7814\u7a76\u786e\u5b9a\u6027\u7ecf\u5178\u6676\u683c\u7cfb\u7edf\u4e2d\u5b8f\u89c2\u89c2\u6d4b\u91cf\u7684\u5178\u578b\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u5927\u7cfb\u7edf\u89c4\u6a21\u4e0b\uff0c\u9a8c\u8bc1\u7edf\u8ba1\u72ec\u7acb\u521d\u59cb\u6761\u4ef6\u4e0b\u52a8\u529b\u5b66\u8f68\u8ff9\u7684\u4e00\u81f4\u6027\u3002", "method": "\u5229\u7528\u6d4b\u5ea6\u96c6\u4e2d\u7406\u8bba\u63d0\u4f9b\u5927\u7cfb\u7edf\u89c4\u6a21\u4e0b\u504f\u79bb\u5178\u578b\u884c\u4e3a\u7684\u4e25\u683c\u754c\u9650\uff0c\u5047\u8bbe\u52a8\u529b\u5b66\u4e2d\u5c40\u90e8\u6270\u52a8\u7684\u5f71\u54cd\u968f\u8ddd\u79bb\u5feb\u901f\u8870\u51cf\u3002", "result": "\u8bc1\u660e\u5728\u7edf\u8ba1\u72ec\u7acb\u521d\u59cb\u6761\u4ef6\u4e0b\uff0c\u7edd\u5927\u591a\u6570\u72b6\u6001\u7684\u5b8f\u89c2\u53ef\u89c2\u6d4b\u91cf\u8f68\u8ff9\u8fd1\u4f3c\u76f8\u540c\uff0c\u5e76\u901a\u8fc7\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\u8026\u5408\u8f6c\u5b50\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u6a21\u62df\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u786e\u5b9a\u6027\u7ecf\u5178\u6676\u683c\u7cfb\u7edf\u4e2d\uff0c\u5728\u7edf\u8ba1\u72ec\u7acb\u521d\u59cb\u6761\u4ef6\u548c\u5c40\u90e8\u6270\u52a8\u5feb\u901f\u8870\u51cf\u7684\u5047\u8bbe\u4e0b\uff0c\u5b8f\u89c2\u89c2\u6d4b\u91cf\u7684\u52a8\u529b\u5b66\u8f68\u8ff9\u5bf9\u7edd\u5927\u591a\u6570\u72b6\u6001\u662f\u5178\u578b\u7684\u3002"}}
{"id": "2510.23778", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.23778", "abs": "https://arxiv.org/abs/2510.23778", "authors": ["H. Hodovanets", "H. Kim", "T. Metz", "Y. Nakajima", "C. J. Eckberg", "K. Wang", "J. Yong", "S. R. Saha", "J. Higgins", "D. Graf", "N. Butch", "T. Vojta", "J. Paglione"], "title": "Magnetic field-tuned magnetic order and metamagnetic criticality in non-stoichiometric CeAuBi$_2$", "comment": null, "summary": "We present a detailed study of magnetization, resistivity, heat capacity, and\nX-ray and neutron powder diffraction measurements performed on single crystals\nof non-stoichiometric CeAuBi$_2$, Au deficiency 18$\\%$, a strongly correlated\nantiferromagnet with N\\'eel temperature T$_N$ = 13.2 K. Field-dependent\nmagnetization measurements reveal a large magnetic anisotropy at low\ntemperatures with an easy axis along the crystallographic c-axis, in which\ndirection a spin-flop transition exhibits strong features in magnetization,\nspecific heat, and resistivity at H$_c$ = 75 kOe. The constructed\ntemperature-field phase diagram connects this transition to the suppression of\nmagnetic order, which evolves from a second-order nature into a first-order\ntransition that bifurcates at the spin-flop into three transitions below 1 K.\nThe smoothed nature of the metamagnetic transitions in non-stoichiometric\nCeAuBi$_2$ is well described by an Ising model with weak quenched disorder,\nsuggesting that the presence of Au vacancies is sufficient to smear the complex\nmetamagnetic behavior and tune the critical behavior of magnetic order.", "AI": {"tldr": "\u5bf9\u975e\u5316\u5b66\u8ba1\u91cf\u6bd4CeAuBi2\uff08Au\u7f3a\u967718%\uff09\u5355\u6676\u7684\u78c1\u6027\u3001\u7535\u963b\u7387\u3001\u70ed\u5bb9\u3001X\u5c04\u7ebf\u548c\u4e2d\u5b50\u7c89\u672b\u884d\u5c04\u7814\u7a76\uff0c\u53d1\u73b0\u5176\u4e3a\u5f3a\u5173\u8054\u53cd\u94c1\u78c1\u4f53\uff0c\u5948\u5c14\u6e29\u5ea613.2K\uff0c\u5177\u6709\u6cbfc\u8f74\u7684\u5f3a\u78c1\u5404\u5411\u5f02\u6027\u548c75kOe\u7684spin-flop\u8f6c\u53d8\u3002", "motivation": "\u7814\u7a76\u975e\u5316\u5b66\u8ba1\u91cf\u6bd4CeAuBi2\u4e2dAu\u7a7a\u4f4d\u5bf9\u5f3a\u5173\u8054\u53cd\u94c1\u78c1\u4f53\u78c1\u6027\u548c\u4e34\u754c\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u78c1\u5316\u3001\u7535\u963b\u7387\u3001\u70ed\u5bb9\u3001X\u5c04\u7ebf\u548c\u4e2d\u5b50\u7c89\u672b\u884d\u5c04\u6d4b\u91cf\uff0c\u7ed3\u5408Ising\u6a21\u578b\u5206\u6790\u3002", "result": "\u6784\u5efa\u4e86\u6e29\u5ea6-\u78c1\u573a\u76f8\u56fe\uff0c\u53d1\u73b0spin-flop\u8f6c\u53d8\u5c06\u78c1\u6709\u5e8f\u6291\u5236\u4ece\u4e8c\u9636\u8f6c\u53d8\u4e3a\u4e09\u53c9\u7684\u4e00\u9636\u8f6c\u53d8\uff0cAu\u7a7a\u4f4d\u5bfc\u81f4\u78c1\u8f6c\u53d8\u5e73\u6ed1\u5316\u3002", "conclusion": "Au\u7a7a\u4f4d\u8db3\u4ee5\u5e73\u6ed1\u590d\u6742\u7684\u78c1\u884c\u4e3a\u5e76\u8c03\u63a7\u78c1\u6709\u5e8f\u7684\u4e34\u754c\u884c\u4e3a\uff0c\u53ef\u7528\u5f31\u6dec\u706b\u65e0\u5e8f\u7684Ising\u6a21\u578b\u63cf\u8ff0\u3002"}}
{"id": "2510.23626", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23626", "abs": "https://arxiv.org/abs/2510.23626", "authors": ["Shuang Geng", "Wenli Zhang", "Jiaheng Xie", "Rui Wang", "Sudha Ram"], "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media", "comment": "Presented at SWAIB2025 and HICSS2026", "summary": "Social media user-generated content (UGC) provides real-time, self-reported\nindicators of mental health conditions such as depression, offering a valuable\nsource for predictive analytics. While prior studies integrate medical\nknowledge to improve prediction accuracy, they overlook the opportunity to\nsimultaneously expand such knowledge through predictive processes. We develop a\nClosed-Loop Large Language Model (LLM)-Knowledge Graph framework that\nintegrates prediction and knowledge expansion in an iterative learning cycle.\nIn the knowledge-aware depression detection phase, the LLM jointly performs\ndepression detection and entity extraction, while the knowledge graph\nrepresents and weights these entities to refine prediction performance. In the\nknowledge refinement and expansion phase, new entities, relationships, and\nentity types extracted by the LLM are incorporated into the knowledge graph\nunder expert supervision, enabling continual knowledge evolution. Using\nlarge-scale UGC, the framework enhances both predictive accuracy and medical\nunderstanding. Expert evaluations confirmed the discovery of clinically\nmeaningful symptoms, comorbidities, and social triggers complementary to\nexisting literature. We conceptualize and operationalize\nprediction-through-learning and learning-through-prediction as mutually\nreinforcing processes, advancing both methodological and theoretical\nunderstanding in predictive analytics. The framework demonstrates the\nco-evolution of computational models and domain knowledge, offering a\nfoundation for adaptive, data-driven knowledge systems applicable to other\ndynamic risk monitoring contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u95ed\u73afLLM-\u77e5\u8bc6\u56fe\u8c31\u6846\u67b6\uff0c\u5c06\u6291\u90c1\u75c7\u68c0\u6d4b\u4e0e\u77e5\u8bc6\u6269\u5c55\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u8fed\u4ee3\u5b66\u4e60\u5faa\u73af\u5b9e\u73b0\u9884\u6d4b\u51c6\u786e\u6027\u548c\u533b\u5b66\u77e5\u8bc6\u7684\u5171\u540c\u8fdb\u5316\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u867d\u7136\u6574\u5408\u533b\u5b66\u77e5\u8bc6\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u901a\u8fc7\u9884\u6d4b\u8fc7\u7a0b\u540c\u65f6\u6269\u5c55\u77e5\u8bc6\u7684\u673a\u4f1a\u3002\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u751f\u6210\u5185\u5bb9\u4e3a\u5fc3\u7406\u5065\u5eb7\u9884\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u65f6\u6570\u636e\u6e90\u3002", "method": "\u5f00\u53d1\u95ed\u73afLLM-\u77e5\u8bc6\u56fe\u8c31\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u77e5\u8bc6\u611f\u77e5\u7684\u6291\u90c1\u75c7\u68c0\u6d4b\u9636\u6bb5\uff08LLM\u8054\u5408\u6267\u884c\u6291\u90c1\u75c7\u68c0\u6d4b\u548c\u5b9e\u4f53\u63d0\u53d6\uff0c\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u548c\u52a0\u6743\u5b9e\u4f53\uff09\uff0c\u4ee5\u53ca\u77e5\u8bc6\u7cbe\u70bc\u548c\u6269\u5c55\u9636\u6bb5\uff08\u5728\u4e13\u5bb6\u76d1\u7763\u4e0b\u5c06\u65b0\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u5b9e\u4f53\u7c7b\u578b\u7eb3\u5165\u77e5\u8bc6\u56fe\u8c31\uff09\u3002", "result": "\u4f7f\u7528\u5927\u89c4\u6a21\u7528\u6237\u751f\u6210\u5185\u5bb9\uff0c\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u589e\u5f3a\u4e86\u533b\u5b66\u7406\u89e3\u3002\u4e13\u5bb6\u8bc4\u4f30\u786e\u8ba4\u53d1\u73b0\u4e86\u4e0e\u73b0\u6709\u6587\u732e\u4e92\u8865\u7684\u4e34\u5e8a\u6709\u610f\u4e49\u75c7\u72b6\u3001\u5171\u75c5\u548c\u793e\u4f1a\u89e6\u53d1\u56e0\u7d20\u3002", "conclusion": "\u6982\u5ff5\u5316\u548c\u64cd\u4f5c\u5316\u4e86\u9884\u6d4b-\u5b66\u4e60\u548c\u5b66\u4e60-\u9884\u6d4b\u4f5c\u4e3a\u76f8\u4e92\u5f3a\u5316\u7684\u8fc7\u7a0b\uff0c\u63a8\u8fdb\u4e86\u9884\u6d4b\u5206\u6790\u7684\u65b9\u6cd5\u8bba\u548c\u7406\u8bba\u7406\u89e3\u3002\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u8ba1\u7b97\u6a21\u578b\u548c\u9886\u57df\u77e5\u8bc6\u7684\u5171\u540c\u8fdb\u5316\uff0c\u4e3a\u5176\u4ed6\u52a8\u6001\u98ce\u9669\u76d1\u6d4b\u73af\u5883\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u3001\u6570\u636e\u9a71\u52a8\u7684\u77e5\u8bc6\u7cfb\u7edf\u57fa\u7840\u3002"}}
{"id": "2510.23772", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23772", "abs": "https://arxiv.org/abs/2510.23772", "authors": ["Vivek Veeriah", "Federico Barbero", "Marcus Chiam", "Xidong Feng", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Johan Obando-Ceron", "Jiaxin Shi", "Shaobo Hou", "Satinder Singh", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions", "comment": "Accepted at the Creative AI Track, NeurIPS 2025", "summary": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u8c61\u68cb\u8c1c\u9898\u9886\u57df\u7684\u521b\u9020\u529b\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u751f\u6210\u5177\u6709\u7f8e\u5b66\u5438\u5f15\u529b\u3001\u65b0\u9896\u6027\u3001\u53cd\u76f4\u89c9\u548c\u72ec\u7279\u89e3\u6cd5\u7684\u8c61\u68cb\u8c1c\u9898AI\u7cfb\u7edf\uff0c\u5e76\u9080\u8bf7\u4e09\u4f4d\u56fd\u9645\u8c61\u68cb\u4e13\u5bb6\u8bc4\u4f30\u5176\u521b\u610f\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7814\u7a76\u5176\u80fd\u5426\u4ea7\u751f\u771f\u6b63\u521b\u610f\u548c\u65b0\u9896\u8f93\u51fa\u6210\u4e3a\u91cd\u8981\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1AI\u5728\u8c61\u68cb\u8c1c\u9898\u521b\u4f5c\u9886\u57df\u7684\u521b\u9020\u529b\u3002", "method": "\u5f00\u53d1\u4e13\u95e8\u7684AI\u7cfb\u7edf\u751f\u6210\u8c61\u68cb\u8c1c\u9898\uff0c\u7136\u540e\u9080\u8bf7\u4e09\u4f4d\u4e16\u754c\u77e5\u540d\u8c61\u68cb\u4e13\u5bb6\uff08\u56fd\u9645\u8c61\u68cb\u7f16\u6392\u5927\u5e08Amatzia Avni\u3001\u7279\u7ea7\u5927\u5e08Jonathan Levitt\u548cMatthew Sadler\uff09\u8bc4\u4f30\u7cfb\u7edf\u751f\u6210\u7684\u8c1c\u9898\uff0c\u57fa\u4e8e\u521b\u610f\u6027\u3001\u6311\u6218\u6027\u548c\u7f8e\u5b66\u8bbe\u8ba1\u7b49\u6807\u51c6\u8bc4\u9009\u6700\u4f73\u4f5c\u54c1\u3002", "result": "\u4e09\u4f4d\u4e13\u5bb6\u5bf9AI\u751f\u6210\u7684\u8c61\u68cb\u8c1c\u9898\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u9009\u51fa\u4e86\u5404\u81ea\u6700\u559c\u6b22\u7684\u8c1c\u9898\uff0c\u5e76\u89e3\u91ca\u4e86\u8fd9\u4e9b\u8c1c\u9898\u5728\u521b\u610f\u6027\u3001\u6311\u6218\u6c34\u5e73\u6216\u7f8e\u5b66\u8bbe\u8ba1\u65b9\u9762\u7684\u5438\u5f15\u529b\u3002", "conclusion": "\u7814\u7a76\u8868\u660eAI\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u5177\u6709\u7f8e\u5b66\u4ef7\u503c\u548c\u521b\u610f\u6027\u7684\u8c61\u68cb\u8c1c\u9898\uff0c\u4e13\u5bb6\u8bc4\u4f30\u9a8c\u8bc1\u4e86AI\u5728\u7279\u5b9a\u9886\u57df\u5c55\u73b0\u521b\u9020\u529b\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.23815", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23815", "abs": "https://arxiv.org/abs/2510.23815", "authors": ["Iagoba Apellaniz", "Manuel Gessner", "G\u00e9za T\u00f3th"], "title": "Differential magnetometry with partially flipped Dicke states", "comment": "15 page, 2 figures, revtex 4.2", "summary": "We study magnetometry of gradients and homogeneous background fields along\nall three spatial axes using two spatially separated spin ensembles. We derive\ntrade-off relations for the achievable estimation precision of these\nparameters. Dicke states, optimal for homogeneous field estimation, can be\nlocally rotated into states sensitive to magnetic gradients by rotating the\nspins in one subensemble. We determine bounds for the precision for gradient\nmetrology in the three orthogonal directions as a function of the sensitivities\nof the homogenous field in those directions. The resulting partially flipped\nDicke state saturates the bounds above, showing similar sensitivity in two\ndirections but significantly reduced sensitivity in the third. Exploiting\nentanglement between the two ensembles, this state achieves roughly twice the\nprecision attainable by the best bipartite separable state, which is a product\nof local Dicke states. For small ensembles, we explicitly identify measurement\noperators saturating the quantum Cram\\'er-Rao bound, while for larger\nensembles, we propose simpler but suboptimal schemes. In both cases, the\ngradient is estimated from second moments and correlations of angular momentum\noperators. Our results demonstrate how the metrological properties of Dicke\nstates can be exploited for quantum-enhanced multiparameter estimation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4f7f\u7528\u4e24\u4e2a\u7a7a\u95f4\u5206\u79bb\u7684\u81ea\u65cb\u7cfb\u7efc\u8fdb\u884c\u78c1\u573a\u68af\u5ea6\u548c\u5747\u5300\u80cc\u666f\u573a\u7684\u78c1\u529b\u6d4b\u91cf\uff0c\u63a8\u5bfc\u4e86\u8fd9\u4e9b\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528Dicke\u6001\u901a\u8fc7\u5c40\u90e8\u65cb\u8f6c\u5b9e\u73b0\u68af\u5ea6\u6d4b\u91cf\u7684\u91cf\u5b50\u589e\u5f3a\u3002", "motivation": "\u7814\u7a76\u78c1\u573a\u68af\u5ea6\u548c\u5747\u5300\u80cc\u666f\u573a\u7684\u591a\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\uff0c\u63a2\u7d22\u5982\u4f55\u5229\u7528\u91cf\u5b50\u7ea0\u7f20\u72b6\u6001\uff08\u5982Dicke\u6001\uff09\u6765\u8d85\u8d8a\u7ecf\u5178\u6d4b\u91cf\u6781\u9650\uff0c\u5b9e\u73b0\u91cf\u5b50\u589e\u5f3a\u7684\u78c1\u529b\u6d4b\u91cf\u3002", "method": "\u901a\u8fc7\u5c06Dicke\u6001\u5728\u5176\u4e2d\u4e00\u4e2a\u5b50\u7cfb\u7efc\u4e2d\u5c40\u90e8\u65cb\u8f6c\uff0c\u6784\u9020\u5bf9\u78c1\u573a\u68af\u5ea6\u654f\u611f\u7684\u72b6\u6001\uff1b\u4f7f\u7528\u91cf\u5b50Cram\u00e9r-Rao\u754c\u5206\u6790\u4f30\u8ba1\u7cbe\u5ea6\uff1b\u5bf9\u4e8e\u5c0f\u7cfb\u7efc\u8bc6\u522b\u6700\u4f18\u6d4b\u91cf\u7b97\u7b26\uff0c\u5bf9\u4e8e\u5927\u7cfb\u7efc\u63d0\u51fa\u7b80\u5316\u4f46\u6b21\u4f18\u7684\u65b9\u6848\uff1b\u901a\u8fc7\u89d2\u52a8\u91cf\u7b97\u7b26\u7684\u4e8c\u9636\u77e9\u548c\u76f8\u5173\u6027\u4f30\u8ba1\u68af\u5ea6\u3002", "result": "\u90e8\u5206\u7ffb\u8f6c\u7684Dicke\u6001\u5728\u4e24\u4e2a\u65b9\u5411\u4e0a\u5177\u6709\u76f8\u4f3c\u7684\u7075\u654f\u5ea6\uff0c\u4f46\u5728\u7b2c\u4e09\u4e2a\u65b9\u5411\u4e0a\u7075\u654f\u5ea6\u663e\u8457\u964d\u4f4e\uff1b\u5229\u7528\u4e24\u4e2a\u7cfb\u7efc\u4e4b\u95f4\u7684\u7ea0\u7f20\uff0c\u8be5\u72b6\u6001\u8fbe\u5230\u7684\u7cbe\u5ea6\u5927\u7ea6\u662f\u6700\u597d\u4e8c\u5206\u53ef\u5206\u79bb\u6001\uff08\u5c40\u90e8Dicke\u6001\u4e58\u79ef\uff09\u7684\u4e24\u500d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528Dicke\u6001\u7684\u8ba1\u91cf\u7279\u6027\u5b9e\u73b0\u91cf\u5b50\u589e\u5f3a\u7684\u591a\u53c2\u6570\u4f30\u8ba1\uff0c\u4e3a\u78c1\u573a\u68af\u5ea6\u6d4b\u91cf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u91cf\u5b50\u8ba1\u91cf\u65b9\u6848\u3002"}}
{"id": "2510.24630", "categories": ["cond-mat.stat-mech", "cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24630", "abs": "https://arxiv.org/abs/2510.24630", "authors": ["Pitambar Bagui", "Arijit Chatterjee", "Bijay Kumar Agarwalla"], "title": "Accelerated relaxation and Mpemba-like effect for operators in open quantum systems", "comment": "11 pages, 5 figures", "summary": "Quantum Mpemba effect occurs when a quantum system, residing far away from\nthe steady state, relaxes faster than a relatively nearer state. We look for\nthe presence of this highly counterintuitive effect in the relaxation dynamics\nof the operators within the open quantum system setting. Since the operators\nevolve under a non-trace preserving map, the trace distance of an operator is\nnot a monotonically decaying function of time, unlike its quantum state\ncounterpart. Consequently, the trace distance can not serve as a reliable\nmeasure for detecting the Mpemba effect in operator dynamics. We circumvent\nthis problem by defining a \\textit{dressed} distance between operators that\ndecays monotonically with time, enabling a generalized framework to explore the\nMpemba-like effect for operators. Applying the formalism to various open\nquantum system settings, we find that, interestingly, in the single qubit case,\nonly accelerated relaxation of operators is possible, while genuine Mpemba-like\neffects emerge in higher-dimensional systems such as qutrits and beyond.\nFurthermore, we demonstrate the existence of Mpemba-like effects in nonlocal,\nnon-equilibrium operators, such as current, in a double-quantum-dot setup. Our\nresults, besides offering fundamental insight about the occurrence of the\nMpemba-like effect under non-trace preserving dynamics, open avenues for new\nexperimental studies where quicker relaxation of observables could be of\nsignificant interest.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7b97\u5b50\u7684\u91cf\u5b50Mpemba\u6548\u5e94\uff0c\u63d0\u51fa\u4e86\u5355\u8c03\u8870\u51cf\u7684\"\u4fee\u9970\"\u8ddd\u79bb\u6765\u68c0\u6d4b\u7b97\u5b50\u52a8\u529b\u5b66\u4e2d\u7684Mpemba\u7c7b\u6548\u5e94\uff0c\u53d1\u73b0\u5728\u5355\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\u53ea\u80fd\u5b9e\u73b0\u52a0\u901f\u5f1b\u8c6b\uff0c\u800c\u5728\u9ad8\u7ef4\u7cfb\u7edf\u4e2d\u4f1a\u51fa\u73b0\u771f\u6b63\u7684Mpemba\u7c7b\u6548\u5e94\u3002", "motivation": "\u7531\u4e8e\u7b97\u5b50\u5728\u975e\u4fdd\u8ff9\u6620\u5c04\u4e0b\u6f14\u5316\uff0c\u8ff9\u8ddd\u79bb\u4e0d\u518d\u662f\u5355\u8c03\u8870\u51cf\u51fd\u6570\uff0c\u65e0\u6cd5\u53ef\u9760\u68c0\u6d4b\u7b97\u5b50\u52a8\u529b\u5b66\u4e2d\u7684Mpemba\u6548\u5e94\uff0c\u9700\u8981\u5bfb\u627e\u65b0\u7684\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u5b9a\u4e49\u4e86\u5355\u8c03\u8870\u51cf\u7684\"\u4fee\u9970\"\u7b97\u5b50\u8ddd\u79bb\uff0c\u5efa\u7acb\u4e86\u68c0\u6d4b\u7b97\u5b50Mpemba\u7c7b\u6548\u5e94\u7684\u901a\u7528\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5404\u79cd\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u8bbe\u7f6e\u3002", "result": "\u5728\u5355\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\u53ea\u80fd\u5b9e\u73b0\u52a0\u901f\u5f1b\u8c6b\uff0c\u800c\u5728qutrit\u7b49\u9ad8\u7ef4\u7cfb\u7edf\u4e2d\u4f1a\u51fa\u73b0\u771f\u6b63\u7684Mpemba\u7c7b\u6548\u5e94\uff1b\u5728\u53cc\u91cf\u5b50\u70b9\u8bbe\u7f6e\u4e2d\uff0c\u975e\u5c40\u57df\u975e\u5e73\u8861\u7b97\u5b50\uff08\u5982\u7535\u6d41\uff09\u4e5f\u5b58\u5728Mpemba\u7c7b\u6548\u5e94\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u7406\u89e3\u975e\u4fdd\u8ff9\u52a8\u529b\u5b66\u4e0bMpemba\u7c7b\u6548\u5e94\u7684\u51fa\u73b0\u63d0\u4f9b\u4e86\u57fa\u672c\u89c1\u89e3\uff0c\u8fd8\u4e3a\u5b9e\u9a8c\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5176\u4e2d\u89c2\u6d4b\u91cf\u7684\u5feb\u901f\u5f1b\u8c6b\u53ef\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.24277", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.24277", "abs": "https://arxiv.org/abs/2510.24277", "authors": ["Goro Nozue", "Hidenori Fujiwara", "Satoru Hamamoto", "Miwa Tsutsumi", "Akane Ose", "Takayuki Kiss", "Atsushi Higashiya", "Atsushi Yamasaki", "Yuina Kanai-Nakata", "Shin Imada", "Masaki Oura", "Kenji Tamasaku", "Makina Yabashi", "Tetsuya Ishikawa", "Farid Labib", "Shintaro Suzuki", "Ryuji Tamura", "Akira Sekiyama"], "title": "Soft and hard x-ray orbital-resolved photoemission study of a strongly correlated Cd-Ce quasicrystal approximant", "comment": "8 pages, 5 figures", "summary": "We have investigated the orbital-dependent electronic states of Cd6Ce, a\nprototype of strongly correlated rare-earth-based Tsai-type quasicrystals and\napproximants (ACs) by soft and hard x-ray photoemission spectroscopy. Our\nresults reveal that the 4f orbitals are predominantly hybridized with the\nvalence-band electrons far from the Fermi level EF, in sharp contrast to the\nhybridization with conduction electrons at EF seen for the intermetallic\nCe-based compounds. This anomalous hybridization effect is likely responsible\nfor the unresolved magnetic ground state in Cd6Ce. These findings suggest that\nCd-based ACs, some of which show the multi-step magnetic transitions, provide a\nnew platform for investigating exotic magnetic properties that cannot be\nunderstood within the conventional framework of hybridization at EF.", "AI": {"tldr": "\u901a\u8fc7\u8f6f\u786cX\u5c04\u7ebf\u5149\u7535\u5b50\u80fd\u8c31\u7814\u7a76Cd6Ce\u7684\u8f68\u9053\u4f9d\u8d56\u7535\u5b50\u6001\uff0c\u53d1\u73b04f\u8f68\u9053\u4e3b\u8981\u4e0e\u8fdc\u79bb\u8d39\u7c73\u80fd\u7ea7\u7684\u4ef7\u5e26\u7535\u5b50\u6742\u5316\uff0c\u8fd9\u4e0e\u4f20\u7edfCe\u57fa\u91d1\u5c5e\u95f4\u5316\u5408\u7269\u5728\u8d39\u7c73\u80fd\u7ea7\u7684\u6742\u5316\u884c\u4e3a\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff0c\u53ef\u80fd\u89e3\u91ca\u4e86Cd6Ce\u672a\u89e3\u51b3\u7684\u78c1\u6027\u57fa\u6001\u3002", "motivation": "\u7814\u7a76\u5f3a\u5173\u8054\u7a00\u571f\u57faTsai\u578b\u51c6\u6676\u53ca\u5176\u8fd1\u4f3c\u6676\u4f53\u4e2d\u7684\u8f68\u9053\u4f9d\u8d56\u7535\u5b50\u6001\uff0c\u7279\u522b\u662fCd6Ce\u4e2d\u5f02\u5e38\u7684\u6742\u5316\u884c\u4e3a\u53ca\u5176\u5bf9\u78c1\u6027\u6027\u8d28\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u8f6fX\u5c04\u7ebf\u548c\u786cX\u5c04\u7ebf\u5149\u7535\u5b50\u80fd\u8c31\u6280\u672f\u7814\u7a76Cd6Ce\u7684\u7535\u5b50\u7ed3\u6784\u3002", "result": "\u53d1\u73b04f\u8f68\u9053\u4e3b\u8981\u4e0e\u8fdc\u79bb\u8d39\u7c73\u80fd\u7ea7\u7684\u4ef7\u5e26\u7535\u5b50\u6742\u5316\uff0c\u800c\u975e\u4f20\u7edfCe\u57fa\u5316\u5408\u7269\u4e2d\u5728\u8d39\u7c73\u80fd\u7ea7\u4e0e\u5bfc\u5e26\u7535\u5b50\u7684\u6742\u5316\uff0c\u8fd9\u79cd\u5f02\u5e38\u6742\u5316\u53ef\u80fd\u5bfc\u81f4\u4e86Cd6Ce\u672a\u89e3\u51b3\u7684\u78c1\u6027\u57fa\u6001\u3002", "conclusion": "Cd\u57fa\u8fd1\u4f3c\u6676\u4f53\u4e3a\u7814\u7a76\u4f20\u7edf\u8d39\u7c73\u80fd\u7ea7\u6742\u5316\u6846\u67b6\u65e0\u6cd5\u89e3\u91ca\u7684\u5947\u5f02\u78c1\u6027\u6027\u8d28\u63d0\u4f9b\u4e86\u65b0\u5e73\u53f0\uff0c\u5176\u4e2d\u4e00\u4e9b\u4f53\u7cfb\u8868\u73b0\u51fa\u591a\u6b65\u78c1\u8f6c\u53d8\u3002"}}
{"id": "2510.23629", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.23629", "abs": "https://arxiv.org/abs/2510.23629", "authors": ["Nuo Chen", "Zehua Li", "Keqin Bao", "Junyang Lin", "Dayiheng Liu"], "title": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models", "comment": null, "summary": "Building robust and general reasoning ability is a central goal in the\ndevelopment of large language models (LLMs). Recent efforts increasingly turn\nto code as a rich training source, given its inherent logical structure and\ndiverse reasoning paradigms such as divide-and-conquer, topological ordering,\nand enumeration. However, reasoning in code is often expressed implicitly and\nentangled with syntactic or implementation noise, making direct training on raw\ncode suboptimal.To address this, we introduce TracePile, a large-scale corpus\nof 2.6 million samples that transforms code execution into explicit,\nstep-by-step chain-of-thought-style rationales, which we call Chain of\nExecution (CoE). The corpus spans domains including mathematics, classical\nalgorithms and algorithmic competition, and is enriched with variable-tracing\nquestions and code rewritings to enhance logical granularity and code\ndiversity. We evaluate TracePile using three training setups:\ncontinue-pretraining, instruction tuning after pretraining, and two-stage\nfinetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,\nand Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and\nalgorithms demonstrate consistent improvements. Notably, TracePile boosts\nLLaMA3.1-8B by 7.1\\% on average across nine math datasets and delivers clear\ngains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.", "AI": {"tldr": "TracePile\u662f\u4e00\u4e2a\u5305\u542b260\u4e07\u6837\u672c\u7684\u5927\u89c4\u6a21\u8bed\u6599\u5e93\uff0c\u5c06\u4ee3\u7801\u6267\u884c\u8f6c\u5316\u4e3a\u663e\u5f0f\u7684\u9010\u6b65\u63a8\u7406\u94fe\uff08CoE\uff09\uff0c\u7528\u4e8e\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4ee3\u7801\u867d\u7136\u5305\u542b\u4e30\u5bcc\u7684\u903b\u8f91\u7ed3\u6784\u548c\u63a8\u7406\u8303\u5f0f\uff0c\u4f46\u5176\u4e2d\u7684\u63a8\u7406\u5f80\u5f80\u662f\u9690\u5f0f\u7684\uff0c\u5e76\u4e0e\u8bed\u6cd5\u6216\u5b9e\u73b0\u566a\u58f0\u7ea0\u7f20\uff0c\u4f7f\u5f97\u76f4\u63a5\u5728\u539f\u59cb\u4ee3\u7801\u4e0a\u8bad\u7ec3\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u6784\u5efaTracePile\u8bed\u6599\u5e93\uff0c\u5c06\u4ee3\u7801\u6267\u884c\u8f6c\u5316\u4e3a\u663e\u5f0f\u7684\u9010\u6b65\u63a8\u7406\u94fe\uff08Chain of Execution\uff09\uff0c\u6db5\u76d6\u6570\u5b66\u3001\u7ecf\u5178\u7b97\u6cd5\u548c\u7b97\u6cd5\u7ade\u8d5b\u7b49\u9886\u57df\uff0c\u5e76\u5305\u542b\u53d8\u91cf\u8ffd\u8e2a\u95ee\u9898\u548c\u4ee3\u7801\u91cd\u5199\u4ee5\u589e\u5f3a\u903b\u8f91\u7c92\u5ea6\u548c\u4ee3\u7801\u591a\u6837\u6027\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u7840\u6a21\u578b\uff08LLaMA 3\u3001LLaMA 3.1\u3001Qwen-2.5\u548cQwen-2.5 Coder\uff09\u548c20\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\u4e86\u4e00\u81f4\u7684\u6539\u8fdb\u3002TracePile\u4f7fLLaMA3.1-8B\u5728\u4e5d\u4e2a\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\u4e867.1%\uff0c\u5e76\u5728\u4e24\u9636\u6bb5\u5fae\u8c03\u4e0b\u5728LiveCodeBench\u3001CRUX\u548cMMLU\u4e0a\u53d6\u5f97\u4e86\u660e\u663e\u589e\u76ca\u3002", "conclusion": "TracePile\u901a\u8fc7\u5c06\u9690\u5f0f\u4ee3\u7801\u63a8\u7406\u8f6c\u5316\u4e3a\u663e\u5f0f\u6267\u884c\u94fe\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u3001\u4ee3\u7801\u3001\u903b\u8f91\u548c\u7b97\u6cd5\u7b49\u591a\u4e2a\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.23807", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23807", "abs": "https://arxiv.org/abs/2510.23807", "authors": ["Hamid R. Tizhoosh"], "title": "Why Foundation Models in Pathology Are Failing", "comment": null, "summary": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.", "AI": {"tldr": "\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u5728\u764c\u75c7\u8bca\u65ad\u548c\u9884\u540e\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u51c6\u786e\u6027\u4f4e\u3001\u9c81\u68d2\u6027\u5dee\u3001\u8ba1\u7b97\u9700\u6c42\u5927\u7b49\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u901a\u7528AI\u5047\u8bbe\u4e0e\u7ec4\u7ec7\u590d\u6742\u6027\u7684\u4e0d\u5339\u914d\u3002", "motivation": "\u8bc4\u4f30\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u5728\u764c\u75c7\u8bca\u65ad\u3001\u9884\u540e\u548c\u591a\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5176\u6839\u672c\u6027\u7f3a\u9677\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u7684\u4e03\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u751f\u7269\u590d\u6742\u6027\u3001\u65e0\u6548\u81ea\u76d1\u7763\u3001\u8fc7\u5ea6\u6cdb\u5316\u3001\u67b6\u6784\u590d\u6742\u3001\u7f3a\u4e4f\u9886\u57df\u521b\u65b0\u3001\u6570\u636e\u4e0d\u8db3\u548c\u8bbe\u8ba1\u7f3a\u9677\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u5b58\u5728\u4f4e\u8bca\u65ad\u51c6\u786e\u6027\u3001\u5dee\u9c81\u68d2\u6027\u3001\u51e0\u4f55\u4e0d\u7a33\u5b9a\u3001\u9ad8\u8ba1\u7b97\u9700\u6c42\u548c\u5b89\u5168\u9690\u60a3\u7b49\u4e25\u91cd\u95ee\u9898\u3002", "conclusion": "\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u4e0e\u7ec4\u7ec7\u5f62\u6001\u5b66\u672c\u8d28\u5b58\u5728\u6982\u5ff5\u6027\u4e0d\u5339\u914d\uff0c\u9700\u8981\u4ece\u6839\u672c\u4e0a\u91cd\u65b0\u601d\u8003\u8be5\u8303\u5f0f\u3002"}}
{"id": "2510.23827", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.other", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.23827", "abs": "https://arxiv.org/abs/2510.23827", "authors": ["Xicheng Xu", "Ahmed Adel Mahmoud", "Noah Gorgichuk", "Ronny Thomale", "Steven Rayan", "Matteo Mariantoni"], "title": "A Scalable Superconducting Circuit Framework for Emulating Physics in Hyperbolic Space", "comment": "18 pages, 12 figures (5 figures in main body and 7 figures in\n  extended material)", "summary": "Theoretical studies and experiments in the last six years have revealed the\npotential for novel behaviours and functionalities in device physics through\nthe synthetic engineering of negatively-curved spaces. For instance, recent\ndevelopments in hyperbolic band theory have unveiled the emergence of\nhigher-dimensional eigenstates -- features fundamentally absent in conventional\nEuclidean systems. At the same time, superconducting quantum circuits have\nemerged as a leading platform for quantum analogue emulations and digital\nsimulations in scalable architectures. Here, we introduce a scalable\nsuperconducting circuit framework for the analogue quantum emulation of\ntight-binding models on hyperbolic and kagome-like lattices. Using this\napproach, we experimentally realize three distinct lattices, including, for the\nfirst time to our knowledge, a hyperbolic lattice whose unit cell resides on a\ngenus-3 Riemann surface. Our method encodes the hyperbolic metric directly into\ncapacitive couplings between high-quality superconducting resonators, enabling\ntenable reproduction of spectral and localization properties while overcoming\nmajor scalability and spectral resolution limitations of previous designs.\nThese results set the stage for large-scale experimental studies of hyperbolic\nmaterials in condensed matter physics and lay the groundwork for realizing\nhyperbolic quantum processors, with potential implications for both fundamental\nphysics and quantum computing", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u8d85\u5bfc\u7535\u8def\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u53cc\u66f2\u548ckagome\u7c7b\u6676\u683c\u4e0a\u7684\u7d27\u675f\u7f1a\u6a21\u578b\uff0c\u9996\u6b21\u5b9e\u9a8c\u5b9e\u73b0\u4e86\u4f4d\u4e8egenus-3\u9ece\u66fc\u66f2\u9762\u4e0a\u7684\u53cc\u66f2\u6676\u683c\u3002", "motivation": "\u8fd1\u5e74\u6765\u7406\u8bba\u7814\u7a76\u548c\u5b9e\u9a8c\u63ed\u793a\u4e86\u901a\u8fc7\u5408\u6210\u8d1f\u66f2\u7387\u7a7a\u95f4\u5de5\u7a0b\u5728\u5668\u4ef6\u7269\u7406\u4e2d\u5b9e\u73b0\u65b0\u9896\u884c\u4e3a\u548c\u529f\u80fd\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u53cc\u66f2\u80fd\u5e26\u7406\u8bba\u53d1\u73b0\u4e86\u9ad8\u7ef4\u672c\u5f81\u6001\u7b49\u4f20\u7edf\u6b27\u51e0\u91cc\u5fb7\u7cfb\u7edf\u4e2d\u6839\u672c\u4e0d\u5b58\u5728\u7684\u65b0\u7279\u5f81\u3002\u540c\u65f6\uff0c\u8d85\u5bfc\u91cf\u5b50\u7535\u8def\u5df2\u6210\u4e3a\u53ef\u6269\u5c55\u67b6\u6784\u4e2d\u91cf\u5b50\u6a21\u62df\u548c\u6570\u5b57\u6a21\u62df\u7684\u4e3b\u8981\u5e73\u53f0\u3002", "method": "\u4f7f\u7528\u53ef\u6269\u5c55\u7684\u8d85\u5bfc\u7535\u8def\u6846\u67b6\uff0c\u5c06\u53cc\u66f2\u5ea6\u91cf\u76f4\u63a5\u7f16\u7801\u5230\u9ad8\u8d28\u91cf\u8d85\u5bfc\u8c10\u632f\u5668\u4e4b\u95f4\u7684\u7535\u5bb9\u8026\u5408\u4e2d\uff0c\u4ece\u800c\u6a21\u62df\u53cc\u66f2\u548ckagome\u7c7b\u6676\u683c\u4e0a\u7684\u7d27\u675f\u7f1a\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u5b9e\u73b0\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u6676\u683c\uff0c\u5305\u62ec\u9996\u6b21\u5728genus-3\u9ece\u66fc\u66f2\u9762\u4e0a\u7684\u53cc\u66f2\u6676\u683c\u5355\u5143\u3002\u8be5\u65b9\u6cd5\u514b\u670d\u4e86\u5148\u524d\u8bbe\u8ba1\u7684\u4e3b\u8981\u53ef\u6269\u5c55\u6027\u548c\u5149\u8c31\u5206\u8fa8\u7387\u9650\u5236\uff0c\u80fd\u591f\u53ef\u9760\u5730\u518d\u73b0\u5149\u8c31\u548c\u5c40\u57df\u5316\u7279\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u51dd\u805a\u6001\u7269\u7406\u4e2d\u53cc\u66f2\u6750\u6599\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u5b9e\u73b0\u53cc\u66f2\u91cf\u5b50\u5904\u7406\u5668\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5bf9\u57fa\u7840\u7269\u7406\u548c\u91cf\u5b50\u8ba1\u7b97\u90fd\u5177\u6709\u6f5c\u5728\u5f71\u54cd\u3002"}}
{"id": "2510.24712", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2510.24712", "abs": "https://arxiv.org/abs/2510.24712", "authors": ["Yuan-Hang Zhang", "Chesson Sipling", "Massimiliano Di Ventra"], "title": "Memory-induced long-range order drag", "comment": "13 pages, 10 figures", "summary": "Recent research has shown that memory, in the form of slow degrees of\nfreedom, can induce a phase of long-range order (LRO) in locally-coupled fast\ndegrees of freedom, producing power-law distributions of avalanches. In fact,\nsuch memory-induced LRO (MILRO) arises in a wide range of physical systems.\nHere, we show that MILRO can be transferred to coupled systems that have no\nmemory of their own. As an example, we consider a stack of layers of spins with\nlocal feedforward couplings: only the first layer contains memory, while\ndownstream layers are memory-free and locally interacting. Analytical arguments\nand simulations reveal that MILRO can indeed drag across the layers, enabling\ndownstream layers to sustain intra-layer LRO despite having neither memory nor\nlong-range interactions. This establishes a simple, yet generic mechanism for\npropagating collective activity through media without fine tuning to\ncriticality, with testable implications for neuromorphic systems and laminar\ninformation flow in the brain cortex.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u4e0b\u6e38\u5c42\u6ca1\u6709\u8bb0\u5fc6\u529f\u80fd\uff0c\u901a\u8fc7\u5c42\u95f4\u8026\u5408\uff0c\u8bb0\u5fc6\u8bf1\u5bfc\u7684\u957f\u7a0b\u6709\u5e8f\u53ef\u4ee5\u4ece\u6709\u8bb0\u5fc6\u7684\u7b2c\u4e00\u5c42\u4f20\u64ad\u5230\u65e0\u8bb0\u5fc6\u7684\u4e0b\u6e38\u5c42\uff0c\u4f7f\u4e0b\u6e38\u5c42\u4e5f\u80fd\u7ef4\u6301\u5c42\u5185\u957f\u7a0b\u6709\u5e8f\u3002", "motivation": "\u7814\u7a76\u8bb0\u5fc6\u8bf1\u5bfc\u7684\u957f\u7a0b\u6709\u5e8f\uff08MILRO\uff09\u662f\u5426\u80fd\u591f\u5728\u8026\u5408\u7cfb\u7edf\u4e2d\u4f20\u64ad\u5230\u6ca1\u6709\u81ea\u8eab\u8bb0\u5fc6\u7684\u7cfb\u7edf\u4e2d\uff0c\u63a2\u7d22\u96c6\u4f53\u6d3b\u52a8\u5728\u65e0\u8bb0\u5fc6\u4ecb\u8d28\u4e2d\u7684\u4f20\u64ad\u673a\u5236\u3002", "method": "\u91c7\u7528\u5177\u6709\u5c40\u90e8\u524d\u9988\u8026\u5408\u7684\u81ea\u65cb\u5c42\u5806\u53e0\u6a21\u578b\uff0c\u5176\u4e2d\u53ea\u6709\u7b2c\u4e00\u5c42\u5305\u542b\u8bb0\u5fc6\uff0c\u4e0b\u6e38\u5c42\u662f\u65e0\u8bb0\u5fc6\u7684\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u8bba\u8bc1\u548c\u6a21\u62df\u9a8c\u8bc1MILRO\u7684\u4f20\u64ad\u6548\u5e94\u3002", "result": "\u6a21\u62df\u548c\u5206\u6790\u8868\u660e\uff0cMILRO\u786e\u5b9e\u80fd\u591f\u8de8\u8d8a\u5c42\u4f20\u64ad\uff0c\u4f7f\u5f97\u4e0b\u6e38\u5c42\u5373\u4f7f\u6ca1\u6709\u8bb0\u5fc6\u548c\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\uff0c\u4e5f\u80fd\u7ef4\u6301\u5c42\u5185\u957f\u7a0b\u6709\u5e8f\u3002", "conclusion": "\u8fd9\u5efa\u7acb\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u901a\u7528\u7684\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u65e0\u9700\u7cbe\u786e\u8c03\u8c10\u5230\u4e34\u754c\u70b9\u7684\u60c5\u51b5\u4e0b\u4f20\u64ad\u96c6\u4f53\u6d3b\u52a8\uff0c\u5bf9\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\u548c\u5927\u8111\u76ae\u5c42\u5c42\u72b6\u4fe1\u606f\u6d41\u5177\u6709\u53ef\u6d4b\u8bd5\u7684\u610f\u4e49\u3002"}}
{"id": "2510.24322", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.24322", "abs": "https://arxiv.org/abs/2510.24322", "authors": ["Declan Nell", "Stefano Sanvito", "Andrea Droghetti"], "title": "Non-equilibrium correlation effects in spin transport through the 2D ferromagnet Fe$_4$GeTe$_2$", "comment": "9 pages. 3 figures", "summary": "Understanding non-equilibrium spin transport through 2D ferromagnets is a\ntheoretical challenge, as correlations produce a complex electronic structure\nwith coexisting itinerant and localized electrons. We have developed a fully\nnon-equilibrium ab initio method, combining density functional theory,\ndynamical mean-field theory, and non-equilibrium Green's functions to\ninvestigate the transport in Fe$_4$GeTe$_2$, a prototypical high-temperature 2D\nferromagnet. We show that, while spin transport remains essentially\nsingle-particle under moderate bias, inelastic spin-dependent scattering of\ncarriers with particle-hole excitations drives a distinctive hot-correlated\nelectron regime beyond a critical voltage. This regime is marked by incoherent\nfeatures in both the electronic spectrum and the conductance, which are\nexperimentally accessible. Our results demonstrates that material-specific\nmany-body non-equilibrium methods are essential for a complete understanding of\nspin transport in 2D ferromagnets.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408DFT\u3001DMFT\u548c\u975e\u5e73\u8861\u683c\u6797\u51fd\u6570\u7684\u975e\u5e73\u8861\u4ece\u5934\u8ba1\u7b97\u65b9\u6cd5\uff0c\u7814\u7a762D\u94c1\u78c1\u4f53Fe4GeTe2\u7684\u81ea\u65cb\u8f93\u8fd0\uff0c\u53d1\u73b0\u8d85\u8fc7\u4e34\u754c\u7535\u538b\u65f6\u4f1a\u51fa\u73b0\u7531\u8f7d\u6d41\u5b50\u4e0e\u7c92\u5b50-\u7a7a\u7a74\u6fc0\u53d1\u975e\u5f39\u6027\u6563\u5c04\u9a71\u52a8\u7684\u70ed\u5173\u8054\u7535\u5b50\u6001\u3002", "motivation": "\u7406\u89e3\u4e8c\u7ef4\u94c1\u78c1\u4f53\u4e2d\u7684\u975e\u5e73\u8861\u81ea\u65cb\u8f93\u8fd0\u662f\u4e00\u4e2a\u7406\u8bba\u6311\u6218\uff0c\u56e0\u4e3a\u5173\u8054\u6548\u5e94\u4f1a\u4ea7\u751f\u5177\u6709\u5171\u5b58\u5de1\u6e38\u548c\u5c40\u57df\u7535\u5b50\u7684\u590d\u6742\u7535\u5b50\u7ed3\u6784\u3002", "method": "\u7ed3\u5408\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba(DFT)\u3001\u52a8\u529b\u5b66\u5e73\u5747\u573a\u7406\u8bba(DMFT)\u548c\u975e\u5e73\u8861\u683c\u6797\u51fd\u6570\u7684\u5b8c\u5168\u975e\u5e73\u8861\u4ece\u5934\u8ba1\u7b97\u65b9\u6cd5\u3002", "result": "\u5728\u9002\u5ea6\u504f\u538b\u4e0b\u81ea\u65cb\u8f93\u8fd0\u57fa\u672c\u4fdd\u6301\u5355\u7c92\u5b50\u7279\u6027\uff0c\u4f46\u8d85\u8fc7\u4e34\u754c\u7535\u538b\u65f6\uff0c\u8f7d\u6d41\u5b50\u4e0e\u7c92\u5b50-\u7a7a\u7a74\u6fc0\u53d1\u7684\u975e\u5f39\u6027\u81ea\u65cb\u76f8\u5173\u6563\u5c04\u4f1a\u9a71\u52a8\u72ec\u7279\u7684\u70ed\u5173\u8054\u7535\u5b50\u6001\uff0c\u8868\u73b0\u4e3a\u7535\u5b50\u8c31\u548c\u7535\u5bfc\u4e2d\u7684\u975e\u76f8\u5e72\u7279\u5f81\u3002", "conclusion": "\u6750\u6599\u7279\u5b9a\u7684\u591a\u4f53\u975e\u5e73\u8861\u65b9\u6cd5\u5bf9\u4e8e\u5b8c\u5168\u7406\u89e3\u4e8c\u7ef4\u94c1\u78c1\u4f53\u4e2d\u7684\u81ea\u65cb\u8f93\u8fd0\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.23822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23822", "abs": "https://arxiv.org/abs/2510.23822", "authors": ["Zhenyu Zhang", "Tianyi Chen", "Weiran Xu", "Alex Pentland", "Jiaxin Pei"], "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents", "comment": null, "summary": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning\nremain challenging for large language models (LLMs). Sequential prompting\nmethods are prone to context drift, loss of goal information, and recurrent\nfailure cycles, while hierarchical prompting methods often weaken cross-level\ncontinuity or incur substantial runtime overhead. We introduce ReCAP (Recursive\nContext-Aware Reasoning and Planning), a hierarchical framework with shared\ncontext for reasoning and planning in LLMs. ReCAP combines three key\nmechanisms: (i) plan-ahead decomposition, in which the model generates a full\nsubtask list, executes the first item, and refines the remainder; (ii)\nstructured re-injection of parent plans, maintaining consistent multi-level\ncontext during recursive return; and (iii) memory-efficient execution, bounding\nthe active prompt so costs scale linearly with task depth. Together these\nmechanisms align high-level goals with low-level actions, reduce redundant\nprompting, and preserve coherent context updates across recursion. Experiments\ndemonstrate that ReCAP substantially improves subgoal alignment and success\nrates on various long-horizon reasoning benchmarks, achieving a 32% gain on\nsynchronous Robotouille and a 29% improvement on asynchronous Robotouille under\nthe strict pass@1 protocol.", "AI": {"tldr": "ReCAP\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9012\u5f52\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u548c\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u5212\u5206\u89e3\u3001\u7236\u8ba1\u5212\u7ed3\u6784\u5316\u91cd\u6ce8\u5165\u548c\u5185\u5b58\u9ad8\u6548\u6267\u884c\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u65f6\u7a0b\u4efb\u52a1\u7684\u63a8\u7406\u80fd\u529b\u548c\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9700\u8981\u591a\u6b65\u63a8\u7406\u548c\u52a8\u6001\u91cd\u89c4\u5212\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u4e0a\u4e0b\u6587\u6f02\u79fb\u3001\u76ee\u6807\u4fe1\u606f\u4e22\u5931\u548c\u5faa\u73af\u5931\u8d25\u7b49\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u5bfc\u81f4\u7684\u8de8\u7ea7\u8fde\u7eed\u6027\u51cf\u5f31\u6216\u8fd0\u884c\u65f6\u5f00\u9500\u8fc7\u5927\u3002", "method": "\u7ed3\u5408\u4e09\u4e2a\u5173\u952e\u673a\u5236\uff1a(1) \u8ba1\u5212\u5148\u884c\u5206\u89e3\uff1a\u751f\u6210\u5b8c\u6574\u5b50\u4efb\u52a1\u5217\u8868\uff0c\u6267\u884c\u7b2c\u4e00\u9879\u5e76\u4f18\u5316\u5269\u4f59\u4efb\u52a1\uff1b(2) \u7236\u8ba1\u5212\u7ed3\u6784\u5316\u91cd\u6ce8\u5165\uff1a\u5728\u9012\u5f52\u8fd4\u56de\u65f6\u4fdd\u6301\u591a\u7ea7\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\uff1b(3) \u5185\u5b58\u9ad8\u6548\u6267\u884c\uff1a\u9650\u5236\u6d3b\u52a8\u63d0\u793a\uff0c\u4f7f\u6210\u672c\u968f\u4efb\u52a1\u6df1\u5ea6\u7ebf\u6027\u6269\u5c55\u3002", "result": "\u5728\u591a\u4e2a\u957f\u65f6\u7a0b\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5b50\u76ee\u6807\u5bf9\u9f50\u548c\u6210\u529f\u7387\uff0c\u5728\u540c\u6b65Robotouille\u4e0a\u83b7\u5f9732%\u7684\u63d0\u5347\uff0c\u5728\u5f02\u6b65Robotouille\u4e0a\u83b7\u5f9729%\u7684\u6539\u8fdb\uff08\u4e25\u683cpass@1\u534f\u8bae\u4e0b\uff09\u3002", "conclusion": "ReCAP\u6846\u67b6\u901a\u8fc7\u5c06\u9ad8\u5c42\u76ee\u6807\u4e0e\u4f4e\u5c42\u52a8\u4f5c\u5bf9\u9f50\u3001\u51cf\u5c11\u5197\u4f59\u63d0\u793a\u548c\u4fdd\u6301\u8fde\u8d2f\u7684\u4e0a\u4e0b\u6587\u66f4\u65b0\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2510.24361", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.24361", "abs": "https://arxiv.org/abs/2510.24361", "authors": ["M. Rumo", "G. Kremer", "M. Heber", "N. Wind", "C. W. Nicholson", "K. Y. Ma", "G. Brenner", "F. Pressacco", "M. Scholz", "K. Rossnagel", "F. O. von Rohr", "D. Kutnyakhov", "C. Monney"], "title": "Ultrafast recovery dynamics of dimer stripes in IrTe2", "comment": "17 pages, 4 figures", "summary": "The transition metal dichalcogenide IrTe2 displays a remarkable series of\nfirst-order phase transitions below room temperature, involving lattice\ndisplacements as large as 20 percents of the initial bond length. This is\nnowadays understood as the result of strong electron-phonon coupling leading to\nthe formation of local multicentre dimers that arrange themselves into\none-dimensional stripes. In this work, we study the out-of-equilibrium dynamics\nof these dimers and track the time evolution of their population following an\ninfrared photoexcitation using free-electron lased-based time-resolved X-ray\nphotoemission spectroscopy. First, we observe that the dissolution of dimers is\ndriven by the transfer of energy from the electronic subsystem to the lattice\nsubsystem, in agreement with previous studies. Second, we observe a\nsurprisingly fast relaxation of the dimer population on the timescale of a few\npicoseconds. By comparing our results to published ultrafast electron\ndiffraction and angle-resolved photoemission spectroscopy data, we reveal that\nthe long-range order needs tens of picoseconds to recover, while the local\ndimer distortion recovers on a short timescale of a few picoseconds.", "AI": {"tldr": "\u4f7f\u7528\u81ea\u7531\u7535\u5b50\u6fc0\u5149\u65f6\u95f4\u5206\u8fa8X\u5c04\u7ebf\u5149\u7535\u5b50\u80fd\u8c31\u7814\u7a76IrTe2\u4e2d\u4e8c\u805a\u4f53\u7684\u975e\u5e73\u8861\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u4e8c\u805a\u4f53\u89e3\u79bb\u7531\u7535\u5b50\u5b50\u7cfb\u7edf\u5411\u6676\u683c\u5b50\u7cfb\u7edf\u7684\u80fd\u91cf\u8f6c\u79fb\u9a71\u52a8\uff0c\u4e8c\u805a\u4f53\u6570\u91cf\u5728\u76ae\u79d2\u5c3a\u5ea6\u5feb\u901f\u6062\u590d\uff0c\u800c\u957f\u7a0b\u6709\u5e8f\u9700\u8981\u6570\u5341\u76ae\u79d2\u624d\u80fd\u6062\u590d\u3002", "motivation": "\u7814\u7a76IrTe2\u4e2d\u7531\u5f3a\u7535\u5b50-\u58f0\u5b50\u8026\u5408\u5f62\u6210\u7684\u4e00\u7ef4\u6761\u7eb9\u72b6\u4e8c\u805a\u4f53\u5728\u7ea2\u5916\u5149\u6fc0\u53d1\u540e\u7684\u975e\u5e73\u8861\u52a8\u529b\u5b66\u884c\u4e3a\uff0c\u7406\u89e3\u5c40\u57df\u4e8c\u805a\u4f53\u7578\u53d8\u4e0e\u957f\u7a0b\u6709\u5e8f\u6062\u590d\u7684\u65f6\u95f4\u5c3a\u5ea6\u5dee\u5f02\u3002", "method": "\u91c7\u7528\u81ea\u7531\u7535\u5b50\u6fc0\u5149\u65f6\u95f4\u5206\u8fa8X\u5c04\u7ebf\u5149\u7535\u5b50\u80fd\u8c31\u6280\u672f\uff0c\u8ddf\u8e2a\u7ea2\u5916\u5149\u6fc0\u53d1\u540e\u4e8c\u805a\u4f53\u6570\u91cf\u7684\u65f6\u95f4\u6f14\u5316\u3002", "result": "\u89c2\u5bdf\u5230\u4e8c\u805a\u4f53\u89e3\u79bb\u7531\u7535\u5b50\u5411\u6676\u683c\u7684\u80fd\u91cf\u8f6c\u79fb\u9a71\u52a8\uff1b\u4e8c\u805a\u4f53\u6570\u91cf\u5728\u51e0\u76ae\u79d2\u5185\u5feb\u901f\u6062\u590d\uff1b\u957f\u7a0b\u6709\u5e8f\u6062\u590d\u9700\u8981\u6570\u5341\u76ae\u79d2\uff0c\u8fdc\u6162\u4e8e\u5c40\u57df\u7578\u53d8\u6062\u590d\u3002", "conclusion": "IrTe2\u4e2d\u5c40\u57df\u4e8c\u805a\u4f53\u7578\u53d8\u4e0e\u957f\u7a0b\u6709\u5e8f\u6062\u590d\u5b58\u5728\u663e\u8457\u65f6\u95f4\u5c3a\u5ea6\u5dee\u5f02\uff0c\u8868\u660e\u5c40\u57df\u7ed3\u6784\u6062\u590d\u5feb\u4e8e\u957f\u7a0b\u6709\u5e8f\u91cd\u5efa\u3002"}}
{"id": "2510.23631", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23631", "abs": "https://arxiv.org/abs/2510.23631", "authors": ["Yuxuan Tang", "Yifan Feng"], "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling", "comment": null, "summary": "Alignment of large language models (LLMs) has predominantly relied on\npairwise preference optimization, where annotators select the better of two\nresponses to a prompt. While simple, this approach overlooks the opportunity to\nlearn from richer forms of human feedback, such as multiwise comparisons and\ntop-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a\nunified framework that bridges preference optimization with (ranked) choice\nmodeling via maximum likelihood estimation. The framework is flexible,\nsupporting both utility-based and rank-based choice models. It subsumes several\nexisting pairwise methods (e.g., DPO, SimPO), while providing principled\ntraining objectives for richer feedback formats. We instantiate this framework\nwith two representative ranked choice models (Multinomial Logit and\nMallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across\nAlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms\ncompetitive baselines. RCPO shows how directly leveraging ranked preference\ndata, combined with the right choice models, yields more effective alignment.\nIt offers a versatile and extensible foundation for incorporating (ranked)\nchoice modeling into LLM training.", "AI": {"tldr": "\u63d0\u51fa\u4e86Ranked Choice Preference Optimization (RCPO)\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5c06\u504f\u597d\u4f18\u5316\u4e0e\u6392\u540d\u9009\u62e9\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u652f\u6301\u591a\u79cd\u53cd\u9988\u683c\u5f0f\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e3b\u8981\u4f9d\u8d56\u6210\u5bf9\u504f\u597d\u4f18\u5316\uff0c\u5ffd\u7565\u4e86\u4ece\u66f4\u4e30\u5bcc\u7684\u4eba\u7c7b\u53cd\u9988\u5f62\u5f0f\uff08\u5982\u591a\u6bd4\u8f83\u548c\u6392\u540d\uff09\u4e2d\u5b66\u4e60\u7684\u673a\u4f1a\u3002", "method": "\u63d0\u51fa\u4e86RCPO\u7edf\u4e00\u6846\u67b6\uff0c\u652f\u6301\u57fa\u4e8e\u6548\u7528\u548c\u57fa\u4e8e\u6392\u540d\u7684\u9009\u62e9\u6a21\u578b\uff0c\u5305\u542b\u591a\u79cd\u73b0\u6709\u6210\u5bf9\u65b9\u6cd5\uff0c\u5e76\u4e3a\u66f4\u4e30\u5bcc\u7684\u53cd\u9988\u683c\u5f0f\u63d0\u4f9b\u539f\u5219\u6027\u8bad\u7ec3\u76ee\u6807\u3002", "result": "\u5728Llama-3-8B-Instruct\u548cGemma-2-9B-it\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cRCPO\u5728AlpacaEval 2\u548cArena-Hard\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u3002", "conclusion": "RCPO\u5c55\u793a\u4e86\u76f4\u63a5\u5229\u7528\u6392\u540d\u504f\u597d\u6570\u636e\u7ed3\u5408\u9002\u5f53\u9009\u62e9\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u5bf9\u9f50\uff0c\u4e3a\u5c06\u6392\u540d\u9009\u62e9\u5efa\u6a21\u878d\u5165LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2510.23824", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23824", "abs": "https://arxiv.org/abs/2510.23824", "authors": ["Murad Ismayilov", "Edwin Meriaux", "Shuo Wen", "Gregory Dudek"], "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "comment": "Accepted at MIT URTC 2025", "summary": "Coordinating multiple autonomous agents in shared environments under\ndecentralized conditions is a long-standing challenge in robotics and\nartificial intelligence. This work addresses the problem of decentralized goal\nassignment for multi-agent path planning, where agents independently generate\nranked preferences over goals based on structured representations of the\nenvironment, including grid visualizations and scenario data. After this\nreasoning phase, agents exchange their goal rankings, and assignments are\ndetermined by a fixed, deterministic conflict-resolution rule (e.g., agent\nindex ordering), without negotiation or iterative coordination. We\nsystematically compare greedy heuristics, optimal assignment, and large\nlanguage model (LLM)-based agents in fully observable grid-world settings. Our\nresults show that LLM-based agents, when provided with well-designed prompts\nand relevant quantitative information, can achieve near-optimal makespans and\nconsistently outperform traditional heuristics. These findings underscore the\npotential of language models for decentralized goal assignment in multi-agent\npath planning and highlight the importance of information structure in such\nsystems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u8d2a\u5a6a\u542f\u53d1\u5f0f\u3001\u6700\u4f18\u5206\u914d\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\u5728\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLM\u667a\u80fd\u4f53\u5728\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u76f8\u5173\u4fe1\u606f\u4e0b\u80fd\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u6761\u4ef6\u4e0b\u591a\u667a\u80fd\u4f53\u5728\u5171\u4eab\u73af\u5883\u4e2d\u7684\u534f\u8c03\u6311\u6218\uff0c\u7279\u522b\u5173\u6ce8\u76ee\u6807\u5206\u914d\u95ee\u9898\uff0c\u63a2\u7d22LLM\u5728\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u667a\u80fd\u4f53\u57fa\u4e8e\u73af\u5883\u7ed3\u6784\u5316\u8868\u793a\uff08\u5305\u62ec\u7f51\u683c\u53ef\u89c6\u5316\u548c\u573a\u666f\u6570\u636e\uff09\u72ec\u7acb\u751f\u6210\u76ee\u6807\u504f\u597d\u6392\u5e8f\uff0c\u7136\u540e\u4ea4\u6362\u6392\u5e8f\u4fe1\u606f\uff0c\u901a\u8fc7\u56fa\u5b9a\u7684\u786e\u5b9a\u6027\u51b2\u7a81\u89e3\u51b3\u89c4\u5219\uff08\u5982\u667a\u80fd\u4f53\u7d22\u5f15\u6392\u5e8f\uff09\u8fdb\u884c\u76ee\u6807\u5206\u914d\uff0c\u65e0\u9700\u534f\u5546\u6216\u8fed\u4ee3\u534f\u8c03\u3002", "result": "LLM\u667a\u80fd\u4f53\u5728\u63d0\u4f9b\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u76f8\u5173\u5b9a\u91cf\u4fe1\u606f\u65f6\uff0c\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u5b8c\u5de5\u65f6\u95f4\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u7684\u76ee\u6807\u5206\u914d\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4fe1\u606f\u7ed3\u6784\u5728\u6b64\u7c7b\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.23923", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23923", "abs": "https://arxiv.org/abs/2510.23923", "authors": ["Ilias Magoulas", "Francesco A. Evangelista"], "title": "Clifford Transformations for Fermionic Quantum Systems: From Paulis to Majoranas to Fermions", "comment": null, "summary": "Clifford gates and transformations, which map products of elementary Pauli or\nMajorana operators to other such products, are foundational in quantum\ncomputing, underpinning the stabilizer formalism, error-correcting codes, magic\nstate distillation, quantum communication and cryptography, and qubit tapering.\nMoreover, circuits composed entirely of Clifford gates are classically\nsimulatable, highlighting their computational significance. In this work, we\nextend the concept of Clifford transformations to fermionic systems. We\ndemonstrate that fermionic Clifford transformations are generated by half-body\nand pair operators, providing a systematic framework for their\ncharacterization. Additionally, we establish connections with fermionic\nmean-field theories and applications in qubit tapering, offering insights into\ntheir broader implications in quantum computing.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Clifford\u53d8\u6362\u7684\u6982\u5ff5\u5230\u8d39\u7c73\u5b50\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u8d39\u7c73\u5b50Clifford\u53d8\u6362\u7531\u534a\u4f53\u548c\u914d\u5bf9\u7b97\u5b50\u751f\u6210\uff0c\u5efa\u7acb\u4e86\u4e0e\u8d39\u7c73\u5b50\u5e73\u5747\u573a\u7406\u8bba\u548c\u91cf\u5b50\u6bd4\u7279\u7f29\u51cf\u7684\u8054\u7cfb\u3002", "motivation": "Clifford\u95e8\u548c\u53d8\u6362\u5728\u91cf\u5b50\u8ba1\u7b97\u4e2d\u5177\u6709\u57fa\u7840\u6027\u4f5c\u7528\uff0c\u652f\u6491\u7740\u7a33\u5b9a\u5b50\u5f62\u5f0f\u3001\u7ea0\u9519\u7801\u3001\u9b54\u6001\u84b8\u998f\u7b49\u5173\u952e\u5e94\u7528\u3002\u7531\u4e8e\u7eafClifford\u95e8\u7535\u8def\u53ef\u7ecf\u5178\u6a21\u62df\uff0c\u5176\u8ba1\u7b97\u610f\u4e49\u91cd\u5927\u3002\u672c\u6587\u65e8\u5728\u5c06\u8fd9\u4e00\u91cd\u8981\u6982\u5ff5\u6269\u5c55\u5230\u8d39\u7c73\u5b50\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u8d39\u7c73\u5b50Clifford\u53d8\u6362\u7531\u534a\u4f53\u7b97\u5b50\u548c\u914d\u5bf9\u7b97\u5b50\u751f\u6210\uff0c\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u8868\u5f81\u6846\u67b6\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u8d39\u7c73\u5b50Clifford\u53d8\u6362\u7684\u751f\u6210\u5143\u7406\u8bba\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u8d39\u7c73\u5b50\u5e73\u5747\u573a\u7406\u8bba\u548c\u91cf\u5b50\u6bd4\u7279\u7f29\u51cf\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u8d39\u7c73\u5b50Clifford\u53d8\u6362\u7684\u6269\u5c55\u4e3a\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5176\u5728\u66f4\u5e7f\u6cdb\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.24713", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.24713", "abs": "https://arxiv.org/abs/2510.24713", "authors": ["Lei Gioia", "Sanjay Moudgalya", "Olexei I. Motrunich"], "title": "Distinct Types of Parent Hamiltonians for Quantum States: Insights from the $W$ State as a Quantum Many-Body Scar", "comment": "24+22 pages, 6 figures", "summary": "The construction of parent Hamiltonians that possess a given state as their\nground state is a well-studied problem. In this work, we generalize this notion\nby considering simple quantum states and examining the local Hamiltonians that\nhave these states as exact eigenstates.These states often correspond to Quantum\nMany-Body Scars (QMBS) of their respective parent Hamiltonians.Motivated by\nearlier works on Hamiltonians with QMBS, in this work we formalize the\ndifferences between three distinct types of parent Hamiltonians, which differ\nin their decompositions into strictly local terms with the same eigenstates. We\nillustrate this classification using the $W$ state as the primary example, for\nwhich we rigorously derive the complete set of local parent Hamiltonians, which\nalso allows us to establish general results such as the existence of asymptotic\nQMBS, and distinct dynamical signatures associated with the different parent\nHamiltonian types. Finally, we derive more general results on the parent\nHamiltonian types that allow us to obtain some immediate results for simple\nquantum states such as product states, where only a single type exists, and for\nshort-range-entangled states, for which we identify constraints on the\nadmissible types. Altogether, our work opens the door to classifying the rich\nstructures and dynamical properties of parent Hamiltonians that arise from the\ninterplay between locality and QMBS.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u91cf\u5b50\u591a\u4f53\u75a4\u75d5(QMBS)\u7684\u5c40\u57df\u7236\u54c8\u5bc6\u987f\u91cf\u5206\u7c7b\u95ee\u9898\uff0c\u4ee5W\u6001\u4e3a\u4e3b\u8981\u793a\u4f8b\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u4e09\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u7236\u54c8\u5bc6\u987f\u91cf\u53ca\u5176\u52a8\u529b\u5b66\u7279\u5f81\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a8\u5e7f\u4f20\u7edf\u7236\u54c8\u5bc6\u987f\u91cf\u6784\u9020\u95ee\u9898\uff0c\u8003\u5bdf\u7b80\u5355\u91cf\u5b50\u6001\u4f5c\u4e3a\u7cbe\u786e\u672c\u5f81\u6001\u7684\u5c40\u57df\u54c8\u5bc6\u987f\u91cf\uff0c\u8fd9\u4e9b\u6001\u901a\u5e38\u5bf9\u5e94\u91cf\u5b50\u591a\u4f53\u75a4\u75d5\u3002", "method": "\u4f7f\u7528W\u6001\u4f5c\u4e3a\u4e3b\u8981\u793a\u4f8b\uff0c\u4e25\u683c\u63a8\u5bfc\u5b8c\u6574\u7684\u5c40\u57df\u7236\u54c8\u5bc6\u987f\u91cf\u96c6\u5408\uff0c\u5efa\u7acb\u4e00\u822c\u6027\u7ed3\u679c\u5982\u6e10\u8fd1QMBS\u7684\u5b58\u5728\u6027\uff0c\u5e76\u5206\u6790\u4e0d\u540c\u7236\u54c8\u5bc6\u987f\u91cf\u7c7b\u578b\u7684\u52a8\u529b\u5b66\u7279\u5f81\u3002", "result": "\u5efa\u7acb\u4e86\u7236\u54c8\u5bc6\u987f\u91cf\u7684\u4e09\u79cd\u4e0d\u540c\u7c7b\u578b\u5206\u7c7b\uff0c\u8bc1\u660e\u4e86\u6e10\u8fd1QMBS\u7684\u5b58\u5728\u6027\uff0c\u5e76\u53d1\u73b0\u4e0d\u540c\u7c7b\u578b\u7236\u54c8\u5bc6\u987f\u91cf\u5177\u6709\u4e0d\u540c\u7684\u52a8\u529b\u5b66\u7279\u5f81\u3002\u5bf9\u4e8e\u7b80\u5355\u91cf\u5b50\u6001\u5982\u4e58\u79ef\u6001\uff0c\u53d1\u73b0\u53ea\u5b58\u5728\u5355\u4e00\u7c7b\u578b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u5c40\u57df\u6027\u548c\u91cf\u5b50\u591a\u4f53\u75a4\u75d5\u76f8\u4e92\u4f5c\u7528\u7684\u7236\u54c8\u5bc6\u987f\u91cf\u4e30\u5bcc\u7ed3\u6784\u548c\u52a8\u529b\u5b66\u6027\u8d28\u7684\u5206\u7c7b\u7814\u7a76\u6253\u5f00\u4e86\u5927\u95e8\u3002"}}
{"id": "2510.24376", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.24376", "abs": "https://arxiv.org/abs/2510.24376", "authors": ["K. Yu. Povarov", "J. Wosnitza", "S. R\u00f6\u00dfler", "M. Schmidt", "A. A. Tsirlin", "S. A. Zvyagin"], "title": "Low-energy magnons in the altermagnet $\u03b1$-MnTe", "comment": "Main - 5 pages, 5 figures; Supplement - 1 page", "summary": "We report high-field electron spin resonance studies of the altermagnetic\nmaterial $\\alpha$-MnTe. In magnetic fields applied parallel to the triangular\nMn$^{2+}$ layers we observed a single resonance line, corresponding to an\nantiferromagnetic resonance (AFMR) mode. The resonance fields of this\nexcitation exhibit an isotropic behavior with $g_\\mathrm{eff}=2.01$, which is\nclose to the free-electron $g$-factor value and agrees with the absence of\norbital momenta for the Mn$^{2+}$ ions. At low temperatures, the AFMR mode is\nremarkably sharp ($\\sim50$ mT for the full width at the half-maximum). This\nmode exhibits a noticeable broadening with increasing temperature, indicating\nthe enhanced effect of magnon-magnon interactions. Based on this behavior, we\nestimate the strength of these interactions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u9ad8\u573a\u7535\u5b50\u81ea\u65cb\u5171\u632f\u7814\u7a76\u53cd\u94c1\u78c1\u6750\u6599\u03b1-MnTe\uff0c\u89c2\u5bdf\u5230\u4e0e\u81ea\u7531\u7535\u5b50g\u56e0\u5b50\u63a5\u8fd1\u7684\u5355\u4e00\u53cd\u94c1\u78c1\u5171\u632f\u6a21\u5f0f\uff0c\u8be5\u6a21\u5f0f\u5728\u4f4e\u6e29\u4e0b\u5f02\u5e38\u5c16\u9510\uff0c\u968f\u6e29\u5ea6\u5347\u9ad8\u56e0\u78c1\u5b50-\u78c1\u5b50\u76f8\u4e92\u4f5c\u7528\u589e\u5f3a\u800c\u5c55\u5bbd\u3002", "motivation": "\u7814\u7a76\u53cd\u94c1\u78c1\u6750\u6599\u03b1-MnTe\u7684\u78c1\u5171\u632f\u7279\u6027\uff0c\u7279\u522b\u662f\u4e86\u89e3\u5176\u53cd\u94c1\u78c1\u5171\u632f\u6a21\u5f0f\u7684\u884c\u4e3a\u4ee5\u53ca\u78c1\u5b50-\u78c1\u5b50\u76f8\u4e92\u4f5c\u7528\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u9ad8\u573a\u7535\u5b50\u81ea\u65cb\u5171\u632f\u6280\u672f\uff0c\u5728\u5e73\u884c\u4e8e\u4e09\u89d2\u5f62Mn\u00b2\u207a\u5c42\u7684\u78c1\u573a\u65b9\u5411\u8fdb\u884c\u6d4b\u91cf\uff0c\u5206\u6790\u5171\u632f\u573a\u7684\u5404\u5411\u540c\u6027\u548c\u7ebf\u5bbd\u53d8\u5316\u3002", "result": "\u89c2\u5bdf\u5230\u5355\u4e00\u53cd\u94c1\u78c1\u5171\u632f\u6a21\u5f0f\uff0c\u5177\u6709\u5404\u5411\u540c\u6027\u7684\u6709\u6548g\u56e0\u5b502.01\uff0c\u63a5\u8fd1\u81ea\u7531\u7535\u5b50\u503c\uff1b\u4f4e\u6e29\u4e0b\u7ebf\u5bbd\u4ec5\u7ea650 mT\uff0c\u968f\u6e29\u5ea6\u5347\u9ad8\u663e\u8457\u5c55\u5bbd\u3002", "conclusion": "\u03b1-MnTe\u7684\u53cd\u94c1\u78c1\u5171\u632f\u884c\u4e3a\u8bc1\u5b9e\u4e86Mn\u00b2\u207a\u79bb\u5b50\u7f3a\u4e4f\u8f68\u9053\u52a8\u91cf\uff0c\u5e76\u901a\u8fc7\u7ebf\u5bbd\u7684\u6e29\u5ea6\u4f9d\u8d56\u6027\u6210\u529f\u4f30\u8ba1\u4e86\u78c1\u5b50-\u78c1\u5b50\u76f8\u4e92\u4f5c\u7528\u7684\u5f3a\u5ea6\u3002"}}
{"id": "2510.23632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23632", "abs": "https://arxiv.org/abs/2510.23632", "authors": ["Guozhong Li", "Muhannad Alhumaidi", "Spiros Skiadopoulos", "Panos Kalnis"], "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression", "comment": null, "summary": "The rapid growth of high-resolution scientific simulations and observation\nsystems is generating massive spatiotemporal datasets, making efficient,\nerror-bounded compression increasingly important. Meanwhile, decoder-only large\nlanguage models (LLMs) have demonstrated remarkable capabilities in modeling\ncomplex sequential data. In this paper, we propose LLMCOMP, a novel lossy\ncompression paradigm that leverages decoder-only large LLMs to model scientific\ndata. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via\nZ-order curves to preserve locality, and applies coverage-guided sampling to\nenhance training efficiency. An autoregressive transformer is then trained with\nspatial-temporal embeddings to model token transitions. During compression, the\nmodel performs top-k prediction, storing only rank indices and fallback\ncorrections to ensure strict error bounds. Experiments on multiple reanalysis\ndatasets show that LLMCOMP consistently outperforms state-of-the-art\ncompressors, achieving up to 30% higher compression ratios under strict error\nbounds. These results highlight the potential of LLMs as general-purpose\ncompressors for high-fidelity scientific data.", "AI": {"tldr": "LLMCOMP\u662f\u4e00\u79cd\u57fa\u4e8e\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u79d1\u5b66\u6570\u636e\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c063D\u573a\u91cf\u5316\u4e3a\u79bb\u6563\u6807\u8bb0\u3001\u4f7f\u7528Z-order\u66f2\u7ebf\u4fdd\u6301\u5c40\u90e8\u6027\uff0c\u5e76\u5e94\u7528\u8986\u76d6\u5f15\u5bfc\u91c7\u6837\u6765\u8bad\u7ec3\u81ea\u56de\u5f52\u53d8\u6362\u5668\uff0c\u5728\u4e25\u683c\u8bef\u5dee\u9650\u5236\u4e0b\u5b9e\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad830%\u7684\u538b\u7f29\u6bd4\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387\u79d1\u5b66\u6a21\u62df\u548c\u89c2\u6d4b\u7cfb\u7edf\u4ea7\u751f\u6d77\u91cf\u65f6\u7a7a\u6570\u636e\u96c6\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u6709\u8bef\u5dee\u9650\u5236\u7684\u538b\u7f29\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5efa\u6a21\u590d\u6742\u5e8f\u5217\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u5353\u8d8a\u80fd\u529b\u3002", "method": "\u5c063D\u573a\u91cf\u5316\u4e3a\u79bb\u6563\u6807\u8bb0\uff0c\u901a\u8fc7Z-order\u66f2\u7ebf\u6392\u5217\u4ee5\u4fdd\u6301\u5c40\u90e8\u6027\uff0c\u5e94\u7528\u8986\u76d6\u5f15\u5bfc\u91c7\u6837\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\uff0c\u8bad\u7ec3\u5e26\u6709\u65f6\u7a7a\u5d4c\u5165\u7684\u81ea\u56de\u5f52\u53d8\u6362\u5668\u5efa\u6a21\u6807\u8bb0\u8f6c\u6362\uff0c\u5728\u538b\u7f29\u65f6\u6267\u884ctop-k\u9884\u6d4b\uff0c\u4ec5\u5b58\u50a8\u6392\u540d\u7d22\u5f15\u548c\u56de\u9000\u6821\u6b63\u4ee5\u786e\u4fdd\u4e25\u683c\u8bef\u5dee\u9650\u5236\u3002", "result": "\u5728\u591a\u4e2a\u518d\u5206\u6790\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLLMCOMP\u5728\u4e25\u683c\u8bef\u5dee\u9650\u5236\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u538b\u7f29\u5668\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe30%\u7684\u66f4\u9ad8\u538b\u7f29\u6bd4\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86LLM\u4f5c\u4e3a\u9ad8\u4fdd\u771f\u79d1\u5b66\u6570\u636e\u901a\u7528\u538b\u7f29\u5668\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.23996", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.23996", "abs": "https://arxiv.org/abs/2510.23996", "authors": ["Y. T. Zhu", "Shibei Xue", "Fangfang Ju", "Haidong Yuan"], "title": "Nonreciprocity enhanced Quantum Gyroscopes based on Surface Acoustic Waves", "comment": "Submitted to Physical Review Applied", "summary": "Surface acoustic waves (SAWs), as Rayleigh waves generated by elastic media,\nhave been used in gyroscopes for over 40 years due to their unique propagation\ncharacteristics. However, their working principle, based on Coriolis effects,\nhas become increasingly ineffective for addressing modern sensing challenges in\ncomplex scenarios. Fortunately, recent advancements in quantized SAWs offer a\npromising solution: SAWs operating at extremely low pump powers (approximately\nat the single-phonon level) can exhibit substantial quantum coherence, enabling\ninvestigations into the fundamental limits of SAW gyroscopes as constrained by\nthe Heisenberg uncertainty relation. In particular, when multiple SAWs couple\nto a common waveguide at distinct locations, the nonlocality arising from the\nspatial separation among coupling points induces directional coupling between\nthe SAWs. To elucidate this directionality, we propose a quantum gyroscope\ncharacterized by multiplepoint couplings. Unlike traditional single-point\ncoupling designs, our gyroscope exhibits distinctive time-delayed dynamics that\ndepend on the system's topologies. We emphasize that these dynamics invalidate\nthe Markovian approximation, even when the time delay is relatively small.\nThrough a comprehensive analysis of all possible topologies, we observe that\nthe directional coupling implies an inherent nonreciprocal transfer. This\nnonreciprocity confers signiffcant advantages to our gyroscope compared to\ntraditional designs, notably enhancing both the signal-to-noise ratio and\nsensitivity. Speciffcally, it enables the extraction of output signals that\nwould otherwise be obscured by noise. Consequently, our ffndings suggest that\nsystems with multiple-point couplings and the associated nonreciprocity can\nserve as valuable resources for advancing quantum sensing technologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u70b9\u8026\u5408\u7684\u91cf\u5b50\u9640\u87ba\u4eea\uff0c\u5229\u7528\u8868\u9762\u58f0\u6ce2\u5728\u6781\u4f4e\u6cf5\u6d66\u529f\u7387\u4e0b\u7684\u91cf\u5b50\u76f8\u5e72\u6027\uff0c\u901a\u8fc7\u7a7a\u95f4\u5206\u79bb\u8026\u5408\u70b9\u4ea7\u751f\u7684\u975e\u5c40\u57df\u6027\u5b9e\u73b0\u5b9a\u5411\u8026\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u566a\u6bd4\u548c\u7075\u654f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u79d1\u91cc\u5965\u5229\u6548\u5e94\u7684\u8868\u9762\u58f0\u6ce2\u9640\u87ba\u4eea\u5728\u73b0\u4ee3\u590d\u6742\u4f20\u611f\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u63a2\u7d22\u91cf\u5b50\u6781\u9650\u4e0b\u7684\u65b0\u578b\u4f20\u611f\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u591a\u70b9\u8026\u5408\u91cf\u5b50\u9640\u87ba\u4eea\uff0c\u5229\u7528\u7a7a\u95f4\u5206\u79bb\u8026\u5408\u70b9\u4ea7\u751f\u7684\u975e\u5c40\u57df\u6027\u548c\u65f6\u95f4\u5ef6\u8fdf\u52a8\u529b\u5b66\uff0c\u7a81\u7834\u9a6c\u5c14\u53ef\u592b\u8fd1\u4f3c\u9650\u5236\uff0c\u5b9e\u73b0\u975e\u4e92\u6613\u4f20\u8f93\u3002", "result": "\u591a\u70b9\u8026\u5408\u7cfb\u7edf\u5c55\u73b0\u51fa\u56fa\u6709\u7684\u975e\u4e92\u6613\u4f20\u8f93\u7279\u6027\uff0c\u80fd\u591f\u63d0\u53d6\u88ab\u566a\u58f0\u63a9\u76d6\u7684\u8f93\u51fa\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u9ad8\u4fe1\u566a\u6bd4\u548c\u7075\u654f\u5ea6\u3002", "conclusion": "\u5177\u6709\u591a\u70b9\u8026\u5408\u548c\u76f8\u5173\u975e\u4e92\u6613\u6027\u7684\u7cfb\u7edf\u53ef\u4f5c\u4e3a\u63a8\u8fdb\u91cf\u5b50\u4f20\u611f\u6280\u672f\u7684\u6709\u4ef7\u503c\u8d44\u6e90\u3002"}}
{"id": "2510.24520", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.24520", "abs": "https://arxiv.org/abs/2510.24520", "authors": ["Tanmoy Mondal", "Pinaki Majumdar"], "title": "Crossover from self-trapped bound states to perturbative scattering in the Heisenberg-Kondo lattice model", "comment": "10 pages, 12 figures", "summary": "We map out the complete transport phase diagram of the ferromagnetic\nHeisenberg-Kondo lattice model in two dimensions. The model involves\ntight-binding electrons with hopping $t$, coupled to classical spins with\ncoupling $J'$, while the spins have a nearest neighbour coupling $J$ between\nthem. We work with a fixed, small $J/t$, and study the temperature dependence\nof resistivity for varying electron density $n$ and coupling $J'/t$. Our\nmagnetic configurations are generated by exact diagonalisation-based Langevin\ndynamics, while the conductivity is computed using the Kubo formula on exact\neigenstates. We work on lattices of size $20 \\times 20$ and can access electron\ndensity down to $n \\sim 0.01$. The electron system remains homogeneous either\nwhen the mean density is large or when the coupling $J'$ is small. In these\nsituations, the resistivity $\\rho(T)$ displays a monotonic increase with\ntemperature and can be understood within a perturbative framework. However, at\nvery low density $n \\lesssim 0.05$, strong coupling $J'/t \\gtrsim 1$, and for\n$T \\sim T_c$, the electrons can locally polarise the magnetic state, create a\ntrapping potential, and form a bound state in it. The resistivity associated\nwith this polaronic phase is distinctly non-monotonic, with a peak near $T_c$.\nWe establish the boundary that separates the many-body polaronic window from\ntraditional scattering and extract a universal form for the resistivity in the\nscattering regime. We suggest the origin of the `excess resistivity' in the\npolaronic regime in terms of an increasing fraction of localised states as the\ntemperature tends to $T_c$. This pushes the mobility edge towards the chemical\npotential $\\mu$ and results in enhanced scattering of momentum states near\n$k_F$. While our specific results are in two dimensions, the phenomenology we\nuncover should be valid even in three dimensions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed8\u5236\u4e86\u4e8c\u7ef4\u94c1\u78c1Heisenberg-Kondo\u6676\u683c\u6a21\u578b\u7684\u5b8c\u6574\u8f93\u8fd0\u76f8\u56fe\uff0c\u53d1\u73b0\u5728\u4f4e\u7535\u5b50\u5bc6\u5ea6\u548c\u5f3a\u8026\u5408\u6761\u4ef6\u4e0b\uff0c\u7535\u5b50\u4f1a\u5f62\u6210\u6781\u5316\u5b50\u6001\uff0c\u5bfc\u81f4\u7535\u963b\u7387\u5728\u5c45\u91cc\u6e29\u5ea6\u9644\u8fd1\u51fa\u73b0\u975e\u5355\u8c03\u5cf0\u503c\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u94c1\u78c1Heisenberg-Kondo\u6676\u683c\u6a21\u578b\u5728\u4e0d\u540c\u7535\u5b50\u5bc6\u5ea6\u548c\u8026\u5408\u5f3a\u5ea6\u4e0b\u7684\u8f93\u8fd0\u7279\u6027\uff0c\u7279\u522b\u5173\u6ce8\u4f4e\u5bc6\u5ea6\u5f3a\u8026\u5408\u533a\u57df\u4e2d\u7535\u5b50-\u81ea\u65cb\u76f8\u4e92\u4f5c\u7528\u5bfc\u81f4\u7684\u975e\u4f20\u7edf\u8f93\u8fd0\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7cbe\u786e\u5bf9\u89d2\u5316\u7684Langevin\u52a8\u529b\u5b66\u751f\u6210\u78c1\u6784\u578b\uff0c\u4f7f\u7528Kubo\u516c\u5f0f\u5728\u7cbe\u786e\u672c\u5f81\u6001\u4e0a\u8ba1\u7b97\u7535\u5bfc\u7387\uff0c\u572820\u00d720\u6676\u683c\u4e0a\u7814\u7a76\u6e29\u5ea6\u3001\u7535\u5b50\u5bc6\u5ea6\u548c\u8026\u5408\u5f3a\u5ea6\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u7535\u5b50\u7cfb\u7edf\u5728\u9ad8\u5bc6\u5ea6\u6216\u5f31\u8026\u5408\u65f6\u4fdd\u6301\u5747\u5300\uff0c\u7535\u963b\u7387\u968f\u6e29\u5ea6\u5355\u8c03\u589e\u52a0\uff1b\u800c\u5728\u4f4e\u5bc6\u5ea6\u5f3a\u8026\u5408\u6761\u4ef6\u4e0b\uff0c\u7535\u5b50\u4f1a\u6781\u5316\u78c1\u6001\u5f62\u6210\u675f\u7f1a\u6001\uff0c\u7535\u963b\u7387\u5728\u5c45\u91cc\u6e29\u5ea6\u9644\u8fd1\u51fa\u73b0\u5cf0\u503c\uff0c\u8868\u73b0\u51fa\u6781\u5316\u5b50\u76f8\u7684\u7279\u5f81\u3002", "conclusion": "\u786e\u5b9a\u4e86\u6781\u5316\u5b50\u7a97\u53e3\u4e0e\u4f20\u7edf\u6563\u5c04\u533a\u57df\u7684\u8fb9\u754c\uff0c\u63ed\u793a\u4e86\u6781\u5316\u5b50\u533a\u57df\u4e2d\u8fc7\u5269\u7535\u963b\u7387\u7684\u8d77\u6e90\u662f\u5c40\u57df\u6001\u6bd4\u4f8b\u589e\u52a0\u5bfc\u81f4\u8fc1\u79fb\u7387\u8fb9\u7f18\u5411\u5316\u5b66\u52bf\u79fb\u52a8\uff0c\u589e\u5f3a\u4e86\u8d39\u7c73\u9762\u9644\u8fd1\u52a8\u91cf\u6001\u7684\u6563\u5c04\u3002"}}
{"id": "2510.23633", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.23633", "abs": "https://arxiv.org/abs/2510.23633", "authors": ["Xun Su", "Hiroyuki Kasai"], "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "comment": "9 pages", "summary": "Pretrained diffusion models have demonstrated strong capabilities in\nzero-shot inverse problem solving by incorporating observation information into\nthe generation process of the diffusion models. However, this presents an\ninherent dilemma: excessive integration can disrupt the generative process,\nwhile insufficient integration fails to emphasize the constraints imposed by\nthe inverse problem. To address this, we propose \\emph{Noise Combination\nSampling}, a novel method that synthesizes an optimal noise vector from a noise\nsubspace to approximate the measurement score, replacing the noise term in the\nstandard Denoising Diffusion Probabilistic Models process. This enables\nconditional information to be naturally embedded into the generation process\nwithout reliance on step-wise hyperparameter tuning. Our method can be applied\nto a wide range of inverse problem solvers, including image compression, and,\nparticularly when the number of generation steps $T$ is small, achieves\nsuperior performance with negligible computational overhead, significantly\nimproving robustness and stability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u566a\u58f0\u7ec4\u5408\u91c7\u6837\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6700\u4f18\u566a\u58f0\u5411\u91cf\u6765\u8fd1\u4f3c\u6d4b\u91cf\u5206\u6570\uff0c\u4ece\u800c\u5728\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u8fc7\u7a0b\u4e2d\u81ea\u7136\u5d4c\u5165\u6761\u4ef6\u4fe1\u606f\uff0c\u65e0\u9700\u4f9d\u8d56\u9010\u6b65\u8d85\u53c2\u6570\u8c03\u6574\u3002", "motivation": "\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u5728\u96f6\u6837\u672c\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u4e00\u4e2a\u56fa\u6709\u56f0\u5883\uff1a\u8fc7\u5ea6\u6574\u5408\u4f1a\u7834\u574f\u751f\u6210\u8fc7\u7a0b\uff0c\u800c\u6574\u5408\u4e0d\u8db3\u5219\u65e0\u6cd5\u5f3a\u8c03\u9006\u95ee\u9898\u65bd\u52a0\u7684\u7ea6\u675f\u3002", "method": "\u566a\u58f0\u7ec4\u5408\u91c7\u6837\u65b9\u6cd5\u4ece\u566a\u58f0\u5b50\u7a7a\u95f4\u5408\u6210\u6700\u4f18\u566a\u58f0\u5411\u91cf\u6765\u8fd1\u4f3c\u6d4b\u91cf\u5206\u6570\uff0c\u66ff\u4ee3\u6807\u51c6\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\u9879\uff0c\u4f7f\u6761\u4ef6\u4fe1\u606f\u81ea\u7136\u5d4c\u5165\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u5e7f\u6cdb\u7684\u9006\u95ee\u9898\u6c42\u89e3\u5668\uff0c\u5305\u62ec\u56fe\u50cf\u538b\u7f29\uff0c\u7279\u522b\u662f\u5728\u751f\u6210\u6b65\u9aa4\u6570T\u8f83\u5c0f\u65f6\uff0c\u4ee5\u53ef\u5ffd\u7565\u7684\u8ba1\u7b97\u5f00\u9500\u5b9e\u73b0\u4f18\u8d8a\u6027\u80fd\uff0c\u663e\u8457\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u566a\u58f0\u7ec4\u5408\u91c7\u6837\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u4e2d\u6761\u4ef6\u4fe1\u606f\u6574\u5408\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u9006\u95ee\u9898\u6c42\u89e3\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23881", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23881", "abs": "https://arxiv.org/abs/2510.23881", "authors": ["Xidong Feng", "Vivek Veeriah", "Marcus Chiam", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Federico Barbero", "Johan Obando-Ceron", "Jiaxin Shi", "Satinder Singh", "Shaobo Hou", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Generating Creative Chess Puzzles", "comment": null, "summary": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u57fa\u4e8e\u8c61\u68cb\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u65b0\u578b\u5956\u52b1\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8c1c\u9898\u7684\u72ec\u7279\u6027\u3001\u53cd\u76f4\u89c9\u6027\u3001\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5728\u5404\u4e2a\u9886\u57df\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u751f\u6210\u771f\u6b63\u5177\u6709\u521b\u9020\u6027\u3001\u7f8e\u5b66\u4ef7\u503c\u548c\u53cd\u76f4\u89c9\u6027\u7684\u8f93\u51fa\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u751f\u6210\u9886\u57df\u7684\u8fd9\u4e9b\u56f0\u96be\u3002", "method": "\u9996\u5148\u5bf9\u751f\u6210\u5f0fAI\u67b6\u6784\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7136\u540e\u5f15\u5165\u57fa\u4e8e\u8c61\u68cb\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u589e\u5f3a\u8c1c\u9898\u72ec\u7279\u6027\u3001\u53cd\u76f4\u89c9\u6027\u3001\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u7684\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5c06\u53cd\u76f4\u89c9\u8c1c\u9898\u751f\u6210\u7387\u4ece0.22%\uff08\u76d1\u7763\u5b66\u4e60\uff09\u5927\u5e45\u63d0\u5347\u81f32.5%\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u6570\u636e\u96c6\u6bd4\u7387\uff082.1%\uff09\u548c\u6700\u4f73Lichess\u8bad\u7ec3\u6a21\u578b\uff080.4%\uff09\u3002\u751f\u6210\u7684\u8c1c\u9898\u6ee1\u8db3\u65b0\u9896\u6027\u548c\u591a\u6837\u6027\u57fa\u51c6\uff0c\u4fdd\u7559\u4e86\u7f8e\u5b66\u4e3b\u9898\uff0c\u5e76\u88ab\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4ef7\u4e3a\u6bd4\u7f16\u5199\u4e66\u7c4d\u8c1c\u9898\u66f4\u5177\u521b\u9020\u6027\u3001\u8da3\u5473\u6027\u548c\u53cd\u76f4\u89c9\u6027\uff0c\u751a\u81f3\u63a5\u8fd1\u7ecf\u5178\u4f5c\u54c1\u6c34\u5e73\u3002", "conclusion": "\u6700\u7ec8\u6210\u679c\u662f\u8fd9\u4e9bAI\u751f\u6210\u8c1c\u9898\u7684\u7cbe\u9009\u624b\u518c\uff0c\u5176\u521b\u9020\u6027\u5f97\u5230\u4e86\u4e09\u4f4d\u4e16\u754c\u77e5\u540d\u4e13\u5bb6\u7684\u8ba4\u53ef\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.24047", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24047", "abs": "https://arxiv.org/abs/2510.24047", "authors": ["B. M. Rodriguez-Lara", "H. Ghaemi-Dizicheh", "S. Dehdashti", "A. Hanke", "A. Touhami", "J. N\u00f6tzel"], "title": "Non-Hermitian $\\mathrm{sl}(3, \\mathbb{C})$ three-mode couplers", "comment": "33 pages, 9 figures", "summary": "Photonic systems with exceptional points, where eigenvalues and corresponding\neigenstates coalesce, have attracted interest due to their topological features\nand enhanced sensitivity to external perturbations. Non-Hermitian mode-coupling\nmatrices provide a tractable analytic framework to model gain, loss, and\nchirality across optical, electronic, and mechanical platforms without the\ncomplexity of full open-system dynamics. Exceptional points define their\nspectral topology, and enable applications in mode control, amplification, and\nsensing. Yet $N$-mode couplers, the minimal setting for $N$th-order exceptional\npoints, are often studied in specific designs that overlook their algebraic\nstructure. We introduce a general $\\mathrm{sl}(N,\\mathbb{C})$ framework for\narbitrary $N$-mode couplers in classical and quantum regimes, and develop it\nexplicitly for $N=3$. This case admits algebraic diagonalization, where a\npropagation-dependent gauge aligns local and dynamical spectra and reveals the\ngeometric phase connecting adiabatic and exact propagation. An exact\nWei--Norman propagator captures the full dynamics and makes crossing\nexceptional points explicit. Our framework enables classification of coupler\nfamilies. We study the family spanning $\\mathcal{PT}$-symmetric and\nnon-Hermitian cyclic couplers, where two exceptional points of order three lie\nwithin a continuum of exceptional points of order two, ruling out pure\nencircling. As an application, we study these exceptional points for a lossy\nthree-leg beam splitter and reveal its propagation dynamics as a function of\ninitial states, such as Fock and NOON states. Our approach provides a\nsystematic route to analyze non-Hermitian mode couplers and guide design in\nclassical and quantum platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684sl(N,C)\u6846\u67b6\u6765\u5206\u6790\u4efb\u610fN\u6a21\u8026\u5408\u5668\uff0c\u7279\u522b\u9488\u5bf9N=3\u7684\u60c5\u51b5\u8fdb\u884c\u4e86\u8be6\u7ec6\u7814\u7a76\u3002\u8be5\u6846\u67b6\u80fd\u591f\u5206\u7c7b\u8026\u5408\u5668\u65cf\u7cfb\uff0c\u7814\u7a76\u9ad8\u9636\u5f02\u5e38\u70b9\u7684\u62d3\u6251\u7279\u6027\uff0c\u5e76\u5e94\u7528\u4e8e\u6709\u635f\u4e09\u817f\u5149\u675f\u5206\u79bb\u5668\u7684\u4f20\u64ad\u52a8\u529b\u5b66\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5173\u6ce8\u7279\u5b9a\u8bbe\u8ba1\u7684N\u6a21\u8026\u5408\u5668\uff0c\u800c\u5ffd\u7565\u4e86\u5176\u4ee3\u6570\u7ed3\u6784\u3002\u4e3a\u4e86\u7cfb\u7edf\u5206\u6790\u975e\u5384\u7c73\u6a21\u8026\u5408\u5668\u5e76\u6307\u5bfc\u7ecf\u5178\u548c\u91cf\u5b50\u5e73\u53f0\u7684\u8bbe\u8ba1\uff0c\u9700\u8981\u5efa\u7acb\u901a\u7528\u7684\u4ee3\u6570\u6846\u67b6\u3002", "method": "\u5f15\u5165sl(N,C)\u4ee3\u6570\u6846\u67b6\uff0c\u5bf9N=3\u60c5\u51b5\u8fdb\u884c\u663e\u5f0f\u5f00\u53d1\uff0c\u5305\u62ec\u4ee3\u6570\u5bf9\u89d2\u5316\u3001\u4f20\u64ad\u76f8\u5173\u89c4\u8303\u3001Wei-Norman\u4f20\u64ad\u5b50\u7b49\u65b9\u6cd5\uff0c\u7528\u4e8e\u6355\u83b7\u5b8c\u6574\u52a8\u529b\u5b66\u548c\u5f02\u5e38\u70b9\u4ea4\u53c9\u3002", "result": "\u6210\u529f\u5206\u7c7b\u4e86\u8026\u5408\u5668\u65cf\u7cfb\uff0c\u53d1\u73b0\u5728PT\u5bf9\u79f0\u548c\u975e\u5384\u7c73\u5faa\u73af\u8026\u5408\u5668\u4e2d\uff0c\u4e24\u4e2a\u4e09\u9636\u5f02\u5e38\u70b9\u4f4d\u4e8e\u4e8c\u9636\u5f02\u5e38\u70b9\u7684\u8fde\u7eed\u4f53\u4e2d\uff0c\u6392\u9664\u4e86\u7eaf\u73af\u7ed5\u7684\u53ef\u80fd\u6027\u3002\u5206\u6790\u4e86\u6709\u635f\u4e09\u817f\u5149\u675f\u5206\u79bb\u5668\u7684\u4f20\u64ad\u52a8\u529b\u5b66\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5206\u6790\u975e\u5384\u7c73\u6a21\u8026\u5408\u5668\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8def\u5f84\uff0c\u80fd\u591f\u6307\u5bfc\u7ecf\u5178\u548c\u91cf\u5b50\u5e73\u53f0\u7684\u8bbe\u8ba1\uff0c\u63ed\u793a\u4e86\u5f02\u5e38\u70b9\u7684\u62d3\u6251\u7279\u6027\u548c\u4f20\u64ad\u52a8\u529b\u5b66\u884c\u4e3a\u3002"}}
{"id": "2510.24556", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.24556", "abs": "https://arxiv.org/abs/2510.24556", "authors": ["J. Philippe", "F. Elson", "T. Arh", "S. Sanz", "M. Metzelaars", "D. W. Tam", "O. K. Forslund", "O. Shliakhtun", "C. Jiang", "J. Lass", "M. D. Le", "J. Ollivier", "P. Bouillot", "T. Giamarchi", "M. Bartkowiak", "D. G. Mazzone", "P. K\u00f6gerler", "M. M\u00e5nsson", "A. M. L\u00e4uchli", "Y. Sassa", "M. Janoschek", "B. Normand", "G. Simutis"], "title": "Magnetic and phononic dynamics in the two-ladder quantum magnet (C5H9NH3)2CuBr4", "comment": null, "summary": "In quantum magnetic materials it is common to observe both static and dynamic\nlattice effects on the magnetic excitation spectrum. Less common is to find\nthat the magnetic correlations have a significant impact on the phonon\nspectrum. Can such an interplay occur in a structurally soft system with\ncomparable elastic and magnetic energy scales? Here we study the metal-organic\nmaterial (C5H9NH3)2CuBr4 (Cu-CPA), in which an explanation of the low-lying\nexcitations depends crucially on a full understanding of both the spin and\nlattice subsystems. We report high-resolution neutron spectroscopy enabled by\nlarge, deuterated single-crystals that reveal how both sectors are affected by\nthe recently discovered structural phase transition. By measuring over several\nBrillouin zones, we disentangle the vibrational contribution to the spectrum in\norder to obtain an accurate estimate of the quasi-one-dimensional magnetic\nsignal. The low-energy magnetic excitations are dominated by two gaps, $\\Delta$\nb = 0.41 meV and $\\Delta$ a = 0.55 meV, which contribute with equal intensity\nratios, confirming that Cu-CPA realizes a two-ladder spin Hamiltonian, and we\ndeduce the magnetic interaction parameters of both ladders. The phonon spectrum\ncontains a highly localized mode at an anomalously low-energy around 2 meV.\nThis characteristic frequency drops by approximately 5 percent as magnetic\ncorrelations become established with decreasing temperature, and we connect\nthis behavior with the location and structure of the cyclopentylammonium rings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u9ad8\u5206\u8fa8\u7387\u4e2d\u5b50\u5149\u8c31\u5206\u6790\u91d1\u5c5e\u6709\u673a\u6750\u6599(C5H9NH3)2CuBr4\uff0c\u63ed\u793a\u4e86\u5728\u7ed3\u6784\u8f6f\u7cfb\u7edf\u4e2d\u78c1\u6027\u548c\u6676\u683c\u5b50\u7cfb\u7edf\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\u78c1\u6027\u6fc0\u53d1\u7531\u4e24\u4e2a\u80fd\u9699\u4e3b\u5bfc\uff0c\u786e\u8ba4\u4e86\u53cc\u68af\u5b50\u81ea\u65cb\u54c8\u5bc6\u987f\u91cf\uff0c\u540c\u65f6\u89c2\u5bdf\u5230\u58f0\u5b50\u8c31\u4e2d\u4e00\u4e2a\u9ad8\u5ea6\u5c40\u57df\u5316\u6a21\u5f0f\u968f\u6e29\u5ea6\u964d\u4f4e\u800c\u9891\u7387\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u5728\u7ed3\u6784\u8f6f\u7cfb\u7edf\u4e2d\uff0c\u5f53\u5f39\u6027\u80fd\u548c\u78c1\u6027\u80fd\u91cf\u5c3a\u5ea6\u76f8\u5f53\u65f6\uff0c\u78c1\u5173\u8054\u662f\u5426\u4f1a\u5bf9\u58f0\u5b50\u8c31\u4ea7\u751f\u663e\u8457\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u5927\u5c3a\u5bf8\u6c18\u5316\u5355\u6676\u8fdb\u884c\u9ad8\u5206\u8fa8\u7387\u4e2d\u5b50\u5149\u8c31\u6d4b\u91cf\uff0c\u901a\u8fc7\u6d4b\u91cf\u591a\u4e2a\u5e03\u91cc\u6e0a\u533a\u6765\u5206\u79bb\u632f\u52a8\u8d21\u732e\uff0c\u4ece\u800c\u51c6\u786e\u83b7\u53d6\u51c6\u4e00\u7ef4\u78c1\u4fe1\u53f7\u3002", "result": "\u53d1\u73b0\u4f4e\u80fd\u78c1\u6fc0\u53d1\u7531\u4e24\u4e2a\u80fd\u9699\u0394b=0.41 meV\u548c\u0394a=0.55 meV\u4e3b\u5bfc\uff0c\u5f3a\u5ea6\u6bd4\u76f8\u7b49\uff0c\u786e\u8ba4\u4e86\u53cc\u68af\u5b50\u81ea\u65cb\u54c8\u5bc6\u987f\u91cf\u3002\u58f0\u5b50\u8c31\u5305\u542b\u4e00\u4e2a\u9ad8\u5ea6\u5c40\u57df\u5316\u76842 meV\u4f4e\u80fd\u6a21\u5f0f\uff0c\u8be5\u9891\u7387\u968f\u6e29\u5ea6\u964d\u4f4e\u800c\u4e0b\u964d\u7ea65%\u3002", "conclusion": "Cu-CPA\u5b9e\u73b0\u4e86\u53cc\u68af\u5b50\u81ea\u65cb\u54c8\u5bc6\u987f\u91cf\uff0c\u78c1\u6027\u548c\u6676\u683c\u5b50\u7cfb\u7edf\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u76f8\u4e92\u5f71\u54cd\uff0c\u7279\u522b\u662f\u73af\u620a\u57fa\u94f5\u73af\u7684\u4f4d\u7f6e\u548c\u7ed3\u6784\u5bfc\u81f4\u4e86\u58f0\u5b50\u9891\u7387\u7684\u6e29\u5ea6\u4f9d\u8d56\u6027\u53d8\u5316\u3002"}}
{"id": "2510.23634", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23634", "abs": "https://arxiv.org/abs/2510.23634", "authors": ["Soutrik Sarangi", "Yonatan Sverdlov", "Nadav Dym", "Abir De"], "title": "Monotone and Separable Set Functions: Characterizations and Neural Models", "comment": null, "summary": "Motivated by applications for set containment problems, we consider the\nfollowing fundamental problem: can we design set-to-vector functions so that\nthe natural partial order on sets is preserved, namely $S\\subseteq T \\text{ if\nand only if } F(S)\\leq F(T) $. We call functions satisfying this property\nMonotone and Separating (MAS) set functions. % We establish lower and upper\nbounds for the vector dimension necessary to obtain MAS functions, as a\nfunction of the cardinality of the multisets and the underlying ground set. In\nthe important case of an infinite ground set, we show that MAS functions do not\nexist, but provide a model called our which provably enjoys a relaxed MAS\nproperty we name \"weakly MAS\" and is stable in the sense of Holder continuity.\nWe also show that MAS functions can be used to construct universal models that\nare monotone by construction and can approximate all monotone set functions.\nExperimentally, we consider a variety of set containment tasks. The experiments\nshow the benefit of using our our model, in comparison with standard set models\nwhich do not incorporate set containment as an inductive bias. Our code is\navailable in https://github.com/yonatansverdlov/Monotone-Embedding.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5355\u8c03\u5206\u79bb\u96c6\u5408\u51fd\u6570\u7684\u8bbe\u8ba1\uff0c\u7528\u4e8e\u4fdd\u6301\u96c6\u5408\u5305\u542b\u5173\u7cfb\uff0c\u5efa\u7acb\u4e86\u5411\u91cf\u7ef4\u5ea6\u7684\u4e0a\u4e0b\u754c\uff0c\u63d0\u51fa\u4e86\u5f31MAS\u6a21\u578b\u7528\u4e8e\u65e0\u9650\u57fa\u7840\u96c6\u60c5\u51b5\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u96c6\u5408\u5305\u542b\u4efb\u52a1\u4e2d\u7684\u5b9e\u9a8c\u4f18\u52bf\u3002", "motivation": "\u53d7\u96c6\u5408\u5305\u542b\u95ee\u9898\u5e94\u7528\u7684\u9a71\u52a8\uff0c\u7814\u7a76\u5982\u4f55\u8bbe\u8ba1\u96c6\u5408\u5230\u5411\u91cf\u7684\u51fd\u6570\uff0c\u4f7f\u5f97\u96c6\u5408\u7684\u81ea\u7136\u504f\u5e8f\u5173\u7cfb\u5f97\u4ee5\u4fdd\u6301\uff0c\u5373S\u2286T\u5f53\u4e14\u4ec5\u5f53F(S)\u2264F(T)\u3002", "method": "\u5efa\u7acb\u4e86MAS\u51fd\u6570\u5411\u91cf\u7ef4\u5ea6\u7684\u4e0a\u4e0b\u754c\uff0c\u9488\u5bf9\u65e0\u9650\u57fa\u7840\u96c6\u63d0\u51fa\u4e86\u5f31MAS\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5177\u6709Holder\u8fde\u7eed\u6027\u7a33\u5b9a\u6027\uff0c\u5e76\u6784\u5efa\u4e86\u5355\u8c03\u901a\u7528\u6a21\u578b\u6765\u903c\u8fd1\u6240\u6709\u5355\u8c03\u96c6\u5408\u51fd\u6570\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u65e0\u9650\u57fa\u7840\u96c6\u60c5\u51b5\u4e0bMAS\u51fd\u6570\u4e0d\u5b58\u5728\uff0c\u4f46\u63d0\u51fa\u7684\u5f31MAS\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u96c6\u5408\u5305\u542b\u5173\u7cfb\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728\u96c6\u5408\u5305\u542b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6807\u51c6\u96c6\u5408\u6a21\u578b\u3002", "conclusion": "MAS\u51fd\u6570\u4e3a\u96c6\u5408\u5305\u542b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5f31MAS\u6a21\u578b\u5728\u65e0\u9650\u96c6\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.23882", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23882", "abs": "https://arxiv.org/abs/2510.23882", "authors": ["Adil Rasheed", "Oscar Ravik", "Omer San"], "title": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins", "comment": null, "summary": "This work investigates the use of digital twins for dynamical system modeling\nand control, integrating physics-based, data-driven, and hybrid approaches with\nboth traditional and AI-driven controllers. Using a miniature greenhouse as a\ntest platform, four predictive models Linear, Physics-Based Modeling (PBM),\nLong Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are\ndeveloped and compared under interpolation and extrapolation scenarios. Three\ncontrol strategies Model Predictive Control (MPC), Reinforcement Learning (RL),\nand Large Language Model (LLM) based control are also implemented to assess\ntrade-offs in precision, adaptability, and implementation effort. Results show\nthat in modeling HAM provides the most balanced performance across accuracy,\ngeneralization, and computational efficiency, while LSTM achieves high\nprecision at greater resource cost. Among controllers, MPC delivers robust and\npredictable performance, RL demonstrates strong adaptability, and LLM-based\ncontrollers offer flexible human-AI interaction when coupled with predictive\ntools.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u6570\u5b57\u5b6a\u751f\u5728\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u548c\u63a7\u5236\u4e2d\u7684\u56db\u79cd\u9884\u6d4b\u6a21\u578b\uff08\u7ebf\u6027\u3001\u7269\u7406\u5efa\u6a21\u3001LSTM\u3001HAM\uff09\u548c\u4e09\u79cd\u63a7\u5236\u7b56\u7565\uff08MPC\u3001RL\u3001LLM\u63a7\u5236\uff09\uff0c\u53d1\u73b0\u5728\u5efa\u6a21\u65b9\u9762HAM\u8868\u73b0\u6700\u5747\u8861\uff0c\u5728\u63a7\u5236\u65b9\u9762MPC\u6700\u7a33\u5065\uff0cRL\u9002\u5e94\u6027\u6700\u5f3a\uff0cLLM\u63a7\u5236\u63d0\u4f9b\u7075\u6d3b\u7684\u4eba\u673a\u4ea4\u4e92\u3002", "motivation": "\u7814\u7a76\u6570\u5b57\u5b6a\u751f\u5728\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u548c\u63a7\u5236\u4e2d\u7684\u5e94\u7528\uff0c\u6574\u5408\u7269\u7406\u57fa\u7840\u3001\u6570\u636e\u9a71\u52a8\u548c\u6df7\u5408\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4f20\u7edf\u548cAI\u9a71\u52a8\u63a7\u5236\u5668\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5fae\u578b\u6e29\u5ba4\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5f00\u53d1\u56db\u79cd\u9884\u6d4b\u6a21\u578b\uff08\u7ebf\u6027\u3001PBM\u3001LSTM\u3001HAM\uff09\u548c\u4e09\u79cd\u63a7\u5236\u7b56\u7565\uff08MPC\u3001RL\u3001LLM\u63a7\u5236\uff09\uff0c\u5728\u63d2\u503c\u548c\u5916\u63a8\u573a\u666f\u4e0b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "HAM\u5728\u5efa\u6a21\u4e2d\u63d0\u4f9b\u6700\u5747\u8861\u7684\u6027\u80fd\uff08\u7cbe\u5ea6\u3001\u6cdb\u5316\u3001\u8ba1\u7b97\u6548\u7387\uff09\uff0cLSTM\u7cbe\u5ea6\u9ad8\u4f46\u8d44\u6e90\u6d88\u8017\u5927\uff1bMPC\u63a7\u5236\u5668\u7a33\u5065\u53ef\u9884\u6d4b\uff0cRL\u9002\u5e94\u6027\u5f3a\uff0cLLM\u63a7\u5236\u5668\u7ed3\u5408\u9884\u6d4b\u5de5\u5177\u63d0\u4f9b\u7075\u6d3b\u7684\u4eba\u673a\u4ea4\u4e92\u3002", "conclusion": "HAM\u6a21\u578b\u5728\u5efa\u6a21\u65b9\u9762\u8868\u73b0\u6700\u5747\u8861\uff0cMPC\u63a7\u5236\u5668\u6700\u7a33\u5065\uff0cRL\u63a7\u5236\u5668\u9002\u5e94\u6027\u6700\u5f3a\uff0cLLM\u63a7\u5236\u5668\u4e3a\u4eba\u7c7b\u4e0eAI\u4ea4\u4e92\u63d0\u4f9b\u7075\u6d3b\u6027\uff0c\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u5404\u6709\u4f18\u52bf\u3002"}}
{"id": "2510.24050", "categories": ["quant-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.24050", "abs": "https://arxiv.org/abs/2510.24050", "authors": ["Connor van Rossum", "Sally Shrapnel", "Riddhi Gupta"], "title": "Exploiting biased noise in variational quantum models", "comment": "17 pages, 7 figures", "summary": "Variational quantum algorithms (VQAs) are promising tools for demonstrating\nquantum utility on near-term quantum hardware, with applications in\noptimisation, quantum simulation, and machine learning. While researchers have\nstudied how easy VQAs are to train, the effect of quantum noise on the\nclassical optimisation process is still not well understood. Contrary to\nexpectations, we find that twirling, which is commonly used in standard\nerror-mitigation strategies to symmetrise noise, actually degrades performance\nin the variational setting, whereas preserving biased or non-unital noise can\nhelp classical optimisers find better solutions. Analytically, we study a\nuniversal quantum regression model and demonstrate that relatively uniform\nPauli channels suppress gradient magnitudes and reduce expressivity, making\noptimisation more difficult. Conversely, asymmetric noise such as amplitude\ndamping or biased Pauli channels introduces directional bias that can be\nexploited during optimisation. Numerical experiments on a variational\neigensolver for the transverse-field Ising model confirm that non-unital noise\nyields lower-energy states compared to twirled noise. Finally, we show that\ncoherent errors are fully mitigated by re-parameterisation. These findings\nchallenge conventional noise-mitigation strategies and suggest that preserving\nnoise biases may enhance VQA performance.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u4e2d\uff0c\u4f20\u7edf\u7684\u566a\u58f0\u5bf9\u79f0\u5316\u65b9\u6cd5\uff08\u5982twirling\uff09\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u800c\u4fdd\u7559\u6709\u504f\u566a\u58f0\uff08\u5982\u632f\u5e45\u963b\u5c3c\uff09\u53ef\u80fd\u5e2e\u52a9\u7ecf\u5178\u4f18\u5316\u5668\u627e\u5230\u66f4\u597d\u7684\u89e3\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u566a\u58f0\u5bf9\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u7ecf\u5178\u4f18\u5316\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u6311\u6218\u4f20\u7edf\u7684\u566a\u58f0\u7f13\u89e3\u7b56\u7565\u3002", "method": "\u5206\u6790\u901a\u7528\u91cf\u5b50\u56de\u5f52\u6a21\u578b\uff0c\u7814\u7a76\u4e0d\u540c\u566a\u58f0\u7c7b\u578b\uff08\u5747\u5300\u6ce1\u5229\u901a\u9053\u3001\u975e\u5e7a\u6b63\u566a\u58f0\u7b49\uff09\u5bf9\u68af\u5ea6\u5e45\u5ea6\u548c\u8868\u8fbe\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u6a2a\u5411\u573a\u4f0a\u8f9b\u6a21\u578b\u7684\u53d8\u5206\u672c\u5f81\u6c42\u89e3\u5668\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u76f8\u5bf9\u5747\u5300\u7684\u6ce1\u5229\u901a\u9053\u4f1a\u6291\u5236\u68af\u5ea6\u5e45\u5ea6\u5e76\u964d\u4f4e\u8868\u8fbe\u80fd\u529b\uff0c\u4f7f\u4f18\u5316\u66f4\u56f0\u96be\uff1b\u800c\u975e\u5bf9\u79f0\u566a\u58f0\uff08\u5982\u632f\u5e45\u963b\u5c3c\uff09\u5f15\u5165\u7684\u65b9\u5411\u6027\u504f\u7f6e\u53ef\u5728\u4f18\u5316\u4e2d\u88ab\u5229\u7528\uff0c\u4ea7\u751f\u66f4\u4f4e\u80fd\u91cf\u7684\u72b6\u6001\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6311\u6218\u4e86\u4f20\u7edf\u7684\u566a\u58f0\u7f13\u89e3\u7b56\u7565\uff0c\u8868\u660e\u4fdd\u7559\u566a\u58f0\u504f\u7f6e\u53ef\u80fd\u589e\u5f3a\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2510.24624", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.24624", "abs": "https://arxiv.org/abs/2510.24624", "authors": ["Pius M. Theiler", "Matthew C. Beard"], "title": "Equilibrium Spin Polarization Arising From Chirality", "comment": "17 pages, 3 figures", "summary": "Chirality-induced spin selectivity (CISS) describes how chiral molecules and\nmaterials generate spin polarization even at thermal equilibrium. This\nobservation has challenged established principles of microscopic reversibility\nand Onsager reciprocity. We resolve this paradox by formulating a\npseudo-Hermitian quantum framework in which structural chirality and electron\ncorrelations are sufficient to produce CISS observables. Chirality enters\nthrough a non-local metric that couples spin and spatial motion, leading to\nreal spectra, unitary evolution, and thermodynamic consistency. The framework\npredicts a chirality-induced spin magnetic ordering characterized by a\nspin--displacement order $\\langle \\sigma \\cdot x \\rangle$, which reconciles\nequilibrium spin polarization with detailed balance and explains the\npersistence of CISS in materials composed of light elements. We also derive\ngeneralized Onsager-Casimir relations that respect the observed parity\n($\\mathcal{P}$) and time-reversal ($\\mathcal{T}$) breaking, while preserving\ncombined $\\mathcal{PT}$-symmetry. This approach establishes a coherent\nfoundation for equilibrium CISS and provides a route to link chemical chirality\nwith measurable spin-to-charge conversion effects.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f2a\u5384\u7c73\u91cf\u5b50\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u624b\u6027\u8bf1\u5bfc\u81ea\u65cb\u9009\u62e9\u6027\uff08CISS\uff09\u4e0e\u5fae\u89c2\u53ef\u9006\u6027\u548c\u6602\u8428\u683c\u4e92\u6613\u6027\u4e4b\u95f4\u7684\u6096\u8bba\uff0c\u9884\u6d4b\u4e86\u624b\u6027\u8bf1\u5bfc\u7684\u81ea\u65cb\u78c1\u6709\u5e8f\uff0c\u5e76\u63a8\u5bfc\u4e86\u5e7f\u4e49\u7684\u6602\u8428\u683c-\u5361\u897f\u7c73\u5c14\u5173\u7cfb\u3002", "motivation": "\u624b\u6027\u8bf1\u5bfc\u81ea\u65cb\u9009\u62e9\u6027\uff08CISS\uff09\u73b0\u8c61\u5728\u70ed\u5e73\u8861\u4e0b\u4ea7\u751f\u81ea\u65cb\u6781\u5316\uff0c\u8fd9\u4e0e\u5fae\u89c2\u53ef\u9006\u6027\u548c\u6602\u8428\u683c\u4e92\u6613\u6027\u7b49\u57fa\u672c\u539f\u7406\u76f8\u77db\u76fe\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u6096\u8bba\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u4f2a\u5384\u7c73\u91cf\u5b50\u6846\u67b6\uff0c\u5176\u4e2d\u7ed3\u6784\u624b\u6027\u548c\u7535\u5b50\u5173\u8054\u901a\u8fc7\u975e\u5c40\u57df\u5ea6\u89c4\u8026\u5408\u81ea\u65cb\u548c\u7a7a\u95f4\u8fd0\u52a8\uff0c\u4ea7\u751f\u5b9e\u8c31\u3001\u5e7a\u6b63\u6f14\u5316\u548c\u70ed\u529b\u5b66\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u6846\u67b6\u9884\u6d4b\u4e86\u624b\u6027\u8bf1\u5bfc\u7684\u81ea\u65cb\u78c1\u6709\u5e8f\uff0c\u8868\u73b0\u4e3a\u81ea\u65cb-\u4f4d\u79fb\u5e8f\u53c2\u91cf\u27e8\u03c3\u00b7x\u27e9\uff0c\u5e76\u63a8\u5bfc\u4e86\u4fdd\u6301\u5b87\u79f0\u548c\u65f6\u95f4\u53cd\u6f14\u5bf9\u79f0\u6027\u7834\u7f3a\u4f46\u4fdd\u7559\u8054\u5408PT\u5bf9\u79f0\u6027\u7684\u5e7f\u4e49\u6602\u8428\u683c-\u5361\u897f\u7c73\u5c14\u5173\u7cfb\u3002", "conclusion": "\u8fd9\u4e00\u65b9\u6cd5\u4e3a\u5e73\u8861\u6001CISS\u5efa\u7acb\u4e86\u8fde\u8d2f\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u5c06\u5316\u5b66\u624b\u6027\u4e0e\u53ef\u6d4b\u91cf\u7684\u81ea\u65cb-\u7535\u8377\u8f6c\u6362\u6548\u5e94\u8054\u7cfb\u8d77\u6765\u7684\u9014\u5f84\u3002"}}
{"id": "2510.23635", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23635", "abs": "https://arxiv.org/abs/2510.23635", "authors": ["Andrea Bontempelli", "Matteo Busso", "Leonardo Javier Malcotti", "Fausto Giunchiglia"], "title": "Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning", "comment": null, "summary": "Any digital personal assistant, whether used to support task performance,\nanswer questions, or manage work and daily life, including fitness schedules,\nrequires high-quality annotations to function properly. However, user\nannotations, whether actively produced or inferred from context (e.g., data\nfrom smartphone sensors), are often subject to errors and noise. Previous\nresearch on Skeptical Learning (SKEL) addressed the issue of noisy labels by\ncomparing offline active annotations with passive data, allowing for an\nevaluation of annotation accuracy. However, this evaluation did not include\nconfirmation from end-users, the best judges of their own context. In this\nstudy, we evaluate SKEL's performance in real-world conditions with actual\nusers who can refine the input labels based on their current perspectives and\nneeds. The study involves university students using the iLog mobile application\non their devices over a period of four weeks. The results highlight the\nchallenges of finding the right balance between user effort and data quality,\nas well as the potential benefits of using SKEL, which include reduced\nannotation effort and improved quality of collected data.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86Skeptical Learning\uff08SKEL\uff09\u5728\u771f\u5b9e\u7528\u6237\u73af\u5883\u4e0b\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u5927\u5b66\u5b66\u751f\u4f7f\u7528iLog\u79fb\u52a8\u5e94\u7528\u8fdb\u884c\u4e3a\u671f\u56db\u5468\u7684\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86SKEL\u5728\u51cf\u5c11\u6807\u6ce8\u5de5\u4f5c\u91cf\u548c\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u6570\u5b57\u4e2a\u4eba\u52a9\u7406\u9700\u8981\u9ad8\u8d28\u91cf\u6807\u6ce8\u6765\u6b63\u5e38\u5de5\u4f5c\uff0c\u4f46\u7528\u6237\u6807\u6ce8\u5e38\u5b58\u5728\u9519\u8bef\u548c\u566a\u58f0\u3002\u5148\u524d\u7814\u7a76\u901a\u8fc7\u6bd4\u8f83\u79bb\u7ebf\u4e3b\u52a8\u6807\u6ce8\u4e0e\u88ab\u52a8\u6570\u636e\u6765\u8bc4\u4f30\u6807\u6ce8\u51c6\u786e\u6027\uff0c\u4f46\u7f3a\u4e4f\u6700\u7ec8\u7528\u6237\u7684\u786e\u8ba4\u3002", "method": "\u5728\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u8bc4\u4f30SKEL\u6027\u80fd\uff0c\u8ba9\u5b9e\u9645\u7528\u6237\u57fa\u4e8e\u5f53\u524d\u89c6\u89d2\u548c\u9700\u6c42\u7cbe\u70bc\u8f93\u5165\u6807\u7b7e\u3002\u7814\u7a76\u6d89\u53ca\u5927\u5b66\u5b66\u751f\u4f7f\u7528iLog\u79fb\u52a8\u5e94\u7528\uff0c\u4e3a\u671f\u56db\u5468\u3002", "result": "\u7ed3\u679c\u7a81\u663e\u4e86\u5728\u7528\u6237\u52aa\u529b\u4e0e\u6570\u636e\u8d28\u91cf\u4e4b\u95f4\u627e\u5230\u9002\u5f53\u5e73\u8861\u7684\u6311\u6218\uff0c\u4ee5\u53ca\u4f7f\u7528SKEL\u7684\u6f5c\u5728\u597d\u5904\uff0c\u5305\u62ec\u51cf\u5c11\u6807\u6ce8\u52aa\u529b\u548c\u63d0\u9ad8\u6536\u96c6\u6570\u636e\u8d28\u91cf\u3002", "conclusion": "SKEL\u5728\u771f\u5b9e\u7528\u6237\u73af\u5883\u4e2d\u663e\u793a\u51fa\u51cf\u5c11\u6807\u6ce8\u5de5\u4f5c\u91cf\u548c\u6539\u5584\u6570\u636e\u8d28\u91cf\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u5728\u7528\u6237\u52aa\u529b\u4e0e\u6570\u636e\u8d28\u91cf\u4e4b\u95f4\u627e\u5230\u9002\u5f53\u5e73\u8861\u3002"}}
{"id": "2510.23883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23883", "abs": "https://arxiv.org/abs/2510.23883", "authors": ["Shrestha Datta", "Shahriar Kabir Nahin", "Anshuman Chhabra", "Prasant Mohapatra"], "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges", "comment": null, "summary": "Agentic AI systems powered by large language models (LLMs) and endowed with\nplanning, tool use, memory, and autonomy, are emerging as powerful, flexible\nplatforms for automation. Their ability to autonomously execute tasks across\nweb, software, and physical environments creates new and amplified security\nrisks, distinct from both traditional AI safety and conventional software\nsecurity. This survey outlines a taxonomy of threats specific to agentic AI,\nreviews recent benchmarks and evaluation methodologies, and discusses defense\nstrategies from both technical and governance perspectives. We synthesize\ncurrent research and highlight open challenges, aiming to support the\ndevelopment of secure-by-design agent systems.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fdAI\u7cfb\u7edf\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u5a01\u80c1\u5206\u7c7b\u6cd5\uff0c\u56de\u987e\u4e86\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u6280\u672f\u548c\u6cbb\u7406\u5c42\u9762\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u968f\u7740\u5177\u5907\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u3001\u8bb0\u5fc6\u548c\u81ea\u4e3b\u80fd\u529b\u7684\u667a\u80fdAI\u7cfb\u7edf\u5728\u81ea\u52a8\u5316\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5b83\u4eec\u5e26\u6765\u4e86\u4e0e\u4f20\u7edfAI\u5b89\u5168\u548c\u8f6f\u4ef6\u5b89\u5168\u4e0d\u540c\u7684\u65b0\u578b\u653e\u5927\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u548c\u5e94\u5bf9\u8fd9\u4e9b\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u667a\u80fdAI\u7279\u6709\u7684\u5a01\u80c1\u5206\u7c7b\u6cd5\uff0c\u56de\u987e\u8fd1\u671f\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ece\u6280\u672f\u548c\u6cbb\u7406\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u9632\u5fa1\u7b56\u7565\uff0c\u7efc\u5408\u5f53\u524d\u7814\u7a76\u5e76\u7a81\u51fa\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002", "result": "\u5efa\u7acb\u4e86\u667a\u80fdAI\u5b89\u5168\u5a01\u80c1\u7684\u7cfb\u7edf\u6027\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u8bc4\u4f30\u65b9\u6cd5\u7684\u5173\u952e\u8fdb\u5c55\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u5c42\u6b21\u9632\u5fa1\u7b56\u7565\uff0c\u4e3a\u5b89\u5168\u8bbe\u8ba1\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u667a\u80fdAI\u7cfb\u7edf\u521b\u9020\u4e86\u72ec\u7279\u7684\u5b89\u5168\u6311\u6218\uff0c\u9700\u8981\u5b89\u5168\u4f18\u5148\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6280\u672f\u9632\u62a4\u548c\u6cbb\u7406\u6846\u67b6\u7684\u7ed3\u5408\u6765\u786e\u4fdd\u5176\u5b89\u5168\u90e8\u7f72\uff0c\u5f53\u524d\u7814\u7a76\u4e3a\u6784\u5efa\u5b89\u5168\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4f46\u4ecd\u6709\u8bb8\u591a\u5f00\u653e\u6027\u95ee\u9898\u9700\u8981\u89e3\u51b3\u3002"}}
{"id": "2510.24686", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.24686", "abs": "https://arxiv.org/abs/2510.24686", "authors": ["Hari Padma", "Prakash Sharma", "Sophia F. R. TenHuisen", "Filippo Glerean", "Antoine Roll", "Pan Zhou", "Sarbajaya Kundu", "Arnau Romaguera", "Elizabeth Skoropata", "Hiroki Ueda", "Biaolong Liu", "Eugenio Paris", "Yu Wang", "Seng Huat Lee", "Zhiqiang Mao", "Mark P. M. Dean", "Edwin W. Huang", "Elia Razzoli", "Yao Wang", "Matteo Mitrano"], "title": "A light-induced charge order mode in a metastable cuprate ladder", "comment": "Main Text with 8 pages, 3 figures, and Supplementary Material with 13\n  pages, 7 figures", "summary": "We report the observation of an emergent charge order mode in the\noptically-excited cuprate ladder Sr$_{14}$Cu$_{24}$O$_{41}$. Near-infrared\nlight in the ladder plane drives a symmetry-protected electronic metastable\nstate together with a partial melting of the equilibrium charge order. Our\ntime-resolved resonant inelastic x-ray scattering measurements at the upper\nHubbard band reveal a gapless collective excitation dispersing from the\ncharge-order wavevector up to 0.8 eV with a slope on the order of the\nquasiparticle velocity. These findings reveal a regime where correlated\ncarriers acquire itinerant character at finite momentum, and charge order\nbecomes dynamically fluctuating, offering a platform to explore light-induced\npairing instabilities.", "AI": {"tldr": "\u5728\u5149\u5b66\u6fc0\u53d1\u7684\u94dc\u9178\u76d0\u68af\u5b50Sr14Cu24O41\u4e2d\u89c2\u5bdf\u5230\u4e00\u79cd\u6d8c\u73b0\u7684\u7535\u8377\u6709\u5e8f\u6a21\u5f0f\uff0c\u8fd1\u7ea2\u5916\u5149\u9a71\u52a8\u5bf9\u79f0\u6027\u4fdd\u62a4\u7684\u7535\u5b50\u4e9a\u7a33\u6001\uff0c\u540c\u65f6\u90e8\u5206\u7194\u5316\u5e73\u8861\u7535\u8377\u6709\u5e8f\u3002\u65f6\u95f4\u5206\u8fa8\u5171\u632f\u975e\u5f39\u6027X\u5c04\u7ebf\u6563\u5c04\u6d4b\u91cf\u63ed\u793a\u4e86\u4ece\u7535\u8377\u6709\u5e8f\u6ce2\u77e2\u91cf\u52300.8 eV\u7684\u65e0\u80fd\u9699\u96c6\u4f53\u6fc0\u53d1\uff0c\u659c\u7387\u4e3a\u51c6\u7c92\u5b50\u901f\u5ea6\u91cf\u7ea7\u3002", "motivation": "\u63a2\u7d22\u5149\u6fc0\u53d1\u4e0b\u94dc\u9178\u76d0\u6750\u6599\u4e2d\u7535\u8377\u6709\u5e8f\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u7814\u7a76\u76f8\u5173\u8f7d\u6d41\u5b50\u5728\u6709\u9650\u52a8\u91cf\u4e0b\u83b7\u5f97\u5de1\u6e38\u7279\u6027\u7684\u673a\u5236\uff0c\u4e3a\u63a2\u7d22\u5149\u8bf1\u5bfc\u914d\u5bf9\u4e0d\u7a33\u5b9a\u6027\u63d0\u4f9b\u5e73\u53f0\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u5206\u8fa8\u5171\u632f\u975e\u5f39\u6027X\u5c04\u7ebf\u6563\u5c04\u6280\u672f\uff0c\u5728\u94dc\u9178\u76d0\u68af\u5b50Sr14Cu24O41\u7684\u4e0a\u54c8\u4f2f\u5fb7\u5e26\u8fdb\u884c\u6d4b\u91cf\uff0c\u5206\u6790\u8fd1\u7ea2\u5916\u5149\u6fc0\u53d1\u540e\u7684\u7535\u8377\u6709\u5e8f\u52a8\u6001\u3002", "result": "\u89c2\u5bdf\u5230\u4ece\u7535\u8377\u6709\u5e8f\u6ce2\u77e2\u91cf\u52300.8 eV\u7684\u65e0\u80fd\u9699\u96c6\u4f53\u6fc0\u53d1\uff0c\u659c\u7387\u7ea6\u4e3a\u51c6\u7c92\u5b50\u901f\u5ea6\u91cf\u7ea7\uff0c\u8868\u660e\u7535\u8377\u6709\u5e8f\u53d8\u4e3a\u52a8\u6001\u6da8\u843d\u72b6\u6001\uff0c\u76f8\u5173\u8f7d\u6d41\u5b50\u5728\u6709\u9650\u52a8\u91cf\u4e0b\u83b7\u5f97\u5de1\u6e38\u7279\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5149\u6fc0\u53d1\u4e0b\u7535\u8377\u6709\u5e8f\u7684\u52a8\u6001\u6da8\u843d\u673a\u5236\uff0c\u4e3a\u63a2\u7d22\u76f8\u5173\u7535\u5b50\u7cfb\u7edf\u4e2d\u5149\u8bf1\u5bfc\u914d\u5bf9\u4e0d\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u5b9e\u9a8c\u5e73\u53f0\u548c\u7269\u7406\u89c1\u89e3\u3002"}}
{"id": "2510.23925", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23925", "abs": "https://arxiv.org/abs/2510.23925", "authors": ["Guohao Sun", "Hang Hua", "Jian Wang", "Jiebo Luo", "Sohail Dianat", "Majid Rabbani", "Raghuveer Rao", "Zhiqiang Tao"], "title": "Latent Chain-of-Thought for Visual Reasoning", "comment": "NeurIPS 2025", "summary": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u63a8\u7406\u7684\u94fe\u5f0f\u601d\u7ef4\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u5956\u52b1\u51fd\u6570\u548c\u8d1d\u53f6\u65af\u63a8\u7406\u6269\u5c55\u7b56\u7565\uff0c\u63d0\u5347\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3001\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u7b97\u6cd5\uff08\u5982SFT\u3001PPO\u3001GRPO\uff09\u5728\u672a\u89c1\u8fc7\u63a8\u7406\u4efb\u52a1\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u4e14\u8fc7\u5ea6\u4f9d\u8d56\u6709\u504f\u7684\u5956\u52b1\u6a21\u578b\uff0c\u9650\u5236\u4e86\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u7684\u53d1\u5c55\u3002", "method": "\u5c06LVLMs\u4e2d\u7684\u63a8\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u540e\u9a8c\u63a8\u7406\uff0c\u57fa\u4e8e\u644a\u9500\u53d8\u5206\u63a8\u7406\u63d0\u51fa\u53ef\u6269\u5c55\u8bad\u7ec3\u7b97\u6cd5\uff0c\u4f7f\u7528\u591a\u6837\u6027\u5bfb\u6c42\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8bbe\u8ba1\u7a00\u758f\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u91c7\u7528\u8d1d\u53f6\u65af\u63a8\u7406\u6269\u5c55\u7b56\u7565\u66ff\u4ee3\u6602\u8d35\u7684\u641c\u7d22\u65b9\u6cd5\u3002", "result": "\u5728\u4e03\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6700\u5148\u8fdbLVLMs\u7684\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u53d8\u5206\u63a8\u7406\u6846\u67b6\u548c\u7a00\u758f\u5956\u52b1\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8bad\u7ec3\u7b97\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24082", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24082", "abs": "https://arxiv.org/abs/2510.24082", "authors": ["Yanjun Ji", "Susanna Kirchhoff", "Frank K. Wilhelm"], "title": "Exploring the Fidelity of Flux Qubit Measurement in Different Bases via Quantum Flux Parametron", "comment": null, "summary": "High-fidelity qubit readout is a fundamental requirement for practical\nquantum computing systems. In this work, we investigate methods to enhance the\nmeasurement fidelity of flux qubits via a quantum flux parametron-mediated\nreadout scheme. Through theoretical modeling and numerical simulations, we\nanalyze the impact of different measurement bases on fidelity in single-qubit\nand coupled two-qubit systems. For single-qubit systems, we show that energy\nbases consistently outperform flux bases in achieving higher fidelity. In\ncoupled two-qubit systems, we explore two measurement models: sequential and\nsimultaneous measurements, both aimed at reading out a single target qubit. Our\nresults indicate that the highest fidelity can be achieved either by performing\nsequential measurement in a dressed basis over a longer duration or by\nconducting simultaneous measurement in a bare basis over a shorter duration.\nImportantly, the sequential measurement model consistently yields more robust\nand higher fidelity readouts compared to the simultaneous approach. These\nfindings quantify achievable fidelities and provide valuable guidance for\noptimizing measurement protocols in emerging quantum computing architectures.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u91cf\u5b50\u901a\u91cf\u53c2\u91cf\u5668\u4ecb\u5bfc\u7684\u8bfb\u53d6\u65b9\u6848\u6765\u63d0\u9ad8\u901a\u91cf\u91cf\u5b50\u6bd4\u7279\u6d4b\u91cf\u4fdd\u771f\u5ea6\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u5728\u5355\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\u80fd\u91cf\u57fa\u4f18\u4e8e\u901a\u91cf\u57fa\uff0c\u5728\u4e24\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\u987a\u5e8f\u6d4b\u91cf\u6bd4\u540c\u65f6\u6d4b\u91cf\u80fd\u83b7\u5f97\u66f4\u7a33\u5065\u548c\u66f4\u9ad8\u7684\u4fdd\u771f\u5ea6\u3002", "motivation": "\u9ad8\u4fdd\u771f\u5ea6\u7684\u91cf\u5b50\u6bd4\u7279\u8bfb\u53d6\u662f\u5b9e\u7528\u91cf\u5b50\u8ba1\u7b97\u7cfb\u7edf\u7684\u57fa\u672c\u8981\u6c42\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u91cf\u5b50\u901a\u91cf\u53c2\u91cf\u5668\u4ecb\u5bfc\u7684\u8bfb\u53d6\u65b9\u6848\u6765\u63d0\u9ad8\u901a\u91cf\u91cf\u5b50\u6bd4\u7279\u7684\u6d4b\u91cf\u4fdd\u771f\u5ea6\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5efa\u6a21\u548c\u6570\u503c\u6a21\u62df\uff0c\u5206\u6790\u4e0d\u540c\u6d4b\u91cf\u57fa\u5bf9\u5355\u91cf\u5b50\u6bd4\u7279\u548c\u8026\u5408\u4e24\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4fdd\u771f\u5ea6\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u987a\u5e8f\u6d4b\u91cf\u548c\u540c\u65f6\u6d4b\u91cf\u4e24\u79cd\u6a21\u578b\u3002", "result": "\u5728\u5355\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\uff0c\u80fd\u91cf\u57fa\u59cb\u7ec8\u6bd4\u901a\u91cf\u57fa\u83b7\u5f97\u66f4\u9ad8\u4fdd\u771f\u5ea6\uff1b\u5728\u4e24\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u4e2d\uff0c\u987a\u5e8f\u6d4b\u91cf\u5728\u8f83\u957f\u65f6\u95f4\u5185\u4f7f\u7528\u4fee\u9970\u57fa\u6216\u540c\u65f6\u6d4b\u91cf\u5728\u8f83\u77ed\u65f6\u95f4\u5185\u4f7f\u7528\u88f8\u57fa\u90fd\u80fd\u83b7\u5f97\u6700\u9ad8\u4fdd\u771f\u5ea6\uff0c\u4f46\u987a\u5e8f\u6d4b\u91cf\u6a21\u578b\u59cb\u7ec8\u80fd\u4ea7\u751f\u66f4\u7a33\u5065\u548c\u66f4\u9ad8\u7684\u4fdd\u771f\u5ea6\u8bfb\u53d6\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u91cf\u5316\u4e86\u53ef\u5b9e\u73b0\u7684\u4fdd\u771f\u5ea6\uff0c\u4e3a\u65b0\u5174\u91cf\u5b50\u8ba1\u7b97\u67b6\u6784\u4e2d\u4f18\u5316\u6d4b\u91cf\u534f\u8bae\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.23942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23942", "abs": "https://arxiv.org/abs/2510.23942", "authors": ["Sridhar Mahadevan"], "title": "Decentralized Causal Discovery using Judo Calculus", "comment": "54 pages", "summary": "We describe a theory and implementation of an intuitionistic decentralized\nframework for causal discovery using judo calculus, which is formally defined\nas j-stable causal inference using j-do-calculus in a topos of sheaves. In\nreal-world applications -- from biology to medicine and social science --\ncausal effects depend on regime (age, country, dose, genotype, or lab\nprotocol). Our proposed judo calculus formalizes this context dependence\nformally as local truth: a causal claim is proven true on a cover of regimes,\nnot everywhere at once. The Lawvere-Tierney modal operator j chooses which\nregimes are relevant; j-stability means the claim holds constructively and\nconsistently across that family. We describe an algorithmic and implementation\nframework for judo calculus, combining it with standard score-based,\nconstraint-based, and gradient-based causal discovery methods. We describe\nexperimental results on a range of domains, from synthetic to real-world\ndatasets from biology and economics. Our experimental results show the\ncomputational efficiency gained by the decentralized nature of sheaf-theoretic\ncausal discovery, as well as improved performance over classical causal\ndiscovery methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f4\u89c9\u4e3b\u4e49\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\u7684\u56e0\u679c\u53d1\u73b0\u7406\u8bba\u2014\u2014judo\u6f14\u7b97\uff0c\u8be5\u6f14\u7b97\u5728\u5c42\u62d3\u6251\u4e2d\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86j-\u7a33\u5b9a\u56e0\u679c\u63a8\u65ad\uff0c\u80fd\u591f\u5904\u7406\u73b0\u5b9e\u5e94\u7528\u4e2d\u56e0\u679c\u6548\u5e94\u968f\u73af\u5883\u53d8\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\uff08\u4ece\u751f\u7269\u5b66\u5230\u533b\u5b66\u548c\u793e\u4f1a\u79d1\u5b66\uff09\uff0c\u56e0\u679c\u6548\u5e94\u901a\u5e38\u4f9d\u8d56\u4e8e\u7279\u5b9a\u73af\u5883\uff08\u5982\u5e74\u9f84\u3001\u56fd\u5bb6\u3001\u5242\u91cf\u3001\u57fa\u56e0\u578b\u6216\u5b9e\u9a8c\u5ba4\u534f\u8bae\uff09\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5f62\u5f0f\u5316\u5904\u7406\u8fd9\u79cd\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528judo\u6f14\u7b97\u7ed3\u5408\u6807\u51c6\u57fa\u4e8e\u5206\u6570\u3001\u7ea6\u675f\u548c\u68af\u5ea6\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\uff0c\u901a\u8fc7Lawvere-Tierney\u6a21\u6001\u7b97\u5b50j\u9009\u62e9\u76f8\u5173\u73af\u5883\uff0c\u5b9e\u73b0j-\u7a33\u5b9a\u6027\u56e0\u679c\u63a8\u65ad\u3002", "result": "\u5728\u4ece\u5408\u6210\u5230\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff08\u751f\u7269\u5b66\u548c\u7ecf\u6d4e\u5b66\uff09\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u5c42\u62d3\u6251\u7684\u56e0\u679c\u53d1\u73b0\u5177\u6709\u8ba1\u7b97\u6548\u7387\u4f18\u52bf\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u7ecf\u5178\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u3002", "conclusion": "judo\u6f14\u7b97\u4e3a\u5904\u7406\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u7684\u5c42\u62d3\u6251\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u7684\u63d0\u5347\u548c\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2510.24099", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24099", "abs": "https://arxiv.org/abs/2510.24099", "authors": ["S. McKay", "S. R. Parnell", "R. M. Dalgliesh", "N. V. Lavrik", "I. I. Kravchenko", "Q. Le Thien", "D. V. Baxter", "G. Ortiz", "R. Pynn"], "title": "Topological shaping of vortex neutron beams using forked phase gratings", "comment": null, "summary": "Beams of light or matter that carry well-defined states of orbital angular\nmomentum (OAM) are promising probes of topological and textured condensed\nmatter systems such as magnetic skyrmions. Using spin-echo small-angle neutron\nscattering (SESANS), we demonstrate the production of vortex neutron beams from\nforked phase gratings of various topological charges. In contrast to some\nprevious techniques used to verify OAM production, SESANS is a more precise\nmeasurement of the neutron's OAM as it is a phase-sensitive, interferometric\ntechnique that directly measures the phase between the scattered neutron spin\nstates.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u81ea\u65cb\u56de\u6ce2\u5c0f\u89d2\u4e2d\u5b50\u6563\u5c04(SESANS)\u6280\u672f\uff0c\u901a\u8fc7\u53c9\u5f62\u76f8\u4f4d\u5149\u6805\u4ea7\u751f\u4e86\u5177\u6709\u8f68\u9053\u89d2\u52a8\u91cf(OAM)\u7684\u6da1\u65cb\u4e2d\u5b50\u675f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u62d3\u6251\u7535\u8377\u7279\u6027\u3002", "motivation": "\u643a\u5e26\u660e\u786e\u8f68\u9053\u89d2\u52a8\u91cf\u72b6\u6001\u7684\u5149\u675f\u6216\u7269\u8d28\u675f\u662f\u63a2\u6d4b\u62d3\u6251\u548c\u7eb9\u7406\u51dd\u805a\u6001\u7269\u8d28\u7cfb\u7edf\uff08\u5982\u78c1\u6027\u65af\u683c\u660e\u5b50\uff09\u7684\u6709\u524d\u9014\u63a2\u9488\u3002", "method": "\u4f7f\u7528\u81ea\u65cb\u56de\u6ce2\u5c0f\u89d2\u4e2d\u5b50\u6563\u5c04(SESANS)\u6280\u672f\uff0c\u901a\u8fc7\u53c9\u5f62\u76f8\u4f4d\u5149\u6805\u4ea7\u751f\u4e0d\u540c\u62d3\u6251\u7535\u8377\u7684\u6da1\u65cb\u4e2d\u5b50\u675f\u3002", "result": "\u6210\u529f\u4ea7\u751f\u4e86\u5177\u6709\u8f68\u9053\u89d2\u52a8\u91cf\u7684\u6da1\u65cb\u4e2d\u5b50\u675f\uff0cSESANS\u6280\u672f\u80fd\u591f\u7cbe\u786e\u6d4b\u91cf\u4e2d\u5b50\u7684OAM\uff0c\u56e0\u4e3a\u5b83\u662f\u4e00\u79cd\u76f8\u4f4d\u654f\u611f\u7684\u5e72\u6d89\u6280\u672f\uff0c\u76f4\u63a5\u6d4b\u91cf\u6563\u5c04\u4e2d\u5b50\u81ea\u65cb\u6001\u4e4b\u95f4\u7684\u76f8\u4f4d\u3002", "conclusion": "SESANS\u6280\u672f\u76f8\u6bd4\u4e4b\u524d\u7684\u9a8c\u8bc1\u65b9\u6cd5\u66f4\u7cbe\u786e\uff0c\u4e3a\u7814\u7a76\u62d3\u6251\u6750\u6599\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6d4b\u91cf\u624b\u6bb5\u3002"}}
{"id": "2510.23639", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.23639", "abs": "https://arxiv.org/abs/2510.23639", "authors": ["Jonathan Amar", "Edward Liu", "Alessandra Breschi", "Liangliang Zhang", "Pouya Kheradpour", "Sylvia Li", "Lisa Soleymani Lehmann", "Alessandro Giulianelli", "Matt Edwards", "Yugang Jia", "David Nola", "Raghav Mani", "Pankaj Vats", "Jesse Tetreault", "T. J. Chen", "Cory Y. McLean"], "title": "Integrating Genomics into Multimodal EHR Foundation Models", "comment": null, "summary": "This paper introduces an innovative Electronic Health Record (EHR) foundation\nmodel that integrates Polygenic Risk Scores (PRS) as a foundational data\nmodality, moving beyond traditional EHR-only approaches to build more holistic\nhealth profiles. Leveraging the extensive and diverse data from the All of Us\n(AoU) Research Program, this multimodal framework aims to learn complex\nrelationships between clinical data and genetic predispositions. The\nmethodology extends advancements in generative AI to the EHR foundation model\nspace, enhancing predictive capabilities and interpretability. Evaluation on\nAoU data demonstrates the model's predictive value for the onset of various\nconditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay\nbetween PRS and EHR data. The work also explores transfer learning for custom\nclassification tasks, showcasing the architecture's versatility and efficiency.\nThis approach is pivotal for unlocking new insights into disease prediction,\nproactive health management, risk stratification, and personalized treatment\nstrategies, laying the groundwork for more personalized, equitable, and\nactionable real-world evidence generation in healthcare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u57fa\u7840\u6a21\u578b\uff0c\u5c06\u591a\u57fa\u56e0\u98ce\u9669\u8bc4\u5206\u4f5c\u4e3a\u57fa\u7840\u6570\u636e\u6a21\u6001\uff0c\u8d85\u8d8a\u4f20\u7edf\u4ec5\u4f7f\u7528EHR\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u66f4\u5168\u9762\u7684\u5065\u5eb7\u6863\u6848\u3002\u8be5\u6a21\u578b\u5229\u7528All of Us\u7814\u7a76\u8ba1\u5212\u7684\u5e7f\u6cdb\u6570\u636e\uff0c\u5b66\u4e60\u4e34\u5e8a\u6570\u636e\u4e0e\u9057\u4f20\u6613\u611f\u6027\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u589e\u5f3a\u9884\u6d4b\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u4e34\u5e8a\u6570\u636e\uff0c\u7f3a\u4e4f\u5bf9\u9057\u4f20\u56e0\u7d20\u7684\u6574\u5408\u3002\u4e3a\u4e86\u6784\u5efa\u66f4\u5168\u9762\u7684\u5065\u5eb7\u6863\u6848\uff0c\u9700\u8981\u5c06\u591a\u57fa\u56e0\u98ce\u9669\u8bc4\u5206\u4e0eEHR\u6570\u636e\u76f8\u7ed3\u5408\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u75be\u75c5\u98ce\u9669\u5e76\u5b9e\u73b0\u4e2a\u6027\u5316\u533b\u7597\u3002", "method": "\u5f00\u53d1\u591a\u6a21\u6001\u6846\u67b6\uff0c\u6574\u5408EHR\u548c\u591a\u57fa\u56e0\u98ce\u9669\u8bc4\u5206\u6570\u636e\uff1b\u5229\u7528\u751f\u6210\u5f0fAI\u6280\u672f\u6269\u5c55EHR\u57fa\u7840\u6a21\u578b\uff1b\u5728All of Us\u7814\u7a76\u8ba1\u5212\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff1b\u63a2\u7d22\u8fc1\u79fb\u5b66\u4e60\u7528\u4e8e\u5b9a\u5236\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u5728All of Us\u6570\u636e\u4e0a\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u6a21\u578b\u5bf9\u591a\u79cd\u75be\u75c5\uff08\u7279\u522b\u662f2\u578b\u7cd6\u5c3f\u75c5\uff09\u7684\u53d1\u75c5\u5177\u6709\u9884\u6d4b\u4ef7\u503c\uff1b\u5c55\u793a\u4e86PRS\u4e0eEHR\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff1b\u9a8c\u8bc1\u4e86\u67b6\u6784\u5728\u5b9a\u5236\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u591a\u529f\u80fd\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5bf9\u4e8e\u75be\u75c5\u9884\u6d4b\u3001\u4e3b\u52a8\u5065\u5eb7\u7ba1\u7406\u3001\u98ce\u9669\u5206\u5c42\u548c\u4e2a\u6027\u5316\u6cbb\u7597\u7b56\u7565\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4e3a\u533b\u7597\u4fdd\u5065\u4e2d\u66f4\u4e2a\u6027\u5316\u3001\u516c\u5e73\u548c\u53ef\u64cd\u4f5c\u7684\u771f\u5b9e\u4e16\u754c\u8bc1\u636e\u751f\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.23965", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23965", "abs": "https://arxiv.org/abs/2510.23965", "authors": ["Aymane El Gadarri", "Ali Aouad", "Vivek F. Farias"], "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity", "comment": null, "summary": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7b26\u53f7\u4f30\u8ba1\u5668\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7528\u4e8c\u5143\u5206\u7c7b\u635f\u5931\u66ff\u6362\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfLLM\u5bf9\u9f50\u65b9\u6cd5\u5728\u4eba\u7c7b\u504f\u597d\u5f02\u8d28\u6027\u4e0b\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u8bc1\u660e\u7684\u4e00\u81f4\u6027\u548c\u591a\u9879\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\u3002", "motivation": "\u4f20\u7edfLLM\u5bf9\u9f50\u65b9\u6cd5\u5bf9\u4eba\u7c7b\u504f\u597d\u7684\u5f02\u8d28\u6027\u5f88\u8106\u5f31\uff0c\u62df\u5408\u6734\u7d20\u6982\u7387\u6a21\u578b\u5230\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u603b\u4f53\u5e73\u5747\u6548\u7528\u4f30\u8ba1\u3002", "method": "\u63d0\u51fa\u7b26\u53f7\u4f30\u8ba1\u5668\u65b9\u6cd5\uff0c\u5728\u805a\u5408\u6b65\u9aa4\u4e2d\u7528\u4e8c\u5143\u5206\u7c7b\u635f\u5931\u66ff\u6362\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u6062\u590d\u4e00\u81f4\u7684\u6709\u5e8f\u5bf9\u9f50\u3002", "result": "\u5728LLM\u5bf9\u9f50\u7684\u6570\u5b57\u5b6a\u751f\u6a21\u62df\u4e2d\uff0c\u7b26\u53f7\u4f30\u8ba1\u5668\u663e\u8457\u51cf\u5c11\u4e86\u504f\u597d\u626d\u66f2\uff0c\u5c06\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e\u4e86\u8fd135%\uff0c\u4e0e\u771f\u5b9e\u603b\u4f53\u504f\u597d\u7684\u4e0d\u4e00\u81f4\u6027\u4ece12%\u964d\u81f38%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u73b0\u6709LLM\u5bf9\u9f50\u7ba1\u9053\u5b9e\u73b0\u7b80\u5355\u6027\u7684\u540c\u65f6\uff0c\u4f18\u4e8e\u660e\u786e\u5efa\u6a21\u7528\u6237\u5f02\u8d28\u6027\u5e76\u9700\u8981\u8ddf\u8e2a\u4e2a\u4f53\u7ea7\u504f\u597d\u6570\u636e\u7684\u9762\u677f\u6570\u636e\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002"}}
{"id": "2510.23989", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23989", "abs": "https://arxiv.org/abs/2510.23989", "authors": ["Shangde Gao", "Zelin Xu", "Zhe Jiang"], "title": "Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance", "comment": null, "summary": "Shifts in individual movement patterns following disruptive events can reveal\nchanging demands for community resources. However, predicting such shifts\nbefore disruptive events remains challenging for several reasons. First,\nmeasures are lacking for individuals' heterogeneous social infrastructure\nresilience (SIR), which directly influences their movement patterns, and\ncommonly used features are often limited or unavailable at scale, e.g.,\nsociodemographic characteristics. Second, the complex interactions between\nindividual movement patterns and spatial contexts have not been sufficiently\ncaptured. Third, individual-level movement may be spatially sparse and not\nwell-suited to traditional decision-making methods for movement predictions.\nThis study incorporates individuals' SIR into a conditioned deep learning model\nto capture the complex relationships between individual movement patterns and\nlocal spatial context using large-scale, sparse individual-level data. Our\nexperiments demonstrate that incorporating individuals' SIR and spatial context\ncan enhance the model's ability to predict post-event individual movement\npatterns. The conditioned model can capture the divergent shifts in movement\npatterns among individuals who exhibit similar pre-event patterns but differ in\nSIR.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e2a\u4f53\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u5f39\u6027(SIR)\u7684\u6761\u4ef6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u7834\u574f\u6027\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u53d8\u5316\u3002", "motivation": "\u9884\u6d4b\u7834\u574f\u6027\u4e8b\u4ef6\u524d\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u53d8\u5316\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u8861\u91cf\u4e2a\u4f53\u5f02\u8d28\u6027\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u5f39\u6027\u7684\u65b9\u6cd5\uff0c\u4f20\u7edf\u7279\u5f81\u6709\u9650\uff0c\u4e14\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u4e0e\u7a7a\u95f4\u73af\u5883\u7684\u590d\u6742\u4ea4\u4e92\u672a\u88ab\u5145\u5206\u6355\u6349\u3002", "method": "\u5c06\u4e2a\u4f53\u7684\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u5f39\u6027(SIR)\u6574\u5408\u5230\u6761\u4ef6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\uff0c\u5229\u7528\u5927\u89c4\u6a21\u7a00\u758f\u7684\u4e2a\u4f53\u7ea7\u6570\u636e\u6355\u6349\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u4e0e\u5c40\u90e8\u7a7a\u95f4\u73af\u5883\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u4e2a\u4f53\u7684SIR\u548c\u7a7a\u95f4\u73af\u5883\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u9884\u6d4b\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u80fd\u529b\u3002\u6761\u4ef6\u6a21\u578b\u80fd\u591f\u6355\u6349\u5230\u5177\u6709\u76f8\u4f3c\u4e8b\u4ef6\u524d\u6a21\u5f0f\u4f46SIR\u4e0d\u540c\u7684\u4e2a\u4f53\u5728\u79fb\u52a8\u6a21\u5f0f\u4e0a\u7684\u5dee\u5f02\u53d8\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5c06\u4e2a\u4f53\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u5f39\u6027\u7eb3\u5165\u9884\u6d4b\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u9884\u6d4b\u7834\u574f\u6027\u4e8b\u4ef6\u540e\u4e2a\u4f53\u884c\u4e3a\u53d8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.24110", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24110", "abs": "https://arxiv.org/abs/2510.24110", "authors": ["Linwei Li", "Hongmei Yao", "Chunlin Yang", "Shaoming Fei"], "title": "Separability Criteria of Quantum States based on Generalized Bloch Representation", "comment": "31 pages, 6 figures", "summary": "Quantum entanglement serves as a fundamental resource in quantum information\ntheory. This paper presents a comprehensive framework of separability criteria\nfor detecting entanglement across quantum systems, from bipartite to\nmultipartite states. We propose a novel unified parameterized extended\ncorrelation tensor, constructed via the generalized Bloch representation under\nan arbitrary orthogonal basis, which bridges our bipartite criterion with\nseveral existing ones. Moreover, we develop a specialized tensor unfolding\ntechnique -- termed mixed mode matrix unfolding -- that naturally generalizes\nthe conventional $k$-mode matrix unfolding and enables the generalization of\nthe extended correlation tensor construction to multipartite systems. And we\nderive several separability criteria for multipartite states. Numerical\nexamples demonstrate that our separability criteria exhibit enhanced capability\nin detecting entanglement.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4b\u91cf\u5b50\u7cfb\u7edf\u7ea0\u7f20\u7684\u7efc\u5408\u6027\u53ef\u5206\u79bb\u6027\u5224\u636e\u6846\u67b6\uff0c\u4ece\u53cc\u4f53\u7cfb\u7edf\u6269\u5c55\u5230\u591a\u4f53\u7cfb\u7edf\u3002\u901a\u8fc7\u6784\u5efa\u53c2\u6570\u5316\u6269\u5c55\u76f8\u5173\u5f20\u91cf\u5e76\u5f00\u53d1\u6df7\u5408\u6a21\u5f0f\u77e9\u9635\u5c55\u5f00\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7ea0\u7f20\u68c0\u6d4b\u80fd\u529b\u7684\u63d0\u5347\u3002", "motivation": "\u91cf\u5b50\u7ea0\u7f20\u662f\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u57fa\u672c\u8d44\u6e90\uff0c\u4f46\u73b0\u6709\u7684\u7ea0\u7f20\u68c0\u6d4b\u65b9\u6cd5\u5728\u4ece\u53cc\u4f53\u7cfb\u7edf\u6269\u5c55\u5230\u591a\u4f53\u7cfb\u7edf\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u901a\u7528\u7684\u6846\u67b6\u6765\u6709\u6548\u68c0\u6d4b\u5404\u7c7b\u91cf\u5b50\u7cfb\u7edf\u7684\u7ea0\u7f20\u7279\u6027\u3002", "method": "1. \u6784\u5efa\u4e86\u57fa\u4e8e\u4efb\u610f\u6b63\u4ea4\u57fa\u4e0b\u5e7f\u4e49Bloch\u8868\u793a\u7684\u7edf\u4e00\u53c2\u6570\u5316\u6269\u5c55\u76f8\u5173\u5f20\u91cf\uff1b2. \u5f00\u53d1\u4e86\u6df7\u5408\u6a21\u5f0f\u77e9\u9635\u5c55\u5f00\u6280\u672f\uff0c\u5c06\u4f20\u7edf\u7684k-\u6a21\u5f0f\u77e9\u9635\u5c55\u5f00\u63a8\u5e7f\u5230\u591a\u4f53\u7cfb\u7edf\uff1b3. \u63a8\u5bfc\u4e86\u591a\u4f53\u7cfb\u7edf\u7684\u591a\u4e2a\u53ef\u5206\u79bb\u6027\u5224\u636e\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u53ef\u5206\u79bb\u6027\u5224\u636e\u5728\u68c0\u6d4b\u7ea0\u7f20\u65b9\u9762\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u80fd\u529b\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8bc6\u522b\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u7ea0\u7f20\u7279\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u6210\u529f\u5730\u5c06\u53cc\u4f53\u7cfb\u7edf\u7684\u7ea0\u7f20\u68c0\u6d4b\u65b9\u6cd5\u63a8\u5e7f\u5230\u591a\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5f20\u91cf\u6784\u9020\u548c\u5c55\u5f00\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ea0\u7f20\u68c0\u6d4b\u7684\u6548\u80fd\uff0c\u4e3a\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2510.23641", "categories": ["cs.LG", "cs.AI", "hep-ex", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2510.23641", "abs": "https://arxiv.org/abs/2510.23641", "authors": ["Aaron Wang", "Zihan Zhao", "Subash Katel", "Vivekanand Gyanchand Sahu", "Elham E Khoda", "Abhijith Gandrakota", "Jennifer Ngadiuba", "Richard Cavanaugh", "Javier Duarte"], "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging", "comment": null, "summary": "Transformers are very effective in capturing both global and local\ncorrelations within high-energy particle collisions, but they present\ndeployment challenges in high-data-throughput environments, such as the CERN\nLHC. The quadratic complexity of transformer models demands substantial\nresources and increases latency during inference. In order to address these\nissues, we introduce the Spatially Aware Linear Transformer (SAL-T), a\nphysics-inspired enhancement of the linformer architecture that maintains\nlinear attention. Our method incorporates spatially aware partitioning of\nparticles based on kinematic features, thereby computing attention between\nregions of physical significance. Additionally, we employ convolutional layers\nto capture local correlations, informed by insights from jet physics. In\naddition to outperforming the standard linformer in jet classification tasks,\nSAL-T also achieves classification results comparable to full-attention\ntransformers, while using considerably fewer resources with lower latency\nduring inference. Experiments on a generic point cloud classification dataset\n(ModelNet10) further confirm this trend. Our code is available at\nhttps://github.com/aaronw5/SAL-T4HEP.", "AI": {"tldr": "SAL-T\u662f\u4e00\u79cd\u7269\u7406\u542f\u53d1\u7684\u7ebf\u6027\u53d8\u6362\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u7a7a\u95f4\u611f\u77e5\u5206\u533a\u548c\u5377\u79ef\u5c42\u6765\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5728\u4fdd\u6301\u4e0e\u5168\u6ce8\u610f\u529b\u53d8\u6362\u5668\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edf\u53d8\u6362\u5668\u5728\u7c92\u5b50\u78b0\u649e\u7b49\u9ad8\u901a\u91cf\u6570\u636e\u5904\u7406\u73af\u5883\u4e2d\u5b58\u5728\u4e8c\u6b21\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5bfc\u81f4\u8d44\u6e90\u9700\u6c42\u5927\u3001\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u67b6\u6784\u3002", "method": "\u7ed3\u5408linformer\u7ebf\u6027\u6ce8\u610f\u529b\u67b6\u6784\uff0c\u5f15\u5165\u57fa\u4e8e\u8fd0\u52a8\u5b66\u7279\u5f81\u7684\u7a7a\u95f4\u611f\u77e5\u7c92\u5b50\u5206\u533a\uff0c\u5e76\u5229\u7528\u5377\u79ef\u5c42\u6355\u83b7\u5c40\u90e8\u76f8\u5173\u6027\uff0c\u501f\u9274\u55b7\u6ce8\u7269\u7406\u5b66\u7684\u6d1e\u89c1\u3002", "result": "\u5728\u55b7\u6ce8\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6807\u51c6linformer\uff0c\u6027\u80fd\u4e0e\u5168\u6ce8\u610f\u529b\u53d8\u6362\u5668\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8d44\u6e90\u4f7f\u7528\u548c\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\uff1b\u5728ModelNet10\u70b9\u4e91\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u4e5f\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u8d8b\u52bf\u3002", "conclusion": "SAL-T\u6210\u529f\u89e3\u51b3\u4e86\u53d8\u6362\u5668\u5728\u9ad8\u901a\u91cf\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u6311\u6218\uff0c\u4e3a\u9ad8\u80fd\u7269\u7406\u548c\u5176\u4ed6\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u5f02\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.24137", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24137", "abs": "https://arxiv.org/abs/2510.24137", "authors": ["Sojeong Park", "Changhun Oh"], "title": "Matrix product state approach to lossy boson sampling and noisy IQP sampling", "comment": "19 pages, 10 figures", "summary": "Sampling problems have emerged as a central avenue for demonstrating quantum\nadvantage on noisy intermediate-scale quantum devices. However, physical noise\ncan fundamentally alter their computational complexity, often making them\nclassically tractable. Motivated by the recent success of matrix product state\n(MPS)-based classical simulation of Gaussian boson sampling (Oh et al., 2024),\nwe extend this framework to investigate the classical simulability of other\nnoisy quantum sampling models. We develop MPS-based classical algorithms for\nlossy boson sampling and noisy instantaneous quantum polynomial-time (IQP)\nsampling, both of which retain the tunable accuracy characteristic of the MPS\napproach through the bond dimension. Our approach constructs pure-state\ndecompositions of noisy or lossy input states whose components remain weakly\nentangled after circuit evolution, thereby providing a means to systematically\nexplore the boundary between quantum-hard and classically-simulable regimes.\nFor boson sampling, we analyze single-photon, Fock, and cat-state inputs,\nshowing that classical simulability emerges at transmission rates scaling as\n$O(1/\\sqrt{N})$, reaching the known boundary of quantum advantage with a\ntunable and scalable method. Beyond reproducing previous thresholds, our\nalgorithm offers significantly improved control over the accuracy-efficiency\ntrade-off. It further extends the applicability of MPS-based simulation to\nbroader classes of noisy quantum sampling models, including IQP circuits.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8e\u77e9\u9635\u4e58\u79ef\u6001\uff08MPS\uff09\u7684\u7ecf\u5178\u6a21\u62df\u6846\u67b6\uff0c\u7814\u7a76\u4e86\u542b\u566a\u58f0\u91cf\u5b50\u91c7\u6837\u6a21\u578b\uff08\u5305\u62ec\u635f\u5931\u6027\u73bb\u8272\u5b50\u91c7\u6837\u548c\u542b\u566a\u58f0IQP\u91c7\u6837\uff09\u7684\u7ecf\u5178\u53ef\u6a21\u62df\u6027\uff0c\u901a\u8fc7\u53ef\u8c03\u8282\u7684\u952e\u7ef4\u5ea6\u63d0\u4f9b\u7cbe\u5ea6\u63a7\u5236\uff0c\u7cfb\u7edf\u63a2\u7d22\u91cf\u5b50\u96be\u89e3\u4e0e\u7ecf\u5178\u53ef\u6a21\u62df\u4e4b\u95f4\u7684\u8fb9\u754c\u3002", "motivation": "\u91c7\u6837\u95ee\u9898\u5df2\u6210\u4e3a\u5c55\u793a\u91cf\u5b50\u4f18\u52bf\u7684\u6838\u5fc3\u9014\u5f84\uff0c\u4f46\u7269\u7406\u566a\u58f0\u4f1a\u6539\u53d8\u5176\u8ba1\u7b97\u590d\u6742\u6027\u3002\u53d7\u8fd1\u671fMPS\u6210\u529f\u6a21\u62df\u9ad8\u65af\u73bb\u8272\u5b50\u91c7\u6837\u7684\u542f\u53d1\uff0c\u5e0c\u671b\u5c06\u6b64\u6846\u67b6\u6269\u5c55\u5230\u5176\u4ed6\u542b\u566a\u58f0\u91cf\u5b50\u91c7\u6837\u6a21\u578b\u7684\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eMPS\u7684\u7ecf\u5178\u7b97\u6cd5\uff0c\u6784\u5efa\u542b\u566a\u58f0\u6216\u635f\u5931\u8f93\u5165\u6001\u7684\u7eaf\u6001\u5206\u89e3\uff0c\u5176\u5206\u91cf\u5728\u7535\u8def\u6f14\u5316\u540e\u4fdd\u6301\u5f31\u7ea0\u7f20\uff0c\u901a\u8fc7\u952e\u7ef4\u5ea6\u5b9e\u73b0\u53ef\u8c03\u8282\u7cbe\u5ea6\u3002", "result": "\u5bf9\u4e8e\u73bb\u8272\u5b50\u91c7\u6837\uff0c\u5728\u4f20\u8f93\u7387\u4e3aO(1/\u221aN)\u65f6\u51fa\u73b0\u7ecf\u5178\u53ef\u6a21\u62df\u6027\uff0c\u8fbe\u5230\u91cf\u5b50\u4f18\u52bf\u7684\u5df2\u77e5\u8fb9\u754c\uff1b\u7b97\u6cd5\u5728\u7cbe\u5ea6-\u6548\u7387\u6743\u8861\u65b9\u9762\u63d0\u4f9b\u663e\u8457\u6539\u8fdb\u63a7\u5236\uff0c\u5e76\u5c06MPS\u6a21\u62df\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u542b\u566a\u58f0\u91cf\u5b50\u91c7\u6837\u6a21\u578b\u3002", "conclusion": "MPS\u65b9\u6cd5\u4e3a\u7cfb\u7edf\u63a2\u7d22\u91cf\u5b50\u96be\u89e3\u4e0e\u7ecf\u5178\u53ef\u6a21\u62df\u8fb9\u754c\u63d0\u4f9b\u4e86\u53ef\u8c03\u8282\u4e14\u53ef\u6269\u5c55\u7684\u624b\u6bb5\uff0c\u6269\u5c55\u4e86\u57fa\u4e8eMPS\u7684\u6a21\u62df\u5728\u542b\u566a\u58f0\u91cf\u5b50\u91c7\u6837\u6a21\u578b\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2510.24028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24028", "abs": "https://arxiv.org/abs/2510.24028", "authors": ["Tingyue Pan", "Mingyue Cheng", "Shilong Zhang", "Zhiding Liu", "Xiaoyu Tao", "Yucong Luo", "Jintao Zhang", "Qi Liu"], "title": "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting", "comment": null, "summary": "Cross-domain time series forecasting is a valuable task in various web\napplications. Despite its rapid advancement, achieving effective generalization\nacross heterogeneous time series data remains a significant challenge. Existing\nmethods have made progress by extending single-domain models, yet often fall\nshort when facing domain-specific trend shifts and inconsistent periodic\npatterns. We argue that a key limitation lies in treating temporal series as\nundifferentiated sequence, without explicitly decoupling their inherent\nstructural components. To address this, we propose OneCast, a structured and\nmodular forecasting framework that decomposes time series into seasonal and\ntrend components, each modeled through tailored generative pathways.\nSpecifically, the seasonal component is captured by a lightweight projection\nmodule that reconstructs periodic patterns via interpretable basis functions.\nIn parallel, the trend component is encoded into discrete tokens at segment\nlevel via a semantic-aware tokenizer, and subsequently inferred through a\nmasked discrete diffusion mechanism. The outputs from both branches are\ncombined to produce a final forecast that captures seasonal patterns while\ntracking domain-specific trends. Extensive experiments across eight domains\ndemonstrate that OneCast mostly outperforms state-of-the-art baselines.", "AI": {"tldr": "OneCast\u662f\u4e00\u4e2a\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u65f6\u95f4\u5e8f\u5217\u7684\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6210\u5206\uff0c\u5206\u522b\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6295\u5f71\u6a21\u5757\u548c\u8bed\u4e49\u611f\u77e5\u5206\u8bcd\u5668\u8fdb\u884c\u5efa\u6a21\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u9762\u4e34\u7684\u9886\u57df\u7279\u5b9a\u8d8b\u52bf\u53d8\u5316\u548c\u4e0d\u4e00\u81f4\u5468\u671f\u6027\u6a21\u5f0f\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5c06\u65f6\u95f4\u5e8f\u5217\u89c6\u4e3a\u672a\u5206\u5316\u7684\u5e8f\u5217\uff0c\u672a\u80fd\u663e\u5f0f\u89e3\u8026\u5176\u5185\u5728\u7ed3\u6784\u6210\u5206\u3002", "method": "\u63d0\u51faOneCast\u6846\u67b6\uff1a1\uff09\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6210\u5206\uff1b2\uff09\u5b63\u8282\u6027\u6210\u5206\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6295\u5f71\u6a21\u5757\u4f7f\u7528\u53ef\u89e3\u91ca\u57fa\u51fd\u6570\u91cd\u5efa\u5468\u671f\u6027\u6a21\u5f0f\uff1b3\uff09\u8d8b\u52bf\u6210\u5206\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u5206\u8bcd\u5668\u7f16\u7801\u4e3a\u5206\u6bb5\u7ea7\u79bb\u6563token\uff0c\u4f7f\u7528\u63a9\u7801\u79bb\u6563\u6269\u6563\u673a\u5236\u8fdb\u884c\u63a8\u65ad\uff1b4\uff09\u4e24\u4e2a\u5206\u652f\u8f93\u51fa\u7ed3\u5408\u751f\u6210\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5728\u516b\u4e2a\u9886\u57df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cOneCast\u5927\u591a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u65f6\u95f4\u5e8f\u5217\u6210\u5206\u5e76\u91c7\u7528\u4e13\u95e8\u7684\u751f\u6210\u8def\u5f84\uff0cOneCast\u80fd\u591f\u6709\u6548\u6355\u6349\u5b63\u8282\u6027\u6a21\u5f0f\u5e76\u8ddf\u8e2a\u9886\u57df\u7279\u5b9a\u8d8b\u52bf\uff0c\u5728\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.24162", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2510.24162", "abs": "https://arxiv.org/abs/2510.24162", "authors": ["F. Cavaliere", "D. Ferraro", "M. Carrega", "G. Benenti", "M. Sassetti"], "title": "Quantum advantage bounds for a multipartite Gaussian battery", "comment": "Main text: 9 pages, 4 figures. Supplemental material: 10 pages, 1\n  figure", "summary": "We demonstrate the possibility of a genuine quantum advantage in the\nefficiency of quantum batteries by analyzing a model that enables a consistent\ncomparison between quantum and classical regimes. Our system consists of $N$\nharmonic oscillator cells coupled to a common thermal reservoir, evolving\nthrough Gaussian states. We define the global efficiency as the ratio of\nextractable work (ergotropy) to stored energy, and derive analytical bounds\nthat distinguish, in order of increasing efficiency, regimes characterized by\nclassical squeezing, quantum squeezing without entanglement, and genuine\nentanglement. Moreover, numerical simulations support the emergence of a\nsimilar hierarchy for the thermodynamic efficiency, defined as the ratio\nbetween ergotropy and the total thermodynamic cost of the charging process.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u91cf\u5b50\u7535\u6c60\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u91cf\u5b50\u4f18\u52bf\u5728\u80fd\u91cf\u63d0\u53d6\u6548\u7387\u4e0a\u7684\u53ef\u80fd\u6027\uff0c\u533a\u5206\u4e86\u7ecf\u5178\u538b\u7f29\u3001\u65e0\u7ea0\u7f20\u91cf\u5b50\u538b\u7f29\u548c\u771f\u6b63\u7ea0\u7f20\u4e09\u79cd\u6548\u7387\u9012\u589e\u7684\u673a\u5236\u3002", "motivation": "\u4e3a\u4e86\u5728\u91cf\u5b50\u7535\u6c60\u6548\u7387\u65b9\u9762\u5b9e\u73b0\u771f\u6b63\u7684\u91cf\u5b50\u4f18\u52bf\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u4e00\u81f4\u6bd4\u8f83\u91cf\u5b50\u4e0e\u7ecf\u5178\u673a\u5236\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528N\u4e2a\u8c10\u632f\u5b50\u7535\u6c60\u5355\u5143\u8026\u5408\u5230\u5171\u540c\u70ed\u5e93\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u9ad8\u65af\u6001\u6f14\u5316\uff0c\u5b9a\u4e49\u5168\u5c40\u6548\u7387\u4e3a\u53ef\u63d0\u53d6\u529f\u4e0e\u5b58\u50a8\u80fd\u91cf\u7684\u6bd4\u503c\uff0c\u5e76\u63a8\u5bfc\u89e3\u6790\u754c\u9650\u3002", "result": "\u5206\u6790\u754c\u9650\u533a\u5206\u4e86\u4e09\u79cd\u6548\u7387\u9012\u589e\u7684\u673a\u5236\uff1a\u7ecf\u5178\u538b\u7f29\u3001\u65e0\u7ea0\u7f20\u91cf\u5b50\u538b\u7f29\u548c\u771f\u6b63\u7ea0\u7f20\uff0c\u6570\u503c\u6a21\u62df\u652f\u6301\u8fd9\u79cd\u5c42\u6b21\u7ed3\u6784\u5728\u70ed\u529b\u5b66\u6548\u7387\u4e2d\u7684\u51fa\u73b0\u3002", "conclusion": "\u91cf\u5b50\u7535\u6c60\u5728\u80fd\u91cf\u63d0\u53d6\u6548\u7387\u4e0a\u5b58\u5728\u771f\u6b63\u7684\u91cf\u5b50\u4f18\u52bf\uff0c\u4e14\u8fd9\u79cd\u4f18\u52bf\u5728\u70ed\u529b\u5b66\u6548\u7387\u4e2d\u540c\u6837\u663e\u73b0\u3002"}}
{"id": "2510.23650", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23650", "abs": "https://arxiv.org/abs/2510.23650", "authors": ["Wei Xia"], "title": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs", "comment": null, "summary": "We proposed Static and Dynamic -- two zero-shot logits-layer debiasing\nmethods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits\nintervention outperforms hidden-layer approaches. We show semantic-aware logits\nintervention is stable and effective for debiasing aligned LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u96f6\u6837\u672clogits\u5c42\u53bb\u504f\u65b9\u6cd5\uff1aStatic\u548cDynamic\uff0c\u5176\u4e2dDynamic\u65b9\u6cd5\u5728\u6700\u5c0f\u5316\u6d41\u7545\u6027\u635f\u5931\u7684\u540c\u65f6\u5c06\u504f\u89c1\u51cf\u5c11\u9ad8\u8fbe70%\uff0clogits\u5e72\u9884\u4f18\u4e8e\u9690\u85cf\u5c42\u65b9\u6cd5\u3002", "motivation": "\u5f00\u53d1\u6709\u6548\u7684\u53bb\u504f\u65b9\u6cd5\u6765\u89e3\u51b3\u5bf9\u9f50\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u96f6\u6837\u672clogits\u5c42\u53bb\u504f\u65b9\u6cd5\uff1aStatic\u548cDynamic\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684logits\u5e72\u9884\u6765\u51cf\u5c11\u6a21\u578b\u504f\u89c1\u3002", "result": "Dynamic\u65b9\u6cd5\u5c06\u504f\u89c1\u51cf\u5c11\u9ad8\u8fbe70%\uff0c\u4e14\u6d41\u7545\u6027\u635f\u5931\u6700\u5c0f\uff1blogits\u5e72\u9884\u65b9\u6cd5\u5728\u53bb\u504f\u6548\u679c\u4e0a\u4f18\u4e8e\u9690\u85cf\u5c42\u65b9\u6cd5\u3002", "conclusion": "\u8bed\u4e49\u611f\u77e5\u7684logits\u5e72\u9884\u662f\u5bf9\u9f50LLMs\u53bb\u504f\u7684\u7a33\u5b9a\u6709\u6548\u65b9\u6cd5\uff0clogits\u5c42\u5e72\u9884\u4f18\u4e8e\u9690\u85cf\u5c42\u65b9\u6cd5\u3002"}}
{"id": "2510.24163", "categories": ["quant-ph", "gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.24163", "abs": "https://arxiv.org/abs/2510.24163", "authors": ["Zhenghao Luo", "Yi Li", "Xingyu Zhao", "Zihan Xie", "Zehua Tian", "Yiheng Lin"], "title": "Experimental Demonstration of the Timelike Unruh Effect with a Trapped-Ion System", "comment": "11 pages, 6 figures", "summary": "The Unruh effect predicts that an accelerated observer perceives the\nMinkowski vacuum as a thermal bath, but its direct observation requires extreme\naccelerations beyond current experimental reach. Foundational theory [Olson &\nRalph, Phys. Rev. Lett. 106, 110404 (2011)] shows that an equivalent thermal\nresponse, known as the timelike Unruh effect, can occur for detectors following\nspecific timelike trajectories without acceleration, enabling laboratory tests\nwith stationary yet time-dependent detectors. Here, we report a\nproof-of-principle demonstration of the timelike Unruh effect in a quantum\nsystem of trapped ion, where a two-level spin serves as the detector and is\ntemporally coupled to the ambient field encoded in the ion's vibrational\nmotion. Specifically, we study both excitation and emission dynamics of the\ndetector moving along a spacetime trajectory in the future/past light cone, and\ndemonstrate the thermal response of the detector to the Minkowski vacuum that\nresembles the Unruh effect. This work establishes a controllable tabletop\nplatform for exploring relativistic quantum physics under accessible laboratory\nconditions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56da\u7981\u79bb\u5b50\u91cf\u5b50\u7cfb\u7edf\u5b9e\u9a8c\u6f14\u793a\u4e86\u7c7b\u65f6Unruh\u6548\u5e94\uff0c\u4f7f\u7528\u4e24\u80fd\u7ea7\u81ea\u65cb\u4f5c\u4e3a\u63a2\u6d4b\u5668\uff0c\u5728\u65e0\u9700\u6781\u7aef\u52a0\u901f\u5ea6\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u7c7b\u4f3cUnruh\u6548\u5e94\u7684\u70ed\u54cd\u5e94\u3002", "motivation": "\u76f4\u63a5\u89c2\u6d4bUnruh\u6548\u5e94\u9700\u8981\u6781\u7aef\u52a0\u901f\u5ea6\uff0c\u8d85\u51fa\u5f53\u524d\u5b9e\u9a8c\u80fd\u529b\u3002\u7406\u8bba\u7814\u7a76\u8868\u660e\u7c7b\u65f6Unruh\u6548\u5e94\u53ef\u5728\u65e0\u52a0\u901f\u5ea6\u4f46\u65f6\u95f4\u4f9d\u8d56\u7684\u63a2\u6d4b\u5668\u4e2d\u51fa\u73b0\uff0c\u4e3a\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u63d0\u4f9b\u53ef\u80fd\u3002", "method": "\u4f7f\u7528\u56da\u7981\u79bb\u5b50\u7cfb\u7edf\uff0c\u5176\u4e2d\u4e24\u80fd\u7ea7\u81ea\u65cb\u4f5c\u4e3a\u63a2\u6d4b\u5668\uff0c\u4e0e\u7f16\u7801\u5728\u79bb\u5b50\u632f\u52a8\u8fd0\u52a8\u4e2d\u7684\u73af\u5883\u573a\u8fdb\u884c\u65f6\u95f4\u8026\u5408\u3002\u7814\u7a76\u63a2\u6d4b\u5668\u5728\u672a\u6765/\u8fc7\u53bb\u5149\u9525\u4e2d\u6cbf\u65f6\u7a7a\u8f68\u8ff9\u7684\u6fc0\u53d1\u548c\u53d1\u5c04\u52a8\u529b\u5b66\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u63a2\u6d4b\u5668\u5bf9Minkowski\u771f\u7a7a\u7684\u70ed\u54cd\u5e94\uff0c\u8fd9\u79cd\u54cd\u5e94\u4e0eUnruh\u6548\u5e94\u76f8\u4f3c\uff0c\u9a8c\u8bc1\u4e86\u7c7b\u65f6Unruh\u6548\u5e94\u7684\u5b58\u5728\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u63a7\u7684\u684c\u9762\u5e73\u53f0\uff0c\u53ef\u5728\u53ef\u8bbf\u95ee\u7684\u5b9e\u9a8c\u5ba4\u6761\u4ef6\u4e0b\u63a2\u7d22\u76f8\u5bf9\u8bba\u91cf\u5b50\u7269\u7406\u3002"}}
{"id": "2510.23652", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23652", "abs": "https://arxiv.org/abs/2510.23652", "authors": ["Yao Lu", "Yuqi Li", "Wenbin Xie", "Shanqing Yu", "Qi Xuan", "Zhaowei Zhu", "Shiping Wen"], "title": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models", "comment": null, "summary": "Although large language models (LLMs) have achieved revolutionary\nbreakthroughs in many fields, their large model size and high computational\ncost pose significant challenges for practical deployment on\nresource-constrained edge devices. To this end, layer pruning has been proposed\nto reduce the computational overhead by directly removing redundant layers.\nHowever, existing layer pruning methods typically rely on hand-crafted metrics\nto evaluate and remove individual layers, while ignoring the dependencies\nbetween layers. This can disrupt the model's information flow and severely\ndegrade performance. To address these issues, we propose CLP, a novel\ncontinuous layer pruning framework that introduces two key innovations: a\ndifferentiable concave gate algorithm that automatically identifies the best\ncontinuous layer segments for pruning via gradient-based optimization; and a\ncutoff endpoint tuning strategy that effectively restores model performance by\nfine-tuning only the layers adjacent to the pruned segments. Extensive\nexperiments across multiple model architectures (including LLaMA2, LLaMA3 and\nQwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly\noutperforms existing state-of-the-art baselines. For example, at a pruning rate\nof $20\\%$, CLP achieves an average performance retention of $95.34\\%$ on\nLLaMA3-70B, outperforming baselines by $4.29\\%$-$30.52\\%$. Furthermore, CLP can\nbe seamlessly combined with quantization to further compress the model with\nonly a slight performance loss.", "AI": {"tldr": "CLP\u662f\u4e00\u79cd\u8fde\u7eed\u5c42\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5fae\u51f9\u95e8\u7b97\u6cd5\u81ea\u52a8\u8bc6\u522b\u6700\u4f73\u526a\u679d\u5c42\u6bb5\uff0c\u5e76\u4f7f\u7528\u622a\u6b62\u7aef\u70b9\u8c03\u4f18\u7b56\u7565\u6062\u590d\u6a21\u578b\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u9762\u4e34\u6a21\u578b\u5c3a\u5bf8\u5927\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u73b0\u6709\u5c42\u526a\u679d\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6307\u6807\u4e14\u5ffd\u7565\u5c42\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\u3002", "method": "\u63d0\u51faCLP\u6846\u67b6\uff1a1\uff09\u53ef\u5fae\u51f9\u95e8\u7b97\u6cd5\u901a\u8fc7\u68af\u5ea6\u4f18\u5316\u81ea\u52a8\u8bc6\u522b\u8fde\u7eed\u5c42\u6bb5\u8fdb\u884c\u526a\u679d\uff1b2\uff09\u622a\u6b62\u7aef\u70b9\u8c03\u4f18\u7b56\u7565\u4ec5\u5fae\u8c03\u526a\u679d\u6bb5\u76f8\u90bb\u5c42\u4ee5\u6062\u590d\u6027\u80fd\u3002", "result": "\u5728LLaMA2\u3001LLaMA3\u548cQwen\u7b49\u6a21\u578b\uff087B-70B\u53c2\u6570\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCLP\u572820%\u526a\u679d\u7387\u4e0b\u5e73\u5747\u6027\u80fd\u4fdd\u7559\u8fbe95.34%\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u53474.29%-30.52%\uff0c\u4e14\u53ef\u4e0e\u91cf\u5316\u6280\u672f\u7ed3\u5408\u8fdb\u4e00\u6b65\u538b\u7f29\u6a21\u578b\u3002", "conclusion": "CLP\u901a\u8fc7\u8003\u8651\u5c42\u95f4\u4f9d\u8d56\u5173\u7cfb\u7684\u8fde\u7eed\u5c42\u526a\u679d\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u7684\u6311\u6218\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u526a\u679d\u6280\u672f\u3002"}}
{"id": "2510.24085", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24085", "abs": "https://arxiv.org/abs/2510.24085", "authors": ["Md. Shihab Uddin", "Md Nazmus Shakib", "Rahul Bhadani"], "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach", "comment": null, "summary": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u7ecf\u5178\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7535\u52a8\u6c7d\u8f66\u8ddf\u9a70\u884c\u4e3a\u5efa\u6a21\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u6240\u6709\u573a\u666f\u4e0b\u90fd\u4f18\u4e8e\u7269\u7406\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u8f66\u8ddd\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u7684\u666e\u53ca\uff0c\u9700\u8981\u7406\u89e3\u5176\u9a7e\u9a76\u884c\u4e3a\u4ee5\u63d0\u9ad8\u4ea4\u901a\u5b89\u5168\u548c\u5f00\u53d1\u667a\u80fd\u9a7e\u9a76\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728\u4e0e\u4f20\u7edf\u5185\u71c3\u673a\u8f66\u8f86\u6df7\u5408\u884c\u9a76\u7684\u73af\u5883\u4e2d\u3002", "method": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e86IDM\u3001OVM\u3001OVRV\u548c\u7b80\u5316CACC\u7b49\u7ecf\u5178\u7269\u7406\u6a21\u578b\u4e0e\u968f\u673a\u68ee\u6797\u56de\u5f52\u5668\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u503c\u4e0e\u5b9e\u9645\u6570\u636e\u7684RMSE\u6765\u6821\u51c6\u6a21\u578b\u53c2\u6570\u3002", "result": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u6240\u6709\u573a\u666f\u4e0b\u8868\u73b0\u6700\u4f73\uff0cRMSE\u5206\u522b\u4e3a0.0046\uff08\u4e2d\u7b49\u8f66\u8ddd\uff09\u30010.0016\uff08\u957f\u8f66\u8ddd\uff09\u548c0.0025\uff08\u8d85\u957f\u8f66\u8ddd\uff09\uff1b\u5728\u7269\u7406\u6a21\u578b\u4e2d\uff0cCACC\u6a21\u578b\u5728\u957f\u8f66\u8ddd\u6761\u4ef6\u4e0b\u8868\u73b0\u6700\u597d\uff0cRMSE\u4e3a2.67\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7535\u52a8\u6c7d\u8f66\u8ddf\u9a70\u884c\u4e3a\u5efa\u6a21\u4e2d\u4f18\u4e8e\u7ecf\u5178\u7269\u7406\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e8e\u6a21\u62df\u7535\u52a8\u6c7d\u8f66\u884c\u4e3a\u548c\u5206\u6790\u6df7\u5408\u81ea\u52a8\u9a7e\u9a76\u4ea4\u901a\u52a8\u6001\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.24181", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24181", "abs": "https://arxiv.org/abs/2510.24181", "authors": ["SiYing Wang", "ZhiXin Xia", "Yue Yan", "Xiang-Bin Wang"], "title": "An exact Error Threshold of Surface Code under Correlated Nearest-Neighbor Errors: A Statistical Mechanical Analysis", "comment": null, "summary": "The surface code represents a promising candidate for fault-tolerant quantum\ncomputation due to its high error threshold and experimental accessibility with\nnearest-neighbor interactions. However, current exact surface code threshold\nanalyses are based on the assumption of independent and identically distributed\n(i.i.d.) errors. Though there are numerical studieds for threshold with\ncorrelated error, they are only the lower bond ranther than exact value, this\noffers potential for higher error thresholds.Here, we establish an error-edge\nmap, which allows for the mapping of quantum error correction to a\nsquare-octagonal random bond Ising model. We then present the exact threshold\nunder a realistic noise model that combines independent single-qubit errors\nwith correlated errors between nearest-neighbor data qubits. Our method is\napplicable for any ratio of nearest-neighbor correlated errors to i.i.d.\nerrors. We investigate the error correction threshold of surface codes and we\npresent analytical constraints giving exact value of error threshold. This\nmeans that our error threshold is both upper bound and achievable and hence on\nthe one hand the existing numerical threshold values can all be improved to our\nthreshold value, on the other hand, our threshold value is highest achievable\nvalue in principle.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u8bef\u5dee-\u8fb9\u7f18\u6620\u5c04\u65b9\u6cd5\uff0c\u5c06\u91cf\u5b50\u7ea0\u9519\u8f6c\u5316\u4e3a\u65b9\u5f62-\u516b\u8fb9\u5f62\u968f\u673a\u952eIsing\u6a21\u578b\uff0c\u5728\u7ed3\u5408\u72ec\u7acb\u5355\u91cf\u5b50\u6bd4\u7279\u8bef\u5dee\u548c\u6700\u8fd1\u90bb\u6570\u636e\u91cf\u5b50\u6bd4\u7279\u76f8\u5173\u8bef\u5dee\u7684\u73b0\u5b9e\u566a\u58f0\u6a21\u578b\u4e0b\uff0c\u7ed9\u51fa\u4e86\u8868\u9762\u7801\u7684\u7cbe\u786e\u8bef\u5dee\u9608\u503c\u3002", "motivation": "\u73b0\u6709\u8868\u9762\u7801\u9608\u503c\u5206\u6790\u57fa\u4e8e\u72ec\u7acb\u540c\u5206\u5e03\u8bef\u5dee\u5047\u8bbe\uff0c\u800c\u5b9e\u9645\u7cfb\u7edf\u4e2d\u5b58\u5728\u76f8\u5173\u8bef\u5dee\u3002\u73b0\u6709\u76f8\u5173\u8bef\u5dee\u9608\u503c\u7814\u7a76\u4ec5\u4e3a\u6570\u503c\u4e0b\u754c\u800c\u975e\u7cbe\u786e\u503c\uff0c\u5b58\u5728\u63d0\u9ad8\u9608\u503c\u7684\u6f5c\u529b\u3002", "method": "\u5efa\u7acb\u8bef\u5dee-\u8fb9\u7f18\u6620\u5c04\uff0c\u5c06\u91cf\u5b50\u7ea0\u9519\u95ee\u9898\u8f6c\u5316\u4e3a\u65b9\u5f62-\u516b\u8fb9\u5f62\u968f\u673a\u952eIsing\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u6700\u8fd1\u90bb\u76f8\u5173\u8bef\u5dee\u4e0e\u72ec\u7acb\u8bef\u5dee\u6bd4\u4f8b\u7684\u60c5\u51b5\u3002", "result": "\u83b7\u5f97\u4e86\u8868\u9762\u7801\u5728\u73b0\u5b9e\u566a\u58f0\u6a21\u578b\u4e0b\u7684\u7cbe\u786e\u8bef\u5dee\u9608\u503c\uff0c\u8be5\u9608\u503c\u65e2\u662f\u4e0a\u754c\u53c8\u662f\u53ef\u8fbe\u503c\uff0c\u610f\u5473\u7740\u73b0\u6709\u6570\u503c\u9608\u503c\u5747\u53ef\u6539\u8fdb\u81f3\u6b64\u503c\uff0c\u4e14\u8be5\u503c\u662f\u7406\u8bba\u4e0a\u53ef\u8fbe\u5230\u7684\u6700\u9ad8\u9608\u503c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u786e\u5b9a\u8868\u9762\u7801\u5728\u5305\u542b\u76f8\u5173\u8bef\u5dee\u7684\u566a\u58f0\u6a21\u578b\u4e0b\u7684\u7cbe\u786e\u8bef\u5dee\u9608\u503c\uff0c\u4e3a\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u9608\u503c\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2510.24115", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24115", "abs": "https://arxiv.org/abs/2510.24115", "authors": ["Sandeep Vissapragada", "Vikrant Sahu", "Gagan Raj Gupta", "Vandita Singh"], "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology", "comment": null, "summary": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u900f\u660eAI\u52a9\u624bHistoLens\uff0c\u8ba9\u75c5\u7406\u5b66\u5bb6\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u7ec4\u7ec7\u5207\u7247\u95ee\u9898\uff0c\u7cfb\u7edf\u63d0\u4f9b\u7ed3\u6784\u5316\u62a5\u544a\u548c\u53ef\u89c6\u5316\u8bc1\u636e\uff0c\u4fdd\u6301\u533b\u751f\u4e3b\u5bfc\u5730\u4f4d\u7684\u540c\u65f6\u63d0\u9ad8\u8bca\u65ad\u6548\u7387\u548c\u4fe1\u5fc3\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u533b\u751f\u771f\u6b63\u4fe1\u4efbAI\uff0c\u9700\u8981\u89e3\u51b3AI\u9ed1\u76d2\u95ee\u9898\uff0c\u4f7f\u5176\u63a8\u7406\u8fc7\u7a0b\u50cf\u540c\u4e8b\u54a8\u8be2\u4e00\u6837\u900f\u660e\u53ef\u7406\u89e3\u3002", "method": "\u521b\u5efaHistoLens\u7cfb\u7edf\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u6362\u4e3a\u7cbe\u786eAI\u67e5\u8be2\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u62a5\u544a\u548c\u70ed\u529b\u56fe\u53ef\u89c6\u5316\u8bc1\u636e\uff0c\u5e76\u8bad\u7ec3AI\u4e13\u6ce8\u60a3\u8005\u7ec4\u7ec7\u3001\u5ffd\u7565\u80cc\u666f\u566a\u58f0\u3002", "result": "\u5b9e\u73b0\u4e86\u533b\u751f\u4e3b\u5bfc\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u75c5\u7406\u5b66\u5bb6\u80fd\u4f7f\u7528\u53ef\u4fe1\u8d56\u7684AI\u52a9\u624b\u9a8c\u8bc1\u89c1\u89e3\uff0c\u505a\u51fa\u66f4\u5feb\u3001\u66f4\u81ea\u4fe1\u7684\u8bca\u65ad\u3002", "conclusion": "\u900f\u660e\u534f\u4f5c\u7684AI\u7cfb\u7edf\u80fd\u5efa\u7acb\u533b\u751f\u5bf9AI\u7684\u4fe1\u4efb\uff0c\u4fdd\u6301\u533b\u751f\u4e13\u4e1a\u4e3b\u5bfc\u5730\u4f4d\u7684\u540c\u65f6\u63d0\u5347\u8bca\u65ad\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2510.24199", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24199", "abs": "https://arxiv.org/abs/2510.24199", "authors": ["Loek van Everdingen", "Jaimy Plugge", "Tim Fuchs", "Guido van de Stolpe", "Dalal Benali", "Thijmen de Jong", "Jasper Bijl", "Wim Bosch", "Tjerk Oosterkamp"], "title": "A Sub-kHz Mechanical Resonator Passively Cooled to 6 mK", "comment": "8 pages, 3 figures", "summary": "Fundamental tests of quantum mechanics, such as the generation of\nnon-classical states and tests of wavefunction collapse models, are performed\non increasingly larger size and mass scales. Highly coherent mechanical\nresonators, which also prove invaluable in ultrasensitive microscopy methods,\nare essential tools towards these efforts. Studying these resonators in a\nthermal equilibrium state at millikelvin temperatures provides a promising path\nto increase their coherence time. Here, we passively cool a 700 Hz, massive\n(1.5 ng) mechanical cantilever down to 6.1(4)mK by means of nuclear\ndemagnetization, as confirmed by detecting its thermal motion via a lock-in\nbased detection scheme. At the lowest temperatures the thermal motion of the\nresonator is still clearly distinguishable from the background noise. Our data\nanalysis confirms that at these temperatures the motion is still thermally\ndistributed. These results pave the way for passiveof cooling low-frequency\nresonators to the sub-milllikelvin regime, which would enable new tests of\nquantum mechanics and advances in ultrasensitive force detection.", "AI": {"tldr": "\u901a\u8fc7\u6838\u9000\u78c1\u65b9\u6cd5\u5c061.5\u7eb3\u514b\u3001700\u8d6b\u5179\u7684\u673a\u68b0\u60ac\u81c2\u6881\u88ab\u52a8\u51b7\u5374\u81f36.1\u6beb\u5f00\u5c14\u6587\uff0c\u9a8c\u8bc1\u4e86\u5176\u70ed\u8fd0\u52a8\u4ecd\u53ef\u88ab\u68c0\u6d4b\uff0c\u4e3a\u91cf\u5b50\u529b\u5b66\u6d4b\u8bd5\u548c\u8d85\u7075\u654f\u529b\u68c0\u6d4b\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002", "motivation": "\u5728\u66f4\u5927\u5c3a\u5ea6\u548c\u8d28\u91cf\u4e0a\u8fdb\u884c\u91cf\u5b50\u529b\u5b66\u57fa\u7840\u6d4b\u8bd5\uff08\u5982\u975e\u7ecf\u5178\u6001\u751f\u6210\u548c\u6ce2\u51fd\u6570\u574d\u7f29\u6a21\u578b\u6d4b\u8bd5\uff09\u9700\u8981\u9ad8\u5ea6\u76f8\u5e72\u7684\u673a\u68b0\u8c10\u632f\u5668\uff0c\u5728\u6beb\u5f00\u5c14\u6587\u6e29\u5ea6\u4e0b\u7814\u7a76\u8fd9\u4e9b\u8c10\u632f\u5668\u53ef\u663e\u8457\u63d0\u9ad8\u5176\u76f8\u5e72\u65f6\u95f4\u3002", "method": "\u91c7\u7528\u6838\u9000\u78c1\u65b9\u6cd5\u88ab\u52a8\u51b7\u5374\u673a\u68b0\u60ac\u81c2\u6881\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u9501\u76f8\u653e\u5927\u5668\u7684\u68c0\u6d4b\u65b9\u6848\u68c0\u6d4b\u5176\u70ed\u8fd0\u52a8\u3002", "result": "\u6210\u529f\u5c061.5\u7eb3\u514b\u3001700\u8d6b\u5179\u7684\u673a\u68b0\u60ac\u81c2\u6881\u51b7\u5374\u81f36.1(4)\u6beb\u5f00\u5c14\u6587\uff0c\u5728\u6700\u4f4e\u6e29\u5ea6\u4e0b\u8c10\u632f\u5668\u7684\u70ed\u8fd0\u52a8\u4ecd\u80fd\u6e05\u6670\u533a\u5206\u4e8e\u80cc\u666f\u566a\u58f0\uff0c\u6570\u636e\u5206\u6790\u786e\u8ba4\u8fd0\u52a8\u4ecd\u5448\u70ed\u5206\u5e03\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u5c06\u4f4e\u9891\u8c10\u632f\u5668\u88ab\u52a8\u51b7\u5374\u81f3\u4e9a\u6beb\u5f00\u5c14\u6587\u533a\u57df\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5c06\u4fc3\u8fdb\u91cf\u5b50\u529b\u5b66\u65b0\u6d4b\u8bd5\u548c\u8d85\u7075\u654f\u529b\u68c0\u6d4b\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.23657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23657", "abs": "https://arxiv.org/abs/2510.23657", "authors": ["Saklain Niam", "Tashfiqur Rahman", "Md. Amjad Patwary", "Mukarram Hossain"], "title": "A machine learning framework integrating seed traits and plasma parameters for predicting germination uplift in crops", "comment": null, "summary": "Cold plasma (CP) is an eco-friendly method to enhance seed germination, yet\noutcomes remain difficult to predict due to complex seed--plasma--environment\ninteractions. This study introduces the first machine learning framework to\nforecast germination uplift in soybean, barley, sunflower, radish, and tomato\nunder dielectric barrier discharge (DBD) plasma. Among the models tested (GB,\nXGB, ET, and hybrids), Extra Trees (ET) performed best (R\\textsuperscript{2} =\n0.919; RMSE = 3.21; MAE = 2.62), improving to R\\textsuperscript{2} = 0.925\nafter feature reduction. Engineering analysis revealed a hormetic response:\nnegligible effects at $<$7 kV or $<$200 s, maximum germination at 7--15 kV for\n200--500 s, and reduced germination beyond 20 kV or prolonged exposures.\nDischarge power was also a dominant factor, with germination rate maximizing at\n$\\geq$100 W with low exposure time. Species and cultivar-level predictions\nshowed radish (MAE = 1.46) and soybean (MAE = 2.05) were modeled with high\nconsistency, while sunflower remained slightly higher variable (MAE = 3.80).\nAmong cultivars, Williams (MAE = 1.23) and Sari (1.33) were well predicted,\nwhile Arian (2.86) and Ny\\'{\\i}rs\\'{e}gi fekete (3.74) were comparatively\npoorly captured. This framework was also embedded into MLflow, providing a\ndecision-support tool for optimizing CP seed germination in precision\nagriculture.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u9996\u4e2a\u673a\u5668\u5b66\u4e60\u6846\u67b6\u6765\u9884\u6d4b\u51b7\u7b49\u79bb\u5b50\u4f53\u5904\u7406\u4e0b\u591a\u79cd\u4f5c\u7269\u7684\u53d1\u82bd\u63d0\u5347\u6548\u679c\uff0c\u5176\u4e2dExtra Trees\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u63ed\u793a\u4e86\u7b49\u79bb\u5b50\u4f53\u5904\u7406\u7684\u6fc0\u7d20\u6548\u5e94\u3002", "motivation": "\u51b7\u7b49\u79bb\u5b50\u4f53\u662f\u4e00\u79cd\u73af\u4fdd\u7684\u4fc3\u8fdb\u79cd\u5b50\u53d1\u82bd\u7684\u65b9\u6cd5\uff0c\u4f46\u7531\u4e8e\u590d\u6742\u7684\u79cd\u5b50-\u7b49\u79bb\u5b50\u4f53-\u73af\u5883\u76f8\u4e92\u4f5c\u7528\uff0c\u7ed3\u679c\u96be\u4ee5\u9884\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5305\u62ec\u68af\u5ea6\u63d0\u5347\u3001XGBoost\u3001Extra Trees\u53ca\u5176\u6df7\u5408\u6a21\u578b\uff09\u6765\u9884\u6d4b\u5927\u8c46\u3001\u5927\u9ea6\u3001\u5411\u65e5\u8475\u3001\u841d\u535c\u548c\u756a\u8304\u5728\u4ecb\u8d28\u963b\u6321\u653e\u7535\u7b49\u79bb\u5b50\u4f53\u5904\u7406\u4e0b\u7684\u53d1\u82bd\u63d0\u5347\u3002", "result": "Extra Trees\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08R\u00b2=0.919\uff1bRMSE=3.21\uff1bMAE=2.62\uff09\uff0c\u7279\u5f81\u51cf\u5c11\u540e\u8fdb\u4e00\u6b65\u63d0\u5347\u81f3R\u00b2=0.925\u3002\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u6fc0\u7d20\u6548\u5e94\uff1a\u5728<7kV\u6216<200s\u65f6\u6548\u679c\u4e0d\u660e\u663e\uff0c\u57287-15kV\u3001200-500s\u65f6\u53d1\u82bd\u7387\u6700\u9ad8\uff0c\u8d85\u8fc720kV\u6216\u957f\u65f6\u95f4\u66b4\u9732\u4f1a\u964d\u4f4e\u53d1\u82bd\u7387\u3002", "conclusion": "\u8be5\u673a\u5668\u5b66\u4e60\u6846\u67b6\u6210\u529f\u9884\u6d4b\u4e86\u51b7\u7b49\u79bb\u5b50\u4f53\u5904\u7406\u7684\u79cd\u5b50\u53d1\u82bd\u6548\u679c\uff0c\u5e76\u96c6\u6210\u5230MLflow\u4e2d\uff0c\u4e3a\u7cbe\u51c6\u519c\u4e1a\u4e2d\u7684\u79cd\u5b50\u5904\u7406\u4f18\u5316\u63d0\u4f9b\u4e86\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002"}}
{"id": "2510.24253", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24253", "abs": "https://arxiv.org/abs/2510.24253", "authors": ["Marcin \u0141obejko", "Tanmoy Biswas", "Micha\u0142 Horodecki"], "title": "Equivalence of Discrete and Continuous Otto-Like Engines assisted by Catalysts: Mapping Catalytic Advantages from the Discrete to the Continuous Framework", "comment": null, "summary": "The catalytic extension of a discrete two-stroke engine employs a cyclic\nauxiliary system - the catalyst - that remains decoupled from the baths and\nperforms no work, yet enhances power and efficiency beyond the corresponding\nnon-catalytic counterpart. Theoretical models of discrete engines are\nrelatively easy to analyze but remain challenging for experimental\nimplementation due to the required control over individual strokes. In\ncontrast, externally driven engines that are simultaneously coupled to both\nheat baths - the so-called continuous engines - are more experimentally\nfeasible. Here, we establish an equivalence between discrete and continuous\nmachines, both with and without a catalyst, by mapping the discrete unitary\nprocesses and thermalization steps onto an interaction Hamiltonian and a\nMarkovian model of dissipation. As a result, by replacing probability flows\nwith probability currents, we construct an analogous continuous machine\ncorresponding to previously demonstrated catalytic schemes that generalize Otto\nengines. We illustrate this mapping for the simplest catalytic extension of the\nOtto engine, demonstrating catalytic enhancement in the continuous regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u79bb\u6563\u548c\u8fde\u7eed\u70ed\u673a\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u901a\u8fc7\u5c06\u79bb\u6563\u7684\u9149\u8fc7\u7a0b\u548c\u70ed\u5316\u6b65\u9aa4\u6620\u5c04\u5230\u76f8\u4e92\u4f5c\u7528\u54c8\u5bc6\u987f\u91cf\u548c\u9a6c\u5c14\u53ef\u592b\u8017\u6563\u6a21\u578b\uff0c\u6784\u5efa\u4e86\u5bf9\u5e94\u7684\u8fde\u7eed\u673a\u5668\uff0c\u5e76\u5c55\u793a\u4e86\u50ac\u5316\u589e\u5f3a\u6548\u5e94\u5728\u8fde\u7eed\u4f53\u7cfb\u4e2d\u7684\u5b9e\u73b0\u3002", "motivation": "\u79bb\u6563\u70ed\u673a\u7406\u8bba\u6a21\u578b\u6613\u4e8e\u5206\u6790\u4f46\u5b9e\u9a8c\u5b9e\u73b0\u56f0\u96be\uff0c\u800c\u8fde\u7eed\u70ed\u673a\u66f4\u6613\u4e8e\u5b9e\u9a8c\u5b9e\u73b0\u3002\u7814\u7a76\u65e8\u5728\u5efa\u7acb\u79bb\u6563\u4e0e\u8fde\u7eed\u70ed\u673a\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u5c06\u5df2\u8bc1\u660e\u7684\u50ac\u5316\u65b9\u6848\u6269\u5c55\u5230\u8fde\u7eed\u4f53\u7cfb\u3002", "method": "\u901a\u8fc7\u5c06\u79bb\u6563\u9149\u8fc7\u7a0b\u548c\u70ed\u5316\u6b65\u9aa4\u6620\u5c04\u5230\u76f8\u4e92\u4f5c\u7528\u54c8\u5bc6\u987f\u91cf\u548c\u9a6c\u5c14\u53ef\u592b\u8017\u6563\u6a21\u578b\uff0c\u7528\u6982\u7387\u6d41\u66ff\u6362\u6982\u7387\u7535\u6d41\uff0c\u6784\u5efa\u4e0e\u79bb\u6563\u50ac\u5316\u65b9\u6848\u5bf9\u5e94\u7684\u8fde\u7eed\u673a\u5668\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u79bb\u6563\u4e0e\u8fde\u7eed\u70ed\u673a\u4e4b\u95f4\u7684\u7b49\u4ef7\u6620\u5c04\uff0c\u5e76\u5728\u6700\u7b80\u5355\u7684\u5965\u6258\u5f15\u64ce\u50ac\u5316\u6269\u5c55\u4e2d\u5c55\u793a\u4e86\u8fde\u7eed\u4f53\u7cfb\u4e2d\u7684\u50ac\u5316\u589e\u5f3a\u6548\u5e94\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u50ac\u5316\u70ed\u673a\u7684\u5b9e\u9a8c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\uff0c\u901a\u8fc7\u8fde\u7eed\u4f53\u7cfb\u5b9e\u73b0\u4e86\u79bb\u6563\u50ac\u5316\u65b9\u6848\u7684\u6027\u80fd\u63d0\u5347\uff0c\u63a8\u52a8\u4e86\u70ed\u673a\u7406\u8bba\u5411\u5b9e\u9a8c\u5e94\u7528\u7684\u8f6c\u5316\u3002"}}
{"id": "2510.23659", "categories": ["cs.LG", "cs.CV", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.23659", "abs": "https://arxiv.org/abs/2510.23659", "authors": ["Md. Farhan Shahriyar", "Gazi Tanbhir", "Abdullah Md Raihan Chy"], "title": "Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "comment": null, "summary": "Recently, there has been growing attention on combining quantum machine\nlearning (QML) with classical deep learning approaches, as computational\ntechniques are key to improving the performance of image classification tasks.\nThis study presents a hybrid approach that uses ResNet-50 (Residual Network)\nfor feature extraction and Quantum Support Vector Machines (QSVM) for\nclassification in the context of potato disease detection. Classical machine\nlearning as well as deep learning models often struggle with high-dimensional\nand complex datasets, necessitating advanced techniques like quantum computing\nto improve classification efficiency. In our research, we use ResNet-50 to\nextract deep feature representations from RGB images of potato diseases. These\nfeatures are then subjected to dimensionality reduction using Principal\nComponent Analysis (PCA). The resulting features are processed through QSVM\nmodels which apply various quantum feature maps such as ZZ, Z, and Pauli-X to\ntransform classical data into quantum states. To assess the model performance,\nwe compared it with classical machine learning algorithms such as Support\nVector Machine (SVM) and Random Forest (RF) using five-fold stratified\ncross-validation for comprehensive evaluation. The experimental results\ndemonstrate that the Z-feature map-based QSVM outperforms classical models,\nachieving an accuracy of 99.23 percent, surpassing both SVM and RF models. This\nresearch highlights the advantages of integrating quantum computing into image\nclassification and provides a potential disease detection solution through\nhybrid quantum-classical modeling.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u65b9\u6cd5\uff0c\u4f7f\u7528ResNet-50\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u91cf\u5b50\u652f\u6301\u5411\u91cf\u673a(QSVM)\u8fdb\u884c\u5206\u7c7b\uff0c\u7528\u4e8e\u9a6c\u94c3\u85af\u75be\u75c5\u68c0\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8eZ\u7279\u5f81\u56fe\u7684QSVM\u51c6\u786e\u7387\u8fbe\u523099.23%\uff0c\u4f18\u4e8e\u4f20\u7edfSVM\u548c\u968f\u673a\u68ee\u6797\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u9ad8\u7ef4\u590d\u6742\u6570\u636e\u96c6\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u91cf\u5b50\u8ba1\u7b97\u7b49\u5148\u8fdb\u6280\u672f\u6765\u63d0\u9ad8\u5206\u7c7b\u6548\u7387\u3002\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e0e\u7ecf\u5178\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u6709\u671b\u63d0\u5347\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528ResNet-50\u4ece\u9a6c\u94c3\u85af\u75be\u75c5RGB\u56fe\u50cf\u4e2d\u63d0\u53d6\u6df1\u5ea6\u7279\u5f81\u8868\u793a\uff0c\u901a\u8fc7\u4e3b\u6210\u5206\u5206\u6790(PCA)\u8fdb\u884c\u964d\u7ef4\uff0c\u7136\u540e\u4f7f\u7528QSVM\u6a21\u578b\u5904\u7406\u7279\u5f81\uff0c\u5e94\u7528ZZ\u3001Z\u548cPauli-X\u7b49\u91cf\u5b50\u7279\u5f81\u56fe\u5c06\u7ecf\u5178\u6570\u636e\u8f6c\u6362\u4e3a\u91cf\u5b50\u6001\u3002", "result": "\u57fa\u4e8eZ\u7279\u5f81\u56fe\u7684QSVM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe\u523099.23%\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u652f\u6301\u5411\u91cf\u673a(SVM)\u548c\u968f\u673a\u68ee\u6797(RF)\u6a21\u578b\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u7a81\u51fa\u4e86\u5c06\u91cf\u5b50\u8ba1\u7b97\u96c6\u6210\u5230\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u901a\u8fc7\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u5efa\u6a21\u63d0\u4f9b\u4e86\u6f5c\u5728\u7684\u75be\u75c5\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24161", "categories": ["cs.AI", "cs.MM", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24161", "abs": "https://arxiv.org/abs/2510.24161", "authors": ["Wentao Tan", "Bowen Wang", "Heng Zhi", "Chenyu Liu", "Zhe Li", "Jian Liu", "Zengrong Lin", "Yukun Dai", "Yipeng Chen", "Wenjie Yang", "Enci Xie", "Hao Xue", "Baixu Ji", "Chen Xu", "Zhibin Wang", "Tianshi Wang", "Lei Zhu", "Heng Tao Shen"], "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks.", "AI": {"tldr": "BLM\u2081\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u8de8\u7a7a\u95f4\u8f6c\u79fb\u3001\u8de8\u4efb\u52a1\u5b66\u4e60\u548c\u8de8\u5177\u8eab\u6cdb\u5316\uff0c\u5728\u6570\u5b57\u548c\u7269\u7406\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709MLLMs\u5728\u6570\u5b57-\u7269\u7406\u7a7a\u95f4\u95f4\u6cdb\u5316\u80fd\u529b\u5dee\uff0cVLAs\u7f3a\u4e4f\u9ad8\u7ea7\u5177\u8eab\u63a8\u7406\u80fd\u529b\uff0cELLMs\u5c40\u9650\u4e8e\u6570\u5b57\u7a7a\u95f4\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u8de8\u7a7a\u95f4\u548c\u8de8\u5177\u8eab\u6a21\u578b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1a\u9636\u6bb5I\u901a\u8fc7\u7cbe\u9009\u6570\u5b57\u8bed\u6599\u6ce8\u5165\u5177\u8eab\u77e5\u8bc6\uff0c\u4fdd\u6301\u8bed\u8a00\u80fd\u529b\uff1b\u9636\u6bb5II\u901a\u8fc7\u610f\u56fe\u6865\u63a5\u63a5\u53e3\u8bad\u7ec3\u7b56\u7565\u6a21\u5757\uff0c\u63d0\u53d6MLLM\u7684\u9ad8\u7ea7\u8bed\u4e49\u6307\u5bfc\u63a7\u5236\u3002", "result": "\u5728\u6570\u5b57\u548c\u7269\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5355\u4e2aBLM\u2081\u5b9e\u4f8b\u4f18\u4e8eMLLMs\u3001ELLMs\u3001VLAs\u548cGMLMs\u56db\u4e2a\u6a21\u578b\u5bb6\u65cf\uff0c\u6570\u5b57\u4efb\u52a1\u63d0\u5347\u7ea66%\uff0c\u7269\u7406\u4efb\u52a1\u63d0\u5347\u7ea63%\u3002", "conclusion": "BLM\u2081\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u7a7a\u95f4\u3001\u8de8\u4efb\u52a1\u548c\u8de8\u5177\u8eab\u7684\u7edf\u4e00\u5efa\u6a21\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24275", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2510.24275", "abs": "https://arxiv.org/abs/2510.24275", "authors": ["Christof Wetterich"], "title": "Quantum evolution with classical fields", "comment": "9 pages", "summary": "Wave guides for classical electromagnetic fields can realize the quantum\nevolution of the wave function for a system of qubits.\n  Phase shifts, switches and beam splits allow for the construction of\narbitrary quantum gates.\n  They can act at once on a large number of qubits.\n  For this correlation based photonic quantum computer the channels of the wave\nguides represent basis states of a multi-qubit system rather than individual\nqubits.\n  The classical probabilistic implementation of a quantum evolution sheds new\nlight on the foundations of quantum mechanics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce2\u5bfc\u7684\u91cf\u5b50\u8ba1\u7b97\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u7ecf\u5178\u7535\u78c1\u573a\u7684\u6ce2\u5bfc\u6765\u6a21\u62df\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u7684\u6ce2\u51fd\u6570\u6f14\u5316\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u7684\u65b0\u5b9e\u73b0\u65b9\u5f0f\uff0c\u901a\u8fc7\u7ecf\u5178\u7535\u78c1\u573a\u6ce2\u5bfc\u7cfb\u7edf\u6765\u6a21\u62df\u91cf\u5b50\u6f14\u5316\uff0c\u4e3a\u91cf\u5b50\u529b\u5b66\u57fa\u7840\u63d0\u4f9b\u65b0\u7684\u89c6\u89d2\u3002", "method": "\u5229\u7528\u6ce2\u5bfc\u4e2d\u7684\u76f8\u79fb\u3001\u5f00\u5173\u548c\u5206\u675f\u5668\u7b49\u5149\u5b66\u5143\u4ef6\u6784\u5efa\u4efb\u610f\u91cf\u5b50\u95e8\uff0c\u6ce2\u5bfc\u901a\u9053\u4ee3\u8868\u591a\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u7684\u57fa\u6001\u800c\u975e\u5355\u4e2a\u91cf\u5b50\u6bd4\u7279\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5173\u8054\u7684\u5149\u5b50\u91cf\u5b50\u8ba1\u7b97\u673a\u67b6\u6784\uff0c\u80fd\u591f\u540c\u65f6\u5bf9\u5927\u91cf\u91cf\u5b50\u6bd4\u7279\u8fdb\u884c\u64cd\u4f5c\u3002", "conclusion": "\u7ecf\u5178\u6982\u7387\u6027\u5b9e\u73b0\u91cf\u5b50\u6f14\u5316\u4e3a\u91cf\u5b50\u529b\u5b66\u57fa\u7840\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u7ecf\u5178\u7cfb\u7edf\u6a21\u62df\u91cf\u5b50\u884c\u4e3a\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.24316", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24316", "abs": "https://arxiv.org/abs/2510.24316", "authors": ["Kyeongan Park", "Gwonhak Lee", "Minhyeok Kang", "Youngjun Park", "Joonsuk Huh"], "title": "Jacobi-Anger Density Estimation for Energy Distribution of Quantum States", "comment": null, "summary": "The energy distribution of a quantum state is essential for accurately\nestimating a molecule's ground state energy in quantum computing. Directly\nobtaining this distribution requires full Hamiltonian diagonalization, which is\ncomputationally prohibitive for large-scale systems. A more practical strategy\nis to approximate the distribution from a finite set of Hamiltonian moments.\nHowever, reconstructing an accurate distribution from only a limited number of\nmoments remains a significant challenge. In this work, we introduce\nJacobi-Anger Density Estimation (JADE), a non-parametric, quantum-inspired\nmethod designed to overcome this difficulty. JADE reconstructs the\ncharacteristic function from a finite set of moments using the Jacobi-Anger\nexpansion and then estimates the underlying distribution via an inverse Fourier\ntransform. We demonstrate that JADE can accurately recover the energy\ndistribution of a quantum state for a molecular system. Beyond quantum\nchemistry, we also show that JADE is broadly applicable to the estimation of\ncomplicated probability density functions in various other scientific and\nengineering fields. Our results highlight JADE as a powerful and versatile tool\nfor practical quantum systems, with the potential to significantly enhance\nground state energy estimation and related applications.", "AI": {"tldr": "JADE\u662f\u4e00\u79cd\u975e\u53c2\u6570\u91cf\u5b50\u542f\u53d1\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c5\u53ef\u6bd4-\u5b89\u683c\u5c14\u5c55\u5f00\u4ece\u6709\u9650\u54c8\u5bc6\u987f\u77e9\u91cd\u5efa\u7279\u5f81\u51fd\u6570\uff0c\u518d\u901a\u8fc7\u9006\u5085\u91cc\u53f6\u53d8\u6362\u4f30\u8ba1\u80fd\u91cf\u5206\u5e03\uff0c\u89e3\u51b3\u4e86\u4ece\u6709\u9650\u77e9\u51c6\u786e\u91cd\u5efa\u80fd\u91cf\u5206\u5e03\u7684\u6311\u6218\u3002", "motivation": "\u91cf\u5b50\u6001\u7684\u80fd\u91cf\u5206\u5e03\u5bf9\u51c6\u786e\u4f30\u8ba1\u5206\u5b50\u57fa\u6001\u80fd\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76f4\u63a5\u83b7\u53d6\u9700\u8981\u5b8c\u5168\u54c8\u5bc6\u987f\u5bf9\u89d2\u5316\uff0c\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002\u4ece\u6709\u9650\u54c8\u5bc6\u987f\u77e9\u8fd1\u4f3c\u5206\u5e03\u66f4\u5b9e\u7528\uff0c\u4f46\u51c6\u786e\u91cd\u5efa\u5206\u5e03\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faJADE\u65b9\u6cd5\uff1a\u4f7f\u7528\u96c5\u53ef\u6bd4-\u5b89\u683c\u5c14\u5c55\u5f00\u4ece\u6709\u9650\u77e9\u91cd\u5efa\u7279\u5f81\u51fd\u6570\uff0c\u7136\u540e\u901a\u8fc7\u9006\u5085\u91cc\u53f6\u53d8\u6362\u4f30\u8ba1\u5e95\u5c42\u5206\u5e03\u3002\u8fd9\u662f\u4e00\u79cd\u975e\u53c2\u6570\u3001\u91cf\u5b50\u542f\u53d1\u7684\u65b9\u6cd5\u3002", "result": "JADE\u80fd\u51c6\u786e\u6062\u590d\u5206\u5b50\u7cfb\u7edf\u4e2d\u91cf\u5b50\u6001\u7684\u80fd\u91cf\u5206\u5e03\uff0c\u4e14\u8bc1\u660e\u5728\u91cf\u5b50\u5316\u5b66\u4ee5\u5916\u7684\u5404\u79cd\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u4e5f\u9002\u7528\u4e8e\u590d\u6742\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u7684\u4f30\u8ba1\u3002", "conclusion": "JADE\u662f\u4e00\u4e2a\u5f3a\u5927\u4e14\u591a\u529f\u80fd\u7684\u5b9e\u7528\u91cf\u5b50\u7cfb\u7edf\u5de5\u5177\uff0c\u6709\u6f5c\u529b\u663e\u8457\u589e\u5f3a\u57fa\u6001\u80fd\u91cf\u4f30\u8ba1\u53ca\u76f8\u5173\u5e94\u7528\u3002"}}
{"id": "2510.23663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23663", "abs": "https://arxiv.org/abs/2510.23663", "authors": ["Padmanabhan Jagannathan Prajesh", "Kaliaperumal Ragunath", "Miriam Gordon", "Bruce Rathgeber", "Suresh Neethirajan"], "title": "AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions", "comment": null, "summary": "Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes\nis essential for guiding emission mitigation strategies. We present a\nSpatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that\nreconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across\nsouthern Canada, emphasizing poultry-intensive regions. The model fuses wavelet\ntime-frequency representations with transformer attention over meteorology,\nvegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT\nattains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions\nlie within +/-1 ppm. Independent validation with TCCON shows robust\ngeneralization (bias = -0.14 ppm; r = 0.928), including faithful reproduction\nof the late-summer drawdown. Spatial analysis across 14 poultry regions reveals\na moderate positive association between facility density and XCO2 (r = 0.43);\nhigh-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced\nsummer variability. Compared with conventional interpolation and standard\nmachine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces\nwith explicit uncertainties, enabling year-round coverage despite sparse\nobservations. The approach supports integration of satellite constraints with\nnational inventories and precision livestock platforms to benchmark emissions,\nrefine region-specific factors, and verify interventions. Importantly,\ntransformer-based Earth observation enables scalable, transparent, spatially\nexplicit carbon accounting, hotspot prioritization, and policy-relevant\nmitigation assessment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u53d8\u6362\u548c\u89c6\u89c9Transformer\u7684\u65f6\u7a7a\u6846\u67b6ST-ViWT\uff0c\u7528\u4e8e\u4ece\u7a00\u758f\u7684OCO-2\u536b\u661f\u89c2\u6d4b\u4e2d\u91cd\u5efa\u8fde\u7eed\u4e14\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u67f1\u5e73\u5747CO2\u6d53\u5ea6\u573a\uff0c\u7279\u522b\u5173\u6ce8\u5bb6\u79bd\u517b\u6b96\u5bc6\u96c6\u533a\u57df\u3002", "motivation": "\u51c6\u786e\u7ed8\u5236\u519c\u4e1a\u666f\u89c2\u4e0a\u7a7a\u7684\u67f1\u5e73\u5747CO2\u6d53\u5ea6\u5bf9\u4e8e\u6307\u5bfc\u6392\u653e\u51cf\u7f13\u7b56\u7565\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u5bb6\u79bd\u517b\u6b96\u5bc6\u96c6\u533a\u57df\uff0c\u9700\u8981\u4ece\u7a00\u758f\u7684\u536b\u661f\u89c2\u6d4b\u4e2d\u91cd\u5efa\u8fde\u7eed\u7684\u9ad8\u8d28\u91cfCO2\u6d53\u5ea6\u573a\u3002", "method": "ST-ViWT\u6846\u67b6\u878d\u5408\u4e86\u5c0f\u6ce2\u65f6\u9891\u8868\u793a\u4e0eTransformer\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6574\u5408\u6c14\u8c61\u6570\u636e\u3001\u690d\u88ab\u6307\u6570\u3001\u5730\u5f62\u548c\u571f\u5730\u8986\u76d6\u4fe1\u606f\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u91cd\u5efaXCO2\u573a\u3002", "result": "\u57282024\u5e74OCO-2\u6570\u636e\u4e0a\uff0c\u6a21\u578b\u8fbe\u5230R2=0.984\u548cRMSE=0.468 ppm\uff1b92.3%\u7684\u586b\u8865\u9884\u6d4b\u5728\u00b11 ppm\u8303\u56f4\u5185\u3002\u72ec\u7acb\u9a8c\u8bc1\u663e\u793a\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff08\u504f\u5dee=-0.14 ppm\uff1br=0.928\uff09\uff0c\u80fd\u591f\u51c6\u786e\u518d\u73b0\u590f\u5b63\u672b\u7684CO2\u4e0b\u964d\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u652f\u6301\u536b\u661f\u7ea6\u675f\u4e0e\u56fd\u5bb6\u6e05\u5355\u548c\u7cbe\u51c6\u755c\u7267\u4e1a\u5e73\u53f0\u7684\u6574\u5408\uff0c\u4e3a\u6392\u653e\u57fa\u51c6\u6d4b\u8bd5\u3001\u533a\u57df\u7279\u5b9a\u56e0\u5b50\u4f18\u5316\u548c\u5e72\u9884\u9a8c\u8bc1\u63d0\u4f9b\u652f\u6301\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u900f\u660e\u3001\u7a7a\u95f4\u660e\u786e\u7684\u78b3\u6838\u7b97\u548c\u70ed\u70b9\u4f18\u5148\u6392\u5e8f\u3002"}}
{"id": "2510.24323", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24323", "abs": "https://arxiv.org/abs/2510.24323", "authors": ["Evandro C. R. Rosa", "Jerusa Marchi", "Eduardo I. Duzzioni", "Rafael de Santiago"], "title": "Optimizing Quantum Compilation via High-Level Quantum Instructions", "comment": null, "summary": "Current quantum programming is dominated by low-level, circuit-centric\napproaches that limit the potential for compiler optimization. This work\npresents how a high-level programming construct provides compilers with the\nsemantic information needed for advanced optimizations. We introduce a novel\noptimization that leverages a quantum-specific instruction to automatically\nsubstitute quantum gates with more efficient, approximate decompositions, a\nprocess that is transparent to the programmer and significantly reduces quantum\nresource requirements. Furthermore, we show how this instruction guarantees the\ncorrect uncomputation of auxiliary qubits, enabling safe, dynamic quantum\nmemory management. We illustrate these concepts by implementing a V-chain\ndecomposition of the multi-controlled NOT gate, showing that our high-level\napproach not only simplifies the code but also enables the compiler to generate\na circuit with up to a 50% reduction in CNOT gates. Our results suggest that\nhigh-level abstractions are crucial for unlocking a new class of powerful\ncompiler optimizations, paving the way for more efficient quantum computation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u7ea7\u91cf\u5b50\u7f16\u7a0b\u6784\u9020\uff0c\u901a\u8fc7\u63d0\u4f9b\u8bed\u4e49\u4fe1\u606f\u4f7f\u7f16\u8bd1\u5668\u80fd\u591f\u8fdb\u884c\u9ad8\u7ea7\u4f18\u5316\uff0c\u5305\u62ec\u81ea\u52a8\u7528\u66f4\u9ad8\u6548\u7684\u8fd1\u4f3c\u5206\u89e3\u66ff\u6362\u91cf\u5b50\u95e8\uff0c\u4ee5\u53ca\u4fdd\u8bc1\u8f85\u52a9\u91cf\u5b50\u4f4d\u7684\u6b63\u786e\u53cd\u8ba1\u7b97\uff0c\u5b9e\u73b0\u52a8\u6001\u91cf\u5b50\u5185\u5b58\u7ba1\u7406\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u7f16\u7a0b\u4e3b\u8981\u91c7\u7528\u4f4e\u7ea7\u7684\u7535\u8def\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u9650\u5236\u4e86\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u6f5c\u529b\u3002\u9700\u8981\u9ad8\u7ea7\u7f16\u7a0b\u6784\u9020\u6765\u63d0\u4f9b\u8bed\u4e49\u4fe1\u606f\uff0c\u4ee5\u652f\u6301\u66f4\u5f3a\u5927\u7684\u7f16\u8bd1\u5668\u4f18\u5316\u3002", "method": "\u5f15\u5165\u91cf\u5b50\u7279\u5b9a\u6307\u4ee4\uff0c\u81ea\u52a8\u5c06\u91cf\u5b50\u95e8\u66ff\u6362\u4e3a\u66f4\u9ad8\u6548\u7684\u8fd1\u4f3c\u5206\u89e3\uff0c\u5e76\u4fdd\u8bc1\u8f85\u52a9\u91cf\u5b50\u4f4d\u7684\u6b63\u786e\u53cd\u8ba1\u7b97\u3002\u901a\u8fc7\u5b9e\u73b0\u591a\u63a7\u5236NOT\u95e8\u7684V\u94fe\u5206\u89e3\u6765\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "\u9ad8\u7ea7\u65b9\u6cd5\u4e0d\u4ec5\u7b80\u5316\u4e86\u4ee3\u7801\uff0c\u8fd8\u4f7f\u7f16\u8bd1\u5668\u751f\u6210\u7684\u7535\u8defCNOT\u95e8\u6570\u91cf\u51cf\u5c11\u4e86\u9ad8\u8fbe50%\u3002", "conclusion": "\u9ad8\u7ea7\u62bd\u8c61\u5bf9\u4e8e\u89e3\u9501\u5f3a\u5927\u7684\u7f16\u8bd1\u5668\u4f18\u5316\u7c7b\u522b\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u66f4\u9ad8\u6548\u7684\u91cf\u5b50\u8ba1\u7b97\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.23665", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23665", "abs": "https://arxiv.org/abs/2510.23665", "authors": ["Juan C. Leon Alcazar", "Mattia Soldan", "Mohammad Saatialsoruji", "Alejandro Pardo", "Hani Itani", "Juan Camilo Perez", "Bernard Ghanem"], "title": "Transformers from Compressed Representations", "comment": null, "summary": "Compressed file formats are the corner stone of efficient data storage and\ntransmission, yet their potential for representation learning remains largely\nunderexplored. We introduce TEMPEST (TransformErs froM comPressed\nrEpreSenTations), a method that exploits the inherent byte-stream structure of\ncompressed files to design an effective tokenization and encoding strategy. By\nleveraging this compact encoding, a standard transformer can directly learn\nsemantic representations from compressed data streams, bypassing the need for\nraw byte-level processing or full media decoding. Our proposal substantially\nreduces the number of tokens required for semantic classification, thereby\nlowering both computational complexity and memory usage. Through extensive\nexperiments across diverse datasets, coding schemes, and modalities, we show\nthat TEMPEST achieves accuracy competitive wit the state-of-the-art while\ndelivering efficiency gains in memory and compute.", "AI": {"tldr": "TEMPEST\u662f\u4e00\u79cd\u5229\u7528\u538b\u7f29\u6587\u4ef6\u56fa\u6709\u5b57\u8282\u6d41\u7ed3\u6784\u8fdb\u884c\u8868\u793a\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u538b\u7f29\u7f16\u7801\u8ba9\u6807\u51c6transformer\u76f4\u63a5\u4ece\u538b\u7f29\u6570\u636e\u6d41\u4e2d\u5b66\u4e60\u8bed\u4e49\u8868\u793a\uff0c\u663e\u8457\u51cf\u5c11\u8bed\u4e49\u5206\u7c7b\u6240\u9700\u7684token\u6570\u91cf\u3002", "motivation": "\u538b\u7f29\u6587\u4ef6\u683c\u5f0f\u662f\u9ad8\u6548\u6570\u636e\u5b58\u50a8\u548c\u4f20\u8f93\u7684\u57fa\u7840\uff0c\u4f46\u5176\u5728\u8868\u793a\u5b66\u4e60\u65b9\u9762\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5229\u7528\u538b\u7f29\u6587\u4ef6\u7684\u5b57\u8282\u6d41\u7ed3\u6784\u8bbe\u8ba1\u6709\u6548\u7684token\u5316\u548c\u7f16\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u7d27\u51d1\u7f16\u7801\u4f7f\u6807\u51c6transformer\u80fd\u591f\u76f4\u63a5\u4ece\u538b\u7f29\u6570\u636e\u6d41\u5b66\u4e60\u8bed\u4e49\u8868\u793a\uff0c\u65e0\u9700\u539f\u59cb\u5b57\u8282\u7ea7\u5904\u7406\u6216\u5b8c\u6574\u5a92\u4f53\u89e3\u7801\u3002", "result": "\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u3001\u7f16\u7801\u65b9\u6848\u548c\u6a21\u6001\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTEMPEST\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\u6027\u51c6\u786e\u5ea6\u7684\u540c\u65f6\uff0c\u5728\u5185\u5b58\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u538b\u7f29\u6570\u636e\u7684\u5185\u5728\u7ed3\u6784\uff0c\u4e3a\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5185\u5b58\u4f7f\u7528\u3002"}}
{"id": "2510.24327", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24327", "abs": "https://arxiv.org/abs/2510.24327", "authors": ["Valia Allori"], "title": "Mind, Matter, and Freedom in Quantum Mechanics and the de Broglie-Bohm Theory", "comment": "Conference BOHM IN BRAZIL (BiB) UNIVERSITY OF SAO PAULO (USP) July\n  2025", "summary": "There are several important philosophical problems to which quantum mechanics\nis often said to have made significant contributions:\n  - Determinism: quantum theory has been taken to refute determinism;\n  -Free Will: in turn, this is thought to open the door to free will;\n  - The mind-body problem: relatedly, it is sometimes said to shed light on\nconsciousness;\n  - Idealism: more radically, quantum theory is assumed to have refuted realism\nand to have placed the observer at the center of the world;\n  - Reductionism: even granting realism, it has been claimed that quantum\ntheory undermines reductionism.\n  Our main thesis in this paper is that none of this is either necessary or\ndesirable. By adopting the de Broglie--Bohm theory (or Bohmian mechanics), one\ncan straightforwardly account for quantum phenomena without endorsing any of\nthese claims.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u91cf\u5b50\u529b\u5b66\u5e76\u4e0d\u5fc5\u7136\u652f\u6301\u5bf9\u51b3\u5b9a\u8bba\u3001\u81ea\u7531\u610f\u5fd7\u3001\u5fc3\u8eab\u95ee\u9898\u3001\u552f\u5fc3\u4e3b\u4e49\u548c\u8fd8\u539f\u8bba\u7684\u7279\u5b9a\u54f2\u5b66\u7acb\u573a\uff0c\u901a\u8fc7\u91c7\u7528\u5fb7\u5e03\u7f57\u610f-\u73bb\u59c6\u7406\u8bba\uff08\u73bb\u59c6\u529b\u5b66\uff09\u53ef\u4ee5\u89e3\u91ca\u91cf\u5b50\u73b0\u8c61\u800c\u65e0\u9700\u63a5\u53d7\u8fd9\u4e9b\u54f2\u5b66\u4e3b\u5f20\u3002", "motivation": "\u63a2\u8ba8\u91cf\u5b50\u529b\u5b66\u5bf9\u51e0\u4e2a\u91cd\u8981\u54f2\u5b66\u95ee\u9898\uff08\u51b3\u5b9a\u8bba\u3001\u81ea\u7531\u610f\u5fd7\u3001\u5fc3\u8eab\u95ee\u9898\u3001\u552f\u5fc3\u4e3b\u4e49\u3001\u8fd8\u539f\u8bba\uff09\u7684\u6240\u8c13\u8d21\u732e\uff0c\u5e76\u8d28\u7591\u8fd9\u4e9b\u54f2\u5b66\u89e3\u91ca\u7684\u5fc5\u8981\u6027\u548c\u53ef\u53d6\u6027\u3002", "method": "\u91c7\u7528\u5fb7\u5e03\u7f57\u610f-\u73bb\u59c6\u7406\u8bba\uff08\u73bb\u59c6\u529b\u5b66\uff09\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u5c55\u793a\u8be5\u7406\u8bba\u5982\u4f55\u80fd\u591f\u89e3\u91ca\u91cf\u5b50\u73b0\u8c61\u800c\u4e0d\u9700\u8981\u63a5\u53d7\u7279\u5b9a\u7684\u54f2\u5b66\u4e3b\u5f20\u3002", "result": "\u8bc1\u660e\u901a\u8fc7\u73bb\u59c6\u529b\u5b66\u53ef\u4ee5\u89e3\u91ca\u91cf\u5b50\u73b0\u8c61\uff0c\u540c\u65f6\u907f\u514d\u5bf9\u51b3\u5b9a\u8bba\u3001\u81ea\u7531\u610f\u5fd7\u3001\u5fc3\u8eab\u95ee\u9898\u3001\u552f\u5fc3\u4e3b\u4e49\u548c\u8fd8\u539f\u8bba\u505a\u51fa\u7279\u5b9a\u7684\u54f2\u5b66\u627f\u8bfa\u3002", "conclusion": "\u91cf\u5b50\u529b\u5b66\u5e76\u4e0d\u5fc5\u7136\u8981\u6c42\u63a5\u53d7\u7279\u5b9a\u7684\u54f2\u5b66\u7acb\u573a\uff0c\u73bb\u59c6\u529b\u5b66\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e2\u80fd\u89e3\u91ca\u91cf\u5b50\u73b0\u8c61\u53c8\u4fdd\u6301\u54f2\u5b66\u4e2d\u7acb\u6027\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.23667", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23667", "abs": "https://arxiv.org/abs/2510.23667", "authors": ["Amin Heyrani Nobari", "Lyle Regenwetter", "Cyril Picard", "Ligong Han", "Faez Ahmed"], "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization", "comment": null, "summary": "Structural topology optimization (TO) is central to engineering design but\nremains computationally intensive due to complex physics and hard constraints.\nExisting deep-learning methods are limited to fixed square grids, a few\nhand-coded boundary conditions, and post-hoc optimization, preventing general\ndeployment. We introduce Optimize Any Topology (OAT), a foundation-model\nframework that directly predicts minimum-compliance layouts for arbitrary\naspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines\na resolution- and shape-agnostic autoencoder with an implicit neural-field\ndecoder and a conditional latent-diffusion model trained on OpenTO, a new\ncorpus of 2.2 million optimized structures covering 2 million unique\nboundary-condition configurations. On four public benchmarks and two\nchallenging unseen tests, OAT lowers mean compliance up to 90% relative to the\nbest prior models and delivers sub-1 second inference on a single GPU across\nresolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These\nresults establish OAT as a general, fast, and resolution-free framework for\nphysics-aware topology optimization and provide a large-scale dataset to spur\nfurther research in generative modeling for inverse design. Code & data can be\nfound at https://github.com/ahnobari/OptimizeAnyTopology.", "AI": {"tldr": "OAT\u662f\u4e00\u4e2a\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u62d3\u6251\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u76f4\u63a5\u9884\u6d4b\u4efb\u610f\u957f\u5bbd\u6bd4\u3001\u5206\u8fa8\u7387\u3001\u4f53\u79ef\u5206\u6570\u3001\u8f7d\u8377\u548c\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u6700\u5c0f\u67d4\u5ea6\u5e03\u5c40\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\u5c40\u9650\u4e8e\u56fa\u5b9a\u65b9\u5f62\u7f51\u683c\u3001\u5c11\u91cf\u8fb9\u754c\u6761\u4ef6\u548c\u540e\u5904\u7406\u4f18\u5316\uff0c\u65e0\u6cd5\u5b9e\u73b0\u901a\u7528\u90e8\u7f72\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u4efb\u610f\u8fb9\u754c\u6761\u4ef6\u548c\u51e0\u4f55\u53c2\u6570\u7684\u901a\u7528\u6846\u67b6\u3002", "method": "\u7ed3\u5408\u5206\u8fa8\u7387\u65e0\u5173\u7684\u81ea\u7f16\u7801\u5668\u3001\u9690\u5f0f\u795e\u7ecf\u573a\u89e3\u7801\u5668\u548c\u6761\u4ef6\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u5728\u5305\u542b220\u4e07\u4e2a\u4f18\u5316\u7ed3\u6784\u7684OpenTO\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u57fa\u51c6\u548c\u4e24\u4e2a\u672a\u89c1\u6d4b\u8bd5\u4e2d\uff0cOAT\u5c06\u5e73\u5747\u67d4\u5ea6\u964d\u4f4e\u9ad8\u8fbe90%\uff0c\u5728\u5355GPU\u4e0a\u5b9e\u73b0\u4e9a\u79d2\u7ea7\u63a8\u7406\uff0c\u652f\u630164\u00d764\u5230256\u00d7256\u5206\u8fa8\u7387\u548c\u9ad8\u8fbe10:1\u7684\u957f\u5bbd\u6bd4\u3002", "conclusion": "OAT\u4e3a\u7269\u7406\u611f\u77e5\u62d3\u6251\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u3001\u5feb\u901f\u4e14\u5206\u8fa8\u7387\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5e76\u4e3a\u9006\u5411\u8bbe\u8ba1\u7684\u751f\u6210\u5efa\u6a21\u7814\u7a76\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002"}}
{"id": "2510.24297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24297", "abs": "https://arxiv.org/abs/2510.24297", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms", "comment": null, "summary": "One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which\ncan be addressed by building and using state and/or action abstractions in\nparallel to the tree search such that information can be shared among nodes of\nthe same layer. The primary usage of abstractions for MCTS is to enhance the\nUpper Confidence Bound (UCB) value during the tree policy by aggregating visits\nand returns of an abstract node. However, this direct usage of abstractions\ndoes not take the case into account where multiple actions with the same parent\nmight be in the same abstract node, as these would then all have the same UCB\nvalue, thus requiring a tiebreak rule. In state-of-the-art abstraction\nalgorithms such as pruned On the Go Abstractions (pruned OGA), this case has\nnot been noticed, and a random tiebreak rule was implicitly chosen. In this\npaper, we propose and empirically evaluate several alternative\nintra-abstraction policies, several of which outperform the random policy\nacross a majority of environments and parameter settings.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9MCTS\u4e2d\u7684\u62bd\u8c61\u6280\u672f\u63d0\u51fa\u6539\u8fdb\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u4e2a\u52a8\u4f5c\u5c5e\u4e8e\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u65f6\u5b58\u5728\u5e73\u5c40\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u4e8e\u968f\u673a\u5e73\u5c40\u7b56\u7565\u7684\u591a\u79cd\u5185\u90e8\u62bd\u8c61\u7b56\u7565\u3002", "motivation": "MCTS\u7684\u6837\u672c\u6548\u7387\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u72b6\u6001/\u52a8\u4f5c\u62bd\u8c61\u6765\u89e3\u51b3\uff0c\u4f46\u73b0\u6709\u62bd\u8c61\u65b9\u6cd5\u5728\u591a\u4e2a\u52a8\u4f5c\u5c5e\u4e8e\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u65f6\uff0c\u7531\u4e8eUCB\u503c\u76f8\u540c\u800c\u9700\u8981\u5e73\u5c40\u89c4\u5219\uff0c\u800c\u5f53\u524d\u65b9\u6cd5\uff08\u5982pruned OGA\uff09\u672a\u6ce8\u610f\u5230\u6b64\u95ee\u9898\u5e76\u9690\u5f0f\u4f7f\u7528\u968f\u673a\u5e73\u5c40\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u8bc1\u8bc4\u4f30\u4e86\u591a\u79cd\u66ff\u4ee3\u7684\u5185\u90e8\u62bd\u8c61\u7b56\u7565\uff0c\u7528\u4e8e\u5904\u7406\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u4e2d\u591a\u4e2a\u52a8\u4f5c\u7684\u5e73\u5c40\u60c5\u51b5\u3002", "result": "\u591a\u4e2a\u63d0\u51fa\u7684\u7b56\u7565\u5728\u5927\u591a\u6570\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u968f\u673a\u7b56\u7565\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdb\u5185\u90e8\u62bd\u8c61\u7b56\u7565\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347MCTS\u62bd\u8c61\u6280\u672f\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u4e2d\u591a\u4e2a\u52a8\u4f5c\u7684\u60c5\u51b5\u65f6\u3002"}}
{"id": "2510.24348", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24348", "abs": "https://arxiv.org/abs/2510.24348", "authors": ["Xin Wang", "Rebing Wu"], "title": "Tight Generalization Bound for Supervised Quantum Machine Learning", "comment": "21 pages, 14 figures", "summary": "We derive a tight generalization bound for quantum machine learning that is\napplicable to a wide range of supervised tasks, data, and models. Our bound is\nboth efficiently computable and free of big-O notation. Furthermore, we point\nout that previous bounds relying on big-O notation may provide misleading\nsuggestions regarding the generalization error. Our generalization bound\ndemonstrates that for quantum machine learning models of arbitrary size and\ndepth, the sample size is the most dominant factor governing the generalization\nerror. Additionally, the spectral norm of the measurement observable, the bound\nand Lipschitz constant of the selected risk function also influence the\ngeneralization upper bound. However, the number of quantum gates, the number of\nqubits, data encoding methods, and hyperparameters chosen during the learning\nprocess such as batch size, epochs, learning rate, and optimizer do not\nsignificantly impact the generalization capability of quantum machine learning.\nWe experimentally demonstrate the tightness of our generalization bound across\nclassification and regression tasks. Furthermore, we show that our tight\ngeneralization upper bound holds even when labels are completely randomized. We\nthus bring clarity to the fundamental question of generalization in quantum\nmachine learning.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u5e7f\u6cdb\u76d1\u7763\u4efb\u52a1\u3001\u6570\u636e\u548c\u6a21\u578b\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7d27\u81f4\u6cdb\u5316\u754c\uff0c\u8be5\u754c\u53ef\u9ad8\u6548\u8ba1\u7b97\u4e14\u4e0d\u542b\u5927O\u7b26\u53f7\u3002\u7814\u7a76\u8868\u660e\u6837\u672c\u91cf\u662f\u5f71\u54cd\u6cdb\u5316\u8bef\u5dee\u7684\u6700\u4e3b\u8981\u56e0\u7d20\uff0c\u800c\u91cf\u5b50\u95e8\u6570\u91cf\u3001\u91cf\u5b50\u6bd4\u7279\u6570\u7b49\u53c2\u6570\u5bf9\u6cdb\u5316\u80fd\u529b\u5f71\u54cd\u4e0d\u5927\u3002", "motivation": "\u5148\u524d\u57fa\u4e8e\u5927O\u7b26\u53f7\u7684\u6cdb\u5316\u754c\u53ef\u80fd\u5bf9\u6cdb\u5316\u8bef\u5dee\u63d0\u4f9b\u8bef\u5bfc\u6027\u5efa\u8bae\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u66f4\u51c6\u786e\u3001\u53ef\u8ba1\u7b97\u7684\u6cdb\u5316\u754c\u6765\u6f84\u6e05\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\u3002", "method": "\u63a8\u5bfc\u4e86\u4e00\u4e2a\u7d27\u81f4\u7684\u6cdb\u5316\u754c\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u89c4\u6a21\u548c\u6df1\u5ea6\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u7d27\u81f4\u6027\uff0c\u5305\u62ec\u5206\u7c7b\u3001\u56de\u5f52\u4efb\u52a1\u4ee5\u53ca\u6807\u7b7e\u968f\u673a\u5316\u7684\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6cdb\u5316\u754c\u5728\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4e2d\u90fd\u5177\u6709\u7d27\u81f4\u6027\uff0c\u5373\u4f7f\u5728\u6807\u7b7e\u5b8c\u5168\u968f\u673a\u5316\u7684\u60c5\u51b5\u4e0b\u4e5f\u6210\u7acb\u3002\u6837\u672c\u91cf\u662f\u4e3b\u5bfc\u6cdb\u5316\u8bef\u5dee\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8868\u660e\u6837\u672c\u91cf\u662f\u5f71\u54cd\u6cdb\u5316\u80fd\u529b\u7684\u6700\u91cd\u8981\u56e0\u7d20\uff0c\u800c\u6a21\u578b\u590d\u6742\u5ea6\u548c\u8d85\u53c2\u6570\u9009\u62e9\u7684\u5f71\u54cd\u76f8\u5bf9\u8f83\u5c0f\u3002"}}
{"id": "2510.23668", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23668", "abs": "https://arxiv.org/abs/2510.23668", "authors": ["Fujiang Yuan", "Yangrui Fan", "Xiaohuan Bing", "Zhen Tian", "Chunhong Yuan", "Yankang Li"], "title": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems", "comment": null, "summary": "Accurate traffic flow forecasting is essential for intelligent transportation\nsystems and urban traffic management. However, single model approaches often\nfail to capture the complex, nonlinear, and multi scale temporal patterns in\ntraffic flow data. This study proposes a decomposition driven hybrid framework\nthat integrates Seasonal Trend decomposition using Loess (STL) with three\ncomplementary predictive models. STL first decomposes the original time series\ninto trend, seasonal, and residual components. Then, a Long Short Term Memory\n(LSTM) network models long term trends, an Autoregressive Integrated Moving\nAverage (ARIMA) model captures seasonal periodicity, and an Extreme Gradient\nBoosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The\nfinal forecast is obtained through multiplicative integration of the sub model\npredictions. Using 998 traffic flow records from a New York City intersection\nbetween November and December 2015, results show that the LSTM ARIMA XGBoost\nhybrid model significantly outperforms standalone models including LSTM, ARIMA,\nand XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy\neffectively isolates temporal characteristics, allowing each model to\nspecialize, thereby improving prediction accuracy, interpretability, and\nrobustness.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSTL\u5206\u89e3\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408LSTM\u3001ARIMA\u548cXGBoost\u4e09\u79cd\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u89e3\u4ea4\u901a\u6d41\u65f6\u95f4\u5e8f\u5217\u5e76\u5206\u522b\u9884\u6d4b\u5404\u5206\u91cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u5355\u4e00\u6a21\u578b\u96be\u4ee5\u6355\u6349\u4ea4\u901a\u6d41\u6570\u636e\u4e2d\u590d\u6742\u7684\u975e\u7ebf\u6027\u3001\u591a\u5c3a\u5ea6\u65f6\u95f4\u6a21\u5f0f\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u6df7\u5408\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528STL\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u8d8b\u52bf\u3001\u5b63\u8282\u6027\u548c\u6b8b\u5dee\u5206\u91cf\uff0c\u5206\u522b\u7528LSTM\u5efa\u6a21\u957f\u671f\u8d8b\u52bf\u3001ARIMA\u6355\u6349\u5b63\u8282\u6027\u5468\u671f\u3001XGBoost\u9884\u6d4b\u975e\u7ebf\u6027\u6b8b\u5dee\u6ce2\u52a8\uff0c\u6700\u540e\u901a\u8fc7\u4e58\u6cd5\u96c6\u6210\u83b7\u5f97\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5728\u7ebd\u7ea6\u5e02\u4ea4\u53c9\u53e3\u7684998\u6761\u4ea4\u901a\u6d41\u8bb0\u5f55\u4e0a\u6d4b\u8bd5\uff0c\u8be5\u6df7\u5408\u6a21\u578b\u5728MAE\u3001RMSE\u548cR\u5e73\u65b9\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u72ec\u7684LSTM\u3001ARIMA\u548cXGBoost\u6a21\u578b\u3002", "conclusion": "\u5206\u89e3\u7b56\u7565\u6709\u6548\u5206\u79bb\u4e86\u65f6\u95f4\u7279\u5f81\uff0c\u4f7f\u5404\u6a21\u578b\u80fd\u591f\u4e13\u4e1a\u5316\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.24299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24299", "abs": "https://arxiv.org/abs/2510.24299", "authors": ["Jiayu Liu", "Wei Dai", "Zhenya Huang", "Ning Miao", "Enhong Chen"], "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank", "comment": null, "summary": "Despite the strong reasoning ability of large language models~(LLMs), they\nare prone to errors and hallucinations. As a result, how to check their outputs\neffectively and efficiently has become a critical problem in their\napplications. Existing checking methods heavily rely on external resources,\nsuch as trained verifiers (e.g., process/outcome reward models) or elaborate\nprompts, which lead to high computational overhead and are only applicable to\nspecific domains. In this paper, we investigate whether the internal behaviors\nof LLMs have already implied the credibility of their reasoning paths.\nSpecifically, we find that the rank of the correlation matrix between the input\nproblem and the output reasoning path is a robust indicator of reasoning\ncorrectness. Different from other correctness indicators for LLMs, the\ncalculation of the correlation matrix only relies on the LLM itself, which\navoids the hassle of training a separate model or designing complicated\nprompts. Based on it, we design a simple, plug-and-play Self-Indicator method\nto reweight candidate reasoning paths, which achieves significant performance\nimprovements than other voting and verification methods with very few\ncomputational overhead. Our experiments across multiple LLMs of varying scales\nand model families have further shown the effectiveness of Self-Indicator. It\nachieves over 75% accuracy in distinguishing correct reasoning paths from\nincorrect ones, and, in turn, improves the accuracies on three reasoning\nbenchmarks by more than 8%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-Indicator\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790LLM\u5185\u90e8\u884c\u4e3a\u7684\u76f8\u5173\u6027\u77e9\u9635\u6765\u8bc4\u4f30\u63a8\u7406\u8def\u5f84\u7684\u53ef\u4fe1\u5ea6\uff0c\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u5373\u53ef\u6709\u6548\u68c0\u6d4bLLM\u8f93\u51fa\u9519\u8bef\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u4f46\u5bb9\u6613\u4ea7\u751f\u9519\u8bef\u548c\u5e7b\u89c9\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\uff08\u5982\u8bad\u7ec3\u9a8c\u8bc1\u5668\u6216\u590d\u6742\u63d0\u793a\uff09\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u9886\u57df\u3002", "method": "\u7814\u7a76\u53d1\u73b0\u8f93\u5165\u95ee\u9898\u4e0e\u8f93\u51fa\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u77e9\u9635\u7684\u79e9\u662f\u63a8\u7406\u6b63\u786e\u6027\u7684\u53ef\u9760\u6307\u6807\uff0c\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u7b80\u5355\u5373\u63d2\u5373\u7528\u7684Self-Indicator\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u52a0\u6743\u5019\u9009\u63a8\u7406\u8def\u5f84\u6765\u8bc4\u4f30\u53ef\u4fe1\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u4e0d\u540c\u89c4\u6a21\u548c\u5bb6\u65cf\u7684LLM\u4e0a\u5b9e\u9a8c\u6709\u6548\uff0c\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u63a8\u7406\u8def\u5f84\u7684\u51c6\u786e\u7387\u8d85\u8fc775%\uff0c\u5e76\u5728\u4e09\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u4e868%\u4ee5\u4e0a\u3002", "conclusion": "Self-Indicator\u65b9\u6cd5\u4ec5\u4f9d\u8d56LLM\u81ea\u8eab\u5185\u90e8\u884c\u4e3a\uff0c\u65e0\u9700\u8bad\u7ec3\u5355\u72ec\u6a21\u578b\u6216\u8bbe\u8ba1\u590d\u6742\u63d0\u793a\uff0c\u8ba1\u7b97\u5f00\u9500\u5c0f\u4e14\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u4e3aLLM\u8f93\u51fa\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24439", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24439", "abs": "https://arxiv.org/abs/2510.24439", "authors": ["Tse-Yu Lin", "Wei-Kai Huang", "Pei-Yu Tu", "Yong-Fan Chen", "Ite A. Yu"], "title": "Fundamental limit on the heralded single photons' spectral brightness", "comment": "5 figures, 3 tables", "summary": "The heralded single photons' (HSPs) spectral brightness (SB) is defined as\nthe generation rate per linewidth. As the generation rate of HSPs gets larger\nor the photons' linewidth becomes narrower, both of which are desirable in\nquantum information processing using HSPs, does the SB have a limit? We\nsystematically studied the SB and the cross-correlation function, or\nequivalently, the signal-to-background ratio. The results in this study provide\nan answer applicable to all types of HSP sources. The answer relies on a newly\ndefined quantity, the quality factor, which reveals how a HSP source approaches\nthe ideal noise-free one. Furthermore, employing the HSP source based on hot\natomic vapor, we achieved an SB of (7.0$\\pm$0.3)$\\times10^5$ pairs/s/MHz and a\nquality factor of 0.68$\\pm$0.02 under the single-photon criterion. Both values\nare the highest records to date among all kinds of HSP sources.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u9884\u793a\u5355\u5149\u5b50(HSP)\u7684\u8c31\u4eae\u5ea6(SB)\u662f\u5426\u5b58\u5728\u6781\u9650\uff0c\u5e76\u5b9a\u4e49\u4e86\u8d28\u91cf\u56e0\u5b50\u6765\u8bc4\u4f30HSP\u6e90\u63a5\u8fd1\u7406\u60f3\u65e0\u566a\u58f0\u6e90\u7684\u7a0b\u5ea6\u3002\u4f7f\u7528\u70ed\u539f\u5b50\u84b8\u6c7dHSP\u6e90\uff0c\u5b9e\u73b0\u4e86\u8fc4\u4eca\u6700\u9ad8\u7684SB\u503c(7.0\u00b10.3)\u00d710^5\u5bf9/\u79d2/MHz\u548c\u8d28\u91cf\u56e0\u5b500.68\u00b10.02\u3002", "motivation": "\u7814\u7a76HSP\u7684\u8c31\u4eae\u5ea6\u662f\u5426\u5b58\u5728\u6781\u9650\uff0c\u56e0\u4e3a\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u65e2\u9700\u8981\u9ad8\u751f\u6210\u7387\u53c8\u9700\u8981\u7a84\u7ebf\u5bbd\uff0c\u800c\u8c31\u4eae\u5ea6\u5b9a\u4e49\u4e3a\u751f\u6210\u7387\u4e0e\u7ebf\u5bbd\u7684\u6bd4\u503c\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u8c31\u4eae\u5ea6\u548c\u4ea4\u53c9\u76f8\u5173\u51fd\u6570(\u4fe1\u566a\u6bd4)\uff0c\u5b9a\u4e49\u4e86\u8d28\u91cf\u56e0\u5b50\u6765\u8861\u91cfHSP\u6e90\u63a5\u8fd1\u7406\u60f3\u65e0\u566a\u58f0\u6e90\u7684\u7a0b\u5ea6\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u70ed\u539f\u5b50\u84b8\u6c7d\u7684HSP\u6e90\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u4f7f\u7528\u70ed\u539f\u5b50\u84b8\u6c7dHSP\u6e90\u5b9e\u73b0\u4e86(7.0\u00b10.3)\u00d710^5\u5bf9/\u79d2/MHz\u7684\u8c31\u4eae\u5ea6\u548c0.68\u00b10.02\u7684\u8d28\u91cf\u56e0\u5b50\uff0c\u8fd9\u662f\u8fc4\u4eca\u6240\u6709\u7c7b\u578bHSP\u6e90\u4e2d\u7684\u6700\u9ad8\u8bb0\u5f55\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u8c31\u4eae\u5ea6\u5b58\u5728\u6781\u9650\uff0c\u65b0\u5b9a\u4e49\u7684\u8d28\u91cf\u56e0\u5b50\u80fd\u591f\u6709\u6548\u8bc4\u4f30HSP\u6e90\u7684\u6027\u80fd\uff0c\u70ed\u539f\u5b50\u84b8\u6c7dHSP\u6e90\u5728\u5355\u5149\u5b50\u6807\u51c6\u4e0b\u8fbe\u5230\u4e86\u8fc4\u4eca\u6700\u4f73\u6027\u80fd\u3002"}}
{"id": "2510.24303", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24303", "abs": "https://arxiv.org/abs/2510.24303", "authors": ["Deniz Gorur", "Antoni Rago", "Francesca Toni"], "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting", "comment": null, "summary": "Judgmental forecasting is the task of making predictions about future events\nbased on human judgment. This task can be seen as a form of claim verification,\nwhere the claim corresponds to a future event and the task is to assess the\nplausibility of that event. In this paper, we propose a novel multi-agent\nframework for claim verification, whereby different agents may disagree on\nclaim veracity and bring specific evidence for and against the claims,\nrepresented as quantitative bipolar argumentation frameworks (QBAFs). We then\ninstantiate the framework for supporting claim verification, with a variety of\nagents realised with Large Language Models (LLMs): (1) ArgLLM agents, an\nexisting approach for claim verification that generates and evaluates QBAFs;\n(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)\nfrom external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,\nextending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of\narguments from external sources. Finally, we conduct experiments with two\nstandard judgmental forecasting datasets, with instances of our framework with\ntwo or three agents, empowered by six different base LLMs. We observe that\ncombining evidence from agents can improve forecasting accuracy, especially in\nthe case of three agents, while providing an explainable combination of\nevidence for claim verification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7528\u4e8e\u58f0\u660e\u9a8c\u8bc1\uff0c\u901a\u8fc7\u4e0d\u540c\u667a\u80fd\u4f53\u5bf9\u58f0\u660e\u771f\u5b9e\u6027\u4ea7\u751f\u5206\u6b67\u5e76\u5206\u522b\u63d0\u4f9b\u652f\u6301/\u53cd\u5bf9\u8bc1\u636e\uff0c\u6784\u5efa\u5b9a\u91cf\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(QBAFs)\uff0c\u5b9e\u9a8c\u8868\u660e\u591a\u667a\u80fd\u4f53\u7ec4\u5408\u8bc1\u636e\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5c06\u5224\u65ad\u6027\u9884\u6d4b\u89c6\u4e3a\u58f0\u660e\u9a8c\u8bc1\u4efb\u52a1\uff0c\u9700\u8981\u8bc4\u4f30\u672a\u6765\u4e8b\u4ef6\u7684\u53ef\u80fd\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u8bc1\u636e\u6536\u96c6\u548c\u9a8c\u8bc1\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5168\u9762\u548c\u53ef\u89e3\u91ca\u7684\u9a8c\u8bc1\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u58f0\u660e\u9a8c\u8bc1\u6846\u67b6\uff0c\u4f7f\u7528\u4e09\u79cdLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\uff1aArgLLM\u667a\u80fd\u4f53\uff08\u73b0\u6709\u65b9\u6cd5\uff09\u3001RbAM\u667a\u80fd\u4f53\uff08\u57fa\u4e8e\u5173\u7cfb\u8bba\u8bc1\u6316\u6398\uff09\u3001RAG-ArgLLM\u667a\u80fd\u4f53\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\uff0c\u6784\u5efaQBAFs\u8fdb\u884c\u8bc1\u636e\u7ec4\u5408\u3002", "result": "\u5728\u4e24\u4e2a\u6807\u51c6\u5224\u65ad\u6027\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u591a\u667a\u80fd\u4f53\uff08\u7279\u522b\u662f\u4e09\u4e2a\u667a\u80fd\u4f53\uff09\u7ec4\u5408\u8bc1\u636e\u80fd\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u7ec4\u5408\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u6846\u67b6\u901a\u8fc7\u6574\u5408\u4e0d\u540c\u8bc1\u636e\u6765\u6e90\u548c\u89c2\u70b9\uff0c\u5728\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u58f0\u660e\u9a8c\u8bc1\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24484", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24484", "abs": "https://arxiv.org/abs/2510.24484", "authors": ["Anindita Sarkar", "Paranjoy Chaki", "Priya Ghosh", "Ujjwal Sen"], "title": "Comparing physical quantities with finite-precision: beyond standard metrology and an illustration for cooling in quantum processes", "comment": "10 pages, 2 figures", "summary": "We propose a general framework to compare the values of a physical quantity\npertaining to two - or more - physical setups, in the finite-precision\nscenario. Such a situation requires us to compare between two \"patches\" on the\nreal line instead of two numbers. Identification of extent of the patches is\ntypically done via standard deviation, as obtained within usual quantum\nmetrological considerations, but can not be always applied, especially for\nasymmetric error distributions. The extent can however be universally\ndetermined by utilizing the concept of percentiles of the probability\ndistribution of the corresponding estimator. As an application, we introduce\nthe concept of finite-precision cooling in a generic quantum system. We use\nthis approach in the working of a three-qubit quantum refrigerator governed by\nMarkovian dynamics, and demonstrate the occurrence of cooling within finite\nprecision for both transient and steady-state regimes, across strong- and\nweak-coupling limits of the inter-qubit interaction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u6709\u9650\u7cbe\u5ea6\u573a\u666f\u4e0b\u6bd4\u8f83\u7269\u7406\u91cf\u503c\u7684\u901a\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u767e\u5206\u4f4d\u6570\u786e\u5b9a\u6982\u7387\u5206\u5e03\u7684\u533a\u95f4\u8303\u56f4\uff0c\u5e76\u5e94\u7528\u4e8e\u4e09\u91cf\u5b50\u6bd4\u7279\u91cf\u5b50\u5236\u51b7\u673a\u7684\u6709\u9650\u7cbe\u5ea6\u51b7\u5374\u5206\u6790\u3002", "motivation": "\u5728\u6709\u9650\u7cbe\u5ea6\u6d4b\u91cf\u4e2d\uff0c\u9700\u8981\u6bd4\u8f83\u5b9e\u6570\u8f74\u4e0a\u7684\u4e24\u4e2a\u533a\u95f4\u800c\u975e\u5355\u4e2a\u6570\u503c\uff0c\u4f20\u7edf\u57fa\u4e8e\u6807\u51c6\u5dee\u7684\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u975e\u5bf9\u79f0\u8bef\u5dee\u5206\u5e03\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u901a\u7528\u7684\u6bd4\u8f83\u6846\u67b6\u3002", "method": "\u5229\u7528\u4f30\u8ba1\u91cf\u6982\u7387\u5206\u5e03\u7684\u767e\u5206\u4f4d\u6570\u6982\u5ff5\u6765\u786e\u5b9a\u533a\u95f4\u8303\u56f4\uff0c\u5e94\u7528\u4e8e\u4e09\u91cf\u5b50\u6bd4\u7279\u91cf\u5b50\u5236\u51b7\u673a\u7684\u9a6c\u5c14\u53ef\u592b\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5206\u6790\u77ac\u6001\u548c\u7a33\u6001\u4e0b\u7684\u51b7\u5374\u6548\u679c\u3002", "result": "\u5728\u5f3a\u8026\u5408\u548c\u5f31\u8026\u5408\u6781\u9650\u4e0b\uff0c\u5747\u8bc1\u660e\u4e86\u6709\u9650\u7cbe\u5ea6\u51b7\u5374\u5728\u77ac\u6001\u548c\u7a33\u6001\u533a\u57df\u7684\u53d1\u751f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u767e\u5206\u4f4d\u6570\u7684\u6846\u67b6\u4e3a\u6709\u9650\u7cbe\u5ea6\u573a\u666f\u4e0b\u7684\u7269\u7406\u91cf\u6bd4\u8f83\u63d0\u4f9b\u4e86\u901a\u7528\u65b9\u6cd5\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u91cf\u5b50\u5236\u51b7\u7cfb\u7edf\u7684\u51b7\u5374\u5206\u6790\u3002"}}
{"id": "2510.23672", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23672", "abs": "https://arxiv.org/abs/2510.23672", "authors": ["Xiangfei Qiu", "Xingjian Wu", "Hanyin Cheng", "Xvyuan Liu", "Chenjuan Guo", "Jilin Hu", "Bin Yang"], "title": "DBLoss: Decomposition-based Loss Function for Time Series Forecasting", "comment": "Accepted by NeurIPS 2025", "summary": "Time series forecasting holds significant value in various domains such as\neconomics, traffic, energy, and AIOps, as accurate predictions facilitate\ninformed decision-making. However, the existing Mean Squared Error (MSE) loss\nfunction sometimes fails to accurately capture the seasonality or trend within\nthe forecasting horizon, even when decomposition modules are used in the\nforward propagation to model the trend and seasonality separately. To address\nthese challenges, we propose a simple yet effective Decomposition-Based Loss\nfunction called DBLoss. This method uses exponential moving averages to\ndecompose the time series into seasonal and trend components within the\nforecasting horizon, and then calculates the loss for each of these components\nseparately, followed by weighting them. As a general loss function, DBLoss can\nbe combined with any deep learning forecasting model. Extensive experiments\ndemonstrate that DBLoss significantly improves the performance of\nstate-of-the-art models across diverse real-world datasets and provides a new\nperspective on the design of time series loss functions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u89e3\u7684\u635f\u5931\u51fd\u6570DBLoss\uff0c\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u5206\u91cf\uff0c\u5206\u522b\u8ba1\u7b97\u635f\u5931\u5e76\u52a0\u6743\uff0c\u53ef\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684MSE\u635f\u5931\u51fd\u6570\u6709\u65f6\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u9884\u6d4b\u8303\u56f4\u5185\u7684\u5b63\u8282\u6027\u6a21\u5f0f\u6216\u8d8b\u52bf\uff0c\u5373\u4f7f\u5728\u524d\u5411\u4f20\u64ad\u4e2d\u4f7f\u7528\u5206\u89e3\u6a21\u5757\u5206\u522b\u5efa\u6a21\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u3002", "method": "\u4f7f\u7528\u6307\u6570\u79fb\u52a8\u5e73\u5747\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u5206\u91cf\uff0c\u7136\u540e\u5206\u522b\u8ba1\u7b97\u8fd9\u4e9b\u5206\u91cf\u7684\u635f\u5931\u5e76\u8fdb\u884c\u52a0\u6743\u3002DBLoss\u53ef\u4f5c\u4e3a\u901a\u7528\u635f\u5931\u51fd\u6570\u4e0e\u4efb\u4f55\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u7ed3\u5408\u4f7f\u7528\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDBLoss\u663e\u8457\u63d0\u5347\u4e86\u6700\u5148\u8fdb\u6a21\u578b\u5728\u591a\u6837\u5316\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "DBLoss\u4e3a\u65f6\u95f4\u5e8f\u5217\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u57fa\u4e8e\u5206\u89e3\u7684\u635f\u5931\u51fd\u6570\u3002"}}
{"id": "2510.24337", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.24337", "abs": "https://arxiv.org/abs/2510.24337", "authors": ["Daria Kravets-Meinke", "Hannah Schmid-Petri", "Sonja Niemann", "Ute Schmid"], "title": "Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research", "comment": null, "summary": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly\nbeing used in communication research for content analysis. Studies show that\ngLLMs can outperform both crowd workers and trained coders, such as research\nassistants, on various coding tasks relevant to communication science, often at\na fraction of the time and cost. Additionally, gLLMs can decode implicit\nmeanings and contextual information, be instructed using natural language,\ndeployed with only basic programming skills, and require little to no annotated\ndata beyond a validation dataset - constituting a paradigm shift in automated\ncontent analysis. Despite their potential, the integration of gLLMs into the\nmethodological toolkit of communication research remains underdeveloped. In\ngLLM-assisted quantitative content analysis, researchers must address at least\nseven critical challenges that impact result quality: (1) codebook development,\n(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)\niterative refinement, (6) validation of the model's reliability, and\noptionally, (7) performance enhancement. This paper synthesizes emerging\nresearch on gLLM-assisted quantitative content analysis and proposes a\ncomprehensive best-practice guide to navigate these challenges. Our goal is to\nmake gLLM-based content analysis more accessible to a broader range of\ncommunication researchers and ensure adherence to established disciplinary\nquality standards of validity, reliability, reproducibility, and research\nethics.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f20\u64ad\u7814\u7a76\u5185\u5bb9\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u5176\u4f18\u52bf\uff08\u4f18\u4e8e\u4eba\u5de5\u7f16\u7801\u3001\u6210\u672c\u4f4e\u3001\u80fd\u89e3\u7801\u9690\u542b\u542b\u4e49\uff09\u548c\u4e03\u5927\u6311\u6218\uff08\u4ee3\u7801\u672c\u5f00\u53d1\u3001\u63d0\u793a\u5de5\u7a0b\u7b49\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u6700\u4f73\u5b9e\u8df5\u6307\u5357\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f20\u64ad\u7814\u7a76\u5185\u5bb9\u5206\u6790\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u65b9\u6cd5\u8bba\u5de5\u5177\u5305\u4e2d\u7684\u6574\u5408\u4ecd\u4e0d\u5145\u5206\uff0c\u9700\u8981\u89e3\u51b3\u5f71\u54cd\u7ed3\u679c\u8d28\u91cf\u7684\u4e03\u5927\u5173\u952e\u6311\u6218\u3002", "method": "\u7efc\u5408\u65b0\u5174\u7814\u7a76\uff0c\u63d0\u51fa\u5168\u9762\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5357\uff0c\u5305\u62ec\u4ee3\u7801\u672c\u5f00\u53d1\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u9009\u62e9\u3001\u53c2\u6570\u8c03\u4f18\u3001\u8fed\u4ee3\u4f18\u5316\u3001\u53ef\u9760\u6027\u9a8c\u8bc1\u548c\u6027\u80fd\u589e\u5f3a\u7b49\u4e03\u4e2a\u65b9\u9762\u3002", "result": "\u7814\u7a76\u8868\u660egLLMs\u5728\u4f20\u64ad\u79d1\u5b66\u76f8\u5173\u7f16\u7801\u4efb\u52a1\u4e2d\u80fd\u8d85\u8d8a\u4f17\u5305\u5de5\u4f5c\u8005\u548c\u8bad\u7ec3\u6709\u7d20\u7684\u7f16\u7801\u5458\uff0c\u4e14\u6210\u672c\u548c\u65f6\u95f4\u5927\u5e45\u964d\u4f4e\uff0c\u80fd\u89e3\u7801\u9690\u542b\u542b\u4e49\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u4f7f\u57fa\u4e8egLLM\u7684\u5185\u5bb9\u5206\u6790\u5bf9\u66f4\u5e7f\u6cdb\u7684\u4f20\u64ad\u7814\u7a76\u8005\u66f4\u52a0\u53ef\u53ca\uff0c\u5e76\u786e\u4fdd\u7b26\u5408\u6709\u6548\u6027\u3001\u53ef\u9760\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u7814\u7a76\u4f26\u7406\u7b49\u5b66\u79d1\u8d28\u91cf\u6807\u51c6\u3002"}}
{"id": "2510.24509", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24509", "abs": "https://arxiv.org/abs/2510.24509", "authors": ["Carlos Flores-Garrigos", "Gaurav Dev", "Michael Falkenthal", "Alejandro Gomez Cadavid", "Anton Simen", "Shubham Kumar", "Enrique Solano", "Narendra N. Hegade"], "title": "Quantum Combinatorial Reasoning for Large Language Models", "comment": null, "summary": "We design and implement a quantum combinatorial reasoning framework for large\nlanguage models (QCR-LLM), integrating a real quantum computer in the hybrid\nworkflow. QCR-LLM reformulates reasoning aggregation as a higher-order\nunconstrained binary optimization (HUBO) problem. In this sense, reasoning\nfragments are represented as binary variables and their interactions encode\nstatistical relevance, logical coherence, and semantic redundancy. We tackle\nthe resulting high-order optimization problem both classically, via simulated\nannealing, and quantumly through the bias-field digitized counterdiabatic\nquantum optimizer (BF-DCQO) executed on IBM's superconducting digital quantum\nprocessors. Experiments on BIG-Bench Extra Hard (BBEH) benchmarks demonstrate\nthat our QCR-LLM consistently improves reasoning accuracy across multiple LLM\nbackbones, surpassing reasoning-native systems such as o3-high and DeepSeek R1\nby up to $+9\\,$pp. Despite requiring multiple reasoning samples per query, our\nQCR-LLM remains approximately five times more energy-efficient than o3-high,\nowing to the low per-token energy footprint of its GPT-4o backbone. These\nresults constitute the first experimental evidence of quantum-assisted\nreasoning, showing that hybrid quantum-classical optimization can efficiently\nenhance reasoning coherence, interpretability, and sustainability in\nlarge-scale language models. We have opened the doors to the emergence of\nquantum intelligence, where harder prompts require quantum optimizers at\nquantum-advantage level.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u91cf\u5b50\u7ec4\u5408\u63a8\u7406\u6846\u67b6QCR-LLM\uff0c\u5c06\u63a8\u7406\u805a\u5408\u91cd\u65b0\u8868\u8ff0\u4e3a\u9ad8\u9636\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u7ecf\u5178\u6a21\u62df\u9000\u706b\u548c\u91cf\u5b50BF-DCQO\u4f18\u5316\u5668\u5728IBM\u91cf\u5b50\u5904\u7406\u5668\u4e0a\u6267\u884c\uff0c\u5728BBEH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u63a8\u7406\u51c6\u786e\u7387\u5e76\u63d0\u9ad8\u80fd\u6548\u3002", "motivation": "\u5f00\u53d1\u91cf\u5b50\u8f85\u52a9\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u4f18\u5316\u589e\u5f3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6301\u7eed\u6027\uff0c\u63a2\u7d22\u91cf\u5b50\u667a\u80fd\u7684\u6f5c\u529b\u3002", "method": "\u5c06\u63a8\u7406\u805a\u5408\u91cd\u65b0\u8868\u8ff0\u4e3a\u9ad8\u9636\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u63a8\u7406\u7247\u6bb5\u8868\u793a\u4e3a\u4e8c\u8fdb\u5236\u53d8\u91cf\uff0c\u901a\u8fc7\u6a21\u62df\u9000\u706b\u548c\u91cf\u5b50BF-DCQO\u4f18\u5316\u5668\u5728IBM\u91cf\u5b50\u5904\u7406\u5668\u4e0a\u6c42\u89e3\u3002", "result": "\u5728BBEH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQCR-LLM\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e2aLLM\u9aa8\u5e72\u7684\u63a8\u7406\u51c6\u786e\u7387\uff0c\u6bd4\u63a8\u7406\u539f\u751f\u7cfb\u7edf\u5982o3-high\u548cDeepSeek R1\u9ad8\u51fa\u6700\u591a9\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u80fd\u6548\u6bd4o3-high\u9ad8\u7ea65\u500d\u3002", "conclusion": "\u8fd9\u662f\u91cf\u5b50\u8f85\u52a9\u63a8\u7406\u7684\u9996\u4e2a\u5b9e\u9a8c\u8bc1\u636e\uff0c\u8868\u660e\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u4f18\u5316\u80fd\u6709\u6548\u589e\u5f3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u91cf\u5b50\u667a\u80fd\u7684\u51fa\u73b0\u6253\u5f00\u4e86\u5927\u95e8\u3002"}}
{"id": "2510.23681", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23681", "abs": "https://arxiv.org/abs/2510.23681", "authors": ["Carl Hvarfner", "David Eriksson", "Eytan Bakshy", "Max Balandat"], "title": "Informed Initialization for Bayesian Optimization and Active Learning", "comment": "28 pages", "summary": "Bayesian Optimization is a widely used method for optimizing expensive\nblack-box functions, relying on probabilistic surrogate models such as Gaussian\nProcesses. The quality of the surrogate model is crucial for good optimization\nperformance, especially in the few-shot setting where only a small number of\nbatches of points can be evaluated. In this setting, the initialization plays a\ncritical role in shaping the surrogate's predictive quality and guiding\nsubsequent optimization. Despite this, practitioners typically rely on\n(quasi-)random designs to cover the input space. However, such approaches\nneglect two key factors: (a) space-filling designs may not be desirable to\nreduce predictive uncertainty, and (b) efficient hyperparameter learning during\ninitialization is essential for high-quality prediction, which may conflict\nwith space-filling designs. To address these limitations, we propose\nHyperparameter-Informed Predictive Exploration (HIPE), a novel acquisition\nstrategy that balances predictive uncertainty reduction with hyperparameter\nlearning using information-theoretic principles. We derive a closed-form\nexpression for HIPE in the Gaussian Process setting and demonstrate its\neffectiveness through extensive experiments in active learning and few-shot BO.\nOur results show that HIPE outperforms standard initialization strategies in\nterms of predictive accuracy, hyperparameter identification, and subsequent\noptimization performance, particularly in large-batch, few-shot settings\nrelevant to many real-world Bayesian Optimization applications.", "AI": {"tldr": "\u63d0\u51faHIPE\u65b9\u6cd5\uff0c\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u83b7\u53d6\u7b56\u7565\uff0c\u7528\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u521d\u59cb\u5316\u9636\u6bb5\uff0c\u5e73\u8861\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u548c\u8d85\u53c2\u6570\u5b66\u4e60\uff0c\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7a7a\u95f4\u586b\u5145\u8bbe\u8ba1\u3002", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u4f18\u5316\u521d\u59cb\u5316\u4f9d\u8d56\uff08\u51c6\uff09\u968f\u673a\u8bbe\u8ba1\u6765\u8986\u76d6\u8f93\u5165\u7a7a\u95f4\uff0c\u4f46\u5ffd\u89c6\u4e86\u4e24\u4e2a\u5173\u952e\u56e0\u7d20\uff1a(a) \u7a7a\u95f4\u586b\u5145\u8bbe\u8ba1\u53ef\u80fd\u4e0d\u5229\u4e8e\u51cf\u5c11\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff1b(b) \u521d\u59cb\u5316\u671f\u95f4\u9ad8\u6548\u8d85\u53c2\u6570\u5b66\u4e60\u5bf9\u9ad8\u8d28\u91cf\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u80fd\u4e0e\u7a7a\u95f4\u586b\u5145\u8bbe\u8ba1\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u8d85\u53c2\u6570\u77e5\u60c5\u9884\u6d4b\u63a2\u7d22\uff08HIPE\uff09\uff0c\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u83b7\u53d6\u7b56\u7565\uff0c\u5728\u9ad8\u65af\u8fc7\u7a0b\u8bbe\u7f6e\u4e2d\u63a8\u5bfc\u51fa\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e73\u8861\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u4e0e\u8d85\u53c2\u6570\u5b66\u4e60\u3002", "result": "\u5728\u4e3b\u52a8\u5b66\u4e60\u548c\u5c11\u6837\u672c\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cHIPE\u5728\u9884\u6d4b\u51c6\u786e\u6027\u3001\u8d85\u53c2\u6570\u8bc6\u522b\u548c\u540e\u7eed\u4f18\u5316\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u6807\u51c6\u521d\u59cb\u5316\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6279\u6b21\u3001\u5c11\u6837\u672c\u8bbe\u7f6e\u4e2d\u3002", "conclusion": "HIPE\u65b9\u6cd5\u5728\u8d1d\u53f6\u65af\u4f18\u5316\u521d\u59cb\u5316\u9636\u6bb5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u7a7a\u95f4\u586b\u5145\u8bbe\u8ba1\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5c11\u6837\u672c\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24339", "abs": "https://arxiv.org/abs/2510.24339", "authors": ["Yunxuan Jiang", "Silan Hu", "Xiaoning Wang", "Yuanyuan Zhang", "Xiangyu Chang"], "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation", "comment": "29 pages, 6 figures. Yunxuan Jiang and Silan Hu contributed equally.\n  Code available at https://github.com/fengzer/VDSAgents", "summary": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.", "AI": {"tldr": "VDSAgents\u662f\u4e00\u4e2a\u57fa\u4e8e\u53ef\u9884\u6d4b\u6027-\u53ef\u8ba1\u7b97\u6027-\u7a33\u5b9a\u6027(PCS)\u539f\u5219\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u63d0\u5347LLM\u9a71\u52a8\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u7aef\u5230\u7aef\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524dLLM\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u4ec5\u4f9d\u8d56LLM\u5185\u90e8\u63a8\u7406\uff0c\u7f3a\u4e4f\u79d1\u5b66\u548c\u7406\u8bba\u539f\u5219\u6307\u5bfc\uff0c\u5728\u5904\u7406\u566a\u58f0\u548c\u590d\u6742\u771f\u5b9e\u6570\u636e\u96c6\u65f6\u53ef\u4fe1\u5ea6\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8ePCS\u539f\u5219\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u91c7\u7528\u6a21\u5757\u5316\u5de5\u4f5c\u6d41\u7a0b\u5904\u7406\u6570\u636e\u6e05\u6d17\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u5efa\u6a21\u548c\u8bc4\u4f30\uff0c\u6bcf\u4e2a\u9636\u6bb5\u7531\u4e13\u95e8\u667a\u80fd\u4f53\u8d1f\u8d23\uff0c\u7ed3\u5408\u6270\u52a8\u5206\u6790\u3001\u5355\u5143\u6d4b\u8bd5\u548c\u6a21\u578b\u9a8c\u8bc1\u3002", "result": "\u57289\u4e2a\u4e0d\u540c\u7279\u5f81\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528DeepSeek-V3\u548cGPT-4o\u4f5c\u4e3a\u540e\u7aef\uff0cVDSAgents\u6301\u7eed\u4f18\u4e8eAutoKaggle\u548cDataInterpreter\u7b49\u6700\u5148\u8fdb\u7684\u7aef\u5230\u7aef\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u3002", "conclusion": "\u5c06PCS\u539f\u5219\u5d4c\u5165LLM\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u81ea\u52a8\u5316\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.24572", "categories": ["quant-ph", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.24572", "abs": "https://arxiv.org/abs/2510.24572", "authors": ["Samuel Alperin"], "title": "A No-Go Theorem for Shaping Quantum Resources", "comment": "5 pages", "summary": "The ability to independently control higher-order statistical moments of\ncontinuous-variable quantum states would allow the direct ``shaping'' of\nnon-Gaussian resources, with wide implications for quantum communication,\ncomputation, and metrology. Here we prove that such control is fundamentally\nimpossible under any smooth Hamiltonian dynamics. Within the full\ninfinite-dimensional algebra of Hamiltonian vector fields on phase space, the\nquadratic (symplectic) subalgebra $\\mathfrak{sp}(2N,\\mathbb R)$ -- and, in the\nsingle-mode case, its $\\mathrm{SU}(1,1)$ representation -- is the unique\nhierarchy-preserving structure: only quadratic generators produce differential\noperators that terminate at second order and thereby decouple first and second\nmoments from higher cumulants. Any smooth non-quadratic Hamiltonian introduces\nthird- and higher-order derivatives in the phase-space generator, enforcing a\nuniversal coupling between the Gaussian and non-Gaussian sectors. This\n\\emph{rigidity of the moment hierarchy} generalizes the Gaussian no-go theorems\nand identifies the analytic boundary between symplectic (Clifford) dynamics and\nthe non-simulable regime beyond the Gottesman--Knill limit.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5728\u5e73\u6ed1\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u4e0b\uff0c\u65e0\u6cd5\u72ec\u7acb\u63a7\u5236\u8fde\u7eed\u53d8\u91cf\u91cf\u5b50\u6001\u7684\u9ad8\u9636\u7edf\u8ba1\u77e9\uff0c\u53ea\u6709\u4e8c\u6b21\u54c8\u5bc6\u987f\u91cf\u624d\u80fd\u4fdd\u6301\u77e9\u5c42\u6b21\u7ed3\u6784\u7684\u89e3\u8026\u3002", "motivation": "\u7814\u7a76\u80fd\u5426\u72ec\u7acb\u63a7\u5236\u8fde\u7eed\u53d8\u91cf\u91cf\u5b50\u6001\u7684\u9ad8\u9636\u7edf\u8ba1\u77e9\uff0c\u8fd9\u5bf9\u4e8e\u91cf\u5b50\u901a\u4fe1\u3001\u8ba1\u7b97\u548c\u8ba1\u91cf\u5b66\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u5206\u6790\u65e0\u9650\u7ef4\u54c8\u5bc6\u987f\u5411\u91cf\u573a\u4ee3\u6570\uff0c\u8bc1\u660e\u5728\u5e73\u6ed1\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u4e0b\uff0c\u53ea\u6709\u4e8c\u6b21\u751f\u6210\u5143\uff08\u8f9b\u4ee3\u6570\uff09\u80fd\u4fdd\u6301\u77e9\u5c42\u6b21\u7ed3\u6784\u7684\u89e3\u8026\u3002", "result": "\u53d1\u73b0\u4efb\u4f55\u5e73\u6ed1\u7684\u975e\u4e8c\u6b21\u54c8\u5bc6\u987f\u91cf\u90fd\u4f1a\u5f15\u5165\u4e09\u9636\u53ca\u4ee5\u4e0a\u5bfc\u6570\uff0c\u5f3a\u5236\u8026\u5408\u9ad8\u65af\u548c\u975e\u9ad8\u65af\u90e8\u5206\uff0c\u8bc1\u660e\u4e86\u77e9\u5c42\u6b21\u7ed3\u6784\u7684\u521a\u6027\u3002", "conclusion": "\u8be5\u7ed3\u679c\u63a8\u5e7f\u4e86\u9ad8\u65af\u4e0d\u53ef\u884c\u5b9a\u7406\uff0c\u5e76\u786e\u5b9a\u4e86\u8f9b\uff08\u514b\u5229\u798f\u5fb7\uff09\u52a8\u529b\u5b66\u4e0e\u8d85\u8d8aGottesman-Knill\u6781\u9650\u7684\u975e\u53ef\u6a21\u62df\u533a\u57df\u4e4b\u95f4\u7684\u89e3\u6790\u8fb9\u754c\u3002"}}
{"id": "2510.24359", "categories": ["cs.AI", "cs.SY", "eess.SY", "q-bio.QM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.24359", "abs": "https://arxiv.org/abs/2510.24359", "authors": ["Pedram Fard", "Alaleh Azhir", "Neguine Rezaii", "Jiazi Tian", "Hossein Estiri"], "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine", "comment": "This study has been supported by grants from the National Institutes\n  of Health: The National Institute on Aging R01AG074372 and The National\n  Institute of Allergy and Infectious Diseases R01AI165535", "summary": "Artificial intelligence in medicine is built to serve the average patient. By\nminimizing error across large datasets, most systems deliver strong aggregate\naccuracy yet falter at the margins: patients with rare variants,\nmultimorbidity, or underrepresented demographics. This average patient fallacy\nerodes both equity and trust. We propose a different design: a multi-agent\necosystem for N-of-1 decision support. In this environment, agents clustered by\norgan systems, patient populations, and analytic modalities draw on a shared\nlibrary of models and evidence synthesis tools. Their results converge in a\ncoordination layer that weighs reliability, uncertainty, and data density\nbefore presenting the clinician with a decision-support packet: risk estimates\nbounded by confidence ranges, outlier flags, and linked evidence. Validation\nshifts from population averages to individual reliability, measured by error in\nlow-density regions, calibration in the small, and risk--coverage trade-offs.\nAnticipated challenges include computational demands, automation bias, and\nregulatory fit, addressed through caching strategies, consensus checks, and\nadaptive trial frameworks. By moving from monolithic models to orchestrated\nintelligence, this approach seeks to align medical AI with the first principle\nof medicine: care that is transparent, equitable, and centered on the\nindividual.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\uff0c\u7528\u4e8eN-of-1\u51b3\u7b56\u652f\u6301\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u533b\u7597AI\u53ea\u670d\u52a1\u4e8e\u5e73\u5747\u60a3\u8005\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u534f\u8c03\u4e0d\u540c\u5668\u5b98\u7cfb\u7edf\u3001\u60a3\u8005\u7fa4\u4f53\u548c\u5206\u6790\u6a21\u5f0f\u7684\u667a\u80fd\u4f53\u6765\u63d0\u4f9b\u4e2a\u6027\u5316\u533b\u7597\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u4f20\u7edf\u533b\u7597AI\u7cfb\u7edf\u901a\u8fc7\u6700\u5c0f\u5316\u5927\u578b\u6570\u636e\u96c6\u4e0a\u7684\u9519\u8bef\u6765\u5b9e\u73b0\u9ad8\u805a\u5408\u51c6\u786e\u6027\uff0c\u4f46\u5728\u8fb9\u7f18\u75c5\u4f8b\uff08\u7f55\u89c1\u53d8\u5f02\u3001\u591a\u75c5\u5171\u5b58\u3001\u4ee3\u8868\u6027\u4e0d\u8db3\u4eba\u7fa4\uff09\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u79cd\u5e73\u5747\u60a3\u8005\u8c2c\u8bef\u635f\u5bb3\u4e86\u516c\u5e73\u6027\u548c\u4fe1\u4efb\u5ea6\u3002", "method": "\u6784\u5efa\u591a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\uff0c\u667a\u80fd\u4f53\u6309\u5668\u5b98\u7cfb\u7edf\u3001\u60a3\u8005\u7fa4\u4f53\u548c\u5206\u6790\u6a21\u5f0f\u805a\u7c7b\uff0c\u5171\u4eab\u6a21\u578b\u5e93\u548c\u8bc1\u636e\u5408\u6210\u5de5\u5177\u3002\u901a\u8fc7\u534f\u8c03\u5c42\u6743\u8861\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u6570\u636e\u5bc6\u5ea6\uff0c\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u5305\u3002", "result": "\u9a8c\u8bc1\u91cd\u70b9\u4ece\u7fa4\u4f53\u5e73\u5747\u503c\u8f6c\u5411\u4e2a\u4f53\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u4f4e\u5bc6\u5ea6\u533a\u57df\u8bef\u5dee\u3001\u5c0f\u6837\u672c\u6821\u51c6\u548c\u98ce\u9669-\u8986\u76d6\u6743\u8861\u6765\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u4ece\u5355\u4e00\u6a21\u578b\u8f6c\u5411\u534f\u8c03\u667a\u80fd\uff0c\u8be5\u65b9\u6cd5\u65e8\u5728\u4f7f\u533b\u7597AI\u4e0e\u533b\u5b66\u7684\u9996\u8981\u539f\u5219\u4fdd\u6301\u4e00\u81f4\uff1a\u63d0\u4f9b\u900f\u660e\u3001\u516c\u5e73\u4e14\u4ee5\u4e2a\u4f53\u4e3a\u4e2d\u5fc3\u7684\u533b\u7597\u670d\u52a1\u3002"}}
{"id": "2510.24615", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24615", "abs": "https://arxiv.org/abs/2510.24615", "authors": ["Yutaka Hirano", "Riki Toshio", "Tomohiro Itogawa", "Keisuke Fujii"], "title": "Efficient magic state cultivation with lattice surgery", "comment": "12 pages, 14 figures", "summary": "Magic state distillation plays a crucial role in fault-tolerant quantum\ncomputation and represents a major bottleneck. In contrast to traditional\nlogical-level distillation, physical-level distillation offers significant\noverhead reduction by enabling direct implementation with physical gates. Magic\nstate cultivation is a state-of-the-art physical-level distillation protocol\nthat is compatible with the square-grid connectivity and yields high-fidelity\nmagic states. However, it relies on the complex grafted code, which incurs\nsubstantial spacetime overhead and complicates practical implementation. In\nthis work, we propose an efficient cultivation-based protocol compatible with\nthe square-grid connectivity. We reduce the spatial overhead by avoiding the\ngrafted code and further reduce the average spacetime overhead by utilizing\ncode expansion and enabling early rejection. Numerical simulations show that,\nwith a color code distance of 3 and a physical error probability of $10^{-3}$,\nour protocol achieves a logical error probability for the resulting magic state\ncomparable to that of magic state cultivation ($\\approx 3 \\times 10^{-6}$),\nwhile requiring about half the spacetime overhead. Our work provides an\nefficient and simple distillation protocol suitable for megaquop use cases and\nearly fault-tolerant devices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57f9\u517b\u7684\u9ad8\u6548\u9b54\u672f\u6001\u84b8\u998f\u534f\u8bae\uff0c\u517c\u5bb9\u65b9\u5f62\u7f51\u683c\u8fde\u63a5\uff0c\u901a\u8fc7\u907f\u514d\u5ac1\u63a5\u7801\u964d\u4f4e\u7a7a\u95f4\u5f00\u9500\uff0c\u5229\u7528\u7801\u6269\u5c55\u548c\u65e9\u671f\u62d2\u7edd\u8fdb\u4e00\u6b65\u964d\u4f4e\u5e73\u5747\u65f6\u7a7a\u5f00\u9500\u3002", "motivation": "\u9b54\u672f\u6001\u84b8\u998f\u662f\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u7684\u5173\u952e\u74f6\u9888\u3002\u7269\u7406\u7ea7\u84b8\u998f\u76f8\u6bd4\u903b\u8f91\u7ea7\u84b8\u998f\u80fd\u663e\u8457\u964d\u4f4e\u5f00\u9500\uff0c\u4f46\u73b0\u6709\u9b54\u672f\u6001\u57f9\u517b\u534f\u8bae\u4f9d\u8d56\u590d\u6742\u7684\u5ac1\u63a5\u7801\uff0c\u5bfc\u81f4\u9ad8\u65f6\u7a7a\u5f00\u9500\u548c\u5b9e\u73b0\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u517c\u5bb9\u65b9\u5f62\u7f51\u683c\u8fde\u63a5\u7684\u57f9\u517b\u534f\u8bae\uff0c\u907f\u514d\u4f7f\u7528\u5ac1\u63a5\u7801\u4ee5\u51cf\u5c11\u7a7a\u95f4\u5f00\u9500\uff0c\u91c7\u7528\u7801\u6269\u5c55\u548c\u65e9\u671f\u62d2\u7edd\u673a\u5236\u964d\u4f4e\u5e73\u5747\u65f6\u7a7a\u5f00\u9500\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u5728\u989c\u8272\u7801\u8ddd\u79bb\u4e3a3\u3001\u7269\u7406\u9519\u8bef\u6982\u7387\u4e3a10^-3\u65f6\uff0c\u8be5\u534f\u8bae\u83b7\u5f97\u7684\u9b54\u672f\u6001\u903b\u8f91\u9519\u8bef\u6982\u7387\u4e0e\u9b54\u672f\u6001\u57f9\u517b\u76f8\u5f53\uff08\u7ea63\u00d710^-6\uff09\uff0c\u4f46\u65f6\u7a7a\u5f00\u9500\u51cf\u5c11\u7ea6\u4e00\u534a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7b80\u5355\u7684\u84b8\u998f\u534f\u8bae\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u91cf\u5b50\u8ba1\u7b97\u7528\u4f8b\u548c\u65e9\u671f\u5bb9\u9519\u8bbe\u5907\u3002"}}
{"id": "2510.23693", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.23693", "abs": "https://arxiv.org/abs/2510.23693", "authors": ["Joachim Baumann"], "title": "On the Societal Impact of Machine Learning", "comment": "PhD thesis", "summary": "This PhD thesis investigates the societal impact of machine learning (ML). ML\nincreasingly informs consequential decisions and recommendations, significantly\naffecting many aspects of our lives. As these data-driven systems are often\ndeveloped without explicit fairness considerations, they carry the risk of\ndiscriminatory effects. The contributions in this thesis enable more\nappropriate measurement of fairness in ML systems, systematic decomposition of\nML systems to anticipate bias dynamics, and effective interventions that reduce\nalgorithmic discrimination while maintaining system utility. I conclude by\ndiscussing ongoing challenges and future research directions as ML systems,\nincluding generative artificial intelligence, become increasingly integrated\ninto society. This work offers a foundation for ensuring that ML's societal\nimpact aligns with broader social values.", "AI": {"tldr": "\u8be5\u535a\u58eb\u8bba\u6587\u7814\u7a76\u673a\u5668\u5b66\u4e60\u7684\u793e\u4f1a\u5f71\u54cd\uff0c\u91cd\u70b9\u5173\u6ce8\u516c\u5e73\u6027\u6d4b\u91cf\u3001\u504f\u5dee\u52a8\u6001\u5206\u6790\u548c\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e0e\u793e\u4f1a\u4ef7\u503c\u89c2\u5bf9\u9f50\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u5f71\u54cd\u91cd\u8981\u51b3\u7b56\uff0c\u4f46\u7531\u4e8e\u5f00\u53d1\u65f6\u7f3a\u4e4f\u660e\u786e\u7684\u516c\u5e73\u6027\u8003\u8651\uff0c\u5b58\u5728\u6b67\u89c6\u6027\u5f71\u54cd\u7684\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u66f4\u5408\u9002\u7684\u516c\u5e73\u6027\u6d4b\u91cf\u65b9\u6cd5\u3001\u7cfb\u7edf\u6027\u5730\u5206\u89e3\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4ee5\u9884\u6d4b\u504f\u5dee\u52a8\u6001\uff0c\u4ee5\u53ca\u5f00\u53d1\u6709\u6548\u7684\u5e72\u9884\u63aa\u65bd\u6765\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u3002", "result": "\u5efa\u7acb\u4e86\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u516c\u5e73\u6027\u7684\u57fa\u7840\u6846\u67b6\uff0c\u80fd\u591f\u5728\u7ef4\u6301\u7cfb\u7edf\u6548\u7528\u7684\u540c\u65f6\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u3002", "conclusion": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\uff08\u5305\u62ec\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff09\u65e5\u76ca\u878d\u5165\u793e\u4f1a\uff0c\u9700\u8981\u7ee7\u7eed\u5e94\u5bf9\u6311\u6218\u5e76\u63a2\u7d22\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u7684\u793e\u4f1a\u5f71\u54cd\u4e0e\u66f4\u5e7f\u6cdb\u7684\u793e\u4f1a\u4ef7\u503c\u89c2\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2510.24681", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24681", "abs": "https://arxiv.org/abs/2510.24681", "authors": ["Moritz Scheer", "Alberto Baiardi", "Elisa B\u00e4umer Marty", "Zhi-Yuan Wei", "Daniel Malz"], "title": "Renormalization-group-based preparation of matrix product states on up to 80 qubits", "comment": "8 pages, 6 figures", "summary": "A key challenge for quantum computers is the efficient preparation of\nmany-body entangled states across many qubits. In this work, we demonstrate the\npreparation of matrix product states (MPS) using a\nrenormalization-group(RG)-based quantum algorithm on superconducting quantum\nhardware. Compared to sequential generation, it has been shown that the\nRG-based protocol asymptotically prepares short-range correlated MPS with an\nexponentially shallower circuit depth (when scaling system size), but it is not\nyet clear for which system sizes it starts to convey an advantage. We thus\napply this algorithm to prepare a class of MPS exhibiting a phase transition\nbetween a symmetry-protected topological (SPT) and a trivial phase for systems\nof up to 80 qubits. We find that the reduced depth of the RG-based circuits\nmakes them more resilient to noise, and that they generally outperform the\nsequential circuits for large systems, as we showcase by measuring\nstring-order-like local expectation values and energy densities. We thus\ndemonstrate that the RG-based protocol enables large-scale preparation of MPS\nand, in particular, SPT-ordered states beyond the fixed point.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u5728\u8d85\u5bfc\u91cf\u5b50\u786c\u4ef6\u4e0a\u4f7f\u7528\u57fa\u4e8e\u91cd\u6574\u5316\u7fa4(RG)\u7684\u91cf\u5b50\u7b97\u6cd5\u5236\u5907\u77e9\u9635\u4e58\u79ef\u6001(MPS)\uff0c\u76f8\u6bd4\u987a\u5e8f\u751f\u6210\u65b9\u6cd5\uff0cRG\u534f\u8bae\u5728\u7cfb\u7edf\u89c4\u6a21\u6269\u5927\u65f6\u7535\u8def\u6df1\u5ea6\u6307\u6570\u7ea7\u66f4\u6d45\uff0c\u5bf9\u566a\u58f0\u66f4\u5177\u9c81\u68d2\u6027\uff0c\u5728\u5927\u7cfb\u7edf\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u673a\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u662f\u5982\u4f55\u9ad8\u6548\u5236\u5907\u591a\u4f53\u7ea0\u7f20\u6001\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u57fa\u4e8eRG\u7684\u91cf\u5b50\u7b97\u6cd5\u5728\u5236\u5907MPS\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5927\u89c4\u6a21\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u91cd\u6574\u5316\u7fa4\u7684\u91cf\u5b50\u7b97\u6cd5\u5728\u8d85\u5bfc\u91cf\u5b50\u786c\u4ef6\u4e0a\u5236\u5907\u77e9\u9635\u4e58\u79ef\u6001\uff0c\u5e76\u5c06\u5176\u4e0e\u987a\u5e8f\u751f\u6210\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002\u5b9e\u9a8c\u9488\u5bf9\u6700\u591a80\u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u7cfb\u7edf\uff0c\u5236\u5907\u4e86\u5728\u5bf9\u79f0\u4fdd\u62a4\u62d3\u6251\u76f8\u548c\u666e\u901a\u76f8\u4e4b\u95f4\u53d1\u751f\u76f8\u53d8\u7684MPS\u3002", "result": "RG\u57fa\u7535\u8def\u7531\u4e8e\u6df1\u5ea6\u8f83\u6d45\u5bf9\u566a\u58f0\u66f4\u5177\u9c81\u68d2\u6027\uff0c\u5728\u5927\u7cfb\u7edf\u4e2d\u666e\u904d\u4f18\u4e8e\u987a\u5e8f\u7535\u8def\u3002\u901a\u8fc7\u6d4b\u91cf\u7c7b\u5f26\u5e8f\u5c40\u90e8\u671f\u671b\u503c\u548c\u80fd\u91cf\u5bc6\u5ea6\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u70b9\u3002", "conclusion": "RG\u57fa\u534f\u8bae\u80fd\u591f\u5b9e\u73b0\u5927\u89c4\u6a21MPS\u7684\u5236\u5907\uff0c\u7279\u522b\u662f\u8d85\u8d8a\u56fa\u5b9a\u70b9\u7684\u5bf9\u79f0\u4fdd\u62a4\u62d3\u6251\u6709\u5e8f\u6001\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u6001\u5236\u5907\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.23727", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23727", "abs": "https://arxiv.org/abs/2510.23727", "authors": ["Anisha Saha", "Varsha Suresh", "Timothy Hospedales", "Vera Demberg"], "title": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection", "comment": null, "summary": "Sarcasm is a specific type of irony which involves discerning what is said\nfrom what is meant. Detecting sarcasm depends not only on the literal content\nof an utterance but also on non-verbal cues such as speaker's tonality, facial\nexpressions and conversational context. However, current multimodal models\nstruggle with complex tasks like sarcasm detection, which require identifying\nrelevant cues across modalities and pragmatically reasoning over them to infer\nthe speaker's intention. To explore these limitations in VideoLMs, we introduce\nMUStReason, a diagnostic benchmark enriched with annotations of\nmodality-specific relevant cues and underlying reasoning steps to identify\nsarcastic intent. In addition to benchmarking sarcasm classification\nperformance in VideoLMs, using MUStReason we quantitatively and qualitatively\nevaluate the generated reasoning by disentangling the problem into perception\nand reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on\nimplied intentions over literal meaning, a property core to detecting sarcasm.", "AI": {"tldr": "MUStReason\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u5728\u8bbd\u523a\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b\u6a21\u6001\u7279\u5b9a\u76f8\u5173\u7ebf\u7d22\u548c\u63a8\u7406\u6b65\u9aa4\u7684\u6807\u6ce8\u3002\u7814\u7a76\u63d0\u51faPragCoT\u6846\u67b6\u6765\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u9690\u542b\u610f\u56fe\u800c\u975e\u5b57\u9762\u610f\u4e49\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u5982\u8bbd\u523a\u68c0\u6d4b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u8de8\u6a21\u6001\u8bc6\u522b\u76f8\u5173\u7ebf\u7d22\u5e76\u8fdb\u884c\u8bed\u7528\u63a8\u7406\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165MUStReason\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b\u4e30\u5bcc\u7684\u6a21\u6001\u7279\u5b9a\u7ebf\u7d22\u548c\u63a8\u7406\u6b65\u9aa4\u6807\u6ce8\uff1b\u63d0\u51faPragCoT\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u611f\u77e5\u548c\u63a8\u7406\uff0c\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u9690\u542b\u610f\u56fe\u3002", "result": "\u901a\u8fc7MUStReason\u5bf9\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u7684\u8bbd\u523a\u5206\u7c7b\u6027\u80fd\u548c\u751f\u6210\u63a8\u7406\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u3002", "conclusion": "PragCoT\u6846\u67b6\u80fd\u591f\u6709\u6548\u5f15\u5bfc\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u5173\u6ce8\u8bbd\u523a\u68c0\u6d4b\u7684\u6838\u5fc3\u5c5e\u6027\u2014\u2014\u9690\u542b\u610f\u56fe\uff0c\u63d0\u5347\u6a21\u578b\u5728\u590d\u6742\u8bed\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2510.24390", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24390", "abs": "https://arxiv.org/abs/2510.24390", "authors": ["Xianjun Gao", "Jianchun Liu", "Hongli Xu", "Liusheng Huang"], "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion", "comment": null, "summary": "The integration of Large Language Models (LLMs) into real-time Web\napplications, such as AI-powered search and conversational agents, presents a\nfundamental Web infrastructure challenge: reconciling the demand for\nhigh-quality, complex reasoning with the stringent low-latency and\nhigh-throughput requirements of interactive services. Current LLM reasoning,\nhindered by computationally inefficient sequential generation and rigid\nreasoning strategies, creates a critical bottleneck for the Web services.\nExisting approaches typically optimize the LLM reasoning for either efficiency\nor quality but struggle to achieve both, and thus fail to meet the dual\nrequirements of modern Web platforms. To overcome these limitations, we propose\nOrion, a novel and efficient reasoning framework that enables dependency-aware\nquery decomposition and logic-parallel content expansion. Concretely, Orion\ndecomposes a single query reasoning process into two synergistic phases: (1)\n\\textit{key point generation}, which distills logically structured key points\nthrough retrieval-augmented few-shot prompting, and (2) \\textit{content\nparallel expansion}, which concurrently elaborates on these points based on a\ndependency graph to ensure logical consistency. Furthermore, Orion introduces a\npipeline scheduling mechanism that exploits the complementary computational\ncharacteristics of the two phases (generation imposes pressure on GPU computing\nand expansion stresses on GPU memory) across multiple queries, enabling\ncross-query parallelism and dramatically improving reasoning performance (\\ie,\nefficiency and quality). Experiments on diverse benchmarks show that Orion not\nonly delivers up to 4.33x higher token generation speed and 3.42x lower answer\nlatency over the baselines but also improves reasoning quality by up to 18.75%\nthrough explicitly modeling inter-point dependencies.", "AI": {"tldr": "Orion\u662f\u4e00\u4e2a\u65b0\u9896\u7684LLM\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4f9d\u8d56\u611f\u77e5\u7684\u67e5\u8be2\u5206\u89e3\u548c\u903b\u8f91\u5e76\u884c\u5185\u5bb9\u6269\u5c55\uff0c\u89e3\u51b3\u4e86Web\u5e94\u7528\u4e2d\u9ad8\u8d28\u91cf\u63a8\u7406\u4e0e\u4f4e\u5ef6\u8fdf\u9ad8\u541e\u5410\u9700\u6c42\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u987a\u5e8f\u751f\u6210\u548c\u50f5\u5316\u63a8\u7406\u7b56\u7565\u95ee\u9898\uff0c\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u73b0\u4ee3Web\u5e73\u53f0\u5bf9\u6548\u7387\u548c\u8d28\u91cf\u7684\u4e8c\u5143\u8981\u6c42\u3002", "method": "\u5c06\u67e5\u8be2\u63a8\u7406\u5206\u89e3\u4e3a\u4e24\u4e2a\u534f\u540c\u9636\u6bb5\uff1a\u68c0\u7d22\u589e\u5f3a\u7684\u5173\u952e\u70b9\u751f\u6210\u548c\u57fa\u4e8e\u4f9d\u8d56\u56fe\u7684\u5e76\u884c\u5185\u5bb9\u6269\u5c55\uff0c\u5e76\u5f15\u5165\u6d41\u6c34\u7ebf\u8c03\u5ea6\u673a\u5236\u5b9e\u73b0\u8de8\u67e5\u8be2\u5e76\u884c\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOrion\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7ebf\u9ad8\u8fbe4.33\u500d\u7684token\u751f\u6210\u901f\u5ea6\u548c3.42\u500d\u7684\u4f4e\u5ef6\u8fdf\uff0c\u540c\u65f6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u70b9\u95f4\u4f9d\u8d56\u5173\u7cfb\u5c06\u63a8\u7406\u8d28\u91cf\u63d0\u5347\u9ad8\u8fbe18.75%\u3002", "conclusion": "Orion\u6846\u67b6\u6210\u529f\u5e73\u8861\u4e86LLM\u63a8\u7406\u7684\u6548\u7387\u548c\u8d28\u91cf\u9700\u6c42\uff0c\u4e3a\u5b9e\u65f6Web\u5e94\u7528\u4e2d\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23751", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23751", "abs": "https://arxiv.org/abs/2510.23751", "authors": ["Ignavier Ng", "Patrick Bl\u00f6baum", "Siddharth Bhandari", "Kun Zhang", "Shiva Kasiviswanathan"], "title": "Debiasing Reward Models by Representation Learning with Guarantees", "comment": null, "summary": "Recent alignment techniques, such as reinforcement learning from human\nfeedback, have been widely adopted to align large language models with human\npreferences by learning and leveraging reward models. In practice, these models\noften exploit spurious correlations, involving, e.g., response length,\ndiscrimination, sycophancy, and conceptual bias, which is a problem that has\nreceived increasing attention. In this work, we propose a principled framework\nthat mitigates these biases in reward models while preserving the underlying\nfactors that reflect intended preferences. We first provide a formulation of\nthe data-generating process, assuming that the observed data (e.g., text) is\ngenerated from both spurious and non-spurious latent variables. We show that,\ninterestingly, these non-spurious latent variables can be theoretically\nidentified from data, regardless of whether a surrogate for the spurious latent\nvariables is available. This further inspires a practical method that uses\nvariational inference to recover these variables and leverages them to train\nreward models. Experiments on synthetic and real-world datasets demonstrate\nthat our method effectively mitigates spurious correlation issues and yields\nmore robust reward models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7f13\u89e3\u5956\u52b1\u6a21\u578b\u4e2d\u865a\u5047\u76f8\u5173\u6027\u7684\u539f\u5219\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u5206\u79bb\u865a\u5047\u4e0e\u975e\u865a\u5047\u6f5c\u5728\u53d8\u91cf\u6765\u8bad\u7ec3\u66f4\u7a33\u5065\u7684\u5956\u52b1\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u9f50\u6280\u672f\uff08\u5982\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u5728\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u65f6\u7ecf\u5e38\u5229\u7528\u865a\u5047\u76f8\u5173\u6027\uff08\u5982\u54cd\u5e94\u957f\u5ea6\u3001\u6b67\u89c6\u3001\u8c04\u5a9a\u548c\u6982\u5ff5\u504f\u89c1\uff09\uff0c\u8fd9\u5df2\u6210\u4e3a\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\u7684\u95ee\u9898\u3002", "method": "\u9996\u5148\u6784\u5efa\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u7684\u516c\u5f0f\u5316\u63cf\u8ff0\uff0c\u5047\u8bbe\u89c2\u6d4b\u6570\u636e\u6765\u81ea\u865a\u5047\u548c\u975e\u865a\u5047\u6f5c\u5728\u53d8\u91cf\uff1b\u7136\u540e\u63d0\u51fa\u4f7f\u7528\u53d8\u5206\u63a8\u65ad\u6765\u6062\u590d\u8fd9\u4e9b\u53d8\u91cf\uff0c\u5e76\u5229\u7528\u5b83\u4eec\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u7684\u5b9e\u7528\u65b9\u6cd5\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u865a\u5047\u76f8\u5173\u6027\u95ee\u9898\uff0c\u4ea7\u751f\u66f4\u7a33\u5065\u7684\u5956\u52b1\u6a21\u578b\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5728\u4fdd\u7559\u53cd\u6620\u9884\u671f\u504f\u597d\u7684\u57fa\u7840\u56e0\u7d20\u7684\u540c\u65f6\uff0c\u6709\u6548\u51cf\u8f7b\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2510.24397", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24397", "abs": "https://arxiv.org/abs/2510.24397", "authors": ["Jiarui Qin", "Yunjia Xi", "Junjie Huang", "Renting Rui", "Di Yin", "Weiwen Liu", "Yong Yu", "Weinan Zhang", "Xing Sun"], "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training", "comment": "46 pages", "summary": "With the rapid development of LLM-based agents, there is a growing trend to\nincorporate agent-specific data into the pre-training stage of LLMs, aiming to\nbetter align LLMs with real-world autonomous task execution. However, current\npre-training benchmarks primarily focus on isolated and static skills, e.g.,\ncommon knowledge or mathematical/code reasoning, and fail to reflect model's\nagentic capabilities. On the other hand, agent benchmarks are typically\ndesigned for post-trained models, requiring multi-turn task execution abilities\nthat base models struggle to support. Thus, there is a compelling need for a\nbenchmark that can evaluate agentic potentials during pre-training and guide\nthe model training more effectively. To address this gap, we propose APTBench,\na framework that converts real-world agent tasks and successful trajectories\ninto multiple-choice or text completion questions tailored for base models. It\nfocuses on core agentic abilities, e.g., planning and action, and covers key\nagent scenarios, software engineering and deep research. Compared to existing\ngeneral-purpose benchmarks, APTBench offers a more predictive signal of a\nmodel's downstream performance as an agent, while remaining significantly more\nlightweight and cost-effective than full-scale, end-to-end agent evaluations\nafter post-training.", "AI": {"tldr": "APTBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u9884\u8bad\u7ec3\u9636\u6bb5\u667a\u80fd\u4f53\u6f5c\u529b\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u771f\u5b9e\u4e16\u754c\u667a\u80fd\u4f53\u4efb\u52a1\u8f6c\u6362\u4e3a\u9002\u5408\u57fa\u7840\u6a21\u578b\u7684\u591a\u9009\u9898\u6216\u6587\u672c\u8865\u5168\u95ee\u9898\uff0c\u6bd4\u73b0\u6709\u57fa\u51c6\u66f4\u80fd\u9884\u6d4b\u4e0b\u6e38\u667a\u80fd\u4f53\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u9884\u8bad\u7ec3\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u9759\u6001\u6280\u80fd\uff0c\u65e0\u6cd5\u53cd\u6620\u6a21\u578b\u7684\u667a\u80fd\u4f53\u80fd\u529b\uff1b\u800c\u667a\u80fd\u4f53\u57fa\u51c6\u901a\u5e38\u9488\u5bf9\u540e\u8bad\u7ec3\u6a21\u578b\uff0c\u57fa\u7840\u6a21\u578b\u96be\u4ee5\u652f\u6301\u591a\u8f6e\u4efb\u52a1\u6267\u884c\uff0c\u56e0\u6b64\u9700\u8981\u80fd\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u8bc4\u4f30\u667a\u80fd\u4f53\u6f5c\u529b\u7684\u57fa\u51c6\u3002", "method": "\u5c06\u771f\u5b9e\u4e16\u754c\u667a\u80fd\u4f53\u4efb\u52a1\u548c\u6210\u529f\u8f68\u8ff9\u8f6c\u6362\u4e3a\u9002\u5408\u57fa\u7840\u6a21\u578b\u7684\u591a\u9009\u9898\u6216\u6587\u672c\u8865\u5168\u95ee\u9898\uff0c\u91cd\u70b9\u5173\u6ce8\u89c4\u5212\u548c\u884c\u52a8\u7b49\u6838\u5fc3\u667a\u80fd\u4f53\u80fd\u529b\uff0c\u8986\u76d6\u8f6f\u4ef6\u5de5\u7a0b\u548c\u6df1\u5ea6\u7814\u7a76\u7b49\u5173\u952e\u573a\u666f\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u901a\u7528\u57fa\u51c6\uff0cAPTBench\u80fd\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4f53\u7684\u4e0b\u6e38\u6027\u80fd\uff0c\u540c\u65f6\u6bd4\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u7aef\u5230\u7aef\u667a\u80fd\u4f53\u8bc4\u4f30\u66f4\u8f7b\u91cf\u4e14\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u3002", "conclusion": "APTBench\u586b\u8865\u4e86\u9884\u8bad\u7ec3\u9636\u6bb5\u667a\u80fd\u4f53\u80fd\u529b\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u66f4\u6709\u6548\u5730\u6307\u5bfc\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.24435", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24435", "abs": "https://arxiv.org/abs/2510.24435", "authors": ["Benjamin Grando Moreira"], "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning", "comment": "12 pages", "summary": "Evaluating reasoning ability in Large Language Models (LLMs) is important for\nadvancing artificial intelligence, as it transcends mere linguistic task\nperformance. It involves understanding whether these models truly understand\ninformation, perform inferences, and are able to draw conclusions in a logical\nand valid way. This study compare logical and abstract reasoning skills of\nseveral LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,\nPerplexity, and Sabi\\'a - using a set of eight custom-designed reasoning\nquestions. The LLM results are benchmarked against human performance on the\nsame tasks, revealing significant differences and indicating areas where LLMs\nstruggle with deduction.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT\u3001Claude\u3001DeepSeek\u7b49\uff09\u5728\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4f7f\u75288\u4e2a\u5b9a\u5236\u63a8\u7406\u95ee\u9898\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86LLMs\u5728\u6f14\u7ece\u63a8\u7406\u65b9\u9762\u7684\u56f0\u96be\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5bf9\u4e8e\u63a8\u8fdb\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u8fd9\u8d85\u8d8a\u4e86\u5355\u7eaf\u7684\u8bed\u8a00\u4efb\u52a1\u8868\u73b0\uff0c\u6d89\u53ca\u7406\u89e3\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u4fe1\u606f\u3001\u8fdb\u884c\u63a8\u7406\u4ee5\u53ca\u4ee5\u903b\u8f91\u6709\u6548\u7684\u65b9\u5f0f\u5f97\u51fa\u7ed3\u8bba\u3002", "method": "\u4f7f\u75288\u4e2a\u5b9a\u5236\u8bbe\u8ba1\u7684\u63a8\u7406\u95ee\u9898\uff0c\u6bd4\u8f83\u4e86GPT\u3001Claude\u3001DeepSeek\u3001Gemini\u3001Grok\u3001Llama\u3001Mistral\u3001Perplexity\u548cSabi'a\u7b49\u591a\u4e2aLLMs\u7684\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u6280\u80fd\uff0c\u5e76\u5c06\u7ed3\u679c\u4e0e\u4eba\u7c7b\u5728\u76f8\u540c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLMs\u4e0e\u4eba\u7c7b\u8868\u73b0\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8868\u660eLLMs\u5728\u6f14\u7ece\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u63d0\u5347\u5176\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.23794", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23794", "abs": "https://arxiv.org/abs/2510.23794", "authors": ["Jun Liu", "Tao Zhou", "Jiarui Li", "Xiaohui Zhong", "Peng Zhang", "Jie Feng", "Lei Chen", "Hao Li"], "title": "Revealing the Potential of Learnable Perturbation Ensemble Forecast Model for Tropical Cyclone Prediction", "comment": "30 pages, 21 figures, 1 table", "summary": "Tropical cyclones (TCs) are highly destructive and inherently uncertain\nweather systems. Ensemble forecasting helps quantify these uncertainties, yet\ntraditional systems are constrained by high computational costs and limited\ncapability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a\nlearnable perturbation scheme for ensemble generation, representing a novel\nAI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with\nECMWF-ENS using all 90 global TCs in 2018, examining their performance in\nTC-related physical variables, track and intensity forecasts, and the\nassociated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear\nadvantages in predicting TC-related physical variables, and achieves more\naccurate track forecasts with reduced ensemble spread, though it still\nunderestimates intensity relative to observations. Further dynamical and\nthermodynamical analyses reveal that FuXi-ENS better captures large-scale\ncirculation, with moisture turbulent energy more tightly concentrated around\nthe TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.\nThese findings highlight the potential of learnable perturbations to improve TC\nforecasting skill and provide valuable insights for advancing AI-based ensemble\nprediction of extreme weather events that have significant societal impacts.", "AI": {"tldr": "FuXi-ENS\u662f\u4e00\u79cd\u57fa\u4e8eAI\u7684\u96c6\u5408\u9884\u62a5\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u6270\u52a8\u65b9\u6848\u751f\u6210\u96c6\u5408\u9884\u62a5\uff0c\u5728\u70ed\u5e26\u6c14\u65cb\u9884\u62a5\u4e2d\u76f8\u6bd4\u4f20\u7edfECMWF-ENS\u7cfb\u7edf\u5c55\u73b0\u51fa\u660e\u663e\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u96c6\u5408\u9884\u62a5\u7cfb\u7edf\u53d7\u9650\u4e8e\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u65e0\u6cd5\u5145\u5206\u8868\u793a\u5927\u6c14\u975e\u7ebf\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u96c6\u5408\u9884\u62a5\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u6270\u52a8\u65b9\u6848\u8fdb\u884c\u96c6\u5408\u751f\u6210\uff0c\u5e76\u4e0eECMWF-ENS\u7cfb\u7edf\u8fdb\u884c\u7cfb\u7edf\u6027\u6bd4\u8f83\uff0c\u5206\u6790\u70ed\u5e26\u6c14\u65cb\u76f8\u5173\u7269\u7406\u53d8\u91cf\u3001\u8def\u5f84\u548c\u5f3a\u5ea6\u9884\u62a5\u6027\u80fd\u3002", "result": "FuXi-ENS\u5728\u9884\u6d4b\u70ed\u5e26\u6c14\u65cb\u76f8\u5173\u7269\u7406\u53d8\u91cf\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u8def\u5f84\u9884\u62a5\u66f4\u51c6\u786e\u4e14\u96c6\u5408\u79bb\u6563\u5ea6\u66f4\u5c0f\uff0c\u4f46\u5728\u5f3a\u5ea6\u9884\u62a5\u65b9\u9762\u4ecd\u4f4e\u4f30\u89c2\u6d4b\u503c\u3002\u52a8\u529b\u5b66\u548c\u70ed\u529b\u5b66\u5206\u6790\u663e\u793aFuXi-ENS\u80fd\u66f4\u597d\u5730\u6355\u6349\u5927\u5c3a\u5ea6\u73af\u6d41\u3002", "conclusion": "\u53ef\u5b66\u4e60\u7684\u6270\u52a8\u65b9\u6848\u6709\u6f5c\u529b\u63d0\u9ad8\u70ed\u5e26\u6c14\u65cb\u9884\u62a5\u6280\u80fd\uff0c\u4e3a\u63a8\u8fdb\u5177\u6709\u91cd\u5927\u793e\u4f1a\u5f71\u54cd\u7684\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u7684AI\u96c6\u5408\u9884\u62a5\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2510.24442", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24442", "abs": "https://arxiv.org/abs/2510.24442", "authors": ["Yiding Wang", "Yuxuan Chen", "Fanxu Meng", "Xifan Chen", "Xiaolei Yang", "Muhan Zhang"], "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents", "comment": null, "summary": "Since real-world legal experiments are often costly or infeasible, simulating\nlegal societies with Artificial Intelligence (AI) systems provides an effective\nalternative for verifying and developing legal theory, as well as supporting\nlegal administration. Large Language Models (LLMs), with their world knowledge\nand role-playing capabilities, are strong candidates to serve as the foundation\nfor legal society simulation. However, the application of LLMs to simulate\nlegal systems remains underexplored. In this work, we introduce Law in Silico,\nan LLM-based agent framework for simulating legal scenarios with individual\ndecision-making and institutional mechanisms of legislation, adjudication, and\nenforcement. Our experiments, which compare simulated crime rates with\nreal-world data, demonstrate that LLM-based agents can largely reproduce\nmacro-level crime trends and provide insights that align with real-world\nobservations. At the same time, micro-level simulations reveal that a\nwell-functioning, transparent, and adaptive legal system offers better\nprotection of the rights of vulnerable individuals.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cd5\u5f8b\u793e\u4f1a\u6a21\u62df\u6846\u67b6Law in Silico\uff0c\u80fd\u591f\u6a21\u62df\u4e2a\u4f53\u51b3\u7b56\u548c\u7acb\u6cd5\u3001\u88c1\u51b3\u3001\u6267\u6cd5\u7b49\u5236\u5ea6\u673a\u5236\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u591f\u590d\u73b0\u5b8f\u89c2\u72af\u7f6a\u8d8b\u52bf\u5e76\u4e3a\u5f31\u52bf\u7fa4\u4f53\u6743\u5229\u4fdd\u62a4\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u7531\u4e8e\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6cd5\u5f8b\u5b9e\u9a8c\u901a\u5e38\u6210\u672c\u9ad8\u6602\u6216\u4e0d\u53ef\u884c\uff0c\u5229\u7528\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u6a21\u62df\u6cd5\u5f8b\u793e\u4f1a\u6210\u4e3a\u9a8c\u8bc1\u548c\u53d1\u5c55\u6cd5\u5f8b\u7406\u8bba\u3001\u652f\u6301\u6cd5\u5f8b\u7ba1\u7406\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002\u5927\u8bed\u8a00\u6a21\u578b\u51ed\u501f\u5176\u4e16\u754c\u77e5\u8bc6\u548c\u89d2\u8272\u626e\u6f14\u80fd\u529b\uff0c\u662f\u6784\u5efa\u6cd5\u5f8b\u793e\u4f1a\u6a21\u62df\u7684\u7406\u60f3\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u4e86Law in Silico\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u80fd\u591f\u6a21\u62df\u5305\u542b\u4e2a\u4f53\u51b3\u7b56\u4ee5\u53ca\u7acb\u6cd5\u3001\u88c1\u51b3\u3001\u6267\u6cd5\u7b49\u5236\u5ea6\u673a\u5236\u7684\u6cd5\u5f8b\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u6bd4\u8f83\u6a21\u62df\u72af\u7f6a\u7387\u4e0e\u73b0\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u8868\u660e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u80fd\u591f\u5f88\u5927\u7a0b\u5ea6\u4e0a\u590d\u73b0\u5b8f\u89c2\u5c42\u9762\u7684\u72af\u7f6a\u8d8b\u52bf\uff0c\u5e76\u63d0\u4f9b\u4e0e\u73b0\u5b9e\u4e16\u754c\u89c2\u5bdf\u4e00\u81f4\u7684\u89c1\u89e3\u3002\u5fae\u89c2\u5c42\u9762\u6a21\u62df\u663e\u793a\uff0c\u529f\u80fd\u826f\u597d\u3001\u900f\u660e\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u6cd5\u5f8b\u7cfb\u7edf\u80fd\u66f4\u597d\u5730\u4fdd\u62a4\u5f31\u52bf\u4e2a\u4f53\u7684\u6743\u5229\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u62df\u6846\u67b6\u80fd\u591f\u6709\u6548\u6a21\u62df\u6cd5\u5f8b\u7cfb\u7edf\uff0c\u4e0d\u4ec5\u80fd\u591f\u590d\u73b0\u5b9e\u4e16\u754c\u72af\u7f6a\u8d8b\u52bf\uff0c\u8fd8\u80fd\u4e3a\u6cd5\u5f8b\u7cfb\u7edf\u7684\u6539\u8fdb\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u4fdd\u62a4\u5f31\u52bf\u7fa4\u4f53\u6743\u5229\u65b9\u9762\u3002"}}
{"id": "2510.23802", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23802", "abs": "https://arxiv.org/abs/2510.23802", "authors": ["Nathan Paek", "Yongyi Zang", "Qihui Yang", "Randal Leistikow"], "title": "Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders", "comment": "Accepted to NeurIPS 2025 Mechanistic Interpretability Workshop", "summary": "While sparse autoencoders (SAEs) successfully extract interpretable features\nfrom language models, applying them to audio generation faces unique\nchallenges: audio's dense nature requires compression that obscures semantic\nmeaning, and automatic feature characterization remains limited. We propose a\nframework for interpreting audio generative models by mapping their latent\nrepresentations to human-interpretable acoustic concepts. We train SAEs on\naudio autoencoder latents, then learn linear mappings from SAE features to\ndiscretized acoustic properties (pitch, amplitude, and timbre). This enables\nboth controllable manipulation and analysis of the AI music generation process,\nrevealing how acoustic properties emerge during synthesis. We validate our\napproach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)\naudio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music\nmodel, to demonstrate how pitch, timbre, and loudness evolve throughout\ngeneration. While our work is only done on audio modality, our framework can be\nextended to interpretable analysis of visual latent space generation models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u89e3\u91ca\u97f3\u9891\u751f\u6210\u6a21\u578b\u6f5c\u5728\u8868\u793a\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7279\u5f81\u6620\u5c04\u5230\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u58f0\u5b66\u6982\u5ff5\uff08\u97f3\u9ad8\u3001\u632f\u5e45\u3001\u97f3\u8272\uff09\uff0c\u5b9e\u73b0\u53ef\u63a7\u64cd\u4f5c\u548c\u751f\u6210\u8fc7\u7a0b\u5206\u6790\u3002", "motivation": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u6210\u529f\u63d0\u53d6\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u4f46\u5728\u97f3\u9891\u751f\u6210\u4e2d\u9762\u4e34\u6311\u6218\uff1a\u97f3\u9891\u7684\u5bc6\u96c6\u7279\u6027\u4f7f\u5f97\u538b\u7f29\u540e\u8bed\u4e49\u4fe1\u606f\u6a21\u7cca\uff0c\u4e14\u81ea\u52a8\u7279\u5f81\u8868\u5f81\u6709\u9650\u3002", "method": "\u5728\u97f3\u9891\u81ea\u7f16\u7801\u5668\u6f5c\u5728\u7a7a\u95f4\u4e0a\u8bad\u7ec3\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u7136\u540e\u5b66\u4e60\u4eceSAE\u7279\u5f81\u5230\u79bb\u6563\u5316\u58f0\u5b66\u5c5e\u6027\u7684\u7ebf\u6027\u6620\u5c04\uff0c\u652f\u6301\u8fde\u7eed\u548c\u79bb\u6563\u97f3\u9891\u6f5c\u5728\u7a7a\u95f4\u3002", "result": "\u5728DiffRhythm-VAE\u3001EnCodec\u548cWavTokenizer\u7b49\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u5206\u6790\u4e86DiffRhythm\u6587\u672c\u5230\u97f3\u4e50\u6a21\u578b\u4e2d\u97f3\u9ad8\u3001\u97f3\u8272\u548c\u54cd\u5ea6\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6f14\u53d8\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u97f3\u9891\u6a21\u6001\uff0c\u8fd8\u53ef\u6269\u5c55\u5230\u89c6\u89c9\u6f5c\u5728\u7a7a\u95f4\u751f\u6210\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u5206\u6790\u3002"}}
{"id": "2510.23804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23804", "abs": "https://arxiv.org/abs/2510.23804", "authors": ["Adela DePavia", "Vasileios Charisopoulos", "Rebecca Willett"], "title": "How do simple rotations affect the implicit bias of Adam?", "comment": null, "summary": "Adaptive gradient methods such as Adam and Adagrad are widely used in machine\nlearning, yet their effect on the generalization of learned models -- relative\nto methods like gradient descent -- remains poorly understood. Prior work on\nbinary classification suggests that Adam exhibits a ``richness bias,'' which\ncan help it learn nonlinear decision boundaries closer to the Bayes-optimal\ndecision boundary relative to gradient descent. However, the coordinate-wise\npreconditioning scheme employed by Adam renders the overall method sensitive to\northogonal transformations of feature space. We show that this sensitivity can\nmanifest as a reversal of Adam's competitive advantage: even small rotations of\nthe underlying data distribution can make Adam forfeit its richness bias and\nconverge to a linear decision boundary that is farther from the Bayes-optimal\ndecision boundary than the one learned by gradient descent. To alleviate this\nissue, we show that a recently proposed reparameterization method -- which\napplies an orthogonal transformation to the optimization objective -- endows\nany first-order method with equivariance to data rotations, and we empirically\ndemonstrate its ability to restore Adam's bias towards rich decision\nboundaries.", "AI": {"tldr": "\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u5982Adam\u548cAdagrad\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u5bf9\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u76f8\u5bf9\u4e8e\u68af\u5ea6\u4e0b\u964d\u7b49\u65b9\u6cd5\u4ecd\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u53d1\u73b0Adam\u5b58\u5728\"\u4e30\u5bcc\u6027\u504f\u5dee\"\uff0c\u4f46\u8be5\u65b9\u6cd5\u5bf9\u7279\u5f81\u7a7a\u95f4\u7684\u6b63\u4ea4\u53d8\u6362\u654f\u611f\uff0c\u53ef\u80fd\u5bfc\u81f4\u5176\u4f18\u52bf\u6d88\u5931\u3002\u901a\u8fc7\u91cd\u53c2\u6570\u5316\u65b9\u6cd5\u53ef\u4ee5\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "motivation": "\u7406\u89e3\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\uff08\u5982Adam\uff09\u76f8\u5bf9\u4e8e\u68af\u5ea6\u4e0b\u964d\u5728\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u5f71\u54cd\u5dee\u5f02\uff0c\u7279\u522b\u662fAdam\u8868\u73b0\u51fa\u7684\"\u4e30\u5bcc\u6027\u504f\u5dee\"\u7279\u6027\u53ca\u5176\u5bf9\u6570\u636e\u53d8\u6362\u7684\u654f\u611f\u6027\u3002", "method": "\u5206\u6790Adam\u65b9\u6cd5\u5728\u4e8c\u5143\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u7814\u7a76\u5176\u5bf9\u6b63\u4ea4\u53d8\u6362\u7684\u654f\u611f\u6027\uff0c\u5e76\u5e94\u7528\u91cd\u53c2\u6570\u5316\u65b9\u6cd5\uff08\u5bf9\u4f18\u5316\u76ee\u6807\u5e94\u7528\u6b63\u4ea4\u53d8\u6362\uff09\u6765\u4f7f\u4e00\u9636\u65b9\u6cd5\u5bf9\u6570\u636e\u65cb\u8f6c\u5177\u6709\u7b49\u53d8\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0Adam\u7684\u4e30\u5bcc\u6027\u504f\u5dee\u5bf9\u6570\u636e\u65cb\u8f6c\u654f\u611f\uff0c\u5373\u4f7f\u5c0f\u7684\u65cb\u8f6c\u4e5f\u53ef\u80fd\u4f7f\u5176\u5931\u53bb\u7ade\u4e89\u4f18\u52bf\u5e76\u6536\u655b\u5230\u8fdc\u79bb\u8d1d\u53f6\u65af\u6700\u4f18\u51b3\u7b56\u8fb9\u754c\u7684\u7ebf\u6027\u8fb9\u754c\u3002\u91cd\u53c2\u6570\u5316\u65b9\u6cd5\u80fd\u591f\u6062\u590dAdam\u5bf9\u4e30\u5bcc\u51b3\u7b56\u8fb9\u754c\u7684\u504f\u597d\u3002", "conclusion": "\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u7684\u6027\u80fd\u53d7\u6570\u636e\u53d8\u6362\u5f71\u54cd\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u91cd\u53c2\u6570\u5316\u53ef\u4ee5\u4f7f\u5176\u5bf9\u6570\u636e\u65cb\u8f6c\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4ece\u800c\u4fdd\u6301\u5176\u5b66\u4e60\u590d\u6742\u51b3\u7b56\u8fb9\u754c\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.23810", "categories": ["cs.LG", "math.AP", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23810", "abs": "https://arxiv.org/abs/2510.23810", "authors": ["Sumanta Roy", "Bahador Bahmani", "Ioannis G. Kevrekidis", "Michael D. Shields"], "title": "A Physics-informed Multi-resolution Neural Operator", "comment": "26 pages, 14 figures, 4 tables", "summary": "The predictive accuracy of operator learning frameworks depends on the\nquality and quantity of available training data (input-output function pairs),\noften requiring substantial amounts of high-fidelity data, which can be\nchallenging to obtain in some real-world engineering applications. These\ndatasets may be unevenly discretized from one realization to another, with the\ngrid resolution varying across samples. In this study, we introduce a\nphysics-informed operator learning approach by extending the Resolution\nIndependent Neural Operator (RINO) framework to a fully data-free setup,\naddressing both challenges simultaneously. Here, the arbitrarily (but\nsufficiently finely) discretized input functions are projected onto a latent\nembedding space (i.e., a vector space of finite dimensions), using pre-trained\nbasis functions. The operator associated with the underlying partial\ndifferential equations (PDEs) is then approximated by a simple multi-layer\nperceptron (MLP), which takes as input a latent code along with spatiotemporal\ncoordinates to produce the solution in the physical space. The PDEs are\nenforced via a finite difference solver in the physical space. The validation\nand performance of the proposed method are benchmarked on several numerical\nexamples with multi-resolution data, where input functions are sampled at\nvarying resolutions, including both coarse and fine discretizations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u7b97\u5b50\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u5206\u8fa8\u7387\u65e0\u5173\u795e\u7ecf\u7b97\u5b50\u6846\u67b6\u6269\u5c55\u5230\u5b8c\u5168\u65e0\u6570\u636e\u8bbe\u7f6e\uff0c\u89e3\u51b3\u4e86\u8bad\u7ec3\u6570\u636e\u83b7\u53d6\u56f0\u96be\u548c\u591a\u5206\u8fa8\u7387\u6570\u636e\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u5de5\u7a0b\u5e94\u7528\u4e2d\uff0c\u83b7\u53d6\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\uff08\u8f93\u5165-\u8f93\u51fa\u51fd\u6570\u5bf9\uff09\u5177\u6709\u6311\u6218\u6027\uff0c\u4e14\u6570\u636e\u96c6\u53ef\u80fd\u5177\u6709\u4e0d\u5747\u5300\u7684\u79bb\u6563\u5316\uff0c\u7f51\u683c\u5206\u8fa8\u7387\u5728\u4e0d\u540c\u6837\u672c\u95f4\u53d8\u5316\u3002", "method": "\u5c06\u4efb\u610f\u79bb\u6563\u5316\u7684\u8f93\u5165\u51fd\u6570\u6295\u5f71\u5230\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u57fa\u51fd\u6570\u3002\u901a\u8fc7\u591a\u5c42\u611f\u77e5\u673a\u8fd1\u4f3c\u504f\u5fae\u5206\u65b9\u7a0b\u7b97\u5b50\uff0c\u7ed3\u5408\u6f5c\u5728\u7f16\u7801\u548c\u65f6\u7a7a\u5750\u6807\u5728\u7269\u7406\u7a7a\u95f4\u4e2d\u4ea7\u751f\u89e3\uff0c\u5e76\u901a\u8fc7\u6709\u9650\u5dee\u5206\u6c42\u89e3\u5668\u5f3a\u5236\u6267\u884c\u504f\u5fae\u5206\u65b9\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u591a\u5206\u8fa8\u7387\u6570\u636e\u7684\u6570\u503c\u793a\u4f8b\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5305\u62ec\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u79bb\u6563\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u5206\u8fa8\u7387\u6570\u636e\uff0c\u5728\u65e0\u6570\u636e\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u7b97\u5b50\u5b66\u4e60\u3002"}}
{"id": "2510.24528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24528", "abs": "https://arxiv.org/abs/2510.24528", "authors": ["Zihan Chen", "Song Wang", "Xingbo Fu", "Chengshuai Shi", "Zhenyu Lei", "Cong Shen", "Jundong Li"], "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning", "comment": null, "summary": "The capability of in-context learning (ICL) enables large language models\n(LLMs) to perform novel tasks without parameter updates by conditioning on a\nfew input-output examples. However, collecting high-quality examples for new or\nchallenging tasks can be costly and labor-intensive. In this work, we propose a\ncost-efficient two-stage pipeline that reduces reliance on LLMs for data\nlabeling. Our approach first leverages readily available cross-task examples to\nprompt an LLM and pseudo-label a small set of target task instances. We then\nintroduce a graph-based label propagation method that spreads label information\nto the remaining target examples without additional LLM queries. The resulting\nfully pseudo-labeled dataset is used to construct in-task demonstrations for\nICL. This pipeline combines the flexibility of cross-task supervision with the\nscalability of LLM-free propagation. Experiments across five tasks demonstrate\nthat our method achieves strong performance while lowering labeling costs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\uff0c\u901a\u8fc7\u8de8\u4efb\u52a1\u793a\u4f8b\u4f2a\u6807\u6ce8\u548c\u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\u65b9\u6cd5\uff0c\u51cf\u5c11\u5bf9LLM\u6570\u636e\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u4e3a\u4e0a\u4e0b\u6587\u5b66\u4e60\u6784\u5efa\u6f14\u793a\u793a\u4f8b\u3002", "motivation": "\u4e3a\u65b0\u7684\u6216\u56f0\u96be\u4efb\u52a1\u6536\u96c6\u9ad8\u8d28\u91cf\u793a\u4f8b\u6210\u672c\u9ad8\u6602\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u9700\u8981\u51cf\u5c11\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6570\u636e\u6807\u6ce8\u7684\u4f9d\u8d56\u3002", "method": "\u4e24\u9636\u6bb5\u6d41\u7a0b\uff1a\u9996\u5148\u5229\u7528\u8de8\u4efb\u52a1\u793a\u4f8b\u63d0\u793aLLM\u4f2a\u6807\u6ce8\u5c11\u91cf\u76ee\u6807\u4efb\u52a1\u5b9e\u4f8b\uff0c\u7136\u540e\u5f15\u5165\u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\u65b9\u6cd5\u5c06\u6807\u7b7e\u4fe1\u606f\u4f20\u64ad\u5230\u5269\u4f59\u76ee\u6807\u793a\u4f8b\uff0c\u65e0\u9700\u989d\u5916LLM\u67e5\u8be2\u3002", "result": "\u5728\u4e94\u4e2a\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5f3a\u52b2\u6027\u80fd\u3002", "conclusion": "\u8be5\u7ba1\u9053\u7ed3\u5408\u4e86\u8de8\u4efb\u52a1\u76d1\u7763\u7684\u7075\u6d3b\u6027\u548c\u65e0LLM\u4f20\u64ad\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23817", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.23817", "abs": "https://arxiv.org/abs/2510.23817", "authors": ["Pedro Cortes dos Santos", "Matheus Becali Rocha", "Renato A Krohling"], "title": "Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes", "comment": null, "summary": "Industrial processes generate complex data that challenge fault detection\nsystems, often yielding opaque or underwhelming results despite advanced\nmachine learning techniques. This study tackles such difficulties using the\nTennessee Eastman Process, a well-established benchmark known for its intricate\ndynamics, to develop an innovative fault detection framework. Initial attempts\nwith standard models revealed limitations in both performance and\ninterpretability, prompting a shift toward a more tractable approach. By\nemploying SHAP (SHapley Additive exPlanations), we transform the problem into a\nmore manageable and transparent form, pinpointing the most critical process\nfeatures driving fault predictions. This reduction in complexity unlocks the\nability to apply causal analysis through Directed Acyclic Graphs, generated by\nmultiple algorithms, to uncover the underlying mechanisms of fault propagation.\nThe resulting causal structures align strikingly with SHAP findings,\nconsistently highlighting key process elements-like cooling and separation\nsystems-as pivotal to fault development. Together, these methods not only\nenhance detection accuracy but also provide operators with clear, actionable\ninsights into fault origins, a synergy that, to our knowledge, has not been\npreviously explored in this context. This dual approach bridges predictive\npower with causal understanding, offering a robust tool for monitoring complex\nmanufacturing environments and paving the way for smarter, more interpretable\nfault detection in industrial systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408SHAP\u89e3\u91ca\u6027\u5206\u6790\u548c\u56e0\u679c\u5206\u6790\u7684\u521b\u65b0\u6545\u969c\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5de5\u4e1a\u8fc7\u7a0b\u590d\u6742\u6570\u636e\u4e2d\u7684\u6545\u969c\u68c0\u6d4b\u96be\u9898\u3002\u901a\u8fc7\u7530\u7eb3\u897f\u4f0a\u65af\u66fc\u8fc7\u7a0b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u5728\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6545\u969c\u6839\u6e90\u5206\u6790\u3002", "motivation": "\u5de5\u4e1a\u8fc7\u7a0b\u4ea7\u751f\u7684\u590d\u6742\u6570\u636e\u7ed9\u6545\u969c\u68c0\u6d4b\u7cfb\u7edf\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5f80\u5f80\u7ed3\u679c\u4e0d\u900f\u660e\u6216\u6027\u80fd\u4e0d\u4f73\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u53c8\u80fd\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u6d1e\u5bdf\u7684\u6545\u969c\u68c0\u6d4b\u6846\u67b6\u3002", "method": "\u4f7f\u7528SHAP\uff08SHapley Additive exPlanations\uff09\u65b9\u6cd5\u8bc6\u522b\u5173\u952e\u8fc7\u7a0b\u7279\u5f81\uff0c\u7136\u540e\u901a\u8fc7\u6709\u5411\u65e0\u73af\u56fe\u8fdb\u884c\u56e0\u679c\u5206\u6790\uff0c\u63ed\u793a\u6545\u969c\u4f20\u64ad\u7684\u6f5c\u5728\u673a\u5236\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u7279\u5f81\u91cd\u8981\u6027\u548c\u56e0\u679c\u63a8\u7406\u3002", "result": "SHAP\u5206\u6790\u6210\u529f\u8bc6\u522b\u51fa\u9a71\u52a8\u6545\u969c\u9884\u6d4b\u7684\u5173\u952e\u8fc7\u7a0b\u7279\u5f81\uff0c\u56e0\u679c\u5206\u6790\u7ed3\u679c\u4e0eSHAP\u53d1\u73b0\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5171\u540c\u7a81\u51fa\u4e86\u51b7\u5374\u548c\u5206\u79bb\u7cfb\u7edf\u7b49\u5173\u952e\u8fc7\u7a0b\u5143\u7d20\u5728\u6545\u969c\u53d1\u5c55\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\u3002", "conclusion": "\u8fd9\u79cd\u53cc\u91cd\u65b9\u6cd5\u5c06\u9884\u6d4b\u80fd\u529b\u4e0e\u56e0\u679c\u7406\u89e3\u76f8\u7ed3\u5408\uff0c\u4e3a\u590d\u6742\u5236\u9020\u73af\u5883\u76d1\u63a7\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u4e3a\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u66f4\u667a\u80fd\u3001\u66f4\u53ef\u89e3\u91ca\u7684\u6545\u969c\u68c0\u6d4b\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.23818", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23818", "abs": "https://arxiv.org/abs/2510.23818", "authors": ["Yilang Zhang", "Xiaodong Yang", "Yiwei Cai", "Georgios B. Giannakis"], "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning", "comment": null, "summary": "As large language models (LLMs) continue to scale in size, the computational\noverhead has become a major bottleneck for task-specific fine-tuning. While\nlow-rank adaptation (LoRA) effectively curtails this cost by confining the\nweight updates to a low-dimensional subspace, such a restriction can hinder\neffectiveness and slow convergence. This contribution deals with these\nlimitations by accumulating progressively a high-rank weight update from\nconsecutive low-rank increments. Specifically, the per update optimal low-rank\nmatrix is identified to minimize the loss function and closely approximate full\nfine-tuning. To endow efficient and seamless optimization without restarting,\nthis optimal choice is formed by appropriately scaling the columns of the\noriginal low-rank matrix. Rigorous performance guarantees reveal that the\noptimal scaling can be found analytically. Extensive numerical tests with\npopular LLMs scaling up to 12 billion parameters demonstrate a consistent\nperformance gain and fast convergence relative to state-of-the-art LoRA\nvariants on diverse tasks including natural language understanding, commonsense\nreasoning, and mathematical problem solving.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7d2f\u79ef\u8fde\u7eed\u4f4e\u79e9\u589e\u91cf\u6765\u6784\u5efa\u9ad8\u79e9\u6743\u91cd\u66f4\u65b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u514b\u670d\u4f20\u7edfLoRA\u5728\u6548\u679c\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u7684\u9650\u5236\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u73b0\u6709LoRA\u53d8\u4f53\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u4e0d\u65ad\u6269\u5927\uff0c\u8ba1\u7b97\u5f00\u9500\u6210\u4e3a\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7684\u4e3b\u8981\u74f6\u9888\u3002\u867d\u7136\u4f4e\u79e9\u9002\u5e94(LoRA)\u901a\u8fc7\u5c06\u6743\u91cd\u66f4\u65b0\u9650\u5236\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u6765\u6709\u6548\u63a7\u5236\u6210\u672c\uff0c\u4f46\u8fd9\u79cd\u9650\u5236\u4f1a\u963b\u788d\u6548\u679c\u5e76\u51cf\u7f13\u6536\u655b\u901f\u5ea6\u3002", "method": "\u901a\u8fc7\u7d2f\u79ef\u8fde\u7eed\u7684\u4f4e\u79e9\u589e\u91cf\u6765\u9010\u6b65\u6784\u5efa\u9ad8\u79e9\u6743\u91cd\u66f4\u65b0\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8bc6\u522b\u6bcf\u4e2a\u66f4\u65b0\u7684\u6700\u4f18\u4f4e\u79e9\u77e9\u9635\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u5e76\u7d27\u5bc6\u903c\u8fd1\u5168\u91cf\u5fae\u8c03\u3002\u901a\u8fc7\u9002\u5f53\u7f29\u653e\u539f\u59cb\u4f4e\u79e9\u77e9\u9635\u7684\u5217\u6765\u5f62\u6210\u6700\u4f18\u9009\u62e9\uff0c\u5b9e\u73b0\u9ad8\u6548\u65e0\u7f1d\u7684\u4f18\u5316\u800c\u65e0\u9700\u91cd\u542f\u3002", "result": "\u5728\u89c4\u6a21\u8fbe120\u4ebf\u53c2\u6570\u7684\u6d41\u884cLLMs\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u6570\u503c\u6d4b\u8bd5\u8868\u660e\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u7b49\u591a\u6837\u5316\u4efb\u52a1\u4e0a\uff0c\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u7684LoRA\u53d8\u4f53\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u548c\u5feb\u901f\u6536\u655b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u6790\u627e\u5230\u6700\u4f18\u7f29\u653e\u56e0\u5b50\uff0c\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6027\u80fd\u4fdd\u8bc1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfLoRA\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.24645", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24645", "abs": "https://arxiv.org/abs/2510.24645", "authors": ["Zengzhuang Xu", "Bingguang Hao", "Zechuan Wang", "Yuntao Wen", "Maolin Wang", "Yang Liu", "Long Chen", "Dong Wang", "Yicheng Chen", "Cunyin Peng", "Chenyi Zhuang", "Jinjie Gu", "Leilei Gan", "Xiangyu Zhao", "Shi Gu"], "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling", "comment": null, "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous\nagents to interface with external tools, a critical capability for solving\ncomplex, real-world problems. As this ability becomes increasingly central to\nadvanced AI systems, the need for high-quality, multi-turn training data to\ndevelop and refine it cannot be overstated. Existing data synthesis methods,\nsuch as random environment sampling or multi-agent role-playing, are not\npowerful enough to generate high-quality data in real-world environments.\nPractical challenges come in three folds: targeted model training, isolation of\ntool architecture, and multi-turn logical dependency. To address these\nstructural deficiencies, we present FunReason-MT, a novel data synthesis\nframework for real-world multi-turn tool use. FunReason-MT resolves the\ncomplexity barrier in multi-turn FC data by employing 1) Environment-API Graph\nInteractions to gather varied high-quality trajectories, 2) Advanced Tool-Query\nSynthesis to simplify hard query construction, and 3) Guided Iterative Chain\nfor sophisticated CoT generation. Evaluations on Berkeley Function-Calling\nLeaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built\nupon FunReason-MT generated data achieves state-of-the-art performance among\ncomparable-sized models, outperforming most close-source models. Further\nperformance improvements on BFCLv4 confirm that FunReason-MT provides a\nreliable and robust source for agentic learning.", "AI": {"tldr": "FunReason-MT\u662f\u4e00\u4e2a\u7528\u4e8e\u5408\u6210\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u7684\u65b0\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u73af\u5883-API\u56fe\u4ea4\u4e92\u3001\u9ad8\u7ea7\u5de5\u5177\u67e5\u8be2\u5408\u6210\u548c\u5f15\u5bfc\u8fed\u4ee3\u94fe\u7b49\u6280\u672f\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff08\u5982\u968f\u673a\u73af\u5883\u91c7\u6837\u6216\u591a\u667a\u80fd\u4f53\u89d2\u8272\u626e\u6f14\uff09\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u7684\u80fd\u529b\u4e0d\u8db3\uff0c\u9762\u4e34\u76ee\u6807\u6a21\u578b\u8bad\u7ec3\u3001\u5de5\u5177\u67b6\u6784\u9694\u79bb\u548c\u591a\u8f6e\u903b\u8f91\u4f9d\u8d56\u4e09\u5927\u6311\u6218\u3002", "method": "\u91c7\u7528\u73af\u5883-API\u56fe\u4ea4\u4e92\u6536\u96c6\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u8f68\u8ff9\uff0c\u9ad8\u7ea7\u5de5\u5177\u67e5\u8be2\u5408\u6210\u7b80\u5316\u590d\u6742\u67e5\u8be2\u6784\u5efa\uff0c\u5f15\u5bfc\u8fed\u4ee3\u94fe\u751f\u6210\u590d\u6742\u601d\u7ef4\u94fe\u3002", "result": "\u5728Berkeley Function-Calling Leaderboard (BFCLv3)\u4e0a\uff0c\u57fa\u4e8eFunReason-MT\u751f\u6210\u6570\u636e\u8bad\u7ec3\u76844B\u6a21\u578b\u5728\u540c\u7c7b\u89c4\u6a21\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8d85\u8d8a\u5927\u591a\u6570\u95ed\u6e90\u6a21\u578b\u3002\u5728BFCLv4\u4e0a\u7684\u8fdb\u4e00\u6b65\u6027\u80fd\u63d0\u5347\u8bc1\u5b9e\u4e86\u5176\u53ef\u9760\u6027\u3002", "conclusion": "FunReason-MT\u4e3a\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u9c81\u68d2\u7684\u6570\u636e\u6e90\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u8f6e\u51fd\u6570\u8c03\u7528\u6570\u636e\u5408\u6210\u7684\u590d\u6742\u6027\u969c\u788d\u3002"}}
{"id": "2510.23866", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23866", "abs": "https://arxiv.org/abs/2510.23866", "authors": ["Paul Rosu", "Muchang Bahng", "Erick Jiang", "Rico Zhu", "Vahid Tarokh"], "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling", "comment": null, "summary": "This work presents a physics-conditioned latent diffusion model tailored for\ndynamical downscaling of atmospheric data, with a focus on reconstructing\nhigh-resolution 2-m temperature fields. Building upon a pre-existing diffusion\narchitecture and employing a residual formulation against a reference UNet, we\nintegrate a partial differential equation (PDE) loss term into the model's\ntraining objective. The PDE loss is computed in the full resolution (pixel)\nspace by decoding the latent representation and is designed to enforce physical\nconsistency through a finite-difference approximation of an effective\nadvection-diffusion balance. Empirical observations indicate that conventional\ndiffusion training already yields low PDE residuals, and we investigate how\nfine-tuning with this additional loss further regularizes the model and\nenhances the physical plausibility of the generated fields. The entirety of our\ncodebase is available on Github, for future reference and development.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7269\u7406\u6761\u4ef6\u5316\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u5927\u6c14\u6570\u636e\u7684\u52a8\u529b\u5b66\u964d\u5c3a\u5ea6\uff0c\u91cd\u70b9\u91cd\u5efa\u9ad8\u5206\u8fa8\u73872\u7c73\u6e29\u5ea6\u573a\u3002\u5728\u73b0\u6709\u6269\u6563\u67b6\u6784\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u6b8b\u5dee\u516c\u5f0f\u7ed3\u5408PDE\u635f\u5931\u9879\u6765\u589e\u5f3a\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u8bad\u7ec3\u867d\u7136\u5df2\u7ecf\u4ea7\u751f\u8f83\u4f4e\u7684PDE\u6b8b\u5dee\uff0c\u4f46\u5e0c\u671b\u901a\u8fc7\u989d\u5916\u635f\u5931\u9879\u7684\u5fae\u8c03\u8fdb\u4e00\u6b65\u6b63\u5219\u5316\u6a21\u578b\uff0c\u589e\u5f3a\u751f\u6210\u573a\u7684\u7269\u7406\u5408\u7406\u6027\u3002", "method": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684\u6269\u6563\u67b6\u6784\uff0c\u91c7\u7528\u6b8b\u5dee\u516c\u5f0f\uff0c\u5728\u8bad\u7ec3\u76ee\u6807\u4e2d\u96c6\u6210\u504f\u5fae\u5206\u65b9\u7a0b\u635f\u5931\u9879\u3002PDE\u635f\u5931\u5728\u5b8c\u6574\u5206\u8fa8\u7387\u7a7a\u95f4\u4e2d\u901a\u8fc7\u89e3\u7801\u6f5c\u5728\u8868\u793a\u8ba1\u7b97\uff0c\u901a\u8fc7\u6709\u9650\u5dee\u5206\u8fd1\u4f3c\u5f3a\u5236\u7269\u7406\u4e00\u81f4\u6027\u3002", "result": "\u7ecf\u9a8c\u89c2\u5bdf\u8868\u660e\uff0c\u4f20\u7edf\u6269\u6563\u8bad\u7ec3\u5df2\u80fd\u4ea7\u751f\u4f4ePDE\u6b8b\u5dee\uff0c\u800c\u4f7f\u7528\u989d\u5916\u635f\u5931\u8fdb\u884c\u5fae\u8c03\u53ef\u8fdb\u4e00\u6b65\u6b63\u5219\u5316\u6a21\u578b\u5e76\u63d0\u9ad8\u751f\u6210\u573a\u7684\u7269\u7406\u5408\u7406\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5f00\u53d1\u4e86\u7269\u7406\u6761\u4ef6\u5316\u7684\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u4e0a\u5f00\u6e90\uff0c\u4f9b\u672a\u6765\u53c2\u8003\u548c\u5f00\u53d1\u3002"}}
{"id": "2510.24650", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24650", "abs": "https://arxiv.org/abs/2510.24650", "authors": ["Nitin Rai", "Daeun", "Choi", "Nathan S. Boyd", "Arnold W. Schumann"], "title": "Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning", "comment": "26 pages, 8 figures, and 2 tables", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through\nmachine and deep learning (ML and DL) for real-time computer vision. Research\nevolved from handcrafted feature extraction to large-scale automated feature\nlearning. With foundation models (FMs), crop disease datasets are now processed\nin fundamentally new ways. Unlike traditional neural networks, FMs integrate\nvisual and textual data, interpret symptoms in text, reason about\nsymptom-management relationships, and support interactive QA for growers and\neducators. Adaptive and imitation learning in robotics further enables\nfield-based disease management. This review screened approx. 40 articles on FM\napplications for SSDM, focusing on large-language models (LLMs) and\nvision-language models (VLMs), and discussing their role in adaptive learning\n(AL), reinforcement learning (RL), and digital twin frameworks for targeted\nspraying. Key findings: (a) FMs are gaining traction with surging literature in\n2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL\nand AL are still nascent for smart spraying; (d) digital twins with RL can\nsimulate targeted spraying virtually; (e) addressing the sim-to-real gap is\ncritical for real-world deployment; (f) human-robot collaboration remains\nlimited, especially in human-in-the-loop approaches where robots detect early\nsymptoms and humans validate uncertain cases; (g) multi-modal FMs with\nreal-time feedback will drive next-gen SSDM. For updates, resources, and\ncontributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to\nsubmit papers, code, or datasets.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u5206\u6790\u4e86\u7ea640\u7bc7\u5173\u4e8e\u57fa\u7840\u6a21\u578b\u5728\u4f5c\u7269\u5b9a\u70b9\u75c5\u5bb3\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u6587\u732e\uff0c\u91cd\u70b9\u5173\u6ce8\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u8ba8\u8bba\u4e86\u5b83\u4eec\u5728\u81ea\u9002\u5e94\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u5728\u5b9e\u65f6\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4f5c\u7269\u5b9a\u70b9\u75c5\u5bb3\u7ba1\u7406\u4ece\u624b\u5de5\u7279\u5f81\u63d0\u53d6\u53d1\u5c55\u5230\u5927\u89c4\u6a21\u81ea\u52a8\u7279\u5f81\u5b66\u4e60\u3002\u57fa\u7840\u6a21\u578b\u4ee5\u5168\u65b0\u65b9\u5f0f\u5904\u7406\u4f5c\u7269\u75c5\u5bb3\u6570\u636e\uff0c\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\uff0c\u89e3\u91ca\u75c7\u72b6\u6587\u672c\uff0c\u63a8\u7406\u75c7\u72b6\u4e0e\u7ba1\u7406\u7684\u5173\u7cfb\uff0c\u5e76\u4e3a\u79cd\u690d\u8005\u548c\u6559\u80b2\u8005\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u95ee\u7b54\u652f\u6301\u3002", "method": "\u901a\u8fc7\u7b5b\u9009\u7ea640\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u5206\u6790\u57fa\u7840\u6a21\u578b\u5728\u5b9a\u70b9\u75c5\u5bb3\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u5173\u6ce8\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u63a2\u8ba8\u5b83\u4eec\u5728\u81ea\u9002\u5e94\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e2d\u7684\u89d2\u8272\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\uff1a(a) \u57fa\u7840\u6a21\u578b\u57282023-24\u5e74\u6587\u732e\u6fc0\u589e\uff1b(b) \u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u5feb\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u8868\u91cf\u589e\u957f5-10\u500d\uff1b(c) \u5f3a\u5316\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u5728\u667a\u80fd\u55b7\u6d12\u4e2d\u4ecd\u5904\u4e8e\u8d77\u6b65\u9636\u6bb5\uff1b(d) \u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u5b57\u5b6a\u751f\u53ef\u865a\u62df\u6a21\u62df\u5b9a\u70b9\u55b7\u6d12\uff1b(e) \u89e3\u51b3\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u5bf9\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff1b(f) \u4eba\u673a\u534f\u4f5c\u4ecd\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u4eba\u5728\u73af\u65b9\u6cd5\u4e2d\uff1b(g) \u5177\u6709\u5b9e\u65f6\u53cd\u9988\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5c06\u63a8\u52a8\u4e0b\u4e00\u4ee3\u5b9a\u70b9\u75c5\u5bb3\u7ba1\u7406\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u6b63\u5728\u6539\u53d8\u4f5c\u7269\u75c5\u5bb3\u7ba1\u7406\u65b9\u5f0f\uff0c\u7279\u522b\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u5e94\u7528\u4ecd\u4e0d\u6210\u719f\uff0c\u4f46\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\u548c\u4eba\u673a\u534f\u4f5c\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5c06\u662f\u672a\u6765\u53d1\u5c55\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2510.23868", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23868", "abs": "https://arxiv.org/abs/2510.23868", "authors": ["Zhichao Wang"], "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA", "comment": null, "summary": "I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine\n\\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning\nLLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT\nminimizes the discrepancy between implicit and explicit reward models. It\ncombines three key ideas: (1) the online multi-response generation and\nnormalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the\nimplicit-explicit reward alignment principle of UNA. By jointly normalizing the\nimplicit and explicit rewards, GIFT eliminates an otherwise intractable term\nthat prevents effective use of implicit rewards. This normalization transforms\nthe complex reward maximization objective into a simple mean squared error\n(MSE) loss between the normalized reward functions, converting a non-convex\noptimization problem into a convex, stable, and analytically differentiable\nformulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy\nand thus retains exploration capability. Compared to GRPO, it requires fewer\nhyperparameters, converges faster, and generalizes better with significantly\nreduced training overfitting. Empirically, GIFT achieves superior reasoning and\nalignment performance on mathematical benchmarks while remaining\ncomputationally efficient.", "AI": {"tldr": "GIFT\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9690\u5f0f\u548c\u663e\u5f0f\u5956\u52b1\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u5bf9\u9f50LLMs\uff0c\u5c06\u590d\u6742\u7684\u5956\u52b1\u6700\u5927\u5316\u76ee\u6807\u8f6c\u5316\u4e3a\u7b80\u5355\u7684MSE\u635f\u5931\uff0c\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982PPO\u3001GRPO\u76f4\u63a5\u6700\u5927\u5316\u7d2f\u79ef\u5956\u52b1\uff0c\u800cDPO\u3001UNA\u7b49\u79bb\u7ebf\u65b9\u6cd5\u7f3a\u4e4f\u63a2\u7d22\u80fd\u529b\u3002GIFT\u65e8\u5728\u7ed3\u5408\u5728\u7ebf\u751f\u6210\u548c\u9690\u5f0f\u5956\u52b1\u7684\u4f18\u52bf\uff0c\u6d88\u9664\u96be\u4ee5\u5904\u7406\u7684\u9879\uff0c\u5b9e\u73b0\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684LLM\u5bf9\u9f50\u3002", "method": "\u7ed3\u5408GRPO\u7684\u5728\u7ebf\u591a\u54cd\u5e94\u751f\u6210\u548c\u5f52\u4e00\u5316\u3001DPO\u7684\u9690\u5f0f\u5956\u52b1\u516c\u5f0f\u4ee5\u53caUNA\u7684\u9690\u5f0f-\u663e\u5f0f\u5956\u52b1\u5bf9\u9f50\u539f\u5219\uff0c\u901a\u8fc7\u8054\u5408\u5f52\u4e00\u5316\u9690\u5f0f\u548c\u663e\u5f0f\u5956\u52b1\uff0c\u5c06\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u7684MSE\u635f\u5931\u3002", "result": "\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u63a8\u7406\u548c\u5bf9\u9f50\u6027\u80fd\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u6536\u655b\u66f4\u5feb\uff0c\u6cdb\u5316\u66f4\u597d\uff0c\u8bad\u7ec3\u8fc7\u62df\u5408\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "GIFT\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u3001\u9ad8\u6548\u4e14\u5177\u6709\u63a2\u7d22\u80fd\u529b\u7684LLM\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u5728\u7ebf\u7b56\u7565\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.24663", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24663", "abs": "https://arxiv.org/abs/2510.24663", "authors": ["Yifu Lu", "Shengjie Liu", "Li Dong"], "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs", "comment": "9 pages, 4 figures", "summary": "Agentic tool use has gained traction with the rise of agentic tool calling,\nyet most existing work overlooks the complexity of multi-turn tool\ninteractions. We introduce OrchDAG, a synthetic data generation pipeline that\nmodels tool execution as directed acyclic graphs (DAGs) with controllable\ncomplexity. Using this dataset, we benchmark model performance and propose a\ngraph-based reward to enhance RLVR training. Experiments show that the dataset\npresents a challenging but solvable benchmark, and the proposed reward is\neffective when combined with GRPO-style algorithms, highlighting the importance\nof leveraging topological structure and data complexity in multi-turn tool use.", "AI": {"tldr": "OrchDAG\u662f\u4e00\u4e2a\u5408\u6210\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5c06\u5de5\u5177\u6267\u884c\u5efa\u6a21\u4e3a\u5177\u6709\u53ef\u63a7\u590d\u6742\u5ea6\u7684\u6709\u5411\u65e0\u73af\u56fe\uff0c\u7528\u4e8e\u591a\u8f6e\u5de5\u5177\u4ea4\u4e92\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5927\u591a\u5ffd\u89c6\u4e86\u591a\u8f6e\u5de5\u5177\u4ea4\u4e92\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u597d\u7684\u57fa\u51c6\u548c\u8bad\u7ec3\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u79cd\u590d\u6742\u6027\u3002", "method": "\u5f15\u5165OrchDAG\u5408\u6210\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5c06\u5de5\u5177\u6267\u884c\u5efa\u6a21\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u5956\u52b1\u6765\u589e\u5f3aRLVR\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u4f46\u53ef\u89e3\u51b3\u7684\u57fa\u51c6\uff0c\u6240\u63d0\u51fa\u7684\u5956\u52b1\u5728\u4e0eGRPO\u98ce\u683c\u7b97\u6cd5\u7ed3\u5408\u65f6\u6709\u6548\u3002", "conclusion": "\u5728\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u4e2d\uff0c\u5229\u7528\u62d3\u6251\u7ed3\u6784\u548c\u6570\u636e\u590d\u6742\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.24690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24690", "abs": "https://arxiv.org/abs/2510.24690", "authors": ["Shengjie Liu", "Li Dong", "Zhenyu Zhang"], "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning", "comment": "4 pages, 2 figures, short paper, NeurIPS 2025 workshop on Bridging\n  Language, Agent, and World Models for Reasoning and Planning", "summary": "We present a framework for uncovering and exploiting dependencies among tools\nand documents to enhance exemplar artifact generation. Our method begins by\nconstructing a tool knowledge graph from tool schemas,including descriptions,\narguments, and output payloads, using a DeepResearch-inspired analysis. In\nparallel, we derive a complementary knowledge graph from internal documents and\nSOPs, which is then fused with the tool graph. To generate exemplar plans, we\nadopt a deep-sparse integration strategy that aligns structural tool\ndependencies with procedural knowledge. Experiments demonstrate that this\nunified framework effectively models tool interactions and improves plan\ngeneration, underscoring the benefits of linking tool graphs with domain\nknowledge graphs for tool-augmented reasoning and planning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u8fc7\u6784\u5efa\u5de5\u5177\u548c\u6587\u6863\u77e5\u8bc6\u56fe\u8c31\u6765\u589e\u5f3a\u793a\u4f8b\u5de5\u4ef6\u751f\u6210\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u7a00\u758f\u96c6\u6210\u7b56\u7565\u5c06\u5de5\u5177\u4f9d\u8d56\u5173\u7cfb\u4e0e\u7a0b\u5e8f\u77e5\u8bc6\u5bf9\u9f50\u3002", "motivation": "\u4e3a\u4e86\u63ed\u793a\u548c\u5229\u7528\u5de5\u5177\u4e0e\u6587\u6863\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u6539\u8fdb\u793a\u4f8b\u5de5\u4ef6\u7684\u751f\u6210\u8d28\u91cf\u3002", "method": "\u4ece\u5de5\u5177\u6a21\u5f0f\u6784\u5efa\u5de5\u5177\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ece\u5185\u90e8\u6587\u6863\u548cSOP\u6784\u5efa\u8865\u5145\u77e5\u8bc6\u56fe\u8c31\uff0c\u7136\u540e\u5c06\u4e24\u8005\u878d\u5408\uff0c\u91c7\u7528\u6df1\u5ea6\u7a00\u758f\u96c6\u6210\u7b56\u7565\u5bf9\u9f50\u5de5\u5177\u4f9d\u8d56\u5173\u7cfb\u4e0e\u7a0b\u5e8f\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7edf\u4e00\u6846\u67b6\u80fd\u6709\u6548\u5efa\u6a21\u5de5\u5177\u4ea4\u4e92\u5e76\u6539\u8fdb\u8ba1\u5212\u751f\u6210\u3002", "conclusion": "\u5c06\u5de5\u5177\u56fe\u8c31\u4e0e\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u5bf9\u4e8e\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u548c\u89c4\u5212\u5177\u6709\u663e\u8457\u76ca\u5904\u3002"}}
{"id": "2510.23901", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23901", "abs": "https://arxiv.org/abs/2510.23901", "authors": ["Cristobal Heredia", "Pedro Chumpitaz-Flores", "Kaixun Hua"], "title": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees", "comment": "20 pages, 1 figure, uses ICLR 2026 LaTeX style. Submitted to arXiv as\n  a preprint version", "summary": "Mixed-integer programming (MIP) has emerged as a powerful framework for\nlearning optimal decision trees. Yet, existing MIP approaches for regression\ntasks are either limited to purely binary features or become computationally\nintractable when continuous, large-scale data are involved. Naively binarizing\ncontinuous features sacrifices global optimality and often yields needlessly\ndeep trees. We recast the optimal regression-tree training as a two-stage\noptimization problem and propose Reduced-Space Optimal Regression Trees\n(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches\nexclusively on tree-structural variables. This design guarantees the\nalgorithm's convergence and its independence from the number of training\nsamples. Leveraging the model's structure, we introduce several bound\ntightening techniques - closed-form leaf prediction, empirical threshold\ndiscretization, and exact depth-1 subtree parsing - that combine with\ndecomposable upper and lower bounding strategies to accelerate the training.\nThe BB node-wise decomposition enables trivial parallel execution, further\nalleviating the computational intractability even for million-size datasets.\nBased on the empirical studies on several regression benchmarks containing both\nbinary and continuous features, RS-ORT also delivers superior training and\ntesting performance than state-of-the-art methods. Notably, on datasets with up\nto 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed\ntraining performance with a simpler tree structure and a better generalization\nability in four hours.", "AI": {"tldr": "RS-ORT\u662f\u4e00\u79cd\u7528\u4e8e\u8bad\u7ec3\u6700\u4f18\u56de\u5f52\u6811\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u5728\u6811\u7ed3\u6784\u53d8\u91cf\u4e0a\u8fdb\u884c\u5206\u652f\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMIP\u65b9\u6cd5\u5728\u5904\u7406\u8fde\u7eed\u7279\u5f81\u548c\u5927\u89c4\u6a21\u6570\u636e\u65f6\u7684\u8ba1\u7b97\u96be\u9898\u3002", "motivation": "\u73b0\u6709\u7684MIP\u65b9\u6cd5\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u8981\u4e48\u4ec5\u9650\u4e8e\u4e8c\u5143\u7279\u5f81\uff0c\u8981\u4e48\u5728\u5904\u7406\u8fde\u7eed\u3001\u5927\u89c4\u6a21\u6570\u636e\u65f6\u8ba1\u7b97\u4e0d\u53ef\u884c\u3002\u7b80\u5355\u5730\u4e8c\u503c\u5316\u8fde\u7eed\u7279\u5f81\u4f1a\u727a\u7272\u5168\u5c40\u6700\u4f18\u6027\u5e76\u4ea7\u751f\u4e0d\u5fc5\u8981\u7684\u6df1\u6811\u3002", "method": "\u5c06\u6700\u4f18\u56de\u5f52\u6811\u8bad\u7ec3\u91cd\u65b0\u6784\u5efa\u4e3a\u4e24\u9636\u6bb5\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faRS-ORT - \u4e00\u79cd\u4e13\u95e8\u7684\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\uff0c\u4ec5\u5728\u6811\u7ed3\u6784\u53d8\u91cf\u4e0a\u8fdb\u884c\u5206\u652f\u3002\u91c7\u7528\u8fb9\u754c\u6536\u7d27\u6280\u672f\uff08\u95ed\u5f0f\u53f6\u9884\u6d4b\u3001\u7ecf\u9a8c\u9608\u503c\u79bb\u6563\u5316\u3001\u7cbe\u786e\u6df1\u5ea6-1\u5b50\u6811\u89e3\u6790\uff09\u548c\u53ef\u5206\u89e3\u7684\u4e0a\u4e0b\u754c\u7b56\u7565\u6765\u52a0\u901f\u8bad\u7ec3\u3002", "result": "\u5728\u5305\u542b\u4e8c\u5143\u548c\u8fde\u7eed\u7279\u5f81\u7684\u591a\u4e2a\u56de\u5f52\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRS-ORT\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u5bf9\u4e8e\u5305\u542b200\u4e07\u6837\u672c\u7684\u8fde\u7eed\u7279\u5f81\u6570\u636e\u96c6\uff0cRS-ORT\u80fd\u57284\u5c0f\u65f6\u5185\u83b7\u5f97\u4fdd\u8bc1\u7684\u8bad\u7ec3\u6027\u80fd\uff0c\u5177\u6709\u66f4\u7b80\u5355\u7684\u6811\u7ed3\u6784\u548c\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RS-ORT\u901a\u8fc7\u4e13\u95e8\u7684\u7b97\u6cd5\u8bbe\u8ba1\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u8fde\u7eed\u7279\u5f81\u56de\u5f52\u6811\u8bad\u7ec3\u7684\u8ba1\u7b97\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6700\u4f18\u6811\u5b66\u4e60\uff0c\u5e76\u5728\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2505.22820", "categories": ["cs.LG", "cs.AI", "econ.TH", "stat.ML"], "pdf": "https://arxiv.org/pdf/2505.22820", "abs": "https://arxiv.org/abs/2505.22820", "authors": ["Ayush Sawarni", "Sahasrajit Sarmasarkar", "Vasilis Syrgkanis"], "title": "Preference Learning with Response Time: Robust Losses and Guarantees", "comment": "Accepted at NeurIPS 2025", "summary": "This paper investigates the integration of response time data into human\npreference learning frameworks for more effective reward model elicitation.\nWhile binary preference data has become fundamental in fine-tuning foundation\nmodels, generative AI systems, and other large-scale models, the valuable\ntemporal information inherent in user decision-making remains largely\nunexploited. We propose novel methodologies to incorporate response time\ninformation alongside binary choice data, leveraging the Evidence Accumulation\nDrift Diffusion (EZ) model, under which response time is informative of the\npreference strength. We develop Neyman-orthogonal loss functions that achieve\noracle convergence rates for reward model learning, matching the theoretical\noptimal rates that would be attained if the expected response times for each\nquery were known a priori. Our theoretical analysis demonstrates that for\nlinear reward functions, conventional preference learning suffers from error\nrates that scale exponentially with reward magnitude. In contrast, our response\ntime-augmented approach reduces this to polynomial scaling, representing a\nsignificant improvement in sample efficiency. We extend these guarantees to\nnon-parametric reward function spaces, establishing convergence properties for\nmore complex, realistic reward models. Our extensive experiments validate our\ntheoretical findings in the context of preference learning over images.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5c06\u54cd\u5e94\u65f6\u95f4\u6570\u636e\u6574\u5408\u5230\u4eba\u7c7b\u504f\u597d\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u83b7\u53d6\u5956\u52b1\u6a21\u578b\u3002\u901a\u8fc7\u5229\u7528\u8bc1\u636e\u79ef\u7d2f\u6f02\u79fb\u6269\u6563\u6a21\u578b\uff0c\u5c06\u54cd\u5e94\u65f6\u95f4\u4fe1\u606f\u4e0e\u4e8c\u5143\u9009\u62e9\u6570\u636e\u7ed3\u5408\uff0c\u5f00\u53d1\u4e86\u5177\u6709\u7406\u8bba\u6700\u4f18\u6536\u655b\u7387\u7684Neyman\u6b63\u4ea4\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u867d\u7136\u4e8c\u5143\u504f\u597d\u6570\u636e\u5df2\u6210\u4e3a\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u548c\u751f\u6210AI\u7cfb\u7edf\u7684\u5173\u952e\uff0c\u4f46\u7528\u6237\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u5b9d\u8d35\u65f6\u95f4\u4fe1\u606f\u4ecd\u672a\u5f97\u5230\u5145\u5206\u5229\u7528\u3002\u54cd\u5e94\u65f6\u95f4\u53ef\u4ee5\u53cd\u6620\u504f\u597d\u7684\u5f3a\u5ea6\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u8fd9\u4e00\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u5c06\u54cd\u5e94\u65f6\u95f4\u4fe1\u606f\u4e0e\u4e8c\u5143\u9009\u62e9\u6570\u636e\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u8bc1\u636e\u79ef\u7d2f\u6f02\u79fb\u6269\u6563\u6a21\u578b\uff0c\u5f00\u53d1Neyman\u6b63\u4ea4\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u5956\u52b1\u6a21\u578b\u5b66\u4e60\u7684\u7406\u8bba\u6700\u4f18\u6536\u655b\u7387\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5bf9\u4e8e\u7ebf\u6027\u5956\u52b1\u51fd\u6570\uff0c\u4f20\u7edf\u504f\u597d\u5b66\u4e60\u7684\u9519\u8bef\u7387\u968f\u5956\u52b1\u5e45\u5ea6\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u800c\u54cd\u5e94\u65f6\u95f4\u589e\u5f3a\u65b9\u6cd5\u5c06\u5176\u964d\u4f4e\u4e3a\u591a\u9879\u5f0f\u589e\u957f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002\u5b9e\u9a8c\u5728\u56fe\u50cf\u504f\u597d\u5b66\u4e60\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u54cd\u5e94\u65f6\u95f4\u589e\u5f3a\u7684\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\u548c\u6536\u655b\u6027\u80fd\uff0c\u4e3a\u5956\u52b1\u6a21\u578b\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u6846\u67b6\u3002"}}
{"id": "2510.23912", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23912", "abs": "https://arxiv.org/abs/2510.23912", "authors": ["Marko Karbevski", "Antonij Mijoski"], "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers", "comment": null, "summary": "The Query, Key, Value weight triplet is a building block of current attention\nmechanisms in state-of-the-art LLMs. We theoretically investigate whether this\ntriplet can be reduced, proving under simplifying assumptions that the Query\nweights are redundant, thereby reducing the number of non-embedding/lm-head\nparameters by over 8%. We validate the theory on full-complexity GPT-3 small\narchitectures (with layer normalization, skip connections, and weight decay)\ntrained from scratch, demonstrating that the reduced model achieves comparable\nvalidation loss to standard baselines. These findings motivate the\ninvestigation of the Query weight redundancy at scale.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u5728\u7b80\u5316\u5047\u8bbe\u4e0b\uff0c\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684Query\u6743\u91cd\u662f\u5197\u4f59\u7684\uff0c\u53ef\u4ee5\u51cf\u5c11\u8d85\u8fc78%\u7684\u975e\u5d4c\u5165\u53c2\u6570\uff0c\u5e76\u5728GPT-3\u5c0f\u67b6\u6784\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u3002", "motivation": "\u7814\u7a76\u5f53\u524dLLM\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684Query\u3001Key\u3001Value\u6743\u91cd\u4e09\u5143\u7ec4\u662f\u5426\u53ef\u4ee5\u88ab\u7b80\u5316\uff0c\u4ee5\u964d\u4f4e\u6a21\u578b\u53c2\u6570\u91cf\u3002", "method": "\u5728\u7406\u8bba\u5206\u6790\u7684\u57fa\u7840\u4e0a\uff0c\u4f7f\u7528\u5b8c\u6574\u7684GPT-3\u5c0f\u67b6\u6784\uff08\u5305\u542b\u5c42\u5f52\u4e00\u5316\u3001\u8df3\u8dc3\u8fde\u63a5\u548c\u6743\u91cd\u8870\u51cf\uff09\u8fdb\u884c\u4ece\u5934\u8bad\u7ec3\u9a8c\u8bc1\u3002", "result": "\u51cf\u5c11Query\u6743\u91cd\u7684\u6a21\u578b\u5728\u9a8c\u8bc1\u635f\u5931\u4e0a\u4e0e\u6807\u51c6\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "Query\u6743\u91cd\u5b58\u5728\u5197\u4f59\u6027\uff0c\u8fd9\u4e3a\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u7814\u7a76Query\u6743\u91cd\u5197\u4f59\u63d0\u4f9b\u4e86\u52a8\u673a\u3002"}}
{"id": "2510.23914", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23914", "abs": "https://arxiv.org/abs/2510.23914", "authors": ["Arsenii Mustafin", "Xinyi Sheng", "Dominik Baumann"], "title": "Geometry-Inspired Unified Framework for Discounted and Average Reward MDPs", "comment": "12 pages, 1 figure", "summary": "The theoretical analysis of Markov Decision Processes (MDPs) is commonly\nsplit into two cases - the average-reward case and the discounted-reward case -\nwhich, while sharing similarities, are typically analyzed separately. In this\nwork, we extend a recently introduced geometric interpretation of MDPs for the\ndiscounted-reward case to the average-reward case, thereby unifying both. This\nallows us to extend a major result known for the discounted-reward case to the\naverage-reward case: under a unique and ergodic optimal policy, the Value\nIteration algorithm achieves a geometric convergence rate.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06MDP\u7684\u51e0\u4f55\u89e3\u91ca\u4ece\u6298\u6263\u5956\u52b1\u60c5\u51b5\u6269\u5c55\u5230\u5e73\u5747\u5956\u52b1\u60c5\u51b5\uff0c\u7edf\u4e00\u4e86\u4e24\u79cd\u5206\u6790\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5728\u552f\u4e00\u4e14\u904d\u5386\u7684\u6700\u4f18\u7b56\u7565\u4e0b\uff0c\u503c\u8fed\u4ee3\u7b97\u6cd5\u80fd\u8fbe\u5230\u51e0\u4f55\u6536\u655b\u901f\u7387\u3002", "motivation": "\u4f20\u7edf\u7684MDP\u7406\u8bba\u5206\u6790\u901a\u5e38\u5c06\u5e73\u5747\u5956\u52b1\u60c5\u51b5\u548c\u6298\u6263\u5956\u52b1\u60c5\u51b5\u5206\u5f00\u5904\u7406\uff0c\u5c3d\u7ba1\u5b83\u4eec\u6709\u76f8\u4f3c\u4e4b\u5904\u3002\u672c\u7814\u7a76\u65e8\u5728\u7edf\u4e00\u8fd9\u4e24\u79cd\u60c5\u51b5\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5c06\u6700\u8fd1\u63d0\u51fa\u7684\u6298\u6263\u5956\u52b1\u60c5\u51b5\u4e0bMDP\u7684\u51e0\u4f55\u89e3\u91ca\u6269\u5c55\u5230\u5e73\u5747\u5956\u52b1\u60c5\u51b5\uff0c\u4ece\u800c\u7edf\u4e00\u4e24\u79cd\u5206\u6790\u6846\u67b6\u3002", "result": "\u6210\u529f\u5c06\u6298\u6263\u5956\u52b1\u60c5\u51b5\u4e0b\u7684\u4e3b\u8981\u7ed3\u679c\u6269\u5c55\u5230\u5e73\u5747\u5956\u52b1\u60c5\u51b5\uff1a\u5728\u552f\u4e00\u4e14\u904d\u5386\u7684\u6700\u4f18\u7b56\u7565\u4e0b\uff0c\u503c\u8fed\u4ee3\u7b97\u6cd5\u5b9e\u73b0\u4e86\u51e0\u4f55\u6536\u655b\u901f\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u51e0\u4f55\u89e3\u91ca\u7edf\u4e00\u4e86MDP\u7684\u5e73\u5747\u5956\u52b1\u548c\u6298\u6263\u5956\u52b1\u5206\u6790\uff0c\u5e76\u8bc1\u660e\u4e86\u503c\u8fed\u4ee3\u7b97\u6cd5\u5728\u4e24\u79cd\u60c5\u51b5\u4e0b\u90fd\u80fd\u8fbe\u5230\u51e0\u4f55\u6536\u655b\u3002"}}
{"id": "2510.23931", "categories": ["cs.LG", "cs.CR", "cs.DC", "68T07 (Primary) 68M14, 68P27, 68Q32, 94A16, 62H35 (Secondary)", "I.2.11; I.2.6; C.2.4; D.4.6; K.4.1"], "pdf": "https://arxiv.org/pdf/2510.23931", "abs": "https://arxiv.org/abs/2510.23931", "authors": ["Miguel Fernandez-de-Retana", "Unai Zulaika", "Rub\u00e9n S\u00e1nchez-Corcuera", "Aitor Almeida"], "title": "Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments", "comment": "17 pages, 12 figures", "summary": "Federated Learning (FL) allows for the training of Machine Learning models in\na collaborative manner without the need to share sensitive data. However, it\nremains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private\ninformation from the shared model updates. In this work, we investigate the\neffectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD\nand a variant based on explicit regularization (PDP-SGD) - as defenses against\nGLAs. To this end, we evaluate the performance of several computer vision\nmodels trained under varying privacy levels on a simple classification task,\nand then analyze the quality of private data reconstructions obtained from the\nintercepted gradients in a simulated FL environment. Our results demonstrate\nthat DP-SGD significantly mitigates the risk of gradient leakage attacks,\nalbeit with a moderate trade-off in model utility. In contrast, PDP-SGD\nmaintains strong classification performance but proves ineffective as a\npractical defense against reconstruction attacks. These findings highlight the\nimportance of empirically evaluating privacy mechanisms beyond their\ntheoretical guarantees, particularly in distributed learning scenarios where\ninformation leakage may represent an unassumable critical threat to data\nsecurity and privacy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\u673a\u5236\uff08DP-SGD\u548cPDP-SGD\uff09\u4f5c\u4e3a\u8054\u90a6\u5b66\u4e60\u4e2d\u68af\u5ea6\u6cc4\u6f0f\u653b\u51fb\u9632\u5fa1\u63aa\u65bd\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0DP-SGD\u80fd\u663e\u8457\u964d\u4f4e\u68af\u5ea6\u6cc4\u6f0f\u98ce\u9669\u4f46\u4f1a\u727a\u7272\u6a21\u578b\u6027\u80fd\uff0c\u800cPDP-SGD\u4fdd\u6301\u826f\u597d\u5206\u7c7b\u6027\u80fd\u4f46\u9632\u5fa1\u6548\u679c\u4e0d\u4f73\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u5141\u8bb8\u5728\u4e0d\u5171\u4eab\u654f\u611f\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u534f\u4f5c\u8bad\u7ec3\u6a21\u578b\uff0c\u4f46\u4ecd\u5bb9\u6613\u53d7\u5230\u68af\u5ea6\u6cc4\u6f0f\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u53ef\u80fd\u6cc4\u9732\u79c1\u6709\u4fe1\u606f\u3002", "method": "\u5728\u6a21\u62df\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u9690\u79c1\u7ea7\u522b\u4e0b\u591a\u4e2a\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u4ece\u622a\u83b7\u68af\u5ea6\u4e2d\u91cd\u5efa\u79c1\u6709\u6570\u636e\u7684\u8d28\u91cf\u3002", "result": "DP-SGD\u663e\u8457\u51cf\u8f7b\u4e86\u68af\u5ea6\u6cc4\u6f0f\u653b\u51fb\u7684\u98ce\u9669\uff0c\u4f46\u5b58\u5728\u6a21\u578b\u6548\u7528\u7684\u9002\u5ea6\u6743\u8861\uff1bPDP-SGD\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u4f46\u4f5c\u4e3a\u91cd\u5efa\u653b\u51fb\u7684\u5b9e\u9645\u9632\u5fa1\u63aa\u65bd\u65e0\u6548\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5728\u5206\u5e03\u5f0f\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u9664\u4e86\u7406\u8bba\u4fdd\u8bc1\u5916\uff0c\u8fd8\u9700\u8981\u5bf9\u9690\u79c1\u673a\u5236\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u56e0\u4e3a\u4fe1\u606f\u6cc4\u6f0f\u53ef\u80fd\u5bf9\u6570\u636e\u5b89\u5168\u548c\u9690\u79c1\u6784\u6210\u4e0d\u53ef\u627f\u53d7\u7684\u4e25\u91cd\u5a01\u80c1\u3002"}}
{"id": "2510.23948", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23948", "abs": "https://arxiv.org/abs/2510.23948", "authors": ["Qianfeng Wen", "Zhenwei Tang", "Ashton Anderson"], "title": "ChessQA: Evaluating Large Language Models for Chess Understanding", "comment": "33 pages,8 figures", "summary": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and\nabstraction capabilities of large language models (LLMs), as it has\nwell-defined structure and objective ground truth while admitting a wide\nspectrum of skill levels. However, existing evaluations of LLM ability in chess\nare ad hoc and narrow in scope, making it difficult to accurately measure LLM\nchess understanding and how it varies with scale, post-training methodologies,\nor architecture choices. We present ChessQA, a comprehensive benchmark that\nassesses LLM chess understanding across five task categories (Structural,\nMotifs, Short Tactics, Position Judgment, and Semantic), which approximately\ncorrespond to the ascending abstractions that players master as they accumulate\nchess knowledge, from understanding basic rules and learning tactical motifs to\ncorrectly calculating tactics, evaluating positions, and semantically\ndescribing high-level concepts. In this way, ChessQA captures a more\ncomprehensive picture of chess ability and understanding, going significantly\nbeyond the simple move quality evaluations done previously, and offers a\ncontrolled, consistent setting for diagnosis and comparison. Furthermore,\nChessQA is inherently dynamic, with prompts, answer keys, and construction\nscripts that can evolve as models improve. Evaluating a range of contemporary\nLLMs, we find persistent weaknesses across all five categories and provide\nresults and error analyses by category. We will release the code, periodically\nrefreshed datasets, and a public leaderboard to support further research.", "AI": {"tldr": "ChessQA\u662f\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56fd\u9645\u8c61\u68cb\u4e2d\u7684\u7406\u89e3\u80fd\u529b\uff0c\u6db5\u76d6\u4e94\u4e2a\u4efb\u52a1\u7c7b\u522b\uff1a\u7ed3\u6784\u3001\u6a21\u5f0f\u3001\u77ed\u6218\u672f\u3001\u4f4d\u7f6e\u5224\u65ad\u548c\u8bed\u4e49\uff0c\u5bf9\u5e94\u73a9\u5bb6\u79ef\u7d2f\u8c61\u68cb\u77e5\u8bc6\u65f6\u7684\u4e0d\u540c\u62bd\u8c61\u5c42\u6b21\u3002", "motivation": "\u56fd\u9645\u8c61\u68cb\u4e3a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u3001\u5efa\u6a21\u548c\u62bd\u8c61\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u60f3\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u96f6\u6563\u4e14\u8303\u56f4\u72ed\u7a84\uff0c\u96be\u4ee5\u51c6\u786e\u8861\u91cfLLM\u7684\u8c61\u68cb\u7406\u89e3\u80fd\u529b\u53ca\u5176\u968f\u89c4\u6a21\u3001\u8bad\u7ec3\u540e\u65b9\u6cd5\u6216\u67b6\u6784\u9009\u62e9\u7684\u53d8\u5316\u3002", "method": "\u5f00\u53d1\u4e86ChessQA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e94\u4e2a\u4efb\u52a1\u7c7b\u522b\uff1a\u7ed3\u6784\uff08\u57fa\u672c\u89c4\u5219\uff09\u3001\u6a21\u5f0f\uff08\u6218\u672f\u6a21\u5f0f\uff09\u3001\u77ed\u6218\u672f\uff08\u6b63\u786e\u8ba1\u7b97\uff09\u3001\u4f4d\u7f6e\u5224\u65ad\uff08\u8bc4\u4f30\u4f4d\u7f6e\uff09\u548c\u8bed\u4e49\uff08\u63cf\u8ff0\u9ad8\u7ea7\u6982\u5ff5\uff09\uff0c\u63d0\u4f9b\u52a8\u6001\u7684\u63d0\u793a\u3001\u7b54\u6848\u952e\u548c\u6784\u5efa\u811a\u672c\u3002", "result": "\u8bc4\u4f30\u5f53\u4ee3LLMs\u53d1\u73b0\uff0c\u5728\u6240\u6709\u4e94\u4e2a\u7c7b\u522b\u4e2d\u90fd\u5b58\u5728\u6301\u7eed\u7684\u5f31\u70b9\uff0c\u5e76\u63d0\u4f9b\u4e86\u6309\u7c7b\u522b\u7684\u7ed3\u679c\u548c\u9519\u8bef\u5206\u6790\u3002", "conclusion": "ChessQA\u63d0\u4f9b\u4e86\u6bd4\u5148\u524d\u7b80\u5355\u8d70\u5b50\u8d28\u91cf\u8bc4\u4f30\u66f4\u5168\u9762\u7684\u8c61\u68cb\u80fd\u529b\u8bc4\u4f30\uff0c\u4e3a\u8bca\u65ad\u548c\u6bd4\u8f83\u63d0\u4f9b\u4e86\u53d7\u63a7\u3001\u4e00\u81f4\u7684\u8bbe\u7f6e\uff0c\u5e76\u5c06\u53d1\u5e03\u4ee3\u7801\u3001\u5b9a\u671f\u66f4\u65b0\u7684\u6570\u636e\u96c6\u548c\u516c\u5171\u6392\u884c\u699c\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.23966", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23966", "abs": "https://arxiv.org/abs/2510.23966", "authors": ["Scott Emmons", "Roland S. Zimmermann", "David K. Elson", "Rohin Shah"], "title": "A Pragmatic Way to Measure Chain-of-Thought Monitorability", "comment": "The first two authors contributed equally", "summary": "While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI\nsafety, this opportunity could be lost through shifts in training practices or\nmodel architecture. To help preserve monitorability, we propose a pragmatic way\nto measure two components of it: legibility (whether the reasoning can be\nfollowed by a human) and coverage (whether the CoT contains all the reasoning\nneeded for a human to also produce the final output). We implement these\nmetrics with an autorater prompt that enables any capable LLM to compute the\nlegibility and coverage of existing CoTs. After sanity-checking our prompted\nautorater with synthetic CoT degradations, we apply it to several frontier\nmodels on challenging benchmarks, finding that they exhibit high\nmonitorability. We present these metrics, including our complete autorater\nprompt, as a tool for developers to track how design decisions impact\nmonitorability. While the exact prompt we share is still a preliminary version\nunder ongoing development, we are sharing it now in the hopes that others in\nthe community will find it useful. Our method helps measure the default\nmonitorability of CoT - it should be seen as a complement, not a replacement,\nfor the adversarial stress-testing needed to test robustness against\ndeliberately evasive models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u601d\u7ef4\u94fe(CoT)\u7684\u53ef\u76d1\u63a7\u6027\uff0c\u5305\u62ec\u53ef\u8bfb\u6027\u548c\u8986\u76d6\u5ea6\u4e24\u4e2a\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u8bc4\u5206\u5668\u5728\u591a\u4e2a\u524d\u6cbf\u6a21\u578b\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u4e3a\u4e86\u5e2e\u52a9\u4fdd\u6301AI\u7cfb\u7edf\u7684\u53ef\u76d1\u63a7\u6027\uff0c\u9632\u6b62\u56e0\u8bad\u7ec3\u5b9e\u8df5\u6216\u6a21\u578b\u67b6\u6784\u53d8\u5316\u800c\u4e27\u5931\u601d\u7ef4\u94fe\u76d1\u63a7\u7684\u673a\u4f1a\u3002", "method": "\u5f00\u53d1\u4e86\u81ea\u52a8\u8bc4\u5206\u5668\u63d0\u793a\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u73b0\u6709\u601d\u7ef4\u94fe\u7684\u53ef\u8bfb\u6027\u548c\u8986\u76d6\u5ea6\uff0c\u5e76\u5728\u5408\u6210\u9000\u5316\u7684\u601d\u7ef4\u94fe\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u591a\u4e2a\u524d\u6cbf\u6a21\u578b\u8868\u73b0\u51fa\u9ad8\u53ef\u76d1\u63a7\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8ddf\u8e2a\u8bbe\u8ba1\u51b3\u7b56\u5bf9\u53ef\u76d1\u63a7\u6027\u5f71\u54cd\u7684\u5de5\u5177\uff0c\u662f\u6545\u610f\u89c4\u907f\u6a21\u578b\u5bf9\u6297\u6027\u538b\u529b\u6d4b\u8bd5\u7684\u8865\u5145\u800c\u975e\u66ff\u4ee3\u3002"}}
{"id": "2510.23972", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23972", "abs": "https://arxiv.org/abs/2510.23972", "authors": ["Andra\u017e Jelin\u010di\u010d", "Owen Lockwood", "Akhil Garlapati", "Guillaume Verdon", "Trevor McCourt"], "title": "An efficient probabilistic hardware architecture for diffusion-like models", "comment": "9 pages, 6 figures", "summary": "The proliferation of probabilistic AI has promoted proposals for specialized\nstochastic computers. Despite promising efficiency gains, these proposals have\nfailed to gain traction because they rely on fundamentally limited modeling\ntechniques and exotic, unscalable hardware. In this work, we address these\nshortcomings by proposing an all-transistor probabilistic computer that\nimplements powerful denoising models at the hardware level. A system-level\nanalysis indicates that devices based on our architecture could achieve\nperformance parity with GPUs on a simple image benchmark using approximately\n10,000 times less energy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5168\u6676\u4f53\u7ba1\u6982\u7387\u8ba1\u7b97\u673a\uff0c\u5728\u786c\u4ef6\u5c42\u9762\u5b9e\u73b0\u5f3a\u5927\u7684\u53bb\u566a\u6a21\u578b\uff0c\u76f8\u6bd4GPU\u5728\u7b80\u5355\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53ef\u5b9e\u73b0\u6027\u80fd\u76f8\u5f53\u4f46\u80fd\u8017\u964d\u4f4e\u7ea610,000\u500d\u3002", "motivation": "\u73b0\u6709\u7684\u6982\u7387AI\u4e13\u7528\u8ba1\u7b97\u673a\u63d0\u6848\u7531\u4e8e\u4f9d\u8d56\u6709\u9650\u5efa\u6a21\u6280\u672f\u548c\u4e0d\u53ef\u6269\u5c55\u7684\u5f02\u8d28\u786c\u4ef6\u800c\u672a\u80fd\u83b7\u5f97\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u7f3a\u9677\u3002", "method": "\u8bbe\u8ba1\u5168\u6676\u4f53\u7ba1\u6982\u7387\u8ba1\u7b97\u673a\u67b6\u6784\uff0c\u5728\u786c\u4ef6\u5c42\u9762\u76f4\u63a5\u5b9e\u73b0\u5f3a\u5927\u7684\u53bb\u566a\u6a21\u578b\u3002", "result": "\u7cfb\u7edf\u7ea7\u5206\u6790\u8868\u660e\uff0c\u57fa\u4e8e\u8be5\u67b6\u6784\u7684\u8bbe\u5907\u5728\u7b80\u5355\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0eGPU\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u80fd\u8017\u964d\u4f4e\u7ea610,000\u500d\u3002", "conclusion": "\u8be5\u5168\u6676\u4f53\u7ba1\u6982\u7387\u8ba1\u7b97\u673a\u67b6\u6784\u89e3\u51b3\u4e86\u73b0\u6709\u6982\u7387\u8ba1\u7b97\u65b9\u6848\u7684\u5c40\u9650\u6027\uff0c\u5177\u6709\u663e\u8457\u7684\u80fd\u6548\u4f18\u52bf\uff0c\u6709\u671b\u63a8\u52a8\u6982\u7387AI\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2510.23974", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23974", "abs": "https://arxiv.org/abs/2510.23974", "authors": ["Byeonghu Na", "Minsang Park", "Gyuwon Sim", "Donghyeok Shin", "HeeSun Bae", "Mina Kang", "Se Jung Kwon", "Wanmo Kang", "Il-Chul Moon"], "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025", "summary": "Text-to-image diffusion models rely on text embeddings from a pre-trained\ntext encoder, but these embeddings remain fixed across all diffusion timesteps,\nlimiting their adaptability to the generative process. We propose Diffusion\nAdaptive Text Embedding (DATE), which dynamically updates text embeddings at\neach diffusion timestep based on intermediate perturbed data. We formulate an\noptimization problem and derive an update rule that refines the text embeddings\nat each sampling step to improve alignment and preference between the mean\npredicted image and the text. This allows DATE to dynamically adapts the text\nconditions to the reverse-diffused images throughout diffusion sampling without\nrequiring additional model training. Through theoretical analysis and empirical\nresults, we show that DATE maintains the generative capability of the model\nwhile providing superior text-image alignment over fixed text embeddings across\nvarious tasks, including multi-concept generation and text-guided image\nediting. Our code is available at https://github.com/aailab-kaist/DATE.", "AI": {"tldr": "DATE\u65b9\u6cd5\u901a\u8fc7\u5728\u6bcf\u4e2a\u6269\u6563\u65f6\u95f4\u6b65\u52a8\u6001\u66f4\u65b0\u6587\u672c\u5d4c\u5165\uff0c\u57fa\u4e8e\u4e2d\u95f4\u6270\u52a8\u6570\u636e\u4f18\u5316\u6587\u672c\u6761\u4ef6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u5728\u6574\u4e2a\u6269\u6563\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u56fa\u5b9a\u7684\u6587\u672c\u5d4c\u5165\uff0c\u9650\u5236\u4e86\u6587\u672c\u6761\u4ef6\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u6269\u6563\u81ea\u9002\u5e94\u6587\u672c\u5d4c\u5165\uff08DATE\uff09\uff0c\u5728\u6bcf\u4e2a\u6269\u6563\u65f6\u95f4\u6b65\u57fa\u4e8e\u4e2d\u95f4\u6270\u52a8\u6570\u636e\u52a8\u6001\u66f4\u65b0\u6587\u672c\u5d4c\u5165\uff0c\u901a\u8fc7\u4f18\u5316\u95ee\u9898\u63a8\u5bfc\u66f4\u65b0\u89c4\u5219\u3002", "result": "DATE\u5728\u4fdd\u6301\u6a21\u578b\u751f\u6210\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5728\u591a\u6982\u5ff5\u751f\u6210\u548c\u6587\u672c\u5f15\u5bfc\u56fe\u50cf\u7f16\u8f91\u7b49\u4efb\u52a1\u4e2d\u63d0\u4f9b\u4e86\u4f18\u4e8e\u56fa\u5b9a\u6587\u672c\u5d4c\u5165\u7684\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\u6548\u679c\u3002", "conclusion": "DATE\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u9700\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6587\u672c\u5d4c\u5165\u663e\u8457\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684\u5bf9\u9f50\u8d28\u91cf\u3002"}}
{"id": "2510.23977", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23977", "abs": "https://arxiv.org/abs/2510.23977", "authors": ["Yohan Abeysinghe", "Muhammad Akhtar Munir", "Sanoojan Baliah", "Ron Sarafian", "Fahad Shahbaz Khan", "Yinon Rudich", "Salman Khan"], "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "comment": null, "summary": "Air pollution remains a leading global health and environmental risk,\nparticularly in regions vulnerable to episodic air pollution spikes due to\nwildfires, urban haze and dust storms. Accurate forecasting of particulate\nmatter (PM) concentrations is essential to enable timely public health warnings\nand interventions, yet existing models often underestimate rare but hazardous\npollution events. Here, we present SynCast, a high-resolution neural\nforecasting model that integrates meteorological and air composition data to\nimprove predictions of both average and extreme pollution levels. Built on a\nregionally adapted transformer backbone and enhanced with a diffusion-based\nstochastic refinement module, SynCast captures the nonlinear dynamics driving\nPM spikes more accurately than existing approaches. Leveraging on harmonized\nERA5 and CAMS datasets, our model shows substantial gains in forecasting\nfidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),\nespecially under extreme conditions. We demonstrate that conventional loss\nfunctions underrepresent distributional tails (rare pollution events) and show\nthat SynCast, guided by domain-aware objectives and extreme value theory,\nsignificantly enhances performance in highly impacted regions without\ncompromising global accuracy. This approach provides a scalable foundation for\nnext-generation air quality early warning systems and supports climate-health\nrisk mitigation in vulnerable regions.", "AI": {"tldr": "SynCast\u662f\u4e00\u79cd\u9ad8\u5206\u8fa8\u7387\u795e\u7ecf\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u6c14\u8c61\u548c\u7a7a\u6c14\u6210\u5206\u6570\u636e\u6765\u6539\u5584\u5e73\u5747\u548c\u6781\u7aef\u6c61\u67d3\u6c34\u5e73\u7684\u9884\u6d4b\uff0c\u7279\u522b\u9488\u5bf9\u91ce\u706b\u3001\u57ce\u5e02\u96fe\u973e\u548c\u6c99\u5c18\u66b4\u7b49\u5bfc\u81f4\u7684\u7f55\u89c1\u4f46\u5371\u9669\u7684\u6c61\u67d3\u4e8b\u4ef6\u3002", "motivation": "\u7a7a\u6c14\u6c61\u67d3\u662f\u5168\u7403\u5065\u5eb7\u548c\u73af\u5883\u7684\u4e3b\u8981\u98ce\u9669\uff0c\u73b0\u6709\u6a21\u578b\u5f80\u5f80\u4f4e\u4f30\u7f55\u89c1\u4f46\u5371\u9669\u7684\u6c61\u67d3\u4e8b\u4ef6\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u9897\u7c92\u7269\u6d53\u5ea6\u9884\u6d4b\u6765\u652f\u6301\u53ca\u65f6\u7684\u516c\u5171\u536b\u751f\u9884\u8b66\u548c\u5e72\u9884\u3002", "method": "\u57fa\u4e8e\u533a\u57df\u9002\u5e94\u7684transformer\u67b6\u6784\uff0c\u7ed3\u5408\u6269\u6563\u57fa\u968f\u673a\u7ec6\u5316\u6a21\u5757\uff0c\u5229\u7528ERA5\u548cCAMS\u6570\u636e\u96c6\uff0c\u91c7\u7528\u9886\u57df\u611f\u77e5\u76ee\u6807\u548c\u6781\u503c\u7406\u8bba\u6307\u5bfc\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u6a21\u578b\u5728\u591a\u4e2aPM\u53d8\u91cf\uff08PM1\u3001PM2.5\u3001PM10\uff09\u7684\u9884\u6d4b\u4fdd\u771f\u5ea6\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u6781\u7aef\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u4e0d\u5f71\u54cd\u5168\u5c40\u51c6\u786e\u6027\u3002", "conclusion": "SynCast\u4e3a\u4e0b\u4e00\u4ee3\u7a7a\u6c14\u8d28\u91cf\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u652f\u6301\u8106\u5f31\u5730\u533a\u7684\u6c14\u5019\u5065\u5eb7\u98ce\u9669\u7f13\u89e3\u3002"}}
{"id": "2510.23992", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23992", "abs": "https://arxiv.org/abs/2510.23992", "authors": ["Yuxiao Wen", "Yanjun Han", "Zhengyuan Zhou"], "title": "Optimal Arm Elimination Algorithms for Combinatorial Bandits", "comment": null, "summary": "Combinatorial bandits extend the classical bandit framework to settings where\nthe learner selects multiple arms in each round, motivated by applications such\nas online recommendation and assortment optimization. While extensions of upper\nconfidence bound (UCB) algorithms arise naturally in this context, adapting arm\nelimination methods has proved more challenging. We introduce a novel\nelimination scheme that partitions arms into three categories (confirmed,\nactive, and eliminated), and incorporates explicit exploration to update these\nsets. We demonstrate the efficacy of our algorithm in two settings: the\ncombinatorial multi-armed bandit with general graph feedback, and the\ncombinatorial linear contextual bandit. In both cases, our approach achieves\nnear-optimal regret, whereas UCB-based methods can provably fail due to\ninsufficient explicit exploration. Matching lower bounds are also provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d88\u9664\u7b97\u6cd5\uff0c\u7528\u4e8e\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u81c2\u5206\u4e3a\u786e\u8ba4\u3001\u6d3b\u8dc3\u548c\u6d88\u9664\u4e09\u7c7b\uff0c\u5e76\u5f15\u5165\u663e\u5f0f\u63a2\u7d22\u6765\u66f4\u65b0\u8fd9\u4e9b\u96c6\u5408\u3002\u8be5\u65b9\u6cd5\u5728\u56fe\u53cd\u9988\u548c\u7ebf\u6027\u4e0a\u4e0b\u6587\u7ec4\u5408\u8001\u864e\u673a\u4e2d\u5747\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u9057\u61be\u754c\u3002", "motivation": "\u7ec4\u5408\u8001\u864e\u673a\u6269\u5c55\u4e86\u7ecf\u5178\u8001\u864e\u673a\u6846\u67b6\uff0c\u4f7f\u5b66\u4e60\u8005\u5728\u6bcf\u8f6e\u9009\u62e9\u591a\u4e2a\u81c2\uff0c\u9002\u7528\u4e8e\u5728\u7ebf\u63a8\u8350\u548c\u5206\u7c7b\u4f18\u5316\u7b49\u5e94\u7528\u3002\u867d\u7136UCB\u7b97\u6cd5\u81ea\u7136\u6269\u5c55\u5230\u6b64\u573a\u666f\uff0c\u4f46\u81c2\u6d88\u9664\u65b9\u6cd5\u7684\u9002\u5e94\u66f4\u5177\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165\u65b0\u9896\u7684\u6d88\u9664\u65b9\u6848\uff0c\u5c06\u81c2\u5206\u4e3a\u786e\u8ba4\u3001\u6d3b\u8dc3\u548c\u6d88\u9664\u4e09\u7c7b\uff0c\u5e76\u52a0\u5165\u663e\u5f0f\u63a2\u7d22\u6765\u66f4\u65b0\u8fd9\u4e9b\u96c6\u5408\u3002\u5e94\u7528\u4e8e\u56fe\u53cd\u9988\u7ec4\u5408\u8001\u864e\u673a\u548c\u7ebf\u6027\u4e0a\u4e0b\u6587\u7ec4\u5408\u8001\u864e\u673a\u4e24\u4e2a\u573a\u666f\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u573a\u666f\u4e2d\u5747\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u9057\u61be\u754c\uff0c\u800c\u57fa\u4e8eUCB\u7684\u65b9\u6cd5\u7531\u4e8e\u7f3a\u4e4f\u8db3\u591f\u7684\u663e\u5f0f\u63a2\u7d22\u53ef\u80fd\u5931\u8d25\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u5339\u914d\u7684\u4e0b\u754c\u8bc1\u660e\u3002", "conclusion": "\u63d0\u51fa\u7684\u6d88\u9664\u7b97\u6cd5\u5728\u7ec4\u5408\u8001\u864e\u673a\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u514b\u670d\u4e86UCB\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7ec4\u5408\u8001\u864e\u673a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23994", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23994", "abs": "https://arxiv.org/abs/2510.23994", "authors": ["Geoffery Agorku", "Sarah Hernandez", "Hayley Hames", "Cade Wagner"], "title": "Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory Derived Features: Proof of Concept", "comment": null, "summary": "Accurate, real-time estimation of barge quantity on inland waterways remains\na critical challenge due to the non-self-propelled nature of barges and the\nlimitations of existing monitoring systems. This study introduces a novel\nmethod to use Automatic Identification System (AIS) vessel tracking data to\npredict the number of barges in tow using Machine Learning (ML). To train and\ntest the model, barge instances were manually annotated from satellite scenes\nacross the Lower Mississippi River. Labeled images were matched to AIS vessel\ntracks using a spatiotemporal matching procedure. A comprehensive set of 30\nAIS-derived features capturing vessel geometry, dynamic movement, and\ntrajectory patterns were created and evaluated using Recursive Feature\nElimination (RFE) to identify the most predictive variables. Six regression\nmodels, including ensemble, kernel-based, and generalized linear approaches,\nwere trained and evaluated. The Poisson Regressor model yielded the best\nperformance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of\nthe 30 features. The feature importance analysis revealed that metrics\ncapturing vessel maneuverability such as course entropy, speed variability and\ntrip length were most predictive of barge count. The proposed approach provides\na scalable, readily implementable method for enhancing Maritime Domain\nAwareness (MDA), with strong potential applications in lock scheduling, port\nmanagement, and freight planning. Future work will expand the proof of concept\npresented here to explore model transferability to other inland rivers with\ndiffering operational and environmental conditions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528AIS\u6570\u636e\u548c\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u5185\u6cb3\u9a73\u8239\u6570\u91cf\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc730\u4e2aAIS\u7279\u5f81\u548c6\u79cd\u56de\u5f52\u6a21\u578b\uff0cPoisson\u56de\u5f52\u5668\u8868\u73b0\u6700\u4f73\uff0cMAE\u4e3a1.92\u8258\u9a73\u8239\u3002", "motivation": "\u7531\u4e8e\u9a73\u8239\u7684\u975e\u81ea\u822a\u7279\u6027\u548c\u73b0\u6709\u76d1\u6d4b\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u51c6\u786e\u5b9e\u65f6\u4f30\u8ba1\u5185\u6cb3\u822a\u9053\u4e0a\u7684\u9a73\u8239\u6570\u91cf\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u4f7f\u7528AIS\u8239\u8236\u8ddf\u8e2a\u6570\u636e\uff0c\u901a\u8fc7\u65f6\u7a7a\u5339\u914d\u7a0b\u5e8f\u5c06\u536b\u661f\u56fe\u50cf\u4e2d\u624b\u52a8\u6807\u6ce8\u7684\u9a73\u8239\u5b9e\u4f8b\u4e0eAIS\u8f68\u8ff9\u5339\u914d\uff0c\u521b\u5efa30\u4e2aAIS\u884d\u751f\u7279\u5f81\uff0c\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664\u8bc4\u4f30\u7279\u5f81\u91cd\u8981\u6027\uff0c\u8bad\u7ec36\u79cd\u56de\u5f52\u6a21\u578b\u3002", "result": "Poisson\u56de\u5f52\u5668\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f7f\u752830\u4e2a\u7279\u5f81\u4e2d\u768412\u4e2a\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a1.92\u8258\u9a73\u8239\u3002\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u663e\u793a\uff0c\u6355\u83b7\u8239\u8236\u673a\u52a8\u6027\u7684\u6307\u6807\u5982\u822a\u5411\u71b5\u3001\u901f\u5ea6\u53d8\u5f02\u6027\u548c\u884c\u7a0b\u957f\u5ea6\u6700\u80fd\u9884\u6d4b\u9a73\u8239\u6570\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u589e\u5f3a\u6d77\u4e8b\u9886\u57df\u611f\u77e5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6613\u4e8e\u5b9e\u65bd\u7684\u65b9\u6cd5\uff0c\u5728\u8239\u95f8\u8c03\u5ea6\u3001\u6e2f\u53e3\u7ba1\u7406\u548c\u8d27\u8fd0\u89c4\u5212\u65b9\u9762\u5177\u6709\u5f3a\u5927\u5e94\u7528\u6f5c\u529b\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u6269\u5c55\u5230\u5176\u4ed6\u5185\u6cb3\u6cb3\u6d41\u7684\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\u7814\u7a76\u3002"}}
{"id": "2510.24027", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24027", "abs": "https://arxiv.org/abs/2510.24027", "authors": ["Zibo Liu", "Zhe Jiang", "Zelin Xu", "Tingsong Xiao", "Yupu Zhang", "Zhengkun Xiao", "Haibo Wang", "Shigang Chen"], "title": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables", "comment": "In submission", "summary": "Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series\nof $n$ spatially distributed variables in a period of recent past to forecast\ntheir values in a period of near future. It has important applications in\nspatio-temporal sensing forecast such as road traffic prediction and air\npollution prediction. Recent papers have addressed a practical problem of\nmissing variables in the model input, which arises in the sensing applications\nwhere the number $m$ of sensors is far less than the number $n$ of locations to\nbe monitored, due to budget constraints. We observe that the state of the art\nassumes that the $m$ variables (i.e., locations with sensors) in the model\ninput are pre-determined and the important problem of how to choose the $m$\nvariables in the input has never been studied. This paper fills the gap by\nstudying a new problem of STMF with chosen variables, which optimally selects\n$m$-out-of-$n$ variables for the model input in order to maximize the forecast\naccuracy. We propose a unified framework that jointly performs variable\nselection and model optimization for both forecast accuracy and model\nefficiency. It consists of three novel technical components: (1) masked\nvariable-parameter pruning, which progressively prunes less informative\nvariables and attention parameters through quantile-based masking; (2)\nprioritized variable-parameter replay, which replays low-loss past samples to\npreserve learned knowledge for model stability; (3) dynamic extrapolation\nmechanism, which propagates information from variables selected for the input\nto all other variables via learnable spatial embeddings and adjacency\ninformation. Experiments on five real-world datasets show that our work\nsignificantly outperforms the state-of-the-art baselines in both accuracy and\nefficiency, demonstrating the effectiveness of joint variable selection and\nmodel optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u7a7a\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\u2014\u2014\u9009\u62e9\u53d8\u91cf\u9884\u6d4b\uff0c\u901a\u8fc7\u4f18\u5316\u9009\u62e9m\u4e2a\u53d8\u91cf\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\u6765\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u5408\u53d8\u91cf\u9009\u62e9\u548c\u6a21\u578b\u4f18\u5316\u7684\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5047\u8bbe\u8f93\u5165\u53d8\u91cf\u662f\u9884\u5148\u786e\u5b9a\u7684\uff0c\u4f46\u5982\u4f55\u9009\u62e9\u6700\u4f18\u7684m\u4e2a\u53d8\u91cf\u4f5c\u4e3a\u8f93\u5165\u4ece\u672a\u88ab\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u89e3\u51b3\u9884\u7b97\u7ea6\u675f\u4e0b\u5982\u4f55\u9009\u62e9\u6700\u4f18\u4f20\u611f\u5668\u4f4d\u7f6e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u5305\u542b\u4e09\u4e2a\u6280\u672f\u7ec4\u4ef6\u7684\u7edf\u4e00\u6846\u67b6\uff1a(1) \u63a9\u7801\u53d8\u91cf\u53c2\u6570\u526a\u679d\uff0c\u901a\u8fc7\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u63a9\u7801\u9010\u6b65\u526a\u679d\u4fe1\u606f\u91cf\u8f83\u5c11\u7684\u53d8\u91cf\u548c\u6ce8\u610f\u529b\u53c2\u6570\uff1b(2) \u4f18\u5148\u53d8\u91cf\u53c2\u6570\u56de\u653e\uff0c\u56de\u653e\u4f4e\u635f\u5931\u5386\u53f2\u6837\u672c\u4ee5\u4fdd\u6301\u6a21\u578b\u7a33\u5b9a\u6027\uff1b(3) \u52a8\u6001\u5916\u63a8\u673a\u5236\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7a7a\u95f4\u5d4c\u5165\u548c\u90bb\u63a5\u4fe1\u606f\u5c06\u4fe1\u606f\u4ece\u8f93\u5165\u53d8\u91cf\u4f20\u64ad\u5230\u6240\u6709\u5176\u4ed6\u53d8\u91cf\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8054\u5408\u53d8\u91cf\u9009\u62e9\u548c\u6a21\u578b\u4f18\u5316\u7684\u65b9\u6cd5\u5728\u65f6\u7a7a\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u6a21\u578b\u6548\u7387\u3002"}}
{"id": "2510.24035", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24035", "abs": "https://arxiv.org/abs/2510.24035", "authors": ["Xinqi Li", "Yiqun Liu", "Shan Jiang", "Enrong Zheng", "Huaijin Zheng", "Wenhao Dai", "Haodong Deng", "Dianhai Yu", "Yanjun Ma"], "title": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research", "comment": null, "summary": "We introduce GraphNet, a dataset of 2.7K real-world deep learning\ncomputational graphs with rich metadata, spanning six major task categories\nacross multiple deep learning frameworks. To evaluate tensor compiler\nperformance on these samples, we propose the benchmark metric Speedup Score\nS(t), which jointly considers runtime speedup and execution correctness under\ntunable tolerance levels, offering a reliable measure of general optimization\ncapability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),\nwhich incorporates error information and helps compiler developers identify key\nperformance bottlenecks. In this report, we benchmark the default tensor\ncompilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer\nvision (CV) and natural language processing (NLP) samples to demonstrate the\npracticality of GraphNet. The full construction pipeline with graph extraction\nand compiler evaluation tools is available at\nhttps://github.com/PaddlePaddle/GraphNet .", "AI": {"tldr": "GraphNet\u662f\u4e00\u4e2a\u5305\u542b2700\u4e2a\u771f\u5b9e\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u56fe\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d66\u4e2a\u4e3b\u8981\u4efb\u52a1\u7c7b\u522b\u548c\u591a\u79cd\u6846\u67b6\u3002\u63d0\u51fa\u4e86Speedup Score S(t)\u548cError-aware Speedup Score ES(t)\u4e24\u4e2a\u57fa\u51c6\u6307\u6807\u6765\u8bc4\u4f30\u5f20\u91cf\u7f16\u8bd1\u5668\u6027\u80fd\uff0c\u5e76\u5728CV\u548cNLP\u6837\u672c\u4e0a\u6d4b\u8bd5\u4e86CINN\u548cTorchInductor\u7f16\u8bd1\u5668\u3002", "motivation": "\u73b0\u6709\u5f20\u91cf\u7f16\u8bd1\u5668\u8bc4\u4f30\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u8ba1\u7b97\u56fe\u6570\u636e\u96c6\u548c\u53ef\u9760\u7684\u6027\u80fd\u5ea6\u91cf\u6807\u51c6\uff0c\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u7f16\u8bd1\u5668\u4f18\u5316\u80fd\u529b\u3002", "method": "\u6784\u5efaGraphNet\u6570\u636e\u96c6\uff0c\u5305\u542b2700\u4e2a\u771f\u5b9e\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u56fe\uff1b\u63d0\u51faSpeedup Score S(t)\u6307\u6807\u7efc\u5408\u8003\u8651\u8fd0\u884c\u52a0\u901f\u6bd4\u548c\u6267\u884c\u6b63\u786e\u6027\uff1b\u6269\u5c55\u4e3aES(t)\u6307\u6807\u52a0\u5165\u9519\u8bef\u4fe1\u606f\uff1b\u5728CV\u548cNLP\u6837\u672c\u4e0a\u6d4b\u8bd5CINN\u548cTorchInductor\u7f16\u8bd1\u5668\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86GraphNet\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e86\u6709\u6548\u7684\u6027\u80fd\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u7f16\u8bd1\u5668\u4e0a\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u8be5\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "GraphNet\u4e3a\u5f20\u91cf\u7f16\u8bd1\u5668\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\uff0c\u63d0\u51fa\u7684S(t)\u548cES(t)\u6307\u6807\u80fd\u53ef\u9760\u8861\u91cf\u7f16\u8bd1\u5668\u4f18\u5316\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u8bc6\u522b\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2510.24043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24043", "abs": "https://arxiv.org/abs/2510.24043", "authors": ["Akira Tamamori"], "title": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection", "comment": "10 pages, 4 figures; submitted to The IEICE Transactions on\n  Information and Systems", "summary": "This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection\nframework that overcomes the coexisting limitations of conventional\nprojection-based methods: their reliance on a fixed statistical metric and\ntheir assumption of a single data structure. Our framework uniquely synthesizes\nthree key concepts: (1) a generalized loss-based outlyingness measure (PLO)\nthat replaces the fixed metric with flexible, adaptive loss functions like our\nproposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear\ndata structures; and (3) a subsequent local clustering stage to handle\nmulti-modal distributions. Comprehensive 5-fold cross-validation experiments on\n10 benchmark datasets, with automated hyperparameter optimization, demonstrate\nthat Two-Stage LKPLO achieves state-of-the-art performance. It significantly\noutperforms strong baselines on datasets with challenging structures where\nexisting methods fail, most notably on multi-cluster data (Optdigits) and\ncomplex, high-dimensional data (Arrhythmia). Furthermore, an ablation study\nempirically confirms that the synergistic combination of both the kernelization\nand localization stages is indispensable for its superior performance. This\nwork contributes a powerful new tool for a significant class of outlier\ndetection problems and underscores the importance of hybrid, multi-stage\narchitectures.", "AI": {"tldr": "Two-Stage LKPLO\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u9636\u6bb5\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5e7f\u4e49\u635f\u5931\u51fd\u6570\u3001\u5168\u5c40\u6838PCA\u548c\u5c40\u90e8\u805a\u7c7b\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6295\u5f71\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7edf\u8ba1\u6307\u6807\u548c\u5047\u8bbe\u5355\u4e00\u6570\u636e\u7ed3\u6784\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6295\u5f71\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7684\u4e24\u5927\u5171\u5b58\u5c40\u9650\uff1a\u4f9d\u8d56\u56fa\u5b9a\u7edf\u8ba1\u6307\u6807\u548c\u5047\u8bbe\u5355\u4e00\u6570\u636e\u7ed3\u6784\uff0c\u8fd9\u4e9b\u9650\u5236\u5bfc\u81f4\u5728\u590d\u6742\u6570\u636e\u7ed3\u6784\u4e0b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u5e7f\u4e49\u635f\u5931\u51fd\u6570PLO\u66ff\u4ee3\u56fa\u5b9a\u6307\u6807\uff1b2) \u5168\u5c40\u6838PCA\u7ebf\u6027\u5316\u975e\u7ebf\u6027\u7ed3\u6784\uff1b3) \u5c40\u90e8\u805a\u7c7b\u5904\u7406\u591a\u6a21\u6001\u5206\u5e03\u3002", "result": "\u572810\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u76845\u6298\u4ea4\u53c9\u9a8c\u8bc1\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7ed3\u6784\u7684\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u591a\u7c07\u6570\u636e\u548c\u590d\u6742\u9ad8\u7ef4\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u91cd\u8981\u7c7b\u522b\u7684\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u5f3a\u5927\u65b0\u5de5\u5177\uff0c\u5e76\u5f3a\u8c03\u4e86\u6df7\u5408\u591a\u9636\u6bb5\u67b6\u6784\u7684\u91cd\u8981\u6027\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u6838\u5316\u548c\u5c40\u90e8\u5316\u9636\u6bb5\u7684\u534f\u540c\u7ec4\u5408\u5bf9\u4f18\u5f02\u6027\u80fd\u4e0d\u53ef\u6216\u7f3a\u3002"}}
{"id": "2510.24044", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24044", "abs": "https://arxiv.org/abs/2510.24044", "authors": ["Hui Sun", "Zheng Xie", "Hao-Yuan He", "Ming Li"], "title": "Mitigating Negative Transfer via Reducing Environmental Disagreement", "comment": "13 pages, 5 figures", "summary": "Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a\nlabeled source domain to an unlabeled target domain, addressing the challenge\nof \\emph{domain shift}. Significant domain shifts hinder effective knowledge\ntransfer, leading to \\emph{negative transfer} and deteriorating model\nperformance. Therefore, mitigating negative transfer is essential. This study\nrevisits negative transfer through the lens of causally disentangled learning,\nemphasizing cross-domain discriminative disagreement on non-causal\nenvironmental features as a critical factor. Our theoretical analysis reveals\nthat overreliance on non-causal environmental features as the environment\nevolves can cause discriminative disagreements~(termed \\emph{environmental\ndisagreement}), thereby resulting in negative transfer. To address this, we\npropose Reducing Environmental Disagreement~(RED), which disentangles each\nsample into domain-invariant causal features and domain-specific non-causal\nenvironmental features via adversarially training domain-specific environmental\nfeature extractors in the opposite domains. Subsequently, RED estimates and\nreduces environmental disagreement based on domain-specific non-causal\nenvironmental features. Experimental results confirm that RED effectively\nmitigates negative transfer and achieves state-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u56e0\u679c\u89e3\u8026\u5b66\u4e60\u51cf\u5c11\u73af\u5883\u5206\u6b67\u7684\u65b9\u6cd5\uff08RED\uff09\uff0c\u6765\u89e3\u51b3\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u4e2d\u7684\u8d1f\u8fc1\u79fb\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u5206\u79bb\u56e0\u679c\u7279\u5f81\u548c\u73af\u5883\u7279\u5f81\uff0c\u5e76\u51cf\u5c11\u8de8\u57df\u73af\u5883\u7279\u5f81\u7684\u5206\u6b67\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u9762\u4e34\u57df\u504f\u79fb\u5bfc\u81f4\u7684\u8d1f\u8fc1\u79fb\u95ee\u9898\uff0c\u5373\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002\u7814\u7a76\u53d1\u73b0\u8fc7\u5ea6\u4f9d\u8d56\u975e\u56e0\u679c\u73af\u5883\u7279\u5f81\u4f1a\u5bfc\u81f4\u8de8\u57df\u5224\u522b\u5206\u6b67\uff0c\u8fd9\u662f\u8d1f\u8fc1\u79fb\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u63d0\u51faRED\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u57df\u7279\u5b9a\u73af\u5883\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u5c06\u6837\u672c\u89e3\u8026\u4e3a\u57df\u4e0d\u53d8\u56e0\u679c\u7279\u5f81\u548c\u57df\u7279\u5b9a\u975e\u56e0\u679c\u73af\u5883\u7279\u5f81\uff1b2\uff09\u57fa\u4e8e\u57df\u7279\u5b9a\u975e\u56e0\u679c\u73af\u5883\u7279\u5f81\u4f30\u8ba1\u5e76\u51cf\u5c11\u73af\u5883\u5206\u6b67\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eRED\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u8d1f\u8fc1\u79fb\u95ee\u9898\uff0c\u5e76\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u56e0\u679c\u89e3\u8026\u5b66\u4e60\u51cf\u5c11\u73af\u5883\u5206\u6b67\u662f\u89e3\u51b3\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u4e2d\u8d1f\u8fc1\u79fb\u95ee\u9898\u7684\u6709\u6548\u9014\u5f84\uff0cRED\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.24046", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24046", "abs": "https://arxiv.org/abs/2510.24046", "authors": ["Tu Anh Hoang Nguyen", "Dang Nguyen", "Tri-Nhan Vo", "Thuc Duy Le", "Sunil Gupta"], "title": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning", "comment": null, "summary": "The utility of tabular data for tasks ranging from model training to\nlarge-scale data analysis is often constrained by privacy concerns or\nregulatory hurdles. While existing data generation methods, particularly those\nbased on Generative Adversarial Networks (GANs), have shown promise, they\nfrequently struggle with capturing complex causal relationship, maintaining\ndata utility, and providing provable privacy guarantees suitable for enterprise\ndeployment. We introduce CA-GAN, a novel generative framework specifically\nengineered to address these challenges for real-world tabular datasets. CA-GAN\nutilizes a two-step approach: causal graph extraction to learn a robust,\ncomprehensive causal relationship in the data's manifold, followed by a custom\nConditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates\nexclusively as per the structure of nodes in the causal graph. More\nimportantly, the generator is trained with a new Reinforcement Learning-based\nobjective that aligns the causal graphs constructed from real and fake data,\nensuring the causal awareness in both training and sampling phases. We\ndemonstrate CA-GAN superiority over six SOTA methods across 14 tabular\ndatasets. Our evaluations, focused on core data engineering metrics: causal\npreservation, utility preservation, and privacy preservation. Our method offers\na practical, high-performance solution for data engineers seeking to create\nhigh-quality, privacy-compliant synthetic datasets to benchmark database\nsystems, accelerate software development, and facilitate secure data-driven\nresearch.", "AI": {"tldr": "CA-GAN\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u8868\u683c\u6570\u636e\u8bbe\u8ba1\u7684\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u56fe\u63d0\u53d6\u548c\u6761\u4ef6WGAN-GP\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u5728\u4fdd\u6301\u6570\u636e\u6548\u7528\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\u6355\u83b7\u590d\u6742\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eGAN\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5728\u6355\u83b7\u590d\u6742\u56e0\u679c\u5173\u7cfb\u3001\u4fdd\u6301\u6570\u636e\u6548\u7528\u548c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u9690\u79c1\u4fdd\u8bc1\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u8868\u683c\u6570\u636e\u5728\u6a21\u578b\u8bad\u7ec3\u548c\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u9996\u5148\u63d0\u53d6\u56e0\u679c\u56fe\u5b66\u4e60\u6570\u636e\u6d41\u5f62\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u7136\u540e\u4f7f\u7528\u6761\u4ef6WGAN-GP\u6309\u7167\u56e0\u679c\u56fe\u7ed3\u6784\u751f\u6210\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u5bf9\u9f50\u771f\u5b9e\u548c\u751f\u6210\u6570\u636e\u7684\u56e0\u679c\u56fe\u3002", "result": "\u572814\u4e2a\u8868\u683c\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e6\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u56e0\u679c\u4fdd\u6301\u3001\u6548\u7528\u4fdd\u6301\u548c\u9690\u79c1\u4fdd\u6301\u4e09\u4e2a\u6838\u5fc3\u6570\u636e\u5de5\u7a0b\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "CA-GAN\u4e3a\u6570\u636e\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u3001\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u521b\u5efa\u9ad8\u8d28\u91cf\u3001\u7b26\u5408\u9690\u79c1\u8981\u6c42\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u5e93\u7cfb\u7edf\u3001\u52a0\u901f\u8f6f\u4ef6\u5f00\u53d1\u548c\u4fc3\u8fdb\u5b89\u5168\u7684\u6570\u636e\u9a71\u52a8\u7814\u7a76\u3002"}}
{"id": "2510.24053", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24053", "abs": "https://arxiv.org/abs/2510.24053", "authors": ["Jacob B. Roberts", "Catherine R. Ji", "Isaac Donnell", "Thomas D. Young", "Allison N. Pearson", "Graham A. Hudson", "Leah S. Keiser", "Mia Wesselkamper", "Peter H. Winegar", "Janik Ludwig", "Sarah H. Klass", "Isha V. Sheth", "Ezechinyere C. Ukabiala", "Maria C. T. Astolfi", "Benjamin Eysenbach", "Jay D. Keasling"], "title": "Low-N Protein Activity Optimization with FolDE", "comment": "18 pages, 4 figures. Preprint. Open-source software available at\n  https://github.com/JBEI/foldy", "summary": "Proteins are traditionally optimized through the costly construction and\nmeasurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)\nalleviates that cost by predicting the best improvements and iteratively\ntesting mutants to inform predictions. However, existing ALDE methods face a\ncritical limitation: selecting the highest-predicted mutants in each round\nyields homogeneous training data insufficient for accurate prediction models in\nsubsequent rounds. Here we present FolDE, an ALDE method designed to maximize\nend-of-campaign success. In simulations across 20 protein targets, FolDE\ndiscovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)\nand is 55% more likely to find top 1% mutants. FolDE achieves this primarily\nthrough naturalness-based warm-starting, which augments limited activity\nmeasurements with protein language model outputs to improve activity\nprediction. We also introduce a constant-liar batch selector, which improves\nbatch diversity; this is important in multi-mutation campaigns but had limited\neffect in our benchmarks. The complete workflow is freely available as\nopen-source software, making efficient protein optimization accessible to any\nlaboratory.", "AI": {"tldr": "FolDE\u662f\u4e00\u79cd\u4e3b\u52a8\u5b66\u4e60\u8f85\u52a9\u5b9a\u5411\u8fdb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7136\u6027\u9884\u70ed\u542f\u52a8\u548c\u6052\u5b9a\u8c0e\u8a00\u6279\u91cf\u9009\u62e9\u5668\uff0c\u5728\u86cb\u767d\u8d28\u4f18\u5316\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d1\u73b0\u66f4\u591a\u4f18\u8d28\u7a81\u53d8\u4f53\u3002", "motivation": "\u4f20\u7edf\u86cb\u767d\u8d28\u4f18\u5316\u65b9\u6cd5\u6210\u672c\u9ad8\u6602\uff0c\u73b0\u6709\u4e3b\u52a8\u5b66\u4e60\u8f85\u52a9\u5b9a\u5411\u8fdb\u5316\u65b9\u6cd5\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u540c\u8d28\u5316\u95ee\u9898\uff0c\u5bfc\u81f4\u540e\u7eed\u9884\u6d4b\u6a21\u578b\u4e0d\u51c6\u786e\u3002", "method": "FolDE\u91c7\u7528\u81ea\u7136\u6027\u9884\u70ed\u542f\u52a8\uff08\u5229\u7528\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u589e\u5f3a\u6709\u9650\u6d3b\u6027\u6d4b\u91cf\uff09\u548c\u6052\u5b9a\u8c0e\u8a00\u6279\u91cf\u9009\u62e9\u5668\uff08\u63d0\u9ad8\u6279\u91cf\u591a\u6837\u6027\uff09\u6765\u6700\u5927\u5316\u4f18\u5316\u6548\u679c\u3002", "result": "\u572820\u4e2a\u86cb\u767d\u8d28\u9776\u70b9\u7684\u6a21\u62df\u4e2d\uff0cFolDE\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u591a\u53d1\u73b023%\u7684\u524d10%\u7a81\u53d8\u4f53\uff0c\u627e\u5230\u524d1%\u7a81\u53d8\u4f53\u7684\u53ef\u80fd\u6027\u9ad855%\u3002", "conclusion": "FolDE\u901a\u8fc7\u6539\u8fdb\u7684\u9884\u70ed\u542f\u52a8\u548c\u6279\u91cf\u9009\u62e9\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u86cb\u767d\u8d28\u4f18\u5316\u6548\u7387\uff0c\u4e14\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u53ef\u4f9b\u4efb\u4f55\u5b9e\u9a8c\u5ba4\u4f7f\u7528\u3002"}}
{"id": "2510.24088", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24088", "abs": "https://arxiv.org/abs/2510.24088", "authors": ["Moongyu Jeon", "Sangwoo Shin", "Dongjae Jeon", "Albert No"], "title": "Information-Theoretic Discrete Diffusion", "comment": "Accepted at NeurIPS 2025", "summary": "We present an information-theoretic framework for discrete diffusion models\nthat yields principled estimators of log-likelihood using score-matching\nlosses. Inspired by the I-MMSE identity for the Gaussian setup, we derive\nanalogous results for the discrete setting. Specifically, we introduce the\nInformation-Minimum Denoising Score Entropy (I-MDSE) relation, which links\nmutual information between data and its diffused version to the minimum\ndenoising score entropy (DSE) loss. We extend this theory to masked diffusion\nand establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)\nrelation, connecting cross-entropy losses to mutual information in discrete\nmasked processes. These results provide a time-integral decomposition of the\nlog-likelihood of the data in terms of optimal score-based losses, showing that\ncommonly used losses such as DSE and DCE are not merely variational bounds but\ntight and principled estimators of log-likelihood. The I-MDCE decomposition\nfurther enables practical extensions, including time-free formula, conditional\nlikelihood estimation in prompt-response tasks, and coupled Monte Carlo\nestimation of likelihood ratios. Experiments on synthetic and real-world data\nconfirm the accuracy, variance stability, and utility of our estimators. The\ncode is publicly available at https://github.com/Dongjae0324/infodis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6570\u5339\u914d\u635f\u5931\u6784\u5efa\u5bf9\u6570\u4f3c\u7136\u7684\u6709\u539f\u5219\u4f30\u8ba1\u5668\u3002\u63a8\u5bfc\u4e86\u79bb\u6563\u8bbe\u7f6e\u4e0b\u7684\u4fe1\u606f-\u6700\u5c0f\u53bb\u566a\u5206\u6570\u71b5\u5173\u7cfb\uff0c\u5c06\u4e92\u4fe1\u606f\u4e0e\u6700\u5c0f\u53bb\u566a\u5206\u6570\u71b5\u635f\u5931\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u6269\u5c55\u5230\u63a9\u7801\u6269\u6563\u8fc7\u7a0b\u3002", "motivation": "\u53d7\u9ad8\u65af\u8bbe\u7f6e\u4e2dI-MMSE\u6052\u7b49\u5f0f\u7684\u542f\u53d1\uff0c\u5e0c\u671b\u5728\u79bb\u6563\u8bbe\u7f6e\u4e2d\u5efa\u7acb\u7c7b\u4f3c\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u79bb\u6563\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u652f\u6491\uff0c\u8bc1\u660e\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\u4e0d\u4ec5\u662f\u53d8\u5206\u4e0b\u754c\uff0c\u800c\u662f\u7d27\u81f4\u7684\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u5668\u3002", "method": "\u5f15\u5165\u4fe1\u606f-\u6700\u5c0f\u53bb\u566a\u5206\u6570\u71b5\u5173\u7cfb\uff0c\u5c06\u6570\u636e\u4e0e\u5176\u6269\u6563\u7248\u672c\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u4e0e\u6700\u5c0f\u53bb\u566a\u5206\u6570\u71b5\u635f\u5931\u8054\u7cfb\u8d77\u6765\u3002\u6269\u5c55\u5230\u63a9\u7801\u6269\u6563\uff0c\u5efa\u7acb\u4fe1\u606f-\u6700\u5c0f\u53bb\u566a\u4ea4\u53c9\u71b5\u5173\u7cfb\u3002\u63d0\u4f9b\u4e86\u5bf9\u6570\u4f3c\u7136\u7684\u65f6\u95f4\u79ef\u5206\u5206\u89e3\u3002", "result": "\u5b9e\u9a8c\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u5668\u7684\u51c6\u786e\u6027\u3001\u65b9\u5dee\u7a33\u5b9a\u6027\u548c\u5b9e\u7528\u6027\u3002\u5b9e\u73b0\u4e86\u65f6\u95f4\u65e0\u5173\u516c\u5f0f\u3001\u63d0\u793a-\u54cd\u5e94\u4efb\u52a1\u4e2d\u7684\u6761\u4ef6\u4f3c\u7136\u4f30\u8ba1\u4ee5\u53ca\u4f3c\u7136\u6bd4\u7684\u8026\u5408\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u79bb\u6563\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u4fe1\u606f\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5e38\u7528\u635f\u5931\u51fd\u6570\u662f\u6709\u539f\u5219\u7684\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u5668\uff0c\u5e76\u652f\u6301\u591a\u79cd\u5b9e\u9645\u6269\u5c55\u5e94\u7528\u3002"}}
{"id": "2510.24095", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24095", "abs": "https://arxiv.org/abs/2510.24095", "authors": ["Vedant Gupta", "Haotian Fu", "Calvin Luo", "Yiding Jiang", "George Konidaris"], "title": "Learning Parameterized Skills from Demonstrations", "comment": "Neurips 2025", "summary": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location.", "AI": {"tldr": "DEPS\u662f\u4e00\u79cd\u7aef\u5230\u7aef\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u53d1\u73b0\u53c2\u6570\u5316\u6280\u80fd\u3002\u8be5\u65b9\u6cd5\u8054\u5408\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u7b56\u7565\u548c\u5143\u7b56\u7565\uff0c\u901a\u8fc7\u65f6\u95f4\u53d8\u5206\u63a8\u7406\u548c\u4fe1\u606f\u8bba\u6b63\u5219\u5316\u89e3\u51b3\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u7684\u9000\u5316\u95ee\u9898\uff0c\u786e\u4fdd\u5b66\u5230\u7684\u6280\u80fd\u5177\u6709\u65f6\u95f4\u6269\u5c55\u6027\u3001\u8bed\u4e49\u610f\u4e49\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4ece\u591a\u4efb\u52a1\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\uff0c\u4ee5\u663e\u8457\u63d0\u9ad8\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u53d8\u5206\u63a8\u7406\u548c\u4fe1\u606f\u8bba\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u8054\u5408\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u7b56\u7565\u548c\u5143\u7b56\u7565\uff0c\u5143\u7b56\u7565\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u9009\u62e9\u9002\u5f53\u7684\u79bb\u6563\u6280\u80fd\u548c\u8fde\u7eed\u53c2\u6570\u3002", "result": "\u5728LIBERO\u548cMetaWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDEPS\u4f18\u4e8e\u591a\u4efb\u52a1\u548c\u6280\u80fd\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u53c2\u6570\u5316\u6280\u80fd\uff0c\u5982\u7269\u4f53\u6293\u53d6\u6280\u80fd\uff0c\u5176\u8fde\u7eed\u53c2\u6570\u5b9a\u4e49\u6293\u53d6\u4f4d\u7f6e\u3002", "conclusion": "\u4ece\u591a\u4efb\u52a1\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u80fd\u663e\u8457\u6539\u5584\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u6cdb\u5316\u6027\u80fd\uff0cDEPS\u65b9\u6cd5\u80fd\u53d1\u73b0\u5177\u6709\u8bed\u4e49\u610f\u4e49\u4e14\u53ef\u89e3\u91ca\u7684\u53c2\u6570\u5316\u6280\u80fd\u3002"}}
{"id": "2510.24120", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24120", "abs": "https://arxiv.org/abs/2510.24120", "authors": ["Ziyu Liu", "Yijing Liu", "Jianfei Yuan", "Minzhi Yan", "Le Yue", "Honghui Xiong", "Yi Yang"], "title": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation", "comment": null, "summary": "Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance\nretrieval in Large Language Model (LLM)-based question answering. It is\nespecially beneficial in domains such as biomedicine, law, and political\nscience, where effective retrieval often involves multi-hop reasoning over\nproprietary documents. However, these methods demand numerous LLM calls to\nextract entities and relations from text chunks, incurring prohibitive costs at\nscale. Through a carefully designed ablation study, we observe that certain\nwords (termed concepts) and their associated documents are more important.\nBased on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its\ncore comprises a chunk selection method and an LLM-independent concept graph.\nThe former selects salient document chunks to reduce KG construction costs; the\nlatter closes knowledge gaps introduced by chunk selection at zero cost.\nEvaluations on multiple real-world datasets show that G2ConS outperforms all\nbaselines in construction cost, retrieval effectiveness, and answering quality.", "AI": {"tldr": "\u63d0\u51faGraph-Guided Concept Selection (G2ConS)\u65b9\u6cd5\uff0c\u901a\u8fc7\u6982\u5ff5\u9009\u62e9\u548c\u6982\u5ff5\u56fe\u6765\u964d\u4f4e\u57fa\u4e8e\u56fe\u7684RAG\u7cfb\u7edf\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u7d22\u6548\u679c\u3002", "motivation": "\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\u5728\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u65f6\u9700\u8981\u5927\u91cfLLM\u8c03\u7528\u6765\u63d0\u53d6\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u5bfc\u81f4\u6210\u672c\u8fc7\u9ad8\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u591a\u8df3\u63a8\u7406\u7684\u9886\u57df\u5982\u751f\u7269\u533b\u5b66\u3001\u6cd5\u5f8b\u548c\u653f\u6cbb\u79d1\u5b66\u4e2d\u3002", "method": "G2ConS\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u6587\u6863\u5757\u9009\u62e9\u65b9\u6cd5\u548c\u72ec\u7acb\u4e8eLLM\u7684\u6982\u5ff5\u56fe\u3002\u524d\u8005\u9009\u62e9\u91cd\u8981\u6587\u6863\u5757\u6765\u964d\u4f4eKG\u6784\u5efa\u6210\u672c\uff0c\u540e\u8005\u5728\u96f6\u6210\u672c\u4e0b\u586b\u8865\u56e0\u5757\u9009\u62e9\u9020\u6210\u7684\u77e5\u8bc6\u7f3a\u53e3\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cG2ConS\u5728\u6784\u5efa\u6210\u672c\u3001\u68c0\u7d22\u6548\u679c\u548c\u56de\u7b54\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "G2ConS\u901a\u8fc7\u6982\u5ff5\u9009\u62e9\u548c\u6982\u5ff5\u56fe\u7684\u521b\u65b0\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u4e8e\u56feRAG\u7cfb\u7edf\u7684\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f18\u8d8a\u7684\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2510.24160", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24160", "abs": "https://arxiv.org/abs/2510.24160", "authors": ["Aiqing Zhu", "Beatrice W. Soh", "Grigorios A. Pavliotis", "Qianxiao Li"], "title": "Identifiable learning of dissipative dynamics", "comment": null, "summary": "Complex dissipative systems appear across science and engineering, from\npolymers and active matter to learning algorithms. These systems operate far\nfrom equilibrium, where energy dissipation and time irreversibility are key to\ntheir behavior, but are difficult to quantify from data. Learning accurate and\ninterpretable models of such dynamics remains a major challenge: the models\nmust be expressive enough to describe diverse processes, yet constrained enough\nto remain physically meaningful and mathematically identifiable. Here, we\nintroduce I-OnsagerNet, a neural framework that learns dissipative stochastic\ndynamics directly from trajectories while ensuring both interpretability and\nuniqueness. I-OnsagerNet extends the Onsager principle to guarantee that the\nlearned potential is obtained from the stationary density and that the drift\ndecomposes cleanly into time-reversible and time-irreversible components, as\ndictated by the Helmholtz decomposition. Our approach enables us to calculate\nthe entropy production and to quantify irreversibility, offering a principled\nway to detect and quantify deviations from equilibrium. Applications to polymer\nstretching in elongational flow and to stochastic gradient Langevin dynamics\nreveal new insights, including super-linear scaling of barrier heights and\nsub-linear scaling of entropy production rates with the strain rate, and the\nsuppression of irreversibility with increasing batch size. I-OnsagerNet thus\nestablishes a general, data-driven framework for discovering and interpreting\nnon-equilibrium dynamics.", "AI": {"tldr": "I-OnsagerNet\u662f\u4e00\u4e2a\u795e\u7ecf\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u8f68\u8ff9\u6570\u636e\u4e2d\u5b66\u4e60\u8017\u6563\u968f\u673a\u52a8\u529b\u5b66\uff0c\u540c\u65f6\u786e\u4fdd\u53ef\u89e3\u91ca\u6027\u548c\u552f\u4e00\u6027\u3002\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86Onsager\u539f\u7406\uff0c\u80fd\u591f\u8ba1\u7b97\u71b5\u4ea7\u751f\u5e76\u91cf\u5316\u4e0d\u53ef\u9006\u6027\u3002", "motivation": "\u590d\u6742\u8017\u6563\u7cfb\u7edf\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46\u8fdc\u79bb\u5e73\u8861\u6001\u4e0b\u7684\u80fd\u91cf\u8017\u6563\u548c\u65f6\u95f4\u4e0d\u53ef\u9006\u6027\u96be\u4ee5\u4ece\u6570\u636e\u4e2d\u91cf\u5316\u3002\u5b66\u4e60\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u52a8\u529b\u5b66\u6a21\u578b\u4ecd\u7136\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u3002", "method": "I-OnsagerNet\u6269\u5c55Onsager\u539f\u7406\uff0c\u786e\u4fdd\u5b66\u4e60\u5230\u7684\u52bf\u80fd\u4ece\u7a33\u6001\u5bc6\u5ea6\u83b7\u5f97\uff0c\u6f02\u79fb\u9879\u5e72\u51c0\u5730\u5206\u89e3\u4e3a\u65f6\u95f4\u53ef\u9006\u548c\u65f6\u95f4\u4e0d\u53ef\u9006\u5206\u91cf\uff0c\u9075\u5faaHelmholtz\u5206\u89e3\u3002", "result": "\u5e94\u7528\u4e8e\u805a\u5408\u7269\u62c9\u4f38\u548c\u968f\u673a\u68af\u5ea6Langevin\u52a8\u529b\u5b66\uff0c\u63ed\u793a\u4e86\u65b0\u7684\u89c1\u89e3\uff1a\u52bf\u5792\u9ad8\u5ea6\u7684\u8d85\u7ebf\u6027\u7f29\u653e\u3001\u71b5\u4ea7\u751f\u7387\u7684\u4e9a\u7ebf\u6027\u7f29\u653e\uff0c\u4ee5\u53ca\u968f\u7740\u6279\u91cf\u5927\u5c0f\u589e\u52a0\u4e0d\u53ef\u9006\u6027\u88ab\u6291\u5236\u3002", "conclusion": "I-OnsagerNet\u5efa\u7acb\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u548c\u89e3\u91ca\u975e\u5e73\u8861\u52a8\u529b\u5b66\u3002"}}
{"id": "2510.24173", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.24173", "abs": "https://arxiv.org/abs/2510.24173", "authors": ["Yiheng Du", "Aditi S. Krishnapriyan"], "title": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale", "comment": "NeurIPS 2025", "summary": "Computationally resolving turbulence remains a central challenge in fluid\ndynamics due to its multi-scale interactions. Fully resolving large-scale\nturbulence through direct numerical simulation (DNS) is computationally\nprohibitive, motivating data-driven machine learning alternatives. In this\nwork, we propose EddyFormer, a Transformer-based spectral-element (SEM)\narchitecture for large-scale turbulence simulation that combines the accuracy\nof spectral methods with the scalability of the attention mechanism. We\nintroduce an SEM tokenization that decomposes the flow into grid-scale and\nsubgrid-scale components, enabling capture of both local and global features.\nWe create a new three-dimensional isotropic turbulence dataset and train\nEddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x\nspeedup over DNS. When applied to unseen domains up to 4x larger than in\ntraining, EddyFormer preserves accuracy on physics-invariant metrics-energy\nspectra, correlation functions, and structure functions-showing domain\ngeneralization. On The Well benchmark suite of diverse turbulent flows,\nEddyFormer resolves cases where prior ML models fail to converge, accurately\nreproducing complex dynamics across a wide range of physical conditions.", "AI": {"tldr": "EddyFormer\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u8c31\u5143\u67b6\u6784\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u6e4d\u6d41\u6a21\u62df\uff0c\u7ed3\u5408\u4e86\u8c31\u65b9\u6cd5\u7684\u7cbe\u5ea6\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5728256^3\u5206\u8fa8\u7387\u4e0b\u8fbe\u5230DNS\u7ea7\u522b\u7cbe\u5ea6\uff0c\u901f\u5ea6\u63d0\u534730\u500d\uff0c\u5e76\u5c55\u793a\u51fa\u826f\u597d\u7684\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7531\u4e8e\u6e4d\u6d41\u7684\u591a\u5c3a\u5ea6\u7279\u6027\uff0c\u5b8c\u5168\u901a\u8fc7\u76f4\u63a5\u6570\u503c\u6a21\u62df(DNS)\u89e3\u6790\u5927\u89c4\u6a21\u6e4d\u6d41\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u6570\u636e\u9a71\u52a8\u7684\u673a\u5668\u5b66\u4e60\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51faEddyFormer\uff0c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u8c31\u5143\u67b6\u6784\uff0c\u5f15\u5165SEM\u6807\u8bb0\u5316\u65b9\u6cd5\u5c06\u6d41\u52a8\u5206\u89e3\u4e3a\u7f51\u683c\u5c3a\u5ea6\u548c\u4e9a\u7f51\u683c\u5c3a\u5ea6\u5206\u91cf\uff0c\u7ed3\u5408\u8c31\u65b9\u6cd5\u7684\u7cbe\u5ea6\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728256^3\u5206\u8fa8\u7387\u4e0b\u8fbe\u5230DNS\u7ea7\u522b\u7cbe\u5ea6\uff0c\u901f\u5ea6\u63d0\u534730\u500d\uff1b\u5728\u672a\u89c1\u57df\u4e0a\u4fdd\u6301\u7269\u7406\u4e0d\u53d8\u6307\u6807\u7684\u51c6\u786e\u6027\uff1b\u5728The Well\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u51c6\u786e\u518d\u73b0\u590d\u6742\u52a8\u529b\u5b66\u3002", "conclusion": "EddyFormer\u6210\u529f\u7ed3\u5408\u4e86\u8c31\u65b9\u6cd5\u7684\u7cbe\u5ea6\u548cTransformer\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u6e4d\u6d41\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.24180", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24180", "abs": "https://arxiv.org/abs/2510.24180", "authors": ["Arpita Kundu", "Joyita Chakraborty", "Anindita Desarkar", "Aritra Sen", "Srushti Anil Patil", "Vishwanathan Raman"], "title": "V-SAT: Video Subtitle Annotation Tool", "comment": null, "summary": "The surge of audiovisual content on streaming platforms and social media has\nheightened the demand for accurate and accessible subtitles. However, existing\nsubtitle generation methods primarily speech-based transcription or OCR-based\nextraction suffer from several shortcomings, including poor synchronization,\nincorrect or harmful text, inconsistent formatting, inappropriate reading\nspeeds, and the inability to adapt to dynamic audio-visual contexts. Current\napproaches often address isolated issues, leaving post-editing as a\nlabor-intensive and time-consuming process. In this paper, we introduce V-SAT\n(Video Subtitle Annotation Tool), a unified framework that automatically\ndetects and corrects a wide range of subtitle quality issues. By combining\nLarge Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,\nand Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from\nboth audio and video. Subtitle quality improved, with the SUBER score reduced\nfrom 9.6 to 3.54 after resolving all language mode issues and F1-scores of\n~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality\nresults, providing the first comprehensive solution for robust subtitle\nannotation.", "AI": {"tldr": "V-SAT\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u89c6\u9891\u5b57\u5e55\u6807\u6ce8\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u3001VLM\u3001\u56fe\u50cf\u5904\u7406\u548cASR\u6280\u672f\uff0c\u81ea\u52a8\u68c0\u6d4b\u548c\u4fee\u6b63\u591a\u79cd\u5b57\u5e55\u8d28\u91cf\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5b57\u5e55\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u5b57\u5e55\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u540c\u6b65\u6027\u5dee\u3001\u6587\u672c\u9519\u8bef\u3001\u683c\u5f0f\u4e0d\u4e00\u81f4\u3001\u9605\u8bfb\u901f\u5ea6\u4e0d\u5f53\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u89e3\u51b3\u5b64\u7acb\u95ee\u9898\uff0c\u5bfc\u81f4\u540e\u671f\u7f16\u8f91\u5de5\u4f5c\u7e41\u91cd\u8017\u65f6\u3002", "method": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u3001\u56fe\u50cf\u5904\u7406\u548c\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\uff0c\u5229\u7528\u97f3\u9891\u548c\u89c6\u9891\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u8fdb\u884c\u5b57\u5e55\u8d28\u91cf\u68c0\u6d4b\u548c\u4fee\u6b63\u3002", "result": "\u5b57\u5e55\u8d28\u91cf\u663e\u8457\u63d0\u5347\uff0cSUBER\u5206\u6570\u4ece9.6\u964d\u81f33.54\uff0c\u56fe\u50cf\u6a21\u5f0f\u95ee\u9898\u7684F1\u5206\u6570\u8fbe\u5230\u7ea60.80\uff0c\u901a\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u786e\u4fdd\u9ad8\u8d28\u91cf\u7ed3\u679c\u3002", "conclusion": "V-SAT\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u7684\u9c81\u68d2\u5b57\u5e55\u6807\u6ce8\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u79cd\u5b57\u5e55\u8d28\u91cf\u95ee\u9898\u3002"}}
{"id": "2510.24200", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.24200", "abs": "https://arxiv.org/abs/2510.24200", "authors": ["Alexander Bakarsky", "Dimitar I. Dimitrov", "Maximilian Baader", "Martin Vechev"], "title": "SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning", "comment": "Published at the Workshop on Regulatable ML at the 39th Conference on\n  Neural Information Processing Systems (NeurIPS 2025)", "summary": "Federated Learning has seen an increased deployment in real-world scenarios\nrecently, as it enables the distributed training of machine learning models\nwithout explicit data sharing between individual clients. Yet, the introduction\nof the so-called gradient inversion attacks has fundamentally challenged its\nprivacy-preserving properties. Unfortunately, as these attacks mostly rely on\ndirect data optimization without any formal guarantees, the vulnerability of\nreal-world systems remains in dispute and requires tedious testing for each new\nfederated deployment. To overcome these issues, recently the SPEAR attack was\nintroduced, which is based on a theoretical analysis of the gradients of linear\nlayers with ReLU activations. While SPEAR is an important theoretical\nbreakthrough, the attack's practicality was severely limited by its exponential\nruntime in the batch size b. In this work, we fill this gap by applying\nState-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the\nproblem of gradient inversion on linear layers with ReLU activations tractable.\nOur experiments demonstrate that our new attack, SPEAR++, retains all desirable\nproperties of SPEAR, such as robustness to DP noise and FedAvg aggregation,\nwhile being applicable to 10x bigger batch sizes.", "AI": {"tldr": "SPEAR++\u653b\u51fb\u901a\u8fc7\u5e94\u7528\u7a00\u758f\u5b57\u5178\u5b66\u4e60\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86SPEAR\u653b\u51fb\u7684\u6548\u7387\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u740610\u500d\u66f4\u5927\u7684\u6279\u6b21\u5927\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9DP\u566a\u58f0\u548cFedAvg\u805a\u5408\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f\u8bad\u7ec3\u800c\u4e0d\u5171\u4eab\u6570\u636e\uff0c\u4f46\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u6311\u6218\u4e86\u5176\u9690\u79c1\u4fdd\u62a4\u7279\u6027\u3002\u73b0\u6709\u7684SPEAR\u653b\u51fb\u867d\u7136\u7406\u8bba\u4e0a\u6709\u7a81\u7834\uff0c\u4f46\u7531\u4e8e\u6307\u6570\u7ea7\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u53d7\u9650\u3002", "method": "\u5e94\u7528\u6700\u5148\u8fdb\u7684\u7a00\u758f\u5b57\u5178\u5b66\u4e60\u6280\u672f\u6765\u89e3\u51b3\u5177\u6709ReLU\u6fc0\u6d3b\u7684\u7ebf\u6027\u5c42\u7684\u68af\u5ea6\u53cd\u8f6c\u95ee\u9898\uff0c\u4f7f\u95ee\u9898\u53d8\u5f97\u53ef\u5904\u7406\u3002", "result": "SPEAR++\u653b\u51fb\u5728\u4fdd\u6301SPEAR\u6240\u6709\u7406\u60f3\u7279\u6027\u7684\u540c\u65f6\uff0c\u80fd\u591f\u5e94\u7528\u4e8e10\u500d\u66f4\u5927\u7684\u6279\u6b21\u5927\u5c0f\uff0c\u4e14\u5bf9DP\u566a\u58f0\u548cFedAvg\u805a\u5408\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "SPEAR++\u653b\u51fb\u586b\u8865\u4e86SPEAR\u653b\u51fb\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u5dee\u8ddd\uff0c\u4e3a\u8bc4\u4f30\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u9690\u79c1\u6f0f\u6d1e\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2510.24216", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24216", "abs": "https://arxiv.org/abs/2510.24216", "authors": ["Fan Xu", "Hao Wu", "Kun Wang", "Nan Wang", "Qingsong Wen", "Xian Wu", "Wei Gong", "Xibin Zhao"], "title": "Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation", "comment": null, "summary": "In dynamical system modeling, traditional numerical methods are limited by\nhigh computational costs, while modern data-driven approaches struggle with\ndata scarcity and distribution shifts. To address these fundamental\nlimitations, we first propose SPARK, a physics-guided quantitative augmentation\nplugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate\nphysical parameters into a physics-rich discrete state dictionary. This state\ndictionary then acts as a structured dictionary of physical states, enabling\nthe creation of new, physically-plausible training samples via principled\ninterpolation in the latent space. Further, for downstream prediction, these\naugmented representations are seamlessly integrated with a Fourier-enhanced\nGraph ODE, a combination designed to robustly model the enriched data\ndistribution while capturing long-term temporal dependencies. Extensive\nexperiments on diverse benchmarks demonstrate that SPARK significantly\noutperforms state-of-the-art baselines, particularly in challenging\nout-of-distribution scenarios and data-scarce regimes, proving the efficacy of\nour physics-guided augmentation paradigm.", "AI": {"tldr": "SPARK\u662f\u4e00\u4e2a\u7269\u7406\u5f15\u5bfc\u7684\u5b9a\u91cf\u589e\u5f3a\u63d2\u4ef6\uff0c\u901a\u8fc7\u91cd\u6784\u81ea\u7f16\u7801\u5668\u5c06\u7269\u7406\u53c2\u6570\u6574\u5408\u5230\u7269\u7406\u4e30\u5bcc\u7684\u79bb\u6563\u72b6\u6001\u5b57\u5178\u4e2d\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u63d2\u503c\u751f\u6210\u7269\u7406\u5408\u7406\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u5e76\u4e0e\u5085\u91cc\u53f6\u589e\u5f3a\u56feODE\u7ed3\u5408\u8fdb\u884c\u4e0b\u6e38\u9884\u6d4b\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u548c\u5206\u5e03\u504f\u79fb\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u4ee3\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6839\u672c\u9650\u5236\u3002", "method": "\u4f7f\u7528\u91cd\u6784\u81ea\u7f16\u7801\u5668\u6784\u5efa\u7269\u7406\u4e30\u5bcc\u7684\u79bb\u6563\u72b6\u6001\u5b57\u5178\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u539f\u7406\u6027\u63d2\u503c\u751f\u6210\u65b0\u8bad\u7ec3\u6837\u672c\uff0c\u7ed3\u5408\u5085\u91cc\u53f6\u589e\u5f3a\u56feODE\u8fdb\u884c\u4e0b\u6e38\u9884\u6d4b\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPARK\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u5e03\u5916\u573a\u666f\u548c\u6570\u636e\u7a00\u7f3a\u673a\u5236\u4e2d\u3002", "conclusion": "\u7269\u7406\u5f15\u5bfc\u7684\u589e\u5f3a\u8303\u5f0f\u5728\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\u4e0a\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.24217", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24217", "abs": "https://arxiv.org/abs/2510.24217", "authors": ["Alisher Turubayev", "Anna Shopova", "Fabian Lange", "Mahmut Kamalak", "Paul Mattes", "Victoria Ayvasky", "Bert Arnrich", "Bjarne Pfitzner", "Robin P. van de Water"], "title": "Closing Gaps: An Imputation Analysis of ICU Vital Signs", "comment": "Preprint", "summary": "As more Intensive Care Unit (ICU) data becomes available, the interest in\ndeveloping clinical prediction models to improve healthcare protocols\nincreases. However, the lack of data quality still hinders clinical prediction\nusing Machine Learning (ML). Many vital sign measurements, such as heart rate,\ncontain sizeable missing segments, leaving gaps in the data that could\nnegatively impact prediction performance. Previous works have introduced\nnumerous time-series imputation techniques. Nevertheless, more comprehensive\nwork is needed to compare a representative set of methods for imputing ICU\nvital signs and determine the best practice. In reality, ad-hoc imputation\ntechniques that could decrease prediction accuracy, like zero imputation, are\nstill used. In this work, we compare established imputation techniques to guide\nresearchers in improving the performance of clinical prediction models by\nselecting the most accurate imputation technique. We introduce an extensible\nand reusable benchmark with currently 15 imputation and 4 amputation methods,\ncreated for benchmarking on major ICU datasets. We hope to provide a\ncomparative basis and facilitate further ML development to bring more models\ninto clinical practice.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86ICU\u751f\u547d\u4f53\u5f81\u6570\u636e\u7f3a\u5931\u503c\u586b\u8865\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u5305\u542b15\u79cd\u586b\u8865\u65b9\u6cd5\u548c4\u79cd\u622a\u65ad\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u57fa\u51c6\uff0c\u65e8\u5728\u4e3a\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u9009\u62e9\u6700\u51c6\u786e\u7684\u586b\u8865\u6280\u672f\u3002", "motivation": "ICU\u6570\u636e\u8d28\u91cf\u4e0d\u8db3\u963b\u788d\u4e86\u673a\u5668\u5b66\u4e60\u5728\u4e34\u5e8a\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u8bb8\u591a\u751f\u547d\u4f53\u5f81\u6d4b\u91cf\u5b58\u5728\u5927\u91cf\u7f3a\u5931\u6bb5\uff0c\u800c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u4ee3\u8868\u6027\u586b\u8865\u65b9\u6cd5\u7684\u5168\u9762\u6bd4\u8f83\uff0c\u73b0\u5b9e\u4e2d\u4ecd\u5728\u4f7f\u7528\u53ef\u80fd\u964d\u4f4e\u9884\u6d4b\u51c6\u786e\u6027\u7684\u4e34\u65f6\u586b\u8865\u6280\u672f\u3002", "method": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u548c\u53ef\u91cd\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b15\u79cd\u586b\u8865\u65b9\u6cd5\u548c4\u79cd\u622a\u65ad\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u4e3b\u8981ICU\u6570\u636e\u96c6\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540c\u586b\u8865\u65b9\u6cd5\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u9009\u62e9\u6700\u51c6\u786e\u586b\u8865\u6280\u672f\u7684\u6307\u5bfc\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u586b\u8865\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6bd4\u8f83\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u66f4\u591a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u5165\u4e34\u5e8a\u5b9e\u8df5\uff0c\u63d0\u9ad8\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2510.24233", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24233", "abs": "https://arxiv.org/abs/2510.24233", "authors": ["Antoine Szatkownik", "Aur\u00e9lien Decelle", "Beatriz Seoane", "Nicolas Bereux", "L\u00e9o Planche", "Guillaume Charpiat", "Burak Yelmen", "Flora Jay", "Cyril Furtlehner"], "title": "PRIVET: Privacy Metric Based on Extreme Value Theory", "comment": null, "summary": "Deep generative models are often trained on sensitive data, such as genetic\nsequences, health data, or more broadly, any copyrighted, licensed or protected\ncontent. This raises critical concerns around privacy-preserving synthetic\ndata, and more specifically around privacy leakage, an issue closely tied to\noverfitting. Existing methods almost exclusively rely on global criteria to\nestimate the risk of privacy failure associated to a model, offering only\nquantitative non interpretable insights. The absence of rigorous evaluation\nmethods for data privacy at the sample-level may hinder the practical\ndeployment of synthetic data in real-world applications. Using extreme value\nstatistics on nearest-neighbor distances, we propose PRIVET, a generic\nsample-based, modality-agnostic algorithm that assigns an individual privacy\nleak score to each synthetic sample. We empirically demonstrate that PRIVET\nreliably detects instances of memorization and privacy leakage across diverse\ndata modalities, including settings with very high dimensionality, limited\nsample sizes such as genetic data and even under underfitting regimes. We\ncompare our method to existing approaches under controlled settings and show\nits advantage in providing both dataset level and sample level assessments\nthrough qualitative and quantitative outputs. Additionally, our analysis\nreveals limitations in existing computer vision embeddings to yield\nperceptually meaningful distances when identifying near-duplicate samples.", "AI": {"tldr": "PRIVET\u662f\u4e00\u79cd\u57fa\u4e8e\u6837\u672c\u7684\u9690\u79c1\u6cc4\u9732\u68c0\u6d4b\u7b97\u6cd5\uff0c\u4f7f\u7528\u6781\u503c\u7edf\u8ba1\u548c\u6700\u8fd1\u90bb\u8ddd\u79bb\u6765\u4e3a\u6bcf\u4e2a\u5408\u6210\u6837\u672c\u5206\u914d\u4e2a\u4f53\u9690\u79c1\u6cc4\u9732\u5206\u6570\uff0c\u80fd\u591f\u53ef\u9760\u5730\u68c0\u6d4b\u8bb0\u5fc6\u5316\u548c\u9690\u79c1\u6cc4\u9732\u3002", "motivation": "\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5e38\u5728\u654f\u611f\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5f15\u53d1\u9690\u79c1\u4fdd\u62a4\u5408\u6210\u6570\u636e\u7684\u62c5\u5fe7\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5168\u5c40\u6807\u51c6\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\uff0c\u7f3a\u4e4f\u6837\u672c\u7ea7\u522b\u7684\u4e25\u683c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u963b\u788d\u4e86\u5408\u6210\u6570\u636e\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u4f7f\u7528\u6781\u503c\u7edf\u8ba1\u548c\u6700\u8fd1\u90bb\u8ddd\u79bb\uff0c\u63d0\u51faPRIVET\u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u901a\u7528\u7684\u57fa\u4e8e\u6837\u672c\u3001\u6a21\u6001\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u4e3a\u6bcf\u4e2a\u5408\u6210\u6837\u672c\u5206\u914d\u4e2a\u4f53\u9690\u79c1\u6cc4\u9732\u5206\u6570\u3002", "result": "PRIVET\u5728\u5404\u79cd\u6570\u636e\u6a21\u6001\u4e2d\u53ef\u9760\u5730\u68c0\u6d4b\u8bb0\u5fc6\u5316\u548c\u9690\u79c1\u6cc4\u9732\uff0c\u5305\u62ec\u9ad8\u7ef4\u8bbe\u7f6e\u3001\u6709\u9650\u6837\u672c\u91cf\uff08\u5982\u9057\u4f20\u6570\u636e\uff09\u751a\u81f3\u6b20\u62df\u5408\u60c5\u51b5\u3002\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u63d0\u4f9b\u6570\u636e\u96c6\u7ea7\u522b\u548c\u6837\u672c\u7ea7\u522b\u8bc4\u4f30\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "PRIVET\u4e3a\u5408\u6210\u6570\u636e\u9690\u79c1\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6837\u672c\u7ea7\u522b\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u73b0\u6709\u8ba1\u7b97\u673a\u89c6\u89c9\u5d4c\u5165\u5728\u8bc6\u522b\u8fd1\u4f3c\u91cd\u590d\u6837\u672c\u65f6\u4ea7\u751f\u611f\u77e5\u4e0a\u6709\u610f\u4e49\u8ddd\u79bb\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.24234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24234", "abs": "https://arxiv.org/abs/2510.24234", "authors": ["Ludovic Schwartz", "Hamish Flynn", "Gergely Neu"], "title": "Sparse Optimistic Information Directed Sampling", "comment": null, "summary": "Many high-dimensional online decision-making problems can be modeled as\nstochastic sparse linear bandits. Most existing algorithms are designed to\nachieve optimal worst-case regret in either the data-rich regime, where\npolynomial depen- dence on the ambient dimension is unavoidable, or the\ndata-poor regime, where dimension-independence is possible at the cost of worse\ndependence on the num- ber of rounds. In contrast, the sparse Information\nDirected Sampling (IDS) algo- rithm satisfies a Bayesian regret bound that has\nthe optimal rate in both regimes simultaneously. In this work, we explore the\nuse of Sparse Optimistic Informa- tion Directed Sampling (SOIDS) to achieve the\nsame adaptivity in the worst-case setting, without Bayesian assumptions.\nThrough a novel analysis that enables the use of a time-dependent learning\nrate, we show that SOIDS can optimally balance information and regret. Our\nresults extend the theoretical guarantees of IDS, pro- viding the first\nalgorithm that simultaneously achieves optimal worst-case regret in both the\ndata-rich and data-poor regimes. We empirically demonstrate the good\nperformance of SOIDS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7a00\u758f\u4e50\u89c2\u4fe1\u606f\u5bfc\u5411\u91c7\u6837\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u6570\u636e\u4e30\u5bcc\u548c\u6570\u636e\u8d2b\u4e4f\u4e24\u79cd\u60c5\u51b5\u4e0b\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u6700\u574f\u60c5\u51b5\u9057\u61be\uff0c\u65e0\u9700\u8d1d\u53f6\u65af\u5047\u8bbe\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u53ea\u80fd\u5728\u6570\u636e\u4e30\u5bcc\u6216\u6570\u636e\u8d2b\u4e4f\u5176\u4e2d\u4e00\u79cd\u60c5\u51b5\u4e0b\u8fbe\u5230\u6700\u4f18\u9057\u61be\uff0c\u65e0\u6cd5\u540c\u65f6\u9002\u5e94\u4e24\u79cd\u60c5\u51b5\u3002\u7a00\u758fIDS\u7b97\u6cd5\u5728\u8d1d\u53f6\u65af\u8bbe\u7f6e\u4e0b\u80fd\u540c\u65f6\u9002\u5e94\uff0c\u4f46\u9700\u8981\u8d1d\u53f6\u65af\u5047\u8bbe\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u4e50\u89c2\u4fe1\u606f\u5bfc\u5411\u91c7\u6837\uff0c\u901a\u8fc7\u65f6\u95f4\u4f9d\u8d56\u5b66\u4e60\u7387\u7684\u65b0\u9896\u5206\u6790\uff0c\u5e73\u8861\u4fe1\u606f\u83b7\u53d6\u548c\u9057\u61be\u6700\u5c0f\u5316\u3002", "result": "SOIDS\u7b97\u6cd5\u5728\u6570\u636e\u4e30\u5bcc\u548c\u6570\u636e\u8d2b\u4e4f\u4e24\u79cd\u60c5\u51b5\u4e0b\u90fd\u8fbe\u5230\u4e86\u6700\u4f18\u6700\u574f\u60c5\u51b5\u9057\u61be\uff0c\u6269\u5c55\u4e86IDS\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "SOIDS\u662f\u7b2c\u4e00\u4e2a\u5728\u4e24\u79cd\u60c5\u51b5\u4e0b\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u6700\u574f\u60c5\u51b5\u9057\u61be\u7684\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2510.24235", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24235", "abs": "https://arxiv.org/abs/2510.24235", "authors": ["Ai Jian", "Jingqing Ruan", "Xing Ma", "Dailin Li", "QianLin Zhou", "Ke Zeng", "Xunliang Cai"], "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling", "comment": null, "summary": "Reward models (RMs) are central to reinforcement learning from human feedback\n(RLHF), providing the critical supervision signals that align large language\nmodels (LLMs) with human preferences. While generative reward models (GRMs)\noffer greater interpretability than traditional scalar RMs, current training\nparadigms remain limited. Pair-wise methods rely on binary good-versus-bad\nlabels, which cause mismatches for point-wise inference and necessitate complex\npairing strategies for effective application in RLHF. On the other hand,\npoint-wise methods require more elaborate absolute labeling with rubric-driven\ncriteria, resulting in poor adaptability and high annotation costs. In this\nwork, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a\nunified framework that integrates a preference-aware reward (PAR) mechanism\nwith dynamic rubric adaptation. PaTaRM leverages relative preference\ninformation from pairwise data to construct robust point-wise training signals,\neliminating the need for explicit point-wise labels. Simultaneously, it employs\na task-adaptive rubric system that flexibly generates evaluation criteria for\nboth global task consistency and instance-specific fine-grained reasoning. This\ndesign enables efficient, generalizable, and interpretable reward modeling for\nRLHF. Extensive experiments show that PaTaRM achieves an average relative\nimprovement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B\nmodels. Furthermore, PaTaRM boosts downstream RLHF performance, with an average\nimprovement of 13.6% across IFEval and InFoBench benchmarks, confirming its\neffectiveness and robustness. Our code is available at\nhttps://github.com/JaneEyre0530/PaTaRM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5956\u52b1\u6a21\u578b\u6846\u67b6PaTaRM\uff0c\u901a\u8fc7\u504f\u597d\u611f\u77e5\u5956\u52b1\u673a\u5236\u548c\u52a8\u6001\u6807\u51c6\u9002\u5e94\uff0c\u5c06\u6210\u5bf9\u6570\u636e\u8f6c\u6362\u4e3a\u70b9\u5f0f\u8bad\u7ec3\u4fe1\u53f7\uff0c\u65e0\u9700\u663e\u5f0f\u70b9\u5f0f\u6807\u6ce8\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u548c\u4e0b\u6e38RLHF\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6210\u5bf9\u5956\u52b1\u6a21\u578b\u65b9\u6cd5\u4f9d\u8d56\u4e8c\u5143\u6807\u7b7e\u5bfc\u81f4\u63a8\u7406\u4e0d\u5339\u914d\uff0c\u70b9\u5f0f\u65b9\u6cd5\u9700\u8981\u590d\u6742\u6807\u6ce8\u4e14\u9002\u5e94\u6027\u5dee\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u7edf\u4e00\u6846\u67b6\u6765\u89e3\u51b3RLHF\u4e2d\u7684\u5956\u52b1\u5efa\u6a21\u95ee\u9898\u3002", "method": "\u63d0\u51faPaTaRM\u6846\u67b6\uff0c\u5305\u542b\u504f\u597d\u611f\u77e5\u5956\u52b1\u673a\u5236\uff08\u5229\u7528\u6210\u5bf9\u6570\u636e\u6784\u5efa\u70b9\u5f0f\u8bad\u7ec3\u4fe1\u53f7\uff09\u548c\u4efb\u52a1\u81ea\u9002\u5e94\u6807\u51c6\u7cfb\u7edf\uff08\u52a8\u6001\u751f\u6210\u8bc4\u4f30\u6807\u51c6\uff09\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6cdb\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u5956\u52b1\u5efa\u6a21\u3002", "result": "\u5728RewardBench\u548cRMBench\u4e0a\u5e73\u5747\u76f8\u5bf9\u63d0\u53474.7%\uff0c\u5728IFEval\u548cInFoBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0b\u6e38RLHF\u6027\u80fd\u5e73\u5747\u63d0\u534713.6%\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "PaTaRM\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u89e3\u51b3\u4e86\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5728\u51cf\u5c11\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e3aRLHF\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5956\u52b1\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24240", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24240", "abs": "https://arxiv.org/abs/2510.24240", "authors": ["Edward Markai", "Sina Molavipour"], "title": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction", "comment": null, "summary": "Temporal Knowledge Graphs have emerged as a powerful way of not only modeling\nstatic relationships between entities but also the dynamics of how relations\nevolve over time. As these informational structures can be used to store\ninformation from a real-world setting, such as a news flow, predicting future\ngraph components to a certain extent equates predicting real-world events. Most\nof the research in this field focuses on embedding-based methods, often\nleveraging convolutional neural net architectures. These solutions act as black\nboxes, limiting insight. In this paper, we explore an extension to an\nestablished rule-based framework, TLogic, that yields a high accuracy in\ncombination with explainable predictions. This offers transparency and allows\nthe end-user to critically evaluate the rules applied at the end of the\nprediction stage. The new rule format incorporates entity category as a key\ncomponent with the purpose of limiting rule application only to relevant\nentities. When categories are unknown for building the graph, we propose a\ndata-driven method to generate them with an LLM-based approach. Additionally,\nwe investigate the choice of aggregation method for scores of retrieved\nentities when performing category prediction.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8e\u89c4\u5219\u7684TLogic\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5b9e\u4f53\u7c7b\u522b\u4f5c\u4e3a\u5173\u952e\u7ec4\u4ef6\u6765\u9650\u5236\u89c4\u5219\u5e94\u7528\u8303\u56f4\uff0c\u5e76\u4f7f\u7528LLM\u65b9\u6cd5\u751f\u6210\u672a\u77e5\u7c7b\u522b\uff0c\u63d0\u9ad8\u4e86\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\u65b9\u6cd5\u591a\u4e3a\u57fa\u4e8e\u5d4c\u5165\u7684\u9ed1\u76d2\u6a21\u578b\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u672c\u6587\u65e8\u5728\u7ed3\u5408\u9ad8\u51c6\u786e\u7387\u548c\u53ef\u89e3\u91ca\u9884\u6d4b\uff0c\u63d0\u4f9b\u900f\u660e\u6027\u8ba9\u7528\u6237\u80fd\u591f\u8bc4\u4f30\u9884\u6d4b\u9636\u6bb5\u5e94\u7528\u7684\u89c4\u5219\u3002", "method": "\u6269\u5c55TLogic\u89c4\u5219\u6846\u67b6\uff0c\u5f15\u5165\u5b9e\u4f53\u7c7b\u522b\u4f5c\u4e3a\u89c4\u5219\u5173\u952e\u7ec4\u4ef6\uff1b\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u751f\u6210\u672a\u77e5\u5b9e\u4f53\u7c7b\u522b\uff1b\u7814\u7a76\u7c7b\u522b\u9884\u6d4b\u4e2d\u68c0\u7d22\u5b9e\u4f53\u5f97\u5206\u7684\u805a\u5408\u65b9\u6cd5\u9009\u62e9\u3002", "result": "\u65b0\u89c4\u5219\u683c\u5f0f\u901a\u8fc7\u5b9e\u4f53\u7c7b\u522b\u9650\u5236\u89c4\u5219\u5e94\u7528\u8303\u56f4\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff1bLLM\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u672a\u77e5\u5b9e\u4f53\u7c7b\u522b\uff1b\u4e0d\u540c\u805a\u5408\u65b9\u6cd5\u5bf9\u7c7b\u522b\u9884\u6d4b\u6548\u679c\u6709\u5f71\u54cd\u3002", "conclusion": "\u6269\u5c55\u7684\u57fa\u4e8e\u89c4\u5219\u6846\u67b6\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5b9e\u4f53\u7c7b\u522b\u4f5c\u4e3a\u5173\u952e\u7ec4\u4ef6\u6709\u6548\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\uff0cLLM\u65b9\u6cd5\u4e3a\u5904\u7406\u672a\u77e5\u7c7b\u522b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.24273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24273", "abs": "https://arxiv.org/abs/2510.24273", "authors": ["Junlin Mu", "Hantao Huang", "Jihang Zhang", "Minghui Yu", "Tao Wang", "Yidong Li"], "title": "SALS: Sparse Attention in Latent Space for KV cache Compression", "comment": null, "summary": "Large Language Models capable of handling extended contexts are in high\ndemand, yet their inference remains challenging due to substantial Key-Value\ncache size and high memory bandwidth requirements. Previous research has\ndemonstrated that KV cache exhibits low-rank characteristics within the hidden\ndimension, suggesting the potential for effective compression. However, due to\nthe widely adopted Rotary Position Embedding mechanism in modern LLMs, naive\nlow-rank compression suffers severe accuracy degradation or creates a new speed\nbottleneck, as the low-rank cache must first be reconstructed in order to apply\nRoPE. In this paper, we introduce two key insights: first, the application of\nRoPE to the key vectors increases their variance, which in turn results in a\nhigher rank; second, after the key vectors are transformed into the latent\nspace, they largely maintain their representation across most layers. Based on\nthese insights, we propose the Sparse Attention in Latent Space framework. SALS\nprojects the KV cache into a compact latent space via low-rank projection, and\nperforms sparse token selection using RoPE-free query-key interactions in this\nspace. By reconstructing only a small subset of important tokens, it avoids the\noverhead of full KV cache reconstruction. We comprehensively evaluate SALS on\nvarious tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and\nadditionally verify its scalability on the RULER-128k benchmark with\nLLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA\nperformance by maintaining competitive accuracy. Under different settings, SALS\nachieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention\noperator compared to FlashAttention2 on the 4K sequence. For the end-to-end\nthroughput performance, we achieves 1.4-fold and 4.5-fold improvement compared\nto GPT-fast on 4k and 32K sequences, respectively.", "AI": {"tldr": "SALS\u662f\u4e00\u79cd\u65b0\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5c06KV\u7f13\u5b58\u6295\u5f71\u5230\u7d27\u51d1\u7684\u6f5c\u5728\u7a7a\u95f4\u5e76\u5728\u8be5\u7a7a\u95f4\u6267\u884c\u7a00\u758ftoken\u9009\u62e9\uff0c\u907f\u514d\u4e86RoPE\u673a\u5236\u5bfc\u81f4\u7684\u4f4e\u79e9\u538b\u7f29\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684KV\u7f13\u5b58\u538b\u7f29\u548c\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u9762\u4e34KV\u7f13\u5b58\u5927\u5c0f\u548c\u5185\u5b58\u5e26\u5bbd\u7684\u6311\u6218\uff0c\u800c\u73b0\u6709\u7684\u4f4e\u79e9\u538b\u7f29\u65b9\u6cd5\u7531\u4e8eRoPE\u673a\u5236\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u7cbe\u5ea6\u4e0b\u964d\u6216\u65b0\u7684\u901f\u5ea6\u74f6\u9888\u3002", "method": "\u63d0\u51faSALS\u6846\u67b6\uff1a1\uff09\u5c06KV\u7f13\u5b58\u901a\u8fc7\u4f4e\u79e9\u6295\u5f71\u5230\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\uff1b2\uff09\u5728\u8be5\u7a7a\u95f4\u4f7f\u7528\u65e0RoPE\u7684\u67e5\u8be2-\u952e\u4ea4\u4e92\u8fdb\u884c\u7a00\u758ftoken\u9009\u62e9\uff1b3\uff09\u4ec5\u91cd\u5efa\u91cd\u8981token\u5b50\u96c6\uff0c\u907f\u514d\u5b8c\u6574KV\u7f13\u5b58\u91cd\u5efa\u5f00\u9500\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff1aLLaMA2-7b-chat\u548cMistral-7b\u4e0a\u5b9e\u73b06.4\u500dKV\u7f13\u5b58\u538b\u7f29\u548c5.7\u500d\u6ce8\u610f\u529b\u7b97\u5b50\u52a0\u901f\uff1b\u57284k\u548c32k\u5e8f\u5217\u4e0a\u5206\u522b\u6bd4GPT-fast\u5b9e\u73b01.4\u500d\u548c4.5\u500d\u7684\u7aef\u5230\u7aef\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "SALS\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86RoPE\u5e26\u6765\u7684\u4f4e\u79e9\u538b\u7f29\u6311\u6218\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684KV\u7f13\u5b58\u538b\u7f29\u548c\u63a8\u7406\u52a0\u901f\u6548\u679c\u3002"}}
{"id": "2510.24310", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24310", "abs": "https://arxiv.org/abs/2510.24310", "authors": ["Guus Toussaint", "Arno Knobbe"], "title": "EDC: Equation Discovery for Classification", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Lecture Notes in Computer Science, and is available online at\n  https://doi.org/10.1007/978-3-032-05461-6_9", "summary": "Equation Discovery techniques have shown considerable success in regression\ntasks, where they are used to discover concise and interpretable models\n(\\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary\nclassification framework. Our proposed method EDC finds analytical functions of\nmanageable size that specify the location and shape of the decision boundary.\nIn extensive experiments on artificial and real-life data, we demonstrate how\nEDC is able to discover both the structure of the target equation as well as\nthe value of its parameters, outperforming the current state-of-the-art\nED-based classification methods in binary classification and achieving\nperformance comparable to the state of the art in binary classification. We\nsuggest a grammar of modest complexity that appears to work well on the tested\ndatasets but argue that the exact grammar -- and thus the complexity of the\nmodels -- is configurable, and especially domain-specific expressions can be\nincluded in the pattern language, where that is required. The presented grammar\nconsists of a series of summands (additive terms) that include linear,\nquadratic and exponential terms, as well as products of two features (producing\nhyperbolic curves ideal for capturing XOR-like dependencies). The experiments\ndemonstrate that this grammar allows fairly flexible decision boundaries while\nnot so rich to cause overfitting.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65b9\u7a0b\u53d1\u73b0(ED)\u7684\u4e8c\u5143\u5206\u7c7b\u6846\u67b6EDC\uff0c\u80fd\u591f\u53d1\u73b0\u6307\u5b9a\u51b3\u7b56\u8fb9\u754c\u4f4d\u7f6e\u548c\u5f62\u72b6\u7684\u89e3\u6790\u51fd\u6570\uff0c\u5728\u4eba\u5de5\u548c\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709ED\u5206\u7c7b\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u4e8c\u5143\u5206\u7c7b\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u65b9\u7a0b\u53d1\u73b0\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u5df2\u8bc1\u660e\u6210\u529f\uff0c\u4f46\u9700\u8981\u5c06\u5176\u6269\u5c55\u5230\u5206\u7c7b\u4efb\u52a1\uff0c\u7279\u522b\u662f\u53d1\u73b0\u80fd\u591f\u660e\u786e\u63cf\u8ff0\u51b3\u7b56\u8fb9\u754c\u7684\u53ef\u89e3\u91ca\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u9002\u5ea6\u590d\u6742\u5ea6\u7684\u8bed\u6cd5\uff0c\u5305\u542b\u7ebf\u6027\u9879\u3001\u4e8c\u6b21\u9879\u3001\u6307\u6570\u9879\u4ee5\u53ca\u4e24\u4e2a\u7279\u5f81\u7684\u4e58\u79ef\u9879\uff08\u4ea7\u751f\u53cc\u66f2\u7ebf\uff09\uff0c\u5f62\u6210\u4e00\u7cfb\u5217\u52a0\u6027\u9879\u6765\u6784\u5efa\u51b3\u7b56\u8fb9\u754c\u51fd\u6570\u3002", "result": "\u5728\u4eba\u5de5\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEDC\u80fd\u591f\u53d1\u73b0\u76ee\u6807\u65b9\u7a0b\u7684\u7ed3\u6784\u548c\u53c2\u6570\u503c\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u4e8eED\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u5728\u4e8c\u5143\u5206\u7c7b\u4e2d\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8bed\u6cd5\u5141\u8bb8\u76f8\u5f53\u7075\u6d3b\u7684\u51b3\u7b56\u8fb9\u754c\uff0c\u540c\u65f6\u4e0d\u4f1a\u8fc7\u4e8e\u4e30\u5bcc\u5bfc\u81f4\u8fc7\u62df\u5408\uff0c\u8bed\u6cd5\u590d\u6742\u5ea6\u53ef\u914d\u7f6e\uff0c\u7279\u522b\u53ef\u4ee5\u5305\u542b\u9886\u57df\u7279\u5b9a\u7684\u8868\u8fbe\u5f0f\u3002"}}
{"id": "2510.24318", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24318", "abs": "https://arxiv.org/abs/2510.24318", "authors": ["Prajit Bhaskaran", "Tom Viering"], "title": "Transformers can do Bayesian Clustering", "comment": null, "summary": "Bayesian clustering accounts for uncertainty but is computationally demanding\nat scale. Furthermore, real-world datasets often contain missing values, and\nsimple imputation ignores the associated uncertainty, resulting in suboptimal\nresults. We present Cluster-PFN, a Transformer-based model that extends\nPrior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained\nentirely on synthetic datasets generated from a finite Gaussian Mixture Model\n(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over\nboth the number of clusters and the cluster assignments. Our method estimates\nthe number of clusters more accurately than handcrafted model selection\nprocedures such as AIC, BIC and Variational Inference (VI), and achieves\nclustering quality competitive with VI while being orders of magnitude faster.\nCluster-PFN can be trained on complex priors that include missing data,\noutperforming imputation-based baselines on real-world genomic datasets, at\nhigh missingness. These results show that the Cluster-PFN can provide scalable\nand flexible Bayesian clustering.", "AI": {"tldr": "Cluster-PFN\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5148\u9a8c\u4e0a\u8bad\u7ec3\uff0c\u5b9e\u73b0\u65e0\u76d1\u7763\u8d1d\u53f6\u65af\u805a\u7c7b\uff0c\u80fd\u540c\u65f6\u4f30\u8ba1\u805a\u7c7b\u6570\u91cf\u548c\u5206\u914d\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u51c6\u786e\u4e14\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u8d1d\u53f6\u65af\u805a\u7c7b\u867d\u7136\u80fd\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u73b0\u5b9e\u6570\u636e\u96c6\u5e38\u5305\u542b\u7f3a\u5931\u503c\uff0c\u7b80\u5355\u63d2\u8865\u65b9\u6cd5\u5ffd\u7565\u4e86\u76f8\u5173\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u7406\u60f3\u3002", "method": "\u63d0\u51faCluster-PFN\u6a21\u578b\uff0c\u6269\u5c55Prior-Data Fitted Networks\u5230\u65e0\u76d1\u7763\u8d1d\u53f6\u65af\u805a\u7c7b\u3002\u5b8c\u5168\u5728\u6709\u9650\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5148\u9a8c\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5b66\u4e60\u4f30\u8ba1\u805a\u7c7b\u6570\u91cf\u548c\u5206\u914d\u7684\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5728\u4f30\u8ba1\u805a\u7c7b\u6570\u91cf\u65b9\u9762\u6bd4AIC\u3001BIC\u548c\u53d8\u5206\u63a8\u65ad\u66f4\u51c6\u786e\uff0c\u805a\u7c7b\u8d28\u91cf\u4e0e\u53d8\u5206\u63a8\u65ad\u76f8\u5f53\u4f46\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002\u5728\u5305\u542b\u7f3a\u5931\u6570\u636e\u7684\u590d\u6742\u5148\u9a8c\u4e0a\u8bad\u7ec3\u65f6\uff0c\u5728\u9ad8\u7f3a\u5931\u7387\u4e0b\u4f18\u4e8e\u57fa\u4e8e\u63d2\u8865\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Cluster-PFN\u80fd\u591f\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u8d1d\u53f6\u65af\u805a\u7c7b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24331", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24331", "abs": "https://arxiv.org/abs/2510.24331", "authors": ["Gabriel O. dos Santos", "Esther Colombini", "Sandra Avila"], "title": "What do vision-language models see in the context? Investigating multimodal in-context learning", "comment": null, "summary": "In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks\nfrom demonstration examples without parameter updates. Although it has been\nextensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)\nremains underexplored. In this work, we present a systematic study of ICL in\nVLMs, evaluating seven models spanning four architectures on three image\ncaptioning benchmarks. We analyze how prompt design, architectural choices, and\ntraining strategies influence multimodal ICL. To our knowledge, we are the\nfirst to analyze how attention patterns in VLMs vary with an increasing number\nof in-context demonstrations. Our results reveal that training on imag-text\ninterleaved data enhances ICL performance but does not imply effective\nintegration of visual and textual information from demonstration examples. In\ncontrast, instruction tuning improves instruction-following but can reduce\nreliance on in-context demonstrations, suggesting a trade-off between\ninstruction alignment and in-context adaptation. Attention analyses further\nshow that current VLMs primarily focus on textual cues and fail to leverage\nvisual information, suggesting a limited capacity for multimodal integration.\nThese findings highlight key limitations in the ICL abilities of current VLMs\nand provide insights for enhancing their ability to learn from multimodal\nin-context examples.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u8bc4\u4f30\u4e867\u79cd\u6a21\u578b\u5728\u56fe\u50cf\u63cf\u8ff0\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524dVLM\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u7ebf\u7d22\u800c\u672a\u80fd\u6709\u6548\u6574\u5408\u89c6\u89c9\u4fe1\u606f\uff0c\u63ed\u793a\u4e86\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u5173\u952e\u5c40\u9650\u6027\u3002", "motivation": "\u5c3d\u7ba1\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "method": "\u8bc4\u4f30\u4e86\u6db5\u76d6\u56db\u79cd\u67b6\u6784\u7684\u4e03\u4e2a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u4e2a\u56fe\u50cf\u63cf\u8ff0\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e86\u63d0\u793a\u8bbe\u8ba1\u3001\u67b6\u6784\u9009\u62e9\u548c\u8bad\u7ec3\u7b56\u7565\u5bf9\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5e76\u9996\u6b21\u5206\u6790\u4e86\u6ce8\u610f\u529b\u6a21\u5f0f\u968f\u6f14\u793a\u793a\u4f8b\u6570\u91cf\u589e\u52a0\u7684\u53d8\u5316\u3002", "result": "\u8bad\u7ec3\u56fe\u50cf-\u6587\u672c\u4ea4\u9519\u6570\u636e\u80fd\u63d0\u5347\u4e0a\u4e0b\u6587\u5b66\u4e60\u6027\u80fd\u4f46\u5e76\u4e0d\u610f\u5473\u7740\u80fd\u6709\u6548\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\uff1b\u6307\u4ee4\u8c03\u4f18\u6539\u5584\u4e86\u6307\u4ee4\u8ddf\u968f\u4f46\u51cf\u5c11\u4e86\u5bf9\u4e0a\u4e0b\u6587\u6f14\u793a\u7684\u4f9d\u8d56\uff1b\u6ce8\u610f\u529b\u5206\u6790\u663e\u793a\u5f53\u524dVLM\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u7ebf\u7d22\u800c\u672a\u80fd\u5229\u7528\u89c6\u89c9\u4fe1\u606f\u3002", "conclusion": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u9762\u5b58\u5728\u5173\u952e\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u95ee\u9898\u662f\u65e0\u6cd5\u6709\u6548\u6574\u5408\u89c6\u89c9\u4fe1\u606f\uff0c\u8fd9\u4e3a\u63d0\u5347\u4ece\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u793a\u4f8b\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.24356", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24356", "abs": "https://arxiv.org/abs/2510.24356", "authors": ["Suman Sanyal"], "title": "Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning", "comment": null, "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's\nsensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic\nsignals, decoupled from downstream decision learning\n$g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free\nperceptual properties, such as stability to nuisances, informativeness without\ncollapse, and controlled geometry, assessed via objective\nrepresentation-invariant metrics. We formalize the separation of perception and\ndecision, define perceptual properties independent of objectives or\nreparameterizations, and prove that PeL updates preserving sufficient\ninvariants are orthogonal to Bayes task-risk gradients. Additionally, we\nprovide a suite of task-agnostic evaluation metrics to certify perceptual\nquality.", "AI": {"tldr": "\u63d0\u51fa\u611f\u77e5\u5b66\u4e60\uff08PeL\uff09\u8303\u5f0f\uff0c\u5c06\u667a\u80fd\u4f53\u7684\u611f\u77e5\u63a5\u53e3\u4f18\u5316\u4e0e\u4e0b\u6e38\u51b3\u7b56\u5b66\u4e60\u89e3\u8026\uff0c\u901a\u8fc7\u4efb\u52a1\u65e0\u5173\u4fe1\u53f7\u76f4\u63a5\u4f18\u5316\u611f\u77e5\u5c5e\u6027\u5982\u7a33\u5b9a\u6027\u3001\u4fe1\u606f\u6027\u548c\u51e0\u4f55\u63a7\u5236\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u611f\u77e5\u548c\u51b3\u7b56\u8026\u5408\u4f18\u5316\uff0c\u5bfc\u81f4\u611f\u77e5\u8d28\u91cf\u65e0\u6cd5\u72ec\u7acb\u8bc4\u4f30\u3002PeL\u65e8\u5728\u5206\u79bb\u611f\u77e5\u5b66\u4e60\uff0c\u4f7f\u5176\u4e0d\u4f9d\u8d56\u5177\u4f53\u4efb\u52a1\u76ee\u6807\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u901a\u7528\u548c\u9c81\u68d2\u7684\u611f\u77e5\u80fd\u529b\u3002", "method": "\u5b9a\u4e49\u611f\u77e5\u63a5\u53e3f_\u03c6\u548c\u51b3\u7b56\u51fd\u6570g_\u03b8\u7684\u5206\u79bb\u6846\u67b6\uff0c\u4f7f\u7528\u4efb\u52a1\u65e0\u5173\u4fe1\u53f7\u4f18\u5316\u611f\u77e5\u5c5e\u6027\uff0c\u5305\u62ec\u5bf9\u6270\u52a8\u7684\u7a33\u5b9a\u6027\u3001\u4fe1\u606f\u4e30\u5bcc\u6027\u800c\u4e0d\u5d29\u6e83\u3001\u4ee5\u53ca\u53ef\u63a7\u7684\u51e0\u4f55\u7ed3\u6784\u3002", "result": "\u8bc1\u660e\u4e86PeL\u66f4\u65b0\u5728\u4fdd\u6301\u8db3\u591f\u4e0d\u53d8\u6027\u7684\u60c5\u51b5\u4e0b\u4e0e\u8d1d\u53f6\u65af\u4efb\u52a1\u98ce\u9669\u68af\u5ea6\u6b63\u4ea4\uff0c\u63d0\u4f9b\u4e86\u4efb\u52a1\u65e0\u5173\u7684\u8bc4\u4f30\u6307\u6807\u6765\u8ba4\u8bc1\u611f\u77e5\u8d28\u91cf\u3002", "conclusion": "PeL\u4e3a\u611f\u77e5\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u611f\u77e5\u4e0e\u51b3\u7b56\u7684\u5206\u79bb\uff0c\u80fd\u591f\u72ec\u7acb\u4f18\u5316\u548c\u8bc4\u4f30\u611f\u77e5\u8d28\u91cf\uff0c\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.24368", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24368", "abs": "https://arxiv.org/abs/2510.24368", "authors": ["Maria Gabriela Valeriano", "David Kohan Marzag\u00e3o", "Alfredo Montelongo", "Carlos Roberto Veiga Kiffer", "Natan Katz", "Ana Carolina Lorena"], "title": "Filtering instances and rejecting predictions to obtain reliable models in healthcare", "comment": "This paper is under review at Machine Learning (Springer)", "summary": "Machine Learning (ML) models are widely used in high-stakes domains such as\nhealthcare, where the reliability of predictions is critical. However, these\nmodels often fail to account for uncertainty, providing predictions even with\nlow confidence. This work proposes a novel two-step data-centric approach to\nenhance the performance of ML models by improving data quality and filtering\nlow-confidence predictions. The first step involves leveraging Instance\nHardness (IH) to filter problematic instances during training, thereby refining\nthe dataset. The second step introduces a confidence-based rejection mechanism\nduring inference, ensuring that only reliable predictions are retained. We\nevaluate our approach using three real-world healthcare datasets, demonstrating\nits effectiveness at improving model reliability while balancing predictive\nperformance and rejection rate. Additionally, we use alternative criteria -\ninfluence values for filtering and uncertainty for rejection - as baselines to\nevaluate the efficiency of the proposed method. The results demonstrate that\nintegrating IH filtering with confidence-based rejection effectively enhances\nmodel performance while preserving a large proportion of instances. This\napproach provides a practical method for deploying ML systems in\nsafety-critical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u6b65\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u6570\u636e\u8d28\u91cf\u548c\u8fc7\u6ee4\u4f4e\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u6765\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u533b\u7597\uff09\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u8003\u8651\u4e0d\u786e\u5b9a\u6027\uff0c\u5373\u4f7f\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u4e0b\u4e5f\u63d0\u4f9b\u9884\u6d4b\uff0c\u8fd9\u5f71\u54cd\u4e86\u9884\u6d4b\u7684\u53ef\u9760\u6027\u3002", "method": "\u7b2c\u4e00\u6b65\u5229\u7528\u5b9e\u4f8b\u786c\u5ea6\uff08IH\uff09\u5728\u8bad\u7ec3\u671f\u95f4\u8fc7\u6ee4\u95ee\u9898\u5b9e\u4f8b\u4ee5\u4f18\u5316\u6570\u636e\u96c6\uff1b\u7b2c\u4e8c\u6b65\u5728\u63a8\u7406\u9636\u6bb5\u5f15\u5165\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u62d2\u7edd\u673a\u5236\uff0c\u53ea\u4fdd\u7559\u53ef\u9760\u9884\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5e73\u8861\u9884\u6d4b\u6027\u80fd\u548c\u62d2\u7edd\u7387\u3002IH\u8fc7\u6ee4\u4e0e\u7f6e\u4fe1\u5ea6\u62d2\u7edd\u7684\u7ed3\u5408\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u5927\u90e8\u5206\u5b9e\u4f8b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u8d28\u91cf\u6539\u8fdb\u548c\u9884\u6d4b\u53ef\u9760\u6027\u4fdd\u8bc1\u6765\u589e\u5f3a\u6a21\u578b\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.24432", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24432", "abs": "https://arxiv.org/abs/2510.24432", "authors": ["Seyed Mahdi Basiri Azad", "Joschka Boedecker"], "title": "Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings", "comment": null, "summary": "Reinforcement learning (RL) in sparse-reward environments remains a\nsignificant challenge due to the lack of informative feedback. We propose a\nsimple yet effective method that uses a small number of successful\ndemonstrations to initialize the value function of an RL agent. By precomputing\nvalue estimates from offline demonstrations and using them as targets for early\nlearning, our approach provides the agent with a useful prior over promising\nactions. The agent then refines these estimates through standard online\ninteraction. This hybrid offline-to-online paradigm significantly reduces the\nexploration burden and improves sample efficiency in sparse-reward settings.\nExperiments on benchmark tasks demonstrate that our method accelerates\nconvergence and outperforms standard baselines, even with minimal or suboptimal\ndemonstration data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f7f\u7528\u5c11\u91cf\u6210\u529f\u6f14\u793a\u521d\u59cb\u5316\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u4ef7\u503c\u51fd\u6570\u7684\u7b80\u5355\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u6f14\u793a\u9884\u8ba1\u7b97\u4ef7\u503c\u4f30\u8ba1\u4f5c\u4e3a\u65e9\u671f\u5b66\u4e60\u76ee\u6807\uff0c\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "motivation": "\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7f3a\u4e4f\u4fe1\u606f\u53cd\u9988\u7684\u6311\u6218\uff0c\u9700\u8981\u51cf\u5c11\u63a2\u7d22\u8d1f\u62c5\u5e76\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "method": "\u4f7f\u7528\u5c11\u91cf\u6210\u529f\u6f14\u793a\u9884\u8ba1\u7b97\u4ef7\u503c\u4f30\u8ba1\uff0c\u5c06\u5176\u4f5c\u4e3a\u65e9\u671f\u5b66\u4e60\u76ee\u6807\uff0c\u7136\u540e\u901a\u8fc7\u6807\u51c6\u5728\u7ebf\u4ea4\u4e92\u8fdb\u884c\u7cbe\u5316\uff0c\u91c7\u7528\u79bb\u7ebf\u5230\u5728\u7ebf\u7684\u6df7\u5408\u8303\u5f0f\u3002", "result": "\u5728\u57fa\u51c6\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u52a0\u901f\u4e86\u6536\u655b\u901f\u5ea6\uff0c\u5373\u4f7f\u4f7f\u7528\u6700\u5c0f\u6216\u6b21\u4f18\u7684\u6f14\u793a\u6570\u636e\u4e5f\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6f14\u793a\u521d\u59cb\u5316\u4ef7\u503c\u51fd\u6570\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2510.24473", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24473", "abs": "https://arxiv.org/abs/2510.24473", "authors": ["Lucas Buk Cardoso", "Simone Aldrey Angelo", "Yasmin Pacheco Gil Bonilha", "Fernando Maia", "Adeylson Guimar\u00e3es Ribeiro", "Maria Paula Curado", "Gisele Aparecida Fernandes", "Vanderlei Cunha Parro", "Fl\u00e1vio Almeida de Magalh\u00e3es Cipparrone", "Alexandre Dias Porto Chiavegatto Filho", "Tatiana Natasha Toporcov"], "title": "Methodology for Comparing Machine Learning Algorithms for Survival Analysis", "comment": null, "summary": "This study presents a comparative methodological analysis of six machine\nlearning models for survival analysis (MLSA). Using data from nearly 45,000\ncolorectal cancer patients in the Hospital-Based Cancer Registries of S\\~ao\nPaulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for\nSurvival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),\nXGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival\nconsidering censored data. Hyperparameter optimization was performed with\ndifferent samplers, and model performance was assessed using the Concordance\nIndex (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score\n(IBS). Survival curves produced by the models were compared with predictions\nfrom classification algorithms, and predictor interpretation was conducted\nusing SHAP and permutation importance. XGB-AFT achieved the best performance\n(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results\nhighlight the potential and applicability of MLSA to improve survival\nprediction and support decision making.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u516d\u79cd\u673a\u5668\u5b66\u4e60\u751f\u5b58\u5206\u6790\u6a21\u578b\u5728\u7ed3\u76f4\u80a0\u764c\u60a3\u8005\u6570\u636e\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0XGB-AFT\u6a21\u578b\u6027\u80fd\u6700\u4f73\uff0c\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u751f\u5b58\u9884\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u751f\u5b58\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5220\u5931\u6570\u636e\u65f6\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4ee5\u6539\u5584\u7ed3\u76f4\u80a0\u764c\u60a3\u8005\u7684\u751f\u5b58\u9884\u6d4b\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002", "method": "\u4f7f\u7528\u5df4\u897f\u5723\u4fdd\u7f57\u533b\u9662\u764c\u75c7\u767b\u8bb0\u5904\u7684\u8fd145,000\u540d\u7ed3\u76f4\u80a0\u764c\u60a3\u8005\u6570\u636e\uff0c\u8bc4\u4f30\u4e86\u516d\u79cd\u673a\u5668\u5b66\u4e60\u751f\u5b58\u5206\u6790\u6a21\u578b\uff08RSF\u3001GBSA\u3001SSVM\u3001XGB-Cox\u3001XGB-AFT\u3001LGBM\uff09\uff0c\u91c7\u7528\u4e0d\u540c\u91c7\u6837\u5668\u8fdb\u884c\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u5e76\u4f7f\u7528C-Index\u3001C-Index IPCW\u3001\u65f6\u95f4\u76f8\u5173AUC\u548cIBS\u7b49\u6307\u6807\u8bc4\u4f30\u6027\u80fd\u3002", "result": "XGB-AFT\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08C-Index = 0.7618\uff1bIPCW = 0.7532\uff09\uff0c\u5176\u6b21\u662fGBSA\u548cRSF\u6a21\u578b\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u751f\u5b58\u5206\u6790\u6a21\u578b\u5177\u6709\u6539\u5584\u751f\u5b58\u9884\u6d4b\u548c\u652f\u6301\u51b3\u7b56\u5236\u5b9a\u7684\u6f5c\u529b\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2510.24503", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24503", "abs": "https://arxiv.org/abs/2510.24503", "authors": ["Mortesa Hussaini", "Jan Thei\u00df", "Anthony Stein"], "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "comment": null, "summary": "In the context of Federated Learning with heterogeneous data environments,\nlocal models tend to converge to their own local model optima during local\ntraining steps, deviating from the overall data distributions. Aggregation of\nthese local updates, e.g., with FedAvg, often does not align with the global\nmodel optimum (client drift), resulting in an update that is suboptimal for\nmost clients. Personalized Federated Learning approaches address this challenge\nby exclusively focusing on the average local performances of clients' models on\ntheir own data distribution. Generalization to out-of-distribution samples,\nwhich is a substantial benefit of FedAvg and represents a significant component\nof robustness, appears to be inadequately incorporated into the assessment and\nevaluation processes. This study involves a thorough evaluation of Federated\nLearning approaches, encompassing both their local performance and their\ngeneralization capabilities. Therefore, we examine different stages within a\nsingle communication round to enable a more nuanced understanding of the\nconsidered metrics. Furthermore, we propose and incorporate a modified approach\nof FedAvg, designated as Federated Learning with Individualized Updates (FLIU),\nextending the algorithm by a straightforward individualization step with an\nadaptive personalization factor. We evaluate and compare the approaches\nempirically using MNIST and CIFAR-10 under various distributional conditions,\nincluding benchmark IID and pathological non-IID, as well as additional novel\ntest environments with Dirichlet distribution specifically developed to stress\nthe algorithms on complex data heterogeneity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u5f02\u6784\u6570\u636e\u73af\u5883\u4e0b\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6539\u8fdb\u7684FedAvg\u7b97\u6cd5FLIU\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u56e0\u5b50\u6765\u5e73\u8861\u672c\u5730\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u591a\u79cd\u6570\u636e\u5206\u5e03\u6761\u4ef6\u4e0b\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5f02\u6784\u6570\u636e\u73af\u5883\u4e2d\uff0c\u672c\u5730\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u504f\u79bb\u5168\u5c40\u6570\u636e\u5206\u5e03\uff0c\u5bfc\u81f4\u5ba2\u6237\u7aef\u6f02\u79fb\u95ee\u9898\u3002\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u5173\u6ce8\u672c\u5730\u6027\u80fd\uff0c\u4f46\u5ffd\u89c6\u4e86\u6cdb\u5316\u80fd\u529b\u8fd9\u4e00\u91cd\u8981\u6307\u6807\u3002", "method": "\u63d0\u51fa\u4e86\u8054\u90a6\u5b66\u4e60\u4e2a\u4f53\u5316\u66f4\u65b0(FLIU)\u65b9\u6cd5\uff0c\u5728FedAvg\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e2a\u4f53\u5316\u6b65\u9aa4\u548c\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u56e0\u5b50\uff0c\u5e76\u5728MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528IID\u3001\u75c5\u7406\u6027\u975eIID\u4ee5\u53ca\u57fa\u4e8eDirichlet\u5206\u5e03\u7684\u65b0\u6d4b\u8bd5\u73af\u5883\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5728\u4e0d\u540c\u901a\u4fe1\u8f6e\u6b21\u9636\u6bb5\u8fdb\u884c\u7ec6\u81f4\u8bc4\u4f30\uff0c\u6bd4\u8f83\u4e86\u5404\u79cd\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u7684\u672c\u5730\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86FLIU\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "FLIU\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u5e73\u8861\u672c\u5730\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u590d\u6742\u6570\u636e\u5f02\u6784\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89c6\u89d2\u3002"}}
{"id": "2510.24500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24500", "abs": "https://arxiv.org/abs/2510.24500", "authors": ["Yong Huang", "Zhongqi Yang", "Amir Rahmani"], "title": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU", "comment": null, "summary": "Sepsis is a leading cause of mortality in intensive care units (ICUs), yet\nexisting research often relies on outdated datasets, non-reproducible\npreprocessing pipelines, and limited coverage of clinical interventions. We\nintroduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from\nthe MIMIC-IV database, designed to support reproducible modeling of sepsis\ntrajectories. Our cohort includes 35,239 ICU patients with time-aligned\nclinical variables and standardized treatment data, including vasopressors,\nfluids, mechanical ventilation and antibiotics. We describe a transparent\npreprocessing pipeline-based on Sepsis-3 criteria, structured imputation\nstrategies, and treatment inclusion-and release it alongside benchmark tasks\nfocused on early mortality prediction, length-of-stay estimation, and shock\nonset classification. Empirical results demonstrate that incorporating\ntreatment variables substantially improves model performance, particularly for\nTransformer-based architectures. MIMIC-Sepsis serves as a robust platform for\nevaluating predictive and sequential models in critical care research.", "AI": {"tldr": "MIMIC-Sepsis\u662f\u4e00\u4e2a\u57fa\u4e8eMIMIC-IV\u6570\u636e\u5e93\u7684\u8113\u6bd2\u75c7\u7814\u7a76\u57fa\u51c6\u6846\u67b6\uff0c\u5305\u542b35,239\u540dICU\u60a3\u8005\u7684\u65f6\u95f4\u5bf9\u9f50\u4e34\u5e8a\u6570\u636e\u548c\u6807\u51c6\u5316\u6cbb\u7597\u6570\u636e\uff0c\u65e8\u5728\u652f\u6301\u8113\u6bd2\u75c7\u8f68\u8ff9\u7684\u53ef\u91cd\u590d\u5efa\u6a21\u3002", "motivation": "\u73b0\u6709\u8113\u6bd2\u75c7\u7814\u7a76\u5b58\u5728\u6570\u636e\u96c6\u8fc7\u65f6\u3001\u9884\u5904\u7406\u6d41\u7a0b\u4e0d\u53ef\u590d\u73b0\u3001\u4e34\u5e8a\u5e72\u9884\u8986\u76d6\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u57fa\u51c6\u6846\u67b6\u6765\u652f\u6301\u53ef\u91cd\u590d\u7684\u5efa\u6a21\u7814\u7a76\u3002", "method": "\u57fa\u4e8eSepsis-3\u6807\u51c6\u6784\u5efa\u900f\u660e\u9884\u5904\u7406\u6d41\u7a0b\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u63d2\u8865\u7b56\u7565\u548c\u6cbb\u7597\u7eb3\u5165\u65b9\u6cd5\uff0c\u63d0\u4f9b\u65e9\u671f\u6b7b\u4ea1\u7387\u9884\u6d4b\u3001\u4f4f\u9662\u65f6\u95f4\u4f30\u8ba1\u548c\u4f11\u514b\u53d1\u4f5c\u5206\u7c7b\u7b49\u57fa\u51c6\u4efb\u52a1\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u7eb3\u5165\u6cbb\u7597\u53d8\u91cf\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u57fa\u4e8eTransformer\u7684\u67b6\u6784\u3002", "conclusion": "MIMIC-Sepsis\u4e3a\u91cd\u75c7\u76d1\u62a4\u7814\u7a76\u4e2d\u7684\u9884\u6d4b\u548c\u5e8f\u5217\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u7684\u5e73\u53f0\u3002"}}
{"id": "2510.24561", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24561", "abs": "https://arxiv.org/abs/2510.24561", "authors": ["Qingyue Zhang", "Chang Chu", "Tianren Peng", "Qi Li", "Xiangyang Luo", "Zhihao Jiang", "Shao-Lun Huang"], "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis", "comment": null, "summary": "With the widespread adoption of LLMs, LoRA has become a dominant method for\nPEFT, and its initialization methods have attracted increasing attention.\nHowever, existing methods have notable limitations: many methods do not\nincorporate target-domain data, while gradient-based methods exploit data only\nat a shallow level by relying on one-step gradient decomposition, which remains\nunsatisfactory due to the weak empirical performance of the one-step\nfine-tuning model that serves as their basis, as well as the fact that these\nmethods either lack a rigorous theoretical foundation or depend heavily on\nrestrictive isotropic assumptions. In this paper, we establish a theoretical\nframework for data-aware LoRA initialization based on asymptotic analysis.\nStarting from a general optimization objective that minimizes the expectation\nof the parameter discrepancy between the fine-tuned and target models, we\nderive an optimization problem with two components: a bias term, which is\nrelated to the parameter distance between the fine-tuned and target models, and\nis approximated using a Fisher-gradient formulation to preserve anisotropy; and\na variance term, which accounts for the uncertainty introduced by sampling\nstochasticity through the Fisher information. By solving this problem, we\nobtain an optimal initialization strategy for LoRA. Building on this\ntheoretical framework, we develop an efficient algorithm, LoRA-DA, which\nestimates the terms in the optimization problem from a small set of target\ndomain samples and obtains the optimal LoRA initialization. Empirical results\nacross multiple benchmarks demonstrate that LoRA-DA consistently improves final\naccuracy over existing initialization methods. Additional studies show faster,\nmore stable convergence, robustness across ranks, and only a small\ninitialization overhead for LoRA-DA. The source code will be released upon\npublication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6e10\u8fd1\u5206\u6790\u7684\u6570\u636e\u611f\u77e5LoRA\u521d\u59cb\u5316\u7406\u8bba\u6846\u67b6LoRA-DA\uff0c\u901a\u8fc7\u4f18\u5316\u76ee\u6807\u51fd\u6570\u4e2d\u7684\u504f\u5dee\u9879\u548c\u65b9\u5dee\u9879\u6765\u83b7\u5f97\u6700\u4f18LoRA\u521d\u59cb\u5316\u7b56\u7565\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6700\u7ec8\u7cbe\u5ea6\u3002", "motivation": "\u968f\u7740LLMs\u7684\u5e7f\u6cdb\u91c7\u7528\uff0cLoRA\u5df2\u6210\u4e3aPEFT\u7684\u4e3b\u5bfc\u65b9\u6cd5\uff0c\u4f46\u5176\u521d\u59cb\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u8bb8\u591a\u65b9\u6cd5\u672a\u5229\u7528\u76ee\u6807\u57df\u6570\u636e\uff0c\u800c\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u4ec5\u901a\u8fc7\u4e00\u6b65\u68af\u5ea6\u5206\u89e3\u6d45\u5c42\u5229\u7528\u6570\u636e\uff0c\u4e14\u7f3a\u4e4f\u4e25\u683c\u7406\u8bba\u57fa\u7840\u6216\u4f9d\u8d56\u9650\u5236\u6027\u5404\u5411\u540c\u6027\u5047\u8bbe\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u6e10\u8fd1\u5206\u6790\u7684\u6570\u636e\u611f\u77e5LoRA\u521d\u59cb\u5316\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u6700\u5c0f\u5316\u5fae\u8c03\u6a21\u578b\u4e0e\u76ee\u6807\u6a21\u578b\u53c2\u6570\u5dee\u5f02\u671f\u671b\u7684\u4e00\u822c\u4f18\u5316\u76ee\u6807\u51fa\u53d1\uff0c\u63a8\u5bfc\u51fa\u5305\u542b\u504f\u5dee\u9879\uff08\u901a\u8fc7Fisher-\u68af\u5ea6\u516c\u5f0f\u4fdd\u6301\u5404\u5411\u5f02\u6027\uff09\u548c\u65b9\u5dee\u9879\uff08\u901a\u8fc7Fisher\u4fe1\u606f\u8003\u8651\u91c7\u6837\u968f\u673a\u6027\uff09\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u9ad8\u6548\u7b97\u6cd5LoRA-DA\u4ece\u5c11\u91cf\u76ee\u6807\u57df\u6837\u672c\u4f30\u8ba1\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5404\u9879\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cLoRA-DA\u76f8\u6bd4\u73b0\u6709\u521d\u59cb\u5316\u65b9\u6cd5\u6301\u7eed\u63d0\u5347\u4e86\u6700\u7ec8\u7cbe\u5ea6\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u66f4\u5feb\u3001\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u6027\u3001\u8de8\u79e9\u7684\u9c81\u68d2\u6027\uff0c\u4e14\u4ec5\u4ea7\u751f\u8f83\u5c0f\u7684\u521d\u59cb\u5316\u5f00\u9500\u3002", "conclusion": "LoRA-DA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u4e25\u683c\u7406\u8bba\u57fa\u7840\u7684LoRA\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.24574", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24574", "abs": "https://arxiv.org/abs/2510.24574", "authors": ["Hao Wang", "Licheng Pan", "Yuan Lu", "Zhixuan Chu", "Xiaoxi Li", "Shuting He", "Zhichao Chen", "Haoxuan Li", "Qingsong Wen", "Zhouchen Lin"], "title": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment", "comment": null, "summary": "Training time-series forecast models requires aligning the conditional\ndistribution of model forecasts with that of the label sequence. The standard\ndirect forecast (DF) approach resorts to minimize the conditional negative\nlog-likelihood of the label sequence, typically estimated using the mean\nsquared error. However, this estimation proves to be biased in the presence of\nlabel autocorrelation. In this paper, we propose DistDF, which achieves\nalignment by alternatively minimizing a discrepancy between the conditional\nforecast and label distributions. Because conditional discrepancies are\ndifficult to estimate from finite time-series observations, we introduce a\nnewly proposed joint-distribution Wasserstein discrepancy for time-series\nforecasting, which provably upper bounds the conditional discrepancy of\ninterest. This discrepancy admits tractable, differentiable estimation from\nempirical samples and integrates seamlessly with gradient-based training.\nExtensive experiments show that DistDF improves the performance diverse\nforecast models and achieves the state-of-the-art forecasting performance. Code\nis available at https://anonymous.4open.science/r/DistDF-F66B.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DistDF\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6761\u4ef6\u9884\u6d4b\u5206\u5e03\u4e0e\u6807\u7b7e\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u76f4\u63a5\u9884\u6d4b\u65b9\u6cd5\u5728\u6807\u7b7e\u81ea\u76f8\u5173\u5b58\u5728\u65f6\u7684\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u76f4\u63a5\u9884\u6d4b\u65b9\u6cd5\u5728\u5b58\u5728\u6807\u7b7e\u81ea\u76f8\u5173\u65f6\uff0c\u6761\u4ef6\u8d1f\u5bf9\u6570\u4f3c\u7136\u7684\u4f30\u8ba1\u5b58\u5728\u504f\u5dee\uff0c\u8fd9\u5f71\u54cd\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faDistDF\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6761\u4ef6\u9884\u6d4b\u5206\u5e03\u4e0e\u6807\u7b7e\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u5b9e\u73b0\u5bf9\u9f50\u3002\u5f15\u5165\u8054\u5408\u5206\u5e03Wasserstein\u5dee\u5f02\u4f5c\u4e3a\u53ef\u5904\u7406\u7684\u4e0a\u754c\u4f30\u8ba1\uff0c\u8be5\u5dee\u5f02\u53ef\u4ece\u7ecf\u9a8c\u6837\u672c\u4e2d\u8fdb\u884c\u53ef\u5fae\u5206\u4f30\u8ba1\uff0c\u5e76\u4e0e\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDistDF\u63d0\u9ad8\u4e86\u591a\u79cd\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "DistDF\u901a\u8fc7\u5206\u5e03\u5bf9\u9f50\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6761\u4ef6\u5206\u5e03\u504f\u5dee\u95ee\u9898\uff0c\u4e3a\u9884\u6d4b\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2510.24639", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24639", "abs": "https://arxiv.org/abs/2510.24639", "authors": ["Pedro P. Sanchez", "Damian Machlanski", "Steven McDonagh", "Sotirios A. Tsaftaris"], "title": "Causal Ordering for Structure Learning From Time Series", "comment": "32 pages", "summary": "Predicting causal structure from time series data is crucial for\nunderstanding complex phenomena in physiology, brain connectivity, climate\ndynamics, and socio-economic behaviour. Causal discovery in time series is\nhindered by the combinatorial complexity of identifying true causal\nrelationships, especially as the number of variables and time points grow. A\ncommon approach to simplify the task is the so-called ordering-based methods.\nTraditional ordering methods inherently limit the representational capacity of\nthe resulting model. In this work, we fix this issue by leveraging multiple\nvalid causal orderings, instead of a single one as standard practice. We\npropose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based\ncausal discovery for temporal data. By integrating multiple orderings, DOTS\neffectively recovers the transitive closure of the underlying directed acyclic\ngraph, mitigating spurious artifacts inherent in single-ordering approaches. We\nformalise the problem under standard assumptions such as stationarity and the\nadditive noise model, and leverage score matching with diffusion processes to\nenable efficient Hessian estimation. Extensive experiments validate the\napproach. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that DOTS outperforms state-of-the-art baselines, offering a\nscalable and robust approach to temporal causal discovery. On synthetic\nbenchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS\nimproves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the\nCausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the\nbest on individual datasets, DOTS attains the highest average summary-graph\n$F1$ while halving runtime relative to graph-optimisation methods. These\nresults establish DOTS as a scalable and accurate solution for temporal causal\ndiscovery.", "AI": {"tldr": "\u63d0\u51faDOTS\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u6709\u6548\u56e0\u679c\u987a\u5e8f\u800c\u975e\u5355\u4e00\u987a\u5e8f\uff0c\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u5bf9\u7406\u89e3\u751f\u7406\u3001\u8111\u8fde\u63a5\u3001\u6c14\u5019\u548c\u793e\u4f1a\u7ecf\u6d4e\u73b0\u8c61\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u57fa\u4e8e\u6392\u5e8f\u7684\u65b9\u6cd5\u9650\u5236\u4e86\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u6269\u6563\u8fc7\u7a0b\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\uff0c\u901a\u8fc7\u5206\u6570\u5339\u914d\u548cHessian\u4f30\u8ba1\uff0c\u6574\u5408\u591a\u4e2a\u6709\u6548\u56e0\u679c\u987a\u5e8f\u6765\u6062\u590d\u6709\u5411\u65e0\u73af\u56fe\u7684\u4f20\u9012\u95ed\u5305\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0cDOTS\u5c06\u5e73\u5747\u7a97\u53e3\u56feF1\u4ece0.63\u63d0\u5347\u52300.81\uff1b\u5728CausalTime\u771f\u5b9e\u57fa\u51c6\u4e0a\u83b7\u5f97\u6700\u9ad8\u5e73\u5747\u6458\u8981\u56feF1\uff0c\u540c\u65f6\u5c06\u8fd0\u884c\u65f6\u95f4\u51cf\u534a\u3002", "conclusion": "DOTS\u4e3a\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24577", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24577", "abs": "https://arxiv.org/abs/2510.24577", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xiaohui Chen", "Pei-Zhi Zhuang"], "title": "Physics-Informed Extreme Learning Machine (PIELM): Opportunities and Challenges", "comment": null, "summary": "We are very delighted to see the fast development of physics-informed extreme\nlearning machine (PIELM) in recent years for higher computation efficiency and\naccuracy in physics-informed machine learning. As a summary or review on PIELM\nis currently not available, we would like to take this opportunity to show our\nperspective and experience for this promising research direction. We can see\nmany efforts are made to solve PDEs with sharp gradients, nonlinearities,\nhigh-frequency behavior, hard constraints, uncertainty, multiphysics coupling.\nDespite the success, many urgent challenges remain to be tackled, which also\nprovides us opportunities to develop more robust, interpretable, and\ngeneralizable PIELM frameworks with applications in science and engineering.", "AI": {"tldr": "\u672c\u6587\u662f\u5bf9\u7269\u7406\u4fe1\u606f\u6781\u9650\u5b66\u4e60\u673a(PIELM)\u53d1\u5c55\u7684\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u8be5\u9886\u57df\u5728\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u65b9\u9762\u7684\u8fdb\u5c55\u3001\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u7531\u4e8e\u76ee\u524d\u7f3a\u4e4f\u5bf9PIELM\u7684\u603b\u7ed3\u6027\u6587\u732e\uff0c\u4f5c\u8005\u5e0c\u671b\u5206\u4eab\u5bf9\u8fd9\u4e00\u6709\u524d\u666f\u7814\u7a76\u65b9\u5411\u7684\u89c1\u89e3\u548c\u7ecf\u9a8c\u3002", "method": "\u901a\u8fc7\u7efc\u8ff0\u5206\u6790PIELM\u5728\u6c42\u89e3\u5177\u6709\u5c16\u9510\u68af\u5ea6\u3001\u975e\u7ebf\u6027\u3001\u9ad8\u9891\u884c\u4e3a\u3001\u786c\u7ea6\u675f\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u591a\u7269\u7406\u573a\u8026\u5408\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u65b9\u9762\u7684\u5404\u79cd\u65b9\u6cd5\u3002", "result": "PIELM\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7cbe\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u591a\u79cd\u590d\u6742\u7269\u7406\u95ee\u9898\u7684\u6c42\u89e3\u3002", "conclusion": "\u5c3d\u7ba1PIELM\u5df2\u53d6\u5f97\u6210\u529f\uff0c\u4f46\u4ecd\u9762\u4e34\u8bb8\u591a\u7d27\u8feb\u6311\u6218\uff0c\u8fd9\u4e3a\u5f00\u53d1\u66f4\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u63a8\u5e7f\u7684PIELM\u6846\u67b6\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u5c06\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2510.24674", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24674", "abs": "https://arxiv.org/abs/2510.24674", "authors": ["Bram De Cooman", "Johan Suykens"], "title": "Learning to Drive Safely with Hybrid Options", "comment": null, "summary": "Out of the many deep reinforcement learning approaches for autonomous\ndriving, only few make use of the options (or skills) framework. That is\nsurprising, as this framework is naturally suited for hierarchical control\napplications in general, and autonomous driving tasks in specific. Therefore,\nin this work the options framework is applied and tailored to autonomous\ndriving tasks on highways. More specifically, we define dedicated options for\nlongitudinal and lateral manoeuvres with embedded safety and comfort\nconstraints. This way, prior domain knowledge can be incorporated into the\nlearning process and the learned driving behaviour can be constrained more\neasily. We propose several setups for hierarchical control with options and\nderive practical algorithms following state-of-the-art reinforcement learning\ntechniques. By separately selecting actions for longitudinal and lateral\ncontrol, the introduced policies over combined and hybrid options obtain the\nsame expressiveness and flexibility that human drivers have, while being easier\nto interpret than classical policies over continuous actions. Of all the\ninvestigated approaches, these flexible policies over hybrid options perform\nthe best under varying traffic conditions, outperforming the baseline policies\nover actions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u9009\u9879\u6846\u67b6\u5e94\u7528\u4e8e\u9ad8\u901f\u516c\u8def\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\uff0c\u901a\u8fc7\u5b9a\u4e49\u7eb5\u5411\u548c\u6a2a\u5411\u64cd\u4f5c\u7684\u4e13\u7528\u9009\u9879\uff0c\u5c06\u9886\u57df\u77e5\u8bc6\u878d\u5165\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u7ea6\u675f\u9a7e\u9a76\u884c\u4e3a\u3002", "motivation": "\u5c3d\u7ba1\u9009\u9879\u6846\u67b6\u5929\u7136\u9002\u7528\u4e8e\u5206\u5c42\u63a7\u5236\u548c\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\uff0c\u4f46\u5728\u81ea\u52a8\u9a7e\u9a76\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e2d\u5374\u5f88\u5c11\u4f7f\u7528\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u5c06\u8be5\u6846\u67b6\u4e13\u95e8\u5e94\u7528\u4e8e\u9ad8\u901f\u516c\u8def\u81ea\u52a8\u9a7e\u9a76\u3002", "method": "\u5b9a\u4e49\u4e86\u5177\u6709\u5b89\u5168\u548c\u8212\u9002\u7ea6\u675f\u7684\u7eb5\u5411\u548c\u6a2a\u5411\u64cd\u4f5c\u4e13\u7528\u9009\u9879\uff0c\u63d0\u51fa\u4e86\u51e0\u79cd\u5206\u5c42\u63a7\u5236\u8bbe\u7f6e\uff0c\u5e76\u57fa\u4e8e\u6700\u5148\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u63a8\u5bfc\u5b9e\u7528\u7b97\u6cd5\u3002\u901a\u8fc7\u5206\u522b\u9009\u62e9\u7eb5\u5411\u548c\u6a2a\u5411\u63a7\u5236\u52a8\u4f5c\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4eba\u7c7b\u9a7e\u9a76\u5458\u76f8\u540c\u7684\u8868\u8fbe\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002", "result": "\u5728\u6240\u6709\u7814\u7a76\u65b9\u6cd5\u4e2d\uff0c\u57fa\u4e8e\u6df7\u5408\u9009\u9879\u7684\u7075\u6d3b\u7b56\u7565\u5728\u4e0d\u540c\u4ea4\u901a\u6761\u4ef6\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u4e8e\u57fa\u4e8e\u52a8\u4f5c\u7684\u57fa\u7ebf\u7b56\u7565\u3002", "conclusion": "\u9009\u9879\u6846\u67b6\u6210\u529f\u5e94\u7528\u4e8e\u9ad8\u901f\u516c\u8def\u81ea\u52a8\u9a7e\u9a76\uff0c\u901a\u8fc7\u5206\u5c42\u63a7\u5236\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4f7f\u5b66\u4e60\u5230\u7684\u9a7e\u9a76\u884c\u4e3a\u66f4\u5bb9\u6613\u89e3\u91ca\u548c\u7ea6\u675f\u3002"}}
{"id": "2510.24633", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.24633", "abs": "https://arxiv.org/abs/2510.24633", "authors": ["Mingyue Liu", "Andrew Cropper"], "title": "Symbolic Snapshot Ensembles", "comment": null, "summary": "Inductive logic programming (ILP) is a form of logical machine learning. Most\nILP algorithms learn a single hypothesis from a single training run. Ensemble\nmethods train an ILP algorithm multiple times to learn multiple hypotheses. In\nthis paper, we train an ILP algorithm only once and save intermediate\nhypotheses. We then combine the hypotheses using a minimum description length\nweighting scheme. Our experiments on multiple benchmarks, including game\nplaying and visual reasoning, show that our approach improves predictive\naccuracy by 4% with less than 1% computational overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5355\u6b21\u8bad\u7ec3ILP\u7b97\u6cd5\u5e76\u4fdd\u5b58\u4e2d\u95f4\u5047\u8bbe\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u52a0\u6743\u65b9\u6848\u7ec4\u5408\u8fd9\u4e9b\u5047\u8bbe\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u73874%\u4e14\u8ba1\u7b97\u5f00\u9500\u4f4e\u4e8e1%\u3002", "motivation": "\u4f20\u7edf\u7684\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b(ILP)\u65b9\u6cd5\u901a\u5e38\u4ece\u5355\u6b21\u8bad\u7ec3\u4e2d\u5b66\u4e60\u5355\u4e2a\u5047\u8bbe\uff0c\u800c\u96c6\u6210\u65b9\u6cd5\u9700\u8981\u591a\u6b21\u8bad\u7ec3\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u53ea\u9700\u5355\u6b21\u8bad\u7ec3\u5c31\u80fd\u83b7\u5f97\u591a\u4e2a\u5047\u8bbe\u3002", "method": "\u5728\u5355\u6b21ILP\u7b97\u6cd5\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u4e2d\u95f4\u5047\u8bbe\uff0c\u7136\u540e\u4f7f\u7528\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u52a0\u6743\u65b9\u6848\u5c06\u8fd9\u4e9b\u5047\u8bbe\u7ec4\u5408\u8d77\u6765\u3002", "result": "\u5728\u5305\u62ec\u6e38\u620f\u73a9\u6cd5\u548c\u89c6\u89c9\u63a8\u7406\u5728\u5185\u7684\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c06\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u9ad8\u4e864%\uff0c\u540c\u65f6\u8ba1\u7b97\u5f00\u9500\u4f4e\u4e8e1%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5355\u6b21\u8bad\u7ec3\u83b7\u5f97\u591a\u4e2a\u5047\u8bbe\u5e76\u6709\u6548\u7ec4\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86ILP\u7684\u6027\u80fd\u800c\u51e0\u4e4e\u4e0d\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2510.24670", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24670", "abs": "https://arxiv.org/abs/2510.24670", "authors": ["Genesis Research Team", "Alejandro Dobles", "Nina Jovic", "Kenneth Leidal", "Pranav Murugan", "David C. Williams", "Drausin Wulsin", "Nate Gruver", "Christina X. Ji", "Korrawat Pruegsanusak", "Gianluca Scarpellini", "Ansh Sharma", "Wojciech Swiderski", "Andrea Bootsma", "Richard Strong Bowen", "Charlotte Chen", "Jamin Chen", "Marc Andr\u00e9 D\u00e4mgen", "Roy Tal Dew", "Benjamin DiFrancesco", "J. D. Fishman", "Alla Ivanova", "Zach Kagin", "David Li-Bland", "Zuli Liu", "Igor Morozov", "Jeffrey Ouyang-Zhang", "Frank C. Pickard IV", "Kushal S. Shah", "Ben Shor", "Gabriel Monteiro da Silva", "Maxx Tessmer", "Carl Tilbury", "Cyr Vetcher", "Daniel Zeng", "Maruan Al-Shedivat", "Aleksandra Faust", "Evan N. Feinberg", "Michael V. LeVine", "Matteus Pan"], "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location", "comment": null, "summary": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.", "AI": {"tldr": "Pearl\u662f\u4e00\u4e2a\u7528\u4e8e\u86cb\u767d\u8d28-\u914d\u4f53\u5171\u6298\u53e0\u7684\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u8bad\u7ec3\u3001SO(3)\u7b49\u53d8\u6269\u6563\u67b6\u6784\u548c\u53ef\u63a7\u63a8\u7406\u7b49\u521b\u65b0\uff0c\u5728\u86cb\u767d\u8d28-\u914d\u4f53\u590d\u5408\u7269\u7ed3\u6784\u9884\u6d4b\u65b9\u9762\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u86cb\u767d\u8d28-\u914d\u4f53\u590d\u5408\u7269\u7684\u4e09\u7ef4\u7ed3\u6784\u662f\u8ba1\u7b97\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u57fa\u672c\u6311\u6218\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u5b9e\u9a8c\u6570\u636e\u7a00\u7f3a\u3001\u67b6\u6784\u6548\u7387\u4f4e\u3001\u7269\u7406\u65e0\u6548\u6784\u8c61\u4ee5\u53ca\u65e0\u6cd5\u5145\u5206\u5229\u7528\u63a8\u7406\u65f6\u7684\u8f85\u52a9\u4fe1\u606f\u3002", "method": "Pearl\u91c7\u7528\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1)\u5305\u542b\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u7684\u8bad\u7ec3\u65b9\u6848\uff1b(2)\u96c6\u6210SO(3)\u7b49\u53d8\u6269\u6563\u6a21\u5757\u7684\u67b6\u6784\uff0c\u5c0a\u91cd3D\u65cb\u8f6c\u5bf9\u79f0\u6027\uff1b(3)\u53ef\u63a7\u63a8\u7406\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u94fe\u6a21\u677f\u548c\u53cc\u91cd\u65e0\u6761\u4ef6/\u6761\u4ef6\u6a21\u5f0f\u3002", "result": "Pearl\u5728\u86cb\u767d\u8d28-\u914d\u4f53\u5171\u6298\u53e0\u4e2d\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u751f\u6210\u51c6\u786e(RMSD < 2\u00c5)\u4e14\u7269\u7406\u6709\u6548\u7684\u6784\u8c61\u65b9\u9762\uff0c\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4AlphaFold 3\u548c\u5176\u4ed6\u5f00\u6e90\u57fa\u7ebf\u5206\u522b\u63d0\u5347\u4e8614.5%\u548c14.2%\u3002\u5728\u53e3\u888b\u6761\u4ef6\u5171\u6298\u53e0\u673a\u5236\u4e0b\uff0c\u5728\u66f4\u4e25\u683c\u7684RMSD < 1\u00c5\u9608\u503c\u4e0b\u5b9e\u73b0\u4e863.6\u500d\u7684\u6539\u8fdb\u3002", "conclusion": "Pearl\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u7b56\u7565\u3001\u67b6\u6784\u8bbe\u8ba1\u548c\u63a8\u7406\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u6784\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\uff0c\u6a21\u578b\u6027\u80fd\u4e0e\u8bad\u7ec3\u4e2d\u4f7f\u7528\u7684\u5408\u6210\u6570\u636e\u96c6\u5927\u5c0f\u76f4\u63a5\u76f8\u5173\u3002"}}
{"id": "2510.24672", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24672", "abs": "https://arxiv.org/abs/2510.24672", "authors": ["Burak Var\u0131c\u0131", "Che-Ping Tsai", "Ritabrata Ray", "Nicholas M. Boffi", "Pradeep Ravikumar"], "title": "Eigenfunction Extraction for Ordered Representation Learning", "comment": null, "summary": "Recent advances in representation learning reveal that widely used\nobjectives, such as contrastive and non-contrastive, implicitly perform\nspectral decomposition of a contextual kernel, induced by the relationship\nbetween inputs and their contexts. Yet, these methods recover only the linear\nspan of top eigenfunctions of the kernel, whereas exact spectral decomposition\nis essential for understanding feature ordering and importance. In this work,\nwe propose a general framework to extract ordered and identifiable\neigenfunctions, based on modular building blocks designed to satisfy key\ndesiderata, including compatibility with the contextual kernel and scalability\nto modern settings. We then show how two main methodological paradigms,\nlow-rank approximation and Rayleigh quotient optimization, align with this\nframework for eigenfunction extraction. Finally, we validate our approach on\nsynthetic kernels and demonstrate on real-world image datasets that the\nrecovered eigenvalues act as effective importance scores for feature selection,\nenabling principled efficiency-accuracy tradeoffs via adaptive-dimensional\nrepresentations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\u6765\u63d0\u53d6\u6709\u5e8f\u4e14\u53ef\u8bc6\u522b\u7684\u7279\u5f81\u51fd\u6570\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u6784\u5efa\u5757\u6ee1\u8db3\u5173\u952e\u9700\u6c42\uff0c\u5305\u62ec\u4e0e\u4e0a\u4e0b\u6587\u6838\u7684\u517c\u5bb9\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u6838\u548c\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7279\u5f81\u503c\u4f5c\u4e3a\u7279\u5f81\u9009\u62e9\u7684\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u7ef4\u5ea6\u8868\u793a\u7684\u6548\u7387-\u51c6\u786e\u6027\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u5bf9\u6bd4\u548c\u975e\u5bf9\u6bd4\u5b66\u4e60\uff09\u4ec5\u6062\u590d\u6838\u7684\u9876\u90e8\u7279\u5f81\u51fd\u6570\u7684\u7ebf\u6027\u8de8\u5ea6\uff0c\u800c\u7cbe\u786e\u7684\u8c31\u5206\u89e3\u5bf9\u4e8e\u7406\u89e3\u7279\u5f81\u6392\u5e8f\u548c\u91cd\u8981\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6a21\u5757\u5316\u6784\u5efa\u5757\u7684\u901a\u7528\u6846\u67b6\uff0c\u5305\u62ec\u4f4e\u79e9\u8fd1\u4f3c\u548cRayleigh\u5546\u4f18\u5316\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\u8303\u5f0f\uff0c\u7528\u4e8e\u63d0\u53d6\u6709\u5e8f\u53ef\u8bc6\u522b\u7684\u7279\u5f81\u51fd\u6570\u3002", "result": "\u5728\u5408\u6210\u6838\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u6062\u590d\u7684\u7279\u5f81\u503c\u53ef\u4f5c\u4e3a\u7279\u5f81\u9009\u62e9\u7684\u6709\u6548\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u7ef4\u5ea6\u8868\u793a\u7684\u6548\u7387-\u51c6\u786e\u6027\u6743\u8861\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u63d0\u53d6\u6709\u5e8f\u53ef\u8bc6\u522b\u7684\u7279\u5f81\u51fd\u6570\uff0c\u4e3a\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u4f30\u548c\u81ea\u9002\u5e94\u7ef4\u5ea6\u8868\u793a\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
