<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 69]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 15]
- [cs.LG](#cs.LG) [Total: 86]
- [cs.AI](#cs.AI) [Total: 29]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 13]
- [nlin.CD](#nlin.CD) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Tractatus Quanticum](https://arxiv.org/abs/2512.06034)
*Niccolò Covoni,Carlo Rovelli*

Main category: quant-ph

TL;DR: 对维特根斯坦《逻辑哲学论》进行量子力学视角的重新编辑，探索关系性量子力学解释的哲学意义


<details>
  <summary>Details</summary>
Motivation: 探索关系性量子力学解释在哲学上的可能含义，形式化这种解释所探索的实在论与工具主义之间的第三条自然主义道路

Method: 对维特根斯坦的《逻辑哲学论》进行重新编辑，融入量子力学视角，特别是关系性量子力学解释的框架

Result: 创作了一个形式上具有游戏性但内容严肃的作品，试图捕捉关系性量子力学解释的哲学含义

Conclusion: 通过量子力学视角重新解读《逻辑哲学论》，为实在论与工具主义之间的哲学争论提供了新的自然主义第三条道路

Abstract: This is a re-editing, which takes quantum mechanics into account, of Wittgenstein's famous Tractatus. The operation has a playful side in the form, but is a serious attempt to capture possible philosophical implications of the Relational Interpretation of Quantum Mechanics, and formalize the naturalistic third-way between realism and instrumentalism explored by this interpretation.

</details>


### [2] [Entanglement is protected by acceleration-induced transparency in thermal field](https://arxiv.org/abs/2512.06043)
*Yongjie Pan,Baocheng Zhang,Qingyu Cai*

Main category: quant-ph

TL;DR: 研究加速诱导透明效应在热场背景下对两个加速探测器量子纠缠的影响，发现热场通常会降低纠缠，但AIT效应能有效保护纠缠


<details>
  <summary>Details</summary>
Motivation: 加速诱导透明效应最近被提出可以增强两能级探测器的跃迁概率，为Unruh效应的实验探测提供了潜在途径。本文研究AIT效应在热场背景下对两个加速探测器量子纠缠的影响，因为在实际实验中热背景场无法完全避免

Method: 研究两个加速探测器在热场背景下的量子纠缠，分析加速诱导透明效应的影响机制

Result: 虽然热背景场通常会降低探测器之间的纠缠，但加速诱导透明效应能够有效保护这种纠缠

Conclusion: AIT效应在热场背景下对量子纠缠具有保护作用，这为在实验条件下研究Unruh效应和量子纠缠提供了新的视角

Abstract: The acceleration-induced transparency (AIT) effect has been suggested recently to amply the transition probability of the two-level detctor and offers a potential avenue for the experimental detection of the Unruh effect. In this paper, we explore the influence of the AIT effect on quantum entanglement between two detectors accelerated in a thermal field background, since the thermal backgound field cannot be avoided completely in any experiments. Interestingly, we find that although the backgound thermal field generally degrade the entanglement between the detectors, the AIT effect can effectively protect it.

</details>


### [3] [RedCarD: A Quantum Assisted Algorithm for Fixed-Depth Unitary Synthesis via Cartan Decomposition](https://arxiv.org/abs/2512.06070)
*Omar Alsheikh,Efekan Kökcü,Bojko N. Bakalov,A. F. Kemper*

Main category: quant-ph

TL;DR: 提出一种混合量子-经典算法，通过进一步划分动力学李代数来分解优化问题，将代价函数评估转移到量子计算机上，减少经典计算开销，用于合成量子模拟的酉算子。


<details>
  <summary>Details</summary>
Motivation: 量子模拟电路开发中，基于动力学李代数Cartan分解的合成算法虽然能产生与模拟时间无关的电路深度，但存在经典计算开销大的问题，包括代价函数评估和高维优化。

Method: 通过进一步划分动力学李代数，将优化问题分解为更小的独立子问题；利用代数结构将代价函数评估转移到量子计算机上，形成混合量子-经典算法。

Result: 在多个IBM设备和Quantinuum H1-1量子计算机上成功合成了4位点横向场Ising模型的时间演化酉算子，验证了算法的有效性。

Conclusion: 提出的代数划分方法和混合算法显著减少了经典计算开销，为量子模拟电路合成提供了更高效的方案，特别是在处理时间无关哈密顿模拟时。

Abstract: A critical step in developing circuits for quantum simulation is to synthesize a desired unitary operator using the circuit building blocks. Studying unitaries and their generators from the Lie algebraic perspective has given rise to several algorithms for synthesis based on a Cartan decomposition of the dynamical Lie algebra. For unitaries of the form $e^{-itH}$, such as time-independent Hamiltonian simulation, the resulting circuits have depth that does not depend on simulation time $t$. However, finding such circuits has a large classical overhead in the cost function evaluation and the high dimensional optimization problem. In this work, by further partitioning the dynamical Lie algebra, we break down the optimization problem into smaller independent subproblems. Moreover, the resulting algebraic structure allows us to easily shift the evaluation of the cost function to the quantum computer, further cutting the classical overhead of the algorithm. As an application of the new hybrid algorithm, we synthesize the time evolution unitary for the 4-site transverse field Ising model on several IBM devices and Quantinuum's H1-1 quantum computer.

</details>


### [4] [The Twin Paradox in Quantum Field Theory](https://arxiv.org/abs/2512.06076)
*Matheus H. Zambianco,T. Rick Perche*

Main category: quant-ph

TL;DR: 该论文研究了量子场论真空涨落对微观时间测量的影响，通过基于有限尺寸量子系统真空衰变概率的时钟模型，探讨了微观双生子佯谬场景，发现在最小尺度上时间不仅依赖于连接两个事件的轨迹，还取决于真空涨落与时钟微观细节的相互作用。


<details>
  <summary>Details</summary>
Motivation: 量子场论中的真空涨落对短时间尺度测量施加了基本限制。为了研究普遍量子场论效应对观测者相关时间测量的影响，需要建立合适的模型来探索微观尺度上的时间测量特性。

Method: 引入基于有限尺寸量子系统真空衰变概率的时钟模型，使用该模型研究微观双生子佯谬场景，分析真空涨落如何与时钟的微观细节相互作用。

Result: 发现在最小尺度上，时间不仅依赖于连接两个事件的轨迹，还显著依赖于真空涨落与时钟微观细节的相互作用方式，这表明微观时间测量具有比经典相对论更复杂的特性。

Conclusion: 量子场论的真空涨落对微观时间测量产生重要影响，在最小尺度上时间测量不仅受相对论效应支配，还与量子场论效应和时钟的微观结构密切相关，这为理解量子引力背景下的时间概念提供了新视角。

Abstract: Vacuum fluctuations in quantum field theory impose fundamental limitations on our ability to measure time in short scales. To investigate the impact of universal quantum field theory effects on observer-dependent time measurements, we introduce a clock model based on the vacuum decay probability of a finite-sized quantum system. Using this model, we study a microscopic twin paradox scenario and find that, in the smallest scales, time is not only dependent on the trajectory connecting two events, but also on how vacuum fluctuations interact with the microscopic details of the clocks.

</details>


### [5] [Entanglement transition in unitary system-bath dynamics](https://arxiv.org/abs/2512.06081)
*Bo Xing,Giuliano Chiriacò,Paola Cappellaro,Rosario Fazio,Dario Poletti*

Main category: quant-ph

TL;DR: 在系统-浴场耦合的幺正演化中，当耦合强度增加时，系统内纠缠的标度行为会从对数律转变为面积律，这一现象在轨迹平均的约化密度矩阵中不可见。


<details>
  <summary>Details</summary>
Motivation: 传统上，系统与浴场耦合的演化通常用主方程描述，其长时间极限给出稳态密度矩阵。然而，当将演化分解为量子轨迹时，可以观察到系统内纠缠标度随系统-浴场耦合增强而发生的转变，这一现象在轨迹平均的约化密度矩阵中是不可见的。本文旨在超越主方程轨迹的范式，探索在组合系统-浴场设置的幺正演化中是否会出现类似的纠缠标度转变。

Method: 研究一个幺正量子设置，由二维自由费米子晶格组成，其中每个格点耦合到一个费米子浴场。通过改变系统-浴场耦合强度，分析对数费米子负性、互信息以及关联函数的标度行为。

Result: 随着系统-浴场耦合强度的变化，纠缠标度从对数律转变为面积律，这一转变在对数费米子负性、互信息和关联函数中均可见。值得注意的是，系统的稳态性质是平凡的，这些不同标度的特征体现在浴场-浴场关联中。

Conclusion: 在系统-浴场耦合的幺正演化中，确实存在纠缠标度从对数律到面积律的转变，这一现象超越了传统主方程轨迹的范式，揭示了在轨迹平均的约化密度矩阵中不可见的量子特性。

Abstract: The evolution of a system coupled to baths is commonly described by a master equation that, in the long-time limit, yields a steady-state density matrix. However, when the same evolution is unraveled into quantum trajectories, it is possible to observe a transition in the scaling of entanglement within the system as the system-bath coupling increases - a phenomenon that is invisible in the trajectory-averaged reduced density matrix of the system. Here, we go beyond the paradigm of trajectories from master equations and explore whether a qualitatively analogous entanglement-scaling transition emerges in the unitary evolution of the combined system-bath setup. We investigate the scaling of entanglement in a unitary quantum setup composed of a 2D lattice of free fermions, where each site is coupled to a fermionic bath. Varying the system-bath coupling reveals a transition from logarithmic-law to area-law scaling, visible in the logarithmic fermionic negativity, mutual information, and also in the correlations. This occurs while the system's steady-state properties are trivial, highlighting that the signatures of these different scalings are within the bath-bath correlations.

</details>


### [6] [High-Performance Labyrinth Circular Bragg Grating Design for Charge and Stark-Tunable Quantum Light Sources Spanning Visible to Telecom Wavelengths](https://arxiv.org/abs/2512.06117)
*Rohit Prasad,Quirin Buchinger,Fei Chi Kristy Yuen,Yorick Reum,Sven Höfling,Tobias Huber-Loyola*

Main category: quant-ph

TL;DR: 本文提出了一种周期性迷宫式圆形布拉格光栅设计，在保持高光学性能的同时实现了量子点单光子源的电学集成。


<details>
  <summary>Details</summary>
Motivation: 传统圆形布拉格光栅的完全蚀刻环限制了通过电接触实现电荷和斯塔克调谐的集成。虽然已有带四个桥的迷宫式设计，但桥的加入显著降低了光学性能。

Method: 采用周期性迷宫式圆形布拉格光栅设计，在引入桥后通过优化保持高性能。展示了在780nm、930nm和1550nm三个波长的优化设计，并提出包含势垒层的器件布局以实现选择性充电。

Result: 在所有三个波长下，实现了超过90%的收集效率（数值孔径0.7）和大于25的珀塞尔因子。包含势垒层的设计经过重新优化后也能保持无势垒器件的性能。

Conclusion: 迷宫式圆形布拉格光栅为高效、可扩展的电可调谐量子点单光子源提供了一个有前景的平台。

Abstract: Semiconductor quantum dots embedded in circular Bragg gratings (CBGs) are among the most efficient integrated single-photon sources. However, the fully etched rings of conventional CBGs restrict the implementation of charge and Stark tuning via electrical contacts. To overcome this limitation, a labyrinth CBG geometry with four bridges has been proposed, yet the added bridges significantly degraded optical performance. In this work, we numerically demonstrate that a periodic labyrinth CBG design preserves both high coupling efficiency and strong Purcell enhancement while enabling electrical integration if optimized after introducing the bridges. We show three optimized designs at emission wavelengths of 780 nm, 930 nm, and 1550 nm, because these wavelengths are among the most relevant for quantum dots and show the general applicability of our approach. At all three wavelengths collection efficiencies exceeding 90% into a numerical aperture of 0.7 and Purcell factors greater than 25 are achieved. Furthermore, we propose a device layout incorporating a barrier layer that separates p- and n-doped semiconductor regions, which is incorporated to prevent tunneling of one of the charge carriers for selective charging. Also this design can be reoptimized to retain the performance of a device without tunnel barrier. These results establish labyrinth CBGs as a platform for electrically tunable quantum dot single-photon sources with high efficiency and scalability.

</details>


### [7] [Collective three-body interactions enable a robust quantum speedup](https://arxiv.org/abs/2512.06170)
*Haoqing Zhang,Anjun Chu,Chengyi Luo,Chitose Maruko,Eliot A. Bohr,James K. Thompson,Ana Maria Rey*

Main category: quant-ph

TL;DR: 三体相互作用相比传统二体相互作用在制备多体纠缠态方面具有显著优势，包括N倍加速制备GHZ态、达到海森堡极限的相位估计精度，以及在腔损耗和退相干环境下保持高灵敏度。


<details>
  <summary>Details</summary>
Motivation: 传统基于全连接二体伊辛相互作用的方法在制备复杂多体纠缠态方面存在效率限制，需要探索更高效的量子相互作用机制来加速纠缠态制备并提升量子传感性能。

Method: 利用光学腔中N个原子实现集体三体相互作用，通过时间反转协议结合简单旋转和可实验实现的集体自旋测量来制备广义GHZ态。

Result: 三体相互作用相比二体相互作用：1）实现约N倍的GHZ态制备加速；2）在相位估计任务中达到海森堡极限；3）在腔损耗和单粒子退相干环境下，对中等原子数具有高灵敏度增益，在大系综中能快速生成纠缠。

Conclusion: 集体三体相互作用为制备复杂多体纠缠态提供了显著优势，在量子信息处理和量子传感应用中具有重要潜力，特别是在可实现的参数范围内能克服传统方法的局限性。

Abstract: We show that collective three-body interactions (3BIs), implementable with $N$ atoms loaded inside an optical cavity, offer a significant advantage for preparing complex multipartite entangled states. Firstly, they enable a speedup of order $\sim N$ in preparing generalized Greenberger-Horne-Zeilinger (GHZ) states, outperforming conventional methods based on all-to-all two-body Ising interactions. Secondly, they saturate the Heisenberg bound in phase estimation tasks using a time-reversal protocol realized through simple rotations and followed by experimentally accessible collective spin measurements. Lastly, compared with two-body interactions (2BIs), in the presence of cavity losses and single particle decoherence, 3BIs feature a high gain in sensitivity for moderate atom numbers and in large ensembles a fast entanglement generation despite constraints in parameter regimes where they are implementable.

</details>


### [8] [Deterministic and Universal Frequency-Bin Gate for High-Dimensional Quantum Technologies](https://arxiv.org/abs/2512.06191)
*Xin Chen*

Main category: quant-ph

TL;DR: 提出基于腔辅助和频产生过程的确定性、通用、全可编程高维量子门，实现M×N截断幺正变换，保真度接近1，维度可达10^4量级，为高维频率量子处理提供可扩展平台。


<details>
  <summary>Details</summary>
Motivation: 高维光子系统为量子信息处理提供大希尔伯特空间，在量子计算、通信和传感中具有优势，但实现跨多模式的可扩展、低损耗幺正门仍是核心挑战。

Method: 基于腔辅助和频产生过程构建确定性、通用、全可编程高维量子门，实现M×N截断幺正变换（1≤M<N），当M=N时实现完整幺正变换。通过多个脉冲整形器可进一步提升维度。

Result: 当前技术下可实现维度达10^4量级的M×N变换，N可达约1000，保真度接近1。与兼容的SPDC源、高效探测和快速前馈结合，形成可扩展的光纤兼容平台。

Conclusion: 该方案为高维频率量子处理提供了可扩展、光纤兼容的平台，解决了高维光子系统中实现可扩展幺正门的关键挑战。

Abstract: High-dimensional photonic systems access large Hilbert spaces for quantum information processing. They offer proven advantages in quantum computation, communication, and sensing. However, implementing scalable, low-loss unitary gates across many modes remains a central challenge. Here we propose a deterministic, universal, and fully programmable high-dimensional quantum gate based on a cavity-assisted sum-frequency-generation process, achieving near-unity fidelity. The device implements an M-by-N truncated unitary transformation (with 1 <= M < N), or a full unitary when M = N, on frequency-bin modes. With current technology, the attainable dimensionality reaches M-by-N on the order of ten to the power of four, with N up to about one thousand, and can be further increased using multiple pulse shapers. Combined with compatible SPDC sources, high-efficiency detection, and fast feed-forward, this approach provides a scalable, fiber-compatible platform for high-dimensional frequency-bin quantum processing.

</details>


### [9] [Highly robust logical qubit encoding in an ensemble of V-symmetrical qutrits](https://arxiv.org/abs/2512.06219)
*Luis Octavio Castaños-Cervantes,Manuel Calixto,Julio Guerrero*

Main category: quant-ph

TL;DR: 该论文提出使用U(3)相干态构成的偶数和奇数薛定谔猫态来编码逻辑量子比特，这些态对耗散和集体退相干具有鲁棒性，并展示了量子门实现。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子比特在耗散和退相干环境下的脆弱性问题，需要设计对特定噪声机制具有免疫性的逻辑量子比特编码方案。

Method: 使用U(3)相干态构成的偶数和奇数薛定谔猫态编码逻辑量子比特，这些态是有效主方程的与参数无关的稳态，构成暗态。通过两个参数耦合腔体与三能级原子系综的物理系统实现。

Result: 逻辑量子比特态对单量子三态衰减和双量子三态同时衰减与驱动具有免疫性。实现了NOT门和Hadamard门等量子门操作。偶数逻辑态对非均匀展宽和局域相关退相干完全免疫。

Conclusion: 提出的逻辑量子比特编码方案对多种噪声机制具有鲁棒性，为量子计算提供了有前景的容错编码方法，结果可推广到任意数量的量子三态。

Abstract: We propose using even and odd Schödinger cat states formed from coherent states of U(3) of an ensemble of qutrits with a symmetrical V-configuration (a qubit-disguised qutrit) to encode a logical qubit. These carefully engineered logical qubit states are parameter independent stationary states of the effective master equation governing the evolution of the ensemble and, consequently, constitute dark states and are invulnerable to dissipation and correlated collective dephasing. In particular, the logical qubit states are immune to single qutrit decay (the analogous of single photon loss process for qutrits) and simultaneous decay and driving of two qutrits (the analogous two-photon loss and driving processes for qutrits). In addition, we show how to implement the single-qubit quantum NOT gate and the Hadamard gate followed by either the phase gate or the phase and $Z$ gates. We study analytically the case of two qutrits and conclude that the logical qubit states exhibit parity-sensitive inhomogeneous broadening and local correlated dephasing: the even logical state is completely immune to these processes, while odd one is vulnerable. Nevertheless, in the presence of these interactions one can also define another odd state with mixed permutation symmetry that is immune to both inhomogeneous broadening and local correlated dephasing. We suggest that these results can be extrapolated to an arbitrary number of qutrits. The effective master equation is deduced from a physical system composed of two parametrically coupled cavities with one of them interacting dispersively with an ensemble of three-level atoms (the qutrits). In principle this physical system can be implemented by means of two coplanar waveguide resonators, a SQUID parametrically coupling them, and a cloud of alkali atoms close to one of the resonators.

</details>


### [10] [Quantum Interior Point Methods: A Review of Developments and An Optimally Scaling Framework](https://arxiv.org/abs/2512.06224)
*Mohammadhossein Mohammadisiahroudi,Zeguan Wu,Pouya Sampourmahani,Adrian Harkness,Tamás Terlaky*

Main category: quant-ph

TL;DR: 本文综述了量子内点法(QIPMs)的最新进展，特别是作者提出的几乎精确的QIPM框架，该框架利用量子计算加速大规模线性与锥优化问题的求解，克服了经典内点法的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 人工智能和机器学习等领域对大规模数据密集型线性与锥优化问题的求解需求日益增长，经典内点法虽然具有多项式时间收敛性，但每次迭代的计算成本很高，尤其对于密集问题实例。量子计算特别是量子线性系统求解器为加速内点法中最耗计算步骤提供了有前景的途径。

Method: 提出了一种混合量子-经典方法：几乎精确的QIPM框架。该方法在量子计算机上完全构建和求解牛顿系统，而在经典计算机上执行解更新。所有矩阵-向量操作都在量子硬件上执行，结合了可行性维护、迭代精化和预条件处理等技术来应对量子误差、硬件噪声和病态系统敏感性等挑战。

Result: 该方法在维度方面实现了最优的最坏情况可扩展性，超越了现有经典和量子内点法的可扩展性。量子硬件执行所有矩阵-向量操作使得该方法能够克服经典内点法的计算瓶颈。

Conclusion: 量子内点法为解决大规模优化问题提供了有前景的方向，作者提出的几乎精确QIPM框架代表了该领域的重要进展，通过混合量子-经典方法有效利用了量子计算的优势，同时通过经典组件处理更新步骤，为实际应用奠定了基础。

Abstract: The growing demand for solving large-scale, data-intensive linear and conic optimization problems, particularly in applications such as artificial intelligence and machine learning, has highlighted the limitations of classical interior point methods (IPMs). Despite their favorable polynomial-time convergence, conventional IPMs often suffer from high per-iteration computational costs, especially for dense problem instances. Recent advances in quantum computing, particularly quantum linear system solvers, offer promising avenues to accelerate the most computationally intensive steps of IPMs. However, practical challenges such as quantum error, hardware noise, and sensitivity to poorly conditioned systems remain significant obstacles. In response, a series of Quantum IPMs (QIPMs) has been developed to address these challenges, incorporating techniques such as feasibility maintenance, iterative refinement, and preconditioning. In this work, we review this line of research with a focus on our recent contributions, including an almost-exact QIPM framework. This hybrid quantum-classical approach constructs and solves the Newton system entirely on a quantum computer, while performing solution updates classically. Crucially, all matrix-vector operations are executed on quantum hardware, enabling the method to achieve an optimal worst-case scalability w.r.t dimension, surpassing the scalability of existing classical and quantum IPMs.

</details>


### [11] [Tradeoffs between quantum and classical resources in linear combination of unitaries](https://arxiv.org/abs/2512.06260)
*Kaito Wada,Hiroyuki Harada,Yasunari Suzuki,Yuuki Tokunaga,Naoki Yamamoto,Suguru Endo*

Main category: quant-ph

TL;DR: 提出了一种介于原始LCU和随机化LCU之间的混合量子算法，通过分组策略在采样开销和电路规模之间取得平衡，并证明了大组规模对应小采样开销的单调性。


<details>
  <summary>Details</summary>
Motivation: 线性组合单元（LCU）算法是许多量子算法的构建块，但通常需要辅助系统和复杂的受控单元操作，不被视为硬件高效。随机化LCU实现虽然减少了电路深度和辅助量子比特使用，但带来了二次增长的采样开销。需要在采样成本和电路规模之间找到更好的平衡。

Method: 提出混合LCU算法：将单元操作集分成若干组，然后从这些组中随机采样LCU电路来评估目标期望值。引入"缩减因子"这一量来确定所有分组策略的采样开销，并证明了大组规模对应小采样开销的单调性。

Result: 该算法在显著减少电路深度和辅助量子比特使用的同时，几乎保持了基于LCU的非厄米动力学模拟器的采样开销；在线性系统求解器中实现了虚拟和相干方法之间的中间缩放；提供了仅需可重置单辅助量子比特的虚拟基态制备方案；通过将量子错误检测视为LCU过程，明确了何时应选择性地应用常规和虚拟检测。

Conclusion: 提出的混合LCU算法在采样开销和电路规模之间提供了有效的权衡，为早期容错量子计算算法提供了更实用的实现方案，并在多个量子算法应用中展示了优势。

Abstract: The linear combination of unitaries (LCU) algorithm is a building block of many quantum algorithms. However, because LCU generally requires an ancillary system and complex controlled unitary operators, it is not regarded as a hardware-efficient routine. Recently, a randomized LCU implementation with many applications to early FTQC algorithms has been proposed that computes the same expectation values as the original LCU algorithm using a shallower quantum circuit with a single ancilla qubit, at the cost of a quadratically larger sampling overhead. In this work, we propose a quantum algorithm intermediate between the original and randomized LCU that manages the tradeoff between sampling cost and the circuit size. Our algorithm divides the set of unitary operators into several groups and then randomly samples LCU circuits from these groups to evaluate the target expectation value. Notably, we analytically prove an underlying monotonicity: larger group sizes entail smaller sampling overhead, by introducing a quantity called the reduction factor, which determines the sampling overhead across all grouping strategies. Our hybrid algorithm not only enables substantial reductions in circuit depth and ancilla-qubit usage while nearly maintaining the sampling overhead of LCU-based non-Hermitian dynamics simulators, but also achieves intermediate scaling between virtual and coherent quantum linear system solvers. It further provides a virtual ground-state preparation scheme that requires only a resettable single-ancilla qubit and asymptotically shows advantages in both virtual and coherent LCU methods. Finally, by viewing quantum error detection as an LCU process, our approach clarifies when conventional and virtual detection should be applied selectively, thereby balancing sampling and hardware overhead.

</details>


### [12] [Adiabaticity Crossover: From Anderson Localization to Planckian Diffusion](https://arxiv.org/abs/2512.06263)
*Tiange Xiang,Yubo Zhang,Joonas Keski-Rahkonen,Anton M. Graf,Eric J. Heller*

Main category: quant-ph

TL;DR: 该研究从量子声学角度探讨一维电子输运，通过相干态表示晶格振动，建立时间依赖形变势模型，提出加速度基绝热判据，识别普朗克扩散区域，为奇异金属中T线性电阻率提供解释。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解一维电子输运中的量子声学效应，特别是晶格振动如何通过形变势影响电子动力学，以及绝热性、退相干和普朗克扩散之间的关联，为奇异金属中观察到的T线性电阻率现象提供理论解释。

Method: 采用量子声学方法，用相干态表示晶格振动，建立时间依赖形变势模型。引入基于加速度的绝热判据，结合Landau-Zener理论，在(T,v)平面上区分绝热和绝热动力学。通过相干长度与初始波包宽度比L_φ(t)/σ_0量化相干性，分析无量纲扩散系数α=Dm/ℏ。

Result: 识别出广泛的普朗克区域，其中无量纲扩散系数α≈1且对参数弱依赖。该区域在绝热区域和相位相干性降低区域更普遍，表明从安德森局域化到普朗克扩散的退相干驱动交叉。利用爱因斯坦关系结合近乎恒定的α，得到低温趋势1/τ_tr∝T，为奇异金属中T线性电阻率提供解释。

Conclusion: 研究提供了绝热性、退相干和普朗克扩散在动态无序量子声学中的统一图像，建立了晶格振动、电子输运和奇异金属行为之间的联系，为理解一维系统中电子-声子相互作用和输运现象提供了新视角。

Abstract: We investigate electron transport in one dimension from the quantum-acoustic perspective, where the coherent-state representation of lattice vibrations results in a time-dependent deformation potential whose rate is set by the sound speed, fluctuation spectrum is set by the temperature, and overall amplitude is set by the electron-lattice coupling strength. We introduce an acceleration-based adiabatic criterion, consistent with the adiabatic theorem and Landau-Zener theory, that separates adiabatic and diabatic dynamics across the $(T,v)$ plane. The discrete classification agrees with a continuous mean-squared acceleration scale and correlates with a coherence measure given by the ratio of coherence length to the initial packet width $L_φ(t)/σ_0$. We identify a broad Planckian domain in which the dimensionless diffusivity $α\!=\!Dm/\hbar$ is of order unity and only weakly depends on the parameters. This domain is more prevalent in diabatic regions and in areas of reduced phase coherence, indicating a dephasing driven crossover from Anderson localization to Planckian diffusion. Using the Einstein relation together with nearly constant $α$, we directly obtain a low temperature tendency $1/τ_{\rm tr}\propto T$, offering a insight to $T$-linear resistivity in strange metals. These results provide a unified picture that links adiabaticity, dephasing, and Planckian diffusion in dynamically disordered quantum-acoustics.

</details>


### [13] [Wigner-Husimi phase-space structure of quasi-exactly solvable sextic potential](https://arxiv.org/abs/2512.06295)
*Angelina N. Mendoza Tavera,Adrian M. Escobar Ruiz,Robin P. Sagar*

Main category: quant-ph

TL;DR: 比较Wigner函数、其模量和Husimi分布在单阱到双阱转变量子系统中的表现，发现Wigner函数对干涉效应最敏感，能显示非单调熵行为，而模量-Wigner和Husimi分布仅反映几何分裂或粗粒化离域。


<details>
  <summary>Details</summary>
Motivation: 研究不同相空间表示（Wigner函数、其模量、Husimi分布）在量子系统从单阱到双阱转变过程中描述结构变化的能力差异，建立这些表示方法在解析量子态结构变化方面的定量层次。

Method: 使用准精确可解六次振荡器作为代表性例子，采用高精度变分波函数计算最低态，分析二维相空间结构、一维边际分布、Shannon熵、互信息和累积残差Jeffreys散度。

Result: Wigner表示对干涉效应具有独特响应性，在阱分离时显示清晰非单调熵行为；模量-Wigner和Husimi分布仅能描述几何分裂或粗粒化离域。建立了W、|W|和H在解析量子态结构变化能力上的定量层次。

Conclusion: Wigner函数在检测量子干涉效应方面最具描述力，而其他相空间表示主要反映几何特征。这为评估不同相空间表示在双峰或隧穿系统中的描述能力提供了通用框架。

Abstract: In this study, we compare the Wigner function $W$, its modulus, and the Husimi distribution $H$ in a one-dimensional quantum system exhibiting a transition from a single-well to a double-well configuration, using the quasi-exactly solvable sextic oscillator as a representative example. High-accuracy variational wavefunctions for the lowest states are used to compute two-dimensional phase-space structures, one-dimensional marginals, and the corresponding Shannon entropies, mutual information, and Cumulative Residual Jeffreys divergences. The analysis shows that the Wigner representation is uniquely responsive to interference effects and displays clear, nonmonotonic entropic behavior as the wells separate, whereas the modulus-Wigner and Husimi distributions account only for geometric splitting or coarse-grained delocalization. These findings establish a quantitative hierarchy in the ability of $W$, $|W|$, and $H$ to resolve structural changes in a quantum state and provide a general framework for assessing the descriptive power of different phase-space representations in systems with emerging bimodality or tunneling.

</details>


### [14] [Interplay between Standard Quantum Detailed Balance and Thermodynamically Consistent Entropy Production](https://arxiv.org/abs/2512.06707)
*Xin-Hai Tong,Kohei Yoshimura,Tan Van Vu,Naruo Ohga*

Main category: quant-ph

TL;DR: 该论文证明了量子马尔可夫半群满足标准量子细致平衡条件与其生成元具有特殊表示形式（导致熵产生率为零）之间的等价关系。


<details>
  <summary>Details</summary>
Motivation: 研究量子开放系统中热力学一致性、细致平衡条件和熵产生率之间的数学关系，为量子热力学理论提供严格的基础。

Method: 采用量子马尔可夫半群理论框架，基于物理文献中标准的热力学一致性Lindblad方程定义熵产生率，通过数学分析建立细致平衡条件与生成元特殊表示之间的等价关系。

Result: 证明了两个方向的等价性：1）满足标准量子细致平衡条件的量子马尔可夫半群，其生成元具有导致熵产生率为零的特殊表示；2）如果生成元具有满足热力学一致性条件且导致熵产生率为零的特殊表示，则对应的量子马尔可夫半群必须满足标准量子细致平衡条件。

Conclusion: 在量子开放系统热力学中，标准量子细致平衡条件与生成元具有导致零熵产生的特殊表示形式是等价的，这为量子热力学一致性提供了严格的数学基础。

Abstract: We demonstrate that if a quantum Markovian semigroup satisfies the standard quantum detailed balance condition, its generator admits a special representation that yields a vanishing entropy production rate. Conversely, if the generator admits a special representation adhering to the condition of thermodynamic consistency and leading to a vanishing entropy production rate, then the corresponding quantum Markovian semigroup must satisfy the standard quantum detailed balance condition. In this context, we adopt the definition of entropy production rate that is motivated by the physics literature and standard for thermodynamically consistent Lindbladians.

</details>


### [15] [Exploring the topology induced by non-Markovian Liouvillian exceptional points](https://arxiv.org/abs/2512.06311)
*Hao-Long Zhang,Yan Wang,Wen Ning,Shou-Bang Yang,Jia-Hao Lü,Fan Wu,Pei-Rong Han,Zhen-Biao Yang,Shi-Biao Zheng*

Main category: quant-ph

TL;DR: 该研究探索了非马尔可夫体系中Liouvillian超算子的拓扑特性，发现单个闭合路径可以同时产生两个不同的绕数，并在超导量子电路中实验验证了这一现象。


<details>
  <summary>Details</summary>
Motivation: 以往对非厄米拓扑的研究局限于非厄米哈密顿量的异常点，而Liouvillian超算子（结合量子跃迁和非厄米哈密顿动力学）的异常点与哈密顿量的异常点有显著差异。本研究旨在探索非马尔可夫体系中Liouvillian异常点的拓扑特性。

Method: 研究采用一个量子比特耦合到非马尔可夫库的系统模型，分析扩展Liouvillian超算子的拓扑特征。实验上使用超导量子比特耦合到衰减谐振器的电路实现，其中谐振器作为具有记忆效应的库。

Result: 发现单个闭合路径环绕由两个重合的LEP2（每个涉及扩展Liouvillian超算子的一对合并特征向量）形成的双重LEP2时，可以同时产生两个不同的绕数。在超导量子电路中成功实验验证了这一纯粹的非马尔可夫现象。

Conclusion: 该研究将异常拓扑的探索从马尔可夫体系扩展到非马尔可夫体系，揭示了Liouvillian异常点独特的拓扑特性，为理解开放量子系统中的拓扑现象提供了新视角。

Abstract: Non-Hermitian (NH) systems can display exotic topological phenomena without Hermitian counterparts, enabled by exceptional points (EPs). So far, investigations of NH topology have been restricted to EPs of the NH Hamiltonian, which governs the system dynamics conditional upon no quantum jumps occurring. The Liouvillian superoperator, which combines the effects of quantum jumps with NH Hamiltonian dynamics, possesses EPs (LEPs) that are significantly different from those of the corresponding NH Hamiltonian. We here study the topological features of the LEPs in the system consisting of a qubit coupled to a non-Markovian reservoir. We find that two distinct winding numbers can be simultaneously produced by executing a single closed path encircling the twofold LEP2, formed by two coinciding LEP2s, each involving a pair of coalescing eigenvectors of the extended Liouvillian superoperator. We experimentally demonstrate this purely non-Markovian phenomenon with a circuit, where a superconducting qubit is coupled to a decaying resonator which acts as a reservoir with memory effects. The results push the exploration of exceptional topology from the Markovian to non-Markovian regime.

</details>


### [16] [Intrinsic non-Markovian magnetisation dynamics](https://arxiv.org/abs/2512.07378)
*Felix Hartmann,Vivek Unikandanunni,Matias Bargheer,Eric E. Fullerton,Stefano Bonetti,Janet Anders*

Main category: quant-ph

TL;DR: 在钴晶体中首次观察到非马尔可夫动力学，通过太赫兹电磁场驱动磁化，发现多峰光谱特征，用开放量子系统理论成功解释


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫动力学在复杂系统中常见，但在基本物理系统中仅限于特定工程案例。本研究旨在探索元素材料中是否存在非马尔可夫效应

Method: 使用强太赫兹电磁场驱动钴晶体磁化进入非平衡态，测量低温磁响应时域信号，通过傅里叶变换得到频域光谱，应用开放量子系统理论建立非马尔可夫记忆核模型

Result: 观察到意外的多峰光谱特征，传统模型无法解释。基于非马尔可夫记忆核的模拟成功复现测量光谱，并能解释高温下光谱变化

Conclusion: 非马尔可夫效应在比预期更基本的层面上可观测，为在凝聚态系统中探索和控制这些效应开辟了新途径

Abstract: Memory effects arise in many complex systems, from protein folding, to the spreading of epidemics and financial decisions. While so-called non-Markovian dynamics is common in larger systems with interacting components, observations in fundamental physical systems have been confined to specifically engineered cases. Here, we report the experimental observation of non-Markovian dynamics in an elemental material, crystalline cobalt. By driving this material with an intense terahertz electromagnetic field, we bring its magnetisation into a non-equilibrium state and follow its evolution. We measure the sample's low temperature magnetic response in the time domain which leads to an unexpectedly rich multi-peaked spectrum in the Fourier domain, that cannot be explained by established models. We use open quantum system theory, which predicts a non-Markovian memory kernel in the dynamical equations to capture the fundamental interaction between the spin system and the phonon bath. Simulations based on this theory produce a multi-peaked spectrum, which matches the measured one. Our non-Markovian approach is also able to reproduce the modification of the spectrum at higher temperatures. Our findings demonstrate that non-Markovian effects are observable at a much more fundamental level than previously thought, opening the door to their exploration and control in a broad range of condensed matter systems.

</details>


### [17] [Witnessing Spin-Orbital Entanglement using Resonant Inelastic X-Ray Scattering](https://arxiv.org/abs/2512.06718)
*Zecheng Shen,Shuhan Ding,Zijun Zhao,Francesco A. Evangelista,Yao Wang*

Main category: quant-ph

TL;DR: 提出基于RIXS光谱的协议，通过构造厄米生成元计算量子费希尔信息，作为自旋-轨道纠缠的稳健见证


<details>
  <summary>Details</summary>
Motivation: 纠缠在量子技术中至关重要，但在材料中的表征和控制仍然具有挑战性。需要开发新的实验可访问方法来检测材料中的多体纠缠，特别是自旋-轨道纠缠。

Method: 开发了一个协议，利用实验可访问的共振非弹性X射线散射（RIXS）来检测自旋-轨道纠缠。核心方法是从实验可测量的光谱构造厄米生成元，从而计算自旋-轨道系统中的量子费希尔信息（QFI）。

Result: 得到的QFI为k-可产生态提供了上界，因此可以作为自旋-轨道纠缠的稳健见证。为考虑实际实验限制，进一步扩展了框架，包括适用于缺乏完全偏振分辨测量的松弛QFI界限。

Conclusion: 该协议为通过RIXS光谱实验检测材料中的自旋-轨道纠缠提供了有效方法，扩展了谱基纠缠见证在宏观材料中的应用，并考虑了实际实验约束。

Abstract: Entanglement plays a central role in quantum technologies, yet its characterization and control in materials remain challenging. Recent developments in spectrum-based entanglement witnesses have enabled new strategies for quantifying many-body entanglement in macroscopic materials. Here, we develop a protocol for detecting spin--orbital entanglement using experiment-accessible resonant inelastic x-ray scattering (RIXS). Central to our approach is the construction of a Hermitian generator from experimentally measurable spectra, which allows us to compute the quantum Fisher information (QFI) available in spin--orbital systems. The resulting QFI provides upper bounds for $k$-producible states and thus serves as a robust witness of spin--orbital entanglement. To account for realistic experimental limitations, we further extend our framework to include relaxed QFI bounds applicable to measurements lacking full polarization resolution.

</details>


### [18] [Testing the weak equivalence principle for nonclassical matter with torsion balances](https://arxiv.org/abs/2512.06333)
*Roberto Onofrio,Alexander R. H. Smith,Lorenza Viola*

Main category: quant-ph

TL;DR: 提出使用扭秤测试弱等效原理的新方法，通过可控方式在测试质量上创建能量本征态的叠加态，利用加速度算符的均值和方差来检测量子相干性导致的WEP违反。


<details>
  <summary>Details</summary>
Motivation: 传统WEP测试主要基于经典物理框架，而量子态在引力场中的行为需要将惯性质量和引力质量视为算符。需要开发能够检测量子相干性导致WEP违反的测试方法，并克服相干态寿命短于信号采集时间的挑战。

Method: 1. 建立模型推导自由落体算符的矩阵元；2. 利用加速度算符的均值和方差来估计WEP违反，这种方法对逐次波动具有鲁棒性；3. 在扭秤实验中引入并量子化扭矩算符；4. 提出动态设置，让扭秤处于时变引力场中，通过角加速度测量编码可能的WEP违反。

Result: 开发了能够检测量子相干性导致WEP违反的理论框架，证明了加速度算符的方差（不仅仅是均值）可用于估计WEP违反。提出了克服相干态寿命限制的动态测量方案，为实验实现提供了具体指导。

Conclusion: 该研究为在量子领域测试弱等效原理提供了新的理论框架和实验方案，通过将惯性质量和引力质量视为算符，并利用量子态的相干特性，能够检测传统方法无法发现的WEP违反，为量子引力实验开辟了新途径。

Abstract: We propose tests of the weak equivalence principle (WEP) using a torsion balance, in which superposition of energy eigenstates are created in a controllable way for the test masses. After general considerations on the significance of tests of the WEP using quantum states and the need for considering inertial and gravitational masses as operators, we develop a model to derive the matrix elements of the free-fall operator, showing that the variance of the acceleration operator, in addition to its mean, enables estimation of violations of the WEP due to quantum coherence in a way that is robust with respect to shot-to-shot fluctuations. Building on this analysis, we demonstrate how the validity of the WEP may be tested in a torsion balance setup, by accessing the mean and variance of a torque operator we introduce and quantize. Due to the long acquisition times of the signal as compared to the timescale on which coherent superposition states may survive, we further propose a dynamical setting, where the torsion balance is subject to a time-dependent gravitational field, and measurements of angular acceleration encode possible violations of the WEP.

</details>


### [19] [Bound state in the continuum and multiple atom state transfer applications in a waveguide QED setup](https://arxiv.org/abs/2512.06365)
*Xiang Guo,Xiaojun Zhang,Mingzhu Weng,Qian Bin,Hao-di Liu,Hai-Jun Xing,Xin-You Lü,Zhihai Wang*

Main category: quant-ph

TL;DR: 该研究探索了连续谱束缚态在波导-QED架构中的应用，展示了如何利用原子-波导耦合系统中的BICs实现高保真量子态传输。


<details>
  <summary>Details</summary>
Motivation: 虽然连续谱束缚态在超材料中已被广泛用于增强光-物质相互作用，但在多原子波导平台中的出现和应用仍较少被探索。研究者希望探索BICs在波导-QED架构中作为量子信息处理资源的潜力。

Method: 研究采用一维耦合谐振器波导系统，其中两个空间分离的原子阵列以时变强度耦合到不同的谐振器。通过分析原子-波导耦合系统中的BICs特性，设计了量子态传输协议。

Result: 研究发现这些BICs支持驻波光子模式，能够实现两个原子阵列之间任意未知量子态的传输，保真度超过99%。该协议对无序和本征耗散都具有鲁棒性。

Conclusion: 研究结果表明，连续谱束缚态可以作为波导-QED架构中长期存在的资源，用于高保真度的量子信息处理，为量子态传输提供了新的有效方法。

Abstract: Bound states in the continuum (BICs) have been extensively exploited to enhance light--matter interactions in metamaterials, yet their emergence and utility in multi-atom waveguide platforms remain far less explored. Here we study atom--waveguide-dressed BICs in a one-dimensional coupled-resonator waveguide, where two spatially separated atomic arrays couple to distinct resonators with time-dependent strengths. We show that these BICs support a standing-wave photonic mode and enable the transfer of an arbitrary unknown quantum state between the two arrays with fidelities exceeding $99\%$. The protocol remains robust against both disorder and intrinsic dissipation. Our results establish BICs as long-lived resources for high-fidelity quantum information processing in waveguide-QED architectures.

</details>


### [20] [Mitigating the Transition of SiV$^-$ in Diamond to an Optically Dark State](https://arxiv.org/abs/2512.06389)
*Manuel Rieger,Rubek Poudel,Tobias Waldmann,Lina M. Todenhagen,Stefan Kresta,Nori N. Chavira Leal,Viviana Villafañe,Martin S. Brandt,Kai Müller,Jonathan J. Finley*

Main category: quant-ph

TL;DR: 通过施加静态电场结合共振激光，可以有效逆转硅空位色心的电荷态变化，提高SiV⁻的稳态光致发光强度，实现单个色心的电控激活和电荷态稳定控制。


<details>
  <summary>Details</summary>
Motivation: 硅空位色心在共振光激发下会意外转变为零自旋的暗态，这限制了其在量子光子技术中的应用。需要找到方法来稳定和控制其电荷态。

Method: 在金刚石表面定义叉指金属电极，施加静态电场结合共振激光激发。通过时间分辨三色实验研究电荷态转换动力学，分析多个单个色心的响应。

Result: 电场使大多数发射体的SiV⁻稳态光致发光强度提高≥3倍，某些单个发射体几乎保持恒定。成功电激活了原本完全暗态的单个SiV⁻。共振激光不仅激发SiV⁻，还在毫秒时间尺度上产生自由空穴将SiV²⁻转换为SiV⁻。

Conclusion: 电场稳定方案增强了硅空位色心的确定性电荷态控制，不同色心的电控程度差异表明局部环境起关键作用。这为量子纠缠生成和量子密钥分发等应用提供了可扩展路径。

Abstract: Negatively charged silicon vacancy centers in diamond (SiV$^-$) are promising for quantum photonic technologies. However, when subject to resonant optical excitation, they can inadvertently transfer into a zero-spin optically dark state. We show that this unwanted change of charge state can be quickly reversed by the resonant laser itself in combination with static electric fields. By defining interdigitated metallic contacts on the diamond surface, we increase the steady-state SiV$^-$ photoluminescence under resonant excitation by a factor $\ge3$ for most emitters, making it practically constant for certain individual emitters. We electrically activate single \sivs near the positively biased electrode, which are entirely dark without applying local electric fields. Using time-resolved 3-color experiments, we show that the resonant laser not only excites the SiV$^-$, but also creates free holes that convert SiV$^{2-}$ to SiV$^-$ on a timescale of milliseconds. Through analysis of several individual emitters, our results show that the degree of electrical charge state controllability differs between individual emitters, indicating that their local environment plays a key role. Our proposed electric-field-based stabilization scheme enhances deterministic charge state control in group-IV color centers and improves its understanding, offering a scalable path toward quantum applications such as entanglement generation and quantum key distribution.

</details>


### [21] [Generalized product-form monogamy relations in multi-qubit systems](https://arxiv.org/abs/2512.06418)
*Wen Zhou,Zhong-Xi Shen,Hong-Xing Wu,Zhi-Xi Wang,Shao-Ming Fei*

Main category: quant-ph

TL;DR: 本文提出了纠缠单配性的乘积形式不等式，基于concurrence和negativity的ν次幂，比现有不等式更紧致，适用于高维态


<details>
  <summary>Details</summary>
Motivation: 纠缠单配性描述了子系统间纠缠的分布特性，通常用求和形式的不等式表示。本文旨在提出更紧致的乘积形式单配性不等式

Method: 提出了concurrence的ν次幂（ν≥2）的乘积形式单配性不等式，并通过具体例子证明其比现有不等式更紧致；然后建立了基于negativity的更紧致的乘积形式不等式

Result: 提出的乘积形式不等式比现有不等式更紧致；基于negativity的不等式即使在CKW不等式失效的高维态中仍然有效

Conclusion: 本文成功建立了纠缠单配性的乘积形式不等式，这些不等式比传统的求和形式不等式更紧致，且适用于更广泛的量子态，包括高维态

Abstract: Monogamy of entanglement essentially characterizes the entanglement distributions among the subsystems. Generally it is given by summation-form monogamy inequalities. In this paper, we present the product-form monogamy inequalities satisfied by the $ν$-th ($ν\geq2$) power of the concurrence. We show that they are tighter than the existing ones by detailed example. We then establish tighter product-form monogamy inequalities based on the negativity. We show that they are valid even for high dimensional states to which the well-known CKW inequality is violated.

</details>


### [22] [Hybrid qubit-oscillator module with motional states of two trapped interacting atoms](https://arxiv.org/abs/2512.06429)
*Jaeyong Hwang,Tianrui Xu,Sean R. Muleady,Steven Pampel,Gur Lubin,Dawson Hewatt,Cindy A. Regal,Ana Maria Rey*

Main category: quant-ph

TL;DR: 该论文提出使用两个相互作用原子在光学镊子工程势阱中的运动态来实现量子比特-振子系统，其中原子质心自由度扮演光子/声子模式角色，相对运动模式作为量子比特。


<details>
  <summary>Details</summary>
Motivation: 受电路量子电动力学和囚禁离子系统的启发，作者希望创建一个不依赖内部态的运动量子比特系统，从而增强对自旋相关噪声的鲁棒性。

Method: 通过精确的时间调制光学镊子势阱，实现对两个相互作用原子运动态的控制，实现位移、旋转、压缩等玻色子操作以及量子比特控制的相应门操作。

Result: 数值模拟显示这些门操作可以实现高保真度，讨论了初始态制备和最终态读取的可能方案，并指出通过偶极或里德堡修饰相互作用可以实现系统扩展。

Conclusion: 该研究提出了一种基于原子运动态的新型量子比特-振子系统，具有对自旋相关噪声的鲁棒性，并展示了实现通用量子操作的可能性，为可扩展量子系统提供了新途径。

Abstract: We propose the use of motional states of two interacting atoms trapped in a potential stroboscopically engineered by an optical tweezer as a means to implement a qubit-oscillator system, in analogy to those implemented in circuit quantum electrodynamics and trapped ions. In our setting, the center of mass degree of freedom of the atoms plays the role of a photon or phonon mode, while the interacting, relative mode acts as a qubit. No internal state is involved in our system, which makes this motional qubit robust to spin-dependent noise. We show that a universal set of bosonic operations, including displacement, rotation, squeezing, and the corresponding set of gates controlled by the qubit, can be implemented through precise temporal modulation of the optical tweezers. We numerically check that these gates can be generated with high fidelity, and discuss possible schemes for initial state preparation and final state readout. While we restrict the discussion to a single qubit-oscillator module, scalability can be achieved by coupling arrays of atoms via dipolar or Rydberg-dressed interactions.

</details>


### [23] [Nonreciprocal photon blockade in a spinning microwave magnomechanical system through kerr-magnon and optical parametric amplifier](https://arxiv.org/abs/2512.06453)
*S. K. Singh,Mohamed Amazioug,Jia-Xin Peng,Mohammad Khalid*

Main category: quant-ph

TL;DR: 该研究提出在旋转微波磁机械系统中通过Kerr磁子相互作用和光学参量放大器的组合非线性效应实现强光子阻塞，并利用Sagnac-Fizeau位移建立非互易光子阻塞。


<details>
  <summary>Details</summary>
Motivation: 非常规量子反聚束效应因其能产生高质量单量子源而备受关注。本研究旨在实现和主动控制旋转微波磁机械系统中的强光子阻塞，探索非互易量子相关性的实现途径。

Method: 结合Kerr诱导的磁子相互作用和光学参量放大器的非线性效应，利用Sagnac-Fizeau位移建立非互易光子阻塞。通过薛定谔方程的解析解近似等时二阶关联函数，并与Lindblad主方程的全数值解进行比较。

Result: 在弱耦合约束下研究了热噪声、探测场振幅和磁偶极耦合强度的影响。使用Mandel参数表征系统的非经典性，并分析了二阶关联函数的时间演化。成功实现了旋转微波磁机械系统中的非互易光子阻塞。

Conclusion: 该工作为在非线性旋转微波磁机械系统中实现非互易光子阻塞提供了一条途径，展示了通过量子干涉效应控制量子相关性的新方法。

Abstract: Unconventional quantum antibunching, arising from quantum interference effects, represents a notable form of quantum correlation that has attracted significant attention for its ability to generate high-quality single-quantum sources. In this work, we propose a scheme to achieve and actively control strong photon blockade in a spinning microwave magnomechanical system by leveraging the combined nonlinear effects of Kerr-induced magnon interactions and an optical parametric amplifier. By exploiting the Sagnac-Fizeau shift, we establish nonreciprocal photon blockade and verify this effect through a combination of analytical modelling and numerical simulations. To gain intuitive insight into the underlying nonreciprocity, we approximate the equal-time second-order correlation function using the analytical solution of the Schrödinger equation. This analytical result is then compared with the full numerical solution derived from the Lindblad master equation. The influences of thermal noise, the probe field amplitude, and the magnetic-dipole coupling strength are investigated within the constraints of the weak-coupling regime. The system's nonclassicality is characterized using the Mandel parameter, complemented by an analysis of the time evolution of the second-order correlation function. Our work provides a pathway for realizing nonreciprocal photon blockade in a nonlinear spinning microwave magnomechanical system.

</details>


### [24] [Scheduling Lattice Surgery with Magic State Cultivation](https://arxiv.org/abs/2512.06484)
*Steven Hofmeyr,Mathias Weiden,Justin Kalloor,John Kubiatowicz,Costin Iancu*

Main category: quant-ph

TL;DR: Pure Magic调度方法通过动态重新利用魔法态培养量子比特进行路由操作，消除了专用总线基础设施，提高了容错量子计算的调度效率。


<details>
  <summary>Details</summary>
Motivation: 现有调度方法使用专用总线量子比特进行路由和分离的外围辅助量子比特工厂进行魔法态制备，导致资源利用效率低下。随着魔法态培养技术的发展，制备量子比特可以放置在任何位置。

Method: 提出Pure Magic调度方法，动态重新利用魔法态培养量子比特进行路由操作，消除专用总线基础设施。当量子比特需要用于路由时中断培养过程，自然偏好较短的培养时间，同时确保没有辅助量子比特闲置。

Result: 在17个基准电路上的评估显示，与传统总线路由相比，调度效率提高了19%到223%，平均魔法态制备时间减少了2.6倍到9.7倍。效益随电路并行度增加而扩大。

Conclusion: Pure Magic架构代表了从静态调度到动态、需求驱动调度的范式转变，特别适用于高度并行的量子算法，是容错量子架构的重要进展。

Abstract: Fault-tolerant quantum computation using surface codes relies on efficient scheduling of non-Clifford operations, realized via the injection of magic states produced through a probabilistic process that dominates spacetime costs. Existing scheduling approaches use dedicated bus qubits for routing and separate peripheral ancilla qubit factories for magic state preparation, leading to inefficient resource utilization. With the advent of magic state cultivation, preparation qubits can be placed anywhere within the surface code architecture. We introduce Pure Magic scheduling, which dynamically re-purposes magic state cultivation qubits for routing operations, eliminating dedicated bus infrastructure. By interrupting cultivation when qubits are needed for routing, Pure Magic naturally favors shorter cultivation times while ensuring no ancilla qubit remains idle. Our evaluation across 17 benchmark circuits improves scheduling efficiency by 19% to 223% compared to traditional bus routing and decreases average magic state preparation time by 2.6x to 9.7x. Benefits scale with circuit parallelism, making Pure Magic particularly valuable for highly parallel quantum algorithms. The Pure Magic architecture represents a paradigm shift from static to dynamic, demand-driven scheduling in fault-tolerant quantum architectures.

</details>


### [25] [Efficient quantum algorithm for solving differential equations with Fourier nonlinearity via Koopman linearization](https://arxiv.org/abs/2512.06488)
*Judd Katz,Gopikrishnan Muraleedharan,Abhijeet Alase*

Main category: quant-ph

TL;DR: 本文提出了一种高效的量子算法，用于求解具有傅里叶非线性项的常微分方程，通过Koopman线性化技术扩展了量子算法在非线性ODE求解中的应用范围。


<details>
  <summary>Details</summary>
Motivation: 现有量子算法主要局限于多项式非线性项的ODE求解，这大大限制了其应用范围。本文旨在开发能够处理傅里叶非线性项（如e^{iu}形式）的量子算法，从而显著扩展量子算法在高维非线性ODE求解中的适用性。

Method: 采用Koopman线性化技术（Carleman线性化的推广）来处理傅里叶非线性项，该技术能够将原始非线性ODE转化为高维线性ODE。同时改进了解决方案提取所需的严格耗散条件，并集成了从解状态中读取经典量的方法。

Result: 成功构建了高效的量子算法，能够求解形式为d𝐮/dt = G₀ + G₁e^{i𝐮}的ODE，其中傅里叶非线性项无法表示为有限多项式之和。该方法为更广泛的高维非线性ODE提供了量子求解途径。

Conclusion: 该研究为开发适用于更广泛非线性ODE类的高效量子算法开辟了新途径，显著扩展了量子算法在非线性微分方程求解中的应用范围，具有重要的理论和应用价值。

Abstract: Quantum algorithms offer an exponential advantage with respect to the number of dependent variables for solving certain nonlinear ordinary differential equations (ODEs). These algorithms typically begin by transforming the original nonlinear ODE into a higher-dimensional linear ODE using a linearization technique, most commonly Carleman linearization. Existing works restrict their analysis to ODEs where the nonlinearities are polynomial functions of the dependent variables, significantly limiting their applicability. In this work we construct an efficient quantum algorithm for solving ODEs with `Fourier' nonlinear terms expressible as $d{\bf u}/dt = G_0 + G_1 e^{i{\bf u}}$, where ${\bf u}$ denotes a vector of $n$ complex variables evolving with $t$, $G_0$ is an $n$-dimensional complex vector, $G_1$ is an $n \times n$ complex matrix and $e^{i{\bf u}}$ denotes the vector with entries $\{e^{iu_j}\}$. To tackle the Fourier nonlinear term, which is not expressible as a finite sum of polynomials of ${\bf u}$, our algorithm employs a generalization of the Carleman linearization technique known as Koopman linearization. We also make other methodological advances towards relaxing the stringent dissipativity condition required for efficient solution extraction and towards integrated readout of classical quantities from the solution state. Our results open avenues to the development of efficient quantum algorithms for a significantly wider class of high-dimensional nonlinear ODEs, thereby broadening the scope of their applications.

</details>


### [26] [High-harmonic generation driven by temporal-mode quantum states of light](https://arxiv.org/abs/2512.06602)
*Juan M. González-Monge,Johannes Feist*

Main category: quant-ph

TL;DR: 该研究为量子光驱动的高次谐波生成建立了理论框架，通过时间模式展开解决了平面波处理的局限性，发现自由空间HHG中量子效应可忽略，并探讨了纳米光子环境中实现量子强场效应的可能性。


<details>
  <summary>Details</summary>
Motivation: 现有高次谐波生成理论主要基于单平面波模式处理，存在非归一化无限平面波的概念不一致问题，且无法准确描述实际脉冲配置。需要建立更完整的理论框架来评估量子光驱动HHG中的真实量子效应。

Method: 基于电磁场的时间模式展开建立理论框架，将单平面波模式处理扩展到实际脉冲配置。推导了量化单模式近似偏差的修正因子，并通过分析典型HHG强度下的光子数来评估量子效应的重要性。

Result: 修正因子在典型HHG强度（~10^14 W/cm²）下低于10^-4，表明自由空间HHG中量子效应可忽略。任何量子光驱动的自由空间HHG都可以通过半经典计算在Husimi分布上平均来准确描述。量子效应可忽略的原因是达到HHG强度所需的光子数极大（~10^11），使得量子涨落微不足道。

Conclusion: 自由空间高次谐波生成中观察不到真实的量子效应，因为所需的高光子数使量子涨落可忽略。然而，具有超小模式体积的纳米光子环境可能为展示量子强场过程提供平台，其中少光子过程可能表现出真实的量子特征。

Abstract: We develop a theoretical framework for high-harmonic generation (HHG) driven by quantum states of light based on a temporal-mode expansion of the electromagnetic field. This approach extends previous single plane-wave mode treatments to realistic pulse configurations, resolving conceptual inconsistencies arising from non-normalizable infinite plane waves and establishing consistency between analytical and numerical methods. We derive a correction factor that quantifies deviations from the single-mode approximation and show that it remains below $10^{-4}$ for intensities typical of HHG ($\sim 10^{14}~$W/cm$^2$). This result confirms that free-space HHG driven by any quantum state of light is accurately described by averaging semi-classical calculations over the Husimi distribution, with no observable genuine quantum effects. The absence of such effects is attributed to the large photon numbers ($\sim 10^{11}$) required to reach HHG intensities in free space, which render quantum fluctuations negligible. We discuss nanophotonic environments with ultrasmall mode volumes as potential platforms where few-photon strong-field processes could exhibit genuine quantum signatures.

</details>


### [27] [Fault-Tolerant Information Processing with Quantum Weak Measurement](https://arxiv.org/abs/2512.06619)
*Qi Song,Hongjing Li,Chengxi Yu,Jingzheng Huang,Ding Wang,Peng Huang,Guihua Zeng*

Main category: quant-ph

TL;DR: 提出一种基于量子弱测量的容错信息处理方法，通过选择微小角度的正交后选择测量基和优化测量结果组合作为解码规则，在噪声信道中实现最小失真信号恢复。


<details>
  <summary>Details</summary>
Motivation: 噪声严重影响信息获取、传输、处理和存储的可靠性，需要开发有效的噪声抑制方法以提高量子信息系统的鲁棒性。

Method: 采用量子弱测量技术，选择成对正交的后选择测量基（具有各种微小角度）和测量结果的最优组合作为解码规则，在噪声信道中传输后恢复受保护的信号。

Result: 通过两能级叠加态或EPR态在随机电报噪声和退相干噪声信道中传输的典型示例，均方误差失真可接近0，容错能力可达1（使用有限量子资源）。实验中使用经典相干光和量子相干态编码信息验证了方法的有效性。

Conclusion: 该方法为长距离量子通信、高灵敏度量子传感和精确量子计算中的噪声抑制提供了潜在解决方案。

Abstract: Noise is an important factor that influences the reliability of information acquisition, transmission, processing, and storage. In order to suppress the inevitable noise effects, a fault-tolerant information processing approach via quantum weak measurement is proposed, where pairwise orthogonal postselected measurement bases with various tiny angles and optimal compositions of measured results are chosen as a decoding rule. The signal to be protected can be retrieved with a minimal distortion after having been transmitted through a noisy channel. Demonstrated by typical examples of encoding signal on two-level superposition state or Einstein-Podolsky-Rossen state transmitted through random telegraph noise and decoherence noises channel, the mean squared error distortion may be close to $0$ and the fault-tolerant capability could reach $1$ with finite quantum resources. To verify the availability of the proposed approach, classic coherent light and quantum coherent state are used for encoding information in the experiment. Potentially, the proposed approach may provide a solution for suppressing noise effects in long-distance quantum communication, high-sensitivity quantum sensing, and accurate quantum computation.

</details>


### [28] [Non-Orthogonal Multiple-Access for Coherent-State Optical Quantum Communications Under Lossy Photon Channels](https://arxiv.org/abs/2512.06739)
*Zhichao Dong,Xiaolin Zhou,Yongkang Chen,Wei Ni,Ekram Hossain,Xin Wang*

Main category: quant-ph

TL;DR: 提出基于SIC的Kennedy接收机用于上行NOMA-OQC系统，开发新的相干态功率分配算法，显著提升系统总速率20%以上


<details>
  <summary>Details</summary>
Motivation: 相干态在光量子通信中应用日益广泛，其固有的非正交性自然适合实现多用户非正交多址接入，但这一方向在文献中尚未得到充分探索

Method: 提出基于SIC的Kennedy接收机，严格推导系统渐近总速率，考虑大气湍流、背景噪声和损耗光子信道影响，通过变量替换和连续凸逼近优化相干态平均光子数

Result: 开发了适用于中小用户数的相干态功率分配算法及其低复杂度变体，仿真显示相比现有方案，系统总速率提升超过20%

Conclusion: 成功将NOMA概念引入相干态光量子通信系统，提出的算法能有效提升多用户系统的总速率性能，为光量子通信的多用户接入提供了新方案

Abstract: Coherent states have been increasingly considered in optical quantum communications (OQCs). With the inherent non-orthogonality of coherent states, non-orthogonal multiple-access (NOMA) naturally lends itself to the implementation of multi-user OQC. However, this remains unexplored in the literature. This paper proposes a novel successive interference cancellation (SIC)-based Kennedy receiver for uplink NOMA-OQC systems, along with a new approach for power allocation of the coherent states emitted by users. The key idea is to rigorously derive the asymptotic sum-rate of the considered systems, taking into account the impact of atmospheric turbulence, background noise, and lossy photon channel. With the asymptotic sum-rate, we optimize the average number of photons (or powers) of the coherent states emitted by the users. Variable substitution and successive convex approximation (SCA) are employed to convexify and maximize the asymptotic sum-rate iteratively. A new coherent-state power allocation algorithm is developed for a small-to-medium number of users. We further develop its low-complexity variant using adaptive importance sampling, which is suitable for scenarios with a medium-to-large number of users. Simulations demonstrate that our algorithms significantly enhance the sum-rate of uplink NOMA-OQC systems using coherent states by over 20\%, compared to their alternatives.

</details>


### [29] [Non-Orthogonal Multiple Access-Based Continuous-Variable Quantum Key Distribution: Secret Key Rate Analysis and Power Allocation](https://arxiv.org/abs/2512.06748)
*Zhichao Dong,Xiaolin Zhou,Huang Peng,Wei Ni,Ekram Hossain,Xin Wang*

Main category: quant-ph

TL;DR: 该论文提出了一种基于非正交多址接入的连续变量量子密钥分发系统，通过功率分配算法最大化系统总密钥率，在恶意量子攻击下实现了比正交多址方案高23%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决大规模量子互联网中多用户量子密钥分发在恶意量子攻击下的安全问题，特别是需要提高系统总密钥率以支持更多用户同时进行安全通信。

Method: 提出上行链路NOMA-CVQKD系统，使用高斯调制相干态和基于量子连续干扰消除的外差接收器。通过熵功率不等式和最大熵原理推导合法用户可达密钥率的闭式渐近界，基于Holevo信息推导窃听者截获信息界。开发基于连续凸近似的功率分配算法，在集体攻击下最大化系统总密钥率。

Result: 仿真结果显示：1）所提NOMA-CVQKD系统比量子正交多址接入方案总密钥率提升高达23%；2）在过量噪声方差0.1时支持16个用户；3）在不同湍流强度和传输距离下保持鲁棒性。

Conclusion: 该研究成功开发了一种高效的多用户量子密钥分发系统，通过创新的NOMA-CVQKD架构和优化的功率分配算法，在恶意量子攻击下显著提升了系统性能，为大规模量子互联网的实现提供了关键技术支撑。

Abstract: We address the multi-user quantum key distribution (QKD) problem under malicious quantum attacks, which is critical for realizing a large-scale quantum Internet. This paper maximizes the sum secret key rate (SKR) of a novel uplink non-orthogonal multiple access based continuous-variable QKD (NOMA-CVQKD) system under collective attacks. The proposed system uses Gaussian-modulated coherent states and a quantum successive interference cancellation based heterodyne receiver. We derive closed-form asymptotic bounds for the legitimate users' achievable key rates via the entropy power inequality and maximum entropy principle, as well as for the eavesdropper's intercepted information based on Holevo information. A successive convex approximation based power allocation algorithm is developed to maximize the asymptotic sum SKR of the NOMA-CVQKD system under collective attacks, with guaranteed convergence to a locally optimal Karush-Kuhn-Tucker solution. Simulation results show that the proposed NOMA-CVQKD system with the power allocation algorithm achieves up to 23% higher sum SKR than quantum-orthogonal multiple access, supports 16 users at excess noise variance 0.1, and remains robust under varying turbulence intensities and transmission distances.

</details>


### [30] [Virtual Qudits for Simon's Problem: Dimension-Lifted Algorithms on Qubit Hardware](https://arxiv.org/abs/2512.06756)
*Abed Semre,Steven Frankel*

Main category: quant-ph

TL;DR: 该论文提出了一种在量子比特硬件上模拟量子比特版本的Simon算法的一般构造方法，通过定义虚拟量子比特并使用受控置换和量子比特相位操作来实现。


<details>
  <summary>Details</summary>
Motivation: Simon问题虽然存在指数级量子加速，但当前量子设备仅支持量子比特。为了在现有硬件上实现更高维度的量子算法，需要一种将量子比特算法扩展到量子比特设备的方法。

Method: 提出了一种通用构造方法：定义通过受控置换和量子比特相位操作实现的虚拟量子比特；构建维度提升的oracle，在维度d中编码隐藏位移；展示如何仅使用量子比特门实现其作用；数学验证提升后的电路能重现正确的测量统计。

Result: 数学验证了提升电路能正确重现测量统计，分析了深度开销与d的权衡关系，并通过QuTiP对示例值进行了数值模拟，证明了方法的有效性。

Conclusion: 该方法展示了如何将更高维度的结构嵌入到量子比特设备中，为将量子比特算法扩展到当前硬件提供了一种通用方法。

Abstract: Simon's problem admits an exponential quantum speedup, but current quantum devices support only qubits. This work introduces a general construction for simulating qudit versions of Simon's algorithm on qubit hardware by defining virtual qudits implemented through controlled permutations and qudit phase operations. We build a dimension lifted oracle that encodes the hidden shift in dimension d and show how to realize its action using only qubit gates. We mathematically verify that the lifted circuit reproduces the correct measurement statistics, analyze the depth overhead tradeoffs as a function of d, and provide numerical simulations in QuTiP for example values. Our approach demonstrates how higher-dimensional structures can be embedded into qubit devices and provides a general method for extending qudit algorithms to current hardware.

</details>


### [31] [Enhancing ground-state interaction strength of neutral atoms via Floquet stroboscopic dynamics](https://arxiv.org/abs/2512.06760)
*Y. Wei,M. Artoni,G. C. La Rocca,J. H. Wu,X. Q. Shao*

Main category: quant-ph

TL;DR: 通过Floquet调制里德堡原子系综增强中性原子基态相互作用，实现高保真度W态制备，应用于单光子源生成


<details>
  <summary>Details</summary>
Motivation: 中性原子系统具有长相干时间，但其固有的弱基态相互作用限制了可扩展量子模拟和计算的发展，需要增强基态相互作用强度

Method: 提出通过Floquet调制里德堡原子系综的方法，每个Floquet周期包含基态耦合和从基态到里德堡态的脉冲驱动

Result: 理论分析和数值模拟表明，经过特定演化时间后，里德堡系综中的中性原子可以在基态流形中集体形成W态，即使里德堡相互作用强度远低于阻塞机制，保真度仍然很高

Conclusion: 该机制为里德堡原子系综中的量子态制备提供了高效且高度可控的方法，显著提高了量子态工程的准确性和稳定性，为单光子生成提供了良好控制的量子环境

Abstract: Neutral atom systems are promising platforms for quantum simulation and computation, owing to their long coherence times. However, their intrinsically weak ground-state interactions pose a major limitation to the advancement of scalable quantum simulation and computation. To address this challenge, we propose an approach to enhancing the ground-state interaction strength of neutral atoms via Floquet modulation of a Rydberg atomic ensemble. Each Floquet period consists of ground-state coupling followed by a pulse driving the transition from the ground state to the Rydberg state. Theoretical analysis and numerical simulations demonstrate that after a defined evolution time, neutral atoms within Rydberg ensembles can collectively form a $W$ state in the ground-state manifold. Even when the Rydberg interaction strength is far below the blockade regime, the fidelity remains remarkably high. Finally, we analyze the application of this scheme in the preparation of single-photon sources. In general, our proposed mechanism offers an efficient and highly controllable method for quantum state preparation within the Rydberg atomic ensembles, significantly enhancing the accuracy and stability of quantum state engineering while providing a well-controlled quantum environment for single-photon generation.

</details>


### [32] [Physics Informed Generative Machine Learning for Accelerated Quantum-centric Supercomputing](https://arxiv.org/abs/2512.06858)
*Chayan Patra,Dibyendu Mondal,Sonaldeep Halder,Dipanjali Halder,Mostafizur Rahaman Laskar,Richa Goel,Rahul Maitra*

Main category: quant-ph

TL;DR: PIGen-SQD是一种量子中心超计算框架，结合生成式机器学习和物理信息配置筛选，用于准确重建费米子态，提高量子硬件噪声环境下的鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 量子中心超计算框架（如SQD）在解决挑战性问题方面具有巨大潜力，但噪声量子硬件会产生错误样本，需要鲁棒高效的配置恢复策略来实现可扩展的QCSC流程。

Method: 提出PIGen-SQD工作流，结合生成式机器学习能力和物理信息配置筛选（通过隐式低秩张量分解），使用高效的微扰度量与硬件样本提供与目标态的显著重叠，引导生成模型在希尔伯特空间的主导区域进行随机探索。

Result: 在IBM Heron R2量子处理器上的数值实验表明，该协同工作流产生紧凑、高保真度的子空间，显著降低对角化成本，同时在强电子关联下保持化学精度。

Conclusion: 通过将经典多体直觉直接嵌入生成式机器学习模型，PIGen-SQD提高了QCSC算法的鲁棒性和可扩展性，为在实用规模量子硬件上进行化学可靠的量子模拟提供了有前景的途径。

Abstract: Quantum centric supercomputing (QCSC) framework, such as sample-based quantum diagonalization (SQD) holds immense promise toward achieving practical quantum utility to solve challenging problems. QCSC leverages quantum computers to perform the classically intractable task of sampling the dominant fermionic configurations from the Hilbert space that have substantial support to a target state, followed by Hamiltonian diagonalization on a classical processor. However, noisy quantum hardware produces erroneous samples upon measurements, making robust and efficient configuration-recovery strategies essential for a scalable QCSC pipeline. Toward this, in this work, we introduce PIGen-SQD, an efficiently designed QCSC workflow that utilizes the capability of generative machine learning (ML) along with physics-informed configuration screening via implicit low-rank tensor decompositions for accurate fermionic state reconstruction. The physics-informed pruning is based on a class of efficient perturbative measures that, in conjunction with hardware samples, provide a substantial overlap with the target state. This distribution induces an anchoring effect on the generative ML models to stochastically explore only the dominant sector of the Hilbert space for effective identification of additional important configurations in a self-consistent manner. Our numerical experiments performed on IBM Heron R2 quantum processors demonstrate this synergistic workflow produces compact, high-fidelity subspaces that substantially reduce diagonalization cost while maintaining chemical accuracy under strong electronic correlations. By embedding classical many body intuitions directly into the generative ML model, PIGen-SQD advances the robustness and scalability of QCSC algorithms, offering a promising pathway toward chemically reliable quantum simulations on utility-scale quantum hardware.

</details>


### [33] [Single Flux Quantum Circuit Operation at Millikelvin Temperatures](https://arxiv.org/abs/2512.06895)
*Jason Walter,Adam C. Weis,Kan-Ting Tsai,Meng-Ju Yu,Naveen Katam,Alex F. Kirichenko,Oleg A. Mukhanov,Shu-Jen Han,Igor V. Vernik*

Main category: quant-ph

TL;DR: 论文研究了超导单磁通量子（SFQ）电路在毫开尔文温度下用于量子比特控制的性能变化，发现相比4.2K，毫开尔文温度下偏置裕度减小，最佳偏置电流增加约15%，可通过热退火恢复。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算处理器规模扩大，需要开发低温电子学来解决系统扩展的挑战。SFQ电路作为替代传统室温电子学的方案，需要适应毫开尔文温度以靠近量子处理器工作，实现数字量子比特控制、读取和协同处理。

Method: 采用SEEQC的SFQuClass数字量子管理方法，将能量高效的ERSFQ电路和量子比特集成在多芯片模块中。系统测试了从4K到10mK温度范围内各种ERSFQ单元电路以及更复杂的可编程计数器和解复用器电路，并测试了相关模拟过程控制监测器（PCMs）。

Result: 在毫开尔文温度下，偏置裕度减小，最佳偏置电流值相比4.2K增加约15%。通过热退火降低约瑟夫森结临界电流Ic可以恢复裕度。PCM测试显示约瑟夫森结临界电流从4.2K到毫开尔文温度增加约15%，与理论和数字电路测量结果一致。

Conclusion: SFQ电路在毫开尔文温度下工作性能会发生变化，但通过热退火可以调整电路参数以适应低温环境。研究结果为SFQ电路在量子计算低温环境中的应用提供了重要指导。

Abstract: As quantum computing processors increase in size, there is growing interest in developing cryogenic electronics to overcome significant challenges to system scaling. Single flux-quantum (SFQ) circuits offer a promising alternative to remote, bulky, and power-hungry room temperature electronics. To meet the need for digital qubit control, readout, and co-processing, SFQ circuits must be adapted to operate at millikelvin temperatures near quantum processors. SEEQC's SFQuClass digital quantum management approach proximally places energy-efficient SFQ (ERSFQ) circuits and qubits in a multi-chip module. This enables extremely low power dissipation, compatible with a typical dilution cryostat's limited cooling power, while maintaining high processing speed and low error rates. We report on systematic testing from 4 K to 10 mK of a comprehensive set of ERSFQ cells, as well as more complex circuits such as programmable counters and demultiplexers used in digital qubit control. We compare the operating margins and error rates of these circuits and find that, at millikelvin, bias margins decrease and the center of the margins (i.e., the optimal bias current value) increases by ~15%, compared to 4.2 K. The margins can be restored by thermal annealing by reducing Josephson junction (JJ) critical current Ic. To provide guidance for how circuit parameters vary from 4.2 K to millikelvin, relevant analog process control monitors (PCMs) were tested in the temperature range of interest. The measured JJ critical current (of the PCM JJ arrays) increases by ~15% when decreasing temperature from 4.2 K to millikelvin, in good agreement with both theory and the empirically measured change in the center of bias margins for the tested digital circuits.

</details>


### [34] [Optimal Transport of a Free Quantum Particle and its Shape Space Interpretation](https://arxiv.org/abs/2512.06940)
*Bernadette Lessel*

Main category: quant-ph

TL;DR: 该论文使用最优传输理论分析自由薛定谔方程的解，证明其定义的测度曲线是Wasserstein空间中的绝对连续曲线，计算了最优传输映射、Wasserstein距离和Fisher信息，并展示了该解在形状空间中的几何特性。


<details>
  <summary>Details</summary>
Motivation: 研究自由薛定谔方程的解与最优传输理论之间的联系，探索量子力学中的概率测度演化在Wasserstein空间中的几何性质，以及如何将其自然解释为形状空间中的测地线。

Method: 采用最优传输理论方法，分析自由薛定谔方程解定义的测度曲线μ_t，证明其在Wasserstein空间W₂(ℝ³)中的绝对连续性，计算最优传输映射、Wasserstein距离和Fisher信息，并将结果推广到形状空间。

Result: 证明了自由薛定谔方程解定义的测度曲线μ_t是Wasserstein空间中的绝对连续曲线，计算了最优传输映射、Wasserstein距离和Fisher信息的具体表达式，并发现该曲线在形状空间中仍然保持最短路径测地线的性质。

Conclusion: 自由薛定谔方程的解可以通过最优传输理论进行几何化描述，其在Wasserstein空间中形成绝对连续曲线，在形状空间中保持测地线性质，这为量子力学与几何分析之间的交叉研究提供了新的视角。

Abstract: A solution of the free Schrödinger equation is investigated by means of Optimal transport. The curve of probability measures $μ_t$ this solution defines is shown to be an absolutely continuous curve in the Wasserstein space $W_2(\mathbb{R}^3)$. The optimal transport map from $μ_t$ to $μ_s$, the cost for this transport (i.e. the Wasserstein distance) and the value of the Fisher information along $μ_t$ are being calculated. It is finally shown that this solution of the free Schrödinger equation can naturally be interpreted as a curve in so-called Shape space, which forgets any positioning in space but only describes properties of shapes. In Shape space, $μ_t$ continues to be a shortest path geodesic.

</details>


### [35] [Suppressing Fast Dipolar Noise in Solid-State Spin Qubits](https://arxiv.org/abs/2512.06948)
*Jaime García Oliván,Ainitze Biteri-Uribarren,Oliver T. Whaites,Jorge Casanova*

Main category: quant-ph

TL;DR: 提出了一种名为Hybrid-LG的解耦机制，能够抑制自旋量子比特中的快速噪声，相比标准技术将NV中心相干时间至少提高两倍。


<details>
  <summary>Details</summary>
Motivation: 固态平台中自旋退相干主要由晶格中的磁活性环境主导，限制了其应用。标准动态解耦技术（如Hahn回波）虽然能延长中心自旋相干性，但无法抑制由浴内强偶极相互作用产生的快速噪声。

Method: 提出Hybrid-LG解耦机制，通过抑制浴内偶极相互作用来减少快速噪声。使用高效的自研CCE模拟验证方法，研究金刚石中氮空位中心与大量密集的替代氮顺磁杂质浴耦合的体系。

Result: Hybrid-LG机制相比标准技术（包括P1中心驱动）将NV中心相干时间至少提高两倍，且不需要额外的控制功率。

Conclusion: Hybrid-LG机制能有效抑制固态量子平台中的快速噪声，显著延长自旋量子比特的相干时间，为量子技术应用提供了重要资源。

Abstract: Spin qubit coherence is a fundamental resource for the realization of quantum technologies. For solid-state platforms, spin decoherence is dominated by the magneto-active environment in the lattice, limiting their applicability. While standard dynamical decoupling techniques, such as the Hahn echo, extend central spin coherence, they fail to suppress the fast noise arising from strong dipolar interactions within the bath. Here, we present a decoupling mechanism, Hybrid-LG, that suppresses intra-bath dipolar interactions -- thus, fast noise acting on spin qubits- and demonstrate its effectiveness in extending spin coherence through efficient in-house CCE simulations. Specifically, we investigate one of the most widely exploited solid-state quantum platforms: an ensemble of nitrogen-vacancy (NV) centers in diamond coupled to a large and dense bath of substitutional nitrogen paramagnetic impurities (P1 centers). Our results reveal at least a twofold enhancement in NV coherence time relative to standard techniques including P1 center driving, without requiring additional control power.

</details>


### [36] [Quantum Correlation Assisted Cooling of Microwave Cavities Below the Ambient Temperature](https://arxiv.org/abs/2512.06996)
*Daryoosh Vashaee,Jahanfar Abouie*

Main category: quant-ph

TL;DR: 该论文提出了一种利用内部相关的二能级系统对微波腔进行冷却的理论框架，通过分析单原子和双原子两种耦合构型，发现双原子方案能实现量子增强冷却，使腔温显著低于储层温度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种新型的微波腔冷却机制，利用内部相关的原子对流实现量子增强冷却，为可扩展量子硬件中的微波模式提供自主、片上制冷方案。

Method: 从声子束缚腔与顺序注入原子对相互作用的Lindblad模型出发，推导了稳态腔占据数和有效温度的闭式表达式。分析了两种耦合构型：单原子构型（每对中只有一个原子与腔相互作用）和双原子构型（两个原子集体耦合）。

Result: 单原子模型只能将腔冷却到低于声子浴温度但无法低于储层温度，而双原子方案通过原子对相关性修改腔的向上和向下跃迁速率，在弱声子阻尼条件下能使稳态温度显著低于储层温度。参数空间分析识别了共振附近的冷却谷以及储层主导和声子主导机制之间的交叉区域。

Conclusion: 双原子构型实现了单原子情况下不存在的真正量子增强冷却机制。实验上可使用两个超导量子比特在3D腔内重复制备、耦合和重置，MHz速率的相互作用循环支持工程化储层将腔温降至50-120 mK，即使低温恒温器在~1 K，为可扩展量子硬件中微波模式的自主片上制冷提供了途径。

Abstract: We develop a theoretical framework for cooling a microwave cavity mode using a Poisson stream of internally correlated pairs of two-level systems and analyze its performance under realistic dissipation. Starting from a Lindblad model of a phonon-tethered cavity interacting with sequentially injected atom pairs, we derive closed-form expressions for the steady-state cavity occupation and effective temperature. Two coupling geometries are examined: a one-atom configuration, where only one member of each pair interacts with the cavity, and a two-atom configuration, where both atoms couple collectively. The single-atom model enables cooling below the phonon bath but not below the reservoir temperature, whereas the two-atom scheme exhibits enhanced refrigeration - pair correlations modify the cavity's upward and downward transition rates so that the steady-state temperature can fall well below that of the reservoir for weak phonon damping. We map the parameter space including detuning, coupling strength, damping, and intra-pair exchange, identifying cooling valleys near resonance and the crossover between reservoir- and phonon-dominated regimes. The two-atom configuration thus realizes a genuine quantum-enhanced cooling mechanism absent in the single-atom case. We further outline an experimental implementation using two superconducting qubits repeatedly prepared, coupled, and reset inside a 3D cavity. Realistic reset and flux-tuning protocols support MHz-rate interaction cycles, enabling engineered reservoirs to impose cavity temperatures of 50-120 mK even when the cryostat is at ~1 K, offering a pathway to autonomous, on-chip refrigeration of microwave modes in scalable quantum hardware.

</details>


### [37] [From Quantum Chaos to Classical Chaos via Gain-Induced Measurement Dynamics in a Photon Gas](https://arxiv.org/abs/2512.07045)
*Violetta Sharoglazova,Marius Puplauskis,Lotte Hof,Jan Klaers*

Main category: quant-ph

TL;DR: 量子混沌光子气体中的增益竞争作为量子测量机制，从初始叠加态中随机选择单一运动模式，自然产生经典混沌行为


<details>
  <summary>Details</summary>
Motivation: 探索量子力学如何演化出经典混沌行为，解决量子系统如何表现出对初始条件的指数敏感度这一核心开放问题

Method: 识别混沌光子气体中的增益竞争作为操作性的量子测量机制，通过随机非线性放大从初始叠加态中选择单一运动模式

Result: 该机制自然产生经典混沌行为，特别是对初始条件的敏感性，为混沌系统中的量子-经典转变提供了具体物理机制

Conclusion: 量子测量的关键方面（状态投影、玻恩规则式选择、不可逆性）可以从内在增益动力学中自然涌现，为量子-经典过渡提供了具体物理机制

Abstract: How classical chaos emerges from quantum mechanics remains a central open question, as the unitary evolution of isolated quantum systems forbids exponential sensitivity to initial conditions. A key insight is that this quantum-classical link is provided by measurement processes. In this work, we identify gain competition in a chaotic photon gas as an operational quantum measurement that selects single motional modes from an initial superposition through stochastic, nonlinear amplification. We show that this mechanism naturally gives rise to classical chaotic behavior, most notably sensitivity to initial conditions. Our results provide a concrete physical mechanism for the quantum-classical transition in a chaotic system and demonstrate that essential aspects of quantum measurement-state projection, Born-rule-like selection, and irreversibility-can naturally emerge from intrinsic gain dynamics.

</details>


### [38] [The uncharted space of non-Hermitian solutions to the Hartree-Fock and Kohn-Sham equations](https://arxiv.org/abs/2512.07048)
*Matthias Ernzerhof,Mohamed Loutis,Pierre-Olivier Roy,Didier Mayou*

Main category: quant-ph

TL;DR: 论文发现Hartree-Fock和Kohn-Sham方程存在一类新的解，这些解对应于单电子与其余N-1电子系统之间的电流密度交换，扩展了传统量子化学方法的适用范围。


<details>
  <summary>Details</summary>
Motivation: 传统量子化学方法（HF和KS）通常只考虑封闭系统，但实际物理化学问题常涉及系统与环境耦合。论文发现即使在没有外部环境的情况下，HF/KS方程中的单电子与其余电子之间也可能发生电流交换，这为扩展这些方法的应用范围提供了新视角。

Method: 采用非厄米量子力学框架，将Hartree-Fock和Kohn-Sham方法重新表述为开放系统问题。通过理论分析发现，在自洽场计算中，单电子与其余N-1电子系统之间存在电流密度交换的可能性，从而得到一类新的解。

Result: 发现了HF和KS方程的一类新解，这些解对应于开放系统条件下的自洽态。这些解具有物理意义，能够描述电子密度在单电子与其余电子系统之间的转移现象，扩展了传统量子化学方法的应用范围。

Conclusion: 即使在传统认为的封闭系统中，HF和KS方程也存在开放系统解，这些解对应着单电子与其余电子之间的电流交换。这一发现不仅揭示了量子化学计算方法的新维度，还为处理更广泛的物理化学问题提供了理论工具。

Abstract: Many problems in physical chemistry involve systems that are coupled to an environment, such as a molecule interacting with an adjacent surface, possibly resulting in meta-stable molecular states where electron density is transferred to the surface. Such systems can be described by non-Hermitian quantum mechanics (NHQM), where the Hamiltonian includes dissipative terms. Within NHQM, one can also formulate the Hartree-Fock (HF) and Kohn-Sham (KS) methods and, as in the conventional theory, an effective independent-particle picture is employed. The crucial observation of the present work is that even for systems that are not coupled to an environment, in the HF or KS equation a single electron is coupled to a bath of the remaining electrons which can act as an environment, opening up the possibility for the exchange of current density between the one-electron and the remaining N-1 electron system. The corresponding self-consistent states represent a new uncharted space of solutions to the HF and KS equations. We show that the additional solutions can have a physical interpretation and thus extend the range of problems HF and KS can be applied to. If open-system HF and KS calculations are performed, the new class of solutions is always encountered but this has also not been noted previously.

</details>


### [39] [Timing quantum emission: coherence, superradiance, and entanglement in order](https://arxiv.org/abs/2512.07055)
*Nur Fadhillah Binti Rahimi,Norman Koo Tze Wei,Daniel Schumayer,Christopher Gies,Leong Chuan Kwek,David. A. W. Hutchinson*

Main category: quant-ph

TL;DR: 研究紧密排列量子发射器中超辐射的短期时间动力学，发现相干性、超辐射和纠缠的极值出现存在明确的时间层次：相对相干性最先发展，然后是相关发射峰值，接着是最小纠缠，最后是相关退相干。


<details>
  <summary>Details</summary>
Motivation: 基于Dicke 1954年的框架，研究紧密排列量子发射器中超辐射过程的短期时间动力学，探索相干性、超辐射和纠缠之间的时间演化关系。

Method: 在Dicke框架基础上，分析紧密排列量子发射器中超辐射的时间演化过程，研究相干性、相关发射、纠缠和相关退相干之间的时间层次关系。

Result: 发现了一个明确的时间层次：相对相干性最先发展，随后是相关发射峰值，接着是最小纠缠，最后是相关退相干。当相关退相干可忽略时，纠缠和相关发射在时间上紧密关联。

Conclusion: 增强的相对相干性启动了相关发射过程，当相关退相干可忽略时，纠缠和相关发射在时间上紧密耦合，这为理解量子发射器集体行为的时间演化提供了新见解。

Abstract: We investigate the short-term temporal dynamics of superradiance in closely spaced quantum emitters. Building on Dicke's 1954 framework, we analyze the sequential emergence of coherence, superradiance, and entanglement, revealing a distinct temporal hierarchy in their extremal values: relative coherence develops first, followed by the peak of correlated emission, then minimal entanglement, and finally correlated dephasing. These findings suggest that enhanced relative coherence initiates correlated emission and when correlated dephasing is negligible, entanglement and correlated emission become tightly linked in time.

</details>


### [40] [Beam search decoder for quantum LDPC codes](https://arxiv.org/abs/2512.07057)
*Min Ye,Dave Wecker,Nicolas Delfosse*

Main category: quant-ph

TL;DR: 提出基于束搜索启发式算法和置信传播的量子LDPC码解码器，相比传统BP-OSD解码器在逻辑错误率和运行时间上有显著改进


<details>
  <summary>Details</summary>
Motivation: 现有量子LDPC码解码器（如BP-OSD）在性能和效率方面仍有改进空间，需要更高效的解码方案来支持大规模量子计算

Method: 提出基于束搜索启发式算法的解码器，使用置信传播作为引导，通过调整束宽度等参数平衡速度与精度，适用于所有量子LDPC码

Result: 在[[144,12,12]]双变量自行车码的电路级噪声模拟中，束宽度64时逻辑错误率降低17倍；束宽度8时达到相同逻辑错误率但99.9百分位运行时间减少26.2倍；束宽度32时逻辑错误率降低5.6倍且运行时间低于1ms

Conclusion: 束搜索解码器在性能和效率上显著优于传统BP-OSD解码器，特别适合离子阱架构，仅需少量CPU核心即可支持大规模量子计算

Abstract: We propose a decoder for quantum low density parity check (LDPC) codes based on a beam search heuristic guided by belief propagation (BP). Our beam search decoder applies to all quantum LDPC codes and achieves different speed-accuracy tradeoffs by tuning its parameters such as the beam width. We perform numerical simulations under circuit level noise for the $[[144, 12, 12]]$ bivariate bicycle (BB) code at noise rate $p=10^{-3}$ to estimate the logical error rate and the 99.9 percentile runtime and we compare with the BP-OSD decoder which has been the default quantum LDPC decoder for the past six years. A variant of our beam search decoder with a beam width of 64 achieves a $17\times$ reduction in logical error rate. With a beam width of 8, we reach the same logical error rate as BP-OSD with a $26.2\times$ reduction in the 99.9 percentile runtime. We identify the beam search decoder with beam width of 32 as a promising candidate for trapped ion architectures because it achieves a $5.6\times$ reduction in logical error rate with a 99.9 percentile runtime per syndrome extraction round below 1ms at $p=5 \times10^{-4}$. Remarkably, this is achieved in software on a single core, without any parallelization or specialized hardware (FPGA, ASIC), suggesting one might only need three 32-core CPUs to decode a trapped ion quantum computer with 1000 logical qubits.

</details>


### [41] [Hidden Structural Variants in ALD NbN Superconducting Trilayers Revealed by Atomistic Analysis](https://arxiv.org/abs/2512.07095)
*Prachi Garg,Danqing Wang,Hong X. Tang,Baishakhi Mazumder*

Main category: quant-ph

TL;DR: 该研究通过先进显微技术和机器学习方法，诊断了NbN/AlN/NbN约瑟夫森结中原子尺度缺陷对超导性能的限制，发现电极中的ε-Nb₂N₂纳米夹杂物是导致临界电流密度降低和软准粒子电流转变的主要原因。


<details>
  <summary>Details</summary>
Motivation: 超导薄膜的微观不均匀性是限制量子电路性能和可扩展性的关键瓶颈。虽然全氮化物约瑟夫森结因其潜在的高相干时间和高温操作能力而备受关注，但其性能常受多晶型、杂质和界面质量等局部变化限制。本研究旨在诊断阻碍NbN/AlN/NbN约瑟夫森结发挥全部潜力的原子尺度限制因素。

Method: 采用先进显微技术和机器学习集成方法，结合电学测量分析。通过电阻与结面积的反比关系确认了均匀的势垒厚度，从而将性能限制因素隔离为电极和势垒的结构与化学变化。重点识别了电极中ε-Nb₂N₂纳米夹杂物与主要δ-NbN相的共存现象。

Result: 电学测量显示临界电流密度被抑制且准粒子电流呈现软转变。研究发现电极中存在ε-Nb₂N₂纳米夹杂物与主要δ-NbN相的共存，这些缺陷影响了约瑟夫森结的直流性能，导致未解析的超电流和向正常态的软转变。研究成功建立了从材料缺陷到器件电学特性的相关性。

Conclusion: 通过识别特定的原子尺度缺陷、追溯其起源于初始薄膜成核过程，并将其与有害的电学特征联系起来，本研究建立了材料到器件的相关性，并为相工程提供了有针对性的策略，以实现可重复、高相干性和可扩展的量子器件。

Abstract: Microscopic inhomogeneity within superconducting films is a critical bottleneck hindering the performance and scalability of quantum circuits. All-nitride Josephson Junctions (JJs) have attracted substantial attention for their potential to provide enhanced coherence times and enable higher temperature operation. However, their performance is often limited by local variations caused by polymorphism, impurities, and interface quality. This work diagnoses atomic-scale limitations preventing superconducting NbN/AlN/NbN JJs from reaching their full potential. Electrical measurements reveal suppressed critical current density and soft onset of quasiparticle current. However, inverse proportionality between resistance and junction area confirms homogenous barrier thickness. This isolates structural and chemical variations in electrodes and barrier as the source of performance limitation. The observed characteristics are attributed to complex materials problems: NbN polymorphism, phase coexistence, and oxygen impurities. Using advanced microscopy and machine learning integrated approach, nanoscale inclusions of epsilon-Nb2N2 are found to coexist within dominant delta-NbN electrodes. DC performance of JJs may be affected by these defects, leading to unresolved supercurrent and soft transition to normal state. By identifying specific atomic scale defects, tracing its origin to initial film nucleation, and linking to its detrimental electrical signature, this work establishes a material-to-device correlation and provides targeted strategy for phase engineering towards reproducible, high coherence and scalable quantum devices.

</details>


### [42] [Wigner's Frame](https://arxiv.org/abs/2512.07101)
*Emily Adlam*

Main category: quant-ph

TL;DR: 该论文提出通过参考系视角重新审视扩展维格纳朋友场景，认为观察者观测到的事实总是明确定义的，但参考系之间的关系不一定明确定义，因此不一定存在可比较的联合分布。


<details>
  <summary>Details</summary>
Motivation: 为扩展维格纳朋友场景提供新的理论视角，通过参考系概念解决量子力学中观察者相对性问题，避免无限回归的相对化问题。

Method: 利用对称性原理区分系统属性：需要外部参考系相对化的属性与无需进一步相对化的属性，分析参考系在量子观测中的作用。

Result: 提出观察者观测事实总是明确定义，但参考系关系不一定明确定义，因此不存在可比较的联合分布，为量子力学预测提供了新的解释框架。

Conclusion: 参考系视角为扩展维格纳朋友场景提供了新见解，反对无限相对化回归的观点，强调观察者事实的明确性与参考系关系的相对性。

Abstract: This article suggests that thinking about the role of reference frames can provide new insight into Extended Wigner's Friend scenarios. This involves appealing to symmetries to make a principled distinction between properties of a system which are meaningful only relative to an external reference system and properties which are meaningful without further relativization. Thus we may propose that there are always well-defined facts about what observers have observed, but there are not necessarily well-defined facts about the relations between their reference frames, so there will not always exist a joint distribution over their outcomes which can meaningfully be compared to the predictions of quantum mechanics. In addition, this approach also offers a general argument against the idea that there should be a regress of relativization.

</details>


### [43] [Digital-Analog-Digital Quantum Supremacy](https://arxiv.org/abs/2512.07127)
*Daniel Lidar*

Main category: quant-ph

TL;DR: 该论文提出了一个用于混合数字-模拟-数字量子计算模型的量子霸权框架，证明了该模型输出分布与IQP电路在常数总变差距离内，并表明在特定假设下，任何实现常数TV误差的高效经典采样器会导致多项式层次结构崩溃。


<details>
  <summary>Details</summary>
Motivation: 量子霸权主要在门模型中被探索，但需要为混合数字-模拟-数字量子计算模型建立量子霸权框架，以利用当前量子退火器和其他混合数字-模拟量子演化设备的潜力。

Method: 采用混合数字-模拟-数字量子计算模型：初始单量子比特门层 + 单个横向场伊辛模拟块 + 最终单量子比特层 + Z基测量。模拟块近似Z对角伊辛演化，证明输出分布在常数总变差距离内接近IQP电路。

Result: 证明了输出分布与IQP电路在常数总变差距离内，建立了全连接和有界度硬件图的界限和构造，匹配多种架构（囚禁离子、中性原子、超导平台）。在反集中假设和平均情况硬度猜想下，任何实现常数TV误差的高效经典采样器会导致多项式层次结构崩溃。

Conclusion: 量子霸权测试可以在当今的量子退火器和其他能够进行混合数字-模拟量子演化的设备上实现，为量子霸权提供了新的实验平台。

Abstract: Quantum supremacy has been explored extensively in gate-model settings. Here, we introduce a quantum-supremacy framework for a hybrid digital-analog-digital quantum computing (DADQC) model. We consider a device that applies an initial layer of single-qubit gates, a single transverse-field Ising analog block, and a final single-qubit layer before $Z$-basis readout. The analog block approximates $Z$-diagonal Ising evolution, and we prove that the resulting output distribution is within constant total-variation (TV) distance of an Instantaneous Quantum Polynomial-time (IQP) circuit. Our bounds and constructions are established for fully connected as well as bounded-degree hardware graphs, matching a variety of architectures, including trapped-ion, neutral atom, and superconducting platforms. Assuming anticoncentration (which we prove for all-to-all hardware graphs and conjecture for bounded-degree hardware graphs) and an average-case hardness conjecture for the associated complex-temperature Ising partition functions, standard reductions imply that any efficient classical sampler achieving constant TV error collapses the polynomial hierarchy. Our results imply that quantum-supremacy tests are possible on today's quantum annealers, as well as other devices capable of hybrid digital-analog quantum evolution.

</details>


### [44] [A manufacturable surface code architecture for spin qubits with fast transversal logic](https://arxiv.org/abs/2512.07131)
*Jason D. Chadwick,Willers Yang,Joshua Viszlai,Frederic T. Chong*

Main category: quant-ph

TL;DR: 提出SNAQ架构，利用硅自旋量子比特的快速穿梭能力，通过时间复用减少读出组件数量，显著降低芯片面积并提升逻辑时钟速度。


<details>
  <summary>Details</summary>
Motivation: 硅量子点阵列中的自旋量子比特具有小尺寸和半导体制造兼容性优势，但读出组件物理尺寸大限制了密集布局，无法同时测量所有量子比特，这给量子纠错带来挑战。

Method: 提出SNAQ（Shuttling-capable Narrow Array of spin Qubits）表面码架构，利用自旋穿梭能力时间复用辅助量子比特的初始化和读出，放松1:1读出-量子比特假设，使用更密集的物理量子比特网格。

Result: SNAQ架构在足够高的量子比特相干时间下，实现逻辑量子比特芯片面积数量级减少；通过更密集的物理量子比特网格，实现本地逻辑时钟速度4.0-22.3倍提升；15-to-1魔法态蒸馏的时空成本降低57-60%。

Conclusion: SNAQ架构为近期可制造的自旋量子比特阵列提供了高性能容错计算的有力路径，并确定了关键硬件指标。

Abstract: Spin qubits in silicon quantum dot arrays are a promising quantum computation platform for long-term scalability due to their small qubit footprint and compatibility with advanced semiconductor manufacturing. However, spin qubit devices face a key architectural bottleneck: the large physical footprint of readout components relative to qubits prevents a dense layout where all qubits can be measured simultaneously, complicating the implementation of quantum error correction. This challenge is offset by the platform's unique rapid shuttling capability, which can be used to transport qubits to distant readout ports. In this work, we explore the design constraints and capabilities of spin qubits in silicon and propose the SNAQ (Shuttling-capable Narrow Array of spin Qubits) surface code architecture, which relaxes the 1:1 readout-to-qubit assumption by leveraging spin shuttling to time-multiplex ancilla qubit initialization and readout. Our analysis shows that, given sufficiently high (experimentally demonstrated) qubit coherence times, SNAQ delivers an orders-of-magnitude reduction in chip area per logical qubit. Additionally, by using a denser grid of physical qubits, SNAQ enables fast transversal logic for short-distance logical operations, achieving 4.0-22.3x improvement in local logical clock speed while still supporting global operations via lattice surgery. This translates to a 57-60% reduction in spacetime cost of 15-to-1 magic state distillation, a key fault-tolerant subroutine. Our work pinpoints critical hardware metrics and provides a compelling path toward high-performance fault-tolerant computation on near-term-manufacturable spin qubit arrays.

</details>


### [45] [Beyond real: Investigating the role of complex numbers in self-testing](https://arxiv.org/abs/2512.07160)
*Ranyiliu Chen,Laura Mančinska,Jurij Volčič*

Main category: quant-ph

TL;DR: 论文研究了复杂自测试，这是标准自测试的推广，考虑了量子策略统计量与其复共轭不可区分的情况。主要结果是算子代数特征：复杂自测试等价于高阶矩实部的唯一性，并给出了基于实C*代数的基无关表述。


<details>
  <summary>Details</summary>
Motivation: 研究复杂自测试的动机在于理解量子策略统计量与其复共轭不可区分的情况，探索标准自测试无法覆盖的边界，阐明复数在双粒子贝尔非定域性中的微妙作用。

Method: 采用算子代数方法，证明复杂自测试等价于高阶矩实部的唯一性，建立基于实C*代数的基无关表述。通过构造涉及四元数的策略，建立首个真正复杂策略的标准自测试。

Result: 1. 将标准自测试的结构结果推广到复杂设置；2. 给出复杂自测试的算子代数特征；3. 对非局域策略进行分类；4. 确定标准自测试不适用而需要复杂自测试的紧边界；5. 构造涉及四元数的策略，建立首个真正复杂策略的标准自测试。

Conclusion: 该工作阐明了复杂自测试的结构，突出了复数在双粒子贝尔非定域性中的微妙作用，为理解量子策略的复杂性质提供了新的理论框架和分类方法。

Abstract: We investigate complex self-testing, a generalization of standard self-testing that accounts for quantum strategies whose statistics is indistinguishable from their complex conjugate's. We show that many structural results from standard self-testing extend to the complex setting, including lifting of common assumptions. Our main result is an operator-algebraic characterization: complex self-testing is equivalent to uniqueness of the real parts of higher moments, leading to a basis-independent formulation in terms of real C* algebras. This leads to a classification of non-local strategies, and a tight boundary where standard self-testing do not apply and complex self-testing is necessary. We further construct a strategy involving quaternions, establishing the first standard self-test for genuinely complex strategy. Our work clarifies the structure of complex self-testing and highlights the subtle role of complex numbers in bipartite Bell non-locality.

</details>


### [46] [A versatile coherent Ising computing platform](https://arxiv.org/abs/2512.07182)
*Hai Wei,Chengjun Ai,Putuo Guo,Bingjie Jia,Lixin Yuan,Hanquan Song,Shaobo Chen,Chongyu Cao,Jie Wu,Chao Ju,Yin Ma,Jintao Fan,Minglie Hu,Chuan Wang,Kai Wen*

Main category: quant-ph

TL;DR: 本文通过飞秒激光泵浦实现了相干伊辛机实验，在100顶点莫比乌斯梯图上达到55%平均成功率，并保持8小时稳定运行，展示了其在解决NP完全问题方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 相干伊辛机作为解决NP完全问题的混合量子计算设备具有巨大潜力，但面临噪声诱导局部极小值等挑战。研究旨在提高CIM的计算精度和稳定性，探索其在分子对接、信用评分等实际应用中的可行性。

Method: 采用飞秒激光泵浦技术实现CIM实验，在光学和结构维度上集成优化策略。飞秒脉冲产生更高峰值功率，在光纤基CIM中实现更显著的量子效应和更低的泵浦功率。

Result: 在100顶点莫比乌斯梯图上达到55%平均成功率识别最优解；飞秒脉冲相比其他方案显著提高峰值功率；系统保持8小时连续稳定运行；展示了在分子对接和信用评分等实际应用中的潜力。

Conclusion: 研究证实了CIM的理论潜力，通过飞秒激光泵浦技术显著提升了计算性能和稳定性，为CIM在大规模实际应用中的集成铺平了道路。

Abstract: Coherent Ising Machines (CIMs) have emerged as a hybrid form of quantum computing devices designed to solve NP-complete problems, offering an exciting opportunity for discovering optimal solutions. Despite challenges such as susceptibility to noise-induced local minima, we achieved notable advantages in improving the computational accuracy and stability of CIMs. We conducted a successful experimental demonstration of CIM via femto-second laser pumping that integrates optimization strategies across optical and structural dimensions, resulting in significant performance enhancements. The results are particularly promising. An average success rate of 55% was achieved to identify optimal solutions within a Mobius Ladder graph comprising 100 vertices. Compared with other alternatives, the femto-second pulse results in significantly higher peak power, leading to more pronounced quantum effects and lower pump power in optical fiber based CIMs. In addition, we have maintained an impressive success rate for a continuous period of 8 hours, emphasizing the practical applicability of CIMs in real-world scenarios. Furthermore, our research extends to the application of these principles in practical applications such as molecular docking and credit scoring. The results presented substantiate the theoretical promise of CIMs, paving the way for their integration into large-scale practical applications.

</details>


### [47] [Non-Hermitian Bose-Hubbard-like quantum models](https://arxiv.org/abs/2512.07250)
*Miloslav Znojil*

Main category: quant-ph

TL;DR: 论文研究非厄米大三角矩阵量子哈密顿量的一个子类，其结构类似于Bose-Hubbard模型，展示了该子类的奇异值可通过"厄米化"薛定谔方程确定，并给出了相关格林函数的两种紧凑数值高效矩阵连分式形式。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米大三角矩阵量子哈密顿量的特定子类，这些模型结构类似于现实的Bose-Hubbard基准模型，旨在找到用户友好的分析方法来处理这类复杂系统。

Method: 选择非厄米大三角矩阵哈密顿量的一个子类，其结构与Bose-Hubbard模型相似。通过"厄米化"过程，将奇异值问题转化为类似薛定谔方程的形式。推导出相关"厄米化"格林函数的两种紧凑矩阵连分式表示。

Result: 成功展示了所选子类的奇异值可通过"厄米化"薛定谔方程确定，并得到了相关格林函数的两种紧凑且数值高效的矩阵连分式形式，为这类非厄米系统的分析提供了有效工具。

Conclusion: 所研究的非厄米大三角矩阵哈密顿量子类具有用户友好的特性，其奇异值分析可通过"厄米化"方法简化，且相关格林函数存在两种高效的矩阵连分式表示，为处理类似Bose-Hubbard模型的复杂系统提供了新的分析框架。

Abstract: Among all of the non-Hermitian large-tridiagonal-matrix quantum Hamiltonians we choose a subclass with the structure resembling the ``benchmark'' realistic Bose-Hubbard model. We demonstrate that this choice can be declared user-friendly in the sense that the underlying singular values can be specified via a ``Hermitized'' Schrödinger-like equation. In particular, the related ``Hermitized'' Green's functions is shown given the two alternative compact and numerically efficient matrix continued fraction forms.

</details>


### [48] [Quantum geometrical effects in non-Hermitian systems](https://arxiv.org/abs/2512.07264)
*Anton Montag,Tomoki Ozawa*

Main category: quant-ph

TL;DR: 该论文探讨了非厄米系统中量子几何与物理可观测现象之间的关系，重点研究了非厄米系统的绝热势和周期非厄米系统中Wannier态的局域化，并展示了非厄米量子度规在系统响应中的出现及其实验测量方法。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中量子几何与物理可观测现象之间的关联，旨在为理解非厄米系统的独特行为提供几何视角，并探索量子几何在实验测量中的实际应用。

Method: 通过分析非厄米系统的绝热势概念和周期系统中Wannier态的局域化行为，研究量子几何在非厄米系统中的表现。进一步展示了非厄米量子度规在时间周期调制响应中的出现，并通过具体示例系统的数值模拟验证理论结果。

Result: 建立了非厄米系统行为与量子几何之间的明确联系，证明了非厄米量子度规可以通过系统对时间周期调制的响应来实验测量，并通过数值模拟验证了理论预测的有效性。

Conclusion: 量子几何为理解非厄米系统的物理行为提供了有力框架，非厄米量子度规不仅是理论概念，而且可以通过实验手段测量，这为非厄米系统的实验研究和应用开辟了新途径。

Abstract: We explore the relation between quantum geometry in non-Hermitian systems and physically measurable phenomena. We highlight various situations in which the behavior of a non-Hermitian system is best understood in terms of quantum geometry, namely the notion of adiabatic potentials in non-Hermitian systems and the localization of Wannier states in periodic non-Hermitian systems. Further, we show that the non-Hermitian quantum metric appears in the response of the system upon time-periodic modulation, which one can use to experimentally measure the non-Hermitian quantum metric. We validate our results by providing numerical simulations of concrete exemplary systems.

</details>


### [49] [Simulating general noise nearly as cheaply as Pauli noise](https://arxiv.org/abs/2512.07304)
*Mark Myers,Mariesa H. Teo,Rajesh Mishra,Jing Hao Chai,Hui Khoon Ng*

Main category: quant-ph

TL;DR: 该论文提出了一种基于分层重要性采样的方法，能够在经典计算机上模拟包含一般噪声（包括相干误差）的Clifford量子电路，突破了传统稳定子模拟只能处理Pauli噪声的限制。


<details>
  <summary>Details</summary>
Motivation: 传统稳定子模拟方法只能处理Pauli型噪声，但实际设备中的噪声通常更为复杂（包括相干误差），这些一般噪声对电路性能的影响可能比Pauli噪声更严重。然而，在数值模拟中很难甚至无法完全研究这些一般噪声。

Method: 采用分层重要性采样方法，在稳定子形式体系中模拟一般噪声。非幺正噪声的模拟成本与Pauli噪声相近，幺正（相干）噪声的模拟时间虽然增加一个数量级，但仍能在合理时间内完成。

Result: 该方法显著改进了以往通常无法收敛的模拟方法，能够在合理时间内完成包含一般噪声的电路模拟。论文展示了旋转平面表面码在电路级一般噪声下的性能直接模拟结果，这在以前只能在有限情况下或通过映射到可高效模拟的物理模型才能获得。

Conclusion: 这项工作使得能够在存在实际设备噪声（通常不是Pauli型）的情况下，对电路性能进行超越Pauli噪声的详细理解，为量子电路性能分析提供了更全面的模拟工具。

Abstract: Stabilizer simulation of Clifford quantum circuits - error-correction circuits, Clifford subroutines, etc. - on classical computers has played a central role in our understanding of circuit performance. The stabilizer description, however, restricts the accessible noise one can incorporate into the simulation to Pauli-type noise. More general noise, including coherent errors, may have more severe impact on circuit performance than Pauli noise; yet, such general noise have been difficult to access, much less investigate fully, in numerical simulations. Here, through the use of stratified importance sampling, we show how general noise can be simulated within the stabilizer formalism in reasonable time, with non-unitary noise being nearly as cheap as Pauli noise. Unitary (or coherent) noise can require an order of magnitude more time for the simulation, but nevertheless completes in very reasonable times, a drastic improvement over past approaches that typically fail to converge altogether. Our work thus enables detailed beyond-Pauli understanding of circuit performance in the presence of real device noise, which is rarely Pauli in nature. Among other examples, we present direct simulation results for the performance of the popular rotated planar surface codes under circuit-level general noise, previously available only in limited situations and/or through mappings to efficiently simulatable physical models.

</details>


### [50] [Single-cell identification with quantum-enhanced nuclear magnetic resonance](https://arxiv.org/abs/2512.07307)
*Zhiyuan Zhao,Qian Shi,Shaoyi Xu,Xiangyu Ye,Mengze Shen,Jia Su,Ya Wang,Tianyu Xie,Qingsong Hu,Fazhan Shi,Jiangfeng Du*

Main category: quant-ph

TL;DR: 该论文提出了一种基于量子增强NMR和金刚石氮空位中心的单细胞无标记识别方法，通过检测细胞内质子信号来区分不同细胞系。


<details>
  <summary>Details</summary>
Motivation: 传统标记分选方法（如荧光激活细胞分选和磁激活细胞分选）在缺乏明确标记物或对标记敏感的细胞中应用受限，因为标记可能损害细胞活性和功能。

Method: 使用量子增强核磁共振技术结合金刚石氮空位中心，无标记检测细胞内质子信号，通过质子自旋-晶格弛豫时间作为细胞固有物理化学特征来区分细胞。

Result: 成功区分了两种人类肿瘤细胞系，通过它们的质子自旋-晶格弛豫时间作为细胞固有特征，证明了该方法的可行性。

Conclusion: 该方法为稀有细胞分析、个性化医疗和单细胞诊断中的无标记分选应用奠定了基础。

Abstract: Identification of individual cells within heterogeneous populations is essential for biomedical research and clinical diagnostics. Conventional labeling-based sorting methods, such as fluorescence-activated cell sorting and magnetic-activated cell sorting, enable precise sorting when reliable markers are available. However, their applicability is limited in cells lacking defined markers or sensitive to labeling, as labeling can compromise cellular viability and function. We present a single-cell identification approach using quantum-enhanced NMR with diamond nitrogen-vacancy centers for label-free detection of intracellular proton ($^1$H) signals. Using this method, we distinguish two human tumor cell lines by their proton spin-lattice ($T_1$) relaxation times, which serve as a cell-intrinsic physicochemical signature. It lays the groundwork for label-free sorting applications in rare cell analysis, personalized medicine, and single-cell diagnostics.

</details>


### [51] [Revisiting Quantum Supremacy: Simulating Sycamore-Class Circuits Using Hybrid CPU/GPU HPC Workloads](https://arxiv.org/abs/2512.07311)
*Bob Wold,Venkateswaran Kasirajan*

Main category: quant-ph

TL;DR: 提出一个框架，使用高性能计算基础设施有效模拟量子霸权电路，在53量子比特Sycamore电路上实现0.549的XEB分数，远超Google的0.002，并展示了显著的速度提升。


<details>
  <summary>Details</summary>
Motivation: 量子霸权实验（如Google的Sycamore电路）声称量子计算机在特定任务上超越经典计算机，但需要验证这些声明的持久性，并探索经典模拟的潜力。

Method: 结合单个NVIDIA A100 GPU进行量子态构建，然后通过N个并行CPU作业进行分布式测量采样，构建混合GPU-CPU模拟框架。

Result: 在53量子比特、14周期Sycamore电路上实现0.549的XEB分数（远超Google的0.002）；在53量子比特、20周期电路上，100个CPU作业在1小时15分36秒内完成250万次采样，相比Google的经典估计加速6.95×10^7倍。

Conclusion: 量子霸权不是固定目标而是移动靶，混合经典-量子策略可能比预期提供更广泛的近期量子效用，经典模拟技术仍在快速进步。

Abstract: We present a framework for effectively simulating the execution of quantum circuits originally designed to demonstrate quantum supremacy using accessible high-performance computing (HPC) infrastructure. Building on prior CPU-only approaches, our pipeline combines a single NVIDIA A100 GPU for quantum state construction, followed by N parallel CPU jobs that perform distributed measurement sampling. We validate the fidelity by simulating the 53-qubit, 14-cycle Sycamore circuit and achieving a linear cross-entropy benchmarking (XEB) score of 0.549, exceeding the published XEB score of 0.002 from Google's reference data. We then evaluate execution time performance with the more complex 53-qubit, 20-cycle circuit, completing the full 2.5 million-shot workload over 100 CPU jobs in 01:15:36, representing a 6.95 x 10^7 speedup compared to Google's original classical estimate. Further, we show that if 1,000 CPU jobs were employed, the estimated duration would be approximately 00:17:35, only 12 minutes slower than the time taken by the original QPU-based experiment. These results illustrate that 'quantum supremacy' is not fixed and continues to be a moving target. In addition, hybrid classical-quantum strategies may provide broader near-term quantum utility than once thought.

</details>


### [52] [33 Gbit/s source-device-independent quantum random number generator based on heterodyne detection with real-time FPGA-integrated extraction](https://arxiv.org/abs/2512.07319)
*Marius Cizauskas,Hamid Tebyanian,Mark Fox,Manfred Bayer,Marc Assmann,Alex Greilich*

Main category: quant-ph

TL;DR: 基于真空涨落外差检测的高速连续变量量子随机数发生器，采用源设备无关安全模型，通过FPGA实时处理实现33.92 Gbit/s的净生成速率。


<details>
  <summary>Details</summary>
Motivation: 开发高速、安全的量子随机数发生器，采用源设备无关安全模型确保安全性，即使面对对抗性态制备也能保持安全，适用于高速量子通信和密钥分发系统。

Method: 使用90°光学混合器将光场分裂，通过两个平衡光电二极管同时测量真空态的两个正交分量；采用双通道12位模数转换器以3.2 GS/s采样率数字化，FPGA实现Toeplitz哈希进行实时随机性提取。

Result: 系统在1.6 GHz检测带宽内确认真空噪声主导，经过提取后实现33.92 Gbit/s的持续均匀分布随机比特生成速率，通过所有NIST和Dieharder统计测试。

Conclusion: 该平台提供了一个紧凑的、基于FPGA的实用外差连续变量源无关量子随机数发生器实现，适用于高速量子通信和安全密钥分发系统。

Abstract: We present a high-speed continuous-variable quantum random number generator (QRNG) based on heterodyne detection of vacuum fluctuations. The scheme follows a source-device-independent (SDI) security model in which the entropy originates from quantum measurement uncertainty and no model of the source is required; security depends only on the trusted measurement device and the calibrated discretization, and thus remains valid even under adversarial state preparation. The optical field is split by a 90$^\circ$ optical hybrid and measured by two balanced photodiodes to obtain both quadratures of the vacuum state simultaneously. The analog outputs are digitized using a dual-channel 12-bit analog-to-digital converter operating at a sampling rate of 3.2 GS/s per channel, and processed in real time by an FPGA implementing Toeplitz hashing for randomness extraction. The quantum-to-classical noise ratio was verified through calibrated power spectral density measurements and cross-checked in the time domain, confirming vacuum-noise dominance within the 1.6 GHz detection bandwidth. After extraction, the system achieves a sustained generation rate of $R_{\rm net}= 33.92~\mathrm{Gbit/s}$ of uniformly distributed random bits, which pass all NIST and Dieharder statistical tests. The demonstrated platform provides a compact, FPGA-based realization of a practical heterodyne continuous-variable source-independent QRNG suitable for high-rate quantum communication and secure key distribution systems.

</details>


### [53] [Tunable Dynamics of a Dipolar Quantum Battery: Role of Spin-Spin Interactions and Coherence](https://arxiv.org/abs/2512.07325)
*J. Ramya Parkavi,R. Muthuganesan,V. K. Chandrasekar*

Main category: quant-ph

TL;DR: 该研究探索了具有Dzyaloshinskii-Moriya相互作用的偶极自旋系统量子电池的能量存储动力学，分析其性能指标如功提取、瞬时功率、容量和量子相干性，并考察温度、磁场等外部参数的影响。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池的能量存储性能，探索如何利用量子相干性和DM相互作用来增强能量存储效率和功率输出，为设计高性能量子能量存储设备提供策略。

Method: 采用两量子比特模型，通过求解系统在循环幺正过程下的时间演化，分析外部参数（温度、磁场、DM相互作用）对充电行为和量子资源的影响，并研究在共同退相干环境下的性能。

Result: 研究发现量子相干性和DM相互作用显著增强量子电池的能量存储效率和功率输出，但共同退相干环境限制了偶极量子电池的长期功提取能力。

Conclusion: 量子相干性和DM相互作用是提升量子电池性能的关键因素，为设计高性能量子能量存储设备提供了有前景的策略，但需要考虑退相干环境对长期性能的限制。

Abstract: This study explores the energy storage dynamics of a quantum battery (QB) modeled using a dipolar spin system with Dzyaloshinskii-Moriya (DM) interaction. We examine the performance of this system in terms of ergotropy, instantaneous power, capacity, and quantum coherence using a two-qubit model. By solving the system's time evolution under cyclic unitary processes, we analyze how external parameters such as temperature, magnetic field, and DM interaction influence the charging behavior and quantum resources of the battery. The findings demonstrate that quantum coherence and DM interaction significantly enhance the energy storage efficiency and power output of the quantum battery, offering promising strategies for designing high-performance quantum energy storage devices. Furthermore, we investigate the performance of quantum battery under the influence of a common dephasing environment, which limits the long-term work-extraction capability of dipolar quantum batteries.

</details>


### [54] [Dispersive readout with two orthogonal modes of a dielectric cavity](https://arxiv.org/abs/2512.07356)
*A. M. Kozodaev,I. S. Cojocaru,S. M. Drofa,P. G. Vilyuzhanina,A. Chernyavskiy,V. G. Vins,A. N. Smolyaninov,S. Ya. Kilin,S. V. Bolshedvorskii,V. V. Soshenko,A. V. Akimov*

Main category: quant-ph

TL;DR: 提出了一种基于金刚石氮空位色心的双通道色散读出磁强计方案，相比传统单通道方法显著提升了灵敏度。


<details>
  <summary>Details</summary>
Motivation: 氮空位色心是优秀的磁场敏感元件，传统方法主要采用光探测磁共振技术，但最近有研究提出使用介电腔的色散读出来增强磁强计灵敏度。

Method: 采用双通道色散读出方案，相比单通道方法进行改进，通过金刚石氮空位色心与介电腔的耦合实现磁场测量。

Result: 研究表明双通道色散读出方法相比传统单通道方案能显著提升磁强计的灵敏度。

Conclusion: 双通道色散读出方案为基于金刚石氮空位色心的磁强计提供了一种有效的灵敏度提升方法，具有实际应用潜力。

Abstract: Nitrogen-vacancy color centers in diamond have proven themselves as a good, sensitive element for the measurement of magnetic fields. While the mainstream of magnetometers based on NV centers uses so-called optically detected magnetic resonance, there has recently been a suggestion to use dispersive readout of a dielectric cavity to enhance the sensitivity of magnetometers. Here, we demonstrate that the dispersive readout approach can be significantly improved if a two-channel scheme is considered.

</details>


### [55] [Resonator-assisted single-photon frequency convertion in a conventional waveguide with a giant V-type atom](https://arxiv.org/abs/2512.07455)
*Ge Sun,Hongzheng Wu,Jing Lu,Lan Zhou*

Main category: quant-ph

TL;DR: 该论文提出了一种利用V型巨原子量子干涉实现单光子频率转换的方案，通过谐振器中的光子触发频率转换，在马尔可夫和非马尔可夫体系中研究散射谱和转换对比度。


<details>
  <summary>Details</summary>
Motivation: 传统波导中单光子频率转换效率有限，需要开发更高效的频率转换方案。通过利用V型巨原子的量子干涉效应和谐振器耦合，可以实现更有效的单光子频率转换。

Method: 采用V型巨原子与谐振器耦合的系统，利用两个耦合点间距表征的巨原子尺度以及单光子跃迁路径产生的量子干涉效应。谐振器中的光子存在触发频率转换过程。

Result: 在马尔可夫和非马尔可夫体系中分析了散射谱和转换对比度。频率转换消失源于激发态到低能态发射的完全抑制。特定条件下发现非马尔可夫性诱导的非互易性，改变光子数n可诱导波导中单光子的非互易传输，从而提高转换概率。

Conclusion: 提出的方案能够有效实现单光子频率转换，通过量子干涉和非马尔可夫效应调控转换过程，为量子信息处理中的频率转换提供了新途径。

Abstract: We propose a scheme to achieve efficient frequency conversion for a single photon propagating in a 1D conventional waveguide by exploiting the quantum interference induced by the scale of a V-type giant atom (GA) characterized by the distance between the two coupling points as well as single-photon transition pathways originated from the coupling between the GA and the resonator. The presence of photons in the resonator triggers the frequency conversion of photons. The scattering spectra and the conversion contrast are studied in both the Markovian and the non-Markovian regimes. The disappearance of frequency conversion is rooted in the complete suppression of the emission from the excited state to either of lower states in the $n+1$ subspace where $n$ is the photon number of the resonator, and the non-Markovicity-induced nonreciprocity is found under specific conditions. Altering the photon number $n$ induces the non-reciprocal transmission of single photons in the waveguide, hence, enhance the conversion probability.

</details>


### [56] [On the emergence of preferred structures in quantum theory](https://arxiv.org/abs/2512.07468)
*Antoine Soulas,Guilherme Franzmann,Andrea Di Biagio*

Main category: quant-ph

TL;DR: 论文探讨希尔伯特空间基本主义，研究哈密顿量能否唯一确定张量积结构，澄清了两个看似冲突的定理，提出了通过哈密顿量和态唯一确定张量积结构的方法。


<details>
  <summary>Details</summary>
Motivation: 研究希尔伯特空间基本主义框架下，如何从最小量子成分（希尔伯特空间、哈密顿量、态）中涌现出物理结构，特别是解决量子整体论中哈密顿量能否唯一确定张量积结构这一关键问题。

Method: 首先聚焦于哈密顿量能否唯一确定张量积结构的问题，回顾、澄清并批判性检验Cotler等人和Stoica的两个定理，解决它们之间的张力，指出前者的广泛误解和后者的局限性。然后提出通过酉不变性质来表征涌现对象的通用数学方法，并将此形式应用于具体案例。

Result: 澄清了两个定理的误解和局限性，提出了正确的数学方法来解决量子理论中优先结构的问题，并证明在特定情况下，哈密顿量和态足以唯一选择优先的张量积结构。

Conclusion: 论文为希尔伯特空间基本主义提供了理论支持，展示了如何从最小量子成分中涌现出物理结构，特别是在哈密顿量和态的基础上可以唯一确定张量积结构，这对量子整体论和量子基础研究具有重要意义。

Abstract: We assess the possibilities offered by Hilbert space fundamentalism, an attitude towards quantum physics according to which all physical structures (e.g. subsystems, locality, spacetime, preferred observables) should emerge from minimal quantum ingredients (typically a Hilbert space, Hamiltonian, and state). As a case study, we first mainly focus on the specific question of whether the Hamiltonian can uniquely determine a tensor product structure, a crucial challenge in the growing field of quantum mereology. The present paper reviews, clarifies, and critically examines two apparently conflicting theorems by Cotler et al. and Stoica. We resolve the tension, show how the former has been widely misinterpreted and why the latter is correct only in some weaker version. We then propose a correct mathematical way to address the general problem of preferred structures in quantum theory, relative to the characterization of emergent objects by unitary-invariant properties. Finally, we apply this formalism in the particular case we started with, and show that a Hamiltonian and a state are enough structure to uniquely select a preferred tensor product structure.

</details>


### [57] [Exponentially accelerated relaxation and quantum Mpemba effect in open quantum systems](https://arxiv.org/abs/2512.07561)
*Emerson Lima Caldas,Diego Paiva Pires*

Main category: quant-ph

TL;DR: 该论文研究开放量子系统中的量子姆潘巴效应，提出基于置换矩阵的酉变换协议，通过抑制最慢衰减模式来加速系统向稳态收敛，实现真正的量子姆潘巴效应。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中的量子姆潘巴效应，即系统初始状态离平衡越远反而越快达到平衡的反常现象，旨在为工程化这一效应提供通用框架。

Method: 提出基于置换矩阵的酉变换协议，作用于系统初始状态：(1)抑制非幺正动力学的最慢衰减模式贡献；(2)确保初始状态与稳态尽可能可区分。证明对于任何初始状态，总存在置换矩阵能最大化其与平衡态的距离。

Result: 该协议能实现真正的量子姆潘巴效应，数值模拟计算成本低。在横向场伊辛链和XXZ链的非幺正动力学中展示了该效应，通过希尔伯特-施密特距离、量子相对熵和迹距离等度量捕获。

Conclusion: 研究结果为工程化开放量子系统中的真正量子姆潘巴效应提供了一个通用且多功能的框架，可用于加速量子系统向稳态的收敛。

Abstract: We investigate the quantum Mpemba effect in the relaxation of open quantum systems whose effective dynamics is described by Davies maps. We present a class of unitary transformations based on permutation matrices that, acting on the initial state of the system, (i) suppress the contribution of slowest decaying modes of the nonunitary dynamics; (ii) ensure that it is as distinguishable as possible from the steady state. The first requirement guarantees an exponentially accelerating convergence to the steady state, while the second implies that a quantum system initially farther from equilibrium approaches it more rapidly than an initial state closer to it. This protocol provides a genuine Mpemba effect, and its numerical simulation requires low computational effort. We prove that, for any initial state, there always exists a permutation matrix that maximizes its distance from the equilibrium for a given information-theoretic distinguishability measure. We illustrate our findings for the nonunitary dynamics of the transverse field Ising chain and XXZ chain, each weakly coupled to a bosonic thermal bath, showing the quantum Mpemba effect captured by the Hilbert-Schmidt distance, quantum relative entropy, and trace distance. Our results provide a universal and versatile framework to engineer the genuine quantum Mpemba effect in open quantum systems.

</details>


### [58] [Uniform relativistic motion through a thermal bath as a thermodynamic resource](https://arxiv.org/abs/2512.07567)
*Rahul Shastri*

Main category: quant-ph

TL;DR: 量子系统在相对论性匀速运动下通过无质量标量场热浴时，会进入非平衡稳态，即使没有外部驱动或多个热浴。相对运动破坏了细致平衡，导致系统无法达到吉布斯态。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统在相对论性运动下与热浴的相互作用，探索相对运动如何破坏热平衡并产生非平衡稳态，以及这些稳态的物理特性和潜在应用。

Method: 分析量子系统以均匀相对论速度通过无质量标量场热浴的情况，研究相对运动如何破坏细致平衡，并识别产生的两类非平衡稳态：具有持续概率流的稳态和无概率流但具有频率依赖有效逆温度的稳态。

Result: 发现相对运动本身就能驱动系统进入非平衡稳态，这些稳态分为两类：1）具有持续概率流的稳态，可作为随机时钟；2）无概率流的非吉布斯稳态，具有非零非平衡自由能，可作为量子电池用于功的提取或存储。

Conclusion: 相对论性运动通过破坏细致平衡，使量子系统进入非平衡稳态，这些稳态具有重要的物理特性和潜在应用价值，包括作为随机时钟和量子电池。

Abstract: We show that a quantum system undergoing motion with uniform relativistic velocity through a thermal bath consisting of a massless scalar field is generically driven into a non-equilibrium steady-state (NESS) solely due to its motion, even in the absence of external driving or multiple baths. The relative motion between the system and the bath breaks detailed balance, preventing thermalization to a Gibbs state. We find that the resulting steady-states fall into two distinct classes: (i) NESSs with persistent probability currents, and (ii) current-free non-Gibbs steady states characterized by a frequency-dependent effective inverse temperature. We demonstrate, using a three-level system, that NESSs with probability current can function as noisy stochastic clock, while current-free non-Gibbs steady states possess non-zero non-equilibrium free energy, indicating their potential as a quantum battery for work extraction or storage.

</details>


### [59] [On-Demand Microwave Single-Photon Source Based on Tantalum Thin Film](https://arxiv.org/abs/2512.07589)
*Ying Hu,Sheng-Yong Li,En-Qi Chen,Jing Zhang,Yu-xi Liu,Jia-Gui Feng,Zhihui Peng*

Main category: quant-ph

TL;DR: 该论文展示了一种基于钽薄膜的微波单光子源，通过二阶相关测量验证了反聚束行为，并利用行波参量放大器提高信噪比，大幅缩短测量时间。


<details>
  <summary>Details</summary>
Motivation: 单光子源是量子信息技术的关键组件。研究旨在开发基于钽薄膜的高质量、稳定的微波单光子源，为微波量子光子学提供可靠平台。

Method: 采用钽基薄膜制造微波单光子源，利用其优越的材料特性实现高质量光子发射。通过二阶相关测量揭示辐射的反聚束行为，并在检测链中使用行波参量放大器作为前置放大器。

Result: 成功演示了钽基微波单光子源，观察到明显的反聚束行为。使用行波参量放大器显著提高了信噪比，将二阶相关测量的采集时间大幅缩短。

Conclusion: 钽基超导器件可作为微波量子光子学的可靠平台，该单光子源技术为量子信息技术发展提供了重要工具。

Abstract: Single-photon sources are crucial for quantum information technologies. Here, we demonstrate a microwave single-photon source fabricated using a tantalum-based thin film, whose favorable material properties enable high-quality and stable photon emission. The antibunching behavior of the emitted radiation is revealed by second-order correlation measurements. Furthermore, traveling-wave parametric amplifiers are used as the pre-amplifier in the detection chains, we substantially improve the signal-to-noise ratio and thereby greatly reduce the acquisition time required for second-order correlation measurements. These results demonstrate the viability of tantalum-based superconducting devices as reliable platforms for microwave quantum photonics.

</details>


### [60] [Sharp values for all dynamical variables via Anti-Wick quantization](https://arxiv.org/abs/2512.07616)
*Simon Friederich*

Main category: quant-ph

TL;DR: 该论文提出了一种通过反维克量子化将量子期望值解释为相空间加权平均的方法，为量子测量问题提供了经典概率解释的新视角。


<details>
  <summary>Details</summary>
Motivation: 解决量子测量问题，弥合量子期望值与经典期望值之间的解释鸿沟。量子期望值通常通过希尔伯特空间内积计算，而经典期望值则是相空间加权积分，两者解释方式不同。

Method: 使用反维克量子化将动力学变量与自伴线性算子关联，在Segal-Bargmann空间中实现量子期望值作为相空间加权平均的解释。在该空间中，产生和湮灭算子表现为简单的乘法和微分算子。

Result: 量子期望值可以被解释为真正的相空间加权平均，Husimi Q函数（量子态的相干态表示）可以被视为相空间中的真实概率密度。

Conclusion: 该方法保留了动力学变量与自伴算子之间的标准对应关系，同时为量子统计提供了类似经典的概率解释，为量子测量问题提供了新的解决思路。

Abstract: This paper proposes an approach to interpreting quantum expectation values that may help address the quantum measurement problem. Quantum expectation values are usually calculated via Hilbert space inner products and, thereby, differently from expectation values in classical mechanics, which are weighted phase-space integrals. It is shown that, by using Anti-Wick quantization to associate dynamical variables with self-adjoint linear operators, quantum expectation values can be interpreted as genuine weighted averages over phase space, paralleling their classical counterparts. This interpretation arises naturally in the Segal-Bargmann space, where creation and annihilation operators act as simple multiplication and differentiation operators. In this setting, the Husimi Q-function - the coherent-state representation of the quantum state - can be seen as a true probability density in phase space. Unlike Bohmian mechanics, the present approach retains the standard correspondence between dynamical variables and self-adjoint operators while paving the way for a classical-like probabilistic interpretation of quantum statistics.

</details>


### [61] [Quantum Diamond Microscopy for Non-Destructive Failure Analysis of an Integrated Fan-Out Package-on-Package iPhone Chip](https://arxiv.org/abs/2512.07619)
*Bartu Bisgin,Marwa Garsi,Andreas Welscher,Michael Hanke,Fleming Bruckmaier*

Main category: quant-ph

TL;DR: 量子钻石显微镜（QDM）作为一种非破坏性磁电流路径成像技术，在先进半导体封装失效分析中展现出潜力，能够定位传统方法难以检测的短路故障。


<details>
  <summary>Details</summary>
Motivation: 先进半导体封装（如小芯片架构和2.5D/3D集成）的复杂性不断增加，使得传统失效定位方法（如锁相热成像）面临挑战，密集的再分布层和埋入式互连限制了现有技术非破坏性理解失效机制的能力。

Method: 使用基于金刚石中氮空位（NV）中心的量子钻石显微镜（QDM）作为非破坏性定位方法，通过磁电流路径成像在封装级别进行失效分析。采用iPhone中的商业集成扇出封装上封装（InFO-PoP）器件，展示包含QDM的完整失效分析工作流程，用于定位封装背面的集成无源器件（IPD）处的短路故障。

Result: QDM结果在传统技术基础上提供了宝贵信息，能够显著增强封装级别失效分析工作流程中的根本原因识别。成功定位了集成无源器件处的短路故障。

Conclusion: 这项工作展示了QDM在半导体芯片和封装分析工作流程中更广泛集成的潜力，为复杂先进封装的非破坏性失效分析提供了有效解决方案。

Abstract: The increasing complexity of advanced semiconductor packages, driven by chiplet architectures and 2.5D/3D integration, challenges conventional failure localization methods such as lock-in thermography (LIT) and complicates current Failure Analysis (FA) workflows. Dense redistribution layers and buried interconnects limit the ability of established techniques to understand failure mechanisms non-destructively. In this work, we validate quantum diamond microscopy (QDM) based on nitrogen-vacancy (NV) centers in diamond as a non-destructive localization method through magnetic current path imaging at the package level. Using commercial Integrated Fan-Out Package-on- Package (InFO-PoP) devices from iPhones, we showcase a complete FA workflow that includes QDM to localize a short-type failure at an Integrated Passive Device (IPD) at the package backside. We showcase that the QDM results provide invaluable information on top of conventional techniques and can significantly enhance root-cause identification in package-level FA workflows. This work demonstrates the potential of QDM for broader integration into semiconductor chip and package analysis workflows.

</details>


### [62] [Enhanced charging power in nonreciprocal quantum battery by reservoir engineering](https://arxiv.org/abs/2512.07626)
*Qi-Yin Lin,Guang-Zheng Ye,Can Li,Wan-Jun Su,Huai-Zhi Wu*

Main category: quant-ph

TL;DR: 该论文提出了一种在非厄米系统中实现非互易量子电池的方案，通过利用环境耗散抑制反向能量转移，在谐振条件下实现了电池能量与充电器能量四倍的比值，并在异常点操作时表现出更强的参数波动鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统量子电池面临固有耗散和反向能量流动的限制，需要开发能够克服这些约束的新方案。非厄米系统提供了利用环境耗散实现非互易能量传输的可能性，为量子电池技术提供了新的设计思路。

Method: 设计基于充电器和电池的相干耦合系统，两者共同与一个"坏腔"相互作用。通过引入辅助坏腔并利用非互易条件，该模型能够利用环境耗散来抑制反向能量转移。在谐振条件下优化阻尼参数，实现高效的短时充电功率。

Result: 在谐振条件下实现了电池能量与充电器能量四倍的比值；在大失谐条件下该比值显著降低；通过阻尼优化获得了高效的短时充电功率；与完全非互易方案相比，在异常点操作的量子电池对参数波动表现出更强的鲁棒性。

Conclusion: 非厄米量子工程在量子电池技术中具有重要潜力，特别是在涉及定向能量转移、受控耗散和开放量子系统熵管理的领域。该方案为克服传统量子电池的限制提供了新途径。

Abstract: We propose a scheme to achieve a nonreciprocal quantum battery (QB) in the non-Hermitian (NH) system, which can overcome the intrinsic dissipation and reverse flow constraints. The design is based on a charger and a battery, which are coherently coupled and jointly interact with a bad cavity. By introducing the auxiliary bad cavity and exploiting the nonreciprocal condition, this model can harness the environmental dissipation to suppress the reverse energy transfer. Under resonant conditions, we have achieved a four ratio of the battery energy to the charger energy; in contrast, this ratio is significantly reduced under large detuning. Through damping optimization, high efficiency of the short-time charging power is attained. In comparison to the fully nonreciprocal scheme, the QB operating at the exceptional point (EP) exhibits greater resilience to parameter fluctuations. These findings highlight the potential of NH quantum engineering for advancing QB technology, particularly in regimes involving directional energy transfer, controlled dissipation, and entropy management in open quantum systems.

</details>


### [63] [Single-Operation Rydberg Phase Gates via Dynamic Population Suppression](https://arxiv.org/abs/2512.07656)
*Sebastian C. Carrasco,Jabir Chathanathil,Svetlana A. Malinovskaya,Ignacio Sola,Vladimir S. Malinovsky*

Main category: quant-ph

TL;DR: 提出基于调制零脉冲面积场的控制协议，动态抑制里德堡激发同时保留里德堡-里德堡相互作用作为纠缠相位资源，实现任意阻塞强度下的完美纠缠相位门


<details>
  <summary>Details</summary>
Motivation: 解决传统里德堡阻塞量子逻辑中存在的有限阻塞误差问题，特别是在拉比频率接近或超过相互作用能量时，需要同时实现速度、保真度和鲁棒性的量子门操作

Method: 基于调制零脉冲面积场的控制协议，动态抑制里德堡激发，同时保留里德堡-里德堡相互作用作为纠缠相位资源，实现单步完美纠缠相位门

Result: 该方法能够消除有限阻塞误差，即使在拉比频率接近或超过相互作用能量时也能工作，定义了一个新的里德堡阻塞量子逻辑操作机制

Conclusion: 该技术简单通用，兼容多种中性原子架构，为实现可扩展、高保真度的量子计算和模拟提供了有前景的途径

Abstract: We propose a versatile control protocol based on modulated zero-pulse-area fields that dynamically suppresses Rydberg excitation while retaining Rydberg-Rydberg interactions as an entangling phase resource. This mechanism enables single-step, perfectly entangling phase gates for arbitrary blockade strengths, eliminating finite-blockade errors even when the Rabi frequency approaches or exceeds the interaction energy. The approach defines a new operational regime for Rydberg-blockade quantum logic in which speed, fidelity, and robustness are achieved simultaneously within a simple dynamical framework. Owing to its simplicity and generality, the technique is compatible with a wide range of neutral-atom architectures and offers a promising route toward scalable, high-fidelity quantum computation and simulation.

</details>


### [64] [Brazilian Twin Photons 32nd anniversary](https://arxiv.org/abs/2512.07670)
*Renné Medeiros de Araújo,Raphael César Souza Pimenta,Lucas Marques Fagundes,Gustavo Henrique dos Santos,Nara Rubiano da Silva,Stephen Patrick Walborn,Paulo Henrique Souto Ribeiro*

Main category: quant-ph

TL;DR: 本文回顾了巴西自发参量下转换（SPDC）技术三十多年的发展历程，从最初的孪生光子实验到当前量子应用研究，展示了巴西量子光学社区的形成与成长。


<details>
  <summary>Details</summary>
Motivation: 纪念巴西SPDC研究三十多年的发展历程，梳理该领域在巴西的起源、关键实验和重要贡献者，展示巴西量子光学社区的形成过程及其国际影响力。

Method: 采用历史回顾的方法，通过梳理关键实验、研究机构和研究人员的贡献，按时间顺序呈现巴西SPDC研究的发展脉络，重点关注空间关联、纠缠和退相干等基础研究。

Result: 成功梳理了巴西SPDC研究三十多年的发展轨迹，识别了关键实验、重要机构和研究人员，展示了巴西在孪生光子系统基础研究方面的国际影响力，以及从基础研究向量子应用转化的趋势。

Conclusion: 巴西的SPDC研究经历了从基础实验到国际影响力的发展过程，形成了强大的科学社区，目前正致力于将基础研究成果转化为量子技术应用，展现了持续的研究活力和发展潜力。

Abstract: We present a historical review of the development and impact of spontaneous parametric down-conversion (SPDC) in Brazil, marking over three decades since the first twin-photon experiments were performed in the country. This article traces the pioneering efforts that initiated the field, highlighting key experiments, institutions, and researchers who contributed to its growth. We discuss seminal works that established SPDC as a fundamental tool in the Brazilian Quantum Optics community, including studies on spatial correlations, entanglement, and decoherence. By presenting a curated sequence of experiments, we offer an overview of how Brazilian research in twin-photon systems has explored profound concepts through fundamental demonstrations, leading to significant international impact. This review also highlights the formation of a strong scientific community and its ongoing efforts to turn fundamental knowledge into quantum applications.

</details>


### [65] [Real-time collisions of fractional charges in a trapped-ion Jackiw-Rebbi field theory](https://arxiv.org/abs/2512.07748)
*Alan Kahan,Pablo Viñas,Torsten V. Zache,Alejandro Bermudez*

Main category: quant-ph

TL;DR: 该论文提出了一种基于囚禁离子系统的Jackiw-Rebbi量子场论模型模拟器，研究标量场与费米子耦合动力学中的反作用和量子涨落效应。


<details>
  <summary>Details</summary>
Motivation: 研究量子场论中分数化费米子的稳定性和实时演化，特别是在考虑反作用和量子涨落的情况下，为实验可观测的物理现象提供理论框架。

Method: 使用囚禁离子系统模拟Jackiw-Rebbi模型，其中标量场由离子位移描述，费米子由离子内部电子态编码。采用Born-Oppenheimer近似获得有效势，并结合截断Wigner近似与费米子高斯态方法研究量子动力学。

Result: 揭示了费米子反作用如何导致拓扑扭结的局域化，量子涨落如何影响扭结的传播和散射，预测了在当前囚禁离子架构中可观测的实验特征。

Conclusion: 该研究为在量子模拟器中探索量子场论中的反作用和量子涨落效应提供了可行方案，展示了囚禁离子系统在研究分数化费米子动力学方面的潜力。

Abstract: We propose and analyze a trapped-ion quantum simulator of the Jackiw-Rebbi model, a paradigmatic quantum field theory in (1+1) dimensions where solitonic excitations of a scalar field can bind fermionic zero modes leading to fractionally charged excitations. In our approach, the scalar field is a coarse-grained description of the planar zigzag ion displacements in the vicinity of a structural phase transition. The internal electronic states of the ions encode spins with interactions mediated by the transverse phonons and in-plane spin-phonon couplings with a zigzag pattern, which together correspond to a Yukawa-coupled Dirac field. Instead of assuming a fixed soliton background, we study the effect of back-reaction and quantum fluctuations on the coupled dynamics of the full fermion-boson system. We start by applying a Born-Oppenheimer approximation to obtain an effective Peierls-Nabarro potential for the topological kink, unveiling how the fermionic back-reaction can lead to localization of the kink. Beyond this limit, a truncated Wigner approximation combined with fermionic Gaussian states captures the quantum spreading and localization of a kink and kink-antikink scattering. Our results reveal how back-reaction and quantum fluctuations modify the stability and real-time evolution of fractionalized fermions, predicting experimentally accessible signatures in current trapped-ion architectures.

</details>


### [66] [Statistical properties of quantum jumps between macroscopic states of light: reading an operational coherence record](https://arxiv.org/abs/2512.07754)
*Th. K. Mavrogordatos*

Main category: quant-ph

TL;DR: 提出一种实验装置，通过振幅双稳态中的向下量子跃迁来揭示量子相干性，将宏观量子态的相干叠加转化为探测器电路积分电荷的统计特性。


<details>
  <summary>Details</summary>
Motivation: 揭示振幅双稳态中向下量子跃迁所表现的量子相干性，探索宏观量子态的相干叠加如何通过探测器电路的统计特性来表征。

Method: 使用模式匹配的外差/零差检测方案，通过辅助腔传输信号的动态演化来定位双稳态主腔中的宏观切换事件，然后让主腔模自由衰减到真空态，监测产生的积分电荷分布。

Result: 在长时间极限下，跃迁过程中产生的纯态集合的电荷分布收敛于Q函数（外差检测）或Wigner函数的边缘分布（零差检测），由本地振荡器相位决定。

Conclusion: 该实验装置能够将宏观量子态的相干叠加转化为可观测的电荷统计特性，连接了切换事件的统计特性与光子阻塞破坏相关的腔场关联。

Abstract: We propose an experimental apparatus to reveal the quantum coherence manifested in downward quantum jumps of amplitude bistability. The underlying coherent superposition of macroscopic quantum states is translated into the statistical properties of the integrated charge deposited in the detector circuit of a mode-matched heterodyne/homodyne detection scheme. At first, the dynamical evolution of a signal transmitted from an auxiliary cavity is employed to pinpoint a macroscopic switching event in a bistable main cavity subject to direct photodetection. Once the decision is made on the occurrence of a downward switch, the main cavity mode is let to freely decay to the vacuum, monitored to the production of an integrated charge. In the long-time limit, the charge distribution over an identical collection of pure states generated during the jumps converges to the Q function (heterodyne detection) or marginals of the Wigner function (homodyne detection) dictated by the phase of the local oscillator. When fluctuations over the ensemble step in, we connect the statistical properties of several switching events and the ensuing production of current records, to the cavity field correlations associated with the breakdown of photon blockade.

</details>


### [67] [Strongly driven cavity quantum electrodynamical-optomechanical hybrid system](https://arxiv.org/abs/2512.07788)
*Xuxin Wang,Jiahe Pan,Tobias J. Kippenberg,Shingo Kono*

Main category: quant-ph

TL;DR: 提出并演示了一种利用强驱动混合系统生成非高斯机械态的方案，该方案结合了腔QED和腔光力学，通过增强的光机械耦合将非高斯腔态转移到机械振子。


<details>
  <summary>Details</summary>
Motivation: 混合量子系统结合了不同物理平台的优势，但由于操作原理的潜在不兼容性，它们的集成并不总是简单的。本文旨在解决腔QED中非高斯态控制与腔光力学所需强腔驱动之间的兼容性问题。

Method: 在腔QED的色散区制备非高斯腔态，然后通过相干腔驱动增强的光机械相互作用将其转移到机械振子。开发了高效模拟框架来建模高光子数区域的腔QED动力学。

Result: 强腔驱动可以相干地位移腔态，同时最小化扰动，有效地将其与量子比特解耦。产生的大相干腔场增强了光机械耦合强度，实现了非高斯腔态到机械模式的高保真度转移。

Conclusion: 这些结果揭示了驱动腔QED的新动力学特征，为实现非高斯机械量子存储器和传感器开辟了新途径。

Abstract: Hybrid quantum systems harness the distinct advantages of different physical platforms, yet their integration is not always trivial due to potential incompatibilities in operational principles. Here, we theoretically propose and demonstrate a scheme for generating non-Gaussian mechanical states using a strongly driven hybrid system that combines cavity quantum electrodynamics (QED) and cavity optomechanics. Our protocol prepares a non-Gaussian cavity state in the dispersive regime of cavity QED and subsequently transfers it to a mechanical oscillator using the optomechanical interaction enhanced by a coherent cavity drive. While non-Gaussian cavity state control in cavity QED is well established in the dispersive regime, its behavior under strong cavity drive, essential for cavity optomechanics, remains largely unexplored. To bridge this gap, we develop an efficient simulation framework to model cavity QED dynamics in the high-photon-number regime. We show that a strong cavity drive can coherently displace the cavity state with minimal perturbations, effectively decoupling it from the qubit. The resulting large coherent cavity field enhances the optomechanical coupling strength, enabling high-fidelity transfer of non-Gaussian cavity states to the mechanical mode. These results reveal new dynamical features of driven cavity QED and open a pathway toward realizing non-Gaussian mechanical quantum memories and sensors.

</details>


### [68] [Fast-feedback protocols for calibration and drift control in quantum computers](https://arxiv.org/abs/2512.07815)
*Alicia B. Magann,Nathan E. Miller,Robin Blume-Kohout,Peter Maunz,Kevin C. Young*

Main category: quant-ph

TL;DR: 该论文提出了两种基于快速反馈的轻量级自适应校准协议，用于量子计算机的实时参数校准，包括基于不确定结果电路的逐次更新和基于确定结果电路的批量更新，并在存在退相干、SPAM误差和参数漂移的情况下验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 量子计算机需要持续校准以维持性能，传统校准方法耗时且无法应对实时参数漂移。需要开发轻量级、自适应的校准协议，能够利用快速反馈在量子计算过程中实时调整设备参数。

Method: 提出了两类校准协议：1）基于简单不确定结果量子电路的逐次更新协议，支持对单个或多个参数进行低延迟实时调整；2）基于确定结果电路（如量子纠错中的综合征提取电路）的批量更新协议，平衡效率与经典控制开销。通过数值模拟验证了两种方法在退相干、SPAM误差和参数漂移情况下的有效性，并提出了自适应超参数调整策略。

Result: 数值模拟表明，两种方法都能快速准确地校准1比特和2比特量子门。特别展示了仅使用综合征数据对[[5,1,3]]码进行实时原位校准的可行性，证明了在量子纠错过程中进行实时校准的潜力。

Conclusion: 提出的轻量级自适应校准协议为量子计算机提供了有效的实时参数调整方案，能够在存在各种误差源的情况下维持设备性能，为量子纠错等应用的持续运行提供了重要支持。

Abstract: We introduce two classes of lightweight, adaptive calibration protocols for quantum computers that leverage fast feedback. The first enables shot-by-shot updates to device parameters using measurement outcomes from simple, indefinite-outcome quantum circuits. This low-latency approach supports rapid tuning of one or more parameters in real time to mitigate drift. The second protocol updates parameters after collecting measurements from definite-outcome circuits (e.g.~syndrome extraction circuits for quantum error correction), balancing efficiency with classical control overheads. We use numerical simulations to demonstrate that both methods can calibrate 1- and 2-qubit gates rapidly and accurately even in the presence of decoherence, state preparation and measurement (SPAM) errors, and parameter drift. We propose and demonstrate effective adaptive strategies for tuning the hyperparameters of both protocols. Finally, we demonstrate the feasibility of real-time in-situ calibration of qubits performing quantum error correction, using only syndrome data, via numerical simulations of syndrome extraction in the [[5,1,3]] code.

</details>


### [69] [Comparing quantum channels using Hermitian-preserving trace-preserving linear maps: A physically meaningful approach](https://arxiv.org/abs/2512.07822)
*Arindam Mitra,Jatin Ghai*

Main category: quant-ph

TL;DR: 该论文提出了一种基于Hermitian保持迹保持线性映射的量子信道比较方法，建立了量子信道间的预序关系，并探讨了其在量子设备不兼容性方面的应用。


<details>
  <summary>Details</summary>
Motivation: 量子信道在传输量子态时通常会引入噪声，降低信息含量。现有的量子信道比较方法有限，需要一种物理意义明确的方式来比较不同量子信道之间的关系，特别是通过Hermitian保持迹保持线性映射来建立信道间的可转换性关系。

Method: 提出了一种基于Hermitian保持迹保持线性映射的量子信道比较框架。通过分析一对量子信道，证明如果一个信道的输出态可以通过对另一个信道的输出进行量子测量获得，那么后者可以通过在前者后级联一个Hermitian保持迹保持线性映射来获得。这种关系构成了一个预序关系。

Result: 建立了量子信道间的预序关系，并尝试对这种关系进行特征化描述。通过具体示例展示了该理论框架在量子设备不兼容性分析中的应用价值。

Conclusion: 该工作提供了一种物理意义明确的量子信道比较方法，通过Hermitian保持迹保持线性映射建立了信道间的预序关系，为量子信道分析和量子设备兼容性研究提供了新的理论工具。

Abstract: In quantum technologies, quantum channels are essential elements for the transmission of quantum states. The action of a quantum channel usually introduces noise in the quantum state and thereby reduces the information contained in it. Concatenating a quantum channel with another quantum channel makes it more noisy and degrades its information and resource preservability. These are mathematically described by completely positive trace-preserving linear maps that represent the generic evolution of quantum systems. These are special cases of Hermitian-preserving trace-preserving linear maps. In this work, we demonstrate a physically meaningful way to compare a pair of quantum channels using Hermitian-preserving trace-preserving linear maps. More precisely, given a pair of quantum channels and an arbitrary unknown input state, we show that if the output state of one quantum channel from the pair can be obtained from the output statistics of the other channel from the pair using some quantum measurement, then the latter channel from the pair can be obtained from the former channel by concatenating it with a Hermitian-preserving trace-preserving linear map. This relation between these two channels is a preorder, and we try to study its characterization in this work. We also illustrate the implications of our results for the incompatibility of quantum devices through an example.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [70] [Ultrasonic observation of small Fermi surfaces in La$T$In$_5$ ($T$ = Co, Rh, Ir)](https://arxiv.org/abs/2512.06235)
*Ryosuke Kurihara,Yusuke Hirose,Kazuki Matsui,Atsushi Miyake,Ryoma Tsunoda,Masaki Kondo,Rikio Settai,Mitsuhiro Akatsu,Yuichi Nemoto,Hiroshi Yaguchi,Masashi Tokunaga*

Main category: cond-mat.str-el

TL;DR: 对LaTIn5（T=Co、Rh、Ir）进行高场超声测量，发现这些化合物中存在隐藏的小费米面，其形成与过渡金属的3d电子有关


<details>
  <summary>Details</summary>
Motivation: 研究LaRhIn5中观察到的6.8T振荡频率对应的小费米面的起源，并探索其他LaTIn5化合物中是否存在类似的隐藏费米面

Method: 对LaTIn5（T=Co、Rh、Ir）化合物进行高场超声测量，通过量子振荡分析来探测费米面特性

Result: 1. 在LaRhIn5中观察到来自小费米面的量子振荡；2. 在LaCoIn5和LaIrIn5中发现频率低于100T的量子振荡，表明存在隐藏费米面；3. Co取代的LaRhIn5表现出10T频率的量子振荡

Conclusion: 小费米面起源于体材料性质，其形成与过渡金属的3d电子贡献有关

Abstract: We performed high-field ultrasonic measurements on La$T$In$_5$ ($T$ = Co, Rh, Ir) to reveal the origin of the small Fermi surface that was recently observed in LaRhIn$_5$ with an oscillation frequency of 6.8 T. We observed quantum oscillations originating from this Fermi surface in LaRhIn$_5$. In addition, we revealed that LaCoIn$_5$ and LaIrIn$_5$ exhibit quantum osciilations with frequencies below 100 T, indicating hidden Fermi surfaces in these compounds. Furthermore, Co-substituted LaRhIn$_5$ exhibited quantum oscillations with a frequency of 10 T. Our results suggest that the small Fermi surface originates from bulk properties and that $3d$ electrons of the transition metal contribute to its formation.

</details>


### [71] [Competing magnetic phases in Cr$_{3+δ}$Te$_4$ are spatially segregated](https://arxiv.org/abs/2512.06262)
*Vivek Bhartiya,Anirban Goswami,Nicholas Ng,Wei Tian,Matthew G. Tucker,Niraj Aryal,Lijun Wu,Weiguo Yin,Yimei Zhu,Milinda Abeykoon,Emmanuel Yakubu,Samaresh Guchhait,J. M. Tranquada*

Main category: cond-mat.str-el

TL;DR: 该研究通过中子衍射等技术发现Cr_{3+δ}Te_4晶体中存在铁磁和反铁磁相共存现象，揭示了磁性与晶格应变的敏感关系


<details>
  <summary>Details</summary>
Motivation: 研究Cr_{1+x}Te_2体系中铁磁与反铁磁相竞争的物理机制，解释先前报道中磁相共存现象的本质

Method: 使用单晶中子衍射、中子粉末衍射、X射线粉末衍射和透射电子显微镜对Cr_{3+δ}Te_4晶体进行表征，结合密度泛函理论计算

Result: δ=-0.10样品中存在两种单斜相：铁磁相（T_C≈321K）和反铁磁相（T_N≈86K），而δ=-0.26样品仅显示铁磁有序；观察到相反符号的自发磁致伸缩

Conclusion: 两种磁相以细粒度（<100nm）共生形式存在，源于生长过程中的旋节分解；磁有序对晶格应变敏感，解释了体材料与薄膜样品间的差异

Abstract: Cr$_{1+x}$Te$_2$ is a self-intercalated vdW system that is of current interest for its room-temperature FM phases and tunable topological properties. Early NPD measurements on the monoclinic phase Cr$_3$Te$_4$ ($x=0.5$) presented evidence for competing FM and AFM phases. Here we apply neutron diffraction to a single crystal of Cr$_{3+δ}$Te$_4$ with $δ=-0.10$ and discover that it consists of two distinct monoclinic phases, one with FM order below $T_{\rm C} \approx 321$ K and another that develops AFM order below $T_{\rm N} \approx 86$ K. In contrast, we find that a crystal with $δ=-0.26$ exhibits only FM order. The single-crystal analysis is complemented by results obtained with NPD, XPD, and TEM measurements on the $δ=-0.10$ composition. From observations of spontaneous magnetostriction of opposite sign at $T_{\rm C}$ and $T_{\rm N}$, along with the TEM evidence for both monoclinic phases in a single thin ($\approx$ 100 nm) grain, we conclude that the two phases must have a fine-grained ($\lesssim$ 100 nm) intergrowth character, as might occur from high-temperature spinodal decomposition during the growth process. Calculations of the relaxed lattice structures for the FM and AFM phases with DFT provide a rationalization of the observed spontaneous magnetostrictions. Correlations between the magnitude and orientation of the magnetic moments with lattice parameter variation demonstrate that the magnetic orders are sensitive to strain, thus explaining why magnetic ordering temperatures and anisotropies can be different between bulk and thin-film samples, when the latter are subject to epitaxial strain. Our results point to the need to investigate the supposed coexistence FM and AFM phases reported elsewhere in the Cr$_{1+x}$Te$_2$ system, such as in the Cr$_5$Te$_8$ phase ($x=0.25$).

</details>


### [72] [Kitaev Meets AKLT: Competing Quantum Disorder in Spin-3/2 Honeycomb Systems](https://arxiv.org/abs/2512.06322)
*Sogen Ikegami,Kiyu Fukui,Rico Pohle,Yukitoshi Motome*

Main category: cond-mat.str-el

TL;DR: S=3/2量子自旋模型在蜂窝晶格上研究Kitaev量子自旋液体和AKLT价键固体两种量子无序态之间的连续过渡，发现经典和半经典预测的非共面序在完全量子涨落下熔化形成量子纠缠态。


<details>
  <summary>Details</summary>
Motivation: 研究具有不同纠缠结构的两种典型量子无序态（Kitaev量子自旋液体和AKLT价键固体）之间的连续过渡，探索它们竞争和量子涨落如何产生新的非常规相。

Method: 结合经典、半经典和精确对角化方法，在二维蜂窝晶格上研究S=3/2量子自旋模型，绘制基态相图并分析整个参数范围内的量子涨落作用。

Result: 经典和半经典框架预测非共面序与共线奈尔态竞争，但这些相在完全量子涨落下是脆弱的，会熔化形成具有抑制自旋关联和增强纠缠熵特征的量子纠缠态。

Conclusion: 定性不同的量子无序相之间的竞争为从它们相互作用和量子涨落中出现的非常规相提供了肥沃的研究平台。

Abstract: We investigate an S=3/2 quantum spin model on a two-dimensional honeycomb lattice that continuously interpolates between two paradigmatic quantum disordered states with distinct entanglement structures: the Kitaev quantum spin liquid and the Affleck-Kennedy-Lieb-Tasaki (AKLT) valence bond solid. Combining classical, semi-classical, and exact diagonalization approaches, we map out the ground-state phase diagram and elucidate the role of quantum fluctuations across the entire parameter range. While classical and semi-classical frameworks predict noncoplanar orders competing with a collinear Néel state, we find these phases to be fragile: once full quantum fluctuations are included, they melt into a quantum-entangled state characterized by suppressed spin correlations and enhanced entanglement entropy. Our findings highlight how competition between qualitatively different quantum disordered phases provides a fertile playground for unconventional phases emerging from their interplay and quantum fluctuations.

</details>


### [73] [Coincidence detection techniques for direct measurement of many-body correlations in strongly correlated electron systems](https://arxiv.org/abs/2512.06593)
*Yuehua Su,Guoya Zhang,Chao Zhang,Dezhong Cao*

Main category: cond-mat.str-el

TL;DR: 该视角文章讨论了理论上提出的符合探测技术，旨在直接测量各种粒子-粒子和粒子-空穴通道中的二体关联，并探讨了这些技术在未来理论和实验发展中的前景。


<details>
  <summary>Details</summary>
Motivation: 强关联电子系统研究面临的基本挑战在于内在多体关联的复杂性，需要发展能够直接探测和阐明这些关联的实验方法。

Method: 讨论理论上提出的符合探测技术，这些技术设计用于直接测量各种粒子-粒子和粒子-空穴通道中的二体关联，具有动量、能量和/或空间分辨率。

Result: 这些符合探测技术有望为解开强关联电子系统中的长期谜题提供强大的新方法，如非常规超导的奥秘机制和长期寻找的量子自旋液体。

Conclusion: 符合探测技术的成功实施和完善将为研究量子材料中的新型现象（如巡游磁性和电子向列性）提供强大的新方法，推动强关联电子系统研究的发展。

Abstract: Research on strongly correlated electron systems faces a fundamental challenge due to the complex nature of intrinsic many-body correlations. A key strategy to address this challenge lies in advancing experimental methods that can directly probe and elucidate the underlying many-body correlations. In this perspective article, we discuss the theoretically proposed coincidence detection techniques, which are designed to directly measure two-body correlations in various particle-particle and particle-hole channels, with momentum, energy, and/or spatial resolution. We also explore the prospects of these coincidence detection techniques for future theoretical and experimental developments. The successful implementation and refinement of these coincidence detection techniques promise to deliver powerful new approaches for unraveling long-standing puzzles in strongly correlated electron systems, such as the enigmatic mechanism of unconventional superconductivity and the long-sought quantum spin liquids. Furthermore, these coincidence detection techniques will offer powerful new methods to investigate novel phenomena like itinerant magnetism and electronic nematicity in quantum materials.

</details>


### [74] [Spurious Strange Correlators in Symmetry-Protected Topological Phases](https://arxiv.org/abs/2512.06691)
*Wei-Liang Gao,Jie-Yu Zhang,Zheng-Xin Liu,Peng Ye*

Main category: cond-mat.str-el

TL;DR: 本文指出奇怪关联子在检测对称保护拓扑相时，若参考态选择不当，会在平凡SPT相中产生虚假的长程关联信号，导致误判。通过矩阵乘积态分析，揭示了三种导致转移矩阵简并的机制。


<details>
  <summary>Details</summary>
Motivation: 奇怪关联子作为检测对称保护拓扑相的重要工具，其结果的准确性严重依赖于参考态的选择。当前研究缺乏对参考态选择不当可能导致的虚假信号的系统分析，这可能导致对SPT相的误判。

Method: 使用矩阵乘积态表示，分析平凡SPT相中奇怪关联子的行为。通过转移矩阵的幅度简并来追踪虚假信号的起源，并系统分类了三种导致这种简并的机制。

Result: 识别出三种导致虚假长程奇怪关联子的机制：1）纠缠空间中存在高维不可约表示；2）目标态与参考态之间对称性表示的相位失配；3）对称性破缺导致的长程序。这些机制通过具体实例得到了验证。

Conclusion: 参考态的选择对奇怪关联子的准确性至关重要。本文阐明了参考态选择不当可能导致的三种虚假信号机制，为避免误判和正确识别SPT序提供了指导原则。

Abstract: Strange correlator is a powerful tool widely used in detecting symmetry-protected topological (SPT) phases. However, the result of strange correlator crucially relies on the adoption of the reference state. In this work, we report that an ill-chosen reference state can induce spurious long-range strange correlators in trivial SPT phases, leading to false positives in SPT diagnosis. Using matrix product state (MPS) representation, we trace the origin of these spurious signals in trivial SPT phases to the magnitude-degeneracy of the transfer matrix. We systematically classify three distinct mechanisms responsible for such degeneracy, each substantiated by concrete examples: (1) the presence of high-dimensional irreducible representations in the entanglement space; (2) a phase mismatch in symmetry representations between the target and reference states; and (3) long-range order arising from symmetry breaking. Our findings clarify the importance of the choice of proper reference states, providing a guideline to avoid pitfalls and correctly identify SPT order using strange correlators.

</details>


### [75] [Exploring electron spin dynamics in spin chains using defects as a quantum probe](https://arxiv.org/abs/2512.06722)
*L. Soriano,A. Manoj-Kumar,G. Gerbaud,A. Savoyant,R. Dassonneville,H. Vezin,O. Jeannin,M. Orio,M. Fourmigué,S. Bertaina*

Main category: cond-mat.str-el

TL;DR: 研究二聚化链中拓扑缺陷（边缘态）的电子自旋共振量子动力学，发现这些受全局系统保护的量子多体多重态具有抗环境退相干特性，并揭示了自旋晶格弛豫和相干时间的调控机制。


<details>
  <summary>Details</summary>
Motivation: 尽管最近在实现孤立有限自旋链方面取得了进展，但量子器件的潜在应用需要了解弛豫和退相干源。研究拓扑缺陷边缘态的量子动力学对于优化量子材料相干性至关重要。

Method: 研究二聚化链中拓扑缺陷（边缘态）的电子自旋共振量子动力学，分析自旋晶格弛豫机制、链间有效偶极场和链内交换耦合的影响。

Result: 1. 电子自旋晶格弛豫在低温下受声子瓶颈过程控制，在高温下受链二聚化能隙控制；2. 链内交换耦合降低了边缘态间的有效偶极场，使相干时间比等效浓度下的孤立离子更长；3. 均匀展宽由链内偶极场控制。

Conclusion: 建立了优化未来材料相干性的设计原则，表明通过调控链内交换耦合和二聚化能隙可以显著增强拓扑缺陷边缘态的量子相干性。

Abstract: We investigate the quantum dynamics of the electron spin resonance of topological defects (edge state) in dimerized chains. These objects are discontinuities of the spin chain protected by the properties of the global system leading to a quantum many-body multiplet protected from the environment decoherence. Despite recent achievements in the realization of isolated and finite spin chains, the potential implementation in quantum devices needs the knowledge of the relaxation and decoherence sources. Our study reveals that electron spin lattice relaxation is governed at lowest temperatures by phonon-bottlenecked process and at high temperature by the chain dimerization gap. We show that the inter edge-state effective dipolar field is reduced by the intrachain exchange coupling leading to a longer coherence time than isolated ions at equivalent concentration. Ultimately, we demonstrate that the homogeneous broadening is governed by the intra-chain dipolar field, and we establish design principles for optimizing coherence in future materials.

</details>


### [76] [A Numerical Perspective on Moiré Superlattices: From Single-Particle Properties to Many-Body Physics](https://arxiv.org/abs/2512.07115)
*Xin Lu,Bo Xie,Jianpeng Liu*

Main category: cond-mat.str-el

TL;DR: 该论文提出了一套研究莫尔超晶格中关联和拓扑态的理论工作流程，结合了连续介质模型、Hartree-Fock平均场近似、多体微扰理论和精确对角化方法，重点关注数值实现细节和常被忽略的技术问题。


<details>
  <summary>Details</summary>
Motivation: 二维材料中的莫尔超晶格为探索强关联和拓扑相提供了多功能平台，但现有理论研究往往忽略了一些关键技术细节（如远程带效应、非均匀和动态屏蔽、双计数问题等），需要一套系统的工作流程来连接技术细节与物理解释。

Method: 提出一个综合理论工作流程，结合：1）连续介质建模；2）Hartree-Fock平均场近似；3）多体微扰理论；4）精确对角化方法。特别关注数值实现中的技术细节，包括远程带效应、非均匀和动态屏蔽、双计数问题等常被忽略的微妙问题。

Result: 该工作流程能够系统地研究莫尔超晶格中出现的对称破缺基态性质、准粒子激发性质和分数陈绝缘体相，提供与实验观测直接相关的见解，有助于理解和预测莫尔材料中的关联现象。

Conclusion: 通过连接技术细节和物理解释，这项工作旨在指导理论家和实验家在理解和预测莫尔材料中的关联现象，为研究莫尔超晶格中的关联和拓扑态提供了一个实用的理论框架。

Abstract: Moiré superlattices in two-dimensional materials provide a versatile platform to explore strongly correlated and topological phases. This work presents a practical theoretical workflow for studying the correlated and topological states in moiré systems, combining continuum modeling, Hartree-Fock mean-field approximations, many-body perturbation theory, and exact diagonalizations. We focus on the numerical implementation of these methods, emphasizing subtleties such as remote band effects, inhomogeneous and dynamical screening, double counting problem, etc., which are often swept under the rug in theoretical works. The workflow enables a systematic investigation of symmetry-breaking ground state properties, quasiparticle excitation properties and fractional Chern insulator phases emerging from moiré superlattices, providing insights that are directly relevant to experimental observations. By bridging technical details and physical interpretations, this work aims to guide both theorists and experimentalists in understanding and predicting correlated phenomena in moiré materials.

</details>


### [77] [Quantum coherent states of mass-imbalanced electron-hole system within optical microcavities](https://arxiv.org/abs/2512.07294)
*Thi-Hau Nguyen,Thi-Hong-Hai Do,Van-Nham Phan*

Main category: cond-mat.str-el

TL;DR: 研究质量不平衡电子-空穴系统中激子极化激元、极化激元和光子极化激元相干态的相互作用，发现随着质量不平衡减小，系统会从无序态依次转变为激子样、极化激元和光子样极化激元凝聚态。


<details>
  <summary>Details</summary>
Motivation: 研究光学微腔中质量不平衡电子-空穴系统中不同极化激元相干态的竞争和相变，理解电子-空穴库仑吸引和光-物质耦合共同作用下的凝聚现象。

Method: 采用无限制Hartree-Fock近似，推导自洽方程组评估两带电子模型中的激子和光子序参数，同时考虑电子-空穴库仑吸引和光-物质耦合。

Result: 随着质量不平衡减小，系统从无序态转变为激子样、极化激元和光子样极化激元凝聚态；增加激发密度会扩展凝聚态范围；降低质量不平衡会在形成稳定凝聚前出现量子相干束缚态。

Conclusion: 质量不平衡电子-空穴系统中存在复杂的极化激元相干态相结构，可通过动量分布和波数分辨光电子谱识别不同凝聚态特征，为理解光-物质耦合系统中的量子相变提供理论框架。

Abstract: The interplay of the excitoniclike polariton, polariton, and photoniclike polariton coherent states in mass-imbalanced electron-hole systems within optical microcavities is theoretically examined. Utilizing the unrestricted Hartree-Fock approximation, we derive a set of self-consistent equations that evaluate the excitonic and photonic order parameters in a two-band electronic model, accounting equally for both electron-hole Coulomb attraction and light-matter coupling. Analyzing the competition among these condensate order parameters reveals a complex phase structure of coherent states in the ground state. As the mass imbalance is reduced, we observe a transition from a normal disordered electron-hole-photon system to excitoniclike, polariton, and ultimately photoniclike polariton condensation states. The distinct features of these robust condensates can be identified in the momentum distribution of the electron-hole pair amplitude and the photonic density, as well as in the wave-number-resolved photoemission spectra of electrons, holes, and photons. Increasing the excitation density further expands the range of condensation states. Additionally, lowering the mass imbalance leads to the emergence of quantum coherent bound states prior to the formation of robust condensates, which are evidenced by the static and dynamical excitonic and photonic susceptibility functions.

</details>


### [78] [Single-Q and Double-Q magnetic orders: A Theoretical Analysis of Inelastic Neutron Scattering in a Centrosymmetric Structure](https://arxiv.org/abs/2512.07428)
*Artem O. Nosenko,Dmitri V. Efremov*

Main category: cond-mat.str-el

TL;DR: 对比双Q磁结构与单Q磁结构的动态磁结构因子


<details>
  <summary>Details</summary>
Motivation: 近年来在中心对称化合物中发现的多Q磁结构引起了对其微观起源和可观测性质的广泛兴趣

Method: 计算双Q磁结构的动态磁结构因子，并与单Q构型进行比较

Result: 未在摘要中明确给出具体结果，但暗示了双Q与单Q磁结构在动态磁结构因子方面的差异

Conclusion: 通过对比分析，有助于理解多Q磁结构的微观机制和可观测特性

Abstract: Recent discoveries of multi-\textbf{Q} magnetic structures in centrosymmetric
  compounds have stimulated growing interest in their microscopic origin and observable properties.
  Here, we calculate the dynamical magnetic structure factor for a double-\textbf{Q} magnetic
  structure and compare it with that of a single-\textbf{Q} configuration.

</details>


### [79] [On the Role of the Canonical Transformation in the Single-Channel Kondo Model](https://arxiv.org/abs/2512.07465)
*Zehra Özcan*

Main category: cond-mat.str-el

TL;DR: 该教学性工作展示了正则变换在解释阿贝尔玻色化的单通道SU(2)近藤模型中的重要作用，特别是对标度维度Δ的影响。


<details>
  <summary>Details</summary>
Motivation: 通过分析正则变换如何影响标度维度，揭示不同参数选择如何导致边际或相关区域，从而更直接地从玻色化哈密顿量追踪标度行为。

Method: 使用正则变换处理玻色化的单通道SU(2)近藤模型，变换改变纵向交换耦合并修正自旋翻转顶点τ±e±iβφ的标度维度，保持α显式而非固定Δ为费米子值1/2。

Result: 通过(1-Δ(α))J⊥可以识别不同选择如何导致边际或相关区域，该方法能够直接从玻色化哈密顿量追踪标度行为，并展示RG流如何与近藤温度定义连接。

Conclusion: 正则变换为理解玻色化近藤模型的标度行为提供了直接途径，展示了RG流与近藤温度定义的连接，其中电阻发散，无需切换到其他方法。

Abstract: This pedagogical work presents the significant role that canonical transformation plays in the interpretation of the Abelian bosonized single-channel SU(2) Kondo model, emphasizing its effect on the scaling dimension $Δ$. The transformation shifts the longitudinal exchange coupling and modifies the scaling dimension of the spin-flip vertex $τ_{\pm} e^{\pm iβφ}$. Rather than fixing $Δ$ to the fermionic value $\tfrac{1}{2}$, we keep $α$ explicit, which allows us to identify how different choices lead to marginal or relevant regimes through $(1-Δ(α))J_\perp$. This approach offers a direct way to trace the scaling behavior from the bosonized Hamiltonian and shows how the RG flow connects to the definition of the Kondo temperature, where the resistance diverges, without switching to other methods.

</details>


### [80] [Interplay of Kekulé bond order and lattice instability in $\mathrm{C}_6\mathrm{Li}$](https://arxiv.org/abs/2512.07491)
*Yuanhao Zhang,Zi Yuan,Xiangru Kong,Weijiang Gong,Shaozhi Li*

Main category: cond-mat.str-el

TL;DR: C6Li作为研究电荷序的新平台，揭示了两种不同机制介导的Kekulé键序：一种由碳π轨道和锂s轨道杂化产生的有效长程跳跃驱动，另一种由费米面嵌套驱动，两者均通过电声耦合诱导晶格畸变。


<details>
  <summary>Details</summary>
Motivation: 理解量子材料中电荷序与晶格不稳定性之间的相互作用是一个核心挑战，因为它们的共存常常模糊了因果关系。本研究旨在通过C6Li这一新平台阐明电子序和结构序之间的因果层次关系。

Method: 引入C6Li作为研究平台，分析碳π轨道和锂s轨道杂化产生的有效长程跳跃机制，研究该跳跃如何驱动Kekulé键序，并探讨键序如何通过电声耦合诱导晶格畸变。同时分析锂原子远离石墨烯层时的费米面嵌套驱动机制。

Result: 发现碳π轨道和锂s轨道杂化产生有效长程跳跃，驱动Kekulé键序，其结构随电荷密度和跳跃符号变化。该键序通过电声耦合诱导Kekulé晶格畸变。当锂原子远离石墨烯层时，费米面嵌套驱动的Kekulé键序出现，并由电声相互作用稳定。

Conclusion: C6Li作为可调控平台，为阐明量子材料中电子序和结构序之间的因果层次关系提供了新途径，揭示了电荷序可以通过不同机制介导并诱导晶格畸变。

Abstract: Understanding the interplay between charge order and lattice instability in quantum materials remains a central challenge, as their coexistence often obscures causal relationships. This work introduces $\mathrm{C}_6\mathrm{Li}$ as a novel platform to investigate charge order mediated by two distinct mechanisms. We show that the hybridization between carbon $π$ and lithium $s$ orbitals generates an effective long-range hopping within Li-centered hexagons. This hopping drives a Kekulé bond order, whose structure varies with charge density and the sign of the hopping. This bond order induces a Kekulé lattice distortion via electron-phonon coupling. In the limit where lithium atoms are distant from the graphene layer, a Fermi surface nesting-driven Kekulé bond order emerges, stabilized by the electron-phonon interaction. Our results establish $\mathrm{C}_6\mathrm{Li}$ as a tunable platform for elucidating the causal hierarchy between electronic and structural orders in quantum materials.

</details>


### [81] [Valence band-satellite, temperature dependent magnetic and spectral study of α-Fe](https://arxiv.org/abs/2512.07505)
*Trishu Verma,Shivani Bhardwaj,Sudhir K Pandey*

Main category: cond-mat.str-el

TL;DR: 研究α-Fe中关联效应和等离子体激发对价带卫星谱的影响，分析温度依赖的磁性和光谱特性，揭示强关联和温度依赖的光谱特征


<details>
  <summary>Details</summary>
Motivation: 研究α-Fe中价带卫星谱的起源，探讨关联效应、等离子体激发以及温度对磁性和光谱性质的影响，理解铁磁相中的强关联特征

Method: 采用约束随机相位近似(cRPA)获取库仑相互作用参数，结合密度泛函理论加动力学平均场理论(DFT+DMFT)计算价带光谱，使用G₀W₀方法分析等离子体激发

Result: 在~6 eV结合能处发现价带卫星谱，由DFT+DMFT的非相干谱权重和G₀W₀计算的~6-8 eV等离子体激发共同支持；观察到温度依赖的泡利自旋磁化率，e_g态在T_c附近表现出强温度驱动的非费米液体行为，高温下轨道选择性相干性损失导致轨道选择性磁化崩溃

Conclusion: α-Fe的铁磁相具有强关联和温度依赖的光谱特征，价带卫星谱由关联效应和等离子体激发共同决定，高温下轨道选择性相干性损失是磁化崩溃的关键机制

Abstract: We investigate the influence of correlations and plasmonic excitation on valence band-satellite of $α$-Fe, along with magnetic and spectral properties as function of temperature. Coulomb interaction parameters are obtained by systematically employing various schemes in constrained random phase approximation (cRPA). This study identifies the presence of valence band satellite in Fe at $\sim$6 eV binding energy supported by (i) substantial incoherent spectral weight in the valence band spectra obtained from Density Functional Theory plus Dynamical Mean Field Theory (DFT+DMFT) and (ii) plasmonic excitations in the frequency range $\sim$6-8 eV suggested by $G_0W_0$ calculations. We note presence of significant contribution of temperature-dependent Pauli-spin susceptibility indicating competing degree of itinerancy. $e_g$ state shows a strong temperature driven non-Fermi-liquid behavior emerging near $T_c$. Our results reveal a high-temperature orbital-selective loss of coherence eventually leads to a orbital selective collapse of magnetization at $T_c$, suggesting a ferromagnetic phase characterized by strong correlation- and temperature- dependent spectral features.

</details>


### [82] [Interlayer coupling driven phase evolution in hyperbolic $1T$-TaS$_2$](https://arxiv.org/abs/2512.07508)
*Achyut Tiwari,Bruno Gompf,Martin Dressel*

Main category: cond-mat.str-el

TL;DR: 1T-TaS₂中电荷密度波相变的三维层间驱动渗流过程研究，发现该材料在可见光范围具有天然II型双曲行为，且金属畴形状随温度从盘状变为针状。


<details>
  <summary>Details</summary>
Motivation: 理解微观相互作用如何控制宏观相变是量子材料研究的核心问题。1T-TaS₂中存在电荷密度波、莫特态和超导性之间的竞争，特别是金属-绝缘体转变的细节和层间耦合的作用尚未明确。

Method: 使用光谱椭偏仪测量块体1T-TaS₂从室温到绝缘态的单轴介电响应，结合各向异性Bruggeman有效介质分析，研究温度依赖的椭偏数据。

Result: 室温数据显示在可见光范围具有天然II型双曲行为（负面内和正面向外介电常数）。温度依赖分析表明，负责渗流的金属畴形状从盘状演变为针状，加热时出现额外的中间相。

Conclusion: 1T-TaS₂中的相变被确定为三维、层间驱动的渗流过程，该材料被确立为天然可调谐的双曲介质。

Abstract: Understanding how microscopic interactions control macroscopic phase transitions is central to quantum materials, where charge density waves (CDWs), Mott states, and superconductivity often compete. In $1T$-TaS$_2$, this competition is tied to a sequence of CDW phases and a hysteretic metal-insulator transition, but details of the transition, especially the role of interlayer coupling, remain unresolved. In this work, spectroscopic ellipsometry is used to determine the uniaxial dielectric response of bulk $1T$-TaS$_2$ from room temperature down to the commensurate insulating state. The room-temperature data reveal natural type-II hyperbolic behavior in the visible range, with negative in-plane and positive out-of-plane permittivity. Temperature-dependent ellipsometry combined with anisotropic Bruggeman effective medium analysis shows that the metallic domains responsible for percolation evolve from disc-like to needle-like shapes, and that, upon heating, an additional intermediate phase emerges. These results identify the transition in $1T$-TaS$_2$ as a three-dimensional, interlayer-driven percolation process and establish this material as a natural, tunable hyperbolic medium.

</details>


### [83] [Critical Density-Wave Vestigial Phases of Commensurate Pair Density Wave](https://arxiv.org/abs/2512.07591)
*Chu-Tian Gao,Jing Zhou,Yu-Bo Liu,Fan Yang*

Main category: cond-mat.str-el

TL;DR: 该研究系统分析了二维可公度配对密度波（PDW）的残留相，发现当晶格扩展倍数n≤4时存在电荷密度波残留相，而n≥5时会出现通过两个BKT转变恢复平移对称性的两步过程，产生临界PDW和临界CDW相。


<details>
  <summary>Details</summary>
Motivation: 实验观测到的PDW通常为可公度形式，但其残留相尚未得到系统研究。先前研究主要关注不可公度PDW，因此需要填补可公度PDW残留相研究的空白。

Method: 基于Ginzburg-Landau理论建立低能有效模型哈密顿量，随后采用重整化群（RG）和蒙特卡洛（MC）方法计算相图和空间相关函数。

Result: 对于n≤4，除了电荷-4e/2e超导性外，还存在平移对称性破缺的电荷密度波（CDW）残留相。对于n≥5，随着温度升高，平移对称性的恢复通过两个连续的Berezinskii-Kosterlitz-Thouless转变实现，产生临界PDW和临界CDW相，其中离散平移对称性准破缺，导致即使在二维情况下密度-密度相关函数也呈幂律衰减。

Conclusion: 该研究首次系统揭示了可公度PDW的残留相行为，特别是n≥5时的两步转变过程，为实验验证提供了理论预测。

Abstract: The pair-density-wave (PDW) is an exotic pairing state hosting a spatially modulated pairing order parameter, which has attracted great interest. Due to its simultaneously breaking U(1)-gauge and translational symmetries, intriguing vestigial phases which restore only one broken symmetry can emerge at an intermediate temperature regime. Previously, investigations on the vestigial phases of PDW were mainly focused on incommensurate PDW. However, the experimentally observed PDW is usually commensurate, whose vestigial phases have not been systematically investigated. Here we study the vestigial phases of 2D commensurate PDW with $n$-times expanded unit vectors, hosting different numbers of wave vectors. Based on the Ginzburg-Landau theory, we get the low energy effective model Hamiltonian. Subsequent renormalization group (RG) and Monte-Carlo (MC) studies are conducted to obtain the phase diagram and spatial dependent correlation functions. Our RG and MC calculations consistently yield the following result. For $n\le 4$, besides the charge-4e/2e superconductivity, there exists the translational symmetry broken charge-density-wave (CDW) vetigial phase. Intriguingly, for $n\ge 5$, the restore of the translational symmetry with increasing temperature is realized through two successive Berezinskii-Kosterlitz-Thouless transitions. Such a two-step process leads into two critical vestigial phases, i.e. the critical-PDW and the critical-CDW phases, in which the discrete translational symmetry is quasily broken, leading into a power-law decaying density-density correlation even at 2D. Our work appeals for experimental verifications.

</details>


### [84] [Extreme Strain Controlled Correlated Metal-Insulator Transition in the Altermagnet CrSb](https://arxiv.org/abs/2512.07683)
*Cong Li,Mengli Hu,Jianfeng Zhang,Magnus H. Berntsen,Francesco Scali,Dibya Phuyal,Chun Lin,Wanyu Chen,Johan Chang,Oliver J. Clark,Timur K. Kim,Jacek Osiecki,Craig Polley,Balasubramanian Thiagarajan,Zhilin Li,Tao Xiang,Oscar Tjernberg*

Main category: cond-mat.str-el

TL;DR: 通过极端拉伸应变在反铁磁体CrSb中实现了平带特征与轨道选择性自旋织构的共存，为应变调控相关平带和自旋织构态提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 平带物理和反铁磁性是量子材料中两个重要研究方向，前者关注相互作用主导的相，后者关注对称性保护的自旋织构态。两者都源于晶格对称性和轨道杂化，暗示极端晶格畸变可能将两者统一于单一材料中，但实现这种大畸变极具挑战。

Method: 结合专用应变装置和定制单晶安装方案，在块体CrSb中施加高度拉伸应变梯度，创建近表面强畸变层。使用角分辨光电子能谱测量应变响应，并通过密度泛函理论计算分析自旋织构变化。

Result: 发现两个应变区域：中等应变下可逆区域，出现深度平带特征（应变梯度抑制Cr-Sb杂化所致）与关联增强的Cr 3d平带共存；大应变下不可逆区域，部分键解耦导致主要绝缘谱响应。密度泛函计算显示，尽管带宽重正化强烈，轨道选择性反铁磁自旋织构在整个关联区域持续存在。

Conclusion: 建立了CrSb的应变-对称性-关联映射，证明极端拉伸应变是共同调控反铁磁体中平带倾向和零净矩自旋织构关联态的有效途径，为应变自适应、自旋选择性莫特滤波及相关器件概念指明方向。

Abstract: Correlated flat bands and altermagnetism are two important directions in quantum materials, centred respectively on interaction-dominated phases and symmetry-enforced spin-textured states, yet both derive from lattice symmetry and orbital hybridization. This common origin implies that extreme crystal distortion, by narrowing bandwidths, enhancing correlations and reshaping the symmetries of altermagnetic spin splittings, could unify flat-band and altermagnetic physics in a single material; in practice, however, achieving such large distortions in a crystalline altermagnet is a formidable challenge. Here we combine a dedicated strain device with a tailored single-crystal mounting scheme to impose a highly tensile strain gradient in bulk CrSb, a prototypical altermagnet, creating a near-surface layer in which the in-plane lattice is strongly distorted relative to the weakly strained bulk, while the average bulk distortion remains small. Angle-resolved photoemission reveals a reversible regime at moderate strain, where a deeper flat-band feature, attributed to a strain-gradient-driven suppression of Cr-Sb hybridization, coexists with a correlation-enhanced Cr 3d flat band, and an irreversible regime at larger strain where partial bond decoupling drives a predominantly insulating spectral response. Density-functional calculations show that an orbital-selective altermagnetic spin texture persists across this correlated regime despite strong bandwidth renormalisation. These results define a strain-symmetry-correlation map for CrSb and establish extreme tensile strain as a route to co-engineer flat-band tendencies and spin-textured, zero-net-moment correlated states in altermagnets, pointing toward strain-adaptive, spin-selective Mott filtering and related device concepts.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [85] [A self-driving lab for solution-processed electrochromic thin films](https://arxiv.org/abs/2512.05989)
*Selma Dahms,Luca Torresi,Shahbaz Tareq Bandesha,Jan Hansmann,Holger Röhm,Alexander Colsmann,Marco Schott,Pascal Friederich*

Main category: cs.LG

TL;DR: 利用自驱动实验室结合自动化和机器学习加速电致变色涂层的开发，通过贝叶斯优化高效探索工艺参数


<details>
  <summary>Details</summary>
Motivation: 溶液处理电致变色材料在节能智能窗户和显示器中具有高潜力，但其性能受材料和工艺条件影响。电致变色薄膜电极需要光滑无缺陷的涂层以获得最佳对比度，而旋涂工艺参数优化的复杂性阻碍了快速开发

Method: 采用自驱动实验室系统，结合自动化数据采集、图像处理、光谱分析和贝叶斯优化，高效探索电致变色涂层的工艺参数

Result: 该方法不仅提高了通量，还能有针对性地搜索最优工艺参数，可应用于各种溶液处理材料

Conclusion: 自驱动实验室在加速材料发现和工艺优化方面具有巨大潜力，为电致变色涂层及其他溶液处理材料的高效开发提供了新途径

Abstract: Solution-processed electrochromic materials offer high potential for energy-efficient smart windows and displays. Their performance varies with material choice and processing conditions. Electrochromic thin film electrodes require a smooth, defect-free coating for optimal contrast between bleached and colored states. The complexity of optimizing the spin-coated electrochromic thin layer poses challenges for rapid development. This study demonstrates the use of self-driving laboratories to accelerate the development of electrochromic coatings by coupling automation with machine learning. Our system combines automated data acquisition, image processing, spectral analysis, and Bayesian optimization to explore processing parameters efficiently. This approach not only increases throughput but also enables a pointed search for optimal processing parameters. The approach can be applied to various solution-processed materials, highlighting the potential of self-driving labs in enhancing materials discovery and process optimization.

</details>


### [86] [Memory-Amortized Inference: A Topological Unification of Search, Closure, and Structure](https://arxiv.org/abs/2512.05990)
*Xin Li*

Main category: cs.LG

TL;DR: 论文提出了记忆摊销推理（MAI）框架，使用代数拓扑统一学习和记忆，通过同调奇偶原理区分内容与上下文，将高复杂度搜索转化为低复杂度查找。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习将参数静态结构与推理动态流程分离，缺乏生物认知的样本效率和热力学经济性，需要统一学习和记忆的理论框架。

Method: 基于代数拓扑的MAI框架，引入同调奇偶原理区分偶维同调（稳定内容）和奇维同调（动态上下文），通过拓扑循环闭合机制实现搜索到查找的转化。

Result: 建立了认知过程的拓扑三位一体变换：搜索→闭合→结构，将NPSPACE复杂度搜索转化为P复杂度查找，为快思考（直觉）从慢思考（推理）中涌现提供理论解释。

Conclusion: MAI框架为后图灵架构提供了蓝图，通过拓扑共振进行计算，统一了学习和记忆，解释了认知效率的数学基础。

Abstract: Contemporary ML separates the static structure of parameters from the dynamic flow of inference, yielding systems that lack the sample efficiency and thermodynamic frugality of biological cognition. In this theoretical work, we propose \textbf{Memory-Amortized Inference (MAI)}, a formal framework rooted in algebraic topology that unifies learning and memory as phase transitions of a single geometric substrate. Central to our theory is the \textbf{Homological Parity Principle}, which posits a fundamental dichotomy: even-dimensional homology ($H_{even}$) physically instantiates stable \textbf{Content} (stable scaffolds or ``what''), while odd-dimensional homology ($H_{odd}$) instantiates dynamic \textbf{Context} (dynamic flows or ``where''). We derive the logical flow of MAI as a topological trinity transformation: \textbf{Search $\to$ Closure $\to$ Structure}. Specifically, we demonstrate that cognition operates by converting high-complexity recursive search (modeled by \textit{Savitch's Theorem} in NPSPACE) into low-complexity lookup (modeled by \textit{Dynamic Programming} in P) via the mechanism of \textbf{Topological Cycle Closure}. We further show that this consolidation process is governed by a topological generalization of the Wake-Sleep algorithm, functioning as a coordinate descent that alternates between optimizing the $H_{odd}$ flow (inference/wake) and condensing persistent cycles into the $H_{even}$ scaffold (learning/sleep). This framework offers a rigorous explanation for the emergence of fast-thinking (intuition) from slow-thinking (reasoning) and provides a blueprint for post-Turing architectures that compute via topological resonance.

</details>


### [87] [ARC-AGI Without Pretraining](https://arxiv.org/abs/2512.06104)
*Isaac Liao,Albert Gu*

Main category: cs.LG

TL;DR: CompressARC是一个仅7.6万参数的无预训练模型，通过最小描述长度（MDL）方法在推理时解决ARC-AGI视觉谜题，在极端数据限制下仍能解决20%的评估谜题。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点：反驳"解决ARC-AGI视觉谜题需要大规模预训练"的常规认知，探索在极端数据限制下实现智能的替代方法。

Method: 使用仅7.6万参数的模型，不进行任何预训练，仅通过最小描述长度（MDL）方法在推理时处理目标谜题。模型仅在单个样本（目标推理谜题本身，去除最终解信息）上进行训练，不使用ARC-AGI提供的训练集。

Result: 在极端数据限制条件下，CompressARC成功解决了20%的评估谜题，展现出深度学习模型中罕见的极端泛化能力。

Conclusion: 最小描述长度（MDL）是除了传统预训练之外，实现智能的另一种可行途径，能够在极端数据限制下解决多样化的创造性ARC-AGI谜题。

Abstract: Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles by minimizing the description length (MDL) of the target puzzle purely during inference time. The MDL endows CompressARC with extreme generalization abilities typically unheard of in deep learning. To our knowledge, CompressARC is the only deep learning method for ARC-AGI where training happens only on a single sample: the target inference puzzle itself, with the final solution information removed. Moreover, CompressARC does not train on the pre-provided ARC-AGI "training set". Under these extremely data-limited conditions, we do not ordinarily expect any puzzles to be solvable at all. Yet CompressARC still solves a diverse distribution of creative ARC-AGI puzzles, suggesting MDL to be an alternative feasible way to produce intelligence, besides conventional pretraining.

</details>


### [88] [A Prescriptive Framework for Determining Optimal Days for Short-Term Traffic Counts](https://arxiv.org/abs/2512.06111)
*Arthur Mukwaya,Nancy Kasamala,Nana Kankam Gyimah,Judith Mwakalonge,Gurcan Comert,Saidi Siuhi,Denis Ruganuza,Mark Ngotonie*

Main category: cs.LG

TL;DR: 该研究提出机器学习框架，为短期交通计数选择最优代表日，以提高年度日均交通量预测精度，相比传统方法显著降低误差。


<details>
  <summary>Details</summary>
Motivation: 美国各州交通部门难以获取准确的年度日均交通量数据，特别是未监测道路。连续计数站成本高难以广泛部署，机构依赖短期计数但缺乏优化选择方法。

Method: 提出机器学习框架，采用"最优日"方法迭代选择对AADT估计最有信息量的日期，与反映当前实践的"非最优日"基线对比。利用得克萨斯州2022-2023年交通量数据，结合留一法技术生成无偏的每日交通特征。

Result: 最优日方法在前5天均优于基线，最佳日（第186天）误差显著降低（RMSE: 7,871.15 vs 11,185.00，MAE: 3,645.09 vs 5,118.57，MAPE: 11.95% vs 14.42%），R²更高（0.9756 vs 0.9499）。

Conclusion: 该研究为交通部门提供了替代传统短期计数实践的方法，能提高AADT估计精度，支持公路性能监测系统合规性，并降低全州交通数据收集的运营成本。

Abstract: The Federal Highway Administration (FHWA) mandates that state Departments of Transportation (DOTs) collect reliable Annual Average Daily Traffic (AADT) data. However, many U.S. DOTs struggle to obtain accurate AADT, especially for unmonitored roads. While continuous count (CC) stations offer accurate traffic volume data, their implementation is expensive and difficult to deploy widely, compelling agencies to rely on short-duration traffic counts. This study proposes a machine learning framework, the first to our knowledge, to identify optimal representative days for conducting short count (SC) data collection to improve AADT prediction accuracy. Using 2022 and 2023 traffic volume data from the state of Texas, we compare two scenarios: an 'optimal day' approach that iteratively selects the most informative days for AADT estimation and a 'no optimal day' baseline reflecting current practice by most DOTs. To align with Texas DOT's traffic monitoring program, continuous count data were utilized to simulate the 24 hour short counts. The actual field short counts were used to enhance feature engineering through using a leave-one-out (LOO) technique to generate unbiased representative daily traffic features across similar road segments. Our proposed methodology outperforms the baseline across the top five days, with the best day (Day 186) achieving lower errors (RMSE: 7,871.15, MAE: 3,645.09, MAPE: 11.95%) and higher R^2 (0.9756) than the baseline (RMSE: 11,185.00, MAE: 5,118.57, MAPE: 14.42%, R^2: 0.9499). This research offers DOTs an alternative to conventional short-duration count practices, improving AADT estimation, supporting Highway Performance Monitoring System compliance, and reducing the operational costs of statewide traffic data collection.

</details>


### [89] [Physics-Informed Neural Koopman Machine for Interpretable Longitudinal Personalized Alzheimer's Disease Forecasting](https://arxiv.org/abs/2512.06134)
*Georgi Hrusanov,Duy-Thanh Vu,Duy-Cat Can,Sophie Tascedda,Margaret Ryan,Julien Bodelet,Katarzyna Koscielska,Carsten Magnus,Oliver Y. Chén*

Main category: cs.LG

TL;DR: NKM是一种基于动态系统和注意力机制的新型机器学习架构，用于同时预测阿尔茨海默病的多种认知评分，整合多模态数据并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病个体认知衰退的早期预测对疾病评估和管理至关重要，但现有方法难以在整合多模态数据进行纵向个性化预测的同时保持可解释性。

Method: 提出神经库普曼机器（NKM），整合分析知识（α）和生物学知识（β）指导特征分组，通过融合组感知分层注意力机制在库普曼算子框架内将复杂非线性轨迹转换为可解释的线性表示。

Result: 在ADNI数据集上，NKM在预测认知衰退轨迹方面持续优于传统机器学习和深度学习模型，能够同时预测多种认知评分变化，量化生物标志物对不同认知评分的贡献差异，并识别最预测认知恶化的脑区。

Conclusion: NKM通过可解释的显式系统推进了基于过去多模态数据的AD未来认知衰退的个性化、可解释预测，并揭示了AD进展的潜在多模态生物学基础。

Abstract: Early forecasting of individual cognitive decline in Alzheimer's disease (AD) is central to disease evaluation and management. Despite advances, it is as of yet challenging for existing methodological frameworks to integrate multimodal data for longitudinal personalized forecasting while maintaining interpretability. To address this gap, we present the Neural Koopman Machine (NKM), a new machine learning architecture inspired by dynamical systems and attention mechanisms, designed to forecast multiple cognitive scores simultaneously using multimodal genetic, neuroimaging, proteomic, and demographic data. NKM integrates analytical ($α$) and biological ($β$) knowledge to guide feature grouping and control the hierarchical attention mechanisms to extract relevant patterns. By implementing Fusion Group-Aware Hierarchical Attention within the Koopman operator framework, NKM transforms complex nonlinear trajectories into interpretable linear representations. To demonstrate NKM's efficacy, we applied it to study the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Our results suggest that NKM consistently outperforms both traditional machine learning methods and deep learning models in forecasting trajectories of cognitive decline. Specifically, NKM (1) forecasts changes of multiple cognitive scores simultaneously, (2) quantifies differential biomarker contributions to predicting distinctive cognitive scores, and (3) identifies brain regions most predictive of cognitive deterioration. Together, NKM advances personalized, interpretable forecasting of future cognitive decline in AD using past multimodal data through an explainable, explicit system and reveals potential multimodal biological underpinnings of AD progression.

</details>


### [90] [gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points](https://arxiv.org/abs/2512.06143)
*Marcus M. Noack,Mark D. Risser,Hengrui Luo,Vardaan Tekriwal,Ronald J. Pandolfi*

Main category: cs.LG

TL;DR: 提出gp2Scale方法，在不依赖诱导点、核插值或邻域近似的情况下，将精确高斯过程扩展到超过1000万个数据点，通过利用灵活、紧支撑、非平稳核的自然稀疏结构实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程扩展方法在计算速度、预测精度和不确定性量化之间存在顽固的权衡，因为它们大多依赖于各种近似，降低了准确性并限制了核和噪声模型设计的灵活性，这在表达性非平稳核在许多领域兴起时是不可接受的。

Method: 提出gp2Scale方法，利用高度灵活、紧支撑和非平稳核来识别协方差矩阵中自然出现的稀疏结构，然后利用这种稀疏性进行线性系统求解和对数行列式计算以实现训练，不依赖诱导点、核插值或邻域近似。

Result: 在多个真实世界数据集上展示了方法的功能，并与最先进的近似算法进行了比较。在许多情况下显示出优越的近似性能，但方法的真正优势在于其对任意GP定制（核心核设计、噪声和均值函数）以及输入空间类型的不可知性。

Conclusion: gp2Scale方法特别适合现代高斯过程应用，能够在保持精确性的同时扩展到大规模数据集，同时保持对核设计和模型定制的完全灵活性。

Abstract: Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximations that lower accuracy and limit the flexibility of kernel and noise-model designs -- an unacceptable drawback at a time when expressive non-stationary kernels are on the rise in many fields. Here, we propose a methodology we term \emph{gp2Scale} that scales exact Gaussian processes to more than 10 million data points without relying on inducing points, kernel interpolation, or neighborhood-based approximations, and instead leveraging the existing capabilities of a GP: its kernel design. Highly flexible, compactly supported, and non-stationary kernels lead to the identification of naturally occurring sparse structure in the covariance matrix, which is then exploited for the calculations of the linear system solution and the log-determinant for training. We demonstrate our method's functionality on several real-world datasets and compare it with state-of-the-art approximation algorithms. Although we show superior approximation performance in many cases, the method's real power lies in its agnosticism toward arbitrary GP customizations -- core kernel design, noise, and mean functions -- and the type of input space, making it optimally suited for modern Gaussian process applications.

</details>


### [91] [Learning Invariant Graph Representations Through Redundant Information](https://arxiv.org/abs/2512.06154)
*Barproda Halder,Pasan Dissanayake,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 该论文提出了RIG框架，利用部分信息分解(PID)工具识别和最大化冗余信息，同时分离虚假和因果子图，以提升图表示在分布外(OOD)场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于经典信息论的图表示学习方法难以完全消除虚假成分，导致在分布外泛化时性能下降。需要更精确的工具来识别和处理虚假子图与不变子图之间关于目标Y的冗余信息。

Method: 提出RIG框架：1) 使用部分信息分解(PID)识别虚假子图Gs和不变子图Gc；2) 通过多级优化框架最大化冗余信息；3) 交替进行冗余信息下界估计和优化目标最大化。

Result: 在合成和真实世界图数据集上的实验表明，RIG框架在多种分布偏移下具有优越的泛化能力。

Conclusion: 部分信息分解(PID)为图表示学习提供了超越经典信息论的工具，RIG框架通过精确处理冗余信息有效提升了分布外泛化性能。

Abstract: Learning invariant graph representations for out-of-distribution (OOD) generalization remains challenging because the learned representations often retain spurious components. To address this challenge, this work introduces a new tool from information theory called Partial Information Decomposition (PID) that goes beyond classical information-theoretic measures. We identify limitations in existing approaches for invariant representation learning that solely rely on classical information-theoretic measures, motivating the need to precisely focus on redundant information about the target $Y$ shared between spurious subgraphs $G_s$ and invariant subgraphs $G_c$ obtained via PID. Next, we propose a new multi-level optimization framework that we call -- Redundancy-guided Invariant Graph learning (RIG) -- that maximizes redundant information while isolating spurious and causal subgraphs, enabling OOD generalization under diverse distribution shifts. Our approach relies on alternating between estimating a lower bound of redundant information (which itself requires an optimization) and maximizing it along with additional objectives. Experiments on both synthetic and real-world graph datasets demonstrate the generalization capabilities of our proposed RIG framework.

</details>


### [92] [PMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations](https://arxiv.org/abs/2512.06183)
*Lindong Liu,Zhixiong Jin,Seongjin Choi*

Main category: cs.LG

TL;DR: PMA-Diffusion：一种物理引导的掩码感知扩散框架，用于从稀疏观测中重建高速公路速度场，在仅有5%可见度的情况下仍优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 高速公路交通状态信息对智能交通系统至关重要，但传统传感器（如环形检测器和探测车）获取的数据通常过于稀疏和嘈杂，难以捕捉交通流的详细动态。

Method: 提出PMA-Diffusion框架，包含两种掩码感知训练策略（单掩码和双掩码），在推理阶段使用物理引导的后验采样器，交替进行反向扩散更新、观测投影和基于自适应各向异性平滑的物理引导投影。

Result: 在I-24 MOTION数据集上测试，即使在仅有5%可见度的严重稀疏情况下，PMA-Diffusion在三个重建误差指标上都优于其他基线方法，且基于稀疏观测训练的性能接近基于完整观测训练的基线模型。

Conclusion: 将掩码感知扩散先验与物理引导后验采样器相结合，为实际传感稀疏条件下的交通状态估计提供了可靠且灵活的解决方案。

Abstract: High-resolution highway traffic state information is essential for Intelligent Transportation Systems, but typical traffic data acquired from loop detectors and probe vehicles are often too sparse and noisy to capture the detailed dynamics of traffic flow. We propose PMA-Diffusion, a physics-guided mask-aware diffusion framework that reconstructs unobserved highway speed fields from sparse, incomplete observations. Our approach trains a diffusion prior directly on sparsely observed speed fields using two mask-aware training strategies: Single-Mask and Double-Mask. At the inference phase, the physics-guided posterior sampler alternates reverse-diffusion updates, observation projection, and physics-guided projection based on adaptive anisotropic smoothing to reconstruct the missing speed fields. The proposed framework is tested on the I-24 MOTION dataset with varying visibility ratios. Even under severe sparsity, with only 5% visibility, PMA-Diffusion outperforms other baselines across three reconstruction error metrics. Furthermore, PMA-diffusion trained with sparse observation nearly matches the performance of the baseline model trained on fully observed speed fields. The results indicate that combining mask-aware diffusion priors with a physics-guided posterior sampler provides a reliable and flexible solution for traffic state estimation under realistic sensing sparsity.

</details>


### [93] [How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?](https://arxiv.org/abs/2512.06200)
*Tomohiro Yamashita,Daichi Amagata,Yusuke Matsui*

Main category: cs.LG

TL;DR: 该研究提出了一个评估近似最近邻搜索（ANNS）索引数据删除效率的实验框架和综合评估指标，将图基ANNS的数据删除方法分为三类并数学形式化，最后应用于HNSW方法并提出了动态选择删除方法的Deletion Control方法。


<details>
  <summary>Details</summary>
Motivation: 随着检索增强生成等应用的发展，动态数据上的ANNS算法需求日益增长，但目前缺乏针对数据删除的全面评估方法。本研究旨在填补这一空白，为ANNS索引的数据删除提供系统化的评估框架。

Method: 1. 提出实验框架和综合评估指标来评估ANNS索引的数据删除效率；2. 将图基ANNS的数据删除方法分为三类并数学形式化；3. 在准确性、查询速度等指标上评估性能；4. 将框架应用于HNSW方法；5. 提出Deletion Control方法，根据所需搜索精度动态选择适当的删除方法。

Result: 建立了ANNS数据删除的评估框架，将删除方法系统分类并形式化，通过实验分析了数据删除对HNSW性能的影响，并开发了能够动态优化删除策略的Deletion Control方法。

Conclusion: 该研究为ANNS索引的数据删除提供了首个全面的评估框架，通过系统化的分类和评估指标，能够有效指导动态ANNS系统的设计和优化，Deletion Control方法展示了在实际应用中动态调整删除策略的可行性。

Abstract: Approximate Nearest Neighbor Search (ANNS) has recently gained significant attention due to its many applications, such as Retrieval-Augmented Generation. Such applications require ANNS algorithms that support dynamic data, so the ANNS problem on dynamic data has attracted considerable interest. However, a comprehensive evaluation methodology for data deletion in ANNS has yet to be established. This study proposes an experimental framework and comprehensive evaluation metrics to assess the efficiency of data deletion for ANNS indexes under practical use cases. Specifically, we categorize data deletion methods in graph-based ANNS into three approaches and formalize them mathematically. The performance is assessed in terms of accuracy, query speed, and other relevant metrics. Finally, we apply the proposed evaluation framework to Hierarchical Navigable Small World, one of the state-of-the-art ANNS methods, to analyze the effects of data deletion, and propose Deletion Control, a method which dynamically selects the appropriate deletion method under a required search accuracy.

</details>


### [94] [K2-V2: A 360-Open, Reasoning-Enhanced LLM](https://arxiv.org/abs/2512.06201)
*K2 Team,Zhengzhong Liu,Liping Tang,Linghao Jin,Haonan Li,Nikhil Ranjan,Desai Fan,Shaurya Rohatgi,Richard Fan,Omkar Pangarkar,Huijuan Wang,Zhoujun Cheng,Suqi Sun,Seungwook Han,Bowen Tan,Gurpreet Gosal,Xudong Han,Varad Pimpalkhute,Shibo Hao,Ming Shan Hee,Joel Hestness,Haolong Jia,Liqun Ma,Aaryamonvikram Singh,Daria Soboleva,Natalia Vassilieva,Renxi Wang,Yingquan Wu,Yuekai Sun,Taylor Killian,Alexander Moreno,John Maggs,Hector Ren,Guowei He,Hongyi Wang,Xuezhe Ma,Yuqi Wang,Mikhail Yurochkin,Eric P. Xing*

Main category: cs.LG

TL;DR: K2-V2是一个从头开始构建的360度开放大语言模型，专为推理适应设计，在72B规模级别中表现优异，超越Qwen2.5-72B并接近Qwen3-235B的性能。


<details>
  <summary>Details</summary>
Motivation: 构建一个专门为复杂推理任务优化的开放基础模型，弥补现有通用LLM在推理能力方面的不足，同时为开源社区提供一个强大的推理中心化基础。

Method: 从头开始训练，在整个训练过程中主动注入领域知识、推理能力、长上下文和工具使用能力；使用简单的监督微调建立强基线；发布完整的训练历史和数据组成。

Result: K2-V2成为最强的完全开放模型，在其规模级别中与开源领导者竞争，超越Qwen2.5-72B并接近Qwen3-235B的性能；为高级对齐留下了显著的提升空间。

Conclusion: K2-V2作为一个强大的推理中心化基础模型，通过发布完整的训练历史和数据组成，最大化持续训练的效果，为开源社区提供了一个能力强大的基础，特别适合复杂推理任务。

Abstract: We introduce K2-V2, a 360-open LLM built from scratch as a superior base for reasoning adaptation, in addition to functions such as conversation and knowledge retrieval from general LLMs. It stands as the strongest fully open model, rivals open-weight leaders in its size class, outperforms Qwen2.5-72B and approaches the performance of Qwen3-235B. We actively infuse domain knowledge, reasoning, long-context, and tool use throughout the training process. This explicitly prepares the model for complex reasoning tasks. We demonstrate this potential using simple supervised fine-tuning, establishing a strong baseline that indicates significant headroom for advanced alignment. By releasing the full training history and data composition, we maximize the effectiveness of continuous training, a key open source production scenario. We release the model weights and signature LLM360 artifacts, such as complete training data, to empower the community with a capable, reasoning-centric foundation.

</details>


### [95] [Quantization Blindspots: How Model Compression Breaks Backdoor Defenses](https://arxiv.org/abs/2512.06243)
*Rohan Pandey,Eric Ye*

Main category: cs.LG

TL;DR: 量化（INT8/INT4）使现有后门防御失效，但后门攻击在量化后仍保持高成功率，暴露了防御评估与模型实际部署之间的不匹配。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的ML系统部署通常会对模型进行量化（如INT8或更低精度）以减少内存和延迟，但现有的后门防御研究主要在FP32精度下进行评估。本研究旨在探究量化如何影响现有后门防御的效果。

Method: 对五种代表性后门防御方法在三种精度设置（FP32、INT8动态量化、INT4模拟量化）下进行系统实证研究，使用标准BadNet攻击，在两个标准视觉基准（GTSRB和CIFAR-10）上进行评估。

Result: INT8量化将所有防御的检测率降至0%，而攻击成功率仍保持在99%以上。INT4量化表现出明显的数据集依赖性：Neural Cleanse在GTSRB上仍有效，但在CIFAR-10上失效，而后门在量化后攻击成功率仍超过90%。

Conclusion: 量化鲁棒性应成为未来后门防御评估和设计的必要考量维度，需要解决防御评估（FP32）与模型实际部署（量化形式）之间的不匹配问题。

Abstract: Backdoor attacks embed input-dependent malicious behavior into neural networks while preserving high clean accuracy, making them a persistent threat for deployed ML systems. At the same time, real-world deployments almost never serve full-precision models: post-training quantization to INT8 or lower precision is now standard practice for reducing memory and latency. This work asks a simple question: how do existing backdoor defenses behave under standard quantization pipelines? We conduct a systematic empirical study of five representative defenses across three precision settings (FP32, INT8 dynamic, INT4 simulated) and two standard vision benchmarks using a canonical BadNet attack. We observe that INT8 quantization reduces the detection rate of all evaluated defenses to 0% while leaving attack success rates above 99%. For INT4, we find a pronounced dataset dependence: Neural Cleanse remains effective on GTSRB but fails on CIFAR-10, even though backdoors continue to survive quantization with attack success rates above 90%. Our results expose a mismatch between how defenses are commonly evaluated (on FP32 models) and how models are actually deployed (in quantized form), and they highlight quantization robustness as a necessary axis in future evaluations and designs of backdoor defenses.

</details>


### [96] [Auto-exploration for online reinforcement learning](https://arxiv.org/abs/2512.06244)
*Caleb Ju,Guanghui Lan*

Main category: cs.LG

TL;DR: 提出具有自动探索功能的新RL方法，无需先验参数知识，在表格和线性函数逼近两种设置下实现O(ε⁻²)样本复杂度


<details>
  <summary>Details</summary>
Motivation: 现有RL算法需要假设充分探索状态和动作空间，这导致算法不可实现且性能次优。需要开发能自动探索的免参数方法来解决探索-利用困境。

Method: 提出两类具有自动探索功能的方法：表格设置和线性函数逼近。采用动态混合时间、折扣状态分布采样、鲁棒梯度估计器和优势差距函数等创新技术。

Result: 在存在探索最优策略的算法独立假设下，两种方法都能达到O(ε⁻²)的样本复杂度来求解ε误差问题。复杂度不包含可能任意大的算法依赖参数。

Conclusion: 新方法通过自动探索解决了RL中的探索-利用困境，实现了免参数、易实现且具有最优样本复杂度的算法，避免了现有方法对问题参数的依赖。

Abstract: The exploration-exploitation dilemma in reinforcement learning (RL) is a fundamental challenge to efficient RL algorithms. Existing algorithms for finite state and action discounted RL problems address this by assuming sufficient exploration over both state and action spaces. However, this yields non-implementable algorithms and sub-optimal performance. To resolve these limitations, we introduce a new class of methods with auto-exploration, or methods that automatically explore both state and action spaces in a parameter-free way, i.e.,~without a priori knowledge of problem-dependent parameters. We present two variants: one for the tabular setting and one for linear function approximation. Under algorithm-independent assumptions on the existence of an exploring optimal policy, both methods attain $O(ε^{-2})$ sample complexity to solve to $ε$ error. Crucially, these complexities are novel since they are void of algorithm-dependent parameters seen in prior works, which may be arbitrarily large. The methods are also simple to implement because they are parameter-free and do not directly estimate the unknown parameters. These feats are achieved by new algorithmic innovations for RL, including a dynamic mixing time, a discounted state distribution for sampling, a simple robust gradient estimator, and a recent advantage gap function to certify convergence.

</details>


### [97] [Learning When to Switch: Adaptive Policy Selection via Reinforcement Learning](https://arxiv.org/abs/2512.06250)
*Chris Tava*

Main category: cs.LG

TL;DR: 提出一种强化学习方法来学习两个正交导航策略之间的切换阈值，使智能体能在系统探索和目标导向路径规划之间动态切换，在迷宫导航任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 自主智能体需要多种策略来解决复杂任务，但确定何时在策略之间切换仍然具有挑战性。固定阈值方法不够灵活，需要手动设计启发式规则，且难以适应不同环境。

Method: 使用Q-learning学习切换阈值，将状态空间离散化为覆盖率和距离到目标的桶。智能体不需要先验的墙壁位置知识、最优阈值或手工启发式规则，而是根据观察到的进度信号动态发现有效的切换策略。仅需要迷宫尺寸和目标位置等最小领域知识。

Result: 在240个测试配置（4种迷宫尺寸×10个独特迷宫×6种智能体变体）中，自适应阈值学习方法优于单策略智能体和固定40%阈值基线。结果显示完成时间改善23-55%，运行时间方差减少83%，最坏情况改善71%。学习到的切换行为在每个尺寸类别内能泛化到未见过的墙壁配置。

Conclusion: 自适应策略选择的价值随着问题复杂性增加而增加，在64×64迷宫中达到55%的改进。该方法证明了强化学习可以有效地学习策略切换阈值，而不需要大量领域知识或手工启发式规则。

Abstract: Autonomous agents often require multiple strategies to solve complex tasks, but determining when to switch between strategies remains challenging. This research introduces a reinforcement learning technique to learn switching thresholds between two orthogonal navigation policies. Using maze navigation as a case study, this work demonstrates how an agent can dynamically transition between systematic exploration (coverage) and goal-directed pathfinding (convergence) to improve task performance. Unlike fixed-threshold approaches, the agent uses Q-learning to adapt switching behavior based on coverage percentage and distance to goal, requiring only minimal domain knowledge: maze dimensions and target location. The agent does not require prior knowledge of wall positions, optimal threshold values, or hand-crafted heuristics; instead, it discovers effective switching strategies dynamically during each run. The agent discretizes its state space into coverage and distance buckets, then adapts which coverage threshold (20-60\%) to apply based on observed progress signals. Experiments across 240 test configurations (4 maze sizes from 16$\times$16 to 128$\times$128 $\times$ 10 unique mazes $\times$ 6 agent variants) demonstrate that adaptive threshold learning outperforms both single-strategy agents and fixed 40\% threshold baselines. Results show 23-55\% improvements in completion time, 83\% reduction in runtime variance, and 71\% improvement in worst-case scenarios. The learned switching behavior generalizes within each size class to unseen wall configurations. Performance gains scale with problem complexity: 23\% improvement for 16$\times$16 mazes, 34\% for 32$\times$32, and 55\% for 64$\times$64, demonstrating that as the space of possible maze structures grows, the value of adaptive policy selection over fixed heuristics increases proportionally.

</details>


### [98] [Learning Without Time-Based Embodiment Resets in Soft-Actor Critic](https://arxiv.org/abs/2512.06252)
*Homayoon Farrahi,A. Rupam Mahmood*

Main category: cs.LG

TL;DR: 本文研究了在无终止和无重置条件下使用SAC算法的强化学习挑战，提出了继续版SAC算法，并通过增加策略熵来补偿无重置带来的探索问题。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习任务通常依赖环境重置和终止条件等辅助组件来加速学习，但这些设置不自然且可能阻碍在真实世界中的长期性能。研究者希望探索在没有终止条件和机器人身体重置情况下的学习挑战。

Method: 1) 提出了继续版SAC算法，通过简单修改现有任务的奖励函数实现；2) 在修改的Gym Reacher任务上分析无身体重置时的失败原因；3) 在模拟任务和真实机器人视觉任务中，通过增加策略熵来补偿无重置带来的探索问题。

Result: 1) 继续版SAC在无终止条件下表现与或优于周期性SAC，且降低了对折扣率γ值的敏感性；2) 身体重置有助于SAC算法中的状态空间探索，移除重置会导致探索不足和学习失败/显著变慢；3) 当性能趋势变差或停滞时增加策略熵，能有效恢复因不使用身体重置而损失的性能。

Conclusion: 无终止和无重置的强化学习是可行的，但需要解决探索问题。继续版SAC算法通过简单修改奖励函数就能获得良好性能，而增加策略熵是补偿无重置条件下探索不足的有效干预措施。

Abstract: When creating new reinforcement learning tasks, practitioners often accelerate the learning process by incorporating into the task several accessory components, such as breaking the environment interaction into independent episodes and frequently resetting the environment. Although they can enable the learning of complex intelligent behaviors, such task accessories can result in unnatural task setups and hinder long-term performance in the real world. In this work, we explore the challenges of learning without episode terminations and robot embodiment resets using the Soft Actor-Critic (SAC) algorithm. To learn without terminations, we present a continuing version of the SAC algorithm and show that, with simple modifications to the reward functions of existing tasks, continuing SAC can perform as well as or better than episodic SAC while reducing the sensitivity of performance to the value of the discount rate $γ$. On a modified Gym Reacher task, we investigate possible explanations for the failure of continuing SAC when learning without embodiment resets. Our results suggest that embodiment resets help with exploration of the state space in the SAC algorithm, and removing embodiment resets can lead to poor exploration of the state space and failure of or significantly slower learning. Finally, on additional simulated tasks and a real-robot vision task, we show that increasing the entropy of the policy when performance trends worse or remains static is an effective intervention for recovering the performance lost due to not using embodiment resets.

</details>


### [99] [Importance-aware Topic Modeling for Discovering Public Transit Risk from Noisy Social Media](https://arxiv.org/abs/2512.06293)
*Fatima Ashraf,Muhammad Ayub Sabir,Jiaxin Deng,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 该论文提出了一种新的主题建模方法，通过联合建模语言交互和用户影响力，从稀疏的社交媒体数据中检测城市交通服务风险。


<details>
  <summary>Details</summary>
Motivation: 城市交通机构越来越多地使用社交媒体监控服务风险（如拥挤、延误、安全事件），但这些关注信号稀疏、简短，容易被日常聊天淹没。现有方法难以有效提取这些稀疏但有影响力的信号。

Method: 构建影响力加权的关键词共现图，使有社会影响力的帖子按比例贡献证据；提出泊松反卷积分解（PDF）方法，将图分解为低秩主题结构和主题局部残差交互；使用去相关正则化促进主题区分，轻量级优化确保稳定收敛；通过一致性驱动的扫描选择主题数量。

Result: 在大规模社交数据流上，该方法实现了最先进的主题一致性，与领先基线相比具有强大的多样性。

Conclusion: 该方法能够从稀疏的社交媒体数据中有效提取城市交通服务风险信号，提供可解释的主题-关键词基础和主题重要性评分，为交通机构提供实用的监控工具。

Abstract: Urban transit agencies increasingly turn to social media to monitor emerging service risks such as crowding, delays, and safety incidents, yet the signals of concern are sparse, short, and easily drowned by routine chatter. We address this challenge by jointly modeling linguistic interactions and user influence. First, we construct an influence-weighted keyword co-occurrence graph from cleaned posts so that socially impactful posts contributes proportionally to the underlying evidence. The core of our framework is a Poisson Deconvolution Factorization (PDF) that decomposes this graph into a low-rank topical structure and topic-localized residual interactions, producing an interpretable topic--keyword basis together with topic importance scores. A decorrelation regularizer \emph{promotes} distinct topics, and a lightweight optimization procedure ensures stable convergence under nonnegativity and normalization constraints. Finally, the number of topics is selected through a coherence-driven sweep that evaluates the quality and distinctness of the learned topics. On large-scale social streams, the proposed model achieves state-of-the-art topic coherence and strong diversity compared with leading baselines. The code and dataset are publicly available at https://github.com/pangjunbiao/Topic-Modeling_ITS.git

</details>


### [100] [Interpretive Efficiency: Information-Geometric Foundations of Data Usefulness](https://arxiv.org/abs/2512.06341)
*Ronald Katende*

Main category: cs.LG

TL;DR: 提出"解释效率"新指标，量化解释性表示传递任务相关信息的效率，基于五条公理，与互信息相关，具有理论保证和实用诊断价值。


<details>
  <summary>Details</summary>
Motivation: 当前可解释性指标很少能有效量化数据对解释性表示的支持程度，需要一种能测量解释通道传递任务相关信息效率的指标。

Method: 提出"解释效率"这一归一化、任务感知的函数，基于五条公理：有界性、Blackwell式单调性、数据处理稳定性、容许不变性和渐近一致性。将其与互信息关联，推导局部Fisher几何展开，使用标准经验过程工具建立渐近和有限样本估计保证。

Result: 在受控图像和信号任务实验中，该指标能恢复理论排序，揭示被准确率掩盖的表示冗余，并与鲁棒性相关，证明其作为表示设计的实用理论支持诊断工具。

Conclusion: 解释效率是一个实用且有理论支持的指标，可用于评估解释性表示设计，量化解释通道传递任务相关信息的效率。

Abstract: Interpretability is central to trustworthy machine learning, yet existing metrics rarely quantify how effectively data support an interpretive representation. We propose Interpretive Efficiency, a normalized, task-aware functional that measures the fraction of task-relevant information transmitted through an interpretive channel. The definition is grounded in five axioms ensuring boundedness, Blackwell-style monotonicity, data-processing stability, admissible invariance, and asymptotic consistency. We relate the functional to mutual information and derive a local Fisher-geometric expansion, then establish asymptotic and finite-sample estimation guarantees using standard empirical-process tools. Experiments on controlled image and signal tasks demonstrate that the measure recovers theoretical orderings, exposes representational redundancy masked by accuracy, and correlates with robustness, making it a practical, theory-backed diagnostic for representation design.

</details>


### [101] [Optimizing Optimizers for Fast Gradient-Based Learning](https://arxiv.org/abs/2512.06370)
*Jaerin Lee,Kyoung Mu Lee*

Main category: cs.LG

TL;DR: 提出自动化优化器设计的理论框架，基于贪心原则将优化器设计问题转化为最大化损失瞬时下降的凸优化问题


<details>
  <summary>Details</summary>
Motivation: 为梯度学习中的优化器设计自动化建立理论基础，解决手动设计优化器和调整超参数的困难

Method: 将优化器视为将损失梯度信号转换为参数运动的函数，将设计问题转化为函数空间上的凸优化问题，在不同约束下求解

Result: 该方法不仅恢复了许多流行优化器的闭式解，还能自动确定这些优化器针对具体问题的最优超参数

Conclusion: 提供了一种系统化的优化器设计和超参数调整方法，可在训练过程中动态执行优化器的优化

Abstract: We lay the theoretical foundation for automating optimizer design in gradient-based learning. Based on the greedy principle, we formulate the problem of designing optimizers as maximizing the instantaneous decrease in loss. By treating an optimizer as a function that translates loss gradient signals into parameter motions, the problem reduces to a family of convex optimization problems over the space of optimizers. Solving these problems under various constraints not only recovers a wide range of popular optimizers as closed-form solutions, but also produces the optimal hyperparameters of these optimizers with respect to the problems at hand. This enables a systematic approach to design optimizers and tune their hyperparameters according to the gradient statistics that are collected during the training process. Furthermore, this optimization of optimization can be performed dynamically during training.

</details>


### [102] [RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs](https://arxiv.org/abs/2512.06392)
*Runlong Zhou,Lefan Zhang,Shang-Chen Wu,Kelvin Zou,Hanzhi Zhou,Ke Ye,Yihao Feng,Dong Yin,Alex Guillen Garcia,Dmytro Babych,Rohit Chatterjee,Matthew Hopkins,Xiang Kong,Chang Lan,Lezhi Li,Yiping Ma,Daniele Molinari,Senyu Tong,Yanchao Sun,Thomas Voice,Jianyu Wang,Chong Wang,Simon Wang,Floris Weers,Yechen Xu,Guolin Yin,Muyang Yu,Yi Zhang,Zheng Zhou,Danyang Zhuo,Ruoming Pang,Cheng Leong*

Main category: cs.LG

TL;DR: RLAX是一个在TPU上运行的强化学习框架，采用参数服务器架构，通过系统优化加速LLM推理能力训练，在1024个TPU上12.8小时内将QwQ-32B模型的pass@8准确率提升12.8%。


<details>
  <summary>Details</summary>
Motivation: 强化学习已成为提升大语言模型推理能力的主流方法，但需要可扩展、容错的训练框架来支持大规模RL算法部署。

Method: 开发RLAX框架，采用参数服务器架构：主训练器定期推送模型权重到参数服务器，推理工作节点拉取最新权重生成rollouts；引入系统技术实现可扩展、可抢占的RL训练；设计新的数据集筛选和对齐技术。

Result: 在1024个v5p TPU上，仅用12小时48分钟就将QwQ-32B模型的pass@8准确率提升12.8%；框架对训练过程中的抢占具有鲁棒性。

Conclusion: RLAX是一个高效、可扩展的RL框架，能够显著加速LLM推理能力的提升，并支持多种先进RL算法的大规模部署。

Abstract: Reinforcement learning (RL) has emerged as the de-facto paradigm for improving the reasoning capabilities of large language models (LLMs). We have developed RLAX, a scalable RL framework on TPUs. RLAX employs a parameter-server architecture. A master trainer periodically pushes updated model weights to the parameter server while a fleet of inference workers pull the latest weights and generates new rollouts. We introduce a suite of system techniques to enable scalable and preemptible RL for a diverse set of state-of-art RL algorithms. To accelerate convergence and improve model quality, we have devised new dataset curation and alignment techniques. Large-scale evaluations show that RLAX improves QwQ-32B's pass@8 accuracy by 12.8% in just 12 hours 48 minutes on 1024 v5p TPUs, while remaining robust to preemptions during training.

</details>


### [103] [Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator](https://arxiv.org/abs/2512.06417)
*Yifan Sun,Lei Cheng,Jianlong Li,Peter Gerstoft*

Main category: cs.LG

TL;DR: Hankel-FNO：基于傅里叶神经算子的高效水下声学图绘制方法，结合声传播知识和地形数据，在保持高计算速度的同时实现高精度，优于传统数值求解器和纯数据驱动方法。


<details>
  <summary>Details</summary>
Motivation: 传统水下声学图绘制方法依赖计算昂贵的数值求解器，不适用于大规模或实时应用；现有的深度学习替代模型存在固定分辨率限制或依赖显式偏微分方程公式的问题，限制了其在不同环境中的适用性和泛化能力。

Method: 提出Hankel-FNO模型，基于傅里叶神经算子框架，结合声传播知识和地形数据，构建高效准确的水下声学图绘制方法。

Result: Hankel-FNO在速度上优于传统求解器，在精度上超越数据驱动替代方法，特别是在长距离预测方面表现优异；实验显示模型对多样化环境和声源设置具有良好适应性，仅需少量微调。

Conclusion: Hankel-FNO为水下声学图绘制提供了一种高效准确的解决方案，结合了物理知识和深度学习优势，在计算速度和预测精度方面均表现出色，具有良好的环境适应性和泛化能力。

Abstract: Fast and accurate underwater acoustic charting is crucial for downstream tasks such as environment-aware sensor placement optimization and autonomous vehicle path planning. Conventional methods rely on computationally expensive while accurate numerical solvers, which are not scalable for large-scale or real-time applications. Although deep learning-based surrogate models can accelerate these computations, they often suffer from limitations such as fixed-resolution constraints or dependence on explicit partial differential equation formulations. These issues hinder their applicability and generalization across diverse environments. We propose Hankel-FNO, a Fourier Neural Operator (FNO)-based model for efficient and accurate acoustic charting. By incorporating sound propagation knowledge and bathymetry, our method has high accuracy while maintaining high computational speed. Results demonstrate that Hankel-FNO outperforms traditional solvers in speed and surpasses data-driven alternatives in accuracy, especially in long-range predictions. Experiments show the model's adaptability to diverse environments and sound source settings with minimal fine-tuning.

</details>


### [104] [BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination](https://arxiv.org/abs/2512.06457)
*Huizheng Wang,Hongbin Wang,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.LG

TL;DR: BitStopper是一种算法-架构协同设计，通过比特级稀疏推测和异步处理，无需稀疏预测器即可显著降低注意力计算开销，相比现有Transformer加速器实现2倍左右的性能提升和能效改进。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的大语言模型存在二次计算成本问题，动态稀疏注意力虽然能缓解但硬件效率受限，主要受限于额外的预测阶段和大量内存访问开销。

Method: 提出BitStopper框架：1) 比特串行使能阶段融合机制，重用内存访问并合并预测与执行阶段；2) 轻量自适应令牌选择策略；3) 比特级异步处理策略；4) 精心设计的硬件架构。

Result: 相比最先进的Transformer加速器Sanger和SOFA，BitStopper分别实现2.03倍和1.89倍的加速，能效分别提升2.4倍和2.1倍。

Conclusion: BitStopper通过算法-架构协同设计，无需稀疏预测器即可有效降低注意力计算开销，在性能和能效方面显著优于现有解决方案。

Abstract: Attention-based large language models (LLMs) have transformed modern AI applications, but the quadratic cost of self-attention imposes significant compute and memory overhead. Dynamic sparsity (DS) attention mitigates this, yet its hardware efficiency is limited by the added prediction stage and the heavy memory traffic it entails. To address these limitations, this paper proposes BitStopper, a fine-grained algorithm-architecture co-design that operates without a sparsity predictor. First, a bit-serial enable stage fusion (BESF) mechanism is proposed to reuse and minimize the memory access by progressively terminating trivial tokens and merging the prediction stage into the execution stage. Second, a lightweight and adaptive token selection (LATS) strategy is developed to work in concert with the bit-level sparsity speculation. Third, a bit-level asynchronous processing (BAP) strategy is employed to improve compute utilization during the on-demand bit-grained memory fetching. Finally, an elaborate architecture is designed to translate the theoretical complexity reduction into practical performance improvement. Extensive evaluations demonstrate that, compared to state-of-the-art (SOTA) Transformer accelerators, BitStopper achieves 2.03x and 1.89x speedups over Sanger and SOFA, respectively, while delivering 2.4x and 2.1x improvements in energy efficiency.

</details>


### [105] [Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control](https://arxiv.org/abs/2512.06471)
*Nathan P. Lawrence,Ali Mesbah*

Main category: cs.LG

TL;DR: 该论文分析了基于最优控制的目标条件强化学习，推导了经典二次目标与目标条件奖励之间的最优性差距，并探讨了部分可观测马尔可夫决策问题中状态估计与概率奖励的关系。


<details>
  <summary>Details</summary>
Motivation: 研究目标条件强化学习与经典最优控制方法之间的关系，解释为什么目标条件RL能够成功而传统的"密集"奖励可能失败，为理解目标条件RL提供理论分析基础。

Method: 基于最优控制理论分析目标条件强化学习，推导经典二次目标函数与目标条件奖励之间的最优性差距；考虑部分可观测马尔可夫决策过程，将状态估计与概率奖励联系起来；在非线性和不确定环境中使用强化学习和预测控制技术验证目标条件策略的优势。

Result: 建立了目标条件奖励与经典最优控制目标之间的理论联系，阐明了目标条件RL成功的原因；在部分可观测环境中将状态估计与概率奖励相结合，使目标条件奖励适用于双重控制问题；在非线性和不确定环境中的实验验证了目标条件策略的优势。

Conclusion: 目标条件强化学习与最优控制理论有深刻联系，其概率性奖励形式在某些情况下优于传统的二次奖励；在部分可观测环境中，目标条件奖励与状态估计的自然结合使其特别适合双重控制问题；理论和实验都支持目标条件策略在复杂环境中的有效性。

Abstract: Goal-conditioned reinforcement learning (RL) concerns the problem of training an agent to maximize the probability of reaching target goal states. This paper presents an analysis of the goal-conditioned setting based on optimal control. In particular, we derive an optimality gap between more classical, often quadratic, objectives and the goal-conditioned reward, elucidating the success of goal-conditioned RL and why classical ``dense'' rewards can falter. We then consider the partially observed Markov decision setting and connect state estimation to our probabilistic reward, further making the goal-conditioned reward well suited to dual control problems. The advantages of goal-conditioned policies are validated on nonlinear and uncertain environments using both RL and predictive control techniques.

</details>


### [106] [Optimizing LLMs Using Quantization for Mobile Execution](https://arxiv.org/abs/2512.06490)
*Agatsya Yadav,Renta Chintala Bhargavi*

Main category: cs.LG

TL;DR: 本文研究使用4位后训练量化技术压缩大语言模型，使其能够在资源受限的移动设备上运行，成功将Llama 3.2 3B模型压缩68.66%并在Android设备上部署。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然功能强大，但其庞大的规模和计算需求阻碍了在资源受限的移动设备上的部署，需要找到有效的压缩和优化方法。

Method: 使用BitsAndBytes库和Hugging Face Transformers框架对Meta的Llama 3.2 3B模型进行4位后训练量化，然后通过llama.cpp工具将量化模型转换为GGUF格式，最后在Android设备的Termux环境和Ollama框架上进行部署和验证。

Result: 通过4位量化实现了68.66%的模型大小缩减，量化后的模型能够在Android设备上成功执行推理任务，证明了在移动设备上运行量化大语言模型的可行性。

Conclusion: 4位后训练量化结合GGUF等移动优化格式，为在移动设备上部署能力强大的大语言模型提供了实用路径，有效平衡了模型大小和性能。

Abstract: Large Language Models (LLMs) offer powerful capabilities, but their significant size and computational requirements hinder deployment on resource-constrained mobile devices. This paper investigates Post-Training Quantization (PTQ) for compressing LLMs for mobile execution. We apply 4-bit PTQ using the BitsAndBytes library with the Hugging Face Transformers framework to Meta's Llama 3.2 3B model. The quantized model is converted to GGUF format using llama.cpp tools for optimized mobile inference. The PTQ workflow achieves a 68.66% reduction in model size through 4-bit quantization, enabling the Llama 3.2 3B model to run efficiently on an Android device. Qualitative validation shows that the 4-bit quantized model can perform inference tasks successfully. We demonstrate the feasibility of running the quantized GGUF model on an Android device using the Termux environment and the Ollama framework. PTQ, especially at 4-bit precision combined with mobile-optimized formats like GGUF, provides a practical pathway for deploying capable LLMs on mobile devices, balancing model size and performance.

</details>


### [107] [Diagnosis-based mortality prediction for intensive care unit patients via transfer learning](https://arxiv.org/abs/2512.06511)
*Mengqi Xu,Subha Maity,Joel Dubin*

Main category: cs.LG

TL;DR: 该研究评估了在ICU诊断特异性死亡率预测中应用迁移学习的方法，发现迁移学习在性能上优于仅使用诊断特异性数据训练的模型和APACHE IVa评分，且校准性更好。


<details>
  <summary>Details</summary>
Motivation: ICU中危重疾病的根本原因在不同诊断间差异很大，但现有的预测模型未能系统性地考虑诊断异质性，存在研究空白。

Method: 使用迁移学习方法进行诊断特异性死亡率预测，基于GLM和XGBoost模型，应用于eICU协作研究数据库，并与APACHE IVa评分进行比较。

Result: 迁移学习在预测性能上持续优于仅使用诊断特异性数据训练的模型和APACHE IVa评分，同时比在汇总数据上训练的模型具有更好的校准性。研究发现Youden截断值比传统的0.5阈值更适合二元结果预测。

Conclusion: 迁移学习是ICU诊断特异性死亡率预测的有效方法，能提高预测性能并保持良好校准，Youden截断值应作为更合适的决策阈值。

Abstract: In the intensive care unit, the underlying causes of critical illness vary substantially across diagnoses, yet prediction models accounting for diagnostic heterogeneity have not been systematically studied. To address the gap, we evaluate transfer learning approaches for diagnosis-specific mortality prediction and apply both GLM- and XGBoost-based models to the eICU Collaborative Research Database. Our results demonstrate that transfer learning consistently outperforms models trained only on diagnosis-specific data and those using a well-known ICU severity-of-illness score, i.e., APACHE IVa, alone, while also achieving better calibration than models trained on the pooled data. Our findings also suggest that the Youden cutoff is a more appropriate decision threshold than the conventional 0.5 for binary outcomes, and that transfer learning maintains consistently high predictive performance across various cutoff criteria.

</details>


### [108] [Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning](https://arxiv.org/abs/2512.06533)
*Ming Chen,Sheng Tang,Rong-Xi Tan,Ziniu Li,Jiacheng Chen,Ke Xue,Chao Qian*

Main category: cs.LG

TL;DR: 本文提出使用强化学习改进基于解码的回归方法，通过序列级奖励解决离散token目标与连续数值之间的不对齐问题，在表格回归和代码度量回归任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 基于解码的回归方法将回归任务重构为序列生成任务，但面临离散token级目标（如交叉熵）与连续数值之间的不对齐问题。现有基于token级约束的方法往往无法捕捉目标值的全局幅度，限制了其精度和泛化能力。

Method: 提出使用强化学习解锁基于解码的回归潜力，将生成过程建模为马尔可夫决策过程，利用序列级奖励来强制全局数值一致性。具体采用ReMax和GRPO方法。

Result: 在表格回归和代码度量回归任务上的广泛实验表明，该方法（特别是使用ReMax和GRPO）一致优于最先进的token级基线和传统回归头，显示了引入序列级信号的优势。

Conclusion: 强化学习显著提高了采样效率和预测精度，确立了基于解码的回归作为通用数值预测的稳健且准确的范式。

Abstract: Decoding-based regression, which reformulates regression as a sequence generation task, has emerged as a promising paradigm of applying large language models for numerical prediction. However, its progress is hindered by the misalignment between discrete token-level objectives (e.g., cross-entropy) and continuous numerical values. Existing approaches relying on token-level constraints often fail to capture the global magnitude of the target value, limiting their precision and generalization. In this paper, we propose to unlock the potential of decoding-based regression via Reinforcement Learning (RL). We formulate the generation process as a Markov Decision Process, utilizing sequence-level rewards to enforce global numerical coherence. Extensive experiments on tabular regression and code metric regression demonstrate that our method (specifically with ReMax and GRPO) consistently outperforms both state-of-the-art token-level baselines and traditional regression heads, showing the superiority of introducing sequence-level signals. Our analysis further reveals that RL significantly enhances sampling efficiency and predictive precision, establishing decoding-based regression as a robust and accurate paradigm for general-purpose numerical prediction.

</details>


### [109] [On fine-tuning Boltz-2 for protein-protein affinity prediction](https://arxiv.org/abs/2512.06592)
*James King,Lewis Cornwall,Andrei Cristian Nica,James Day,Aaron Sim,Neil Dalchau,Lilly Wollman,Joshua Meyers*

Main category: cs.LG

TL;DR: 将Boltz-2蛋白质-配体亲和力预测器适配用于蛋白质-蛋白质亲和力回归，但在TCR3d和PPB-affinity数据集上表现不如序列基方法，结合两种方法可互补提升性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测蛋白质-蛋白质结合亲和力对于理解分子相互作用和设计治疗方法至关重要。研究者希望将最先进的结构基蛋白质-配体亲和力预测器Boltz-2应用于蛋白质-蛋白质亲和力预测。

Method: 将Boltz-2适配为Boltz-2-PPI用于蛋白质-蛋白质亲和力回归，在两个数据集（TCR3d和PPB-affinity）上进行评估，并与序列基方法比较。同时尝试结合结构基和序列基嵌入来提升性能。

Result: 尽管结构准确性高，但Boltz-2-PPI在小规模和较大规模数据上都表现不如序列基替代方法。将Boltz-2-PPI嵌入与序列基嵌入结合可产生互补性改进，特别是对于较弱的序列模型，表明序列基和结构基模型学习了不同的信号。

Conclusion: 当前结构基表示方法尚未准备好用于高性能亲和力预测，结果反映了与结构数据训练相关的已知偏差。结合序列和结构信息可能提供更好的预测性能。

Abstract: Accurate prediction of protein-protein binding affinity is vital for understanding molecular interactions and designing therapeutics. We adapt Boltz-2, a state-of-the-art structure-based protein-ligand affinity predictor, for protein-protein affinity regression and evaluate it on two datasets, TCR3d and PPB-affinity. Despite high structural accuracy, Boltz-2-PPI underperforms relative to sequence-based alternatives in both small- and larger-scale data regimes. Combining embeddings from Boltz-2-PPI with sequence-based embeddings yields complementary improvements, particularly for weaker sequence models, suggesting different signals are learned by sequence- and structure-based models. Our results echo known biases associated with training with structural data and suggest that current structure-based representations are not primed for performant affinity prediction.

</details>


### [110] [A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs](https://arxiv.org/abs/2512.06607)
*Humzah Merchant,Bradford Levy*

Main category: cs.LG

TL;DR: 提出一种通过调整大模型logits来消除前瞻性偏差的方法，使用一对小型专业模型在推理时指导生成，有效移除金融预测中的知识泄露问题


<details>
  <summary>Details</summary>
Motivation: 将大语言模型应用于金融预测任务时面临前瞻性偏差挑战，因为模型训练使用了长时间序列数据，导致无法进行金融领域典型的回测验证。从头开始用特定知识截止日期重新训练前沿模型成本过高。

Method: 在推理时通过调整大型基础模型的logits来指导生成，使用一对小型专业模型：一个在需要遗忘的信息上微调，另一个在需要保留的信息上微调。这种方法快速、有效且成本低。

Result: 该方法能有效移除字面和语义知识，纠正偏差，并且在性能上优于先前的方法。

Conclusion: 提出的方法为解决金融预测中LLMs的前瞻性偏差问题提供了一种实用解决方案，通过推理时调整而非重新训练，实现了知识控制并提升了预测可靠性。

Abstract: Applying LLMs to predictive tasks in finance is challenging due to look-ahead bias resulting from their training on long time-series data. This precludes the backtests typically employed in finance since retraining frontier models from scratch with a specific knowledge cutoff is prohibitive. In this paper, we introduce a fast, effective, and low-cost alternative. Our method guides generation at inference time by adjusting the logits of a large base model using a pair of smaller, specialized models -- one fine-tuned on information to be forgotten and another on information to be retained. We demonstrate that our method effectively removes both verbatim and semantic knowledge, corrects biases, and outperforms prior methods.

</details>


### [111] [Vector Quantization using Gaussian Variational Autoencoder](https://arxiv.org/abs/2512.06609)
*Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang*

Main category: cs.LG

TL;DR: 提出Gaussian Quant (GQ)方法，将带约束的高斯VAE转换为VQ-VAE而无需训练，通过理论证明和实践验证优于现有VQ-VAE方法


<details>
  <summary>Details</summary>
Motivation: VQ-VAE由于离散化难以训练，需要一种更简单有效的离散化方法

Method: 提出Gaussian Quant (GQ)技术：1) 生成随机高斯噪声作为码本；2) 寻找最接近后验均值的噪声；3) 提出目标散度约束(TDC)启发式方法训练高斯VAE

Result: GQ在UNet和ViT架构上优于VQGAN、FSQ、LFQ、BSQ等现有VQ-VAE方法；TDC也改进了TokenBridge等高斯VAE离散化方法

Conclusion: GQ提供了一种简单有效的VQ-VAE训练方法，通过理论保证和实际改进证明了其有效性

Abstract: Vector quantized variational autoencoder (VQ-VAE) is a discrete auto-encoder that compresses images into discrete tokens. It is difficult to train due to discretization. In this paper, we propose a simple yet effective technique, dubbed Gaussian Quant (GQ), that converts a Gaussian VAE with certain constraint into a VQ-VAE without training. GQ generates random Gaussian noise as a codebook and finds the closest noise to the posterior mean. Theoretically, we prove that when the logarithm of the codebook size exceeds the bits-back coding rate of the Gaussian VAE, a small quantization error is guaranteed. Practically, we propose a heuristic to train Gaussian VAE for effective GQ, named target divergence constraint (TDC). Empirically, we show that GQ outperforms previous VQ-VAEs, such as VQGAN, FSQ, LFQ, and BSQ, on both UNet and ViT architectures. Furthermore, TDC also improves upon previous Gaussian VAE discretization methods, such as TokenBridge. The source code is provided in https://github.com/tongdaxu/VQ-VAE-from-Gaussian-VAE.

</details>


### [112] [Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning](https://arxiv.org/abs/2512.06649)
*Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou*

Main category: cs.LG

TL;DR: 利用交通监控视频和天气数据，通过机器学习模型估计街道级别的黑碳浓度，填补交通监测与环境影响之间的数据缺口。


<details>
  <summary>Details</summary>
Motivation: 城市黑碳排放主要来自交通，但现有监测设备昂贵且稀少，导致缺乏本地交通源的黑碳数据，无法为针对本地因素的干预政策提供支持。交通监控系统广泛部署，但环境后果数据缺失，形成信息不平衡。

Method: 提出机器学习驱动系统，从交通视频中提取车辆行为和状况的视觉信息，结合天气数据，构建模型估计街道级别的黑碳浓度。

Result: 模型达到R平方值0.72，RMSE为129.42 ng/m³，能够有效估计黑碳浓度。

Conclusion: 该工作利用现有城市基础设施资源和成熟建模技术，生成与交通排放相关的信息，为污染减排、城市规划、公共卫生和环境正义提供可操作的本地数据支持。

Abstract: Black carbon (BC) emissions in urban areas are primarily driven by traffic, with hotspots near major roads disproportionately affecting marginalized communities. Because BC monitoring is typically performed using costly and specialized instruments. there is little to no available data on BC from local traffic sources that could help inform policy interventions targeting local factors. By contrast, traffic monitoring systems are widely deployed in cities around the world, highlighting the imbalance between what we know about traffic conditions and what do not know about their environmental consequences. To bridge this gap, we propose a machine learning-driven system that extracts visual information from traffic video to capture vehicles behaviors and conditions. Combining these features with weather data, our model estimates BC at street level, achieving an R-squared value of 0.72 and RMSE of 129.42 ng/m3 (nanogram per cubic meter). From a sustainability perspective, this work leverages resources already supported by urban infrastructure and established modeling techniques to generate information relevant to traffic emission. Obtaining BC concentration data provides actionable insights to support pollution reduction, urban planning, public health, and environmental justice at the local municipal level.

</details>


### [113] [Adaptive Test-Time Training for Predicting Need for Invasive Mechanical Ventilation in Multi-Center Cohorts](https://arxiv.org/abs/2512.06652)
*Xiaolei Lu,Shamim Nemati*

Main category: cs.LG

TL;DR: 该论文提出AdaTTT框架，通过自适应测试时训练提升ICU患者有创机械通气需求预测的泛化能力，解决跨机构部署时的领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: ICU患者有创机械通气需求预测对及时干预和资源分配至关重要，但不同机构的患者群体、临床实践和电子健康记录系统存在差异，导致预测模型在部署时出现领域偏移和泛化性能下降。

Method: 提出自适应测试时训练框架AdaTTT：1) 推导测试时预测误差的信息论边界；2) 引入基于重建和掩码特征建模的自监督学习框架，采用动态掩码策略强调主任务关键特征；3) 结合原型学习和部分最优传输进行灵活的特征对齐，保持临床意义的患者表示。

Result: 在多中心ICU队列实验中，在不同测试时适应基准上展现出有竞争力的分类性能。

Conclusion: AdaTTT框架通过自适应测试时训练有效缓解了跨机构部署时的领域偏移问题，提升了ICU患者有创机械通气需求预测模型的泛化能力。

Abstract: Accurate prediction of the need for invasive mechanical ventilation (IMV) in intensive care units (ICUs) patients is crucial for timely interventions and resource allocation. However, variability in patient populations, clinical practices, and electronic health record (EHR) systems across institutions introduces domain shifts that degrade the generalization performance of predictive models during deployment. Test-Time Training (TTT) has emerged as a promising approach to mitigate such shifts by adapting models dynamically during inference without requiring labeled target-domain data. In this work, we introduce Adaptive Test-Time Training (AdaTTT), an enhanced TTT framework tailored for EHR-based IMV prediction in ICU settings. We begin by deriving information-theoretic bounds on the test-time prediction error and demonstrate that it is constrained by the uncertainty between the main and auxiliary tasks. To enhance their alignment, we introduce a self-supervised learning framework with pretext tasks: reconstruction and masked feature modeling optimized through a dynamic masking strategy that emphasizes features critical to the main task. Additionally, to improve robustness against domain shifts, we incorporate prototype learning and employ Partial Optimal Transport (POT) for flexible, partial feature alignment while maintaining clinically meaningful patient representations. Experiments across multi-center ICU cohorts demonstrate competitive classification performance on different test-time adaptation benchmarks.

</details>


### [114] [The Meta-Learning Gap: Combining Hydra and Quant for Large-Scale Time Series Classification](https://arxiv.org/abs/2512.06666)
*Urav Maniar*

Main category: cs.LG

TL;DR: 该研究探讨时间序列分类中准确性与计算效率的权衡，通过结合Hydra和Quant两种高效算法，在大型数据集上验证了有限但显著的性能提升，发现当前元学习方法未能充分利用算法互补性。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类面临准确性与计算效率的根本权衡。虽然像HIVE-COTE 2.0这样的综合集成方法能达到最先进的准确性，但其在UCR基准测试上340小时的训练时间使其在大规模数据集上不切实际。研究旨在探索是否可以通过有针对性地结合来自互补范式的两种高效算法来获得集成效益，同时保持计算可行性。

Method: 结合Hydra（竞争性卷积核）和Quant（分层区间分位数）两种高效算法，在六种集成配置下进行评估。使用10个大规模MONSTER数据集（训练实例从7,898到1,168,774个）进行性能测试。比较了预测组合集成和特征连接方法。

Result: 最强配置将平均准确率从0.829提高到0.836，在10个数据集中成功7个。但预测组合集成仅捕获了11%的理论oracle潜力，显示出显著的元学习优化差距。特征连接方法通过学习新的决策边界超过了oracle界限，而预测级互补性与集成增益呈中等相关性。

Conclusion: 核心发现：挑战已从确保算法不同转变为学习如何有效结合它们。当前的元学习策略难以利用oracle分析确认存在的互补性。改进的组合策略可能使集成增益在多样化时间序列分类应用中翻倍或三倍。

Abstract: Time series classification faces a fundamental trade-off between accuracy and computational efficiency. While comprehensive ensembles like HIVE-COTE 2.0 achieve state-of-the-art accuracy, their 340-hour training time on the UCR benchmark renders them impractical for large-scale datasets. We investigate whether targeted combinations of two efficient algorithms from complementary paradigms can capture ensemble benefits while maintaining computational feasibility. Combining Hydra (competing convolutional kernels) and Quant (hierarchical interval quantiles) across six ensemble configurations, we evaluate performance on 10 large-scale MONSTER datasets (7,898 to 1,168,774 training instances). Our strongest configuration improves mean accuracy from 0.829 to 0.836, succeeding on 7 of 10 datasets. However, prediction-combination ensembles capture only 11% of theoretical oracle potential, revealing a substantial meta-learning optimization gap. Feature-concatenation approaches exceeded oracle bounds by learning novel decision boundaries, while prediction-level complementarity shows moderate correlation with ensemble gains. The central finding: the challenge has shifted from ensuring algorithms are different to learning how to combine them effectively. Current meta-learning strategies struggle to exploit the complementarity that oracle analysis confirms exists. Improved combination strategies could potentially double or triple ensemble gains across diverse time series classification applications.

</details>


### [115] [GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning](https://arxiv.org/abs/2512.06678)
*Shrihari Sridharan,Deepak Ravikumar,Anand Raghunathan,Kaushik Roy*

Main category: cs.LG

TL;DR: GradientSpace框架通过在完整梯度空间中直接聚类样本，避免降维带来的精度损失，使用在线SVD算法识别潜在技能，训练专门的LoRA专家和轻量级路由器，在推理时选择最佳专家，显著提升性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据集通常是异构的，包含多样信息，导致梯度干扰问题——冲突的梯度将模型拉向相反方向，降低性能。现有方法基于语义或嵌入相似性分组数据，但无法捕捉数据如何影响模型参数学习；而直接聚类梯度的方法通过随机投影降维会导致精度损失，且依赖专家集成需要多次推理和昂贵的梯度计算。

Method: 提出GradientSpace框架：1）在完整梯度空间中直接聚类样本，避免降维精度损失；2）引入基于在线SVD的算法，在LoRA梯度上操作，识别潜在技能，无需存储所有样本梯度；3）为每个聚类训练专门的LoRA专家；4）训练轻量级路由器在推理时选择最佳专家。

Result: 在数学推理、代码生成、金融和创意写作任务上的实验表明，GradientSpace能够实现一致的专家专业化，相比最先进的聚类方法和微调技术获得一致的精度提升。路由到单个适当专家的方法优于先前工作中的专家集成，同时显著降低推理延迟。

Conclusion: GradientSpace通过直接在完整梯度空间中聚类样本，有效解决了异构数据集中的梯度干扰问题，避免了降维精度损失，同时通过专门的LoRA专家和轻量级路由器实现了高效推理，在多个任务上展现了优越性能。

Abstract: Instruction tuning is one of the key steps required for adapting large language models (LLMs) to a broad spectrum of downstream applications. However, this procedure is difficult because real-world datasets are rarely homogeneous; they consist of a mixture of diverse information, causing gradient interference, where conflicting gradients pull the model in opposing directions, degrading performance. A common strategy to mitigate this issue is to group data based on semantic or embedding similarity. However, this fails to capture how data influences model parameters during learning. While recent works have attempted to cluster gradients directly, they randomly project gradients into lower dimensions to manage memory, which leads to accuracy loss. Moreover, these methods rely on expert ensembles which necessitates multiple inference passes and expensive on-the-fly gradient computations during inference. To address these limitations, we propose GradientSpace, a framework that clusters samples directly in full-dimensional gradient space. We introduce an online SVD-based algorithm that operates on LoRA gradients to identify latent skills without the infeasible cost of storing all sample gradients. Each cluster is used to train a specialized LoRA expert along with a lightweight router trained to select the best expert during inference. We show that routing to a single, appropriate expert outperforms expert ensembles used in prior work, while significantly reducing inference latency. Our experiments across mathematical reasoning, code generation, finance, and creative writing tasks demonstrate that GradientSpace leads to coherent expert specialization and consistent accuracy gains over state-of-the-art clustering methods and finetuning techniques.

</details>


### [116] [State Diversity Matters in Offline Behavior Distillation](https://arxiv.org/abs/2512.06692)
*Shiye Lei,Zhihao Cheng,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文发现离线行为蒸馏中原始数据集与合成数据集存在不对齐问题，提出状态多样性在训练损失较大时比状态质量更重要，并设计了状态密度加权算法来提升蒸馏性能。


<details>
  <summary>Details</summary>
Motivation: 离线行为蒸馏通过将大量离线RL数据压缩为紧凑的合成行为数据集，为高效策略训练提供了有前景的方法。然而，作者发现原始数据集与蒸馏后的合成数据集之间存在不对齐问题：高质量的原始数据集不一定能产生更优的合成数据集。这种不对齐现象需要深入分析和解决。

Method: 1. 通过实证分析不同训练损失水平下的策略性能，发现当训练损失较大时（离线行为蒸馏的典型情况），状态多样性比状态质量更重要；而在损失较小时，关系则相反。
2. 理论分析将状态质量和多样性分别与减少关键误差和周围误差相关联，证明当关键误差较大时，周围误差对策略性能的影响更关键。
3. 提出状态密度加权算法：通过使用状态密度倒数为蒸馏目标加权，强调状态多样性，从而将更多样化的状态信息蒸馏到合成数据中。

Result: 在多个D4RL数据集上的广泛实验证实，当原始数据集状态多样性有限时，状态密度加权算法能显著提升离线行为蒸馏的性能。该算法通过强调状态多样性，有效解决了原始数据集与合成数据集之间的不对齐问题。

Conclusion: 离线行为蒸馏中状态多样性比状态质量更为关键，特别是在训练损失较大的情况下。提出的状态密度加权算法通过强调状态多样性，有效提升了蒸馏性能，为解决原始数据集与合成数据集之间的不对齐问题提供了有效方案。

Abstract: Offline Behavior Distillation (OBD), which condenses massive offline RL data into a compact synthetic behavioral dataset, offers a promising approach for efficient policy training and can be applied across various downstream RL tasks. In this paper, we uncover a misalignment between original and distilled datasets, observing that a high-quality original dataset does not necessarily yield a superior synthetic dataset. Through an empirical analysis of policy performance under varying levels of training loss, we show that datasets with greater state diversity outperforms those with higher state quality when training loss is substantial, as is often the case in OBD, whereas the relationship reverses under minimal loss, which contributes to the misalignment. By associating state quality and diversity in reducing pivotal and surrounding error, respectively, our theoretical analysis establishes that surrounding error plays a more crucial role in policy performance when pivotal error is large, thereby highlighting the importance of state diversity in OBD scenario. Furthermore, we propose a novel yet simple algorithm, state density weighted (SDW) OBD, which emphasizes state diversity by weighting the distillation objective using the reciprocal of state density, thereby distilling a more diverse state information into synthetic data. Extensive experiments across multiple D4RL datasets confirm that SDW significantly enhances OBD performance when the original dataset exhibits limited state diversity.

</details>


### [117] [Mitigating Barren plateaus in quantum denoising diffusion probabilistic models](https://arxiv.org/abs/2512.06695)
*Haipeng Cao,Kaining Zhang,Dacheng Tao,Zhaofeng Su*

Main category: cs.LG

TL;DR: 本文发现量子去噪扩散概率模型(QuDDPM)存在贫瘠高原问题，并提出改进方案以提升训练效果和生成质量。


<details>
  <summary>Details</summary>
Motivation: 量子生成模型利用量子叠加和纠缠特性提升学习效率，QuDDPM作为量子生成学习框架在量子数据学习方面表现优异，但存在贫瘠高原问题，限制了其实际应用效果。

Method: 通过理论分析和实验验证确认原始QuDDPM存在贫瘠高原问题，提出改进的QuDDPM，使用与Haar分布保持一定距离的分布作为去噪过程输入，确保更好的可训练性。

Result: 实验结果表明，改进方法有效缓解了贫瘠高原问题，生成了更高质量的样本，为可扩展和高效的量子生成学习铺平了道路。

Conclusion: 虽然QuDDPM在量子生成学习方面具有潜力，但原始版本存在贫瘠高原问题，通过使用与Haar分布保持距离的分布可以显著改善训练效果和生成质量。

Abstract: Quantum generative models leverage quantum superposition and entanglement to enhance learning efficiency for both classical and quantum data. The quantum denoising diffusion probabilistic model (QuDDPM), inspired by its classical counterpart, has been proposed as a promising framework for quantum generative learning. QuDDPM is capable of efficiently learning and generating quantum data, and it demonstrates excellent performance in learning correlated quantum noise models, quantum many-body phases, and the topological structure of quantum data. However, we show that barren plateaus emerge in QuDDPMs due to the use of 2-design states as the input for the denoising process, which severely undermines the performance of QuDDPM. Through theoretical analysis and experimental validation, we confirm the presence of barren plateaus in the original QuDDPM. To address this issue, we introduce an improved QuDDPM that utilizes a distribution maintaining a certain distance from the Haar distribution, ensuring better trainability. Experimental results demonstrate that our approach effectively mitigates the barren plateau problem and generates samples with higher quality, paving the way for scalable and efficient quantum generative learning.

</details>


### [118] [Pathway to $O(\sqrt{d})$ Complexity bound under Wasserstein metric of flow-based models](https://arxiv.org/abs/2512.06702)
*Xiangjun Meng,Zhongjian Wang*

Main category: cs.LG

TL;DR: 论文为基于流的生成模型提供了可实现的误差分析工具，证明了在Wasserstein度量下最优采样迭代复杂度为O(√d)，误差由两部分控制：与维度无关的反向流推前映射的Lipschitz性，以及局部离散误差O(√d)。


<details>
  <summary>Details</summary>
Motivation: 为基于流的生成模型提供可实现的误差分析工具，建立维度相关的采样迭代复杂度界限，解决现有理论分析中维度依赖关系不明确的问题。

Method: 将误差分解为两部分：反向流推前映射的Lipschitz性（与维度无关）和局部离散误差（维度相关O(√d)）。利用Föllmer过程和1-整流流在Gaussian尾假设下的性质验证假设有效性。

Result: 证明了基于流的生成模型在Wasserstein度量下的最优采样迭代复杂度为O(√d)，采样迭代复杂度与协方差算子迹的平方根线性相关。

Conclusion: 论文建立了基于流的生成模型的严格误差分析框架，明确了维度对采样复杂度的具体影响，为实际应用提供了理论指导。

Abstract: We provide attainable analytical tools to estimate the error of flow-based generative models under the Wasserstein metric and to establish the optimal sampling iteration complexity bound with respect to dimension as $O(\sqrt{d})$. We show this error can be explicitly controlled by two parts: the Lipschitzness of the push-forward maps of the backward flow which scales independently of the dimension; and a local discretization error scales $O(\sqrt{d})$ in terms of dimension. The former one is related to the existence of Lipschitz changes of variables induced by the (heat) flow. The latter one consists of the regularity of the score function in both spatial and temporal directions.
  These assumptions are valid in the flow-based generative model associated with the Föllmer process and $1$-rectified flow under the Gaussian tail assumption. As a consequence, we show that the sampling iteration complexity grows linearly with the square root of the trace of the covariance operator, which is related to the invariant distribution of the forward process.

</details>


### [119] [A Novel Multimodal RUL Framework for Remaining Useful Life Estimation with Layer-wise Explanations](https://arxiv.org/abs/2512.06708)
*Waleed Razzaq,Yun-Bo Zhao*

Main category: cs.LG

TL;DR: 提出了一种新颖的多模态RUL估计框架，联合利用振动信号的图像表示和时间频率表示，通过多分支架构提取空间和时间退化特征，并引入可解释性技术增强模型透明度。


<details>
  <summary>Details</summary>
Motivation: 滚动轴承是机械故障的常见原因，现有RUL估计方法存在泛化能力差、鲁棒性不足、数据需求高、可解释性有限等问题，需要更稳健的RUL估计方法。

Method: 提出多模态RUL框架，包含三个分支：1)图像表示分支使用Bresenham线算法转换振动信号；2)时间频率表示分支使用连续小波变换；3)融合分支通过LSTM建模时间退化模式，并采用多头注意力机制强调重要特征，最后通过线性层进行RUL回归。

Result: 在XJTU-SY和PRONOSTIA基准数据集上验证，方法在已知和未知工况下均达到或超越最先进基线，训练数据需求分别减少约28%和48%，模型具有强噪声鲁棒性，多模态LRP可视化证实了预测的可解释性和可信度。

Conclusion: 该框架通过多模态特征融合和可解释性技术，实现了高效、稳健、可解释的RUL估计，非常适合实际工业部署。

Abstract: Estimating the Remaining Useful Life (RUL) of mechanical systems is pivotal in Prognostics and Health Management (PHM). Rolling-element bearings are among the most frequent causes of machinery failure, highlighting the need for robust RUL estimation methods. Existing approaches often suffer from poor generalization, lack of robustness, high data demands, and limited interpretability. This paper proposes a novel multimodal-RUL framework that jointly leverages image representations (ImR) and time-frequency representations (TFR) of multichannel, nonstationary vibration signals. The architecture comprises three branches: (1) an ImR branch and (2) a TFR branch, both employing multiple dilated convolutional blocks with residual connections to extract spatial degradation features; and (3) a fusion branch that concatenates these features and feeds them into an LSTM to model temporal degradation patterns. A multi-head attention mechanism subsequently emphasizes salient features, followed by linear layers for final RUL regression. To enable effective multimodal learning, vibration signals are converted into ImR via the Bresenham line algorithm and into TFR using Continuous Wavelet Transform. We also introduce multimodal Layer-wise Relevance Propagation (multimodal-LRP), a tailored explainability technique that significantly enhances model transparency. The approach is validated on the XJTU-SY and PRONOSTIA benchmark datasets. Results show that our method matches or surpasses state-of-the-art baselines under both seen and unseen operating conditions, while requiring ~28 % less training data on XJTU-SY and ~48 % less on PRONOSTIA. The model exhibits strong noise resilience, and multimodal-LRP visualizations confirm the interpretability and trustworthiness of predictions, making the framework highly suitable for real-world industrial deployment.

</details>


### [120] [A Novel Deep Neural Network Architecture for Real-Time Water Demand Forecasting](https://arxiv.org/abs/2512.06714)
*Tony Salloom,Okyay Kaynak,Wei He*

Main category: cs.LG

TL;DR: 提出一种基于深度学习的短期用水需求预测方法，通过数据扩展减少极端点误差，结合GRU和K-means降低模型复杂度


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在短期用水需求预测中存在两个主要问题：1）模型参数过多导致复杂度高；2）在极端点预测误差较大。需要一种既能降低复杂度又能提高极端点预测准确性的方法。

Method: 1）提出数据扩展方法：在实际数据中插入虚拟数据，缓解极端点周围的非线性问题；2）构建新型深度学习模型：使用GRU处理历史需求数据的序列关系，引入K-means无监督分类方法创建新特征，在减少参数的同时提高预测精度。

Result: 使用中国两个不同水厂的真实数据进行验证，结果表明：1）模型复杂度降低至文献中方法的六分之一，同时保持相同精度；2）数据扩展方法显著减少约30%的预测误差，但会增加训练时间。

Conclusion: 该研究首次关注短期用水需求预测中的极端点问题，提出的数据扩展方法和新型深度学习模型在降低复杂度和提高预测精度方面均取得显著效果，为水供应系统优化控制提供了更有效的解决方案。

Abstract: Short-term water demand forecasting (StWDF) is the foundation stone in the derivation of an optimal plan for controlling water supply systems. Deep learning (DL) approaches provide the most accurate solutions for this purpose. However, they suffer from complexity problem due to the massive number of parameters, in addition to the high forecasting error at the extreme points. In this work, an effective method to alleviate the error at these points is proposed. It is based on extending the data by inserting virtual data within the actual data to relieve the nonlinearity around them. To our knowledge, this is the first work that considers the problem related to the extreme points. Moreover, the water demand forecasting model proposed in this work is a novel DL model with relatively low complexity. The basic model uses the gated recurrent unit (GRU) to handle the sequential relationship in the historical demand data, while an unsupervised classification method, K-means, is introduced for the creation of new features to enhance the prediction accuracy with less number of parameters. Real data obtained from two different water plants in China are used to train and verify the model proposed. The prediction results and the comparison with the state-of-the-art illustrate that the method proposed reduces the complexity of the model six times of what achieved in the literature while conserving the same accuracy. Furthermore, it is found that extending the data set significantly reduces the error by about 30%. However, it increases the training time.

</details>


### [121] [KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models](https://arxiv.org/abs/2512.06727)
*Sourjya Roy,Shrihari Sridharan,Surya Selvam,Anand Raghunathan*

Main category: cs.LG

TL;DR: KV CAR是一个统一的KV缓存压缩框架，通过轻量级自编码器和相似性驱动的重用机制，在不改变Transformer架构的情况下显著减少KV缓存内存占用，实现更高效的大语言模型推理。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模和上下文长度的增加，KV缓存在自回归解码过程中的内存需求已成为主要瓶颈。KV缓存随序列长度和嵌入维度增长，常常超过模型本身的内存占用，限制了可实现的批处理大小和上下文窗口。

Method: KV CAR结合两种互补技术：1）轻量级自编码器学习键值张量在嵌入维度上的紧凑表示，在存储到KV缓存前压缩并在检索时恢复；2）相似性驱动的重用机制识别在相邻层间重用特定注意力头KV张量的机会。这两种方法共同减少了KV张量的维度和结构冗余。

Result: 在GPT-2和TinyLLaMA模型上的评估显示，KV CAR在Wikitext、C4、PIQA和Winogrande数据集上实现了高达47.85%的KV缓存内存减少，同时对困惑度和零样本准确率影响最小。在NVIDIA A40 GPU上的系统级测量表明，减少的KV占用直接转化为推理过程中更长的序列长度和更大的批处理大小。

Conclusion: KV CAR框架有效地实现了内存高效的大语言模型推理，通过减少KV缓存的内存需求，使模型能够处理更长的序列和更大的批处理，同时保持模型保真度。

Abstract: As Large Language Models (LLMs) scale in size and context length, the memory requirements of the key value (KV) cache have emerged as a major bottleneck during autoregressive decoding. The KV cache grows with sequence length and embedding dimension, often exceeding the memory footprint of the model itself and limiting achievable batch sizes and context windows. To address this challenge, we present KV CAR, a unified and architecture agnostic framework that significantly reduces KV cache storage while maintaining model fidelity. KV CAR combines two complementary techniques. First, a lightweight autoencoder learns compact representations of key and value tensors along the embedding dimension, compressing them before they are stored in the KV cache and restoring them upon retrieval. Second, a similarity driven reuse mechanism identifies opportunities to reuse KV tensors of specific attention heads across adjacent layers. Together, these methods reduce the dimensional and structural redundancy in KV tensors without requiring changes to the transformer architecture. Evaluations on GPT 2 and TinyLLaMA models across Wikitext, C4, PIQA, and Winogrande datasets demonstrate that KV CAR achieves up to 47.85 percent KV cache memory reduction with minimal impact on perplexity and zero shot accuracy. System level measurements on an NVIDIA A40 GPU show that the reduced KV footprint directly translates into longer sequence lengths and larger batch sizes during inference. These results highlight the effectiveness of KV CAR in enabling memory efficient LLM inference.

</details>


### [122] [Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data](https://arxiv.org/abs/2512.06730)
*Lin Yang,Xiang Li,Xin Ma,Xinxin Zhao*

Main category: cs.LG

TL;DR: 该研究提出了一种基于增强现实的SSVEP脑机接口系统，通过改进的CNN-BiLSTM架构结合多头注意力机制，提高了运动意图识别的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统SSVEP-BCI系统依赖外部视觉刺激设备，在实际应用中受限；运动功能障碍患者康复训练主观参与度低，治疗师工作负担重。

Method: 设计基于HoloLens 2的四种EEG类别，收集7名健康受试者数据；构建MACNN-BiLSTM模型（CNN-BiLSTM+多头注意力），提取10个时频EEG特征，使用CNN学习高级表征，BiLSTM建模序列依赖，多头注意力突出运动意图相关模式，SHAP方法可视化特征贡献。

Result: 提出的AR-SSVEP系统增强了实时运动意图识别能力，支持运动障碍患者的康复恢复。

Conclusion: 该研究通过AR技术和改进的深度学习架构，解决了传统BCI系统的局限性，提高了患者康复训练的主动性和系统实用性。

Abstract: Patients with motor dysfunction show low subjective engagement in rehabilitation training. Traditional SSVEP-based brain-computer interface (BCI) systems rely heavily on external visual stimulus equipment, limiting their practicality in real-world settings. This study proposes an augmented reality steady-state visually evoked potential (AR-SSVEP) system to address the lack of patient initiative and the high workload on therapists. Firstly, we design four HoloLens 2-based EEG classes and collect EEG data from seven healthy subjects for analysis. Secondly, we build upon the conventional CNN-BiLSTM architecture by integrating a multi-head attention mechanism (MACNN-BiLSTM). We extract ten temporal-spectral EEG features and feed them into a CNN to learn high-level representations. Then, we use BiLSTM to model sequential dependencies and apply a multi-head attention mechanism to highlight motor-intention-related patterns. Finally, the SHAP (SHapley Additive exPlanations) method is applied to visualize EEG feature contributions to the neural network's decision-making process, enhancing the model's interpretability. These findings enhance real-time motor intention recognition and support recovery in patients with motor impairments.

</details>


### [123] [Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics](https://arxiv.org/abs/2512.06737)
*Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta*

Main category: cs.LG

TL;DR: ArcGD优化器在非凸基准函数和真实ML数据集上均表现优异，在CIFAR-10图像分类任务中取得了最高平均测试准确率，展现出良好的泛化能力和抗过拟合特性。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的优化器ArcGD，旨在解决现有优化器在非凸函数优化和深度学习任务中存在的收敛问题，特别是在长时间训练时可能出现的性能退化问题。

Method: 首先在高度非凸的Rosenbrock函数上进行评估，从2D到1000D再到极端情况50000D，采用两种学习率配置消除偏差。然后在CIFAR-10数据集上评估，使用8种不同的MLP架构（1-5个隐藏层），与Adam、AdamW、Lion、SGD等先进优化器对比。

Result: 在Rosenbrock函数上，ArcGD在使用自身有效学习率时始终优于Adam；在使用Adam默认学习率时虽然收敛较慢，但在大多数情况下获得了更优的最终解。在CIFAR-10上，ArcGD在20,000次迭代时取得了最高平均测试准确率50.7%，优于其他优化器，在8种架构中的6种上获胜或持平。ArcGD在长时间训练中持续改进，而Adam和AdamW在早期收敛后出现性能退化。

Conclusion: ArcGD优化器在几何压力测试和标准深度学习基准测试中均表现出色，显示出广泛的适用性。研究还发现ArcGD的变体可解释为Lion优化器的特例，揭示了这类优化方法内在机制之间的联系，值得进一步探索。

Abstract: The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.

</details>


### [124] [Angular Regularization for Positive-Unlabeled Learning on the Hypersphere](https://arxiv.org/abs/2512.06785)
*Vasileios Sevetlidis,George Pavlidis,Antonios Gasteratos*

Main category: cs.LG

TL;DR: AngularPU是一种新的正例-未标记学习框架，使用余弦相似度和角度间隔在单位超球面上操作，通过可学习的原型向量表示正类，无需显式负类建模。


<details>
  <summary>Details</summary>
Motivation: 现有的PU学习方法要么依赖强分布假设，要么在高维设置中容易崩溃。需要一种更稳健、无需显式负类建模的方法来处理正例稀缺和高维嵌入的场景。

Method: 提出AngularPU框架：1）在单位超球面上使用余弦相似度和角度间隔；2）用可学习的原型向量表示正类；3）通过阈值化嵌入与原型之间的余弦相似度进行分类；4）引入角度正则化器，鼓励未标记集在超球面上分散，改善分离效果。

Result: 在基准数据集上的实验表明，AngularPU在正例稀缺和高维嵌入设置中，相比最先进的PU方法具有竞争性或更优性能，同时提供几何可解释性和可扩展性。

Conclusion: AngularPU通过角度决策规则、原型学习和正则化，提供了一种无需显式负类建模的稳健PU学习框架，特别适用于正例稀缺和高维场景，具有理论保证和实际优势。

Abstract: Positive-Unlabeled (PU) learning addresses classification problems where only a subset of positive examples is labeled and the remaining data is unlabeled, making explicit negative supervision unavailable. Existing PU methods often rely on negative-risk estimation or pseudo-labeling, which either require strong distributional assumptions or can collapse in high-dimensional settings. We propose AngularPU, a novel PU framework that operates on the unit hypersphere using cosine similarity and angular margin. In our formulation, the positive class is represented by a learnable prototype vector, and classification reduces to thresholding the cosine similarity between an embedding and this prototype-eliminating the need for explicit negative modeling. To counteract the tendency of unlabeled embeddings to cluster near the positive prototype, we introduce an angular regularizer that encourages dispersion of the unlabeled set over the hypersphere, improving separation. We provide theoretical guarantees on the Bayes-optimality of the angular decision rule, consistency of the learned prototype, and the effect of the regularizer on the unlabeled distribution. Experiments on benchmark datasets demonstrate that AngularPU achieves competitive or superior performance compared to state-of-the-art PU methods, particularly in settings with scarce positives and high-dimensional embeddings, while offering geometric interpretability and scalability.

</details>


### [125] [Optimal Analysis for Bandit Learning in Matching Markets with Serial Dictatorship](https://arxiv.org/abs/2512.06758)
*Zilong Wang,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了一种多级连续选择算法，在满足序列独裁假设的双边匹配市场中实现了与下界匹配的遗憾上界。


<details>
  <summary>Details</summary>
Motivation: 双边匹配市场在序列独裁假设下存在遗憾下界与上界之间的差距（从N到K），目前不清楚是下界需要改进还是上界需要改进，需要设计能达到下界的算法。

Method: 提出多级连续选择算法，在满足序列独裁假设的匹配市场中运行，实现了与下界匹配的遗憾上界。

Result: 算法获得了$O\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$的遗憾上界，与Sankararaman等人提出的下界完全匹配。

Conclusion: 这是首个在匹配市场与多臂老虎机问题中达到下界的算法，解决了下界与上界之间的差距问题。

Abstract: The problem of two-sided matching markets is well-studied in computer science and economics, owing to its diverse applications across numerous domains. Since market participants are usually uncertain about their preferences in various online matching platforms, an emerging line of research is dedicated to the online setting where one-side participants (players) learn their unknown preferences through multiple rounds of interactions with the other side (arms). Sankararaman et al. provide an $Ω\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret lower bound for this problem under serial dictatorship assumption, where $N$ is the number of players, $K (\geq N)$ is the number of arms, $Δ$ is the minimum reward gap across players and arms, and $T$ is the time horizon. Serial dictatorship assumes arms have the same preferences, which is common in reality when one side participants have a unified evaluation standard. Recently, the work of Kong and Li proposes the ET-GS algorithm and achieves an $O\left( \frac{K\log(T)}{Δ^2} \right)$ regret upper bound, which is the best upper bound attained so far. Nonetheless, a gap between the lower and upper bounds, ranging from $N$ to $K$, persists. It remains unclear whether the lower bound or the upper bound needs to be improved. In this paper, we propose a multi-level successive selection algorithm that obtains an $O\left( \frac{N\log(T)}{Δ^2} + \frac{K\log(T)}Δ \right)$ regret bound when the market satisfies serial dictatorship. To the best of our knowledge, we are the first to propose an algorithm that matches the lower bound in the problem of matching markets with bandits.

</details>


### [126] [Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features](https://arxiv.org/abs/2512.06925)
*Aseer Al Faisal*

Main category: cs.LG

TL;DR: 提出了一种结合RoBERTa语义嵌入和手工特征词特征的QR-DQN方法，用于钓鱼网站检测，通过分位数回归建模回报分布，在105,000个URL数据集上取得了99.86%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击通过欺诈信息、误导广告和合法网站漏洞欺骗用户泄露个人信息，造成经济损失。传统DQN方法估计单一标量Q值存在局限性，需要更稳定且能处理不确定性的检测方法。

Method: 提出Quantile Regression Deep Q-Network (QR-DQN)方法，整合RoBERTa语义嵌入和手工特征词特征。与传统DQN不同，QR-DQN使用分位数回归建模回报分布，提高模型稳定性和泛化能力。使用来自PhishTank、OpenPhish、Cloudflare等源的105,000个URL数据集，采用80/20训练测试分割。

Result: QR-DQN框架测试准确率达99.86%，精确率99.75%，召回率99.96%，F1分数99.85%。相比仅使用特征词特征的标准DQN，混合QR-DQN将泛化差距从1.66%降至0.04%。五折交叉验证平均准确率99.90%，标准差0.04%。

Conclusion: 提出的混合QR-DQN方法能有效识别钓鱼威胁，适应不断演变的攻击策略，对未见数据具有良好的泛化能力，显著提高了钓鱼检测的鲁棒性和准确性。

Abstract: Phishing is a cybercrime in which individuals are deceived into revealing personal information, often resulting in financial loss. These attacks commonly occur through fraudulent messages, misleading advertisements, and compromised legitimate websites. This study proposes a Quantile Regression Deep Q-Network (QR-DQN) approach that integrates RoBERTa semantic embeddings with handcrafted lexical features to enhance phishing detection while accounting for uncertainties. Unlike traditional DQN methods that estimate single scalar Q-values, QR-DQN leverages quantile regression to model the distribution of returns, improving stability and generalization on unseen phishing data. A diverse dataset of 105,000 URLs was curated from PhishTank, OpenPhish, Cloudflare, and other sources, and the model was evaluated using an 80/20 train-test split. The QR-DQN framework achieved a test accuracy of 99.86%, precision of 99.75%, recall of 99.96%, and F1-score of 99.85%, demonstrating high effectiveness. Compared to standard DQN with lexical features, the hybrid QR-DQN with lexical and semantic features reduced the generalization gap from 1.66% to 0.04%, indicating significant improvement in robustness. Five-fold cross-validation confirmed model reliability, yielding a mean accuracy of 99.90% with a standard deviation of 0.04%. These results suggest that the proposed hybrid approach effectively identifies phishing threats, adapts to evolving attack strategies, and generalizes well to unseen data.

</details>


### [127] [Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise](https://arxiv.org/abs/2512.06926)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 本文通过系统实证分析，研究了输入序列长度和加性噪声对BiLSTM时间序列预测模型性能的影响，发现长序列会增加过拟合风险，噪声会降低预测精度，两者同时存在时模型稳定性下降最显著。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在时间序列预测中应用广泛，特别是BiLSTM架构能有效捕捉复杂时间依赖关系。然而，现有文献对这类模型的鲁棒性和泛化能力对输入数据特征的敏感性研究不足，特别是输入序列长度和加性噪声的影响尚未得到充分探索。

Method: 开发了一个模块化、可复现的预测流程，包含标准化预处理、序列生成、模型训练、验证和评估。在三个具有不同采样频率的真实世界数据集上进行控制实验，评估BiLSTM在不同输入条件下的性能表现。

Result: 研究得出三个关键发现：1) 较长的输入序列会显著增加过拟合和数据泄露风险，特别是在数据受限环境中；2) 加性噪声在不同采样频率下都会持续降低预测精度；3) 两个因素同时存在时，模型稳定性下降最为显著。虽然高观测频率的数据集表现出更强的鲁棒性，但在两个输入挑战同时存在时仍然脆弱。

Conclusion: 这项工作揭示了当前基于深度学习的预测流程的重要局限性，强调了数据感知设计策略的必要性。研究有助于深入理解深度学习模型在动态时间序列环境中的行为，并为开发更可靠、更可泛化的预测系统提供了实用见解。

Abstract: Deep learning (DL) models, a specialized class of multilayer neural networks, have become central to time-series forecasting in critical domains such as environmental monitoring and the Internet of Things (IoT). Among these, Bidirectional Long Short-Term Memory (BiLSTM) architectures are particularly effective in capturing complex temporal dependencies. However, the robustness and generalization of such models are highly sensitive to input data characteristics - an aspect that remains underexplored in existing literature. This study presents a systematic empirical analysis of two key data-centric factors: input sequence length and additive noise. To support this investigation, a modular and reproducible forecasting pipeline is developed, incorporating standardized preprocessing, sequence generation, model training, validation, and evaluation. Controlled experiments are conducted on three real-world datasets with varying sampling frequencies to assess BiLSTM performance under different input conditions. The results yield three key findings: (1) longer input sequences significantly increase the risk of overfitting and data leakage, particularly in data-constrained environments; (2) additive noise consistently degrades predictive accuracy across sampling frequencies; and (3) the simultaneous presence of both factors results in the most substantial decline in model stability. While datasets with higher observation frequencies exhibit greater robustness, they remain vulnerable when both input challenges are present. These findings highlight important limitations in current DL-based forecasting pipelines and underscore the need for data-aware design strategies. This work contributes to a deeper understanding of DL model behavior in dynamic time-series environments and provides practical insights for developing more reliable and generalizable forecasting systems.

</details>


### [128] [Adaptive Normalization Mamba with Multi Scale Trend Decomposition and Patch MoE Encoding](https://arxiv.org/abs/2512.06929)
*MinCheol Jeon*

Main category: cs.LG

TL;DR: AdaMamba是一种统一的时间序列预测架构，通过自适应归一化、多尺度趋势提取和上下文序列建模来解决非平稳性、多尺度时间模式和分布偏移等挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列预测面临非平稳性、多尺度时间模式和分布偏移等挑战，这些因素会降低模型的稳定性和准确性。传统Transformer模型在处理这些问题时存在局限性。

Method: AdaMamba包含自适应归一化块（多尺度卷积趋势提取和通道级重新校准）、上下文编码器（补丁嵌入、位置编码、Mamba增强的Transformer层和专家混合前馈模块）、轻量级预测头和去归一化机制。

Result: 实验评估表明，AdaMamba的自适应归一化和专家增强的上下文建模相结合，在稳定性和准确性方面比传统Transformer基线有持续改进。

Conclusion: AdaMamba通过其模块化设计有效缓解协变量偏移，增强预测可靠性，支持确定性预测并兼容概率扩展，在异构数据集上表现出色。

Abstract: Time series forecasting in real world environments faces significant challenges non stationarity, multi scale temporal patterns, and distributional shifts that degrade model stability and accuracy. This study propose AdaMamba, a unified forecasting architecture that integrates adaptive normalization, multi scale trend extraction, and contextual sequence modeling to address these challenges. AdaMamba begins with an Adaptive Normalization Block that removes non stationary components through multi scale convolutional trend extraction and channel wise recalibration, enabling consistent detrending and variance stabilization. The normalized sequence is then processed by a Context Encoder that combines patch wise embeddings, positional encoding, and a Mamba enhanced Transformer layer with a mixture of experts feed forward module, allowing efficient modeling of both long range dependencies and local temporal dynamics. A lightweight prediction head generates multi horizon forecasts, and a denormalization mechanism reconstructs outputs by reintegrating local trends to ensure robustness under varying temporal conditions. AdaMamba provides strong representational capacity with modular extensibility, supporting deterministic prediction and compatibility with probabilistic extensions. Its design effectively mitigates covariate shift and enhances predictive reliability across heterogeneous datasets. Experimental evaluations demonstrate that AdaMamba's combination of adaptive normalization and expert augmented contextual modeling yields consistent improvements in stability and accuracy over conventional Transformer based baselines.

</details>


### [129] [Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games](https://arxiv.org/abs/2512.06791)
*Vedansh Sharma*

Main category: cs.LG

TL;DR: 论文提出SGN（小增益纳什）条件，在自定义块加权几何中通过局部曲率和跨玩家Lipschitz耦合边界构造可验证的收缩证书，解决传统单调性条件在强耦合游戏中失效的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的博弈学习收敛性分析需要伪梯度在欧几里得几何中满足（强）单调性条件，但这一条件在具有强跨玩家耦合的简单博弈中经常失效，限制了现有方法的适用范围。

Method: 引入SGN（Small-Gain Nash）条件，在自定义块加权几何中将局部曲率和跨玩家Lipschitz耦合边界转化为可处理的收缩证书；构造加权块度量使伪梯度在满足这些边界的区域上变为强单调；分析连续流的指数收缩性，并推导投影欧拉和RK4离散化的显式步长边界。

Result: SGN成功认证了欧几里得单调性分析无法预测收敛的二次博弈的收敛性；扩展构造到镜像/Fisher几何用于马尔可夫博弈中的熵正则化策略梯度；建立了离线认证流程，可估计参数、优化块权重并返回包含度量、收缩率和安全步长的可计算收敛证书。

Conclusion: SGN框架为传统单调性条件失效的非单调博弈提供了结构化的收敛性认证方法，通过识别"时间尺度带"而非强制渐近时间尺度分离，实现了有限相对度量权重下的可证明收缩性。

Abstract: Classical convergence guarantees for gradient-based learning in games require the pseudo-gradient to be (strongly) monotone in Euclidean geometry as shown by rosen(1965), a condition that often fails even in simple games with strong cross-player couplings. We introduce Small-Gain Nash (SGN), a block small-gain condition in a custom block-weighted geometry. SGN converts local curvature and cross-player Lipschitz coupling bounds into a tractable certificate of contraction. It constructs a weighted block metric in which the pseudo-gradient becomes strongly monotone on any region where these bounds hold, even when it is non-monotone in the Euclidean sense. The continuous flow is exponentially contracting in this designed geometry, and projected Euler and RK4 discretizations converge under explicit step-size bounds derived from the SGN margin and a local Lipschitz constant. Our analysis reveals a certified ``timescale band'', a non-asymptotic, metric-based certificate that plays a TTUR-like role: rather than forcing asymptotic timescale separation via vanishing, unequal step sizes, SGN identifies a finite band of relative metric weights for which a single-step-size dynamics is provably contractive. We validate the framework on quadratic games where Euclidean monotonicity analysis fails to predict convergence, but SGN successfully certifies it, and extend the construction to mirror/Fisher geometries for entropy-regularized policy gradient in Markov games. The result is an offline certification pipeline that estimates curvature, coupling, and Lipschitz parameters on compact regions, optimizes block weights to enlarge the SGN margin, and returns a structural, computable convergence certificate consisting of a metric, contraction rate, and safe step-sizes for non-monotone games.

</details>


### [130] [Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies](https://arxiv.org/abs/2512.06932)
*Salma Albelali,Moataz Ahmed*

Main category: cs.LG

TL;DR: 该研究评估了数据泄露对LSTM时间序列预测模型性能的影响，发现验证设计方法显著影响泄露敏感性，其中10折交叉验证的RMSE增益最高可达20.5%，而2-way和3-way分割更为稳健。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中广泛使用的深度学习模型（特别是LSTM）经常受到数据泄露问题的影响，这种方法论缺陷会导致未来信息无意中影响训练过程，从而损害评估的完整性。研究旨在探究数据泄露对性能的影响，重点关注验证设计如何调节泄露敏感性。

Method: 研究评估了三种常用的验证技术（2-way分割、3-way分割和10折交叉验证），在泄露（分割前生成序列）和干净（分割后生成序列）两种条件下进行对比。使用RMSE增益来衡量泄露引起的相对RMSE增加，计算泄露设置与干净设置之间的百分比差异。同时研究了输入窗口大小和滞后步长对泄露敏感性的影响。

Result: 实证结果显示：10折交叉验证表现出最高的泄露敏感性，在较长滞后步长下RMSE增益可达20.5%；而2-way和3-way分割更为稳健，通常将RMSE增益控制在5%以下。输入窗口大小和滞后步长显著影响泄露敏感性：较小的窗口和较长的滞后步长会增加泄露风险，而较大的窗口有助于减少泄露。

Conclusion: 研究强调了构建配置感知、抗泄露的评估流程的重要性，以确保可靠的性能估计。验证设计的选择对时间序列预测模型的评估完整性具有关键影响，需要根据具体配置选择适当的验证方法来避免数据泄露问题。

Abstract: Deep learning models, particularly Long Short-Term Memory (LSTM) networks, are widely used in time series forecasting due to their ability to capture complex temporal dependencies. However, evaluation integrity is often compromised by data leakage, a methodological flaw in which input-output sequences are constructed before dataset partitioning, allowing future information to unintentionally influence training. This study investigates the impact of data leakage on performance, focusing on how validation design mediates leakage sensitivity. Three widely used validation techniques (2-way split, 3-way split, and 10-fold cross-validation) are evaluated under both leaky (pre-split sequence generation) and clean conditions, with the latter mitigating leakage risk by enforcing temporal separation during data splitting prior to sequence construction. The effect of leakage is assessed using RMSE Gain, which measures the relative increase in RMSE caused by leakage, computed as the percentage difference between leaky and clean setups. Empirical results show that 10-fold cross-validation exhibits RMSE Gain values of up to 20.5% at extended lag steps. In contrast, 2-way and 3-way splits demonstrate greater robustness, typically maintaining RMSE Gain below 5% across diverse configurations. Moreover, input window size and lag step significantly influence leakage sensitivity: smaller windows and longer lags increase the risk of leakage, whereas larger windows help reduce it. These findings underscore the need for configuration-aware, leakage-resistant evaluation pipelines to ensure reliable performance estimation.

</details>


### [131] [A Unifying Human-Centered AI Fairness Framework](https://arxiv.org/abs/2512.06944)
*Munshi Mahbubur Rahman,Shimei Pan,James R. Foulds*

Main category: cs.LG

TL;DR: 本文提出了一个统一的人本公平框架，系统性地覆盖八种不同的公平性指标，帮助利益相关者根据自身价值观和情境考虑选择公平性干预措施，并在四个真实数据集上展示了框架的应用。


<details>
  <summary>Details</summary>
Motivation: 人工智能在关键社会领域的应用日益增多，引发了关于公平性的担忧，特别是在种族、性别和社会经济地位等敏感属性方面的不平等对待。虽然已有大量关于确保AI公平性的工作，但在不同公平性概念之间以及预测准确性之间进行权衡仍然具有挑战性，这阻碍了公平AI系统的实际部署。

Method: 引入一个统一的人本公平框架，系统性地覆盖八种不同的公平性指标，这些指标通过结合个体公平性和群体公平性、边际内假设和交叉性假设、结果导向和机会平等视角而形成。该框架使用一致且易于理解的公式化表达，降低非专业人士的学习曲线，允许利益相关者为多个公平性目标分配权重，反映其优先级并促进多方妥协。

Result: 将该方法应用于四个真实数据集：UCI Adult人口普查数据集（收入预测）、COMPAS数据集（犯罪再犯率）、德国信贷数据集（信用风险评估）和MEPS数据集（医疗保健利用）。调整权重揭示了不同公平性指标之间的细微权衡。通过司法决策和医疗保健的案例研究，展示了该框架如何为公平AI系统的实际和价值敏感部署提供信息。

Conclusion: 该人本公平框架为利益相关者提供了一个系统化的工具，使其能够根据自身价值观和具体情境选择适当的公平性干预措施，促进公平AI系统的实际部署，并在不同公平性目标之间实现价值敏感的权衡。

Abstract: The increasing use of Artificial Intelligence (AI) in critical societal domains has amplified concerns about fairness, particularly regarding unequal treatment across sensitive attributes such as race, gender, and socioeconomic status. While there has been substantial work on ensuring AI fairness, navigating trade-offs between competing notions of fairness as well as predictive accuracy remains challenging, creating barriers to the practical deployment of fair AI systems. To address this, we introduce a unifying human-centered fairness framework that systematically covers eight distinct fairness metrics, formed by combining individual and group fairness, infra-marginal and intersectional assumptions, and outcome-based and equality-of-opportunity (EOO) perspectives. This structure allows stakeholders to align fairness interventions with their values and contextual considerations. The framework uses a consistent and easy-to-understand formulation for all metrics to reduce the learning curve for non-experts. Rather than privileging a single fairness notion, the framework enables stakeholders to assign weights across multiple fairness objectives, reflecting their priorities and facilitating multi-stakeholder compromises. We apply this approach to four real-world datasets: the UCI Adult census dataset for income prediction, the COMPAS dataset for criminal recidivism, the German Credit dataset for credit risk assessment, and the MEPS dataset for healthcare utilization. We show that adjusting weights reveals nuanced trade-offs between different fairness metrics. Finally, through case studies in judicial decision-making and healthcare, we demonstrate how the framework can inform practical and value-sensitive deployment of fair AI systems.

</details>


### [132] [Neural Factorization-based Bearing Fault Diagnosis](https://arxiv.org/abs/2512.06837)
*Zhenhao Li,Xu Cheng,Yi Zhou*

Main category: cs.LG

TL;DR: 提出基于神经分解的分类框架用于高铁轴承故障诊断，通过多模态潜在特征向量嵌入和神经分解融合，有效挖掘原始时序数据中的复杂故障特征


<details>
  <summary>Details</summary>
Motivation: 高铁轴承作为列车运行系统的核心部件，其健康状况直接关系到列车运行安全。传统诊断方法在复杂工况下诊断精度不足，需要更有效的故障诊断方法

Method: 提出神经分解分类框架，包含两个核心思想：1）将振动时序数据嵌入到多个模态潜在特征向量中以捕获多样化的故障相关模式；2）利用神经分解原理将这些向量融合为统一的振动表示。基于CP和Tucker融合方案分别实例化为CP-NFC和Tucker-NFC模型

Result: 实验结果表明，两种模型相比传统机器学习方法都取得了优越的诊断性能。比较分析为高铁轴承监测中选择有效的诊断策略提供了有价值的经验证据和实践指导

Conclusion: 提出的神经分解分类框架能够有效挖掘原始时序数据中的复杂潜在故障特征，为高铁轴承故障诊断提供了有效的解决方案，具有实际应用价值

Abstract: This paper studies the key problems of bearing fault diagnosis of high-speed train. As the core component of the train operation system, the health of bearings is directly related to the safety of train operation. The traditional diagnostic methods are facing the challenge of insufficient diagnostic accuracy under complex conditions. To solve these problems, we propose a novel Neural Factorization-based Classification (NFC) framework for bearing fault diagnosis. It is built on two core idea: 1) Embedding vibration time series into multiple mode-wise latent feature vectors to capture diverse fault-related patterns; 2) Leveraging neural factorization principles to fuse these vectors into a unified vibration representation. This design enables effective mining of complex latent fault characteristics from raw time-series data. We further instantiate the framework with two models CP-NFC and Tucker-NFC based on CP and Tucker fusion schemes, respectively. Experimental results show that both models achieve superior diagnostic performance compared with traditional machine learning methods. The comparative analysis provides valuable empirical evidence and practical guidance for selecting effective diagnostic strategies in high-speed train bearing monitoring.

</details>


### [133] [Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis](https://arxiv.org/abs/2512.06917)
*Clifford F,Devika Jay,Abhishek Sarkar,Satheesh K Perepu,Santhosh G S,Kaushik Dey,Balaraman Ravindran*

Main category: cs.LG

TL;DR: 提出一种新的可解释强化学习框架，通过轨迹级分析和状态重要性度量来评估智能体的长期行为，识别最优轨迹并提供反事实解释。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习在现实应用中的部署，确保智能体行为透明可信变得至关重要。现有可解释强化学习主要关注局部单步决策，缺乏对智能体长期行为的解释能力。

Method: 引入一个新颖框架，通过定义和聚合新的状态重要性度量来对完整轨迹进行排序。该度量结合了经典的Q值差异和"激进项"，后者捕捉智能体达到目标的亲和力，提供更细致的状态关键性衡量。通过从关键状态生成反事实推演来验证智能体选择路径的优越性。

Result: 在标准OpenAI Gym环境中验证，所提出的重要性度量在识别最优行为方面比经典方法更有效。能够成功从异构的智能体经验集合中识别最优轨迹，并通过反事实推演证明智能体选择路径的鲁棒优越性。

Conclusion: 该框架为解释智能体长期行为提供了有力工具，通过轨迹级分析和"为什么是这个而不是那个"的解释，向可信赖的自主系统迈出了重要一步。

Abstract: As Reinforcement Learning (RL) agents are increasingly deployed in real-world applications, ensuring their behavior is transparent and trustworthy is paramount. A key component of trust is explainability, yet much of the work in Explainable RL (XRL) focuses on local, single-step decisions. This paper addresses the critical need for explaining an agent's long-term behavior through trajectory-level analysis. We introduce a novel framework that ranks entire trajectories by defining and aggregating a new state-importance metric. This metric combines the classic Q-value difference with a "radical term" that captures the agent's affinity to reach its goal, providing a more nuanced measure of state criticality. We demonstrate that our method successfully identifies optimal trajectories from a heterogeneous collection of agent experiences. Furthermore, by generating counterfactual rollouts from critical states within these trajectories, we show that the agent's chosen path is robustly superior to alternatives, thereby providing a powerful "Why this, and not that?" explanation. Our experiments in standard OpenAI Gym environments validate that our proposed importance metric is more effective at identifying optimal behaviors compared to classic approaches, offering a significant step towards trustworthy autonomous systems.

</details>


### [134] [Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models](https://arxiv.org/abs/2512.06920)
*Alexandr Plashchinsky*

Main category: cs.LG

TL;DR: PGSRM是一种轻量级强化学习奖励框架，使用父模型参考输出嵌入与子模型生成输出的余弦相似度作为语义奖励，无需人工标注或额外模型训练。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法依赖二元正确性信号、人类偏好数据或训练奖励模型，这些方法需要大量人工标注或计算资源。PGSRM旨在提供一种更简单、更实用的替代方案。

Method: PGSRM使用父模型（如预训练大模型）的参考输出嵌入与子模型（待优化的较小模型）生成输出的余弦相似度作为密集语义奖励信号，无需额外训练奖励模型。

Result: 在五个语言任务上应用PGSRM，相比二元奖励基线，产生了更平滑的奖励改进和更稳定的PPO动态，表明基于嵌入的语义奖励是RLHF风格奖励建模的实用替代方案。

Conclusion: PGSRM为较小Transformer模型的父引导对齐提供了一种无需人工标注或额外模型训练的实用强化学习奖励框架，基于嵌入的语义奖励是RLHF奖励建模的有效替代方案。

Abstract: We introduce the Parent-Guided Semantic Reward Model (PGSRM), a lightweight reward framework for reinforcement learning (RL) of transformer language models. PGSRM replaces binary correctness signals, human preference data, and trained reward models with a simple signal: cosine similarity between a parent model's reference output embedding and a child model's generated output for the same input. This yields a dense, semantically meaningful reward with no human annotation or additional model training. We apply PGSRM on five language tasks and find that it produces smoother reward improvement and more stable PPO dynamics than a binary reward baseline, suggesting that embedding-based semantic rewards are a practical alternative to RLHF-style reward modeling for parent-guided alignment in smaller transformer models.

</details>


### [135] [Transferring Clinical Knowledge into ECGs Representation](https://arxiv.org/abs/2512.07021)
*Jose Geraldo Fernandes,Luiz Facury de Souza,Pedro Robles Dutenhefner,Gisele L. Pappa,Wagner Meira*

Main category: cs.LG

TL;DR: 提出一种三阶段训练范式，将多模态临床数据知识迁移到单模态ECG编码器中，提升心电图分类准确性和可解释性，仅需ECG信号即可推理。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在心电图分类中表现出高准确性，但其黑盒特性缺乏可解释性，阻碍了临床采用。需要建立更可信赖的ECG分类模型。

Method: 1. 三阶段训练范式：将多模态临床数据（实验室检查、生命体征、生物特征）知识迁移到单模态ECG编码器；2. 自监督联合嵌入预训练阶段：创建富含临床上下文信息的ECG表示；3. 训练模型从ECG嵌入预测相关实验室异常，作为间接解释模型输出的方式。

Result: 在MIMIC-IV-ECG数据集上评估，模型在多标签诊断分类中优于标准信号基线，显著缩小了与需要所有数据推理的完全多模态模型之间的性能差距。

Conclusion: 该方法为创建更准确、可信赖的ECG分类模型提供了实用有效的方法，通过将抽象预测转化为基于生理学的解释，为AI更安全地融入临床工作流程提供了有前景的路径。

Abstract: Deep learning models have shown high accuracy in classifying electrocardiograms (ECGs), but their black box nature hinders clinical adoption due to a lack of trust and interpretability. To address this, we propose a novel three-stage training paradigm that transfers knowledge from multimodal clinical data (laboratory exams, vitals, biometrics) into a powerful, yet unimodal, ECG encoder. We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enriched with contextual clinical information, while only requiring the ECG signal at inference time. Furthermore, as an indirect way to explain the model's output we train it to also predict associated laboratory abnormalities directly from the ECG embedding. Evaluated on the MIMIC-IV-ECG dataset, our model outperforms a standard signal-only baseline in multi-label diagnosis classification and successfully bridges a substantial portion of the performance gap to a fully multimodal model that requires all data at inference. Our work demonstrates a practical and effective method for creating more accurate and trustworthy ECG classification models. By converting abstract predictions into physiologically grounded \emph{explanations}, our approach offers a promising path toward the safer integration of AI into clinical workflows.

</details>


### [136] [Self-Supervised Learning on Molecular Graphs: A Systematic Investigation of Masking Design](https://arxiv.org/abs/2512.07064)
*Jiannan Yang,Veronika Thost,Tengfei Ma*

Main category: cs.LG

TL;DR: 该研究将分子图的自监督学习预训练-微调流程统一到概率框架中，系统评估了掩码策略的三个核心设计维度，发现对于常见节点级预测任务，复杂掩码分布相比均匀采样并无优势，而预测目标选择和编码器架构的协同更为关键。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在分子表示学习中占据核心地位，但许多基于掩码的预训练方法创新缺乏原则性评估，难以确定哪些设计选择真正有效。研究旨在通过统一框架透明比较和深入理解掩码策略。

Method: 将整个预训练-微调流程统一到概率框架中，在严格控制的设置下系统研究三个核心设计维度：掩码分布、预测目标和编码器架构。使用信息论度量评估预训练信号的信息量，并将其与经验基准的下游性能联系起来。

Result: 研究发现：1) 对于常见节点级预测任务，复杂掩码分布相比均匀采样没有一致优势；2) 预测目标选择及其与编码器架构的协同更为关键；3) 转向语义更丰富的预测目标能带来显著的下游性能提升，特别是与表达能力强的图Transformer编码器配对时。

Conclusion: 研究为开发更有效的分子图自监督学习方法提供了实用指导，强调应更关注预测目标选择和编码器架构的协同，而非过度复杂的掩码策略。

Abstract: Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs.

</details>


### [137] [Procrustean Bed for AI-Driven Retrosynthesis: A Unified Framework for Reproducible Evaluation](https://arxiv.org/abs/2512.07079)
*Anton Morgunov,Victor S. Batista*

Main category: cs.LG

TL;DR: RetroCast是一个统一的评估套件，用于标准化计算机辅助合成规划模型的评估，解决现有评估方法缺乏标准化和过度关注拓扑完成度而忽视化学有效性的问题。


<details>
  <summary>Details</summary>
Motivation: 计算机辅助合成规划领域缺乏标准化的评估基础设施，现有指标过度强调拓扑完成度而忽视化学有效性，导致模型性能评估不准确且难以比较。

Method: 开发RetroCast统一评估套件，将异构模型输出标准化为统一模式；建立可重复的基准测试流程，包括分层抽样和自举置信区间；创建SynthArena交互式平台用于定性路径检查。

Result: 评估发现"可解性"（库存终止率）与路径质量存在差异：高可解性分数常掩盖化学无效性，且与实验真实结果的再现性不相关；识别出"复杂性悬崖"现象，搜索方法在重建长程合成计划时性能急剧下降。

Conclusion: RetroCast为计算机辅助合成规划领域提供了透明、可重复的评估框架，揭示了现有评估指标的局限性，并发布了完整的框架、基准定义和标准化预测数据库以支持该领域的发展。

Abstract: Progress in computer-aided synthesis planning (CASP) is obscured by the lack of standardized evaluation infrastructure and the reliance on metrics that prioritize topological completion over chemical validity. We introduce RetroCast, a unified evaluation suite that standardizes heterogeneous model outputs into a common schema to enable statistically rigorous, apples-to-apples comparison. The framework includes a reproducible benchmarking pipeline with stratified sampling and bootstrapped confidence intervals, accompanied by SynthArena, an interactive platform for qualitative route inspection. We utilize this infrastructure to evaluate leading search-based and sequence-based algorithms on a new suite of standardized benchmarks. Our analysis reveals a divergence between "solvability" (stock-termination rate) and route quality; high solvability scores often mask chemical invalidity or fail to correlate with the reproduction of experimental ground truths. Furthermore, we identify a "complexity cliff" in which search-based methods, despite high solvability rates, exhibit a sharp performance decay in reconstructing long-range synthetic plans compared to sequence-based approaches. We release the full framework, benchmark definitions, and a standardized database of model predictions to support transparent and reproducible development in the field.

</details>


### [138] [FOAM: Blocked State Folding for Memory-Efficient LLM Training](https://arxiv.org/abs/2512.07112)
*Ziqing Wen,Jiahuan Wang,Ping Luo,Dongsheng Li,Tao Sun*

Main category: cs.LG

TL;DR: FOAM是一种通过计算块级梯度均值压缩优化器状态的内存高效优化器，在保持Adam收敛性能的同时减少约50%总训练内存和90%优化器状态内存开销。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练面临显著的内存瓶颈，特别是使用Adam等内存密集型优化器时。现有内存高效方法存在计算开销大、需要额外投影内存或性能下降等问题。

Method: 提出FOAM方法，通过计算块级梯度均值压缩优化器状态，并引入残差校正来恢复丢失的信息。该方法与现有内存高效优化器兼容。

Result: 理论上FOAM在标准非凸优化设置下达到与原始Adam相当的收敛率。实验上减少约50%总训练内存，消除90%优化器状态内存开销，并加速收敛。

Conclusion: FOAM是一种高效的内存优化器压缩方法，在保持性能的同时显著减少内存需求，可与现有内存高效优化器结合使用，性能匹配或超越现有基线。

Abstract: Large language models (LLMs) have demonstrated remarkable performance due to their large parameter counts and extensive training data. However, their scale leads to significant memory bottlenecks during training, especially when using memory-intensive optimizers like Adam. Existing memory-efficient approaches often rely on techniques such as singular value decomposition (SVD), projections, or weight freezing, which can introduce substantial computational overhead, require additional memory for projections, or degrade model performance. In this paper, we propose Folded Optimizer with Approximate Moment (FOAM), a method that compresses optimizer states by computing block-wise gradient means and incorporates a residual correction to recover lost information. Theoretically, FOAM achieves convergence rates equivalent to vanilla Adam under standard non-convex optimization settings. Empirically, FOAM reduces total training memory by approximately 50\%, eliminates up to 90\% of optimizer state memory overhead, and accelerates convergence. Furthermore, FOAM is compatible with other memory-efficient optimizers, delivering performance and throughput that match or surpass both full-rank and existing memory-efficient baselines.

</details>


### [139] [FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers](https://arxiv.org/abs/2512.07150)
*Jonghyun Park,Jong Chul Ye*

Main category: cs.LG

TL;DR: FlowLPS：一种基于预训练流模型解决逆问题的新框架，通过Langevin近端采样策略，在FFHQ和DIV2K数据集上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于深度生成模型解决逆问题的方法在应用于流模型时存在收敛问题或流形偏差，需要改进

Method: 提出FlowLPS框架，结合Langevin动力学进行流形一致探索和近端优化进行精确模式搜索

Result: 在FFHQ和DIV2K数据集上的多个逆任务中，实现了重建保真度和感知质量的优越平衡，超越了现有最先进的逆问题求解器

Conclusion: FlowLPS是一种有效的训练免费框架，能够解决预训练流模型在逆问题中的收敛和流形偏差问题

Abstract: Deep generative models have become powerful priors for solving inverse problems, and various training-free methods have been developed. However, when applied to latent flow models, existing methods often fail to converge to the posterior mode or suffer from manifold deviation within latent spaces. To mitigate this, here we introduce a novel training-free framework, FlowLPS, that solves inverse problems with pretrained flow models via a Langevin Proximal Sampling (LPS) strategy. Our method integrates Langevin dynamics for manifold-consistent exploration with proximal optimization for precise mode seeking, achieving a superior balance between reconstruction fidelity and perceptual quality across multiple inverse tasks on FFHQ and DIV2K, outperforming state of the art inverse solvers.

</details>


### [140] [Prediction with Expert Advice under Local Differential Privacy](https://arxiv.org/abs/2512.06971)
*Ben Jacobsen,Kassem Fawaz*

Main category: cs.LG

TL;DR: 该论文研究在本地差分隐私约束下的专家建议预测问题，提出了两种改进算法：RW-AdaBatch利用LDP诱导的有限切换行为实现隐私增强，RW-Meta能够私有地选择非平凡学习算法作为专家，并在COVID-19医院数据预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究在本地差分隐私约束下的经典专家建议预测问题，旨在开发既能保护隐私又能保持预测性能的算法。现有方法主要考虑数据无关的专家，而实际应用中专家可能是复杂的学习算法，需要新的方法来处理这种情况。

Method: 首先证明经典算法自然满足LDP，然后设计两种新算法：1) RW-AdaBatch：利用LDP诱导的有限切换行为，提供一种新型隐私增强机制，类似于离线学习中的洗牌模型；2) RW-Meta：开发了一种私有选择专家的一般方法，这些专家本身是非平凡的学习算法，在LDP背景下不增加额外隐私成本。

Result: RW-Meta在COVID-19疫情期间医院报告数据的真实世界评估中表现出色，在预测每周报告COVID患者密度最高的医院任务上，比经典基线和最先进的中心差分隐私算法性能提升1.5-3倍。同时推导了与专家间独立性程度成反比的正式遗憾界。

Conclusion: 该研究成功开发了在本地差分隐私约束下改进专家建议预测的新算法，RW-AdaBatch通过随机游走理论实现隐私增强而不损失效用，RW-Meta能够有效选择复杂学习算法作为专家，在真实医疗数据预测任务中显著优于现有方法。

Abstract: We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing on the theory of random walks, we prove that this improvement carries essentially no utility cost. For RW-Meta, we develop a general method for privately selecting between experts that are themselves non-trivial learning algorithms, and we show that in the context of LDP this carries no extra privacy cost. In contrast, prior work has only considered data-independent experts. We also derive formal regret bounds that scale inversely with the degree of independence between experts. Our analysis is supplemented by evaluation on real-world data reported by hospitals during the COVID-19 pandemic; RW-Meta outperforms both the classical baseline and a state-of-the-art \textit{central} DP algorithm by 1.5-3$\times$ on the task of predicting which hospital will report the highest density of COVID patients each week.

</details>


### [141] [Geometric Prior-Guided Federated Prompt Calibration](https://arxiv.org/abs/2512.07208)
*Fei Luo,Ziwei Zhao,Mingxuan Wang,Duoyang Li,Zhe Qian,Jiayi Tuo,Chenyue Zhou,Yanbiao Ma*

Main category: cs.LG

TL;DR: GGTPC提出了一种几何引导的文本提示校准框架，通过全局几何先验纠正联邦提示学习中数据异构导致的本地训练偏差，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦提示学习(FPL)虽然提供了参数高效的协作训练方案，但其性能受到数据异构性的严重影响，导致本地训练的提示产生偏差。现有方法主要关注聚合或正则化，未能解决本地训练偏差的根本原因。

Method: 提出几何引导文本提示校准(GGTPC)框架，通过隐私保护方式在服务器端重构全局数据分布的几何先验（协方差矩阵表示），客户端使用新颖的几何先验校准层(GPCL)在训练过程中将本地特征分布与全局先验对齐。

Result: 在标签偏斜的CIFAR-100数据集上(β=0.1)，GGTPC比最先进方法提升2.15%；在极端偏斜(β=0.01)下，比基线提升9.17%；在域偏斜的Office-Home数据集上作为即插即用模块，将FedAvg性能提升4.60%。

Conclusion: GGTPC通过纠正本地训练偏差有效缓解数据异构问题，作为一个通用模块能够增强各种联邦学习算法，证明了全局几何先验在解决联邦提示学习偏差问题中的有效性。

Abstract: Federated Prompt Learning (FPL) offers a parameter-efficient solution for collaboratively training large models, but its performance is severely hindered by data heterogeneity, which causes locally trained prompts to become biased. Existing methods, focusing on aggregation or regularization, fail to address this root cause of local training bias. To this end, we propose Geometry-Guided Text Prompt Calibration (GGTPC), a novel framework that directly corrects this bias by providing clients with a global geometric prior. This prior, representing the shape of the global data distribution derived from the covariance matrix, is reconstructed on the server in a privacy-preserving manner. Clients then use a novel Geometry-Prior Calibration Layer (GPCL) to align their local feature distributions with this global prior during training. Extensive experiments show GGTPC's effectiveness. On the label-skewed CIFAR-100 dataset ($β$=0.1), it outperforms the state-of-the-art by 2.15\%. Under extreme skew ($β$=0.01), it improves upon the baseline by 9.17\%. Furthermore, as a plug-and-play module on the domain-skewed Office-Home dataset, it boosts FedAvg's performance by 4.60\%. These results demonstrate that GGTPC effectively mitigates data heterogeneity by correcting the fundamental local training bias, serving as a versatile module to enhance various FL algorithms.

</details>


### [142] [LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding](https://arxiv.org/abs/2512.06982)
*Yu Yu,Qian Xie,Nairen Cao,Li Jin*

Main category: cs.LG

TL;DR: 提出基于大语言模型的神经架构搜索方法，用于设计多源信息强化学习的状态编码器，相比传统方法更高效


<details>
  <summary>Details</summary>
Motivation: 多源信息强化学习（如传感器测量、时序信号、图像观察、文本指令）的状态编码器设计缺乏系统方法，通常需要手动设计，现有神经架构搜索方法忽略了模块中间输出的有用信息

Method: 将多源状态编码器设计形式化为复合神经架构搜索问题，提出基于大语言模型的NAS流程，利用语言模型先验和中间输出信号指导搜索，提高样本效率

Result: 在混合自主交通控制任务中，该方法比传统NAS基线和基于大语言模型的GENIUS框架发现性能更高的架构，且需要更少的候选评估

Conclusion: 基于大语言模型的神经架构搜索方法能够有效设计多源强化学习的状态编码器，通过利用中间输出信号和语言模型先验提高搜索效率

Abstract: Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate outputs of these modules -- such as their representation quality -- limiting sample efficiency in multi-source RL settings. To address this, we propose an LLM-driven NAS pipeline that leverages language-model priors and intermediate-output signals to guide sample-efficient search for high-performing composite state encoders. On a mixed-autonomy traffic control task, our approach discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines and the LLM-based GENIUS framework.

</details>


### [143] [OXtal: An All-Atom Diffusion Model for Organic Crystal Structure Prediction](https://arxiv.org/abs/2512.06987)
*Emily Jin,Andrei Cristian Nica,Mikhail Galkin,Jarrid Rector-Brooks,Kin Long Kelvin Lee,Santiago Miret,Frances H. Arnold,Michael Bronstein,Avishek Joey Bose,Alexander Tong,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: OXtal是一个100M参数的全原子扩散模型，直接从2D化学图预测3D分子晶体结构，通过数据增强和晶格无关训练方案实现高效扩展，在600K实验验证晶体结构数据集上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 准确预测分子晶体结构是计算化学中长期存在的开放挑战，对制药和有机半导体等领域至关重要，因为晶体堆积直接影响有机固体的物理化学性质。

Method: 提出OXtal全原子扩散模型，放弃显式等变架构，采用数据增强策略；引入结晶启发的晶格无关训练方案S^4，避免显式晶格参数化，实现全原子分辨率下的可扩展架构选择。

Result: 在600K实验验证晶体结构数据集上，OXtal相比先前的从头算机器学习CSP方法获得数量级改进，同时比传统量子化学方法便宜数量级；恢复实验结构的构象RMSD<0.5Å，达到超过80%的堆积相似率。

Conclusion: OXtal能够有效建模分子结晶的热力学和动力学规律，为晶体结构预测提供了高效准确的解决方案。

Abstract: Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\text{RMSD}_1<0.5$ Å and attains over 80\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.

</details>


### [144] [Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach](https://arxiv.org/abs/2512.07332)
*Zhengquan Luo,Guy Tadmor,Or Amar,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: RicciKGE提出了一种动态几何适应的知识图谱嵌入方法，通过将嵌入损失梯度与局部曲率耦合在扩展的Ricci流中，使实体嵌入与底层流形几何共同演化，从而适应知识图谱中变化剧烈的局部曲率。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱嵌入方法将所有实体放置在单一均匀流形上（欧几里得、球面、双曲或其乘积/多曲率变体），但预定义的均匀流形无法适应真实世界图谱中局部区域变化剧烈的曲率。这种几何先验与知识图谱局部曲率的不匹配会扭曲实体间距离，损害嵌入的表达能力。

Method: 提出RicciKGE方法，将KGE损失梯度与局部曲率耦合在扩展的Ricci流中，使实体嵌入与底层流形几何动态共同演化，实现相互适应。理论上证明了当耦合系数有界且适当选择时：i)所有边曲率指数衰减，流形趋向欧几里得平坦；ii)KGE距离严格收敛到全局最优，表明几何平坦化与嵌入优化相互促进。

Result: 在链接预测和节点分类基准测试中，RicciKGE在适应异构知识图谱结构方面表现出有效性，实验改进证明了该方法优于现有方法。

Conclusion: RicciKGE通过动态几何适应机制解决了现有知识图谱嵌入方法中预定义均匀流形与真实图谱局部曲率不匹配的问题，实现了嵌入优化与流形几何的协同演化，为处理异构知识图谱结构提供了有效解决方案。

Abstract: Knowledge graph embedding (KGE) relies on the geometry of the embedding space to encode semantic and structural relations. Existing methods place all entities on one homogeneous manifold, Euclidean, spherical, hyperbolic, or their product/multi-curvature variants, to model linear, symmetric, or hierarchical patterns. Yet a predefined, homogeneous manifold cannot accommodate the sharply varying curvature that real-world graphs exhibit across local regions. Since this geometry is imposed a priori, any mismatch with the knowledge graph's local curvatures will distort distances between entities and hurt the expressiveness of the resulting KGE. To rectify this, we propose RicciKGE to have the KGE loss gradient coupled with local curvatures in an extended Ricci flow such that entity embeddings co-evolve dynamically with the underlying manifold geometry towards mutual adaptation. Theoretically, when the coupling coefficient is bounded and properly selected, we rigorously prove that i) all the edge-wise curvatures decay exponentially, meaning that the manifold is driven toward the Euclidean flatness; and ii) the KGE distances strictly converge to a global optimum, which indicates that geometric flattening and embedding optimization are promoting each other. Experimental improvements on link prediction and node classification benchmarks demonstrate RicciKGE's effectiveness in adapting to heterogeneous knowledge graph structures.

</details>


### [145] [Toward Reliable Machine Unlearning: Theory, Algorithms, and Evaluation](https://arxiv.org/abs/2512.06993)
*Ali Ebrahimpour-Boroojeny*

Main category: cs.LG

TL;DR: 该论文提出了两种新的机器学习遗忘方法：AMUN用于样本遗忘，TRW用于类别遗忘，均通过模拟重新训练模型的行为来超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘方法在保护隐私方面存在不足，无法有效模拟重新训练模型的行为，导致遗忘后的模型仍可能泄露敏感信息。

Method: 1. AMUN：通过对抗样本微调降低模型对遗忘样本的置信度；2. FastClip：层谱范数裁剪方法控制Lipschitz常数；3. TRW：基于类间相似性估计，调整目标分布以模拟重新训练模型。

Result: AMUN在图像分类任务中超越了现有SOTA方法（基于MIA分数）；TRW在多个基准测试中匹配或超越了现有遗忘方法；FastClip实现了可扩展的平滑模型训练。

Conclusion: 通过模拟重新训练模型的行为，AMUN和TRW方法在机器遗忘任务中取得了显著改进，为隐私保护提供了更有效的解决方案。

Abstract: We propose new methodologies for both unlearning random set of samples and class unlearning and show that they outperform existing methods. The main driver of our unlearning methods is the similarity of predictions to a retrained model on both the forget and remain samples. We introduce Adversarial Machine UNlearning (AMUN), which surpasses prior state-of-the-art methods for image classification based on SOTA MIA scores. AMUN lowers the model's confidence on forget samples by fine-tuning on their corresponding adversarial examples. Through theoretical analysis, we identify factors governing AMUN's performance, including smoothness. To facilitate training of smooth models with a controlled Lipschitz constant, we propose FastClip, a scalable method that performs layer-wise spectral-norm clipping of affine layers. In a separate study, we show that increased smoothness naturally improves adversarial example transfer, thereby supporting the second factor above.
  Following the same principles for class unlearning, we show that existing methods fail in replicating a retrained model's behavior by introducing a nearest-neighbor membership inference attack (MIA-NN) that uses the probabilities assigned to neighboring classes to detect unlearned samples and demonstrate the vulnerability of such methods. We then propose a fine-tuning objective that mitigates this leakage by approximating, for forget-class inputs, the distribution over remaining classes that a model retrained from scratch would produce. To construct this approximation, we estimate inter-class similarity and tilt the target model's distribution accordingly. The resulting Tilted ReWeighting(TRW) distribution serves as the desired target during fine-tuning. Across multiple benchmarks, TRW matches or surpasses existing unlearning methods on prior metrics.

</details>


### [146] [MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis](https://arxiv.org/abs/2512.07430)
*Yangle Li,Danli Luo,Haifeng Hu*

Main category: cs.LG

TL;DR: 提出了一种用于多模态情感分析领域泛化的新框架MIDG，通过混合不变专家模型提取领域不变特征，并设计跨模态适配器增强多模态表示语义丰富度。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析领域泛化方法在提取不变特征时忽略了模态间的协同作用，无法准确捕捉多模态数据的丰富语义信息；同时现有知识注入技术存在跨模态知识碎片化问题，忽略了单模态边界之外的特定表示。

Method: 1. 混合不变专家模型：提取领域不变特征，增强模型学习模态间协同关系的能力；2. 跨模态适配器：通过跨模态知识注入增强多模态表示的语义丰富度。

Result: 在三个数据集上进行的广泛领域实验表明，提出的MIDG框架取得了优越的性能表现。

Conclusion: 提出的MIDG框架通过混合不变专家模型和跨模态适配器，有效解决了多模态情感分析领域泛化中模态协同作用不足和跨模态知识碎片化的问题，提升了模型性能。

Abstract: Existing methods in domain generalization for Multimodal Sentiment Analysis (MSA) often overlook inter-modal synergies during invariant features extraction, which prevents the accurate capture of the rich semantic information within multimodal data. Additionally, while knowledge injection techniques have been explored in MSA, they often suffer from fragmented cross-modal knowledge, overlooking specific representations that exist beyond the confines of unimodal. To address these limitations, we propose a novel MSA framework designed for domain generalization. Firstly, the framework incorporates a Mixture of Invariant Experts model to extract domain-invariant features, thereby enhancing the model's capacity to learn synergistic relationships between modalities. Secondly, we design a Cross-Modal Adapter to augment the semantic richness of multimodal representations through cross-modal knowledge injection. Extensive domain experiments conducted on three datasets demonstrate that the proposed MIDG achieves superior performance.

</details>


### [147] [Block Sparse Flash Attention](https://arxiv.org/abs/2512.07011)
*Daniel Ohayon,Itay Lamprecht,Itay Hubara,Israel Cohen,Daniel Soudry,Noam Elata*

Main category: cs.LG

TL;DR: BSFA是一种无需训练的注意力加速方法，通过计算精确的查询-键相似度来选择最重要的值块，跳过约50%的计算和内存传输，在保持99%以上基线准确率的同时实现1.10-1.24倍加速。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型需要长上下文处理，但注意力机制的二次复杂度造成严重计算瓶颈，需要高效的加速方法。

Method: BSFA通过计算精确的查询-键相似度，选择每个查询的top-k最重要值块，通过比较每块最大分数与校准阈值来跳过约50%的计算和内存传输。该方法无需训练，只需在小数据集上进行一次性阈值校准。

Result: 在Llama-3.1-8B上，BSFA在真实世界推理基准上实现最高1.10倍加速，在"大海捞针"检索任务中实现最高1.24倍加速，同时保持99%以上基线准确率，某些配置甚至通过关注最相关内容提高了准确性。

Conclusion: BSFA是一种有效的训练无关注意力加速方法，可作为FlashAttention的即插即用替代方案，显著优于现有稀疏注意力方法。

Abstract: Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention

</details>


### [148] [TRACE: A Generalizable Drift Detector for Streaming Data-Driven Optimization](https://arxiv.org/abs/2512.07082)
*Yuan-Ting Zhong,Ting Huang,Xiaolin Xiao,Yue-Jiao Gong*

Main category: cs.LG

TL;DR: TRACE是一种可迁移的概念漂移估计器，用于检测流数据中的分布变化，具有跨数据集泛化能力，并能集成到流优化器中实现自适应优化。


<details>
  <summary>Details</summary>
Motivation: 现有流数据驱动优化方法通常假设固定的漂移间隔和完全环境可观测性，这些限制性假设限制了它们在多样化动态环境中的适应性。需要一种能够有效检测不同时间尺度流数据分布变化的方法。

Method: TRACE采用原则化的标记化策略从数据流中提取统计特征，并使用基于注意力的序列学习来建模漂移模式，从而实现对未见数据集的准确检测，并展示学习漂移模式的可迁移性。

Result: 在多样化基准测试上的综合实验结果表明，该方法在流数据驱动优化场景中具有优越的泛化能力、鲁棒性和有效性。

Conclusion: TRACE作为一种可迁移的概念漂移估计器，能够有效检测流数据中的分布变化，其即插即用特性使其能够集成到流优化器中，促进未知漂移下的自适应优化。

Abstract: Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively detects distributional changes in streaming data with varying time scales. TRACE leverages a principled tokenization strategy to extract statistical features from data streams and models drift patterns using attention-based sequence learning, enabling accurate detection on unseen datasets and highlighting the transferability of learned drift patterns. Further, we showcase TRACE's plug-and-play nature by integrating it into a streaming optimizer, facilitating adaptive optimization under unknown drifts. Comprehensive experimental results on diverse benchmarks demonstrate the superior generalization, robustness, and effectiveness of our approach in SDDO scenarios.

</details>


### [149] [Time Series Foundation Models for Process Model Forecasting](https://arxiv.org/abs/2512.07624)
*Yongbo Yu,Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

TL;DR: 本文研究了时间序列基础模型（TSFMs）在过程模型预测（PMF）中的应用，发现预训练的时间序列基础模型在零样本设置下就能超越传统方法和专门训练的模型，微调带来的改进有限，表明TSFMs在过程相关时间序列上具有良好的泛化能力和数据效率。


<details>
  <summary>Details</summary>
Motivation: 过程模型预测（PMF）旨在预测业务流程控制流结构随时间的变化，但现有机器学习方法由于直接跟随关系时间序列的稀疏性和异质性，相比统计基线只有有限的改进。本文探索使用预训练的时间序列基础模型作为PMF的替代方案。

Method: 使用真实事件日志中提取的直接跟随关系时间序列，比较了时间序列基础模型的零样本使用（无需额外训练）与在PMF特定数据上微调的变体。与传统方法和专门训练的模型进行对比，评估了MAE和RMSE等预测误差指标。

Result: 时间序列基础模型通常比在相同日志上从头训练的传统和专门模型获得更低的预测误差，表明从非过程领域有效转移了时间结构知识。虽然微调可以进一步提高准确性，但改进通常很小，在较小或更复杂的数据集上可能消失，因此零样本使用仍然是强大的默认选择。

Conclusion: 本研究突出了时间序列基础模型在过程相关时间序列上的泛化能力和数据效率，据我们所知，这是首次对时间基础模型在过程模型预测中的系统评估，为零样本使用预训练模型提供了实证支持。

Abstract: Process Model Forecasting (PMF) aims to predict how the control-flow structure of a process evolves over time by modeling the temporal dynamics of directly-follows (DF) relations, complementing predictive process monitoring that focuses on single-case prefixes. Prior benchmarks show that machine learning and deep learning models provide only modest gains over statistical baselines, mainly due to the sparsity and heterogeneity of the DF time series. We investigate Time Series Foundation Models (TSFMs), large pre-trained models for generic time series, as an alternative for PMF. Using DF time series derived from real-life event logs, we compare zero-shot use of TSFMs, without additional training, with fine-tuned variants adapted on PMF-specific data. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than traditional and specialized models trained from scratch on the same logs, indicating effective transfer of temporal structure from non-process domains. While fine-tuning can further improve accuracy, the gains are often small and may disappear on smaller or more complex datasets, so zero-shot use remains a strong default. Our study highlights the generalization capability and data efficiency of TSFMs for process-related time series and, to the best of our knowledge, provides the first systematic evaluation of temporal foundation models for PMF.

</details>


### [150] [A Mathematical Theory of Top-$k$ Sparse Attention via Total Variation Distance](https://arxiv.org/abs/2512.07647)
*Georgios Tzachristas,Lei Deng,Ioannis Tzachristas,Gong Zhang,Renhai Chen*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的数学框架，用于认证Top-k注意力截断，量化分布和输出层面的近似误差，推导出确定性误差界限，并给出了高斯评分模型下的闭式解和渐近规则。


<details>
  <summary>Details</summary>
Motivation: 注意力机制中的Top-k截断虽然能提高计算效率，但缺乏严格的误差界限分析。现有方法通常使用通用不等式，无法提供针对Top-k截断的精确误差控制，需要建立专门的数学框架来量化截断带来的近似误差。

Method: 1. 建立统一的数学框架，证明总变差距离等于丢弃的softmax尾部质量，并满足TV(P,ˆP)=1-e^{-KL(ˆP∥P)}；2. 推导非渐近确定性界限（从单一边界间隙到多间隙和分块变体）；3. 使用精确的头尾分解证明输出误差可分解为τ∥μ_tail-μ_head∥₂；4. 在高斯评分模型下推导闭式尾部质量和最小k_ε的渐近规则。

Result: 1. 获得了Top-k特定的尖锐误差界限，替代了通用不等式；2. 推导了基于排序logits的TV(P,ˆP)控制界限；3. 证明了输出误差可分解为头尾分布距离的乘积；4. 在高斯模型下得到k_ε/n≈Φ_c(σ+Φ^{-1}(ε))的渐近规则；5. 实验验证了k_ε/n的预测缩放，在bert-base-uncased和合成logits上显示认证Top-k可平均减少2-4倍的评分键数。

Conclusion: 该研究为注意力机制的Top-k截断提供了严格的数学基础和认证框架，能够精确控制近似误差，在保持计算效率的同时确保模型性能，为高效注意力机制的开发提供了理论保证。

Abstract: We develop a unified mathematical framework for certified Top-$k$ attention truncation that quantifies approximation error at both the distribution and output levels. For a single attention distribution $P$ and its Top-$k$ truncation $\hat P$, we show that the total-variation distance coincides with the discarded softmax tail mass and satisfies $\mathrm{TV}(P,\hat P)=1-e^{-\mathrm{KL}(\hat P\Vert P)}$, yielding sharp Top-$k$-specific bounds in place of generic inequalities. From this we derive non-asymptotic deterministic bounds -- from a single boundary gap through multi-gap and blockwise variants -- that control $\mathrm{TV}(P,\hat P)$ using only the ordered logits. Using an exact head-tail decomposition, we prove that the output error factorizes as $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2=τ\|μ_{\mathrm{tail}}-μ_{\mathrm{head}}\|_2$ with $τ=\mathrm{TV}(P,\hat P)$, yielding a new head-tail diameter bound $\|\mathrm{Attn}(q,K,V)-\mathrm{Attn}_k(q,K,V)\|_2\leτ\,\mathrm{diam}_{H,T}$ and refinements linking the error to $\mathrm{Var}_P(V)$. Under an i.i.d. Gaussian score model $s_i\sim\mathcal N(μ,σ^2)$ we derive closed-form tail masses and an asymptotic rule for the minimal $k_\varepsilon$ ensuring $\mathrm{TV}(P,\hat P)\le\varepsilon$, namely $k_\varepsilon/n\approxΦ_c(σ+Φ^{-1}(\varepsilon))$. Experiments on bert-base-uncased and synthetic logits confirm the predicted scaling of $k_\varepsilon/n$ and show that certified Top-$k$ can reduce scored keys by 2-4$\times$ on average while meeting the prescribed total-variation budget.

</details>


### [151] [In-Context and Few-Shots Learning for Forecasting Time Series Data based on Large Language Models](https://arxiv.org/abs/2512.07705)
*Saroj Gopali,Bipin Chhetri,Deepika Giri,Sima Siami-Namini,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 该研究比较了时间序列预测中传统深度学习模型（LSTM、TCN）与预训练基础模型（TimesFM、LLMs）的性能，发现TimesFM在RMSE和推理时间上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着预训练基础模型（如LLMs和专门的时间序列基础模型TimesFM）的发展，需要研究这些模型是否能在时间序列分析和预测方面超越现有的ARIMA、Transformer、LSTM和TCN等传统方法。

Method: 研究探索了LLMs的上下文学习、零样本学习和少样本学习方法，使用OpenAI o4-mini和Gemini 2.5 Flash Lite进行时间序列预测，同时测试了Google的TimesFM基础模型，并与TCN和LSTM深度学习模型进行对比。

Result: TimesFM在整体性能上表现最佳，具有最低的RMSE值（0.3023）和竞争力的推理时间（266秒）。OpenAI的o4-mini在零样本学习方面也表现出良好性能。

Conclusion: 预训练时间序列基础模型是实时预测的有前景方向，能够以最小的模型适应实现准确且可扩展的部署。

Abstract: Existing data-driven approaches in modeling and predicting time series data include ARIMA (Autoregressive Integrated Moving Average), Transformer-based models, LSTM (Long Short-Term Memory) and TCN (Temporal Convolutional Network). These approaches, and in particular deep learning-based models such as LSTM and TCN, have shown great results in predicting time series data. With the advancement of leveraging pre-trained foundation models such as Large Language Models (LLMs) and more notably Google's recent foundation model for time series data, {\it TimesFM} (Time Series Foundation Model), it is of interest to investigate whether these foundation models have the capability of outperforming existing modeling approaches in analyzing and predicting time series data.
  This paper investigates the performance of using LLM models for time series data prediction. We investigate the in-context learning methodology in the training of LLM models that are specific to the underlying application domain. More specifically, the paper explores training LLMs through in-context, zero-shot and few-shot learning and forecasting time series data with OpenAI {\tt o4-mini} and Gemini 2.5 Flash Lite, as well as the recent Google's Transformer-based TimesFM, a time series-specific foundation model, along with two deep learning models, namely TCN and LSTM networks. The findings indicate that TimesFM has the best overall performance with the lowest RMSE value (0.3023) and the competitive inference time (266 seconds). Furthermore, OpenAI's o4-mini also exhibits a good performance based on Zero Shot learning.
  These findings highlight pre-trained time series foundation models as a promising direction for real-time forecasting, enabling accurate and scalable deployment with minimal model adaptation.

</details>


### [152] [Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity](https://arxiv.org/abs/2512.07723)
*Yonggeon Lee,Jibin Hwang,Alfred Malengo Kondoro,Juhyun Song,Youngtae Noh*

Main category: cs.LG

TL;DR: 提出基于Transformer的实时事件时间预测模型，用于准确预测电动汽车用户出发时间，以优化充电策略并延长电池寿命。


<details>
  <summary>Details</summary>
Motivation: 电动汽车锂离子电池在长时间高荷电状态下会加速退化，可以通过延迟充满电直到出发前充电来缓解，但这需要准确预测用户出发时间。

Method: 提出基于Transformer的实时事件时间预测模型，将每天表示为TTE序列，通过将时间离散化为基于网格的token，利用流式上下文信息而非仅依赖历史模式来预测出发时间。

Result: 在包含93名用户的真实世界研究中，使用被动智能手机数据进行评估，该方法能有效捕捉个体日常中的不规则出发模式，性能优于基线模型。

Conclusion: 该方法具有实际部署潜力，可为可持续交通系统做出贡献，通过优化充电策略延长电池寿命。

Abstract: Electric vehicles (EVs) are key to sustainable mobility, yet their lithium-ion batteries (LIBs) degrade more rapidly under prolonged high states of charge (SOC). This can be mitigated by delaying full charging \ours until just before departure, which requires accurate prediction of user departure times. In this work, we propose Transformer-based real-time-to-event (TTE) model for accurate EV departure prediction. Our approach represents each day as a TTE sequence by discretizing time into grid-based tokens. Unlike previous methods primarily dependent on temporal dependency from historical patterns, our method leverages streaming contextual information to predict departures. Evaluation on a real-world study involving 93 users and passive smartphone data demonstrates that our method effectively captures irregular departure patterns within individual routines, outperforming baseline models. These results highlight the potential for practical deployment of the \ours algorithm and its contribution to sustainable transportation systems.

</details>


### [153] [PlantBiMoE: A Bidirectional Foundation Model with SparseMoE for Plant Genomes](https://arxiv.org/abs/2512.07113)
*Kepeng Lin,Qizhe Zhang,Rui Wang,Xuehai Hu,Wei Xu*

Main category: cs.LG

TL;DR: PlantBiMoE：一种轻量级且表达能力强的植物基因组语言模型，通过双向Mamba和稀疏混合专家框架解决现有模型参数过大和双向建模能力有限的问题，在31个数据集上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有植物基因组语言模型（如AgroNT和PDLLMs）存在参数规模过大和双向建模能力有限的问题，需要开发更高效且能充分捕捉DNA双链结构依赖的模型。

Method: 提出PlantBiMoE模型，集成双向Mamba架构以有效捕捉DNA正反链的结构依赖，同时采用稀疏混合专家（SparseMoE）框架显著减少激活参数数量，在保持建模能力的同时提高计算效率。

Result: 在增强的基因组基准测试MPGB（包含11个代表性任务的31个数据集）上评估，PlantBiMoE在31个数据集中20个取得最佳性能，平均性能优于现有模型，输入序列长度范围50-6,000 bp。

Conclusion: PlantBiMoE能有效表示植物基因组序列，为多样化基因组任务提供稳健计算工具，对植物基因组学、基因编辑和合成生物学做出实质性贡献。

Abstract: Understanding the underlying linguistic rules of plant genomes remains a fundamental challenge in computational biology. Recent advances including AgroNT and PDLLMs have made notable progress although, they suffer from excessive parameter size and limited ability to model the bidirectional nature of DNA strands respectively. To address these limitations, we propose PlantBiMoE, a lightweight and expressive plant genome language model that integrates bidirectional Mamba and a Sparse Mixture-of-Experts (SparseMoE) framework. The bidirectional Mamba enables the model to effectively capture structural dependencies across both the forward and reverse DNA strands, while SparseMoE significantly reduces the number of active parameters, improving computational efficiency without sacrificing modeling capacity. We evaluated and tested our model on the Modified Plants Genome Benchmark (MPGB), an enhanced genomic benchmark, which consolidates 31 datasets across 11 representative tasks, with input sequence lengths ranging from 50 to 6,000 bp. Experimental results demonstrate that PlantBiMoE achieves the best performance on 20 out of 31 datasets and the average best when comparing with existing models. In summary, all above results demonstrate that our model can effectively represent plant genomic sequences, serving as a robust computational tool for diverse genomic tasks, while making substantive contributions to plant genomics, gene editing, and synthetic biology. The code is available at: https://github.com/HUST-Keep-Lin/PlantBiMoE

</details>


### [154] [Group Representational Position Encoding](https://arxiv.org/abs/2512.07805)
*Yifan Zhang,Zixiang Chen,Yifeng Liu,Zhen Qin,Huizhuo Yuan,Kangping Xu,Yang Yuan,Quanquan Gu,Andrew Chi-Chih Yao*

Main category: cs.LG

TL;DR: GRAPE是一个基于群作用的统一位置编码框架，包含乘法旋转和加法logit偏置两种机制，将RoPE和ALiBi作为特例包含在内。


<details>
  <summary>Details</summary>
Motivation: 为长上下文模型提供一个有原则的位置几何设计空间，统一现有的位置编码方法，特别是将RoPE和ALiBi纳入一个理论框架。

Method: 基于群作用理论，提出两种位置编码机制：1) 乘法GRAPE：在SO(d)中使用乘法旋转，位置n作用为G(n)=exp(nωL)；2) 加法GRAPE：在GL中使用单能作用产生加法logit偏置。

Result: 1) 当d/2平面为具有对数均匀谱的规范坐标对时，精确恢复RoPE；2) 学习可交换子空间和紧凑非交换混合将几何扩展到捕获跨子空间特征耦合；3) 加法GRAPE精确恢复ALiBi和Forgetting Transformer。

Conclusion: GRAPE为长上下文模型中的位置几何提供了一个有原则的设计空间，将RoPE和ALiBi作为特例包含在内，支持相对性、组合性、范数保持和流式缓存等特性。

Abstract: We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\mathrm{GL}$. In Multiplicative GRAPE, a position $n \in \mathbb{Z}$ (or $t \in \mathbb{R}$) acts as $\mathbf{G}(n)=\exp(n\,ω\,\mathbf{L})$ with a rank-2 skew generator $\mathbf{L} \in \mathbb{R}^{d \times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.

</details>


### [155] [Provable Long-Range Benefits of Next-Token Prediction](https://arxiv.org/abs/2512.07818)
*Xinyuan Cao,Santosh S. Vempala*

Main category: cs.LG

TL;DR: 论文证明：通过优化下一个词预测训练的RNN语言模型能够近似训练分布，使得任何有界描述长度的算法都无法区分模型生成的k个连续词符与真实文档中的k个连续词符。


<details>
  <summary>Details</summary>
Motivation: 解释为什么现代语言模型（基于下一个词预测训练）能够生成连贯文档并捕捉长距离结构，从理论上证明下一个词预测任务对于学习长距离结构的有效性。

Method: 理论证明方法：证明优化RNN的下一个词预测任务会产生一个近似训练分布的模型。具体证明对于从训练分布采样的文档，任何有界描述长度且只能检查接下来k个词符的算法，都无法区分真实文档的k个连续词符与模型在相同前缀下生成的k个词符。

Result: 提供了实现k词符不可区分性所需模型大小的多项式边界（与k相关，与文档长度无关），为实践中观察到的长距离连贯性提供了复杂性理论解释。

Conclusion: 下一个词预测任务在理论上具有强大的长距离结构学习能力，这解释了为什么基于此任务训练的现代语言模型能够生成连贯文档并捕捉长距离依赖关系。

Abstract: Why do modern language models, trained to do well on next-word prediction, appear to generate coherent documents and capture long-range structure? Here we show that next-token prediction is provably powerful for learning longer-range structure, even with common neural network architectures. Specifically, we prove that optimizing next-token prediction over a Recurrent Neural Network (RNN) yields a model that closely approximates the training distribution: for held-out documents sampled from the training distribution, no algorithm of bounded description length limited to examining the next $k$ tokens, for any $k$, can distinguish between $k$ consecutive tokens of such documents and $k$ tokens generated by the learned language model following the same prefix. We provide polynomial bounds (in $k$, independent of the document length) on the model size needed to achieve such $k$-token indistinguishability, offering a complexity-theoretic explanation for the long-range coherence observed in practice.

</details>


### [156] [Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration](https://arxiv.org/abs/2512.07173)
*Jucheng Shen,Gaurav Sarkar,Yeonju Ro,Sharath Nittur Sridhar,Zhangyang Wang,Aditya Akella,Souvik Kundu*

Main category: cs.LG

TL;DR: CadLLM是一种无需训练的方法，通过动态调整生成块大小、步长和阈值来加速基于扩散的LLMs推理吞吐量，最高可达2.28倍加速。


<details>
  <summary>Details</summary>
Motivation: 扩散基LLMs（dLLMs）推理速度较慢，需要提高其推理吞吐量。研究发现token unmasking置信度在不同块和步骤中存在动态变化特性，这为优化提供了机会。

Method: 1. 分析token unmasking置信度的动态特性；2. 基于平均置信度设计轻量级自适应方法，控制生成块大小、步长和阈值；3. 通过动态利用词汇表子集减少softmax开销；4. 兼容基于KV缓存的dLLMs，即插即用。

Result: 在四个流行任务上的实验表明，CadLLM相比最先进的基线方法，在保持竞争力的准确度前提下，实现了最高2.28倍的吞吐量提升。

Conclusion: CadLLM是一种有效、无需训练、模型无关的dLLMs推理加速方法，通过自适应控制生成参数和减少计算开销，显著提升推理效率。

Abstract: We present CadLLM, a training-free method to accelerate the inference throughput of diffusion-based LLMs (dLLMs). We first investigate the dynamic nature of token unmasking confidence across blocks and steps. Based on this observation, we present a lightweight adaptive approach that controls the generation block size, step size, and threshold based on the average confidence of unmasked tokens. We further reduce softmax overhead by dynamically leveraging a subset of the vocabulary to regulate sampling breadth. CadLLM is a plug-and-play, model-agnostic method compatible with KV-cache-based dLLMs. Extensive experiments on four popular tasks demonstrate that CadLLM yields up to 2.28x throughput improvement over the state-of-the-art baseline with competitive accuracy.

</details>


### [157] [SPACE: Noise Contrastive Estimation Stabilizes Self-Play Fine-Tuning for Large Language Models](https://arxiv.org/abs/2512.07175)
*Yibo Wang,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.LG

TL;DR: SPACE是一种基于噪声对比估计的自博弈微调方法，通过将合成样本视为辅助成分并与真实样本进行二元分类，独立优化每类数据的绝对奖励值，解决了传统基于差距的方法因目标退化而导致的不稳定演化问题。


<details>
  <summary>Details</summary>
Motivation: 现有自博弈微调方法主要关注真实数据和合成数据之间的奖励差距，忽略了它们的绝对值。理论分析表明，这种基于差距的方法由于目标可能退化而存在不稳定演化问题，需要一种更稳定的方法来适应下游任务。

Method: SPACE（Self-PlAy via Noise Contrastive Estimation）采用噪声对比估计来捕捉真实世界数据分布。该方法将合成样本视为辅助成分，通过二元分类方式将它们与真实样本区分开来，从而独立优化每类数据的绝对奖励值，确保目标始终保持有意义。

Result: 理论分析表明SPACE的最优解与真实世界数据的基础分布一致，并能保证可证明的稳定收敛到最优分布。实证结果显示，SPACE在各种任务上显著提升了LLM性能，优于使用更多真实样本的监督微调，相比基于差距的自博弈微调方法表现出显著优势和稳定演化。

Conclusion: SPACE通过噪声对比估计解决了传统自博弈微调方法的不稳定问题，提供了一种更稳定有效的LLM微调方法，能够在有限真实数据的情况下实现更好的性能表现。

Abstract: Self-play fine-tuning has demonstrated promising abilities in adapting large language models (LLMs) to downstream tasks with limited real-world data. The basic principle is to iteratively refine the model with real samples and synthetic ones generated from itself. However, the existing methods primarily focus on the relative gaps between the rewards for two types of data, neglecting their absolute values. Through theoretical analysis, we identify that the gap-based methods suffer from unstable evolution, due to the potentially degenerated objectives. To address this limitation, we introduce a novel self-play fine-tuning method, namely Self-PlAy via Noise Contrastive Estimation (SPACE), which leverages noise contrastive estimation to capture the real-world data distribution. Specifically, SPACE treats synthetic samples as auxiliary components, and discriminates them from the real ones in a binary classification manner. As a result, SPACE independently optimizes the absolute reward values for each type of data, ensuring a consistently meaningful objective and thereby avoiding the instability issue. Theoretically, we show that the optimal solution of the objective in SPACE aligns with the underlying distribution of real-world data, and SPACE guarantees a provably stable convergence to the optimal distribution. Empirically, we show that SPACE significantly improves the performance of LLMs over various tasks, and outperforms supervised fine-tuning that employs much more real-world samples. Compared to gap-based self-play fine-tuning methods, SPACE exhibits remarkable superiority and stable evolution.

</details>


### [158] [UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.07184)
*Da Zhang,Bingyu Li,Zhuyuan Zhao,Junyu Gao,Feiping Nie,Xuelong Li*

Main category: cs.LG

TL;DR: UniDiff：一个用于多模态时间序列预测的统一扩散框架，通过并行融合模块和新型分类器自由引导机制，有效整合文本和时间戳信息，在多个领域实现最先进的预测性能。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据在现实应用中的激增，利用文本和时间戳等异构信息进行准确时间序列预测成为关键挑战。现有扩散模型在时间序列预测中主要局限于单模态数值序列建模，忽略了复杂异构数据中丰富的跨模态信号。

Method: 提出UniDiff统一扩散框架：1）将时间序列分块标记化，通过轻量级MLP映射到嵌入空间以保留局部时间动态；2）核心是统一并行融合模块，使用单一交叉注意力机制自适应加权整合时间戳的结构信息和文本的语义上下文；3）引入针对多源条件的新型分类器自由引导机制，在推理过程中解耦控制文本和时间信息的引导强度。

Result: 在八个领域的真实世界基准数据集上进行广泛实验，证明UniDiff模型实现了最先进的性能。

Conclusion: UniDiff通过统一融合模块和创新的多源条件引导机制，有效解决了多模态时间序列预测问题，显著提升了模型鲁棒性和预测准确性。

Abstract: As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their application to TSF remains largely confined to modeling single-modality numerical sequences, overlooking the abundant cross-modal signals inherent in complex heterogeneous data. To address this gap, we propose UniDiff, a unified diffusion framework for multimodal time series forecasting. To process the numerical sequence, our framework first tokenizes the time series into patches, preserving local temporal dynamics by mapping each patch to an embedding space via a lightweight MLP. At its core lies a unified and parallel fusion module, where a single cross-attention mechanism adaptively weighs and integrates structural information from timestamps and semantic context from texts in one step, enabling a flexible and efficient interplay between modalities. Furthermore, we introduce a novel classifier-free guidance mechanism designed for multi-source conditioning, allowing for decoupled control over the guidance strength of textual and temporal information during inference, which significantly enhances model robustness. Extensive experiments on real-world benchmark datasets across eight domains demonstrate that the proposed UniDiff model achieves state-of-the-art performance.

</details>


### [159] [Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction](https://arxiv.org/abs/2512.07200)
*Zhen Huang,Jiaxin Deng,Jiayu Xu,Junbiao Pang,Haitao Yu*

Main category: cs.LG

TL;DR: 提出基于强化学习的非均匀道路分段方法，用于公交车到达时间预测，通过两阶段解耦实现高效预测


<details>
  <summary>Details</summary>
Motivation: 传统均匀分段方法无法考虑道路物理约束（如路况、交叉口、兴趣点）的差异，限制了预测效率。需要一种能自适应学习非均匀道路分段的方法来提升到达时间预测性能。

Method: 1) 使用强化学习框架基于影响分数提取非均匀道路分段；2) 对选定的分段应用线性预测模型进行预测。这种方法在保持计算效率的同时确保最优分段选择。

Result: 实验结果表明该方法在大规模基准测试中不仅提高了效率，还提升了学习性能。线性方法甚至能比更复杂的方法获得更好的性能。

Conclusion: 提出的基于强化学习的非均匀道路分段方法显著优于传统均匀方法，在公交车到达时间预测任务中实现了效率和性能的双重提升。

Abstract: In bus arrival time prediction, the process of organizing road infrastructure network data into homogeneous entities is known as segmentation. Segmenting a road network is widely recognized as the first and most critical step in developing an arrival time prediction system, particularly for auto-regressive-based approaches. Traditional methods typically employ a uniform segmentation strategy, which fails to account for varying physical constraints along roads, such as road conditions, intersections, and points of interest, thereby limiting prediction efficiency. In this paper, we propose a Reinforcement Learning (RL)-based approach to efficiently and adaptively learn non-uniform road segments for arrival time prediction. Our method decouples the prediction process into two stages: 1) Non-uniform road segments are extracted based on their impact scores using the proposed RL framework; and 2) A linear prediction model is applied to the selected segments to make predictions. This method ensures optimal segment selection while maintaining computational efficiency, offering a significant improvement over traditional uniform approaches. Furthermore, our experimental results suggest that the linear approach can even achieve better performance than more complex methods. Extensive experiments demonstrate the superiority of the proposed method, which not only enhances efficiency but also improves learning performance on large-scale benchmarks. The dataset and the code are publicly accessible at: https://github.com/pangjunbiao/Less-is-More.

</details>


### [160] [Pay Less Attention to Function Words for Free Robustness of Vision-Language Models](https://arxiv.org/abs/2512.07222)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Chao Shen*

Main category: cs.LG

TL;DR: 本文提出Function-word De-Attention (FDA)方法，通过减少功能词对跨模态对抗攻击的敏感性，在保持性能的同时显著提升视觉语言模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒视觉语言模型在鲁棒性和性能之间存在权衡问题，研究发现功能词是导致VLM对跨模态对抗攻击脆弱的关键因素，因此需要一种方法来减轻功能词的影响。

Method: 提出Function-word De-Attention (FDA)方法，类似于差分放大器，在注意力头中计算原始交叉注意力和功能词交叉注意力，然后将后者从前者中差分减去，从而获得更对齐和鲁棒的VLM。

Result: 在6种不同攻击、2个下游任务、3个数据集和3个模型上的综合实验显示：在检索任务上，FDA在3个测试模型上平均降低18/13/53%的攻击成功率，仅带来0.2/0.3/0.6%的性能下降；在视觉定位任务上，降低90%的攻击成功率同时获得0.3%的性能提升。

Conclusion: FDA方法有效解决了鲁棒VLM中鲁棒性与性能的权衡问题，实验证明了其可扩展性、泛化能力和零样本性能，为构建更鲁棒的视觉语言模型提供了有效解决方案。

Abstract: To address the trade-off between robustness and performance for robust VLM, we observe that function words could incur vulnerability of VLMs against cross-modal adversarial attacks, and propose Function-word De-Attention (FDA) accordingly to mitigate the impact of function words. Similar to differential amplifiers, our FDA calculates the original and the function-word cross-attention within attention heads, and differentially subtracts the latter from the former for more aligned and robust VLMs. Comprehensive experiments include 2 SOTA baselines under 6 different attacks on 2 downstream tasks, 3 datasets, and 3 models. Overall, our FDA yields an average 18/13/53% ASR drop with only 0.2/0.3/0.6% performance drops on the 3 tested models on retrieval, and a 90% ASR drop with a 0.3% performance gain on visual grounding. We demonstrate the scalability, generalization, and zero-shot performance of FDA experimentally, as well as in-depth ablation studies and analysis. Code will be made publicly at https://github.com/michaeltian108/FDA.

</details>


### [161] [Learning-Augmented Ski Rental with Discrete Distributions: A Bayesian Approach](https://arxiv.org/abs/2512.07313)
*Bosun Kang,Hyejun Park,Chenglin Fan*

Main category: cs.LG

TL;DR: 本文提出了一种基于贝叶斯决策和机器学习预测的滑雪租赁问题新框架，通过维护精确的后验分布实现不确定性量化，在准确先验下达到接近最优结果，同时保持鲁棒的worst-case保证。


<details>
  <summary>Details</summary>
Motivation: 传统滑雪租赁问题算法仅最小化最坏情况成本，而最近的学习增强方法利用噪声预测但缺乏不确定性量化。本文旨在统一这两种视角，通过贝叶斯框架实现更原则性的决策。

Method: 提出离散贝叶斯框架，维护时间范围上的精确后验分布，支持专家先验的无缝整合，算法能够优雅地在最坏情况和完全知情设置之间插值。

Result: 算法实现了先验依赖的竞争性保证，在广泛实验中表现出优越的实证性能，在准确先验下达到接近最优结果，同时保持鲁棒的最坏情况保证。

Conclusion: 贝叶斯推理框架为具有不完美预测的在线决策问题提供了实用优势，自然支持多预测、非均匀先验和上下文信息的整合，展示了贝叶斯方法在在线决策中的价值。

Abstract: We revisit the classic ski rental problem through the lens of Bayesian decision-making and machine-learned predictions. While traditional algorithms minimize worst-case cost without assumptions, and recent learning-augmented approaches leverage noisy forecasts with robustness guarantees, our work unifies these perspectives. We propose a discrete Bayesian framework that maintains exact posterior distributions over the time horizon, enabling principled uncertainty quantification and seamless incorporation of expert priors. Our algorithm achieves prior-dependent competitive guarantees and gracefully interpolates between worst-case and fully-informed settings. Our extensive experimental evaluation demonstrates superior empirical performance across diverse scenarios, achieving near-optimal results under accurate priors while maintaining robust worst-case guarantees. This framework naturally extends to incorporate multiple predictions, non-uniform priors, and contextual information, highlighting the practical advantages of Bayesian reasoning in online decision problems with imperfect predictions.

</details>


### [162] [Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood](https://arxiv.org/abs/2512.07390)
*Gilhyun Nam,Taewon Kim,Joonhyun Jeong,Eunho Yang*

Main category: cs.LG

TL;DR: SICL是一个基于风格不变性的测试时适应不确定性校准框架，通过测量风格变换变体间的预测一致性来估计实例级正确性似然，无需反向传播，可与任何TTA方法兼容。


<details>
  <summary>Details</summary>
Motivation: 测试时适应（TTA）方法虽然能高效适应部署模型，但通常导致预测不确定性校准不佳，这在自动驾驶、金融和医疗等高风险领域是严重问题。现有校准方法假设固定模型或静态分布，在真实世界动态测试条件下性能下降。

Method: 提出SICL框架，利用风格不变性进行鲁棒不确定性估计。通过测量预测在风格变换变体间的一致性来估计实例级正确性似然，仅需模型前向传播，无需反向传播，可作为即插即用的校准模块与任何TTA方法兼容。

Result: 在4个基线、5种TTA方法和2个现实场景下的综合评估显示，SICL相比传统校准方法平均减少13个百分点的校准误差。

Conclusion: SICL提供了一种有效且实用的TTA不确定性校准解决方案，通过风格不变性原理实现了鲁棒的不确定性估计，在高风险应用中具有重要价值。

Abstract: Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.

</details>


### [163] [Mitigating Bias in Graph Hyperdimensional Computing](https://arxiv.org/abs/2512.07433)
*Yezi Liu,William Youngwoo Chung,Yang Ni,Hanning Chen,Mohsen Imani*

Main category: cs.LG

TL;DR: FairGHDC：一种用于图超维计算（HDC）的公平性感知训练框架，通过引入基于人口统计均等正则化的偏置校正项，在保持HDC计算效率的同时显著减少公平性差距。


<details>
  <summary>Details</summary>
Motivation: 图超维计算（HDC）作为一种新兴的类脑计算范式，在图结构数据处理中展现出鲁棒性和高效性，但其公平性影响尚未得到充分研究。数据表示和决策规则中的偏置可能导致对不同群体的不平等对待。

Method: 提出FairGHDC框架，引入基于人口统计均等差距的正则化器推导出的偏置校正项，将其转换为标量公平因子，用于缩放真实标签类超向量的更新。该方法直接在超向量空间中进行去偏置，无需修改图编码器或反向传播。

Result: 在六个基准数据集上的实验结果表明，FairGHDC显著减少了人口统计均等和机会均等差距，同时保持与标准GNN和公平性感知GNN相当的准确性。在训练时间上，FairGHDC在GPU上比GNN和公平性感知GNN基线实现了约10倍的加速。

Conclusion: FairGHDC成功解决了图HDC中的公平性问题，在保持HDC计算优势的同时有效减轻了偏置，为公平高效的图学习提供了有前景的解决方案。

Abstract: Graph hyperdimensional computing (HDC) has emerged as a promising paradigm for cognitive tasks, emulating brain-like computation with high-dimensional vectors known as hypervectors. While HDC offers robustness and efficiency on graph-structured data, its fairness implications remain largely unexplored. In this paper, we study fairness in graph HDC, where biases in data representation and decision rules can lead to unequal treatment of different groups. We show how hypervector encoding and similarity-based classification can propagate or even amplify such biases, and we propose a fairness-aware training framework, FairGHDC, to mitigate them. FairGHDC introduces a bias correction term, derived from a gap-based demographic-parity regularizer, and converts it into a scalar fairness factor that scales the update of the class hypervector for the ground-truth label. This enables debiasing directly in the hypervector space without modifying the graph encoder or requiring backpropagation. Experimental results on six benchmark datasets demonstrate that FairGHDC substantially reduces demographic-parity and equal-opportunity gaps while maintaining accuracy comparable to standard GNNs and fairness-aware GNNs. At the same time, FairGHDC preserves the computational advantages of HDC, achieving up to about one order of magnitude ($\approx 10\times$) speedup in training time on GPU compared to GNN and fairness-aware GNN baselines.

</details>


### [164] [Parallel Algorithms for Combined Regularized Support Vector Machines: Application in Music Genre Classification](https://arxiv.org/abs/2512.07463)
*Rongmei Liang,Zizheng Liu,Xiaofei Wu,Jingwen Tu*

Main category: cs.LG

TL;DR: 提出基于共识结构的统一优化框架，开发分布式并行ADMM算法处理分布式存储大数据中的组合正则化支持向量机，引入高斯回代法确保收敛，并应用于音乐信息检索。


<details>
  <summary>Details</summary>
Motivation: 在人工智能快速发展的时代，组合正则化支持向量机（CR-SVMs）能有效处理数据特征间的结构信息，但在分布式存储的大数据场景中缺乏高效算法。

Method: 提出基于共识结构的统一优化框架，开发分布式并行交替方向乘子法（ADMM）算法，引入高斯回代法确保收敛，并提出了稀疏群套索支持向量机（SGL-SVM）新模型。

Result: 理论分析证实算法计算复杂度不受不同正则化项和损失函数影响，突显了并行算法的普适性。在合成和免费音乐档案数据集上的实验证明了算法的可靠性、稳定性和效率。

Conclusion: 提出的统一优化框架和分布式并行ADMM算法能有效解决分布式存储大数据中组合正则化支持向量机的计算问题，具有强扩展性和普适性。

Abstract: In the era of rapid development of artificial intelligence, its applications span across diverse fields, relying heavily on effective data processing and model optimization. Combined Regularized Support Vector Machines (CR-SVMs) can effectively handle the structural information among data features, but there is a lack of efficient algorithms in distributed-stored big data. To address this issue, we propose a unified optimization framework based on consensus structure. This framework is not only applicable to various loss functions and combined regularization terms but can also be effectively extended to non-convex regularization terms, showing strong scalability. Based on this framework, we develop a distributed parallel alternating direction method of multipliers (ADMM) algorithm to efficiently compute CR-SVMs when data is stored in a distributed manner. To ensure the convergence of the algorithm, we also introduce the Gaussian back-substitution method. Meanwhile, for the integrity of the paper, we introduce a new model, the sparse group lasso support vector machine (SGL-SVM), and apply it to music information retrieval. Theoretical analysis confirms that the computational complexity of the proposed algorithm is not affected by different regularization terms and loss functions, highlighting the universality of the parallel algorithm. Experiments on synthetic and free music archiv datasets demonstrate the reliability, stability, and efficiency of the algorithm.

</details>


### [165] [Materium: An Autoregressive Approach for Material Generation](https://arxiv.org/abs/2512.07486)
*Niklas Dobberstein,Jan Hamaekers*

Main category: cs.LG

TL;DR: Materium是一种基于自回归变换器的晶体结构生成模型，将3D材料表示转换为包含元素、氧化态、分数坐标和晶格参数的标记序列，实现快速、可扩展的晶体生成。


<details>
  <summary>Details</summary>
Motivation: 现有扩散方法需要多次去噪步骤迭代细化原子位置，计算成本高且速度慢。需要开发一种能够快速、精确生成晶体结构的方法，支持多种物理性质作为生成条件。

Method: 采用自回归变换器架构，将3D晶体结构转换为包含元素、氧化态、分数坐标和晶格参数的标记序列。模型通过条件生成支持多种物理性质作为输入条件，包括基本性质（如密度、空间群）和实用目标（如带隙、磁密度）。

Result: 模型可在单GPU上几小时内完成训练，在GPU和CPU上生成速度远快于扩散方法。在单一和组合条件下均表现一致，生成的候选结构能够与输入条件良好对齐。

Conclusion: Materium提供了一种高效、快速的晶体结构生成方法，克服了扩散模型的迭代去噪瓶颈，支持多种物理性质的条件生成，为材料发现提供了实用的计算工具。

Abstract: We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs.

</details>


### [166] [Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent](https://arxiv.org/abs/2512.07490)
*Zhiyu Liu,Zhi Han,Yandong Tang,Jun Fan,Yao Wang*

Main category: cs.LG

TL;DR: 提出交替预条件梯度下降算法（APGD）解决低管秩张量估计问题，在过参数化情况下加速收敛，收敛率与张量条件数无关。


<details>
  <summary>Details</summary>
Motivation: 传统张量奇异值分解方法计算昂贵，不适用于大规模张量；现有基于梯度下降的因子分解方法需要准确估计张量秩，当秩被高估时收敛速度显著下降甚至发散。

Method: 提出交替预条件梯度下降算法（APGD），通过向原始梯度添加预条件项，交替更新两个因子张量，在过参数化设置下加速收敛。

Result: 基于几何假设建立了线性收敛保证，特别分析了低管秩张量分解和张量恢复的具体情况。理论结果表明APGD在过参数化下仍能实现线性收敛，且收敛率与张量条件数无关。

Conclusion: APGD算法有效解决了低管秩张量估计中的过参数化问题，在合成数据上的大量模拟验证了理论断言。

Abstract: The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.

</details>


### [167] [FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting](https://arxiv.org/abs/2512.07539)
*Qingyuan Yang,Shizhuo,Dongyue Chen,Da Teng,Zehua Gan*

Main category: cs.LG

TL;DR: FRWKV：一种结合线性注意力和频域分析的时间序列预测框架，将计算复杂度从O(T²)降低到O(T)，在8个真实数据集上取得最佳平均排名。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在长序列时间序列预测中存在两个主要瓶颈：1）二次计算复杂度O(T²)限制了可扩展性；2）未能有效利用频域信息来增强特征表示。

Method: 提出FRWKV框架，结合RWKV的线性注意力机制（O(T)复杂度）与频域建模，通过频域分析增强时间特征表示，实现可扩展的长序列建模。

Result: 在8个真实世界数据集上，FRWKV取得了第一的平均排名。消融研究证实了线性注意力和频域编码器两个组件的关键作用。

Conclusion: 这项工作展示了线性注意力与频域分析之间的强大协同作用，为可扩展的时间序列建模建立了新范式。

Abstract: Traditional Transformers face a major bottleneck in long-sequence time series forecasting due to their quadratic complexity $(\mathcal{O}(T^2))$ and their limited ability to effectively exploit frequency-domain information. Inspired by RWKV's $\mathcal{O}(T)$ linear attention and frequency-domain modeling, we propose FRWKV, a frequency-domain linear-attention framework that overcomes these limitations. Our model integrates linear attention mechanisms with frequency-domain analysis, achieving $\mathcal{O}(T)$ computational complexity in the attention path while exploiting spectral information to enhance temporal feature representations for scalable long-sequence modeling. Across eight real-world datasets, FRWKV achieves a first-place average rank. Our ablation studies confirm the critical roles of both the linear attention and frequency-encoder components. This work demonstrates the powerful synergy between linear attention and frequency analysis, establishing a new paradigm for scalable time series modeling. Code is available at this repository: https://github.com/yangqingyuan-byte/FRWKV.

</details>


### [168] [ReLaX: Reasoning with Latent Exploration for Large Reasoning Models](https://arxiv.org/abs/2512.07558)
*Shimin Zhang,Xianwei Chen,Yufan Shen,Ziyuan Ye,Jibin Wu*

Main category: cs.LG

TL;DR: ReLaX通过Koopman算子理论线性化大推理模型的隐状态动态，提出动态谱分散度指标量化探索程度，有效缓解RLVR中的熵崩溃问题，提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 虽然可验证奖励的强化学习能提升大推理模型的推理能力，但常导致熵崩溃，造成策略过早收敛和性能饱和。现有方法主要操纵token级熵来促进探索，但作者认为token生成背后的隐动态包含更丰富的计算结构，能更有效地指导探索-利用权衡。

Method: 提出ReLaX框架：1) 利用Koopman算子理论获得模型隐状态的线性化表示；2) 引入动态谱分散度指标量化隐动态的异质性，作为策略探索的直接指标；3) 在策略优化中显式地结合隐动态来调节探索与利用。

Result: 在广泛的多模态和纯文本推理基准测试中，ReLaX显著缓解了过早收敛问题，并持续实现了最先进的性能表现。

Conclusion: 通过分析和干预大推理模型的隐动态，ReLaX框架能够更有效地平衡探索与利用，解决RLVR中的熵崩溃问题，提升推理模型的整体性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.

</details>


### [169] [Depth-Wise Activation Steering for Honest Language Models](https://arxiv.org/abs/2512.07667)
*Gracjan Góral,Marysia Winkels,Steven Basart*

Main category: cs.LG

TL;DR: 提出一种无需训练的激活引导方法，通过高斯调度在深度维度加权引导强度，改善大语言模型诚实性而非准确性，在MASK基准测试中优于单层引导和其他深度分配策略。


<details>
  <summary>Details</summary>
Motivation: 大语言模型有时会断言虚假信息，尽管内部表示正确答案，这是诚实性而非准确性的失败，损害了可审计性和安全性。现有方法主要优化事实正确性或依赖重新训练和脆弱的单层编辑，对真实报告的控制有限。

Method: 提出无需训练的激活引导方法，使用高斯调度在深度维度加权引导强度。该方法简单、模型无关、无需微调，为从模型现有能力中引出真实报告提供低成本控制手段。

Result: 在MASK基准测试中评估了LLaMA、Qwen和Mistral家族的七个模型，高斯调度在六个模型中改善了诚实性，优于无引导和单层基线。在LLaMA-3.1-8B-Instruct和Qwen-2.5-7B-Instruct上的等预算消融实验显示，高斯调度优于随机、均匀和盒滤波深度分配，表明干预在深度上的分布方式对结果有实质性影响。

Conclusion: 高斯调度激活引导方法能有效改善大语言模型的诚实性，提供了一种简单、模型无关、无需微调的控制手段，为从模型现有能力中引出真实报告提供了实用解决方案。

Abstract: Large language models sometimes assert falsehoods despite internally representing the correct answer, failures of honesty rather than accuracy, which undermines auditability and safety. Existing approaches largely optimize factual correctness or depend on retraining and brittle single-layer edits, offering limited leverage over truthful reporting. We present a training-free activation steering method that weights steering strength across network depth using a Gaussian schedule. On the MASK benchmark, which separates honesty from knowledge, we evaluate seven models spanning the LLaMA, Qwen, and Mistral families and find that Gaussian scheduling improves honesty over no-steering and single-layer baselines in six of seven models. Equal-budget ablations on LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct show the Gaussian schedule outperforms random, uniform, and box-filter depth allocations, indicating that how intervention is distributed across depth materially affects outcomes beyond total strength. The method is simple, model-agnostic, requires no finetuning, and provides a low-cost control knob for eliciting truthful reporting from models' existing capabilities.

</details>


### [170] [GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory](https://arxiv.org/abs/2512.07782)
*Jiaxu Liu,Yuhe Bai,Christos-Savvas Bouganis*

Main category: cs.LG

TL;DR: 提出GatedFWA机制，在保持滑动窗口注意力效率的同时，通过门控记忆更新解决训练不稳定和梯度消失问题。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的Softmax注意力存在二次复杂度问题，滑动窗口注意力(SWA)虽然实现线性复杂度，但其基于差异的更新方式导致训练目标无界，而Softmax注意力则存在记忆收缩和梯度消失问题。

Method: 提出GatedFWA：一种记忆门控的滑动窗口注意力机制，通过为每个token/head累积门控值作为衰减偏置添加到注意力logits中，实现可学习的记忆收缩递归。实现了融合的单次门控预处理和与FlashAttention兼容的内核。

Result: 在语言建模基准测试中，GatedFWA以可忽略的开销实现了竞争性的吞吐量，更好地利用了全局上下文，并能与NSA等token压缩/选择方法无缝集成，适用于各种自回归领域。

Conclusion: GatedFWA在保持滑动窗口注意力效率优势的同时，通过门控机制稳定了记忆更新并实现了可控的梯度流动，解决了现有注意力机制的关键问题。

Abstract: Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \emph{unbounded}. In contrast, Softmax attention normalizes updates, leading to \emph{memory shrinkage and gradient vanishing}. We propose GatedFWA: a Memory-\underline{Gated} (\underline{F}lash) \underline{W}indowed \underline{A}ttention mechanism that preserves SWAs efficiency while stabilizing memory updates and making gradient flow controllable. In essence, GatedFWA accumulate a per-token/head gate into a decay bias added to the attention logits, acting as a learnable contraction in the memory recurrence. We implement a fused one-pass gate preprocessing and a FlashAttention-compatible kernel that injects the gate under a sliding mask, ensuring I/O efficiency and numerical stability. On language modelling benchmarks, GatedFWA delivers competitive throughput with negligible overhead and better use of global context, and it integrates cleanly with token compression/selection methods such as NSA and generalizes to various autoregressive domains.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [171] [Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals](https://arxiv.org/abs/2512.05998)
*Michael Todasco*

Main category: cs.AI

TL;DR: 研究测试了将LLM评估任务设计为投注游戏（使用虚构货币的预测市场）是否能提高预测准确性并产生校准的信心信号。实验发现投注条件能产生可读的信心信号，大额投注准确率高达99%，小额投注仅74%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在评估其他模型时通常缺乏信心表示，研究者希望探索通过金融框架（投注游戏）来改善预测准确性并让模型的内部信念变得可见和可用。

Method: 生成了100个数学和逻辑问题，6个基线模型（3个当前代，3个前代）回答所有问题。3个预测模型在两种条件下预测每个问题-基线配对：控制条件（简单正确/错误预测）和激励条件（预测加1-100,000 LLMCoin的投注，起始资金1,000,000 LLMCoin）。

Result: 激励条件下的预测准确性略高（81.5% vs. 79.1%），学习速度显著更快（第1轮到第4轮改进12.0% vs. 2.9%）。投注金额与信心相关：40,000+硬币的"鲸鱼"投注正确率约99%，而<1,000硬币的小额投注仅74%准确率。

Conclusion: 投注机制创造了从二元是/否输出中缺失的可读信心信号，表明简单的金融框架可能帮助LLM成为风险感知的预测者，使其内部信念变得可见和可用。该协议为未来的元评估系统和LLM-to-LLM预测市场奠定了基础。

Abstract: Large language models are increasingly used to evaluate other models, yet these judgments typically lack any representation of confidence. This pilot study tests whether framing an evaluation task as a betting game (a fictional prediction market with its own LLM currency) improves forecasting accuracy and surfaces calibrated confidence signals. We generated 100 math and logic questions with verifiable answers. Six Baseline models (three current-generation, three prior-generation) answered all items. Three Predictor models then forecasted, for each question-baseline pair, if the baseline would answer correctly. Each predictor completed matched runs in two conditions: Control (simple correct/incorrect predictions) and Incentive (predictions plus wagers of 1-100,000 LLMCoin under even odds, starting from a 1,000,000 LLMCoin bankroll). Across 5,400 predictions per condition, Incentive runs showed modestly higher accuracy (81.5% vs. 79.1%, p = .089, d = 0.86) and significantly faster learning across rounds (12.0 vs. 2.9 percentage-point improvement from Round 1 to Round 4, p = .011). Most notably, stake size tracked confidence. "Whale" bets of 40,000+ coins were correct ~99% of the time, while small bets (<1,000 coins) showed only ~74% accuracy. The key finding is not that fictional money makes models smarter; accuracy gains were modest and did not reach statistical significance (p = .089) in this pilot. Rather, the betting mechanic created a legible confidence signal absent from binary yes/no outputs. This suggests that simple financial framing may help transform LLMs into risk-aware forecasters, making their internal beliefs visible and usable. The protocol offers a foundation for future work for meta-evaluation systems and what may become LLM-to-LLM prediction markets.

</details>


### [172] [Deep learning for autism detection using clinical notes: A comparison of transfer learning for a transparent and black-box approach](https://arxiv.org/abs/2512.06161)
*Gondy Leroy,Prakash Bisht,Sai Madhuri Kandula,Nell Maltman,Sydney Rice*

Main category: cs.AI

TL;DR: 使用BioBERT分析临床文本的透明可解释机器学习方法，通过将行为描述映射到诊断标准来进行自闭症谱系障碍诊断，在混合数据集训练中表现优于黑盒模型。


<details>
  <summary>Details</summary>
Motivation: 自闭症谱系障碍诊断过程漫长且需求增加，现有机器学习模型多为黑盒且通常基于单一数据集训练，限制了其可泛化性和临床可信度。

Method: 采用基于BioBERT的透明可解释机器学习方法，分析非结构化临床文本，将行为描述标记并映射到诊断标准，然后分配最终标签（ASD或非ASD）。评估了两种训练策略：顺序训练和混合训练，并与黑盒方法进行比较。

Result: 透明模型表现出稳健性能，混合数据训练策略效果最佳（97%灵敏度，98%特异性）。顺序训练导致性能略有下降。黑盒模型在顺序或混合训练中表现较差（90%灵敏度，96%特异性）。透明方法整体优于黑盒方法。

Conclusion: 透明可解释的机器学习方法在自闭症诊断中优于黑盒方法，混合数据集训练可获得最佳性能，为神经发育诊断中更可信、可泛化和临床可操作的AI工具铺平了道路。

Abstract: Autism spectrum disorder (ASD) is a complex neurodevelopmental condition whose rising prevalence places increasing demands on a lengthy diagnostic process. Machine learning (ML) has shown promise in automating ASD diagnosis, but most existing models operate as black boxes and are typically trained on a single dataset, limiting their generalizability. In this study, we introduce a transparent and interpretable ML approach that leverages BioBERT, a state-of-the-art language model, to analyze unstructured clinical text. The model is trained to label descriptions of behaviors and map them to diagnostic criteria, which are then used to assign a final label (ASD or not). We evaluate transfer learning, the ability to transfer knowledge to new data, using two distinct real-world datasets. We trained on datasets sequentially and mixed together and compared the performance of the best models and their ability to transfer to new data. We also created a black-box approach and repeated this transfer process for comparison. Our transparent model demonstrated robust performance, with the mixed-data training strategy yielding the best results (97 % sensitivity, 98 % specificity). Sequential training across datasets led to a slight drop in performance, highlighting the importance of training data order. The black-box model performed worse (90 % sensitivity, 96 % specificity) when trained sequentially or with mixed data. Overall, our transparent approach outperformed the black-box approach. Mixing datasets during training resulted in slightly better performance and should be the preferred approach when practically possible. This work paves the way for more trustworthy, generalizable, and clinically actionable AI tools in neurodevelopmental diagnostics.

</details>


### [173] [ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment](https://arxiv.org/abs/2512.06196)
*Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: ARCANE框架将AI对齐问题转化为多智能体协作问题，通过自然语言评分标准动态表示利益相关者偏好，实现可解释、无需重新训练即可调整的对齐方法。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体越来越多地部署到长期任务中，保持其与利益相关者偏好的一致性变得至关重要。需要可解释的奖励模型让利益相关者能够理解和审计模型目标，并且能够在交互时指导智能体，无需重新训练即可纳入偏好变化。

Method: 提出ARCANE框架，将对齐问题构建为多智能体协作问题，将利益相关者偏好动态表示为自然语言评分标准（可验证的加权标准集合）。采用正则化组序列策略优化（GSPO）程序进行评分标准学习，平衡可解释性、忠实性和计算效率。

Result: 使用GDPVal基准的219个标记评分标准进行评估，在需要多步推理和工具使用的挑战性任务上表现良好。学习的评分标准产生紧凑、易读的评估，无需重新训练即可实现可配置的权衡（如正确性与简洁性）。

Conclusion: 基于评分标准的奖励模型为复杂、长期AI系统提供了一条有前景的可解释、测试时自适应对齐路径。

Abstract: As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.

</details>


### [174] [On measuring grounding and generalizing grounding problems](https://arxiv.org/abs/2512.06205)
*Daniel Quigley,Eric Maynard*

Main category: cs.AI

TL;DR: 论文将符号接地问题从二元判断重构为基于评估元组（上下文、意义类型、威胁模型、参考分布）的多维度审计框架，包含真实性、保持性、忠实性、鲁棒性和组合性五个标准，并应用于四种接地模式和三个案例研究。


<details>
  <summary>Details</summary>
Motivation: 传统符号接地问题将"接地"视为二元判断（接地或未接地），这种简化无法捕捉实际认知和计算系统中意义的复杂性。作者希望建立一个更精细的框架来系统评估不同系统中的意义表征质量。

Method: 提出基于评估元组（上下文、意义类型、威胁模型、参考分布）的多维度审计框架，包含五个核心标准：真实性（机制是否在智能体内部并通过学习/进化获得）、保持性（原子意义是否保持完整）、忠实性（相关性和因果性）、鲁棒性（在扰动下的优雅降级）、组合性（系统构建性）。将此框架应用于四种接地模式（符号、指称、向量、关系）和三个案例研究。

Result: 模型论语义学实现精确组合但缺乏因果保证；大语言模型在语言任务上显示相关拟合和局部鲁棒性，但在无接地交互的世界任务中缺乏成功选择；人类语言通过进化和发展获得满足强真实性标准。框架为哲学、计算机科学、语言学和数学提供了共同语言和技术工具。

Conclusion: 通过将哲学上的表征问题操作化，作者提供了一个系统研究接地和意义的共同框架，使不同学科的研究者能够更精确地评估和比较不同系统中的意义表征质量，超越了传统的二元接地判断。

Abstract: The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.

</details>


### [175] [AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems](https://arxiv.org/abs/2512.06240)
*Chuanhao Nie,Yunbo Liu,Chao Wang*

Main category: cs.AI

TL;DR: 该论文探讨了人工智能在反洗钱工作流程中的应用，提出了一种结合图检索增强生成技术的KYC应用，以提高检测准确性、降低误报率并优化合规流程。


<details>
  <summary>Details</summary>
Motivation: 洗钱和金融欺诈每年造成数万亿美元损失，严重威胁全球金融稳定。传统反洗钱工作流程存在检测准确性低、误报率高、人工调查负担重等问题，需要现代化技术解决方案来支持可持续发展。

Method: 论文首先综述了AI在反洗钱中的应用，然后提出了一种AI驱动的KYC应用架构，该架构整合了基于图的检索增强生成技术与生成模型，以提高KYC流程的效率和透明度。

Result: 实验结果表明，RAG-Graph架构在不同评估场景下都表现出高忠实度和强答案相关性，显著提升了KYC客户尽职调查/增强尽职调查工作流程的效率和透明度。

Conclusion: AI技术能够现代化反洗钱工作流程，提高检测准确性并降低运营负担。未来的研究方向包括隐私保护的联邦学习、公平可解释AI、自适应防御的强化学习以及人机协同可视化系统，以确保下一代反洗钱架构的透明性、问责制和鲁棒性。

Abstract: Money laundering and financial fraud remain major threats to global financial stability, costing trillions annually and challenging regulatory oversight. This paper reviews how artificial intelligence (AI) applications can modernize Anti-Money Laundering (AML) workflows by improving detection accuracy, lowering false-positive rates, and reducing the operational burden of manual investigations, thereby supporting more sustainable development. It further highlights future research directions including federated learning for privacy-preserving collaboration, fairness-aware and interpretable AI, reinforcement learning for adaptive defenses, and human-in-the-loop visualization systems to ensure that next-generation AML architectures remain transparent, accountable, and robust. In the final part, the paper proposes an AI-driven KYC application that integrates graph-based retrieval-augmented generation (RAG Graph) with generative models to enhance efficiency, transparency, and decision support in KYC processes related to money-laundering detection. Experimental results show that the RAG-Graph architecture delivers high faithfulness and strong answer relevancy across diverse evaluation settings, thereby enhancing the efficiency and transparency of KYC CDD/EDD workflows and contributing to more sustainable, resource-optimized compliance practices.

</details>


### [176] [How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion](https://arxiv.org/abs/2512.06296)
*Sooho Moon,Yunyong Ko*

Main category: cs.AI

TL;DR: 本文提出了PROBE评估框架，通过考虑预测锐度（A1）和流行度偏差鲁棒性（A2）两个关键视角，改进了知识图谱补全的评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全（KGC）评估指标存在不足，忽视了预测锐度（评估单个预测的严格程度）和流行度偏差鲁棒性（预测低流行度实体的能力）这两个关键视角。

Method: 提出了PROBE评估框架，包含两个组件：1）秩变换器（RT）根据所需的预测锐度水平估计每个预测的分数；2）秩聚合器（RA）以流行度感知的方式聚合所有分数。

Result: 在真实世界知识图谱上的实验表明，现有指标倾向于高估或低估KGC模型的准确性，而PROBE能够提供对KGC模型的全面理解并产生可靠的评估结果。

Conclusion: PROBE框架通过同时考虑预测锐度和流行度偏差鲁棒性，为知识图谱补全提供了更全面、更可靠的评估方法，揭示了现有评估指标的局限性。

Abstract: Knowledge graph completion (KGC) aims to predict missing facts from the observed KG. While a number of KGC models have been studied, the evaluation of KGC still remain underexplored. In this paper, we observe that existing metrics overlook two key perspectives for KGC evaluation: (A1) predictive sharpness -- the degree of strictness in evaluating an individual prediction, and (A2) popularity-bias robustness -- the ability to predict low-popularity entities. Toward reflecting both perspectives, we propose a novel evaluation framework (PROBE), which consists of a rank transformer (RT) estimating the score of each prediction based on a required level of predictive sharpness and a rank aggregator (RA) aggregating all the scores in a popularity-aware manner. Experiments on real-world KGs reveal that existing metrics tend to over- or under-estimate the accuracy of KGC models, whereas PROBE yields a comprehensive understanding of KGC models and reliable evaluation results.

</details>


### [177] [DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization](https://arxiv.org/abs/2512.06337)
*Xuan Xie,Xuan Wang,Wenjie Wang*

Main category: cs.AI

TL;DR: DaGRPO通过引入序列级梯度校正和离策略数据增强，解决了GRPO在长程推理训练中的不稳定性和样本效率低的问题，在数学推理和OOD泛化基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: GRPO虽然在大语言模型的后训练推理能力激发方面表现出色，但存在显著的训练不稳定性和样本效率低的问题。研究发现这些问题的根源在于策略内样本缺乏区分度：对于常规查询，高度同质的样本导致破坏性梯度冲突；对于困难查询，有效正样本稀缺导致优化无效。

Method: 提出Distinctiveness-aware Group Relative Policy Optimization (DaGRPO)，包含两个核心机制：1) 序列级梯度校正：利用细粒度评分动态掩码低区分度的样本对，从源头消除梯度冲突；2) 离策略数据增强：引入高质量锚点样本，为困难任务恢复训练信号。

Result: 在9个数学推理和OOD泛化基准上的广泛实验表明，DaGRPO显著超越现有的SFT、GRPO和混合基线，实现了新的SOTA性能（例如在数学基准上平均准确率提升+4.7%）。深入分析证实DaGRPO有效缓解了梯度爆炸，加速了长链推理能力的出现。

Conclusion: DaGRPO通过解决GRPO中样本区分度不足的问题，显著提升了训练稳定性和样本效率，为大语言模型的长程推理能力激发提供了更有效的后训练方法。

Abstract: The evolution of Large Language Models (LLMs) has catalyzed a paradigm shift from superficial instruction following to rigorous long-horizon reasoning. While Group Relative Policy Optimization (GRPO) has emerged as a pivotal mechanism for eliciting such post-training reasoning capabilities due to its exceptional performance, it remains plagued by significant training instability and poor sample efficiency. We theoretically identify the root cause of these issues as the lack of distinctiveness within on-policy rollouts: for routine queries, highly homogeneous samples induce destructive gradient conflicts; whereas for hard queries, the scarcity of valid positive samples results in ineffective optimization. To bridge this gap, we propose Distinctiveness-aware Group Relative Policy Optimization (DaGRPO). DaGRPO incorporates two core mechanisms: (1) Sequence-level Gradient Rectification, which utilizes fine-grained scoring to dynamically mask sample pairs with low distinctiveness, thereby eradicating gradient conflicts at the source; and (2) Off-policy Data Augmentation, which introduces high-quality anchors to recover training signals for challenging tasks. Extensive experiments across 9 mathematical reasoning and out-of-distribution (OOD) generalization benchmarks demonstrate that DaGRPO significantly surpasses existing SFT, GRPO, and hybrid baselines, achieving new state-of-the-art performance (e.g., a +4.7% average accuracy gain on math benchmarks). Furthermore, in-depth analysis confirms that DaGRPO effectively mitigates gradient explosion and accelerates the emergence of long-chain reasoning capabilities.

</details>


### [178] [Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression](https://arxiv.org/abs/2512.06393)
*Qiming Bao,Xiaoxuan Fu*

Main category: cs.AI

TL;DR: LLMs在逻辑推理中表现出对语义保持变换的稳定性，但对缺失或矛盾证据极度脆弱


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在自然语言任务上表现出色，但其在逻辑推理中对结构性扰动的泛化能力尚未被充分理解，需要建立系统评估框架来诊断推理失败模式

Method: 提出受控评估框架，包含四种针对性压力测试：规则删除（冗余vs必要）、矛盾证据注入、逻辑保持重写（六种等价定律）、多定律等价叠加（2-5个同时变换），在BERT、Qwen2和LLaMA类模型上进行实验

Result: 所有模型在基础任务上达到完美准确率，对冗余规则删除和所有等价重写（单或多定律）完全泛化，但在必要规则删除时准确率骤降至25%，面对明确矛盾时完全崩溃（0%准确率）

Conclusion: LLMs对语义保持的逻辑变换具有稳定不变性，但对缺失或冲突证据保持根本性脆弱，该框架为诊断推理失败模式提供了清晰工具，突显了当前LLMs在逻辑泛化能力上的持久差距

Abstract: Large language models (LLMs) excel across many natural language tasks, yet their generalisation to structural perturbations in logical contexts remains poorly understood. We introduce a controlled evaluation framework that probes reasoning reliability through four targeted stress tests: (1) rule deletion, removing either redundant or essential rules from a multi-step inference chain; (2) contradictory evidence injection; (3) logic-preserving rewrites generated through several families of equivalence laws (contrapositive, double negation, implication, De Morgan, identity, and commutativity); and (4) multi-law equivalence stacking that introduces 2-5 simultaneous logical transformations.
  Across three representative model families: BERT, Qwen2, and LLaMA-like models. Our experiments reveal a strikingly consistent pattern: all models achieve perfect accuracy on the base tasks and remain fully generalise to redundant rule deletion and all equivalence-based rewrites (single or multi-law), but fail sharply under essential rule deletion (dropping to 25% accuracy) and collapse completely in the presence of explicit contradictions (0% accuracy). These results demonstrate that LLMs possess stable invariance to semantic-preserving logical transformations, yet remain fundamentally brittle to missing or conflicting evidence. Our framework provides a clean diagnostic tool for isolating such reasoning failure modes and highlights persistent gaps in the logical generalisation abilities of current LLMs.

</details>


### [179] [GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols](https://arxiv.org/abs/2512.06404)
*Mohammad Soleymanibrojeni,Roland Aydin,Diego Guedes-Sobrinho,Alexandre C. Dias,Maurício J. Piotrowski,Wolfgang Wenzel,Celso Ricardo Caldeira Rêgo*

Main category: cs.AI

TL;DR: GENIUS是一个AI驱动的自动化工作流，将人类自然语言提示转换为经过验证的量子ESPRESSO输入文件，成功率达到80%，显著降低了材料模拟的门槛。


<details>
  <summary>Details</summary>
Motivation: 材料预测性模拟需要专业计算知识，这限制了非专家使用先进的集成计算材料工程工具。需要解决设置和调试的瓶颈，使材料模拟更加民主化。

Method: GENIUS结合了智能量子ESPRESSO知识图谱、分层大语言模型层次结构，以及由有限状态错误恢复机监督的自动化修复机制。

Result: 在295个多样化基准测试中，约80%的案例成功运行，其中76%能自主修复错误。相比纯LLM基线，推理成本减半，幻觉基本消除。

Conclusion: 该框架通过智能自动化协议生成、验证和修复，民主化了电子结构DFT模拟，为学术界和工业界的大规模筛选和ICME设计循环开辟了新途径。

Abstract: Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide.

</details>


### [180] [UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems](https://arxiv.org/abs/2512.06406)
*Xianzong Wu,Xiaohong Li,Lili Quan,Qiang Hu*

Main category: cs.AI

TL;DR: UncertaintyZoo是一个统一的不确定性量化工具包，集成了29种方法，用于评估大语言模型输出的置信度，并在代码漏洞检测任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在安全关键场景中可能做出错误预测，导致潜在损失。虽然已有多种不确定性量化方法，但缺乏集成工具，阻碍了这些方法的实际应用和未来研究。

Method: 开发UncertaintyZoo工具包，统一集成29种不确定性量化方法，涵盖五大类别，提供标准化接口。在CodeBERT和ChatGLM3模型上进行代码漏洞检测任务评估。

Result: UncertaintyZoo能够有效揭示模型预测的不确定性，为评估大语言模型输出的置信度提供了实用工具。

Conclusion: UncertaintyZoo填补了不确定性量化工具集的空白，促进了相关方法的实际应用和未来研究，特别是在安全关键场景中评估大语言模型输出的可靠性。

Abstract: Large language models(LLMs) are increasingly expanding their real-world applications across domains, e.g., question answering, autonomous driving, and automatic software development. Despite this achievement, LLMs, as data-driven systems, often make incorrect predictions, which can lead to potential losses in safety-critical scenarios. To address this issue and measure the confidence of model outputs, multiple uncertainty quantification(UQ) criteria have been proposed. However, even though important, there are limited tools to integrate these methods, hindering the practical usage of UQ methods and future research in this domain. To bridge this gap, in this paper, we introduce UncertaintyZoo, a unified toolkit that integrates 29 uncertainty quantification methods, covering five major categories under a standardized interface. Using UncertaintyZoo, we evaluate the usefulness of existing uncertainty quantification methods under the code vulnerability detection task on CodeBERT and ChatGLM3 models. The results demonstrate that UncertaintyZoo effectively reveals prediction uncertainty. The tool with a demonstration video is available on the project site https://github.com/Paddingbuta/UncertaintyZoo.

</details>


### [181] [Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City](https://arxiv.org/abs/2512.06431)
*Mohamed Shamroukh,Mohamed Alkhuzamy Aziz*

Main category: cs.AI

TL;DR: 该研究为埃及基纳市开发了一个定制化的城市规划模型，使用基于Voronoi图的智能空间分析算法，评估公共服务覆盖率，发现平均覆盖率为81.3%，救护车站效率最高(99.8%)，公园覆盖率最低(10%)。


<details>
  <summary>Details</summary>
Motivation: 埃及国家公共服务规划标准往往无法适应地方独特特征，存在规划标准与地方特点不匹配的问题，需要开发针对特定城市的定制化规划模型。

Method: 采用混合方法（描述性、分析性和实验性），使用Python编程开发基于Voronoi图的智能空间分析算法，创建城市特定的规划标准并评估现有公共设施覆盖率。

Result: 应用模型显示平均服务覆盖率为81.3%，救护车站效率最高(99.8%)，公园和开放空间覆盖率最低(10%)；市中心服务密度高(>45个/km²)，郊区显著降低(<5个/km²)；Hajer Qena区未服务区域最多，第一区服务覆盖率最高。

Conclusion: 成功开发了本地化规划标准模型和自动化评估算法，为埃及城市提供了可复制的数据驱动城市规划框架，能够更精准地评估和优化公共服务分布。

Abstract: National planning standards for public services in Egypt often fail to align with unique local characteristics. Addressing this gap, this study develops a tailored planning model for Qena City. Using a hybrid methodology (descriptive, analytical, and experimental), the research utilizes Python programming to generate an intelligent spatial analysis algorithm based on Voronoi Diagrams. This approach creates city-specific planning criteria and evaluates the current coverage of public facilities. The primary contribution of this study is the successful derivation of a localized planning standards model and the deployment of an automated algorithm to assess service efficiency. Application of this model reveals a general service coverage average of 81.3%. Ambulance stations demonstrated the highest efficiency (99.8%) due to recent upgrades, while parks and open spaces recorded the lowest coverage (10%) caused by limited land availability. Spatial analysis indicates a high service density in midtown (>45 services/km^2), which diminishes significantly towards the outskirts (<5 services/km^2). Consequently, the Hajer Qena district contains the highest volume of unserved areas, while the First District (Qesm 1) exhibits the highest level of service coverage. This model offers a replicable framework for data-driven urban planning in Egyptian cities.

</details>


### [182] [The Effect of Belief Boxes and Open-mindedness on Persuasion](https://arxiv.org/abs/2512.06573)
*Onur Bilgin,Abdullah As Sami,Sriram Sai Vujjini,John Licato*

Main category: cs.AI

TL;DR: 该研究探讨了在LLM智能体中引入信念陈述（信念盒）如何影响其行为、信念改变倾向以及在多智能体场景中的说服力，发现信念盒技术能有效影响智能体的信念抵抗和改变。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统在推理和决策应用中日益普及，需要让基于LLM的智能体具备类似命题信念的能力。研究者希望了解在提示空间中包含信念陈述（信念盒）如何影响智能体的行为、信念倾向以及在多智能体场景中的说服力，同时探索"开放心态"指令对智能体行为的影响。

Method: 通过一系列实验探索信念盒技术：在智能体的提示空间中包含信念陈述及其强度信息，研究这些陈述如何影响智能体对相反观点的抵抗和说服力；同时测试"开放心态"指令对信念改变倾向的影响；特别关注在辩论中被相反观点包围（同伴压力场景）时的信念改变可能性。

Result: 研究发现：1）指示智能体保持开放心态会影响其信念改变的倾向性；2）包含信念陈述及其强度会影响智能体对相反观点的抵抗力和说服力；3）在辩论中被相反观点包围（同伴压力场景）时，信念陈述会影响信念改变的可能性；4）信念盒技术在推理和决策任务中具有可行性和有效性。

Conclusion: 信念盒技术能够有效影响LLM智能体的信念相关行为，包括信念改变倾向、对相反观点的抵抗力和说服力，特别是在多智能体交互场景中。该技术为构建具有更稳定信念系统的智能体提供了可行方法。

Abstract: As multi-agent systems are increasingly utilized for reasoning and decision-making applications, there is a greater need for LLM-based agents to have something resembling propositional beliefs. One simple method for doing so is to include statements describing beliefs maintained in the prompt space (in what we'll call their belief boxes). But when agents have such statements in belief boxes, how does it actually affect their behaviors and dispositions towards those beliefs? And does it significantly affect agents' ability to be persuasive in multi-agent scenarios? Likewise, if the agents are given instructions to be open-minded, how does that affect their behaviors? We explore these and related questions in a series of experiments. Our findings confirm that instructing agents to be open-minded affects how amenable they are to belief change. We show that incorporating belief statements and their strengths influences an agent's resistance to (and persuasiveness against) opposing viewpoints. Furthermore, it affects the likelihood of belief change, particularly when the agent is outnumbered in a debate by opposing viewpoints, i.e., peer pressure scenarios. The results demonstrate the feasibility and validity of the belief box technique in reasoning and decision-making tasks.

</details>


### [183] [FlatFormer: A Flat Transformer Knowledge Tracing Model Based on Cognitive Bias Injection](https://arxiv.org/abs/2512.06629)
*Xiao-li Xia,Hou-biao Li*

Main category: cs.AI

TL;DR: FlatFormer提出了一种扁平化Transformer架构，通过信息注入而非结构堆叠来解决知识追踪中的"性能-复杂度陷阱"，在保持高性能的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 知识追踪模型面临"性能-复杂度陷阱"：捕捉复杂认知动态（如学习会话和记忆衰减）需要深层层次架构，但这会导致实时部署时计算成本过高。需要一种既能保持高性能又计算效率高的解决方案。

Method: 提出FlatFormer架构，采用"信息注入而非结构堆叠"的设计范式。具体包括：(1) 混合输入编码策略：结合可学习的会话标识符和固定的正弦步长嵌入；(2) 预计算的幂律偏置直接集成到注意力对数中，显式建模遗忘曲线。

Result: 在四个大规模数据集（如EdNet、Junyi）上的实验表明，FlatFormer达到最先进性能。在EdNet数据集上，相比最强的层次基线（HiTSKT），绝对AUC提升8.3%，参数使用量不到15%，推理速度约快3倍。

Conclusion: 高认知保真度不需要架构复杂性。FlatFormer通过信息注入而非结构堆叠，在保持高性能的同时显著降低了计算复杂度，解决了知识追踪中的性能-复杂度权衡问题。

Abstract: Knowledge Tracing (KT) models face a critical ``Performance-Complexity Trap'': capturing complex cognitive dynamics like learning sessions and memory decay typically requires deep hierarchical architectures, which incur prohibitive computational costs for real-time deployment. To resolve this, we propose FlatFormer, a streamlined architecture based on the novel design paradigm of ``Information Injection over Structural Stacking.'' Unlike parameter-heavy hierarchical models, FlatFormer leverages a standard flat Transformer augmented with two lightweight injection mechanisms: (i) a hybrid input encoding strategy combining learnable session identifiers with fixed sinusoidal step embeddings; and (ii) a pre-computed power-law bias integrated directly into attention logits to explicitly model the forgetting curve. Extensive experiments on four large-scale datasets (e.g., EdNet, Junyi) show that FlatFormer achieves state-of-the-art performance. For example, on the EdNet dataset, compared to the strongest hierarchical baseline (HiTSKT), its absolute AUC increased by 8.3%, while using less than 15% of parameters, and inference speed was about three times faster. These results validate that high cognitive fidelity does not necessitate architectural complexity.

</details>


### [184] [LightSearcher: Efficient DeepSearch via Experiential Memory](https://arxiv.org/abs/2512.06653)
*Hengzhi Lan,Yue Yu,Li Qian,Li Peng,Jie Wu,Wei Liu,Jian Luan,Ting Bai*

Main category: cs.AI

TL;DR: LightSearcher是一个高效的强化学习框架，通过结合文本经验记忆和自适应奖励机制，在保持准确性的同时显著减少DeepSearch范式中的工具调用次数和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的RL驱动的DeepSearch系统存在准确性-效率的跷跷板权衡：频繁调用搜索工具可以提高事实正确性，但会导致不必要的计算开销和效率下降。需要解决这一挑战。

Method: 提出了LightSearcher框架：1) 通过对比学习推理轨迹来生成可解释的成功推理模式摘要，实现文本经验记忆；2) 采用自适应奖励塑造机制，仅在正确答案场景中惩罚冗余工具调用。

Result: 在四个多跳QA基准测试中，LightSearcher保持了与SOTA基线ReSearch相当的准确性，同时将搜索工具调用减少了39.6%，推理时间减少了48.6%，token消耗减少了21.2%。

Conclusion: LightSearcher通过创新的文本经验记忆和自适应奖励机制，有效平衡了DeepSearch范式中的准确性-效率权衡，实现了高效且准确的推理。

Abstract: DeepSearch paradigms have become a core enabler for deep reasoning models, allowing them to invoke external search tools to access up-to-date, domain-specific knowledge beyond parametric boundaries, thereby enhancing the depth and factual reliability of reasoning. Building upon this foundation, recent advances in reinforcement learning (RL) have further empowered models to autonomously and strategically control search tool usage, optimizing when and how to query external knowledge sources. Yet, these RL-driven DeepSearch systems often reveal a see-saw trade-off between accuracy and efficiency-frequent tool invocations can improve factual correctness but lead to unnecessary computational overhead and diminished efficiency. To address this challenge, we propose LightSearcher, an efficient RL framework that incorporates textual experiential memory by learning contrastive reasoning trajectories to generate interpretable summaries of successful reasoning patterns. In addition, it employs an adaptive reward shaping mechanism that penalizes redundant tool calls only in correct-answer scenarios. This design effectively balances the inherent accuracy-efficiency trade-off in DeepSearch paradigms. Experiments on four multi-hop QA benchmarks show that LightSearcher maintains accuracy comparable to SOTA baseline ReSearch, while reducing search tool invocations by 39.6%, inference time by 48.6%, and token consumption by 21.2%, demonstrating its superior efficiency.

</details>


### [185] [Academic journals' AI policies fail to curb the surge in AI-assisted academic writing](https://arxiv.org/abs/2512.06705)
*Yongyuan He,Yi Bu*

Main category: cs.AI

TL;DR: 对5114种期刊和520万篇论文的分析显示，尽管70%的期刊采用了AI使用政策（主要是要求披露），但研究人员对AI写作工具的使用在各学科中急剧增加，有政策与无政策的期刊之间无显著差异。非英语国家、物理科学和高OA期刊增长最快，但透明度存在巨大差距：2023年以来发表的7.5万篇论文中，只有76篇（0.1%）明确披露了AI使用。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在学术写作中的快速整合，期刊和出版商纷纷出台政策应对，但这些政策的实际效果尚不明确。本研究旨在评估AI使用指南在现实世界中的影响。

Method: 分析了5,114种期刊和超过520万篇论文，通过大规模数据分析评估AI政策的实际效果。特别对164,000篇科学出版物进行了全文分析，重点关注2023年以来发表的论文中AI使用披露情况。

Result: 1. 尽管70%的期刊采用了AI政策（主要是要求披露），但研究人员对AI写作工具的使用在各学科中急剧增加；2. 有政策与无政策的期刊之间在AI使用率上无显著差异；3. 非英语国家、物理科学和高开放获取（OA）期刊的AI使用增长最快；4. 透明度存在巨大差距：2023年以来发表的75,000篇论文中，只有76篇（0.1%）明确披露了AI使用。

Conclusion: 当前的AI使用政策在促进透明度或限制AI采用方面基本失败。需要重新评估伦理框架，以促进AI在科学中的负责任整合。

Abstract: The rapid integration of generative AI into academic writing has prompted widespread policy responses from journals and publishers. However, the effectiveness of these policies remains unclear. Here, we analyze 5,114 journals and over 5.2 million papers to evaluate the real-world impact of AI usage guidelines. We show that despite 70% of journals adopting AI policies (primarily requiring disclosure), researchers' use of AI writing tools has increased dramatically across disciplines, with no significant difference between journals with or without policies. Non-English-speaking countries, physical sciences, and high-OA journals exhibit the highest growth rates. Crucially, full-text analysis on 164k scientific publications reveals a striking transparency gap: Of the 75k papers published since 2023, only 76 (0.1%) explicitly disclosed AI use. Our findings suggest that current policies have largely failed to promote transparency or restrain AI adoption. We urge a re-evaluation of ethical frameworks to foster responsible AI integration in science.

</details>


### [186] [Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning](https://arxiv.org/abs/2512.06835)
*Tingyu Li,Zheng Sun,Jingxuan Wei,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.AI

TL;DR: DoGe提出了一种双解耦框架，通过将学习过程分解为思考者和解决者两个组件，解决视觉语言模型在强化学习中面临的奖励破解问题，并构建了演化课程学习管道来增加训练数据多样性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型通过强化学习实现自我演化，但在专业领域（如化学、地球科学、多模态数学）面临高质量多模态数据稀缺的问题。现有方法如合成数据和自奖励机制存在分布有限和对齐困难，导致奖励破解问题——模型利用高奖励模式，导致策略熵崩溃和训练不稳定。

Method: DoGe采用双解耦框架：1）将学习过程分解为思考者和解决者两个组件，引导模型首先从上下文学习而非直接解决问题；2）提出两阶段强化学习后训练方法，从自由探索上下文到实际解决任务；3）构建演化课程学习管道，包括扩展的本地领域知识语料库和迭代演化的种子问题池。

Result: 实验表明，该方法在各种基准测试中持续优于基线方法，为实现自我演化的大型视觉语言模型提供了可扩展的途径。

Conclusion: DoGe通过双解耦框架解决了视觉语言模型强化学习中的奖励破解问题，通过合理的奖励信号量化和演化课程学习，为专业领域的大视觉语言模型自我演化提供了有效的解决方案。

Abstract: Recent vision-language models (VLMs) achieve remarkable reasoning through reinforcement learning (RL), which provides a feasible solution for realizing continuous self-evolving large vision-language models (LVLMs) in the era of experience. However, RL for VLMs requires abundant high-quality multimodal data, especially challenging in specialized domains like chemistry, earth sciences, and multimodal mathematics. Existing strategies such as synthetic data and self-rewarding mechanisms suffer from limited distributions and alignment difficulties, ultimately causing reward hacking: models exploit high-reward patterns, collapsing policy entropy and destabilizing training. We propose DoGe (Decouple to Generalize), a dual-decoupling framework that guides models to first learn from context rather than problem solving by refocusing on the problem context scenarios overlooked by synthetic data methods. By decoupling learning process into dual components (Thinker and Solver), we reasonably quantify the reward signals of this process and propose a two-stage RL post-training approach from freely exploring context to practically solving tasks. Second, to increase the diversity of training data, DoGe constructs an evolving curriculum learning pipeline: an expanded native domain knowledge corpus and an iteratively evolving seed problems pool. Experiments show that our method consistently outperforms the baseline across various benchmarks, providing a scalable pathway for realizing self-evolving LVLMs.

</details>


### [187] [JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models](https://arxiv.org/abs/2512.06859)
*Ce Chi,Xing Wang,Zhendong Wang,Xiaofan Liu,Ce Li,Zhiyan Song,Chen Zhao,Kexin Yang,Boshen Shi,Jingjing Yang,Chao Deng,Junlan Feng*

Main category: cs.AI

TL;DR: JT-DA-8B是一个专门用于复杂表格推理任务的8B参数大语言模型，通过构建包含34个表格推理任务的多样化训练语料，结合SFT和RL优化，在多种表格推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前在表格推理场景中缺乏高质量的监督数据，需要构建专门针对复杂表格推理任务的大语言模型，以应对现实世界多样化的表格分析需求。

Method: 1. 构建包含34个表格推理任务的多样化训练语料，整合29个公开表格QA数据集和300万张表格；2. 提出自动流水线生成现实的多步分析任务；3. 基于开源JT-Coder-8B模型，采用LLM评分和工作流对齐过滤来蒸馏高质量表格中心数据；4. 结合监督微调(SFT)和强化学习(RL)优化模型；5. 提出四阶段表格推理工作流：表格预处理、表格感知、工具集成推理和提示工程。

Result: JT-DA-8B在各种表格推理任务中取得了强劲的性能表现，证明了数据中心的生成方法和工作流驱动的优化策略的有效性。

Conclusion: 通过构建高质量的表格推理训练语料和系统性的工作流优化，JT-DA-8B模型能够有效处理复杂的表格推理任务，为现实世界的表格分析提供了有效的解决方案。

Abstract: In this work, we present JT-DA-8B (JiuTian Data Analyst 8B), a specialized large language model designed for complex table reasoning tasks across diverse real-world scenarios. To address the lack of high-quality supervision in tabular reasoning scenarios, we construct a comprehensive and diverse training corpus with 34 well-defined table reasoning tasks, by aggregating 29 public table QA datasets and 3 million tables. An automatic pipeline is proposed to generate realistic multi-step analytical tasks involving reasoning patterns. The model is trained upon open-source JT-Coder-8B model, an 8B-parameter decoder-only foundation model trained from scratch. In the training stage, we leverage LLM-based scoring and workflow-aligned filtering to distill high-quality, table-centric data. Both supervised fine-tuning (SFT) and Reinforcement learning (RL) are adopted to optimize our model. Afterwards, a four-stage table reasoning workflow is proposed, including table preprocessing, table sensing, tool-integrated reasoning, and prompt engineering, to improve model interpretability and execution accuracy. Experimental results show that JT-DA-8B achieves strong performance in various table reasoning tasks, demonstrating the effectiveness of data-centric generation and workflow-driven optimization.

</details>


### [188] [Do Persona-Infused LLMs Affect Performance in a Strategic Reasoning Game?](https://arxiv.org/abs/2512.06867)
*John Licato,Stephen Steinle,Brayden Hollis*

Main category: cs.AI

TL;DR: 研究探讨了在大型语言模型中使用角色提示是否能在对抗性战略环境中产生可测量的行为差异，发现通过中介翻译过程将角色转化为启发式值可以提升游戏表现。


<details>
  <summary>Details</summary>
Motivation: 虽然角色提示在大型语言模型中似乎能触发不同的文本生成风格，但尚不清楚这些差异是否能转化为可测量的行为差异，特别是在对抗性战略环境中的决策影响。

Method: 在PERIL世界统治棋盘游戏中研究角色提示对战略表现的影响，比较角色衍生的启发式策略与手动选择的策略。引入基于探索性因子分析的结构化翻译过程作为中介，将LLM生成的清单响应映射为启发式值。

Result: 研究发现某些与战略思维相关的角色能提高游戏表现，但仅当使用中介将角色翻译为启发式值时有效。该方法相比直接推断的启发式方法，增强了启发式的可靠性和表面效度。

Conclusion: 研究推进了对角色提示如何影响基于LLM的决策的理解，并提出了一种将心理测量学原理应用于LLM的启发式生成方法。

Abstract: Although persona prompting in large language models appears to trigger different styles of generated text, it is unclear whether these translate into measurable behavioral differences, much less whether they affect decision-making in an adversarial strategic environment that we provide as open-source. We investigate the impact of persona prompting on strategic performance in PERIL, a world-domination board game. Specifically, we compare the effectiveness of persona-derived heuristic strategies to those chosen manually. Our findings reveal that certain personas associated with strategic thinking improve game performance, but only when a mediator is used to translate personas into heuristic values. We introduce this mediator as a structured translation process, inspired by exploratory factor analysis, that maps LLM-generated inventory responses into heuristics. Results indicate our method enhances heuristic reliability and face validity compared to directly inferred heuristics, allowing us to better study the effect of persona types on decision making. These insights advance our understanding of how persona prompting influences LLM-based decision-making and propose a heuristic generation method that applies psychometric principles to LLMs.

</details>


### [189] [On Memory: A comparison of memory mechanisms in world models](https://arxiv.org/abs/2512.06983)
*Eli J. Laird,Corey Clark*

Main category: cs.AI

TL;DR: 该论文研究了基于Transformer的世界模型的有效记忆跨度问题，分析了多种记忆增强机制，提出了记忆编码与记忆注入的分类方法，并通过状态回忆任务评估了不同机制的性能。


<details>
  <summary>Details</summary>
Motivation: 世界模型能够让智能体在想象环境中进行规划，但基于Transformer架构的有效记忆跨度限制了其在长时程规划中的能力，导致长轨迹生成中的感知漂移问题，阻碍了模型在想象轨迹中完成闭环检测。

Method: 1. 分析多种记忆增强机制的有效记忆跨度；2. 提出区分记忆编码和记忆注入机制的分类法；3. 从残差流动态角度理解这些机制如何扩展世界模型的记忆；4. 使用状态回忆评估任务测量每种机制的记忆回忆能力并分析各自的权衡。

Result: 研究发现记忆机制能够提升视觉Transformer的有效记忆跨度，并为在世界模型想象中完成闭环检测提供了路径。

Conclusion: 通过系统分析记忆增强机制，该研究为改善基于Transformer的世界模型的长时程规划能力提供了理论基础和方法指导，特别是在解决感知漂移和实现闭环检测方面具有重要意义。

Abstract: World models enable agents to plan within imagined environments by predicting future states conditioned on past observations and actions. However, their ability to plan over long horizons is limited by the effective memory span of the backbone architecture. This limitation leads to perceptual drift in long rollouts, hindering the model's capacity to perform loop closures within imagined trajectories. In this work, we investigate the effective memory span of transformer-based world models through an analysis of several memory augmentation mechanisms. We introduce a taxonomy that distinguishes between memory encoding and memory injection mechanisms, motivating their roles in extending the world model's memory through the lens of residual stream dynamics. Using a state recall evaluation task, we measure the memory recall of each mechanism and analyze its respective trade-offs. Our findings show that memory mechanisms improve the effective memory span in vision transformers and provide a path to completing loop closures within a world model's imagination.

</details>


### [190] [ClinNoteAgents: An LLM Multi-Agent System for Predicting and Interpreting Heart Failure 30-Day Readmission from Clinical Notes](https://arxiv.org/abs/2512.07081)
*Rongjia Zhou,Chengzhuo Li,Carl Yang,Jiaying Lu*

Main category: cs.AI

TL;DR: 本文提出了ClinNoteAgents框架，利用LLM多智能体系统从临床自由文本笔记中提取心衰再入院风险因素，实现结构化表示和风险预测，减少对结构化字段和人工标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 心衰是美国老年人再住院的主要原因之一。临床笔记包含丰富的患者信息，占电子健康记录的大部分，但在心衰再入院风险分析中未得到充分利用。传统模型依赖专家规则、医学术语库和本体论来解释临床笔记，但这些笔记通常存在拼写错误、缩写和领域特定术语。

Method: 提出ClinNoteAgents框架，这是一个基于LLM的多智能体系统，能够将自由文本临床笔记转化为：(1) 临床和社会风险因素的结构化表示用于关联分析；(2) 临床医生风格的抽象表示用于心衰30天再入院预测。

Result: 在3,544份来自2,065名患者（再入院率35.16%）的笔记上评估ClinNoteAgents，结果显示在从自由文本提取风险因素、识别关键贡献因素和预测再入院风险方面表现优异。

Conclusion: 通过减少对结构化字段的依赖并最小化人工标注和模型训练，ClinNoteAgents为数据有限的医疗系统提供了可扩展且可解释的基于笔记的心衰再入院风险建模方法。

Abstract: Heart failure (HF) is one of the leading causes of rehospitalization among older adults in the United States. Although clinical notes contain rich, detailed patient information and make up a large portion of electronic health records (EHRs), they remain underutilized for HF readmission risk analysis. Traditional computational models for HF readmission often rely on expert-crafted rules, medical thesauri, and ontologies to interpret clinical notes, which are typically written under time pressure and may contain misspellings, abbreviations, and domain-specific jargon. We present ClinNoteAgents, an LLM-based multi-agent framework that transforms free-text clinical notes into (1) structured representations of clinical and social risk factors for association analysis and (2) clinician-style abstractions for HF 30-day readmission prediction. We evaluate ClinNoteAgents on 3,544 notes from 2,065 patients (readmission rate=35.16%), demonstrating strong performance in extracting risk factors from free-text, identifying key contributing factors, and predicting readmission risk. By reducing reliance on structured fields and minimizing manual annotation and model training, ClinNoteAgents provides a scalable and interpretable approach to note-based HF readmission risk modeling in data-limited healthcare systems.

</details>


### [191] [ContextualSHAP : Enhancing SHAP Explanations Through Contextual Language Generation](https://arxiv.org/abs/2512.07178)
*Latifa Dwiyanti,Sergio Ryan Wibisono,Hidetaka Nambo*

Main category: cs.AI

TL;DR: 该研究开发了一个Python包，将SHAP特征重要性可视化与大型语言模型（GPT）结合，生成上下文文本解释，提高非技术用户对机器学习模型解释的理解度。


<details>
  <summary>Details</summary>
Motivation: SHAP虽然能有效可视化特征重要性，但缺乏对非技术背景终端用户有意义的上下文解释。在医疗等高风险领域部署机器学习模型时，可解释的人工智能（XAI）变得尤为重要，需要更用户友好的解释方法。

Method: 提出一个Python包，通过用户定义的参数（如特征别名、描述和附加背景信息）将SHAP与OpenAI的GPT大型语言模型集成，生成上下文化的文本解释。在医疗相关案例研究中应用该包，并通过李克特量表调查和后续访谈进行用户评估。

Result: 用户评估结果表明，与仅可视化输出相比，生成的解释被认为更容易理解和上下文更合适。虽然结果是初步的，但表明可视化与上下文文本结合可以支持更用户友好和可信的模型解释。

Conclusion: 将SHAP可视化与大型语言模型生成的上下文文本解释相结合，可以提高非技术用户对机器学习模型解释的理解度和接受度，特别是在高风险应用领域。

Abstract: Explainable Artificial Intelligence (XAI) has become an increasingly important area of research, particularly as machine learning models are deployed in high-stakes domains. Among various XAI approaches, SHAP (SHapley Additive exPlanations) has gained prominence due to its ability to provide both global and local explanations across different machine learning models. While SHAP effectively visualizes feature importance, it often lacks contextual explanations that are meaningful for end-users, especially those without technical backgrounds. To address this gap, we propose a Python package that extends SHAP by integrating it with a large language model (LLM), specifically OpenAI's GPT, to generate contextualized textual explanations. This integration is guided by user-defined parameters (such as feature aliases, descriptions, and additional background) to tailor the explanation to both the model context and the user perspective. We hypothesize that this enhancement can improve the perceived understandability of SHAP explanations. To evaluate the effectiveness of the proposed package, we applied it in a healthcare-related case study and conducted user evaluations involving real end-users. The results, based on Likert-scale surveys and follow-up interviews, indicate that the generated explanations were perceived as more understandable and contextually appropriate compared to visual-only outputs. While the findings are preliminary, they suggest that combining visualization with contextualized text may support more user-friendly and trustworthy model explanations.

</details>


### [192] [PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations](https://arxiv.org/abs/2512.07179)
*Wonbeen Lee,Channyoung Lee,Junho Sohn,Hansam Cho*

Main category: cs.AI

TL;DR: 提出PICKT模型解决知识追踪中的冷启动和输入格式限制问题，通过知识图谱处理多类型数据，提升个性化学习系统的实用性。


<details>
  <summary>Details</summary>
Motivation: 随着个性化学习需求的增长，智能辅导系统需要准确追踪学生知识状态并提供个性化学习路径。现有知识追踪模型存在输入数据格式受限、新学生/新问题冷启动问题、以及实际服务环境稳定性不足等局限性。

Method: 提出实用的互联概念知识追踪（PICKT）模型，利用知识图谱结构化概念间关系，考虑问题和概念文本信息，有效处理多种类型输入数据，解决冷启动问题。

Result: 在反映真实操作环境的实验中，模型表现出优异的性能和实用性。在两大核心冷启动挑战（新学生注册和新问题添加）上显著优于现有模型，并通过精细实验设计验证了模型的稳定性和实用性。

Conclusion: PICKT模型为下一代智能辅导系统的实际实施提供了重要的理论和技术基础，增强了在真实产品环境中的适用性。

Abstract: With the recent surge in personalized learning, Intelligent Tutoring Systems (ITS) that can accurately track students' individual knowledge states and provide tailored learning paths based on this information are in demand as an essential task. This paper focuses on the core technology of Knowledge Tracing (KT) models that analyze students' sequences of interactions to predict their knowledge acquisition levels. However, existing KT models suffer from limitations such as restricted input data formats, cold start problems arising with new student enrollment or new question addition, and insufficient stability in real-world service environments. To overcome these limitations, a Practical Interlinked Concept Knowledge Tracing (PICKT) model that can effectively process multiple types of input data is proposed. Specifically, a knowledge map structures the relationships among concepts considering the question and concept text information, thereby enabling effective knowledge tracing even in cold start situations. Experiments reflecting real operational environments demonstrated the model's excellent performance and practicality. The main contributions of this research are as follows. First, a model architecture that effectively utilizes diverse data formats is presented. Second, significant performance improvements are achieved over existing models for two core cold start challenges: new student enrollment and new question addition. Third, the model's stability and practicality are validated through delicate experimental design, enhancing its applicability in real-world product environments. This provides a crucial theoretical and technical foundation for the practical implementation of next-generation ITS.

</details>


### [193] [M-STAR: Multi-Scale Spatiotemporal Autoregression for Human Mobility Modeling](https://arxiv.org/abs/2512.07314)
*Yuxiao Luo,Songming Zhang,Sijie Ruan,Siran Chen,Kang Liu,Yang Xu,Yu Zheng,Ling Yin*

Main category: cs.AI

TL;DR: M-STAR是一个多尺度时空自回归框架，用于高效生成长时人类移动轨迹，通过从粗到细的预测过程解决现有方法在长时生成中的效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归和扩散模型的方法虽然能生成单日轨迹，但在生成长时轨迹（如周轨迹）时效率低下，且缺乏显式的时空多尺度建模能力。

Method: 提出M-STAR框架，包含多尺度时空标记器用于编码层次化移动模式，以及基于Transformer的解码器进行下一尺度自回归预测，实现从粗到细的轨迹生成。

Result: 在两个真实世界数据集上的实验表明，M-STAR在保真度上优于现有方法，并显著提高了生成速度。

Conclusion: M-STAR通过多尺度时空建模有效解决了长时轨迹生成的效率问题，为人类移动建模提供了新的高效解决方案。

Abstract: Modeling human mobility is vital for extensive applications such as transportation planning and epidemic modeling. With the rise of the Artificial Intelligence Generated Content (AIGC) paradigm, recent works explore synthetic trajectory generation using autoregressive and diffusion models. While these methods show promise for generating single-day trajectories, they remain limited by inefficiencies in long-term generation (e.g., weekly trajectories) and a lack of explicit spatiotemporal multi-scale modeling. This study proposes Multi-Scale Spatio-Temporal AutoRegression (M-STAR), a new framework that generates long-term trajectories through a coarse-to-fine spatiotemporal prediction process. M-STAR combines a Multi-scale Spatiotemporal Tokenizer that encodes hierarchical mobility patterns with a Transformer-based decoder for next-scale autoregressive prediction. Experiments on two real-world datasets show that M-STAR outperforms existing methods in fidelity and significantly improves generation speed. The data and codes are available at https://github.com/YuxiaoLuo0013/M-STAR.

</details>


### [194] [A Geometric Unification of Concept Learning with Concept Cones](https://arxiv.org/abs/2512.07355)
*Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi*

Main category: cs.AI

TL;DR: 论文通过几何框架统一了概念瓶颈模型（CBM）和稀疏自编码器（SAE）两种可解释性方法，提出两者都学习激活空间中的线性方向形成概念锥，区别仅在于如何选择这个锥。作者建立了评估SAE学习概念与CBM人工定义概念对齐程度的量化指标。


<details>
  <summary>Details</summary>
Motivation: 两种可解释性传统（CBM和SAE）各自发展但很少对话：CBM规定概念应该是什么，SAE发现概念如何涌现。需要建立统一框架来连接这两种监督和非监督的概念发现方法。

Method: 提出几何框架：CBM和SAE都学习激活空间中的线性方向，其非负组合形成概念锥。建立包含框架，用CBM提供人工定义参考几何，评估SAE学习锥与CBM锥的近似或包含程度。开发量化指标连接SAE的归纳偏置（类型、稀疏度、扩展比）与合理概念的涌现。

Result: 发现了稀疏度和扩展因子的"最佳点"，能最大化与CBM概念的几何和语义对齐。建立了连接监督和非监督概念发现的统一几何框架，提供了衡量SAE进展和评估发现概念与人工概念对齐程度的原理性指标。

Conclusion: 通过共享几何框架统一了监督和非监督概念发现，为测量SAE进展和评估发现概念与合理人类概念的对齐提供了原理性方法。两种范式在本质上相同，区别仅在于如何选择概念锥。

Abstract: Two traditions of interpretability have evolved side by side but seldom spoken to each other: Concept Bottleneck Models (CBMs), which prescribe what a concept should be, and Sparse Autoencoders (SAEs), which discover what concepts emerge. While CBMs use supervision to align activations with human-labeled concepts, SAEs rely on sparse coding to uncover emergent ones. We show that both paradigms instantiate the same geometric structure: each learns a set of linear directions in activation space whose nonnegative combinations form a concept cone. Supervised and unsupervised methods thus differ not in kind but in how they select this cone. Building on this view, we propose an operational bridge between the two paradigms. CBMs provide human-defined reference geometries, while SAEs can be evaluated by how well their learned cones approximate or contain those of CBMs. This containment framework yields quantitative metrics linking inductive biases -- such as SAE type, sparsity, or expansion ratio -- to emergence of plausible\footnote{We adopt the terminology of \citet{jacovi2020towards}, who distinguish between faithful explanations (accurately reflecting model computations) and plausible explanations (aligning with human intuition and domain knowledge). CBM concepts are plausible by construction -- selected or annotated by humans -- though not necessarily faithful to the true latent factors that organise the data manifold.} concepts. Using these metrics, we uncover a ``sweet spot'' in both sparsity and expansion factor that maximizes both geometric and semantic alignment with CBM concepts. Overall, our work unifies supervised and unsupervised concept discovery through a shared geometric framework, providing principled metrics to measure SAE progress and assess how well discovered concept align with plausible human concepts.

</details>


### [195] [LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services](https://arxiv.org/abs/2512.07436)
*Hang He,Chuhuai Yue,Chengqi Dong,Mingxue Tian,Zhenfeng Liu,Jiajun Chai,Xiaohan Wang,Yufei Zhang,Qun Liao,Guojun Yin,Wei Lin,Chengcheng Wan,Haiying Sun,Ting Su*

Main category: cs.AI

TL;DR: LocalSearchBench是首个针对本地生活服务的智能搜索基准测试，包含超过15万条高质量数据，构建了300个多跳问答任务，实验显示即使是当前最先进的大模型在该领域表现也较差。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在通用信息检索方面取得进展，但很少探索具有独特挑战的垂直领域。本地生活服务领域的查询通常模糊且需要跨商家和产品的多跳推理，现有研究未能充分解决这些问题。

Method: 构建LocalSearchBench基准测试，包含来自不同城市和业务类型的超过15万条高质量条目；基于真实用户查询构建300个多跳问答任务；开发LocalPlayground统一环境，集成多种工具供智能体交互。

Result: 实验显示即使最先进的模型（DeepSeek-V3.1）在LocalSearchBench上正确率仅为34.34%，大多数模型在完整性（平均77.33%）和忠实性（平均61.99%）方面存在问题，表明该领域的挑战性。

Conclusion: 本地生活服务领域需要专门的基准测试和领域特定的智能体训练，现有模型在该领域表现不足，凸显了进一步研究和改进的必要性。

Abstract: Recent advances in large reasoning models (LRMs) have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often ambiguous and require multi-hop reasoning across merchants and products, remaining challenging and not fully addressed. As the first comprehensive benchmark for agentic search in local life services, LocalSearchBench includes over 150,000 high-quality entries from various cities and business types. We construct 300 multi-hop QA tasks based on real user queries, challenging agents to understand questions and retrieve information in multiple steps. We also developed LocalPlayground, a unified environment integrating multiple tools for agent interaction. Experiments show that even state-of-the-art LRMs struggle on LocalSearchBench: the best model (DeepSeek-V3.1) achieves only 34.34% correctness, and most models have issues with completeness (average 77.33%) and faithfulness (average 61.99%). This highlights the need for specialized benchmarks and domain-specific agent training in local life services. Code, Benchmark, and Leaderboard are available at localsearchbench.github.io.

</details>


### [196] [Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement](https://arxiv.org/abs/2512.07611)
*Yongsheng Lian*

Main category: cs.AI

TL;DR: 系统比较了PPO、GRPO和DAPO三种强化学习算法在提升大语言模型复杂推理能力上的表现，通过控制迁移学习实验发现RL训练模型在所有任务上都优于基础模型，但改进程度因基准而异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索不同强化学习算法如何有效提升大语言模型的复杂推理能力，为RL-based LLM训练提供实用指导。

Method: 采用控制迁移学习评估方法：先在专门的Countdown Game上微调模型，然后在通用推理基准套件上进行评估。系统比较了PPO、GRPO和DAPO三种RL算法，并分析了组大小、KL惩罚系数等参数的影响。

Result: 所有RL训练模型在各项任务上都优于对应的基础模型。GRPO和DAPO中增加组大小能带来更稳定的训练动态和更高准确率，KL惩罚系数的影响是非单调的。DAPO中的动态采样组件并未改善性能，禁用DS时DAPO取得最佳整体结果。

Conclusion: 强化学习能有效提升大语言模型的推理能力，但不同算法和参数设置对性能有显著影响。GRPO和DAPO的组大小是关键参数，而DAPO的动态采样组件在实际应用中可能不必要。

Abstract: This study presents a systematic comparison of three Reinforcement Learning (RL) algorithms (PPO, GRPO, and DAPO) for improving complex reasoning in large language models (LLMs). Our main contribution is a controlled transfer-learning evaluation: models are first fine-tuned on the specialized Countdown Game and then assessed on a suite of general-purpose reasoning benchmarks. Across all tasks, RL-trained models outperform their corresponding base models, although the degree of improvement differs by benchmark.
  Our parametric analysis offers practical guidance for RL-based LLM training. Increasing the group size in GRPO and DAPO leads to more stable training dynamics and higher accuracy, while the impact of the KL-penalty coefficient is non-monotonic. Additionally, we find that the Dynamic Sampling (DS) component in DAPO does not improve performance; in fact, the best overall results are achieved with DAPO when DS is disabled.

</details>


### [197] [Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE](https://arxiv.org/abs/2512.07710)
*Anxiang Zeng,Haibo Zhang,Hailing Zhang,Kaixiang Mo,Liang Yao,Ling Hu,Long Zhang,Shuman Liu,Shuyi Xie,Yanshi Li,Yizhang Chen,Yuepeng Sheng,Yuwei Huang,Zhaochen Xu,Zhiqiang Zhou,Ziqin Liew*

Main category: cs.AI

TL;DR: CompassMax-V3-Thinking是一个千亿规模的MoE推理模型，采用新的RL框架训练，核心原则是"每个提示都必须重要"。通过多项创新技术解决了大规模RL训练中的效率问题，实现了稳定高效的大规模MoE模型训练。


<details>
  <summary>Details</summary>
Motivation: 将强化学习扩展到千亿规模时暴露出关键效率问题：零方差提示浪费rollout资源、长视野重要性采样不稳定、标准奖励模型导致的优势反转，以及rollout处理中的系统性瓶颈。需要解决这些问题来实现大规模MoE模型的稳定高效训练。

Method: 提出四项统一创新：1) 多阶段零方差消除，过滤非信息性提示并稳定基于组的策略优化；2) ESPO熵自适应优化方法，平衡token级和序列级重要性采样；3) 路由器重放策略，对齐训练时MoE路由器决策与推理时行为；4) 高吞吐RL系统，采用FP8精度rollout、重叠奖励计算和长度感知调度。

Result: 该模型在内部和公开评估中都表现出强大的性能，形成了一个使千亿规模MoE模型RL训练稳定高效的完整流程。

Conclusion: 通过创新的RL框架和多项技术改进，成功实现了千亿规模MoE推理模型的稳定高效训练，解决了大规模RL训练中的关键效率瓶颈问题。

Abstract: We present CompassMax-V3-Thinking, a hundred-billion-scale MoE reasoning model trained with a new RL framework built on one principle: each prompt must matter. Scaling RL to this size exposes critical inefficiencies-zero-variance prompts that waste rollouts, unstable importance sampling over long horizons, advantage inversion from standard reward models, and systemic bottlenecks in rollout processing. To overcome these challenges, we introduce several unified innovations: (1) Multi-Stage Zero-Variance Elimination, which filters out non-informative prompts and stabilizes group-based policy optimization (e.g. GRPO) by removing wasted rollouts; (2) ESPO, an entropy-adaptive optimization method that balances token-level and sequence-level importance sampling to maintain stable learning dynamics; (3) a Router Replay strategy that aligns training-time MoE router decisions with inference-time behavior to mitigate train-infer discrepancies, coupled with a reward model adjustment to prevent advantage inversion; (4) a high-throughput RL system with FP8-precision rollouts, overlapped reward computation, and length-aware scheduling to eliminate performance bottlenecks. Together, these contributions form a cohesive pipeline that makes RL on hundred-billion-scale MoE models stable and efficient. The resulting model delivers strong performance across both internal and public evaluations.

</details>


### [198] [RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2512.07761)
*Xiqiao Xiong,Ouxiang Li,Zhuo Liu,Moxin Li,Wentao Shi,Fuli Feng,Xiangnan He*

Main category: cs.AI

TL;DR: 该论文提出了一种基于强化学习的多轮越狱攻击方法，通过优化最终输出的危害性作为结果奖励，并引入两个启发式过程奖励来提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到越狱攻击的威胁，影响其在现实应用中的安全部署。现有方法通常依赖单轮优化，不足以学习长期攻击策略，因此需要研究更有效的多轮越狱方法。

Method: 将问题形式化为多轮强化学习任务，直接优化最终轮输出的危害性作为结果奖励。提出两个启发式过程奖励：1) 控制中间输出的危害性以避免触发黑盒模型的拒绝机制；2) 保持中间输出的语义相关性以避免偏离主题。

Result: 在多个基准测试上的实验结果显示，该方法在多个模型上持续提高了攻击成功率，证明了方法的有效性。

Conclusion: 提出的基于强化学习的多轮越狱攻击方法能够有效提升攻击成功率，为黑盒模型的安全评估提供了新思路，但论文包含有害内容示例需要谨慎处理。

Abstract: Large language models are vulnerable to jailbreak attacks, threatening their safe deployment in real-world applications. This paper studies black-box multi-turn jailbreaks, aiming to train attacker LLMs to elicit harmful content from black-box models through a sequence of prompt-output interactions. Existing approaches typically rely on single turn optimization, which is insufficient for learning long-term attack strategies. To bridge this gap, we formulate the problem as a multi-turn reinforcement learning task, directly optimizing the harmfulness of the final-turn output as the outcome reward. To mitigate sparse supervision and promote long-term attack strategies, we propose two heuristic process rewards: (1) controlling the harmfulness of intermediate outputs to prevent triggering the black-box model's rejection mechanisms, and (2) maintaining the semantic relevance of intermediate outputs to avoid drifting into irrelevant content. Experimental results on multiple benchmarks show consistently improved attack success rates across multiple models, highlighting the effectiveness of our approach. The code is available at https://github.com/xxiqiao/RL-MTJail. Warning: This paper contains examples of harmful content.

</details>


### [199] [ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning](https://arxiv.org/abs/2512.07795)
*Nearchos Potamitis,Lars Klein,Akhil Arora*

Main category: cs.AI

TL;DR: ReasonBENCH是首个专门量化LLM推理不稳定性的基准测试，通过多轮运行协议提供统计可靠的性能和质量指标，揭示当前推理方法普遍存在的高不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理评估主要报告单次运行的准确率，忽略了随机解码带来的内在不确定性，导致无法可靠评估方法的稳定性、可重复性和成本一致性，存在评估盲点。

Method: 提出ReasonBENCH基准测试，包含：(1)标准化推理框架、模型和任务的模块化评估库；(2)报告质量和成本统计可靠指标的多轮运行协议；(3)鼓励方差感知报告的公开排行榜。

Result: 跨不同领域任务发现，绝大多数推理策略和模型表现出高度不稳定性。即使平均性能相似的策略，置信区间宽度可能相差四倍，且性能最佳的方法通常成本更高且更不稳定。

Conclusion: 推理不稳定性损害了跨运行的可重复性和报告性能的可靠性。可重复性是可靠LLM推理的关键维度，ReasonBENCH为未来推理方法和不确定性量化技术提供了基础。

Abstract: Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [200] [Anderson localization of quantum droplets in disordered potentials](https://arxiv.org/abs/2512.06087)
*Zohra Mehri,Abdeaali Boudjemaa*

Main category: cond-mat.dis-nn

TL;DR: 研究一维量子液滴在散斑势中的安德森局域化，发现液滴宽度、密度分布、扩散指数和系数等特性随无序强度变化，观察到从超扩散到亚扩散的异常扩散行为，并发现存在临界无序强度导致安德森局域化转变。


<details>
  <summary>Details</summary>
Motivation: 研究量子液滴在无序势中的输运行为和局域化现象，探索量子多体系统在无序环境中的动力学特性，为实验观测提供理论指导。

Method: 采用广义Gross-Pitaevskii方程研究一维量子液滴在散斑势中的行为，计算液滴宽度、密度分布、扩散指数和系数以及局域化长度等物理量。

Result: 发现液滴在强无序强度下表现出从超扩散到亚扩散的异常扩散行为，存在临界无序强度导致安德森局域化转变，这些结果可通过近期实验进行可靠探测。

Conclusion: 一维量子液滴在散斑势中表现出丰富的输运行为，包括异常扩散和安德森局域化转变，为理解量子多体系统在无序环境中的行为提供了新见解。

Abstract: We study Anderson localization of a one-dimensional quantum droplet in a speckle-like potential employing the generalized Gross-Pitaevskii equation. We compute the droplet width, density profiles, diffusion exponent and coefficient, and the localization length for both small and large droplets. Interesting classes of anomalous diffusions are obtained in transport dynamics ranging from superdiffusion to subdiffusion for a strong disorder strength. We find that above a certain critical disorder strength the droplet exhibits a transition to Anderson localization. Our results can be redibly probed with recent experiments.

</details>


### [201] [Towards probing velocity distributions in dense granular matter: Utilizing Fiber Bragg Gratings](https://arxiv.org/abs/2512.07321)
*Marlo Kunzner,Luis Henriques,Fahad Puthalath,Leonardo Facchini,Mohammadhossein Shahsavari,Léa Gommeringer,Martin Angelmahr,Peidong Yu,Till Böhmer,Jan Philipp Gabriel*

Main category: cond-mat.dis-nn

TL;DR: 提出基于光纤布拉格光栅传感器的新技术，用于测量颗粒气体中粒子速度，克服了传统粒子追踪在高密度下的局限性


<details>
  <summary>Details</summary>
Motivation: 传统粒子追踪技术在中等和高粒子密度下受到限制，需要一种能在更高密度下测量颗粒速度的新方法

Method: 使用光纤布拉格光栅传感器检测粒子-光纤碰撞引起的应变脉冲，从中推导出撞击粒子的速度，应用于振动激发的颗粒系统

Result: 成功提取了颗粒系统的速度分布，并通过与传统粒子追踪测量的对比验证了FBG技术的可靠性

Conclusion: FBG传感器技术为高密度颗粒气体中粒子速度测量提供了有效的新方法，扩展了颗粒系统实验研究的可能性

Abstract: Granular gases are commonly characterized through their velocity distribution, which provides access to the granular temperature. In experiments, velocity distributions are typically obtained by particle tracking, which however becomes limited at moderate and high particle densities. As a way forward, we propose a new technique for measuring particle velocities in situ by using a Fiber Bragg Grating (FBG) sensor, which remains applicable at significantly higher particle densities.The FBG sensor detects strain pulses induced by particle-fiber collisions, from which the velocity of the impacting particle can be derived. Applying this method to an ensemble of granular particles allows to extract its velocity distributions as we present for a granular system excited by a vibrational shaker. We validate the extracted velocity distribution against conventional particle-tracking measurements, confirming the reliability of the FBG-based technique.

</details>


### [202] [Non-Hermitian off-diagonal disordered optical lattices](https://arxiv.org/abs/2512.07435)
*E. T. Kokkinakis,I. Komis,K. G. Makris,E. N. Economou*

Main category: cond-mat.dis-nn

TL;DR: 研究非厄米光子学中具有非对角无序的光学晶格，分析其光谱特性、本征模局域化及传输行为，发现新型跳跃现象


<details>
  <summary>Details</summary>
Motivation: 在非厄米光子学框架下，研究非对角无序光学晶格的光谱和动力学特性，探索与传统厄米系统不同的物理现象

Method: 研究一维和二维非厄米非对角无序光学晶格，分析本征值分布和本征模局域化特性，并与对应的厄米晶格进行比较；研究单通道激发下的传输行为

Result: 发现了纯实谱系统中的远距离区域跳跃现象，以及二维系统中首次报道的复谱诱导安德森跳跃；建立了非厄米非对角无序的参考框架

Conclusion: 为研究非厄米非对角无序建立了参考框架，为未来局域化现象研究开辟了新方向

Abstract: Within the framework of non-Hermitian photonics, we investigate the spectral and dynamical properties of one- and two-dimensional non-Hermitian off-diagonal disordered optical lattices, where randomness is applied to the couplings rather than to the on-site potential terms. We analyze eigenvalue distributions and the localization properties of the eigenmodes, comparing them with those of the corresponding Hermitian lattices. Furthermore, we study their transport behavior under single-channel excitation and identify unconventional phenomena such as jumps between distant lattice regions in systems with a purely real spectrum, as well as complex spectrum-induced Anderson jumps, reported here for the first time in two dimensions. Our results establish a reference framework for non-Hermitian off-diagonal disorder and open new directions for future studies of localization phenomena.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [203] [Thermodynamic description of world GDP distribution over countries](https://arxiv.org/abs/2512.06420)
*Klaus M. Frahm,Dima L. Shepelyansky*

Main category: cond-mat.stat-mech

TL;DR: 该研究将瑞利-金斯经典场热化概念应用于描述世界各国GDP分布，发现GDP分布呈现热化现象，并在低GDP状态出现凝聚，这解释了贫困和寡头阶段的出现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解释世界各国GDP分布的不平等现象，特别是贫困和寡头阶段的出现。作者受到多模光纤中瑞利-金斯凝聚现象的启发，认为类似的热化机制可能适用于经济系统。

Method: 采用瑞利-金斯经典场热化理论框架，将国家间的各种相互作用视为热化过程，同时保持总GDP和概率（范数）两个积分守恒。该方法借鉴了多模光纤中热化现象的理论和实验研究。

Result: 研究发现瑞利-金斯热化理论能够很好地描述过去50年世界各国GDP的分布情况。在低GDP状态出现了瑞利-金斯凝聚现象，这解释了经济系统中贫困和寡头阶段的形成。

Conclusion: 瑞利-金斯热化概念为理解世界各国GDP分布提供了新的理论框架，能够解释经济不平等现象的产生机制，特别是贫困和寡头阶段的出现，这与财富热化假说对财富分布的解释相一致。

Abstract: We apply the concept of Rayleigh-Jeans thermalization of classical fields for a description of the world Gross Domestic Product (GDP) distribution over countries. The thermalization appears due to a variety of interactions between countries with conservation of two integrals being total GDP and probability (norm). In such a case there is an emergence of Rayleigh-Jeans condensation at states with low GDP. This phenomenon has been studied theoretically and experimentally in multimode optical fibers and we argue that it is at the origin of emergence of poverty and oligarchic phases for GDP of countries. A similar phenomenon has been discussed recently in the framework of the Wealth Thermalization Hypothesis to explain the high inequality of wealth distribution in human society and companies at Stock Exchange markets. We show that the Rayleigh-Jeans thermalization well describes the GDP distribution during the last 50 years.

</details>


### [204] [Convective Viscous Cahn-Hilliard/Allen-Cahn Equation with memory effects](https://arxiv.org/abs/2512.06508)
*P. O. Mchedlov-Petrosyan,L. N. Davydov*

Main category: cond-mat.stat-mech

TL;DR: 研究考虑记忆效应的对流-粘性Cahn-Hilliard/Allen-Cahn方程，获得精确解并分析外场、耗散和记忆的联合作用


<details>
  <summary>Details</summary>
Motivation: Cahn-Hilliard和Allen-Cahn方程的组合可用于描述表面过程（如同时吸附/解吸和表面扩散），但需要考虑对流、粘性和记忆效应的影响

Method: 研究考虑记忆效应的对流-粘性Cahn-Hilliard/Allen-Cahn方程，通过数学方法获得精确解

Result: 获得了该方程的精确解，并讨论了外场、耗散和记忆效应的联合作用机制

Conclusion: 对流-粘性Cahn-Hilliard/Allen-Cahn方程结合记忆效应能够更全面地描述表面过程，精确解的获得有助于深入理解各物理因素的相互作用

Abstract: The combination of the well-known Cahn-Hilliard and Allen-Cahn equations is used to describe surface processes, such as simultaneous adsorption/desorption and surface diffusion. In the present paper we have considered the convective-viscous Cahn-Hilliard/Allen-Cahn equation complemented by memory effects. Exact solutions are obtained and the combined action of the applied field, dissipation and memory are discussed.

</details>


### [205] [Free energy dissipation and a decomposition of general jump diffusions on $\mathbb{R}^n$ without detailed balance](https://arxiv.org/abs/2512.06839)
*Shuyuan Fan,Qi Zhang*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究了结合布朗运动和泊松噪声的跳跃扩散过程的热力学结构，这类随机动力学在非平衡统计物理中很重要。文章推导了自由能的完整耗散公式，并分解为熵产生和管家热。核心结果是将生成元分解为关于稳态测度的对称和反对称部分。


<details>
  <summary>Details</summary>
Motivation: 研究结合布朗运动和泊松噪声的跳跃扩散过程的热力学结构，这类非局部动力学在非平衡统计物理中具有重要意义。需要理解这类系统的自由能耗散机制和非平衡稳态的结构。

Method: 分析跳跃扩散过程的生成元，将其分解为关于稳态测度的对称和反对称部分。对称部分对应可逆动力学，反对称部分生成保守流。通过数值例子验证分解方法。

Result: 推导出自由能的完整耗散公式，分解为熵产生和管家热。证明生成元可以分解为对称和反对称部分，对称部分控制自由能衰减（非局部Fisher信息），反对称部分产生循环但不耗散。数值例子展示了分解如何阐明跳跃驱动系统中非平衡稳态的结构。

Conclusion: 该研究为跳跃扩散过程的热力学结构提供了系统的理论框架，生成元分解方法能够清晰地区分可逆和不可逆动力学成分，有助于理解非平衡稳态的形成机制和耗散特性。

Abstract: We analyze the thermodynamic structure of jump diffusions combining Brownian and Poisson noise, a class of stochastic dynamics relevant to nonequilibrium statistical physics. For such nonlocal dynamics, the free energy admits a full dissipation formula that decomposes into entropy production and housekeeping heat. A central result is a decomposition of the generator into symmetric and anti-symmetric parts with respect to the invariant measure $ρ_{ss}$. The symmetric sector corresponds to a reversible dynamics and yields a nonlocal Fisher information governing free-energy decay, whereas the anti-symmetric sector generates a canonical conservative flow that produces circulation but no dissipation. Several numerical examples demonstrate how this decomposition clarifies the structure of nonequilibrium stationary states in jump-driven systems.

</details>


### [206] [Geometry protected probabilistic structure in many-body dynamics](https://arxiv.org/abs/2512.06894)
*Yue Liu,Chushun Tian,Dahai He*

Main category: cond-mat.stat-mech

TL;DR: 论文揭示了哈密顿系统中普遍存在的测度集中现象，该结构受相空间几何保护且不受遍历性破坏影响，导致反直觉现象：孤立FPUT系统表现为热理想气体，而孤立GPE系统通过非线性波局域化避免了紫外灾难。


<details>
  <summary>Details</summary>
Motivation: 统计力学虽然绕过了处理多体动力学的艰巨任务，但从哈密顿方程推导孤立系统的宏观性质仍是挑战。随着统计现象焦点从虚构系综转向单个孤立系统，解决这一长期问题（希尔伯特第六问题的一部分）变得尤为重要。

Method: 研究两个系统家族的哈密顿动力学：有限维且（几乎）遍历的Fermi-Pasta-Ulam-Tsingou（FPUT）模型，以及无限维且遭受强遍历性破坏的Gross-Pitaevskii方程（GPE）。分析它们共同的概率结构——测度集中现象。

Result: 发现测度集中结构受相空间几何保护，对遍历性破坏免疫。孤立FPUT系统即使存在强模态相互作用也表现为热理想气体，热化时间类似于量子混沌中的Ehrenfest时间。孤立GPE系统在没有量子输入的情况下，通过模态空间中的非线性波局域化避免了紫外灾难，Rayleigh-Jeans平衡在局域化体积中建立。

Conclusion: 测度集中是哈密顿动力学中的普遍结构，不受遍历性影响，能解释反直觉的统计现象。这一发现可能在非线性光学和冷原子动力学中有应用价值。

Abstract: Insomuch as statistical mechanics circumvents the formidable task of addressing many-body dynamics, it remains a challenge to derive macroscopic properties from a solution to Hamiltonian equations for microscopic motion of an isolated system. Launching new attacks on this long-standing problem -- part of Hilbert's sixth problem -- is urgently important, for focus of statistical phenomena is shifting from a fictitious ensemble to an individual member, i.e. a mechanically isolated system. Here we uncover a common probabilistic structure, the concentration of measure, in Hamiltonian dynamics of two families of systems, the Fermi-Pasta-Ulam-Tsingou (FPUT) model which is finite-dimensional and (almost) ergodic, and the Gross-Pitaevskii equation (GPE) which is infinite-dimensional and suffers strong ergodicity breaking. That structure is protected by the geometry of phase space and immune to ergodicity breaking, leading to counterintuitive phenomena. Notably, an isolated FPUT behaves as a thermal ideal gas even for strong modal interaction, with the thermalization time analogous to the Ehrenfest time in quantum chaos, while an isolated GPE system, without any quantum inputs, escapes the celebrated ultraviolet catastrophe through nonlinear wave localization in the mode space, and the Rayleigh-Jeans equilibrium sets in the localization volume. Our findings may have applications in nonlinear optics and cold-atom dynamics.

</details>


### [207] [Self-organized criticality in complex model ecosystems](https://arxiv.org/abs/2512.06961)
*Thibaut Arnoulx de Pirey*

Main category: cond-mat.stat-mech

TL;DR: 空间扩展的多物种种群动力学模型在物种数量无限时，种群大小的相关函数呈现无标度特征


<details>
  <summary>Details</summary>
Motivation: 研究具有随机相互作用的Lotka-Volterra等多物种种群动力学模型在空间扩展情况下的统计特性，特别是相关函数的标度行为

Method: 使用动力学平均场理论，将多物种系统描述为具有人口统计和环境噪声的单物种动力学，分析随机质量项和随机时空平均增长率的影响

Result: 单物种模型具有随机质量项，使某些物种接近灭绝阈值，产生越来越大的相关时间和长度标度，导致种群大小波动呈现无标度相关

Conclusion: 这些相关函数由三维空间中的定向渗流指数描述，但在低维空间中不适用，揭示了多物种生态系统中的普遍标度行为

Abstract: We show that spatial extensions of many-species population dynamics models, such as the Lotka-Volterra model with random interactions we focus on in this work, generically exhibit scale-free correlation functions of population sizes in the limit of an infinite number of species. Using dynamical mean-field theory, we describe the many-species system in terms of single-species dynamics with demographic and environmental noises. We show that the single-species model features a random mass term, or equivalently a random space-time averaged growth rate, poising some species very close to extinction. This introduces a hierarchy of ever larger correlation times and lengths as the extinction threshold is approached. In turn, every species, even those far from extinction, are coupled to these near-critical fields which combine to make fluctuations of population sizes generically scale-free. We argue that these correlations are described by exponents derived from those of directed percolation in spatial dimension $d=3$, but not in lower dimensions.

</details>


### [208] [Statistical structural properties of many-body chaotic eigenfunctions and applications](https://arxiv.org/abs/2512.07016)
*Wen-ge Wang,Qingchen Li,Jiaozi Wang,Xiao Wang*

Main category: cond-mat.stat-mech

TL;DR: 本文使用半微扰理论研究多体量子混沌系统中能量本征函数的统计结构特性，重点关注中心系统与环境耦合的情况。


<details>
  <summary>Details</summary>
Motivation: 研究多体量子混沌系统中能量本征函数的统计结构特性，特别是当中心系统与环境耦合时，理解本征函数在系统-环境乘积基上的分布规律。

Method: 采用半微扰理论，在特定假设下推导能量本征函数在系统-环境乘积基上的平均形状和统计涨落，并将结果应用于两个基本问题。

Result: 得到了能量本征函数统计特性的理论结果，并应用于：(1) 本征态中中心系统的约化密度矩阵性质；(2) 本征态热化假说框架下的非对角光滑函数结构。数值结果支持主要发现。

Conclusion: 通过半微扰理论成功描述了多体量子混沌系统中能量本征函数的统计结构特性，为理解本征态热化和约化密度矩阵性质提供了理论框架。

Abstract: In this paper, we employ a semiperturbative theory to study the statistical structural properties of energy eigenfunctions (EFs) in many-body quantum chaotic systems consisting of a central system coupled to an environment. Under certain assumptions, we derive both the average shape and the statistical fluctuations of EFs on the basis formed by the direct product of the energy eigenbases of the system and the environment. Furthermore, we apply our results to two fundamental questions: (i) the properties of the reduced density matrix of the central system in an eigenstate, and (ii) the structure of the off-diagonal smooth function within the framework of the eigenstate thermalization hypothesis. Numerical results are also presented in support of our main findings.

</details>


### [209] [Generalized density functional theory framework for the non-linear density response of quantum many-body systems](https://arxiv.org/abs/2512.07457)
*Zhandos A. Moldabekov,Cheng Ma,Xuecheng Shao,Sebastian Schwalbe,Pontus Svensson,Panagiotis Tolias,Jan Vorberger,Tobias Dornheim*

Main category: cond-mat.stat-mech

TL;DR: 该研究提出了一个密度泛函理论框架，将自由能泛函的函数导数与量子多体系统中的非线性静态密度响应函数联系起来，推导了高阶响应函数的显式表达式，并首次获得了立方响应函数χ₀^(1,3)(q)的理论结果。


<details>
  <summary>Details</summary>
Motivation: 建立连接自由能泛函函数导数与非线性密度响应函数的理论框架，以更好地理解和描述量子多体系统的非线性响应特性，特别是为构建改进的F_s[n]近似提供精确约束，适用于有限温度下的暖密物质应用。

Method: 提出了密度泛函理论框架，推导了均匀系统高阶响应函数的显式表达式，包括首次获得立方响应函数χ₀^(1,3)(q)的理论结果。通过Kohn-Sham DFT模拟验证理论预测，获得理想二次和立方响应函数的长波长极限精确解析表达式，并评估F_s[n]的常用近似。

Result: 理论预测的χ₀^(1,3)(q)与Kohn-Sham DFT模拟结果高度一致。获得了理想二次和立方响应函数的长波长极限精确解析表达式。通过轨道自由DFT模拟评估了F_s[n]的常用近似，并与Kohn-Sham DFT计算结果在从基态到暖密区域的不同温度下进行比较，详细分析了理想二次和立方响应函数的温度和波数依赖的非单调行为。

Conclusion: 该框架成功建立了自由能泛函函数导数与非线性密度响应函数之间的联系，为构建改进的F_s[n]近似提供了精确约束，特别适用于暖密物质应用。理论预测与数值模拟的优异一致性验证了该框架的有效性，对理解量子多体系统的非线性响应特性具有重要意义。

Abstract: A density functional theory (DFT) framework is presented that links functional derivatives of free-energy functionals to non-linear static density response functions in quantum many-body systems. Within this framework, explicit expressions are derived for various higher-order response functions of systems that are homogeneous on average, including the first theoretical result for the cubic response at the first harmonic $χ_0^{(1,3)}(\vec{q})$. Specifically, our framework includes hitherto neglected mode-coupling effects that are important for the non-linear density response even in the presence of a single harmonic perturbation. We compare these predictions for $χ_0^{(1,3)}(\vec{q})$ to new Kohn-Sham DFT simulations, leading to excellent agreement between theory and numerical results. Exact analytical expressions are also obtained for the long-wavelength limits of the ideal quadratic and cubic response functions. Particular emphasis is placed on the connections between the third- and fourth-order functional derivatives of the non-interacting free-energy functional $F_s[n]$ and the ideal quadratic and cubic response functions of the uniform electron gas, respectively. These relations provide exact constraints that may prove useful for the future construction of improved approximations to $F_s[n]$, in particular for warm dense matter applications at finite temperatures. Here, we use this framework to assess several commonly employed approximations to $F_s[n]$ through orbital-free DFT simulations of the harmonically perturbed ideal electron gas. The results are compared with Kohn-Sham DFT calculations across temperatures ranging from the ground state to the warm dense regime. Additionally, we analyze in detail the temperature- and wavenumber-dependent non-monotonic behavior of the ideal quadratic and cubic response functions.

</details>


### [210] [Boundary Criticality of Complex Conformal Field Theory: A Case Study in the Non-Hermitian 5-State Potts Model](https://arxiv.org/abs/2512.07625)
*Yin Tang,Qianyu Liu,Qicheng Tang,W. Zhu*

Main category: cond-mat.stat-mech

TL;DR: 该研究探索了非厄米量子5态Potts模型中的边界临界现象，识别了自由、固定和混合共形边界条件，观察了能谱的共形塔结构，并研究了不同边界条件在Kramers-Wannier变换下的对偶关系。


<details>
  <summary>Details</summary>
Motivation: 虽然现有研究主要关注厄米系统，但非厄米系统中的边界临界现象研究相对缺乏。该研究旨在探索非厄米量子5态Potts模型中的边界临界现象，该模型在体相中表现出复杂的共形性，以增进对复杂共形场论的理解。

Method: 研究非厄米量子5态Potts模型，该模型在体相中表现出复杂的共形性。通过分析边界条件，识别了自由、固定和混合共形边界条件，并观察了能谱的共形塔结构。同时研究了不同边界条件在Kramers-Wannier变换下的对偶关系。

Result: 成功识别了三种共形边界条件（自由、固定和混合），观察到了能谱的共形塔结构，这支持了共形边界临界性的出现。还发现了不同共形边界条件在Kramers-Wannier变换下的对偶关系。

Conclusion: 这些发现有助于全面理解复杂共形场论，并促进对非厄米强关联系统中边界临界现象的进一步探索。研究揭示了非厄米系统中边界临界现象的丰富性，为理解复杂共形场论提供了新视角。

Abstract: Conformal fields with boundaries give rise to rich critical phenomena that can reveal information about the underlying conformality. While most existing studies focus on Hermitian systems, here we explore boundary critical phenomena in a non-Hermitian quantum 5-state Potts model which exhibits complex conformality in the bulk. We identify free, fixed and mixed conformal boundary conditions and observe the conformal tower structure of energy spectra, supporting the emergence of conformal boundary criticality. We also studied the duality relation between different conformal boundary conditions under the Kramers-Wannier transformation. These findings should facilitate a comprehensive understanding for complex CFTs and stimulate further exploration on the boundary critical phenomena within non-Hermitian strongly-correlated systems.

</details>


### [211] [Geometric Characterization of Anisotropic Correlations via Mutual Information Tomography](https://arxiv.org/abs/2512.07659)
*Beau Leighton-Trudel*

Main category: cond-mat.stat-mech

TL;DR: 提出基于局部信息线元的几何映射，用于表征量子与统计系统的各向异性关联，通过互信息断层扫描协议重构几何分量


<details>
  <summary>Details</summary>
Motivation: 需要坐标不变框架来表征量子与统计系统中的各向异性关联，现有方法在处理各向异性时存在局限性

Method: 引入基于局部信息线元的几何映射，使用参数不变的幺模分解分离局部密度涨落与方向各向异性，提出互信息断层扫描协议从有限方向测量重构几何分量

Result: 证明该映射产生光滑黎曼结构的充要条件是短距离互信息遵循各向异性逆二次律，在2D量子谐振晶格模型中重构的形状张量定量恢复了物理耦合各向异性

Conclusion: 各向异性是激活张量几何的必要条件，提出的几何框架和操作协议为表征量子与统计系统的各向异性关联提供了有效工具

Abstract: Characterizing anisotropic correlations in quantum and statistical systems requires a coordinate-invariant framework. We introduce a geometric map based on the local informational line element, calibrated by the Euclidean benchmark scale $C_{\mathrm{vac}}$: $ds^{2} = C_{\mathrm{vac}}/I(x,x+ε)$. We prove that this map yields a smooth Riemannian structure $g_{ij}$ if and only if the short-distance mutual information (MI) follows the anisotropic inverse-quadratic law (local exponent $X_{\text{loc}}=2$). A key insight is that anisotropy is necessary to activate tensor geometry; isotropic MI forces conformal flatness $g_{ij} \propto δ_{ij}$, suppressing shear degrees of freedom. We employ a parameterization-invariant unimodular split $g_{ij} = V^{2/D}γ_{ij}$, which rigorously separates local density fluctuations (volume $V$) from directional anisotropy (shape/shear $γ_{ij}$). We introduce ``MI Tomography,'' an operational protocol to reconstruct these geometric components from finite directional measurements. The protocol is validated using the equal-time ground state of an anisotropic 2D quantum harmonic lattice (massless relativistic scalar) on a torus, where the reconstructed shape tensor $γ_{ij}$ quantitatively recovers the physical coupling anisotropy. We work strictly in the local, fixed-coarse-graining $X_{\text{loc}}=2$ branch; the line element is used solely to extract the local kinematic structure (the local metric tensor), deferring global distance claims.

</details>


### [212] [Strong zero modes in integrable spin-S chains](https://arxiv.org/abs/2512.07742)
*Fabian H. L. Essler,Paul Fendley,Eric Vernier*

Main category: cond-mat.stat-mech

TL;DR: 该论文推导了具有开放边界条件和边界场的可积自旋-S链的精确强零模算子，这些算子的局域性比已知情况更弱，但仍能保证边缘附近的无限相干时间。


<details>
  <summary>Details</summary>
Motivation: 研究可积自旋链中强零模算子的性质，特别是当系统具有开放边界条件和边界场时，探索这些算子的局域性特征及其对量子相干时间的影响。

Method: 推导具有开放边界条件和边界场的可积自旋-S链的精确强零模算子，分析其局域性性质，并解释这些链如何拥有描述一阶量子相变的多个基态。

Result: 发现精确强零模算子的局域性通常比先前已知情况更弱，但它们仍然意味着边缘附近的无限相干时间。对于整数自旋S，由于基态数量为奇数，这种较弱的局域性是必要的。

Conclusion: 可积自旋链中的精确强零模算子具有独特的局域性特征，这些特征与系统的基态简并度密切相关，并且对于S=1/2情况，可以通过Bethe方程的解来理解这些算子在能量本征态上的作用。

Abstract: We derive exact strong zero mode (ESZM) operators for integrable spin-S chains with open boundary conditions and a boundary field. Their locality properties are generally weaker than in the previously known cases, but they still imply infinite coherence times in the vicinity of the edges. We explain how such integrable chains possess multiple ground states describing a first-order quantum phase transition, and that the odd number of such states for integer S makes the weaker locality properties necessary. We make contact with more traditional approaches by showing how the ESZM for S=1/2 acts on energy eigenstates given by solutions of the Bethe equations.

</details>


### [213] [Anomalous coarsening and nonlinear diffusion of kinks in an one-dimensional quasi-classical Holstein model](https://arxiv.org/abs/2512.07744)
*Ho Jang,Yang Yang,Gia-Wei Chern*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究了准经典Holstein模型的相分离动力学，发现电荷密度波畴的生长速度比标准扩散预测更慢，这是由于电子费米-狄拉克统计和电子数准守恒导致的协同kink跳跃机制。


<details>
  <summary>Details</summary>
Motivation: 研究准经典Holstein模型中电子在相分离动力学中的作用，特别是电荷密度波畴的生长机制，以理解电子-声子系统中相分离的基本物理过程。

Method: 采用准经典Holstein模型，在半填充条件下研究零温基态为电荷密度波有序态。通过热淬火模拟相分离动力学，进行大规模数值模拟分析畴生长行为，特别关注分隔两种对称相关CDW有序的拓扑缺陷（kinks）的扩散和湮灭过程。

Result: 研究发现畴生长速度比标准扩散预测的平方根时间标度更慢，呈现温度依赖的幂律指数。这种反常行为源于电子费米-狄拉克统计和电子数准守恒导致的协同kink跳跃机制，这种相关跳跃产生了依赖于kink密度的有效扩散系数。

Conclusion: 该研究揭示了一种新的缓慢相分离机制，对完整Holstein模型和相关电子-声子系统中的相分离动力学具有重要意义，表明电子统计特性可以显著影响拓扑缺陷的动力学行为。

Abstract: We study the phase-ordering dynamics of a quasi-classical Holstein model. At half-filling, the zero-temperature ground state is a commensurate charge-density-wave (CDW) with alternating occupied and empty sites. This quasi-classical formulation enables us to isolate the role of electrons in coarsening dynamics. Following a thermal quench, CDW domains grow through the diffusion and annihilation of kinks -- topological defects separating the two symmetry-related CDW orders. While standard diffusive dynamics predicts domain sizes scaling as the square root of time, our large-scale simulations reveal a slower power-law growth with a temperature-dependent exponent. We trace this anomalous behavior to a cooperative kink hopping arising from Fermi-Dirac statistics of electrons and quasi-conservation of electron numbers. The correlated-hopping of kinks in turn gives rise to an effective diffusion coefficient that depends on the kink density. These results uncover a new mechanism for slow coarsening and carry implications for phase-ordering in the full Holstein model and related electron-phonon systems.

</details>


### [214] [Universal bounds on entropy production from fluctuating coarse-grained trajectories](https://arxiv.org/abs/2512.07772)
*Udo Seifert*

Main category: cond-mat.stat-mech

TL;DR: 该论文系统综述了从粗粒度观测数据推断熵产生的各种方法，重点关注非平衡稳态系统，并总结了在单个轨迹层面量化熵产生的最新进展。


<details>
  <summary>Details</summary>
Motivation: 熵产生是衡量非平衡行为最通用的度量，但在小系统中直接测量困难，因为并非所有贡献熵产生的自由度都可实验观测。因此需要从粗粒度观测数据推断熵产生。

Method: 系统回顾了基于粗粒度状态观测、涨落电流、粗粒度可观测量相关函数、马尔可夫事件间等待时间分布等多种技术，这些方法仅假设底层动力学是马尔可夫的（无记忆）。

Result: 提供了多种模型无关的下界估计方法，能够从粗粒度数据推断熵产生，并扩展到时间依赖和弛豫系统，同时总结了在单个轨迹层面量化熵产生的进展。

Conclusion: 该综述系统整理了从粗粒度观测推断熵产生的理论框架和方法，为非平衡系统（特别是生物分子和软物质系统）的实验研究提供了重要工具，并指出了未来研究方向。

Abstract: Entropy production is arguably the most universally applicable measure of non-equilibrium behavior, particularly for systems coupled to a heat bath. This setting encompasses driven soft matter as well as biomolecular, biochemical, and biophysical systems. Despite its central role, direct measurements of entropy production remain challenging - especially in small systems dominated by fluctuations. The main difficulty arises because not all degrees of freedom contributing to entropy production are experimentally accessible. A key question, therefore, is how to infer entropy production from coarse-grained observations, such as time series of experimentally measurable variables. Over the past decade, stochastic thermodynamics has provided several inequalities that yield model-free lower bounds on entropy production from such coarse-grained data. The major approaches rely on observations of coarse-grained states, fluctuating currents or ticks, correlation functions of coarse-grained observables, and waiting-time distributions between so-called Markovian events, which correspond to transitions between mesoscopic states. Here, we systematically review these techniques valid under the sole assumption of a Markovian, i.e., memoryless, dynamics on an underlying, not necessarily observable, network of states or following a possibly high-dimensional Langevin equation. We discuss in detail the large class of non-equilibrium steady states and highlight extensions of these methods to time-dependent and relaxing systems. While our focus is on mean entropy production, we also summarize recent progress in quantifying entropy production along individual coarse-grained trajectories.

</details>


### [215] [A dynamical order parameter for the transition to nonergodic dynamics in the discrete nonlinear Schrödinger equation](https://arxiv.org/abs/2512.07774)
*Andrew Kalish,Pedro Fittipaldi de Castro,Wladimir A. Benalcazar*

Main category: cond-mat.stat-mech

TL;DR: 该研究提出使用Kolmogorov-Sinai熵的渐近系综方差作为动力学序参量，来精确刻画离散非线性薛定谔方程中从遍历性到弱非遍历性（呼吸子形成）的相变。


<details>
  <summary>Details</summary>
Motivation: 离散非线性薛定谔方程表现出从遍历性、离域动力学到弱非遍历性呼吸子形成的转变，但这一转变的精确表征一直难以捉摸。需要一种轨迹无关的方法来检测非线性晶格系统中的遍历性破缺。

Method: 通过采样大量微正则等价的初始条件，识别Kolmogorov-Sinai熵的渐近系综方差作为动力学序参量。该序参量在遍历相中消失，在遍历性破缺后变为有限值。同时研究了KS熵系综收敛的弛豫时间在相变点处的行为。

Result: KS熵的渐近系综方差在遍历相中消失，在遍历性破缺后变为有限值。弛豫时间在相变点处表现出本质奇异性，为两个动力学区域提供了清晰的边界。

Conclusion: 该框架提供了一种轨迹无关的方法来检测遍历性破缺，广泛适用于具有守恒量的非线性晶格系统，为精确刻画DNLSE中的动力学相变提供了新工具。

Abstract: The discrete nonlinear Schrödinger equation (DNLSE) exhibits a transition from ergodic, delocalized dynamics to a weakly nonergodic regime characterized by breather formation; yet, a precise characterization of this transition has remained elusive. By sampling many microcanonically equivalent initial conditions, we identify the asymptotic ensemble variance of the Kolmogorov-Sinai entropy as a dynamical order parameter that vanishes in the ergodic phase and becomes finite once ergodicity is broken. The relaxation time governing the ensemble convergence of the KS entropy displays an essential singularity at the transition, yielding a sharp boundary between the two dynamical regimes. This framework provides a trajectory-independent method for detecting ergodicity breaking that is broadly applicable to nonlinear lattice systems with conserved quantities.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [216] [Delay as an energy regulator of the generation of deterministic chaos in hydrodynamic systems with limited excitation](https://arxiv.org/abs/2512.07451)
*Aleksandr Shvets,Ilmi Seit-Dzhelil*

Main category: nlin.CD

TL;DR: 该研究分析了Miles-Krasnopolskaya系统中延迟时间对系统动力学的影响，发现延迟在确定性混沌的产生和消失中起关键作用，并能导致吸引子类型的质变。


<details>
  <summary>Details</summary>
Motivation: 研究非线性相互作用中延迟效应对系统动力学的影响，特别是在Miles-Krasnopolskaya系统中，延迟如何影响"储罐-液体-激励源"系统的吸引子行为。

Method: 提出了一种研究此类系统吸引子的技术方法，考虑了激励源脉冲的延迟时间对系统动力学的影响。

Result: 延迟在Miles-Krasnopolskaya系统中确定性混沌的产生和消失中起关键作用。延迟值的定量变化可导致系统吸引子类型的定性变化，包括规则吸引子与混沌吸引子之间的相互转化，以及不同类型混沌吸引子之间的转变。

Conclusion: 延迟时间是影响Miles-Krasnopolskaya系统动力学行为的关键参数，能够显著改变系统的吸引子类型和混沌特性，为理解非线性系统中延迟效应提供了重要见解。

Abstract: The Miles-Krasnopolskaya system is considered, which is used to study the nonlinear interaction of a tank with a liquid and the source of excitation of its oscillations. Additionally, delay time of impulse from the source of excitation of oscillations on the dynamics of the aggregate system "tank with liquid - source of excitation" is taken into account. A technique for studying the attractors of such systems is proposed.
  It is shown that delay plays a key role in the emergence (disappearance) of deterministic chaos in the Miles-Krasnopolskaya system. Quantitative changes in the value of the delay can lead to qualitative changes in the types of attractors of the system. So, regular attractors can turn into chaotic ones and vice versa. Also, a change in the delay value can lead to the implementation of new scenarios, both transitions from regular attractors to chaotic ones and transitions from a chaotic attractor of one type to a chaotic attractor of another type.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [217] [Agency at the Interface: Distinguishing Teleological from Structural Self-Organization via Internal Coarse-Graining and Downward Causation](https://arxiv.org/abs/2512.06771)
*Kazuya Horibe,Keisuke Suzuki*

Main category: nlin.AO

TL;DR: 该论文提出了一种基于内在动力学生成过程的能动性理论框架，通过系统内部粗粒化和向下因果的自指循环，区分系统自身组织与观察者解释，从而定义能动性。


<details>
  <summary>Details</summary>
Motivation: 现有能动性理论通常从观察者视角定义，缺乏对系统自主生成目标的功能性基础区分。需要建立一种能够区分系统内在组织与外部解释的理论框架，以更好地理解生物系统与人工系统的本质差异。

Method: 提出基于内在动力学生成过程的能动性理论：1）系统通过内部粗粒化将微观状态压缩为宏观变量；2）宏观变量通过向下因果约束微观时间演化；3）通过预测间隙的动态变化定义能动性，即系统预期与实现之间的内部差异；4）区分系统内在动力学与观察者外部粗粒化。

Result: 建立了能动性谱系框架：生物系统的目的性约束通过自身调节动力学生成，而人工系统的组织则设计为满足外部指定目标。该框架还可扩展到社会领域，解释参与式意义生成和涌现协调。

Conclusion: 能动性应基于系统内在动力学生成过程来定义，通过预测间隙的动态变化表征系统自主性。这一框架为区分生物与人工系统的能动性提供了理论基础，并具有扩展到社会认知领域的潜力。

Abstract: Agency is widely characterized as the capacity of a system to regulate its internal states toward self-generated goals, yet characterizing the functional basis of this autonomy requires a distinction between the system's own organization and an observer's interpretation. In this paper, we ground this capacity functionally in the generative process of intrinsic dynamics, characterized as a self-referential loop generated by internal coarse-graining and downward causation. This process allows the system to autonomously compress microscopic states into macroscopic variables that subsequently constrain microscopic temporal evolution. By distinguishing the intrinsic dynamics of the system from the external coarse-graining of an observer's interpretation, we define agency through the dynamics of the predictive gap. This gap constitutes the internal divergence between the system's anticipation and its realization, as well as the limited reducibility of the system's generated constraints within the observer's interpretive model. This framework outlines a spectrum of agency that distinguishes biological systems, whose teleological constraints are generated through their own regulatory dynamics, from artificial systems, whose organization is designed to satisfy externally specified objectives. Finally, we extend this interface to the social domain, proposing that these generative divergences underpin participatory sense-making and emergent coordination.

</details>
