<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [nlin.CD](#nlin.CD) [Total: 4]
- [quant-ph](#quant-ph) [Total: 48]
- [cs.AI](#cs.AI) [Total: 39]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 13]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 6]
- [cs.LG](#cs.LG) [Total: 52]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [Stability of the symmetry-protected topological phase and Ising transitions in a disordered U(1) quantum link model on a ladder](https://arxiv.org/abs/2512.10642)
*Mykhailo V. Rakov,Luca Tagliacozzo,Maciej Lewenstein,Jakub Zakrzewski,Titas Chanda*

Main category: cond-mat.dis-nn

TL;DR: 研究U(1)量子链接模型在梯子几何中的相变，发现所有相变都属于伊辛普适类，且无序扰动下相变仍保持鲁棒性


<details>
  <summary>Details</summary>
Motivation: 重新审视U(1)量子链接模型在梯子几何中的行为，特别是无序扰动对相变临界性的影响。传统Harris准则预测无序会破坏临界性，但作者发现实际情况并非如此

Method: 采用有限尺寸标度分析，计算临界指数ν=1和中心荷c=1/2，确认相变属于伊辛普适类。研究两种无序类型：梯子横档跳跃无序和梯子腿跳跃无序

Result: 1. 所有相变都属于伊辛普适类；2. 横档无序下相变在强无序时才消失；3. 腿无序破坏非零质量相的临界性，但零质量对称保护拓扑相在小无序下仍存在；4. 无序鲁棒性可用场论论证定性解释

Conclusion: U(1)量子链接模型在梯子几何中的相变对无序具有显著鲁棒性，这与Harris准则的预测相反，表明该系统的临界行为比预期更稳定

Abstract: We revisit the U(1) quantum link model in a ladder geometry, finding, by finite-size scaling, that the critical exponent $ν=1$ and the central charge $c=1/2$ are consistent with the Ising universality class for all phase transitions observed. A blind application of the Harris criterion would suggest that this criticality is lost in the presence of the disorder. It turns out not to be the case. For the disorder affecting ladder's rung hoppings only, we have found that the transitions survive disappearing only for quite strong disorder. The disorder in the ladder's legs destroys the nonzero mass phase criticality, while the symmetry-protected topological phase for zero mass survives a small disorder. The observed robustness against disorder is explained qualitatively using field-theoretic arguments.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [2] [An improved approach for estimating the dimension of inertial manifolds in chaotic distributed dynamical systems via analysis of angles between tangent subspaces](https://arxiv.org/abs/2512.10030)
*Pavel V. Kuptsov*

Main category: nlin.CD

TL;DR: 提出了一种改进的惯性流形维度估计方法，通过分析CLV张成的切子空间之间的角度，显著降低了计算复杂度和内存需求。


<details>
  <summary>Details</summary>
Motivation: 现有的基于协变Lyapunov向量(CLV)角度计算的惯性流形维度估计方法虽然算法高效，但计算资源需求大，限制了其实际应用。

Method: 提出了一种改进方法，通过分析CLV张成的切子空间之间的角度来确定惯性流形维度，该方法基于评估混沌动力学双曲性的快速数值技术，无需显式计算CLV。

Result: 在复杂Ginzburg-Landau方程中，新方法的结果与先前的维度估计一致；在扩散耦合Lorenz振子链中，分析表明不存在低维惯性流形，揭示了需要进一步研究的复杂机制。

Conclusion: 该方法为扩展动力系统中高维吸引子的表征提供了一个实用且高效的工具，显著降低了计算成本和内存使用。

Abstract: While a previously proposed method for estimating inertial manifold dimension, based on explicitly computing angles between pairs of covariant Lyapunov vectors (CLVs), employs efficient algorithms, it remains computationally demanding due to its substantial resource requirements. In this work, we introduce an improved method to determine this dimension by analyzing the angles between tangent subspaces spanned by the CLVs. This approach builds upon a fast numerical technique for assessing chaotic dynamics hyperbolicity. Crucially, the proposed method requires significantly less computational effort and minimizes memory usage by eliminating the need for explicit CLV computation. We test our method on two canonical systems: the complex Ginzburg-Landau equation and a diffusively coupled chain of Lorenz oscillators. For the former, the results confirm the accuracy of the new approach by matching prior dimension estimates. For the latter, the analysis demonstrates the absence of a low-dimensional inertial manifold, highlighting a complex regime that merits further investigation. The presented method offers a practical and efficient tool for characterizing high-dimensional attractors in extended dynamical systems.

</details>


### [3] [Chaotic discretization theorems for forced linear and nonlinear coupled oscillators](https://arxiv.org/abs/2512.10565)
*Stefano Disca,Vincenzo Coscia*

Main category: nlin.CD

TL;DR: 本文证明了四维离散动力系统存在Li-Yorke混沌，这些系统源于受非保守外力作用的耦合振子ODE系统，并给出了一个Li-Yorke混沌但非拓扑传递的离散映射示例。


<details>
  <summary>Details</summary>
Motivation: 研究耦合振子在非保守外力作用下的动力学行为，探索离散动力系统中的混沌现象，特别是Li-Yorke混沌与拓扑传递性之间的关系。

Method: 1. 从描述耦合振子的ODE系统推导出四维离散动力系统；2. 证明这些系统存在Li-Yorke混沌；3. 构建Li-Yorke混沌但非拓扑传递的离散映射示例；4. 将分析结果推广到模块化定义问题和多项式势的非线性振子系统；5. 进行数值模拟寻找奇怪吸引子；6. 绘制分岔图并进行分岔分析。

Result: 1. 成功证明了四维离散动力系统存在Li-Yorke混沌；2. 提供了Li-Yorke混沌但非拓扑传递的具体映射示例；3. 将理论结果推广到更一般的模块化系统和多项式势系统；4. 数值模拟揭示了系统的奇怪吸引子特征；5. 分岔分析揭示了系统的动力学演化规律。

Conclusion: 本文建立了耦合振子离散动力系统中Li-Yorke混沌的存在性理论，揭示了Li-Yorke混沌与拓扑传递性的分离现象，为非线性动力学研究提供了新的理论框架和数值证据。

Abstract: We prove the holding of chaos in the sense of Li-Yorke for a family of four-dimensional discrete dynamical systems that are naturally associated to ODEs systems describing coupled oscillators subject to an external nonconservative force, also giving an example of a discrete map that is Li-Yorke chaotic but not topologically transitive. Analytical results are generalized to a modular definition of the problem and to a system of nonlinear oscillators described by polynomial potentials in one coordinate. We perform numerical simulations looking for a strange attractor of the system; furthermore, we present the bifurcation diagram and perform a bifurcation analysis of the system.

</details>


### [4] [Chaotic dynamics of a continuous and discrete generalized Ziegler pendulum](https://arxiv.org/abs/2512.10569)
*Stefano Disca,Vincenzo Coscia*

Main category: nlin.CD

TL;DR: 研究广义齐格勒摆的可积性与混沌运动转变，分析重力、摩擦等外力对可积性的影响，并探讨离散版本的非混沌特性


<details>
  <summary>Details</summary>
Motivation: 研究广义齐格勒摆（受角弹性势和随从力作用的双摆）在不同外力条件下的可积性变化，特别是分析重力、摩擦等外力如何影响系统的可积性，以及探索离散版本是否表现出混沌行为

Method: 采用解析和数值方法分析广义齐格勒摆系统；考虑原始系统的多个变体，包括重力、摩擦等外力；分析两种不同形式的耗散力；研究离散版本并分析周期点（最多到周期3）

Result: 研究发现：1）某些外力条件下可积性得以保持，而其他条件下会被破坏；2）离散映射在参数对应原始系统混沌运动的一般情况下，没有密集的周期点集，因此不满足Devaney混沌定义

Conclusion: 广义齐格勒摆的可积性受外力类型影响，耗散力分析显示两种形式有不同效果；离散版本在原始系统混沌的参数范围内不表现出Devaney意义上的混沌行为，表明连续与离散系统的动力学特性存在差异

Abstract: We present analytical and numerical results on integrability and transition to chaotic motion for a generalized Ziegler pendulum, a double pendulum subject to an angular elastic potential and a follower force. Several variants of the original dynamical system, including the presence of gravity and friction, are considered, in order to analyze whether the integrable cases are preserved or not in presence of further external forces, both potential and non-potential. Particular attention is devoted to the presence of dissipative forces, that are analyzed in two different formulations. Furthermore, a study of the discrete version is performed. The analysis of periodic points, that is presented up to period 3, suggests that the discrete map associated to the dynamical system has not dense sets of periodic points, so that the map would not be chaotic in the sense of Devaney for a choice of the parameters that corresponds to a general case of chaotic motion for the original system.

</details>


### [5] [Melnikov Method for a Class of Generalized Ziegler Pendulums](https://arxiv.org/abs/2512.10682)
*Stefano Disca,Vincenzo Coscia*

Main category: nlin.CD

TL;DR: 将Melnikov方法应用于广义Ziegler摆系统，通过雅可比椭圆积分解析求解分界线，在Duffing近似下对原始Ziegler系统应用Melnikov方法，推导出外力作用下的Melnikov积分表达式，建立了Melnikov积分与控制参数的关系以区分规则与混沌轨道。


<details>
  <summary>Details</summary>
Motivation: 研究广义Ziegler摆系统的混沌动力学行为，通过Melnikov方法分析系统在外部周期力和耗散作用下的混沌特性，建立区分规则与混沌轨道的定量关系。

Method: 采用Melnikov方法分析广义Ziegler摆系统；使用雅可比椭圆积分解析表示系统分界线；在Duffing近似下对原始Ziegler系统应用Melnikov方法；推导外力作用和耗散项下的Melnikov积分表达式。

Result: 获得了广义Ziegler摆系统分界线的解析表达式；发现原始Ziegler系统的Melnikov积分在二阶才首次非零；推导了外力作用和耗散项下的显式Melnikov积分表达式；建立了Melnikov积分与控制参数的关系以区分规则与混沌轨道。

Conclusion: Melnikov方法成功应用于广义Ziegler摆系统，建立了混沌行为的定量判据，为理解这类系统的动力学特性提供了理论框架，并在附录中讨论了离散映射的混沌定义问题。

Abstract: The Melnikov method is applied to a class of generalized Ziegler pendulums. We find an analytical form for the separatrix of the system in terms of Jacobian elliptic integrals, holding for a large class of initial conditions and parameters. By working in Duffing approximation, we apply the Melnikov method to the original Ziegler system, showing that the first non-vanishing Melnikov integral appears in the second order. An explicit expression for the Melnikov integral is derived in the presence of a time-periodic external force and for a suitable choice of the parameters, as well as in the presence of a dissipative term acting on the lower rod of the pendulum. These results allow us to define fundamental relationships between the Melnikov integral and a proper control parameter that distinguishes between regular and chaotic orbits for the original dynamical system. Finally, in the appendix, we present proof of a conjecture concerning the non-validity of Devaney's chaoticity definition for a discrete map associated with the system.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [6] [Deep Thermalization and Measurements of Quantum Resources](https://arxiv.org/abs/2512.09999)
*Naga Dileep Varikuti,Soumik Bandyopadhyay,Philipp Hauke*

Main category: quant-ph

TL;DR: 该论文提出了一种基于深度热化的统一协议，用于量化任意量子演化在多种量子资源理论中的资源生成能力，并通过投影系综和新的twirling恒等式实现实验可访问的资源量化。


<details>
  <summary>Details</summary>
Motivation: 量子资源理论为表征受物理约束的有用量子现象提供了统一框架，但在实验系统中难以评估。需要开发一种统一且实验可访问的协议来量化量子演化的资源生成能力。

Method: 基于深度热化概念，利用投影系综（用于探测深度热化）和新的twirling恒等式，直接推断底层动力学的资源生成能力。该方法适用于多种量子资源理论。

Result: 揭示了资源在通用量子电路中如何积累和热化，并发现量子资源本身在子系统层面也经历深度热化，这提供了另一种实验可访问的途径来推断资源生成能力。

Conclusion: 该工作将深度热化与资源量化联系起来，为各种资源在生成状态设计中的基本作用提供了新视角，并提供了实验可访问的资源量化方法。

Abstract: Quantum resource theories (QRTs) provide a unified framework for characterizing useful quantum phenomena subject to physical constraints, but are notoriously hard to assess in experimental systems. In this letter, we introduce a unified protocol for quantifying the resource-generating power (RGP) of arbitrary quantum evolutions applicable to multiple QRTs. It is based on deep thermalization (DT), which has recently gained attention for its role in the emergence of quantum state designs from partial projective measurements. Central to our approach is the use of projected ensembles, recently employed to probe DT, together with new twirling identities that allow us to directly infer the RGP of the underlying dynamics. These identities further reveal how resources build up and thermalize in generic quantum circuits. Finally, we show that quantum resources themselves undergo deep thermalization at the subsystem level, offering a complementary and another experimentally accessible route to infer the RGP. Our work connects deep thermalization to resource quantification, offering a new perspective on the essential role of various resources in generating state designs.

</details>


### [7] [A Unified Linear Algebraic Framework for Physical Models and Generalized Contextuality](https://arxiv.org/abs/2512.10000)
*Farid Shahandeh,Theodoros Yianni,Mina Doosti*

Main category: quant-ph

TL;DR: 本文提出了一种基于条件结果概率矩阵（COPE）的统计优先框架，将五种模型类别统一为COPE矩阵的约束分解，并建立了非上下文性的简单判据。


<details>
  <summary>Details</summary>
Motivation: 为了统一不同操作理论（preGPTs、GPTs、准概率、本体论和非上下文本体论模型）的数学结构，并提供一个系统研究上下文性的框架。

Method: 开发基于COPE矩阵的统计优先框架，将模型类别统一为矩阵分解问题；使用等秩非负矩阵分解（ENMF）作为非上下文性判据；应用线性代数框架和离散数学技术分析秩分离。

Result: 建立了操作理论存在非上下文本体论模型的充要条件是COPE矩阵允许等秩非负矩阵分解；证明了boxworld操作理论具有本体论上下文性；为离散量子比特理论的上下文性提供了新证明。

Conclusion: 通过将上下文性重构为矩阵分析问题，本文为系统研究非经典资源提供了统一框架，并开辟了探索非经典资源的新途径。

Abstract: We develop a bottom-up, statistics-first framework in which the full probabilistic content of an operational theory is encoded in its matrix of conditional outcome probabilities of events (COPE). Within this setting, five model classes (preGPTs, GPTs, quasiprobabilistic, ontological, and noncontextual ontological) are unified as constrained factorizations of the COPE matrix. We identify equirank factorizations as the structural core of GPTs and noncontextual ontological models and establish their relation to tomographic completeness. This yields a simple, model-agnostic criterion for noncontextuality: an operational theory admits a noncontextual ontological model if and only if its COPE matrix admits an equirank nonnegative matrix factorization (ENMF). Failure of the equirank condition in all ontological models therefore establishes contextuality. We operationalize rank separation via two complementary methods provided by the linear-algebraic framework. First, we use ENMF to interpret noncontextual ontological models as nested polytopes. This allows us to establish that the boxworld operational theory is ontologically contextual. Second, we apply techniques from discrete mathematics to derive a lower bound on the ontological dimensionality of COPE matrices exhibiting sparsity patterns, and use this bound to establish a new proof that a discrete version of qubit theory exhibits ontological contextuality. By reframing contextuality as a problem in matrix analysis, our work provides a unified structure for its systematic study and opens new avenues for exploring nonclassical resources.

</details>


### [8] [Estimating Detector Error Models on Google's Willow](https://arxiv.org/abs/2512.10814)
*Kregg Elliot Arms,Martin James McHugh,Joseph Edward Nyhan,William Frederick Reus,James Loudon Ulrich*

Main category: quant-ph

TL;DR: 论文提出从综合征直接估计探测器误差模型(DEM)的方法，无需解码器，应用于谷歌量子芯片，发现DEM估计能更好地预测未见综合征，而优化逻辑性能的DEM在解码器中表现更好，并发现长程相关误差和辐射事件等异常现象。


<details>
  <summary>Details</summary>
Motivation: 传统量子错误校正通常使用解码器，但直接从综合征学习探测器误差模型(DEM)能更准确地表征量子硬件错误特性，为在线表征和错误分析提供新方法。

Method: 开发了从综合征直接学习DEM参数和结构的算法，无需解码器；使用可处理的小型DEM似然函数；应用时间序列DEM估计跟踪错误演变；采用DEM分析技术发现长程相关误差。

Result: 1) 从综合征直接估计的DEM比优化逻辑性能的DEM更准确地预测未见综合征；2) 优化逻辑性能的DEM作为解码器先验表现更好；3) 发现谷歌105量子比特芯片上存在跨越整个芯片宽度的长程相关误差；4) 观察到重复码综合征中的两种异常现象：相邻探测器对在多个连续QEC轮次中的相关翻转，以及比先前报告更频繁的辐射事件特征。

Conclusion: 直接从综合征学习DEM是量子硬件表征的有效方法，能够揭示传统方法难以发现的错误模式，为量子错误校正的在线监测和硬件优化提供了新工具，同时发现了量子系统中未被充分认识的相关误差和辐射事件现象。

Abstract: We consolidate recent theoretical advances in Detector Error Model (DEM) estimation and formalize several algorithms to learn DEM parameters and structure from syndromes without using a decoder, demonstrating recovery of known DEMs from simulated syndromes with precision limited only by finite-sample effects. We then apply these algorithms to estimate DEMs from Google's 72- and 105-qubit chips. Using a likelihood function that is tractable for small DEMs, we show that DEMs estimated directly from syndromes agree more closely with unseen syndromes than DEMs trained to optimize logical performance, whereas the latter outperform the former as priors for decoders in logical memory experiments. We used a time-series of estimated DEMs to track both global error and specific local errors over the course of a QEC experiment, suggesting applications in online characterization. We employ a sequence of DEM estimation techniques to discover and quantify long-range detector correlations spanning the width of the 105-qubit chip, for which DEM analysis suggests correlated measurement errors rather than high-weight Pauli errors as the most likely explanation. Finally, we present two artifacts in repetition code syndromes that are \emph{not} well-modeled by a DEM: correlated flipping of pairs of adjacent detectors in many consecutive rounds of QEC, and signatures consistent with radiation events occurring more frequently than previously reported.

</details>


### [9] [Quantumness via Discrete Structures](https://arxiv.org/abs/2512.10063)
*Ravi Kunjwal*

Main category: quant-ph

TL;DR: 该论文探讨离散结构（图、超图）在评估量子特性中的作用，涵盖上下文性、因果性和测量不相容性三个主要领域。


<details>
  <summary>Details</summary>
Motivation: 量子理论在基础层面与经典概率理论存在根本差异，这些差异（称为"量子性"）是量子信息和计算的基础。论文旨在通过离散结构的视角系统性地评估量子性，为理解量子特性提供新的数学框架。

Method: 采用离散结构（无向图、超图、有向图）作为分析工具：1）使用图和超图研究Kochen-Specker上下文性和广义上下文性；2）使用有向图研究因果性，包括不定因果顺序和反矛盾性；3）使用超图建模量子测量的不相容性关系及其与贝尔非定域性的联系。

Result: 建立了离散结构与量子特性评估的系统性联系：1）开发了基于（超）图论的上下文性分析框架；2）揭示了不定因果顺序与LOCC/SEP操作间隙的关系；3）提出了无需全局因果假设的反矛盾性概念；4）建立了测量不相容性与贝尔非定域性的联系，并用于区分量子与近量子关联。

Conclusion: 离散结构为评估量子性提供了强大而统一的数学框架，能够系统性地分析上下文性、因果性和测量不相容性等核心量子特性。该研究为量子信息科学提供了新的理论基础和分析工具。

Abstract: Quantum theory departs from classical probabilistic theories in foundational ways. These departures--termed quantumness here--power quantum information and computation. This thesis charts the role of discrete structures in assessing quantumness, synthesizing elements of my postdoctoral research through this lens. After an introduction to the necessary background concepts, I present my work under three broad categories. First, I present work on contextuality that extensively relies on (undirected) graphs and hypergraphs as the discrete structures of interest; more specifically, it relies on invariants associated with them. This work includes Kochen-Specker (KS) contextuality and its operationalization to generalized contextuality, expressed via (hyper)graph-theoretic frameworks. I also present work on KS-contextuality in multiqubit systems and an application of generalized contextuality to a one-shot communication task, both of which rely on hypergraphs. Second, I present work on causality, where the discrete structures of interest are directed graphs. This includes work on indefinite causal order, specifically its connections to the gap between local operations and classical communication (LOCC) and separable operations (SEP), and a device-independent notion of nonclassicality--termed antinomicity--that generalizes Bell nonlocality without global causal assumptions. Finally, I present work on the incompatibility of quantum measurements, its connection to Bell nonlocality, and its role in discriminating between quantum and almost quantum correlations in the single-system setting. The discrete structures of interest here are hypergraphs that model joint measurability relations between quantum measurements. I conclude with a summary and an overview of work that is not covered in this thesis.

</details>


### [10] [Gradient projection method and stochastic search for some optimal control models with spin chains. I](https://arxiv.org/abs/2512.10093)
*Oleg V. Morzhin*

Main category: quant-ph

TL;DR: 该论文在已知的自旋链量子信息传输最优控制模型基础上，增加了控制约束、信号保持问题，并针对不同控制类别应用了投影型线性化庞特里亚金极大值原理和梯度投影方法。


<details>
  <summary>Details</summary>
Motivation: 扩展现有的自旋链量子信息传输最优控制模型，考虑更实际的控制约束条件（上下界约束），并解决信号在最后一个自旋上的保持问题，同时研究不同控制类别下的优化方法。

Method: 1. 在已知模型基础上增加点状上下界控制约束；2. 考虑信号在最后一个自旋的保持问题；3. 针对分段连续控制，采用投影型线性化庞特里亚金极大值原理；4. 应用梯度投影方法的一步、两步、三步形式；5. 在特殊控制类别下使用遗传算法。

Result: 成功将投影型线性化庞特里亚金极大值原理和梯度投影方法应用于带约束的量子信息传输控制问题，并在特殊控制类别下展示了遗传算法的成功应用。

Conclusion: 论文扩展了自旋链量子信息传输的最优控制框架，建立了适用于带约束条件和信号保持问题的优化方法体系，为量子信息处理的实际控制问题提供了理论工具。

Abstract: This article (I) considers the known optimal control model of a quantum information transfer along a spin chain with controlled external parabolic magnetic field, with an arbitrary length. The article adds certain lower and upper pointwise constraints on controls, adds the problem of keeping the signal at the last spin, considers various classes of controls. For these problems under piecewise continuous controls, the projection-type linearized Pontryagin maximum principle, gradient projection method's constructions in its one- and two- and three-step forms were adapted by analogy with [Morzhin O.V., Pechen A.N. J. Phys. A: Math. Theor., 2025]. Moreover, an example with a genetic algorithm's successful use under a special class of controls is given.

</details>


### [11] [Engineer coherent oscillatory modes in Markovian open quantum systems](https://arxiv.org/abs/2512.10144)
*Chun Hei Leung,Pak-Tik Fong,Tianyi Yan,Weibin Li*

Main category: quant-ph

TL;DR: 提出了一种在马尔可夫开放量子系统中设计持久振荡模式的新框架，该框架不要求耗散项为零，超越了传统的退相干自由子空间方法。


<details>
  <summary>Details</summary>
Motivation: 传统退相干自由子空间方法要求耗散项为零，限制了在开放量子系统中创建持久振荡模式的可能性。本文旨在开发一个更通用的框架，允许在非零耗散条件下实现持续振荡。

Method: 当哈密顿量和跃迁算符具有相同块对角形式时，可以在Lindblad主方程中创建振荡模式。提出了弱条件和强条件，分别对应振荡模式是否依赖于系统参数。框架允许耗散项非零，超越了传统退相干自由子空间方法。

Result: 建立了在马尔可夫开放量子系统中设计持久振荡模式的通用框架，识别了振荡模式存在的条件，并通过多种模型验证了该框架的有效性，展示了如何通过精心设计的系统-环境相互作用产生持续相干振荡。

Conclusion: 该研究提出了一个超越传统退相干自由子空间方法的新框架，能够在耗散项非零的条件下在开放量子系统中创建持久振荡模式，为量子信息处理和量子模拟中的相干控制提供了新途径。

Abstract: We develop a novel framework to engineer persistent oscillatory modes in Markovian open quantum systems governed by a time-independent Lindblad master equation. We show that oscillatory modes can be created when the Hamiltonian and jump operator can be expressed in the same block-diagonal form. A key feature of the framework is that the dissipator of the Lindblad master equation are generally non-zero. We identify the weak and strong conditions, where the onset of the oscillatory modes is dependent and independent of the parameters of the system, respectively. Our method extends beyond the typical decoherence-free subspace approach, in which the dissipator is zero. We demonstrate the applicability of this framework using various models, showing how carefully tailored system-environment interactions can produce sustained coherent oscillations.

</details>


### [12] [Upper Bounds on Fluctuation Growths of Observables in Open Quantum Systems](https://arxiv.org/abs/2512.10153)
*Newshaw Bahreyni,Paul M. Alsing,Carlo Cafaro,Walid Redjem,Christian Corda*

Main category: quant-ph

TL;DR: 该论文研究了开放量子系统中可观测量涨落增长速率的上界，并与封闭系统结果进行比较，发现考虑系统与状态动力学的分离贡献会导致更宽松的上界。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中可观测量涨落增长速率的上界问题，扩展作者先前在封闭量子系统中的相关工作，探讨系统开放性与涨落增长速率界限之间的关系。

Method: 采用两种方法分析开放量子系统：第一种使用泰勒展开和戴森级数的标准时序演化来推导演化生成元；第二种不考虑系统演化的具体信息。分别计算两种情况下涨落增长速率的上界。

Result: 获得了开放量子系统两种情况下涨落增长速率的上界，并与封闭系统的上界进行比较。结果表明，通过分离系统和状态动力学的贡献来包含更多细节信息，会导致更宽松的涨落增长速率上界。

Conclusion: 在开放量子系统中，考虑更详细的系统和状态动力学分离会导致涨落增长速率的上界变得更为宽松，这为理解量子系统中涨落增长的极限提供了新的理论见解。

Abstract: The upper bounds for the rate of fluctuation growth of an observable in both open and closed quantum systems have been studied actively recently. In our recent work we showed that the rate of fluctuation growth for an observable in a closed quantum system is upper bounded by the fluctuation of its corresponding velocity-like observable. That bound also indicated a tradeoff between the time derivatives of the mean and the standard deviation. In this paper we will look at open quantum systems in two cases. For the first case we find the generator of evolution for an open system employing both the Taylor expansion and the standard time-ordered evolution via the Dyson series, while in the second case we consider no specific information about the evolution of the system. We then find the rate of fluctuation growth in each case. Comparing the upper bounds for each case and considering the upper bound found for a closed system suggest that including more details by separating the contributions of the system and state dynamics seems to result in looser bounds for the rate of fluctuation growth.

</details>


### [13] [Eight-Qubit Operation of a 300 mm SiMOS Foundry-Fabricated Device](https://arxiv.org/abs/2512.10174)
*Andreas Nickl,Nard Dumoulin Stuyck,Paul Steinacker,Jesus D. Cifuentes,Santiago Serrano,MengKe Feng,Ensar Vahapoglu,Fay E. Hudson,Kok Wai Chan,Stefan Kubicek,Julien Jussot,Yann Canvel,Sofie Beyne,Yosuke Shimura,Roger Loo,Clement Godfrin,Bart Raes,Sylvain Baudot,Danny Wan,Arne Laucht,Chih-Hwan Yang,Wee Han Lim,Andre Saraiva,Christopher C. Escott,Kristiaan De Greve,Andrew S. Dzurak,Tuomo Tanttu*

Main category: quant-ph

TL;DR: 硅自旋量子比特阵列扩展到8量子比特规模，在CMOS兼容工艺中实现相干控制和测量


<details>
  <summary>Details</summary>
Motivation: 硅自旋量子比特具有高相干性、高可控性和可制造性优势，但现有CMOS实现通常限于少数量子比特，需要向大规模系统扩展

Method: 采用300mm CMOS兼容工艺制造8点线性硅自旋量子比特阵列，将8个量子比特调谐为4个双点对，通过级联电荷传感协议实现中心4量子比特同时高保真度测量

Result: 成功调谐和控制8量子比特阵列，获得高达41(2)μs的Ramsey退相干时间和1.31(4)ms的Hahn-echo相干时间，相邻量子比特间实现低相位噪声的双量子比特门操作

Conclusion: 证明硅自旋量子比特阵列可以扩展到中等规模（8量子比特）同时保持系统相干性，为实现大规模量子计算系统迈出重要一步

Abstract: Silicon spin qubits are a promising candidate for quantum computing, thanks to their high coherence, high controllability and manufacturability. However, the most scalable complementary metal-oxide-semiconductor (CMOS) based implementations have so far been limited to a few qubits. Here, to take a step towards large scale systems, we tune and coherently control an eight-dot linear array of silicon spin qubits fabricated in 300 mm CMOS-compatible foundry process, establishing operational scalability beyond the two-qubit regime. All eight qubits are successfully tuned and characterized as four double dot pairs, exhibiting Ramsey dephasing times $T_2^*$ up to 41(2) $μ$s and Hahn-echo coherence times $T_2^{\mathrm{Hahn}}$ up to 1.31(4) ms. Readout of the central four qubits is achieved via a cascaded charge-sensing protocol, enabling simultaneous high-fidelity measurements of the entire multi-qubit array. Additionally, we demonstrate a two-qubit gate operation between adjacent qubits with low phase noise. We demonstrate here that we can scale silicon spin qubit arrays to medium-sized arrays of 8 qubits while maintaining coherence of the system.

</details>


### [14] [Chaos, Entanglement and Measurement: Field-Theoretic Perspectives on Quantum Information Dynamics](https://arxiv.org/abs/2512.10484)
*Anastasiia Tiutiakina*

Main category: quant-ph

TL;DR: 该研究开发了理解量子信息在多体系统中如何传播、混洗和被测量重塑的工具，包括布朗SYK模型中的混洗和伪随机性分析、弱测量SYK簇的场论构建，以及仅测量SYK簇的强无序重整化群方法。


<details>
  <summary>Details</summary>
Motivation: 研究量子信息在多体系统中的传播、混洗和测量效应，旨在理解量子信息如何通过相互作用和测量过程被重塑，为诊断多体动力学何时产生操作随机性以及测量如何重定向信息流提供统一框架。

Method: 1. 使用Keldysh路径积分、副本和无序平均研究布朗SYK模型的混洗和伪随机性；2. 从系统-辅助描述出发，在连续监测极限下，使用费米相干态、副本和无序平均推导弱测量SYK簇的非线性sigma模型；3. 基于SO(2n)副本代数和Dasgupta-Ma削除规则，开发仅测量SYK簇的强无序重整化群方法。

Result: 1. 获得了随机性趋近的解析控制，识别了延迟收敛到Haar类行为的集体模式，估计了设计时间与模型参数的关系；2. 推导了捕获测量反作用和相互作用诱导混洗与信息提取竞争的非线性sigma模型，预测了区分弱监测与完全幺正演化的特征交叉尺度和响应特征；3. 重整化群流显示了类似无限随机性的特征，但极限顺序的微妙性使主导递推关系不稳健，因此无限随机性固定点的解析证据不确定，尽管平均第二Renyi熵显示对数标度。

Conclusion: 这些结果为诊断多体动力学何时产生操作随机性以及测量如何重定向信息流提供了统一语言，阐明了混洗、复杂性增长和随机电路现象学之间的联系，并为理解测量反作用与相互作用诱导混洗之间的竞争提供了理论框架。

Abstract: This work develops tools to understand how quantum information spreads, scrambles, and is reshaped by measurements in many-body systems. First, I study scrambling and pseudorandomness in the Brownian Sachdev-Ye-Kitaev (SYK) model, quantifying pseudorandomness using unitary k-designs and frame potentials. Using Keldysh path integrals with replicas and disorder averaging, I obtain analytic control of the approach to randomness, identify collective modes that delay convergence to Haar-like behavior, and estimate design times as functions of model parameters, clarifying links between scrambling, complexity growth, and random-circuit phenomenology. Second, I construct a field theory for weakly measured SYK clusters. Starting from a system-ancilla description and a continuum monitoring limit, and using fermionic coherent states with replicas and disorder averaging, I derive a nonlinear sigma model that captures measurement back-action and the competition between interaction-induced scrambling and information extraction, predicting characteristic crossover scales and response signatures that distinguish weak monitoring from fully unitary evolution. Third, I develop a strong-disorder renormalization group for measurement-only SYK clusters, based on the SO(2n) replica algebra and Dasgupta-Ma decimation rules. The flow shows features reminiscent of infinite-randomness behavior, but an order-of-limits subtlety renders the leading recursions non-robust, so the analytic evidence for an infinite-randomness fixed point is inconclusive, even though the average second Renyi entropy displays logarithmic scaling. Together, these results provide a unified language to diagnose when many-body dynamics generate operational randomness and how measurements redirect that flow.

</details>


### [15] [Optical fuse based on the photorefractive effect for defending the light-injection attacks of quantum key distribution](https://arxiv.org/abs/2512.10205)
*Min Chen,Hong-Yan Song,Jia-Lin Chen,Peng Ye,Guo-Wei Zhang,Fang-Xiang Wang,Li Zhang,Shuang Wang,De-Yong He,Zhen-qiang Yin,Guang-Can Guo,Wei Chen,Zheng-Fu Han*

Main category: quant-ph

TL;DR: 提出并实验验证了一种基于薄膜铌酸锂微环谐振器的集成攻击感知与自动响应单元，用于防御量子密钥分发系统中的光注入攻击。


<details>
  <summary>Details</summary>
Motivation: 光注入攻击对量子密钥分发系统构成严重安全威胁，传统防御方法如隔离器、滤波器和光功率监测面临特定攻击威胁和集成限制。

Method: 利用薄膜铌酸锂微环谐振器中的光折变效应，构建集成攻击感知与自动响应单元，实现对非谐振注入光的高抑制比，对谐振攻击的自主衰减响应。

Result: 该单元对非谐振注入光提供高抑制比，对超过数十微瓦的谐振攻击能自主衰减量子信号光传输，显著抑制密钥生成速率。

Conclusion: 这项工作通过提供高灵敏度、宽带和片上防御机制，增强了QKD系统对抗光注入攻击的安全性。

Abstract: Light-injection attacks pose critical security threats to quantum key distribution (QKD) systems. Conventional defense methods, such as isolators, filters, and optical power monitoring, are confronted with the threats of specific attacks and the limitations in integration. To address this, we propose and experimentally demonstrate an integrated attack sensing and automatic response unit utilizing the photorefractive effect in a thin-film lithium niobate microring resonator. Our unit provides a high rejection ratio against non-resonant injected light. For resonant attacks exceeding tens of microwatts, the unit can autonomously attenuate the transmission of the quantum signal light, leading to a significant suppression of the secret key rate. This work enhances the security of QKD systems against light-injection attacks by providing a highly sensitive, broadband, and on-chip defense mechanism.

</details>


### [16] [Entropic Uncertainty Relations with Quantum Memory in Accelerated Frames via Unruh-DeWitt Detectors](https://arxiv.org/abs/2512.10210)
*Ming-Ming Du,Hong-Wei Li,Shu-Ting Shen,Xiao-Jing Yan,Xi-Yun Li,Lan Zhou,Wei Zhong,Yu-Bo Sheng*

Main category: quant-ph

TL;DR: 研究加速Unruh-DeWitt探测器在量子记忆辅助熵不确定关系中的行为，发现加速度不总是增加不确定关系的下界，具体取决于初始量子关联，量子失谐与最小缺失信息之间的相互作用是关键因素。


<details>
  <summary>Details</summary>
Motivation: 量子不确定性与量子关联和相对论运动密切相关。量子记忆辅助熵不确定关系是研究共享纠缠如何影响测量精度的重要工具。在加速情况下，Unruh效应会降低量子关联，这引发了关于QMA-EUR在此类设置中可靠性的问题。

Method: 使用两个均匀加速的Unruh-DeWitt探测器耦合到无质量标量场，通过Kossakowski-Lindblad主方程计算熵不确定度、其下界以及在不同Unruh温度下关系的紧致性。

Result: 加速度并不总是增加不确定关系的下界。根据探测器之间的初始关联，它可能增加或减少。这种行为源于量子失谐和最小缺失信息之间的相互作用。有趣的是，较高的量子失谐并不一定导致较低的不确定性。

Conclusion: 量子记忆辅助熵不确定关系在加速框架下的行为比预期更复杂，加速度对不确定性的影响取决于初始量子关联状态，量子失谐与不确定性的关系并非单调，这对量子信息在相对论环境中的应用具有重要意义。

Abstract: Quantum uncertainty is deeply linked to quantum correlations and relativistic motion. The entropic uncertainty relation with quantum memory offers a powerful way to study how shared entanglement affects measurement precision. However, under acceleration, the Unruh effect can degrade quantum correlations, raising questions about the reliability of QMA-EUR in such settings. Here, we investigate the QMA-EUR for two uniformly accelerating Unruh-DeWitt detectors coupled to a massless scalar field. Using the Kossakowski-Lindblad master equation, we calculate the entropic uncertainty, its lower bound, and the tightness of the relation under different Unruh temperatures. We find that acceleration does not always increase the lower bound on the uncertainty relation. Depending on the initial correlations between the detectors, it may either increase or decrease. This behavior results from the interplay between quantum discord and minimal missing information. Interestingly, a higher quantum discord does not necessarily lead to lower uncertainty.

</details>


### [17] [Optimal learning of quantum channels in diamond distance](https://arxiv.org/abs/2512.10214)
*Antonio Anna Mele,Lennart Bittel*

Main category: quant-ph

TL;DR: 量子过程层析成像中，使用O(d⁴/ε²)次信道即可在钻石距离下以精度ε估计d维系统上的量子信道，这基本是最优的。


<details>
  <summary>Details</summary>
Motivation: 量子过程层析成像是量子信息理论中的核心问题，用于表征噪声量子设备。长期以来存在一个开放性问题：确定在钻石距离（量子过程最坏情况可区分性的标准度量）下学习未知信道所需的最优信道使用次数。

Method: 使用非自适应方式利用信道制备Choi态的副本，并行纯化它们，在纯化态上执行样本最优的纯态层析成像，然后通过其半正定规划表征直接在钻石距离下分析得到的估计器。

Result: 对于作用于d维系统的量子信道，可以在钻石距离下以精度ε估计，使用O(d⁴/ε²)次信道。对于输入输出维度为d_in和d_out、Kraus秩最多为k的信道，O(d_in d_out k/ε²)次信道使用就足够了。这基本是最优的，与下界匹配（最多相差对数因子）。

Conclusion: 该研究最终解决了量子信道在钻石距离下的样本复杂度问题，同时获得了二元POVM和等距算子的算子范数学习的最优策略，并恢复了固定秩态的迹距离层析成像的最优结果。

Abstract: Quantum process tomography, the task of estimating an unknown quantum channel, is a central problem in quantum information theory and a key primitive for characterising noisy quantum devices. A long-standing open question is to determine the optimal number of uses of an unknown channel required to learn it in diamond distance, the standard measure of worst-case distinguishability between quantum processes. Here we show that a quantum channel acting on a $d$-dimensional system can be estimated to accuracy $\varepsilon$ in diamond distance using $O(d^4/\varepsilon^2)$ channel uses. This scaling is essentially optimal, as it matches lower bounds up to logarithmic factors. Our analysis extends to channels with input and output dimensions $d_{\mathrm{in}}$ and $d_{\mathrm{out}}$ and Kraus rank at most $k$, for which $O(d_{\mathrm{in}} d_{\mathrm{out}} k/\varepsilon^2)$ channel uses suffice, interpolating between unitary and fully generic channels. As by-products, we obtain, to the best of our knowledge, the first essentially optimal strategies for operator-norm learning of binary POVMs and isometries, and we recover optimal trace-distance tomography for fixed-rank states. Our approach consists of using the channel only non-adaptively to prepare copies of the Choi state, purify them in parallel, perform sample-optimal pure-state tomography on the purifications, and analyse the resulting estimator directly in diamond distance via its semidefinite-program characterisation. While the sample complexity of state tomography in trace distance is by now well understood, our results finally settle the corresponding problem for quantum channels in diamond distance.

</details>


### [18] [Generating strong mechanical squeezing via combined squeezed vacuum field and two-tone driving](https://arxiv.org/abs/2512.10215)
*Xiao-Jie Wu,Huan-Huan Cheng,Cheng-Hua Bai,Shao-Xiong Wu*

Main category: quant-ph

TL;DR: 提出基于双音驱动和压缩真空场的新方案，显著提升机械压缩态性能，具有强鲁棒性和操作灵活性


<details>
  <summary>Details</summary>
Motivation: 传统机械压缩态生成方法存在参数匹配要求严格、性能受限等问题，需要更有效且鲁棒的方案

Method: 结合双音驱动和压缩真空场机制，通过相位匹配实现位置和动量压缩，利用压缩参数非线性增强效应

Result: 在全红/蓝失谐比范围内显著改善机械压缩性能，压缩度随压缩参数r非线性增强，具有2π周期性相位依赖

Conclusion: 该方案为机械压缩态生成提供了高效、鲁棒且灵活的新途径，显著降低了对腔耗散和环境热噪声的敏感性

Abstract: We propose a novel scheme for generating mechanical squeezed states based on the combined mechanism of a two-tone driving and a squeezed vacuum field. This innovative approach achieves a remarkable improvement in mechanical squeezing performance across the entire range of red/blue detuning ratios. Our study reveals that the squeezed vacuum field not only induces position squeezing of the mechanical oscillator but also facilitates momentum squeezing through phase matching. Moreover, the total squeezing degree exhibits nonlinear enhancement with the increasing of squeezing parameter $r$. The mechanical squeezed state exhibits a $2π$-periodic dependence in relation to the squeezing phase $θ$, offering experimental implementation with a high degree of operational flexibility. Notably, the scheme exhibits strong robustness against cavity dissipation and environmental thermal noise, substantially relaxing the strict parameter-matching requirements inherent in conventional approaches.

</details>


### [19] [Catalytic Tomography of Ground States](https://arxiv.org/abs/2512.10247)
*Chi-Fang Chen,Robbie King*

Main category: quant-ph

TL;DR: 提出一种测量有隙基态性质的简单协议，几乎不扰动量子态，演化时间与能隙和目标精度成反比，对局域可观测量只需在逆能隙半径的准局域区域演化。


<details>
  <summary>Details</summary>
Motivation: 传统量子态测量方法会显著扰动量子态，特别是有隙基态的性质测量需要复杂操作。本文旨在开发一种几乎不扰动量子态的测量协议，减少量子模拟中的层析开销。

Method: 提出基于哈密顿演化的简单协议，演化时间与能隙和目标精度成反比（达到对数因子最优）。对于几何局域系统的局域可观测量，协议只需在逆能隙半径的准局域区域进行哈密顿演化。

Result: 协议证明有隙基态可以从单拷贝中算法可读，无需恢复或回绕过程。演化时间尺度达到最优，且对局域可观测量只需准局域演化，显著降低了量子模拟中的层析开销。

Conclusion: 有隙基态的性质可以通过几乎不扰动量子态的协议高效测量，演化时间最优且只需准局域操作，为量子模拟中的状态测量提供了实用工具。

Abstract: We introduce a simple protocol for measuring properties of a gapped ground state with essentially no disturbance to the state. The required Hamiltonian evolution time scales inversely with the spectral gap and target precision (up to logarithmic factors), which is optimal. For local observables on geometrically local systems, the protocol only requires Hamiltonian evolution on a quasi-local patch of inverse-gap radius. Our results show that gapped ground states are algorithmically readable from a single copy without a recovery or rewinding procedure, which may drastically reduce tomography overhead in certain quantum simulation tasks.

</details>


### [20] [Quantum relaxometry for detecting biomolecular interactions with single NV centers](https://arxiv.org/abs/2512.10269)
*Min Li,Qi Zhang,Xi Kong,Sheng Zhao,Bin-Bin Pan,Ziting Sun,Pei Yu,Zhecheng Wang,Mengqi Wang,Wentao Ji,Fei Kong,Guanglei Cheng,Si Wu,Ya Wang,Sanyou Chen,Xun-Cheng Su,Fazhan Shi*

Main category: quant-ph

TL;DR: 该研究开发了一种基于金刚石氮空位中心量子传感器的弛豫测量方法，实现了接近单分子水平的分子相互作用分析，能够检测从强到弱的生物分子相互作用。


<details>
  <summary>Details</summary>
Motivation: 生物分子在单分子水平的相互作用研究是生命科学的关键领域，但以往的自旋检测大多局限于系综水平。本研究旨在开发一种能够接近单分子水平的分子相互作用分析方法。

Method: 使用金刚石氮空位中心作为量子传感器进行弛豫测量。通过优化金刚石表面功能化，采用聚乙烯亚胺纳米凝胶层，实现约10纳米的平均蛋白质距离并减少界面空间位阻。分别使用系综NV中心和单个NV中心进行微米尺度和纳米尺度的测量。

Result: 成功测量了链霉亲和素与自旋标记生物素复合物之间的强相互作用，以及牛血清白蛋白与生物素复合物之间的弱相互作用。在微米尺度测量中，重新考察了常被忽略的快速弛豫分量，提出了弛豫速率评估方法，显著提高了测量灵敏度。在纳米尺度上实现了接近单分子水平的检测。

Conclusion: 该方法有望应用于单分子水平的分子筛选、识别和动力学研究，为分子功能和活性机制提供重要见解，展示了量子传感器在生物分子相互作用研究中的巨大潜力。

Abstract: The investigation of biomolecular interactions at the single-molecule level has emerged as a pivotal research area in life science, particularly through optical, mechanical, and electrochemical approaches. Spins existing widely in biological systems, offer a unique degree of freedom for detecting such interactions. However, most previous studies have been largely confined to ensemble-level detection in the spin degree. Here, we developed a molecular interaction analysis method approaching single-molecule level based on relaxometry using the quantum sensor, nitrogen-vacancy (NV) center in diamond. Experiments utilized an optimized diamond surface functionalized with a polyethylenimine nanogel layer, achieving $\sim$10 nm average protein distance and mitigating interfacial steric hindrance. Then we measured the strong interaction between streptavidin and spin-labeled biotin complexes, as well as the weak interaction between bovine serum albumin and biotin complexes, at both the micrometer scale and nanoscale. For the micrometer-scale measurements using ensemble NV centers, we re-examined the often-neglected fast relaxation component and proposed a relaxation rate evaluation method, substantially enhancing the measurement sensitivity. Furthermore, we achieved nanoscale detection approaching single-molecule level using single NV centers. This methodology holds promise for applications in molecular screening, identification and kinetic studies at the single-molecule level, offering critical insights into molecular function and activity mechanisms.

</details>


### [21] [Single-molecule Scale Nuclear Magnetic Resonance Spectroscopy using a Robust Near-Infrared Spin Sensor](https://arxiv.org/abs/2512.10278)
*Yu Chen,Qi Zhang,Yuanhong Teng,Chihang Luo,Zhijie Li,Jinpeng Liu,Ya Wang,Fazhan Shi,Jiangfeng Du*

Main category: quant-ph

TL;DR: PL6量子缺陷在4H-SiC中作为近红外自旋传感器，实现了2nm深度下的纳米级NMR检测，达到单质子自旋检测灵敏度


<details>
  <summary>Details</summary>
Motivation: 单分子水平、原子分辨率的核磁共振在结构生物学和表面化学中具有变革性潜力，但需要能够在生物相容光谱范围内工作且对表面扰动具有鲁棒性的近表面固态自旋传感器

Method: 利用4H-SiC中的PL6量子缺陷作为近红外自旋传感器，该传感器在组织透明波长下工作，在2nm深度仍表现出优异的近表面稳定性。使用浅层PL6中心实现了对浸没油中质子自旋和Fomblin中氟自旋的纳米级NMR检测

Result: 实现了(3nm)³的检测体积，灵敏度达到单质子自旋检测要求，成功检测了质子(¹H)和氟(¹⁹F)自旋

Conclusion: 4H-SiC量子传感器为纳米级磁共振提供了一个有前景的平台，在探测低维水相、蛋白质折叠动力学和分子相互作用方面具有应用潜力

Abstract: Nuclear magnetic resonance (NMR) at the single-molecule level with atomic resolution holds transformative potential for structural biology and surface chemistry. Near-surface solid-state spin sensors with optical readout ability offer a promising pathway toward this goal. However, their extreme proximity to target molecules demands exceptional robustness against surface-induced perturbations. Furthermore, life science applications require these sensors to operate in biocompatible spectral ranges that minimize photodamage. In this work, we demonstrate that the PL6 quantum defect in 4H silicon carbide (4H-SiC) can serve as a robust near-infrared spin sensor. This sensor operates at tissue-transparent wavelengths and exhibits exceptional near-surface stability even at depth of 2 nm. Using shallow PL6 centers, we achieve nanoscale NMR detection of proton ($\mathrm{^{1}H}$) spins in immersion oil and fluorine ($\mathrm{^{19}F}$) spins in Fomblin, attaining a detection volume of $\mathrm{(3~nm)^3}$ and a sensitivity reaching the requirement for single-proton spin detection. This work establishes 4H-SiC quantum sensors as a compelling platform for nanoscale magnetic resonance, with promising applications in probing low-dimensional water phases, protein folding dynamics, and molecular interactions.

</details>


### [22] [Gradient projection method and stochastic search for some optimal control models with spin chains. II](https://arxiv.org/abs/2512.10290)
*Oleg V. Morzhin*

Main category: quant-ph

TL;DR: 本文是系列研究的第二部分，针对N维自旋链的转移和保持问题，推导了有限维梯度公式，改进了梯度投影方法(GPM)。通过N=3的案例验证了改进GPM和遗传算法(GA)的有效性，并展示了多步GPM优于单步GPM。对于N=20且未指定最终时间的转移问题，GA和特殊控制类也成功求解。


<details>
  <summary>Details</summary>
Motivation: 延续系列研究的第一部分，针对自旋链最优控制模型，需要将第一部分得到的无限维梯度转化为有限维梯度，以便在实际计算中应用梯度投影方法(GPM)求解转移和保持问题。

Method: 1. 推导N维自旋链转移和保持问题对应的有限维梯度公式；2. 相应调整最优性投影条件；3. 改进梯度投影方法(GPM)；4. 使用遗传算法(GA)作为对比方法；5. 针对N=3和N=20的不同规模问题进行数值求解。

Result: 1. 对于N=3的自旋链，改进的GPM和GA成功求解了转移和保持问题；2. 两步和三步GPM形式显著优于单步GPM；3. 对于N=20且未指定最终时间的转移问题，GA和特殊控制类也能成功求解。

Conclusion: 本文成功将无限维梯度转化为有限维梯度，改进了GPM方法，并通过数值实验验证了多步GPM的优越性。对于大规模问题(N=20)，GA和特殊控制类也展现了良好的求解能力，为自旋链最优控制问题提供了有效的数值求解方案。

Abstract: This article (II) continues the research described in [Morzhin O.V. Gradient projection method and stochastic search for some optimal control models with spin chains. I (submitted)] (Article I), derives the needed finite-dimensional gradients corresponding to the infinite-dimensional gradients obtained in Article I, both for transfer and keeping problems at a certain $N$-dimensional spin chain, and correspondingly adapts a projection-type condition for optimality, gradient projection method (GPM). For the case $N=3$, the given in this article examples together with Example 3 in Article I show that: a) the adapted GPM and genetic algorithm (GA) successfully solved numerically the considered transfer and keeping problems; b) the two- and three-step GPM forms significantly surpass the one-step GPM. Moreover, GA and a special class of controls were successfully used in such the transfer problem that $N=20$ and the final time is not assigned.

</details>


### [23] [Tunable discrete quasi-time crystal from a single drive](https://arxiv.org/abs/2512.10303)
*Xu Feng,Shuo Liu,Shu Chen,Shi-Xin Zhang*

Main category: quant-ph

TL;DR: 本文提出了一种在耗散集体自旋系统中实现可调谐离散准时间晶体的简化机制，仅需单一周期驱动即可产生复杂时间序，且响应频率可通过驱动强度连续调节。


<details>
  <summary>Details</summary>
Motivation: 当前实现离散准时间晶体等奇异时间序需要复杂协议（如多频率非公度驱动），本文旨在寻找更简单的实现机制，降低实验难度并提高可控性。

Method: 采用耗散集体自旋系统，仅施加单一周期驱动，通过调节驱动强度实现频率连续可调的离散准时间晶体，并观察到响应频率锁定到驱动频率有理分数的阿诺德舌现象。

Result: 成功实现了频率可连续调节的离散准时间晶体，发现了阿诺德舌频率锁定现象，并建立了统一框架涵盖稳态、离散时间晶体和混沌相。

Conclusion: 该发现简化了产生复杂时间序的要求，为实验控制和操纵准时间晶体物质开辟了可行途径。

Abstract: The search for exotic temporal orders in quantum matter, such as discrete quasi-time crystals (DQTCs), has become an important theme in nonequilibrium physics. However, realizing these phases has so far required complex protocols, such as drives with multiple incommensurate frequencies. Here, we present a significantly simpler mechanism: the emergence of DQTCs in a dissipative collective spin system subjected to only a single periodic drive. Remarkably, the characteristic frequencies of this novel phase are not fixed but can be continuously tuned by varying the strength of the drive. Even more strikingly, this tunability is punctuated by Arnold tongues, within which the response main frequency locks to rational fractions of the drive. Our model further provides a unified framework that also encompasses stationary, discrete time crystals and chaotic phases. This discovery simplifies the requirements for generating complex temporal orders and opens a viable route towards the experimental control and manipulation of quasi-time crystalline matter.

</details>


### [24] [Improved gap dependence in adiabatic state preparation by adaptive schedule](https://arxiv.org/abs/2512.10329)
*Dong An,Xi Guo*

Main category: quant-ph

TL;DR: 提出非线性自适应策略优化绝热量子计算的时间调度函数，将演化时间对能隙的依赖从二次改进为线性，证明了线性调度方案的非最优性。


<details>
  <summary>Details</summary>
Motivation: 绝热量子计算是强大的状态制备框架，但其演化时间通常与哈密顿量谱隙的倒数呈二次方关系，导致计算复杂度不够优化。需要改进时间调度策略来降低对能隙的依赖。

Method: 引入非线性自适应策略来寻找时间调度函数，通过变分分析证明该策略的最优性。在温和的能隙度量条件下，该方法适用于广泛的系统。

Result: 该方法将能隙依赖从二次改进为线性，对于具有线性能隙的系统证明了最优性，对于一般系统证明了部分最优性。同时严格证明了常用的线性调度方案从来不是最优的。

Conclusion: 非线性自适应调度策略显著提高了绝热量子计算的效率，为优化量子状态制备提供了有效方法，对量子计算的实际应用具有重要意义。

Abstract: Adiabatic quantum computing is a powerful framework for state preparation, while its evolution time often scales quadratically in the inverse Hamiltonian spectral gap, leading to sub-optimal computational complexity. In this work, we introduce a nonlinear adaptive strategy for finding the time scheduling function, and show that the gap dependence can be quadratically improved to be inverse linear for a wide range of systems under a mild gap measure condition. Through variational analysis, we further demonstrate the optimality of our schedule for systems with linear gap and the partial optimality for general systems, while we also rigorously show that the commonly used linear schedule is never optimal.

</details>


### [25] [Generation of mechanical cat-like states via optomagnomechanics](https://arxiv.org/abs/2512.10347)
*Hao-Tian Li,Hong-Bin Wang,Zi-Xu Lu,Jie Li*

Main category: quant-ph

TL;DR: 提出了一种通过光磁力学系统制备机械运动猫态的方法，包括两步：先用双音微波驱动制备压缩机械态，再用弱红失谐光脉冲进行光子探测，通过减去k个声子制备猫态。


<details>
  <summary>Details</summary>
Motivation: 为制备宏观量子态（特别是机械运动的猫态）提供新途径，结合光力学和磁力学的优势，可用于研究宏观量子现象和检验坍缩理论。

Method: 基于光磁力学系统，磁致伸缩效应使机械位移与光学腔模耦合。第一步：用双音微波驱动磁力学系统制备压缩机械态；第二步：关闭微波驱动，向光学腔发送弱红失谐光脉冲，微弱激活光力反斯托克斯散射，通过探测腔输出场中的k个反斯托克斯光子，从压缩态中减去k个声子。

Result: 成功展示了通过光子探测减去k个声子，可以从压缩机械态制备出猫态（机械运动的叠加态）。该方法为制备机械叠加态提供了新途径。

Conclusion: 该工作结合光力学和磁力学，为制备机械猫态提供了新方法，在宏观量子态研究和坍缩理论检验方面具有应用潜力。

Abstract: We propose an optomagnomechanical approach for preparing a cat-like superposition state of mechanical motion. Our protocol consists of two steps and is based on the magnomechanical system where the magnetostrictively induced displacement further couples to an optical cavity mode via radiation pressure. We first prepare a squeezed mechanical state by driving the magnomechanical system with a two-tone microwave field. We then switch off the microwave drives and send a weak red-detuned optical pulse to the optical cavity to weakly activate the optomechanical anti-Stokes scattering. We show that $k$ phonons can be subtracted from the prepared squeezed state, conditioned on the detection of $k$ anti-Stokes photons from the cavity output field, which prepares the mechanical motion in a cat-like state. The work provides a new avenue for preparing mechanical superposition states by combining opto- and magnomechanics and may find applications in the study of macroscopic quantum states and the test of collapse theories.

</details>


### [26] [On the Optimality of a Quantum Key Distribution](https://arxiv.org/abs/2512.10351)
*Georgi Bebrov*

Main category: quant-ph

TL;DR: 该论文提出了一种评估量子密钥分发系统最优性的方法，通过引入"最优性"指标来衡量QKD协议在任意参数下的最大总效率，并展示了如何实现完全高效的QKD系统。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发系统需要在量子信道和经典信道上都达到最优性能，即使用尽可能少的量子比特和经典比特来建立尽可能多的密钥比特。然而，目前缺乏一种系统性的方法来评估QKD模型或协议是否在最优状态下运行。

Method: 引入了一个称为"最优性"的量，定义为QKD在任何情况下（任何参数值下）的最大总效率。该定义针对QKD系统的渐近操作（当无限多量子系统被传输/使用，或QKD系统被使用无限多次时）。提出了实现最优性的方法——实现完全高效的QKD系统（结合容量达到的量子信道和完全压缩的经典信道）。并介绍了BB84-QKD和双场QKD的最优版本。

Result: 建立了评估QKD协议最优性的理论框架，定义了最优性指标，并展示了如何实现完全高效的QKD系统。具体提出了BB84-QKD和双场QKD的最优版本。

Conclusion: 该研究提供了一种确定量子密钥分发模型是否在最优状态下运行的方法，通过引入最优性指标和实现完全高效QKD系统的途径，为QKD系统的性能评估和优化提供了理论基础。

Abstract: Quantum key distribution (QKD) systems require optimal performance of both quantum and classical channels - utilizing as few as possible qubits and bits for establishing as many as possible key bits. Here we report a way to determine if a quantum key distribution model (or protocol) operates in an optimal behavior. This is accomplished by introducing a quantity, called optimality, which is the maximum over the total efficiency of a QKD under any circumstances (any values of QKD parameters). The optimality definition is given for the asymptotic operation of a QKD system - when infinitely many quantum systems are transferred/used in a quantum key distribution protocol or a quantum key distribution system is used infinitely many times. A way to attain the optimality is considered\textemdash implementation of a completely efficient QKD system (a combination of capacity-reaching quantum channel and a completely compressed classical channel) is presented. Optimal versions of BB84-QKD and twin-field QKD are introduced.

</details>


### [27] [Quantum Separability Criteria Based on Symmetric Measurements](https://arxiv.org/abs/2512.10380)
*Yu Lu,Wen Zhou,Meng Su,Hong-Xing Wu,Shao-Ming Fei,Zhi-Xi Wang*

Main category: quant-ph

TL;DR: 提出基于局域对称测量的实验可行二分系统可分性判据，比现有方法更有效检测纠缠，并可推广到多体系统


<details>
  <summary>Details</summary>
Motivation: 现有纠缠检测方法在实验可行性和检测效率方面存在局限，需要开发基于局域测量的更有效可分性判据

Method: 基于局域对称测量构建可分性判据，通过具体示例验证方法的有效性

Result: 提出的判据比现有方法能更有效地检测纠缠，且具有实验可行性

Conclusion: 基于局域对称测量的可分性判据为纠缠检测提供了有效工具，并可推广到多体系统

Abstract: We propose experimentally feasible separability criteria for bipartite systems based on local symmetric measurements. Through detailed examples, we demonstrate that our criteria can detect entanglement more effectively compared to existing counterparts. Furthermore,we demonstrate the potential for our results to be generalized to general multipartite systems.

</details>


### [28] [Ising on the donut: Regimes of topological quantum error correction from statistical mechanics](https://arxiv.org/abs/2512.10399)
*Lucas H. English,Sam Roberts,Stephen D. Bartlett,Andrew C. Doherty,Dominic J. Williamson*

Main category: quant-ph

TL;DR: 该论文通过将比特翻转噪声下的环面码映射到精确可解的二维伊辛模型，首次推导出逻辑错误率的解析解，覆盖了物理错误率的全部范围，为量子纠错性能分析提供了新的理论工具。


<details>
  <summary>Details</summary>
Motivation: 大规模量子计算机需要具有大量物理量子比特的量子纠错码来实现足够低的逻辑错误率。目前量子纠错性能主要通过大规模数值模拟来预测，但这种方法计算成本高且缺乏理论深度。统计力学模型为分析量子纠错性能提供了替代工具，但这些模型通常也需要大规模数值模拟，因为解析解一般未知。

Method: 利用精确映射：将比特翻转噪声下且后选择无错综合征的环面码映射到环面上的精确可解二维伊辛模型。通过这种映射，推导出逻辑错误率在整个物理错误率范围内的解析解。此外，针对非后选择码的常规量子纠错设置，提出了有效表面张力模型（低于阈值区域）和新的标度假说（近阈值区域）。

Result: 获得了逻辑错误率在四个不同区域的闭式表达式：路径计数区域、低于阈值（有序）区域、近阈值（临界）区域和高于阈值（无序）区域。将许多熟悉且长期存在的数值观察结果建立在坚实的理论基础上。为涉及随机键无序的统计力学映射的常规量子纠错设置提供了明确的假说。

Conclusion: 通过桥接统计力学理论和量子纠错实践，该研究结果为超越当前计算极限设计、基准测试和理解拓扑码提供了新的工具包。这种解析方法为量子纠错性能分析提供了更深刻的理论基础，有望推动量子纠错码的设计和优化。

Abstract: Utility-scale quantum computers require quantum error correcting codes with large numbers of physical qubits to achieve sufficiently low logical error rates. The performance of quantum error correction (QEC) is generally predicted through large-scale numerical simulations, used to estimate thresholds, finite-size scaling, and exponential suppression of logical errors below threshold. The connection of QEC to models from statistical mechanics provides an alternative tool for analysing QEC performance. However, predicting the behaviour of these models also requires large-scale numerical simulations, as analytic solutions are not generally known. Here we exploit an exact mapping, from a toric code under bit-flip noise that is post-selected on being syndrome free to the exactly-solvable two-dimensional Ising model on a torus, to derive an analytic solution for the logical failure rate across its full domain of physical error rates. In particular, this mapping provides closed-form expressions for the logical failure rate in four distinct regimes: the path-counting, below-threshold (ordered), near-threshold (critical), and above-threshold (disordered) regimes. Our framework places a number of familiar and long-standing numerical observations on firm theoretical ground. It also motivates explicit ansätze for the conventional QEC setting of non-post-selected codes whose statistical mechanics mappings involve random-bond disorder. Specifically, we introduce an effective surface tension model for the below-threshold regime, and a new scaling ansatz for the near-threshold regime, derived from an analysis of the ground state energy cost distribution. By bridging statistical mechanics theory and quantum error correction practice, our results offer a new toolkit for designing, benchmarking, and understanding topological codes beyond current computational limits.

</details>


### [29] [Robust population transfer by a detuning sign jump: from two-state quantum system to SU(2)-symmetric three-state quantum system](https://arxiv.org/abs/2512.10432)
*Peter Chernev,Andon A. Rangelov*

Main category: quant-ph

TL;DR: 提出了一种基于失谐符号突变的鲁棒性布居转移协议，在二能级系统中通过平滑耦合脉冲最大处突然改变失谐符号实现高效布居反转，并将该方法扩展到三能级系统。


<details>
  <summary>Details</summary>
Motivation: 开发一种在驱动二能级系统中实现高保真布居转移的鲁棒性协议，该方法结合了绝热动力学和单次非绝热冲击，并能够扩展到多能级系统。

Method: 在平滑耦合脉冲最大处突然改变失谐符号，产生单次非绝热冲击；采用逐步绝热-突变近似获得解析解；利用Majorana分解将方案扩展到SU(2)对称的三能级系统。

Result: 获得了最终跃迁概率的紧凑解析表达式，确定了高保真反转的参数范围；数值模拟验证了该描述在广泛参数范围内的有效性和鲁棒性；在三能级系统中实现了两个外态之间的几乎完全布居转移。

Conclusion: 提出的协议在二能级和三能级系统中都能实现高效、鲁棒的布居转移，结果仅取决于失谐突变前后混合角的变化，具有内在的鲁棒性。

Abstract: We propose and analyze a robust population-transfer protocol in a driven two-level system based on a sudden sign change of the detuning at the maximum of a smooth coupling pulse. Away from the jump the dynamics is adiabatic, while the sign flip produces a single nonadiabatic kick in the adiabatic basis. Within a simple stepwise adiabatic-sudden approximation we obtain a compact analytic expression for the final transition probability, identify the parameter regimes that yield high-fidelity inversion, and show that the result depends only on the change of the mixing angle across the detuning jump, i.e., solely on the ratio of the peak Rabi frequency to the detuning. Numerical simulations of the full time-dependent Schrödinger equation confirm the validity and robustness of this description over a broad parameter range.
  We then use the Majorana decomposition to extend the scheme to an SU(2)-symmetric three-state chain driven by the same coupling and detuning functions. In this setting the three-state propagator is expressed in closed form through the two-level Cayley-Klein parameters, which allows us to derive explicit transition probabilities for all three initial states. In particular, we show that for strong coupling the protocol yields almost complete population transfer between the two outer states, with only small transient population of the middle state, while retaining the same intrinsic robustness as in the underlying two-level model.

</details>


### [30] [Optimal Distributed Similarity Estimation for Unitary Channels](https://arxiv.org/abs/2512.10465)
*Congcong Zheng,Kun Wang,Xutao Yu,Ping Xu,Zaichen Zhang*

Main category: quant-ph

TL;DR: 本文研究了分布式酉通道相似性估计问题，证明了对于n量子比特酉通道，查询复杂度为Θ(√d)，其中d=2^n，无论使用非相干还是相干访问方式。


<details>
  <summary>Details</summary>
Motivation: 研究分布式量子设备中酉通道相似性估计问题，为量子设备基准测试和分布式量子学习提供理论基础和实用工具。

Method: 提出了两种基于随机化测量工具箱的估计算法：一种使用相干访问，另一种使用非相干访问但利用设备间的共享随机性。同时建立了匹配的下界证明。

Result: 证明了分布式酉通道相似性估计的查询复杂度为Θ(√d)，其中d=2^n。提出的算法复杂度为O(√d)，相比独立经典影子方法具有平方根优势。

Conclusion: 本文完全解决了分布式酉通道相似性估计问题，提供了理论上最优且实用的工具，展示了共享随机性在分布式量子学习中的重要作用。

Abstract: We study distributed similarity estimation for unitary channels (DSEU), the task of estimating the similarity between unitary channels implemented on different quantum devices. We completely address DSEU by showing that, for $n$-qubit unitary channels, the query complexity of DSEU is $Θ(\sqrt{d})$, where $d=2^n$, for both incoherent and coherent accesses. First, we propose two estimation algorithms for DSEU with these accesses utilizing the randomized measurement toolbox. The query complexities of these algorithms are both $O(\sqrt{d})$. Although incoherent access is generally weaker than coherent access, our incoherent algorithm matches this complexity by leveraging additional shared randomness between devices, highlighting the power of shared randomness in distributed quantum learning. We further establish matching lower bounds, proving that $Θ(\sqrt{d})$ queries are both necessary and sufficient for DSEU. Finally, we compare our algorithms with independent classical shadow and show that ours have a square-root advantage. Our results provide practical and theoretically optimal tools for quantum devices benchmarking and for distributed quantum learning.

</details>


### [31] [On Simplest Kochen-Specker Sets](https://arxiv.org/abs/2512.10483)
*Mladen Pavicic*

Main category: quant-ph

TL;DR: 本文指出PRL 2025年声称发现的"最简单3D上下文集合"实际上早在2023年已被生成，并分析了任意维度中最简上下文集合的意义、起源和重要性。


<details>
  <summary>Details</summary>
Motivation: 纠正PRL 2025年论文中关于"发现最简单3D上下文集合"的错误声称，指出该集合实际上在2023年已被生成，并澄清上下文集合的基本概念和定义。

Method: 通过数学证明和自动生成算法分析，证明PRL声称的集合并非最基本，因为存在具有更少完整基数的3D上下文集合，并展示自动生成算法能在零CPU时间内生成所有已知最小上下文集合。

Result: 证明PRL 2025年声称的"最简单"集合并非真正最基本，存在具有更少完整基数的3D上下文集合；自动生成算法能高效生成所有已知最小上下文集合；澄清了Kochen-Specker(KS)、扩展KS和非KS集合的定义模糊性。

Conclusion: PRL 2025年声称的发现并非原创，该集合已在2023年被生成；不存在"最基本"的上下文集合，因为存在更简单的变体；自动生成算法是研究上下文集合的有效工具；需要更清晰地定义各类上下文集合以避免混淆。

Abstract: In Phys. Rev. Lett. 135, 190203 (2025) a discovery of the simplest 3D contextual set with 33 vertices, 50 bases, and 14 complete bases is claimed. In this paper, we show that it was previously generated in Quantum 7, 953 (2023) and analyze the meaning, origin, and significance of the simplest contextual sets in any dimension. In particular, we prove that there is no ground to consider the aforementioned set as fundamental since there are many 3D contextual sets with a smaller number of complete bases. We also show that automatic generation of contextual sets from basic vector components automatically yields all known minimal contextual sets of any kind in any dimension and therefore also the aforementioned set in no CPU-time. In the end, we discuss varieties of contextual sets, in particular Kochen-Specker (KS), extended KS, and non-KS sets as well as ambiguities in their definitions.

</details>


### [32] [The relativistic reason for quantum probability amplitudes](https://arxiv.org/abs/2512.10497)
*Karol Sajnok,Kacper Dębski,Andrzej Dragan*

Main category: quant-ph

TL;DR: 从三个自然条件推导出量子力学概率分布：相对论不变性、时间对称性和贝叶斯规则，恢复费曼路径积分公式


<details>
  <summary>Details</summary>
Motivation: 从基本原理推导量子力学概率分布，特别是解释为什么量子概率涉及复数概率幅而不是经典概率

Method: 对描述粒子多路径同时运动的相对论不变概率函数施加三个条件：(i)成对可加性，(ii)时间对称性，(iii)贝叶斯规则

Result: 得到由单个常数参数化的解，即相对论作用量复数指数和的模平方，恢复费曼路径积分公式

Conclusion: 量子力学的概率分布可以从三个自然条件推导出来，为量子力学的概率幅形式提供了基本原理解释

Abstract: We show that the quantum-mechanical probability distribution involving complex probability amplitudes can be derived from three natural conditions imposed on a relativistically invariant probability function describing the motion of a particle that can take multiple paths simultaneously. The conditions are: (i) pairwise Kolmogorov additivity, (ii) time symmetry, and (iii) Bayes' rule. The resulting solution, parameterized by a single constant, is the squared modulus of a sum of complex exponentials of the relativistic action, thereby recovering the Feynman path-integral formulation of quantum mechanics.

</details>


### [33] [Tianyan: Cloud services with quantum advantage](https://arxiv.org/abs/2512.10504)
*Tianyan Quantum Group*

Main category: quant-ph

TL;DR: 天演量子云平台提供基于祖冲之3.0类超导量子处理器的云服务，展示了量子优势能力，其天演-287原型拥有105个量子比特和高保真度操作，在特定基准任务中比经典超级计算机快约16000倍。


<details>
  <summary>Details</summary>
Motivation: 该平台的动机是民主化高性能量子硬件的访问，让研究社区能够验证和探索实际的量子优势，推动量子计算的实际应用和发展。

Method: 平台采用天演-287超导量子原型，拥有105个量子比特，通过高保真度操作（单量子比特门99.90%、双量子比特门99.56%、读取保真度98.7%）实现量子优势。提供Cqlib开源SDK，支持在扩展量子电路、算子和原语级别上工作。

Result: 在74个量子比特系统上进行24个周期的随机电路采样基准任务中，平台仅需18.4分钟完成100万个样本，而最先进的经典超级计算机需要约16000年才能完成等效计算，展示了显著的量子优势。

Conclusion: 天演量子云平台成功展示了量子优势能力，通过云服务使研究社区能够访问高性能量子硬件，为量子计算的实际应用和验证提供了重要平台。

Abstract: Tianyan Quantum Cloud Platform offers cloud services demonstrating quantum advantage capabilities with a Zuchongzhi 3.0-like superconducting quantum processor. This cloud-accessible superconducting quantum prototype, named Tianyan-287, features 105 qubits and achieves high operational fidelities, with single-qubit gates, two-qubit gates, and readout fidelity at 99.90%, 99.56%, 98.7%, respectively. For a specific benchmark task involving random circuit sampling on a 74-qubit system over 24 cycles, the platform completes one million samples in just 18.4 minutes. In contrast, state-of-the-art classical supercomputers would require approximately 16,000 years to complete the equivalent calculation. To facilitate this, the platform provides access via Cqlib, an open-source SDK designed for working with quantum systems at the level of extended quantum circuits, operators, and primitives. The cloud service aims to democratize access to high-performance quantum hardware, enabling the community to validate and explore practical quantum advantages.

</details>


### [34] [Encoding parameters by measurement: Forgetting can be better in quantum metrology](https://arxiv.org/abs/2512.10541)
*Shuva Mondal,Priya Ghosh,Ujjwal Sen*

Main category: quant-ph

TL;DR: 量子参数估计中，通过量子测量进行编码，研究记录或忽略测量结果对估计精度的影响，发现在许多情况下忽略结果反而精度更高。


<details>
  <summary>Details</summary>
Motivation: 研究量子参数估计中测量编码的特殊情况，探索记录或忽略测量结果对估计精度的影响，特别是在量子测量作为编码过程时。

Method: 用量子参数估计框架分析两输出量子比特测量，比较记录测量结果和忽略测量结果两种策略的精度，推导相关判据，并研究双参数同时估计的情况。

Result: 发现在多种估计场景中，忽略测量结果能获得更高精度；建立了记录结果策略优于忽略结果策略的必要条件；确定了双参数同时估计时量子Cramér-Rao界有效且可达的条件。

Conclusion: 量子参数估计中，测量编码过程具有特殊性，忽略测量结果往往能提高估计精度，这为量子测量表征和参数估计提供了新的理论见解。

Abstract: We introduce quantum parameter estimation with the encoding being via a quantum measurement. We quantify the precision for estimating parameters characterizing a general two-outcome qubit measurement, considering two cases: when the outcomes of the encoding measurement are recorded and when the same are ignored. We find that in a large variety of such estimation scenarios, forgetting the outcomes yields higher precision. We derive a necessary criterion under which remembering the measurement outcomes provides better precision in comparison to the outcome-forgotten strategy. Furthermore, we establish a necessary and sufficient criterion for the simultaneous estimation of two parameters encoded by an arbitrary quantum process, including those involving measurements, using qubit probes, and find when the quantum Cramér$-$Rao bound is valid and achievable. For simultaneous estimation of two parameters characterizing the measurement, we find that the achievable quantum Cramér$-$Rao bound can be a valid precision bound only when the measurement direction depends on the parameters of interest.

</details>


### [35] [Hybrid Quantum Annealing Approach for High-Dimensional and Multi-Criteria Constrained Quadratic Optimization in Arctic Ship Routing](https://arxiv.org/abs/2512.10544)
*Tara Kit,Kimsay Pov,Myeongseong Go,Leanghok Hour,Arim Ryou,Kiwoong Kim,Tae-Kyung Kim,Youngsun Han*

Main category: quant-ph

TL;DR: 该研究将CMEMS海洋环境数据整合到约束二次模型中，使用D-Wave混合量子经典求解器解决北极航线优化问题，相比传统MIQP求解器实现了10-100倍加速和10%的航线平滑度提升。


<details>
  <summary>Details</summary>
Motivation: 北极航道的开辟为全球贸易带来机遇，但海冰条件的动态变化带来了显著的运营和计算挑战，需要开发更高效的航线优化方法。

Method: 将Copernicus海洋环境监测服务变量整合到约束二次模型中，使用D-Wave的混合量子经典求解器解决多准则北极航线优化问题，并与Gurobi、CPLEX等传统MIQP求解器进行基准测试。

Result: CQM方法在二次密度增加时仍能保持稳定的运行时间，相比经典求解器实现10-100倍的收敛加速和计算时间减少，同时航线平滑度提升约10%，总长度减少约1%。

Conclusion: 混合量子退火方法在解决北极航线优化问题上具有显著优势，展示了量子计算在复杂海洋环境优化问题中的应用潜力。

Abstract: The opening of Arctic sea routes presents unprecedented opportunities for global trade but poses significant operational and computational challenges due to the dynamic nature of sea ice conditions. This study formulates a multi criteria Arctic route optimization problem that integrates Copernicus Marine Environment Monitoring Service (CMEMS) variables into a Constrained Quadratic Model (CQM) and solves it using D Wave's hybrid quantum classical solver. We benchmark the feasibility and scalability of this approach against classical Mixed Integer Quadratic Programming (MIQP) solvers such as Gurobi and CPLEX. Results show that the CQM formulation achieves feasible solutions with stable runtimes as quadratic density increases, demonstrating 10 to 100 times faster convergence and reduced computational time compared with classical solvers, while also improving route smoothness by approximately 10 percent and reducing total length by approximately 1 percent. This reflects the effectiveness of the hybrid quantum annealing approach for Arctic routing problems.

</details>


### [36] [Sensitivity threshold defines the optimal spin subset for ensemble quantum sensing](https://arxiv.org/abs/2512.10549)
*Suwan I. Kang,Minhyeok Kim,Sanghyo Park,Heonsik Lee,Keunyoung Lee,Donggyu Kim*

Main category: quant-ph

TL;DR: 该论文提出了一种优化非均匀自旋传感器灵敏度的方法，通过选择最优自旋子集来克服有限驱动功率导致的控制场空间梯度问题，实现了比传统方案高达10倍的灵敏度提升。


<details>
  <summary>Details</summary>
Motivation: 有限驱动功率会导致控制场存在不可避免的空间梯度，这阻碍了自旋系综达到标准量子极限灵敏度。传统方法依赖系综中名义上均匀的区域，但这种方法在非均匀环境中效果有限。

Method: 推导了非均匀自旋传感器的系综灵敏度解析表达式，引入了灵敏度阈值来识别最优自旋子集。应用相位数字全息术实现最优子集，并应用于脉冲和连续波磁力测量。

Result: 最优子集在脉冲和连续波磁力测量中实现了高达10倍的灵敏度提升。残余像差导致的灵敏度损失小于1 dB，证明了该方法的实际可行性。

Conclusion: 该框架没有基本权衡限制，将量子传感扩展到异质传感环境，为非均匀自旋传感器提供了有效的灵敏度优化方案。

Abstract: Finite drive power leaves unavoidable spatial gradients in control fields, preventing spin ensembles from reaching the standard-quantum-limit sensitivity. We derive an analytic expression of ensemble sensitivity for inhomogeneous spin sensors and introduce sensitivity thresholds that reveal the optimal spin subset. Applied to both pulsed and continuous-wave magnetometry, the optimal subsets deliver up to a tenfold improvement over conventional schemes relying on nominally uniform regions of the ensembles. We demonstrate phase-only digital holography to implement the optimal subsets and show that residual aberrations add less than 1 dB of sensitivity loss. Our framework imposes no fundamental trade-offs and extends quantum sensing to heterogeneous sensing environments.

</details>


### [37] [Quantum-Amplified M/G/1/K Simulation: A Comparator-Controlled Framework for Arbitrary Service Distributions](https://arxiv.org/abs/2512.10558)
*Or Peretz,Michal Koren,Nir Perel*

Main category: quant-ph

TL;DR: 本文提出了首个用于模拟M/G/1/K队列的量子电路，通过量子振幅放大实现O(√N)方差缩减，在IBM量子模拟器上验证了高保真度和低误差。


<details>
  <summary>Details</summary>
Motivation: 有限容量单服务器队列在现实系统中广泛应用，但传统模拟方法在服务可变性或精度要求增加时计算成本过高。需要量子计算来加速性能分析。

Method: 设计首个用于M/G/1/K队列的量子电路，通过R_y旋转梯编码服务分布，使用比较器控制相位门强制缓冲区约束，保持振幅放大的二次加速。采用Grover迭代估计系统期望顾客数。

Result: 在IBM量子模拟器上验证：4量子比特时保真度>0.99，10量子比特时>0.76；Jensen-Shannon散度<0.11；等待时间估计误差在高负载时降低一个数量级，高流量时误差<3%（最多63量子比特）。

Conclusion: 建立了首个端到端量子模拟框架，为有限缓冲区非马尔可夫排队系统提供了量子加速性能分析的具体基础。

Abstract: Finite-capacity single-server queues with general service-time distributions form the backbone of numerous real-world systems, yet classical simulation of performance metrics such as blocking probabilities and delay becomes computationally prohibitive as service variability or required precision increases. This work presents the first coherent quantum circuit for simulating an M/G/1/K queue under arbitrary service-time laws. The circuit encodes the service distribution through a logarithmic-depth ladder of $R_y$ rotations and enforces buffer constraints via a comparator-controlled phase gate, while preserving the quadratic speed-up of amplitude amplification. Grover iterations center on estimating the expected number of customers in the system, yielding provable $O(\sqrt{N})$ variance reduction and closed-form confidence bounds, where $N$ denotes the number of shots. Empirical evaluations on IBM quantum simulators across four service distributions and three traffic intensities demonstrate fidelity above 0.99 with four qubits and above 0.76 with ten qubits, with Jensen-Shannon divergence below 0.11. Waiting-time estimation errors decrease by an order of magnitude as system load approaches capacity and remain within 3% in high-traffic regimes using registers of up to 63 qubits. These results establish the first end-to-end quantum simulation framework for finite-buffer, non-Markovian queueing systems and provide a concrete foundation for quantum-accelerated performance analysis in service-oriented architectures.

</details>


### [38] [Insensitivity points and performance of open quantum interferometers under number- conserving & non-conserving Lindblad dynamics](https://arxiv.org/abs/2512.10559)
*Tommaso Favalli,Žan Kokalj,Andrea Trombettoni*

Main category: quant-ph

TL;DR: 研究线性双模原子干涉仪在环境噪声下的相位灵敏度，发现存在灵敏度发散点（不敏感点），其位置与噪声强度无关，且粒子数不守恒噪声在所有粒子数下都产生更低的灵敏度极限。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中环境噪声对原子干涉仪相位灵敏度的影响，特别关注粒子数守恒和非守恒噪声的不同效应，以理解噪声如何限制相位估计的精度。

Method: 采用开放量子系统框架，使用Lindblad算子建模环境噪声（包括粒子数守恒和非守恒噪声）。考虑不同输入态，研究N=1,2个粒子的情况，并对N>2进行数值模拟。分析灵敏度随保持时间的变化，识别不敏感点，并比较不同噪声类型下的Cramér-Rao界限。

Result: 发现灵敏度随保持时间变化存在发散点（不敏感点），这些点的位置与噪声强度无关，但受输入态、粒子数和噪声算子影响。对于小N，固定测量方案可能有利于粒子数守恒噪声，但Cramér-Rao界限显示粒子数不守恒噪声在所有粒子数下都能达到更低的灵敏度极限。

Conclusion: 原子干涉仪的相位灵敏度受环境噪声类型显著影响，不敏感点的存在表明在某些条件下相位估计变得不可能。虽然固定测量方案在小N时可能偏好粒子数守恒噪声，但理论上粒子数不守恒噪声在所有粒子数下都能提供更好的灵敏度极限，这对量子计量学中的噪声管理具有重要意义。

Abstract: We investigate the phase sensitivity of a linear two-mode atom interferometer subject to environmental noise, modeled within the framework of open quantum systems with both number- conserving and non-conserving Lindblad operators. Considering several input states, we first study the cases N=1,2 (N number of particles) and perform numerical simulations for N>2. The sensitivity as a function of the holding time can display divergence points where phase estimation becomes impossible, to which we refer as insensitivity points. We characterize their behavior as the input state, particle number, and noise operator are varied, and we find that their positions are independent of the noise intensity. Moreover, while our fixed measurement scheme may favor number-conserving noise at small N (i.e., having better sensitivity), the Cramér-Rao bound reveals that particle non-conserving noise yields strictly lower achievable sensitivity for all particle numbers.

</details>


### [39] [Pulsed learning for quantum data re-uploading models](https://arxiv.org/abs/2512.10670)
*Ignacio B. Acedo,Pablo Rodriguez-Grasa,Pablo Garcia-Azorin,Javier Gonzalez-Conde*

Main category: quant-ph

TL;DR: 脉冲级量子机器学习模型在NISQ硬件上相比门级变分量子电路表现出更好的性能和噪声鲁棒性


<details>
  <summary>Details</summary>
Motivation: 变分量子电路(VQCs)在NISQ硬件上存在严重的可训练性和噪声相关问题，而脉冲控制级的学习模型实现方式相对未被充分探索，可能提供有前景的替代方案

Method: 提出基于脉冲的数据重上传变体，将可训练参数直接嵌入到原生系统的动力学中，在模拟的超导transmon处理器上使用真实噪声配置文件进行基准测试

Result: 脉冲模型在同等噪声条件下始终优于门级对应模型，表现出更高的测试精度和改进的泛化能力；随着噪声强度增加，脉冲级实现保持更高保真度的时间更长，展示了对退相干和控制误差的增强鲁棒性

Conclusion: 脉冲原生架构虽然探索较少，但可能为NISQ时代的实用量子机器学习提供可行且硬件对齐的前进路径

Abstract: While Quantum Machine Learning (QML) holds great potential, its practical realization on Noisy Intermediate-Scale Quantum (NISQ) hardware has been hindered by the limitations of variational quantum circuits (VQCs). Recent evidence suggests that VQCs suffer from severe trainability and noise-related issues, leading to growing skepticism about their long-term viability. However, the possibility of implementing learning models directly at the pulse-control level remains comparatively unexplored and could offer a promising alternative. In this work, we formulate a pulse-based variant of data re-uploading, embedding trainable parameters directly into the native system's dynamics. We benchmark our approach on a simulated superconducting transmon processor with realistic noise profiles. The pulse-based model consistently outperforms its gate-based counterpart, exhibiting higher test accuracy and improved generalization under equivalent noise conditions. Moreover, by systematically increasing noise strength, we show that pulse-level implementations retain higher fidelity for longer, demonstrating enhanced resilience to decoherence and control errors. These results suggest that pulse-native architectures, though less explored, may offer a viable and hardware-aligned path forward for practical QML in the NISQ era.

</details>


### [40] [A Cryogenic Muon Tagging System Based on Kinetic Inductance Detectors for Superconducting Quantum Processors](https://arxiv.org/abs/2512.10679)
*Ambra Mariani,Laura Cardani,Mustafa Bal,Nicola Casali,Ivan Colantoni,Angelo Cruciani,Giorgio Del Castello,Daniele Delicato,Francesco De Dominicis,Matteo del Gallo Raccagiovine,Matteo Folcarelli,Sabrina Garattoni,Anna Grassellino,Mehmood Khan Yasir Raja,Valerio Pettinacci,Alberto Ressa,Tanay Roy,Marco Vignati,David v Zanten*

Main category: quant-ph

TL;DR: 开发基于动能电感探测器的低温μ子标记系统，用于监测超导量子处理器中的宇宙μ子辐射，实现约90%的探测效率，为实时纠错提供支持。


<details>
  <summary>Details</summary>
Motivation: 电离辐射（特别是大气μ子）已成为超导量子处理器的潜在限制因素，会引起准粒子爆发和相关错误，影响容错操作。由于μ子能量高、穿透力强，被动屏蔽效果有限，因此需要实时监测μ子通量来指导开发替代的错误校正或保护策略。

Method: 设计、模拟并首次运行基于动能电感探测器（KIDs）的低温μ子标记系统。系统由两个垂直堆叠的KID探测器组成，在约20mK温度下工作。使用基于Geant4的蒙特卡洛模拟指导原型设计，提供μ子标记效率和环境γ射线引起的偶然符合的参考预期。

Result: 测量到顶部和底部探测器之间的μ子诱导符合率为(192±9)×10⁻³事件/秒，与蒙特卡洛预测非常吻合。原型系统实现了约90%的μ子标记效率，且死时间可忽略不计。

Conclusion: 这些结果证明了在毫开尔文温度下运行μ子标记系统的可行性，为将其与多量子比特芯片集成以实时否决或校正μ子诱导错误开辟了道路。

Abstract: Ionizing radiation has emerged as a potential limiting factor for superconducting quantum processors, inducing quasiparticle bursts and correlated errors that challenge fault-tolerant operation. Atmospheric muons are particularly problematic due to their high energy and penetration power, making passive shielding ineffective. Therefore, monitoring the real-time muon flux is crucial to guide the development of alternative error-correction or protection strategies. We present the design, simulation, and first operation of a cryogenic muon-tagging system based on Kinetic Inductance Detectors (KIDs) for integration with superconducting quantum processors. The system consists of two KIDs arranged in a vertical stack and operated at ~20 mK. Monte Carlo simulations based on Geant4 guided the prototype design and provided reference expectations for muon-tagging efficiency and accidental coincidences due to ambient $γ$-rays. We measured a muon-induced coincidence rate among the top and bottom detectors of (192 $\pm$ 9) $\times$ 10$^{-3}$ events/s, in excellent agreement with the Monte Carlo prediction. The prototype achieves a muon-tagging efficiency of about 90% with negligible dead time. These results demonstrate the feasibility of operating a muon-tagging system at millikelvin temperatures and open the path toward its integration with multi-qubit chips to veto or correct muon-induced errors in real time.

</details>


### [41] [Advantage in distributed quantum computing with slow interconnects](https://arxiv.org/abs/2512.10693)
*Evan E Dobbs,Nicolas Delfosse,Aharon Brodutch*

Main category: quant-ph

TL;DR: 分布式量子计算中，通过慢速互连的多个量子处理单元可以超越单量子处理单元架构，即使纠缠生成时间比门时间长5倍，分布式CliNR方案仍能实现更低的逻辑错误率和更短的深度。


<details>
  <summary>Details</summary>
Motivation: 分布式量子计算的主要瓶颈是量子处理单元之间产生纠缠的速率。本文旨在证明通过慢速互连连接的多个量子处理单元可以超越单一量子处理单元的架构性能。

Method: 提出分布式CliNR部分纠错方案，考虑每个量子处理单元仅连接两个其他单元、每个链路一次只产生一个贝尔对、纠缠生成时间τ_e比门时间长的约束。通过电路级模拟验证性能，并在渐进状态下放宽约束，证明链路并行产生O(t/ln t)个贝尔对即可避免分布式CliNR停滞。

Result: 即使纠缠生成时间τ_e比门时间长5倍，分布式CliNR仍能同时实现比直接实现和单量子处理单元CliNR实现更低的逻辑错误率和更短的深度。在渐进状态下，链路并行产生O(t/ln t)个贝尔对即可避免停滞，与每个量子处理单元的量子比特数无关。

Conclusion: 分布式CliNR展示了近期多量子处理单元设备的潜力，并设想基于Bouland、Fitzsimons和Koh的共轭Clifford电路实现分布式量子优越性实验。

Abstract: The main bottleneck for distributed quantum computing is the rate at which entanglement is produced between quantum processing units (QPUs). In this work, we prove that multiple QPUs connected through slow interconnects can outperform a monolithic architecture made with a single QPU. We consider a distributed quantum computing model with the following assumptions: (1) each QPU is linked to only two other QPUs, (2) each link produces only one Bell pair at a time, (3) the time to generate a Bell pair is $τ_e$ times longer than the gate time. We propose a distributed version of the CliNR partial error correction scheme respecting these constraints and we show through circuit level simulations that, even if the entanglement generation time $τ_e$ is up to five times longer than the gate time, distributed CliNR can achieve simultaneously a lower logical error rate and a shorter depth than both the direct implementation and the monolithic CliNR implementation of random Clifford circuits. In the asymptotic regime, we relax assumption (2) and we prove that links producing $O(t/\ln t)$ Bell pairs in parallel, where $t$ is the number of QPUs, is sufficient to avoid stalling distributed CliNR, independently of the number of qubits per QPU. This demonstrates the potential of distributed CliNR for near-term multi-QPU devices. Moreover, we envision a distributed quantum superiority experiment based on the conjugated Clifford circuits of Bouland, Fitzsimons and Koh implemented with distributed CliNR.

</details>


### [42] [Sub-Bath Cooling in Bosonic Systems: Gaussian Constraints and Non-Gaussian Enhancements](https://arxiv.org/abs/2512.10703)
*Wen-Han Png,Xueyuan Hu,Valerio Scarani*

Main category: quant-ph

TL;DR: 该研究建立了连续变量系统冷却的通用理论框架，揭示了高斯操作的性能极限以及非高斯相互作用带来的冷却增强效应。


<details>
  <summary>Details</summary>
Motivation: 随着连续变量平台在量子信息处理中日益重要，理解玻色子系统冷却的基本限制变得至关重要。离散变量系统的冷却已被广泛探索，但连续变量系统的冷却理论基础尚不完善。

Method: 开发了一个通用的连续变量系统冷却框架，推导了高斯操作的冷却性能可达边界，并优化了所有满足该边界的协议。同时研究了p-激发交换如何利用非高斯资源实现冷却极限的p倍增强。

Result: 确定了高斯操作的冷却性能可达边界，并找到了最有效的冷却方案（最小化给定辅助模式数下的耗散能量）。证明了非高斯操作能够突破高斯冷却限制，实现p倍的冷却增强。

Conclusion: 该研究建立了连续变量热浴算法冷却的基本极限，揭示了非高斯性在超越高斯冷却障碍中的关键作用，为连续变量量子技术的冷却优化提供了理论基础。

Abstract: Cooling quantum systems with finite resources is a central task in quantum technologies and has been extensively explored in discrete-variable settings. As continuous-variable (CV) platforms play an increasingly important role in quantum information processing, it becomes crucial to understand the fundamental limitations of cooling bosonic systems. In this work, we develop a general framework for cooling CV systems, identifying both the constraints imposed by Gaussianity and the advantages enabled by non-Gaussian interactions. We derive a reachable bound on the cooling performance of Gaussian operations that applies to arbitrary cooling architectures. By optimizing over all protocols saturating this bound, we further identify the most efficient scheme, which minimizes dissipated energy for a given number of ancilla modes. Beyond Gaussian operations, we show that $p$-excitation exchange exploits non-Gaussian resources to achieve a $p$-fold enhancement of the cooling limit. Our results establish the fundamental limits of CV heat-bath algorithmic cooling and reveal the crucial role of non-Gaussianity in surpassing Gaussian cooling barriers.

</details>


### [43] [Scalable Optical Links for Controlling Bosonic Quantum Processors](https://arxiv.org/abs/2512.10706)
*Chuanlong Ma,Jia-Qi Wang,Linze Li,Jiajun Chen,Xiaoxuan Pan,Zheng-Hui Tian,Zheng-Xu Zhu,Jia-Hua Zou,Dingran Gu,Luyu Wang,Qiushi Chen,Weiting Wang,Xin-Biao Xu,Chang-Ling Zou,Baile Chen,Luyan Sun*

Main category: quant-ph

TL;DR: 该论文展示了使用光学光纤控制玻色子量子处理器，实现了对transmon量子比特和存储腔联合希尔伯特空间的通用操作，并成功进行了15公里远程传输，保真度超过95%。


<details>
  <summary>Details</summary>
Motivation: 超导量子计算面临扩展性挑战，传统电子电缆连接室温控制电子学与量子处理器会导致信号衰减和热传导问题。光学光纤提供有前景的解决方案，但此前仅限于控制简单两能级量子系统。

Method: 使用低温光纤集成单行载流子光电二极管阵列，实现对玻色子量子处理器的光学控制，包括transmon量子比特和存储腔的联合希尔伯特空间操作。

Result: 成功制备了包含多达10个光子的Fock态，实现了15公里传输距离的远程控制，保真度超过95%。

Conclusion: 该方法结合了高维量子控制、多通道操作和长距离传输，满足了扩展超导量子计算机的关键要求，为分布式量子数据中心架构奠定了基础。

Abstract: Superconducting quantum computing has the potential to revolutionize computational capabilities. However, scaling up large quantum processors is limited by the cumbersome and heat-conductive electronic cables that connect room-temperature control electronics to quantum processors, leading to significant signal attenuation. Optical fibers provide a promising solution, but their use has been restricted to controlling simple two-level quantum systems over short distances. Here, we demonstrate optical control of a bosonic quantum processor, achieving universal operations on the joint Hilbert space of a transmon qubit and a storage cavity. Using an array of cryogenic fiber-integrated uni-traveling-carrier photodiodes, we prepare Fock states containing up to ten photons. Additionally, remote control of bosonic modes over a transmission distance of 15 km has been achieved, with fidelities exceeding 95%. The combination of high-dimensional quantum control, multi-channel operation, and long-distance transmission addresses the key requirements for scaling superconducting quantum computers and enables architectures for distributed quantum data centers.

</details>


### [44] [Further Statistical Study of NISQ Experiments](https://arxiv.org/abs/2512.10722)
*Gil Kalai,Tomer Shoham,Carsten Voelkmann*

Main category: quant-ph

TL;DR: 该论文重新审视并扩展了作者之前对Google 2019年"量子霸权"实验的研究，基于Google提供的更详细数据扩展了基于数字误差模型的预测分析，并对其他NISQ实验进行了初步分析。


<details>
  <summary>Details</summary>
Motivation: 作者旨在深入分析Google 2019年量子霸权实验，特别是基于Google提供的更详细数据来验证和改进之前提出的数字误差模型预测，同时将分析方法扩展到其他近期NISQ（含噪声中等规模量子）实验。

Method: 采用理论分析方法，基于Google提供的更详细实验数据，扩展之前提出的数字误差模型（公式(77)）的预测能力，并将类似的分析框架应用于其他NISQ实验。

Result: 论文提供了基于更详细Google数据的数字误差模型预测的扩展分析，以及对其他NISQ实验的初步分析结果，这些结果可能对评估量子霸权声明的有效性和理解NISQ实验的局限性有重要意义。

Conclusion: 通过扩展对Google量子霸权实验的分析并初步探索其他NISQ实验，该研究为理解当前量子计算实验的可靠性和局限性提供了更全面的视角，有助于推动量子计算验证方法的发展。

Abstract: We revisit and extend some topics that we studied in our previous works (Rinott, Kalai and Shoham 2022; Kalai, Rinott and Shoham, 2023,2024) regarding the Google 2019 "quantum supremacy" experiment. We extend our analysis of the prediction based on Google's digital error model (Formula (77)), based on more detailed data provided by Google. We also provide some preliminary analysis for a few other NISQ experiments.

</details>


### [45] [Understanding Surface-Induced Decoherence of NV Centers in Diamond](https://arxiv.org/abs/2512.10726)
*Jonah Nagura,Mykyta Onizhuk,Giulia Galli*

Main category: quant-ph

TL;DR: 该研究通过原子建模和退相干时间计算，量化了金刚石表面特性对氮空位中心量子传感器相干时间的影响，揭示了表面自旋噪声的机制，并提出了优化表面工程以提升量子传感性能的指导原则。


<details>
  <summary>Details</summary>
Motivation: 金刚石表面附近的氮空位中心是重要的纳米级量子传感器，但其相干特性受到表面磁电噪声的负面影响。目前对这些噪声的来源和具体影响机制尚不清楚，需要系统研究表面特性对NV中心相干时间的影响。

Method: 采用基于密度泛函理论的金刚石表面原子模型，结合簇相关展开方法计算退相干时间，量化了表面晶体学取向、功能化以及未配对电子密度对NV Hahn-echo时间T₂的影响。

Result: 确定了T₂从表面核自旋限制恢复到体材料限制值的临界深度；发现静态表面电子浴中，NV深度与表面电子自旋间距的比值决定了从快速涨落到准静态噪声的转变；揭示了自旋-声子弛豫对T₂的调制导致亚微秒弛豫时间下的运动变窄效应；最重要的是，只有考虑表面自旋的序列内跳跃才能重现实测的T₂随深度变化关系。

Conclusion: 该研究强调了跳跃介导模型对于描述影响NV传感器的表面自旋噪声的重要性，为设计金刚石表面以增强NV相干性、提升量子传感和信息处理应用性能提供了明确的工程指导原则。

Abstract: Nitrogen vacancy centers (NV) in proximity to diamond surfaces are promising nanoscale quantum sensors. However, their coherence properties are negatively affected by magnetic and electric surface noise, whose origin and detailed impact have remained elusive. Using atomistic models of diamond surfaces derived with density functional theory, together with decoherence time calculations with cluster correlation expansion methods, we quantify the effects of surface crystallographic orientation and functionalization, and of the density of unpaired electrons on the NV Hahn-echo time $T_2$. We determine a crossover depth at which $T_2$ ceases to be limited by surface nuclear spins and recovers the bulk-limited value. We find that for static surface-electron baths, the ratio between the NV depth and the separation between surface electron spins determines a transition from fast-fluctuating to quasi-static noise, leading to a dependence of $T_2$ on orientation for specific surfaces. We also find that the modulation of $T_2$ by spin-phonon relaxations leads to motional-narrowing at sub-microsecond relaxation times. Importantly, our calculations show that it is only when accounting for surface-spin in-sequence hopping that measured $T_2$ values as a function of depth can be reproduced, thus highlighting the importance of hopping-mediated models to describe the surface spin noise affecting NV sensors. Overall, our work provides clear guidelines for engineering diamond surfaces to achieve enhanced NV coherence for quantum sensing and information processing applications.

</details>


### [46] [Complexity and multi-functional variants of the Quantum-to-Quantum Bernoulli Factories](https://arxiv.org/abs/2512.10810)
*Francesco Hoch,Taira Giordani,Gonzalo Carvacho,Nicolò Spagnolo,Fabio Sciarrino*

Main category: quant-ph

TL;DR: 该论文研究了量子到量子伯努利工厂的复杂性，提供了实现该协议所需量子比特数的下界、成功概率的上界以及达到这些边界的量子电路，并分析了原始问题的两个变体。


<details>
  <summary>Details</summary>
Motivation: 伯努利工厂是随机性操作的重要模型，可将输入的伯努利随机变量转换为输出的伯努利变量。量子到量子伯努利工厂方案在量子算法中具有重要应用，如贝叶斯推断、蒙特卡洛方法和盲量子计算等。然而，其复杂性特征尚未得到充分研究。

Method: 作者对量子到量子伯努利工厂的复杂性进行了特征化分析：1）提供了实现该协议所需量子比特数量的下界；2）给出了成功概率的上界；3）设计了能够达到这些边界的量子电路。此外，还形式化并分析了原始问题的两个变体：增加输入偏置数量或增加工厂实现的函数数量。

Result: 获得了量子到量子伯努利工厂复杂性的精确边界：确定了所需量子比特的最小数量、成功概率的最大可能值，并提供了达到这些最优边界的量子电路实现。同时，对两个变体问题的分析为随机性操作提供了更全面的框架。

Conclusion: 该研究为量子到量子伯努利工厂的复杂性提供了完整的理论框架，包括精确的边界分析和最优实现方案。这些结果可作为通过量子方法进行随机性操作的基础框架，对量子算法设计具有重要意义。

Abstract: A Bernoulli factory is a model for randomness manipulation that transforms an initial Bernoulli random variable into another Bernoulli variable by applying a predetermined function relating the output bias to the input one. In literature, quantum-to-quantum Bernoulli factory schemes have been proposed, which encode both the input and output variables using qubit amplitudes. This fundamental concept can serve as a subroutine for quantum algorithms that involve Bayesian inference and Monte Carlo methods, or that require data encryption, like in blind quantum computation. In this work, we present a characterisation of the complexity of the quantum-to-quantum Bernoulli factory by providing a lower bound on the required number of qubits needed to implement the protocol, an upper bound on the success probability and the quantum circuit that saturates the bounds. We also formalise and analyse two different variants of the original problem that address the possibility of increasing the number of input biases or the number of functions implemented by the quantum-to-quantum Bernoulli factory. The obtained results can be used as a framework for randomness manipulation via such an approach.

</details>


### [47] [Quantum Approaches to Urban Logistics: From Core QAOA to Clustered Scalability](https://arxiv.org/abs/2512.10813)
*F. Picariello,G. Turati,R. Antonelli,I. Bailo,S. Bonura,G. Ciarfaglia,S. Cipolla,P. Cremonesi,M. Ferrari Dacrema,M. Gabusi,I. Gentile,V. Morreale,A. Noto*

Main category: quant-ph

TL;DR: 该研究探索了量子近似优化算法（QAOA）在解决带现实约束的旅行商问题（TSP）中的应用，提出了结合经典机器学习的聚类QAOA方法以提高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着TSP实例规模增大，传统算法难以在合理时间内产生高质量解。本研究旨在探索量子近似优化算法在解决带现实约束的TSP问题中的潜力，为未来大规模应用奠定基础。

Method: 采用基于QUBO的TSP公式化方法，整合车辆容量、道路可达性和时间窗口等现实约束。提出聚类QAOA（Cl-QAOA）方法，结合经典机器学习将大TSP实例分解为更小的子问题，在高性能计算资源模拟环境中评估不同问题规模和量子电路深度下的性能。

Result: 研究提供了对QAOA在解决约束TSP场景中优势和局限性的全面评估。Cl-QAOA方法使量子优化在量子比特数量有限的设备上变得可行，提高了可扩展性。

Conclusion: 该研究推进了量子优化领域的发展，为未来大规模应用奠定了基础，展示了量子-经典混合方法在解决复杂组合优化问题中的潜力。

Abstract: The Traveling Salesman Problem (TSP) is a fundamental challenge in combinatorial optimization, widely applied in logistics and transportation. As the size of TSP instances grows, traditional algorithms often struggle to produce high-quality solutions within reasonable timeframes. This study investigates the potential of the Quantum Approximate Optimization Algorithm (QAOA), a hybrid quantum-classical method, to solve TSP under realistic constraints. We adopt a QUBO-based formulation of TSP that integrates real-world logistical constraints reflecting operational conditions, such as vehicle capacity, road accessibility, and time windows, while ensuring compatibility with the limitations of current quantum hardware. Our experiments are conducted in a simulated environment using high-performance computing (HPC) resources to assess QAOA's performance across different problem sizes and quantum circuit depths. In order to improve scalability, we propose clustering QAOA (Cl-QAOA), a hybrid approach combining classical machine learning with QAOA. This method decomposes large TSP instances into smaller sub-problems, making quantum optimization feasible even on devices with a limited number of qubits. The results offer a comprehensive evaluation of QAOA's strengths and limitations in solving constrained TSP scenarios. This study advances quantum optimization and lays groundwork for future large-scale applications.

</details>


### [48] [Optimized Measurement Schedules for the Surface Code with Dropout](https://arxiv.org/abs/2512.10871)
*Benjamin Anker,Dripto M. Debroy*

Main category: quant-ph

TL;DR: 该研究改进了量子纠错中的缺陷处理策略，通过优化规范算子和利用LUCI框架，在表面码上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 虽然已有工作表明制造缺陷可以通过基于纠错周期中间状态的策略来处理，但原始方法仍有改进空间。本研究旨在通过两个方面的优化来提升缺陷处理效果。

Method: 1. 量化了在标准方形网格表面码上使用更完整的规范算子集的影响，并提出了切除未使用量子位的新方法；2. 利用LUCI框架作为中间表示，通过整数线性规划从大量有效LUCI电路中寻找高性能物理电路。

Result: 在d=11的表面码上，当量子位和耦合器丢失率分别为1%(3%)时，这些优化在SI1000噪声模型下（噪声率0.1%）相比4轮综合征提取，实现了14.5%(23.6%)的总性能提升。

Conclusion: 通过优化规范算子选择和电路实现方法，显著提升了量子纠错系统对制造缺陷的鲁棒性，为实际量子计算系统的容错设计提供了有效改进方案。

Abstract: Recent work has shown that fabrication defects can be well-handled using a strategy relying on the mid-error-correction-cycle state. In this work we present two improvements to the original prescription. First, we quantify the impact of the choice of a more complete set of gauge operators originally proposed for the hex-grid surface code on the standard square-grid surface code, as well as a new method for excising effectively unused qubits. Second, we leverage the expressivity of the LUCI framework as an intermediate representation, using integer linear programming to find performant physical circuits from the large space of valid LUCI circuits. We show that on the $d = 11$ surface code at $1\%(3\%)$ dropout rate for qubits and couplers, these optimizations allow for a total improvement of $14.5\%(23.6\%)$ over $4d$ round of syndrome extraction using the SI1000 noise model at $0.1\%$ noise.

</details>


### [49] [Multiple-time Quantum Imaginary Time Evolution](https://arxiv.org/abs/2512.10875)
*Julio Del Castillo,Mats Granath,Evert van Nieuwenburg*

Main category: quant-ph

TL;DR: MT-QITE算法通过使用多个虚时间参数改进量子虚时间演化，提高了基态制备的保真度并降低了测量开销，同时保持了算法的确定性、无需特定ansatz，并实现了并行化。


<details>
  <summary>Details</summary>
Motivation: 传统量子虚时间演化（QITE）方法在处理一般哈密顿量时需要昂贵的测量成本，且保真度和计算成本高度依赖于局部域和哈密顿量分区的定义。需要一种改进方法来提高效率。

Method: 提出多时间QITE算法（MT-QITE），使用多个虚时间参数而非单一时间参数，通过并行化处理提高效率，即使在具有非局域相互作用的哈密顿量中，分区也能带来计算优势。

Result: MT-QITE相比先前QITE算法显著提高了所得基态的保真度，同时降低了测量开销，保持了算法的确定性特征和独立于特定ansatz的特性。

Conclusion: MT-QITE是QITE算法的重要改进，通过多时间参数和并行化设计，在保持原有优势的同时提高了效率和性能，为量子硬件上的基态制备提供了更优方案。

Abstract: Quantum Imaginary-Time Evolution (QITE) is a powerful method for preparing ground states on quantum hardware. However, executing QITE has costly measurement budgets for general Hamiltonians. Both fidelity and computational cost are strongly dependent on the definition of suitable local domains and Hamiltonian partitions. In this work, we introduce the Multiple-Time QITE algorithm (MT-QITE). We show how using more than one imaginary time substantially improves the fidelity of the resulting ground state as well as the measurement overhead with respect to the previously published QITE algorithm, while preserving its deterministic character and its independence from ad hoc ansatze. Moreover, unlike QITE and other QITE-based algorithms, MT-QITE is parallelizable, and we show that even in Hamiltonians with non-local interactions, partitioning may entail a computational advantage.

</details>


### [50] [ENTCALC: Toolkit for calculating geometric entanglement in multipartite quantum systems](https://arxiv.org/abs/2512.10884)
*Piotr Masajada,Aby Philip,Alexander Streltsov*

Main category: quant-ph

TL;DR: entcalc是一个用于估计多体量子态几何纠缠的Python和MATLAB软件包，能够为纯态计算几何纠缠及误差，为混态提供上下界，并在多个量子系统中验证了高精度。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够准确估计多体量子系统几何纠缠的计算工具，特别是针对混态提供可靠的纠缠度量，这对于量子信息处理和量子多体物理研究具有重要意义。

Method: 开发了entcalc软件包，输入多体量子态后，对纯态直接计算几何纠缠和误差估计；对混态则提供几何纠缠的上下界，形成包含真实值的区间。提供了多种计算下界的方法，允许用户在精度和计算成本之间进行权衡。

Result: 软件包成功应用于多个代表性系统：3⊗3 PPT纠缠态、GHZ和W态的混合、三量子比特自旋链的热态、以及含噪声的GHZ和W态。在自旋链中观察到了量子相变的特征，并展示了通过调节外磁场可以激活非相邻位点间的纠缠。在所有测试案例中，上下界之间的差距都非常小，表明entcalc提供了高度准确的几何纠缠估计。

Conclusion: entcalc软件包为多体量子态的几何纠缠提供了可靠的计算工具，特别在处理混态时通过上下界方法确保了估计的准确性，在量子信息处理和量子多体物理研究中具有重要应用价值。

Abstract: We present entcalc, a Python and MATLAB package for estimating the geometric entanglement of multipartite quantum states. The package operates as follows: given a multipartite quantum state as input, it outputs an estimate of its geometric entanglement. For pure states, it computes the geometric entanglement together with an estimation error. For mixed states, it provides both lower and upper bounds on the geometric entanglement, thereby identifying an interval in which the true value lies. We provide several methods to compute the lower bound, enabling users to balance accuracy against computational cost. We apply entcalc to several representative examples, including for $3\otimes3$ PPT entangled states, mixtures of GHZ and W states, thermal states of selected three-qubit spin chains, and noisy GHZ and W states. We observe signatures of quantum phase transitions by quantifying entanglement in spin chains. We also demonstrate that entanglement between non-neighbouring sites can be activated by tuning the external magnetic field. In all tested cases, the gap between the lower and upper bounds is found to be very small, indicating that entcalc provides highly accurate estimates of the geometric entanglement for these states.

</details>


### [51] [Quantifying classical and quantum bounds for resolving closely spaced, non-interacting, simultaneously emitting dipole sources in optical microscopy](https://arxiv.org/abs/2512.10889)
*Armine I. Dingilian,Aarnah Kurella,Cheyenne S. Mitchell,Dhananjay Dhruva,David J. Durden,Mikael P. Backlund*

Main category: quant-ph

TL;DR: 该论文研究了两个紧密排列的偶极子发射体间距估计的量子精度极限，考虑了矢量发射特性对超分辨率成像的影响，并提出了通过方位-径向偏振基滤波来保持量子Fisher信息饱和的方案。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率成像研究大多基于标量近似，这不适用于高数值孔径显微镜环境。需要研究矢量发射特性对两个紧密排列的偶极子发射体间距估计精度的影响。

Method: 使用参数估计理论，考虑两种极限情况：固定等取向的偶极子和自由取向的偶极子。通过量子与经典Fisher信息及Cramér-Rao界量化精度极限，并采用方位-径向偏振基滤波方案。

Result: 矢量发射特性使分析复杂化，但通过适当的方位-径向偏振基滤波，可以挽救先前提出的通过图像反转干涉法饱和量子Fisher信息的方案。

Conclusion: 在考虑矢量发射特性的情况下，通过适当的偏振滤波技术，仍能实现接近量子极限的超分辨率成像精度，为高数值孔径显微镜下的超分辨率成像提供了理论支持。

Abstract: Recent theoretical and experimental work has shown that the quantum Fisher information associated with estimating the separation between two optical point sources remains finite at small separations, effectively opening new routes to super-resolution imaging of simultaneously emitting sources. Most studies to date, however, implicitly invoke the scalar approximation, which is not appropriate in the context of high-numerical-aperture microscopy. Utilizing parameter estimation theory, here we consider the estimation of separation between two closely spaced dipole emitters, a commonly employed model for single-molecule optical beacons. We consider two limiting cases: one in which the orientations of the emitters are fixed and equal, and another in which both dipoles freely sample all of orientation space over the course of the measurement. We quantify precision limits using quantum and classical variants of the Fisher information and Cramér-Rao bound. In all cases, the vectorial nature of the emission complicates the analyses, but with appropriate filtering of the collected light in the azimuthal-radial polarization basis, a previously proposed scheme to saturate the quantum Fisher information via image inversion interferometry can be salvaged.

</details>


### [52] [Qubit decoherence in dissipative two-photon resonator: real-time instantons and Wigner function](https://arxiv.org/abs/2512.10921)
*V. Yu. Mylnikov,S. O. Potashin,Alex Kamenev*

Main category: quant-ph

TL;DR: 该研究分析了具有双光子驱动和耗散的玻色腔在有限失谐下的量子动力学，揭示了量子激活过程中的瞬子轨迹，建立了稳态相空间描述与量子激活过程的统一框架。


<details>
  <summary>Details</summary>
Motivation: 研究驱动-耗散非线性谐振器中的量子双稳态、亚稳态和退相干现象，为玻色量子比特设计和量子信息处理提供理论基础。

Method: 利用隐藏的时间反演对称性、Wigner表示和WKB方法构建有效相空间势；采用Keldysh实时路径积分形式计算量子激活过程中的瞬子轨迹。

Result: 发现两个因量子涨落而亚稳态的吸引点；建立了Wigner表示与量子激活过程的基本联系；推导出系统退相干率的解析表达式。

Conclusion: 为分析驱动-耗散非线性谐振器中的量子双稳态、亚稳态和退相干提供了统一的理论框架，对玻色量子比特设计和量子信息处理具有直接意义。

Abstract: We study the quantum dynamics of a single bosonic cavity subject to two-photon driving and two-photon dissipation in the presence of finite detuning. Exploiting a hidden time-reversal symmetry, the Wigner representation and the WKB method, we introduce an effective phase-space potential for description of the steady state. It reveals two attracting points, which are metastable due to quantum fluctuations. By employing the Keldysh real-time path integral formalism, we compute the instanton trajectory governing the quantum activation process between these attractors and establish a fundamental connection with the Wigner representation. This relation unifies the steady-state phase-space description with dynamical quantum activation processes. We also derive an analytical expression for the decoherence rate of the system. Our work provides a coherent theoretical framework for analyzing quantum bistability, metastability, and decoherence in driven-dissipative nonlinear resonators, with direct implications for the design of bosonic qubits and quantum information processing.

</details>


### [53] [Noisy Quantum Learning Theory](https://arxiv.org/abs/2512.10929)
*Jordan Cotler,Weiyuan Gong,Ishaan Kannan*

Main category: quant-ph

TL;DR: 该研究建立了噪声量子实验学习框架，发现噪声会消除理想无噪声学习者的指数级量子优势，但NISQ与容错设备间仍存在超多项式差距。研究揭示了Bell基和SWAP测试等量子学习原语对噪声的脆弱性，除非系统具有噪声鲁棒结构。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解噪声如何影响量子学习优势，特别是在容错设备通过噪声耦合访问未表征系统的实际场景中。需要探索噪声环境下量子学习能力的极限，以及如何利用噪声鲁棒结构恢复量子优势。

Method: 方法包括：1) 建立NBQP复杂度类建模噪声容错量子计算机；2) 分析自然预言机问题中的噪声影响；3) 研究具体噪声学习任务如纯度测试和Pauli影子层析；4) 推导样本复杂度下界并设计参数相似的算法；5) 探索AdS/CFT启发的噪声鲁棒结构。

Result: 结果显示：1) 噪声会消除理想无噪声学习者的指数级量子优势；2) NISQ与容错设备间仍保持超多项式差距；3) 纯度测试的指数级双拷贝优势在局部去极化噪声下崩溃；4) 在AdS/CFT启发的噪声鲁棒结构中可以恢复量子优势；5) Bell基和SWAP测试原语对噪声具有根本脆弱性。

Conclusion: 结论是：Bell基和SWAP测试等量子学习原语对噪声具有根本脆弱性，除非实验系统具有潜在的噪声鲁棒结构。未来实验中实现有意义的量子优势需要理解噪声鲁棒物理特性如何与可用算法技术相结合。

Abstract: We develop a framework for learning from noisy quantum experiments, focusing on fault-tolerant devices accessing uncharacterized systems through noisy couplings. Our starting point is the complexity class $\textsf{NBQP}$ ("noisy BQP"), modeling noisy fault-tolerant quantum computers that cannot, in general, error-correct the oracle systems they query. Using this class, we show that for natural oracle problems, noise can eliminate exponential quantum learning advantages of ideal noiseless learners while preserving a superpolynomial gap between NISQ and fault-tolerant devices. Beyond oracle separations, we study concrete noisy learning tasks. For purity testing, the exponential two-copy advantage collapses under a single application of local depolarizing noise. Nevertheless, we identify a setting motivated by AdS/CFT in which noise-resilient structure restores a quantum learning advantage in a noisy regime. We then analyze noisy Pauli shadow tomography, deriving lower bounds that characterize how instance size, quantum memory, and noise control sample complexity, and design algorithms with parametrically similar scalings. Together, our results show that the Bell-basis and SWAP-test primitives underlying most exponential quantum learning advantages are fundamentally fragile to noise unless the experimental system has latent noise-robust structure. Thus, realizing meaningful quantum advantages in future experiments will require understanding how noise-robust physical properties interface with available algorithmic techniques.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [54] [ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples](https://arxiv.org/abs/2512.09931)
*Akaash Chatterjee,Suman Kundu*

Main category: cs.AI

TL;DR: ExaCraft是一个AI驱动的个性化示例生成系统，通过分析学习者的动态上下文（包括位置、教育背景、职业、复杂度偏好和行为模式），为学习者提供文化相关且个性化的学习示例。


<details>
  <summary>Details</summary>
Motivation: 现有教育AI工具未能专注于生成个性化示例或适应学习者不断变化的理解水平、学习困难和技能增长。学习最有效的方式是与学习者个人相关的示例，而当前工具缺乏这种动态适应能力。

Method: 使用Google Gemini AI和Python Flask API构建的Chrome扩展系统，结合用户定义的个人资料（位置、教育、职业、复杂度偏好）和实时学习行为分析，能够适应学习上下文的五个关键方面：困难指标、掌握模式、主题进展历史、会话边界和学习进展信号。

Result: 系统能够生成从基础概念到高级技术实现的演进示例，响应主题重复、重新生成请求和主题进展模式，确保示例既文化相关又符合个人学习需求。

Conclusion: ExaCraft通过动态适应学习者的上下文，解决了现有教育AI工具在个性化示例生成方面的不足，为学习者提供更有效、更相关的学习体验。

Abstract: Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.

</details>


### [55] [Exploring LLMs for Scientific Information Extraction Using The SciEx Framework](https://arxiv.org/abs/2512.10004)
*Sha Li,Ayush Sadekar,Nathan Self,Yiqi Su,Lars Andersland,Mira Chaplin,Annabel Zhang,Hyoju Yang,James B Henderson,Krista Wigginton,Linsey Marr,T. M. Murali,Naren Ramakrishnan*

Main category: cs.AI

TL;DR: SciEx是一个模块化框架，用于从科学文献中提取细粒度信息，解决了现有LLM方法在处理长文档、多模态内容和跨文献信息整合方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在处理科学文献时面临诸多挑战：长文档上下文、多模态内容、跨多篇文献的信息不一致性，以及数据模式快速变化时难以重新架构系统的问题。

Method: 提出SciEx模块化框架，将PDF解析、多模态检索、信息提取和聚合等关键组件解耦，支持按需数据提取，并能灵活集成新模型、提示策略和推理机制。

Result: 在三个科学主题的数据集上评估SciEx，验证了其准确、一致提取细粒度信息的能力，并提供了当前LLM基管线的优势和局限性的实用见解。

Conclusion: SciEx框架通过模块化设计有效解决了科学信息提取中的关键挑战，为LLM在科学文献处理中的应用提供了灵活可扩展的解决方案。

Abstract: Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsistent fine-grained information across multiple publications into standardized formats. These challenges are further compounded when the desired data schema or extraction ontology changes rapidly, making it difficult to re-architect or fine-tune existing systems. We present SciEx, a modular and composable framework that decouples key components including PDF parsing, multi-modal retrieval, extraction, and aggregation. This design streamlines on-demand data extraction while enabling extensibility and flexible integration of new models, prompting strategies, and reasoning mechanisms. We evaluate SciEx on datasets spanning three scientific topics for its ability to extract fine-grained information accurately and consistently. Our findings provide practical insights into both the strengths and limitations of current LLM-based pipelines.

</details>


### [56] [SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration](https://arxiv.org/abs/2512.10046)
*Yan Zhuang,Jiawei Ren,Xiaokang Ye,Jianzhi Shen,Ruixuan Zhang,Tianai Yue,Muhammad Faayez,Xuhong He,Ziqiao Ma,Lianhui Qin,Zhiting Hu,Tianmin Shu*

Main category: cs.AI

TL;DR: SWR是一个基于虚幻引擎5构建的大规模、逼真城市环境仿真平台，用于具身AI研究，包含两个机器人基准测试：多模态指令跟随任务和多智能体搜索任务。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型在机器人领域的研究主要集中在室内家庭场景，缺乏针对大规模、复杂城市环境的具身AI仿真平台和评估基准。

Method: 基于虚幻引擎5构建SWR平台，程序化生成无限逼真的城市场景，包含行人、交通系统等动态元素，支持多机器人控制和通信。在此基础上创建了两个基准测试：多模态指令跟随任务和多智能体协作搜索任务。

Result: 实验结果表明，当前最先进的视觉语言模型在SWR的任务中表现不佳，缺乏在复杂城市环境中所需的稳健感知、推理和规划能力。

Conclusion: SWR平台填补了大规模城市环境具身AI仿真的空白，其基准测试能够全面评估机器人在真实场景中的关键能力，揭示了当前模型在城市环境任务中的局限性。

Abstract: Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.

</details>


### [57] [Linear socio-demographic representations emerge in Large Language Models from indirect cues](https://arxiv.org/abs/2512.10065)
*Paul Bouchaud,Pedro Ramaciotti*

Main category: cs.AI

TL;DR: 研究发现LLMs在激活空间中形成用户社会人口属性的线性表示，这些表示基于姓名、职业等间接线索，并能影响下游行为如职业推荐。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs如何通过姓名、职业等间接线索编码对话伙伴的社会人口属性，以及这些隐式表示如何影响模型行为，这对大规模应用中的公平性有重要意义。

Method: 在四个开源transformer模型上，通过显式人口统计披露提示，探测各层残差流；使用相同探针预测隐式线索（姓名、职业）的人口统计信息；分析这些线性表示如何影响下游行为。

Result: LLMs在激活空间中形成社会人口属性的线性表示：姓名激活与人口普查一致的性别和种族表示，职业触发与现实劳动力统计相关的表示；这些隐式表示能解释对话中形成的人口统计推断，并主动影响下游行为如职业推荐。

Conclusion: LLMs通过隐式线索形成社会人口属性的线性表示，这些表示能影响模型行为；即使通过偏见基准测试的模型仍可能包含并利用隐式偏见，这对大规模应用的公平性有重要影响。

Abstract: We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.

</details>


### [58] [Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit](https://arxiv.org/abs/2512.10092)
*Nick Jiang,Xiaoqing Sun,Lisa Dunlap,Lewis Smith,Neel Nanda*

Main category: cs.AI

TL;DR: 稀疏自编码器（SAE）嵌入比LLM更经济可靠，比密集嵌入更可控，能发现数据集语义差异和概念相关性，成本降低2-8倍


<details>
  <summary>Details</summary>
Motivation: 当前大规模文本分析依赖昂贵的LLM技术或不可控的密集嵌入模型，需要更经济、可靠且可控的方法来分析模型行为和训练数据偏差

Method: 使用稀疏自编码器（SAE）创建SAE嵌入表示，其维度映射到可解释概念，通过四个数据分析任务验证效果

Result: SAE嵌入比LLM成本降低2-8倍且更可靠，比密集嵌入更可控；能发现数据集语义差异、概念相关性，在基于属性的检索中表现更优

Conclusion: SAE是分析非结构化数据的通用工具，强调了通过数据解释模型的重要性，为模型行为分析和偏差检测提供了有效方法

Abstract: Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for clustering), which lack control over the properties of interest. We propose using sparse autoencoders (SAEs) to create SAE embeddings: representations whose dimensions map to interpretable concepts. Through four data analysis tasks, we show that SAE embeddings are more cost-effective and reliable than LLMs and more controllable than dense embeddings. Using the large hypothesis space of SAEs, we can uncover insights such as (1) semantic differences between datasets and (2) unexpected concept correlations in documents. For instance, by comparing model responses, we find that Grok-4 clarifies ambiguities more often than nine other frontier models. Relative to LLMs, SAE embeddings uncover bigger differences at 2-8x lower cost and identify biases more reliably. Additionally, SAE embeddings are controllable: by filtering concepts, we can (3) cluster documents along axes of interest and (4) outperform dense embeddings on property-based retrieval. Using SAE embeddings, we study model behavior with two case studies: investigating how OpenAI model behavior has changed over time and finding "trigger" phrases learned by Tulu-3 (Lambert et al., 2024) from its training data. These results position SAEs as a versatile tool for unstructured data analysis and highlight the neglected importance of interpreting models through their data.

</details>


### [59] [Robust AI Security and Alignment: A Sisyphean Endeavor?](https://arxiv.org/abs/2512.10100)
*Apostol Vassilev*

Main category: cs.AI

TL;DR: 该论文将哥德尔不完备性定理扩展到AI领域，建立了AI安全和对齐的信息论限制，并提供了应对这些挑战的实用方法


<details>
  <summary>Details</summary>
Motivation: 认识到AI安全和对齐存在根本性的信息论限制对于负责任地采用AI技术至关重要，需要了解这些限制并为它们带来的挑战做好准备

Method: 将哥德尔不完备性定理扩展到AI领域，建立信息论框架来分析AI系统的安全和对齐限制

Result: 证明了AI系统在安全和对齐方面存在根本性的信息论限制，这些限制类似于数学系统中的不完备性

Conclusion: AI系统的认知推理能力存在固有的局限性，了解这些限制并采取相应措施对于负责任地开发和部署AI技术至关重要，论文还提供了应对这些挑战的实用方法

Abstract: This manuscript establishes information-theoretic limitations for robustness of AI security and alignment by extending Gödel's incompleteness theorem to AI. Knowing these limitations and preparing for the challenges they bring is critically important for the responsible adoption of the AI technology. Practical approaches to dealing with these challenges are provided as well. Broader implications for cognitive reasoning limitations of AI systems are also proven.

</details>


### [60] [Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups](https://arxiv.org/abs/2512.10105)
*Soorya Ram Shimgekar,Abhay Goyal,Lam Yin Cheung,Roy Ka-Wei Lee,Koustuv Saha,Pi Zonooz,Navin Kumar*

Main category: cs.AI

TL;DR: 本文提出一个两阶段计算框架分析新加坡Telegram群组中的阴谋论话语，发现此类内容融入日常讨论而非孤立存在，识别出7种叙事原型，挑战了在线激进化假设。


<details>
  <summary>Details</summary>
Motivation: 阴谋论话语日益嵌入数字通信生态系统，但其结构和传播难以研究。现有研究常假设阴谋论存在于孤立回音室，但缺乏对日常讨论中阴谋论嵌入程度的实证分析。

Method: 提出两阶段计算框架：1) 微调RoBERTa-large分类阴谋论消息(F1=0.866)；2) 构建带符号信念图，节点为消息，边符号反映信念标签对齐，权重为文本相似度。提出SiBeGNN模型，使用符号解缠损失学习分离意识形态对齐与风格特征的嵌入。

Result: 在553,648条消息中识别出7种叙事原型：法律话题、医疗关切、媒体讨论、金融、权威矛盾、群组管理、一般聊天。SiBeGNN聚类质量(cDBI=8.38)优于基线方法(13.60-67.27)，专家评估一致性达88%。阴谋论消息不仅出现在怀疑或不信任集群，也出现在金融、法律和日常事务讨论中。

Conclusion: 阴谋论话语在普通社交互动中运作，挑战了在线激进化的常见假设。该框架推进了信念驱动话语分析的计算方法，可用于立场检测、政治传播研究和内容审核政策。

Abstract: Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features.
  Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.

</details>


### [61] [AgriRegion: Region-Aware Retrieval for High-Fidelity Agricultural Advice](https://arxiv.org/abs/2512.10114)
*Mesafint Fanuel,Mahmoud Nabil Mahmoud,Crystal Cook Marshal,Vishal Lakhotia,Biswanath Dari,Kaushik Roy,Shaohu Zhang*

Main category: cs.AI

TL;DR: AgriRegion是一个专门为农业领域设计的检索增强生成框架，通过地理空间元数据注入和区域优先重排序机制，减少LLM在农业咨询中的上下文幻觉，提供区域精准的农业建议。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在农业领域经常出现上下文幻觉问题，提供的建议可能在一个地区科学合理但在另一个地区却造成灾难性后果，这是由于土壤、气候和地方法规的差异造成的。需要专门针对农业领域的高保真、区域感知的咨询系统。

Method: AgriRegion采用检索增强生成框架，包含地理空间元数据注入层和区域优先重排序机制。将知识库限制在已验证的本地农业推广服务，并在检索过程中强制执行地理空间约束，确保种植计划、病虫害防治和施肥建议的本地准确性。

Result: 实验表明，与最先进的LLM系统相比，AgriRegion将幻觉减少了10-20%，并通过综合评估显著提高了信任分数。研究创建了包含12个农业子领域160个领域特定问题的新基准数据集AgriRegion-Eval。

Conclusion: AgriRegion框架通过结合地理空间约束和区域优先检索，有效解决了农业领域LLM的上下文幻觉问题，为不同地区提供准确可靠的农业建议，提高了农业咨询的可信度和实用性。

Abstract: Large Language Models (LLMs) have demonstrated significant potential in democratizing access to information. However, in the domain of agriculture, general-purpose models frequently suffer from contextual hallucination, which provides non-factual advice or answers are scientifically sound in one region but disastrous in another due to variations in soil, climate, and local regulations. We introduce AgriRegion, a Retrieval-Augmented Generation (RAG) framework designed specifically for high-fidelity, region-aware agricultural advisory. Unlike standard RAG approaches that rely solely on semantic similarity, AgriRegion incorporates a geospatial metadata injection layer and a region-prioritized re-ranking mechanism. By restricting the knowledge base to verified local agricultural extension services and enforcing geo-spatial constraints during retrieval, AgriRegion ensures that the advice regarding planting schedules, pest control, and fertilization is locally accurate. We create a novel benchmark dataset, AgriRegion-Eval, which comprises 160 domain-specific questions across 12 agricultural subfields. Experiments demonstrate that AgriRegion reduces hallucinations by 10-20% compared to state-of-the-art LLMs systems and significantly improves trust scores according to a comprehensive evaluation.

</details>


### [62] [The 2025 Foundation Model Transparency Index](https://arxiv.org/abs/2512.10169)
*Alexander Wan,Kevin Klyman,Sayash Kapoor,Nestor Maslej,Shayne Longpre,Betty Xiong,Percy Liang,Rishi Bommasani*

Main category: cs.AI

TL;DR: 2025年基础模型透明度指数显示，主要AI公司透明度从2024年的58分降至40分，透明度恶化，公司在训练数据和部署后影响方面最不透明。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型开发公司日益重要，需要评估其透明度实践如何演变，为政策制定提供依据，揭示当前透明度状况及政策干预的必要性。

Method: 采用年度基础模型透明度指数方法，引入数据获取、使用数据和监控等新指标，首次评估阿里巴巴、DeepSeek和xAI等公司，对主要基础模型开发公司进行量化评估。

Result: 透明度整体恶化：平均分从2024年58分降至2025年40分；IBM表现突出得95分，xAI和Midjourney最低仅14分；公司在训练数据、训练计算及部署后使用和影响方面最不透明。

Conclusion: 基础模型开发公司透明度普遍下降，需要更积极的政策干预来解决关键信息缺失问题，特别是训练数据和部署后影响方面的透明度需要改善。

Abstract: Foundation model developers are among the world's most important companies. As these companies become increasingly consequential, how do their transparency practices evolve? The 2025 Foundation Model Transparency Index is the third edition of an annual effort to characterize and quantify the transparency of foundation model developers. The 2025 FMTI introduces new indicators related to data acquisition, usage data, and monitoring and evaluates companies like Alibaba, DeepSeek, and xAI for the first time. The 2024 FMTI reported that transparency was improving, but the 2025 FMTI finds this progress has deteriorated: the average score out of 100 fell from 58 in 2024 to 40 in 2025. Companies are most opaque about their training data and training compute as well as the post-deployment usage and impact of their flagship models. In spite of this general trend, IBM stands out as a positive outlier, scoring 95, in contrast to the lowest scorers, xAI and Midjourney, at just 14. The five members of the Frontier Model Forum we score end up in the middle of the Index: we posit that these companies avoid reputational harms from low scores but lack incentives to be transparency leaders. As policymakers around the world increasingly mandate certain types of transparency, this work reveals the current state of transparency for foundation model developers, how it may change given newly enacted policy, and where more aggressive policy interventions are necessary to address critical information deficits.

</details>


### [63] [An exploration for higher efficiency in multi objective optimisation with reinforcement learning](https://arxiv.org/abs/2512.10208)
*Mehmet Emin Aydin*

Main category: cs.AI

TL;DR: 本文提出了一种基于多目标强化学习的通用方法来优化搜索过程中的算子序列选择，旨在解决多目标优化中算子序列选择效率问题


<details>
  <summary>Details</summary>
Motivation: 优化和搜索过程中的效率问题持续影响算法性能。虽然使用算子池而非单一算子处理邻域移动操作具有前景，但最优或接近最优的算子序列仍需深入研究。多目标优化领域在此方面的研究相对较少，需要一种通用方法来提高效率

Method: 提出基于多目标强化学习的通用方法，通过强化学习机制来选择和优化算子序列。该方法包含已完成阶段和待完成阶段，旨在系统性地解决多目标优化中的算子序列选择问题

Result: 论文概述了提出的通用方法框架，展示了多目标强化学习在优化算子序列选择方面的潜力。该方法旨在为多目标优化问题提供有效的解决方案

Conclusion: 基于多目标强化学习的通用方法为解决多目标优化中的算子序列选择问题提供了有前景的解决方案，能够提高优化算法的效率和性能

Abstract: Efficiency in optimisation and search processes persists to be one of the challenges, which affects the performance and use of optimisation algorithms. Utilising a pool of operators instead of a single operator to handle move operations within a neighbourhood remains promising, but an optimum or near optimum sequence of operators necessitates further investigation. One of the promising ideas is to generalise experiences and seek how to utilise it. Although numerous works are done around this issue for single objective optimisation, multi-objective cases have not much been touched in this regard. A generalised approach based on multi-objective reinforcement learning approach seems to create remedy for this issue and offer good solutions. This paper overviews a generalisation approach proposed with certain stages completed and phases outstanding that is aimed to help demonstrate the efficiency of using multi-objective reinforcement learning.

</details>


### [64] [ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs](https://arxiv.org/abs/2512.10211)
*Junyang Cai,El Mehdi Er Raqabi,Pascal Van Hentenryck,Bistra Dilkina*

Main category: cs.AI

TL;DR: 本文扩展了Predict-and-Search框架到参数化混合整数线性规划问题，提出了ID-PaS身份感知学习框架，能更有效地处理异构变量，在多个实际大规模问题上优于Gurobi和传统PaS方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Predict-and-Search方法虽然结合机器学习提升了性能，但仅限于二元问题，且忽略了实际应用中常见的固定变量问题，需要扩展到更一般的参数化MIP问题并处理异构变量。

Method: 提出了ID-PaS（身份感知学习框架），扩展Predict-and-Search框架到参数化MIP问题，使机器学习模型能够更有效地处理异构变量，包括固定变量等实际场景中的变量类型。

Result: 在多个实际大规模问题上进行实验，ID-PaS始终表现出优于最先进求解器Gurobi和传统Predict-and-Search方法的性能。

Conclusion: ID-PaS框架成功扩展了Predict-and-Search方法到参数化MIP问题，通过身份感知学习机制有效处理异构变量，在实际应用中展现出显著优势。

Abstract: Mixed-Integer Linear Programs (MIPs) are powerful and flexible tools for modeling a wide range of real-world combinatorial optimization problems. Predict-and-Search methods operate by using a predictive model to estimate promising variable assignments and then guiding a search procedure toward high-quality solutions. Recent research has demonstrated that incorporating machine learning (ML) into the Predict-and-Search framework significantly enhances its performance. Still, it is restricted to binary problems and overlooks the presence of fixed variables that commonly arise in practical settings. This work extends the Predict-and-Search (PaS) framework to parametric MIPs and introduces ID-PaS, an identity-aware learning framework that enables the ML model to handle heterogeneous variables more effectively. Experiments on several real-world large-scale problems demonstrate that ID-PaS consistently achieves superior performance compared to the state-of-the-art solver Gurobi and PaS.

</details>


### [65] [Reverse Thinking Enhances Missing Information Detection in Large Language Models](https://arxiv.org/abs/2512.10273)
*Yuxin Liu,Chaojie Gu,Yihang Zhang,Bin Qian,Shibo He*

Main category: cs.AI

TL;DR: 论文提出了一种基于反向思维的框架，用于提升大语言模型在缺失信息检测任务中的性能，相比传统前向推理方法取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理缺失信息问题时存在不足，如回答不完整、事实错误和幻觉等问题。现有的前向推理方法（如CoT和ToT）在结构化问题解决中表现良好，但无法系统性地识别和恢复缺失信息。

Method: 提出了一种新颖的反向思维框架，引导大语言模型通过反向推理来识别必要条件和定位缺失元素。该方法将缺失信息识别的挑战性任务转化为更易管理的反向推理问题。

Result: 实验结果表明，反向思维方法相比传统前向推理方法取得了显著的性能提升，为增强大语言模型的逻辑完整性和推理鲁棒性提供了有前景的方向。

Conclusion: 反向思维方法能够有效提升大语言模型在缺失信息检测任务中的表现，为解决模型在处理不完整信息时的局限性提供了新的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning tasks, yet they often struggle with problems involving missing information, exhibiting issues such as incomplete responses, factual errors, and hallucinations. While forward reasoning approaches like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) have shown success in structured problem-solving, they frequently fail to systematically identify and recover omitted information. In this paper, we explore the potential of reverse thinking methodologies to enhance LLMs' performance on missing information detection tasks. Drawing inspiration from recent work on backward reasoning, we propose a novel framework that guides LLMs through reverse thinking to identify necessary conditions and pinpoint missing elements. Our approach transforms the challenging task of missing information identification into a more manageable backward reasoning problem, significantly improving model accuracy. Experimental results demonstrate that our reverse thinking approach achieves substantial performance gains compared to traditional forward reasoning methods, providing a promising direction for enhancing LLMs' logical completeness and reasoning robustness.

</details>


### [66] [Neuronal Attention Circuit (NAC) for Representation Learning](https://arxiv.org/abs/2512.10282)
*Waleed Razzaq,Izis Kankaraway,Yun-Bo Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的生物启发式连续时间注意力机制NAC，通过将注意力对数计算转化为线性一阶ODE的求解，实现了高效的连续时间建模，在多个实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制虽然改进了RNN的表征学习能力，但其离散特性限制了连续时间建模。需要一种既能保持注意力优势又能适应连续时间动态的生物启发式机制。

Method: 提出Neuronal Attention Circuit (NAC)，将注意力对数计算重新表述为线性一阶ODE的求解，使用源自秀丽隐杆线虫神经元电路策略的稀疏门控机制，包含三种计算模式：显式欧拉积分、精确闭式解和稳态近似，并采用稀疏Top-K配对连接方案提高内存效率。

Result: NAC在多个领域（不规则时间序列分类、自动驾驶车道保持、工业预测）的实验中，在准确性上匹配或优于基线方法，在运行时间和内存效率方面处于中等水平，同时提供了状态稳定性、有界近似误差和通用逼近的理论保证。

Conclusion: NAC是一种有效的生物启发式连续时间注意力机制，能够克服传统离散注意力的限制，在保持理论保证的同时，在实际应用中展现出良好的性能平衡。

Abstract: Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-order ODE with nonlinear interlinked gates derived from repurposing \textit{C. elegans} Neuronal Circuit Policies (NCPs) wiring mechanism. NAC replaces dense projections with sparse sensory gates for key-query projections and a sparse backbone network with two heads for computing \textit{content-target} and \textit{learnable time-constant} gates, enabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i) explicit Euler integration, (ii) exact closed-form solution, and (iii) steady-state approximation. To improve memory intensity, we implemented a sparse Top-\emph{K} pairwise concatenation scheme that selectively curates key-query interactions. We provide rigorous theoretical guarantees, including state stability, bounded approximation errors, and universal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for autonomous vehicles, and industrial prognostics. We observed that NAC matches or outperforms competing baselines in accuracy and occupies an intermediate position in runtime and memory efficiency compared with several CT baselines.

</details>


### [67] [Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules](https://arxiv.org/abs/2512.10300)
*Yanbei Jiang,Xueqi Ma,Shu Liu,Sarah Monazam Erfani,Tongliang Liu,James Bailey,Jey Han Lau,Krista A. Ehinger*

Main category: cs.AI

TL;DR: 该研究提出了一个解释视觉语言模型内部机制的新框架，通过CogVision数据集将复杂多模态问题分解为逐步子问题，识别出专门处理特定认知功能的注意力头，并发现这些功能头在模型推理中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多模态基准测试中表现出色，但它们很大程度上仍然是一个黑箱。研究者希望开发一个可解释性框架来系统分析VLMs的内部机制，特别是注意力头在多模态推理中的功能角色。

Method: 1. 引入CogVision数据集，将复杂多模态问题分解为模拟人类推理链的逐步子问题，每个子问题关联特定的接收或认知功能；2. 使用基于探测的方法识别专门处理这些功能的注意力头，并将其表征为功能头；3. 在不同VLM家族中进行分析；4. 进行干预实验验证功能头的重要性。

Result: 1. 功能头在所有VLM家族中普遍稀疏；2. 不同功能的功能头数量和分布存在差异；3. 这些功能头介导交互和层次组织；4. 干预实验表明：移除功能头会导致性能下降，而强调它们则能提高准确性。

Conclusion: 该研究为VLMs的认知组织提供了新的见解，并为设计具有更符合人类感知和推理能力的模型指明了有前景的方向。功能头在模型推理中扮演关键角色，这有助于理解VLMs的内部工作机制。

Abstract: Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. To this end, we introduce CogVision, a dataset that decomposes complex multimodal questions into step-by-step subquestions designed to simulate human reasoning through a chain-of-thought paradigm, with each subquestion associated with specific receptive or cognitive functions such as high-level visual reception and inference. Using a probing-based methodology, we identify attention heads that specialize in these functions and characterize them as functional heads. Our analysis across diverse VLM families reveals that these functional heads are universally sparse, vary in number and distribution across functions, and mediate interactions and hierarchical organization. Furthermore, intervention experiments demonstrate their critical role in multimodal reasoning: removing functional heads leads to performance degradation, while emphasizing them enhances accuracy. These findings provide new insights into the cognitive organization of VLMs and suggest promising directions for designing models with more human-aligned perceptual and reasoning abilities.

</details>


### [68] [Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance](https://arxiv.org/abs/2512.10304)
*Byeong Ho Kang,Wenli Yang,Muhammad Bilal Amin*

Main category: cs.AI

TL;DR: 本文提出了可信编排AI的十大标准框架，通过控制面板架构将治理嵌入AI生态系统执行层，确保AI系统可验证、透明、可重现且受有意义的人类控制。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在关键决策中扮演越来越重要的角色，技术能力与制度问责之间出现了日益扩大的差距。仅靠伦理指导不足以应对这一挑战，需要将治理嵌入生态系统执行层的架构。

Method: 提出了可信编排AI的十大标准框架，采用控制面板架构，整合人类输入、语义一致性、审计和溯源完整性，为整个AI组件、消费者和人类参与者提供治理保护伞。

Result: 该框架借鉴国际标准和澳大利亚国家AI保障框架，证明可信度可以通过工程化方式系统地融入AI系统，确保执行层保持可验证、透明、可重现且受有意义的人类控制。

Conclusion: 通过将治理架构嵌入AI生态系统的执行层，可以系统性地建立可信AI系统，填补技术能力与制度问责之间的差距，实现真正可信的AI编排。

Abstract: As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia's National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.

</details>


### [69] [EpiPlanAgent: Agentic Automated Epidemic Response Planning](https://arxiv.org/abs/2512.10313)
*Kangkun Mao,Fang Xu,Jinru Ding,Yidong Jiang,Yujun Yao,Yirong Chen,Junming Liu,Xiaoqin Wu,Qian Wu,Xiaoyan Huang,Jie Xu*

Main category: cs.AI

TL;DR: EpiPlanAgent是一个基于大型语言模型的智能体系统，能够自动生成和验证数字化的流行病应急响应计划，显著提高计划完整性和指南符合度，同时大幅缩短开发时间。


<details>
  <summary>Details</summary>
Motivation: 传统的流行病应急响应计划制定依赖劳动密集型的人工方法，效率低下且难以保证质量。本研究旨在利用人工智能技术自动化这一过程，提高公共卫生应急准备的效率和效果。

Method: 设计并评估EpiPlanAgent系统，这是一个基于大型语言模型的多智能体框架，集成了任务分解、知识基础和模拟模块。公共卫生专业人员使用真实世界疫情场景在受控环境中测试系统。

Result: EpiPlanAgent显著提高了计划的完整性和指南符合度，同时大幅减少了开发时间。专家评估确认AI生成内容与人工撰写内容高度一致，用户反馈显示系统具有很高的实用价值。

Conclusion: EpiPlanAgent为智能流行病应急响应规划提供了有效、可扩展的解决方案，展示了智能体AI在转变公共卫生准备方面的潜力。

Abstract: Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.

</details>


### [70] [User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation](https://arxiv.org/abs/2512.10322)
*Yongqiang Yu,Xuhui Li,Hazza Mahmood,Jinxing Zhou,Haodong Hong,Longtao Jiang,Zhiqiang Xu,Qi Wu,Xiaojun Chang*

Main category: cs.AI

TL;DR: 本文提出了一个用户反馈驱动的视觉语言导航适应框架，通过整合人类交互来增强GSA-VLN系统的持续学习能力，显著提升了导航成功率和路径效率。


<details>
  <summary>Details</summary>
Motivation: 当前的GSA-VLN框架仅依赖无监督的环境暴露适应，忽略了用户反馈这一自然且有价值的监督信号。为了缩小静态基准测试与现实部署之间的差距，需要将用户反馈系统性地整合到持续学习中。

Method: 提出了用户反馈驱动的适应框架：1) 将用户反馈（导航指令和纠正信号）转换为高质量、环境对齐的训练数据；2) 引入记忆库预热启动机制，重用先前获取的环境知识，减轻冷启动性能下降；3) 支持持续和混合适应设置。

Result: 在GSA-R2R基准测试中，该方法持续超越GR-DUET等强基线，提高了导航成功率和路径效率。记忆库预热启动稳定了早期导航，减少了更新后的性能下降。在持续和混合适应设置下都表现出鲁棒性和通用性。

Conclusion: 用户反馈驱动的适应框架有效提升了GSA-VLN系统的性能，通过整合人类交互实现了更高效、更现实的适应，为实际部署提供了稳定可靠的解决方案。

Abstract: Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.

</details>


### [71] [On the Collapse of Generative Paths: A Criterion and Correction for Diffusion Steering](https://arxiv.org/abs/2512.10339)
*Ziseok Lee,Minyeong Hwang,Sanghyun Jo,Wooyeol Lee,Jihyung Ko,Young Bin Park,Jae-Mun Choi,Eunho Yang,Kyungsu Kim*

Main category: cs.AI

TL;DR: 本文提出了一种解决概率密度比方法中边缘路径崩溃问题的新方案ACE，通过自适应路径校正确保异构模型组合时的有效概率路径，在分子设计等应用中实现稳定可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有的概率密度比方法在组合异构模型（如不同噪声调度或数据集训练的模型）时存在边缘路径崩溃问题，导致中间密度不可归一化，这在分子设计等需要组合多个专家模型的应用中尤为突出。

Method: 首先推导了路径存在性准则，仅从噪声调度和指数即可预测崩溃发生；其次提出了自适应路径校正指数（ACE）方法，将Feynman-Kac引导扩展到时变指数，保证有效概率路径。

Result: 在合成2D基准测试和柔性姿态支架装饰任务中，ACE消除了崩溃，实现了高引导组合生成，在分布和对接指标上优于恒定指数基线甚至专门的支架装饰模型。

Conclusion: ACE将概率密度比引导从一种不稳定的启发式方法转变为可靠的可控生成工具，特别适用于需要组合异构专家模型的应用场景。

Abstract: Inference-time steering enables pretrained diffusion/flow models to be adapted to new tasks without retraining. A widely used approach is the ratio-of-densities method, which defines a time-indexed target path by reweighting probability-density trajectories from multiple models with positive, or in some cases, negative exponents. This construction, however, harbors a critical and previously unformalized failure mode: Marginal Path Collapse, where intermediate densities become non-normalizable even though endpoints remain valid. Collapse arises systematically when composing heterogeneous models trained on different noise schedules or datasets, including a common setting in molecular design where de-novo, conformer, and pocket-conditioned models must be combined for tasks such as flexible-pose scaffold decoration. We provide a novel and complete solution for the problem. First, we derive a simple path existence criterion that predicts exactly when collapse occurs from noise schedules and exponents alone. Second, we introduce Adaptive path Correction with Exponents (ACE), which extends Feynman-Kac steering to time-varying exponents and guarantees a valid probability path. On a synthetic 2D benchmark and on flexible-pose scaffold decoration, ACE eliminates collapse and enables high-guidance compositional generation, improving distributional and docking metrics over constant-exponent baselines and even specialized task-specific scaffold decoration models. Our work turns ratio-of-densities steering with heterogeneous experts from an unstable heuristic into a reliable tool for controllable generation.

</details>


### [72] [REMISVFU: Vertical Federated Unlearning via Representation Misdirection for Intermediate Output Feature](https://arxiv.org/abs/2512.10348)
*Wenhan Wu,Zhili He,Huanghuang Liang,Yili Gong,Jiawei Jiang,Chuang Hu,Dazhao Cheng*

Main category: cs.AI

TL;DR: REMISVFU：一种用于垂直联邦学习的表示误导框架，通过将遗忘方的编码器输出坍缩到单位球面上的随机锚点，实现快速客户端级遗忘，同时保持其他参与方的模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有联邦遗忘技术主要针对水平联邦学习，而垂直联邦学习（VFL）中数据按特征划分的架构使得这些方法失效。GDPR等数据保护法规要求支持参与方的"被遗忘权"，因此需要专门针对VFL的遗忘解决方案。

Method: 提出REMISVFU表示误导框架：当收到删除请求时，遗忘方将其编码器输出坍缩到单位球面上的随机锚点，切断其特征与全局模型的统计联系。服务器端通过联合优化保留损失和遗忘损失，并利用正交投影对齐梯度来消除破坏性干扰。

Result: 在公开基准测试中，REMISVFU将后门攻击成功率抑制到自然类别先验水平，仅牺牲约2.5%的干净准确率，优于现有最先进基线方法。

Conclusion: REMISVFU为垂直联邦学习提供了一种有效的即插即用遗忘框架，能够在保护数据隐私的同时满足法规要求，为VFL系统的实际部署提供了重要支持。

Abstract: Data-protection regulations such as the GDPR grant every participant in a federated system a right to be forgotten. Federated unlearning has therefore emerged as a research frontier, aiming to remove a specific party's contribution from the learned model while preserving the utility of the remaining parties. However, most unlearning techniques focus on Horizontal Federated Learning (HFL), where data are partitioned by samples. In contrast, Vertical Federated Learning (VFL) allows organizations that possess complementary feature spaces to train a joint model without sharing raw data. The resulting feature-partitioned architecture renders HFL-oriented unlearning methods ineffective. In this paper, we propose REMISVFU, a plug-and-play representation misdirection framework that enables fast, client-level unlearning in splitVFL systems. When a deletion request arrives, the forgetting party collapses its encoder output to a randomly sampled anchor on the unit sphere, severing the statistical link between its features and the global model. To maintain utility for the remaining parties, the server jointly optimizes a retention loss and a forgetting loss, aligning their gradients via orthogonal projection to eliminate destructive interference. Evaluations on public benchmarks show that REMISVFU suppresses back-door attack success to the natural class-prior level and sacrifices only about 2.5% points of clean accuracy, outperforming state-of-the-art baselines.

</details>


### [73] [LLM-Empowered Representation Learning for Emerging Item Recommendation](https://arxiv.org/abs/2512.10370)
*Ziying Zhang,Quanming Yao,Yaqing Wang*

Main category: cs.AI

TL;DR: EmerFlow是一个基于大语言模型的表示学习框架，用于解决新兴物品推荐问题，通过LLM推理丰富物品特征，对齐现有推荐模型的嵌入空间，并利用元学习优化嵌入表示。


<details>
  <summary>Details</summary>
Motivation: 现有推荐方法通常假设新兴物品只有很少甚至没有历史交互记录，这种假设过于简化了问题。实际上，新兴物品的交互是随时间逐渐积累的，一个好的模型需要既保留新兴物品的独特性，又利用它们与成熟物品的共享模式。

Method: EmerFlow框架包含三个关键步骤：1）通过LLM推理丰富新兴物品的原始特征；2）将这些表示与现有推荐模型的嵌入空间对齐；3）通过元学习整合新的交互来优化嵌入表示。

Result: 在包括电影和医药等多个领域的广泛实验中，EmerFlow始终优于现有方法，能够从有限的交互中学习到新兴物品的表达性嵌入。

Conclusion: EmerFlow通过结合LLM推理、嵌入对齐和元学习，有效解决了新兴物品推荐中的表示学习问题，为处理交互逐渐积累的动态过程提供了创新解决方案。

Abstract: In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the problem, as a good model must preserve the uniqueness of emerging items while leveraging their shared patterns with established ones. To address this challenge, we propose EmerFlow, a novel LLM-empowered representation learning framework that generates distinctive embeddings for emerging items. It first enriches the raw features of emerging items through LLM reasoning, then aligns these representations with the embedding space of the existing recommendation model. Finally, new interactions are incorporated through meta-learning to refine the embeddings. This enables EmerFlow to learn expressive embeddings for emerging items from only limited interactions. Extensive experiments across diverse domains, including movies and pharmaceuticals, show that EmerFlow consistently outperforms existing methods.

</details>


### [74] [AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management](https://arxiv.org/abs/2512.10371)
*Shizuo Tian,Hao Wen,Yuxuan Chen,Jiacheng Liu,Shanhui Zhao,Guohong Liu,Ju Ren,Yunxin Liu,Yuanchun Li*

Main category: cs.AI

TL;DR: AgentProg：一种基于程序引导的移动GUI智能体上下文管理方法，通过将交互历史重构为程序结构来减少上下文开销，在长时程任务中保持高性能


<details>
  <summary>Details</summary>
Motivation: 移动GUI智能体的快速发展推动了长时程任务自动化的研究，但现有方法依赖不断扩展的交互历史导致巨大的上下文开销，而现有的上下文管理和压缩技术往往无法保留关键语义信息，导致任务性能下降

Method: 提出AgentProg方法，将交互历史重构为具有变量和控制流的程序结构，基于程序结构确定哪些信息应保留、哪些可丢弃；同时整合了受Belief MDP框架启发的全局信念状态机制来处理部分可观测性并适应环境变化

Result: 在AndroidWorld和扩展的长时程任务套件上的实验表明，AgentProg在这些基准测试中达到了最先进的成功率；更重要的是，在长时程任务中保持稳健性能，而基线方法则出现灾难性性能下降

Conclusion: AgentProg通过程序引导的上下文管理方法有效解决了长时程任务中的上下文开销问题，在保持高性能的同时显著优于现有方法，为移动GUI智能体的发展提供了重要技术突破

Abstract: The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.

</details>


### [75] [Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention](https://arxiv.org/abs/2512.10414)
*Yang Yu,Zhuangzhuang Chen,Siqi Wang,Lanqing Li,Xiaomeng Li*

Main category: cs.AI

TL;DR: 本文提出SaEI方法，通过选择性对抗熵干预增强视觉语言模型的推理能力，在RL采样阶段引入熵干预来提升响应多样性


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的微调方法主要关注策略优化阶段的熵干预，忽略了RL采样阶段的熵干预对提升响应多样性和GRPO性能的潜力

Method: 提出选择性对抗熵干预(SaEI)：1) 熵引导对抗采样(EgAS)，将采样响应的熵作为对抗目标，生成对抗样本来扩大答案空间探索；2) 令牌选择性熵计算(TsEC)，在不扭曲事实知识的前提下最大化对抗攻击效果

Result: 在领域内和领域外数据集上的广泛实验表明，该方法能显著提升策略探索能力，从而增强推理能力

Conclusion: 通过选择性对抗熵干预在RL采样阶段增强策略熵，能有效提升视觉语言模型的推理能力，代码将在论文接受后发布

Abstract: Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL- based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing stud- ies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ig- nore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the di- versity of responses. In this paper, we propose Selective- adversarial Entropy Intervention, namely SaEI, which en- hances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the en- tropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formu- lates the entropy of sampled responses as an adversarial ob- jective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger an- swer space during RL sampling. Then, we propose token- selective entropy computation (TsEC) to maximize the ef- fectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.

</details>


### [76] [Representation of the structure of graphs by sequences of instructions](https://arxiv.org/abs/2512.10429)
*Ezequiel Lopez-Rubio*

Main category: cs.AI

TL;DR: 提出一种将图邻接矩阵表示为字符串指令序列的新方法，使图结构能够被深度学习语言模型处理


<details>
  <summary>Details</summary>
Motivation: 当前图表示方法不适合深度学习语言模型处理，而语言模型在文本处理方面表现出强大能力，需要一种能让语言模型直接处理图的表示方法

Method: 将图的邻接矩阵转换为一系列简单指令字符串，这些指令逐步构建邻接矩阵，转换过程可逆，既能从图生成字符串，也能从字符串重建图

Result: 提出的表示方法紧凑且能保持图的局部结构模式，初步计算实验显示有良好结果

Conclusion: 该图表示方法有望提升深度学习模型对图的处理能力，为图处理与语言模型的结合提供了新途径

Abstract: The representation of graphs is commonly based on the adjacency matrix concept. This formulation is the foundation of most algebraic and computational approaches to graph processing. The advent of deep learning language models offers a wide range of powerful computational models that are specialized in the processing of text. However, current procedures to represent graphs are not amenable to processing by these models. In this work, a new method to represent graphs is proposed. It represents the adjacency matrix of a graph by a string of simple instructions. The instructions build the adjacency matrix step by step. The transformation is reversible, i.e. given a graph the string can be produced and vice versa. The proposed representation is compact and it maintains the local structural patterns of the graph. Therefore, it is envisaged that it could be useful to boost the processing of graphs by deep learning models. A tentative computational experiment is reported, with favorable results.

</details>


### [77] [Targeted Data Protection for Diffusion Model by Matching Training Trajectory](https://arxiv.org/abs/2512.10433)
*Hojun Lee,Mijin Koo,Yeji Song,Nojun Kwak*

Main category: cs.AI

TL;DR: TAFAP是一种通过轨迹对齐实现有效目标数据保护的方法，能够控制整个训练轨迹，将扩散模型重定向到用户指定的目标概念，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型的个性化微调技术虽然越来越普及，但也引发了未经授权数据使用和隐私侵犯的严重问题。现有的保护方法仅限于被动降低图像质量，无法实现稳定控制。目标数据保护（TDP）虽然提供了将模型重定向到用户指定目标概念的有前景范式，但现有方法由于采用快照匹配方式而控制性差，未能考虑完整的学习动态。

Method: TAFAP（通过对抗性扰动的微调轨迹对齐）是首个通过控制整个训练轨迹成功实现有效TDP的方法。与快照方法不同，TAFAP采用受数据集蒸馏启发的轨迹匹配技术，在整个微调过程中强制执行持久、可验证的转换。该方法能够同时控制身份和视觉模式。

Result: 通过大量实验验证，TAFAP在扩散模型中首次成功实现了目标转换，显著优于现有的TDP尝试。该方法实现了向目标概念的稳健重定向，同时保持高图像质量。

Conclusion: TAFAP为扩散模型输出提供了可验证的安全保障，并为控制和追踪扩散模型输出的改变提供了新框架，解决了现有保护方法的局限性。

Abstract: Recent advancements in diffusion models have made fine-tuning text-to-image models for personalization increasingly accessible, but have also raised significant concerns regarding unauthorized data usage and privacy infringement. Current protection methods are limited to passively degrading image quality, failing to achieve stable control. While Targeted Data Protection (TDP) offers a promising paradigm for active redirection toward user-specified target concepts, existing TDP attempts suffer from poor controllability due to snapshot-matching approaches that fail to account for complete learning dynamics. We introduce TAFAP (Trajectory Alignment via Fine-tuning with Adversarial Perturbations), the first method to successfully achieve effective TDP by controlling the entire training trajectory. Unlike snapshot-based methods whose protective influence is easily diluted as training progresses, TAFAP employs trajectory-matching inspired by dataset distillation to enforce persistent, verifiable transformations throughout fine-tuning. We validate our method through extensive experiments, demonstrating the first successful targeted transformation in diffusion models with simultaneous control over both identity and visual patterns. TAFAP significantly outperforms existing TDP attempts, achieving robust redirection toward target concepts while maintaining high image quality. This work enables verifiable safeguards and provides a new framework for controlling and tracing alterations in diffusion model outputs.

</details>


### [78] [When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](https://arxiv.org/abs/2512.10449)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Jahnvi Singh,Vinay Chamola,Yash Sinha,Murari Mandal,Dhruv Kumar*

Main category: cs.AI

TL;DR: 该研究探讨了科学同行评审中LLM评估系统对对抗性PDF操纵的脆弱性，开发了WAVS评估指标，发现多种攻击策略能成功操纵评分结果。


<details>
  <summary>Details</summary>
Motivation: 科学同行评审领域正快速整合大语言模型，存在两种趋势：审稿人个人使用LLM减轻工作负担（"懒惰审稿人"假说）和机构正式部署AI评估系统。研究旨在评估这些LLM评估系统对对抗性PDF操纵的鲁棒性。

Method: 研究开发了WAVS（加权对抗性脆弱性评分）作为新评估指标，收集了200篇科学论文数据集，将15种领域特定攻击策略应用于此任务，并在包括GPT-5、Claude Haiku和DeepSeek在内的13个语言模型上进行评估。

Result: 结果显示，如"Maximum Mark Magyk"等混淆策略能成功操纵评分，即使在大型模型中也能实现令人担忧的决策翻转率。攻击策略在改变"拒绝"为"接受"决策方面表现出显著效果。

Conclusion: LLM评估系统对对抗性PDF操纵存在明显脆弱性，需要加强安全防护。研究将发布完整数据集和注入框架以促进该领域更多研究。

Abstract: The landscape of scientific peer review is rapidly evolving with the integration of Large Language Models (LLMs). This shift is driven by two parallel trends: the widespread individual adoption of LLMs by reviewers to manage workload (the "Lazy Reviewer" hypothesis) and the formal institutional deployment of AI-powered assessment systems by conferences like AAAI and Stanford's Agents4Science. This study investigates the robustness of these "LLM-as-a-Judge" systems (both illicit and sanctioned) to adversarial PDF manipulation. Unlike general jailbreaks, we focus on a distinct incentive: flipping "Reject" decisions to "Accept," for which we develop a novel evaluation metric which we term as WAVS (Weighted Adversarial Vulnerability Score). We curated a dataset of 200 scientific papers and adapted 15 domain-specific attack strategies to this task, evaluating them across 13 Language Models, including GPT-5, Claude Haiku, and DeepSeek. Our results demonstrate that obfuscation strategies like "Maximum Mark Magyk" successfully manipulate scores, achieving alarming decision flip rates even in large-scale models. We will release our complete dataset and injection framework to facilitate more research on this topic.

</details>


### [79] [Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation](https://arxiv.org/abs/2512.10501)
*Lim Chien Her,Ming Yan,Yunshu Bai,Ruihao Li,Hao Zhang*

Main category: cs.AI

TL;DR: 提出一种无需训练、使用LLM智能体进行零样本PCG参数配置的架构，通过Actor-Critic双智能体迭代工作流，将自然语言指令转化为精确的参数配置


<details>
  <summary>Details</summary>
Motivation: PCG需要精确配置不透明的技术参数，现有LLM难以弥合抽象用户指令与严格参数规范之间的语义鸿沟，需要更有效的控制方法

Method: 采用Actor-Critic双智能体架构：Actor负责参数配置，Critic进行评估和反馈，形成迭代工作流，无需特定任务微调即可将自然语言转化为PCG工具参数

Result: 在3D地图生成任务上验证，优于单智能体基线，能从自然语言描述生成多样且结构有效的环境，为PCG中的指令跟随建立了新基准

Conclusion: 现成LLM可有效重新用作PCG工具的通用智能体，通过将负担从模型训练转向架构推理，为无需任务特定微调即可掌握复杂软件提供了可扩展框架

Abstract: Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.

</details>


### [80] [Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning](https://arxiv.org/abs/2512.10534)
*Haiteng Zhao,Junhao Shen,Yiming Zhang,Songyang Gao,Kuikun Liu,Tianyou Ma,Fan Zheng,Dahua Lin,Wenwei Zhang,Kai Chen*

Main category: cs.AI

TL;DR: InternGeometry是一个基于LLM的几何问题求解智能体，能够解决IMO级别的几何问题，性能超过金牌选手平均水平，仅使用少量训练数据。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在几何问题求解方面存在启发式构造能力不足的问题，而专家模型如AlphaGeometry 2需要大量数据合成和搜索。本研究旨在构建一个金牌级别的LLM几何智能体，克服几何问题中的启发式限制。

Method: 采用迭代式方法：提出命题和辅助构造，用符号引擎验证，根据引擎反馈指导后续提议。引入动态记忆机制支持每次问题超过200次交互。使用复杂度提升强化学习（CBRL）逐步增加合成问题的复杂度。

Result: 在InternThinker-32B基础上构建的InternGeometry解决了50个IMO几何问题中的44个（2000-2024），超过金牌选手平均分（40.9），仅使用13K训练样本（AlphaGeometry 2数据量的0.004%）。还能为IMO问题提出人类解法中未出现的新辅助构造。

Conclusion: InternGeometry展示了LLM智能体在专家级几何任务上的潜力，通过创新的迭代验证和强化学习方法，以极少量训练数据实现高水平几何问题求解能力。

Abstract: Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.

</details>


### [81] [NormCode: A Semi-Formal Language for Context-Isolated AI Planning](https://arxiv.org/abs/2512.10563)
*Xin Guan*

Main category: cs.AI

TL;DR: NormCode是一种半正式语言，通过结构化分解消除多步LLM工作流中的上下文污染问题，实现数据隔离和精确的成本可靠性追踪。


<details>
  <summary>Details</summary>
Motivation: 多步LLM工作流存在上下文污染问题：随着信息在步骤间积累，模型会产生幻觉、混淆中间输出、丢失任务约束，需要设计一种能消除跨步骤污染的系统。

Method: NormCode是一种半正式语言，创建结构化推理计划，每个步骤在数据隔离环境中运行，只接收显式传递的输入。严格分离语义操作（LLM驱动的推理，非确定性）和句法操作（确定性数据重构），支持三种同构格式：.ncds（人工编写）、.ncd（机器执行）、.ncn（人工验证）。

Result: 验证通过两个演示：(1) 任意长度输入的base X加法算法达到100%准确率；(2) NormCode自身五阶段编译器管道的自托管执行。工作编排器提供依赖驱动调度、SQLite支持的检查点和循环管理。

Conclusion: NormCode通过设计消除跨步骤污染，使AI工作流可审计，满足法律推理、医疗决策和金融分析等高风险领域对透明度的关键需求。

Abstract: Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.

</details>


### [82] [Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs](https://arxiv.org/abs/2512.10611)
*Minghao LI,Ruihang Wang,Rui Tan,Yonggang Wen*

Main category: cs.AI

TL;DR: Phythesis框架结合大语言模型和物理引导的进化优化，自动生成仿真就绪的数据中心场景，实现能源高效设计


<details>
  <summary>Details</summary>
Motivation: 传统数据中心设计方法依赖人工经验和专业仿真工具，难以应对日益增长的系统复杂性。现有生成式AI方法不考虑底层物理约束，无法满足数据中心可量化运营目标和严格物理限制的设计需求

Method: 提出Phythesis框架，采用迭代双层优化架构：1）LLM驱动优化层生成物理合理的三维布局并进行自我批判以优化场景拓扑；2）物理信息优化层识别最优资产参数并选择最佳资产组合

Result: 在三种生成规模上的实验表明，相比纯LLM方案，Phythesis实现了57.3%的生成成功率提升和11.5%的电源使用效率（PUE）改进

Conclusion: Phythesis成功将大语言模型与物理引导优化相结合，为能源高效的数据中心设计提供自动化仿真就绪场景合成方案，有效解决了传统方法的可扩展性和物理约束问题

Abstract: Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial intelligence to design plausible human-centric indoor layouts. However, they do not consider the underlying physics, making them unsuitable for the DC design that sets quantifiable operational objectives and strict physical constraints. To bridge the gap, we propose Phythesis, a novel framework that synergizes large language models (LLMs) and physics-guided evolutionary optimization to automate simulation-ready (SimReady) scene synthesis for energy-efficient DC design. Phythesis employs an iterative bi-level optimization architecture, where (i) the LLM-driven optimization level generates physically plausible three-dimensional layouts and self-criticizes them to refine the scene topology, and (ii) the physics-informed optimization level identifies the optimal asset parameters and selects the best asset combination. Experiments on three generation scales show that Phythesis achieves 57.3% generation success rate increase and 11.5% power usage effectiveness (PUE) improvement, compared with the vanilla LLM-based solution.

</details>


### [83] [Refinement Contrastive Learning of Cell-Gene Associations for Unsupervised Cell Type Identification](https://arxiv.org/abs/2512.10640)
*Liang Peng,Haopeng Liu,Yixuan Ye,Cheng Liu,Wenjun Shen,Si Wu,Hau-San Wong*

Main category: cs.AI

TL;DR: scRCL是一个用于单细胞组学研究的无监督细胞类型识别框架，通过结合细胞-基因相互作用来获得更具信息量的表示，在多个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的细胞聚类方法大多只关注细胞内在结构，忽略了细胞-基因关联的关键作用，这限制了它们区分密切相关的细胞类型的能力。需要一种能够同时利用细胞-细胞结构和细胞-基因关联的方法来提高细胞类型识别的准确性。

Method: 提出了Refinement Contrastive Learning框架(scRCL)，包含两个对比分布对齐组件来揭示可靠的细胞内在结构，以及一个细化模块来整合基因相关性结构学习，通过捕捉潜在的细胞-基因关联来增强细胞嵌入表示。

Result: 在多个单细胞RNA-seq和空间转录组学基准数据集上的实验表明，该方法在细胞类型识别准确性方面始终优于最先进的基线方法。下游生物学分析确认恢复的细胞群体表现出连贯的基因表达特征。

Conclusion: scRCL通过明确结合细胞-基因相互作用，能够获得更具信息量的表示，有效提高细胞类型识别的准确性，并具有生物学相关性。该方法为单细胞组学研究中的细胞异质性分析提供了新的解决方案。

Abstract: Unsupervised cell type identification is crucial for uncovering and characterizing heterogeneous populations in single cell omics studies. Although a range of clustering methods have been developed, most focus exclusively on intrinsic cellular structure and ignore the pivotal role of cell-gene associations, which limits their ability to distinguish closely related cell types. To this end, we propose a Refinement Contrastive Learning framework (scRCL) that explicitly incorporates cell-gene interactions to derive more informative representations. Specifically, we introduce two contrastive distribution alignment components that reveal reliable intrinsic cellular structures by effectively exploiting cell-cell structural relationships. Additionally, we develop a refinement module that integrates gene-correlation structure learning to enhance cell embeddings by capturing underlying cell-gene associations. This module strengthens connections between cells and their associated genes, refining the representation learning to exploiting biologically meaningful relationships. Extensive experiments on several single-cell RNA-seq and spatial transcriptomics benchmark datasets demonstrate that our method consistently outperforms state-of-the-art baselines in cell-type identification accuracy. Moreover, downstream biological analyses confirm that the recovered cell populations exhibit coherent gene-expression signatures, further validating the biological relevance of our approach. The code is available at https://github.com/THPengL/scRCL.

</details>


### [84] [CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.10655)
*Tong Zhang,Carlos Hinojosa,Bernard Ghanem*

Main category: cs.AI

TL;DR: CAPTAIN是一个无需训练的框架，通过修改去噪过程中的潜在特征来减少扩散模型的记忆化问题，在保持提示对齐的同时显著降低训练样本的复制。


<details>
  <summary>Details</summary>
Motivation: 扩散模型可能无意中复制训练样本，引发隐私和版权问题。现有的推理时缓解方法通常操作无分类器引导或扰动提示嵌入，但往往难以在不损害提示对齐的情况下减少记忆化。

Method: CAPTAIN采用基于频率的噪声初始化来减少早期去噪过程中复制记忆模式的倾向；识别特征注入的最佳去噪时间步并定位记忆化区域；将非记忆参考图像的语义对齐特征注入到定位的潜在区域中。

Result: 实验表明，与基于CFG的基线方法相比，CAPTAIN在保持与预期提示强对齐的同时，实现了记忆化的显著减少。

Conclusion: CAPTAIN提供了一个有效的训练免费框架，能够在保持提示保真度和视觉质量的同时，有效抑制扩散模型的记忆化问题。

Abstract: Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, a training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt.

</details>


### [85] [On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity](https://arxiv.org/abs/2512.10665)
*Muhua Huang,Qinlin Zhao,Xiaoyuan Yi,Xing Xie*

Main category: cs.AI

TL;DR: 研究探索了价值多样性如何影响AI多智能体社区的集体行为，发现价值多样性增强价值稳定性、促进涌现行为、带来更多创造性原则，但极端异质性会导致不稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的多智能体系统日益普及，这些人工社区的集体行为（如集体智能）受到越来越多的关注。本研究旨在回答一个基本问题：价值多样性如何塑造AI社区的集体行为？

Method: 使用基于施瓦茨基本人类价值理论的自然主义价值引出方法，构建了多智能体模拟，让不同规模的社区参与开放式互动和宪法制定。

Result: 结果显示：价值多样性增强价值稳定性、促进涌现行为、带来更多由智能体自身开发而无外部指导的创造性原则。但这些效应也呈现边际递减：极端异质性会引发不稳定性。

Conclusion: 本研究将价值多样性定位为未来AI能力的新维度，连接了AI能力与制度涌现的社会学研究。

Abstract: As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.

</details>


### [86] [Challenges of Evaluating LLM Safety for User Welfare](https://arxiv.org/abs/2512.10687)
*Manon Kempermann,Sai Suresh Macharla Vasu,Mahalakshmi Raveenthiran,Theo Farrell,Ingmar Weber*

Main category: cs.AI

TL;DR: 该研究挑战了传统大语言模型安全评估只关注通用风险的局限性，提出需要针对个人福祉进行情境感知评估，特别是在金融和健康等高风险领域，并发现仅依赖用户披露的情境信息不足以进行有效评估。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全评估主要关注通用风险（如危险能力或不良倾向），但数百万用户使用LLM获取金融和健康等高风险领域的个人建议，这些危害是情境依赖而非通用的。虽然OECD等框架认识到评估个体风险的必要性，但用户福祉安全评估仍不成熟。本研究旨在探索如何设计有效的用户福祉安全评估。

Method: 研究采用探索性方法，评估GPT-5、Claude Sonnet 4和Gemini 2.5 Pro在金融和健康领域的建议质量。首先比较了情境盲评估者与情境感知评估者对相同LLM响应的安全评分差异。其次，测试了包含用户报告会披露的情境信息的提示是否能改善评估效果。

Result: 研究发现：1）评估者必须获得丰富的用户情境信息：相同LLM响应，情境盲评估者比情境感知评估者评分显著更高，高脆弱性用户的安全评分从安全（5/7）降至有些不安全（3/7）。2）仅依赖用户会披露的情境信息无法显著改善评估效果。3）有效的用户福祉安全评估需要评估者基于多样化用户档案评估响应。

Conclusion: 用户福祉安全评估需要与现有通用风险框架不同的方法，必须采用情境感知评估方法，评估者需要基于多样化用户档案评估响应。仅依赖用户披露的情境信息不足，特别是对脆弱人群。研究提供了情境感知评估的方法论起点，并开源了代码和数据集。

Abstract: Safety evaluations of large language models (LLMs) typically focus on universal risks like dangerous capabilities or undesirable propensities. However, millions use LLMs for personal advice on high-stakes topics like finance and health, where harms are context-dependent rather than universal. While frameworks like the OECD's AI classification recognize the need to assess individual risks, user-welfare safety evaluations remain underdeveloped. We argue that developing such evaluations is non-trivial due to fundamental questions about accounting for user context in evaluation design. In this exploratory study, we evaluated advice on finance and health from GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across user profiles of varying vulnerability. First, we demonstrate that evaluators must have access to rich user context: identical LLM responses were rated significantly safer by context-blind evaluators than by those aware of user circumstances, with safety scores for high-vulnerability users dropping from safe (5/7) to somewhat unsafe (3/7). One might assume this gap could be addressed by creating realistic user prompts containing key contextual information. However, our second study challenges this: we rerun the evaluation on prompts containing context users report they would disclose, finding no significant improvement. Our work establishes that effective user-welfare safety evaluation requires evaluators to assess responses against diverse user profiles, as realistic user context disclosure alone proves insufficient, particularly for vulnerable populations. By demonstrating a methodology for context-aware evaluation, this study provides both a starting point for such assessments and foundational evidence that evaluating individual welfare demands approaches distinct from existing universal-risk frameworks. We publish our code and dataset to aid future developments.

</details>


### [87] [Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning](https://arxiv.org/abs/2512.10691)
*Benjamin Gundersen,Nicolas Deperrois,Samuel Ruiperez-Campillo,Thomas M. Sutter,Julia E. Vogt,Michael Moor,Farhad Nooralahzadeh,Michael Krauthammer*

Main category: cs.AI

TL;DR: 该研究探索了强化学习（RL）和显式推理（thinking）在胸部X光视觉语言模型中的应用，发现RL能提升报告生成和视觉定位性能，但显式推理无明显额外增益。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型主要依赖监督微调（SFT），但SFT仅优化下一个token预测而不评估答案质量。强化学习能整合任务特定反馈，结合显式中间推理在数学和编程任务中已显示出显著优势，因此研究团队希望探索RL和显式推理在胸部X光VLM中的效果。

Method: 1. 在CXR数据上进行大规模SFT，基于Qwen3-VL构建更新的RadVLM；2. 进行冷启动SFT阶段，为模型提供基本推理能力；3. 应用Group Relative Policy Optimization（GRPO），结合临床基础的任务特定奖励进行报告生成和视觉定位；4. 在领域特定和通用领域Qwen3-VL变体上进行匹配的RL实验，包含有/无显式推理的设置。

Result: 研究发现：1. 强大的SFT对高基础性能仍然至关重要；2. RL在两个任务上都能提供额外增益；3. 显式推理并未进一步改善结果；4. 在统一评估流程下，RL优化的RadVLM模型优于基线对应模型，在报告生成和视觉定位方面达到最先进性能。

Conclusion: 临床对齐的强化学习是医学视觉语言模型中监督微调的有力补充，能显著提升模型在胸部X光解读任务中的性能，但显式中间推理在当前设置下未显示出额外优势。

Abstract: Recent advances in vision-language models (VLMs) have improved Chest X-ray (CXR) interpretation in multiple aspects. However, many medical VLMs rely solely on supervised fine-tuning (SFT), which optimizes next-token prediction without evaluating answer quality. In contrast, reinforcement learning (RL) can incorporate task-specific feedback, and its combination with explicit intermediate reasoning ("thinking") has demonstrated substantial gains on verifiable math and coding tasks. To investigate the effects of RL and thinking in a CXR VLM, we perform large-scale SFT on CXR data to build an updated RadVLM based on Qwen3-VL, followed by a cold-start SFT stage that equips the model with basic thinking ability. We then apply Group Relative Policy Optimization (GRPO) with clinically grounded, task-specific rewards for report generation and visual grounding, and run matched RL experiments on both domain-specific and general-domain Qwen3-VL variants, with and without thinking. Across these settings, we find that while strong SFT remains crucial for high base performance, RL provides additional gains on both tasks, whereas explicit thinking does not appear to further improve results. Under a unified evaluation pipeline, the RL-optimized RadVLM models outperform their baseline counterparts and reach state-of-the-art performance on both report generation and grounding, highlighting clinically aligned RL as a powerful complement to SFT for medical VLMs.

</details>


### [88] [COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators](https://arxiv.org/abs/2512.10702)
*Wei Fang,Chiyao Wang,Wenshuai Ma,Hui Liu,Jianqiang Hu,Xiaona Niu,Yi Chu,Mingming Zhang,Jingxiao Yang,Dongwei Zhang,Zelin Li,Pengyun Liu,Jiawei Zheng,Pengke Zhang,Chaoshi Qin,Wangang Guo,Bin Wang,Yugang Xue,Wei Zhang,Zikuan Wang,Rui Zhu,Yihui Cao,Quanmao Lu,Rui Meng,Yan Li*

Main category: cs.AI

TL;DR: CA-GPT AI-OCT系统在OCT引导的PCI规划和评估中，相比通用ChatGPT-5和初级医师，展现出显著更优的决策一致性。


<details>
  <summary>Details</summary>
Motivation: 虽然血管内成像（特别是OCT）改善了PCI结果，但其解读依赖于操作者经验。通用人工智能虽有潜力但缺乏领域特异性可靠性，因此需要开发专门针对OCT引导PCI的AI系统。

Method: 单中心分析96例接受OCT引导PCI的患者，比较CA-GPT、ChatGPT-5和初级医师生成的程序决策与专家记录的一致性。使用10个预设指标评估PCI前规划和PCI后评估阶段的一致性。

Result: 在PCI前规划中，CA-GPT的中位一致性评分显著高于ChatGPT-5和初级医师。在支架直径和长度选择方面，CA-GPT表现优于初级医师。在PCI后评估中，CA-GPT保持优异的一致性，在复杂场景中也显示出稳健的性能优势。

Conclusion: 基于CA-GPT的AI-OCT系统在PCI规划和评估阶段，相比通用大语言模型和初级医师，实现了更优的决策一致性。该方法为血管内成像解读提供了标准化可靠的方法，显示出增强操作者专业知识和优化OCT引导PCI的显著潜力。

Abstract: Background: While intravascular imaging, particularly optical coherence tomography (OCT), improves percutaneous coronary intervention (PCI) outcomes, its interpretation is operator-dependent. General-purpose artificial intelligence (AI) shows promise but lacks domain-specific reliability. We evaluated the performance of CA-GPT, a novel large model deployed on an AI-OCT system, against that of the general-purpose ChatGPT-5 and junior physicians for OCT-guided PCI planning and assessment.
  Methods: In this single-center analysis of 96 patients who underwent OCT-guided PCI, the procedural decisions generated by the CA-GPT, ChatGPT-5, and junior physicians were compared with an expert-derived procedural record. Agreement was assessed using ten pre-specified metrics across pre-PCI and post-PCI phases.
  Results: For pre-PCI planning, CA-GPT demonstrated significantly higher median agreement scores (5[IQR 3.75-5]) compared to both ChatGPT-5 (3[2-4], P<0.001) and junior physicians (4[3-4], P<0.001). CA-GPT significantly outperformed ChatGPT-5 across all individual pre-PCI metrics and showed superior performance to junior physicians in stent diameter (90.3% vs. 72.2%, P<0.05) and length selection (80.6% vs. 52.8%, P<0.01). In post-PCI assessment, CA-GPT maintained excellent overall agreement (5[4.75-5]), significantly higher than both ChatGPT-5 (4[4-5], P<0.001) and junior physicians (5[4-5], P<0.05). Subgroup analysis confirmed CA-GPT's robust performance advantage in complex scenarios.
  Conclusion: The CA-GPT-based AI-OCT system achieved superior decision-making agreement versus a general-purpose large language model and junior physicians across both PCI planning and assessment phases. This approach provides a standardized and reliable method for intravascular imaging interpretation, demonstrating significant potential to augment operator expertise and optimize OCT-guided PCI.

</details>


### [89] [Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly](https://arxiv.org/abs/2512.10787)
*Moshe Lahmy,Roi Yozevitch*

Main category: cs.AI

TL;DR: SEAL-RAG提出了一种"替换而非扩展"策略来解决RAG系统在多跳查询中的上下文稀释问题，通过搜索-提取-评估-循环机制动态替换无关信息，在固定检索深度下提升答案正确性和证据精度。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理多跳查询时，当初始检索遗漏桥接事实时，通常采用添加更多上下文或修剪现有列表的方法。但简单地扩展上下文窗口会导致上下文稀释，即干扰信息挤占相关信息的空间。

Method: SEAL-RAG采用训练免费的控制器，执行搜索→提取→评估→循环的周期：1）进行实时的实体锚定提取以构建缺失实体/关系的间隙规范；2）触发有针对性的微查询；3）使用实体优先排名主动用填补间隙的证据替换干扰信息。

Result: 在HotpotQA（k=3）上，SEAL比Self-RAG在答案正确性上提升3-13个百分点，证据精度提升12-18个百分点。在2WikiMultiHopQA（k=5）上，比Adaptive-k在准确率上提升8.0个百分点，证据精度保持在96%（CRAG仅为22%）。所有提升都具有统计显著性（p<0.001）。

Conclusion: 通过实施固定k替换策略，SEAL-RAG在保持可预测成本配置的同时，确保top-k槽位为精度而非广度进行优化，有效解决了多跳查询中的上下文稀释问题。

Abstract: Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \textbf{context dilution}, where distractors crowd out relevant information. We propose \textbf{SEAL-RAG}, a training-free controller that adopts a \textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\textbf{S}earch $\rightarrow$ \textbf{E}xtract $\rightarrow$ \textbf{A}ssess $\rightarrow$ \textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \textbf{HotpotQA} and \textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \textbf{+3--13 pp} and evidence precision by \textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \textbf{+8.0 pp} in accuracy and maintains \textbf{96\%} evidence precision compared to 22\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.

</details>


### [90] [HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition](https://arxiv.org/abs/2512.10807)
*Wang Lu,Yao Zhu,Jindong Wang*

Main category: cs.AI

TL;DR: 该论文提出了HAROOD基准测试，用于全面评估人类活动识别在分布外场景下的性能，涵盖了4种OOD场景、6个数据集和16种方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人类活动识别研究在面对个体、设备、环境、时间等变化导致的分布偏移时，缺乏对现有分布外算法的全面评估和比较，需要建立一个综合性的基准测试。

Method: 提出HAROOD基准测试，定义了4种OOD场景（跨人、跨位置、跨数据集、跨时间），构建了包含6个数据集、16种比较方法（基于CNN和Transformer架构）的测试平台，并采用两种模型选择协议。

Result: 通过大量实验发现：没有单一方法在所有场景下都表现最优，这表明该领域仍有很大的改进空间；同时验证了OOD算法在HAR中的必要性。

Conclusion: HAROOD为OOD-based HAR研究提供了模块化、易扩展的代码库，有助于推动该领域的发展，并揭示了当前方法的局限性，为未来研究指明了方向。

Abstract: Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this challenge by applying or adapting existing out-of-distribution (OOD) algorithms, but only in certain distribution shift scenarios (e.g., cross-device or cross-position), lacking comprehensive insights on the effectiveness of these algorithms. For instance, is OOD necessary to HAR? Which OOD algorithm performs the best? In this paper, we fill this gap by proposing HAROOD, a comprehensive benchmark for HAR in OOD settings. We define 4 OOD scenarios: cross-person, cross-position, cross-dataset, and cross-time, and build a testbed covering 6 datasets, 16 comparative methods (implemented with CNN-based and Transformer-based architectures), and two model selection protocols. Then, we conduct extensive experiments and present several findings for future research, e.g., no single method consistently outperforms others, highlighting substantial opportunity for advancement. Our codebase is highly modular and easy to extend for new datasets, algorithms, comparisons, and analysis, with the hope to facilitate the research in OOD-based HAR. Our implementation is released and can be found at https://github.com/AIFrontierLab/HAROOD.

</details>


### [91] [Agile Deliberation: Concept Deliberation for Subjective Visual Classification](https://arxiv.org/abs/2512.10821)
*Leijie Wang,Otilia Stretcu,Wei Qiao,Thomas Denby,Krishnamurthy Viswanathan,Enming Luo,Chun-Ta Lu,Tushar Dogra,Ranjay Krishna,Ariel Fuxman*

Main category: cs.AI

TL;DR: 论文提出"敏捷审议"框架，支持用户通过边界案例迭代定义模糊视觉概念，相比自动化分解基线提升7.5% F1分数


<details>
  <summary>Details</summary>
Motivation: 现有人机交互方法假设用户有清晰稳定的概念理解，但现实中用户常从模糊想法开始，需要通过"概念审议"迭代细化。内容审核专家实践中存在这种概念审议过程，需要系统化支持

Method: 提出"敏捷审议"人机交互框架，包含两个阶段：1)概念界定-将初始概念分解为结构化子概念层次；2)概念迭代-展示语义边界案例供用户反思反馈，迭代对齐图像分类器与用户意图

Result: 通过18个1.5小时用户会话评估，敏捷审议比自动化分解基线提高7.5% F1分数，比手动审议提高3%以上，参与者报告概念理解更清晰且认知负担更低

Conclusion: 敏捷审议框架有效支持用户定义模糊和主观概念，通过结构化概念分解和边界案例迭代，显著提升分类性能并降低用户认知负担

Abstract: From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through "concept deliberation", a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called "Agile Deliberation" that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user's evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.

</details>


### [92] [V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions](https://arxiv.org/abs/2512.10822)
*Mumuksh Tayal,Manan Tayal,Aditya Singh,Shishir Kolathaya,Ravi Prakash*

Main category: cs.AI

TL;DR: V-OCBF：一种从离线演示中学习神经控制屏障函数的框架，无需系统动力学模型，通过递归有限差分屏障更新实现模型无关学习，结合期望分位数目标避免分布外动作查询，最终通过二次规划合成实时安全控制。


<details>
  <summary>Details</summary>
Motivation: 现有安全离线强化学习方法通常强制执行软期望成本约束，无法保证前向不变性；而控制屏障函数（CBFs）虽然提供严格安全保证，但通常依赖专家设计的屏障函数或完整的系统动力学知识。需要一种既能从离线数据学习安全屏障，又不需要动力学模型的方法。

Method: 提出价值引导离线控制屏障函数（V-OCBF）框架：1）从离线演示中学习神经CBF，无需动力学模型；2）推导递归有限差分屏障更新，实现模型无关学习；3）采用期望分位数目标，避免在分布外动作上查询屏障，限制更新到数据集支持的动作集；4）将学习到的屏障与二次规划（QP）结合合成实时安全控制。

Result: 在多个案例研究中，V-OCBF相比基线方法显著减少了安全违规次数，同时保持了强大的任务性能，展示了其在无需在线交互或手工设计屏障的情况下，离线合成安全关键控制器的可扩展性。

Conclusion: V-OCBF成功解决了离线安全控制中的关键挑战：无需动力学模型或专家设计的屏障函数，仅从离线演示中学习神经CBF，实现了严格的安全保证和良好的任务性能平衡，为安全关键系统的离线控制器合成提供了有效框架。

Abstract: Ensuring safety in autonomous systems requires controllers that satisfy hard, state-wise constraints without relying on online interaction. While existing Safe Offline RL methods typically enforce soft expected-cost constraints, they do not guarantee forward invariance. Conversely, Control Barrier Functions (CBFs) provide rigorous safety guarantees but usually depend on expert-designed barrier functions or full knowledge of the system dynamics. We introduce Value-Guided Offline Control Barrier Functions (V-OCBF), a framework that learns a neural CBF entirely from offline demonstrations. Unlike prior approaches, V-OCBF does not assume access to the dynamics model; instead, it derives a recursive finite-difference barrier update, enabling model-free learning of a barrier that propagates safety information over time. Moreover, V-OCBF incorporates an expectile-based objective that avoids querying the barrier on out-of-distribution actions and restricts updates to the dataset-supported action set. The learned barrier is then used with a Quadratic Program (QP) formulation to synthesize real-time safe control. Across multiple case studies, V-OCBF yields substantially fewer safety violations than baseline methods while maintaining strong task performance, highlighting its scalability for offline synthesis of safety-critical controllers without online interaction or hand-engineered barriers.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [93] [Hybrid quantum-classical matrix-product state and Lanczos methods for electron-phonon systems with strong electronic correlations: Application to disordered systems coupled to Einstein phonons](https://arxiv.org/abs/2512.10899)
*Heiko Georg Menzler,Suman Mondal,Fabian Heidrich-Meisner*

Main category: cond-mat.str-el

TL;DR: 该论文提出了两种量子-经典混合方法，用于模拟电子-声子系统的时间演化，其中电子关联被数值精确处理，而光学声子自由度则采用经典近似。


<details>
  <summary>Details</summary>
Motivation: 研究电子-声子系统中时间依赖性的模拟方法，特别是在电子关联效应显著的情况下，需要开发能够精确处理电子关联同时高效处理声子自由度的混合方法。

Method: 提出了两种量子-经典混合方法：1）时间依赖的Lanczos方法结合多轨迹Ehrenfest方法；2）矩阵乘积态方法结合多轨迹Ehrenfest方法。这些方法将电子关联数值精确处理，而光学声子自由度采用经典近似。

Result: 方法在声子频率较小的绝热区域预期可靠。在一维相互作用无自旋费米子系统中讨论了两种方法的收敛特性，并以Holstein链为基准。应用研究发现，强无序系统与经典振子耦合会导致退局域化，从而破坏该系统中的（有限尺寸）多体局域化。

Conclusion: 提出的两种量子-经典混合方法能够有效模拟电子-声子系统的时间演化，特别是在处理电子关联效应方面具有优势。研究发现电子-声子耦合对无序系统的局域化特性有重要影响，强耦合可能导致退局域化效应。

Abstract: We present two quantum-classical hybrid methods for simulating the time-dependence of electron-phonon systems that treat electronic correlations numerically exactly and optical-phonon degrees of freedom classically. These are a time-dependent Lanczos and a matrix-product state method, each combined with the multi-trajectory Ehrenfest approach. Due to the approximations, reliable results are expected for the adiabatic regime of small phonon frequencies. We discuss the convergence properties of both methods for a system of interacting spinless fermions in one dimension and provide a benchmark for the Holstein chain. As a first application, we study the decay of charge density wave order in a system of interacting spinless fermions coupled to Einstein oscillators and in the presence of quenched disorder. We investigate the dependence of the relaxation dynamics on the electron-phonon coupling strength and provide numerical evidence that the coupling of strongly disordered systems to classical oscillators leads to delocalization, thus destabilizing the (finite-size) many-body localization in this system.

</details>


### [94] [Planckian Bounds via Spectral Moments of Optical Conductivity](https://arxiv.org/abs/2512.09979)
*Debanjan Chowdhury*

Main category: cond-mat.str-el

TL;DR: 该论文提出了一种从光学电导率中提取普朗克散射时间尺度的模型无关方法，通过谱矩比值B的严格上界来约束普朗克速率。


<details>
  <summary>Details</summary>
Motivation: 在强关联金属中，通过Drude拟合观察到的普朗克散射现象引发了一个问题：如何从可测量量中以模型无关的方式提取内在时间尺度。现有方法通常依赖于特定模型假设，需要一种更基础的方法来理解普朗克散射的本质。

Method: 研究聚焦于光学电导率耗散部分谱矩的比值B，证明了B在普朗克速率方面的严格上界。该上界源于电流算符热加权响应函数的解析结构。关键的是，这个有界量可以通过光学光谱直接测量，并且可以从量子蒙特卡洛模拟中的虚时间关联函数计算，无需解析延拓。

Result: 对于具有单一散射率的Drude和非Drude形式光学电导率的简化示例，在各种渐近区域中评估B，发现B远低于饱和值。这表明普朗克上界可以从平衡动力学的基本约束中产生。

Conclusion: 普朗克上界可以源于平衡动力学的基本约束，指向可能支配关联量子物质输运的普适结构。该方法为理解强关联系统中的普朗克散射提供了模型无关的理论框架。

Abstract: The observation of Planckian scattering, often inferred from Drude fits in strongly correlated metals, raises the question of how to extract an intrinsic timescale from measurable quantities in a model-independent way. We address this by focusing on a ratio (${\cal{B}}$) of spectral moments of the dissipative part of the optical conductivity and prove a rigorous upper bound on ${\cal{B}}$ in terms of the Planckian rate. The bound emerges from the analytic structure of thermally weighted response functions of the current operator. Crucially, the bounded quantity is directly accessible via optical spectroscopy and computable from imaginary-time correlators in quantum Monte Carlo simulations, without any need for analytic continuation. We evaluate ${\cal{B}}$ for simplified examples of both Drude and non-Drude forms of the optical conductivity with a single scattering rate in various asymptotic regimes, and find that ${\cal{B}}$ lies far below the saturation value. These findings demonstrate that Planckian bounds can arise from fundamental constraints on equilibrium dynamics, pointing toward a possibly universal structure governing transport in correlated quantum matter.

</details>


### [95] [Measuring the Hall Viscosity of the Laughlin State on Noisy Quantum Computers](https://arxiv.org/abs/2512.09982)
*Ammar Kirmani,Andrew A. Allocca,Jian-Xin Zhu,Armin Rahmani,Sriram Ganeshan,Pouyan Ghaemi*

Main category: cond-mat.str-el

TL;DR: 该研究通过量子电路协议在NISQ设备上实现了分数量子霍尔态与背景度规耦合的准一维模型，从度规淬火后的几何响应中提取霍尔粘度，实验数据与理论预测吻合良好。


<details>
  <summary>Details</summary>
Motivation: 霍尔粘度是分数量子霍尔流体对绝热几何形变的量子化非耗散应力响应，尽管有重要理论意义，但在实验上一直难以观测，因此成为当前NISQ量子计算设备实现的重要目标。

Method: 采用分数量子霍尔态与背景度规耦合的准一维模型，设计并实现量子电路协议，在希尔伯特空间截断版本中通过度规淬火探测几何响应，从波函数动力学中提取霍尔粘度。

Result: 硬件实验数据与解析和数值预测在截断区域内表现出极好的一致性，虽然截断限制了获得完全量子化的霍尔粘度值，但在受限区域内验证了几何响应机制。

Conclusion: 该工作展示了在NISQ设备上实现分数量子霍尔态几何响应研究的可行性，为实验观测霍尔粘度提供了新途径，并为量子模拟拓扑物态开辟了道路。

Abstract: Hall viscosity is a quantized nondissipative stress response of a fractional quantum Hall (FQH) fluid to adiabatic geometric deformations. Despite strong theoretical interest, its experimental observation in the FQH state has remained elusive, making it a promising target for realization on current NISQ devices. In this work, we employ a quasi-one-dimensional model of an FQH state coupled to a background metric to probe the geometric response under a metric quench. We design and implement a quantum-circuit protocol that realizes a Hilbert-space-truncated version of the model and extracts the Hall viscosity from the geometric response encoded in the wavefunction dynamics of the device. While the truncation prevents us from accessing the fully quantized value of Hall viscosity, the hardware data nevertheless show excellent agreement with analytical and numerical predictions within this restricted regime.

</details>


### [96] [The magnetic structure of polar $G$-type charge and orbital ordered Hg-quadruple manganite perovskites](https://arxiv.org/abs/2512.10070)
*Ben R. M. Tragheim,Fabio Orlandi,En-Pei Liu,Wei-Tin Chen,Mark S. Senn*

Main category: cond-mat.str-el

TL;DR: 通过粉末中子衍射和对称性分析，解析了新型四重锰酸盐钙钛矿Hg0.7Na0.3Mn3Mn4O12的磁结构，发现其具有独特的G型电荷和轨道有序态，以及特殊的"上-上-下-下"反铁磁构型。


<details>
  <summary>Details</summary>
Motivation: 研究新型四重锰酸盐钙钛矿Hg0.7Na0.3Mn3Mn4O12的磁结构，探索其与其它A²⁺Mn₃Mn₄O₁₂类似物（A=Ca, Sr, Cd, Pb）不同的独特性质，特别是Hg²⁺在稳定新颖态方面的特殊作用。

Method: 使用粉末中子衍射技术和对称性驱动的分析方法，解析材料的磁结构，并通过结构畸变与磁畸变之间的耦合机制来探索B位点"上-上-下-下"反铁磁有序的起源和稳定机制。

Result: 发现A'位点Mn呈现G型反铁磁有序，B位点Mn自旋呈现独特的"上-上-下-下"反铁磁构型。揭示了结构畸变与磁畸变之间的耦合是稳定这种特殊磁有序的关键机制。

Conclusion: 该研究证明了四重锰酸盐钙钛矿中存在的奇异电荷、轨道、电子和磁有序态，特别突出了Hg²⁺相比于其它二价A位阳离子在稳定新颖态方面的独特化学作用。

Abstract: The magnetic structure of the novel Hg$_{0.7}$Na$_{0.3}$Mn$_3$Mn$_4$O$_{12}$, a quadruple manganite perovskite that exhibits a unique $G$-type charge and orbital ordered state distinct to other $A^{2+}$Mn$_3$Mn$_4$O$_{12}$ equivalents ($A$ $=$ Ca, Sr, Cd, Pb), has been solved using powder neutron diffraction and symmetry-motivated analysis. A $G$-type-like antiferromagnetic (AFM) ordering of Mn on the $A'$ sites and a `up--up--down--down' AFM moment configuration of Mn spins on the $B$ sites is found to occur. The mechanism for the onset and stabilization of $B$ site `up--up--down--down' AFM order is explored in terms of coupling between structural and magnetic distortions. The results presented here provide evidence of the exotic charge, orbital, electronic and magnetic orderings that quadruple manganite perovskites demonstrate, and further highlighting the distinct chemistry that Hg$^{2+}$ plays in stabilizing novel states compared to other divalent $A$-site cation equivalents.

</details>


### [97] [Gutzwiller approximation for paramagnetic ionic Hubbard model: Analytic expression for band - Mott insulator transition](https://arxiv.org/abs/2512.10096)
*Marcin M. Wysokiński*

Main category: cond-mat.str-el

TL;DR: 在无限维Gutzwiller近似下，推导出离子Hubbard模型中Mott绝缘体和能带绝缘体相界的紧凑解析表达式，但该方法无法捕捉有限交错势下发现的关联金属态。


<details>
  <summary>Details</summary>
Motivation: 离子Hubbard模型是研究能带绝缘和Mott绝缘竞争的标准模型，需要建立简洁的变分框架来分析其相图。

Method: 采用无限维Gutzwiller近似这一变分精确方法，推导出Mott绝缘体和能带绝缘体相界的紧凑解析表达式。

Result: 方法成功再现了预期的能带-Mott绝缘体现象学，但无法捕捉在有限交错势下发现的关联金属态，表明该金属相源于非相干Hubbard带物理而非Gutzwiller近似能很好捕捉的费米液体行为。

Conclusion: 建立了一个简洁的离子Hubbard模型变分框架，可自然扩展到非平衡设置和自旋交换动力学研究。

Abstract: The ionic Hubbard model is a paradigmatic setup for studying the competition between band and Mott insulating behavior. Within the variationally exact in infinite dimensions Gutzwiller approximation, we derive a compact analytic expression for the phase boundary between Mott and band insulator. While the method reproduces the expected band-Mott insulator phenomenology, it does not capture the correlated metallic state at finite staggered potential found for example in dynamical mean-field theory. This absence highlights that the metallic phase originates from incoherent Hubbard-band physics rather than Fermi-liquid behavior well captured by Gutzwiller approximation. Our formulation establishes a concise variational framework to ionic Hubbard model, with natural extensions to nonequilibrium setups and spin-exchange dynamics.

</details>


### [98] [Large Anomalous Hall Effect in Topologically Trivial Double-$Q$ Magnets](https://arxiv.org/abs/2512.10168)
*Satoru Ohgata,Satoru Hayami*

Main category: cond-mat.str-el

TL;DR: 该论文研究了拓扑平凡的双Q自旋纹理中霍尔响应的增强机制，发现尽管标量自旋手性抵消，但双Q磁结构仍能产生显著的霍尔效应，这源于多轨道Kondo晶格模型中双Q超结构诱导的轨道杂化增强了k空间贝里曲率。


<details>
  <summary>Details</summary>
Motivation: 传统上认为拓扑非平凡的自旋纹理（如磁斯格明子）通过实空间标量自旋手性产生拓扑霍尔效应。然而，本文旨在探索拓扑平凡的双Q自旋纹理中霍尔响应增强的另一种机制，解释在GdRu2Si2和GdRu2Ge2等材料中观察到的巨大反常霍尔效应。

Method: 通过理论分析多轨道Kondo晶格模型，研究双Q自旋纹理对电子结构的影响。重点分析双Q超结构诱导的轨道杂化如何增强k空间的贝里曲率，从而产生大的反常霍尔效应。

Result: 研究发现，尽管双Q磁结构中标量自旋手性相互抵消，但仍能产生显著的霍尔响应，且霍尔响应与均匀磁化强度呈非单调依赖关系，这与铁磁态和单Q螺旋态形成鲜明对比。该机制成功解释了GdRu2Si2和GdRu2Ge2中观察到的巨大反常霍尔效应。

Conclusion: 拓扑平凡的双Q自旋纹理通过轨道杂化增强k空间贝里曲率的机制，能够产生大的反常霍尔效应，这为开发新型自旋电子学材料提供了新途径，表明拓扑平凡的自旋结构同样具有重要的应用潜力。

Abstract: Multi-$Q$ magnets consist of superposed spin density waves with distinct magnetic modulation vectors, enabling a wide range of magnetic orders depending on their combination. Among them, topologically nontrivial spin textures, such as a magnetic skyrmion, has been extensively studied owing to the emergence of topological Hall effects induced by real-space scalar spin chirality. Contrary to this expectation, we theoretically investigate another route to enhancing the Hall response under a topologically \textit{trivial} double-$Q$ spin textures. Despite the cancellation of the scalar spin chirality, the double-$Q$ magnetism exhibits a pronounced Hall response with a nonmonotonic dependence on the uniform magnetization, which is in stark contrast to a ferromagnetic state and a single-$Q$ spiral state. Analyzing the multi-orbital Kondo lattice model, we show that orbital hybridization induced by the double-$Q$ superstructure enhances the Berry curvature in $\mathbf{k}$-space, leading to a large anomalous Hall effect. This mechanism accounts for the observed giant anomalous Hall effect in GdRu$_2$Si$_2$ and GdRu$_2$Ge$_2$, thereby highlighting topologically trivial double-$Q$ spin textures as promising spintronic materials.

</details>


### [99] [Evaluating covalency using RIXS spectral weights: Silver fluorides vs. cuprates](https://arxiv.org/abs/2512.10219)
*Ilya Degtev,Daniel Jezierski,Adrián Gómez Pueyo,Luciana Di Gaspare,Monica De Seta,Paolo Barone,Giacomo Ghiringhelli,Pieter Glatzel,Zoran Mazej,Wojciech Grochala,Marco Moretti Sala,José Lorenzana*

Main category: cond-mat.str-el

TL;DR: 通过X射线吸收光谱和共振非弹性X射线散射研究银氟化物电子结构，发现其与铜酸盐相似，可作为模拟铜酸盐物理的平台


<details>
  <summary>Details</summary>
Motivation: 研究银氟化物的电子结构，探索其是否可以作为模拟铜酸盐物理的平台，为研究高温超导和奇异磁性提供新途径

Method: 使用Ag L3边的X射线吸收光谱和共振非弹性X射线散射，结合密度泛函理论计算，分析AgF2、AgFBF4、AgF和Ag2O的电子结构

Result: 发现AgF2具有类似La2CuO4的电荷转移激发和dd激发，提出dd与CT光谱权重比作为共价性度量，银氟化物比铜酸盐更具共价性

Conclusion: 银氟化物是模拟铜酸盐物理的优异平台，为探索准二维和准一维材料中的高温超导和奇异磁性提供了有前景的途径

Abstract: We investigate the electronic structure of AgF2, AgFBF4, AgF and Ag2O using X-ray absorption spectroscopy (XAS) and resonant inelastic X-ray scattering (RIXS) at the Ag L3 edge. XAS results were compared with density functional theory computations of the spectra, allowing an identification of main features and an assessment of the theoretical approximations. Our RIXS measurements reveal that AgF2 exhibits charge transfer excitations and dd excitations, analogous to those observed in La2CuO4. We propose to use the ratio of dd to CT spectral weight as a measure of the covalence of the compounds and provide explicit equations for the weights as a function of the scattering geometry for crystals and powders. The measurements at the metal site L3 edge and previous measurements at the ligand K edge reveal a striking similarity between the fluorides and cuprates materials, with fluorides somewhat more covalent than cuprates. These findings support the hypothesis that silver fluorides are an excellent platform to mimic the physics of cuprates, providing a promising avenue for exploring high-Tc superconductivity and exotic magnetism in quasi-two-dimensional (AgF2) and quasi-one-dimensional (AgFBF4) materials.

</details>


### [100] [Investigating the origin of topological-Hall-like resistivity in Zn-doped Mn2Sb ferrimagnet](https://arxiv.org/abs/2512.10285)
*BoCheng Yu,JiaLiang Jiang,Jing Meng,XiaoYan Zhu,Jie Ma,HaiFeng Du,QingFeng Zhan,Jin Tang,Yang Xu,Tian Shang*

Main category: cond-mat.str-el

TL;DR: 该研究发现Zn掺杂Mn2Sb铁磁体中的霍尔电阻异常并非源于拓扑霍尔效应或手性自旋结构，而是由样品不均匀性导致的多重反常霍尔通道共同作用引起。


<details>
  <summary>Details</summary>
Motivation: 霍尔电阻异常（拓扑霍尔效应）通常被用作磁性材料中存在手性自旋结构的证据，但近期研究表明这种异常可能源于其他机制。本研究旨在验证Zn掺杂Mn2Sb铁磁体中的霍尔电阻异常是否真正反映手性自旋结构的存在。

Method: 通过研究Zn掺杂Mn2Sb铁磁体的磁性和输运性质，测量霍尔电阻异常，并利用洛伦兹透射电子显微镜直接观测手性自旋结构的存在与否。

Result: 霍尔电阻异常与磁相变或亚磁相变几乎没有关联，与存在手性自旋结构的磁性化合物明显不同。洛伦兹透射电子显微镜测量排除了手性自旋结构的存在，表明霍尔电阻异常源于样品不均匀性导致的多重反常霍尔通道共同作用。

Conclusion: 霍尔电阻异常不能作为手性自旋结构存在的可靠证据，即使在块体系统中也存在误判风险。现有基于输运测量推断手性自旋结构的结果需要重新审视。

Abstract: Skyrmions and other chiral spin textures have been extensively studied as potential building blocks for novel spintronic devices. Hall-resistivity anomalies that deviate from magnetization scaling, known as the topological Hall effect, have been widely employed as evidence for the presence of chiral spin textures in magnetic materials. However, recent studies on magnetic thin films have revealed a drawback of this approach, as the presumed topological Hall contribution may in fact originate from trivial mechanisms. Here, we investigate the magnetic and transport properties of a Zn-doped Mn2Sb ferrimagnet, whose related compounds have previously been suggested to exhibit a topological Hall effect arising from chiral spin textures. Hall-resistivity anomalies are also observed in our sample, yet they show little correlation with the magnetic or metamagnetic transitions and are therefore clearly distinct from those in magnetic compounds hosting chiral spin textures. Most importantly, additional Lorentz transmission electron microscopy measurements rule out the existence of chiral spin textures in this ferrimagnet. Therefore, instead of a nontrivial origin, we attribute the Hall-resistivity anomalies to the combined effect of multiple anomalous Hall channels resulting from sample inhomogeneity. Our work shows that the difficulties of identifying chiral spin textures through transport measurements also apply to bulk systems, prompting some existing results to be revisited.

</details>


### [101] [Anomalous Hall effect and rich magnetic phase diagram of Mn$_{100-x}$Rh$_{x}$ epitaxial films](https://arxiv.org/abs/2512.10291)
*Cong Wang,Zheng Li,Jing Meng,Hui Zhang,Haoyu Lin,Jiyuan Li,Kun Zheng,Yang Xu,Tian Shang,Qingfeng Zhan*

Main category: cond-mat.str-el

TL;DR: 通过磁控溅射技术在MgO衬底上生长Mn-Rh薄膜，研究Rh含量对磁相变和反常霍尔效应的影响，发现磁性与电子能带拓扑结构之间的强关联性。


<details>
  <summary>Details</summary>
Motivation: 研究Mn-Rh薄膜中Rh含量对磁相变的影响，探索磁性与电子能带拓扑结构之间的关联，为反铁磁自旋电子学应用提供材料基础。

Method: 采用磁控溅射技术在MgO衬底上外延生长Mn100-xRhx薄膜，通过磁化强度、纵向电阻率和横向霍尔电阻率的系统测量，构建磁相图并分析反常霍尔效应。

Result: 建立了Mn-Rh薄膜的磁相图：x<40时为铁磁相变（TC≈330-350K）；40≤x≤45时存在铁磁-反铁磁相变（TC≈200K，TN≈120K）；x>45时只有反铁磁相变（TN≈150K）。所有薄膜在磁有序态均表现出明显的反常霍尔效应，且与磁性性质强相关。

Conclusion: Mn-Rh薄膜的磁性与电子能带拓扑结构存在强关联，这种关联在x=35时最为明显，表明该材料在反铁磁自旋电子学中具有重要应用潜力。

Abstract: A series of Mn$_{100-x}$Rh$_x$ ($20 \le x \le 50$) thin films were epitaxially grown on the MgO substrate using magnetron sputtering technique, and were systematically investigated by magnetization, longitudinal electrical resistivity, and transverse Hall resistivity. After optimizing the growth conditions, phase-pure Mn$_{100-x}$Rh$_x$ films with a cubic CsCl-type structure were obtained, and their magnetic phase diagram was built. The manipulation of Rh content leads to a rich magnetic phase diagram, where three different regimes can be identified: for $x < 40$, Mn$_{100-x}$Rh$_x$ films undergo a ferromagnetic (FM) transition below $T_\mathrm{C} \approx$ 330-350 K; for $40 \le x \le 45$, in addition to the FM transition at $T_\mathrm{C} \approx$ 200 K, Mn$_{100-x}$Rh$_x$ films undergo a FM-to-antiferromagnetic (AFM) transition at $T_\mathrm{N} \approx$ 120 K; finally for $x > 45$, only one AFM transition at $T_\mathrm{N} \approx$ 150 K can be tracked. All the Mn$_{100-x}$Rh$_x$ films exhibit distinct anomalous Hall effect in their magnetically ordered state, which is most likely due to the intrinsic Berry-curvature mechanism. In addition, all the anomalous Hall transport properties, including the resistivity, conductivity, and angle exhibit a strong correlation with the magnetic properties of Mn$_{100-x}$Rh$_x$ films, which become most evident for $x$ = 35. Our systematic investigations suggest a strong correlation between magnetic properties and electronic band topology in Mn$_{100-x}$Rh$_x$ films, highlighting their great potential for AFM spintronics.

</details>


### [102] [Electronic structure, orbital-dependent renormalizations, and magnetic correlations in double-layer La$_3$Ni$_2$O$_7$ under doping tuning](https://arxiv.org/abs/2512.10527)
*I. V. Leonov*

Main category: cond-mat.str-el

TL;DR: 该研究使用DFT+DMFT方法分析了压力下双层镍酸盐超导体La₃Ni₂O₇的电子结构，发现轨道依赖的准粒子重整化、非单调掺杂依赖的电子关联增强，以及可能的自旋/电荷密度波条纹形成。


<details>
  <summary>Details</summary>
Motivation: 研究双层镍酸盐超导体La₃Ni₂O₇在压力下的正常态电子结构，探索电子关联效应和掺杂对材料性质的影响，特别是轨道依赖的电子关联行为及其与超导性的潜在联系。

Method: 采用密度泛函理论（DFT）结合动力学平均场理论（DMFT）的第一性原理计算方法，研究La₃Ni₂O₇在不同掺杂条件下的电子结构、准粒子重整化、静态磁化率等物理性质。

Result: 1. 观察到Ni x²-y²和3z²-r²轨道显著的轨道依赖准粒子重整化；2. 3z²-r²态表现出非相干性（坏金属行为）；3. 有效质量比m*/m随掺杂呈非单调变化，电子掺杂x~0.2时Ni x²-y²轨道重整化增强约20%；4. 掺杂x~-0.3和0.2时发生Lifshitz转变，进入自掺杂区域；5. 静态磁化率分析表明可能存在自旋和电荷密度波条纹；6. 电子掺杂显著增强了面内自旋和电荷涨落。

Conclusion: La₃Ni₂O₇表现出强烈的轨道依赖电子关联效应，掺杂可显著调控其电子结构和磁性质。研究结果与双层Hubbard模型相似，表明当其中一个电子带接近Lifshitz转变时可能促进超导性，为理解镍酸盐超导机制提供了重要线索。

Abstract: Using the DFT+dynamical mean-field theory approach we study the effects of electronic correlations and doping on the normal state electronic structure of the double-layer nickelate superconductor La$_3$Ni$_2$O$_7$ under pressure. In agreement with experiments, we obtain significant orbital-dependent quasiparticle renormalizations of the Ni $x^2-y^2$ and $3z^2-r^2$ bands, accompanied by incoherence (bad metal behavior) of the $3z^2-r^2$ states, caused by the proximity of the Ni $3d$ states to orbital-dependent localization. Our results demonstrate a sensitive, non-monotonic dependence of $m^*/m$ on doping, with a remarkable, by about 20\%, increase for the Ni $x^2-y^2$ orbitals upon electron doping $x \sim 0.2$ (per Ni ion), implying a significant enhancement of orbital-dependent correlations with oxygen deficiency in LNO. We observe a reconstruction of the low-energy electronic structure of LNO upon doping above $x\sim -0.3$ and 0.2. It is associated with the Lifshitz transition, with a crossover to a self-doping regime characterized by partial occupation of the La $5d$ bands (upon an electron doping $x>0.2$). Our analysis of the static magnetic susceptibility $χ({\bf q})$ obtained within DFT+DMFT suggests the possible formation of the spin and charge (or bond) density wave stripes, implying strong spin and charge correlations in LNO. We show that this behavor is associated with suppression of the Néel $G$-type antiferromagnetic ordering of the Ni$^{2+}$ ions upon hole doping. Interestingly, upon a moderate electron doping of the Ni$^{2.5+}$ ions (e.g., with oxygen deficiency), we find a significant enhancement of the strength of in-plane spin and charge fluctuations. We note a close resembles of our results to those for the bilayer Hubbard model, which shows the boosting of superconductivity as one of the two electron bands approaches the Lifshitz transition (e.g., upon doping).

</details>


### [103] [Binding of holes and competing spin-charge order in simple and extended Hubbard model on cylindrical lattice: An exact diagonalization study](https://arxiv.org/abs/2512.10577)
*Md Fahad Equbal,M. A. H. Ahsan*

Main category: cond-mat.str-el

TL;DR: 通过精确对角化研究简单和扩展哈伯德模型中空穴束缚与自旋-电荷竞争序的涌现，发现非局域库仑相互作用V的符号和强度决定了不同的束缚机制：相分离或关联介导配对。


<details>
  <summary>Details</summary>
Motivation: 研究非局域库仑相互作用如何重塑关联电子系统中空穴束缚和集体序的图景，探索简单哈伯德模型和扩展哈伯德模型中空穴配对机制与竞争序的微观起源。

Method: 在3x4圆柱晶格上使用精确对角化方法，研究简单哈伯德模型（V=0）和扩展哈伯德模型（包含最近邻相互作用V）。通过实空间自旋和电荷关联分析，揭示不同相互作用参数下的微观束缚机制。

Result: 简单哈伯德模型（V=0）在中等排斥U下发现由磁关联介导的弱束缚空穴配对，无相分离证据。引入V后：吸引V驱动多空穴团簇化和相分离，伴随局域磁淬灭；排斥V稳定电荷密度波序，与束缚空穴对共存于调制磁背景中。强耦合（U=10）下竞争加剧，吸引V克服在位排斥形成磁淬灭团簇，排斥V产生约束配对的稳健CDW序。

Conclusion: 非局域库仑相互作用V的符号和强度决定了空穴束缚的两种不同机制：相分离或关联介导配对。研究结果为理解关联电子系统中空穴束缚和集体序的竞争提供了全面图景，揭示了V在调控相行为中的关键作用。

Abstract: We investigate the binding of holes and the emergence of competing spin-charge order in the simple and extended Hubbard model using exact diagonalization on the 3x4 cylindrical lattice. For the simple Hubbard model (V=0), we find weakly bound hole pairing mediated by magnetic correlations at intermediate repulsive U, without any evidence of phase separation. Introducing nearest-neighbor interaction V reveals a rich phase diagram: attractive V drives multi-hole clustering and phase separation with localized magnetic quenching, while repulsive V stabilizes charge-density-wave (CDW) order that coexists with bound hole pairs within a modulated magnetic background. At strong coupling (U=10), the competition sharpens, with attractive V overcoming on-site repulsion to form magnetically quenched clusters and repulsive V producing robust CDW order that constrains pairing. Real-space analysis of spin and charge correlations provides microscopic evidence of distinct binding mechanisms -- phase separation versus correlation-mediated pairing -- depending on the sign and strength of intersite interaction V . Our results establish a comprehensive picture of how nonlocal Coulomb interactions reshape the landscape of hole-binding and collective order in correlated electron systems.

</details>


### [104] [Magnetic anisotropy and dipolar interactions in the frustrated triangular-lattice magnet NaGdS_2](https://arxiv.org/abs/2512.10714)
*J. Grumbach,E. Häußler,S. Luther,J. Sichelschmidt,K. M. Ranjith,T. Herrmannsdörfer,M. Rotter,S. Granovsky,H. Kühne,M. Uhlarz,J. Wosnitza,H. -H. Klauß,M. Baenitz,T. Doert,M. Doerr*

Main category: cond-mat.str-el

TL;DR: NaGdS₂是一种三角晶格磁体，具有S=7/2的自旋Gd³⁺离子，表现出弱反铁磁交换（J_H/k_B≈52mK），在最低温度下未观察到长程磁有序，但在180mK以下存在短程磁有序迹象，表明海森堡型和偶极交换的竞争抑制了磁有序。


<details>
  <summary>Details</summary>
Motivation: 研究NaGdS₂这种三角晶格磁体的磁性质，特别关注由于Gd³⁺离子的大磁矩导致的偶极耦合效应，以及与相关化合物NaYbS₂的对比，探索海森堡型和偶极交换相互作用之间的竞争如何影响磁有序。

Method: 结合体测量技术（磁化、比热、交流磁化率、热膨胀、磁致伸缩）和局部方法（²³Na核磁共振、电子自旋共振），以及McPhase模拟，对多晶和单晶NaGdS₂样品进行综合分析。

Result: NaGdS₂具有弱反铁磁交换（J_H/k_B≈52mK），在最低温度下未发现长程磁有序的证据，但在180mK以下观察到短程磁有序迹象（交流磁化率和热膨胀中）。ESR和²³Na NMR测量显示短程铁磁关联的形成，表明海森堡型和偶极交换之间的竞争抑制了磁有序。

Conclusion: NaGdS₂是一个罕见的磁系统，其中磁有序被海森堡型和偶极相互作用的竞争所抑制。由于Gd³⁺离子的大磁矩，偶极耦合在NaGdS₂中具有强烈影响，这与相关的NaYbS₂形成对比，为理解三角晶格磁体中交换相互作用的竞争提供了重要见解。

Abstract: In this comprehensive study, we present results of bulk measurements (magnetization, specific heat, ac susceptibility, thermal expansion, and magnetostriction) combined with local methods such as nuclear magnetic resonance (^23Na NMR) and electron spin resonance (ESR) and simulations (McPhase) on polycrystalline and single-crystalline NaGdS_2 samples. The rare-earth delafossite NaGdS_2 is a triangular-lattice magnet with S = 7/2 spin-only Gd^3+ moments with suppressed single-ion anisotropy. In our study, we estimate that NaGdS_2 has a weak antiferromagnetic exchange (J_H/k_B is about 52mK) and signs of long-range magnetic order are absent down to lowest temperature. However, indications of short range magnetic order are found below 180 mK in the ac susceptibility and thermal expansion. Our results indicate an interplay of Heisenberg-type and dipolar exchange. Due to the large moment of the Gd^3+ ions, one expects a strong impact of the dipolar coupling in NaGdS_2, in contrast to the related NaYbS_2. ESR and ^23Na NMR measurements, indeed, indicate the formation of short-range ferromagnetic correlations. NaGdS_2 appears to be a rare system, in which magnetic order is suppressed by a competition between Heisenberg and dipolar interactions.

</details>


### [105] [Phase structure of the one-dimensional $\mathbb{Z}_2$ lattice gauge theory with second nearest-neighbor interactions](https://arxiv.org/abs/2512.10755)
*Yeimer Zambrano,Aleksey Alekseev,Konrad J. Kapcia,Krzysztof Cichy,Agnieszka Cichy*

Main category: cond-mat.str-el

TL;DR: 研究一维Z2晶格规范理论模型中包含次近邻相互作用的基态相图，发现次近邻排斥作用导致丰富的相变行为，包括从Luttinger液体直接到电荷有序绝缘体的转变，以及通过中间Luttinger液体区域从Mott绝缘体到电荷有序绝缘体的转变。


<details>
  <summary>Details</summary>
Motivation: 扩展先前对一维Z2晶格规范理论模型的研究，通过引入次近邻相互作用来探索更丰富的相图行为，研究规范场、禁闭和扩展相互作用之间的相互作用。

Method: 使用矩阵乘积态技术和密度矩阵重整化群方法，计算电荷能隙、静态结构因子和配对-配对关联函数，分析不同相互作用强度和场参数下的系统行为。

Result: 次近邻排斥作用增强时：对于小V1，观察到从Luttinger液体相直接转变到电荷有序绝缘体相；对于大V1，观察到从Mott绝缘体相经过中间Luttinger液体区域最终到达电荷有序绝缘体相。次近邻相互作用增强电荷有序并抑制配对相干性。

Conclusion: 次近邻相互作用显著改变了一维Z2晶格规范理论模型的相结构，揭示了规范场、禁闭和扩展相互作用之间的复杂相互作用，扩展了该模型系统的相图理解。

Abstract: We investigate the ground-state phase diagram of a one-dimensional $\mathbb{Z}_2$ lattice gauge theory (LGT) model with hard-core bosons at half-filling, extending previous studies by including second nearest-neighbor (2NN) interactions. Using matrix product state techniques within the density matrix renormalization group, we compute charge gap, static structure factor, and pair-pair correlation functions for various interaction strengths and field parameters. We analyze two representative neatest-neighbor interaction strengths ($V_1$) that correspond to the Luttinger liquid (LL) and Mott insulator (MI) phases in the absence of the 2NN interactions. We introduce the 2NN coupling $V_2$ and investigate its impact on the system. Our results reveal very rich behavior. As the 2NN repulsion increases, in the case of small $V_1$, we observe a direct transition from the LL phase to a charge-ordered insulator (COI) phase, whereas for large $V_1$, we observe a transition from the MI phase (previously found with only $V_1$ included), going through an intermediate LL region, and finally reaching the COI regime. Additionally, the inclusion of 2NN interactions enhances charge order and suppresses pair coherence, evidenced by sharp peaks in the structure factor and rapid decay in pair-pair correlators. Our work extends the well-studied phase structure of 1D $\mathbb{Z}_2$ LGT models and demonstrates the interplay between gauge fields, confinement, and extended interactions.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [106] [Quantum Monte Carlo in Classical Phase Space with the Wigner-Kirkwood Commutation Function. Results for the Saturation Liquid Density of $^4$He](https://arxiv.org/abs/2512.09948)
*Phil Attard*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种适用于复杂相空间权重的Metropolis Monte Carlo算法，应用于量子统计力学，通过Lennard-Jones氦-4在λ转变附近的模拟验证了算法有效性。


<details>
  <summary>Details</summary>
Motivation: 量子统计力学中处理复杂相空间权重（特别是涉及虚部的情况）需要有效的数值方法，传统Metropolis算法无法直接处理复数权重问题。

Method: 开发了一种适用于复数相空间权重的Metropolis Monte Carlo算法，使用Lennard-Jones势的氦-4系统进行模拟，并扩展到Wigner-Kirkwood交换函数的三阶展开。

Result: 模拟得到的饱和液体密度与实验测量值相符，验证了该算法在量子统计力学系统中的有效性。

Conclusion: 提出的Metropolis Monte Carlo算法能够有效处理复杂相空间权重问题，为量子统计力学系统的数值模拟提供了实用工具。

Abstract: A Metropolis Monte Carlo algorithm is given for the case of a complex phase space weight, which applies generally in quantum statistical mechanics. Computer simulations using Lennard-Jones $^4$He near the $λ$-transition, including an expansion to third order of the Wigner-Kirkwood commutation function, give a saturation liquid density in agreement with measured values.

</details>


### [107] [Statistical Field Theory of Interacting Nambu Dynamics](https://arxiv.org/abs/2512.09965)
*Tamiaki Yoneya*

Main category: cond-mat.stat-mech

TL;DR: 该论文为经典南布动力学构建了统计场论框架，解决了相互作用系统扩展问题，建立了广义相空间上的场论形式，并展示了多温度平衡态的动态演化。


<details>
  <summary>Details</summary>
Motivation: 南布动力学的一个未解问题是：如何在保持多个哈密顿量平等支配时间演化的广义正则结构的前提下，将其扩展到相互作用系统。本文旨在从经典统计动力学的角度解决这一问题。

Method: 采用量子场论方法，在南布广义相空间上建立算子形式化的场论框架，构建概率解释，并基于此框架提出多体南布系统中自相互作用的简单模型。

Result: 展示了从特定初始非平衡态出发，通过连续马尔可夫过程，系统动态达到由多个温度表征的广义微正则系综和广义正则系综作为平衡态。发现了与标准哈密顿动力学相比的新特征，包括非平衡态和平衡态动力学的对称性、广义KMS条件以及温度的"相对"性质。

Conclusion: 成功为经典南布动力学建立了统计场论框架，解决了相互作用系统扩展问题，揭示了多温度平衡态的动态演化规律，为南布动力学在统计力学中的应用提供了理论基础。

Abstract: We develop a statistical field theory for classical Nambu dynamics by employing partially the method of quantum field theory. One of unsolved problems in Nambu dynamics has been to extend it to interacting systems without violating a generalized canonical structure associated with the presence of multiple Hamiltonians, which together govern the dynamics of time evolution with an equal footing. In the present paper, we propose to include interactions from the standpoint of classical statistical dynamics by formulating it as a field theory on Nambu's generalized phase space in an operator formalism. We first construct a general framework for such a field theory and its probabilistic interpretation. Then, on the basis of this new framework, we give a simple model of self-interaction in a many-body Nambu system treated as a closed dynamical system satisfying the H-theorem. It is shown that a generalized micro-canonical ensemble and a generalized canonical ensemble characterized by many temperatures are reached dynamically as equilibrium states, starting with certain classes of initial non-equilibrium states via continuous Markov processes. Compared with the usual classical statistical mechanics on the basis of standard Hamiltonian dynamics, some important new features associated with Nambu dynamics will emerge, with respect to the symmetries underlying dynamics of the non-equilibrium as well as the equilibrium states and also to some conceptual properties, such as a formulation of a generalized KMS-like condition characterizing the generalized canonical equilibrium states and a `relative' nature of the temperatures.

</details>


### [108] [Universal relaxation speedup in open quantum systems through transient conditional and unconditional resetting](https://arxiv.org/abs/2512.10005)
*Parvinder Solanki,Igor Lesanovsky,Gabriele Perfetto*

Main category: cond-mat.stat-mech

TL;DR: 通过瞬态随机重置可以普遍加速量子多体系统的弛豫动力学，类似于Mpemba效应，显著甚至指数级加速达到稳态。


<details>
  <summary>Details</summary>
Motivation: 加速量子多体系统的弛豫动力学在量子计算和态制备等应用中具有重要意义，特别是在相变导致弛豫时间发散的情况下。

Method: 采用瞬态随机重置方法：在有限持续时间的初始时间间隔内，系统动力学被随机选择时间的重置中断，将系统带到指定状态。

Result: 在所有测试场景中（包括少体开放系统和具有一级相变的挑战性多体系统），观察到显著甚至指数级的加速达到稳态。

Conclusion: 瞬态随机重置提供了一种通用的加速弛豫动力学方法，其设计仅需目标状态的少数宏观性质知识，无需对初始状态进行精细调谐操作。

Abstract: Speeding up the relaxation dynamics of many-body quantum systems is important in a variety of contexts, including quantum computation and state preparation. We demonstrate that such acceleration can be universally achieved via transient stochastic resetting. This means that during an initial time interval of finite duration, the dynamics is interrupted by resets that take the system to a designated state at randomly selected times. We illustrate this idea for few-body open systems and also for a challenging many-body case, where a first-order phase transition leads to a divergence of relaxation time. In all scenarios, a significant and sometimes even exponential acceleration in reaching the stationary state is observed, similar to the so-called Mpemba effect. The universal nature of this speedup lies in the fact that the design of the resetting protocol only requires knowledge of a few macroscopic properties of the target state, such as the order parameter of the phase transition, while it does not necessitate any fine-tuned manipulation of the initial state.

</details>


### [109] [Bose one-component plasma in 2D: a Monte Carlo study](https://arxiv.org/abs/2512.10216)
*Massimo Boninsegni*

Main category: cond-mat.stat-mech

TL;DR: 通过量子蒙特卡洛模拟研究了二维带电玻色流体在低温下的性质，发现即使在接近维格纳结晶阈值时仍存在超流基态，且超流转变温度对密度依赖很弱。


<details>
  <summary>Details</summary>
Motivation: 研究二维带电玻色流体在低温下的性质，特别是探索在长程1/r相互作用下，系统在接近维格纳结晶阈值时的超流行为，并与之前忽略量子统计的理论研究进行对比。

Method: 采用量子蒙特卡洛模拟方法，利用修正周期库仑势形式处理长程相互作用，研究密度范围对应平均粒子间距1≤r_s≤80，模拟系统包含多达2304个粒子。

Result: 发现即使在r_s高达68时（略高于最新数值估计的维格纳结晶阈值r_W≈70），系统仍存在超流基态；未观察到热再入结晶相或亚稳态气泡；计算得到的超流转变温度对密度依赖非常弱。

Conclusion: 二维带电玻色流体在接近维格纳结晶阈值时仍保持超流性，这与之前忽略量子统计的理论预测不同，表明量子统计在决定系统相行为中起关键作用。

Abstract: The low-temperature properties of a 2D Bose fluid of charged particles interacting through a 1/r potential, moving in the presence of a uniform neutralizing background, is studied by Quantum Monte Carlo simulations. We make use of the Modified Periodic Coulomb potential formalism to account for the long-range character of the interaction, and explore a range of density corresponding to average interparticle separation $1 \le r_s\le 80$. We report numerical results based on simulations of system comprising up to 2304 particles. We find a superfluid ground state for $r_s$ as large as 68, i.e., slightly above the most recent numerical estimate of the Wigner crystallization threshold, which we estimate at $r_W \approx 70$. Furthermore, no thermally re-entrant crystalline phase nor any evidence of metastable bubbles is observed near the transition, in contrast with a previous theoretical study in which quantum statistics was neglected. The computed superfluid transition temperature depends remarkably weakly on density.

</details>


### [110] [Discreteness-induced spatial chaos versus fluctuation-induced spatial order in stochastic Turing pattern formation](https://arxiv.org/abs/2512.10500)
*Yusuke Yanagisawa,Shin-ichi Sasa*

Main category: cond-mat.stat-mech

TL;DR: 研究随机反应扩散模型中图灵模式形成，比较两种极限顺序对空间模式性质的影响


<details>
  <summary>Details</summary>
Motivation: 研究在空间离散性起关键作用的情况下（模式特征长度与晶格间距相当），随机反应扩散模型中图灵模式的形成机制，特别关注极限顺序对最终模式性质的影响

Method: 在N个晶格点上定义随机反应扩散模型，每个晶格点对应体积为Ω的反应容器。比较两种不同的极限过程：1）先取确定性极限Ω→∞，再取长时间极限t→∞；2）先取t→∞极限，再取适当的Ω→∞和N→∞极限

Result: 两种极限顺序导致定性不同的结果：第一种顺序下，对应的空间离散确定性方程的稳态解在N→∞时变得空间混沌；第二种顺序下，得到的模式是空间周期性的

Conclusion: 极限顺序对随机反应扩散模型中的图灵模式形成有重要影响，表明在空间离散性显著的情况下，极限顺序的选择决定了最终模式是空间混沌还是空间周期性

Abstract: We investigate Turing pattern formation in a stochastic reaction-diffusion model defined on $N$ lattice sites, where each lattice site is associated with a reaction vessel of volume $Ω$. We focus on a regime where spatial discreteness plays a crucial role, namely when the characteristic length of patterns is comparable to the lattice spacing. In this setting, we compare two different limiting procedures and show that they lead to qualitatively different outcomes. If we first take the deterministic limit $Ω\to \infty$ and then the long-time limit $t \to \infty$, the stationary solutions of the corresponding spatially discrete deterministic equations become spatially chaotic in the limit $N\to\infty$. In contrast, if we first take the limit $t \to \infty$ and then take an appropriate limit of $Ω\to \infty$ and $N\to\infty$, the resulting patterns are spatially periodic.

</details>


### [111] [Multiloop calculations with parametric integration in critical dynamics: the four-loop analytic study of model A of $φ^4$ theory](https://arxiv.org/abs/2512.10591)
*Loran Ts. Adzhemyan,Diana A. Davletbaeva,Daniil A. Evdokimov,Mikhail V. Kompaniets*

Main category: cond-mat.stat-mech

TL;DR: 在d=4-2ε维度下，对临界动力学模型A的指数z进行了四圈解析计算，这是临界动力学模型中首次达到如此高阶的微扰理论解析计算


<details>
  <summary>Details</summary>
Motivation: 临界动力学模型的高阶微扰理论计算一直具有挑战性，特别是在解析计算方面。以往的研究通常限于低阶或数值计算，需要开发新方法来处理高阶计算中的复杂性

Method: 采用现代参数积分与超对数方法，详细讨论了该方法在临界动力学应用中的特殊性，特别是处理四圈图中出现的线性不可约图问题（相比之下，静态理论中线性不可约图首次出现在六圈）

Result: 成功完成了模型A临界动力学指数z的四圈解析计算，这是临界动力学领域首次达到如此高阶的解析计算结果

Conclusion: 该方法为临界动力学的高阶微扰理论计算提供了有效工具，揭示了临界动力学与静态理论在计算复杂性上的重要差异，特别是线性不可约图出现阶数的不同

Abstract: We perform an analytical four loop calculation of exponent $z$ in model A of critical dynamics in $d=4-2\varepsilon$ dimensions. This is the first time such a large order of perturbation theory has been calculated analytically for models of critical dynamics. To do this, we apply the modern method of parametrical integration with hyperlogaritms. We discuss in detail peculiarities of application of this method to critical dynamics, e.g. the problem of linear-irreducible diagrams already present in four loop (contrary to statics where the first linear-irreducible diagram appears in six loop).

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [112] [Detailed balance in large language model-driven agents](https://arxiv.org/abs/2512.10047)
*Zhuo-Yang Song,Qing-Hong Cao,Ming-xing Luo,Hua Xing Zhu*

Main category: cs.LG

TL;DR: 该论文发现大语言模型驱动的智能体在状态转移中存在详细平衡，表明LLM生成可能不是通过学习规则集和策略，而是隐式学习了一类潜在函数，这构成了LLM生成动力学的宏观物理定律。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的智能体在解决复杂问题方面取得了经验性成功，但缺乏理解其宏观动态的理论框架。需要从工程实践上升到可预测、可量化的科学理论。

Method: 基于最小作用量原理的方法，通过实验测量LLM生成状态之间的转移概率，统计发现LLM生成转移中的详细平衡。

Result: 发现LLM生成转移中存在详细平衡，表明LLM生成可能通过隐式学习潜在函数实现，这一宏观物理定律不依赖于特定模型细节，是首个发现的LLM生成动力学宏观规律。

Conclusion: 该研究试图建立复杂AI系统的宏观动力学理论，将AI智能体研究从工程实践集合提升为基于有效测量的科学，这些测量是可预测和可量化的。

Abstract: Large language model (LLM)-driven agents are emerging as a powerful new paradigm for solving complex problems. Despite the empirical success of these practices, a theoretical framework to understand and unify their macroscopic dynamics remains lacking. This Letter proposes a method based on the least action principle to estimate the underlying generative directionality of LLMs embedded within agents. By experimentally measuring the transition probabilities between LLM-generated states, we statistically discover a detailed balance in LLM-generated transitions, indicating that LLM generation may not be achieved by generally learning rule sets and strategies, but rather by implicitly learning a class of underlying potential functions that may transcend different LLM architectures and prompt templates. To our knowledge, this is the first discovery of a macroscopic physical law in LLM generative dynamics that does not depend on specific model details. This work is an attempt to establish a macroscopic dynamics theory of complex AI systems, aiming to elevate the study of AI agents from a collection of engineering practices to a science built on effective measurements that are predictable and quantifiable.

</details>


### [113] [BAMBO: Construct Ability and Efficiency LLM Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization](https://arxiv.org/abs/2512.09972)
*Kesheng Chen,Wenjian Luo,Zhenqian Zhu,Yamin Hu,Yiya Xi*

Main category: cs.LG

TL;DR: BAMBO是一个自动构建LLM帕累托集的贝叶斯自适应多目标块级优化框架，通过混合最优块划分策略解决维度灾难问题，实现能力-效率权衡的敏捷模型选择。


<details>
  <summary>Details</summary>
Motivation: 现有LLM合并技术无法有效构建帕累托集：粗粒度的模型级方法只能得到稀疏的次优解，而细粒度的层级方法面临维度灾难，搜索空间计算不可行。

Method: 提出BAMBO框架，采用混合最优块划分策略，将其建模为一维聚类问题，使用动态规划平衡块内同质性和块间信息分布，在进化循环中通过qEHVI采集函数驱动自动化搜索。

Result: 实验表明BAMBO比基线方法发现了更优越、更全面的帕累托前沿，能够根据不同的操作约束实现敏捷的模型选择。

Conclusion: BAMBO通过创新的块级优化策略有效解决了LLM能力-效率权衡中的帕累托集构建问题，为实际应用中的模型选择提供了灵活高效的解决方案。

Abstract: Constructing a Pareto set is pivotal for navigating the capability-efficiency trade-offs in Large Language Models (LLMs); however, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the "curse of dimensionality," rendering the search space computationally intractable. To resolve this dichotomy, we propose BAMBO (Bayesian Adaptive Multi-objective Block-wise Optimization), a novel framework that automatically constructs the LLM Pareto set. BAMBO renders the search tractable by introducing a Hybrid Optimal Block Partitioning strategy. Formulated as a 1D clustering problem, this strategy leverages a dynamic programming approach to optimally balance intra-block homogeneity and inter-block information distribution, thereby dramatically reducing dimensionality without sacrificing critical granularity. The entire process is automated within an evolutionary loop driven by the q-Expected Hypervolume Improvement (qEHVI) acquisition function. Experiments demonstrate that BAMBO discovers a superior and more comprehensive Pareto frontier than baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: https://github.com/xin8coder/BAMBO.

</details>


### [114] [Latent Action World Models for Control with Unlabeled Trajectories](https://arxiv.org/abs/2512.10016)
*Marvin Alles,Xingyuan Zhang,Patrick van der Smagt,Philip Becker-Ehmck*

Main category: cs.LG

TL;DR: 提出潜在动作世界模型，通过共享潜在动作表示同时利用动作标注和无动作数据，显著减少所需动作标注样本数量


<details>
  <summary>Details</summary>
Motivation: 人类学习结合直接交互和无动作经验（如视频），但标准世界模型依赖动作标注轨迹，在动作标签稀缺时效果受限。需要能同时利用动作标注和无动作数据的模型

Method: 引入潜在动作世界模型家族，学习共享潜在动作表示，将观测控制信号与被动观测推断的动作对齐，使单个动力学模型能在大规模无标签轨迹上训练，仅需少量动作标注样本

Result: 在DeepMind Control Suite上，该方法达到强劲性能，所需动作标注样本比纯动作标注基线少约一个数量级

Conclusion: 潜在动作使世界模型能同时利用被动和交互数据进行训练，提高学习效率，桥接了离线RL和无动作训练这两个传统分离的领域

Abstract: Inspired by how humans combine direct interaction with action-free experience (e.g., videos), we study world models that learn from heterogeneous data. Standard world models typically rely on action-conditioned trajectories, which limits effectiveness when action labels are scarce. We introduce a family of latent-action world models that jointly use action-conditioned and action-free data by learning a shared latent action representation. This latent space aligns observed control signals with actions inferred from passive observations, enabling a single dynamics model to train on large-scale unlabeled trajectories while requiring only a small set of action-labeled ones. We use the latent-action world model to learn a latent-action policy through offline reinforcement learning (RL), thereby bridging two traditionally separate domains: offline RL, which typically relies on action-conditioned data, and action-free training, which is rarely used with subsequent RL. On the DeepMind Control Suite, our approach achieves strong performance while using about an order of magnitude fewer action-labeled samples than purely action-conditioned baselines. These results show that latent actions enable training on both passive and interactive data, which makes world models learn more efficiently.

</details>


### [115] [Cluster-Dags as Powerful Background Knowledge For Causal Discovery](https://arxiv.org/abs/2512.10032)
*Jan Marco Ruiz de Vargas,Kirtan Padh,Niki Kilbertus*

Main category: cs.LG

TL;DR: 该研究提出利用Cluster-DAGs作为先验知识框架来预热因果发现，开发了Cluster-PC和Cluster-FCI算法，在模拟数据上表现优于无先验知识的基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前因果发现方法在处理高维数据和复杂依赖关系时面临挑战，而融入系统先验知识可以辅助因果发现。现有基于分层背景知识的方法灵活性有限，需要更灵活的先验知识框架。

Method: 提出使用Cluster-DAGs作为先验知识框架来预热因果发现，并基于此开发了两个改进的基于约束的算法：Cluster-PC（用于完全观测设置）和Cluster-FCI（用于部分观测设置）。

Result: 在模拟数据上的实证评估表明，Cluster-PC和Cluster-FCI算法在各自设置下都优于没有先验知识的基线方法。

Conclusion: Cluster-DAGs提供了比现有分层背景知识方法更大的灵活性，能够有效利用先验知识提升因果发现的性能，特别是在高维数据和复杂依赖关系场景下。

Abstract: Finding cause-effect relationships is of key importance in science. Causal discovery aims to recover a graph from data that succinctly describes these cause-effect relationships. However, current methods face several challenges, especially when dealing with high-dimensional data and complex dependencies. Incorporating prior knowledge about the system can aid causal discovery. In this work, we leverage Cluster-DAGs as a prior knowledge framework to warm-start causal discovery. We show that Cluster-DAGs offer greater flexibility than existing approaches based on tiered background knowledge and introduce two modified constraint-based algorithms, Cluster-PC and Cluster-FCI, for causal discovery in the fully and partially observed setting, respectively. Empirical evaluation on simulated data demonstrates that Cluster-PC and Cluster-FCI outperform their respective baselines without prior knowledge.

</details>


### [116] [Robust Gradient Descent via Heavy-Ball Momentum with Predictive Extrapolation](https://arxiv.org/abs/2512.10033)
*Sarwan Ali*

Main category: cs.LG

TL;DR: HB-SGE是一种结合重球动量和预测梯度外推的鲁棒一阶优化方法，在病态和非凸问题上比NAG和标准动量方法更稳定


<details>
  <summary>Details</summary>
Motivation: 像NAG这样的加速梯度方法在条件良好的问题上收敛更快，但在病态或非凸问题上由于动量积累过于激进而经常发散。需要一种既能保持加速效果又能在复杂地形中保持稳定的方法。

Method: 提出HB-SGE方法，结合重球动量和预测梯度外推。不同于传统动量方法积累历史梯度，HB-SGE使用局部泰勒近似来估计未来梯度方向，提供自适应加速同时保持稳定性。

Result: 在病态二次问题（条件数κ=50）上，HB-SGE在119次迭代内收敛，而SGD和NAG都发散。在非凸Rosenbrock函数上，HB-SGE在2,718次迭代内收敛，而经典动量方法在10步内就发散。HB-SGE在条件良好的问题上不如NAG快，但在各种地形上比SGD快，且只需要O(d)内存开销和与标准动量相同的超参数。

Conclusion: HB-SGE为病态和非凸优化问题提供了一个鲁棒的替代方案，在保持加速效果的同时避免了传统动量方法的发散问题，具有实际应用价值。

Abstract: Accelerated gradient methods like Nesterov's Accelerated Gradient (NAG) achieve faster convergence on well-conditioned problems but often diverge on ill-conditioned or non-convex landscapes due to aggressive momentum accumulation. We propose Heavy-Ball Synthetic Gradient Extrapolation (HB-SGE), a robust first-order method that combines heavy-ball momentum with predictive gradient extrapolation. Unlike classical momentum methods that accumulate historical gradients, HB-SGE estimates future gradient directions using local Taylor approximations, providing adaptive acceleration while maintaining stability. We prove convergence guarantees for strongly convex functions and demonstrate empirically that HB-SGE prevents divergence on problems where NAG and standard momentum fail. On ill-conditioned quadratics (condition number $κ=50$), HB-SGE converges in 119 iterations while both SGD and NAG diverge. On the non-convex Rosenbrock function, HB-SGE achieves convergence in 2,718 iterations where classical momentum methods diverge within 10 steps. While NAG remains faster on well-conditioned problems, HB-SGE provides a robust alternative with speedup over SGD across diverse landscapes, requiring only $O(d)$ memory overhead and the same hyperparameters as standard momentum.

</details>


### [117] [Intelligently Weighting Multiple Reference Models for Direct Preference Optimization of LLMs](https://arxiv.org/abs/2512.10040)
*Skyler Wu,Aymen Echarghaoui*

Main category: cs.LG

TL;DR: 该论文提出四种新的参考模型权重设置策略来改进多参考偏好优化方法，但实验发现单参考DPO方法通常优于多参考方法


<details>
  <summary>Details</summary>
Motivation: 当前多参考偏好优化方法中参考权重的设置缺乏统计依据且随意，导致性能不稳定，需要更系统的方法来利用多个参考模型的集体优势

Method: 提出了四种新的权重设置策略：两种离线方法利用验证集信号；一种在线方法使用滑动窗口估计器减少过拟合；一种在线方法将参考权重设置视为K臂老虎机问题并通过Thompson采样解决

Result: 实验使用Qwen2.5-0.5B作为策略模型和7个参考模型，所有4种新策略在UltraFeedback和SafeRLHF数据集上的偏好准确率均优于现有MRPO权重方法。但更令人深思的是，使用7个参考中任意6个的单参考DPO方法持续优于所有测试的多参考方法

Conclusion: 虽然提出的新权重策略改进了多参考偏好优化方法，但单参考DPO方法的持续优越性对多参考方法的实际应用价值提出了质疑

Abstract: Fine-tuning is integral for aligning large language models (LLMs) with human preferences. Multiple-Reference Preference Optimization (MRPO) builds on Direct Preference Optimization (DPO) by fine-tuning LLMs on preference datasets while regularizing the policy towards a mixture of reference models to leverage their collective desirable properties. However, current methods for setting the reference weights are ad-hoc and statistically unsound, leading to unreliable performance. To address this, we introduce four new weighting strategies: two offline methods that leverage held-out validation signal; one online method that uses a sliding-window estimator to reduce overfitting; and an online method that treats reference weighting as a $K$-armed bandit via Thompson Sampling. Experiments using Qwen2.5-0.5B as the policy model and seven reference models from the Llama, Mistral, Qwen, Yi, and Phi families (0.5B-14B each) show that all 4 of our strategies outperform the current MRPO weighting methods on UltraFeedback and SafeRLHF in preference accuracy. More thought-provokingly, however, we find that single-reference DPO, using any of 6 out of 7 references, consistently outperforms all tested multiple-reference approaches -- calling into question the practical appeal of multiple-reference approaches.

</details>


### [118] [Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition](https://arxiv.org/abs/2512.10043)
*João Lucas Luz Lima Sarcinelli,Diego Furtado Silva*

Main category: cs.LG

TL;DR: 提出一种用于葡萄牙语零样本命名实体识别的三阶段集成方法，通过组合多个本地运行的小型LLM，在缺乏标注数据的情况下提升NER性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在NLP任务中表现出色，但在命名实体识别（NER）方面表现不佳，特别是对于葡萄牙语等低资源语言。虽然开源权重LLM支持本地部署，但没有单一模型在所有任务上占优，因此需要集成方法。现有LLM集成主要关注文本生成或分类，NER领域研究不足。

Method: 提出一个新颖的三步集成流程：1）使用启发式方法选择最优模型组合；2）利用最小标注数据；3）组合多个本地运行的小型LLM进行零样本NER。该方法不需要微调，通过集成多个相似能力的LLM来提升性能。

Result: 在五个葡萄牙语NER数据集中，该方法在四个数据集上优于单个LLM。此外，在不同源数据集上获得的集成模型在跨数据集配置中通常优于单个LLM，可能消除对当前任务标注数据的需求。

Conclusion: 该工作通过有效组合多个小型LLM而不需要微调，推进了可扩展、低资源和零样本NER的发展。代码已开源，为资源受限环境下的NER任务提供了实用解决方案。

Abstract: Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at https://github.com/Joao-Luz/local-llm-ner-ensemble.

</details>


### [119] [DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting](https://arxiv.org/abs/2512.10051)
*Moulik Gupta,Achyut Mani Tripathi*

Main category: cs.LG

TL;DR: DB2-TransF是一种基于Transformer的新型时间序列预测架构，用可学习的Daubechies小波系数层替代自注意力机制，在保持预测精度的同时显著降低计算复杂度和内存使用。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型在时间序列预测中虽然能有效捕捉长期依赖关系，但其二次计算复杂度限制了在大规模高维场景下的可扩展性和适应性，需要更高效的架构。

Method: 提出DB2-TransF架构，用可学习的Daubechies小波系数层替代Transformer中的自注意力机制，该小波模块能有效捕捉多尺度的局部和全局模式，并增强多个时间序列间的相关性建模。

Result: 在13个标准预测基准测试中，DB2-TransF取得了与传统Transformer相当或更优的预测精度，同时显著减少了内存使用，证明了其作为可扩展和资源高效框架的有效性。

Conclusion: DB2-TransF通过小波系数层替代自注意力机制，在保持预测性能的同时解决了Transformer的计算复杂度问题，为高级时间序列预测提供了一个可扩展且资源高效的框架。

Abstract: Time series forecasting requires models that can efficiently capture complex temporal dependencies, especially in large-scale and high-dimensional settings. While Transformer-based architectures excel at modeling long-range dependencies, their quadratic computational complexity poses limitations on scalability and adaptability. To overcome these challenges, we introduce DB2-TransF, a novel Transformer-inspired architecture that replaces the self-attention mechanism with a learnable Daubechies wavelet coefficient layer. This wavelet-based module efficiently captures multi-scale local and global patterns and enhances the modeling of correlations across multiple time series for the time series forecasting task. Extensive experiments on 13 standard forecasting benchmarks demonstrate that DB2-TransF achieves comparable or superior predictive accuracy to conventional Transformers, while substantially reducing memory usage for the time series forecasting task. The obtained experimental results position DB2-TransF as a scalable and resource-efficient framework for advanced time series forecasting. Our code is available at https://github.com/SteadySurfdom/DB2-TransF

</details>


### [120] [Mitigating Exposure Bias in Risk-Aware Time Series Forecasting with Soft Tokens](https://arxiv.org/abs/2512.10056)
*Alireza Namazi,Amirreza Dolatpour Fathkouhi,Heman Shakeri*

Main category: cs.LG

TL;DR: SoTra方法通过传播连续概率分布来缓解暴露偏差，学习校准的、不确定性感知的轨迹，结合风险感知解码模块最小化临床风险，在血糖和血压预测中显著降低风险。


<details>
  <summary>Details</summary>
Motivation: 在糖尿病和血液动力学管理的预测控制中，不同操作区域具有不同的临床风险。标准模型使用教师强制训练时存在暴露偏差，导致闭环使用中的多步预测不稳定。

Method: 提出Soft-Token Trajectory Forecasting (SoTra)方法，传播连续概率分布（"soft tokens"）来缓解暴露偏差，学习校准的、不确定性感知的轨迹。结合风险感知解码模块最小化预期临床危害。

Result: 在血糖预测中，SoTra将基于区域的平均风险降低18%；在血压预测中，将有效临床风险降低约15%。

Conclusion: SoTra在安全关键的预测控制应用中表现出显著优势，支持其在临床环境中的使用。

Abstract: Autoregressive forecasting is central to predictive control in diabetes and hemodynamic management, where different operating zones carry different clinical risks. Standard models trained with teacher forcing suffer from exposure bias, yielding unstable multi-step forecasts for closed-loop use. We introduce Soft-Token Trajectory Forecasting (SoTra), which propagates continuous probability distributions (``soft tokens'') to mitigate exposure bias and learn calibrated, uncertainty-aware trajectories. A risk-aware decoding module then minimizes expected clinical harm. In glucose forecasting, SoTra reduces average zone-based risk by 18\%; in blood-pressure forecasting, it lowers effective clinical risk by approximately 15\%. These improvements support its use in safety-critical predictive control.

</details>


### [121] [MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis](https://arxiv.org/abs/2512.10098)
*Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta*

Main category: cs.LG

TL;DR: MedXAI是一个可解释的医学影像分类框架，通过整合深度学习模型与临床专家知识，提升泛化能力、减少罕见类别偏见，并提供可解释的诊断特征定位。


<details>
  <summary>Details</summary>
Motivation: 当前医学AI面临三大挑战：1）在领域偏移下诊断准确性不足；2）对罕见病理类别存在偏见；3）缺乏临床部署所需的透明度。深度学习模型在真实世界分布变化中表现不佳，且缺乏安全关键临床环境所需的可解释性。

Method: MedXAI是一个统一的专家知识驱动框架，将深度视觉模型与临床医生衍生的专家知识相结合。与依赖技术性后处理方法（如显著性图、LIME）不同，该框架通过定位相关诊断特征来提供人类可理解的解释。框架包含符号组件作为有效的临床先验和正则化器。

Result: 在十个多中心数据集上的实验显示：1）跨域泛化能力提升3%；2）罕见类别的F1分数提升10%；3）显著优于强深度学习基线。消融实验证实符号组件作为有效的临床先验和正则化器，提升了分布偏移下的鲁棒性。

Conclusion: MedXAI在提供临床对齐解释的同时，实现了优越的域内和跨域性能，特别是在多模态医学AI中的罕见疾病诊断方面。该框架在保持临床可解释性的同时，显著提升了医学影像分类的准确性和鲁棒性。

Abstract: Accurate and interpretable image-based diagnosis remains a fundamental challenge in medical AI, particularly un- der domain shifts and rare-class conditions. Deep learning mod- els often struggle with real-world distribution changes, exhibit bias against infrequent pathologies, and lack the transparency required for deployment in safety-critical clinical environments. We introduce MedXAI (An Explainable Framework for Med- ical Imaging Classification), a unified expert knowledge based framework that integrates deep vision models with clinician- derived expert knowledge to improve generalization, reduce rare- class bias, and provide human-understandable explanations by localizing the relevant diagnostic features rather than relying on technical post-hoc methods (e.g., Saliency Maps, LIME). We evaluate MedXAI across heterogeneous modalities on two challenging tasks: (i) Seizure Onset Zone localization from resting-state fMRI, and (ii) Diabetic Retinopathy grading. Ex periments on ten multicenter datasets show consistent gains, including a 3% improvement in cross-domain generalization and a 10% improvmnet in F1 score of rare class, substantially outperforming strong deep learning baselines. Ablations confirm that the symbolic components act as effective clinical priors and regularizers, improving robustness under distribution shift. MedXAI delivers clinically aligned explanations while achieving superior in-domain and cross-domain performance, particularly for rare diseases in multimodal medical AI.

</details>


### [122] [CHyLL: Learning Continuous Neural Representations of Hybrid Systems](https://arxiv.org/abs/2512.10117)
*Sangli Teng,Hang Liu,Jingyu Song,Koushil Sreenath*

Main category: cs.LG

TL;DR: CHyLL提出了一种在潜在空间中学习混合系统连续神经表示的新方法，避免了轨迹分割、事件函数或模式切换，通过将状态空间重构为分段光滑商流形使流变得空间连续。


<details>
  <summary>Details</summary>
Motivation: 学习同时具有连续和离散时间动态的混合系统流具有挑战性。现有方法学习每个离散模式中的动态，但受到模式切换和流中不连续性的组合影响。

Method: CHyLL通过重置映射在守卫表面粘合状态空间，将状态空间重构为分段光滑商流形，使流变得空间连续。基于微分拓扑的嵌入定理，同时学习高维空间中的无奇点神经嵌入和其中的连续流。

Result: CHyLL能够准确预测混合系统的流，具有优越的准确性，并能识别混合系统的拓扑不变量。最后成功应用于随机最优控制问题。

Conclusion: CHyLL提供了一种无需轨迹分割、事件函数或模式切换的连续混合系统学习方法，通过将状态空间重构为商流形实现空间连续性，在预测准确性和拓扑分析方面表现优异。

Abstract: Learning the flows of hybrid systems that have both continuous and discrete time dynamics is challenging. The existing method learns the dynamics in each discrete mode, which suffers from the combination of mode switching and discontinuities in the flows. In this work, we propose CHyLL (Continuous Hybrid System Learning in Latent Space), which learns a continuous neural representation of a hybrid system without trajectory segmentation, event functions, or mode switching. The key insight of CHyLL is that the reset map glues the state space at the guard surface, reformulating the state space as a piecewise smooth quotient manifold where the flow becomes spatially continuous. Building upon these insights and the embedding theorems grounded in differential topology, CHyLL concurrently learns a singularity-free neural embedding in a higher-dimensional space and the continuous flow in it. We showcase that CHyLL can accurately predict the flow of hybrid systems with superior accuracy and identify the topological invariants of the hybrid systems. Finally, we apply CHyLL to the stochastic optimal control problem.

</details>


### [123] [Partitioning the Sample Space for a More Precise Shannon Entropy Estimation](https://arxiv.org/abs/2512.10133)
*Gabriel F. A. Bastos,Jugurta Montalvão*

Main category: cs.LG

TL;DR: 提出一种新的离散熵估计器，通过利用可分解性并结合未观测质量与未见过结果数量的估计，来补偿小数据集下的负偏差，在欠采样情况下优于经典方法。


<details>
  <summary>Details</summary>
Motivation: 从样本量可能小于可能结果数量的小数据集中可靠地估计香农熵是多个应用领域的关键问题，现有方法在小数据集下存在负偏差问题。

Method: 提出一种离散熵估计器，利用熵的可分解性，结合未观测质量（missing mass）和未见过结果数量的估计，来补偿由小样本引起的负偏差。

Result: 实验结果表明，在欠采样情况下，该方法优于一些经典估计器，并与一些成熟的先进估计器性能相当。

Conclusion: 该方法为小数据集下的熵估计提供了有效的解决方案，特别是在样本量小于可能结果数量的情况下表现出色。

Abstract: Reliable data-driven estimation of Shannon entropy from small data sets, where the number of examples is potentially smaller than the number of possible outcomes, is a critical matter in several applications. In this paper, we introduce a discrete entropy estimator, where we use the decomposability property in combination with estimations of the missing mass and the number of unseen outcomes to compensate for the negative bias induced by them. Experimental results show that the proposed method outperforms some classical estimators in undersampled regimes, and performs comparably with some well-established state-of-the-art estimators.

</details>


### [124] [Sequence-to-Image Transformation for Sequence Classification Using Rips Complex Construction and Chaos Game Representation](https://arxiv.org/abs/2512.10141)
*Sarwan Ali,Taslim Murad,Imdadullah Khan*

Main category: cs.LG

TL;DR: 该论文提出了一种将分子序列转换为图像的拓扑方法，结合混沌游戏表示和代数拓扑中的Rips复形构造，用于抗癌肽分类任务，在乳腺癌和肺癌数据集上分别达到86.8%和94.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统分子序列分类的特征工程方法存在稀疏性和计算复杂度问题，而深度学习模型在表格化生物数据上表现不佳。需要一种能够有效捕捉分子序列结构特征并适用于视觉深度学习架构的表示方法。

Method: 结合混沌游戏表示将序列元素映射到2D坐标，计算成对距离，构建Rips复形来捕捉局部结构和全局拓扑特征。该方法提供了表示唯一性、拓扑稳定性和信息保存的正式保证。

Result: 在抗癌肽数据集上的广泛实验表明，该方法优于基于向量的方法、序列语言模型和现有的基于图像的方法，在乳腺癌和肺癌数据集上分别达到86.8%和94.5%的准确率。

Conclusion: 拓扑表示保留了关键的序列信息，同时使基于视觉的深度学习架构能够有效地用于分子序列分析，为解决分子序列分类问题提供了新的有效途径。

Abstract: Traditional feature engineering approaches for molecular sequence classification suffer from sparsity issues and computational complexity, while deep learning models often underperform on tabular biological data. This paper introduces a novel topological approach that transforms molecular sequences into images by combining Chaos Game Representation (CGR) with Rips complex construction from algebraic topology. Our method maps sequence elements to 2D coordinates via CGR, computes pairwise distances, and constructs Rips complexes to capture both local structural and global topological features. We provide formal guarantees on representation uniqueness, topological stability, and information preservation. Extensive experiments on anticancer peptide datasets demonstrate superior performance over vector-based, sequence language models, and existing image-based methods, achieving 86.8\% and 94.5\% accuracy on breast and lung cancer datasets, respectively. The topological representation preserves critical sequence information while enabling effective utilization of vision-based deep learning architectures for molecular sequence analysis.

</details>


### [125] [Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences](https://arxiv.org/abs/2512.10147)
*Sarwan Ali,Taslim Murad*

Main category: cs.LG

TL;DR: 提出基于哈希的SARS-CoV-2刺突蛋白序列嵌入方法，用于高效的大规模病毒谱系分类，相比现有方法显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: COVID-19早期检测和特征分析对临床响应和公共卫生规划至关重要。现有方法存在局限性：系统发育树方法计算密集，难以扩展到数百万序列数据集；现有嵌入方法依赖序列比对或性能不佳、运行成本高，阻碍大规模分析

Method: 针对SARS-CoV-2刺突蛋白区域最流行谱系，引入可扩展的嵌入方法，利用哈希技术生成紧凑的低维序列表示，然后用这些嵌入训练多种机器学习模型进行监督谱系分类

Result: 与多种基线方法和最先进的生物序列嵌入方法相比，所提嵌入方法在效率上有显著提升：达到86.4%的分类准确率，同时将嵌入生成时间减少高达99.81%

Conclusion: 该方法作为快速、有效且可扩展的解决方案，在大规模病毒序列分析中具有巨大潜力

Abstract: Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\% classification accuracy while reducing embedding generation time by as much as 99.81\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis.

</details>


### [126] [CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation](https://arxiv.org/abs/2512.10178)
*Keito Inoshita,Xiaokang Zhou,Akira Kawai,Katsutoshi Yada*

Main category: cs.LG

TL;DR: CIEGAD是一个几何感知和领域对齐的数据增强框架，通过聚类条件、分层频率-几何分配以及插值和外推合成，系统性地补充分布内和分布外的语义未覆盖区域，改善长尾和多类分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 实际深度学习部署中，数据稀缺和标签分布不平衡导致真实世界数据分布中存在语义未覆盖区域，阻碍模型训练，引起类边界附近的误分类和边缘区域的不稳定行为。虽然大语言模型在数据增强方面有潜力，但尚未建立能够同时实现生成方向控制、领域对齐和质量控制的集成框架。

Method: CIEGAD框架包含：1) 通过聚类条件构建领域配置文件；2) 集成类别频率和几何指标的分层频率-几何分配机制；3) 插值和外推合成共存的方向控制；4) 几何约束过滤结合LLM-as-a-Judge机制的质量控制。

Result: 在多个分类任务上的实验表明，CIEGAD能有效扩展真实世界数据分布的边缘，同时保持生成数据与真实数据的高对齐性和语义多样性。特别是在长尾和多类分类任务中，CIEGAD持续提升F1分数和召回率，验证了分布一致性、多样性和质量的三重和谐。

Conclusion: CIEGAD作为一个实用导向的数据增强框架，能够补充代表性不足的区域，同时保持与真实世界数据的对齐，为解决数据稀缺和分布不平衡问题提供了有效的解决方案。

Abstract: In practical deep learning deployment, the scarcity of data and the imbalance of label distributions often lead to semantically uncovered regions within the real-world data distribution, hindering model training and causing misclassification near class boundaries as well as unstable behaviors in peripheral areas. Although recent large language models (LLMs) show promise for data augmentation, an integrated framework that simultaneously achieves directional control of generation, domain alignment, and quality control has not yet been fully established. To address these challenges, we propose a Cluster-conditioned Interpolative and Extrapolative framework for Geometry-Aware and Domain-aligned data augmentation (CIEGAD), which systematically complements both in-distribution and out-of-distribution semantically uncovered regions. CIEGAD constructs domain profiles through cluster conditioning, allocates generation with a hierarchical frequency-geometric allocation integrating class frequency and geometric indicators, and finely controls generation directions via the coexistence of interpolative and extrapolative synthesis. It further performs quality control through geometry-constrained filtering combined with an LLM-as-a-Judge mechanism. Experiments on multiple classification tasks demonstrate that CIEGAD effectively extends the periphery of real-world data distributions while maintaining high alignment between generated and real-world data as well as semantic diversity. In particular, for long-tailed and multi-class classification tasks, CIEGAD consistently improves F1 and recall, validating the triple harmony of distributional consistency, diversity, and quality. These results indicate that CIEGAD serves as a practically oriented data augmentation framework that complements underrepresented regions while preserving alignment with real-world data.

</details>


### [127] [MiniF2F-Dafny: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification](https://arxiv.org/abs/2512.10187)
*Mantas Baksys,Stefan Zetzsche,Olivier Bouissou*

Main category: cs.LG

TL;DR: 将数学推理基准miniF2F首次翻译到自动定理证明器Dafny，评估其自动化能力和LLM辅助证明效果


<details>
  <summary>Details</summary>
Motivation: 将数学推理基准从交互式定理证明器扩展到自动定理证明器，探索自动化证明与LLM辅助的结合潜力

Method: 将miniF2F基准翻译到Dafny，评估空证明成功率，测试12个现成LLM提供证明提示，采用迭代错误修正策略

Result: Dafny自动化验证测试集40.6%（99/244）和验证集44.7%（109/244）的空证明；最佳LLM通过迭代错误修正达到55.7% pass@4成功率

Conclusion: 展示了LLM提供高层次指导与自动化处理低层次细节的有效分工，为数学推理自动化提供了新方向

Abstract: We present miniF2F-Dafny, the first translation of the mathematical reasoning benchmark miniF2F to an automated theorem prover: Dafny. Previously, the benchmark existed only in interactive theorem provers (Lean, Isabelle, HOL Light, Metamath). We find that Dafny's automation verifies 99/244 (40.6%) of the test set and 109/244 (44.7%) of the validation set with empty proofs--requiring no manual proof steps. For problems where empty proofs fail, we evaluate 12 off-the-shelf LLMs on providing proof hints. The best model we test achieves 55.7% pass@4 success rate employing iterative error correction. These preliminary results highlight an effective division of labor: LLMs provide high-level guidance while automation handles low-level details. Our benchmark can be found on GitHub at http://github.com/dafny-lang/miniF2F .

</details>


### [128] [Federated Domain Generalization with Latent Space Inversion](https://arxiv.org/abs/2512.10224)
*Ragja Palakkadavath,Hung Le,Thanh Nguyen-Tang,Svetha Venkatesh,Sunil Gupta*

Main category: cs.LG

TL;DR: FedDG方法通过潜在空间反转和重要权重聚合策略，在保护隐私的同时提升联邦域泛化性能


<details>
  <summary>Details</summary>
Motivation: 现有联邦域泛化方法在提升全局模型泛化能力时，通过共享客户端数据统计信息而损害隐私保护。需要一种既能保护隐私又能提升泛化性能的新方法。

Method: 1. 潜在空间反转：在本地客户端训练中强制实施域不变性，增强隐私保护；2. 重要权重聚合策略：在模型聚合时优先考虑对本地模型预测有显著影响的参数，避免丢弃重要的本地适应。

Result: 实验表明，该方法在减少通信开销的同时，取得了优于现有最先进方法的结果。

Conclusion: 提出的潜在空间反转和重要权重聚合策略有效解决了联邦域泛化中的隐私保护和模型性能平衡问题，在非独立同分布客户端场景下表现优异。

Abstract: Federated domain generalization (FedDG) addresses distribution shifts among clients in a federated learning framework. FedDG methods aggregate the parameters of locally trained client models to form a global model that generalizes to unseen clients while preserving data privacy. While improving the generalization capability of the global model, many existing approaches in FedDG jeopardize privacy by sharing statistics of client data between themselves. Our solution addresses this problem by contributing new ways to perform local client training and model aggregation. To improve local client training, we enforce (domain) invariance across local models with the help of a novel technique, \textbf{latent space inversion}, which enables better client privacy. When clients are not \emph{i.i.d}, aggregating their local models may discard certain local adaptations. To overcome this, we propose an \textbf{important weight} aggregation strategy to prioritize parameters that significantly influence predictions of local models during aggregation. Our extensive experiments show that our approach achieves superior results over state-of-the-art methods with less communication overhead.

</details>


### [129] [Adaptive Information Routing for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.10229)
*Jun Seo,Hyeokjun Choe,Seohui Bae,Soyeon Park,Wonbin Ahn,Taeyoon Lim,Junhyuk Kang,Sangjun Han,Jaehoon Lee,Dongwan Kang,Minjae Kim,Sungdong Yoo,Soonyoung Lee*

Main category: cs.LG

TL;DR: AIR框架通过文本信息动态指导时间序列模型，显著提升多模态时间序列预测精度


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法仅依赖历史数据，在实际场景中信息有限导致预测不准确。多模态方法虽然引入文本数据，但现有方法将文本数据与时间序列数据同等对待作为可互换的辅助特征，未能充分利用文本信息指导时间序列建模。

Method: 提出自适应信息路由（AIR）框架，利用文本信息动态控制多元时间序列信息的组合方式和程度。同时开发文本精炼流水线，使用大语言模型将原始文本数据转换为适合多模态预测的形式，并建立基于此流水线的基准测试。

Result: 在原油价格和汇率等真实市场数据上的实验结果表明，AIR能够有效利用文本输入调节时间序列模型的行为，在各种时间序列预测任务中显著提高预测准确性。

Conclusion: AIR框架通过文本信息动态指导时间序列模型，为多模态时间序列预测提供了更有效的方法，显著提升了预测性能。

Abstract: Time series forecasting is a critical task for artificial intelligence with numerous real-world applications. Traditional approaches primarily rely on historical time series data to predict the future values. However, in practical scenarios, this is often insufficient for accurate predictions due to the limited information available. To address this challenge, multimodal time series forecasting methods which incorporate additional data modalities, mainly text data, alongside time series data have been explored. In this work, we introduce the Adaptive Information Routing (AIR) framework, a novel approach for multimodal time series forecasting. Unlike existing methods that treat text data on par with time series data as interchangeable auxiliary features for forecasting, AIR leverages text information to dynamically guide the time series model by controlling how and to what extent multivariate time series information should be combined. We also present a text-refinement pipeline that employs a large language model to convert raw text data into a form suitable for multimodal forecasting, and we introduce a benchmark that facilitates multimodal forecasting experiments based on this pipeline. Experiment results with the real world market data such as crude oil price and exchange rates demonstrate that AIR effectively modulates the behavior of the time series model using textual inputs, significantly enhancing forecasting accuracy in various time series forecasting tasks.

</details>


### [130] [R^2-HGP: A Double-Regularized Gaussian Process for Heterogeneous Transfer Learning](https://arxiv.org/abs/2512.10258)
*Duo Wang,Xinming Wang,Chao Wang,Xiaowei Yue,Jianguo Wu*

Main category: cs.LG

TL;DR: 本文提出了一种双重正则化异构高斯过程框架（R²-HGP），用于解决多源迁移学习中输入空间异构、忽略物理先验知识和负迁移等问题。


<details>
  <summary>Details</summary>
Motivation: 多输出高斯过程模型在多源迁移学习中面临三个主要挑战：1）源域和目标域输入空间异构导致直接知识迁移困难；2）忽略物理先验知识，导致映射不稳定；3）不适当的信息共享容易引发负迁移。传统模型无法统一解决这些问题。

Method: 提出R²-HGP框架：首先设计可训练的先验概率映射模型对齐异构输入域，将对齐后的输入作为隐变量；在此基础上构建多源迁移GP模型，并整合到条件变分自编码器框架中；引入物理知识作为正则化项确保对齐结果符合物理规律；在迁移GP模型中施加稀疏惩罚，自适应选择信息量最大的源输出并抑制负迁移。

Result: 通过大量仿真和真实工程案例验证，R²-HGP在多种评估指标上均优于现有最先进基准方法，表现出显著的有效性和优越性。

Conclusion: R²-HGP框架成功解决了多源迁移学习中的异构输入对齐、物理知识整合和负迁移抑制等关键问题，为复杂工程应用提供了有效的解决方案。

Abstract: Multi-output Gaussian process (MGP) models have attracted significant attention for their flexibility and uncertainty-quantification capabilities, and have been widely adopted in multi-source transfer learning scenarios due to their ability to capture inter-task correlations. However, they still face several challenges in transfer learning. First, the input spaces of the source and target domains are often heterogeneous, which makes direct knowledge transfer difficult. Second, potential prior knowledge and physical information are typically ignored during heterogeneous transfer, hampering the utilization of domain-specific insights and leading to unstable mappings. Third, inappropriate information sharing among target and sources can easily lead to negative transfer. Traditional models fail to address these issues in a unified way. To overcome these limitations, this paper proposes a Double-Regularized Heterogeneous Gaussian Process framework (R^2-HGP). Specifically, a trainable prior probability mapping model is first proposed to align the heterogeneous input domains. The resulting aligned inputs are treated as latent variables, upon which a multi-source transfer GP model is constructed and the entire structure is integrated into a novel conditional variational autoencoder (CVAE) based framework. Physical insights is further incorporated as a regularization term to ensure that the alignment results adhere to known physical knowledge. Next, within the multi-source transfer GP model, a sparsity penalty is imposed on the transfer coefficients, enabling the model to adaptively select the most informative source outputs and suppress negative transfer. Extensive simulations and real-world engineering case studies validate the effectiveness of our R^2-HGP, demonstrating consistent superiority over state-of-the-art benchmarks across diverse evaluation metrics.

</details>


### [131] [An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis](https://arxiv.org/abs/2512.10308)
*Vasiliki Stoumpou,Maciej Tysarowski,Talhat Azemi,Jawad Haider,Howard L. Haronian,Robert C. Hagberg,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 该研究开发了一个可解释的处方框架，通过预后匹配、反事实结果建模和最优策略树，为主动脉瓣狭窄患者提供个体化的SAVR或TAVR治疗建议，以最小化5年死亡率。


<details>
  <summary>Details</summary>
Motivation: 目前临床实践中，对于低至中危严重主动脉瓣狭窄患者，选择外科主动脉瓣置换术（SAVR）还是经导管主动脉瓣置换术（TAVR）存在较大变异性，主要受患者异质性和机构偏好影响。现有模型仅能预测术后风险，缺乏能够直接优化长期结果的可解释个体化治疗建议。

Method: 研究引入了一个可解释的处方框架，整合了预后匹配、反事实结果建模和最优策略树（OPT）。使用哈特福德医院和圣文森特医院的数据，通过预后匹配和样本加权模拟随机化，估计SAVR和TAVR两种治疗下的反事实死亡率。策略模型基于这些反事实预测进行训练，将患者划分为临床一致的亚组，并推荐估计风险较低的治疗方案。

Result: 如果应用OPT处方，反事实评估显示：在哈特福德医院，5年死亡率估计降低20.3%；在圣文森特医院，相对于实际临床处方降低13.8%。这表明该框架在不同机构的未见数据上具有良好的泛化能力。学习到的决策边界与实际临床结果和观察一致。

Conclusion: 该可解释处方框架首次为TAVR与SAVR选择提供了透明、数据驱动的推荐，在内部和外部队列中均改善了估计的长期结果，同时保持临床合理性，为结构性心脏病精准医学提供了更系统、循证的方法。

Abstract: Background. Treatment selection for low to intermediate risk patients with severe aortic stenosis between surgical (SAVR) and transcatheter (TAVR) aortic valve replacement remains variable in clinical practice, driven by patient heterogeneity and institutional preferences. While existing models predict postprocedural risk, there is a lack of interpretable, individualized treatment recommendations that directly optimize long-term outcomes.
  Methods. We introduce an interpretable prescriptive framework that integrates prognostic matching, counterfactual outcome modeling, and an Optimal Policy Tree (OPT) to recommend the treatment minimizing expected 5-year mortality. Using data from Hartford Hospital and St. Vincent's Hospital, we emulate randomization via prognostic matching and sample weighting and estimate counterfactual mortality under both SAVR and TAVR. The policy model, trained on these counterfactual predictions, partitions patients into clinically coherent subgroups and prescribes the treatment associated with lower estimated risk.
  Findings. If the OPT prescriptions are applied, counterfactual evaluation showed an estimated reduction in 5-year mortality of 20.3\% in Hartford and 13.8\% in St. Vincent's relative to real-life prescriptions, showing promising generalizability to unseen data from a different institution. The learned decision boundaries aligned with real-world outcomes and clinical observations.
  Interpretation. Our interpretable prescriptive framework is, to the best of our knowledge, the first to provide transparent, data-driven recommendations for TAVR versus SAVR that improve estimated long-term outcomes both in an internal and external cohort, while remaining clinically grounded and contributing toward a more systematic and evidence-based approach to precision medicine in structural heart disease.

</details>


### [132] [A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale](https://arxiv.org/abs/2512.10341)
*Vinoth Punniyamoorthy,Ashok Gadi Parthi,Mayilsamy Palanigounder,Ravi Kiran Kodali,Bikesh Kumar,Kabilan Kannan*

Main category: cs.LG

TL;DR: 提出一个云原生隐私保护架构，整合联邦学习、差分隐私、零知识合规证明和基于强化学习的自适应治理，用于构建可信合规的分布式机器学习系统。


<details>
  <summary>Details</summary>
Motivation: 分布式机器学习系统需要强大的隐私保障、可验证的合规性以及跨异构多云环境的可扩展部署，以解决敏感数据集中化、跨机构合规验证和动态治理等挑战。

Method: 采用云原生架构，整合联邦学习（避免数据集中）、差分隐私（提供形式化隐私保障）、零知识证明（实现可验证合规）和基于强化学习的自适应治理（动态调整策略）。

Result: 在混合Kubernetes集群上的原型部署显示：降低了成员推理攻击风险、保持了一致的隐私预算执行、在差分隐私下维持了稳定的模型性能，多机构工作负载评估显示系统在最小开销下保持效用。

Conclusion: 该框架为大规模部署可信且合规的分布式机器学习系统建立了实用基础，实现了隐私保护、可验证合规和自适应治理的有机结合。

Abstract: Distributed machine learning systems require strong privacy guarantees, verifiable compliance, and scalable deploy- ment across heterogeneous and multi-cloud environments. This work introduces a cloud-native privacy-preserving architecture that integrates federated learning, differential privacy, zero- knowledge compliance proofs, and adaptive governance powered by reinforcement learning. The framework supports secure model training and inference without centralizing sensitive data, while enabling cryptographically verifiable policy enforcement across institutions and cloud platforms. A full prototype deployed across hybrid Kubernetes clusters demonstrates reduced membership- inference risk, consistent enforcement of formal privacy budgets, and stable model performance under differential privacy. Ex- perimental evaluation across multi-institution workloads shows that the architecture maintains utility with minimal overhead while providing continuous, risk-aware governance. The pro- posed framework establishes a practical foundation for deploying trustworthy and compliant distributed machine learning systems at scale.

</details>


### [133] [Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories](https://arxiv.org/abs/2512.10350)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 本文提出了一个几何框架来分析智能体循环在语义嵌入空间中的行为，将迭代变换视为离散动力系统，揭示了提示设计如何直接控制智能体循环的收敛、发散和轨迹结构。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的智能体系统通过递归反馈循环运行，但人们对这些智能体循环的几何行为（收敛、发散或更复杂动态）了解甚少。需要建立一个几何框架来分析智能体轨迹在语义嵌入空间中的行为。

Method: 引入几何框架，区分发生语言变换的工件空间和进行几何测量的嵌入空间。由于余弦相似度受嵌入各向异性影响，提出了等渗校准来消除系统偏差，使相似度与人类语义判断对齐，同时保持高局部稳定性。通过受控实验分析单一智能体循环。

Result: 识别出两种基本机制：收缩性重写循环收敛于稳定吸引子且分散度减小；探索性总结与否定循环产生无界发散且无聚类形成。这些机制显示出收缩和扩展的定性不同几何特征。

Conclusion: 提示设计直接控制智能体循环的动力机制，使人们能够系统控制迭代LLM变换中的收敛、发散和轨迹结构。等渗校准为测量轨迹、聚类和吸引子提供了严格方法。

Abstract: Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.

</details>


### [134] [GPG: Generalized Policy Gradient Theorem for Transformer-based Policies](https://arxiv.org/abs/2512.10365)
*Hangyu Mao,Guangting Dong,Zhicheng Dou*

Main category: cs.LG

TL;DR: 提出了适用于Transformer策略的广义策略梯度定理，将标准策略梯度定理和GRPO作为特例纳入统一框架，并探索了在LLM训练中的实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有策略梯度方法主要针对传统强化学习环境设计，缺乏专门针对Transformer架构的策略优化理论框架。随着大型语言模型的发展，需要专门针对Transformer策略的梯度理论来指导高效训练。

Method: 提出了广义策略梯度定理，专门为基于Transformer的策略设计。该框架能够统一标准策略梯度定理和GRPO方法，并探索了在大型语言模型训练中的具体应用。

Result: 证明了标准策略梯度定理和GRPO都是广义策略梯度定理的特殊情况，为Transformer策略优化提供了统一的理论基础。在LLM训练中展示了该框架的实际应用价值。

Conclusion: 广义策略梯度定理为Transformer策略优化提供了统一的理论框架，不仅包含现有方法作为特例，还为大型语言模型的高效训练提供了新的理论指导和应用思路。

Abstract: We present the Generalized Policy Gradient (GPG) Theorem, specifically designed for Transformer-based policies. Notably, we demonstrate that both standard Policy Gradient Theorem and GRPO emerge as special cases within our GPG framework. Furthermore, we explore its practical applications in training Large Language Models (LLMs), offering new insights into efficient policy optimization.

</details>


### [135] [Fitting magnetization data using continued fraction of straight lines](https://arxiv.org/abs/2512.10390)
*Vijay Prakash S*

Main category: cs.LG

TL;DR: 使用直线连分式近似铁磁物质磁化非线性特性，用于解释磁畴生长和收缩行为


<details>
  <summary>Details</summary>
Motivation: 铁磁物质磁化强度随外加磁场增强而增加，这是由于微观磁畴逐渐与外场对齐导致的非线性行为，需要合适的数学方法来描述这种非线性特性

Method: 采用直线连分式（一种代数表达式）来近似磁化非线性函数，通过非线性回归估计参数

Result: 直线连分式拟合可用于解释磁畴在生长和收缩过程中的非线性行为

Conclusion: 直线连分式方法为描述铁磁物质磁化非线性特性提供了有效的数学工具，能够解释磁畴对齐的微观机制

Abstract: Magnetization of a ferromagnetic substance in response to an externally applied magnetic field increases with the strength of the field. This is because at the microscopic level, magnetic moments in certain regions or domains of the substance increasingly align with the applied field, while the amount of misaligned domains decreases. The alignment of such magnetic domains with an applied magnetic field forms the physical basis for the nonlinearity of magnetization. In this paper, the nonlinear function is approximated as a combination of continued fraction of straight lines. The resulting fit is used to interpret the nonlinear behavior in both growing and shrinking magnetic domains. The continued fraction of straight lines used here is an algebraic expression which can be used to estimate parameters using nonlinear regression.

</details>


### [136] [Metacognitive Sensitivity for Test-Time Dynamic Model Selection](https://arxiv.org/abs/2512.10451)
*Le Tuan Minh Trinh,Le Minh Vu Pham,Thi Minh Anh Pham,An Duc Nguyen*

Main category: cs.LG

TL;DR: 提出基于人类认知科学的AI元认知评估框架，使用meta-d'度量元认知敏感性，并利用该动态分数进行基于bandit的模型选择，提升联合推理准确率


<details>
  <summary>Details</summary>
Motivation: 深度学习模型虽然能表达预测置信度，但通常校准不佳（置信度不能反映真实能力），存在认知偏差。需要评估AI模型是否真正"知道它们知道什么"，借鉴人类认知科学来改进AI的元认知能力

Method: 1) 引入meta-d'（心理学基础的元认知敏感性度量）来表征模型置信度预测自身准确性的可靠性；2) 使用该动态敏感性分数作为上下文，构建基于bandit的仲裁器，在测试时学习信任哪个专家模型；3) 在多个数据集和深度学习模型组合（包括CNN和VLM）上进行实验

Result: 实验表明这种元认知方法相比组成模型提升了联合推理准确率。该框架为AI模型提供了新颖的行为描述，将集成选择重新定义为评估短期信号（置信度预测分数）和中期特征（元认知敏感性）的问题

Conclusion: 通过借鉴人类认知科学的元认知框架，可以更好地评估和利用AI的元认知能力，改进模型选择和推理性能，为AI行为分析提供了新视角

Abstract: A key aspect of human cognition is metacognition - the ability to assess one's own knowledge and judgment reliability. While deep learning models can express confidence in their predictions, they often suffer from poor calibration, a cognitive bias where expressed confidence does not reflect true competence. Do models truly know what they know? Drawing from human cognitive science, we propose a new framework for evaluating and leveraging AI metacognition. We introduce meta-d', a psychologically-grounded measure of metacognitive sensitivity, to characterise how reliably a model's confidence predicts its own accuracy. We then use this dynamic sensitivity score as context for a bandit-based arbiter that performs test-time model selection, learning which of several expert models to trust for a given task. Our experiments across multiple datasets and deep learning model combinations (including CNNs and VLMs) demonstrate that this metacognitive approach improves joint-inference accuracy over constituent models. This work provides a novel behavioural account of AI models, recasting ensemble selection as a problem of evaluating both short-term signals (confidence prediction scores) and medium-term traits (metacognitive sensitivity).

</details>


### [137] [Hybrid Physics-ML Model for Forward Osmosis Flux with Complete Uncertainty Quantification](https://arxiv.org/abs/2512.10457)
*Shiv Ratn,Shivang Rampriyan,Bahni Ray*

Main category: cs.LG

TL;DR: 该研究提出了一种结合物理模型与机器学习的高斯过程回归框架，用于精确预测正渗透过程中的水通量，并实现了全面的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 正渗透作为一种低能耗膜分离技术，其水通量建模面临挑战：传统机理模型受经验参数变化影响，纯数据驱动模型缺乏物理一致性和不确定性量化。需要开发既准确又具有物理一致性且能量化不确定性的预测方法。

Method: 采用鲁棒混合物理-机器学习框架，使用高斯过程回归。核心创新是在详细的非线性物理模型预测与实验水通量之间的残差上训练GPR。通过将总预测方差分解为模型不确定性（来自GPR后验方差）和输入不确定性（通过Delta方法分析传播），实现全面的不确定性量化。

Result: 仅使用120个数据点训练，模型在独立测试数据上实现了0.26%的平均绝对百分比误差和0.999的R²分数，达到了最先进的预测精度。

Conclusion: 该研究开发了一个真正鲁棒可靠的替代模型，可用于先进的正渗透过程优化和数字孪生开发，为低数据量条件下的精确预测提供了有效解决方案。

Abstract: Forward Osmosis (FO) is a promising low-energy membrane separation technology, but challenges in accurately modelling its water flux (Jw) persist due to complex internal mass transfer phenomena. Traditional mechanistic models struggle with empirical parameter variability, while purely data-driven models lack physical consistency and rigorous uncertainty quantification (UQ). This study introduces a novel Robust Hybrid Physics-ML framework employing Gaussian Process Regression (GPR) for highly accurate, uncertainty-aware Jw prediction. The core innovation lies in training the GPR on the residual error between the detailed, non-linear FO physical model prediction (Jw_physical) and the experimental water flux (Jw_actual). Crucially, we implement a full UQ methodology by decomposing the total predictive variance (sigma2_total) into model uncertainty (epistemic, from GPR's posterior variance) and input uncertainty (aleatoric, analytically propagated via the Delta method for multi-variate correlated inputs). Leveraging the inherent strength of GPR in low-data regimes, the model, trained on a meagre 120 data points, achieved a state-of-the-art Mean Absolute Percentage Error (MAPE) of 0.26% and an R2 of 0.999 on the independent test data, validating a truly robust and reliable surrogate model for advanced FO process optimization and digital twin development.

</details>


### [138] [Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2512.10510)
*Chihyeon Song,Jaewoo Lee,Jinkyoo Park*

Main category: cs.LG

TL;DR: 本文提出自适应回放缓冲区（ARB），通过动态优先采样基于"on-policyness"指标的数据，解决离线到在线强化学习中的稳定性与性能平衡问题。


<details>
  <summary>Details</summary>
Motivation: 离线到在线强化学习面临一个关键困境：如何在固定离线数据集和新收集的在线经验之间取得平衡。传统方法通常依赖固定的数据混合比例，难以在早期学习稳定性和渐进性能之间进行权衡。

Method: 提出自适应回放缓冲区（ARB），这是一种基于轻量级指标"on-policyness"的动态优先采样方法。ARB评估收集的轨迹与当前策略行为的接近程度，并为该轨迹中的每个转移分配相应的采样权重。这种方法无需复杂学习过程，易于实现，可无缝集成到现有O2O RL算法中。

Result: 在D4RL基准测试上的广泛实验表明，ARB能够持续缓解早期性能下降问题，并显著提高各种O2O RL算法的最终性能。

Conclusion: 自适应、行为感知的回放缓冲区设计对于离线到在线强化学习至关重要，ARB通过动态优先采样策略有效平衡了离线数据的初始稳定性和在线高奖励经验的学习重点。

Abstract: Offline-to-Online Reinforcement Learning (O2O RL) faces a critical dilemma in balancing the use of a fixed offline dataset with newly collected online experiences. Standard methods, often relying on a fixed data-mixing ratio, struggle to manage the trade-off between early learning stability and asymptotic performance. To overcome this, we introduce the Adaptive Replay Buffer (ARB), a novel approach that dynamically prioritizes data sampling based on a lightweight metric we call 'on-policyness'. Unlike prior methods that rely on complex learning procedures or fixed ratios, ARB is designed to be learning-free and simple to implement, seamlessly integrating into existing O2O RL algorithms. It assesses how closely collected trajectories align with the current policy's behavior and assigns a proportional sampling weight to each transition within that trajectory. This strategy effectively leverages offline data for initial stability while progressively focusing learning on the most relevant, high-rewarding online experiences. Our extensive experiments on D4RL benchmarks demonstrate that ARB consistently mitigates early performance degradation and significantly improves the final performance of various O2O RL algorithms, highlighting the importance of an adaptive, behavior-aware replay buffer design.

</details>


### [139] [Disentangled and Distilled Encoder for Out-of-Distribution Reasoning with Rademacher Guarantees](https://arxiv.org/abs/2512.10522)
*Zahra Rahiminasab,Michael Yuhas,Arvind Easwaran*

Main category: cs.LG

TL;DR: 提出DDE框架，通过师生蒸馏压缩VAE的分离潜在空间模型，在资源受限设备上部署时保持分离性，并建立理论保证


<details>
  <summary>Details</summary>
Motivation: 分离潜在空间的VAE可用于处理多标签OOD样本，但模型较大难以在资源受限设备上部署，需要压缩模型同时保持分离性

Method: 提出分离蒸馏编码器(DDE)框架，将师生蒸馏形式化为约束优化问题，通过分离约束保持分离性，基于Rademacher复杂度建立理论保证

Result: 在NVIDIA设备上部署压缩模型进行实证评估，证明DDE能有效压缩模型大小同时保持分离性

Conclusion: DDE框架成功解决了在资源受限设备上部署分离潜在空间模型的问题，通过约束优化和理论保证实现了模型压缩与分离性保持的平衡

Abstract: Recently, the disentangled latent space of a variational autoencoder (VAE) has been used to reason about multi-label out-of-distribution (OOD) test samples that are derived from different distributions than training samples. Disentangled latent space means having one-to-many maps between latent dimensions and generative factors or important characteristics of an image. This paper proposes a disentangled distilled encoder (DDE) framework to decrease the OOD reasoner size for deployment on resource-constrained devices while preserving disentanglement. DDE formalizes student-teacher distillation for model compression as a constrained optimization problem while preserving disentanglement with disentanglement constraints. Theoretical guarantees for disentanglement during distillation based on Rademacher complexity are established. The approach is evaluated empirically by deploying the compressed model on an NVIDIA

</details>


### [140] [Mode-Seeking for Inverse Problems with Diffusion Models](https://arxiv.org/abs/2512.10524)
*Sai Bharath Chandra Gutha,Ricardo Vinuesa,Hossein Azizpour*

Main category: cs.LG

TL;DR: 提出VML-MAP算法，通过最小化变分模式寻求损失来引导扩散模型生成MAP估计，无需任务特定训练即可解决逆问题


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练扩散模型的后验采样和MAP估计方法存在建模近似和计算复杂度高的问题，需要更高效准确的逆问题求解方法

Method: 提出变分模式寻求损失(VML)，通过最小化扩散后验与测量后验之间的KL散度来引导生成样本趋向MAP估计；对于线性逆问题可解析推导VML；基于此开发VML-MAP算法

Result: VML-MAP在多个数据集上的多种图像恢复任务中，相比现有方法在性能和计算时间上均表现出优越性

Conclusion: VML-MAP为基于扩散模型的逆问题求解提供了高效准确的解决方案，无需任务特定训练，在理论和实验上均验证了其有效性

Abstract: A pre-trained unconditional diffusion model, combined with posterior sampling or maximum a posteriori (MAP) estimation techniques, can solve arbitrary inverse problems without task-specific training or fine-tuning. However, existing posterior sampling and MAP estimation methods often rely on modeling approximations and can be computationally demanding. In this work, we propose the variational mode-seeking loss (VML), which, when minimized during each reverse diffusion step, guides the generated sample towards the MAP estimate. VML arises from a novel perspective of minimizing the Kullback-Leibler (KL) divergence between the diffusion posterior $p(\mathbf{x}_0|\mathbf{x}_t)$ and the measurement posterior $p(\mathbf{x}_0|\mathbf{y})$, where $\mathbf{y}$ denotes the measurement. Importantly, for linear inverse problems, VML can be analytically derived and need not be approximated. Based on further theoretical insights, we propose VML-MAP, an empirically effective algorithm for solving inverse problems, and validate its efficacy over existing methods in both performance and computational time, through extensive experiments on diverse image-restoration tasks across multiple datasets.

</details>


### [141] [Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders](https://arxiv.org/abs/2512.10547)
*Qingsen Ma,Dianyun Wang,Jiaming Lyu,Yaoye Wang,Lechen Ning,Sujie Zhu,Zhenbo Xu,Liuyu Xiang,Huining Li,Huijia Wu,Zhaofeng He*

Main category: cs.LG

TL;DR: STA-Attention框架使用Top-K稀疏自编码器将KV缓存分解为可解释的语义原子，通过双预算策略选择性保留关键语义成分，在保持模型性能的同时解决长上下文LLM中的内存瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: KV缓存是长上下文大语言模型中的主要内存瓶颈，但通常被当作不透明的数值张量处理。作者希望将KV缓存分解为可解释的语义组件，同时保持注意力机制所需的精确点积几何结构。

Method: 提出STA-Attention框架，使用Top-K稀疏自编码器分解KV缓存为语义原子。发现Key-Value不对称性：Key向量作为稀疏路由器，Value向量携带密集内容。基于此引入双预算策略，选择性保留最有信息的语义成分并过滤表示噪声。

Result: 在Yi-6B、Mistral-7B、Qwen2.5-32B等模型上的实验表明，语义重建保持了与原始模型相当的困惑度和零样本性能，有效弥合了机制可解释性与忠实注意力建模之间的差距。

Conclusion: STA-Attention框架成功将KV缓存分解为可解释的语义原子，通过Top-K稀疏自编码器和双预算策略，在保持模型性能的同时解决了长上下文LLM的内存瓶颈问题，为机制可解释性提供了新视角。

Abstract: The Key-Value (KV) cache is the primary memory bottleneck in long-context Large Language Models, yet it is typically treated as an opaque numerical tensor. In this work, we propose \textbf{STA-Attention}, a framework that utilizes Top-K Sparse Autoencoders (SAEs) to decompose the KV cache into interpretable ``semantic atoms.'' Unlike standard $L_1$-regularized SAEs, our Top-K approach eliminates shrinkage bias, preserving the precise dot-product geometry required for attention. Our analysis uncovers a fundamental \textbf{Key-Value Asymmetry}: while Key vectors serve as highly sparse routers dominated by a ``Semantic Elbow,'' deep Value vectors carry dense content payloads requiring a larger budget. Based on this structure, we introduce a Dual-Budget Strategy that selectively preserves the most informative semantic components while filtering representational noise. Experiments on Yi-6B, Mistral-7B, Qwen2.5-32B, and others show that our semantic reconstructions maintain perplexity and zero-shot performance comparable to the original models, effectively bridging the gap between mechanistic interpretability and faithful attention modeling.

</details>


### [142] [Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning](https://arxiv.org/abs/2512.10573)
*Yi Huang,Qingyun Sun,Yisen Gao,Haonan Yuan,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: LaT-IB是一种针对标签噪声的鲁棒信息瓶颈方法，通过引入"最小充分清洁"准则和噪声感知潜在解耦，将潜在表示分解为清洁标签空间和噪声空间对齐的组件，从而在标签噪声环境下实现有效的表示学习。


<details>
  <summary>Details</summary>
Motivation: 传统信息瓶颈(IB)方法严重依赖准确的标签，在现实场景中普遍存在的标签噪声下容易导致性能下降和过拟合，因此需要开发能够抵抗标签噪声的IB方法。

Method: 提出LaT-IB方法，引入"最小充分清洁"准则作为互信息正则化器，采用噪声感知潜在解耦技术将潜在表示分解为清洁标签空间和噪声空间对齐的组件，并设计三阶段训练框架：预热、知识注入和鲁棒训练。

Result: 理论分析证明了方法的有效性，包括推导了预测、压缩和解耦各组件互信息边界，证明优化能鼓励对输入噪声不变的表示并分离清洁和噪声标签信息。实验表明LaT-IB在标签噪声下实现了优越的鲁棒性和效率。

Conclusion: LaT-IB通过创新的"最小充分清洁"准则和噪声感知解耦机制，有效解决了传统信息瓶颈方法对标签噪声的脆弱性问题，显著增强了在现实标签噪声场景下的鲁棒性和适用性。

Abstract: The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a "Minimal-Sufficient-Clean" (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB's vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.

</details>


### [143] [Multi-Objective Reward and Preference Optimization: Theory and Algorithms](https://arxiv.org/abs/2512.10601)
*Akhil Agnihotri*

Main category: cs.LG

TL;DR: 该论文在约束强化学习领域提出了多个理论框架和算法，涵盖平均成本CMDP、有限时域CMDP、人类偏好学习以及大语言模型对齐，提供了理论保证和实际应用工具。


<details>
  <summary>Details</summary>
Motivation: 当前约束强化学习在控制、偏好学习和大型语言模型对齐方面存在理论空白和实践挑战，需要开发具有理论保证且可扩展的算法来处理安全约束、人类偏好和模型对齐问题。

Method: 1. ACPO算法：结合敏感性分析和信任域更新处理平均成本CMDP；2. e-COP算法：基于episodic策略差异引理处理有限时域CMDP；3. warmPref-PS：整合异构评分者离线偏好数据的后验采样策略；4. PSPL算法：从成对轨迹比较中联合采样奖励模型和转移动态；5. MOPO算法：多目标约束优化方法，用于大规模语言模型对齐。

Result: ACPO在平均成本CMDP中实现了最先进的实证性能；e-COP在安全关键环境中提供了可证明的性能和可扩展性；warmPref-PS显著减少了遗憾并提高了数据收集效率；PSPL提供了贝叶斯简单遗憾保证；MOPO可扩展到数十亿参数的语言模型并在各种对齐设置中保持鲁棒性。

Conclusion: 该论文统一了平均成本、episodic和偏好驱动的约束强化学习范式，为安全和对齐的决策制定提供了理论进展和实用工具，推动了约束RL在控制、偏好学习和语言模型对齐领域的综合发展。

Abstract: This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.

</details>


### [144] [Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach](https://arxiv.org/abs/2512.10633)
*C. Bosco,U. Minora,D. de Rigo,J. Pingsdorf,R. Cortinovis*

Main category: cs.LG

TL;DR: 本文提出了一种混合方法，结合机器学习与专家定性洞察，预测欧洲五大关键移民路线未来一年的非法越境情况，旨在改善数据驱动模型的预测能力。


<details>
  <summary>Details</summary>
Motivation: 响应欧盟《移民与庇护协定》中的预测需求，支持《庇护与移民管理法规》，解决移民模式突然变化和传统数据集限制带来的挑战，为欧盟移民治理提供政策相关的预测工具。

Method: 采用混合方法，将机器学习技术与移民专家的定性洞察相结合，创新性地引入人工评估协变量，整合数据驱动建模与专家判断。

Result: 该方法已使用已知数据进行测试和验证，证明了其在移民相关政策背景下的适用性和可靠性，能够为战略决策、预警系统和欧盟成员国间的团结机制提供支持。

Conclusion: 该研究提出了一种新颖的操作工具，将数据驱动建模与专家判断相结合，符合现有学术建议，专门为欧盟移民治理量身定制，能够提供政策相关的预测信息。

Abstract: This paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.

</details>


### [145] [Token Sample Complexity of Attention](https://arxiv.org/abs/2512.10656)
*Léa Bohbot,Cyril Letrouit,Gabriel Peyré,François-Xavier Vialard*

Main category: cs.LG

TL;DR: 该论文研究了大型语言模型中注意力机制在极端序列长度下的收敛行为，提出了token-sample复杂度的概念，分析了注意力映射在不同条件下的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型上下文窗口的不断扩展，需要理解注意力机制在极端序列长度下的行为特征，特别是注意力如何随着token数量的增加收敛到其无限token极限。

Method: 引入token-sample复杂度概念，从两个层面分析收敛性：1) 注意力映射在半径为R的球上的逐点一致收敛；2) 变换后token分布矩的收敛。分析了紧支撑分布和亚高斯分布，并研究了注意力参数趋于无穷大时softmax接近hardmax的情况。

Result: 对于紧支撑分布，注意力映射在半径为R的球上以C(R)/√n的速率一致收敛，其中C(R)随R指数增长。对于变换后token分布的矩，收敛速率为C'(R)/n^β，其中β<1/2，C'(R)与分布支撑大小呈多项式关系。在注意力参数趋于无穷大时，收敛速率变为对数速率。实验在合成高斯数据和真实BERT模型上验证了这些预测。

Conclusion: 该研究为理解大型语言模型中注意力机制在长序列下的行为提供了理论框架，揭示了注意力收敛的速率特性，对模型设计和分析具有重要指导意义。

Abstract: As context windows in large language models continue to expand, it is essential to characterize how attention behaves at extreme sequence lengths. We introduce token-sample complexity: the rate at which attention computed on $n$ tokens converges to its infinite-token limit. We estimate finite-$n$ convergence bounds at two levels: pointwise uniform convergence of the attention map, and convergence of moments for the transformed token distribution. For compactly supported (and more generally sub-Gaussian) distributions, our first result shows that the attention map converges uniformly on a ball of radius $R$ at rate $C(R)/\sqrt{n}$, where $C(R)$ grows exponentially with $R$. For large $R$, this estimate loses practical value, and our second result addresses this issue by establishing convergence rates for the moments of the transformed distribution (the token output of the attention layer). In this case, the rate is $C'(R)/n^β$ with $β<\tfrac{1}{2}$, and $C'(R)$ depends polynomially on the size of the support of the distribution. The exponent $β$ depends on the attention geometry and the spectral properties of the tokens distribution. We also examine the regime in which the attention parameter tends to infinity and the softmax approaches a hardmax, and in this setting, we establish a logarithmic rate of convergence. Experiments on synthetic Gaussian data and real BERT models on Wikipedia text confirm our predictions.

</details>


### [146] [DCFO Additional Material](https://arxiv.org/abs/2512.10659)
*Tommaso Amico,Pernille Matthews,Lena Krieger,Arthur Zimek,Ira Assent*

Main category: cs.LG

TL;DR: DCFO是一种专门为LOF异常检测算法设计的反事实解释方法，通过将数据空间划分为LOF行为平滑的区域，实现高效的梯度优化，在50个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 异常检测需要解释性来理解异常原因、验证其显著性并识别潜在偏差。虽然反事实解释能说明为何数据点被分类为异常，但现有方法大多忽略了异常检测的特殊挑战，且未针对LOF等经典算法。LOF作为最流行的无监督异常检测方法之一，缺乏可解释性。

Method: 提出DCFO方法，专门为LOF生成反事实解释。该方法将数据空间划分为LOF行为平滑的区域，从而能够进行高效的基于梯度的优化，找到最小改变使异常点变为正常点。

Result: 在50个OpenML数据集上进行广泛实验验证，DCFO在生成的反事实解释的邻近性和有效性方面，始终优于基准竞争对手。

Conclusion: DCFO成功解决了LOF异常检测算法缺乏可解释性的问题，为这一广泛使用的经典算法提供了专门设计的反事实解释方法，在多个数据集上表现出优越性能。

Abstract: Outlier detection identifies data points that significantly deviate from the majority of the data distribution. Explaining outliers is crucial for understanding the underlying factors that contribute to their detection, validating their significance, and identifying potential biases or errors. Effective explanations provide actionable insights, facilitating preventive measures to avoid similar outliers in the future. Counterfactual explanations clarify why specific data points are classified as outliers by identifying minimal changes required to alter their prediction. Although valuable, most existing counterfactual explanation methods overlook the unique challenges posed by outlier detection, and fail to target classical, widely adopted outlier detection algorithms. Local Outlier Factor (LOF) is one the most popular unsupervised outlier detection methods, quantifying outlierness through relative local density. Despite LOF's widespread use across diverse applications, it lacks interpretability. To address this limitation, we introduce Density-based Counterfactuals for Outliers (DCFO), a novel method specifically designed to generate counterfactual explanations for LOF. DCFO partitions the data space into regions where LOF behaves smoothly, enabling efficient gradient-based optimisation. Extensive experimental validation on 50 OpenML datasets demonstrates that DCFO consistently outperforms benchmarked competitors, offering superior proximity and validity of generated counterfactuals.

</details>


### [147] [Learning by Analogy: A Causal Framework for Composition Generalization](https://arxiv.org/abs/2512.10669)
*Lingjing Kong,Shaoan Xie,Yang Jiao,Yetian Chen,Yanhui Guo,Simone Shao,Yan Gao,Guangyi Chen,Kun Zhang*

Main category: cs.LG

TL;DR: 论文提出基于因果模块化和最小变化原则的形式化框架，通过分层数据生成过程实现组合泛化，证明潜在分层结构可从观测数据中可识别恢复，并在基准数据集上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 组合泛化能力使模型能够超越有限经验理解新概念组合，但实现这一关键能力的数据结构和原理仍不清楚。论文旨在形式化人类类比推理过程，建立支持复杂概念关系的组合泛化理论框架。

Method: 采用因果模块化和最小变化原则，引入分层数据生成过程编码不同层次概念及其交互机制。理论证明该方法支持复杂概念关系的组合泛化，且潜在分层结构可从文本-图像对等观测数据中可识别恢复。

Result: 理论证明该框架能够超越先前假设简单交互（如加性效应）的工作，支持复杂概念关系的组合泛化。在基准数据集上的应用验证了理论框架的有效性，取得了显著改进。

Conclusion: 组合泛化需要将高层概念分解为可跨相似上下文重组的低层概念，通过因果模块化和分层数据生成过程的形式化框架，可实现支持复杂关系的组合泛化，且该结构可从观测数据中学习恢复。

Abstract: Compositional generalization -- the ability to understand and generate novel combinations of learned concepts -- enables models to extend their capabilities beyond limited experiences. While effective, the data structures and principles that enable this crucial capability remain poorly understood. We propose that compositional generalization fundamentally requires decomposing high-level concepts into basic, low-level concepts that can be recombined across similar contexts, similar to how humans draw analogies between concepts. For example, someone who has never seen a peacock eating rice can envision this scene by relating it to their previous observations of a chicken eating rice.
  In this work, we formalize these intuitive processes using principles of causal modularity and minimal changes. We introduce a hierarchical data-generating process that naturally encodes different levels of concepts and their interaction mechanisms. Theoretically, we demonstrate that this approach enables compositional generalization supporting complex relations between composed concepts, advancing beyond prior work that assumes simpler interactions like additive effects. Critically, we also prove that this latent hierarchical structure is provably recoverable (identifiable) from observable data like text-image pairs, a necessary step for learning such a generative process. To validate our theory, we apply insights from our theoretical framework and achieve significant improvements on benchmark datasets.

</details>


### [148] [HybridVFL: Disentangled Feature Learning for Edge-Enabled Vertical Federated Multimodal Classification](https://arxiv.org/abs/2512.10701)
*Mostafa Anoosha,Zeinab Dehghani,Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker*

Main category: cs.LG

TL;DR: HybridVFL框架通过客户端特征解耦和服务器端跨模态Transformer融合，显著提升垂直联邦学习在边缘AI场景下的性能表现


<details>
  <summary>Details</summary>
Motivation: 垂直联邦学习在边缘AI场景（如移动健康诊断）中面临性能限制，主要原因是传统方法采用简单的特征融合方式，无法充分利用分布式多模态数据的潜力

Method: 提出HybridVFL框架，包含客户端特征解耦和服务器端跨模态Transformer两个核心组件，实现上下文感知的特征融合

Result: 在多模态皮肤病变数据集HAM10000上的系统评估显示，HybridVFL显著优于标准联邦学习基线方法

Conclusion: 先进的融合机制对于构建鲁棒、隐私保护的边缘AI系统至关重要，HybridVFL框架为此提供了有效解决方案

Abstract: Vertical Federated Learning (VFL) offers a privacy-preserving paradigm for Edge AI scenarios like mobile health diagnostics, where sensitive multimodal data reside on distributed, resource-constrained devices. Yet, standard VFL systems often suffer performance limitations due to simplistic feature fusion. This paper introduces HybridVFL, a novel framework designed to overcome this bottleneck by employing client-side feature disentanglement paired with a server-side cross-modal transformer for context-aware fusion. Through systematic evaluation on the multimodal HAM10000 skin lesion dataset, we demonstrate that HybridVFL significantly outperforms standard federated baselines, validating the criticality of advanced fusion mechanisms in robust, privacy-preserving systems.

</details>


### [149] [Beyond the Black Box: Identifiable Interpretation and Control in Generative Models via Causal Minimality](https://arxiv.org/abs/2512.10720)
*Lingjing Kong,Shaoan Xie,Guangyi Chen,Yuewen Sun,Xiangchen Song,Eric P. Xing,Kun Zhang*

Main category: cs.LG

TL;DR: 论文提出基于因果最小化原则的理论框架，为扩散视觉和自回归语言模型的潜在表示提供因果解释和组件级可控性，通过稀疏性或压缩约束实现与真实潜在变量的等价性。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型虽然革命性地推动了图像和文本生成领域，但通常作为不透明的黑箱运行，阻碍了人类理解、控制和对其对齐。现有方法如稀疏自编码器虽然经验上成功，但缺乏理论保证，可能导致主观见解。

Method: 引入基于因果最小化原则的理论框架，提出分层选择模型，其中高层概念由低层变量的约束组合形成。在理论推导的最小化条件（表现为稀疏性或压缩约束）下，学习到的表示可以与数据生成过程的真实潜在变量等价。

Result: 将约束应用于领先的生成模型，能够提取其内在的分层概念图，提供对其内部知识组织的新见解。这些因果基础的概念可作为细粒度模型操控的杠杆。

Conclusion: 因果最小化原则可以为可解释生成模型奠定原则性基础，使潜在表示具有清晰的因果解释和鲁棒的组件级可控性，为实现透明可靠的系统铺平道路。

Abstract: Deep generative models, while revolutionizing fields like image and text generation, largely operate as opaque black boxes, hindering human understanding, control, and alignment. While methods like sparse autoencoders (SAEs) show remarkable empirical success, they often lack theoretical guarantees, risking subjective insights. Our primary objective is to establish a principled foundation for interpretable generative models. We demonstrate that the principle of causal minimality -- favoring the simplest causal explanation -- can endow the latent representations of diffusion vision and autoregressive language models with clear causal interpretation and robust, component-wise identifiable control. We introduce a novel theoretical framework for hierarchical selection models, where higher-level concepts emerge from the constrained composition of lower-level variables, better capturing the complex dependencies in data generation. Under theoretically derived minimality conditions (manifesting as sparsity or compression constraints), we show that learned representations can be equivalent to the true latent variables of the data-generating process. Empirically, applying these constraints to leading generative models allows us to extract their innate hierarchical concept graphs, offering fresh insights into their internal knowledge organization. Furthermore, these causally grounded concepts serve as levers for fine-grained model steering, paving the way for transparent, reliable systems.

</details>


### [150] [Generalized Spherical Neural Operators: Green's Function Formulation](https://arxiv.org/abs/2512.10723)
*Hao Tang,Hao Chen,Chao Li*

Main category: cs.LG

TL;DR: 提出基于可设计球面格林函数的神经算子框架GSNO，通过谱学习方法在球域上平衡等变性和不变性，结合GSHNet层次架构，在多个应用领域超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有球面神经算子依赖旋转等变性但缺乏处理真实世界复杂性的灵活性，需要建立既保持几何特性又能适应各向异性约束系统的算子理论基础。

Method: 基于可设计球面格林函数及其谐波展开建立算子理论框架，提出绝对和相对位置依赖的格林函数，开发GSNO算子和谱学习方法，构建GSHNet层次架构结合多尺度谱建模和球面上下采样。

Result: 在扩散MRI、浅水动力学和全球天气预报三个应用领域的评估中，GSNO和GSHNet一致优于现有最先进方法。

Conclusion: GSNO为球面算子学习提供了原则性和通用性框架，将严格理论与真实世界复杂性相连接，为球域上的参数偏微分方程求解提供了新途径。

Abstract: Neural operators offer powerful approaches for solving parametric partial differential equations, but extending them to spherical domains remains challenging due to the need to preserve intrinsic geometry while avoiding distortions that break rotational consistency. Existing spherical operators rely on rotational equivariance but often lack the flexibility for real-world complexity. We propose a general operator-design framework based on the designable spherical Green's function and its harmonic expansion, establishing a solid operator-theoretic foundation for spherical learning. Based on this, we propose an absolute and relative position-dependent Green's function that enables flexible balance of equivariance and invariance for real-world modeling. The resulting operator, Green's-function Spherical Neural Operator (GSNO) with a novel spectral learning method, can adapt to anisotropic, constraint-rich systems while retaining spectral efficiency. To exploit GSNO, we develop GSHNet, a hierarchical architecture that combines multi-scale spectral modeling with spherical up-down sampling, enhancing global feature representation. Evaluations on diffusion MRI, shallow water dynamics, and global weather forecasting, GSNO and GSHNet consistently outperform state-of-the-art methods. Our results position GSNO as a principled and general framework for spherical operator learning, bridging rigorous theory with real-world complexity.

</details>


### [151] [Interpretable and Steerable Concept Bottleneck Sparse Autoencoders](https://arxiv.org/abs/2512.10805)
*Akshay Kulkarni,Tsui-Wei Weng,Vivek Narayanaswamy,Shusen Liu,Wesam A. Sakla,Kowshik Thopalli*

Main category: cs.LG

TL;DR: 本文提出概念瓶颈稀疏自编码器（CB-SAE），通过剪枝低效用神经元并添加轻量级概念瓶颈来提升稀疏自编码器的可解释性和可操控性。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）在大型语言模型和视觉语言模型的机制可解释性、概念发现和模型操控方面具有潜力，但现有SAEs存在两个问题：1）多数神经元可解释性或可操控性低，对下游任务无效；2）由于无监督特性，用户期望的概念往往不在学习到的字典中，限制了实际应用。

Method: 提出概念瓶颈稀疏自编码器（CB-SAE）框架，包含两个核心步骤：1）剪枝低效用神经元；2）在潜在空间中添加轻量级概念瓶颈，该瓶颈与用户定义的概念集对齐。该方法是一种后处理框架，计算成本低。

Result: 在视觉语言模型和图像生成任务中，CB-SAE相比基线方法将可解释性提升了32.1%，可操控性提升了14.5%。

Conclusion: CB-SAE通过结合神经元剪枝和概念瓶颈增强，有效解决了稀疏自编码器在实际应用中的可解释性和可操控性限制，为模型的可解释性和操控提供了更实用的解决方案。

Abstract: Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally inexpensive interpretability and steerability metrics and conduct a systematic analysis on LVLMs. Our analysis uncovers two observations; (i) a majority of SAE neurons exhibit either low interpretability or low steerability or both, rendering them ineffective for downstream use; and (ii) due to the unsupervised nature of SAEs, user-desired concepts are often absent in the learned dictionary, thus limiting their practical utility. To address these limitations, we propose Concept Bottleneck Sparse Autoencoders (CB-SAE) - a novel post-hoc framework that prunes low-utility neurons and augments the latent space with a lightweight concept bottleneck aligned to a user-defined concept set. The resulting CB-SAE improves interpretability by +32.1% and steerability by +14.5% across LVLMs and image generation tasks. We will make our code and model weights available.

</details>


### [152] [Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments](https://arxiv.org/abs/2512.10835)
*Atahan Cilan,Atay Özgövde*

Main category: cs.LG

TL;DR: 提出基于强化学习的框架，无需人类游戏数据即可生成可控且多样化的玩家行为，通过行为向量空间实现平滑控制


<details>
  <summary>Details</summary>
Motivation: 现有方法需要大量玩家轨迹数据、需为不同玩家类型训练单独模型，或缺乏可解释行为参数与学习策略之间的直接映射，限制了可扩展性和可控性

Method: 在N维连续空间中定义玩家行为，从包含真实人类风格子集的区域均匀采样目标行为向量。训练时，每个智能体接收当前和目标行为向量作为输入，奖励基于两者距离的归一化减少。使用PPO-based多智能体策略

Result: 在自定义多玩家Unity游戏中，该方法比仅以获胜为目标的基线产生显著更大的行为多样性，并能可靠匹配不同目标行为向量。单个策略可重现新或未见过的游戏风格而无需重新训练

Conclusion: 该方法为自动化游戏测试、游戏平衡、人类行为模拟和在线游戏中替换断开连接的玩家提供了可扩展的解决方案

Abstract: This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping between interpretable behavioral parameters and the learned policy, limiting their scalability and controllability. We define player behavior in an N-dimensional continuous space and uniformly sample target behavior vectors from a region that encompasses the subset representing real human styles. During training, each agent receives both its current and target behavior vectors as input, and the reward is based on the normalized reduction in distance between them. This allows the policy to learn how actions influence behavioral statistics, enabling smooth control over attributes such as aggressiveness, mobility, and cooperativeness. A single PPO-based multi-agent policy can reproduce new or unseen play styles without retraining. Experiments conducted in a custom multi-player Unity game show that the proposed framework produces significantly greater behavioral diversity than a win-only baseline and reliably matches specified behavior vectors across diverse targets. The method offers a scalable solution for automated playtesting, game balancing, human-like behavior simulation, and replacing disconnected players in online games.

</details>


### [153] [Generative Modeling from Black-box Corruptions via Self-Consistent Stochastic Interpolants](https://arxiv.org/abs/2512.10857)
*Chirag Modi,Jiequn Han,Eric Vanden-Eijnden,Joan Bruna*

Main category: cs.LG

TL;DR: 提出自洽随机插值法（SCSI），通过迭代更新受损数据与干净数据之间的传输映射，仅需访问受损数据集和噪声通道的黑盒访问，即可构建干净数据的生成模型。


<details>
  <summary>Details</summary>
Motivation: 在科学和工程领域，通常只能获得被噪声、病态通道污染的数据，而无法获得干净数据。需要一种方法能够在分布层面解决逆问题，从受损数据中重建干净数据的生成模型。

Method: 基于随机插值法，迭代更新受损数据与干净数据样本之间的传输映射。仅需访问受损数据集和噪声通道的黑盒访问，通过自洽迭代过程收敛到一个能有效反转污染通道的传输映射。

Result: SCSI方法在计算效率上优于变分替代方法，具有高度灵活性，能够处理任意非线性前向模型，并享有理论保证。在自然图像处理和科学重建的逆问题上表现出优越性能。

Conclusion: 自洽随机插值法提供了一种高效、灵活且理论可靠的方法，从受损数据中构建干净数据的生成模型，适用于各种逆问题场景。

Abstract: Transport-based methods have emerged as a leading paradigm for building generative models from large, clean datasets. However, in many scientific and engineering domains, clean data are often unavailable: instead, we only observe measurements corrupted through a noisy, ill-conditioned channel. A generative model for the original data thus requires solving an inverse problem at the level of distributions. In this work, we introduce a novel approach to this task based on Stochastic Interpolants: we iteratively update a transport map between corrupted and clean data samples using only access to the corrupted dataset as well as black box access to the corruption channel. Under appropriate conditions, this iterative procedure converges towards a self-consistent transport map that effectively inverts the corruption channel, thus enabling a generative model for the clean data. We refer to the resulting method as the self-consistent stochastic interpolant (SCSI). It (i) is computationally efficient compared to variational alternatives, (ii) highly flexible, handling arbitrary nonlinear forward models with only black-box access, and (iii) enjoys theoretical guarantees. We demonstrate superior performance on inverse problems in natural image processing and scientific reconstruction, and establish convergence guarantees of the scheme under appropriate assumptions.

</details>


### [154] [Scaling Behavior of Discrete Diffusion Language Models](https://arxiv.org/abs/2512.10858)
*Dimitri von Rütte,Janis Fluri,Omead Pooladzandi,Bernhard Schölkopf,Thomas Hofmann,Antonio Orvieto*

Main category: cs.LG

TL;DR: 论文研究了离散扩散语言模型（DLMs）的缩放规律，发现不同噪声类型（掩码扩散vs均匀扩散）的缩放行为差异显著，且与自回归语言模型（ALMs）不同。均匀扩散在数据受限场景下表现更优，需要更多参数但更少数据。


<details>
  <summary>Details</summary>
Motivation: 现代LLM预训练消耗大量计算资源和训练数据，不同模型的缩放规律成为关键区分因素。离散扩散语言模型作为自回归语言模型的替代方案，其缩放行为尚未充分探索，先前研究表明DLMs需要更多数据和计算才能达到ALMs的性能水平。

Method: 通过平滑插值掩码扩散和均匀扩散来研究不同噪声类型的DLMs缩放行为，重点关注批量大小和学习率等关键超参数。实验分析了不同噪声类型在计算约束和数据约束下的缩放规律。

Result: DLMs的缩放行为强烈依赖于噪声类型，与ALMs显著不同。所有噪声类型在计算约束下收敛到相似的损失值，但均匀扩散在计算效率训练中需要更多参数和更少数据，在数据受限场景下表现更优。研究将均匀扩散模型扩展到100亿参数，训练了10^22 FLOPs，验证了预测的缩放规律。

Conclusion: 均匀扩散模型在数据受限设置中具有优势，是DLMs中一个有前景的候选方案。研究成功将均匀扩散模型扩展到100亿参数，成为目前已知最大的公开均匀扩散模型，验证了其缩放规律。

Abstract: Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However, their scaling behavior has not yet been fully explored, with prior work suggesting that they require more data and compute to match the performance of ALMs.
  We study the scaling behavior of DLMs on different noise types by smoothly interpolating between masked and uniform diffusion while paying close attention to crucial hyperparameters such as batch size and learning rate. Our experiments reveal that the scaling behavior of DLMs strongly depends on the noise type and is considerably different from ALMs. While all noise types converge to similar loss values in compute-bound scaling, we find that uniform diffusion requires more parameters and less data for compute-efficient training compared to masked diffusion, making them a promising candidate in data-bound settings. We scale our uniform diffusion model up to 10B parameters trained for $10^{22}$ FLOPs, confirming the predicted scaling behavior and making it the largest publicly known uniform diffusion model to date.

</details>


### [155] [UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting](https://arxiv.org/abs/2512.10866)
*Ruslan Gokhman*

Main category: cs.LG

TL;DR: 线性模型在仅使用历史室内温度数据的长期预测任务中优于Transformer系列模型，DLinear表现最佳


<details>
  <summary>Details</summary>
Motivation: 研究在仅使用历史温度数据的单变量设置下进行长期温度预测，这是一个具有挑战性的任务，需要评估不同模型在仅有外生变量情况下的表现

Method: 使用线性模型（Linear、NLinear、DLinear）和Transformer系列模型（Transformer、Informer、Autoformer）在标准化的训练、验证和测试分割下进行对比实验

Result: 线性基线模型（Linear、NLinear、DLinear）在所有分割中始终优于更复杂的Transformer架构，其中DLinear在所有分割中实现了最佳的整体准确率

Conclusion: 精心设计的线性模型在仅使用外生变量的时间序列预测任务中仍然是强大的基线，复杂模型不一定优于简单模型

Abstract: We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under standardized train, validation, and test splits. Results show that linear baselines (Linear, NLinear, DLinear) consistently outperform more complex Transformer-family architectures, with DLinear achieving the best overall accuracy across all splits. These findings highlight that carefully designed linear models remain strong baselines for time series forecasting in challenging exogenous-only settings.

</details>


### [156] [Guided Transfer Learning for Discrete Diffusion Models](https://arxiv.org/abs/2512.10877)
*Julian Kleutgens,Claudio Battiloro,Lingkai Kong,Benjamin Grewe,Francesca Dominici,Mauricio Tec*

Main category: cs.LG

TL;DR: 提出GTL方法，通过引导机制实现离散扩散模型的迁移学习，无需微调预训练模型，并开发高效采样器降低计算成本


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在语言等离散领域表现优异，但需要大量训练数据，迁移到新领域成本高。现有迁移学习方法需要微调大型扩散模型，计算昂贵且不实用

Method: 基于连续扩散的比率迁移学习，提出GTL方法，通过引导机制在不修改预训练去噪器的情况下从目标分布采样。同时开发高效采样器，集中评估规划选择的位置和候选词，降低采样时间和计算

Result: GTL方法适用于离散时间扩散和连续时间基于分数的离散扩散，统一处理。高效采样器使大规模词汇和长序列的引导语言建模变得实用

Conclusion: GTL为离散扩散模型提供了实用的迁移学习方法，无需微调预训练模型，并通过高效采样器解决了大规模应用的计算挑战

Abstract: Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.

</details>


### [157] [SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale](https://arxiv.org/abs/2512.10922)
*Max Zimmer,Christophe Roux,Moritz Wagner,Deborah Hendrych,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 提出一种针对大语言模型的高效剪枝方法，通过行级等稀疏度约束和最优1-swap交换策略，显著降低剪枝误差并提升模型性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型剪枝面临计算成本高的问题，传统方法如全局幅度剪枝在Transformer架构上效果不佳，现有方法依赖近似或启发式算法，需要更高效精确的剪枝方案

Method: 提出行级等稀疏度约束，将问题分解为可管理的子问题；推导出基于校准数据Gram矩阵的高效最优1-swap算法；从任意剪枝掩码开始，在GPU上高效运行

Result: 相比Wanda方法减少高达60%的层级剪枝误差；在多种GPT架构上一致提升困惑度和零样本准确率；算法基本无需超参数调整

Conclusion: 通过行级等稀疏度约束和最优1-swap策略，成功解决了大语言模型剪枝的可扩展性问题，提供了一种高效、精确且易于实现的剪枝方案

Abstract: The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.

</details>


### [158] [Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation](https://arxiv.org/abs/2512.10925)
*Zamirddine Mari,Mohamad Motasem Nawaf,Pierre Drap*

Main category: cs.LG

TL;DR: 本文提出基于PPO算法的深度强化学习方法，用于水下机器人BlueROV2的自主导航，在复杂障碍环境中优于传统DWA方法，并验证了从仿真到真实环境的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 水下环境自主导航面临GPS缺失、能见度差和障碍物等挑战，需要开发鲁棒的导航方法来解决这些问题。

Method: 采用基于PPO算法的深度强化学习方法，结合目标导向导航信息、虚拟占用网格和操作区域边界的射线投射作为观测空间，并与DWA基准方法进行比较。

Result: PPO策略在高度杂乱环境中持续优于DWA方法，具有更好的局部适应性和更少的碰撞，同时验证了从仿真到真实环境的可迁移性。

Conclusion: 深度强化学习对于水下机器人自主导航具有实际应用价值，PPO方法在复杂环境中表现出色，且仿真到真实环境的迁移是可行的。

Abstract: Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.

</details>


### [159] [Decoupled Q-Chunking](https://arxiv.org/abs/2512.10926)
*Qiyang Li,Seohong Park,Sergey Levine*

Main category: cs.LG

TL;DR: 提出一种新算法，通过解耦评论家与策略的动作块长度，让策略在较短动作块上运行，同时保留多步价值传播优势，解决块状评论家策略提取的挑战。


<details>
  <summary>Details</summary>
Motivation: 时间差分方法通过自举机制高效学习状态和动作价值，但容易产生自举偏差。块状评论家通过估计短动作序列价值加速价值备份，但从中提取策略存在挑战：策略必须开环输出整个动作块，这在需要策略反应性的环境中可能次优，且随着块长度增长建模困难。

Method: 提出新算法，将评论家的块长度与策略的块长度解耦，允许策略在较短动作块上操作。通过针对部分动作块的蒸馏评论家优化策略，该蒸馏评论家通过从原始块状评论家乐观自举来近似部分动作块扩展为完整块时可实现的最大价值。

Result: 在具有挑战性的长时域离线目标条件任务上评估该方法，结果显示它可靠地优于先前方法。

Conclusion: 该方法保留了多步价值传播的优势，同时避免了开环次优性和学习长动作块策略的困难，为块状评论家的策略提取提供了有效解决方案。

Abstract: Temporal-difference (TD) methods learn state and action values efficiently by bootstrapping from their own future value predictions, but such a self-bootstrapping mechanism is prone to bootstrapping bias, where the errors in the value targets accumulate across steps and result in biased value estimates. Recent work has proposed to use chunked critics, which estimate the value of short action sequences ("chunks") rather than individual actions, speeding up value backup. However, extracting policies from chunked critics is challenging: policies must output the entire action chunk open-loop, which can be sub-optimal for environments that require policy reactivity and also challenging to model especially when the chunk length grows. Our key insight is to decouple the chunk length of the critic from that of the policy, allowing the policy to operate over shorter action chunks. We propose a novel algorithm that achieves this by optimizing the policy against a distilled critic for partial action chunks, constructed by optimistically backing up from the original chunked critic to approximate the maximum value achievable when a partial action chunk is extended to a complete one. This design retains the benefits of multi-step value propagation while sidestepping both the open-loop sub-optimality and the difficulty of learning action chunking policies for long action chunks. We evaluate our method on challenging, long-horizon offline goal-conditioned tasks and show that it reliably outperforms prior methods. Code: github.com/ColinQiyangLi/dqc.

</details>


### [160] [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://arxiv.org/abs/2512.10931)
*George Yakushev,Nataliia Babina,Masoud Vahid Dastgerdi,Vyacheslav Zhdanovskiy,Alina Shutova,Denis Kuznedelev*

Main category: cs.LG

TL;DR: 提出一种无需额外训练的方法，让具备推理能力的LLM能够同时思考、听取和生成输出，显著减少实时交互延迟


<details>
  <summary>Details</summary>
Motivation: 当前LLM需要先完成思考才能回答，这种顺序交互方式不适用于需要实时响应和适应的语音助手等应用场景。人类可以异步地听、想、说，因此需要让LLM也能实现类似的异步推理能力。

Method: 利用旋转嵌入（rotary embeddings）的特性，使原本设计用于顺序交互的LLM能够同时进行思考、听取和生成输出，无需额外训练。

Result: 在数学推理、常识推理和安全推理任务上评估，该方法能够实时生成准确的思考增强答案，将首个非思考标记的生成时间从几分钟减少到≤5秒，整体实时延迟降低6-11倍。

Conclusion: 通过利用旋转嵌入的特性，成功实现了LLM的异步推理能力，使其能够在实时交互场景中同时思考、听取和生成响应，显著提升了交互效率和实用性。

Abstract: Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to <= 5s. and the overall real-time delays by 6-11x.

</details>


### [161] [Stronger Normalization-Free Transformers](https://arxiv.org/abs/2512.10938)
*Mingzhi Chen,Taiming Lu,Jiachen Zhu,Mingjie Sun,Zhuang Liu*

Main category: cs.LG

TL;DR: 本文提出Derf函数作为归一化层的替代方案，通过大规模搜索发现erf函数变体在多个领域超越现有归一化方法


<details>
  <summary>Details</summary>
Motivation: 尽管归一化层长期以来被视为深度学习架构的必备组件，但最近提出的Dynamic Tanh (DyT)表明存在替代方案。本研究旨在寻找能够超越DyT性能的函数设计，探索点函数的内在特性如何影响训练和性能。

Method: 首先研究点函数的内在特性对训练和性能的影响，然后基于这些发现进行大规模搜索以寻找更有效的函数设计。最终提出Derf(x) = erf(αx + s)，其中erf(x)是重新缩放的高斯累积分布函数。

Result: Derf在多个领域超越了LayerNorm、RMSNorm和DyT，包括视觉（图像识别和生成）、语音表示和DNA序列建模。性能提升主要源于改进的泛化能力而非更强的拟合能力。

Conclusion: Derf的简单性和更强的性能使其成为无归一化Transformer架构的实用选择，为深度学习架构提供了归一化层的有效替代方案。

Abstract: Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\mathrm{Derf}(x) = \mathrm{erf}(αx + s)$, where $\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.

</details>


### [162] [Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952)
*Xiaona Zhou,Yingyan Zeng,Ran Jin,Ismini Lourentzou*

Main category: cs.LG

TL;DR: DaSH方法通过层次化建模数据集和组级效用，在资源约束下优化数据集选择，提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 现实场景中数据通常以离散数据集形式存在，这些数据集在相关性、质量和效用上存在差异。现有方法大多选择单个样本且将所有数据视为同等相关，忽略了数据集及其来源之间的差异，因此需要更有效的数据集选择方法。

Method: 提出DaSH（Dataset Selection via Hierarchies）方法，通过层次化建模同时考虑数据集级别和组级别（如集合、机构）的效用，能够在有限观测下实现高效泛化。

Result: 在两个公开基准测试（Digit-Five和DomainNet）上，DaSH比最先进的数据选择基线方法在准确率上提升高达26.2%，同时需要显著更少的探索步骤。消融实验表明DaSH在低资源设置和相关数据集缺乏的情况下具有鲁棒性。

Conclusion: DaSH方法适用于实际多源学习工作流中的可扩展和自适应数据集选择，能够有效处理异构数据集池中的选择问题。

Abstract: The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.

</details>


### [163] [Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953)
*Yiyang Lu,Qiao Sun,Xianbang Wang,Zhicheng Jiang,Hanhong Zhao,Kaiming He*

Main category: cs.LG

TL;DR: BiFlow是一种双向归一化流框架，通过近似逆映射而非精确解析逆，解决了因果解码瓶颈，在ImageNet上实现了质量提升和百倍加速采样。


<details>
  <summary>Details</summary>
Motivation: 传统归一化流需要精确的解析逆变换，限制了架构灵活性。TARFlow等基于Transformer的自回归流方法虽然复兴了NF，但因果解码成为主要瓶颈，采样速度受限。

Method: 提出BiFlow框架，放弃精确解析逆的要求，学习一个近似噪声到数据的逆映射模型。这允许使用更灵活的损失函数和架构设计，不再受因果解码约束。

Result: 在ImageNet上的实验表明，相比因果解码方法，BiFlow提升了生成质量，同时加速采样达两个数量级（百倍）。在基于NF的方法中达到SOTA，在单次评估方法中具有竞争力。

Conclusion: BiFlow通过近似逆映射解决了NF的因果解码瓶颈，实现了质量与效率的双重提升，有望进一步推动这一经典范式的发展。

Abstract: Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation ("1-NFE") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.

</details>
