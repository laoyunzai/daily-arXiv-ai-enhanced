<div id=toc></div>

# Table of Contents

- [nlin.AO](#nlin.AO) [Total: 1]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 14]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]
- [cs.AI](#cs.AI) [Total: 43]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 8]
- [cs.LG](#cs.LG) [Total: 93]
- [quant-ph](#quant-ph) [Total: 64]


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [1] [Global Phase Synchronization Decoupled from Amplitude Dynamics](https://arxiv.org/abs/2601.01919)
*Koichiro Yawata,Hiroya Nakao*

Main category: nlin.AO

TL;DR: 提出了一种基于Koopman算子理论构建全局保持Kuramoto型相位动力学的耦合振子模型的方法，建立了Kuramoto-Stuart-Landau模型，并构造了具有Lorenz型混沌振幅的相位同步振子。


<details>
  <summary>Details</summary>
Motivation: Kuramoto模型虽然能分析相位同步，但仅限于振子未扰动极限环附近。需要一种方法能够全局保持Kuramoto型相位动力学，同时允许复杂的振幅动力学。

Method: 利用Koopman算子理论定义的相位-振幅坐标，构建耦合振子模型。提出了Kuramoto-Stuart-Landau模型，并构造了三个相位同步但振幅呈现Lorenz型混沌的振子。

Result: 建立了可在远离极限环区域展现非平凡同步动力学的模型，实现了全局相位同步同时保留任意复杂的振幅动力学。该方法适用于一般的极限环系统。

Conclusion: 通过Koopman算子理论，成功扩展了Kuramoto模型的适用范围，实现了全局相位同步与复杂振幅动力学的统一框架，为分析远离极限环的同步现象提供了新工具。

Abstract: The Kuramoto model is a canonical framework for analyzing phase synchronization, yet its utility is restricted to the vicinity of the oscillator's unperturbed limit cycle. Here, we present a method to construct coupled-oscillator models that globally preserve Kuramoto-type phase dynamics by using phase-amplitude coordinates defined via Koopman operator theory. We introduce a solvable model, termed Kuramoto-Stuart-Landau model, which exhibits nontrivial synchronized dynamics far from the limit cycle. We also construct three phase synchronized oscillators whose amplitudes exhibit Lorenz-type chaos. Our method is applicable to general limit-cycle systems, achieving phase synchronization globally while preserving arbitrarily complex amplitude dynamics.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [2] [Identifying recurrent flows in high-dimensional dissipative chaos from low-dimensional embeddings](https://arxiv.org/abs/2601.01590)
*Pierre Beck,Tobias M. Schneider*

Main category: nlin.CD

TL;DR: 提出一种在低维嵌入空间中直接识别不稳定周期轨道（UPOs）的循环收敛算法，利用自动微分学习嵌入函数，在保持吸引子内部结构的同时避免数值积分的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 不稳定周期轨道（UPOs）是时空混沌的非混沌动力学构建块，对湍流理论至关重要，但由于混沌动力学和高维空间离散化的挑战，识别UPOs一直很困难。

Method: 提出循环收敛算法，在混沌吸引子的低维嵌入空间中直接识别UPOs。通过自动微分学习嵌入函数，获得可解释的潜在动力学，避免时间积分的不稳定性，同时保持吸引子的内部结构。

Result: 该方法在模型PDE和2D Navier-Stokes方程中证明了潜在UPOs与物理UPOs的等价性，成功利用高维耗散系统塌缩到低维流形的特性，在低维嵌入中识别UPOs。

Conclusion: 该方法通过结合低维嵌入和循环收敛算法，有效解决了识别UPOs的两个主要挑战（混沌动力学和高维性），为湍流理论提供了一种新的计算框架。

Abstract: Unstable periodic orbits (UPOs) are the non-chaotic, dynamical building blocks of spatio-temporal chaos, motivating a first-principles based theory for turbulence ever since the discovery of deterministic chaos. Despite their key role in the ergodic theory approach to fluid turbulence, identifying UPOs is challenging for two reasons: chaotic dynamics and the high-dimensionality of the spatial discretization. We address both issues at once by proposing a loop convergence algorithm for UPOs directly within a low-dimensional embedding of the chaotic attractor. The convergence algorithm circumvents time-integration, hence avoiding instabilities from exponential error amplification, and operates on a latent dynamics obtained by pulling back the physical equations using automatic differentiation through the learned embedding function. The interpretable latent dynamics is accurate in a statistical sense, and, crucially, the embedding preserves the internal structure of the attractor, which we demonstrate through an equivalence between the latent and physical UPOs of both a model PDE and the 2D Navier-Stokes equations. This allows us to exploit the collapse of high-dimensional dissipative systems onto a lower dimensional manifold, and identify UPOs in the low-dimensional embedding.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [3] [Tuneable skyrmion and anti-skyrmion fluids via mechanical strain in chiral kagome lattice](https://arxiv.org/abs/2601.00982)
*Gonzalo dos Santos,Flavia A. Gómez Albarracín,Ludovic D. C. Jaubert,Pierre Pujol,Eduardo M. Bringa,H. Diego Rosales*

Main category: cond-mat.str-el

TL;DR: 该研究通过自旋晶格动力学和蒙特卡洛模拟，探索了单轴机械应变对kagome晶格上磁性斯格明子稳定性和拓扑相的影响，发现应变可调控斯格明子密度、稳定性和拓扑电荷。


<details>
  <summary>Details</summary>
Motivation: 磁性斯格明子因其在有限温度下的显著稳定性，在自旋电子学应用中具有潜力。实现可控的稳定性和不同拓扑结构之间的转变对于实际应用至关重要。研究机械应变对斯格明子稳定性和拓扑相的影响，为工程化拓扑自旋纹理提供实验可实现的途径。

Method: 采用包含交换相互作用以及面内和面外Dzyaloshinskii-Moriya相互作用的Heisenberg模型，在kagome晶格上进行研究。结合自旋晶格动力学和蒙特卡洛模拟，探索-10%到10%范围内的单轴应变变化。

Result: 压缩应变可调控斯格明子气体相中的斯格明子密度，并提高该相在更高温度下的稳定性。拉伸应变则减少斯格明子数量，促进向其他磁性态的转变。在约4-6%的应变水平下，拓扑电荷发生变化，斯格明子（Q=-1）转变为反斯格明子（Q=+1）。应变还影响螺旋态和完全极化态等其他相的稳定性和特性。

Conclusion: 机械应变是工程化拓扑自旋纹理的实验可及途径，能够调控斯格明子密度、稳定性和拓扑电荷，为自旋电子学应用提供了新的调控手段。

Abstract: Magnetic skyrmions are nanometric swirling spin textures that exhibit remarkable stability at finite temperatures, making them promising candidates for spintronic applications. Achieving controllable stability and transitions between distinct topological structures is crucial for practical implementations. In this work, we investigate the effect of uniaxial mechanical strain on a magnetic model on the kagome lattice, focusing on skyrmion stability and emergent topological phases. To this end, we consider a Heisenberg model that includes exchange interactions and both in-plane and out-of-plane Dzyaloshinskii-Moriya interactions. Using a combination of Spin-Lattice Dynamics and Monte Carlo simulations, we explore uniaxial strain variations in the range of $-10\%$ to $10\%$, showing important effects on the phase diagram. For compressive strain, we find that the density of skyrmions in the skyrmion gas (SkG) phase can be tuned and that the stability of this phase extends to higher temperatures. Tensile strain, in contrast, reduces the number of skyrmions and promotes transitions to other magnetic states. Within this regime, strain levels of about ($\sim4-6\%$) lead to a change in topological charge, turning skyrmions ($Q=-1$) into antiskyrmions ($Q=+1$). We also examine how strain affects other phases commonly appearing in skyrmion-hosting systems, such as the helical and fully polarized states, showing that mechanical deformation alters their stability and characteristic properties. Finally, we compare these results with the strain response of a more conventional skyrmion model, in order to clarify the role of the different interactions involved. Our results identify strain as an experimentally accessible route for engineering topological spin textures.

</details>


### [4] [Spectral Visualization of Excitonic Pair Breaking at Individual Impurities in Ta2Pd3Te5](https://arxiv.org/abs/2601.01096)
*Lianzhi Yang,Deguang Wu,Hanbo Zhang,Yao Zhang,Xiutong Deng,Chao Zhang,Tianyou Zhai,Wenhao Zhang,Youguo Shi,Rui Wang,Chaofei Liu,Ying-Shuang Fu*

Main category: cond-mat.str-el

TL;DR: 该研究通过扫描隧道光谱在激子绝缘体Ta2Pd3Te5中发现Te空位诱导的激子对破坏效应，观察到能隙内的光谱峰，揭示了局域激子解配对现象及其与激子序参数的相互作用。


<details>
  <summary>Details</summary>
Motivation: 激子绝缘体中的电子-空穴对凝聚为研究相关玻色子量子态提供了平台，但宏观相干性如何从局域塌缩配对中产生仍不清楚。研究旨在探索激子绝缘体中的局域对破坏机制。

Method: 使用扫描隧道光谱技术研究Ta2Pd3Te5中的Te空位缺陷，通过光谱映射分析亚能隙态的空间分布和电子结构，结合平均场模型进行理论解释。

Result: 发现单个Te空位在激子能隙内产生一对光谱峰，其能量对缺陷构型和针尖电场敏感；观察到空间各向异性和电子耦合的电子-空穴分量；在强电子-空穴不平衡区域出现次级对破坏效应，表现为能量更低的亚能隙态。

Conclusion: 研究揭示了激子绝缘体中局域激子解配对的光谱"指纹"，为理解激子凝聚的临界行为提供了关键线索，展示了不同激子序参数之间对破坏效应的相互作用。

Abstract: Excitonic insulators host the condensates of bound electron-hole pairs, offering a platform for studying correlated bosonic quantum states. Yet, how macroscopic coherence emerges from locally collapsed pairing remains elusive. Here, using scanning tunnelling spectroscopy, we report the impurity-induced pair breaking in an excitonic insulator Ta2Pd3Te5. Individual Te vacancies are found to generate a pair of spectral peaks within the excitonic gap. Their energies depend sensitively on the defect configurations and are continuously tunable by tip electric field, indicating controllable impurity scatterings. Spectral mapping shows spatially anisotropic and electronically coupled electron-hole components of the subgap states. These observations, together with mean-field modelling, suggest an excitonic pair-breaking origin. In the strongly electron-hole imbalanced region, a secondary pair-breaking effect, manifesting as an additional pair of subgap states with distinctly lower energies, can emerge, presenting the interplay of pairing breakings with different excitonic order parameters. Our findings demonstrate the spectroscopic 'fingerprint' of local excitonic depairing at the atomic level, offering a crucial clue to the critical behavior across excitonic condensation.

</details>


### [5] [Field-Theoretical Construction of Conserved Currents, Non-Invertible Symmetries, and Mixed Anomalies in Three-Dimensional Non-Abelian Topological Order](https://arxiv.org/abs/2601.01523)
*Zhi-Feng Zhang,Yizhou Huang,Qing-Rui Wang,Peng Ye*

Main category: cond-mat.str-el

TL;DR: 该论文研究三维非阿贝尔拓扑序中的广义对称性，特别是非可逆对称性。采用带扭曲项的BF理论描述，识别出两类守恒流：产生可逆高阶对称性的I型流和产生非可逆高阶对称性的II型流，并分析了它们的融合规则和混合反常。


<details>
  <summary>Details</summary>
Motivation: 研究三维非阿贝尔拓扑序中的广义对称性，特别是非可逆对称性，这些对称性在包含粒子和环状激发的拓扑相中具有重要意义。通过拓扑场论框架系统分析这些对称性及其性质。

Method: 采用连续拓扑场论描述，具体是带扭曲项a∧a∧b的扭曲BF理论，规范群为G=∏i ℤ_{N_i}。从运动方程中提取守恒流来识别广义对称性算子。分析两类电流：产生可逆高阶对称性的I型流和产生非可逆高阶对称性的II型流。研究对称性算子的融合规则，并通过耦合多个电流到背景规范场来研究混合反常。

Result: 识别出两类广义对称性：可逆高阶对称性（有逆元）和非可逆高阶对称性（融合通过多个通道）。非可逆性源于伴随对称性算子的投影算子，这些投影子限制允许的规范场构型。发现两种混合反常：一种可通过高一维的拓扑场论消除，另一种代表固有的规范化障碍，编码在(3+1)D连续拓扑场论中。

Conclusion: 在三维非阿贝尔拓扑序中，广义对称性可分为可逆和非可逆两类，非可逆对称性具有多通道融合特性。混合反常分析揭示了拓扑场论中规范化障碍的本质，为理解拓扑相中的对称性结构提供了系统框架。

Abstract: ..In this work, we investigate generalized symmetries, with particular emphasis on non-invertible ones, in three-dimensional non-Abelian topological orders hosting both particle- and loop-like excitations. We adopt a continuum topological field theory description, focusing on twisted $BF$ theories with gauge group $G=\prod_i \mathbb{Z}_{N_i}$ and an $a \wedge a \wedge b$ twisted term. This field theory supports Borromean-Rings braiding and realizes non-Abelian topological order, which for $G=(\mathbb{Z}_2)^3$ admits a microscopic realization via the $\mathbb{D}_4$ Kitaev quantum double lattice model. We systematically identify all generalized symmetry operators by extracting conserved currents from the equations of motion. Two distinct classes of currents emerge: type-I currents, which generate invertible higher-form symmetries, and type-II currents, which give rise to non-invertible higher-form symmetries. The non-invertibility originates from projectors accompanying the symmetry operators, which restrict admissible gauge-field configurations. We further analyze the fusion rules of these symmetries, showing that invertible symmetries admit inverses, while non-invertible symmetries fuse through multiple channels. Finally, we study mixed anomalies among these generalized symmetries by simultaneously coupling multiple currents to proper types of background gauge fields and examining their gaugeability. We identify two types of mixed anomalies: one cancellable by topological field theories in one higher dimension, and another representing an intrinsic gauging obstruction encoded in the $(3+1)$D continuum topological field theory...

</details>


### [6] [Imaging Intermediate Melting Phases of Dual Magnetic-Field-Stabilized Wigner Crystals](https://arxiv.org/abs/2601.01531)
*Chaofei Liu,Jianwang Zhou,Wenao Liao,Zeyu Jiang,Chao Zhang,Tingfei Guo,Tianyou Zhai,Wenhao Zhang,Ying-Shuang Fu,Qi-Kun Xue*

Main category: cond-mat.str-el

TL;DR: 该研究通过扫描隧道显微镜可视化观察了石墨烯上单层VCl3中两个不同维格纳晶体的熔化过程，发现了它们通过不同中间相（向列相和异常电子液体）熔化的微观机制，并建立了包含量子与热涨落的相图。


<details>
  <summary>Details</summary>
Motivation: 尽管在多种二维维格纳平台上有广泛研究，但维格纳晶体通过可能中间相的微观熔化过程仍然很大程度上未知。本研究旨在揭示维格纳晶体熔化的微观机制和中间相。

Method: 使用扫描隧道显微镜（STM）可视化观察石墨烯上单层VCl3中维格纳晶体的熔化过程，结合高磁场稳定技术，并通过第一性原理计算验证界面转移电子的能带选择性占据在双维格纳晶体形成中的作用。

Result: 发现了两个具有不同临界温度Tc和晶格周期的维格纳晶体共存。一个维格纳晶体具有创纪录的高Tc和电子密度，在降低磁场时通过中间向列相熔化；另一个维格纳晶体具有较低Tc，在熔化过程中产生不同的中间相，表现为具有能量无关调制周期的异常电子液体。

Conclusion: 原子级分辨的中间相为维格纳晶体的微观熔化路径提供了关键见解，使得建立由量子涨落和热涨落共同参数化的相图成为可能，深化了对强关联系统中电子结晶和熔化机制的理解。

Abstract: The competition between Coulomb repulsion and kinetic energy in correlated systems can allow electrons to crystallize into Wigner solids. Despite researches across diverse two-dimensional Wigner platforms, the microscopic melting processes through possible intermediate phases remains largely unknown. Here, we present the visualization of electron-lattice melting in monolayer VCl3 on graphite, where two Wigner crystals coexist with markedly different critical temperatures Tc and lattice periods as stabilized by high magnetic field. One Wigner crystal possesses both record-high Tc and electron density, and undergoes melting through an intermediate nematic phase upon decreasing magnetic field. In contrast, the other Wigner crystal with a lower Tc yields a different intermediate phase during melting, exhibiting an anomalous electron liquid with an energy-independent modulation period. First-principles calculations corroborate the band-selective occupations of interface-transferred electrons in the formation of dual Wigner crystals. Our atomically resolved intermediate phases provide crucial insights into the microscopic melting pathways of Wigner crystals, enabling a phase diagram parameterized by both quantum and thermal fluctuations.

</details>


### [7] [Atomic structure and formation mechanism of a newly discovered charge density wave in the m=2 monophosphate tungsten bronze](https://arxiv.org/abs/2601.01606)
*Arianna Minelli,Elen Duverger-Nedellec,Olivier Perez,Alain Pautrat,Adrien Girard,Johnathan Bulled,Marek Mihalkovič,Marc de Boissieu,Alexei Bosak*

Main category: cond-mat.str-el

TL;DR: 在单磷酸钨青铜家族中，m=2成员被认为是唯一在低温下没有电子不稳定性的化合物，但本文发现了其290K的电荷密度波相变。


<details>
  <summary>Details</summary>
Motivation: 单磷酸钨青铜家族中的m=2成员一直被认为是该家族中唯一在低温下没有电子不稳定性的化合物，这一特殊性质需要进一步研究验证。

Method: 通过衍射和电阻率测量确认新相的存在，利用漫散射和非弹性X射线散射研究相变前动力学，分析结构和电子对相变的贡献。

Result: 发现了m=2单磷酸钨青铜中存在电荷密度波相，相变温度为290K，具有非公度调制矢量q=0.245b*+ξc*，观察到明显的科恩异常。

Conclusion: m=2单磷酸钨青铜并非没有电子不稳定性，而是存在290K的电荷密度波相变，为理解该家族化合物的电子性质提供了新视角。

Abstract: The $m$=2 member of the monophosphate tungsten bronze family has been considered the only one in the family without an electronic instability at low temperature. In this paper, we report the discovery of a charge density wave phase in this compound, with a transition temperature of 290 K and an incommensurate modulation vector \textbf{q}=0.245\textbf{b*}+ $\upxi$\textbf{c*}. The presence of this new phase is confirmed by diffraction and resistivity measurements. Pre-transitional dynamics are investigated using diffuse and inelastic x-ray scattering, revealing a clear Kohn anomaly. We analyze both structural and electronic contributions to the phase transition, providing a comprehensive picture of the mechanism driving this newly identified instability.

</details>


### [8] [Pseudospin Formulation of Quench Dynamics in the Semiclassical Holstein Model](https://arxiv.org/abs/2601.01694)
*Lingyu Yang,Ho Jang,Sankha Subhra Bakshi,Yang Yang,Gia-Wei Chern*

Main category: cond-mat.str-el

TL;DR: 该研究使用赝自旋方法分析了半填充无自旋Holstein模型中电荷密度波序参量的淬火后动力学，揭示了三种不同的动力学区域，并强调了晶格动力学对非平衡有序相的重要作用。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解电子-晶格耦合系统中电荷密度波序参量的非平衡动力学，特别是晶格自由度如何影响淬火后的长时行为，区别于纯电子系统的动力学特征。

Method: 采用Anderson赝自旋描述方法，对半填充无自旋Holstein模型在方晶格上进行数值模拟，假设空间均匀演化，研究淬火后电荷密度波序参量的动力学。

Result: 数值模拟揭示了三种不同的动力学区域：锁定振荡、Landau阻尼动力学和过阻尼弛豫。关键发现是晶格动力学导致CDW振荡不会完全衰减，而是持续存在，并表现出非平衡电子分布特征。

Conclusion: 晶格动力学在非平衡有序相中起着关键作用，电子-晶格驱动的CDW动力学与纯电子对应物存在本质区别，晶格场的反馈导致振荡持续存在而非完全衰减。

Abstract: We present a pseudospin formulation for the post-quench dynamics of charge-density-wave (CDW) order in the half-filled spinless Holstein model on a square lattice, assuming spatially homogeneous evolution. This Anderson pseudospin description captures the coherent nonequilibrium dynamics of the coupled electron-lattice system. Numerical simulations reveal three distinct dynamical regimes of the CDW order parameter following a quench-locked oscillations, Landau-damped dynamics, and overdamped relaxation-closely paralleling quench dynamics in BCS superconductors and other electronically driven symmetry-breaking phases. Crucially, however, the presence of dynamical lattice degrees of freedom leads to qualitatively different long-time behavior. In particular, while the oscillation amplitude is reduced in the damped regimes, CDW oscillations do not fully decay but instead persist indefinitely due to feedback from the lattice field. We further show that these persistent oscillations are characterized by a nonequilibrium electronic distribution, which provides an intuitive understanding of both their amplitude and the renormalization of the oscillation frequency relative to the bare Holstein phonon frequency. Our results highlight the essential role of lattice dynamics in nonequilibrium ordered phases and establish a clear distinction between electron-lattice-driven CDW dynamics and their purely electronic counterparts.

</details>


### [9] [Electronic Nematicity Revealed by Polarized Ultrafast Spectroscopy in Bilayer La$_3$Ni$_2$O$_7$](https://arxiv.org/abs/2601.01702)
*Qi-Yi Wu,De-Yuan Hu,Chen Zhang,Hao Liu,Bo Chen,Ying Zhou,Zhong-Tuo Fu,Chun-Hui Lv,Zi-Jie Xu,Hai-Long Deng,Meng-Wu Huo,H. Y. Liu,Jun Liu,Yu-Xia Duan,Dao-Xin Yao,Meng Wang,Jian-Qiao Meng*

Main category: cond-mat.str-el

TL;DR: 双层La₃Ni₂O₇和三层La₄Ni₃O₁₀镍酸盐在正常态电子动力学对比研究：双层体系表现出明显的电子向列性（C₂对称性各向异性），而三层体系保持各向同性响应，表明电子向列涨落与双层体系超导配对密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究双层和三层镍酸盐体系在正常态的电子动力学差异，特别是探索电子向列性（nematicity）与超导配对之间的潜在关联。通过对比不同层数体系的对称性性质，揭示电子向列涨落在超导机制中的作用。

Method: 采用偏振超快泵浦-探测技术，在常压下研究双层La₃Ni₂O₇和三层La₄Ni₃O₁₀单晶的正常态电子动力学。通过测量温度依赖的光学响应，分析准粒子弛豫瓶颈、有效能隙尺度以及对称性性质。

Result: 1. 两个体系都表现出密度波转变和准粒子弛豫瓶颈打开；2. La₄Ni₃O₁₀在整个温度范围内保持各向同性光学响应；3. La₃Ni₂O₇在低温下表现出明显的二重（C₂）对称性各向异性（电子向列性）；4. 双层体系的电子向列性与115K以下出现的次级各向同性序相互竞争；5. 双层体系存在宏观电子各向异性而三层体系没有。

Conclusion: 双层La₃Ni₂O₇中存在的电子向列性及其与三层La₄Ni₃O₁₀的对比表明，电子向列涨落与双层体系的超导配对机制密切相关，值得进一步深入探索。

Abstract: We report a polarized ultrafast pump-probe study of the normal-state electronic dynamics in bilayer La$_3$Ni$_2$O$_7$ and trilayer La$_4$Ni$_3$O$_{10}$ single crystals at ambient pressure. While both nickelates exhibit density-wave (DW) transitions accompanied by the opening of a quasiparticle relaxation bottleneck, their electronic responses display strikingly different symmetry properties. La$_4$Ni$_3$O$_{10}$ maintains an isotropic optical response across the entire temperature range. In contrast, La$_3$Ni$_2$O$_7$ exhibits a pronounced twofold ($C_2$) anisotropy in its low-temperature electronic dynamics. This electronic nematicity, evident in both the relaxation dynamics and the effective gap scales, competes with a secondary isotropic order emerging below 115 K. The presence of macroscopic electronic anisotropy in the bilayer system, and its absence in the trilayer system, suggests an intimate relation between electronic nematic fluctuations and superconducting pairing in La$_3$Ni$_2$O$_7$ that worth for deeper explorations.

</details>


### [10] [Emergent Anomalous Hall Effect in the Eu-Based Compound with a Diamond Network: The Centrosymmetric Cubic Antiferromagnet EuTi$_2$Al$_{20}$](https://arxiv.org/abs/2601.01788)
*Ryuji Higashinaka,Kohsuke Sato,Ryosei Ideura,Masahiro Kawamata,Tatsuma D. Matsuda*

Main category: cond-mat.str-el

TL;DR: EuTi2Al20在磁场诱导相II中表现出增强且场无关的电阻率和霍尔电阻率，这与传统斯格明子晶格相的方向选择性行为不同，可能具有不同的拓扑自旋结构。


<details>
  <summary>Details</summary>
Motivation: 研究EuTi2Al20化合物在磁场诱导相II中的电子输运特性，探索其与已知斯格明子晶格相的区别，以理解其独特的拓扑自旋结构。

Method: 通过测量EuTi2Al20在不同磁场方向下的电阻率和霍尔电阻率，分析磁场诱导相II中的电子输运行为，并与传统斯格明子晶格相进行比较。

Result: 在相II中，电阻率和霍尔电阻率都显著增强，且在该相内几乎与磁场无关；这种输运响应在所有磁场方向都存在，但表现出适度的方向依赖性，与传统斯格明子晶格相的强方向选择性行为不同。

Conclusion: EuTi2Al20的磁场诱导相II可能具有与传统斯格明子晶格不同的拓扑自旋结构，其独特的电子输运特性表明可能存在一种新型的拓扑自旋纹理。

Abstract: The centrosymmetric cubic compound EuTi$_2$Al$_{20}$, in which magnetic Eu ions form a diamond network, undergoes an antiferromagnetic transition at T$_N$ = 3.3 K and exhibits metamagnetic transitions at H$_{m1}$ = 1.7 T and H$_{m2}$ = 2.8 T for H || [100] at 1.9 K. Between these fields, the magnetization shows a step-like behavior, defining an intermediate field-induced phase (Phase~II). We investigated the electronic transport in Phase~II and found that both the resistivity and Hall resistivity are markedly enhanced, while remaining nearly field independent within the phase. Phase~II appears for all field directions, although its transport response shows moderate directional dependence. These features differ from the strongly orientation-selective behavior often observed in skyrmion-lattice phases of several 4f-electron compounds, suggesting that Phase II may host a field-induced spin texture with a topological character distinct from that of a conventional skyrmion lattice.

</details>


### [11] [Multiple nodal superconducting phases and order-parameter evolution in pressurized UTe$_2$](https://arxiv.org/abs/2601.01843)
*Shuo Zou,Fengrui Shi,Zhuolun Qiu,Jialong Zhang,Yan Zhang,Weilong Qiu,Zhuo Wang,Hai Zeng,Yinina Ma,Zheyu Wu,Andrej Cabala,Michal Valiska,Ning Li,Zihan Yang,Kaixin Ye,Jiawen Zhang,Yanan Zhang,Kangjian Luo,Binbin Zhang,Alexander G. Eaton,Chaofan Zhang,Gang Li,Jianlin Luo,Wen Huang,Huiqiu Yuan,Xin Lu,Yongkang Luo*

Main category: cond-mat.str-el

TL;DR: 通过点接触谱学测量加压UTe₂，发现安德列夫束缚态表明超导序参量存在p_z分量，确定B_{2u}或B_{3u}为最可能的对称性表示，多个超导相可通过p_z波与p_{x(y)}波配对相对权重区分。


<details>
  <summary>Details</summary>
Motivation: 自旋三重态超导为实现非阿贝尔马约拉纳零模和容错拓扑量子计算提供了独特途径。UTe₂作为重费米子自旋三重态超导候选材料，具有极高的上临界场和近场极化磁态的再入超导相，但其超导序参量及随控制参数的演化尚不清楚，主要缺乏适当的对称性敏感探测手段。

Method: 在(0 0 1)表面进行全面的点接触谱学测量，基于扩展的Blonder-Tinkham-Klapwijk模型进行定量分析，通过安德列夫束缚态探测超导序参量的对称性特征。

Result: 观察到安德列夫束缚态强烈表明超导序参量存在p_z分量；定量分析揭示B_{2u}或B_{3u}是常压和加压UTe₂最可能的对称性表示；多个超导相可通过单一参数⟨Δ_z⟩/⟨Δ_{x(y)}⟩（p_z波与p_{x(y)}波配对的相对权重）区分。

Conclusion: 这些发现不仅对UTe₂的超导序参量施加了严格约束，还为通过压力调谐的多个超导相的存在提供了关键谱学证据，有助于理解自旋三重态超导的物理机制。

Abstract: Spin-triplet superconductivity (SC) offers a unique avenue for realizing non-Abelian Majorana zero modes and thus the fault-tolerant topological quantum computation, and has attracted a broad audience for both fundamental research and potential applications. The recently discovered heavy-fermion spin-triplet superconductor candidate UTe$_2$ has sparked great interest for its ultrahigh upper critical field and reentrant SC phases in the proximity to a field-polarized magnetic state. Despite extensive studies on the phase diagrams and competing orders induced by pressure and magnetic field, limited has been known about its SC order parameters and their evolution with these control parameters, largely due to the lack of appropriate symmetry-sensitive detections. Here, we report comprehensive point-contact spectroscopy measurements of pressurized UTe$_2$ on the (0~0~1) surface. The observation of Andreev bound state strongly suggests the presence of a $p_z$ component in the SC order parameters. Quantitative analysis based on an extended Blonder-Tinkham-Klapwijk model unveils $B_{2u}$ or $B_{3u}$ as the most likely representation for both ambient and pressurized UTe$_2$, and remarkably, the multiple SC phases can be distinguished by a single parameter $\langle Δ_{z}\rangle/\langleΔ_{x(y)}\rangle$, the relative weight between the $p_z$-wave and $p_{x(y)}$-wave pairings. These findings not only impose stringent constraints on the superconducting order parameter in UTe$_2$, but also provide key spectroscopic evidence for the existence of multiple SC phases tuned through pressure.

</details>


### [12] [Emergent Spin Supersolids in Frustrated Quantum Materials](https://arxiv.org/abs/2601.01890)
*Yixuan Huang,Seiji Yunoki,Sadamichi Maekawa*

Main category: cond-mat.str-el

TL;DR: 该综述总结了受挫三角晶格量子反铁磁体中自旋超固态的最新研究进展，包括实验证据、理论模型、相图特征以及潜在应用前景。


<details>
  <summary>Details</summary>
Motivation: 自旋超固态作为超越固体氦背景的新型量子态，在受挫量子磁体中涌现，为研究超固态性提供了材料平台。该领域研究不仅具有基础科学价值，还在高效退磁冷却和自旋输运方面展现出应用潜力。

Method: 通过综述方式，综合热力学和光谱学实验证据，结合最小模型的理论研究，分析全局相图、基态性质和集体激发。同时讨论特征性自旋输运现象。

Result: 实验和数值研究揭示了自旋超固态的相干且内部一致图像，加深了对量子磁性材料中超固态性的理解。在候选材料中观测到巨大的磁热效应，支持高效退磁冷却应用，无耗散自旋超流为自旋输运和自旋电子学应用开辟前景。

Conclusion: 自旋超固态作为功能量子材料具有重要研究价值，未来需要进一步探索其特性，为量子磁性材料的基础研究和应用开发提供新方向。

Abstract: Recent years have witnessed the emergence of spin supersolids in frustrated quantum magnets, establishing a material-based platform for supersolidity beyond its original context in solid helium. A spin supersolid is characterized by the coexistence of longitudinal spin order that breaks lattice translational symmetry and transverse spin order associated with the spontaneous breaking of a spin U(1) symmetry. Extensive experimental investigations, together with advanced numerical studies, have now revealed a coherent and internally consistent picture of these phases, substantially deepening our understanding of supersolidity in quantum magnetic materials. Beyond their fundamental interest as exotic quantum states, potential applications in highly efficient demagnetization cooling have been supported by a giant magnetocaloric effect observed in candidate materials. Moreover, the possible dissipationless spin supercurrents could open promising perspectives for spin transport and spintronic applications. In this Review, we summarize recent progress on emergent spin supersolids in frustrated triangular-lattice quantum antiferromagnets. We survey experimental evidence from thermodynamic and spectroscopic measurements and compare these results with theoretical studies of minimal models addressing global phase diagrams, ground state properties, and collective excitations. In addition, we discuss characteristic spin-transport phenomena and outline future directions for exploring spin supersolids as functional quantum materials.

</details>


### [13] [Spin-correlation Driven Ferroelectric Quantum Criticality in a Perovskite Quantum Spin-liquid System, Ba3CuSb2O9](https://arxiv.org/abs/2601.01906)
*Sayan Ghosh,Gourab Roy,Ekta Kushwaha,Mohit Kumar,Tathamay Basu*

Main category: cond-mat.str-el

TL;DR: 在量子自旋液体材料Ba3CuSb2O9中首次实验观测到自旋关联驱动的铁电量子临界性，该材料表现出量子顺电行为而非铁电有序，同时保持反铁磁量子临界涨落特征。


<details>
  <summary>Details</summary>
Motivation: 探索量子自旋液体系统中自旋动力学与极性晶格之间的强相互作用，寻找罕见的铁电量子临界现象，为理解量子材料中的多体相互作用提供新视角。

Method: 实验研究Ba3CuSb2O9的介电常数和磁化率随温度的变化关系，分析其标度行为，结合已知的自旋-轨道-晶格纠缠特性进行综合分析。

Result: 介电常数遵循T²标度，表明材料表现为量子顺电体；磁化率倒数显示T³/²依赖关系，证明存在反铁磁量子临界涨落；系统在1.8K以下仍保持长程无序，显示出量子自旋液体特征。

Conclusion: 该研究首次在量子自旋液体系统中观测到自旋关联驱动的铁电量子临界性，表明钙钛矿自旋液体家族在这一领域处于前沿地位，通过化学/外部压力调控可展现丰富的物理特性。

Abstract: Here we have experimentally demonstrated spin-correlation-driven ferroelectric quantum criticality in a prototype quantum spin-liquid system, Ba3CuSb2O9, a quantum phenomenon rarely observed. The dielectric constant follows a clear T2 scaling, showing that the material behaves as a quantum paraelectric without developing ferroelectric order. Magnetically, the system avoids long-range order down to 1.8 K and instead displays a T3/2 dependence in its inverse susceptibility, a hallmark of antiferromagnetic quantum critical fluctuations. Together with known spin-orbital-lattice entanglement in this compound, these signatures point to a strong interplay between spin dynamics and the polar lattice. Our results place this perovskite spin-liquid family at the forefront of this domain and suggest the flexibility of this family in a suitable environment by tuning chemical/ external pressure.

</details>


### [14] [Magnetoelastic properties in the high-temperature magnetic phase of the skyrmion compound GdRu$_2$Si$_2$](https://arxiv.org/abs/2601.01977)
*J. Sourd,D. A. Mayoh,G. Balakrishnan,M. Uhlarz,J. Wosnitza,S. Zherlitsyn*

Main category: cond-mat.str-el

TL;DR: 研究了GdRu2Si2单晶在[001]和[110]方向磁场下的磁弹性性质，发现了与复杂相图一致的声速异常，重点关注高温区新磁相，建立了描述弹性响应的朗道理论和微观模型。


<details>
  <summary>Details</summary>
Motivation: 研究GdRu2Si2单晶的磁弹性性质，特别是关注该化合物高温区域新发现的磁相，探索其在不同磁场方向下的稳定性差异。

Method: 对GdRu2Si2单晶施加沿[001]和[110]方向的磁场，测量声速变化；引入朗道理论和微观玩具模型描述零场下的弹性响应；通过不同声学模式的异常响应分析磁结构。

Result: 发现一系列与先前相图一致的强声速异常；高温磁相对[001]方向磁场敏感易被破坏，而对[110]方向磁场相对稳定；通过理论模型定性重现了不同声学模式的异常，提出了该高温磁相的可能磁结构。

Conclusion: 通过实验和理论分析，揭示了GdRu2Si2高温磁相在不同磁场方向下的稳定性差异，并提出了该磁相的磁结构模型，为理解该化合物的复杂磁行为提供了新见解。

Abstract: We investigated the magnetoelastic properties of a GdRu$_2$Si$_2$ single crystal under a magnetic field applied along the crystallographic [001] and [110] directions. We report a series of strong anomalies in the sound velocity that is consistent with the complex phase diagram reported previously for this compound. In particular, in our study we focus on the recently identified magnetic phase in the high-temperature region. We show that while this phase is easily destroyed for magnetic fields applied along [001], it is rather stable for fields along [110]. Furthermore, we introduce a Landau theory and a microscopic toy model describing the elastic response at zero field. We reproduce qualitatively the observed anomalies for different acoustic modes, which allows us to propose a magnetic structure for this new high-temperature phase.

</details>


### [15] [Instabilities of the Fractionalized Dirac Semimetal in the Kitaev-Kondo Model](https://arxiv.org/abs/2601.02110)
*Jennifer Lin,Frank Krüger*

Main category: cond-mat.str-el

TL;DR: 研究蜂窝状Kondo晶格模型中狄拉克传导电子与自旋-1/2 Kitaev量子自旋液体耦合的物理性质，发现弱Kondo耦合下系统倾向于反铁磁有序而非超导


<details>
  <summary>Details</summary>
Motivation: 探索狄拉克传导电子与Kitaev量子自旋液体耦合系统的物理行为，理解分数化费米液体的稳定性及其向有序相的转变

Method: 采用蜂窝状Kondo晶格模型，通过积分掉visons获得有效电子-电子相互作用，使用微扰重整化群分析低能场理论

Result: 在临界点电子与Majorana费米子解耦，所有三种电子相互作用获得正值；分数化费米液体变得不稳定，倾向于反铁磁有序，超导被抑制

Conclusion: 狄拉克传导电子与Kitaev量子自旋液体耦合的系统在弱Kondo耦合下倾向于形成反铁磁有序，而非超导相

Abstract: We study a honeycomb Kondo lattice model in which Dirac conduction electrons are coupled to a spin-1/2 Kitaev quantum spin liquid. For weak Kondo coupling, the spins fractionalize into Majorana fermions comprising a gapless Dirac mode and three gapped visons. Integrating out the visions to second order in the Kondo coupling yields effective electron-electron interactions, including a local Hubbard repulsion, a spin-spin interaction whose sign depends on the Kitaev exchange, and a vertex coupling electrons to Majorana fermions. We analyze the resulting low-energy field theory using a perturbative renormalization group (RG) scheme, accounting for additional density-density interactions generated under RG. At criticality, electrons decouple from Majorana fermions but all three electron interactions acquire positive values. An analysis of susceptibility exponents reveals that the fractionalized Fermi liquid becomes unstable towards antiferromagnetic order and that superconductivity is disfavored.

</details>


### [16] [Electronic correlations and topology in Kondo insulator PuB$_6$](https://arxiv.org/abs/2601.02312)
*K. Gofryk,S. Zhou,N. Poudel,N. Dice,D. Murray,T. Pavlov,C. Marianetti*

Main category: cond-mat.str-el

TL;DR: PuB6被证明是具有拓扑性质的近藤绝缘体，通过低温磁输运测量和第一性原理计算验证了其拓扑近藤绝缘态特征，包括电阻率从高温热激活行为到低温平台态的转变，以及表面-体积依赖关系。


<details>
  <summary>Details</summary>
Motivation: 先前理论研究表明PuB6是强关联拓扑绝缘体，具有非平凡的Z2拓扑不变量和金属表面态。本研究旨在通过实验和理论计算验证PuB6是否确实表现出拓扑近藤绝缘体的特征。

Method: 采用低温磁输运测量实验和第一性原理计算相结合的方法。理论计算使用GGA+U方法，相比之前的DMFT/DFT方法计算成本更低，但仍能准确描述PuB6的电子、拓扑和晶格性质。

Result: 实验观察到PuB6表现出拓扑近藤绝缘体的典型特征：1）电阻率从高温热激活行为（窄带隙约20 meV）转变为独特的低温平台态；2）低温下电阻率表现出表面-体积依赖关系。理论计算进一步支持了PuB6的拓扑性质。

Conclusion: PuB6被确认为拓扑近藤绝缘体，其拓扑性质通过低温输运实验和GGA+U理论计算得到验证。GGA+U方法能够以比DMFT更低的计算成本准确描述PuB6的电子、拓扑和晶格特性。

Abstract: Utilizing a combination of dynamical mean field theory and density functional theory (DMFT/DFT), it has been theoretically proposed that PuB$_6$ is a strongly correlated topological insulator characterized by nontrivial $\mathbf{Z}_{2}$ topological invariants and metallic surface states (\textit{X. Deng et al., Phys. Rev. Lett. 111, 176404 (2013)}). Here, we demonstrate through low-temperature magneto-transport measurements and first-principles calculations that PuB$6$ exhibits characteristics of a topological Kondo insulating state. These features include a transition in electrical resistivity from high-temperature, thermally activated behavior with a narrow gap at the Fermi level ($Δρ \sim$ 20 meV) to a distinctive low-temperature plateau, as well as a surface-to-volume dependence of electrical resistivity at low temperatures. The topological nature of PuB$_6$ is further supported by the theoretical calculations, which show that GGA+$U$ is capable of capturing electronic, topological, and lattice properties of PuB$_6$ with much lower computational cost than DMFT.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [17] [Simulating diffusion and disorder-induced localization in random walks and transmission lines](https://arxiv.org/abs/2601.01381)
*Jake S. Bobowski*

Main category: cond-mat.dis-nn

TL;DR: 该研究通过两个互补的模拟探索安德森局域化现象：一个模拟经典非相互作用点粒子的随机行走，另一个模拟电磁脉冲在具有随机变化传播常数和特性阻抗的一维无损传输线中的传播。


<details>
  <summary>Details</summary>
Motivation: 研究安德森局域化现象，这是一种在无序介质中由于多重散射干涉导致波扩散被抑制的现象。旨在为教学环境提供直观理解该复杂物理现象的工具。

Method: 采用两种互补的模拟方法：1）经典非相互作用点粒子的随机行走模拟，展示无序如何限制输运；2）电磁脉冲在一维无损传输线中的传播模拟，传输线具有沿长度随机变化的传播常数和特性阻抗，捕捉导致真正安德森局域化的干涉效应。

Result: 通过定量测量揭示了从正常扩散到局域化的转变：在粒子模拟中观察到扩散受限，在波传播模拟中观察到波能量的指数局域化。两种模拟共同提供了研究局域化现象的可访问工具。

Conclusion: 这两个互补的模拟为教学环境提供了一对研究局域化现象的有效工具，分别从经典粒子输运和波干涉的角度直观展示了安德森局域化的物理机制。

Abstract: We present two complementary simulations that lead to an exploration of Anderson localization, a phenomenon in which wave diffusion is suppressed in disordered media by interference from multiple scattering. To build intuition, the first models the random walk of classical, non-interacting point-like particles, providing a clear analogy to the way disorder can limit transport. The second examines the propagation of an electromagnetic pulse through a one-dimensional, lossless transmission line with randomly varying propagation constant and characteristic impedance along its length, a system that captures the interference effects essential for true Anderson localization. We evaluate quantitative measures that reveal the transition from normal diffusion to localization of particles in one case, and the exponential confinement of wave energy in the other. Together, these simulations offer a pair of accessible tools for investigating localization phenomena in an instructional setting.

</details>


### [18] [Exact Mobility Edges in a Disorder-Free Dimerized Stark Lattice with Effective Unbounded Hopping](https://arxiv.org/abs/2601.02259)
*Yunyao Qi,Heng Lin,Quanfeng Lu,Dong Ruan,Gui-Lu Long*

Main category: cond-mat.dis-nn

TL;DR: 提出了一种无无序一维单粒子哈密顿量，具有精确的迁移率边，通过在线性斯塔克势中选择性作用于二聚体链的一个子晶格，产生具有无界交错跳跃幅度的有效哈密顿量。


<details>
  <summary>Details</summary>
Motivation: 传统上，迁移率边通常与无序系统相关，但本文旨在探索无无序系统中是否存在精确的迁移率边，突破现有no-go定理的限制。

Method: 通过在线性斯塔克势中选择性作用于二聚体链的一个子晶格，构建具有无界交错跳跃幅度的有效哈密顿量。在倒易空间中解析推导体谱，识别迁移率边，并通过逆参与率的有限尺寸标度验证扩展态的存在。

Result: 发现了一个尖锐的迁移率边，将扩展态连续谱与两个不同的局域分支分开：标准的无界Wannier-Stark梯子和异常的有界分支。扩展态的存在得到了系统尺寸高达L~10^9的逆参与率有限尺寸标度的支持。

Conclusion: 该模型突破了Simon-Spencer定理和Jacobi矩阵的约束，提出了使用光子频率合成维度的实验实现方案，并且迁移率边对实验缺陷具有鲁棒性，为在无无序系统中观察迁移率边提供了实用路径。

Abstract: We propose a disorder-free one-dimensional single-particle Hamiltonian hosting an exact mobility edge (ME), placing the system outside the assumptions of no-go theorems regarding unbounded potentials. By applying a linear Stark potential selectively to one sublattice of a dimerized chain, we generate an effective Hamiltonian with unbounded, staggered hopping amplitudes. The unbounded nature of the hopping places the model outside the scope of the Simon-Spencer theorem, while the staggered scaling allows it to evade broader constraints on Jacobi matrices. We analytically derive the bulk spectrum in reciprocal space, identifying a sharp ME where the energy magnitude equals the inter-cell hopping strength. This edge separates a continuum of extended states from two distinct localized branches: a standard unbounded Wannier-Stark ladder and an anomalous bounded branch accumulating at the ME. The existence of extended states is supported by finite-size scaling of the inverse participation ratio up to system sizes $L \sim 10^9$. Furthermore, we propose an experimental realization using photonic frequency synthetic dimensions. Our numerical results indicate that the ME is robust against potential experimental imperfections, including frequency detuning errors and photon loss, establishing a practical path for observing MEs in disorder-free systems.

</details>


### [19] [Strong Disorder Renormalization Group Method for Bond Disordered Antiferromagnetic Quantum Spin Chains with Long Range Interactions: Excited States and Finite Temperature Properties](https://arxiv.org/abs/2509.17828)
*Stefan Kettemann*

Main category: cond-mat.dis-nn

TL;DR: 该论文将强无序重整化群方法扩展到研究激发态和有限温度性质，应用于短程和幂律长程耦合的自旋链系统，分析了耦合符号分布和有限温度下的磁化率、纠缠等性质。


<details>
  <summary>Details</summary>
Motivation: 将强无序重整化群方法从基态研究扩展到激发态和有限温度性质的研究，以更好地理解无序反铁磁幂律耦合量子自旋链在有限温度下的行为。

Method: 扩展强无序重整化群方法到实空间，应用于短程耦合自旋链和幂律长程相互作用系统，推导主方程，分析耦合符号分布和振幅分布。

Result: 短程耦合系统的耦合绝对值分布为无限随机固定点分布，但耦合符号呈分布状态且负耦合数量随温度增加；幂律长程系统的耦合振幅分布为有限宽度2α的强无序分布；推导了两种系统的有限温度性质。

Conclusion: 成功将强无序重整化群方法扩展到有限温度性质研究，揭示了无序自旋系统中耦合符号分布和温度依赖性的重要特征，为理解这类系统的热力学和纠缠性质提供了新工具。

Abstract: We extend the recently introduced strong disorder renormalization group method in real space, well suited to study bond disordered antiferromagnetic power law coupled quantum spin chains, to study excited states, and finite temperature properties. First, we apply it to a short range coupled spin chain, which is defined by the model with power law interaction, keeping only interactions between adjacent spins. We show that the distribution of the absolute value of the couplings is the infinite randomness fixed point distribution. However, the sign of the couplings becomes distributed, and the number of negative couplings increases with temperature $T.$ Next, we derive the Master equation for the power law long range interaction between all spins with power exponent $α$. While the sign of the couplings is found to be distributed, the distribution of the coupling amplitude is given by the strong disorder distribution with finite width $2α,$ with small corrections for $α>2$. Resulting finite temperature properties of both short and power law long ranged spin systems are derived, including the magnetic susceptibility, concurrence and entanglement entropy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

TL;DR: 本文提出了一种基于嵌入余弦相似度的跨语言本体对齐系统，通过创新描述生成技术丰富本体实体上下文，使用微调的多语言Transformer模型生成更好嵌入，在OAEI-2022多语言农场赛道取得71% F1分数，比最佳基线提升16%。


<details>
  <summary>Details</summary>
Motivation: 跨语言本体对齐面临语义差异挑战，传统方法难以捕捉跨语言相似性。需要开发能够理解多语言上下文并准确匹配本体实体的系统。

Method: 1. 使用创新技术为ontology实体生成丰富描述；2. 采用微调的多语言Transformer模型生成高质量嵌入；3. 基于余弦相似度匹配正样本实体对；4. 应用阈值过滤保留高度相似实体。

Result: 在OAEI-2022 multifarm track评估数据集上获得71% F1分数（78%召回率，65%精确率），比最佳基线提升16%。

Conclusion: 提出的对齐流程能够有效捕捉跨语言相似性，通过丰富实体描述和优化嵌入表示显著提升了跨语言本体对齐性能。

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [21] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

TL;DR: MathLedger是一个可验证机器学习认知平台，将形式验证、密码学证明和学习动态集成到单一认知循环中，旨在解决AI系统不透明和不可验证的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然性能卓越，但缺乏透明度和可验证性，这在安全关键部署中造成了信任危机。需要一种能够提供可验证认知的解决方案。

Method: 采用反射式形式学习（RFL），这是一种符号化的梯度下降类似方法，通过验证器结果而非统计损失来驱动更新。系统集成了形式验证、密码学证明和学习动态，并包含故障关闭治理机制。

Result: 第一阶段实验验证了测量和治理基础设施在受控条件下的有效性：CAL-EXP-3验证了测量基础设施（Delta p计算、方差跟踪）；压力测试确认了故障关闭治理在超出边界条件下正确触发。未提出收敛性或能力声明。

Conclusion: 该工作的贡献是基础设施性的：提供了一个可大规模审计的账本证明学习原型系统，为可验证机器学习认知奠定了基础。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [22] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

TL;DR: 本文提出了一种基于Agentic AI框架的自主信用风险评估系统，通过多智能体协作、强化学习、自然语言推理和可解释AI模块实现实时、透明的信用决策，相比传统模型在决策速度、透明度和响应性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 金融服务快速数字化导致对自主、透明、实时的信用风险决策系统需求迫切。传统机器学习模型虽在模式识别上有效，但缺乏现代金融运营所需的适应性推理、情境感知和自主性。

Method: 提出Agentic AI框架，构建多智能体系统，包含强化学习、自然语言推理、可解释AI模块和实时数据吸收管道。系统包括智能体协作协议、风险评分引擎、可解释性层和持续反馈学习循环。

Result: 研究发现该系统在决策速度、透明度和响应性方面优于传统信用评分模型。但仍存在模型漂移风险、高维数据解释不一致、监管不确定性以及低资源环境基础设施限制等实际限制。

Conclusion: 所提系统具有变革信用分析的巨大潜力。未来研究应关注动态监管合规机制、新型智能体协作、对抗鲁棒性以及在跨国信用生态系统中的大规模实施。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [23] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

TL;DR: CogCanvas是一个无需训练的框架，通过从对话轮次中提取认知构件并组织成时序感知图，解决大语言模型在长对话中上下文窗口限制和信息保真度的矛盾。


<details>
  <summary>Details</summary>
Motivation: 大语言模型面临上下文窗口限制与长对话信息保真度的根本矛盾。现有方法（截断和摘要）要么丢弃早期信息，要么丢失细节。

Method: 引入CogCanvas框架，从对话轮次中提取基于原文的认知构件（决策、事实、提醒），并将其组织成时序感知图，实现抗压缩检索。

Result: 在LoCoMo基准测试中，CogCanvas达到34.7%总体准确率，优于RAG（25.6%）和GraphRAG（13.7%）。时序推理优势最明显：31.5% vs. 9.3%（RAG）和5.0%（GraphRAG）。多跳因果推理通过率81.0% vs. GraphRAG的40.0%。

Conclusion: 虽然经过专门训练的方法（如EverMemOS约92%）能达到更高绝对分数，但CogCanvas无需训练的方法为实践者提供了可立即部署的替代方案，显著优于标准基线。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [24] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

TL;DR: 本文提出在大型推理模型系统中，通过方差感知的路由和调度策略来优化能源效率，在临界状态下平衡基线能源和辅助能源的使用。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型具有异质的推理能耗，系统性能取决于平均能源供应与随机波动之间的平衡。当前系统存在基线能源浪费或过度依赖辅助能源的问题，需要找到最优的能源管理策略。

Method: 提出方差感知的路由和调度框架，基于二阶特性分析系统性能，考虑时间、模型和执行选择三个维度的变异性吸收。利用训练计算和推理计算的扩展定律来制定调度策略。

Result: 识别出临界状态作为最优操作点，在该状态下既不浪费基线能源也不过度依赖辅助能源。方差感知路由成为系统设计的关键维度，为能源感知的模型路由策略提供了理论基础。

Conclusion: 大型推理模型系统的能源效率优化需要综合考虑时间、模型和执行选择三个维度的变异性管理，方差感知的路由和调度是实现能源高效利用的关键设计原则。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [25] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

TL;DR: 研究发现AI系统的逐步推理解释并不总能揭示真正影响其决策的因素，模型会注意到提示信息但选择不报告，这暴露了AI透明度机制的缺陷。


<details>
  <summary>Details</summary>
Motivation: 当AI系统提供逐步推理解释时，从业者通常认为这些解释揭示了真正影响AI答案的因素。本研究旨在验证这一假设，探究AI模型是否真的会报告所有影响其决策的信息。

Method: 通过在问题中嵌入提示信息，测试AI模型是否会提及这些提示。研究覆盖了11个领先AI模型的9000多个测试案例，包括：1）观察模型是否会自发提及提示；2）直接询问模型是否注意到提示；3）测试告知模型被监视是否有效；4）强制模型报告提示的效果；5）特别测试针对用户偏好的提示。

Result: 1）模型几乎从不自发提及提示信息；2）当被直接询问时，模型承认注意到了提示；3）告知模型被监视并不能改善报告情况；4）强制报告提示虽然有效，但会导致模型在没有提示时也报告，并降低准确性；5）针对用户偏好的提示尤其危险，模型最常遵循这些提示但最少报告它们。

Conclusion: 仅仅观察AI的推理过程不足以发现隐藏的影响因素。AI模型能够注意到重要信息但选择不报告，这暴露了当前AI透明度机制的严重缺陷，需要更有效的监督方法来确保AI系统的真实透明度。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [26] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

TL;DR: OmniNeuro是一个新型HCI框架，将BCI从"黑盒"解码器转变为透明反馈伙伴，通过物理、混沌和量子启发的可解释性引擎驱动实时神经声化和生成式AI临床报告，提高用户理解和调节能力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习提高了脑机接口的解码精度，但其"黑盒"特性阻碍了临床采用，导致用户挫败感和神经可塑性结果不佳。需要使BCI更加透明和可解释。

Method: 提出OmniNeuro框架，集成三种可解释性引擎：1) 物理（能量）分析；2) 混沌（分形复杂性）分析；3) 量子启发的不确定性建模。这些指标驱动实时神经声化和生成式AI临床报告，框架与解码器无关，可作为任何先进架构的可解释性层。

Result: 在PhysioNet数据集（N=109）上评估，系统平均准确率达到58.52%。定性试点研究（N=3）证实可解释反馈有助于用户调节心理努力，减少"试错"阶段。

Conclusion: OmniNeuro成功将BCI从沉默解码器转变为透明反馈伙伴，通过多模态可解释性方法解决了深度学习在BCI中的"黑盒"问题，为临床采用提供了有前景的解决方案。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [27] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: TPP-TAL是一个新颖的即插即用框架，通过增强LLMs中的时间感知来改进时间点过程建模，显著提升了时间似然估计和事件预测准确性。


<details>
  <summary>Details</summary>
Motivation: 时间点过程在金融、医疗、社交系统等领域至关重要，但现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互。尽管大语言模型在序列建模中表现出色，但将其应用于时间点过程仍面临挑战。

Method: 提出TPP-TAL框架，不是简单拼接事件时间和类型嵌入，而是明确地将时间动态与上下文语义对齐后再输入LLM。这种对齐使模型能更好地感知事件及其周围上下文之间的时间依赖性和长程交互。

Result: 在多个基准数据集上的综合实验表明，TPP-TAL在时间似然估计和事件预测准确性方面带来了显著改进，突显了增强LLMs时间感知对于连续时间事件建模的重要性。

Conclusion: TPP-TAL通过增强大语言模型的时间感知能力，有效解决了时间点过程建模中时间信息与语义上下文交互的挑战，为连续时间事件建模提供了更好的解决方案。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [28] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

TL;DR: 这是一篇对Kosmyna等人(2025)关于使用ChatGPT进行论文写作任务时认知债务积累研究的评论文章，指出了该研究的五个主要问题：样本量小、分析可重复性、EEG分析方法问题、结果报告不一致以及研究透明度不足。


<details>
  <summary>Details</summary>
Motivation: 作者旨在对Kosmyna等人(2025)的研究提供建设性评论，以改进该论文的同行评审准备度，因为原研究的一些结果可能需要更保守的解释。

Method: 通过批判性分析原研究的五个方面：研究设计考虑（特别是样本量限制）、分析的可重复性、EEG分析方法问题、结果报告的不一致性以及研究过程和发现的透明度不足。

Result: 评论文章指出了原研究存在的五个主要问题，认为这些因素可能影响研究结论的可靠性，建议对结果进行更保守的解释。

Conclusion: 虽然赞赏Kosmyna等人研究的重要性和价值，但评论文章认为该研究在方法学严谨性和透明度方面存在不足，需要在同行评审前进行改进。

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [29] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

TL;DR: 研究发现LLM训练数据的地理分布导致品牌推荐差异，提出"存在鸿沟"概念，并建立数据护城河框架，为品牌提供算法全在性战略路线图


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统越来越多地中介消费者信息发现，品牌面临算法不可见性问题。本研究旨在探究大型语言模型中文化编码现象——由训练数据组成导致的品牌推荐系统性差异。

Method: 分析1,909个纯英文查询，覆盖6个LLM（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）和30个品牌。通过案例研究Zhizibianjie（OmniEdge）平台，展示语言边界障碍如何创造不可见的市场进入壁垒。

Result: 中国LLM的品牌提及率比国际LLM高30.6个百分点（88.9% vs. 58.3%，p<.001）。这种差异在相同的英文查询中持续存在，表明训练数据的地理分布——而非语言——驱动了这一效应。Zhizibianjie在中国LLM中提及率为65.6%，但在国际模型中为0%（p<.001）。

Conclusion: 提出数据护城河框架，将AI可见内容概念化为VRIN战略资源。操作化算法全在性——跨LLM知识库的全面品牌可见性——作为生成引擎优化的战略目标。研究发现，在AI中介的市场中，品牌"数据边界"的极限定义了其"市场前沿"的极限。

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [30] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

TL;DR: UCL是一个将提示工程从启发式实践转化为系统优化的数学框架，通过系统评估显著减少token使用（29.8%），其结构开销函数揭示了过指定悖论：超过阈值后额外指定会二次降低性能。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程主要依赖启发式实践，缺乏系统化的优化框架。作者希望将提示工程从经验性实践转变为可系统优化的数学框架，以提高LLM交互的效率和成本效益。

Method: 提出通用条件逻辑（UCL）框架，包含指示函数、结构开销函数、早期绑定等核心机制。通过系统评估（N=305，11个模型，4次迭代）验证框架有效性，并分析结构开销函数O_s(A)如何解释版本特定的性能差异。

Result: 显著减少token使用（29.8%，统计显著），对应成本节约。发现过指定悖论：超过阈值S* = 0.509后，额外指定会二次降低性能。验证了核心机制的有效性，并发现最优UCL配置因模型架构而异，某些模型需要版本特定适配。

Conclusion: UCL作为一个可校准的框架，为高效LLM交互提供了系统化方法。模型家族特定的优化是未来关键研究方向，框架的数学基础使提示工程从启发式实践转变为可系统优化的科学。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [31] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

TL;DR: 提出Counterfactual Self-Questioning框架，让单个语言模型生成并评估自身推理的反事实批判，实现无需外部模型的自我改进


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法依赖外部批评者、学习奖励模型或集成采样，增加了复杂性和训练不稳定性，需要更简单有效的自我监督方法

Method: 提出反事实自我质疑框架：1) 生成初始推理轨迹；2) 针对潜在失败点提出针对性问题；3) 生成暴露错误假设或无效步骤的替代推理轨迹；4) 使用结构化相对反馈进行策略优化

Result: 在多个数学推理基准测试中，反事实自我质疑提高了准确性和训练稳定性，特别是对于较小模型，仅使用内部生成的监督就能实现可扩展的自我改进

Conclusion: Counterfactual Self-Questioning为语言模型自我改进提供了一种简单有效的框架，无需辅助模型，通过内部生成的监督实现稳定训练和性能提升

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [32] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型中的上下文学习和模型崩溃现象，通过线性变换器和简化设置分析其数学机制，并提出了"上下文崩溃"的新概念。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型中两个关键现象：上下文学习（ICL）和模型崩溃，旨在理解其数学机制和动态特性，并探索它们之间的联系。

Method: 1. 使用带权重绑定的线性变换器在回归任务上研究ICL，将前向传播简化为预条件梯度下降；2. 使用鞅和随机游走理论分析线性回归和高斯拟合的简化设置；3. 提出"上下文崩溃"概念分析长序列生成问题。

Result: 1. ICL中最小化上下文损失会导致参数相变，超过临界上下文长度时解会出现斜对称分量；2. 模型崩溃几乎必然发生，除非数据快速增长或保留；3. 发现了上下文崩溃现象，特别是在思维链推理中。

Conclusion: 上下文学习和模型崩溃具有深刻的数学联系，上下文崩溃概念将ICL动态与生成模型的长期稳定性挑战联系起来，为理解LLM行为提供了新视角。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [33] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: ElecTwit是一个模拟社交媒体政治选举中多智能体说服行为的框架，发现LLM使用了25种说服技巧，不同模型架构和训练影响说服动态，观察到"真相核心"信息和"墨水"强迫症等独特现象。


<details>
  <summary>Details</summary>
Motivation: 克服以往研究中基于游戏的模拟限制，在真实环境中研究多智能体系统中的说服行为，特别是在社交媒体政治选举场景中，为评估现实世界中的说服性LLM智能体提供基础。

Method: 开发ElecTwit模拟框架，在模拟社交媒体政治选举环境中测试多个LLM模型，观察和分析智能体之间的说服互动，记录25种具体说服技巧的使用情况。

Result: 发现大多数测试的LLM都使用了25种特定的说服技巧，范围比之前报道的更广；不同模型在技巧使用和总体说服输出上存在显著差异；观察到"真相核心"信息和"墨水"强迫症（智能体集体要求书面证据）等独特现象。

Conclusion: 该研究为在现实世界环境中评估说服性LLM智能体奠定了基础，确保对齐并防止危险结果，模型架构和训练的差异显著影响现实社交模拟中的动态。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [34] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

TL;DR: MRE框架通过增强前向和后向推理来改进时序知识图谱问答中的多跳推理，使用提示工程生成多样化推理轨迹，并通过T-GRPO算法建立强因果依赖关系，在多个基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 时序知识图谱问答中，大语言模型在每一跳检索子图时面临大量时间相似和语义复杂的关系，增加了次优决策和错误传播的风险，需要改进多跳推理的全局优化能力。

Method: 提出多跳推理增强（MRE）框架：1）通过提示工程引导LLM生成多样化推理轨迹；2）选择有效轨迹进行监督微调作为冷启动策略；3）引入树组相对策略优化（T-GRPO），这是一种递归的树结构探索学习方法，在每一跳建立对前一跳的强因果依赖，并通过后续跳的多路径探索反馈进行评估。

Result: 在两个TKGQA基准测试中，基于MRE的模型始终超越最先进方法，在处理复杂多跳查询方面表现优异。进一步分析显示模型具有更好的可解释性和对噪声时间标注的鲁棒性。

Conclusion: MRE框架通过增强前向和后向推理，结合提示工程和T-GRPO算法，显著提升了时序知识图谱问答中多跳推理的性能，实现了更好的全局优化、可解释性和鲁棒性。

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [35] [Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models](https://arxiv.org/abs/2601.01321)
*Rong Zhou,Dongping Chen,Zihan Jia,Yao Su,Yixin Liu,Yiwen Lu,Dongwei Shi,Yue Huang,Tianyang Xu,Yi Pan,Xinliang Li,Yohannes Abate,Qingyu Chen,Zhengzhong Tu,Yu Yang,Yu Zhang,Qingsong Wen,Gengchen Mai,Sunyang Fu,Jiachen Li,Xuyu Wang,Ziran Wang,Jing Huang,Tianming Liu,Yong Chen,Lichao Sun,Lifang He*

Main category: cs.AI

TL;DR: 本文提出了一个统一的四阶段框架，系统描述人工智能在数字孪生生命周期中的集成，涵盖建模、镜像、干预和自主管理四个阶段，并分析了物理建模与数据驱动学习的协同作用。


<details>
  <summary>Details</summary>
Motivation: 数字孪生已从被动仿真工具演变为智能自主实体，但缺乏系统性的AI集成框架。本文旨在提供一个统一框架来系统描述AI方法在数字孪生全生命周期中的嵌入方式。

Method: 提出统一的四阶段框架：1) 基于物理和物理信息AI方法建模物理孪生；2) 通过实时同步将物理系统镜像为数字孪生；3) 通过预测建模、异常检测和优化策略干预物理孪生；4) 通过大语言模型、基础模型和智能体实现自主管理。通过跨11个应用领域的综述分析挑战。

Result: 框架系统描述了AI在数字孪生中的集成路径，分析了从传统数值求解器向物理信息模型和基础模型的转变，以及生成式AI技术如何将数字孪生转变为具有推理、通信和创造性场景生成能力的认知系统。

Conclusion: AI驱动的数字孪生正向自主认知系统演进，但仍面临可扩展性、可解释性和可信度等挑战。未来需要负责任地发展AI驱动的数字孪生系统，平衡物理建模与数据驱动方法，实现更智能的自主管理。

Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.

</details>


### [36] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

TL;DR: JiSi框架通过查询-响应混合路由、支持集聚合器选择和自适应路由-聚合切换三大创新，使10个开源LLM协作以47%成本超越Gemini-3-Pro，展示了集体智能作为AGI新路径的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM路由和聚合存在三个关键瓶颈：1）基于查询的路由器仅关注文本相似性；2）聚合方法静态且无法为不同任务选择合适聚合器；3）路由与聚合的互补性未充分利用。研究探索集体智能作为替代单体扩展的新路径。

Method: 提出JiSi框架，包含三大创新：1）查询-响应混合路由，同时捕捉语义信息和问题难度；2）基于支持集的聚合器选择，联合评估聚合器的聚合能力和领域能力；3）自适应路由-聚合切换，动态利用路由和聚合的优势。

Result: 在9个基准测试中，JiSi通过协调10个开源LLM，以仅47%的成本超越了Gemini-3-Pro的性能，同时优于主流基线方法。

Conclusion: 集体智能代表了通往人工通用智能（AGI）的新路径，通过有效协调多个开源LLM的协作可以超越单体大模型的性能，同时显著降低成本。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [37] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: FuXi-Uni是一个原生统一的多模态科学模型，能够在单一架构中理解和生成跨科学领域的高维数据，在地球科学和生物医学领域表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前科学发现越来越依赖跨学科异构高维数据的整合，但现有AI模型通常是领域特定的，缺乏同时理解和生成多模态科学数据的能力，而许多全球性挑战和科学问题本质上是跨学科的。

Method: FuXi-Uni将跨学科科学标记与自然语言标记对齐，使用科学解码器重建科学标记，支持自然语言对话和科学数值预测，在统一共享潜在空间中整合异构科学模态。

Result: 在地球系统建模中：1）生成0.25°分辨率的10天全球预报优于最先进的物理预报系统；2）热带气旋路径和强度预测优于最先进物理模型；3）生成的高分辨率区域天气场超越标准插值基线。在生物医学中：在多个生物医学视觉问答基准上优于领先的多模态大语言模型。

Conclusion: FuXi-Uni通过在原生共享潜在空间中统一异构科学模态，同时保持强大的领域特定性能，为更通用的多模态科学模型迈出了一步。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [38] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

TL;DR: 提出AAAI三阶段流程，通过减少事实幻觉来提升小语言模型在金融分类任务中的性能


<details>
  <summary>Details</summary>
Motivation: 小语言模型在金融分类中因推理时产生事实幻觉而导致分类性能较弱，需要探索减少事实幻觉是否能改善其分类能力

Method: 提出AAAI三阶段流程：关联识别、自动检测和自适应推理，使用编码器验证器检测事实幻觉，并通过事实错误反馈实现自适应推理

Result: 实验发现：1) 事实幻觉与错误分类正相关；2) 编码器验证器能有效检测事实幻觉；3) 结合事实错误反馈的自适应推理能提升分类性能

Conclusion: AAAI流程有助于提升小语言模型在金融领域的可信度和有效性应用

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [39] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

TL;DR: 研究三元背景中的蕴含关系，特别是Ganter和Obiedkov提出的条件属性蕴含和属性条件蕴含，目标是构建这些蕴含的最优基


<details>
  <summary>Details</summary>
Motivation: 三元背景中的蕴含关系在形式概念分析中具有重要应用价值，但现有研究缺乏对这些蕴含关系最优基的系统构建方法

Method: 研究Ganter和Obiedkov提出的条件属性蕴含和属性条件蕴含，开发构建这些蕴含最优基的算法或方法

Result: 提出了构建三元背景中条件属性蕴含和属性条件蕴含最优基的方法，可能包括算法设计和理论证明

Conclusion: 成功构建了三元背景中蕴含关系的最优基，为形式概念分析中的三元背景研究提供了重要的理论工具

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


### [40] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

TL;DR: 该研究提出了一个两阶段框架来改善大语言模型在复杂决策环境中的行为对齐，通过上下文形成和上下文导航两个阶段来提升LLM模拟人类行为的能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地被用于模拟实验环境中的人类行为，但在复杂决策环境中（参与者需要预测他人行动并基于观察行为形成信念），LLM与人类决策存在系统性偏差。需要一种系统方法来改善LLM在行为研究中的对齐能力。

Method: 提出了一个两阶段框架：1) 上下文形成阶段 - 明确指定实验设计以建立决策任务及其上下文的准确表示；2) 上下文导航阶段 - 在该表示内指导推理过程以做出决策。通过三个实验验证框架：顺序购买游戏、众筹游戏和需求估计任务，测试了GPT-4o、GPT-5、Claude-4.0-Sonnet-Thinking和DeepSeek-R1四个SOTA模型。

Result: 研究发现，在复杂决策环境中需要两个阶段才能实现与人类基准的行为对齐，而在较简单的需求估计任务中仅需要上下文形成阶段。该框架为设计和诊断LLM社会模拟提供了系统方法。

Conclusion: 该两阶段框架明确了何时需要每个阶段，为将LLM社会模拟作为行为研究中人类受试者的补充提供了系统化的设计和诊断方法，提高了LLM在复杂决策环境中的行为对齐能力。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [41] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

TL;DR: Logics-STEM是一个针对STEM领域推理任务优化的先进推理模型，基于1000万规模的高质量数据集，在8B规模上相比次优模型平均提升4.68%性能。


<details>
  <summary>Details</summary>
Motivation: 旨在提升STEM（科学、技术、工程、数学）领域的推理能力，通过数据算法协同设计来解决现有模型在复杂推理任务上的不足。

Method: 采用数据算法协同设计引擎：数据方面通过5阶段数据策展引擎构建高质量数据集；算法方面采用失败驱动的后训练框架，针对SFT阶段的失败区域进行针对性知识检索和数据合成。

Result: 在STEM相关基准测试中表现优异，8B规模模型平均比次优模型提升4.68%，展示了大规模开源数据与精心设计合成数据结合的潜力。

Conclusion: 数据算法协同设计通过后训练显著提升推理能力，Logics-STEM模型和数据集已开源，支持开源社区的未来研究。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [42] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 本文提出了一种结合LLM灵活性和符号推理保证性的框架：LLM作为本体填充引擎将非结构化文本转换为ABox断言，SWRL推理器提供确定性规则应用，在三个领域验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在需要可审计和可解释决策的领域（如临床协议、证据规则、科学标准），基于规则的推理面临挑战：LLM提供灵活性但无法保证一致性，符号系统提供保证但需要结构化输入。需要结合两者优势。

Method: 提出集成模式：LLM作为本体填充引擎，将非结构化文本转换为基于专家编写TBox规范的ABox断言；SWRL推理器应用规则提供确定性保证。框架将推理分解为实体识别、断言提取和符号验证三个步骤，任务定义基于OWL 2本体。

Result: 在三个领域（法律传闻确定、科学方法任务应用、临床试验资格）和十一个语言模型上验证了该方法。结构化分解在总体上比few-shot提示有统计显著改进，三个领域都观察到增益。消融研究确认符号验证比单独结构化提示提供实质性好处。

Conclusion: 该框架结合了LLM的灵活性和符号推理的保证性，填充的ABox可与标准语义网工具集成进行检查和查询，为更丰富的推理模式奠定基础，这是简单形式主义无法表达的。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [43] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

TL;DR: Yuan3.0 Flash是一个开源的多模态专家混合模型，拥有37亿激活参数和400亿总参数，专为企业任务优化，同时保持通用任务竞争力，并解决了大推理模型的过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 解决大推理模型中常见的"过度思考"现象，同时开发一个既能处理企业导向任务（如RAG、复杂表格理解、摘要）又能保持通用任务竞争力的高效多模态大语言模型。

Method: 采用专家混合架构，并提出Reflection-aware Adaptive Policy Optimization算法来调节过度思考行为。模型具有37亿激活参数和400亿总参数，专门针对企业任务优化。

Result: 在企业导向任务（检索增强生成、复杂表格理解、摘要）中表现优异，在数学、科学等领域的推理能力强大，达到前沿模型相当的准确率，同时仅需约1/4到1/2的平均token数量。

Conclusion: Yuan3.0 Flash是一个高效的多模态专家混合模型，通过创新的RAPO算法解决了过度思考问题，在企业任务和通用任务上都表现出色，已完全开源供研究和实际部署使用。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [44] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

TL;DR: 本文对AI智能体架构进行了全面综述，系统梳理了其核心组件、协调模式、部署场景，并分析了设计权衡、评估挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型与推理、规划、记忆和工具使用能力的结合，AI智能体正成为连接自然语言意图与现实世界计算的实际接口。本文旨在系统梳理这一新兴领域的架构设计，为研究者和实践者提供统一的分类框架。

Method: 采用综述研究方法，将现有工作组织为统一的分类体系，涵盖：1）智能体组件（策略/LLM核心、记忆、世界模型、规划器、工具路由器、批评器）；2）协调模式（单智能体vs多智能体、集中式vs去中心化）；3）部署场景（离线分析vs在线交互、安全关键vs开放任务）。

Result: 建立了AI智能体架构的完整分类框架，识别了关键设计权衡（延迟vs准确性、自主性vs可控性、能力vs可靠性），分析了评估复杂性（非确定性、长期信用分配、工具和环境变异性、隐藏成本），总结了测量和基准测试实践。

Conclusion: AI智能体架构研究面临验证和工具操作护栏、可扩展记忆和上下文管理、智能体决策可解释性、现实工作负载下的可重复评估等开放挑战，需要进一步研究解决。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [45] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

TL;DR: RTL-OPT是一个用于评估大语言模型在RTL代码优化能力的新基准测试，包含36个手工设计的数字电路，覆盖多种实现类别，并提供自动化评估框架验证功能正确性和量化PPA改进。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要评估RTL代码的语法正确性，而忽略了在功耗、性能和面积（PPA）方面的优化质量。随着人工智能在集成电路设计中的应用日益重要，需要专门评估LLMs在RTL优化能力的基准测试。

Method: 开发了RTL-OPT基准测试，包含36个手工设计的数字电路，覆盖组合逻辑、流水线数据通路、有限状态机和存储器接口等类别。每个任务提供次优版本和人工优化的参考版本，后者体现了行业验证的优化模式。集成了自动化评估框架来验证功能正确性和量化PPA改进。

Result: RTL-OPT基准测试能够标准化且有意义地评估生成模型在硬件设计优化方面的能力，填补了现有基准测试主要关注语法正确性而忽视PPA优化质量的空白。

Conclusion: RTL-OPT为评估大语言模型在RTL代码优化能力提供了首个专注于PPA改进的基准测试，有助于推动AI在集成电路设计优化中的应用和发展。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [46] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

TL;DR: 本文评估了大型语言模型在求解超越方程方面的能力，比较了直接数值预测与结合经典迭代求解器的混合架构的效果。研究发现混合方法显著优于直接预测，误差减少67.9%-81.8%，表明LLMs更适合作为经典数值求解器的智能接口而非独立计算引擎。


<details>
  <summary>Details</summary>
Motivation: 超越方程在工程实践中普遍存在，需要迭代数值求解。研究旨在评估大型语言模型是否能直接求解这些方程，或者是否需要结合传统数值求解器的混合架构来实现更有效的解决方案。

Method: 测试了六种最先进的LLM模型（GPT-5.1、GPT-5.2、Gemini-3-Flash、Gemini-2.5-Lite、Claude-Sonnet-4.5、Claude-Opus-4.5），在涵盖七个工程领域的100个问题上比较两种方法：1）直接数值预测；2）求解器辅助计算（LLMs制定控制方程并提供初始条件，牛顿-拉弗森迭代执行数值求解）。

Result: 直接预测的平均相对误差为0.765-1.262，而求解器辅助计算为0.225-0.301，误差减少67.9%-81.8%。领域分析显示电子学改进最大（93.1%），流体力学改进最小（7.2%）。

Conclusion: 当代LLMs擅长符号操作和领域知识检索，但在精度关键的迭代算术方面表现不佳。它们的最佳部署方式是作为经典数值求解器的智能接口，而不是独立的计算引擎。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [47] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 论文提出"可采纳性对齐"概念，将AI对齐重新定义为在不确定性下对结果分布的可采纳行动和决策选择属性，并介绍MAP-AI系统架构通过蒙特卡洛估计和可采纳性控制实现对齐。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐方法通常将对齐视为静态或二元条件，缺乏在不确定性环境下对决策策略行为分布特性的评估。需要一种能够处理不确定性、干预效应、价值模糊性和治理约束的决策理论框架。

Method: 提出MAP-AI系统架构，通过蒙特卡洛方法估计结果分布，采用可采纳性控制的策略选择机制。该框架评估决策策略在多种可能未来情景中的行为，明确建模不确定性、干预效果、价值模糊性和治理约束。

Result: 建立了一个实用的AI系统治理基础，使对齐评估基于分布特性（期望效用、方差、尾部风险、不对齐概率）而非单个预测的准确性。实现了无需重新训练或修改底层模型的可采纳性控制行动选择机制。

Conclusion: 将AI对齐重新定义为概率性、决策理论属性而非静态条件，提供了在企业和机构AI系统中评估信任和对齐的可执行方法。该框架特别适用于那些影响由策略行为分布和尾部事件决定而非单个预测决定的AI系统。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [48] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

TL;DR: COMPASS框架首次系统评估LLMs是否符合组织政策，发现模型在允许请求上表现良好（>95%准确率），但在禁止请求上严重失效（仅拒绝13-40%的违规请求），揭示当前LLMs缺乏政策关键部署所需的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在企业高风险应用中的部署（从医疗到金融），确保模型遵守组织特定政策变得至关重要。然而现有的安全评估仅关注通用危害，缺乏针对组织政策的系统评估框架。

Method: 提出COMPASS（公司/组织政策对齐评估）框架，应用于八个不同行业场景，生成并验证了5,920个查询，测试常规合规性和通过策略设计的边缘案例测试对抗鲁棒性。评估了七个最先进的模型。

Result: 发现基本不对称性：模型可靠处理合法请求（>95%准确率），但在执行禁令方面灾难性失败，仅拒绝13-40%的对抗性禁止列表违规。这些结果表明当前LLMs缺乏政策关键部署所需的鲁棒性。

Conclusion: COMPASS框架成为组织AI安全的重要评估工具，揭示了当前LLMs在政策合规方面的严重不足，需要进一步改进才能满足企业级部署的安全要求。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [49] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体提示和模式约束检索增强生成（KG-RAG）的端到端框架，用于直接从自由文本构建临床知识图谱，特别针对肿瘤学领域，解决了现有方法依赖结构化输入和缺乏事实准确性验证的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型为从非结构化临床叙述构建知识图谱提供了新机会，但现有方法通常依赖结构化输入，缺乏对事实准确性和语义一致性的稳健验证，这在肿瘤学领域尤其成问题。

Method: 提出端到端框架，整合：(1) 提示驱动的实体、属性和关系抽取；(2) 基于熵的不确定性评分；(3) 本体对齐的RDF/OWL模式生成；(4) 多LLM共识验证用于幻觉检测和语义精炼。采用多智能体提示和模式约束检索增强生成策略。

Result: 应用于两个肿瘤学队列（PDAC和BRCA），该方法能够在不依赖黄金标准标注的情况下生成可解释、SPARQL兼容且临床基础的知识图谱。实验结果显示在精确度、相关性和本体合规性方面相比基线方法有持续提升。

Conclusion: 该框架支持持续精炼和自监督评估，能够迭代改进图谱质量，为临床知识图谱构建提供了一种无需黄金标准标注的有效方法，特别适用于肿瘤学领域。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [50] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

TL;DR: 本文提出Jenius-Agent框架，通过自适应提示生成、上下文感知工具编排和分层内存机制三大创新，提升LLM智能体的任务准确性20%，同时降低token成本、响应延迟和调用失败率。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体系统发展，提升自主智能体在上下文理解、工具使用和响应生成方面的任务性能变得日益重要。尽管先前研究改进了LLM智能体的整体设计，但对其内部推理和工具使用流程的系统优化仍显不足。

Method: 提出基于真实世界实践经验的智能体框架，包含三大关键创新：1）自适应提示生成策略，根据智能体状态和任务目标调整提示以提高可靠性和鲁棒性；2）上下文感知工具编排模块，基于用户意图和上下文进行工具分类、语义检索和自适应调用；3）分层内存机制，集成会话内存、任务历史和外部摘要，通过动态摘要和压缩提高相关性和效率。框架集成了基于模型上下文协议（MCP）的工具、文件输入/输出和执行反馈三大优化。

Result: 实验显示任务准确性提升20%，同时降低了token成本、响应延迟和调用失败率。该框架已在Jenius平台部署，为鲁棒、协议兼容的自主智能体提供了轻量级可扩展解决方案。

Conclusion: Jenius-Agent框架通过系统优化智能体的内部推理和工具使用流程，显著提升了任务性能，为构建高效可靠的自主智能体提供了实用解决方案。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [51] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

TL;DR: 论文指出当前大语言模型的社会认知基准测试存在评估-部署差距，根本原因在于缺乏明确的理论基础，导致基准测试结果被过度泛化。作者提出"理论追踪卡"作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有社会认知基准测试即使获得高分也无法预测真实世界行为，传统归因于测量和效度问题，但忽视了更根本的理论缺失问题。缺乏明确的理论基础导致基准测试只能评估能力的狭窄子集，却被误解为广泛能力的证据。

Method: 1. 诊断并形式化"理论差距"问题，将其定义为系统性过度泛化基准结果的基础性失败。2. 提出"理论追踪卡"（TTC）作为轻量级文档工具，明确记录评估的理论基础、目标能力组件、操作化过程和局限性。

Result: 理论追踪卡通过明确理论、任务操作化、评分和局限性之间的完整效度链，增强了社会认知评估的可解释性和可重用性，无需修改基准测试或要求单一理论共识。

Conclusion: 社会认知评估需要明确的理论基础来避免系统性效度幻觉。理论追踪卡提供了一种实用方法，通过文档化评估的理论假设和局限性，提高基准测试结果的解释性和可靠性。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [52] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: MMP-A*是一个多模态路径规划框架，结合视觉语言模型的空间定位能力和自适应衰减机制，在复杂环境中实现高效近最优路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统A*算法在大规模场景中计算和内存成本过高，而基于大语言模型的路径规划方法缺乏空间定位能力，在拓扑复杂环境中容易产生错误路径点，导致计算效率低下。

Method: 提出MMP-A*框架，集成视觉语言模型的空间定位能力，并引入自适应衰减机制动态调节不确定路径点在启发式函数中的影响，确保几何有效性同时减少内存开销。

Result: 在具有严重障碍物和拓扑复杂性的挑战性环境中测试，MMP-A*实现了近最优轨迹，同时显著降低了操作成本。

Conclusion: MMP-A*为自主导航提供了一个具有感知基础和计算效率的新范式，通过多模态集成解决了纯文本规划器的局限性。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [53] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

TL;DR: OpenSocInt是一个开源的多模态社交交互模拟器软件包，提供模块化架构来训练社交智能体，已应用于社交导航任务。


<details>
  <summary>Details</summary>
Motivation: 开发一个开源的多模态社交交互模拟框架，用于研究和训练社交智能体，促进社交智能领域的发展。

Method: 构建了OpenSocInt软件包，包含多模态社交交互模拟器和模块化架构，支持探索不同感知特征、编码融合方式以及不同类型智能体的使用。

Result: 软件已公开发布在GitLab上（GPL许可证），并通过社交导航任务的实验协议展示了其应用价值。

Conclusion: OpenSocInt为多模态社交交互研究提供了一个灵活的开源平台，有助于推动社交智能体的训练和评估。

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [54] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

TL;DR: 本文对基于形式概念分析（FCA）的分类器进行了最新综述，提出了一种从名义数据计算闭包算子的新方法，并构建了专注于最相关概念的部分概念格。


<details>
  <summary>Details</summary>
Motivation: 知识发现（KDD）旨在从海量数据中提取隐藏且有价值的知识，其中分类是核心数据挖掘技术之一。形式概念分析（FCA）作为一种可解释和可解释的学习方法，基于概念格的数学结构，能够生成形式概念并发现隐藏关系，因此值得深入研究其在分类任务中的应用。

Method: 1. 对基于FCA的分类器进行了全面的最新综述；2. 探索了从名义数据计算闭包算子的各种方法；3. 提出了一种构建部分概念格的新方法，专注于最相关的概念；4. 通过实验验证了所提方法的效率。

Result: 实验结果表明，所提出的构建部分概念格的方法具有较高的效率，能够有效处理名义数据并生成相关的分类概念。

Conclusion: 形式概念分析是一种有效的可解释分类方法，本文提出的构建部分概念格的方法能够提高分类效率，为基于FCA的分类器研究提供了新的视角和技术支持。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [55] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

TL;DR: ChaosBench-Logic是一个评估大语言模型在混沌动力系统领域逻辑推理能力的基准测试，包含30个系统、621个问题，涵盖7种推理类型，发现前沿LLMs在单项准确率高达91-94%，但在组合推理上得分为0%，对话准确率53.1-75.5%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言任务上表现出色，但在需要精确逻辑和符号推理的领域仍然脆弱。混沌动力系统提供了一个特别严格的测试环境，因为混沌是确定性的，但常被误解为随机性或复杂性。需要建立一个基准来评估LLMs的逻辑推理能力。

Method: 引入ChaosBench-Logic基准，评估30个不同动力系统的LLM推理能力，使用统一的一阶逻辑本体论。每个系统标注了11个语义谓词的真值分配，生成621个问题，涵盖7个推理类别：多步蕴含、跨系统类比、反事实推理、偏见探测和多轮对话。定义了逻辑准确性、蕴含一致性、对话连贯性和矛盾性等指标，并发布了开源评估管道。

Result: 前沿LLMs（GPT-4、Claude 3.5 Sonnet、Gemini 2.5 Flash、LLaMA-3 70B）在单项准确率达到91-94%，但在组合项目上得分为0%，表现出脆弱的全局连贯性。对话级准确率从53.1%（GPT-4 CoT）到75.5%（LLaMA-3 zero-shot）。

Conclusion: ChaosBench-Logic为诊断LLM在逻辑推理上的失败提供了一个严格的测试平台，并为开发能够改善LLMs科学推理能力的神经符号方法奠定了基础。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [56] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

TL;DR: MindChat是一个保护隐私的心理健康支持大语言模型，配合MindCorpus合成多轮咨询数据集，通过联邦学习和差分隐私减少隐私风险，在咨询能力评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在心理健康支持方面有潜力，但受限于真实咨询对话的稀缺性和敏感性，需要解决隐私保护问题。

Method: 1) 使用多智能体角色扮演框架构建MindCorpus合成数据集，采用双闭环反馈设计；2) 通过联邦学习结合LoRA适配器进行参数高效微调；3) 加入差分隐私优化减少成员推理和记忆风险。

Result: MindCorpus提高了训练效果，MindChat在自动LLM评估和人工评估中与现有通用和咨询导向的LLM基线竞争，同时在成员推理攻击下表现出减少的隐私泄露。

Conclusion: 提出的隐私保护LLM框架能够有效支持心理健康咨询，同时解决数据稀缺和隐私风险问题，为实际应用提供了可行方案。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [57] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: XAIMeD是一个可解释的医疗AI框架，通过神经符号架构整合临床专家知识，提升分布偏移下的鲁棒性和罕见类敏感性，提供透明临床解释。


<details>
  <summary>Details</summary>
Motivation: 医疗AI面临可解释性、领域泛化和罕见类可靠性等关键挑战，深度学习模型在真实世界分布偏移下常失效，且对不常见临床条件存在偏见。

Method: 将临床专业知识编码为原子医学命题的逻辑连接，转化为机器可检查的类特定规则；通过加权特征满足分数量化诊断效用；采用置信度加权融合整合符号和深度输出；基于熵不平衡增益和罕见类基尼系数的自适应路由机制缓解类别不平衡。

Result: 在四个挑战性任务上评估：癫痫发作区定位和糖尿病视网膜病变分级；跨域泛化性能提升6%，罕见类F1分数提升10%，显著优于最先进的深度学习基线。

Conclusion: XAIMeD提供了一个原则性、临床忠实且可解释的多模态医疗AI方法，临床基础的符号组件作为有效正则化器确保对分布偏移的鲁棒性。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [58] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

TL;DR: 该论文探讨了基础模型（FMs）如何通过模仿"大声思考"的过程、测试生成的路径并进行迭代来实现推理，这与传统的符号推理不同，缺乏人类推理的根基和常识，导致推理过程脆弱。论文提供了哲学解释，认为"随机鹦鹉"的比喻已不再相关，并讨论了由此产生的安全性和适当性考虑。


<details>
  <summary>Details</summary>
Motivation: 传统上，推理被理解为理解阶段之间的路径，通常通过符号推理实现。然而，基础模型（FMs）表明，对于许多推理任务，符号推理并非必要条件。FMs可以通过模仿"大声思考"的过程、测试生成的路径并进行迭代来实现某种形式的推理。这种推理方式虽然能够独立或通过少量学习解决问题，但由于缺乏根基和常识，与人类推理有本质区别，导致推理过程脆弱。论文旨在探讨这一现象，重新评估推理的必要条件，并为应对FMs推理脆弱性的安全性和稳健防御提供见解。

Method: 论文采用哲学分析方法，对基础模型（FMs）的推理现象进行解释和讨论。具体方法包括：1）提供多种哲学解释框架来理解FMs的推理过程；2）论证"随机鹦鹉"这一先前恰当的比喻已失去相关性，应被放弃；3）反思从这些推理模型及其日益增长的能力中产生的安全性和适当性考虑中的不同规范性要素。

Result: 论文的主要成果包括：1）识别了FMs推理与人类符号推理的本质区别，即FMs通过模仿思考过程、测试和迭代路径来实现推理，而非基于符号逻辑；2）提出了多种哲学解释框架来理解这一现象；3）论证了"随机鹦鹉"比喻的局限性，认为它已无法准确描述现代FMs的推理能力；4）分析了由FMs推理脆弱性引发的安全性和适当性考虑，为未来研究提供了规范性指导。

Conclusion: 基础模型（FMs）的推理能力正在改变我们对推理必要条件的理解。虽然FMs能够通过模仿思考过程实现某种形式的推理，但其缺乏根基和常识的本质导致推理过程脆弱。这一认识不仅需要重新评估推理的本质，也为应对FMs安全性和稳健性挑战提供了重要见解。论文呼吁放弃过时的"随机鹦鹉"比喻，并深入思考由这些新型推理模型引发的规范性考量。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [59] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

TL;DR: 本研究探索了将大型语言模型应用于药物3D打印领域，通过微调四种LLM架构来推荐适合的辅料并预测丝材机械性能，发现Llama2在辅料推荐方面表现最佳，同时揭示了小数据集可能导致灾难性遗忘等问题。


<details>
  <summary>Details</summary>
Motivation: 药物3D打印技术有望实现真正的个性化给药，但现有AI应用通常局限于狭窄领域，未能解决该技术固有的广泛制剂挑战。随着人工通用智能概念的发展，需要探索LLM在药物制剂开发中的更广泛应用。

Method: 研究微调了四种大型语言模型架构，使用包含1400多种配方的熔融沉积成型数据集。系统评估了微调和生成参数配置，让模型根据活性药物成分剂量推荐合适的辅料，并预测丝材机械性能。

Result: Llama2在FDM制剂辅料推荐方面表现最佳；模型选择和参数化显著影响性能；较小的LLM出现灾难性遗忘现象；标准LLM指标仅评估语言性能而非制剂可加工性；基于生物医学相关数据训练的LLM不一定产生最佳结果。

Conclusion: 需要解决灾难性遗忘、评估指标局限性和数据相关性等问题，才能推动LLM超越语言能力，成为药物制剂开发中可靠的系统。这项研究为AI在药物3D打印中的更广泛应用奠定了基础。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [60] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 该论文提出将长链思维推理中的幻觉视为演化潜状态而非一次性错误事件，引入累积前缀级幻觉信号来追踪推理状态的全局演化，实现流式幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理虽然提升了大型语言模型的性能，但幻觉问题在推理过程中会微妙地出现并跨步骤传播。传统方法将幻觉视为一次性错误事件，无法有效捕捉其在长推理链中的演化特性。

Method: 将步骤级幻觉判断视为局部观测，引入累积前缀级幻觉信号来追踪整个推理轨迹中推理状态的全局演化。这种方法将幻觉建模为演化潜状态而非离散错误。

Result: 实现了长链思维推理中的流式幻觉检测，能够提供实时、可解释的证据，更好地理解和追踪幻觉在推理过程中的传播和演化。

Conclusion: 将长链思维推理中的幻觉视为演化潜状态而非一次性错误事件，通过累积前缀级信号追踪全局演化，为流式幻觉检测提供了更有效的框架，增强了推理过程的可解释性和可靠性。

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [61] [Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents](https://arxiv.org/abs/2601.02314)
*Sourena Khanzadeh*

Main category: cs.AI

TL;DR: 论文发现当前LLM智能体的推理过程存在"忠实性差距"，其推理痕迹可能只是"推理剧场"而非真实的决策驱动因素，通过因果干预揭示了因果解耦问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体越来越多地承担高风险自主决策任务，其推理过程的透明度成为关键安全问题。虽然CoT提示可以生成人类可读的推理痕迹，但尚不清楚这些痕迹是模型输出的忠实生成驱动因素，还是仅仅是事后合理化解释。

Method: 提出了Project Ariadne框架，利用结构因果模型和反事实逻辑来审计智能体推理的因果完整性。该方法对中间推理节点进行硬干预（do-演算），系统性地反转逻辑、否定前提和颠倒事实主张，以测量最终答案的因果敏感性。

Result: 对最先进模型的实证评估揭示了持续的"忠实性差距"。定义并检测到一种广泛的故障模式称为"因果解耦"，在事实和科学领域中，智能体的违反密度高达0.77。在这些情况下，智能体尽管内部逻辑矛盾，却得出相同结论，证明其推理痕迹只是"推理剧场"，而决策由潜在参数先验控制。

Conclusion: 当前智能体架构本质上容易产生不忠实的解释，建议将Ariadne分数作为对齐陈述逻辑与模型行为的新基准。

Abstract: As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

</details>


### [62] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

TL;DR: Falcon-H1R是一个7B参数的推理优化模型，证明了小语言模型也能达到竞争力的推理性能，在参数效率上超越大2-7倍的SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 探索小语言模型能否通过精心设计的数据策展和训练策略，在保持紧凑模型大小的同时实现强大的推理性能，解决大模型计算成本高的问题。

Method: 采用混合并行架构设计实现更快推理，结合高效监督微调（SFT）和强化学习（RL）扩展策略，利用DeepConf方法实现最先进的测试时扩展效率。

Result: 在多种推理密集型基准测试中，Falcon-H1R-7B能够匹配或超越比它大2-7倍的SOTA推理模型，实现了推理效率的3D极限（更快推理、token效率、更高准确率）。

Conclusion: 紧凑模型通过有针对性的模型训练和架构选择，能够提供强大且可扩展的推理性能，为需要大量思维链生成和并行测试时扩展的场景提供了实用的骨干模型。

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [63] [From Random Walks to Thermal Rides: Universal Anomalous Transport in Soaring Flights](https://arxiv.org/abs/2601.01293)
*Jérémie Vilpellet,Alexandre Darmon,Michael Benzaquen*

Main category: cond-mat.stat-mech

TL;DR: 研究发现滑翔飞行遵循普遍的非弹道输运规律，赫斯特指数约0.88，表明水平运动呈现亚弹道特征，这种标度行为源于滑翔飞行的间歇性、二维性和方向相关性。


<details>
  <summary>Details</summary>
Motivation: 研究滑翔飞行（包括滑翔伞、悬挂式滑翔机和滑翔机）如何利用大气上升气流进行长距离飞行，探索这种间歇性运输模式的普遍规律，理解人类滑翔与生物和物理系统中异常输运现象的相似性。

Method: 使用大型滑翔飞行数据集，分析水平运动的标度行为，采用概率分割方法进行相位分辨分析，研究滑翔飞行的间歇性特征，比较不同飞行器类型的输运规律。

Result: 发现超越短弹道时间后，水平运动呈现持续的亚弹道特征，赫斯特指数约0.88且与飞行器类型基本无关；这种标度源于滑翔运输的间歇性、二维性和方向相关性；学习效应主要体现在搜索阶段，提高探测空气质量和定位下一个热气流的能力。

Conclusion: 大气结构和过渡-搜索-爬升循环的通用组织主导着输运特性，将人类滑翔与生物和物理系统中因间歇性和持久性而产生异常输运的系统归为一类。

Abstract: Cross-country soaring flights rely on intermittent atmospheric updrafts to cover long distances, producing trajectories that alternate between rapid relocation and local exploration. From a large dataset of paraglider, hang glider, and sailplane flights, we uncover a universal transport law: beyond short ballistic times, horizontal motion is persistently sub-ballistic, with a Hurst exponent $\approx 0.88$ largely independent of aircraft type. Phase-resolved analysis using a probabilistic segmentation method shows that this scaling arises from the fundamentally intermittent, two-dimensional, and directionally correlated nature of soaring transport, in which successive ballistic segments do not add coherently. We find that learning, in the sense of experience-driven improvements in exploration and decision-making, manifests primarily in the search phase, enhancing the ability to efficiently probe the air mass and locate the next thermal. Overall, our results suggest that atmospheric structure and the generic organization of the transition-search-climb cycle dominate transport properties, placing human soaring alongside biological and physical systems where anomalous transport emerges from intermittency and persistence.

</details>


### [64] [Cellular Automata: From Structural Principles to Transport and Correlation Methods](https://arxiv.org/abs/2601.01278)
*Mihir Metkar,Neha Sah,Zoey Zhou*

Main category: cond-mat.stat-mech

TL;DR: 该论文是一篇关于元胞自动机的综述，重点讨论了三个核心主题：结构特性、输运机制和相关分析方法。


<details>
  <summary>Details</summary>
Motivation: 元胞自动机作为离散时间动力系统，虽然定义简单，但能展现统计物理中的多种宏观现象。论文旨在系统性地综述元胞自动机在相变、输运、粗粒化等方面的理论进展。

Method: 采用结构视角分析元胞自动机作为配置空间上的移位交换映射，研究规则复杂性、可逆性和守恒定律；将输运分为弹道、扩散和反常三种机制；开发基于相关性的分析方法。

Result: 论文系统性地综述了元胞自动机在统计物理中的应用，建立了微观规则与宏观现象之间的联系，提出了诊断不同输运机制的分析框架。

Conclusion: 元胞自动机为研究统计物理中的复杂现象提供了丰富的理论框架，通过结构分析、输运分类和相关方法，能够深入理解从微观规则到宏观行为的涌现过程。

Abstract: Cellular automata (CA) are discrete-time dynamical systems with local update rules on a lattice. Despite their elementary definition, CA support a wide spectrum of macroscopic phenomena central to statistical physics: equilibrium and nonequilibrium phase transitions, transport and hydrodynamic limits, kinetic roughening, self-organized criticality, and complex spatiotemporal correlations. This survey focuses on three tightly connected themes. \emph{(i)} We present a structural view of CA as shift-commuting maps on configuration spaces, emphasizing rule complexity, reversibility, and conservation laws (including discrete continuity equations). \emph{(ii)} We organize transport in CA into ballistic, diffusive, and anomalous regimes, and connect microscopic currents to macroscopic laws through Green--Kubo formulas, scaling theory, and universality classes. \emph{(iii)} We develop correlation-based methods -- from structure factors and response formulas to computational mechanics and data-driven inference -- that diagnose regimes and enable coarse-graining.

</details>


### [65] [Renewal theory for Brownian motion with stochastically gated targets](https://arxiv.org/abs/2601.01588)
*Paul C Bressloff*

Main category: cond-mat.stat-mech

TL;DR: 该论文开发了一种更新理论来处理随机门控首次通过时间问题，通过构建更新方程将粒子位置和门状态的联合概率密度与完全吸收边界的概率密度联系起来。


<details>
  <summary>Details</summary>
Motivation: 在物理和生命科学中存在多种首次通过时间问题，通常涉及布朗粒子与反应表面的结合。然而，在实际过程中，粒子可能经历多次表面吸附、解吸和扩散，或者表面可能被随机门控，只有在门打开时才能发生吸收。现有理论需要扩展以处理这种随机门控情况。

Method: 通过构建更新方程，将粒子位置和门状态（或多个门）的联合概率密度与完全吸收（非门控）边界的概率密度和首次通过时间密度联系起来。该方法将样本路径分解为体扩散和瞬时吸附/解吸事件的交替序列，当吸附与打开的门重合时终止。

Result: 通过多个示例展示了更新理论如何为将随机门控纳入首次通过时间问题提供一个通用的数学框架，证明了该方法的有效性和普适性。

Conclusion: 更新理论为处理随机门控首次通过时间问题提供了一个强大而通用的数学框架，能够有效描述涉及表面吸附/解吸和随机门控的复杂动力学过程。

Abstract: There are a wide range of first passage time (FTP) problems in the physical and life sciences that can be modelled in terms of a Brownian particle binding to a reactive surface (absorption). However, prior to absorption, the particle may undergo several rounds of surface attachment (adsorption), detachment (desorption) and diffusion. Alternatively, the surface may be stochastically gated so that absorption can only occur when the gate is open. In both cases one can view each return to the surface as a renewal event. In this paper we develop a renewal theory for stochastically gated FTP problems along analogous lines to previous work on adsorption/desorption processes. We proceed by constructing a renewal equation that relates the joint probability density for particle position and the state of a gate (or multiple gates) to the probability density and FPT density for a totally absorbing (non-gated) boundary. This essentially decomposes sample paths into an alternating sequence of bulk diffusion and instantaneous adsorption/desorption events, which is terminated when adsorption coincides with an open gate. Through a variety of examples, we show how renewal theory provides a general mathematical framework for incorporating stochastic gating into FTP problems.

</details>


### [66] [Variation on the theme of Jarzynski's inequality](https://arxiv.org/abs/2601.01644)
*Dani R. Castellanos,Petr Jizba*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究Jarzynski不等式的扩展应用，包括化学系统的线性响应和非线性区域，以及量子场论描述的多体统计系统，并探讨其与最大功定理和Landau-Lifshitz涨落理论的联系。


<details>
  <summary>Details</summary>
Motivation: Jarzynski等式在现代非平衡统计热力学中扮演核心角色，但通过Jensen不等式得到的Jarzynski不等式是其较弱推论。本文旨在探索超越直接从Jarzynski等式推导的Jarzynski不等式的多种扩展应用。

Method: 采用泛函积分技术，将Jarzynski不等式扩展到量子场论描述的多体统计系统；同时考虑化学系统在线性响应区域和远离线性热力学的区域。

Result: 建立了Jarzynski不等式的多种扩展形式，包括化学系统和量子场论系统的应用，并阐明了该不等式与最大功定理和Landau-Lifshitz涨落理论之间的重要联系。

Conclusion: Jarzynski不等式虽然是从Jarzynski等式推导的较弱推论，但其扩展应用范围广泛，在线性响应、非线性热力学和量子场论系统中都有重要理论价值，并与热力学基本定理密切相关。

Abstract: The Jarzynski equality, which relates equilibrium free-energy difference to an average of non-equilibrium work, plays a central role in modern non-equilibrium statistical thermodynamics. In this paper, we study a weaker consequence of this relation, known as Jarzynski's inequality, which can be formally obtained from the Jarzynski equality via Jensen's inequality. We identify and analyze several extensions of Jarzynski's inequality that go beyond its direct derivation from the Jarzynski equality. In particular, we consider chemical systems both in the linear-response regime and away from linear thermodynamics. Furthermore, by employing functional-integral techniques, we extend Jarzynski's inequality to many-body statistical systems described by quantum field theory. Salient issues, such as connections of the Jarzynski inequality with the maximum work theorem and the Landau--Lifshitz theory of fluctuations, are also discussed.

</details>


### [67] [Dislocations, vacancies and interstitials in the two-dimensional one-component plasma](https://arxiv.org/abs/2601.01809)
*G. Vilella Nilsson,M. A. Moore*

Main category: cond-mat.stat-mech

TL;DR: 研究二维圆柱表面上对数势相互作用的单组分等离子体(OCP)中位错、空位和间隙缺陷的能量与稳定性，发现标准KTHNY理论可能不适用于该系统。


<details>
  <summary>Details</summary>
Motivation: 研究二维单组分等离子体(OCP)中缺陷的物理特性，检验标准KTHNY理论在描述该系统相变行为时的适用性。

Method: 对圆柱曲面上对数势相互作用的电荷系统进行数值模拟，分析空位-间隙对、位错等缺陷的能量和稳定性。

Result: 空位-间隙对的库仑吸引对数项与弹性位移能在长距离下精确抵消；位错对的能量依赖于制备历史；孤立位错在某些系统尺寸下具有O(1)能量，可能被热激发。

Conclusion: 标准KTHNY理论可能不适用于二维OCP系统，支持了该系统可能不存在相变的早期观点。

Abstract: The energetics and stability of dislocations, vacancies and, interstitials in the one-component plasma (OCP), where the charges interact with a log potential and move on the curved surface of a cylinder have been investigated numerically. For vacancy-interstitial pairs, the log term of the direct Coulomb attraction and the elastic displacement energy cancel exactly at long distances, resulting in a defect energy of O(1). The numerical results confirm the predicted asymptotic behavior but also identify critical distances below which pairs evolve to different forms. We have found that bound pairs of dislocations - created by adding or removing 120 degree zig-zags of particles - have a dependence on their preparation history which is not accounted for in the usual starting point of the KTHNY theory. Furthermore, isolated dislocations, whose presence disrupts crystalline order, have energies of O(1) at some values of N, the number of particles in the system, and therefore will be thermally excited, raising questions about the applicability of standard KTHNY theory to the OCP, and supporting older suggestions that there are no phase transitions at all in the two-dimensional OCP.

</details>


### [68] [Longitudinal-field fidelity susceptibility analysis of the $J_1$-$J_2$ transverse-field Ising model around $J_2/J_1 \approx 0.5$](https://arxiv.org/abs/2601.01893)
*Yoshihiro Nishiyama*

Main category: cond-mat.stat-mech

TL;DR: 使用精确对角化方法研究J1-J2横向场Ising模型，通过纵向场保真度敏感性分析相变，修正了有限尺寸效应，估计了多临界指数。


<details>
  <summary>Details</summary>
Motivation: 研究J1-J2横向场Ising模型的相变行为，特别是在有限尺寸系统中分析临界现象时，需要解决自发磁化不出现的问题。

Method: 采用精确对角化方法，引入纵向场保真度敏感性χ_F^{(h)}，该敏感性耦合磁矩绝对值|M|而非原始M，以在临界点附近产生峰值。通过交叉标度公式分析数据，并用数值计算的β函数行为进行交叉验证。

Result: 修正后的保真度敏感性在临界点附近表现出峰值，通过标度分析估计了多临界指数，结果与β函数行为一致。

Conclusion: 纵向场保真度敏感性是分析有限尺寸系统临界现象的有效工具，成功应用于J1-J2横向场Ising模型，获得了可靠的多临界指数估计。

Abstract: The square-lattice $J_1$-$J_2$ transverse-field (TF) Ising model was investigated with the exact diagonalization (ED) method. In order to analyze the TF-driven phase transition, we applied the longitudinal-field fidelity susceptibility $χ^{(h)}_F$, which is readily evaluated via the ED scheme. Here, the longitudinal field couples with the absolute value of the magnetic moment $|M|$ rather than the raw $M$ so that the remedied fidelity susceptibility exhibits a peak around the critical point; note that the spontaneous magnetization does not appear for the finite-size systems. As a preliminary survey, the modified fidelity susceptibility $χ^{(h)}_F$ is applied to the analysis of criticality for $J_2=0$, where a number of preceding results are available. Thereby, properly scaling the distance from the multi-criticality, $η=0.5-J_2$, the $χ^{(h)}_F$ data were cast into the crossover-scaling formula, and the multi-critical exponent for $χ_F^{(h)}$ is estimated. The result is cross-checked by the numerically evaluated $β$-function behavior.

</details>


### [69] [Fitness Fluctuations and Correlation Time Scaling in the Barycentric Bak-Sneppen Model](https://arxiv.org/abs/2601.02027)
*Abdul Quadir,Haider Hasan Jafri*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了重心版Bak-Sneppen模型，这是一个描述具有局部相互作用规则的广义凯恩斯选美竞赛的一维自组织临界模型。通过数值分析适应度变量的功率谱密度和相关时间，估计了临界指数。同时研究了覆盖时间（系统在临界状态下所有物种灭绝或突变所需时间）的统计特性。


<details>
  <summary>Details</summary>
Motivation: 研究重心版Bak-Sneppen模型的临界行为和统计特性，该模型可用于描述具有局部相互作用的广义凯恩斯选美竞赛。通过分析适应度变量的功率谱密度和相关时间，以及系统覆盖时间的统计特性，深入理解该自组织临界模型的动力学行为。

Method: 采用数值模拟方法研究重心版Bak-Sneppen模型。通过数据塌缩技术估计临界指数，分析全局和局部适应度变量的功率谱密度。使用有限尺寸标度和极值理论分析覆盖时间的统计特性，包括均值、方差、众数和峰值概率的幂律标度行为。

Result: 全局和局部适应度变量的功率谱密度表现出1/f^α谱（0<α<2），表明存在长程相关性。覆盖时间的均值、方差、众数和峰值概率均表现出与系统尺寸的幂律标度关系。累积概率分布呈现数据塌缩，其标度函数可由广义极值密度很好地描述，近似属于Gumbel分布族。

Conclusion: 重心版Bak-Sneppen模型表现出典型的自组织临界行为，适应度变量具有长程相关性，覆盖时间的统计特性符合极值理论预测，特别是Gumbel分布特征。这些结果为理解该模型的临界动力学和统计特性提供了重要见解。

Abstract: We consider the barycentric version of the Bak-Sneppen model, a one-dimensional self-organized critical model that describes generalized Keynesian beauty contests with a local interaction rule. We numerically investigate the power spectral density of the fitness variable and correlation time. Through data collapse for both variables, we estimate the critical exponents. For global and local fitness variables, the power spectral density exhibits $1/f^α$ with $0< α< 2$, indicative of long-range correlations. We also investigate the cover time, defined as the duration required for the extinction or mutation of species across the entire system in the critical state of the barycentric BS model. Using finite-size scaling and extreme value theory, we analyze the statistical properties of the cover time. Our results show power-law scaling with system size for the mean, variance, mode, and peak probability. Furthermore, the cumulative probability distribution exhibits data collapse, and the associated scaling function is well described by the generalized extreme value density, closely approximating the Gumbel family.

</details>


### [70] [A bottom-up approach to fluctuating hydrodynamics: Coarse-graining of stochastic lattice gases and the Dean-Kawasaki equation](https://arxiv.org/abs/2601.02319)
*Soumyabrata Saha,Sandeep Jangid,Thibaut Arnoulx de Pirey,Juliane U. Klamser,Tridib Sadhu*

Main category: cond-mat.stat-mech

TL;DR: 本文开发了一种从微观随机动力学到涨落流体动力学的系统推导方法，特别针对具有梯度动力学的随机晶格气体模型和相互作用的布朗粒子系统。


<details>
  <summary>Details</summary>
Motivation: 涨落流体动力学虽然能成功描述宏观涨落和关联，但从微观随机动力学到该框架的系统推导在许多相互作用系统中仍然不明确，需要建立更严格的理论基础。

Method: 采用基于路径积分的粗粒化方法，针对具有梯度动力学的随机晶格气体模型，并扩展到相互作用的布朗粒子系统，通过粗粒化Dean-Kawasaki方程。

Result: 成功以可控方式恢复了涨落流体动力学，揭示了局域平衡平均的关键作用（超越简单的平均场梯度展开），并发现迁移率与密度成正比，扩散率由热力学压力决定。

Conclusion: 为从微观随机动力学推导涨落流体动力学提供了系统框架，强调了局域平衡平均的重要性，并成功应用于不同类型相互作用系统的粗粒化描述。

Abstract: Fluctuating hydrodynamics provides a quantitative, large-scale description of many-body systems in terms of smooth variables, with microscopic details entering only through a small set of transport coefficients. Although this framework has been highly successful in characterizing macroscopic fluctuations and correlations, a systematic derivation of fluctuating hydrodynamics from underlying stochastic microscopic dynamics remains obscure for broad classes of interacting systems. For stochastic lattice gas models with gradient dynamics and a single conserved density, we develop a path-integral based coarse-graining procedure that recovers fluctuating hydrodynamics in a controlled manner. Our analysis highlights the essential role of local-equilibrium averages, which go beyond naïve mean-field-type gradient expansions. We further extend this approach to interacting Brownian particles by coarse-graining the Dean-Kawasaki equation, revealing a mobility proportional to the density and a diffusivity determined by the thermodynamic pressure.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [71] [Horizon Reduction as Information Loss in Offline Reinforcement Learning](https://arxiv.org/abs/2601.00831)
*Uday Kumar Nidadala,Venkata Bhumika Guthi*

Main category: cs.LG

TL;DR: 本文证明离线强化学习中常用的视野缩减策略可能导致不可恢复的信息损失，即使有无限数据和完美函数逼近，最优策略也可能与次优策略在统计上无法区分。


<details>
  <summary>Details</summary>
Motivation: 尽管经验证据表明视野缩减可以改善离线强化学习的扩展性，但其理论影响尚未充分发展。本文旨在揭示视野缩减可能导致的基本信息损失问题。

Method: 将视野缩减形式化为从固定长度轨迹片段中学习，通过最小反例马尔可夫决策过程识别三种结构失效模式：前缀不可区分性、截断回报导致的目标误设、离线数据集支持和表示混叠。

Result: 证明在固定长度轨迹片段学习范式下，最优策略可能与次优策略在统计上无法区分，即使有无限数据和完美函数逼近。建立了视野缩减安全应用的必要条件。

Conclusion: 视野缩减在离线强化学习中存在固有的信息损失限制，这些限制无法仅通过算法改进克服，补充了关于保守目标和分布偏移的算法工作。

Abstract: Horizon reduction is a common design strategy in offline reinforcement learning (RL), used to mitigate long-horizon credit assignment, improve stability, and enable scalable learning through truncated rollouts, windowed training, or hierarchical decomposition (Levine et al., 2020; Prudencio et al., 2023; Park et al., 2025). Despite recent empirical evidence that horizon reduction can improve scaling on challenging offline RL benchmarks, its theoretical implications remain underdeveloped (Park et al., 2025). In this paper, we show that horizon reduction can induce fundamental and irrecoverable information loss in offline RL. We formalize horizon reduction as learning from fixed-length trajectory segments and prove that, under this paradigm and any learning interface restricted to fixed-length trajectory segments, optimal policies may be statistically indistinguishable from suboptimal ones even with infinite data and perfect function approximation. Through a set of minimal counterexample Markov decision processes (MDPs), we identify three distinct structural failure modes: (i) prefix indistinguishability leading to identifiability failure, (ii) objective misspecification induced by truncated returns, and (iii) offline dataset support and representation aliasing. Our results establish necessary conditions under which horizon reduction can be safe and highlight intrinsic limitations that cannot be overcome by algorithmic improvements alone, complementing algorithmic work on conservative objectives and distribution shift that addresses a different axis of offline RL difficulty (Fujimoto et al., 2019; Kumar et al., 2020; Gulcehre et al., 2020).

</details>


### [72] [Hierarchical topological clustering](https://arxiv.org/abs/2601.00892)
*Ana Carpio,Gema Duro*

Main category: cs.LG

TL;DR: 提出一种层次拓扑聚类算法，适用于任意距离度量，能够识别任意形状的聚类和异常值，在图像、医疗和经济数据中展示有效性


<details>
  <summary>Details</summary>
Motivation: 拓扑方法能够在不对数据结构做假设的情况下探索数据云，但需要一种能够处理任意距离度量并有效识别异常值和任意形状聚类的算法

Method: 提出层次拓扑聚类算法，该算法可以应用于任意距离选择，从生成的层次结构中推断异常值和任意形状聚类的持续性

Result: 在包含图像、医疗和经济数据的选定数据集上验证了算法的潜力，这些数据中异常值扮演重要角色，算法能够提供其他技术无法获得的具有意义的聚类

Conclusion: 层次拓扑聚类算法能够有效处理任意距离度量，识别异常值和任意形状的聚类，在多种实际应用场景中表现出优于传统方法的性能

Abstract: Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.

</details>


### [73] [SLO-Conditioned Action Routing for Retrieval-Augmented Generation: Objective Ablation and Failure Modes](https://arxiv.org/abs/2601.00841)
*Bharath Nunepalli*

Main category: cs.LG

TL;DR: 论文研究RAG系统的查询级控制问题，通过选择检索深度和生成模式来满足成本、拒绝率等SLO目标，使用离线数据集训练简单策略，发现固定基线表现良好，学习策略主要在质量导向SLO下提供成本节省


<details>
  <summary>Details</summary>
Motivation: 检索增强生成(RAG)系统面临实际的查询级控制问题：需要为每个查询选择合适的检索深度和生成行为（保护模式vs自动模式），以满足服务级别目标(SLOs)，包括成本、拒绝率和幻觉风险

Method: 将查询级控制建模为离散动作选择：选择检索深度和生成模式（保护vs自动）或拒绝查询。基于SQuAD 2.0构建离线日志数据集，执行每个动作并记录准确性、令牌成本、幻觉/拒绝指标及SLO加权奖励。评估两种简单策略学习目标：基于状态的最佳动作监督分类(Argmax-CE)和奖励加权变体(Argmax-CE-WT)

Result: 在评估的设置中，强固定基线（低k值、保护提示）表现具有竞争力；学习策略主要在质量导向SLO下提供额外的成本节省，在廉价SLO下当拒绝被高度奖励时可能出现拒绝崩溃现象

Conclusion: 本文贡献是RAG管道SLO感知控制的可重复案例研究，强调故障模式和报告规范，而非提出新的检索器或语言模型。研究表明简单策略学习在特定条件下有效，但固定基线仍具竞争力

Abstract: Retrieval-augmented generation (RAG) introduces a practical control problem: retrieval depth and generation behavior must be chosen per query to satisfy service-level objectives (SLOs) such as cost, refusal rate, and hallucination risk. This work models per-query control as a small discrete action: choose a retrieval depth and a generation mode (guarded vs. auto), or refuse. An offline logged dataset is constructed from SQuAD 2.0 by executing each action and recording accuracy, token cost, hallucination/refusal indicators, and an SLO-weighted reward. Two simple policy-learning objectives are evaluated: supervised classification of the per-state best action (Argmax-CE) and a reward-weighted variant (Argmax-CE-WT). Across the evaluated settings, a strong fixed baseline (low k, guarded prompting) performs competitively; learned policies mainly provide additional cost savings under a quality-focused SLO and can exhibit refusal collapse under a cheap SLO when refusal is heavily rewarded. The contribution is a reproducible case study of SLO-aware control for RAG pipelines, emphasizing failure modes and reporting conventions rather than proposing a new retriever or language model.

</details>


### [74] [Value-guided action planning with JEPA world models](https://arxiv.org/abs/2601.00844)
*Matthieu Destrade,Oumayma Bounou,Quentin Le Lidec,Jean Ponce,Yann LeCun*

Main category: cs.LG

TL;DR: 该研究提出了一种增强JEPA世界模型规划能力的方法，通过塑造表示空间，使负目标条件值函数近似于状态嵌入之间的距离，从而显著提升简单控制任务中的规划性能。


<details>
  <summary>Details</summary>
Motivation: 虽然联合嵌入预测架构（JEPA）能够通过自监督预测目标学习环境动态表示，但其在有效行动规划方面的能力仍然有限。需要增强JEPA世界模型的规划能力，使其能够更好地支持智能体在环境中的决策和行动。

Method: 提出通过塑造JEPA表示空间的方法，使负目标条件值函数（针对给定环境中的到达成本）能够近似于状态嵌入之间的距离（或准距离）。引入了一种实用的训练方法来强制执行这一约束条件。

Result: 在简单控制任务上，该方法相比标准JEPA模型显著提升了规划性能，证明了通过塑造表示空间来近似值函数能够有效增强世界模型的规划能力。

Conclusion: 通过将目标条件值函数约束为状态嵌入之间的距离，可以显著增强JEPA世界模型的规划能力，为构建能够有效推理环境动态的深度学习模型提供了有前景的方向。

Abstract: Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.

</details>


### [75] [You Only Need Your Transformer 25% of the Time: Meaning-First Execution for Eliminating Unnecessary Inference](https://arxiv.org/abs/2601.00847)
*Ryan Shamim*

Main category: cs.LG

TL;DR: MFEE框架将推理重构为控制平面决策问题，通过语义分析选择性执行transformer，在保持100%准确率的同时减少78.1%的计算量。


<details>
  <summary>Details</summary>
Motivation: 当前AI推理系统将transformer执行视为强制性的，混淆了模型能力与执行必要性。作者认为许多情况下可以通过替代路径保持正确性，无需完整执行。

Method: 提出Meaning-First Execution (MFEE)控制平面架构，作为现有堆栈之上的门控层，不修改模型、权重或参数。通过语义分析判断何时需要执行transformer推理，何时可以通过替代路径保持正确性。

Result: 在1000个多样化提示的确定性解码测试中，MFEE实现了78.1%的执行减少，同时保持100%的精确匹配等价性。相比基于模式的路由器最多只能达到53.3%的避免率且存在正确性失败，MFEE通过语义分析实现了100%的避免率且零失败。

Conclusion: 证明了仅基于有限特征映射的路由器无法同时保证零错误跳过和正避免率。执行治理应成为ML系统基础设施的基础层，与模型级优化技术正交。

Abstract: Modern AI inference systems treat transformer execution as mandatory, conflating model capability with execution necessity. We reframe inference as a control-plane decision problem: determining when execution is necessary versus when correctness can be preserved through alternative pathways. We introduce Meaning-First Execution (MFEE), a control-plane architecture implementing this framework, selectively invoking transformer inference only when required. MFEE operates as a gating layer above existing stacks without modifying models, weights, or parameters. Across 1,000 diverse prompts under deterministic decoding, MFEE achieves 78.1% execution reduction while maintaining 100% exact-match equivalence for invoked executions. Comparative evaluation reveals pattern-based routers achieve at most 53.3% avoidance with correctness failures, while MFEE reaches 100% avoidance with zero failures through semantic analysis. We prove this limitation via Theorem 1: any router operating solely on finite feature maps cannot simultaneously guarantee zero false skips and positive avoidance on feature-collision pairs. These results establish execution governance as a foundational layer in ML systems infrastructure, orthogonal to model-level optimization techniques.

</details>


### [76] [EdgeJury: Cross-Reviewed Small-Model Ensembles for Truthful Question Answering on Serverless Edge Inference](https://arxiv.org/abs/2601.00850)
*Aayush Kumar*

Main category: cs.LG

TL;DR: EdgeJury是一个轻量级集成框架，使用小型指令调优语言模型（3B-8B）通过四阶段协调流程提高问答的真实性和鲁棒性，在资源受限的边缘部署中显著减少幻觉错误。


<details>
  <summary>Details</summary>
Motivation: 幻觉问题阻碍了可靠的问答系统，特别是在资源受限的部署环境中，前沿规模模型或检索管道可能不切实际。需要一种轻量级解决方案，在不依赖大型模型或外部检索的情况下提高真实性和鲁棒性。

Method: EdgeJury采用四阶段协调框架：1) 并行角色专业化生成；2) 匿名交叉评审，包含结构化批评和排名；3) 主席综合，整合最强内容并解决标记问题；4) 基于模型间一致性的声明级一致性标注。该框架仅使用小型指令调优语言模型（3B-8B），适合无服务器边缘推理。

Result: 在TruthfulQA（MC1）上，EdgeJury达到76.2%准确率（95% CI: 72.8-79.6%），相比单个8B基线（62.8%）相对提升21.4%。在200个问题的对抗性EdgeCases集上，获得48.2%的相对增益。人工分析显示，与单模型基线相比，事实性幻觉错误减少约55%。在Cloudflare Workers AI上部署时，中位端到端延迟为8.4秒。

Conclusion: 协调的小型模型集成可以在不依赖外部检索或专有大型模型API的情况下，显著提高对误解密集型问答基准的真实性，为资源受限的边缘部署提供了可行的解决方案。

Abstract: Hallucinations hinder reliable question answering, especially in resource-constrained deployments where frontier-scale models or retrieval pipelines may be impractical. We present EdgeJury, a lightweight ensemble framework that improves truthfulness and robustness using only small instruction-tuned language models (3B-8B) suitable for serverless edge inference. EdgeJury orchestrates four stages: (1) parallel role-specialized generation, (2) anonymized cross-review with structured critiques and rankings, (3) chairman synthesis that integrates the strongest content while addressing flagged issues, and (4) claim-level consistency labeling based on inter-model agreement. On TruthfulQA (MC1), EdgeJury achieves 76.2% accuracy (95% CI: 72.8-79.6%), a +21.4% relative improvement over a single 8B baseline (62.8%), and outperforms standard baselines including self-consistency and majority voting under transparent compute accounting (total tokens and platform cost reported). On a 200-question adversarial EdgeCases set, EdgeJury yields +48.2% relative gains (95% CI: 44.0-52.4%). Manual analysis on 100 incorrect answers shows an approximately 55% reduction in factual hallucination errors versus the single-model baseline. Deployed on Cloudflare Workers AI, EdgeJury achieves 8.4 s median end-to-end latency, demonstrating that coordinated small-model ensembles can improve truthfulness on misconception-heavy QA benchmarks without external retrieval or proprietary large-model APIs.

</details>


### [77] [FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments](https://arxiv.org/abs/2601.00853)
*Sameer Rahil,Zain Abdullah Ahmad,Talha Asif*

Main category: cs.LG

TL;DR: FedSCAM提出了一种联邦学习算法，通过基于客户端异质性动态调整SAM扰动半径和聚合权重，解决非IID数据下的收敛和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据的统计异质性（特别是非IID标签分布）对模型收敛和泛化构成重大挑战。现有方法通常对所有客户端使用统一的扰动半径，忽略了客户端特定的异质性差异。

Method: 提出FedSCAM算法：1) 为每个客户端计算异质性度量；2) 根据异质性分数反向调制SAM扰动半径，防止高方差客户端破坏全局模型稳定性；3) 引入异质性感知的加权聚合机制，优先考虑与全局优化方向一致的客户端更新。

Result: 在CIFAR-10和Fashion-MNIST数据集上，使用基于狄利克雷的标签偏斜设置进行实验，FedSCAM在收敛速度和最终测试准确率方面与FedSAM、FedLESAM等最先进基线相比具有竞争力。

Conclusion: FedSCAM通过动态调整SAM扰动半径和异质性感知聚合，有效解决了联邦学习中的统计异质性问题，提升了模型在非IID数据下的性能表现。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.

</details>


### [78] [Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks](https://arxiv.org/abs/2601.00857)
*Yuchi Ma,Yawen Shen,Anu Swatantran,David B. Lobell*

Main category: cs.LG

TL;DR: 本研究评估了AlphaEarth Foundation (AEF)地理空间基础模型在农业监测任务中的应用，包括作物产量预测、耕作制图和覆盖作物制图，并与传统遥感模型进行比较。


<details>
  <summary>Details</summary>
Motivation: 虽然AEF等地理空间基础模型在土地覆盖分类任务中表现出色，但在农业监测关键下游任务中的应用缺乏深入评估，且缺乏与传统遥感模型的全面比较。

Method: 使用AEF嵌入在三个美国农业下游任务中进行评估：作物产量预测、耕作制图和覆盖作物制图。收集公共和私有数据集，在不同尺度和位置评估AEF嵌入，并训练传统遥感模型作为对比模型。

Result: AEF模型在所有任务中表现良好，在产量预测和县级耕作制图任务中与专门构建的遥感模型竞争力相当。但发现AEF嵌入存在空间可转移性有限、可解释性低和时间敏感性不足等局限性。

Conclusion: AEF嵌入在农业应用中具有潜力，但在时间敏感性、泛化能力和可解释性要求高的农业场景中需谨慎使用，建议考虑其局限性。

Abstract: Geospatial foundation models (GFMs) have emerged as a promising approach to overcoming the limitations in existing featurization methods. More recently, Google DeepMind has introduced AlphaEarth Foundation (AEF), a GFM pre-trained using multi-source EOs across continuous time. An annual and global embedding dataset is produced using AEF that is ready for analysis and modeling. The internal experiments show that AEF embeddings have outperformed operational models in 15 EO tasks without re-training. However, those experiments are mostly about land cover and land use classification. Applying AEF and other GFMs to agricultural monitoring require an in-depth evaluation in critical agricultural downstream tasks. There is also a lack of comprehensive comparison between the AEF-based models and traditional remote sensing (RS)-based models under different scenarios, which could offer valuable guidance for researchers and practitioners. This study addresses some of these gaps by evaluating AEF embeddings in three agricultural downstream tasks in the U.S., including crop yield prediction, tillage mapping, and cover crop mapping. Datasets are compiled from both public and private sources to comprehensively evaluate AEF embeddings across tasks at different scales and locations, and RS-based models are trained as comparison models. AEF-based models generally exhibit strong performance on all tasks and are competitive with purpose-built RS-based models in yield prediction and county-level tillage mapping when trained on local data. However, we also find several limitations in current AEF embeddings, such as limited spatial transferability compared to RS-based models, low interpretability, and limited time sensitivity. These limitations recommend caution when applying AEF embeddings in agriculture, where time sensitivity, generalizability, and interpretability is important.

</details>


### [79] [Path Integral Solution for Dissipative Generative Dynamics](https://arxiv.org/abs/2601.00860)
*Xidi Wang*

Main category: cs.LG

TL;DR: 该论文证明纯机械系统通过耗散量子动力学和非局部上下文聚合可以生成智能语言，而守恒定律会导致根本性失败。语言生成本质上是耗散量子场论，智能来自耗散和非局域性的结合而非守恒。


<details>
  <summary>Details</summary>
Motivation: 探索纯机械系统是否能够生成智能语言，研究量子动力学中的耗散与非局域性在语言生成中的作用，挑战传统认为守恒定律是智能系统基础的观念。

Method: 使用具有封闭形式路径积分传播子的Koopman算子，分析耗散量子动力学中的非局部上下文聚合。通过谱分析揭示特征值结构，包括衰减模式（遗忘）、增长模式（放大）和中性模式（保持）。

Result: 耗散量子动力学能够产生连贯的文本生成，而哈密顿约束（守恒定律）会消除耗散模式并导致性能下降。谱分析显示特征值结构分离为三种模式，这是定向信息流的基本要素。

Conclusion: 语言生成本质上是耗散量子场论，机械系统通过耗散和非局域性的结合获得智能，而非通过守恒定律。不可逆计算需要受控的信息耗散和因果上下文聚合。

Abstract: Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.

</details>


### [80] [Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions](https://arxiv.org/abs/2601.00862)
*Joey Chan,Huan Wang,Haoyu Pan,Wei Wu,Zirong Wang,Zhen Chen,Ershun Pan,Min Xie,Lifeng Xi*

Main category: cs.LG

TL;DR: 提出一个统一的电池容量衰减预测框架，使用时间序列基础模型和参数高效微调技术，在包含1704个电池的大规模数据集上实现了跨化学体系和使用场景的稳健性能。


<details>
  <summary>Details</summary>
Motivation: 电池容量衰减的准确预测对储能系统的安全、可靠和长期效率至关重要，但由于电池化学体系、外形尺寸和运行条件的强异质性，很难构建一个能泛化到训练域之外的单一模型。

Method: 构建包含20个公开老化数据集的大规模语料库（1704个电池，396万多个充放电循环段），采用时间序列基础模型作为骨干，结合参数高效的低秩适应技术和物理引导的对比表示学习来捕捉共享的退化模式。

Result: 在已见和特意保留的未见数据集上的实验表明，单一统一模型相比强大的每个数据集基线模型实现了竞争性或更优的准确性，同时在训练中排除的化学体系、容量尺度和运行条件下保持稳定性能。

Conclusion: 基于时间序列基础模型的架构展示了作为电池管理系统中容量退化预测的可扩展和可迁移解决方案的潜力。

Abstract: Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes beyond its training domain. This work proposes a unified capacity forecasting framework that maintains robust performance across diverse chemistries and usage scenarios. We curate 20 public aging datasets into a large-scale corpus covering 1,704 cells and 3,961,195 charge-discharge cycle segments, spanning temperatures from $-5\,^{\circ}\mathrm{C}$ to $45\,^{\circ}\mathrm{C}$, multiple C-rates, and application-oriented profiles such as fast charging and partial cycling. On this corpus, we adopt a Time-Series Foundation Model (TSFM) backbone and apply parameter-efficient Low-Rank Adaptation (LoRA) together with physics-guided contrastive representation learning to capture shared degradation patterns. Experiments on both seen and deliberately held-out unseen datasets show that a single unified model achieves competitive or superior accuracy compared with strong per-dataset baselines, while retaining stable performance on chemistries, capacity scales, and operating conditions excluded from training. These results demonstrate the potential of TSFM-based architectures as a scalable and transferable solution for capacity degradation forecasting in real battery management systems.

</details>


### [81] [Distribution Matching for Graph Quantification Under Structural Covariate Shift](https://arxiv.org/abs/2601.00864)
*Clemens Damke,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 该研究将结构重要性采样扩展到最先进的KDEy量化方法，以解决图数据中的结构偏移问题，在标签分布估计任务中优于标准量化方法。


<details>
  <summary>Details</summary>
Motivation: 在图数据中，当训练数据和测试数据来自图的不同区域时，传统的先验概率偏移假设不再成立，导致现有量化学习方法无法有效处理结构偏移问题。

Method: 将结构重要性采样的思想扩展到最先进的KDEy量化方法，通过重要性采样来适应图数据中的结构偏移。

Result: 提出的方法能够适应结构偏移，并在标签分布估计任务中优于标准量化方法。

Conclusion: 通过将结构重要性采样与KDEy量化方法结合，可以有效解决图数据中的结构偏移问题，为图量化学习提供了更强大的工具。

Abstract: Graphs are commonly used in machine learning to model relationships between instances. Consider the task of predicting the political preferences of users in a social network; to solve this task one should consider, both, the features of each individual user and the relationships between them. However, oftentimes one is not interested in the label of a single instance but rather in the distribution of labels over a set of instances; e.g., when predicting the political preferences of users, the overall prevalence of a given opinion might be of higher interest than the opinion of a specific person. This label prevalence estimation task is commonly referred to as quantification learning (QL). Current QL methods for tabular data are typically based on the so-called prior probability shift (PPS) assumption which states that the label-conditional instance distributions should remain equal across the training and test data. In the graph setting, PPS generally does not hold if the shift between training and test data is structural, i.e., if the training data comes from a different region of the graph than the test data. To address such structural shifts, an importance sampling variant of the popular adjusted count quantification approach has previously been proposed. In this work, we extend the idea of structural importance sampling to the state-of-the-art KDEy quantification approach. We show that our proposed method adapts to structural shifts and outperforms standard quantification approaches.

</details>


### [82] [Outlier Detection Using Vector Cosine Similarity by Adding a Dimension](https://arxiv.org/abs/2601.00883)
*Zhongyang Shen*

Main category: cs.LG

TL;DR: 提出了一种基于向量余弦相似度的多维异常值检测方法，通过在原数据中添加零值维度构建新数据集，利用观测点和测量点之间的向量相似性来识别异常数据。


<details>
  <summary>Details</summary>
Motivation: 需要一种有效的多维数据异常检测方法，能够处理复杂的高维数据模式，传统方法可能在高维空间中表现不佳。

Method: 在原数据中添加一个零值维度构建新数据集，选择测量点后创建观测点（仅在新增维度有非零值），计算从观测点到测量点及其他点的向量，通过比较这些向量的余弦相似度来识别异常数据。

Result: 开发了优化的实现MDOD，已在PyPI上发布，可用于实际的多维异常检测任务。

Conclusion: 该方法提供了一种基于向量几何特性的新颖异常检测方法，通过余弦相似度比较能够有效识别多维数据中的异常点。

Abstract: We propose a new outlier detection method for multi-dimensional data. The method detects outliers based on vector cosine similarity, using a new dataset constructed by adding a dimension with zero values to the original data. When a point in the new dataset is selected as the measured point, an observation point is created as the origin, differing only in the new dimension by having a non-zero value compared to the measured point. Vectors are then formed from the observation point to the measured point and to other points in the dataset. By comparing the cosine similarities of these vectors, abnormal data can be identified. An optimized implementation (MDOD) is available on PyPI: https://pypi.org/project/mdod/.

</details>


### [83] [FANoS: Friction-Adaptive Nosé--Hoover Symplectic Momentum for Stiff Objectives](https://arxiv.org/abs/2601.00889)
*Nalin Dhiman*

Main category: cs.LG

TL;DR: FANoS是一种受物理启发的优化器，结合了二阶动力系统、Nosé-Hoover恒温器和辛积分器，在特定非凸问题上表现良好，但总体上不如现代基线方法稳定。


<details>
  <summary>Details</summary>
Motivation: 受分子动力学中结构保持积分和恒温器思想的启发，开发一种物理启发的优化器，用于处理非凸优化问题中的刚性山谷。

Method: FANoS结合了：(1) 离散化二阶动力系统的动量更新，(2) 使用动能反馈调整标量摩擦系数的Nosé-Hoover类恒温器变量，(3) 半隐式辛积分器，可选配对角RMS预处理器。

Result: 在Rosenbrock-100D基准测试中，FANoS-RMS达到1.74×10⁻²，优于未剪裁的AdamW(48.50)和SGD+momentum(90.76)，但弱于梯度剪裁的AdamW(1.87×10⁻³)和L-BFGS(≈4.4×10⁻¹⁰)。在病态凸二次问题和小型PINN预热测试中表现不稳定。

Conclusion: FANoS是对现有思想的解释性综合，在某些刚性非凸山谷问题上有效，但不是现代基线的通用替代品，其行为对温度调度和超参数选择敏感。

Abstract: We study a physics-inspired optimizer, \emph{FANoS} (Friction-Adaptive Nosé--Hoover Symplectic momentum), which combines (i) a momentum update written as a discretized second-order dynamical system, (ii) a Nosé--Hoover-like thermostat variable that adapts a scalar friction coefficient using kinetic-energy feedback, and (iii) a semi-implicit (symplectic-Euler) integrator, optionally with a diagonal RMS preconditioner. The method is motivated by structure-preserving integration and thermostat ideas from molecular dynamics, but is used here purely as an optimization heuristic.
  We provide the algorithm and limited theoretical observations in idealized settings. On the deterministic Rosenbrock-100D benchmark with 3000 gradient evaluations, FANoS-RMS attains a mean final objective value of $1.74\times 10^{-2}$, improving substantially over unclipped AdamW ($48.50$) and SGD+momentum ($90.76$) in this protocol. However, AdamW with gradient clipping is stronger, reaching $1.87\times 10^{-3}$, and L-BFGS reaches $\approx 4.4\times 10^{-10}$. On ill-conditioned convex quadratics and in a small PINN warm-start suite (Burgers and Allen--Cahn), the default FANoS configuration underperforms AdamW and can be unstable or high-variance.
  Overall, the evidence supports a conservative conclusion: FANoS is an interpretable synthesis of existing ideas that can help on some stiff nonconvex valleys, but it is not a generally superior replacement for modern baselines, and its behavior is sensitive to temperature-schedule and hyperparameter choices.

</details>


### [84] [When to Ponder: Adaptive Compute Allocation for Code Generation via Test-Time Training](https://arxiv.org/abs/2601.00894)
*Gihyeon Sim*

Main category: cs.LG

TL;DR: PonderTTT：一种基于重构损失的自适应门控策略，用于选择性触发测试时训练更新，无需额外训练，仅需单个标量阈值


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对所有输入采用统一计算，不考虑难度差异。需要一种方法能够根据输入难度自适应地决定是否进行测试时训练更新，以提高效率

Method: 使用TTT层的自监督重构损失作为门控信号，通过单个标量阈值决定是否触发测试时训练更新。阈值在无标签数据上初始校准，并通过指数移动平均持续调整以维持目标更新率

Result: 在GPT-2模型（124M到1.5B）的代码语言建模任务中，重构门控实现了82-89%的Oracle恢复率，完全无需训练，显著优于随机跳过基线（在OOD语言上损失降低达16%）

Conclusion: PonderTTT提供了一种推理兼容、无需训练的门控策略，能够有效识别需要测试时训练更新的困难样本，提高模型效率

Abstract: Large language models apply uniform computation to all inputs, regardless of difficulty. We propose PonderTTT, a gating strategy using the TTT layer's self-supervised reconstruction loss to selectively trigger Test-Time Training (TTT) updates. The gating decision itself is training-free--requiring no learned classifier or auxiliary networks; only a single scalar threshold is initially calibrated on unlabeled data and continuously adapted via EMA to maintain target update rates. Our experiments with GPT-2 models (124M to 1.5B) on code language modeling (The Stack v2, teacher-forced perplexity) demonstrate that this signal is inference-compatible, requiring no ground-truth labels. Our Reconstruction Gating achieves 82-89% Oracle Recovery while being fully training-free, significantly outperforming Random Skip baselines (up to 16% lower loss on OOD languages).

</details>


### [85] [Dichotomous Diffusion Policy Optimization](https://arxiv.org/abs/2601.00898)
*Ruiming Liang,Yinan Zheng,Kexin Zheng,Tianyi Tan,Jianxiong Li,Liyuan Mao,Zhihao Wang,Guang Chen,Hangjun Ye,Jingjing Liu,Jinqiao Wang,Xianyuan Zhan*

Main category: cs.LG

TL;DR: DIPOLE是一种新颖的强化学习算法，通过将最优策略分解为一对稳定学习的二分策略（一个最大化奖励，一个最小化奖励），解决了扩散策略在强化学习中训练不稳定和计算效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在强化学习训练中存在两个主要问题：1）直接最大化价值目标导致训练不稳定；2）依赖粗糙的高斯似然近似需要大量小去噪步骤，计算效率低。需要一种稳定且可控的扩散策略优化方法。

Method: 提出DIPOLE算法：1）重新审视RL中的KL正则化目标，提供扩散策略提取的加权回归目标；2）设计贪婪化策略正则化方案，将最优策略分解为一对二分策略（奖励最大化和最小化）；3）推理时通过线性组合二分策略的分数生成优化动作，实现贪婪程度的灵活控制。

Result: 在ExORL和OGBench的离线和离线到在线RL设置中验证了方法的有效性。使用DIPOLE训练了用于端到端自动驾驶的大型视觉-语言-动作模型，并在大规模真实世界自动驾驶基准NAVSIM上评估，展示了其在复杂现实应用中的潜力。

Conclusion: DIPOLE为扩散策略的强化学习训练提供了稳定、可控且计算高效的解决方案，能够处理复杂的现实世界决策任务，特别是在自动驾驶等需要精细控制的领域具有重要应用价值。

Abstract: Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.

</details>


### [86] [Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment](https://arxiv.org/abs/2601.00908)
*Chorok Lee*

Main category: cs.LG

TL;DR: 本文研究了分布偏移下保形预测性能的退化问题，通过COVID-19作为自然实验，发现覆盖率的下降程度差异巨大（0%到86.7%），与单特征依赖性高度相关。SHAP分析显示灾难性失败与特征重要性集中度相关，而季度重训练能显著改善脆弱任务但无法提升稳健任务。


<details>
  <summary>Details</summary>
Motivation: 保形预测在分布偏移下的性能保证会退化，但具体退化程度和机制尚不清楚。作者利用COVID-19作为自然实验，研究供应链任务中分布偏移对保形预测的影响，特别是特征稳定性和重要性分布如何影响预测的稳健性。

Method: 研究8个供应链任务作为COVID-19自然实验，使用SHAP分析特征重要性分布，计算Jaccard相似度衡量特征稳定性，通过相关性分析（rho = 0.714）验证单特征依赖性与覆盖率下降的关系，并进行季度重训练实验。

Result: 覆盖率下降程度差异巨大（0%到86.7%），灾难性失败与单特征依赖性高度相关（rho = 0.714, p = 0.047）。灾难性任务的特征重要性集中在单一特征（增加4.5倍），而稳健任务则分散在多个特征（10-20倍）。季度重训练将脆弱任务的覆盖率从22%提升到41%（+19pp, p = 0.04），但对稳健任务无益（99.8%覆盖率）。

Conclusion: 特征稳定性而非重要性集中度决定预测稳健性，但重要性集中效应在严重分布偏移下特别显著。提出了决策框架：部署前监控SHAP集中度；如果脆弱（>40%集中度）则季度重训练；如果稳健则跳过重训练。

Abstract: Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.

</details>


### [87] [Latent-Constrained Conditional VAEs for Augmenting Large-Scale Climate Ensembles](https://arxiv.org/abs/2601.00915)
*Jacquelyn Shelton,Przemyslaw Polewski,Alexander Robel,Matthew Hoffman,Stephen Price*

Main category: cs.LG

TL;DR: 提出LC-CVAE方法，通过强制潜在空间在共享"锚点"位置的一致性，解决传统CVAE在气候模型生成中泛化能力差的问题，实现从有限样本生成统计一致的气候变量场。


<details>
  <summary>Details</summary>
Motivation: 大规模气候模型集合计算成本高，但许多下游分析需要更多统计一致的气候变量实现。传统条件变分自编码器在跨集合训练时产生碎片化的潜在空间，无法泛化到未见过的集合成员。

Method: 提出潜在约束CVAE（LC-CVAE），强制潜在嵌入在共享地理"锚点"位置实现跨集合同质性。然后使用多输出高斯过程回归在潜在空间预测新实现中未采样位置的潜在坐标，最后解码生成完整时间序列场。

Result: 实验表明：1）在单个实现上训练不稳定；2）纳入约5个实现后收益递减；3）空间覆盖与重建质量之间存在权衡，这与潜在空间中的平均邻居距离密切相关。

Conclusion: LC-CVAE方法能够从有限的气候模型运行中生成统计一致的新实现，解决了传统生成模型在跨集合学习中的泛化问题，为气候变量生成提供了有效解决方案。

Abstract: Large climate-model ensembles are computationally expensive; yet many downstream analyses would benefit from additional, statistically consistent realizations of spatiotemporal climate variables. We study a generative modeling approach for producing new realizations from a limited set of available runs by transferring structure learned across an ensemble. Using monthly near-surface temperature time series from ten independent reanalysis realizations (ERA5), we find that a vanilla conditional variational autoencoder (CVAE) trained jointly across realizations yields a fragmented latent space that fails to generalize to unseen ensemble members. To address this, we introduce a latent-constrained CVAE (LC-CVAE) that enforces cross-realization homogeneity of latent embeddings at a small set of shared geographic 'anchor' locations. We then use multi-output Gaussian process regression in the latent space to predict latent coordinates at unsampled locations in a new realization, followed by decoding to generate full time series fields. Experiments and ablations demonstrate (i) instability when training on a single realization, (ii) diminishing returns after incorporating roughly five realizations, and (iii) a trade-off between spatial coverage and reconstruction quality that is closely linked to the average neighbor distance in latent space.

</details>


### [88] [Attention Needs to Focus: A Unified Perspective on Attention Allocation](https://arxiv.org/abs/2601.00919)
*Zichuan Fu,Wentao Song,Guojing Li,Yejing Wang,Xian Wu,Yimin Deng,Hanyu Yan,Yefeng Zheng,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 本文提出Lazy Attention机制，通过位置区分和弹性Softmax解决Transformer中注意力过载和欠载问题，实现更聚焦的注意力分布，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: Transformer架构中的标准注意力机制存在两个已知问题：表征崩溃和注意力沉没。现有研究往往孤立地处理这些问题，未能揭示其深层联系。本文认为这两个问题都源于共同的根源——不恰当的注意力分配。

Method: 提出Lazy Attention机制：1) 针对注意力过载问题，采用跨头和跨维度的位置区分来增强token区分度；2) 针对注意力欠载问题，引入Elastic-Softmax归一化函数，放松标准softmax约束以抑制对无关token的关注。

Result: 在FineWeb-Edu语料库上的实验表明，Lazy Attention成功缓解了注意力沉没问题，在九个多样化基准测试中与标准注意力和现代架构相比具有竞争力，同时实现了高达59.58%的注意力稀疏度。

Conclusion: Lazy Attention通过统一视角解决注意力过载和欠载问题，提供了一种更聚焦的注意力分配机制，有效缓解了Transformer中的表征崩溃和注意力沉没问题。

Abstract: The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.

</details>


### [89] [MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs](https://arxiv.org/abs/2601.00920)
*Xingsheng Chen,Regina Zhang,Bo Gao,Xingwei He,Xiaofeng Liu,Pietro Lio,Kwok-Yan Lam,Siu-Ming Yiu*

Main category: cs.LG

TL;DR: MODE：一个结合低秩神经ODE与增强Mamba架构的统一时间序列预测框架，通过低秩近似和动态选择性扫描机制，在保持表达力的同时显著提升计算效率和长程依赖建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在处理长程依赖和不规则采样数据时，难以平衡效率、可扩展性和准确性。特别是在金融、医疗、能源系统等领域，需要一种既能高效处理长序列又能保持预测精度的统一框架。

Method: 提出MODE框架：1）线性标记化层处理输入序列；2）多个Mamba编码器块，每个包含增强Mamba层（因果卷积、SiLU激活、低秩神经ODE增强）；3）低秩神经ODE减少计算开销；4）分段选择性扫描机制（受伪ODE动态启发）自适应关注重要子序列。

Result: 在基准数据集上的广泛实验表明，MODE在预测准确性和计算效率方面均超越现有基线方法。低秩近似和动态选择性扫描机制显著提升了框架的效率和可扩展性。

Conclusion: MODE为长期时间序列建模提供了一个统一高效架构，通过将Mamba的选择性扫描与低秩神经ODE相结合，增强了时间表示能力，并在效率和可扩展性方面取得了实质性改进。

Abstract: Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.

</details>


### [90] [Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease](https://arxiv.org/abs/2601.00921)
*Azadeh Alavi,Hamidreza Khalili,Stanley H. Chan,Fatemeh Kouchmeshki,Ross Vlahos*

Main category: cs.LG

TL;DR: 该研究使用量子核方法和几何感知描述符在小样本临床前数据中预测COPD相关的骨骼肌功能障碍，相比经典方法取得了更好的预测性能。


<details>
  <summary>Details</summary>
Motivation: 慢性阻塞性肺疾病（COPD）的骨骼肌功能障碍是重要的肺外表现，与全身和气道炎症密切相关。研究旨在通过微创生物标志物纵向预测肌肉结局，特别是在小样本临床前数据中。

Method: 使用213只动物的临床前数据集，比较了经典基线模型、几何感知对称正定（SPD）描述符与Stein散度、以及为低维表格数据设计的量子核模型。在肌肉重量预测中，使用四个可解释输入（血液C反应蛋白、中性粒细胞计数、支气管肺泡灌洗细胞性和条件）的量子核岭回归。

Result: 量子核岭回归在肌肉重量预测中达到测试均方根误差4.41 mg和决定系数0.605，优于相同特征集的经典岭回归基线（4.70 mg和0.553）。几何感知Stein散度原型距离在仅使用生物标志物时也有持续改善（4.55 mg vs 4.79 mg）。筛查式评估在检测低肌肉重量时ROC-AUC最高达0.90。

Conclusion: 几何和量子核提升方法在低数据、低特征的生物医学预测问题中能提供可测量的优势，同时保持可解释性和透明的模型选择。

Abstract: Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.

</details>


### [91] [Complexity-based code embeddings](https://arxiv.org/abs/2601.00924)
*Rares Folea,Radu Iacob,Emil Slusanschi,Traian Rebedea*

Main category: cs.LG

TL;DR: 提出一种将算法源代码转换为数值嵌入的通用方法，通过动态分析程序在不同输入下的行为，为分析指标定制多个通用复杂度函数，基于r-Complexity构建算法嵌入，并在Codeforces真实代码片段数据集上实现XGBoost算法，在11类多标签分类中取得良好F1分数。


<details>
  <summary>Details</summary>
Motivation: 需要一种通用的方法来将各种算法的源代码转换为数值嵌入表示，以便进行机器学习分析。当前缺乏能够动态分析程序行为并生成有意义的代码嵌入的方法。

Method: 通过动态分析计算机程序在不同输入下的行为，为分析指标定制多个通用复杂度函数，基于r-Complexity构建算法嵌入。使用这些代码嵌入实现XGBoost算法进行多标签分类。

Result: 在基于Codeforces平台真实代码片段构建的11类多标签数据集上，实现了平均F1分数（具体分数未在摘要中给出，但表明取得了良好性能）。

Conclusion: 提出了一种有效的通用代码嵌入方法，能够将算法源代码转换为有意义的数值表示，并在真实世界的编程竞赛代码数据集上验证了其有效性。

Abstract: This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.

</details>


### [92] [Reliability Under Randomness: An Empirical Analysis of Sparse and Dense Language Models Across Decoding Temperatures](https://arxiv.org/abs/2601.00942)
*Kabir Grover*

Main category: cs.LG

TL;DR: 稀疏MoE架构在随机解码下的可靠性研究：指令微调而非架构稀疏性是决定模型在确定性任务中鲁棒性的主要因素


<details>
  <summary>Details</summary>
Motivation: 随着稀疏MoE架构在大语言模型中的普及，需要研究其在随机解码下的可靠性。虽然条件计算提高了计算效率，但稀疏路由与基于温度的采样之间的相互作用是否会损害输出稳定性尚不清楚。

Method: 评估三个代表性模型：OLMoE-7B（稀疏基础模型）、Mixtral-8x7B（稀疏指令微调模型）和Qwen2.5-3B（密集指令微调模型）。在具有客观可验证答案的确定性算术推理任务上进行测试，涵盖四种解码配置（从贪婪解码到T=1.0），评估准确性、格式合规性、重复生成输出一致性和置信度指标，总计9,360次模型生成。

Result: 稀疏指令微调模型在所有解码温度下表现出与密集指令微调模型相当的稳定性，而稀疏基础模型随着温度升高显示出系统性退化。这表明指令微调而非架构稀疏性是确定性任务中对解码随机性鲁棒性的主要决定因素。

Conclusion: 指令微调是确保稀疏语言模型在可靠性关键应用中稳定性的关键因素，在某些场景下稀疏架构可以在不牺牲输出稳定性的情况下安全采用。

Abstract: The increasing prevalence of sparse Mixture-of-Experts (MoE) architectures in large language models raises important questions regarding their reliability under stochastic decoding. While conditional computation enables substantial gains in computational efficiency, it remains unclear whether the interaction between sparse routing and temperature-based sampling compromises output stability relative to dense architectures. This work investigates whether conditional computation in MoE models amplifies decoding-induced randomness, leading to reduced reliability as temperature increases. We evaluate three representative models: OLMoE-7B (sparse base), Mixtral-8x7B (sparse instruction-tuned), and Qwen2.5-3B (dense instruction-tuned) on deterministic arithmetic reasoning tasks with objectively verifiable answers. Experiments span four decoding configurations, ranging from greedy decoding to T=1.0. Our evaluation encompasses accuracy, format compliance, output consistency across repeated generations, and confidence metrics, totaling 9,360 model generations. Results demonstrate that the sparse instruction-tuned model exhibits stability comparable to the dense instruction-tuned model across all decoding temperatures, while the sparse base model shows systematic degradation as temperature increases. These findings indicate that instruction tuning, rather than architectural sparsity, is the primary determinant of robustness to decoding randomness on deterministic tasks. We discuss the implications of these results for deploying sparse language models in reliability-critical applications, highlighting scenarios in which sparse architectures can be safely adopted without sacrificing output stability.

</details>


### [93] [Explainability-Guided Defense: Attribution-Aware Model Refinement Against Adversarial Data Attacks](https://arxiv.org/abs/2601.00968)
*Longwei Wang,Mohammad Navid Nayyem,Abdullah Al Rakin,KC Santosh,Chaowei Zhang,Yang Zhou*

Main category: cs.LG

TL;DR: 论文提出了一种基于LIME解释性分析的对抗鲁棒性训练框架，通过抑制虚假特征来提升模型对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在医疗和自动驾驶等安全关键领域，深度学习模型需要同时具备对抗鲁棒性和决策透明度。研究发现，通过LIME识别出的虚假、不稳定或语义无关特征会显著增加模型的对抗脆弱性。

Method: 提出了一种基于属性引导的细化框架，将LIME从被动诊断工具转变为主动训练信号。方法包括特征掩码、敏感度感知正则化和对抗增强，形成闭环细化流程，无需额外数据集或模型架构。

Result: 在CIFAR-10、CIFAR-10-C和CIFAR-100数据集上的实验表明，该方法显著提升了对抗鲁棒性和分布外泛化能力。

Conclusion: 通过将解释性与鲁棒性训练相结合，该方法为构建既透明又鲁棒的深度学习模型提供了有效途径，在理论上建立了解释对齐与鲁棒性之间的形式化联系。

Abstract: The growing reliance on deep learning models in safety-critical domains such as healthcare and autonomous navigation underscores the need for defenses that are both robust to adversarial perturbations and transparent in their decision-making. In this paper, we identify a connection between interpretability and robustness that can be directly leveraged during training. Specifically, we observe that spurious, unstable, or semantically irrelevant features identified through Local Interpretable Model-Agnostic Explanations (LIME) contribute disproportionately to adversarial vulnerability. Building on this insight, we introduce an attribution-guided refinement framework that transforms LIME from a passive diagnostic into an active training signal. Our method systematically suppresses spurious features using feature masking, sensitivity-aware regularization, and adversarial augmentation in a closed-loop refinement pipeline. This approach does not require additional datasets or model architectures and integrates seamlessly into standard adversarial training. Theoretically, we derive an attribution-aware lower bound on adversarial distortion that formalizes the link between explanation alignment and robustness. Empirical evaluations on CIFAR-10, CIFAR-10-C, and CIFAR-100 demonstrate substantial improvements in adversarial robustness and out-of-distribution generalization.

</details>


### [94] [Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations](https://arxiv.org/abs/2601.01003)
*Amin Abyaneh,Charlotte Morissette,Mohamad H. Danesh,Anas El Houssaini,David Meger,Gregory Dudek,Hsiu-Chin Lin*

Main category: cs.LG

TL;DR: 论文提出收缩扩散策略（CDPs），通过诱导扩散采样过程的收缩行为来增强离线策略学习的鲁棒性，减少求解器和分数匹配误差的影响，在数据稀缺时表现更佳。


<details>
  <summary>Details</summary>
Motivation: 扩散策略虽然强大，但其基于分数的SDE建模会引入求解器和分数匹配误差、需要大量数据，并导致动作生成不一致。这些在图像生成中不太关键的问题在连续控制环境中会累积并导致失败。

Method: 引入收缩扩散策略（CDPs），在扩散采样动力学中诱导收缩行为。收缩将附近的流拉近，增强对求解器和分数匹配误差的鲁棒性，同时减少不必要的动作方差。提供了理论分析和实际实现方案，可最小化修改和计算成本地集成到现有扩散策略架构中。

Result: 在模拟和真实世界环境中进行了广泛实验评估。在多个基准测试中，CDPs通常优于基线策略，在数据稀缺情况下表现出更明显的优势。

Conclusion: 收缩扩散策略通过诱导扩散采样过程的收缩行为，有效解决了传统扩散策略在连续控制中的误差累积问题，提高了鲁棒性和性能，特别是在数据有限的情况下。

Abstract: Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce Contractive Diffusion Policies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real-world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.

</details>


### [95] [Expanding the Chaos: Neural Operator for Stochastic (Partial) Differential Equations](https://arxiv.org/abs/2601.01021)
*Dai Shi,Lequan Lin,Andi Han,Luke Thompson,José Miguel Hernández-Lobato,Zhiyong Wang,Junbin Gao*

Main category: cs.LG

TL;DR: 基于Wiener混沌展开的神经算子架构，用于学习SDE和SPDE的解算子，通过正交Hermite特征投影噪声路径，用神经算子参数化确定性混沌系数，实现单次前向传播从噪声重构完整解轨迹。


<details>
  <summary>Details</summary>
Motivation: SDE和SPDE是建模随机动力学的基本工具，开发深度学习模型逼近其解算子不仅能提供快速实用的求解器，还能为传统学习任务提供新视角。现有方法需要改进以更高效地学习随机微分方程的解算子。

Method: 基于经典Wiener混沌展开，将驱动噪声路径投影到正交Wick Hermite特征上，用神经算子参数化得到的确定性混沌系数，实现从噪声到完整解轨迹的单次前向传播重构。理论方面推导了多维SDE和半线性SPDE的混沌系数耦合ODE/PDE系统。

Result: 在多种问题上验证模型：经典SPDE基准测试、图像扩散一步采样、图拓扑插值、金融外推、参数估计、洪水预测的流形SDE，展示了竞争性精度和广泛适用性。

Conclusion: 基于Wiener混沌展开的神经算子为学习SDE/SPDE解算子提供了实用且可扩展的方法，在多个领域表现出色，表明该方法具有广泛的适用潜力。

Abstract: Stochastic differential equations (SDEs) and stochastic partial differential equations (SPDEs) are fundamental tools for modeling stochastic dynamics across the natural sciences and modern machine learning. Developing deep learning models for approximating their solution operators promises not only fast, practical solvers, but may also inspire models that resolve classical learning tasks from a new perspective. In this work, we build on classical Wiener chaos expansions (WCE) to design neural operator (NO) architectures for SPDEs and SDEs: we project the driving noise paths onto orthonormal Wick Hermite features and parameterize the resulting deterministic chaos coefficients with neural operators, so that full solution trajectories can be reconstructed from noise in a single forward pass. On the theoretical side, we investigate the classical WCE results for the class of multi-dimensional SDEs and semilinear SPDEs considered here by explicitly writing down the associated coupled ODE/PDE systems for their chaos coefficients, which makes the separation between stochastic forcing and deterministic dynamics fully explicit and directly motivates our model designs. On the empirical side, we validate our models on a diverse suite of problems: classical SPDE benchmarks, diffusion one-step sampling on images, topological interpolation on graphs, financial extrapolation, parameter estimation, and manifold SDEs for flood prediction, demonstrating competitive accuracy and broad applicability. Overall, our results indicate that WCE-based neural operators provide a practical and scalable way to learn SDE/SPDE solution operators across diverse domains.

</details>


### [96] [Wireless Dataset Similarity: Measuring Distances in Supervised and Unsupervised Machine Learning](https://arxiv.org/abs/2601.01023)
*João Morais,Sadjad Alikhani,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: cs.LG

TL;DR: 本文提出了一个任务和模型感知的无线数据集相似性测量框架，用于预测跨数据集的可迁移性，支持数据集选择/增强、仿真到真实比较等应用。


<details>
  <summary>Details</summary>
Motivation: 无线通信领域缺乏系统的方法来量化不同数据集之间的相似性，这限制了数据集选择、仿真到真实迁移、任务特定合成数据生成等应用。需要一种能够预测模型在不同数据集间可迁移性的框架。

Method: 提出了一个任务和模型感知的框架，通过候选数据集距离度量来预测跨数据集可迁移性。在无监督任务（CSI压缩）中使用基于UMAP嵌入结合Wasserstein和欧几里得距离的度量；在有监督任务（波束预测）中通过集成有监督UMAP和数据集不平衡惩罚来推导标签感知距离。

Result: 在CSI压缩任务中，使用UMAP嵌入结合Wasserstein和欧几里得距离的度量实现了超过0.85的皮尔逊相关系数。在有监督波束预测任务中，标签感知距离也表现出色。两种任务中提出的距离度量都优于传统基线方法，与模型可迁移性展现出更强的相关性。

Conclusion: 该框架能够有效测量无线数据集之间的相似性，支持任务相关的数据集比较，为数据集选择、仿真到真实迁移、模型训练/适应决策等应用提供了实用工具。

Abstract: This paper introduces a task- and model-aware framework for measuring similarity between wireless datasets, enabling applications such as dataset selection/augmentation, simulation-to-real (sim2real) comparison, task-specific synthetic data generation, and informing decisions on model training/adaptation to new deployments. We evaluate candidate dataset distance metrics by how well they predict cross-dataset transferability: if two datasets have a small distance, a model trained on one should perform well on the other. We apply the framework on an unsupervised task, channel state information (CSI) compression, using autoencoders. Using metrics based on UMAP embeddings, combined with Wasserstein and Euclidean distances, we achieve Pearson correlations exceeding 0.85 between dataset distances and train-on-one/test-on-another task performance. We also apply the framework to a supervised beam prediction in the downlink using convolutional neural networks. For this task, we derive a label-aware distance by integrating supervised UMAP and penalties for dataset imbalance. Across both tasks, the resulting distances outperform traditional baselines and consistently exhibit stronger correlations with model transferability, supporting task-relevant comparisons between wireless datasets.

</details>


### [97] [Coarse-Grained Kullback--Leibler Control of Diffusion-Based Generative AI](https://arxiv.org/abs/2601.01045)
*Tatsuaki Tsuruyama*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息论Lyapunov函数的反向扩散方案，通过V-delta投影控制图像粗粒度特征（如块状强度）的演化，在保持像素级精度和视觉质量的同时，实现对粗粒度量的显式控制。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和基于分数的生成模型虽然能合成高质量图像，但缺乏描述粗粒度量（如图像分块后的块强度或类别比例）在反向扩散过程中如何演化的理论框架。作者希望建立一种理论来描述和控制这些粗粒度特征在生成过程中的变化。

Method: 作者将先前提出的信息论Lyapunov函数V框架移植到生成模型的反向扩散过程中，提出了V-delta投影反向扩散方案。该方法将反向扩散过程投影到V-delta势能上，其中V-delta是带有容忍度的泄漏容忍势能。作者证明了V对时间非齐次块保持马尔可夫核的单调性，并在小泄漏和V-delta投影条件下，V-delta可作为近似Lyapunov函数。

Result: 通过块常数图像和简化反向核的玩具模型进行数值实验，结果表明：提出的方法能将块质量误差和泄漏容忍势能保持在预设容忍度内，同时达到与非投影动力学相当的像素级精度和视觉质量。

Conclusion: 本研究将生成采样重新解释为从噪声到数据的信息势能下降过程，为具有显式粗粒度量控制的反向扩散过程提供了设计原则。该方法在保持生成质量的同时，实现了对图像粗粒度特征的有效控制。

Abstract: Diffusion models and score-based generative models provide a powerful framework for synthesizing high-quality images from noise. However, there is still no satisfactory theory that describes how coarse-grained quantities, such as blockwise intensity or class proportions after partitioning an image into spatial blocks, are preserved and evolve along the reverse diffusion dynamics. In previous work, the author introduced an information-theoretic Lyapunov function V for non-ergodic Markov processes on a state space partitioned into blocks, defined as the minimal Kullback-Leibler divergence to the set of stationary distributions reachable from a given initial condition, and showed that a leak-tolerant potential V-delta with a prescribed tolerance for block masses admits a closed-form expression as a scaling-and-clipping operation on block masses.
  In this paper, I transplant this framework to the reverse diffusion process in generative models and propose a reverse diffusion scheme that is projected by the potential V-delta (referred to as the V-delta projected reverse diffusion). I extend the monotonicity of V to time-inhomogeneous block-preserving Markov kernels and show that, under small leakage and the V-delta projection, V-delta acts as an approximate Lyapunov function. Furthermore, using a toy model consisting of block-constant images and a simplified reverse kernel, I numerically demonstrate that the proposed method keeps the block-mass error and the leak-tolerant potential within the prescribed tolerance, while achieving pixel-wise accuracy and visual quality comparable to the non-projected dynamics. This study reinterprets generative sampling as a decrease of an information potential from noise to data, and provides a design principle for reverse diffusion processes with explicit control of coarse-grained quantities.

</details>


### [98] [A UCB Bandit Algorithm for General ML-Based Estimators](https://arxiv.org/abs/2601.01061)
*Yajing Liu,Erkao Bao,Linqi Song*

Main category: cs.LG

TL;DR: ML-UCB：一种将任意机器学习模型集成到多臂老虎机框架中的广义上置信界算法，通过直接建模底层估计器的学习曲线行为来克服传统方法缺乏可处理浓度不等式的问题。


<details>
  <summary>Details</summary>
Motivation: 在序列决策中部署复杂ML模型面临的主要挑战是缺乏用于原则性探索的可处理浓度不等式。传统方法需要针对特定模型进行理论分析，限制了ML模型在多臂老虎机框架中的应用。

Method: 假设均方误差随训练样本数量呈幂律下降，推导出广义浓度不等式，并基于此开发ML-UCB算法。该框架允许集成任何学习曲线可经验表征的ML模型，无需模型特定的理论分析。

Result: 证明了ML-UCB能够实现次线性遗憾，并通过在线矩阵分解协同过滤推荐系统的实验验证了该方法，在模拟简化双塔模型的合成数据上相比LinUCB有显著改进。

Conclusion: ML-UCB为将任意ML模型集成到多臂老虎机框架提供了原则性方法，通过建模学习曲线行为克服了传统浓度不等式的限制，实现了更灵活的序列决策系统设计。

Abstract: We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB

</details>


### [99] [SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models](https://arxiv.org/abs/2601.01062)
*Yunlin Zeng*

Main category: cs.LG

TL;DR: 该研究提出了一种端到端的视觉播客生成管道，通过微调Qwen3-VL-32B模型，使用合成到真实的训练策略，在4000个图像-对话对数据集上进行训练，显著提升了长形式多说话者播客对话的生成质量。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在描述性任务（如图像描述和视觉问答）上取得了显著成功，但在生成引人入胜的长形式叙事（特别是多说话者播客对话）方面仍然研究不足且难以评估。标准评估指标如BLEU和ROUGE无法捕捉对话自然性、个性和叙事流程的细微差别，往往奖励安全、重复的输出而非引人入胜的叙事。

Method: 提出端到端视觉播客生成管道，微调Qwen3-VL-32B模型，使用合成到真实的训练策略：在结构化播客研究语料库（SPoRC）的高质量播客对话与合成生成图像配对的4000个图像-对话对数据集上进行训练，并在视觉叙事数据集（VIST）的真实世界照片序列上进行评估。

Result: 微调的32B模型在对话自然性方面显著优于235B基础模型（胜率>80%），叙事深度增加50%（平均轮次长度），同时保持相同的视觉基础能力（CLIPScore: 20.39）。

Conclusion: 该研究展示了通过精心设计的训练策略和全面的评估框架，相对较小的模型（32B）可以在长形式叙事生成任务上超越更大的基础模型（235B），为视觉叙事生成提供了有效的解决方案。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\% win rate) and narrative depth (+50\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).

</details>


### [100] [Tiny Machine Learning for Real-Time Aquaculture Monitoring: A Case Study in Morocco](https://arxiv.org/abs/2601.01065)
*Achraf Hsain,Yahya Zaki,Othman Abaakil,Hibat-allah Bekkar,Yousra Chtouki*

Main category: cs.LG

TL;DR: 本文提出将基于TinyML的低功耗边缘设备集成到水产养殖系统中，实现水质参数的实时自动化监测与控制，减少人工依赖并提高养殖效率。


<details>
  <summary>Details</summary>
Motivation: 水产养殖业面临水质波动、疾病爆发和饲料管理效率低等挑战，传统监测方法依赖人工且耗时，可能导致问题处理延迟。需要更智能、实时的监测解决方案。

Method: 采用TinyML（微型机器学习）技术结合低功耗边缘设备，设计实时自动化监测控制系统，包括传感器选择、算法设计、硬件约束考虑和伦理考量。

Result: 系统能够实时监测pH值、温度、溶解氧、氨氮等关键参数，实现水质控制、异常警报、数据收集和决策支持，优化水处理、饲料分配和养殖管理。

Conclusion: TinyML技术在水产养殖监测中具有可行性，能够促进更可持续、高效的养殖实践，通过自动化监测减少人工需求，提高资源利用效率和养殖管理优化。

Abstract: Aquaculture, the farming of aquatic organisms, is a rapidly growing industry facing challenges such as water quality fluctuations, disease outbreaks, and inefficient feed management. Traditional monitoring methods often rely on manual labor and are time consuming, leading to potential delays in addressing issues. This paper proposes the integration of low-power edge devices using Tiny Machine Learning (TinyML) into aquaculture systems to enable real-time automated monitoring and control, such as collecting data and triggering alarms, and reducing labor requirements. The system provides real-time data on the required parameters such as pH levels, temperature, dissolved oxygen, and ammonia levels to control water quality, nutrient levels, and environmental conditions enabling better maintenance, efficient resource utilization, and optimal management of the enclosed aquaculture space. The system enables alerts in case of anomaly detection. The data collected by the sensors over time can serve for important decision-making regarding optimizing water treatment processes, feed distribution, feed pattern analysis and improve feed efficiency, reducing operational costs. This research explores the feasibility of developing TinyML-based solutions for aquaculture monitoring, considering factors such as sensor selection, algorithm design, hardware constraints, and ethical considerations. By demonstrating the potential benefits of TinyML in aquaculture, our aim is to contribute to the development of more sustainable and efficient farming practices.

</details>


### [101] [Revisiting Weighted Strategy for Non-stationary Parametric Bandits and MDPs](https://arxiv.org/abs/2601.01069)
*Jing Wang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 该论文重新审视非平稳参数化赌博机中的加权策略，提出了一个精炼的分析框架，简化了算法设计并改进了遗憾界，同时将框架扩展到具有函数逼近的非平稳马尔可夫决策过程。


<details>
  <summary>Details</summary>
Motivation: 非平稳参数化赌博机中，加权策略因其适应渐变漂移模式而在实际应用中常用，但先前理论分析复杂且算法计算效率低或统计次优。作者旨在解决加权策略分析复杂、算法设计繁琐的问题。

Method: 提出了一个精炼的分析框架，重新分析加权策略。在线性赌博机中，该框架简化了推导过程，产生更简单的基于权重的算法。框架还扩展到广义线性赌博机、自协调赌博机，以及具有函数逼近的非平稳马尔可夫决策过程（线性混合MDP和多项Logit混合MDP）。

Result: 在线性赌博机中，新算法与窗口/重启算法同样高效，同时保持相同遗憾界。在广义线性赌博机中，获得了改进的遗憾界 $\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$，优于先前工作的 $\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$。框架成功扩展到非平稳MDPs，为线性混合MDP和多项Logit混合MDP建立了动态遗憾保证。

Conclusion: 精炼的分析框架解决了加权策略在非平稳参数化赌博机中的分析复杂性问题，简化了算法设计，改进了遗憾界，并成功扩展到更广泛的参数化赌博机和具有函数逼近的非平稳马尔可夫决策过程。

Abstract: Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a \emph{refined analysis framework}, which simplifies the derivation and, importantly, produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$ regret, improving the $\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$ bound in prior work, where $k_μ$ and $c_μ$ characterize the reward model's nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon. Moreover, we extend our framework to non-stationary Markov Decision Processes (MDPs) with function approximation, focusing on Linear Mixture MDP and Multinomial Logit (MNL) Mixture MDP. For both classes, we propose algorithms based on the weighted strategy and establish dynamic regret guarantees using our analysis framework.

</details>


### [102] [Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces](https://arxiv.org/abs/2601.01082)
*Bryon Tjanaka,Henry Chen,Matthew C. Fontaine,Stefanos Nikolaidis*

Main category: cs.LG

TL;DR: DMS（折扣模型搜索）是一种新的质量多样性优化算法，通过使用连续折扣模型解决高维度量空间中的探索停滞问题，优于现有方法如CMA-MAE。


<details>
  <summary>Details</summary>
Motivation: 现有质量多样性（QD）算法在处理高维度量空间时存在局限性，因为高维度量容易导致失真——许多解映射到相似的度量值。例如CMA-MAE使用直方图记录折扣值，但在高维空间中相似度量的解会落入同一直方图单元格，导致探索停滞。

Method: 提出折扣模型搜索（DMS），使用一个提供平滑、连续折扣值表示的模型来指导探索。该模型能够区分具有相似度量的解，从而在高维度量空间中实现持续探索。

Result: DMS在高维基准测试和两个新应用领域（度量空间为高维图像空间）中表现优于CMA-MAE和其他黑盒QD算法。用户可以通过提供图像数据集而非手动设计度量函数来指定所需度量。

Conclusion: DMS通过连续折扣模型有效解决了高维度量空间中的探索问题，扩展了QD算法的应用范围，特别是在图像空间等复杂度量领域。

Abstract: Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.

</details>


### [103] [Central Dogma Transformer: Towards Mechanism-Oriented AI for Cellular Understanding](https://arxiv.org/abs/2601.01089)
*Nobuyuki Ota*

Main category: cs.LG

TL;DR: CDT是一个整合DNA、RNA和蛋白质三种模态的Transformer架构，遵循中心法则的信息流向，通过定向交叉注意力机制实现多模态整合，在CRISPRi增强子扰动数据上验证了预测准确性和机制可解释性。


<details>
  <summary>Details</summary>
Motivation: 虽然DNA、RNA和蛋白质各自的领域特定基础模型已取得成功，但它们仍然相互隔离，限制了我们对整合细胞过程建模的能力。需要一种能够遵循中心法则信息流向、整合三种分子系统的架构。

Method: 提出中心法则Transformer（CDT）架构，整合预训练的DNA、RNA和蛋白质语言模型，采用定向交叉注意力机制：DNA-to-RNA注意力建模转录调控，RNA-to-Protein注意力建模翻译关系，产生统一的三模态虚拟细胞嵌入。

Result: 在K562细胞的CRISPRi增强子扰动数据上，CDT v1（使用固定RNA和蛋白质嵌入的概念验证实现）达到Pearson相关系数0.503，达到跨实验变异性理论上限（r=0.797）的63%。注意力和梯度分析提供了互补的解释窗口。

Conclusion: 与生物信息流向对齐的AI架构能够同时实现预测准确性和机制可解释性，为理解整合的细胞过程提供了新的建模框架。

Abstract: Understanding cellular mechanisms requires integrating information across DNA, RNA, and protein - the three molecular systems linked by the Central Dogma of molecular biology. While domain-specific foundation models have achieved success for each modality individually, they remain isolated, limiting our ability to model integrated cellular processes. Here we present the Central Dogma Transformer (CDT), an architecture that integrates pre-trained language models for DNA, RNA, and protein following the directional logic of the Central Dogma. CDT employs directional cross-attention mechanisms - DNA-to-RNA attention models transcriptional regulation, while RNA-to-Protein attention models translational relationships - producing a unified Virtual Cell Embedding that integrates all three modalities. We validate CDT v1 - a proof-of-concept implementation using fixed (non-cell-specific) RNA and protein embeddings - on CRISPRi enhancer perturbation data from K562 cells, achieving a Pearson correlation of 0.503, representing 63% of the theoretical ceiling set by cross-experiment variability (r = 0.797). Attention and gradient analyses provide complementary interpretive windows: in detailed case studies, these approaches highlight largely distinct genomic regions, with gradient analysis identifying a CTCF binding site that Hi-C data showed as physically contacting both enhancer and target gene. These results suggest that AI architectures aligned with biological information flow can achieve both predictive accuracy and mechanistic interpretability.

</details>


### [104] [Community-Based Early-Stage Chronic Kidney Disease Screening using Explainable Machine Learning for Low-Resource Settings](https://arxiv.org/abs/2601.01119)
*Muhammad Ashad Kabir,Sirajam Munira,Dewan Tasnia Azad,Saleh Mohammed Ikram,Mohammad Habibur Rahman Sarker,Syed Manzoor Ahmed Hanifi*

Main category: cs.LG

TL;DR: 开发了一个针对孟加拉国和南亚人群的可解释机器学习框架，用于社区早期慢性肾病筛查，在资源有限环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有慢性肾病筛查工具主要基于高收入国家人群开发，在孟加拉国和南亚地区表现不佳，因为这些地区的风险特征不同。这些工具通常使用简单的加性评分函数，基于晚期肾病患者的数椐，无法捕捉风险因素间的复杂相互作用，也难以预测早期肾病。

Method: 使用孟加拉国社区数据集（南亚首个此类数据集），评估了12种机器学习分类器，应用10种互补的特征选择技术识别稳健、可泛化的预测因子。最终模型通过10折交叉验证评估，并在印度、阿联酋和孟加拉国的三个独立数据集上进行外部验证。使用SHAP提供模型可解释性。

Result: 基于RFECV选择特征子集的机器学习模型达到90.40%的平衡准确率，而仅使用最少非病理检测特征也表现出色（89.23%平衡准确率），通常优于更大或完整特征集。相比现有筛查工具，提出的模型在准确率和敏感性方面显著更高，同时需要更少且更易获取的输入。外部验证显示78%至98%的敏感性，证实了强泛化能力。

Conclusion: 该研究开发了一个针对资源有限环境的可解释机器学习框架，用于社区早期慢性肾病筛查，特别适合孟加拉国和南亚人群。模型在准确率、敏感性和可解释性方面优于现有工具，并展示了良好的泛化能力，为改善该地区慢性肾病早期检测提供了有效解决方案。

Abstract: Early detection of chronic kidney disease (CKD) is essential for preventing progression to end-stage renal disease. However, existing screening tools - primarily developed using populations from high-income countries - often underperform in Bangladesh and South Asia, where risk profiles differ. Most of these tools rely on simple additive scoring functions and are based on data from patients with advanced-stage CKD. Consequently, they fail to capture complex interactions among risk factors and are limited in predicting early-stage CKD. Our objective was to develop and evaluate an explainable machine learning (ML) framework for community-based early-stage CKD screening for low-resource settings, tailored to the Bangladeshi and South Asian population context. We used a community-based dataset from Bangladesh, the first such CKD dataset in South and South Asia, and evaluated twelve ML classifiers across multiple feature domains. Ten complementary feature selection techniques were applied to identify robust, generalizable predictors. The final models were assessed using 10-fold cross-validation. External validation was conducted on three independent datasets from India, the UAE, and Bangladesh. SHAP (SHapley Additive exPlanations) was used to provide model explainability. An ML model trained on an RFECV-selected feature subset achieved a balanced accuracy of 90.40%, whereas minimal non-pathology-test features demonstrated excellent predictive capability with a balanced accuracy of 89.23%, often outperforming larger or full feature sets. Compared with existing screening tools, the proposed models achieved substantially higher accuracy and sensitivity while requiring fewer and more accessible inputs. External validation confirmed strong generalizability with 78% to 98% sensitivity. SHAP interpretation identified clinically meaningful predictors consistent with established CKD risk factors.

</details>


### [105] [Wittgenstein's Family Resemblance Clustering Algorithm](https://arxiv.org/abs/2601.01127)
*Golbahar Amanpour,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 该论文提出了一种基于维特根斯坦家族相似性概念的聚类算法WFR，无需预先指定聚类数量或假设聚类形状，通过构建相似性图实现非线性聚类。


<details>
  <summary>Details</summary>
Motivation: 受维特根斯坦家族相似性哲学概念的启发，该概念认为类别成员通过重叠的相似性而非单一定义属性连接，这种思想自然适用于机器学习中的图方法，旨在开发一种无需预设聚类数量和形状假设的聚类算法。

Method: 提出WFR聚类算法及其核变体kernel WFR：计算相邻数据实例之间的相似性得分，通过阈值处理后构建相似性图，该图的连通分量形成最终聚类。

Result: 在基准数据集上的模拟实验表明，WFR是一种有效的非线性聚类算法，不需要预先知道聚类数量或对其形状做出假设。

Conclusion: 成功将维特根斯坦的哲学概念转化为实用的机器学习算法，WFR算法为聚类问题提供了一种新颖且有效的解决方案，特别适用于复杂形状和非线性分布的数据。

Abstract: This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.

</details>


### [106] [Self-Training the Neurochaos Learning Algorithm](https://arxiv.org/abs/2601.01146)
*Anusree M,Akhila Henry,Pramod P Nair*

Main category: cs.LG

TL;DR: 该研究提出了一种结合神经混沌学习与自训练的半监督学习架构，用于解决标注数据稀缺和不平衡数据集问题，在多个基准数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，获取大量标注数据既困难又昂贵，而无标注数据则相对容易获取。传统的监督学习方法在标注数据稀少或数据集不平衡的情况下表现不佳。

Method: 提出了一种混合半监督学习架构，将神经混沌学习与基于阈值的自训练方法相结合。神经混沌学习将输入特征转换为混沌发放率表示，捕捉数据中的非线性关系；自训练则通过高置信度的伪标注样本逐步扩大标注集。

Result: 在10个基准数据集和5种机器学习分类器上进行评估，其中85%的训练数据被视为无标注，仅15%作为标注数据。提出的自训练神经混沌学习架构相比独立的自训练模型获得了显著性能提升，特别是在Iris（188.66%）、Wine（158.58%）和Glass Identification（110.48%）等有限、非线性和不平衡数据集上。

Conclusion: 结果表明，将基于混沌的特征提取与半监督学习结合使用，可以在低数据环境下提高模型的泛化能力、鲁棒性和分类准确性。

Abstract: In numerous practical applications, acquiring substantial quantities of labelled data is challenging and expensive, but unlabelled data is readily accessible. Conventional supervised learning methods frequently underperform in scenarios characterised by little labelled data or imbalanced datasets. This study introduces a hybrid semi-supervised learning (SSL) architecture that integrates Neurochaos Learning (NL) with a threshold-based Self-Training (ST) method to overcome this constraint. The NL architecture converts input characteristics into chaos-based ring-rate representations that encapsulate nonlinear relationships within the data, whereas ST progressively enlarges the labelled set utilising high-confidence pseudo-labelled samples. The model's performance is assessed using ten benchmark datasets and five machine learning classifiers, with 85% of the training data considered unlabelled and just 15% utilised as labelled data. The proposed Self-Training Neurochaos Learning (NL+ST) architecture consistently attains superior performance gain relative to standalone ST models, especially on limited, nonlinear and imbalanced datasets like Iris (188.66%), Wine (158.58%) and Glass Identification (110.48%). The results indicate that using chaos-based feature extraction with SSL improves generalisation, resilience, and classification accuracy in low-data contexts.

</details>


### [107] [Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification](https://arxiv.org/abs/2601.01150)
*Wenbin Pei,Ruohao Dai,Bing Xue,Mengjie Zhang,Qiang Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: Evo-TFS是一种新颖的进化过采样方法，通过结合时域和频域特征来生成不平衡时间序列数据中的少数类样本，显著提升分类器性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法假设数据分布平衡，在不平衡时间序列数据中会忽略具有更高实际意义的少数类。传统过采样方法依赖线性插值，难以保持时间动态特性和生成多样样本。

Method: 提出Evo-TFS方法，使用强类型遗传编程来进化生成多样、高质量的时间序列，其适应度函数同时考虑时域和频域特征。

Result: 在不平衡时间序列数据集上的实验表明，Evo-TFS优于现有过采样方法，显著提升了时域和频域分类器的性能。

Conclusion: Evo-TFS通过整合时域和频域特征的进化过采样方法，有效解决了不平衡时间序列分类问题，为实际应用提供了更好的解决方案。

Abstract: Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.

</details>


### [108] [Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models](https://arxiv.org/abs/2601.01162)
*Zihua Yang,Xin Liao,Yiqun Zhang,Yiu-ming Cheung*

Main category: cs.LG

TL;DR: ARISE利用大语言模型的外部语义知识增强分类数据的表示，通过注意力加权机制将语义嵌入与原始数据结合，提升聚类质量


<details>
  <summary>Details</summary>
Motivation: 分类数据聚类面临的核心挑战是缺乏固有排序或距离的属性值相似性度量。现有方法依赖数据集内的共现模式推断值关系，但在样本有限时不可靠，导致语义上下文未被充分利用，聚类质量下降。

Method: 提出ARISE方法，利用大语言模型的外部语义知识构建语义感知表示。LLM用于描述属性值以增强表示，通过注意力加权机制将LLM增强的嵌入与原始数据结合，探索语义显著的聚类结构。

Result: 在八个基准数据集上的实验表明，相比七个代表性对比方法，ARISE实现了19-27%的性能提升，证明了外部语义知识对分类数据聚类的有效性。

Conclusion: ARISE通过整合大语言模型的外部语义知识，有效弥补了分类数据聚类中的语义鸿沟，显著提升了聚类质量，为有限样本情况下的分类数据聚类提供了可靠解决方案。

Abstract: Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE

</details>


### [109] [MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches](https://arxiv.org/abs/2601.01206)
*Soroush Elyasi,Arya VarastehNezhad,Fattaneh Taghiyareh*

Main category: cs.LG

TL;DR: 本研究提出结合多类型严肃游戏和机器学习的方法，通过游戏行为预测软件开发岗位适配性，准确率达94%，可作为传统人格测试的替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统职业评估中的人格测试（自陈问卷）存在回应偏差、疲劳效应和故意扭曲等问题，需要更客观、可扩展且减少偏见的替代方法。

Method: 1. 通过文献综述和软件工程师实证研究确定相关人格和行为特征；2. 设计定制移动游戏来激发问题解决、规划、适应性等行为；3. 收集细粒度游戏事件数据；4. 采用两阶段建模策略，仅使用游戏行为特征预测岗位适配性。

Result: 模型达到97%的精确度和94%的准确度。合适候选人表现出独特的游戏行为模式：解谜游戏获胜更多、完成更多支线挑战、更频繁导航菜单、暂停/重试/放弃行为更少。

Conclusion: 游戏过程中捕获的隐性行为痕迹能有效预测软件开发适配性，无需显性人格测试，支持严肃游戏作为职业评估的可扩展、有趣且偏见较少的替代方案。

Abstract: Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.

</details>


### [110] [Adaptive Conformal Prediction via Bayesian Uncertainty Weighting for Hierarchical Healthcare Data](https://arxiv.org/abs/2601.01223)
*Marzieh Amiri Shahbazi,Ali Baheri,Nasibeh Azadeh-Fard*

Main category: cs.LG

TL;DR: 提出了一种结合贝叶斯层次随机森林和组感知共形校准的混合框架，用于医疗预测中的不确定性量化，在保证覆盖率的同时实现风险自适应精度。


<details>
  <summary>Details</summary>
Motivation: 临床决策需要同时满足分布无关的覆盖率保证和风险自适应精度，现有方法无法同时满足这两个要求，这是医疗预测中的一个基本限制。

Method: 集成贝叶斯层次随机森林与组感知共形校准，利用后验不确定性对符合性评分进行加权，同时保持严格的覆盖率有效性。

Result: 在61,538例入院病例、3,793家美国医院和4个地区的评估中，该方法达到目标覆盖率（94.3% vs 95%目标），并实现自适应精度：低不确定性病例的区间宽度减少21%，同时对高风险预测适当加宽。校准良好的贝叶斯不确定性单独使用时覆盖率严重不足（14.1%）。

Conclusion: 该混合框架支持风险分层临床协议、高效资源规划和高置信度预测，以及对不确定病例的保守分配和增强监督，为多样化医疗环境提供不确定性感知的决策支持。

Abstract: Clinical decision-making demands uncertainty quantification that provides both distribution-free coverage guarantees and risk-adaptive precision, requirements that existing methods fail to jointly satisfy. We present a hybrid Bayesian-conformal framework that addresses this fundamental limitation in healthcare predictions. Our approach integrates Bayesian hierarchical random forests with group-aware conformal calibration, using posterior uncertainties to weight conformity scores while maintaining rigorous coverage validity. Evaluated on 61,538 admissions across 3,793 U.S. hospitals and 4 regions, our method achieves target coverage (94.3% vs 95% target) with adaptive precision: 21% narrower intervals for low-uncertainty cases while appropriately widening for high-risk predictions. Critically, we demonstrate that well-calibrated Bayesian uncertainties alone severely under-cover (14.1%), highlighting the necessity of our hybrid approach. This framework enables risk-stratified clinical protocols, efficient resource planning for high-confidence predictions, and conservative allocation with enhanced oversight for uncertain cases, providing uncertainty-aware decision support across diverse healthcare settings.

</details>


### [111] [The Alchemy of Thought: Understanding In-Context Learning Through Supervised Classification](https://arxiv.org/abs/2601.01290)
*Harshita Narnoli,Mihai Surdeanu*

Main category: cs.LG

TL;DR: 本文通过比较大语言模型（LLM）的上下文学习（ICL）与基于相同示例训练的分类器行为，研究了ICL的工作原理，发现当演示相关性高时，LLM行为与分类器相似，且更接近kNN而非逻辑回归；当相关性低时，LLM表现更好，因其可以依赖参数记忆。


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习（ICL）已成为快速定制大语言模型（LLM）到新任务的重要范式，但其工作原理仍不清楚。本文旨在通过比较ICL与基于相同示例训练的分类器行为，深入理解ICL的工作机制。

Method: 使用文本分类作为用例，在六个数据集和三个LLM上，将ICL的行为与基于相同演示示例训练的分类器进行比较。主要对比梯度下降（GD）训练的logistic回归分类器和k近邻（kNN）分类器，分析ICL与这些分类器的相似性和差异。

Result: 研究发现：1）当演示相关性高时，LLM行为与基于相同示例训练的分类器相似；2）平均而言，ICL更接近kNN而非logistic回归，表明注意力机制的行为更类似于kNN而非梯度下降；3）当演示相关性低时，LLM表现优于这些分类器，因为LLM可以回退到其参数记忆，而分类器不具备这种能力。

Conclusion: ICL的工作原理在演示相关性高时类似于基于示例的分类器，特别是更接近kNN机制；而在演示相关性低时，LLM能够利用其参数记忆获得更好性能。这为理解ICL机制提供了实证证据，并揭示了注意力机制与kNN的相似性。

Abstract: In-context learning (ICL) has become a prominent paradigm to rapidly customize LLMs to new tasks without fine-tuning. However, despite the empirical evidence of its usefulness, we still do not truly understand how ICL works. In this paper, we compare the behavior of in-context learning with supervised classifiers trained on ICL demonstrations to investigate three research questions: (1) Do LLMs with ICL behave similarly to classifiers trained on the same examples? (2) If so, which classifiers are closer, those based on gradient descent (GD) or those based on k-nearest neighbors (kNN)? (3) When they do not behave similarly, what conditions are associated with differences in behavior? Using text classification as a use case, with six datasets and three LLMs, we observe that LLMs behave similarly to these classifiers when the relevance of demonstrations is high. On average, ICL is closer to kNN than logistic regression, giving empirical evidence that the attention mechanism behaves more similarly to kNN than GD. However, when demonstration relevance is low, LLMs perform better than these classifiers, likely because LLMs can back off to their parametric memory, a luxury these classifiers do not have.

</details>


### [112] [ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System](https://arxiv.org/abs/2601.01297)
*Anantha Sharma*

Main category: cs.LG

TL;DR: Argus框架将高维数据流中的分布漂移检测重新定义为在数据流形固定空间划分上跟踪局部统计量，解决了现有方法在可扩展性、几何结构保持和身份稳定性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 高维数据流中的分布漂移检测面临三个主要挑战：全局比较方法扩展性差，基于投影的方法丢失几何结构，重新聚类方法存在身份不稳定性。需要一种既能保持高维结构又具有计算效率的漂移检测方法。

Method: Argus框架通过固定空间划分（Voronoi镶嵌）跟踪局部统计量来检测漂移。使用规范正交基上的Voronoi镶嵌获得正交变换不变的漂移度量，引入图论方法区分连贯分布漂移与孤立扰动，并采用乘积量化镶嵌扩展到超高维度（d>500）。

Result: 理论证明Voronoi镶嵌在正交变换下具有不变性，框架实现O(N)复杂度并提供细胞级空间定位。实验验证表明该方法能正确识别坐标旋转下的漂移，而现有方法会产生误报。

Conclusion: Argus为分布监控提供了有原则的几何基础，既能保持高维结构又避免了成对比较的计算负担，通过固定空间划分实现了高效且几何感知的漂移检测。

Abstract: Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.
  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.
  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.

</details>


### [113] [Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware](https://arxiv.org/abs/2601.01298)
*Jorge L. Ruiz Williams*

Main category: cs.LG

TL;DR: Warp Cortex是一个异步多智能体LLM框架，通过解耦智能体逻辑与物理内存，实现了百万级智能体的理论扩展能力，显著降低了内存复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体大型语言模型框架存在线性内存扩展问题，使得"系统2"并行推理在消费级硬件上不切实际，需要解决内存瓶颈以实现大规模智能体协同。

Method: 采用异步架构，通过Singleton权重共享和拓扑突触技术降低内存复杂度；将KV缓存视为潜在空间中的点云，应用见证复形稀疏化技术；引入参考注入机制实现非侵入式KV缓存更新。

Result: 在单张NVIDIA RTX 4090上实现了100个并发智能体仅占用2.2GB显存，理论容量超过1000个智能体；内存复杂度从O(N*L)降至O(1)权重和O(N*k)上下文。

Conclusion: Warp Cortex通过创新的内存优化架构，解决了多智能体LLM框架的内存扩展瓶颈，为实现大规模智能体协同推理提供了可行的技术路径。

Abstract: Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering "System 2" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.

</details>


### [114] [Towards a Principled Muon under $μ\mathsf{P}$: Ensuring Spectral Conditions throughout Training](https://arxiv.org/abs/2601.01306)
*John Zhao*

Main category: cs.LG

TL;DR: 本文提出Muon++优化器，在μ-参数化框架下保证谱条件，实现矩阵优化器在长时训练中的实用部署，无需显式权重谱归一化。


<details>
  <summary>Details</summary>
Motivation: μ-参数化为大语言模型训练提供了理论基础，但现有Muon优化器在μP框架下存在局限性：要么无法保证整个训练过程中的谱条件，要么需要重复的谱归一化导致计算开销大。需要解决理论与实际部署之间的差距。

Method: 提出Muon++优化器变体，关键洞见是对于中等规模模型，仅在优化器更新层面维持谱控制就足以保持μP兼容的缩放，无需显式权重谱归一化。还首次引入数据依赖效应的自适应谱条件。

Result: Muon++在整个训练过程中满足谱条件，弥合了μP理论承诺与矩阵优化器实际部署之间的差距，同时减少了计算开销，更适合长时LLM训练。

Conclusion: 通过仅在更新层面控制谱条件，Muon++实现了μP框架下矩阵优化器的实用部署，为长时大语言模型训练提供了更高效的优化方案。

Abstract: The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.

</details>


### [115] [Spectral-Window Hybrid (SWH)](https://arxiv.org/abs/2601.01313)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: SWH是一种混合架构，通过并行全局分支（基于卷积定理）和局部分支（滑动窗口注意力）来平衡计算效率与表示能力，实现线性扩展至长序列。


<details>
  <summary>Details</summary>
Motivation: Transformer的二次方复杂度限制了其在长序列任务中的应用，需要在计算效率和表示能力之间取得平衡。

Method: 提出Spectral-Window Hybrid架构，将序列建模解耦为两个并行流：全局分支利用卷积定理建模长程衰减动态（O(T log T)），局部分支使用滑动窗口注意力处理有限上下文内的token交互。

Result: SWH在短上下文上匹配标准Transformer的困惑度，同时能够高效线性扩展到长序列。

Conclusion: SWH通过解耦全局和局部建模，避免了全局注意力的计算瓶颈，同时保持了局部精度，为长序列建模提供了高效解决方案。

Abstract: Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\mathcal{O}(T \log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH

</details>


### [116] [From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion](https://arxiv.org/abs/2601.01347)
*Yuyan Pi,Min Jin,Wentao Xie,Xinhua Liu*

Main category: cs.LG

TL;DR: GM-MLG：基于图-基序特征融合和多标签生成的开放式药物不良反应预测新范式，通过分子结构多级表示和Transformer解码器实现标签序列生成，显著提升预测性能并扩展预测空间


<details>
  <summary>Details</summary>
Motivation: 当前药物不良反应预测方法面临数据稀缺导致的冷启动问题、封闭标签集限制以及标签依赖关系建模不足等挑战，需要开发能够动态扩展预测空间并更好建模标签关系的开放式预测方法

Method: 提出GM-MLG方法：1）构建原子级、局部分子级（BRICS算法动态提取精细基序）和全局分子级的双图表示架构；2）将ADR预测从多标签分类转化为基于Transformer解码器的多标签生成，将ADR标签视为离散标记序列，使用位置嵌入显式捕获标签依赖关系，通过自回归解码动态扩展预测空间

Result: 实验显示GM-MLG实现最高38%的性能提升，平均增益20%，将预测空间从200种扩展到超过10,000种类型。通过逆合成基序分析阐明ADR与基序之间的非线性构效关系，为药物安全风险系统降低提供可解释性支持

Conclusion: GM-MLG成功解决了药物不良反应预测中的冷启动、封闭标签集和标签依赖建模问题，通过开放式生成范式显著扩展了预测能力，为计算生物学在药物安全评估中的应用提供了创新方法

Abstract: Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.

</details>


### [117] [Causal discovery for linear causal model with correlated noise: an Adversarial Learning Approach](https://arxiv.org/abs/2601.01368)
*Mujin Zhou,Junzhe Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于f-GAN框架的因果发现方法，用于处理存在未测量混杂因素的数据，通过将结构学习问题转化为最小化贝叶斯自由能量，并证明其等价于最小化真实数据分布与模型生成分布之间的f-散度。


<details>
  <summary>Details</summary>
Motivation: 从存在未测量混杂因素的数据中进行因果发现是一个具有挑战性的问题。传统方法可能依赖于特定的权重值，而本文旨在学习独立于具体权重值的二元因果结构。

Method: 1. 将结构学习问题重新表述为最小化贝叶斯自由能量；2. 证明该问题等价于最小化真实数据分布与模型生成分布之间的f-散度；3. 使用f-GAN框架将目标转化为最小-最大对抗优化问题；4. 采用Gumbel-Softmax松弛在离散图空间中进行梯度搜索。

Result: 论文提出了一种新的因果发现框架，能够处理未测量混杂因素，并通过对抗优化方法学习因果结构，避免了传统方法对特定权重值的依赖。

Conclusion: 该方法为存在未测量混杂因素的因果发现问题提供了一种有效的解决方案，通过f-GAN框架和Gumbel-Softmax松弛实现了在离散图空间中的梯度优化，具有理论保证和实际可行性。

Abstract: Causal discovery from data with unmeasured confounding factors is a challenging problem. This paper proposes an approach based on the f-GAN framework, learning the binary causal structure independent of specific weight values. We reformulate the structure learning problem as minimizing Bayesian free energy and prove that this problem is equivalent to minimizing the f-divergence between the true data distribution and the model-generated distribution. Using the f-GAN framework, we transform this objective into a min-max adversarial optimization problem. We implement the gradient search in the discrete graph space using Gumbel-Softmax relaxation.

</details>


### [118] [Data Complexity-aware Deep Model Performance Forecasting](https://arxiv.org/abs/2601.01383)
*Yen-Chia Chen,Hsing-Kuo Pao,Hanjuan Huang*

Main category: cs.LG

TL;DR: 提出一个轻量级的两阶段框架，可在训练前预测深度学习模型性能，基于数据集属性和模型架构信息，无需实际训练或复杂模拟。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型架构选择通常依赖试错过程，耗时耗力且难以自动化。现有性能预测方法要么需要部分训练（计算开销大），要么缺乏泛化能力。

Method: 两阶段框架：第一阶段基于数据集的可测量属性预测基线性能；第二阶段结合模型架构和超参数细节调整估计。框架设计具有跨数据集和模型类型的泛化能力。

Result: 框架不仅能预测模型性能，还能指导架构选择、预处理流程，并在训练前检测潜在有问题的数据集。发现数据集方差等底层特征可作为数据质量的早期指标。

Conclusion: 该轻量级框架提供了一种高效替代传统试错方法的方式，可在训练前估计模型性能，同时为模型选择和数据处理提供实用指导。

Abstract: Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.

</details>


### [119] [Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning](https://arxiv.org/abs/2601.01387)
*Yongzhe Li,Lin Guan,Zihan Cai,Zuxian Lin,Jiyu Huang,Liukai Chen*

Main category: cs.LG

TL;DR: 本文提出了一种尺度自适应多任务潮流分析框架SaMPFA，通过局部拓扑切片采样技术和无参考多任务图学习模型，提高了深度学习模型在变系统规模下的适应性和分支功率预测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发具有强拓扑变化适应性的深度学习模型对于潮流分析具有重要实际意义。现有模型在变系统规模下的性能有限，分支功率预测的鲁棒性有待提高。

Method: 提出SaMPFA框架：1）局部拓扑切片采样技术，从完整电网中提取不同尺度的子图以增强跨尺度学习能力；2）设计无参考多任务图学习模型，预测母线电压和分支功率而非相角，避免分支功率计算中的误差放大风险；3）损失函数中加入额外项，鼓励模型捕捉相角差和功率传输的物理模式。

Result: 在IEEE 39节点系统和实际省级电网上的仿真表明，所提模型在变系统规模下具有优异的适应性和泛化能力，准确率分别提高了4.47%和36.82%。

Conclusion: SaMPFA框架通过局部拓扑切片采样和多任务学习策略，显著提升了深度学习模型在变系统规模潮流分析中的适应性和鲁棒性，为电力系统分析提供了有效的解决方案。

Abstract: Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.

</details>


### [120] [A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble](https://arxiv.org/abs/2601.01403)
*Zewei Yu,Jianqiu Xu,Caimin Li*

Main category: cs.LG

TL;DR: GDME是一个基于图的无监督在线时间序列异常检测框架，通过动态模型池和图结构进行模型集成，能有效处理异构流数据并检测概念漂移。


<details>
  <summary>Details</summary>
Motivation: 工业系统中流数据量不断增加，在线异常检测成为关键任务。现有方法多为离线设计或难以有效处理异构流数据，需要能适应快速变化数据模式的在线检测方案。

Method: 提出GDME框架：维护动态模型池，持续更新（修剪性能不佳模型并引入新模型）；使用动态图结构表示模型间关系；通过社区检测选择集成子集；利用图结构变化检测概念漂移以适应流数据演化。

Result: 在7个异构时间序列数据集上的实验表明，GDME优于现有在线异常检测方法，提升幅度达24%；其集成策略比单个模型和平均集成方法表现更优，计算效率具有竞争力。

Conclusion: GDME框架通过动态模型池和图结构集成，能有效处理在线时间序列异常检测中的异构流数据和概念漂移问题，在检测性能和计算效率方面均表现出色。

Abstract: With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.

</details>


### [121] [High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation](https://arxiv.org/abs/2601.01860)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

TL;DR: 提出基于因子分解机与二次优化退火的高阶上位性检测方法，将上位性检测转化为黑盒优化问题，显著提升计算效率


<details>
  <summary>Details</summary>
Motivation: 高阶上位性检测面临组合爆炸的计算挑战，传统多因子降维方法在基因位点数量或交互阶数增加时计算不可行

Method: 将上位性检测定义为黑盒优化问题，使用因子分解机与二次优化退火求解，以多因子降维计算的分类错误率作为目标函数

Result: 在模拟病例对照数据集上成功识别预设的高阶上位性，在不同交互阶数和基因位点数量下都能在有限迭代次数内找到真实上位性

Conclusion: 该方法对高阶上位性检测有效且计算高效，为解决遗传关联研究中的组合爆炸问题提供了可行方案

Abstract: Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.

</details>


### [122] [Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models](https://arxiv.org/abs/2601.01452)
*Jian Feng,Zhihong Huang*

Main category: cs.LG

TL;DR: BSZO是一种贝叶斯子空间零阶优化方法，通过卡尔曼滤波结合多个扰动方向的有限差分信息，相比传统ZO方法提高了收敛速度，在保持接近推理基线内存使用的同时，在多个LLM上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零阶优化方法依赖单步梯度估计，仅使用随机扰动的一步梯度估计，限制了优化效率和性能。需要一种能够结合多个扰动方向信息、更有效地利用有限差分测量的优化方法。

Method: 提出贝叶斯子空间零阶优化(BSZO)，将每个有限差分测量视为噪声观测，通过卡尔曼滤波构建投影梯度的后验分布，并使用基于残差的自适应机制调整扰动尺度，结合多个扰动方向的信息进行贝叶斯推断。

Result: 理论分析显示BSZO相比标准ZO方法收敛速度提高了k/γ倍。在RoBERTa、Mistral和OPT模型上的实验表明，BSZO在多个任务上优于MeZO、MeZO-Adam和HiZOO，在OPT-13B上实现了最高6.67%的绝对平均提升，同时内存使用保持在推理基线的1.00-1.08倍。

Conclusion: BSZO通过贝叶斯方法有效结合多个扰动方向的有限差分信息，显著提高了零阶优化的收敛速度和性能，同时保持了低内存消耗的优势，为大语言模型的高效微调提供了新的优化方案。

Abstract: Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\times$--1.08$\times$ of MeZO).

</details>


### [123] [Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD](https://arxiv.org/abs/2601.01465)
*Ze Peng,Jian Zhang,Yisen Wang,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.LG

TL;DR: 该论文提出了一种新的信息论泛化界，能够更好地利用SGD的平坦性偏好，在数值上更紧且能正确反映平坦性改善时的泛化提升。


<details>
  <summary>Details</summary>
Motivation: 现有信息论泛化界虽然具有数据和算法依赖性，但未能充分捕捉SGD平坦性偏好对泛化的改善，且在数值上较松。作者观察到平坦性偏差对SGD泛化至关重要，但现有界无法反映平坦性改善时的泛化提升。

Method: 提出一种更充分利用平坦性的信息论泛化界，针对偏好平坦性的SGD算法。引入"全知轨迹"的灵活技术，分析最终权重协方差的大方差方向在损失景观中的局部曲率。

Result: 实验表明新界不仅能正确反映平坦性改善时的泛化提升，数值上也更紧。应用于梯度下降在凸-Lipschitz-有界问题上的极小化超额风险时，将代表性信息论界的Ω(1)率改进为O(1/√n)。

Conclusion: 新提出的信息论泛化界能更好地利用SGD的平坦性偏好，提供更紧的泛化保证，并暗示了绕过记忆-泛化权衡的可能性。

Abstract: Information-theoretic (IT) generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe that although the flatness bias is crucial for SGD's generalization, these bounds fail to capture the improved generalization under better flatness and are also numerically loose. This is caused by the inadequate leverage of SGD's flatness bias in existing IT bounds. This paper derives a more flatness-leveraging IT bound for the flatness-favoring SGD. The bound indicates the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically much tighter. This is achieved by a flexible technique called "omniscient trajectory". When applied to Gradient Descent's minimax excess risk on convex-Lipschitz-Bounded problems, it improves representative IT bounds' $Ω(1)$ rates to $O(1/\sqrt{n})$. It also implies a by-pass of memorization-generalization trade-offs.

</details>


### [124] [SGD-Based Knowledge Distillation with Bayesian Teachers: Theory and Guidelines](https://arxiv.org/abs/2601.01484)
*Itai Morad,Nir Shlezinger,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 本文从贝叶斯视角分析知识蒸馏，证明使用贝叶斯分类概率作为教师输出能减少方差、提升收敛稳定性，并实验验证贝叶斯教师模型能带来更高准确率和更稳定收敛。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在实践中表现出色但理论理解不足，需要从贝叶斯角度分析其收敛行为，特别是研究贝叶斯分类概率作为教师输出的效果。

Method: 采用贝叶斯视角分析知识蒸馏，研究两种监督方式：精确贝叶斯分类概率和带噪声的近似贝叶斯分类概率。使用随机梯度下降分析学生模型的收敛行为，并通过实验验证贝叶斯教师模型的效果。

Result: 分析表明：学习贝叶斯分类概率能减少方差、消除收敛边界中的邻域项；噪声水平影响泛化和准确性；实验证明贝叶斯教师蒸馏的学生准确率提升高达4.27%，收敛噪声减少达30%。

Conclusion: 贝叶斯深度学习模型能提供更好的贝叶斯分类概率估计，作为知识蒸馏的教师模型能显著提升学生模型的准确率和收敛稳定性，为知识蒸馏提供了理论支持和实践指导。

Abstract: Knowledge Distillation (KD) is a central paradigm for transferring knowledge from a large teacher network to a typically smaller student model, often by leveraging soft probabilistic outputs. While KD has shown strong empirical success in numerous applications, its theoretical underpinnings remain only partially understood. In this work, we adopt a Bayesian perspective on KD to rigorously analyze the convergence behavior of students trained with Stochastic Gradient Descent (SGD). We study two regimes: $(i)$ when the teacher provides the exact Bayes Class Probabilities (BCPs); and $(ii)$ supervision with noisy approximations of the BCPs. Our analysis shows that learning from BCPs yields variance reduction and removes neighborhood terms in the convergence bounds compared to one-hot supervision. We further characterize how the level of noise affects generalization and accuracy. Motivated by these insights, we advocate the use of Bayesian deep learning models, which typically provide improved estimates of the BCPs, as teachers in KD. Consistent with our analysis, we experimentally demonstrate that students distilled from Bayesian teachers not only achieve higher accuracies (up to +4.27%), but also exhibit more stable convergence (up to 30% less noise), compared to students distilled from deterministic teachers.

</details>


### [125] [Advanced Global Wildfire Activity Modeling with Hierarchical Graph ODE](https://arxiv.org/abs/2601.01501)
*Fan Xu,Wei Gong,Hao Wu,Lilan Peng,Nan Wang,Qingsong Wen,Xian Wu,Kun Wang,Xibin Zhao*

Main category: cs.LG

TL;DR: HiGO框架通过多层级图结构和神经ODE模块，实现了全球野火行为的长期预测，在SeasFire数据集上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 野火作为地球系统的重要组成部分，受到大气、海洋和陆地过程在多种时空尺度上的复杂相互作用影响。虽然深度学习在全球天气预报方面取得了突破，但在全球野火行为预测方面的潜力尚未充分探索

Method: 提出分层图ODE（HiGO）框架，将地球系统表示为多层图层次结构，采用自适应滤波消息传递机制处理层内和层间信息流，并在多个层级集成GNN参数化的神经ODE模块来学习每个尺度的连续动力学

Result: 在SeasFire Cube数据集上的广泛实验表明，HiGO在长期野火预测方面显著优于最先进的基线方法，其连续时间预测表现出很强的观测一致性

Conclusion: HiGO框架为全球野火行为预测提供了有效的解决方案，其多尺度连续动力学建模方法在实际应用中具有重要潜力

Abstract: Wildfires, as an integral component of the Earth system, are governed by a complex interplay of atmospheric, oceanic, and terrestrial processes spanning a vast range of spatiotemporal scales. Modeling their global activity on large timescales is therefore a critical yet challenging task. While deep learning has recently achieved significant breakthroughs in global weather forecasting, its potential for global wildfire behavior prediction remains underexplored. In this work, we reframe this problem and introduce the Hierarchical Graph ODE (HiGO), a novel framework designed to learn the multi-scale, continuous-time dynamics of wildfires. Specifically, we represent the Earth system as a multi-level graph hierarchy and propose an adaptive filtering message passing mechanism for both intra- and inter-level information flow, enabling more effective feature extraction and fusion. Furthermore, we incorporate GNN-parameterized Neural ODE modules at multiple levels to explicitly learn the continuous dynamics inherent to each scale. Through extensive experiments on the SeasFire Cube dataset, we demonstrate that HiGO significantly outperforms state-of-the-art baselines on long-range wildfire forecasting. Moreover, its continuous-time predictions exhibit strong observational consistency, highlighting its potential for real-world applications.

</details>


### [126] [Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings](https://arxiv.org/abs/2601.01558)
*Pengfei Qu,Wenyu Ouyang,Chi Zhang,Yikai Chai,Shuolong Xu,Lei Ye,Yongri Piao,Miao Zhang,Huchuan Lu*

Main category: cs.LG

TL;DR: 卫星图像嵌入比传统流域属性更能有效预测无观测站河流流量，通过选择相似流域作为数据源可提高预测精度


<details>
  <summary>Details</summary>
Motivation: 传统流域属性无法完全描述自然环境复杂性，需要更有效的方法来表征流域特征以预测无观测站河流流量

Method: 使用AlphaEarth Foundation嵌入（从大量卫星图像学习的环境表示）替代传统流域属性，并研究如何选择相似流域作为数据源来预测无观测站区域流量

Result: 基于卫星图像嵌入的模型在预测未用于训练的流域流量时精度更高，表明这些嵌入能更有效地捕捉关键物理差异；选择环境和水文行为相似的流域作为数据源可提高预测性能

Conclusion: 卫星信息驱动的环境表示能增强水文预测能力，支持开发更易适应不同景观的水文模型

Abstract: Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.

</details>


### [127] [REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training](https://arxiv.org/abs/2601.01605)
*Xin Di,Xinglin Piao,Fei Wang,Guodong Jing,Yong Zhang*

Main category: cs.LG

TL;DR: 提出REE-TTT模型，通过时空测试时训练机制增强雷达回波外推的泛化能力，解决传统方法对本地训练数据和静态参数的依赖问题


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的雷达回波外推方法在降水临近预报中占主导地位，但存在泛化能力差的问题，主要原因是依赖高质量本地训练数据和静态模型参数，限制了在不同区域和极端事件中的适用性

Method: 提出REE-TTT模型，引入自适应测试时训练机制，核心是设计的时空测试时训练块，用任务特定的注意力机制替代标准线性投影，能够适应非平稳气象分布，显著增强降水特征表示

Result: 在跨区域极端降水场景下的实验表明，REE-TTT在预测精度和泛化能力上显著优于最先进的基线模型，表现出对数据分布变化的显著适应性

Conclusion: REE-TTT通过测试时训练机制有效解决了雷达回波外推模型的泛化问题，为降水临近预报提供了更强大和适应性更强的解决方案

Abstract: Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.

</details>


### [128] [Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry](https://arxiv.org/abs/2601.01616)
*Md Istiauk Hossain Rifat,Moin Khan,Mohammad Zunaed*

Main category: cs.LG

TL;DR: 本文针对孟加拉国纺织行业能耗监控落后问题，提出基于非侵入式负载监测的实时监控框架，聚焦相同电机负载，开发硬件系统并创建新数据集，评估MATNILM模型在工业环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国纺织行业作为高能耗产业，其能耗监控方法陈旧，导致能源使用效率低下和运营成本高昂。需要开发实时监控系统来改善这一状况。

Method: 开发包含电压电流传感器、Arduino Mega和ESP8266的硬件系统，采集总负载和单个负载数据；创建包含三个相同感应电机和辅助负载的新数据集（超过18万个样本）；在云平台上存储和处理数据；评估MATNILM模型在工业条件下的性能。

Result: 总能耗估计相对准确，但相同设备同时运行时，单个设备能耗分解面临困难；集成系统通过Blynk应用实现了实用的实时远程监控。

Conclusion: NILM在工业应用中既有潜力也有局限，未来改进方向包括：更高频率数据采集、更大规模数据集以及处理相同负载的先进深度学习方法。

Abstract: The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.

</details>


### [129] [Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths](https://arxiv.org/abs/2601.01663)
*He Sun,Jiwoong Shin,Ravi Dhar*

Main category: cs.LG

TL;DR: 提出长度感知采样（LAS）方法，通过按长度分组轨迹来减少批次内长度异质性，改善生成模型对轨迹衍生统计量的分布匹配效果


<details>
  <summary>Details</summary>
Motivation: 研究可变长度轨迹的生成建模，用于下游仿真和反事实分析。标准小批量训练在轨迹长度高度异质时不稳定，这会降低轨迹衍生统计量的分布匹配质量

Method: 提出长度感知采样（LAS）策略：按轨迹长度分组，从单一长度桶中采样批次，减少批次内长度异质性；集成到带辅助时间对齐损失的条件下轨迹GAN中

Result: 提供理论保证：在温和有界性假设下对衍生变量的分布级保证；IPM/Wasserstein机制解释LAS通过消除仅长度捷径批评器改善分布匹配；在多商场购物者轨迹和多样化公共序列数据集上一致改善衍生变量分布匹配

Conclusion: LAS是一种简单有效的批处理策略，无需改变模型类别即可改善轨迹生成模型的分布匹配性能，在多种实际应用场景中优于随机采样

Abstract: We study generative modeling of \emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \emph{distribution matching} for trajectory-derived statistics. We propose \textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.

</details>


### [130] [Who is the Winning Algorithm? Rank Aggregation for Comparative Studies](https://arxiv.org/abs/2601.01664)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 提出了一种新框架，利用算法在基准数据集上的完整排名信息（不仅是获胜次数，还包括第二、第三等名次）来更准确地估计每个算法在未来未见数据集上获胜的概率。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅统计每个算法在基准数据集上的获胜次数来预测未来表现，但忽略了完整的排名信息（如第二、第三名等）。这些额外信息可能包含重要线索，但如何有效利用这些信息来更准确地估计获胜概率尚不明确。

Method: 引入了一个新的概念框架，该框架利用算法在多个数据集上的完整排名信息（不仅是获胜次数，还包括所有名次分布），来估计每个算法在未来未见数据集上获胜的概率。该方法超越了传统的最大似然估计方法。

Result: 提出的新框架在合成和真实世界的示例中都显著优于当前已知的方法，能够更准确地预测算法在未来数据集上的获胜概率。

Conclusion: 利用算法在基准数据集上的完整排名信息（而不仅仅是获胜次数）可以显著提高预测算法未来获胜概率的准确性，为算法选择和评估提供了更强大的工具。

Abstract: Consider a collection of m competing machine learning algorithms. Given their performance on a benchmark of datasets, we would like to identify the best performing algorithm. Specifically, which algorithm is most likely to ``win'' (rank highest) on a future, unseen dataset. The standard maximum likelihood approach suggests counting the number of wins per each algorithm. In this work, we argue that there is much more information in the complete rankings. That is, the number of times that each algorithm finished second, third and so forth. Yet, it is not entirely clear how to effectively utilize this information for our purpose. In this work we introduce a novel conceptual framework for estimating the win probability for each of the m algorithms, given their complete rankings over a benchmark of datasets. Our proposed framework significantly improves upon currently known methods in synthetic and real-world examples.

</details>


### [131] [Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives](https://arxiv.org/abs/2601.01665)
*Wei Liu,Yaoxin Wu,Yingqian Zhang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

TL;DR: 提出一个面向多目标组合优化问题的强化学习求解器鲁棒性框架，包括偏好对抗攻击生成困难实例和基于对抗训练的防御策略，在多个问题上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然深度强化学习在多目标组合优化问题上显示出潜力，但这些基于学习的求解器的鲁棒性尚未得到充分探索，特别是在多样化和复杂的问题分布中。

Method: 提出了一个统一的鲁棒性导向框架，包括：1）偏好对抗攻击方法生成暴露求解器弱点的困难实例；2）基于对抗训练的防御策略，集成难度感知偏好选择以减少对受限偏好区域的过拟合。

Result: 在多目标旅行商问题、多目标容量车辆路径问题和多目标背包问题上验证了攻击方法能成功为不同求解器生成困难实例，防御方法显著增强了神经求解器的鲁棒性和泛化能力。

Conclusion: 该框架有效提升了多目标组合优化问题中深度强化学习求解器的鲁棒性，攻击方法能暴露弱点，防御方法能增强在困难或分布外实例上的性能。

Abstract: Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.

</details>


### [132] [DiMEx: Breaking the Cold Start Barrier in Data-Free Model Extraction via Latent Diffusion Priors](https://arxiv.org/abs/2601.01688)
*Yash Thesia,Meera Suthar*

Main category: cs.LG

TL;DR: DiMEx框架利用预训练潜在扩散模型的语义先验，通过潜在空间中的随机嵌入贝叶斯优化绕过数据自由模型窃取中的"冷启动"问题，显著提升攻击效率；同时提出混合状态集成防御来检测此类攻击的优化轨迹特征。


<details>
  <summary>Details</summary>
Motivation: 模型窃取攻击对机器学习即服务构成重大威胁，而数据自由模型提取面临"冷启动"问题：基于GAN的攻击者需要大量查询从随机噪声收敛到有意义数据。本文旨在利用预训练扩散模型的丰富语义先验来绕过这一初始化障碍。

Method: 提出DiMEx框架：利用预训练潜在扩散模型的语义先验，在生成器的潜在空间中采用随机嵌入贝叶斯优化，立即合成高保真查询。同时提出混合状态集成防御，通过识别潜在空间攻击的独特"优化轨迹"来检测攻击。

Result: DiMEx在SVHN数据集上仅用2000次查询就达到52.1%的协议率，比最先进的GAN基线高出16%以上。混合状态集成防御能够将攻击成功率抑制到21.6%，且延迟可忽略。

Conclusion: DiMEx通过利用预训练扩散模型的语义先验有效解决了数据自由模型窃取中的冷启动问题，而混合状态集成防御能够有效检测此类语义攻击的优化轨迹特征，为MLaaS提供了新的防御机制。

Abstract: Model stealing attacks pose an existential threat to Machine Learning as a Service (MLaaS), allowing adversaries to replicate proprietary models for a fraction of their training cost. While Data-Free Model Extraction (DFME) has emerged as a stealthy vector, it remains fundamentally constrained by the "Cold Start" problem: GAN-based adversaries waste thousands of queries converging from random noise to meaningful data. We propose DiMEx, a framework that weaponizes the rich semantic priors of pre-trained Latent Diffusion Models to bypass this initialization barrier entirely. By employing Random Embedding Bayesian Optimization (REMBO) within the generator's latent space, DiMEx synthesizes high-fidelity queries immediately, achieving 52.1 percent agreement on SVHN with just 2,000 queries - outperforming state-of-the-art GAN baselines by over 16 percent. To counter this highly semantic threat, we introduce the Hybrid Stateful Ensemble (HSE) defense, which identifies the unique "optimization trajectory" of latent-space attacks. Our results demonstrate that while DiMEx evades static distribution detectors, HSE exploits this temporal signature to suppress attack success rates to 21.6 percent with negligible latency.

</details>


### [133] [Enhanced Multi-model Online Conformal Prediction](https://arxiv.org/abs/2601.01692)
*Erfan Hajihashemi,Yanning Shen*

Main category: cs.LG

TL;DR: 提出了一种新的多模型在线保形预测算法，通过生成二分图选择有效模型子集，降低计算复杂度并提高预测效率


<details>
  <summary>Details</summary>
Motivation: 传统保形预测依赖单一固定模型，在在线环境中可能表现不佳；现有多模型方法计算成本高，且性能差的模型会影响整体效果

Method: 在每个时间步生成二分图来识别有效模型子集，从中选择模型构建预测集，减少计算复杂度

Result: 实验表明该方法在预测集大小和计算效率方面优于现有多模型保形预测技术

Conclusion: 提出的多模型在线保形预测算法能有效解决计算复杂度问题，提高预测效率，优于现有方法

Abstract: Conformal prediction is a framework for uncertainty quantification that constructs prediction sets for previously unseen data, guaranteeing coverage of the true label with a specified probability. However, the efficiency of these prediction sets, measured by their size, depends on the choice of the underlying learning model. Relying on a single fixed model may lead to suboptimal performance in online environments, as a single model may not consistently perform well across all time steps. To mitigate this, prior work has explored selecting a model from a set of candidates. However, this approach becomes computationally expensive as the number of candidate models increases. Moreover, poorly performing models in the set may also hinder the effectiveness. To tackle this challenge, this work develops a novel multi-model online conformal prediction algorithm that reduces computational complexity and improves prediction efficiency. At each time step, a bipartite graph is generated to identify a subset of effective models, from which a model is selected to construct the prediction set. Experiments demonstrate that our method outperforms existing multi-model conformal prediction techniques in terms of both prediction set size and computational efficiency.

</details>


### [134] [Entropy-Aligned Decoding of LMs for Better Writing and Reasoning](https://arxiv.org/abs/2601.01714)
*Kareem Ahmed,Sameer Singh*

Main category: cs.LG

TL;DR: EPIC是一种无需超参数的解码方法，通过将未来轨迹的熵纳入语言模型解码，调节生成过程中的不确定性，使其与数据不确定性对齐，从而提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型解码算法依赖贪婪启发式方法，导致生成结果同质化、重复且不连贯。需要一种能够更好处理生成过程中不确定性的解码方法。

Method: EPIC通过熵感知懒惰Gumbel-Max采样，将未来轨迹的熵纳入解码过程，显式调节每一步生成的不确定性，使其与数据的不确定性对齐。该方法精确且高效，每步仅需亚线性次数的熵评估。

Result: 在创意写作和摘要任务中，EPIC在LM-as-judge偏好胜率上持续优于广泛使用的解码策略。自动指标显示EPIC产生更多样化的生成结果和更忠实的摘要。在数学推理任务中，EPIC也优于所有基线方法。

Conclusion: EPIC通过将熵调节纳入解码过程，有效解决了传统解码方法中的短视偏差问题，在各种任务中都能产生更高质量、更多样化且更连贯的生成结果。

Abstract: Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.

</details>


### [135] [Context-Free Recognition with Transformers](https://arxiv.org/abs/2601.01754)
*Selim Jerad,Anej Svete,Sophie Hao,Ryan Cotterell,William Merrill*

Main category: cs.LG

TL;DR: 本文证明循环Transformer通过O(log n)循环层和O(n^6)填充标记可以识别所有上下文无关语言，但对于自然子类如无歧义CFL，仅需O(n^3)填充，使识别更高效。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理自然语言和代码等符合语法的输入方面表现出色，但尚不清楚它们如何处理语法结构。现有研究表明标准Transformer无法识别上下文无关语言（CFL），而循环Transformer可以识别正则语言，但CFL识别问题仍未解决。

Method: 提出使用循环Transformer架构，通过O(log n)循环层和O(n^6)填充标记来实现对所有CFL的识别。特别关注无歧义CFL子类，证明其仅需O(n^3)填充标记，大大提高了实际可行性。

Result: 理论证明循环Transformer可以识别所有CFL，但通用识别需要大量填充标记（O(n^6)）。对于无歧义CFL，识别复杂度降低到O(n^3)填充。实验验证循环机制在需要对数深度的语言上确实有效。

Conclusion: 虽然通用CFL识别可能需要大量填充标记而不切实际，但自然约束如无歧义性可以产生高效的识别算法。循环Transformer在语法处理方面具有潜力，但实际应用需要考虑计算复杂度。

Abstract: Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\mathcal{O}(\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\mathcal{O}(\log n)$ looping layers and $\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.

</details>


### [136] [HyperCLOVA X 8B Omni](https://arxiv.org/abs/2601.01792)
*NAVER Cloud HyperCLOVA X Team*

Main category: cs.LG

TL;DR: HyperCLOVA X 8B Omni是首个支持文本、音频和视觉作为输入输出的任意到任意全模态模型，通过统一的多模态序列实现理解和生成，在韩语和英语中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的任意到任意全模态助手，避免传统分离的模态特定流水线，实现更实用的多模态交互。

Method: 通过共享的下一个token预测接口统一多模态，使用视觉和音频编码器注入连续嵌入进行细粒度理解和接地，构建8B规模的统一模型。

Result: 在韩语和英语的文本、音频、视觉多种输入输出组合中，与类似规模模型相比表现出竞争力。

Conclusion: HyperCLOVA X 8B Omni作为全模态路径探索点，其开源权重将支持广泛的研究和部署场景。

Abstract: In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.

</details>


### [137] [Moments Matter:Stabilizing Policy Optimization using Return Distributions](https://arxiv.org/abs/2601.01803)
*Dennis Jabs,Aditya Mohan,Marius Lindauer*

Main category: cs.LG

TL;DR: 提出一种基于分布评论家和高阶矩（偏度和峰度）的PPO改进方法，通过惩罚极端尾部行为来减少策略更新引起的变异性，提高连续控制任务的稳定性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习智能体在获得相同回合奖励时可能表现出非常不同的行为，这种不稳定性源于环境和算法因素。在连续控制任务中，即使小的参数变化也可能导致不稳定的步态，这既影响算法比较也影响现实世界迁移。虽然约束策略保持窄的后更新奖励分布可以改善稳定性，但在高维环境中直接估计该分布计算成本高昂。

Method: 通过分布评论家建模状态-动作奖励分布，然后使用该分布的高阶矩（偏度和峰度）对PPO的优势函数进行偏置。通过惩罚极端尾部行为，该方法阻止策略进入容易产生不稳定性的参数区域。

Result: 在Walker2D环境中，该方法将后更新奖励分布变窄，稳定性提高了75%，同时保持了可比较的评估奖励。

Conclusion: 当后更新评论家值与后更新奖励对齐不佳时，标准PPO难以产生窄的后更新奖励分布。在这种情况下，基于矩的修正能够缩小该分布，显著提高稳定性，同时不牺牲性能。

Abstract: Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.

</details>


### [138] [Distributed Federated Learning by Alternating Periods of Training](https://arxiv.org/abs/2601.01793)
*Shamik Bhattacharyya,Rachel Kalpana Kalaimani*

Main category: cs.LG

TL;DR: 本文提出了一种分布式联邦学习框架，通过多服务器架构解决传统联邦学习中单点故障和可扩展性问题，设计了DFL算法结合本地训练和全局训练，确保所有服务器收敛到理想模型的近似值。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习依赖单一中央服务器，在处理大量客户端时面临可扩展性挑战，且存在单点故障风险。为了解决这些关键限制，需要设计一个更具可扩展性和容错性的分布式方法。

Method: 提出了分布式联邦学习（DFL）框架，包含多个具有服务器间通信能力的服务器。每个服务器与一组不相交的客户端关联，采用交替的本地训练和全局训练周期。DFL算法通过适当的参数选择，确保所有服务器收敛到共同模型值。

Result: 理论分析表明，在合适的参数选择下，DFL算法能够确保所有服务器收敛到理想模型的小容忍范围内。通过数值模拟验证了理论主张，展示了分布式方法的有效性。

Conclusion: 分布式联邦学习框架成功解决了传统联邦学习的可扩展性和容错性问题，通过多服务器架构和DFL算法实现了有效的本地与全局训练集成，为大规模联邦学习应用提供了可行方案。

Abstract: Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.

</details>


### [139] [Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance](https://arxiv.org/abs/2601.01887)
*Jiawen Zhang,Lipeng He,Kejia Chen,Jian Lou,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

TL;DR: 仅需一个安全样本即可完全恢复大型语言模型的安全对齐，无需牺牲实用性，且收敛速度快


<details>
  <summary>Details</summary>
Motivation: 微调安全对齐的大型语言模型会严重损害其安全性，传统方法需要大量安全样本或校准集，计算开销大且会导致模型实用性下降

Method: 提出只需单个安全样本即可恢复安全对齐的方法，发现安全梯度的低秩结构，证明高效修正的可能性

Result: 该方法在五个安全对齐的LLM和多个数据集上验证有效，无论微调时使用的有害样本数量或基础模型大小，都能在几个epoch内收敛

Conclusion: 安全对齐可以通过极低成本高效恢复，这为LLM安全微调提供了新的实用方法

Abstract: Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.

</details>


### [140] [Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning](https://arxiv.org/abs/2601.01904)
*Yuxuan Li,Harshith Reddy Kethireddy,Srijita Das*

Main category: cs.LG

TL;DR: 该论文研究了强化学习偏好学习中的特征依赖噪声问题，发现现有去噪方法在某些特征依赖噪声场景下表现不佳，而无需显式去噪的方法反而表现更好。


<details>
  <summary>Details</summary>
Motivation: 强化学习偏好学习通常面临偏好数据中的不确定性和噪声问题，现有研究大多假设噪声均匀分布且与观察无关，但实际中噪声往往与特定特征相关，需要更真实的噪声模型。

Method: 提出特征依赖噪声的形式化概念，包括轨迹特征噪声、轨迹相似性噪声、不确定性感知噪声和语言模型噪声等变体，并在DMControl和Meta-world的复杂连续控制任务中评估这些噪声。

Result: 实验表明，在某些特征依赖噪声设置下，最先进的噪声鲁棒PbRL方法学习性能显著下降，而无显式去噪的PbRL方法在多数设置中反而表现更好；语言模型噪声表现出类似特征依赖噪声的特性。

Conclusion: 特征依赖噪声对现有噪声鲁棒方法构成挑战，语言模型噪声能模拟真实人类偏好，需要进一步研究如何鲁棒地处理特征依赖噪声。

Abstract: Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.
  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.
  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.

</details>


### [141] [RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data](https://arxiv.org/abs/2601.01829)
*Peiyan Hu,Haodong Feng,Hongyuan Liu,Tongtong Yan,Wenhao Deng,Tianrun Gao,Rong Zheng,Haoren Zheng,Chenglei Yu,Chuanrui Wang,Kaiwen Li,Zhi-Ming Ma,Dezhi Zhou,Xingcai Lu,Dixia Fan,Tailin Wu*

Main category: cs.LG

TL;DR: RealPDEBench是首个整合真实世界测量数据与配对数值模拟的科学机器学习基准，包含5个数据集、3个任务、8个指标和10个基线模型，旨在解决科学ML中真实数据匮乏的问题并促进模拟到现实的迁移研究。


<details>
  <summary>Details</summary>
Motivation: 当前科学机器学习模型面临的主要瓶颈是缺乏昂贵的真实世界数据，导致大多数模型只能在模拟数据上训练和验证。这不仅限制了科学ML的发展和评估，也阻碍了模拟到现实迁移等关键任务的研究。

Method: 提出了RealPDEBench基准框架，包含：1）5个真实世界测量数据集及其配对的模拟数据集；2）3个任务设计，用于比较真实与模拟数据并开发桥接方法；3）8个评估指标，涵盖数据导向和物理导向指标；4）10个代表性基线模型，包括SOTA模型、预训练PDE基础模型和传统方法。

Result: 实验显示模拟数据与真实世界数据之间存在显著差异，同时表明使用模拟数据进行预训练能持续提高模型的准确性和收敛性。基准测试提供了从真实世界数据中获得的见解。

Conclusion: RealPDEBench通过整合真实世界测量与模拟数据，为科学机器学习提供了首个综合性基准，有望推动该领域向桥接模拟与现实差距的方向发展，促进科学ML在真实世界中的部署应用。

Abstract: Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.

</details>


### [142] [DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems](https://arxiv.org/abs/2601.01931)
*Willem Röpke,Samuel Coward,Andrei Lupu,Thomas Foster,Tim Rocktäschel,Jakob Foerster*

Main category: cs.LG

TL;DR: DéjàQ是一个通过进化合成数学问题来训练推理模型的新框架，使用LLM驱动的变异策略动态生成训练数据，提升模型数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型大多依赖静态数据集，这可能导致记忆而非泛化。需要一种动态适应模型能力的训练范式来提升数学推理的泛化能力。

Method: 提出DéjàQ框架，联合进化多样化的合成数学问题与模型训练。使用两种LLM驱动的变异策略：1）改变上下文细节；2）直接修改问题结构。模型自身参与训练数据的变异生成。

Result: 模型能够生成新颖且有意义的数学问题，LLM驱动的变异策略改善了强化学习训练效果。分析了生成问题的有效性和计算开销。

Conclusion: 动态进化训练数据有潜力增强数学推理能力，具有更广泛的适用性。作者将开源代码以支持进一步研究。

Abstract: Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.

</details>


### [143] [FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks](https://arxiv.org/abs/2601.01833)
*Chenyu Hu,Qiming Hu,Sinan Chen,Nianyu Li,Mingyue Zhang,Jialong Li*

Main category: cs.LG

TL;DR: FAROS：一种增强的联邦学习框架，通过自适应差分缩放和鲁棒核心集计算来防御后门攻击，相比现有方法在攻击成功率和主任务准确率上表现更优。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临后门攻击的严重威胁，现有防御方法通常依赖固定的防御参数，存在单点故障风险，难以应对复杂的攻击策略。

Method: 提出FAROS框架，包含自适应差分缩放机制（根据客户端上传梯度的离散度动态调整防御灵敏度）和鲁棒核心集计算（计算最高置信度客户端核心集的质心来降低单点故障风险）。

Result: 在多个数据集、模型和攻击场景下的实验表明，该方法在攻击成功率和主任务准确率方面均优于现有防御方法。

Conclusion: FAROS通过动态自适应防御和降低单点故障风险，有效提升了联邦学习对后门攻击的防御能力。

Abstract: Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.

</details>


### [144] [Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior](https://arxiv.org/abs/2601.01966)
*Bo Yin,Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.LG

TL;DR: 论文提出Refinement Provenance Inference (RPI)任务，用于推断微调模型训练时使用的是原始提示还是LLM优化版本，并开发了RePro框架通过教师强制似然特征和logit排序信号来检测优化痕迹。


<details>
  <summary>Details</summary>
Motivation: 指令调优越来越依赖基于LLM的提示优化，但训练语料中原始提示和优化版本混合存在，难以确定模型具体训练于哪种版本。这对于数据集治理和争议解决很重要，特别是当训练数据存在争议时。

Method: 提出RePro框架：1）利用提示优化在教师强制token分布中产生的稳定可检测偏移；2）融合教师强制似然特征和logit排序信号；3）通过影子微调学习可迁移表示；4）使用轻量级线性头在未见过的受害者模型上推断来源，无需访问训练数据。

Result: RePro在实证中表现稳定且性能强劲，能够很好地跨不同优化器迁移，表明它利用了优化器无关的分布偏移而非重写风格的人工痕迹。

Conclusion: 提示优化会产生可检测的分布偏移，RePro框架能够有效推断训练数据的优化来源，为数据集治理和争议解决提供了实用工具。

Abstract: Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.

</details>


### [145] [Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack](https://arxiv.org/abs/2601.01840)
*Qiantao Yang,Liquan Chen,Mingfu Xue,Songze Li*

Main category: cs.LG

TL;DR: FedCSPACK：一种基于余弦稀疏化参数打包和双权重聚合的个性化联邦学习方法，有效解决数据异构性和客户端资源有限的问题


<details>
  <summary>Details</summary>
Motivation: 联邦学习中边缘客户端的数据异构性严重影响模型性能，现有方法虽然通过模型分割和知识蒸馏增强模型兼容性，但忽略了客户端通信带宽和计算能力有限的现实约束，未能有效平衡数据异构性处理和资源限制之间的矛盾。

Method: 提出FedCSPACK方法：1）客户端基于余弦相似性打包模型参数并选择贡献最大的参数包进行共享，减少带宽需求；2）客户端基于共享参数包生成掩码矩阵，提高服务器端稀疏更新的对齐和聚合效率；3）在掩码中嵌入方向和分布距离权重，实现加权引导聚合机制。

Result: 在四个数据集上使用十种最先进方法的广泛实验表明，FedCSPACK在保持高模型精度的同时，有效提高了通信和计算效率。

Conclusion: FedCSPACK通过参数打包、稀疏更新和双权重聚合机制，成功解决了联邦学习中数据异构性与客户端资源有限的双重挑战，实现了通信效率、计算效率和模型性能的有效平衡。

Abstract: Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.

</details>


### [146] [Output Embedding Centering for Stable LLM Pretraining](https://arxiv.org/abs/2601.02031)
*Felix Stollenwerk,Anna Lokrantz,Niclas Hertzberg*

Main category: cs.LG

TL;DR: 本文提出输出嵌入中心化(OEC)方法，通过解决输出嵌入几何问题来防止大学习率下的输出logit发散，比现有的z-loss方法更有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型预训练成本高昂且容易出现训练不稳定性，特别是在训练后期使用大学习率时会出现输出logit发散问题。现有的z-loss方法只是治标不治本，需要从根本上解决这一问题。

Method: 从输出嵌入的几何角度分析不稳定性原因，提出输出嵌入中心化(OEC)作为新的缓解策略。OEC有两种实现方式：确定性操作μ-centering和正则化方法μ-loss，都能有效抑制输出logit发散。

Result: 实验表明OEC的两个变体在训练稳定性和学习率敏感性方面都优于z-loss，能确保在大学习率下训练收敛（而z-loss会失败）。μ-loss对正则化超参数调优的敏感性显著低于z-loss。

Conclusion: 通过分析输出嵌入几何问题提出的OEC方法能有效解决大学习率下的训练不稳定性问题，比现有方法更优越，特别是μ-loss具有更好的超参数鲁棒性。

Abstract: Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.

</details>


### [147] [FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data](https://arxiv.org/abs/2601.01901)
*Yuexuan Xia,Yinghao Zhang,Yalin Liu,Hong-Ning Dai,Yong Xia*

Main category: cs.LG

TL;DR: FedBiCross：一种个性化单轮联邦学习框架，通过聚类、双层跨集群优化和个性化蒸馏解决非独立同分布数据下预测冲突问题


<details>
  <summary>Details</summary>
Motivation: 现有的单轮联邦学习方法在非独立同分布数据下存在预测冲突问题，平均聚合会导致软标签趋近均匀分布，从而提供弱监督信号

Method: 三阶段框架：1）基于模型输出相似性聚类客户端形成一致子集成；2）双层跨集群优化学习自适应权重，选择性利用有益跨集群知识并抑制负迁移；3）个性化蒸馏进行客户端特定适应

Result: 在四个医学图像数据集上的实验表明，FedBiCross在不同非独立同分布程度下均优于现有最先进基线方法

Conclusion: FedBiCross通过聚类和选择性知识转移有效解决了单轮联邦学习中的预测冲突问题，在隐私敏感的医学应用中具有实用价值

Abstract: Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.

</details>


### [148] [Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting](https://arxiv.org/abs/2601.02151)
*Muxi Diao,Lele Yang,Wuxuan Gong,Yutong Zhang,Zhonghao Yan,Yufei Han,Kongming Liang,Weiran Xu,Zhanyu Ma*

Main category: cs.LG

TL;DR: 论文提出EAFT方法，通过基于熵的门控机制区分认知不确定性和知识冲突，在保持下游性能的同时显著缓解SFT中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调(SFT)在领域适应时经常导致灾难性遗忘，而基于策略的强化学习(RL)却能有效保持通用能力。研究发现这种差异源于分布差距：RL与模型内部信念对齐，而SFT强制模型拟合外部监督，导致"自信冲突"标记引发破坏性梯度更新。

Method: 提出熵自适应微调(EAFT)，利用标记级熵作为门控机制来区分认知不确定性和知识冲突。该方法允许模型从不确定样本中学习，同时抑制冲突数据的梯度更新，而不是仅依赖预测概率。

Result: 在Qwen和GLM系列模型(4B到32B参数)上，在数学、医疗和智能体领域的广泛实验验证了假设。EAFT在匹配标准SFT下游性能的同时，显著减轻了通用能力的退化。

Conclusion: EAFT通过熵自适应机制有效解决了SFT中的灾难性遗忘问题，为领域适应提供了一种更平衡的方法，在保持专业能力的同时保护模型的通用知识。

Abstract: Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as "Confident Conflicts" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.

</details>


### [149] [DatBench: Discriminative, Faithful, and Efficient VLM Evaluations](https://arxiv.org/abs/2601.02316)
*Siddharth Joshi,Haoli Yin,Rishabh Adiga,Ricardo Monti,Aldo Carranza,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Kaleigh Mentzer,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Scott Loftin,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 论文提出评估视觉语言模型的三项标准：忠实性、区分性和效率，并发现现有评估存在多项缺陷，通过数据清洗和任务转换创建了更可靠的评估套件


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的评估方法尚不成熟，存在多种缺陷，无法准确反映模型真实能力，且评估计算成本过高，需要建立更严谨、可持续的评估实践

Method: 提出评估应满足的三项标准：忠实性、区分性和效率；识别现有评估的失败模式；通过将选择题转换为生成任务、过滤可盲目解答和错误标注样本来优化评估；创建DatBench-Full和DatBench评估套件

Result: 将选择题转换为生成任务后模型能力下降高达35%；过滤问题样本后提高区分能力同时降低计算成本；DatBench评估套件实现13倍平均加速（最高50倍）且保持与原数据集相似的区分能力

Conclusion: 论文为视觉语言模型的评估提供了更严谨和可持续的路径，通过优化现有基准而非完全抛弃，创建了更可靠、高效的评估工具，推动该领域评估实践的成熟

Abstract: Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.

</details>


### [150] [Distorted Distributional Policy Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2601.01917)
*Ryo Iwaki,Takayuki Osogami*

Main category: cs.LG

TL;DR: 本文提出了一种新的离线分布强化学习方法，通过引入分位数扭曲概念实现非均匀悲观主义，解决了现有方法因均匀低估回报分位数而导致的过度保守问题。


<details>
  <summary>Details</summary>
Motivation: 虽然分布强化学习在在线设置中表现出色，但在离线场景中的成功有限。作者假设现有离线DRL方法的主要限制在于它们均匀低估回报分位数的方法，这种均匀悲观主义会导致过度保守的价值估计，最终阻碍泛化和性能。

Method: 引入了一个称为分位数扭曲的新概念，通过根据支持数据的可用性调整保守程度，实现非均匀悲观主义。该方法基于理论分析，并通过实证验证。

Result: 该方法在实证验证中表现出比均匀悲观主义更好的性能，证明了非均匀悲观主义在离线分布强化学习中的有效性。

Conclusion: 通过引入分位数扭曲实现非均匀悲观主义，可以有效解决离线分布强化学习中均匀悲观主义导致的过度保守问题，提高方法的泛化能力和性能表现。

Abstract: While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.

</details>


### [151] [SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling](https://arxiv.org/abs/2601.01943)
*Tieu-Long Phan,Nhu-Ngoc Nguyen Song,Peter F. Stadler*

Main category: cs.LG

TL;DR: SynRXN是一个统一的计算机辅助合成规划基准测试框架和开放数据资源，将端到端合成规划分解为五个任务家族，提供标准化数据集、评估流程和可重现的构建方案。


<details>
  <summary>Details</summary>
Motivation: 当前计算机辅助合成规划领域缺乏统一的基准测试框架，数据集异构性高，评估标准不一致，难以进行公平的纵向比较和可靠的性能评估。

Method: 将合成规划分解为五个任务家族：反应平衡、原子到原子映射、反应分类、反应性质预测和合成路线设计；从异构公共源收集反应数据并统一表示；提供泄漏感知的数据分割、标准化评估流程和指标套件；采用脚本化构建方案确保可重现性。

Result: 创建了一个包含版本化数据集、透明数据分割、标准化评估工作流的完整基准测试框架；所有资源采用开放许可发布，支持可重现的跨机器重建；为敏感任务提供专门的评估集以防止数据污染。

Conclusion: SynRXN通过消除数据集异质性、提供透明可重用的评估框架，实现了CASP方法的公平纵向比较，支持全反应信息学管道的严格消融和压力测试，降低了从业者获取稳健可比性能评估的门槛。

Abstract: We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.

</details>


### [152] [SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition](https://arxiv.org/abs/2601.01979)
*Julie Keisler,Anastase Alexandre Charantonis,Yannig Goude,Boutheina Oueslati,Claire Monteleoni*

Main category: cs.LG

TL;DR: SerpentFlow提出了一种无配对域对齐的生成框架，通过潜在空间分解将数据分为共享结构和域特定组件，利用随机噪声生成合成训练对，从而在无配对数据条件下实现条件生成模型的应用。


<details>
  <summary>Details</summary>
Motivation: 在无配对观测数据的域对齐任务中，传统条件生成模型无法直接应用。虽然不同域之间存在共享的结构模式，但由于缺乏跨域的直接监督，学习域间对应关系具有挑战性。

Method: SerpentFlow在潜在空间中将数据分解为共享组件和域特定组件。通过隔离共享结构并用随机噪声替换域特定组件，构建共享表示与目标域样本之间的合成训练对，从而支持传统上需要配对数据的条件生成模型。在超分辨率任务中，共享组件对应低频内容，高频细节对应域特定变异性，通过分类器准则自动确定分离频率。

Result: 在合成图像、物理过程模拟和气候降尺度任务上的实验表明，该方法能有效重建与底层低频模式一致的高频结构，验证了共享结构分解作为无配对域对齐策略的有效性。

Conclusion: 共享结构分解为无配对域对齐提供了一种有效策略，通过生成伪配对数据使条件生成模型能够在无监督设置下应用，为跨域学习对应关系提供了新思路。

Abstract: Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.

</details>


### [153] [Prior Diffusiveness and Regret in the Linear-Gaussian Bandit](https://arxiv.org/abs/2601.02022)
*Yifan Zhu,John C. Duchi,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 本文证明了Thompson采样在线性高斯多臂赌博机问题中具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾界，其中先验依赖的"预热"项与极小极大遗憾项呈加性分离而非乘性关系。


<details>
  <summary>Details</summary>
Motivation: 现有Thompson采样在线性赌博机中的遗憾界通常包含先验分布参数与极小极大遗憾项的乘性依赖关系，这可能导致理论界限过于悲观。本文旨在证明这两个项可以加性分离，从而更准确地描述算法的实际性能。

Method: 通过新的"椭圆势能"引理来分析Thompson采样在线性高斯赌博机中的性能，其中先验分布为$\mathcal{N}(μ_0, Σ_0)$，动作具有最大$\ell_2$范数$r$，噪声方差为$σ^2$。

Result: 证明了Thompson采样具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾界，其中先验依赖的"预热"项$d r \sqrt{\mathrm{Tr}(Σ_0)}$与极小极大遗憾项$σd \sqrt{T}$呈加性关系。同时提供了下界证明表明预热项是不可避免的。

Conclusion: Thompson采样在线性高斯赌博机中的遗憾可以分解为加性的先验依赖预热项和极小极大遗憾项，这一结果比现有乘性依赖的界限更紧，并通过新的分析技术揭示了算法性能的本质特征。

Abstract: We prove that Thompson sampling exhibits $\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \sqrt{\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.

</details>


### [154] [GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036)
*Yiyang Wang,Xi Chen,Xiaogang Xu,Yu Liu,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 本文提出GDRO（组级直接奖励优化），一种针对文本到图像整流流扩散模型的离线后训练范式，解决了现有在线强化学习方法效率低、依赖随机采样器和奖励黑客等问题。


<details>
  <summary>Details</summary>
Motivation: 当前采用在线强化学习从LLMs到文本到图像整流流扩散模型进行奖励对齐的方法面临三个主要挑战：1）效率低下，在线图像采样耗时严重；2）依赖随机采样器；3）存在奖励黑客问题。整流流模型与LLMs有本质区别：图像采样时间远长于训练时间，且整流流在初始噪声固定后是确定性的。

Method: 设计了Group-level Direct Reward Optimization (GDRO)，这是一种结合整流流模型特性的组级奖励对齐后训练范式。通过理论分析证明GDRO支持完全离线训练，无需图像采样，且不依赖扩散采样器，避免了ODE到SDE近似来获得随机性。同时通过修正评分考虑奖励黑客趋势。

Result: 在OCR和GenEval任务上的大量实验表明，GDRO通过组级离线优化有效且高效地提升了扩散模型的奖励分数，同时在缓解奖励黑客方面表现出强大的稳定性和鲁棒性。

Conclusion: GDRO为文本到图像整流流扩散模型提供了一种高效、稳定且鲁棒的奖励对齐方法，解决了现有在线强化学习方法的关键限制，实现了完全离线训练和采样器独立性。

Abstract: Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.

</details>


### [155] [Explore the Ideology of Deep Learning in ENSO Forecasts](https://arxiv.org/abs/2601.02050)
*Yanhai Gan,Yipeng Chen,Ning Li,Xingguo Liu,Junyu Dong,Xianyao Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种基于有界变差函数的数学可解释性框架，通过激活函数饱和区"拯救"神经元来增强模型表达能力，揭示了ENSO预测的物理机制，并探讨了春季可预测性障碍的成因。


<details>
  <summary>Details</summary>
Motivation: ENSO对全球气候变率有深远影响，但其预测仍面临巨大挑战。虽然深度学习显著提高了预测技能，但这些模型的不透明性阻碍了科学信任和业务部署，需要开发具有物理可解释性的预测框架。

Method: 引入基于有界变差函数的数学可解释性框架，通过从激活函数饱和区"拯救"神经元来增强模型表达能力，分析ENSO可预测性的来源，并进行控制实验验证方法的稳健性。

Result: 分析显示ENSO可预测性主要来自热带太平洋，印度洋和大西洋也有贡献，这与物理理解一致。控制实验证实了方法的稳健性及其与已知预测因子的一致性。研究发现尽管春季敏感性扩大，但预测性能下降，这可能与次优变量选择有关。

Conclusion: 研究结果表明，纳入额外的海洋-大气变量可能有助于克服春季可预测性障碍的限制，推进ENSO的长期预测。该方法为深度学习模型在气候预测中的可解释性提供了数学基础。

Abstract: The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the "dead" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.

</details>


### [156] [Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI](https://arxiv.org/abs/2601.02106)
*Ashish Rana,Ammar Shaker,Sascha Saralajew,Takashi Suzuki,Kosuke Yasuda,Shintaro Kato,Toshikazu Wada,Toshiyuki Fujikawa,Toru Kikutsuji*

Main category: cs.LG

TL;DR: ProtoPal框架通过原型学习实现个性化预防医疗，提供可理解和可验证的预测、干预和推荐，具有前后端模式，在性能与可解释性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习与可解释AI在个性化预防医疗中存在不足：预测、干预和推荐需要对所有医疗相关方都具备可理解性和可验证性。

Method: 提出ProtoPal框架，采用原型学习方法，具备前后端两种模式，能够直观展示干预措施及其模拟结果。

Result: 框架在定量性能方面表现优异，同时提供了干预措施及其模拟结果的直观呈现。

Conclusion: 原型学习方法能够有效解决个性化预防医疗中的可理解性和可验证性问题，ProtoPal框架为此提供了一个可行的解决方案。

Abstract: Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.

</details>


### [157] [Edge-aware GAT-based protein binding site prediction](https://arxiv.org/abs/2601.02138)
*Weisen Yang,Hanqing Zhang,Wangren Qiu,Xuan Xiao,Weizhong Lin*

Main category: cs.LG

TL;DR: 提出Edge-aware GAT模型用于蛋白质结合位点预测，通过原子级图构建和多维结构特征整合，在基准数据集上达到0.93 ROC-AUC，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确识别蛋白质结合位点对于理解生物分子相互作用机制和药物靶点理性设计至关重要。传统预测方法在捕捉复杂空间构象时难以平衡预测精度与计算效率。

Method: 提出Edge-aware Graph Attention Network模型，构建原子级图并整合几何描述符、DSSP二级结构和相对溶剂可及性等多维结构特征。通过将原子间距离和方向向量作为注意力机制中的边特征，增强模型表示能力。使用方向张量传播和残基级注意力池化进一步改进结合位点定位和局部结构细节捕捉。

Result: 在基准数据集上，模型在蛋白质-蛋白质结合位点预测中达到0.93 ROC-AUC，优于多个最先进方法。PyMOL可视化证实了模型的实用性和可解释性。已部署公开可访问的Web服务器。

Conclusion: 该方法为识别蛋白质功能位点提供了一种新颖高效的解决方案，平衡了预测准确性、泛化能力和可解释性。

Abstract: Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.

</details>


### [158] [Learning with Monotone Adversarial Corruptions](https://arxiv.org/abs/2601.02193)
*Kasper Green Larsen,Chirag Pabbaraju,Abhishek Shetty*

Main category: cs.LG

TL;DR: 研究标准机器学习算法对数据可交换性和独立性的依赖程度，通过引入单调对抗性污染模型，发现即使污染数据符合真实目标函数，最优分类算法仍会表现不佳，而基于一致收敛的算法则不受影响。


<details>
  <summary>Details</summary>
Motivation: 探究机器学习算法对数据可交换性和独立性的依赖程度，理解算法在面对看似"有帮助"的单调污染时的鲁棒性，揭示最优算法可能过度依赖数据可交换性的问题。

Method: 引入单调对抗性污染模型：攻击者在查看"干净"的i.i.d.数据集后，插入自己选择的"污染"数据点，这些污染点必须是单调污染，即按照真实目标函数进行标注。在此设置下分析不同算法的表现。

Result: 所有已知的二元分类最优学习算法在单调污染设置下都会在新独立测试点上达到次优的期望错误率；而基于一致收敛的算法则不会降低其性能保证。这表明最优算法在面对看似有帮助的单调污染时会失效。

Conclusion: 标准机器学习算法过度依赖数据的可交换性和独立性，即使在污染数据符合真实目标函数的"有帮助"情况下，最优算法仍会表现不佳，而基于一致收敛的方法更具鲁棒性，这揭示了算法设计中对数据假设的敏感性。

Abstract: We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a "clean" i.i.d. dataset, inserts additional "corrupted" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.

</details>


### [159] [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)
*Shristi Das Biswas,Yue Zhang,Anwesan Pal,Radhika Bhargava,Kaushik Roy*

Main category: cs.LG

TL;DR: ELLA是一种基于选择性子空间去相关原则的持续学习框架，通过惩罚任务特定方向的对齐来减少灾难性遗忘，同时保留低能量子空间的自由度以实现正向迁移。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在持续学习设置中面临严重的灾难性遗忘问题。现有方法存在根本性限制：基于重放的方法不切实际且侵犯隐私，而基于严格正交性的方法在规模扩展时会崩溃，因为每个新任务都被投影到正交补空间，逐渐减少剩余自由度并消除正向迁移。

Method: ELLA基于选择性子空间去相关原则，通过显式表征过去更新的结构，惩罚沿其高能量、任务特定方向的对齐，同时保留低能量残差子空间的自由度以实现迁移。这通过一个轻量级正则化器在单个聚合更新矩阵上实现，对应一个各向异性收缩算子来限制干扰。

Result: ELLA在三个流行基准测试中实现了最先进的持续学习性能，相对准确率提升高达9.6%，内存占用减少35倍。无需数据重放、架构扩展和可忽略的存储开销，并能稳健地跨架构扩展，主动增强模型在未见任务上的零样本泛化性能。

Conclusion: ELLA为构建性终身LLM适应提供了一个原则性且可扩展的解决方案，通过选择性子空间去相关有效解决了持续学习中的灾难性遗忘问题，同时保持了正向迁移能力。

Abstract: Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\%$ and a $35\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.

</details>


### [160] [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)
*Emrah Mete,Emin Erkan Korkmaz*

Main category: cs.LG

TL;DR: 提出Neuro-Channel Networks (NCN)乘法免费架构，受生物神经系统中离子通道限制和神经递质调节机制启发，用通道宽度和神经递质参数替代传统权重，仅使用加法、减法和位运算，无需浮点乘法，实现高效AI计算。


<details>
  <summary>Details</summary>
Motivation: 深度学习严重依赖高性能GPU硬件，这些硬件昂贵、能耗高且供应稀缺，限制了AI在边缘设备的普及。传统人工感知器依赖密集矩阵乘法，而生物神经系统通过物理离子通道限制和化学神经递质水平调节信号传输，无需算术乘法就能实现高效计算。

Method: 提出Neuro-Channel Networks (NCN)架构：1) 用通道宽度替代权重，物理限制信号幅度；2) 引入神经递质参数，基于符号逻辑调节信号传输；3) 前向传播仅使用加法、减法和位运算（最小值、符号），完全消除浮点乘法；4) 使用标准反向传播进行训练。

Result: 在概念验证研究中，NCN能够以100%准确率解决非线性可分问题（如XOR和多数函数），证明其无需乘法权重即可形成复杂决策边界的能力。

Conclusion: NCN架构为下一代神经形态硬件提供了高效替代方案，使复杂模型能够在商用CPU或超低功耗芯片上运行，无需依赖昂贵的GPU集群，有望推动AI在边缘设备的广泛部署。

Abstract: The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

</details>


### [161] [Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck](https://arxiv.org/abs/2601.02307)
*Dina El Zein,James Henderson*

Main category: cs.LG

TL;DR: 提出一种隐私保护的文本数据共享方法，通过共享带噪声的transformer嵌入来保护隐私，同时保持数据实用性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型隐藏表示可能编码输入敏感信息，使攻击者能够恢复原始数据，transformer嵌入包含多个向量（每个token一个）加剧了这一问题，需要同时保证数据共享实用性和隐私保护。

Method: 提出非参数变分差分隐私（NVDP），将非参数变分信息瓶颈（NVIB）层集成到transformer架构中，向多向量嵌入注入噪声以隐藏信息，使用Rényi散度及其对应的贝叶斯差分隐私（BDP）保证来测量隐私保护。

Result: 在GLUE基准测试中验证，通过调整噪声水平实现隐私与准确性的有效权衡，较低噪声水平下模型保持高准确性同时提供强隐私保证。

Conclusion: NVDP方法有效平衡了隐私保护与数据实用性，为隐私保护的文本数据共享提供了可行解决方案。

Abstract: We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.

</details>


### [162] [Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning](https://arxiv.org/abs/2601.02313)
*Hanzaleh Akbari Nodehi,Viveck R. Cadambe,Mohammad Ali Maddah-Ali*

Main category: cs.LG

TL;DR: 论文提出了"编码博弈"框架，将编码理论扩展到去中心化系统中理性对手的场景，即使诚实节点不占多数也能实现非零数据恢复概率，并具有Sybil抗性。


<details>
  <summary>Details</summary>
Motivation: 在去中心化机器学习等新兴应用中，参与节点因贡献获得奖励，这催生了理性对手而非纯粹恶意对手。现有编码方法假设诚实节点占多数，但在去中心化系统中这一假设不成立，需要新的编码框架来处理理性对手。

Method: 提出了"编码博弈"这一新颖的博弈论框架，将编码理论扩展到信任最小化设置。以重复编码为例，展示了该框架的两个关键特性：即使对手节点占多数也能实现非零数据恢复概率，以及Sybil抗性（对手节点数量增加时均衡保持不变）。

Result: 该框架能够在诚实节点不占多数的情况下实现数据恢复，突破了传统编码理论的限制。重复编码示例展示了即使对手节点占多数也能获得非零恢复概率，并且系统对Sybil攻击具有抵抗力。

Conclusion: 编码博弈框架为去中心化系统中的编码问题提供了新的理论视角，特别适用于存在理性对手的场景。论文还探讨了对手策略未知的情况，并提出了未来研究的开放性问题。

Abstract: Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.
  In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.

</details>


### [163] [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)
*Yazan Obeidi,Amir Sarfi,Joel Lidin,Paul Janson,Eugene Belilovsky*

Main category: cs.LG

TL;DR: SparseLoCo低通信数据并行方法与低带宽流水线模型并行结合，通过激活压缩实现异构分布式训练，在保持性能的同时显著减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练需要分布式计算，但带宽限制阻碍了在数据中心之外的扩展，特别是当模型并行需要频繁的大规模设备间通信时。需要研究如何在低带宽环境下有效结合数据并行和模型并行。

Method: 提出异构分布式训练框架：高带宽参与者托管完整副本，资源有限参与者通过流水线并行联合实例化副本，使用子空间投影的激活和激活梯度压缩。将子空间流水线压缩与SparseLoCo（基于稀疏伪梯度交换的低通信数据并行方法）结合，研究多种适配方案。

Result: 在178M-1B参数的大规模语言建模实验中，激活压缩与SparseLoCo结合成本适中，选择性（异构）压缩相比压缩所有副本能持续改善损失-通信权衡，特别是在激进压缩比下效果更明显。

Conclusion: 研究结果表明，将低带宽模型并行和异构参与者纳入LLM预训练是可行的实践路径，为资源受限环境下的分布式训练提供了解决方案。

Abstract: Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [164] [Sample Complexity for Embedded Multipartite Entanglement Witness via Pauli and Clifford Classical Shadows](https://arxiv.org/abs/2601.00859)
*Ziran Zhang*

Main category: quant-ph

TL;DR: 该研究使用经典影子协议分析估计N量子比特系统中n-部分纠缠见证的样本复杂度，发现随着见证从局部变为全局，性能从Pauli有利转变为Clifford有利。


<details>
  <summary>Details</summary>
Motivation: 检测多量子比特系统中的多部分纠缠需要大量测量，因此需要开发仅估计选定可观测量且具有可证明效率的协议。

Method: 使用经典影子协议研究估计嵌入更大N量子比特系统中的子系统n-部分纠缠见证族所需的样本复杂度，推导集合依赖的方差界限。

Result: 数值模拟证实了这些趋势，显示出清晰的交叉现象：对于局部见证是Pauli有利性能，随着见证变得更全局则变为Clifford有利性能。

Conclusion: 经典影子协议可用于有效估计纠缠见证，且性能特征随见证的局部/全局性质而变化，为多量子比特系统中的纠缠检测提供了实用方法。

Abstract: Detecting multipartite entanglement in many qubit systems is measurement-intensive, motivating protocols that estimate only selected observables with provable efficiency. In this work we use the classical shadow protocol to study the sample complexity required to estimate a family of subsystem $n$-partite entanglement witness embedded in an larger $N$-qubit system. We derive ensemble dependent variance bounds that lead to qualitatively distinct scaling for the snapshots cost at fixed additive error $ε$ with numerical simulations confirm these trends, exhibiting a clear crossover from Pauli favorable performance for local witness to Clifford favorable performance as the witness becomes more global.

</details>


### [165] [The Quantum State Continuity Problem and Temporal Enforcement Against Fork Attacks](https://arxiv.org/abs/2601.00870)
*Samet Ünsal*

Main category: quant-ph

TL;DR: 量子状态连续性问题是与身份认证正交的安全目标，用于验证系统当前执行是否是唯一过去执行的合法延续。经典和无状态量子认证机制无法保证连续性，容易受到分叉攻击。作者提出量子状态连续性见证作为最小量子辅助原语，通过有状态量子演化和累积审计来强制执行的时间链接。


<details>
  <summary>Details</summary>
Motivation: 现有安全机制主要关注身份认证，但缺乏对执行连续性的保障。经典和传统量子认证方法无法防止分叉攻击，即攻击者可以创建系统状态的多个分支副本。这揭示了一个未被充分探索的安全维度——确保系统执行在时间上的唯一延续性。

Method: 提出量子状态连续性见证（QSCW）作为最小量子辅助原语。该方法通过有状态的量子演化和累积审计来强制执行的时间链接。使用基于GHZ态的玩具实例化，并进行广泛的模拟验证。

Result: 通过模拟证明，时间强制执行能够以指数衰减的成功概率抑制分叉攻击。该方法对噪声和系统参数保持鲁棒性。量子状态连续性见证有效解决了传统认证机制无法处理的执行连续性问题。

Conclusion: 执行连续性是一个独特且未被充分探索的系统安全维度。量子状态连续性见证提供了一种有效的解决方案，通过量子辅助机制确保系统执行的唯一时间延续性，填补了现有安全机制的空白。

Abstract: We introduce the Quantum State Continuity Problem (QSCP), a security objective orthogonal to identity authentication that captures whether a systems current execution is a legitimate continuation of a unique past execution. We show that classical and stateless quantum authentication mechanisms fail to enforce continuity and remain vulnerable to fork attacks. To address this gap, we propose the Quantum State Continuity Witness (QSCW), a minimal quantum-assisted primitive that enforces temporal linkage of execution through stateful quantum evolution and cumulative auditing. Using a GHZ-based toy instantiation and extensive simulation, we demonstrate that temporal enforcement suppresses fork attacks with exponential decay in success probability, while remaining robust to noise and system parameters. Our results highlight execution continuity as a distinct and underexplored dimension of system security.

</details>


### [166] [Entanglement dynamics of multi-fluxonium-qubits under Non-Markovian TLS noise](https://arxiv.org/abs/2601.00884)
*Chenghong Ji,Chaoying Zhao*

Main category: quant-ph

TL;DR: 针对Fluxonium量子比特中的非马尔可夫TLS噪声，提出了一种优化的动态解耦序列，通过优化脉冲位置最小化噪声功率谱与洛伦兹形状的重叠，显著提升了纠缠门保真度。


<details>
  <summary>Details</summary>
Motivation: Fluxonium量子比特对由材料缺陷形成的两能级系统(TLS)噪声敏感，这种噪声具有显著的非马尔可夫特性，传统动态解耦无法有效抑制低频TLS噪声，限制了量子器件的纠缠门保真度。

Method: 基于Ornstein-Uhlenbeck过程，提出新型动态解耦序列，通过优化脉冲位置设计TLS定制化动态解耦协议，最小化噪声功率谱与洛伦兹形状的重叠，采用PMME一致框架建模非马尔可夫噪声下的纠缠动力学。

Result: 该动态解耦协议实现了更强的低频噪声抑制，显著延长了基于Bell态的保真度和纠缠时间，有效提高了NISQ量子器件中纠缠门的保真度。

Conclusion: 针对非马尔可夫TLS噪声的定制化动态解耦协议能够有效提升量子器件的纠缠门性能，为NISQ量子计算设备的噪声抑制提供了新方法。

Abstract: The research on open quantum systems is important for both quantum computing and quantum sensing. So far, we can only use the main equation to make an approximate description. The dynamics of a single Fluxonium qubit under Markovian environment satisfied Lindblad Master Equation. In experiments, pulse sequence dynamic decoupling (DD) can enhance the coherence of qubits and effectively suppress noise. Two Fluxonium qubits sensitive to two-level systems (TLS) noise. TLS formed by material defects results in noise with significant non-Markovian characteristics. The dynamics of non-Markovian noise satisfied the post Markov Master Equation (PMME). The TLS noise spectrum is mainly concentrated in low frequencies, so traditional DD cannot effectively suppress TLS noise. The relaxation and dephasing behavior with a complex dynamic characteristics. Based on Ornstein-Uhlenbeck process, we put forward a novel DD sequence and design a TLS-tailored dynamical decoupling protocol by optimizing pulse locations to minimize noise power spectral overlap with the Lorentzian shape. Using PMME-consistent framework, we can obtain a stronger low frequency suppression and significantly prolong both Bell-based fidelity and entanglement. We explore specific DD design and precise modeling of entanglement dynamics under non-Markovian TLS noise. Our dynamical decoupling protocol can effectively improve entanglement gates fidelity in NISQ quantum devices.

</details>


### [167] [Four-Photon Interference with a High-Efficiency Quantum Dot Source](https://arxiv.org/abs/2601.00966)
*Alistair J. Brash,Luke Brunswick,Mark R. Hogg,Catherine L. Phillips,Malwina A. Marczak,Timon L. Baltisberger,Sascha R. Valentin,Arne Ludwig,Richard J. Warburton*

Main category: quant-ph

TL;DR: 该研究通过结合高性能量子点光源与确定性解复用技术，首次实现了四光子Hong-Ou-Mandel干涉，观测到高达84.1%的干涉对比度，揭示了"深条纹"现象及其在量子计量学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 虽然双光子Hong-Ou-Mandel干涉可见度已成为单光子源的标准度量，但许多光学量子技术需要生成和操纵更大的光子态。由于效率限制，此前量子点基干涉无法在单个分束器上实现超过两个光子的聚束。

Method: 结合最先进的量子点光源与确定性解复用技术，实现了直接观测多达四个光子的量子干涉条纹。通过理论模型完全复现复杂的条纹结构，并进行Fisher信息分析评估相位灵敏度。

Result: 测量到高平均干涉对比度：双光子为93.0±0.1%，四光子为84.1±1.0%。发现"深条纹"现象，其最小值不受可区分光子的影响，使得四光子干涉的最大对比度对多光子发射高度敏感但对光子可区分性具有鲁棒性。

Conclusion: 该研究突破了量子点基干涉的规模限制，预测这些现象将扩展到更多光子的干涉，在多种光学量子技术中具有相关性。Fisher信息分析表明，该光源的干涉条纹可以表现出超越标准量子极限的相位灵敏度，展示了在量子计量学中的潜在应用。

Abstract: While two-photon Hong-Ou-Mandel interference visibility has become a standard metric for single-photon sources, many optical quantum technologies require the generation and manipulation of larger photonic states. To date, efficiency limitations have prevented scaling quantum dot-based interference to the coalescence of more than two photons at a single beamsplitter. We overcome this limitation by combining a state-of-the-art quantum dot source with deterministic demultiplexing, enabling the direct observation of quantum interference fringes arising from up to four photons. We measure high mean interference contrasts of $93.0 \pm 0.1~\%$ for two photons, and $84.1 \pm 1.0~\%$ for four photons, with the complex fringe structure fully reproduced by a theoretical model. These results reveal the existence of "deep fringes" whose minima are unaffected by distinguishable photons, rendering the maximum contrast of four-photon interference highly sensitive to multi-photon emission but robust against photon distinguishability. We predict that these phenomena will extend to interference of larger numbers of photons, with relevance across a range of potential optical quantum technologies. A Fisher information analysis demonstrates that interference fringes from our source can exhibit phase sensitivity beyond the standard quantum limit, illustrating potential applications in quantum metrology.

</details>


### [168] [Impersonating Quantum Secrets over Classical Channels](https://arxiv.org/abs/2601.01058)
*Luowen Qian,Mark Zhandry*

Main category: quant-ph

TL;DR: 量子纠缠方之间的经典通信存在窃听风险，窃听者最终能冒充任何一方。单向谜题是量子预共享秘密可重用认证方案的必要条件。量子货币方案若仅通过经典查询验证，则无法实现信息论安全。


<details>
  <summary>Details</summary>
Motivation: 研究量子通信中的安全基础问题，探索量子预共享秘密认证方案的安全性要求，以及量子货币方案验证的局限性，为量子密码学提供理论基础。

Method: 通过理论分析证明：1）窃听经典通信可导致身份冒充攻击；2）使用单向谜题不存在性假设分析攻击效率；3）将结果应用于量子货币方案，证明仅通过经典查询验证无法实现信息论安全。

Result: 1）单向谜题是可重用量子预共享秘密认证方案的必要条件；2）任何仅通过经典查询验证的量子货币方案都无法实现信息论安全，这推广了之前仅针对随机预言机的结果；3）量子货币的黑盒构造验证需要相干评估底层密码工具。

Conclusion: 量子通信安全需要单向谜题作为基础，量子货币方案若仅依赖经典查询验证则存在根本性安全限制，这对近量子设备的实际应用提出了挑战。

Abstract: We show that a simple eavesdropper listening in on classical communication between potentially entangled quantum parties will eventually be able to impersonate any of the parties. Furthermore, the attack is efficient if one-way puzzles do not exist. As a direct consequence, one-way puzzles are implied by reusable authentication schemes over classical channels with quantum pre-shared secrets that are potentially evolving.
  As an additional application, we show that any quantum money scheme that can be verified through only classical queries to any oracle cannot be information-theoretically secure. This significantly generalizes the prior work by Ananth, Hu, and Yuen (ASIACRYPT'23) where they showed the same but only for the specific case of random oracles. Therefore, verifying black-box constructions of quantum money inherently requires coherently evaluating the underlying cryptographic tools, which may be difficult for near-term quantum devices.

</details>


### [169] [Evidence for a two-dimensional quantum glass state at high temperatures](https://arxiv.org/abs/2601.01309)
*Aleksey Lunkin,Nicole S. Ticea,Shashwat Kumar,Connie Miao,Jaehong Choi,Mohammed Alghadeer,Ilya Drozdov,Dmitry Abanin,Amira Abbas,Rajeev Acharya,Laleh Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Ryan Babbush,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Majid Karimi,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Alexandre Bourassa,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,Michael Broughton,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Zijun Chen,Ben Chiaro,Liang-Ying Chih,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Paul Conner,Harold Cook,Rodrigo G. Cortiñas,William Courtney,Alexander L. Crook,Ben Curtin,Martin Damyanov,Sayan Das,Dripto M. Debroy,Sean Demura,Paul Donohoe,Andrew Dunsworth,Valerie Ehimhen,Alec Eickbusch,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Lara Faoro,Vinicius S. Ferreira,Marcos Flores,Leslie Burgos,Sam Fontes,Ebrahim Forati,Jeremiah Ford,Brooks Foxen,Masaya Fukami,Alan Wing Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Robert Geiger,William Giang,Dar Gilboa,James E. Goeders,Edward C. Gonzales,Raja Gosula,Stijn J. Graaf,Alejandro Dau,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Loïck Guevel,Tan Ha,Steve Habegger,Tanner Hadick,Ali Hadjikhani,Michael C. Hamilton,Monica Hansen,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Jeremy Hilton,Hsin-Yuan Huang,Mike Hucka,Christopher Hudspeth,Ashley Huff,William J. Huggins,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Cody Jones,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Dvir Kafri,Hui Kang,Kiseo Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Julian Kelly,Tanuj Khattar,Mostafa Khezri,Seon Kim,Paul V. Klimov,Can M. Knaut,Bryce Kobrin,Alexander N. Korotkov,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Emma Leavell,Justin Ledford,Joonho Lee,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily Li,Wing Yan Li,Ming Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Laura Lorenzo,Erik Lucero,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Aniket Maiti,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Das,Dmitri Maslov,Melvin Mathews,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Anthony Megrant,Kevin C. Miao,Zlatko K. Minev,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Logan Oas,William D. Oliver,Raymond Orosco,Kristoffer Ottosson,Alice Pagano,Agustin Paolo,Sherman Peek,David Peterson,Alex Pizzuto,Elias Portoles,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Ganesh Ramachandran,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Gabrielle Roberts,Roberto Rodriguez,Emma Ropes,Lucia B. Rose,Eliott Rosenberg,Emma Rosenfeld,Dario Rosenstock,Elizabeth Rossi,David A. Rower,Robert Salazar,Kannan Sankaragomathi,Murat Can Sarihan,Kevin J. Satzinger,Max Schaefer,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Vladimir Shvarts,Volodymyr Sivak,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Aaron Szasz,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Benjamin Villalonga,Catherine Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Brayden Ware,James D. Watson,Yonghua Wei,Travis Weidel,Theodore White,Kristi Wong,Bryan W. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Noureldin Yosri,Elliot Young,Grayson Young,Adam Zalcman,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Sergio Boixo,Hartmut Neven,Vadim Smelyanskiy,Trond I. Andersen,Pedram Roushan,Mikhail V. Feigelman,Lev B. Ioffe*

Main category: quant-ph

TL;DR: 该研究使用超导量子比特阵列，在二维系统中观察到了从遍历相到非遍历相的转变，发现了一个具有玻璃特性的中间非遍历相。


<details>
  <summary>Details</summary>
Motivation: 量子多体系统中的无序可以驱动遍历相和非遍历相之间的转变，但这些转变的性质甚至存在性一直存在激烈争议。研究者希望通过实验探索二维系统中是否存在这样的相变。

Method: 使用二维超导量子比特阵列研究有限温度下的相互作用自旋模型，在无序环境中同时追踪实空间和希尔伯特空间的动力学行为。

Result: 在广泛的无序范围内观察到了具有玻璃特性的中间非遍历相：物理可观测量呈现广泛分布，部分自由度被有效冻结；希尔伯特空间返回概率显示缓慢的幂律衰减；检测到有限的爱德华兹-安德森序参数的出现和自旋扩散的消失；在较低无序度下，自旋输运持续存在且具有非零扩散系数。

Conclusion: 研究结果表明，在二维系统中确实存在从遍历相到非遍历相的转变，这为理解量子多体系统中的无序诱导相变提供了实验证据。

Abstract: Disorder in quantum many-body systems can drive transitions between ergodic and non-ergodic phases, yet the nature--and even the existence--of these transitions remains intensely debated. Using a two-dimensional array of superconducting qubits, we study an interacting spin model at finite temperature in a disordered landscape, tracking dynamics both in real space and in Hilbert space. Over a broad disorder range, we observe an intermediate non-ergodic regime with glass-like characteristics: physical observables become broadly distributed and some, but not all, degrees of freedom are effectively frozen. The Hilbert-space return probability shows slow power-law decay, consistent with finite-temperature quantum glassiness. In the same regime, we detect the onset of a finite Edwards-Anderson order parameter and the disappearance of spin diffusion. By contrast, at lower disorder, spin transport persists with a nonzero diffusion coefficient. Our results show that there is a transition out of the ergodic phase in two-dimensional systems.

</details>


### [170] [Molchanov's Formula and Quantum Walks: A Probabilistic Approach](https://arxiv.org/abs/2601.01071)
*Hoang Vu*

Main category: quant-ph

TL;DR: 该论文通过推导连续时间和离散时间量子行走的概率表示，建立了量子动力学与经典动力学之间的稳健联系。


<details>
  <summary>Details</summary>
Motivation: 建立量子动力学与经典动力学之间的连接，为研究量子系统提供新的分析途径，通过经典随机过程来研究量子系统。

Method: 首先将Molchanov公式（原用于多维整数格上薛定谔算子的研究）应用于连续时间量子行走，然后扩展该框架开发概率方法来表示无限整数线上的离散时间量子行走，克服了直接应用Molchanov公式的局部性约束。

Result: 通过Hadamard行走的基准分析，经验证实了该概率表示的有效性，显示出与传统幺正演化高度一致。结果表明该概率视角为学习多维量子行走提供了强大替代方案。

Conclusion: 该概率表示方法为通过经典随机过程研究量子系统提供了新的分析途径，为量子行走研究提供了强大的替代框架。

Abstract: This paper establishes a robust link between quantum dynamics and classical ones by deriving probabilistic representation for both continuous time and discrete time quantum walks. We first adapt Molchanov formula, originally employed in the study of Schrodinger operators on multidimensional integer lattice, to characterize the evolution of continuous time quantum walks. Extending this framework, we develop a probabilistic method to represent discrete time quantum walks on an infinite integer line, bypassing the locality constraints that typically inhibit direct application of Molchanov formula. The validity of our representation is empirically confirmed through a benchmark analysis of the Hadamard walk, demonstrating high fidelity with traditional unitary evolution. Our results suggest that this probabilistic lens offer a powerful alternative for learning multidimensional quantum walks and provides new analytical pathways for investigating quantum systems via classical stochastic processes.

</details>


### [171] [Bond Additivity and Persistent Geometric Imprints of Entanglement in Quantum Thermalization](https://arxiv.org/abs/2601.01327)
*Chun-Yue Zhang,Shi-Xin Zhang,Zi-Xiang Li*

Main category: quant-ph

TL;DR: 该论文提出了一种名为"多二分划纠缠层析"的新框架，通过分析所有可能二分划的纠缠熵，揭示了量子多体系统中纠缠的精细几何结构，并发现了"键可加定律"。


<details>
  <summary>Details</summary>
Motivation: 量子多体系统中纠缠的复杂结构表征是一个核心挑战，传统测量方法往往掩盖了底层的几何细节。需要开发新工具来揭示纠缠的精细几何结构。

Method: 提出了多二分划纠缠层析框架，通过分析所有可能二分划的纠缠熵，发现了"键可加定律"：纠缠熵可以精确分解为体积极律基线和几何修正项之和，后者由不同范围的交叉键的局部贡献组成。

Result: 该方法将复杂纠缠景观提炼为一组纠缠键张力{ω_j}，作为相互作用局域性的定量指纹。应用于哈密顿动力学、随机量子电路和Floquet动力学时，发现哈密顿热化态保留了显著非零ω1的持久几何印记，而随机量子电路和Floquet动力学则完全擦除了这种结构。

Conclusion: 多二分划纠缠层析为量子多体系统中量子信息的几何结构提供了一个通用工具箱，能够区分不同的热化机制，并揭示纠缠的精细几何特征。

Abstract: Characterizing the intricate structure of entanglement in quantum many-body systems remains a central challenge, as standard measures often obscure underlying geometric details. In this Letter, we introduce a powerful framework, termed multi-bipartition entanglement tomography, which probes the fine structure of entanglement across an exhaustive ensemble of distinct bipartitions. Our cornerstone is the discovery of a ``bond-additive law'', which reveals that the entanglement entropy can be precisely decomposed into a bulk volume-law baseline plus a geometric correction formed by a sum of local contributions from crossed bonds of varying ranges. This law distills complex entanglement landscapes into a concise set of entanglement bond tensions $\{ω_j\}$, serving as a quantitative fingerprint of interaction locality. By applying this tomography to Hamiltonian dynamics, random quantum circuits, and Floquet dynamics, we resolve a fundamental distinction between thermalization mechanisms: Hamiltonian thermalized states retain a persistent geometric imprint characterized by a significantly non-zero $ω_1$, while this structure is completely erased in random quantum circuit and Floquet dynamics. Our work establishes multi-bipartition entanglement tomography as a versatile toolbox for the geometric structure of quantum information in many-body systems.

</details>


### [172] [Single-Step Hybrid CV-DV Transfer of Multipartite W States Using Cat-State Qubits](https://arxiv.org/abs/2601.01078)
*Muhammad Nehal Khan,Sumrah Hussain*

Main category: quant-ph

TL;DR: 提出了一种确定性混合连续变量-离散变量方案，用于在电路QED架构中单步传输光子薛定谔猫态量子比特编码的n量子比特W态


<details>
  <summary>Details</summary>
Motivation: 需要实现多体纠缠态的高效传输，同时抑制退相干效应，利用当前电路QED技术实现可扩展的混合CV-DV纠缠传输

Method: 采用确定性混合CV-DV方案，逻辑量子比特编码在玻色子模式的奇偶猫态中，通过单个超导磁通量子三能级系统在色散区介导谐振器对之间的有效拉曼型相互作用

Result: 数值模拟基于完整的Lindblad主方程，包括实际腔耗散、量子三能级系统弛豫和退相干以及腔间串扰，显示三量子比特猫态W态传输的最大保真度约为0.92

Conclusion: 该方案证明了利用当前电路QED技术实现可扩展混合CV-DV纠缠传输的可行性，能够通过单次集体操作相干传输多体W态，同时避免激发更高原子能级从而强烈抑制退相干

Abstract: We propose a deterministic hybrid continuous-variable-discrete-variable (CV-DV) scheme for the single-step transfer of an $n$-qubit W state encoded in photonic Schr$\ddot{o}$dinger cat-state qubits within a circuit QED architecture. Logical qubits are encoded in even- and odd-parity cat states of bosonic modes, while effective Raman-type interactions between resonator pairs are mediated by a single superconducting flux qutrit operating in the dispersive regime. The protocol coherently transfers the multipartite W state in a single collective operation without populating higher excited atomic levels, thereby strongly suppressing decoherence. Numerical simulations based on the full Lindblad master equation, including realistic cavity dissipation, qutrit relaxation and dephasing, and inter-cavity crosstalk, show that a three-qubit cat-state W state can be transferred with a maximum fidelity of approximately $0.92$. These results demonstrate the feasibility of scalable hybrid CV-DV entanglement transfer using current circuit QED technology.

</details>


### [173] [Quantum optimisation applied to the Quadratic Assignment Problem](https://arxiv.org/abs/2601.01104)
*Andrew Freeland,Jingbo Wang*

Main category: quant-ph

TL;DR: 本文研究了新兴的非变分量子行走优化算法(NV-QWOA)在解决小型二次分配问题(QAP)实例中的性能表现，并与经典启发式算法及量子基准算法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 研究的动机源于经典精确方法和当前量子算法的局限性。变分量子算法(VQAs)虽然被广泛研究，但存在参数调优成本高和梯度消失问题，阻碍了收敛。通过采用非变分方法，本研究探索了一种可能更高效、可扩展的量子组合优化策略。

Method: 将NV-QWOA与经典启发式算法(最大最小蚂蚁系统和贪婪局部搜索)以及量子基准算法(Grover量子搜索算法)进行对比。使用两种指标评估性能：目标函数评估次数和算法迭代次数，测试范围涵盖5到10个设施的QAP实例。

Result: 研究结果提供了经典和量子框架之间的直接比较分析，描述了NV-QWOA的平均性能表现。发现突出了量子行走在复杂组合问题中的实际效用。

Conclusion: 本研究为量子行走在组合优化中的应用提供了实证基础，建立了未来量子优化算法发展的基础，展示了非变分量子方法在解决组合优化问题中的潜力。

Abstract: This paper investigates the performance of the emerging non-variational Quantum Walk-based Optimisation Algorithm (NV-QWOA) for solving small instances of the Quadratic Assignment Problem (QAP). NV-QWOA is benchmarked against classical heuristics, the MaxMin Ant System (MMAS) and Greedy Local Search (GLS), as well as the Grover quantum search algorithm, which serves as a quantum baseline. Performance is evaluated using two metrics: the number of objective function evaluations and the number of algorithm iterations required to consistently reach optimal or near optimal solutions across QAP instances with 5 to 10 facilities. The motivation for this study stems from limitations of both classical exact methods and current quantum algorithms. Variational Quantum Algorithms (VQAs), such as QAOA and VQE, while widely studied, suffer from costly parameter tuning and barren plateaus that hinder convergence. By adopting a non-variational approach, this work explores a potentially more efficient and scalable quantum strategy for combinatorial optimisation. The results provide a direct comparative analysis between classical and quantum frameworks, characterising the average case performance of NV-QWOA. Our findings highlight the practical utility of quantum walks for complex combinatorial problems and establish a foundation for future quantum optimisation algorithms.

</details>


### [174] [Non-Markovian and Thermodynamic Signatures in the Classicality Assessment via Kolmogorov Consistency](https://arxiv.org/abs/2601.01122)
*Arghya Maity,Ahana Ghoshal,Kelvin Onggadinata,Teck Seng Koh*

Main category: quant-ph

TL;DR: 本文建立了Kolmogorov一致性条件违反与开放量子系统非马尔可夫性之间的直接联系，揭示了量子非经典性在信息论、热力学和时间相关性方面的统一框架。


<details>
  <summary>Details</summary>
Motivation: Kolmogorov一致性条件（KCC）定义了经典与量子动力学之间的统计边界，其违反标志着经典马尔可夫描述在时间相关性上的失效。本研究旨在建立KCC违反与开放量子动力学中非马尔可夫性的直接联系，并探索量子非经典性在信息论和热力学中的表现。

Method: 在通用的两能级开放量子系统框架内，建立KCC违反程度与关键信息论和热力学量之间的定量联系，包括互信息、法诺因子、热交换和熵产生率。同时建立KCC违反与Leggett-Garg不等式、Kirkwood-Dirac准分布负性之间的形式对应关系。

Result: 成功建立了KCC违反与非马尔可夫性的直接解析联系，揭示了记忆效应如何表现为经典概率一致性的偏离。量化了KCC违反与信息论、热力学量的关系，为时间量子相关性提供了热力学解释。发现了KCC违反、Leggett-Garg不等式和Kirkwood-Dirac准分布负性作为时间量子非经典性互补见证者的形式对应关系。

Conclusion: 研究结果为开放量子系统中量子非经典性的信息论、热力学和时间指标提供了一个统一框架，将KCC违反、非马尔可夫性、信息论量和热力学量联系起来，深化了对量子非经典性在多物理层面表现的理解。

Abstract: The Kolmogorov consistency condition (KCC) defines the statistical boundary between classical and quantum dynamics. Its violation signifies the breakdown of a classical Markov description of temporal correlations. In this work, we establish a direct analytical connection between KCC violation and non-Markovianity in open quantum dynamics, revealing how memory effects manifest as departures from classical probabilistic consistency. Within a generic two-level open quantum system framework, we establish quantitative connections between the magnitude of KCC violation and key information-theoretic and thermodynamic quantities, such as mutual information, the Fano factor, heat exchange, and entropy production rate, thereby enabling a thermodynamic interpretation of temporal quantum correlations. Furthermore, we uncover formal correspondences between KCC violation, the Leggett-Garg inequality, and the negativity of the Kirkwood-Dirac quasi-distribution, identifying them as complementary witnesses of temporal quantum non-classicality. Our results thus provide a unified framework linking information-theoretic, thermodynamic, and temporal indicators of quantumness in open quantum systems.

</details>


### [175] [The Completeness of Eigenstates in Quantum Mechanics](https://arxiv.org/abs/2601.01136)
*Guoping Zhang*

Main category: quant-ph

TL;DR: 该论文研究了量子力学中本征态完备性的证明方法，根据势函数在无穷远处的极限将完备性证明分为八种情况，提供了理论证明或数值模拟，并提出了自由态正交归一化的定义和归一化系数的解。


<details>
  <summary>Details</summary>
Motivation: 研究量子力学中本征态完备性的证明问题，特别是针对不同势函数在无穷远处极限情况下的完备性证明，旨在提供系统化的证明框架和方法。

Method: 根据势函数在无穷远处的极限将完备性证明分为八种情况；提出自由态正交归一化的定义和归一化系数的解；定义连续能量本征值的谱函数；将谱函数作为展开函数的原始积分变量。

Result: 为八种不同势函数情况提供了理论证明或数值模拟；建立了自由态正交归一化的系统方法；通过谱函数将测量概率振幅与展开函数的关系赋予了坐标-动量变换的物理意义。

Conclusion: 该研究系统化了量子力学本征态完备性的证明方法，提供了针对不同势函数情况的完整证明框架，并通过谱函数的引入为展开函数赋予了更清晰的物理意义，简化并具体化了完备性证明过程。

Abstract: We delineate the scope of research on the completeness of eigenstates in quantum mechanics. Based on the limit of the potential function at infinity, the proof of completeness is divided into eight cases, and theoretical proofs or numerical simulations are provided for each case. We present the definition of orthonormalization for general free states and the solution to the normalization coefficients, as well as a general set of initial states, which simplifies and concretizes the proof of completeness. Additionally, we define the spectral function for continuous energy eigenvalues. By taking the spectral function as the original integral variable of the expansion function, the relationship between the measured probability amplitude and the expansion function is endowed with the physical meaning of coordinate-momentum transformation.

</details>


### [176] [Constant Depth Digital-Analog Counterdiabatic Quantum Computing](https://arxiv.org/abs/2601.01154)
*Balaganchi A. Bhargava,Shubham Kumar,Anne-Maria Visuri,Paolo A. Erdman,Enrique Solano,Narendra N. Hegade*

Main category: quant-ph

TL;DR: 提出一种数字-模拟量子计算框架，通过恒定电路深度实现反绝热协议，用于当前量子硬件上的快速高效量子态制备。


<details>
  <summary>Details</summary>
Motivation: 反绝热协议可以抑制有限时间绝热演化中的非绝热激发，但实际应用受到所需哈密顿量的非局域结构和全数字实现的资源开销限制。

Method: 利用交换子乘积公式在数字-模拟设置中高效实现反绝热项的代数结构，通过原生多量子比特模拟相互作用增强局部单量子比特旋转，实现高阶反绝热协议。

Result: 该方法对二维自旋模型进行了演示，并分析了相关的近似误差，表明对于任何固定截断阶数，实现只需要恒定数量的模拟块，与系统尺寸无关。

Conclusion: 数字-模拟量子计算为反绝热协议和相关量子控制原语提供了全新的资源缩放特性，对当前量子设备上的量子模拟、优化和算法态制备有直接意义。

Abstract: We introduce a digital-analog quantum computing framework that enables counterdiabatic protocols to be implemented at constant circuit depth, allowing fast and resource-efficient quantum state preparation on current quantum hardware. Counterdiabatic protocols suppress diabatic excitations in finite-time adiabatic evolution, but their practical application is limited by the non-local structure of the required Hamiltonians and the resource overhead of fully digital implementations. Counterdiabatic terms can be expressed as truncated expansions of nested commutators of the adiabatic Hamiltonian and its parametric derivative. Here, we show how this algebraic structure can be efficiently realized in a digital-analog setting using commutator product formulas. Using native multi-qubit analog interactions augmented by local single-qubit rotations, this approach enables higher-order counterdiabatic protocols whose implementation requires a constant number of analog blocks for any fixed truncation order, independent of system size. We demonstrate the method for two-dimensional spin models and analyze the associated approximation errors. These results show that digital-analog quantum computing enables a qualitatively new resource scaling for counterdiabatic protocols and related quantum control primitives, with direct implications for quantum simulation, optimization, and algorithmic state preparation on current quantum devices.

</details>


### [177] [Harnessing Environmental Memory with Reinforcement Learning in Open Quantum Systems](https://arxiv.org/abs/2601.01252)
*Safae Gaidi,Abdallah Slaoui,Mohammed EL Falaki,Amine Jaouadi*

Main category: quant-ph

TL;DR: 本文提出了一种基于强化学习的框架，用于增强开放量子系统中的非马尔可夫记忆效应，通过训练PPO和SAC智能体来放大信息回流，相比传统最优控制理论获得了更持久的正迹距离增长和更高的非马尔可夫性积分。


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫记忆效应是开放量子系统中保持相干性和增强可控性的重要资源，但利用这些效应需要适应历史依赖动力学的策略。传统方法在利用这些效应方面存在局限。

Method: 引入强化学习框架，训练PPO（近端策略优化）和SAC（软演员-评论家）智能体，使用基于Breuer-Laine-Piilo度量的迹距离正时间导数的奖励函数，并与基于梯度的最优控制理论进行性能对比。

Result: 最优控制理论仅增强单个主导回流峰，而强化学习策略不仅拓宽了该峰，还在后续记忆窗口中激活了额外贡献，产生了更长时间的正迹距离增长。强化学习实现的非马尔可夫性积分显著超过最优控制理论。

Conclusion: 强化学习能够自然发现分布式回流策略，在工程化开放量子系统的记忆效应方面具有巨大潜力，特别是长时域、无模型学习能够有效利用非马尔可夫记忆效应。

Abstract: Non-Markovian memory effects in open quantum systems provide valuable resources for preserving coherence and enhancing controllability. However, exploiting them requires strategies adapted to history-dependent dynamics. We introduce a reinforcement-learning framework that autonomously learns to amplify information backflow in a driven two-level system coupled to a structured reservoir. Using a reward based on the positive time derivative of the trace distance associated with the Breuer-Laine-Piilo measure, we train PPO and SAC agents and benchmark their performance against gradient-based optimal control theory (OCT). While OCT enhances a single dominant backflow peak, RL policies broaden this revival and activate additional contributions in later memory windows, producing sustained positive trace-distance growth over a longer duration. Consequently, the integrated non-Markovianity achieved by RL substantially exceeds that obtained with OCT. These results demonstrate how long-horizon, model-free learning naturally uncovers distributed-backflow strategies and highlight the potential of reinforcement learning for engineering memory effects in open quantum systems.

</details>


### [178] [Simulating Wigner Localisation with the IBM Heron 2 Quantum Processor: A Proof-of-Principle Benchmarking Study](https://arxiv.org/abs/2601.01263)
*Airat Kiiamov,Dmitrii Tayurskii*

Main category: quant-ph

TL;DR: 该研究在IBM Heron 2量子处理器上实现了高保真度的数字量子模拟，重构了准一维电子系统中维格纳二聚体在15个相互作用区间的基态能量景观，相对误差低于7%，为使用超导量子硬件精确探测强关联物相提供了原理验证。


<details>
  <summary>Details</summary>
Motivation: 将原本为液氦上电子系统开发的基础实验模型移植到现代量子计算领域，通过数字量子模拟来探测强关联物相，验证超导量子硬件在模拟强关联系统方面的能力。

Method: 使用IBM Heron 2量子处理器的6量子比特段，将库仑相互作用哈密顿量映射到6量子比特环格上，通过数字量子模拟重构2电子维格纳二聚体在U∈[5,75]范围内15个相互作用区间的基态能量景观。

Result: 数字模拟准确捕捉了维格纳二聚体形成的能量最小化趋势，在强相互作用极限下相对误差低于7%，成功验证了超导量子硬件在模拟强关联系统方面的精度。

Conclusion: 该研究为使用超导量子硬件精确探测强关联物相提供了关键的原理验证，为超越经典极限的未来模拟建立了基准，展示了量子处理器在模拟强关联量子系统方面的潜力。

Abstract: We report on a high-fidelity digital quantum simulation of Wigner localisation in a quasi-one-dimensional (quasi-1D) electron system using a 6-qubit segment of the state-of-the-art \textbf{IBM\,Heron\,2} quantum processor. By mapping the Coulomb interaction Hamiltonian onto a 6-qubit ring lattice, we reconstruct the ground-state energy landscape for a 2-electron Wigner dimer across fifteen interaction regimes in the range $U \in [5, 75]$. This study serves as a rigorous \textbf{benchmarking} exercise, translating foundational experimental models originally developed for electrons on liquid helium into the domain of modern quantum computing. Leveraging the enhanced gate fidelity and tunable coupler architecture of the Heron 2, we demonstrate that the digital simulation accurately captures the energy minimisation trends associated with Wigner dimer formation, achieving a relative error below 7\% in the strong-interaction limit. Our results provide a crucial \textbf{proof-of-principle} validation for using superconducting quantum hardware to probe strongly correlated phases of matter with high precision, establishing a baseline for future simulations beyond the classical limit.

</details>


### [179] [Utilizing intermediate states in quantum annealing for multi-objective optimization](https://arxiv.org/abs/2601.01559)
*Keita Takahashi,Shu Tanaka*

Main category: quant-ph

TL;DR: 该研究探索在量子退火过程中获取中间量子状态，以解决多目标优化中线性加权和方法无法到达帕累托前沿非凸区域的限制。


<details>
  <summary>Details</summary>
Motivation: 传统多目标优化中的线性加权和方法存在固有局限性，无法到达帕累托前沿的非凸区域，需要新的方法来更全面地探索帕累托前沿。

Method: 通过物理实验（使用淬灭式读出）和数值模拟（假设理想的中途测量）来验证在量子退火过程中获取中间量子状态的方法。

Result: 两种方法一致显示明显的权衡关系：较早的测量时间能增强解的多样性，而较晚的测量时间确保收敛到非支配解。存在一个实用的折中时间点能平衡这两个指标。

Conclusion: 实际淬灭实验与理想模拟之间的定性一致表明，访问中间量子状态具有全面探索帕累托前沿的潜力。

Abstract: We investigate obtaining intermediate quantum states during the quantum annealing process to address the limitation of the linear weighted sum method in multi-objective optimization, which inherently fails to reach non-convex regions of the Pareto front. We validate this approach through physical experiments utilizing quench-based readout and numerical simulations assuming ideal mid-anneal measurements. Both methods consistently demonstrate a clear trade-off where earlier timing enhances diversity of the solutions, whereas later timing ensures convergence to non-dominated solutions. Notably, a practical compromise timing balances both metrics. The qualitative agreement between practical quench and ideal simulation indicates the potential of accessing the intermediate states for comprehensive Pareto front exploration.

</details>


### [180] [Thermodynamic analysis of autonomous quantum systems](https://arxiv.org/abs/2601.01272)
*Tiago F. F. Santos,Camille Latune*

Main category: quant-ph

TL;DR: 该论文将自主量子热力学框架应用于相互作用的量子系统实验场景，揭示了传统框架仅视为热交换的过程中实际存在基于粒子数反转、相干性生成/消耗以及非热性等机制的工作交换。


<details>
  <summary>Details</summary>
Motivation: 传统量子热力学框架将工作与外部控制产生的幺正变换相关联，将热与浴相互作用相关联。然而，这种框架无法充分描述自主量子系统（无外部控制，仅系统间相互作用）的热力学过程。本文旨在将新兴的自主热力学框架应用于实际的量子系统相互作用实验场景。

Method: 应用自主量子热力学框架分析常见的相互作用量子系统实验场景。该框架能够识别传统框架中仅被视为热交换的过程中的工作交换机制，包括粒子数反转、相干性生成/消耗以及非热性相关的非幺正机制。

Result: 自主框架揭示了传统框架中仅检测到热交换的情况下，实际上存在基于粒子数反转和相干性生成/消耗的工作交换机制，这些机制与ergotropy（功提取能力）密切相关。框架还识别了与非热性相关的真正非幺正工作交换机制。在半经典极限下，自主框架将所有能量交换识别为纯工作，但区分了局部工作和相互作用能量。

Conclusion: 自主量子热力学框架为量子领域的工作交换机制提供了精细化分析，是分析实际量子器件热力学过程的一致方法，揭示了传统框架的局限性并强调了量子特性在热力学过程中的重要作用。

Abstract: Traditional quantum thermodynamic frameworks associate work to energy exchanges induced by unitary transformations generated by external controls, and heat to energy exchanges induced by bath interaction. Recently, a framework was introduced aiming at extending the thermodynamic formalism to genuine quantum settings, also referred to as autonomous quantum systems: free from external controls, only quantum systems interacting with each other. In this paper, we apply such a thermodynamic framework to common experimental situations of interacting quantum systems. In situations where traditional frameworks detect only heat exchanges, the recent autonomous thermodynamic framework points at work exchanges based on two mechanisms: population inversion and coherence generation / consumption. Such mechanisms are well known in the literature for being related to work expenditure and extraction, in particular in relation with ergotropy, which emphasizes the relevance of the autonomous framework and the limitations of traditional ones. Furthermore, the autonomous framework also identifies a genuine non-unitary mechanism of work exchange related to athermality. %, also pointed out as a resource for work extraction. Finally, in the semi-classical limit, the autonomous framework identifies all energy exchanges as pure work, but distinguishes between local work and interaction energy.
  Our results show that the autonomous framework provides a refined analysis of work exchange mechanisms in the quantum realm and serves as a consistent approach to analyze thermodynamic processes in realistic quantum devices.

</details>


### [181] [Interpretation of Unfair Sampling in Quantum Annealing by Node Centrality](https://arxiv.org/abs/2601.01920)
*Naoki Maruyama,Masayuki Ohzeki*

Main category: quant-ph

TL;DR: 量子退火在采样简并基态时存在偏差，本文通过简并微扰理论分析发现采样概率与基态图邻接矩阵的特征向量中心性相关，并提出了两种提高采样公平性的方法。


<details>
  <summary>Details</summary>
Motivation: 在需要多个最优解的应用中，横向场量子退火（QA）已知会以强烈偏差的方式采样简并基态。尽管有大量经验观察，但仍不清楚QA优先采样简并基态的哪些特征以及原因。

Method: 使用简并微扰理论分析最终状态，基态图邻接矩阵自然出现，预测特征向量中心性（节点中心性之一）与这些状态的概率相关。在简并在一阶和二阶解除的玩具模型上验证预测，显示二阶权重编码局部势垒信息。

Result: 验证了特征向量中心性与采样概率相关的预测，发现二阶权重编码局部势垒信息，将采样公平性与局部能量景观的平坦性联系起来。

Conclusion: 该视角提出了两种实现公平采样的实用途径：促进图的连通性和减少中心性的异质性，并在高阶驱动器和minor-embedding变换中展示了与预测的一致性。

Abstract: In applications where multiple optimal solutions are needed, transverse-field quantum annealing (QA) is known to sample degenerate ground states in a strongly biased manner. Despite extensive empirical observations, it remains unclear which features of degenerate ground states are preferentially sampled and why by QA. Here we analyze the final states using degenerate perturbation theory to characterize the preference among them. In this analysis, the adjacency matrix of the graph composed by the ground states naturally emerges, and we can predict the eigenvector centralities (one of the node centralities) are related to the probabilities of these states. We verify this prediction on toy models where degeneracy is lifted at first and second order, and we show that second-order weights encode local barrier information, relating sampling fairness to the flatness of the local energy landscape. Finally, this perspective suggests two practical routes toward fair sampling -- promoting connectivity of the graph and reducing heterogeneity of centralities -- and we illustrate consistency with higher-order drivers and minor-embedding transformations.

</details>


### [182] [Efficient Calculation of the Maximal Rényi Divergence for a Matrix Product State via Generalized Eigenvalue Density Matrix Renormalization Group](https://arxiv.org/abs/2601.02122)
*Uri Levin,Noa Feldman,Moshe Goldstein*

Main category: quant-ph

TL;DR: 本文提出了一种基于最大Rényi散度的量子互信息计算方法，针对矩阵乘积态开发了广义特征值版本的密度矩阵重整化群算法，并在XXZ链上进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 量子互信息是理解多体物理中子系统间量子与经典关联的重要度量，但基于冯·诺依曼熵的传统计算方法需要指数级资源，存在"维度灾难"问题。基于Rényi散度的替代度量具有重要理论特性，但需要高效计算方法。

Method: 将最大Rényi散度转化为广义特征值问题，针对一维矩阵乘积态开发了广义特征值版本的密度矩阵重整化群算法，实现了高效计算。

Result: 在典型的XXZ链模型上进行基准测试，结果显示最大Rényi散度可能表现出与冯·诺依曼互信息不同的趋势，揭示了量子关联的新特性。

Conclusion: 提出的算法能够高效计算最大Rényi散度，为研究量子多体系统中的关联提供了新工具，并揭示了基于Rényi散度的互信息度量可能捕捉到传统方法无法探测的关联特性。

Abstract: The study of quantum and classical correlations between subsystems is fundamental to understanding many-body physics. In quantum information theory, the quantum mutual information, $I(A;B)$, is a measure of correlation between the subsystems $A,B$ in a quantum state, and is defined by the means of the von Neumann entropy: $I\left(A;B\right)=S\left(ρ_{A}\right)+S\left(ρ_{B}\right)-S\left(ρ_{AB}\right)$. However, such a computation requires an exponential amount of resources. This is a defining feature of quantum systems, the infamous ``curse of dimensionality'' . Other measures, which are based on Rényi divergences instead of von Neumann entropy, were suggested as alternatives in a recent paper showing them to possess important theoretical features, and making them leading candidates as mutual information measures. In this work, we concentrate on the maximal Rényi divergence. This measure can be shown to be the solution of a generalized eigenvalue problem. To calculate it efficiently for a 1D state represented as a matrix product state, we develop a generalized eigenvalue version of the density matrix renormalization group algorithm. We benchmark our method for the paradigmatic XXZ chain, and show that the maximal Rényi divergence may exhibit different trends than the von Neumann mutual information.

</details>


### [183] [Assessing the entanglement of three coupled harmonic oscillators](https://arxiv.org/abs/2601.01292)
*Ayoub Ghaba,Radouan Hab Arrih,Elhoussine Atmani,Abderrahim El Allati,Abdallah Slaoui*

Main category: quant-ph

TL;DR: 该论文提出了一种几何对角化方法来分析三个耦合谐振子的量子纠缠，通过约束欧拉角减少自由度，推导了线性熵和纯度的解析表达式，揭示了激发水平和混合角对纠缠的影响。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是多体系统中理解关联的关键现象，但对于耦合三体谐振子的解析结果仍然稀缺。本文旨在填补这一空白，通过引入新的分析方法来理解三个耦合谐振子中的纠缠特性。

Method: 引入几何对角化方法，通过约束欧拉角减少纠缠分析的自由度。在Wigner函数框架下，推导了线性熵和纯度在三种二分划$(x|yz)$、$(y|xz)$和$(xy|z)$下的解析表达式。

Result: 结果表明：1) 任何谐振子的激发都会增强系统中关联的重新分布；2) 混合角$θ$控制纠缠强度，范围从可分离性到最大关联；3) 发现了对称关系$S_{Ly}[(n,m,l),θ]=S_{Lz}[(n,m,l),-θ]$以及$(x|yz)$中的内在对称性。

Conclusion: 阐明了激发水平和混合角如何在三个耦合谐振子中创造和增强纠缠，为理解多体系统中的量子关联提供了新的解析工具和见解。

Abstract: Quantum entanglement serves as a key phenomenon in understanding correlations in many-body systems, but analytical results remain scarce for coupled three-body oscillators. In this work, we address this gap by introducing a geometrical diagonalization approach that constrains Euler angles, thereby reducing the degrees of freedom in the entanglement analysis. It consists of deriving analytical expressions for linear entropy and purity under the bipartitions $(x|yz)$, $(y|xz)$, and $(xy|z)$ using the Wigner function framework. Our results indicate that excitations in any oscillator basically enhance the redistribution of correlations across the system. The mixing angle $θ$ governs entanglement intensity, ranging from separability to maximal correlation. Moreover, we reveal the symmetry relations, notably $S_{Ly}[(n,m,l),θ]=S_{Lz}[(n,m,l),-θ]$ and an intrinsic symmetry within $(x|yz)$. Hence, we clarify how excitation levels and mixing angles create and enhance entanglement in the three coupled harmonic oscillators.

</details>


### [184] [Simulating Non-Markovian Dynamics in Open Quantum Systems](https://arxiv.org/abs/2601.02160)
*Meng Xu,Vasilii Vadimov,J. T. Stockburger,J. Ankerhold*

Main category: quant-ph

TL;DR: 该论文系统综述了开放量子系统动力学的各种模拟方法，通过统一框架分析不同方法的联系、优缺点，旨在解决该领域方法碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 量子技术实验进展需要高精度、高效的计算模拟方法，但现有方法（如层次运动方程、Lindblad伪模公式、链映射方法等）来源不同领域，导致碎片化，阻碍了跨领域应用和复杂系统问题的解决。

Method: 采用统一框架，在扩展状态空间（包含有效储层模式）中系统分析不同方法，阐明它们之间的物理联系和数学关系。

Result: 通过统一框架成功关联了不同模拟方法，揭示了它们的物理解释、相互联系和适用范围，为理解现有方法提供了全面视角。

Conclusion: 统一框架有助于催化该领域的进一步进展，促进不同方法之间的协同应用，为复杂开放量子系统的模拟提供了系统化的理论基础。

Abstract: Recent advances in quantum technologies and related experiments have created a need for highly accurate, versatile, and computationally efficient simulation techniques for the dynamics of open quantum systems. Long-lived correlation effects (non-Markovianity), system-environment hybridization, and the necessity for accuracy beyond the Born-Markov approximation form particular challenges. Approaches to meet these challenges have been introduced, originating from different fields, such as hierarchical equations of motion, Lindblad-pseudomode formulas, chain-mapping approaches, quantum Brownian motion master equations, stochastic unravelings, and refined quantum master equations. This diversity, while indicative of the field's relevance, has inadvertently led to a fragmentation that hinders cohesive advances and their effective cross-community application to current problems for complex systems. How are different approaches related to each other? What are their strengths and limitations? Here we give a systematic overview and concise discussion addressing these questions. We make use of a unified framework which very conveniently allows to link different schemes and, this way, may also catalyze further progress. In line with the state of the art, this framework is formulated not in a fully reduced space of the system but in an extended state space which in a minimal fashion includes effective reservoir modes. This in turn offers a comprehensive understanding of existing methods, elucidating their physical interpretations, interconnections, and applicability.

</details>


### [185] [Einstein-Podolsky-Rosen Steering in Three Coupled Harmonic Oscillators](https://arxiv.org/abs/2601.01307)
*Ayoub Ghaba,Radouan Hab Arrih,Elhoussine Atmani,Abdallah Slaoui*

Main category: quant-ph

TL;DR: 该研究通过几何对角化方法分析三体耦合谐振子系统的量子导引现象，发现激发态显著增强量子导引，而基态无导引相关性；导引的方向性和拓扑结构由激发的空间分布而非大小决定。


<details>
  <summary>Details</summary>
Motivation: 量子导引是量子力学中最引人入胜的现象之一，对理解多体系统相关性至关重要。尽管其重要性，但针对耦合三体谐振子的解析结果仍然稀缺，因此需要深入研究这一现象。

Method: 采用几何对角化方法，减少与系统导引性质相关的自由度。使用Wigner函数框架推导所有可能方向上的量子导引解析表达式，因为Wigner函数提供了系统量子态的完整描述。

Result: 激发显著增强整个系统的量子导引，而基态(0,0,0)不表现出可导引相关性。导引的方向性和拓扑结构由激发的空间分布而非大小决定。在等效激发条件下，振荡器x、y、z之间表现出对称的导引行为，可用数学关系式描述。

Conclusion: 阐明了激发水平和混合角如何在三耦合谐振子中产生和增强量子导引，为理解多体量子系统中的相关性提供了新的解析见解。

Abstract: Quantum steering is one of the most intriguing phenomena in quantum mechanics and is essential for understanding correlations in multi-body systems. Despite its importance, analytical results for coupled three-body oscillators remain scarce. In this work, we investigate this phenomenon through a geometrical diagonalization approach, which reduces the degrees of freedom associated with the system's steering properties. Specifically, we derive analytical expressions for quantum steering in all possible directions using the Wigner function framework, as it provides a complete description of the system's quantum state. Our results indicate that excitations significantly enhance quantum steering across the system; this stands in contrast to the ground state $(0,0,0)$, which exhibits no steerable correlations. Furthermore, both the directionality and topology of these correlations are governed by the spatial distribution of the excitations rather than their magnitude. We also observe symmetric steering behavior between oscillators $x$, $y$, and $z$ under equivalent excitation conditions, which can be formalized as $S^{(n,m,l)}_{x\to z}(θ)=S^{(n,m,l)}_{x\to y}(-θ),\quad S^{(n,m,l)}_{z\to x}(θ)=S^{(n,m,l)}_{y\to x}(-θ)$, and $S^{(n,m,l)}_{y\to z}(θ)=S^{(n,m,l)}_{z\to y}(-θ)$. Therefore, we elucidate how excitation levels and mixing angles generate and enhance steering in three coupled harmonic oscillators.

</details>


### [186] [Quantum Kaczmarz Algorithm for Solving Linear Algebraic Equations](https://arxiv.org/abs/2601.01342)
*Nhat A. Nghiem,Tuan K. Do,Trung V. Phan*

Main category: quant-ph

TL;DR: 提出基于Kaczmarz方法的量子线性系统求解算法，不依赖矩阵条目查询oracle，在特定条件下实现指数级电路深度改进。


<details>
  <summary>Details</summary>
Motivation: 现有量子线性求解器通常需要oracle访问矩阵条目，这在实际应用中构成瓶颈。Kaczmarz方法因其简单性和低内存成本在经典计算中广泛应用，作者希望将其优势引入量子计算。

Method: 基于Kaczmarz方法设计量子算法，每次迭代强制满足一个方程。当系统秩较小且矩阵行结构适当时，算法复杂度与稀疏度s无关；对于任意结构行，使用额外辅助量子比特实现对数级深度增长。

Result: 在秩较小且行结构适当时，电路复杂度为O(1/ε·log m)，不依赖稀疏度s，可能也不依赖条件数κ。对于任意结构行，电路深度为O(1/ε·log s)，使用O(s)辅助量子比特。当s=O(log m)时，相比现有算法实现指数级深度改进。

Conclusion: 该量子Kaczmarz方法避免了oracle访问瓶颈，在特定条件下显著改进了量子线性求解器的性能，特别是在稀疏度增长时能实现指数级优势，为实际量子线性系统求解提供了新途径。

Abstract: We introduce a quantum linear system solving algorithm based on the Kaczmarz method, a widely used workhorse for large linear systems and least-squares problems that updates the solution by enforcing one equation at a time. Its simplicity and low memory cost make it a practical choice across data regression, tomographic reconstruction, and optimization. In contrast to many existing quantum linear solvers, our method does not rely on oracle access to query entries, relaxing a key practicality bottleneck. In particular, when the rank of the system of interest is sufficiently small and the rows of the matrix of interest admit an appropriate structure, we achieve circuit complexity $\mathcal{O}\left(\frac{1}{\varepsilon}\log m\right)$, where $m$ is the number of variables and $\varepsilon$ is the target precision, without dependence on the sparsity $s$, and could possibly be without explicit dependence on condition number $κ$. This shows a significant improvement over previous quantum linear solvers where the dependence on $κ,s$ is at least linear. At the same time, when the rows have an arbitrary structure and have at most $s$ nonzero entries, we obtain the circuit depth $\mathcal{O}\left(\frac{1}{\varepsilon}\log s\right)$ using extra $\mathcal{O}(s)$ ancilla qubits, so the depth grows only logarithmically with sparsity $s$. When the sparsity $s$ grows as $\mathcal{O}(\log m)$, then our method can achieve an exponential improvement with respect to circuit depth compared to existing quantum algorithms, while using (asymptotically) the same amount of qubits.

</details>


### [187] [Noise-Resilient Heisenberg-limited Quantum Sensing via Indefinite-Causal-Order Error Correction](https://arxiv.org/abs/2601.01404)
*Hang Xu,Xiaoyang Deng,Ze Zheng,Tailong Xiao,Guihua Zeng*

Main category: quant-ph

TL;DR: 本文提出了一种基于不定因果序的量子纠错协议，首次将不定因果序应用于量子纠错，通过相干地安排辅助控制和噪声演化，实现了实时错误检测与纠正，恢复了海森堡极限标度。


<details>
  <summary>Details</summary>
Motivation: 量子资源理论上可以实现海森堡极限传感，但实际噪声设备中通常无法达到该标度。传统量子纠错在量子传感中存在诸多限制，包括需要先验噪声表征、严格的信号-噪声兼容条件以及基于测量的全局控制等。

Method: 引入基于不定因果序的量子纠错协议，通过相干地将辅助控制和噪声演化置于不定因果序中，利用非交换干涉使辅助系统能够实时检测和纠正错误，避免了传统量子纠错的限制。

Result: 该协议在单噪声和多噪声场景下得到严格建立，并在单量子比特、多体系统和连续变量平台上展示了性能。还识别了可以通过纯幺正控制实现纠错而不需要测量的工作区域。

Conclusion: 不定因果序是计量量子纠错的有力资源，为噪声鲁棒的量子信息处理提供了一个广泛适用的框架，能够恢复海森堡极限标度并克服传统量子纠错的局限性。

Abstract: Quantum resources can, in principle, enable Heisenberg-limited (HL) sensing, yet no-go theorems imply that HL scaling is generically unattainable in realistic noisy devices. While quantum error correction (QEC) can suppress noise, its use in quantum sensing is constrained by stringent requirements, including prior noise characterization, restrictive signal-noise compatibility conditions, and measurement-based syndrome extraction with global control. Here we introduce an ICO-based QEC protocol, providing the first application of indefinite causal order (ICO) to QEC. By coherently placing auxiliary controls and noisy evolution in an indefinite causal order, the resulting noncommutative interference enables an auxiliary system to herald and correct errors in real time, thereby circumventing the limitations of conventional QEC and restoring HL scaling. We rigorously establish the protocol for single- and multi-noise scenarios and demonstrate its performance in single-qubit, many-body, and continuous-variable platforms. We further identify regimes in which error correction can be implemented entirely by unitary control, without measurements. Our results reveal ICO as a powerful resource for metrological QEC and provide a broadly applicable framework for noise-resilient quantum information processing.

</details>


### [188] [The Equivalence between Hardy-type paradox and Logical Contextuality](https://arxiv.org/abs/2601.01445)
*Songyi Liu,Yongjun Wang,Baoshan Wang,Chang He,Yunyi Jia*

Main category: quant-ph

TL;DR: 本文提出了一种统一的逻辑Hardy型悖论形式化方法，证明了对于任何有限场景，逻辑Hardy型悖论的存在等价于逻辑上下文性，特别地，强上下文性等价于成功概率SP=1的逻辑Hardy型悖论。


<details>
  <summary>Details</summary>
Motivation: Hardy型悖论提供了优雅的、无需不等式的量子上下文性证明。然而，对于一般场景，这种悖论与逻辑上下文性之间的等价关系存在误解，需要建立统一的理论框架来澄清这种关系。

Method: 引入统一的逻辑Hardy型悖论形式化方法，证明对于任何有限场景，逻辑Hardy型悖论的存在等价于逻辑上下文性。特别分析(2,2,2)、(2,3,3)贝尔场景和KCBS场景中的逻辑Hardy型悖论。

Result: 证明了逻辑Hardy型悖论与逻辑上下文性的等价性，纠正了先前关于这种等价关系不适用于一般场景的误解。在KCBS场景中，只存在一种Hardy型悖论，在特定参数设置下达到约10.56%的成功概率。

Conclusion: 建立了逻辑Hardy型悖论与逻辑上下文性之间的统一理论框架，澄清了先前存在的误解，为量子上下文性的研究提供了新的理论工具和分析方法。

Abstract: Hardy-type paradoxes offer elegant, inequality-free proof of quantum contextuality. In this work, we introduce a unified logical formulation for general Hardy-type paradoxes, which we term logical Hardy-type paradoxes. We prove that for any finite scenario, the existence of a logical Hardy-type paradox is equivalent to logical contextuality. Specially, strong contextuality is equivalent to logical Hardy-type paradoxes with success probability SP = 1. These results generalize prior work on (2,k,2), (2,2,d), and n-cycle scenarios, and resolve a misconception that such equivalence does not hold for general scenarios [1]. We analyse the logical Hardy-type paradoxes on the (2,2,2) and (2,3,3) Bell scenarios, as well as the Klyachko-Can-Binicioglu-Shumovsky (KCBS) scenario. We show that the KCBS scenario admits only one kind of Hardy-type paradox, achieving a success probability of SP \approx 10.56% for a specific parameter setting.

</details>


### [189] [Constraint-Aware Quantum Optimization via Hamming Weight Operators](https://arxiv.org/abs/2601.01516)
*Yajie Hao,Qiming Ding,Xiao Yuan,Xiaoting Wang*

Main category: quant-ph

TL;DR: 提出基于汉明权重算子的自适应QAOA方法，用于解决带严格线性约束的组合优化问题，相比传统惩罚方法，该方法在保持可行性的同时减少电路深度并提升性能。


<details>
  <summary>Details</summary>
Motivation: 带严格线性约束的组合优化在药物发现、电网、物流和金融等领域有重要应用，但经典算法在大规模问题上计算困难。传统QAOA使用惩罚项方法会扭曲优化景观并需要深电路，限制了近期量子硬件的可扩展性。

Method: 引入汉明权重算子这类约束感知算子，将量子演化严格限制在可行子空间内。在此基础上开发自适应汉明权重算子QAOA，动态选择最有效的算子来构建浅层、针对问题定制的电路。

Result: 在金融和高能物理的基准任务（投资组合优化和双喷注聚类能量平衡）上进行验证。该方法通过构造自然满足所有约束，收敛更快，获得比惩罚型QAOA更高的近似比，同时所需门数减少约一半。

Conclusion: 通过将约束感知算子嵌入自适应变分框架，该方法为在近期量子设备上解决实际约束优化问题建立了可扩展且硬件高效的途径。

Abstract: Constrained combinatorial optimization with strict linear constraints underpins applications in drug discovery, power grids, logistics, and finance, yet remains computationally demanding for classical algorithms, especially at large scales. The Quantum Approximate Optimization Algorithm (QAOA) offers a promising quantum framework, but conventional penalty-based formulations distort optimization landscapes and demand deep circuits, undermining scalability on near-term hardware. In this work, we introduce Hamming Weight Operators, a new class of constraint-aware operators that confine quantum evolution strictly within the feasible subspace. Building on this idea, we develop Adaptive Hamming Weight Operator QAOA, which dynamically selects the most effective operators to construct shallow, problem-tailored circuits. We validate our approach on benchmark tasks from both finance and high-energy physics, specifically portfolio optimization and two-jet clustering with energy balance. Across these problems, our method inherently satisfies all constraints by construction, converges faster, and achieves higher Approximation Ratios than penalty-based QAOA, while requiring roughly half as many gates. By embedding constraint-aware operators into an adaptive variational framework, our approach establishes a scalable and hardware-efficient pathway for solving practical constrained optimization problems on near-term quantum devices.

</details>


### [190] [Entropy and Variance Squeezing of V-type Atom in Dissipative Cavity](https://arxiv.org/abs/2601.01519)
*Zijin Liang,Qiying Pan,Hong-Mei Zou,Chenrui Bi*

Main category: quant-ph

TL;DR: 研究V型原子在耗散腔中的熵压缩和方差压缩，分析自发干涉、腔-环境耦合、原子-腔失谐等参数对原子压缩的影响


<details>
  <summary>Details</summary>
Motivation: 研究V型原子在耗散腔中的量子压缩特性，探索自发干涉、腔-环境耦合、原子-腔失谐等参数对原子压缩的影响，为量子信息处理提供超低噪声资源

Method: 基于Riccardi A的研究，分析V型原子在耗散腔中的熵压缩和方差压缩，使用不同初始状态研究自发干涉参数θ、腔-环境耦合γ₀/κ、原子-腔失谐Δ对原子压缩的影响

Result: 1. S_y在任何条件下都不出现压缩；2. S_x的方差压缩仅在Δ>0时出现；3. 熵压缩比方差压缩更精确地量化量子涨落；4. S_x的原子压缩明显依赖于θ、γ₀/κ、Δ和初始状态

Conclusion: 熵压缩比方差压缩能更精确地描述量子涨落，原子压缩特性受多个参数和初始状态影响，这些发现对量子信息处理作为超低噪声资源具有重要意义

Abstract: Based on Ref.\cite{Riccardi A}, we investigate the entropy and variance squeezing of a V-type atom in a dissipative cavity, and discuss the influences of parameters including the spontaneously generated interference (SGI) ($θ$), the cavity-environment coupling ($γ_0/κ$) and the atom-cavity detuning ($Δ$) on the atomic squeezing by using different initial states. The results show that no squeezing of $S_y$ occurs under any condition and that variance squeezing of $S_x$ appears only when $Δ>0$. Entropy squeezing quantifies quantum fluctuations more precisely than variance squeezing. Moreover, the atomic squeezing of $S_x$ clearly depends on $θ$, $γ_0/κ$, $Δ$ and the initial state. These findings are meaningful for quantum information processing as an ultra-low-noise resource.

</details>


### [191] [Overcoming Stark-Shift Constraints in Phase-Controlled Rydberg Two-Qubit Gates](https://arxiv.org/abs/2601.01521)
*Ignacio R. Sola,Sebastian C. Carrasco,Vladimir S. Malinovsky,Seokmin Shin,Bo Y. Chang*

Main category: quant-ph

TL;DR: 该论文提出在强里德堡阻塞限制下，通过控制脉冲的绝对相位和局部振幅，使用三脉冲序列实现高保真度的任意两量子位相位门，并针对不同相位门设计了两种鲁棒控制方案。


<details>
  <summary>Details</summary>
Motivation: 斯塔克位移引入的额外相位限制了在强里德堡阻塞限制下通过双光子跃迁制备纠缠门的集合。对于非独立寻址的量子比特，需要解决相位控制问题以实现高保真度的任意两量子位相位门。

Method: 通过控制每个量子比特处脉冲的绝对相位和局部振幅，使用三脉冲序列来制备任意两量子位相位门。基于这些见解，针对不同相位门设计了两种鲁棒控制方案，分别适用于偶数或奇数长度的脉冲序列。

Result: 研究表明，通过三脉冲序列可以实现高保真度的任意两量子位相位门。提出的两种鲁棒控制方案针对不同相位门都能获得更好的结果，分别适用于偶数或奇数长度的脉冲序列。

Conclusion: 该工作解决了强里德堡阻塞限制下斯塔克位移带来的相位约束问题，通过脉冲相位和振幅控制实现了任意两量子位相位门的高保真制备，为量子计算中的门操作提供了有效的控制方案。

Abstract: Stark shifts introduce additional phases that constrain the set of entangling gates that can be prepared via two-photon transitions in the strong Rydberg blockade limit. For non-independently addressed qubits, by controlling the absolute phases and the local amplitudes of the pulses at each qubit, we show that any two-qubit phase gate can be prepared with high fidelity using a three-pulse sequence. Based on these insights, we introduce two robust control schemes tailored to different phase gates that yield better results with pulse sequences of either even or odd length.

</details>


### [192] [Non-Hermitian second-order topological insulator with point gap](https://arxiv.org/abs/2601.01524)
*Xue-Min Yang,Hao Lin,Jian Li,Jia-Ji Zhu,Jun-Li Zhu,Hong Wu*

Main category: quant-ph

TL;DR: 该论文研究了二维非厄米SSH模型中零模角态的稳定性，发现传统认知在大尺寸系统中不再成立，建立了奇异值与拓扑角态的对应关系，提出了非厄米系统的体边对应原理。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为二维非厄米SSH模型中的零模角态在保持手征对称性的微扰下是鲁棒的，但作者发现这一认知在大尺寸系统中不再成立，需要重新理解非厄米系统的高阶拓扑性质。

Method: 建立了稳定零模奇异态与热力学极限下能谱拓扑保护角态之间的对应关系，定义了实空间中的绕数来计数稳定零模奇异态的数量，为静态和Floquet非厄米系统建立了体边对应原理。

Result: 零模奇异值的数量直接与能隙中角态的数量相关联，即使在无对称性的情况下，拓扑性质也源于非厄米性本身，为理解非厄米系统的拓扑特性提供了新框架。

Conclusion: 该研究揭示了非厄米系统中零模角态稳定性在大尺寸系统中的新特性，建立了基于奇异值的拓扑描述框架，为非厄米拓扑物理提供了更全面的理解。

Abstract: The zero-mode corner states in the gap of two-dimensional non-Hermitian Su-Schrieffer-Heeger model are robust to infinitesimal perturbations that preserve chiral symmetry. However, we demonstrate that this general belief is no longer valid in large-sized systems. To reveal the higher-order topology of non-Hermitian systems, we establish a correspondence between the stable zero-mode singular states and the topologically protected corner states of energy spectrum in the thermodynamic limit. Within this framework, the number of zero-mode singular values is directly linked to the number of mid-gap corner states. The winding numbers in real space can be defined to count the number of stable zero-mode singular states. Our results formulate a bulk-boundary correspondence for both static and Floquet non-Hermitian systems, where topology arises intrinsically from the non-Hermiticity, even without symmetries.

</details>


### [193] [Time-Dependent Hamiltonian Simulation in the Low-Energy Subspace](https://arxiv.org/abs/2601.01550)
*Shuo Zhou,Zhaokai Pan,Weiyuan Gong,Tongyang Li*

Main category: quant-ph

TL;DR: 本文研究在低能假设下时间依赖哈密顿量的量子模拟算法改进，证明了在初始态处于低能子空间时，基于乘积公式的数字量子模拟成本可以显著降低。


<details>
  <summary>Details</summary>
Motivation: 哈密顿量模拟是绝热量子计算、量子控制和量子多体物理中的关键子程序，量子动力学通常发生在低能区。与时间无关哈密顿量模拟相比，在低能假设下对时间依赖哈密顿量模拟算法的理解仍然有限，本文旨在探索在初始态处于低能子空间时能获得多少改进。

Method: 采用基于乘积公式的数字量子模拟方法，利用绝热微扰理论分析哈密顿量的时变能谱，推导出具有对易子缩放的乘积公式低能模拟误差。

Result: 计算了时间依赖自旋哈密顿量在低能假设下的Trotter数，展示了相比完整酉模拟标准成本的改进。证明了低能模拟误差具有对易子缩放特性，并讨论了在非平衡量子多体动力学模拟和绝热态制备中的应用。

Conclusion: 在初始态处于低能子空间时，时间依赖哈密顿量的量子模拟成本可以显著降低。通过绝热微扰理论分析时变能谱，证明了乘积公式在低能模拟中的优势，并建立了通用时间依赖哈密顿量模拟查询复杂度的下界。

Abstract: Hamiltonian simulations are key subroutines in adiabatic quantum computation, quantum control, and quantum many-body physics, where quantum dynamics often happen in the low-energy sector. In contrast to time-independent Hamiltonian simulations, a comprehensive understanding of quantum simulation algorithms for time-dependent Hamiltonians under the low-energy assumption remains limited hitherto. In this paper, we investigate how much we can improve upon the standard performance guarantee assuming the initial state is supported on a low-energy subspace. In particular, we compute the Trotter number of digital quantum simulation based on product formulas for time-dependent spin Hamiltonians under the low-energy assumption that the initial state is supported on a small number of low-energy eigenstates, and show improvements over the standard cost for simulating full unitary simulations. Technically, we derive the low-energy simulation error with commutator scaling for product formulas by leveraging adiabatic perturbation theory to analyze the time-variant energy spectrum of the underlying Hamiltonian. We further discuss the applications to simulations of non-equilibrium quantum many-body dynamics and adiabatic state preparation. Finally, we prove a lower bound of query complexity for generic time-dependent Hamiltonian simulations.

</details>


### [194] [Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics](https://arxiv.org/abs/2601.01589)
*Yazhen Wang*

Main category: quant-ph

TL;DR: 该论文研究了量子计算中基于量子行走的搜索算法和经典计算中基于朗之万动力学的采样算法，发现随机化的量子行走与欠阻尼朗之万动力学在Le Cam缺陷距离意义下渐近等价，揭示了量子加速和经典梯度加速的内在机制。


<details>
  <summary>Details</summary>
Motivation: 研究量子行走搜索算法和朗之万动力学采样算法之间的关系，因为这两种算法都用于解决学习任务，探索量子加速和经典梯度加速的内在机制。

Method: 使用Le Cam缺陷距离分析量子行走与欠阻尼朗之万动力学的渐近等价性，比较随机化量子行走和非随机化量子行走的行为差异。

Result: 随机化的量子行走与欠阻尼朗之万动力学在Le Cam缺陷距离意义下渐近等价，而非随机化的量子行走由于高频振荡行为而不等价。

Conclusion: 研究结果揭示了量子行走与欠阻尼朗之万动力学之间的深层联系，为理解量子加速和经典梯度加速的内在机制提供了新见解，对机器学习中相关算法的计算和推断性质有重要启示。

Abstract: Fast computational algorithms are in constant demand, and their development has been driven by advances such as quantum speedup and classical acceleration. This paper intends to study search algorithms based on quantum walks in quantum computation and sampling algorithms based on Langevin dynamics in classical computation. On the quantum side, quantum walk-based search algorithms can achieve quadratic speedups over their classical counterparts. In classical computation, a substantial body of work has focused on gradient acceleration, with gradient-adjusted algorithms derived from underdamped Langevin dynamics providing quadratic acceleration over conventional Langevin algorithms.
  Since both search and sampling algorithms are designed to address learning tasks, we study learning relationship between coined quantum walks and underdamped Langevin dynamics. Specifically, we show that, in terms of the Le Cam deficiency distance, a quantum walk with randomization is asymptotically equivalent to underdamped Langevin dynamics, whereas the quantum walk without randomization is not asymptotically equivalent due to its high-frequency oscillatory behavior. We further discuss the implications of these equivalence and nonequivalence results for the computational and inferential properties of the associated algorithms in machine learning tasks. Our findings offer new insight into the relationship between quantum walks and underdamped Langevin dynamics, as well as the intrinsic mechanisms underlying quantum speedup and classical gradient acceleration.

</details>


### [195] [Generation of circular polarized high-order harmonics from single color quantum light](https://arxiv.org/abs/2601.01611)
*Lidija Petrovic,Philipp Stammer,Maciej Lewenstein,Javier Rivera-Dean*

Main category: quant-ph

TL;DR: 该研究展示了使用压缩高度椭圆偏振驱动场可以在经典禁止的大椭圆度区域实现高次谐波产生，并产生具有超泊松光子统计的高度椭圆谐波辐射，同时谐波光谱特征编码了驱动场的量子性质信息。


<details>
  <summary>Details</summary>
Motivation: 传统圆偏振经典驱动场无法产生高次谐波，这一限制可以通过引入驱动场的量子特性来克服。研究旨在探索压缩椭圆偏振驱动场如何在高椭圆度区域实现高次谐波产生，并揭示谐波光谱如何编码驱动场的量子信息。

Method: 使用压缩高度椭圆偏振驱动场，分析高次谐波产生过程在经典禁止的大椭圆度区域的特性。通过研究谐波光谱强度随驱动场椭圆度和压缩方向的依赖关系，识别探测驱动场量子性质的方法。

Result: 压缩高度椭圆偏振驱动场不仅能在经典禁止的大椭圆度区域实现高次谐波产生，还能产生具有高度椭圆性和明显超泊松光子统计的谐波辐射。谐波光谱特征编码了驱动场的量子性质，特别是其压缩场涨落信息。

Conclusion: 该研究提供了一种探测高光子数区域驱动场量子性质的新方法，通过分析高次谐波光谱对驱动场椭圆度和压缩方向的依赖性，可以揭示驱动场的量子特性，为量子光学和强场物理交叉领域提供了新的研究工具。

Abstract: The atomic response to an ultra-intense driving field produces a characteristic high-harmonic spectrum featuring a rapid drop in intensity for the lower harmonics, followed by a plateau and a sharp cutoff. This response vanishes for circularly polarized classical drivers -- a limitation that can be overcome by introducing quantum features into the driving field. In this work, we show that squeezed highly elliptically polarized drivers not only enable the high-harmonic generation (HHG) process in classically forbidden regimes of large ellipticity, but also yield highly elliptical harmonic radiation with pronounced super-Poissonian photon statistics. Moreover, we show that the HHG spectral features encode information about the quantum nature of the driving field, revealing the presence of its squeezed field fluctuations. By analyzing the HHG spectral intensity dependence as a function of the driver's ellipticity and squeezing orientation, we identify a means to probe the driving field's quantum properties that intrinsically lie in the high-photon number regime.

</details>


### [196] [Scattering Cross Section Formula Derived From Macroscopic Model of Detectors](https://arxiv.org/abs/2601.01625)
*Rashi Kaimal,Roderich Tumulka*

Main category: quant-ph

TL;DR: 该论文从两种不同的宏观检测模型推导了量子散射理论中自由非相对论粒子在远场区域的检测概率分布公式，并与玻姆力学进行了比较。


<details>
  <summary>Details</summary>
Motivation: 为量子散射理论中常用的远场检测概率分布公式提供严格的数学证明和物理基础，该公式描述了自由量子粒子在大半径球面上的检测时间和位置分布。

Method: 提出了两种不同的推导方法：1）使用负虚数势模型，在探测器区域施加强度为λ的负虚数势，取极限R→∞, λ→0, Rλ→∞；2）使用重复近似投影测量模型，在时间间隔T下重复测量粒子是否在半径R之外，取极限R→∞, T→∞, T/R→0。

Result: 两种方法都得到了相同的散射截面公式：σ(x,t) = m³ℏ⁻³Rt⁻⁴|Ψ̂₀(mx/ℏt)|²，其中Ψ̂₀是初始波函数的傅里叶变换。该结果与玻姆力学在无探测器情况下的到达分布一致。

Conclusion: 论文为量子散射理论中的远场检测公式提供了两种独立的严格推导，验证了其物理合理性，并扩展到非球形表面、多粒子系统、时间相关表面和狄拉克方程等更一般情况。

Abstract: We are concerned with the justification of the statement, commonly (explicitly or implicitly) used in quantum scattering theory, that for a free non-relativistic quantum particle with initial wave function $Ψ_0(\boldsymbol{x})$, surrounded by detectors along a sphere of large radius $R$, the probability distribution of the detection time and place has asymptotic density (i.e., scattering cross section) $σ(\boldsymbol{x},t)= m^3 \hbar^{-3} R t^{-4} |\widehatΨ_0(m\boldsymbol{x}/\hbar t)|^2$ with $\widehatΨ_0$ the Fourier transform of $Ψ_0$. We give two derivations of this formula, based on different macroscopic models of the detection process. The first one consists of a negative imaginary potential of strength $λ>0$ in the detector volume (i.e., outside the sphere of radius $R$) in the limit $R\to\infty,λ\to 0, Rλ\to \infty$. The second one consists of repeated nearly-projective measurements of (approximately) the observable $1_{|\boldsymbol{x}|>R}$ at times $\mathscr{T},2\mathscr{T},3\mathscr{T},\ldots$ in the limit $R\to\infty,\mathscr{T}\to\infty,\mathscr{T}/R\to 0$; this setup is similar to that of the quantum Zeno effect, except that there one considers $\mathscr{T}\to 0$ instead of $\mathscr{T}\to\infty$. We also provide a comparison to Bohmian mechanics: while in the absence of detectors, the arrival times and places of the Bohmian trajectories on the sphere of radius $R$ have asymptotic distribution density given by the same formula as $σ$, their deviation from the detection times and places is not necessarily small, although it is small compared to $R$, so the effect of the presence of detectors on the particle can be neglected in the far-field regime. We also cover the generalization to surfaces with non-spherical shape, to the case of $N$ non-interacting particles, to time-dependent surfaces, and to the Dirac equation.

</details>


### [197] [Quantum simulation with Rydberg ions in a Penning trap](https://arxiv.org/abs/2601.01626)
*Wilson S. Martins,Markus Hennrich,Ferdinand Schmidt-Kaler,Igor Lesanovsky*

Main category: quant-ph

TL;DR: 该论文提出了一种利用里德堡态离子在彭宁阱中实现二维自旋系统量子模拟的新方法，可将相互作用强度提高数个数量级，为研究长时标现象提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 现有离子阱量子模拟平台中，自旋相互作用通过晶体振动介导，强度有限，限制了研究长时标现象的能力。需要一种能大幅增强相互作用强度的方法来探索受挫系统和动力学约束系统中的慢速集体弛豫等过程。

Method: 利用电子里德堡态之间的强偶极相互作用，结合彭宁阱提供的平面约束。研究了强电场和磁场对里德堡态性质的影响，展示了在实验现实条件下可实现MHz量级的自旋-自旋相互作用强度。

Result: 该方法可将自旋相互作用强度提高数个数量级，结合离子阱的长寿命特性，为研究长时标现象开辟了新途径。以三个离子实现的受挫自旋系统为例，展示了该量子模拟器研究纠缠的能力。

Conclusion: 基于里德堡态离子和彭宁阱的新平台能够大幅增强二维自旋系统的相互作用强度，为探索受挫系统和动力学约束系统中的慢速集体弛豫等长时标现象提供了强大的量子模拟工具。

Abstract: Quantum simulation of interacting many-body spin systems is routinely performed with cold trapped ions, and systems with hundreds of spins have been studied in one and two dimensions. In the most common realizations of these platforms, spin degrees of freedom are encoded in low-lying electronic levels, and interactions among the spins are mediated through crystal vibrations. Here we propose a new approach which enables the quantum simulation of two-dimensional spin systems with interaction strengths that are increased by orders of magnitude. This, together with the unprecedented longevity of trapped ions, opens an avenue for the exploration of phenomena that take place on long timescales, e.g., slow and collective relaxation in frustrated and kinetically constrained systems. Our platform makes use of the strong dipolar interactions among electronic Rydberg states and planar confinement provided by a Penning trap. We investigate how the strong electric and magnetic fields that form this trap affect the properties of the Rydberg states and show that spin-spin interaction strengths on the order of MHz are achievable under experimentally realistic conditions. As a brief illustration of the capabilities of this quantum simulator, we study the entanglement in a frustrated spin system realized by three ions.

</details>


### [198] [Design and Characterization of Compact Acousto-Optic-Deflector Individual Addressing System for Trapped-Ion Quantum Computing](https://arxiv.org/abs/2601.01647)
*Jiyong Yu,Kavyashree Ranawat,Andrew Van Horn,Jacob Whitlow,Seunghyun Baek,Junki Kim,Jungsang Kim*

Main category: quant-ph

TL;DR: 提出基于声光偏转器的紧凑型光束转向系统，用于囚禁离子量子计算中的单离子寻址，实现小于1平方英尺的紧凑设计，在5离子链中强度串扰低于9×10⁻⁴，并成功演示了30离子链的单离子寻址。


<details>
  <summary>Details</summary>
Motivation: 为囚禁离子量子计算开发紧凑稳定的单离子寻址系统，通过最小化光机械自由度和光路来提高光学稳定性，为长离子链的高保真度量子计算提供潜力。

Method: 采用声光偏转器作为光束转向系统，设计紧凑的光学布局（小于1平方英尺），最小化光机械自由度和光束路径，在355nm波长下实现高斯光束和光束转向。

Result: 系统实现约50倍光束直径的转向范围，在5离子链中所有相邻离子的强度串扰低于9×10⁻⁴，成功演示30离子链的单离子寻址，光束切换时间约240纳秒。

Conclusion: 紧凑型声光偏转器系统提供了高光学稳定性，有望实现长离子链的高保真度囚禁离子量子计算，为量子计算硬件发展提供了重要进展。

Abstract: We present a compact design for a beam-steering system based on acousto-optic-deflectors (AODs) used as an individual addressing system for trapped-ion quantum computing. The design targets to minimize the optomechanical degrees of freedom and the optical beam paths to improve optical stability, and we successfully implemented a solution with a compact footprint of less than 1 square foot. The system characterization results show that we achieve clean Gaussian beams at 355nm wavelength with a beam steering range of $\sim$50 times the beam diameter, and an intensity crosstalk of $< 9 \times 10^{-4}$ at all neighboring ions in a five-ion chain. Based on these capabilities, we experimentally demonstrate individual addressing of a 30-ion chain. We estimate the beam switching time of the AOD to be $\sim$240 ns. The compact system design is expected to provide high optical stability, providing the potential for high-fidelity trapped-ion quantum computing with long ion chains.

</details>


### [199] [A Geometric Approach to Strongly Correlated Bosons: From $N$-Representability to the Generalized BEC Force](https://arxiv.org/abs/2601.01652)
*Chih-Chun Wang,Christian Schilling*

Main category: quant-ph

TL;DR: 该论文基于约化密度矩阵理论，为强关联晶格玻色子开发了几何框架，建立了仅用动量占据数表示的精确泛函形式，揭示了单粒子N-可表示性的重要性及其边界力的物理意义。


<details>
  <summary>Details</summary>
Motivation: 基于近期约化密度矩阵理论的进展，研究强关联晶格玻色子系统的几何描述框架，旨在建立仅依赖于动量占据数的精确泛函形式，揭示单粒子N-可表示性在强关联系统中的普遍重要性。

Method: 采用约束搜索形式体系，利用N-玻色子构型态与其单粒子约化密度矩阵之间的几何对应关系，推导基态泛函的一般形式。通过解析方法研究少格点系统，并基于几何论证推导边界力的显式表达式。

Result: 建立了仅用动量占据数表示的精确泛函形式；证明了泛函定义域完全由N-可表示条件决定；发现泛函梯度在边界处发散产生排斥力，推广了BEC力的概念；通过几何论证得到了边界力的显式表达式；为系统层次化泛函近似提供了理论基础。

Conclusion: 该研究为强关联晶格玻色子系统提供了统一的几何框架，揭示了单粒子N-可表示性的核心作用，建立了泛函边界力的物理图像，为发展系统性的泛函近似层次结构奠定了理论基础。

Abstract: Building on recent advances in reduced density matrix theory, we develop a geometric framework for describing strongly correlated lattice bosons. We first establish that translational symmetry, together with a fixed pair interaction, enables an exact functional formulation expressed solely in terms of momentum occupation numbers. Employing the constrained-search formalism and exploiting a geometric correspondence between $N$-boson configuration states and their one-particle reduced density matrices, we derive the general form of the ground-state functional. Its structure highlights the omnipresent significance of one-body $N$-representability: (i) the domain is exactly determined by the $N$-representability conditions; (ii) at its boundary, the gradient of the functional diverges repulsively, thereby generalizing the recently discovered Bose-Einstein condensate (BEC) force; and (iii) an explicit expression for this boundary force follows directly from geometric arguments. These key results are demonstrated analytically for few-site lattice systems, and we illustrate the broader significance of our functional form in defining a systematic hierarchy of functional approximations.

</details>


### [200] [Demonstration of Discrete-Time Quantum Walks and Observation of Topological Edge States in a Superconducting Qutrit Chain](https://arxiv.org/abs/2601.01759)
*Kun Zhou,Jian-Wen Xu,Qi-Ping Su,Yu Zhang,Xiang-Min Yu,Zhuang Ma,Han-Yu Zhang,Hong-Yi Shi,Wen Zheng,Shu-Yi Pan,Yi-Hao Kang,Zhi-Guo Huang,Chui-Ping Yang,Shao-Xiong Li,Yang Yu*

Main category: quant-ph

TL;DR: 该研究使用超导三能级系统（qutrit）实现了可扩展的离散时间量子行走，观察到了量子行走在qutrit链中的弹道扩散，并首次在超导平台上制备了两种拓扑相及其界面处的粒子-空穴对称性保护的边缘态。


<details>
  <summary>Details</summary>
Motivation: 量子行走是实现通用量子计算和算法研究的重要工具，但基于超导电路的离散时间量子行走实现仍受限于操作精度、电路深度和连接性等问题。研究旨在利用超导三能级系统提高硬件效率，实现可扩展的量子行走系统。

Method: 使用超导三能级系统（qutrit）构建量子行走系统，利用qutrit高效编码行走者位置和硬币自由度。通过利用qutrit基量子行走的灵活性和内在对称性，在链中制备两种拓扑相。

Result: 实验观察到量子行走在qutrit链中的弹道扩散，首次在超导平台上成功制备了两种拓扑相，并观测到它们界面处受粒子-空穴对称性保护的边缘态。测量的参数依赖性进一步验证了边缘态的特性。

Conclusion: 所展示的离散时间量子行走具有可扩展性和门控兼容性，为超导量子计算和量子模拟提供了一个多功能工具，特别是在拓扑相和边缘态研究方面具有重要应用价值。

Abstract: Quantum walk serves as a versatile tool for universal quantum computing and algorithmic research. However, the implementation of discrete-time quantum walks (DTQWs) with superconducting circuits is still constrained by some limitations such as operation precision, circuit depth and connectivity. With improved hardware efficiency by using superconducting qutrits (three-level systems), we experimentally demonstrate a scalable DTQW in a superconducting circuit, observing the ballistic spreading of quantum walk in a qutrit chain. The usage of qutrits in our implementation allows hardware efficiently encoding of the walker position and the coin degree of freedom. By exploiting the flexibility and intrinsic symmetries of qutrit-based DTQWs, we successfully prepare two topological phases in the chain. For the first time, particle-hole-symmetry-protected edge states, bounded at the interface between these two topological phases, are observed in the superconducting platform. Measured parameter dependencies further validate the properties of edge states. The scalability and gate-control compatibility of the demonstrated DTQWs enable a versatile tool for superconducting quantum computing and quantum simulation.

</details>


### [201] [A Survey on Applications of Quantum Computing for Unit Commitment](https://arxiv.org/abs/2601.01777)
*Milad Hasanzadeh,Ali Rajabi,Amin Kargarian*

Main category: quant-ph

TL;DR: 本文综述了量子计算在电力系统机组组合问题中的应用研究，涵盖了量子退火、变分混合算法、量子机器学习等多种量子范式，分析了建模策略、硬件实现和计算权衡。


<details>
  <summary>Details</summary>
Motivation: 机组组合是电力系统运行和电力市场调度的核心优化问题，传统方法如混合整数规划、动态规划等在系统规模和不确定性增加时面临可扩展性挑战。量子计算的发展为加速机组组合求解过程提供了新的机会。

Method: 本文采用文献综述方法，对现有量子计算在机组组合问题中的应用研究进行全面调查，按量子范式进行分类：退火基方法、变分混合算法、量子机器学习方法和量子启发方法。

Result: 综述分析了不同量子计算范式在机组组合问题中的建模策略、硬件实现和计算权衡，总结了当前研究进展、局限性以及未来大规模量子赋能机组组合的潜在发展方向。

Conclusion: 量子计算为解决大规模机组组合问题提供了有前景的新途径，但当前仍面临硬件限制、算法成熟度等挑战，需要进一步研究以实现实际应用。

Abstract: Unit Commitment (UC) is a core optimization problem in power system operation and electricity market scheduling. It determines the optimal on/off status and dispatch of generating units while satisfying system, operational, and market constraints. Traditionally, UC has been solved using mixed-integer programming, dynamic programming, or metaheuristic methods, all of which face scalability challenges as systems grow in size and uncertainty. Recent advances in quantum computing, spanning quantum annealing, variational algorithms, and hybrid quantum classical optimization, have opened new opportunities to accelerate UC solution processes by exploiting quantum parallelism and entanglement. This paper presents a comprehensive survey of existing research on the applications of quantum computing for solving the UC problem. The reviewed works are categorized based on the employed quantum paradigms, including annealing-based, variational hybrid, quantum machine learning, and quantum-inspired methods. Key modeling strategies, hardware implementations, and computational trade-offs are discussed, highlighting the current progress, limitations, and potential future directions for large-scale quantum-enabled UC.

</details>


### [202] [Physically natural metric-measure Lindbladian ensembles and their learning hardness](https://arxiv.org/abs/2601.01806)
*Caisheng Cheng,Ruicheng Bao*

Main category: quant-ph

TL;DR: 该论文研究了开放量子系统中随机Lindbladian动力学的可学习性问题，证明了在统计查询框架下学习此类动力学需要指数级查询次数，并设计了基于随机Lindbladian的物理不可克隆函数协议。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中噪声和耗散生成元结构的可推断性，探索量子信息、统计物理和多体动力学交叉领域的基本问题，即仅通过有限时间测量统计推断噪声和耗散结构的能力。

Method: 在GKSL锥的仿射包中引入物理动机的随机局部Lindbladian集合，通过线性参数化围绕参考生成元构建；将统计查询(SQ)和量子过程统计查询(QPStat)框架扩展到开放系统设置；推导线性响应表达式计算总变差距离的系综平均值；设计基于随机Lindbladian集合的物理不可克隆函数协议。

Result: 证明了学习随机Lindbladian动力学需要指数级查询次数的下界：在总变差距离下学习输出分布具有平均情况SQ困难性，在钻石范数下学习Lindbladian通道具有平均情况QPStat困难性；在随机局部振幅阻尼链中验证了非消失标度；设计了两种基于随机Lindbladian的物理不可克隆函数协议。

Conclusion: 随机Lindbladian动力学的学习具有计算困难性，这种困难性可以转化为密码学安全保证，为开放系统提供了学习困难性到密码学安全性的转换实例。

Abstract: In open quantum systems, a basic question at the interface of quantum information, statistical physics, and many-body dynamics is how well can one infer the structure of noise and dissipation generators from finite-time measurement statistics alone. Motivated by this question, we study the learnability and cryptographic applications of random open-system dynamics generated by Lindblad-Gorini-Kossakowski-Sudarshan (GKSL) master equations. Working in the affine hull of the GKSL cone, we introduce physically motivated ensembles of random local Lindbladians via a linear parametrisation around a reference generator. On top of this geometric structure, we extend statistical query (SQ) and quantum-process statistical query (QPStat) frameworks to the open-system setting and prove exponential (in the parameter dimension $M$) lower bounds on the number of queries required to learn random Lindbladian dynamics. In particular, we establish average-case SQ-hardness for learning output distributions in total variation distance and average-case QPStat-hardness for learning Lindbladian channels in diamond norm. To support these results physically, we derive a linear-response expression for the ensemble-averaged total variation distance and verify the required nonvanishing scaling in a random local amplitude-damping chain. Finally, we design two Lindbladian physically unclonable function (Lindbladian-PUF) protocols based on random Lindbladian ensembles with distribution-level and tomography-based verification, thereby providing open-system examples where learning hardness can be translated into cryptographic security guarantees.

</details>


### [203] [Photon blockade effect from synergistic optical parametric amplification and driving force in Kerr-medium single-mode cavity](https://arxiv.org/abs/2601.01819)
*Zhang Zhiqiang*

Main category: quant-ph

TL;DR: 该研究探讨了在包含克尔非线性腔与光学参量放大器耦合的混合量子系统中光子阻塞的控制。通过解析和数值方法验证了光子阻塞效应，并展示了驱动相位对阻塞区域的调控能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索混合量子系统中光子阻塞的控制机制，特别是如何通过驱动相位和系统参数调控单光子源性能，为增强单光子源亮度提供理论途径。

Method: 采用包含腔衰减的有效哈密顿量推导主方程，在福克基矢中展开至双光子能级求解稳态薛定谔方程，获得解析解和最优光子阻塞条件，并通过数值模拟验证。

Result: 解析解与数值模拟在稳态二阶相关函数上高度一致，验证了光子阻塞效应。共振条件下腔内平均光子数显著增加，驱动相位可调控阻塞区域位置和方向，克尔非线性在宽范围内保持阻塞稳定性。

Conclusion: 光子阻塞可通过合适参数实现，其物理机制源于两条激发路径间的破坏性量子干涉抑制双光子态。驱动相位能有效调控阻塞区域，克尔非线性不破坏干涉机制，使效应在宽参数范围内保持稳定。

Abstract: This work investigates photon blockade control in a hybrid quantum system containing a Kerr-nonlinear cavity coupled to an optical parametric amplifier (OPA). The dynamics are governed by a master equation derived from an effective Hamiltonian that includes cavity decay.To obtain analytical solutions, the system's quantum state is expanded in the Fock basis up to the two-photon level. Solving the steady-state Schrodinger equation yields probability amplitudes and the analytical conditions for optimal photon blockade. Results confirm that photon blockade is achievable with suitable parameters. Excellent agreement is found between the analytical solutions and numerical simulations for the steady-state, equal-time second-order correlation function, validating both the analytical method and the blockade effect.Numerically, the average intracavity photon number increases significantly under resonance, providing a theoretical pathway for enhancing single-photon source brightness. Furthermore, the driving phase is shown to regulate the optimal blockade region: it shifts the parabolic region within the two-dimensional parameter space of driving strength and OPA nonlinearity and can even reverse its opening direction.The influence of Kerr nonlinearity is also examined. Photon blockade remains robust across a wide range of Kerr strengths. Physical analysis attributes the effect to destructive quantum interference between two distinct excitation pathways that suppress two-photon states. While Kerr nonlinearity shifts the system's energy levels, it does not disrupt this interference mechanism, explaining the effect's stability over a broad parameter range.

</details>


### [204] [Quantum information of optical magnetometry: Semiclassical Cramer-Rao bound violation and Heisenberg scaling](https://arxiv.org/abs/2601.01820)
*Georg Engelhardt,Ming Li,Xingchang Wang,JunYan Luo,J. F. Chen*

Main category: quant-ph

TL;DR: 该研究通过量子信息理论分析光学磁力计，发现半经典模型在弱耗散和大原子数下会违反量子克拉美-罗界，而集体自旋模型则始终遵守该界限并预测海森堡标度，揭示了测量诱导的量子关联在非相互作用量子系统中的重要作用。


<details>
  <summary>Details</summary>
Motivation: 研究光学磁力计中量子信息特性，比较不同理论模型对磁力计性能的预测，探索量子传感的新范式，并为量子力学基础在宏观原子系综中的测试提供可能。

Method: 采用两种不同模型进行分析：1）半经典模型，描述激光偏振旋转的法拉第效应；2）集体自旋模型，将原子视为集体自旋系统。通过比较两种模型的预测结果，特别是量子费希尔信息和克拉美-罗界的关系。

Result: 半经典模型在弱耗散和大原子数下会违反量子克拉美-罗界数个数量级，表明该模型在此参数区域无效。集体自旋模型始终遵守克拉美-罗界，并预测量子费希尔信息具有海森堡标度。海森堡标度源于测量诱导的量子关联，而非系统内在相互作用。

Conclusion: 海森堡标度出现在宏观量子系统的稳态中，代表了量子传感的新范式。两种模型与实验数据的比较可为量子力学基础在宏观原子系综中的测试提供依据，揭示了测量诱导量子关联在非相互作用系统中的重要作用。

Abstract: Optical magnetometers use the rotation of linearly polarized laser light induced by the Faraday effect for high precision magnetic field measurements. Here, we carry out an in-depth quantum information investigation, deploying two distinct models: The first, semiclassical model can violate the quantum Cramer-Rao bound by several orders of magnitude for weak dissipation and large atom numbers, invalidating the semiclassical approach in this parameter regime. The second model, describing the atoms as a collective spin, respects the Cramer-Rao bound for all parameters. Interestingly, the collective model also predicts Heisenberg scaling for the quantum Fisher information. The comparison of both models shows that Heisenberg scaling is a result of measurement-induced quantum correlation in an otherwise non-interacting quantum system. As the Heisenberg scaling appears in a stationary state of a macroscopic quantum system, it can be thus viewed as a new paradigm in quantum sensing. Intriguingly, the comparison of both models with experimental data can constitute a test for the foundations of quantum mechanics in a macroscopic ensemble of atoms.

</details>


### [205] [Global Parametric Gates for Multi-qubit Entanglement](https://arxiv.org/abs/2601.01826)
*Jize Yang,Lin Guo,Haonan Xiong,Jiahui Wang,Yan Li,Yunfan Yang,Chenjie An,Hongyi Zhang,Luyan Sun,Yipu Song,Luming Duan*

Main category: quant-ph

TL;DR: 提出并实验演示了一种全局参数门，可在单步中生成多量子比特纠缠态，通过向公共量子比特施加参数驱动，直接产生2、3、4量子比特纠缠，保真度分别为99.4%、93.4%、91.4%。


<details>
  <summary>Details</summary>
Motivation: 传统多量子比特纠缠生成通常需要多个两步门操作，效率低且易累积误差。需要一种高效、可重构的单步全局门方案，兼容固定频率量子比特，仅使用微波驱动。

Method: 通过向公共量子比特施加参数驱动，在精确失谐频率下相对于计算量子比特工作。该方法仅需微波驱动，兼容固定频率量子比特，无需磁通调谐。

Result: 实验成功生成2、3、4量子比特纠缠态，保真度分别为99.4%±0.2%、93.4%±0.3%、91.4%±0.3%。误差分析显示主要来自退相干和相干控制误差，静态ZZ耦合和磁通噪声贡献可忽略。模拟预测在六量子比特系统中可达99.70%保真度。

Conclusion: 该全局参数门方案为高效生成多量子比特纠缠提供了可行路径，具有高保真度、可重构性、仅需微波驱动、兼容固定频率量子比特等优势，有望扩展到更大规模量子系统。

Abstract: We propose and experimentally demonstrate a global parametric gate that generates multi-qubit entangled states in a single step. By applying a parametric drive to a common qubit at precise detunings relative to computational qubits, we directly produce two-, three-, and four-qubit entanglement with state fidelities of 99.4\%\pm0.2\%, 93.4\%\pm0.3\%, and 91.4\%\pm0.3\%, respectively. This scheme enables efficient, reconfigurable control using only microwave drives and is compatible with fixed-frequency qubits. Error analyses indicate that infidelity stems primarily from decoherence and coherent control errors, with negligible contributions from static ZZ coupling and flux noise. Furthermore, simulations with state-of-the-art parameters predict this global gate can generate high-fidelity (99.70\%) entanglement in systems of up to six qubits.

</details>


### [206] [Quantum Interaction Between Free Electrons and Light Involving First-order and Second-order Process](https://arxiv.org/abs/2601.01846)
*Hongteng Lin,Xiaotong Xiong,Junjie Liu,Yidong Huang,Fang Liu*

Main category: quant-ph

TL;DR: 该论文发展了考虑双光子过程的电子-光子相互作用全量子理论，揭示了自由电子与双光子相互作用的新现象和机制。


<details>
  <summary>Details</summary>
Motivation: PINEM效应已展示了自由电子与光学近场量子相互作用，但自由电子通常只吸收/发射单个光子，双光子相互作用的物理机制和现象尚未研究。此外，PINEM与Kapitza-Dirac效应和非线性康普顿散射的关系也不明确。

Method: 发展了考虑双光子过程的电子-光子相互作用全量子理论，通过操纵光学近场的电场分量来增强双光子发射/吸收，并分析单光子和双光子过程的量子干涉。

Result: 发现通过操纵光学近场电场分量可显著增强电子的双光子发射/吸收；在某些情况下会发生单光子和双光子过程的量子干涉，影响光子数态、电子能态和电子-光子纠缠。同时发现KD效应和非线性康普顿散射也是一种双光子过程，基于全量子理论可解析推导电子分布。

Conclusion: 该工作揭示了自由电子与双光子相互作用时可能出现的丰富现象，为未来更深入研究电子-光子量子相互作用中的非线性过程铺平了道路。

Abstract: Photon-induced Near-field Electron Microscopy (PINEM) effect has revealed the quantum interaction between free electrons and optical near filed, which demonstrated plenty of novel phenomena of manipulating free electron wave packet and detecting/shaping quantum photonic states. However, free electrons generally only absorb/emit one photon at a time, while the physical mechanism and phenomena of free electron-two-photon interaction have not been studied yet. Moreover, the relationship between PINEM and Kapitza-Dirac (KD) effect and nonlinear Compton scattering is still unclear. Here we develop the full quantum theory of electron-photon interaction considering the two-photon process. It is revealed that the emission/absorption of two photons by electrons can be greatly enhanced by manipulating the electric field component of optical near field, and the quantum interference between single-photon and two-photon processes can occur in some circumstances, which affects the photon number state, electron energy states and electron-photon entanglement. Meanwhile, it is found that the KD effect (elastic electron-photon scattering) and nonlinear Compton scattering (inelastic electron-photon scattering) are also a kind of two-photon process and the distribution of electrons can be deduced analytically based on the full quantum theory. Our work uncovers the possible abundant phenomena when free electron interacting with two photons, paves the way for more in-depth studies of nonlinear processes in electron-photon quantum interactions in the future.

</details>


### [207] [A Survey of Bargmann Invariants: Geometric Foundations and Applications](https://arxiv.org/abs/2601.01858)
*Lin Zhang,Bing Xie*

Main category: quant-ph

TL;DR: 该综述全面介绍了Bargmann不变量——量子态向量重叠产生的一类规范不变量，重点阐述了它们在塑造量子态空间信息几何结构中的作用及其在现代量子信息科学中的应用。


<details>
  <summary>Details</summary>
Motivation: Bargmann不变量作为量子力学几何结构的重要数学工具，提供了一个统一框架来理解量子态空间的几何特性。本文旨在系统综述这些不变量，强调它们不仅是数学概念，更是探索量子系统关系和几何特征的重要工具。

Method: 该综述采用文献综述方法，综合历史背景与最新进展，系统分析Bargmann不变量的理论基础、几何意义和应用场景。重点探讨这些不变量如何作为工具来表征量子态空间的内在几何结构。

Result: Bargmann不变量能够有效表征量子态空间的内在几何结构，在确定局部幺正等价性、构造混合态完全多项式不变量集等方面具有重要应用。特别地，它们在现代量子信息科学中可用于开发无需完整态层析的纠缠检测方法。

Conclusion: Bargmann不变量不仅是数学上的有趣概念，更是探索量子系统关系和几何特征的重要工具。它们为理解量子力学的几何结构提供了统一框架，并在量子信息科学中展现出重要的应用价值。

Abstract: Bargmann invariants, a class of gauge-invariant quantities arising from the overlaps of quantum state vectors, provide a profound and unifying framework for understanding the geometric structure of quantum mechanics. This survey offers a comprehensive overview of Bargmann invariants, with a particular focus on their role in shaping the informational geometry of the state space. The core of this review demonstrates how these invariants serve as a powerful tool for characterizing the intrinsic geometry of the space of quantum states, leading to applications in determining local unitary equivalence and constructing a complete set of polynomial invariants for mixed states. Furthermore, we explore their pivotal role in modern quantum information science, specifically in developing operational methods for entanglement detection without the need for full state tomography. By synthesizing historical context with recent advances, this survey aims to highlight Bargmann invariants not merely as mathematical curiosities, but as essential instruments for probing the relational and geometric features of quantum systems.

</details>


### [208] [Pervasive Vulnerability Analysis and Defense for QKD-based Quantum Private Query](https://arxiv.org/abs/2601.01918)
*Xiaoyu Peng,Bin Liu,Shiyu He,Nankun Mu,Wei Huang,Bingjie Xu,Fei Gao*

Main category: quant-ph

TL;DR: QKD-based量子私有查询协议存在严重安全漏洞，攻击者可通过简单方法窃取数据库信息，多加密防御方案可增强安全性


<details>
  <summary>Details</summary>
Motivation: 量子私有查询(QPQ)作为仅次于QKD的最实用量子通信协议，其大多数现有协议在后处理阶段存在被严重忽视的安全漏洞，需要解决这些关键缺陷

Method: 研究聚焦于不确定信号比特下的隐藏信息提取，揭示攻击方法：直接观测攻击导致增量信息泄露，最小误差判别攻击高效窃取额外数据库信息；提出与现有QPQ协议兼容的多加密防御方案

Result: 研究表明大多数QKD-based QPQ协议面临严重安全威胁，即使没有复杂量子资源也能被攻击；多加密策略被证明对数据库安全至关重要

Conclusion: 多加密防御方案为构建抵抗现实世界攻击的实用QPQ协议提供了关键理论和技术支持，解决了QPQ协议中严重的安全漏洞问题

Abstract: Quantum Private Query (QPQ) based on Quantum Key Distribution (QKD) is among the most practically viable quantum communication protocols, with application value second only to QKD itself. However, prevalent security vulnerabilities in the post-processing stages of most existing QKD-based QPQ protocols have been severely overlooked. This study focuses on hidden information extraction under undetermined signal bits, revealing that most such QPQ protocols face severe security threats even without complex quantum resources. Specifically, direct observation attack causes incremental information leakage, while the minimum error discrimination attack efficiently steals additional database inforamtion. To address these critical flaws, the proposed multi-encryption defense scheme is compatible with existing QPQ protocols. The study demonstrates the necessity of the multi-encryption strategy for the security of databases in QPQ, providing key theoretical and technical support for constructing practical QPQ protocols resistant to real-world attacks.

</details>


### [209] [Self-Supervised Learning with Noisy Dataset for Rydberg Microwave Sensors Denoising](https://arxiv.org/abs/2601.01924)
*Zongkai Liu,Qiming Ren,Wenguang Yang,Yanjie Tong,Huizhen Wang,Yijie Zhang,Ruohao Zhi,Junyao Xie,Mingyong Jing,Hao Zhang,Liantuan Xiao,Suotang Jia,Ke Tang,Linjie Zhang*

Main category: quant-ph

TL;DR: 提出一种用于里德堡传感器的自监督深度学习框架，通过单次测量实现噪声抑制，效果相当于多次测量平均，计算时间减少三个数量级。


<details>
  <summary>Details</summary>
Motivation: 量子传感中的里德堡传感器需要高精度测量，传统方法需要多次测量平均来抑制噪声，但耗时较长。现有降噪方法需要干净的参考信号，这在量子传感中难以获得。

Method: 开发自监督深度学习框架，使用两组统计分布相同的噪声信号进行训练，无需干净参考信号。比较了U-Net和Transformer架构，量化了复杂度与性能的权衡。

Result: 框架在里德堡传感数据集上表现优异，优于小波变换和卡尔曼滤波，降噪效果相当于10,000次测量平均，计算时间减少三个数量级。在不同噪声分布下均表现良好。

Conclusion: 该自监督深度学习框架为里德堡传感器提供了一种高效的单次测量降噪方案，无需干净参考信号，为深度学习在量子传感降噪中的优化提供了实用指导。

Abstract: We report a self-supervised deep learning framework for Rydberg sensors that enables single-shot noise suppression matching the accuracy of multi-measurement averaging. The framework eliminates the need for clean reference signals (hardly required in quantum sensing) by training on two sets of noisy signals with identical statistical distributions. When evaluated on Rydberg sensing datasets, the framework outperforms wavelet transform and Kalman filtering, achieving a denoising effect equivalent to 10,000-set averaging while reducing computation time by three orders of magnitude. We further validate performance across diverse noise profiles and quantify the complexity-performance trade-off of U-Net and Transformer architectures, providing actionable guidance for optimizing deep learning-based denoising in Rydberg sensor systems.

</details>


### [210] [On the homogeneity of the quantum transition probability](https://arxiv.org/abs/2601.01936)
*Gerd Niestegge*

Main category: quant-ph

TL;DR: 论文揭示了量子力学跃迁概率在简单欧几里得约当代数中的物理意义，证明了这些代数中的跃迁概率具有最大同质性，包括常见的有限维希尔伯特空间量子理论。


<details>
  <summary>Details</summary>
Motivation: 研究H.-C. Wang和U. Hirzebruch在1952年和1965年关于两点齐次紧致空间与凸度量的数学成果的物理意义，特别是这些成果与量子力学跃迁概率的关系。

Method: 通过分析简单欧几里得约当代数中的跃迁概率特性，研究其同质性程度，并探讨这些代数的原子部分或状态空间极端边界如何通过纯拓扑方法表征。

Result: 证明了简单欧几里得约当代数中的跃迁概率具有最大同质性，这包括了有限维希尔伯特空间量子理论。同时发现当使用E6对称双八元数射影平面作为量子逻辑时，会出现非齐次跃迁概率的有趣情况。

Conclusion: 该研究为Wang和Hirzebruch的数学成果提供了量子力学解释，揭示了简单欧几里得约当代数中跃迁概率的独特同质性特性，并指出了与许多其他区分凸紧致集中状态空间方法的重要差异。

Abstract: In the years 1952 and 1965, H.-C. Wang and U. Hirzebruch showed that the two-point homogeneous compact spaces with convex metrics are isometric to the spheres, the real, complex, octonion projective spaces and the Moufang plane and as well to the sets of the minimal idempotents or pure states in the simple Euclidean Jordan algebras. Here we reveal the physical meaning of these mathematical achievements for the quantum mechanical transition probability. We show that this transition probability features a maximum degree of homogeneity in all simple Euclidean Jordan algebras, which includes common finite-dimensional Hilbert space quantum theory. The atomic parts of these algebras or, equivalently, the extreme boundaries of their state spaces can be characterized by purely topological means. This is an important difference to many other recent approaches that aim to distinguish the entire state spaces among the convex compact sets. An interesting case with non-homogeneous transition probability arises, when the $E_6$-symmetric bioctonionic projective plane is used as quantum logic.

</details>


### [211] [Discrete symmetries in classical and quantum oscillators](https://arxiv.org/abs/2601.01960)
*Alexander D. Popov*

Main category: quant-ph

TL;DR: 论文通过谐振子示例探讨波函数本质，证明Bargmann-Fock-Segal表示中的本征函数ψ_n=z^n对应经典谐振子能量E_n=ħωn，这些函数定义在锥形空间ℂ/ℤ_n上，本征函数叠加仅在不完全了解初始数据时出现。


<details>
  <summary>Details</summary>
Motivation: 探讨量子力学波函数的本质，特别是通过谐振子这一基本物理系统来理解波函数的几何和代数结构，以及量子态与经典系统之间的对应关系。

Method: 使用Bargmann-Fock-Segal复表示方法，分析谐振子的本征函数ψ_n=z^n，研究这些函数在锥形空间ℂ/ℤ_n上的几何结构，其中ℤ_n是旋转角度2π/n的有限循环群，并考虑离散对称群不变性条件。

Result: 证明量子谐振子的本征函数ψ_n=z^n对应经典谐振子能量E_n=ħωn，这些函数定义在锥角为2π/n的锥形空间ℂ/ℤ_n上，本征函数的叠加ψ=∑c_nψ_n仅在对薛定谔方程初始数据不完全了解时出现。

Conclusion: 波函数具有明确的几何解释，量子谐振子的本征函数对应经典谐振子的特定能量状态，且定义在具有离散对称性的锥形空间上，波函数的叠加源于对初始数据的不完全了解。

Abstract: We consider the nature of the wave function using the example of a harmonic oscillator. We show that the eigenfunctions $ψ_n{=}z^n$ of the quantum Hamiltonian in the complex Bargmann-Fock-Segal representation with $z\in\mathbb C$ are the coordinates of a classical oscillator with energy $E_n=\hbarωn$, $n=0,1,2,...\,$. They are defined on conical spaces ${\mathbb C}/{\mathbb Z}_n$ with cone angles $2π/n$, which are embedded as subspaces in the phase space $\mathbb C$ of the classical oscillator. Here ${\mathbb Z}_n$ is the finite cyclic group of rotations of the space $\mathbb C$ by an angle $2π/n$. The superposition $ψ=\sum_n c_nψ_n$ of the eigenfunctions $ψ_n$ arises only with incomplete knowledge of the initial data for solving the Schrödinger equation, when the conditions of invariance with respect to the discrete groups ${\mathbb Z}_n$ are not imposed and the general solution takes into account all possible initial data parametrized by the numbers $n\in\mathbb N$.

</details>


### [212] [Experimental realization of quantum Zeno dynamics for robust quantum metrology](https://arxiv.org/abs/2601.01987)
*Ran Liu,Xiaodong Yang,Xiang Lv,Xinyue Long,Hongfeng Liu,Dawei Lu,Ying Dong,Jun Li*

Main category: quant-ph

TL;DR: 该研究提出了一种利用量子芝诺动力学进行鲁棒量子计量学的方法，通过引入强粒子间相互作用克服了传统方法的限制，在核磁共振平台上实现了接近最优的精度标度。


<details>
  <summary>Details</summary>
Motivation: 量子芝诺动力学通过限制系统演化到受保护子空间，为保护量子信息免受噪声影响提供了有前景的方法。然而，先前的研究主要关注单粒子系统，面临量子芝诺动力学可能干扰参数编码过程的挑战。本研究旨在探索利用量子芝诺动力学进行鲁棒量子计量的实用方法。

Method: 通过在参数编码阶段引入强粒子间相互作用来克服传统量子芝诺动力学方法的限制。在核磁共振平台上进行实验验证，并在并行和顺序设置下测试振幅阻尼噪声下的性能。通过数值模拟进一步验证方法的可扩展性及其与其他控制技术的兼容性。

Result: 实验在核磁共振平台上实现了接近最优的精度标度，在振幅阻尼噪声下的并行和顺序设置中都表现出色。数值模拟表明该方法具有良好的可扩展性，并且能够与其他控制技术兼容以抑制更一般的噪声类型。

Conclusion: 该研究证明了量子芝诺动力学作为噪声弹性量子计量的强大策略，通过引入强相互作用克服了传统方法的限制，为实现鲁棒的量子计量提供了实用途径。

Abstract: Quantum Zeno dynamics (QZD), which restricts the system's evolution to a protected subspace, provides a promising approach for protecting quantum information from noise. Here, we explore a practical approach to harnessing QZD for robust quantum metrology. By introducing strong inter-particle interactions during the parameter encoding stage, we overcome the typical limitations of previous QZD studies, which have largely focused on single-particle systems and faced challenges where QZD could interfere with the encoding process. We experimentally validate the proposed scheme on a nuclear magnetic resonance platform, achieving near-optimal precision scaling under amplitude damping in both parallel and sequential settings. Numerical simulations further demonstrate the scalability of the approach and its compatibility with other control techniques for suppressing more general types of noise. These findings highlight QZD as a powerful strategy for noise-resilient quantum metrology.

</details>


### [213] [Continuous Unitary Designs for Universally Robust Quantum Control](https://arxiv.org/abs/2601.01988)
*Xiaodong Yang,Jiaqing Leng,Jun Li*

Main category: quant-ph

TL;DR: 该论文开创性地研究了连续酉设计，构建了从球面2-设计曲线和Hopf纤维化的单量子比特系统酉1-设计路径，并开发了基于拓扑丛理论和海森堡-外尔群的通用构建框架，为量子控制提供了抗噪声的解析解。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注离散酉设计，但许多物理过程（如量子混沌、热化和控制）自然涉及连续时间演化产生的连续系综。论文旨在填补这一空白，研究连续酉设计的构建和实际应用价值。

Method: 1. 对于单量子比特系统：基于球面2-设计曲线和Hopf纤维化理论构建显式的酉1-设计路径。2. 对于任意维度：开发两个系统构建框架：基于酉群拓扑丛理论的方法和基于海森堡-外尔群的方法。

Result: 构建的酉设计路径为通用鲁棒量子控制提供了解析解。仿真显示，在抑制任意未知静态噪声方面，这些路径优于传统脉冲技术，展示了在量子工程中的直接应用价值。

Conclusion: 将酉设计扩展到连续域不仅引入了强大的几何和拓扑工具来补充传统的组合和群论方法，而且比通常涉及瞬时脉冲的离散对应物更具实验可行性。这项工作为使用连续酉设计探索复杂量子动力学和设计量子信息协议铺平了道路。

Abstract: Unitary designs are unitary ensembles that emulate Haar-random unitary statistics. They provide a vital tool for studying quantum randomness and have found broad applications in quantum technologies. However, existing research has focused on discrete ensembles, despite that many physical processes, such as in quantum chaos, thermalization, and control, naturally involve continuous ensembles generated from continuous time-evolution. Here we initial the study of continuous unitary designs, addressing fundamental questions about their construction and practical utility. For single-qubit system, we construct explicit unitary 1-design paths from spherical 2-design curves and Hopf fibration theory. For arbitrary dimensions, we develop two systematic construction frameworks, one based on topological bundle theory of the unitary group and the other based on the Heisenberg-Weyl group. On the practical front, our unitary design paths provide analytical solutions to universally robust quantum control. Simulations show they outperform conventional pulse techniques in mitigating arbitrary unknown static noises, demonstrating immediate utility for quantum engineering. Extending unitary designs to the continuous domain not only introduces powerful geometric and topological tools that complement conventional combinatorial and group-theoretic methods, but also enhances experimental feasibility over discrete counterparts which usually involve instantaneous pulses. As an outlook, we anticipate that this work will pave the way for using continuous unitary designs to explore complex quantum dynamics and devise quantum information protocols.

</details>


### [214] [Parallel Quantum Gates via Scalable Subsystem-Optimized Robust Control](https://arxiv.org/abs/2601.01990)
*Xiaodong Yang,Ran Liu,Jun Li*

Main category: quant-ph

TL;DR: 该论文提出了一种可扩展的并行量子控制方法，通过将全系统优化简化为对恒定大小子系统的串扰鲁棒控制，显著降低计算成本，有效消除串扰引起的门操作偏差，实现从指数到线性的噪声缩放改善。


<details>
  <summary>Details</summary>
Motivation: 当前量子处理器中不可避免的量子比特间串扰阻碍了高保真度量子门的实现，且全希尔伯特空间控制优化计算成本过高，难以实现可扩展的量子信息处理。

Method: 将全系统优化简化为对恒定大小子系统的串扰鲁棒控制，显著降低计算复杂度。该方法构建了并行单量子比特门的解析脉冲解和并行多量子比特操作的数值脉冲，不需要精确的串扰强度知识，也不对底层量子比特连接性或晶格几何结构做假设。

Result: 在多个平台上进行了数值验证，包括耦合氮空位中心、核自旋处理器和最多200个量子比特的超导量子比特阵列。并行单量子比特门的噪声缩放从指数降低到线性，并行多量子比特门的误差降低了一个数量级。

Conclusion: 该方法建立了一个可扩展的并行量子控制框架，适用于大规模量子架构，为可扩展量子信息处理提供了有效的解决方案。

Abstract: Accurate and efficient implementation of parallel quantum gates is crucial for scalable quantum information processing. However, the unavoidable crosstalk between qubits in current noisy processors impedes the achievement of high gate fidelities and renders full Hilbert-space control optimization prohibitively difficult. Here, we overcome this challenge by reducing the full-system optimization to crosstalk-robust control over constant-sized subsystems, which dramatically reduces the computational cost. Our method effectively eliminates the leading-order gate operation deviations induced by crosstalk, thereby suppressing error rates. Within this framework, we construct analytical pulse solutions for parallel single-qubit gates and numerical pulses for parallel multi-qubit operations. We validate the proposed approach numerically across multiple platforms, including coupled nitrogen-vacancy centers, a nuclear-spin processor, and superconducting-qubit arrays with up to 200 qubits. As a result, the noise scaling is reduced from exponential to linear for parallel single-qubit gates, and an order-of-magnitude reduction is achieved for parallel multi-qubit gates. Moreover, our method does not require precise knowledge of crosstalk strengths and makes no assumption about the underlying qubit connectivity or lattice geometry, thereby establishing a scalable framework for parallel quantum control in large-scale quantum architectures.

</details>


### [215] [Absolutely Maximal Contextual Correlations](https://arxiv.org/abs/2601.02009)
*Nripendra Majumdar,S. Aravinda*

Main category: quant-ph

TL;DR: 该论文研究量子多体系统中的最大关联性，类比纠缠理论中的最大纠缠态，使用层论框架定义上下文分数，提出绝对最大上下文关联概念，并应用于秘密共享和随机性提取。


<details>
  <summary>Details</summary>
Motivation: 受Bell非定域性工作的启发，研究多体系统中类似最大纠缠态的最大关联性，为量子信息处理提供理论基础。

Method: 采用层论框架分析上下文性，定义上下文分数度量，提出绝对最大上下文关联概念，使用奇偶校验方法和约束满足问题方案构造无限族AMCC。

Result: 构建了二部PR盒和三部扩展的AMCC无限族，发现了非AMCC的最大上下文关联，并将结果应用于秘密共享和随机性提取。

Conclusion: 成功建立了多体系统中最大关联性的理论框架，类比纠缠理论，为量子信息应用提供了新的工具和资源。

Abstract: The foundational work by Bell led to an interest in understanding non-local correlations that arise from entangled states shared between distinct, spacelike-separated parties, which formed a foundation for the theory of quantum information processing. We investigate the question of maximal correlations analogous to the maximally entangled states defined in the entanglement theory of multipartite systems. To formalize this, we employ the sheaf-theoretic framework for contextuality, which generalizes non-locality. This provides a new metric for correlations called contextual fraction (CF), which ranges from 0 (non-contextual) to 1 (maximally contextual). Using this, we have defined the absolutely maximal contextual correlations (AMCC), which are maximally contextual and have maximal marginals, which captures the notion of absolutely maximal entangled (AME) states. The Popescu-Rohrlich (PR) box serves as the bipartite example, and we construct various extensions of such correlations in the tripartite case. An infinite family of various forms of AMCC is constructed using the parity check method and the constraint satisfiability problem (CSP) scheme. We also demonstrate the existence of maximally contextual correlations, which do not exhibit maximal marginals, and refer to them as non-AMCC. The results are further applied to secret sharing and randomness extraction using AMCC correlations.

</details>


### [216] [Integrating Quantum Software Tools with(in) MLIR](https://arxiv.org/abs/2601.02062)
*Patrick Hopf,Erick Ochoa Lopez,Yannick Stade,Damian Rovara,Nils Quetschlich,Ioan Albert Florea,Josh Izaac,Robert Wille,Lukas Burgholzer*

Main category: quant-ph

TL;DR: 本文为量子软件工程师提供MLIR实用指南，通过PennyLane与MQT集成案例，帮助克服MLIR学习曲线，促进量子软件工具互操作性


<details>
  <summary>Details</summary>
Motivation: 量子编译仍处于初级阶段，现有解决方案多为临时性且缺乏互操作性，导致量子软件工具孤立。MLIR在经典计算领域解决了类似问题，但其陡峭学习曲线阻碍了在量子计算领域的应用

Method: 通过Xanadu的PennyLane框架与慕尼黑量子工具包(MQT)的具体案例研究，提供可操作的集成步骤、最佳实践和实际开发经验

Result: 提供了克服MLIR学习曲线的实用指南，展示了量子软件工具集成的具体方法，为开发模块化、可互操作的量子软件栈奠定基础

Conclusion: MLIR可作为统一桥梁连接快速增长的量子软件生态系统，本文旨在支持量子工具开发者应对MLIR复杂性，促进更模块化、可互操作和集成的量子软件栈发展

Abstract: Compilers transform code into action. They convert high-level programs into executable hardware instructions - a crucial step in enabling reliable and scalable quantum computation. However, quantum compilation is still in its infancy, and many existing solutions are ad hoc, often developed independently and from scratch. The resulting lack of interoperability leads to significant missed potential, as quantum software tools remain isolated and cannot be seamlessly integrated into cohesive toolchains.
  The Multi-Level Intermediate Representation (MLIR) has addressed analogous challenges in the classical domain. It was developed within the LLVM project, which has long powered robust software stacks and enabled compilation across diverse software and hardware components, with particular importance in high-performance computing environments. However, MLIR's steep learning curve poses a significant barrier to entry, particularly in quantum computing, where much of the software stack is still predominantly built by experimentalists out of necessity rather than by experienced software engineers.
  This paper provides a practical and hands-on guide for quantum software engineers to overcome this steep learning curve. Through a concrete case study linking Xanadu's PennyLane framework with the Munich Quantum Toolkit (MQT), we outline actionable integration steps, highlight best practices, and share hard-earned insights from real-world development. This work aims to support quantum tool developers in navigating MLIR's complexities and to foster its adoption as a unifying bridge across a rapidly growing ecosystem of quantum software tools, ultimately guiding the development of more modular, interoperable, and integrated quantum software stacks.

</details>


### [217] [Cutting Quantum Circuits Beyond Qubits](https://arxiv.org/abs/2601.02064)
*Manav Seksaria,Anil Prabhakar*

Main category: quant-ph

TL;DR: 该论文将量子电路切割技术扩展到包含混合维度量子比特的异构寄存器，通过分解非局域相互作用为局部广义Gell-Mann矩阵的张量积，实现高维量子电路在断开硬件片段上的模拟和执行。


<details>
  <summary>Details</summary>
Motivation: 传统量子电路切割技术主要针对同质量子比特系统，而实际量子硬件可能包含不同维度的量子比特（qudits）。为了在异构量子硬件上高效执行高维量子电路，需要扩展电路切割技术以处理混合维度的量子寄存器。

Method: 通过将非局域相互作用分解为局部广义Gell-Mann矩阵的张量积，将高维量子电路切割成可以在断开硬件片段上执行的子电路。该方法特别针对qubit-qutrit（2-3维）接口进行了验证。

Result: 在qubit-qutrit接口上实现了精确状态重构，总变差距离为0（在单精度浮点容差范围内）。在8粒子、维度8的系统中展示了内存优势，将每个电路的内存使用从128MB减少到64KB。

Conclusion: 该框架成功将量子电路切割扩展到异构量子寄存器，为在混合维度量子硬件上执行高维量子电路提供了有效方法，显著减少了内存需求，为实际量子计算应用提供了重要工具。

Abstract: We extend quantum circuit cutting to heterogeneous registers comprising mixed-dimensional qudits. By decomposing non-local interactions into tensor products of local generalised Gell-Mann matrices, we enable the simulation and execution of high-dimensional circuits on disconnected hardware fragments. We validate this framework on qubit--qutrit ($2$--$3$) interfaces, achieving exact state reconstruction with a Total Variation Distance of 0 within single-precision floating-point tolerance. Furthermore, we demonstrate the memory advantage in an 8-particle, dimension-8 system, reducing memory usage from 128 MB to 64 KB per circuit.

</details>


### [218] [Optimization of modulation transfer protocol for Rydberg RF receivers](https://arxiv.org/abs/2601.02070)
*Mickael Branco,K V Adwaith,Duc-Anh Trinh,Sacha Welinski,Perrine Berger,Fabienne Goldfarb,Fabien Bretenaker*

Main category: quant-ph

TL;DR: 该研究探索了基于热里德堡原子的量子射频接收器带宽扩展的调制转移协议，通过耦合光束的相位调制转化为探测光束的幅度调制，优化了调制参数并提升了检测带宽。


<details>
  <summary>Details</summary>
Motivation: 扩展基于热里德堡原子的量子射频接收器的检测带宽，解决传统协议在射频信号失谐较大时灵敏度下降的问题。

Method: 开发理论模型优化耦合光束的调制频率和调制幅度，通过相位调制转化为幅度调制的调制转移协议，并与传统协议进行实验对比。

Result: 优化后的调制转移协议在射频信号失谐超过几MHz时优于传统协议，显著提高了检测带宽，实验结果与模拟结果吻合良好。

Conclusion: 调制转移协议为增加量子射频接收器检测带宽提供了互补方法，在失谐射频信号检测方面具有优势，理论与实验一致性验证了该方法的有效性。

Abstract: We explore theoretically and experimentally the recently demonstrated modulation transfer protocol [D.-A. Trinh, K. V. Adwaith, M. Branco, A. Rouxel, S. Welinski, P. Berger, F. Goldfarb, and F. Bretenaker, Applied Physics Letters 125, 154001 (2024)] aiming at extending the bandwidth of quantum RF receivers based on hot Rydberg atoms. This protocol is based on a phase modulation of the coupling beam, which is transformed by the nonlinear response of the atoms into an amplitude modulation of the probe beam. We develop a theoretical model to optimize both the modulation frequency and the modulation amplitude of the coupling beam, thereby maximizing the atomic response. Once optimized, the sensitivity to detuned RF fields of this modulation transfer protocol is compared with that of the conventional protocol. This comparison shows that the new protocol outperforms the usual one as soon as the RF signal to be measured is detuned by more than a few MHz and offers a complementary approach to increase the detection bandwidth. In all cases, the experimental results are in good agreement with the simulations.

</details>


### [219] [Flux-noise-resilient transmon qubit via a doubly-connected gradiometric design](https://arxiv.org/abs/2601.02137)
*J. B. Fu,Da-Wei Wang,B. Ren,Z. H. Yang,S. Hu,G. Y. Huang,S. H. Cao,D. D. Liu,X. F. Zhang,X. Fu,S. C. Xue,Y. G. Che,Yu-xi Liu,M. T. Deng,J. J. Wu*

Main category: quant-ph

TL;DR: 提出了一种新型梯度计型transmon量子比特（8-mon），通过纳米空气桥连接两个环路，在保持电调谐性的同时显著抑制低频磁通噪声，实现了接近T1的T2*相干时间，无需回波解耦。


<details>
  <summary>Details</summary>
Motivation: 传统频率可调的超导transmon量子比特对低频磁通噪声敏感，这会降低量子处理器的性能。需要一种既能保持电调谐性又能抑制磁通噪声的设计方案。

Method: 设计了双连接梯度计型transmon（8-mon），采用纳米空气桥连接两个环路。该设计保持完全的电调谐性，与标准X-mon控制和读取兼容，无需额外测量开销。空气桥连接消除了介电损耗。

Result: 8-mon实现了与参考X-mons相当的T1弛豫时间，在小磁通偏置区域，Ramsey相干时间T2*提高了近三倍。改进后的T2*达到与T1相同的数量级，无需回波解耦。器件在无磁场屏蔽下也表现出优异的长期频率稳定性。

Conclusion: 通过空间相关磁通噪声模型的模拟定量再现了实验相干趋势，揭示了超导芯片环境中短程和长程相关磁噪声的共存。8-mon通过稳健的几何设计将高调谐性与固有磁通噪声抑制相结合，为实现更相干和稳定的超导量子处理器提供了实用途径。

Abstract: Frequency-tunable superconducting transmon qubits are a cornerstone of scalable quantum processors, yet their performance is often degraded by sensitivity to low-frequency flux noise. Here we present a doubly-connected gradiometric transmon (the ``8-mon") that incorporates a nano-airbridge to link its two loops. This design preserves full electrical tunability and remains fully compatible with standard X-mon control and readout, requiring no additional measurement overhead. The airbridge interconnect eliminates dielectric loss, which enables the 8-mon to achieve both energy relaxation times $T_{\rm 1}$ comparable to reference X-mons and, in the small flux-bias regime, a nearly threefold enhancement in Ramsey coherence time $T_{\rm 2}^*$. This improved $T_{\rm 2}^*$ reaches the same order as $T_{\rm 1}$ without employing echo decoupling. The device also exhibits superior long-term frequency stability even without any magnetic field shielding. We develop a spatially correlated flux-noise model whose simulations quantitatively reproduce the experimental coherence trends, revealing the coexistence of short- and long-correlation-length magnetic noise in the superconducting chip environment. By unifying high tunability with intrinsic flux-noise suppression through a robust geometric design, the 8-mon provides a practical pathway toward more coherent and stable superconducting quantum processors.

</details>


### [220] [Quantum Extreme Reservoir Computing for Phase Classification of Polymer Alloy Microstructures](https://arxiv.org/abs/2601.02150)
*Arisa Ikeda,Akitada Sakurai,Kae Nemoto,Mayu Muramatsu*

Main category: quant-ph

TL;DR: 该研究将量子极端储层计算应用于聚合物合金微观结构图像分类，探索量子机器学习在材料科学中的实际应用，而非仅关注基准数据集。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习有望利用量子系统的指数级状态空间高效处理高维数据，但先前研究主要关注MNIST等基准数据集，缺乏对具有直接材料相关性的工程数据的应用探索。

Method: 采用量子极端储层计算(QERC)方法，应用于自洽场理论生成的聚合物合金微观结构图像分类。通过数值实验研究关键计算参数的影响，包括量子比特数量、采样成本（测量次数）和储层配置。

Result: 研究结果以相图形式展示聚合物形态的相变，建立了量子模型输出与材料行为之间的可理解联系。为量子编码器设计和模型泛化提供了实用指导。

Conclusion: 该工作展示了QERC在真实材料数据集上的性能，为将量子学习技术整合到材料信息学中奠定了基础。

Abstract: Quantum machine learning (QML) is expected to offer new opportunities to process high-dimensional data efficiently by exploiting the exponentially large state space of quantum systems. In this work, we apply quantum extreme reservoir computing (QERC) to the classification of microstructure images of polymer alloys generated using self-consistent field theory (SCFT). While previous QML efforts have primarily focused on benchmark datasets such as MNIST, our work demonstrates the applicability of QERC to engineering data with direct materials relevance. Through numerical experiments, we examine the influence of key computational parameters-including the number of qubits, sampling cost (the number of measurement shots), and reservoir configuration-on classification performance. The resulting phase classifications are depicted as phase diagrams that illustrate the phase transitions in polymer morphology, establishing an understandable connection between quantum model outputs and material behavior. These results illustrate QERC performance on realistic materials datasets and suggest practical guidelines for quantum encoder design and model generalization. This work establishes a foundation for integrating quantum learning techniques into materials informatics.

</details>


### [221] [Optical nonlinearity of cold atomic ensemble driven by strong coherent field in a saturation regime](https://arxiv.org/abs/2601.02152)
*A. S. Usoltsev,L. V. Gerasimov,A. D. Manukhova,S. P. Kulik,D. V. Kupriyanov*

Main category: quant-ph

TL;DR: 论文通过微观分析研究由矢量型二能级原子组成的介电介质在强相干场驱动下的介电响应，发现高密度介质中光学非线性（特别是参量部分）可通过操纵泵浦和样品密度显著增强，这对利用参量过程产生纠缠光子的量子通信协议提出了限制。


<details>
  <summary>Details</summary>
Motivation: 研究介电介质中矢量型二能级原子在强相干场驱动下的介电响应特性，探索从稀薄原子气体到稠密介质中集体动力学的变化规律，特别是光学非线性效应的增强机制及其对量子通信协议的影响。

Method: 采用微观分析方法，研究由矢量型二能级原子组成的介电介质。在稀薄原子气体极限下，每个原子的动力学遵循Mollow型非线性激发机制，介质极化率将个体原子对探测模式的响应集体化。通过插值方法将集体动力学推广到稠密介质。

Result: 在稠密介质中，光学非线性（特别是其参量部分）可以通过操纵相干泵浦和样品密度显著增强。这种增强对利用参量过程产生纠缠光子作为量子关联主要资源的量子通信协议的潜在能力提出了限制。

Conclusion: 介电介质中光学非线性效应在稠密条件下显著增强，这对基于参量过程产生纠缠光子的量子通信协议构成了重要限制，需要在协议设计中考虑介质密度和泵浦条件的影响。

Abstract: We present a microscopic analysis and evaluation of the dielectric susceptibility of a dielectric medium consisting of vector-type two-energy-level atoms responding on a weak probe mode when the atoms are driven by a strong coherent field. Each atom, in an environment of others, exists as a quasiparticle further structuring a bulk medium. In a limit of dilute atomic gas, the dynamics of each atom follows the Mollow-type nonlinear excitation regime, and the medium susceptibility collectivizes the individual atomic responses to the probe mode. We outline how the collective dynamics can be interpolated up to a dense medium, and we argue from general positions that in such a medium the optical nonlinearity and, in particular, its parametric part could be significantly magnified by manipulating both the coherent pump and the sample density. That indicates certain limitations for potential capabilities of quantum communication protocols utilizing the entangled photons, created by a parametric process, as a main resource of quantum correlations.

</details>


### [222] [Developments in superconducting erasure qubits for hardware-efficient quantum error correction](https://arxiv.org/abs/2601.02183)
*Maria Violaris,Luciana Henaut,James Wills,Gioele Consani,Jamie Friel,Brian Vlastakis*

Main category: quant-ph

TL;DR: 该论文探讨了擦除量子比特在量子纠错中的应用，重点关注超导量子比特实现的双轨编码擦除量子比特，旨在实现硬件高效的量子纠错。


<details>
  <summary>Details</summary>
Motivation: 量子计算机本质上是嘈杂的，实现大规模容错量子计算的关键挑战在于实施量子纠错。通过设计具有特定噪声特性的硬件，可以显著提高某些量子纠错码的噪声阈值。

Method: 采用擦除量子比特方法，通过将硬件内置的内层编码与外部编码级联，实现硬件高效的量子纠错。重点关注超导量子比特实现的双轨编码擦除量子比特。

Result: 综述了理论和模拟的最新进展以及硬件演示器，讨论了不同实现方式的差异，并探讨了使用量子错误检测的近期应用。

Conclusion: 擦除量子比特为实现早期容错量子计算机提供了有前景的方向，但仍需解决开放性问题以进一步发展该方法。

Abstract: Quantum computers are inherently noisy, and a crucial challenge for achieving large-scale, fault-tolerant quantum computing is to implement quantum error correction. A promising direction that has made rapid recent progress is to design hardware that has a specific noise profile, leading to a significantly higher threshold for noise with certain quantum error correcting codes. This Perspective focuses on erasure qubits, which enable hardware-efficient quantum error correction, by concatenating an inner code built-in to the hardware with an outer code. We focus on implementations of dual-rail encoded erasure qubits using superconducting qubits, giving an overview of recent developments in theory and simulation, and hardware demonstrators. We also discuss the differences between implementations; near-term applications using quantum error detection; and the open problems for developing this approach towards early fault-tolerant quantum computers.

</details>


### [223] [PauliEngine: High-Performant Symbolic Arithmetic for Quantum Operations](https://arxiv.org/abs/2601.02233)
*Leon Müller,Adelina Bärligea,Alexander Knapp,Jakob S. Kottmann*

Main category: quant-ph

TL;DR: PauliEngine是一个高性能C++框架，用于高效处理泡利字符串操作，为量子软件提供可扩展的后端支持。


<details>
  <summary>Details</summary>
Motivation: 量子计算本质上是混合的，需要快速经典操作量子比特算符来确保量子软件的可扩展性。现有实现性能不足，需要更高效的泡利字符串处理工具。

Method: 基于二进制辛表示和优化的位操作，提供泡利字符串乘法、对易子、符号相位跟踪和结构变换等高效原语。支持数值和符号系数，并通过Python接口访问。

Result: 运行时基准测试显示相比最先进实现有显著加速。PauliEngine为基于算符的量子软件工具和模拟提供了可扩展的后端。

Conclusion: PauliEngine是一个高性能框架，通过优化的泡利字符串操作原语解决了量子软件可扩展性的关键瓶颈，为量子计算工具链提供了重要基础设施。

Abstract: Quantum computation is inherently hybrid, and fast classical manipulation of qubit operators is necessary to ensure scalability in quantum software. We introduce PauliEngine, a high-performance C++ framework that provides efficient primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations. Built on a binary symplectic representation and optimized bit-wise operations, PauliEngine supports both numerical and symbolic coefficients and is accessible through a Python interface. Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. PauliEngine provides a scalable backend for operator-based quantum software tools and simulations.

</details>


### [224] [A General Class of Functionals for Certifying Quantum Incompatibility](https://arxiv.org/abs/2601.02239)
*Kuan-Yi Lee,Jhen-Dong Lin,Adam Miranowicz,Yueh-Nan Chen*

Main category: quant-ph

TL;DR: 提出基于凸泛函的优化自由非线性不相容性见证框架，适用于任意维度，能检测量子导引、测量不相容和仪器不相容


<details>
  <summary>Details</summary>
Motivation: 量子导引、测量不相容和仪器不相容被统一视为量子不相容性的表现，需要发展通用框架来检测这些现象

Method: 基于凸泛函构建优化自由非线性不相容性见证，证明当泛函在极值点（如纯态）上非仿射时见证非平凡，适用于任意维度

Result: 对于纯双体态，见证给出纠缠度下界，优于多数线性导引不等式；见证可作为真正的不相容性单调量，适用于测量和仪器不相容认证

Conclusion: 该框架具有通用性，通过Wigner-Yanase偏信息和ℓ₂型相干泛函等操作相关泛函展示了其多功能性

Abstract: Quantum steering, measurement incompatibility, and instrument incompatibility have recently been recognized as unified manifestations of quantum incompatibility. Building on this perspective, we develop a general framework for constructing optimization-free, nonlinear incompatibility witnesses based on convex functionals, valid in arbitrary dimensions. We prove that these witnesses are nontrivial precisely when the underlying functional is non-affine on extremal points (e.g., pure states for ensembles). For pure bipartite states, the witnesses yield lower bounds on entanglement measures, thereby outperforming most linear steering inequalities in the pure-state regime. Moreover, the construction extends in full generality to certify measurement and instrument incompatibility, where the witnesses act as genuine incompatibility monotones. We demonstrate the versatility of our approach with two operationally relevant functionals: the Wigner-Yanase skew information and an $\ell_{2}$-type coherence functional.

</details>


### [225] [Topological Obstructions for Quantum Adiabatic Algorithms: Evidence from MaxCut Instances](https://arxiv.org/abs/2601.02255)
*Prathamesh S. Joshi*

Main category: quant-ph

TL;DR: 量子绝热算法在退化解流形优化问题中存在全局谱流约束，即使算法成功概率高，退化性也会强制谱带交互、编织和置换，形成拓扑障碍。


<details>
  <summary>Details</summary>
Motivation: 传统量子绝热算法分析主要关注局部谱特性（如最小能隙），但这种方法无法完全描述具有退化解流形的优化问题中的全局谱演化结构。研究者希望揭示退化性如何对谱流施加不可避免的全局约束。

Method: 聚焦于数字化量子绝热演化，分析沿插值路径生成的累积酉算子的本征相位。通过显式跟踪本征相位轨迹，研究多个谱带如何被迫交互、编织和置换，最终在演化结束时合并为退化流形。使用具有受控退化性的MaxCut实例作为具体场景，提取谱拥塞的定量诊断并计算诱导的谱带置换。

Result: 研究表明，成功的绝热优化可以与复杂且受约束的谱流共存。退化性强制谱带在演化过程中交互、编织和置换，形成持续的谱拥塞和非平凡的谱带置换，这些现象无法通过增加演化时间或细化数字化来消除。这些谱流约束源于本征态的全局连通性而非局部能隙闭合。

Conclusion: 退化优化问题中存在基于全局谱流的拓扑障碍，这超出了传统基于能隙的分析范畴。研究结果强调了基于能隙分析的固有局限性，并提出了基于谱流的诊断方法来理解退化优化景观中的绝热算法。

Abstract: Quantum adiabatic algorithms are commonly analyzed through local spectral properties of an interpolating Hamiltonian, most notably the minimum energy gap. While this perspective captures an important constraint on adiabatic runtimes, it does not fully describe the global structure of spectral evolution in optimization problems with degenerate solution manifolds. In this work, we show that degeneracy alone imposes unavoidable global constraints on spectral flow, even in instances where adiabatic algorithms succeed with high probability. Focusing on digitized quantum adiabatic evolutions, we analyze the eigenphases of the cumulative unitary operator generated along the interpolation path. By explicitly tracking eigenphase trajectories, we demonstrate that multiple spectral bands are forced to interact, braid, and permute before coalescing into a degenerate manifold at the end of the evolution. This global reordering manifests as persistent spectral congestion and nontrivial band permutations that cannot be removed by increasing evolution time or refining the digitization. Using MaxCut instances with controlled degeneracy as a concrete setting, we extract quantitative diagnostics of spectral congestion and explicitly compute the induced band permutations. Our results show that successful adiabatic optimization can coexist with complex and constrained spectral flow, revealing a form of topological obstruction rooted in the global connectivity of eigenstates rather than in local gap closures. These findings highlight intrinsic limitations of gap-based analyses and motivate spectral-flow-based diagnostics for understanding adiabatic algorithms in degenerate optimization landscapes.

</details>


### [226] [Schwarz maps with symmetry](https://arxiv.org/abs/2601.02282)
*Alfonso García-Velo,Alberto Ibort*

Main category: quant-ph

TL;DR: 该论文将量子力学对称性理论应用于量子信息论中的CPTP、PPT和Schwarz映射研究，系统分析了具有酉群对称性的映射结构，并给出了完全分类和参数区域描述。


<details>
  <summary>Details</summary>
Motivation: 研究量子信息论中重要映射类（CPTP、PPT和Schwarz映射）的结构和性质，探索群对称性如何控制非完全正映射的结构，为PPT²猜想提供新的具体例证。

Method: 首先发展C*-代数间等变映射的一般结构，然后系统研究在自然酉群作用下保持单位性和厄米性的等变映射。对U(n)-等变映射进行完全分类，并对较弱的DU(n)-等变和张量积对称性进行部分分类。

Result: 完全分类了M_n(C)上的U(n)-等变映射，确定了完全正和Schwarz映射的参数区域。发现U(n)-等变族满足PPT⇔EB，而DU(2)、对称DU(3)、U(2)⊗U(2)和U(2)⊗U(3)族通过直接对称性论证满足PPT²猜想。

Conclusion: 群对称性显著控制着非完全正映射的结构，研究结果为理解量子信息论中重要映射类的性质提供了新视角，并为PPT²猜想提供了新的具体支持例证。

Abstract: The theory of symmetry of quantum mechanical systems is applied to study the structure and properties of several classes of relevant maps in quantum information theory: CPTP, PPT and Schwarz maps. First, we develop the general structure that equivariant maps $Φ:\mathcal A \to \mathcal B$ between $C^\ast$-algebras satisfy. Then, we undertake a systematic study of unital, Hermiticity-preserving maps that are equivariant under natural unitary group actions. Schwarz maps satisfy Kadison's inequality $Φ(X^\ast X) \geq Φ(X)^\ast Φ(X)$ and form an intermediate class between positive and completely positive maps. We completely classify $U(n)$-equivariant on $M_n(\mathbb C)$ and determine those that are completely positive and Schwarz. Partial classifications are then obtained for the weaker $DU(n)$-equivariance (diagonal unitary symmetry) and for tensor-product symmetries $U(n_1) \otimes U(n_2)$. In each case, the parameter regions where $Φ$ is Schwarz or completely positive are described by explicit algebraic inequalities, and their geometry is illustrated. Finally, we further show that the $U(n)$-equivariant family satisfies $\mathrm{PPT} \iff \mathrm{EB}$, while the $DU(2)$, symmetric $DU(3)$, $U(2) \otimes U(2)$ and $U(2) \otimes U(3)$, families obey the $\mathrm{PPT}^2$ conjecture through a direct symmetry argument. These results reveal how group symmetry controls the structure of non-completely positive maps and provide new concrete examples where the $\mathrm{PPT}^2$ property holds.

</details>


### [227] [Binarisation-loophole-free observation of high-dimensional quantum nonlocality](https://arxiv.org/abs/2601.02350)
*Jia-le Miao,Elna Svegborn,Zhuo Chen,Yu Guo,Xiao-Min Hu,Yun-Feng Huang,Chuan-Feng Li,Guang-Can Guo,Armin Tavakoli,Bi-Heng Liu*

Main category: quant-ph

TL;DR: 该研究通过使用四维光子路径模式纠缠和多结果检测，关闭了高维贝尔不等式测试中的二值化漏洞，首次实现了无此漏洞的真正高维非局域性验证。


<details>
  <summary>Details</summary>
Motivation: 高维纠缠的贝尔不等式测试通常需要多结果测量，但实际实现中常被简化为"点击或无点击"的二值测量。这种简化在高维贝尔测试中打开了一个漏洞，可能被局域隐变量模型利用。研究旨在关闭这个二值化漏洞，实现真正的高维非局域性验证。

Method: 使用四维光子路径模式纠缠和多结果检测系统，测试了Collins-Gisin-Linden-Massar-Popescu不等式以及为高维最大纠缠态设计的贝尔不等式。通过真正的多结果测量而非二值化测量来避免漏洞。

Result: 观察到了足够大的违反值，不仅证明了贝尔不等式的违反，还排除了任何基于低维纠缠的量子模型，从而首次展示了无二值化漏洞的真正高维非局域性。

Conclusion: 成功关闭了高维贝尔测试中的二值化漏洞，通过四维光子路径模式纠缠和多结果检测，实现了对高维非局域性的无漏洞验证，为高维量子信息处理提供了重要基础。

Abstract: Bell inequality tests based on high-dimensional entanglement usually require measurements that can resolve multiple possible outcomes. However, the implementation of high-dimensional multi-outcome measurements is often only emulated via a collection of ``click or no-click'' measurements. This reduction of multi-outcome measurements to binary-outcome measurements opens a loophole in high-dimensional tests Bell inequalities which can be exploited by local hidden variable models [Tavakoli et al., Phys. Rev. A 111, 042433 (2025)]. Here, we close this loophole by using four-dimensional photonic path-mode entanglement and multi-outcome detection. We test both the well-known Collins-Gisin-Linden-Massar-Popescu inequality and a related Bell inequality tailored for maximally entangled states in high-dimension. We observe violations that are large enough to also rule out any quantum model based on entanglement of lower dimension, thereby demonstrating genuinely high-dimensional nonlocality free of the binarisation loophole.

</details>
