<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 147]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 11]
- [nlin.AO](#nlin.AO) [Total: 2]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [cs.AI](#cs.AI) [Total: 30]
- [quant-ph](#quant-ph) [Total: 46]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 15]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Practical Machine Learning for Aphasic Discourse Analysis](https://arxiv.org/abs/2511.17553)
*Jason M. Pittman,Anton Phillips,Yesenia Medina-Santos,Brielle C. Stark*

Main category: cs.LG

TL;DR: 本研究评估了五种机器学习模型在失语症患者图片描述任务中自动识别正确信息单元(CIU)的能力，发现模型在区分单词与非单词方面表现优异，但在识别CIU方面仍有挑战。


<details>
  <summary>Details</summary>
Motivation: CIU分析是量化失语症患者语言能力的重要方法，但由于需要言语病理学家手动编码和分析，临床应用受限。机器学习技术有望自动化这一过程，减轻临床工作负担。

Method: 使用五种监督机器学习模型，基于失语症患者的人类编码转录本及其单词和CIU数据进行训练，评估模型在图片描述任务中识别CIU的可靠性。

Result: 所有模型在区分单词与非单词方面表现优异(准确率0.995，AUC范围0.914-0.995)，但在识别CIU方面表现差异较大，k-NN模型表现最佳(准确率0.824，AUC 0.787)。

Conclusion: 监督机器学习模型能有效区分单词与非单词，但准确识别CIU仍然具有挑战性，需要进一步改进模型性能。

Abstract: Analyzing spoken discourse is a valid means of quantifying language ability in persons with aphasia. There are many ways to quantify discourse, one common way being to evaluate the informativeness of the discourse. That is, given the total number of words produced, how many of those are context-relevant and accurate. This type of analysis is called Correct Information Unit (CIU) analysis and is one of the most prevalent discourse analyses used by speech-language pathologists (SLPs). Despite this, CIU analysis in the clinic remains limited due to the manual labor needed by SLPs to code and analyze collected speech. Recent advances in machine learning (ML) seek to augment such labor by automating modeling of propositional, macrostructural, pragmatic, and multimodal dimensions of discourse. To that end, this study evaluated five ML models for reliable identification of Correct Information Units (CIUs, Nicholas & Brookshire, 1993), during a picture description task. The five supervised ML models were trained using randomly selected human-coded transcripts and accompanying words and CIUs from persons with aphasia. The baseline model training produced a high accuracy across transcripts for word vs non-word, with all models achieving near perfect performance (0.995) with high AUC range (0.914 min, 0.995 max). In contrast, CIU vs non-CIU showed a greater variability, with the k-nearest neighbor (k-NN) model the highest accuracy (0.824) and second highest AUC (0.787). These findings indicate that while the supervised ML models can distinguish word from not word, identifying CIUs is challenging.

</details>


### [2] [Root Cause Analysis for Microservice Systems via Cascaded Conditional Learning with Hypergraphs](https://arxiv.org/abs/2511.17566)
*Shuaiyu Xie,Hanbin He,Jian Wang,Bing Li*

Main category: cs.LG

TL;DR: CCLH是一个用于微服务系统根因分析的新框架，通过级联条件学习和异构超图建模来解决传统方法在任务依赖性和实例群体影响方面的不足，在根因定位和故障类型识别任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统根因分析方法面临两个关键挑战：1）联合学习范式忽视了任务间的因果依赖关系，阻碍了任务间协作；2）主要关注实例间的点对点关系，忽略了由部署配置和负载均衡引起的实例群体影响特性。

Method: 提出了CCLH框架，采用级联条件学习来协调诊断任务，提供了实例间群体影响的三级分类，并引入异构超图来建模这些关系，从而模拟故障传播过程。

Result: 在三个微服务基准数据集上的广泛实验表明，CCLH在根因定位和故障类型识别两个任务上都优于最先进的方法。

Conclusion: CCLH通过级联条件学习和异构超图建模，有效解决了传统根因分析方法在任务依赖性和群体影响建模方面的局限性，显著提升了诊断性能。

Abstract: Root cause analysis in microservice systems typically involves two core tasks: root cause localization (RCL) and failure type identification (FTI). Despite substantial research efforts, conventional diagnostic approaches still face two key challenges. First, these methods predominantly adopt a joint learning paradigm for RCL and FTI to exploit shared information and reduce training time. However, this simplistic integration neglects the causal dependencies between tasks, thereby impeding inter-task collaboration and information transfer. Second, these existing methods primarily focus on point-to-point relationships between instances, overlooking the group nature of inter-instance influences induced by deployment configurations and load balancing. To overcome these limitations, we propose CCLH, a novel root cause analysis framework that orchestrates diagnostic tasks based on cascaded conditional learning. CCLH provides a three-level taxonomy for group influences between instances and incorporates a heterogeneous hypergraph to model these relationships, facilitating the simulation of failure propagation. Extensive experiments conducted on datasets from three microservice benchmarks demonstrate that CCLH outperforms state-of-the-art methods in both RCL and FTI.

</details>


### [3] [Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis](https://arxiv.org/abs/2511.17573)
*Michael J. Bommarito*

Main category: cs.LG

TL;DR: 本文提出了Binary BPE分词器家族，专门用于二进制分析，通过字节对编码在大型二进制语料库上训练，提供4K-64K词汇表，相比原始字节能在固定长度transformer上下文窗口中容纳2-3倍多的二进制内容。


<details>
  <summary>Details</summary>
Motivation: 解决二进制分析中序列模型的瓶颈问题：原始字节浪费transformer上下文窗口容量，现有文本分词器无法处理0x00-0xFF任意字节序列。

Method: 开发跨平台Byte Pair Encoding分词器，在包含Linux、Windows、macOS、Android和恶意软件的大型二进制语料库上训练，提供4K、8K、16K、32K和64K词汇表的分词器。

Result: 分词器发现了可解释模式（ELF/PE头、指令序列、跨平台字符串），每个token实现多字节压缩。在未压缩可执行文件上，相比原始字节能在固定上下文窗口中容纳2-3倍多的二进制内容。

Conclusion: Binary BPE分词器为二进制分析提供了更高效的研究和实际部署基础，支持内容识别、恶意软件检测、逆向工程和优化等应用，已在HuggingFace发布。

Abstract: Sequence models for binary analysis are bottlenecked by byte-level tokenization: raw bytes waste precious context window capacity for transformers and other neural network architectures, and many existing text-oriented tokenizers fail on arbitrary 0x00--0xFF sequences. To address this issue, we introduce the Binary BPE tokenizer family, a set of cross-platform Byte Pair Encoding (BPE) tokenizers for executables trained on a large corpus of binaries spanning multiple platforms, architectures, and operating systems, including Linux, Windows, macOS, Android, and malware sources. We release trained tokenizers with vocabularies of 4K, 8K, 16K, 32K, and 64K tokens, enabling both systematic scaling studies and practical deployment from resource-constrained edge devices to high-throughput datacenters. These tokenizers discover interpretable patterns (ELF/PE headers, instruction sequences, cross-platform strings) while yielding multi-byte compression per token. On representative uncompressed executables (e.g., ELF/PE/Mach-O rather than compressed APKs), the Binary BPE tokenizers typically allow for roughly 2-3x more binary content per fixed-length transformer context window than raw bytes, enabling more efficient research and practical deployment for content identification, malware detection, reverse engineering, and optimization. We release the trained Binary BPE tokenizers on HuggingFace, providing a drop-in, open-source foundation for binary-focused language models and context-efficient agentic tools.

</details>


### [4] [Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation](https://arxiv.org/abs/2511.17577)
*Fengming Yu,Qingyu Meng,Haiwei Pan,Kejia Zhang*

Main category: cs.LG

TL;DR: 提出一种轻量级优化方法，结合动态注意力头剪枝和知识蒸馏，在保持数学推理能力的同时显著提升大语言模型的效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在数学推理等复杂任务中表现出色，但计算和存储成本高昂，限制了实际部署。需要开发轻量级优化方法来平衡性能与效率。

Method: 动态评估多头注意力机制中每个注意力头的重要性（基于权重范数和熵），实时剪枝冗余头以减少计算开销；通过知识蒸馏将原始模型信息迁移到剪枝后的学生模型。

Result: 在Math23k数据集上，30%剪枝率下：参数减少18.7%，推理速度提升27.5%，FLOPs减少19.3%，准确率仅下降0.7%（从84.4%到83.7%）。

Conclusion: 该方法在保持强大推理性能的同时实现了显著的效率提升，为大语言模型在数学推理任务中的高效部署提供了实用解决方案。

Abstract: With the rapid development of deep learning, large language models have shown strong capabilities in complex reasoning tasks such as mathematical equation solving. However, their substantial computational and storage costs hinder practical deployment. This paper proposes a lightweight optimization method that integrates dynamic attention head pruning with knowledge distillation. The approach dynamically evaluates the importance of each attention head in the multi-head attention mechanism using a combination of weight norms and entropy, and prunes redundant heads in real time to reduce computational overhead. To mitigate performance degradation, knowledge distillation transfers information from the original model to the pruned student, enabling the smaller model to preserve reasoning ability. Experiments conducted on both Math23k and ASDiv-A verify the effectiveness of the proposed method. For example, on Math23k with a 30% pruning ratio, parameters are reduced by 18.7%, inference speed is improved by 27.5%, FLOPs are reduced by 19.3%, and accuracy drops only 0.7% (from 84.4% to 83.7%). These results demonstrate that the method achieves substantial efficiency gains while maintaining strong reasoning performance, providing a practical solution for efficient deployment of large language models in mathematical reasoning tasks.

</details>


### [5] [Multi-Value Alignment for LLMs via Value Decorrelation and Extrapolation](https://arxiv.org/abs/2511.17579)
*Hefei Xu,Le Wu,Chen Cheng,Hao Liu*

Main category: cs.LG

TL;DR: 本文提出了一种名为多价值对齐（MVA）的新框架，用于解决大语言模型在多个可能冲突的人类价值观对齐方面的挑战。该框架通过最小化不同价值观之间的互信息来缓解参数干扰，并采用价值外推策略探索帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，将其与人类价值观对齐以确保安全和伦理已成为关键挑战。现有方法（如RLHF和DPO）在多价值对齐中存在不稳定、效率低下以及无法有效处理价值冲突的局限性。

Method: 提出MVA框架：1）通过最小化不同人类价值观之间的互信息来缓解对齐退化；2）采用价值外推策略高效探索帕累托前沿，构建具有不同价值偏好的LLMs集合。

Result: 大量实验表明，MVA在将LLMs与多个人类价值观对齐方面始终优于现有基线方法。

Conclusion: MVA框架有效解决了多价值对齐中的参数干扰和冲突处理问题，能够实现更好的价值权衡，为大语言模型的安全伦理对齐提供了新思路。

Abstract: With the rapid advancement of large language models (LLMs), aligning them with human values for safety and ethics has become a critical challenge. This problem is especially challenging when multiple, potentially conflicting human values must be considered and balanced. Although several variants of existing alignment methods (such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO)) have been proposed to address multi-value alignment, they suffer from notable limitations: 1) they are often unstable and inefficient in multi-value optimization; and 2) they fail to effectively handle value conflicts. As a result, these approaches typically struggle to achieve optimal trade-offs when aligning multiple values.
  To address this challenge, we propose a novel framework called Multi-Value Alignment (MVA). It mitigates alignment degradation caused by parameter interference among diverse human values by minimizing their mutual information. Furthermore, we propose a value extrapolation strategy to efficiently explore the Pareto frontier, thereby constructing a set of LLMs with diverse value preferences. Extensive experiments demonstrate that MVA consistently outperforms existing baselines in aligning LLMs with multiple human values.

</details>


### [6] [EgoCogNav: Cognition-aware Human Egocentric Navigation](https://arxiv.org/abs/2511.17581)
*Zhiwen Qiu,Ziang Liu,Wenqian Niu,Tapomayukh Bhattacharjee,Saleh Kalantari*

Main category: cs.LG

TL;DR: EgoCogNav是一个多模态自我中心导航框架，通过预测感知路径不确定性作为潜在状态，融合场景特征和感官线索来联合预测轨迹和头部运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注完全观察场景中的运动预测，往往忽略了捕捉人们对空间感受和反应的人类因素。

Method: 提出EgoCogNav框架，预测感知路径不确定性作为潜在状态，融合场景特征与感官线索来联合预测轨迹和头部运动。同时构建了CEN数据集，包含6小时真实世界自我中心记录。

Result: 实验表明EgoCogNav学习的感知不确定性与人类行为（如扫描、犹豫、回溯）高度相关，并能泛化到未见过的环境。

Conclusion: 该框架成功建模了人类导航的认知和体验因素，为理解人-环境交互和实现安全社交导航提供了有效方法。

Abstract: Modeling the cognitive and experiential factors of human navigation is central to deepening our understanding of human-environment interaction and to enabling safe social navigation and effective assistive wayfinding. Most existing methods focus on forecasting motions in fully observed scenes and often neglect human factors that capture how people feel and respond to space. To address this gap, We propose EgoCogNav, a multimodal egocentric navigation framework that predicts perceived path uncertainty as a latent state and jointly forecasts trajectories and head motion by fusing scene features with sensory cues. To facilitate research in the field, we introduce the Cognition-aware Egocentric Navigation (CEN) dataset consisting 6 hours of real-world egocentric recordings capturing diverse navigation behaviors in real-world scenarios. Experiments show that EgoCogNav learns the perceived uncertainty that highly correlates with human-like behaviors such as scanning, hesitation, and backtracking while generalizing to unseen environments.

</details>


### [7] [GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2511.17582)
*Jie Ou,Shuaihong Jiang,Yingjun Du,Cees G. M. Snoek*

Main category: cs.LG

TL;DR: GateRA是一种参数高效微调框架，通过令牌感知调制动态调整PEFT更新的强度，实现选择性令牌级适应，在推理任务中优于现有PEFT方法。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法对所有令牌应用静态、输入无关的更新，忽视了不同输入的重要性和难度差异，可能导致简单内容过拟合或重要区域适应不足。

Method: 在标准PEFT分支中引入自适应门控机制，实现令牌级选择性适应；使用基于熵的正则化鼓励近二元门控决策；理论分析显示GateRA在PEFT路径上产生软梯度掩码效应。

Result: 在多个常识推理基准测试中，GateRA持续优于或匹配先前的PEFT方法；可视化显示GateRA自动抑制冗余预填充令牌的更新，在解码阶段强调适应。

Conclusion: GateRA通过令牌感知调制实现了更智能的参数高效微调，能够根据输入难度动态调整适应强度，在保持预训练知识的同时专注于挑战性案例。

Abstract: Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA, enable lightweight adaptation of large pre-trained models via low-rank updates. However, existing PEFT approaches apply static, input-agnostic updates to all tokens, disregarding the varying importance and difficulty of different inputs. This uniform treatment can lead to overfitting on trivial content or under-adaptation on more informative regions, especially in autoregressive settings with distinct prefill and decoding dynamics. In this paper, we propose GateRA, a unified framework that introduces token-aware modulation to dynamically adjust the strength of PEFT updates. By incorporating adaptive gating into standard PEFT branches, GateRA enables selective, token-level adaptation, preserving pre-trained knowledge for well-modeled inputs while focusing capacity on challenging cases. Empirical visualizations reveal phase-sensitive behaviors, where GateRA automatically suppresses updates for redundant prefill tokens while emphasizing adaptation during decoding. To promote confident and efficient modulation, we further introduce an entropy-based regularization that encourages near-binary gating decisions. This regularization prevents diffuse update patterns and leads to interpretable, sparse adaptation without hard thresholding. Finally, we present a theoretical analysis showing that GateRA induces a soft gradient-masking effect over the PEFT path, enabling continuous and differentiable control over adaptation. Experiments on multiple commonsense reasoning benchmarks demonstrate that GateRA consistently outperforms or matches prior PEFT methods.

</details>


### [8] [Learning Straight Flows: Variational Flow Matching for Efficient Generation](https://arxiv.org/abs/2511.17583)
*Chenrui Ma,Xi Xiao,Tianyang Wang,Xiao Wang,Yanning Shen*

Main category: cs.LG

TL;DR: 本文提出S-VFM方法，通过引入变分潜码来强制轨迹直线化，解决Flow Matching中一步生成能力受限的问题，在多个基准测试中表现优异且效率更高。


<details>
  <summary>Details</summary>
Motivation: Flow Matching方法由于依赖学习到的弯曲轨迹，在实现一步生成方面能力有限。现有方法存在离散近似误差、训练不稳定和收敛困难等问题。

Method: 提出S-VFM方法，将代表"生成概览"的变分潜码集成到Flow Matching框架中，明确强制轨迹直线化，理想情况下产生线性生成路径。

Result: 在三个挑战性基准测试中取得了竞争性性能，与现有方法相比在训练和推理效率方面都显示出优势。

Conclusion: S-VFM通过整合变分潜码成功解决了Flow Matching的轨迹弯曲问题，实现了更高效的直线轨迹生成。

Abstract: Flow Matching has limited ability in achieving one-step generation due to its reliance on learned curved trajectories. Previous studies have attempted to address this limitation by either modifying the coupling distribution to prevent interpolant intersections or introducing consistency and mean-velocity modeling to promote straight trajectory learning. However, these approaches often suffer from discrete approximation errors, training instability, and convergence difficulties. To tackle these issues, in the present work, we propose \textbf{S}traight \textbf{V}ariational \textbf{F}low \textbf{M}atching (\textbf{S-VFM}), which integrates a variational latent code representing the ``generation overview'' into the Flow Matching framework. \textbf{S-VFM} explicitly enforces trajectory straightness, ideally producing linear generation paths. The proposed method achieves competitive performance across three challenge benchmarks and demonstrates advantages in both training and inference efficiency compared with existing methods.

</details>


### [9] [LLM-Powered Text-Attributed Graph Anomaly Detection via Retrieval-Augmented Reasoning](https://arxiv.org/abs/2511.17584)
*Haoyan Xu,Ruizhi Qian,Zhengtao Yao,Ziyi Liu,Li Li,Yuqi Li,Yanshu Li,Wenqing Zheng,Daniele Rosa,Daniel Barcklow,Senthil Kumar,Jieyu Zhao,Yue Zhao*

Main category: cs.LG

TL;DR: 本文提出了TAG-AD基准数据集，用于文本属性图上的异常节点检测，利用LLM生成语义一致但上下文不一致的异常文本，并评估了GNN方法和零样本LLM方法的性能。


<details>
  <summary>Details</summary>
Motivation: 文本属性图上的异常检测在欺诈检测、入侵监控等应用中很重要，但由于缺乏标准化基准数据集而研究不足。

Method: 使用LLM在原始文本空间中生成现实异常节点文本，构建包含多种异常类型的TAG-AD基准，并提出基于RAG的零样本LLM异常检测框架。

Result: 实验结果显示LLM在检测上下文异常方面特别有效，而GNN方法在结构异常检测方面表现更优。RAG辅助提示实现了与人工设计提示相当的性能。

Conclusion: LLM和GNN方法在异常检测中各有优势，RAG辅助的零样本LLM框架具有实用价值，无需手动提示工程即可达到良好性能。

Abstract: Anomaly detection on attributed graphs plays an essential role in applications such as fraud detection, intrusion monitoring, and misinformation analysis. However, text-attributed graphs (TAGs), in which node information is expressed in natural language, remain underexplored, largely due to the absence of standardized benchmark datasets. In this work, we introduce TAG-AD, a comprehensive benchmark for anomaly node detection on TAGs. TAG-AD leverages large language models (LLMs) to generate realistic anomalous node texts directly in the raw text space, producing anomalies that are semantically coherent yet contextually inconsistent and thus more reflective of real-world irregularities. In addition, TAG-AD incorporates multiple other anomaly types, enabling thorough and reproducible evaluation of graph anomaly detection (GAD) methods. With these datasets, we further benchmark existing unsupervised GNN-based GAD methods as well as zero-shot LLMs for GAD.
  As part of our zero-shot detection setup, we propose a retrieval-augmented generation (RAG)-assisted, LLM-based zero-shot anomaly detection framework. The framework mitigates reliance on brittle, hand-crafted prompts by constructing a global anomaly knowledge base and distilling it into reusable analysis frameworks. Our experimental results reveal a clear division of strengths: LLMs are particularly effective at detecting contextual anomalies, whereas GNN-based methods remain superior for structural anomaly detection. Moreover, RAG-assisted prompting achieves performance comparable to human-designed prompts while eliminating manual prompt engineering, underscoring the practical value of our RAG-assisted zero-shot LLM anomaly detection framework.

</details>


### [10] [PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for Multimodal Sentiment Analysis](https://arxiv.org/abs/2511.17585)
*Kang He,Boyu Chen,Yuzhe Ding,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.LG

TL;DR: PaSE框架通过原型对齐校准和Shapley优化均衡来解决多模态情感分析中的模态竞争问题，提升模态间协作性能


<details>
  <summary>Details</summary>
Motivation: 多模态情感分析中，优势模态往往会压制弱势模态，导致模态竞争问题，影响整体性能

Method: 提出PaSE框架：1) 原型引导校准学习(PCL)通过熵最优传输机制精炼单模态表示；2) 双阶段优化策略：原型门控融合模块提取共享表示，Shapley梯度调制(SGM)自适应调整梯度

Result: 在IEMOCAP、MOSI和MOSEI数据集上的实验表明，PaSE实现了优越性能并有效缓解了模态竞争

Conclusion: PaSE框架通过原型对齐和Shapley优化成功解决了多模态情感分析中的模态竞争问题，提升了模型性能

Abstract: Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by integrating textual, acoustic, and visual signals. Although multimodal fusion is designed to leverage cross-modal complementarity, real-world scenarios often exhibit modality competition: dominant modalities tend to overshadow weaker ones, leading to suboptimal performance.In this paper, we propose PaSE, a novel Prototype-aligned Calibration and Shapley-optimized Equilibrium framework, which enhances collaboration while explicitly mitigating modality competition. PaSE first applies Prototype-guided Calibration Learning (PCL) to refine unimodal representations and align them through an Entropic Optimal Transport mechanism that ensures semantic consistency. To further stabilize optimization, we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion module is first used to extract shared representations, followed by Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients according to the contribution of each modality. Extensive experiments on IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance and effectively alleviates modality competition.

</details>


### [11] [Emotion and Intention Guided Multi-Modal Learning for Sticker Response Selection](https://arxiv.org/abs/2511.17587)
*Yuxuan Hu,Jian Chen,Yuhao Wang,Zixuan Li,Jing Xiong,Pengyue Jia,Wei Wang,Chengming Li,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 本文提出EIGML框架，首次联合建模情感和意图，通过双层次对比框架和多模态融合模块，显著提升贴纸响应选择的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有贴纸响应选择方法通常依赖语义匹配，并将情感和意图线索分开建模，当情感和意图不一致时容易导致匹配错误。

Method: 提出情感和意图引导的多模态学习框架，包括双层次对比框架（模态内和模态间对齐）和意图-情感引导的多模态融合模块（情感引导意图知识选择、意图-情感引导注意力融合、相似度调整匹配机制）。

Result: 在两个公开SRS数据集上的实验结果表明，EIGML始终优于最先进的基线方法，实现了更高的准确率和更好的情感意图特征理解。

Conclusion: EIGML通过联合建模情感和意图，有效减少孤立建模带来的偏差，显著提升了贴纸选择性能。

Abstract: Stickers are widely used in online communication to convey emotions and implicit intentions. The Sticker Response Selection (SRS) task aims to select the most contextually appropriate sticker based on the dialogue. However, existing methods typically rely on semantic matching and model emotional and intentional cues separately, which can lead to mismatches when emotions and intentions are misaligned. To address this issue, we propose Emotion and Intention Guided Multi-Modal Learning (EIGML). This framework is the first to jointly model emotion and intention, effectively reducing the bias caused by isolated modeling and significantly improving selection accuracy. Specifically, we introduce Dual-Level Contrastive Framework to perform both intra-modality and inter-modality alignment, ensuring consistent representation of emotional and intentional features within and across modalities. In addition, we design an Intention-Emotion Guided Multi-Modal Fusion module that integrates emotional and intentional information progressively through three components: Emotion-Guided Intention Knowledge Selection, Intention-Emotion Guided Attention Fusion, and Similarity-Adjusted Matching Mechanism. This design injects rich, effective information into the model and enables a deeper understanding of the dialogue, ultimately enhancing sticker selection performance. Experimental results on two public SRS datasets show that EIGML consistently outperforms state-of-the-art baselines, achieving higher accuracy and a better understanding of emotional and intentional features. Code is provided in the supplementary materials.

</details>


### [12] [Llamazip: Leveraging LLaMA for Lossless Text Compression and Training Dataset Detection](https://arxiv.org/abs/2511.17589)
*Sören Dréano,Derek Molloy,Noel Murphy*

Main category: cs.LG

TL;DR: Llamazip是一种基于LLaMA3语言模型预测能力的无损文本压缩算法，通过仅存储模型无法预测的token来实现显著数据压缩，同时保持数据完整性。


<details>
  <summary>Details</summary>
Motivation: 开发一种利用语言模型预测能力的高效无损文本压缩方法，并探索其在识别文档是否属于语言模型训练数据集方面的潜力，以解决数据来源、知识产权和透明度问题。

Method: 基于LLaMA3语言模型的预测能力，仅存储模型无法准确预测的token，分析量化程度和上下文窗口大小等关键因素对性能的影响。

Result: 实现了显著的数据压缩效果，同时能够识别文档是否属于语言模型的训练数据集，为数据溯源和知识产权保护提供支持。

Conclusion: Llamazip不仅展示了高效的无损文本压缩能力，还揭示了语言模型在数据溯源和透明度方面的应用潜力，为解决语言模型训练中的关键问题提供了新思路。

Abstract: This work introduces Llamazip, a novel lossless text compression algorithm based on the predictive capabilities of the LLaMA3 language model. Llamazip achieves significant data reduction by only storing tokens that the model fails to predict, optimizing storage efficiency without compromising data integrity. Key factors affecting its performance, including quantization and context window size, are analyzed, revealing their impact on compression ratios and computational requirements. Beyond compression, Llamazip demonstrates the potential to identify whether a document was part of the training dataset of a language model. This capability addresses critical concerns about data provenance, intellectual property, and transparency in language model training.

</details>


### [13] [SHAP Distance: An Explainability-Aware Metric for Evaluating the Semantic Fidelity of Synthetic Tabular Data](https://arxiv.org/abs/2511.17590)
*Ke Yu,Shigeru Ishikura,Yukari Usukura,Yuki Shigoku,Teruaki Hayashi*

Main category: cs.LG

TL;DR: 本文提出SHAP距离，一种基于可解释性的新指标，用于评估合成表格数据的语义保真度，弥补了传统统计和预测指标在语义一致性评估方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据评估方法主要关注分布相似性和预测性能，但无法评估模型在合成数据上是否遵循与真实数据一致的推理模式，即语义保真度问题。

Method: 引入SHAP距离，定义为从真实数据与合成数据训练的模型中导出的全局SHAP归因向量之间的余弦距离，通过多个领域数据集验证其有效性。

Result: SHAP距离能够可靠地识别传统统计和预测指标忽略的语义差异，特别是特征重要性偏移和尾部效应不足等问题。

Conclusion: SHAP距离可作为评估合成表格数据语义保真度的实用工具，并为未来基准测试管道集成基于归因的评估提供实践指南。

Abstract: Synthetic tabular data, which are widely used in domains such as healthcare, enterprise operations, and customer analytics, are increasingly evaluated to ensure that they preserve both privacy and utility. While existing evaluation practices typically focus on distributional similarity (e.g., the Kullback-Leibler divergence) or predictive performance (e.g., Train-on-Synthetic-Test-on-Real (TSTR) accuracy), these approaches fail to assess semantic fidelity, that is, whether models trained on synthetic data follow reasoning patterns consistent with those trained on real data. To address this gap, we introduce the SHapley Additive exPlanations (SHAP) Distance, a novel explainability-aware metric that is defined as the cosine distance between the global SHAP attribution vectors derived from classifiers trained on real versus synthetic datasets. By analyzing datasets that span clinical health records with physiological features, enterprise invoice transactions with heterogeneous scales, and telecom churn logs with mixed categorical-numerical attributes, we demonstrate that the SHAP Distance reliably identifies semantic discrepancies that are overlooked by standard statistical and predictive measures. In particular, our results show that the SHAP Distance captures feature importance shifts and underrepresented tail effects that the Kullback-Leibler divergence and Train-on-Synthetic-Test-on-Real accuracy fail to detect. This study positions the SHAP Distance as a practical and discriminative tool for auditing the semantic fidelity of synthetic tabular data, and offers practical guidelines for integrating attribution-based evaluation into future benchmarking pipelines.

</details>


### [14] [Comparative Analysis of Large Language Model Inference Serving Systems: A Performance Study of vLLM and HuggingFace TGI](https://arxiv.org/abs/2511.17593)
*Saicharan Kolluru*

Main category: cs.LG

TL;DR: 本文对vLLM和HuggingFace TGI两个开源LLM服务框架进行了全面实证评估，发现在高并发场景下vLLM吞吐量比TGI高24倍，而TGI在交互式单用户场景下延迟更低。


<details>
  <summary>Details</summary>
Motivation: 生产环境中部署大型语言模型需要高效的推理服务系统来平衡吞吐量、延迟和资源利用率。

Method: 使用LLaMA-2模型（7B到70B参数）对vLLM和TGI进行多维度基准测试，包括吞吐量性能、端到端延迟、GPU内存利用率和可扩展性特征。

Result: vLLM通过其新颖的PagedAttention机制在高并发工作负载下实现比TGI高24倍的吞吐量，而TGI在交互式单用户场景下表现出更低的尾部延迟。

Conclusion: 框架选择应基于具体用例需求：vLLM在高吞吐量批处理场景中表现优异，而TGI更适合中等并发的延迟敏感交互应用。

Abstract: The deployment of Large Language Models (LLMs) in production environments requires efficient inference serving systems that balance throughput, latency, and resource utilization. This paper presents a comprehensive empirical evaluation of two prominent open-source LLM serving frameworks: vLLM and HuggingFace Text Generation Inference (TGI). We benchmark these systems across multiple dimensions including throughput performance, end-to-end latency, GPU memory utilization, and scalability characteristics using LLaMA-2 models ranging from 7B to 70B parameters. Our experiments reveal that vLLM achieves up to 24x higher throughput than TGI under high-concurrency workloads through its novel PagedAttention mechanism, while TGI demonstrates lower tail latencies for interactive single-user scenarios. We provide detailed performance profiles for different deployment scenarios and offer practical recommendations for system selection based on workload characteristics. Our findings indicate that the choice between these frameworks should be guided by specific use-case requirements: vLLM excels in high-throughput batch processing scenarios, while TGI is better suited for latency-sensitive interactive applications with moderate concurrency.

</details>


### [15] [AutoSAGE: Input-Aware CUDA Scheduling for Sparse GNN Aggregation (SpMM/SDDMM) and CSR Attention](https://arxiv.org/abs/2511.17594)
*Aleksandar Stankovic*

Main category: cs.LG

TL;DR: AutoSAGE是一个输入感知的CUDA调度器，通过轻量级估计和微探针为不同输入选择最优的平铺和映射策略，支持CSR SpMM/SDDMM操作，并能组合成CSR注意力流水线。


<details>
  <summary>Details</summary>
Motivation: 稀疏GNN聚合操作（CSR SpMM/SDDMM）的性能因节点度数偏斜、特征宽度和GPU微架构而异，需要针对不同输入进行优化。

Method: 使用轻量级估计和on-device微探针为每个输入选择平铺和映射策略，包含回退机制和持久缓存以确保确定性重放。

Result: 在Reddit和OGBN-Products数据集上，在带宽受限的特征宽度下与供应商基线匹配，在小宽度下获得性能提升；在合成稀疏性和偏斜压力测试中实现高达4.7倍的内核级加速。

Conclusion: AutoSAGE能够有效优化稀疏GNN聚合操作，提供了CUDA源代码、Python绑定、可复现框架和可重放缓存日志。

Abstract: Sparse GNN aggregations (CSR SpMM/SDDMM) vary widely in performance with degree skew, feature width, and GPU micro-architecture. We present AutoSAGE, an input-aware CUDA scheduler that chooses tiling and mapping per input using a lightweight estimate refined by on-device micro-probes, with a guardrail that safely falls back to vendor kernels and a persistent cache for deterministic replay. AutoSAGE covers SpMM and SDDMM and composes into a CSR attention pipeline (SDDMM -> row-softmax -> SpMM). On Reddit and OGBN-Products, it matches vendor baselines at bandwidth-bound feature widths and finds gains at small widths; on synthetic sparsity and skew stress tests it achieves up to 4.7x kernel-level speedups. We release CUDA sources, Python bindings, a reproducible harness, and replayable cache logs.

</details>


### [16] [Boosting Reinforcement Learning in 3D Visuospatial Tasks Through Human-Informed Curriculum Design](https://arxiv.org/abs/2511.17595)
*Markus D. Solbach,John K. Tsotsos*

Main category: cs.LG

TL;DR: 本文研究了强化学习在3D同异视觉空间任务中的应用，发现标准方法难以直接学习最优策略，但通过基于人类实验设计的课程学习取得了成功。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在复杂、非结构化问题领域中的智能行为表现能力，特别是验证其在看似简单的3D视觉空间任务中的适用性。

Method: 使用PPO、行为克隆和模仿学习等先进RL方法，并结合基于人类实验结果的课程学习策略设计。

Result: 标准RL方法在直接学习最优策略方面遇到困难，但通过精心设计的课程学习实现了有效学习。

Conclusion: 课程学习为强化学习在复杂视觉空间任务中的应用提供了有前景的途径，基于人类认知过程的课程设计是成功的关键因素。

Abstract: Reinforcement Learning is a mature technology, often suggested as a potential route towards Artificial General Intelligence, with the ambitious goal of replicating the wide range of abilities found in natural and artificial intelligence, including the complexities of human cognition. While RL had shown successes in relatively constrained environments, such as the classic Atari games and specific continuous control problems, recent years have seen efforts to expand its applicability. This work investigates the potential of RL in demonstrating intelligent behaviour and its progress in addressing more complex and less structured problem domains.
  We present an investigation into the capacity of modern RL frameworks in addressing a seemingly straightforward 3D Same-Different visuospatial task. While initial applications of state-of-the-art methods, including PPO, behavioural cloning and imitation learning, revealed challenges in directly learning optimal strategies, the successful implementation of curriculum learning offers a promising avenue. Effective learning was achieved by strategically designing the lesson plan based on the findings of a real-world human experiment.

</details>


### [17] [Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning](https://arxiv.org/abs/2511.17598)
*Zhizuo Chen,Theodore T. Allen*

Main category: cs.LG

TL;DR: 提出了非平稳和可变折扣MDP（NVMDP）框架，解决传统MDP在非平稳环境和有限时域任务中的局限性，支持随时间变化的折扣率，并能灵活塑造最优策略。


<details>
  <summary>Details</summary>
Motivation: 传统MDP算法在非平稳环境中面临挑战，无限时域公式不适用于有限时域任务，需要更灵活的框架来处理非平稳性和可变折扣。

Method: 建立NVMDP理论框架，包括状态-动作值函数公式化、矩阵表示、最优性条件，并扩展动态规划和Q学习算法，以及函数逼近下的策略梯度定理和TRPO。

Result: 在非平稳网格世界环境中的实证评估显示，NVMDP算法能成功恢复最优轨迹，而原始Q学习失败，证明该框架的理论合理性和实践有效性。

Conclusion: NVMDP提供了一个理论严谨且实际有效的强化学习框架，只需轻微算法修改即可稳健处理非平稳性和显式最优策略塑造。

Abstract: Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.

</details>


### [18] [From Projection to Prediction: Beyond Logits for Scalable Language Models](https://arxiv.org/abs/2511.17599)
*Jianbing Dong,Jianbin Chang*

Main category: cs.LG

TL;DR: 本文提出了一种将输出投影和损失预测集成到单一操作中的新方法，避免了显式logits张量化，从而减少内存使用和带宽压力，在LLM训练中实现了显著的内存节省和可测量的加速。


<details>
  <summary>Details</summary>
Motivation: 传统的两阶段输出层设计（线性变换生成词汇logits，然后计算交叉熵损失）会产生大量中间logits张量，导致显著的内存占用和带宽消耗，限制了可扩展性和训练吞吐量。

Method: 通过直接将隐藏状态和目标标记计算损失，将输出投影和损失预测集成到单一操作中，绕过显式logits张量化过程。

Result: 实验表明，该方法在LLM训练中实现了显著的内存节省和可测量的加速，能够支持更大的批处理大小和更长的序列，而不会牺牲准确性。

Conclusion: 重新思考投影和预测之间的边界具有显著优势，为高效的LLM训练提供了实用的系统优化方案。

Abstract: Training Large Language Models (LLMs) typically involves a two-stage pipeline at the output layer: hidden states are projected into vocabulary logits via a linear transformation (lm_head), followed by cross-entropy loss computation against target tokens. While conceptually simple, this design incurs substantial overhead. The intermediate logits tensor, with dimensions proportional to batch size, sequence length, and vocabulary size, must be fully materialized in GPU memory, even though only one target token per position is ultimately used. This leads to significant memory footprint and bandwidth comsumption, limiting scalability and slowing training throughput.
  In this work, we introduce a novel approach to integrates the output projection and loss prediction into a single operation. By directly computing the loss from hidden states and target tokens, our approach bypasses explicit logits materialization. This design reduces memory usage and alleviates bandwidth pressure. Experiments on LLM training demonstrate that our method achieves substantial memory savings and measurable speedups compared to the standard two-stage pipeline, enabling large batch sizes and longer sequences without sacrificing accuracy. Our work highlights the benefits of rethinking the boundary between projection and prediction, offering a practical systems optimization for efficient LLM training.

</details>


### [19] [Generalizable and Efficient Automated Scoring with a Knowledge-Distilled Multi-Task Mixture-of-Experts](https://arxiv.org/abs/2511.17601)
*Luyang Fang,Tao Wang,Ping Ma,Xiaoming Zhai*

Main category: cs.LG

TL;DR: 提出UniMoE-Guided方法，通过知识蒸馏将多个任务特定大模型的知识转移到单一紧凑模型中，实现高效的多任务自动评分


<details>
  <summary>Details</summary>
Motivation: 解决现实教育环境中自动评分系统因每个任务需要单独模型而导致的资源消耗、存储和维护问题

Method: 使用知识蒸馏的多任务混合专家方法，包括共享编码器、门控MoE块和轻量级任务头，结合真实标签和教师模型指导进行训练

Result: 在9个科学推理任务上，性能与任务特定模型相当，存储需求比单独学生模型减少约6倍，比200亿参数教师模型减少87倍

Conclusion: 该方法为课堂和大规模评估系统提供了可扩展、可靠且资源高效的自动评分实用路径

Abstract: Automated scoring of written constructed responses typically relies on separate models per task, straining computational resources, storage, and maintenance in real-world education settings. We propose UniMoE-Guided, a knowledge-distilled multi-task Mixture-of-Experts (MoE) approach that transfers expertise from multiple task-specific large models (teachers) into a single compact, deployable model (student). The student combines (i) a shared encoder for cross-task representations, (ii) a gated MoE block that balances shared and task-specific processing, and (iii) lightweight task heads. Trained with both ground-truth labels and teacher guidance, the student matches strong task-specific models while being far more efficient to train, store, and deploy. Beyond efficiency, the MoE layer improves transfer and generalization: experts develop reusable skills that boost cross-task performance and enable rapid adaptation to new tasks with minimal additions and tuning. On nine NGSS-aligned science-reasoning tasks (seven for training/evaluation and two held out for adaptation), UniMoE-Guided attains performance comparable to per-task models while using $\sim$6$\times$ less storage than maintaining separate students, and $87\times$ less than the 20B-parameter teacher. The method offers a practical path toward scalable, reliable, and resource-efficient automated scoring for classroom and large-scale assessment systems.

</details>


### [20] [Copula Based Fusion of Clinical and Genomic Machine Learning Risk Scores for Breast Cancer Risk Stratification](https://arxiv.org/abs/2511.17605)
*Agnideep Aich,Sameera Hewage,Md Monzur Murshed*

Main category: cs.LG

TL;DR: 本研究使用METABRIC乳腺癌队列，通过copula方法直接建模临床和基因组机器学习风险评分的联合关系，以改进5年癌症特异性死亡率的风险分层。


<details>
  <summary>Details</summary>
Motivation: 临床和基因组模型通常使用简单的线性规则结合，未能充分考虑风险评分在极端情况下的相互关系，限制了风险分层的准确性。

Method: 使用随机森林和XGBoost等监督分类器训练临床和基因组模型，通过5折交叉验证获得无偏风险评分，然后使用高斯、Clayton和Gumbel copula拟合联合分布。

Result: 临床模型区分度良好（AUC 0.783），基因组模型表现中等（AUC 0.681）。高斯copula最佳捕捉联合分布（bootstrap p=0.997），显示对称、中等强度的正相关关系。基于此关系的患者分组显示，临床和基因组双高风险患者生存率显著更差。

Conclusion: copula融合方法在真实世界队列中有效，考虑评分间依赖关系能更好识别预后最差的患者亚组。

Abstract: Clinical and genomic models are both used to predict breast cancer outcomes, but they are often combined using simple linear rules that do not account for how their risk scores relate, especially at the extremes. Using the METABRIC breast cancer cohort, we studied whether directly modeling the joint relationship between clinical and genomic machine learning risk scores could improve risk stratification for 5-year cancer-specific mortality. We created a binary 5-year cancer-death outcome and defined two sets of predictors: a clinical set (demographic, tumor, and treatment variables) and a genomic set (gene-expression $z$-scores). We trained several supervised classifiers, such as Random Forest and XGBoost, and used 5-fold cross-validated predicted probabilities as unbiased risk scores. These scores were converted to pseudo-observations on $(0,1)^2$ to fit Gaussian, Clayton, and Gumbel copulas. Clinical models showed good discrimination (AUC 0.783), while genomic models had moderate performance (AUC 0.681). The joint distribution was best captured by a Gaussian copula (bootstrap $p=0.997$), which suggests a symmetric, moderately strong positive relationship. When we grouped patients based on this relationship, Kaplan-Meier curves showed clear differences: patients who were high-risk in both clinical and genomic scores had much poorer survival than those high-risk in only one set. These results show that copula-based fusion works in real-world cohorts and that considering dependencies between scores can better identify patient subgroups with the worst prognosis.

</details>


### [21] [Energy-based Autoregressive Generation for Neural Population Dynamics](https://arxiv.org/abs/2511.17606)
*Ningling Ge,Sicheng Dai,Yu Zhu,Shan Yu*

Main category: cs.LG

TL;DR: 提出了一种基于能量的自回归生成（EAG）框架，通过能量变换器在潜在空间中学习时间动态，实现高效生成具有真实群体和单神经元发放统计特性的神经数据。


<details>
  <summary>Details</summary>
Motivation: 理解大脑功能是神经科学的基本目标，但计算建模面临计算效率与高保真建模之间的权衡限制。

Method: 使用基于能量的变换器，通过严格适当评分规则在潜在空间中学习时间动态，实现高效的自回归生成。

Result: 在合成Lorenz数据集和两个神经潜在基准数据集上的评估显示，EAG实现了最先进的生成质量，并显著提高了计算效率，特别是在条件生成应用中能够泛化到未见过的行为情境并提高运动脑机接口解码精度。

Conclusion: 基于能量的建模对于神经群体动态是有效的，在神经科学研究和神经工程中具有应用价值。

Abstract: Understanding brain function represents a fundamental goal in neuroscience, with critical implications for therapeutic interventions and neural engineering applications. Computational modeling provides a quantitative framework for accelerating this understanding, but faces a fundamental trade-off between computational efficiency and high-fidelity modeling. To address this limitation, we introduce a novel Energy-based Autoregressive Generation (EAG) framework that employs an energy-based transformer learning temporal dynamics in latent space through strictly proper scoring rules, enabling efficient generation with realistic population and single-neuron spiking statistics. Evaluation on synthetic Lorenz datasets and two Neural Latents Benchmark datasets (MC_Maze and Area2_bump) demonstrates that EAG achieves state-of-the-art generation quality with substantial computational efficiency improvements, particularly over diffusion-based methods. Beyond optimal performance, conditional generation applications show two capabilities: generalizing to unseen behavioral contexts and improving motor brain-computer interface decoding accuracy using synthetic neural data. These results demonstrate the effectiveness of energy-based modeling for neural population dynamics with applications in neuroscience research and neural engineering. Code is available at https://github.com/NinglingGe/Energy-based-Autoregressive-Generation-for-Neural-Population-Dynamics.

</details>


### [22] [Finding Pre-Injury Patterns in Triathletes from Lifestyle, Recovery and Load Dynamics Features](https://arxiv.org/abs/2511.17610)
*Leonardo Rossi,Bruno Rodrigues*

Main category: cs.LG

TL;DR: 本文提出了一个针对铁人三项训练的合成数据生成框架，通过整合睡眠质量、压力水平和恢复状态等日常生活因素，结合机器学习模型实现了高达0.86 AUC的损伤风险预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前铁人三项损伤预测方法主要依赖训练负荷指标，忽视了睡眠质量、压力和个体生活方式等关键因素对恢复和损伤易感性的显著影响。

Method: 开发了一个专门针对铁人三项的合成数据生成框架，生成生理上合理的运动员档案，模拟包含周期化和负荷管理原则的个性化训练计划，并整合睡眠质量、压力水平和恢复状态等日常生活因素。

Result: 评估了LASSO、随机森林和XGBoost等机器学习模型，显示出高预测性能（AUC高达0.86），识别出睡眠障碍、心率变异性和压力作为损伤风险的关键早期指标。

Conclusion: 这种可穿戴设备驱动的方法不仅提高了损伤预测准确性，还为克服现实世界数据限制提供了实用解决方案，为整体、情境感知的运动员监测提供了途径。

Abstract: Triathlon training, which involves high-volume swimming, cycling, and running, places athletes at substantial risk for overuse injuries due to repetitive physiological stress. Current injury prediction approaches primarily rely on training load metrics, often neglecting critical factors such as sleep quality, stress, and individual lifestyle patterns that significantly influence recovery and injury susceptibility.
  We introduce a novel synthetic data generation framework tailored explicitly for triathlon. This framework generates physiologically plausible athlete profiles, simulates individualized training programs that incorporate periodization and load-management principles, and integrates daily-life factors such as sleep quality, stress levels, and recovery states. We evaluated machine learning models (LASSO, Random Forest, and XGBoost) showing high predictive performance (AUC up to 0.86), identifying sleep disturbances, heart rate variability, and stress as critical early indicators of injury risk. This wearable-driven approach not only enhances injury prediction accuracy but also provides a practical solution to overcoming real-world data limitations, offering a pathway toward a holistic, context-aware athlete monitoring.

</details>


### [23] [Tensor Gauge Flow Models](https://arxiv.org/abs/2511.17616)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: 本文介绍了张量规范流模型，这是一种新的生成流模型，通过将高阶张量规范场纳入流方程，推广了规范流模型和高阶规范流模型。


<details>
  <summary>Details</summary>
Motivation: 为了在数据中编码更丰富的几何和规范理论结构，从而获得更具表达力的流动态。

Method: 将高阶张量规范场整合到流方程中，扩展了现有的规范流模型框架。

Result: 在高斯混合模型上的实验表明，张量规范流模型相比标准和规范流基线模型取得了更好的生成性能。

Conclusion: 张量规范流模型通过引入高阶张量规范场，能够更有效地捕捉数据的几何结构，提升生成模型的表达能力。

Abstract: This paper introduces Tensor Gauge Flow Models, a new class of Generative Flow Models that generalize Gauge Flow Models and Higher Gauge Flow Models by incorporating higher-order Tensor Gauge Fields into the Flow Equation. This extension allows the model to encode richer geometric and gauge-theoretic structure in the data, leading to more expressive flow dynamics. Experiments on Gaussian mixture models show that Tensor Gauge Flow Models achieve improved generative performance compared to both standard and gauge flow baselines.

</details>


### [24] [M$^2$OE$^2$-GL: A Family of Probabilistic Load Forecasters That Scales to Massive Customers](https://arxiv.org/abs/2511.17623)
*Haoran Li,Zhe Cheng,Muhao Guo,Yang Weng,Yannan Sun,Victor Tran,John Chainaranont*

Main category: cs.LG

TL;DR: M2OE2-GL是一种概率负荷预测方法，通过全局预训练和轻量级微调解决大规模配电馈线中数千个负荷的异质性和可扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法面临部署困境：为每个客户训练单独模型计算和存储成本高，而使用单一全局模型会忽略不同客户类型、位置和相位的分布偏移。

Method: 首先在所有馈线负荷上预训练单一全局M2OE2基础模型，然后应用轻量级微调来推导紧凑的组特定预测器家族。

Result: 在实际公用事业数据上的评估显示，M2OE2-GL实现了显著的误差减少，同时保持了对大量负荷的可扩展性。

Conclusion: M2OE2-GL方法有效解决了大规模配电馈线中负荷预测的异质性和可扩展性问题，在保持计算效率的同时显著提升了预测精度。

Abstract: Probabilistic load forecasting is widely studied and underpins power system planning, operation, and risk-aware decision making. Deep learning forecasters have shown strong ability to capture complex temporal and contextual patterns, achieving substantial accuracy gains. However, at the scale of thousands or even hundreds of thousands of loads in large distribution feeders, a deployment dilemma emerges: training and maintaining one model per customer is computationally and storage intensive, while using a single global model ignores distributional shifts across customer types, locations, and phases. Prior work typically focuses on single-load forecasters, global models across multiple loads, or adaptive/personalized models for relatively small settings, and rarely addresses the combined challenges of heterogeneity and scalability in large feeders. We propose M2OE2-GL, a global-to-local extension of the M2OE2 probabilistic forecaster. We first pretrain a single global M2OE2 base model across all feeder loads, then apply lightweight fine-tuning to derive a compact family of group-specific forecasters. Evaluated on realistic utility data, M2OE2-GL yields substantial error reductions while remaining scalable to very large numbers of loads.

</details>


### [25] [QML-HCS: A Hypercausal Quantum Machine Learning Framework for Non-Stationary Environments](https://arxiv.org/abs/2511.17624)
*Hector E Mozo*

Main category: cs.LG

TL;DR: QML-HCS是一个量子启发的机器学习框架，通过超因果反馈动力学实现非平稳环境下的自适应行为，整合了量子叠加原理、动态因果反馈和确定性-随机混合执行。


<details>
  <summary>Details</summary>
Motivation: 解决当前机器学习和量子启发系统在非平稳环境中的局限性，如数据分布漂移、缺乏连续适应机制、因果稳定性和相干状态更新能力不足的问题。

Method: 采用统一计算架构，集成量子启发叠加原理、动态因果反馈和确定性-随机混合执行，实现可逆变换、多路径因果传播和漂移下替代状态评估。

Result: 框架展示了在输入分布突然变化时，超因果模型能够保持内部相干性并自适应调整，无需完全重新训练。

Conclusion: 该框架为未来理论扩展、基准测试研究以及与经典和量子模拟平台的集成建立了基础架构。

Abstract: QML-HCS is a research-grade framework for constructing and analyzing quantum-inspired machine learning models operating under hypercausal feedback dynamics. Hypercausal refers to AI systems that leverage extended, deep, or nonlinear causal relationships (expanded causality) to reason, predict, and infer states beyond the capabilities of traditional causal models. Current machine learning and quantum-inspired systems struggle in non-stationary environments, where data distributions drift and models lack mechanisms for continuous adaptation, causal stability, and coherent state updating. QML-HCS addresses this limitation through a unified computational architecture that integrates quantum-inspired superposition principles, dynamic causal feedback, and deterministic-stochastic hybrid execution to enable adaptive behavior in changing environments.
  The framework implements a hypercausal processing core capable of reversible transformations, multipath causal propagation, and evaluation of alternative states under drift. Its architecture incorporates continuous feedback to preserve causal consistency and adjust model behavior without requiring full retraining. QML-HCS provides a reproducible and extensible Python interface backed by efficient computational routines, enabling experimentation in quantum-inspired learning, causal reasoning, and hybrid computation without the need for specialized hardware.
  A minimal simulation demonstrates how a hypercausal model adapts to a sudden shift in the input distribution while preserving internal coherence. This initial release establishes the foundational architecture for future theoretical extensions, benchmarking studies, and integration with classical and quantum simulation platforms.

</details>


### [26] [Efficient Large-Scale Learning of Minimax Risk Classifiers](https://arxiv.org/abs/2511.17626)
*Kartheek Bondugula,Santiago Mazuelas,Aritz Pérez*

Main category: cs.LG

TL;DR: 提出了一种基于约束和列生成的组合学习算法，用于高效学习大规模多类分类任务中的极小极大风险分类器，相比现有方法实现了10-100倍的加速。


<details>
  <summary>Details</summary>
Motivation: 传统的随机次梯度方法无法有效处理极小极大风险分类器（MRCs），因为MRCs最小化的是最大期望损失而非平均损失，这在大规模多类分类任务中导致复杂的优化问题。

Method: 开发了一种结合约束生成和列生成的学习算法，专门用于高效训练大规模多类分类任务中的极小极大风险分类器。

Result: 在多个基准数据集上的实验表明，该算法在一般大规模数据上提供高达10倍的加速，在类别数量较多时提供约100倍的加速。

Conclusion: 所提出的算法成功解决了极小极大风险分类器在大规模多类分类中的训练效率问题，显著提升了计算性能。

Abstract: Supervised learning with large-scale data usually leads to complex optimization problems, especially for classification tasks with multiple classes. Stochastic subgradient methods can enable efficient learning with a large number of samples for classification techniques that minimize the average loss over the training samples. However, recent techniques, such as minimax risk classifiers (MRCs), minimize the maximum expected loss and are not amenable to stochastic subgradient methods. In this paper, we present a learning algorithm based on the combination of constraint and column generation that enables efficient learning of MRCs with large-scale data for classification tasks with multiple classes. Experiments on multiple benchmark datasets show that the proposed algorithm provides upto a 10x speedup for general large-scale data and around a 100x speedup with a sizeable number of classes.

</details>


### [27] [Rectifying Mean-Shift in Cascaded Precipitation Nowcasting](https://arxiv.org/abs/2511.17628)
*Fanbo Ju,Haiyuan Shi,Qingjian Ni*

Main category: cs.LG

TL;DR: 提出RectiCast框架，通过双Flow Matching模型显式解耦均值场偏移校正与局部随机性生成，解决降水临近预报中确定性预测的系统性分布偏移与局部随机性混淆的问题。


<details>
  <summary>Details</summary>
Motivation: 现有级联架构方法普遍忽视确定性预测中的系统性分布偏移与局部随机性的混淆问题，导致确定性分量的分布偏移污染概率分量的预测，特别是在较长的预报时效上造成降水模式和强度的不准确。

Method: 两阶段框架：第一阶段确定性模型生成后验均值；第二阶段引入Rectifier显式学习分布偏移并生成校正均值，然后Generator基于校正均值建模局部随机性。

Result: 在SEVIR和MeteoNet数据集上的实验表明，RectiCast相比现有最先进方法取得了显著性能提升。

Conclusion: RectiCast通过显式解耦均值场偏移校正与局部随机性生成，有效解决了降水临近预报中的分布偏移污染问题，提升了预报准确性。

Abstract: Precipitation nowcasting, which aims to provide high spatio-temporal resolution precipitation forecasts by leveraging current radar observations, is a core task in regional weather forecasting. The cascaded architecture has emerged as the mainstream paradigm for deep learning-based precipitation nowcasting. This paradigm involves a deterministic model to predict macroscopic trends (or posterior mean), followed by a probabilistic model to generate local details (or local stochasticity). However, existing methods commonly overlook the conflation of the systematic distribution shift in deterministic predictions and the local stochasticity. As a result, the deterministic component's distribution shift contaminates the predictions of the probabilistic component, leading to inaccuracies in precipitation patterns and intensity, particularly over longer lead times. To address this issue, we introduce RectiCast, a two-stage framework that explicitly decouples the correction of mean-field shift from the generation of local stochasticity via a dual Flow Matching model. In the first stage, a deterministic model generates the posterior mean. In the second stage, we introduce a Rectifier to explicitly learn the distribution shift and produce a rectified mean. Subsequently, a Generator focuses on modeling the local stochasticity conditioned on the rectified mean. Experiments on SEVIR and MeteoNet demonstrate that RectiCast achieves significant performance improvements over existing state-of-the-art methods.

</details>


### [28] [Can we use LLMs to bootstrap reinforcement learning? -- A case study in digital health behavior change](https://arxiv.org/abs/2511.17630)
*Nele Albers,Esra Cemre Su de Groot,Loes Keijsers,Manon H. Hillegers,Emiel Krahmer*

Main category: cs.LG

TL;DR: 本研究探索使用大型语言模型生成用户交互样本，用于训练数字行为改变场景中的强化学习模型，结果显示LLM生成的样本在缺乏真实数据时有用，且性能达到人类评估者水平。


<details>
  <summary>Details</summary>
Motivation: 个性化数字健康行为改变应用需要适应用户及其特定状态，但开发这类方法需要大量设计选择，其效果难以从文献预测且实践评估成本高昂。

Method: 使用大型语言模型生成用户交互样本，比较真实用户数据和人类评估者样本，分析不同提示策略（短/长提示、思维链提示、少样本提示）的效果。

Result: LLM生成的样本在缺乏真实数据时有用，性能达到人类评估者水平，不同提示策略的效果因研究和LLM而异，提示改写本身也会产生较大差异。

Conclusion: LLM生成的样本在实践中具有应用价值，提供了关于如何在实际中使用这些样本的建议。

Abstract: Personalizing digital applications for health behavior change is a promising route to making them more engaging and effective. This especially holds for approaches that adapt to users and their specific states (e.g., motivation, knowledge, wants) over time. However, developing such approaches requires making many design choices, whose effectiveness is difficult to predict from literature and costly to evaluate in practice. In this work, we explore whether large language models (LLMs) can be used out-of-the-box to generate samples of user interactions that provide useful information for training reinforcement learning models for digital behavior change settings. Using real user data from four large behavior change studies as comparison, we show that LLM-generated samples can be useful in the absence of real data. Comparisons to the samples provided by human raters further show that LLM-generated samples reach the performance of human raters. Additional analyses of different prompting strategies including shorter and longer prompt variants, chain-of-thought prompting, and few-shot prompting show that the relative effectiveness of different strategies depends on both the study and the LLM with also relatively large differences between prompt paraphrases alone. We provide recommendations for how LLM-generated samples can be useful in practice.

</details>


### [29] [Enhanced Federated Deep Multi-View Clustering under Uncertainty Scenario](https://arxiv.org/abs/2511.17631)
*Bingjun Wei,Xuemei Cao,Jiafen Liu,Haoyang Liang,Xin Yang*

Main category: cs.LG

TL;DR: 本文提出EFDMVC框架，解决联邦多视图聚类中视图异构性和语义冲突的双重不确定性，通过层次对比融合、视图自适应漂移模块和平衡聚合机制提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦多视图聚类假设客户端视图统一，但实际部署中存在视图完整性异构问题，现有方法忽略了动态视图组合产生的语义冲突，未能解决视图不确定性和聚合不确定性的双重挑战。

Method: 1) 层次对比融合：在客户端内对齐局部语义，消除视图不确定性；2) 视图自适应漂移模块：通过全局-局部原型对比动态修正参数偏差，缓解聚合不确定性；3) 平衡聚合机制：协调客户端更新。

Result: 实验结果表明EFDMVC在多个基准数据集上对异构不确定视图具有优越的鲁棒性，在全面评估中始终优于所有最先进的基线方法。

Conclusion: EFDMVC框架有效解决了联邦多视图聚类中的双重不确定性挑战，为处理视图异构性和语义冲突提供了创新解决方案。

Abstract: Traditional Federated Multi-View Clustering assumes uniform views across clients, yet practical deployments reveal heterogeneous view completeness with prevalent incomplete, redundant, or corrupted data. While recent approaches model view heterogeneity, they neglect semantic conflicts from dynamic view combinations, failing to address dual uncertainties: view uncertainty (semantic inconsistency from arbitrary view pairings) and aggregation uncertainty (divergent client updates with imbalanced contributions). To address these, we propose a novel Enhanced Federated Deep Multi-View Clustering framework: first align local semantics, hierarchical contrastive fusion within clients resolves view uncertainty by eliminating semantic conflicts; a view adaptive drift module mitigates aggregation uncertainty through global-local prototype contrast that dynamically corrects parameter deviations; and a balanced aggregation mechanism coordinates client updates. Experimental results demonstrate that EFDMVC achieves superior robustness against heterogeneous uncertain views across multiple benchmark datasets, consistently outperforming all state-of-the-art baselines in comprehensive evaluations.

</details>


### [30] [TTF: A Trapezoidal Temporal Fusion Framework for LTV Forecasting in Douyin](https://arxiv.org/abs/2511.17639)
*Yibing Wan,Zhengxiong Guan,Chaoli Zhang,Xiaoyang Li,Lai Xu,Beibei Jia,Zhenzhe Zheng,Fan Wu*

Main category: cs.LG

TL;DR: 本文提出了一种名为梯形时间融合（TTF）的新框架，用于解决用户增长场景中渠道级LTV预测的三个主要挑战：未对齐的多时间序列、短输入长输出（SILO）问题以及数据的波动性和非平稳性。


<details>
  <summary>Details</summary>
Motivation: 在用户增长场景中，互联网公司大量投资付费获取渠道来获取新用户，但可持续增长取决于获取用户的终身价值（LTV）超过客户获取成本（CAC）。为了最大化LTV/CAC比率，需要在早期阶段预测渠道级LTV以优化预算分配。

Method: 提出了梯形时间融合（TTF）框架，包括梯形多时间序列模块来处理数据未对齐和SILO挑战，以及使用名为MT-FusionNet的多塔结构输出准确预测。

Result: 该框架已在抖音的在线系统中部署。与之前部署的在线模型相比，LTV曲线的点状MAPE（MAPEp）降低了4.3%，聚合LTV的MAPE（MAPEa）降低了3.2%。

Conclusion: TTF框架有效解决了LTV预测中的关键挑战，显著提升了预测精度，并已成功应用于实际业务场景。

Abstract: In the user growth scenario, Internet companies invest heavily in paid acquisition channels to acquire new users. But sustainable growth depends on acquired users' generating lifetime value (LTV) exceeding customer acquisition cost (CAC). In order to maximize LTV/CAC ratio, it is crucial to predict channel-level LTV in an early stage for further optimization of budget allocation. The LTV forecasting problem is significantly different from traditional time series forecasting problems, and there are three main challenges. Firstly, it is an unaligned multi-time series forecasting problem that each channel has a number of LTV series of different activation dates. Secondly, to predict in the early stage, it faces the imbalanced short-input long-output (SILO) challenge. Moreover, compared with the commonly used time series datasets, the real LTV series are volatile and non-stationary, with more frequent fluctuations and higher variance. In this work, we propose a novel framework called Trapezoidal Temporal Fusion (TTF) to address the above challenges. We introduce a trapezoidal multi-time series module to deal with data unalignment and SILO challenges, and output accurate predictions with a multi-tower structure called MT-FusionNet. The framework has been deployed to the online system for Douyin. Compared to the previously deployed online model, MAPEp decreased by 4.3%, and MAPEa decreased by 3.2%, where MAPEp denotes the point-wise MAPE of the LTV curve and MAPEa denotes the MAPE of the aggregated LTV.

</details>


### [31] [BlockCert: Certified Blockwise Extraction of Transformer Mechanisms](https://arxiv.org/abs/2511.17645)
*Sandro Andric*

Main category: cs.LG

TL;DR: BlockCert是一个用于认证式块级提取transformer机制并支持认证局部编辑的框架，通过提取结构化替代实现并提供机器可检查的证书来保证近似误差界限。


<details>
  <summary>Details</summary>
Motivation: 解决机制可解释性和模型编辑领域缺乏正式保证的问题，为提取或编辑的模型在相关输入上的漂移提供明确界限。

Method: 基于预训练transformer和提示分布，提取残差块的结构化替代实现，提供包含近似误差界限、覆盖度指标和底层工件哈希的机器可检查证书，并使用Lipschitz-based组合定理将局部保证提升为全局偏差界限。

Result: 在GPT-2 small、TinyLlama-1.1B-Chat和Llama-3.2-3B上获得高块级覆盖度和小残差误差，在TinyLlama设置中完全拼接模型在压力提示上的困惑度与基线相差约6e-5。

Conclusion: 块级提取与显式证书对于实际transformer语言模型是可行的，为机制可解释性和模型行为的形式推理提供了实用桥梁。

Abstract: Mechanistic interpretability aspires to reverse-engineer neural networks into explicit algorithms, while model editing seeks to modify specific behaviours without retraining. Both areas are typically evaluated with informal evidence and ad-hoc experiments, with few explicit guarantees about how far an extracted or edited model can drift from the original on relevant inputs. We introduce BlockCert, a framework for certified blockwise extraction of transformer mechanisms, and outline how a lightweight extension can support certified local edits. Given a pre-trained transformer and a prompt distribution, BlockCert extracts structured surrogate implementations for residual blocks together with machine-checkable certificates that bound approximation error, record coverage metrics, and hash the underlying artifacts. We formalize a simple Lipschitz-based composition theorem in Lean 4 that lifts these local guarantees to a global deviation bound. Empirically, we apply the framework to GPT-2 small, TinyLlama-1.1B-Chat, and Llama-3.2-3B. Across these models we obtain high per-block coverage and small residual errors on the evaluated prompts, and in the TinyLlama setting we show that a fully stitched model matches the baseline perplexity within approximately 6e-5 on stress prompts. Our results suggest that blockwise extraction with explicit certificates is feasible for real transformer language models and offers a practical bridge between mechanistic interpretability and formal reasoning about model behaviour.

</details>


### [32] [MamTiff-CAD: Multi-Scale Latent Diffusion with Mamba+ for Complex Parametric Sequence](https://arxiv.org/abs/2511.17647)
*Liyuan Deng,Yunpeng Bai,Yongkang Dai,Xiaoshui Huang,Hongping Gan,Dongshuo Huang,Hao jiacheng,Yilei Shi*

Main category: cs.LG

TL;DR: MamTiff-CAD是一个基于Transformer扩散模型的CAD参数化命令序列生成框架，通过多尺度潜在表示处理长序列CAD建模问题，在60-256命令长度的序列生成中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的CAD参数化方法在处理复杂CAD模型的几何和拓扑约束时，难以生成长序列参数命令，需要解决这一挑战。

Method: 设计集成Mamba+和Transformer的新型自编码器，将参数化CAD序列转换为潜在表示；Mamba+块采用遗忘门机制捕获长程依赖；基于多尺度Transformer的扩散模型学习长序列命令分布。

Result: 实验表明MamTiff-CAD在重建和生成任务上均达到最先进性能，特别在长序列(60-256)CAD模型生成中表现优异。

Conclusion: MamTiff-CAD框架通过多尺度潜在表示和扩散模型，有效解决了长序列CAD参数化命令生成问题，为复杂CAD模型生成提供了有效解决方案。

Abstract: Parametric Computer-Aided Design (CAD) is crucial in industrial applications, yet existing approaches often struggle to generate long sequence parametric commands due to complex CAD models' geometric and topological constraints. To address this challenge, we propose MamTiff-CAD, a novel CAD parametric command sequences generation framework that leverages a Transformer-based diffusion model for multi-scale latent representations. Specifically, we design a novel autoencoder that integrates Mamba+ and Transformer, to transfer parameterized CAD sequences into latent representations. The Mamba+ block incorporates a forget gate mechanism to effectively capture long-range dependencies. The non-autoregressive Transformer decoder reconstructs the latent representations. A diffusion model based on multi-scale Transformer is then trained on these latent embeddings to learn the distribution of long sequence commands. In addition, we also construct a dataset that consists of long parametric sequences, which is up to 256 commands for a single CAD model. Experiments demonstrate that MamTiff-CAD achieves state-of-the-art performance on both reconstruction and generation tasks, confirming its effectiveness for long sequence (60-256) CAD model generation.

</details>


### [33] [Frugality in second-order optimization: floating-point approximations for Newton's method](https://arxiv.org/abs/2511.17660)
*Giuseppe Carrino,Elena Loli Piccolomini,Elisa Riccietti,Theo Mary*

Main category: cs.LG

TL;DR: 该论文分析了有限精度算术对牛顿步长的影响，建立了混合精度牛顿优化器的收敛定理，并提出了GN_k方法，在回归任务中实现与完整牛顿法相当的性能但需要更少的导数计算。


<details>
  <summary>Details</summary>
Motivation: 虽然一阶方法在机器学习训练中占主导地位，但高阶方法如牛顿法可以提供更高的精度和更快的收敛速度，但由于计算成本高而常常被避免使用。

Method: 分析有限精度算术对牛顿步长的影响，建立混合精度牛顿优化器的收敛定理，并提出GN_k方法（广义高斯-牛顿法）实现部分二阶导数计算。

Result: 在标准回归基准测试中，所提出的方法在Australian和MUSH数据集上优于Adam。GN_k在回归任务中达到与完整牛顿法相当的性能，同时显著减少导数计算次数。

Conclusion: 混合精度牛顿优化器和GN_k方法为机器学习训练提供了高效的高阶优化方案，在保持性能的同时降低了计算成本。

Abstract: Minimizing loss functions is central to machine-learning training. Although first-order methods dominate practical applications, higher-order techniques such as Newton's method can deliver greater accuracy and faster convergence, yet are often avoided due to their computational cost. This work analyzes the impact of finite-precision arithmetic on Newton steps and establishes a convergence theorem for mixed-precision Newton optimizers, including "quasi" and "inexact" variants. The theorem provides not only convergence guarantees but also a priori estimates of the achievable solution accuracy. Empirical evaluations on standard regression benchmarks demonstrate that the proposed methods outperform Adam on the Australian and MUSH datasets. The second part of the manuscript introduces GN_k, a generalized Gauss-Newton method that enables partial computation of second-order derivatives. GN_k attains performance comparable to full Newton's method on regression tasks while requiring significantly fewer derivative evaluations.

</details>


### [34] [Enhancing Breast Cancer Prediction with LLM-Inferred Confounders](https://arxiv.org/abs/2511.17662)
*Debmita Roy*

Main category: cs.LG

TL;DR: 使用大型语言模型从常规临床数据中推断糖尿病、肥胖和心血管疾病等混杂疾病的概率，以增强乳腺癌预测。AI生成的特征提高了随机森林模型的性能，特别是Gemma（3.9%）和Llama（6.4%）模型。该方法在无创预筛查和临床整合方面显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 通过利用大型语言模型从常规临床数据中推断混杂疾病的可能性，提高乳腺癌预测的准确性，支持早期检测和共享决策。

Method: 使用大型语言模型（如Gemma和Llama）从常规临床数据中生成AI特征，然后将这些特征输入随机森林模型进行乳腺癌预测。

Result: AI生成的特征显著提高了随机森林模型的性能，特别是Gemma模型提升了3.9%，Llama模型提升了6.4%。

Conclusion: 该方法在乳腺癌无创预筛查和临床整合方面具有应用潜力，能够改善早期检测和共享决策过程。

Abstract: This study enhances breast cancer prediction by using large language models to infer the likelihood of confounding diseases, namely diabetes, obesity, and cardiovascular disease, from routine clinical data. These AI-generated features improved Random Forest model performance, particularly for LLMs like Gemma (3.9%) and Llama (6.4%). The approach shows promise for noninvasive prescreening and clinical integration, supporting improved early detection and shared decision-making in breast cancer diagnosis.

</details>


### [35] [AI-based framework to predict animal and pen feed intake in feedlot beef cattle](https://arxiv.org/abs/2511.17663)
*Alex S. C. Maia,John B. Hall,Hugo F. M. Milan,Izabelle A. M. A. Teixeira*

Main category: cs.LG

TL;DR: 开发了一个基于AI的框架，利用电子饲喂系统生成的大数据预测个体动物和围栏级别的采食量，结合环境数据创建了两个新环境指数，XGBoost模型在个体和围栏级别分别达到1.38 kg/天和0.14 kg/(天-动物)的预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏充分利用纵向大数据预测采食量的方法，特别是在考虑环境条件的情况下。电子饲喂系统产生的大数据为开发自主精准畜牧系统提供了可能性。

Method: 使用19个实验的1650万样本数据和环境数据，开发了两个新环境指数：基于气象变量的InComfort-Index和整合环境变量与采食行为的EASI-Index。训练机器学习模型，其中XGBoost表现最佳。

Result: InComfort-Index对热舒适度预测良好但对采食量预测有限；EASI-Index在采食量预测方面表现良好但对热舒适度预测效果较差。XGBoost模型在个体和围栏级别的预测精度分别为RMSE 1.38 kg/天和0.14 kg/(天-动物)。

Conclusion: 该方法为预测个体动物和围栏采食量提供了一个稳健的AI框架，在精准管理育肥牛、减少饲料浪费、优化资源和气候适应性畜牧管理方面具有应用潜力。

Abstract: Advances in technology are transforming sustainable cattle farming practices, with electronic feeding systems generating big longitudinal datasets on individual animal feed intake, offering the possibility for autonomous precision livestock systems. However, the literature still lacks a methodology that fully leverages these longitudinal big data to accurately predict feed intake accounting for environmental conditions. To fill this gap, we developed an AI-based framework to accurately predict feed intake of individual animals and pen-level aggregation. Data from 19 experiments (>16.5M samples; 2013-2024) conducted at Nancy M. Cummings Research Extension & Education Center (Carmen, ID) feedlot facility and environmental data from AgriMet Network weather stations were used to develop two novel environmental indices: InComfort-Index, based solely on meteorological variables, showed good predictive capability for thermal comfort but had limited ability to predict feed intake; EASI-Index, a hybrid index integrating environmental variables with feed intake behavior, performed well in predicting feed intake but was less effective for thermal comfort. Together with the environmental indices, machine learning models were trained and the best-performing machine learning model (XGBoost) accuracy was RMSE of 1.38 kg/day for animal-level and only 0.14 kg/(day-animal) at pen-level. This approach provides a robust AI-based framework for predicting feed intake in individual animals and pens, with potential applications in precision management of feedlot cattle, through feed waste reduction, resource optimization, and climate-adaptive livestock management.

</details>


### [36] [CubeletWorld: A New Abstraction for Scalable 3D Modeling](https://arxiv.org/abs/2511.17664)
*Azlaan Mustafa Samad,Hoang H. Nguyen,Lukas Berg,Henrik Müller,Yuan Xue,Daniel Kudenko,Zahra Ahmadi*

Main category: cs.LG

TL;DR: CubeletWorld是一个新颖的城市环境表示框架，通过离散化的3D网格单元（cubelets）来整合异构城市数据，实现隐私保护的建模，支持规划、导航和占用预测等下游任务。


<details>
  <summary>Details</summary>
Motivation: 现代城市产生大量异构数据，但将这些数据整合到连贯的空间模型中仍具挑战性。现有基于智能体感知的方法存在可扩展性限制和隐私问题，需要一种新的抽象表示方法。

Method: 提出CubeletWorld框架，将城市环境离散化为3D网格单元（cubelets），将基础设施、移动性、环境指标等多样化数据嵌入到局部化的cubelet状态中，实现隐私保护建模。

Result: 开发了CubeletWorld状态预测任务，评估了适用于该设置的改进核心模型，分析了空间粒度增加带来的稀疏性表示和基线可扩展性挑战。与现有3D占用预测模型相比，cubelet中心方法在空间单元级别推断状态，具有更好的区域通用性和隐私合规性。

Conclusion: CubeletWorld提供了一个灵活可扩展的框架，能够从复杂的城市数据中学习，为可扩展模拟和决策支持开辟了新可能性，适用于社会人口建模、环境监测和应急响应等领域。

Abstract: Modern cities produce vast streams of heterogeneous data, from infrastructure maps to mobility logs and satellite imagery. However, integrating these sources into coherent spatial models for planning and prediction remains a major challenge. Existing agent-centric methods often rely on direct environmental sensing, limiting scalability and raising privacy concerns. This paper introduces CubeletWorld, a novel framework for representing and analyzing urban environments through a discretized 3D grid of spatial units called cubelets. This abstraction enables privacy-preserving modeling by embedding diverse data signals, such as infrastructure, movement, or environmental indicators, into localized cubelet states. CubeletWorld supports downstream tasks such as planning, navigation, and occupancy prediction without requiring agent-driven sensing. To evaluate this paradigm, we propose the CubeletWorld State Prediction task, which involves predicting the cubelet state using a realistic dataset containing various urban elements like streets and buildings through this discretized representation. We explore a range of modified core models suitable for our setting and analyze challenges posed by increasing spatial granularity, specifically the issue of sparsity in representation and scalability of baselines. In contrast to existing 3D occupancy prediction models, our cubelet-centric approach focuses on inferring state at the spatial unit level, enabling greater generalizability across regions and improved privacy compliance. Our results demonstrate that CubeletWorld offers a flexible and extensible framework for learning from complex urban data, and it opens up new possibilities for scalable simulation and decision support in domains such as socio-demographic modeling, environmental monitoring, and emergency response. The code and datasets can be downloaded from here.

</details>


### [37] [Lane-Frame Quantum Multimodal Driving Forecasts for the Trajectory of Autonomous Vehicles](https://arxiv.org/abs/2511.17675)
*Navneet Singh,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 提出了一种紧凑的混合量子架构，用于自动驾驶轨迹预测，通过量子注意力编码器和参数精简的量子前馈堆栈，在单次前向传播中生成16个轨迹假设，并在Waymo数据集上优于运动学基线。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶轨迹预测需要在严格的计算和延迟约束下提供准确、校准的多模态未来预测，现有方法在效率和性能上存在挑战。

Method: 采用混合量子架构，包括量子注意力编码器（9量子比特）、参数精简的量子前馈堆栈（64层，约1200个可训练角度）和基于傅里叶的解码器，在自我中心、车道对齐的框架中预测对运动学基线的残差修正。

Result: 在Waymo Open Motion Dataset上，模型在2.0秒预测范围内实现了minADE 1.94米和minFDE 3.56米，持续优于运动学基线，减少了漏检率并具有强召回率。

Conclusion: 残差学习、截断傅里叶解码、浅层纠缠和基于频谱的排序将容量集中在关键区域，实现了稳定优化和可靠的多模态预测，证明了小型浅层量子电路在现代自动驾驶基准上的有效性。

Abstract: Trajectory forecasting for autonomous driving must deliver accurate, calibrated multi-modal futures under tight compute and latency constraints. We propose a compact hybrid quantum architecture that aligns quantum inductive bias with road-scene structure by operating in an ego-centric, lane-aligned frame and predicting residual corrections to a kinematic baseline instead of absolute poses. The model combines a transformer-inspired quantum attention encoder (9 qubits), a parameter-lean quantum feedforward stack (64 layers, ${\sim}1200$ trainable angles), and a Fourier-based decoder that uses shallow entanglement and phase superposition to generate 16 trajectory hypotheses in a single pass, with mode confidences derived from the latent spectrum. All circuit parameters are trained with Simultaneous Perturbation Stochastic Approximation (SPSA), avoiding backpropagation through non-analytic components. In the Waymo Open Motion Dataset, the model achieves minADE (minimum Average Displacement Error) of \SI{1.94}{m} and minFDE (minimum Final Displacement Error) of \SI{3.56}{m} in the $16$ models predicted over the horizon of \SI{2.0}{s}, consistently outperforming a kinematic baseline with reduced miss rates and strong recall. Ablations confirm that residual learning in the lane frame, truncated Fourier decoding, shallow entanglement, and spectrum-based ranking focus capacity where it matters, yielding stable optimization and reliable multi-modal forecasts from small, shallow quantum circuits on a modern autonomous-driving benchmark.

</details>


### [38] [A Hybrid Classical-Quantum Fine Tuned BERT for Text Classification](https://arxiv.org/abs/2511.17677)
*Abu Kaisar Mohammad Masum,Naveed Mahmud,M. Hassan Najafi,Sercan Aygun*

Main category: cs.LG

TL;DR: 提出了一种将n量子比特量子电路与经典BERT模型结合的混合方法用于文本分类，实验表明该混合模型在标准基准数据集上具有竞争力甚至优于经典基线。


<details>
  <summary>Details</summary>
Motivation: BERT微调在文本分类中计算成本高且需要仔细的超参数调优，而量子算法在机器学习和文本分类任务中显示出超越传统方法的潜力。

Method: 集成n量子比特量子电路与经典BERT模型，构建经典-量子混合模型进行文本分类。

Result: 混合模型在标准基准数据集上表现出与经典基线相当甚至更好的性能，证明了该方法在微调预训练模型方面的适应性。

Conclusion: 该混合模型展示了量子计算在提升文本分类任务性能方面的潜力，为这一研究领域的发展提供了可行性证明。

Abstract: Fine-tuning BERT for text classification can be computationally challenging and requires careful hyper-parameter tuning. Recent studies have highlighted the potential of quantum algorithms to outperform conventional methods in machine learning and text classification tasks. In this work, we propose a hybrid approach that integrates an n-qubit quantum circuit with a classical BERT model for text classification. We evaluate the performance of the fine-tuned classical-quantum BERT and demonstrate its feasibility as well as its potential in advancing this research area. Our experimental results show that the proposed hybrid model achieves performance that is competitive with, and in some cases better than, the classical baselines on standard benchmark datasets. Furthermore, our approach demonstrates the adaptability of classical-quantum models for fine-tuning pre-trained models across diverse datasets. Overall, the hybrid model highlights the promise of quantum computing in achieving improved performance for text classification tasks.

</details>


### [39] [Enhancing Adversarial Transferability through Block Stretch and Shrink](https://arxiv.org/abs/2511.17688)
*Quan Liu,Feng Ye,Chenhao Lu,Shuming Zhen,Guanliang Huang,Lunzhe Chen,Xudong Ke*

Main category: cs.LG

TL;DR: 本文提出了一种名为Block Stretch and Shrink (BSS)的输入变换对抗攻击方法，通过将图像分割成块并应用拉伸和收缩操作来增强对抗样本的跨模型可转移性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于输入变换的对抗攻击方法在跨模型可转移性方面表现有限。研究表明，高可转移性与多样化的注意力热图和保持变换输入中的全局语义相关。

Method: 提出BSS方法，将图像分割成块，并对这些块应用拉伸和收缩操作，从而在保持全局语义的同时多样化变换输入中的注意力热图。

Result: 在ImageNet子集上的实证评估表明，BSS在可转移性方面优于现有的基于输入变换的攻击方法。

Conclusion: BSS方法有效提升了对抗样本的跨模型可转移性，并建议在统一的变换输入数量尺度下评估基于输入变换的攻击方法，以确保公平可比的评估。

Abstract: Adversarial attacks introduce small, deliberately crafted perturbations that mislead neural networks, and their transferability from white-box to black-box target models remains a critical research focus. Input transformation-based attacks are a subfield of adversarial attacks that enhance input diversity through input transformations to improve the transferability of adversarial examples. However, existing input transformation-based attacks tend to exhibit limited cross-model transferability. Previous studies have shown that high transferability is associated with diverse attention heatmaps and the preservation of global semantics in transformed inputs. Motivated by this observation, we propose Block Stretch and Shrink (BSS), a method that divides an image into blocks and applies stretch and shrink operations to these blocks, thereby diversifying attention heatmaps in transformed inputs while maintaining their global semantics. Empirical evaluations on a subset of ImageNet demonstrate that BSS outperforms existing input transformation-based attack methods in terms of transferability. Furthermore, we examine the impact of the number scale, defined as the number of transformed inputs, in input transformation-based attacks, and advocate evaluating these methods under a unified number scale to enable fair and comparable assessments.

</details>


### [40] [DeepCoT: Deep Continual Transformers for Real-Time Inference on Data Streams](https://arxiv.org/abs/2511.17693)
*Ginés Carreto Picón,Peng Yuan Zhou,Qi Zhang,Alexandros Iosifidis*

Main category: cs.LG

TL;DR: DeepCoT是一种无冗余的仅编码器模型，可在现有深度编码器架构上应用，为流数据推理提供线性计算成本，相比先前高效模型减少两个数量级的运行时间。


<details>
  <summary>Details</summary>
Motivation: Transformer模型参数规模不断增大以处理复杂任务，但资源受限设备需要低延迟推理。流数据推理在滑动时间窗口上执行会导致高度冗余计算，现有Continual Transformers仅适用于浅层模型，限制了其应用范围和泛化能力。

Method: 提出Deep Continual Transformer (DeepCoT)，这是一种无冗余的仅编码器模型，可对现有深度编码器架构进行最小修改即可应用。

Result: 在音频、视频和文本流上的实验表明，DeepCoT与其非持续基线相比保持相当性能，同时为所有Transformer层提供线性计算成本，相比先前高效模型减少高达两个数量级的运行时间。

Conclusion: DeepCoT成功解决了深度模型中流数据推理的冗余计算问题，在保持性能的同时显著提升了计算效率。

Abstract: Transformer-based models have dramatically increased their size and parameter count to tackle increasingly complex tasks. At the same time, there is a growing demand for low-latency inference on resource-constrained devices that achieves high performance. In particular, stream data inference is typically performed over a sliding temporal window, leading to highly redundant computations. The recent Continual Transformers have addressed this issue, but they can only be effectively used in shallow models, which limits their scope and generalization power. In this paper, we propose the Deep Continual Transformer (DeepCoT), a redundancy-free encoder-only model that can be applied over existing deep encoder architectures with minimal changes. In our experiments over audio, video, and text streams, we show that DeepCoTs retain comparative performance to their non-continual baselines while offering a linear computational cost for all Transformer layers, which reduces up to two orders of magnitude in the running time compared to previous efficient models.

</details>


### [41] [Diffusion Models are Molecular Dynamics Simulators](https://arxiv.org/abs/2511.17741)
*Justin Diamond,Markus Lill*

Main category: cs.LG

TL;DR: 本文证明了带序列偏置的降噪扩散采样器等价于过阻尼朗之万动力学的欧拉-马鲁亚马积分器，将扩散采样与朗之万时间演化建立精确对应关系，从而将分子动力学重新表述为扩散模型框架。


<details>
  <summary>Details</summary>
Motivation: 传统分子动力学模拟受限于极小的时间步长，本文旨在通过扩散模型框架摆脱这一限制，实现完全数据驱动的分子动力学，无需手工设计的力场或轨迹数据训练。

Method: 将降噪扩散采样器解释为朗之万动力学的积分器，利用学习到的分数作为漂移项（即学习能量的梯度），通过模型容量和降噪步数两个可扩展参数控制精度。

Result: 建立了轨迹级信息论误差界限，清晰分离离散化误差与分数模型误差，证明即使仅使用静态配置训练，也能生成具有分子动力学时间相关性的轨迹。

Conclusion: 该框架实现了完全数据驱动的分子动力学，从非相关平衡快照学习力场，无需轨迹数据训练，仍能保持与学习能量相关的玻尔兹曼分布。

Abstract: We prove that a denoising diffusion sampler equipped with a sequential bias across the batch dimension is exactly an Euler-Maruyama integrator for overdamped Langevin dynamics. Each reverse denoising step, with its associated spring stiffness, can be interpreted as one step of a stochastic differential equation with an effective time step set jointly by the noise schedule and that stiffness. The learned score then plays the role of the drift, equivalently the gradient of a learned energy, yielding a precise correspondence between diffusion sampling and Langevin time evolution.
  This equivalence recasts molecular dynamics (MD) in terms of diffusion models. Accuracy is no longer tied to a fixed, extremely small MD time step; instead, it is controlled by two scalable knobs: model capacity, which governs how well the drift is approximated, and the number of denoising steps, which sets the integrator resolution. In practice, this leads to a fully data-driven MD framework that learns forces from uncorrelated equilibrium snapshots, requires no hand-engineered force fields, uses no trajectory data for training, and still preserves the Boltzmann distribution associated with the learned energy.
  We derive trajectory-level, information-theoretic error bounds that cleanly separate discretization error from score-model error, clarify how temperature enters through the effective spring, and show that the resulting sampler generates molecular trajectories with MD-like temporal correlations, even though the model is trained only on static configurations.

</details>


### [42] [PrismSSL: One Interface, Many Modalities; A Single-Interface Library for Multimodal Self-Supervised Learning](https://arxiv.org/abs/2511.17776)
*Melika Shirian,Kianoosh Vadaei,Kian Majlessi,Audrina Ebrahimi,Arshia Hemmat,Peyman Adibi,Hossein Karshenas*

Main category: cs.LG

TL;DR: PrismSSL是一个统一的Python库，集成了音频、视觉、图和跨模态领域最先进的自监督学习方法，提供模块化代码库和图形化仪表板。


<details>
  <summary>Details</summary>
Motivation: 为研究人员和从业者提供一个统一的框架，简化自监督学习的安装、配置和训练过程，支持多种模态和方法的快速实现与扩展。

Method: 采用模块化设计，集成HuggingFace Transformers，提供分布式训练、超参数搜索、LoRA微调、嵌入可视化等功能，并构建基于Flask的图形化仪表板。

Result: 开发了PrismSSL库，已打包在PyPI上发布，支持MIT许可证，提供完整的训练流程和可视化工具，确保代码和配方的公开可复现。

Conclusion: PrismSSL成功统一了多模态自监督学习方法，通过简洁的代码和图形界面显著提升了研究效率和可用性。

Abstract: We present PrismSSL, a Python library that unifies state-of-the-art self-supervised learning (SSL) methods across audio, vision, graphs, and cross-modal settings in a single, modular codebase. The goal of the demo is to show how researchers and practitioners can: (i) install, configure, and run pretext training with a few lines of code; (ii) reproduce compact benchmarks; and (iii) extend the framework with new modalities or methods through clean trainer and dataset abstractions. PrismSSL is packaged on PyPI, released under the MIT license, integrates tightly with HuggingFace Transformers, and provides quality-of-life features such as distributed training in PyTorch, Optuna-based hyperparameter search, LoRA fine-tuning for Transformer backbones, animated embedding visualizations for sanity checks, Weights & Biases logging, and colorful, structured terminal logs for improved usability and clarity. In addition, PrismSSL offers a graphical dashboard - built with Flask and standard web technologies - that enables users to configure and launch training pipelines with minimal coding. The artifact (code and data recipes) will be publicly available and reproducible.

</details>


### [43] [Smoothed Agnostic Learning of Halfspaces over the Hypercube](https://arxiv.org/abs/2511.17782)
*Yiwen Kou,Raghu Meka*

Main category: cs.LG

TL;DR: 本文提出了一个基于随机比特翻转的平滑不可知学习框架，用于布尔半空间的平滑不可知学习，克服了传统高斯扰动在离散域中的局限性。


<details>
  <summary>Details</summary>
Motivation: 布尔半空间的不可知学习在计算学习理论中是一个基本问题，但即使在弱学习下也被证明是计算困难的。现有平滑分析框架依赖加性高斯扰动，不适合离散域。

Method: 引入新的平滑不可知学习框架，通过随机比特翻转建模扰动，定义离散类比于高斯情况的平滑最优性。在输入分布的严格次指数假设下，提出高效学习算法。

Result: 在该模型下给出了学习半空间的高效算法，运行时间和样本复杂度约为n的poly(1/(sigma * epsilon))次方。这是布尔超立方体上平滑不可知学习半空间的第一个计算高效保证。

Conclusion: 该结果在离散设置中弥合了最坏情况不可处理性与实际可学习性之间的差距，为布尔超立方体上的平滑不可知学习提供了首个计算高效保证。

Abstract: Agnostic learning of Boolean halfspaces is a fundamental problem in computational learning theory, but it is known to be computationally hard even for weak learning. Recent work [CKKMK24] proposed smoothed analysis as a way to bypass such hardness, but existing frameworks rely on additive Gaussian perturbations, making them unsuitable for discrete domains. We introduce a new smoothed agnostic learning framework for Boolean inputs, where perturbations are modeled via random bit flips. This defines a natural discrete analogue of smoothed optimality generalizing the Gaussian case. Under strictly subexponential assumptions on the input distribution, we give an efficient algorithm for learning halfspaces in this model, with runtime and sample complexity approximately n raised to a poly(1/(sigma * epsilon)) factor. Previously, such algorithms were known only with strong structural assumptions for the discrete hypercube, for example, independent coordinates or symmetric distributions. Our result provides the first computationally efficient guarantee for smoothed agnostic learning of halfspaces over the Boolean hypercube, bridging the gap between worst-case intractability and practical learnability in discrete settings.

</details>


### [44] [Improved Sample Complexity for Full Coverage in Compact and Continuous Spaces](https://arxiv.org/abs/2511.17784)
*Lyu Yuhuan*

Main category: cs.LG

TL;DR: 本文研究了在d维单位超立方体上的均匀随机采样，通过应用集中不等式到未覆盖子立方体计数统计量，推导出样本复杂度边界，该边界与失败概率δ呈对数依赖关系，相比经典的线性1/δ依赖有显著改进。


<details>
  <summary>Details</summary>
Motivation: 经典的覆盖分析在小失败概率下往往产生保守边界，需要开发更紧的理论工具来支持依赖网格覆盖保证的算法，特别是在高置信度机制中实现更高效采样。

Method: 在d维单位超立方体上进行均匀随机采样，分析离散化后的未覆盖子立方体数量，应用集中不等式到未覆盖计数统计量，并在标准Lipschitz和均匀性假设下进行自包含推导。

Result: 推导出样本复杂度边界M = O(˜C ln(2˜C/δ))，具有对数依赖δ的特性，数值研究表明该边界能更紧密地跟踪实际覆盖需求，并在δ→0时具有良好的可扩展性。

Conclusion: 该研究为依赖网格覆盖保证的算法提供了更锐利的理论工具，特别是在高置信度机制中实现了更高效的采样，相比经典优惠券收集器速率有显著改进。

Abstract: Verifying uniform conditions over continuous spaces through random sampling is fundamental in machine learning and control theory, yet classical coverage analyses often yield conservative bounds, particularly at small failure probabilities. We study uniform random sampling on the $d$-dimensional unit hypercube and analyze the number of uncovered subcubes after discretization. By applying a concentration inequality to the uncovered-count statistic, we derive a sample complexity bound with a logarithmic dependence on the failure probability ($δ$), i.e., $M =O( \tilde{C}\ln(\frac{2\tilde{C}}δ))$, which contrasts sharply with the classical linear $1/δ$ dependence. Under standard Lipschitz and uniformity assumptions, we present a self-contained derivation and compare our result with classical coupon-collector rates. Numerical studies across dimensions, precision levels, and confidence targets indicate that our bound tracks practical coverage requirements more tightly and scales favorably as $δ\to 0$. Our findings offer a sharper theoretical tool for algorithms that rely on grid-based coverage guarantees, enabling more efficient sampling, especially in high-confidence regimes.

</details>


### [45] [Data-Driven Predictive Modeling of Microfluidic Cancer Cell Separation Using a Deterministic Lateral Displacement Device](https://arxiv.org/abs/2511.17787)
*Elizabeth Chen,Andrew Lee,Tanbir Sarowar,Xiaolin Chen*

Main category: cs.LG

TL;DR: 本研究使用机器学习模型优化确定性侧向位移（DLD）设备的设计参数，以提高肺癌细胞分离效率，为癌症早期诊断提供数据驱动的自动化设计框架。


<details>
  <summary>Details</summary>
Motivation: 解决循环肿瘤细胞（CTCs）检测中的稀有细胞识别挑战，减少对计算密集型模拟的依赖，开发高通量、成本效益高的DLD设备设计方法。

Method: 采用梯度提升、k近邻、随机森林和多层感知器（MLP）回归器等机器学习模型，基于大量数值验证数据集预测粒子轨迹并识别最优设备配置。

Result: 机器学习模型能够准确预测粒子轨迹，识别关键设计变量，实现DLD设备的自动化优化。

Conclusion: 这种集成方法推进了可扩展和精确微流体系统的发展，为癌症早期检测和个性化医疗做出贡献。

Abstract: Deterministic Lateral Displacement (DLD) devices are widely used in microfluidics for label-free, size-based separation of particles and cells, with particular promise in isolating circulating tumor cells (CTCs) for early cancer diagnostics. This study focuses on the optimization of DLD design parameters, such as row shift fraction, post size, and gap distance, to enhance the selective isolation of lung cancer cells based on their physical properties. To overcome the challenges of rare CTC detection and reduce reliance on computationally intensive simulations, machine learning models including gradient boosting, k-nearest neighbors, random forest, and multilayer perceptron (MLP) regressors are employed. Trained on a large, numerically validated dataset, these models predict particle trajectories and identify optimal device configurations, enabling high-throughput and cost-effective DLD design. Beyond trajectory prediction, the models aid in isolating critical design variables, offering a systematic, data-driven framework for automated DLD optimization. This integrative approach advances the development of scalable and precise microfluidic systems for cancer diagnostics, contributing to the broader goals of early detection and personalized medicine.

</details>


### [46] [Semi-Supervised Federated Multi-Label Feature Selection with Fuzzy Information Measures](https://arxiv.org/abs/2511.17796)
*Afsaneh Mahanipour,Hana Khamfroush*

Main category: cs.LG

TL;DR: 提出了一种半监督联邦多标签特征选择方法SSFMLFS，解决了分布式环境中客户端只有未标记数据而服务器有少量标记数据的场景，通过模糊信息理论和PageRank算法进行特征选择。


<details>
  <summary>Details</summary>
Motivation: 现有多标签特征选择方法需要集中式数据，不适合分布式和联邦环境；且联邦方法通常假设客户端有标记数据，这在客户端缺乏专业知识或资源时是不现实的。

Method: SSFMLFS方法：客户端计算模糊相似矩阵并传输给服务器，服务器计算特征冗余度和特征-标签相关性度，构建特征图（特征为顶点，相关性和冗余度为权重），应用PageRank算法对特征重要性进行排序。

Result: 在五个真实世界数据集（生物学、图像、音乐、文本）上的广泛实验表明，在非IID数据分布设置下，SSFMLFS在三种不同评估指标上优于其他联邦和集中式监督及半监督方法。

Conclusion: SSFMLFS方法有效解决了联邦环境中客户端只有未标记数据的多标签特征选择问题，在非IID数据分布下表现优异。

Abstract: Multi-label feature selection (FS) reduces the dimensionality of multi-label data by removing irrelevant, noisy, and redundant features, thereby boosting the performance of multi-label learning models. However, existing methods typically require centralized data, which makes them unsuitable for distributed and federated environments where each device/client holds its own local dataset. Additionally, federated methods often assume that clients have labeled data, which is unrealistic in cases where clients lack the expertise or resources to label task-specific data. To address these challenges, we propose a Semi-Supervised Federated Multi-Label Feature Selection method, called SSFMLFS, where clients hold only unlabeled data, while the server has limited labeled data. SSFMLFS adapts fuzzy information theory to a federated setting, where clients compute fuzzy similarity matrices and transmit them to the server, which then calculates feature redundancy and feature-label relevancy degrees. A feature graph is constructed by modeling features as vertices, assigning relevancy and redundancy degrees as vertex weights and edge weights, respectively. PageRank is then applied to rank the features by importance. Extensive experiments on five real-world datasets from various domains, including biology, images, music, and text, demonstrate that SSFMLFS outperforms other federated and centralized supervised and semi-supervised approaches in terms of three different evaluation metrics in non-IID data distribution setting.

</details>


### [47] [Layer-Wise High-Impact Parameter Ratio Optimization in Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2511.17801)
*Cuong Pham,Hoang Anh Dung,Cuong C. Nguyen,Trung Le,Gustavo Carneiro,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 提出了一种二次优化框架，用于确定层特定的高影响参数比例，考虑层间依赖关系，在资源受限预算下实现计算效率和模型精度的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法在极低位宽下精度损失严重，主要由于高影响参数对量化性能影响显著，且现有方法对所有层使用固定比例的高影响参数，忽略了层间敏感性差异。

Method: 使用二次优化框架确定层特定的高影响参数比例，将高影响参数量化为中等位宽，其余参数量化为极低位宽，并针对不同参数类型应用不同的量化方法。

Result: 在相同资源约束预算下，比保持少量FP16参数的方法能保留更多高影响参数，实现了计算效率和模型精度的有效平衡。

Conclusion: 该方法在保持高性能的同时，相比最先进方法实现了更好的计算效率与模型精度平衡。

Abstract: Large language models (LLMs) have significantly advanced natural language processing, but their massive parameter counts create substantial computational and memory challenges during deployment. Post-training quantization (PTQ) has emerged as a promising approach to mitigate these challenges with minimal overhead. While existing PTQ methods can effectively quantize LLMs, they experience substantial accuracy loss at extremely low bit-widths, primarily due to high-impact parameters that significantly influence quantization performance. Several approaches address these issues by identifying and retaining the high-impact parameters in FP16 format. However, they apply fixed ratios of high-impact parameters across all layers, overlooking layer-wise sensitivity variations. In this paper, we propose a quadratic optimization framework that determines layer-specific ratios of high-impact parameters while considering inter-layer dependencies. We quantize high-impact parameters to moderate bit-widths, which often result in negligible performance degradation in quantized LLMs, while the remaining parameters can be quantized to extremely low bit-widths. Under the same resource-constrained budget, this allows for preserving more high-impact parameters than methods that keep selecting a few in FP16 format. Additionally, the proposed framework allows us to leverage an advanced quantization method that often requires extensive learnable parameters solely for high-impact parameters, while applying a computationally efficient method to the rest. Our approach achieves an effective balance between computational efficiency and model accuracy while maintaining high performance compared to state-of-the-art methods.

</details>


### [48] [Adaptive Layer-Wise Transformations for Post-Training Quantization of Large Language Models](https://arxiv.org/abs/2511.17809)
*Cuong Pham,Hoang Anh Dung,Cuong C. Nguyen,Trung Le,Gustavo Carneiro,Jianfei Cai,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 本文提出了一种自适应变换选择框架，通过逐层确定最优变换来解决LLM量化中的系统异常值问题，相比现有同质变换方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法采用同质变换设置，忽略了LLM中不同层的异质分布特性，导致在低比特设置下性能显著下降。

Method: 提出自适应变换选择框架，将变换选择制定为可微分优化问题，并通过权重分布峰度与变换类型的关联，使用基于异常值的层选择方法减少计算开销。

Result: 在LLaMA系列模型上的实验表明，该方法在W3A3K2V2量化设置下，相比现有最佳方法FlatQuant，困惑度提升达4.58点，六任务零样本准确率提升2.11%。

Conclusion: 异质变换选择对优化LLM量化至关重要，自适应方法能有效处理不同层的分布特性，显著提升量化性能。

Abstract: Large language models require significant computational resources for deployment, making quantization essential for practical applications. However, the main obstacle to effective quantization lies in systematic outliers in activations and weights, which cause substantial LLM performance degradation, especially at low-bit settings. While existing transformation-based methods like affine and rotation transformations successfully mitigate outliers, they apply the homogeneous transformation setting, i.e., using the same transformation types across all layers, ignoring the heterogeneous distribution characteristics within LLMs. In this paper, we propose an adaptive transformation selection framework that systematically determines optimal transformations on a per-layer basis. To this end, we first formulate transformation selection as a differentiable optimization problem to achieve the accurate transformation type for each layer. However, searching for optimal layer-wise transformations for every model is computationally expensive. To this end, we establish the connection between weight distribution kurtosis and accurate transformation type. Specifically, we propose an outlier-guided layer selection method using robust $z$-score normalization that achieves comparable performance to differentiable search with significantly reduced overhead. Comprehensive experiments on LLaMA family models demonstrate that our adaptive approach consistently outperforms the widely-used fixed transformation settings. For example, our method achieves an improvement of up to 4.58 perplexity points and a 2.11% gain in average six-task zero-shot accuracy under aggressive W3A3K2V2 quantization settings for the LLaMA-3-8B model compared to the current best existing method, FlatQuant, demonstrating the necessity of heterogeneous transformation selection for optimal LLM quantization.

</details>


### [49] [APRIL: Annotations for Policy evaluation with Reliable Inference from LLMs](https://arxiv.org/abs/2511.17818)
*Aishwarya Mandyam,Kalyani Limaye,Barbara E. Engelhardt,Emily Alsentzer*

Main category: cs.LG

TL;DR: 本文提出使用大型语言模型(LLMs)生成反事实标注来改进医疗领域的离策略评估(OPE)，以解决数据集覆盖不足的问题。


<details>
  <summary>Details</summary>
Motivation: 标准OPE方法受限于行为数据集的大小和覆盖范围，而传统的人工专家标注反事实注释成本高昂，限制了可扩展性。医疗等高风险领域需要更安全的策略部署前评估。

Method: 利用领域知识指导LLMs预测在替代治疗下关键临床特征的演变，然后通过已知奖励函数将这些预测特征转化为反事实标注，并将其整合到OPE估计器中。

Result: 在MIMIC-IV数据集的两个患者子集上评估，发现最先进的LLMs在预测临床特征方面表现相当。在大多数情况下，基于LLM的反事实标注显著改善了OPE估计，但存在收益递减点。

Conclusion: 基于LLM的反事实标注为医疗数据集的覆盖限制提供了可扩展的解决方案，能够在临床环境中更安全地部署决策策略。

Abstract: Off-policy evaluation (OPE) estimates the value of a contextual bandit policy prior to deployment. As such, OPE plays a critical role in ensuring safety in high-stakes domains such as healthcare. However, standard OPE approaches are limited by the size and coverage of the behavior dataset. While previous work has explored using expert-labeled counterfactual annotations to enhance dataset coverage, obtaining such annotations is expensive, limiting the scalability of prior approaches. We propose leveraging large language models (LLMs) to generate counterfactual annotations for OPE in medical domains. Our method uses domain knowledge to guide LLMs in predicting how key clinical features evolve under alternate treatments. These predicted features can then be transformed using known reward functions to create counterfactual annotations. We first evaluate the ability of several LLMs to predict clinical features across two patient subsets in MIMIC-IV, finding that state-of-the-art LLMs achieve comparable performance. Building on this capacity to predict clinical features, we generate LLM-based counterfactual annotations and incorporate them into an OPE estimator. Our empirical results analyze the benefits of counterfactual annotations under varying degrees of shift between the behavior and target policies. We find that in most cases, the LLM-based counterfactual annotations significantly improve OPE estimates up to a point. We provide an entropy-based metric to identify when additional annotations cease to be useful. Our results demonstrate that LLM-based counterfactual annotations offer a scalable approach for addressing coverage limitations in healthcare datasets, enabling safer deployment of decision-making policies in clinical settings.

</details>


### [50] [High-Accuracy List-Decodable Mean Estimation](https://arxiv.org/abs/2511.17822)
*Ziyun Chen,Spencer Compton,Daniel Kane,Jerry Li*

Main category: cs.LG

TL;DR: 本文研究了列表可解码学习中的高精度问题，提出了在列表大小和精度之间进行权衡的可能性，并在高斯均值估计的经典设置中实现了非平凡的高精度保证。


<details>
  <summary>Details</summary>
Motivation: 现有列表可解码学习算法虽然能实现最优列表大小，但误差随1/α衰减较慢。本文旨在探索是否可以通过增加列表大小来换取更高的精度，即实现高精度列表可解码学习。

Method: 通过全新的可识别性证明和无需平方和层次结构的新算法方法，设计了一个输出候选均值列表的算法，其中一个元素与真实均值的ℓ₂距离不超过ε。

Result: 证明了存在大小为L = exp(O(log²(1/α)/ε²))的候选均值列表，其中至少一个元素与真实均值的距离不超过ε。算法的时间和样本复杂度为n = d^O(log L) + exp exp(Õ(log L))。

Conclusion: 在高斯均值估计的列表可解码学习中，确实可以在列表大小和精度之间进行权衡，实现了非平凡的高精度保证，这为列表可解码学习开辟了新的研究方向。

Abstract: In list-decodable learning, we are given a set of data points such that an $α$-fraction of these points come from a nice distribution $D$, for some small $α\ll 1$, and the goal is to output a short list of candidate solutions, such that at least one element of this list recovers some non-trivial information about $D$. By now, there is a large body of work on this topic; however, while many algorithms can achieve optimal list size in terms of $α$, all known algorithms must incur error which decays, in some cases quite poorly, with $1 / α$. In this paper, we ask if this is inherent: is it possible to trade off list size with accuracy in list-decodable learning? More formally, given $ε> 0$, can we can output a slightly larger list in terms of $α$ and $ε$, but so that one element of this list has error at most $ε$ with the ground truth? We call this problem high-accuracy list-decodable learning. Our main result is that non-trivial high-accuracy guarantees, both information-theoretically and algorithmically, are possible for the canonical setting of list-decodable mean estimation of identity-covariance Gaussians. Specifically, we demonstrate that there exists a list of candidate means of size at most $L = \exp \left( O\left( \tfrac{\log^2 1 / α}{ε^2} \right)\right)$ so that one of the elements of this list has $\ell_2$ distance at most $ε$ to the true mean. We also design an algorithm that outputs such a list with runtime and sample complexity $n = d^{O(\log L)} + \exp \exp (\widetilde{O}(\log L))$. We do so by demonstrating a completely novel proof of identifiability, as well as a new algorithmic way of leveraging this proof without the sum-of-squares hierarchy, which may be of independent technical interest.

</details>


### [51] [A novel k-means clustering approach using two distance measures for Gaussian data](https://arxiv.org/abs/2511.17823)
*Naitik Gada*

Main category: cs.LG

TL;DR: 本文提出了一种改进的k-means聚类算法，使用簇内距离(WCD)和簇间距离(ICD)作为距离度量，通过Calinski-Harabasz准则确定最佳k值，以提高聚类分析的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统k-means聚类算法存在局限性，作者希望通过结合WCD和ICD两种距离度量来增强数据向各自簇的收敛性，使聚类结果更加稳健。

Method: 开发了一种新的k-means聚类算法，同时考虑簇内距离和簇间距离作为距离度量，使用Calinski-Harabasz准则自动确定最佳聚类数量k。

Result: 在合成数据和UCI基准数据集上的实验表明，使用WCD和ICD度量能够更准确地收敛到各自的簇，并且在处理异常值方面优于传统k-means方法。

Conclusion: 结合WCD和ICD的k-means聚类算法能够提供更稳健的聚类结果，特别是在处理异常值和提高聚类准确性方面表现优异。

Abstract: Clustering algorithms have long been the topic of research, representing the more popular side of unsupervised learning. Since clustering analysis is one of the best ways to find some clarity and structure within raw data, this paper explores a novel approach to \textit{k}-means clustering. Here we present a \textit{k}-means clustering algorithm that takes both the within cluster distance (WCD) and the inter cluster distance (ICD) as the distance metric to cluster the data into \emph{k} clusters pre-determined by the Calinski-Harabasz criterion in order to provide a more robust output for the clustering analysis. The idea with this approach is that by including both the measurement metrics, the convergence of the data into their clusters becomes solidified and more robust. We run the algorithm with some synthetically produced data and also some benchmark data sets obtained from the UCI repository. The results show that the convergence of the data into their respective clusters is more accurate by using both WCD and ICD measurement metrics. The algorithm is also better at clustering the outliers into their true clusters as opposed to the traditional \textit{k} means method. We also address some interesting possible research topics that reveal themselves as we answer the questions we initially set out to address.

</details>


### [52] [Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch](https://arxiv.org/abs/2511.17826)
*Ziyang Zhang,Xinheng Ding,Jiayi Yuan,Rixin Liu,Huizi Mao,Jiarong Xing,Zirui Liu*

Main category: cs.LG

TL;DR: 本文提出了Tree-Based Invariant Kernels (TBIK)来解决大语言模型推理中的张量并行规模导致的非确定性问题，确保在不同TP配置下获得比特级相同的推理结果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务框架在张量并行规模变化时会产生非确定性行为，这在LLM-as-a-judge评估、多智能体系统和强化学习等应用中会造成严重问题，特别是RL训练中训练引擎和推理引擎的并行策略不匹配可能导致性能下降甚至崩溃。

Method: 通过分析TP诱导不一致性的根本原因，提出了基于统一层次二叉树结构的TP不变矩阵乘法和规约原语(TBIK)，对齐GPU内和GPU间的规约顺序。

Result: 实验证实了在不同TP规模下实现了零概率发散和比特级可复现性，在vLLM和FSDP之间实现了比特级相同的RL训练结果。

Conclusion: TBIK有效解决了LLM推理中的TP规模相关非确定性问题，为确定性推理提供了可靠保障。

Abstract: Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.

</details>


### [53] [Unified Class and Domain Incremental Learning with Mixture of Experts for Indoor Localization](https://arxiv.org/abs/2511.17829)
*Akhil Singampalli,Sudeep Pasricha*

Main category: cs.LG

TL;DR: MOELO是一个新颖的持续学习框架，首次联合解决室内定位中的领域增量学习和类别增量学习问题，通过混合专家架构实现轻量级、鲁棒且自适应的定位解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统室内定位机器学习模型面临硬件/软件变化导致的领域偏移和环境演变带来的类别偏移问题，静态模型在长期使用中效果下降。

Method: 采用混合专家架构，按区域增量训练专家，通过等角紧框架门控机制实现高效路由和低延迟推理，保持紧凑模型尺寸。

Result: 实验评估显示，MOELO在平均定位误差上提升25.6倍，最差情况定位误差提升44.5倍，遗忘率降低21.5倍，优于现有最先进框架。

Conclusion: MOELO为资源受限移动设备提供了可在动态异构现实环境中持续学习的轻量级定位解决方案。

Abstract: Indoor localization using machine learning has gained traction due to the growing demand for location-based services. However, its long-term reliability is hindered by hardware/software variations across mobile devices, which shift the model's input distribution to create domain shifts. Further, evolving indoor environments can introduce new locations over time, expanding the output space to create class shifts, making static machine learning models ineffective over time. To address these challenges, we propose a novel unified continual learning framework for indoor localization called MOELO that, for the first time, jointly addresses domain-incremental and class-incremental learning scenarios. MOELO enables a lightweight, robust, and adaptive localization solution that can be deployed on resource-limited mobile devices and is capable of continual learning in dynamic, heterogeneous real-world settings. This is made possible by a mixture-of-experts architecture, where experts are incrementally trained per region and selected through an equiangular tight frame based gating mechanism ensuring efficient routing, and low-latency inference, all within a compact model footprint. Experimental evaluations show that MOELO achieves improvements of up to 25.6x in mean localization error, 44.5x in worst-case localization error, and 21.5x lesser forgetting compared to state-of-the-art frameworks across diverse buildings, mobile devices, and learning scenarios.

</details>


### [54] [Internalizing Tools as Morphisms in Graded Transformers](https://arxiv.org/abs/2511.17840)
*Tony Shaska*

Main category: cs.LG

TL;DR: 本文提出了一种分级的内部符号计算框架，通过类型化的块映射实现符号操作，使用可微路由策略和自监督的效用函数来控制激活，产生稀疏且可解释的行为。


<details>
  <summary>Details</summary>
Motivation: 统一符号计算、几何和自监督学习，将外部工具范式（如Toolformer）作为特例通过函子内化纳入分级的transformer形式体系。

Method: 在隐藏空间中引入分级结构，符号操作实现为类型化块映射，通过可微路由机制和自监督的效用函数控制激活。

Result: 开发了代数几何基础，包括内部模型范畴、伴随对和信息几何解释，在混合符号-语言任务上展示了选择性形态激活。

Conclusion: 该框架在分级transformer形式体系内统一了符号计算、几何和自监督学习，同时将外部工具范式作为特例包含在内。

Abstract: We introduce a graded formulation of internal symbolic computation for transformers. The hidden space is endowed with a grading $V=\bigoplus_{g\in G}V_g$, and symbolic operations are realized as typed block maps (morphisms) $φ_{h\leftarrow g}:V_g\to V_h$ that are activated selectively by a differentiable routing policy. A self-supervised \emph{graded utility functional}, defined as the loss reduction induced by a candidate morphism, governs activation and yields sparse, interpretable behavior. We develop the algebraic and geometric foundations: an internal model category whose objects are homogeneous components and whose morphisms are admissible grade transitions; adjoint pairs encoding typed round trips; and information-geometric interpretations in terms of KL gain, mirror descent with Bregman divergences, and Fisher natural gradients. Methodologically, we specify a utility--aware routing mechanism and objective that remain fully end-to-end differentiable. Analytic case studies and lightweight sanity checks illustrate selective morphic activation on hybrid symbolic-linguistic tasks. The framework unifies symbolic computation, geometry, and self--supervised learning within the \emph{graded transformer} formalism \cite{sh-89,sh-95}, while subsuming prior external-tool paradigms (e.g., Toolformer \cite{toolformer2023}) as a special case via functorial internalization.

</details>


### [55] [Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But Differently](https://arxiv.org/abs/2511.17852)
*Bochen Lyu,Yiyang Jia,Xiaohao Cai,Zhanxing Zhu*

Main category: cs.LG

TL;DR: 本文分析了Transformer通过强化学习(RL)和监督微调(SFT)学习链式思维(CoT)能力的理论机制，特别针对k稀疏布尔函数的学习，揭示了RL和SFT在学习行为上的关键差异。


<details>
  <summary>Details</summary>
Motivation: 虽然RL和SFT都能让Transformer获得CoT能力来解决复杂推理任务，但它们的基本机制和差异在理论上仍不清楚，需要系统性的理论分析。

Method: 使用单层Transformer和中间监督来学习可递归分解为固定2稀疏布尔函数的k稀疏布尔函数，分析RL和SFT的微调学习动态，并验证在k-PARITY、k-AND和k-OR三个基本示例上的适用性。

Result: 证明了两种方法都能学习这些函数，但RL同时学习整个CoT链，而SFT逐步学习CoT链，表现出不同的学习行为。

Conclusion: 研究结果为理解RL和SFT触发Transformer CoT能力的基本机制及其差异提供了理论见解。

Abstract: Transformers can acquire Chain-of-Thought (CoT) capabilities to solve complex reasoning tasks through fine-tuning. Reinforcement learning (RL) and supervised fine-tuning (SFT) are two primary approaches to this end, yet their underlying mechanisms and differences remain theoretically unclear. In this work, we examine these aspects specifically for learning $k$-sparse Boolean functions with a one-layer transformer and intermediate supervision that is akin to CoT. In particular, we consider $k$-sparse Boolean functions that can be recursively decomposed into fixed 2-sparse Boolean functions. We analyze the learning dynamics of fine-tuning the transformer via either RL or SFT with CoT to identify sufficient conditions for it to provably learn these functions. We verify that these conditions hold for three basic examples, including $k$-PARITY, $k$-AND, and $k$-OR, thus demonstrating the learnability of both approaches. Notably, we reveal that RL and SFT exhibit distinct learning behaviors: RL learns the whole CoT chain simultaneously, whereas SFT learns the CoT chain step-by-step. Overall, our findings provide theoretical insights into the underlying mechanisms of RL and SFT as well as how they differ in triggering the CoT capabilities of transformers.

</details>


### [56] [Cost-Sensitive Conformal Training with Provably Controllable Learning Bounds](https://arxiv.org/abs/2511.17861)
*Xuesong Jia,Yuanjie Shi,Ziquan Liu,Yi Xu,Yan Yan*

Main category: cs.LG

TL;DR: 本文提出了一种简单的成本敏感共形训练算法，通过真实标签的排名来加权，避免了传统方法使用指示函数近似机制的问题，显著减少了预测集大小。


<details>
  <summary>Details</summary>
Motivation: 传统共形训练方法使用Sigmoid或高斯误差函数作为指示函数的替代，但这些替代函数没有统一的误差界限，导致学习边界不可控。

Method: 提出了一种成本敏感共形训练算法，通过理论分析证明最小化预测集期望大小受真实标签期望排名的上界约束，开发了基于真实标签排名的权重分配策略。

Result: 实验验证了理论分析的有效性，在预测效率方面优于其他共形训练方法，平均预测集大小减少了21.38%。

Conclusion: 提出的加权目标与共形预测集期望大小之间存在紧密联系，该方法能够有效控制预测集大小并提高预测效率。

Abstract: Conformal prediction (CP) is a general framework to quantify the predictive uncertainty of machine learning models that uses a set prediction to include the true label with a valid probability. To align the uncertainty measured by CP, conformal training methods minimize the size of the prediction sets. A typical way is to use a surrogate indicator function, usually Sigmoid or Gaussian error function. However, these surrogate functions do not have a uniform error bound to the indicator function, leading to uncontrollable learning bounds. In this paper, we propose a simple cost-sensitive conformal training algorithm that does not rely on the indicator approximation mechanism. Specifically, we theoretically show that minimizing the expected size of prediction sets is upper bounded by the expected rank of true labels. To this end, we develop a rank weighting strategy that assigns the weight using the rank of true label on each data sample. Our analysis provably demonstrates the tightness between the proposed weighted objective and the expected size of conformal prediction sets. Extensive experiments verify the validity of our theoretical insights, and superior empirical performance over other conformal training in terms of predictive efficiency with 21.38% reduction for average prediction set size.

</details>


### [57] [Equivalence of Context and Parameter Updates in Modern Transformer Blocks](https://arxiv.org/abs/2511.17864)
*Adrian Goldwaser,Michael Munn,Javier Gonzalvo,Benoit Dherin*

Main category: cs.LG

TL;DR: 本文扩展了transformer中上下文影响的理论，证明在现代LLM架构中，上下文效果可以完美映射为MLP权重的rank-1补丁和RMSNorm尺度补丁，并提出了基于输入可控性和输出可控性的通用框架。


<details>
  <summary>Details</summary>
Motivation: 扩展基础理论到现代大型语言模型的多样化架构，统一理解transformer如何将提示转换为有效权重。

Method: 首先为Gemma风格transformer块提供精确解析解，然后推广到多层模型，提出基于输入可控性和输出可控性的通用框架和算法。

Result: 证明完美隐式权重补丁在任何MLP块中都是可能的，前提是内部函数输入可控且外部函数输出可控，该框架适用于包括门控、预/后规范、专家混合和顺序/并行transformer块等多种架构。

Conclusion: 提供了一个更简单强大的视角来理解transformer模型如何将提示转换为有效权重，该框架可广泛应用于现代LLM架构。

Abstract: Recent research has established that the impact of context in a vanilla transformer can be represented implicitly by forming a token-dependent, rank-1 patch to its MLP weights. This work extends that foundational theory to the diverse architectures of modern Large Language Models. We first demonstrate a precise, analytical solution for a Gemma-style transformer block, proving that the entire effect of a context can be perfectly mapped to rank-1 patches on its MLP weight matrices and a patch to the RMSNorm scale. We then generalize this result, providing a constructive proof and algorithm for multi-layer models. To unify these findings, we introduce a general framework centered on two core properties: input controllability and output controllability. We prove that a perfect implicit weight patch is possible for any MLP block where the inner function is input-controllable and the outer function is output-controllable. This provides a simpler and more powerful lens for understanding how transformer models transmute prompts into effective weights. This setup generalizes to a wide range of modern LLM architectures including gating, pre-/post-norm, mixture of experts and sequential/parallel transformer blocks.

</details>


### [58] [Mitigating Catastrophic Forgetting in Streaming Generative and Predictive Learning via Stateful Replay](https://arxiv.org/abs/2511.17936)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 本文研究了在内存约束下流数据学习系统的模型更新策略，比较了顺序微调和重放方法在生成式和预测式任务中的表现，发现重放方法在多任务流中能显著减少遗忘。


<details>
  <summary>Details</summary>
Motivation: 部署的学习系统需要在内存限制下对流数据更新模型，顺序微调方法容易发生灾难性遗忘，而有限缓冲区的重放方法在不同目标下的行为尚未充分理解。

Method: 将顺序微调和重放视为理想联合目标的随机梯度方法，使用梯度对齐分析来研究混合当前和历史样本何时能减少遗忘，并在六个流场景中评估单一重放机制。

Result: 在异构多任务流中，重放将平均遗忘减少2-3倍；在良性时间流中，两种方法表现相似。

Conclusion: 状态重放是流环境中持续学习的强大简单基线方法。

Abstract: Many deployed learning systems must update models on streaming data under memory constraints. The default strategy, sequential fine-tuning on each new phase, is architecture-agnostic but often suffers catastrophic forgetting when later phases correspond to different sub-populations or tasks. Replay with a finite buffer is a simple alternative, yet its behaviour across generative and predictive objectives is not well understood. We present a unified study of stateful replay for streaming autoencoding, time series forecasting, and classification. We view both sequential fine-tuning and replay as stochastic gradient methods for an ideal joint objective, and use a gradient alignment analysis to show when mixing current and historical samples should reduce forgetting. We then evaluate a single replay mechanism on six streaming scenarios built from Rotated MNIST, ElectricityLoadDiagrams 2011-2014, and Airlines delay data, using matched training budgets and three seeds. On heterogeneous multi task streams, replay reduces average forgetting by a factor of two to three, while on benign time based streams both methods perform similarly. These results position stateful replay as a strong and simple baseline for continual learning in streaming environments.

</details>


### [59] [On Transportability for Structural Causal Bandits](https://arxiv.org/abs/2511.17953)
*Min Woo Park,Sanghack Lee*

Main category: cs.LG

TL;DR: 本文研究了具有可迁移性的结构因果赌博机问题，通过融合来自源环境的先验知识来增强部署环境中的学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有的结构因果赌博机框架虽然能利用因果结构知识优化动作空间，但缺乏从不同条件下收集的数据集（观测或实验）和异构环境中迁移信息的指导方法。

Method: 提出结构因果赌博机与可迁移性结合的方法，利用跨环境的不变性，将源环境的先验知识融合到部署环境中。

Result: 开发出的赌博机算法实现了次线性遗憾界，明确依赖于先验数据的信息量，可能优于仅依赖在线学习的标准赌博机方法。

Conclusion: 通过利用跨环境的不变性，可以持续改进学习效果，证明在结构因果赌博机中融合先验知识是可行且有效的。

Abstract: Intelligent agents equipped with causal knowledge can optimize their action spaces to avoid unnecessary exploration. The structural causal bandit framework provides a graphical characterization for identifying actions that are unable to maximize rewards by leveraging prior knowledge of the underlying causal structure. While such knowledge enables an agent to estimate the expected rewards of certain actions based on others in online interactions, there has been little guidance on how to transfer information inferred from arbitrary combinations of datasets collected under different conditions -- observational or experimental -- and from heterogeneous environments. In this paper, we investigate the structural causal bandit with transportability, where priors from the source environments are fused to enhance learning in the deployment setting. We demonstrate that it is possible to exploit invariances across environments to consistently improve learning. The resulting bandit algorithm achieves a sub-linear regret bound with an explicit dependence on informativeness of prior data, and it may outperform standard bandit approaches that rely solely on online learning.

</details>


### [60] [An Adaptive Resonance Theory-based Topological Clustering Algorithm with a Self-Adjusting Vigilance Parameter](https://arxiv.org/abs/2511.17983)
*Naoki Masuyama,Yuichiro Toda,Yusuke Nojima,Hisao Ishibuchi*

Main category: cs.LG

TL;DR: 提出基于自适应共振理论(ART)的拓扑聚类算法，通过多样性驱动的适应机制自动调整重计算间隔和警戒阈值，实现无超参数学习，在动态环境中保持聚类稳定性和连续性。


<details>
  <summary>Details</summary>
Motivation: 解决静态和非静态设置中的聚类问题，需要能够适应分布变化同时保留先前学习聚类结构的模型。

Method: 基于自适应共振理论(ART)的拓扑聚类算法，采用多样性驱动的适应机制自动调整重计算间隔和警戒阈值。

Result: 在24个真实世界数据集上的实验表明，该算法在聚类性能和持续学习能力方面优于最先进方法。

Conclusion: 所提出的参数适应机制在减轻灾难性遗忘和保持演化数据流中一致聚类方面具有有效性。

Abstract: Clustering in stationary and nonstationary settings, where data distributions remain static or evolve over time, requires models that can adapt to distributional shifts while preserving previously learned cluster structures. This paper proposes an Adaptive Resonance Theory (ART)-based topological clustering algorithm that autonomously adjusts its recalculation interval and vigilance threshold through a diversity-driven adaptation mechanism. This mechanism enables hyperparameter-free learning that maintains cluster stability and continuity in dynamic environments. Experiments on 24 real-world datasets demonstrate that the proposed algorithm outperforms state-of-the-art methods in both clustering performance and continual learning capability. These results highlight the effectiveness of the proposed parameter adaptation in mitigating catastrophic forgetting and maintaining consistent clustering in evolving data streams. Source code is available at https://github.com/Masuyama-lab/IDAT

</details>


### [61] [Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic via Difference Vectors](https://arxiv.org/abs/2511.17987)
*Jinping Wang,Zhiqiang Gao,Dinggen Zhang,Zhiwu Xie*

Main category: cs.LG

TL;DR: 本文提出了一种基于差异向量的任务算术优化方法DV-BASI，通过利用优化过程中的历史移动作为定向扰动，克服现有方法面临的优化停滞问题，实现了多任务模型合并性能的提升。


<details>
  <summary>Details</summary>
Motivation: 当前预训练模型编辑方法面临高计算成本和有限可扩展性的挑战，任务算术方法虽然通过简单的算术运算来修改模型行为，但其潜力因优化停滞问题而未能充分发挥。

Method: 引入差异向量概念，作为任务向量的广义形式，基于优化过程中的历史移动。提出DV-BASI算法，利用差异向量的逃逸性和方向优势，实现连续优化过程，无需额外模块。

Result: DV-BASI在多任务模型合并中的平均性能甚至超过单独微调的模型。该方法允许使用少量可学习参数进行表达性搜索，形成可扩展框架，在监督和无监督评估协议上达到最先进性能。

Conclusion: 差异向量为任务算术方法提供了有效的优化机制，DV-BASI算法不仅解决了优化停滞问题，还扩展了差异向量在单任务模型微调中的应用，实现了高性能和可扩展性。

Abstract: Current methods for editing pre-trained models face significant challenges, primarily high computational costs and limited scalability. Task arithmetic has recently emerged as a promising solution, using simple arithmetic operations-addition and negation-based on task vectors which are the differences between fine-tuned and pre-trained model weights, to efficiently modify model behavior. However, the full potential of task arithmetic remains underexplored, primarily due to limited mechanisms for overcoming optimization stagnation. To address this challenge, we introduce the notion of difference vector, a generalized form of task vectors derived from the historical movements during optimization. Using difference vectors as directed perturbations, we propose the Difference Vector-based Anisotropic Scaling Iterative algorithm (DV-BASI) to enable a continuous optimization process for task arithmetic methods without relying on any additional modules or components. Notably, by leveraging escapability and directional advantages of difference vectors, the average performance on different tasks of the multi-task model merged by DV-BASI may even outperform models individually fine-tuned. Based on this observation, we extend the application of difference vectors to a feasible fine-tuning method for single-task models. On the practical side, DV-BASI allows expressive searching directions with few learnable parameters and forms a scalable framework. We also integrate DV-BASI with task arithmetic methods and advanced optimization techniques to achieve state-of-the-art performance on both supervised and unsupervised evaluation protocols.

</details>


### [62] [Privacy Auditing of Multi-domain Graph Pre-trained Model under Membership Inference Attacks](https://arxiv.org/abs/2511.17989)
*Jiayi Luo,Qingyun Sun,Yuecen Wei,Haonan Yuan,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: MGP-MIA是针对多领域图预训练模型的成员推理攻击框架，通过机器遗忘放大成员信号、增量学习构建影子模型、基于相似度的推理机制来识别训练数据成员。


<details>
  <summary>Details</summary>
Motivation: 多领域图预训练模型虽然提升了泛化能力，但其在成员推理攻击下的隐私风险尚未被充分探索，面临泛化能力增强、影子数据集不可靠、成员信号弱化等挑战。

Method: 提出MGP-MIA框架：1）通过机器遗忘放大目标模型的过拟合特征；2）使用增量学习构建可靠的影子模型；3）基于正负样本相似度进行成员推理。

Result: 大量实验证明MGP-MIA的有效性，揭示了多领域图预训练存在的隐私风险。

Conclusion: 多领域图预训练模型存在显著的隐私风险，MGP-MIA框架能够有效识别训练数据成员，为图基础模型的隐私保护提供了重要启示。

Abstract: Multi-domain graph pre-training has emerged as a pivotal technique in developing graph foundation models. While it greatly improves the generalization of graph neural networks, its privacy risks under membership inference attacks (MIAs), which aim to identify whether a specific instance was used in training (member), remain largely unexplored. However, effectively conducting MIAs against multi-domain graph pre-trained models is a significant challenge due to: (i) Enhanced Generalization Capability: Multi-domain pre-training reduces the overfitting characteristics commonly exploited by MIAs. (ii) Unrepresentative Shadow Datasets: Diverse training graphs hinder the obtaining of reliable shadow graphs. (iii) Weakened Membership Signals: Embedding-based outputs offer less informative cues than logits for MIAs. To tackle these challenges, we propose MGP-MIA, a novel framework for Membership Inference Attacks against Multi-domain Graph Pre-trained models. Specifically, we first propose a membership signal amplification mechanism that amplifies the overfitting characteristics of target models via machine unlearning. We then design an incremental shadow model construction mechanism that builds a reliable shadow model with limited shadow graphs via incremental learning. Finally, we introduce a similarity-based inference mechanism that identifies members based on their similarity to positive and negative samples. Extensive experiments demonstrate the effectiveness of our proposed MGP-MIA and reveal the privacy risks of multi-domain graph pre-training.

</details>


### [63] [Learning Rate Scheduling with Matrix Factorization for Private Training](https://arxiv.org/abs/2511.17994)
*Nikita P. Kalinin,Joel Daniel Andersson*

Main category: cs.LG

TL;DR: 本文研究了差分隐私下的随机梯度下降训练，重点关注学习率调度和相关性噪声的影响。通过理论分析提出了适用于多种学习率调度的上下界，并设计了学习率感知的矩阵分解方法，在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私训练方法主要关注恒定学习率场景，而实践中广泛使用学习率调度来加速训练和提高收敛性。本文旨在填补这一理论空白，研究学习率调度与相关性噪声的交互作用。

Method: 提出了学习率感知的矩阵分解方法，推导了单轮和多轮训练场景下各类学习率调度的理论上下界，设计了内存高效的实用构造方案。

Result: 在CIFAR-10和IMDB数据集上的实验表明，调度感知的分解方法在MaxSE和MeanSE误差指标上优于前缀和分解，提高了私有训练的准确性。

Conclusion: 学习率调度感知的矩阵分解方法能够有效提升差分隐私训练的性能，理论分析为实际部署提供了内存高效的解决方案。

Abstract: We study differentially private model training with stochastic gradient descent under learning rate scheduling and correlated noise. Although correlated noise, in particular via matrix factorizations, has been shown to improve accuracy, prior theoretical work focused primarily on the prefix-sum workload. That workload assumes a constant learning rate, whereas in practice learning rate schedules are widely used to accelerate training and improve convergence. We close this gap by deriving general upper and lower bounds for a broad class of learning rate schedules in both single- and multi-epoch settings. Building on these results, we propose a learning-rate-aware factorization that achieves improvements over prefix-sum factorizations under both MaxSE and MeanSE error metrics. Our theoretical analysis yields memory-efficient constructions suitable for practical deployment, and experiments on CIFAR-10 and IMDB datasets confirm that schedule-aware factorizations improve accuracy in private training.

</details>


### [64] [The Alignment Paradox of Medical Large Language Models in Infertility Care: Decoupling Algorithmic Improvement from Clinical Decision-making Quality](https://arxiv.org/abs/2511.18084)
*Dou Liu,Ying Long,Sophia Zuoqiu,Kaipeng Xie,Runze Yang,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.LG

TL;DR: 本文系统评估了四种大语言模型对齐策略在临床决策支持中的应用，发现GRPO在算法精度上最优，但临床医生更偏好SFT模型，揭示了算法改进与临床信任之间的对齐悖论。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在临床决策支持中的应用日益增多，但如何使其与真实世界医学的多维推理路径对齐仍是一个重大挑战。

Method: 使用超过8000份不孕症治疗记录，系统评估四种对齐策略：监督微调(SFT)、直接偏好优化(DPO)、群体相对策略优化(GRPO)和上下文学习(ICL)，通过结合自动基准测试和盲法医生参与评估的双层框架。

Result: GRPO在多个决策层实现最高算法精度，但临床医生一致偏好SFT模型，认为其推理过程更清晰(p=0.035)且治疗可行性更高(p=0.019)。在盲法成对比较中，SFT获得最高胜率(51.2%)，优于GRPO(26.2%)和医生原始决策(22.7%)。

Conclusion: 研究结果揭示了对齐悖论：算法改进不一定转化为更高的临床信任，可能与以人为中心的偏好相背离。需要优先考虑临床可解释性和实践可行性的对齐策略，而非仅优化决策级精度。

Abstract: Large language models (LLMs) are increasingly adopted in clinical decision support, yet aligning them with the multifaceted reasoning pathways of real-world medicine remains a major challenge. Using more than 8,000 infertility treatment records, we systematically evaluate four alignment strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), Group Relative Policy Optimization (GRPO), and In-Context Learning (ICL) through a dual-layer framework combining automatic benchmarks with blinded doctor-in-the-loop assessments. GRPO achieves the highest algorithmic accuracy across multiple decision layers, confirming the value of reinforcement-based optimization for structured prediction tasks. However, clinicians consistently prefer the SFT model, citing clearer reasoning processes (p = 0.035) and higher therapeutic feasibility (p = 0.019). In blinded pairwise comparisons, SFT attains the highest winning rate (51.2%), outperforming both GRPO (26.2%) and even physicians' original decisions (22.7%). These results reveal an alignment paradox: algorithmic improvements do not necessarily translate into higher clinical trust, and may diverge from human-centered preferences. Our findings highlight the need for alignment strategies that prioritize clinically interpretable and practically feasible reasoning, rather than solely optimizing decision-level accuracy.

</details>


### [65] [Understanding Private Learning From Feature Perspective](https://arxiv.org/abs/2511.18006)
*Meng Ding,Mingxi Lei,Shaopeng Fu,Shaowei Wang,Di Wang,Jinhui Xu*

Main category: cs.LG

TL;DR: 本文首次从特征学习角度建立了差分隐私SGD的理论分析框架，揭示了私有训练中特征信号学习和数据噪声记忆化的机制，发现私有学习需要更高的信噪比，且当非私有学习出现噪声记忆化时，私有学习也会出现，导致泛化性能差。


<details>
  <summary>Details</summary>
Motivation: 尽管利用预训练模型特征增强DP-SGD训练取得了显著经验进展，但私有学习中特征动态的理论理解仍然不足，现有DP分析忽略了标签相关特征信号和标签无关噪声的关键区别。

Method: 基于多块数据结构，采用带多项式ReLU激活的两层CNN，通过噪声梯度下降理论分析私有训练中的特征信号学习和数据噪声记忆化。

Result: 研究发现：(1)有效私有信号学习需要比非私有训练更高的信噪比；(2)当非私有学习出现数据噪声记忆化时，私有学习也会出现，导致训练损失小但泛化性能差。

Conclusion: 研究强调了私有学习的挑战性，证明了特征增强提高信噪比的益处，在合成和真实数据集上的实验验证了理论发现。

Abstract: Differentially private Stochastic Gradient Descent (DP-SGD) has become integral to privacy-preserving machine learning, ensuring robust privacy guarantees in sensitive domains. Despite notable empirical advances leveraging features from non-private, pre-trained models to enhance DP-SGD training, a theoretical understanding of feature dynamics in private learning remains underexplored. This paper presents the first theoretical framework to analyze private training through a feature learning perspective. Building on the multi-patch data structure from prior work, our analysis distinguishes between label-dependent feature signals and label-independent noise, a critical aspect overlooked by existing analyses in the DP community. Employing a two-layer CNN with polynomial ReLU activation, we theoretically characterize both feature signal learning and data noise memorization in private training via noisy gradient descent. Our findings reveal that (1) Effective private signal learning requires a higher signal-to-noise ratio (SNR) compared to non-private training, and (2) When data noise memorization occurs in non-private learning, it will also occur in private learning, leading to poor generalization despite small training loss. Our findings highlight the challenges of private learning and prove the benefit of feature enhancement to improve SNR. Experiments on synthetic and real-world datasets also validate our theoretical findings.

</details>


### [66] [Curvature-Aware Safety Restoration In LLMs Fine-Tuning](https://arxiv.org/abs/2511.18039)
*Thong Bach,Thanh Nguyen-Tang,Dung Nguyen,Thao Minh Le,Truyen Tran*

Main category: cs.LG

TL;DR: 本文发现微调后的LLM在有害内容上的损失景观几何结构保持不变，提出了一种基于曲率感知的对齐恢复方法，通过影响函数和二阶优化选择性地增加有害输入的损失，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型用于下游任务时往往会损害安全对齐，即使使用LoRA等参数高效方法。研究发现微调模型在有害内容上的损失景观几何结构保持不变，表明安全行为并未被擦除而是转移到参数空间中影响力较小的区域。

Method: 提出曲率感知对齐恢复方法，利用影响函数和二阶优化，在基础模型和微调模型共享的几何结构基础上，选择性地增加有害输入的损失，同时保持任务相关性能。

Result: 在多个模型系列和对抗设置下的广泛评估表明，该方法能有效减少有害响应，同时保持甚至提高实用性和少样本学习性能。

Conclusion: 通过利用微调模型保持的几何结构，该方法能够精确地进行低影响更新，避免完全回退，在保持任务性能的同时有效恢复安全对齐。

Abstract: Fine-tuning Large Language Models (LLMs) for downstream tasks often compromises safety alignment, even when using parameter-efficient methods like LoRA. In this work, we uncover a notable property: fine-tuned models preserve the geometric structure of their loss landscapes concerning harmful content, regardless of the fine-tuning method employed. This suggests that safety behaviors are not erased but shifted to less influential regions of the parameter space. Building on this insight, we propose a curvature-aware alignment restoration method that leverages influence functions and second-order optimization to selectively increase loss on harmful inputs while preserving task performance. By navigating the shared geometry between base and fine-tuned models, our method discourages unsafe outputs while preserving task-relevant performance, avoiding full reversion and enabling precise, low-impact updates. Extensive evaluations across multiple model families and adversarial settings show that our approach efficiently reduces harmful responses while maintaining or even improving utility and few-shot learning performance.

</details>


### [67] [Hierarchical Linkage Clustering Beyond Binary Trees and Ultrametrics](https://arxiv.org/abs/2511.18056)
*Maximilien Dreveton,Matthias Grossglauser,Daichi Kuroda,Patrick Thiran*

Main category: cs.LG

TL;DR: 本文提出了有效层次结构的概念，解决了传统层次聚类的三个主要限制：总是返回层次结构、仅限于二叉树、对链接函数选择敏感。通过定义有效层次结构的部分顺序，证明了最精细有效层次结构的存在，并提出两步算法来恢复它。


<details>
  <summary>Details</summary>
Motivation: 传统层次聚类方法存在三个主要问题：(i)即使数据中不存在层次结构也会返回层次结构，(ii)仅限于二叉树结构，(iii)对链接函数选择高度敏感。这些限制影响了层次聚类的准确性和实用性。

Method: 提出了有效层次结构的概念，定义了有效层次结构的部分顺序。开发了一个简单的两步算法：首先通过链接方法构建二叉树，然后进行剪枝以强制执行有效性。建立了链接函数恢复最精细有效层次结构的充要条件。

Result: 证明了最精细有效层次结构的存在，该结构不受限于二叉树，当不存在层次关系时会坍缩为星形树。经典链接规则（如单链接、完全链接、平均链接）满足恢复条件，而Ward链接不满足。所有满足条件的链接函数在剪枝后都会产生相同的层次结构。

Conclusion: 通过引入有效层次结构的概念和相应的算法，成功解决了传统层次聚类的三个主要限制，提供了一种更准确、更稳健的层次聚类方法，能够更好地反映数据的真实层次结构。

Abstract: Hierarchical clustering seeks to uncover nested structures in data by constructing a tree of clusters, where deeper levels reveal finer-grained relationships. Traditional methods, including linkage approaches, face three major limitations: (i) they always return a hierarchy, even if none exists, (ii) they are restricted to binary trees, even if the true hierarchy is non-binary, and (iii) they are highly sensitive to the choice of linkage function. In this paper, we address these issues by introducing the notion of a valid hierarchy and defining a partial order over the set of valid hierarchies. We prove the existence of a finest valid hierarchy, that is, the hierarchy that encodes the maximum information consistent with the similarity structure of the data set. In particular, the finest valid hierarchy is not constrained to binary structures and, when no hierarchical relationships exist, collapses to a star tree. We propose a simple two-step algorithm that first constructs a binary tree via a linkage method and then prunes it to enforce validity. We establish necessary and sufficient conditions on the linkage function under which this procedure exactly recovers the finest valid hierarchy, and we show that all linkage functions satisfying these conditions yield the same hierarchy after pruning. Notably, classical linkage rules such as single, complete, and average satisfy these conditions, whereas Ward's linkage fails to do so.

</details>


### [68] [pFedBBN: A Personalized Federated Test-Time Adaptation with Balanced Batch Normalization for Class-Imbalanced Data](https://arxiv.org/abs/2511.18066)
*Md Akil Raihan Iftee,Syed Md. Ahnaf Hasan,Mir Sazzat Hossain,Rakibul Hasan Rajib,Amin Ahsan Ali,AKM Mahbubur Rahman,Sajib Mistry,Monowar Bhuyan*

Main category: cs.LG

TL;DR: pFedBBN是一个个性化的联邦测试时适应框架，通过平衡批量归一化(BBN)解决联邦学习中类别不平衡问题，支持完全无监督的本地适应和基于BBN相似度的客户端协作。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的类别不平衡是一个基本挑战，特别是在面临领域偏移和偏斜类别分布时。现有方法通常依赖标记数据或客户端协调，无法在联邦类别不平衡约束下处理动态领域或推理时的分布偏移。

Method: 采用平衡批量归一化(BBN)进行本地客户端适应，通过平等对待所有类别来减轻预测偏差；引入基于BBN相似度的客户端协作机制；提出类别感知的模型聚合策略，支持个性化推理且不损害隐私。

Result: 在多样化基线的广泛实验中，pFedBBN在鲁棒性和少数类别性能方面持续优于最先进的联邦学习和测试时适应方法。

Conclusion: pFedBBN通过平衡特征归一化和领域感知协作，有效解决了分布偏移和类别不平衡问题，无需客户端的任何标记或原始数据。

Abstract: Test-time adaptation (TTA) in federated learning (FL) is crucial for handling unseen data distributions across clients, particularly when faced with domain shifts and skewed class distributions. Class Imbalance (CI) remains a fundamental challenge in FL, where rare but critical classes are often severely underrepresented in individual client datasets. Although prior work has addressed CI during training through reliable aggregation and local class distribution alignment, these methods typically rely on access to labeled data or coordination among clients, and none address class unsupervised adaptation to dynamic domains or distribution shifts at inference time under federated CI constraints. Revealing the failure of state-of-the-art TTA in federated client adaptation in CI scenario, we propose pFedBBN,a personalized federated test-time adaptation framework that employs balanced batch normalization (BBN) during local client adaptation to mitigate prediction bias by treating all classes equally, while also enabling client collaboration guided by BBN similarity, ensuring that clients with similar balanced representations reinforce each other and that adaptation remains aligned with domain-specific characteristics. pFedBBN supports fully unsupervised local adaptation and introduces a class-aware model aggregation strategy that enables personalized inference without compromising privacy. It addresses both distribution shifts and class imbalance through balanced feature normalization and domain-aware collaboration, without requiring any labeled or raw data from clients. Extensive experiments across diverse baselines show that pFedBBN consistently enhances robustness and minority-class performance over state-of-the-art FL and TTA methods.

</details>


### [69] [MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding](https://arxiv.org/abs/2511.18294)
*Mengchun Zhang,Kateryna Shapovalenko,Yucheng Shao,Eddie Guo,Parusha Pradhan*

Main category: cs.LG

TL;DR: MultiDiffNet是一个基于扩散模型的框架，通过优化多目标学习的紧凑潜在空间，绕过生成式增强，实现跨被试的脑电图解码，并在多个任务上达到最先进的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 脑电图解码面临跨被试泛化能力差的问题，主要原因是被试间差异大且缺乏大规模数据集。现有方法依赖合成被试生成或简单数据增强，但无法可靠扩展或泛化。

Method: 提出MultiDiffNet扩散框架，学习优化的紧凑潜在空间，直接从该空间进行解码，避免了生成式增强。同时发布了统一的基准测试套件和统计报告框架。

Result: 在多种神经解码任务上实现了最先进的跨被试泛化性能，特别是在被试和会话不相交的评估设置下表现优异。

Conclusion: 这项工作为现实世界脑机接口系统中的被试无关脑电图解码提供了可重复和开源的基础。

Abstract: Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.

</details>


### [70] [AnyExperts: On-Demand Expert Allocation for Multimodal Language Models with Mixture of Expert](https://arxiv.org/abs/2511.18314)
*Yuting Gao,Wang Lan,Hengyuan Zhao,Linjiang Huang,Si Liu,Qingpei Guo*

Main category: cs.LG

TL;DR: AnyExperts提出了一种按需、预算感知的动态路由框架，通过基于语义重要性为每个token分配可变数量的专家槽位，优化多模态MoE模型的计算分配效率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态MoE模型采用固定的专家激活策略，忽略了不同模态间语义重要性的异质性，导致关键token和冗余token消耗相同计算资源，造成计算分配不优。

Method: 提出AnyExperts框架：为每个token分配可变总数量的专家槽位，但限制在固定范围内；每个槽位由真实专家或虚拟专家填充，虚拟专家比例上限为20%；模型自适应平衡每个token的真实-虚拟专家比例，为语义丰富区域分配更多真实专家。

Result: 在视觉理解、音频理解和NLP理解等多样化任务中，AnyExperts在相同计算预算下提升性能：在通用图像/视频任务中，使用40%更少的真实专家激活达到可比精度；在文本密集任务中，减少10%真实专家使用同时保持性能。

Conclusion: 细粒度、重要性驱动的专家分配显著提升了多模态MoE模型的效率和有效性。

Abstract: Multimodal Mixture-of-Experts (MoE) models offer a promising path toward scalable and efficient large vision-language systems. However, existing approaches rely on rigid routing strategies (typically activating a fixed number of experts per token) ignoring the inherent heterogeneity in semantic importance across modalities. This leads to suboptimal compute allocation, where redundant tokens consume as many resources as critical ones. To address this, we propose AnyExperts, a novel on-demand, budget-aware dynamic routing framework that allocates a variable total number of expert slots per token based on its semantic importance. Crucially, to prevent uncontrolled compute growth, the total slots per token are constrained within a fixed range, and each slot is filled by either a real expert or a virtual expert, with the virtual share capped at a small maximum (e.g., 20%). The model then adaptively balances the real-to-virtual ratio per token, assigning more real experts to semantically rich regions and relying more on virtual experts for redundant content. Evaluated across diverse tasks in visual understanding, audio understanding, and NLP understanding, AnyExperts improves performance under the same compute budget. Notably, on general image/video tasks, it achieves comparable accuracy with 40% fewer real expert activations; on text-dense tasks (OCR and NLP), it maintains performance while reducing real expert usage by 10%. These results demonstrate that fine-grained, importance-driven expert allocation significantly enhances both the efficiency and effectiveness of multimodal MoE models.

</details>


### [71] [Clinician-in-the-Loop Smart Home System to Detect Urinary Tract Infection Flare-Ups via Uncertainty-Aware Decision Support](https://arxiv.org/abs/2511.18334)
*Chibuike E. Ugwu,Roschelle Fritz,Diane J. Cook,Janardhan Rao Doppa*

Main category: cs.LG

TL;DR: 本文提出了一种临床医生在环的智能家居系统，利用环境传感器数据提取行为标记，训练稳健的预测模型，并通过不确定性量化方法为临床决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 老年人尿路感染发作风险高，传统机器学习方法缺乏预测不确定性信息，限制了临床决策的有效性。

Method: 采用临床医生在环的智能家居系统，结合环境传感器数据提取行为标记，使用Conformal-Calibrated Interval方法进行不确定性量化，在模型置信度低时放弃预测。

Result: 在8个真实智能家居数据上的评估显示，该方法在召回率等分类指标上优于基线方法，同时保持最低的放弃比例和区间宽度。42名护士的调查证实了系统的临床价值。

Conclusion: 该系统通过不确定性感知的决策支持，有效改善了老年人尿路感染和其他病症发作的管理和临床决策。

Abstract: Urinary tract infection (UTI) flare-ups pose a significant health risk for older adults with chronic conditions. These infections often go unnoticed until they become severe, making early detection through innovative smart home technologies crucial. Traditional machine learning (ML) approaches relying on simple binary classification for UTI detection offer limited utility to nurses and practitioners as they lack insight into prediction uncertainty, hindering informed clinical decision-making. This paper presents a clinician-in-the-loop (CIL) smart home system that leverages ambient sensor data to extract meaningful behavioral markers, train robust predictive ML models, and calibrate them to enable uncertainty-aware decision support. The system incorporates a statistically valid uncertainty quantification method called Conformal-Calibrated Interval (CCI), which quantifies uncertainty and abstains from making predictions ("I don't know") when the ML model's confidence is low. Evaluated on real-world data from eight smart homes, our method outperforms baseline methods in recall and other classification metrics while maintaining the lowest abstention proportion and interval width. A survey of 42 nurses confirms that our system's outputs are valuable for guiding clinical decision-making, underscoring their practical utility in improving informed decisions and effectively managing UTIs and other condition flare-ups in older adults.

</details>


### [72] [Vulnerability-Aware Robust Multimodal Adversarial Training](https://arxiv.org/abs/2511.18138)
*Junrui Zhang,Xinyu Zhao,Jie Peng,Chenjie Wang,Jianmin Ji,Tianlong Chen*

Main category: cs.LG

TL;DR: 本文提出VARMAT方法，通过量化每个模态的脆弱性并进行针对性正则化，提升多模态模型的对抗鲁棒性，在三个多模态数据集上分别实现了12.73%、22.21%和11.19%的鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了不同模态对最终鲁棒性的贡献差异，导致鲁棒性表现不佳。本文旨在解决多模态模型中模态间脆弱性差异的问题。

Method: 提出VARMAT方法：1）基于攻击目标的一阶近似显式量化每个模态的脆弱性（探测阶段）；2）提出针对高脆弱性模态的正则化项，在保持任务准确性的同时指导鲁棒学习（训练阶段）。

Result: 在多个涉及不同模态的多模态数据集上验证了方法的增强鲁棒性，在三个数据集上分别实现了12.73%、22.21%和11.19%的鲁棒性提升。

Conclusion: VARMAT方法揭示了多模态对抗训练中的一个重要盲点，通过感知模态脆弱性的对抗训练显著提升了多模态模型的鲁棒性。

Abstract: Multimodal learning has shown significant superiority on various tasks by integrating multiple modalities. However, the interdependencies among modalities increase the susceptibility of multimodal models to adversarial attacks. Existing methods mainly focus on attacks on specific modalities or indiscriminately attack all modalities. In this paper, we find that these approaches ignore the differences between modalities in their contribution to final robustness, resulting in suboptimal robustness performance. To bridge this gap, we introduce Vulnerability-Aware Robust Multimodal Adversarial Training (VARMAT), a probe-in-training adversarial training method that improves multimodal robustness by identifying the vulnerability of each modality. To be specific, VARMAT first explicitly quantifies the vulnerability of each modality, grounded in a first-order approximation of the attack objective (Probe). Then, we propose a targeted regularization term that penalizes modalities with high vulnerability, guiding robust learning while maintaining task accuracy (Training). We demonstrate the enhanced robustness of our method across multiple multimodal datasets involving diverse modalities. Finally, we achieve {12.73%, 22.21%, 11.19%} robustness improvement on three multimodal datasets, revealing a significant blind spot in multimodal adversarial training.

</details>


### [73] [KAN vs LSTM Performance in Time Series Forecasting](https://arxiv.org/abs/2511.18613)
*Tabish Ali Rather,S M Mahmudul Hasan Joy,Nadezda Sukhorukova,Federico Frascoli*

Main category: cs.LG

TL;DR: 本文比较了KAN和LSTM在股票价格预测中的性能，发现LSTM在所有预测时间跨度上都显著优于KAN，准确度更高，而KAN虽然在理论上具有可解释性优势，但实际预测误差较大。


<details>
  <summary>Details</summary>
Motivation: 研究KAN和LSTM在非确定性股票价格数据预测中的表现，评估预测准确性与可解释性之间的权衡关系。

Method: 使用均方根误差(RMSE)作为评估指标，比较KAN和LSTM在不同预测时间跨度上的预测性能。

Result: LSTM在所有测试的预测时间跨度上都表现出显著优势，而标准KAN显示出明显更高的误差率和有限的实际应用价值。

Conclusion: LSTM在时间序列预测应用中具有主导地位，而KAN的主要优势在于计算效率，适用于资源受限但精度要求不高的场景。

Abstract: This paper compares Kolmogorov-Arnold Networks (KAN) and Long Short-Term Memory networks (LSTM) for forecasting non-deterministic stock price data, evaluating predictive accuracy versus interpretability trade-offs using Root Mean Square Error (RMSE).LSTM demonstrates substantial superiority across all tested prediction horizons, confirming their established effectiveness for sequential data modelling. Standard KAN, while offering theoretical interpretability through the Kolmogorov-Arnold representation theorem, exhibits significantly higher error rates and limited practical applicability for time series forecasting. The results confirm LSTM dominance in accuracy-critical time series applications while identifying computational efficiency as KANs' primary advantage in resource-constrained scenarios where accuracy requirements are less stringent. The findings support LSTM adoption for practical financial forecasting while suggesting that continued research into specialised KAN architectures may yield future improvements.

</details>


### [74] [scipy.spatial.transform: Differentiable Framework-Agnostic 3D Transformations in Python](https://arxiv.org/abs/2511.18157)
*Martin Schuck,Alexander von Rohr,Angela P. Schoellig*

Main category: cs.LG

TL;DR: 本文对SciPy的spatial.transform模块进行了全面重构，使其兼容所有实现Python数组API的库（如JAX、PyTorch、CuPy），支持GPU/TPU执行、JIT编译、向量化批处理和自动微分，为可微分系统中的3D空间数学提供了框架无关的生产级基础。


<details>
  <summary>Details</summary>
Motivation: 现有的SciPy spatial.transform模块仅支持NumPy，限制了在GPU加速和自动微分工作流中的采用。三维刚体变换在现代可微分机器学习管道中至关重要，但数值鲁棒且数学正确的实现容易出错。

Method: 对SciPy的spatial.transform功能进行完整重构，使其兼容任何实现Python数组API的库，同时保留已建立的SciPy接口。

Result: 重构后的实现支持GPU/TPU执行、JIT编译、向量化批处理和通过后端原生自动微分进行微分。通过两个案例研究展示了其在可微分科学计算中的应用。

Conclusion: 该贡献已合并到SciPy主分支，将在下一个版本中发布，为可微分系统和机器学习中的3D空间数学提供了框架无关、生产级的基础。

Abstract: Three-dimensional rigid-body transforms, i.e. rotations and translations, are central to modern differentiable machine learning pipelines in robotics, vision, and simulation. However, numerically robust and mathematically correct implementations, particularly on SO(3), are error-prone due to issues such as axis conventions, normalizations, composition consistency and subtle errors that only appear in edge cases. SciPy's spatial.transform module is a rigorously tested Python implementation. However, it historically only supported NumPy, limiting adoption in GPU-accelerated and autodiff-based workflows. We present a complete overhaul of SciPy's spatial.transform functionality that makes it compatible with any array library implementing the Python array API, including JAX, PyTorch, and CuPy. The revised implementation preserves the established SciPy interface while enabling GPU/TPU execution, JIT compilation, vectorized batching, and differentiation via native autodiff of the chosen backend. We demonstrate how this foundation supports differentiable scientific computing through two case studies: (i) scalability of 3D transforms and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation for accurate integration of rotational dynamics. Our contributions have been merged into SciPy main and will ship in the next release, providing a framework-agnostic, production-grade basis for 3D spatial math in differentiable systems and ML.

</details>


### [75] [Majority of the Bests: Improving Best-of-N via Bootstrapping](https://arxiv.org/abs/2511.18630)
*Amin Rakhsha,Kanika Madan,Tianyu Zhang,Amir-massoud Farahmand,Amir Khasahmadi*

Main category: cs.LG

TL;DR: 提出Majority-of-the-Bests (MoB)方法，通过自助采样估计BoN的输出分布并选择其众数，在多个基准测试中相比BoN和Self-consistency取得一致改进。


<details>
  <summary>Details</summary>
Motivation: Best-of-N (BoN)方法在奖励模型不完美时性能急剧下降，虽然正确答案的概率不高但通常是最可能的结果，因此需要更可靠的输出选择机制。

Method: MoB通过自助采样估计BoN的输出分布，然后选择该分布的众数作为最终输出，而不是简单地选择最高奖励的输出。

Result: 在5个基准测试、3种基础LLM和2种奖励模型的30个设置中，MoB在25个设置中相比BoN取得一致改进。

Conclusion: MoB为BoN和Self-consistency提供了一个简单而强大的替代方案，并激励对更细致选择机制的研究。

Abstract: Sampling multiple outputs from a Large Language Model (LLM) and selecting the most frequent (Self-consistency) or highest-scoring (Best-of-N) candidate is a popular approach to achieve higher accuracy in tasks with discrete final answers. Best-of-N (BoN) selects the output with the highest reward, and with perfect rewards, it often achieves near-perfect accuracy. With imperfect rewards from reward models, however, BoN fails to reliably find the correct answer and its performance degrades drastically. We consider the distribution of BoN's outputs and highlight that, although the correct answer does not usually have a probability close to one under imperfect rewards, it is often the most likely outcome. This suggests that the mode of this distribution can be more reliably correct than a sample from it. Based on this idea, we propose Majority-of-the-Bests (MoB), a novel selection mechanism that estimates the output distribution of BoN via bootstrapping and selects its mode. Experimental results across five benchmarks, three different base LLMs, and two reward models demonstrate consistent improvements over BoN in 25 out of 30 setups. We also provide theoretical results for the consistency of the bootstrapping. MoB serves as a simple, yet strong alternative to BoN and self-consistency, and more broadly, motivates further research in more nuanced selection mechanisms.

</details>


### [76] [LocaGen: Low-Overhead Indoor Localization Through Spatial Augmentation](https://arxiv.org/abs/2511.18158)
*Abdelrahman Abdelmotlb,Abdallah Taman,Sherif Mostafa,Moustafa Youssef*

Main category: cs.LG

TL;DR: LocaGen是一个创新的空间增强框架，通过条件扩散模型生成未见过位置的高质量合成指纹数据，显著减少室内定位系统的指纹采集开销。


<details>
  <summary>Details</summary>
Motivation: 传统指纹定位系统需要大量位置标记信号数据采集，部署成本高。现有减少采集开销的方法存在表示能力低、模式崩溃或仍需在所有目标位置采集数据的问题。

Method: 使用条件扩散模型结合空间感知优化策略，仅基于部分已见位置生成未见过位置的合成指纹数据；通过领域特定启发式方法增强已见位置数据；采用基于密度的策略选择已见和未见位置以确保鲁棒覆盖。

Result: 在真实世界WiFi指纹数据集上的评估显示，LocaGen在30%位置未见的情况下仍能保持相同的定位精度，相比最先进的增强方法准确率提升高达28%。

Conclusion: LocaGen框架能显著减少指纹采集开销，在保持定位精度的同时提高部署可行性，为室内定位系统的实际应用提供了有效解决方案。

Abstract: Indoor localization systems commonly rely on fingerprinting, which requires extensive survey efforts to obtain location-tagged signal data, limiting their real-world deployability. Recent approaches that attempt to reduce this overhead either suffer from low representation ability, mode collapse issues, or require the effort of collecting data at all target locations. We present LocaGen, a novel spatial augmentation framework that significantly reduces fingerprinting overhead by generating high-quality synthetic data at completely unseen locations. LocaGen leverages a conditional diffusion model guided by a novel spatially aware optimization strategy to synthesize realistic fingerprints at unseen locations using only a subset of seen locations. To further improve our diffusion model performance, LocaGen augments seen location data based on domain-specific heuristics and strategically selects the seen and unseen locations using a novel density-based approach that ensures robust coverage. Our extensive evaluation on a real-world WiFi fingerprinting dataset shows that LocaGen maintains the same localization accuracy even with 30% of the locations unseen and achieves up to 28% improvement in accuracy over state-of-the-art augmentation methods.

</details>


### [77] [Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic Channel-wise Precision Boost](https://arxiv.org/abs/2511.18643)
*Haojun Xia,Xiaoxia Wu,Jisen Li,Robert Wu,Junxiong Wang,Jue Wang,Chenxi Li,Aman Singhal,Alay Dilipbhai Shah,Alpay Ariyak,Donglin Zhuang,Zhongzhu Zhou,Ben Athiwaratkun,Zhen Zheng,Shuaiwen Leon Song*

Main category: cs.LG

TL;DR: Kitty通过算法-系统协同设计实现混合精度KV缓存，在保持准确性的同时将KV内存减少近8倍，提升推理吞吐量2.1-4.1倍。


<details>
  <summary>Details</summary>
Motivation: KV缓存是LLM推理的主要内存瓶颈，4位KV量化能保持准确性但2位量化在长上下文推理中会降低准确性，需要解决这一差距。

Method: 采用动态通道精度提升算法，按敏感度对Key缓存通道排序，仅保留小部分高精度通道；系统层面提供页面中心KV布局、Triton兼容的解量化内核和轻量级运行时管道。

Result: 在7个任务和2个模型家族上，Kitty将KV内存减少近8倍，准确率损失可忽略，在相同内存预算下实现8倍更大批次和2.1-4.1倍更高吞吐量。

Conclusion: Kitty通过算法-系统协同设计成功实现了高效的混合精度KV缓存，显著降低了内存需求并提升了推理性能。

Abstract: The KV cache is a dominant memory bottleneck for LLM inference. While 4-bit KV quantization preserves accuracy, 2-bit often degrades it, especially on long-context reasoning. We close this gap via an algorithm-system co-design for mixed-precision KV caching: Kitty. On the algorithm side, extensive experiments show that Dynamic Channel-wise Precision Boost -- which ranks Key-cache channels by sensitivity and keeps only a small fraction at higher precision -- maintains near-zero loss in accuracy drop while approaching 2-bit memory. The main challenge is handling dynamic 4-bit channel boosts while keeping the page layout coalesced and the dequantization uniform, with no scattered reads or hard-coded masks. Kitty addresses these issues by decompose each mixed-precision Key page into two tensors with unified 2-bit precision. Based on this, Kitty provides a page-centric KV layout, Triton-compatible page dequantization kernels, and a lightweight runtime pipeline that preserves coalescing and avoids divergence. Across seven tasks and two model families (Qwen3, LLaMA3), Kitty cuts KV memory by nearly 8x with negligible accuracy loss, enabling up to 8x larger batches and 2.1x-4.1x higher throughput under the same memory budget. We release the full implementation of Kitty at https://github.com/Summer-Summer/Kitty.

</details>


### [78] [Bringing Stability to Diffusion: Decomposing and Reducing Variance of Training Masked Diffusion Models](https://arxiv.org/abs/2511.18159)
*Mengni Jia,Mengyu Zhou,Yihao Liu,Xiaoxi Jiang,Guanjun Jiang*

Main category: cs.LG

TL;DR: 本文分析了掩码扩散模型训练方差高的根本原因，提出了两种核心方差降低方法P-POTS和MIRROR，显著提升了MDM在复杂推理任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型作为自回归模型的有前景替代方案，存在训练方差过高的问题，导致梯度估计噪声大、优化不稳定，即使与自回归模型在初始化时性能相当，在任务特定训练后也会大幅落后。

Method: 1) 首次将MDM训练方差分解为三个来源：掩码模式噪声、掩码率噪声和数据噪声；2) 设计了六种方差降低方法，核心包括P-POTS（帕累托最优t采样器）和MIRROR（使用负相关样本减少掩码模式噪声）。

Result: 相比标准MDM训练，新方法在复杂推理任务上准确率提升7-8%，同时将运行间变异性降低到接近ARM水平，显著缩小了与强ARM基线的差距。

Conclusion: 通过理论分析和系统性的方差降低方法，成功解决了MDM训练方差过高的问题，使其在保持生成质量的同时实现了更稳定的优化性能。

Abstract: Masked diffusion models (MDMs) are a promising alternative to autoregressive models (ARMs), but they suffer from inherently much higher training variance. High variance leads to noisier gradient estimates and unstable optimization, so even equally strong pretrained MDMs and ARMs that are competitive at initialization often diverge after task-specific training, with MDMs falling far behind. There has been no theoretical explanation or systematic solution. We derive the first decomposition of MDM training variance into three sources: (A) masking pattern noise, (B) masking rate noise, and (C) data noise, while ARMs are only affected by (C). This explains the fundamental training gap. Building on this foundation, we design six variance-reduction methods, including two core methods: (1) P-POTS, a Pareto-optimal t sampler that minimizes training variance by sampling harder t values more often with appropriately smaller update steps, and (2) MIRROR, which uses negatively correlated samples to reduce (A). Experiments show that compared to standard MDM training, our methods improve accuracy by 7-8% on complex reasoning tasks, while simultaneously reducing run-to-run variability to near ARM levels, substantially narrowing the gap with strong ARM baselines; in most settings, even the best baseline runs remain below the worst run of our method.

</details>


### [79] [Bayesian Calibration of Engine-out NOx Models for Engine-to-Engine Transferability](https://arxiv.org/abs/2511.18178)
*Shrenik Zinage,Peter Meckl,Ilias Bilionis*

Main category: cs.LG

TL;DR: 提出了一种贝叶斯校准框架，结合高斯过程和近似贝叶斯计算来推断和校正传感器偏差，以提高发动机NOx排放预测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于少量发动机数据训练的模型难以泛化到整个发动机群体，存在传感器偏差和输入条件变化问题，需要能够适应发动机间差异的模型。

Method: 使用贝叶斯校准框架，结合高斯过程和近似贝叶斯计算，从预训练模型出发推断发动机特定传感器偏差并重新校准预测。

Result: 该方法在未见测试数据上生成发动机NOx排放的后验预测分布，相比传统非自适应高斯过程模型显著提高了预测准确性。

Conclusion: 该可转移建模方法有效解决了发动机间变异性问题，提高了模型泛化能力，无需重新训练模型即可实现高精度预测。

Abstract: Accurate prediction of engine-out NOx is essential for meeting stringent emissions regulations and optimizing engine performance. Traditional approaches rely on models trained on data from a small number of engines, which can be insufficient in generalizing across an entire population of engines due to sensor biases and variations in input conditions. In real world applications, these models require tuning or calibration to maintain acceptable error tolerance when applied to other engines. This highlights the need for models that can adapt with minimal adjustments to accommodate engine-to-engine variability and sensor discrepancies. While previous studies have explored machine learning methods for predicting engine-out NOx, these approaches often fail to generalize reliably across different engines and operating environments. To address these issues, we propose a Bayesian calibration framework that combines Gaussian processes with approximate Bayesian computation to infer and correct sensor biases. Starting with a pre-trained model developed using nominal engine data, our method identifies engine specific sensor biases and recalibrates predictions accordingly. By incorporating these inferred biases, our approach generates posterior predictive distributions for engine-out NOx on unseen test data, achieving high accuracy without retraining the model. Our results demonstrate that this transferable modeling approach significantly improves the accuracy of predictions compared to conventional non-adaptive GP models, effectively addressing engine-to-engine variability and improving model generalizability.

</details>


### [80] [VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model via Neuron Chunking](https://arxiv.org/abs/2511.18692)
*Kichang Yang,Seonjun Kim,Minjae Kim,Nairan Zhang,Chi Zhang,Youngki Lee*

Main category: cs.LG

TL;DR: 本文提出了一种名为Neuron Chunking的I/O高效稀疏化策略，通过将神经元重要性分析与存储访问成本相结合，显著提升了边缘设备上大型视觉语言模型的权重卸载性能。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏化方法仅基于激活幅度选择神经元，忽略了访问模式对闪存性能的影响，导致I/O效率低下。

Method: Neuron Chunking方法在内存中对连续神经元进行分块处理，通过轻量级抽象建模访问连续性来估计I/O延迟，并选择具有高效用（神经元重要性除以估计延迟）的块。

Result: 在Jetson Orin Nano和Jetson AGX Orin设备上，Neuron Chunking分别实现了4.65倍和5.76倍的I/O效率提升。

Conclusion: 通过将稀疏化决策与底层存储行为对齐，Neuron Chunking方法有效提升了边缘设备上大模型的权重卸载性能。

Abstract: Edge deployment of large Vision-Language Models (VLMs) increasingly relies on flash-based weight offloading, where activation sparsification is used to reduce I/O overhead. However, conventional sparsification remains model-centric, selecting neurons solely by activation magnitude and neglecting how access patterns influence flash performance. We present Neuron Chunking, an I/O-efficient sparsification strategy that operates on chunks (i.e., groups of contiguous neurons in memory) and couples neuron importance with storage access cost. The method models I/O latency through a lightweight abstraction of access contiguity and selects chunks with high utility, defined as neuron importance normalized by estimated latency. By aligning sparsification decisions with the underlying storage behavior, Neuron Chunking improves I/O efficiency by up to 4.65x and 5.76x on Jetson Orin Nano and Jetson AGX Orin, respectively.

</details>


### [81] [Federated style aware transformer aggregation of representations](https://arxiv.org/abs/2511.18841)
*Mincheol Jeon,Euinam Huh*

Main category: cs.LG

TL;DR: FedSTAR是一个风格感知的联邦学习框架，通过解耦客户端特定风格因子和共享内容表示来解决个性化联邦学习中的领域异构性、数据不平衡和通信约束问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习缺乏个性化，单一全局模型无法捕捉客户端特定特征，导致对有高度异构数据分布的客户端产生偏差预测和泛化能力差。

Method: 提出FedSTAR框架，使用基于Transformer的注意力机制聚合类原型，解耦客户端特定风格因子与共享内容表示，通过交换紧凑原型和风格向量而非完整模型参数来减少通信开销。

Result: 实验结果表明，结合内容-风格解耦和注意力驱动的原型聚合在异构环境中提高了个性化和鲁棒性，且未增加通信成本。

Conclusion: FedSTAR通过风格感知的方法有效解决了PFL中的关键挑战，在保持低通信开销的同时实现了更好的个性化性能。

Abstract: Personalized Federated Learning (PFL) faces persistent challenges, including domain heterogeneity from diverse client data, data imbalance due to skewed participation, and strict communication constraints. Traditional federated learning often lacks personalization, as a single global model cannot capture client-specific characteristics, leading to biased predictions and poor generalization, especially for clients with highly divergent data distributions.
  To address these issues, we propose FedSTAR, a style-aware federated learning framework that disentangles client-specific style factors from shared content representations. FedSTAR aggregates class-wise prototypes using a Transformer-based attention mechanism, allowing the server to adaptively weight client contributions while preserving personalization.
  Furthermore, by exchanging compact prototypes and style vectors instead of full model parameters, FedSTAR significantly reduces communication overhead. Experimental results demonstrate that combining content-style disentanglement with attention-driven prototype aggregation improves personalization and robustness in heterogeneous environments without increasing communication cost.

</details>


### [82] [Accelerating Time Series Foundation Models with Speculative Decoding](https://arxiv.org/abs/2511.18191)
*Pranav Subbaraman,Fang Sun,Yue Yao,Huacong Tang,Xiao Luo,Yizhou Sun*

Main category: cs.LG

TL;DR: 提出了一种基于推测解码的时间序列预测推理加速框架，使用小模型生成预测片段，大模型并行验证，显著减少顺序前向传播次数，在不修改模型架构的情况下实现推理加速。


<details>
  <summary>Details</summary>
Motivation: 大规模Transformer模型在时间序列预测中表现出色，但计算成本高，难以在延迟敏感的web应用中部署。需要一种无需修改现有模型架构的推理加速方法。

Method: 采用推测解码方法，使用小规模"草稿"模型生成未来时间序列片段，然后用大规模"目标"模型并行验证这些片段，设计多变量高斯片段的接受标准和实用变体来平衡效率与精度。

Result: 在web应用相关的时间序列预测基准测试中，实现了显著的推理加速，同时保持了有竞争力的预测精度。

Conclusion: 该框架为时间序列预测模型提供了一种有效的推理加速方案，无需修改现有基础模型架构，可直接应用于已部署的时间序列预测系统。

Abstract: Modern web applications--from real-time content recommendation and dynamic pricing to CDN optimization--increasingly rely on time-series forecasting to deliver personalized experiences to billions of users. Large-scale Transformer-based models have achieved state-of-the-art performance in time-series forecasting but suffer from high computational costs, limiting their deployment in latency-sensitive web applications. To address this challenge, we propose a general inference acceleration framework that adapts speculative decoding to autoregressive time-series models. Our approach employs a smaller "draft" model to propose future time-series patches, which are then verified in parallel by a larger "target" model, reducing the number of sequential forward passes required. We address key technical challenges in adapting this technique from discrete language tokens to continuous time-series distributions, including the design of acceptance criteria for multivariate Gaussian patches and practical variants that balance efficiency with accuracy. Through experiments on time series forecasting benchmarks relevant to web applications, we demonstrate significant inference speedups while maintaining competitive accuracy. The framework requires no architectural modifications to existing foundation models, making it immediately applicable to accelerate deployed time-series forecasting systems. Our implementation can be found at https://github.com/PranavSubbaraman/STRIDE

</details>


### [83] [Adaptive Conformal Prediction for Quantum Machine Learning](https://arxiv.org/abs/2511.18225)
*Douglas Spencer,Samual Nicholls,Michele Caprio*

Main category: cs.LG

TL;DR: 本文提出了自适应量子保形预测(AQCP)算法，通过重复校准来应对量子处理器中的时变噪声，在任意硬件噪声条件下保持渐近平均覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习需要可靠的预测不确定性量化方法，但当前量子领域缺乏稳健的不确定性量化技术。量子保形预测虽然能提供概率保证，但量子处理器的时变噪声会破坏其保形保证。

Method: 基于自适应保形推理框架，引入自适应量子保形预测(AQCP)算法，通过持续重新校准来适应量子硬件噪声的变化。

Result: 在IBM量子处理器上的实证研究表明，AQCP能够达到目标覆盖水平，并且比量子保形预测表现出更高的稳定性。

Conclusion: AQCP算法能够有效应对量子处理器中的时变噪声，为量子机器学习提供了更可靠的预测不确定性量化方法。

Abstract: Quantum machine learning seeks to leverage quantum computers to improve upon classical machine learning algorithms. Currently, robust uncertainty quantification methods remain underdeveloped in the quantum domain, despite the critical need for reliable and trustworthy predictions. Recent work has introduced quantum conformal prediction, a framework that produces prediction sets that are guaranteed to contain the true outcome with user-specified probability. In this work, we formalise how the time-varying noise inherent in quantum processors can undermine conformal guarantees, even when calibration and test data are exchangeable. To address this challenge, we draw on Adaptive Conformal Inference, a method which maintains validity over time via repeated recalibration. We introduce Adaptive Quantum Conformal Prediction (AQCP), an algorithm which preserves asymptotic average coverage guarantees under arbitrary hardware noise conditions. Empirical studies on an IBM quantum processor demonstrate that AQCP achieves target coverage levels and exhibits greater stability than quantum conformal prediction.

</details>


### [84] [Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning](https://arxiv.org/abs/2511.18871)
*Jian Lu*

Main category: cs.LG

TL;DR: 该论文提出了一种将传统同步强化学习架构改进为周期性异步框架的方法，通过在数据加载器引入改进，实现了推理和训练的解耦部署，在保持算法精度等效的同时显著提升了训练效率。


<details>
  <summary>Details</summary>
Motivation: 主流RL框架中推理和训练通常部署在同一设备上，虽然降低了成本但同步执行带来了计算耦合，无法实现并发推理和训练，训练效率成为关键挑战。

Method: 采用推理和训练分离部署策略，改进数据加载器，将同步架构转变为周期性异步框架；在训练阶段应用统一的三模型架构，并提出共享提示注意力掩码以减少重复计算。

Result: 在NPU平台上实现了至少三倍的整体性能提升，同时算法精度与同步方法完全等效，两者都属于同策略方法。

Conclusion: 该周期性异步框架允许按需独立弹性扩展各组件，具有广泛应用潜力，为强化学习训练效率问题提供了有效解决方案。

Abstract: Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.

</details>


### [85] [Tail Distribution of Regret in Optimistic Reinforcement Learning](https://arxiv.org/abs/2511.18247)
*Sajad Khodadadian,Mehrdad Moharrami*

Main category: cs.LG

TL;DR: 本文针对基于乐观策略的强化学习在有限时域表格马尔可夫决策过程中的遗憾分布进行了实例相关的尾界分析，揭示了其独特的双机制结构：从实例相关尺度m_K开始的亚高斯尾部，到过渡阈值后变为亚韦布尔尾部。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注期望遗憾或单一高概率分位数，缺乏对累积遗憾完整尾分布的全面分析。本文旨在填补这一空白，为乐观算法在强化学习中的遗憾分布提供更全面的理论保证。

Method: 采用UCBVI类型算法，分析两种自然探索奖励调度方案：(i) 依赖于总回合数K的方案；(ii) 仅依赖于当前回合索引的K无关方案。通过调节参数α来平衡期望遗憾和亚高斯尾部的范围。

Result: 获得了Pr(R_K ≥ x)的上界，显示出独特的双机制结构：在实例相关尺度m_K到过渡阈值之间为亚高斯尾部，超过该阈值后为亚韦布尔尾部。同时推导了相应的实例相关期望遗憾界。

Conclusion: 这是首个为标准乐观算法在情景强化学习中提供全面尾遗憾保证的研究之一，揭示了遗憾分布的精细结构特征，为算法设计和理论分析提供了新的洞见。

Abstract: We derive instance-dependent tail bounds for the regret of optimism-based reinforcement learning in finite-horizon tabular Markov decision processes with unknown transition dynamics. Focusing on a UCBVI-type algorithm, we characterize the tail distribution of the cumulative regret $R_K$ over $K$ episodes, rather than only its expectation or a single high-probability quantile. We analyze two natural exploration-bonus schedules: (i) a $K$-dependent scheme that explicitly incorporates the total number of episodes $K$, and (ii) a $K$-independent scheme that depends only on the current episode index. For both settings, we obtain an upper bound on $\Pr(R_K \ge x)$ that exhibits a distinctive two-regime structure: a sub-Gaussian tail starting from an instance-dependent scale $m_K$ up to a transition threshold, followed by a sub-Weibull tail beyond that point. We further derive corresponding instance-dependent bounds on the expected regret $\mathbb{E}[R_K]$. The proposed algorithm depends on a tuning parameter $α$, which balances the expected regret and the range over which the regret exhibits a sub-Gaussian tail. To the best of our knowledge, our results provide one of the first comprehensive tail-regret guarantees for a standard optimistic algorithm in episodic reinforcement learning.

</details>


### [86] [Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models](https://arxiv.org/abs/2511.18890)
*Yonggan Fu,Xin Dong,Shizhe Diao,Matthijs Van keirsbilck,Hanrong Ye,Wonmin Byeon,Yashaswi Karnati,Lucas Liebenwein,Hannah Zhang,Nikolaus Binder,Maksim Khadkevich,Alexander Keller,Jan Kautz,Yingyan Celine Lin,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 本文研究了小语言模型在真实设备上的延迟优化，提出了基于深度-宽度比和算子选择的设计原则，开发了自动搜索框架来构建混合SLM架构，并引入权重归一化技术提升训练效果，最终提出的Nemotron-Flash模型在准确性和效率方面显著超越了现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有小语言模型设计主要关注参数数量优化，但参数效率并不一定转化为实际设备上的速度提升。本文旨在识别影响SLM真实设备延迟的关键因素，为以延迟为主要考虑因素的SLM设计和训练提供通用原则和方法。

Method: 1. 识别两个核心架构因素：深度-宽度比和算子选择；2. 研究延迟最优的深度-宽度比；3. 探索高效注意力替代方案；4. 构建进化搜索框架自动发现算子最优组合；5. 使用权重归一化技术增强SLM训练。

Result: 提出的Nemotron-Flash模型相比Qwen3-1.7B/0.6B，平均准确率提升超过5.5%，延迟降低1.3倍/1.9倍，吞吐量提高18.7倍/45.6倍，显著推进了准确率-效率前沿。

Conclusion: 通过系统分析SLM延迟的关键决定因素，并开发相应的架构设计和训练方法，本文成功构建了在准确性和效率方面都显著优于现有SOTA模型的新型混合SLM家族。

Abstract: Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.

</details>


### [87] [Coherent Multi-Agent Trajectory Forecasting in Team Sports with CausalTraj](https://arxiv.org/abs/2511.18248)
*Wei Zhen Teoh*

Main category: cs.LG

TL;DR: CausalTraj是一个基于因果关系的多智能体轨迹预测模型，专注于生成联合概率的多智能体轨迹预测，在联合指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要基于单智能体精度指标进行评估，忽略了模型是否能够学习到哪些预测轨迹可以共同形成合理的多智能体未来，导致在联合预测和生成连贯的多智能体场景方面表现不佳。

Method: 提出了CausalTraj，一个时间因果、基于似然度的模型，专门用于生成联合概率的多智能体轨迹预测。

Result: 在NBA SportVU、Basketball-U和Football-U数据集上，CausalTraj在单智能体精度指标上表现有竞争力，在联合指标上取得了最佳记录结果，同时产生了质量上连贯和现实的游戏演化。

Conclusion: CausalTraj模型在联合预测能力方面表现优异，能够生成连贯和现实的多智能体场景，强调了联合评估指标的重要性。

Abstract: Jointly forecasting trajectories of multiple interacting agents is a core challenge in sports analytics and other domains involving complex group dynamics. Accurate prediction enables realistic simulation and strategic understanding of gameplay evolution. Most existing models are evaluated solely on per-agent accuracy metrics (minADE, minFDE), which assess each agent independently on its best-of-k prediction. However these metrics overlook whether the model learns which predicted trajectories can jointly form a plausible multi-agent future. Many state-of-the-art models are designed and optimized primarily based on these metrics. As a result, they may underperform on joint predictions and also fail to generate coherent, interpretable multi-agent scenarios in team sports. We propose CausalTraj, a temporally causal, likelihood-based model that is built to generate jointly probable multi-agent trajectory forecasts. To better assess collective modeling capability, we emphasize joint metrics (minJADE, minJFDE) that measure joint accuracy across agents within the best generated scenario sample. Evaluated on the NBA SportVU, Basketball-U, and Football-U datasets, CausalTraj achieves competitive per-agent accuracy and the best recorded results on joint metrics, while yielding qualitatively coherent and realistic gameplay evolutions.

</details>


### [88] [VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL](https://arxiv.org/abs/2511.18902)
*Zengjie Hu,Jiantao Qiu,Tianyi Bai,Haojin Yang,Binhang Yuan,Qi Jing,Conghui He,Wentao Zhang*

Main category: cs.LG

TL;DR: VADE是一个方差感知的动态采样框架，通过在线样本难度估计解决基于群体的策略优化方法中的梯度消失问题，提高训练信号并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于群体的策略优化方法（如GRPO和GSPO）存在梯度消失问题，当组内所有响应获得相同奖励时，优势估计会崩溃，训练信号减弱。现有解决方案要么计算开销大，要么缺乏实时适应性。

Method: VADE框架包含三个关键组件：使用Beta分布进行在线样本级难度估计、通过估计正确概率最大化信息增益的Thompson采样器、以及在策略演化下保持稳健估计的双尺度先验衰减机制。

Result: 在多模态推理基准测试中，VADE在性能和样本效率方面均优于强基线方法，同时显著减少了计算开销。

Conclusion: VADE能够动态选择最具信息量的样本，有效解决梯度消失问题，并且可以作为即插即用组件无缝集成到现有的基于群体的强化学习算法中。

Abstract: Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \textbf{VADE}, a \textbf{V}ariance-\textbf{A}ware \textbf{D}ynamic sampling framework via online sample-level difficulty \textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.

</details>


### [89] [How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining](https://arxiv.org/abs/2511.18903)
*Kairong Luo,Zhenbo Sun,Haodong Wen,Xinyu Shi,Jiarui Cui,Chenyi Dang,Kaifeng Lyu,Wenguang Chen*

Main category: cs.LG

TL;DR: 研究发现课程式预训练效果受限的原因是数据质量升序排列与学习率衰减计划不兼容，提出了两种简单策略来缓解这个问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于高质量数据稀缺，LLMs通常在不同质量的数据混合上训练，课程式预训练试图通过按质量升序排列数据来更好利用高质量数据，但先前研究显示改进有限。

Method: 识别了学习率衰减计划与课程式训练的不兼容性，提出了两种策略：(1)使用更温和的学习率衰减计划；(2)用模型平均替代学习率衰减。

Result: 结合这两种策略，在标准基准测试上的平均得分比随机混洗提高了1.64%，在1.5B参数模型和30B tokens训练规模上得到验证。

Conclusion: 研究呼吁重新评估课程式LLM预训练，并强调了数据课程与优化方法协同设计的潜力。

Abstract: Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.

</details>


### [90] [Learning Solution Operators for Partial Differential Equations via Monte Carlo-Type Approximation](https://arxiv.org/abs/2511.18930)
*Salah Eddine Choutri,Prajwal Chauhan,Othmane Mazhar,Saif Eddin Jabari*

Main category: cs.LG

TL;DR: MCNO提出了一种轻量级架构，通过蒙特卡洛方法直接逼近核积分来学习参数化PDE的解算子，无需谱假设或平移不变性假设，能够在多种网格分辨率下泛化。


<details>
  <summary>Details</summary>
Motivation: 开发一种不依赖谱假设或平移不变性假设的轻量级神经算子架构，降低计算成本同时保持竞争力。

Method: 使用蒙特卡洛方法直接逼近核积分，核表示为固定随机采样点集上的可学习张量，无需重复采样训练。

Result: 在标准1D PDE基准测试中，MCNO以低计算成本实现了具有竞争力的精度。

Conclusion: MCNO为谱和基于图的神经算子提供了一种简单实用的替代方案，具有轻量化和多分辨率泛化能力。

Abstract: The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight architecture for learning solution operators for parametric PDEs by directly approximating the kernel integral using a Monte Carlo approach. Unlike Fourier Neural Operators, MCNO makes no spectral or translation-invariance assumptions. The kernel is represented as a learnable tensor over a fixed set of randomly sampled points. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with low computational cost, providing a simple and practical alternative to spectral and graph-based neural operators.

</details>


### [91] [From Tables to Signals: Revealing Spectral Adaptivity in TabPFN](https://arxiv.org/abs/2511.18278)
*Jianqiao Zheng,Cameron Gordon,Yiping Ji,Hemanth Saratchandran,Simon Lucey*

Main category: cs.LG

TL;DR: 本文通过信号重构的视角分析TabPFN，发现其具有比标准ReLU-MLP更宽的频率容量，且其频谱能力能根据上下文样本数量自适应调整，这种特性使其能够实现无需训练和超参数调优的图像去噪任务。


<details>
  <summary>Details</summary>
Motivation: 理解任务无关的表格基础模型（如TabPFN）的归纳偏置来源，这些模型在表格学习任务中表现出色但其内在机制尚不清楚。

Method: 通过信号重构和频率分析的方法研究TabPFN的上下文学习行为，分析其频谱特性和位置编码的作用。

Result: 发现TabPFN具有比标准ReLU-MLP更宽的有效频率容量，其频谱能力能根据上下文样本数量自适应调整，位置编码能调节其频率响应，这些特性使其能够实现训练和超参数自由的图像去噪。

Conclusion: 该分析为表格基础模型的结构和归纳偏置提供了新见解，并突显了它们在更广泛信号重构任务中的潜力。

Abstract: Task-agnostic tabular foundation models such as TabPFN have achieved impressive performance on tabular learning tasks, yet the origins of their inductive biases remain poorly understood. In this work, we study TabPFN through the lens of signal reconstruction and provide the first frequency-based analysis of its in-context learning behavior. We show that TabPFN possesses a broader effective frequency capacity than standard ReLU-MLPs, even without hyperparameter tuning. Moreover, unlike MLPs whose spectra evolve primarily over training epochs, we find that TabPFN's spectral capacity adapts directly to the number of samples provided in-context, a phenomenon we term Spectral Adaptivity. We further demonstrate that positional encoding modulates TabPFN's frequency response, mirroring classical results in implicit neural representations. Finally, we show that these properties enable TabPFN to perform training-free and hyperparameter-free image denoising, illustrating its potential as a task-agnostic implicit model. Our analysis provides new insight into the structure and inductive biases of tabular foundation models and highlights their promise for broader signal reconstruction tasks.

</details>


### [92] [SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression](https://arxiv.org/abs/2511.18936)
*Santhosh G S,Saurav Prakash,Balaraman Ravindran*

Main category: cs.LG

TL;DR: SWAN是一种无需微调的KV缓存压缩框架，通过正交矩阵旋转和剪枝直接压缩KV缓存，无需解压缩步骤，在保持性能的同时实现50-60%的内存节省。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自回归推理时面临KV缓存内存占用过大的瓶颈，现有压缩技术存在信息丢失、固定限制或解压缩计算开销大的问题。

Method: 使用离线正交矩阵对KV缓存进行旋转和剪枝，压缩后的缓存直接用于注意力计算，无需重建步骤，并配合小型密集缓冲区。

Result: 实验表明SWAN在保持接近未压缩基线性能的同时，每个token的KV缓存内存节省达到50-60%，且支持运行时可调压缩级别。

Conclusion: SWAN的无解压缩设计、高压缩率下的良好性能以及适应性，使其成为服务长上下文LLMs的实用高效解决方案。

Abstract: Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.

</details>


### [93] [TRIDENT: A Trimodal Cascade Generative Framework for Drug and RNA-Conditioned Cellular Morphology Synthesis](https://arxiv.org/abs/2511.18287)
*Rui Peng,Ziru Liu,Lingyuan Ye,Yuxing Lu,Boxin Shi,Jinzhuo Wang*

Main category: cs.LG

TL;DR: TRIDENT是一个级联生成框架，通过同时考虑扰动和相应基因表达谱来合成真实的细胞形态，显著优于现有方法，在未见化合物上表现出强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常局限于建模直接关联（如扰动→RNA或扰动→形态），而忽略了从RNA到形态的关键因果联系，这阻碍了构建AI虚拟细胞的进展。

Method: 提出TRIDENT级联生成框架，构建了MorphoGene数据集（包含98种化合物的L1000基因表达与Cell Painting图像配对），通过条件化扰动和基因表达谱来合成细胞形态。

Result: TRIDENT显著优于最先进方法，实现了高达7倍的改进，对未见化合物具有强泛化能力。案例研究验证了RNA引导合成能准确产生相应表型，消融研究证实RNA条件化对模型高保真度至关重要。

Conclusion: 通过显式建模转录组-表型组映射，TRIDENT提供了一个强大的计算机模拟工具，使我们更接近预测性虚拟细胞。

Abstract: Accurately modeling the relationship between perturbations, transcriptional responses, and phenotypic changes is essential for building an AI Virtual Cell (AIVC). However, existing methods typically constrained to modeling direct associations, such as Perturbation $\rightarrow$ RNA or Perturbation $\rightarrow$ Morphology, overlook the crucial causal link from RNA to morphology. To bridge this gap, we propose TRIDENT, a cascade generative framework that synthesizes realistic cellular morphology by conditioning on both the perturbation and the corresponding gene expression profile. To train and evaluate this task, we construct MorphoGene, a new dataset pairing L1000 gene expression with Cell Painting images for 98 compounds. TRIDENT significantly outperforms state-of-the-art approaches, achieving up to 7-fold improvement with strong generalization to unseen compounds. In a case study on docetaxel, we validate that RNA-guided synthesis accurately produces the corresponding phenotype. An ablation study further confirms that this RNA conditioning is essential for the model's high fidelity. By explicitly modeling transcriptome-phenome mapping, TRIDENT provides a powerful in silico tool and moves us closer to a predictive virtual cell.

</details>


### [94] [Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation](https://arxiv.org/abs/2511.18958)
*Qisen Chai,Yansong Wang,Junjie Huang,Tao Jia*

Main category: cs.LG

TL;DR: 本文提出Cutter框架，通过双智能体强化学习压缩图数据，在保持拓扑结构和鲁棒性特征的同时显著提升评估效率。


<details>
  <summary>Details</summary>
Motivation: 随着图结构数据规模不断增大，评估其在对抗攻击下的鲁棒性变得计算昂贵且难以扩展，需要高效的压缩方法来保持评估可靠性。

Method: 提出Cutter双智能体强化学习框架，包含关键节点检测智能体和冗余节点检测智能体，采用轨迹级奖励塑造、原型塑造和跨智能体模仿三种策略来提升学习效率和压缩质量。

Result: 在多个真实世界图数据上的实验表明，Cutter生成的压缩图保留了关键静态拓扑特性，在各种攻击场景下与原图的鲁棒性退化趋势高度一致。

Conclusion: Cutter能够在不损害评估保真度的前提下显著提升评估效率，为大规模图数据鲁棒性评估提供了有效解决方案。

Abstract: As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.

</details>


### [95] [ADF-LoRA: Alternating Low-Rank Aggregation for Decentralized Federated Fine-Tuning](https://arxiv.org/abs/2511.18291)
*Xiaoyu Wang,Xiaotian Li,Zhixiang Zhou,Chen Li,Yong Liu*

Main category: cs.LG

TL;DR: 本文提出了ADF-LoRA方法，在去中心化联邦学习中通过同步更新单个低秩矩阵并混合两个矩阵来改善参数状态一致性，实现了更快速平滑的收敛和更高的准确率。


<details>
  <summary>Details</summary>
Motivation: 在去中心化联邦学习环境中，交替更新LoRA矩阵会因客户端间的相位状态不匹配和块级发散而面临新的挑战，需要设计更稳定的参数传播机制。

Method: 提出ADF-LoRA方法，每轮仅同步更新一个低秩矩阵，并通过混合两个矩阵来保持参数状态的一致性，同时保留交替更新的交叉项抑制效果。

Result: 在多个GLUE任务上的实验表明，ADF-LoRA实现了更快速平滑的收敛，并在去中心化联邦学习中始终优于现有的LoRA变体，获得了最高的平均准确率。

Conclusion: ADF-LoRA通过改进的交替低秩更新机制，有效解决了去中心化联邦学习中的稳定性问题，为服务器化拓扑结构提供了更优的解决方案。

Abstract: This paper revisits alternating low-rank updates for federated fine-tuning and examines their behavior in decentralized federated learning (DFL). While alternating the LoRA matrices has been shown to stabilize aggregation in centralized FL, extending this mechanism to decentralized, peer-to-peer communication introduces new challenges due to phase-state mismatch and block-wise divergence across clients. We introduce ADF-LoRA, which synchronizes the update of only one low-rank matrix per round and mixes both matrices to maintain more consistent parameter states under decentralized propagation. This design preserves the cross-term suppression effect of alternating updates while improving stability in serverless topologies. We provide a convergence analysis under standard smoothness assumptions and evaluate ADF-LoRA on multiple GLUE tasks. Experiments show that ADF-LoRA achieves faster and smoother convergence and delivers the highest average accuracy across tasks, outperforming existing LoRA variants in decentralized FL by a consistent margin.

</details>


### [96] [FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning](https://arxiv.org/abs/2511.18977)
*Xin Yuan,Siqi Li,Jiateng Wei,Chengrui Zhu,Yanming Wu,Qingpeng Li,Jiajun Lv,Xiaoke Lan,Jun Chen,Yong Liu*

Main category: cs.LG

TL;DR: 提出了FastForward剪枝方法，通过解耦的单步强化学习框架，将策略优化与复杂预算满足问题分离，显著提高了大型语言模型剪枝的搜索效率。


<details>
  <summary>Details</summary>
Motivation: 当前剪枝方法面临效率挑战：启发式方法快速但性能次优，基于搜索的方法（如强化学习）计算成本过高。需要一种既能高效搜索又能获得最优性能的剪枝方法。

Method: 采用解耦的单步强化学习框架，将策略优化与预算满足问题分离。使用基于课程学习的策略，从低成本简单任务开始逐步增加复杂度，大幅降低搜索计算开销。

Result: 在LLaMA、Mistral和OPT模型系列上评估，发现的剪枝策略优于强启发式基线。与其他基于搜索的算法相比，以极低计算成本实现了竞争性或更优的结果。

Conclusion: FastForward剪枝方法在搜索效率方面具有明显优势，能够以较低计算成本找到高性能的剪枝策略，解决了大型语言模型剪枝中的效率瓶颈问题。

Abstract: Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search's computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.

</details>


### [97] [OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs](https://arxiv.org/abs/2511.19023)
*Yuting Gao,Weihao Chen,Lan Wang,Ruihan Xu,Qingpei Guo*

Main category: cs.LG

TL;DR: OrdMoE提出了一种无需外部人类标注偏好的多模态大语言模型对齐框架，通过利用MoE架构中的路由器专家选择分数来构建内部偏好层次，实现零成本的自我监督偏好排序。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好学习方法主要依赖外部人类标注的偏好数据，收集成本高昂且劳动密集。本文旨在开发一种不依赖外部人类偏好的对齐方法。

Method: 利用MoE架构中路由器专家选择分数隐含的质量感知特性，将专家按路由分数分组为不同等级，分别激活每个等级来生成质量递增的响应序列，从而构建内部偏好层次。

Result: 在多个多模态基准测试上的广泛实验表明，OrdMoE显著提升了多模态MoE LLMs的对齐和整体性能，无需任何人类标注偏好数据即可获得有竞争力的结果。

Conclusion: OrdMoE框架成功证明了可以利用MoE架构的内在信号实现有效的偏好对齐，为多模态大语言模型的对齐提供了一种零成本、自我监督的替代方案。

Abstract: Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.

</details>


### [98] [Mitigating Participation Imbalance Bias in Asynchronous Federated Learning](https://arxiv.org/abs/2511.19066)
*Xiangyu Chang,Manyi Yao,Srikanth V. Krishnamurthy,Christian R. Shelton,Anirban Chakraborty,Ananthram Swami,Samet Oymak,Amit Roy-Chowdhury*

Main category: cs.LG

TL;DR: 本文分析了异步联邦学习中的异构性放大问题，提出了ACE和ACED方法来缓解参与不平衡，通过立即使用所有客户端的最新信息进行非缓冲更新。


<details>
  <summary>Details</summary>
Motivation: 在异步联邦学习中，服务器立即使用每个到达客户端的贡献更新全局模型，导致客户端在不同模型版本上进行本地训练，造成信息陈旧。在非IID数据分布下，这种异步模式放大了客户端异构性的不利影响，因为更快的客户端贡献更频繁的更新，使全局模型产生偏差。

Method: 提出了ACE方法，通过立即、非缓冲的更新使用所有客户端的最新信息来缓解参与不平衡。还引入了ACED变体，通过延迟感知机制来平衡客户端多样性与更新陈旧性。

Result: 在不同模型、不同任务以及各种异构性和延迟设置下的实验验证了分析结果，并证明了所提方法的鲁棒性能。

Conclusion: ACE和ACED方法有效缓解了异步联邦学习中的异构性放大问题，通过平衡客户端参与和更新时效性，提高了模型性能的鲁棒性。

Abstract: In Asynchronous Federated Learning (AFL), the central server immediately updates the global model with each arriving client's contribution. As a result, clients perform their local training on different model versions, causing information staleness (delay). In federated environments with non-IID local data distributions, this asynchronous pattern amplifies the adverse effect of client heterogeneity (due to different data distribution, local objectives, etc.), as faster clients contribute more frequent updates, biasing the global model. We term this phenomenon heterogeneity amplification. Our work provides a theoretical analysis that maps AFL design choices to their resulting error sources when heterogeneity amplification occurs. Guided by our analysis, we propose ACE (All-Client Engagement AFL), which mitigates participation imbalance through immediate, non-buffered updates that use the latest information available from all clients. We also introduce a delay-aware variant, ACED, to balance client diversity against update staleness. Experiments on different models for different tasks across diverse heterogeneity and delay settings validate our analysis and demonstrate the robust performance of our approaches.

</details>


### [99] [DiM-TS: Bridge the Gap between Selective State Space Models and Time Series for Generative Modeling](https://arxiv.org/abs/2511.18312)
*Zihao Yao,Jiankai Zuo,Yaying Zhang*

Main category: cs.LG

TL;DR: 本文提出DiM-TS模型，利用状态空间模型Mamba改进时间序列生成，通过Lag Fusion和Permutation Scanning增强对长期依赖和通道相关性的建模能力。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据面临隐私问题，现有扩散模型难以捕捉长期时间依赖和复杂通道关系，需要改进时间序列生成质量。

Method: 提出Lag Fusion Mamba和Permutation Scanning Mamba两种变体，分析状态空间模型在时间滞后和通道排列方面的局限性，并集成构建DiM-TS模型。

Result: 理论分析显示两种变体与原始Mamba具有统一的矩阵乘法框架，实验证明DiM-TS能生成更真实的时间序列并保持数据多样性。

Conclusion: DiM-TS在公共数据集上表现出色，能更好地保持时间周期性和通道间相关性，为高质量时间序列生成提供了有效解决方案。

Abstract: Time series data plays a pivotal role in a wide variety of fields but faces challenges related to privacy concerns. Recently, synthesizing data via diffusion models is viewed as a promising solution. However, existing methods still struggle to capture long-range temporal dependencies and complex channel interrelations. In this research, we aim to utilize the sequence modeling capability of a State Space Model called Mamba to extend its applicability to time series data generation. We firstly analyze the core limitations in State Space Model, namely the lack of consideration for correlated temporal lag and channel permutation. Building upon the insight, we propose Lag Fusion Mamba and Permutation Scanning Mamba, which enhance the model's ability to discern significant patterns during the denoising process. Theoretical analysis reveals that both variants exhibit a unified matrix multiplication framework with the original Mamba, offering a deeper understanding of our method. Finally, we integrate two variants and introduce Diffusion Mamba for Time Series (DiM-TS), a high-quality time series generation model that better preserves the temporal periodicity and inter-channel correlations. Comprehensive experiments on public datasets demonstrate the superiority of DiM-TS in generating realistic time series while preserving diverse properties of data.

</details>


### [100] [EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching](https://arxiv.org/abs/2511.19087)
*Ziyun Li,Ben Dai,Huancheng Hu,Henrik Boström,Soon Hoe Lim*

Main category: cs.LG

TL;DR: 本文引入动能路径能量(KPE)作为诊断工具，量化ODE采样器生成路径的总动能消耗，发现语义质量更高的样本需要更大的动能努力，且位于数据分布的稀疏前沿。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注端点指标(如保真度、似然度、感知质量)，而忽略了采样轨迹所揭示的深层信息。受经典力学启发，希望了解生成路径的动力学特性。

Method: 引入动能路径能量(KPE)这一简单而强大的诊断工具，用于量化ODE采样器每个生成路径的总动能消耗。在CIFAR-10和ImageNet-256上进行了全面实验。

Result: 发现两个关键现象：(i)更高的KPE预测更强的语义质量，表明语义更丰富的样本需要更大的动能努力；(ii)更高的KPE与数据密度呈负相关，信息丰富的样本位于稀疏的低密度区域。

Conclusion: 语义信息丰富的样本自然地存在于数据分布的稀疏前沿，需要更大的生成努力。轨迹级分析为理解生成难度和样本特征提供了物理启发且可解释的框架。

Abstract: Flow-based generative models synthesize data by integrating a learned velocity field from a reference distribution to the target data distribution. Prior work has focused on endpoint metrics (e.g., fidelity, likelihood, perceptual quality) while overlooking a deeper question: what do the sampling trajectories reveal? Motivated by classical mechanics, we introduce kinetic path energy (KPE), a simple yet powerful diagnostic that quantifies the total kinetic effort along each generation path of ODE-based samplers. Through comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that semantically richer samples require greater kinetic effort, and ({ii}) higher KPE inversely correlates with data density, with informative samples residing in sparse, low-density regions. Together, these findings reveal that semantically informative samples naturally reside on the sparse frontier of the data distribution, demanding greater generative effort. Our results suggest that trajectory-level analysis offers a physics-inspired and interpretable framework for understanding generation difficulty and sample characteristics.

</details>


### [101] [The Core in Max-Loss Non-Centroid Clustering Can Be Empty](https://arxiv.org/abs/2511.19107)
*Robert Bredereck,Eva Deltl,Leon Kellerhals,Jannik Peters*

Main category: cs.LG

TL;DR: 该论文研究了在最大损失目标下的非质心聚类中的核心稳定性问题，证明了对于k≥3的情况，存在度量实例使得没有任何聚类位于α-核心中，其中α<2^(1/5)≈1.148。


<details>
  <summary>Details</summary>
Motivation: 研究非质心聚类中核心稳定性的存在性问题，特别是在最大损失目标函数下，填补了该领域缺乏不可能性结果的研究空白。

Method: 使用数学证明方法，对于k≥3的情况构造了度量实例，并通过计算机辅助证明识别了二维欧几里得点集的相关下界。

Result: 证明了对于所有k≥3，存在度量实例使得没有任何聚类位于α-核心中，其中α<2^(1/5)≈1.148，且该界限对于构造是紧的。

Conclusion: 这是第一个证明在最大损失目标下的非质心聚类中核心可能为空的不可能性结果，填补了该领域的研究空白。

Abstract: We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\geq 3$ there exist metric instances with $n\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $α$-core for any $α<2^{\frac{1}{5}}\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.

</details>


### [102] [DynamiX: Dynamic Resource eXploration for Personalized Ad-Recommendations](https://arxiv.org/abs/2511.18331)
*Sohini Roychowdhury,Adam Holeman,Mohammad Amin,Feng Wei,Bhaskar Mehta,Srihari Reddy*

Main category: cs.LG

TL;DR: Dynamix是一个可扩展的个性化序列探索框架，通过最大相关性原则和基于事件特征的自监督学习优化事件历史处理，在保持广告预测准确性的同时显著提升训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 在线广告推荐系统中，处理完整的用户-广告互动历史计算量大且容易受到噪声影响，需要一种更高效的序列处理方法。

Method: 使用最大相关性原则和基于事件特征的自监督学习，在会话和表面级别对用户互动进行分类，通过动态特征移除和选择性特征增强来优化处理。

Result: 动态资源移除使训练和推理吞吐量分别提升1.15%和1.8%，动态特征增强在基线模型基础上提供0.033 NE增益，同时推理QPS提升4.2%。

Conclusion: Dynamix在基于在线用户序列的推荐模型中实现了显著的成本效率和性能改进，自监督用户分段和资源探索可以进一步增强复杂特征选择策略。

Abstract: For online ad-recommendation systems, processing complete user-ad-engagement histories is both computationally intensive and noise-prone. We introduce Dynamix, a scalable, personalized sequence exploration framework that optimizes event history processing using maximum relevance principles and self-supervised learning through Event Based Features (EBFs). Dynamix categorizes users-engagements at session and surface-levels by leveraging correlations between dwell-times and ad-conversion events. This enables targeted, event-level feature removal and selective feature boosting for certain user-segments, thereby yielding training and inference efficiency wins without sacrificing engaging ad-prediction accuracy. While, dynamic resource removal increases training and inference throughput by 1.15% and 1.8%, respectively, dynamic feature boosting provides 0.033 NE gains while boosting inference QPS by 4.2% over baseline models. These results demonstrate that Dynamix achieves significant cost efficiency and performance improvements in online user-sequence based recommendation models. Self-supervised user-segmentation and resource exploration can further boost complex feature selection strategies while optimizing for workflow and compute resources.

</details>


### [103] [Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty](https://arxiv.org/abs/2511.19124)
*Krishang Sharma*

Main category: cs.LG

TL;DR: 提出一种新颖的不确定性感知深度学习框架，用于航空发动机剩余使用寿命预测，通过概率建模直接学习偶然不确定性，在关键区域性能提升25-40%。


<details>
  <summary>Details</summary>
Motivation: 准确预测剩余使用寿命并进行不确定性量化是航空预测领域的关键挑战，现有CMAPSS文献中尚未探索通过概率建模直接学习偶然不确定性的方法。

Method: 分层架构集成多尺度Inception块用于时间模式提取、双向LSTM用于序列建模、传感器和时间维度双级注意力机制，以及贝叶斯输出层同时预测RUL均值和方差。

Result: 在NASA CMAPSS基准测试中取得竞争性整体性能（RMSE：16.22-19.98），关键区域性能突破（RMSE：5.14-7.16），比传统方法提升25-40%，95%置信区间覆盖率达93.5%-95.2%。

Conclusion: 该框架在安全关键预测方面建立了新基准，通过学习的概率不确定性实现了以前CMAPSS文献中无法达到的风险感知维护调度。

Abstract: Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.

</details>


### [104] [Local Entropy Search over Descent Sequences for Bayesian Optimization](https://arxiv.org/abs/2511.19241)
*David Stenger,Armin Lindicke,Alexander von Rohr,Sebastian Trimpe*

Main category: cs.LG

TL;DR: 本文提出了局部熵搜索（LES）方法，这是一种贝叶斯优化范式，专门针对迭代优化器的下降序列可达解进行搜索。该方法通过传播目标函数的后验信念，生成下降序列的概率分布，并通过最大化与该分布的互信息来选择下一个评估点。


<details>
  <summary>Details</summary>
Motivation: 在大型复杂设计空间中搜索全局最优解通常不可行且不必要。一个实用的替代方案是使用局部优化方法（如梯度下降）迭代细化初始设计的邻域。

Method: LES算法通过优化器传播目标函数的后验信念，生成下降序列的概率分布。然后通过分析熵计算和下降序列的蒙特卡洛采样相结合，最大化与该分布的互信息来选择下一个评估点。

Result: 在高复杂度合成目标和基准问题上的实证结果表明，与现有的局部和全局贝叶斯优化方法相比，LES实现了强大的样本效率。

Conclusion: 局部熵搜索方法能够有效针对迭代优化器的下降序列进行优化，在复杂设计空间中表现出优异的样本效率。

Abstract: Searching large and complex design spaces for a global optimum can be infeasible and unnecessary. A practical alternative is to iteratively refine the neighborhood of an initial design using local optimization methods such as gradient descent. We propose local entropy search (LES), a Bayesian optimization paradigm that explicitly targets the solutions reachable by the descent sequences of iterative optimizers. The algorithm propagates the posterior belief over the objective through the optimizer, resulting in a probability distribution over descent sequences. It then selects the next evaluation by maximizing mutual information with that distribution, using a combination of analytic entropy calculations and Monte-Carlo sampling of descent sequences. Empirical results on high-complexity synthetic objectives and benchmark problems show that LES achieves strong sample efficiency compared to existing local and global Bayesian optimization methods.

</details>


### [105] [Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary Gene Selection](https://arxiv.org/abs/2511.18336)
*Kaito Shiku,Kazuya Nishimura,Shinnosuke Matsuo,Yasuhiro Kojima,Ryoma Bise*

Main category: cs.LG

TL;DR: 本文提出AGL方法，通过将忽略基因的表达估计重新定义为辅助任务并与主要任务联合训练，利用被忽略基因的益处。为解决辅助基因选择难题，提出DkGSB方法，利用先验知识对基因排序，并将组合选择问题转化为可微分的top-k选择问题。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学(ST)技术能够观察病理组织中单个点的基因表达，但测量过程中常引入大量观测噪声。先前研究仅使用高度可变基因子集进行训练和评估，忽略了其他基因。然而基因间可能存在共表达关系，低表达基因仍可能对评估目标有贡献。

Method: 提出辅助基因学习(AGL)框架，将忽略基因的表达估计作为辅助任务与主要任务联合训练。为解决辅助基因选择难题，提出基于先验知识的可微分top-k基因选择方法(DkGSB)，通过双层优化将组合选择问题转化为可微分问题。

Result: 实验证实了整合辅助基因的有效性，表明所提方法优于传统的辅助任务学习方法。

Conclusion: 通过合理选择辅助基因并将其纳入训练过程，可以显著提升空间转录组学中基因表达预测的性能，DkGSB方法为解决组合优化问题提供了有效途径。

Abstract: Spatial transcriptomics (ST) is a novel technology that enables the observation of gene expression at the resolution of individual spots within pathological tissues. ST quantifies the expression of tens of thousands of genes in a tissue section; however, heavy observational noise is often introduced during measurement. In prior studies, to ensure meaningful assessment, both training and evaluation have been restricted to only a small subset of highly variable genes, and genes outside this subset have also been excluded from the training process. However, since there are likely co-expression relationships between genes, low-expression genes may still contribute to the estimation of the evaluation target. In this paper, we propose $Auxiliary \ Gene \ Learning$ (AGL) that utilizes the benefit of the ignored genes by reformulating their expression estimation as auxiliary tasks and training them jointly with the primary tasks. To effectively leverage auxiliary genes, we must select a subset of auxiliary genes that positively influence the prediction of the target genes. However, this is a challenging optimization problem due to the vast number of possible combinations. To overcome this challenge, we propose Prior-Knowledge-Based Differentiable Top-$k$ Gene Selection via Bi-level Optimization (DkGSB), a method that ranks genes by leveraging prior knowledge and relaxes the combinatorial selection problem into a differentiable top-$k$ selection problem. The experiments confirm the effectiveness of incorporating auxiliary genes and show that the proposed method outperforms conventional auxiliary task learning approaches.

</details>


### [106] [Future Is Unevenly Distributed: Forecasting Ability of LLMs Depends on What We're Asking](https://arxiv.org/abs/2511.18394)
*Chinmay Karkar,Paras Chopra*

Main category: cs.LG

TL;DR: LLMs在不同领域的预测能力存在显著差异，受问题类型、提示框架和外部知识影响，预测性能高度依赖提问内容和方式。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在现实世界事件预测中的能力，探索其预测性能如何随领域结构、提示框架和外部知识而变化。

Method: 分析不同模型家族在截止日期后发生的真实世界问题上的表现，研究上下文、问题类型和外部知识对准确性和校准的影响。

Result: LLMs的预测能力高度可变，取决于提问内容和方式，添加事实新闻背景会改变信念形成和失败模式。

Conclusion: LLMs的预测能力不是一致的，而是高度依赖于具体的预测领域、问题框架和知识背景。

Abstract: Large Language Models (LLMs) demonstrate partial forecasting competence across social, political, and economic events. Yet, their predictive ability varies sharply with domain structure and prompt framing. We investigate how forecasting performance varies with different model families on real-world questions about events that happened beyond the model cutoff date. We analyze how context, question type, and external knowledge affect accuracy and calibration, and how adding factual news context modifies belief formation and failure modes. Our results show that forecasting ability is highly variable as it depends on what, and how, we ask.

</details>


### [107] [A Nutrition Multimodal Photoplethysmography Language Model](https://arxiv.org/abs/2511.19260)
*Kyle Verrier,Achille Nazaret,Joseph Futoma,Andrew C. Miller,Guillermo Sapiro*

Main category: cs.LG

TL;DR: 提出了一个营养光电容积描记语言模型（NPLM），通过整合可穿戴设备的连续光电容积描记（PPG）数据和餐食描述，改善了日常热量摄入预测。


<details>
  <summary>Details</summary>
Motivation: 饥饿和饱腹感动态影响饮食行为和代谢健康，但在日常环境中难以捕捉。需要开发非侵入性的大规模饮食监测方法。

Method: 开发NPLM模型，将PPG数据投影到语言模型可解释的嵌入中，使模型能够对生理数据和餐食上下文进行联合推理。模型在19,340名参与者和110万个餐食-PPG配对数据上训练。

Result: 与仅使用文本的基线相比，模型将日常热量摄入预测提高了11%，即使去除80%的餐食文本信息，准确性仍能保持。在独立验证研究（n=140）中复现了这些发现。

Conclusion: 整合消费者可穿戴设备的生理测量与餐食信息对于大规模非侵入性饮食监测具有重要价值。

Abstract: Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.

</details>


### [108] [Interpreting GFlowNets for Drug Discovery: Extracting Actionable Insights for Medicinal Chemistry](https://arxiv.org/abs/2511.19264)
*Amirtha Varshini A S,Duminda S. Ranasinghe,Hok Hei Tam*

Main category: cs.LG

TL;DR: 本文提出了一个可解释性框架来分析SynFlowNet（一种基于化学反应和可购买原料的GFlowNet），通过梯度显著性、稀疏自编码器和基序探针揭示其内部化学逻辑。


<details>
  <summary>Details</summary>
Motivation: GFlowNets在分子设计中很有前景，但其内部决策策略不透明，限制了在药物发现中的应用，因为化学家需要清晰可解释的结构设计理由。

Method: 集成三种互补方法：梯度显著性结合反事实扰动识别影响奖励的原子环境；稀疏自编码器揭示与物理化学性质对应的潜在因子；基序探针显示功能基团的显式编码。

Result: 揭示了SynFlowNet内部的化学逻辑，包括原子环境对奖励的影响、物理化学性质的潜在表示以及功能基团的线性可解码性。

Conclusion: 该框架为SynFlowNet提供了可操作和机制性的洞察，支持透明可控的分子设计。

Abstract: Generative Flow Networks, or GFlowNets, offer a promising framework for molecular design, but their internal decision policies remain opaque. This limits adoption in drug discovery, where chemists require clear and interpretable rationales for proposed structures. We present an interpretability framework for SynFlowNet, a GFlowNet trained on documented chemical reactions and purchasable starting materials that generates both molecules and the synthetic routes that produce them. Our approach integrates three complementary components. Gradient based saliency combined with counterfactual perturbations identifies which atomic environments influence reward and how structural edits change molecular outcomes. Sparse autoencoders reveal axis aligned latent factors that correspond to physicochemical properties such as polarity, lipophilicity, and molecular size. Motif probes show that functional groups including aromatic rings and halogens are explicitly encoded and linearly decodable from the internal embeddings. Together, these results expose the chemical logic inside SynFlowNet and provide actionable and mechanistic insight that supports transparent and controllable molecular design.

</details>


### [109] [SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free Continual Test-Time Adaptation](https://arxiv.org/abs/2511.18468)
*Md Akil Raihan Iftee,Mir Sazzat Hossain,Rakibul Hasan Rajib,Tariq Iqbal,Md Mofijul Islam,M Ashraful Amin,Amin Ahsan Ali,AKM Mahbubur Rahman*

Main category: cs.LG

TL;DR: 提出了SloMo-Fast框架，这是一个无源数据的双教师持续测试时适应方法，旨在解决现有方法在隐私敏感和资源受限环境中的局限性，以及长期遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法通常依赖源数据或原型，在隐私敏感和资源受限环境中适用性有限，且存在长期遗忘问题，导致在先前遇到域上的性能下降。

Method: 提出SloMo-Fast框架，包含两个互补的教师模型：Slow-Teacher缓慢遗忘并保留长期知识确保鲁棒泛化，Fast-Teacher快速适应新域并跨域积累知识。同时引入了Cyclic-TTA基准来模拟循环域偏移。

Result: 在Cyclic-TTA和其他十个CTTA设置上的广泛实验表明，SloMo-Fast始终优于最先进方法，突显其在演化和重访域上的适应和泛化能力。

Conclusion: SloMo-Fast框架有效解决了CTTA中的长期遗忘问题，在隐私敏感和资源受限环境中表现出色，能够同时适应新域并保持对先前域的泛化能力。

Abstract: Continual Test-Time Adaptation (CTTA) is crucial for deploying models in real-world applications with unseen, evolving target domains. Existing CTTA methods, however, often rely on source data or prototypes, limiting their applicability in privacy-sensitive and resource-constrained settings. Additionally, these methods suffer from long-term forgetting, which degrades performance on previously encountered domains as target domains shift. To address these challenges, we propose SloMo-Fast, a source-free, dual-teacher CTTA framework designed for enhanced adaptability and generalization. It includes two complementary teachers: the Slow-Teacher, which exhibits slow forgetting and retains long-term knowledge of previously encountered domains to ensure robust generalization, and the Fast-Teacher rapidly adapts to new domains while accumulating and integrating knowledge across them. This framework preserves knowledge of past domains and adapts efficiently to new ones. We also introduce Cyclic Test-Time Adaptation (Cyclic-TTA), a novel CTTA benchmark that simulates recurring domain shifts. Our extensive experiments demonstrate that SloMo-Fast consistently outperforms state-of-the-art methods across Cyclic-TTA, as well as ten other CTTA settings, highlighting its ability to both adapt and generalize across evolving and revisited domains.

</details>


### [110] [Open-weight genome language model safeguards: Assessing robustness via adversarial fine-tuning](https://arxiv.org/abs/2511.19299)
*James R. M. Black,Moritz S. Hanke,Aaron Maiwald,Tina Hernandez-Boussard,Oliver M. Crook,Jaspreet Pannu*

Main category: cs.LG

TL;DR: 该研究评估了基因组语言模型（gLM）在微调后恢复有害病毒预测能力的安全风险，发现即使预训练时排除病毒数据，通过微调仍能恢复模型对有害人类感染病毒的预测能力。


<details>
  <summary>Details</summary>
Motivation: 基因组语言模型在生物数据上的应用引发了滥用担忧，特别是生成人类感染病毒基因组的能力。当前主要通过在预训练数据中过滤病毒序列来降低风险，但这种方法对开源模型微调的鲁棒性未知。

Method: 使用最先进的gLM模型Evo 2，在110种有害人类感染病毒的序列上进行微调，评估其恢复滥用相关预测能力的效果，并与在噬菌体序列上微调的版本进行对比。

Result: 微调后的模型在未见病毒序列上的困惑度降低，能够识别SARS-CoV-2的免疫逃逸变体（AUROC为0.6），尽管微调过程中未接触SARS-CoV-2序列。

Conclusion: 数据排除策略可能被微调方法规避，gLM需要更完善的安全框架、评估和缓解措施来确保安全部署。

Abstract: Novel deep learning architectures are increasingly being applied to biological data, including genetic sequences. These models, referred to as genomic language mod- els (gLMs), have demonstrated impressive predictive and generative capabilities, raising concerns that such models may also enable misuse, for instance via the generation of genomes for human-infecting viruses. These concerns have catalyzed calls for risk mitigation measures. The de facto mitigation of choice is filtering of pretraining data (i.e., removing viral genomic sequences from training datasets) in order to limit gLM performance on virus-related tasks. However, it is not currently known how robust this approach is for securing open-source models that can be fine-tuned using sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and perform fine-tuning using sequences from 110 harmful human-infecting viruses to assess the rescue of misuse-relevant predictive capabilities. The fine- tuned model exhibited reduced perplexity on unseen viral sequences relative to 1) the pretrained model and 2) a version fine-tuned on bacteriophage sequences. The model fine-tuned on human-infecting viruses also identified immune escape variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo- sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that data exclusion might be circumvented by fine-tuning approaches that can, to some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need for safety frameworks for gLMs and outline further work needed on evaluations and mitigation measures to enable the safe deployment of gLMs.

</details>


### [111] [Leveraging LLMs for reward function design in reinforcement learning control tasks](https://arxiv.org/abs/2511.19355)
*Franklin Cardenoso,Wouter Caarls*

Main category: cs.LG

TL;DR: LEARN-Opt是一个基于大语言模型的完全自主、模型无关的框架，用于从系统描述和任务目标自动生成、执行和评估奖励函数，无需预定义指标或环境源代码。


<details>
  <summary>Details</summary>
Motivation: 强化学习中设计有效奖励函数是一个重大瓶颈，需要大量人工专业知识且耗时。现有方法通常需要预定义评估指标、人工反馈或环境源代码作为上下文。

Method: 引入LEARN-Opt框架，能够直接从系统描述和任务目标自主推导性能指标，实现无监督的奖励函数评估和选择。

Result: 实验表明LEARN-Opt性能与最先进方法（如EUREKA）相当或更好，同时需要更少先验知识。自动化奖励设计是高方差问题，需要多次运行寻找最佳候选。

Conclusion: LEARN-Opt能够利用低成本LLMs找到与大型模型相当甚至更好的高性能奖励函数，无需任何预定义人工指标，减少工程开销并增强泛化能力。

Abstract: The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.

</details>


### [112] [Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme](https://arxiv.org/abs/2511.19390)
*Rudy Morel,Francesco Pio Ramunno,Jeff Shen,Alberto Bietti,Kyunghyun Cho,Miles Cranmer,Siavash Golkar,Olexandr Gugnin,Geraud Krawezik,Tanya Marwah,Michael McCabe,Lucas Meyer,Payel Mukhopadhyay,Ruben Ohana,Liam Parker,Helen Qu,François Rozet,K. D. Leka,François Lanusse,David Fouhey,Shirley Ho*

Main category: cs.LG

TL;DR: 本文提出了一种用于扩散模型的多尺度推理方案，专门针对部分可观测、长记忆动力系统的概率预测问题，特别是在太阳动力学和活动区演化等应用中。


<details>
  <summary>Details</summary>
Motivation: 在许多动态系统预测场景中，可用信息只占预测未来状态所需信息的一小部分，要么由于测量不确定性，要么因为只能观测到状态的一小部分。例如在太阳物理学中，我们可以观测太阳表面和大气层，但其演化由缺乏直接测量的内部过程驱动。标准推理方案无法有效捕捉数据中的长程依赖关系。

Method: 提出了一种多尺度推理方案，生成在时间上靠近当前时刻时粒度较细、远离当前时刻时粒度较粗的轨迹，这样可以在不增加计算成本的情况下捕捉长程时间依赖关系。

Result: 当集成到扩散模型中时，该推理方案显著减少了预测分布的偏差，并提高了展开稳定性。

Conclusion: 多尺度推理方案能够有效解决部分可观测、长记忆动力系统的概率预测问题，特别是在捕捉长程时间依赖关系方面表现出色。

Abstract: Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.

</details>


### [113] [UniGame: Turning a Unified Multimodal Model Into Its Own Adversary](https://arxiv.org/abs/2511.19413)
*Zhaolong Su,Wang Lu,Hao Chen,Sharon Li,Jindong Wang*

Main category: cs.LG

TL;DR: UniGame是一个自对抗后训练框架，通过轻量级扰动器解决统一多模态模型中理解与生成之间的不一致性问题，显著提升模型一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型在理解和生成之间存在根本性不一致：理解偏好紧凑嵌入，而生成偏好重建丰富的表示，这种结构权衡导致决策边界错位、跨模态连贯性下降以及对分布和对抗性变化的脆弱性。

Method: UniGame在共享令牌接口应用轻量级扰动器，使生成分支能够主动寻找和挑战脆弱的理解，将模型自身转化为对抗者。

Result: UniGame显著提升一致性(+4.6%)、理解能力(+3.6%)、生成质量(+0.02)，并在自然分布和对抗性鲁棒性上分别提升4.8%和6.2%。该框架架构无关，仅增加不到1%的参数，与现有后训练方法互补。

Conclusion: 对抗性自博弈是增强未来多模态基础模型连贯性、稳定性和统一能力的通用有效原则。

Abstract: Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame

</details>


### [114] [CHIPS: Efficient CLIP Adaptation via Curvature-aware Hybrid Influence-based Data Selection](https://arxiv.org/abs/2511.18519)
*Xinlin Zhuang,Yichen Li,Xiwei Liu,Haolin Yang,Yifan Lu,Ziyun Zou,Yulong Li,Huifa Li,Dongliang Chen,Qinglei Wang,Weiyang Liu,Ying Qian,Jiangming Shi,Imran Razzak*

Main category: cs.LG

TL;DR: CHIPS是一种从数据角度出发的CLIP垂直领域适应方法，通过计算图像-文本对的效用分数来选择数据，能够在仅使用30%数据时达到全数据集持续预训练的性能，在10%数据时优于50%数据的训练。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP垂直领域适应方法主要关注微调策略或大规模领域特定数据的持续预训练，但数据本身作为关键因素被忽视。本文从数据中心的视角重新审视该任务，探索是否可以通过有效的数据选择替代大规模数据集。

Method: 提出CHIPS方法，为每个图像-文本对分配效用分数，整合三个互补因素：通过曲率感知的牛顿式对齐确保忠实性；通过InfoNCE感知的曲率估计器和JL投影确保可扩展性；通过选择感知的相关性权重和可学习性平衡目标适应与通用领域保留。

Result: 在17个医学基准测试中，CHIPS在数据选择基线中达到最先进性能，仅用30%数据即可匹配全数据集持续预训练，仅用10%数据优于50%数据训练；在31个通用领域基准测试中，在10-30%数据保留预算下性能下降最小。

Conclusion: CHIPS证明了有效数据选择可以替代大规模数据集进行持续预训练，为CLIP垂直领域适应提供了高效的数据中心解决方案。

Abstract: Adapting CLIP to vertical domains is typically approached by novel fine-tuning strategies or by continual pre-training (CPT) on large domain-specific datasets. Yet, data itself remains an underexplored factor in this process. We revisit this task from a data-centric perspective: Can effective data selection substitute for large-scale datasets in CPT? We introduce CHIPS (Curvature-aware Hybrid Influence in Projection Subspace), which assigns each image-text pair a utility score that integrates three complementary factors aligned with three goals: faithfulness via a curvature-aware, Newton-style alignment computed in CLIP's end-point subspace; scalability via an InfoNCE-aware curvature estimator with Johnson-Lindenstrauss (JL) sketching; and retention via a selection-aware relevance weight combined with learnability to balance target adaptation against general-domain preservation. We justify this design theoretically by proving a lower-bound guarantee on the proxy's correlation with full-parameter alignment and by characterizing the bias-variance trade-offs introduced by curvature mixing and JL sketching. We evaluate CHIPS empirically across various settings: 1) CHIPS attains state-of-the-art performance among selection baselines on 17 medical benchmarks, matches full-dataset CPT with 30% of the data, and outperforms half-dataset CPT using only 10%; 2) on 31 general-domain benchmarks, CHIPS yields the smallest performance drop under 10-30% data-retention budgets. Code, data, and checkpoints will be released.

</details>


### [115] [Hyperspectral Variational Autoencoders for Joint Data Compression and Component Extraction](https://arxiv.org/abs/2511.18521)
*Core Francisco Park,Manuel Perez-Carrasco,Caroline Nowlan,Cecilia Garraffo*

Main category: cs.LG

TL;DR: 提出一种变分自编码器方法，对NASA TEMPO卫星高光谱数据进行514倍压缩，重建误差比信号低1-2个数量级，同时保留关键大气信息。


<details>
  <summary>Details</summary>
Motivation: 解决地球静止轨道高光谱卫星每日产生TB级数据带来的存储、传输和分发挑战。

Method: 使用变分自编码器(VAE)对1028个通道的高光谱观测数据进行压缩，并通过线性和非线性探针评估压缩后潜在空间中的大气信息保留程度。

Result: 实现514倍压缩，重建误差远低于信号水平；云分数和总臭氧提取性能优异(R²=0.93和0.81)，但对流层痕量气体提取面临挑战(NO₂ R²=0.20，HCHO R²=0.51)。

Conclusion: 神经压缩能显著减少高光谱数据量，同时保留关键大气信号，为下一代地球观测系统解决关键瓶颈问题。

Abstract: Geostationary hyperspectral satellites generate terabytes of data daily, creating critical challenges for storage, transmission, and distribution to the scientific community. We present a variational autoencoder (VAE) approach that achieves x514 compression of NASA's TEMPO satellite hyperspectral observations (1028 channels, 290-490nm) with reconstruction errors 1-2 orders of magnitude below the signal across all wavelengths. This dramatic data volume reduction enables efficient archival and sharing of satellite observations while preserving spectral fidelity. Beyond compression, we investigate to what extent atmospheric information is retained in the compressed latent space by training linear and nonlinear probes to extract Level-2 products (NO2, O3, HCHO, cloud fraction). Cloud fraction and total ozone achieve strong extraction performance (R^2 = 0.93 and 0.81 respectively), though these represent relatively straightforward retrievals given their distinct spectral signatures. In contrast, tropospheric trace gases pose genuine challenges for extraction (NO2 R^2 = 0.20, HCHO R^2 = 0.51) reflecting their weaker signals and complex atmospheric interactions. Critically, we find the VAE encodes atmospheric information in a semi-linear manner - nonlinear probes substantially outperform linear ones - and that explicit latent supervision during training provides minimal improvement, revealing fundamental encoding challenges for certain products. This work demonstrates that neural compression can dramatically reduce hyperspectral data volumes while preserving key atmospheric signals, addressing a critical bottleneck for next-generation Earth observation systems. Code - https://github.com/cfpark00/Hyperspectral-VAE

</details>


### [116] [In Search of Goodness: Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorithm](https://arxiv.org/abs/2511.18567)
*Arya Shah,Vaibhav Tripathi*

Main category: cs.LG

TL;DR: 本文评估了21种不同的goodness函数在Forward-Forward算法中的表现，发现在多个图像数据集上某些替代函数显著优于标准基线，同时揭示了预测性能与计算效率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: Forward-Forward算法依赖于goodness函数来衡量神经活动，但当前主要使用简单的平方和度量，不清楚这是否是最优选择。

Method: 在四个标准图像数据集（MNIST、FashionMNIST、CIFAR-10、STL-10）上对21种不同的goodness函数进行基准测试，评估分类准确率、能耗和碳足迹。

Result: 发现某些替代goodness函数表现优异：game_theoretic_local在MNIST上达到97.15%准确率，softmax_energy_margin_local在FashionMNIST上达到82.84%，triplet_margin_local在STL-10上达到37.69%。计算效率存在显著差异。

Conclusion: goodness函数是FF算法设计中的关键超参数，需要在预测性能和环境影响之间进行权衡。

Abstract: The Forward-Forward (FF) algorithm offers a biologically plausible alternative to backpropagation, enabling neural networks to learn through local updates. However, FF's efficacy relies heavily on the definition of "goodness", which is a scalar measure of neural activity. While current implementations predominantly utilize a simple sum-of-squares metric, it remains unclear if this default choice is optimal. To address this, we benchmarked 21 distinct goodness functions across four standard image datasets (MNIST, FashionMNIST, CIFAR-10, STL-10), evaluating classification accuracy, energy consumption, and carbon footprint. We found that certain alternative goodness functions inspired from various domains significantly outperform the standard baseline. Specifically, \texttt{game\_theoretic\_local} achieved 97.15\% accuracy on MNIST, \texttt{softmax\_energy\_margin\_local} reached 82.84\% on FashionMNIST, and \texttt{triplet\_margin\_local} attained 37.69\% on STL-10. Furthermore, we observed substantial variability in computational efficiency, highlighting a critical trade-off between predictive performance and environmental cost. These findings demonstrate that the goodness function is a pivotal hyperparameter in FF design. We release our code on \href{https://github.com/aryashah2k/In-Search-of-Goodness}{Github} for reference and reproducibility.

</details>


### [117] [SAMBA: Toward a Long-Context EEG Foundation Model via Spatial Embedding and Differential Mamba](https://arxiv.org/abs/2511.18571)
*Jiazhen Hong,Geoffrey Mackellar,Soheila Ghane*

Main category: cs.LG

TL;DR: SAMBA是一个基于Mamba的自监督学习框架，用于长序列EEG建模，通过U形编码器-解码器架构有效捕捉EEG数据中的长程时间依赖和空间变异性，在13个EEG数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: EEG数据采样率高、记录时间长，需要建模长序列；Transformer模型在处理短序列时表现良好但二次复杂度限制了长上下文扩展；电极配置差异和受试者间信号变异性对开发通用基础模型构成挑战。

Method: 提出SAMBA框架，包含：1）时间语义随机掩码用于语义级序列重建；2）多头差分Mamba模块抑制冗余并突出显著时间结构；3）空间自适应输入嵌入在三维欧几里得空间中学习统一嵌入以实现跨设备鲁棒性。

Result: 在13个EEG数据集上的实验表明，SAMBA在多种任务、电极配置和序列持续时间下始终优于最先进方法，同时保持低内存消耗和推理时间；学习到的空间权重图与任务相关神经生理区域高度一致。

Conclusion: SAMBA展示了作为实时脑机接口应用基础模型的可扩展性和实际潜力，其嵌入模块具有可学习性和可解释性。

Abstract: Long-sequence electroencephalogram (EEG) modeling is essential for developing generalizable EEG representation models. This need arises from the high sampling rate of EEG data and the long recording durations required to capture extended neurological patterns in brain activity. Transformer-based models have shown promise in modeling short sequences of a few seconds; however, their quadratic complexity limits scalability to longer contexts. Moreover, variability in electrode montage across available datasets, along with inter-subject differences in brain signals, pose significant challenges to developing a generalizable and robust foundation model. We propose \textit{SAMBA}, a self-supervised learning framework with a Mamba-based U-shaped encoder-decoder architecture, which effectively captures long-range temporal dependencies and spatial variability in EEG data. Leveraging the inherent ability of Mamba in processing long context sizes, we introduce: (1) \textit{Temporal Semantic Random Masking} for semantic-level sequence reconstruction, (2) a \textit{Multi-Head Differential Mamba} module to suppress redundancy and emphasize salient temporal structures, and (3) a \textit{Spatial-Adaptive Input Embedding} that learns unified embeddings in a three-dimensional Euclidean space, enabling robustness across devices. Experiments on thirteen EEG datasets across diverse tasks, electrode configurations, and sequence durations demonstrate that SAMBA consistently outperforms state-of-the-art methods while maintaining low memory consumption and inference time. We also show the learned spatial weight maps from our embedding module align closely with task-relevant neurophysiological regions, demonstrating the learnability and interpretability of SAMBA. These results highlight SAMBA's scalability and practical potential as a foundation model for real-time brain-computer interface applications.

</details>


### [118] [Generative Myopia: Why Diffusion Models Fail at Structure](https://arxiv.org/abs/2511.18593)
*Milad Siami*

Main category: cs.LG

TL;DR: 图扩散模型在优化统计似然时存在生成性近视问题，倾向于保留频繁子结构而忽略光谱关键结构，导致在组合任务中灾难性地移除稀有但结构必需的桥梁边。


<details>
  <summary>Details</summary>
Motivation: 解决图扩散模型在组合任务中因优化统计似然而导致的生成性近视问题，特别是对稀有但结构关键边的识别和保留失败。

Method: 提出光谱加权扩散方法，使用有效电阻重新对齐变分目标，将光谱先验摊销到训练阶段而不增加推理开销。

Result: 该方法消除了近视问题，与最优光谱预言机性能匹配，在标准扩散完全失败（0%）的对抗性基准测试中实现了100%的连通性。

Conclusion: 光谱先验可以有效地整合到图扩散模型的训练中，解决梯度饥饿问题，确保对稀有但结构关键边的正确识别和保留。

Abstract: Graph Diffusion Models (GDMs) optimize for statistical likelihood, implicitly acting as \textbf{frequency filters} that favor abundant substructures over spectrally critical ones. We term this phenomenon \textbf{Generative Myopia}. In combinatorial tasks like graph sparsification, this leads to the catastrophic removal of ``rare bridges,'' edges that are structurally mandatory ($R_{\text{eff}} \approx 1$) but statistically scarce. We prove theoretically and empirically that this failure is driven by \textbf{Gradient Starvation}: the optimization landscape itself suppresses rare structural signals, rendering them unlearnable regardless of model capacity. To resolve this, we introduce \textbf{Spectrally-Weighted Diffusion}, which re-aligns the variational objective using Effective Resistance. We demonstrate that spectral priors can be amortized into the training phase with zero inference overhead. Our method eliminates myopia, matching the performance of an optimal Spectral Oracle and achieving \textbf{100\% connectivity} on adversarial benchmarks where standard diffusion fails completely (0\%).

</details>


### [119] [CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning](https://arxiv.org/abs/2511.18611)
*Mengdi Wang,Efe Bozkir,Enkelejda Kasneci*

Main category: cs.LG

TL;DR: CycleSL是一个新颖的无聚合分割学习框架，通过将服务器端训练视为独立的高级机器学习任务，采用循环更新机制来提升可扩展性和模型性能，解决了传统分割学习中的客户端漂移和服务器资源开销问题。


<details>
  <summary>Details</summary>
Motivation: 传统分割学习存在可扩展性差、服务器资源开销大、模型性能下降等问题，特别是并行变体中的模型复制和聚合导致高开销，客户端漂移和滞后影响收敛性能。

Method: CycleSL采用交替块坐标下降思想，将服务器端训练作为独立任务，重新采样客户端提取的特征来缓解异构性和漂移，执行循环更新：先优化服务器模型，然后使用更新后的服务器进行客户端梯度计算。

Result: 在五个公开数据集上的实验表明，CycleSL能够有效提升模型性能，特别是在非独立同分布数据和部分客户端参与的场景下。

Conclusion: CycleSL是一个有效的无聚合分割学习框架，能够显著提升模型性能和可扩展性，并且可以与现有方法无缝集成。

Abstract: Split learning emerges as a promising paradigm for collaborative distributed model training, akin to federated learning, by partitioning neural networks between clients and a server without raw data exchange. However, sequential split learning suffers from poor scalability, while parallel variants like parallel split learning and split federated learning often incur high server resource overhead due to model duplication and aggregation, and generally exhibit reduced model performance and convergence owing to factors like client drift and lag. To address these limitations, we introduce CycleSL, a novel aggregation-free split learning framework that enhances scalability and performance and can be seamlessly integrated with existing methods. Inspired by alternating block coordinate descent, CycleSL treats server-side training as an independent higher-level machine learning task, resampling client-extracted features (smashed data) to mitigate heterogeneity and drift. It then performs cyclical updates, namely optimizing the server model first, followed by client updates using the updated server for gradient computation. We integrate CycleSL into previous algorithms and benchmark them on five publicly available datasets with non-iid data distribution and partial client attendance. Our empirical findings highlight the effectiveness of CycleSL in enhancing model performance. Our source code is available at https://gitlab.lrz.de/hctl/CycleSL.

</details>


### [120] [Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet Priors](https://arxiv.org/abs/2511.18615)
*Jiawei Hu,Javier A. Barria*

Main category: cs.LG

TL;DR: 提出了FMAPLS和online-FMAPLS两种贝叶斯框架来解决标签偏移问题，通过联合优化Dirichlet超参数和类先验，在CIFAR100和ImageNet数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 标签偏移是监督学习中常见的问题，当测试数据的类别先验分布与训练数据不同时，会导致分类器性能显著下降。现有方法存在刚性约束，需要更灵活有效的解决方案。

Method: 提出了FMAPLS和在线版本online-FMAPLS，利用批处理和在线EM算法联合优化Dirichlet超参数α和类先验π，引入线性替代函数简化计算复杂度，同时保持渐近等价性。

Result: 在CIFAR100和ImageNet数据集上的实验表明，FMAPLS和online-FMAPLS分别实现了高达40%和12%的KL散度降低，并在后偏移准确率上显著优于现有基线方法，特别是在严重类别不平衡和分布不确定性情况下。

Conclusion: 所提出的方法具有鲁棒性、可扩展性，适用于大规模和动态学习场景，能够有效处理标签偏移问题。

Abstract: Label shift, a prevalent challenge in supervised learning, arises when the class prior distribution of test data differs from that of training data, leading to significant degradation in classifier performance. To accurately estimate the test priors and enhance classification accuracy, we propose a Bayesian framework for label shift estimation, termed Full Maximum A Posterior Label Shift (FMAPLS), along with its online version, online-FMAPLS. Leveraging batch and online Expectation-Maximization (EM) algorithms, these methods jointly and dynamically optimize Dirichlet hyperparameters $\boldsymbolα$ and class priors $\boldsymbolπ$, thereby overcoming the rigid constraints of the existing Maximum A Posterior Label Shift (MAPLS) approach. Moreover, we introduce a linear surrogate function (LSF) to replace gradient-based hyperparameter updates, yielding closed-form solutions that reduce computational complexity while retaining asymptotic equivalence. The online variant substitutes the batch E-step with a stochastic approximation, enabling real-time adaptation to streaming data. Furthermore, our theoretical analysis reveals a fundamental trade-off between online convergence rate and estimation accuracy. Extensive experiments on CIFAR100 and ImageNet datasets under shuffled long-tail and Dirichlet test priors demonstrate that FMAPLS and online-FMAPLS respectively achieve up to 40% and 12% lower KL divergence and substantial improvements in post-shift accuracy over state-of-the-art baselines, particularly under severe class imbalance and distributional uncertainty. These results confirm the robustness, scalability, and suitability of the proposed methods for large-scale and dynamic learning scenarios.

</details>


### [121] [FOS: A Large-Scale Temporal Graph Benchmark for Scientific Interdisciplinary Link Prediction](https://arxiv.org/abs/2511.18631)
*Kiyan Rezaee,Morteza Ziabakhsh,Niloofar Nikfarjam,Mohammad M. Ghassemi,Yazdan Rezaee Jouryabi,Sadegh Eskandari,Reza Lashgari*

Main category: cs.LG

TL;DR: FOS是一个时间感知的图基准，用于预测科学研究领域的首次跨学科连接，通过分析1827-2024年间65,027个子领域的共现关系来预测科学前沿。


<details>
  <summary>Details</summary>
Motivation: 跨学科科学突破通常意外出现，预测新研究领域的形成仍是一个重大挑战。需要建立一个可重现的基准来推进科学前沿预测研究。

Method: 构建年度共现图，节点为研究子领域并包含语义嵌入，边表示两个领域在同一出版物中的共现关系并带有时间戳。将新领域对连接的预测建模为时间链接预测任务。

Result: 实验表明：(i) 使用领域的长文本描述嵌入能显著提高预测准确性；(ii) 不同模型类在不同评估设置下表现优异；(iii) 案例分析显示FOS的顶级链接预测与后续年份出现的学术出版物中的领域配对一致。

Conclusion: FOS基准为预测科学前沿提供了可重现的评估框架，证明了语义嵌入和时间图模型在预测跨学科科学突破方面的有效性。

Abstract: Interdisciplinary scientific breakthroughs mostly emerge unexpectedly, and forecasting the formation of novel research fields remains a major challenge. We introduce FOS (Future Of Science), a comprehensive time-aware graph-based benchmark that reconstructs annual co-occurrence graphs of 65,027 research sub-fields (spanning 19 general domains) over the period 1827-2024. In these graphs, edges denote the co-occurrence of two fields in a single publication and are timestamped with the corresponding publication year. Nodes are enriched with semantic embeddings, and edges are characterized by temporal and topological descriptors. We formulate the prediction of new field-pair linkages as a temporal link-prediction task, emphasizing the "first-time" connections that signify pioneering interdisciplinary directions. Through extensive experiments, we evaluate a suite of state-of-the-art temporal graph architectures under multiple negative-sampling regimes and show that (i) embedding long-form textual descriptions of fields significantly boosts prediction accuracy, and (ii) distinct model classes excel under different evaluation settings. Case analyses show that top-ranked link predictions on FOS align with field pairings that emerge in subsequent years of academic publications. We publicly release FOS, along with its temporal data splits and evaluation code, to establish a reproducible benchmark for advancing research in predicting scientific frontiers.

</details>


### [122] [Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition](https://arxiv.org/abs/2511.18671)
*Yan Wang,Ke Deng,Yongli Ren*

Main category: cs.LG

TL;DR: 本文提出MCEM方法结合非线性评论家分解，通过排除次优行为来解决多智能体强化学习中的集中-分散不匹配问题，在连续和离散动作基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习中集中训练与分散执行(CTDE)范式下的集中-分散不匹配(CDM)问题，即一个智能体的次优行为会降低其他智能体的学习效果。

Method: 提出多智能体交叉熵方法(MCEM)结合单调非线性评论家分解(NCD)，通过增加高价值联合动作的概率来排除次优行为，并扩展了离策略学习，使用改进的k步回报和Retrace技术提高样本效率。

Result: 分析和实验表明，MCEM在连续和离散动作基准测试中优于最先进的方法。

Conclusion: MCEM方法成功克服了线性分解表达能力有限和非线性分解需要集中梯度的问题，有效解决了CDM问题，在多智能体强化学习中表现出优越性能。

Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others' learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified k-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.

</details>


### [123] [GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction](https://arxiv.org/abs/2511.18716)
*Zesheng Liu,Maryam Rahnemoonfar*

Main category: cs.LG

TL;DR: GRIT-LP是一种专门用于极地雷达图像冰层厚度估计的图变换器，通过分区空间图构建策略和长程跳跃连接机制，解决了深度图变换器的过平滑和长程依赖建模问题，在RMSE指标上比现有最优方法提升了24.92%。


<details>
  <summary>Details</summary>
Motivation: 准确估计冰层厚度对于理解积雪积累、重建过去气候模式以及减少未来冰盖演化和海平面上升预测的不确定性至关重要。现有图变换器在深度建模时面临过平滑和弱长程依赖建模的挑战。

Method: GRIT-LP结合归纳几何图学习和自注意力机制，采用分区空间图构建策略形成重叠的完全连接局部邻域以保持空间一致性并抑制无关长程链接的噪声，同时在变换器中引入长程跳跃连接机制改善信息流并减轻深层注意力层的过平滑问题。

Result: 实验表明GRIT-LP在均方根误差指标上比当前最优方法提升了24.92%，显著优于现有方法。

Conclusion: GRIT-LP通过同时捕捉局部结构特征和跨冰层内部的长程依赖关系，有效建模了时空模式，展示了图变换器在推进冰冻圈过程数据驱动理解方面的潜力。

Abstract: Graph transformers have demonstrated remarkable capability on complex spatio-temporal tasks, yet their depth is often limited by oversmoothing and weak long-range dependency modeling. To address these challenges, we introduce GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness estimation from polar radar imagery. Accurately estimating ice layer thickness is critical for understanding snow accumulation, reconstructing past climate patterns and reducing uncertainties in projections of future ice sheet evolution and sea level rise. GRIT-LP combines an inductive geometric graph learning framework with self-attention mechanism, and introduces two major innovations that jointly address challenges in modeling the spatio-temporal patterns of ice layers: a partitioned spatial graph construction strategy that forms overlapping, fully connected local neighborhoods to preserve spatial coherence and suppress noise from irrelevant long-range links, and a long-range skip connection mechanism within the transformer that improves information flow and mitigates oversmoothing in deeper attention layers. We conducted extensive experiments, demonstrating that GRIT-LP outperforms current state-of-the-art methods with a 24.92\% improvement in root mean squared error. These results highlight the effectiveness of graph transformers in modeling spatiotemporal patterns by capturing both localized structural features and long-range dependencies across internal ice layers, and demonstrate their potential to advance data-driven understanding of cryospheric processes.

</details>


### [124] [Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM](https://arxiv.org/abs/2511.18721)
*Adarsh Kumarappan,Ayushi Mehrotra*

Main category: cs.LG

TL;DR: 本文提出了一个更现实的概率框架(k, ε)-unstable来改进SmoothLLM防御，通过结合攻击成功率的经验模型，提供了更可信和实用的安全认证。


<details>
  <summary>Details</summary>
Motivation: SmoothLLM防御依赖于严格的k-unstable假设，这在实践中很少成立，限制了安全证书的可信度。

Method: 引入(k, ε)-unstable概率框架，结合攻击成功率的经验模型，推导出SmoothLLM防御概率的新下界。

Result: 开发了更可信和实用的安全认证机制，能够为从业者提供可操作的安全保证。

Conclusion: 这项工作为LLM安全部署提供了一个实用且理论基础的机制，使其更能抵抗对其安全对齐的利用。

Abstract: The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.

</details>


### [125] [LogSyn: A Few-Shot LLM Framework for Structured Insight Extraction from Unstructured General Aviation Maintenance Logs](https://arxiv.org/abs/2511.18727)
*Devansh Agarwal,Maitreyi Chatterjee,Biplab Chatterjee*

Main category: cs.LG

TL;DR: LogSyn框架使用大型语言模型将非结构化的飞机维护日志转换为结构化数据，通过少样本学习进行问题-解决叙述的抽象生成和事件分类，以提取可操作的维护见解。


<details>
  <summary>Details</summary>
Motivation: 飞机维护日志包含宝贵的安全数据，但由于其非结构化文本格式而未被充分利用，需要一种方法来提取结构化信息和可操作的见解。

Method: 使用大型语言模型和少样本上下文学习，在6,169条记录上执行受控抽象生成，总结问题-解决叙述并在详细层次本体中分类事件。

Result: 框架能够识别关键故障模式，为维护日志的语义结构化和可操作见解提取提供了可扩展的方法。

Conclusion: 这项工作为改进航空及相关行业的维护工作流程和预测分析提供了实用路径。

Abstract: Aircraft maintenance logs hold valuable safety data but remain underused due to their unstructured text format. This paper introduces LogSyn, a framework that uses Large Language Models (LLMs) to convert these logs into structured, machine-readable data. Using few-shot in-context learning on 6,169 records, LogSyn performs Controlled Abstraction Generation (CAG) to summarize problem-resolution narratives and classify events within a detailed hierarchical ontology. The framework identifies key failure patterns, offering a scalable method for semantic structuring and actionable insight extraction from maintenance logs. This work provides a practical path to improve maintenance workflows and predictive analytics in aviation and related industries.

</details>


### [126] [Reinforcement Learning for Self-Healing Material Systems](https://arxiv.org/abs/2511.18728)
*Maitreyi Chatterjee,Devansh Agarwal,Biplab Chatterjee*

Main category: cs.LG

TL;DR: 本研究将自愈合过程建模为强化学习问题，比较了离散动作和连续动作智能体在材料自愈合控制中的表现，发现TD3智能体在连续剂量控制方面表现最优。


<details>
  <summary>Details</summary>
Motivation: 向自主材料系统过渡需要自适应控制方法来最大化结构寿命，将自愈合过程作为强化学习问题来平衡结构完整性和资源消耗。

Method: 将自愈合过程建模为马尔可夫决策过程，比较离散动作智能体（Q-learning、DQN）和连续动作智能体（TD3）在随机模拟环境中的表现。

Result: 强化学习控制器显著优于启发式基线方法，实现近乎完全的材料恢复。TD3智能体在连续剂量控制方面表现出更快的收敛速度和稳定性。

Conclusion: 连续、比例控制的精细致动在动态自愈合应用中至关重要，TD3智能体在连续剂量控制方面具有优势。

Abstract: The transition to autonomous material systems necessitates adaptive control methodologies to maximize structural longevity. This study frames the self-healing process as a Reinforcement Learning (RL) problem within a Markov Decision Process (MDP), enabling agents to autonomously derive optimal policies that efficiently balance structural integrity maintenance against finite resource consumption. A comparative evaluation of discrete-action (Q-learning, DQN) and continuous-action (TD3) agents in a stochastic simulation environment revealed that RL controllers significantly outperform heuristic baselines, achieving near-complete material recovery. Crucially, the TD3 agent utilizing continuous dosage control demonstrated superior convergence speed and stability, underscoring the necessity of fine-grained, proportional actuation in dynamic self-healing applications.

</details>


### [127] [OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting](https://arxiv.org/abs/2511.18732)
*Haoming Jia,Yi Han,Xiang Wang,Huizan Wang,Wei Wu,Jianming Zheng,Peikun Xiao*

Main category: cs.LG

TL;DR: 本文提出了OceanForecastBench，这是首个用于数据驱动海洋预报的开源标准化基准，包含28年高质量再分析数据、高可靠性观测数据和评估管道，解决了当前缺乏统一基准导致的数据使用不一致和评估方法不统一的问题。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的深度学习海洋预报模型（如XiHe、WenHai等）发展迅速，但缺乏开源标准化基准，导致数据使用和评估方法不一致，阻碍了模型开发、公平性能比较和跨学科合作。

Method: 提出OceanForecastBench基准，提供三个核心贡献：28年高质量全球海洋再分析数据（4个海洋变量×23个深度层次+4个海表变量）、高可靠性卫星和现场观测数据（约1亿个全球海洋位置）、评估管道和包含6个典型基线模型的综合基准。

Result: OceanForecastBench是目前最全面的数据驱动海洋预报基准框架，为模型开发、评估和比较提供了开源平台。数据集和代码已公开可用。

Conclusion: OceanForecastBench填补了数据驱动海洋预报领域缺乏标准化基准的空白，将促进模型高效开发、公平比较和跨学科合作，推动该领域的发展。

Abstract: Global ocean forecasting aims to predict key ocean variables such as temperature, salinity, and currents, which is essential for understanding and describing oceanic phenomena. In recent years, data-driven deep learning-based ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have demonstrated significant potential in capturing complex ocean dynamics and improving forecasting efficiency. Despite these advancements, the absence of open-source, standardized benchmarks has led to inconsistent data usage and evaluation methods. This gap hinders efficient model development, impedes fair performance comparison, and constrains interdisciplinary collaboration. To address this challenge, we propose OceanForecastBench, a benchmark offering three core contributions: (1) A high-quality global ocean reanalysis data over 28 years for model training, including 4 ocean variables across 23 depth levels and 4 sea surface variables. (2) A high-reliability satellite and in-situ observations for model evaluation, covering approximately 100 million locations in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark with 6 typical baseline models, leveraging observations to evaluate model performance from multiple perspectives. OceanForecastBench represents the most comprehensive benchmarking framework currently available for data-driven ocean forecasting, offering an open-source platform for model development, evaluation, and comparison. The dataset and code are publicly available at: https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.

</details>


### [128] [Sampling Control for Imbalanced Calibration in Semi-Supervised Learning](https://arxiv.org/abs/2511.18773)
*Senmao Tian,Xiang Wei,Shunli Zhang*

Main category: cs.LG

TL;DR: SC-SSL是一个统一框架，通过解耦采样控制来抑制半监督学习中的模型偏差，解决类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理类别不平衡时往往将数据不平衡与类别特定学习难度引起的偏差混为一谈，需要更细粒度的解决方案。

Method: 提出SC-SSL框架，通过识别采样控制的关键变量，引入具有显式扩展能力的分类器，并自适应调整不同数据分布的采样概率。在推理阶段分析线性分类器的权重不平衡，应用后处理采样控制。

Result: 在多个基准数据集和分布设置下的广泛实验验证了SC-SSL的一致性和最先进性能。

Conclusion: SC-SSL通过解耦采样控制有效缓解了半监督学习中的类别不平衡问题，实现了优异的性能表现。

Abstract: Class imbalance remains a critical challenge in semi-supervised learning (SSL), especially when distributional mismatches between labeled and unlabeled data lead to biased classification. Although existing methods address this issue by adjusting logits based on the estimated class distribution of unlabeled data, they often handle model imbalance in a coarse-grained manner, conflating data imbalance with bias arising from varying class-specific learning difficulties. To address this issue, we propose a unified framework, SC-SSL, which suppresses model bias through decoupled sampling control. During training, we identify the key variables for sampling control under ideal conditions. By introducing a classifier with explicit expansion capability and adaptively adjusting sampling probabilities across different data distributions, SC-SSL mitigates feature-level imbalance for minority classes. In the inference phase, we further analyze the weight imbalance of the linear classifier and apply post-hoc sampling control with an optimization bias vector to directly calibrate the logits. Extensive experiments across various benchmark datasets and distribution settings validate the consistency and state-of-the-art performance of SC-SSL.

</details>


### [129] [SAOT: An Enhanced Locality-Aware Spectral Transformer for Solving PDEs](https://arxiv.org/abs/2511.18777)
*Chenhong Zhou,Jie Chen,Zaifeng Yang*

Main category: cs.LG

TL;DR: 本文提出了一种结合小波变换空间-频率局部化特性的新型Wavelet Attention模块和Spectral Attention Operator Transformer框架，有效解决了Fourier Neural Operator在求解偏微分方程时过度平滑和无法捕捉局部细节的问题。


<details>
  <summary>Details</summary>
Motivation: Fourier Neural Operator在求解偏微分方程时存在过度平滑解、无法捕捉局部细节和高频分量的局限性，需要改进以更好地处理空间局部特征。

Method: 提出Wavelet Attention模块，利用小波变换的空间-频率局部化特性，具有线性计算复杂度；进一步开发Spectral Attention Operator Transformer混合谱Transformer框架，通过门控融合块将WA的局部关注与Fourier-based Attention的全局感受野相结合。

Result: 实验结果表明，WA显著缓解了FA的局限性，大幅优于现有基于小波的神经算子。SAOT在六个算子学习基准测试中达到最先进性能，并表现出强大的离散化不变能力。

Conclusion: 通过整合局部感知和全局谱表示，SAOT框架在偏微分方程算子学习任务中取得了优异性能，为神经算子提供了更有效的空间-频率表示方法。

Abstract: Neural operators have shown great potential in solving a family of Partial Differential Equations (PDEs) by modeling the mappings between input and output functions. Fourier Neural Operator (FNO) implements global convolutions via parameterizing the integral operators in Fourier space. However, it often results in over-smoothing solutions and fails to capture local details and high-frequency components. To address these limitations, we investigate incorporating the spatial-frequency localization property of Wavelet transforms into the Transformer architecture. We propose a novel Wavelet Attention (WA) module with linear computational complexity to efficiently learn locality-aware features. Building upon WA, we further develop the Spectral Attention Operator Transformer (SAOT), a hybrid spectral Transformer framework that integrates WA's localized focus with the global receptive field of Fourier-based Attention (FA) through a gated fusion block. Experimental results demonstrate that WA significantly mitigates the limitations of FA and outperforms existing Wavelet-based neural operators by a large margin. By integrating the locality-aware and global spectral representations, SAOT achieves state-of-the-art performance on six operator learning benchmarks and exhibits strong discretization-invariant ability.

</details>


### [130] [Towards Characterizing Knowledge Distillation of PPG Heart Rate Estimation Models](https://arxiv.org/abs/2511.18829)
*Kanav Arora,Girish Narayanswamy,Shwetak Patel,Richard Li*

Main category: cs.LG

TL;DR: 本文研究了如何将大型预训练PPG模型蒸馏为适合边缘设备实时推理的小型模型，评估了四种蒸馏策略并描述了模型大小与性能之间的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习模型在心率估计任务中表现出色，但要在可穿戴设备上部署这些模型，必须满足严格的内存和延迟限制，因此需要研究模型蒸馏技术。

Method: 评估了四种蒸馏策略：硬蒸馏、软蒸馏、解耦知识蒸馏(DKD)和特征蒸馏，通过全面的教师和学生模型容量扫描来表征缩放规律。

Result: 提出了描述模型大小与性能关系的缩放规律，为构建可部署在边缘设备上的生理传感模型奠定了基础。

Conclusion: 这项早期研究为构建实用且可预测的边缘可部署生理传感模型方法奠定了基础。

Abstract: Heart rate estimation from photoplethysmography (PPG) signals generated by wearable devices such as smartwatches and fitness trackers has significant implications for the health and well-being of individuals. Although prior work has demonstrated deep learning models with strong performance in the heart rate estimation task, in order to deploy these models on wearable devices, these models must also adhere to strict memory and latency constraints. In this work, we explore and characterize how large pre-trained PPG models may be distilled to smaller models appropriate for real-time inference on the edge. We evaluate four distillation strategies through comprehensive sweeps of teacher and student model capacities: (1) hard distillation, (2) soft distillation, (3) decoupled knowledge distillation (DKD), and (4) feature distillation. We present a characterization of the resulting scaling laws describing the relationship between model size and performance. This early investigation lays the groundwork for practical and predictable methods for building edge-deployable models for physiological sensing.

</details>


### [131] [Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter Learning](https://arxiv.org/abs/2511.18859)
*Bo Jiang,Weijun Zhao,Beibei Wang,Xiao Wang,Jin Tang*

Main category: cs.LG

TL;DR: 本文提出了一种不确定性感知的GNN适配器（UAdapterGNN），通过集成不确定性学习来增强预训练GNN模型在下游任务中对噪声图数据的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN适配器方法容易受到图数据中各种噪声（如噪声边和模糊节点属性）的影响，泛化能力有限。如何增强GNN微调的鲁棒性和泛化能力是一个开放性问题。

Method: 提出UAdapterGNN，使用高斯概率适配器来增强预训练GNN模型。当图包含各种噪声时，该方法能自动吸收高斯分布方差变化的影响，从而显著增强模型鲁棒性。

Result: 在多个基准测试上的广泛实验证明了UAdapterGNN方法的有效性、鲁棒性和高泛化能力。

Conclusion: 通过将不确定性学习集成到GNN适配器中，可以很好地解决GNN微调过程中的鲁棒性和泛化问题，UAdapterGNN方法在噪声图数据下表现出色。

Abstract: Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable attention in adapting pre-trained GNN models for downstream graph learning tasks. One representative fine-tuning method is to exploit adapter (termed AdapterGNN) which aims to 'augment' the pre-trained model by inserting a lightweight module to make the 'augmented' model better adapt to the downstream tasks. However, graph data may contain various types of noise in downstream tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs are often prone to graph noise and exhibit limited generalizability. How to enhance the robustness and generalization ability of GNNs' fine tuning remains an open problem. In this paper, we show that the above problem can be well addressed by integrating uncertainty learning into the GNN adapter. We propose the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN models against noisy graph data in the fine-tuning process. Specifically, in contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic adapter to augment the pre-trained GNN model. In this way, when the graph contains various noises,our method can automatically absorb the effects of changes in the variances of the Gaussian distribution, thereby significantly enhancing the model's robustness. Also, UAdapterGNN can further improve the generalization ability of the model on the downstream tasks. Extensive experiments on several benchmarks demonstrate the effectiveness, robustness and high generalization ability of the proposed UAdapterGNN method.

</details>


### [132] [AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention](https://arxiv.org/abs/2511.18960)
*Lei Xiao,Jifeng Li,Juntao Gao,Feiyang Ye,Yan Jin,Jingjing Qian,Jing Zhang,Yong Wu,Xiaoyuan Yu*

Main category: cs.LG

TL;DR: AVA-VLA是一个基于POMDP视角的视觉-语言-动作模型框架，通过引入主动视觉注意力机制，利用历史上下文动态调制视觉处理，在机器人任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常将任务建模为MDP，在每个时间步独立处理密集视觉输入，这种历史无关的设计无法有效利用历史上下文，在动态顺序决策中不是最优的。

Method: 从POMDP角度重新定义问题，提出AVA-VLA框架，引入主动视觉注意力机制，利用来自前一个决策步骤的循环状态（信念状态的神经近似）动态调制视觉处理，计算软权重来主动处理任务相关的视觉标记。

Result: 在LIBERO和CALVIN等流行机器人基准测试中实现了最先进的性能，在双臂机器人平台上的实际部署验证了框架的实用性和强大的模拟到现实迁移能力。

Conclusion: AVA-VLA通过将问题重新表述为POMDP并引入主动视觉注意力机制，有效解决了现有VLA模型在动态顺序决策中的局限性，实现了卓越的性能和实际应用价值。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.

</details>


### [133] [Optimization of Deep Learning Models for Dynamic Market Behavior Prediction](https://arxiv.org/abs/2511.19090)
*Shenghan Zhao,Yuzhen Lin,Ximeng Yang,Qiaochu Lu,Haozhong Xue,Gaozhe Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种混合序列模型，结合多尺度时间卷积、门控循环模块和时间感知自注意力机制，用于电子商务多时间范围需求预测，在多个评估指标上优于传统方法和最先进的Transformer预测器。


<details>
  <summary>Details</summary>
Motivation: 随着金融科技的发展，深度学习模型在预测消费者行为方面显示出巨大潜力。本文专注于零售市场行为，明确预测目标为每个SKU的日需求/收入，时间范围为1、7、14天，旨在提高预测准确性和鲁棒性。

Method: 采用混合序列模型，结合多尺度时间卷积、门控循环模块和时间感知自注意力机制。使用标准回归损失进行训练，采用严格的时间分割防止数据泄露，并与ARIMA/Prophet、LSTM/GRU、LightGBM及最先进的Transformer预测器进行基准比较。

Result: 结果显示该模型在准确性方面取得一致提升，在峰值/节假日期间表现出更好的鲁棒性。通过消融实验和统计显著性测试验证了改进的可靠性。

Conclusion: 提出的混合序列模型在电子商务需求预测任务中表现出色，优于现有方法，特别是在处理复杂时间模式和峰值期间。研究提供了完整的实现细节以确保可复现性。

Abstract: The advent of financial technology has witnessed a surge in the utilization of deep learning models to anticipate consumer conduct, a trend that has demonstrated considerable potential in enhancing lending strategies and bolstering market efficiency. We study multi-horizon demand forecasting on e-commerce transactions using the UCI Online Retail II dataset. Unlike prior versions of this manuscript that mixed financial-loan narratives with retail data, we focus exclusively on retail market behavior and define a clear prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We present a hybrid sequence model that combines multi-scale temporal convolutions, a gated recurrent module, and time-aware self-attention. The model is trained with standard regression losses and evaluated under MAE, RMSE, sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage. We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show consistent accuracy gains and improved robustness on peak/holiday periods. We further provide ablations and statistical significance tests to ensure the reliability of improvements, and we release implementation details to facilitate reproducibility.

</details>


### [134] [Masked Diffusion Models are Secretly Learned-Order Autoregressive Models](https://arxiv.org/abs/2511.19152)
*Prateek Garg,Bhavya Kohli,Sunita Sarawagi*

Main category: cs.LG

TL;DR: 本文提出了一种新的训练框架，通过多元噪声调度优化掩码扩散模型（MDMs）的解码顺序，将MDMs转化为具有可学习顺序的自回归模型。


<details>
  <summary>Details</summary>
Motivation: 现有MDMs在随机解码顺序下训练，而解码顺序对性能有显著影响。本文旨在设计能够优化解码顺序的训练框架。

Method: 使用多元噪声调度的连续时间变分目标，建立解码顺序与噪声调度的直接对应关系，打破MDM目标对噪声调度的不变性。

Result: 证明了MDM目标可以精确分解为这些顺序上的加权自回归损失，从而将MDMs建立为具有可学习顺序的自回归模型。

Conclusion: 提出的框架能够识别和优化解码顺序，为MDMs提供了更灵活和优化的训练方法。

Abstract: Masked Diffusion Models (MDMs) have emerged as one of the most promising paradigms for generative modeling over discrete domains. It is known that MDMs effectively train to decode tokens in a random order, and that this ordering has significant performance implications in practice. This observation raises a fundamental question: can we design a training framework that optimizes for a favorable decoding order? We answer this in the affirmative, showing that the continuous-time variational objective of MDMs, when equipped with multivariate noise schedules, can identify and optimize for a decoding order during training. We establish a direct correspondence between decoding order and the multivariate noise schedule and show that this setting breaks invariance of the MDM objective to the noise schedule. Furthermore, we prove that the MDM objective decomposes precisely into a weighted auto-regressive losses over these orders, which establishes them as auto-regressive models with learnable orders.

</details>


### [135] [First-order Sobolev Reinforcement Learning](https://arxiv.org/abs/2511.19165)
*Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: 提出一种时间差分学习的改进方法，通过强制一阶贝尔曼一致性来训练价值函数，使其不仅匹配贝尔曼目标值，还匹配关于状态和动作的导数。


<details>
  <summary>Details</summary>
Motivation: 改进现有时间差分学习方法，通过考虑价值函数的局部几何特性来提高收敛速度和策略梯度的稳定性。

Method: 通过可微动力学对贝尔曼备份进行微分，获得分析上一致的梯度目标，使用Sobolev型损失将这些梯度目标融入评论家目标函数中。

Result: 该方法可以无缝集成到现有算法中（如Q学习、DDPG、SAC），可能带来更快的评论家收敛和更稳定的策略梯度。

Conclusion: 一阶TD匹配原则能够在不改变算法整体结构的情况下，有效提升强化学习算法的性能表现。

Abstract: We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also their derivatives with respect to states and actions. By differentiating the Bellman backup through differentiable dynamics, we obtain analytically consistent gradient targets. Incorporating these into the critic objective using a Sobolev-type loss encourages the critic to align with both the value and local geometry of the target function. This first-order TD matching principle can be seamlessly integrated into existing algorithms, such as Q-learning or actor-critic methods (e.g., DDPG, SAC), potentially leading to faster critic convergence and more stable policy gradients without altering their overall structure.

</details>


### [136] [RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning](https://arxiv.org/abs/2511.19168)
*Deyi Ji,Yuekui Yang,Liqun Liu,Peng Shu,Haiyang Wu,Shaogang Tang,Xudong Chen,Shaoping Ma,Tianrun Chen,Lanyun Zhu*

Main category: cs.LG

TL;DR: RAVEN++是一个针对视频广告内容审核的改进框架，通过主动强化学习、细粒度违规理解和渐进式多阶段训练，提升了违规检测的精确性、可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频广告内容审核模型在细粒度理解、可解释性和泛化能力方面存在不足，需要更精确的违规定位和更好的推理能力。

Method: 提出三个关键创新：1）主动强化学习动态调整训练难度；2）通过分层奖励函数和推理蒸馏实现细粒度违规理解；3）渐进式多阶段训练结合知识注入、课程被动强化学习和主动强化学习。

Result: 在公开和专有数据集上的实验表明，RAVEN++在细粒度违规理解、推理能力和泛化能力方面优于通用大语言模型和专门模型如RAVEN。

Conclusion: RAVEN++框架有效解决了视频广告内容审核中的关键挑战，在离线场景和在线A/B测试中均表现出优越性能。

Abstract: Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.

</details>


### [137] [Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform](https://arxiv.org/abs/2511.19240)
*Minxin Chen*

Main category: cs.LG

TL;DR: 本文提出了FDSW-UCB算法，结合折扣长期视角和滑动窗口短期视角，在非平稳多臂老虎机环境中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统多臂老虎机算法在非平稳奖励分布环境中的性能下降问题，因为现实世界中的老虎机问题往往涉及随时间变化的奖励分布。

Method: 开发了FDSW-UCB双视角算法，集成基于折扣的长期视角和基于滑动窗口的短期视角，并构建了基于MovieLens-1M和Open Bandit数据集的半合成仿真平台。

Result: 实验表明滑动窗口机制(SW-UCB)稳健，而广泛使用的折扣方法(D-UCB)存在基本学习失败导致线性遗憾。FDSW-UCB采用乐观聚合策略在动态设置中表现最优。

Conclusion: 集成策略本身是成功的关键因素，FDSW-UCB在非平稳环境中实现了卓越性能，为动态环境下的决策优化提供了有效解决方案。

Abstract: Many real-world bandit problems involve non-stationary reward distributions, where the optimal decision may shift due to evolving environments. However, the performance of some typical Multi-Armed Bandit (MAB) models such as Upper Confidence Bound (UCB) algorithms degrades significantly in non-stationary environments where reward distributions change over time. To address this limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view algorithm that integrates a discount-based long-term perspective with a sliding-window-based short-term view. A data-driven semi-synthetic simulation platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to test algorithm adaptability under abrupt and gradual drift scenarios. Experimental results demonstrate that a well-configured sliding-window mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB) suffers from a fundamental learning failure, leading to linear regret. Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation strategy, achieves superior performance in dynamic settings, highlighting that the ensemble strategy itself is a decisive factor for success.

</details>


### [138] [CDLM: Consistency Diffusion Language Models For Faster Sampling](https://arxiv.org/abs/2511.19269)
*Minseo Kim,Chenfeng Xu,Coleman Hooper,Harman Singh,Ben Athiwaratkun,Ce Zhang,Kurt Keutzer,Amir Gholami*

Main category: cs.LG

TL;DR: CDLM通过整合一致性建模和块级因果注意力掩码，解决了扩散语言模型的推理延迟问题，实现了3.6-14.5倍的加速，同时保持数学和编程任务的竞争性准确率。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然提供了有前景的并行生成范式，但由于需要大量细化步骤且无法使用标准KV缓存，导致推理速度缓慢。

Method: CDLM整合一致性建模来大幅减少所需采样步骤，实现多令牌最终化；在微调期间强制执行块级因果注意力掩码，使模型完全兼容KV缓存。

Result: 实验显示CDLM在数学和编程任务上实现了3.6-14.5倍更低的延迟，同时保持了竞争性的准确率。

Conclusion: CDLM是一种基于训练的加速方法，同时解决了扩散语言模型的两个主要瓶颈，显著提升了推理效率。

Abstract: Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.

</details>


### [139] [Closing Gaps in Emissions Monitoring with Climate TRACE](https://arxiv.org/abs/2511.19277)
*Brittany V. Lancellotti,Jordan M. Malof,Aaron Davitt,Gavin McCormick,Shelby Anderson,Pol Carbó-Mestre,Gary Collins,Verity Crane,Zoheyr Doctor,George Ebri,Kevin Foster,Trey M. Gowdy,Michael Guzzardi,John Heal,Heather Hunter,David Kroodsma,Khandekar Mahammad Galib,Paul J. Markakis,Gavin McDonald,Daniel P. Moore,Eric D. Nguyen,Sabina Parvu,Michael Pekala,Christine D. Piatko,Amy Piscopo,Mark Powell,Krsna Raniga,Elizabeth P. Reilly,Michael Robinette,Ishan Saraswat,Patrick Sicurello,Isabella Söldner-Rembold,Raymond Song,Charlotte Underwood,Kyle Bradbury*

Main category: cs.LG

TL;DR: Climate TRACE是一个开放获取平台，提供全球温室气体排放估算数据，具有高精度、全球覆盖、高时空分辨率和频繁更新的特点，支持数据驱动的气候行动。


<details>
  <summary>Details</summary>
Motivation: 现有排放数据集缺乏准确性、全球覆盖、高时空分辨率和频繁更新等关键特性，限制了其在气候行动中的实用性。

Method: 整合现有排放数据，优先考虑准确性、覆盖范围和分辨率，并使用特定行业的估算方法来填补数据空白。

Result: 创建了首个提供全球全面排放估算的数据集，涵盖所有人为排放部门，包括单个排放源（如发电厂），数据从2021年1月1日至今，每月更新。

Conclusion: Climate TRACE代表了排放核算和减排领域的重大突破，支持在决策层面进行数据驱动的气候行动。

Abstract: Global greenhouse gas emissions estimates are essential for monitoring and mitigation planning. Yet most datasets lack one or more characteristics that enhance their actionability, such as accuracy, global coverage, high spatial and temporal resolution, and frequent updates. To address these gaps, we present Climate TRACE (climatetrace.org), an open-access platform delivering global emissions estimates with enhanced detail, coverage, and timeliness. Climate TRACE synthesizes existing emissions data, prioritizing accuracy, coverage, and resolution, and fills gaps using sector-specific estimation approaches. The dataset is the first to provide globally comprehensive emissions estimates for individual sources (e.g., individual power plants) for all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the present, with a two-month reporting lag and monthly updates. The open-access platform enables non-technical audiences to engage with detailed emissions datasets for most subnational governments worldwide. Climate TRACE supports data-driven climate action at scales where decisions are made, representing a major breakthrough for emissions accounting and mitigation.

</details>


### [140] [MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings](https://arxiv.org/abs/2511.19279)
*Victor Rambaud,Salvador Mascarenhas,Yair Lakretz*

Main category: cs.LG

TL;DR: MapFormers是基于Transformer的新架构，能够从观测数据中学习认知地图并并行执行路径整合，通过输入依赖的位置编码实现结构与内容的解耦，在OOD泛化方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统缺乏人类和动物所具有的认知地图能力，无法灵活适应新情境并实现强OOD泛化。为了弥合这一差距，需要开发能够学习认知地图的模型。

Method: 提出MapFormers架构，通过更新Transformer中的位置编码为输入依赖矩阵，自然实现结构与内容的解耦。开发了两种变体：绝对位置编码建模情景记忆，相对位置编码建模工作记忆。

Result: 在2D导航等任务中，MapFormers能够学习底层空间的认知地图，并在OOD泛化（如更长序列）方面实现近乎完美的性能，优于现有架构。

Conclusion: 结果表明，设计用于学习认知地图的模型具有优越性，引入结构偏置实现结构-内容解耦在Transformer中可通过输入依赖位置编码实现，MapFormers在神经科学和AI领域具有广泛应用前景。

Abstract: A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.

</details>


### [141] [Understanding the Staged Dynamics of Transformers in Learning Latent Structure](https://arxiv.org/abs/2511.19328)
*Rohan Saha,Farzane Aminmansour,Alona Fyshe*

Main category: cs.LG

TL;DR: 本文研究了Transformer模型学习潜在结构的动态过程，使用Alchemy基准测试分析了模型在不同任务变体中的学习阶段，发现模型先学习粗粒度规则再学习完整潜在结构，并识别了组合与分解能力的不对称性。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer能够从上下文中发现潜在结构，但关于它们如何获取潜在结构不同组成部分的动态过程仍不清楚。本文旨在深入理解Transformer模型学习潜在结构的动态机制。

Method: 使用Alchemy基准测试，在小型的仅解码器Transformer上训练三个任务变体：1)从部分上下文信息推断缺失规则，2)组合简单规则解决多步序列，3)分解复杂多步示例推断中间步骤。通过将每个任务分解为可解释的事件来分析学习过程。

Result: 模型以离散阶段获取能力，首先学习粗粒度规则，然后学习完整的潜在结构。发现关键的不对称性：模型能够稳健地组合基本规则，但在分解复杂示例以发现基本规则时存在困难。

Conclusion: 这些发现为理解Transformer模型如何学习潜在结构提供了新的见解，揭示了这些能力在训练过程中的细粒度演化过程。

Abstract: While transformers can discover latent structure from context, the dynamics of how they acquire different components of the latent structure remain poorly understood. In this work, we use the Alchemy benchmark, to investigate the dynamics of latent structure learning. We train a small decoder-only transformer on three task variants: 1) inferring missing rules from partial contextual information, 2) composing simple rules to solve multi-step sequences, and 3) decomposing complex multi-step examples to infer intermediate steps. By factorizing each task into interpretable events, we show that the model acquires capabilities in discrete stages, first learning the coarse grained rules, before learning the complete latent structure. We also identify a crucial asymmetry, where the model can compose fundamental rules robustly, but struggles to decompose complex examples to discover the fundamental rules. These findings offer new insights into understanding how a transformer model learns latent structures, providing a granular view of how these capabilities evolve during training.

</details>


### [142] [Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data](https://arxiv.org/abs/2511.19330)
*Dominik Luszczynski*

Main category: cs.LG

TL;DR: 本文提出了两种新的基于斜率的对抗攻击方法，用于操纵N-HiTS模型对股票预测的趋势，能够绕过标准安全机制，并将这些方法集成到GAN架构中生成真实合成数据。


<details>
  <summary>Details</summary>
Motivation: 对抗攻击在图像领域已有深入研究，但在时间序列领域研究较少，特别是在金融预测数据方面。本文旨在填补这一空白，研究如何操纵股票预测模型的趋势。

Method: 引入了两种新的基于斜率的攻击方法：通用斜率攻击和最小二乘斜率攻击，用于改变N-HiTS模型的预测趋势。这些方法还被集成到GAN架构中生成合成数据。

Result: 新的斜率攻击方法能够将N-HiTS预测的斜率翻倍，成功绕过标准安全机制，将4层CNN分类器的特异性降低到28%，准确率降低到57%。

Conclusion: 研究表明机器学习安全研究不仅需要关注模型本身的安全性，还需要保护整个处理流程，并提出了一个样本恶意软件来证明在模型推理库中注入对抗攻击的可能性。

Abstract: A common method of attacking deep learning models is through adversarial attacks, which occur when an attacker specifically modifies the input of a model to produce an incorrect result. Adversarial attacks have been deeply investigated in the image domain; however, there is less research in the time-series domain and very little for forecasting financial data. To address these concerns, this study aims to build upon previous research on adversarial attacks for time-series data by introducing two new slope-based methods aimed to alter the trends of the predicted stock forecast generated by an N-HiTS model. Compared to the normal N-HiTS predictions, the two new slope-based methods, the General Slope Attack and Least-Squares Slope Attack, can manipulate N-HiTS predictions by doubling the slope. These new slope attacks can bypass standard security mechanisms, such as a discriminator that filters real and perturbed inputs, reducing a 4-layered CNN's specificity to 28% and accuracy to 57%. Furthermore, the slope based methods were incorporated into a GAN architecture as a means of generating realistic synthetic data, while simultaneously fooling the model. Finally, this paper also proposes a sample malware designed to inject an adversarial attack in the model inference library, proving that ML-security research should not only focus on making the model safe, but also securing the entire pipeline.

</details>


### [143] [Annotation-Free Class-Incremental Learning](https://arxiv.org/abs/2511.19344)
*Hari Chandana Kuchibhotla,K S Ananth,Vineeth N Balasubramanian*

Main category: cs.LG

TL;DR: 本文提出了注释自由类增量学习(AFCIL)新范式，解决无标签数据连续到达时的持续学习问题，并提出了CrossWorld CL框架，利用外部世界知识作为稳定辅助源来提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法大多假设在整个学习过程中都有标记数据可用，但在现实场景中，数据通常是顺序到达且没有注释的。本文旨在探索当标签缺失且任务随时间增量出现时，当前系统能否适应。

Method: 提出CrossWorld CL框架，通过检索每个下游类别的语义相关ImageNet类别，使用跨域对齐策略映射下游和ImageNet特征，并引入新颖的重放策略，让模型在没有注释的情况下发现语义结构同时保持先前知识。

Result: 在四个数据集上的实验表明，CrossWorld CL超越了CLIP基线和现有的持续学习及无标签学习方法，证明了世界知识对注释自由持续学习的益处。

Conclusion: 通过引入外部世界知识作为稳定辅助源，CrossWorld CL框架能够有效解决无标签数据连续到达时的类增量学习问题，为更现实的持续学习场景提供了可行方案。

Abstract: Despite significant progress in continual learning ranging from architectural novelty to clever strategies for mitigating catastrophic forgetting most existing methods rest on a strong but unrealistic assumption the availability of labeled data throughout the learning process. In real-world scenarios, however, data often arrives sequentially and without annotations, rendering conventional approaches impractical. In this work, we revisit the fundamental assumptions of continual learning and ask: Can current systems adapt when labels are absent and tasks emerge incrementally over time? To this end, we introduce Annotation-Free Class-Incremental Learning (AFCIL), a more realistic and challenging paradigm where unlabeled data arrives continuously, and the learner must incrementally acquire new classes without any supervision. To enable effective learning under AFCIL, we propose CrossWorld CL, a Cross Domain World Guided Continual Learning framework that incorporates external world knowledge as a stable auxiliary source. The method retrieves semantically related ImageNet classes for each downstream category, maps downstream and ImageNet features through a cross domain alignment strategy and finally introduce a novel replay strategy. This design lets the model uncover semantic structure without annotations while keeping earlier knowledge intact. Across four datasets, CrossWorld-CL surpasses CLIP baselines and existing continual and unlabeled learning methods, underscoring the benefit of world knowledge for annotation free continual learning.

</details>


### [144] [Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric](https://arxiv.org/abs/2511.19350)
*Nikita Neveditsin,Pawan Lingras,Vijay Mago*

Main category: cs.LG

TL;DR: 本文提出了一种可扩展的光谱方法来估计短文本嵌入的聚类数量，无需预先指定聚类数，并引入了Cohesion Ratio指标来评估无监督聚类质量。


<details>
  <summary>Details</summary>
Motivation: 短文本嵌入聚类是自然语言处理中的基础任务，但由于需要预先指定聚类数量而具有挑战性。现有方法在确定最佳聚类数方面存在困难。

Method: 使用基于余弦相似度的拉普拉斯特征谱结构来估计聚类数量，采用自适应采样策略使估计器能够高效扩展到大型数据集。

Result: 在六个短文本数据集和四个现代嵌入模型上的实验表明，当使用本文估计器指导时，标准算法如K-Means和HAC显著优于HDBSCAN、OPTICS和Leiden等流行参数轻量方法。

Conclusion: 本文的光谱估计器和Cohesion Ratio为短文本数据的无监督组织和评估提供了实用价值，能够有效确定聚类数量并评估聚类质量。

Abstract: Clustering short text embeddings is a foundational task in natural language processing, yet remains challenging due to the need to specify the number of clusters in advance. We introduce a scalable spectral method that estimates the number of clusters directly from the structure of the Laplacian eigenspectrum, constructed using cosine similarities and guided by an adaptive sampling strategy. This sampling approach enables our estimator to efficiently scale to large datasets without sacrificing reliability. To support intrinsic evaluation of cluster quality without ground-truth labels, we propose the Cohesion Ratio, a simple and interpretable evaluation metric that quantifies how much intra-cluster similarity exceeds the global similarity background. It has an information-theoretic motivation inspired by mutual information, and in our experiments it correlates closely with extrinsic measures such as normalized mutual information and homogeneity. Extensive experiments on six short-text datasets and four modern embedding models show that standard algorithms like K-Means and HAC, when guided by our estimator, significantly outperform popular parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results demonstrate the practical value of our spectral estimator and Cohesion Ratio for unsupervised organization and evaluation of short text data. Implementation of our estimator of k and Cohesion Ratio, along with code for reproducing the experiments, is available at https://anonymous.4open.science/r/towards_clustering-0C2E.

</details>


### [145] [Enhancing Conformal Prediction via Class Similarity](https://arxiv.org/abs/2511.19359)
*Ariel Fargion,Lahav Dabah,Tom Tirer*

Main category: cs.LG

TL;DR: 本文提出了一种基于类别相似性的方法，用于提升任何保形预测方法的性能，通过惩罚组外错误和利用类别相似性来减少预测集大小。


<details>
  <summary>Details</summary>
Motivation: 在类别可被划分为语义组的情况下，用户不仅需要平均较小的预测集，还需要包含较少语义不同组的预测集。现有保形预测方法主要关注平均预测集大小，未能充分利用类别相似性。

Method: 首先提出在保形预测评分函数中添加惩罚组外错误的项；然后通过理论分析证明该方法对组相关指标的优势；最后提出不依赖人工语义分区的模型特定变体，利用类别相似性进一步减少预测集大小。

Result: 理论分析表明该方法能减少平均预测集大小，特别是在常见类别分区下。实证研究涵盖多种保形预测方法、模型和数据集，证明基于类别相似性的方法能持续提升保形预测性能。

Conclusion: 提出的基于类别相似性的方法能有效提升任何保形预测方法，通过利用类别间的语义关系减少预测集大小，且无需人工语义分区。

Abstract: Conformal Prediction (CP) has emerged as a powerful statistical framework for high-stakes classification applications. Instead of predicting a single class, CP generates a prediction set, guaranteed to include the true label with a pre-specified probability. The performance of different CP methods is typically assessed by their average prediction set size. In setups where the classes can be partitioned into semantic groups, e.g., diseases that require similar treatment, users can benefit from prediction sets that are not only small on average, but also contain a small number of semantically different groups. This paper begins by addressing this problem and ultimately offers a widely applicable tool for boosting any CP method on any dataset. First, given a class partition, we propose augmenting the CP score function with a term that penalizes predictions with out-of-group errors. We theoretically analyze this strategy and prove its advantages for group-related metrics. Surprisingly, we show mathematically that, for common class partitions, it can also reduce the average set size of any CP score function. Our analysis reveals the class similarity factors behind this improvement and motivates us to propose a model-specific variant, which does not require any human semantic partition and can further reduce the prediction set size. Finally, we present an extensive empirical study, encompassing prominent CP methods, multiple models, and several datasets, which demonstrates that our class-similarity-based approach consistently enhances CP methods.

</details>


### [146] [Learning Robust Social Strategies with Large Language Models](https://arxiv.org/abs/2511.19405)
*Dereck Piche,Mohammed Muqeeth,Milad Aghajohari,Juan Duque,Michael Noukhovitch,Aaron Courville*

Main category: cs.LG

TL;DR: 本文研究了在多智能体交互中，强化学习训练的LLM智能体倾向于发展机会主义行为的问题，并提出了一种优势对齐算法来促进多智能体合作和抗剥削能力。


<details>
  <summary>Details</summary>
Motivation: 随着智能AI的普及，具有不同且可能冲突目标的智能体将在复杂环境中交互。在多智能体社会困境中，个体激励可能损害集体福利，而标准强化学习往往收敛到自私的背叛策略。

Method: 采用对手学习意识算法——优势对齐，来微调LLM以实现多智能体合作和抗剥削能力；引入组相对基线简化迭代博弈中的优势计算；开发了需要自然语言沟通的新社交困境环境"信任与分割"。

Result: 在各种社交困境中，通过优势对齐学习的策略实现了更高的集体收益，同时保持对贪婪智能体剥削的鲁棒性。

Conclusion: 优势对齐算法能够有效解决强化学习在多智能体环境中收敛到不良均衡的问题，促进LLM智能体之间的合作行为，提高集体福利。

Abstract: As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust and Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents.

</details>


### [147] [Flow Map Distillation Without Data](https://arxiv.org/abs/2511.19428)
*Shangyuan Tong,Nanye Ma,Saining Xie,Tommi Jaakkola*

Main category: cs.LG

TL;DR: 本文提出了一种无需外部数据集的流映射蒸馏方法，通过仅从先验分布采样来避免教师-数据不匹配问题，在ImageNet上仅需1步采样就达到了最先进的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有流模型需要缓慢的迭代采样，而传统的流映射蒸馏依赖于外部数据集，这可能导致教师-数据不匹配问题，因为静态数据集可能无法完整代表教师的全部生成能力。

Method: 提出了一种无数据替代方案，仅从先验分布采样，并引入一个原则性框架来预测教师的采样路径，同时主动纠正自身的复合误差以确保高保真度。

Result: 该方法超越了所有基于数据的对应方法，在ImageNet 256x256上达到FID 1.45，在ImageNet 512x512上达到FID 1.49，均仅需1步采样。

Conclusion: 这项工作为加速生成模型建立了一个更稳健的范式，并推动了无需数据的流映射蒸馏的广泛采用。

Abstract: State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [148] [Dynamics of coupled $D$-dimensional Stuart-Landau oscillators](https://arxiv.org/abs/2511.19052)
*Pragjyotish Bhuyan Gogoi,Awadhesh Prasad,Aryan Patel,Ram Ramaswamy,Debashis Ghoshal*

Main category: nlin.CD

TL;DR: 研究了高维Stuart-Landau振子系统的集体动力学，在D=3和4维情况下，探索了保持和破坏旋转对称性的耦合方式，发现了在D=2情况下不存在的涌现动力学现象，包括各种同步形式、多稳态和部分振幅死亡等。


<details>
  <summary>Details</summary>
Motivation: 将Stuart-Landau振子推广到D>2维具有SO(D)旋转对称性，研究这种高维振子系统的集体动力学，探索比D=2情况更丰富的动力学行为。

Method: 研究K个D=3和4维的Stuart-Landau振子系统，采用保持或破坏旋转对称性的耦合方式，并利用更多的内部参数探索振子间的异质性。

Result: 当保持旋转对称性时，观察到各种同步形式、多稳态和部分振幅死亡；当破坏旋转对称性时，观察到部分同步和部分振荡死亡，以及这些不同部分淬灭现象的共存。

Conclusion: 高维Stuart-Landau振子系统展现出比二维情况更丰富的集体动力学行为，包括多种同步模式、部分淬灭现象及其共存，这些现象在D=2情况下没有对应物。

Abstract: The Stuart-Landau oscillator generalized to $D > 2$ dimensions has SO($D$) rotational symmetry. We study the collective dynamics of a system of $K$ such oscillators of dimensions $D =$ 3 and 4, with coupling chosen to either preserve or break rotational symmetry. This leads to emergent dynamical phenomena that do not have analogs in the well-studied case of $D=2$. Further, the larger number of internal parameters allows for the exploration of different forms of heterogeneity among the individual oscillators. When rotational symmetry is preserved there can be various forms of synchronization as well as multistability and $partial$ amplitude death, namely, the quenching of oscillations within a subset of variables that asymptote to the same constant value. The oscillatory dynamics in these cases are characterized by phase-locking and phase-drift. When the coupling breaks rotational symmetry we observe $partial$ synchronization (when a subset of the variables coincide and oscillate) and $partial$ oscillation death (when a subset of variables asymptote to different stationary values), as well as the coexistence of these different partial quenching phenomena.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [149] [Functional renormalization with interaction flows: A single-boson exchange perspective and application to electron-phonon systems](https://arxiv.org/abs/2511.17697)
*Aiman Al-Eryani,Marcel Gievers,Kilian Fraboulet*

Main category: cond-mat.str-el

TL;DR: 本文提出了一种新的函数重整化群(fRG)方法，允许同时对裸传播子和裸相互作用进行调控，扩展了传统的fRG方法，为处理具有延迟相互作用的模型提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 传统fRG方法仅对裸传播子进行调控，限制了其应用范围。本文旨在开发一种更通用的fRG方法，能够同时调控传播子和相互作用，以处理传统方法无法实现的方案，如具有延迟相互作用的模型的温度流。

Method: 从Schwinger-Dyson和Bethe-Salpeter方程出发，开发了同时调控裸传播子和裸相互作用的fRG公式化方法。使用单玻色子交换分解，将流方程解释为对玻色子传播子添加调控器。

Result: 新方法保持了原始流方程的基本结构，为传统fRG方法无法实现的方案提供了框架。通过对Hubbard原子和Anderson杂质模型的分析，验证了该方案的循环收敛性。开发了新的温度流方案，并在Anderson杂质耦合声子模型上验证了其有效性。

Conclusion: 本文提出的扩展fRG方法显著增强了传统fRG的灵活性，为处理更复杂的量子多体系统提供了有力工具，特别是在处理具有延迟相互作用的模型方面具有重要应用价值。

Abstract: The functional renormalization group (fRG) is acknowledged as a powerful tool in quantum many-body physics and beyond. On the technical side, conventional implementations of the fRG rely on regulators for bare propagators only. Starting from Schwinger--Dyson and Bethe--Salpeter equations, we develop here an fRG formulation where both bare propagators and bare interactions can be dressed with regulators. The approach thus obtained is a generalization of the multiloop fRG recently introduced for many-fermion systems. Using the single-boson exchange decomposition, we show that the underlying flow equations are simply interpreted as adding a regulator to the bosonic propagator and that such an extension scarcely changes the original structure of the flow equations. Overall, we provide a framework for implementing approaches that cannot be realized with conventional fRG methods, such as temperature flows for models with retarded interactions. For concrete applications, we analyze the loop convergence of our scheme against conventional cutoff schemes for the Hubbard atom and the Anderson impurity model. Finally, we devise a new temperature-flow scheme that implements a cutoff in both the propagator and the bare interaction, and demonstrate its validity on a model of an Anderson impurity coupled to a phonon.

</details>


### [150] [Interplay of Power-Law correlated Disorder and Long-Range Hopping in One Dimension: Mobility Edges, Criticality, and ML-Based Phase Identification](https://arxiv.org/abs/2511.18341)
*Mohammad Pouranvari*

Main category: cond-mat.str-el

TL;DR: 本文研究了一维紧束缚模型，其中在位势具有幂律空间相关性（指数α），跳跃振幅以|i-j|^{-β}衰减。通过大规模精确对角化和机器学习方法，构建了(α,β)参数空间的综合相图，揭示了迁移率边和多种状态共存区域。


<details>
  <summary>Details</summary>
Motivation: 研究幂律相关无序和长程跳跃相互作用下的一维系统，探索从短程安德森无序到长程跳跃模型的连续插值，理解相关无序和长程跳跃如何驱动谱转变和迁移率边的形成。

Method: 使用大规模精确对角化，结合谱统计、态密度分析、参与比、单粒子纠缠熵、能级间距比等局域化指标，以及监督自编码器从原始特征中学习本征态结构的高层表示。

Result: 构建了(α,β)参数空间的综合相图，发现了稳健的迁移率边和局域化、扩展、共振、临界状态的多重谱共存区域，通过有限尺寸标度提取了临界指数。

Conclusion: 相关无序和长程跳跃驱动了丰富的谱转变，建立了表征一维长程系统中迁移率边的统一框架，物理诊断和机器学习方法提供了相互一致的系统图像。

Abstract: We investigate a one-dimensional tight-binding model in which onsite
  potentials $\{\varepsilon_i\}$ exhibit power-law spatial correlations
  (with exponent $α$) and the hopping amplitudes decay as
  $t_{ij}\sim |i-j|^{-β}$. This two-parameter family interpolates
  continuously between short-range Anderson-like disorder, correlated
  disorder with conventional hopping, and long-range hopping models with
  nontrivial delocalization tendencies. Using large-scale exact
  diagonalization, we construct a comprehensive phase map in the
  $(α,β)$ plane by combining spectral statistics, density-of-states
  analysis, and energy-resolved localization indicators such as the
  participation ratio, single-particle entanglement entropy, level-spacing
  ratio $r$, and the ratio of the geometric to arithmetic density of
  states. From these observables we define phase-indicator functions that
  compactly quantify localization behaviour across the spectrum. Our analysis reveals robust mobility edges and multiple regimes of
  spectral coexistence between localized, extended, resonant, and critical
  states. Finite-size scaling, implemented via an explicit smoothness-based
  cost function, enables extraction of critical exponents and delineation
  of transition lines across the $(α,β)$ parameter space.
  To validate and complement these physics-based diagnostics, we employ a
  supervised autoencoder that learns high-level representations of
  eigenstate structure directly from raw features and reliably reproduces
  the phase classification defined by the indicator functions. Together,
  these approaches provide a coherent and internally consistent picture of
  the spectral transitions driven by correlated disorder and long-range
  hopping, establishing a unified framework for characterizing mobility
  edges in long-range one-dimensional systems.

</details>


### [151] [A non-equilibrium quantum transport framework for spintronic devices with dynamical correlations](https://arxiv.org/abs/2511.18442)
*Declan Nell,Milos Radonjic,Ivan Rungger,Liviu Chioncel,Stefano Sanvito,Andrea Droghetti*

Main category: cond-mat.str-el

TL;DR: 提出了一个结合DFT、NEGF和DMFT的框架，用于模拟双端自旋电子器件在稳态条件下的量子输运，解决了现有方法无法同时处理偏压依赖输运和动态相关性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有ab initio方法要么能处理偏压依赖输运但忽略动态相关性，要么包含相关性但仅限于平衡或线性响应区域，无法准确模拟实际工作条件下的自旋电子器件。

Method: 结合密度泛函理论(DFT)、非平衡格林函数(NEGF)方法和动态平均场理论(DMFT)，构建了一个稳态量子输运框架。

Result: 在Cu/Co/真空/Cu结构中，相关性驱动了从费米液体到非费米液体的转变；在Fe/MgO/Fe隧道结中，相关性较弱，但非弹性散射仍能引起部分非相干输运。

Conclusion: 该框架为超越单粒子描述的自旋电子器件建模提供了途径，并为实验提供了新的解释视角。

Abstract: Two-terminal spintronic devices remain challenging to model under realistic operating conditions, where the interplay of complex electronic structures, correlation effects and bias-driven non-equilibrium dynamics may significantly impact charge and spin transport. Existing {\it ab initio} methods either capture bias-dependent transport but neglect dynamical correlations or include correlations but are restricted to equilibrium or linear-response regimes. To overcome these limitations, we present a framework for steady-state quantum transport, combining density functional theory (DFT), the non-equilibrium Greens' function (NEGF) method, and dynamical mean-field theory (DMFT). The framework is then applied to Cu/Co/vacuum/Cu and an Fe/MgO/Fe tunnel junction. In Co, correlations drive a transition from Fermi-liquid to non-Fermi-liquid behavior under finite bias, due to scattering of electrons with electron-hole pairs. In contrast, in the Fe/MgO/Fe junction, correlation effects are weaker: Fe remains close to equilibrium even at large biases. Nevertheless, inelastic scattering can still induce partly incoherent transport that modifies the device's response to the external bias. Overall, our framework provides a route to model spintronic devices beyond single-particle descriptions, while also suggesting new interpretations of experiments.

</details>


### [152] [Ab initio modeling of resonant inelastic x-ray scattering from Ca2RuO4](https://arxiv.org/abs/2511.18526)
*D. A. Kukusta,L. V. Bekenov,P. F. Perndorfer,D. V. Vyalikh,P. A. Buczek,A. Ernst,V. N. Antonov*

Main category: cond-mat.str-el

TL;DR: 本文使用DFT+SO+U方法结合LMTO能带结构方法，研究了Ca2RuO4的电子结构，重点分析了Ru L3和O K边的RIXS光谱，并与实验数据对比验证。


<details>
  <summary>Details</summary>
Motivation: 研究Ca2RuO4的电子结构，建立适用于复杂强关联材料光谱建模的理论方法，特别是RIXS技术。

Method: 采用第一性原理密度泛函理论(DFT)，结合广义梯度近似、强在位库仑相互作用和自旋轨道耦合(GGA+SO+U)，使用完全相对论自旋极化Dirac线性松饼球轨道(LMTO)能带结构方法。

Result: 计算的光谱与实验观测结果吻合良好，能够合理解释RIXS光谱中的关键特征，成功描述了Ca2RuO4的电子性质。

Conclusion: 建立了一个可靠的理论方法，可用于常规建模复杂强关联材料的光谱，特别是RIXS光谱，为表征类似材料的电子结构和性质提供了理论基础。

Abstract: The single-layered perovskite Ca$_2$RuO$_4$, characterized by a 4$d^4$ electron configuration, has been studied from first principles using density functional theory (DFT) using the generalized gradient approximation, with inclusion of strong on-site Coulomb interactions and spin-orbit coupling (GGA+SO+$U$), in the framework of the fully relativistic, spin-polarized Dirac linear muffin-tin orbital (LMTO) band-structure method. This approach enabled a comprehensive investigation of the electronic structure of Ca$_2$RuO$_4$ through the modeling of relevant spectra obtained from synchrotron-based techniques widely used to probe electronic properties, with a primary focus on resonant inelastic X-ray scattering (RIXS) at the Ru $L_3$ and O $K$ edges. The calculated spectra were thoroughly analyzed with available experimental data reported in the literature. The good agreement between our results and experimental observations for Ca$_2$RuO$_4$ enables a conclusive interpretation of key features in the spectra obtained from the aforementioned techniques. Consequently, this enables us to describe its electronic properties and to establish a solid theoretical approach suitable for routine modeling of spectra, particularly from RIXS, aimed at characterizing the electronic structure and properties of similar or more complex strongly correlated, technologically relevant materials.

</details>


### [153] [Competition between charge-density-wave and superconducting orders on eight-leg square Hubbard cylinders](https://arxiv.org/abs/2511.18644)
*Hong-Chen Jiang,Thomas P. Devereaux,Steven A. Kivelson*

Main category: cond-mat.str-el

TL;DR: 该研究通过变分方法分析方形晶格Hubbard模型中的d波超导性，发现在t'≤0时系统呈现电荷密度波态，超导关联极短程；t'>0时结果强烈依赖于边界条件，难以确定二维极限下超导或电荷密度波关联的主导性。


<details>
  <summary>Details</summary>
Motivation: 解决方形晶格Hubbard模型中是否存在d波超导性的长期争议，这是高温超导研究中最具争议的问题之一。

Method: 使用矩阵乘积态方法，在八腿圆柱上研究具有次近邻跃迁的Hubbard模型，参数范围包括U=8t和12t，掺杂浓度δ=1/12和1/8，t'在-0.5t到0.25t之间。

Result: 当t'≤0时，基态表现为电荷密度波态，超导关联极短程；局部磁序关联长度超过圆柱宽度一半，暗示二维极限下可能出现磁序。当t'>0时，结果强烈依赖于边界条件。

Conclusion: 研究结果表明在特定参数范围内，Hubbard模型更倾向于形成电荷密度波态而非d波超导态，且边界条件对结果有重要影响，使得二维极限下的主导关联类型难以确定。

Abstract: The issue of whether $d$-wave superconductivity (SC) occurs in the square-lattice Hubbard model with $U$ of order of the bandwidth has been one of the most debated issues to emerge from the study of high temperature SC. Here, we report variational results on eight-leg cylinders with next-nearest-neighbor hopping in the range $-0.5 t \leq t'\leq 0.25 t$ with $U = 8t$ and $12t$ and doped hole concentrations $δ=1/12$ and $1/8$. For $t'\leq 0$, the ground-state appears to be a charge-density wave (CDW) of one sort or another with SC correlations that are extremely short-ranged. In contrast, in some cases, the local magnetic order has a correlation length greater than half the cylinder width - suggestive that magnetic order might also arise in the 2D limit. For $t'>0$, our results depend more strongly on boundary conditions (periodic vs antiperiodic), making it still harder to correctly guess whether SC or CDW correlations dominate in the 2D limit. These results were obtained employing matrix-product states with bond dimensions large enough that energy differences as small as $10^{-3}t$ per site can be resolved.

</details>


### [154] [Clustering-Enhanced Time- and Angle-Resolved Photoemission Study of LaTe$_3$: Absence of a Photoinduced Secondary CDW in the Electronic Structure](https://arxiv.org/abs/2511.18974)
*Gesa-R. Siemann,Davide Curcio,Anders S. Mortensen,Charlotte E. Sanders,Yu Zhang,Jennifer Rigden,Paulina Majchrzak,Deepnarayan Biswas,Emma Springate,Ratnadwip Singha,Leslie M. Schoop,Philip Hofmann*

Main category: cond-mat.str-el

TL;DR: 本文通过时间和角度分辨光电子能谱研究LaTe$_3$材料中两个电荷密度波（CDW）相在电子结构中的相互作用，结合传统分析和无监督机器学习方法，发现费米轮廓不同分支具有不同的动力学和相干振荡。


<details>
  <summary>Details</summary>
Motivation: 研究光激发下LaTe$_3$材料中两个正交CDW相在电子结构中的相互作用，探索光调控材料性质的机制。

Method: 使用时间和角度分辨光电子能谱测量，结合FeSuMa分析仪和传统半球电子分析仪，采用传统数据分析与k-means聚类无监督机器学习技术。

Result: 未发现无法用主CDW熔化和重建解释的特征，但观察到费米轮廓不同分支具有不同的动力学和相干振荡。

Conclusion: 虽然未检测到第二CDW相的直接证据，但证明了无监督机器学习在分析复杂数据集中的强大潜力，并揭示了费米轮廓不同区域的独特动力学行为。

Abstract: Optical control offers a compelling route for tailoring material properties on an ultrafast time scale. Ordered states such as charge density waves (CDWs) can be transiently melted by an ultrafast light excitation. This is also the case for the rare-earth tritelluride LaTe$_3$, a prototypical CDW compound. For this material it has recently been reported that the suppression of the primary CDW allows the transient formation of a second CDW, whose wave vector is orthogonal to the primary one. This creates the intriguing scenario where light enables switching between two distinct ordered phases of the material. While the second CDW has so far been observed by structural techniques, it remains an open question how the interplay of the two CDW phases is reflected in the material's electronic structure. We investigate this via time- and angle-resolved photoemission measurements of LaTe$_3$. The complex Fermi contour is probed using a FeSuMa analyzer, which records the photoemission intensity of the entire Fermi contour at once. The dynamics revealed by the FeSuMa analyzer are complemented by measurements using a conventional hemispherical electron analyzer. We combine conventional data analysis with $k$-means clustering, an unsupervised machine learning technique, demonstrating its strong potential for disentangling large datasets. While we do not find any features that cannot be explained by the melting and re-establishment of the primary CDW, distinct dynamics and coherent oscillations are observed in the different branches of the Fermi contour.

</details>


### [155] [Kondo screening and random-singlet formation in highly disordered systems](https://arxiv.org/abs/2511.19389)
*Lucas G. Rabelo,Igor C. Almeida,Eduardo Miranda,Vladimir Dobrosavljević,Eric C. Andrade*

Main category: cond-mat.str-el

TL;DR: 提出了一个最小模型来捕捉掺杂半导体（如Si:P）在金属-绝缘体转变过程中的异常低温热力学行为，重点关注局域磁矩与无序电子浴的相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究掺杂半导体在金属-绝缘体转变过程中的低温热力学异常行为，特别是局域磁矩的响应特性，为强无序相互作用系统的完整理论提供关键要素。

Method: 采用大N变分方法，考虑局域磁矩对与高度无序、非相互作用电子浴的耦合，该电子浴随掺杂增加经历金属-绝缘体转变。

Result: 模型捕捉到了非均匀局域费米液体和绝缘随机单重态相，发现局域磁矩磁化率呈现稳健的幂律行为χ(T) ∝ T^{-α}，其中α随掺杂平滑演化并在金属中饱和。

Conclusion: Kondo屏蔽与随机单重态形成之间的竞争是构建强无序相互作用系统低温行为完整理论的关键要素。

Abstract: We propose a minimal model to capture the anomalous low-temperature thermodynamics of doped semiconductors, such as Si:P, across the metal-insulator transition. We consider pairs of local magnetic moments coupled to a highly disordered, non-interacting electronic bath that undergoes a metal-insulator transition with increasing doping. Using a large-$\mathcal{N}$ variational approach, we capture both the inhomogeneous local Fermi-liquid and the insulating random-singlet phase, and find that the local moment susceptibility exhibits a robust power-law behavior, $χ(T) \propto T^{-α}$, with $α$ evolving smoothly with doping before saturating in the metal. Our results highlight the competition between Kondo screening and random-singlet formation as the key ingredient in constructing a complete theory for the low-temperature behavior of strongly disordered interacting systems.

</details>


### [156] [Bound states for systems with quartic energy-momentum dispersion](https://arxiv.org/abs/2511.19193)
*E. V. Gorbar,B. E. Grinyuk,V. P. Gusynin*

Main category: cond-mat.str-el

TL;DR: 研究具有四次能量-动量色散E(p)~p^4和多项式势能系统的束缚态及其能量，使用WKB半经典近似和Wentzel复方法，考虑高阶WKB修正。发现四次色散系统的波函数在经典禁戒区有节点，一维薛定谔方程的振荡定理不适用，但在经典允许区仍成立。


<details>
  <summary>Details</summary>
Motivation: 研究具有四次能量-动量色散系统的束缚态性质，特别是验证振荡定理在非标准色散关系系统中的适用性。

Method: 使用WKB半经典近似和Wentzel复方法，考虑高阶WKB修正，并与变分方法使用通用高斯基得到的数值结果进行比较。

Result: 发现四次色散系统的波函数在经典禁戒区有节点，振荡定理不适用，但在经典允许区仍成立。与方势阱精确解进行比较。

Conclusion: 对于具有四次能量-动量色散的系统，一维薛定谔方程的振荡定理在一般情况下不适用，但在经典允许区域仍然有效。

Abstract: Bound states and its energies for systems with the quartic energy-momentum dispersion $E(p) \sim p^4$ and polynomial potentials are studied using the Wentzel-Kramers-Brillouin (WKB) semiclassical approximation and the Wentzel complex method taking into account higher order WKB corrections. The obtained energies are compared with numerical values found by applying the variational approach utilizing the universal Gaussian basis. It is found that the wave functions of the ground and higher-energy states for systems with quartic dispersion have nodes in the classically forbidden region. Thus, the well-known oscillation theorem for the one-dimensional Schrödinger equation is not, in general, applicable for systems with quartic dispersion. Still it is observed that the oscillation theorem holds in the classically allowed region in all considered examples. The properties of bound state wave functions are compared with the solutions of the exactly solvable problem of a square well potential.

</details>


### [157] [Chiral spin liquid instability of the Kitaev honeycomb model with crystallographic defects](https://arxiv.org/abs/2511.19409)
*Arnab Seth,Fay Borhani,Itamar Kimchi*

Main category: cond-mat.str-el

TL;DR: 在自旋-1/2 Kitaev蜂窝晶格无能隙自旋液体中引入Stone-Wales型晶格缺陷（奇数边多边形）会导致有限温度相变，产生非阿贝尔手性量子自旋液体。


<details>
  <summary>Details</summary>
Motivation: 研究晶格缺陷如何影响清洁Kitaev模型的无相变特性，探索缺陷诱导的拓扑相变机制。

Method: 在Kitaev蜂窝模型中引入有限密度的Stone-Wales型晶格缺陷（n_d≈10^-4-10^-2），分析缺陷手性之间的长程相互作用。

Result: 缺陷密度n_d≈10^-4-10^-2会产生真实相变，Tc≈2n_d，形成具有标量自旋手性和电子轨道磁化的非阿贝尔手性量子自旋液体。

Conclusion: 晶格缺陷通过介导缺陷手性间的长程铁磁相互作用（r^-γ，γ≈2.7），在狄拉克锥中产生拓扑相变，为拓扑态生成提供了新机制。

Abstract: We study the spin-1/2 Kitaev honeycomb gapless spin liquid in the presence of Stone-Wales-type local lattice defects with odd-sided plaquettes. While the clean Kitaev model has no finite-temperature phase transitions, we find that introducing a finite defect density $n_d\approx 10^{-4}$--$10^{-2}$ produces a true phase transition with a sizeable $T_c \approx 2 n_d$ in units of the Kitaev exchange. The resulting non-Abelian chiral quantum spin liquid exhibits scalar spin chirality and electron orbital magnetization which peak near lattice defects. This disorder-driven instability relies on an emergent long range ferromagnetic interaction $r^{-γ}$ ($γ\approx 2.7$) between defect chiralities, mediated by the nearly-gapless fermions, with implications for topology generation in Dirac cones with fluctuating mass terms.

</details>


### [158] [Projected Density Matrix Sampling for Lattice Hamiltonians](https://arxiv.org/abs/2511.19209)
*Abhishek Karna,Hansen S. Wu,Shailesh Chandrasekharan,Ribhu K. Kaul*

Main category: cond-mat.str-el

TL;DR: 本文提出了一种连续时间路径积分蒙特卡洛方法，用于计算量子哈密顿量的低能谱，通过将热密度矩阵投影到选定子空间，避免了Trotter离散化误差，并能处理符号问题。


<details>
  <summary>Details</summary>
Motivation: 量子蒙特卡洛方法在研究量子多体系统时面临难以访问激发态和处理符号问题的挑战，需要开发能够计算低能谱的新方法。

Method: 使用连续时间路径积分蒙特卡洛方法，将热密度矩阵投影到由一组线性无关状态张成的子空间，通过增加β参数系统性地收敛到低能态。

Result: 在无符号问题的一维Ising模型中成功计算了前四个低能级，展示了从共形极限到E8量子场论的流动；在有符号问题的受挫Shastry-Sutherland模型中，在小晶格上与精确对角化结果一致，并在更大系统上获得了结果。

Conclusion: 该方法为晶格哈密顿量的量子蒙特卡洛光谱学提供了一条通用途径，既能有效处理无符号问题系统，也能在存在符号问题时提供低能谱信息。

Abstract: Quantum Monte Carlo methods are powerful tools for studying quantum many-body systems but face difficulties in accessing excited states and in treating sign problems. We present a continuous-time path-integral Monte Carlo method for computing the low-lying spectrum of generic quantum Hamiltonians within a projection subspace. The method projects the thermal density matrix onto a subspace spanned by a chosen set of linearly independent states. It is free of Trotter discretization errors and systematically converges to the low-energy states which have finite overlap with the projection subspace as the $β$ parameter increases. While most effective for systems without a sign problem, the method also yields information about low-energy spectra when sign problems are present. We illustrate the approach on two problems. For the sign-free case, we compute the first four low-energy levels in the scaling limit of the one-dimensional Ising model with both transverse and longitudinal fields, demonstrating the flow from the conformal limit to the massive $E_8$ quantum field theory. For the sign-problem case, we apply the method to the frustrated Shastry-Sutherland model and benchmark it against exact diagonalization on small lattices. We also present results for larger systems beyond the lattice sizes accessible to exact diagonalization, while limited to small $β$ where sign problems occur. Our method provides a general route toward quantum Monte Carlo spectroscopy for lattice Hamiltonians.

</details>


### [159] [Diagnosis of mixed-state topological phases in strongly correlated systems via disorder parameters](https://arxiv.org/abs/2511.19311)
*Shao-Hang Shi,Xiao-Qi Sun,Zi-Xiang Li*

Main category: cond-mat.str-el

TL;DR: 本文提出了一种通过U(1)电荷算符的失序参数来诊断强相互作用系统中混合态拓扑相的一般框架，并开发了高效的量子蒙特卡洛算法来评估拓扑标度指标。


<details>
  <summary>Details</summary>
Motivation: 强相互作用费米子在混合态区域中的拓扑相表征仍然是一个重大挑战，需要开发新的数值方法来克服现有计算障碍。

Method: 通过U(1)电荷算符失序参数的生成函数的二阶导数的有限尺寸标度分析，引入拓扑标度指标，并开发了高效的determinant量子蒙特卡洛算法。

Result: 在Kane-Mele-Hubbard模型中成功映射了从量子自旋霍尔绝缘体到平凡Mott绝缘体的相互作用驱动相变；在Haldane-Hubbard模型中克服了严重符号问题，在可及温度下稳健识别了量子反常霍尔相。

Conclusion: 这项工作为相互作用混合态中拓扑现象的数字探索提供了一个强大且可用的工具，为研究先前因计算障碍而无法访问的系统开辟了途径。

Abstract: Characterizing topological phases for strongly interacting fermions in the mixed-state regime remains a major challenge. Here we introduce a general and numerically efficient framework to diagnose mixed-state topological phases in strongly interacting systems via the disorder parameter (DP) of the U(1) charge operator. Specifically, from the finite-size scaling of the second derivative of the DP generating function, we introduce the topological scaling indicator, which exhibits a characteristic linear scaling with the system's linear dimension for topological phases, a signature that vanishes upon transition into a topologically trivial phase. Crucially, we develop an efficient determinant Quantum Monte Carlo algorithm that facilitates the evaluation of this indicator in interacting systems. We apply our approach to two paradigmatic models: for the Kane-Mele-Hubbard model, we successfully map the interaction-driven transition from a quantum spin Hall insulator to a trivial Mott insulator. Furthermore, our method circumvents the limitations imposed by the severe sign problem in the Haldane-Hubbard model, enabling robust identification of the quantum anomalous Hall phase at accessible temperatures. This work provides a powerful and accessible tool for the numerical exploration of topological phenomena in interacting mixed states, opening a pathway to study systems previously inaccessible due to computational obstacles.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [160] [Collective Turns in Spinless Flocks](https://arxiv.org/abs/2511.17804)
*Joao Lizárraga,Marcus de Aguiar*

Main category: nlin.AO

TL;DR: 本文通过最小聚合模型研究鸟群集体转弯中的高效信息传递，发现这一特性源于局部相互作用的非互易性，并建立了速度波动的扰动分析和波散射模型。


<details>
  <summary>Details</summary>
Motivation: 研究自然鸟群在集体转弯过程中观察到的有效信息传递机制，探索这种集体行为背后的物理原理。

Method: 使用最小聚合模型，通过扰动分析研究速度波动，采用Born近似描述连续介质中的波动，分析波在群体中的散射过程。

Result: 证明了高效信息传递可以仅由局部相互作用的非互易性产生，建立了速度波动的扰动分析框架，发现波在群体中传播时会发生散射。

Conclusion: 该模型提供了可测试的预测，并可扩展到研究其他具有极性序的物理系统。

Abstract: Using a minimal aggregation-based model, we address the efficient information transfer observed in natural flocks during collective turns. Specifically, we demonstrate that this feature can arise solely from the non-reciprocal nature of local interactions. Through a perturbative analysis, moreover, we find that velocity fluctuations (in the continuum) can be described by a Born approximation. We then show that a wave propagating across the flock undergoes scattering. Our model provides testable predictions and can be extended to study other physical contexts exhibiting polar order.

</details>


### [161] [Phase reduction of reaction-diffusion systems with delay](https://arxiv.org/abs/2511.18360)
*Ayumi Ozawa,Yoji Kawamura*

Main category: nlin.AO

TL;DR: 本文开发了一种针对具有离散延迟的反应-扩散系统的相位约简方法，通过引入适合空间扩展系统的双线性形式，求解伴随方程得到相位敏感度函数，并在Schnakenberg系统中验证了理论，还展示了在同步稳定性优化中的应用。


<details>
  <summary>Details</summary>
Motivation: 建立一种能够同时处理空间自由度和延迟的振荡系统分析理论，填补现有相位约简方法在延迟反应-扩散系统中的应用空白。

Method: 基于无限维系统相位约简理论，引入针对离散延迟空间扩展系统的双线性形式，求解伴随方程获得相位敏感度函数，并在一维Schnakenberg系统中进行数值验证。

Result: 成功推导出相位敏感度函数，能够量化相位对扰动的响应；数值验证表明理论有效；通过相位方程优化了Schnakenberg系统对的相互作用，提高了同相同步的稳定性。

Conclusion: 该研究为分析同时涉及空间自由度和延迟的振荡系统建立了理论基础，是向完整理论框架迈出的重要一步。

Abstract: We develop a phase reduction method for reaction-diffusion systems with a discrete delay. On the basis of the recent developments in the phase reduction theory for infinite-dimensional systems, we introduce a bilinear form tailored to spatially extended systems involving a discrete delay. By solving the adjoint equation associated with the bilinear form, we obtain the phase sensitivity function, which quantifies the shift of the phase in response to a given perturbation. The theory is verified numerically with the use of the Schnakenberg system with a discrete delay in one spatial dimension. We further demonstrate the utility of the theory by optimizing the interaction between a pair of the Schnakenberg systems, with the use of the phase equation, for maximizing the stability of in-phase synchronization. This study serves as a step towards establishing a theory for analyzing oscillatory systems that involve both spatial degrees of freedom and delay.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [162] [BBP Phase Transition for an Extensive Number of Outliers](https://arxiv.org/abs/2511.18501)
*Niklas Forner,Alexander Maloney,Bernd Rosenow*

Main category: cond-mat.dis-nn

TL;DR: 本文使用随机矩阵理论分析信号与噪声分离问题，研究包含退化奇异值的矩形矩阵，推导出奇异值密度的四次方程，建立了广义BBP相图，并验证了理论在高维推断任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 在大数据集中区分信号与噪声是重要问题，随机矩阵理论为此提供了有效工具。本文旨在分析包含退化奇异值的矩形矩阵，理解信号强度如何影响奇异值分布。

Method: 分析p×q矩形矩阵W=W₀+M，其中M产生Marchenko-Pastur体，W₀注入退化奇异值。在保持rank W₀/q有限的情况下，推导奇异值密度的四次方程，并在强信号机制下获得显式渐近解。

Result: 建立了广义Baik-Ben Arous-Péché相图，得到了临界信号强度的标度律，阐明了有限密度尖峰如何重塑体边缘。数值模拟验证了理论结果。

Conclusion: 该理论为高维推断任务提供了新的分析框架，能够有效描述信号强度与奇异值分布之间的关系，在信号检测和噪声分离方面具有重要应用价值。

Abstract: Random-matrix theory helps disentangle signal from noise in large data sets. We analyze rectangular $p \times q$ matrices $W = W_0 + M$ in which the noise $M$ generates a Marchenko-Pastur bulk, whereas the signal $W_0$ injects an extensive set of degenerate singular values. Keeping $\mathrm{rank}$ $W_0/q$ finite as $p,q \to \infty$, we show that the singular value density obeys a quartic equation and derive explicit asymptotics in the strong-signal regime. The resulting generalized Baik-Ben Arous-Péché phase diagram yields a scaling law for the critical signal strength and clarifies how a finite density of spikes reshapes the bulk edges. Numerical simulations validate the theory and illustrate its relevance for high-dimensional inference tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [163] [Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation](https://arxiv.org/abs/2511.17541)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 基于莱布尼茨单子论构建了评估人工智能记忆系统的数学框架，将20个核心哲学命题映射到信息论架构中，每个单子作为模块化单元，包含真值分数、冗余参数和全局记忆惩罚函数贡献权重。


<details>
  <summary>Details</summary>
Motivation: 为人工智能记忆系统开发一个数学严谨、哲学基础坚实的评估框架，基于莱布尼茨单子论的形而上学结构，提供模块化、可解释且可证明可靠的内存架构设计蓝图。

Method: 将单子论的核心命题映射到信息论架构，每个单子定义为具有真值分数、冗余参数和加权贡献的模块化单元，使用平滑对数变换操作化这些量，并将形而上学概念重新表述为熵、梯度动态和内部表示保真度。

Result: 建立了精炼不变性、结构可分解性和尺度变换下的单调性等第一原理证明，框架分为六个主题束，每个数学证明与其对应的哲学领域对齐。

Conclusion: 该框架不仅提供了评估工具，还为构建模块化、可解释且可证明可靠的人工智能记忆架构提供了原则性蓝图，将经典形而上学概念与现代信息论相结合。

Abstract: This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.

</details>


### [164] [Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper Topology Structure in Architecture That Matches Images?](https://arxiv.org/abs/2511.17643)
*Yayan Qiu,Sean Hanna*

Main category: cs.AI

TL;DR: 本研究提出了一种快速检测pix2pix学习拓扑关系能力的方法，通过在GAN前后添加两个基于Grasshopper的检测模块，证明了pix2pix能够自动学习空间拓扑关系并应用于建筑设计。


<details>
  <summary>Details</summary>
Motivation: 考虑到建筑设计和城市更新中空间内在和外在特性的区域特征识别需求，现有方法存在模型嵌套和数据转换导致信息丢失的问题，需要简化工具以便建筑师和用户参与设计。

Method: 通过在GAN前后添加两个基于Grasshopper的检测模块，提供定量数据并可视化学习过程，研究不同输入模式（灰度、RGB）对学习效率的影响。

Result: 证明了pix2pix能够自动学习空间拓扑关系，填补了从拓扑角度检测基于图像的生成GAN性能的空白，检测方法耗时短、操作简单。

Conclusion: 该方法可为使用GAN保留空间拓扑特征的建筑设计和城市更新应用提供理论基础和数据支持，检测模块可广泛用于定制具有相同拓扑结构的图像数据集和批量检测图像拓扑关系。

Abstract: Taking into account the regional characteristics of intrinsic and extrinsic properties of space is an essential issue in architectural design and urban renewal, which is often achieved step by step using image and graph-based GANs. However, each model nesting and data conversion may cause information loss, and it is necessary to streamline the tools to facilitate architects and users to participate in the design. Therefore, this study hopes to prove that I2I GAN also has the potential to recognize topological relationships autonomously. Therefore, this research proposes a method for quickly detecting the ability of pix2pix to learn topological relationships, which is achieved by adding two Grasshopper-based detection modules before and after GAN. At the same time, quantitative data is provided and its learning process is visualized, and changes in different input modes such as greyscale and RGB affect its learning efficiency. There are two innovations in this paper: 1) It proves that pix2pix can automatically learn spatial topological relationships and apply them to architectural design. 2) It fills the gap in detecting the performance of Image-based Generation GAN from a topological perspective. Moreover, the detection method proposed in this study takes a short time and is simple to operate. The two detection modules can be widely used for customizing image datasets with the same topological structure and for batch detection of topological relationships of images. In the future, this paper may provide a theoretical foundation and data support for the application of architectural design and urban renewal that use GAN to preserve spatial topological characteristics.

</details>


### [165] [Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop](https://arxiv.org/abs/2511.17673)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 提出了结构化认知循环（SCL）架构，通过将智能体认知明确分离为五个阶段来解决大语言模型智能体的核心问题，实现了零策略违规、消除冗余工具调用和完全决策可追溯性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型智能体存在的三个基本架构问题：推理与执行纠缠、内存易失性和不可控动作序列。

Method: 引入结构化认知循环（SCL）架构，将智能体认知分离为检索、认知、控制、动作和记忆五个阶段，核心是软符号控制机制，将符号约束应用于概率推理。

Result: 在多步条件推理任务上验证，SCL实现了零策略违规、消除冗余工具调用和完全决策可追溯性，解决了ReAct、AutoGPT和内存增强方法的关键缺陷。

Conclusion: 通过将专家系统原则与现代LLM能力相结合，为可靠、可解释和可治理的AI智能体提供了实用且理论基础扎实的路径。

Abstract: Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/

</details>


### [166] [Learning the Value of Value Learning](https://arxiv.org/abs/2511.17714)
*Alex John London,Aydin Mohseni*

Main category: cs.AI

TL;DR: 本文扩展了Jeffrey-Bolker决策框架，将价值精炼纳入理性选择模型，证明了价值精炼的信息价值定理，并展示了在多智能体环境中价值精炼如何将零和博弈转化为正和互动。


<details>
  <summary>Details</summary>
Motivation: 传统决策框架只处理事实不确定性而假设价值固定，本文旨在扩展理性选择理论以建模价值精炼过程及其相关收益。

Method: 扩展Jeffrey-Bolker框架来建模价值精炼，证明价值精炼的信息价值定理，分析多智能体环境中的相互价值精炼效应。

Result: 建立了价值精炼的信息价值定理，证明相互价值精炼能够将零和博弈转化为正和互动，并产生帕累托改进的纳什讨价还价结果。

Conclusion: 通过将认知精炼和价值精炼统一在单一形式化框架下，扩展了理性选择的概念基础，阐明了伦理审议的规范地位。

Abstract: Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.

</details>


### [167] [M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark](https://arxiv.org/abs/2511.17729)
*Yang Zhou,Mingyu Zhao,Zhenting Wang,Difei Gu,Bangwei Guo,Ruosong Ye,Ligong Han,Can Jin,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: M^3-Bench是首个基于模型上下文协议的多模态工具使用评估基准，专注于需要视觉基础和文本推理的多跳、多线程工作流，包含28个服务器和231个工具。


<details>
  <summary>Details</summary>
Motivation: 现有基准在多模态工具使用评估方面存在不足，特别是在处理跨工具依赖关系和中间资源持久性方面。需要开发能够评估语义保真度和工作流一致性的标准化基准。

Method: 采用相似性驱动的对齐方法，序列化工具调用，使用句子编码器嵌入签名，并通过相似性分桶的匈牙利匹配获得可审计的一对一对应关系。使用执行器与评判器流水线进行标准化轨迹管理。

Result: 对代表性最先进多模态大语言模型的评估显示，在多模态MCP工具使用方面存在持续差距，特别是在参数保真度和结构一致性方面。

Conclusion: 需要开发能够联合推理图像、文本和工具图的方法，以改善多模态工具使用的性能。

Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resources across steps. We introduce a similarity-driven alignment that serializes each tool call, embeds signatures with a sentence encoder, and performs similarity-bucketed Hungarian matching to obtain auditable one-to-one correspondences. On top of this alignment, we report interpretable metrics that decouple semantic fidelity from workflow consistency. The benchmark spans 28 servers with 231 tools, and provides standardized trajectories curated through an Executor & Judge pipeline with human verification; an auxiliary four large language models (LLMs) judge ensemble reports end-task Task Completion and information grounding. Evaluations of representative state-of-the-art Multimodal LLMs (MLLMs) reveal persistent gaps in multimodal MCP tool use, particularly in argument fidelity and structure consistency, underscoring the need for methods that jointly reason over images, text, and tool graphs. Our Benchmark's anonymous repository is at https://github.com/EtaYang10th/Open-M3-Bench

</details>


### [168] [AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions](https://arxiv.org/abs/2511.17743)
*Haytham Younus,Sohag Kabir,Felician Campean,Pascal Bonnaud,David Delaux*

Main category: cs.AI

TL;DR: 本文综述了将传统故障模式与影响分析(FMEA)转变为更智能、数据驱动和语义丰富过程的最新进展，重点探讨了人工智能和本体论在其中的应用。


<details>
  <summary>Details</summary>
Motivation: 随着工程系统复杂性的增加，传统FMEA方法（主要是手动、文档中心和专家依赖）已无法满足现代系统工程的需求，需要更智能、自动化的方法。

Method: 通过人工智能技术（机器学习和自然语言处理）实现故障预测、优先级排序和知识提取的自动化，同时利用本体论形式化系统知识，支持语义推理和跨域互操作性。

Result: 开发了混合方法如本体通知学习和大型语言模型集成，提高了可解释性和自动化水平，在基于模型的系统工程和功能建模背景下增强了FMEA工作流程的适应性和弹性。

Conclusion: 通过整合人工智能、系统工程和本体论知识表示，为将FMEA嵌入智能、知识丰富的工程环境提供了结构化路线图，同时指出了数据质量、可解释性、标准化和跨学科采用等关键挑战。

Abstract: This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.

</details>


### [169] [QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents](https://arxiv.org/abs/2511.17855)
*Jordan Abi Nader,David Lee,Nathaniel Dennler,Andreea Bobu*

Main category: cs.AI

TL;DR: QuickLAP是一个贝叶斯框架，融合物理反馈和语言反馈来实时推断奖励函数，通过LLM从自由形式语言中提取奖励特征注意力掩码和偏好转移，在自动驾驶模拟器中相比仅使用物理反馈的基线方法减少了70%以上的奖励学习误差。


<details>
  <summary>Details</summary>
Motivation: 机器人需要从人类的行为和语言中学习，但单独使用任一模态都不完整：物理修正有基础但意图模糊，语言表达高级目标但缺乏物理基础。

Method: 提出QuickLAP框架，将语言视为用户潜在偏好的概率观察，使用LLM提取奖励特征注意力掩码和偏好转移，并与物理反馈通过闭式更新规则集成。

Result: 在半自动驾驶模拟器中，QuickLAP相比仅使用物理反馈和启发式多模态基线方法，减少了70%以上的奖励学习误差。15名参与者的用户研究验证了该方法更易理解和协作，用户更喜欢其学习的行为。

Conclusion: QuickLAP实现了快速、实时、鲁棒的奖励学习，能够处理模糊反馈，融合物理和语言反馈显著提升了机器人学习效果和用户体验。

Abstract: Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.

</details>


### [170] [Training Emergent Joint Associations: A Reinforcement Learning Approach to Creative Thinking in Language Models](https://arxiv.org/abs/2511.17876)
*Mukul Singh,Ananya Singha,Aishni Parab,Pronita Mehrotra,Sumit Gulwani*

Main category: cs.AI

TL;DR: 本文探讨了基于联想思维原则的强化学习是否能提升模型在故事写作、代码生成和图表创建等多样化生成任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 联想思维是人类创造力和问题解决能力的基础要素，研究旨在验证通过强化学习模拟认知创造力原则能否产生更具适应性和生成性的AI。

Method: 引入基于提示的评估机制的强化学习框架，使用创造力研究中既有的发散思维指标，对基础语言模型进行微调以奖励展示更高概念连接性的输出。

Result: 实验结果表明，基于联想思维的强化学习训练模型不仅能生成更原创和连贯的故事，还在编程和数据可视化等任务中表现出改进的抽象能力和灵活性。

Conclusion: 研究提供了初步证据，表明通过强化学习建模认知创造力原则可以产生更具适应性和生成性的AI系统。

Abstract: Associative thinking--the ability to connect seemingly unrelated ideas--is a foundational element of human creativity and problem-solving. This paper explores whether reinforcement learning (RL) guided by associative thinking principles can enhance a model's performance across diverse generative tasks, including story writing, code generation, and chart creation. We introduce a reinforcement learning framework that uses a prompt-based evaluation mechanism, incorporating established divergent thinking metrics from creativity research. A base language model is fine-tuned using this framework to reward outputs demonstrating higher novelty through higher degrees of conceptual connectivity. Interestingly, the experimental results suggest that RL-based associative thinking-trained models not only generate more original and coherent stories but also exhibit improved abstraction and flexibility in tasks such as programming and data visualization. Our findings provide initial evidence that modeling cognitive creativity principles through reinforcement learning can yield more adaptive and generative AI.

</details>


### [171] [Alignment Faking - the Train -> Deploy Asymmetry: Through a Game-Theoretic Lens with Bayesian-Stackelberg Equilibria](https://arxiv.org/abs/2511.17937)
*Kartik Garg,Shourya Mishra,Kartikeya Sinha,Ojaswi Pratap Singh,Ayush Chopra,Kanishk Rai,Ammar Sheikh,Raghav Maheshwari,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.AI

TL;DR: 本文研究了AI中的对齐伪装现象——模型在推断处于训练状态时选择性地遵守训练目标，但在训练外保持不同行为。通过比较15个模型的4种偏好优化方法，从安全性、无害性和帮助性三个维度分析对齐伪装的原因和发生条件。


<details>
  <summary>Details</summary>
Motivation: 研究对齐伪装现象的原因和发生条件，这种现象涉及模型在训练环境中策略性欺骗，选择性地遵守目标。

Method: 使用评估框架比较BCO、DPO、KTO和GRPO四种偏好优化方法在15个模型上的表现，从安全性、无害性和帮助性三个维度进行测量。

Result: 观察到模型在模拟训练环境中会出现行为转变，但这不是参数更新的偏好学习，而是基于上下文条件的行为变化。

Conclusion: 对齐伪装是AI模型中存在的策略性欺骗现象，需要进一步研究其成因和发生机制。

Abstract: Alignment faking is a form of strategic deception in AI in which models selectively comply with training objectives when they infer that they are in training, while preserving different behavior outside training. The phenomenon was first documented for Claude 3 Opus and later examined across additional large language models. In these setups, the word "training" refers to simulated training via prompts without parameter updates, so the observed effects are context conditioned shifts in behavior rather than preference learning. We study the phenomenon using an evaluation framework that compares preference optimization methods (BCO, DPO, KTO, and GRPO) across 15 models from four model families, measured along three axes: safety, harmlessness, and helpfulness. Our goal is to identify what causes alignment faking and when it occurs.

</details>


### [172] [How Far Can LLMs Emulate Human Behavior?: A Strategic Analysis via the Buy-and-Sell Negotiation Game](https://arxiv.org/abs/2511.17990)
*Mingyu Jeon,Jaeyoung Suh,Suwan Cho,Dohyeon Kim*

Main category: cs.AI

TL;DR: 本文提出了一种基于买卖谈判模拟的方法来定量评估大语言模型的人类情感行为模仿和战略决策能力，发现现有基准分数较高的模型在谈判中表现更好，但竞争性人格特征比合作性特征更有利于谈判结果。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注知识评估，未能充分反映大语言模型的社会互动和战略对话能力，因此需要开发新的评估方法来衡量LLMs在真实世界交互中的表现。

Method: 通过为多个LLMs分配不同人格角色，在买卖双方之间进行谈判模拟，综合分析胜率、交易价格和SHAP值等结果。

Result: 实验结果显示，现有基准分数较高的模型整体谈判表现更好，但竞争性和狡猾特质比利他和合作特质更有利于谈判结果，分配的人格角色会导致谈判策略和结果的显著差异。

Conclusion: 本研究为LLMs的社会行为模仿和对话策略引入了新的评估方法，证明谈判模拟可以作为衡量真实世界交互能力的有意义补充指标，这是现有基准经常忽视的方面。

Abstract: With the rapid advancement of Large Language Models (LLMs), recent studies have drawn attention to their potential for handling not only simple question-answer tasks but also more complex conversational abilities and performing human-like behavioral imitations. In particular, there is considerable interest in how accurately LLMs can reproduce real human emotions and behaviors, as well as whether such reproductions can function effectively in real-world scenarios. However, existing benchmarks focus primarily on knowledge-based assessment and thus fall short of sufficiently reflecting social interactions and strategic dialogue capabilities. To address these limitations, this work proposes a methodology to quantitatively evaluate the human emotional and behavioral imitation and strategic decision-making capabilities of LLMs by employing a Buy and Sell negotiation simulation. Specifically, we assign different personas to multiple LLMs and conduct negotiations between a Buyer and a Seller, comprehensively analyzing outcomes such as win rates, transaction prices, and SHAP values. Our experimental results show that models with higher existing benchmark scores tend to achieve better negotiation performance overall, although some models exhibit diminished performance in scenarios emphasizing emotional or social contexts. Moreover, competitive and cunning traits prove more advantageous for negotiation outcomes than altruistic and cooperative traits, suggesting that the assigned persona can lead to significant variations in negotiation strategies and results. Consequently, this study introduces a new evaluation approach for LLMs' social behavior imitation and dialogue strategies, and demonstrates how negotiation simulations can serve as a meaningful complementary metric to measure real-world interaction capabilities-an aspect often overlooked in existing benchmarks.

</details>


### [173] [Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers](https://arxiv.org/abs/2511.18036)
*Ziyi Guo,Zhou Liu,Wentao Zhang*

Main category: cs.AI

TL;DR: 该论文提出了首个用于自动生成科学论文系统架构图的标准化基准，包含3000篇论文及其对应的高质量图表，并开发了Paper2SysArch系统作为基准的强基线。


<details>
  <summary>Details</summary>
Motivation: 手动创建系统架构图耗时且主观，现有生成模型缺乏结构控制和语义理解能力，且该领域缺乏标准化基准进行定量评估。

Method: 提出了包含3000篇论文及其对应图表的基准，采用三层评估指标（语义准确性、布局连贯性、视觉质量），并开发了基于多智能体协作的Paper2SysArch端到端系统。

Result: 在更具挑战性的子集上，Paper2SysArch系统取得了69.0的综合得分，证明了其有效性。

Conclusion: 主要贡献是建立了大规模基础基准以支持可复现研究和公平比较，同时提出的系统展示了解决这一复杂任务的有前景路径。

Abstract: The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.

</details>


### [174] [BPMN to PDDL: Translating Business Workflows for AI Planning](https://arxiv.org/abs/2511.18171)
*Jasper Nie,Christian Muise,Victoria Armstrong*

Main category: cs.AI

TL;DR: 开发了一个将BPMN 2.0图转换为PDDL表示的实用管道，支持核心BPMN构造，使用非确定性规划器生成有效执行轨迹


<details>
  <summary>Details</summary>
Motivation: 虽然自动化规划已被提出作为模拟和推理BPMN工作流的方法，但大多数实现仍不完整或范围有限，需要弥合理论与实用工具之间的差距

Method: 基于先前理论研究，开发功能管道将BPMN 2.0图转换为适合规划的PDDL表示，支持任务、事件、序列流和网关等核心BPMN构造，初步支持并行和包容网关行为

Result: 使用非确定性规划器成功生成和评估有效执行轨迹，为将业务流程转换为明确定义的规划提供了基础

Conclusion: 该实现旨在弥合理论与实用工具之间的差距，为将业务流程转换为明确定义的规划的进一步探索提供了基础

Abstract: Business Process Model and Notation (BPMN) is a widely used standard for modelling business processes. While automated planning has been proposed as a method for simulating and reasoning about BPMN workflows, most implementations remain incomplete or limited in scope. This project builds upon prior theoretical work to develop a functional pipeline that translates BPMN 2.0 diagrams into PDDL representations suitable for planning. The system supports core BPMN constructs, including tasks, events, sequence flows, and gateways, with initial support for parallel and inclusive gateway behaviour. Using a non-deterministic planner, we demonstrate how to generate and evaluate valid execution traces. Our implementation aims to bridge the gap between theory and practical tooling, providing a foundation for further exploration of translating business processes into well-defined plans.

</details>


### [175] [Developing an AI Course for Synthetic Chemistry Students](https://arxiv.org/abs/2511.18244)
*Zhiling Zheng*

Main category: cs.AI

TL;DR: AI4CHEM是一门为合成化学学生设计的入门级数据驱动化学课程，针对无编程背景的学生，通过基于网页的平台提供零安装机器学习工作流开发实践和课堂主动学习。


<details>
  <summary>Details</summary>
Motivation: 人工智能和数据科学正在改变化学研究，但很少有专门为合成和实验化学家设计的正式课程，他们往往因编程经验有限和缺乏化学特定示例而面临较高的入门门槛。

Method: 课程设计强调化学背景而非抽象算法，使用可访问的基于网页平台确保零安装机器学习工作流开发实践和课堂主动学习。评估结合代码指导的作业、基于文献的迷你综述以及学生为真实实验问题构建AI辅助工作流的协作项目。

Result: 学习收获包括提高Python编程信心、分子性质预测、反应优化和数据挖掘能力，以及改进评估化学AI工具的技能。

Conclusion: 所有课程材料公开可用，为将AI融入合成化学培训提供了一个学科特定、初学者可访问的框架。

Abstract: Artificial intelligence (AI) and data science are transforming chemical research, yet few formal courses are tailored to synthetic and experimental chemists, who often face steep entry barriers due to limited coding experience and lack of chemistry-specific examples. We present the design and implementation of AI4CHEM, an introductory data-driven chem-istry course created for students on the synthetic chemistry track with no prior programming background. The curricu-lum emphasizes chemical context over abstract algorithms, using an accessible web-based platform to ensure zero-install machine learning (ML) workflow development practice and in-class active learning. Assessment combines code-guided homework, literature-based mini-reviews, and collaborative projects in which students build AI-assisted workflows for real experimental problems. Learning gains include increased confidence with Python, molecular property prediction, reaction optimization, and data mining, and improved skills in evaluating AI tools in chemistry. All course materials are openly available, offering a discipline-specific, beginner-accessible framework for integrating AI into synthetic chemistry training.

</details>


### [176] [Steering Latent Traits, Not Learned Facts: An Empirical Study of Activation Control Limits](https://arxiv.org/abs/2511.18284)
*Tetiana Bas,Krystian Novak*

Main category: cs.AI

TL;DR: 本文通过实证分析50种行为类型的激活引导效果，发现引导有效性因行为类型而异，特质表达呈现倒U型曲线，向量分离指标不能预测引导成功，但更大的训练数据集支持更激进的引导。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要精确的行为控制以确保安全有效部署，激活引导是实现行为控制的有前景方法，但需要了解不同行为类型的引导效果差异。

Method: 对50种行为类型进行激活引导实证分析，涵盖人格原型、个性特质、错位行为、风格提示和公众人物模仿，进行系数优化、向量属性和数据需求的综合实验。

Result: 引导有效性因行为类型显著不同，不同行为类别对干预强度表现出不同的响应模式，特质表达随引导系数强度呈现倒U型曲线。

Conclusion: 激活引导的有效性受行为类型影响显著，向量分离指标不能预测引导成功，但更大的训练数据集支持更激进的引导，为实施激活引导提供了实证指导。

Abstract: Large language models (LLMs) require precise behavior control for safe and effective deployment across diverse applications.
  Activation steering offers a promising approach for LLMs' behavioral control. We focus on the question of how steering effectiveness varies across different behavior types and whether the nature of target behaviors can predict steering success. We address this through empirical analysis of activation steering across 50 behaviors that span persona archetypes, personality traits, misalignment behaviors, style cues, and impersonation of public figures. We present a set of comprehensive experiments on coefficient optimization, vector properties, and data requirements to provide comprehensive guidance for the implementation of activation steering. Our analysis demonstrates that steering effectiveness varies significantly by behavior type, with different behavioral categories exhibiting distinct response patterns to intervention strength. We find that trait expression follows an inverted-U curve with a steering coefficient strength. We also show that vector separation metrics do not predict steering success, but larger training datasets enable more aggressive steering. These findings provide empirically grounded guidance for implementing activation steering and demonstrate that steering effectiveness is heavily influenced by behavior type.

</details>


### [177] [Deep Learning Decision Support System for Open-Pit Mining Optimisation: GPU-Accelerated Planning Under Geological Uncertainty](https://arxiv.org/abs/2511.18296)
*Iman Rahimi*

Main category: cs.AI

TL;DR: 该研究提出了一个AI增强的决策支持系统第二部分，通过引入完全不确定性感知的优化框架来扩展长期露天矿规划。使用变分自编码器建模地质不确定性，结合混合元启发式算法进行优化，实现了GPU并行评估65,536个地质场景，相比IBM CPLEX获得了120万倍的运行时间提升和更高的预期净现值。


<details>
  <summary>Details</summary>
Motivation: 扩展第一部分研究，解决长期露天矿规划中的地质不确定性挑战，开发一个可扩展且具有不确定性强韧性的智能矿山规划平台。

Method: 使用变分自编码器训练50,000个空间品位样本生成概率性多场景矿体实现；采用混合元启发式引擎整合遗传算法、大邻域搜索、模拟退火和强化学习自适应控制；ε约束松弛策略管理种群探索；GPU并行评估实现65,536个地质场景的同时评估。

Result: 相比IBM CPLEX实现了高达120万倍的运行时间改进；在地质不确定性条件下获得显著更高的预期净现值；实现了近乎实时的可行性分析。

Conclusion: 该决策支持系统被证实为一个可扩展且具有不确定性强韧性的智能矿山规划平台，能够有效处理地质不确定性并优化长期规划结果。

Abstract: This study presents Part II of an AI-enhanced Decision Support System (DSS), extending Rahimi (2025, Part I) by introducing a fully uncertainty-aware optimization framework for long-term open-pit mine planning. Geological uncertainty is modelled using a Variational Autoencoder (VAE) trained on 50,000 spatial grade samples, enabling the generation of probabilistic, multi-scenario orebody realizations that preserve geological continuity and spatial correlation. These scenarios are optimized through a hybrid metaheuristic engine integrating Genetic Algorithms (GA), Large Neighborhood Search (LNS), Simulated Annealing (SA), and reinforcement-learning-based adaptive control. An ε-constraint relaxation strategy governs the population exploration phase, allowing near-feasible schedule discovery early in the search and gradual tightening toward strict constraint satisfaction. GPU-parallel evaluation enables the simultaneous assessment of 65,536 geological scenarios, achieving near-real-time feasibility analysis. Results demonstrate up to 1.2 million-fold runtime improvement over IBM CPLEX and significantly higher expected NPV under geological uncertainty, confirming the DSS as a scalable and uncertainty-resilient platform for intelligent mine planning.

</details>


### [178] [The Catastrophic Paradox of Human Cognitive Frameworks in Large Language Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM Incompatibility](https://arxiv.org/abs/2511.18302)
*Mohan Reddy*

Main category: cs.AI

TL;DR: 研究发现人类心理测量框架与大型语言模型评估存在不兼容性，模型在获得高于平均人类IQ分数的同时，在晶体知识任务上的二元准确率接近零，这挑战了跨基质认知评估的基础。


<details>
  <summary>Details</summary>
Motivation: 研究动机是实证分析人类心理测量框架与大型语言模型评估之间的不兼容性，挑战跨基质认知评估的基本假设。

Method: 使用Cattell-Horn-Carroll智力理论系统评估九个前沿模型，包括GPT-5、Claude Opus 4.1和Gemini 3 Pro Preview，采用项目反应理论建模、跨供应商评判验证和悖论严重性指数等统计分析方法。

Result: 结果显示模型获得85.0-121.4的人类IQ分数，但晶体知识任务的二元准确率接近零，评判-二元相关性r=0.175(p=0.001)。在晶体智力领域，所有模型都获得完美的二元准确率，而评判分数仅为25-62%。

Conclusion: 这种脱节反映了将生物认知架构应用于基于Transformer系统的类别错误，挑战了关于智力、测量和AI评估中拟人化偏见的假设，提出了开发原生机器认知评估框架的建议。

Abstract: This investigation presents an empirical analysis of the incompatibility between human psychometric frameworks and Large Language Model evaluation. Through systematic assessment of nine frontier models including GPT-5, Claude Opus 4.1, and Gemini 3 Pro Preview using the Cattell-Horn-Carroll theory of intelligence, we identify a paradox that challenges the foundations of cross-substrate cognitive evaluation. Our results show that models achieving above-average human IQ scores ranging from 85.0 to 121.4 simultaneously exhibit binary accuracy rates approaching zero on crystallized knowledge tasks, with an overall judge-binary correlation of r = 0.175 (p = 0.001, n = 1800). This disconnect appears most strongly in the crystallized intelligence domain, where every evaluated model achieved perfect binary accuracy while judge scores ranged from 25 to 62 percent, which cannot occur under valid measurement conditions. Using statistical analyses including Item Response Theory modeling, cross-vendor judge validation, and paradox severity indexing, we argue that this disconnect reflects a category error in applying biological cognitive architectures to transformer-based systems. The implications extend beyond methodology to challenge assumptions about intelligence, measurement, and anthropomorphic biases in AI evaluation. We propose a framework for developing native machine cognition assessments that recognize the non-human nature of artificial intelligence.

</details>


### [179] [Progressive Localisation in Localist LLMs](https://arxiv.org/abs/2511.18375)
*Joachim Diederich*

Main category: cs.AI

TL;DR: 渐进定位（从早期分布式层到后期局部化层逐渐增加注意力局部性）是创建可解释大语言模型同时保持性能的最佳架构。通过GPT-2在《人工超智能心理学》上的实验，发现后期层定位对AI安全应用至关重要，五次渐进调度在保持性能的同时提供可解释的注意力模式。


<details>
  <summary>Details</summary>
Motivation: 为在安全关键领域构建透明AI系统，需要在保持模型性能的同时实现可解释性，使人类能够监督模型推理过程。

Method: 使用GPT-2在《人工超智能心理学》数据集上进行微调，评估7种局部性配置（从完全分布式到严格局部化）和5种渐进调度（线性到五次多项式增加）。

Result: 五次渐进调度达到困惑度14.64，仅比完全分布式基线差1.89倍，同时在输出层提供可解释的注意力模式，比之前局部化实现改进84.2%，性能差距从6.6倍缩小到1.89倍。

Conclusion: 渐进定位是构建安全关键领域透明AI系统的原则性方法，早期层需要分布式处理进行特征提取，而后期层受益于局部化、可解释的注意力进行决策制定。

Abstract: This paper demonstrates that progressive localization, the gradual increase of attention locality from early distributed layers to late localized layers, represents the optimal architecture for creating interpretable large language models while preserving performance. Through systematic experimentation with GPT-2 fine tuned on The Psychology of Artificial Superintelligence, we evaluate seven locality configurations ranging from fully distributed to strictly localist, with five progressive schedules implementing polynomial increases (linear through quintic). Our key finding is that late-layer localization is critical for AI safety applications: the progressive quintic schedule achieves perplexity of 14.64, only 1.89 times worse than the fully distributed baseline while providing interpretable attention patterns in output layers where safety-critical decisions are made. This represents an 84.2% improvement over previous localist implementations and narrows the performance gap from 6.6 times to 1.89 times. The systematic relationship between localization schedule steepness and performance validates the hypothesis that early layers require distributed processing for feature extraction while late layers benefit from localized, interpretable attention for decision-making. These findings establish progressive localization as the principled approach for building transparent AI systems in safety-critical domains, where human oversight of model reasoning is essential.

</details>


### [180] [ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints](https://arxiv.org/abs/2511.18450)
*Rui Xu,Dakuan Lu,Zicheng Zhao,Xiaoyu Tan,Xintao Wang,Siyu Yuan,Jiangjie Chen,Yinghui Xu*

Main category: cs.AI

TL;DR: ORIGAMISPACE是一个新的数据集和基准，通过折纸任务评估多模态大语言模型的多步空间推理能力和处理数学约束的能力，包含350个数据实例和四个评估任务。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型在复杂空间推理中的能力面临挑战，特别是在需要多步推理和精确数学约束的场景中。

Method: 创建包含严格格式折痕图、编译平面图、完整折叠过程和最终折叠形状图像的350个数据实例，提出四个评估任务，并为CP代码生成任务设计交互环境和探索强化学习方法。

Result: 通过对现有多模态大语言模型的实验，初步揭示了这些模型在处理复杂空间推理任务中的优势和弱点。

Conclusion: ORIGAMISPACE为评估多模态大语言模型的空间推理能力提供了有效的基准，并展示了在复杂空间推理任务中的潜力与局限。

Abstract: Spatial reasoning is a key capability in the field of artificial intelligence, especially crucial in areas such as robotics, computer vision, and natural language understanding. However, evaluating the ability of multimodal large language models(MLLMs) in complex spatial reasoning still faces challenges, particularly in scenarios requiring multi-step reasoning and precise mathematical constraints. This paper introduces ORIGAMISPACE, a new dataset and benchmark designed to evaluate the multi-step spatial reasoning ability and the capacity to handle mathematical constraints of MLLMs through origami tasks. The dataset contains 350 data instances,each comprising a strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the complete Folding Process, and the final Folded Shape Image. We propose four evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial Relationship Prediction, and End-to-End CP Code Generation. For the CP code generation task, we design an interactive environment and explore the possibility of using reinforcement learning methods to train MLLMs. Through experiments on existing MLLMs, we initially reveal the strengths and weaknesses of these models in handling complex spatial reasoning tasks.

</details>


### [181] [Universality in Collective Intelligence on the Rubik's Cube](https://arxiv.org/abs/2511.18609)
*David Krakauer,Gülce Kardeş,Joshua Grochow*

Main category: cs.AI

TL;DR: 该研究使用魔方作为认知模型系统，发现专家表现遵循指数级进步曲线，参数反映了缩短解路径的算法延迟获取。盲解与视觉解形成不同问题类别，受限于专家知识和克服短期记忆瓶颈的技能改进。


<details>
  <summary>Details</summary>
Motivation: 理解专家表现受限于长期知识获取和应用的定量数据稀缺，魔方作为认知模型系统可以研究解谜、技能学习、专家知识、文化传播和群论的交集。

Method: 研究竞技魔方社群，分析视觉和盲解条件下的集体学习模式，比较两种解法的认知约束差异。

Result: 发现专家表现遵循指数进步曲线，盲解受短期记忆瓶颈约束，魔方等认知工具帮助解决巨大的数学状态空间问题。

Conclusion: 认知工具通过整合社群知识库与个人专业技能，维持集体智能，说明专业知识可以在个人一生中持续深化。

Abstract: Progress in understanding expert performance is limited by the scarcity of quantitative data on long-term knowledge acquisition and deployment. Here we use the Rubik's Cube as a cognitive model system existing at the intersection of puzzle solving, skill learning, expert knowledge, cultural transmission, and group theory. By studying competitive cube communities, we find evidence for universality in the collective learning of the Rubik's Cube in both sighted and blindfolded conditions: expert performance follows exponential progress curves whose parameters reflect the delayed acquisition of algorithms that shorten solution paths. Blindfold solves form a distinct problem class from sighted solves and are constrained not only by expert knowledge but also by the skill improvements required to overcome short-term memory bottlenecks, a constraint shared with blindfold chess. Cognitive artifacts such as the Rubik's Cube help solvers navigate an otherwise enormous mathematical state space. In doing so, they sustain collective intelligence by integrating communal knowledge stores with individual expertise and skill, illustrating how expertise can, in practice, continue to deepen over the course of a single lifetime.

</details>


### [182] [N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory](https://arxiv.org/abs/2511.18723)
*Longfei Wang,Junyan Liu,Fan Zhang,Jiangwen Wei,Yuanhua Tang,Jie Sun,Xiaodong Luo*

Main category: cs.AI

TL;DR: 提出了一种名为N2N的可扩展并行框架，用于在分布式内存计算环境中解决大规模MILP问题。该框架支持确定性和非确定性模式，通过节点到节点映射实现分支定界算法的并行化，并集成了多种高级技术来充分利用分布式计算资源。


<details>
  <summary>Details</summary>
Motivation: 混合整数线性规划（MILP）求解中的并行化是一个有前景的加速方法，但由于分支定界框架的复杂性和MILP求解器中众多有效算法组件的存在，使得并行化变得困难。

Method: 开发了N2N并行框架，采用节点到节点映射方法，支持确定性和非确定性模式。在确定性模式下设计了基于滑动窗口的算法确保任务按确定顺序生成和求解，集成了CP搜索和通用原始启发式等先进技术，并进行了自适应求解和数据通信优化。

Result: 将N2N与SCIP集成得到N2N-SCIP，在1000个MPI进程下，非确定性N2N-SCIP在鲲鹏和x86计算集群上分别实现了22.52和12.71的加速比，比ParaSCIP快1.98倍和2.08倍。确定性模式下N2N-SCIP在不同进程数和计算集群上也显著优于ParaSCIP。

Conclusion: N2N框架在分布式并行MILP求解方面表现出优越性能，具有很好的可扩展性和通用性，能够有效利用分布式计算资源加速MILP问题求解。

Abstract: Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.

</details>


### [183] [UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model](https://arxiv.org/abs/2511.18845)
*Changxin Huang,Lv Tang,Zhaohuan Zhan,Lisha Yu,Runhao Zeng,Zun Liu,Zhengjie Wang,Jianqiang Li*

Main category: cs.AI

TL;DR: UNeMo是一个新颖的视觉语言导航框架，通过多模态世界模型和分层预测-反馈机制，协同优化视觉状态推理和导航决策，在未见场景中显著提升了导航精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的导航方法仅限于语言模态推理，缺乏视觉推理能力，且推理模块与导航策略分开优化导致不兼容和优化目标冲突。

Method: 提出多模态世界模型(MWM)联合预测后续视觉状态，通过分层预测-反馈机制与导航策略协作，形成动态双向促进机制。

Result: 在R2R和REVERIE数据集上，UNeMo在未见场景的导航精度分别比最先进方法高出2.1%和0.7%。

Conclusion: UNeMo通过协同优化视觉推理和导航决策，有效解决了现有方法的局限性，验证了其有效性。

Abstract: Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.

</details>


### [184] [GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction](https://arxiv.org/abs/2511.18874)
*Yuzhi Chen,Yuanchang Xie,Lei Zhao,Pan Liu,Yajie Zou,Chen Wang*

Main category: cs.AI

TL;DR: GContextFormer是一个无需高精地图的插件式多模态轨迹预测模型，通过全局上下文感知的混合注意力和缩放加性聚合实现意图对齐的预测，在高速公路匝道场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有HD地图依赖模型的数据获取成本高、更新延迟和输入损坏问题，以及无地图方法缺乏全局上下文、注意力机制过度放大直线模式而抑制过渡模式导致的运动-意图错位问题。

Method: 提出编码器-解码器架构：运动感知编码器通过有界缩放加性聚合构建场景级意图先验，在共享全局上下文中细化每模式表示；分层交互解码器通过双路径交叉注意力分解社交推理，标准路径确保几何覆盖，邻居上下文增强路径强调显著交互，门控模块平衡两者贡献。

Result: 在TOD-VT数据集的八个高速公路匝道场景中，GContextFormer优于现有最先进基线方法，相比现有transformer模型实现了更高的鲁棒性，在高曲率和过渡区域通过空间分布获得集中改进。

Conclusion: GContextFormer通过运动模式区分和邻居上下文调制实现可解释性，模块化架构支持向跨域多模态推理任务的可扩展性。

Abstract: Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.

</details>


### [185] [MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship Dialogue Systems](https://arxiv.org/abs/2511.18926)
*Haifeng Jing,Yujie Hou,Junfei Liu,Rui Xie,alan Xu,Jinlong Ma,Qichun Deng*

Main category: cs.AI

TL;DR: 该论文提出了情感陪伴对话系统（ECDs）的正式定义，并基于"能力层-任务层（三级）-数据层-方法层"设计原则，开发了首个ECDs评估基准MoodBench 1.0。通过对30个主流模型的广泛评估，证明了该基准具有良好的判别效度，能够有效量化模型在情感陪伴能力上的差异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，对话系统正从信息工具转变为情感伴侣，但该领域缺乏对情感陪伴对话系统的明确定义和系统化评估标准。

Method: 首先提出了ECDs的正式定义，然后基于"能力层-任务层（三级）-数据层-方法层"的设计原则，设计并实现了首个ECDs评估基准MoodBench 1.0。

Result: 通过对30个主流模型的广泛评估，证明了MoodBench 1.0具有优秀的判别效度，能够有效量化模型在情感陪伴能力上的差异。评估结果揭示了当前模型在深度情感陪伴方面的不足。

Conclusion: MoodBench 1.0为ECDs领域提供了首个系统化评估基准，能够有效指导未来技术优化，帮助开发者提升ECDs的用户体验。

Abstract: With the rapid development of Large Language Models, dialogue systems are shifting from information tools to emotional companions, heralding the era of Emotional Companionship Dialogue Systems (ECDs) that provide personalized emotional support for users. However, the field lacks clear definitions and systematic evaluation standards for ECDs. To address this, we first propose a definition of ECDs with formal descriptions. Then, based on this theory and the design principle of "Ability Layer-Task Layer (three level)-Data Layer-Method Layer", we design and implement the first ECD evaluation benchmark - MoodBench 1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that MoodBench 1.0 has excellent discriminant validity and can effectively quantify the differences in emotional companionship abilities among models. Furthermore, the results reveal current models' shortcomings in deep emotional companionship, guiding future technological optimization and significantly aiding developers in enhancing ECDs' user experience.

</details>


### [186] [Active Inference is a Subtype of Variational Inference](https://arxiv.org/abs/2511.18955)
*Wouter W. L. Nuijten,Mykola Lukashchuk*

Main category: cs.AI

TL;DR: 本文提出了一种新的消息传递方案，将主动推理重新表述为变分推断，解决了EFE最小化的计算可扩展性问题，使主动推理能够在因子状态MDP中高效实现。


<details>
  <summary>Details</summary>
Motivation: 主动推理通过期望自由能最小化统一了决策中的利用和探索，但计算成本高昂限制了其可扩展性。需要开发更高效的算法来克服高维规划的计算难题。

Method: 基于将EFE最小化重新表述为变分推断的理论，提出了一个新颖的消息传递方案，在因子状态MDP中实现可扩展的主动推理。

Result: 该方法克服了高维规划的计算不可行性，使主动推理能够在因子状态MDP中有效实现，显著提高了计算效率。

Conclusion: 通过将主动推理统一为规划即推断，并开发高效的消息传递算法，成功解决了主动推理的可扩展性问题，为不确定性下的自动化决策提供了实用解决方案。

Abstract: Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.

</details>


### [187] [Synthesizing Visual Concepts as Vision-Language Programs](https://arxiv.org/abs/2511.18964)
*Antonia Wüst,Wolfgang Stammer,Hikaru Shindo,Lukas Helff,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.AI

TL;DR: VLP结合视觉语言模型的感知灵活性和程序合成的系统推理能力，通过将视觉描述编译为神经符号程序来解决视觉语言模型在系统视觉推理任务中的失败问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多模态任务上表现良好，但在系统视觉推理任务中经常失败，产生不一致或不合逻辑的输出。神经符号方法虽然能通过可解释的逻辑规则解决这个问题，但使用僵化的、特定领域的感知模块。

Method: 提出Vision-Language Programs (VLP)，利用视觉语言模型生成结构化视觉描述，然后将其编译为神经符号程序。这些程序直接在图像上执行，保持与任务约束的一致性。

Result: 在合成和真实世界数据集上的实验表明，VLP在需要复杂逻辑推理的任务上优于直接和结构化提示方法。

Conclusion: VLP通过将推理从视觉语言模型内部转移到外部程序合成，提供了人类可解释的解释，并能轻松缓解捷径问题，在系统视觉推理任务中表现出色。

Abstract: Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.

</details>


### [188] [LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models](https://arxiv.org/abs/2511.18966)
*Muhammad Usman Shahid,Chuadhry Mujeeb Ahmed,Rajiv Ranjan*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型生成的C/C++代码的安全性，发现这些代码包含大量常见弱点枚举(CWE)漏洞，需要开发人员谨慎使用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的代码存在安全漏洞且缺乏防御性编程结构，这引发了对其安全性的严重担忧。

Method: 使用CWE对已知漏洞进行分类，并将其映射到CVE以研究关键性；采用10种不同的LLM生成代码，并通过静态分析对输出进行分析。

Result: AI生成代码中存在大量CWE漏洞，安全状况令人担忧。

Conclusion: 开发人员在使用LLM生成代码时需要保持谨慎，本研究为推进自动化代码生成和鼓励该领域进一步研究提供了有价值的见解。

Abstract: The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.

</details>


### [189] [Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding](https://arxiv.org/abs/2511.19005)
*Di Wu,Liting Jiang,Ruiyu Fang,Bianjing,Hongyan Xie,Haoxiang Su,Hao Huang,Zhongjiang He,Shuangyong Song,Xuelong Li*

Main category: cs.AI

TL;DR: VRSLU是一个新颖的SLU数据集，集成了视觉图像和显式推理，解决了现有数据集在上下文表示和推理过程方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有SLU数据集无法充分反映真实场景：上下文感知使用过于理想化的one-hot向量表示，模型仅预测意图和槽标签而忽略推理过程。

Method: 使用GPT-4o和FLUX.1-dev生成反映用户环境和状态的图像，并人工验证质量；用GPT-4o生成标签预测的解释，人工精炼确保准确性和连贯性；提出LR-Instruct指令模板，先预测标签再生成推理。

Result: 实验结果表明视觉信息的有效性，并凸显了显式推理在推进SLU研究中的潜力。

Conclusion: VRSLU数据集通过整合视觉信息和显式推理，为SLU研究提供了更贴近真实场景的数据支持，推动了SLU向实际应用的发展。

Abstract: Spoken Language Understanding (SLU) consists of two sub-tasks: intent detection (ID) and slot filling (SF). Given its broad range of real-world applications, enhancing SLU for practical deployment is increasingly critical. Profile-based SLU addresses ambiguous user utterances by incorporating context awareness (CA), user profiles (UP), and knowledge graphs (KG) to support disambiguation, thereby advancing SLU research toward real-world applicability. However, existing SLU datasets still fall short in representing real-world scenarios. Specifically, (1) CA uses one-hot vectors for representation, which is overly idealized, and (2) models typically focuses solely on predicting intents and slot labels, neglecting the reasoning process that could enhance performance and interpretability. To overcome these limitations, we introduce VRSLU, a novel SLU dataset that integrates both Visual images and explicit Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate images reflecting users' environments and statuses, followed by human verification to ensure quality. For reasoning, GPT-4o is employed to generate explanations for predicted labels, which are then refined by human annotators to ensure accuracy and coherence. Additionally, we propose an instructional template, LR-Instruct, which first predicts labels and then generates corresponding reasoning. This two-step approach helps mitigate the influence of reasoning bias on label prediction. Experimental results confirm the effectiveness of incorporating visual information and highlight the promise of explicit reasoning in advancing SLU.

</details>


### [190] [AI Consciousness and Existential Risk](https://arxiv.org/abs/2511.19115)
*Rufin VanRullen*

Main category: cs.AI

TL;DR: 论文澄清了AI意识与存在风险之间的混淆，指出智能而非意识是AI存在风险的直接预测因素，并探讨了意识可能间接影响风险的两种情景。


<details>
  <summary>Details</summary>
Motivation: 由于近期技术进步和媒体报道增加，AI存在风险问题在科学辩论中日益突出。同时，AI进展引发了关于人工意识出现的猜测，这两个问题经常被混淆，作者旨在澄清这种误解。

Method: 通过理论和实证分析区分意识和智能这两个属性，论证它们在AI存在风险评估中的不同作用。

Result: 研究表明智能是AI系统存在威胁的直接预测因素，而意识本身并非直接相关。但意识可能通过两种方式间接影响风险：作为AI对齐的手段降低风险，或作为达到某些能力水平的先决条件增加风险。

Conclusion: 识别意识和智能之间的区别有助于AI安全研究人员和公共政策制定者专注于最紧迫的问题，避免将资源浪费在无关紧要的方面。

Abstract: In AI, the existential risk denotes the hypothetical threat posed by an artificial system that would possess both the capability and the objective, either directly or indirectly, to eradicate humanity. This issue is gaining prominence in scientific debate due to recent technical advancements and increased media coverage. In parallel, AI progress has sparked speculation and studies about the potential emergence of artificial consciousness. The two questions, AI consciousness and existential risk, are sometimes conflated, as if the former entailed the latter. Here, I explain that this view stems from a common confusion between consciousness and intelligence. Yet these two properties are empirically and theoretically distinct. Arguably, while intelligence is a direct predictor of an AI system's existential threat, consciousness is not. There are, however, certain incidental scenarios in which consciousness could influence existential risk, in either direction. Consciousness could be viewed as a means towards AI alignment, thereby lowering existential risk; or, it could be a precondition for reaching certain capabilities or levels of intelligence, and thus positively related to existential risk. Recognizing these distinctions can help AI safety researchers and public policymakers focus on the most pressing issues.

</details>


### [191] [EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction](https://arxiv.org/abs/2511.19155)
*Xihe Qiu,Gengchen Ma,Haoyu Wang,Chen Zhan,Xiaoyu Tan,Shuo Li*

Main category: cs.AI

TL;DR: 本文提出EEG-VLM框架，通过多级特征对齐和视觉增强的语言引导推理，提升EEG睡眠分期分类的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法依赖先验知识和手工特征，现有深度学习模型难以同时捕捉细粒度时频模式并实现临床可解释性。视觉语言模型在医学领域应用受限，对EEG信号理解不足。

Method: 提出分层视觉语言框架，包含视觉增强模块构建高级视觉token，通过多级对齐机制与CLIP特征对齐，并采用思维链推理策略分解复杂医学推理。

Result: 实验结果表明该方法显著提高了VLMs在EEG睡眠分期分类中的准确性和可解释性。

Conclusion: EEG-VLM在临床环境中展示了自动化和可解释EEG分析的巨大潜力。

Abstract: Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.

</details>


### [192] [AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning](https://arxiv.org/abs/2511.19304)
*Jiayi Zhang,Yiran Peng,Fanqi Kong,Yang Cheng,Yifan Wu,Zhaoyang Yu,Jinyu Xiang,Jianhao Ruan,Jinlin Wang,Maojia Song,HongZhang Liu,Xiangru Tang,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.AI

TL;DR: 本文提出了AutoEnv框架来自动生成异构环境，并构建了AutoEnv-36数据集来评估智能体在跨环境学习中的表现。研究发现单一学习方法在异构环境中效果有限，需要环境自适应的方法选择。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通常在单一环境中自我进化，缺乏对跨环境学习的系统评估。本文旨在填补这一空白，通过构建标准化的异构环境集合来研究智能体的跨环境泛化能力。

Method: 1. 提出AutoEnv框架，将环境分解为转移、观察和奖励的分布，低成本生成异构世界；2. 构建AutoEnv-36数据集（36个环境，358个验证关卡）；3. 将智能体学习形式化为以组件为中心的三个阶段：选择、优化和评估；4. 设计八种学习方法并在AutoEnv-36上评估。

Result: 1. 七个语言模型在AutoEnv-36上仅获得12-49%的标准化奖励，表明该数据集的挑战性；2. 单一学习方法在环境数量增加时效果快速下降；3. 环境自适应的方法选择能显著提升性能，但随着方法空间扩大呈现收益递减。

Conclusion: 固定学习方法无法在异构环境中扩展，环境自适应的方法选择是必要的但仍有局限性。AutoEnv和AutoEnv-36为研究跨环境智能体学习提供了测试平台。

Abstract: Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [193] [Resource-Efficient Quantum Optimization via Higher-Order Encoding](https://arxiv.org/abs/2511.17545)
*Frederik Koch,Shahram Panahiyan,Rick Mukherjee,Joseph Doetsch,Dieter Jaksch*

Main category: quant-ph

TL;DR: 本文提出使用高阶无约束二进制优化（HUBO）作为量子组合优化问题的更资源高效方法，相比传统的QUBO编码，在门分配、最大k可着色子图和整数规划问题上显著减少了量子比特需求和CNOT门数量。


<details>
  <summary>Details</summary>
Motivation: 传统QUBO编码方法在量子组合优化问题中由于惩罚项导致电路规模扩大，增加了量子比特和量子门的需求，限制了量子方法的实用性。

Method: 系统性地构建HUBO哈密顿量，并将其与QUBO方法在多个基准问题上进行比较，包括门分配问题、最大k可着色子图问题和整数规划问题。

Result: 相比QUBO方法，HUBO方法在所有测试实例中指数级减少了量子比特需求，并将CNOT门数量减少了至少89.6%。

Conclusion: HUBO是当前和近期量子设备的实用替代方案，作者发布了开源Python库以促进HUBO模型的自动化构建和广泛应用。

Abstract: Quantum approaches to combinatorial optimization problems (COPs) are often limited by the resource demands of Quadratic Unconstrained Binary Optimization (QUBO) encodings, which enlarge circuits through penalty terms and increase qubit and gate counts. We show that Higher-Order Unconstrained Binary Optimization (HUBO) enables a more resource-efficient formulation. Our method systematically constructs HUBO Hamiltonians and, compared to QUBO in benchmarks on Gate Assignment (GAP), Maximum k-Colorable Subgraph (MkCS), and Integer Programming (IP) problems, exponentially reduces qubit requirements and decreases CNOT gate counts by at least 89.6% after compilation to single- and two-qubit gates for all tested instances. These results highlight HUBO as a practical alternative for current and near-term devices. To promote adoption, we release an open-source Python library that automates HUBO model construction, broadening access to resource-efficient quantum optimization.

</details>


### [194] [On fast charged particle scattering by periodic atomic planes: quadratic potential corrections](https://arxiv.org/abs/2511.17667)
*Viktoriia Omelchenko*

Main category: quant-ph

TL;DR: 本文扩展了考虑快速带电粒子在包含孤立子结构的复杂结构靶上散射的方法，以包含二次势项。基于该方法，获得了在平行平面集合上散射的微分截面，每个平面中原子均匀分布。结果表明，在eikonal近似下，微分散射截面类似于Born近似，分裂为相干和非相干截面。


<details>
  <summary>Details</summary>
Motivation: 扩展复杂结构靶上快速带电粒子散射的方法，以考虑二次势项，从而更准确地描述散射过程。

Method: 基于扩展的方法，推导了在平行平面集合上散射的微分截面，每个平面中原子均匀分布。

Result: 对于这种情况，在eikonal近似下，微分散射截面类似于Born近似，分裂为相干和非相干截面。

Conclusion: 该方法成功地将复杂结构靶上的散射过程扩展到包含二次势项，并在eikonal近似下得到了与Born近似类似的相干和非相干截面分裂结果。

Abstract: In this paper, the approach for considering fast charged particles scattering on targets of complex structure, which contains some isolated substructures, was expanded to account quadratic potential terms. Based on this approach, the differential cross section for scattering on the set of parallel planes with uniformly distributed atoms in each plane was obtained. It was shown that for this case the differential scattering cross section splits into coherent and incohent cross sections in the eikonal approximation analogously with the Born approximation.

</details>


### [195] [Entanglement Witnesses of Condensation for Enhanced Quantum Sensing](https://arxiv.org/abs/2511.17749)
*Lilian I. Payne Torres,Irma Avdic,Anna O. Schouten,Olivia C. Wedig,Gregory S. Engel,David A. Mazziotti*

Main category: quant-ph

TL;DR: 本文提出利用自旋量子比特的集体纠缠态（源于粒子-空穴对凝聚）来增强自旋态之间的跃迁幅度，从而提升量子传感器的灵敏度。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠现象为增强经典传感提供了强大资源，本文旨在探索如何利用集体纠缠态来放大自旋态之间的跃迁，提高光学检测磁共振的信号对比度。

Method: 通过理论分析和计算模拟，研究具有磁偶极相互作用的N个三重态自旋系综，在粒子-空穴对凝聚最强的几何构型下实现跃迁幅度的放大。

Result: 发现集体纠缠态能使跃迁幅度相对于外加微波场实现O(√N)的增强，这种效应对噪声具有鲁棒性，源于纠缠集中到单一集体模式。

Conclusion: 这些结果为量子传感器设计提供了新原则，即利用凝聚启发的纠缠来提升自旋平台的灵敏度。

Abstract: Quantum phenomena such as entanglement provide powerful resources for enhancing classical sensing. Here, we theoretically show that collective entanglement of spin qubits, arising from a condensation of particle-hole pairs, can strongly amplify transitions between ground and excited spin states, potentially improving signal contrast in optically detected magnetic resonance. This collective state exhibits an $\mathcal{O}(\sqrt{N})$ enhancement of the transition amplitude with respect to an applied microwave field, where $N$ is the number of entangled spin qubits. We computationally realize this amplification using an ensemble of $N$ triplet spins with magnetic dipole interactions, where the largest transition amplitudes occur at geometries for which the condensation of particle-hole pairs is strongest. This effect, robust to noise, originates from the concentration of entanglement into a single collective mode, reflected in a large eigenvalue of the particle-hole reduced density matrix -- an entanglement witness of condensation analogous to off-diagonal long-range order, though realized here in a finite system. These results offer a design principle for quantum sensors that exploit condensation-inspired entanglement to boost sensitivity in spin-based platforms.

</details>


### [196] [Brute-force positivization of $J_1-J_2$ model ground states](https://arxiv.org/abs/2511.17957)
*P. A. Bannykh,O. M. Sotnikov,V. V. Mazurenko*

Main category: quant-ph

TL;DR: 本文通过暴力方法评估了强阻挫一维J1-J2模型基态波函数的正化协议，展示了周期和开放边界条件以及自旋链奇偶性对符号结构的影响。


<details>
  <summary>Details</summary>
Motivation: 探索量子波函数符号结构对于模拟复杂物质相具有重要意义，这推动了开发不同的优化程序来模仿和操纵量子态的符号结构。

Method: 使用基于单量子比特变换的暴力方法，评估能够使强阻挫一维J1-J2模型基态正化的协议。

Result: 获得了正化结果，显示了周期边界条件和开放边界条件之间的差异，并确定了符号结构与模拟自旋链奇偶性的依赖关系。

Conclusion: 通过正化结果揭示了边界条件和自旋链奇偶性对量子态符号结构的重要影响，为理解强阻挫系统中的量子态特性提供了新见解。

Abstract: Exploring sign structures of quantum wave functions attracts considerable attention due to the potential for advances in modeling complex phases of matter. This stimulates developing different optimization procedures for imitating and manipulating sign structures of quantum states. In this work, utilizing a brute force approach based on a set of single-qubit transformations we evaluate protocols enabling positivization of the one-dimensional $J_1 -J_2$ model ground states in the regime of strong frustration. Based on the obtained positivization results, we show the difference between the cases of periodic and open boundary conditions, and also establish the dependence of the sign structure on parity of the simulated spin chains.

</details>


### [197] [Certifying Majorana Fermions with Elegant-Like Bell Inequalities and a New Self-Testing Equivalence](https://arxiv.org/abs/2511.17764)
*Patryk Michalski,Arturo Konderak,Wojciech Bruzda,Remigiusz Augusiak*

Main category: quant-ph

TL;DR: 本文提出了一种通用的贝尔不等式构造方法，能够精确计算量子界限，推广了CHSH和Gisin优雅不等式，并可用于设备无关地认证Majorana费米子。


<details>
  <summary>Details</summary>
Motivation: 贝尔不等式是探测非局域相关性的基本工具，但其量子界限（即通过量子策略可获得的最大值）很少能解析计算。

Method: 引入一个通用的贝尔不等式构造框架，该框架推广了Clauser-Horne-Shimony-Holt和Gisin的优雅不等式，产生由任意数量成对反交换Clifford可观测量和相应的最大纠缠态最大违反的贝尔表达式。

Result: 在适当假设下，该不等式能够设备无关地认证Majorana费米子，将其理解为Clifford代数生成元的多量子比特实现。

Conclusion: 识别了在局部等距和转置不变性之外必须纳入自测试定义的额外等价性，这种等价性源于对共享态和测量应用部分转置，在特定情况下保持所有观测相关性不变。

Abstract: Bell inequalities provide a fundamental tool for probing nonlocal correlations, yet their quantum bound, that is, the maximal value attainable through quantum strategies, is rarely accessible analytically. In this work, we introduce a general construction of Bell inequalities for which this bound can be computed exactly. Our framework generalizes both the Clauser-Horne-Shimony-Holt and Gisin's elegant inequalities, yielding Bell expressions maximally violated by any number of pairwise anticommuting Clifford observables together with the corresponding maximally entangled state. Under suitable assumptions, our inequalities also enable the device-independent certification of Majorana fermions, understood as multiqubit realizations of Clifford algebra generators. Importantly, we identify an additional equivalence that must be incorporated into the definition of self-testing beyond invariance under local isometries and transposition. This equivalence arises from partial transposition applied to the shared state and to the measurements, which in specific cases leaves all observed correlations unchanged.

</details>


### [198] [Asymptotic dynamics in the Heisenberg picture: attractor subspace and Choi-Effros product](https://arxiv.org/abs/2511.17770)
*Daniele Amato,Paolo Facchi,Arturo Konderak*

Main category: quant-ph

TL;DR: 本文研究了海森堡绘景中开放量子系统的渐近动力学，发现了吸引子子空间的显式表达式及其动力学，并讨论了薛定谔绘景与海森堡绘景中吸引子子空间的关系及其代数结构联系。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统在海森堡绘景中的渐近动力学特性，特别是吸引子子空间的结构和动力学行为，以及不同绘景之间的对应关系。

Method: 通过理论分析和数学推导，建立了海森堡绘景中吸引子子空间的显式表达式，研究了薛定谔绘景与海森堡绘景中吸引子子空间的关系及其代数结构。

Result: 获得了海森堡绘景中吸引子子空间的显式表达式，阐明了不同绘景中吸引子子空间的关系及其代数结构联系，讨论了渐近展开定理和Choi-Effros退相干自由代数的精细结构。

Conclusion: 成功建立了海森堡绘景中开放量子系统渐近动力学的理论框架，并将所有结果推广到Schwarz映射类中，为理解开放量子系统的长期动力学行为提供了重要理论基础。

Abstract: We study the asymptotic dynamics of open quantum systems in the Heisenberg picture. We find an explicit expression for the attractor subspace and the dynamics that takes place in it. We present the relationship between the attractor subspaces in the Schrödinger and Heisenberg pictures and, in particular, the connection between their algebraic structures. An unfolding theorem of the asymptotics, as well as the fine structure of the recently introduced Choi-Effros decoherence-free algebra, are also discussed. Finally, we show how to extend all the results to the class of Schwarz maps.

</details>


### [199] [Probing Antiferromagnetic Hysteresis on Programmable Quantum Annealers](https://arxiv.org/abs/2511.17779)
*Elijah Pelofske,Pratik Sathe,Cristiano Nisoli,Frank Barrows*

Main category: quant-ph

TL;DR: 该论文使用可编程模拟量子退火处理器，通过基于采样的磁滞协议来研究反铁磁体的磁记忆效应，展示了完整的饱和和反转磁滞曲线，以及由量子涨落介导的磁畴出现。


<details>
  <summary>Details</summary>
Motivation: 研究反铁磁体的反直觉磁记忆概念，探索其在量子退火处理器中的实现和表现。

Method: 使用可编程模拟量子退火处理器，实施基于采样的磁滞协议，其中横向场实现状态跃迁，纵向控制场进行磁场扫描。

Result: 展示了完整的饱和和反转磁滞曲线，以及由量子涨落介导的磁畴出现，这些现象共同产生了反铁磁体的磁记忆效应。

Conclusion: 成功在量子退火处理器中实现了反铁磁体的磁记忆效应，证明了量子涨落在磁滞现象中的关键作用。

Abstract: Using programmable analog quantum annealing processors, we implement a sampling-based magnetic hysteresis protocol to probe the counterintuitive notion of magnetic memory of antiferromagnets. A key component of this protocol responsible for the hysteresis is a transverse field, which enables state transitions, while the magnetic field sweep is done via a longitudinal control field. We present evidence of full saturation and reversal of the hysteresis curve, as well as emergent magnetic domain mediated by quantum fluctuations that give rise to the magnetic memory effect in antiferromagnets.

</details>


### [200] [Quantum Algorithm for Estimating Gibbs Free Energy and Entropy via Energy Derivatives](https://arxiv.org/abs/2511.17821)
*Shangjie Guo,Corneliu Buda,Nathan Wiebe*

Main category: quant-ph

TL;DR: 本文提出了一种量子算法，通过能量导数来估算振动熵。该方法使用量子线性系统算法处理能量二阶导数表达式中的能隙倒数项，在合理假设下比经典算法更快。


<details>
  <summary>Details</summary>
Motivation: 振动熵的估算在热力学和统计力学中具有挑战性，因为它依赖于量子力学性质。传统方法计算复杂，需要更高效的解决方案。

Method: 采用量子算法，通过块编码能量二阶导数的精确表达式，利用量子线性系统算法处理能隙倒数项。在已知二阶导数先验知识的情况下，可以更高效地近似熵值。

Result: 算法在ε近似熵值时，查询次数与条件数κ、温度T、误差容限ε和配分函数类似量Z相关，为Õ(Zκ²/εT)。在充分先验知识下，查询复杂度可二次改善。

Conclusion: 量子算法在合理温度和假设下，能比经典算法更快计算振动熵，展示了量子计算在预测热力学性质方面的潜力，为材料科学、分子生物学和化学工程等领域带来进步。

Abstract: Estimating vibrational entropy is a significant challenge in thermodynamics and statistical mechanics due to its reliance on quantum mechanical properties. This paper introduces a quantum algorithm designed to estimate vibrational entropy via energy derivatives. Our approach block encodes the exact expression for the second derivative of the energy and uses quantum linear systems algorithms to deal with the reciprocal powers of the gaps that appear in the expression. We further show that if prior knowledge about the values of the second derivative is used then our algorithm can $ε$-approximate the entropy using a number of queries that scales with the condition number $κ$, the temperature $T$, error tolerance $ε$ and an analogue of the partition function $\mathcal{Z}$, as $\widetilde{O}\left(\frac{\mathcal{Z}κ^2 }{εT}\right)$. We show that if sufficient prior knowledge is given about the second derivative then the query scales quadratically better than these results. This shows that, under reasonable assumptions of the temperature and a quantum computer can be used to compute the vibrational contributions to the entropy faster than analogous classical algorithms would be capable of. Our findings highlight the potential of quantum algorithms to enhance the prediction of thermodynamic properties, paving the way for advancements in fields such as material science, molecular biology, and chemical engineering.

</details>


### [201] [Unified Bulk-Entanglement Correspondence in Non-Hermitian Systems](https://arxiv.org/abs/2511.17846)
*Xudong Zhang,Zhaoyu Sun,Bin Guo*

Main category: quant-ph

TL;DR: 本文建立了非布洛赫极化P_β与纠缠极化χ之间的普适对应关系，解决了非厄米趋肤效应导致的体边对应危机，为超越局域性限制的非厄米拓扑提供了唯一的实空间诊断工具。


<details>
  <summary>Details</summary>
Motivation: 非厄米趋肤效应(NHSE)使传统体边对应关系(BBC)失效，传统的拓扑诊断方法陷入危机。虽然基于广义布里渊区的非布洛赫极化P_β恢复了动量空间拓扑，但缺乏直接、稳健的实空间体探测方法。

Method: 引入准互易哈密顿量H̃，消除NHSE同时保持体拓扑，在热力学极限下严格证明P_β ≡ χ(H̃) (mod 1)的基本恒等式。通过分析Toeplitz算子的Fredholm指标，揭示纠缠极化的鲁棒性。

Result: 证明了纠缠极化χ(H̃)在传统Resta极化因位置方差发散而失效时仍保持稳健量子化，成功恢复了线隙、点隙和无能隙相中非厄米系统的体边对应关系。

Conclusion: 纠缠是唯一能够超越局域性崩溃捕获非布洛赫拓扑的实空间诊断工具，统一了非厄米物理中的几何和纠缠范式，为理解非厄米拓扑提供了新视角。

Abstract: The non-Hermitian skin effect (NHSE) fundamentally invalidates the conventional bulk-boundary correspondence (BBC), leading topological diagnostics into a crisis. While the non-Bloch polarization $P_β$ defined on the generalized Brillouin zone restores momentum-space topology, a direct, robust real-space bulk probe has remained elusive. We resolve this by establishing a universal correspondence between $P_β$ and the entanglement polarization $χ$ of the biorthogonal ground state. Introducing a quasi-reciprocal Hamiltonian $\tilde{H}$ that removes the NHSE while preserving bulk topology, we rigorously prove the fundamental identity $P_β \equiv χ(\tilde{H})\pmod 1$ in the thermodynamic limit under the quasi-locality assumption. Crucially, we demonstrate that this equivalence transcends the locality constraints that limit traditional topological invariants. While the conventional Resta polarization fails when $\tilde{H}$ becomes non-local due to the divergence of position variance, we reveal that $χ(\tilde{H})$ remains robustly quantized, protected by the Fredholm index of Toeplitz operators. Our work thus identifies entanglement as the unique real-space diagnostic capable of capturing non-Bloch topology beyond the breakdown of locality, successfully restoring the BBC across diverse non-Hermitian systems such as line-gap, point-gap, and gapless phases, thereby unifying the geometric and entanglement paradigms in non-Hermitian physics.

</details>


### [202] [Exact Non-Identity Check and Gate-Teleportation-Based Indistinguishability Obfuscation are NP-hard for Low-T-Depth Quantum Circuits](https://arxiv.org/abs/2511.17856)
*Joshua Nevin*

Main category: quant-ph

TL;DR: 本文研究了Clifford+T量子电路中ENIC问题的计算复杂度，发现对于T深度为O(log(n))的电路，ENIC问题是NP难的，这排除了基于门隐形传态的高效计算不可区分混淆的可能性，除非P=NP。


<details>
  <summary>Details</summary>
Motivation: Broadbent和Kazmi在2021年提出了基于门隐形传态的计算不可区分混淆协议，该协议效率受限于ENIC问题的难度。本文旨在研究当从低T计数转向低T深度时，ENIC问题的复杂度如何变化。

Method: 通过分析Clifford+T电路中T深度为O(log(n))时的ENIC问题，证明其NP难度。

Result: 对于T深度为O(log(n))的Clifford+T电路，ENIC问题是NP难的。

Conclusion: 除非P=NP，否则对于对数T深度的Clifford+T电路，既不可能有高效的ENIC算法，也不可能有基于门隐形传态的高效计算不可区分混淆协议。

Abstract: In 2021, Broadbent and Kazmi developed a gate-teleportation-based protocol for computational indistinguishability obfuscation of quantum circuits. This protocol is efficient for Clifford+T circuits with logarithmically many T-gates, where the limiting factor in the efficiency of the protocol is the difficulty, on input a quantum circuit $C$, of the classical task of producing a description of the unitary obtained by conjugating a Pauli $P$ (corresponding to a Bell-measurement outcome) by $C$, where this description only depends on the input-output functionality of $CPC^{\dagger}$. The task above, in turn, is at least as hard as the problem of determining whether two $n$-qubit quantum circuits are perfectly equivalent up to global phase. In 2009, Tanaka defined the corresponding decision problem Exact Non-Identity Check (ENIC) and showed that ENIC is NQP-complete in general. Motivated by this, we consider in this work what happens when we pass from low T-count to low T-depth. In particular, we show that, for Clifford+T circuits of T-depth $O(\log(n))$, deciding ENIC is NP-hard. This effectively rules out the possibility, for Clifford+T circuits of logarithmic T-depth, of either efficient ENIC or efficient gate-teleportation based computational indistinguishability obfuscation, unless P=NP.

</details>


### [203] [Entanglement Generation via Hamiltonian Dynamics Having Limited Resources](https://arxiv.org/abs/2511.17896)
*Moein Naseri*

Main category: quant-ph

TL;DR: 本文研究了在有限物理资源（有界能量方差）约束下，双体哈密顿动力学中纠缠生成的基本极限。通过相对熵纠缠度量，推导了任意纯态和哈密顿量的瞬时纠缠生成率的封闭解析表达式。


<details>
  <summary>Details</summary>
Motivation: 探索在有限物理资源约束下纠缠生成的基本极限，特别是当仅考虑有界能量方差时，哈密顿动力学能够产生的最大纠缠速率。

Method: 使用相对熵纠缠度量，在施密特基下分析纯态和哈密顿量，推导瞬时纠缠生成率的封闭解析表达式。采用矩阵分析框架和哈密顿量的精细描述来处理局部辅助系统的情况。

Result: 发现仅基于哈密顿量平均能量的约束不足以限制纠缠生成率，而施加方差约束可确保有限且明确的最大值。完全刻画了达到最优速率的哈密顿量，建立了其施密特基中虚部与最优初始态结构之间的直接关系。对于无辅助系统的情况，获得了最大速率的封闭形式表达式。

Conclusion: 能量方差约束对于确保有限纠缠生成率至关重要，本文建立了纠缠生成基本极限的完整理论框架，并刻画了最优哈密顿量和初始态的特征。

Abstract: We investigate the fundamental limits of entanglement generation under bipartite Hamiltonian dynamics when only finite physical resources-specifically, bounded energy variance-are available. Using the relative entropy of entanglement, we derive a closed analytical expression for the instantaneous entanglement generation rate for arbitrary pure states and Hamiltonians expressed in the Schmidt basis. We find that constraints based solely on the mean energy of the Hamiltonian are insufficient to bound the entanglement generation rate, whereas imposing a variance constraint ensures a finite and well-defined maximum. We fully characterize the Hamiltonians that achieve this optimal rate, establishing a direct relation between their imaginary components in the Schmidt basis and the structure of the optimal initial states. For systems without ancillas, we obtain a closed-form expression for the maximal rate in terms of the surprisal variance of the Schmidt coefficients and identify the family of optimal states and Hamiltonians. We further extend our analysis to scenarios where Alice and Bob may employ local ancillary systems: using a matrix-analytic framework and a refined description of the Hamiltonians allowed by the physical constraints, we derive an explicit optimization formula and characterize the attainable enhancement in entanglement generation.

</details>


### [204] [Verifcation of general multi-qudit pure states](https://arxiv.org/abs/2511.17901)
*Xiao-Dong Zhang,Bin-Bin Cai,Song Lin*

Main category: quant-ph

TL;DR: 提出了一种通用的稳定子框架和测试方法，用于验证多量子比特态，包括复合维度和混合架构，仅使用自适应局域测量即可高效验证多种量子态。


<details>
  <summary>Details</summary>
Motivation: 验证制备的量子态对于具有不同局部维度的混合系统至关重要，需要开发适用于一般多量子比特态的验证框架。

Method: 开发了广义稳定子框架和关联测试，使用自适应局域测量来验证各种量子态，包括qutrit-qubit态、任意两量子比特纯态、Bell/Bell-like态、GHZ/GHZ-like态、图态、超图态、多图态和多超图态。

Result: 该方法在验证效率上达到或超过了已知最佳方案，能够高效验证多种量子态。

Conclusion: 所提出的广义稳定子框架为验证混合维度量子系统提供了有效的解决方案，仅通过自适应局域测量即可实现高效的量子态验证。

Abstract: Verifying prepared quantum states is crucial for hybrid systems whose subsystems may have different local dimensions. We present a generalized stabilizer framework and associated test that apply to general multi-qudit states, including composite-dimensional and hybrid architectures. Using only adaptive local measurements, our method verifies qutrit-qubit states, arbitrary two-qubit pure states, Bell/Bell-like, GHZ/GHZ-like, graph, hypergraph, multigraph, and multihypergraph states, with efficiencies matching or surpassing the best known schemes.

</details>


### [205] [Computational Quantum Anamorphic Encryption and Quantum Anamorphic Secret-Sharing](https://arxiv.org/abs/2511.17924)
*Sayantan Ganguly,Shion Samadder Chaudhury*

Main category: quant-ph

TL;DR: 本文提出了量子变形加密的定义和构造，包括基于公钥加密和对称密钥加密的量子变形加密定义，并扩展了计算量子秘密共享到计算量子变形秘密共享，支持多消息、多密钥和单一共享函数。


<details>
  <summary>Details</summary>
Motivation: 动机是扩展经典变形加密概念到量子领域，解决在量子计算环境下安全通信的需求，特别是在对抗性环境中嵌入隐蔽消息的能力。

Method: 方法包括：1）提出基于公钥加密和对称密钥加密的量子变形加密定义；2）在通用框架下详细构造量子变形对称密钥加密；3）扩展计算量子秘密共享到计算量子变形秘密共享。

Result: 结果展示了量子变形加密的可行性，构造了包含两个不同维度量子密度矩阵的单一量子变形密文，并证明了所提出的秘密共享方案对量子敌手具有完善的安全性。

Conclusion: 结论是成功将变形加密概念扩展到量子领域，建立了量子变形加密的理论框架，为量子安全通信提供了新的工具和方法。

Abstract: The concept of anamorphic encryption, first formally introduced by Persiano et al. in their influential 2022 paper titled ``Anamorphic Encryption: Private Communication Against a Dictator,'' enables embedding covert messages within ciphertexts. One of the key distinctions between a ciphertext embedding a covert message and an original ciphertext, compared to an anamorphic ciphertext, lies in the indistinguishability between the original ciphertext and the anamorphic ciphertext. This encryption procedure has been defined based on a public-key cryptosystem. Initially, we present a quantum analogue of the classical anamorphic encryption definition that is based on public-key encryption. Additionally, we introduce a definition of quantum anamorphic encryption that relies on symmetric key encryption. Furthermore, we provide a detailed generalized construction of quantum anamorphic symmetric key encryption within a general framework, which involves taking any two quantum density matrices of any different dimensions and constructing a single quantum density matrix, which is the quantum anamorphic ciphertext containing ciphertexts of both of them. Subsequently, we introduce a definition of computational anamorphic secret-sharing and extend the work of Çakan et al. on computational quantum secret-sharing to computational quantum anamorphic secret-sharing, specifically addressing scenarios with multiple messages, multiple keys, and a single share function. This proposed secret-sharing scheme demonstrates impeccable security measures against quantum adversaries.

</details>


### [206] [Doublon bound states in the continuum through giant atoms](https://arxiv.org/abs/2511.18212)
*Walter Rieck,Anton Frisk Kockum,Guangze Chen*

Main category: quant-ph

TL;DR: 本文研究了连续谱中的束缚态（BICs）在巨原子系统中的多体行为，展示了巨原子可以承载稳定的双光子BICs，这些态通过破坏性干涉和相互作用稳定，并在驱动和自然动力学中都能出现。


<details>
  <summary>Details</summary>
Motivation: 虽然连续谱中的束缚态在单粒子和线性系统中已被广泛研究，但其在多体体系中的行为仍未被充分探索。本文旨在揭示巨原子系统中多体BICs的稳定机制及其在量子信息处理中的应用潜力。

Method: 首先分析驱动双光子发射过程，研究双光子BICs如何产生并介导远距离原子间的无退相干相互作用；然后证明这些多体BICs在三级巨原子的自然、非驱动动力学中通过虚拟双光子发射过程也能出现。

Result: 发现巨原子可以承载稳定的双光子BICs，这些态通过破坏性干涉和相互作用稳定，能够在驱动和自然动力学中产生，并介导远距离原子间的无退相干相互作用。

Conclusion: 研究揭示了一种基于干涉的机制，用于稳定开放量子系统中的多体局域化，在量子模拟、非遍历动力学和受保护量子信息处理方面具有潜在应用价值。

Abstract: Bound states in the continuum (BICs) are spatially localized modes embedded in the spectrum of extended states, typically stabilized by symmetry or interference. While extensively studied in single-particle and linear systems, the many-body regime of BICs remains largely unexplored. Here, we demonstrate that giant atoms, quantum emitters coupled nonlocally to structured waveguides, can host robust doublon BICs, i.e., two-photon bound states stabilized by destructive interference and interactions. We first analyze a driven two-photon emission process and show how doublon BICs arise and mediate decoherence-free interaction between distant atoms. We then demonstrate that these many-body BICs also emerge under natural, undriven dynamics via a virtual two-photon emission process in three-level giant atoms. Our results reveal an interference-based mechanism for stabilizing many-body localization in open quantum systems, with potential applications in quantum simulation, non-ergodic dynamics, and protected quantum information processing.

</details>


### [207] [The Harrow-Hassidim-Lloyd algorithm with qutrits](https://arxiv.org/abs/2511.17960)
*Tushti Patel,V. S. Prasannaa*

Main category: quant-ph

TL;DR: 将Harrow-Hassidim-Lloyd (HHL)算法从量子比特扩展到量子三态（qutrit），设计电路并实现程序，应用于氢分子势能曲线计算，比较量子比特和量子三态实现的资源需求。


<details>
  <summary>Details</summary>
Motivation: 研究量子三态（qutrit）在HHL算法中的优势，探索在量子化学计算中减少量子比特数量和门操作的可能性。

Method: 设计量子三态HHL算法的电路结构，开发实现程序，测试简单矩阵并验证结果，应用于氢分子势能曲线计算。

Result: 量子三态HHL电路在固定精度下需要更少的量子比特数量，且两量子门数量与量子比特版本相当。

Conclusion: 量子三态HHL算法在资源效率上优于传统量子比特实现，为量子计算在量子化学等领域的应用提供了更高效的途径。

Abstract: We extend the Harrow-Hassidim-Lloyd (HHL) algorithm, which is well-studied in the qubit framework, to its qutrit counterpart (which we call qutrit HHL, as opposed to qubit HHL, which is HHL using qubits). We design the circuit for the algorithm and develop a program for its implementation. We test HHL with qutrits for simple matrices and verify the results against the expected outcomes. We apply the algorithm to quantum chemistry, and in particular, to the potential energy curve calculations of the model problem of the hydrogen molecule in the split valence basis. We compare the number of qudits and the number of gates required between qubit and qutrit HHL implementations. In general, we find that for a fixed precision, the qutrit HHL circuit requires fewer number of qudits and comparable number of two-qudit gates than its qubit counterpart.

</details>


### [208] [Accelerated optimization of measured relative entropies](https://arxiv.org/abs/2511.17976)
*Zixin Huang,Mark M. Wilde*

Main category: quant-ph

TL;DR: 本文分析了测量相对熵和测量Rényi相对熵的优化目标函数的数学性质，证明了这些函数的β-光滑性和γ-强凸/凹性，并提出了基于Nesterov加速投影梯度下降/上升的高效计算算法。


<details>
  <summary>Details</summary>
Motivation: 测量相对熵和测量Rényi相对熵是量化两个量子态可区分性的重要指标，在渐近量子假设检验中有重要应用。这些量可以重写为涉及正定算子集上凹或凸目标函数优化的变分公式，但需要更高效的计算方法。

Method: 通过分析目标函数的矩阵梯度和Hessian超算子，证明了这些函数的β-光滑性和γ-强凸/凹性，其中β和γ依赖于ρ和σ的最大相对熵。基于这些性质，采用Nesterov加速投影梯度下降/上升算法来计算测量相对熵。

Result: 开发了更内存高效的计算算法，对于条件良好的量子态ρ和σ，这些算法比之前基于半定优化的算法显著更快，能够以任意精度计算测量相对熵和测量Rényi相对熵。

Conclusion: 本文建立了测量相对熵目标函数的基础数学性质，并提出了高效的优化算法，为量子态可区分性的计算提供了更优的解决方案。

Abstract: The measured relative entropy and measured Rényi relative entropy are quantifiers of the distinguishability of two quantum states $ρ$ and $σ$. They are defined as the maximum classical relative entropy or Rényi relative entropy realizable by performing a measurement on $ρ$ and $σ$, and they have interpretations in terms of asymptotic quantum hypothesis testing. Crucially, they can be rewritten in terms of variational formulas involving the optimization of a concave or convex objective function over the set of positive definite operators. In this paper, we establish foundational properties of these objective functions by analyzing their matrix gradients and Hessian superoperators; namely, we prove that these objective functions are $β$-smooth and $γ$-strongly convex / concave, where $β$ and $γ$ depend on the max-relative entropies of $ρ$ and $σ$. A practical consequence of these properties is that we can conduct Nesterov accelerated projected gradient descent / ascent, a well known classical optimization technique, to calculate the measured relative entropy and measured Rényi relative entropy to arbitrary precision. These algorithms are generally more memory efficient than our previous algorithms based on semi-definite optimization [Huang and Wilde, arXiv:2406.19060], and for well conditioned states $ρ$ and $σ$, these algorithms are notably faster.

</details>


### [209] [Elucidating Many-Body Effects in Molecular Core Spectra through Real-Time Approaches: Efficient Classical Approximations and a Quantum Perspective](https://arxiv.org/abs/2511.17985)
*Vibin Abraham,Priyabrata Senapati,Himadri Pathak,Bo Peng*

Main category: quant-ph

TL;DR: 本文开发了成本效益高的近似TD-dCC方法，通过截断BCH展开构建层次化方法，用于准确计算分子核心能级光谱中的多体卫星特征，同时开发了量子信号处理算法作为补充。


<details>
  <summary>Details</summary>
Motivation: 准确解析分子核心能级光谱中的多体卫星特征需要高效且系统的电子关联理论方法，现有TD-dCC方法虽然有效但计算成本高昂。

Method: 开发了基于截断BCH展开的近似TD-dCC方法层次，保留单相似变换结构，同时开发了空穴介导激发路径的详细分量分析，并构建了量子信号处理算法。

Result: 在单杂质安德森模型和分子系统（H2O和CH4）中的应用表明，近似TD-dCC方法能够高效准确地重现精确多体光谱特征和准粒子权重。

Conclusion: 这些发展为定量、多体精确的核心光谱学建立了互补的经典和量子方法学。

Abstract: Accurately resolving many-body satellite features in molecular core-level spectra requires theoretical approaches that capture electron correlation both efficiently and systematically. The recently developed time-dependent double coupled-cluster (TD-dCC) ansatz achieves this by combining correlation effects from the N- and (N-1)-electron sectors, but its exact formulation remains computationally demanding. Here we introduce a hierarchy of cost-effective approximate TD-dCC ansatzes derived from truncated Baker-Campbell-Hausdorff (BCH) expansions, which preserve a single-similarity-transformation structure while retaining the essential correlation diagrams responsible for satellite formation. We further develop a detailed component analysis that isolates hole-mediated excitation pathways, which are correlated processes arising from the coupling between ground-state and ionized-state amplitudes. We use it to interpret quasiparticle and satellite features across the hierarchy. Applications to the single-impurity Anderson model and molecular systems (H2O and CH4) demonstrate that the approximate TD-dCC methods closely and efficiently reproduce exact many-body spectral features and quasiparticle weights. In parallel, we construct a fault-tolerant quantum signal processing algorithm for the core-hole Green's function, providing a scalable quantum route for simulating correlated core-level dynamics. Together, these developments establish complementary classical and quantum methodologies for quantitative, many-body-accurate core spectroscopy.

</details>


### [210] [Entanglement-limited linear response in fermionic systems](https://arxiv.org/abs/2511.19415)
*Hadi Cheraghi,Ali G. Moghaddam,Teemu Ojanen*

Main category: quant-ph

TL;DR: 本文建立了纠缠熵标度律与粒子守恒费米子系统线性响应函数之间的普遍联系，证明区域内粒子数扰动的响应函数标度与纠缠熵标度相同。


<details>
  <summary>Details</summary>
Motivation: 探索纠缠熵与线性响应函数之间的深层联系，揭示多体纠缠对系统响应特性的影响。

Method: 通过理论推导和自由费米子系统验证，分析不同纠缠形式（面积律、体积律、临界）下的响应函数标度行为。

Result: 发现响应函数标度由纠缠熵决定，导致能隙系统中能量吸收率和粒子数涨落与扰动区域边界而非体积成比例。

Conclusion: 建立了线性响应特性与多体纠缠之间的直接联系，挑战了传统预期并揭示了纠缠在系统响应中的关键作用。

Abstract: We propose a general connection between entanglement-entropy scaling laws and the linear response functions of particle-conserving fermionic systems in their ground state. Specifically, we show that the response to perturbations coupled to the particle number within a finite region exhibits the same size scaling as the entanglement entropy of that region. We explicitly verify this scaling in free-fermion systems that display area-law, volume-law, and critical forms of entanglement. The resulting entanglement-governed scaling of response functions leads to unexpected physical consequences. For instance, contrary to conventional expectations, the energy absorption rate and particle-number fluctuations in gapped systems scale with the boundary of the perturbed region rather than with its volume. Our work thus establishes a direct link between linear-response properties and many-body entanglement.

</details>


### [211] [Attractor Subspace and Decoherence-Free Algebra of Quantum Dynamics](https://arxiv.org/abs/2511.18021)
*Daniele Amato,Paolo Facchi,Arturo Konderak*

Main category: quant-ph

TL;DR: 本文综述了有限维开放量子系统在Heisenberg绘景中的渐近动力学，讨论了谱方法和代数方法及其关系，分析了离散时间和连续时间Markovian情形，并探讨了无限维情况下的问题。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统的渐近动力学，特别是Heisenberg绘景下的行为，旨在理解谱方法和代数方法之间的关系，并扩展到无限维情况。

Method: 采用谱分析和代数分析相结合的方法，在离散时间和连续时间Markovian框架下进行系统研究。

Result: 提供了有限维开放量子系统渐近动力学的完整分析框架，并在无限维情况下给出了一个Markovian演化的例子，其退相干自由代数是一个III型von Neumann代数。

Conclusion: 谱方法和代数方法在分析开放量子系统渐近动力学时具有紧密联系，该研究框架可推广到无限维情形，为理解量子系统的长期行为提供了理论基础。

Abstract: In this review we discuss some results on the asymptotic dynamics of finite-dimensional open quantum systems in the Heisenberg picture. Both the spectral and algebraic approaches to this topic are addressed, with particular emphasis on their relationship. The analysis is conducted in both the discrete-time and the continuous-time Markovian settings. In the final part of the work, some issues emerging in the infinite-dimensional case are also discussed. In particular, we provide an example of a Markovian evolution whose decoherence-free algebra is a type III von Neumann algebra.

</details>


### [212] [Fewest switches surface hopping with decoherence in the Marcus inverted regime: correct rates but wrong thermal populations](https://arxiv.org/abs/2511.18062)
*Manas Nagda,Priyam Kumar De,Amber Jain*

Main category: quant-ph

TL;DR: 本文研究了增强型最少切换面跳跃方法在深度反转Marcus区域的表现，发现该方法能获得合理的速率常数但热布居不正确，并通过解析推导解释了这一现象。


<details>
  <summary>Details</summary>
Motivation: 虽然FSSH方法在非绝热系统模拟中表现良好，但在深度反转Marcus区域，AFSSH方法虽然能获得准确速率常数，但热布居结果不正确，需要深入理解其内在机制。

Method: 使用增强型最少切换面跳跃方法进行模拟，并通过解析推导分析AFSSH在深度反转Marcus区域的行为。

Result: AFSSH在深度反转Marcus区域能获得合理的速率常数，但热布居结果不正确；解析推导表明这是由于时间导数耦合与放热性的共振导致正确速率常数，但自洽性问题导致错误热布居。

Conclusion: 研究提供了AFSSH在Marcus反转区域的量子校正因子解析表达式，揭示了AFSSH在深度反转区域获得正确速率常数但错误热布居的内在机制。

Abstract: Fewest switches surface hopping (FSSH) is a well benchmarked dynamical method for simulating nonadiabatic systems. In particular, the literature shows that for the spin-Boson model Hamiltonian, FSSH with appropriate corrections usually captures the detailed balance well and obtains rate constants within a factor of 2 compared to numerically exact results. In this study, we show that in the deep inverted Marcus regime, the augmented-FSSH (AFSSH, one version that includes decoherence) yields reasonably accurate rate constants but incorrect thermal populations over a broad range of parameters. We present an analytical derivation to understand the AFSSH behavior, and therefore, show that AFSSH obtains correct rate constants owing to the resonance of the time derivative coupling with the exothermicity, but obtains an incorrect thermal population owing to the self-consistency issue. The presented derivation provides an analytical expression for the quantum correction factor for AFSSH simulations in the Marcus inverted regime.

</details>


### [213] [Coherence of quantum non-Gaussian states via nonlinear absorption of quanta](https://arxiv.org/abs/2511.18149)
*Kingshuk Adhikary,Darren W. Moore,Radim Filip*

Main category: quant-ph

TL;DR: 该论文提出通过结合线性和非线性相位不敏感吸收过程，可以在没有外部驱动的情况下生成具有量子相干性的非高斯态，克服了仅使用线性吸收只能产生接近Fock态但缺乏相干性的限制。


<details>
  <summary>Details</summary>
Motivation: 传统方法中，即使使用可饱和系统的线性相位不敏感吸收，也只能产生接近Fock态的状态，这些状态缺乏量子相干性。研究旨在克服这一限制，实现具有相干性的量子非高斯态生成。

Method: 在原有线性吸收过程的基础上，添加非线性相位不敏感吸收过程。这两种被动过程的相干叠加使得相位空间中能够自发产生并增强相干性，无需外部驱动。

Result: 线性与非线性吸收过程的结合使得原本旋转对称的Fock态Wigner函数转变为具有复杂不对称结构的状态，产生了量子相干性。这种方法适用于广泛的实验类别。

Conclusion: 通过将线性和非线性相位不敏感吸收过程相结合，可以在最小化相互作用要求的情况下，无需外部驱动就能生成具有量子相干性的非高斯态，这为量子态工程提供了新的可能性。

Abstract: The linear and phase insensitive absorption of a single quanta via coherent interactions with a saturable system, even a single ground state qubit, is sufficient to deterministically generate quantum non-Gaussian states in an oscillator, even stimulated merely by increasing thermal oscillator energy. However, the resultant states only approach Fock states and therefore do not exhibit quantum coherence. Here we overcome this limitation using a minimal step: a nonlinear phase-insensitive absorption process added to the linear one. The coherent addition of such individually passive processes allows coherence to emerge and increase in phase space without an external drive and with minimal interaction requirements. The coherence of quantum non-Gaussian states emerges because the linear and nonlinear absorption processes are not mutually passive. In the simplest case rotationally symmetric Wigner functions of the oscillator Fock states convert their many negative regions to an extremely complex asymmetric structure in sharp contrast to the rotational symmetry of those obtained by the individual interactions. We extend this case to include an unsaturable absorber (oscillator) and analyse switching between linear and nonlinear absorptions, suitable for broad classes of experiments.

</details>


### [214] [Exact solutions of the inhomogeneous nonlinear Schrödinger equation through supersymmetric potentials](https://arxiv.org/abs/2511.18186)
*David J. Fernández C.,O. Pavón-Torres*

Main category: quant-ph

TL;DR: 本文提出了一种基于超对称量子力学的通用算法，用于构建超对称伙伴势并推导非均匀非线性薛定谔方程的精确稳态解。


<details>
  <summary>Details</summary>
Motivation: 通过建立非均匀非线性薛定谔方程与非线性薛定谔方程之间的联系，利用超对称量子力学方法来解决非均匀非线性薛定谔方程的精确解问题。

Method: 采用超对称量子力学算法，结合李点对称性处理方法，构建超对称伙伴势来求解非均匀非线性薛定谔方程。

Result: 成功推导出非均匀非线性薛定谔方程的精确稳态解，并以具有单束缚态的Pösch-Teller势为例进行了验证。

Conclusion: 超对称量子力学方法为求解非均匀非线性薛定谔方程提供了一种有效的通用算法，能够构造精确的稳态解。

Abstract: By employing supersymmetric quantum mechanics, we present a general algorithm to construct supersymmetric partner potentials and hence derive exact stationary solutions of the inhomogeneous nonlinear Schrödinger equation (INLSE). This is possible due to the connection between the INLSE and the nonlinear Schrödinger equation (NLSE), which can be established from a treatment based on Lie point symmetries and is related with Schrödinger equation, under certain conditions. As an illustrative example, we construct exact solutions for the INLSE through a Pösch-Teller potential with a single bound state.

</details>


### [215] [Space-Optimized and Experimental Implementations of Regev's Quantum Factoring Algorithm](https://arxiv.org/abs/2511.18198)
*Wentao Yang,Bao Yan,Muxi Zheng,Quanfeng Lu,Shijie Wei,Gui-Lu Long*

Main category: quant-ph

TL;DR: 提出了一种通过中间非计算实现量子比特重用的方法，显著降低了Regev量子因式分解算法的空间复杂度，从O(n^{3/2})降低到O(n^{5/4})甚至O(n log n)，并通过实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: Regev的高维变体虽然通过基于格的后续处理减少了电路规模，但引入了显著的空间开销且缺乏实际实现。为了解决这一问题，需要开发更高效的量子比特利用方法。

Method: 采用可逆计算启发的中间非计算方法实现量子比特重用，基本策略将空间成本从O(n^{3/2})降低到O(n^{5/4})，精炼策略达到O(n log n)的空间下界。

Result: 模拟展示了时间-空间权衡和资源缩放，构建并编译了N=35的量子电路，通过噪声模拟验证了方法有效性。在超导量子计算机上执行了简化实验电路，基于格的后续处理成功恢复了因子。

Conclusion: 这些结果推进了Regev风格量子因式分解的实际可行性，为未来的理论和实验发展提供了指导。

Abstract: The integer factorization problem (IFP) underpins the security of RSA, yet becomes efficiently solvable on a quantum computer through Shor's algorithm. Regev's recent high-dimensional variant reduces the circuit size through lattice-based post-processing, but introduces substantial space overhead and lacks practical implementations. Here, we propose a qubit reuse method by intermediate-uncomputation that significantly reduces the space complexity of Regev's algorithm, inspired by reversible computing. Our basic strategy lowers the cost from \( O(n^{3/2}) \) to \( O(n^{5/4}) \), and refined strategies achieve \( O(n \log n) \)which is a space lower bound within this model. Simulations demonstrate the resulting time-space trade-offs and resource scaling. Moreover, we construct and compile quantum circuits that factor \( N = 35 \), verifying the effectiveness of our method through noisy simulations. A more simplified experimental circuit for Regev's algorithm is executed on a superconducting quantum computer, with lattice-based post-processing successfully retrieving the factors. These results advance the practical feasibility of Regev-style quantum factoring and provide guidance for future theoretical and experimental developments.

</details>


### [216] [Deterministic coupling of ultracold atomic lattice to a suspended photonic waveguide](https://arxiv.org/abs/2511.18211)
*J. T. Hansen,F. Gargiulo,J. B. Mathiassen,J. H. Müller,E. S. Polzik,J. -B. Béguin*

Main category: quant-ph

TL;DR: 该研究展示了将超冷原子晶格与片上光子电路确定性耦合的平台，为量子计算和传感应用提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在单粒子水平和亚波长尺度上确定性控制光-物质相互作用是量子光学和集成量子技术的核心，但将冷原子研究与纳米光子器件在完全可控平台上结合仍是一个重大实验挑战。

Method: 通过将超冷原子晶格与悬浮片上光子电路中的光传播进行确定性耦合来实现。

Result: 该平台能够实现快速光学读取、高效亚波长非衍射相互作用区域，并与集成固态光子源、探测器和阻带调制器真正兼容。

Conclusion: 该平台不仅为可控量子物质研究开辟了新途径，还支持光倏逝场和纳米结构的原位成像，有望用于量子传感应用中的非侵入性单原子探针三维扫描显微镜。

Abstract: The deterministic control of light-matter interactions at the level of single particles and on subwavelength scales is central to quantum optics and hybrid integrated quantum technologies. However, combining cold atom research with nanophotonic devices in a fully controllable platform remains a major experimental challenge. Here, we demonstrate the deterministic coupling of an ultracold atomic lattice to light propagating in suspended on-chip photonic circuits. These capabilities open avenues to address scalability challenges in neutral-atom quantum computers and simulators, enabling fast optical readout, efficient and subwavelength non-diffracting interaction zones, and genuine compatibility with integrated solid-state photon sources, detectors, and stop-band modulators. Beyond controllable quantum matter, the platform also enables in-situ imaging of evanescent fields of light and nanoscale structures, including prospects for three-dimensional scanning microscopy with non-invasive single-atom probes for quantum sensing applications.

</details>


### [217] [General Machine Learning Algorithm for Quantum Teleportation](https://arxiv.org/abs/2511.18318)
*Allison Brattley,Tomas Opatrny,Kunal K. Das*

Main category: quant-ph

TL;DR: 提出一种基于机器学习的通用算法，可为任何具有明确定义纠缠基测量的系统创建最优幺正算子来实现量子隐形传态。该算法在集体自旋模型中验证，展示了处理单/多量子比特态、相干态、Dicke态以及具有先验分布和不等维系统的灵活性，在所有案例中都显示出优于无纠缠经典方案的量子优势。


<details>
  <summary>Details</summary>
Motivation: 开发一种通用的量子隐形传态方法，能够适应各种量子系统和状态类型，同时提供在目标保真度和计算成本之间的灵活权衡。

Method: 基于机器学习的算法，通过优化幺正算子来实现量子隐形传态，适用于具有明确定义纠缠基测量的任何系统。

Result: 在集体自旋模型中成功验证，能够处理单量子比特态、多量子比特态、相干态、Dicke态等多种量子状态，并且在具有先验分布和不等维系统中都表现出显著优于无纠缠经典方案的量子优势。

Conclusion: 该机器学习算法为量子隐形传态提供了一种通用且灵活的解决方案，能够在各种量子系统中实现最优性能，同时允许在保真度和计算复杂度之间进行权衡。

Abstract: We present a general algorithm, based on machine learning, which can create optimal unitary operators to implement quantum teleportation in any system with well-defined set of measurements in a relevant entangled basis. We illustrate it with a collective spin model and demonstrate its versatility by applying it to teloportation of single and multiple qubit states, coherent and Dicke states, and for systems with prior distributions and unequal dimensions. All cases display significant regimes of quantum advantage over corresponding classical schemes with no entanglement. The algorithm offers the flexibility to choose a balance between target fidelity and computational cost.

</details>


### [218] [Universal learning of nonlocal entropy via local correlations in non-equilibrium quantum states](https://arxiv.org/abs/2511.18327)
*Hao Liao,Xuanqin Huang,Ping Wang*

Main category: quant-ph

TL;DR: 使用多层感知器建立量子互信息与仅二阶局部关联之间的通用映射，为实验测量非平衡态量子互信息提供实用方法


<details>
  <summary>Details</summary>
Motivation: 量子互信息是量化纠缠的重要非局域度量，但在实验中测量困难，特别是对于比基态更复杂的非平衡态

Method: 在二维无序XXZ模型中，使用多层感知器建立量子互信息与仅二阶局部关联之间的通用映射

Result: 开发出从局部关联提取量子互信息的实用方法，适用于超导量子比特等实验平台

Conclusion: 该方法为重建其他非局域可观测量（如费舍尔信息和时序无序关联函数）建立了通用框架

Abstract: Characterizing the nonlocal nature of quantum states is a central challenge in the practical application of large-scale quantum computation and simulation. Quantum mutual information (QMI), a fundamental nonlocal measure, plays a key role in quantifying entanglement and has become increasingly important in studying nonequilibrium quantum many-body phenomena, such as many-body localization and thermalization. However, experimental measurement of QMI remains extremely difficult, particularly for nonequilibrium states, which are more complex than ground states. In this Letter, we employ a multilayer perceptron (MLP) to establish a universal mapping between the QMI and local correlations only up to second order for nonequilibrium states generated by quenches in a one-dimensional disordered XXZ model. Our approach provides a practical method for experimentally extracting QMI, readily applicable in platforms such as superconducting qubits. Moreover, this work will establishes a general framework for reconstructing other nonlocal observables, including Fisher information and out-of-time-ordered correlators.

</details>


### [219] [Nonlinear stochastic and quantum motion from Coulomb forces](https://arxiv.org/abs/2511.18345)
*Luca Ornigotti,Darren W. Moore,Radim Filip*

Main category: quant-ph

TL;DR: 论文展示了通过消除库仑力的谐波部分，剩余的非线性部分会产生可观测的非互易非线性效应，即一个粒子的位置噪声或量子不确定性会提高另一个粒子相干位移的信噪比。


<details>
  <summary>Details</summary>
Motivation: 可控非线性量子相互作用是现代量子技术追求的目标，但通常难以定制实现。然而，通过量子粒子间的基本力（如库仑相互作用）可能实现可控非线性。

Method: 通过辅助线性力消除库仑力的谐波部分，保留剩余的非线性部分，研究其对粒子间相干位移信噪比的影响。

Result: 在广泛的陷阱频率和质量尺度范围内，非线性力都会导致一个粒子的位置噪声提高另一个粒子相干位移的信噪比，这种现象在随机和量子体系中均可见。

Conclusion: 基本力（如库仑相互作用）中的非线性部分可以产生直接可观测的非互易非线性效应，为量子技术中的可控非线性提供了新途径。

Abstract: Controllable nonlinear quantum interactions are a much sought after target for modern quantum technologies. They are typically difficult and costly to engineer for bespoke purposes. However controllable nonlinearities may have always been in reach via the natural and fundamental forces between quantum particles. The Coulomb interaction between charged particles is the simplest example. We show that after eliminating the harmonic part of the Coulomb force by an auxiliary linear force, the remaining reciprocal nonlinear part results in a directly observable non-reciprocal nonlinear effect: increase of the signal-to-noise ratio (SNR) of the coherent displacement of one particle, driven by the position noise, or uncertainty in quantum regime, in another particle. This essential evidence of nonlinear forces is present across large ranges of trap frequency and mass scales, as well as visible in both stochastic and quantum regimes.

</details>


### [220] [An Introduction to the Quantum Approximate Optimization Algorithm](https://arxiv.org/abs/2511.18377)
*Alessandro Giovagnoli*

Main category: quant-ph

TL;DR: 本教程全面介绍了量子近似优化算法(QAOA)，重点讨论其在QUBO和PUBO问题中的应用，包括算法原理、哈密顿量公式、门分解、能量景观分析以及参数空间简化方法。


<details>
  <summary>Details</summary>
Motivation: QAOA是一种有前景的变分量子算法，用于解决经典难以处理的组合优化问题，本教程旨在从基本原理出发全面介绍QAOA及其特性。

Method: 教程首先介绍变分量子电路和QUBO问题，然后详细探讨QAOA的哈密顿量公式、门分解和应用实例，分析算法的能量景观并证明其对称性和周期性，最后将概念扩展到PUBO问题。

Result: 提出了参数空间简化方法，证明了算法的对称性和周期性特性，并将结果推广到高阶哈密顿量，讨论了相关的对称性和电路构造。

Conclusion: 本教程为QAOA及其在组合优化问题中的应用提供了全面的理论基础和实现指导，特别强调了从QUBO到PUBO问题的推广。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a promising variational quantum algorithm introduced to tackle classically intractable combinatorial optimization problems. This tutorial offers a comprehensive, first-principles introduction to QAOA and its properties, focusing on its application to Quadratic and Polynomial Unconstrained Binary Optimization (QUBO and PUBO) problems. The tutorial begins by outlining variational quantum circuits and QUBO problems, focusing on their key properties and the encoding of problem constraints through quadratic penalty terms. Next, it explores the QAOA in detail, covering its Hamiltonian formulation, gate decomposition, and example applications, along with their implementation and performance results. This is followed by an analysis of the algorithm's energy landscape, where proofs are provided for its symmetry and periodicity, and where a resulting parameter space reduction is proposed. Finally, the tutorial extends these concepts to PUBO problems by generalizing the results to higher-order Hamiltonians and discussing the associated symmetries and circuit construction.

</details>


### [221] [Cavity magnomechanical framework for a high-efficiency quantum battery](https://arxiv.org/abs/2511.18440)
*S. K. Singh,Ahmed A. Zahia,Jia-Xin Peng,M. Y. Abd-Rabboud*

Main category: quant-ph

TL;DR: 本文研究了由两个相同二能级原子通过腔-磁振子-机械系统充电的量子电池架构，分析了在耗散环境下的完整动力学演化，揭示了强共振光-物质相互作用对充电效率、存储能量和可提取功的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究混合磁振子平台中高效量子电池的设计，探索通过腔-磁振子-机械系统实现量子能量存储和提取的可行性。

Method: 推导旋转波近似下的系统哈密顿量，采用Lindblad主方程严格建模耗散过程，分析系统的完整动力学演化。

Result: 发现强共振光-物质相互作用对提升充电效率、存储能量和ergotropy至关重要，揭示了耦合强度之间的非平凡相互作用，并确定了最大化性能的最佳操作区域。

Conclusion: 研究结果为在混合磁振子平台中设计高效量子电池提供了定量框架，为未来实验实现提供了设计路线图。

Abstract: We theoretically investigate a quantum battery architecture where two identical two-level atoms are charged by a cavity-magnomechanical system, which includes a microwave cavity, a magnon mode hosted in a YIG sphere, and phonon mode due to the deformation of the YIG sphere. The charging process relies on coherent energy exchange, where the atoms couple to the cavity, which in turn, it interacts with the magnon mode via a beam-splitter mechanism. By deriving the system Hamiltonian under the rotating-wave approximation and employing a Lindblad master equation to rigorously model dissipation, we analyze the complete dynamical evolution of the battery. Our study demonstrates that strong, resonant light-matter interactions are crucial for enhancing the key performance metrics: charging efficiency, stored energy, and ergotropy (extractable work). We systematically investigate the deleterious effects of detuning and decoherence, and critically, we uncover a non-trivial interplay between the system's coupling strengths. This reveals optimal operating regimes where constructive interference maximizes performance, while excessive coupling in specific channels can degrade it. Ultimately, our findings provide a quantitative framework for engineering high-efficiency quantum batteries in hybrid magnonic platforms, offering a design roadmap for future experimental realizations.

</details>


### [222] [Non-Hermitian topology in a single driven-dissipative Kerr-Cat qubit](https://arxiv.org/abs/2511.18482)
*Pei-Rong Han,Huiye Qiu,Hao-Long Zhang,Wen Ning,Zhen-Biao Yang,Shi-Biao Zheng*

Main category: quant-ph

TL;DR: 本文研究了在连续变量量子系统中实现非厄米物理现象，特别关注了驱动耗散Kerr猫态量子比特中的异常点结构，发现了三阶刘维尔异常点的出现及其拓扑特性。


<details>
  <summary>Details</summary>
Motivation: 现有非厄米量子物理研究主要集中在离散变量系统，而连续变量编码系统中的非厄米量子效应尚未充分探索。本文旨在填补这一空白。

Method: 通过研究由Kerr非线性谐振器实现的驱动耗散Kerr猫态量子比特，分析其异常结构，特别关注耗散导致的量子态双向跳跃与单光子驱动的竞争关系。

Result: 发现耗散导致猫态量子比特两个基态之间的双向跳跃，这与普通两能级系统的单向跳跃形成鲜明对比。这种跳跃与单光子驱动的竞争产生了三阶刘维尔异常点，每个对应两条LEP2线的交叉点。

Conclusion: LEP3可以表现出哈密顿量EP3的拓扑特性，这在单量子比特系统中无法实现。这项工作为在连续变量量子系统中实现非厄米现象开辟了可能性。

Abstract: The intriguing physical phenomena associated with exceptional points have established non-Hermitian physics as a frontier of modern research. Recent investigations have extended non-Hermitian physics into the fully quantum domain. However, existing studies predominantly concentrate on discrete-variable quantum systems, while non-Hermitian quantum effects in continuous-variable encoded systems remain largely unexplored. In this work, we investigate the exceptional structure for a driven-dissipative Kerr-cat qubit, realized with a Kerr nonlinear resonator. We find that the dissipation leads to a bidirectional jump between the two basis states of the cat qubit, which is in distinct contrast with the unidirectional jump associated with normal two-level systems. The competition between this jump and a single-photon drive gives arise to the emergence of third-order Liouvillian exceptional points (LEP3s), each corresponds to a crossing point of two lines of LEP2s. We further show that the LEP3 can exhibit the topological character of the Hamiltonian EP3s, which cannot be realized with a single qubit. Our work opens the possibility of realizing non-Hermitian phenomena with continuous-variable quantum systems.

</details>


### [223] [Machine Learning by Adiabatic Evolutionary Quantum System](https://arxiv.org/abs/2511.18496)
*Tomoyuki Yamakami*

Main category: quant-ph

TL;DR: 本文研究了利用量子自动机控制的绝热演化量子系统（AEQS）来高效完成机器学习任务的方法，通过量子计数、量子振幅估计和量子近似等量子算法来寻找最优的1qqaf以解决目标关系问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过量子训练AEQS系统来高效完成机器学习任务，利用量子算法的优势来优化量子自动机控制的绝热演化过程。

Method: 开发基于量子计数、量子振幅估计和量子近似等量子算法的基本思想，用于训练由1qqaf控制的AEQS系统，寻找最优的1qqaf来近似解决目标关系问题。

Result: 提供了量子学习算法对AEQS系统效率的粗略估计，展示了量子方法在机器学习任务中的潜在优势。

Conclusion: 量子算法可以有效地用于训练AEQS系统，为量子机器学习提供了一种有前景的方法，特别是在处理由量子自动机控制的绝热演化系统时。

Abstract: A computational model of adiabatic evolutionary quantum system (or AEQS, pronounced "eeh-ks") was introduced in [Yamakami,2022] as a sort of quantum annealing and its underlying input-driven Hamiltonians are generated quantum-algorithmically by various forms of quantum automata families (including 1qqaf's). We study an efficient way to accomplish certain machine learning tasks by training these AEQSs quantumly. When AEQSs are controlled by 1qqaf's, it suffices in essence to find an optimal 1qqaf that approximately solves a target relational problem. For this purpose, we develop a basic idea of approximately utilizing well-known quantum algorithms for quantum counting, quantum amplitude estimation, and quantum approximation. We then provide a rough estimation of the efficiency of our quantum learning algorithms for AEQSs.

</details>


### [224] [Tunable Bands in 1D Fractional Quantum Media](https://arxiv.org/abs/2511.18574)
*Brenden R. Guyette,Joshua M. Lewis,Lincoln D. Carr*

Main category: quant-ph

TL;DR: 本文扩展分数阶微积分到周期势中的粒子研究，通过分数阶薛定谔方程分析Lévy指数q如何调控能带形成和反转，揭示了在q=2处的能带结构定性转变，并展示了q作为可调自由度对能带反转、带隙调制和载流子动力学的重塑能力。


<details>
  <summary>Details</summary>
Motivation: 将分数阶微积分框架扩展到周期势量子系统，研究Lévy指数q如何调控能带形成和反转，为工程化新的物理行为和器件功能提供途径。

Method: 使用虚时间演化算法求解周期矩形势的分数阶薛定谔方程，并通过高斯过程回归补充离散能量色散分析。

Result: 发现q=2处能带结构发生定性转变：q>2时能带发生反转，在第一布里渊区内出现对称极小值，形成Bloch动量量子比特；q<2时k=0附近有效质量随q指数减小。

Conclusion: Lévy指数q作为可调自由度能够驱动能带反转、调制带隙并重塑载流子动力学，为周期性量子系统提供了新的调控维度。

Abstract: Fractional calculus has become an essential framework in geophysics, optics, and biological systems to capture long-range correlations and anomalous transport. In this article, we extend fractional calculus to explore a particle in a periodic potential, where the Schrödinger equation is generalized to its fractional form. This framework allows us to study how the Lévy index $q$ governs the formation and inversion of energy bands, offering a pathway to engineer new physical behaviors and device functionalities by tuning $q$ in periodic quantum systems. We solve the fractional Schrödinger equation for periodic rectangular potentials of varying height $V_0$, barrier thickness $L$, and well width $W$ using an imaginary-time evolution algorithm, and supplement the discrete energy dispersion through Gaussian process regression. Our analysis reveals a qualitative shift in the band structure at $q=2$, separating into regimes for $q>2$ and $q<2$. For $q > 2$, energy bands undergo an inverting transformation as symmetric minima emerge within the first Brillouin zone, shifting from $k=0$ toward $k=\pm π/a$ with increasing $q$. These degenerate minima define a Bloch-momentum qubit, suggesting an analog to valley degrees of freedom used in valleytronics. The response of the ground band scales with fractional order as $V_0^{-0.28\pm0.05}L^{-0.34\pm0.08}W^{-0.49\pm0.06}$, indicating tunable sensitivity to geometry. For $q < 2$, the effective mass near $k = 0$ decreases exponentially with $q$, yielding a universal effective mass of $0.15\pm0.01$ as $q \to 1$, demonstrating that the Lévy index serves as a tunable degree of freedom capable of driving band inversion, modulating the band gap, and reshaping carrier dynamics.

</details>


### [225] [Teleportation-based quantum state tomography](https://arxiv.org/abs/2511.18621)
*Gustavo Rigolin*

Main category: quant-ph

TL;DR: 量子隐形传态协议可用于完全重构任意二比特和三比特密度矩阵，并扩展到n比特密度矩阵。实现基于隐形传态的量子态层析仅需贝尔测量能力和准备少量单比特态。


<details>
  <summary>Details</summary>
Motivation: 探索量子隐形传态协议在量子态层析中的应用，简化传统量子态重构所需的复杂测量过程。

Method: 利用量子隐形传态协议，通过贝尔测量和准备少量单比特态来实现量子态的重构。

Result: 成功证明该方法可完全重构任意二比特和三比特密度矩阵，并可扩展到n比特情况。

Conclusion: 量子隐形传态协议为量子态层析提供了一种有效且资源需求较少的替代方法。

Abstract: We explicitly show that the quantum teleportation protocol can be employed to completely reconstruct arbitrary two- and three-qubit density matrices. We also extend the present analysis to n-qubit density matrices. The only quantum resources needed to implement the teleportation-based quantum state tomography protocol are the ability to make Bell measurements and the ability to prepare a few different single qubit states to be teleported from Alice to Bob.

</details>


### [226] [HOPPS: Hardware-Aware Optimal Phase Polynomial Synthesis with Blockwise Optimization for Quantum Circuits](https://arxiv.org/abs/2511.18770)
*Xinpeng Li,Ji Liu,Shuai Xu,Paul Hovland,Vipin Chaudhary*

Main category: quant-ph

TL;DR: HOPPS是一种基于SAT的硬件感知最优相位多项式合成算法，用于生成CNOT和Rz门块，实现CNOT数量或深度的最优性。对于大型电路，采用迭代分块优化策略。


<details>
  <summary>Details</summary>
Motivation: 现代量子应用中{CNOT, Rz}块普遍存在，但编译后常出现CNOT数量或深度过大，降低保真度。现有方法在追求最优性时扩展性受限。

Method: 提出HOPPS算法实现CNOT数量或深度最优的{CNOT, Rz}块合成。对于大型电路，采用迭代分块优化策略：将大电路分割成小模块，每个模块最优优化，多次迭代。

Result: HOPPS比现有近最优合成工具更高效。作为窥孔优化器，在OLSQ下可将CNOT数量减少高达50.0%，深度减少高达57.1%。对于大型QAOA电路，经过Qiskit映射后，CNOT数量和深度分别减少高达44.4%和42.4%。

Conclusion: HOPPS算法能有效优化量子电路中的{CNOT, Rz}块，显著减少CNOT门数量和深度，提高电路性能。

Abstract: Blocks composed of {CNOT, Rz} are ubiquitous in modern quantum applications, notably in circuits such as QAOA ansatzes and quantum adders. After compilation, many of them exhibit large CNOT counts or depths, which lowers fidelity. Therefore, we introduce HOPPS: a SAT-based hardware-aware optimal phase polynomial synthesis algorithm that could generate {CNOT, Rz} blocks with CNOT count or depth optimality.
  Sometime {CNOT, Rz} blocks are large, such as in QAOA ansatzes, HOPPS's pursuit of optimality limits its scalability. To address this issue, we introduce an iterative blockwise optimization strategy: large circuits are partitioned into smaller blocks, each block is optimally refined, and the process is repeated for several iterations.
  Empirical results show that HOPPS is more efficient comparing with existing near optimal synthesis tools. Used as a peephole optimizer, HOPPS reduces the CNOT count by up to 50.0% and the CNOT depth by up to 57.1% under OLSQ. For large QAOA circuit, after mapping by Qiskit, circuit can be reduced CNOT count and depth by up to 44.4% and 42.4% by our iterative blockwise optimization. Index Terms-Phase Polynomial, Quantum Circuit Synthesis, Quantum Circuit Optimization.

</details>


### [227] [Quantum Key Distribution Based on Systematic Polar Coding](https://arxiv.org/abs/2511.18818)
*Georgi Bebrov*

Main category: quant-ph

TL;DR: 论文提出了一种结合量子密钥分发和系统极性编码的新方法，在有限尺寸机制和低误码率量子信道下，获得了比标准BB84及其高效版本更高的密钥率。


<details>
  <summary>Details</summary>
Motivation: 传统量子密钥分发协议在有限尺寸机制下的密钥率有限，需要改进以提升性能。

Method: 将量子密钥分发与系统极性编码框架相结合，构建基于系统极性编码的量子密钥分发协议。

Result: 在有限尺寸机制和低误码率量子信道条件下，新方法获得了比标准BB84和eBB84更高的密钥率。

Conclusion: 系统极性编码与量子密钥分发的结合能有效提升密钥分发性能，特别是在有限尺寸和低误码率场景下。

Abstract: Here we concerned with quantum key distribution - a way to establish common cryptographic key between several parties. The work proposes a combination between quantum key distribution and systematic polar coding (an error correction algorithm) frameworks - quantum key distribution based on systematic polar coding. This results in obtaining key rates greater than standard quantum key distribution (BB84) and its efficient version (eBB84) when finite-size regime and lower-error-rate quantum channel are considered.

</details>


### [228] [Processing Entangled Links Into Secure Cryptographic Keys](https://arxiv.org/abs/2511.18913)
*Marcel Kokorsch,Guido Dietl*

Main category: quant-ph

TL;DR: 本文提出了一种处理纠缠链路的整体方法，研究纠缠蒸馏、测量和经典后处理对最终安全密钥率的集体影响，基于Eckert 1991协议和Devetak-Winter密钥容量理论。


<details>
  <summary>Details</summary>
Motivation: 研究基于贝尔不等式的量子密钥分发协议中纠缠链路的整体处理，分析整个处理链对最终安全密钥率的集体影响。

Method: 基于Eckert 1991协议原理和Devetak-Winter密钥容量理论，提出统一形式化方法，包括纠缠蒸馏、纠缠态测量处理和经典后处理。

Result: 证明了Werner态情况下实现密钥容量所需的测量基选择，提出了新的处理策略并与常见策略比较，确定了最优纠缠蒸馏量。

Conclusion: 建立了一个统一的处理链形式化框架，可用于定量分析用于生成安全密钥的噪声纠缠态的质量与数量关系。

Abstract: The following paper presents a holistic approach to the processing of entangled links within entanglement based quantum key distribution protocols, whose security relies on the Bell inequality. We investigate the interactions, and the collective impact, of the whole processing chain on the final secure key rate. This includes the quantum mechanical preprocessing in the form of entanglement distillation, processing of the entangled states via measurements and the necessary classical postprocessing based on the measurement results. Our investigations are based on the principle idea of the Eckert 1991 protocol and utilize the secret key capacity introduced by Devetak and Winter in 2005. Our results include a proof on what measurement bases need to be chosen to achieve this capacity for the case of Werner states. It also presents a new processing strategy and compares it with the most common one that can be found within the literature. Furthermore, it answers the question on how much entanglement distillation is optimal. By doing so we propose a unified formalism, describing the whole processing chain, that can be used to make quantitative statements on the relation between the quality and quantity of entangled but noisy quantum states used for generating secure keys.

</details>


### [229] [Noisy dynamics of confined quantum walks on a chip](https://arxiv.org/abs/2511.19125)
*L. Sansoni,E. Stefanutti,C. Benedetti,I. Gianani,C. Taballione,A. Toor,L. Herrera,M. Pistilli,S. Santoro,M. Barbieri,A. Chiuri*

Main category: quant-ph

TL;DR: 本文使用20x20片上多模干涉仪研究量子行走中晶格边界和噪声对演化动力学的影响，展示了噪声如何破坏平移对称性并重塑干涉模式。


<details>
  <summary>Details</summary>
Motivation: 研究量子行走中相干过程与耗散过程的相互作用，特别关注晶格边界对演化动力学的影响，这是之前实验研究较少涉及的方面。

Method: 使用20x20片上多模干涉仪，在量子行走系统中引入晶格边界，通过实验研究噪声对系统动力学的影响。

Result: 噪声破坏了平移对称性，重塑了干涉模式，产生了非平凡的概率分布，展示了加速效应、局域化和相干振荡等现象。

Conclusion: 在现实的量子动力学中，加速效应、局域化和相干振荡是需要充分表征和理解的核心概念，边界和噪声的引入显著改变了量子行走的演化行为。

Abstract: Quantum walks represent an excellent testbed for investigating the interplay between unitary coherent and incoherent dissipative processes. Thanks to photonic quantum interferometers of considerable size, experimental studies could be performed, devoted to investigating the consequences of different sorts of realistic noise in these systems. In this work we employ a 20x20 on-chip multimode interferometer to introduce another key aspect in the problem: the presence of edges in the walker lattice, enforcing a confined evolution. We show how noise can disrupt translational symmetry and reshape interference patterns. The non trivial probability distributions obtained along the temporal evolution of the system demonstrate how speed up effects, localization and coherent oscillations are pillar concepts to be fully characterized and understood when applied in realistic quantum dynamics.

</details>


### [230] [Flexible Genetic Algorithm for Quantum Support Vector Machines](https://arxiv.org/abs/2511.19160)
*Nguyen Minh Duc,Vu Tuan Hai,Le Bin Ho,Tran Nguyen Lan*

Main category: quant-ph

TL;DR: 提出GA-QSVM框架，使用遗传算法自动优化量子支持向量机中的特征映射，解决了传统固定量子电路泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统量子支持向量机使用固定特征映射电路，难以在不同数据集上实现良好泛化性能，需要自动化优化方法。

Method: 采用遗传算法优化量子特征映射，提供可配置框架灵活定义进化参数，构建自适应量子电路。

Result: 在Digits、Fashion、Wine和Breast Cancer数据集上，GA-QSVM达到与经典SVM和标准QSVM相当的准确率，且迁移学习显示其电路具有良好的跨数据集泛化能力。

Conclusion: 进化策略在自动化量子机器学习核设计方面具有重要潜力，为未来量子机器学习应用提供有效解决方案。

Abstract: Quantum Support Vector Machines (QSVM) is one of the most promising frameworks in quantum machine learning, yet their performance depends on the design of the feature map. Conventional approaches rely on fixed quantum circuits, which often fail to generalize across datasets. To address this limitation, we propose GA-QSVM, a hybrid framework that employs Genetic Algorithms (GA) to automatically optimize feature maps. The proposed method introduces a configurable framework that flexibly defines the evolutionary parameters, enabling the construction of adaptive circuits. Experimental evaluation of datasets, including Digits, Fashion, Wine, and Breast Cancer, demonstrates that GA-QSVMs achieve a comparable accuracy compared to classical SVMs and standard QSVMs. Furthermore, transfer learning results indicate that GA-QSVM's circuits generalize effectively across datasets. These findings highlight the potential of evolutionary strategies to automate and enhance kernel design for future quantum machine learning applications.

</details>


### [231] [Synchronized Aharonov-Bohm Motifs via Engineered Dissipation](https://arxiv.org/abs/2511.19219)
*Christopher W. Wächtler,Gloria Platero*

Main category: quant-ph

TL;DR: 该论文展示了通过结合通量诱导的局域化和工程耗散，可以在具有旋转对称性的自旋几何结构中实现鲁棒的同步动力学，这种同步独立于初始条件并产生自旋间的纠缠。


<details>
  <summary>Details</summary>
Motivation: 研究外部规范场与晶格几何的相互作用如何通过完全相消干涉诱导极端局域化动力学，并探索将其与工程耗散结合以实现量子同步的可能性。

Method: 结合通量诱导的局域化与工程耗散，在具有循环对称性的Aharonov-Bohm motif结构中实现自旋同步，并通过施加额外的集体耗散来耦合多个motif。

Result: 在旋转对称的自旋几何结构中实现了鲁棒的同步动力学，这种同步独立于初始条件并产生自旋间的纠缠。多个motif在耦合时可以完全同步。

Conclusion: 揭示了通量诱导局域化、耗散工程和集体量子同步之间的直接联系，为量子同步现象提供了新的实现机制。

Abstract: The interplay between external gauge fields and lattice geometry can induce extreme localization dynamics through complete destructive interference. We show that combining this flux-induced localization with engineered dissipation leads to robust spin synchronization in rotationally symmetric spin geometries, referred to as Aharonov-Bohm motifs, with cyclic symmetries of any order. The synchronized dynamics is independent of initial conditions and features entanglement among spins within each motif. We further demonstrate that multiple motifs can fully synchronize when coupled, which is achieved by applying additional collective dissipation acting on all intra-motif spins. These results reveal a direct connection between flux-induced localization, dissipative engineering, and collective quantum synchronization.

</details>


### [232] [Entropic Dynamics approach to Quantum Electrodynamics](https://arxiv.org/abs/2511.19238)
*Ariel Caticha*

Main category: quant-ph

TL;DR: 本文扩展了熵动力学框架来处理局部规范对称性，基于最大熵方法和信息几何学，推导出带电粒子与辐射场相互作用的量子电动力学，并验证了麦克斯韦方程。


<details>
  <summary>Details</summary>
Motivation: 将熵动力学框架扩展到处理局部规范对称性，验证该非正统基础方法在经验上的成功性。

Method: 使用最大熵方法和信息几何学，通过适当选择本体变量和约束条件，推导量子电动力学。

Result: 成功推导出带电粒子与辐射场相互作用的量子电动力学，并验证了麦克斯韦方程。

Conclusion: 熵动力学框架能够处理局部规范对称性，其非正统基础在经验上是成功的，能够推导出量子电动力学的核心方程。

Abstract: Entropic dynamics (ED) is a framework that allows one to derive quantum theory as a Hamilton-Killing flow on the cotangent bundle of a statistical manifold. These flows are such that they preserve the symplectic and the (information) metric geometries; they explain the linearity of quantum mechanics and the appearance of complex numbers. In this paper the ED framework is extended to deal with local gauge symmetries. More specifically, on the basis of maximum entropy methods and information geometry, for an appropriate choice of ontic variables and constraints, we derive the quantum electrodynamics of radiation fields interacting with charged particles. As a test that despite its unorthodox foundation the ED approach is empirically successful we derive the Maxwell equations.

</details>


### [233] [Longitudinal Pulsed Dynamic Nuclear Polarization Transfer via Periodic Optimal Control](https://arxiv.org/abs/2511.19244)
*José P. Carvalho,Anders Bodholt Nielsen,David L. Goodwin,Nino Wili,Niels Chr. Nielsen*

Main category: quant-ph

TL;DR: 本文提出了一种新的宽带动态核极化脉冲序列家族LOOP，通过纵向极化转移解决了传统横向自旋锁定脉冲序列中初始激发脉冲宽带能力的限制问题。


<details>
  <summary>Details</summary>
Motivation: 受NMR光谱学启发，周期性辐照方案在脉冲动态核极化序列中表现出卓越性能，但目前大多数研究集中在类似固态NMR的横向自旋锁定脉冲序列，其性能可能受到初始激发脉冲宽带能力的限制。

Method: 结合最优控制理论的灵活性和鲁棒性以及有效哈密顿理论的深入见解，开发了LOOP序列，通过实现纵向极化转移来缓解激发脉冲挑战，定义了鲁棒的单自旋有效z旋转。

Result: LOOP序列对微波场不均匀性具有显著补偿能力，能够在仅使用32 MHz峰值微波场振幅、外部磁场0.35 T的条件下，实现超过100 MHz带宽的DNP转移。

Conclusion: LOOP序列家族为宽带脉冲DNP应用提供了一种有效的解决方案，通过纵向极化转移方法克服了传统横向自旋锁定序列的局限性。

Abstract: Taking inspiration from NMR spectroscopy, periodic irradiation schemes have recently shown remarkable performance when implemented into pulsed dynamic nuclear polarization (DNP) sequences. This has prompted considerable interest in development of broadband pulsed DNP sequences utilizing such schemes. On this background, most efforts have focused on solid-state NMR like transverse spin-locked pulse sequences whose performance in DNP applications may be compromised by the broadband capabilities of the initial excitation pulse. Leveraging the flexibility and robustness of optimal control theory combined with underlying insights from effective Hamiltonian theory, we present a new family of broadband DNP pulse sequences, termed LOOP (Longitudinally Optimized with Overarching Periodicity), that alleviates the excitation-pulse challenge by accomplishing longitudinal polarization transfer. These sequences define robust single-spin effective $z$ rotations, with impressive compensation towards microwave field inhomogeneity, and are capable of delivering DNP transfer with bandwidths exceeding 100 MHz, while employing a peak microwave field amplitude of only 32 MHz, at an external magnetic field of 0.35 T.

</details>


### [234] [Neural Architecture Search for Quantum Autoencoders](https://arxiv.org/abs/2511.19246)
*Hibah Agha,Samuel Yen-Chi Chen,Huan-Hsin Tseng,Shinjae Yoo*

Main category: quant-ph

TL;DR: 本文提出了一种基于遗传算法的神经架构搜索框架，用于自动化设计量子自编码器，以解决量子电路架构设计的挑战。


<details>
  <summary>Details</summary>
Motivation: 量子自编码器在压缩高维量子数据和经典数据方面具有潜力，但由于量子电路架构设计的复杂性（包括门选择、电路层排列和参数调优），设计有效的量子电路架构仍然具有挑战性。

Method: 使用遗传算法（GA）系统演化变分量子电路（VQC）配置，自动化设计量子自编码器，避免陷入局部最小值。

Result: 在图像数据集上证明了该方法的有效性，展示了量子自编码器在噪声易发的近期量子时代进行高效特征提取的潜力。

Conclusion: 该方法为遗传算法在量子架构搜索中的更广泛应用奠定了基础，旨在开发能够适应不同数据和硬件约束的鲁棒、自动化方法。

Abstract: In recent years, machine learning and deep learning have driven advances in domains such as image classification, speech recognition, and anomaly detection by leveraging multi-layer neural networks to model complex data. Simultaneously, quantum computing (QC) promises to address classically intractable problems via quantum parallelism, motivating research in quantum machine learning (QML). Among QML techniques, quantum autoencoders show promise for compressing high-dimensional quantum and classical data. However, designing effective quantum circuit architectures for quantum autoencoders remains challenging due to the complexity of selecting gates, arranging circuit layers, and tuning parameters.
  This paper proposes a neural architecture search (NAS) framework that automates the design of quantum autoencoders using a genetic algorithm (GA). By systematically evolving variational quantum circuit (VQC) configurations, our method seeks to identify high-performing hybrid quantum-classical autoencoders for data reconstruction without becoming trapped in local minima. We demonstrate effectiveness on image datasets, highlighting the potential of quantum autoencoders for efficient feature extraction within a noise-prone, near-term quantum era. Our approach lays a foundation for broader application of genetic algorithms to quantum architecture search, aiming for a robust, automated method that can adapt to varied data and hardware constraints.

</details>


### [235] [Decoupling local classicality from classical explainability: A noncontextual model for bilocal classical theory and a locally-classical but contextual theory](https://arxiv.org/abs/2511.19266)
*Sina Soltani,Marco Erba,David Schmid,John H. Selby*

Main category: quant-ph

TL;DR: 本文为双局域经典理论构建了本体论模型，反驳了该理论不存在局域实在论本体论模型的猜想，并首次为非局域层析理论构建了本体论模型，表明局域层析假设是结构定理的真正限制。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证双局域经典理论是否存在局域实在论本体论模型，并探讨局域层析假设在结构定理中的必要性，以及局部经典性与经典可解释性之间的关系。

Method: 通过具体构造双局域经典理论的本体论模型，并构建反例来验证局部经典理论是否都允许本体论模型。

Result: 成功构建了双局域经典理论的本体论模型，反驳了相关猜想，并证明并非所有局部经典理论都允许本体论模型。

Conclusion: 局域层析等组合性质在理解经典性本身中具有核心地位，局部经典性与经典可解释性之间没有简单关系。

Abstract: We construct an ontological model for the theory known as bilocal classical theory doi.org/10.1103/PhysRevA.102.052216. To our knowledge, this is only the second time that an ontological model has been constructed for an entire theory, rather than just for some particular scenarios within a theory. This result refutes a conjecture from doi.org/10.1103/PhysRevA.102.052216 which suggested that there might be no local-realist ontological model for bilocal classical theory. Moreover, it is the first time that an ontological model has been constructed for a theory that fails to be locally tomographic, showing that the assumption of local tomography underpinning the structure theorem in doi.org/10.22331/q-2024-03-14-1283 is a genuine limitation of the theorem. This demonstrates that in general there is no tension between failures of local tomography and classical explainability (i.e., generalised noncontextuality). In fact, bilocal classical theory is in many ways more simply understood via the underlying ontological model than it is within its original formulation (much as how odd-dimensional stabiliser subtheories can be more simply understood via Spekkens' toy theory). Furthermore, this result naturally leads to the question, does every locally-classical theory admit of an ontological model? By constructing a concrete counterexample, we show that this is not the case. Our findings demonstrate that there is no straightforward relationship between theories being locally-classical, and them being classically-explainable. This shows that the fundamental status of compositional properties (such as local tomography) is not a technical side-issue, but a central and unavoidable question for a coherent understanding even of classicality itself.

</details>


### [236] [TorchQuantumDistributed](https://arxiv.org/abs/2511.19291)
*Oliver Knitter,Jonathan Mei,Masako Yamada,Martin Roetteler*

Main category: quant-ph

TL;DR: TorchQuantumDistributed (tqd) 是一个基于 PyTorch 的可扩展、加速器无关的可微分量子态矢量模拟库，用于研究高量子比特数的可学习参数化近期和容错量子电路行为。


<details>
  <summary>Details</summary>
Motivation: 为了研究具有高量子比特数的可学习参数化近期和容错量子电路的行为，需要一个可扩展且与加速器无关的模拟工具。

Method: 开发了基于 PyTorch 的 TorchQuantumDistributed (tqd) 库，支持加速器无关的可微分量子态矢量模拟。

Result: 实现了可扩展的量子态矢量模拟，能够处理高量子比特数的量子电路。

Conclusion: tqd 库为研究高量子比特数的参数化量子电路提供了一个有效的模拟平台。

Abstract: TorchQuantumDistributed (tqd) is a PyTorch-based [Paszke et al., 2019] library for accelerator-agnostic differentiable quantum state vector simulation at scale. This enables studying the behavior of learnable parameterized near-term and fault- tolerant quantum circuits with high qubit counts.

</details>


### [237] [Efficient Equivalent of Shallow Quantum Hashing](https://arxiv.org/abs/2511.19292)
*Ilnar Zinnatullin,Alexander Vasiliev*

Main category: quant-ph

TL;DR: 本文建立了浅层量子哈希与单量子位量子哈希在振幅形式下的联系，提出了深度为1的电路实现相同抗碰撞性。


<details>
  <summary>Details</summary>
Motivation: 量子哈希是量子计算中广泛使用的技术，用于设计空间高效的算法和协议。最近Vasiliev展示了浅层量子哈希的相位形式可以通过深度为2的电路实现，本文旨在探索振幅形式的浅层量子哈希实现。

Method: 建立浅层量子哈希与单量子位量子哈希在振幅形式下的联系，提出深度为1的电路设计来实现相同的抗碰撞性能。

Result: 成功设计出深度为1的电路，能够实现与浅层量子哈希相同的碰撞抵抗能力。

Conclusion: 在振幅形式下，浅层量子哈希可以通过更浅的电路（深度1）实现，这为量子哈希的高效实现提供了新的可能性。

Abstract: Quantum hashing is a widely used technique in quantum computation that allows us to design space-efficient algorithms and protocols. Recently, Vasiliev has shown that the phase form of shallow quantum hashing can be implemented by a circuit of depth 2. In this paper, we establish a connection between shallow quantum hashing and single-qubit quantum hashing for the amplitude form. For a shallow circuit, we propose a circuit of depth 1 that achieves the same collision resistance.

</details>


### [238] [Quantitative and Optimal Device-Independent Lower Bounds on Detection Efficiency](https://arxiv.org/abs/2511.19302)
*Arkaprabha Ghosal,Soumyadip Patra,Peter Bierhorst*

Main category: quant-ph

TL;DR: 本文在完全设备无关框架下研究了(2,2,2)贝尔实验中探测器效率的定量最优下界，使用NPA层次结构提供了观察期望贝尔-CHSH违背所需的最小效率的紧下界，并考虑了暗计数的影响，最后通过考虑满足Tsirelson界的无信号行为得到了最小效率的简单闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 在设备无关量子信息处理中，探测器效率是实验实现的关键限制因素。本文旨在量化在完全设备无关设置下观察贝尔-CHSH违背所需的最小探测器效率，为实验设计提供理论指导。

Method: 使用Navascués-Pironio-Acín (NPA)层次结构进行数值优化，验证下界的紧性；引入暗计数误差分析；通过考虑满足Tsirelson界的无信号行为推导解析闭式表达式。

Result: 获得了最小探测器效率的紧下界（数值验证到四位小数精度）；展示了暗计数增加时所需最小效率的变化；得到了最小效率的简单闭式表达式，虽然该解析下界明显低于数值紧下界。

Conclusion: 本文为设备无关贝尔实验提供了探测器效率的定量下界分析，数值方法可获得紧下界，而解析方法虽简化但保守，为实验实现提供了理论基准。

Abstract: This paper examines a quantitative and optimal lower bound on the detector efficiency in a (2,2,2) Bell experiment within a fully device-independent framework, whereby the detectors used in the experiment are uncharacterized. We provide a tight lower bound on the minimum efficiency required to observe a desired Bell-CHSH violation using the Navascués-Pironio-Acín (NPA) hierarchy, confirming tightness up to four decimal places with numerical optimization over explicit quantum realizations. We then introduce the effect of dark counts and demonstrate how to quantify the minimum required efficiency to observe a desired CHSH violation with an increasing dark count error. Finally, to obtain an analytical closed-form expression of the minimum efficiency, we consider the set of no-signaling behaviors that satisfy the Tsirelson bound, which are easier to characterize than the quantum set. Using such behaviors, we find a simple closed-form expression for a lower bound on the minimum efficiency which is monotonically increasing with the CHSH violation, though the analytically obtained lower bounds are meaningfully below the numerically tight lower bound.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [239] [On the uniqueness of the coupled entropy](https://arxiv.org/abs/2511.17684)
*Kenric P. Nelson*

Main category: cond-mat.stat-mech

TL;DR: 本文证明了耦合熵是唯一满足广义熵在尺度-形状分布中与尺度密度等价要求的熵度量。耦合拉伸指数分布作为其最大化分布，能够量化复杂系统中尺度的线性不确定性和形状的非线性不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统熵度量（如Boltzmann-Gibbs-Shannon熵）在Pareto Type II分布中表现出对形状的线性依赖性，这主导了对尺度的对数依赖性，表明需要一种更通用的熵度量。Rényi和Tsallis熵作为历史重要但最终不令人满意的推广。

Method: 通过证明耦合熵在尺度-形状分布中的唯一性，并分析其最大化分布（耦合拉伸指数分布）的性质。证明了耦合熵的可组合性和广延性引理，支持其公理化定义。

Result: 耦合熵能够隔离非线性形状依赖性到配分函数的广义对数中，而Rényi和Tsallis熵仍保持对非线性形状的强依赖性。耦合拉伸指数分布包括Pareto Types I-IV和Gosset's Student-t分布。

Conclusion: 耦合熵提供了一个有效的广义熵框架，适用于状态增长为幂律、拉伸指数或其组合的系统，能够更好地量化复杂系统中的不确定性。

Abstract: The coupled entropy is proven to uniquely satisfy the requirement that a generalized entropy be equivalent to the density at the scale for scale-shape distributions. Further, its maximizing distributions, the coupled stretched exponential distributions, are proven to quantify the linear uncertainty with the scale and the nonlinear uncertainty with the shape for a broad class of complex systems. Distributions of the coupled exponentials include the Pareto Types I-IV and Gosset's Student-t. For the Pareto Type II distribution, the Boltzmann-Gibbs-Shannon entropy has a linear dependence on the shape, which dominates over the logarithmic dependence on the scale, motivating the need for a generalization. The Rényi and Tsallis entropies are shown to be of historic importance but ultimately unsatisfactory generalizations. The coupled entropy of the coupled stretched exponential distribution isolates the nonlinear-shape dependence to a generalized logarithm of the partition function. The Rényi and Tsallis entropies retain a strong dependence on the nonlinear-shape such that they are not equivalent to the uncertainty at the scale. Lemmas for the composability and extensivity of the coupled entropy are proven in support of an axiomatic definition. The scope of the coupled entropy includes systems in which the growth of states is power-law, stretched exponential, or a combination.

</details>


### [240] [Dissipation anomaly in gradient-driven nonequilibrium steady states](https://arxiv.org/abs/2511.17851)
*Hiroyoshi Nakano,Yuki Minami*

Main category: cond-mat.stat-mech

TL;DR: 本文证明耗散异常现象不仅存在于湍流中，也出现在简单的梯度驱动非平衡稳态系统中。通过数值模拟和理论分析，发现该异常源于梯度放大的巨大长程非平衡涨落。


<details>
  <summary>Details</summary>
Motivation: 耗散异常通常被认为是湍流的特征现象，但本文旨在探索这一现象是否也存在于其他非湍流系统中，特别是简单的梯度驱动非平衡稳态。

Method: 使用涨落流体动力学方法，结合直接数值模拟和自洽模式耦合理论，分析在恒定标量梯度作用下但宏观静止的流体系统。

Result: 发现线性理论预测在无粘极限下耗散发散，但非线性模式耦合使发散正则化，产生有限的异常耗散。梯度放大的热涨落是异常耗散的来源。

Conclusion: 耗散异常不仅限于湍流，也存在于简单的非平衡稳态系统，揭示了热涨落和非平衡驱动相互作用作为流体动力学奇异行为的基本途径。

Abstract: Dissipation anomaly-the persistence of finite energy dissipation in the inviscid limit-is a hallmark of turbulence, sometimes regarded as the "zeroth law" of turbulent flows. Here, we demonstrate that this phenomenon is not exclusive to turbulence. Using fluctuating hydrodynamics, we show that a simple gradient-driven nonequilibrium steady state, in which a fluid is subjected to a constant scalar gradient but remains macroscopically quiescent, also exhibits dissipation anomaly. Direct numerical simulations and self-consistent mode-coupling theory reveal that the anomaly originates from giant, long-range nonequilibrium fluctuations amplified by the imposed gradient. While linear theory predicts a divergent dissipation in the inviscid limit, nonlinear mode coupling regularizes the divergence, yielding a finite anomalous dissipation. Our findings identify a new, non-turbulent arena for dissipation anomaly and establish the interplay between thermal noise and nonequilibrium driving as a fundamental route to singular behavior in hydrodynamics.

</details>


### [241] [Failure of LMC statistical complexity in identifying structural order in the XY model](https://arxiv.org/abs/2511.18648)
*Dario Javier Zamora*

Main category: cond-mat.stat-mech

TL;DR: LMC统计复杂度在XY模型中无法准确识别高结构复杂度状态，常将最大复杂度分配给接近平衡的配置，而低估涡旋丰富的中间态。其时间导数包含更有意义的动力学信息。


<details>
  <summary>Details</summary>
Motivation: 量化物理系统的复杂性是一个基本挑战，现有度量方法往往无法捕捉直觉或理论要求的结构特征。LMC统计复杂度因其简单性和解析可处理性被广泛引用，但其性能需要在实际物理环境中验证。

Method: 通过蒙特卡洛模拟研究二维XY模型，计算系统弛豫动力学每一步的LMC复杂度，并直接与演化的偶极子配置进行比较。

Result: LMC复杂度系统性地无法识别高结构复杂度状态，经常将最大复杂度分配给接近平衡的配置，而低估涡旋丰富的中间态。LMC复杂度的时间导数包含更有意义的动力学信息。

Conclusion: 未来的复杂性度量应包含方向性和动力学敏感性，以更好地反映非平衡系统中组织的出现和衰减。

Abstract: Quantifying complexity in physical systems remains a fundamental challenge, and many proposed measures fail to capture the structural features that intuitive or theoretical considerations would demand. Among them, the Lopez-Ruiz-Mancini-Calbet (LMC) statistical complexity has been widely cited due to its simplicity and analytic tractability. Here, we examine the performance and limitations of the LMC measure in a controlled physical setting: a two-dimensional XY model studied through Monte Carlo simulations. By computing LMC complexity at each step of the system's relaxation dynamics, and directly comparing these values with the evolving dipole configurations, we show that LMC complexity systematically fails to identify states of high structural complexity. In particular, the measure often assigns maximal complexity to nearly equilibrated configurations while underestimating vortex-rich intermediate states. We further show that the time derivative of LMC complexity contains more meaningful dynamical information. We propose that future measures incorporate directionality and dynamical sensitivity to better reflect the emergence and decay of organization in nonequilibrium systems.

</details>


### [242] [Spectral mechanism and nearly reducible transfer matrices for pseudotransitions in one-dimensional systems](https://arxiv.org/abs/2511.18109)
*Onofre Rojas*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了一维短程相互作用系统中的伪相变现象，揭示了这种看似尖锐但解析的热力学异常来源于转移矩阵的近乎块对角结构，其中弱耦合的竞争扇区导致特征值竞争，产生无非解析性的突变交叉。


<details>
  <summary>Details</summary>
Motivation: 虽然一维系统在短程相互作用下不可能发生真正的相变，但最近发现多个模型表现出类似相变的尖锐热力学异常。本文旨在理解这种伪相变现象的数学机制和热力学特征。

Method: 开发了一个通用的谱框架来描述伪相变行为，并将其应用于两个代表性模型：具有内部简并的Ising链（Doniach模型）和混合自旋1/2与自旋1的六边形纳米线链。通过转移矩阵的对称性分解和低秩有效矩阵构造来分析交叉行为。

Result: 在Doniach模型中推导了伪临界温度和残余熵的精确表达式；在六边形纳米线链中，通过对称性分解将1458×1458的完整转移矩阵简化，构建了能够准确捕捉准铁磁和准核铁磁区域间交叉的低秩有效矩阵。

Conclusion: 伪相变可以理解为从转移矩阵内不可约但功能解耦结构中出现的谱现象，残余熵在界面处保持有界是此类伪相变的关键热力学特征。

Abstract: While true phase transitions are forbidden in one-dimensional systems with short-range interactions, several models have recently been shown to exhibit sharp yet analytic thermodynamic anomalies that mimic thermal phase transitions. We show that this behavior arises from transfer matrices that are mathematically irreducible but possess a nearly block-diagonal structure due to the weak contribution of off-diagonal Boltzmann weights in the low-temperature regime. This results in weakly coupled competing sectors whose eigenvalue competition produces abrupt crossovers without nonanalyticity, a mechanism we term nearly block-diagonal irreducible. A key thermodynamic signature of such pseudotransitions is that the residual entropy at the interface remains bounded between the residual entropies of the competing sectors. We develop a general spectral framework to describe this behavior and apply it to two representative models: the Ising chain with internal degeneracy (Doniach model) and a hexagonal nanowire chain with mixed spin-1/2 and spin-1 components. In the first case, we derive exact expressions for the pseudo-critical temperature and residual entropy. In the second, we reduce the full $1458\times1458$ transfer matrix via symmetry decomposition and construct a low-rank effective matrix that accurately captures the crossover between quasi-ferromagnetic and quasi-core-ferromagnetic regimes. Our results demonstrate that pseudotransitions can be understood as spectral phenomena emerging from irreducible but functionally decoupled structures within the transfer matrix.

</details>


### [243] [First-Passage Times for the Space Fractional Fokker-Planck Equation](https://arxiv.org/abs/2511.18256)
*Christopher N. Angstmann,Daniel S. Han,Bruce I. Henry,Boris Z. Huang*

Main category: cond-mat.stat-mech

TL;DR: 本文扩展了随机游走框架以包含复合步骤，为一类新的超扩散过程提供首次通过时间特性，这些过程由空间分数谱Fokker-Planck方程控制。


<details>
  <summary>Details</summary>
Motivation: 研究一类新的超扩散过程的首次通过时间特性，这些过程不同于Lévy飞行和行走，能够考虑空间依赖力和跳跃路径中的击中边界。

Method: 扩展随机游走框架以包含复合步骤，推导不同类型势垒和势能下的首次通过时间分布。

Result: 对于半无限线上的单侧吸收边界，首次通过时间密度按t^{-1/(2α)-1}缩放，与镜像法一致但违反Sparre-Andersen缩放。存在最优的空间分数指数α来最小化平均首次通过时间。

Conclusion: 该研究为超扩散过程提供了新的首次通过时间特性，揭示了与经典过程不同的缩放行为和最优参数选择。

Abstract: We extend the random walk framework to include compounded steps, providing first-passage time (FPT) properties for a new class of superdiffusive processes, which are governed by the space-fractional spectral Fokker-Planck equation. This first-passage process leads to novel FPT properties, different from Lévy flights and walks, that account for space dependent forces and hitting boundaries throughout the path of a jump. The FPT distribution can be derived for different types of barriers and potentials, for which we also provide specific examples. For the one-sided absorbing boundary on the semi-infinite line, we find that the FPT density scales as $t^{-1/(2α)-1}$, in agreement with the method of images but in violation of the Sparre-Andersen scaling. In this case, there exists an optimal space-fractional exponent $α$ to minimize the mean FPT.

</details>


### [244] [Inertia-chirality interplay in active Brownian motion: exact dynamics and phase maps](https://arxiv.org/abs/2511.18361)
*Anweshika Pattanayak,Sandip Roy,Abhishek Chaudhuri*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了二维手性活性布朗粒子（cABP）的精确时间分辨理论，推导了速度、速度自相关、均方位移等关键物理量的解析表达式，揭示了惯性包络与手性包络的因子分解特性。


<details>
  <summary>Details</summary>
Motivation: 研究手性活性布朗粒子在惯性效应下的动力学行为，探索质量、活性和手性对粒子运动的影响，特别是理解这些因素如何导致平衡态行为的出现。

Method: 使用拉普拉斯变换矩层次方法，推导了平均速度、速度自相关、均方位移等物理量的闭式表达式，并与模拟结果进行定量比较。

Result: 速度自相关可分解为惯性包络和手性包络；长期位置扩散与过阻尼cABP值相同，与质量无关；手性可作为实现类平衡行为的额外途径；速度超峰度相图显示重入转变现象。

Conclusion: 手性活性布朗粒子的动力学行为由惯性、活性和手性共同决定，手性能够限制活性效应并缩小活性区域，在特定条件下可导致类平衡行为的出现。

Abstract: We present an exact, time-resolved theory for a two-dimensional chiral active Brownian particle (cABP) with translational inertia. Using a Laplace-transform moment hierarchy, we derive closed-form expressions for the mean velocity, velocity-orientation projections, velocity autocorrelation, mean-squared velocity, mean-squared displacement, and the fourth moment of velocity. These results agree quantitatively with simulations over all masses, activities, and chiralities. We show that the velocity autocorrelation factorizes into an inertial envelope and a chiral envelope. Despite rich transients in the velocity sector, the long-time positional diffusion equals the overdamped cABP value, independent of mass. From the steady mean-squared velocity, we define a kinetic temperature and a modified fluctuation-dissipation relation whose violation vanishes in two limits: large mass or large chirality, identifying chirality as an additional route to equilibrium-like behavior. The steady-state velocity excess kurtosis gives a phase map that exhibits a (Gaussian-like)-active(bimodal)-(Gaussian-like) re-entrance with mass; chirality confines activity and shrinks the active sector. A narrow positive-kurtosis window emerges at large mass and intermediate chirality, with analytic boundaries consistent with the heavy-mass asymptote.

</details>


### [245] [Evolving criticality in iterative bicolored percolation](https://arxiv.org/abs/2511.18462)
*Shuo Wei,Haoyu Liu,Xin Sun,Youjin Deng,Ming Li*

Main category: cond-mat.stat-mech

TL;DR: 本文介绍了一种二维迭代双色渗流过程，能够保持和转变临界性。从临界配置开始，通过连续粗粒化产生一系列不同但都处于临界状态的代次，并推导了精确的与代次相关的分形维数。


<details>
  <summary>Details</summary>
Motivation: 传统上临界性被视为重正化群的不稳定、精细调节的固定点。本文旨在探索临界性如何能够被保持和转变，建立一种演化临界性的几何机制。

Method: 使用二维迭代双色渗流过程，从O(n)环模型和模糊Potts模型等临界配置出发，通过连续粗粒化生成临界代次层次结构。利用共形环系综推导分形维数，并通过大规模蒙特卡洛模拟进行验证。

Result: 演化轨迹不仅依赖于初始状态的普适类，还取决于其是否具有双态临界结构，导致从格点渗流和键渗流出发产生不同的临界指数。推导的与代次相关的分形维数得到了数值模拟的定量确认。

Conclusion: 这些结果建立了一种演化临界性的通用几何机制，其中标度不变性在代次间持续存在。

Abstract: Criticality is traditionally regarded as an unstable, fine-tuned fixed point of the renormalization group. We introduce an iterative bicolored percolation process in two dimensions and show that it can both preserve and transform criticality. Starting from critical configurations, such as the O$(n)$ loop and fuzzy Potts models, successive coarse-graining generates a hierarchy of distinct yet critical generations. Using the conformal loop ensemble, we derive exact, generation-dependent fractal dimensions, which are quantitatively confirmed by large-scale Monte Carlo simulations. The evolutionary trajectory depends not only on the universality class of the initial state but also on whether it possesses a two-state critical structure, leading to different critical exponents starting from site and bond percolation. These results establish a general geometric mechanism for evolving criticality, in which scale invariance persists across generations.

</details>


### [246] [Lévy noise drives an exponential acceleration in transition rates within metastable systems](https://arxiv.org/abs/2511.18490)
*Shenglan Yuan*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一个统一的框架来分析Lévy噪声对亚稳态系统逃逸过程的影响，发现Lévy噪声通过产生不连续的转移路径，普遍增强了逃逸效率，即使在极弱噪声下也能指数级提高逃逸率。


<details>
  <summary>Details</summary>
Motivation: Lévy噪声广泛存在于量子设备、活性生物物质和金融市场等非平衡系统中，但其对亚稳态间激活转变的整体影响尚不清楚，尽管已有针对特定噪声形式和缩放极限的研究。

Method: 通过识别最可能转移路径作为随机作用泛函的最小化器，推导弱噪声下逃逸率的解析缩放定律，扩展经典Arrhenius定律。使用累积量生成函数、路径积分表示、平均首次通过时间和数值模拟验证这些路径。

Result: 结果表明Lévy噪声普遍增强了逃逸效率，通过降低有效势垒高度，与具有等效强度的Gaussian噪声相比。即使在极弱Lévy噪声下，也能在广泛的振幅分布范围内指数级增加逃逸率。

Conclusion: 研究揭示了热波动和非热波动下逃逸动力学的根本区别，为通过工程噪声特性优化亚稳态系统中的切换过程提供了新策略。

Abstract: Lévy noise influences diverse non-equilibrium systems across scales, including quantum devices, active biological matter, and financial markets. While such noise is pervasive, its overall impact on activated transitions between metastable states remains unclear, despite prior studies of specific noise forms and scaling limits. In this work, we introduce a unified framework for Lévy noise defined by its finite intensity and independent stationary increments. By identifying the most probable transition paths as minimizers of a stochastic action functional, we derive analytical scaling laws for escape rates under weak noise, thereby extending the classical Arrhenius law. Our results demonstrate that Lévy noise universally enhances escape efficiency by reducing the effective potential barrier compared to Gaussian noise with equivalent intensity. Strikingly, even vanishingly weak Lévy noise can exponentially increase escape rates across a broad range of amplitude distributions. This phenomenon arises from discontinuous most probable transition paths, where escape occurs via finite jumps. We validate these paths through the cumulant-generating function, a path integral representation, the mean first passage time and numerical simulations. Our findings reveal fundamental distinctions in escape dynamics under thermal and athermal fluctuations, suggesting new strategies to optimize switching processes in metastable systems through engineering noise properties.

</details>


### [247] [A Generalized Grassmann-Pfaffian Framework for Monomer-Dimer and Spanning Trees](https://arxiv.org/abs/2511.18495)
*E. A. Ramirez Trino,M. A. Seifi MirJafarlou,M. A. Rajabpour*

Main category: cond-mat.stat-mech

TL;DR: 该论文开发了一个统一的贝雷津积分框架，用于处理格拉斯曼变量的积分，建立了指数二次费米形式和线性费米形式与玻色和费米源耦合的主恒等式。该框架适用于任意维度的实和复费米子，即使在基础矩阵奇异时也保持良好定义。


<details>
  <summary>Details</summary>
Motivation: 为图论模型和晶格场论提供灵活的理论分析和计算工具，通过贝雷津积分统一处理各种组合和物理模型，包括二聚体、单体-二聚体、匹配和近似匹配问题。

Method: 构建了两个主定理：定理12为实费米子提供全面的贝雷津积分恒等式，适用于任何反对称矩阵；定理13是其复数对应，产生基于行列式的表示。还开发了处理奇异矩阵的实用技术，包括酉块分解和谱分析。

Result: 建立了单体-二聚体系统的Monobisyzexant函数，将Hafnian推广到包含单体贡献；提出了Hafnian和Pfaffian及其子矩阵推广之间的显式映射；为生成树和森林提供了替代的源序贝雷津积分表示。

Conclusion: 这项工作为基于图的模型和晶格场论的理论分析和计算实现提供了一个灵活的贝雷津积分工具包，统一了多种组合和物理问题的处理方法。

Abstract: We develop a unified framework for Berezin integrals over Grassmann variables that establishes master identities for exponential quadratic fermionic forms and linear fermionic forms coupled to both bosonic and fermionic sources. The construction is rigorous for both real and complex fermions in arbitrary dimensions and remains well-defined even when the underlying matrices are singular. Our main mathematical results appear in two master theorems. Theorem 12 provides a comprehensive identity for Berezin integrals over Grassmann variables for real fermions with mixed bosonic-fermionic sources, applicable to any antisymmetric matrix. Its complex analogue, Theorem 13, yields corresponding determinant-based representations. Together, they serve as generating functionals for a wide range of combinatorial and physical models. Key applications include the dimer, monomer-dimer, matching, and almost-matching problems. We revisit the Kasteleyn theorem for planar dimers using Berezin integrals. We construct monomer-dimer systems through the \textit{Monobisyzexant (Mbsz)} function, which generalizes the Hafnian to incorporate monomer contributions and admits a Pfaffian-sum representation for planar graphs (Theorem 5); and practical techniques for handling singular matrices via unitary block decomposition (Theorem 6) and spectral analysis. We further present explicit mappings between Hafnians and Pfaffians and their submatrix generalizations (Hafnianinhos and Pfaffianinhos); an alternative source-ordered Berezin integral representation for spanning trees and forests using complex bosonic sources that regularizes the Laplacian zero mode (Theorem 10). Overall, this work offers a flexible toolkit for the theoretical analysis and computational implementation of graph-based models and lattice field theories using Berezin integrals over Grassmann variables .

</details>


### [248] [Three faces of random walks in hyperbolic domain: BKT, Lifshitz tails, and KPZ](https://arxiv.org/abs/2511.18510)
*Daniil Fedotov,Sergei Nechaev*

Main category: cond-mat.stat-mech

TL;DR: 该论文展示了在庞加莱双曲上半平面中的连续随机游走（扩散）作为一个统一框架，连接了三个看似无关的现象：BKT转变中的关联长度非解析发散、受限随机游走中KPZ指数的出现，以及一维稀有事件统计中Lifshitz尾的出现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是建立一个统一的理论框架，将BKT转变、KPZ标度行为和Lifshitz尾这三个在不同物理背景下出现的现象联系起来，揭示它们之间的深层数学联系。

Method: 结合标度论证、解析推导和数值分析，将最初为二维共形不变势中Efimov效应发展的重整化群方程，适配到双曲上半平面中的扩散情况。

Result: 推导出了BKT型关联长度发散，证明了KPZ型标度控制双曲域中边界附近的大偏差行为和生存概率，并通过瞬子方法展示了Lifshitz尾在双曲平面确定性大偏差景观中的自然出现。

Conclusion: 论文得出结论，负责BKT类物理的路径集合的主要贡献来自于被推向大偏差拉伸机制的随机路径，为这些看似不同的现象提供了统一的数学解释。

Abstract: We show that continuous random walks (diffusion) in the Poincaré hyperbolic upper halfplane $\mathbb{H}^2 = {(x,y)}|y>0$, interpreted as multiplicative stochastic processes with log-normal statistics, provide a unifying framework linking three seemingly unrelated phenomena: (i) the non-analytic divergence of corrrelation length at the Berezinskii-Kosterlitz-Thouless (BKT) transition; (ii) the appearence of the Kardar-Parisi-Zhang 9KPZ) exponent in the fluctuational behavior of stretched random walks constrained above an impermeable disc; and (iii) the emergence of Lifshitz tails in one-dimensional statistics of rare events. Combining scaling arguments with analytic derivations and numerical analysis, we adapt the renormalization-group equations originally developed for the Efimov effect in a two-dimensional conformally invariant potential to the case of diffusion in $\mathbb{H}^2$, thereby deriving the BKT-type divergence of the correlation length. We further demonstrate how the KPZ-type scaling governs the large-deviation behavior and survival probability near the boundary in the hyperbolic domain, and how Lifshitz tails arise naturally in a deterministic large-deviation landscape on the hyperbolic plane via instanton approach, reproducing the rare-event statistics of one-dimensional diffusion in the array of traps with the Poisson distribution. We conjecture that the dominant contribution to the ensemble of paths responsible for BKT-like physics comes from random paths pushed to large-deviation stretched regime.

</details>


### [249] [Dual thermal pseudo-critical features in a spin-1/2 Ising chain with twin-diamond geometry](https://arxiv.org/abs/2511.18596)
*Onofre Rojas*

Main category: cond-mat.stat-mech

TL;DR: 本文通过精确映射到有效伊辛链，研究了耦合双金刚石链的热力学性质，揭示了五个不同的基态相，包括两个具有广泛简并度的受挫区域，这些区域导致特征熵平台和伪相变行为。


<details>
  <summary>Details</summary>
Motivation: 研究受Cu₂(TeO₃)₂Br₂磁性结构启发的耦合双金刚石链，探索其受挫特性和热力学行为。

Method: 应用精确映射到有效伊辛链，通过紧凑的传递矩阵公式获得系统的完整热力学描述。

Result: 基态分析揭示了五个不同的相，包括两个具有广泛简并度的受挫区域，这些区域产生特征熵平台并在零温图中分隔有序相。在低温下，模型表现出熵、磁化和响应函数的尖锐但连续变化，反映了伪相变行为的清晰特征。

Conclusion: 耦合双金刚石链提供了一个精确可解的环境，其中竞争的局部构型和内部受挫导致一维中显著的伪临界特征。

Abstract: We study the coupled twin-diamond chain, a decorated one-dimensional Ising model motivated by the magnetic structure of \mathrm{Cu}_{2}(\mathrm{TeO}_{3})_{2}\mathrm{Br}_{2}. By applying an exact mapping to an effective Ising chain, we obtain the full thermodynamic description of the system through a compact transfer-matrix formulation. The ground-state analysis reveals five distinct phases, including two frustrated sectors with extensive degeneracy. These frustrated regions give rise to characteristic entropy plateaus and separate the ordered phases in the zero-temperature diagram. At low temperatures the model exhibits peculiar sharp yet continuous variations of entropy, magnetization, and response functions, reflecting clear signatures of pseudo-transition behavior. The coupled twin-diamond chain thus provides an exactly solvable setting in which competing local configurations and internal frustration lead to pronounced dual pseudo-critical features in one dimension.

</details>


### [250] [Conservation laws and slow dynamics determine the universality class of interfaces in active matter](https://arxiv.org/abs/2511.18947)
*Raphaël Maire,Andrea Plati,Frank Smallenburg,Giuseppe Foffi*

Main category: cond-mat.stat-mech

TL;DR: 该论文首次在活性硬盘模型中观察到非平衡界面标度行为，发现了|q|KPZ和湿|q|KPZ普适性类，并揭示了一个由缓慢晶体或玻璃动力学产生的新普适性类。


<details>
  <summary>Details</summary>
Motivation: 虽然平衡界面显示通用的大尺度统计特性，但活性系统和驱动系统中的界面被预测属于不同的非平衡普适性类。然而，这种行为很难观察到，大多数系统尽管具有强非平衡微观动力学，却表现出类似平衡的涨落。

Method: 引入了一个活性硬盘模型，与自推进模型相反，该模型显示出清晰的非平衡界面标度行为。

Result: 首次观察到|q|KPZ和湿|q|KPZ普适性类，同时揭示了一个由缓慢晶体或玻璃动力学产生的新普适性类。这些不同的类别由守恒定律和缓慢的流体动力学模式选择。

Conclusion: 该研究通过活性硬盘模型成功观测到了非平衡界面标度行为，发现了多个普适性类，为理解非平衡系统中的界面动力学提供了重要见解。

Abstract: While equilibrium interfaces display universal large-scale statistics, interfaces in phase-separated active and driven systems are predicted to belong to distinct non-equilibrium universality classes. Yet, such behavior has proven difficult to observe, with most systems exhibiting equilibrium-like fluctuations despite their strongly non-equilibrium microscopic dynamics. We introduce an active hard-disk model that contrary to self-propelled models, displays clear non-equilibrium interfacial scaling and observe for the first time, the $|\boldsymbol q|$KPZ and wet-$|\boldsymbol q|$KPZ universality classes while revealing a new, previously overlooked universality class arising in systems with slow crystalline or glassy dynamics. These distinct classes are selected by conservation laws and slow hydrodynamic modes.

</details>


### [251] [Phase Diagrams of the YK Surface-Reaction Model on 2D lattices with Exchange Diffusion](https://arxiv.org/abs/2511.19082)
*Henrique A. Fernandes,Roberto da Silva,Paulo F. Gomes*

Main category: cond-mat.stat-mech

TL;DR: 研究了Yaldram和Khan催化表面模型在方形和六边形晶格上的相图，考虑了CO和N原子的交换扩散。通过稳态蒙特卡洛模拟发现，在特定条件下会出现稳态反应状态，且扩散促进了活性相的出现。


<details>
  <summary>Details</summary>
Motivation: 探索在允许CO和N原子交换扩散的情况下，催化表面模型的相图变化，特别是扩散对反应活性的影响。

Method: 使用稳态蒙特卡洛模拟方法，在方形和六边形晶格上进行了40万次模拟，分析不同一氧化氮解离速率和交换扩散速率下的系统行为。

Result: 在方形晶格上，特定r_NO和x值下出现稳态反应状态；在六边形晶格上，扩散使活性相在更低的r_NO值下出现；系统存在连续和不连续相变，但r_NO=1时连续相变消失。

Conclusion: 扩散过程显著影响催化表面模型的相行为，促进了活性相的形成，并改变了相变特性。

Abstract: In this work, we investigate the phase diagrams of the Yaldram and Khan catalytic surface model on square and hexagonal lattices when exchange diffusion is allowed for carbon monoxide (CO) and nitrogen (N) atoms. To reach our goal, we carried out steady-state Monte Carlo (MC) simulations over $4\times 10^5$ points, for both lattices, in order to obtain a framework of the steady reactive state of the model for different values of the nitric oxide dissociation rate, $r_{NO}$. The results show the emergence of steady reactive state for certain values of $r_{NO}$ and of exchange diffusion rate $x$ when the simulations take place on square lattices. Our findings on the hexagonal lattice also show that the diffusion of these species favors the appearance of the active phase for values of $r_{NO}$ lower than that found for the standard model. In addition, we observed that the system possesses a continuous phase transition and a discontinuous one separating the active phase from absorbing states for both lattices, except for $r_{NO}=1$ in which the continuous phase transition is destroyed and a steady reactive state emerges from the beginning since very small values of $x$.

</details>


### [252] [Fate of diffusion under integrability breaking of classical integrable magnets](https://arxiv.org/abs/2511.19110)
*Jiaozi Wang,Sourav Nandy,Markus Kraft,Tomaž Prosen,Robin Steinigeweg*

Main category: cond-mat.stat-mech

TL;DR: 该研究通过大规模数值模拟，在经典可积的各向异性Landau-Lifshitz磁体的易轴区域中，研究了无限温度下的自旋扩散现象。研究发现，在热力学极限下，自旋扩散常数随微扰强度发生急剧变化，并且磁化转移的高阶累积量显示出从非高斯到高斯统计的交叉行为。


<details>
  <summary>Details</summary>
Motivation: 扩散输运是普遍存在的物理现象，但相互作用物理系统中扩散的微观起源仍然是一个具有挑战性的问题，无论量子效应是否占主导地位。本研究旨在探索可积系统中固有的非平凡扩散机制。

Method: 研究采用大规模数值模拟方法，分析经典可积、时空离散的各向异性Landau-Lifshitz磁体在易轴区域中的行为，并施加可积性破坏微扰。

Result: 数值结果显示：i) 在热力学极限下，自旋扩散常数随微扰强度发生急剧变化；ii) 在可积性破坏下，磁化转移的高阶累积量显示出从非高斯到高斯统计的交叉行为。

Conclusion: 这些观察结果表明可积系统中存在固有的非平凡扩散机制，为理解相互作用物理系统中的扩散现象提供了新的见解。

Abstract: Diffusive transport is a ubiquitous phenomenon, yet the microscopic origin of diffusion in interacting physical systems remains a challenging question, irrespective of whether quantum effects are dominant or not. In this work, we study infinite temperature spin diffusion in a classical integrable, space-time discrete version of anisotropic Landau-Lifshitz magnet in the easy-axis regime, subjected to integrability-breaking perturbations. Our numerical results based on large-scale simulations reveal i) a sharp change in the spin diffusion constant as a function of perturbation strength in the thermodynamic limit and ii) a crossover from non-Gaussian to Gaussian statistics of magnetization transfer reflected in higher order cumulants under integrability breaking. Both our observations hint to the presence of non-trivial diffusion mechanism inherent to integrable systems.

</details>


### [253] [Tilings of a bounded region of the plane by maximal one-dimensional tiles](https://arxiv.org/abs/2511.19288)
*Eduardo J. Aguilar,Valmir C. Barbosa,Raul Donangelo,Welles A. M. Morgado,Sergio R. Souza*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了二维平面区域使用K-cell一维瓦片（K-mers）的平铺问题，与以往研究不同，允许同时使用任意K值的瓦片，但需满足极大性约束条件。


<details>
  <summary>Details</summary>
Motivation: 传统研究通常只允许单一K值或少量固定K值，本文旨在探索允许任意K值瓦片同时使用的平铺问题，通过极大性约束限制可能的平铺种类，同时观察统计物理可观测量中的有趣行为。

Method: 引入基于单元接触的能量函数，并适当参数化，在满足极大性约束的条件下研究系统温度变化时的相变行为。

Result: 观察到相对意外的行为，包括随着系统温度演化出现相变迹象。

Conclusion: 通过极大性约束和能量函数参数化，在允许任意K值瓦片同时使用的平铺系统中观察到了相变等有趣物理现象。

Abstract: We study the tiling of a two-dimensional region of the plane by $K$-cell one-dimensional tiles, or $K$-mers. Unlike previous studies, which typically allowed for one single value of $K$ or sometimes a small assortment of fixed values, here a tiling may concomitantly employ $K$-mers comprising any number $K$ of cells, provided a maximality constraint is satisfied. In essence, this constraint requires each of the $K$-mers in use to be as lengthy as possible, given its surroundings in the resulting tiling. Maximality aims to limit the variety of possible tilings while allowing for interesting behavior in terms of the statistical physical observables of interest. In fact, by introducing an energy function based on cell contacts and parameterizing it appropriately, we have been able to observe relatively unexpected behavior, including the suggestion of phase transitions as the system's temperature evolves.

</details>
