<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 38]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 10]
- [cs.AI](#cs.AI) [Total: 10]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 5]
- [cs.LG](#cs.LG) [Total: 48]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 4]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [An ETH-ansatz-based environmental-branch approach to master equation](https://arxiv.org/abs/2512.09007)
*Wen-ge Wang*

Main category: quant-ph

TL;DR: 提出了一种无需Born近似和Markov近似的量子主方程推导方法，适用于与满足本征态热化假设的量子混沌环境局部耦合的小型量子系统。


<details>
  <summary>Details</summary>
Motivation: 传统主方程推导通常需要Born近似和Markov近似，这些近似在某些情况下可能不成立。本文旨在开发一种更通用的方法，适用于与量子混沌环境耦合的系统，仅基于环境的动力学特性进行推导。

Method: 基于总系统的薛定谔演化，在环境分支与相互作用哈密顿量无关联的初始条件下，通过对环境分支演化的形式表达式进行分段二阶展开来推导主方程。推导中主要使用基于环境动力学特性的近似。

Result: 开发了一种新的主方程推导方法，该方法不依赖于Born近似和Markov近似，而是基于环境的动态特性，适用于满足本征态热化假设的量子混沌环境。

Conclusion: 该方法为研究与量子混沌环境耦合的小型量子系统的动力学提供了一种更通用的理论框架，避免了传统推导中的限制性近似，为理解复杂量子系统的开放系统动力学开辟了新途径。

Abstract: In this paper, a method for deriving master equation is developed for a generic small quantum system, which is locally coupled to an environment as a many-body quantum chaotic system that satisfies the eigenstate thermalization hypothesis ansatz, resorting to neither the Born approximation nor the Markov approximation. The total system undergoes Schrödinger evolution, under an initial condition in which the environmental branches possess no correlation with the interaction Hamiltonian. Derivation of the master equation is based on piecewise usage of a second-order expansion of a formal expression, which is derived for the evolution of the environmental branches. Approximations used in the derivation are mainly based on dynamic properties of the environment.

</details>


### [2] [The Richness of Bell Nonlocality: Generalized Bell Polygamy and Hyper-Polygamy](https://arxiv.org/abs/2512.09034)
*Gerard Anglès Munné,Paweł Cieśliński,Jan Wójcik,Wiesław Laskowski*

Main category: quant-ph

TL;DR: 该论文研究了多体量子系统中贝尔非定域性的多配偶性质，证明单个N量子比特态可以同时违反所有相关的贝尔不等式，并构建了最大化违反的对称化不等式。


<details>
  <summary>Details</summary>
Motivation: 研究多体量子系统中贝尔非定域性的多配偶性质，探索量子非经典关联在量子技术中的应用潜力，特别是可扩展的量子设备认证。

Method: 利用MABK不等式的对称性质，将(N-k)量子比特贝尔不等式对称化构建N量子比特贝尔不等式，分析GHZ态和多配偶态的违反情况。

Result: 证明单个N量子比特态可以同时违反所有binom(N,k)个相关贝尔不等式，构建了最大化违反的多配偶态，并展示了超多配偶现象。

Conclusion: 多体量子系统中的贝尔非定域性具有固有的多配偶性质，这种结构揭示了多体量子态中非定域性的丰富性，为量子技术应用提供了新视角。

Abstract: Non-classical quantum correlations underpin both the foundations of quantum mechanics and modern quantum technologies. Among them, Bell nonlocality is a central example. For bipartite Bell inequalities, nonlocal correlations obey strict monogamy: a violation of one inequality precludes violations of other inequalities on the overlapping subsystems. In the multipartite setting, however, Bell nonlocality becomes inherently polygamous. This was previously shown for subsystems obtained by removing a single particle from an $N$-partite system. Here, we generalize this result to arbitrary $(N-k)$-partite subsystems with $k>0$. We demonstrate that a single $N$-qubit state can violate all $\binom{N}{k}$ relevant Bell inequalities simultaneously. We further construct an $N$-qubit Bell inequality, obtained by symmetrizing the $(N-k)$-qubit ones, that is maximally violated by states exhibiting this generalized polygamy. We compare these violations with those achievable by GHZ states and show that polygamy offers an advantage in multipartite scenarios, providing new insights into scalable certification of non-classicality in quantum devices. Our analysis relies on symmetry properties of the MABK inequalities. Finally, we show that this behavior can occur across multiple subsystem sizes, a phenomenon we call hyper-polygamy. These structures reveal the remarkable abundance of nonlocality present in multipartite quantum states and offer perspectives for their applications in quantum technologies.

</details>


### [3] [Slow dynamics and magnon bound states in the 2D long-range quantum Ising model](https://arxiv.org/abs/2512.09037)
*Vighnesh Dattatraya Naik,Markus Heyl*

Main category: quant-ph

TL;DR: 使用神经量子态方法模拟二维长程量子伊辛模型的全局淬火动力学，发现慢弛豫和长寿命振荡现象，这源于幂律相互作用产生的磁振子束缚态形成。


<details>
  <summary>Details</summary>
Motivation: 长程量子伊辛模型的动力学是实验物理的前沿领域（如囚禁离子或里德堡原子系统），但超越一维的理论描述对传统方法构成重大挑战。

Method: 采用神经量子态方法模拟二维量子伊辛模型中从完全极化铁磁态出发的全局淬火动力学，该模型具有幂律衰减的相互作用。

Result: 数值精确模拟显示动力学表现出慢弛豫和长寿命振荡行为，这可以通过磁振子束缚态形成理论解释，该束缚态源于幂律相互作用产生的有效吸引相互作用。

Conclusion: 研究结果可直接在当前实现长程相互作用模型的量子模拟平台（如里德堡原子系统）中观测到，为理解长程量子系统的非平衡动力学提供了新见解。

Abstract: The dynamics of long-range quantum Ising models represents a current frontier in experimental physics, notably in trapped ions or Rydberg atomic systems. However, a theoretical description of these dynamics beyond 1D remains a significant challenge for conventional methods. Here, we address this challenge by means of neural quantum states to simulate global quenches from the fully polarized ferromagnetic state in the 2D quantum Ising model with power-law decaying interactions. From these numerically exact simulations, we find that the dynamics exhibit slow relaxation with long-lived oscillations. We explain this behavior through a theory for the formation of magnon bound states, which are generated, as we show, through effective attractive interactions between magnons that persist over several lattice sites due to the power-law nature of the interactions. Our results are readily observable in current quantum simulation platforms realizing long-range interacting models such as in Rydberg atomic systems.

</details>


### [4] [Optimizing the dynamical preparation of quantum spin lakes on the ruby lattice](https://arxiv.org/abs/2512.09040)
*DinhDuy Vu,Dominik S. Kufel,Jack Kemp,Lode Pollet,Chris R. Laumann,Norman Y. Yao*

Main category: quant-ph

TL;DR: 使用神经量子态模拟量子自旋湖的动态制备，在384原子系统中获得接近γ=ln2的拓扑纠缠熵，提取约束量子自旋湖范围的两个物理长度尺度。


<details>
  <summary>Details</summary>
Motivation: 量子自旋液体是难以捉摸的长程纠缠态。实验表明即使在基态相图不包含拓扑相的情况下，也能通过动力学方法制备具有量子自旋液体关联的状态。理解这种量子自旋"湖"态的微观本质及其与平衡态自旋液体序的关系至关重要。

Method: 扩展使用近似对称神经量子态进行实时演化，直接模拟在多达N=384原子系统中的动力学制备过程。分析各种自旋液体诊断指标随制备协议的变化，优化量子自旋湖的扩展范围。

Result: 在最优情况下，制备的状态显示出覆盖系统一半尺寸的自旋液体特性，拓扑纠缠熵稳定在接近γ=ln2的水平。提取了两个物理长度尺度λ和ξ，分别从上下两个方向约束量子自旋湖的范围ℓ。

Conclusion: 通过神经量子态方法成功模拟了量子自旋湖的动力学制备，揭示了其微观特性与平衡态自旋液体序的关系，为理解非平衡量子态提供了新见解。

Abstract: Quantum spin liquids are elusive long-range entangled states. Motivated by experiments in Rydberg quantum simulators, recent excitement has centered on the possibility of dynamically preparing a state with quantum spin liquid correlation even when the ground state phase diagram does not exhibit such a topological phase. Understanding the microscopic nature of such quantum spin "lake" states and their relationship to equilibrium spin liquid order remains an essential question. Here, we extend the use of approximately symmetric neural quantum states for real-time evolution and directly simulate the dynamical preparation in systems of up to $N=384$ atoms. We analyze a variety of spin liquid diagnostics as a function of the preparation protocol and optimize the extent of the quantum spin lake thus obtained. In the optimal case, the prepared state shows spin-liquid properties extending over half the system size, with a topological entanglement entropy plateauing close to $γ= \ln 2$. We extract two physical length scales $λ$ and $ξ$ which constrain the extent of the quantum spin lake $\ell$ from above and below.

</details>


### [5] [Quantum bootstrap for central potentials](https://arxiv.org/abs/2512.09041)
*Scott Lawrence,Brian McPeak*

Main category: quant-ph

TL;DR: 该论文研究量子力学自举方法在三维中心势场束缚态中的应用，展示了该方法对非代数势（如Yukawa势、高斯势）的有效性，并实现了Cornell势的高精度计算。


<details>
  <summary>Details</summary>
Motivation: 探索量子力学自举方法在更广泛势场类型中的应用潜力，特别是针对非代数势场，验证该方法作为高精度数值计算工具的普适性和有效性。

Method: 采用量子力学自举方法，将其应用于多种三维中心势场，包括Yukawa势、高斯势、Coulomb势和Cornell势，通过数值计算获得基态能量的上下界。

Result: 成功将自举方法应用于非代数势场，实现了Cornell势临界耦合常数的高精度计算（精度优于10^-7），获得了高精度的基态能量下界（部分精度超过10^-8），并探讨了获得有意义上界的条件。

Conclusion: 量子力学自举方法是一种强大的数值工具，能够处理包括非代数势在内的多种势场，实现高精度计算，特别适用于基态物理研究，为量子系统的高精度数值分析提供了有效途径。

Abstract: We study the quantum-mechanical bootstrap as it applies to the bound states of several central potentials in three dimensions. As part of this effort, we show how the bootstrap approach may be applied to ``non-algebraic'' potentials, such as the Yukawa potential (which asymptotically decays as an exponential) and a Gaussian potential. We additionally review the bootstrap of the Coulomb potential, demonstrate a high-precision bootstrap of the Cornell potential, and study conformal quantum mechanics. These results further recommend the bootstrap as a numerical method for high-precision calculations of ground-state physics, where applicable: for example, we are able to determine the critical coupling in the Cornell potential to better than one part in $10^7$, the most precise determination to date. Lower bounds on energies are also of high precision, occasionally one part in greater than $10^8$. Finally, we discuss the circumstances under which we are able to obtain meaningful upper bounds on ground-state energies.

</details>


### [6] [Dressed-state Hamiltonian engineering in a strongly interacting solid-state spin ensemble](https://arxiv.org/abs/2512.09043)
*Haoyang Gao,Nathaniel T. Leitao,Siddharth Dandavate,Lillian B. Hughes Wyatt,Piotr Put,Mathew Mammen,Leigh S. Martin,Hongkun Park,Ania C. Bleszynski Jayich,Mikhail D. Lukin*

Main category: quant-ph

TL;DR: 该研究提出了一种直接调控金刚石中氮空位中心系综本征相互作用的新方法，相比传统的Floquet工程，实现了3.2倍的相干参数提升和2.6倍的AC磁测量灵敏度增强。


<details>
  <summary>Details</summary>
Motivation: 在量子科学应用中，通过Floquet工程控制自旋系综中的偶极相互作用通常会降低自旋间的相互作用强度，从而削弱与目标传感场的有效耦合，限制了计量灵敏度。

Method: 开发了一种直接调控氮空位中心系综本征相互作用的方法，采用垂直于晶格取向的磁场下的缀饰态量子比特编码。

Result: 实现了3.2倍的无量纲相干参数JT₂提升，以及2.6倍（8.3 dB）的AC磁测量灵敏度增强。利用延长的相干时间，实验探测了中间到晚期时间的自旋输运。

Conclusion: 该方法为未来研究氮空位中心系综和其他相互作用的高自旋（S>1/2）系统提供了强大的哈密顿量工程工具。

Abstract: In quantum science applications, ranging from many-body physics to quantum metrology, dipolar interactions in spin ensembles are controlled via Floquet engineering. However, this technique typically reduces the interaction strength between spins, and effectively weakens the coupling to a target sensing field, limiting the metrological sensitivity. In this work, we develop and demonstrate a method for direct tuning of the native interaction in an ensemble of nitrogen-vacancy (NV) centers in diamond. Our approach utilizes dressed-state qubit encoding under a magnetic field perpendicular to the crystal lattice orientation. This method leads to a $3.2\times$ enhancement of the dimensionless coherence parameter $JT_2$ compared to state-of-the-art Floquet engineering, and a $2.6\times$ ($8.3~$dB) enhanced sensitivity in AC magnetometry. Utilizing the extended coherence we experimentally probe spin transport at intermediate to late times. Our results provide a powerful Hamiltonian engineering tool for future studies with NV ensembles and other interacting higher-spin ($S>\frac{1}{2}$) systems.

</details>


### [7] [Quantum Clocks Tick Faster: Entanglement, Contextuality, and the Flow of Time](https://arxiv.org/abs/2512.09100)
*Karl Svozil*

Main category: quant-ph

TL;DR: 基于纠缠态的单量子钟协议，通过贝尔不等式违反证明时间标准的量子特性


<details>
  <summary>Details</summary>
Motivation: 探索如何用量子纠缠系统定义时空度规，研究量子时钟与经典时钟在时间同步上的本质差异

Method: 提出基于单重态关联的纠缠时钟协议，与Peres的经典"炸弹碎片"模型对比，分析不同测量角度下的同步滴答率

Result: 在钝角相对角度下，纠缠时钟比经典基准的同步滴答率高13%；量子系统违反贝尔型不等式，证明其非经典特性

Conclusion: 纠缠时钟的量子特性需要通过多个角度的关联同时考虑才能显现，贝尔型不等式的违反认证了共享时间标准的真正量子本质

Abstract: Building on the recent proposal that a single ``bona fide'' clock suffices to define spacetime's metric, we introduce an Entangled Clock protocol based on singlet-state correlations. Invoking Zeilinger's Foundational Principle, we argue that while the local flow of time, operationally defined as a sequence of detector ``ticks,'' is irreducibly random (one bit per elementary system), the synchronized flow between spatially separated observers depends on their measurement geometry. Comparing the quantum prediction for the coincidence rate with Peres' classical ``bomb fragment'' model, we find that at obtuse relative angles the entangled clock exhibits a 13 percent higher synchronized tick rate than this linear classical benchmark. This ``temporal acceleration'' is linked to contextuality: following Peres, ``unperformed experiments have no results,'' and quantum systems are not constrained to maintain consistency with all counterfactual measurement settings. We stress, however, that for any single measurement angle a suitably tailored classical model can reproduce the quantum rate. The genuinely nonclassical character of the entangled clock emerges only when correlations at several angles are considered simultaneously and are shown to violate Bell-type inequalities. In this sense, the violation of Bell-type bounds serves as a certification that the shared time standard is genuinely quantum.

</details>


### [8] [Islands of Instability in Nonlinear Wavefunction Models in the Continuum: A Different Route to "Chaos"](https://arxiv.org/abs/2512.09109)
*W. David Wick*

Main category: quant-ph

TL;DR: 作者提出了一种绕过精确解限制的方法，通过将测试函数代入可计算表达式来验证非线性波函数模型中的不稳定性判据，适用于实际分子间势能。


<details>
  <summary>Details</summary>
Motivation: 先前研究发现了非线性波函数模型中可能出现的"不稳定岛"，但连续模型的唯一例子基于精确可解的线性薛定谔方程。由于多体问题的精确解罕见，需要一种不依赖精确解的方法来验证不稳定性判据。

Method: 提出通过将测试函数代入可计算表达式来验证不稳定性判据的方法，绕过精确解的限制。该方法可以处理实际的分子间势能。

Result: 该方法能够验证非线性波函数模型中的不稳定性判据，无需依赖精确解，从而可以应用于更广泛的物理系统。

Conclusion: 提出的方法克服了精确解的限制，使得不稳定性判据的验证可以应用于包含实际分子间势能的系统，可能对流体和气体中的不稳定性研究有重要意义。

Abstract: In two previous papers the author described ``Islands of Instability" that may appear in wavefunction models with nonlinear evolution (of a type proposed originally in the context of the Measurement Problem). Such ``IsoI" represent a new scenario for Hamiltonian systems implying so-called ``chaos". Criteria was derived for, and shown to be fulfilled in, some finite-dimensional (multi-qubit) models, and generalized in the second paper to continuum models. But the only example produced of the latter was a model whose linear Schrodinger equation was exactly-solvable. As exact solutions of many-body problems are rare, here I show that the instability criteria can be verified by plugging test-functions into certain computable expressions, bypassing the solvability blockade. The method can accommodate realistic inter-molecular potentials and so may be relevant to instabilities in fluids and gasses.

</details>


### [9] [Quantum error correction via purification using a single auxiliary](https://arxiv.org/abs/2512.09745)
*Chandrima B. Pushpan,Tanoy Kanti Konar,Aditi Sen De,Amit Kumar Pal*

Main category: quant-ph

TL;DR: 提出一种基于辅助系统的量子纠错框架，通过联合时间演化和单次测量实现从激发态到基态子空间的纯化，能纠正包括振幅阻尼噪声在内的多种错误类型。


<details>
  <summary>Details</summary>
Motivation: 传统量子纠错码主要针对基态子空间内的错误，但实际量子系统可能被驱动到激发态。需要开发能够纠正将系统从基态子空间驱动到激发态的错误的方法，特别是针对振幅阻尼噪声等非传统错误类型。

Method: 提出辅助系统辅助的纯化框架：1）系统与辅助系统在特定设计的相互作用哈密顿量下进行联合时间演化；2）在能量本征基中对辅助系统进行单次测量；3）对特定测量结果进行后选择。通过这种方法将系统从激发态纯化回基态子空间。

Result: 1）纯化后的状态总能达到单位保真度；2）辅助系统获得非基态能量的概率即为协议的成功率；3）该方法扩展了给定纠错码的可纠正错误类别，特别是在振幅阻尼噪声下；4）在3、4、5量子比特码和一维各向同性海森堡模型中验证了有效性；5）分析了用单辅助量子比特替代辅助量子dit的影响以及噪声在纠错周期中持续存在时的性能变化。

Conclusion: 该辅助系统辅助的纯化框架为量子纠错提供了新方法，特别适用于纠正将系统驱动到激发态的错误，扩展了现有纠错码的能力范围，为实际量子计算中的噪声处理提供了有前景的解决方案。

Abstract: We propose a single auxiliary-assisted purification-based framework for quantum error correction, capable of correcting errors that drive a system from its ground-state subspace into excited-state sectors. The protocol consists of a joint time evolution of the system-auxiliary duo under a specially engineered interaction Hamiltonian, followed by a single measurement of the auxiliary in its energy eigenbasis and a subsequent post-selection of one of the measurement outcomes. We show that the resulting purified state always achieves unit fidelity, while the probability of obtaining any energy of the auxiliary other than its ground state energy yields the success rate of the protocol. We demonstrate the power of this proposed method for several low-distance quantum codes, including the three-, four-, and five-qubit codes, and for the one-dimensional isotropic Heisenberg model, subjected to bit-flip, phase-flip, and amplitude-damping noises acting on all qubits. Notably, the protocol expands the class of correctable errors for a given code, particularly in the presence of amplitude-damping noise. We further analyze the impact of replacing the auxiliary qudit with a single auxiliary qubit, and the changes in the performance of the protocol under the realistic scenario where noise remains active during the correction cycle.

</details>


### [10] [Transition rates and their applications in accelerated single-qubit for fermionic spinor field coupling](https://arxiv.org/abs/2512.09144)
*Arnab Mukherjee,Sunandan Gangopadhyay,P. H. M. Barros,H. A. S. Costa*

Main category: quant-ph

TL;DR: 研究加速运动的量子比特与费米子旋量场的相互作用，发现费米子场耦合比标量场耦合导致更快的量子相干性退相干，而粒子质量对Unruh效应引起的退相干具有保护作用。


<details>
  <summary>Details</summary>
Motivation: 研究均匀加速的量子比特（Unruh-DeWitt探测器）与费米子旋量场的相互作用，探究费米子场耦合对量子相干性的影响，并与标量场耦合情况进行比较。

Method: 采用微扰理论分析有限时间内量子比特与费米子旋量场的相互作用，计算跃迁概率率，进而评估初始处于量子比特态的UDW探测器的量子相干性。考虑无质量和有质量的费米子旋量场两种情况。

Result: UDW探测器与费米子场耦合时响应更强，量子相干性退相干比标量场耦合情况更快。粒子质量对Unruh效应引起的退相干具有保护作用：当静止质量能与探测器能级间距相当时，探测器激发概率和响应降低，从而减缓量子相干性退化。

Conclusion: 费米子场耦合比标量场耦合导致更显著的量子相干性退相干，而粒子质量可以作为保护机制减缓加速量子系统中的Unruh效应引起的退相干。

Abstract: In this work, we investigate the interaction between a uniformly accelerated single qubit and a fermionic spinor field. Here we consider both the massless and the massive fermionic spinor fields. The qubit-field interaction occurs over a finite time and was evolved via perturbation theory. This approach yields the transition probability rates, from which we subsequently evaluate the quantum coherence of an Unruh-DeWitt (UDW) detector initially prepared in a qubit state. Our findings reveal that the UDW detector responds more when coupled with the fermionic field, and consequently, quantum coherence (for the fermionic case) degrades much more rapidly when compared to the case of the qubit linearly coupled with the scalar field. Moreover, the analysis suggests that particle mass plays a protective role against Unruh-induced decoherence as the rest mass energy becomes comparable to the detector's energy-level spacing, the detector's excitation probability and response decreases, which leads to the mitigation of quantum coherence degradation in accelerated quantum systems.

</details>


### [11] [Exact and Efficient Stabilizer Simulation of Thermal-Relaxation Noise for Quantum Error Correction](https://arxiv.org/abs/2512.09189)
*Sean R. Garner,Nathan M. Myers,Meng Wang,Samuel Stein,Chenxu Liu,Ang Li*

Main category: quant-ph

TL;DR: 本文开发了一种精确且与稳定子兼容的量子比特热弛豫噪声模型，解决了传统泡利旋转近似在模拟物理相关通道时的失真问题，并应用于超导平台上的大表面码和双变量自行车码分析。


<details>
  <summary>Details</summary>
Motivation: 传统基于稳定子的量子纠错码模拟通常依赖泡利旋转近似（PTA）来处理非克利福德噪声，但PTA会扭曲热弛豫等物理相关通道的行为。需要物理精确的噪声模拟来训练解码器并理解量子纠错码的噪声抑制能力。

Method: 开发了精确且与稳定子兼容的量子比特热弛豫噪声模型，证明了当T2 ≤ T1时，组合的振幅阻尼和退相干通道可以完全正概率分解为克利福德操作和重置操作。对于T2 > T1的情况，虽然分解会产生负概率，但比独立通道的采样开销更小。进一步引入了带重置的近似误差通道，消除了分解的负性，同时比PTA获得更高的通道保真度，并将构造扩展到有限温度弛豫。

Result: 将精确组合模型应用于具有现实热弛豫误差的超导平台上的大表面码和双变量自行车码。不同编码状态之间的逻辑性能差异表明，基于噪声模型信息的解码器对于准确捕捉未来容错架构中的热噪声结构至关重要。

Conclusion: 本文提出的精确热弛豫噪声模型解决了PTA的失真问题，为物理精确的量子纠错码模拟提供了有效工具。研究结果表明，噪声模型感知的解码器对于准确处理热噪声结构在未来容错量子计算中具有关键重要性。

Abstract: Stabilizer-based simulation of quantum error-correcting codes typically relies on the Pauli-twirling approximation (PTA) to render non-Clifford noise classically tractable, but PTA can distort the behavior of physically relevant channels such as thermal relaxation. Physically accurate noise simulation is needed to train decoders and understand the noise suppression capabilities of quantum error correction codes. In this work, we develop an exact and stabilizer-compatible model of qubit thermal relaxation noise and show that the combined amplitude damping and dephasing channel admits a fully positive probability decomposition into Clifford operations and reset whenever $T_2 \leqslant T_1$. For $T_2 > T_1$, the resulting decomposition is negative, but allows a smaller sampling overhead versus independent channels. We further introduce an approximated error channel with reset that removes the negativity of the decomposition while achieving higher channel fidelity to the true thermal relaxation than PTA, and extend our construction to finite temperature relaxation. We apply the exact combined model to investigate large surface codes and bivariate bicycle codes on superconducting platforms with realistic thermal relaxation error. The differing logical performances across code states further indicate that noise-model-informed decoders will be essential for accurately capturing thermal-noise structure in future fault-tolerant architectures.

</details>


### [12] [Parallel accelerated electron paramagnetic resonance spectroscopy using diamond sensors](https://arxiv.org/abs/2512.09230)
*Zhehua Huang,Zhengze Zhao,Fei Kong,Zhecheng Wang,Pengju Zhao,Xiangtian Gong,Xiangyu Ye,Ya Wang,Fazhan Shi,Jiangfeng Du*

Main category: quant-ph

TL;DR: 该论文提出了一种零场交叉弛豫电子顺磁共振（EPR）光谱方法，通过振幅调制控制场调节氮空位（NV）中心传感器，使其与目标匹配，解决了传统NV系综EPR光谱中传感器和目标不均匀性导致的谱线展宽问题。


<details>
  <summary>Details</summary>
Motivation: 传统使用NV系综进行EPR光谱测量效率较低，主要问题在于传感器（NV中心）和目标（自由基）的不均匀性会导致谱线展宽，这对光谱分析是有害的。需要开发一种能够克服这些不均匀性问题的EPR测量方法。

Method: 提出了一种零场交叉弛豫EPR光谱方法，使用振幅调制控制场来调节NV中心传感器，使其与目标匹配。调制使检测对传感器的不均匀性具有鲁棒性，而零场EPR自然对目标的不均匀性具有鲁棒性。该方法在大约30000个NV中心的系综上进行了演示。

Result: 该方法实现了高效的EPR测量，不仅能够获取自由基的无歧义EPR光谱，还能够实时监测其光谱动力学变化。演示表明该方法在NV系综上具有实际应用价值。

Conclusion: 提出的零场交叉弛豫EPR光谱方法通过调制技术和零场条件，有效克服了传统NV系综EPR测量中的不均匀性问题，为基于NV中心的磁传感应用提供了更高效、更精确的EPR测量方案。

Abstract: The nitrogen-vacancy (NV) center can serve as a magnetic sensor for electron paramagnetic resonance (EPR) measurements. Benefiting from its atomic size, the diamond chip can integrate a tremendous amount of NV centers to improve the magnetic-field sensitivity. However, EPR spectroscopy using NV ensembles is less efficient due to inhomogeneities in both sensors and targets. Spectral line broadening induced by ensemble averaging is even detrimental to spectroscopy. Here we show a kind of cross-relaxation EPR spectroscopy at zero field, where the sensor is tuned by an amplitude-modulated control field to match the target. The modulation makes detection robust to the sensor's inhomogeneity, while zero-field EPR is naturally robust to the target's inhomogeneity. We demonstrate an efficient EPR measurement on an ensemble of roughly 30000 NV centers. Our method shows the ability to not only acquire unambiguous EPR spectra of free radicals, but also monitor their spectroscopic dynamics in real time.

</details>


### [13] [Spontaneous Decoherence from Imaginary-Order Spectral Deformations](https://arxiv.org/abs/2512.09236)
*Sridhar Tayur*

Main category: quant-ph

TL;DR: 论文提出一种通过哈密顿量虚数阶谱变形H^{1+iβ}实现自发退相干的新机制，该机制通过E^{iβ} = e^{iβlogE}因子修改动力学相位，快速振荡抑制不同能量间的干涉。


<details>
  <summary>Details</summary>
Motivation: 物理动机来自时钟不完美性、重整化群和有效作用量修正引入的对数谱项，以及半经典量子引力分析中复数作用量产生的E^{iβ}形式谱因子。该机制为量子引力动机有效理论中出现的对数谱修正提供了紧凑且可测试的现象学表示。

Method: 将量子动力学生成元替换为正定哈密顿量H的虚数阶谱变形H^{1+iβ}，通过非平稳相位分析获得振幅或退相干泛函中振荡贡献的定量估计。Born规则和希尔伯特空间内积保持不变，修改完全是动力学的。

Result: 非平稳相位分析表明振荡贡献对振幅或退相干泛函的衰减至少为O(1/|β|)。通过FRW迷你超空间、四次势、弯曲背景哈密顿量和Schwarzschild内部型模型等示例，该机制产生明确的退相干速率。参数β可通过低噪声量子平台中的精密相干测量进行实验约束。

Conclusion: 该机制与Milburn型内在退相干、Diosi-Penrose引力坍缩和实数阶分数动力学不同，它完全通过单个哈密顿量的确定性谱相位起作用。该框架作为量子引力动机有效理论中出现的对数谱修正的紧凑且可测试的现象学表示。

Abstract: We examine a mechanism of spontaneous decoherence in which the generator of quantum dynamics is replaced by the imaginary-order spectral deformation $H^{1+iβ}$ of a positive Hamiltonian $H$. The deformation modifies dynamical phases through the factor $E^{iβ} = e^{iβ\log E}$, whose rapid oscillation suppresses interference between distinct energies. A non-stationary-phase analysis yields quantitative estimates showing that oscillatory contributions to amplitudes or decoherence functionals decay at least as $O(1/|β|)$. The Born rule and the Hilbert-space inner product remain unchanged; the modification is entirely dynamical.
  The physical motivation for the deformation arises from clock imperfections, renormalization-group and effective-action corrections that introduce logarithmic spectral terms, and semiclassical quantum-gravity analyses in which complex actions produce spectral factors of the form $E^{iβ}$. Examples including FRW minisuperspace, quartic potentials, curved-background Hamiltonians, and a Schwarzschild interior-type model illustrate how the mechanism yields explicit decoherence rates. The parameter $β$ may be experimentally constrained through precision coherence measurements in low-noise quantum platforms. The mechanism contrasts with Milburn-type intrinsic decoherence, Diosi-Penrose gravitational collapse, and real-order fractional dynamics in that it acts purely through deterministic spectral phases of a single Hamiltonian. The analysis positions the framework as a compact and testable phenomenological representation of logarithmic spectral corrections appearing in quantum-gravity-motivated effective theories.

</details>


### [14] [Harvesting entanglement from the Lorentz-violating quantum field vacuum in a dipolar Bose-Einstein condensate](https://arxiv.org/abs/2512.09263)
*Zehua Tian,Weiping Yao,Xiaobao Liu,Mengjie Wang,Jieci Wang,Jiliang Jing*

Main category: quant-ph

TL;DR: 提出利用偶极玻色-爱因斯坦凝聚体（BEC）中的杂质对来研究从洛伦兹破缺量子场真空中提取纠缠的方案，发现与洛伦兹不变情况不同的参数依赖关系


<details>
  <summary>Details</summary>
Motivation: 探索从洛伦兹破缺量子场真空中提取纠缠的机制，为量子场论中的洛伦兹不变性破缺研究提供实验可行的测试平台

Method: 使用超低温偶极BEC模拟洛伦兹破缺真空场，将两个杂质作为Unruh-DeWitt探测器来探测BEC准粒子，研究从这种模拟量子场真空中提取纠缠的方案

Result: 发现与洛伦兹不变情况不同的关键参数依赖：更平滑的探测器开关不会增强纠缠提取效率；洛伦兹不变性破缺强度会改变探测器的最佳能级结构

Conclusion: 该量子流体平台为从有效洛伦兹破缺量子场真空中提取纠缠提供了实验可行的测试床，对探索量子场论中的洛伦兹不变性破缺具有潜在意义

Abstract: We theoretically propose an experimentally viable scheme to explore the transfer of nonclassical correlations from a dipolar Bose-Einstein condensate (BEC) to a pair of impurities immersed in it. Operating at ultra-low temperature, density fluctuations of the dipolar BEC emulate a vacuum field with Lorentz-violating dispersion, while the two impurities function as Unruh-DeWitt detectors for the BEC quasiparticles. We study the harvesting of entanglement from the quantum vacuum of this analogue Lorentz-violating quantum field by spatially separated Unruh-DeWitt detectors. Our analysis reveals key parameter dependencies that optimize the harvesting of entanglement. In particular, unlike the Lorentz-invariant case, smoother detector switchings does not enhance the entanglement harvesting efficiency from the Lorentz-violating quantum field vacuum. Moreover, the strength of the Lorentz-invariant violation can shift the optimal energy structure of the detectors for harvesting entanglement from the Lorentz-violating quantum field vacuum-a clear deviation from the Lorentz-invariant scenario. As a fundamental quantum mechanical setup, our quantum fluid platform provides an experimentally realizable testbed for examining the entanglement harvesting protocol from an effective Lorentz-violating quantum field vacuum using a pair of impurity probers, which may also has potential implications for exploring the Lorentz-invariant violation in quantum field theory.

</details>


### [15] [Mpemba as an Emergent Effect of System Relaxation](https://arxiv.org/abs/2512.09324)
*Gourab Das*

Main category: quant-ph

TL;DR: 该论文提出了一个解释量子系统中Mpemba效应的通用模型，该效应指远离平衡态的系统比接近平衡态的系统弛豫更快。模型基于马尔可夫弛豫动力学，不依赖系统结构或环境，关键在于初始态与快速弛豫模式的重叠。


<details>
  <summary>Details</summary>
Motivation: Mpemba效应在经典和量子系统中都存在，但现有理论多为针对特定驱动系统的解释。对于最初观察到该效应的无驱动系统，其基本机制仍未解决，需要建立一个通用的理论模型来解释这一反常现象。

Method: 提出了一个适用于量子系统的通用Mpemba效应模型，基于马尔可夫弛豫动力学。模型的关键在于初始态与快速弛豫模式的重叠，系统组分通过共享环境的相互作用创建快速衰减模式。还研究了各向异性弛豫系统，即使没有共享环境也能展现Mpemba效应。

Result: 建立了Mpemba效应的通用理论框架，表明该效应源于系统的集体行为。系统组分通过共享环境的相互作用创建快速衰减模式，导致远离平衡态的系统弛豫更快。各向异性弛豫系统即使没有共享环境也能自然展现Mpemba效应。

Conclusion: Mpemba效应是量子系统中普遍存在的现象，不依赖特定系统结构或环境。该效应源于系统的集体行为，通过初始态与快速弛豫模式的重叠实现。各向异性弛豫系统即使没有共享环境也能展现这一效应，为理解这一反常现象提供了统一的理论基础。

Abstract: The Mpemba effect (MpE), where a far-from-equilibrium state of a system relaxes faster compared to a state closer to it, is a well-known counterintuitive phenomenon in classical and quantum systems. Various system-specific theories have been proposed to explain this anomalous behavior in driven systems, though the fundamental mechanism of MpE in undriven systems, where MpE was first observed, remains unresolved. This paper provides a generic model of MpE for a quantum system following Markovian relaxation dynamics, regardless of system structure or environment. The key lies in the overlap of initial states with the fast relaxation mode; here, the constituents create a fast decay mode via interaction through the shared environment to show MpE, indicating MpE happens due to the collective behavior of the system. I also show that a system with anisotropic relaxation naturally exhibits MpE, even without a shared environment among the particles.

</details>


### [16] [Routes of Transport in the Path Integral Lindblad Dynamics through State-to-State Analysis](https://arxiv.org/abs/2512.09362)
*Devansh Sharma,Amartya Bose*

Main category: quant-ph

TL;DR: 扩展状态到状态分析方法，使其能够处理更一般的Lindblad型耗散、泵浦和退相干过程，用于分析开放量子系统中的输运路径


<details>
  <summary>Details</summary>
Motivation: 现有的非厄米描述无法处理更一般的经验过程，特别是各种泵浦过程。需要扩展状态到状态分析方法，使其能够处理Lindblad型耗散、泵浦和退相干过程，以分析开放量子系统中的输运机制

Method: 将状态到状态分析扩展到Lindblad描述，处理一般的耗散、泵浦和退相干过程。该方法可以阐明系统与热浴耦合并受Lindblad跳跃算子作用时的输运路径

Result: 使用激子聚集体受非相干泵浦和耗散过程的例子演示了该方法，展示了稳态激子电流在分子聚集体中的建立

Conclusion: Lindblad状态到状态方法为量化开放量子系统中的输运路径提供了新的第一性原理方法，特别适用于处理更一般的耗散、泵浦和退相干过程

Abstract: Analyzing routes of transport for open quantum systems with non-equilibrium initial conditions is extremely challenging. The state-to-state approach [A. Bose, and P.L. Walters, J. Chem. Theory Comput. 2023, 19, 15, 4828-4836] has proven to be a useful method for understanding transport mechanisms in quantum systems interacting with dissipative thermal baths, and has been recently extended to non-Hermitian systems to account for empirical loss. These non-Hermitian descriptions are, however, not capable of describing empirical processes of more general nature, including but not limited to a variety of pumping processes. We extend the state-to-state analysis to account for Lindbladian descriptions of generic dissipative, pumping and decohering processes acting on a system which is exchanging energy with a thermal bath. This Lindblad state-to-state method can elucidate routes of transport in systems coupled to a bath and additionally acted upon by Lindblad jump operators. The method is demonstrated using examples of excitonic aggregates subject to incoherent pumping and draining processes. Using this new state-to-state formalism, we demonstrate the establishment of steady-state excitonic currents across molecular aggregates, yielding a different first-principles approach to quantifying the same.

</details>


### [17] [Compact and efficient quantum frequency conversion of a fiber-pigtailed single-photon source](https://arxiv.org/abs/2512.09390)
*Mathis Cohen,Anthony Martin,Romain Dalidet,Florian Pastier,Marie Billard,Aristide Lemaitre,Valérian Giesz,Niccolo Somaschi,Sarah Thomas,Pascale Senellart-Mardon,Sébastien Tanzilli,Laurent Labonté*

Main category: quant-ph

TL;DR: 该论文报道了一种结合非线性光学铌酸锂波导和量子点单光子源的相干频率转换方案，成功将单光子从925.7nm转换到电信C波段，实现了48.4%的端到端效率，并完全保持了单光子纯度和不可区分性。


<details>
  <summary>Details</summary>
Motivation: 量子频率转换是连接量子发射器和电信光子的关键技术，对于实现不同波长量子信息处理系统的实用互连至关重要。

Method: 采用基于光纤耦合的非线性光学铌酸锂波导与光纤尾纤的半导体量子点单光子源相结合的相干频率转换方案。

Result: 实现了从925.7nm到电信C波段的单光子频率转换，端到端效率达到48.4%，完全保持了单光子纯度和不可区分性。

Conclusion: 两个基于光纤的模块集成实现了顶级性能，这代表了未来在不同波长运行的量子信息处理系统实用互连的重要进展。

Abstract: Quantum frequency converters are key enabling technologies in photonic quantum information science to bridge the gap between quantum emitters and telecom photons. Here, we report a co- herent frequency converter scheme combining a fiber-coupled nonlinear optical Lithium Niobate waveguide with a fiber-pigtailed single-photon source based on semiconductor quantum dots. Single and indistinguishable photons are converted from 925.7 nm to the telecommunication C-band, with a 48.4% end-to-end efficiency and full preservation of single-photon purity and indistinguishability. The integration of the two fiber-based modules achieving top-level performance represents an im- portant step toward the practical interconnection of future quantum information processing systems operating at different wavelengths.

</details>


### [18] [Two-Photon Bandwidth of Hyper-Entangled Photons in Complex Media](https://arxiv.org/abs/2512.09456)
*Ronen Shekel,Ohad Lib,Sébastien M. Popoff,Yaron Bromberg*

Main category: quant-ph

TL;DR: 利用空间-光谱超纠缠光子对，通过双光子带宽实现宽带模态色散消除，提升量子成像、通信和传感性能


<details>
  <summary>Details</summary>
Motivation: 光在复杂介质中传播时，输出空间分布对波长高度敏感，这限制了成像和通信等应用的带宽。需要解决这一经典限制

Method: 使用空间和光谱同时纠缠的超纠缠光子对，通过一个光子的色散模态被其光谱反关联的双胞胎光子抵消，定义"双光子带宽"

Result: 在多模光纤、薄扩散器和闪耀光栅中实现了模态色散消除，证明了量子态宽带波前整形的实用性

Conclusion: 超纠缠光子对的空间关联在宽带宽下保持稳定，双光子带宽可远超经典对应物，推动了量子光在复杂介质中的基础理解和应用

Abstract: When light propagates through complex media, its output spatial distribution is highly sensitive to its wavelength. This fundamentally limits the bandwidth of applications ranging from imaging to communication. Here, we demonstrate analytically and numerically that the spatial correlations of hyper-entangled photon pairs, simultaneously entangled spatially and spectrally, remain stable across a broad bandwidth: The chromatic modal dispersion experienced by one photon is canceled to first order by its spectrally anti-correlated twin, defining a "two-photon bandwidth" that can far exceed its classical counterpart. We illustrate this modal dispersion cancellation in multimode fibers, thin diffusers and blazed gratings, and demonstrate its utility for broadband wavefront shaping of quantum states. These findings advance our fundamental understanding of quantum light in complex media with applications in quantum imaging, communication, and sensing.

</details>


### [19] [Can Intense Quantum Light Beat Classical Uncertainty Relations?](https://arxiv.org/abs/2512.09558)
*Felipe Reibnitz Willemann,Mauro Antezza,Johannes Feist*

Main category: quant-ph

TL;DR: 该论文研究了多模光量子态中时间延迟和频率带宽的联合不确定性关系，发现违反经典界限可以证明纠缠的存在，且非经典修正与平均光子数成反比关系。


<details>
  <summary>Details</summary>
Motivation: 不确定性关系是量子力学的基础，编码了共轭可观测量同时测量的限制。违反联合不确定性界限可以证明纠缠的存在，而纠缠是量子信息协议的关键资源，在强场物理中也越来越重要。

Method: 研究任意多模光量子态中成对的时间延迟和频率带宽不确定性，推导出它们联合乘积的一般下界。

Result: 发现非经典修正与平均光子数成反比，这种行为源于所谓的"纠缠单配性"。这些结果阐明了非经典光态中量子优势的强度标度，并突出了纠缠和光子统计之间的相互作用。

Conclusion: 该研究为理解多模光量子态中的不确定性关系提供了新的理论框架，揭示了纠缠与光子统计之间的深刻联系，对量子信息处理和强场物理有重要意义。

Abstract: Uncertainty relations are fundamental to quantum mechanics, encoding limits on the simultaneous measurement of conjugate observables. Violations of joint uncertainty bounds can certify entanglement -- a resource critical for quantum information protocols and increasingly relevant in strong-field physics. Here, we investigate the pairwise time-delay and frequency-bandwidth uncertainties for arbitrary multimode quantum states of light, deriving a general lower bound for their joint product. We find that the nonclassical correction scales inversely with the average photon number, a behavior rooted in the so-called ``monogamy of entanglement''. These results clarify the intensity scaling of quantum advantages in nonclassical light states and highlight the interplay between entanglement and photon statistics.

</details>


### [20] [Exceptional points of arbitrary high orders induced by non-Markovian dynamics](https://arxiv.org/abs/2512.09582)
*Timofey T. Sergeev,Evgeny S. Andrianov,Alexander A. Zyablovsky*

Main category: quant-ph

TL;DR: 非厄米系统中的高阶异常点：通过非马尔可夫效应和观测时间选择，可以实现超越系统自由度数量的高阶异常点


<details>
  <summary>Details</summary>
Motivation: 传统观点认为异常点的阶数受限于非厄米系统的自由度数量，本文旨在挑战这一观点，展示非马尔可夫效应如何产生超越系统自由度的高阶异常点

Method: 利用非马尔可夫效应，当能量从储层返回系统时，系统动力学被分为多个区间，每个区间由指数函数和多项式函数的乘积描述，多项式阶数不断增加

Result: 通过选择合适的观测时间，可以观察到任意高阶的异常点，突破了传统上异常点阶数受限于系统自由度的限制

Conclusion: 非马尔可夫效应能够产生超越系统自由度数量的高阶异常点，这一发现扩展了对非厄米系统中异常点行为的理解

Abstract: Exceptional points are singularities in the spectrum of non-Hermitian systems in which several eigenvectors are linearly dependent and their eigenvalues are equal to each other. Usually it is assumed that the order of the exceptional point is limited by the number of degrees of freedom of a non-Hermitian system. In this letter, we refute this common opinion and show that non-Markovian effects can lead to dynamics characteristic of systems with exceptional points of higher orders than the number of degrees of freedom in the system. This takes place when the energy returns from reservoir to the system such that the dynamics of the system are divided into intervals in which it describes by the product of the exponential and a polynomial function of ever-increasing order. We demonstrate that by choosing the observation time, it is possible to observe exceptional points of arbitrary high orders.

</details>


### [21] [Quantum Gradient Flow Algorithm for Symmetric Positive Definite Systems via Quantum Eigenvalue Transformation: Towards Quantum CAE](https://arxiv.org/abs/2512.09623)
*Yuto Lewis Terashima,Tadashi Kadowaki,Yohichi Suzuki,Mayu Muramatsu,Katsuhiro Endo*

Main category: quant-ph

TL;DR: 提出量子梯度流算法（QGFA），基于变分原理和时间演化动力学解决对称正定线性系统，相比传统量子矩阵逆算法在条件数增大时表现更好，应用于二维线性弹性有限元问题验证效果。


<details>
  <summary>Details</summary>
Motivation: 传统量子线性求解器（如量子矩阵逆算法）在条件数增大时计算效率下降，而经典对称正定线性求解器（如最速下降法和共轭梯度法）基于变分优化原理具有快速收敛性，受此启发开发新的量子算法。

Method: 提出量子梯度流算法（QGFA），通过相应二次能量泛函的梯度流过程获得解向量，基于变分公式和时间演化动力学，应用于位移基有限元法求解二维线性弹性平面应力问题。

Result: 即使使用中等数量的量子信号处理相位因子，QGFA也能准确收敛到经典有限元解；与量子矩阵逆算法相比，在合适的初始状态下获得更低的相对误差和更快的收敛速度。

Conclusion: QGFA作为高效的预条件量子线性求解器具有潜力，为经典迭代求解器与量子计算范式之间提供物理可解释的连接，可作为量子计算机辅助工程（Quantum CAE）未来发展的基础。

Abstract: In this study, we propose the Quantum Gradient Flow Algorithm (QGFA), a novel quantum algorithm for solving symmetric positive definite (SPD) linear systems based on the variational formulation and time-evolution dynamics. Conventional quantum linear solvers, such as the quantum matrix inverse algorithm (QMIA), focus on approximating the matrix inverse through quantum signal processing (QSP). However, QMIA suffers from a crucial drawback: its computational efficiency deteriorates as the condition number increases. In contrast, classical SPD linear solvers, such as the steepest descent and conjugate gradient methods, are known for their fast convergence, which stems from the variational optimization principle of SPD systems. Inspired by this, we develop QGFA, which obtains the solution vector through the gradient-flow process of the corresponding quadratic energy functional. To validate the proposed method, we apply QGFA to the displacement-based finite element method (FEM) for two-dimensional linear elastic problems under plane stress conditions. The algorithm demonstrates accurate convergence toward classical FEM solutions even with a moderate number of QSP phase factors. Compared with QMIA, QGFA achieves lower relative errors and faster convergence when initialized with suitable initial states, demonstrating its potential as an efficient preconditioned quantum linear solver. The proposed framework provides a physically interpretable connection between classical iterative solvers and quantum computational paradigms. These findings suggest that QGFA can serve as a foundation for future developments in Quantum Computer-Aided Engineering (Quantum CAE), including nonlinear and multiphysics simulations.

</details>


### [22] [Geometric Origin of Quantum Entanglement](https://arxiv.org/abs/2512.09640)
*Marco Zaopo*

Main category: quant-ph

TL;DR: 该论文研究了扩展庞加莱群的质量零表示，发现这些表示与标准庞加莱群的维格纳表示不同，具有额外的自由度，导致光子表现为前后传播电磁波的叠加态，这种依赖关系产生了与双量子比特纠缠态相同的关联。


<details>
  <summary>Details</summary>
Motivation: 研究扩展庞加莱群的质量零表示，探索这些表示与标准维格纳表示的区别，特别是光类轨道稳定子具有额外自由度的情况，为量子场论框架下光子的量子纠缠提供几何起源。

Method: 通过分析扩展庞加莱群的幺正不可约表示（UIRs），证明质量零粒子表示必须分解为质量零前向（正零动量分量）和质量零后向（负零动量分量）维格纳表示的直接和，这两个表示通过内部二值自由度连接。进一步证明这些表示与双量子比特纠缠态幺正等价。

Result: 发现扩展庞加莱群的质量零幺正不可约表示必须分解为前向和后向维格纳表示的直接和，这些表示与双量子比特纠缠态幺正等价。这为光子的量子纠缠提供了几何起源：光子表现为依赖于二值参数的前后传播电磁波的叠加态，这种依赖关系产生了与双量子比特纠缠态相同的局部可观测量关联。

Conclusion: 扩展庞加莱群的质量零表示提供了量子场论中光子量子纠缠的几何解释，光子作为前后传播电磁波的叠加态表现出纠缠特性。论文还提出了能够区分连接前后质量零表示的二值参数的实验方案，为该理论提供了实验验证的可能性。

Abstract: We investigate massless representations related to the extension of Poincarè group constructed in [1]. These representations differ from Wigner's ones of standard Poincarè group because the stabilizer of lightlike orbits has extra degrees of freedom. The unitary irreducible representations (UIRs) of massless particles in this extension must decompose as a direct sum of a massless forward (positive zeroth component momentum) and massless backward (negative zeroth component momentum) Wigner's representations linked by internal two valued degree of freedom. We prove that these representations are unitarily equivalent to entangled states of two qubits. This provides a geometric origin of quantum entanglement for photons in the framework of quantum field theory: photons appear as superpositions of backward and forward propagating electromagnetic waves depending on a two valued parameter and this dependency gives rise to correlations between the values of local observables identical to those experienced with an entangled state of two qubits. Finally we describe an experiment capable of distinguishing the two different values of the parameter that links backward and forward massless representations providing experimental falsification of the theory.

</details>


### [23] [Entanglement with a mode observable via a tunable interaction with a qubit](https://arxiv.org/abs/2512.09658)
*Małgorzata Strzałka,Radim Filip,Katarzyna Roszak*

Main category: quant-ph

TL;DR: 研究通过仅测量量子比特来检测"自旋-玻色子"纠缠的可能性，利用可调耦合克服传统方法的对称性限制


<details>
  <summary>Details</summary>
Motivation: 传统固定系统-环境相互作用的方案由于耦合和初始态的固有对称性，无法检测自旋-玻色子纠缠，需要新的检测方法

Method: 利用量子比特-环境耦合可调的特性（如超导transmon量子比特与微波腔系统），设计合适的哈密顿量参数用于准备和测量阶段

Result: 提出的检测方案在有限温度下仍能产生非可忽略的信号，适合实验验证

Conclusion: 通过利用可调耦合特性，实现了仅通过量子比特测量来检测自旋-玻色子纠缠的新方法，为量子信息处理提供了重要工具

Abstract: We study the possibility of detection of ``spin-boson'' entanglement by qubit only measurements. Such entanglement is impossible to detect by previously proposed schemes that involve a fixed system-environment interaction, because of inherent symmetries within the coupling and the initial state of the environment. We take advantage of the possibility of tuning of qubit-environment coupling, that is available in some qubit realizations. As an example we study a superconducting transmon qubit interacting with a microwave cavity, which is one of such systems and is, furthermore, essential in the context of quantum information processing. We propose suitable Hamiltonian parameters for the preparation and measurement phases of the detection scheme that allow for an experimental test, and verify that the reported signal is nonnegligibly large still at finite temperatures.

</details>


### [24] [Pattern Based Quantum Key Distribution using the five qubit perfect code for eavesdropper detection](https://arxiv.org/abs/2512.09672)
*Mehedi Hasan Rumi*

Main category: quant-ph

TL;DR: 提出一种基于五量子比特纠错码的量子密钥分发协议，通过特定编码模式检测窃听者，将信息论攻击转化为经典模式猜测问题


<details>
  <summary>Details</summary>
Motivation: 传统量子密钥分发协议面临各种信息论攻击的威胁，需要更可靠的窃听检测机制。本文旨在利用量子纠错码的特性，将窃听行为转化为可检测的量子错误模式

Method: 使用五量子比特纠错码，将逻辑量子比特按特定模式编码到五个物理量子比特块中。协议安全性依赖于Alice和Bob选择的正确编码模式，任何错误的解码模式都会增加多量子比特错误率

Result: 五量子比特码能将窃听者的逻辑扰动转化为可检测的特征信号，与自然信道噪声在特定距离内可区分，从而可靠检测窃听者存在

Conclusion: 该协议通过量子纠错码的编码模式选择，实现了对窃听者的可靠检测，将信息论攻击转化为经典模式猜测问题，提高了量子密钥分发的安全性

Abstract: I propose a new quantum key distribution protocol that uses the five qubit error correction code to detect the presence of eavesdropper reliably. The protocol turns any information theoretical attacks into a classical guess about the pattern. The logical qubit is encoded with a specific pattern into a block of five physical qubits. The security of the protocol relies on the correct pattern choice of Alice and Bob. Decoding with any wrong pattern choice increases multi qubit error rate and the 5 qubit code transforms an eavesdropper's logical disturbance into a signature that is detectable and distinguishable from natural channel noise up to a certain distance.

</details>


### [25] [Three-body interaction in a magnon-Andreev-superconducting qubit system: collapse-revival phenomena and entanglement redistribution](https://arxiv.org/abs/2512.09697)
*Sheng Zhao,Peng-Bo Li*

Main category: quant-ph

TL;DR: 提出了一种混合量子架构，利用磁振子模式、安德烈夫自旋量子比特和超导量子比特实现单量子级别的强三体相互作用，展示了通过三体耦合产生的新型量子现象。


<details>
  <summary>Details</summary>
Motivation: 三体相互作用对于实现超越成对物理的新型量子现象至关重要，但特别是在不同量子系统之间实现三体相互作用仍然具有挑战性。需要开发能够实现强三体相互作用的混合量子架构。

Method: 提出了一种混合量子架构，包含YIG球体中的磁振子模式、安德烈夫自旋量子比特和超导量子比特。利用ASQ的自旋相关超电流和电路集成灵活性，设计了一种强三方耦合，在磁振子湮灭时共同激发两个量子比特（或在ASQ退激发时激发磁振子和SCQ）。

Result: 通过分析和数值研究证明，当磁振子初始处于相干态时，这种相互作用会引起量子比特布居数的同步坍缩和复苏。在坍缩区域（布居数保持静态），纠缠结构会发生剧烈且连续的重组。真正的三方纠缠被重新分配到两个量子比特之间的两体纠缠中，反之亦然，总纠缠守恒。

Conclusion: 这些通过两体耦合无法实现的现象，突显了三体相互作用在探索本质上新的量子效应和推进混合量子信息平台方面的潜力。

Abstract: Three-body interactions are fundamental for realizing novel quantum phenomena beyond pairwise physics, yet their implementation -- particularly among distinct quantum systems -- remains challenging. Here, we propose a hybrid quantum architecture comprising a magnonic mode (in a YIG sphere), an Andreev spin qubit (ASQ), and a superconducting qubit (SCQ), to realize a strong three-body interaction at the single-quantum level. Leveraging the spin-dependent supercurrent and circuit-integration flexibility of the ASQ, it is possible to engineer a strong tripartite coupling that jointly excites both qubits upon magnon annihilation (or excites magnons and SCQs upon ASQ deexcitation). Through analytical and numerical studies, we demonstrate that this interaction induces synchronized collapse and revival in qubit populations when the magnon is initially prepared in a coherent state. Notably, during the collapse region -- where populations remain static -- the entanglement structure undergoes a dramatic and continuous reorganization. We show that the genuine tripartite entanglement is redistributed into bipartite entanglement between the two qubits, and vice versa, with the total entanglement conserved. These phenomena, unattainable via two-body couplings, underscore the potential of three-body interactions for exploring intrinsically new quantum effects and advancing hybrid quantum information platforms.

</details>


### [26] [Device Independent Quantum Secret Sharing Using Multiparty Pseudo-telepathy Game](https://arxiv.org/abs/2512.09699)
*Santanu Majhi,Goutam Paul*

Main category: quant-ph

TL;DR: 提出基于多体伪心灵感应奇偶校验游戏的设备无关量子秘密共享协议，无需专用测试轮次即可同时实现设备无关性验证和密钥生成，相比CHSH方案资源需求更低且抗噪声


<details>
  <summary>Details</summary>
Motivation: 克服不可信量子设备带来的安全限制，开发更高效的设备无关量子秘密共享协议

Method: 基于多体伪心灵感应奇偶校验游戏构建DI-QSS协议，使用七量子比特GHZ态配置，无需专用测试轮次即可同时进行设备无关性验证和密钥生成

Result: 协议在七量子比特GHZ态配置下达到最优性能，相比先前协议对相同长度原始密钥的资源需求更低，且在噪声环境中保持鲁棒性

Conclusion: 提出的基于多体伪心灵感应奇偶校验游戏的DI-QSS协议实现了高效、资源节约且抗噪声的设备无关量子秘密共享

Abstract: Device-independent quantum secret sharing (DI-QSS) is a cryptographic protocol that overcomes the security limitations posed by untrusted quantum devices. We propose a DI-QSS protocol based on the multipartite pseudo-telepathy parity game, which achieves device-independence with simultaneous key generation without requiring dedicated test rounds, unlike CHSH-based schemes [Zhang et al., Phys. Rev. A, 2024]. Notably, the proposed scheme allows simultaneous device-independence verification and key-generation phases, achieving optimal performance for a seven-qubit GHZ state configuration. Further, we analyse the security of our protocol against collective attack and establish reduced resource requirement for the same length of the raw key compared to the previous protocol. Finally, we show that our protocol remains robust even in a noisy environment.

</details>


### [27] [Dynamic stimulated emission for deterministic addition and subtraction of propagating photons](https://arxiv.org/abs/2512.09711)
*Haoyuan Luo,Parth S. Shah,Frank Yang,Mohammad Mirhosseini,Sahand Mahmoodian*

Main category: quant-ph

TL;DR: 该论文提出了一种基于动态受激发射的确定性单光子加减方法，通过量子发射体与时间相关耦合实现高保真度的非高斯光态制备。


<details>
  <summary>Details</summary>
Motivation: 传统使用线性光学和数分辨探测的光子加减方法成功率低，需要开发更高效的确定性光子加减技术来制备非高斯光态。

Method: 提出动态受激发射概念，利用量子发射体（二能级和三能级系统）与时间相关耦合，实现确定性单光子加减。提供了福克态的半解析解，并扩展到光子数叠加态。

Result: 实现了保真度>0.996的确定性无条件单光子加减，能够从压缩真空制备薛定谔猫态，对压缩位移态的光子加法保真度>0.99，成功率高。

Conclusion: 该协议为构建高效的单模非高斯光源提供了新途径，可将量子发射体从单光子源扩展为单光子加高斯态源，无需在线压缩。

Abstract: Photon subtraction and addition are essential non-Gaussian processes in quantum optics, where conventional methods using linear optics and number-resolving detection often suffer from low success probability. Here, we introduce the concept of \textit{dynamic stimulated emission}, whereby a quantum emitter undergoes stimulated emission with a time-dependent coupling. We show that, for both two- and three-level emitters, this process can be used to deterministically add or subtract a photon to a single propagating optical mode. We provide semi-analytic solutions to this problem for Fock states, enabling deterministic and unconditional single-photon subtraction and addition with fidelity ${\cal F}>0.996$. Our semi-analytic solutions are provided for both dynamically coupled two-level systems and for three-level systems whose dynamical coupling is controlled by a coherent laser drive. Moving beyond individual Fock states, we further showcase the ability to subtract and add single photons to photon-number superposition states. We show that Schrödinger cat states can be prepared from squeezed vacuum input via cascaded subtraction or cascaded addition. Finally, we show that our photon-addition process can be used to add a photon to any squeezed and displaced state with high success probability and fidelity ${\cal F}>0.99$, thereby potentially converting quantum emitters from single-photon sources to sources of single-photon-added Gaussian states without the need for inline squeezing. Our protocols provide a path towards integrating quantum emitters to construct efficient sources of single-mode non-Gaussian light beyond single photons.

</details>


### [28] [Quantum random number generation from the continuous variable payload for the SPOQC mission](https://arxiv.org/abs/2512.09716)
*Vinod N. Rao,Killian Murphy,Fadi Ahwal,Emma Tien Hwai Medlock,Timothy P. Spiller,Rupesh Kumar*

Main category: quant-ph

TL;DR: 该论文展示了在SPOQC任务中使用连续变量有效载荷实现CV-QRNG（连续变量量子随机数生成器），通过零态的同调测量生成随机数，原始密钥长度约1Mb，经认证后获得约19.5Kb的随机数。


<details>
  <summary>Details</summary>
Motivation: 随机数在模拟、密码学等众多任务中具有关键且巨大的需求，需要开发可靠且安全的随机数生成方法。量子随机数生成器（QRNG）利用量子力学原理生成真正随机的数字，比传统伪随机数生成器具有更高的安全性。

Method: 使用SPOQC任务的连续变量有效载荷实现CV-QRNG，采用同调测量设置测量真空态。该设置使用有效载荷的激光，在上行链路场景中还可作为探测器使用。通过12位ADC采集数据，对提取的随机性进行NIST测试套件验证，并形式上界定了最小熵。

Result: 在单次卫星过境中，原始密钥长度约为1Mb，从12位ADC中获得了约19.5Kb的认证随机数。提取的随机性通过了NIST测试套件的验证，并正式界定了最小熵的上限。

Conclusion: 成功演示了在SPOQC任务中使用连续变量有效载荷实现CV-QRNG，验证了从真空态同调测量中提取安全随机数的可行性。该方法能够生成经过认证的随机数，为实际应用中的安全随机数需求提供了量子解决方案。

Abstract: The necessity of random numbers for various tasks, from simulation to cryptography, is crucial and immense. Here we demonstrate CV-QRNG using the CV payload of the SPOQC mission. The homodyne setup for QRNG uses the laser from the payload, in addition to potentially being used as detector in the case of an uplink scenario. Here we quantify the extractable secure randomness from the QRNG setup, that involves homodyne measurement of the vacuum states. The extracted randomness is tested against NIST test suite in addition to formally upper bounding the min-entropy. With the raw key length being $\approx1$ Mb in a given satellite pass, we get a total length of $\approx19.5$ Kb of certified random numbers from the 12-bit ADC.

</details>


### [29] [Quantumness certification via non-demolition measurements](https://arxiv.org/abs/2512.09734)
*Paolo Solinas,Stefano Gherardini*

Main category: quant-ph

TL;DR: 该论文综述了量子非破坏测量作为认证系统内在量子性的工具，建立了其与违反宏观实在性的充分必要条件之间的联系，并展示了其在追踪量子-经典转变和噪声环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决如何绝对地判断静态或动态系统是否具有内在量子性的基本问题，超越经典可模拟性或计算复杂性的考量，专注于系统的可测量或可重构特征。

Method: 采用量子非破坏测量作为理论实验工具，将其与违反宏观实在性的充分必要条件直接关联，建立与Leggett-Garg不等式的概念平行，通过具体例子展示如何检测QNDM产生的准概率密度函数中的负项。

Result: QNDM方法能够直接认证量子纠缠和量子叠加等真正量子特征的出现和持续，可用于追踪系统与环境相互作用导致的量子-经典转变，且在噪声源存在时具有鲁棒性，相比Leggett-Garg不等式具有优势。

Conclusion: QNDM方法因其直接实现性，对量子力学基础和量子信息理论都具有直接相关性，在受控生成和认证真正量子资源方面具有重要价值。

Abstract: The fundamental question of when a static or dynamic system should be deemed intrinsically quantum remains a challenge to address in absolute terms. A rigorous criterion, however, can be established by focusing on the measurable or reconstructible features of the system. This determination transcends mere issues of a system's classical simulability or computational complexity. Instead, the critical requirement lies in the certification (ideally, in real-time) of the emergence and persistence of genuine quantum features, principally entanglement and quantum superposition. Quantum Non-Demolition Measurements (QNDM) serve as the appropriate instrument for this certification, both from a theoretical and experimental standpoint. In this review paper, we demonstrate, with accessible clarity, how the implementation of QNDM can be directly linked to a necessary and sufficient condition for the violation of macrorealism in finite-dimensional systems, establishing a conceptual parallel with Leggett-Garg inequalities. Using concrete examples that detail the detection of negative terms in the quasi-probability density function resulting from QNDM, we introduce the core concepts for certifying genuinely quantum features. As specific examples, we discuss an application where the quantum-to-classical transition due to the interaction with an environment can be tracked by QNDM. Moreover, we argue about the robustness of QNDM protocols in the presence of noise sources and their advantages with respect to the Leggett-Garg inequalities. Because of its straightforward implementation, the QNDM approach can be of direct relevance to both the foundations of quantum mechanics and quantum information theory, where a controlled generation and certification of genuinely quantum resources is a central concern.

</details>


### [30] [Rotational excitation of molecules in the regime of strong ro-vibrational coupling: Comparison between an optical centrifuge and a transform-limited pulse](https://arxiv.org/abs/2512.09746)
*J. M. García-Garrido,V. Milner,C. P. Koch,R. González-Férez*

Main category: quant-ph

TL;DR: 光学离心机（旋转偏振激光脉冲）可在刚性转子近似失效时控制分子转动，实现高转动态激发同时保持振动坐标的低展宽，优于传统高斯脉冲。


<details>
  <summary>Details</summary>
Motivation: 研究在振动-转动耦合导致刚性转子近似失效的情况下，光学离心机控制分子转动的能力。传统方法在激发转动时往往伴随显著的振动展宽，需要寻找更精确的控制手段。

Method: 使用光学离心机（线性偏振以加速速率旋转的激光脉冲）作为控制工具，与具有相同光谱宽度和脉冲能量的线性偏振高斯脉冲进行对比分析，研究两者对分子转动和振动状态的不同影响。

Result: 光学离心机能够实现受控的高转动态激发，同时保持振动坐标的相对低展宽。相比之下，传统高斯脉冲虽然也能产生相当的转动激发，但不可避免地伴随显著的振动波包展宽。

Conclusion: 光学离心机在振动-转动耦合显著的情况下，能够更精确地控制分子转动，实现高转动激发的同时最小化振动展宽，为分子动力学控制提供了更优的工具。

Abstract: We investigate theoretically the ability of an optical centrifuge - a laser pulse whose linear polarization is rotating at an accelerated rate, to control molecular rotation in the regime when the rigid-rotor approximation breaks down due to coupling between the vibrational and rotational degrees of freedom. Our analysis demonstrates that the centrifuge field enables controlled excitation of high rotational states while maintaining relatively low spread along the vibrational coordinate. We contrast this to the rotational excitation by a linearly polarized Gaussian pulse of equal spectral width and pulse energy which, although comparable to the centrifuge-induced rotation, is unavoidably accompanied by a substantial broadening of the vibrational wavepacket.

</details>


### [31] [Optimal certification of constant-local Hamiltonians](https://arxiv.org/abs/2512.09778)
*Junseo Lee,Myeongjin Shin*

Main category: quant-ph

TL;DR: 该论文提出了首个对所有常数局域性哈密顿量实现最优性能的不容忍哈密顿量认证协议，仅使用正向实时动力学，无需逆演化或受控操作。


<details>
  <summary>Details</summary>
Motivation: 现有哈密顿量认证方法存在局限性：要么需要实现哈密顿量的逆演化，要么需要受控访问演化算子，要么只能在受限设置（如Ising模型）中达到近最优保证。需要开发一种仅使用正向实时动力学就能对所有常数局域性哈密顿量实现最优认证的通用方法。

Method: 提出了一种不容忍哈密顿量认证协议，通过oracle访问未知k-局域哈密顿量H的演化算子e^{-itH}，与完全指定的目标哈密顿量H_0进行比较。算法仅使用正向实时动力学，无需逆演化或受控操作。对于n-量子比特、k-局域、无迹哈密顿量，总演化时间为O(c^k/ε)，其中c为通用常数。

Result: 对于常数局域性哈密顿量（k=O(1)），总演化时间为Θ(1/ε)，匹配已知的Ω(1/ε)下界，达到海森堡极限标度。这是首个对所有常数局域性哈密顿量实现最优性能的不容忍认证协议。

Conclusion: 该研究首次实现了仅使用正向实时动力学就能对所有常数局域性哈密顿量进行最优不容忍认证的协议，克服了先前方法需要逆演化或受控操作的局限性，为哈密顿量认证提供了更实用和高效的解决方案。

Abstract: We study the problem of certifying local Hamiltonians from real-time access to their dynamics. Given oracle access to $e^{-itH}$ for an unknown $k$-local Hamiltonian $H$ and a fully specified target Hamiltonian $H_0$, the goal is to decide whether $H$ is exactly equal to $H_0$ or differs from $H_0$ by at least $\varepsilon$ in normalized Frobenius norm, while minimizing the total evolution time. We introduce the first intolerant Hamiltonian certification protocol that achieves optimal performance for all constant-locality Hamiltonians. For general $n$-qubit, $k$-local, traceless Hamiltonians, our procedure uses $O(c^k/\varepsilon)$ total evolution time for a universal constant $c$, and succeeds with high probability. In particular, for $O(1)$-local Hamiltonians, the total evolution time becomes $Θ(1/\varepsilon)$, matching the known $Ω(1/\varepsilon)$ lower bounds and achieving the gold-standard Heisenberg-limit scaling. Prior certification methods either relied on implementing inverse evolution of $H$, required controlled access to $e^{-itH}$, or achieved near-optimal guarantees only in restricted settings such as the Ising case ($k=2$). In contrast, our algorithm requires neither inverse evolution nor controlled operations: it uses only forward real-time dynamics and achieves optimal intolerant certification for all constant-locality Hamiltonians.

</details>


### [32] [Pinball: A Cryogenic Predecoder for Quantum Error Correction Decoding Under Circuit-Level Noise](https://arxiv.org/abs/2512.09807)
*Alexander Knapen,Guanchen Tao,Jacob Mack,Tomas Bruno,Mehdi Saligane,Dennis Sylvester,Qirui Zhang,Gokul Subramanian Ravi*

Main category: quant-ph

TL;DR: Pinball是一种基于低温CMOS的量子纠错预解码器设计，针对实际电路级噪声，相比现有技术显著提升了预解码精度和能效，支持大规模量子计算扩展。


<details>
  <summary>Details</summary>
Motivation: 扩展容错量子计算机面临数据处理和功耗方面的挑战，特别是在低温量子比特和室温解码器系统中。现有低温预解码方法仅考虑部分误差源且精度有限，无法满足实际需求，同时依赖SFQ逻辑限制了架构技术协同优化。

Method: 提出Pinball设计，采用低温CMOS技术实现量子纠错预解码器，充分考虑QEC电路中误差的产生和传播。与22nm FDSOI技术协同设计，利用电压/频率缩放和体偏置技术优化功耗。

Result: 相比现有最佳低温预解码器，逻辑错误率提升近六个数量级；相比室温预解码器和集成配置，逻辑错误率分别降低32.58倍和5倍。功耗峰值低于0.56mW，典型功耗降低22.2倍，总能耗节省达67.4倍。在4K功率预算1.5W下，支持最多2,668个逻辑量子比特(d=21)。

Conclusion: Pinball通过低温CMOS预解码器设计，实现了对实际电路级噪声的高精度处理，显著提升了量子纠错性能，同时大幅降低功耗和带宽需求，为大规模容错量子计算机的扩展提供了可行方案。

Abstract: Scaling fault tolerant quantum computers, especially cryogenic systems, to millions of qubits is challenging due to poorly-scaling data processing and power consumption overheads. One key challenge is the design of decoders for real-time quantum error correction (QEC), which demands high data rates for error processing; this is particularly apparent in systems with cryogenic qubits and room temperature (RT) decoders. In response, cryogenic predecoding using lightweight logic has been proposed to handle common, sparse errors in the cryogenic domain. However, prior work only accounts for a subset of error sources present in real-world quantum systems with limited accuracy, often degrading performance below a useful level in practical scenarios. Furthermore, prior reliance on SFQ logic precludes detailed architecture-technology co-optimization.
  To address these shortcomings, this paper introduces Pinball, a comprehensive design in cryogenic CMOS of a QEC predecoder tailored to realistic, circuit-level noise. By accounting for error generation and propagation through QEC circuits, our design achieves higher predecoding accuracy, outperforming logical error rates (LER) of the current state-of-the-art cryogenic predecoder by nearly six orders of magnitude. Remarkably, despite operating under much stricter power and area constraints, Pinball also reduces LER by 32.58x and 5x, respectively, compared to the state-of-the-art RT predecoder and RT ensemble configurations. By increasing cryogenic coverage, we also reduce syndrome bandwidth up to 3780.72x. Through co-design with 4 K-characterized 22 nm FDSOI technology, we achieve a peak power consumption under 0.56 mW. Voltage/frequency scaling and body biasing enable 22.2x lower typical power consumption, yielding up to 67.4x total energy savings. Assuming a 4 K power budget of 1.5 W, our predecoder supports up to 2,668 logical qubits at d=21.

</details>


### [33] [Transpiling quantum circuits by a transformers-based algorithm](https://arxiv.org/abs/2512.09834)
*Michele Banfi,Paolo Zentilini,Sebastiano Corli,Enrico Prati*

Main category: quant-ph

TL;DR: 该研究开发了一个Transformer模型，用于将量子电路从qasm标准转换为适合特定量子硬件（IonQ的囚禁离子量子计算机）的本地门集，实现了高达99.98%的正确转换率。


<details>
  <summary>Details</summary>
Motivation: 量子计算需要将量子电路转换为特定硬件支持的本地门集，传统方法复杂且效率有限。Transformer在自然语言处理中表现出色，而量子门操作类似于低级文本编程语言，因此探索使用Transformer进行量子电路转译。

Method: 开发基于Transformer的模型，将量子电路从qasm标准格式转换为IonQ囚禁离子量子计算机的本地门集。模型处理量子电路作为文本序列，利用Transformer的序列处理能力捕获电路结构中的长程依赖关系。

Result: 在最多5个量子比特的电路中，实现了99.98%或更高的正确转译率。证明无论寄存器深度和门数量如何，Transformer模型的复杂度在最坏情况下随寄存器深度和电路长度呈多项式增长趋势。

Conclusion: Transformer模型能够高效地将量子电路转换为特定硬件的本地门集，为量子电路转译提供了一种可扩展的解决方案，支持在HPC基础设施上训练更多参数的模型。

Abstract: Transformers have gained popularity in machine learning due to their application in the field of natural language processing. They manipulate and process text efficiently, capturing long-range dependencies among data and performing the next word prediction. On the other hand, gate-based quantum computing is based on controlling the register of qubits in the quantum hardware by applying a sequence of gates, a process which can be interpreted as a low level text programming language. We develop a transformer model capable of transpiling quantum circuits from the qasm standard to other sets of gates native suited for a specific target quantum hardware, in our case the set for the trapped-ion quantum computers of IonQ. The feasibility of a translation up to five qubits is demonstrated with a percentage of correctly transpiled target circuits equal or superior to 99.98%. Regardless the depth of the register and the number of gates applied, we prove that the complexity of the transformer model scales, in the worst case scenario, with a polynomial trend by increasing the depth of the register and the length of the circuit, allowing models with a higher number of parameters to be efficiently trained on HPC infrastructures.

</details>


### [34] [Practical and Efficient Verification of Entanglement with Incomplete Measurement Settings](https://arxiv.org/abs/2512.09856)
*Jiheon Seong,Jin-Woo Kim,Seungchan Seo,Seung-Hyun Nam,Anindita Bera,Dariusz Chruściński,June-Koo Kevin Rhee,Heonoh Kim,Joonwoo Bae*

Main category: quant-ph

TL;DR: 提出一种在测量设置不完备情况下验证纠缠态的实用框架，仅需少量可观测量即可构建纠缠见证并高效识别纠缠态


<details>
  <summary>Details</summary>
Motivation: 在实际实验中，通常只能获得不完备的测量设置，观测量的访问受到严重限制，这给纠缠态的验证带来了挑战。需要开发在有限测量条件下仍能有效验证纠缠的方法。

Method: 1. 利用少量实验观测的可观测量直接构建大量纠缠见证；2. 引入半正定规划优化方法，系统搜索在给定测量约束下最适合揭示纠缠的见证；3. 在光子偏振量子比特的原理验证实验中展示方法的实用性。

Result: 1. 成功开发了在测量设置不完备情况下验证纠缠态的框架；2. 在光子偏振量子比特实验中，仅使用部分完整测量数据就成功验证了纠缠；3. 证明了不完备测量设置在现实场景中验证纠缠的最大效用。

Conclusion: 该工作提供了一种实用高效的框架，能够在测量设置不完备的情况下验证纠缠态，仅需少量可观测量即可构建纠缠见证并高效识别纠缠。该方法在实际实验中得到了验证，展示了在现实场景中利用不完备测量设置验证纠缠的最大潜力。

Abstract: In this work, we present a practical and efficient framework for verifying entangled states when only a tomographically incomplete measurement setting is available-specifically, when access to observables is severely limited. We show how the experimental estimation of a small number of observables can be directly exploited to construct a large family of entanglement witnesses, enabling the efficient identification of entangled states. Moreover, we introduce an optimization approach, formulated as a semidefinite program, that systematically searches for those witnesses best suited to reveal entanglement under the given measurement constraints. We demonstrate the practicality of the approach in a proof-of-principle experiment with photon-polarization qubits, where entanglement is certified using only a fraction of the full measurement data. These results reveal the maximal usefulness of incomplete measurement settings for entanglement verification in realistic scenarios.

</details>


### [35] [True Random Number Generators on IQM Spark](https://arxiv.org/abs/2512.09862)
*Andrzej Gnatowski,Jarosław Rudy,Teodor Niżyński,Krzysztof Święcicki*

Main category: quant-ph

TL;DR: 本文在Odra 5量子计算机上对5种TRNG电路及其105个子变体进行了实验研究，生成了1百万比特序列，并使用NIST测试套件评估随机性质量，填补了现有研究主要依赖IBM量子计算机和模拟的空白。


<details>
  <summary>Details</summary>
Motivation: 现有量子计算机真随机数生成研究主要局限于IBM量子计算机，多使用模拟而非真实硬件，且测试的TRNG量子电路种类有限。本研究旨在解决这些问题，在Odra 5量子计算机上进行更全面的TRNG电路研究。

Method: 在Wrocław University of Science and Technology的Odra 5量子计算机（采用IQM超导架构）上，测试了5种TRNG电路类型共105个电路子变体，每个电路生成1百万比特随机序列，使用NIST SP 800-22和NIST SP 800-90B测试套件评估随机性质量。

Result: 在真实量子硬件上进行了大规模TRNG电路测试，提供了详细的随机性质量分析结果，这是首次利用IQM超导架构的研究，也是首次在本地部署的量子计算机上进行如此全面的TRNG研究。

Conclusion: 本研究填补了量子计算机TRNG研究的空白，提供了在真实量子硬件上的全面实验结果，为量子随机数生成的实用化提供了重要参考，并提供了现有文献的全面综述。

Abstract: Random number generation is fundamental for many modern applications including cryptography, simulations and machine learning. Traditional pseudo-random numbers may offer statistical unpredictability, but are ultimately deterministic. On the other hand, True Random Number Generation (TRNG) offers true randomness. One way of obtaining such randomness are quantum systems, including quantum computers. As such the use of quantum computers for TRNG has received considerable attention in recent years. However, existing studies almost exclusively consider IBM quantum computers, often stop at using simulations and usually test only a handful of different TRNG quantum circuits. In this paper, we address those issues by presenting a study of TRNG circuits on Odra 5 a real-life quantum computer installed at Wrocław University of Science and Technology. It is also the first study to utilize the IQM superconducting architecture. Since Odra 5 is available on-premises it allows for much more comprehensive study of various TRNG circuits. In particular, we consider 5 types of TRNG circuits with 105 circuit subvariants in total. Each circuit is used to generate 1 million bits. We then perform an analysis of the quality of the obtained random sequences using the NIST SP 800-22 and NIST SP 800-90B test suites. We also provide a comprehensive review of existing literature on quantum computer-based TRNGs.

</details>


### [36] [Tomographic characterization of non-Hermitian Hamiltonians in reciprocal space](https://arxiv.org/abs/2512.09870)
*Francesco Di Colandrea,Fabrizio Pavan,Sarvesh Bansal,Paola Savarese,Grazia Di Bello,Giulio De Filippis,Carmine Antonio Perroni,Donato Farina,Filippo Cardano*

Main category: quant-ph

TL;DR: 实验展示了一种光子平台，能够模拟非厄米哈密顿量生成的量子行走，通过直接访问倒空间实现精确的哈密顿量断层重建，从而获得复能带结构并解析动量空间中的异常点。


<details>
  <summary>Details</summary>
Motivation: 非厄米哈密顿量能够扩展传统相图，实现新的拓扑现象和异常点，在量子传感等领域有潜在应用。然而，文献中对特定类型的非厄米哈密顿量研究较少，需要新的实验平台来探索这些现象。

Method: 开发了一种实验光子平台，能够模拟由非厄米哈密顿量生成的量子行走。该平台的创新之处在于能够直接访问倒空间，通过扫描整个布里渊区的准动量，实现对底层非厄米哈密顿量的精确断层重建。

Result: 通过理论预测与实验测量的比较，成功重建了非厄米哈密顿量。从推断的哈密顿量中获得了复数值能带结构，解析了动量空间中的异常点，并通过特征向量合并检测了相关的宇称-时间对称性破缺。

Conclusion: 该研究在准动量空间中呈现的结果代表了研究非厄米现象视角的重大转变，为探索非厄米量子系统提供了新的实验工具和方法。

Abstract: Non-Hermitian Hamiltonians enrich quantum physics by extending conventional phase diagrams, enabling novel topological phenomena, and realizing exceptional points with potential applications in quantum sensing. Here, we present an experimental photonic platform capable of simulating a non-unitary quantum walk generated by a peculiar type of non-Hermitian Hamiltonian, largely unexplored in the literature. The novelty of this platform lies in its direct access to the reciprocal space, which enables us to scan the quasi-momentum across the entire Brillouin zone and thus achieve a precise tomographic reconstruction of the underlying non-Hermitian Hamiltonian, indicated by the comparison between theoretical predictions and experimental measurements. From the inferred Hamiltonian, it is possible to retrieve complex-valued band structures, resolve exceptional points in momentum space, and detect the associated parity-time symmetry breaking through eigenvector coalescence. Our results, presented entirely in quasi-momentum space, represent a substantial shift in perspective in the study of non-Hermitian phenomena.

</details>


### [37] [A 0.8395-approximation algorithm for the EPR problem](https://arxiv.org/abs/2512.09896)
*Anuj Apte,Eunou Lee,Kunal Marwaha,Ojas Parekh,Lennart Sinjorgo,James Sud*

Main category: quant-ph

TL;DR: 提出了一种高效的0.8395近似算法用于EPR哈密顿量问题，通过新的星图纠缠单配性非线性界限和改进的浅层量子电路参数化实现改进，同时证明了当前方法的局限性


<details>
  <summary>Details</summary>
Motivation: EPR哈密顿量问题在量子计算和量子信息理论中具有重要意义，需要开发更高效的近似算法来提升性能

Method: 采用新的星图纠缠单配性非线性界限，并结合改进的浅层量子电路参数化技术

Result: 实现了0.8395的近似比，这是目前最先进的性能，同时证明了当前方法无法获得显著更好的近似比

Conclusion: 该算法在EPR哈密顿量问题上取得了显著改进，但进一步突破需要全新的技术方法

Abstract: We give an efficient 0.8395-approximation algorithm for the EPR Hamiltonian. Our improvement comes from a new nonlinear monogamy-of-entanglement bound on star graphs and a refined parameterization of a shallow quantum circuit from previous works. We also prove limitations showing that current methods cannot achieve substantially better approximation ratios, indicating that further progress will require fundamentally new techniques.

</details>


### [38] [Two simple models derived from a quantum-mechanical particle on an elliptical path](https://arxiv.org/abs/2512.09905)
*Francisco M. Fernández*

Main category: quant-ph

TL;DR: 本文分析了源自椭圆路径上量子力学粒子的两个简单模型。第一个哈密顿算符是非厄米的但与厄米算符同构，表现出与圆路径粒子相同的二重简并性。第二个哈密顿算符是厄米的，不显示这种简并性，其第n激发能级在第n阶微扰理论中分裂。


<details>
  <summary>Details</summary>
Motivation: 研究椭圆路径上量子力学粒子的两种不同哈密顿算符模型，探索非厄米与厄米算符在能级简并性方面的差异，以及它们与点群对称性的关系。

Method: 从椭圆路径上的量子力学粒子出发，构建两个简单模型：第一个是非厄米但同构于厄米算符的哈密顿算符；第二个是厄米哈密顿算符。通过理论分析和微扰理论方法研究它们的能级特性。

Result: 第一个非厄米哈密顿算符表现出与圆路径粒子相同的二重简并性，能级满足E_n=n²E₁（n=1,2,...），外加精确本征值E₀=0。第二个厄米哈密顿算符不显示这种简并性，其第n激发能级在第n阶微扰理论中分裂。两种模型都可以用相同的点群对称性描述。

Conclusion: 椭圆路径上量子力学粒子的两种哈密顿算符模型展示了不同的能级简并特性：非厄米但同构于厄米算符的模型保持了圆路径的简并性，而纯厄米模型则失去了这种简并性。两种模型共享相同的点群对称性，但对称性在能级分裂中的表现不同。

Abstract: We analyze two simple models derived from a quantum-mechanical particle on an elliptical path. The first Hamiltonian operator is non-Hermitian but isomorphic to an Hermitian operator. It appears to exhibit the same two-fold degeneracy as the particle on a circular path. More precisely, $E_n=n^2E_1,\ n=1,2,\ldots$ (in addition to an exact eigenvalue $E_0=0$). The second Hamiltonian operator is Hermitian and does not exhibit such degeneracy. In this case the nth excited energy level splits at the nth order of perturbation theory. Both models can be described in terms of the same point-group symmetry.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [39] [Anisotropic scattering rates in strain-tuned Sr$_2$RuO$_4$](https://arxiv.org/abs/2512.09024)
*Ben Currie,David T. S. Perkins,Evgeny Kozik,Joseph J. Betouras,Jörg Schmalian*

Main category: cond-mat.str-el

TL;DR: 该研究分析了Sr₂RuO₄在应变条件下γ能带的单粒子散射率，特别关注Lifshitz转变点附近的行为，发现实验观测到的散射率指数α≈1.4可由线性和二次项的叠加解释，而非新的普适幂律。


<details>
  <summary>Details</summary>
Motivation: 受近期角分辨光电子能谱实验启发，研究Sr₂RuO₄在应变条件下γ能带的单粒子散射率，特别关注Lifshitz转变点（费米能级穿过单个范霍夫奇点）附近的行为。

Method: 分析应变下Sr₂RuO₄ γ能带模型的单粒子散射率，研究其温度、频率和动量依赖性，特别关注Lifshitz转变点附近的行为，通过理论模型计算不同能量尺度下的散射率贡献。

Result: 散射率在零应变时各向异性较弱，但在Lifshitz点变得强烈各向异性。低能下恢复预期普适行为：范霍夫点τ⁻¹∼ω，远离点τ⁻¹∼ω³/²。高能下ω²阶修正变得重要。实验观测的α≈1.4可由线性和二次贡献的叠加定量解释。

Conclusion: 实验观测的散射率指数α≈1.4可由线性和二次项的叠加解释，而非新的普适幂律。预测了Lifshitz转变点散射率的独特各向异性、应变依赖性和非单调频率依赖性，这些都可直接通过实验验证。

Abstract: Motivated by recent angle-resolved photoemission spectroscopy (ARPES) experiments, we analyze the temperature, frequency, and momentum dependence of the single-particle scattering rate in a model of the $γ$-band of Sr$_2$RuO$_4$ under strain, with particular emphasis on the behavior near the Lifshitz transition where the Fermi energy crosses a single Van Hove point. While the scattering rate is only moderately anisotropic at zero strain, we find that it becomes strongly anisotropic at the Lifshitz point. At the lowest energies, we recover the expected universal behavior: the scattering rate varies (ignoring logarithmic corrections) as $τ^{-1}\sim ω$ at the Van Hove point and as $τ^{-1}\sim ω^{3/2}$ away from it. At higher energies, however, corrections of order $ω^2$ become important in both regimes. We show that the experimentally observed behavior $τ^{-1} \sim ω^α$ with $α\approx 1.4(2)$ at the Van Hove point can be quantitatively explained by a superposition of linear and quadratic contributions to the scattering rate, which are comparable in magnitude at the intermediate energies probed by experiment, rather than in terms of a new universal power law. We further predict a distinctive anisotropy, strain dependence, and a non-monotonic frequency dependence of the scattering rate at a Lifshitz transition, all of which may be directly tested in experiments.

</details>


### [40] [How a bilayer Nickelate superconducts: a Quantum Monte Carlo study](https://arxiv.org/abs/2512.09025)
*Xu Zhang*

Main category: cond-mat.str-el

TL;DR: 使用行列式量子蒙特卡洛方法研究双层镍酸盐La₃Ni₂O₇中掺杂、层间隧穿和现场Hund耦合对超导稳定性的影响，发现特定参数下无符号问题，并揭示了强相互作用极限下的(π,π)激子凝聚与实验中密度波态的关联。


<details>
  <summary>Details</summary>
Motivation: 研究双层镍酸盐La₃Ni₂O₇中超导性的稳定机制，特别是掺杂、层间隧穿和现场Hund耦合这三个关键因素的相互作用，以理解该材料中超导相的形成和竞争关系。

Method: 采用行列式量子蒙特卡洛方法，研究双层镍酸盐La₃Ni₂O₇的双轨道模型。在特定相互作用参数下，辅助场解耦的费米子哈密顿量具有Kramers反幺正对称性，保证了无符号问题。利用这些对称性分析系统的稳定性。

Result: 发现特定参数下系统无符号问题，揭示了强相互作用极限下存在(π,π)激子凝聚的第二不稳定性。该激子有序可能与实验中观察到的密度波态相关，层间隧穿在超导与激子凝聚的竞争中起决定性作用。

Conclusion: 层间隧穿是调控双层镍酸盐La₃Ni₂O₇中超导与激子凝聚竞争的关键因素，为增强超导转变温度和稳定超导相提供了可能的理论方向。

Abstract: Using determinant Quantum Monte Carlo, we investigate the interplay between doping, inter-layer tunneling and onsite Hund's coupling in stabilizing superconductivity (SC) in a two-orbital model for the bilayer Nickelate $\text{La}_3\text{Ni}_2\text{O}_7$. With realistic dispersion and for certain values of the interaction parameters, the auxiliary-field-decoupled fermion Hamiltonian has Kramers anti-unitary symmetries which guarantee the absence of a sign problem. The same anti-unitary symmetries can also be used to show there is a second instability towards $(π,π)$ exciton condensation in the strong interaction limit. We indicate the possible connection between this exciton order and the enigmatic density wave state observed in experiment, and clarify the decisive role played by the inter-layer tunneling in the competition between SC and exciton condensation. Finally, possible directions on how to enhance the SC transition temperature and stabilize the SC phase are also discussed.

</details>


### [41] [Microscopic Theory Revealing Dual Field-Induced Transitions in Spin-1/2 Screw-Chain Magnets](https://arxiv.org/abs/2512.09039)
*Mandev Bhullar,Philip Richard,Hae-Young Kee*

Main category: cond-mat.str-el

TL;DR: 该研究为具有自旋轨道耦合的赝自旋-1/2螺旋链化合物建立了微观理论，超越了传统的唯象g-张量描述。基于对称性允许的JKΓ哈密顿量，揭示了Γ相互作用自然产生与晶体螺旋对称性相关的四子晶格模式，并发现了两个不同的场诱导相变。


<details>
  <summary>Details</summary>
Motivation: 传统上对BaCo₂V₂O₈等XXZ类材料使用唯象的位点依赖g-张量描述存在局限性。需要建立更基础的微观理论来理解赝自旋-1/2螺旋链化合物的物理性质，特别是自旋轨道耦合效应。

Method: 从对称性允许的JKΓ哈密顿量出发，包含海森堡J、基塔耶夫K和非对角Γ相互作用。使用密度矩阵重整化群方法研究系统性质，通过纠缠熵标度分析相变临界行为。

Result: 发现Γ相互作用自然产生与晶体螺旋对称性相关的四子晶格模式。识别出两个场诱导相变：第一个是进入中间相的连续相变，破坏了二重基态简并的对称性；第二个是进入高场相的一级相变，自旋-自旋关联函数出现不连续跳跃。纠缠熵标度确认第一个相变属于中心荷为1/2的伊辛临界点。

Conclusion: 为Co²⁺材料等赝自旋-1/2螺旋链系统建立了微观理论框架，揭示了中间相的存在及其宽度随Γ增加而增大的规律，为系统探索其他场取向和结构畸变提供了指导。

Abstract: We develop a microscopic theory for pseudospin-$\frac{1}{2}$ screw-chain compounds with spin-orbit coupling that goes beyond the phenomenological site-dependent $g$-tensor description traditionally used for XXZ-like BaCo$_2$V$_2$O$_8$ and related materials. Starting from the symmetry-allowed $JKΓ$ Hamiltonian with Heisenberg $J$, Kitaev $K$, and off-diagonal $Γ$ interactions, we show that the $Γ$ interaction naturally generates the four-sublattice pattern associated with the crystal's screw symmetry. Using the density matrix renormalization group, we identify two distinct field-induced transitions. The first is a continuous transition into an intermediate phase, where the symmetry responsible for the two-fold ground-state degeneracy is broken. The second is a first-order transition into the high-field phase, characterized by a discontinuous jump in the spin-spin correlator. Entanglement-entropy scaling confirms that the first transition belongs to the Ising critical point with the central charge $1/2$. These results establish a microscopic framework for pseudospin-$\frac{1}{2}$ screw-chain systems such as Co$^{2+}$ materials, uncover an intermediate phase whose width increases with $Γ$, and provide guidance for systematic exploration of additional field orientations and structural distortions.

</details>


### [42] [Magnetochiral eigenstate of the Heisenberg chain with spontaneous symmetry breaking](https://arxiv.org/abs/2512.09107)
*Tigran A. Sedrakyan,Junjun Pang,Chenan Wei,Baigeng Wang*

Main category: cond-mat.str-el

TL;DR: 提出一种利用守恒荷变形的哈密顿量基态构造量子系统中非典型高能本征态的协议，并在自旋-1/2海森堡XXX链中通过标量手性荷和总磁化强度构建手性哈密顿量，用Bethe ansatz精确求解。


<details>
  <summary>Details</summary>
Motivation: 探索量子系统中非典型高能本征态的构造方法，这些态具有特殊的对称性破缺和输运性质，为冷原子和里德堡平台提供新的物理实现可能性。

Method: 提出通用协议：利用守恒荷变形的哈密顿量基态来构造非典型高能本征态。具体在自旋-1/2海森堡XXX链中，通过标量手性荷和总磁化强度构建手性哈密顿量，采用Bethe ansatz方法进行精确求解。

Result: 手性哈密顿量的基态是一个磁化、携带电流的XXX本征态，它打破了SU(2)、时间反演和宇称对称性，但仍保持临界性。这种零熵宏观态展现出弹道自旋和手性输运特性。

Conclusion: 该协议成功构造了具有特殊对称性破缺和输运性质的非典型高能本征态，为冷原子和里德堡平台提供了实验实现的可能性，展示了量子系统中新型宏观态的物理特性。

Abstract: We propose a protocol to construct atypical high-energy eigenstates in quantum systems by using ground states of Hamiltonians deformed by conserved charges. For the spin-1/2 Heisenberg XXX chain we study a chiral Hamiltonian built from the scalar-chirality charge and total magnetization and solve it exactly by Bethe ansatz. Its ground state is a magnetized, current-carrying XXX eigenstate that breaks SU(2), time-reversal, and parity yet stays critical. This zero-entropy macrostate shows ballistic spin and chirality transport and admits realistic cold-atom and Rydberg platforms.

</details>


### [43] [Observation of ubiquitous charge correlations and hidden quantum critical point in hole-doped kagome superconductors](https://arxiv.org/abs/2512.09256)
*Ilija K. Nikolov,Giuseppe Allodi,Adrien Rosuel,Ginevra Corsale,Anshu Kataria,Pietro Bonfà,Roberto De Renzi,Andrea Capa Salinas,Stephen D. Wilson,Marc-Henri Julien,Samuele Sanna,Vesna F. Mitrović*

Main category: cond-mat.str-el

TL;DR: 通过核四极共振技术研究CsV₃Sb₅₋ₓSnₓ中电荷密度波与超导的相互作用，发现无序缺陷导致CDW碎片化，揭示了隐藏的量子临界点位于两个超导穹顶之间。


<details>
  <summary>Details</summary>
Motivation: 研究超导与电荷密度波（CDW）序之间的相互作用及其随载流子密度的演化，特别是在空穴掺杂的kagome化合物中观察到的令人困惑的双穹顶超导现象。由于化学取代不可避免地引入淬灭无序，这些材料的性质仍然知之甚少。

Method: 利用核四极共振（NQR）技术对局部和静态有序的敏感性，研究CsV₃Sb₅₋ₓSnₓ中的电荷景观。通过分析静态CDW斑块的掺杂和温度演化，揭示无序缺陷对CDW序的影响。

Result: 1. 在转变温度以上观察到静态CDW斑块，这是缺陷钉扎的标志；2. 在无无序情况下，逆大卫之星π位移（ISD-π）CDW序在x=0.12附近消失，位于两个超导穹顶之间，代表一个隐藏的量子临界点；3. ISD-π模式持续存在超出先前报道的范围，但其体积分数逐渐减小直至临界掺杂后饱和；4. 载流子掺杂促进ISD-π序的碎片化，而无序性则保留ISD-π斑块。

Conclusion: 该研究揭示了无序在kagome金属CsV₃Sb₅₋ₓSnₓ中电荷密度波序演化中的关键作用，发现了位于双超导穹顶之间的隐藏量子临界点，并阐明了载流子掺杂与无序性对CDW碎片化的不同影响机制。

Abstract: The interplay between superconductivity and charge-density wave (CDW) order, and its evolution with carrier density, is central to the physics of many quantum materials, notably high-$T_c$ cuprates and kagome metals. Hole-doped kagome compounds exhibit puzzling double-dome superconductivity and, as chemical substitution inevitably introduces quenched disorder, their properties remain poorly understood. Here, by leveraging the sensitivity of nuclear quadrupole resonance to local and static orderings, we uncover new features, primarily the incipient and fragmented CDW phases, in the charge landscape of CsV$_3$Sb$_{5-x}$Sn$_x$. Static CDW puddles are observed well above the transition temperature, a hallmark of pinning by defects. Their doping and temperature evolution indicate that, in the absence of disorder, the inverse Star-of-David $π$-shifted (ISD-$π$) CDW order would vanish near $x=0.12$, between the two superconducting domes. This critical doping represents a hidden quantum critical point. Nevertheless, the ISD-$π$ pattern persists well beyond previous reports, although its volume fraction is progressively reduced up to the critical doping at which it saturates. We establish that carrier doping promotes fragmentation of the ISD-$π$ order, whereas randomness preserves the ISD-$π$ patches.

</details>


### [44] [Modified Kondorsky Domain Reversal in Microstructured Phase-Separated Manganites](https://arxiv.org/abs/2512.09306)
*Monique Kubovsky,Dylan Tagrin,Amlan Biswas*

Main category: cond-mat.str-el

TL;DR: LPCMO锰氧化物微结构中的磁畴翻转机制研究：微结构遵循修正的Kondorsky模型，表明受限几何中局部磁场对矫顽场有显著影响


<details>
  <summary>Details</summary>
Motivation: 研究空穴掺杂锰氧化物(LPCMO)中电子相分离现象，特别是在微结构中的磁畴翻转机制，探索受限几何对磁性能的影响

Method: 在(110)NGO衬底上生长LP5CMO薄膜，通过光刻技术制备微结构，通过磁输运测量研究磁畴翻转机制

Result: 体膜遵循标准Kondorsky模型，而微结构遵循修正的Kondorsky模型，表明局部磁场在受限几何中对矫顽场有显著影响

Conclusion: 磁输运测量是探测锰氧化物微结构中形状各向异性和磁晶各向异性竞争的有效方法，为低电流密度下控制磁畴提供了替代途径

Abstract: The hole-doped manganite (La$_{1-y}$Pr$_{y}$)$_{0.67}$Ca$_{0.33}$MnO$_3$ (LPCMO) shows electronic phase separation between ferromagnetic metallic (FMM) and anti-ferromagnetic charge-ordered insulating (AFM-COI) regions. In this study, (La$_{0.5}$Pr$_{0.5}$)$_{0.67}$Ca$_{0.33}$MnO$_{3}$ (LP5CMO) microstructures were fabricated using photolithography on thin films grown on (110) NdGaO$_3$ (NGO) substrates. We investigated the domain reversal mechanism of these microstructures through magnetotransport measurements. Our results demonstrate that, while bulk (unpatterned) films follow the standard Kondorsky model for domain reversal, the microstructures obey a modified Kondorsky model. This difference indicates that local magnetic fields from reversed domains significantly influence the coercive field in confined geometries. Although we did not observe a strong electric field effect, this study establishes that magnetotransport measurements are a feasible method for probing the competition between shape and magnetocrystalline anisotropy in manganite microstructures, which could provide an alternative path for controlling magnetic domains at low current densities.

</details>


### [45] [Low-dimensionality-induced tunable ferromagnetism in SrRuO$_3$ ultrathin films](https://arxiv.org/abs/2512.09320)
*Jinyoung Kim,Minjae Kim,Donghan Kim,Sungsoo Hahn,Younsik Kim,Minsoo Kim,Byungmin Sohn,Changyoung Kim*

Main category: cond-mat.str-el

TL;DR: 通过电子掺杂调控SrRuO₃超薄膜的费米能级，在相变交叉点处通过态密度控制实现了铁磁性的精确调控。


<details>
  <summary>Details</summary>
Motivation: 量子材料在电子或磁相边界附近具有增强的可调性，其涌现性质对外部扰动高度敏感。研究旨在探索通过态密度控制来工程化调控铁磁性的可能性。

Method: 使用自旋和角分辨光电子能谱(SRPES/ARPES)、输运测量和理论计算，通过电子掺杂系统性地调控SrRuO₃超薄膜的费米能级，使其跨越高态密度点。

Result: 直接可视化了自旋分裂的能带结构，揭示了其对磁性和输运性质的影响，证明了在相变交叉点处通过态密度控制可以工程化调控铁磁性。

Conclusion: 在相变交叉点处通过态密度控制可以工程化调控磁性，为可调谐量子材料的理性设计建立了途径。

Abstract: Quantum materials near electronic or magnetic phase boundaries exhibit enhanced tunability, as their emergent properties become highly sensitive to external perturbations. Here, we demonstrate precise control of ferromagnetism in a SrRuO$_3$ ultrathin film, where a high density of states (DOS), arising from low-dimensional quantum states, places the system at the crossover between a non-magnetic and bulk ferromagnetic state. Using spin- and angle-resolved photoemission spectroscopy (SRPES/ARPES), transport measurements, and theoretical calculations, we systematically tune the Fermi level via electron doping across the high-DOS point. We directly visualize the spin-split band structure and reveal its influence on both magnetic and transport properties. Our findings provide compelling evidence that magnetism can be engineered through DOS control at a phase crossover, establishing a pathway for the rational design of tunable quantum materials.

</details>


### [46] [Transport properties and thermopower of the spinful Sachdev-Ye-Kitaev dot](https://arxiv.org/abs/2512.09494)
*Marco Uguccioni,Daniele Morotti,Luca Dell'Anna*

Main category: cond-mat.str-el

TL;DR: 研究自旋SYK量子点与金属引线组成的N-SYK-N结中的电和热电输运，使用非平衡Keldysh场论方法，揭示了SYK模型的非费米液体特征在输运性质中的独特表现。


<details>
  <summary>Details</summary>
Motivation: 传统平衡方法无法处理开放、相互作用的量子导体在非平衡条件下的输运问题。本研究旨在开发一种无需复制技巧的非平衡场论方法，研究SYK量子点系统的输运特性，寻找SYK物理在介观系统中的实验可观测特征。

Method: 采用Keldysh场论方法处理开放量子系统，从精确的Keldysh-Dyson方程出发，推导了隧穿极限和零温极限的解析结果，并在线性响应区域进行了数值分析。

Result: 表征了电导、热电系数和塞贝克效应对粒子-空穴不对称参数和引线耦合强度的依赖关系。结果揭示了SYK模型非费米液体特征在输运性质中的独特表现，并识别出热电效应增强的耦合区域。

Conclusion: SYK模型的非费米液体特征在输运性质中表现出独特的指纹，热电效应在特定耦合区域增强，这为在介观系统中实验观测SYK物理提供了可访问的途径。

Abstract: We study the electric and thermoelectric transport through a spinful complex Sachdev-Ye-Kitaev (SYK) quantum dot coupled to metallic leads, forming a N-SYK-N junction, by the Keldysh field theory approach. Unlike traditional equilibrium approaches, our formulation treats the system as an open, interacting quantum conductor under non-equilibrium conditions, without resorting to the replica trick. Starting from the exact Keldysh-Dyson equations, we derive analytical results for the tunneling and zero-temperature limits and perform a numerical analysis in the linear-response regime. We characterize the dependence of conductance, thermoelectric coefficient, and Seebeck effect on the particle-hole asymmetry parameter and coupling strength to the leads. Our results reveal distinctive non-Fermi liquid signatures of the SYK model in transport properties and identify coupling regimes where thermoelectric effects are enhanced, suggesting experimentally accessible fingerprints of SYK physics in mesoscopic systems.

</details>


### [47] [Single-crystal growth, structural characterization, and physical properties of a decorated square-kagome antiferromagnet KCu$_7$TeO$_4$(SO$_4$)$_5$Cl](https://arxiv.org/abs/2512.09584)
*Jingjing Jing,Andreas Eich,Yiqiu Liu,Lunhua He,Aifeng Wang,Yisheng Chai,Young Sun,Yi Cui,Weiqiang Yu,Xinrun Mi,Michael Merz,Mingquan He*

Main category: cond-mat.str-el

TL;DR: KCu7TeO4(SO4)5Cl是一种具有扭曲装饰方形kagome晶格的新型材料，在4K附近出现磁相变，在30K和27K附近发生两次铁电相变，表明其磁电行为需要三维模型解释。


<details>
  <summary>Details</summary>
Motivation: 方形kagome晶格为研究受挫磁性提供了新平台，但实际材料实现仍然稀缺。本研究旨在探索KCu7TeO4(SO4)5Cl这种具有扭曲装饰方形kagome晶格的新型材料的磁性和电学性质。

Method: 通过单晶生长、结构表征、磁化率测量、比热测量以及35Cl核磁共振(NMR)技术，系统研究了KCu7TeO4(SO4)5Cl的磁性和电学性质。

Result: 在4K附近观察到磁化率和比热的微弱异常，表明磁相变开始；35Cl NMR证实了4.5K以下形成长程反铁磁态；磁化率数据显示各向同性的居里-外斯温度(~-145K)和g因子(~2.4)；在30K和27K观察到两次铁电相变，由反演对称性破缺驱动。

Conclusion: KCu7TeO4(SO4)5Cl的磁性和电学行为需要通过包含装饰位点层间耦合的三维模型来解释，这为研究方形kagome晶格系统的受挫磁性和多铁性提供了新平台。

Abstract: The square-kagome lattice, composed of two-dimensional corner-sharing triangles, provides a novel platform for studying frustrated magnetism. However, material realizations of the square-kagome lattice remain scarce. Here, we report the single-crystal growth, structural characterization, magnetic and electric properties of KCu$_7$TeO$_4$(SO$_4$)$_5$Cl, a nabokoite-type compound featuring a distorted and decorated square-kagome lattice. Weak anomalies near 4 K are observed in both magnetization and specific heat, indicating the onset of a magnetic transition.The formation of a long-range antiferromagnetic state below 4.5 K is further confirmed by $^{35}$Cl nuclear magnetic resonance (NMR) measurements. Magnetic susceptibility data reveal nearly isotropic Curie-Weiss temperatures ($\sim-145$ K) and $g$-factors ($\sim2.4$) for both in-plane and out-of-plane magnetic fields. Moreover, we observe two successive ferroelectric transitions at $T_\mathrm{FE1}\sim30$ K and $T_\mathrm{FE2}\sim27$ K, driven by inversion-symmetry breaking, most likely associated with distortions in the Cu2O$_4$Cl$_1$ pyramids and the adjacent SO$_4$ tetrahedra. These results suggest that a three-dimensional model incorporating interlayer couplings via decorating sites is essential for capturing the magnetic and electric behaviors in KCu$_7$TeO$_4$(SO$_4$)$_5$Cl.

</details>


### [48] [Contrasting magnetic behavior in MnSc_2X_4 (X = S, Se) spinel compounds investigated by magnetoelastic studies](https://arxiv.org/abs/2512.09698)
*J. Grumbach,J. Sourd,M. Deeb,A. Miyata,H. Suwa,T. Gottschall,A. Hauspurg,S. Chattopadhyay,M. Rotter,S. Granovsky,L. Prodan,V. Tsurkan,S. Zherlitsyn,M. Doerr,J. Wosnitza*

Main category: cond-mat.str-el

TL;DR: 该研究通过超声和膨胀测量揭示了MnSc₂S₄中存在稳定的斯格明子相，而MnSc₂Se₄中则没有发现斯格明子相，并通过模型计算验证了实验结果。


<details>
  <summary>Details</summary>
Motivation: 研究MnSc₂X₄系列自旋化合物中的磁相变，特别是探索其中是否存在斯格明子等涡旋状磁态，并比较不同阴离子（S和Se）对磁相图的影响。

Method: 使用超声测量和膨胀测量技术提取磁相图，同时结合比热和交流磁化率测量。对MnSc₂S₄和MnSc₂Se₄进行对比研究，并进行模型计算来验证实验结果。

Result: 在MnSc₂S₄中发现多种磁相，包括稳定到最低温度的斯格明子相；而在MnSc₂Se₄中没有发现斯格明子相，也没有观察到明显的相变异常。模型计算较好地再现了实验观察到的磁致伸缩和比热结果。

Conclusion: MnSc₂S₄中存在稳定的斯格明子相，而MnSc₂Se₄中由于磁性离子间距增大导致磁相互作用减弱，没有形成斯格明子相。磁致伸缩耦合在决定这些化合物的磁相行为中起着关键作用。

Abstract: The spinel compounds MnSc_2X_4 are highly frustrated and candidate materials for vortex-like 3q magnetic states, such as skyrmions, with propagation vectors in the [111] plane. Because of the strong magnetoelastic coupling, we could extract a refined magnetic (H, T) phase diagram for MnSc_2S_4 from ultrasound and dilatometry measurements. We found a variety of magnetic phases, including the skyrmion phase, which is stable down to lowest temperatures. In comparison, we investigated MnSc_2Se_4 , having a larger distance between the magnetic Mn^3+ ions using the same methods. Unlike in MnSc_2S_4 , we found no skyrmion phase and overall a lack of sharp anomalies indicative of phase transitions, neither in dilatometry nor ultrasound nor in specific heat and ac-susceptibility data. Motivated by our findings, we performed model calculations, which reproduced the experimentally observed magnetostriction and specific-heat results reasonably well.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [49] [Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study](https://arxiv.org/abs/2512.09088)
*Adrian Ryser,Florian Allwein,Tim Schlippe*

Main category: cs.AI

TL;DR: 本文研究大型语言模型（LLM）的幻觉如何影响用户信任和交互，发现幻觉不会导致全面不信任，而是引发情境敏感的信任校准，并识别了直觉作为新的用户相关信任因素。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型产生的幻觉（看似合理但事实错误的内容）如何影响用户对LLM的信任以及用户与LLM的交互方式，以理解日常使用中的信任动态。

Method: 采用定性研究方法，对192名参与者进行实证研究，基于Lee & See的校准信任模型以及Afroogh等人的信任相关因素理论框架进行分析。

Result: 研究发现：1）幻觉不会导致全面不信任，而是引发情境敏感的信任校准；2）确认期望、先前经验、用户专业知识和领域知识为用户相关信任因素；3）识别直觉作为幻觉检测的额外用户相关因素；4）信任动态受情境因素影响，特别是感知风险和决策风险；5）验证并扩展了Blöbaum的递归信任校准过程。

Conclusion: 基于研究结果，提出了负责任和反思性使用大型语言模型的实用建议，强调信任校准的动态性和情境敏感性，以及直觉在幻觉检测中的重要作用。

Abstract: Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Blöbaum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.

</details>


### [50] [AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance](https://arxiv.org/abs/2512.09114)
*Pamela Gupta*

Main category: cs.AI

TL;DR: 论文提出AI TIPS框架2.0版本，旨在解决当前AI治理框架的三个关键缺陷：缺乏针对具体用例的风险评估、现有框架过于概念化缺乏可操作控制、以及缺乏规模化实施治理的机制。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理框架存在三个关键挑战：1) 组织在用例层面缺乏充分的风险评估能力，如Humana集体诉讼案所示；2) 现有框架如ISO 42001和NIST AI RMF停留在概念层面，缺乏可操作的控制措施；3) 组织缺乏规模化实施治理的机制，无法将可信AI实践嵌入整个开发生命周期。

Method: 提出AI TIPS（人工智能信任集成支柱）2.0框架，这是对2019年开发的综合操作框架的更新，该框架比NIST的AI风险管理框架早四年。该框架直接针对上述挑战提供解决方案。

Result: AI TIPS框架能够为组织提供：1) 针对具体AI用例的定制化风险评估；2) 将治理要求转化为具体技术实施的可操作控制；3) 在整个开发生命周期中规模化实施治理的机制，并提供从董事会到数据科学家的角色适当可见性。

Conclusion: AI TIPS 2.0框架填补了当前AI治理框架的关键空白，通过提供可操作、可扩展的解决方案，帮助组织有效管理AI部署风险，实现可信AI实践的规模化实施。

Abstract: The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case presents unique risk profiles requiring tailored governance, yet most frameworks provide one size fits all guidance. Second, existing frameworks like ISO 42001 and NIST AI RMF remain at high conceptual levels, offering principles without actionable controls, leaving practitioners unable to translate governance requirements into specific technical implementations. Third, organizations lack mechanisms for operationalizing governance at scale, with no systematic approach to embed trustworthy AI practices throughout the development lifecycle, measure compliance quantitatively, or provide role-appropriate visibility from boards to data scientists. We present AI TIPS, Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0, update to the comprehensive operational framework developed in 2019,four years before NIST's AI Risk Management Framework, that directly addresses these challenges.

</details>


### [51] [A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem](https://arxiv.org/abs/2512.09117)
*Luciano Floridi,Yiyang Jia,Fernando Tohmé*

Main category: cs.AI

TL;DR: 本文提出了一个形式化的范畴论框架，用于分析人类和大型语言模型如何将内容转化为关于可能世界状态空间W的真值命题，并论证LLMs并未解决而是绕过了符号接地问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解人类和大型语言模型在将内容转化为真值命题方面的根本差异，特别是探讨LLMs是否真正解决了符号接地问题，还是仅仅绕过了这个问题。

Method: 采用形式化的范畴论框架来分析内容到真值命题的转化过程，通过建立可能世界状态空间W的数学模型，对比人类和LLMs在这一转化过程中的不同机制。

Result: 分析结果表明，大型语言模型并没有真正解决符号接地问题，而是通过不同的机制绕过了这个问题，这与人类处理符号接地的方式存在本质区别。

Conclusion: 结论是LLMs并未解决符号接地问题，而是通过范畴论框架中描述的特殊机制规避了这一问题，这对理解LLMs的能力局限性和本质特征具有重要意义。

Abstract: This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.

</details>


### [52] [Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration](https://arxiv.org/abs/2512.09340)
*Chethana Prasad Kabgere*

Main category: cs.AI

TL;DR: 论文对比了人类和AI系统在模糊视觉刺激下的图像标注表现，分析了两者在感知、推理和决策上的异同，为开发神经符号AI架构提供认知科学基础。


<details>
  <summary>Details</summary>
Motivation: 研究人类与AI系统如何解释模糊视觉刺激，对于理解感知、推理和决策的本质至关重要。通过对比两者在低分辨率、感知退化刺激下的表现，可以揭示生物与人工系统的核心差异，为开发更符合认知原理的AI系统提供理论基础。

Method: 结合计算认知科学、认知架构和连接主义-符号混合模型，对比人类策略（类比推理、形状识别、置信度调节）与AI的特征处理。基于Marr的三层次假说、Simon的有限理性和Thagard的表征与情感框架，分析参与者反应与Grad-CAM可视化模型注意力的关系。使用ACT-R和Soar认知架构解释人类行为，揭示不确定性下的分层启发式决策策略。

Result: 研究发现人类与AI系统在表征、推理和置信度校准方面存在关键相似性和差异性。人类表现出分层和启发式决策策略，而AI主要依赖特征处理。Grad-CAM可视化揭示了模型注意力模式与人类认知策略的对比。

Conclusion: 分析为未来神经符号架构的发展提供了动机，这种架构将结构化符号推理与连接主义表征统一起来。基于具身性、可解释性和认知对齐原则的架构，有望开发出不仅性能优越，而且可解释且具有认知基础的AI系统。

Abstract: Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptually degraded stimuli. Drawing from computational cognitive science, cognitive architectures, and connectionist-symbolic hybrid models, we contrast human strategies such as analogical reasoning, shape-based recognition, and confidence modulation with AI's feature-based processing. Grounded in Marr's tri-level hypothesis, Simon's bounded rationality, and Thagard's frameworks of representation and emotion, we analyze participant responses in relation to Grad-CAM visualizations of model attention. Human behavior is further interpreted through cognitive principles modeled in ACT-R and Soar, revealing layered and heuristic decision strategies under uncertainty. Our findings highlight key parallels and divergences between biological and artificial systems in representation, inference, and confidence calibration. The analysis motivates future neuro-symbolic architectures that unify structured symbolic reasoning with connectionist representations. Such architectures, informed by principles of embodiment, explainability, and cognitive alignment, offer a path toward AI systems that are not only performant but also interpretable and cognitively grounded.

</details>


### [53] [Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search](https://arxiv.org/abs/2512.09566)
*Junkai Ji,Zhangfan Yang,Dong Xu,Ruibin Bai,Jianqiang Li,Tingjun Hou,Zexuan Zhu*

Main category: cs.AI

TL;DR: Trio是一个整合片段分子语言建模、强化学习和蒙特卡洛树搜索的分子生成框架，用于高效可解释的闭环靶向分子设计，在结合亲和力、类药性和合成可及性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统药物发现方法耗时昂贵且成功率低，现有生成模型存在泛化能力不足、可解释性有限、过度关注结合亲和力而忽视其他关键药理学性质等问题，限制了其转化应用价值。

Method: Trio框架整合三个关键组件：基于片段的分子语言建模实现上下文感知的片段组装；强化学习确保物理化学和合成可行性；蒙特卡洛树搜索平衡新颖化学型探索与有前景中间体利用。

Result: 实验结果显示Trio可靠地生成化学有效且药理学增强的配体，在结合亲和力（+7.85%）、类药性（+11.10%）和合成可及性（+12.05%）方面优于最先进方法，同时将分子多样性扩展四倍以上。

Conclusion: Trio提供了一个高效、可解释的闭环靶向分子设计框架，通过整合多种技术解决了现有生成模型的局限性，在药物发现中展现出优越的性能和转化潜力。

Abstract: Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.

</details>


### [54] [An End-to-end Planning Framework with Agentic LLMs and PDDL](https://arxiv.org/abs/2512.09629)
*Emanuele La Malfa,Ping Zhu,Samuele Marro,Sara Bernardini,Michael Wooldridge*

Main category: cs.AI

TL;DR: 提出一个基于验证器的端到端规划框架，使用LLM将自然语言规范转换为PDDL模型，通过多智能体迭代精炼解决时间约束、最优性等规划需求，最终生成可读的自然语言计划


<details>
  <summary>Details</summary>
Motivation: 解决LLM在复杂规划任务（如Blocksworld、汉诺塔）中的局限性，实现无需人工干预的端到端自动规划，处理自然语言规范中的模糊性和矛盾

Method: 使用编排器接收自然语言规范，转换为PDDL模型，通过多个LLM驱动的智能体迭代精炼领域和问题定义，处理时间约束、最优性等需求，最后使用外部规划引擎生成计划并翻译回自然语言

Result: 框架在Google NaturalPlan基准、PlanBench以及Blocksworld、汉诺塔等规划问题上表现出灵活性和有效性，可与Fast Downward、LPG、POPF等多种PDDL规划引擎集成

Conclusion: 该框架代表了LLM辅助端到端规划的重要进展，能够处理LLM难以应对的复杂规划实例，支持多种规划引擎集成，实现全自动规划流程

Abstract: We present an end-to-end framework for planning supported by verifiers. An orchestrator receives a human specification written in natural language and converts it into a PDDL (Planning Domain Definition Language) model, where the domain and problem are iteratively refined by sub-modules (agents) to address common planning requirements, such as time constraints and optimality, as well as ambiguities and contradictions that may exist in the human specification. The validated domain and problem are then passed to an external planning engine to generate a plan. The orchestrator and agents are powered by Large Language Models (LLMs) and require no human intervention at any stage of the process. Finally, a module translates the final plan back into natural language to improve human readability while maintaining the correctness of each step. We demonstrate the flexibility and effectiveness of our framework across various domains and tasks, including the Google NaturalPlan benchmark and PlanBench, as well as planning problems like Blocksworld and the Tower of Hanoi (where LLMs are known to struggle even with small instances). Our framework can be integrated with any PDDL planning engine and validator (such as Fast Downward, LPG, POPF, VAL, and uVAL, which we have tested) and represents a significant step toward end-to-end planning aided by LLMs.

</details>


### [55] [Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions](https://arxiv.org/abs/2512.09727)
*Junlin Xiao,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.AI

TL;DR: 本文提出了一种在连续动作空间中使用高斯过程回归来聚合并行MCTS线程统计信息的方法，相比现有聚合策略表现更优。


<details>
  <summary>Details</summary>
Motivation: 在连续动作空间环境中，如何最佳地聚合来自不同并行线程的统计信息是一个重要但尚未充分探索的问题。当计算时间有限但需要最佳性能时，根并行MCTS变体被广泛使用，但现有聚合策略存在改进空间。

Method: 引入高斯过程回归方法，利用该技术获取未在环境中实际尝试的有前景动作的价值估计，从而更有效地聚合并行线程的统计信息。

Result: 在6个不同领域进行了系统评估，结果表明该方法优于现有的聚合策略，同时推理时间仅需适度增加。

Conclusion: 提出的基于高斯过程回归的聚合方法在连续动作空间的并行MCTS中表现出色，为在线规划提供了更有效的统计信息聚合解决方案。

Abstract: Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.

</details>


### [56] [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829)
*Khurram Khalil,Muhammad Mahad Khaliq,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: RIFT框架使用强化学习自动发现最小化高影响故障场景，加速AI加速器的故障评估，相比进化方法提速2.2倍，相比随机故障注入减少99%测试向量，同时提供更好的故障覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现代AI加速器规模庞大，传统故障评估方法面临计算成本过高、关键故障模式覆盖不足的问题，需要更高效的故障评估框架。

Method: 将复杂的最坏情况故障搜索转化为序列决策问题，结合混合灵敏度分析进行搜索空间剪枝，使用强化学习智能生成最小化高影响测试套件。

Result: 在NVIDIA A100 GPU上的十亿参数大语言模型工作负载评估中，RIFT相比进化方法实现2.2倍加速，相比随机故障注入减少99%测试向量，同时获得更优故障覆盖率。RIFT指导的选择性纠错码相比统一三模冗余保护，成本效益提升12.8倍。

Conclusion: RIFT提供可扩展的故障评估框架，自动生成UVM兼容验证工件，确保结果可直接集成到商业RTL验证流程中，为智能硬件保护策略提供可操作数据。

Abstract: The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \textbf{2.2$\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \textbf{99\%} compared to random fault injection, all while achieving \textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \textbf{12.8$\times$} improvement in \textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.

</details>


### [57] [Interpretation as Linear Transformation: A Cognitive-Geometric Model of Belief and Meaning](https://arxiv.org/abs/2512.09831)
*Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 该论文提出了一个几何框架来建模认知异质智能体之间的信念、动机和影响，将智能体表示为个性化价值空间，信念作为结构化向量，通过线性解释映射传播，并建立了信念在传播中生存的结构性条件。


<details>
  <summary>Details</summary>
Motivation: 论文旨在为认知异质智能体之间的信念动态提供统一的理论框架，解决信念传播、动机漂移、相互理解限制等核心问题，将概念空间、社会认识论和AI价值对齐等领域的见解整合到一个几何模型中。

Method: 采用几何建模方法，将每个智能体表示为个性化价值空间（向量空间），信念形式化为结构化向量，信念传播通过线性解释映射实现，并引入"无零空间领导条件"等代数约束来分析信念动态。

Result: 建立了信念在传播中生存的结构性条件（避免解释映射的零空间），解释了信念扭曲、动机漂移和相互理解限制的代数根源，提出了领导力作为表征可达性而非说服或权威的新定义。

Conclusion: 该认知几何框架通过结构兼容性而非共享信息或理性来统一信念动态分析，为理解人类和人工系统中影响的认知边界提供了理论基础，并为分析异质智能体间的信念动态提供了通用基础。

Abstract: This paper develops a geometric framework for modeling belief, motivation, and influence across cognitively heterogeneous agents. Each agent is represented by a personalized value space, a vector space encoding the internal dimensions through which the agent interprets and evaluates meaning. Beliefs are formalized as structured vectors-abstract beings-whose transmission is mediated by linear interpretation maps. A belief survives communication only if it avoids the null spaces of these maps, yielding a structural criterion for intelligibility, miscommunication, and belief death.
  Within this framework, I show how belief distortion, motivational drift, counterfactual evaluation, and the limits of mutual understanding arise from purely algebraic constraints. A central result-"the No-Null-Space Leadership Condition"-characterizes leadership as a property of representational reachability rather than persuasion or authority. More broadly, the model explains how abstract beings can propagate, mutate, or disappear as they traverse diverse cognitive geometries.
  The account unifies insights from conceptual spaces, social epistemology, and AI value alignment by grounding meaning preservation in structural compatibility rather than shared information or rationality. I argue that this cognitive-geometric perspective clarifies the epistemic boundaries of influence in both human and artificial systems, and offers a general foundation for analyzing belief dynamics across heterogeneous agents.

</details>


### [58] [Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science](https://arxiv.org/abs/2512.09895)
*Jane Greenberg,Scott McClellan,Addy Ireland,Robert Sammarco,Colton Gerber,Christopher B. Rauch,Mat Kelly,John Kunze,Yuan An,Eric Toberer*

Main category: cs.AI

TL;DR: MatSci-YAMZ平台整合AI与人类参与循环，通过众包方式支持材料科学领域元数据词汇开发，成功验证了AI-HILT模型的可行性。


<details>
  <summary>Details</summary>
Motivation: 元数据词汇表对推进FAIR和FARR数据原则至关重要，但受限于人力资源不足和标准化实践不一致，需要新的开发方法。

Method: 开发MatSci-YAMZ平台，整合人工智能与人类参与循环（包括众包），在材料科学领域进行概念验证，6名参与者通过提供术语定义和示例来促进AI定义精炼。

Result: 成功生成19个AI定义，迭代反馈循环验证了AI-HILT精炼的可行性，证明该模型能够增强语义透明度并减少元数据词汇开发所需时间。

Conclusion: MatSci-YAMZ模型具有跨领域扩展潜力，成功验证了AI-HILT方法在元数据词汇开发中的可行性，符合FAIR和开放科学原则。

Abstract: Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [59] [Single particle dynamical signature of topology induced by single mode cavities in Su-Schrieffer-Heeger chain](https://arxiv.org/abs/2512.09520)
*Fabrizio Pavan,Grazia Di Bello,Giulio De Filippis,Carmine Antonio Perroni*

Main category: cond-mat.stat-mech

TL;DR: 该研究探讨了在SSH链中单粒子与多个腔模耦合时，平均手征位移的动力学行为，揭示了耦合频率对拓扑相变检测的影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索环境相互作用如何诱导拓扑相变，以及如何通过平均手征位移这一体探针来检测这些变化。特别关注在非平衡条件下，腔模耦合对拓扑性质的影响。

Method: 研究了一维Su-Schrieffer-Heeger链中单粒子的动力学，该链通过胞间跳跃项与多个腔模耦合。分析了平均手征位移在非平衡条件下的行为，特别关注耦合频率与静态跳跃振幅的相对大小。

Result: 当耦合频率大于静态跳跃振幅时，平均手征位移在短时间内出现不连续跳跃，表明耦合在边缘概率中留下特征。当频率与静态跳跃振幅相当时，拓扑序与耗散效应竞争，使平均手征位移行为平滑，但仍保留驱动耗散拓扑信息。

Conclusion: 腔模耦合对SSH链的拓扑性质有显著影响，平均手征位移能够检测到由环境相互作用诱导的拓扑相变特征，为理解驱动耗散系统中的拓扑性质提供了新见解。

Abstract: Witnessing and tracking topological phase transitions induced by interactions with the environment is a crucial challenge. Among the various experimental approaches to detect topological properties, the Mean Chiral Displacement (MCD) has emerged as a powerful bulk probe in one-dimensional chiral systems, allowing the extraction of the topological invariant from single-particle dynamics. Here we study the dynamics of a single particle in a one-dimensional Su-Schrieffer-Heeger chain coupled to multiple cavity modes via inter-cell hopping terms, focusing on the out-of-equilibrium behavior of the MCD. We show that, whenever the frequency is larger than the static hopping amplitudes, the coupling induces a discontinuous jump in the MCD, already at small times, signaling that such a coupling also leaves a signature in the survival edge probability when the dynamics are initialized at one of the two edges. For frequencies comparable to the static hopping amplitudes, topological order competes with dissipative effects, which makes the MCD behave smoothly, retaining information about the driven-dissipative topology.

</details>


### [60] [Synchronization of thermodynamically consistent stochastic phase oscillators](https://arxiv.org/abs/2512.09718)
*Maciej Chudak,Massimiliano Esposito,Krzysztof Ptaszynski*

Main category: cond-mat.stat-mech

TL;DR: 该研究通过一个简单的两个随机振荡器耦合模型，展示了同步相变与耗散极值原理无关，同步可能减少或增强耗散，并发现了相变附近波动和响应的普适标度行为。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过一个简单的双振荡器耦合模型来理解更复杂、更现实的振荡器系统中的同步现象，特别是探索非平衡相变与耗散原理之间的关系。

Method: 采用一个简单的玩具模型：两个动力学耦合的随机振荡器，其动力学被描述为在N个离散相位状态之间的马尔可夫跳跃过程。当N很大时，该模型映射到确定性的双振荡器Kuramoto同步模型。

Result: 在热力学极限下，模型展示了非平衡相变，但该相变不受任何耗散极值原理支配——同步可能减少或增强耗散。相变附近观察到波动和响应的发散行为，振荡器相位协方差和局部熵产生趋于负无穷。互信息和信息流在同步和非同步状态下表现出不同的标度行为，可作为同步的序参量。

Conclusion: 该简单模型为理解复杂振荡器系统提供了洞见，揭示了同步相变与耗散极值原理无关，并展示了信息论量作为同步序参量的潜力。发现的负无穷发散现象是此前未报道的新现象。

Abstract: We consider a toy model of two kinetically coupled stochastic oscillators whose dynamics is described as a Markov jump process among $N$ discrete phase states. For large $N$, it maps onto the deterministic two-oscillator Kuramoto model of synchronization. Despite its simplicity, we postulate its relevance for understanding more complex and realistic oscillator systems. In the thermodynamic limit, the model exhibits a continuous nonequilibrium phase transition between the unsynchronized and synchronized states. We show that this transition is not governed by any extremum dissipation principle -- depending on system parameters, synchronization may either reduce or enhance the dissipation. Close to the phase transition, we observe a divergent behavior of fluctuations and responses with $N$ and characterize their universal scaling behavior. In particular, the covariances of the oscillator phases and the local entropy productions are shown to diverge towards $-\infty$, a phenomenon that has not been reported before. Finally, we study the behavior of information-theoretic quantities, demonstrating that mutual information and information flow between oscillators display different scaling with $N$ in synchronized and unsynchronized states, and thus can act as order parameters of synchronization.

</details>


### [61] [Burgers equation from non-thermal stationary states in nearly-integrable gases](https://arxiv.org/abs/2512.09726)
*Paweł Lisiak,Maciej Łebek,Miłosz Panfil*

Main category: cond-mat.stat-mech

TL;DR: 研究弱耦合可积系统中气体粒子与大型储层相互作用时的输运行为，发现在非热态背景下会出现Burgers方程而非简单扩散


<details>
  <summary>Details</summary>
Motivation: 传统观点认为气体粒子与大型储层相互作用时，大尺度密度动力学通常由扩散主导。本文旨在研究弱耦合可积系统中，在长寿命非热态背景下输运行为是否会发生改变

Method: 使用Chapman-Enskog理论的变体计算扩散常数和Burgers方程的非线性欧拉尺度耦合，通过数值模拟验证理论结果，采用简化的随机二体碰撞模型（速度交换模型）

Result: 发现在非宇称不变态下，流体力学极限中出现Burgers方程而非简单扩散，理论预测与数值模拟结果高度一致

Conclusion: 弱耦合可积系统在非热态背景下的输运行为与传统扩散图像不同，Burgers方程的出现仅依赖于伽利略不变性、小系统-储层耦合参数和小动量交换条件

Abstract: When a gas of particles interacts with much a larger reservoir the dynamics of density on large scales is typically governed by diffusion. We study this paradigmatic problem for weakly coupled integrable systems and show that this picture is altered when transport is investigated on top of long-lived non-thermal states. Remarkably, for states non-invariant under parity we find Burgers equation arising in the hydrodynamic limit. We explicitly compute the diffusion constant and nonlinear Euler-scale coupling of the Burgers equation using a variant of the Chapman-Enskog theory. We find excellent agreement between our theory and numerical simulations of a simplified model of stochastic two-body collisions, which we call velocity swap models. Our conclusions are based only on Galilean invariance, existence of a small system-bath coupling parameter and a small momentum exchange between the system and the bath.

</details>


### [62] [Hitting the blinking target under stochastic resetting](https://arxiv.org/abs/2512.09739)
*Bartosz Zbik,Bartłomiej Dybiec,Karol Capała,Zbigniew Palmowski,Igor M. Sokolov*

Main category: cond-mat.stat-mech

TL;DR: 研究随机过程首次击中时间，但目标在活跃/非活跃状态间切换，关注目标活跃时的首次击中时间分布，并引入随机重置机制


<details>
  <summary>Details</summary>
Motivation: 首次击中时间在生物学、化学、经济学等多个科学领域具有重要意义。传统研究假设目标状态固定，而现实中目标状态可能动态变化，因此需要研究目标状态切换情况下的首次击中时间分布

Method: 修改标准设置，允许目标在活跃和非活跃两种状态间自发切换，研究目标活跃时首次击中时间的分布。引入随机重置机制，推导重置条件下活跃目标首次被击中的时间公式。通过朗之万动力学的计算机模拟验证分析结果

Result: 为目标活跃时的首次击中时间分布提供了闭式解。在随机重置设置下，推导了活跃目标首次被击中时间的公式。发现重置后系统仍保留部分记忆，不再是马尔可夫过程，这阻碍了标准技术的直接应用

Conclusion: 成功建立了目标状态切换情况下的首次击中时间分析框架，解决了随机重置机制下非马尔可夫系统的分析挑战，为多状态目标系统的首次击中时间研究提供了理论基础和计算方法

Abstract: The first hitting times of a stochastic process, i.e., the first time a process reaches a particular level, are of significant interest across various scientific disciplines, including biology, chemistry, and economics. We modify the standard setup by allowing the target to spontaneously switch between two states, either active or inactive, and investigate the distribution of first hitting times accrued while the target is active. For this setup, we provide closed formulas for the distribution of the first hitting time. Additionally, we can introduce stochastic resetting to the underlying process and, utilizing our results, derive the formulas for the first time the active target is hit by the process under stochastic resetting. Interestingly, we show that resetting in this setup still leaves some memory; the system is no longer Markovian, which prevents a straightforward application of standard techniques. The analytical results are accompanied by computer simulations of Langevin dynamics.

</details>


### [63] [Burgers dynamics for Poisson point process initial conditions of the Weibull class](https://arxiv.org/abs/2512.09813)
*Patrick Valageas*

Main category: cond-mat.stat-mech

TL;DR: 研究推导了一维Burgers方程在泊松点过程随机初始条件下的统计特性，该过程强度遵循幂律分布，指数α>-1。在无粘极限下，利用一阶接触抛物线几何构造，获得了速度概率分布、空隙和激波多重性函数、相关函数及功率谱等解析表达式。


<details>
  <summary>Details</summary>
Motivation: 研究Burgers湍流在特定随机初始条件下的统计特性，这类初始条件能产生自相似演化，其概率分布具有从1到无穷大的拉伸指数尾部，为理解湍流统计特性提供理论框架。

Method: 采用无粘极限下的几何构造方法，利用一阶接触抛物线求解Burgers方程。初始条件由泊松点过程定义，其强度遵循幂律分布。通过解析推导获得各种统计量的显式表达式。

Result: 获得了速度的一点和两点概率分布、空隙和激波的多重性函数、速度和密度相关函数及其功率谱的解析表达式。证明了n点分布层次可分解为两点条件概率序列。特征长度尺度随时间呈幂律增长，指数在0到1/2之间。

Conclusion: 这类初始条件导致自相似演化，产生具有拉伸指数尾部的概率分布，尾部指数覆盖从1到无穷大的完整范围。为Burgers湍流的统计特性提供了完整的理论描述。

Abstract: We derive the statistical properties of one-dimensional Burgers dynamics with stochastic initial conditions for the velocity potential defined by a Poisson point process whose intensity follows a power law with exponent $α> -1$. Working in the inviscid limit and exploiting the geometrical construction of solutions in terms of first-contact parabolas, we derive explicit analytical expressions for a broad set of statistical quantities. These include the one- and two-point probability distributions of the velocity, the multiplicity functions of voids and shocks, and the velocity and density correlation functions together with their associated power spectra. We also show that the full hierarchy of $n$-point distributions factorizes into a sequence of two-point conditional probabilities. This class of initial conditions leads to self-similar evolution and produces probability distributions characterized by stretched-exponential tails, with tail exponents spanning the full range from unity to infinity. The associated characteristic length scale grows as a power law of time, with an exponent lying between zero and one half.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [64] [Optimizing Algorithms for Mobile Health Interventions with Active Querying Optimization](https://arxiv.org/abs/2512.08950)
*Aseel Rawashdeh*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯扩展的ATM算法，用卡尔曼滤波风格的贝叶斯更新替代标准Q学习，在移动健康干预中实现更稳定、样本效率更高的强化学习，但发现ATM框架在复杂现实场景中存在局限性。


<details>
  <summary>Details</summary>
Motivation: 移动健康干预中的强化学习需要在干预效果和用户负担之间取得平衡，特别是在状态测量成本高但至关重要的情况下。标准的ATM启发式方法使用基于时间差分的Q学习，在稀疏和嘈杂环境中容易不稳定。

Method: 提出贝叶斯ATM扩展，用卡尔曼滤波风格的贝叶斯更新替代标准Q学习，维护Q值的不确定性感知估计，实现更稳定和样本效率更高的学习。

Result: 在小型表格环境中，贝叶斯ATM实现了相当或改进的标量化回报，方差显著降低，策略行为更稳定。但在更大更复杂的移动健康设置中，标准和贝叶斯ATM变体都表现不佳，表明ATM的建模假设与现实移动健康领域的结构挑战不匹配。

Conclusion: 研究强调了不确定性感知方法在低数据环境中的价值，同时强调了需要新的强化学习算法，这些算法需要在观察成本约束下显式建模因果结构、连续状态和延迟反馈。

Abstract: Reinforcement learning in mobile health (mHealth) interventions requires balancing intervention efficacy with user burden, particularly when state measurements (for example, user surveys or feedback) are costly yet essential. The Act-Then-Measure (ATM) heuristic addresses this challenge by decoupling control and measurement actions within the Action-Contingent Noiselessly Observable Markov Decision Process (ACNO-MDP) framework. However, the standard ATM algorithm relies on a temporal-difference-inspired Q-learning method, which is prone to instability in sparse and noisy environments. In this work, we propose a Bayesian extension to ATM that replaces standard Q-learning with a Kalman filter-style Bayesian update, maintaining uncertainty-aware estimates of Q-values and enabling more stable and sample-efficient learning. We evaluate our method in both toy environments and clinically motivated testbeds. In small, tabular environments, Bayesian ATM achieves comparable or improved scalarized returns with substantially lower variance and more stable policy behavior. In contrast, in larger and more complex mHealth settings, both the standard and Bayesian ATM variants perform poorly, suggesting a mismatch between ATM's modeling assumptions and the structural challenges of real-world mHealth domains. These findings highlight the value of uncertainty-aware methods in low-data settings while underscoring the need for new RL algorithms that explicitly model causal structure, continuous states, and delayed feedback under observation cost constraints.

</details>


### [65] [An Electrocardiogram Multi-task Benchmark with Comprehensive Evaluations and Insightful Findings](https://arxiv.org/abs/2512.08954)
*Yuhao Xu,Jiaying Lu,Sirui Ding,Defu Cao,Xiao Hu,Carl Yang*

Main category: cs.LG

TL;DR: 该研究评估了基础模型在ECG分析中的表现，发现通用时间序列/ECG基础模型能达到80%的顶级性能，证明了其在心电图分析中的有效性。


<details>
  <summary>Details</summary>
Motivation: 心电图分析需要专业知识，这限制了人工智能在医疗保健中的应用。虽然自监督学习和基础模型使AI系统能够获取领域知识，但缺乏对基础模型在ECG分析性能的全面评估。

Method: 通过将语言/通用时间序列/ECG基础模型与时间序列深度学习模型进行比较，评估它们在ECG分析中的表现。

Result: 实验结果显示，通用时间序列/ECG基础模型达到了80%的顶级性能率，表明它们在ECG分析中是有效的。

Conclusion: 该研究突出了基础模型在推进生理波形分析方面的局限性和潜力，为ECG分析提供了新的AI方法。

Abstract: In the process of patient diagnosis, non-invasive measurements are widely used due to their low risks and quick results. Electrocardiogram (ECG), as a non-invasive method to collect heart activities, is used to diagnose cardiac conditions. Analyzing the ECG typically requires domain expertise, which is a roadblock to applying artificial intelligence (AI) for healthcare. Through advances in self-supervised learning and foundation models, AI systems can now acquire and leverage domain knowledge without relying solely on human expertise. However, there is a lack of comprehensive analyses over the foundation models' performance on ECG. This study aims to answer the research question: "Are Foundation Models Useful for ECG Analysis?" To address it, we evaluate language/general time-series/ECG foundation models in comparison with time-series deep learning models. The experimental results show that general time-series/ECG foundation models achieve a top performance rate of 80%, indicating their effectiveness in ECG analysis. In-depth analyses and insights are provided along with comprehensive experimental results. This study highlights the limitations and potential of foundation models in advancing physiological waveform analysis. The data and code for this benchmark are publicly available at https://github.com/yuhaoxu99/ECGMultitasks-Benchmark.

</details>


### [66] [DW-KNN: A Transparent Local Classifier Integrating Distance Consistency and Neighbor Reliability](https://arxiv.org/abs/2512.08956)
*Kumarjit Pathak,Karthik K,Sachin Madan,Jitin Kapila*

Main category: cs.LG

TL;DR: DW-KNN是一种改进的KNN分类器，通过结合指数距离和邻居有效性双重加权，解决了传统KNN在异构特征空间中所有邻居同等可靠的假设问题，提高了预测可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统距离加权KNN及其变体假设所有k个邻居都同等可靠，这在异构特征空间中成为限制因素，影响了预测观测真实水平的可靠性。

Method: 提出DW-KNN（双重加权KNN），这是一种透明且鲁棒的变体，整合了指数距离和邻居有效性双重加权机制，实现了实例级可解释性，抑制了噪声或错误标记样本，并降低了超参数敏感性。

Result: 在9个数据集上的综合评估显示，DW-KNN平均准确率达到0.8988，在六种方法中排名第二，与表现最好的Ensemble KNN相差不到0.2%。同时表现出最低的交叉验证方差（0.0156），表明预测稳定性可靠。统计显著性测试证实了相对于紧凑性加权KNN（+4.09%）和核加权KNN（+1.13%）的显著改进（p < 0.001）。

Conclusion: DW-KNN为复杂自适应方案提供了一个简单而有效的替代方案，特别适用于需要可解释预测的高风险应用场景。

Abstract: K-Nearest Neighbors (KNN) is one of the most used ML classifiers. However, if we observe closely, standard distance-weighted KNN and relative variants assume all 'k' neighbors are equally reliable. In heterogeneous feature space, this becomes a limitation that hinders reliability in predicting true levels of the observation.
  We propose DW-KNN (Double Weighted KNN), a transparent and robust variant that integrates exponential distance with neighbor validity. This enables instance-level interpretability, suppresses noisy or mislabeled samples, and reduces hyperparameter sensitivity.
  Comprehensive evaluation on 9 data-sets helps to demonstrate that DW-KNN achieves 0.8988 accuracy on average. It ranks 2nd among six methods and within 0.2% of the best-performing Ensemble KNN. It also exhibits the lowest cross-validation variance (0.0156), indicating reliable prediction stability. Statistical significance test confirmed ($p < 0.001$) improvement over compactness weighted KNN (+4.09\%) and Kernel weighted KNN (+1.13\%). The method provides a simple yet effective alternative to complex adaptive schemes, particularly valuable for high-stakes applications requiring explainable predictions.

</details>


### [67] [LUMOS: Large User MOdels for User Behavior Prediction](https://arxiv.org/abs/2512.08957)
*Dhruv Nigam*

Main category: cs.LG

TL;DR: LUMOS是一个基于Transformer的大规模用户模型，通过联合学习多个任务，消除了传统任务特定模型和手动特征工程的需求，利用原始用户活动数据实现用户行为预测。


<details>
  <summary>Details</summary>
Motivation: 在线B2C平台的用户行为预测面临规模化挑战，传统方法依赖任务特定模型和领域特定特征工程，耗时、计算成本高、需要专业知识且不可扩展。

Method: 提出LUMOS架构：1) 基于Transformer的架构，联合学习多个任务；2) 引入新颖的交叉注意力机制，基于未来已知事件（如节假日、促销）进行预测；3) 采用多模态标记化，结合用户交易、事件上下文和静态用户人口统计属性；4) 通过专门的嵌入路径处理丰富表示。

Result: 在包含2750亿用户活动标记、2.5亿用户的生产数据集上，LUMOS在5个任务上优于传统任务特定模型：二分类任务ROC-AUC平均提升0.025，回归任务MAPE降低4.6%。在线A/B测试验证了业务影响，日活跃用户增加3.15%。

Conclusion: LUMOS通过消除任务特定模型和手动特征工程，实现了可扩展的用户行为预测，能够预测复杂行为模式，并在大规模生产环境中验证了其有效性和业务价值。

Abstract: User behavior prediction at scale remains a critical challenge for online B2C platforms. Traditional approaches rely heavily on task-specific models and domain-specific feature engineering. This is time-consuming, computationally expensive, and requires domain expertise and therefore not scalable. We present LUMOS (Large User MOdel Series), a transformer-based architecture that eliminates task-specific models and manual feature engineering by learning multiple tasks jointly using only raw user activity data. LUMOS introduces a novel cross-attention mechanism that conditions predictions on future known events (e.g., holidays, sales, etc.), enabling the model to predict complex behaviour patterns like "how will upcoming holidays affect user engagement?" The architecture also employs multi-modal tokenization, combining user transactions, event context, and static user demographic attributes into rich representations processed through specialized embedding pathways.
  Through extensive experiments on a production dataset spanning 275 billion user activity tokens from 250 million users, we demonstrate that LUMOS achieves superior performance compared to traditional task-specific models. Across 5 tasks with established baselines, we achieve an average improvement of 0.025 in ROC-AUC for binary classification tasks and 4.6\% reduction in MAPE for regression tasks. Online A/B testing validates these improvements translate to measurable business impact with a 3.15\% increase in Daily Active Users.

</details>


### [68] [EEG-Bench: A Benchmark for EEG Foundation Models in Clinical Applications](https://arxiv.org/abs/2512.08959)
*Ard Kastrati,Josua Bürki,Jonas Lauer,Cheng Xuan,Raffaele Iaquinto,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 提出了一个统一的基准测试框架，用于评估基于EEG的基础模型在临床应用中的表现，涵盖11个诊断任务和14个公开EEG数据集。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个统一的基准测试框架来评估EEG基础模型在临床应用中的表现，需要标准化的评估协议来比较传统方法和现代基础模型的性能。

Method: 构建了一个统一的基准测试框架，包含11个明确定义的诊断任务，覆盖14个公开EEG数据集，采用最小预处理和标准化评估协议，支持传统基线模型和现代基础模型的并行比较。

Result: 结果显示，基础模型在某些场景下表现强劲，但在临床分布偏移情况下，更简单的模型通常仍具有竞争力。

Conclusion: 该框架为EEG基础模型的临床评估提供了标准化基准，促进了可重复性和采用，所有准备的数据和代码都以可访问和可扩展的格式发布。

Abstract: We introduce a unified benchmarking framework focused on evaluating EEG-based foundation models in clinical applications. The benchmark spans 11 well-defined diagnostic tasks across 14 publicly available EEG datasets, including epilepsy, schizophrenia, Parkinson's disease, OCD, and mild traumatic brain injury. It features minimal preprocessing, standardized evaluation protocols, and enables side-by-side comparisons of classical baselines and modern foundation models. Our results show that while foundation models achieve strong performance in certain settings, simpler models often remain competitive, particularly under clinical distribution shifts. To facilitate reproducibility and adoption, we release all prepared data and code in an accessible and extensible format.

</details>


### [69] [Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces](https://arxiv.org/abs/2512.08960)
*Yueer Zhou,Yichen Wu,Ying Wei*

Main category: cs.LG

TL;DR: PS-LoRA通过双正则化目标解决LoRA在持续学习中的灾难性遗忘问题，通过惩罚冲突方向和对齐优化子空间来保持参数稳定性，并在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LoRA在持续学习中虽然高效，但经常遭受灾难性遗忘问题。分析发现这种退化主要由对抗性方向更新驱动，即新任务梯度与历史权重轨迹直接冲突。

Method: 提出PS-LoRA框架，采用双正则化目标：1) 惩罚冲突方向，2) 约束幅度偏差以确保与先验知识一致。还实现了基于幅度的合并策略，将顺序适配器整合为鲁棒表示而无需重新训练。

Result: 在NLP和视觉基准测试中，PS-LoRA优于最先进的方法，能够在高效适应新领域的同时保持学习表示的稳定性。

Conclusion: PS-LoRA通过解决LoRA在持续学习中的对抗性更新问题，提供了一种有效的参数稳定性框架，显著减轻了灾难性遗忘，并在多个任务上表现出优越性能。

Abstract: Low-Rank Adaptation (LoRA) enables efficient Continual Learning but often suffers from catastrophic forgetting due to destructive interference between tasks. Our analysis reveals that this degradation is primarily driven by antagonistic directional updates where new task gradients directly oppose the historical weight trajectory. To address this, we propose PS-LoRA (Parameter Stability LoRA), a framework designed to resolve conflicts by aligning updates within the optimization subspace. Our approach employs a dual-regularization objective that penalizes conflicting directions and constrains magnitude deviations to ensure consistency with prior knowledge. Additionally, we implement a magnitude-based merging strategy to consolidate sequential adapters into a robust representation without retraining. Experiments on NLP and Vision benchmarks show that PS-LoRA outperforms state-of-the-art methods by preserving the stability of learned representations while efficiently adapting to new domains.

</details>


### [70] [Financial Instruction Following Evaluation (FIFE)](https://arxiv.org/abs/2512.08965)
*Glenn Matlin,Siddharth,Anirudh JM,Aditya Shukla,Yahya Hassan,Sudheer Chava*

Main category: cs.LG

TL;DR: FIFE是一个用于评估语言模型金融分析指令遵循能力的高难度基准，包含88个人工编写的提示和可验证约束系统。评估显示开源权重模型表现优于专有系统，但所有模型都难以完全满足复杂要求。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理复杂、相互依赖的指令时存在困难，特别是在金融等高精度要求领域。需要专门的基准来评估模型在金融分析任务中的指令遵循能力。

Method: 开发了FIFE基准，包含88个人工编写的金融分析提示，采用可链接、可验证的约束系统提供细粒度奖励信号。在零样本设置下评估了53个模型（专有、开源权重、开源）。

Result: 评估结果显示明确的性能层次：顶级开源权重模型（76.1严格/79.5宽松）优于领先的专有系统（65.9严格/70.5宽松），而最佳开源模型显著落后（45.5严格/48.9宽松）。所有顶级模型都难以完全满足FIFE的复杂要求。

Conclusion: FIFE基准揭示了语言模型在复杂金融分析任务中的局限性，开源权重模型表现优于专有系统。发布数据集和代码作为开源资源，促进金融领域强化学习研究。

Abstract: Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.

</details>


### [71] [CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing](https://arxiv.org/abs/2512.08967)
*Zixia Wang,Gaojie Jin,Jia Hu,Ronghui Mu*

Main category: cs.LG

TL;DR: CluCERT：通过聚类引导去噪平滑认证大语言模型鲁棒性的新框架，在认证边界和计算效率上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能力强大，但仍易受对抗攻击，即使微小的同义词替换也可能导致错误预测。现有认证方法存在两个关键局限：1）由于缺乏对扰动输出的语义验证导致鲁棒性边界宽松；2）由于重复采样导致计算成本高

Method: 提出CluCERT框架，通过聚类引导去噪平滑认证LLM鲁棒性。包括：语义聚类过滤器减少噪声样本并保留有意义的扰动；精炼模块提取核心语义；快速同义词替换策略加速去噪过程

Result: 在各种下游任务和越狱防御场景中的实验表明，该方法在鲁棒性边界和计算效率方面均优于现有认证方法

Conclusion: CluCERT通过语义聚类和高效去噪机制，有效解决了现有LLM鲁棒性认证方法的局限性，提供了更紧的认证边界和更高的计算效率

Abstract: Recent advancements in Large Language Models (LLMs) have led to their widespread adoption in daily applications. Despite their impressive capabilities, they remain vulnerable to adversarial attacks, as even minor meaning-preserving changes such as synonym substitutions can lead to incorrect predictions. As a result, certifying the robustness of LLMs against such adversarial prompts is of vital importance. Existing approaches focused on word deletion or simple denoising strategies to achieve robustness certification. However, these methods face two critical limitations: (1) they yield loose robustness bounds due to the lack of semantic validation for perturbed outputs and (2) they suffer from high computational costs due to repeated sampling. To address these limitations, we propose CluCERT, a novel framework for certifying LLM robustness via clustering-guided denoising smoothing. Specifically, to achieve tighter certified bounds, we introduce a semantic clustering filter that reduces noisy samples and retains meaningful perturbations, supported by theoretical analysis. Furthermore, we enhance computational efficiency through two mechanisms: a refine module that extracts core semantics, and a fast synonym substitution strategy that accelerates the denoising process. Finally, we conduct extensive experiments on various downstream tasks and jailbreak defense scenarios. Experimental results demonstrate that our method outperforms existing certified approaches in both robustness bounds and computational efficiency.

</details>


### [72] [StructuredDNA: A Bio-Physical Framework for Energy-Aware Transformer Routing](https://arxiv.org/abs/2512.08968)
*Mustapha Hamdi*

Main category: cs.LG

TL;DR: StructuredDNA是一个基于生物物理能量最小化原理的稀疏Transformer路由框架，通过语义能量最小化动态选择专家，显著降低计算能耗，在专业和开放领域基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型计算模型的快速扩展导致能源和计算成本急剧增加。受生物系统中结构和功能从低能量配置中涌现的启发，研究者希望开发一种模块化、能量感知的Transformer路由框架。

Method: StructuredDNA用基于语义能量最小化的生物物理能量引导路由层替代密集的混合专家路由。输入被动态分组为语义密码子，路由通过最小化结合内聚性、不确定性和计算成本的全局能量泛函来选择单个专家。

Result: 在BioASQ基准测试中（K=50），实现了97.7%的能量利用密度降低和0.998的语义稳定性指数。在WikiText-103上展示了语义缩放定律，在专家粒度扩展到2048时仍保持超过99%的能量效率。

Conclusion: StructuredDNA建立了生物物理原理与Transformer稀疏专家路由之间的明确联系，为未来能量感知、模块化和可扩展的计算系统提供了基础。该框架具有领域无关性，为稀疏计算框架建立了稳健范式。

Abstract: The rapid scaling of large computational models has led to a critical increase in energy and compute costs. Inspired by biological systems where structure and function emerge from low-energy configurations, we introduce StructuredDNA, a sparse architecture framework for modular, energy-aware Transformer routing. StructuredDNA replaces dense Mixture-of-Experts routing with a bio-physical, energy-guided routing layer based on semantic energy minimization. Inputs are dynamically grouped into semantic codons, and routing selects a single expert by minimizing a global energy functional that combines cohesion, uncertainty, and computational cost.
  We validate StructuredDNA on both specialized (BioASQ) and open-domain benchmarks (WikiText-103). On BioASQ (K = 50), we achieve a 97.7% reduction in Energy Utilization Density (EUD) and a Semantic Stability Index (SSI) of 0.998. We further demonstrate a Semantic Scaling Law on WikiText-103, showing that the architecture generalizes to open domains by scaling expert granularity (K = 2048) while maintaining more than 99% energy efficiency. StructuredDNA thus establishes a robust, domain-agnostic paradigm for future sparse computational frameworks.
  StructuredDNA provides an explicit link between bio-physical principles and sparse expert routing in Transformer architectures, and points toward future energy-aware, modular, and scalable computational systems. We discuss limitations of this proof-of-concept study and outline directions for scaling the approach to larger models, datasets, and hardware platforms. The StructuredDNA implementation is available at https://github.com/InnoDeep-repos/StructuredDNA .

</details>


### [73] [Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs](https://arxiv.org/abs/2512.08976)
*Isha Chaturvedi,Anjana Nair,Yushen Li,Adhitya Rajendra Kumar,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma*

Main category: cs.LG

TL;DR: CRM是一种无需训练的诊断方法，通过对比性区域掩码揭示多模态大语言模型在思维链推理中如何依赖特定视觉区域，从答案正确性评估转向推理忠实性评估。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于最终答案或注意力图，无法提供因果性、步骤级的归因，需要新的评估框架来衡量多模态模型推理的鲁棒性和忠实性。

Method: CRM通过系统性地掩码标注的视觉区域，并将得到的推理轨迹与未掩码基线进行对比，实现训练自由的诊断，揭示模型在思维链推理中对特定视觉区域的依赖。

Result: 在VisArgs等数据集上，CRM揭示了不同的失败模式：一些模型保持推理结构但在证据缺失时产生幻觉，另一些模型紧密依赖视觉线索但在扰动下崩溃。

Conclusion: CRM将视觉基准重新定义为诊断工具，强调需要不仅衡量性能，还要评估推理鲁棒性和忠实性的多模态评估框架。

Abstract: We introduce Contrastive Region Masking (CRM), a training free diagnostic that reveals how multimodal large language models (MLLMs) depend on specific visual regions at each step of chain-of-thought (CoT) reasoning. Unlike prior approaches limited to final answers or attention maps, CRM provides causal, step-level attri- bution by systematically masking annotated regions and contrasting the resulting reasoning traces with unmasked baselines. Applied to datasets such as VisArgs, CRM reveals distinct failure modes: some models preserve reasoning structure, but hallucinate when evidence is missing, while others ground tightly to visual cues yet collapse under perturbations. By shifting the evaluation from correctness of an- swers to faithfulness of reasoning, CRM reframes visual benchmarks as diagnostic tools, highlighting the need for multimodal evaluation frameworks that measure not just performance, but also robustness and fidelity of reasoning.

</details>


### [74] [Improving Multi-Class Calibration through Normalization-Aware Isotonic Techniques](https://arxiv.org/abs/2512.09054)
*Alon Arad,Saharon Rosset*

Main category: cs.LG

TL;DR: 提出新的等渗归一化感知多类校准方法，相比传统方法显著改善概率预测的准确性和可靠性


<details>
  <summary>Details</summary>
Motivation: 多类监督学习需要准确可靠的概率预测，但现有等渗回归方法在多类校准中表现不佳，限制了实际应用

Method: 提出两种新方法：NA-FIR（将归一化直接纳入优化过程）和SCIR（建模为累积双变量等渗回归问题）

Result: 在多种文本和图像分类数据集及不同模型架构上，新方法持续改善负对数似然和期望校准误差指标

Conclusion: 提出的等渗归一化感知技术为多类校准提供了有效解决方案，基于自然直观的假设，优于现有方法

Abstract: Accurate and reliable probability predictions are essential for multi-class supervised learning tasks, where well-calibrated models enable rational decision-making. While isotonic regression has proven effective for binary calibration, its extension to multi-class problems via one-vs-rest calibration produced suboptimal results when compared to parametric methods, limiting its practical adoption. In this work, we propose novel isotonic normalization-aware techniques for multiclass calibration, grounded in natural and intuitive assumptions expected by practitioners. Unlike prior approaches, our methods inherently account for probability normalization by either incorporating normalization directly into the optimization process (NA-FIR) or modeling the problem as a cumulative bivariate isotonic regression (SCIR). Empirical evaluation on a variety of text and image classification datasets across different model architectures reveals that our approach consistently improves negative log-likelihood (NLL) and expected calibration error (ECE) metrics.

</details>


### [75] [A Diffusion-Based Framework for High-Resolution Precipitation Forecasting over CONUS](https://arxiv.org/abs/2512.09059)
*Marina Vicens-Miquel,Amy McGovern,Aaron J. Hill,Efi Foufoula-Georgiou,Clement Guilloteau,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散的深度学习框架，系统比较了三种残差预测策略：纯数据驱动模型、HRRR预报校正模型和混合模型，在1公里分辨率下进行1-12小时降水预报，结果显示深度学习框架在所有预报时效上都优于HRRR基准，混合模型在短时效表现最佳，HRRR校正模型在长时效表现最优。


<details>
  <summary>Details</summary>
Motivation: 准确的降水预报对于水文气象风险管理至关重要，特别是对于可能导致山洪暴发和基础设施损坏的极端降雨。本研究旨在通过系统比较不同数据源（观测数据、数值预报、混合数据）对降水预报技能的贡献，提高预报准确性和可靠性。

Method: 采用基于扩散的深度学习框架，比较三种残差预测策略：1）仅使用MRMS系统历史观测数据的纯数据驱动模型；2）仅使用HRRR数值天气预报系统预报的校正模型；3）整合MRMS和选定HRRR预报变量的混合模型。在1公里空间分辨率下进行1-12小时预报，使用自回归滚动预测，并针对残差学习设置进行校准的不确定性量化。

Result: 在所有预报时效上，深度学习框架在像素级和空间统计指标上都一致优于HRRR基准。混合模型在最短预报时效表现最佳，而HRRR校正模型在较长预报时效上优于其他模型，在12小时内保持高技能。通过校准的不确定性量化评估了预报可靠性。

Conclusion: 该研究通过增强预测技能、可靠性和区域适用性，推进了基于深度学习的降水预报。特别是在较长预报时效上的改进对于应急准备至关重要，适度的预报时效增加可以改善决策制定。HRRR校正模型在长时效预报中的优势表明数值天气预报在深度学习框架中的重要价值。

Abstract: Accurate precipitation forecasting is essential for hydrometeorological risk management, especially for anticipating extreme rainfall that can lead to flash flooding and infrastructure damage. This study introduces a diffusion-based deep learning (DL) framework that systematically compares three residual prediction strategies differing only in their input sources: (1) a fully data-driven model using only past observations from the Multi-Radar Multi-Sensor (MRMS) system, (2) a corrective model using only forecasts from the High-Resolution Rapid Refresh (HRRR) numerical weather prediction system, and (3) a hybrid model integrating both MRMS and selected HRRR forecast variables. By evaluating these approaches under a unified setup, we provide a clearer understanding of how each data source contributes to predictive skill over the Continental United States (CONUS). Forecasts are produced at 1-km spatial resolution, beginning with direct 1-hour predictions and extending to 12 hours using autoregressive rollouts. Performance is evaluated using both CONUS-wide and region-specific metrics that assess overall performance and skill at extreme rainfall thresholds. Across all lead times, our DL framework consistently outperforms the HRRR baseline in pixel-wise and spatiostatistical metrics. The hybrid model performs best at the shortest lead time, while the HRRR-corrective model outperforms others at longer lead times, maintaining high skill through 12 hours. To assess reliability, we incorporate calibrated uncertainty quantification tailored to the residual learning setup. These gains, particularly at longer lead times, are critical for emergency preparedness, where modest increases in forecast horizon can improve decision-making. This work advances DL-based precipitation forecasting by enhancing predictive skill, reliability, and applicability across regions.

</details>


### [76] [Modular Deep-Learning-Based Early Warning System for Deadly Heatwave Prediction](https://arxiv.org/abs/2512.09074)
*Shangqing Xu,Zhiyuan Zhao,Megha Sharma,José María Martín-Olalla,Alexander Rodríguez,Gregory A. Wellenius,B. Aditya Prakash*

Main category: cs.LG

TL;DR: DeepTherm是一个无需热相关死亡率历史数据的模块化致命热浪预警系统，通过深度学习技术分离基线死亡率和异常事件，在西班牙真实数据上表现出稳健性能。


<details>
  <summary>Details</summary>
Motivation: 城市地区的严重热浪对公共健康构成重大威胁，需要建立早期预警策略。现有方法难以预测即将到来的致命热浪，因为定义和估计热相关死亡率存在困难，且早期预警系统需要满足数据可用性、时空稳健性和决策成本等额外要求。

Method: DeepTherm采用模块化设计，利用深度学习的灵活性，采用双预测管道，从全因死亡率中分离出无热浪和其他异常事件时的基线死亡率。系统无需热相关死亡率历史数据。

Result: 在西班牙真实数据上的评估表明，DeepTherm在不同地区、时间段和人群群体中表现出一致、稳健和准确的性能，同时允许在漏报和误报之间进行权衡。

Conclusion: DeepTherm成功解决了预测致命热浪的挑战，提供了一个无需历史死亡率数据的有效早期预警系统，具有实际应用价值。

Abstract: Severe heatwaves in urban areas significantly threaten public health, calling for establishing early warning strategies. Despite predicting occurrence of heatwaves and attributing historical mortality, predicting an incoming deadly heatwave remains a challenge due to the difficulty in defining and estimating heat-related mortality. Furthermore, establishing an early warning system imposes additional requirements, including data availability, spatial and temporal robustness, and decision costs. To address these challenges, we propose DeepTherm, a modular early warning system for deadly heatwave prediction without requiring heat-related mortality history. By highlighting the flexibility of deep learning, DeepTherm employs a dual-prediction pipeline, disentangling baseline mortality in the absence of heatwaves and other irregular events from all-cause mortality. We evaluated DeepTherm on real-world data across Spain. Results demonstrate consistent, robust, and accurate performance across diverse regions, time periods, and population groups while allowing trade-off between missed alarms and false alarms.

</details>


### [77] [Beyond the Hype: Comparing Lightweight and Deep Learning Models for Air Quality Forecasting](https://arxiv.org/abs/2512.09076)
*Moazzam Umer Gondal,Hamad ul Qudous,Asma Ahmad Farhan*

Main category: cs.LG

TL;DR: 轻量级可加模型（Facebook Prophet和NeuralProphet）在北京PM2.5和PM10预测中表现优于传统统计方法和复杂深度学习模型，提供准确性、可解释性和易部署性的平衡。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习和混合模型在空气污染预测研究中占主导地位，但其复杂性和有限的可解释性阻碍了实际应用。本研究旨在探索轻量级可加模型是否能在北京PM2.5和PM10预测中提供有竞争力的性能。

Method: 使用多年污染物和气象数据，应用系统特征选择（相关性、互信息、mRMR）、防泄漏缩放和时序数据分割。训练Facebook Prophet和NeuralProphet模型，并实现LSTM、LightGBM和SARIMAX作为基准模型进行对比。

Result: Facebook Prophet在7天保留测试集上表现最佳，对两种污染物的测试R²均超过0.94，优于NeuralProphet、SARIMAX和基于学习的基准模型。

Conclusion: 可解释的可加模型在空气污染预测中仍具有竞争力，提供了准确性、透明度和易部署性的实用平衡，是复杂深度学习方法的可行替代方案。

Abstract: Accurate forecasting of urban air pollution is essential for protecting public health and guiding mitigation policies. While Deep Learning (DL) and hybrid pipelines dominate recent research, their complexity and limited interpretability hinder operational use. This study investigates whether lightweight additive models -- Facebook Prophet (FBP) and NeuralProphet (NP) -- can deliver competitive forecasts for particulate matter (PM$_{2.5}$, PM$_{10}$) in Beijing, China. Using multi-year pollutant and meteorological data, we applied systematic feature selection (correlation, mutual information, mRMR), leakage-safe scaling, and chronological data splits. Both models were trained with pollutant and precursor regressors, with NP additionally leveraging lagged dependencies. For context, two machine learning baselines (LSTM, LightGBM) and one traditional statistical model (SARIMAX) were also implemented. Performance was evaluated on a 7-day holdout using MAE, RMSE, and $R^2$. Results show that FBP consistently outperformed NP, SARIMAX, and the learning-based baselines, achieving test $R^2$ above 0.94 for both pollutants. These findings demonstrate that interpretable additive models remain competitive with both traditional and complex approaches, offering a practical balance of accuracy, transparency, and ease of deployment.

</details>


### [78] [Learning Unmasking Policies for Diffusion Language Models](https://arxiv.org/abs/2512.09106)
*Metod Jazbec,Theo X. Olausson,Louis Béthune,Pierre Ablin,Michael Kirchhof,Joao Monterio,Victor Turrisi,Jason Ramapuram,Marco Cuturi*

Main category: cs.LG

TL;DR: 本文提出使用强化学习训练扩散语言模型的采样策略，替代需要手动调优的启发式方法，在保持生成质量的同时提高效率。


<details>
  <summary>Details</summary>
Motivation: 当前扩散语言模型使用启发式采样策略（如置信度阈值）存在需要手动调优、在大缓冲区下性能下降的问题，需要更自动化的采样方法。

Method: 将掩码扩散采样形式化为马尔可夫决策过程，使用基于单层Transformer的轻量级策略架构，将dLLM标记置信度映射到解掩码决策，通过强化学习训练采样策略。

Result: 训练的策略在半自回归生成中达到最先进启发式方法的性能，在完整扩散设置中表现更优，且能泛化到新的底层dLLM和更长序列长度。

Conclusion: 强化学习训练的采样策略能有效替代启发式方法，但在域外数据上性能会下降，且精度-效率权衡的细粒度调优仍具挑战性。

Abstract: Diffusion (Large) Language Models (dLLMs) now match the downstream performance of their autoregressive counterparts on many tasks, while holding the promise of being more efficient during inference. One particularly successful variant is masked discrete diffusion, in which a buffer filled with special mask tokens is progressively replaced with tokens sampled from the model's vocabulary. Efficiency can be gained by unmasking several tokens in parallel, but doing too many at once risks degrading the generation quality. Thus, one critical design aspect of dLLMs is the sampling procedure that selects, at each step of the diffusion process, which tokens to replace. Indeed, recent work has found that heuristic strategies such as confidence thresholding lead to both higher quality and token throughput compared to random unmasking. However, such heuristics have downsides: they require manual tuning, and we observe that their performance degrades with larger buffer sizes. In this work, we instead propose to train sampling procedures using reinforcement learning. Specifically, we formalize masked diffusion sampling as a Markov decision process in which the dLLM serves as the environment, and propose a lightweight policy architecture based on a single-layer transformer that maps dLLM token confidences to unmasking decisions. Our experiments show that these trained policies match the performance of state-of-the-art heuristics when combined with semi-autoregressive generation, while outperforming them in the full diffusion setting. We also examine the transferability of these policies, finding that they can generalize to new underlying dLLMs and longer sequence lengths. However, we also observe that their performance degrades when applied to out-of-domain data, and that fine-grained tuning of the accuracy-efficiency trade-off can be challenging with our approach.

</details>


### [79] [Towards Optimal Valve Prescription for Transcatheter Aortic Valve Replacement (TAVR) Surgery: A Machine Learning Approach](https://arxiv.org/abs/2512.09198)
*Phevos Paschalidis,Vasiliki Stoumpou,Lisa Everest,Yu Ma,Talhat Azemi,Jawad Haider,Steven Zweibel,Eleftherios M. Protopapas,Jeff Mather,Maciej Tysarowski,George E. Sarris,Robert C. Hagberg,Howard L. Haronian,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 该研究开发了一个数据驱动的临床支持工具，用于在经导管主动脉瓣置换术（TAVR）中选择最优瓣膜类型，以降低永久起搏器植入（PPI）的风险。


<details>
  <summary>Details</summary>
Motivation: TAVR已成为治疗严重主动脉瓣狭窄的微创方法，但不同经导管心脏瓣膜（THV）的选择指南仍存在争议。永久起搏器植入是主要的术后并发症，需要优化瓣膜选择策略来降低这一风险。

Method: 1. 整合了美国和希腊患者群体的多源数据集（人口统计学、CT扫描、超声心动图）
2. 采用叶级分析（leaf-level analysis）利用人群异质性，避免基于不确定反事实风险估计的基准比较
3. 开发了统一的个性化处方模型

Result: 最终处方模型在美国内部人群中使PPI率降低了26%，在希腊外部验证队列中降低了16%，相比当前标准护理有明显改善。

Conclusion: 该研究首次提出了TAVR中THV选择的统一、个性化处方策略，通过数据驱动方法显著降低了永久起搏器植入风险，为临床决策提供了有力支持。

Abstract: Transcatheter Aortic Valve Replacement (TAVR) has emerged as a minimally invasive treatment option for patients with severe aortic stenosis, a life-threatening cardiovascular condition. Multiple transcatheter heart valves (THV) have been approved for use in TAVR, but current guidelines regarding valve type prescription remain an active topic of debate. We propose a data-driven clinical support tool to identify the optimal valve type with the objective of minimizing the risk of permanent pacemaker implantation (PPI), a predominant postoperative complication. We synthesize a novel dataset that combines U.S. and Greek patient populations and integrates three distinct data sources (patient demographics, computed tomography scans, echocardiograms) while harmonizing differences in each country's record system. We introduce a leaf-level analysis to leverage population heterogeneity and avoid benchmarking against uncertain counterfactual risk estimates. The final prescriptive model shows a reduction in PPI rates of 26% and 16% compared with the current standard of care in our internal U.S. population and external Greek validation cohort, respectively. To the best of our knowledge, this work represents the first unified, personalized prescription strategy for THV selection in TAVR.

</details>


### [80] [LLMs for Analog Circuit Design Continuum (ACDC)](https://arxiv.org/abs/2512.09199)
*Yasaman Esfandiari,Jocelyn Rego,Austin Meyer,Jonathan Gallagher,Mia Levy*

Main category: cs.LG

TL;DR: 该研究探讨了大型语言模型在模拟电路设计中的应用可靠性和一致性，发现模型对数据格式敏感、生成设计不稳定、泛化能力有限等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs和Transformer架构在各种自然语言任务中表现出色，但它们在真实工程领域（特别是模拟电路设计）的可靠性和鲁棒性尚未得到充分探索，这限制了其在人类中心工作流程中的实际应用价值。

Method: 研究比较了不同数据表示对模型行为的影响，对比了较小模型（如T5、GPT-2）与较大基础模型（如Mistral-7B、GPT-oss-20B）在不同训练条件下的表现，重点关注AI辅助设计中人类保持参与的情况。

Result: 研究发现了关键可靠性挑战：对数据格式敏感、生成设计不稳定、对未见电路配置的泛化能力有限。这些发现揭示了LLMs作为增强人类在复杂工程任务中能力工具的局限性。

Conclusion: 该研究为LLMs作为增强人类在复杂工程任务中能力的工具提供了早期证据，揭示了其局限性和潜力，并为设计可靠、可部署的基础模型在结构化真实世界应用中提供了见解。

Abstract: Large Language Models (LLMs) and transformer architectures have shown impressive reasoning and generation capabilities across diverse natural language tasks. However, their reliability and robustness in real-world engineering domains remain largely unexplored, limiting their practical utility in human-centric workflows. In this work, we investigate the applicability and consistency of LLMs for analog circuit design -- a task requiring domain-specific reasoning, adherence to physical constraints, and structured representations -- focusing on AI-assisted design where humans remain in the loop. We study how different data representations influence model behavior and compare smaller models (e.g., T5, GPT-2) with larger foundation models (e.g., Mistral-7B, GPT-oss-20B) under varying training conditions. Our results highlight key reliability challenges, including sensitivity to data format, instability in generated designs, and limited generalization to unseen circuit configurations. These findings provide early evidence on the limits and potential of LLMs as tools to enhance human capabilities in complex engineering tasks, offering insights into designing reliable, deployable foundation models for structured, real-world applications.

</details>


### [81] [Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation](https://arxiv.org/abs/2512.09267)
*Ce Wang,Weihang Dai,Hanru Bai,Xiaomeng Li*

Main category: cs.LG

TL;DR: 该论文提出了一种用于半监督回归的对比学习方法，通过构建特征相似度矩阵并利用谱排序算法恢复未标记样本的序数关系，减少对昂贵标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习方法高度依赖标签信息来恢复特征的序数关系，限制了其在半监督回归中的应用。需要一种方法能够利用未标记数据来减少对昂贵标注的依赖。

Method: 1. 构建包含标记和未标记样本的特征相似度矩阵以反映样本间关系
2. 使用谱排序算法恢复未标记样本的序数关系（在误差范围内）
3. 利用标记样本提供正则化，使排序更可靠
4. 使用动态规划算法选择鲁棒特征进行矩阵构建
5. 将恢复的序数关系用于未标记样本的对比学习
6. 使用序数排序监督未标记样本的预测作为额外训练信号

Result: 通过理论保证和多个数据集的实验验证，该方法超越了现有的最先进的半监督深度回归方法。

Conclusion: 该方法成功地将对比回归方法扩展到半监督设置，通过利用未标记数据和恢复序数关系，实现了更鲁棒的特征表示学习，减少了对比学习方法对标签信息的依赖。

Abstract: Contrastive learning methods enforce label distance relationships in feature space to improve representation capability for regression models. However, these methods highly depend on label information to correctly recover ordinal relationships of features, limiting their applications to semi-supervised regression. In this work, we extend contrastive regression methods to allow unlabeled data to be used in the semi-supervised setting, thereby reducing the dependence on costly annotations. Particularly we construct the feature similarity matrix with both labeled and unlabeled samples in a mini-batch to reflect inter-sample relationships, and an accurate ordinal ranking of involved unlabeled samples can be recovered through spectral seriation algorithms if the level of error is within certain bounds. The introduction of labeled samples above provides regularization of the ordinal ranking with guidance from the ground-truth label information, making the ranking more reliable. To reduce feature perturbations, we further utilize the dynamic programming algorithm to select robust features for the matrix construction. The recovered ordinal relationship is then used for contrastive learning on unlabeled samples, and we thus allow more data to be used for feature representation learning, thereby achieving more robust results. The ordinal rankings can also be used to supervise predictions on unlabeled samples, serving as an additional training signal. We provide theoretical guarantees and empirical verification through experiments on various datasets, demonstrating that our method can surpass existing state-of-the-art semi-supervised deep regression methods. Our code have been released on https://github.com/xmed-lab/CLSS.

</details>


### [82] [Self-Supervised Learning with Gaussian Processes](https://arxiv.org/abs/2512.09322)
*Yunshan Duan,Sinead Williamson*

Main category: cs.LG

TL;DR: 提出GPSSL方法，使用高斯过程进行自监督学习，解决了传统SSL方法在正样本生成困难和不确定性量化方面的不足


<details>
  <summary>Details</summary>
Motivation: 传统自监督学习方法需要生成相似样本对，这在某些数据类型中具有挑战性，且缺乏不确定性量化能力，在样本外预测中表现不佳

Method: 提出高斯过程自监督学习（GPSSL），在表示上施加高斯过程先验，通过最小化损失函数获得广义贝叶斯后验，利用GP的协方差函数自然地将相似单元的表示拉近

Result: GPSSL在多个数据集上的分类和回归任务中，在准确性、不确定性量化和误差控制方面优于传统方法

Conclusion: GPSSL为自监督学习提供了一种新方法，能够处理传统SSL的局限性，提供更好的不确定性量化能力，并与核PCA和VICReg等方法有理论联系

Abstract: Self supervised learning (SSL) is a machine learning paradigm where models learn to understand the underlying structure of data without explicit supervision from labeled samples. The acquired representations from SSL have demonstrated useful for many downstream tasks including clustering, and linear classification, etc. To ensure smoothness of the representation space, most SSL methods rely on the ability to generate pairs of observations that are similar to a given instance. However, generating these pairs may be challenging for many types of data. Moreover, these methods lack consideration of uncertainty quantification and can perform poorly in out-of-sample prediction settings. To address these limitations, we propose Gaussian process self supervised learning (GPSSL), a novel approach that utilizes Gaussian processes (GP) models on representation learning. GP priors are imposed on the representations, and we obtain a generalized Bayesian posterior minimizing a loss function that encourages informative representations. The covariance function inherent in GPs naturally pulls representations of similar units together, serving as an alternative to using explicitly defined positive samples. We show that GPSSL is closely related to both kernel PCA and VICReg, a popular neural network-based SSL method, but unlike both allows for posterior uncertainties that can be propagated to downstream tasks. Experiments on various datasets, considering classification and regression tasks, demonstrate that GPSSL outperforms traditional methods in terms of accuracy, uncertainty quantification, and error control.

</details>


### [83] [Branching Strategies Based on Subgraph GNNs: A Study on Theoretical Promise versus Practical Reality](https://arxiv.org/abs/2512.09355)
*Junru Zhou,Yicheng Wang,Pan Li*

Main category: cs.LG

TL;DR: 该研究探讨了子图GNN作为混合整数线性规划中分支选择的理论中间方案，发现节点锚定子图GNN理论上能近似强分支评分，但实际应用中因计算复杂度高导致性能不佳。


<details>
  <summary>Details</summary>
Motivation: 标准消息传递GNN在混合整数线性规划分支选择中效率高但表达能力不足，而高阶GNN表达能力足够但计算成本过高。研究旨在寻找理论表达能力与计算效率之间的平衡点。

Method: 采用节点锚定子图GNN作为理论中间方案，证明其表达能力虽低于3-WL但足以近似强分支评分，并在四个基准数据集上进行实证评估。

Result: 理论上节点锚定子图GNN能提供更优的分支决策，但实际中O(n)复杂度导致显著的内存瓶颈和较慢的求解时间，性能反而不如MPNN和启发式方法。

Conclusion: 对于MILP分支选择，表达性GNN的计算成本目前超过了决策质量带来的收益，未来研究应聚焦于保持效率的表达性提升。

Abstract: Graph Neural Networks (GNNs) have emerged as a promising approach for ``learning to branch'' in Mixed-Integer Linear Programming (MILP). While standard Message-Passing GNNs (MPNNs) are efficient, they theoretically lack the expressive power to fully represent MILP structures. Conversely, higher-order GNNs (like 2-FGNNs) are expressive but computationally prohibitive. In this work, we investigate Subgraph GNNs as a theoretical middle ground. Crucially, while previous work [Chen et al., 2025] demonstrated that GNNs with 3-WL expressive power can approximate Strong Branching, we prove a sharper result: node-anchored Subgraph GNNs whose expressive power is strictly lower than 3-WL [Zhang et al., 2023] are sufficient to approximate Strong Branching scores. However, our extensive empirical evaluation on four benchmark datasets reveals a stark contrast between theory and practice. While node-anchored Subgraph GNNs theoretically offer superior branching decisions, their $O(n)$ complexity overhead results in significant memory bottlenecks and slower solving times than MPNNs and heuristics. Our results indicate that for MILP branching, the computational cost of expressive GNNs currently outweighs their gains in decision quality, suggesting that future research must focus on efficiency-preserving expressivity.

</details>


### [84] [Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design](https://arxiv.org/abs/2512.09329)
*Amin Tavakoli,Raswanth Murugan,Ozan Gokdemir,Arvind Ramanathan,Frances Arnold,Anima Anandkumar*

Main category: cs.LG

TL;DR: 提出了一种简单通用的蛋白质语言模型快速监督微调方法，通过轻量级筛选管道构建高质量训练数据，无需昂贵实验数据集，能生成更稳定、功能更好的酶蛋白序列


<details>
  <summary>Details</summary>
Motivation: 蛋白质序列建模中高质量标注数据难以获取，现有监督微调方法依赖昂贵的实验数据集，需要一种更高效的方法来改进蛋白质语言模型的生成质量

Method: 利用蛋白质语言模型自身，结合轻量级筛选管道和领域特定过滤器构建高质量训练数据，然后进行监督微调，该方法不依赖于特定蛋白质语言模型或蛋白质系统

Result: 在色氨酸合酶酶家族上应用基因组规模蛋白质语言模型（GenSLM）验证，微调后的模型生成的序列不仅更新颖，而且在目标设计约束和涌现蛋白质特性指标上都显示出改进特征

Conclusion: 该方法提供了一种高效监督微调蛋白质语言模型的通用方案，能够生成更稳定、功能更好的酶蛋白，同时扩展了对蛋白质序列空间的探索

Abstract: Supervised fine-tuning (SFT) is a standard approach for adapting large language models to specialized domains, yet its application to protein sequence modeling and protein language models (PLMs) remains ad hoc. This is in part because high-quality annotated data are far more difficult to obtain for proteins than for natural language. We present a simple and general recipe for fast SFT of PLMs, designed to improve the fidelity, reliability, and novelty of generated protein sequences. Unlike existing approaches that require costly precompiled experimental datasets for SFT, our method leverages the PLM itself, integrating a lightweight curation pipeline with domain-specific filters to construct high-quality training data. These filters can independently refine a PLM's output and identify candidates for in vitro evaluation; when combined with SFT, they enable PLMs to generate more stable and functional enzymes, while expanding exploration into protein sequence space beyond natural variants. Although our approach is agnostic to both the choice of protein language model (PLM) and the protein system, we demonstrate its effectiveness with a genome-scale PLM (GenSLM) applied to the tryptophan synthase enzyme family. The supervised fine-tuned model generates sequences that are not only more novel but also display improved characteristics across both targeted design constraints and emergent protein property measures.

</details>


### [85] [Towards Resilient Transportation: A Conditional Transformer for Accident-Informed Traffic Forecasting](https://arxiv.org/abs/2512.09398)
*Hongjun Wang,Jiawei Yong,Jiawei Wang,Shintaro Fukushima,Renhe Jiang*

Main category: cs.LG

TL;DR: 本文提出了ConFormer（条件Transformer）框架，通过整合交通事故和管制数据来增强交通预测准确性，在东京和加州数据集上超越了现有最佳模型STAEFormer。


<details>
  <summary>Details</summary>
Motivation: 交通预测面临的主要挑战是外部因素（如交通事故和交通管制）的复杂影响，现有模型由于数据整合有限往往忽视这些因素，导致预测准确性受限。

Method: 提出了ConFormer框架，整合了图传播和引导归一化层，能够基于历史模式动态调整空间和时间节点关系，并使用了包含交通事故和管制数据的东京和加州数据集。

Result: ConFormer在预测性能和效率上都超越了最先进的STAEFormer模型，计算成本更低，参数需求更少，在多个指标上持续优于主流时空基线模型。

Conclusion: ConFormer框架通过有效整合外部因素数据，显著提升了交通预测的准确性，展示了在交通预测研究中的潜力。

Abstract: Traffic prediction remains a key challenge in spatio-temporal data mining, despite progress in deep learning. Accurate forecasting is hindered by the complex influence of external factors such as traffic accidents and regulations, often overlooked by existing models due to limited data integration. To address these limitations, we present two enriched traffic datasets from Tokyo and California, incorporating traffic accident and regulation data. Leveraging these datasets, we propose ConFormer (Conditional Transformer), a novel framework that integrates graph propagation with guided normalization layer. This design dynamically adjusts spatial and temporal node relationships based on historical patterns, enhancing predictive accuracy. Our model surpasses the state-of-the-art STAEFormer in both predictive performance and efficiency, achieving lower computational costs and reduced parameter demands. Extensive evaluations demonstrate that ConFormer consistently outperforms mainstream spatio-temporal baselines across multiple metrics, underscoring its potential to advance traffic prediction research.

</details>


### [86] [Representation Invariance and Allocation: When Subgroup Balance Matters](https://arxiv.org/abs/2512.09496)
*Anissa Alloula,Charles Jones,Zuzanna Wakefield-Skorniewska,Francesco Quinzan,Bartłomiej Papież*

Main category: cs.LG

TL;DR: 研究发现，在预训练模型微调中，子群性能对数据平衡的敏感性取决于预训练模型潜在空间中子群的分离程度，而非简单的数据平衡假设。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设平衡子群表示能优化模型性能，但近期实证结果显示这一假设并不总是成立。有时不平衡的数据分布反而能改善子群性能，有时即使训练数据中完全缺失某个子群，其性能也不受影响。这种矛盾现象需要系统性研究。

Method: 对四个视觉和语言模型进行系统性研究，通过改变训练数据组成来表征子群性能对数据平衡的敏感性。提出"潜在分离假说"，即部分微调模型对子群表示的依赖程度由预训练模型潜在空间中子群的分离程度决定。对该假说进行形式化、理论分析，并通过实证验证。

Result: 研究验证了潜在分离假说，发现子群性能对数据平衡的敏感性确实与预训练模型潜在空间中子群的分离程度相关。当子群在潜在空间中高度分离时，数据平衡对性能影响显著；当分离程度较低时，不平衡数据分布甚至可能改善性能。

Conclusion: 传统的数据平衡假设过于简化。通过定量分析潜在子群分离程度，可以为基础模型微调中的数据收集和平衡决策提供信息，实现更有效的模型优化策略。

Abstract: Unequal representation of demographic groups in training data poses challenges to model generalisation across populations. Standard practice assumes that balancing subgroup representation optimises performance. However, recent empirical results contradict this assumption: in some cases, imbalanced data distributions actually improve subgroup performance, while in others, subgroup performance remains unaffected by the absence of an entire subgroup during training. We conduct a systematic study of subgroup allocation across four vision and language models, varying training data composition to characterise the sensitivity of subgroup performance to data balance. We propose the latent separation hypothesis, which states that a partially fine-tuned model's dependence on subgroup representation is determined by the degree of separation between subgroups in the latent space of the pre-trained model. We formalise this hypothesis, provide theoretical analysis, and validate it empirically. Finally, we present a practical application to foundation model fine-tuning, demonstrating that quantitative analysis of latent subgroup separation can inform data collection and balancing decisions.

</details>


### [87] [A Granular Framework for Construction Material Price Forecasting: Econometric and Machine-Learning Approaches](https://arxiv.org/abs/2512.09360)
*Boge Lyu,Qianye Yin,Iris Denise Tommelein,Hanyang Liu,Karnamohit Ranka,Karthik Yeluripati,Junzhe Shi*

Main category: cs.LG

TL;DR: 本研究开发了一个基于CSI MasterFormat的建筑材料价格预测框架，通过整合原材料价格、商品指数和宏观经济指标等解释变量，显著提升了预测精度。LSTM模型表现最佳，相比传统ARIMA模型精度提升达59%。


<details>
  <summary>Details</summary>
Motivation: 建筑材料价格的持续波动对成本估算、预算编制和项目交付构成重大风险，迫切需要开发细粒度、可扩展的预测方法。

Method: 采用CSI MasterFormat作为目标数据结构，在六位数章节级别进行预测。整合原材料价格、商品指数和宏观经济指标等解释变量。评估了LSTM、ARIMA、VECM和Chronos-Bolt四种时间序列模型，分别在仅使用CSI数据的基准配置和包含解释变量的扩展版本中进行测试。

Result: 纳入解释变量显著提高了所有模型的预测性能。LSTM模型表现最佳，RMSE值低至1.390，MAPE值为0.957，相比传统ARIMA模型精度提升达59%。验证了框架在多个CSI分区的可扩展性，并以第06分区（木材、塑料和复合材料）作为详细演示案例。

Conclusion: 本研究提供了一个稳健的方法论，使业主和承包商能够在确定性水平上改进预算实践并实现更可靠的成本估算。

Abstract: The persistent volatility of construction material prices poses significant risks to cost estimation, budgeting, and project delivery, underscoring the urgent need for granular and scalable forecasting methods. This study develops a forecasting framework that leverages the Construction Specifications Institute (CSI) MasterFormat as the target data structure, enabling predictions at the six-digit section level and supporting detailed cost projections across a wide spectrum of building materials. To enhance predictive accuracy, the framework integrates explanatory variables such as raw material prices, commodity indexes, and macroeconomic indicators. Four time-series models, Long Short-Term Memory (LSTM), Autoregressive Integrated Moving Average (ARIMA), Vector Error Correction Model (VECM), and Chronos-Bolt, were evaluated under both baseline configurations (using CSI data only) and extended versions with explanatory variables. Results demonstrate that incorporating explanatory variables significantly improves predictive performance across all models. Among the tested approaches, the LSTM model consistently achieved the highest accuracy, with RMSE values as low as 1.390 and MAPE values of 0.957, representing improvements of up to 59\% over the traditional statistical time-series model, ARIMA. Validation across multiple CSI divisions confirmed the framework's scalability, while Division 06 (Wood, Plastics, and Composites) is presented in detail as a demonstration case. This research offers a robust methodology that enables owners and contractors to improve budgeting practices and achieve more reliable cost estimation at the Definitive level.

</details>


### [88] [Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models](https://arxiv.org/abs/2512.09591)
*Magnus Ruud Kjaer,Rahul Thapa,Gauri Ganjoo,Hyatt Moore,Poul Joergen Jennum,Brandon M. Westover,James Zou,Emmanuel Mignot,Bryan He,Andreas Brink-Kjaer*

Main category: cs.LG

TL;DR: 斯坦福睡眠基准是一个大规模多导睡眠图数据集，包含17,467条记录，超过163,000小时数据，涵盖13种临床疾病预测任务。研究系统评估了自监督表示学习方法在睡眠分期、呼吸暂停诊断、年龄估计及疾病死亡率预测等任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 多导睡眠图产生大量多模态临床数据，为自监督表示学习提供了机会，但睡眠基础模型发展面临两大障碍：缺乏共享数据集和基准测试，以及缺少对自监督学习方法在睡眠相关任务上的系统评估。

Method: 引入斯坦福睡眠基准数据集，包含17,467条多导睡眠图记录，涵盖13种临床疾病预测任务及经典睡眠相关任务。系统评估了多种自监督预训练方法在四个下游任务上的表现：睡眠分期、呼吸暂停诊断、年龄估计、疾病和死亡率预测。

Result: 多种预训练方法在睡眠分期、呼吸暂停诊断和年龄估计任务上表现相当。但在死亡率和疾病预测任务中，对比学习方法显著优于其他方法，且在预训练期间收敛更快。

Conclusion: 斯坦福睡眠基准填补了睡眠研究领域的数据集和评估空白，对比学习在疾病预测任务中表现突出。研究将发布数据集、预训练模型权重、训练流程和评估代码以促进可重复性和睡眠研究进展。

Abstract: Polysomnography (PSG), the gold standard test for sleep analysis, generates vast amounts of multimodal clinical data, presenting an opportunity to leverage self-supervised representation learning (SSRL) for pre-training foundation models to enhance sleep analysis. However, progress in sleep foundation models is hindered by two key limitations: (1) the lack of a shared dataset and benchmark with diverse tasks for training and evaluation, and (2) the absence of a systematic evaluation of SSRL approaches across sleep-related tasks. To address these gaps, we introduce Stanford Sleep Bench, a large-scale PSG dataset comprising 17,467 recordings totaling over 163,000 hours from a major sleep clinic, including 13 clinical disease prediction tasks alongside canonical sleep-related tasks such as sleep staging, apnea diagnosis, and age estimation. We systematically evaluate SSRL pre-training methods on Stanford Sleep Bench, assessing downstream performance across four tasks: sleep staging, apnea diagnosis, age estimation, and disease and mortality prediction. Our results show that multiple pretraining methods achieve comparable performance for sleep staging, apnea diagnosis, and age estimation. However, for mortality and disease prediction, contrastive learning significantly outperforms other approaches while also converging faster during pretraining. To facilitate reproducibility and advance sleep research, we will release Stanford Sleep Bench along with pretrained model weights, training pipelines, and evaluation code.

</details>


### [89] [KGOT: Unified Knowledge Graph and Optimal Transport Pseudo-Labeling for Molecule-Protein Interaction Prediction](https://arxiv.org/abs/2512.09365)
*Jiayu Qin,Zhengquan Luo,Guy Tadmor,Changyou Chen,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 该论文提出了一种基于最优传输的生物信息融合框架，通过生成高质量伪标签来解决分子-蛋白质相互作用预测中的数据稀缺问题，显著提升了预测精度和零样本能力。


<details>
  <summary>Details</summary>
Motivation: 分子-蛋白质相互作用预测在药物发现和分子功能注释中至关重要，但现有方法面临两大挑战：1) 标记数据稀缺，现有数据集仅捕获了生物相关相互作用的一小部分；2) 大多数方法仅依赖分子和蛋白质特征，忽略了基因、代谢通路和功能注释等更广泛的生物上下文信息。

Method: 首先整合多样化的生物数据集（包括分子、蛋白质、基因和通路水平的相互作用），然后开发基于最优传输的方法为未标记的分子-蛋白质对生成高质量伪标签，利用已知相互作用的底层分布来指导标签分配。将伪标记视为连接不同生物模态的机制，有效利用异构数据增强MPI预测。

Result: 在多个MPI数据集（包括虚拟筛选任务和蛋白质检索任务）上的评估表明，该方法在预测准确性和对未见相互作用的零样本能力方面均显著优于现有最先进方法。

Conclusion: 该方法不仅提升了MPI预测性能，还为利用多样化生物数据源解决传统上受限于单模态或双模态学习的问题提供了新范式，为计算生物学和药物发现的未来发展铺平了道路。

Abstract: Predicting molecule-protein interactions (MPIs) is a fundamental task in computational biology, with crucial applications in drug discovery and molecular function annotation. However, existing MPI models face two major challenges. First, the scarcity of labeled molecule-protein pairs significantly limits model performance, as available datasets capture only a small fraction of biological relevant interactions. Second, most methods rely solely on molecular and protein features, ignoring broader biological context such as genes, metabolic pathways, and functional annotations that could provide essential complementary information. To address these limitations, our framework first aggregates diverse biological datasets, including molecular, protein, genes and pathway-level interactions, and then develop an optimal transport-based approach to generate high-quality pseudo-labels for unlabeled molecule-protein pairs, leveraging the underlying distribution of known interactions to guide label assignment. By treating pseudo-labeling as a mechanism for bridging disparate biological modalities, our approach enables the effective use of heterogeneous data to enhance MPI prediction. We evaluate our framework on multiple MPI datasets including virtual screening tasks and protein retrieval tasks, demonstrating substantial improvements over state-of-the-art methods in prediction accuracies and zero shot ability across unseen interactions. Beyond MPI prediction, our approach provides a new paradigm for leveraging diverse biological data sources to tackle problems traditionally constrained by single- or bi-modal learning, paving the way for future advances in computational biology and drug discovery.

</details>


### [90] [CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning](https://arxiv.org/abs/2512.09368)
*Mingyuan Li,Chunyu Liu,Zhuojun Li,Xiao Liu,Guangsheng Yu,Bo Du,Jun Shen,Qiang Wu*

Main category: cs.LG

TL;DR: CFLight是一个基于反事实学习的安全强化学习框架，用于交通信号控制，通过回溯替代行动来减少交叉口事故，在提升安全性的同时保持交通效率。


<details>
  <summary>Details</summary>
Motivation: 全球每年有数百万人在交通事故中伤亡，其中大量事故发生在交叉口。现有的强化学习方法在交通信号控制中往往优先考虑交通效率而忽视安全性，且缺乏可解释性。需要一种能平衡安全与效率、具有解释性的方法。

Method: 提出基于反事实学习的新框架，通过结构因果模型预测执行不同行动后的结果，引入反事实模块与额外的"X"模块集成，开发出CFLight算法。该算法采用近乎零碰撞控制策略，回溯不安全事件发生时的替代行动。

Result: 在真实世界和合成数据集上的实验表明，CFLight相比传统强化学习方法和近期安全强化学习模型，显著减少了碰撞事故，同时提升了整体交通性能。

Conclusion: CFLight为强化学习方法提供了一个通用且安全的框架，能有效处理具有挑战性的安全事件，显著提升交叉口安全性，并具有扩展到其他领域的潜力。

Abstract: Traffic accidents result in millions of injuries and fatalities globally, with a significant number occurring at intersections each year. Traffic Signal Control (TSC) is an effective strategy for enhancing safety at these urban junctures. Despite the growing popularity of Reinforcement Learning (RL) methods in optimizing TSC, these methods often prioritize driving efficiency over safety, thus failing to address the critical balance between these two aspects. Additionally, these methods usually need more interpretability. CounterFactual (CF) learning is a promising approach for various causal analysis fields. In this study, we introduce a novel framework to improve RL for safety aspects in TSC. This framework introduces a novel method based on CF learning to address the question: ``What if, when an unsafe event occurs, we backtrack to perform alternative actions, and will this unsafe event still occur in the subsequent period?'' To answer this question, we propose a new structure causal model to predict the result after executing different actions, and we propose a new CF module that integrates with additional ``X'' modules to promote safe RL practices. Our new algorithm, CFLight, which is derived from this framework, effectively tackles challenging safety events and significantly improves safety at intersections through a near-zero collision control strategy. Through extensive numerical experiments on both real-world and synthetic datasets, we demonstrate that CFLight reduces collisions and improves overall traffic performance compared to conventional RL methods and the recent safe RL model. Moreover, our method represents a generalized and safe framework for RL methods, opening possibilities for applications in other domains. The data and code are available in the github https://github.com/MJLee00/CFLight-Enhancing-Safety-with-Traffic-Signal-Control-through-Counterfactual-Learning.

</details>


### [91] [Circuits, Features, and Heuristics in Molecular Transformers](https://arxiv.org/abs/2512.09757)
*Kristof Varadi,Mark Marosi,Peter Antal*

Main category: cs.LG

TL;DR: 该论文对训练在药物类小分子上的自回归Transformer进行机制分析，揭示了模型在不同抽象层次捕捉分子表示规则的计算结构，并发现这些机制性见解能提升下游任务的预测性能。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer能够生成有效且多样化的化学结构，但模型捕捉分子表示规则的具体机制尚不清楚。研究者希望揭示这些模型在不同抽象层次上的计算结构，理解它们如何编码化学有效性约束。

Method: 使用稀疏自编码器（SAEs）提取与化学相关激活模式相关的特征词典，对训练在药物类小分子上的自回归Transformer进行机制分析，识别从低层语法解析到高层化学有效性约束的计算模式。

Result: 发现了与低层语法解析和更抽象的化学有效性约束一致的计算模式，通过SAEs成功提取了与化学相关激活模式相关的特征词典，并在下游任务中验证了这些发现。

Conclusion: 机制性分析揭示了Transformer捕捉分子表示规则的计算结构，这些见解不仅有助于理解模型工作原理，还能转化为各种实际场景中的预测性能提升。

Abstract: Transformers generate valid and diverse chemical structures, but little is known about the mechanisms that enable these models to capture the rules of molecular representation. We present a mechanistic analysis of autoregressive transformers trained on drug-like small molecules to reveal the computational structure underlying their capabilities across multiple levels of abstraction. We identify computational patterns consistent with low-level syntactic parsing and more abstract chemical validity constraints. Using sparse autoencoders (SAEs), we extract feature dictionaries associated with chemically relevant activation patterns. We validate our findings on downstream tasks and find that mechanistic insights can translate to predictive performance in various practical settings.

</details>


### [92] [Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs](https://arxiv.org/abs/2512.09369)
*Yezi Liu,William Youngwoo Chung,Hanning Chen,Calvin Yeung,Mohsen Imani*

Main category: cs.LG

TL;DR: PathHD：基于超维度计算的轻量级知识图谱推理框架，用单次LLM调用替代神经路径评分，实现高效、可解释的KG-LLM推理


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的LLM推理方法依赖重型神经编码器或重复LLM调用，导致高延迟、高GPU成本和不透明决策，阻碍了忠实、可扩展的部署

Method: 提出PathHD框架：1）使用超维度计算将关系路径编码为块对角GHRR超向量；2）通过块状余弦相似度和Top-K剪枝对候选进行排序；3）执行一次性LLM裁决生成最终答案并引用支持路径

Result: 在WebQSP、CWQ和GrailQA数据集上：1）每次查询仅用一次LLM调用即达到或超过强神经基线的Hits@1；2）端到端延迟降低40-60%，GPU内存减少3-5倍；3）提供忠实、基于路径的推理依据，改善错误诊断和可控性

Conclusion: 精心设计的HDC表示为高效KG-LLM推理提供了实用基础，在准确性、效率和可解释性之间实现了有利的权衡

Abstract: Recent advances in large language models (LLMs) have enabled strong reasoning over both structured and unstructured knowledge. When grounded on knowledge graphs (KGs), however, prevailing pipelines rely on heavy neural encoders to embed and score symbolic paths or on repeated LLM calls to rank candidates, leading to high latency, GPU cost, and opaque decisions that hinder faithful, scalable deployment. We propose PathHD, a lightweight and encoder-free KG reasoning framework that replaces neural path scoring with hyperdimensional computing (HDC) and uses only a single LLM call per query. PathHD encodes relation paths into block-diagonal GHRR hypervectors, ranks candidates with blockwise cosine similarity and Top-K pruning, and then performs a one-shot LLM adjudication to produce the final answer together with cited supporting paths. Technically, PathHD is built on three ingredients: (i) an order-aware, non-commutative binding operator for path composition, (ii) a calibrated similarity for robust hypervector-based retrieval, and (iii) a one-shot adjudication step that preserves interpretability while eliminating per-path LLM scoring. On WebQSP, CWQ, and the GrailQA split, PathHD (i) attains comparable or better Hits@1 than strong neural baselines while using one LLM call per query; (ii) reduces end-to-end latency by $40-60\%$ and GPU memory by $3-5\times$ thanks to encoder-free retrieval; and (iii) delivers faithful, path-grounded rationales that improve error diagnosis and controllability. These results indicate that carefully designed HDC representations provide a practical substrate for efficient KG-LLM reasoning, offering a favorable accuracy-efficiency-interpretability trade-off.

</details>


### [93] [Provably Learning from Modern Language Models via Low Logit Rank](https://arxiv.org/abs/2512.09892)
*Noah Golowich,Allen Liu,Abhishek Shetty*

Main category: cs.LG

TL;DR: 本文提出了一种基于低对数秩假设的高效算法，用于从查询中学习近似低对数秩模型，为现代语言模型提供了首个端到端学习保证。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型虽然复杂，但经验观察表明它们都具有近似低对数秩特性。这种结构可能被算法利用来获得可证明的学习保证，但低对数秩模型也能编码难以学习的分布（如噪声奇偶性），因此需要研究在查询学习模型下的算法。

Method: 采用查询学习模型，通过对数查询来反映常见API的访问模式。开发了一种高效算法，能够从查询中学习任何近似低对数秩模型。

Result: 主要结果是获得了从查询中学习近似低对数秩模型的高效算法。该结构假设密切反映了现代语言模型的经验观察行为。

Conclusion: 本文结果为生成模型提供了首个端到端学习保证，该模型合理捕捉了现代语言模型的特征。低对数秩假设为理解语言模型提供了简单且可能可处理的抽象。

Abstract: While modern language models and their inner workings are incredibly complex, recent work (Golowich, Liu & Shetty; 2025) has proposed a simple and potentially tractable abstraction for them through the observation that empirically, these language models all seem to have approximately low logit rank. Roughly, this means that a matrix formed by the model's log probabilities of various tokens conditioned on certain sequences of tokens is well approximated by a low rank matrix.
  In this paper, our focus is on understanding how this structure can be exploited algorithmically for obtaining provable learning guarantees. Since low logit rank models can encode hard-to-learn distributions such as noisy parities, we study a query learning model with logit queries that reflects the access model for common APIs. Our main result is an efficient algorithm for learning any approximately low logit rank model from queries. We emphasize that our structural assumption closely reflects the behavior that is empirically observed in modern language models. Thus, our result gives what we believe is the first end-to-end learning guarantee for a generative model that plausibly captures modern language models.

</details>


### [94] [Rates and architectures for learning geometrically non-trivial operators](https://arxiv.org/abs/2512.09376)
*T. Mitchell Roddenberry,Leo Tzou,Ivan Dokmanić,Maarten V. de Hoop,Richard G. Baraniuk*

Main category: cs.LG

TL;DR: 该论文扩展了科学机器学习的学习理论，将双纤维变换（包括广义Radon变换和测地线射线变换）纳入研究范围，证明了这类算子不受维度诅咒影响，误差随训练样本数量呈超代数衰减。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习理论主要针对几何简单的椭圆算子，但科学机器学习常涉及奇异性传播问题（如波动、对流、流体动力学）。需要扩展理论以涵盖包含奇异性传播的几何积分算子。

Method: 将学习理论扩展到双纤维变换这类几何积分算子；提出基于水平集方法的交叉注意力架构，显式编码变换的几何结构；证明该架构具有普适性、稳定性，并能从少量训练样本中学习双纤维变换。

Result: 证明了双纤维变换类算子不受维度诅咒影响，误差随训练样本数量呈超代数衰减（快于任何固定幂次的倒数）；提出的架构能够从极少训练样本中有效学习这类算子。

Conclusion: 该研究扩展了科学机器学习算子学习的理论框架，为处理包含奇异性传播的问题提供了理论基础和有效架构，推动了科学机器学习理论的发展。

Abstract: Deep learning methods have proven capable of recovering operators between high-dimensional spaces, such as solution maps of PDEs and similar objects in mathematical physics, from very few training samples. This phenomenon of data-efficiency has been proven for certain classes of elliptic operators with simple geometry, i.e., operators that do not change the domain of the function or propagate singularities. However, scientific machine learning is commonly used for problems that do involve the propagation of singularities in a priori unknown ways, such as waves, advection, and fluid dynamics. In light of this, we expand the learning theory to include double fibration transforms--geometric integral operators that include generalized Radon and geodesic ray transforms. We prove that this class of operators does not suffer from the curse of dimensionality: the error decays superalgebraically, that is, faster than any fixed power of the reciprocal of the number of training samples. Furthermore, we investigate architectures that explicitly encode the geometry of these transforms, demonstrating that an architecture reminiscent of cross-attention based on levelset methods yields a parameterization that is universal, stable, and learns double fibration transforms from very few training examples. Our results contribute to a rapidly-growing line of theoretical work on learning operators for scientific machine learning.

</details>


### [95] [Federated Distillation Assisted Vehicle Edge Caching Scheme Based on Lightweight DDPM](https://arxiv.org/abs/2512.09378)
*Xun Li,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 提出基于轻量去噪扩散概率模型和联邦蒸馏的车辆边缘缓存方案，解决传统联邦学习的通信开销大和车辆移动导致的训练失败问题


<details>
  <summary>Details</summary>
Motivation: 车辆边缘缓存能降低用户访问内容的延迟，但需要准确预测用户感兴趣内容同时保护隐私。传统联邦学习虽然能保护隐私，但存在通信开销大和车辆移动导致训练失败的问题

Method: 提出联邦蒸馏辅助的车辆边缘缓存方案，基于轻量去噪扩散概率模型，通过知识蒸馏减少模型传输，降低通信开销

Result: 仿真结果表明，该方案对车辆速度变化具有良好鲁棒性，显著降低通信开销并提高缓存命中率

Conclusion: 提出的基于LDPM的联邦蒸馏方案有效解决了传统联邦学习在车辆边缘缓存中的通信开销和训练失败问题，提高了系统性能

Abstract: Vehicle edge caching is a promising technology that can significantly reduce the latency for vehicle users (VUs) to access content by pre-caching user-interested content at edge nodes. It is crucial to accurately predict the content that VUs are interested in without exposing their privacy. Traditional federated learning (FL) can protect user privacy by sharing models rather than raw data. However, the training of FL requires frequent model transmission, which can result in significant communication overhead. Additionally, vehicles may leave the road side unit (RSU) coverage area before training is completed, leading to training failures. To address these issues, in this letter, we propose a federated distillation-assisted vehicle edge caching scheme based on lightweight denoising diffusion probabilistic model (LDPM). The simulation results demonstrate that the proposed vehicle edge caching scheme has good robustness to variations in vehicle speed, significantly reducing communication overhead and improving cache hit percentage.

</details>


### [96] [FALCON: Few-step Accurate Likelihoods for Continuous Flows](https://arxiv.org/abs/2512.09914)
*Danyal Rehman,Tara Akhound-Sadegh,Artem Gazizov,Yoshua Bengio,Alexander Tong*

Main category: cs.LG

TL;DR: FALCON方法通过混合训练目标实现连续流的少步采样，在分子玻尔兹曼采样中优于现有归一化流模型，速度比同等性能的CNF模型快两个数量级。


<details>
  <summary>Details</summary>
Motivation: 热力学平衡中分子状态的可扩展采样是统计物理学的长期挑战。玻尔兹曼生成器通过结合生成模型和重要性采样来解决这个问题，但现有方法使用连续归一化流(CNFs)时，每个样本需要数千次函数评估，似然计算成本极高，严重限制了其应用。

Method: 提出FALCON方法，通过引入混合训练目标来鼓励可逆性，实现连续流的少步采样，同时保持足够准确的似然用于重要性采样应用。

Result: FALCON在分子玻尔兹曼采样方面优于最先进的归一化流模型，比同等性能的连续归一化流模型快两个数量级。

Conclusion: FALCON方法解决了连续归一化流在玻尔兹曼采样中计算成本过高的问题，通过少步采样实现了高效准确的分子状态采样。

Abstract: Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous Flows (FALCON), a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We show FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the equivalently performing CNF model.

</details>


### [97] [Cauchy-Schwarz Fairness Regularizer](https://arxiv.org/abs/2512.09467)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: 论文提出基于柯西-施瓦茨散度的公平性正则化器，通过惩罚敏感群体间预测分布的差异来提升群体公平性，相比现有方法具有更紧的泛化界、尺度鲁棒性和对任意预测分布的处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有公平性正则化器基于不同的距离度量和设计选择，导致其行为难以推理且在不同任务上性能不一致。需要探究什么特性构成一个好的公平性正则化器，并设计满足这些特性的新方法。

Method: 将现有方法分为三类：跨敏感群体匹配预测统计量、对齐潜在表示、直接最小化预测与敏感属性间的依赖性。基于理想距离度量的特性（紧泛化界、尺度鲁棒性、处理任意分布能力），提出柯西-施瓦茨公平性正则化器，惩罚敏感群体间预测分布的经验CS散度。

Result: 在四个表格基准和一个图像数据集上的实验表明，CS正则化器在保持竞争力的准确率的同时，持续改进人口统计均等和机会均等指标，并且相比先前正则化器在超参数设置下实现了更稳定的效用-公平性权衡。

Conclusion: 柯西-施瓦茨散度作为公平性正则化器的基础距离度量具有理论优势，包括更紧的泛化界和更好的实际性能，为构建更可靠、一致的公平机器学习方法提供了新方向。

Abstract: Group fairness in machine learning is often enforced by adding a regularizer that reduces the dependence between model predictions and sensitive attributes. However, existing regularizers are built on heterogeneous distance measures and design choices, which makes their behavior hard to reason about and their performance inconsistent across tasks. This raises a basic question: what properties make a good fairness regularizer? We address this question by first organizing existing in-process methods into three families: (i) matching prediction statistics across sensitive groups, (ii) aligning latent representations, and (iii) directly minimizing dependence between predictions and sensitive attributes. Through this lens, we identify desirable properties of the underlying distance measure, including tight generalization bounds, robustness to scale differences, and the ability to handle arbitrary prediction distributions. Motivated by these properties, we propose a Cauchy-Schwarz (CS) fairness regularizer that penalizes the empirical CS divergence between prediction distributions conditioned on sensitive groups. Under a Gaussian comparison, we show that CS divergence yields a tighter bound than Kullback-Leibler divergence, Maximum Mean Discrepancy, and the mean disparity used in Demographic Parity, and we discuss how these advantages translate to a distribution-free, kernel-based estimator that naturally extends to multiple sensitive attributes. Extensive experiments on four tabular benchmarks and one image dataset demonstrate that the proposed CS regularizer consistently improves Demographic Parity and Equal Opportunity metrics while maintaining competitive accuracy, and achieves a more stable utility-fairness trade-off across hyperparameter settings compared to prior regularizers.

</details>


### [98] [Contextual Dynamic Pricing with Heterogeneous Buyers](https://arxiv.org/abs/2512.09513)
*Thodoris Lykouris,Sloan Nietert,Princewill Okoroafor,Chara Podimata,Julian Zimmert*

Main category: cs.LG

TL;DR: 论文研究了具有异质买家群体的情境动态定价问题，提出了基于乐观后验采样的算法，获得了$\widetilde{O}(K_{\star}\sqrt{dT})$的遗憾界，并证明其在$d$和$T$维度上达到最优。


<details>
  <summary>Details</summary>
Motivation: 现有动态定价研究大多假设买家类型同质，而实际市场中买家估值类型存在异质性。本文旨在解决具有未知有限支持大小$K_{\star}$的异质买家群体的情境动态定价问题。

Method: 提出基于乐观后验采样的情境定价算法，通过观测$d$维情境信息并接收二元购买反馈，在$T$轮中重复定价。针对非情境定价情况，进一步提出了方差感知的缩放算法。

Result: 情境定价算法获得了$\widetilde{O}(K_{\star}\sqrt{dT})$的遗憾界，证明在$d$和$T$维度上达到最优（忽略对数项）。非情境定价的方差感知缩放算法在$K_{\star}$依赖上达到最优。

Conclusion: 本文首次系统研究了异质买家群体的情境动态定价问题，提出的算法在多个维度上达到理论最优，为实际市场中的个性化定价提供了理论基础。

Abstract: We initiate the study of contextual dynamic pricing with a heterogeneous population of buyers, where a seller repeatedly posts prices (over $T$ rounds) that depend on the observable $d$-dimensional context and receives binary purchase feedback. Unlike prior work assuming homogeneous buyer types, in our setting the buyer's valuation type is drawn from an unknown distribution with finite support size $K_{\star}$. We develop a contextual pricing algorithm based on optimistic posterior sampling with regret $\widetilde{O}(K_{\star}\sqrt{dT})$, which we prove to be tight in $d$ and $T$ up to logarithmic terms. Finally, we refine our analysis for the non-contextual pricing case, proposing a variance-aware zooming algorithm that achieves the optimal dependence on $K_{\star}$.

</details>


### [99] [QuanvNeXt: An end-to-end quanvolutional neural network for EEG-based detection of major depressive disorder](https://arxiv.org/abs/2512.09517)
*Nabil Anan Orka,Ehtashamul Haque,Maftahul Jannat,Md Abdul Awal,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: QuanvNeXt是一个用于基于EEG的抑郁症诊断的端到端全量子卷积模型，通过创新的交叉残差块减少特征同质性并增强跨特征关系，在两个公开数据集上取得了93.1%的平均准确率和97.2%的平均AUC-ROC，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效可靠的基于脑电图（EEG）的抑郁症诊断模型，解决现有方法中特征同质性问题和跨特征关系不足的挑战，同时保持参数效率。

Method: 提出QuanvNeXt模型，采用端到端全量子卷积架构，引入创新的交叉残差块来减少特征同质性并增强跨特征关系，同时保持参数效率。模型在两个公开EEG数据集上进行评估，并进行不确定性分析和可解释AI分析。

Result: 在两个公开数据集上平均准确率达到93.1%，平均AUC-ROC达到97.2%，优于InceptionTime等现有基线方法（91.7%准确率，95.9% AUC-ROC）。不确定性分析显示即使在最高扰动水平（ε=0.1）下，ECE分数仍保持较低水平。可解释AI分析确认模型能有效识别和学习区分健康对照和重度抑郁症的频谱时间模式。

Conclusion: QuanvNeXt为基于EEG的抑郁症诊断建立了一种高效可靠的方法，通过创新的交叉残差块设计解决了特征同质性问题，在准确性和鲁棒性方面均表现出色，具有临床应用潜力。

Abstract: This study presents QuanvNeXt, an end-to-end fully quanvolutional model for EEG-based depression diagnosis. QuanvNeXt incorporates a novel Cross Residual block, which reduces feature homogeneity and strengthens cross-feature relationships while retaining parameter efficiency. We evaluated QuanvNeXt on two open-source datasets, where it achieved an average accuracy of 93.1% and an average AUC-ROC of 97.2%, outperforming state-of-the-art baselines such as InceptionTime (91.7% accuracy, 95.9% AUC-ROC). An uncertainty analysis across Gaussian noise levels demonstrated well-calibrated predictions, with ECE scores remaining low (0.0436, Dataset 1) to moderate (0.1159, Dataset 2) even at the highest perturbation (ε = 0.1). Additionally, a post-hoc explainable AI analysis confirmed that QuanvNeXt effectively identifies and learns spectrotemporal patterns that distinguish between healthy controls and major depressive disorder. Overall, QuanvNeXt establishes an efficient and reliable approach for EEG-based depression diagnosis.

</details>


### [100] [Latent-Autoregressive GP-VAE Language Model](https://arxiv.org/abs/2512.09535)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 提出了一种基于高斯过程的完全潜在自回归方案，将其集成到变分自编码器中，将序列动态从观测空间转移到连续潜在空间，同时通过非自回归解码器保持语言生成的并行性。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型中时间结构是否可以通过潜在空间的概率几何来支持，而不是完全依赖于显式的神经操作，旨在将序列动态与语言生成解耦。

Method: 采用高斯过程作为因果先验，构建结构化摊销后验，基于正则化ELBO的训练协议，在变分自编码器框架中实现完全潜在自回归。

Result: 在概念验证框架中，模型能够稳定训练，序列和并行采样变体表现出一致行为，表明部分时间结构确实可以通过潜在空间的概率几何来支持。

Conclusion: 语言模型中的部分时间结构可以由潜在空间的概率几何支持，而非完全依赖显式神经操作，这为序列建模提供了新的视角。

Abstract: We investigate a fully Latent AutoRegressive scheme based on a Gaussian Process (GP) integrated into a Variational Autoencoder (VAE). In this setting, sequential dynamics are transferred from the observation space to a continuous latent space, while linguistic generation remains parallel through a non-autoregressive decoder. We present a complete methodological formulation, including a causal GP prior, a structured amortized posterior, and a training protocol based on a regularized ELBO. Empirical evaluation, conducted within a deliberately constrained proof-of-concept (POC) framework, shows that the model can be trained stably and that the sequential and parallel sampling variants exhibit consistent behavior. Overall, the results suggest that part of the temporal structure in a language model can be supported by the probabilistic geometry of the latent space rather than by explicit neural operations.

</details>


### [101] [Semantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks](https://arxiv.org/abs/2512.09621)
*Jingbo Zhang,Maoxin Ji,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于三方协作语义通信（TCSC）的车联网边缘计算框架，通过V2I和V2V通信实现语义任务卸载，使用MAPPO-PDN算法优化语义符号数量，LP优化卸载比例，在高速公路场景中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 车联网边缘计算结合语义通信为车辆任务处理提供了高效范式，但现有方法在高速公路场景下的任务卸载效率和语义符号优化方面仍有改进空间，需要更有效的协作框架和优化算法。

Method: 提出三方协作语义通信框架，将MINLP问题分解为两个子问题：1）使用基于参数分布噪声的多智能体近端策略优化算法优化语义符号数量；2）使用线性规划优化任务卸载比例。

Result: 仿真结果表明，该方案在任务延迟和语义符号数量优化方面优于其他对比算法，显著提升了车联网边缘计算系统的性能。

Conclusion: TCSC框架结合MAPPO-PDN和LP算法有效解决了车联网语义通信中的任务卸载优化问题，为高速公路场景下的车联网边缘计算提供了高效解决方案。

Abstract: Semantic Communication (SC) combined with Vehicular edge computing (VEC) provides an efficient edge task processing paradigm for Internet of Vehicles (IoV). Focusing on highway scenarios, this paper proposes a Tripartite Cooperative Semantic Communication (TCSC) framework, which enables Vehicle Users (VUs) to perform semantic task offloading via Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) communications. Considering task latency and the number of semantic symbols, the framework constructs a Mixed-Integer Nonlinear Programming (MINLP) problem, which is transformed into two subproblems. First, we innovatively propose a multi-agent proximal policy optimization task offloading optimization method based on parametric distribution noise (MAPPO-PDN) to solve the optimization problem of the number of semantic symbols; second, linear programming (LP) is used to solve offloading ratio. Simulations show that performance of this scheme is superior to that of other algorithms.

</details>


### [102] [Membership and Dataset Inference Attacks on Large Audio Generative Models](https://arxiv.org/abs/2512.09654)
*Jakub Proboszcz,Paweł Kochanski,Karol Korszun,Donato Crisostomi,Giorgio Strano,Emanuele Rodolà,Kamil Deja,Jan Dubinski*

Main category: cs.LG

TL;DR: 该研究探讨了在生成式音频模型中验证艺术家作品是否被用于训练的可能性，发现单独使用成员推理攻击效果有限，但数据集推理方法通过聚合多个样本的证据，能有效检测艺术家作品是否被用于模型训练。


<details>
  <summary>Details</summary>
Motivation: 随着生成式音频模型（基于扩散和自回归架构）在质量和表现力方面的快速发展，引发了严重的版权问题。这些模型通常使用大量艺术和商业作品进行训练，因此需要可靠的方法来验证艺术家的材料是否被包含在训练数据中，为版权持有者提供保护内容的手段。

Method: 研究通过成员推理攻击（MIA）来验证特定音频样本是否属于训练集，但发现单独使用MIA在大规模数据集上效果有限。随后借鉴文本和视觉领域的研究，采用数据集推理（DI）方法，该方法通过聚合多个样本的成员证据来增强检测能力。

Result: 实证结果显示：1）单独使用成员推理攻击在大型多样化数据集上效果有限，因为每个样本的成员信号较弱；2）数据集推理方法在音频领域表现成功，能够有效评估艺术家的作品是否对模型训练有贡献，为版权保护提供了更实用的机制。

Conclusion: 数据集推理是音频生成模型时代版权保护和数据集问责制的有前景方向，为艺术家和媒体所有者提供了一种实用的验证机制，能够检测其作品集合是否被用于模型训练。

Abstract: Generative audio models, based on diffusion and autoregressive architectures, have advanced rapidly in both quality and expressiveness. This progress, however, raises pressing copyright concerns, as such models are often trained on vast corpora of artistic and commercial works. A central question is whether one can reliably verify if an artist's material was included in training, thereby providing a means for copyright holders to protect their content. In this work, we investigate the feasibility of such verification through membership inference attacks (MIA) on open-source generative audio models, which attempt to determine whether a specific audio sample was part of the training set. Our empirical results show that membership inference alone is of limited effectiveness at scale, as the per-sample membership signal is weak for models trained on large and diverse datasets. However, artists and media owners typically hold collections of works rather than isolated samples. Building on prior work in text and vision domains, in this work we focus on dataset inference (DI), which aggregates diverse membership evidence across multiple samples. We find that DI is successful in the audio domain, offering a more practical mechanism for assessing whether an artist's works contributed to model training. Our results suggest DI as a promising direction for copyright protection and dataset accountability in the era of large audio generative models.

</details>


### [103] [A data-driven approach to linking design features with manufacturing process data for sustainable product development](https://arxiv.org/abs/2512.09690)
*Jiahang Li,Lucas Cazzonelli,Jacqueline Höllig,Markus Doellken,Sven Matthiesen*

Main category: cs.LG

TL;DR: 本文提出了一种数据驱动方法，用于映射和分析设计特征与制造过程数据之间的关系，通过机器学习模型实现自动化设计改进建议，促进可持续产品开发。


<details>
  <summary>Details</summary>
Motivation: 工业物联网技术在制造业的广泛应用实现了制造过程数据的自动化实时采集，为数据驱动的产品开发提供了新机遇。然而，当前的数据驱动方法通常局限于特定领域（如设计或制造），缺乏对设计特征与制造过程数据整合的探索。由于设计决策显著影响制造结果（如错误率、能耗和处理时间），这种整合的缺失限制了数据驱动产品设计改进的潜力。

Method: 本文提出了一种数据驱动方法来映射和分析设计特征与制造过程数据之间的关系。开发了一个全面的系统架构，确保数据的持续收集和整合。基于设计特征与制造过程数据之间的关联，开发了机器学习模型，实现自动化设计改进建议。该方法还将制造过程数据与可持续性指标相结合。

Result: 该方法建立了设计特征与制造过程数据之间的映射关系，为自动化设计改进提供了基础。通过整合可持续性指标，为可持续产品开发开辟了新的可能性。

Conclusion: 本文提出的数据驱动方法成功整合了设计特征与制造过程数据，通过机器学习模型实现了自动化设计改进建议。该方法不仅提升了产品设计的效率和质量，还为可持续产品开发提供了新的技术途径，具有重要的工业应用价值。

Abstract: The growing adoption of Industrial Internet of Things (IIoT) technologies enables automated, real-time collection of manufacturing process data, unlocking new opportunities for data-driven product development. Current data-driven methods are generally applied within specific domains, such as design or manufacturing, with limited exploration of integrating design features and manufacturing process data. Since design decisions significantly affect manufacturing outcomes, such as error rates, energy consumption, and processing times, the lack of such integration restricts the potential for data-driven product design improvements. This paper presents a data-driven approach to mapping and analyzing the relationship between design features and manufacturing process data. A comprehensive system architecture is developed to ensure continuous data collection and integration. The linkage between design features and manufacturing process data serves as the basis for developing a machine learning model that enables automated design improvement suggestions. By integrating manufacturing process data with sustainability metrics, this approach opens new possibilities for sustainable product development.

</details>


### [104] [Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning](https://arxiv.org/abs/2512.09706)
*Kaichen He,Zihao Wang,Muyao Li,Anji Liu,Yitao Liang*

Main category: cs.LG

TL;DR: CrossAgent是一个统一智能体模型，能够掌握异构动作空间并自主选择每个步骤的最有效交互接口，在Minecraft环境中实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通常局限于静态预定义的动作空间（如API、GUI事件或机器人命令），这种刚性限制了它们在动态环境中的适应性，因为最优交互粒度会随上下文变化。

Method: 提出了一个综合训练流程，结合冷启动监督微调和多轮组相对策略优化（GRPO）算法，使智能体能够学习自适应动作切换，无需人工指定规则。

Result: 在开放世界Minecraft环境中的800多个任务上进行广泛实验，CrossAgent实现了最先进的性能，通过动态利用不同动作空间的优势，显著优于固定动作基线模型。

Conclusion: CrossAgent通过掌握异构动作空间和自主选择最优交互接口，展示了在长时程推理中优越的泛化能力和效率，为智能体在动态环境中的适应性提供了新范式。

Abstract: The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching--balancing high-level efficiency with low-level precision--without human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at https://github.com/CraftJarvis/OpenHA

</details>


### [105] [Mixture of Lookup Key-Value Experts](https://arxiv.org/abs/2512.09723)
*Zongcheng Wang*

Main category: cs.LG

TL;DR: MoLKV模型通过引入上下文感知的键值对专家机制，改进了MoLE仅基于输入ID选择专家的局限性，在小规模评估中显著降低了验证损失。


<details>
  <summary>Details</summary>
Motivation: MoLE（查找专家混合）模型虽然适合资源受限设备，但其仅基于输入ID的上下文无关专家选择机制可能限制模型性能。需要一种能考虑上下文信息的改进方案。

Method: 提出MoLKV（查找键值专家混合）模型，每个专家被构建为键值对。对于给定输入，从输入派生的查询与当前序列缓存的键值专家交互，生成上下文感知的专家输出。

Result: 实验结果表明，MoLKV在小规模评估中实现了显著更低的验证损失，证明上下文感知机制有效缓解了MoLE的局限性。

Conclusion: MoLKV通过上下文感知的键值对专家机制成功改进了MoLE模型，为资源受限设备上的LLM推理提供了更优的解决方案。

Abstract: Recent research has developed several LLM architectures suitable for inference on end-user devices, such as the Mixture of Lookup Experts (MoLE)~\parencite{jie_mixture_2025}. A key feature of MoLE is that each token id is associated with a dedicated group of experts. For a given input, only the experts corresponding to the input token id will be activated. Since the communication overhead of loading this small number of activated experts into RAM during inference is negligible, expert parameters can be offloaded to storage, making MoLE suitable for resource-constrained devices. However, MoLE's context-independent expert selection mechanism, based solely on input ids, may limit model performance. To address this, we propose the \textbf{M}ixture \textbf{o}f \textbf{L}ookup \textbf{K}ey-\textbf{V}alue Experts (\textbf{MoLKV}) model. In MoLKV, each expert is structured as a key-value pair. For a given input, the input-derived query interacts with the cached key-value experts from the current sequence, generating a context-aware expert output. This context-aware mechanism alleviates the limitation of MoLE, and experimental results demonstrate that MoLKV achieves significantly lower validation loss in small-scale evaluations.

</details>


### [106] [Knowledge Diversion for Efficient Morphology Control and Policy Transfer](https://arxiv.org/abs/2512.09796)
*Fu Feng,Ruixiao Shi,Yucheng Xie,Jianlu Shen,Jing Wang,Xin Geng*

Main category: cs.LG

TL;DR: DivMorph提出了一种模块化训练范式，通过知识分流学习可分解控制器，实现跨异构形态的通用控制，显著提升样本效率和减小模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer控制器计算成本高，部署开销大，且跨任务泛化能力有限，需要为每个新任务从头训练。

Method: 通过SVD将随机初始化的Transformer权重分解为因子单元，使用动态软门控基于任务和形态嵌入调制这些单元，分离为共享的learngenes和特定于形态/任务的tailors，实现知识解耦。

Result: 在跨任务迁移中比直接微调提升3倍样本效率，单智能体部署时模型规模减少17倍，达到最先进性能。

Conclusion: DivMorph通过模块化知识解耦实现了可扩展、高效的策略部署，支持向新任务的有效策略迁移。

Abstract: Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and existing methods exhibit limited cross-task generalization, necessitating training from scratch for each new task. To this end, we propose \textbf{DivMorph}, a modular training paradigm that leverages knowledge diversion to learn decomposable controllers. DivMorph factorizes randomly initialized Transformer weights into factor units via SVD prior to training and employs dynamic soft gating to modulate these units based on task and morphology embeddings, separating them into shared \textit{learngenes} and morphology- and task-specific \textit{tailors}, thereby achieving knowledge disentanglement. By selectively activating relevant components, DivMorph enables scalable and efficient policy deployment while supporting effective policy transfer to novel tasks. Extensive experiments demonstrate that DivMorph achieves state-of-the-art performance, achieving a 3$\times$ improvement in sample efficiency over direct finetuning for cross-task transfer and a 17$\times$ reduction in model size for single-agent deployment.

</details>


### [107] [Ariel-ML: Computing Parallelization with Embedded Rust for Neural Networks on Heterogeneous Multi-core Microcontrollers](https://arxiv.org/abs/2512.09800)
*Zhaolan Huang,Kaspar Schleiser,Gyungmin Myung,Emmanuel Baccelli*

Main category: cs.LG

TL;DR: Ariel-ML是一个用于多核MCU的Rust嵌入式TinyML平台，能够自动并行化推理计算，在保持内存占用与C/C++相当的同时显著降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 随着低功耗MCU从单核向多核架构演进，以及Rust在嵌入式领域的兴起，目前缺乏能够自动利用多核能力执行任意TinyML模型的Rust嵌入式软件平台。现有解决方案无法满足在已部署的传感/执行系统中持续通过ANN执行进行增量改进和创新服务的需求。

Method: 设计了Ariel-ML工具包，结合通用TinyML流水线和嵌入式Rust软件平台，能够充分利用多种32位微控制器家族（Arm Cortex-M、RISC-V、ESP-32）的多核能力。实现了完整的开源代码，并使用多种TinyML模型进行基准测试。

Result: Ariel-ML在推理延迟方面优于现有技术，同时与使用嵌入式C/C++的现有工具包相比，实现了相当的内存占用。为各种TinyML模型提供了有效的多核并行推理能力。

Conclusion: Ariel-ML填补了Rust嵌入式软件平台在多核MCU上自动并行化TinyML模型推理的空白，为TinyML从业者和资源受限的嵌入式Rust开发者提供了有用的基础。

Abstract: Low-power microcontroller (MCU) hardware is currently evolving from single-core architectures to predominantly multi-core architectures. In parallel, new embedded software building blocks are more and more written in Rust, while C/C++ dominance fades in this domain. On the other hand, small artificial neural networks (ANN) of various kinds are increasingly deployed in edge AI use cases, thus deployed and executed directly on low-power MCUs. In this context, both incremental improvements and novel innovative services will have to be continuously retrofitted using ANNs execution in software embedded on sensing/actuating systems already deployed in the field. However, there was so far no Rust embedded software platform automating parallelization for inference computation on multi-core MCUs executing arbitrary TinyML models. This paper thus fills this gap by introducing Ariel-ML, a novel toolkit we designed combining a generic TinyML pipeline and an embedded Rust software platform which can take full advantage of multi-core capabilities of various 32bit microcontroller families (Arm Cortex-M, RISC-V, ESP-32). We published the full open source code of its implementation, which we used to benchmark its capabilities using a zoo of various TinyML models. We show that Ariel-ML outperforms prior art in terms of inference latency as expected, and we show that, compared to pre-existing toolkits using embedded C/C++, Ariel-ML achieves comparable memory footprints. Ariel-ML thus provides a useful basis for TinyML practitioners and resource-constrained embedded Rust developers.

</details>


### [108] [Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering](https://arxiv.org/abs/2512.09810)
*Adithya K Moorthy,V Vijaya Saradhi,Bhanu Prasad*

Main category: cs.LG

TL;DR: 该研究提出了公平k近邻和公平ε邻域图构建方法，通过在图构建阶段主动实施人口统计平等约束，实现更公平的谱聚类结果。


<details>
  <summary>Details</summary>
Motivation: 传统图聚类方法在图构建过程中存在偏见，可能对某些群体代表性不足，导致不公平的聚类结果。现有研究缺乏在图构建预处理阶段考虑公平性的方法。

Method: 提出两种公平图构建方法：公平k近邻图和公平ε邻域图。通过在邻域选择步骤中融入公平约束，确保每个节点的邻域中敏感特征群体具有比例代表性，同时保持几何一致性。

Result: 在三个合成数据集、七个真实世界表格数据集和三个真实世界图像数据集上的实验证明，提出的公平图构建方法在聚类任务中超越了现有基线方法。

Conclusion: 图构建阶段的拓扑公平性对于实现公平聚类结果至关重要。通过在预处理阶段实施公平约束，可以在不改变聚类算法本身的情况下获得更公平的谱聚类结果，填补了公平无监督学习的重要空白。

Abstract: Graph clustering plays a pivotal role in unsupervised learning methods like spectral clustering, yet traditional methods for graph clustering often perpetuate bias through unfair graph constructions that may underrepresent some groups. The current research introduces novel approaches for constructing fair k-nearest neighbor (kNN) and fair epsilon-neighborhood graphs that proactively enforce demographic parity during graph formation. By incorporating fairness constraints at the earliest stage of neighborhood selection steps, our approaches incorporate proportional representation of sensitive features into the local graph structure while maintaining geometric consistency.Our work addresses a critical gap in pre-processing for fair spectral clustering, demonstrating that topological fairness in graph construction is essential for achieving equitable clustering outcomes. Widely used graph construction methods like kNN and epsilon-neighborhood graphs propagate edge based disparate impact on sensitive groups, leading to biased clustering results. Providing representation of each sensitive group in the neighborhood of every node leads to fairer spectral clustering results because the topological features of the graph naturally reflect equitable group ratios. This research fills an essential shortcoming in fair unsupervised learning, by illustrating how topological fairness in graph construction inherently facilitates fairer spectral clustering results without the need for changes to the clustering algorithm itself. Thorough experiments on three synthetic datasets, seven real-world tabular datasets, and three real-world image datasets prove that our fair graph construction methods surpass the current baselines in graph clustering tasks.

</details>


### [109] [Conformal Bandits: Bringing statistical validity and reward efficiency to the small-gap regime](https://arxiv.org/abs/2512.09850)
*Simone Cuonzo,Nina Deliu*

Main category: cs.LG

TL;DR: 将Conformal Prediction整合到bandit问题中，为顺序决策提供有限时间统计保证，在收益差距小的场景下优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统bandit策略如Thompson Sampling和UCB通常依赖分布假设或渐近保证，且主要关注遗憾最小化而忽视统计特性。本文旨在填补这一空白，将决策策略的遗憾最小化潜力与统计保证相结合。

Method: 提出Conformal Bandits框架，将Conformal Prediction整合到bandit问题中。在投资组合分配应用中，进一步整合隐马尔可夫模型来捕捉金融市场的制度转换行为。

Result: 在模拟研究和投资组合分配应用中展示了Conformal Bandits的潜力。在小差距场景下，该框架在遗憾方面具有实际优势，并在传统UCB策略失败的情况下实现了名义覆盖保证。整合隐马尔可夫模型增强了探索-利用权衡，转化为更高的风险调整回报，同时保持覆盖保证。

Conclusion: Conformal Bandits框架成功地将Conformal Prediction与bandit问题相结合，为顺序决策提供了有限时间统计保证，在收益差距小的场景下优于传统方法，并在实际应用中展示了优越性能。

Abstract: We introduce Conformal Bandits, a novel framework integrating Conformal Prediction (CP) into bandit problems, a classic paradigm for sequential decision-making under uncertainty. Traditional regret-minimisation bandit strategies like Thompson Sampling and Upper Confidence Bound (UCB) typically rely on distributional assumptions or asymptotic guarantees; further, they remain largely focused on regret, neglecting their statistical properties. We address this gap. Through the adoption of CP, we bridge the regret-minimising potential of a decision-making bandit policy with statistical guarantees in the form of finite-time prediction coverage.
  We demonstrate the potential of it Conformal Bandits through simulation studies and an application to portfolio allocation, a typical small-gap regime, where differences in arm rewards are far too small for classical policies to achieve optimal regret bounds in finite sample. Motivated by this, we showcase our framework's practical advantage in terms of regret in small-gap settings, as well as its added value in achieving nominal coverage guarantees where classical UCB policies fail. Focusing on our application of interest, we further illustrate how integrating hidden Markov models to capture the regime-switching behaviour of financial markets, enhances the exploration-exploitation trade-off, and translates into higher risk-adjusted regret efficiency returns, while preserving coverage guarantees.

</details>


### [110] [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886)
*Gustavo Coelho Haase,Paulo Henrique Dourado da Silva*

Main category: cs.LG

TL;DR: HPM-KD是一个知识蒸馏框架，通过六个协同组件解决了传统KD的四个关键限制：超参数敏感、容量差距、多教师协调不佳和计算资源低效。该框架实现了10-15倍压缩，保持85%准确率，无需手动调参，并通过并行化减少30-40%训练时间。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏技术存在四个关键限制：1）对超参数敏感，需要大量手动调优；2）从大型教师模型到小型学生模型存在容量差距；3）在多教师场景中协调不佳；4）计算资源使用效率低下。这些限制阻碍了知识蒸馏在实际应用中的广泛部署。

Method: HPM-KD框架集成了六个协同组件：1）基于元学习的自适应配置管理器，消除手动超参数调优；2）渐进蒸馏链，自动确定中间模型；3）注意力加权多教师集成，学习动态的每样本权重；4）元学习温度调度器，在整个训练过程中自适应调整温度；5）具有智能负载均衡的并行处理流水线；6）跨实验重用的共享优化内存。

Result: 在CIFAR-10、CIFAR-100和表格数据集上的实验表明，HPM-KD实现了10-15倍的模型压缩，同时保持85%的准确率保留。消除了手动调参需求，通过并行化减少了30-40%的训练时间。消融研究确认了每个组件的独立贡献（0.10-0.98个百分点）。

Conclusion: HPM-KD是一个有效的知识蒸馏框架，通过六个协同组件系统性地解决了传统KD的关键限制。该框架实现了高效的模型压缩，无需手动调参，显著减少了训练时间，并已作为开源DeepBridge库的一部分提供。

Abstract: Knowledge Distillation (KD) has emerged as a promising technique for model compression but faces critical limitations: (1) sensitivity to hyperparameters requiring extensive manual tuning, (2) capacity gap when distilling from very large teachers to small students, (3) suboptimal coordination in multi-teacher scenarios, and (4) inefficient use of computational resources. We present \textbf{HPM-KD}, a framework that integrates six synergistic components: (i) Adaptive Configuration Manager via meta-learning that eliminates manual hyperparameter tuning, (ii) Progressive Distillation Chain with automatically determined intermediate models, (iii) Attention-Weighted Multi-Teacher Ensemble that learns dynamic per-sample weights, (iv) Meta-Learned Temperature Scheduler that adapts temperature throughout training, (v) Parallel Processing Pipeline with intelligent load balancing, and (vi) Shared Optimization Memory for cross-experiment reuse. Experiments on CIFAR-10, CIFAR-100, and tabular datasets demonstrate that HPM-KD: achieves 10x-15x compression while maintaining 85% accuracy retention, eliminates the need for manual tuning, and reduces training time by 30-40% via parallelization. Ablation studies confirm independent contribution of each component (0.10-0.98 pp). HPM-KD is available as part of the open-source DeepBridge library.

</details>


### [111] [Closing the Train-Test Gap in World Models for Gradient-Based Planning](https://arxiv.org/abs/2512.09929)
*Arjun Parthasarathy,Nimit Kalra,Rohun Agrawal,Yann LeCun,Oumayma Bounou,Pavel Izmailov,Micah Goldblum*

Main category: cs.LG

TL;DR: 提出改进世界模型训练方法，通过缩小训练-测试差距，使基于梯度的规划性能在10%时间预算下达到或超过传统CEM方法


<details>
  <summary>Details</summary>
Motivation: 基于梯度的规划虽然计算效率高，但性能一直落后于其他方法。作者观察到世界模型在训练时使用下一状态预测目标，但在测试时却用于估计动作序列，存在训练-测试差距

Method: 提出训练时数据合成技术来改进基于梯度的规划。通过缩小训练-测试差距，使世界模型能更好地支持梯度规划

Result: 在10%的时间预算下，该方法在各种物体操作和导航任务中达到或超过传统无梯度交叉熵方法(CEM)的性能

Conclusion: 通过改进世界模型训练方法，可以显著提升基于梯度规划的性能，使其在远少于传统方法的时间预算下达到同等或更好的效果

Abstract: World models paired with model predictive control (MPC) can be trained offline on large-scale datasets of expert trajectories and enable generalization to a wide range of planning tasks at inference time. Compared to traditional MPC procedures, which rely on slow search algorithms or on iteratively solving optimization problems exactly, gradient-based planning offers a computationally efficient alternative. However, the performance of gradient-based planning has thus far lagged behind that of other approaches. In this paper, we propose improved methods for training world models that enable efficient gradient-based planning. We begin with the observation that although a world model is trained on a next-state prediction objective, it is used at test-time to instead estimate a sequence of actions. The goal of our work is to close this train-test gap. To that end, we propose train-time data synthesis techniques that enable significantly improved gradient-based planning with existing world models. At test time, our approach outperforms or matches the classical gradient-free cross-entropy method (CEM) across a variety of object manipulation and navigation tasks in 10% of the time budget.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [112] [Hill's Lunar Equations, Series, Convergence, Motion of the Perigee](https://arxiv.org/abs/2512.08961)
*Thomas Ligon*

Main category: nlin.CD

TL;DR: 该研究深入探讨了希尔月球方程、级数展开和近地点运动，通过计算机计算将希尔级数的系数扩展到了m的24阶，并将不依赖于a_0的系数计算到了30阶，发现级数收敛半径接近尖点轨道对应的m值(0.560958)。


<details>
  <summary>Details</summary>
Motivation: 研究动机是进一步探索希尔月球方程的数学性质，特别是希尔级数的收敛性和近地点运动的精确计算，超越以往已知的研究范围。

Method: 采用计算机数值计算方法，将希尔级数系数计算扩展到更高阶数(m的24阶，不依赖a_0的系数到30阶)，并使用希尔文献中近点周期方程的线性化方法来计算近地点运动，但发现了一些差异。

Result: 数值计算表明希尔级数的收敛半径接近尖点轨道对应的m值(0.560958)，提出了这一猜想；同时计算了近地点运动，但与希尔原始文献存在一些差异。

Conclusion: 希尔级数的收敛性可能与其尖点轨道特性相关，这为理解希尔月球方程的数学性质提供了新见解；近地点运动计算中的差异表明需要进一步研究希尔原始方法的精确性。

Abstract: We investigate Hill's lunar equations, series and the motion of the perigee, and we use computers to go farther than has previously been known, calculating the coefficients of Hill's series up to order 24 in m, and the coefficients that do not depend on a_0 up to order 30. Numerical calculations indicate that the radius of convergence of Hill's series is somewhere near the value of m of the cusped orbit (0.560958), which we formulate as a conjecture. We calculate the motion of the perigee using a linearization of the equation for the anomalistic period, as in Hill's documentation, but with some discrepancies.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [113] [Extreme statistics as a probe of the superfluid to Bose-glass Berezinskii-Kosterlitz-Thouless transition](https://arxiv.org/abs/2512.09029)
*Jeanne Colbois,Natalia Chepiga,Shaffique Adam,Gabriel Lemarié,Nicolas Laflorencie*

Main category: cond-mat.dis-nn

TL;DR: 该论文提出使用局部可观测量（如密度或磁化强度）的极值统计来探测无序量子链中的离域-局域化相变，特别关注由弱连接驱动的强无序区域。


<details>
  <summary>Details</summary>
Motivation: 研究无序量子链中的离域-局域化相变，特别是由链断裂事件驱动的局域化现象。需要找到一种既适用于实验又适用于数值模拟的简单方法来表征这些相变。

Method: 采用玻色子语言研究无序诱导的BKT量子相变（从超流体到玻色玻璃）。使用高精度密度矩阵重整化群模拟，分析局部密度极值如何捕捉相变，特别关注强无序区域和弱连接驱动机制。

Result: 数值模拟显示，局部密度极值能够准确捕捉BKT相变，即使在相对较短的链（几十到一百个格点）中也能有效工作。在强无序区域效果显著，但在弱无序区域面临更大的有限尺寸效应挑战。

Conclusion: 局部可观测量（如密度）的极值统计为探测无序量子链中的离域-局域化相变提供了坚实基础，适用于基态和高能态研究，具有实验和数值模拟的双重适用性。

Abstract: Recent studies of delocalization-localization transitions in disordered quantum chains have highlighted the role of rare, chain-breaking events that favor localization, in particular for high-energy eigenstates related to many-body localization. In this context, we revisit the random-field XXZ spin-1/2 chain at zero temperature with ferromagnetic interactions, equivalent to interacting fermions or hard-core bosons in a random potential with attractive interactions. We argue that localization in this model can be characterized by chain-breaking events, which are probed by the extreme values of simple local observables, such as the on-site density or the local magnetization, that are readily accessible in both experiments and numerical simulations. Adopting a bosonic language, we study the disorder-induced Berezinskii-Kosterlitz-Thouless (BKT) quantum phase transition from superfluid (SF) to Bose glass (BG), and focus on the strong disorder regime where localization is driven by weak links. Based on high-precision density matrix renormalization group simulations, we numerically show that extreme local densities accurately capture the BKT transition, even for relatively short chains ranging from a few dozen to a hundred sites. We also discuss the SF-BG transition in the weak disorder regime, where finite-size effects pose greater challenges. Overall, our work seeks to establish a solid foundation for using extreme statistics of local observables, such as density, to probe delocalization-localization transitions in disordered quantum chains, both in the ground state and at high energy.

</details>


### [114] [Transport Scaling and Critical Tilt Effects in Disordered 2D Dirac Fermions](https://arxiv.org/abs/2512.09133)
*Swadeepan Nanda,Pavan Hosur*

Main category: cond-mat.dis-nn

TL;DR: 该研究探讨了二维狄拉克费米子中倾斜对输运和谱性质的影响，发现倾斜能显著改变电导标度行为，揭示出丰富的输运物理现象。


<details>
  <summary>Details</summary>
Motivation: 在凝聚态系统中，二维狄拉克费米子广泛存在于拓扑相和量子临界点中。随着拓扑半金属的发展，倾斜已成为控制物理性质的关键参数。本研究旨在探索倾斜如何影响二维狄拉克费米子在标量无序下的输运和谱性质。

Method: 研究分析了倾斜二维狄拉克费米子在标量无序下的输运和谱性质。通过电导标度g(L)的分析，考察了单狄拉克节点和双狄拉克节点系统在不同倾斜方向下的行为。

Result: 谱分析始终符合适当的高斯系综，暗示退局域化。但电导标度显示丰富行为：单狄拉克节点时g(L)∼a₁log(L)，a₁>0且倾斜依赖；当倾斜与输运方向对齐时，在I型和II型狄拉克节点临界点处a₁出现尖峰。双狄拉克节点时g(L)∼L^{a₁}(log L)^{a₂}，但倾斜方向不同导致相反行为：沿输运方向时a₁随倾斜改变符号，暗示局域化-退局域化转变；垂直输运方向时a₁<0，表明局域化。

Conclusion: 倾斜是揭示二维狄拉克材料中丰富且非常规输运物理的关键控制参数。研究发现了谱性质显示的退局域化与输运行为显示的局域化之间的张力，表明实空间和希尔伯特空间中局域化趋势的差异。

Abstract: Two-dimensional (2D) Dirac fermions occur ubiquitously in condensed matter systems from topological phases to quantum critical points. Since the advent of topological semimetals, where the dispersion is often tilted around the band crossing where the Dirac fermion can appear, tilt has emerged as a key handle that controls physical properties. We study how tilt affects the transport and spectral properties of tilted 2D Dirac fermions under scalar disorder. Although our spectral analyses always show conformity to appropriate Gaussian ensembles, suggestive of delocalization, the conductivity scaling $g(L)$ shows a surprising richness. For a single Dirac node, relevant for quantum Hall transitions and topological insulator surface states, we find $g(L)\sim a_1\log(L)$ with a tilt-dependent coefficient $a_1>0$. Interestingly, when the tilt and transport directions are aligned, $a_1$ and hence $g(L)$ shows a spike at the critical point between the type-I and type-II regimes of the Dirac node. For systems with two Dirac nodes with unbroken time-reversal symmetry, pertinent to quasi-2D Dirac materials, we find $g(L)\sim L^{a_1}(\log L)^{a_2}$. However, we find a surprising tension between tilt along and perpendicular to the transport directions. For the former, $a_1$ changes sign as a function of tilt, hinting at a tilt-driven localization-delocalization transition, while $a_1<0$ for all tilts in the latter case, implying localization. These localized behaviors also reveal tension with the delocalization seen in spectral properties and suggest differing localization tendencies in real and Hilbert spaces. Overall, our work identifies tilt as an essential control parameter that uncovers rich and unconventional transport physics in 2D Dirac materials.

</details>


### [115] [Unified theory of local integrals of motion](https://arxiv.org/abs/2512.09595)
*Ben Craps,Oleg Evnin,Dmitry Kovrizhin,Gabriele Pascuzzi*

Main category: cond-mat.dis-nn

TL;DR: 提出了一种构建精确局部运动积分(LIOMs)的通用框架，将寻找LIOMs转化为优化问题，连接了多体局域化、自旋玻璃物理和约束优化问题


<details>
  <summary>Details</summary>
Motivation: 多体局域化(MBL)理论通过存在大量局部运动积分(LIOMs)来理解，这些守恒量与空间局域的微观量子自由度相关。需要一种系统方法来构建具有特定局域性和量子数的精确LIOMs

Method: 提出了一个通用框架，将寻找LIOMs表述为优化问题。在简单情况下相当于矩阵对角化，在复杂情况下则与寻找自旋玻璃模型的经典基态问题相关。通过单粒子安德森局域化和相互作用自旋链中的MBL等范例进行说明

Result: 该框架能够构建具有所需局域性和量子数的精确LIOMs，揭示了多体局域化、自旋玻璃物理和约束优化问题之间的深刻联系

Conclusion: 该研究统一了先前结果，揭示了多体局域化、自旋玻璃物理和约束优化问题之间的有趣联系，为理解MBL提供了新的理论框架

Abstract: Many-body localization (MBL) is understood theoretically through the existence of an extensive number of local integrals of motion (LIOMs). These conserved quantities are related to the microscopic quantum degrees of freedom that are spatially localized. Here, we present a general framework for constructing exact LIOMs with the desired locality and quantum numbers supplied as input rather than arising as emergent properties. We show that one can express the task of finding LIOMs as an optimization problem. In simple cases, solving this problem amounts to matrix diagonalization, while in more complex settings, it connects to the question of finding classical ground states of spin-glass models. We illustrate our theory using paradigmatic examples of single-particle Anderson localization and MBL in interacting spin chains. These developments unify previous results and reveal intriguing connections among many-body localization, spin-glass physics and constrained optimization problems.

</details>


### [116] [Topological boundaries in non-Hermitian p-wave Kitaev chains with Rashba spin-orbit coupling](https://arxiv.org/abs/2512.09676)
*Shahroze Shahab,Aditi Chakrabarty,Sanjoy Datta*

Main category: cond-mat.dis-nn

TL;DR: 研究了Rashba自旋轨道耦合与非厄米性对自旋p波Kitaev链拓扑相变的协同效应，发现RSOC的影响高度依赖于模型类型，且非厄米性与RSOC的结合能显著降低拓扑相变所需的势能强度。


<details>
  <summary>Details</summary>
Motivation: 先前研究分别探讨了Kitaev链的非厄米扩展和Hermitian系统中RSOC效应，但两者之间的相互作用机制尚未得到充分研究。本文旨在探索非厄米性与RSOC在自旋p波Kitaev链中的协同效应对拓扑相变的影响。

Method: 考虑两种类型的复在位势：(i)均匀增益/损耗项和(ii)复准周期势。通过分析RSOC与这两种非厄米机制的相互作用，推导拓扑相变的解析表达式，并通过能谱和实空间绕数的数值计算验证理论预测。

Result: RSOC的影响高度模型依赖：在均匀增益/损耗模型的Hermitian极限中，RSOC不影响拓扑相边界（当自旋翻转跳跃弱于配对强度时），但在非厄米区域显著改变拓扑景观；在准周期模型中，RSOC同时改变Hermitian和非厄米情况下的相边界。非厄米性与RSOC的结合能显著降低拓扑相变所需的势能强度。

Conclusion: 这项工作全面揭示了非厄米性与Rashba自旋轨道耦合如何协同重塑一维超导系统中的拓扑相图，为理解这两种机制在拓扑相变中的相互作用提供了系统框架。

Abstract: In this work, we investigate the combined effects of Rashba spin-orbit coupling (RSOC) and non-Hermiticity on topological phase transitions in spinful p-wave Kitaev chains. While previous studies have separately examined non-Hermitian (NH) extensions of Kitaev chains and the effects of RSOC in Hermitian systems, the interplay between these two mechanisms remains largely unexplored. We analyze this interplay by considering two distinct types of complex on-site potentials: (i) a uniform gain/loss term and (ii) a complex quasiperiodic potential. We demonstrate that the impact of RSOC is highly model-dependent. In particular, RSOC does not affect the topological phase boundary in the Hermitian limit of the uniform gain/loss model (provided the spin-flip hopping is weaker than the pairing strength), but significantly alters the topological landscape in the NH regime. In contrast, for the quasiperiodic model, RSOC modifies the phase boundaries in both the Hermitian and non-Hermitian cases. Notably, we find that the combined interplay of non-Hermiticity and RSOC drives topological transitions at significantly lower potential strengths compared to the Hermitian limit. We derive analytical expressions for the topological phase transitions in both cases and validate our predictions through numerical calculations of energy spectra and real-space winding numbers. This work provides a comprehensive understanding of how non-Hermiticity and RSOC cooperatively reshape topological phase diagrams in one-dimensional superconducting systems.

</details>
