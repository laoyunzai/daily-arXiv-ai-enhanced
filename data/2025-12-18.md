<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 56]
- [cs.AI](#cs.AI) [Total: 16]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [quant-ph](#quant-ph) [Total: 47]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 12]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 7]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Autonomous Source Knowledge Selection in Multi-Domain Adaptation](https://arxiv.org/abs/2512.14710)
*Keqiuyin Li,Jie Lu,Hua Zuo,Guangquan Zhang*

Main category: cs.LG

TL;DR: AutoS方法通过自主选择源域样本和模型，利用密度驱动策略筛选最可迁移的知识，结合多模态预训练模型增强伪标签，提升多域自适应性能


<details>
  <summary>Details</summary>
Motivation: 多源域自适应中，多个源域常包含冗余或不相关信息，这些信息会损害迁移性能，特别是在大规模源域设置下。需要开发有效策略从大量源域中识别和选择最具可迁移性的知识来解决目标任务。

Method: 提出AutoS方法：1）采用密度驱动选择策略在训练中选择源域样本，并确定哪些源模型应对目标预测做出贡献；2）基于预训练多模态模型构建伪标签增强模块，减轻目标标签噪声并改进自监督学习。

Result: 在真实世界数据集上的实验表明，所提方法具有优越性。

Conclusion: AutoS方法能够自主选择源域训练样本和模型，利用更相关和可迁移的源信息进行目标预测，有效解决了多源域自适应中的知识选择问题。

Abstract: Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \underline{\textit{Auto}}nomous Source Knowledge \underline{\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.

</details>


### [2] [A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour](https://arxiv.org/abs/2512.14713)
*Georges Sfeir,Stephane Hess,Thomas O. Hancock,Filipe Rodrigues,Jamal Amani Rad,Michiel Bliemer,Matthew Beck,Fayyaz Khan*

Main category: cs.LG

TL;DR: 提出了一种潜在类别强化学习模型，用于捕捉旅行决策中的异质性和偏好演化，通过驾驶模拟器数据识别出三种不同的个体适应模式。


<details>
  <summary>Details</summary>
Motivation: 旅行决策通常涉及经验形成过程，个体随时间学习自己的偏好，同时旅行者之间存在显著的异质性，包括基础偏好和偏好演化方式。现有模型难以同时捕捉这两种现象。

Method: 提出了潜在类别强化学习模型，通过变分贝叶斯方法估计参数，应用于驾驶模拟器数据集，识别不同类别的个体行为模式。

Result: 识别出三类显著不同的个体：第一类显示情境依赖性偏好和情境特异性开发倾向；第二类遵循持久性开发策略；第三类采用探索性策略结合情境特异性偏好。

Conclusion: LCRL模型能够有效捕捉旅行决策中的异质性和偏好演化，为理解个体旅行行为提供了新的分析框架。

Abstract: Many travel decisions involve a degree of experience formation, where individuals learn their preferences over time. At the same time, there is extensive scope for heterogeneity across individual travellers, both in their underlying preferences and in how these evolve. The present paper puts forward a Latent Class Reinforcement Learning (LCRL) model that allows analysts to capture both of these phenomena. We apply the model to a driving simulator dataset and estimate the parameters through Variational Bayes. We identify three distinct classes of individuals that differ markedly in how they adapt their preferences: the first displays context-dependent preferences with context-specific exploitative tendencies; the second follows a persistent exploitative strategy regardless of context; and the third engages in an exploratory strategy combined with context-specific preferences.

</details>


### [3] [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)
*Zafaryab Haider,Md Hafizur Rahman,Shane Moeykens,Vijay Devabhaktuni,Prabuddha Chakraborty*

Main category: cs.LG

TL;DR: 本文首次研究如何通过对大语言模型权重进行比特级扰动（故障注入），影响图像描述生成的语义含义，同时保持语法结构完整。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明硬件比特翻转可能使transformer在非生成任务中变得脆弱，但这些方法忽略了生成系统的语义和语言维度。在图像描述模型中，单个比特翻转可能微妙地改变视觉特征到词语的映射，从而改变AI对世界的叙述方式。

Method: 设计了可微分故障分析框架BLADE，使用基于梯度的敏感性估计来定位语义关键比特，然后通过描述级别的语义流畅性目标来优化比特选择。

Result: 研究表明语义漂移不是随机的，而是可以通过模型自身的梯度进行可微分估计的。即使难以察觉的低级变化也能引导生成式视觉语言模型的高级语义输出。

Conclusion: 这项工作不仅为了破坏描述，更重要的是理解语义如何在比特级别编码、分布和改变，揭示了比特级故障如何重塑模型的语义输出，为鲁棒性测试、对抗防御和可解释AI开辟了新途径。

Abstract: Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LLM) used for image captioning can influence the semantic meaning of its generated descriptions while preserving grammatical structure. While prior fault analysis methods have shown that flipping a few bits can crash classifiers or degrade accuracy, these approaches overlook the semantic and linguistic dimensions of generative systems. In image captioning models, a single flipped bit might subtly alter how visual features map to words, shifting the entire narrative an AI tells about the world. We hypothesize that such semantic drifts are not random but differentiably estimable. That is, the model's own gradients can predict which bits, if perturbed, will most strongly influence meaning while leaving syntax and fluency intact. We design a differentiable fault analysis framework, BLADE (Bit-level Fault Analysis via Differentiable Estimation), that uses gradient-based sensitivity estimation to locate semantically critical bits and then refines their selection through a caption-level semantic-fluency objective. Our goal is not merely to corrupt captions, but to understand how meaning itself is encoded, distributed, and alterable at the bit level, revealing that even imperceptible low-level changes can steer the high-level semantics of generative vision-language models. It also opens pathways for robustness testing, adversarial defense, and explainable AI, by exposing how structured bit-level faults can reshape a model's semantic output.

</details>


### [4] [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)
*Ziqian Bi,Danyang Zhang,Junhao Song,Chiung-Yi Tseng*

Main category: cs.LG

TL;DR: GPT-OSS模型家族在金融NLP任务评估中显示，较小的20B参数模型在保持相近准确率（65.1% vs 66.5%）的同时，计算效率显著优于120B版本，挑战了模型规模与性能直接相关的传统假设。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融服务中的快速应用，需要建立严格的评估框架来评估其性能、效率和实际适用性，特别是在资源受限的生产环境中。

Method: 对GPT-OSS模型家族（120B和20B参数变体）以及当代其他LLMs在10个不同的金融NLP任务上进行全面评估，使用真实金融数据集（Financial PhraseBank、FiQA-SA、FLARE FINERORD），涵盖情感分析、问答和实体识别等任务，并引入新的效率指标来衡量性能与资源利用的权衡。

Result: GPT-OSS-20B模型在保持与120B版本相近准确率（65.1% vs 66.5%）的同时，展现出显著的计算效率优势：198.4 Token Efficiency Score和159.80 tokens/秒的处理速度。GPT-OSS模型在多项任务中表现优于包括Qwen3-235B在内的更大竞争对手。

Conclusion: GPT-OSS的架构创新和训练策略使较小模型能够以显著降低的计算开销实现竞争性性能，为金融应用中可持续和成本效益高的LLM部署提供了可行路径，挑战了模型规模与任务性能直接相关的普遍假设。

Abstract: The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten diverse financial NLP tasks. Through extensive experimentation on 120B and 20B parameter variants of GPT-OSS, we reveal a counterintuitive finding: the smaller GPT-OSS-20B model achieves comparable accuracy (65.1% vs 66.5%) while demonstrating superior computational efficiency with 198.4 Token Efficiency Score and 159.80 tokens per second processing speed [1]. Our evaluation encompasses sentiment analysis, question answering, and entity recognition tasks using real-world financial datasets including Financial PhraseBank, FiQA-SA, and FLARE FINERORD. We introduce novel efficiency metrics that capture the trade-off between model performance and resource utilization, providing critical insights for deployment decisions in production environments. The benchmark reveals that GPT-OSS models consistently outperform larger competitors including Qwen3-235B, challenging the prevailing assumption that model scale directly correlates with task performance [2]. Our findings demonstrate that architectural innovations and training strategies in GPT-OSS enable smaller models to achieve competitive performance with significantly reduced computational overhead, offering a pathway toward sustainable and cost-effective deployment of LLMs in financial applications.

</details>


### [5] [Hybrid Attribution Priors for Explainable and Robust Model Training](https://arxiv.org/abs/2512.14719)
*Zhuoran Zhang,Feng Zhang,Shangyuan Li,Yang Shi,Yuanxing Zhang,Wei Chen,Tengjiao Wang,Kam-Fai Wong*

Main category: cs.LG

TL;DR: 本文提出CAP框架，通过提取类别感知的归因先验，帮助小语言模型在分类任务中学习更细粒度的类别区分特征，提升可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前解释引导学习框架在分类任务中面临挑战：现有的归因方法虽然能可靠地突出类别相关标记，但往往聚焦于语义相似类别共享的常见关键词，这些类别本身在标准训练中就难以区分，导致归因先验缺乏足够的判别性线索，限制了模型区分能力的提升。

Method: 提出Class-Aware Attribution Prior (CAP)框架，引导语言模型捕捉细粒度的类别差异，生成更显著、更具判别性的归因先验。进一步提出CAP Hybrid方法，将CAP的先验与现有归因技术的先验相结合，形成更全面平衡的监督信号。通过将模型的自归因与这些丰富的先验对齐，促使模型学习多样化的决策相关特征。

Result: 在完整数据、少样本和对抗场景下的广泛实验表明，该方法能持续提升模型的可解释性和鲁棒性。

Conclusion: CAP框架通过提取类别感知的归因先验，有效解决了现有归因方法在分类任务中判别性不足的问题，为小语言模型在需要低延迟和轻量部署的分类任务中提供了更好的可解释性和鲁棒性解决方案。

Abstract: Small language models (SLMs) are widely used in tasks that require low latency and lightweight deployment, particularly classification. As interpretability and robustness gain increasing importance, explanation-guided learning has emerged as an effective framework by introducing attribution-based supervision during training; however, deriving general and reliable attribution priors remains a significant challenge. Through an analysis of representative attribution methods in classification settings, we find that although these methods can reliably highlight class-relevant tokens, they often focus on common keywords shared by semantically similar classes. Because such classes are already difficult to distinguish under standard training, these attributions provide insufficient discriminative cues, limiting their ability to improve model differentiation. To overcome this limitation, we propose Class-Aware Attribution Prior (CAP), a novel attribution prior extraction framework that guides language models toward capturing fine-grained class distinctions and producing more salient, discriminative attribution priors. Building on this idea, we further introduce CAP Hybrid, which combines priors from CAP with those from existing attribution techniques to form a more comprehensive and balanced supervisory signal. By aligning a model's self-attribution with these enriched priors, our approach encourages the learning of diverse, decision-relevant features. Extensive experiments in full-data, few-shot, and adversarial scenarios demonstrate that our method consistently enhances both interpretability and robustness.

</details>


### [6] [Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example](https://arxiv.org/abs/2512.14721)
*Arno Appenzeller,Nick Terzer,André Hohmeyer,Jan-Philipp Redlich,Sabine Luttmann,Friedrich Feuerhake,Nadine S. Schaadt,Timm Intemann,Sarah Teuber-Hanselmann,Stefan Nikolin,Joachim Weis,Klaus Kraywinkel,Pascal Birnstill*

Main category: cs.LG

TL;DR: 本文提出了一种基于癌症报告统计数据自动生成Synthea规则的方法，并以胶质母细胞瘤为例验证了该方法的有效性，生成的合成数据在保留统计特性的同时保护了患者隐私。


<details>
  <summary>Details</summary>
Motivation: 合成数据生成是医疗数据隐私合规二次使用的重要技术。Synthea作为流行的基于规则的合成患者数据生成器，其规则创建过程复杂且需要专家知识和真实样本数据，这限制了其广泛应用。

Method: 提出了一种从表格数据（癌症报告）中提取统计信息并自动生成Synthea规则的方法。以胶质母细胞瘤真实数据集为例，创建了相应的Synthea模块并生成了合成数据集。

Result: 生成的合成数据能够重现已知的疾病进程，并且在很大程度上保留了原始数据集的统计特性。合成数据与原始数据集在统计属性上表现一致。

Conclusion: 合成患者数据在隐私保护研究方面具有巨大潜力，可用于假设制定和原型开发，但医疗解释应考虑当前所有可用方法的特定局限性。

Abstract: The generation of synthetic data is a promising technology to make medical data available for secondary use in a privacy-compliant manner. A popular method for creating realistic patient data is the rule-based Synthea data generator. Synthea generates data based on rules describing the lifetime of a synthetic patient. These rules typically express the probability of a condition occurring, such as a disease, depending on factors like age. Since they only contain statistical information, rules usually have no specific data protection requirements. However, creating meaningful rules can be a very complex process that requires expert knowledge and realistic sample data. In this paper, we introduce and evaluate an approach to automatically generate Synthea rules based on statistics from tabular data, which we extracted from cancer reports. As an example use case, we created a Synthea module for glioblastoma from a real-world dataset and used it to generate a synthetic dataset. Compared to the original dataset, the synthetic data reproduced known disease courses and mostly retained the statistical properties. Overall, synthetic patient data holds great potential for privacy-preserving research. The data can be used to formulate hypotheses and to develop prototypes, but medical interpretation should consider the specific limitations as with any currently available approach.

</details>


### [7] [HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers](https://arxiv.org/abs/2512.14722)
*Mohamed Malhou,Ludovic Perret,Kristin Lauter*

Main category: cs.LG

TL;DR: 本文改进了Kera等人（NeurIPS 2024）使用Transformer计算Gröbner基的方法，通过引入分层注意力Transformer（HAT）架构来求解多元多项式方程组，实现了显著的计算效率提升。


<details>
  <summary>Details</summary>
Motivation: Gröbner基是计算机代数中的核心对象，具有众多实际应用。Kera等人首次将Transformer应用于Gröbner基计算，但存在计算效率限制。本文旨在通过引入更适合数据结构层次关系的架构来改进这一方法。

Method: 采用分层注意力Transformer（HAT）架构，该架构包含树结构归纳偏置，能够建模数据中的层次关系。方法推广到任意深度，并结合课程学习策略，同时进行了详细的计算成本分析。

Result: 相比传统的平面注意力模型，HAT架构实现了显著的计算节省。结合课程学习后，该方法能够解决比Kera等人（2024）工作中大得多的实例。

Conclusion: 分层注意力Transformer架构为Gröbner基计算提供了更高效的方法，通过利用数据中的层次结构关系，显著提升了计算效率和处理更大规模问题的能力。

Abstract: At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate polynomial equations via Groebner bases computation. The HAT architecture incorporates a tree-structured inductive bias that enables the modeling of hierarchical relationships present in the data and thus achieves significant computational savings compared to conventional flat attention models. We generalize to arbitrary depths and include a detailed computational cost analysis. Combined with curriculum learning, our method solves instances that are much larger than those in Kera et al. (2024 Learning to compute Groebner bases)

</details>


### [8] [A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications](https://arxiv.org/abs/2512.14727)
*Klaus-Rudolf Kladny,Bernhard Schölkopf,Lisa Koch,Christian F. Baumgartner,Michael Muehlebach*

Main category: cs.LG

TL;DR: 本文质疑了共形预测在小样本校准集上的实际效用，指出虽然统计保证在任意样本量下都成立，但这些保证的实际价值高度依赖校准集大小，这在医疗数据稀缺的场景中尤为重要。


<details>
  <summary>Details</summary>
Motivation: 机器学习在医疗领域的应用需要可靠的置信度估计，但标准ML模型无法提供。共形预测虽然能将启发式不确定性估计转化为具有统计保证的估计，但现有理论声称其统计保证适用于任意大小的校准样本，这可能误导人们认为即使在小样本校准集上也能获得有实际意义的统计保证。作者质疑这一承诺，特别是在医疗领域数据稀缺的背景下。

Method: 通过理论分析和实证验证，作者展示了共形预测的统计保证虽然在小样本校准集上仍然成立，但这些保证的实际效用高度依赖校准集的大小。在医疗图像分类任务上进行了实证演示来支持这一批判。

Result: 研究发现，虽然共形预测的统计保证在数学上对任意大小的校准集都成立，但这些保证的实际意义和实用性随着校准集大小的减小而显著降低。在医疗图像分类任务中，小校准集产生的预测集可能过于保守或信息量不足，无法为临床决策提供有意义的指导。

Conclusion: 共形预测在医疗领域的应用需要谨慎对待校准集大小的问题。虽然理论保证在任意样本量下都成立，但实际应用中必须考虑校准集大小对预测集实用性的影响。在数据稀缺的医疗领域，这一局限性尤为突出，需要开发更适应小样本场景的不确定性量化方法。

Abstract: Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistical guarantees. CP works by converting predictions of a ML model, together with a calibration sample, into prediction sets that are guaranteed to contain the true label with any desired probability. An often cited advantage is that CP theory holds for calibration samples of arbitrary size, suggesting that uncertainty estimates with practically meaningful statistical guarantees can be achieved even if only small calibration sets are available. We question this promise by showing that, although the statistical guarantees hold for calibration sets of arbitrary size, the practical utility of these guarantees does highly depend on the size of the calibration set. This observation is relevant in medical domains because data is often scarce and obtaining large calibration sets is therefore infeasible. We corroborate our critique in an empirical demonstration on a medical image classification task.

</details>


### [9] [A data-driven approach to inferring travel trajectory during peak hours in urban rail transit systems](https://arxiv.org/abs/2512.14728)
*Jie He,Yong Qin,Jianyuan Guo,Xuan Sun,Xuanchuan Zheng*

Main category: cs.LG

TL;DR: 本文提出了一种基于AFC和AVL数据的城市轨道交通个体出行轨迹推断方法，采用KLEM算法进行数据驱动的参数估计，无需外部调查数据，在高峰时段轨迹推断准确率超过90%。


<details>
  <summary>Details</summary>
Motivation: 城市轨道交通精细化轨迹推断对运营组织具有重要意义。现有方法依赖外部调查数据进行参数拟合，且验证多使用合成数据，限制了模型的鲁棒性和适用性。

Method: 1. 基于时空约束建立列车备选集；2. 提出基于KL散度结合EM算法的KLEM方法进行数据驱动的自适应参数估计；3. 构建完整的出行轨迹推断框架，包括进出站时间、换乘时间等关键要素推断。

Result: 该方法在城市轨道交通出行轨迹推断中实现了高精度，高峰时段轨迹推断准确率超过90%，且使用真实个体出行轨迹数据进行验证，增强了结果的可信度。

Conclusion: 本文提出的完全数据驱动的城市轨道交通个体出行轨迹推断方法，通过KLEM算法消除了对外部调查数据的依赖，提高了模型的鲁棒性和适用性，为轨道交通运营组织提供了有效的技术支撑。

Abstract: Refined trajectory inference of urban rail transit is of great significance to the operation organization. In this paper, we develop a fully data-driven approach to inferring individual travel trajectories in urban rail transit systems. It utilizes data from the Automatic Fare Collection (AFC) and Automatic Vehicle Location (AVL) systems to infer key trajectory elements, such as selected train, access/egress time, and transfer time. The approach includes establishing train alternative sets based on spatio-temporal constraints, data-driven adaptive trajectory inference, and trave l trajectory construction. To realize data-driven adaptive trajectory inference, a data-driven parameter estimation method based on KL divergence combined with EM algorithm (KLEM) was proposed. This method eliminates the reliance on external or survey data for parameter fitting, enhancing the robustness and applicability of the model. Furthermore, to overcome the limitations of using synthetic data to validate the result, this paper employs real individual travel trajectory data for verification. The results show that the approach developed in this paper can achieve high-precision passenger trajectory inference, with an accuracy rate of over 90% in urban rail transit travel trajectory inference during peak hours.

</details>


### [10] [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)
*Hyakka Nakada,Shu Tanaka*

Main category: cs.LG

TL;DR: 该研究探讨了随机矩阵中经过min-max归一化后的特征值的统计特性，推导了累积分布的标度律和矩阵分解中的残差误差，并通过数值实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 在数据科学实践中，输入数据通常需要进行归一化处理。随机矩阵理论在纯数学、数学物理和机器学习中都有重要应用，因此研究归一化特征值的统计特性具有实际意义。

Method: 应用先前提出的归一化特征值有效分布，推导累积分布的标度律和矩阵分解中的残差误差，并通过数值实验进行验证。

Result: 成功推导了归一化特征值累积分布的标度律和矩阵分解的残差误差，数值实验结果与理论预测一致。

Conclusion: 该研究为随机矩阵中归一化特征值的统计特性提供了理论框架，推导的标度律和残差误差公式对数据科学中的矩阵处理具有指导意义。

Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.

</details>


### [11] [Semantic Geometry for policy-constrained interpretation](https://arxiv.org/abs/2512.14731)
*Nikit Phadke*

Main category: cs.LG

TL;DR: 提出一种几何框架，通过球面凸区域表示语义，将证据与策略约束分离，确保高风险领域零幻觉承诺


<details>
  <summary>Details</summary>
Motivation: 解决高风险领域（如金融监管）中语义解释产生幻觉承诺的问题，需要可证明的安全保证机制

Method: 使用单位球面上的方向表示语义，证据建模为见证向量集，可接受解释对应球面凸区域，策略约束作为显式先验，通过约束优化进行解释

Result: 理论证明复杂度边界在信息论上最优，大规模监管金融数据实证显示在多种策略制度下实现零幻觉批准

Conclusion: 该几何框架为高风险领域的语义解释提供了可证明的安全保证，首次在大规模应用中实现零幻觉承诺

Abstract: We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.

</details>


### [12] [Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness](https://arxiv.org/abs/2512.14734)
*Qiang Chen,Venkatesh Ganapati Hegde,Hongfei Li*

Main category: cs.LG

TL;DR: 提出了一种轻量级、模型无关的日内个性化方法，通过推理时注入近期观看历史来更新用户特征，无需模型重训练，显著提升长视频流媒体推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有长视频流媒体推荐系统依赖批量训练模型和每日更新的特征，无法捕捉用户最新行为，导致推荐内容陈旧。需要一种能实时响应用户偏好变化但无需完全实时架构重训练的方法。

Method: 开发了轻量级、模型无关的日内个性化方法，在推理时有选择地用近期观看历史覆盖陈旧的用户特征，使系统能即时适应用户偏好变化，无需模型重训练。

Result: 通过将个性化反馈循环从每日缩短到日内，观察到关键用户参与度指标有统计学意义的0.47%提升，这是近期实验周期中观察到的最显著参与度增益之一。

Conclusion: 这是首个证明日内个性化能在长视频流媒体服务中产生有意义影响的公开证据，为需要模型重训练的完全实时架构提供了有吸引力的替代方案。

Abstract: Many recommender systems in long-form video streaming reply on batch-trained models and batch-updated features, where user features are updated daily and served statically throughout the day. While efficient, this approach fails to incorporate a user's most recent actions, often resulting in stale recommendations. In this work, we present a lightweight, model-agnostic approach for intra-day personalization that selectively injects recent watch history at inference time without requiring model retraining. Our approach selectively overrides stale user features at inference time using the recent watch history, allowing the system to adapt instantly to evolving preferences. By reducing the personalization feedback loop from daily to intra-day, we observed a statistically significant 0.47% increase in key user engagement metrics which ranked among the most substantial engagement gains observed in recent experimentation cycles. To our knowledge, this is the first published evidence that intra-day personalization can drive meaningful impact in long-form video streaming service, providing a compelling alternative to full real-time architectures where model retraining is required.

</details>


### [13] [NoveltyRank: Estimating Conceptual Novelty of AI Papers](https://arxiv.org/abs/2512.14738)
*Zhengxu Yan,Han Li,Yuming Feng*

Main category: cs.LG

TL;DR: 开发了一个评估AI论文概念新颖性的模型，通过标题、摘要和语义相似度来量化研究原创性，帮助研究人员和审稿人识别真正创新的工作。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版门槛降低，AI领域论文数量激增，难以识别真正新颖和有影响力的工作，手动评估新颖性不稳定且耗时。

Method: 通过论文标题、摘要和与先前文献的语义相似度评估新颖性，探索两种任务形式：二元分类（预测绝对新颖性）和成对新颖性比较（学习相对新颖性），使用Qwen3-4B-Instruct-2507和SciBERT进行微调。

Result: 开发了公开可用的实现（GitHub），并与GPT-5.1进行基准测试，分析了任务形式和建模选择对性能的影响。

Conclusion: 该项目为AI论文的概念新颖性评估提供了一个数据驱动、可扩展的系统，有助于高效识别真正创新的研究，并为会议审稿人提供定量、一致的新颖性信号。

Abstract: With the growing ease of academic publishing, the volume of research papers, especially in AI-related fields, has surged dramatically. This flood of publications makes it difficult for truly novel and impactful work to stand out, and manual novelty assessment is often unstable and time-consuming. Our project aims to develop a model that estimates and ranks the conceptual novelty of AI papers, enabling a data-driven and scalable assessment of research originality. Such a system can help researchers efficiently identify submissions that introduce genuinely innovative ideas rather than minor variants, and provide conference reviewers with a quantitative and consistent signal of novelty. Our approach evaluates novelty primarily through a paper's title, abstract, and semantic similarity to prior literature. Given the motivation of novelty estimation, we explore two task formulations with different modeling objectives, each offering a different perspective: (1) binary classification, which predicts the paper's absolute novelty from learned patterns of prior novel works, and (2) pairwise novelty comparison, which learns to distinguish papers by relative novelty over others. We fine-tune Qwen3-4B-Instruct-2507 and SciBERT on both tasks, benchmarking against GPT-5.1 to analyze how task formulation and modeling choices affect performance. The implementation is publicly available at https://github.com/ZhengxuYan/NoveltyRank.

</details>


### [14] [Guided Discrete Diffusion for Constraint Satisfaction Problems](https://arxiv.org/abs/2512.14765)
*Justin Jung*

Main category: cs.LG

TL;DR: 提出离散扩散引导方法解决约束满足问题，并在无监督情况下成功求解数独谜题


<details>
  <summary>Details</summary>
Motivation: 约束满足问题（CSPs）是人工智能和优化领域的重要问题，传统方法通常需要监督学习或复杂的启发式规则。研究者希望开发一种无需监督的方法来解决这类问题，特别是像数独这样的经典CSP问题。

Method: 提出离散扩散引导方法，该方法基于扩散模型的思想，但专门针对离散空间设计。通过引导扩散过程来满足约束条件，从而在无监督的情况下解决CSP问题。

Result: 该方法成功应用于数独谜题的求解，展示了在无监督情况下解决约束满足问题的能力。

Conclusion: 离散扩散引导为约束满足问题提供了一种新颖的无监督解决方案，特别适用于像数独这样的离散优化问题，为CSP求解开辟了新的研究方向。

Abstract: We propose discrete diffusion guidance for constraint satisfaction problems (CSPs) and demonstrate its ability to solve Sudoku puzzles without supervision.

</details>


### [15] [Evaluating Weather Forecasts from a Decision Maker's Perspective](https://arxiv.org/abs/2512.14779)
*Kornelius Raeth,Nicole Ludwig*

Main category: cs.LG

TL;DR: 决策校准框架从决策者角度评估天气预报价值，发现传统预报评估与下游决策表现不一致


<details>
  <summary>Details</summary>
Motivation: 传统天气预报评估主要关注预报者视角和统计指标，但实际应用中预报用于决策制定，需要从决策者角度量化预报价值

Method: 提出决策校准框架，在决策层面而非预报层面评估预报性能，比较机器学习与传统数值天气预报模型在不同天气依赖决策任务中的表现

Result: 预报层面的模型性能不能可靠地转化为下游决策表现：有些性能差异只在决策层面显现，不同决策任务中模型排名会发生变化

Conclusion: 传统预报评估不足以为特定决策任务选择最优预报模型，需要采用决策层面的评估方法

Abstract: Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forecast by its ability to improve decision-making. Decision calibration provides a novel framework for evaluating forecast performance at the decision level rather than the forecast level. We evaluate decision calibration to compare Machine Learning and classical numerical weather prediction models on various weather-dependent decision tasks. We find that model performance at the forecast level does not reliably translate to performance in downstream decision-making: some performance differences only become apparent at the decision level, and model rankings can change among different decision tasks. Our results confirm that typical forecast evaluations are insufficient for selecting the optimal forecast model for a specific decision task.

</details>


### [16] [Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse](https://arxiv.org/abs/2512.14879)
*Jingwei Chen*

Main category: cs.LG

TL;DR: 提出ERBP框架，将自指学习中的模型崩溃现象统一解释为分布空间中的Bregman投影序列，通过引入熵储层实现稳定控制。


<details>
  <summary>Details</summary>
Motivation: 自指学习（模型在自身生成的数据上训练）虽然具有无限扩展潜力，但长期存在模型崩溃问题。尽管实践中采用各种临时修复方法，但缺乏统一的理论框架来解释失败模式和修复方法的成功原理。

Method: 提出熵储层Bregman投影（ERBP）框架，将自指学习建模为分布空间中的随机Bregman投影序列。通过引入熵储层（高熵分布）注入可控的熵通量来稳定动力学。

Result: 理论推导出：(1) 崩溃的必要条件；(2) 保证非平凡熵底限的充分条件；(3) 仅依赖于样本量和Bregman生成器常数的闭式速率。在大型语言模型自训练、强化学习和GAN优化中验证了预测。

Conclusion: ERBP将各种经验性稳定启发式方法统一为单一量化设计规则：监控和预算熵通量，为自指学习提供了理论基础和设计指导。

Abstract: Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.

</details>


### [17] [Task Matrices: Linear Maps for Cross-Model Finetuning Transfer](https://arxiv.org/abs/2512.14880)
*Darrin O' Brien,Dhikshith Gajulapalli,Eric Xia*

Main category: cs.LG

TL;DR: 论文提出"任务矩阵"概念，证明预训练和微调模型之间存在跨层线性编码，通过线性变换提升基础模型性能，接近微调水平


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大型视觉和语言模型在上下文提示偏置下学习隐式线性编码，但在更一般的适应机制中是否存在类似线性表示尚未得到证实

Method: 开发"任务矩阵"概念，即从基础嵌入状态到微调嵌入状态的线性变换，在视觉和文本模型及十个不同数据集上进行验证

Result: 基础模型增强任务矩阵后性能超越线性探针，有时接近微调水平，验证了预训练和微调架构间存在跨层线性编码，数据近似方法高效且可泛化到多个领域

Conclusion: 任务矩阵证明了预训练和微调模型间存在可学习的线性关系，为模型适应提供了高效且可泛化的方法

Abstract: Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.

</details>


### [18] [OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams](https://arxiv.org/abs/2512.14892)
*Mohammad Abu-Shaira,Alejandro Rodriguez,Greg Speegle,Victor Sheng,Ishfaq Ahmad*

Main category: cs.LG

TL;DR: OLR-WA是一种新颖的多变量在线线性回归模型，通过加权平均更新机制，在数据漂移场景下实现与批量回归相当的性能，并具有快速收敛和置信度处理能力。


<details>
  <summary>Details</summary>
Motivation: 在线学习需要增量更新模型以避免大存储需求和昂贵的模型重计算，同时需要处理数据漂移（底层模式随时间变化）的挑战场景。

Method: 提出"OLR-WA"（在线回归加权平均）模型，采用加权平均更新机制，对置信度较高的旧数据点给予优先权，采用保守更新策略。

Result: OLR-WA性能与批量回归相当，优于其他在线模型，快速收敛（从第1次迭代到最后一次迭代都保持高r2值），即使仅用1%-10%数据初始化也能有效工作，是唯一能有效处理置信度挑战场景的模型。

Conclusion: OLR-WA在不同场景下展现出多功能性和实用性，是在线线性回归任务的有价值解决方案，特别在处理时间漂移和置信度挑战方面表现突出。

Abstract: Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce "OLR-WA; OnLine Regression with Weighted Average", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.

</details>


### [19] [Low-rank MMSE filters, Kronecker-product representation, and regularization: a new perspective](https://arxiv.org/abs/2512.14932)
*Daniel Gomes de Pinho Zanco,Leszek Szczecinski,Jacob Benesty,Eduardo Vinicius Kuhn*

Main category: cs.LG

TL;DR: 提出一种基于Kronecker积表示的低秩MMSE滤波器正则化参数高效选择方法，该方法与秩选择问题相关，在低秩设置中至关重要。


<details>
  <summary>Details</summary>
Motivation: 在低秩MMSE滤波器中，正则化参数的选择对性能至关重要，但传统方法效率不高。本文旨在开发一种高效的正则化参数选择方法，特别是针对基于Kronecker积表示的低秩滤波器。

Method: 提出一种基于Kronecker积表示的低秩MMSE滤波器正则化参数高效选择方法。该方法发现正则化参数与秩选择问题存在关联，通过这种关联来优化参数选择。

Result: 通过仿真验证，该方法相比常用方法取得了显著性能提升，证明了所提方法的有效性。

Conclusion: 正则化参数的选择在低秩设置中至关重要，本文提出的高效选择方法通过建立与秩选择问题的联系，实现了优于传统方法的性能。

Abstract: In this work, we propose a method to efficiently find the regularization parameter for low-rank MMSE filters based on a Kronecker-product representation. We show that the regularization parameter is surprisingly linked to the problem of rank selection and, thus, properly choosing it, is crucial for low-rank settings. The proposed method is validated through simulations, showing significant gains over commonly used methods.

</details>


### [20] [Softly Constrained Denoisers for Diffusion Models](https://arxiv.org/abs/2512.14980)
*Victor M. Yeom Song,Severi Rissanen,Arno Solin,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出一种软约束去噪器方法，通过将约束知识整合到去噪器本身而非损失函数或采样循环中，在保持数据分布真实性的同时提高约束遵从性


<details>
  <summary>Details</summary>
Motivation: 扩散模型在科学应用中难以生成符合约束条件的样本，现有方法通过损失函数正则化或采样引导会偏离真实数据分布，特别是在约束条件设定错误时问题更严重

Method: 将引导式调整整合到去噪器本身，赋予其软归纳偏置，使其倾向于生成符合约束的样本，同时保持足够的灵活性以在约束设定错误时偏离约束

Result: 软约束去噪器利用约束知识提高了样本的约束遵从性，同时保持了足够的灵活性，在约束设定错误时能够偏离约束以更好地拟合观测数据

Conclusion: 通过将约束知识整合到去噪器本身而非外部调整，可以在保持数据分布真实性的同时有效处理科学数据中的约束遵从问题，特别是对约束设定错误的情况具有鲁棒性

Abstract: Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Recent approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. We show that these softly constrained denoisers exploit constraint knowledge to improve compliance over standard denoisers, and maintain enough flexibility to deviate from it when there is misspecification with observed data.

</details>


### [21] [Prompt Repetition Improves Non-Reasoning LLMs](https://arxiv.org/abs/2512.14982)
*Yaniv Leviathan,Matan Kalman,Yossi Matias*

Main category: cs.LG

TL;DR: 重复输入提示能提升主流大模型性能，无需增加生成token或延迟


<details>
  <summary>Details</summary>
Motivation: 探索在不使用推理的情况下，如何通过简单方法提升主流大语言模型的性能表现

Method: 通过重复输入提示（prompt repetition）的方法，在不增加生成token数量和延迟的情况下测试模型性能

Result: 对于Gemini、GPT、Claude和Deepseek等主流模型，重复输入提示能有效提升性能

Conclusion: 简单的提示重复是一种有效的性能提升策略，适用于多种主流大语言模型

Abstract: When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.

</details>


### [22] [Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes](https://arxiv.org/abs/2512.14991)
*Hanqing Jin,Renyuan Xu,Yanzhao Yang*

Main category: cs.LG

TL;DR: 提出一种用于无界连续状态空间扩散过程的强化学习算法，通过自适应划分状态-动作空间，平衡探索与近似，在金融、经济等领域的高维问题中实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 金融、经济和运筹学中的许多问题涉及无界连续状态空间、有界连续动作和多项式增长奖励的扩散过程，现有方法难以处理这类高维连续域问题。

Method: 提出基于模型的算法，自适应划分联合状态-动作空间，在每个分区内估计漂移、波动率和奖励，当估计偏差超过统计置信度时细化离散化，平衡探索与近似。

Result: 建立了后悔界，依赖于问题视界、状态维度、奖励增长阶数以及针对无界扩散过程新定义的缩放维度概念，将现有有界设置的结果作为特例包含在内。

Conclusion: 该算法能有效处理无界扩散过程的高维强化学习问题，数值实验验证了其有效性，包括在多资产均值-方差投资组合选择等实际应用中的表现。

Abstract: We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

</details>


### [23] [DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding](https://arxiv.org/abs/2512.15000)
*Ruiyi Zhang,Peijia Qin,Qi Cao,Pengtao Xie*

Main category: cs.LG

TL;DR: DreamPRM-Code提出了一种针对代码任务的流程奖励模型，通过将函数作为推理步骤并使用元学习校正机制，在代码生成任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有流程奖励模型在代码任务上效果有限，主要原因是代码缺乏有意义的步骤分解，以及蒙特卡洛生成的中间标签存在噪声问题。

Method: 1. 使用Chain-of-Function提示策略，将函数视为推理步骤，实现模块化代码生成；2. 引入基于元学习的校正机制，利用干净的最终解决方案单元测试标签，通过双层优化精炼中间标签。

Result: 在LiveCodeBench基准测试中达到80.9%的pass@1率，超越了OpenAI o4-mini，实现了最先进的性能。

Conclusion: DreamPRM-Code通过创新的步骤分解和标签校正方法，有效解决了代码任务中流程奖励模型的关键挑战，显著提升了代码生成的质量。

Abstract: Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.

</details>


### [24] [Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets](https://arxiv.org/abs/2512.15008)
*Sandeep Neela*

Main category: cs.LG

TL;DR: SPA是一个确定性框架，用于从股价数据中提取单调价格走势，关联相关公共事件，并生成事实性、历史性的解释，旨在提供透明、可复现的历史价格结构分析。


<details>
  <summary>Details</summary>
Motivation: 现有技术指标和预测模型在透明度和可解释性方面存在不足，特别是在需要审计和解释性的场景中。技术指标依赖于平台特定规则，而预测系统通常缺乏解释性。

Method: SPA使用每日OHLCV数据和标准化事件流，通过确定性框架提取单调价格走势，通过对称相关窗口关联公共事件，并生成受约束的解释。

Result: 在AAPL、NVDA、SCHW、PGR四只股票上的评估显示，SPA能够稳定地生成结构性分解和上下文叙事。消融实验表明确定性分割、事件对齐和约束解释都对可解释性有贡献。

Conclusion: SPA不是预测系统或交易信号生成器，其价值在于提供透明、可复现的历史价格结构视图，可补充分析师工作流程、风险评估和可解释AI管道。

Abstract: Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.

</details>


### [25] [Epistemic diversity across language models mitigates knowledge collapse](https://arxiv.org/abs/2512.15011)
*Damian Hodel,Jevin D. West*

Main category: cs.LG

TL;DR: 研究AI生态系统多样性如何缓解知识崩溃问题，发现适度的认知多样性可以缓解崩溃，但过多或过少的多样性都会导致性能下降


<details>
  <summary>Details</summary>
Motivation: 随着AI的广泛应用，出现了知识崩溃的担忧，即知识会缩减到最主流和核心的思想集合。先前研究已证明单一模型崩溃现象，本研究受生态学启发，探讨AI生态系统多样性（模型间的多样性）是否能缓解这种崩溃

Method: 基于单一模型方法，但关注在集体输出上训练的模型生态系统。通过在不同语言模型间分割训练数据，评估由此产生的生态系统在十次自训练迭代中的表现，研究多样性对模型性能的影响

Result: 研究发现增加的认知多样性确实可以缓解崩溃，但有趣的是，只达到一个最优水平。包含太少多样化模型的生态系统无法表达完整真实分布的丰富混合，导致快速性能衰减；而将数据分布在太多模型中会降低每个模型对真实分布的近似能力，导致在第一次迭代步骤中就表现不佳

Conclusion: 在AI单一文化的背景下，研究结果表明需要监控AI系统间的多样性，并制定政策激励更多领域和社区特定的模型，以维持健康的AI生态系统

Abstract: The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.

</details>


### [26] [The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems](https://arxiv.org/abs/2512.15068)
*Debu Sinha*

Main category: cs.LG

TL;DR: 本文应用符合预测方法到幻觉检测，提供有限样本覆盖保证，发现基于嵌入的方法在真实幻觉基准上存在不可接受的高误报率，而GPT-4作为LLM法官表现更好，揭示了"语义幻觉"现象。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成(RAG)系统基于检索证据，但仍容易产生幻觉。当前基于语义相似性和自然语言推理的检测方法存在根本性限制，但尚未被严格表征。

Method: 应用符合预测方法进行幻觉检测，提供有限样本覆盖保证。使用约600个示例的校准集，在合成幻觉上测试，并在三个真实幻觉基准上评估多种方法，包括基于嵌入的方法和GPT-4作为LLM法官。

Result: 在合成幻觉上达到94%覆盖率且0%误报率，但在真实基准上，基于嵌入的方法误报率极高：HaluEval 100%、RAGTruth 88%、WikiBio 50%。GPT-4作为LLM法官仅7%误报率，证明任务可通过推理解决。

Conclusion: 揭示了"语义幻觉"现象：语义上合理的幻觉保持与源文档的相似性，同时引入嵌入方法无法检测的事实错误。这种限制跨越嵌入架构、LLM生成器和任务类型，表明基于嵌入的检测不足以用于生产RAG部署。

Abstract: Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the "semantic illusion": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.

</details>


### [27] [The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks](https://arxiv.org/abs/2512.15082)
*Wanfu Gao,Zebin He,Jun Gao*

Main category: cs.LG

TL;DR: FEAML是一种基于大语言模型的自动化特征工程方法，专门针对多标签学习任务，通过代码生成、反馈机制和标签依赖建模来提升多标签分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的特征工程方法尚未应用于多标签学习任务，缺乏对复杂标签依赖关系的建模能力，也没有针对多标签任务特点进行专门适配。

Method: FEAML利用大语言模型的代码生成能力，通过元数据和标签共现矩阵引导LLMs理解数据特征与任务目标之间的关系，生成高质量特征。新生成的特征通过模型准确率评估有效性，使用皮尔逊相关系数检测冗余，并将评估结果作为反馈驱动LLMs在后续迭代中持续优化代码生成。

Result: 在各种多标签数据集上的实证结果表明，FEAML优于其他特征工程方法。

Conclusion: 通过将大语言模型与反馈机制相结合，FEAML实现了一种高效、可解释且自我改进的特征工程范式，为多标签学习任务提供了有效的自动化特征工程解决方案。

Abstract: Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.

</details>


### [28] [FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation](https://arxiv.org/abs/2512.15116)
*Runze Li,Hanchen Wang,Wenjie Zhang,Binghao Li,Yu Zhang,Xuemin Lin,Ying Zhang*

Main category: cs.LG

TL;DR: FADTI是一个基于扩散模型的多元时间序列插补框架，通过可学习的傅里叶偏置投影模块注入频率感知特征调制，结合自注意力和门控卷积进行时序建模，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列插补在医疗、交通预测和生物建模等领域至关重要，但现有的Transformer和扩散模型缺乏明确的归纳偏置和频率感知能力，限制了它们在结构化缺失模式和分布偏移下的泛化性能。

Method: 提出FADTI框架，通过可学习的傅里叶偏置投影模块注入频率感知特征调制，支持多种谱基，能够自适应编码平稳和非平稳模式，并结合自注意力和门控卷积进行时序建模。

Result: 在多个基准测试（包括新引入的生物时间序列数据集）上的实验表明，FADTI始终优于最先进的方法，特别是在高缺失率情况下表现突出。

Conclusion: FADTI通过将频域归纳偏置注入生成式插补过程，有效解决了现有模型在频率感知和泛化能力方面的限制，为多元时间序列插补提供了更强大的解决方案。

Abstract: Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF

</details>


### [29] [From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?](https://arxiv.org/abs/2512.15134)
*Aaron Mueller,Andrew Lee,Shruti Joshi,Ekdeep Singh Lubana,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: 该研究提出多概念评估框架，分析稀疏自编码器和稀疏探针在概念相关性增强时能否学习解耦表示，发现特征与概念存在一对多关系，且即使训练时概念分布均匀，特征在操纵时仍影响多个概念，表明相关性度量不足以评估独立性。


<details>
  <summary>Details</summary>
Motivation: 可解释性研究通常孤立评估概念表示质量，并隐含独立性假设，但这些假设在实践中可能不成立。需要评估常见特征化方法（如稀疏自编码器和稀疏探针）是否真正恢复了解耦的概念表示。

Method: 提出多概念评估设置，控制文本概念（如情感、领域、时态）之间的相关性，分析在相关性增强时的性能。首先评估特征化方法在不同相关强度下学习每个概念解耦表示的能力，然后进行操纵实验，测量每个概念是否可独立操纵。

Result: 发现特征与概念存在一对多关系：特征对应不超过一个概念，但概念分布在多个特征中。即使训练时概念分布均匀，稀疏自编码器特征在操纵时通常影响多个概念，表明它们既不具选择性也不独立；然而特征影响不相交的子空间。

Conclusion: 相关性度量通常不足以在操纵时建立独立性，影响不相交子空间也不足以实现概念选择性。这些结果强调了可解释性研究中组合评估的重要性。

Abstract: A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, it is unclear whether common featurization methods - including sparse autoencoders (SAEs) and sparse probes - recover disentangled representations of these concepts. This study proposes a multi-concept evaluation setting where we control the correlations between textual concepts, such as sentiment, domain, and tense, and analyze performance under increasing correlations between them. We first evaluate the extent to which featurizers can learn disentangled representations of each concept under increasing correlational strengths. We observe a one-to-many relationship from concepts to features: features correspond to no more than one concept, but concepts are distributed across many features. Then, we perform steering experiments, measuring whether each concept is independently manipulable. Even when trained on uniform distributions of concepts, SAE features generally affect many concepts when steered, indicating that they are neither selective nor independent; nonetheless, features affect disjoint subspaces. These results suggest that correlational metrics for measuring disentanglement are generally not sufficient for establishing independence when steering, and that affecting disjoint subspaces is not sufficient for concept selectivity. These results underscore the importance of compositional evaluations in interpretability research.

</details>


### [30] [Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis](https://arxiv.org/abs/2512.15250)
*Youssef Ghallab,Omar Iraqy,Mohamed Kandil,Mohamed Ashraf,Saadeldine Eletter,Morougue Ghazal,Ayman Khalafallah,Nagwa El-Makky*

Main category: cs.LG

TL;DR: 该研究提出了一种用于生理信号多模态融合的方法，通过自监督预训练ECG编码器，并与预训练的EEG编码器结合，使用简单的嵌入拼接实现跨模态融合，在情感识别任务中达到接近SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）和脑电图（EEG）等生理信号提供了对人体健康和认知的互补洞察，但多模态整合面临挑战：多模态标注数据有限，以及模态特异性差异。需要开发能够有效融合不同生理信号的方法。

Method: 1. 采用CBraMod编码器进行大规模自监督ECG预训练，引入双掩码策略捕捉导联内和导联间依赖关系；2. 使用预训练的CBraMod编码器处理EEG信号；3. 预训练对称的ECG编码器；4. 通过简单的嵌入拼接融合两种模态的表示；5. 让分类头学习跨模态交互，在有限的多模态监督下实现有效的下游学习。

Result: 在情感识别任务上，该方法达到了接近最先进的性能。结果表明，精心设计的生理信号编码器，即使采用简单的融合策略，也能显著提升下游任务性能。

Conclusion: 该方法展示了基础模型方法在利用生理信号整体特性方面的潜力，能够为医疗保健和情感计算提供可扩展、标签高效且可泛化的解决方案。精心设计的生理编码器配合简单的融合策略就能显著改善下游性能。

Abstract: Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.

</details>


### [31] [Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany](https://arxiv.org/abs/2512.15140)
*Roland Baatz*

Main category: cs.LG

TL;DR: 该研究比较了机器学习模型在德国农业产量预测中的泛化性能和可解释性，发现模型在时间独立验证中表现显著下降，即使测试集表现良好的模型也可能产生看似可信但不可靠的特征重要性解释。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决机器学习模型在农业和环境系统中泛化能力评估的挑战，特别是在时间维度上的泛化问题，以及模型可解释性在泛化失败时的可靠性问题。

Method: 使用德国NUTS-3区域的高质量长期数据集，系统比较集成树模型（XGBoost、随机森林）和深度学习方法（LSTM、TCN）的评估和时间验证行为，分析模型在空间分割测试集和时间独立验证集上的表现差异。

Result: 所有模型在空间分割测试集上表现良好，但在时间独立验证年份中性能显著下降；测试集准确率高但时间验证性能弱的模型仍能产生看似可信的SHAP特征重要性值，揭示了后验可解释性方法的脆弱性。

Conclusion: 研究强调农业和环境系统中需要验证感知的机器学习解释，特征重要性不应被表面接受，除非模型明确显示能在未见时空条件下泛化；提倡领域感知验证、混合建模策略和对可解释性方法更严格的审查。

Abstract: This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN).
  While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize.
  These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?

</details>


### [32] [An Efficient Gradient-Based Inference Attack for Federated Learning](https://arxiv.org/abs/2512.15143)
*Pablo Montaña-Fernández,Ines Ortega-Fernandez*

Main category: cs.LG

TL;DR: 提出一种基于梯度时序演化的联邦学习成员推理攻击方法，利用多轮训练中最后一层梯度的变化模式，无需访问私有数据集，适用于半诚实和恶意攻击者，并可扩展到属性推理攻击。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然减少了直接数据暴露，但参与者与聚合器之间交换的模型更新仍可能泄露敏感信息。现有攻击方法存在局限，需要探索多轮联邦学习中梯度时序演化模式带来的隐私风险。

Method: 使用影子技术学习训练记录在多轮联邦学习中的最后一层梯度模式，无需访问私有数据集。攻击方法模型无关，适用于任何基于梯度的模型，可应用于分类和回归任务。还提供了扩展到离散属性推理的自然扩展方法。

Result: 在CIFAR-100和Purchase100数据集上的成员推理攻击表现出色，与文献中其他攻击相比具有可比的计算和内存开销。在Breast Cancer Wisconsin数据集上的属性推理也有效。发现多轮联邦学习增加了推理攻击的脆弱性，聚合器比数据所有者构成更大威胁，攻击性能受训练数据集性质影响，高维丰富数据比简单表格数据泄露更严重。

Conclusion: 多轮联邦学习增加了对推理攻击的脆弱性，聚合器是主要威胁源，数据集特性显著影响攻击效果。需要开发更强大的隐私保护机制来应对基于梯度时序演化的推理攻击。

Abstract: Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.

</details>


### [33] [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)
*Hiroyoshi Nagahama,Katsufumi Inoue,Masayoshi Todorokihara,Michifumi Yoshioka*

Main category: cs.LG

TL;DR: 该论文提出了两种相位感知预处理策略来解决多轴振动数据中的随机相位变化问题，并在新构建的转子数据集上验证了这些方法能显著提升深度学习模型的预测维护性能。


<details>
  <summary>Details</summary>
Motivation: 旋转机械的预测维护越来越依赖振动信号，但大多数基于学习的方法要么在频谱特征提取时丢弃相位信息，要么使用原始时间波形而不显式利用相位信息。多轴振动数据中的随机相位变化问题需要解决。

Method: 提出了两种相位感知预处理策略：1）三轴独立相位调整，将每个轴单独对齐到零相位；2）单轴参考相位调整，通过应用统一的时间偏移来保持轴间关系。使用新构建的同步三轴传感器采集的转子数据集，在两级学习框架下评估了六种深度学习架构。

Result: 结果显示架构无关的改进：三轴独立方法实现了持续增益（Transformer模型提升2.7%），而单轴参考方法通过保持空间相位关系实现了高达96.2%的准确率（提升5.4%）。

Conclusion: 这些发现确立了两种相位对齐策略作为预测维护系统的实用且可扩展的增强方法。

Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

</details>


### [34] [Understanding NTK Variance in Implicit Neural Representations](https://arxiv.org/abs/2512.15169)
*Chengguang Ou,Yixin Zhuang*

Main category: cs.LG

TL;DR: 该研究揭示了隐式神经表示（INRs）中谱偏差问题的根源，通过神经正切核（NTK）理论框架，分析了不同架构选择如何影响NTK条件数，并提出统一的方差分解方法来解释常见INR组件如何改善谱偏差。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）通常收敛缓慢且难以恢复高频细节，这归因于谱偏差问题。虽然先前工作将此行为与神经正切核（NTK）联系起来，但具体架构选择如何影响NTK条件数仍不清楚。研究旨在揭示不同INR机制如何通过影响NTK特征值方差来改善谱偏差问题。

Method: 研究提出一个统一的理论框架，将多种INR机制理解为一小组成对相似性因子和缩放项的影响，这些因素共同决定NTK特征值方差。推导了常见INR组件的闭式方差分解：位置编码重塑输入相似性，球面归一化通过层间缩放减少方差，Hadamard调制引入小于1的额外相似性因子，产生乘法方差减少。

Result: 对于标准坐标MLP，有限的输入特征交互导致大的特征值分散和不良条件数。研究展示了不同INR架构通过改善NTK条件数来缓解谱偏差的机制。跨多个任务的实验证实了预测的方差减少，并证明了更快、更稳定的收敛以及改进的重建质量。

Conclusion: 该研究为理解INR架构如何缓解谱偏差提供了统一的理论视角，通过NTK特征值方差分解解释了位置编码、球面归一化和Hadamard调制等机制的工作原理，为设计更有效的INR架构提供了理论指导。

Abstract: Implicit Neural Representations (INRs) often converge slowly and struggle to recover high-frequency details due to spectral bias. While prior work links this behavior to the Neural Tangent Kernel (NTK), how specific architectural choices affect NTK conditioning remains unclear. We show that many INR mechanisms can be understood through their impact on a small set of pairwise similarity factors and scaling terms that jointly determine NTK eigenvalue variance. For standard coordinate MLPs, limited input-feature interactions induce large eigenvalue dispersion and poor conditioning. We derive closed-form variance decompositions for common INR components and show that positional encoding reshapes input similarity, spherical normalization reduces variance via layerwise scaling, and Hadamard modulation introduces additional similarity factors strictly below one, yielding multiplicative variance reduction. This unified view explains how diverse INR architectures mitigate spectral bias by improving NTK conditioning. Experiments across multiple tasks confirm the predicted variance reductions and demonstrate faster, more stable convergence with improved reconstruction quality.

</details>


### [35] [Double Horizon Model-Based Policy Optimization](https://arxiv.org/abs/2512.15439)
*Akihiro Kubo,Paavo Parmas,Shin Ishii*

Main category: cs.LG

TL;DR: DHMBPO提出双视野模型强化学习方法，通过长分布视野和短训练视野解决模型偏差与梯度稳定性之间的权衡问题


<details>
  <summary>Details</summary>
Motivation: 在基于模型的强化学习中，选择视野长度存在两个困境：长视野能更好地保持同策略训练但会放大模型偏差；长视野可能减少价值估计偏差但会增加策略梯度的方差。这两个最优视野可能不同，需要解决这一冲突。

Method: 提出双视野模型策略优化（DHMBPO），将视野过程分为长"分布视野"（DR）和短"训练视野"（TR）。DR生成同策略状态样本来缓解分布偏移，而短TR利用可微分转移提供准确的价值梯度估计和稳定的梯度更新。

Result: 双视野方法有效平衡了分布偏移、模型偏差和梯度不稳定性，在连续控制基准测试中超越了现有的MBRL方法，在样本效率和运行时间方面都有优势。

Conclusion: DHMBPO通过分离分布视野和训练视野，解决了模型强化学习中视野长度选择的冲突，实现了更好的性能平衡。

Abstract: Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long "distribution rollout" (DR) and a short "training rollout" (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.

</details>


### [36] [Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT](https://arxiv.org/abs/2512.15206)
*Liyu Zhang,Yejia Liu,Kwun Ho Liu,Runxi Huang,Xiaomin Ouyang*

Main category: cs.LG

TL;DR: Chorus是一种面向物联网应用的上下文感知、无需目标域数据的模型定制方法，通过学习有效的上下文表示来适应未见过的部署条件，在多种上下文偏移场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 物联网应用中传感器数据通常在多样化和动态的上下文条件下收集，传统领域适应或泛化方法往往忽略上下文信息或使用简单集成策略，导致在部署后无法有效处理未见的上下文偏移。

Method: 1) 通过无监督跨模态重建学习传感器数据与语言上下文嵌入之间的关联，正则化上下文嵌入空间以获得鲁棒、可泛化的上下文表示；2) 在有限标注样本上训练轻量级门控头，动态平衡传感器和上下文贡献；3) 采用上下文缓存机制减少推理延迟，仅在检测到上下文偏移时更新缓存。

Result: 在IMU、语音和WiFi感知任务中，Chorus在未见上下文条件下比最先进基线方法性能提升高达11.3%，同时在智能手机和边缘设备上保持可比的延迟。

Conclusion: Chorus通过上下文感知的模型定制方法有效解决了物联网应用中动态上下文条件下的模型适应问题，实现了无需目标域数据的高性能适应，具有实际部署价值。

Abstract: In real-world IoT applications, sensor data is usually collected under diverse and dynamic contextual conditions where factors such as sensor placements or ambient environments can significantly affect data patterns and downstream performance. Traditional domain adaptation or generalization methods often ignore such context information or use simplistic integration strategies, making them ineffective in handling unseen context shifts after deployment. In this paper, we propose Chorus, a context-aware, data-free model customization approach that adapts models to unseen deployment conditions without requiring target-domain data. The key idea is to learn effective context representations that capture their influence on sensor data patterns and to adaptively integrate them based on the degree of context shift. Specifically, Chorus first performs unsupervised cross-modal reconstruction between unlabeled sensor data and language-based context embeddings, while regularizing the context embedding space to learn robust, generalizable context representations. Then, it trains a lightweight gated head on limited labeled samples to dynamically balance sensor and context contributions-favoring context when sensor evidence is ambiguous and vice versa. To further reduce inference latency, Chorus employs a context-caching mechanism that reuses cached context representations and updates only upon detected context shifts. Experiments on IMU, speech, and WiFi sensing tasks under diverse context shifts show that Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts, while maintaining comparable latency on smartphone and edge devices.

</details>


### [37] [How Smoothing is N-simplicial Attention?](https://arxiv.org/abs/2512.15600)
*Alexandre Dussolle,Pietro Liò*

Main category: cs.LG

TL;DR: 该论文提出了N-单纯形注意力机制，从传统的成对token相似性扩展到高阶交互，并适配了RoPE位置编码。为了管理增加的复杂度，提出了成本有效的单纯形选择方法，让模型能聚焦于任务敏感度更高的交互。同时研究了该机制的平滑性，推导了Lipschitz上界，并证明其本身也存在过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 从纯MLP到可学习的图消息传递机制（如GATs或Transformers）虽然带来了最先进的结果，但存在计算权衡。为了进一步推进，需要从成对token相似性扩展到高阶交互，同时管理增加的复杂度。

Method: 1. 引入N-单纯形注意力机制，将注意力从成对交互扩展到高阶交互；2. 将该机制适配到RoPE位置编码；3. 提出成本有效的单纯形选择方法，让模型能选择性关注任务敏感度更高的交互；4. 推导N-单纯形注意力的Lipschitz上界，分析其平滑特性。

Result: 1. 成功构建了支持高阶交互的注意力机制；2. 开发了有效的复杂度管理方法；3. 理论上证明了N-单纯形注意力也存在过平滑问题，尽管它开启了高阶交互的消息传递。

Conclusion: N-单纯形注意力机制是注意力架构的重要扩展，从成对交互推进到高阶交互。虽然需要管理增加的复杂度，但通过提出的单纯形选择方法可以有效地处理。该机制虽然开启了高阶交互，但仍然存在过平滑问题，这为未来的改进提供了方向。

Abstract: Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.

</details>


### [38] [O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization](https://arxiv.org/abs/2512.15229)
*Elio Gruttadauria,Mathieu Fontaine,Jonathan Le Roux,Slim Essid*

Main category: cs.LG

TL;DR: O-EENC-SD是一种基于EEND-EDA的端到端在线说话人日志系统，采用新颖的RNN拼接机制，通过质心细化解码器实现高效在线预测，在双人电话对话场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有说话人日志方法存在局限性：无监督聚类方法需要超参数调优，而当前在线端到端方法计算成本高昂。需要开发一种既无需超参数调优又计算高效的在线说话人日志系统。

Method: 基于EEND-EDA框架，引入RNN拼接机制处理在线预测，开发了新颖的质心细化解码器。系统采用独立分块处理（无重叠），实现高效计算。

Result: 在CallHome数据集的双人电话对话测试中，O-EENC-SD与最先进方法竞争激烈。系统在DER（说话人日志错误率）和复杂度之间提供了良好权衡，即使处理无重叠的独立分块也保持高效。

Conclusion: O-EENC-SD是一种超参数免费且计算高效的在线说话人日志系统，在双人对话场景中表现出色，为在线说话人日志任务提供了实用的解决方案。

Abstract: We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.

</details>


### [39] [Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2512.15687)
*Zhenwen Liang,Sidi Lu,Wenhao Yu,Kishan Panaganti,Yujun Zhou,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: G2RL提出了一种基于梯度引导的强化学习框架，使用模型自身的梯度方向而非外部启发式方法来指导探索，在数学和推理基准测试中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习探索机制（如熵奖励和外部语义比较器）与大型语言模型的实际学习方式存在根本性不匹配，它们鼓励表面变化但不能保证采样轨迹在优化方向上产生差异。

Method: G2RL框架利用模型最后一层的敏感性构建序列级特征，通过比较采样组内这些特征来衡量每个轨迹如何重塑策略。引入新颖梯度方向的轨迹获得有界乘法奖励缩放，冗余或离流形更新被弱化。

Result: 在MATH500、AMC、AIME24、AIME25、GPQA、MMLUpro等数学和通用推理基准测试中，G2RL在Qwen3基础1.7B和4B模型上持续改进了pass@1、maj@16和pass@k指标，优于基于熵的GRPO和外部嵌入方法。

Conclusion: 策略自身的更新空间为大型语言模型强化学习中的探索提供了更忠实和有效的指导基础，G2RL能够扩展探索到更多正交且常常相反的梯度方向，同时保持语义连贯性。

Abstract: Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.

</details>


### [40] [Topological Metric for Unsupervised Embedding Quality Evaluation](https://arxiv.org/abs/2512.15285)
*Aleksei Shestov,Anton Klenitskiy,Daria Denisova,Amurkhan Dzagkoev,Daniil Petrovich,Andrey Savchenko,Maksim Makarenko*

Main category: cs.LG

TL;DR: 提出了一种基于持久同调的无监督度量方法Persistence，用于评估嵌入空间的质量，无需标签即可量化几何结构和拓扑丰富度


<details>
  <summary>Details</summary>
Motivation: 现代表示学习主要依赖无监督和自监督方法，但在没有标签的情况下评估嵌入质量仍然是一个开放挑战。现有方法通常假设线性可分性或依赖协方差结构，无法捕捉全局和多尺度组织特征。

Method: 提出Persistence度量方法，基于持久同调（拓扑数据分析技术），能够量化嵌入空间的几何结构和拓扑丰富度。该方法完全无监督，不依赖标签信息，能够捕捉全局和多尺度组织特征。

Result: 在多个领域的实证结果表明，Persistence与下游任务性能的相关性始终处于顶级水平，优于现有的无监督度量方法，能够实现可靠的模型和超参数选择。

Conclusion: Persistence作为一种基于拓扑感知的无监督度量方法，能够有效评估嵌入空间的质量，为无监督表示学习提供了可靠的评估工具，解决了无标签情况下评估嵌入质量的挑战。

Abstract: Modern representation learning increasingly relies on unsupervised and self-supervised methods trained on large-scale unlabeled data. While these approaches achieve impressive generalization across tasks and domains, evaluating embedding quality without labels remains an open challenge. In this work, we propose Persistence, a topology-aware metric based on persistent homology that quantifies the geometric structure and topological richness of embedding spaces in a fully unsupervised manner. Unlike metrics that assume linear separability or rely on covariance structure, Persistence captures global and multi-scale organization. Empirical results across diverse domains show that Persistence consistently achieves top-tier correlations with downstream performance, outperforming existing unsupervised metrics and enabling reliable model and hyperparameter selection.

</details>


### [41] [A Regime-Aware Fusion Framework for Time Series Classification](https://arxiv.org/abs/2512.15378)
*Honey Singh Chauhan,Zahraa S. Abdallah*

Main category: cs.LG

TL;DR: Fusion-3 (F3)框架通过自适应融合Rocket、Sax和Sfa三种时间序列表示，在特定类型数据集上比单独使用Rocket获得一致改进，尤其在具有结构化变异或丰富频率内容的数据集上表现更佳。


<details>
  <summary>Details</summary>
Motivation: 虽然基于核的方法如Rocket在单变量时间序列分类中非常有效，但并非在所有数据集上表现一致。研究者重新审视了不同表示能捕捉互补结构的长期直觉，希望通过选择性融合这些表示来获得系统性改进。

Method: 提出Fusion-3 (F3)轻量级框架，自适应融合Rocket、Sax和Sfa三种表示。通过元特征（序列长度、频谱结构、粗糙度、类别不平衡）将UCR数据集聚类为6组可解释的数据结构机制，分析融合在哪些机制中有效。采用三种互补分析：跨数据集的非参数配对统计、分离单个表示作用的消融研究、以及通过SHAP识别预测融合增益的数据集属性。

Result: 在113个UCR数据集上的5折交叉验证显示，F3相比Rocket获得小而一致的平均改进，得到频率论和贝叶斯证据支持。融合通常在具有结构化变异或丰富频率内容的数据集机制中优于强基线，而在高度不规则或异常值多的设置中收益递减。样本级案例研究表明融合主要通过纠正特定错误来提升性能。

Conclusion: 选择性应用的融合为强核方法提供了可靠且可解释的扩展，在数据支持的情况下精确纠正其弱点。融合主要在具有结构化变异或丰富频率内容的数据集上有效，而在高度不规则或异常值多的设置中收益有限。

Abstract: Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and show that selectively fusing them can yield consistent improvements over Rocket on specific, systematically identifiable kinds of datasets. We introduce Fusion-3 (F3), a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations. To understand when fusion helps, we cluster UCR datasets into six groups using meta-features capturing series length, spectral structure, roughness, and class imbalance, and treat these clusters as interpretable data-structure regimes. Our analysis shows that fusion typically outperforms strong baselines in regimes with structured variability or rich frequency content, while offering diminishing returns in highly irregular or outlier-heavy settings. To support these findings, we combine three complementary analyses: non-parametric paired statistics across datasets, ablation studies isolating the roles of individual representations, and attribution via SHAP to identify which dataset properties predict fusion gains. Sample-level case studies further reveal the underlying mechanism: fusion primarily improves performance by rescuing specific errors, with adaptive increases in frequency-domain weighting precisely where corrections occur. Using 5-fold cross-validation on the 113 UCR datasets, F3 yields small but consistent average improvements over Rocket, supported by frequentist and Bayesian evidence and accompanied by clearly identifiable failure cases. Our results show that selectively applied fusion provides dependable and interpretable extension to strong kernel-based methods, correcting their weaknesses precisely where the data support it.

</details>


### [42] [Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection](https://arxiv.org/abs/2512.15385)
*Julian Oelhaf,Mehran Pashaei,Georg Kordowich,Christian Bergler,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.LG

TL;DR: 论文提出一个统一框架，用于系统评估电力系统保护中机器学习模型的鲁棒性，通过高保真EMT仿真模拟传感器故障、采样率降低等实际退化场景，量化有限观测性影响并识别关键测量通道。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源和分布式发电渗透率增加，传统依赖固定设置和本地测量的保护方案面临挑战。机器学习为集中式故障分类和定位提供了数据驱动替代方案，但实际部署需要鲁棒性保证，保护算法必须在传感器数据缺失、噪声或退化时仍保持可靠。

Method: 引入统一框架系统评估ML模型在电力系统保护中的鲁棒性，使用高保真电磁暂态（EMT）仿真模拟实际退化场景，包括传感器中断、采样率降低和瞬态通信丢失。框架提供一致的基准测试方法，量化有限观测性影响，识别关键测量通道。

Result: 故障分类在大多数退化类型下保持高度稳定，但在单相丢失时下降约13%；故障定位整体更敏感，电压丢失使定位误差增加超过150%。研究为未来ML辅助保护系统的鲁棒性设计提供了可操作的指导。

Conclusion: 该框架为系统评估电力系统保护中ML模型的鲁棒性提供了方法论，识别了不同退化场景下的性能变化，为设计具有鲁棒性的ML辅助保护系统提供了实用指导。

Abstract: The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection.
  High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.

</details>


### [43] [EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning](https://arxiv.org/abs/2512.15405)
*Jianfei Ma,Wee Sun Lee*

Main category: cs.LG

TL;DR: 提出了一种基于贝叶斯强化学习的算法EUBRL，利用认知不确定性指导探索，在无限时域折扣MDP中实现了接近极小极大最优的遗憾和样本复杂度保证。


<details>
  <summary>Details</summary>
Motivation: 智能体在已知与未知边界面临探索-利用困境，认知不确定性反映了知识有限导致的系统性不确定性。现有方法需要更原则性的探索策略来减少估计误差带来的每步遗憾。

Method: 提出贝叶斯强化学习算法EUBRL，利用认知不确定性指导探索，自适应减少因估计误差产生的每步遗憾。算法适用于一类充分表达的先验分布。

Result: 在无限时域折扣MDP中建立了接近极小极大最优的遗憾和样本复杂度保证。实验表明，在稀疏奖励、长时域和随机性任务中，EUBRL具有优越的样本效率、可扩展性和一致性。

Conclusion: EUBRL通过认知不确定性指导实现了原则性探索，在理论和实证上都表现出色，为解决强化学习中的探索-利用困境提供了有效方案。

Abstract: At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.

</details>


### [44] [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)
*Yeonwoo Cha,Semin Kim,Jinhyeon Kwon,Seunghoon Hong*

Main category: cs.LG

TL;DR: FlowBind是一个高效的多模态任意到任意生成框架，通过共享潜在空间和模态特定可逆流，显著减少数据需求和计算成本，训练速度比现有方法快10倍


<details>
  <summary>Details</summary>
Motivation: 现有基于流的方法存在效率低下问题：需要大规模数据集且有配对约束、建模联合分布计算成本高、依赖复杂的多阶段训练。需要更简单高效的任意到任意生成框架

Method: FlowBind学习一个捕获跨模态信息的共享潜在空间，通过模态特定的可逆流将每个模态桥接到这个潜在空间。两个组件在单一流匹配目标下联合优化，推理时这些可逆流作为编码器和解码器实现跨模态直接翻译

Result: 在文本、图像和音频上的实验表明，FlowBind在保持可比生成质量的同时，参数数量减少6倍，训练速度比先前方法快10倍

Conclusion: 通过共享潜在空间分解交互，FlowBind能够自然利用任意模态子集进行训练，在显著减少数据需求和计算成本的同时实现有竞争力的生成质量

Abstract: Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, incur high computational cost from modeling joint distribution, and rely on complex multi-stage training. We propose FlowBind, an efficient framework for any-to-any generation. Our approach is distinguished by its simplicity: it learns a shared latent space capturing cross-modal information, with modality-specific invertible flows bridging this latent to each modality. Both components are optimized jointly under a single flow-matching objective, and at inference the invertible flows act as encoders and decoders for direct translation across modalities. By factorizing interactions through the shared latent, FlowBind naturally leverages arbitrary subsets of modalities for training, and achieves competitive generation quality while substantially reducing data requirements and computational cost. Experiments on text, image, and audio demonstrate that FlowBind attains comparable quality while requiring up to 6x fewer parameters and training 10x faster than prior methods. The project page with code is available at https://yeonwoo378.github.io/official_flowbind.

</details>


### [45] [Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting](https://arxiv.org/abs/2512.15442)
*Neeraj Sarna,Yuanyuan Li,Michael von Gablenz*

Main category: cs.LG

TL;DR: 该论文研究如何通过思维链和任务指令提示等技术减少文本到图像生成模型中的版权内容生成，降低侵权风险。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像生成模型可能记忆并复制其训练数据中的受版权保护内容，这会导致用户和开发者面临法律风险和财务损失。

Method: 结合思维链和任务指令提示技术，配合负向提示和提示重写两种版权缓解策略，研究生成图像与版权图像的相似度以及与用户输入的相关性。

Result: 在不同复杂度的模型上进行数值实验，提供了关于这些技术在减少版权内容生成方面有效性的见解。

Conclusion: 思维链和任务指令提示结合负向提示和提示重写等技术可以有效减少文本到图像生成模型中的版权内容生成，降低侵权风险。

Abstract: Large scale text-to-image generation models can memorize and reproduce their training dataset. Since the training dataset often contains copyrighted material, reproduction of training dataset poses a copyright infringement risk, which could result in legal liabilities and financial losses for both the AI user and the developer. The current works explores the potential of chain-of-thought and task instruction prompting in reducing copyrighted content generation. To this end, we present a formulation that combines these two techniques with two other copyright mitigation strategies: a) negative prompting, and b) prompt re-writing. We study the generated images in terms their similarity to a copyrighted image and their relevance of the user input. We present numerical experiments on a variety of models and provide insights on the effectiveness of the aforementioned techniques for varying model complexity.

</details>


### [46] [From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning](https://arxiv.org/abs/2512.15460)
*Xiangrui Xu,Zhize Li,Yufei Han,Bin Wang,Jiqiang Liu,Wei Wang*

Main category: cs.LG

TL;DR: 该论文提出了Invertibility Loss (InvLoss)框架来量化联邦学习中数据重建攻击的风险，并开发了InvRE风险估计器和自适应噪声防御方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习系统中的数据重建攻击对隐私构成严重威胁，但缺乏理论基础的量化框架来评估风险。现有研究未能解决如何系统表征和评估DRA风险的问题。

Method: 引入Invertibility Loss (InvLoss)来量化数据重建攻击的最大可达效果；推导InvLoss的紧致可计算上界；从三个角度探索其含义：1) 基于雅可比矩阵谱性质分析DRA风险；2) 开发InvRE风险估计器；3) 提出两种自适应噪声扰动防御方法。

Result: 实验验证表明，该框架能系统评估DRA风险，InvRE提供攻击方法无关的全面风险评估，自适应噪声防御在保持分类准确性的同时增强隐私保护。

Conclusion: 提出的InvLoss框架为联邦学习中的数据重建攻击提供了理论基础的风险量化方法，统一解释了防御方法的有效性，并为系统性的风险评估和缓解提供了实用工具。

Abstract: Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework. In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model updates or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems.

</details>


### [47] [Robustness and uncertainty: two complementary aspects of the reliability of the predictions of a classifier](https://arxiv.org/abs/2512.15492)
*Adrián Detavernier,Jasper De Bock*

Main category: cs.LG

TL;DR: 该论文比较了评估分类器个体预测可靠性的两种方法：鲁棒性量化(RQ)和不确定性量化(UQ)，发现两者互补，结合后的混合方法优于单独使用任一种方法。


<details>
  <summary>Details</summary>
Motivation: 评估分类器个体预测的可靠性是机器学习中的重要问题，目前存在两种概念上不同的方法：鲁棒性量化(RQ)和不确定性量化(UQ)。研究者希望系统比较这两种方法的优劣，探索它们是否可以结合以获得更好的可靠性评估。

Method: 在多个基准数据集上系统比较RQ和UQ方法，分析两种方法的性能差异，然后提出将两者结合的混合方法。同时开发了评估不确定性和鲁棒性作为不可靠性来源相对重要性的方法。

Result: 实验结果显示RQ和UQ方法之间没有明确的优劣之分，但两者具有互补性。结合两者的混合方法在性能上优于单独使用RQ或UQ。此外，该方法还能为每个数据集提供不确定性和鲁棒性作为不可靠性来源的相对重要性评估。

Conclusion: RQ和UQ是评估分类器预测可靠性的两种互补方法，结合两者的混合方法能够提供更优的可靠性评估。该方法还能帮助理解不同数据集中不确定性和鲁棒性对预测不可靠性的相对贡献。

Abstract: We consider two conceptually different approaches for assessing the reliability of the individual predictions of a classifier: Robustness Quantification (RQ) and Uncertainty Quantification (UQ). We compare both approaches on a number of benchmark datasets and show that there is no clear winner between the two, but that they are complementary and can be combined to obtain a hybrid approach that outperforms both RQ and UQ. As a byproduct of our approach, for each dataset, we also obtain an assessment of the relative importance of uncertainty and robustness as sources of unreliability.

</details>


### [48] [Tracking Temporal Dynamics of Vector Sets with Gaussian Process](https://arxiv.org/abs/2512.15538)
*Taichi Aida,Mamoru Komachi,Toshinobu Ogiso,Hiroya Takamura,Daichi Mochihashi*

Main category: cs.LG

TL;DR: 该论文提出了一种基于无限维高斯过程的方法，用于建模随时间变化的向量集合分布，通过随机傅里叶特征近似获得紧凑可比的时序向量表示，从而在低维空间中追踪和可视化向量集合的时序演变。


<details>
  <summary>Details</summary>
Motivation: 理解向量集合的时序演变是生态学、犯罪分析和语言学等多个领域的基础挑战。这些领域中的向量集合（如生态系统结构、犯罪空间分布、词嵌入向量）具有复杂的结构且随时间变化，分析这些时间变化的向量集合具有挑战性。

Method: 提出一种新颖方法，使用无限维高斯过程建模每个向量集合的底层分布。通过随机傅里叶特征近似高斯过程中的潜在函数，获得随时间变化的紧凑且可比较的向量表示，从而在低维空间中追踪和可视化向量集合的时序转换。

Result: 将方法应用于社会学数据（犯罪分布）和语言学数据（词嵌入），证明其能有效捕捉时序动态。结果显示该方法提供了可解释且稳健的表示，为分析跨领域时间索引向量集合的结构变化提供了强大框架。

Conclusion: 该方法为分析时间变化向量集合的结构变化提供了一个强大框架，能够捕捉跨多个领域的时序动态，提供可解释和稳健的低维表示，有助于理解和可视化复杂系统的演变过程。

Abstract: Understanding the temporal evolution of sets of vectors is a fundamental challenge across various domains, including ecology, crime analysis, and linguistics. For instance, ecosystem structures evolve due to interactions among plants, herbivores, and carnivores; the spatial distribution of crimes shifts in response to societal changes; and word embedding vectors reflect cultural and semantic trends over time. However, analyzing such time-varying sets of vectors is challenging due to their complicated structures, which also evolve over time. In this work, we propose a novel method for modeling the distribution underlying each set of vectors using infinite-dimensional Gaussian processes. By approximating the latent function in the Gaussian process with Random Fourier Features, we obtain compact and comparable vector representations over time. This enables us to track and visualize temporal transitions of vector sets in a low-dimensional space. We apply our method to both sociological data (crime distributions) and linguistic data (word embeddings), demonstrating its effectiveness in capturing temporal dynamics. Our results show that the proposed approach provides interpretable and robust representations, offering a powerful framework for analyzing structural changes in temporally indexed vector sets across diverse domains.

</details>


### [49] [Joint Learning of Unsupervised Multi-view Feature and Instance Co-selection with Cross-view Imputation](https://arxiv.org/abs/2512.15574)
*Yuxin Cai,Yanyong Huang,Jinyuan Chang,Dongjie Wang,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: JUICE是一种联合学习框架，用于无监督多视图特征和实例协同选择，同时处理缺失数据，通过跨视图信息改进插补和选择效果。


<details>
  <summary>Details</summary>
Motivation: 当前处理未标记不完整多视图数据的方法通常先插补缺失数据，然后将所有视图拼接为单一数据集进行协同选择，这种方法将协同选择和缺失数据插补视为两个独立过程，忽略了它们之间的潜在交互作用。同时，简单合并多视图数据无法捕捉视图间的互补信息，限制了协同选择的效果。

Method: JUICE首先利用可用观测重建不完整多视图数据，将缺失数据恢复与特征和实例协同选择统一在一个框架中。然后利用跨视图邻域信息学习样本间关系，在重建过程中进一步优化缺失值的插补，从而选择更具代表性的特征和实例。

Result: 大量实验表明，JUICE在性能上优于现有的最先进方法。

Conclusion: JUICE通过联合学习框架有效解决了未标记不完整多视图数据的特征和实例协同选择问题，将缺失数据插补与协同选择过程有机结合，利用跨视图信息提升了选择效果。

Abstract: Feature and instance co-selection, which aims to reduce both feature dimensionality and sample size by identifying the most informative features and instances, has attracted considerable attention in recent years. However, when dealing with unlabeled incomplete multi-view data, where some samples are missing in certain views, existing methods typically first impute the missing data and then concatenate all views into a single dataset for subsequent co-selection. Such a strategy treats co-selection and missing data imputation as two independent processes, overlooking potential interactions between them. The inter-sample relationships gleaned from co-selection can aid imputation, which in turn enhances co-selection performance. Additionally, simply merging multi-view data fails to capture the complementary information among views, ultimately limiting co-selection effectiveness. To address these issues, we propose a novel co-selection method, termed Joint learning of Unsupervised multI-view feature and instance Co-selection with cross-viEw imputation (JUICE). JUICE first reconstructs incomplete multi-view data using available observations, bringing missing data recovery and feature and instance co-selection together in a unified framework. Then, JUICE leverages cross-view neighborhood information to learn inter-sample relationships and further refine the imputation of missing values during reconstruction. This enables the selection of more representative features and instances. Extensive experiments demonstrate that JUICE outperforms state-of-the-art methods.

</details>


### [50] [Corrective Diffusion Language Models](https://arxiv.org/abs/2512.15596)
*Shuibai Zhang,Fred Zhangzhi Peng,Yiheng Zhang,Jin Pan,Grigorios G. Chrysos*

Main category: cs.LG

TL;DR: 本文研究了扩散语言模型的纠错能力，发现传统掩码扩散训练无法可靠地实现错误定位和修正，提出了基于纠正导向的后训练方法，显著提升了模型的纠错性能。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在结构上适合迭代错误修正，但标准的掩码扩散语言模型训练无法可靠地诱导这种纠错行为，模型往往无法识别完整输入中的不可靠标记，导致基于置信度的细化无效。

Method: 提出了纠正导向的后训练原则，明确监督可见的错误标记，使模型具备错误感知的置信度和针对性修正能力。同时引入了代码修订基准（CRB）来评估纠错行为。

Result: 实验表明，采用本文方法训练的模型在纠错场景中显著优于标准掩码扩散语言模型，同时还能提升纯补全性能。

Conclusion: 扩散语言模型的纠错能力需要通过专门的训练方法来激发，本文提出的纠正导向后训练方法有效解决了传统训练无法实现可靠错误定位和修正的问题。

Abstract: Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.

</details>


### [51] [Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction](https://arxiv.org/abs/2512.15605)
*Mathieu Blondel,Michael E. Sander,Germain Vivier-Ardisson,Tianlin Liu,Vincent Roulet*

Main category: cs.LG

TL;DR: 该论文建立了自回归模型（ARMs）与能量模型（EBMs）之间的函数空间双射关系，揭示了它们在监督学习中的等价性，并为EBMs蒸馏到ARMs提供了理论误差界。


<details>
  <summary>Details</summary>
Motivation: 目前自回归模型主导大语言模型发展，而能量模型在训练后对齐中自然表征最优策略。论文旨在统一这两种模型类别，理解ARMs基于下一个token预测范式却能够进行前瞻规划的能力。

Method: 以概率链式法则为起点，在函数空间中建立ARMs与EBMs之间的显式双射关系，证明该双射对应最大熵强化学习中软贝尔曼方程的特例。基于此双射推导监督学习的等价性，并分析EBMs蒸馏到ARMs的理论误差界。

Result: 建立了ARMs与EBMs之间的理论联系，证明了两种模型在监督学习中的等价性，为EBMs蒸馏到ARMs提供了理论误差界，解释了ARMs能够进行前瞻规划的能力。

Conclusion: 论文通过建立ARMs与EBMs的统一框架，为理解自回归模型的内在机制提供了新的理论视角，揭示了基于下一个token预测的模型如何能够实现前瞻规划，为模型对齐和优化提供了理论基础。

Abstract: Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.

</details>


### [52] [Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary](https://arxiv.org/abs/2512.15614)
*Xinshun Feng,Mingzhe Liu,Yi Qiao,Tongyu Zhu,Leilei Sun,Shuai Wang*

Main category: cs.LG

TL;DR: BEAT是一个可迁移的推荐框架，将用户和物品行为编码为离散、可解释的序列，通过向量量化自编码构建行为词汇表，解耦宏观兴趣和微观意图，并嵌入冻结语言模型实现零样本推荐和解释生成。


<details>
  <summary>Details</summary>
Motivation: 现有可解释推荐方法依赖ID表示，语义模糊且对语言模型有结构限制，难以适应开放场景。真实交互中用户意图复杂多样，协作信号与语言语义不匹配，需要更灵活的框架。

Method: 提出BEAT框架：1) 通过向量量化自编码构建行为词汇表，从图表示中解耦宏观兴趣和微观意图；2) 引入多级语义监督桥接行为信号与语言空间；3) 设计语义对齐正则化机制，将行为标记直接嵌入冻结语言模型的输入空间。

Result: 在三个公开数据集上的实验表明，BEAT提升了零样本推荐性能，同时生成连贯且信息丰富的解释。进一步分析显示行为标记捕获了细粒度语义，为复杂行为模式集成到大语言模型提供了即插即用接口。

Conclusion: BEAT通过将行为序列化为离散标记，有效解决了现有可解释推荐方法的局限性，实现了语义对齐和可迁移性，为开放场景下的推荐系统提供了统一框架。

Abstract: Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.

</details>


### [53] [SoFlow: Solution Flow Models for One-Step Generative Modeling](https://arxiv.org/abs/2512.15657)
*Tianze Luo,Haotian Yuan,Zhuang Liu*

Main category: cs.LG

TL;DR: SoFlow框架通过分析速度函数与速度ODE解函数的关系，提出Flow Matching损失和解一致性损失，实现从零开始的一步生成，避免了多步去噪过程的效率问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和Flow Matching模型中的多步去噪过程存在严重的效率问题，这促使研究者探索少步生成方法，特别是从零开始的一步生成。

Method: 提出Solution Flow Models (SoFlow)框架，通过分析速度函数与速度ODE解函数的关系，设计Flow Matching损失和解一致性损失来训练模型。Flow Matching损失允许模型在训练期间为Classifier-Free Guidance提供估计速度场，而一致性损失不需要计算Jacobian-vector product，避免了深度学习框架中的优化问题。

Result: 在ImageNet 256x256数据集上，使用相同的Diffusion Transformer架构和相同训练轮数从头训练时，SoFlow模型比MeanFlow模型获得了更好的FID-50K分数。

Conclusion: SoFlow框架成功实现了高效的一步生成，通过创新的损失函数设计避免了传统方法中的计算瓶颈，在图像生成质量上超越了现有方法。

Abstract: The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.

</details>


### [54] [A Multivariate Statistical Framework for Detection, Classification and Pre-localization of Anomalies in Water Distribution Networks](https://arxiv.org/abs/2512.15685)
*Oleg Melnikov,Yurii Dorofieiev,Yurii Shakhnovskiy,Huy Truong,Victoria Degeler*

Main category: cs.LG

TL;DR: SICAMS框架使用多元统计分析检测、分类和初步定位供水管网异常，通过白化变换消除空间相关性，利用Hotelling's T²统计量进行异常检测和健康评估，可估算漏水量并分类异常类型。


<details>
  <summary>Details</summary>
Motivation: 供水管网异常检测需要处理异构的压力和流量传感器数据，传统方法依赖校准的水力模型，而本文旨在开发无需水力模型的统计框架，实现异常检测、分类和初步定位。

Method: 提出SICAMS框架：1) 对压力和流量数据进行白化变换消除空间相关性；2) 构建Hotelling's T²统计量进行异常检测；3) 通过回归模型估算漏水量；4) 开发启发式算法分类异常类型；5) 基于统计贡献度和拉普拉斯插值进行粗定位。

Result: 在BattLeDIM L-Town基准数据集上验证，显示高灵敏度和可靠的泄漏检测性能，即使在多重泄漏情况下仍保持鲁棒性，无需校准水力模型即可应用于实际运营环境。

Conclusion: SICAMS框架为供水管网异常管理提供了有效的统计方法，能够检测、分类和初步定位异常，估算漏水量，且不依赖水力模型，具有实际应用价值。

Abstract: This paper presents a unified framework, for the detection, classification, and preliminary localization of anomalies in water distribution networks using multivariate statistical analysis. The approach, termed SICAMS (Statistical Identification and Classification of Anomalies in Mahalanobis Space), processes heterogeneous pressure and flow sensor data through a whitening transformation to eliminate spatial correlations among measurements. Based on the transformed data, the Hotelling's $T^2$ statistic is constructed, enabling the formulation of anomaly detection as a statistical hypothesis test of network conformity to normal operating conditions. It is shown that Hotelling's $T^2$ statistic can serve as an integral indicator of the overall "health" of the system, exhibiting correlation with total leakage volume, and thereby enabling approximate estimation of water losses via a regression model. A heuristic algorithm is developed to analyze the $T^2$ time series and classify detected anomalies into abrupt leaks, incipient leaks, and sensor malfunctions. Furthermore, a coarse leak localization method is proposed, which ranks sensors according to their statistical contribution and employs Laplacian interpolation to approximate the affected region within the network. Application of the proposed framework to the BattLeDIM L-Town benchmark dataset demonstrates high sensitivity and reliability in leak detection, maintaining robust performance even under multiple leaks. These capabilities make the method applicable to real-world operational environments without the need for a calibrated hydraulic model.

</details>


### [55] [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)
*Matin Mortaheb,Erciyes Karakaya,Sennur Ulukus*

Main category: cs.LG

TL;DR: 提出多模态语义通信框架，通过文本查询引导视觉信息提取，使用跨模态注意力机制融合视觉和语言特征，根据相关性评分和信道带宽自适应传输图像块，实现任务驱动的语义通信。


<details>
  <summary>Details</summary>
Motivation: 传统基于transformer的语义通信方法在复杂多物体场景中表现不佳，因为自注意力机制缺乏明确的任务指导。需要一种能够整合用户查询来引导信息提取的框架，以提高复杂场景下的通信效率。

Method: 提出多模态语义通信框架，使用跨模态注意力机制融合视觉特征和语言嵌入，生成视觉数据的软相关性评分。根据评分和瞬时信道带宽，采用算法自适应传输图像块，使用独立训练的编码器-解码器对，总比特率匹配信道容量。

Result: 接收端能够重建和组合图像块，保留任务关键信息。该设计实现了灵活、目标驱动的语义通信，在复杂和带宽受限环境中具有高效性。

Conclusion: 提出的多模态语义通信框架通过整合文本查询来引导信息提取，解决了复杂场景中自注意力缺乏任务指导的问题，实现了高效、自适应的语义通信，适用于远程呈现、增强现实和遥感等应用。

Abstract: Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

</details>


### [56] [FrontierCS: Evolving Challenges for Evolving Intelligence](https://arxiv.org/abs/2512.15699)
*Qiuyang Mang,Wenhao Chai,Zhifei Li,Huanzhi Mao,Shang Zhou,Alexander Du,Hanchen Li,Shu Liu,Edwin Chen,Yichuan Wang,Xieting Chu,Zerui Cheng,Yuan Xu,Tian Xia,Zirui Wang,Tianneng Shi,Jianzhu Yao,Yilong Zhao,Qizheng Zhang,Charlie Ruan,Zeyu Shen,Kaiyuan Liu,Runyuan He,Dong Xing,Zerui Li,Zirong Zeng,Yige Jiang,Lufeng Cheng,Ziyi Zhao,Youran Sun,Wesley Zheng,Meiyuwang Zhang,Ruyi Ji,Xuechang Tu,Zihan Zheng,Zexing Chen,Kangyang Zhou,Zhaozi Wang,Jingbang Chen,Aleksandra Korolova,Peter Henderson,Pramod Viswanath,Vijay Ganesh,Saining Xie,Zhuang Liu,Dawn Song,Sewon Min,Ion Stoica,Joseph E. Gonzalez,Jingbo Shang,Alvin Cheung*

Main category: cs.LG

TL;DR: FrontierCS是一个包含156个开放问题的计算机科学基准测试，专注于最优解未知但可客观评估的问题，要求模型通过编写可执行程序而非直接答案来解决问题，评估显示前沿推理模型仍远落后于人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注已知最优解的任务，而计算机科学前沿存在许多最优解未知但可客观评估的开放问题，需要一个新的基准来评估模型在这些挑战性任务上的表现。

Method: 创建了包含156个开放问题的基准测试，涵盖算法问题和研究问题，每个问题都提供专家参考解决方案和自动评估器。问题由CS博士、顶级竞赛编程参与者和问题设计者设计和评审。

Result: 实证研究发现：前沿推理模型在算法和研究两个轨道上都远落后于人类专家；仅增加推理预算无法缩小这一差距；模型往往过度优化生成仅能工作的代码，而不是发现高质量的算法和系统设计。

Conclusion: FrontierCS提供了一个位于计算机科学难度前沿的基准测试，结合了开放设计、可测量进展和专家策划，揭示了当前模型在解决开放计算机科学问题方面的局限性。

Abstract: We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [57] [Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning](https://arxiv.org/abs/2512.14709)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 该论文提出将Transformer自注意力机制解释为近似的向量符号架构(VSA)，用代数视角分析语言模型的推理行为与失败模式，并提出了VSA启发的架构改进方案。


<details>
  <summary>Details</summary>
Motivation: Transformer语言模型展现出类似推理的行为，但在需要稳定符号操作的任务上仍然脆弱。本文旨在通过向量符号架构的统一视角来解释这些现象，理解注意力机制如何实现近似的符号计算。

Method: 将自注意力和残差流解释为近似的VSA：查询和键定义角色空间，值编码填充物，注意力权重执行软解绑定，残差连接实现多个绑定结构的叠加。基于此视角分析思维链、程序推理和记忆增强工具使用，并提出VSA启发的架构偏置，包括显式绑定/解绑定头和超维记忆层。

Result: 建立了Transformer内部机制与向量符号计算之间的对应关系，解释了变量混淆和逻辑相关提示不一致等特征性失败模式。提出了测量"VSA相似度"和逻辑组合性的指标，以及促进角色-填充物分离和鲁棒叠加的训练目标。

Conclusion: 将注意力视为软向量符号计算为构建更可解释和逻辑可靠推理系统提供了原则性途径。该视角有助于理解Transformer的推理能力与局限性，并为改进架构设计提供了理论基础。

Abstract: Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries and keys define role spaces, values encode fillers, attention weights perform soft unbinding, and residual connections realize superposition of many bound structures. We use this algebraic lens to relate transformer internals to chain-of-thought traces, program-based reasoning, and memory-augmented tool use, and to explain characteristic failure modes such as variable confusion and inconsistency across logically related prompts. Building on this perspective, we propose VSA-inspired architectural biases, including explicit binding/unbinding heads and hyperdimensional memory layers, and training objectives that promote role-filler separation and robust superposition. Finally, we outline metrics for measuring "VSA-likeness" and logical compositionality, and pose theoretical and architectural open problems. Overall, the paper argues that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and logically reliable reasoning systems.

</details>


### [58] [GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge](https://arxiv.org/abs/2512.14766)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Jiaoyan Chen,Steffen Staab,Yuan He,Evgeny Kharlamov*

Main category: cs.AI

TL;DR: 论文提出了一种在知识图谱不完整情况下的评估方法，并开发了自适应图推理智能体（GR-Agent）来解决不完整知识图谱上的问答问题


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱问答（KGQA）基准大多假设知识图谱是完整的，而现实中的知识图谱往往不完整，许多事实缺失，需要从现有事实中推理得出答案。这种不完整性被现有评估方法忽视，导致对模型推理能力的评估不准确。

Method: 1. 提出构建不完整知识图谱基准的方法论：移除直接支持三元组，但保留推理答案所需的替代推理路径；2. 开发自适应图推理智能体（GR-Agent）：从知识图谱构建交互环境，将KGQA形式化为智能体与环境交互，使用图推理工具作为动作空间，维护潜在支持推理证据的记忆。

Result: 实验表明：1. 现有方法在不完整性下性能持续下降，凸显其推理能力有限；2. GR-Agent在完整和不完整设置下均优于非训练基线方法，与基于训练的方法性能相当。

Conclusion: 论文填补了知识图谱不完整性评估的空白，提出的GR-Agent通过智能体-环境交互框架有效处理不完整知识图谱上的推理任务，为KGQA研究提供了更现实的评估基准和解决方案。

Abstract: Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.

</details>


### [59] [IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection](https://arxiv.org/abs/2512.14792)
*Roman Nekrasov,Stefano Fossati,Indika Kumara,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.AI

TL;DR: 该研究通过结构化配置知识注入，将LLM生成Terraform代码的整体成功率从27.1%提升至62.6%，但发现意图对齐存在瓶颈，揭示了"正确性-一致性差距"。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在生成正确且意图对齐的基础设施即代码方面成功率较低，特别是在Terraform代码生成中存在技术正确性和用户意图对齐的双重挑战。

Method: 1. 增强IaC-Eval基准测试，增加云仿真和自动错误分析；2. 开发LLM辅助IaC代码生成的错误分类法；3. 实施从朴素检索增强生成到图RAG的知识注入技术，包括图组件的语义丰富化和资源间依赖关系建模。

Result: 基线LLM性能较差（整体成功率27.1%），注入结构化配置知识后，技术验证成功率提升至75.3%，整体成功率提升至62.6%。然而意图对齐出现平台期，表明LLM能成为熟练的"编码者"但在满足细微用户意图方面仍是有限的"架构师"。

Conclusion: 研究揭示了"正确性-一致性差距"，即LLM在技术正确性方面可以显著提升，但在理解并满足复杂用户意图方面仍有局限，需要进一步研究如何提升LLM作为"架构师"的能力。

Abstract: Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a "Correctness-Congruence Gap" where LLMs can become proficient "coders" but remain limited "architects" in fulfilling nuanced user intent.

</details>


### [60] [AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally](https://arxiv.org/abs/2512.14910)
*Nadine Angela Cantonjos,Arpita Biswas*

Main category: cs.AI

TL;DR: AgroAskAI是一个用于农业气候适应的多智能体推理系统，通过模块化角色架构协调自主智能体，整合实时工具和数据，为农村社区提供可操作的气候适应决策支持。


<details>
  <summary>Details</summary>
Motivation: 农村农业地区面临干旱、强降雨和天气模式变化等气候相关风险的损害，需要适应性风险管理解决方案和决策策略。现有系统多为单智能体模型或仅用于静态功能的多智能体框架，缺乏支持动态协作推理和上下文感知输出的架构。

Method: 提出AgroAskAI多智能体推理系统，采用模块化、角色专业化的架构，使用责任链方法协调自主智能体，整合实时工具和数据集。系统内置治理机制减少幻觉，支持内部反馈和多语言交互。

Result: 在常见农业气候适应查询上的实验表明，通过额外工具和提示优化，AgroAskAI能够提供更可操作、更接地气、更具包容性的输出结果。

Conclusion: AgroAskAI展示了智能体AI在农业气候适应中提供可持续和负责任决策支持的潜力，特别关注弱势农村社区的需求。

Abstract: Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.

</details>


### [61] [Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study](https://arxiv.org/abs/2512.15044)
*Wenwen Xie,Geng Sun,Ruichen Zhang,Xuejie Liu,Yinqiu Liu,Jiacheng Wang,Dusit Niyato,Ping Zhang*

Main category: cs.AI

TL;DR: 本文探讨了智能体人工智能在集成感知与通信系统中的应用价值，提出了一个新型的智能体ISAC框架，并通过案例研究验证了其在优化ISAC性能方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 随着无线环境日益动态复杂，ISAC系统需要更智能的处理和更自主的操作来保持效率和适应性，而智能体人工智能通过持续感知-推理-行动循环为解决这些挑战提供了可行方案。

Method: 首先全面回顾了智能体AI和ISAC系统的关键特性；其次展示了ISAC系统的几种常见优化方法，并突出了基于生成式AI的智能体AI的显著优势；然后提出了一个新型的智能体ISAC框架，并通过案例研究验证其性能优越性。

Result: 提出的智能体ISAC框架在优化ISAC性能方面表现出优越性，案例研究验证了其有效性。

Conclusion: 智能体AI为ISAC系统提供了智能、自主、高效操作的解决方案，未来需要进一步研究智能体AI在ISAC系统中的具体应用方向和发展前景。

Abstract: Integrated sensing and communication (ISAC) has emerged as a key development direction in the sixth-generation (6G) era, which provides essential support for the collaborative sensing and communication of future intelligent networks. However, as wireless environments become increasingly dynamic and complex, ISAC systems require more intelligent processing and more autonomous operation to maintain efficiency and adaptability. Meanwhile, agentic artificial intelligence (AI) offers a feasible solution to address these challenges by enabling continuous perception-reasoning-action loops in dynamic environments to support intelligent, autonomous, and efficient operation for ISAC systems. As such, we delve into the application value and prospects of agentic AI in ISAC systems in this work. Firstly, we provide a comprehensive review of agentic AI and ISAC systems to demonstrate their key characteristics. Secondly, we show several common optimization approaches for ISAC systems and highlight the significant advantages of generative artificial intelligence (GenAI)-based agentic AI. Thirdly, we propose a novel agentic ISAC framework and prensent a case study to verify its superiority in optimizing ISAC performance. Finally, we clarify future research directions for agentic AI-based ISAC systems.

</details>


### [62] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)
*Jinwu Hu,Dongjin Yang,Langyu Bian,Zhiquan Wen,Yufeng Wang,Yaofo Chen,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.AI

TL;DR: CogER是一个受人类分层推理启发的弹性推理框架，通过动态选择最适合每个查询的推理策略来平衡推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理策略主要依赖LLM自身的快慢模式（如o1思考），难以在不同难度查询间平衡推理效率和准确性。

Method: 1) 评估查询复杂度并分配到预定义级别；2) 将策略选择建模为马尔可夫决策过程，用强化学习训练CogER-Agent；3) 引入认知工具辅助推理，使LLM能在思维链中自主调用外部工具。

Result: CogER在In-Domain任务上平均精确匹配相对提升至少13%，在Out-of-Domain任务上相对提升8%，优于最先进的测试时缩放方法。

Conclusion: CogER通过动态策略选择和工具辅助推理，有效解决了LLM在不同难度查询中平衡效率与准确性的挑战。

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.

</details>


### [63] [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)
*Mohsen Nafar,Michael Römer,Lin Xie*

Main category: cs.AI

TL;DR: 提出基于聚类的变量排序框架，通过将变量分组来缩小动态排序的搜索空间，在最大加权独立集问题上显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 离散优化中，松弛决策图通过节点合并提供对偶边界，但边界质量严重依赖变量排序和合并决策。动态变量排序能收紧边界但计算开销大，需要在边界质量和计算效率间取得平衡

Method: 提出基于聚类的变量排序框架：先将变量分区成簇，再基于结构分解指导排序过程。研究两种策略：1) 簇到簇策略，按问题特定聚合标准顺序处理簇；2) 选取排序策略，从每个簇迭代选择和排序代表性变量。针对MWISP提出两种设置簇数量的策略，并嵌入到基于决策图的分支定界算法中

Result: 在最大加权独立集问题的基准实例上，相比标准动态变量排序基线，提出的方法能持续降低计算成本

Conclusion: 基于聚类的变量排序框架有效平衡了边界质量和计算效率，通过缩小搜索空间显著降低了动态排序的计算开销，为离散优化中的决策图编译提供了更高效的变量排序方法

Abstract: Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.

</details>


### [64] [ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I](https://arxiv.org/abs/2512.15298)
*Seok-Hyun Ga,Chun-Yen Chang*

Main category: cs.AI

TL;DR: 该研究使用2025年韩国高考地球科学I部分，分析GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro等大语言模型的多模态科学推理能力和认知局限性，发现模型存在感知-认知鸿沟、计算-概念化差异和过程幻觉等问题，为设计"AI抗性题目"提供依据。


<details>
  <summary>Details</summary>
Motivation: 随着学生使用AI完成作业的情况日益普遍，学术诚信和评估有效性受到威胁。研究旨在深入分析先进大语言模型在科学推理方面的能力和局限性，为解决AI未经授权使用问题提供实证基础。

Method: 使用2025年韩国高考地球科学I部分作为测试材料，设计三种实验条件（整页输入、单项输入和优化多模态输入），对GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro进行定量和定性分析，评估模型在不同数据结构下的表现。

Result: 非结构化输入因分割和OCR失败导致性能显著下降；即使在优化条件下，模型仍表现出基本推理缺陷。定性分析发现"感知错误"占主导地位，存在感知-认知鸿沟、计算-概念化差异和过程幻觉等认知弱点。

Conclusion: 通过利用AI的认知弱点（特别是感知与认知之间的鸿沟），教育工作者可以设计针对性的"AI抗性题目"，区分真实学生能力与AI生成回答，确保评估的公平性。

Abstract: The rapid development of Generative AI is bringing innovative changes to education and assessment. As the prevalence of students utilizing AI for assignments increases, concerns regarding academic integrity and the validity of assessments are growing. This study utilizes the Earth Science I section of the 2025 Korean College Scholastic Ability Test (CSAT) to deeply analyze the multimodal scientific reasoning capabilities and cognitive limitations of state-of-the-art Large Language Models (LLMs), including GPT-4o, Gemini 2.5 Flash, and Gemini 2.5 Pro. Three experimental conditions (full-page input, individual item input, and optimized multimodal input) were designed to evaluate model performance across different data structures. Quantitative results indicated that unstructured inputs led to significant performance degradation due to segmentation and Optical Character Recognition (OCR) failures. Even under optimized conditions, models exhibited fundamental reasoning flaws. Qualitative analysis revealed that "Perception Errors" were dominant, highlighting a "Perception-Cognition Gap" where models failed to interpret symbolic meanings in schematic diagrams despite recognizing visual data. Furthermore, models demonstrated a "Calculation-Conceptualization Discrepancy," successfully performing calculations while failing to apply the underlying scientific concepts, and "Process Hallucination," where models skipped visual verification in favor of plausible but unfounded background knowledge. Addressing the challenge of unauthorized AI use in coursework, this study provides actionable cues for designing "AI-resistant questions" that target these specific cognitive vulnerabilities. By exploiting AI's weaknesses, such as the gap between perception and cognition, educators can distinguish genuine student competency from AI-generated responses, thereby ensuring assessment fairness.

</details>


### [65] [Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations](https://arxiv.org/abs/2512.15388)
*Reinhard Moratz,Niklas Daute,James Ondieki,Markus Kattenbeck,Mario Krajina,Ioannis Giannopoulos*

Main category: cs.AI

TL;DR: 该论文通过定性空间关系改进大型语言模型为行人提供路线指引的能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在提供行人路线指引方面存在局限性，特别是在空间关系的准确表达上，需要改进其空间推理能力

Method: 使用定性空间关系来增强大型语言模型，可能包括空间关系表示、推理框架和指令生成方法

Result: 改进后的模型能够生成更准确、更符合人类认知的行人路线指引

Conclusion: 定性空间关系是提升大型语言模型空间导航能力的关键，能够显著改善行人路线指引的质量

Abstract: This paper deals with improving the capabilities of Large Language Models (LLM) to provide route instructions for pedestrian wayfinders by means of qualitative spatial relations.

</details>


### [66] [Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat](https://arxiv.org/abs/2512.15435)
*Stefan Edelkamp*

Main category: cs.AI

TL;DR: 提出一个通过自学习扩展人类专家游戏数据库的通用框架，用于改进多人纸牌游戏早期决策的预测准确性


<details>
  <summary>Details</summary>
Motivation: 在多人纸牌游戏中，早期阶段如叫牌、游戏选择和初始出牌对成功至关重要，但当前计算限制下这些决策依赖于有限的人类专家游戏统计信息

Method: 开发通用自学习框架，通过AI自玩生成数百万游戏扩展数据库，使用完美特征哈希函数处理压缩表，实现持续自我改进的游戏引擎

Result: 在Skat游戏案例研究中，该自动化方法能够支持游戏中的各种决策

Conclusion: 通过自学习扩展人类游戏数据库的框架能够有效改进纸牌游戏早期决策的预测准确性

Abstract: In multi-player card games such as Skat or Bridge, the early stages of the game, such as bidding, game selection, and initial card selection, are often more critical to the success of the play than refined middle- and end-game play. At the current limits of computation, such early decision-making resorts to using statistical information derived from a large corpus of human expert games. In this paper, we derive and evaluate a general bootstrapping outer-learning framework that improves prediction accuracy by expanding the database of human games with millions of self-playing AI games to generate and merge statistics. We implement perfect feature hash functions to address compacted tables, producing a self-improving card game engine, where newly inferred knowledge is continuously improved during self-learning. The case study in Skat shows that the automated approach can be used to support various decisions in the game.

</details>


### [67] [Intent-Driven UAM Rescheduling](https://arxiv.org/abs/2512.15462)
*Jeongseok Kim,Kangjin Kim*

Main category: cs.AI

TL;DR: 该论文提出了一种结合ASP和MILP的集成框架，用于处理城市空中交通（UAM）垂直起降场的动态调度问题，支持模糊的人类重调度请求。


<details>
  <summary>Details</summary>
Motivation: 城市空中交通（UAM）垂直起降场资源受限，需要高效的调度系统。现有调度问题通常采用混合整数线性规划（MILP）和资源受限项目调度问题（RCPSP）建模，但缺乏处理动态操作需求和人类模糊重调度请求的能力。

Method: 1. 采用混合整数线性规划（MILP）和资源受限项目调度问题（RCPSP）建模调度问题；2. 使用三值逻辑解释模糊的用户意图；3. 结合决策树和答案集编程（ASP），提出ASP与MILP的集成系统框架；4. 该框架优化调度并透明地支持人类输入。

Result: 开发了一个集成框架，能够优化UAM调度，同时处理动态操作需求和模糊的人类重调度请求，为可解释、自适应的UAM调度提供了稳健的结构。

Conclusion: 提出的ASP与MILP集成框架为城市空中交通垂直起降场调度提供了一个强大的解决方案，能够有效处理动态需求和人类模糊输入，实现可解释、自适应的调度系统。

Abstract: Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.

</details>


### [68] [Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision](https://arxiv.org/abs/2512.15489)
*Wei Du,Shubham Toshniwal,Branislav Kisacanin,Sadegh Mahdavi,Ivan Moshkov,George Armstrong,Stephen Ge,Edgar Minasyan,Feng Chen,Igor Gitman*

Main category: cs.AI

TL;DR: Nemotron-Math是一个包含750万条数学推理轨迹的大规模数据集，整合了AoPS竞赛题和StackExchange数学问题，支持多种推理模式和Python工具集成，在数学推理任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据集在推理风格多样性、长形式轨迹和工具集成方面存在局限，需要更高质量、更大规模的监督数据来提升数学推理模型的性能。

Method: 利用GPT-OSS-120B的多模式生成能力，创建包含高、中、低三种推理模式的数据集，整合85K AoPS竞赛题和262K StackExchange数学问题，开发序列分桶策略加速长上下文训练。

Result: Nemotron-Math在匹配的AoPS问题上持续优于原始OpenMathReasoning，StackExchange-Math的加入显著提高了鲁棒性和泛化能力，在AIME 2024和2025上实现了100% maj@16准确率。

Conclusion: Nemotron-Math通过大规模、多样化的数学推理数据集和高效的训练策略，实现了数学推理任务的最先进性能，为数学AI研究提供了有价值的资源。

Abstract: High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.
  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.
  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.

</details>


### [69] [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
*Zhangde Song,Jieyu Lu,Yuanqi Du,Botao Yu,Thomas M. Pruyn,Yue Huang,Kehan Guo,Xiuzhe Luo,Yuanhao Qu,Yi Qu,Yinkai Wang,Haorui Wang,Jeff Guo,Jingru Gan,Parshin Shojaee,Di Luo,Andres M Bran,Gen Li,Qiyuan Zhao,Shao-Xiong Lennon Luo,Yuxuan Zhang,Xiang Zou,Wanru Zhao,Yifan F. Zhang,Wucheng Zhang,Shunan Zheng,Saiyang Zhang,Sartaaj Takrim Khan,Mahyar Rajabi-Kochi,Samantha Paradi-Maropakis,Tony Baltoiu,Fengyu Xie,Tianyang Chen,Kexin Huang,Weiliang Luo,Meijing Fang,Xin Yang,Lixue Cheng,Jiajun He,Soha Hassoun,Xiangliang Zhang,Wei Wang,Chandan K. Reddy,Chao Zhang,Zhiling Zheng,Mengdi Wang,Le Cong,Carla P. Gomes,Chang-Yu Hsieh,Aditya Nandy,Philippe Schwaller,Heather J. Kulik,Haojun Jia,Huan Sun,Seyed Mohamad Moosavi,Chenru Duan*

Main category: cs.AI

TL;DR: 该论文提出了一个面向科学发现的两阶段评估框架(SDE)，用于评估大语言模型在真实科学研究场景中的能力，发现当前LLMs在科学发现方面存在系统性弱点，距离通用科学"超级智能"还很遥远。


<details>
  <summary>Details</summary>
Motivation: 当前科学基准测试主要评估去语境化的知识，忽略了驱动科学发现的迭代推理、假设生成和观察解释等关键能力。需要建立一个更贴近真实科学研究过程的评估框架。

Method: 引入基于场景的基准测试，涵盖生物学、化学、材料科学和物理学领域。由领域专家定义真实研究项目，将其分解为模块化研究场景，从中抽样验证问题。采用两阶段评估：1) 场景关联问题的准确率；2) 项目级性能评估，包括提出可测试假设、设计模拟/实验、解释结果等。

Result: 应用SDE框架评估最先进的LLMs发现：1) 相对于通用科学基准存在持续性能差距；2) 模型规模和推理能力的扩展收益递减；3) 不同提供商顶级模型存在系统性弱点；4) 研究场景中性能差异大导致最佳模型选择不稳定；5) LLMs在多种科学发现项目中已显示出潜力。

Conclusion: 当前所有LLMs距离通用科学"超级智能"还很遥远，但已展现出在科学发现中的潜力。SDE框架为LLMs的发现相关评估提供了可复现的基准，并为推动其向科学发现方向发展指明了实用路径。

Abstract: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific "superintelligence". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.

</details>


### [70] [A Decision-Theoretic Approach for Managing Misalignment](https://arxiv.org/abs/2512.15584)
*Daniel A. Herrmann,Abinav Chari,Isabelle Qian,Sree Sharvesh,B. A. Levinstein*

Main category: cs.AI

TL;DR: 论文提出了一个决策理论框架，分析在不确定性下何时应将决策委托给AI系统，强调需要在价值对齐、认知准确性和行动范围之间权衡，区分了通用委托和情境特定委托的不同要求。


<details>
  <summary>Details</summary>
Motivation: 现有价值对齐文献主要关注如何塑造AI价值观，但较少研究在不确定性条件下，如何确定不完美的对齐何时足够好以证明委托决策的合理性。需要建立原则性方法来评估何时AI在特定情境下足够对齐。

Method: 引入正式的决策理论框架，精确分析委托决策中的权衡，考虑委托者对AI价值对齐、认知准确性和行动范围的不确定性。开发了新的评分框架来量化这种事前决策。

Result: 分析揭示了两种委托场景的明显区别：通用委托需要近乎完美的价值对齐和完全的认知信任（实践中很少满足），而情境特定委托即使在显著价值不对齐的情况下也可能是最优的，因为AI的更高准确性或更广行动范围可能提供更好的整体决策问题。

Conclusion: 研究提供了原则性方法来确定AI在特定情境下何时足够对齐，将重点从实现完美对齐转向在不确定性下管理委托的风险和回报，为理性委托决策提供了理论基础。

Abstract: When should we delegate decisions to AI systems? While the value alignment literature has developed techniques for shaping AI values, less attention has been paid to how to determine, under uncertainty, when imperfect alignment is good enough to justify delegation. We argue that rational delegation requires balancing an agent's value (mis)alignment with its epistemic accuracy and its reach (the acts it has available). This paper introduces a formal, decision-theoretic framework to analyze this tradeoff precisely accounting for a principal's uncertainty about these factors. Our analysis reveals a sharp distinction between two delegation scenarios. First, universal delegation (trusting an agent with any problem) demands near-perfect value alignment and total epistemic trust, conditions rarely met in practice. Second, we show that context-specific delegation can be optimal even with significant misalignment. An agent's superior accuracy or expanded reach may grant access to better overall decision problems, making delegation rational in expectation. We develop a novel scoring framework to quantify this ex ante decision. Ultimately, our work provides a principled method for determining when an AI is aligned enough for a given context, shifting the focus from achieving perfect alignment to managing the risks and rewards of delegation under uncertainty.

</details>


### [71] [Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning](https://arxiv.org/abs/2512.15662)
*Jiaqi Xu,Cuiling Lan,Xuejin Chen,Yan LU*

Main category: cs.AI

TL;DR: STC框架在单个模型中交织推理与自我批判，通过混合强化学习优化推理质量和自我评估，在数学推理基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型将推理与验证解耦，要么缺乏即时反馈，要么依赖外部验证器增加系统复杂性。受人类批判性思维启发，需要统一框架在单模型中交织推理与自我批判。

Method: 提出Stepwise Think-Critique (STC)框架，在每一步推理中交织推理和自我批判。使用混合强化学习目标，结合推理奖励和批判一致性奖励，联合优化推理质量和自我评估。

Result: 在数学推理基准测试中，STC表现出强大的批判性思维能力，产生更可解释的推理轨迹，向具有内置批判性思维的大语言模型迈进了一步。

Conclusion: STC框架通过单模型内交织推理与自我批判，有效模拟人类批判性思维，为开发具有内置批判性思维能力的LLMs提供了有前景的方向。

Abstract: Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.

</details>


### [72] [Explaining the Reasoning of Large Language Models Using Attribution Graphs](https://arxiv.org/abs/2512.15663)
*Chase Walker,Rickard Ewetz*

Main category: cs.AI

TL;DR: CAGE框架通过构建有向属性图来改进大语言模型的解释方法，量化每个生成内容如何受到提示和先前生成的影响，相比现有方法将忠实度平均提升达40%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然能力强大但推理过程不透明，存在安全和信任问题。现有的上下文归因方法通过将生成标记直接关联到提示来解释模型行为，但这种方法不完整，忽略了生成过程中的代际影响。

Method: 提出CAGE框架，构建一个有向属性图来量化每个生成内容如何受到提示和所有先前生成的影响。该图保持因果关系和行随机性两个属性，通过沿图中路径边缘化中间贡献来计算上下文归因。

Result: 在多个模型、数据集、指标和方法上，CAGE显著提高了上下文归因的忠实度，平均提升达40%。

Conclusion: CAGE框架通过考虑生成过程中的代际影响，提供了更完整和忠实的大语言模型解释方法，解决了现有上下文归因方法的局限性。

Abstract: Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [73] [Consecutive-gap ratio distribution for crossover ensembles](https://arxiv.org/abs/2512.15390)
*Gerson C. Duarte-Filho,Julian Siegl,John Schliemann,J. Carlos Egues*

Main category: cond-mat.dis-nn

TL;DR: 该研究提出了一个双参数推测表达式，用于描述高斯正交系综（GOE）与泊松统计之间的交叉分布，这种交叉出现在具有无序局域场的各向同性海森堡自旋-1/2链中，表现出多体局域化（MBL）转变。


<details>
  <summary>Details</summary>
Motivation: 研究谱统计（如连续能隙比分布）可以揭示多体复杂系统的许多有趣性质。作者希望建立一个理论框架来描述GOE和泊松统计之间的交叉，这种交叉与多体局域化转变相关，并分析不同对称性条件下系统的行为差异。

Method: 1. 提出双参数推测表达式描述GOE-泊松统计交叉；2. 将交叉表示为参数空间中的流动模式，其中泊松统计作为固定点代表MBL相；3. 分析两种系统：无序局域场系统（显示MBL转变）和无序局域交换耦合系统（由于自旋旋转对称性无法达到MBL相）；4. 提出线性化随机微分方程组估计固定点；5. 研究连续状态马尔可夫过程，分析系统接近固定点的概率分布。

Result: 1. 建立了描述GOE-泊松统计交叉的双参数推测表达式；2. 发现无序局域场系统表现出清晰的MBL转变，泊松统计作为固定点；3. 无序局域交换耦合系统由于对称性无法达到MBL相，对有限尺寸效应更敏感，流动模式类似于二维随机游走；4. 提出了估计固定点的数学框架，并分析了系统接近固定点的概率分布特性。

Conclusion: 该研究为多体局域化转变提供了新的谱统计视角，建立了GOE-泊松统计交叉的理论框架。不同对称性条件导致系统行为的显著差异：无序局域场系统能实现MBL相，而无序局域交换耦合系统由于自旋旋转对称性无法达到真正的MBL相。提出的数学方法为分析这类系统的统计特性提供了有效工具。

Abstract: The study of spectrum statistics, such as the consecutive-gap ratio distribution, has revealed many interesting properties of many-body complex systems. Here we propose a two-parameter surmise expression for such distribution to describe the crossover between the Gaussian orthogonal ensemble (GOE) and Poisson statistics. This crossover is observed in the isotropic Heisenberg spin-$1/2$ chain with disordered local field, exhibiting the Many-Body Localization (MBL) transition. Inspired by the analysis of stability in dynamical systems, this crossover is presented as a flow pattern in the parameter space, with the Poisson statistics being the fixed point of the system, which represents the MBL phase. We also analyze an isotropic Heisenberg spin-$1/2$ chain with disordered local exchange coupling and a zero magnetic field. In this case, the system never achieves the MBL phase because of the spin rotation symmetry. This case is more sensitive to finite-size effects than the previous one, and thus the flow pattern resembles a two-dimensional random walk close to its fixed point. We propose a system of linearized stochastic differential equations to estimate this fixed point. We study the continuous-state Markov process that governs the probability of finding the system close to this fixed point as the disorder strength increases. In addition, we discuss the conditions under which the stationary probability distribution is given by a bivariate normal distribution.

</details>


### [74] [Interacting Hysterons with Asymptotically Small or Large Spans](https://arxiv.org/abs/2512.15449)
*Margot Teunisse,Martin van Hecke*

Main category: cond-mat.dis-nn

TL;DR: 研究磁滞元模型在两种物理极限下的行为：当磁滞元跨度远大于其他尺度时，系统行为简化；当跨度趋近于零时，磁滞元表现为相互作用的二元自旋；并建立了磁滞元与自旋系统的映射关系。


<details>
  <summary>Details</summary>
Motivation: 磁滞元模型虽然能描述复杂系统的序列响应和记忆效应，但即使简单的模型也表现出令人困惑的多种行为。研究旨在理解磁滞元参数对其集体行为的影响，并探索磁滞元模型与自旋模型之间的联系和差异。

Method: 研究磁滞元模型在两种物理极限下：1）当磁滞元跨度（两个磁滞转变之间的间隔）远大于其他尺度时；2）当磁滞元跨度趋近于零时。通过分析转移图（t-graphs）和雪崩行为，并建立磁滞元与成对强相互作用自旋之间的映射关系。

Result: 在第一种极限下，由于许多雪崩缺失，转移图中编码的路径范围变得有限；在第二种极限下，磁滞元表现为相互作用的二元自旋，需要雪崩才能展现非平凡路径。研究还表明，n个相互作用的磁滞元可以映射到2n个相互作用的自旋，尽管需要高度特定的相互作用。

Conclusion: 该工作深化了对磁滞元参数对其集体行为影响的理解，指出了基于自旋和基于磁滞元的复杂物质模型之间的联系和差异，为设计智能超材料提供了理论基础。

Abstract: Models of interacting hysteretic elements, called hysterons, capture the sequential response and complex memory effects in a wide range of complex systems and can guide the design of intelligent metamaterials. However, even simple models with few hysterons feature a bewildering number and variety of behaviors. Here we study the hysteron model in two physically relevant limits, where {the} response {of a hysteron system} is easier to understand. First, when the hysteron span - the gap between its two hysteretic transitions - dominates all other scales, the range of pathways encoded in transition graphs (t-graphs) becomes limited because many avalanches {are} absent. Second, when the hysteron span becomes vanishingly small, hysterons behave as interacting binary spins, {which require avalanches in order to} exhibit nontrivial pathways. Finally we show that hysterons can be mimicked by pairs of strongly interacting spins, {such} that collections of $n$ interacting hysterons can be mapped to $2n$ interacting spins, albeit {via} highly specific interactions. {Altogether,} our work provides a deeper understanding of the role of the hysteron parameters on their collective behavior, and points to connections and differences between spin- and hysteron-based models of complex matter.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [75] [Information-Theoretic Constraints on Variational Quantum Optimization: Efficiency Transitions and the Dynamical Lie Algebra](https://arxiv.org/abs/2512.14701)
*Jun Liang Tan*

Main category: quant-ph

TL;DR: 该论文从信息论角度研究变分量子算法的可扩展性限制，通过相干反馈控制建立了功提取与互信息的经验关系，发现量子纠缠相比经典Landauer界限有2倍优势，并识别出由动力学李代数维度控制的效率转变。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法是实现近期量子优势的主要候选方案，但其可扩展性受到"贫瘠高原"现象的限制。传统上将其归因于几何梯度消失，本文提出从信息论角度重新审视这一问题，探索量子反馈控制的信息论极限与算法可训练性边界之间的关系。

Method: 使用辅助量子比特介导的相干反馈控制方法，建立功提取与互信息的经验本构关系ΔE ≤ ηI(S:A)。通过缩放系统规模，分析动力学李代数维度对效率转变的影响，比较多项式复杂度与指数复杂度系统的不同行为。

Result: 发现量子纠缠相比经典Landauer界限提供2倍优势。识别出由动力学李代数维度控制的效率转变：多项式代数复杂度的系统保持持续正效率，而指数复杂度的系统在约6个量子比特时经历"效率崩溃"(η→0)。

Conclusion: 变分量子算法中的可训练性边界与量子反馈控制的信息论极限相关。动力学李代数维度是决定效率转变的关键因素，这为理解和克服"贫瘠高原"现象提供了新的信息论视角。

Abstract: Variational quantum algorithms are the leading candidates for near-term quantum advantage, yet their scalability is limited by the ``Barren Plateau'' phenomenon. While traditionally attributed to geometric vanishing gradients, we propose an information-theoretic perspective. Using ancilla-mediated coherent feedback, we demonstrate an empirical constitutive relation $ΔE \leq ηI(S:A)$ linking work extraction to mutual information, with quantum entanglement providing a factor-of-2 advantage over classical Landauer bounds. By scaling the system size, we identify a distinct efficiency transition governed by the dimension of the Dynamical Lie Algebra. Systems with polynomial algebraic complexity exhibit sustained positive efficiency, whereas systems with exponential complexity undergo an ``efficiency collapse'' ($η\to 0$) at $N \approx 6$ qubits. These results suggest that the trainability boundary in variational algorithms correlates with information-theoretic limits of quantum feedback control.

</details>


### [76] [Quantum Resource Analysis of Low-Round Keccak/SHA-3 Preimage Attack: From Classical 2^57.8 to Quantum 2^28.9 using Qiskit Modeling](https://arxiv.org/abs/2512.14759)
*Ramin Rezvani Gilkolae*

Main category: quant-ph

TL;DR: 论文对使用Grover算法加速经典3轮Keccak-256原像攻击进行了硬件意识分析，发现尽管理论上量子加速从T_cl=2^{57.8}到T_qu=2^{28.9}是数学上正确的，但实际实现开销极大，使得攻击在资源和运行时间维度都完全不可行。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算机对SHA-3（Keccak-256）密码安全性的实际威胁，特别关注Grover算法在加速原像攻击时的实际实现开销，强调理论量子加速与实际硬件约束之间的差距。

Method: 使用Qiskit进行电路合成，分析3轮Keccak量子预言机实现的具体资源需求，包括Toffoli门数量、逻辑量子比特需求、总双量子比特门数、物理量子比特需求（考虑量子纠错）以及执行时间估算。

Result: 3轮Keccak量子预言机需要：9,600个Toffoli门（含可逆计算）；3,200个逻辑量子比特；7.47×10^{13}个总双量子比特门；320万个物理量子比特（含纠错）；执行时间从0.12年（43天）到2,365年以上。这些资源需求极其庞大，使得量子攻击不可行。

Conclusion: SHA-3的安全性不会受到量子计算机的原像攻击威胁。Grover算法的优雅渐近理论隐藏了极其庞大的工程开销，从资源和实现角度看量子方法都不可行。强调硬件感知的复杂性分析在量子密码分析中的关键重要性。

Abstract: This paper presents a hardware-conscious analysis of the quantum acceleration of the classical 3-round Keccak-256 preimage attack using Grover's Algorithm. While the theoretical quantum speed-up from T_cl=2^{57.8} (classical) to T_qu = 2^{28.9} (quantum) is mathematically sound, the practical implementation overhead is so extreme that attacks remain wholly infeasible in both resource and runtime dimensions. Using Qiskit-based circuit synthesis, we derive that a 3-round Keccak quantum oracle requires: 9,600 Toffoli gates (with uncomputation for reversibility); 3,200 logical qubits (1,600 state + 1,600 auxiliary); 7.47 * 10^{13} total 2-qubit gates (full Grover search); 3.2 million physical qubits (with quantum error correction)PROHIBITIVE; 0.12 years (43 days) to 2,365+ years execution time, depending on machine assumptions. These barriers -- particularly the physical qubit requirements, circuit depth, and error accumulation -- render the quantum attack infeasible for any foreseeable quantum computer. Consequently, SHA-3 security is not threatened by quantum computers for preimage attacks. We emphasize the critical importance of hardware-aware complexity analysis in quantum cryptanalysis: the elegant asymptotic theory of Grover's Algorithm hides an engineering overhead so prohibitive that the quantum approach becomes infeasible from both resource and implementation perspectives.

</details>


### [77] [Dawn and Twilight Time in Quantum Tunneling](https://arxiv.org/abs/2512.14809)
*Tinglong Feng,Jesse Moes,Tomislav Prokopec*

Main category: quant-ph

TL;DR: 该论文研究了量子力学共振模型中亚稳态衰变的完整时间演化，提出了"黎明时间"和"黄昏时间"两个可计算的时间尺度，并展示了衰变核的通用极点-分支分解结构。


<details>
  <summary>Details</summary>
Motivation: 研究亚稳态衰变的时间演化特征，特别是早期偏离指数衰变和晚期幂律尾部的现象，为量子衰变过程提供更完整的理论描述。

Method: 采用基于实时通量的衰变率定义方法，对一维量子力学共振模型进行完整分析，提出衰变核的极点-分支分解结构，并定义两个可计算的时间尺度。

Result: 获得了衰变核的通用分解结构，推导出黎明时间和黄昏时间的计算公式，其中黄昏时间可通过Lambert W函数以闭合形式表示。对于特定势垒模型获得了厚势垒公式，并阐明了衰变率、振荡周期和透射概率之间的关系。

Conclusion: 该研究为量子衰变过程提供了完整的谱图描述，所提出的时间尺度计算方法无需拟合即可揭示参数依赖性，并且该框架可自然扩展到量子场论中的真空衰变问题。

Abstract: Metastable decay exhibits a familiar exponential regime bracketed by early-time deviations and late-time power-law tails. We adopt the real-time, flux-based definition of the decay rate in the spirit of Andreassen et al.\ direct method and present a complete analysis of one-dimensional quantum-mechanical resonance models. We show that the kernel admits a universal pole--plus--branch decomposition and use it to define two computable time scales: a dawn time, when a single resonant contribution starts dominating and exponential decay sets in, and a twilight time, when the branch-cut tail overtakes exponential decay. The latter can be expressed in closed form via the Lambert $W$ function, making its parametric dependence manifest without fitting. For square, modified square, and Pöschl--Teller barriers we obtain simple thick-barrier formulas, clarify the relation $ΓT = T_{\text{trans}}$ between the decay rate $Γ$, oscillation period $T$, and transmission probability $T_{\text{trans}}$, and indicate how our spectral picture can be naturally extended to quantum field theoretic vacuum decay.

</details>


### [78] [The entangling power of non-entangling channels](https://arxiv.org/abs/2512.14819)
*Julien Pinske,Jan Sperling,Klaus Mølmer*

Main category: quant-ph

TL;DR: 非纠缠操作在某些条件下可以放大已有纠缠，但只有能以非零概率生成纠缠的操作才能增加量子态的施密特数，这与LOCC操作形成鲜明对比


<details>
  <summary>Details</summary>
Motivation: 研究非纠缠操作如何影响量子纠缠，特别是探索那些不能生成纠缠但可能放大已有纠缠的过程，以及概率性操作在纠缠生成中的作用

Method: 通过分析非纠缠操作与施密特数的关系，引入随机非纠缠映射的概念，设计量子通道的施密特数来量化通道概率性生成纠缠的能力，并建立通道非纠缠性与对偶映射保持见证者性质之间的等价关系

Result: 发现非纠缠操作只有在能以非零概率生成纠缠时才能增加施密特数；某些非纠缠操作在选择特定测量结果时会变得纠缠；建立了通道非纠缠性与对偶映射保持见证者性质之间的等价关系；推导了违反即表示过程生成纠缠的贝尔式不等式

Conclusion: 概率性操作在纠缠生成中扮演关键角色，随机非纠缠映射是更严格的非纠缠操作类别，量子通道的施密特数为量化纠缠生成能力提供了新工具，对偶映射性质为判断通道是否纠缠提供了新判据

Abstract: There are processes that cannot generate entanglement but may, nevertheless, amplify entanglement already present in a system. Here, we show that a non-entangling operation can increase the Schmidt number of a quantum state only if it can generate entanglement with some non-zero probability. This is in stark contrast to the case where the parties of a quantum network are only able to control their joint state by local operations and classical communication (LOCC). There, being able to apply operations probabilistically (stochastic LOCC) does not increase the Schmidt number. Our findings show that certain non-entangling operations become entangling when selecting on specific measurement outcomes. This naturally leads us to the class of stochastically non-entangling maps, being those that cannot generate entanglement even probabilistically. Intrigued by this finding, we devise a Schmidt number for quantum channels that quantifies whether a channel can generate entanglement probabilistically. Moreover, we show that a channel is non-entangling if and only if its dual map is witness-preserving -- it takes entanglement witnesses to witnesses. Based on this finding, we derive Bell-like inequalities whose violation signals that a process generates entanglement.

</details>


### [79] [Growth and spreading of quantum resources under random circuit dynamics](https://arxiv.org/abs/2512.14827)
*Sreemayee Aditya,Xhek Turkeshi,Piotr Sierant*

Main category: quant-ph

TL;DR: 研究量子多体动力学中资源（魔法、相干性、费米子非高斯性）在随机砖墙电路中的时空演化规律，发现资源生成门产生"上升-峰值-下降"的普适行为，而非资源生成门则导致资源的弹道扩散。


<details>
  <summary>Details</summary>
Motivation: 量子多体动力学自然产生非经典关联，这些关联可以用量子资源理论来描述。研究这些资源（特别是量子魔法资源、相干性和费米子非高斯性）在局部电路中的时空演化，为了解结构化量子多体系统的资源动力学提供基准。

Method: 在一维量子比特链的子系统中，通过随机砖墙电路演化来追踪量子资源。研究两种类型的电路：资源生成门（产生目标资源）和非资源生成门（仅纠缠相邻量子比特但不产生目标资源）。分析资源随时间演化的行为模式。

Result: 对于资源生成门，从低资源态演化时表现出普适的"上升-峰值-下降"行为，峰值时间随子系统大小对数增长，最终资源衰减至子系统接近最大混合态。对于非资源生成门，初始局限于特定区域的资源会以弹道方式扩散。

Conclusion: 研究为局部电路中量子资源的时空动力学提供了统一图景，为研究更结构化量子多体系统的资源演化建立了基准，揭示了资源生成和非生成门的不同扩散机制。

Abstract: Quantum many-body dynamics generate nonclassical correlations naturally described by quantum resource theories. Quantum magic resources (or nonstabilizerness) capture deviation from classically simulable stabilizer states, while coherence and fermionic non-Gaussianity measure departure from the computational basis and from fermionic Gaussian states, respectively. We track these resources in a subsystem of a one-dimensional qubit chain evolved by random brickwall circuits. For resource-generating gates, evolution from low-resource states exhibits a universal rise-peak-fall behavior, with the peak time scaling logarithmically with subsystem size and the resource eventually decaying as the subsystem approaches a maximally mixed state. Circuits whose gates do not create the resource but entangle neighboring qubits, give rise to a ballistic spreading of quantum resource initially confined to a region of the initial state. Our results give a unified picture of spatiotemporal resource dynamics in local circuits and a baseline for more structured quantum many-body systems.

</details>


### [80] [Strong-to-weak symmetry breaking in monitored dipole conserving quantum circuits](https://arxiv.org/abs/2512.14830)
*Caterina Zerba,Sarang Gopalakrishnan,Michael Knap*

Main category: quant-ph

TL;DR: 研究具有电荷和偶极矩守恒的监测量子电路的信息论相，探索对称性自发破缺与从局部测量学习全局电荷能力之间的关系。


<details>
  <summary>Details</summary>
Motivation: 探索在同时具有电荷和偶极矩守恒的量子系统中，监测动力学如何影响信息获取能力，特别是从局部测量推断全局守恒量的可能性。

Method: 使用监测量子电路模型，其中电荷和偶极矩守恒是强对称性，但动力学可能导致对称性自发破缺为弱对称性，通过改变测量速率研究相图。

Result: 发现丰富的相图：一维中电荷总是容易学习，偶极矩可易可难；二维中存在三相，随测量频率降低，偶极矩和电荷依次变得难以学习；低测量相是类似近晶液晶的各向异性临界相。

Conclusion: 电荷和偶极矩守恒量子系统的监测动力学产生复杂的信息论相结构，对称性自发破缺与从局部测量学习全局守恒量的能力密切相关，二维系统中存在各向异性临界相。

Abstract: We explore the information-theoretic phases of monitored quantum circuits subject to dynamics that conserves both charge and dipole moment, as well as measurements of the local charge density. Explicitly, both charge and dipole-moment conservation are strong symmetries, but under the dynamics they can be spontaneously broken to weak symmetries: this spontaneous symmetry breaking has an information-theoretic interpretation in terms of whether one can learn global charges from local measurements. We find a rich phase diagram: in one spatial dimension, charge is always easy to learn, while dipole moment can be either easy or hard. In two dimensions, we find three phases: for frequent measurements, both charge and dipole moment are easy to learn; as the measurement rate is decreased, first dipole moment and then charge become hard. In two dimensions, the low-measurement phase is an exotic critical phase with anisotropic spacetime scaling, analogous to a smectic liquid crystal.

</details>


### [81] [Extreme non-negative Wigner functions](https://arxiv.org/abs/2512.14831)
*Zacharie Van Herstraeten,Jack Davis,Nuno C. Dias,João N. Prata,Nicolas J. Cerf,Ulysse Chabaud*

Main category: quant-ph

TL;DR: 该论文研究了维格纳正态（WPS）的极端点特征，提出了一种构造性方法生成大量极端WPS，揭示了混合态维格纳正态的结构特性。


<details>
  <summary>Details</summary>
Motivation: 维格纳正态（具有非负维格纳函数的量子态）的操作性表征是一个长期未解决的开放问题。对于混合态，情况比纯态（只有高斯态是WPS）要复杂得多，需要深入理解其结构。

Method: 采用凸几何方法，通过以下步骤构造极端WPS：(1) 表征维格纳正准态（WPQS）超集的相位不变极端点；(2) 引入新的量子映射（Vertigo映射），将极端WPQS映射到极端WPS同时保持相位不变性；(3) 识别保持极端性的映射族，用于获得非相位不变的极端WPS。

Result: 该构造方法从分束器态出发，生成了所有低维度的极端WPS。结果揭示了混合态维格纳正态的显著结构特性，并基于配套论文中推导的WPS集合的新数学性质。

Conclusion: 该研究为维格纳正态的操作性表征提供了重要进展，通过凸几何方法和新的量子映射揭示了混合态维格纳正态的结构特性，为解决这一长期开放问题提供了新的途径。

Abstract: Providing an operational characterization of the Wigner-positive states (WPS), i.e., the set of quantum states with non-negative Wigner function, is a longstanding open problem. For pure states, the only WPS are Gaussian states, but the situation is considerably more subtle for mixed states. Here, we approach the problem using convex geometry, reducing the question to the characterization of the extreme points of the set of WPS. We give a constructive method to generate a large class of such extreme WPS, which combines the following steps: (i) we characterize the phase-invariant extreme points of the superset of Wigner-positive quasi-states (WPQS); (ii) we introduce a new quantum map, named Vertigo map, which maps extreme WPQS to extreme WPS while preserving phase invariance; (iii) we identify families of extremality-preserving maps and use them to obtain extreme WPS while relaxing phase invariance. Our construction generates all extreme WPS of low dimension, starting from a specific kind of WPS known as beam-splitter states. Our results build upon new mathematical properties of the set of WPS derived in a companion paper and unveil the remarkable structure of mixed states with non-negative Wigner functions.

</details>


### [82] [Entanglement without Quantum Mechanics: Operational Constraints on the Quantum Signature](https://arxiv.org/abs/2512.14834)
*Samuel Schlegel,Borivoje Dakić,Flavio Del Santo*

Main category: quant-ph

TL;DR: 经典关联在受限操作条件下可以表现出类似量子纠缠的非可分性特征，只有解除更多操作限制后才能区分真正的量子纠缠


<details>
  <summary>Details</summary>
Motivation: 挑战"纠缠是纯粹量子特征"的传统观点，探索在受限操作条件下经典关联如何表现出类似纠缠的行为，建立操作层次来区分经典赝象、经典可复现的非可分性和真正的量子纠缠

Method: 通过限制观测者的测量和变换操作集，分析经典相空间分布在量子力学形式主义中的表现，引入希尔伯特空间算符的正定性作为物理性要求，逐步解除操作限制来区分不同层次的"纠缠"行为

Result: 发现经典关联在受限操作条件下可以表现出非可分性特征，通过正定性要求可以去除部分赝象，揭示出经典模型可复现的非可分性区域，只有完全解除操作限制（允许测量不相容性等非经典特征的检验）才能获得真正的量子纠缠

Conclusion: 纠缠并非纯粹的量子特征，而是依赖于操作可及性的层次结构：经典赝象、经典可复现的非可分性和真正的量子纠缠，这为理解量子-经典边界提供了新的操作视角

Abstract: Entanglement is often regarded as an inherently quantum feature. We show that this does not have to be the case: under restricted operational access, classical correlations can appear nonseparable when expressed in the formalism of quantum mechanics. If an observer is limited to a constrained set of measurements and transformations, certain classical phase-space distributions can mimic entanglement-like behaviours. Imposing positivity of the associated Hilbert space operator as a physicality requirement removes some of these representational artifacts, revealing a regime in which nonseparability is genuine but still reproducible by classical models. Only when the operational restrictions on the observer are lifted further--allowing operational tests of measurement incompatibility or other nonclassical signatures--does one obtain entanglement that can no longer be captured by any classical description. This operational hierarchy distinguishes classical artifacts, classically reproducible nonseparability, and genuine entanglement.

</details>


### [83] [Noise-Induced Thermalization in Quantum Systems](https://arxiv.org/abs/2512.14842)
*Sameer Dambal,Yu Zhang,Eric R Bittner,Pavan Hosur*

Main category: quant-ph

TL;DR: 噪声可以加速量子计算机中吉布斯态的制备，在非可积模型中实现约3.5倍的热化加速，在可积模型中促使系统达到热态


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，噪声通常被视为实现容错量子计算的主要障碍，但本文发现量子计算流程中的某些阶段实际上可以从噪声中受益。作者旨在探索如何利用噪声来加速量子计算中的关键任务——吉布斯态制备。

Method: 利用本征态热化假说，通过经典和量子模拟研究噪声对热化的影响。使用具有局部哈密顿量的自旋1/2链模型，分别研究了Haar随机噪声和相位翻转噪声的作用。

Result: 在非可积模型中，噪声使热化速度提高了约3.5倍；在可积模型中，原本不会热化的系统在噪声作用下达到了热态。由于在量子计算机上认证局部吉布斯态相对容易，这为量子计算中的关键问题提供了新的实用解决方案。

Conclusion: 噪声可以加速吉布斯态制备，为在容错量子计算实现之前利用噪声获得实际优势建立了新范式。这表明噪声可以在量子计算机中被有效利用，而不仅仅是需要克服的障碍。

Abstract: In the current Noisy Intermediate-Scale Quantum era, noise is widely regarded as the primary obstacle to achieving fault-tolerant quantum computation. However, certain stages of the quantum computing pipeline can, in fact, benefit from this noise. In this work, we exploit the Eigenstate Thermalization Hypothesis to show that noise generically accelerates a fundamental task in quantum computing -- the preparation of Gibbs states. We demonstrate this behavior using classical and quantum simulations with Haar-random and phase-flip noise, respectively, on a spin-1/2 chain with a local Hamiltonian. Our non-integrable model sees ~3.5x faster thermalization in the presence of noise, while our integrable model, which would not otherwise thermalize, reaches a thermal state due to noise. Since certifying a local Gibbs state is relatively easy on a quantum computer, our approach provides a new practical solution to a key problem in quantum computing. More broadly, these results establish a new paradigm in which noise can be harnessed on quantum computers, enabling practical advantages before the years of fault-tolerance.

</details>


### [84] [Quantum Fisher-information limits of resonant nanophotonic sensors: why high-Q is not optimal even at the quantum limit](https://arxiv.org/abs/2512.14899)
*J. Sumaya-Martinez*

Main category: quant-ph

TL;DR: 量子计量学框架应用于基于亚波长法布里-珀罗狭缝腔的共振纳米光子传感器，发现即使在量子极限下，最佳估计精度由参数相关相移的生成元决定而非腔品质因子，量子资源增强灵敏度但不改变最佳几何结构。


<details>
  <summary>Details</summary>
Motivation: 建立量子计量学框架来分析共振纳米光子传感器，探索量子资源如何增强这类传感器的性能，并确定量子极限下的最优设计原则。

Method: 基于经典费希尔信息分析，将参数编码建模为嵌入马赫-曾德尔干涉仪一臂中的相位和损耗量子通道，推导相干和高斯探针态在线性损耗下的量子费希尔信息。

Result: 即使在量子极限下，最佳估计精度也由参数相关相移的生成元决定，而非腔品质因子；最大化量子费希尔信息的操作点通常不与最大Q值共振点重合；量子资源增强灵敏度但不重新定义最优几何结构。

Conclusion: 研究结果为量子增强纳米光子传感提供了物理透明的设计原则，表明量子资源可以提升灵敏度但不会改变传感器的最优几何配置。

Abstract: We develop a quantum metrological framework for resonant nanophotonic sensors based on subwavelength Fabry--Perot slit cavities. Building on classical Fisher-information analyses of resonant transmission sensors, we model parameter encoding as a phase-and-loss quantum channel embedded in one arm of a Mach-Zehnder interferometer. We derive the quantum Fisher information (QFI) for coherent and Gaussian probe states under linear loss and show that, even at the quantum limit, optimal estimation precision is governed by the generator of parameter-dependent phase shifts rather than by the cavity quality factor. Consequently, the operating point that maximizes the QFI does not generally coincide with the maximum-Q resonance. Quantum resources enhance sensitivity but do not redefine the optimal geometry. Our results provide physically transparent design principles for quantum-enhanced nanophotonic sensing.

</details>


### [85] [Defect-Driven Nonlinear and Nonlocal Perturbations in Quantum Chains](https://arxiv.org/abs/2512.15130)
*Anish Acharya,Luca Giuggioli,Shamik Gupta*

Main category: quant-ph

TL;DR: 单个缺陷可以显著改变量子系统中波函数的传播行为，即使在有限孤立周期性紧束缚晶格中也能诱导非线性非局域效应，包括非单调的输运抑制、远处位点的局域增强以及对初始位置的长时敏感性。


<details>
  <summary>Details</summary>
Motivation: 传统上，量子系统中的输运和局域化通常归因于空间扩展的随机无序，而少数可控缺陷的影响很少被探索，尽管这在工程量子平台中具有重要意义。本研究旨在揭示单个缺陷如何深刻影响有限孤立周期性晶格中的波函数传播。

Method: 采用从经典随机游走研究中借鉴的缺陷技术，建立了一个解析框架，获得了精确的时间分辨位点占据概率和多个相关可观测量。该方法适用于有限孤立和周期性紧束缚晶格。

Result: 即使只有一个缺陷也能诱导显著的非线性和非局域效应：1）输运的非单调抑制；2）远处位点的局域增强；3）长时尺度上对初始粒子位置的强敏感性。这些结果表明最小扰动可以产生意想不到的长时输运特征。

Conclusion: 单个缺陷足以在量子系统中产生显著的局域化效应，建立了微观缺陷驱动的量子局域化机制。这挑战了传统上认为需要空间扩展无序才能实现量子局域化的观点，为工程量子平台中的输运控制提供了新思路。

Abstract: Transport and localization in isolated quantum systems are typically attributed to spatially-extended disorder, leaving the influence of a few controllable defects largely unexplored despite their relevance to engineered quantum platforms. We introduce an analytic framework showing how a single defect profoundly reshapes wave-function spreading on a finite isolated and periodic tight-binding lattice. Adapting the defect technique from classical random-walk studies, we obtain exact time-resolved site-occupation probabilities and several observables of interest. Even one defect induces striking nonlinear and nonlocal effects, including non-monotonic suppression of transport, enhanced localization at distant sites, and strong sensitivity to the initial particle position at long times. These results demonstrate that minimal perturbations can generate unexpected long-time transport signatures, establishing a microscopic defect-driven mechanism of quantum localization.

</details>


### [86] [Quantum Radiometric Calibration](https://arxiv.org/abs/2512.14947)
*Leif Albers,Jan-Malte Michaelsen,Roman Schnabel*

Main category: quant-ph

TL;DR: 提出基于压缩光和量子关联的量子辐射测量校准方法，直接测量光电二极管的量子效率，发现1550nm商用光电二极管效率低于预期


<details>
  <summary>Details</summary>
Motivation: 光学量子计算、量子通信和传感技术需要接近完美量子效率的光电二极管，现有辐射测量校准方法存在局限，需要新的校准技术

Method: 基于压缩光和量子关联的量子辐射测量校准方法，利用压缩真空态和不确定性原理，实现原位校准，直接测量检测效率和量子效率

Result: 使用10dB压缩真空态校准1550nm商用光电二极管，获得(97.20±0.37)%的系统检测效率，发现现有光电二极管效率低于未来引力波探测器和光学量子计算的要求

Conclusion: 量子辐射测量校准方法具有更高精度和准确度的潜力，但当前商用光电二极管效率不足，需要进一步提高以满足未来量子技术应用需求

Abstract: Optical quantum computing, as well as quantum communication and sensing technology based on quantum correlations are in preparation. These require photodiodes for the detection of about 10^16 photons per second with close to perfect quantum efficiency. Already the radiometric calibration is a challenge. Here, we provide the theoretical description of the quantum radiometric calibration method. Its foundation is squeezed light and Heisenberg's uncertainty principle, making it an example of quantum metrology based on quantum correlations. Unlike all existing radiometric calibration methods, ours is in situ and provides both the detection efficiency and the more stringent quantum efficiency directly for the measurement frequencies of the user application. We calibrate a pair of the most efficient commercially available photodiode at 1550 nm to a system detection efficiency of (97.20 + 0.37)% using 10-dB-squeezed vacuum states. Our method has great potential for significantly higher precision and accuracy, but even with this measurement, we can clearly say that the available photodiode efficiencies for 1550 nm are unexpectedly low, too low for future gravitational wave detectors and for optical quantum computing.

</details>


### [87] [Quantum Mpemba effect in Local Gauge Symmetry Restoration](https://arxiv.org/abs/2512.15223)
*Hao-Yue Qi,Wei Zheng*

Main category: quant-ph

TL;DR: 该论文研究了具有局域规范对称性的规范理论中的量子Mpemba效应，发现在格点Schwinger模型中，子系统规范结构由初态决定且不随时间演化，规范对称性恢复依赖于Maxwell项的存在，并构造了展示QME的初态族。


<details>
  <summary>Details</summary>
Motivation: 研究孤立量子多体系统中的弛豫过程是核心挑战，量子Mpemba效应作为反直觉的弛豫现象已在全局对称性系统中得到广泛研究，但尚未在具有局域规范对称性的规范理论中进行探索。

Method: 在格点Schwinger模型中分析子系统约化密度矩阵的规范结构，研究对称淬火后规范对称性的动态恢复，通过解析和数值方法分析Maxwell项的作用，在量子链接模型（截断格点Schwinger模型）中进一步探索QME，并设计实验可观测的序参数。

Result: 发现子系统规范结构完全由初态决定且不随时间演化；当Maxwell项为零时，由于特殊守恒定律的出现，规范对称性恢复失败；对于任何有限Maxwell项，在热力学极限下子系统规范对称性得以恢复；成功构造了展示QME的初态族，并提出了实验可观测的序参数。

Conclusion: 该工作证明了量子Mpemba效应在局域规范对称性中的普遍性，为规范理论的量子模拟实验提供了直接相关的理论基础和实验方案。

Abstract: Understanding relaxation in isolated quantum many-body systems remains a central challenge. Recently, the quantum Mpemba effect (QME), a counterintuitive relaxation phenomenon, has attracted considerable attention and has been extensively studied in systems with global symmetries. Here, we study the QME in gauge theories with massive local gauge symmetries. In the lattice Schwinger model, we demonstrate that the gauge structure of the reduced density matrix of a subsystem is entirely determined by the initial state and remain unchanged during the time evolution. We then investigate whether gauge symmetry can be dynamically restored following a symmetric quench. Analytical and numerical results show that when the Maxwell term is zero, gauge symmetry restoration fails due to the emergence of a peculiar conservation law. However, for any finite Maxwell term, subsystem gauge symmetry is restored in the thermodynamic limit. Based on these results, we systematically construct a families of initial states exhibiting the QME. We further explore the QME in the quantum link model-a truncated lattice Schwinger model, which has been realized in experiments. Moreover, we propose an experimentally accessible order parameter that correctly captures the QME. Our work demonstrates the generality of the quantum Mpemba effect even in the local gauge symmetries, and are directly relevant to ongoing quantum simulation experiments of gauge theories.

</details>


### [88] [Pulsed single-photon spectroscopy of an emitter with vibrational coupling](https://arxiv.org/abs/2512.14964)
*Sourav Das,Aiman Khan,Elnaz Darsheshdar,Francesco Albarelli,Animesh Datta*

Main category: quant-ph

TL;DR: 该论文解析推导了单光子脉冲与量子二能级发射体（与振动浴相互作用）散射后的量子态，用于信息论表征振动效应在量子光谱学中的影响。


<details>
  <summary>Details</summary>
Motivation: 研究振动环境对量子光与物质相互作用的影响，特别是在量子光谱学中如何定量表征振动诱导退相干对参数估计精度的影响。

Method: 解析推导单光子脉冲与量子二能级发射体（耦合振动浴）散射后的量子态，构建四体系统模型，使用量子费舍尔信息（QFI）分析振动效应对发射体线宽估计精度的影响。

Result: 振动诱导退相干降低了发射体线宽估计的量子费舍尔信息，主要反映了Franck-Condon因子对光-物质耦合的抑制；比较时域和频域分辨的光探测，发现对于更强的振动耦合，频域分辨探测能提供更多信息。

Conclusion: 振动环境显著影响量子光谱测量精度，频域分辨探测在强振动耦合条件下更具优势，为优化量子光光谱实验设计提供了理论指导。

Abstract: We analytically derive the quantum state of a single-photon pulse scattered from a single quantum two-level emitter interacting with a vibrational bath. This solution for the quadripartite system enables an information-theoretic characterization of vibrational effects in quantum light spectroscopy. We show that vibration-induced dephasing reduces the quantum Fisher information (QFI) for estimating the emitter's linewidth, largely reflecting the Franck-Condon suppression of light-matter coupling. Comparing time- and frequency-resolved photodetection, we find the latter to be more informative in estimating the emitter's linewidth for stronger vibrational coupling.

</details>


### [89] [Decoherence in the Pure Dephasing Spin-Boson Model with Hermitian or Non-Hermitian Bath](https://arxiv.org/abs/2512.15297)
*Yue-Hong Wu,Ning-Hua Tong*

Main category: quant-ph

TL;DR: 研究量子比特与厄米/非厄米环境耦合时的退相干现象，发现非厄米环境能抑制退相干，这与先前研究结论相反


<details>
  <summary>Details</summary>
Motivation: 研究量子比特在厄米和非厄米环境中的退相干行为，探索非厄米环境工程在抑制量子比特退相干方面的潜力

Method: 使用纯退相自旋玻色子模型，分析量子比特与厄米/非厄米环境耦合的情况，通过解析方法建立非平衡与平衡相关函数之间的相似性

Result: 1) 建立了非平衡相关函数P_x(t)与平衡相关函数C_x(t)的相似性；2) 在P_x(t)的短/长时间渐近行为中发现了对耦合强度A和浴指数s在整数值处的奇异依赖性；3) 发现非厄米环境对所有A和s值都能抑制量子比特退相干，这与Dey等人的结论相反

Conclusion: 非厄米环境工程在抑制量子比特退相干方面具有潜力，为量子信息处理中的退相干控制提供了新思路

Abstract: In this paper, we investigate the decoherence of qubit due to its coupling to a Hermitian or a non-Hermitian bath within the pure dephasing spin-boson model. First, using this model, we analytically establish the previously anticipated similarity between the non-equilibrium and the equilibrium correlation functions $P_x(t)$ and $C_x(t)$. Then, in the short/long time asymptotic behaviors of $P_x(t)$, we find singular dependence on $A$ (coupling strength) and $s$ (bath exponent) at their integer values. Finally, we find that the non-Hermitian bath tends to suppress the decoherence of qubit for all values of $A$ and $s$, in contrast to the conclusion of Dey et al. . Our results show the potential of non-Hermitian environment engineering in suppressing the decoherence of qubit.

</details>


### [90] [Roadmap: 2D Materials for Quantum Technologies](https://arxiv.org/abs/2512.14973)
*Qimin Yan,Tongcang Li,Xingyu Gao,Sumukh Vaidya,Saakshi Dikshit,Yue Luo,Stefan Strauf,Reda Moukaouine,Anton Pershin,Adam Gali,Zhenyao Fang,Harvey Stanfield,Ivan J. Vera-Marun,Michael Newburger,Simranjeet Singh,Tiancong Zhu,Mauro Brotons-Gisbert,Klaus D. Jöns,Brian D. Gerardot,Brian S. Y. Kim,John R. Schaibley,Kyle L. Seyler,Jesse Balgley,James Hone,Kin Chung Fong,Lin Wang,Guido Burkard,Yihang Zeng,Tobias Heindel,Serkan Ateş,Tobias Vogl,Igor Aharonovich*

Main category: quant-ph

TL;DR: 二维材料作为量子技术平台，具有原子级控制、强量子限制和异质集成能力，可用于量子传感、计算、通信和模拟等领域。


<details>
  <summary>Details</summary>
Motivation: 二维材料因其独特的量子现象（如自旋缺陷、单光子发射器、莫尔超晶格等）和器件集成优势，为下一代量子技术提供了有前景的平台。

Method: 通过路线图形式，全面综述二维材料在量子技术各领域的进展，包括自旋缺陷与量子传感、量子发射器与非线性光子学、计算理论与数据驱动发现、自旋电子与磁子器件、腔工程量子材料、超导与混合量子电路、量子点、莫尔量子模拟器和量子通信平台等。

Result: 识别了缺陷控制、相干性保持、界面工程和可扩展集成等共同挑战，同时指出了机器学习辅助设计和实验-理论反馈循环带来的新兴机遇。

Conclusion: 二维材料通过连接微观量子态、介观激发和宏观器件架构，为集成相干量子功能提供了材料中心框架，是下一代量子技术的基础构建模块。

Abstract: Two-dimensional (2D) materials have emerged as a versatile and powerful platform for quantum technologies, offering atomic-scale control, strong quantum confinement, and seamless integration into heterogeneous device architectures. Their reduced dimensionality enables unique quantum phenomena, including optically addressable spin defects, tunable single-photon emitters, low-dimensional magnetism, gate-controlled superconductivity, and correlated states in Moiré superlattices. This Roadmap provides a comprehensive overview of recent progress and future directions in exploiting 2D materials for quantum sensing, computation, communication, and simulation. We survey advances spanning spin defects and quantum sensing, quantum emitters and nonlinear photonics, computational theory and data-driven discovery of quantum defects, spintronic and magnonic devices, cavity-engineered quantum materials, superconducting and hybrid quantum circuits, quantum dots, Moiré quantum simulators, and quantum communication platforms. Across these themes, we identify common challenges in defect control, coherence preservation, interfacial engineering, and scalable integration, alongside emerging opportunities driven by machine$-$learning$-$assisted design and integrated experiment$-$theory feedback loops. By connecting microscopic quantum states to mesoscopic excitations and macroscopic device architectures, this Roadmap outlines a materials-centric framework for integrating coherent quantum functionalities and positions 2D materials as foundational building blocks for next-generation quantum technologies.

</details>


### [91] [Trade-off relations and enhancement protocol of quantum battery capacities in multipartite systems](https://arxiv.org/abs/2512.14999)
*Yiding Wang,Xiaofen Huang,Shao-Ming Fei,Tinggui Zhang*

Main category: quant-ph

TL;DR: 该论文研究量子电池容量的权衡关系，在两比特系统中发现子系统电池容量之和受总系统容量约束，并建立了剩余电池容量概念和相干/非相干分量。提出了通过非相干幺正操作增强子系统容量的协议，并在三比特系统中建立了平行理论。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池容量的基本限制和增强机制，为量子能量存储系统的发展提供理论基础。特别关注子系统电池容量之间的权衡关系以及如何通过操作来优化能量存储能力。

Method: 1. 在两比特系统中分析量子电池容量的权衡关系；2. 定义剩余电池容量并建立相干/非相干分量；3. 提出通过非相干幺正操作增强子系统容量的协议；4. 将理论扩展到三比特系统；5. 数值验证协议可行性；6. 确定增强子系统容量所需的最小时间。

Result: 1. 发现子系统电池容量之和受总系统容量约束的权衡关系；2. 建立了剩余电池容量概念和相干/非相干分量分解；3. 提出了有效的非相干幺正操作协议；4. 数值验证了协议的可行性；5. 将理论成功扩展到三比特系统；6. 确定了增强子系统容量所需的最小时间。

Conclusion: 该研究为量子电池理论和量子能量存储系统的发展做出了重要贡献，揭示了量子电池容量的基本限制，并提供了通过非相干操作优化子系统能量存储能力的具体方法。

Abstract: First, we investigate the trade-off relations of quantum battery capacities in two-qubit system. We find that the sum of subsystem battery capacity is governed by the total system capacity, with this trade-off relation persisting for a class of Hamiltonians, including Ising, XX, XXZ and XXX models. Then building on this relation, we define residual battery capacity for general quantum states and establish coherent/incoherent components of subsystem battery capacity. Furthermore, we introduce the protocol to guide the selection of appropriate incoherent unitary operations for enhancing subsystem battery capacity in specific scenarios, along with a sufficient condition for achieving subsystem capacity gain through unitary operation. Numerical examples validate the feasibility of the incoherent operation protocol. Additionally, for the three-qubit system, we also established a set of theories and results parallel to those for two-qubit case. Finally, we determine the minimum time required to enhance subsystem battery capacity via a single incoherent operation in our protocol. Our findings contribute to the development of quantum battery theory and quantum energy storage systems.

</details>


### [92] [Enabling Technologies for Scalable Superconducting Quantum Computing](https://arxiv.org/abs/2512.15001)
*Xanthe Croot,Kasra Nowrouzi,Christopher Spitzer,Carmen G. Almudever,Alexandre Blais,Malcolm Carroll,Jerry Chow,Daniel Friedman,Masao Tokunari,Edoardo Charbon,Vivek Chidambaram,Andrew N. Cleland,David Danovitch,Joseph Emerson,David Gunnarsson,Raymond Laflamme,John Martinis,Robert McDermott,William D. Oliver,Michel Pioro-Ladriere,Yoshiaki Sato,Hidenori Ohata,Kouichi Semba,Irfan Siddiqi*

Main category: quant-ph

TL;DR: 该论文探讨了超导量子计算机实现大规模容错量子计算所需的关键技术挑战，特别关注量子信息在低温环境内外的处理和传输问题。


<details>
  <summary>Details</summary>
Motivation: 虽然超导量子处理器已成功展示了量子计算的基本功能，但要实现量子计算的全部潜力，关键在于构建大规模容错量子计算机。目前缺乏足够规模的纠错量子比特阵列，需要科学、工程和工业多方面的进步来支撑指数级增长的希尔伯特空间。

Method: 论文通过分析超导量子计算系统的现状，识别出量子系统及其生态系统发展的关键领域，特别关注量子信息在低温环境内外的处理和传输问题，为加速超导量子计算机的发展提供建议。

Result: 论文提出了超导量子计算机发展的关键瓶颈和加速路径，重点关注量子信息处理、低温环境内的量子操作、以及低温环境与外部系统的接口等核心问题。

Conclusion: 要实现基于超导电路的大规模容错量子计算机，需要在量子系统及其生态系统方面进行重点发展，特别是在量子信息的处理和传输技术方面，这将是加速量子计算发展的关键。

Abstract: Experiments with superconducting quantum processors have successfully demonstrated the basic functions needed for quantum computation and evidence of utility, albeit without a sizable array of error-corrected qubits. The realization of the full potential of quantum computing centers on achieving large scale fault-tolerant quantum computers. Science, engineering and industry advances are needed to robustly generate, sustain, and efficiently manipulate an exponentially large computational (Hilbert) space as well as supply the number and quality components needed for such a scaled system. In this article, we suggest critical areas of quantum system and ecosystem development, with respect to the handling and transmission of quantum information within and out of a cryogenic environment, that would accelerate the development of quantum computers based on superconducting circuits.

</details>


### [93] [Characterizing entanglement shareability and distribution in $N$-partite systems](https://arxiv.org/abs/2512.15018)
*Hui Li,Ting Gao,Fengli Yan*

Main category: quant-ph

TL;DR: 本文证明了G_q-并发度的平方在N量子比特态中满足层次性单配关系，并构建了两种层次性指示器用于纠缠检测。在2⊗d系统中建立了G_q-并发度与并发度的解析关系，证明了在2⊗d₂⊗d₃⊗⋯⊗d_N系统中平方G_q-并发度的单配性优于平方并发度，并通过多级系统实例说明平方G_q-并发度在平方并发度不满足单配关系时仍能保持单配性。


<details>
  <summary>Details</summary>
Motivation: 探索纠缠的可共享性和分布特性在量子信息任务中具有基础重要性。本文旨在研究G_q-并发度（并发度的推广）的平方在量子态中的单配关系，揭示多级纠缠的有趣特性，并为多体量子系统中的纠缠分布提供关键见解。

Method: 1. 证明G_q-并发度平方在任意N量子比特态中满足层次性单配关系；2. 基于这些单配不等式构建两种层次性指示器用于纠缠检测；3. 在2⊗d系统中建立G_q-并发度与并发度的解析关系；4. 严格证明在2⊗d₂⊗d₃⊗⋯⊗d_N系统中平方G_q-并发度的单配性优于平方并发度；5. 提供具体实例说明多级系统中平方G_q-并发度的单配性优势。

Result: 1. 成功证明了G_q-并发度平方在N量子比特态中的层次性单配关系；2. 构建的两种层次性指示器在纠缠检测能力上表现出明显优势；3. 建立了2⊗d系统中G_q-并发度与并发度的解析关系；4. 证明了在2⊗d₂⊗d₃⊗⋯⊗d_N系统中平方G_q-并发度的单配性确实优于平方并发度；5. 通过具体实例证实了多级系统中平方G_q-并发度在平方并发度不满足单配关系时仍能保持单配性。

Conclusion: 本文的研究结果更好地揭示了多级纠缠的有趣特性，为多体量子系统中的纠缠分布提供了关键见解。平方G_q-并发度在单配性方面优于平方并发度，特别是在多级系统中表现出更强的单配关系保持能力，这对量子信息任务中的纠缠分析和应用具有重要意义。

Abstract: Exploring the shareability and distribution of entanglement possesses fundamental significance in quantum information tasks. In this paper, we demonstrate that the square of bipartite entanglement measures $G_q$-concurrence, which is the generalization of concurrence, follows a set of hierarchical monogamy relations for any $N$-qubit quantum state. On the basis of these monogamy inequalities, we render two kinds of hierarchical indicators that exhibit evident advantages in the capacity of witnessing entanglement. Moreover, we show an analytical relation between $G_q$-concurrence and concurrence in $2\otimes d$ systems. Furthermore, we rigorously prove that the monogamy property of squared $G_q$-concurrence is superior to that of squared concurrence in $2\otimes d_2\otimes d_3\otimes\cdots\otimes d_N$ systems. In addition, several concrete examples are provided to illustrate that for multilevel systems, the squared $G_q$-concurrence satisfies the monogamy relation, even if the squared concurrence does not. These results better reveal the intriguing characteristic of multilevel entanglement and provide critical insights into the entanglement distribution within multipartite quantum systems.

</details>


### [94] [Graph-theoretical search for integrable multistate Landau-Zener models](https://arxiv.org/abs/2512.15046)
*Zixuan Li,Chen Sun*

Main category: quant-ph

TL;DR: 通过图论方法系统搜索多态Landau-Zener模型的可积性，验证了已知图族（超立方体、扇形图及其笛卡尔积）的猜想，并提出了可能违反该猜想的"(0,2)-图"后代家族。


<details>
  <summary>Details</summary>
Motivation: 寻找新的精确可解多态Landau-Zener模型，验证关于可积MTLZ模型仅存在于超立方体、扇形图及其笛卡尔积的猜想，并探索可能的例外情况。

Method: 采用图论方法，首先识别MTLZ模型所需的最小图结构，然后设计高效算法系统搜索候选图，使用计算软件枚举最多13个顶点的所有候选图，并对≤11个顶点的图进行深入分析。

Result: 对于≤11个顶点的图，结果支持猜想：可积MTLZ模型仅存在于超立方体、扇形图及其笛卡尔积。对于更大图，提出了"(0,2)-图"后代家族作为可能违反猜想的候选者。

Conclusion: 该研究为未来识别新的精确可解多态Landau-Zener模型提供了指导框架，验证了现有猜想在小规模图上的正确性，并指出了可能的新方向。

Abstract: The search for exactly solvable models is an evergreen topic in theoretical physics. In the context of multistate Landau-Zener models -- $N$-state quantum systems with linearly time-dependent Hamiltonians -- the theory of integrability provides a framework for identifying new solvable cases. In particular, it was proved that the integrability of a specific class known as the multitime Landau-Zener (MTLZ) models guarantees their exact solvability. A key finding was that an $N$-state MTLZ model can be represented by data defined on an $N$-vertex graph. While known host graphs for MTLZ models include hypercubes, fans, and their Cartesian products, no other families have been discovered, leading to the conjecture that these are the only possibilities. In this work, we conduct a systematic graph-theoretical search for integrable models within the MTLZ class. By first identifying minimal structures that a graph must contain to host an MTLZ model, we formulate an efficient algorithm to systematically search for candidate graphs for MTLZ models. Implementing this algorithm using computational software, we enumerate all candidate graphs with up to $N = 13$ vertices and perform an in-depth analysis of those with $N \le 11$. Our results corroborate the aforementioned conjecture for graphs up to $11$ vertices. For even larger graphs, we propose a specific family, termed descendants of ``$(0,2)$-graphs'', as promising candidates that may violate the conjecture above. Our work can serve as a guideline to identify new exactly solvable multistate Landau-Zener models in the future.

</details>


### [95] [Microscopic model for a spatial multimode generation based on Multi-pump Four Wave Mixing in hot vapours](https://arxiv.org/abs/2512.15051)
*H. M. Florez*

Main category: quant-ph

TL;DR: 该论文提出了首个描述密集原子介质中双泵浦四波混频多模纠缠生成的微观模型，通过Floquet展开解决多模增益放大和噪声特性，预测模式间的量子关联。


<details>
  <summary>Details</summary>
Motivation: 多体纠缠是量子信息处理的重要资源，利用碱金属原子通过空间模式非线性过程实现单器件多体纠缠已有实验展示，但缺乏相应的微观理论描述。

Method: 扩展单泵浦四波混频的双Λ模型来描述双泵浦配置的多模生成，提出Floquet展开方法解决多模增益放大和噪声特性，分析角度和双光子依赖关系。

Result: 模型成功描述了多模生成的角度和双光子依赖性以及模式间的量子关联，解释了先前实验观测的主要特性，能够预测典型实验参数范围内的增益分布和量子关联。

Conclusion: 该微观描述为密集原子介质中双泵浦四波混频多模纠缠提供了理论框架，可用于优化实验参数以实现高效的多体纠缠生成。

Abstract: Multipartite entanglement is an important resource for quantum information processing. It has been shown that it is possible to employ alkali atoms to implement single device multipartite entanglement by using nonlinear processes with spatial modes. This work presents the first microscopic description of such multi-mode generation with two-pump four wave mixing (4WM) in dense atomic media. We implement an extension of a double $Λ$ model for a single pump 4WM in order to describe the multi-mode generation with a two-pump configuration. We propose a Floquet expansion to solve the multimode gain amplification and noise properties. The model describes the angle and the two-photon dependency of the multimode generation and the quantum correlations among the modes. We investigate the entanglement properties of the system, describing the main properties of previous experimental observations. Such a microscopic description can be used to predict the gain distribution of modes and the quantum correlation within a typical range of experimental parameters.

</details>


### [96] [Bosonic quantum computing with near-term devices and beyond](https://arxiv.org/abs/2512.15063)
*Timo Hillmann*

Main category: quant-ph

TL;DR: 该论文研究可扩展容错量子计算，开发了玻色子量子编码、量子LDPC码和连接连续变量与离散变量纠错的解码协议，提出了多种创新编码方案和解码方法。


<details>
  <summary>Details</summary>
Motivation: 研究可扩展容错量子计算的需求，通过开发新型量子编码和解码协议来克服当前量子纠错技术的局限性，特别是连接连续变量和离散变量纠错系统。

Method: 采用多种方法：1) 开发玻色子量子编码如耗散稳定压缩猫态量子比特；2) 分析旋转对称码和GKP码在实际噪声下的性能；3) 开发利用模拟校验信息的解码方法；4) 提出局部统计解码和量子径向码；5) 引入故障复形作为分析动态量子纠错协议的拓扑框架。

Result: 实现了：1) 确定性生成立方相位态；2) 具有增强错误抑制和更快门操作的噪声偏置玻色子编码；3) 测量方案中的关键权衡分析；4) 准单次解码的级联系统；5) 高度可并行化的量子LDPC解码器；6) 低开销、强电路性能的单次LDPC码；7) 分析动态量子纠错协议的通用框架。

Conclusion: 该研究为可扩展容错量子计算提供了全面的理论和技术框架，通过连接连续变量和离散变量纠错，开发了多种创新编码方案和解码协议，为实际量子计算系统的实现奠定了重要基础。

Abstract: (Abridged.) This thesis investigates scalable fault-tolerant quantum computation through the development of bosonic quantum codes, quantum LDPC codes, and decoding protocols that connect continuous-variable and discrete-variable error correction. We investigate superconducting microwave implementations of continuous-variable quantum computing, including the deterministic generation of cubic phase states, and introduce the dissipatively stabilized squeezed cat qubit, a noise-biased bosonic encoding with enhanced error suppression and faster gates. The performance of rotation-symmetric and GKP codes is analyzed under realistic noise and measurement models, revealing key trade-offs in measurement-based schemes. To integrate bosonic codes into larger architectures, we develop decoding methods that exploit analog syndrome information, enabling quasi-single-shot decoding in concatenated systems. On the discrete-variable side, we introduce localized statistics decoding, a highly parallelizable decoder for quantum LDPC codes, and propose quantum radial codes, a new family of single-shot LDPC codes with low overhead and strong circuit-level performance. Finally, we present fault complexes, a homological framework for analyzing faults in dynamic quantum error correction protocols. Extending the role of homology in static CSS codes, fault complexes provide a general language for the design and analysis of fault-tolerant schemes.

</details>


### [97] [Quantum Batteries in Coherent Ising Machine](https://arxiv.org/abs/2512.15072)
*Jin-Tian Zhang,Shuang-Quan Ma,Jing-Yi-Ran Jin,Qing Ai*

Main category: quant-ph

TL;DR: 该论文提出了一种基于简并光学参量振荡器的量子电池架构，利用信号场作为能量存储单元，研究了其充放电过程，并找到了最优充电时间点。


<details>
  <summary>Details</summary>
Motivation: 量子电池作为量子热力学研究的重要方向，虽然已有许多理论模型，但退相干问题仍是严重挑战，实际平台仍然稀缺。本文旨在建立一个现实且可立即实现的光学平台量子电池架构。

Method: 提出基于简并光学参量振荡器的量子电池，将信号场作为能量存储单元。将ergotropy（可提取功）分离为相干和非相干分量，分析其衰减特性。通过耦合两能级系统作为负载来演示放电过程。

Result: 发现相干ergotropy的衰减速度约为非相干部分的一半。相干ergotropy和平均充电功率在γ_s t ≈ 10时同时达到最大值，这定义了关闭泵浦的最佳时刻。放电过程显示量子电池能够高效地向两能级系统负载传递能量。

Conclusion: 该工作建立了一个现实且可立即实现的光学平台量子电池架构，为量子能量存储和传输提供了实用的解决方案。

Abstract: With intensive studies of quantum thermodynamics, the quantum batteries (QBs) have been proposed to store and transfer energy via quantum effects. Despite many theoretical models, decoherence remains a severe challenge and practical platforms are still rare. Here we propose the QB based on the degenerate optical parametric oscillator (DOPO), using the signal field as the energy-storage unit. We carefully separate the ergotropy into coherent and incoherent components and find that the coherent part decays roughly half as slowly as the incoherent part. More importantly, the coherent ergotropy and the average charging power reach their respective maxima at essentially the same moment, i.e., $γ_s t \approx 10$. This coincidence defines the optimal instant to switch off the pump. Finally, coupling the QB to a two-level system (TLS) as the load, we demonstrate an efficient discharge process of the QB. Our work establishes a realistic and immediately-implementable QB architecture on a mature optical platform.

</details>


### [98] [Coherent transfer via parametric control of normal-mode splitting in a superconducting multimode resonator](https://arxiv.org/abs/2512.15087)
*Kai-I Chu,Xiao-Cheng Lu,Hsin Chang,Wei-Cheng Hung,Jing-Yang Chang,Jeng-Chung Chen,Chii-Dong Chen,Yung-Fu Chen*

Main category: quant-ph

TL;DR: 该论文展示了一种基于片上多模谐振器的微波存储与检索方法，通过强参数调制产生可调谐的正常模式分裂，实现了微波脉冲的按需存储和检索。


<details>
  <summary>Details</summary>
Motivation: 微波存储和检索是超导量子电路的关键能力，需要开发实用的可控量子存储器机制。

Method: 使用片上多模谐振器，通过强参数调制产生大且可调谐的正常模式分裂。当短微波脉冲的光谱带宽覆盖两个修饰态吸收峰时，部分脉冲被吸收并在模式间进行相干能量交换，产生时域拍频信号。在拍频到达前关闭调制，实现按需存储和检索。

Result: 成功演示了微波脉冲的存储和检索功能，实现了超导电路中可控量子存储器机制的替代方案。

Conclusion: 参数正常模式分裂协议为超导电路中的可控量子存储器机制提供了实用途径。

Abstract: Microwave storage and retrieval are essential capabilities for superconducting quantum circuits. Here, we demonstrate an on-chip multimode resonator in which strong parametric modulation induces a large and tunable normal-mode splitting that enables microwave storage. When the spectral bandwidth of a short microwave pulse covers the two dressed-state absorption peaks, part of the pulse is absorbed and undergoes coherent energy exchange between the modes, producing a clear time-domain beating signal. By switching off the modulation before the beating arrives, we realize on-demand storage and retrieval, demonstrating an alternative approach to microwave photonic quantum memory. This parametric-normal-mode-splitting protocol offers a practical route toward a controllable quantum-memory mechanism in superconducting circuits.

</details>


### [99] [Quantum data hiding with two-qubit separable states](https://arxiv.org/abs/2512.15095)
*Donghoon Ha,Jeong San Kim*

Main category: quant-ph

TL;DR: 该论文提出了一种使用两比特可分态实现量子数据隐藏的方案，建立了局部区分两方量子态的最优界限，并给出了构建数据隐藏方案的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究两方量子态的区分问题，旨在开发一种使用可分态实现量子数据隐藏的方案，降低实际实现的难度。

Method: 首先建立了局部区分两方量子态的最优界限，然后提出了构建数据隐藏方案的充分条件，最后用两比特正交可分态组成的态系综作为示例说明。

Result: 成功构建了使用两比特可分态的数据隐藏方案，由于使用了最低维度的可分态，使得实际实现变得显著更容易。

Conclusion: 该研究提供了一种实用的量子数据隐藏方案，使用两比特可分态降低了实现难度，为量子信息处理中的安全通信提供了新方法。

Abstract: We consider the discrimination of two-party quantum states and provide a quantum data-hiding scheme using two-qubit separable states. We first provide a bound on the optimal local discrimination of two-party quantum states, and establish a sufficient condition under which a two-party quantum state ensemble can be used to construct a data-hiding scheme. We illustrate this condition with examples of two-qubit state ensembles consisting of two orthogonal separable states. As our data-hiding scheme can be implemented with separable states of the lowest possible dimension, its practical realization becomes significantly more attainable.

</details>


### [100] [Exponential convergence dynamics in Grover's search algorithm](https://arxiv.org/abs/2512.15100)
*Samuel Cogan,Jonathan Raghoonanan,Tim Byrnes*

Main category: quant-ph

TL;DR: 本文提出了一种改进的Grover搜索算法，通过消除振荡动力学，使搜索过程呈现指数衰减进入解状态，解决了原算法需要预先知道解数量的"舒芙蕾问题"。


<details>
  <summary>Details</summary>
Motivation: Grover搜索算法是量子计算应用的基础，提供相对于经典方法的二次加速。但该算法存在一个主要限制：需要预先知道解的数量才能获得最优成功概率，这是由于初始状态和解状态之间的振荡动力学（"舒芙蕾问题"）。虽然已有多种方法试图解决这个问题，但各自存在效率低下或对控制误差敏感的缺点。

Method: 通过修改Grover算法来消除振荡动力学，使搜索过程呈现指数衰减进入解状态。基本思想是使用辅助量子比特将解状态转换为一个储层，使得初始状态被非反射性地吸收。通过对连续算法进行Trotter化，得到一个量子电路，其性能与原始算法相当。

Result: 改进后的算法消除了振荡动力学，搜索过程呈现指数衰减特性。通过Trotter化得到的量子电路具有与原始Grover算法相同的二次量子加速性能。

Conclusion: 本文提出的改进Grover算法成功解决了"舒芙蕾问题"，消除了对解数量先验知识的需求，同时保持了原始算法的二次加速优势，为量子搜索算法提供了更稳健的实现方案。

Abstract: Grover's search algorithm is the cornerstone of many applications of quantum computing, providing a quadratic speed-up over classical methods. One limitation of the algorithm is that it requires knowledge of the number of solutions to obtain an optimal success probability, due to the oscillatory dynamics between the initial and solutions states (the ``soufflé problem''). While various methods have been proposed to solve this problem, each has their drawbacks in terms of inefficiency or sensitivity to control errors. Here, we modify Grover's algorithm to eliminate the oscillatory dynamics, such that the search proceeds as an exponential decay into the solution states. The basic idea is to convert the solution states into a reservoir by using ancilla qubits such that the initial state is nonreflectively absorbed. Trotterizing the continuous algorithm yields a quantum circuit that gives equivalent performance, which has the same quadratic quantum speedup as the original algorithm.

</details>


### [101] [Universal Blind Quantum Computation with Recursive Rotation Gates](https://arxiv.org/abs/2512.15101)
*Mohit Joshi,Manoj Kumar Mishra,S. Karthikeyan*

Main category: quant-ph

TL;DR: 提出了一种基于参数旋转门递归解密的通用盲量子计算协议，无需服务器端高度纠缠态，显著减少安全变分算法原型设计的通信轮次。


<details>
  <summary>Details</summary>
Motivation: 现有盲量子计算协议要么依赖高度纠缠的资源态（测量基模型），要么基于非参数资源集（电路基模型），这些限制阻碍了在NISQ时代特别是依赖参数门的混合量子-经典基础设施中的实际应用。

Method: 基于参数旋转门的递归解密，该协议不需要服务器端的高度纠缠态，并且显著减少了实际原型设计中安全变分算法所需的通信轮次。

Result: 提出了一种通用盲量子计算协议，能够在混合量子-经典基础设施中实现安全的盲计算，特别适用于依赖参数门的变分算法。

Conclusion: 该协议解决了现有盲量子计算协议在NISQ时代的实际应用限制，为安全变分算法的原型设计提供了更实用的解决方案。

Abstract: Blind Quantum Computation lets a limited-capability client delegate its complex computation to a remote server without revealing its data or computation. Several such protocols have been proposed under varied quantum computing models. However, these protocols either rely on highly entangled resource states (in measurement-based models) or are based on non-parametric resource sets (in circuit-based models). These restrictions hinder the practical applicability of such an algorithm in the NISQ era, especially concerning the hybrid quantum-classical infrastructure, which depends on parametric gates. We present a protocol for universal blind quantum computation based on recursive decryption of parametric rotation gates, which does not require a highly entangled state at the server side and substantially reduces the communication rounds required for practical prototyping of secure variational algorithms.

</details>


### [102] [Sharing quantum indistinguishability with multiple parties](https://arxiv.org/abs/2512.15199)
*Lemieux Wang,Hanwool Lee,Joonwoo Bae,Kieran Flatt*

Main category: quant-ph

TL;DR: 该论文提出了一种基于最大置信度测量的顺序状态判别方案，允许多方共享由单一方产生的量子不确定性（以最大相对熵衡量），利用弱测量让多个参与方能在单个量子系统上进行状态判别。


<details>
  <summary>Details</summary>
Motivation: 量子非正交态的不可区分性是量子信息应用（如密码学和随机性生成）中的宝贵资源。本文旨在开发一种方案，使多个参与方能够共享由单一方产生的量子不确定性，这对于理解顺序信息提取的极限和指导量子资源在顺序设置中的共享具有重要意义。

Method: 提出基于最大置信度测量的顺序状态判别方案，利用弱测量技术，允许多个参与方在单个量子系统上执行状态判别。通过包含对称性和不包含对称性的多个示例来展示方案的工作原理。

Result: 开发了一种有效的顺序状态判别方案，能够实现多方共享量子不确定性。通过具体示例验证了方案在不同情况下的可行性，包括具有对称性和不具有对称性的量子态系综。

Conclusion: 该顺序状态判别方案对于理解顺序信息提取的最终极限具有重要作用，并将指导顺序设置中量子资源共享的发展，为量子密码学和随机性生成等应用提供理论基础。

Abstract: Quantum indistinguishability of non-orthogonal quantum states is a valuable resource in quantum information applications such as cryptography and randomness generation. In this article, we present a sequential state-discrimination scheme that enables multiple parties to share quantum uncertainty, in terms of the max relative entropy, generated by a single party. Our scheme is based upon maximum-confidence measurements and takes advantages of weak measurements to allow a number of parties to perform state discrimination on a single quantum system. We review known sequential state discrimination and show how our scheme would work through a number of examples where ensembles may or may not contain symmetries. Our results will have a role to play in understanding the ultimate limits of sequential information extraction and guide the development of quantum resource sharing in sequential settings.

</details>


### [103] [Continuous-mode analysis for practical continuous-variable quantum key distribution](https://arxiv.org/abs/2512.15301)
*Yanhao Sun,Jiayu Ma,Xiangyu Wang,Song Yu,Ziyang Chen,Hong Guo*

Main category: quant-ph

TL;DR: 该论文提出了一个基于时间模式的连续变量量子密钥分发理论框架，能够更准确地描述设备非理想性，并开发了适用于连续模式场景的密钥率计算方法，通过优化脉冲整形格式和数字信号处理，在30公里光纤实验中实现了约50%的密钥率提升。


<details>
  <summary>Details</summary>
Motivation: 随着CV-QKD系统向数字化实现发展，设备非理想性导致光场从单模区域进入连续模区域，理论模型与实际系统之间存在不匹配问题，需要更准确描述设备非理想性的理论框架。

Method: 引入时间模式构建基于纠缠的方案来更准确捕捉设备非理想性，开发适用于连续模式场景的密钥率计算方法，优化脉冲整形格式，分析线性加权重构数字信号处理方法。

Result: 实验证明优化脉冲整形格式在探测器带宽受限条件下能显著提升性能，提出的模型有效描述了采样时间偏差的影响，线性加权重构DSP方法在30公里光纤实验中使密钥率提升约50%，无需额外硬件。

Conclusion: 提出的理论框架能够适应更广泛的实验条件，可以指导数字CV-QKD系统的优化，为实际系统提供了更准确的理论模型和性能提升方法。

Abstract: Continuous-variable quantum key distribution (CV-QKD) enables two remote parties to establish information-theoretically secure keys and offers high practical feasibility due to its compatibility with mature coherent optical communication technologies. However, as CV-QKD systems progress toward digital implementations, device nonidealities drive the optical field from a single-mode to a continuous-mode region, thereby underscoring the mismatch between theoretical models and practical systems. Here, we introduce temporal modes to construct an entanglement-based scheme that more accurately captures device nonidealities and develop a corresponding secret key rate calculation method applicable to continuous-mode scenarios. We demonstrate that optimizing the pulse-shaping format can significantly improve performance under detector-bandwidth-limited conditions. Experimental results also confirm that the proposed model effectively describes the impact of sampling-time deviations. We further analyze a linear weighted-reconstruction digital signal processing method,which improves the secret key rate by approximately 50% in a 30-km fiber experiment without requiring additional hardware, demonstrating a substantial performance enhancement at metropolitan distances. The proposed theoretical framework accommodates a broader range of experimental conditions and can guide the optimization of digital CV-QKD systems.

</details>


### [104] [Practical Challenges in Executing Shor's Algorithm on Existing Quantum Platforms](https://arxiv.org/abs/2512.15330)
*Paul Bagourd,Julian Jang-Jaccard,Vincent Lenders,Alain Mermoud,Torsten Hoefler,Cornelius Hempel*

Main category: quant-ph

TL;DR: 当前量子计算机通过Shor算法破解RSA等公钥密码系统仍存在巨大差距，实验显示现有云量子硬件无法分解密码学相关整数


<details>
  <summary>Details</summary>
Motivation: 量子计算机对RSA、ECC等公钥密码系统构成根本威胁，Shor算法理论上可用不到百万个噪声量子比特破解2048位RSA密钥。虽然这种机器尚未存在，但小型云量子处理器和开源Shor算法实现的出现，促使研究当前平台能实际分解多大密钥

Method: 在多个云量子计算机上实验研究Shor算法，使用公开可用的实现方案

Result: 发现当前量子硬件能力与分解密码学相关整数的要求之间存在显著差距。电路构造仍需针对每个模数高度定制，机器保真度不稳定，错误率高且波动大

Conclusion: 虽然量子计算对密码学构成理论威胁，但当前量子硬件在分解密码学相关整数方面仍存在实质性技术障碍，距离实际威胁还有相当距离

Abstract: Quantum computers pose a fundamental threat to widely deployed public-key cryptosystems, such as RSA and ECC, by enabling efficient integer factorization using Shor's algorithm. Theoretical resource estimates suggest that 2048-bit RSA keys could be broken using Shor's algorithm with fewer than a million noisy qubits. Although such machines do not yet exist, the availability of smaller, cloud-accessible quantum processors and open-source implementations of Shor's algorithm raises the question of what key sizes can realistically be factored with today's platforms. In this work, we experimentally investigate Shor's algorithm on several cloud-based quantum computers using publicly available implementations. Our results reveal a substantial gap between the capabilities of current quantum hardware and the requirements for factoring cryptographically relevant integers. In particular, we observe that circuit constructions still need to be highly specific for each modulus, and that machine fidelities are unstable, with high and fluctuating error rates.

</details>


### [105] [Wave-packet dynamics in pseudo-Hermitian lattices: Coexistence of Hermitian and non-Hermitian wavefronts](https://arxiv.org/abs/2512.15333)
*Alon Beck,Moshe Goldstein*

Main category: quant-ph

TL;DR: 非厄米晶格系统中波包动力学研究，发现同时存在两个不同速度的波前传播现象：一个以非厄米速度传播，另一个以厄米速度传播。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米系统中的波包动力学行为，探索非厄米系统特有的动力学效应，为理解非厄米系统的拓扑性质提供新视角。

Method: 以伪厄米哈密顿量为基础，使用典型的Hatano-Nelson模型作为主要示例，通过解析预测和数值模拟相结合的方法进行研究。

Result: 发现双波前共存现象，解释了包括"非厄米反射"、高斯波包突然位移、无序诱导波包等非传统动力学效应，解析预测与数值模拟高度吻合。

Conclusion: 双波前行为是非厄米系统的基本特征，为理解非厄米系统拓扑性质提供了新见解，并指出了可测量的实验后果。

Abstract: This paper investigates wave-packet dynamics in non-Hermitian lattice systems and reveals a surprising phenomenon: The simultaneous propagation of two distinct wavefronts, one traveling at the non-Hermitian velocity and the other at the Hermitian velocity. We show that this dual-front behavior arises naturally in systems governed by a pseudo-Hermitian Hamiltonian. Using the paradigmatic Hatano-Nelson model as our primary example, we demonstrate that this coexistence is essential for understanding a wide array of unconventional dynamical effects, including abrupt ``non-Hermitian reflections'', sudden shifts of Gaussian wave-packets, and disorder-induced emergent packets seeded by the small initial tails. We present analytic predictions that closely match numerical simulations. These results may offer new insight into the topology of non-Hermitian systems and point toward measurable experimental consequences.

</details>


### [106] [A Quantum Bluestein's Algorithm for Arbitrary-Size Quantum Fourier Transform](https://arxiv.org/abs/2512.15349)
*Nan-Hong,Kuo,Renata Wong*

Main category: quant-ph

TL;DR: 提出了一种量子版本的Bluestein算法（QBA），用于实现任意N点的精确量子傅里叶变换，避免了需要嵌入更大希尔伯特空间的问题。


<details>
  <summary>Details</summary>
Motivation: 传统量子傅里叶变换通常要求N是2的幂次，对于任意N需要嵌入到更大的希尔伯特空间，这增加了资源消耗。需要一种能够处理任意N点的高效精确量子傅里叶变换算法。

Method: 将N维QFT酉矩阵分解为三个对角二次相位门和两个标准基数为2的QFT子电路（大小为M=2^m，其中M≥2N-1）。算法基于Bluestein算法的量子版本实现。

Result: 实现了渐近门复杂度O((log N)^2)和O(log N)量子比特使用量，性能与m量子比特的2的幂次QFT相当。通过Qiskit实现和经典仿真验证了算法正确性，确认QBA能够产生任意长度输入的精确N点离散傅里叶变换。

Conclusion: QBA提供了一种高效实现任意N点精确量子傅里叶变换的方法，避免了嵌入更大希尔伯特空间的需求，在量子计算中具有重要应用价值。

Abstract: We propose a quantum analogue of Bluestein's algorithm (QBA) that implements an exact $N$-point Quantum Fourier Transform (QFT) for arbitrary $N$. Our construction factors the $N$-dimensional QFT unitary into three diagonal quadratic-phase gates and two standard radix-2 QFT subcircuits of size $M = 2^m$ (with $M \ge 2N - 1$). This achieves asymptotic gate complexity $O((\log N)^2)$ and uses $O(\log N)$ qubits, matching the performance of a power-of-two QFT on $m$ qubits while avoiding the need to embed into a larger Hilbert space. We validate the correctness of the algorithm through a concrete implementation in Qiskit and classical simulation, confirming that QBA produces the exact $N$-point discrete Fourier transform on arbitrary-length inputs.

</details>


### [107] [Amplitude-amplified coherence detection and estimation](https://arxiv.org/abs/2512.15352)
*Rhea Alexander,Michalis Skotiniotis,Daniel Manzano*

Main category: quant-ph

TL;DR: 该论文研究了未知纯量子态的相干性检测问题，提出了基于振幅放大和相位估计的协议，将样本复杂度从O(1/c)降低到O(1/√c)，并为几何相干度量提供了新的操作解释。


<details>
  <summary>Details</summary>
Motivation: 量子相干性的检测在量子理论基础和量子技术发展中至关重要，传统相干性见证只能检测部分量子态的相干性，无法处理未知纯态的情况。需要开发能够检测未知纯态相干性的高效协议。

Method: 1) 对于m个未知纯态|ψ⟩副本，证明相干性检测的样本复杂度为Θ(c(|ψ⟩)^{-1})；2) 在能够访问制备态|ψ⟩的幺正算符U_ψ及其逆U_ψ†的情况下，设计基于Grover振幅放大的协议，将样本复杂度降低到O(c(|ψ⟩)^{-1/2})；3) 通过结合振幅放大和相位估计，实现几何相干度量的加性误差估计。

Result: 1) 建立了未知纯态相干性检测的基本样本复杂度界限；2) 振幅放大协议实现了样本复杂度的二次加速；3) 相位估计协议以O(1/ε)的样本复杂度估计相干度量，优于蒙特卡洛方法的O(1/ε²)；4) 为几何相干度量提供了新的操作解释；5) 推导了协议对噪声的容忍界限。

Conclusion: 该工作开发了检测未知纯态相干性的高效协议，利用振幅放大和相位估计技术显著降低了样本复杂度，为量子相干性的实验检测提供了实用工具，并为几何相干度量赋予了新的操作意义。

Abstract: The detection and characterization of quantum coherence is of fundamental importance both in the foundations of quantum theory as well as for the rapidly developing field of quantum technologies, where coherence has been linked to quantum advantage. Typical approaches for detecting coherence employ {\it coherence witnesses} -- observable quantities whose expectation value can be used to certify the presence of coherence. By design, coherence witnesses are only able to detect coherence for some, but not all, possible states of a quantum system. In this work we construct protocols capable of detecting the presence of coherence in an {\it unknown} pure quantum state $|ψ\rangle$. Having access to $m$ copies of an unknown pure state $|ψ\rangle$ we show that the sample complexity of any experimental procedure for detecting coherence with constant probability of success $\ge 2/3$ is $Θ(c(|ψ\rangle)^{-1})$, where $c(|ψ\rangle)$ is the geometric measure of coherence of $|ψ\rangle$. However, assuming access to the unitary $U_ψ$ which prepares the unknown state $|ψ\rangle$, and its inverse $U_ψ^\dagger$, we devise a coherence detecting protocol that employs amplitude-amplification {\it a la} Grover, and uses a quadratically smaller number $O(c(|ψ\rangle)^{-1/2})$ of samples. Furthermore, by augmenting amplitude amplification with phase estimation we obtain an experimental estimation of upper bounds on the geometric measure of coherence within additive error $\varepsilon$ with a sample complexity that scales as $O(1/\varepsilon)$ as compared to the $O(1/\varepsilon^2)$ sample complexity of Monte Carlo estimation methods. The average number of samples needed in our amplitude estimation protocol provides a new operational interpretation for the geometric measure of coherence. Finally, we also derive bounds on the amount of noise our protocols are able to tolerate.

</details>


### [108] [A short history of Quantum Illumination](https://arxiv.org/abs/2512.15415)
*Marco Genovese,Ivano Ruo-Berchera*

Main category: quant-ph

TL;DR: 量子照明协议的历史发展概述，该协议具有抗噪声和损耗的鲁棒性特点


<details>
  <summary>Details</summary>
Motivation: 量子照明作为量子技术中最有趣的例子之一，一方面具有重要的应用前景，另一方面是少数能够抵抗噪声和损耗的量子协议，因此值得对其历史发展进行总结

Method: 本文采用历史回顾和总结的方法，梳理量子照明协议的发展历程

Result: 提供了量子照明协议发展的历史脉络和关键进展的简要总结

Conclusion: 量子照明是一个重要的量子技术协议，具有实际应用价值且对噪声和损耗具有鲁棒性，对其历史的总结有助于理解该领域的发展

Abstract: Quantum illumination represents one of the most interesting examples of quantum technologies. On the one hand, it can find significant applications; on the other hand, it is one of the few quantum protocols robust against noise and losses. Here we present a short summary of the history of this quantum protocol.

</details>


### [109] [Characterizing Fisher information of quantum measurement](https://arxiv.org/abs/2512.15428)
*Rakesh Saini,Jukka Kiukas,Daniel Burgarth,Alexei Gilchrist*

Main category: quant-ph

TL;DR: 该论文建立了信息完备测量与量子参数估计之间的理论联系，通过算子框架理论分析信息提取的几何特性，揭示了信息完备性对局部量子参数估计施加的基本权衡。


<details>
  <summary>Details</summary>
Motivation: 信息完备测量是量子态重构的基础，而量子参数估计基于量子态流形的局部结构。本文旨在建立这两方面之间的理论联系，特别是在单一信息完备测量的背景下，理解信息提取的几何特性和操作特性。

Method: 采用适当调整的算子框架理论，通过分析相关框架算子的谱分解，将经典Fisher信息与量子Fisher信息的比值与该谱分解联系起来，并将这些界限与参数编码的最优和最差方向相关联。

Result: 建立了经典Fisher信息与量子Fisher信息比值的界限，该界限由相关框架算子的谱分解决定。揭示了信息提取的几何和操作特性，展示了信息完备性对局部量子参数估计施加的基本权衡。

Conclusion: 通过算子框架理论，成功建立了信息完备测量与量子参数估计之间的理论联系，揭示了信息完备性对局部量子参数估计的基本限制和权衡，为理解量子信息提取的几何特性提供了新的理论框架。

Abstract: Informationally complete measurements form the foundation of universal quantum state reconstruction, while quantum parameter estimation is based on the local structure of the manifold of quantum states. Here we establish a general link between these two aspects, in the context of a single informationally complete measurement, by employing a suitably adapted operator frame theory. In particular, we bound the ratio between the classical and quantum Fisher information in terms of the spectral decomposition of the associated frame operator, and connect these bounds to the optimal and least optimal directions for parameter encoding. The geometric and operational characterization of information extraction thus obtained reveals the fundamental tradeoff imposed by informational completeness on local quantum parameter estimation.

</details>


### [110] [The inverse parametric problem](https://arxiv.org/abs/2512.15453)
*Michele Cortinovis,Fabio Lingua,David B. Haviland*

Main category: quant-ph

TL;DR: 提出计算参量振荡器泵浦波形频率分量的方法，实现模式间期望的频率混合或散射，验证了方法有效性并展示复杂散射过程


<details>
  <summary>Details</summary>
Motivation: 开发一种工具来实现多模态高斯态中连续变量量子信息的编码和操控，需要能够精确控制模式间散射过程的方法

Method: 提出计算泵浦波形频率分量的方法，通过数值分析验证，研究对高斯噪声的敏感性，并开发动态控制模式散射的近似方法

Result: 方法成功实现了微波频率下涉及多模式的复杂散射过程，包括非互易模式循环，并能快速按预定方式在模式间路由信号

Conclusion: 这些方法为多模态高斯态中连续变量量子信息的编码和操控提供了有用工具

Abstract: We present a method to calculate the frequency components of a pump waveform driving a parametric oscillator, which realizes a desired frequency mixing or scattering between modes. The method is validated by numerical analysis and we study its sensitivity to added Gaussian noise. A series of experiments apply the method and demonstrate its ability to realize complex scattering processes involving many modes at microwave frequencies, including non-reciprocal mode circulation. We also present an approximate method to dynamically control mode scattering, capable of rapidly routing signals between modes in a prescribed manner. These methods are useful tools for encoding and manipulating continuous variable quantum information with multi-modal Gaussian states.

</details>


### [111] [Benchmarking Atomic Ionization Driven by Strong Quantum Light](https://arxiv.org/abs/2512.15458)
*Yi-Jia Mao,En-Rui Zhou,Yang Li,Pei-Lun He,Feng He*

Main category: quant-ph

TL;DR: 该研究通过求解原子暴露于明亮压缩真空光下的完全量子化含时薛定谔方程，建立了强量子光与物质相互作用的理论基准，揭示了广泛使用的Q表示的局限性，并开发了基于费曼路径积分的理论框架来正确处理电子-光子量子纠缠。


<details>
  <summary>Details</summary>
Motivation: 高强度量子光脉冲为控制光-物质相互作用提供了新工具，但目前用于描述强量子光与原子分子相互作用的理论框架的严谨性尚未得到验证。需要建立严格的理论基准来评估现有方法的准确性。

Method: 通过求解原子暴露于明亮压缩真空光下的完全量子化含时薛定谔方程进行从头算模拟，并开发基于费曼路径积分的理论框架来正确处理电子-光子量子纠缠。

Result: 从头算模拟揭示了广泛使用的Q表示的关键局限性：虽然它能准确再现追踪光子态后的总光电子谱，但完全无法捕捉电子-光子联合能谱。新开发的基于费曼路径积分的框架能够正确处理量子纠缠。

Conclusion: 该研究为强场量子光学这一新兴领域提供了定量基准和基础理论见解，揭示了现有方法的局限性并提出了更准确的理论框架来处理量子纠缠效应。

Abstract: The recently available high-intensity quantum light pulses provide novel tools for controlling light-matter interactions. However, the rigor of the theoretical frameworks currently used to describe the interaction of strong quantum light with atoms and molecules remains unverified. Here, we establish a rigorous benchmark by solving the fully quantized time-dependent Schrödinger equation for an atom exposed to bright squeezed vacuum light. Our \textit{ab initio} simulations reveal a critical limitation of the widely used $Q$-representation: although it accurately reproduces the total photoelectron spectrum after tracing over photon states, it completely fails to capture the electron-photon joint energy spectrum. To overcome this limitation, we develop a general theoretical framework based on the Feynman path integral that properly incorporates the electron-photon quantum entanglement. Our results provide both quantitative benchmarks and fundamental theoretical insights for the emerging field of strong-field quantum optics.

</details>


### [112] [Energy Inference of Black-Box Quantum Computers Using Quantum Speed Limit](https://arxiv.org/abs/2512.15472)
*Nobumasa Ishida,Yoshihiko Hasegawa*

Main category: quant-ph

TL;DR: 该论文提出了一种通过量子速度极限来推断黑盒量子处理器中门哈密顿量能量尺度的方法，仅使用用户可访问的执行时间数据，无需硬件级信息。


<details>
  <summary>Details</summary>
Motivation: 云量子计算机用户无法访问硬件级信息（如哈密顿量），这阻碍了对量子处理器物理特性的表征。需要一种仅基于用户可访问数据的方法来推断黑盒量子处理器的能量尺度。

Method: 将Margolus-Levitin和Mandelstam-Tamm量子速度极限重新解释为能量期望值和方差的估计器，并将其与量子态正交化的最短时间联系起来。通过门时间放大技术，从秒级作业执行时间推断纳秒级的最短门时间，从而估计单量子比特、双量子比特和三量子比特门的能量尺度。

Result: 在IBM超导量子处理器上应用该方法，估计出的能量尺度与超导量子比特系统中典型的驱动能量一致，表明当前门操作接近量子速度极限。

Conclusion: 通过操作时间测量可以定量访问黑盒量子计算机的基本能量特性，这反映了不确定性原理强加的时间与能量之间的共轭关系。该方法为表征云量子计算机的物理特性提供了一种新途径。

Abstract: Cloud-based quantum computers do not provide users with access to hardware-level information such as the underlying Hamiltonians, which obstructs the characterization of their physical properties. We propose a method to infer the energy scales of gate Hamiltonians in such black-box quantum processors using only user-accessible data, by exploiting quantum speed limits. Specifically, we reinterpret the Margolus-Levitin and Mandelstam-Tamm bounds as estimators of the energy expectation value and variance, respectively, and relate them to the shortest time for the processor to orthogonalize a quantum state. This shortest gate time, expected to lie on the nanosecond scale, is inferred from job execution times measured in seconds by employing gate-time amplification. We apply the method to IBM's superconducting quantum processor and estimate the energy scales associated with single-, two-, and three-qubit gates. The order of estimated energy is consistent with typical drive energies in superconducting qubit systems, suggesting that current gate operations approach the quantum speed limit. Our results demonstrate that fundamental energetic properties of black-box quantum computers can be quantitatively accessed through operational time measurements, reflecting the conjugate relationship between time and energy imposed by the uncertainty principle.

</details>


### [113] [QuantGraph: A Receding-Horizon Quantum Graph Solver](https://arxiv.org/abs/2512.15476)
*Pranav Vaidhyanathan,Aristotelis Papatheodorou,David R. M. Arvidsson-Shukur,Mark T. Mitchison,Natalia Ares,Ioannis Havoutis*

Main category: quant-ph

TL;DR: QuantGraph是一个两阶段量子增强框架，将图优化问题转化为量子搜索问题，通过局部最优路径阈值剪枝搜索空间，并结合经典控制理论实现稳定高效的求解。


<details>
  <summary>Details</summary>
Motivation: 传统动态规划在图优化问题中随着问题规模增大而扩展性不佳，需要更高效的解决方案来处理大规模图优化问题。

Method: 采用两阶段量子增强框架：1）局部阶段寻找局部最优转移序列，其累积成本作为阈值剪枝搜索空间；2）全局阶段基于阈值细化解决方案。两个阶段都使用Grover自适应搜索算法的变体，并嵌入到滚动时域模型预测控制方案中实现稳定和引导。

Result: 搜索空间减少高达60%，在固定查询预算下控制离散化精度提高2倍，同时保持Grover搜索相对于经典方法的固有二次加速优势。

Conclusion: QuantGraph框架通过量子增强和经典控制理论的结合，实现了对图优化问题的高效、稳定求解，显著降低了计算复杂度并提高了精度。

Abstract: Dynamic programming is a cornerstone of graph-based optimization. While effective, it scales unfavorably with problem size. In this work, we present QuantGraph, a two-stage quantum-enhanced framework that casts local and global graph-optimization problems as quantum searches over discrete trajectory spaces. The solver is designed to operate efficiently by first finding a sequence of locally optimal transitions in the graph (local stage), without considering full trajectories. The accumulated cost of these transitions acts as a threshold that prunes the search space (up to 60% reduction for certain examples). The subsequent global stage, based on this threshold, refines the solution. Both stages utilize variants of the Grover-adaptive-search algorithm. To achieve scalability and robustness, we draw on principles from control theory and embed QuantGraph's global stage within a receding-horizon model-predictive-control scheme. This classical layer stabilizes and guides the quantum search, improving precision and reducing computational burden. In practice, the resulting closed-loop system exhibits robust behavior and lower overall complexity. Notably, for a fixed query budget, QuantGraph attains a 2x increase in control-discretization precision while still benefiting from Grover-search's inherent quadratic speedup compared to classical methods.

</details>


### [114] [Lower Bounding the Secret Key Capacity of Bosonic Gaussian Channels via Optimal Gaussian Measurements](https://arxiv.org/abs/2512.15502)
*Giuseppe Ortolano,Stefano Pirandola,Leonardo Banchi*

Main category: quant-ph

TL;DR: 论文研究了在玻色子量子信道中，基于最优单模高斯测量的全高斯协议所能达到的最大私有通信速率，为信道保密容量建立了下界。


<details>
  <summary>Details</summary>
Motivation: 研究玻色子量子信道中私有通信的最大可实现速率，为相位不敏感高斯信道的保密容量建立更准确的下界，特别是针对热损耗、热放大和加性噪声信道。

Method: 采用基于最优单模高斯测量的全高斯协议，分析相位不敏感高斯信道类，包括热损耗信道、热放大信道和加性噪声信道。

Result: 对于热损耗和热放大信道，验证了先前提出协议的最优性，并提供了简化的性能评估公式；对于加性噪声信道，获得了比以往已知更好的下界。

Conclusion: 该研究为玻色子量子信道的私有通信建立了重要的性能基准，特别是在相位不敏感高斯信道中，为量子保密通信的实际实现提供了理论指导。

Abstract: We find the maximum rate achievable in the private communication over a bosonic quantum channel with a fully Gaussian protocol based on optimal single-mode Gaussian measurements. This rate establishes a lower bound on the secret rate capacity of the channel. We focus on the class of phase-insensitive Gaussian channels. For the thermal-loss and thermal amplification channels, our results demonstrate the optimality, within the constraints of our analysis, of previously proposed protocols, while also providing a significantly simplified formula for their performance evaluation. For the added noise channel, our rate provides a better lower bound than any previously known.

</details>


### [115] [Decoherence dynamics across sub-Planckian to arbitrary scales using kitten states](https://arxiv.org/abs/2512.15513)
*Naeem Akhtar,Jia-Xin Peng,Tan Hailin,Xiaosen Yang,Dong Wang*

Main category: quant-ph

TL;DR: 该研究探讨了量子态在相空间中的精细特征（特别是亚普朗克结构）与环境退相干之间的权衡关系，以罗盘态及其光子加减变体为例，发现相空间特征越精细，对退相干越敏感。


<details>
  <summary>Details</summary>
Motivation: 环境退相干会破坏量子系统的相干性和干涉效应，影响量子特性的保持。不同量子态在相空间中的特征结构（如亚普朗克尺度特征）对退相干的敏感性不同，这关系到量子传感等应用的实际可行性。

Method: 研究采用多种成熟的理论技术，分析罗盘态及其光子加减变体与热库的相互作用。这些量子态在相空间中具有超越普朗克尺度的特征维度，适合用于量子传感。通过研究它们与热库的耦合，揭示相空间精细特征与退相干之间的权衡关系。

Result: 研究发现相空间中最精细特征（如亚普朗克结构）的精细程度与退相干程度之间存在明确权衡：增加参数可以增强相空间中的亚普朗克精度，但同时会放大这些罗盘态对退相干的脆弱性。相空间扩展更大的特征表现出更强的可持续性。

Conclusion: 该研究通过罗盘态验证了一个普遍规律：任何纯量子态与热库相互作用时，相空间特征越精细（特别是亚普朗克结构），对退相干越敏感；而相空间扩展更大的特征则更具可持续性。这对量子传感应用中量子态的设计和选择具有重要指导意义。

Abstract: Environmental decoherence occurs when a quantum system interacts with its surroundings, progressively reducing quantum interference and coherence, complicating the preservation of critical quantum properties over time, especially during experimental implementation. The effect of decoherence varies depending on the phase-space features of quantum states, which are theoretically characterized by the Wigner phase space and appear at different scales. We explore the compass state and its photon-added and photon-subtracted variants, each of which exhibits phase-space features with dimensions beyond the Planck scale, making them suitable for quantum sensing applications. We investigate the interaction of these states with a heat reservoir by employing a range of well-established theoretical techniques, revealing a clear tradeoff between the degree of fineness in the smallest features, such as the sub-Planck structure, and the extent of decoherence. Specifically, increasing the parameters enhances sub-Planck precision in phase space, concomitantly amplifying the fragility of these compass states to undesired decoherence. Our general illustration, validated through these compass states, also applies to any pure quantum state interacting with the considered heat reservoir, exhibiting enhanced sustainability of features at larger phase-space extensions.

</details>


### [116] [Quadratic power enhancement in extended Dicke quantum battery](https://arxiv.org/abs/2512.15607)
*Harsh Sharma,Himadri Shekhar Dhar*

Main category: quant-ph

TL;DR: 该论文展示了一种由N个两能级系统（自旋）与两个光子腔模相互作用的电池，其中一个腔模处于色散区，实现了功率的二次增强（N²缩放）。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池的功率增强机制，探索超越Dicke电池的量子优势，同时确保实验可实现性、能量效率和抗噪声稳定性。

Method: 采用混合系统设计：N个两能级系统（自旋）与两个光子腔模相互作用，其中一个腔模工作在色散区。通过量子关联和演化速度的N²缩放实现功率增强。

Result: 实现了功率的二次增强（N²缩放），这源于量子关联和演化速度的同时N²缩放，展示了真正的量子优势。该系统实验可实现，功率增强不以显著牺牲能量效率为代价，且具有更好的可调谐性和抗噪声稳定性。

Conclusion: 该混合量子电池设计通过量子关联和演化速度的N²缩放实现了真正的量子优势，为实验可实现的、高效且稳定的量子能量存储系统提供了新途径。

Abstract: We demonstrate a quadratic enhancement of power in a battery consisting of $N$ two-level systems or spins interacting with two photonic cavity modes, where one of the modes is in the dispersive regime. In contrast to Dicke batteries, the power enhancement arises from a $N^2$ scaling of both quantum correlations and speed of evolution, thus highlighting genuine quantum advantage. Moreover, this hybrid setup is experimentally realizable and ensures that power enhancement is not achieved at significant cost to energy efficiency, while allowing for greater tunability and stable operation in the presence of noise.

</details>


### [117] [Implementation of the Quantum Fourier Transform on a molecular qudit with full refocusing and state tomography](https://arxiv.org/abs/2512.15611)
*Marcos Rubín-Osanz,Laura Bersani,Simone Chicco,Giuseppe Allodi,Roberto De Renzi,Athanasios Mavromagoulos,Michael D. Roy,Stergios Piligkos,Elena Garlatti,Stefano Carretta*

Main category: quant-ph

TL;DR: 在173Yb(trensal)分子自旋qudit中实现了量子傅里叶变换，通过全重聚焦协议克服了非均匀展宽，展示了分子自旋qudit进行量子逻辑运算的可行性。


<details>
  <summary>Details</summary>
Motivation: 镧系分子自旋qudit为量子技术提供了有前景的平台，但实验上对其相干态精确控制的演示仍然稀缺，特别是在长脉冲序列中实现qudit态之间的相干控制存在困难。

Method: 在173Yb(trensal) qudit中实现量子傅里叶变换，将量子信息存储在相干相位中。采用嵌入全重聚焦协议的算法来缓解非均匀展宽，通过完整态层析评估算法性能，并结合模拟分析非均匀展宽的物理机制。

Result: 成功实现了高保真度的量子傅里叶变换，全重聚焦协议有效减轻了非均匀展宽的影响，实现了量子态的高保真恢复。完整态层析证实了算法的性能，模拟揭示了非均匀展宽背后的物理机制。

Conclusion: 这项工作证明了分子自旋qudit进行量子逻辑运算的可行性，突显了其在量子技术中的潜力，为复杂量子算法在分子自旋系统中的实现奠定了基础。

Abstract: Molecular spin qudits based on lanthanide complexes offer a promising platform for quantum technologies, combining chemical tunability with multi-level encoding. However, experimental demonstrations of their envisaged capabilities remain scarce, posing the difficulty of achieving precise control over coherences between qudit states in long pulse sequences. Here, we implement in 173Yb(trensal) qudit the Quantum Fourier Transform (QFT), a core component of numerous quantum algorithms, storing quantum information in the phases of coherences. QFT provides an ideal benchmark for coherence manipulation and an unprecedented challenge for molecular spin qudits. We address this challenge by embedding a full-refocusing protocol for spin qudits in our algorithm, mitigating inhomogeneous broadening and enabling a high-fidelity recovery of the state. Complete state tomography demostrates the performance of the algorithm, while simulations provide insight into the physical mechanisms behind inhomogeneous broadening. This work shows the feasibility of quantum logic on molecular spin qudits and highlights their potential.

</details>


### [118] [Characterization of Generalized Coherent States through Intensity-Field Correlations](https://arxiv.org/abs/2512.15655)
*Ignacio Salinas Valdivieso,Victor Gondret,Gerd Hartmann S.,Mariano Uria,Pablo Solano,Carla Hermann-Avigliano*

Main category: quant-ph

TL;DR: 该论文提出使用强度-场关联函数作为检测非高斯量子态非经典性的简单实验方法，特别针对广义相干态，其归一化关联函数偏离1即表明非经典行为。


<details>
  <summary>Details</summary>
Motivation: 广义相干态作为量子信息处理和精密计量中的重要资源，具有Wigner负性和计量优势等量子特性。然而，由于这些态在所有阶上保持相干性，传统的强度-强度关联测量无法揭示其非经典特性，因此需要开发更简单、实验上可访问的非经典性见证方法。

Method: 提出使用强度-场关联函数作为非经典性的见证指标。对于广义相干态，该归一化关联函数偏离1即表明非经典行为。推导了Kerr生成态的解析结果，并将分析扩展到广义相干态的统计混合态。

Result: 强度-场关联函数能够有效检测广义相干态的非经典特性，为实验提供了一种实时、低复杂度的量子特征检测方法，适用于广泛的非线性体系。

Conclusion: 强度-场关联函数是一种简单且实验上可访问的非经典性见证方法，特别适用于检测广义相干态等非高斯量子态的量子特征，为实验研究提供了实用工具。

Abstract: Non-Gaussian quantum states of light are essential resources for quantum information processing and precision metrology. Among them, generalized coherent states (GCS), which naturally arise from the evolution of a coherent state with a nonlinear medium, exhibit useful quantum features such as Wigner negativity and metrological advantages [Phys. Rev. Res. 5, 013165 (2023)]. Because these states remain coherent to all orders, their nonclassical character cannot be revealed through standard intensity-intensity correlation measurements. Here, we demonstrate that the intensity-field correlation function alone provides a simple and experimentally accessible witness of nonclassicality. For GCSs, any deviation of this normalized correlation from unity signals nonclassical behavior. We derive analytical results for Kerr-generated states and extend the analysis to statistical mixtures of GCSs. The proposed approach enables real-time, low-complexity detection of quantum signatures in non-Gaussian states, offering a practical tool for experiments across a broad range of nonlinear regimes.

</details>


### [119] [Prospects for quantum advantage in machine learning from the representability of functions](https://arxiv.org/abs/2512.15661)
*Sergi Masot-Llima,Elies Gil-Fuster,Carlos Bravo-Prieto,Jens Eisert,and Tommaso Guaita*

Main category: quant-ph

TL;DR: 该论文提出了一个连接参数化量子电路结构与可学习函数数学性质的框架，用于分析量子机器学习模型的经典可模拟性，并识别量子优势的潜在机会。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习领域存在大量模型和算法，需要清晰的理论框架来理解哪些模型真正具有量子优势，哪些可以被经典模拟，从而指导寻找量子优势的实际路径。

Method: 引入一个连接参数化量子电路结构与可学习函数数学性质的框架，分析电路深度、非Clifford门数量等基本属性如何决定模型的经典可模拟性，揭示去量子化的共同路径。

Result: 该框架揭示了量子机器学习模型的三类区分：完全可经典模拟的模型、函数空间可经典处理的模型、以及保持量子鲁棒性的模型，为理解不同模型与经典可模拟性的关系提供了概念地图。

Conclusion: 这一视角为量子机器学习领域提供了清晰的概念框架，阐明了不同模型与经典可模拟性的关系，并指出了量子优势可能存在的具体方向，有助于指导寻找真正的量子优势。

Abstract: Demonstrating quantum advantage in machine learning tasks requires navigating a complex landscape of proposed models and algorithms. To bring clarity to this search, we introduce a framework that connects the structure of parametrized quantum circuits to the mathematical nature of the functions they can actually learn. Within this framework, we show how fundamental properties, like circuit depth and non-Clifford gate count, directly determine whether a model's output leads to efficient classical simulation or surrogation. We argue that this analysis uncovers common pathways to dequantization that underlie many existing simulation methods. More importantly, it reveals critical distinctions between models that are fully simulatable, those whose function space is classically tractable, and those that remain robustly quantum. This perspective provides a conceptual map of this landscape, clarifying how different models relate to classical simulability and pointing to where opportunities for quantum advantage may lie.

</details>


### [120] [Combinatorial structures in quantum correlation: A new perspective](https://arxiv.org/abs/2512.15686)
*Rohit kumar,Satyabrata Adhikari*

Main category: quant-ph

TL;DR: 该论文提出了一种新的量子态类别——$A_α$-graph states，通过图的度矩阵和邻接矩阵的凸组合构建，并研究了其纠缠特性检测方法。


<details>
  <summary>Details</summary>
Motivation: 图论结构在量子系统描述和分析中具有核心作用。现有标准图态方法存在局限性，需要构建新的图相关量子态类别，并建立与图参数直接相关的纠缠检测框架。

Method: 1. 引入$A_α$-graph states：通过度矩阵$D$和邻接矩阵$A_G$的归一化凸组合构建量子态，包含可调参数$α∈(0,1]$
2. 建立正半定条件：确定$ρ_α^{A_G}$为有效量子态的条件
3. 推导PPT条件：基于图参数（邻接矩阵Frobenius范数、顶点度、顶点总数）建立正部分转置条件
4. 开发基于矩的纠缠检测：将$p_3$-PPT准则（依赖部分转置的第二和第三矩）与图论结合

Result: 1. 建立了$A_α$-graph states作为有效量子态的条件
2. 获得了简单图中$A_α$-graph states表示纠缠态的$α$参数范围
3. 开发了基于图论的矩检测框架，该框架可通过随机测量、交换操作和机器学习协议实验实现
4. 为从图导出的结构化量子态提供了物理相关的纠缠检测方法

Conclusion: 该工作将图论与基于矩的纠缠检测相结合，为量子关联中组合结构的作用提供了新视角。提出的$A_α$-graph states不同于标准图态，其纠缠特性可通过图参数直接分析，为实验可访问的纠缠检测提供了理论框架。

Abstract: Graph-theoretic structures play a central role in the description and analysis of quantum systems. In this work, we introduce a new class of quantum states, called $A_α$-graph states, which are constructed from either unweighted or weighted graphs by taking the normalised convex combination of the degree matrix $D$ and the adjacency matrix $A_G$ of a graph $G$. The constructed states are different from the standard graph states arising from stabiliser formalism. Our approach is also different from the approach used by Braunstein et al. This class of states depend on a tunable mixing parameter $α\in (0,1]$. We first establish the conditions under which the associated operator $ρ_α^{A_G}$ is positive semidefinite and hence represents a valid quantum state. We then derive a positive partial transposition (PPT) condition for $A_α$-graph states in terms of graph parameters. This PPT condition involves only the Frobenius norm of the adjacency matrix of the graph, the degrees of the vertices and the total number of vertices. For simple graphs, we obtain the range of the parameter $α$ for which the $A_α$-graph states represent a class of entangled states. We then develop a graph-theoretic formulation of a moments-based entanglement detection criterion, focusing on the recently proposed $p_3$-PPT criterion, which relies on the second and third moments of the partial transposition. Since the estimation of these moments is experimentally accessible via randomised measurements, swap operations, and machine-learning-based protocols, our approach provides a physically relevant framework for detecting entanglement in structured quantum states derived from graphs. This work bridges graph theory and moments-based entanglement detection, offering a new perspective on the role of combinatorial structures in quantum correlations.

</details>


### [121] [A random purification channel for arbitrary symmetries with applications to fermions and bosons](https://arxiv.org/abs/2512.15690)
*Michael Walter,Freek Witteveen*

Main category: quant-ph

TL;DR: 论文提出了一种针对任意对称群的随机纯化通道构造，将混合量子态映射到通过群扭转获得的随机纯化态，并应用于费米子和玻色子高斯态。


<details>
  <summary>Details</summary>
Motivation: 现有随机纯化通道仅适用于一般混合态，需要扩展到具有对称性的量子系统，特别是费米子和玻色子系统，以开发更高效的态层析和性质测试协议。

Method: 为任意酉群G构造量子通道，将包含在G生成代数中的态映射到通过群G扭转获得的随机纯化态，推广了原始随机纯化构造。

Result: 获得了费米子和玻色子高斯纯化通道的存在性，实现了首个在模式和误差方面均最优的费米子高斯态层析协议，并改进了该类态的性质测试方法。

Conclusion: 通过将随机纯化推广到任意对称群，为对称量子系统提供了统一的纯化框架，在费米子高斯态表征方面取得了显著进展，为量子信息处理提供了新工具。

Abstract: The random purification channel maps n copies of any mixed quantum state to n copies of a random purification of the state. We generalize this construction to arbitrary symmetries: for any group G of unitaries, we construct a quantum channel that maps states contained in the algebra generated by G to random purifications obtained by twirling over G. In addition to giving a surprisingly concise proof of the original random purification theorem, our result implies the existence of fermionic and bosonic Gaussian purification channels. As applications, we obtain the first tomography protocol for fermionic Gaussian states that scales optimally with the number of modes and the error, as well as an improved property test for this class of states.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [122] [Single-doublet model of spin reorientation](https://arxiv.org/abs/2512.14771)
*Evgenii Vasinovich,Alexander Moskvin*

Main category: cond-mat.str-el

TL;DR: 本文开发了一个简单的理论模型来描述稀土正铁氧体和正铬酸盐中的自旋重取向转变，预测了不同类型的相变行为。


<details>
  <summary>Details</summary>
Motivation: 研究稀土正铁氧体和正铬酸盐中自旋重取向转变的理论机制，这些材料在磁学研究中具有重要意义，但需要更简单的理论模型来描述其复杂的相变行为。

Method: 采用"单双重态"方法，构建包含3d子晶格各向异性和4f离子低双重态分裂贡献的自由能模型，分析各向异性参数对相变类型的影响。

Result: 模型预测了三种类型的自旋重取向转变：一级相变、二级相变和混合相变，取决于各向异性参数。分析了非磁性稀释、热容异常以及稀土磁矩在SR区域的行为。

Conclusion: 该简单理论模型能够有效描述稀土正铁氧体和正铬酸盐中的自旋重取向转变，为理解这些材料的复杂磁学行为提供了理论框架。

Abstract: A simple theoretical model is developed to describe spin reorientation (SR) transitions in rare-earth orthoferrites and orthochromites RFeO3 and RCrO3. Within a ``single-doublet'' approach, the free energy includes anisotropy contributions from the 3d-sublattice and the splitting of the lower doublet of 4f-ions. The model predicts various types of SR transitions - first-order, second-order, and mixed - depending on anisotropy parameters. Effects of non-magnetic dilution, heat capacity anomalies, and behavior of the rare-earth magnetic moment in the SR region are analyzed.

</details>


### [123] [Hearing the light: stray-field noise from the emergent photon in quantum spin ice](https://arxiv.org/abs/2512.14843)
*Gautam K. Naik,Jonathan N. Hallén,Nishan C. Jayarama,Roderich Moessner,Chris R. Laumann*

Main category: cond-mat.str-el

TL;DR: 提出利用杂散场磁力测量作为量子自旋冰中涌现光子（U(1)量子自旋液相的元激发）的直接探测方法


<details>
  <summary>Details</summary>
Motivation: 量子自旋冰中U(1)量子自旋液相的实验确认仍然是一个重大挑战，需要直接探测其元激发——涌现光子

Method: 提出使用杂散场磁力测量技术，分析腔体和薄膜几何结构下涌现光子的离散模式，研究杂散磁噪声的频谱和空间结构特征

Result: 发现杂散磁噪声的频谱和空间结构为底层电动力学提供了清晰的定性特征，预测的杂散场噪声功率在当前固态缺陷磁力测量技术的检测范围内

Conclusion: 杂散场磁力测量是探测量子自旋冰中涌现光子的有效直接方法，为实验确认U(1)量子自旋液相提供了可行的技术途径

Abstract: Decisive experimental confirmation of the $U(1)$ quantum spin liquid phase in quantum spin ice remains an outstanding challenge. In this work, we propose stray-field magnetometry as a direct probe of the emergent photons -- the gapless excitation of the emergent electrodynamics in quantum spin ice. The emergent photons are transverse magnetization waves, which, in a finite sample, form discrete modes governed by one of two sets of natural boundary conditions: ``insulating'' or ``superconducting''. Considering cavity and thin film geometries, we find that the spectrum and spatial structure of the stray magnetic noise provide a sharp qualitative signature of the underlying electrodynamics. The predicted stray-field noise power lies comfortably within the detection range of present-day solid-state defect magnetometry.

</details>


### [124] [On the applicability of the cumulant expansion method for the calculation of transport properties in electron-phonon systems](https://arxiv.org/abs/2512.14900)
*Petar Mitrić,Veljko Janković,Darko Tanasković,Nenad Vukmirović*

Main category: cond-mat.str-el

TL;DR: 评估累积展开法结合独立粒子近似在电子-声子系统中计算电荷迁移率的准确性，以Peierls和Fröhlich模型为测试平台，与玻尔兹曼形式、Migdal近似等方法对比。


<details>
  <summary>Details</summary>
Motivation: 评估累积展开法在电子-声子系统中计算电荷迁移率的准确性，因为目前玻尔兹曼形式、Migdal近似等方法是更常用的替代方法，需要验证CE方法的可靠性。

Method: 使用累积展开法结合独立粒子近似，在Peierls和Fröhlich模型上进行测试，与玻尔兹曼形式、Migdal近似及其自洽扩展方法进行对比，并基于谱求和规则进行理论分析。

Result: 对于弱到中等耦合强度且温度不太低的情况，CE方法在IPA框架下能提供准确结果；在Peierls模型中还讨论了顶点修正的作用。

Conclusion: 累积展开法结合独立粒子近似在特定条件下（弱到中等耦合、温度不太低）能准确计算电子-声子系统的电荷迁移率，为该方法的应用提供了理论支持。

Abstract: We assess the accuracy of the cumulant expansion (CE) method, combined with the independent-particle approximation (IPA), for calculating charge mobility in electron-phonon systems. As representative testbeds, we consider the Peierls and Fröhlich models, which serve as simplified frameworks where accurate or numerically exact benchmarks are available. These are used to compare the CE results with those obtained using the Boltzmann formalism, the Migdal approximation, and its self consistent extension-approaches that are presently the most commonly employed alternatives for transport calculations. Supported by analytical arguments based on spectral sum rules and by our previous results for the Holstein model, we argue that, for weak to moderate coupling strengths and not-too-low temperatures, the CE within the IPA framework yields accurate results. In the case of the Peierls model, the role of vertex corrections is also discussed.

</details>


### [125] [Pair-density-wave superconductivity and Anderson's theorem in bilayer nickelates](https://arxiv.org/abs/2512.15023)
*Hanbit Oh,Ya-Hui Zhang*

Main category: cond-mat.str-el

TL;DR: 双层镍酸盐中通过位移场打破镜像对称性可以稳定零磁场下的对密度波超导态，类似FFLO态但无需磁场


<details>
  <summary>Details</summary>
Motivation: 双层镍酸盐高温超导性的实验发现引发关注，先前研究假设两层间存在镜像对称性并关注均匀清洁超导态。本文探索打破这种镜像对称性对超导态的影响。

Method: 基于d_x^2-y^2轨道模型，采用平均场分析研究有效层间吸引作用；分析位移场、层间跃迁强度和电子填充对PDW相的影响；在一阶玻恩近似下研究无序对层间超导性的影响

Result: 位移场打破镜像对称性可以稳定对密度波超导相，该相在宽范围的位移场、层间跃迁强度和电子填充条件下保持稳定；破坏镜像对称性的无序会削弱配对，即使时间反演对称性未破缺

Conclusion: 双层镍酸盐是实现有限动量配对和探索广义无序效应的可调控平台，为研究零磁场下的对密度波超导态提供了新途径

Abstract: The recent experimental observations of high temperature superconductivity in bilayer nickelate have attracted lots of attentions. Previous studies have assumed a mirror symmetry $\mathcal M$ between the two layers and focused on uniform and clean superconducting states. Here, we show that breaking this mirror symmetry via an applied displacement field can stabilize a pair-density-wave (PDW) superconductor, which is similar to the Fulde--Ferrell--Larkin--Ovchinnikov (FFLO) state, but at zero magnetic field. Based on a mean-field analysis of a model of $d_{x^2-y^2}$ orbital with an effective inter-layer attraction, we demonstrate that the PDW phase is robust over a wide range of displacement field, interlayer hopping strengths, and electron fillings. Finally, we analyze disorder effects on interlayer superconductivity within the first Born approximation. Based on symmetry considerations, we show that pairing is weaken by disorders which break the mirror symmetry, even with unbroken time reversal symmetry. Our results establish bilayer nickelate as a tunable platform for realizing finite-momentum pairing and for exploring generalized disorder effects.

</details>


### [126] [Canted ferromagnetic order in a distorted triangular-lattice magnet Na$_2$SrCo(VO$_4$)$_2$](https://arxiv.org/abs/2512.15090)
*Tengfei Peng,Xiaobai Ma,Xinyang Liu,Feiran Shen,Lunhua He,Junsen Xiang,Wenyun Yang,Wentao Jin*

Main category: cond-mat.str-el

TL;DR: 该研究报道了三角晶格钴酸盐Na₂SrCo(VO₄)₂的结构和磁性性质，发现其在3.4K发生铁磁转变，具有倾斜的铁磁有序结构，并揭示了TO₄四面体在调控交换相互作用中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究三角晶格钴酸盐中量子磁性的丰富物理现象，特别是具有glaserite型结构的X₂YCo(TO₄)₂化合物，为探索量子磁性提供了理想平台。

Method: 采用室温X射线和中子粉末衍射确定晶体结构，通过磁化测量和比热测量研究磁性相变，利用2.3K中子衍射确定磁有序结构，并与姐妹化合物进行比较分析。

Result: Na₂SrCo(VO₄)₂在3.4K发生铁磁转变，比热显示λ型异常，磁熵恢复接近Rln2的90%，支持Co²⁺离子在低温下的有效自旋-1/2态。中子衍射确认了倾斜的铁磁有序结构，磁矩大小为~2.6μB，位于ac平面。

Conclusion: TO₄四面体在调控glaserite结构化合物的交换相互作用和磁性行为中起决定性作用，解释了不同化合物（如Na₂BaCo(VO₄)₂的共线铁磁结构和Na₂BaCo(PO₄)₂的Y型反铁磁基态）之间的磁性差异。

Abstract: Triangular-lattice cobaltates with glaserite-type $X_2Y$Co($T$O$_4)_2$ structure provide an ideal platform to investigate intriguing quantum magnetism. Here we report a comprehensive study of the structural and magnetic properties of a triangular-lattice cobalt vanadate $\rm Na_2SrCo(VO_4)_2$. Room-temperature x-ray and neutron powder diffraction confirm that $\rm Na_2SrCo(VO_4)_2$ crystallizes in the monoclinic $P2_1/c$ space group with slightly distorted triangular layers of $\rm Co^{2+}$ ions. Magnetization measurements reveal a ferromagnetic transition at $T\rm_C \approx 3.4~{\rm K}$, where a sharp $λ$-type anomaly is observed in the specific heat. The magnetic entropy recovered up to 55 K approaches 90$\%$ of $R{\rm ln}2$, supporting an effective spin-1/2 state of Co$^{2+}$ ions at low temperature. Neutron diffraction at 2.3 K (below $T_{\rm C}$) further confirms a long-range canted ferromagnetic order with the Co$^{2+}$ moments aligned in the $ac$ plane and the ordered moment size of $\sim$ 2.6 $μ\rm_{B}$. Comparing with its sister compounds with a trigonal symmetry, $\rm Na_2BaCo(VO_4)_2$ with a collinear ferromagnetic structure and the recently discovered spin supersolid candidate $\rm Na_2BaCo(PO_4)_2$ with a distinct Y-like antiferromagnetic ground state, this study indicates the decisive role of the $T{\rm O_4}$ tetrahedra in tuning exchange interactions and contrasting magnetic behaviors of these glaserite-structure compounds.

</details>


### [127] [Study of Correlated Disorders and interaction in the Hofstadter Butterfly](https://arxiv.org/abs/2512.15106)
*Pooja Saini,Saptarshi Mandal,Sanjay Gupta*

Main category: cond-mat.str-el

TL;DR: 研究准周期无序及其与Aubry-André势的连续插值对Hofstadter蝴蝶谱的影响，发现弱无序轻微模糊分形谱，强准周期势破坏蝴蝶结构并产生多个能隙，AA势导致最强的谱重构。


<details>
  <summary>Details</summary>
Motivation: 研究不同准周期无序类型及其与Aubry-André势的插值如何影响二维方晶格中Hofstadter蝴蝶的量子特性，探索无序与磁场相互作用下的谱结构、纠缠熵和局域化行为。

Method: 采用零温度下的平均场近似方法，研究二维方晶格系统。分析多种准周期无序及其与AA势的连续插值对Hofstadter蝴蝶的影响，使用纠缠熵、IPR（逆参与率）和NPR（归一化参与率）进行局域化分析。

Result: 弱无序轻微模糊分形谱，强准周期势破坏蝴蝶结构并产生多个能隙。AA势产生最强的谱重构，在半填充附近产生显著能隙。插值过程显示从AA主导的能隙机制到竞争无序产生的鲁棒半填充能隙的转变。纠缠熵在低高磁场下遵循面积律，但在中间磁场出现明显偏差。局域化分析显示无序增强局域化，AA势产生最大的IPR。

Conclusion: 准周期无序类型及其与AA势的插值对Hofstadter蝴蝶的谱结构、纠缠熵和局域化特性有显著影响，揭示了不同无序机制之间的竞争和交叉行为，为理解无序磁场系统中的量子相提供了新见解。

Abstract: We investigate the impact of several quasiperiodic disorders and their continuous interpolation with the Aubry-Andre (AA) potential on the Hofstadter butterfly using mean field approximation at zero temperature for a two-dimensional square lattice. Weak disorder mildly smears the fractal spectrum, while strong quasiperiodic potentials destroy the butterfly and generate multiple energy gaps. The AA potential produces the strongest spectral restructuring, creating prominent gaps near half-filling. Interpolating AA with other quasiperiodic potentials reveals competing gap-opening mechanisms, ranging from AA-dominated gaps at small interpolation parameters to a robust half-filling gap generated by the competing disorders at large parameters. Entanglement entropy follows the area law at low and high magnetic fields but shows pronounced deviations at intermediate fields, with opposite trends for strong AA versus other quasiperiodic potentials. Localization analysis using IPR and NPR confirms enhanced localization with increasing disorder; the AA potential yields the largest IPR, with notable field dependence. Interpolation produces smooth crossovers between distinct localization regimes.

</details>


### [128] [Sub-10 nm helices stabilized by single-ion anisotropy in the chiral Mott insulator Co$_5$TeO$_8$](https://arxiv.org/abs/2512.15147)
*Priya R. Baral,Ravi Yadav,Victor Ukleev,Thomas LaGrange,Ivica Živković,Wen Hua Bi,Marek Bartkowiak,Robert Cubitt,Nina-Juliane Steinke,Vladimir Pomjakushin,Yurii Skourski,Henrik M. Rønnow,Oleg V. Yazyev,Arnaud Magrez,Jonathan S. White*

Main category: cond-mat.str-el

TL;DR: 该研究通过理论计算和实验验证，在Co5TeO8中发现了一种窄带隙莫特绝缘体，具有可电压调控的亚10纳米磁结构，为低功耗自旋电子学提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 窄带隙莫特绝缘体在低功耗自旋电子学中具有电压调控磁结构的潜力，但这类材料的预测和发现仍然具有挑战性。

Method: 采用密度泛函理论指导的方法预测材料特性，结合中子散射、磁测量等实验手段验证，并通过从头算波函数计算分析各向异性机制。

Result: 在Co5TeO8中预测并验证了127 meV的窄电荷转移带隙，发现了螺距为5.7-10 nm的螺旋磁结构，建立了包含八个不同相的复杂相图，证实了各向异性-阻挫相互作用的主导地位。

Conclusion: Co5TeO8为电压可调的亚10纳米磁结构提供了理想平台，展示了在关联氧化物中通过理论指导发现功能磁性材料的有效策略。

Abstract: Narrow-gap Mott insulators promise exceptional opportunities for voltage-controlled magnetic textures in low-dissipation spintronics, although their prediction remains challenging. Here we employ a density functional theory-guided approach to predict a narrow charge-transfer gap (127 meV) in the chiral cubic frustrated oxide Co$_5$TeO$_8$. Comprehensive neutron scattering and magnetometry reveal proper-screw Bloch-type helices with field- and temperature-tunable pitch of 5.7-10 nm embedded in a complex phase diagram with eight distinct phases. Ab initio wavefunction calculations demonstrate site-dependent single-ion anisotropy exceeding Dzyaloshinskii-Moriya (DM) interactions by an order of magnitude, establishing the anisotropy-frustration interplay as the stabilization mechanism, contrasting starkly with DM-dominated cubic helimagnets. Sharp capacitance anomalies at phase boundaries confirm intrinsic magnetoelectric coupling throughout the phase diagram. Co$_5$TeO$_8$ thus provides a platform for voltage-tunable sub-10 nm magnetic textures, demonstrating effective theory-guided discovery of functional magnetic materials in correlated oxides.

</details>


### [129] [Quantum Entanglement of Anyonic Charges and Emergent Spacetime Geometry](https://arxiv.org/abs/2512.15256)
*Hoang-Anh Le,Hyun Cheol Lee,S. -R. Eric Yang*

Main category: cond-mat.str-el

TL;DR: 该论文研究了拓扑有序相中任意子之间的纠缠如何产生类似反德西特（AdS）空间的涌现几何结构，并以石墨烯纳米带中的分数化任意子为例进行了分析。


<details>
  <summary>Details</summary>
Motivation: 研究拓扑有序相中任意子之间的纠缠结构，探索量子纠缠如何产生涌现几何，特别是在没有共形对称性的情况下，为分数化自由度提供全息描述。

Method: 使用互信息分析分数化任意子的纠缠结构，将石墨烯纳米带中的e/2带电半子对作为具体实例，研究其尺度依赖的纠缠特性，并将系统嵌入AdS类体几何中。

Result: 发现位于相反之字形边缘的分数化电荷尽管空间分离，仍表现出长程量子纠缠。纠缠结构定义了体几何中的最小曲面，为边缘关联提供了几何视角，展示了量子纠缠如何在没有共形对称性的情况下产生涌现几何。

Conclusion: 拓扑有序相中任意子之间的纠缠可以产生类似AdS空间的涌现几何结构，为准一维系统中的分数化自由度提供了全息图像，表明量子纠缠本身就能生成几何结构，无需依赖共形对称性。

Abstract: Intrinsically topologically ordered phases can host anyons. Here, we take the view that entanglement between anyons can give rise to an emergent geometry resembling Anti-de Sitter (AdS) space. We analyze the entanglement structure of fractionalized anyons using mutual information and interpret the results within this emergent geometric framework. As a concrete example, we consider pairs of $e/2$-charged semions that arise from instanton configurations in a disordered zigzag graphene nanoribbon. These fractional charges, located on opposite zigzag edges, show long-range quantum entanglement despite being spatially separated. We analyze the scale dependence of their entanglement and embed the ribbon into an AdS-like bulk geometry. In this setup, the entanglement structure defines minimal surfaces in the bulk, providing a geometric view of the edge correlations. This gives a holographic picture of fractionalized degrees of freedom in quasi-one-dimensional systems and shows how quantum entanglement can generate emergent geometry even without conformal symmetry.

</details>


### [130] [Functional renormalization group for extremely correlated electrons](https://arxiv.org/abs/2512.15437)
*Jonas Arnold,Peter Kopietz,Andreas Rückriegel*

Main category: cond-mat.str-el

TL;DR: 在强关联极限下，研究无限大U Hubbard模型中的极端关联电子系统，发现电子谱显著重整化，费米液体行为仅适用于低密度区域


<details>
  <summary>Details</summary>
Motivation: 研究强关联极限下（U→∞）的Hubbard模型，探索极端关联电子系统的低能物理性质，特别是仅由希尔伯特空间投影引起的运动学相互作用

Method: 采用强耦合泛函重整化群技术，在严格U=∞极限下研究方晶格上最近邻跳跃的模型，使用作用在无双重占据投影希尔伯特空间上的非正则算符

Result: 电子谱显著重整化：带宽和准粒子残差随电子密度增加而强烈减小；阻尼和粒子-空穴不对称性增加；在空穴区形成极化子连续谱。费米液体现象学仅适用于低密度顺磁区域；高密度区域出现坏金属态和强磁关联，基态为高密度下的Nagaoka铁磁态和中等密度下的条纹反铁磁态；顺磁和铁磁区域均违反Luttinger定理

Conclusion: 极端关联电子系统在强耦合极限下表现出丰富的物理行为，包括从低密度费米液体到高密度坏金属态的转变，以及违反Luttinger定理的现象，揭示了投影希尔伯特空间运动学相互作用的重要影响

Abstract: At strong on-site repulsion $ U $, the fermionic Hubbard model realizes an extremely correlated electron system. In this regime, it is natural to derive the low-energy physics with the help of non-canonical operators acting on a projected Hilbert space without double occupancies. Using a strong-coupling functional renormalization group technique, we study the physics of such extreme correlations in the strict $ U = \infty $ limit, where only kinematic interactions due to the Hilbert space projection remain. For nearest-neighbor hopping on a square lattice, we find that the electronic spectrum is significantly renormalized, with bandwidth and quasi-particle residue strongly decreasing with increasing electron density. On the other hand, damping and particle-hole asymmetry increase, while a polaronic continuum forms in the hole sector, below the single-particle band. Fermi liquid phenomenology applies only at low densities, where the system remains paramagnetic. At higher densities, we find a bad metal with strong magnetic correlations, indicating that the ground state is the Nagaoka ferromagnet at high densities and a stripe antiferromagnet at intermediate densities. Both in the paramagnetic and the ferromagnetic regimes, we observe a violation of Luttinger's theorem.

</details>


### [131] [Anomalous Dynamical Scaling at Topological Quantum Criticality](https://arxiv.org/abs/2512.15537)
*Menghua Deng,Chen Sun,Fuxiang Li,Xue-Jia Yu*

Main category: cond-mat.str-el

TL;DR: 研究拓扑非平庸量子临界点（QCPs）的非平衡驱动动力学，发现拓扑边缘模在临界点处导致反常的普适动力学标度行为


<details>
  <summary>Details</summary>
Motivation: 探索拓扑量子临界点的非平衡驱动动力学，特别是拓扑边缘模如何影响动力学行为，挑战传统的Kibble-Zurek标度机制

Method: 分析拓扑不同Ising量子临界点的体相和边界序参量的驱动动力学，并在自由费米子模型中研究拓扑不同QCPs的缺陷产生动力学

Result: 体相动力学遵循标准Kibble-Zurek标度，而边界动力学表现出反常的普适标度行为，这种反常行为是拓扑临界性特有的，超越了传统KZ机制

Conclusion: 拓扑与驱动动力学之间的相互作用导致了反常的动力学标度行为，挑战了量子临界动力学的标准范式

Abstract: We study the nonequilibrium driven dynamics at topologically nontrivial quantum critical points (QCPs),and find that topological edge modes at criticality give rise to anomalous universal dynamical scaling behavior. By analyzing the driven dynamics of bulk and boundary order parameters at topologically distinct Ising QCPs, we demonstrate that, while the bulk dynamics remain indistinguishable and follow standard Kibble Zurek (KZ) scaling, the anomalous boundary dynamics is unique to topological criticality, and its explanation goes beyond the traditional KZ mechanism. To elucidate the unified origin of this anomaly, we further study the dynamics of defect production at topologically distinct QCPs in free-fermion models and demonstrate similar anomalous universal scaling exclusive to topological criticality. These findings establish the existence of anomalous dynamical scaling arising from the interplay between topology and driven dynamics, challenging standard paradigms of quantum critical dynamics.

</details>


### [132] [Symmetry classification of magnetic octupole current based on multipole representation theory](https://arxiv.org/abs/2512.15619)
*Yuuga Takasu,Satoru Hayami*

Main category: cond-mat.str-el

TL;DR: 该论文研究了磁八极矩电流在d波交变磁体中的作用，通过多极子表示法分析了磁八极矩电导张量的对称性，并与自旋电流进行了对比。


<details>
  <summary>Details</summary>
Motivation: 磁八极矩电流最近作为d波交变磁体中尼尔矢量动力学的驱动力受到关注，但需要从对称性角度澄清磁八极矩电流与自旋电流的区别。

Method: 采用多极子表示法推导了五阶磁八极矩电导张量，对所有晶体点群进行了对称性分类，并通过微观紧束缚模型的线性响应计算验证了对称性降低对磁八极矩电导的激活作用。

Result: 时间反演偶的电型多极子产生无耗散磁八极矩电流，时间反演奇的磁型多极子产生耗散磁八极矩电流；对称性降低（如从Oh到Th）激活了磁八极矩电导。

Conclusion: 研究阐明了磁八极矩电流与自旋电流的对称性区别，为实验识别提供了理论基础。

Abstract: Magnetic octupole (MO) currents have recently attracted significant attention as a driving force for the Neel vector dynamics in d-wave altermagnets, a new class of antiferromagnets that exhibit nonrelativistic spin-split band structures. From a symmetry perspective, the MO includes an axial-dipole component analogous to that of the spin, making it essential to clarify how MO currents differ from spin currents. We here investigate the correspondence between MO conductivities and electronic multipoles, which provide a unified and powerful framework for symmetry analysis. We derive the multipole representation of the rank-five MO conductivity tensor and classify its symmetry-allowed components for all crystallographic point groups, in direct comparison with spin conductivity. We show that time-reversal-even electric-type multipoles give rise to the dissipationless MO current, whereas time-reversal-odd magnetic-type multipoles generate dissipative MO current under an applied electric field. Complementing this macroscopic analysis, the linear-response calculations for a microscopic tight-binding model demonstrate how MO conductivities are activated by symmetry lowering, exemplified by the symmetry reduction from Oh to Th. Our results elucidate the symmetry distinctions between MO currents and spin currents, and provide insights into their experimental identification.

</details>


### [133] [Large Isolated Stripes on Short 18-leg $t$-$J$ Cylinders](https://arxiv.org/abs/2512.15714)
*Tizian Blatz,Sebastian Paeckel,Ulrich Schollwöck,Fabian Grusdt,Annabelle Bohrdt*

Main category: cond-mat.str-el

TL;DR: 该研究通过密度矩阵重整化群算法研究高温超导体中的自旋-电荷条纹相，使用18腿圆柱几何结构分析条纹填充分数，揭示了高填充和低填充两种不同机制。


<details>
  <summary>Details</summary>
Motivation: 自旋-电荷条纹相是高温超导体中除超导性外最重要的低温有序相之一，但由于有限尺寸效应，数值研究这一相具有挑战性。研究旨在通过分析孤立长条纹的形成，提供与典型有限掺杂相图互补的视角。

Method: 使用密度矩阵重整化群算法提取18腿圆柱条带几何结构的基态，使直径显著大于先前工作。通过这种方法绘制电子掺杂和空穴掺杂侧可能的条纹填充分数范围。

Result: 研究发现与已有结果良好吻合，表明文献中观察到的填充分数分布受单个条纹物理支配。微观分析揭示了两种不同机制：高填充机制可由简化的压缩空间模型描述，低填充机制则以单个掺杂对的结构为特征。

Conclusion: 研究将条纹相的唯象学追溯到其微观组成，并强调了在量子模拟实验中观察这两种机制面临的不同挑战。这为理解高温超导体中的条纹相提供了新的微观视角。

Abstract: Spin-charge stripes belong to the most prominent low-temperature orders besides superconductivity in high-temperature superconductors. This phase is particularly challenging to study numerically due to finite-size effects. By investigating the formation of long, isolated stripes, we offer a perspective complementary to typical finite-doping phase diagrams. We use the density-matrix renormalization group algorithm to extract the ground states of an 18-leg cylindrical strip geometry, making the diameter significantly wider than in previous works. This approach allows us to map out the range of possible stripe filling fractions on the electron versus hole-doped side. We find good agreement with established results, suggesting that the spread of filling fractions observed in the literature is governed by the physics of a single stripe. Taking a microscopic look at stripe formation, we reveal two separate regimes - a high-filling regime captured by a simplified squeezed-space model and a low-filling regime characterized by the structure of individual pairs of dopants. Thereby, we trace back the phenomenology of the striped phase to its microscopic constituents and highlight the different challenges for observing the two regimes in quantum simulation experiments.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [134] [Large-$n$ $O(n)$ with long-range interactions: integrability and resonance dynamics](https://arxiv.org/abs/2512.14868)
*Guido Giachetti,Nicolo Defenu*

Main category: cond-mat.stat-mech

TL;DR: 研究长程量子O(n)模型在大n极限下的动力学，重点关注强长程区域α<d，发现介观时间尺度t∼ln N上存在由参数共振激活引起的非平凡动力学特征。


<details>
  <summary>Details</summary>
Motivation: 研究长程量子O(n)模型在强长程区域α<d下的动力学行为，特别是探索在介观时间尺度上由量子模式近简并性导致的参数共振现象及其对系统动力学的影响。

Method: 利用大n极限可积性的最新结果，推导共振条件，构建捕获有限尺寸动力学的简化多模哈密顿量，建立共振相图分析框架。

Result: 揭示了参数共振条件，阐明了何时以及如何偏离平均场行为，发现多共振模式的存在增强了纠缠的对数增长并导致空间调制关联。

Conclusion: 通过大n极限可积性分析，建立了长程量子O(n)模型在强长程区域介观时间尺度动力学的理论框架，揭示了参数共振对纠缠增长和空间关联的重要影响。

Abstract: We study the the large-$n$ dynamics of the long-range quantum $O(n)$ model, focusing on the strong long-range regime $α<d$. The dynamics of the model exhibits non-trivial features on mesoscopic timescales $t\sim\ln N$, due to the activation of parametric resonances of the nearly degenerate quantum modes. By using recent results establishing the integrability of the large-$n$ limit, we derive the resonance conditions, and construct the reduced multi-mode Hamiltonian that captures the finite-size dynamics. This framework yields the resonance phase diagram and clarifies when and how deviations from mean-field behavior arise. In particular, the presence of multiple resonant modes enhances the logarithmic growth of entanglement and leads to spatially modulated correlations.

</details>


### [135] [Thermodynamics of the $q$-deformed Kittel--Shore model](https://arxiv.org/abs/2512.15216)
*V. Mariscal,J. J. Relancio*

Main category: cond-mat.stat-mech

TL;DR: 研究q变形Kittel-Shore哈密顿量的热力学性质，分析变形参数q对自旋1/2系统比热、磁化率、磁化和相变的影响


<details>
  <summary>Details</summary>
Motivation: 量子群和su_q(2)代数可用于变形具有长程相互作用的Kittel-Shore哈密顿量，需要研究这种变形对系统热力学性质的影响，并探索其在描述非相同耦合的少自旋量子系统中的应用潜力

Method: 使用量子群特别是su_q(2)代数对Kittel-Shore哈密顿量进行变形，研究自旋1/2粒子的变形模型，分析比热、磁化率、磁化和相变随变形参数q的变化

Result: 变形使热力学行为向更高温度偏移，并改变了相变特性；与未变形模型相比，q变形显著影响系统的热力学响应

Conclusion: q变形模型为描述具有非相同耦合的少自旋量子系统提供了潜在应用，变形参数q可调控系统的热力学性质和相变行为

Abstract: The Kittel--Shore Hamiltonian characterizes $N$ spins with identical long-range interactions, and the $\mathfrak{su}(2)$ coalgebra has been proven to be a symmetry of this model, which can be exactly solved. By using quantum groups and, in particular, $\mathfrak{su}_{q}(2)$, this Hamiltonian was deformed. In this work, we study the thermodynamic properties of this deformed model for spin-$1/2$ particles. In particular, we discuss how this deformation affects the specific heat, magnetic susceptibility, magnetisation, and phase transitions as a function of the parameter $q$ of the deformation and compare them with those of the undeformed model. Deformation was found to shift the thermodynamic behaviours to higher temperatures and alter the phase transitions. The potential applications of this $q$-deformed model for describing few-spin quantum systems with non-identical couplings are discussed.

</details>


### [136] [Exponents and front fluctuations in the quenched Kardar-Parisi-Zhang universality class of one and two dimensional interfaces](https://arxiv.org/abs/2512.15366)
*Ángela Tajuelo-Valbuena,Jara Trujillo-Mulero,Juan J. Meléndez,Rodolfo Cuerno,Juan J. Ruiz-Lorenzo*

Main category: cond-mat.stat-mech

TL;DR: 该研究通过模拟淬火KPZ方程的元胞自动机版本，在一维和二维中研究了界面在钉扎-脱钉转变中的标度特性，计算了多个临界指数，发现其与定向渗流脱钉普适类兼容，并分析了生长区前沿涨落的概率密度函数。


<details>
  <summary>Details</summary>
Motivation: 研究淬火KPZ方程在钉扎-脱钉转变中的标度特性，特别是界面动力学粗糙化和脱钉行为的临界指数，以及前沿涨落的统计特性。

Method: 模拟淬火KPZ方程的元胞自动机版本，在一维和二维系统中直接计算α、β、θ、δ等临界指数，通过研究实空间高度差关联函数计算动态关联长度及其临界指数z，并数值计算生长区前沿涨落的概率密度函数。

Result: 获得了一维和二维界面的完整标度指数集，与定向渗流脱钉普适类基本兼容；前沿涨落的PDF显示出强烈的非高斯偏度和峰度，但在物理基底维度下与时间相关噪声的KPZ方程的PDF在中心部分和尾部均存在差异。

Conclusion: 淬火KPZ方程在钉扎-脱钉转变中的标度特性与定向渗流脱钉普适类一致，但其前沿涨落的概率分布与时间相关噪声的KPZ方程存在显著差异，表明淬火噪声对界面统计特性有重要影响。

Abstract: We have simulated an automaton version of the quenched Kardar-Parisi-Zhang (qKPZ) equation in one and two dimensions in order to study the scaling properties of the interface at the depinning transition. Specifically, the $α$, $β$, $θ$, and $δ$ critical exponents characterizing the surface kinetic roughening and depinning behaviors have been directly computed from the simulations. In addition, by studying the height-difference correlation function in real space, we have also been able to directly compute the dynamic correlation length and its associated dynamic critical exponent $z$. The full sets of scaling exponents are largely compatible with those of the Directed Percolation Depinning universality class for one and two dimensional interfaces. Furthermore, we have computed numerically the probability density function (PDF) of the front fluctuations in the growth regime, finding its asymptotic form in one and two dimensions. While the PDF features strongly non-Gaussian skewness and kurtosis values, it also differs from the PDF of the KPZ equation with time-dependent noise for physical substrate dimensions, both in the central part and at the tails of the distribution.

</details>


### [137] [Dynamical Scarring from Scrambling in Two Dimensional Topological Materials](https://arxiv.org/abs/2512.15417)
*Dominik Szpara,Szczepan Głodzik,Nicholas Sedlmayr*

Main category: cond-mat.stat-mech

TL;DR: 该研究探讨了二维拓扑模型中量子信息扰动的传播特性，发现拓扑边缘模式会导致信息在边界上传播而不被扰乱，形成动态疤痕现象。


<details>
  <summary>Details</summary>
Motivation: 研究二维拓扑模型中量子信息扰动的传播特性，特别是拓扑边缘模式如何影响信息在系统中的传播和扰乱过程。

Method: 使用超时有序关联子作为量子混沌和信息扰乱的探针，通过解析计算和数值模拟研究二维拓扑模型中的信息传播特性。

Result: 发现蝴蝶速度在体材料中具有方向依赖性，而手性或螺旋边缘模式会导致动态疤痕现象，信息沿边界传播而不被扰乱，疤痕不相互干扰。

Conclusion: 二维拓扑系统中的边缘模式能够保护信息不被扰乱，形成沿边界传播的动态疤痕，这为拓扑系统中的信息传播提供了新的理解。

Abstract: Out-of-time ordered correlators are a probe of how the information of an initial perturbation is effectively scrambled under unitary time evolution, widely used to study quantum chaos. They have also been used to demonstrate that information is trapped in the zero dimensional edge modes of topological insulators and superconductors, and does not become scrambled. Here we study scrambling in two dimensional topological models. In the bulk the butterfly velocity, the speed at which the out-of-time ordered correlator spreads, gains a directional dependence from the underlying lattice. Furthermore when there are chiral or helical edge modes present these cause a form of dynamical scarring. The information about an initial perturbation on the boundary of the system travels around the edge, carried by the edge modes, but is not scrambled over very long time scales. The direction and speed of the scars are given by the velocities of the linearly dispersing edge modes. We further show that these scars do not interact, passing through each other. We back up these results with analytical and numerical calculations on exemplary models.

</details>


### [138] [Correlations between rare events due to long-term memory](https://arxiv.org/abs/2512.15479)
*Apurba Biswas,Thomas Guérin*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究了具有长期记忆的非马尔可夫高斯过程中罕见事件的动力学，发现长期记忆导致首次和二次通过时间的非指数分布，并量化了极端事件之间的相关性。


<details>
  <summary>Details</summary>
Motivation: 传统基于阿伦尼乌斯定律的罕见事件预测方法假设指数分布的等待时间且事件间无相关性，但在存在长期记忆的系统（如地球物理时间序列或蛋白质动力学）中，这种描述失效。现有分析方法未能量化长期记忆导致的罕见事件相关性。

Method: 针对非马尔可夫高斯过程，通过解析方法研究了长期记忆对罕见阈值首次和二次通过时间分布的影响。推导了首次和二次通过时间的协方差表达式，并预测了下一个极端事件的平均时间如何依赖于前一个通过时间。

Result: 获得了非指数分布的时间分布，超越了阿伦尼乌斯范式。得到了首次和二次通过时间协方差的显式表达式，揭示了极端事件聚类现象。通过大量随机模拟验证了这些解析结果。

Conclusion: 长期记忆导致极端事件之间存在强相关性，表现为非指数分布的时间间隔和事件聚类现象。这些解析结果为理解具有长期记忆系统中罕见事件的动力学提供了新的理论框架。

Abstract: Rare events refer to qualitatively unlikely events whose realization can nevertheless have important consequences. Typically, the prediction of the kinetics of these events relies on Arrhenius laws, with exponentially distributed waiting times, and no correlations between successive occurrences. However, this description breaks down in the presence of long-term memory, as has been observed in the contexts of geophysical time series or protein dynamics. So far, existing analytical approaches do not quantify the correlations between rare events due to long-term memory. Here, for non-Markovian Gaussian processes, we determine analytically the impact of long-term memory on the distribution of first and second passage times to a rarely reached threshold. This distribution is non-exponential, thus going beyond the Arrhenius paradigm. We obtain an explicit expression for the covariance between the first and second passage times, and we predict how the mean time to the next extreme event depends on the previous passage time, illustrating the phenomenon of clustering of extreme events. These analytical results, validated through extensive stochastic simulations, shed lights on the strong correlation between successive occurrences of extreme events due to long-term memory.

</details>


### [139] [Macroscopic fluctuation theory of interacting Brownian particles](https://arxiv.org/abs/2512.15569)
*Aurélien Grabsch,Davide Venturelli,Olivier Bénichou*

Main category: cond-mat.stat-mech

TL;DR: 应用宏观涨落理论研究具有任意成对相互作用的布朗粒子的大尺度动力学性质，获得密度与粒子流之间动力学关联的精确结果


<details>
  <summary>Details</summary>
Motivation: 研究具有任意成对相互作用的布朗粒子系统的大尺度动力学特性，特别是在平衡和非平衡状态下的精确动力学行为

Method: 结合宏观涨落理论（MFT）与平衡统计力学中集体扩散系数的标准结果，分析一维和高维系统的动力学关联

Result: 获得了密度与粒子流之间动力学关联的精确结果，对一维系统如Calogero气体、Riesz气体、Rouse链等模型进行了精确描述，并研究了单文件约束下的示踪扩散

Conclusion: 宏观涨落理论为研究具有任意成对相互作用的布朗粒子系统的大尺度动力学特性提供了有效框架，能够获得平衡和非平衡状态下的精确动力学结果

Abstract: We apply the macroscopic fluctuation theory (MFT) to study the large-scale dynamical properties of Brownian particles with arbitrary pairwise interaction. By combining it with standard results of equilibrium statistical mechanics for the collective diffusion coefficient, the MFT gives access to the exact large-scale dynamical properties of the system, both in- and out-of-equilibrium. In particular, we obtain exact results for dynamical correlations between the density and the current of particles. For one-dimensional systems, this allows us to obtain a precise description of these correlations for emblematic models, such as the Calogero and Riesz gases, and for systems with nearest-neighbor interactions such as the Rouse chain of hardcore particles or the recently introduced model of tethered particles. Tracer diffusion with the single-file constraint (but for arbitrary pairwise interaction) is also studied. For higher-dimensional systems, we quantitatively characterize these dynamical correlations by relying on standard methods such as the virial expansion.

</details>


### [140] [Subsampling of avalanches in the fiber bundle models of fracture](https://arxiv.org/abs/2512.15582)
*Narendra Kumar Bodaballa,Soumyajyoti Biswas*

Main category: cond-mat.stat-mech

TL;DR: 研究纤维束断裂模型中雪崩事件的子采样问题，发现局部观测会扭曲雪崩统计，但在弹性失效区域附近这种扭曲最小化


<details>
  <summary>Details</summary>
Motivation: 研究当只能观测系统部分区域的微观失效事件时，记录的雪崩统计如何与实际断裂事件产生偏差，特别是在载荷重分布局部化的情况下

Method: 使用纤维束断裂模型，分析系统子采样对雪崩统计的影响，特别关注载荷重分布局部化的情况

Result: 局部观测会显著扭曲雪崩统计，但在接近弹性失效区域时，这种扭曲最小化，表明在弹性固体断裂情况下，即使观测能力大幅降低仍能代表实际失效动力学

Conclusion: 在弹性失效区域附近，观测到的雪崩统计与实际断裂事件偏差最小，这为在有限观测条件下研究弹性固体断裂动力学提供了理论基础

Abstract: We study the subsampling of the avalanches in the fiber bundle model of fracture. In cases where only a part of the system is observed for the micro-failure events, the recorded avalanche statistics gets distorted compared to the actual fracture events. We show that, particularly in the cases where the load redistribution is localized, this distortion is significant. Surprisingly, however, near an elastic failure regime, the distortion is minimized, suggesting a much reduced observational capacity could still represent the actual failure dynamics in the case of fracture of elastic solids.

</details>
