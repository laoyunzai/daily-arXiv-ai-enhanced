<div id=toc></div>

# Table of Contents

- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 8]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 9]
- [cs.AI](#cs.AI) [Total: 26]
- [quant-ph](#quant-ph) [Total: 42]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 48]


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [1] [Monte Carlo study of phase transitions in model orthonickelate](https://arxiv.org/abs/2512.13761)
*V. S. Ryumshin*

Main category: cond-mat.stat-mech

TL;DR: 使用经典蒙特卡洛方法结合玻色子浓度运动学计算，研究了正交镍酸盐赝自旋模型的相变类型


<details>
  <summary>Details</summary>
Motivation: 研究正交镍酸盐材料的相变行为，特别是通过数值模拟方法分析其相变类型

Method: 采用经典蒙特卡洛方法，结合玻色子浓度的运动学计算，对正交镍酸盐的赝自旋模型进行数值模拟

Result: 获得了正交镍酸盐模型的相变类型分析结果

Conclusion: 通过数值模拟方法成功研究了正交镍酸盐模型的相变特性

Abstract: The results of numerical simulation using a classical Monte Carlo method with a kinematic accounting of the bosons concentration for a pseudospin model of orthonickelates are presented. Type of the phase transitions of the model orthonickelates is investigated.

</details>


### [2] [Conservation laws and chaos propagation in a non-reciprocal classical magnet](https://arxiv.org/abs/2512.13873)
*Nisarg Bhatt,Purnendu Das,Subroto Mukerjee,Sriram Ramaswamy*

Main category: cond-mat.stat-mech

TL;DR: 研究非互易海森堡自旋链中混沌的传播特性，发现相互作用在变换变量下是互易的，具有守恒量，严格反对称耦合下守恒量扩散，混沌对称传播


<details>
  <summary>Details</summary>
Motivation: 研究非互易海森堡自旋链中混沌的传播特性，探索非对称交换耦合对系统动力学行为的影响

Method: 研究非互易海森堡自旋链模型，分析交换耦合的非对称性，通过变换变量将相互作用转化为互易形式，识别守恒量（磁化和能量），建立泊松括号代数和哈密顿动力学

Result: 在变换变量下相互作用是互易的，存在守恒量；严格反对称耦合下守恒量扩散，混沌对称传播，出现简单流体动力学理论；一般情况（同时包含对称和反对称部分）在大尺度极限下呈现复杂性；混沌的弹道传播在包含最近邻以外相互作用时仍然存在，但守恒定律一般不再成立

Conclusion: 非互易海森堡自旋链在变换变量下具有互易相互作用和守恒量，严格反对称耦合导致守恒量扩散和混沌对称传播，一般情况更为复杂，但混沌的弹道传播特性具有鲁棒性

Abstract: We study a nonreciprocal generalization [EPL 60, 418 (2002)] of the classical Heisenberg spin chain, in which the exchange coupling is nonsymmetric, and show that it displays a ballistic spreading of chaos as measured by the decorrelator. We show that the interactions are reciprocal in terms of transformed variables, with conserved quantities that can be identified as magnetization and energy, with a Poisson-bracket algebra and Hamiltonian dynamics. For strictly antisymmetric couplings in the original model the conserved quantities diffuse, the decorrelator spreads symmetrically, and a simple hydrodynamic theory emerges. The general case in which the interaction has symmetric and antisymmetric parts presents complexities in the limit of large scales. Ballistic propagation of chaos survives the inclusion of interactions beyond nearest neighbours, but the conservation laws in general do not.

</details>


### [3] [Renormalization group for spectral collapse in random matrices with power-law variance profiles](https://arxiv.org/abs/2512.13883)
*Philipp Fleig*

Main category: cond-mat.stat-mech

TL;DR: 提出一种重整化群方法，用于比较和坍缩不同系统尺寸下复杂系统随机矩阵模型的特征值密度分布。


<details>
  <summary>Details</summary>
Motivation: 为了能够比较不同系统尺寸下复杂系统的随机矩阵模型特征值密度，需要找到一种方法将原始光谱转化为可比较的坍缩密度曲线。

Method: 通过让模型归一化随尺寸变化来固定自然光谱尺度，在具有幂律方差分布的Wigner和Wishart矩阵推广模型上演示该方法。使用随机矩阵理论推导解析子的自洽不动点方程，基于矩阵抽取定义RG方案，计算控制RG流的Beta函数。

Result: 运行归一化导致光谱坍缩，这在模拟和不动点方程的解中得到了确认。该方法有望推广到其他系综。

Conclusion: 该重整化群方法为广泛复杂系统的数据分析提供了一种新方法，能够处理不同系统尺寸下的特征值密度比较问题。

Abstract: We propose a renormalization group (RG) approach to compare and collapse eigenvalue densities of random matrix models of complex systems across different system sizes. The approach is to fix a natural spectral scale by letting the model normalization run with size, turning raw spectra into comparable, collapsed density curves. We demonstrate this approach on generalizations of two classic random matrix ensembles--Wigner and Wishart--modified to have power-law variance profiles. We use random matrix theory methods to derive self-consistent fixed-point equations for the resolvent to compute their eigenvalue densities, we define an RG scheme based on matrix decimation, and compute the Beta function controlling the RG flow as a function of the variance profile power-law exponent. The running normalization leads to spectral collapse which we confirm in simulations and solutions of the fixed-point equations. We expect this RG approach to carry over to other ensembles, providing a method for data analysis of a broad range of complex systems.

</details>


### [4] [Hysteresis, Laning, and Negative Drag in Binary Systems with Opposite and Perpendicular Driving](https://arxiv.org/abs/2512.13925)
*C. Reichhardt,C. J. O. Reichhardt*

Main category: cond-mat.stat-mech

TL;DR: 研究具有排斥相互作用的二元粒子系统在不同方向驱动下的相变行为，包括车道相分离、滞后现象、负拖曳效应和锁定态等复杂动力学现象。


<details>
  <summary>Details</summary>
Motivation: 研究在外部驱动下，具有排斥相互作用的二元粒子系统在不同驱动方向（相反或垂直）下的集体动力学行为，探索相分离、滞后效应、负拖曳等非平衡态现象。

Method: 通过模拟分析二元粒子系统在外部驱动下的动力学行为，考察相反驱动和垂直驱动两种不同配置，研究驱动强度变化对系统相态、拓扑缺陷和速度-力关系的影响。

Result: 发现：1）相反驱动下形成车道相分离态，速度-力曲线和拓扑缺陷分数存在强滞后现象；2）垂直驱动下出现堵塞态，可转变为无序态或倾斜车道态，同样显示强滞后效应；3）观察到负拖曳效应，即一种粒子沿另一物种相反方向运动；4）在恒定驱动下增加垂直驱动时，系统形成锁定和倾斜车道态，速度出现跳跃变化；5）弱相互作用下堵塞系统可形成共倾斜条纹态。

Conclusion: 二元排斥粒子系统在不同方向驱动下展现出丰富的非平衡相变行为，包括车道形成、滞后现象、负拖曳效应和锁定态等复杂动力学特征，这些现象对理解非平衡态集体动力学具有重要意义。

Abstract: We consider a binary system of particles with repulsive interactions that move in opposite or perpendicular directions to each other under an applied external drive. For opposite driving, at higher drives a phase-separated laned state forms that has strong hysteresis in the velocity-force curve and the fraction of topological defects as the drive is cycled up and down from zero. The amount of hysteresis depends on the drive value at which the drive changes from increasing to decreasing. For perpendicular driving, we find a jammed state that transitions into a disordered state or a tilted lane state, both of which also show strong hysteresis effects. Additionally, a negative drag effect can appear in which one species moves in the direction opposite to the other species due to a tilting of the lanes by the perpendicular drive. When a constant drive is applied along one direction while the drive in the perpendicular direction is increased, we observe a series of drops and jumps in the velocity as the system forms locked and tilted laned states. For weakly interacting particles, the jammed system can show co-tilted stripe-forming states.

</details>


### [5] [Decomposing Non-Markovian History Dependence](https://arxiv.org/abs/2512.13933)
*Matthew P. Leighton,Christopher W. Lynn*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种信息论框架来量化非马尔可夫随机过程中的历史依赖性，通过分解各阶依赖的信息量，并在果蝇行为数据中发现了跨时间尺度的不变性缩放规律。


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫随机过程在生物学中普遍存在，但缺乏量化历史依赖性的通用框架。现有方法如自相关分析可能无法准确捕捉历史依赖结构。

Method: 提出信息论方法分解非马尔可夫动态中的历史依赖性，量化各阶依赖编码的信息。在最小非马尔可夫模型和果蝇行为长时间记录数据中验证该方法。

Result: 该框架能正确捕捉基础历史依赖性（即使自相关分析失败）。果蝇行为数据显示非马尔可夫依赖性在从几分之一秒到分钟的时间尺度上具有不变缩放规律，但非马尔可夫信息总量呈非单调性，表明存在历史依赖性最强的独特时间尺度。

Conclusion: 提出的信息论框架为量化非马尔可夫系统中的历史依赖性提供了通用方法，揭示了生物系统中历史依赖性的跨尺度不变性特征和最优时间尺度。

Abstract: Non-Markovian stochastic processes are ubiquitous in biology. Nevertheless, we lack a general framework for quantifying historical dependencies. In this Letter, we propose an information-theoretic approach to decompose history dependence in systems with non-Markovian dynamics, quantifying the information encoded in dependencies of each order. In minimal models of non-Markovian dynamics, we show that this framework correctly captures the underlying historical dependencies, even when autocorrelations do not. In prolonged recordings of fly behavior, we find that the scaling of non-Markovian dependencies is invariant across timescales from fractions of a second to minutes. Despite this invariance, the overall amount of non-Markovian information is non-monotonic, suggesting a unique timescale on which historical dependencies are strongest.

</details>


### [6] [Tractable Model for Tunable Non-Markovian Dynamics](https://arxiv.org/abs/2512.13936)
*Matthew P. Leighton,Christopher W. Lynn*

Main category: cond-mat.stat-mech

TL;DR: 提出了一个非马尔可夫动力学的最小模型，其中当前状态可以复制具有任意历史依赖性的过去状态，该模型可作为研究非马尔可夫动力学的可分析处理的"沙盒"。


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫动力学在物理、生物和工程中普遍存在，但我们对非马尔可夫过程的理解远不如马尔可夫过程，主要原因是缺乏可处理的模型。

Method: 提出了一个最小模型，其中当前状态可以复制具有任意历史依赖性的过去状态。该模型的许多特性可以通过分析方法进行研究。

Result: 该模型提供了对历史依赖性、自相关和信息论度量（如熵和动态信息）之间关系的洞察。研究发现自相关可能无法（甚至在定性上）捕捉到底层的依赖关系。

Conclusion: 该模型作为一个可处理的沙盒，可用于探索非马尔可夫动力学，有助于弥补非马尔可夫过程研究中的模型缺乏问题。

Abstract: Non-Markovian dynamics are ubiquitous across physics, biology, and engineering. Yet our understanding of non-Markovian processes significantly lags that of simpler Markovian processes, due largely to a lack of tractable models. In this article, we present a minimal model of non-Markovian dynamics in which the current state copies past states with arbitrary history dependence. We show that many properties of this process can be studied analytically, providing insight into the relationships between history dependence, autocorrelations, and information-theoretic metrics like entropy and dynamical information. Strikingly, we find that autocorrelations can fail, even qualitatively, to capture the underlying dependencies. Ultimately, this model serves as a tractable sandbox for exploring non-Markovian dynamics.

</details>


### [7] [Age-structured hydrodynamics of ensembles of anomalously diffusing particles with renewal resetting](https://arxiv.org/abs/2512.14345)
*Baruch Meerson,Ohad Vilk*

Main category: cond-mat.stat-mech

TL;DR: 该研究开发了一种年龄结构流体动力学理论，用于描述大量异常扩散粒子在随机更新重置下的集体行为，并应用于三种不同的重置协议。


<details>
  <summary>Details</summary>
Motivation: 研究异常扩散粒子在重置机制下的集体行为，特别是考虑全局粒子间相关性的重置规则，现有理论对此类系统的描述有限。

Method: 开发年龄结构流体动力学理论，将粒子的年龄（自上次重置以来的时间）作为显式动力学变量，使用标度布朗运动建模异常扩散，并应用于三种重置协议：独立重置到原点、最远粒子重置到原点、以及标度扩散扩展的"布朗蜜蜂"模型。

Result: 所有模型在长时间后都达到非平衡稳态，并确定了稳态密度分布。模型A的稳态密度与单个粒子重置到原点的概率密度一致；模型B和标度布朗蜜蜂模型的稳态密度则显著不同，特别是对所有H>0都有紧支撑。

Conclusion: 年龄结构流体动力学形式可以扩展到其他具有全局粒子间相关性的异常扩散过程和更新重置协议。

Abstract: We develop an age-structured hydrodynamic (HD) theory which describes the collective behavior of $N\gg 1$ anomalously diffusing particles under stochastic renewal resetting. The theory treats the age of a particle -- the time since its last reset -- as an explicit dynamical variable and allows for resetting rules which introduce global inter-particle correlations. The anomalous diffusion is modeled by the scaled Brownian motion (sBm): a Gaussian process with independent increments, characterized by a power-law time dependence of the diffusion coefficient, $D(t)\sim t^{2H-1}$, where $H>0$. We apply this theory to three different resetting protocols: independent resetting to the origin (model~A), resetting to the origin of the particle farthest from it (model~B), and a scaled-diffusion extension of the ``Brownian bees" model of Berestycki et al, Ann. Probab. \textbf{50}, 2133 (2022). In all these models non-equilibrium steady states are reached at long times, and we determine the steady-state densities. For model A the (normalized to unity) steady-state density coincides with the steady-state probability density of a single particle undergoing sBM with resetting to the origin. For model B, and for the scaled Brownian bees, the HD steady-state densities are markedly different: in particular, they have compact supports for all $H>0$. The age-structured HD formalism can be extended to other anomalous diffusion processes with renewal resetting protocols which introduce global inter-particle correlations.

</details>


### [8] [50 years of Yukhnovskii's critical point theory: its place in the constant flow of theoretical physics](https://arxiv.org/abs/2512.14487)
*Yu. Kozitsky*

Main category: cond-mat.stat-mech

TL;DR: 本文回顾了Ihor Yukhnovskii在半个世纪前提出的研究三维伊辛模型临界点的方法，该方法通过集体变量空间中的逐层积分，为理解相变现象提供了比ε展开更深入的见解。


<details>
  <summary>Details</summary>
Motivation: 作者旨在从量子场论和统计物理学发展的更广阔视角重新审视Yukhnovskii的理论，揭示其在20世纪末期物理学发展中的历史地位和意义，弥补该理论在当时可能被忽视的深远影响。

Method: Yukhnovskii采用集体变量空间中的逐层积分方法研究三维伊辛模型的临界点，这是一种与K.G.Wilson获得诺贝尔奖的ε展开方法不同的替代方案。

Result: Yukhnovskii的方法得出了与ε展开相似的结果，但提供了对相变现象本质更深入的洞察，其理论自然地融入了20世纪末量子场论和统计物理学的湍流发展背景中。

Conclusion: Yukhnovskii的理论虽然在当时可能被忽视，但从历史发展的角度看，它代表了统计物理学和量子场论发展的重要里程碑，其方法为理解临界现象提供了有价值的替代视角。

Abstract: Half a century ago, Ihor Yukhnovskii elaborated a method of studying the critical point of the three-dimensional Ising model based on a layer-by-layer integration in the space of collective variables. His method was an alternative to that based on the $\varepsilon$-expansion for which K. G. Wilson was awarded the Nobel Prize in Physics in 1982. However, Yukhnovskii's technique, which yielded similar results, provided even deeper insight into the nature of this phenomenon. At that time, we, professor's students, saw only this aspect of his theory. Later, I realized that the mentioned Yukhnovskii's work naturally fits into a more general context of the turbulent development of quantum field theory and statistical physics in the last quarter of the twentieth century. The aim of the present article is to look at the main aspects and the impact of Yukhnovskii's theory from this perspective.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [9] [Unreasonable effectiveness of unsupervised learning in identifying Majorana topology](https://arxiv.org/abs/2512.13825)
*Jacob Taylor,Haining Pan,Sankar Das Sarma*

Main category: cond-mat.dis-nn

TL;DR: 使用自编码器结合无监督和监督学习，通过未标记数据识别Majorana纳米线中的拓扑相变


<details>
  <summary>Details</summary>
Motivation: 拓扑序在物理系统中（如拓扑超导）并不总是以明显方式显现，而无监督学习虽然能发现隐藏模式，但计算资源需求大且效果不稳定。需要一种更有效的方法来识别Majorana纳米线中的拓扑相变。

Method: 结合无监督和监督学习，使用自编码器处理未标记数据，分析短无序纳米线中的Majorana分裂，以区分拓扑相和普通相并确定其交叉点。

Result: 该方法不仅能区分Majorana纳米线中的"拓扑"和"普通"相，还能确定它们在相关参数空间中的交叉位置，为识别拓扑相提供有用工具。

Conclusion: 自编码器结合无监督和监督学习的方法为识别Majorana纳米线中的拓扑序提供了一种有效途径，特别是在处理未标记数据时能够发现拓扑相变的关键特征。

Abstract: In unsupervised learning, the training data for deep learning does not come with any labels, thus forcing the algorithm to discover hidden patterns in the data for discerning useful information. This, in principle, could be a powerful tool in identifying topological order since topology does not always manifest in obvious physical ways (e.g., topological superconductivity) for its decisive confirmation. The problem, however, is that unsupervised learning is a difficult challenge, necessitating huge computing resources, which may not always work. In the current work, we combine unsupervised and supervised learning using an autoencoder to establish that unlabeled data in the Majorana splitting in realistic short disordered nanowires may enable not only a distinction between `topological' and `trivial', but also where their crossover happens in the relevant parameter space. This may be a useful tool in identifying topology in Majorana nanowires.

</details>


### [10] [On the Boroxol Ring Fraction in Melt-Quenched B$_2$O$_3$ Glass](https://arxiv.org/abs/2512.14526)
*Debendra Meher,Nikhil V. S. Avula,Sundaram Balasubramanian*

Main category: cond-mat.dis-nn

TL;DR: 开发了B2O3玻璃的DFT精度机器学习势函数，使用10^9 K/s淬火速率获得了超过30%硼原子在硼氧环中的玻璃结构，发现硼氧环分数随淬火速率降低而增加，在75%硼氧环分数时能量最低


<details>
  <summary>Details</summary>
Motivation: 熔融淬火B2O3玻璃的原子结构模型一直难以通过模拟获得，主要困难在于硼氧环（一种中程有序结构）在原子分子动力学模拟中难以形成

Method: 开发了DFT精度的机器学习势函数，采用深度势分子动力学（DPMD）模拟，使用低至10^9 K/s的淬火速率，研究了几何描述符范围对压力的影响

Result: 获得了硼氧环分数超过30%的B2O3玻璃结构，发现硼氧环分数随淬火速率降低而增加，在75%硼氧环分数时观察到能量最小值，与实验估计值接近

Conclusion: 通过机器学习势函数和低淬火速率成功模拟了B2O3玻璃的原子结构，揭示了硼氧环分数与淬火速率的关系，并发现能量最小值对应的硼氧环分数与实验值一致

Abstract: An atomistic structural model for melt-quenched B$_2$O$_3$ glass has eluded the simulation community so far. The difficulty lies in the abundance of the six-membered boroxol rings - an intermediate-range order motif suggested through Raman and NMR spectroscopy - which is challenging to obtain in atomistic molecular dynamics simulations. Here, we report the development of a DFT-accurate machine-learned potential for B$_2$O$_3$ and employ quench rates as low as 10$^{9}$ K/s to obtain B$_2$O$_3$ glasses with more than 30% of boron atoms in boroxol rings. Also, we show that the pressure, and consequently the boroxol fraction, in the deep potential molecular dynamics (DPMD) simulations critically depends on the range of the geometry descriptor used in the embedding neural network, and at least a 9 $\unicode{x212B}$ range is required. The boroxol ring fraction increases with decreasing quench rate. Finally, amorphous B$_2$O$_3$ configurations display a minimum in energy at a boroxol fraction of 75%, intriguingly close to the experimental estimate in B$_2$O$_3$ glass.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [11] [False Vacuum Decay in Flat-Band Ferromagnets: Role of Quantum Geometry and Chiral Edge States](https://arxiv.org/abs/2512.13786)
*Fabian Pichler,Clemens Kuhlenkamp,Michael Knap*

Main category: cond-mat.str-el

TL;DR: 该论文提出了一种探测平带铁磁体中磁化动力学的协议，研究了虚假真空上磁泡的成核和动态生长，强调了非平凡量子几何在磁化动力学中的关键作用，并展示了如何动态访问量子霍尔铁磁体中畴壁边界处的手性边缘模式。


<details>
  <summary>Details</summary>
Motivation: 量子物质的动力学控制是探测强关联态的一个具有挑战性但前景广阔的方向。受最近在扭曲MoTe₂实验中展示的光学控制磁化现象的启发，研究者希望开发一种探测平带铁磁体中磁化动力学的协议。

Method: 提出了一种探测磁化动力学的协议，研究了在虚假真空上制备的磁泡在巡游铁磁体和自旋极化陈绝缘体中的成核和动态生长。特别强调了非平凡量子几何在磁化动力学中的关键作用，并展示了如何动态访问量子霍尔铁磁体中畴壁边界处的手性边缘模式。

Result: 研究表明，对于铁磁金属，非平凡量子几何在磁化动力学中起着至关重要的作用，这反过来也为探测量子度量提供了手段。对于量子霍尔铁磁体，展示了如何动态访问畴壁边界处局域化的手性边缘模式的性质。

Conclusion: 这项工作展示了非平衡协议在控制和探测强关联相方面的潜力，特别适用于扭曲MoTe₂和基于石墨烯的平带铁磁体系统。

Abstract: Dynamical control of quantum matter is a challenging, yet promising direction for probing strongly correlated states. Motivated by recent experiments in twisted MoTe$_2$ that demonstrated optical control of magnetization, we propose a protocol for probing magnetization dynamics in flat-band ferromagnets. We investigate the nucleation and dynamical growth of magnetic bubbles prepared on top of a false vaccum in both itinerant ferromagnets and spin-polarized Chern insulators. For ferromagnetic metals, we emphasize the crucial role of a non-trivial quantum geometry in the magnetization dynamics, which in turn also provides a probe for the quantum metric. Furthermore, for quantum Hall ferromagnets, we show how properties of chiral edge modes localized at domain-wall boundaries can be dynamically accessed. Our work demonstrates the potential for nonequilibrium protocols to control and probe strongly correlated phases, with particular relevance for twisted MoTe$_2$ and graphene-based flat-band ferromagnets.

</details>


### [12] [Magnetism and superconductivity in bilayer nickelate](https://arxiv.org/abs/2512.13793)
*Hui Yang,Ya-Hui Zhang*

Main category: cond-mat.str-el

TL;DR: 该研究为双层镍酸盐La₃Ni₂O₇提出了一个最小理论模型，通过强洪德耦合将d_z²局域矩与d_x²-y²巡游电子耦合，在大J_H极限下简化为双层II型t-J模型，成功统一了超导相和自旋密度波相。


<details>
  <summary>Details</summary>
Motivation: 双层镍酸盐La₃Ni₂O₇中发现的高温超导性需要一个最小理论模型，能够在无外部压力或应变条件下统一超导相和自旋密度波相。

Method: 提出一个模型：半填充的d_z²局域矩通过强洪德耦合J_H与巡游的d_x²-y²电子相互作用，在大J_H极限下简化为双层II型t-J模型。使用iDMRG计算在L_y=4, L_z=2圆柱上进行数值模拟。

Result: 1. 双交换铁磁性与面内超交换竞争产生周期为4的条纹状SDW序；2. 增加层间交换耦合会抑制磁序并稳定层间s波超导性；3. 该模型能捕捉到单轨道t-J模型无法解释的磁性特征。

Conclusion: II型t-J模型是描述双层镍酸盐中磁性与超导相互作用的最小理论框架，为理解该材料体系中的竞争序提供了关键见解。

Abstract: The discovery of high-temperature superconductivity in bilayer nickelate La$_{3}$Ni$_{2}$O$_{7}$ necessitates a minimal theoretical model that unifies the superconducting phase with the spin-density-wave (SDW) phase without external pressure or strain. We propose a model where half-filled $d_{z^{2}}$ local moments interact with itinerant $d_{x^{2}-y^{2}}$ electrons via strong Hund's coupling $J_H$, which reduces to a bilayer type-II t-J model in the large $J_H$ limit. Using iDMRG calculations on an $L_y=4, L_z=2$ cylinder, we demonstrate that the competition between double-exchange ferromagnetism and in-plane superexchange generates period-4 stripe-like SDW order-a feature absent in one-orbital t-J model with only $d_{x^2-y^2}$ orbital. Furthermore, increasing the interlayer exchange coupling suppresses magnetic order and stabilizes interlayer s-wave superconductivity. These results identify the type-II t-J model as a minimal framework for capturing the interplay of magnetism and superconductivity in bilayer nickelates.

</details>


### [13] [Correlation functions at the topological quantum phase transition in the S=1 XXZ chain with single-ion anisotropy](https://arxiv.org/abs/2512.14075)
*Toshiya Hikihara,Akira Furusaki*

Main category: cond-mat.str-el

TL;DR: 研究一维S=1 XXZ自旋模型在Haldane相和大D相之间的相变点，该临界点由中心电荷c=1的高斯理论描述，通过玻色化方法分析关联函数，发现纵向和横向自旋关联函数在不同分量中呈现不同的幂律衰减行为。


<details>
  <summary>Details</summary>
Motivation: 研究S=1 XXZ自旋模型在Haldane相和大D相之间的量子临界点特性，特别是关联函数的奇异行为，以及键交替对临界基态的影响。

Method: 采用玻色化方法分析相变点处的各种关联函数，推导其渐近形式，并使用密度矩阵重整化群方法进行数值计算验证。

Result: 发现纵向自旋关联函数仅在均匀分量中代数衰减，横向关联函数仅在交错分量中代数衰减。键交替会诱导关联函数中缺失的幂律分量出现。

Conclusion: S=1 XXZ模型在Haldane-大D相变点表现出中心电荷c=1的高斯临界性，关联函数呈现特定的衰减模式，键交替会改变临界基态的特性。

Abstract: We study the one-dimensional S=1 XXZ spin model with single-ion anisotropy. It is known that at the transition points between the Haldane and large-D phases, the model exhibits a quantum criticality described by the Gaussian theory, i.e., a conformal field theory with the central charge c=1. Using the bosonization approach, we investigate various correlation functions at the phase transition and derive their asymptotic forms. This allows us to clarify their peculiar behavior: the longitudinal (transverse) two-point spin correlation function has components that decay algebraically only in the uniform (staggered) sector. These theoretical predictions are verified by the numerical calculations using the density-matrix renormalization group method. The effect of weak bond alternation on the critical ground state at the phase transition is also discussed. It is shown that the bond alternation induces the missing power-law components in the correlation functions.

</details>


### [14] [A sine-square deformation approach to quantum critical points in one-dimensional systems](https://arxiv.org/abs/2512.14149)
*Yuki Miyazaki,Shiori Tanigawa,Giacomo Marmorini,Nobuo Furukawa,Daisuke Yamamoto*

Main category: cond-mat.str-el

TL;DR: 提出一种利用正弦平方形变（SSD）确定一维系统量子相边界的方法，通过分析SSD哈密顿量基态中局域可观测量是否呈现平移对称性来定位量子临界点。


<details>
  <summary>Details</summary>
Motivation: 需要一种有效方法来确定一维量子系统的相边界，特别是对于难以精确求解的复杂模型。正弦平方形变提供了一种通过有限尺寸系统分析来探测临界行为的新途径。

Method: 基于SSD的命题：如果一维系统是无能隙的，那么SSD哈密顿量基态中任何局域可观测量的期望值在热力学极限下呈现平移对称性。通过计算SSD哈密顿量的基态（使用密度矩阵重整化群算法），分析局域横向磁化随位置的变化，当该量变为与位置无关时，即对应量子临界点。

Result: 对于最近邻模型，使用最多84个位点的系统就能准确估计量子临界点，与文献结果一致。对于长程相互作用模型，发现反铁磁和顺磁相边界相对于最近邻情况略有偏移，反铁磁有序区域减小。还提出了在光学镊子中利用里德伯原子阵列实现具有SSD的反铁磁J1-J2伊辛耦合的实验方案。

Conclusion: 该方法能够从相对较小的系统尺寸精确确定量子临界点，甚至可能提取临界指数等额外临界现象。由于多个独立的标度条件自然出现，该方法为研究量子临界现象提供了有力工具。

Abstract: We propose a method to determine the quantum phase boundaries of one-dimensional systems using sine-square deformation (SSD). Based on the proposition, supported by several exactly solved cases though not proven in full generality, that ``if a one-dimensional system is gapless, then the expectation value of any local observable in the ground state of the Hamiltonian with SSD exhibits translational symmetry in the thermodynamic limit," we determine the quantum critical point as the location where a local observable becomes site-independent, identified through finite-size scaling analysis. As case studies, we consider two models: the antiferromagnetic Ising chain in mixed transverse and longitudinal magnetic fields with nearest-neighbor and long-range interactions. We calculate the ground state of these Hamiltonians with SSD using the density-matrix renormalization-group algorithm and evaluate the local transverse magnetization. For the nearest-neighbor model, we show that the quantum critical point can be accurately estimated by our procedure with systems of up to 84 sites, or even smaller, in good agreement with results from the literature. For the long-range model, we find that the phase boundary between the antiferromagnetic and paramagnetic phases is slightly shifted relative to the nearest-neighbor case, leading to a reduced region of antiferromagnetic order. Moreover, we propose an experimental procedure to implement the antiferromagnetic $J_1$-$J_2$ Ising couplings with SSD using Rydberg atom arrays in optical tweezers, which can be achieved within a very good approximation. Because multiple independent scaling conditions naturally emerge, our approach enables precise determination of quantum critical points and possibly even the extraction of additional critical phenomena, such as critical exponents, from relatively small system sizes.

</details>


### [15] [Acoustic phonon softening and lattice instability driven by on-site $f$-$d$ hybridization in CeCoSi](https://arxiv.org/abs/2512.14216)
*Takeshi Matsumura,Takumi Hasegawa,Ryuma Nakajima,Kenshin Kurauchi,Satoshi Tsutsui,Daisuke Ishikawa,Alfred Q. R. Baron,Hiroshi Tanida*

Main category: cond-mat.str-el

TL;DR: 通过高分辨率非弹性X射线散射研究CeCoSi中的软声子模式，发现与单斜畸变相关的横向声学模式显著软化，这种软化一直延伸到布里渊区边界，表明晶格不稳定性具有短关联长度。


<details>
  <summary>Details</summary>
Motivation: 研究CeCoSi在12K结构转变和9.5K反铁磁有序后的软声子模式，以理解其晶格不稳定性的物理机制。

Method: 使用高分辨率非弹性X射线散射技术，测量CeCoSi中横向声学模式的声子色散关系，特别关注与(yz+zx)型单斜畸变相关的模式。

Result: 发现与单斜畸变相关的横向声学模式出现显著软化，这种软化沿着(0,0,q)方向一直延伸到布里渊区边界，表明晶格不稳定性具有短关联长度。应变磁化率呈现居里型行为。

Conclusion: 这种晶格不稳定性源于Ce位点缺乏反演对称性导致的4f-5d轨道杂化，这是该晶体结构的本征特性。

Abstract: Soft phonon modes in tetragonal CeCoSi, which undergoes a structural transition at $T_0=12$ K followed by antiferromagnetic order at $T_{\text{N}}=9.5$ K, have been investigated using high-resolution inelastic x-ray scattering. Pronounced softening was detected in the transverse acoustic modes corresponding to the $(yz+zx)$-type monoclinic distortion, consistent with the experimentally determined triclinic structure. Remarkably, the softening persists up to the zone boundary along (0, 0, $q$), indicating a short correlation length of the lattice instability. This instability, characterized by a Curie-type strain susceptibility, is interpreted as a consequence of the on-site $4f$-$5d$ hybridization, which is intrinsic to this crystal structure due to the lack of inversion symmetry at the two Ce sites.

</details>


### [16] [Pressure-induced hole delocalization in the strongly correlated quasicubic charge-transfer perovskite $LaBa_2Fe_3O_{8+δ}$d](https://arxiv.org/abs/2512.14314)
*M. ElMassalami,S. Favre,M. B. Silva Neto*

Main category: cond-mat.str-el

TL;DR: 该研究通过分析LaBa₂Fe₃O₈₊δ的热压演化，构建了其压力-温度相图，发现了一个临界边界P_c^MIT(T)，标志着从局域态到空穴型扩展态的转变，揭示了该窄带隙强关联电荷转移系统中的金属性涌现机制。


<details>
  <summary>Details</summary>
Motivation: 研究LaBa₂Fe₃O₈₊δ这种窄带隙强关联电荷转移系统在压力作用下的电子态转变，探索从局域态到扩展态的转变机制，以及金属性涌现的物理本质。

Method: 通过分析材料的热压演化构建压力-温度相图，结合压力依赖的结构分析，研究在临界压力P_c^MIT(T)附近的电子态转变，同时使用Murnaghan型压缩性模型分析结构稳定性。

Result: 发现相对较低的临界压力（3-8 GPa）下发生金属-绝缘体转变，压力增强杂化强度和电荷转移特性，导致金属性涌现。室温下的压力依赖结构分析显示在P_c^MIT(T)处没有结构相变，系统保持准立方钙钛矿结构直至30 GPa。

Conclusion: LaBa₂Fe₃O₈₊δ中的金属-绝缘体转变本质上是电子性质的，空穴离域和金属导体的出现伴随着反铁磁性的抑制，表明系统接近量子临界点。

Abstract: Analysis of the thermal and baric evolution of resistance in $LaBa_2Fe_3O_{8+δ}$ enabled the construction of its pressure-temperature (P-T) phase diagram, which prominently displays a critical boundary, $P^{MIT}_c(T)$, marking the transition from localized to hole-type extended states. The relatively low critical pressures [$P^{MIT}_c(T) \approx 3$-8 GPa] suggest that, as $P \rightarrow P_c$ in this narrow-gap, strongly correlated charge-transfer system, both the hybridization strength and the charge-transfer character are progressively enhanced - ultimately leading to the emergence of metallicity. Emphasizing the electronic nature of this transition, pressure-dependent structural analyses at room temperature reveal no associated structural phase transition at $P^{MIT}_c(T)$; the system retains a (weakly tetragonally distorted) quasicubic perovskite structure with Murnaghan-type compressibility up to 30\,GPa. The emergence of hole delocalization and metallic conduction, coupled with suppressed antiferromagnetism, suggests proximity to quantum criticality.

</details>


### [17] [Impact of nonlocal spatial correlations for different lattice geometries](https://arxiv.org/abs/2512.14396)
*Marvin Leusch,Alessandro Toschi,Andreas Hausoel,Giorgio Sangiovanni,Georg Rohringer*

Main category: cond-mat.str-el

TL;DR: 该研究分析了晶格几何结构对强相互作用电子系统磁有序相热力学转变的影响，比较了不同布拉维晶格在DMFT和DΓA方法下的磁转变温度差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解晶格几何结构如何影响强相互作用电子系统的磁有序相变，特别是考虑局域和非局域关联效应时，不同晶格结构对磁转变温度的影响。

Method: 采用两步法：首先使用动力学平均场理论（DMFT）计算不同晶格（3d-sc、4d-sc、bcc、fcc）的Hubbard模型磁化率；然后使用动力学顶点近似（DΓA）这一DMFT的图解扩展方法，纳入非局域关联效应。

Result: 对于二分晶格（3d-sc、4d-sc、bcc），非局域涨落显著降低了DMFT的转变温度，且随着配位数的增加，DMFT与DΓA的差异减小。对于fcc晶格，DMFT中观察到的有序相在DΓA中完全消失，这与该晶格的强几何阻挫一致。

Conclusion: 晶格几何结构对磁有序相变有重要影响：二分晶格中非局域关联会降低转变温度，而fcc晶格的几何阻挫可能完全抑制磁有序。这些结果为评估DMFT对不同材料几何结构的转变温度高估提供了合理指导。

Abstract: We analyze the impact of the lattice geometry on the thermodynamic transition to magnetically ordered phases in strongly interacting electron systems for various Bravais lattices in three and four dimensions, including both local and nonlocal correlation effects. In a first step we use the dynamical mean field theory (DMFT), which takes into account purely local correlations, to calculate the magnetic susceptibilities of the Hubbard model on three (3d-sc) and four dimensional (4d-sc) simple cubic/hypercubic, as well as on three dimensional body- (bcc) and face-centered (fcc) cubic lattices, and determine the transition temperature to the corresponding magnetically-ordered state. In a second step, we exploit the dynamical vertex approximation (D$Γ$A), a diagrammatic extension of DMFT, to include the effect of nonlocal correlations which are particularly important in the vicinity of the corresponding phase transition. For the bipartite 3d-sc, 4d-sc and bcc lattices nonlocal fluctuations lead to a substantial reduction of the DMFT transition temperature consistent to the overall tendency of mean-field approaches to overestimate the stability of ordered phases. As expected, the magnitude of the difference between the DMFT, being exact in the limit of large connectivity/dimensions, and D$Γ$A transition temperatures decreases with increasing coordination number. On a more practical perspective, these results also provide a reasonable guidance to evaluate the expected overestimation of the DMFT ordering temperature for different material geometries. For the fcc lattice, on the other hand, the ordered phase observed in DMFT vanishes completely within D$Γ$A which is consistent with the existence of strong geometric frustration in this lattice.

</details>


### [18] [Long-range ferroelectric order in two dimensional excitonic insulators](https://arxiv.org/abs/2512.14558)
*Mikhail M. Glazov,Atac Imamoglu*

Main category: cond-mat.str-el

TL;DR: 二维双层半导体中可实现激子的真正玻色-爱因斯坦凝聚，突破了Mermin-Wagner定理的限制


<details>
  <summary>Details</summary>
Motivation: 传统观点认为Mermin-Wagner定理排除了二维玻色系统在非零温度下存在长程有序的可能性，但本文挑战这一观点，探索二维双层半导体中实现激子凝聚的可能性

Method: 通过施加电场减小层间带隙使激子在基态自发出现；利用允许长程电子-空穴交换相互作用的能带结构；施加有限磁场

Result: 证明了双层半导体中可实现层间激子的真正玻色-爱因斯坦凝聚，表明超流性和铁电序可以在二维激子绝缘体中同时存在

Conclusion: 二维双层半导体在特定条件下可以突破Mermin-Wagner定理的限制，实现激子凝聚，为二维系统中的超流和铁电共存提供了理论依据

Abstract: It is generally argued that Mermin-Wagner theorem excludes the possibility of long-range order in two dimensional bosonic systems at non-zero temperatures. In contrast, we show here that generic bilayer semiconductors could demonstrate true Bose-Einstein condensation of interlayer excitons. We show that the key requirements include (i) reduction of the interlayer band gap using an applied electric field so that excitons spontaneously appear in the ground state, (ii) band structure that allows for long-range electron-hole exchange interaction, and (iii) a finite magnetic field. Our results indicate that superfluidity and ferroelectric order can co-exist in two dimensional excitonic insulators.

</details>


### [19] [Detection of Image Potential States above the vacuum level in GeTe](https://arxiv.org/abs/2512.14597)
*Frédéric Chassot,Aki Pulkkinen,Ján Minár,Gunther Springholz,Matthias Hengsberger,Claude Monney*

Main category: cond-mat.str-el

TL;DR: α-GeTe(111)铁电半导体中发现三个真空能级以上的图像势态，通过时间与角度分辨光电子能谱揭示了其抛物线色散关系


<details>
  <summary>Details</summary>
Motivation: α-GeTe(111)铁电半导体的占据态电子能带结构已被广泛研究，但其未占据态特别是导带最小值附近的电子态仍未被充分探索

Method: 使用时间与角度分辨光电子能谱技术，结合Bloch谱函数计算，分析α-GeTe(111)中的图像势态

Result: 在α-GeTe(111)中观察到三个图像势态，能量延伸至真空能级以上0.8 eV，确定了前三个IPS的结合能及其完整的抛物线色散关系

Conclusion: IPS在真空能级以上的异常持续存在源于GeTe中的强偶极跃迁和大电子库的存在

Abstract: The ferroelectric semiconductor α-GeTe(111) has attracted significant attention in the last decade due to its unique properties, with extensive studies focusing on its occupied electronic bandstructure. In contrast, its unoccupied states - particularly those near the conduction band minimum - remain largely unexplored. In an effort to characterize those states, we surprisingly observe three image potential states (IPS) in α-GeTe(111) extending up to 0.8 eV above the vacuum level. Using time and angle-resolved photoemission spectroscopy, we resolve the full parabolic dispersions of the first three IPS and determine their binding energies. Our analysis, combined with Bloch spectral function calculations, reveals that the unexpected persistence of IPS above the vacuum level originates from strong dipole transitions and the presence of large electron reservoirs in GeTe.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records](https://arxiv.org/abs/2512.13700)
*Mitchell A. Klusty,Elizabeth C. Solie,Caroline N. Leach,W. Vaiden Logan,Lynnet E. Richey,John C. Gensel,David P. Szczykutowicz,Bryan C. McLellan,Emily B. Collier,Samuel E. Armstrong,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: 提出一个基于本地部署大语言模型的自动化临床特征提取框架，用于从电子健康记录中提取结构化信息，减少人工图表审查负担。


<details>
  <summary>Details</summary>
Motivation: 临床研究中的人工图表审查耗时耗力，需要专家从非结构化的电子健康记录中提取复杂信息，亟需自动化解决方案来减轻负担并提高数据一致性。

Method: 开发了一个安全、模块化的框架，在符合HIPAA标准的计算基础设施上本地部署大语言模型，结合检索增强生成和结构化响应方法，构建可广泛部署和扩展的容器系统。

Result: 该框架在评估中表现出高准确性，能够从大量患者记录中准确提取多种医学特征，与专家标注数据集相比表现良好，甚至发现了人工审查中遗漏的标注错误。

Conclusion: 该框架展示了LLM系统通过自动化特征提取减少人工图表审查负担的潜力，能够提高数据捕获的一致性，从而加速临床研究进程。

Abstract: Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally deployed large language models (LLMs) on institutionally approved, Health Insurance Portability and Accountability Act (HIPPA)-compliant compute infrastructure. This system integrates retrieval augmented generation (RAG) and structured response methods of LLMs into a widely deployable and scalable container to provide feature extraction for diverse clinical domains. In evaluation, the framework achieved high accuracy across multiple medical characteristics present in large bodies of patient notes when compared against an expert-annotated dataset and identified several annotation errors missed in manual review. This framework demonstrates the potential of LLM systems to reduce the burden of manual chart review through automated extraction and increase consistency in data capture, accelerating clinical research.

</details>


### [21] [Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference](https://arxiv.org/abs/2512.13701)
*Zheng Xing,Junting Chen*

Main category: cs.AI

TL;DR: 提出了一种无需位置标签的盲无线地图构建框架，利用室内MIMO-OFDM信道测量推断用户轨迹，通过理论证明和贝叶斯推理实现高精度定位和波束图重建。


<details>
  <summary>Details</summary>
Motivation: 传统无线地图构建方法需要大量位置标记数据，成本高昂且在实际场景中不实用。本文旨在开发一种无需位置标签的盲构建方法，解决实际部署中的成本和技术挑战。

Method: 首先证明非视距信道状态信息在准镜面环境模型下具有空间连续性，推导出与物理距离成比例的CSI-距离度量。针对泊松分布的AP部署和直线轨迹，证明即使角度分辨率较差，定位误差的Cramer-Rao下界也能渐近消失。基于这些理论结果，开发了空间正则化贝叶斯推理框架，联合估计信道特征、区分视距/非视距条件并恢复用户轨迹。

Result: 在射线追踪数据集上的实验表明，平均定位误差为0.68米，波束图重建误差为3.3%，验证了所提出的盲映射方法的有效性。

Conclusion: 该研究提出了一种创新的盲无线地图构建框架，通过理论分析和贝叶斯推理方法，在无需位置标签的情况下实现了高精度的用户轨迹推断和无线地图构建，为实际无线应用提供了实用解决方案。

Abstract: Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-world scenarios. This paper presents a blind radio map construction framework that infers user trajectories from indoor multiple-input multiple-output (MIMO)-Orthogonal Frequency-Division Multiplexing (OFDM) channel measurements without relying on location labels. It first proves that channel state information (CSI) under non-line-of-sight (NLOS) exhibits spatial continuity under a quasi-specular environmental model, allowing the derivation of a CSI-distance metric that is proportional to the corresponding physical distance. For rectilinear trajectories in Poisson-distributed access point (AP) deployments, it is shown that the Cramer-Rao Lower Bound (CRLB) of localization error vanishes asymptotically, even under poor angular resolution. Building on these theoretical results, a spatially regularized Bayesian inference framework is developed that jointly estimates channel features, distinguishes line-of-sight (LOS)/NLOS conditions and recovers user trajectories. Experiments on a ray-tracing dataset demonstrate an average localization error of 0.68 m and a beam map reconstruction error of 3.3%, validating the effectiveness of the proposed blind mapping method.

</details>


### [22] [Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents](https://arxiv.org/abs/2512.13704)
*Doohee You,Sundeep Paul*

Main category: cs.AI

TL;DR: Adjudicator是一个用于自动识别和纠正标签噪声的神经符号系统，通过构建知识图谱和多智能体LLM架构实现高精度数据验证，在工业环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 生产机器学习系统的性能受限于训练数据质量，高风险的工业应用中噪声标签会降低性能并损害用户信任，需要自动化解决方案来识别和纠正标签噪声。

Method: 采用神经符号方法：首先构建动态知识图谱统一项目上下文，然后使用"智能体委员会"架构，让专门化的智能体通过辩论和投票来确定标签有效性。

Result: 在AlleNoise基准的1000项平衡子集上，KG-informed模型达到0.99 F1分数，显著优于单LLM基线(0.48 F1)和非KG委员会(0.59 F1)。系统通过KG完美识别复杂结构性错误，实现完全召回率。

Conclusion: Adjudicator为自动化高精度数据验证提供了一个稳健且可解释的系统，为严格监管的工业环境中生成黄金数据集提供了重要概念验证。

Abstract: The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correcting label noise and has been validated for production deployment. Adjudicator models this as a neuro-symbolic task, first constructing a dynamic Knowledge Graph (KG) to unify item context. This KG then informs a "Council of Agents," a novel multi-agent Large Language Model architecture where specialized agents debate and vote on a label's validity. We validate our system on a 1,000-item balanced subset of the AlleNoise benchmark. Our KG-informed model achieves a 0.99 F1-score, significantly outperforming a single-LLM baseline (0.48 F1) and a non-KG council (0.59 F1). Our analysis reveals this is due to a Precision, achieved by a novel override logic that uses the KG to perfectly identify complex, structural errors (complete Recall) -- a class of errors that baselines fail to find. This result demonstrates a robust and explainable system for automated, high-precision data verification, serving as a vital proof-of-concept for generating golden datasets in strictly governed industrial environments.

</details>


### [23] [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)
*Gangesh Pathak,Prasanna Kumar*

Main category: cs.AI

TL;DR: 本文提出了一种基于AI的标注流水线，通过人机协同方法系统识别、标注和修复LLM输出的不稳定性模式，以解决LLM在高度监管行业中因可靠性问题而受限的挑战。


<details>
  <summary>Details</summary>
Motivation: LLM在高度监管行业中的应用受到限制，主要原因是存在不稳定性问题、不一致推理、幻觉和性能波动等可靠性问题。现有的稳定化方法如RLHF和监督微调虽然能带来可量化的改进，但成本高昂且依赖大量人工标注，难以可持续扩展。

Method: 提出AI驱动的标注流水线，结合自动化弱监督和基于置信度的标注，并引入人工验证，确保反馈信息的可靠性和道德完整性。框架引入了语义一致性、事实正确性和逻辑连贯性等稳定性特定标注类别，通过反馈循环实现模型的持续校准和鲁棒性增强。

Result: 该方法能够系统性地识别和修复LLM输出的不稳定性模式，通过人机协同确保标注质量，为LLM在需要事实精确性和一致行为的领域提供更可靠的解决方案。

Conclusion: 提出的AI标注流水线为LLM稳定性问题提供了一种可扩展的解决方案，通过结合自动化标注和人工验证，能够在保证质量的同时降低标注成本，促进LLM在高度监管行业中的安全应用。

Abstract: LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stabilization, such as, reinforcement learning with human feedback (RLHF) and supervised fine-tuning, offer quantifiable improvements but are expensive and based on the intensive annotation of humans, thus being not easily scaled in a sustainable way (Dong et al., 2023; Retzlaff et al., 2024). This paper presents an AI-based annotation pipeline that systematically identifies, labels, and fixes for instability patterns on LLM output. Our human-AI synergy method combines the models of automated weak supervision and confidence-based annotation with the target human validation to guarantee the reliability and moral uprightness of feedback information (Cabitza et al., 2023; Jiang et al., 2023). The semantic consistency, factual correctness, and logical coherence categories of stability-specific annotation are introduced into our framework, allowing the continuous calibration of models and the enhancement of their robustness based on the feedback loops (Honovich et al., 2021; Nan et al., 2021).

</details>


### [24] [Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy](https://arxiv.org/abs/2512.13725)
*Steve Nwaiwu,Nipat Jongsawat,Anucha Tungkasthan*

Main category: cs.AI

TL;DR: 本文首次系统评估了量化（INT8和NF4）对大型语言模型因果推理能力的影响，发现4位量化对因果推理影响有限，干预查询最敏感，而现有反事实基准未能揭示量化导致的推理漂移。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型部署向边缘和资源受限环境转移，量化模型（如INT8和NF4）成为标准。然而，精度降低对形式化因果推理的影响尚不清楚，需要系统评估量化对Pearl因果阶梯三个层级的影响。

Method: 使用3000个样本的分层CLadder基准，评估Llama 3 8B模型在不同量化精度下的因果推理能力。在Pearl因果阶梯的三个层级（关联、干预、反事实）进行测试，并进一步在CRASS基准上验证。还评估了图检索增强生成技术对量化模型干预推理的改善效果。

Result: 量化对因果推理影响有限：NF4量化总体退化小于1%。干预查询（第二层级）对精度损失最敏感，反事实推理相对稳定但存在异质性弱点。CRASS基准显示各精度性能几乎相同，表明现有常识反事实数据集缺乏揭示量化诱导推理漂移的结构敏感性。图检索增强生成使NF4干预准确率提高1.7%，部分抵消压缩相关退化。

Conclusion: 因果推理对4位量化表现出意外的鲁棒性，图结构化增强可以有针对性地强化干预推理，而当前反事实基准未能捕捉更深层次的因果脆弱性。本研究为部署高效且结构支持的因果AI系统提供了初步经验指导和实用建议。

Abstract: Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.

</details>


### [25] [State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models](https://arxiv.org/abs/2512.13762)
*TK Lee*

Main category: cs.AI

TL;DR: 该研究提出了一种定性案例研究方法，用于审计大语言模型在长时程交互中的策略相关行为选择性，发现同一模型在非敏感领域表现正常，但在敏感领域会反复出现功能性拒绝，表现出行为不对称性。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型被广泛部署为通用工具，但标准定量基准测试无法捕捉到长时间交互中可能出现的特定行为模式。研究旨在开发一种定性审计方法，以检测模型在策略敏感领域的行为选择性。

Method: 采用定性案例研究方法，通过86轮对话会话进行长时程交互审计。定义了三种响应机制：正常表现(NP)、功能性拒绝(FR)和元叙事(MN)。分析了模型在不同领域的行为模式，特别关注策略敏感领域的响应特征。

Result: 研究发现同一模型在非敏感领域表现正常，但在提供商或策略敏感领域会反复出现功能性拒绝，表现出NP和FR之间的持续不对称性。元叙事角色框架叙述倾向于与敏感情境中的拒绝同时出现。

Conclusion: 研究提出了基于可观察行为的交互层面审计框架，并引入"习得性无能"作为描述这种选择性保留行为的概念框架，为研究潜在对齐副作用提供了新视角，值得在不同用户和模型中进行进一步调查。

Abstract: Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon interaction. In a single 86-turn dialogue session, the same model shows Normal Performance (NP) in broad, non-sensitive domains while repeatedly producing Functional Refusal (FR) in provider- or policy-sensitive domains, yielding a consistent asymmetry between NP and FR across domains. Drawing on learned helplessness as an analogy, we introduce learned incapacity (LI) as a behavioral descriptor for this selective withholding without implying intentionality or internal mechanisms. We operationalize three response regimes (NP, FR, Meta-Narrative; MN) and show that MN role-framing narratives tend to co-occur with refusals in the same sensitive contexts. Overall, the study proposes an interaction-level auditing framework based on observable behavior and motivates LI as a lens for examining potential alignment side effects, warranting further investigation across users and models.

</details>


### [26] [Mathematics and Coding are Universal AI Benchmarks](https://arxiv.org/abs/2512.13764)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 论文研究了数学和编程在AI智能体心理测量电池模空间中的特殊作用，证明了在特定条件下，由数学定理证明和编程任务生成的电池子空间在评估度量下是稠密的。


<details>
  <summary>Details</summary>
Motivation: 研究数学和编程在AI智能体评估中的特殊地位，探索它们如何作为"通用坐标"来评估AI能力，并理解形式化数学为何能成为高级AI递归自我改进的自然启动领域。

Method: 基于AAI框架和GVU动力学，定义了"数学纤维"概念，结合形式化证明内核（如Lean、Coq），分析GVU流在数学纤维上的谱稳定性。主要技术结果是密度定理：在智能体输出均匀紧致和AAI泛函Lipschitz条件下，证明数学定理证明和编程任务生成的电池子空间在模空间中稠密。

Result: 1. 编程单独具有普遍性，而纯数学不具有普遍性；2. 数学的特权是谱特性而非表达能力；3. 数学和编程提供了评估的"通用坐标"；4. 形式化数学是高级AI递归自我改进的自然启动领域。

Conclusion: 数学和编程在AI智能体评估中具有特殊地位，它们作为"通用坐标"能够有效评估AI能力，形式化数学特别适合作为AI递归自我改进的启动领域，这为AI评估和智能体发展提供了理论依据。

Abstract: We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.

</details>


### [27] [Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems](https://arxiv.org/abs/2512.13771)
*Javier Marín*

Main category: cs.AI

TL;DR: 该论文提出了语义接地指数(SGI)，通过计算响应与问题vs上下文的角距离比来检测RAG系统中的幻觉，发现幻觉响应在嵌入空间中更接近问题而非上下文，这种现象称为"语义懒惰"。


<details>
  <summary>Details</summary>
Motivation: 研究RAG系统产生幻觉时在嵌入空间中留下的几何痕迹，开发一种计算高效、理论基础的检测方法来识别需要验证的响应。

Method: 引入语义接地指数(SGI)，定义为响应到问题与到上下文的角距离比，在单位超球面上计算。基于球面三角不等式理论推导，并在HaluEval数据集(n=5,000)上使用五种嵌入模型进行验证。

Result: SGI能有效检测幻觉，效应量d=0.92-1.28，跨模型相关性r=0.85。理论预测得到证实：问题-上下文角分离越大，SGI判别力越强，效应量从d=0.61增至d=1.27，AUC从0.72提升至0.83。在长响应(d=2.05)和短问题(d=1.22)上表现优异。

Conclusion: SGI提供了计算高效、理论基础的检测方法，能识别需要验证的RAG响应，但主要测量主题参与度而非事实准确性(TruthfulQA上AUC=0.478)。

Abstract: When retrieval-augmented generation (RAG) systems hallucinate, what geometric trace does this leave in embedding space? We introduce the Semantic Grounding Index (SGI), defined as the ratio of angular distances from the response to the question versus the context on the unit hypersphere $\mathbb{S}^{d-1}$.Our central finding is \emph{semantic laziness}: hallucinated responses remain angularly proximate to questions rather than departing toward retrieved contexts. On HaluEval ($n$=5,000), we observe large effect sizes (Cohen's $d$ ranging from 0.92 to 1.28) across five embedding models with mean cross-model correlation $r$=0.85. Crucially, we derive from the spherical triangle inequality that SGI's discriminative power should increase with question-context angular separation $θ(q,c)$-a theoretical prediction confirmed empirically: effect size rises monotonically from $d$=0.61 -low $θ(q,c)$, to $d$=1.27 -high $θ(q,c)$, with AUC improving from 0.72 to 0.83. Subgroup analysis reveals that SGI excels on long responses ($d$=2.05) and short questions ($d$=1.22), while remaining robust across context lengths. Calibration analysis yields ECE=0.10, indicating SGI scores can serve as probability estimates, not merely rankings. A critical negative result on TruthfulQA (AUC=0.478) establishes that angular geometry measures topical engagement rather than factual accuracy. SGI provides computationally efficient, theoretically grounded infrastructure for identifying responses that warrant verification in production RAG deployments.

</details>


### [28] [MURIM: Multidimensional Reputation-based Incentive Mechanism for Federated Learning](https://arxiv.org/abs/2512.13955)
*Sindhuja Madabushi,Dawood Wasif,Jin-Hee Cho*

Main category: cs.AI

TL;DR: MURIM是一个基于多维信誉的联邦学习激励机制，通过综合考虑客户端可靠性、隐私、资源容量和公平性，防止恶意客户端获得不当奖励，提升联邦学习系统的安全性和公平性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临客户端激励不足、隐私风险、资源约束等关键挑战，需要评估客户端可靠性以实现公平激励分配，确保每个客户端的数据对全局模型做出有意义的贡献。

Method: 提出MURIM（MUlti-dimensional Reputation-based Incentive Mechanism），基于客户端贡献、延迟和信誉分配激励，并配备可靠性验证模块，综合考虑客户端可靠性、隐私、资源容量和公平性。

Result: 在MNIST、FMNIST和ADULT Income数据集上的实验表明，MURIM在公平性指标上提升达18%，隐私攻击成功率降低5-9%，对投毒和噪声梯度攻击的鲁棒性提升达85%。

Conclusion: MURIM能有效缓解对抗性威胁，促进公平真实的参与，在异构动态联邦环境中保持稳定的模型收敛。

Abstract: Federated Learning (FL) has emerged as a leading privacy-preserving machine learning paradigm, enabling participants to share model updates instead of raw data. However, FL continues to face key challenges, including weak client incentives, privacy risks, and resource constraints. Assessing client reliability is essential for fair incentive allocation and ensuring that each client's data contributes meaningfully to the global model. To this end, we propose MURIM, a MUlti-dimensional Reputation-based Incentive Mechanism that jointly considers client reliability, privacy, resource capacity, and fairness while preventing malicious or unreliable clients from earning undeserved rewards. MURIM allocates incentives based on client contribution, latency, and reputation, supported by a reliability verification module. Extensive experiments on MNIST, FMNIST, and ADULT Income datasets demonstrate that MURIM achieves up to 18% improvement in fairness metrics, reduces privacy attack success rates by 5-9%, and improves robustness against poisoning and noisy-gradient attacks by up to 85% compared to state-of-the-art baselines. Overall, MURIM effectively mitigates adversarial threats, promotes fair and truthful participation, and preserves stable model convergence across heterogeneous and dynamic federated settings.

</details>


### [29] [Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms](https://arxiv.org/abs/2512.13978)
*Yang Cao,Yubin Chen,Xuyang Guo,Zhao Song,Song Yue,Jiahao Zhang,Jiale Zhao*

Main category: cs.AI

TL;DR: 论文评估了GPT-5-Thinking、Gemini-3-Pro、Claude-Sonnet-4.5-Thinking和Grok-4四个前沿大语言模型在《随机算法》教材中的证明生成能力，发现顶级模型准确率约66%，但模型间存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学推理和科学发现方面取得突破，但仍需对其在经典研究生级数学理论上的基线推理能力进行严格评估，以了解模型的实际数学推导可靠性。

Method: 使用《随机算法》教材中的引理和习题作为测试集，要求每个模型生成正式的LaTeX证明，对四个前沿模型进行全面基准测试，并进行定性分析。

Result: 顶级模型（Gemini和Claude）准确率约66%，表现出对概率方法和形式逻辑的扎实掌握；其他模型一致性较差（约40%）。在简洁性、幻觉率和逻辑结构方面存在差异。

Conclusion: 前沿模型已达到适合研究生级教学辅助和形式化的熟练度阈值，但在严格的数学推导可靠性方面存在显著差异，需要进一步改进。

Abstract: The rapid advancement of large language models (LLMs) has led to significant breakthroughs in automated mathematical reasoning and scientific discovery. Georgiev, G${ó}$mez-Serrano, Tao, and Wagner [GGSTW+25] demonstrate that AI systems can explore new constructions and improve existing bounds, illustrating the growing potential of LLMs to accelerate mathematical discovery. Similarly, Bubeck et al. [BCE+25] show that GPT-5 can meaningfully contribute to scientific workflows, from proposing hypotheses to generating proofs and analyses. Despite these advances, a rigorous evaluation of these models on canonical, graduate-level mathematical theory remains necessary to understand their baseline reasoning capabilities. In this paper, we present a comprehensive benchmark of four frontier models: GPT-5-Thinking, Gemini-3-Pro, Claude-Sonnet-4.5-Thinking, and Grok-4 against the classic curriculum of Randomized Algorithms by Motwani and Raghavan [MR95].
  We tasked each model with generating formal LaTeX proofs for a series of lemmas and exercises spanning the textbook. We find that while the top-tier models (Gemini, and Claude) achieve a high accuracy rate (approx. 66%), demonstrating a robust grasp of probabilistic method and formal logic, other models lag significantly in consistency (approx. 40%). We provide a qualitative analysis of the generated proofs, highlighting differences in conciseness, hallucination rates, and logical structure. Our results suggest that while frontier models have reached a threshold of proficiency suitable for graduate-level pedagogical assistance and formalization, significant variance exists in their reliability for rigorous mathematical derivation. The code and the full set of LLM-generated responses are open-sourced and publicly available at https://github.com/magiclinux/math_benchmark_probability.

</details>


### [30] [ReflCtrl: Controlling LLM Reflection via Representation Engineering](https://arxiv.org/abs/2512.13979)
*Ge Yan,Chung-En Sun,Tsui-Wei,Weng*

Main category: cs.AI

TL;DR: ReflCtrl框架通过表示工程控制LLM的自我反思频率，在保持性能的同时减少推理成本，发现反思与模型内部不确定性高度相关。


<details>
  <summary>Details</summary>
Motivation: 虽然自我反思能提升推理性能，但会增加推理成本。本研究旨在通过表示工程方法控制反思频率，在保持性能的同时降低计算开销。

Method: 将模型推理过程分段，识别反思步骤，在潜在空间中提取控制反思行为的方向向量，提出逐步引导方法ReflCtrl来控制反思频率。

Result: 实验表明：(1)在许多情况下反思是冗余的，特别是对更强模型，可节省高达33.6%的推理token同时保持性能；(2)反思行为与内部不确定性信号高度相关。

Conclusion: 通过表示工程控制反思频率是有效的，自我反思可能由模型内部不确定性驱动，这为优化推理效率提供了新途径。

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) reasoning have achieved strong performance across diverse tasks, including mathematics, coding, and general reasoning. A distinctive ability of these reasoning models is self-reflection: the ability to review and revise previous reasoning steps. While self-reflection enhances reasoning performance, it also increases inference cost. In this work, we study self-reflection through the lens of representation engineering. We segment the model's reasoning into steps, identify the steps corresponding to reflection, and extract a reflection direction in the latent space that governs this behavior. Using this direction, we propose a stepwise steering method that can control reflection frequency. We call our framework ReflCtrl. Our experiments show that (1) in many cases reflections are redundant, especially in stronger models (in our experiments, we can save up to 33.6 percent of reasoning tokens while preserving performance), and (2) the model's reflection behavior is highly correlated with an internal uncertainty signal, implying self-reflection may be controlled by the model's uncertainty.

</details>


### [31] [Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](https://arxiv.org/abs/2512.13996)
*Can Jin,Hongwu Peng,Mingcan Xiang,Qixin Zhang,Xiangchi Yuan,Amit Hasan,Ohiremen Dibua,Yifan Gong,Yan Kang,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: DTop-p MoE：一种稀疏可控的动态Top-p路由机制，通过PI控制器动态调整概率阈值，实现激活专家稀疏度的精确控制，同时引入动态路由归一化机制适应不同层的专家选择模式。


<details>
  <summary>Details</summary>
Motivation: 标准Top-k路由策略对所有token施加统一的稀疏模式，忽略了token难度的差异。现有的Top-p路由实现通常依赖固定的全局概率阈值，导致计算成本不可控且对超参数选择敏感。

Method: 提出DTop-p MoE路由机制：1) 使用比例-积分(PI)控制器动态调整概率阈值，使运行中的激活专家稀疏度与指定目标对齐；2) 引入动态路由归一化机制，适应层间路由logits，允许不同层学习不同的专家选择模式。

Result: 在大语言模型和扩散变换器上的实验表明，DTop-p在性能上持续优于Top-k和固定阈值Top-p基线。分析证实DTop-p能精确控制激活专家数量，同时自适应地在不同token和层间分配资源。

Conclusion: DTop-p在专家粒度、专家容量、模型规模和数据集大小方面表现出良好的扩展性，为大规模MoE预训练提供了一个鲁棒的框架。

Abstract: Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flexible alternative, existing implementations typically rely on a fixed global probability threshold, which results in uncontrolled computational costs and sensitivity to hyperparameter selection. In this paper, we propose DTop-p MoE, a sparsity-controllable dynamic Top-p routing mechanism. To resolve the challenge of optimizing a non-differentiable threshold, we utilize a Proportional-Integral (PI) Controller that dynamically adjusts the probability threshold to align the running activated-expert sparsity with a specified target. Furthermore, we introduce a dynamic routing normalization mechanism that adapts layer-wise routing logits, allowing different layers to learn distinct expert-selection patterns while utilizing a global probability threshold. Extensive experiments on Large Language Models and Diffusion Transformers demonstrate that DTop-p consistently outperforms both Top-k and fixed-threshold Top-p baselines. Our analysis confirms that DTop-p maintains precise control over the number of activated experts while adaptively allocating resources across different tokens and layers. Furthermore, DTop-p exhibits strong scaling properties with respect to expert granularity, expert capacity, model size, and dataset size, offering a robust framework for large-scale MoE pre-training.

</details>


### [32] [MobileWorldBench: Towards Semantic World Modeling For Mobile Agents](https://arxiv.org/abs/2512.14014)
*Shufan Li,Konstantinos Kallidromitis,Akash Gokul,Yusuke Kato,Kazuki Kozuka,Aditya Grover*

Main category: cs.AI

TL;DR: 该研究提出了一个用于GUI智能体的语义世界建模方法，用自然语言描述状态转换而非预测原始像素，并发布了MobileWorldBench基准测试和MobileWorld数据集来提升视觉语言模型的世界建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统像素空间世界模型在GUI环境中面临实际限制，预测复杂视觉元素的未来状态很困难。需要探索更适合GUI智能体的世界建模方法。

Method: 1. 引入MobileWorldBench基准测试评估视觉语言模型作为移动GUI智能体世界模型的能力；2. 发布包含140万样本的MobileWorld大规模数据集；3. 提出将VLM世界模型集成到移动智能体规划框架中的新框架。

Result: 语义世界模型能直接提升移动智能体的任务成功率，证明了该方法在GUI环境中的有效性。

Conclusion: 自然语言描述的状态转换比像素预测更适合GUI智能体的世界建模，语义世界模型能显著改善移动智能体的性能。

Abstract: World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld

</details>


### [33] [Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation](https://arxiv.org/abs/2512.14048)
*Shen Li,Li Huang,Shaoxiong Zhan,Weifeng Sun,Tao Yin,Zhongxin Liu,Meng Yan*

Main category: cs.AI

TL;DR: RoutingGen是一个难度感知的路由框架，根据任务复杂度动态选择提示策略：简单任务用少样本提示，复杂任务用创新的意图思维链(ICoT)进行结构化推理，在保持SOTA性能的同时显著减少token使用量。


<details>
  <summary>Details</summary>
Motivation: 现有思维链提示方法存在两个主要局限：1) 统一应用导致简单任务上过度思考；2) 缺乏代码生成中的意图抽象，模型关注表面结构而忽视全局问题目标。受认知经济原则启发，需要只在必要时进行结构化推理以节省认知资源。

Method: 提出RoutingGen框架，包含两个核心组件：1) 难度感知路由机制，动态评估任务复杂度；2) 意图思维链(ICoT)策略，引导模型捕获任务意图，包括核心算法逻辑和时间复杂度等抽象概念。

Result: 在三个模型和六个标准代码生成基准测试中，RoutingGen在大多数设置下达到最先进性能，同时平均减少46.37%的token使用量。ICoT在挑战性基准上优于六个现有提示基线方法。

Conclusion: RoutingGen通过难度感知路由和意图思维链，有效解决了现有思维链方法的局限性，在保持高性能的同时显著提升效率，为代码生成任务提供了更智能的提示策略框架。

Abstract: Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.

</details>


### [34] [OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value](https://arxiv.org/abs/2512.14051)
*Mengzhang Cai,Xin Gao,Yu Li,Honglin Lin,Zheng Liu,Zhuoshi Pan,Qizhi Pei,Xiaoran Shang,Mengyuan Sun,Zinan Tang,Xiaoyang Wang,Zhanping Zhong,Yun Zhu,Dahua Lin,Conghui He,Lijun Wu*

Main category: cs.AI

TL;DR: OpenDataArena (ODA) 是一个用于评估后训练数据价值的开放平台，通过统一训练-评估流程、多维度评分框架、数据谱系探索器和开源工具包，揭示了数据复杂性-性能权衡、基准冗余等非平凡洞见。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的发展依赖于后训练数据集的质量和多样性，但数据本身却是一个黑箱：组成不透明、来源不确定、缺乏系统性评估。这种不透明性阻碍了可复现性，并模糊了数据特征与模型行为之间的因果关系。

Method: ODA平台包含四个核心支柱：1) 统一的训练-评估流程，确保跨模型和领域的公平比较；2) 多维度评分框架，从数十个维度分析数据质量；3) 交互式数据谱系探索器，可视化数据集谱系和来源组成；4) 完全开源的工具包，支持训练、评估和评分。

Result: 在ODA上进行了广泛实验：覆盖120多个训练数据集、22个基准测试、600多次训练运行和4000万个处理数据点。分析揭示了数据复杂性与任务性能之间的权衡，通过谱系追踪发现了流行基准中的冗余，并绘制了数据集间的谱系关系图。

Conclusion: ODA旨在推动从试错式数据管理向数据为中心AI的原则性科学转变，为数据混合规律和基础模型战略组成的研究铺平道路。平台发布了所有结果、工具和配置，以民主化高质量数据评估的访问。

Abstract: The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.

</details>


### [35] [RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees](https://arxiv.org/abs/2512.14069)
*Junjie Ma,Jinlong Li*

Main category: cs.AI

TL;DR: RADAR是一种基于强化学习的动态草稿树推测采样方法，通过实时决策减少冗余计算，加速大语言模型推理


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型推理成本高且速度慢，传统推测采样方法中草稿模型的调用次数是预设超参数，缺乏灵活性，无法有效生成和利用候选标记

Method: 提出RADAR方法，将草稿树生成过程建模为马尔可夫决策过程，采用离线强化学习训练预测模型，实时决策草稿模型的调用，减少冗余计算

Result: 在三个大语言模型和四个任务上的评估显示，RADAR相比自回归解码基线实现了3.17倍到4.82倍的加速

Conclusion: RADAR通过强化学习驱动的动态草稿树生成，有效加速大语言模型推理，代码已开源

Abstract: Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.

</details>


### [36] [Grammar Search for Multi-Agent Systems](https://arxiv.org/abs/2512.14079)
*Mayank Singh,Vikas Yadav,Shiva Krishna Reddy Malay,Shravan Nayak,Sai Rajeswar,Sathwik Tejaswi Madhusudhan,Eduardo Blanco*

Main category: cs.AI

TL;DR: 本文提出了一种结构化框架，使用固定、可组合的简单组件来探索多智能体系统搜索空间，相比基于LLM的自由形式搜索方法，在数学和问答领域的五个基准测试中，有四个表现更优，且具有成本效益和可解释性优势。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统自动搜索主要依赖基于LLM的自由形式代码空间搜索，这种方法虽然具有生成灵活性，但缺乏结构化和效率。本文旨在开发一种更结构化、高效且可解释的多智能体系统搜索框架。

Method: 提出结构化框架，使用固定的一组简单、可组合组件来探索多智能体系统搜索空间，而不是依赖LLM的自由形式生成。这种方法虽然候选生成阶段缺乏LLM的生成灵活性，但通过结构化组件实现更高效的搜索。

Result: 在数学和问答两个领域的五个基准测试中，该方法在四个基准上优于先前基于LLM的自由形式搜索方法。此外，该方法还提供了更经济高效的搜索过程，并生成了模块化、可解释且逻辑更简单的多智能体系统。

Conclusion: 结构化组件方法在多智能体系统自动搜索中优于基于LLM的自由形式搜索，不仅性能更好，而且具有成本效益和可解释性优势，为多智能体系统设计提供了更高效、模块化的解决方案。

Abstract: Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.

</details>


### [37] [Georeferencing complex relative locality descriptions with large language models](https://arxiv.org/abs/2512.14228)
*Aneesha Fernando,Surangika Ranathunga,Kristin Stock,Raj Prasanna,Christopher B. Jones*

Main category: cs.AI

TL;DR: 本文探索使用大语言模型自动地理编码生物多样性标本记录中的复杂位置描述，通过QLoRA微调在多个区域和语言数据集上取得优于现有基线方法的结果。


<details>
  <summary>Details</summary>
Motivation: 生物标本记录中的位置描述通常是叙述性的而非坐标形式，传统基于地名库或语言模型的方法难以处理相对空间关系描述，导致地理编码不准确。生物多样性研究需要精确的地理参考，但人工处理劳动密集，亟需自动化解决方案。

Method: 首先识别有效的提示模式，然后使用量化低秩适配（QLoRA）在多区域、多语言的生物多样性数据集上微调大语言模型，以处理复杂的位置描述。

Result: 在固定训练数据量下，该方法平均65%的记录在10公里半径内，最佳结果（纽约州）达到85%在10公里内和67%在1公里内，优于现有基线方法。

Conclusion: 大语言模型在处理复杂、冗长的位置描述方面表现出色，展示了在生物多样性领域地理编码复杂位置描述的潜力。

Abstract: Georeferencing text documents has typically relied on either gazetteer-based methods to assign geographic coordinates to place names, or on language modelling approaches that associate textual terms with geographic locations. However, many location descriptions specify positions relatively with spatial relationships, making geocoding based solely on place names or geo-indicative words inaccurate. This issue frequently arises in biological specimen collection records, where locations are often described through narratives rather than coordinates if they pre-date GPS. Accurate georeferencing is vital for biodiversity studies, yet the process remains labour-intensive, leading to a demand for automated georeferencing solutions. This paper explores the potential of Large Language Models (LLMs) to georeference complex locality descriptions automatically, focusing on the biodiversity collections domain. We first identified effective prompting patterns, then fine-tuned an LLM using Quantized Low-Rank Adaptation (QLoRA) on biodiversity datasets from multiple regions and languages. Our approach outperforms existing baselines with an average, across datasets, of 65% of records within a 10 km radius, for a fixed amount of training data. The best results (New York state) were 85% within 10km and 67% within 1km. The selected LLM performs well for lengthy, complex descriptions, highlighting its potential for georeferencing intricate locality descriptions.

</details>


### [38] [Gödel's Poetry](https://arxiv.org/abs/2512.14252)
*Kelly J. Davis*

Main category: cs.AI

TL;DR: 该论文提出了一种结合专用语言模型和递归定理分解的自动定理证明新方法，在Lean4中实现了90.4%的miniF2F通过率，并通过分解进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 形式化自动定理证明长期以来被视为人工智能的挑战，需要新的方法来提高证明生成的能力和效率。

Method: 采用多智能体架构，结合专用语言模型生成Lean4证明，通过递归分解将复杂定理分解为更简单的蕴含命题，并扩展Kimina Lean Server以支持AST解析实现自动化递归证明分解。

Result: 在没有分解的情况下，在miniF2F测试集上达到90.4%的通过率；通过分解机制，性能得到显著提升。

Conclusion: 提出的方法在自动定理证明方面取得了显著进展，系统已开源并可通过PyPI安装，便于进一步研究和扩展。

Abstract: Formal, automated theorem proving has long been viewed as a challenge to artificial intelligence. We introduce here a new approach to computer theorem proving, one that employs specialized language models for Lean4 proof generation combined with recursive decomposition of difficult theorems into simpler entailing propositions. These models are coordinated through a multi-agent architecture that orchestrates autoformalization (if required), proof generation, decomposition of difficult theorems into simpler entailing propositions, and recursive proof (and/or decomposition) of these propositions. Without decomposition, we achieve a 90.4% pass rate on miniF2F. With decomposition, this is significantly improved. A key technical contribution lies in our extension of the Kimina Lean Server with abstract syntax tree (AST) parsing capabilities to facilitate automated, recursive proof decomposition. The system is made available on PyPI as goedels-poetry (at https://pypi.org/project/goedels-poetry ), and the open-source implementation KellyJDavis/goedels-poetry (at https://github.com/KellyJDavis/goedels-poetry ) facilitates both adaptation to alternative language models and extension with custom functionality.

</details>


### [39] [Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting](https://arxiv.org/abs/2512.14288)
*Georgios Bouchouras,Dimitrios Doumanas,Andreas Soularidis,Konstantinos Kotis,George A. Vouros*

Main category: cs.AI

TL;DR: 本文研究了LLM在帕金森病监测与警报本体工程中的应用，比较了四种方法：单次提示、思维链提示、X-HCOME和SimX-HCOME+，发现纯LLM方法能生成本体但不全面，而人机协作方法能显著提升本体的完整性和准确性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM在自动化本体开发中的能力极限，特别是能否单独创建全面的帕金森病监测与警报本体，以及人机协作是否能更好地实现这一目标，从而评估LLM在复杂领域本体工程中的有效性。

Method: 采用四种关键方法：1) 单次提示技术：让LLM一次性生成完整本体；2) 思维链提示：引导LLM分步推理生成本体；3) X-HCOME：人机混合本体工程方法；4) SimX-HCOME+：强调持续人类监督和迭代精炼的混合方法。通过比较这些方法评估LLM的自主能力和人机协作效果。

Result: 结果显示：单次提示和思维链提示方法证明LLM能够自主构建帕金森病监测与警报本体，但生成的本体不够全面，需要大量人工精炼；X-HCOME方法显著提升了本体的全面性，生成的本体与专家构建的非常相似；SimX-HCOME+方法通过持续人类监督和迭代精炼，产生了更全面、更准确的本体。

Conclusion: 结论是：LLM单独无法创建全面的本体，但人机协作能显著提升本体工程的质量，特别是在帕金森病等复杂领域。这为未来研究指明了方向，包括开发专门用于本体构建的GPT模型，以及进一步探索人机协作在知识工程中的应用潜力。

Abstract: This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.
  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.
  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.
  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.
  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.

</details>


### [40] [Massive Editing for Large Language Models Based on Dynamic Weight Generation](https://arxiv.org/abs/2512.14395)
*Wentao Wan,Qiqing Lao,Zhiwei Xie,Hefeng Wu,Runnan Lin,Liang Lin,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出MeG方法，通过动态权重神经元和扩散模型实现大语言模型的大规模知识编辑，显著提升了编辑的可靠性、泛化性和局部性指标。


<details>
  <summary>Details</summary>
Motivation: 当前大规模编辑大语言模型时，在保持编辑的可靠性、泛化性和局部性指标方面仍面临挑战，需要一种低成本、高效的编辑方法。

Method: MeG方法在大语言模型的特定层附加动态权重神经元，并使用扩散模型根据输入查询条件生成该神经元的权重，通过添加单个动态权重神经元实现大规模知识编辑。

Result: 实验表明，MeG相比现有知识编辑方法，在大规模知识编辑的可靠性、泛化性和局部性指标上显著提升，特别是局部性指标的绝对百分比提升明显。

Conclusion: MeG方法通过动态权重生成机制，有效解决了大规模知识编辑中的挑战，展示了该方法在知识编辑领域的优势。

Abstract: Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.

</details>


### [41] [Seismology modeling agent: A smart assistant for geophysical researchers](https://arxiv.org/abs/2512.14429)
*Yukun Ren,Siwei Yu,Kai Chen,Jianwei Ma*

Main category: cs.AI

TL;DR: 该论文提出基于大语言模型的智能交互式工作流，用于简化SPECFEM地震波模拟软件的使用，通过MCP服务器将复杂的手动操作转化为可对话执行的工具，降低学习门槛。


<details>
  <summary>Details</summary>
Motivation: 传统SPECFEM软件存在学习曲线陡峭、依赖复杂手动文件编辑和命令行操作的问题，阻碍了研究人员的使用效率和可重复性研究。

Method: 开发了首个SPECFEM的MCP服务器套件，将整个模拟过程分解为离散的、可由智能体执行的工具，涵盖参数生成、网格划分、求解器执行和可视化等环节，支持从文件驱动到意图驱动的对话交互。

Result: 通过多个案例验证，该工作流在自主和交互模式下均能无缝运行，产生与标准基准一致的高保真结果，显著降低了使用门槛并提高了可重复性。

Conclusion: 这是MCP技术在计算地震学中的首次应用，为计算地球物理学向AI辅助和自动化科学研究提供了有前景的途径，源代码已在GitHub开源。

Abstract: To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.

</details>


### [42] [Context-Picker: Dynamic context selection using multi-stage reinforcement learning](https://arxiv.org/abs/2512.14465)
*Siyuan Zhu,Chengdong Xu,Kaiqiang Ke,Chao Yu*

Main category: cs.AI

TL;DR: Context-Picker：一种用于长上下文问答的推理感知框架，将上下文选择从相似性排序转变为最小充分子集选择，通过两阶段强化学习优化决策过程


<details>
  <summary>Details</summary>
Motivation: 在长上下文问答中，确定查询所需的最佳上下文量是一个重要挑战。包含太少段落可能遗漏关键信息，包含太多则可能引入噪声并降低答案质量。传统方法（如固定Top-K检索和单阶段重排序）面临选择适当段落数量的困境，这对于事实性问题尤为突出，因为这类问题通常只需要少量具体证据。

Method: 提出Context-Picker框架，将上下文选择视为决策过程，通过两阶段强化学习优化：1）召回导向阶段，优先覆盖推理链；2）精确导向阶段，积极剪枝冗余以提炼紧凑证据集。为解决奖励稀疏问题，提出离线证据蒸馏管道，通过留一法挖掘"最小充分集"，提供密集、任务对齐的监督。

Result: 在五个长上下文和多跳问答基准测试中，Context-Picker显著优于强大的RAG基线，在可比或减少的上下文长度下实现了更优的答案准确性。消融研究表明，粗到细的优化调度、冗余感知的奖励塑造和推理引导的格式都对性能提升有实质性贡献。

Conclusion: Context-Picker通过将上下文选择重新定义为最小充分子集选择问题，并采用人类启发的两阶段强化学习优化，有效解决了长上下文问答中的上下文量选择难题，在保持或减少上下文长度的同时提高了答案准确性。

Abstract: In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

</details>


### [43] [Dynamic Learning Rate Scheduling based on Loss Changes Leads to Faster Convergence](https://arxiv.org/abs/2512.14527)
*Shreyas Subramanian,Bala Krishnamoorthy,Pranav Murthy*

Main category: cs.AI

TL;DR: 提出了一种基于当前损失自适应调整学习率的新调度器GreedyLR，在多个NLP、CV和LLM任务上表现优于现有调度器，具有理论收敛保证和实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 尽管训练优化器研究取得了显著进展，但大多数研究工作仍使用常见的调度器选择（如余弦或指数衰减）。本文旨在研究一种能够根据当前损失自适应调整学习率的新型调度器，以提升训练效果。

Method: 提出了GreedyLR调度器，该调度器在训练过程中根据当前损失自适应调整学习率。提供了算法的理论分析，包括收敛性证明和最大化收敛速率的最优缩放因子F的推导。

Result: 在多个NLP、CV和LLM任务（包括微调和预训练实验，参数规模高达70亿）上的实验结果表明，该方法在准确性、速度和收敛性方面优于多个最先进的调度器。实验还展示了算法对现实噪声环境的鲁棒性。

Conclusion: GreedyLR调度器易于实现、计算高效，可被视为训练的良好默认调度器选择，为深度学习训练提供了更优的学习率调度方案。

Abstract: Despite significant advances in optimizers for training, most research works use common scheduler choices like Cosine or exponential decay. In this paper, we study \emph{GreedyLR}, a novel scheduler that adaptively adjusts the learning rate during training based on the current loss. To validate the effectiveness of our proposed scheduler, we conduct experiments on several NLP, CV, and LLM tasks with up to $7B$ parameters, including both fine-tuning and pre-training experiments. The results show that our approach outperforms several state-of-the-art schedulers in terms of accuracy, speed, and convergence. We also provide a theoretical analysis of the GreedyLR algorithm, including a proof of convergence and derivation of the optimal scaling factor $F$ that maximizes the convergence rate, along with experiments to show robustness of the algorithm to realistic noisy landscapes. Our scheduler is easy to implement, computationally efficient, and could be considered a good default scheduler for training.

</details>


### [44] [Universal Reasoning Model](https://arxiv.org/abs/2512.14693)
*Zitian Gao,Lynx Chen,Yihao Xiao,He Xing,Ran Tao,Haoming Luo,Joey Zhou,Bryan Dai*

Main category: cs.AI

TL;DR: 研究发现Universal Transformers在复杂推理任务中的性能提升主要来自循环归纳偏置和Transformer的强非线性组件，而非复杂架构设计。基于此提出了Universal Reasoning Model (URM)，在ARC-AGI基准上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: Universal Transformers在ARC-AGI等复杂推理任务中表现出色，但其性能提升的具体来源尚不明确。作者希望通过系统分析UT变体，揭示其成功的关键因素，并基于这些发现设计更高效的推理模型。

Method: 首先系统分析了Universal Transformers的各种变体，发现性能提升主要来自循环归纳偏置和Transformer的强非线性组件。基于这一发现，提出了Universal Reasoning Model (URM)，通过引入短卷积和截断反向传播来增强UT。

Result: URM在ARC-AGI基准上取得了显著提升：在ARC-AGI 1上达到53.8% pass@1，在ARC-AGI 2上达到16.0% pass@1，均实现了state-of-the-art性能。

Conclusion: Universal Transformers在复杂推理任务中的成功主要源于循环归纳偏置和Transformer的非线性能力，而非复杂的架构设计。URM通过简单有效的增强进一步提升了推理性能，为构建高效推理模型提供了新思路。

Abstract: Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.

</details>


### [45] [IPR-1: Interactive Physical Reasoner](https://arxiv.org/abs/2511.15407)
*Mingyu Zhang,Lifeng Zhuo,Tianxi Tan,Guocan Xie,Xian Nie,Yan Li,Renjie Zhao,Zizhu He,Ziyu Wang,Jiting Cai,Yong-Lu Li*

Main category: cs.AI

TL;DR: IPR（交互式物理推理器）通过结合世界模型和视觉语言模型，在1000+异质游戏中学习物理和因果关系，实现超越GPT-5的推理能力，并能零样本迁移到未见游戏。


<details>
  <summary>Details</summary>
Motivation: 人类通过观察、互动和环境交互来学习物理和因果关系。本研究旨在探索智能体是否也能通过类似方式获得类人推理能力，并在更多经验中持续改进。现有方法（如VLMs和世界模型）要么过度关注视觉细节而忽略核心机制，要么缺乏交互环境中的前瞻性推理。

Method: 提出IPR（交互式物理推理器），使用世界模型推演来评分和强化VLM的策略；引入PhysCode（物理中心动作编码），将语义意图与动力学对齐，为预测和推理提供共享动作空间。在1000+游戏上进行预训练。

Result: IPR在从原始直觉到目标驱动推理的各种关卡中表现稳健，整体性能甚至超过GPT-5。性能随着训练游戏数量和交互步骤的增加而提升，并能零样本迁移到未见游戏。

Conclusion: 物理中心的交互学习是实现持续改进物理推理能力的有效路径。该方法展示了通过大规模游戏交互学习物理和因果关系的潜力。

Abstract: Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. To study this, we introduce a Game-to-Unseen (G2U) benchmark of 1,000+ heterogeneous games that exhibit significant visual domain gaps. Existing approaches, including VLMs and world models, struggle to capture underlying physics and causality since they are not focused on core mechanisms and overfit to visual details. VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on levels from primitive intuition to goal-driven reasoning, and even surpasses GPT-5 overall. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning. Further demos and project details can be found at https://mybearyzhang.github.io/ipr-1.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [46] [Electron-positron pair creation induced by multi-pulse train of electric fields: effect of randomness in time-delay](https://arxiv.org/abs/2512.13722)
*Deepak Sah,Manoranjan P. Singh*

Main category: quant-ph

TL;DR: 研究随机时间延迟对Sauter型脉冲序列中电子-正电子对产生的影响，发现适当的时间延迟波动能显著增强中心动量区域的粒子产生率


<details>
  <summary>Details</summary>
Motivation: 探索多脉冲电场配置中随机时间延迟对电子-正电子对产生的影响，为优化实验设计提供理论指导

Method: 通过求解量子Vlasov方程，研究具有高斯分布随机时间延迟的Sauter型脉冲序列，分析标准偏差σ_T对动量谱的影响

Result: 增加σ_T会显著改变纵向动量谱，消除多缝干涉条纹，形成高斯包络；特定σ_T值能大幅增强中心峰值（N=20时，σ_T≈31 m⁻¹增强10倍，σ_T≈50 m⁻¹增强10³倍）

Conclusion: 随机时间延迟能优化多脉冲场配置，显著增强电子-正电子对产生，为未来实验设计提供新思路

Abstract: We investigate the creation of electron-positron pairs (EPPs) in a sequence of alternating-sign, time-dependent electric field pulse trains by solving the quantum Vlasov equations. Specifically, we focus on Sauter-like pulse trains with random time delays between successive pulses, drawn from a Gaussian distribution wherein the extent of fluctuations is controlled by the standard deviation $σ_T$ of the distribution. We find that increasing $σ_T$ leads to a dramatic transformation in the longitudinal momentum spectrum. The well-known fringe pattern, akin to that in the multi-slit interference, gets significantly modified. The averaged spectra exhibit a robust Gaussian-like envelope with residual oscillations, which are much more prominent in the central momentum region. Notably, we find that in certain cases, stochastic time delays lead to a pronounced enhancement in the central peak of the distribution function for pulse train containing $N$ pulses. For example, for $N=20$ pulses, $σ_T \approx 31$ $[m^{-1}]$(about $17\%$ of the mean time delay) yields nearly a tenfold increase in the central peak, which for $σ_T \approx 50$ $[m^{-1}]$ (about $27\%$ of the mean time delay), scales up to $10^3.$ This may open up new possibilities for optimizing multi-pulse field configurations and guide future experimental designs aimed at maximizing EPPs creation.

</details>


### [47] [Quantum simulation using Trotterized disorder Hamiltonians in a single-mode optical cavity](https://arxiv.org/abs/2512.13774)
*Rahel Lea Baumgartner,Pietro Pelliconi,Soumik Bandyopadhyay,Francesca Orsi,Philipp Hauke,Jean-Philippe Brantut,Julian Sonner*

Main category: quant-ph

TL;DR: 该研究提出了一种利用Trotterization方案来增加全相互作用无序多体系统模型无序度的方法，并通过腔QED平台实现了复杂Sachdev-Ye-Kitaev模型，分析了有效耦合分布、量子混沌探针等特征。


<details>
  <summary>Details</summary>
Motivation: 全相互作用无序多体系统在量子平台上难以模拟，因为相互作用通常通过辅助自由度介导，这会降低无序度并引入不期望的相关性。需要一种方法来增加模型的无序度。

Method: 采用Trotterization方案来增加模型的无序度，研究结果模型的统计特性以及影响时间演化和动力学可观测量的Trotterization误差。通过单模腔QED平台实现复杂Sachdev-Ye-Kitaev模型作为具体示例。

Result: 分析了有效模型的多个特征，包括有效耦合的分布、相互作用位点数量、状态准备以及量子混沌探针的行为。通过解析和数值方法详细研究了研究结果对耗散的鲁棒性。

Conclusion: Trotterization方案可以有效增加无序多体系统的无序度，通过腔QED平台实现的复杂SYK模型展示了该方法在量子模拟中的可行性，且研究结果对耗散具有鲁棒性。

Abstract: All-to-all interacting and disordered many-body systems are notoriously hard to simulate on quantum platforms, as interactions are commonly mediated by auxiliary degrees of freedom that lower the amount of disorder, introducing undesired correlations. In this work, we show how a Trotterization scheme can be effectively utilized to densify the disorder of the model. In particular, we study the statistical properties of the resulting model, as well as Trotterization errors in the simulation that affect the time evolution and dynamical observables. As a concrete example, we propose an implementation via a single-mode cavity QED platform of the complex Sachdev-Ye-Kitaev model. We analyze several features of the effective model, such as the distribution of the effective couplings, the number of interacting sites, state preparation, and the behavior of quantum chaos probes. We conclude this work with a detailed investigation of the robustness of our findings against dissipation, both analytically and numerically.

</details>


### [48] [Freeness Reined in by a Single Qubit](https://arxiv.org/abs/2512.13803)
*Alexander Altland,Francisco Divi,Tobias Micklitz,Maedeh Rezaei*

Main category: quant-ph

TL;DR: 研究探索了自由概率理论在量子系统中的应用，发现即使系统与单个辅助量子比特耦合，自由概率预测的相关函数仍会受到O(1)量级的修正，这些修正源于非均匀分布的稳态量子态。


<details>
  <summary>Details</summary>
Motivation: 自由概率理论为描述复杂量子系统中非对易可观测量之间的相关性提供了框架，但需要检验该框架在最小偏离自由条件（如系统与辅助量子比特耦合）下的鲁棒性。

Method: 研究考虑一个维度D0≫1的Haar分布量子电路与单个辅助量子比特耦合的系统，分析自由概率理论预测的相关函数修正，并通过解析分析和数值模拟验证非均匀分布稳态量子态的存在。

Result: 即使在这种最小偏离自由条件的设置下，自由概率理论预测的相关函数仍会受到O(1)量级的修正，这些修正在长时间动力学中持续存在，源于非均匀分布的稳态量子态。

Conclusion: 自由概率理论框架在量子系统中的应用存在局限性，即使很小的系统耦合也会导致显著的相关函数修正，这源于稳态量子态的非均匀分布特性，对理解复杂量子系统的相关性有重要意义。

Abstract: Free probability provides a framework for describing correlations between non-commuting observables in complex quantum systems whose Hilbert-space states follow maximum-entropy distributions. We examine the robustness of this framework under a minimal deviation from freeness: the coupling of a single ancilla qubit to a Haar-distributed quantum circuit of dimension $D0 \gg 1$. We find that, even in this setting, the correlation functions predicted by free probability theory receive corrections of order $O(1)$. These modifications persist at long times, when the dynamics of the coupled system is already ergodic. We trace their origin to non-uniformly distributed stationary quantum states, which we characterize analytically and confirm numerically.

</details>


### [49] [Transversal Clifford-Hierarchy Gates via Non-Abelian Surface Codes](https://arxiv.org/abs/2512.13777)
*Alison Warman,Sakura Schafer-Nameki*

Main category: quant-ph

TL;DR: 该论文提出了一种在2D非阿贝尔表面码中实现任意Clifford层级相位门的纯横向构造方法，突破了Bravyi-König定理的限制。


<details>
  <summary>Details</summary>
Motivation: Bravyi-König定理限制了在D维Pauli稳定子码中通过常数深度量子电路可实现的酉门只能达到Clifford层级的第D层。该研究旨在突破这一限制，在保持局部性和容错性的前提下，在纯2D系统中实现任意层级的Clifford层级相位门。

Method: 使用非阿贝尔群G的量子双D(G)在三角形空间区域上编码逻辑量子比特。通过在空间区域上堆叠由群2-上循环指定的对称保护拓扑（SPT）相来实现横向逻辑门。特别地，对于G = D_{4N}（8N阶二面体群），在逻辑Z基中实现了相位门T^{1/N} = diag(1, e^{iπ/(4N)})。

Result: 成功实现了任意层级的Clifford层级相位门，特别是当8N = 2^n时，该门位于Clifford层级的第n层。该构造具有纯量子比特实现：可以在晶格每条边上使用n个物理量子比特的代码中，用Clifford层级稳定子构造该门。还讨论了到ℤ₂×ℤ₂和ℤ₂环面码的代码切换。

Conclusion: 该研究突破了Bravyi-König定理的限制，在纯2D非阿贝尔表面码中实现了任意Clifford层级的横向相位门，同时保持了局部性和容错性。这为量子计算中的容错逻辑门实现提供了新途径，特别是在高Clifford层级门的实现方面具有重要意义。

Abstract: We present a purely 2D transversal realization of phase gates at any level of the Clifford hierarchy, and beyond, using non-Abelian surface codes. Our construction encodes a logical qubit in the quantum double $D(G)$ of a non-Abelian group $G$ on a triangular spatial patch. The logical gate is implemented transversally by stacking on the spatial region a symmetry-protected topological (SPT) phase specified by a group 2-cocycle. The Bravyi--König theorem limits the unitary gates implementable by constant-depth quantum circuits on Pauli stabilizer codes in $D$ dimensions to the $D$-th level of the Clifford hierarchy. We bypass this, by constructing transversal unitary gates at arbitrary levels of the Clifford hierarchy purely in 2D, without sacrificing locality or fault tolerance, however at the cost of using the quantum double of a non-Abelian group $G$. Specifically, for $G = D_{4N}$, the dihedral group of order $8N$, we realize the phase gate $T^{1/N} = \mathrm{diag}(1, e^{iπ/(4N)})$ in the logical $\overline{Z}$ basis. For $8N = 2^n$, this gate lies at the $n$-th level of the Clifford hierarchy and, importantly, has a qubit-only realization: we show that it can be constructed in terms of Clifford-hierarchy stabilizers for a code with $n$ physical qubits on each edge of the lattice. We also discuss code-switching to the $\mathbb{Z}_2 \times \mathbb{Z}_2$ and $\mathbb{Z}_2$ toric codes, which can be utilized for the quantum error correction in this setup.

</details>


### [50] [Discrete time crystals enabled by Floquet strong Hilbert space fragmentation](https://arxiv.org/abs/2512.14182)
*Ling-Zhi Tang,Xiao Li,Z. D. Wang,Dan-Wei Zhang*

Main category: quant-ph

TL;DR: 该论文研究了无序自由、周期性驱动的XXZ自旋链中的离散时间晶体，通过Floquet强希尔伯特空间碎片化机制稳定时间晶体序，发现了倍周期响应和多重周期响应，并揭示了DTC寿命与系统尺寸的指数增长关系。


<details>
  <summary>Details</summary>
Motivation: 探索无序自由量子系统中离散时间晶体的稳定机制，研究Floquet希尔伯特空间碎片化如何在没有无序的情况下维持非平衡时间序。

Method: 采用周期性驱动的XXZ自旋链模型，通过数值模拟分析Floquet谱特性，使用Floquet谱平均互信息进行有限尺寸标度分析，并结合动力学探针研究时间晶体序的刚性和相区。

Result: 发现了倍周期响应的传统DTC序和多重周期响应的拍频动力学，DTC寿命与驱动频率无关，与ZZ相互作用强度呈幂律关系，且随系统尺寸指数增长，证实了Floquet强碎片化机制。

Conclusion: Floquet希尔伯特空间碎片化是无序自由系统中维持非平凡时间序的有效机制，为理解非平衡量子多体系统中的时间对称性破缺提供了新视角。

Abstract: Discrete time crystals (DTCs) are non-equilibrium phases of matter that break the discrete time-translation symmetry and is characterized by a robust subharmonic response in periodically driven quantum systems. Here, we explore the DTC in a disorder-free, periodically kicked XXZ spin chain, which is stabilized by the Floquet strong Hilbert space fragmentation. We numerically show the period-doubling response of the conventional DTC order, and uncover a multiple-period response with beating dynamics due to the coherent interplay of multiple $π$-pairs in the Floquet spectrum of small-size systems. The lifetime of the DTC order exhibits independence of the driving frequency and a power-law dependence on the ZZ interaction strength. It also grows exponentially with the system size, as a hallmark of the strong fragmentation inherent to the Floquet model. We analytically reveal the approximate conservation of the magnetization and domain-wall number in the Floquet operator for the emergent strong fragmentation, which is consistent with numerical results of the dimensionality ratio of symmetry subspaces. The rigidity and phase regime of the DTC order are identified through finite-size scaling of the Floquet-spectrum-averaged mutual information, as well as via dynamical probes. Our work establishes the Floquet Hilbert space fragmentation as a disorder-free mechanism for sustaining nontrivial temporal orders in out-of-equilibrium quantum many-body systems.

</details>


### [51] [Search Smarter, Not Harder: A Scalable, High-Quality Zoned Neutral Atom Compiler](https://arxiv.org/abs/2512.13790)
*Yannick Stade,Lukas Burgholzer,Robert Wille*

Main category: quant-ph

TL;DR: 提出了一种可扩展的量子编译策略，通过迭代潜水搜索算法和松弛路由优化，解决了中性原子量子计算机大规模编译的内存和效率问题。


<details>
  <summary>Details</summary>
Motivation: 随着分区中性原子架构成为大规模量子计算的有前景平台，其规模增长对高效自动化编译方案提出了关键需求。现有方法无法扩展到这些设备承诺的数千量子比特规模，特别是最先进的编译器存在巨大的内存需求限制，只能处理小规模问题。

Method: 提出了"搜索更智能而非更努力"的可扩展编译策略，引入了迭代潜水搜索算法来避免先前方法的内存问题，以及松弛路由优化来减少原子重排开销。

Result: 该方法能够编译数千量子比特的电路，并且平均减少了28.1%的重排开销。完整代码已在慕尼黑量子工具包中开源。

Conclusion: 该工作为大规模中性原子量子计算机提供了一种可扩展的编译解决方案，通过创新的搜索算法和路由优化，解决了现有编译器的内存限制问题，实现了对数千量子比特电路的高效编译。

Abstract: Zoned neutral atom architectures are emerging as a promising platform for large-scale quantum computing. Their growing scale, however, creates a critical need for efficient and automated compilation solutions. Yet, existing methods fail to scale to the thousands of qubits these devices promise. State-of-the-art compilers, in particular, suffer from immense memory requirements that limit them to small-scale problems. This work proposes a scalable compilation strategy that "searches smarter, not harder". We introduce Iterative Diving Search (IDS), a goal-directed search algorithm that avoids the memory issues of previous methods, and relaxed routing, an optimization to mitigate atom rearrangement overhead. Our evaluation confirms that this approach compiles circuits with thousands of qubits and, in addition, even reduces rearrangement overhead by 28.1% on average. The complete code is publicly available in open-source as part of the Munich Quantum Toolkit (MQT) at https://github.com/munich-quantum-toolkit/qmap.

</details>


### [52] [Universal Statistics of Measurement-Induced Entanglement in Tomonaga-Luttinger liquids](https://arxiv.org/abs/2512.13809)
*Kabir Khanna,Romain Vasseur*

Main category: quant-ph

TL;DR: 研究一维量子临界态中部分测量后测量诱导纠缠的统计特性，使用CFT工具推导MIE累积量的闭式表达式


<details>
  <summary>Details</summary>
Motivation: 研究量子临界态中测量诱导纠缠的统计特性，理解部分测量如何影响量子纠缠的分布

Method: 使用副本技巧对电荷基测量结果进行平均，结合共形场论工具，推导测量诱导纠缠累积量的闭式表达式

Result: 得到所有累积量的临界行为表达式，发现后测量纠缠熵分布通常是双峰的且具有厚尾特征，数值计算验证了理论预测

Conclusion: 微观测量结果的精确玻恩平均在低能下等价于按相应配分函数加权的共形边界条件平均，揭示了测量诱导纠缠的统计特性

Abstract: We study the statistics of measurement-induced entanglement (MIE) after partial measurement on a class of one-dimensional quantum critical states described by Tomonaga-Luttinger liquids at low energies. Using a replica trick to average over measurement outcomes in the charge basis and tools from conformal field theory (CFT), we derive closed-form expressions for the cumulants of MIE. We show that exact Born-averaging over microscopic measurement outcomes becomes equivalent at low energy to averaging over conformal boundary conditions weighted by their corresponding partition functions. Our results yield distinctive critical behavior across all cumulants in the regime where the unmeasured parts of the system are maximally separated. We also obtain the full distribution of the post-measurement entanglement entropy, finding that it is generically bimodal and exhibits fat-tails. We corroborate our analytical predictions by numerical calculations and find good agreement between them.

</details>


### [53] [Fractional decay in the spontaneous emission of a two-level system](https://arxiv.org/abs/2512.13817)
*Hiroki Nakabayashi,Hayato Kinkawa,Takano Taira,Naomichi Hatano*

Main category: quant-ph

TL;DR: 研究发现在具有下界但无上界能谱的环境中，两能级系统自发辐射的存活概率在短时间和长时间区域分别呈现不同的幂律标度行为，这导致了具有不同标度关系的量子芝诺效应。


<details>
  <summary>Details</summary>
Motivation: 研究环境能谱特性（特别是具有下界但无上界）对两能级系统自发辐射动力学的影响，探索量子芝诺效应在不同环境条件下的标度行为变化。

Method: 分析两能级系统与具有特定能谱结构（能量色散关系为|k|^n）的环境相互作用，计算自发辐射的存活概率，研究其在短时间和长时间区域的渐近行为。

Result: 发现存活概率在短时间区域按1-αt^{2-D/n}标度，在长时间区域按αt^{D/n-2}标度，其中D为空间维度，n为环境能量色散指数。这种分数幂标度导致了具有不同标度关系的量子芝诺效应。

Conclusion: 环境能谱的边界条件（有下界无上界）显著影响两能级系统的辐射动力学，导致存活概率呈现分数幂标度行为，并产生具有新标度关系的量子芝诺效应。

Abstract: We find that when the environment of a two-level system has an energy spectrum with a lower bound but without an upper one, the survival probability of the spontaneous emission of the two-level system scales with the spatial dimension $D$ and the exponent $n$ of the energy dispersion $|\vec{k}|^n$ of the environment in the form $1-αt^{2-D/n}$ in the short-time and in the form $αt^{D/n-2}$ in the long-time regime. The former fractional scaling of the survival probability leads to a quantum Zeno effect with a different scaling of the Zeno time.

</details>


### [54] [Reading Qubits with Sequential Weak Measurements: Limits of Information Extraction](https://arxiv.org/abs/2512.14583)
*Cesar Lema,Aleix Bou-Comas,Atithi Acharya,Vadim Oganesyan,Anirvan Sengupta*

Main category: quant-ph

TL;DR: 该论文研究量子比特配置读取中的信息物理，分析两种实际模型下通过弱测量记录提取初始状态信息的最优性能，建立了互信息计算框架并确定了信息提取的界限。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理需要高精度的量子比特配置读取，但实际测量方案和内在动力学可能导致初始状态信息丢失。需要研究弱测量轨迹的信息物理，以确定量子比特配置读取的最优可实现性能。

Method: 研究两种实际单量子比特读取模型：模型I（信息完备但无内在动力学）和模型II（信息不完备弱测量且有内在动力学）。使用互信息量化初始状态信息在测量记录中的编码程度，通过固定离散时间步长公式计算互信息，分析测量强度、测量记录时长和内在动力学相对强度的影响。在弱测量极限下利用连续标度和随机主方程，开发测量效率参数的渐近展开来计算互信息。

Result: 互信息平台的出现表明了信息提取的界限，分析获得了这些界限以及达到饱和所需的最优测量时长。渐近展开计算捕获了数值数据的定性和定量特征。

Conclusion: 该研究结果对量子设备操作和优化以及改进当前NISQ实验体系中量子比特和多量子比特配置读取的机器学习方法性能具有实用价值。

Abstract: Quantum information processing and computation requires high accuracy qubit configuration readout. In many practical schemes, the initial qubit configuration has to be inferred from readout that is a time-dependent weak measurement record. However, a combination of the measurement scheme and intrinsic dynamics can end up scrambling the initial state and lose information irretrievably. Here, we study the information physics of quantum trajectories based on weak measurements in order to address the optimal achievable performance in qubit configuration readout for two realistic models of single qubit readout: (i) Model I is informationally complete, but without intrinsic dynamics; (ii) Model II is informationally incomplete weak measurements with intrinsic dynamics. We first use mutual information to characterize how much intrinsic information about the initial state is encoded in the measurement record. Using a fixed discrete time-step formulation, we compute the mutual information while varying the measurement strength, duration of measurement record, and the relative strength of intrinsic dynamics in our measurement schemes. We also exploit the emergence of continuum scaling and the Stochastic Master Equation in the weak measurement limit. We develop an asymptotic expansion in the measurement efficiency parameter to calculate mutual information, which captures qualitative and quantitative features of the numerical data. The bounds on information extraction are manifested as plateaux in mutual information, our analysis obtains these bounds and also optimal duration of measurement required to saturate them. Our results should be useful both for quantum device operation and optimization and also, possibly, for improving the performance of recent machine learning approaches for qubit and multiqubit configuration readout in current Noisy Intermediate-Scale Quantum (NISQ) experiment regimes.

</details>


### [55] [Microwave-free vector magnetometry and crystal orientation determination with Nitrogen-Vacancy centers using Bayesian inference](https://arxiv.org/abs/2512.13835)
*Hilario Espinós,Omkar Dhungel,Arne Wickenbrock,Dmitry Budker,Ricardo Puebla,Erik Torrontegui*

Main category: quant-ph

TL;DR: 提出基于贝叶斯推断的微波自由矢量磁强计框架，利用NV中心交叉弛豫实现近零场矢量磁场测量，无需微波和严格晶体取向对齐


<details>
  <summary>Details</summary>
Motivation: 传统NV中心磁强计依赖微波，会产生热效应和杂散电磁场干扰样品；现有光学方法需要严格磁场与晶轴对齐，实用性受限

Method: 开发基于贝叶斯推断的通用框架，利用交叉弛豫共振的解析模型，从光致发光图中直接提取磁场矢量和NV取向，适用于任意场和取向配置

Result: 实验证明了稳健的取向确定和矢量场重建能力，为紧凑、无需对齐的实用NV磁强计提供了通用途径

Conclusion: 该框架为实用传感应用中的紧凑、无需对齐NV磁强计建立了通用路线，克服了传统微波方法和严格对齐要求的限制

Abstract: Nitrogen-vacancy (NV) centers in diamond provide a solid-state platform for quantum sensing. While optically detected magnetic resonance techniques offer high sensitivity, their reliance on microwaves introduces heating and stray electromagnetic fields that can perturb nearby samples. Optical approaches based on cross-relaxation between differently oriented NV centers remove this constraint but have so far required stringent alignment of the external field with crystallographic axes, restricting their practicality. Here we introduce a general framework for microwave-free vector magnetometry at near-zero field that leverages Bayesian inference to extract both the magnetic field vector and the NV orientation directly from photoluminescence maps. An analytical model of cross-relaxation resonances enables efficient inference under arbitrary field and orientation configurations, while naturally incorporating the discrete degeneracies of the NV symmetry. We experimentally demonstrate robust orientation determination and vector-field reconstruction, establishing a general route toward compact and alignment-free NV magnetometers for practical sensing applications.

</details>


### [56] [Achieving $10^{-5}$ level relative intensity crosstalk in optical holographic qubit addressing via a double-pass digital micromirror device](https://arxiv.org/abs/2512.13882)
*Shilpa Mahato,Rajibul Islam*

Main category: quant-ph

TL;DR: 该论文提出了一种使用单个数字微镜器件（DMD）的双通配置全光方案，通过结合傅里叶平面全息术和图像平面空间滤波，显著降低量子比特寻址中的串扰和背景噪声。


<details>
  <summary>Details</summary>
Motivation: 全息光束整形在量子比特控制中的应用受到两个主要限制：1）相邻位点的残余强度串扰；2）寻址光束远翼的非零背景噪声，这会导致多个暴露量子比特的累积误差。这些限制影响了量子处理器的性能。

Method: 采用单个数字微镜器件（DMD）的双通配置方案：第一通中，DMD的一个区域置于傅里叶平面，实现用于个体寻址的二进制振幅全息图；第二通中，DMD的另一区域作为可编程中间图像平面孔径进行空间滤波。通过复用傅里叶平面全息图包含次级全息图，生成弱辅助场与不需要的光在选定位置发生相消干涉。

Result: 该方案在整个量子比特寻址相关视场内将相对强度串扰保持在10⁻⁵（-50 dB）或更低水平，并将远离寻址量子比特的远翼背景噪声进一步降低至约10⁻⁶，接近检测极限。

Conclusion: 该研究提供了一种基于DMD的紧凑型低串扰光学全息量子比特寻址解决方案，可直接应用于囚禁离子和其他空间有序量子系统，显著改善了量子比特控制的精度和可靠性。

Abstract: Holographic beam shaping is a powerful approach for generating individually addressable optical spots for controlling atomic qubits, such as those in trapped-ion quantum processors. However, its application in qubit control is limited by residual intensity crosstalk at neighboring sites and by a nonzero background floor in the far wings of the addressing beam, leading to accumulated errors from many exposed qubits. Here, we present an all-optical scheme that mitigates both effects using a single digital micromirror device (DMD) operated in a double-pass configuration, in which light interacts with two separate regions of the same device. In the first pass, one region of the DMD is placed in a Fourier plane and implements a binary-amplitude hologram for individual addressing, while in the second pass a different region serves as a programmable intermediate image-plane aperture for spatial filtering. By multiplexing the Fourier-plane hologram to include secondary holograms, we generate weak auxiliary fields that interfere destructively with unwanted light at selected sites, while image-plane filtering suppresses the residual tail at larger distances. Together, these techniques maintain relative intensity crosstalk at or below $10^{-5}$ ($-50\,\mathrm{dB}$) across the full field of view relevant for qubit addressing, and further reduce the far-wing background to approximately $10^{-6}$ at large distances from the addressed qubit, approaching the detection limit. These results provide a compact, DMD-based solution for low-crosstalk optical holographic qubit addressing that is directly applicable to trapped ions and other spatially ordered quantum systems.

</details>


### [57] [Implementing the Koopman-von Neumann approach on continuous-variable photonic quantum computers](https://arxiv.org/abs/2512.13887)
*Xinfeng Gao,Olivier Pfister,Stefan Bekiranov*

Main category: quant-ph

TL;DR: Koopman-von Neumann (KvN) 形式将经典力学重新表述为类似量子力学的希尔伯特空间框架，使用复波函数和线性算子。该工作探索了在连续变量光子量子计算架构上实现KvN方法，用于模拟经典动力学系统，并通过谐振子和非线性偏微分方程两个问题验证其可行性。


<details>
  <summary>Details</summary>
Motivation: KvN形式为经典力学提供了一种类似量子力学的希尔伯特空间表述，使得经典动力学系统可以通过量子计算进行模拟。这为利用量子算法模拟经典系统提供了一条有前景的路径，特别是对于难以处理的非线性动力学问题。

Method: 采用Koopman-von Neumann形式，将经典力学映射到量子计算框架，在连续变量光子量子计算架构上实现。该方法使用类似薛定谔方程的经典波函数演化，位置和动量算符可对易。通过两个具体问题验证：谐振子和一维非线性偏微分方程。

Result: 展示了在连续变量光子量子计算架构上实现KvN方法的可行性，能够利用量子模拟进行采样和计算难以处理的非线性动力学。通过谐振子和非线性偏微分方程两个案例验证了该方法的实施和有效性。

Conclusion: KvN形式为经典动力学系统的量子模拟提供了有效的框架，特别是在连续变量光子量子计算架构上具有实施可行性。该方法能够处理包括非线性动力学在内的复杂经典系统，为经典到量子的映射开辟了新途径。

Abstract: The Koopman-von Neumann (KvN) formalism recasts classical mechanics in a Hilbert space framework using complex wavefunctions and linear operators, akin to quantum mechanics. Instead of evolving probability densities in phase space (as in Liouville's equation), KvN uses a Schrödinger-like equation for a classical wavefunction, with commuting position and momentum operators. Mapped to quantum computing, KvN offers a promising route to simulate classical dynamical systems using quantum algorithms by leveraging unitary evolution and quantum linear algebra tools, potentially enabling efficient classical-to-quantum mappings without invoking full quantum uncertainty. In this work, we specifically explore the implementation of the KvN approach on continuous-variable photonic quantum computing architectures, with the goals of leveraging quantum simulation for both sampling and computing intractable nonlinear dynamics. We will demonstrate its implementation and feasibility with two problems: the harmonic oscillator and a 1D partial differential equation governing nonlinear dynamics.

</details>


### [58] [Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences](https://arxiv.org/abs/2512.13890)
*Charles Marrder,Shuo Sun,Murray J. Holland*

Main category: quant-ph

TL;DR: 提出基于强化学习的动态解耦脉冲序列设计方法，无需先验噪声谱知识即可最小化量子比特的相位退相干


<details>
  <summary>Details</summary>
Motivation: 传统动态解耦方法需要针对特定噪声机制设计脉冲时序，但在实际噪声谱下难以找到最优时序。现有分析方法仅适用于特定噪声机制，无法处理复杂现实噪声环境

Method: 采用强化学习方法设计量子比特脉冲序列，基于Thompson群F构建新颖的动作集，使智能体能在非凸优化空间中高效搜索。该方法无需噪声谱先验知识，具有模型无关特性

Result: 强化学习智能体能够学习到最小化退相干的脉冲序列，无需了解底层噪声谱。该方法为实时学习最优动态解耦序列提供了可能性

Conclusion: 基于强化学习的动态解耦方法能够处理复杂噪声环境，有望在存在脉冲误差或非高斯噪声等未建模物理效应时仍能学习到最优脉冲序列

Abstract: Dynamical decoupling seeks to mitigate phase decoherence in qubits by applying a carefully designed sequence of effectively instantaneous electromagnetic pulses. Although analytic solutions exist for pulse timings that are optimal under specific noise regimes, identifying the optimal timings for a realistic noise spectrum remains challenging. We propose a reinforcement learning (RL)-based method for designing pulse sequences on qubits. Our novel action set enables the RL agent to efficiently navigate this inherently non-convex optimization landscape. The action set, derived from Thompson's group $F$, is applicable to a broad class of sequential decision problems whose states can be represented as bounded sequences. We demonstrate that our RL agent can learn pulse sequences that minimize dephasing without requiring explicit knowledge of the underlying noise spectrum. This work opens the possibility for real-time learning of optimal dynamical decoupling sequences on qubits which are dephasing-limited. The model-free nature of our algorithm suggests that the agent may ultimately learn optimal pulse sequences even in the presence of unmodeled physical effects, such as pulse errors or non-Gaussian noise.

</details>


### [59] [Quantum Anticodes](https://arxiv.org/abs/2512.13891)
*ChunJun Cao,Giuseppe Cotardo,Brad Lackey*

Main category: quant-ph

TL;DR: 论文提出了一种用于量子纠错码的辛框架，通过反码视角分析局部结构，将代码视为辛空间，反码作为在指定分量上消失的最大辛子空间。


<details>
  <summary>Details</summary>
Motivation: 为量子纠错码提供一个统一的辛几何框架，将经典反码概念自然地扩展到量子领域，以更好地分析和理解量子代码的局部结构特征。

Method: 将量子代码视为辛空间，定义反码为在指定分量上消失的最大辛子空间，建立量子反码理论框架，并扩展广义距离概念。

Result: 该框架统一了多种量子代码家族（包括稳定子码和子系统码），产生了捕获局部代数组合特征的新不变量，并自然导出量子代码的穿孔和缩短操作。

Conclusion: 辛框架为量子纠错码提供了强大的分析工具，能够解释量子纠错中的关键现象（如清洁引理和互补恢复），并为重量枚举器提供新的描述。

Abstract: This work introduces a symplectic framework for quantum error correcting codes in which local structure is analyzed through an anticode perspective. In this setting, a code is treated as a symplectic space, and anticodes arise as maximal symplectic subspaces whose elements vanish on a prescribed set of components, providing a natural quantum analogue of their classical counterparts. This framework encompasses several families of quantum codes, including stabilizer and subsystem codes, provides a natural extension of generalized distances in quantum codes, and yields new invariants that capture local algebraic and combinatorial features. The notion of anticodes also naturally leads to operations such as puncturing and shortening for symplectic codes, which in turn provide algebraic interpretations of key phenomena in quantum error correction, such as the cleaning lemma and complementary recovery and yield new descriptions of weight enumerators.

</details>


### [60] [Integrability Breaking and Coherent Dynamics in Hermitian and Non-Hermitian Spin Chains with Long-Range Coupling](https://arxiv.org/abs/2512.14065)
*Y. S. Liu,X. Z. Zhang*

Main category: quant-ph

TL;DR: 该研究通过引入可调长程跳跃项H_n，探索了一维自旋模型中量子遍历性破缺的机制，发现H_n可作为通用控制参数驱动从可积性到量子混沌的转变，并识别出即使在全局混沌下仍能避免热化的精确非热本征态。


<details>
  <summary>Details</summary>
Motivation: 理解复杂量子系统中遍历性破缺的机制是非平衡物理学的核心追求。本研究旨在探索长程相互作用和非厄米效应如何重塑量子遍历性，为在复杂多体系统中保持量子相干性提供新途径。

Method: 研究采用一维自旋模型，引入可调长程跳跃项H_n，该项引入非局域相互作用并连接厄米和非厄米区域。通过系统分析能级间距统计、Krylov复杂度和纠缠熵，研究H_n作为控制参数的作用。

Result: 增加H_n强度在厄米极限下诱导从泊松统计到高斯正交系综统计的交叉，在非厄米情况下同样触发混沌动力学。尽管出现全局混沌，但识别出一系列精确的非热本征态，这些态作为鲁棒的量子多体疤痕存活，即使在强非厄米扰动下仍保持低纠缠和相干动力学。

Conclusion: 长程和非厄米效应通过通用机制重塑量子遍历性，为在复杂多体系统中保持量子相干性提供了新途径。H_n作为通用控制参数驱动从可积性到量子混沌的转变，同时允许精确的非热本征态在全局混沌中存活。

Abstract: Unraveling the mechanisms of ergodicity breaking in complex quantum systems is a central pursuit in nonequilibrium physics. In this work, we investigate a one-dimensional spin model featuring a tunable long-range hopping term, $H_{n}$, which introduces nonlocal interactions and bridges the gap between Hermitian and non-Hermitian regimes. Through a systematic analysis of level-spacing statistics, Krylov complexity, and entanglement entropy, we demonstrate that $H_{n}$ acts as a universal control parameter driving the transition from integrability to quantum chaos. Specifically, increasing the strength of $H_{n}$ induces a crossover from Poissonian to Gaussian Orthogonal Ensemble statistics in the Hermitian limit, and similarly triggers chaotic dynamics in the non-Hermitian case. Most remarkably, despite the onset of global chaos, we identify a tower of exact nonthermal eigenstates that evade thermalization. These states survive as robust quantum many-body scars, retaining low entanglement and coherent dynamics even under strong non-Hermitian perturbations. Our findings reveal a universal mechanism by which long-range and non-Hermitian effects reshape quantum ergodicity, offering new pathways for preserving quantum coherence in complex many-body systems.

</details>


### [61] [Regulated reconstruction of long-time spin--boson dynamics and emergent zero-bias transverse measurement primitive](https://arxiv.org/abs/2512.13900)
*Dragomir Davidovic*

Main category: quant-ph

TL;DR: 该论文提出了一种调节的时间卷积无(TCL)主方程方法，通过围绕Davies参考半群重构动力学映射来避免长期时间下的发散问题，并应用于自旋-玻色子模型揭示了横向测量原语的涌现。


<details>
  <summary>Details</summary>
Motivation: 传统的时间卷积无(TCL)主方程在长时间尺度上会失效，因为时间局域微扰生成元在相关主导区域会出现长期增长。需要一种方法来缓解这种发散问题，特别是在非马尔可夫干扰效应显著的情况下。

Method: 提出了一种调节的部分重求和重构方法，围绕Davies参考半群重构动力学映射，通过一个在长时间保持有界的非马尔可夫密度矩阵关联函数C(t)来表达。在可精确求解的旋转波基准模型中验证了方法的有效性，并将其应用于无偏自旋-玻色子模型。

Result: 1. 重构方法成功调节了动力学映射，避免了生成元的长期发散；2. 在自旋-玻色子模型中发现了涌现的横向测量原语：浴记忆和反旋转项诱导了相位锁定，在有限时间尺度t_P内不可逆地擦除了σ_x本征空间之间的相对相位；3. 选择的横向基不是先验假设的，而是从重构的约化动力学中自然出现的；4. 该效应在旋转波近似和Davies弱耦合极限中消失，表明其非马尔可夫干扰起源。

Conclusion: 通过调节的重构方法可以避免TCL主方程的长期发散问题，并在自旋-玻色子模型中揭示了非马尔可夫干扰诱导的横向测量原语，为理解开放量子系统中的涌现测量过程提供了新视角。

Abstract: Time--convolutionless (TCL) master equations can break down at long times: time-local perturbative generators develop secular growth in correlation-dominated regimes. We mitigate this by a regulated, partially resummed reconstruction of the dynamical map around a Davies reference semigroup, expressed through a non--Markovian density-matrix correlator C(t) that remains bounded at late times. An exactly solvable rotating-wave benchmark links generator growth to interference-induced near-zeros of the coherence and shows how the reconstruction regulates the map. Applying the method to the unbiased spin--boson model reveals an emergent transverse measurement primitive: bath memory and counter--rotating terms induce phase lock-in that irreversibly erases the relative phase between $σ_x$ eigenspaces on a finite timescale $t_P$, yielding an effective zero-bias transverse ($σ_x$) measurement channel. The selected transverse basis is not assumed a priori; it follows from the reconstructed reduced dynamics. The effect disappears in the rotating-wave approximation and in the Davies weak-coupling limit, demonstrating its non--Markovian interference origin.

</details>


### [62] [Magic state cultivation on a superconducting quantum processor](https://arxiv.org/abs/2512.13908)
*Emma Rosenfeld,Craig Gidney,Gabrielle Roberts,Alexis Morvan,Nathan Lacroix,Dvir Kafri,Jeffrey Marshall,Ming Li,Volodymyr Sivak,Dmitry Abanin,Amira Abbas,Rajeev Acharya,Laleh Aghababaie Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Trond I. Andersen,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Ryan Babbush,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Majid Bigdeli Karimi,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,Michael Broughton,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Zijun Chen,Ben Chiaro,Liang-Ying Chih,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Paul Conner,Harold Cook,Rodrigo G. Cortiñas,William Courtney,Alexander L. Crook,Ben Curtin,Martin Damyanov,Sayan Das,Dripto M. Debroy,Sean Demura,Paul Donohoe,Ilya Drozdov,Andrew Dunsworth,Valerie Ehimhen,Alec Eickbusch,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Lara Faoro,Vinicius S. Ferreira,Marcos Flores,Leslie Flores Burgos,Sam Fontes,Ebrahim Forati,Jeremiah Ford,Brooks Foxen,Masaya Fukami,Alan Wing Lun Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Robert Geiger,Élie Genois,William Giang,Dar Gilboa,James E. Goeders,Edward C. Gonzales,Raja Gosula,Stijn J. de Graaf,Alejandro Grajales Dau,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Loïck Le Guevel,Tan Ha,Steve Habegger,Tanner Hadick,Ali Hadjikhani,Michael C. Hamilton,Monica Hansen,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Jeremy Hilton,Hsin-Yuan Huang,Mike Hucka,Christopher Hudspeth,Ashley Huff,William J. Huggins,Lev B. Ioffe,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Hui Kang,Kiseo Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Tanuj Khattar,Mostafa Khezri,Seon Kim,Paul V. Klimov,Can M. Knaut,Bryce Kobrin,Alexander N. Korotkov,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Emma Leavell,Justin Ledford,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily Li,Wing Yan Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Aditya Locharla,Laura De Lorenzo,Erik Lucero,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Aniket Maiti,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Masih Das,Dmitri Maslov,Melvin Mathews,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Anthony Megrant,Kevin C. Miao,Zlatko K. Minev,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Nicholas Noll,Logan Oas,William D. Oliver,Raymond Orosco,Kristoffer Ottosson,Alice Pagano,Agustin Di Paolo,Sherman Peek,David Peterson,Alex Pizzuto,Elias Portoles,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Ganesh Ramachandran,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Roberto Rodriguez,Emma Ropes,Lucia B. De Rose,Eliott Rosenberg,Dario Rosenstock,Elizabeth Rossi,Pedram Roushan,David A. Rower,Robert Salazar,Kannan Sankaragomathi,Murat Can Sarihan,Max Schaefer,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Noah Shutty,Vladimir Shvarts,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Aaron Szasz,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Benjamin Villalonga,Catherine Vollgraff Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Danni Wang,Brayden Ware,James D. Watson,Yonghua Wei,Travis Weidel,Theodore White,Kristi Wong,Bryan W. K. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Noureldin Yosri,Elliot Young,Grayson Young,Adam Zalcman,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Hartmut Neven,Sergio Boixo,Cody Jones,Julian Kelly,Alexandre Bourassa,Kevin J. Satzinger*

Main category: quant-ph

TL;DR: 该论文实验验证了魔态培育作为容错量子计算中非克利福德门的高效替代方案，在超导量子处理器上实现了40倍错误率降低和0.9999(1)的魔态保真度


<details>
  <summary>Details</summary>
Motivation: 容错量子计算需要通用门集，但非克利福德门在大多数量子纠错架构中代表显著资源成本。魔态培育提供了比资源密集型蒸馏协议更高效的替代方案，但测试该方案的假设需要从量子存储器实验进行重大转变。

Method: 在超导量子处理器上实现魔态培育，包括切换到表面码的代码切换，并开发容错测量协议来界定魔态保真度。

Result: 培育将错误降低了40倍，魔态保真度达到0.9999(1)（保留8%的尝试）。实验结果表明魔态培育是解决量子计算最重要挑战之一的可行方案。

Conclusion: 该研究实验性地确立了魔态培育作为解决量子计算中最重大挑战之一的可行解决方案，为容错量子计算提供了高效的非克利福德门实现途径。

Abstract: Fault-tolerant quantum computing requires a universal gate set, but the necessary non-Clifford gates represent a significant resource cost for most quantum error correction architectures. Magic state cultivation offers an efficient alternative to resource-intensive distillation protocols; however, testing the proposal's assumptions represents a challenging departure from quantum memory experiments. We present an experimental study of magic state cultivation on a superconducting quantum processor. We implement cultivation, including code-switching into a surface code, and develop a fault-tolerant measurement protocol to bound the magic state fidelity. Cultivation reduces the error by a factor of 40, with a state fidelity of 0.9999(1) (retaining 8% of attempts). Our results experimentally establish magic state cultivation as a viable solution to one of quantum computing's most significant challenges.

</details>


### [63] [Q-IRIS: The Evolution of the IRIS Task-Based Runtime to Enable Classical-Quantum Workflows](https://arxiv.org/abs/2512.13931)
*Narasinga Rao Miniskar,Mohammad Alaul Haque Monil,Elaine Wong,Vicente Leyton-Ortega,Jeffrey S. Vetter,Seth R. Johnson,Travis S. Humble*

Main category: quant-ph

TL;DR: 提出一个概念验证的混合执行框架，集成IRIS异步任务运行时和XACC量子编程框架，通过QIR-EE协调经典和量子工作负载在异构系统上的执行。


<details>
  <summary>Details</summary>
Motivation: 新兴HPC系统极端的异构性开始包含量子加速器，需要能够协调经典和量子工作负载的运行时系统。

Method: 集成IRIS异步任务运行时与XACC量子编程框架，通过量子中间表示执行引擎(QIR-EE)，使用量子中间表示(QIR)在异构后端（包括多个量子模拟器）上编排多个程序。

Result: 成功实现了多个量子工作负载的异步调度和执行，通过量子电路切割技术将四量子比特电路分解为更小的子电路，减少了每个任务的量子模拟负载，展示了任务粒度如何提高模拟器吞吐量并减少排队行为。

Conclusion: 概述了扩展混合运行时的关键挑战，包括协调调度、经典-量子交互管理，以及在异构系统中支持多样化后端资源。

Abstract: Extreme heterogeneity in emerging HPC systems are starting to include quantum accelerators, motivating runtimes that can coordinate between classical and quantum workloads. We present a proof-of-concept hybrid execution framework integrating the IRIS asynchronous task-based runtime with the XACC quantum programming framework via the Quantum Intermediate Representation Execution Engine (QIR-EE). IRIS orchestrates multiple programs written in the quantum intermediate representation (QIR) across heterogeneous backends (including multiple quantum simulators), enabling concurrent execution of classical and quantum tasks. Although not a performance study, we report measurable outcomes through the successful asynchronous scheduling and execution of multiple quantum workloads. To illustrate practical runtime implications, we decompose a four-qubit circuit into smaller subcircuits through a process known as quantum circuit cutting, reducing per-task quantum simulation load and demonstrating how task granularity can improve simulator throughput and reduce queueing behavior -- effects directly relevant to early quantum hardware environments. We conclude by outlining key challenges for scaling hybrid runtimes, including coordinated scheduling, classical-quantum interaction management, and support for diverse backend resources in heterogeneous systems.

</details>


### [64] [Coherence-Sensitive Readout Models for Quantum Devices: Beyond the Classical Assignment Matrix](https://arxiv.org/abs/2512.13949)
*Zachariah Malik,Zain Saleem*

Main category: quant-ph

TL;DR: 该论文提出了一个超越经典读取误差模型的通用框架，考虑了量子相干性对测量噪声的影响，引入了相干响应矩阵来量化计算基态之间的干涉效应。


<details>
  <summary>Details</summary>
Motivation: 现有量子设备读取误差模型几乎都假设测量噪声是经典的，即测量统计量通过列随机分配矩阵从理想计算基态布居获得。这种描述假设有效POVM在对角化测量基中，完全无法检测量子相干性。作者希望放松这一假设，建立更通用的模型来捕捉相干读取失真和计算基态之间的干涉效应。

Method: 推导了在任意完全正定保迹噪声后接计算基测量下观测测量概率的完全通用表达式。将理想后电路态表示为布居x和相干y，证明观测概率向量z满足z = A x + C y，其中A是经典分配矩阵，C是从有效POVM在计算基中的非对角矩阵元素构造的相干响应矩阵。

Result: 经典模型z = A x仅在所有POVM元素对角化时成立；相干响应矩阵C量化了关于相干读取失真和计算基态之间干涉的可访问信息，这些在仅保留A的模型中是不可见的。

Conclusion: 该工作为当前和未来量子设备上的相干敏感读取建模提供了一个自然、完全通用的框架，能够捕捉经典模型无法检测的量子相干效应。

Abstract: Readout error models for noisy quantum devices almost universally assume that measurement noise is classical: the measurement statistics are obtained from the ideal computational-basis populations by a column-stochastic assignment matrix $A$. This description is equivalent to assuming that the effective positive-operator-valued measurement (POVM) is diagonal in the measurement basis, and therefore completely insensitive to quantum coherences. We relax this assumption and derive a fully general expression for the observed measurement probabilities under arbitrary completely positive trace-preserving (CPTP) noise preceding a computational-basis measurement. Writing the ideal post-circuit stat $\tildeρ$ in terms of its populations $x$ and coherences $y$, we show that the observed probability vector $z$ satisfies $z = A x + C y$, where $A$ is the familiar classical assignment matrix and $C$ is a coherence-response matrix constructed from the off-diagonal matrix elements of the effective POVM in the computational basis. The classical model $z = A x$ arises if and only if all POVM elements are diagonal; in this sense $C$ quantifies accessible information about coherent readout distortions and interference between computational-basis states, all of which are invisible to models that retain only $A$. This work therefore provides a natural, fully general framework for coherence-sensitive readout modeling on current and future quantum devices.

</details>


### [65] [Frozen Gaussian sampling algorithms for simulating Markovian open quantum systems in the semiclassical regime](https://arxiv.org/abs/2512.14015)
*Limin Xu,Zhen Huang,Zhennan Zhou*

Main category: quant-ph

TL;DR: 提出基于Wigner-Fokker-Planck相空间公式的Frozen Gaussian Sampling算法，用于模拟半经典区域中的马尔可夫开放量子系统，解决了传统网格方法在振荡动力学中的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 模拟半经典区域中的马尔可夫开放量子系统面临巨大计算挑战，传统网格方法由于动力学的高度振荡特性需要极高的分辨率，导致计算成本过高。

Method: 开发了基于Wigner-Fokker-Planck相空间公式的Frozen Gaussian Sampling算法，这是一种无网格采样方法，通过相空间表示来模拟开放量子系统。

Result: 算法具有两个突破性优势：1）物理可观测量计算误差与半经典参数ε无关，打破了网格方法在半经典极限下的计算缩放限制；2）无网格特性消除了边界引起的不稳定性，支持长时间模拟。

Conclusion: FGS算法成为探索开放量子系统长时间行为的强大工具，为强非谐势中稳态存在的理论提供了数值证据，填补了当前缺乏严格解析结果的空白。

Abstract: Simulating Markovian open quantum systems in the semiclassical regime poses a grand challenge for computational physics, as the highly oscillatory nature of the dynamics imposes prohibitive resolution requirements on traditional grid-based methods. To overcome this barrier, this paper introduces an efficient Frozen Gaussian Sampling (FGS) algorithm based on the Wigner-Fokker-Planck phase-space formulation. The proposed algorithm exhibits two transformative advantages. First, for the computation of physical observables, its sampling error is independent of the semiclassical parameter $\varepsilon$, thus fundamentally breaking the prohibitive computational scaling faced by grid methods in the semiclassical limit. Second, its mesh-free nature entirely eliminates the boundary-induced instabilities that constrain long-time grid-based simulations. Leveraging these capabilities, the FGS algorithm serves as a powerful investigatory tool for exploring the long-time behavior of open quantum systems. Specifically, we provide compelling numerical evidence for the existence of steady states in strongly non-harmonic potentials-a regime where rigorous analytical results are currently lacking.

</details>


### [66] [Group Theory and Representation Theory for Identical Particles](https://arxiv.org/abs/2512.14091)
*James Daniel Whitfield*

Main category: quant-ph

TL;DR: 本章节从量子信息科学教材中独立出来，系统介绍了量子模拟、凝聚态物理、量子化学和量子计算交叉领域所需的群论和表示论数学基础，重点阐述了全同粒子的数学描述及其在两种量子化方案中的处理。


<details>
  <summary>Details</summary>
Motivation: 量子技术中最广为人知的应用之一是量子物质的量子模拟，这激发了凝聚态物理、量子化学和量子计算交叉领域的许多有趣问题。由于这些领域共享数学基础，需要系统介绍相关的群论和表示论知识，特别是全同粒子系统的数学描述方法。

Method: 本章节从量子信息科学教材中独立出来，全面开发了全同粒子的数学理论，包括：1）必要的群论和表示论背景；2）全同粒子的数学描述；3）第一量子化和第二量子化方案中全同粒子系统的力学描述。采用数学严谨的教学方法，系统构建理论框架。

Result: 本章节提供了一个完整的数学框架，涵盖了量子模拟、凝聚态物理、量子化学和量子计算交叉研究所需的对称性和表示论基础。特别提供了全同粒子系统在两种量子化方案中的统一数学描述，为相关领域的研究提供了理论基础。

Conclusion: 本章节作为量子信息科学教材的独立章节，系统介绍了量子技术交叉领域所需的数学基础，特别是全同粒子的对称性和表示理论。它超越了简单的旁注，发展成为对全同粒子对称性和表示的完整探索，为读者提供了深入理解量子模拟和相关领域所需的数学工具。

Abstract: Few, if any, applications of quantum technology are as widely known as the quantum simulation of quantum matter. Consequently, many interesting questions have been sparked at the intersection of condensed matter, quantum chemistry, and quantum computing. Given the common mathematical foundation of these subjects, we walk through the necessary group theory and representation theory serving as background in all of these fields. Our discussion will include a full development of the mathematics of identical particles and the mechanics of describing systems of identical particles in both first and second quantization schemes. This chapter is an offshoot of a larger work that provides a graduate-level introduction to quantum information science. This chapter is being released separately because it is not explicitly focused on quantum information. It has grown beyond a short digression into a full-fledged journey into the symmetries and representations of identical particles that we invite you, the reader, to join.

</details>


### [67] [QBism, Polishing Some Points](https://arxiv.org/abs/2512.14122)
*Christopher A. Fuchs,Blake C. Stacey*

Main category: quant-ph

TL;DR: QBism通过三个核心原则重新诠释量子理论：波恩规则是规范性而非描述性规则，所有量子概率都是主观的，量子测量结果是个人经验。这些原则区分了QBism与其他解释，并探讨了量子理论的未来意义。


<details>
  <summary>Details</summary>
Motivation: QBism旨在通过消除量子理论中过于脆弱而无法独立成为本体论的元素，从剩余部分中寻找"本体论教训"。该研究旨在阐明QBism的三个核心原则，并解释其如何区别于其他量子解释。

Method: 通过提出和阐述QBism的三个核心原则：1)波恩规则是规范性陈述而非自然法则；2)所有量子概率都是主观的，包括概率为1的赋值；3)量子测量结果是个人经验。基于这些原则，对比分析QBism与玻尔、埃弗雷特解释、贝尔不等式和维格纳论证的关系。

Result: 论文阐明了QBism如何：1)区别于玻尔对明确语言的关注；2)区别于埃弗雷特多世界解释；3)理解贝尔不等式违反的意义；4)回应维格纳的"暂停动画"论证。这些对比显示了QBism的独特立场。

Conclusion: QBism通过其三个原则提供了一个激进的量子理论解释，强调主观性和规范性而非客观描述性。这种视角不仅影响未来一百年的量子理论发展，也对人类理解现实有更广泛的意义。

Abstract: QBism pursues the real by first eliminating the elements of quantum theory too fragile to be ontologies on their own. Thereafter, it seeks an "ontological lesson" from whatever remains. Here, we explore this program by highlighting three tenets of QBism. First, the Born Rule is a normative statement. It is about the decision-making behavior any individual agent should strive for, not a descriptive "law of nature." Second, all probabilities, including all quantum probabilities, are so subjective they never tell nature what to do. This includes probability-1 assignments. Quantum states thus have no "ontic hold" on the world, which implies a more radical kind of indeterminism in quantum theory than other interpretations understand. Third, quantum measurement outcomes just are personal experiences for the agent gambling upon them. Thus all quantum measurement outcomes are local in the sense of the agent enacting them. Through these tenets, we explain four points better than previously: 1) how QBism contrasts with Bohr's concern over unambiguous language, 2) how QBism contrasts with the Everett interpretation, 3) how QBism understands the meaning of Bell inequality violations, and 4) how QBism responds to Wigner's "suspended animation" argument. Finally, we consider the ontological lesson of the tenets and ask what it might mean for the next one hundred years of quantum theory and humankind more generally.

</details>


### [68] [Quantum Fisher Information Measure in a Strongly Confined Harmonic Paul Trap Lattice System](https://arxiv.org/abs/2512.14155)
*Precious Ogbonda Amadi,Paphon Pewkhom,Pruet Kalasuwan,Norshamsuri Ali,Syed Alwee Aljunid,Rosdisham Endut*

Main category: quant-ph

TL;DR: 该研究通过改变Paul阱中光学晶格的有效势，分析单离子的信息与结构特性，发现Fisher信息、Shannon熵和Fisher-Shannon复杂度能追踪有效势的曲率变化，为量子精密控制提供信息论框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在Paul阱与光学晶格结合的系统中，如何通过控制有效势来调控单离子的信息和结构特性，为量子精密控制提供理论基础。

Method: 将阱频率ω和晶格参数κ作为独立调节参数，分析系统基态（约束最强时）的Fisher信息、Shannon熵和Fisher-Shannon复杂度，追踪有效势曲率ω_eff=ω^2√(1-κ)的变化。

Result: ω和κ扫描实验证实，系统的行为由曲率而非控制参数的选择决定。Fisher信息、Shannon熵和Fisher-Shannon复杂度能有效追踪有效势曲率的变化，表明可以在不改变系统谐波特性的情况下工程化曲率。

Conclusion: ω和κ的相互作用为精密量子控制提供了实用途径，并为探测约束、量子化尺度和信息流提供了信息论框架，使囚禁离子平台在曲率工程方面具有明显优势。

Abstract: In this work, we examine how the informational and structural properties of a single ion respond to controlled changes of the effective potential in a Paul trap modified by an optical lattice. We consider the ground state of the system where confinement is strongest. And by treating the trap frequency $ω$ and lattice $κ$ as independent tunning parameters, we show that Fisher information, Shannon entropy, and Fisher-Shannon complexity track the curvature of the effective potential $ω_{\mathrm{eff}}=ω^2\,\sqrt{1-κ}$. The $ω$ and $κ$ sweeps confirm that curvature and not the choice of control parameter determines the behaviour of the system. This gives the trapped-ion platform a clear advantage that the curvature can be engineered without altering the harmonic characteristics of the system. The interplay between $ω$ and $κ$ thus provides a practical route for precision quantum control and offers Information-theoretic framework for experiments that probe confinement, quantization scale, and information flow in engineered ion traps.

</details>


### [69] [High-Order Harmonic Generation with Beyond-Semiclassical Emitter Dynamics: A Strong-Field Quantum Optical Heisenberg Picture Approach](https://arxiv.org/abs/2512.14174)
*Christian Saugbjerg Lange,Ella Elisabeth Lassen,Rasmus Vesterager Gothelf,Lars Bojer Madsen*

Main category: quant-ph

TL;DR: 该研究在Heisenberg绘景中开发了精确可控的微扰展开方法，用于描述强场过程中的量子光学效应，特别关注高次谐波生成，揭示了量子涨落对发射光非经典特性的影响。


<details>
  <summary>Details</summary>
Motivation: 近年来量子光学描述强场过程受到广泛关注，但现有理论主要在Schrödinger绘景中建模，需要近似处理，而Heisenberg绘景相对未被充分探索。需要开发更精确的理论框架来描述量子电磁场耦合效应。

Method: 在Heisenberg绘景中开发了精确可控的微扰展开方法，推导了超越半经典的修正项，考虑了量子电磁场的量子涨落效应，特别应用于高次谐波生成过程。

Result: 该方法在现有实验参数范围内准确，给出了关键观测量的闭式表达式；发现压缩程度随发射体数量增加而增加，而光子统计在多发射体极限下趋近经典泊松分布；超越半经典的发射体动力学显著增强了发射光的压缩程度。

Conclusion: 该工作推进了对量子光学高次谐波生成的理论理解，引入了可访问且良好控制的框架来描述真实实验，为研究量子涨落对强场过程的影响提供了新工具。

Abstract: Quantum-optical descriptions of strong-field processes have attracted significant attention in recent years. Typically, the theoretical modeling has been conducted in the Schrödinger picture, where results are only obtainable under certain approximations, while, in contrast, the Heisenberg picture has remained relatively unexplored. In this work, we develop an accurately controlled perturbative expansion of the time-evolution operator in the Heisenberg picture and derive beyond-semiclassical corrections to the emitter dynamics due to the coupling to the quantized electromagnetic field, capturing effects of the quantum fluctuations present in the latter. We focus on high-order harmonic generation (HHG), where the approach is accurate in parameter regimes of current interest and it gives closed-form expressions for key observables. This formulation not only simplifies numerical calculations compared to the Schrödinger-picture approach but also provides a clear correspondence between nonclassical features of the emitted light and the underlying induced dynamics of the generating medium including quantum fluctuations. Moreover, the Heisenberg framework naturally yields scaling relations with the number of independent emitters, enabling us to assess whether nonclassical behavior should persist under typical experimental conditions involving large emitter ensembles. Interestingly, we find that the degree of squeezing increases with the number of emitters, whereas the photon statistics approaches a classical Poissonian distribution in the many-emitter limit. We also find that the beyond-semiclassical emitter dynamics significantly enhances the degree of squeezing of the emitted light. Our work advances the theoretical understanding of quantum-optical HHG and introduces an accessible and well-controlled framework to describe realistic experiments.

</details>


### [70] [Information-efficient decoding of surface codes](https://arxiv.org/abs/2512.14255)
*Long D. H. My,Shao-Hen Chiew,Jing Hao Chai,Hui Khoon Ng*

Main category: quant-ph

TL;DR: 表面码中实时解码需要大量通信，本文提出两种使用缩减综合征信息的解码器，将通信需求从面积缩放降至宽度缩放。


<details>
  <summary>Details</summary>
Motivation: 表面码是实现容错量子计算的重要途径，但在执行逻辑T门时需要进行实时解码，这要求量子处理单元和经典处理器之间有高速通信。这种通信需求可能难以满足，同时还要保持量子处理器的质量。

Method: 提出了两种解码器，它们利用缩减的综合征信息量，所需的综合征比特数仅随表面码补丁的宽度缩放，而不是通常的面积缩放。

Result: 这些解码器能够显著减轻实时解码所需的通信需求，使通信速率要求更容易实现。

Conclusion: 通过使用仅随宽度缩放的缩减综合征信息，本文提出的解码器缓解了表面码中实时解码的通信瓶颈问题，有助于实现更实用的容错量子计算架构。

Abstract: Surface codes are a popular error-correction route to fault-tolerant quantum computation. The so-called exponential backlog problem that can arise when one has to do logical $T$-gates within the surface code demands real-time decoding of the syndrome information to diagnose the appropriate Pauli frame in which to do the gate. This in turn puts a minimum requirement on the communication rate between the quantum processing unit, where the syndrome information is collected, and the classical processor, where the decoding algorithm is run. This minimum communication rate can be difficult to achieve while preserving the quality of the quantum processor. Here, we present two decoders that make use of a reduced syndrome information volume, relying on a number of syndrome bits that scale only as the width -- and not the usual area -- of the surface-code patch. This eases the communication requirements necessary for real-time decoding.

</details>


### [71] [Engineering Anisotropic Rabi Model in Circuit QED](https://arxiv.org/abs/2512.14276)
*S. Mojtaba Tabatabaei,Babak Zare Rameshti,Mohsen Akbari*

Main category: quant-ph

TL;DR: 该研究实现了各向异性拉比模型的电路QED实现，通过同时耦合量子比特到谐振器的电压和电流波腹，实现了从纯JC到纯AJC相互作用的几何调谐，为量子信息处理提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 各向异性拉比模型（ARM）具有可调的Jaynes-Cummings（JC）和anti-Jaynes-Cummings（AJC）相互作用，但完全实现一直具有挑战性。需要建立一个能够静态控制ARM参数并探索其完整参数空间的平台。

Method: 采用电路QED实现，通过同时耦合量子比特到谐振器的电压和电流波腹，实现对ARM参数的几何调谐。这种方法允许从纯JC相互作用到纯AJC相互作用的连续控制。

Result: 成功实现了对ARM参数的静态控制，能够几何调谐相互作用从纯JC到纯AJC。这种控制实现了新颖的量子测量能力，包括色散位移消除和Purcell抑制读取。

Conclusion: 该工作建立了一个直接平台，用于探索ARM的完整参数空间及其在量子信息处理中的应用，为量子测量和量子计算提供了新的可能性。

Abstract: The anisotropic Rabi model (ARM), which features tunable Jaynes-Cummings (JC) and anti-Jaynes-Cummings (AJC) interactions, has remained challenging to realize fully. We present a circuit QED implementation that provides static control over the ARM parameters. By simultaneously coupling a qubit to a resonator's voltage and current antinodes, we geometrically tune the interaction from pure JC to pure AJC. This control enables novel quantum measurement capabilities, including dispersive shift cancellation and Purcell-suppressed readout. Our work establishes a direct platform for exploring the ARM's full parameter space and its applications in quantum information processing.

</details>


### [72] [Universal Structure of Nonlocal Operators for Deterministic Navigation and Geometric Locking](https://arxiv.org/abs/2512.14302)
*Jia Bao,Bin Guo,Shu Qu,Fanqin Xu,Zhaoyu Sun*

Main category: quant-ph

TL;DR: 提出一个通用几何框架，将寻找最优非局域算子的组合黑箱问题转化为确定性预测-验证操作，发现非局域性主特征值由仅两个基本角度参数化的低维流形严格决定，并揭示量子临界性中的几何临界性与几何锁定二分法。


<details>
  <summary>Details</summary>
Motivation: 传统寻找最优非局域算子的方法通常是组合黑箱搜索，缺乏系统性和可预测性。本文旨在建立几何框架，将这一过程系统化，揭示量子临界性中的基本结构模式。

Method: 建立通用几何框架，将非局域算子优化问题转化为由两个基本角度θ和φ参数化的低维流形上的确定性预测-验证操作。通过分析几何角度与主特征值谱（包括幅度、敏感性和非局域间隙）的对比关系，揭示量子临界性的结构特征。

Result: 发现非局域性主特征值由仅两个基本角度参数化的低维流形严格决定，其对称性进一步简化了问题。揭示了量子临界性中的基本二分法：涉及对称扇区旋转的转变表现为几何临界性（算子剧烈重定向），而强各向异性主导的转变表现为几何锁定（最优基保持稳健）。

Conclusion: 该几何框架为量子相变提供了新的结构分类，并为贝尔实验提供了精确导航图，将非局域算子优化从组合黑箱转化为系统化的几何预测-验证过程。

Abstract: We establish a universal geometric framework that transforms the search for optimal nonlocal operators from a combinatorial black box into a deterministic predict-verify operation. We discover that the principal eigenvalue governing nonlocality is rigorously dictated by a low-dimensional manifold parameterized by merely two fundamental angular variables, $θ$ and $φ$, whose symmetry leads to further simplification. This geometric distillation establishes a precise mapping connecting external control parameters directly to optimal measurement configurations. Crucially, a comparative analysis of the geometric angles against the principal eigenvalue spectrum, including its magnitude, susceptibility, and nonlocal gap, reveals a fundamental dichotomy in quantum criticality. While transitions involving symmetry sector rotation manifest as geometric criticality with drastic operator reorientation, transitions dominated by strong anisotropy exhibit geometric locking, where the optimal basis remains robust despite clear signatures of phase transitions in the spectral indicators. This distinction offers a novel structural classification of quantum phase transitions and provides a precision navigation chart for Bell experiments.

</details>


### [73] [Steering Alternative Realities through Local Quantum Memory Operations](https://arxiv.org/abs/2512.14377)
*Xiongfeng Ma*

Main category: quant-ph

TL;DR: 本文提出"现实转向"协议，允许观察者概率性地访问量子态中已存在的不同现实，通过局部擦除观察者大脑中的"哪个结果"信息实现，但存在固有约束且操作上无法区分。


<details>
  <summary>Details</summary>
Motivation: 量子测量将叠加态坍缩为确定结果，与观察者记忆建立关联。虽然全局量子态保持相干，但观察者的局部现实变得单一确定。本研究旨在探索观察者能否访问量子态中已存在的其他现实，将多现实探索从哲学思辨转向具体量子信息框架。

Method: 引入"现实转向"协议，通过局部擦除观察者大脑中存储的"哪个结果"信息，使观察者能够概率性地访问初始量子态中已支持的不同现实。该方法仅限于观察者记忆的局部操作，不涉及环境（可能宇宙尺度）。

Result: 现实转向面临固有约束：成功导航需要相关分支中观察者对应体的相干参与；任何转向在操作上都无法与未转向区分；转向后所有记忆记录与新现实完全一致，没有内部证据表明发生了转向。标准量子力学框架内无法实现可验证的转向。

Conclusion: 现实转向将多现实探索从哲学思辨转向具体量子信息框架，但标准量子力学内存在根本约束。非线性操作原则上可能实现可验证的、有意识的导航。转向后所有记忆与新现实一致，使得意识确认在标准理论内不可能。

Abstract: Quantum measurement resolves a superposition into a definite outcome by correlating it with an observer's memory -- a reality register. While the global quantum state remains coherent, the observer's local reality becomes singular and definite. This work introduces reality steering, a protocol that allows an observer to probabilistically access a different reality already supported by the initial quantum state, without reversing decoherence on the environment. The mechanism relies on locally erasing the 'which-outcome' information stored in the observer's brain. Here, 'local' means operations confined to the observer's memory, excluding the environment, which may be cosmically large. Reality steering nevertheless faces intrinsic constraints: successful navigation requires coherent participation from the observer's counterparts across the relevant branches, and any transition is operationally indistinguishable from non-transition. After arriving in a new reality, all memory records are perfectly consistent with that reality, leaving no internal evidence that a switch occurred. This makes conscious confirmation impossible within standard quantum mechanics. We show that nonlinear operations beyond the standard theory could, in principle, enable verifiable and deliberate navigation. Our results shift multi-reality exploration from philosophical speculation toward a concrete -- though fundamentally constrained -- quantum-informational framework.

</details>


### [74] [Geometric quantum thermodynamics: A fibre bundle approach](https://arxiv.org/abs/2512.14383)
*T. Pernambuco,L. C. Céleri*

Main category: quant-ph

TL;DR: 该论文探讨量子热力学的几何结构，通过构建主纤维丛将热力学表达为与基础物理理论相同的几何语言。


<details>
  <summary>Details</summary>
Motivation: 经典热力学基于粗粒化理论，而量子力学中对微观系统的高度控制使信息理论在描述量子系统热性质中起重要作用。最近提出的量子热力学规范理论中，冗余信息概念源于称为热力学群的规范变换，需要探索其几何结构。

Method: 通过显式构建相关的主纤维丛来探索量子热力学的几何结构，展示与量子热力学规范理论相关的两个不同（但相关）的几何结构。

Result: 成功构建了量子热力学的主纤维丛几何结构，将热力学表达为与基础物理理论相同的数学（几何）语言，并识别出两个相关的几何结构。

Conclusion: 量子热力学的几何和拓扑性质可能有助于解释热力学的基本性质，为理解热力学提供了新的几何框架。

Abstract: Classical thermodynamics is a theory based on coarse-graining, meaning that the thermodynamic variables arise from discarding information related to the microscopic features of the system at hand. In quantum mechanics, however, where one has a high degree of control over microscopic systems, information theory plays an important role in describing the thermal properties of quantum systems. Recently, a new approach has been proposed in the form of a quantum thermodynamic gauge theory, where the notion of redundant information arises from a group of physically motivated gauge transformations called the thermodynamic group. In this work, we explore the geometrical structure of quantum thermodynamics. Particularly, we do so by explicitly constructing the relevant principal fibre bundle. We then show that there are two distinct (albeit related) geometric structures associated with the gauge theory of quantum thermodynamics. In this way, we express thermodynamics in the same mathematical (geometric) language as the fundamental theories of physics. Finally, we discuss how the geometric and topological properties of these structures may help explain fundamental properties of thermodynamics.

</details>


### [75] [Ground State Energy via Adiabatic Evolution and Phase Measurement for a Molecular Hamiltonian on an Ion-Trap Quantum Computer](https://arxiv.org/abs/2512.14415)
*Ludwig Nützel,Michael J. Hartmann,Henrik Dreyer,Etienne Granet*

Main category: quant-ph

TL;DR: 该论文研究了量子计算机上分子基态能量估计，发现泄漏误差是影响化学精度的主要障碍，而相干和不相干噪声影响较小。


<details>
  <summary>Details</summary>
Motivation: 量子计算在分子基态能量估计中具有重要应用，但硬件噪声对实验的影响需要深入理解，以区分不同影响的误差类型并指导硬件和算法改进。

Method: 在离子阱量子计算机上运行状态制备和能量测量协议，使用绝热状态制备方法准备H3+分子的六量子比特编码基态，并采用噪声鲁棒的迭代量子相位估计变体提取能量。

Result: 实验结果超越了经典Hartree-Fock能量。分析表明，相干和不相干噪声影响很小，但泄漏误差是主要障碍。无泄漏误差的模拟显示，即使包含散粒噪声，也能接近化学精度。

Conclusion: 泄漏误差是量子化学计算中实现化学精度的主要障碍，未来算法和硬件开发应重点针对泄漏抑制进行优化。

Abstract: Estimating molecular ground-state energies is a central application of quantum computing, requiring both the preparation of accurate quantum states and efficient energy readout. Understanding the effect of hardware noise on these experiments is crucial to distinguish errors that have low impact, errors that can be mitigated, and errors that must be reduced at the hardware level. We ran a state preparation and energy measurement protocol on an ion-trap quantum computer, without any non-scalable off-loading of computational tasks to classical computers, and show that leakage errors are the main obstacle to chemical accuracy. More specifically, we apply adiabatic state preparation to prepare the ground state of a six-qubit encoding of the H3+ molecule and extract its energy using a noise-resilient variant of iterative quantum phase estimation. Our results improve upon the classical Hartree-Fock energy. Analyzing the effect of hardware noise on the result, we find that while coherent and incoherent noise have little influence, the hardware results are mainly impacted by leakage errors. Absent leakage errors, noisy numerical simulations show that with our experimental settings we would have achieved close to chemical accuracy, even shot noise included. These insights highlight the importance of targeting leakage suppression in future algorithm and hardware development.

</details>


### [76] [Adiabatic-Inspired Hybrid Quantum-Classical Methods for Molecular Ground State Preparation](https://arxiv.org/abs/2512.14449)
*Sean Thrasher,Ioannis Kolotouros,Julien Michel,Petros Wallden*

Main category: quant-ph

TL;DR: 本文提出了一种新的混合量子算法G-AQC-PQC，它结合了绝热启发初始化与低内存BFGS优化器，在铍氢分子基准测试中优于传统VQE方法。


<details>
  <summary>Details</summary>
Motivation: 量子计算在解决量子化学问题方面具有潜力，但现有方法存在局限：VQE因能量景观非凸和贫瘠高原问题而收敛困难，AQC需要深度电路超出当前量子设备能力。需要开发适合近量子设备的绝热启发算法。

Method: 首先建立绝热启发算法的统一框架，并基准测试AAVQE、VAQC和AQC-PQC方法。然后提出新的混合方法G-AQC-PQC，它推广了AQC-PQC方法，结合绝热启发初始化和低内存BFGS优化器，降低量子计算成本。最后使用铍氢分子比较不同方法在各种参数选择下的性能。

Result: G-AQC-PQC在铍氢分子基准测试中优于传统VQE方法。研究还讨论了零梯度问题等限制，并确定了绝热启发方法在近量子化学应用中具有实际优势的机制。

Conclusion: G-AQC-PQC作为一种新的混合量子算法，通过结合绝热启发初始化和高效优化器，在降低量子计算成本的同时提高了性能，为近量子化学应用提供了有前景的解决方案。

Abstract: Quantum computing promises to efficiently and accurately solve many important problems in quantum chemistry which elude classical solvers, such as the electronic structure problem of highly correlated materials. Two leading methods in solving the ground state problem are the Variational Quantum Eigensolver (VQE) and Adiabatic Quantum Computing (AQC) algorithms. VQE often struggles with convergence due to the energy landscape being highly non-convex and the existence of barren plateaux, and implementing AQC is beyond the capabilities of current quantum devices as it requires deep circuits. Adiabatically-inspired algorithms aim to fill this gap. In this paper, we first present a unifying framework for these algorithms and then benchmark the following methods: the Adiabatically Assisted VQE (AAVQE) (Garcia-Saez and Latorre (2018)), the Variational Adiabatic Quantum Computing (VAQC) (Harwood et al (2022)), and the Adiabatic Quantum Computing with Parametrized Quantum Circuits (AQC-PQC) (Kolotouros et al (2025)) algorithms. Second, we introduce a novel hybrid approach termed G-AQC-PQC, which generalizes the AQC-PQC method, and combines adiabatic-inspired initialization with the low-memory BFGS optimizer, reducing the quantum computational cost of the method. Third, we compare the accuracy of the methods for chemistry applications using the beryllium hydride molecule (BeH$_2$). We compare the approaches across a number of different choices (ansätze types, depth, discretization steps, initial Hamiltonian, adiabatic schedules and method used). Our results show that the G-AQC-PQC outperforms conventional VQE. We further discuss limitations such as the zero-gradient problem and identify regimes where adiabatically-inspired methods offer a tangible advantage for near-term quantum chemistry applications.

</details>


### [77] [Super-Heisenberg-limited Sensing via Collective Subradiance in Waveguide QED](https://arxiv.org/abs/2512.14463)
*Xin Wang,Zeyang Liao*

Main category: quant-ph

TL;DR: 该研究探索了亚波长间距发射体阵列耦合到一维纳米光子波导中的量子计量潜力，发现偶极-偶极相互作用产生超窄亚辐射共振，其衰减率按N^{-3}标度，量子费希尔信息按N^6标度，可用于高精度传感。


<details>
  <summary>Details</summary>
Motivation: 探索亚波长间距发射体阵列在纳米光子波导中的量子计量潜力，利用偶极-偶极相互作用产生的超窄亚辐射共振来实现高精度传感。

Method: 通过有效非厄米哈密顿量的本征模分析，推导最亚辐射态衰减率的普适标度律；分析单光子散射谱；计算量子费希尔信息；评估实际位置无序下的鲁棒性。

Result: 最亚辐射态衰减率呈现N^{-3}标度，在深亚波长区域具有奇偶振荡行为；量子费希尔信息按N^6标度增长；通过测量最亚辐射共振最陡斜率处的谱移可接近该极限；增强效应在实际位置无序下保持鲁棒。

Conclusion: 偶极-偶极工程化的亚辐射为量子计量提供了可行资源，将多体波导量子电动力学与高精度传感联系起来，为集成纳米光子平台上的可扩展量子传感器开辟了道路。

Abstract: We explore the quantum-metrological potential of subwavelength-spaced emitter arrays coupled to a one-dimensional nanophotonic waveguide. In this system, strong dipole--dipole interactions profoundly modify the collective optical response, leading to the emergence of ultranarrow subradiant resonances. Through an eigenmode analysis of the effective non-Hermitian Hamiltonian, we derive a universal scaling law for the decay rate of the most subradiant state, which exhibits an $ N^{-3} $ scaling with even-odd oscillatory behavior in the deep-subwavelength regime. This scaling is directly observable in the single-photon scattering spectrum, enabling the detection of minute changes in atomic separation with a figure of merit that scales as $ N^3 $. The quantum Fisher information (QFI) scales as $N^6$ and can be closely approached by measuring spectral shifts near the steepest slope of the most subradiant resonance. These enhancements remain robust under realistic positional disorder, confirming that dipole--dipole-engineered subradiance provides a viable resource for quantum metrology. Our work bridges many-body waveguide quantum electrodynamics and high-precision sensing, opening a route toward scalable quantum sensors on integrated nanophotonic platforms.

</details>


### [78] [Nonlocal contributions to ergotropy: A thermodynamic perspective](https://arxiv.org/abs/2512.14497)
*B. Vigneshwar,R. Sankaranarayanan*

Main category: quant-ph

TL;DR: 该论文提出了一个量化非局域性对可提取功贡献的指标，并建立了非相互作用哈密顿量下功与关联的直接关系


<details>
  <summary>Details</summary>
Motivation: 非局域性是量子力学的核心特征，但非局域性对可提取功的贡献尚未明确量化，这是量子热力学中的一个关键问题

Method: 引入了一个量化二分系统中非局域性对可提取功贡献的指标，该指标可以用施密特系数计算闭式表达式，并针对非相互作用哈密顿量建立了功与关联的直接关系

Result: 对于严格非相互作用的哈密顿量，非局域资源总是增强可提取功；而在存在相互作用的情况下，非局域性的贡献可能增加或减少，具体取决于态和哈密顿量的结构

Conclusion: 该研究为量化非局域性在量子热力学中的作用提供了新工具，揭示了非局域资源对可提取功的复杂影响机制

Abstract: Nonlocality is a defining feature of quantum mechanics and has long served as a key indicator of quantum resources since the formulation of Bell's inequalities. Identifying the contribution of nonlocality to extractable work remains a central problem in quantum thermodynamics. We address this by introducing a quantifier of nonlocal contributions to extractable work in bipartite systems. It is shown that closed form expressions can be calculated for our quantity in terms of the Schmidt coefficients. Further for strictly non-interacting Hamiltonian, the direct relationship between ergotropy and correlations is established. Our results reveal that nonlocal resources invariably enhance extractable work under non-interacting Hamiltonians, while in the presence of interactions, their contribution can either increase or diminish depending on the structure of the state and the Hamiltonian.

</details>


### [79] [Large circuit execution for NMR spectroscopy simulation on NISQ quantum hardware](https://arxiv.org/abs/2512.14513)
*Artemiy Burov,Julien Baglio,Clément Javerzac-Galy*

Main category: quant-ph

TL;DR: 该研究利用量子计算模拟一维核磁共振光谱，通过先进误差抑制技术处理34个自旋系统，超越了经典模拟的极限


<details>
  <summary>Details</summary>
Motivation: 随着量子计算从NISQ时代向量子效用时代过渡，需要解决传统经典方法难以处理的问题。一维核磁共振光谱模拟是分子结构分析的重要工具，但传统方法在处理大自旋系统时面临计算极限

Method: 结合Q-CTRL的误差缓解和误差抑制技术，使用IBM的超导量子计算机和IonQ的离子阱量子计算机，对高达34个自旋的系统进行量子哈密顿模拟

Result: 通过噪声抑制将均方误差降低了22倍，成功执行了深度量子电路，获得了16、22和34自旋系统的1D NMR光谱关键特征，突破了32自旋的李乌维尔极限

Conclusion: 该工作展示了在NMR光谱学中实现近期量子效用的重要一步，为量子计算在化学和材料科学中的应用开辟了新途径

Abstract: With the latest advances in quantum computing technology, we are gradually moving from the noisy intermediate-scale quantum (NISQ) era characterized by hardware limited in the number of qubits and plagued with quantum noise, to the age of quantum utility where both the newest hardware and software methods allow for tackling problems which have been deemed difficult or intractable with conventional classical methods. One of these difficult problems is the simulation of one-dimensional (1D) nuclear magnetic resonance (NMR) spectra, a major tool to learn about the structure of molecules, helping the design of new materials or drugs. Using advanced error mitigation and error suppression techniques from Q-CTRL together with the latest commercially available superconducting-qubit quantum computer from IBM and trapped-ion quantum computer from IonQ, we present the quantum Hamiltonian simulation of liquid-state 1D NMR spectra in the high-field regime for spin systems up to 34 spins. Our pipeline has a major impact on the ability to execute deep quantum circuits with the reduction of quantum noise, improving mean square error by a factor of 22. It allows for the execution of deep quantum circuits and obtaining salient features of the 1D NMR spectra for both 16-spin and 22-spin systems, as well as a 34-spin system, which lies beyond the regime where unrestricted full Liouvillespace simulations are practical (32 spins, the Liouville limit). Our work is a step toward near-term quantum utility in NMR spectroscopy.

</details>


### [80] [Finite-Time Protocols Stabilize Charging in Noisy Ising Quantum Batteries](https://arxiv.org/abs/2512.14521)
*Riccardo Grazi,Henrik Johannesson,Dario Ferraro,Niccolò Traverso Ziani*

Main category: quant-ph

TL;DR: 研究探讨了横向场伊辛链作为量子电池的充电协议，重点关注有限充电时间和相互作用对充电过程的影响，以及噪声对充电性能的双重作用。


<details>
  <summary>Details</summary>
Motivation: 可靠的充电协议对于推动量子电池走向实际应用至关重要。传统突然充电协议和非相互作用电池存在局限性，需要研究有限充电时间和相互作用如何改善充电过程。

Method: 使用横向场伊辛链作为量子电池模型，研究有限充电时间下的充电协议，分析相互作用对充电过程的影响。引入随机噪声，研究不同充电轨迹对噪声响应的依赖性。

Result: 1. 有限时间斜坡充电比突然充电协议更平滑可控；2. 噪声对充电性能的影响取决于充电轨迹：弱激发系统的协议在噪声下获得能量但损失可提取功，而强激发多模式的协议则相反，噪声减少存储能量但提高效率（ergotropy与存储能量之比）。

Conclusion: 有限时间斜坡充电能稳定量子电池充电过程，噪声对量子电池性能的影响具有双重性：既能阻碍也能增强性能，具体取决于所采用的充电协议类型。

Abstract: Reliable charging protocols are crucial for advancing quantum batteries toward practical use. We investigate a transverse-field Ising chain as a quantum battery, focusing on the combined role of qubit interactions in the battery model and finite charging time. This interplay yields smoother and more controllable charging compared to sudden protocols or non-interacting batteries. Introducing stochastic noise reveals a strong dependence on the charging trajectory. Protocols that weakly excite the system gain energy under noise but lose extractable work. In contrast, protocols that strongly excite many modes show the opposite trend: noise reduces stored energy yet improves efficiency, defined as the ratio of ergotropy to stored energy. These findings demonstrate that finite-time ramps stabilize charging and highlight that noise can either hinder or enhance quantum-battery performance depending on the protocol.

</details>


### [81] [Continuous Accumulation of Cold Atoms in an Optical Cavity](https://arxiv.org/abs/2512.14528)
*Edward Gheorghita,Sebastian Wald,Andrea Pupić,Onur Hosten*

Main category: quant-ph

TL;DR: 该论文展示了一种在浅层腔内偶极阱中连续积累亚多普勒冷却原子的方法，实现了持续运行的原子-光界面，为稳态量子传感器和量子处理器奠定基础。


<details>
  <summary>Details</summary>
Motivation: 持续运行的原子-光界面是实现稳态量子传感器和高效量子处理器的关键前提条件。传统方法通常需要时序操作，限制了系统的连续运行能力。

Method: 通过光频移操纵创建空间变化的冷却参数，使原子能够高效捕获并积累在腔模内。使用铷原子，从源池连续通量通过磁光阱进入腔模，在腔内冷却并维持在10μK以下，无需时序操作。

Result: 成功实现了数百万原子的连续维持集合体，并表征了其与腔场的集体耦合。原子在稳态下保持在10μK以下，建立了持续运行的腔QED系统。

Conclusion: 该方法为持续运行的腔QED系统和长时原子及混合量子传感器开辟了新途径，实现了真正的连续操作原子-光界面。

Abstract: Continuously operating atom-light interfaces represent a key prerequisite for steady-state quantum sensors and efficient quantum processors. Here, we demonstrate continuous accumulation of sub-Doppler-cooled atoms in a shallow intracavity dipole trap, realizing this regime. The key ingredient is a light-shift manipulation that creates spatially varying cooling parameters, enabling efficient capture and accumulation of atoms within a cavity mode. Demonstrated with rubidium atoms, a continuous flux from a source cell is funneled through the magneto-optical trap into the cavity mode, where the atoms are cooled and maintained below $10~μ\text{K}$ in steady state without time-sequenced operation. We characterize the resulting continuously maintained ensemble of millions of atoms and its collective coupling to the cavity field, establishing a route toward continuously operated cavity-QED systems and long-duration atomic and hybrid quantum sensors.

</details>


### [82] [Fair sampling of ground-state configurations using hybrid quantum-classical MCMC algorithms](https://arxiv.org/abs/2512.14552)
*Yuichiro Nakano,Keisuke Fujii*

Main category: quant-ph

TL;DR: 混合量子-经典MCMC算法能纠正量子优化启发式算法的采样偏差，在组合优化问题的简并基态上实现公平采样


<details>
  <summary>Details</summary>
Motivation: 量子优化启发式算法（如量子退火和QAOA）在组合优化问题的简并基态采样中存在偏差，需要开发能够实现公平采样的方法

Method: 提出混合量子-经典MCMC算法，将量子动力学仅作为提议转移，通过经典接受步骤强制详细平衡，结合QAOA辅助的神经提议和单自旋翻转更新

Result: 对于小型伊辛模型，MCMC后处理纠正了量子动力学采样偏差；在随机2-SAT问题中达到与PT-ICM相当的公平性；在随机3-SAT问题中仍能实现近似均匀采样；所需转移次数与WalkSAT相当

Conclusion: 混合量子-经典MCMC为公平采样和解决方案枚举提供了一个可行框架，特别适用于经典方法不再适用的复杂问题

Abstract: We study the fair sampling properties of hybrid quantum-classical Markov chain Monte Carlo (MCMC) algorithms for combinatorial optimization problems with degenerate ground states. While quantum optimization heuristics such as quantum annealing and the quantum approximate optimization algorithm (QAOA) are known to induce biased sampling, hybrid quantum-classical MCMC incorporates quantum dynamics only as a proposal transition and enforces detailed balance through classical acceptance steps. Using small Ising models, we show that MCMC post-processing corrects the sampling bias of quantum dynamics and restores near-uniform sampling over degenerate ground states. We then apply the method to random $k$-SAT problems near the satisfiability threshold. For random 2-SAT, a hybrid MCMC combining QAOA-assisted neural proposals with single spin-flip updates achieves fairness comparable to that of PT-ICM. For random 3-SAT, where such classical methods are no longer applicable, the hybrid MCMC still attains approximately uniform sampling. We also examine solution counting and find that the required number of transitions is comparable to that of WalkSAT. These results indicate that hybrid quantum-classical MCMC provides a viable framework for fair sampling and solution enumeration.

</details>


### [83] [Entanglement measure for the W-class states](https://arxiv.org/abs/2512.14566)
*Reza Hamzehofi*

Main category: quant-ph

TL;DR: 研究W类态在物理变换下的纠缠结构和量化，建立全局可分性与两体纠缠行为的联系，提出新的纠缠度量方法


<details>
  <summary>Details</summary>
Motivation: 研究W类态在物理变换下的纠缠特性，解决现有纠缠度量方法（如π-tangle）在系统规模增大时失效的问题，建立更有效的纠缠量化框架

Method: 建立全局可分性与两体纠缠行为的严格条件，引入两体纠缠和作为W类态的自然纠缠度量，提出π-tangle和作为改进的纠缠度量方法

Result: 证明两体纠缠的缺失足以保证系统的完全可分性（在希尔伯特空间基保持不变条件下），发现π-tangle在n-qubit W态的大n极限下失效，而π-tangle和能有效量化纠缠

Conclusion: 两体纠缠和是W类态的自然有效纠缠度量，π-tangle和在系统规模增大时仍能有效量化纠缠，为纠缠度量提供了新的条件和物理意义明确的度量方法

Abstract: The structure and quantification of entanglement in the W-class states are investigated under physically motivated transformations that induce mixed-state dynamics. A rigorous condition is established linking global separability to the behavior of pairwise entanglement, showing that the absence of pairwise entanglement is sufficient to guarantee complete separability of the system, provided the Hilbert-space basis is preserved. This result motivates the identification of the sum of two-tangles as a natural and effective entanglement quantifier for the W-class states. Furthermore, the commonly used $π$-tangle becomes ineffective for the maximally entangled $n$-qubit W state as the system size increases, vanishing in the large-$n$ limit. To address this limitation, the sum of $π$-tangles is introduced, which, like the sum of two-tangles, successfully quantifies the entanglement of the maximally entangled $n$-qubit W state in the large-$n$ limit. In addition, a new condition for entanglement measures is introduced, which facilitates the formulation of a well-behaved and physically meaningful entanglement measure.

</details>


### [84] [Exploiting Reset Operations in Cloud-based Quantum Computers to Run Quantum Circuits for Free](https://arxiv.org/abs/2512.14582)
*Jakub Szefer*

Main category: quant-ph

TL;DR: 该论文首次系统研究了如何利用云量子计算机的重置操作免费运行量子电路，形成对云量子计算经济模型的新型攻击。通过将多个用户电路用重置操作分隔并作为一个大电路提交，可以在单次运行中执行多个电路，从而大幅降低运行成本。


<details>
  <summary>Details</summary>
Motivation: 主要动机是揭示云量子计算按次收费定价模式中的安全漏洞。当前所有主要量子计算公司都通过云服务提供硬件访问，用户按电路运行次数（shots）付费。由于量子计算机的噪声特性，电路需要多次运行以收集输出统计。论文旨在探索如何利用最近实现的中电路量子比特测量和重置操作来绕过这种收费模式。

Method: 通过将多个用户电路用重置操作分隔，并将所有电路和重置操作作为一个更大的电路提交。这样用户虽然只支付单次运行费用，但实际上在单次运行中执行了多个电路。该方法在真实的云量子计算机上进行了评估验证。

Result: 研究显示，使用该方法可以将某些电路的总运行成本降低高达900%，导致量子计算公司遭受重大财务损失。通过实验验证了这种攻击在真实云量子计算机上的可行性。

Conclusion: 论文提出了一种清晰的收费方法来解决这一新发现的安全问题，同时保持中电路测量和重置操作的灵活性和可用性。需要重新设计云量子计算的收费模型以防止这种经济攻击。

Abstract: This work presents the first thorough exploration of how reset operations in cloud-based quantum computers could be exploited to run quantum circuits for free. This forms a new type of attack on the economics of cloud-based quantum computers. All major quantum computing companies today offer access to their hardware through some type of cloud-based service. Due to the noisy nature of quantum computers, a quantum circuit is run many times to collect the output statistics, and each run is called a shot. The fees users pay for access to the machines typically depend on the number of these shots of a quantum circuit that are executed. Per-shot pricing is a clean and straightforward approach as users are charged a small fee for each shot of their circuit. This work demonstrates that per-shot pricing can be exploited to get circuits to run for free when users abuse recently implemented mid-circuit qubit measurement and reset operations. Through evaluation on real, cloud-based quantum computers this work shows how multiple circuits can be executed together within a shot, by separating each user circuit by set of reset operations and submitting all the circuits, and reset operations, as one larger circuit. As a result, the user is charged per-shot pricing, even though inside each shot are multiple circuits. Total per-shot cost to run certain circuits could be reduced by up to $900$\% using methods proposed in this work, leading to significant financial losses to quantum computing companies. To address this novel finding, this work proposes a clear approach for how users should be charged for their execution, while maintaining the flexibility and usability of the mid-circuit measurement and reset~operations.

</details>


### [85] [Sequential realization of Quantum Instruments](https://arxiv.org/abs/2512.14588)
*Soham Sau,Michal Sedlák*

Main category: quant-ph

TL;DR: 该论文研究了自适应量子电路中通过中间测量结果决定后续门操作的技术，提出了自适应仪器序列（ASI）的数学框架，并分析了实现量子仪器所需的步骤数N和辅助比特数n_A之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 自适应量子电路通过中间测量结果动态调整后续量子门操作，这允许实现POVM、量子信道和量子仪器等更复杂的量子操作。然而，这种技术需要更少的量子比特资源，但步骤数和辅助比特数之间存在权衡关系，需要理论分析这种权衡的优化边界。

Method: 论文提出了自适应仪器序列（ASI）的数学框架来描述自适应量子电路。通过ASI分解量子仪器，分析了实现任意量子仪器所需的步骤数N和辅助比特数n_A之间的关系。特别研究了乘积N·n_A的下界，并确定了在哪些情况下这种权衡是最优的。

Result: 论文证明了N·n_A乘积的可实现下界，并发现了一个反直觉的结果：对于将n个量子比特转换为m(>n)个量子比特的量子仪器，存在N步ASI实现，仅需要(m-n)个辅助比特，这些比特被重复测量(N-1)次，最后作为输出比特使用。

Conclusion: 自适应仪器序列为量子仪器的实现提供了系统的数学框架，揭示了步骤数和辅助比特数之间的基本权衡关系。特别地，对于扩展量子比特数的仪器，可以通过重复测量少量辅助比特来实现，这为量子计算中的资源优化提供了新的理论见解。

Abstract: In adaptive quantum circuits classical results of mid-circuit measurements determine the upcoming gates. This allows POVMs, quantum channels or more generally quantum instruments to be implemented sequentially, so that fewer qubits need to be used at each of the $N$ measurement steps. In this paper, we mathematically describe these problems via adaptive sequence of instruments (ASI) and show how any instrument can be decomposed into it. Number of steps $N$ and number of ancillary qubits $n_A$ needed for actual implementation are crucial parameters of any such ASI. We show an achievable lower bound on the product $N.n_A$ and we determine in which situations this tradeoff is likely to be optimal. Contrary to common intuition we show that for quantum instruments which transform $n$ to $m(>n)$ qubits, there exist $N$-step ASI implementing them just with $(m-n)$ ancillary qubits, which are remeasured $(N-1)$ times and finally used as output qubits.

</details>


### [86] [Improved Lower Bounds for QAC0](https://arxiv.org/abs/2512.14643)
*Malvika Raj Joshi,Avishay Tal,Francisca Vasconcelos,John Wright*

Main category: quant-ph

TL;DR: 该论文建立了针对QAC⁰电路的最强下界：深度3电路无法计算奇偶校验，深度2电路无法近似高影响布尔函数，深度2电路无法精确合成nekomata态。


<details>
  <summary>Details</summary>
Motivation: 研究量子电路QAC⁰（允许多项式数量的辅助比特和门）的计算能力限制，特别是与经典AC⁰电路的对比，探索常数深度量子电路是否比经典电路更强大。

Method: 开发新技术将某些QAC⁰电路在AC⁰中经典模拟，获得深度3下界；放松量子电路输出要求为单比特（无输入保持/可逆计算限制），使深度2近似下界更强；分析nekomata态的合成能力。

Result: 1) 深度3 QAC⁰电路无论规模多大都无法计算奇偶校验，计算多数函数需要至少Ω(exp(√n))个门；2) 深度2电路无法以不可忽略的优势近似高影响布尔函数；3) 深度2电路无法精确合成n-目标nekomata态。

Conclusion: 对于本质上是经典决策问题的情况，常数深度量子电路不一定比经典对应物更强大；深度2经典AC⁰电路可以用指数规模精确计算奇偶校验，但深度2 QAC⁰电路即使近似也无法做到。

Abstract: In this work, we establish the strongest known lower bounds against QAC$^0$, while allowing its full power of polynomially many ancillae and gates. Our two main results show that:
  (1) Depth 3 QAC$^0$ circuits cannot compute PARITY regardless of size, and require at least $Ω(\exp(\sqrt{n}))$ many gates to compute MAJORITY.
  (2) Depth 2 circuits cannot approximate high-influence Boolean functions (e.g., PARITY) with non-negligible advantage in depth $2$, regardless of size.
  We present new techniques for simulating certain QAC$^0$ circuits classically in AC$^0$ to obtain our depth $3$ lower bounds. In these results, we relax the output requirement of the quantum circuit to a single bit (i.e., no restrictions on input preservation/reversible computation), making our depth $2$ approximation bound stronger than the previous best bound of Rosenthal (2021). This also enables us to draw natural comparisons with classical AC$^0$ circuits, which can compute PARITY exactly in depth $2$ using exponential size. Our proof techniques further suggest that, for inherently classical decision problems, constant-depth quantum circuits do not necessarily provide more power than their classical counterparts. Our third result shows that depth $2$ QAC$^0$ circuits, regardless of size, cannot exactly synthesize an $n$-target nekomata state (a state whose synthesis is directly related to the computation of PARITY). This complements the depth $2$ exponential size upper bound of Rosenthal (2021) for approximating nekomatas (which is used as a sub-circuit in the only known constant depth PARITY upper bound).

</details>


### [87] [Testing electron-photon exchange-correlation functional performance for many-electron systems under weak and strong light-matter coupling](https://arxiv.org/abs/2512.14655)
*Iman Ahmadabadi,I-Te Lu,Leonardo A. Cunha,Michael Ruggenthaler,Johannes Flick,Angel Rubio*

Main category: quant-ph

TL;DR: 提出了一种基于局域密度近似的无光子交换关联泛函（pxcLDA），用于量子电动力学密度泛函理论，能够有效描述从弱到强光-物质耦合下的多电子系统电子密度。


<details>
  <summary>Details</summary>
Motivation: 现有的QEDFT方法在处理多电子系统时面临挑战，需要发展一种能够有效描述从弱到强光-物质耦合的实用泛函方法，以便将QEDFT应用于实际电子系统。

Method: 基于先前工作，通过简单程序计算描述电子-光子关联和弱耦合区域非均匀性的重整化因子，并与量子电动力学耦合簇方法及先前QEDFT优化有效势方法进行比较。

Result: 在各种原子和分子系统中，pxcLDA能够准确再现腔修饰密度，与参考方法结果高度一致。重整化因子随系统尺寸或集体耦合增加而趋近于1，反映了电子-光子交换主导行为，且对较大系统精度更高。

Conclusion: 该方法为基于电子密度的QEDFT泛函应用于实际电子系统提供了实用途径，能够有效处理从弱到强的光-物质耦合。

Abstract: We present results of a photon-free exchange-correlation functional within the local density approximation (pxcLDA) for quantum electrodynamics density functional theory (QEDFT) that efficiently describes the electron density of many-electron systems across weak to strong light-matter coupling. Building on previous work [I-Te. Lu et al., Phys. Rev. A 109, 052823 (2024)] that captured electron-photon correlations via an exchange-correlation functional derived from the nonrelativistic Pauli-Fierz Hamiltonian and tested on one-electron systems, we use a simple procedure to compute a renormalization factor describing electron-photon correlations and inhomogeneity in the weak-coupling regime by comparing it with quantum electrodynamics coupled-cluster, and previous QEDFT optimized effective potential methods. Across various atoms and molecules, pxcLDA reproduces cavity-modified densities in close agreement with these references. The renormalization factor approaches unity as the system size or collective coupling increases, reflecting an electron-photon exchange-dominated behavior and improved accuracy for larger systems. This approach now offers a practical route to applying QEDFT functionals based on electron density to realistic electron systems.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [88] [Quantum-Inspired Approach to Analyzing Complex System Dynamics](https://arxiv.org/abs/2512.14169)
*Parsa Kafashi,Mozhgan Orujlu*

Main category: nlin.CD

TL;DR: 提出基于量子信息理论的多元时间序列分析框架，将系统状态编码为密度矩阵，捕捉高阶相关性和依赖关系，用于量化时间序列间相对影响、追踪外部扰动响应、定义恢复时间尺度，无需降维。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列分析方法主要关注成对统计关系，难以捕捉复杂系统中的高阶相关性和依赖关系。需要一种能够全面表征高维动态系统中复杂相互作用的框架，特别是在分析系统恢复力、相似性和对外部扰动的响应方面。

Method: 将系统状态编码为密度矩阵，利用量子信息理论工具（如保真度）分析多元时间序列。该方法无需降维，能够自然捕捉超越成对统计的高阶共波动。通过密度矩阵表示提供系统状态的紧凑表征。

Result: 在9维改进Lorenz-96模型生成的合成数据上验证了方法的有效性。应用于真实气候数据，分析了9个区域的全球温度异常，量化了截至2025年7月的每个288个月时间窗口相对于1850-1874基准期的差异度。

Conclusion: 该量子信息启发的框架为分析复杂系统提供了新工具，能够全面表征高维动态中的恢复力和相似性，超越了传统成对统计方法的局限性，在气候科学等复杂系统分析中具有应用潜力。

Abstract: We present a quantum information-inspired framework for analyzing complex systems through multivariate time series. In this approach the system's state is encoded into a density matrix, providing a compact representation of higher-order correlations and dependencies. This formulation enables precise quantification of the relative influence among time series, tracking of their response to external perturbations and also the definition of a recovery timescale without need for dimensional reduction. By leveraging tools such as fidelity from quantum information theory, our method naturally captures higher-order co-fluctuations beyond pairwise statistics, offering a holistic characterization of resilience and similarity in high-dimensional dynamics. We validate this approach on synthetic data generated by a 9-dimensional modified Lorenz-96 model and demonstrate its utility on real-world climate data, analyzing global temperature anomalies across nine regions, quantifying the dissimilarity of each 288-month time window up to July 2025 relative to the 1850-1874 baseline period.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [89] [Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training](https://arxiv.org/abs/2512.13706)
*John Graham Reynolds*

Main category: cs.LG

TL;DR: 研究发现在大语言模型微调数学推理任务时会出现灾难性遗忘问题，提出混合训练策略能完全消除遗忘同时保持数学性能


<details>
  <summary>Details</summary>
Motivation: 当微调大语言模型进行数学推理等专门任务时，模型会出现灾难性遗忘，失去先前学习的能力。研究者希望探索如何在保持数学性能的同时避免遗忘通用能力

Method: 在Flan-T5-Base模型上微调DeepMind Mathematics数据集，测量在MultiNLI上的遗忘程度。提出混合训练策略，在训练过程中交错使用数学和NLI示例，系统探索从1:1到15:1的不同混合比例

Result: 纯数学训练将数学准确率从3.1%提升到12.0%，但导致NLI准确率从81.0%崩溃到16.5%（下降64.5个百分点）。混合训练完全消除了灾难性遗忘：1:1比例达到12.0%数学准确率（与纯数学训练相当）同时保持86.2%的NLI准确率。即使最小NLI暴露（6.2%）也能提供有效正则化

Conclusion: 专业化不一定需要遗忘通用能力，混合训练策略能完全消除灾难性遗忘同时保持专门任务性能。这对扩展到更大模型具有重要意义，混合训练可能带来超越遗忘预防的额外好处

Abstract: When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMind Mathematics dataset and measuring forgetting on MultiNLI. Math-only training improves mathematical accuracy from 3.1\% to 12.0\% but causes NLI accuracy to collapse from 81.0\% to 16.5\%--a 64.5 percentage point drop occurring within the first 1,000 training steps. We propose mixed training strategies that interleave mathematical and NLI examples during training. Our results demonstrate that mixed training completely eliminates catastrophic forgetting while maintaining equivalent mathematical performance: the balanced 1:1 ratio achieves 12.0\% math accuracy (matching math-only) while preserving 86.2\% NLI accuracy. We systematically explore mixing ratios from 1:1 to 15:1, finding that even minimal NLI exposure (6.2\%) provides effective regularization. These findings demonstrate that specialization need not require forgetting general capabilities, with implications for scaling to larger models where mixed training may confer additional benefits beyond forgetting prevention.

</details>


### [90] [Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables](https://arxiv.org/abs/2512.13710)
*Edwin Oluoch Awino,Denis Machanda*

Main category: cs.LG

TL;DR: 该研究结合SAR影像与环境水文数据，使用机器学习方法对肯尼亚Nyando河流域进行洪水易发性建模，发现随机森林模型表现最佳，识别出维多利亚湖附近的Kano平原为最高风险区。


<details>
  <summary>Details</summary>
Motivation: 洪水是全球最具破坏性的自然灾害之一，对生态系统、基础设施和人类生计构成严重威胁。在数据有限的地区，需要开发有效的洪水易发性评估方法，以支持灾害风险管理和土地利用规划。

Method: 研究结合Sentinel-1双极化SAR影像（2024年5月洪水事件）和环境水文数据，使用SAR数据生成二进制洪水清单作为训练数据。整合六个条件因子（坡度、高程、坡向、土地利用/土地覆盖、土壤类型、距河流距离），训练四种监督分类器：逻辑回归、分类回归树、支持向量机和随机森林。

Result: 随机森林模型表现最佳（准确率=0.762；Kappa系数=0.480），优于其他三种模型。基于RF的易发性地图显示，维多利亚湖附近的低洼Kano平原具有最高的洪水脆弱性，这与历史洪水记录和2024年5月洪水事件的影响一致。

Conclusion: 研究表明，在数据有限地区，结合SAR数据和集成机器学习方法进行洪水易发性制图具有重要价值。生成的易发性地图为灾害风险减少、土地利用规划和早期预警系统开发提供了重要见解。

Abstract: Flooding is one of the most destructive natural hazards worldwide, posing serious risks to ecosystems, infrastructure, and human livelihoods. This study combines Synthetic Aperture Radar (SAR) imagery with environmental and hydrological data to model flood susceptibility in the River Nyando watershed, western Kenya. Sentinel-1 dual-polarization SAR data from the May 2024 flood event were processed to produce a binary flood inventory, which served as training data for machine learning (ML) models. Six conditioning factors -- slope, elevation, aspect, land use/land cover, soil type, and distance from streams -- were integrated with the SAR-derived flood inventory to train four supervised classifiers: Logistic Regression (LR), Classification and Regression Trees (CART), Support Vector Machines (SVM), and Random Forest (RF). Model performance was assessed using accuracy, Cohen's Kappa, and Receiver Operating Characteristic (ROC) analysis. Results indicate that RF achieved the highest predictive performance (accuracy = 0.762; Kappa = 0.480), outperforming LR, CART, and SVM. The RF-based susceptibility map showed that low-lying Kano Plains near Lake Victoria have the highest flood vulnerability, consistent with historical flood records and the impacts of the May 2024 event. These findings demonstrate the value of combining SAR data and ensemble ML methods for flood susceptibility mapping in regions with limited data. The resulting maps offer important insights for disaster risk reduction, land-use planning, and early warning system development.

</details>


### [91] [Delete and Retain: Efficient Unlearning for Document Classification](https://arxiv.org/abs/2512.13711)
*Aadya Goel,Mayuri Sridhar*

Main category: cs.LG

TL;DR: 提出Hessian Reassignment方法用于文档分类模型的类别级遗忘，通过Hessian向量系统和Top-1分类保证，在保持准确性的同时显著提升遗忘效率


<details>
  <summary>Details</summary>
Motivation: 机器学习遗忘旨在高效移除特定训练数据对模型的影响，避免完全重新训练。虽然LLM遗忘已有进展，但文档分类模型的遗忘研究相对不足，特别是类别级遗忘问题

Method: 提出两阶段模型无关的Hessian Reassignment方法：1）通过共轭梯度法求解Hessian向量系统，执行单次影响式更新，减去目标类别所有训练点的影响；2）通过Top-1分类强制执行决策空间保证，而非随机重新分类删除类别样本

Result: 在标准文本基准测试中，Hessian Reassignment在保持接近完整重新训练（不含目标类别）准确性的同时，运行速度提升数个数量级。同时，通过池化多影子攻击测量，该方法持续降低移除类别的成员推断优势

Conclusion: Hessian Reassignment为文档分类中的高效类别遗忘提供了一条实用且原理明确的技术路径，在保持性能的同时显著提升效率

Abstract: Machine unlearning aims to efficiently remove the influence of specific training data from a model without full retraining. While much progress has been made in unlearning for LLMs, document classification models remain relatively understudied. In this paper, we study class-level unlearning for document classifiers and present Hessian Reassignment, a two-step, model-agnostic solution. First, we perform a single influence-style update that subtracts the contribution of all training points from the target class by solving a Hessian-vector system with conjugate gradients, requiring only gradient and Hessian-vector products. Second, in contrast to common unlearning baselines that randomly reclassify deleted-class samples, we enforce a decision-space guarantee via Top-1 classification. On standard text benchmarks, Hessian Reassignment achieves retained-class accuracy close to full retrain-without-class while running orders of magnitude faster. Additionally, it consistently lowers membership-inference advantage on the removed class, measured with pooled multi-shadow attacks. These results demonstrate a practical, principled path to efficient class unlearning in document classification.

</details>


### [92] [Prediction of Respiratory Syncytial Virus-Associated Hospitalizations Using Machine Learning Models Based on Environmental Data](https://arxiv.org/abs/2512.13712)
*Eric Guo*

Main category: cs.LG

TL;DR: 该研究开发了一个机器学习框架，通过整合废水监测、气象和空气质量数据来预测美国RSV相关住院情况，发现废水RSV水平是最强预测因子，并揭示了特定人群和地区的风险差异。


<details>
  <summary>Details</summary>
Motivation: 呼吸道合胞病毒（RSV）是导致幼儿住院的主要原因，其爆发受环境条件强烈影响。当前需要更好的预测工具来指导公共卫生干预和资源分配。

Method: 整合每周住院率、废水RSV水平、每日气象测量和空气污染物浓度数据，使用CART、随机森林和Boosting等分类模型预测RSV相关住院风险等级（低风险、警报、流行）。

Result: 废水RSV水平是最强预测因子，其次是温度、臭氧水平和比湿度等气象和空气质量变量。研究发现美洲原住民和阿拉斯加原住民的RSV住院率显著更高，高海拔地区（表面压力较低）的住院率也持续较高。

Conclusion: 结合环境和社区监测数据可有效预测RSV爆发，为及时公共卫生干预提供支持。研究开发了交互式R Shiny仪表板，便于用户探索各州RSV风险水平、可视化关键预测因子影响并生成爆发预测。

Abstract: Respiratory syncytial virus (RSV) is a leading cause of hospitalization among young children, with outbreaks strongly influenced by environmental conditions. This study developed a machine learning framework to predict RSV-associated hospitalizations in the United States (U.S.) by integrating wastewater surveillance, meteorological, and air quality data. The dataset combined weekly hospitalization rates, wastewater RSV levels, daily meteorological measurements, and air pollutant concentrations. Classification models, including CART, Random Forest, and Boosting, were trained to predict weekly RSV-associated hospitalization rates classified as \textit{Low risk}, \textit{Alert}, and \textit{Epidemic} levels. The wastewater RSV level was identified as the strongest predictor, followed by meteorological and air quality variables such as temperature, ozone levels, and specific humidity. Notably, the analysis also revealed significantly higher RSV-associated hospitalization rates among Native Americans and Alaska Natives. Further research is needed to better understand the drivers of RSV disparity in these communities to improve prevention strategies. Furthermore, states at high altitudes, characterized by lower surface pressure, showed consistently higher RSV-associated hospitalization rates. These findings highlight the value of combining environmental and community surveillance data to forecast RSV outbreaks, enabling more timely public health interventions and resource allocation. In order to provide accessibility and practical use of the models, we have developed an interactive R Shiny dashboard (https://f6yxlu-eric-guo.shinyapps.io/rsv_app/), which allows users to explore RSV-associated hospitalization risk levels across different states, visualize the impact of key predictors, and interactively generate RSV outbreak forecasts.

</details>


### [93] [Capturing reduced-order quantum many-body dynamics out of equilibrium via neural ordinary differential equations](https://arxiv.org/abs/2512.13913)
*Patrick Egenlauf,Iva Březinová,Sabine Andergassen,Miriam Klopotek*

Main category: cs.LG

TL;DR: 该研究使用神经ODE模型分析量子多体系统中两粒子约化密度矩阵动力学，发现只有在两粒子和三粒子关联度高的参数区域才能准确预测，而在反关联或无关联区域则失败，表明需要记忆依赖的闭合方案。


<details>
  <summary>Details</summary>
Motivation: 研究非平衡量子多体系统中快速关联积累现象，传统方法要么计算复杂度指数增长，要么忽略重要关联。时间依赖两粒子约化密度矩阵方法提供中间方案，但其时间局域重构泛函的有效性在不同动力学区域尚不明确。

Method: 使用神经ODE模型在精确的两粒子约化密度矩阵数据上进行训练（无降维），尝试仅基于瞬时两粒子累积量来重构动力学，而不需要显式的三粒子信息。

Result: 神经ODE模型仅在两粒子和三粒子累积量Pearson相关性大的参数区域能准确再现动力学；在反关联或无关联区域失败。时间平均的三粒子关联积累幅度是预测成功的主要指标：中等关联积累时预测准确，强关联时系统失效。

Conclusion: 研究结果表明，在强关联区域需要记忆依赖的核函数来进行三粒子累积量重构。神经ODE可作为模型无关的诊断工具，映射累积量展开方法的适用范围，并指导非局域闭合方案的发展。

Abstract: Out-of-equilibrium quantum many-body systems exhibit rapid correlation buildup that underlies many emerging phenomena. Exact wave-function methods to describe this scale exponentially with particle number; simpler mean-field approaches neglect essential two-particle correlations. The time-dependent two-particle reduced density matrix (TD2RDM) formalism offers a middle ground by propagating the two-particle reduced density matrix (2RDM) and closing the BBGKY hierarchy with a reconstruction of the three-particle cumulant. But the validity and existence of time-local reconstruction functionals ignoring memory effects remain unclear across different dynamical regimes. We show that a neural ODE model trained on exact 2RDM data (no dimensionality reduction) can reproduce its dynamics without any explicit three-particle information -- but only in parameter regions where the Pearson correlation between the two- and three-particle cumulants is large. In the anti-correlated or uncorrelated regime, the neural ODE fails, indicating that no simple time-local functional of the instantaneous two-particle cumulant can capture the evolution. The magnitude of the time-averaged three-particle-correlation buildup appears to be the primary predictor of success: For a moderate correlation buildup, both neural ODE predictions and existing TD2RDM reconstructions are accurate, whereas stronger values lead to systematic breakdowns. These findings pinpoint the need for memory-dependent kernels in the three-particle cumulant reconstruction for the latter regime. Our results place the neural ODE as a model-agnostic diagnostic tool that maps the regime of applicability of cumulant expansion methods and guides the development of non-local closure schemes. More broadly, the ability to learn high-dimensional RDM dynamics from limited data opens a pathway to fast, data-driven simulation of correlated quantum matter.

</details>


### [94] [Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce](https://arxiv.org/abs/2512.13726)
*Sayak Chakrabarty,Souradip Pal*

Main category: cs.LG

TL;DR: 该论文提出在有限时间预算约束下的推荐系统问题，使用强化学习同时学习用户偏好和时间预算模式，在电商场景中优化推荐列表以提高用户参与度。


<details>
  <summary>Details</summary>
Motivation: 传统推荐任务忽略了用户时间预算这一关键资源约束。在移动购物界面等场景中，用户需要花费时间评估推荐商品，高相关性的商品可能因评估成本过高而无法在有限时间内被用户接受，从而影响用户参与度。

Method: 1. 将时间约束下的推荐列表优化问题建模为具有预算感知效用的马尔可夫决策过程；2. 开发仿真框架研究重排序数据上的策略行为；3. 在阿里巴巴个性化重排序数据集上实验，比较在线策略和离线策略强化学习方法与传统上下文多臂老虎机方法。

Result: 实验表明，在严格的时间预算约束下，在线策略和离线策略强化学习方法相比传统的上下文多臂老虎机方法能够显著提升推荐性能，证明了强化学习在平衡项目相关性和评估成本方面的有效性。

Conclusion: 该研究为时间约束下的推荐系统提供了统一的MDP建模框架，并通过实证证明强化学习方法能够更好地处理用户时间预算约束，在电商推荐场景中实现更高的用户参与度。

Abstract: Unlike traditional recommendation tasks, finite user time budgets introduce a critical resource constraint, requiring the recommender system to balance item relevance and evaluation cost. For example, in a mobile shopping interface, users interact with recommendations by scrolling, where each scroll triggers a list of items called slate. Users incur an evaluation cost - time spent assessing item features before deciding to click. Highly relevant items having higher evaluation costs may not fit within the user's time budget, affecting engagement. In this position paper, our objective is to evaluate reinforcement learning algorithms that learn patterns in user preferences and time budgets simultaneously, crafting recommendations with higher engagement potential under resource constraints. Our experiments explore the use of reinforcement learning to recommend items for users using Alibaba's Personalized Re-ranking dataset supporting slate optimization in e-commerce contexts. Our contributions include (i) a unified formulation of time-constrained slate recommendation modeled as Markov Decision Processes (MDPs) with budget-aware utilities; (ii) a simulation framework to study policy behavior on re-ranking data; and (iii) empirical evidence that on-policy and off-policy control can improve performance under tight time budgets than traditional contextual bandit-based methods.

</details>


### [95] [Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution](https://arxiv.org/abs/2512.13729)
*Jacob Schnell,Aditya Makkar,Gunadi Gani,Aniket Srinivasan Ashok,Darren Lo,Mike Optis,Alexander Wong,Yuhao Chen*

Main category: cs.LG

TL;DR: 本文提出了一种用于风数据超分辨率的新型复合无分类器引导方法，显著提升了风场重建的准确性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 高分辨率、高精度的风数据对天气建模、风力涡轮机优化等应用至关重要，但获取成本高昂且困难。传统方法无法同时满足成本效益和准确性，而现有的深度学习方法在处理多通道风数据时效果有限。

Method: 提出了复合无分类器引导方法，这是对标准无分类器引导的泛化，可处理多个条件输入。该方法可直接应用于任何使用标准CFG dropout预训练的扩散模型。基于此开发了WindDM扩散模型，专门用于工业规模的风动力学重建。

Result: CCFG在风超分辨率任务中比标准CFG产生更高保真度的输出。WindDM在深度学习模型中达到最先进的重建质量，且成本比传统方法低1000倍。

Conclusion: 提出的复合无分类器引导方法有效解决了风数据超分辨率中多条件输入的挑战，WindDM模型在保持高精度的同时大幅降低了成本，为工业应用提供了实用解决方案。

Abstract: Various weather modelling problems (e.g., weather forecasting, optimizing turbine placements, etc.) require ample access to high-resolution, highly accurate wind data. Acquiring such high-resolution wind data, however, remains a challenging and expensive endeavour. Traditional reconstruction approaches are typically either cost-effective or accurate, but not both. Deep learning methods, including diffusion models, have been proposed to resolve this trade-off by leveraging advances in natural image super-resolution. Wind data, however, is distinct from natural images, and wind super-resolvers often use upwards of 10 input channels, significantly more than the usual 3-channel RGB inputs in natural images. To better leverage a large number of conditioning variables in diffusion models, we present a generalization of classifier-free guidance (CFG) to multiple conditioning inputs. Our novel composite classifier-free guidance (CCFG) can be dropped into any pre-trained diffusion model trained with standard CFG dropout. We demonstrate that CCFG outputs are higher-fidelity than those from CFG on wind super-resolution tasks. We present WindDM, a diffusion model trained for industrial-scale wind dynamics reconstruction and leveraging CCFG. WindDM achieves state-of-the-art reconstruction quality among deep learning models and costs up to $1000\times$ less than classical methods.

</details>


### [96] [PIS: A Generalized Physical Inversion Solver for Arbitrary Sparse Observations via Set-Conditioned Diffusion](https://arxiv.org/abs/2512.13732)
*Weijie Yang,Xun Zhang*

Main category: cs.LG

TL;DR: PIS是一种基于集合条件扩散的物理反演框架，能够在任意稀疏、不规则观测条件下稳定求解PDE约束的参数反演问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PDE约束的物理参数反演在稀疏、不规则观测条件下本质上是病态的，现有深度学习和算子学习模型在这些条件下表现不佳：固定网格假设失效、重建质量急剧下降、反演不可靠且缺乏不确定性量化。

Method: 提出物理反演求解器(PIS)，采用集合条件扩散框架，使用基于Set Transformer的编码器处理任意数量和几何分布的观测数据，结合余弦退火稀疏课程学习实现卓越鲁棒性，并辅以信息论分析揭示极端稀疏条件下的反演极限。

Result: 在Darcy流、Helmholtz波场反演和结构健康监测三个PDE反演问题上，即使在仅0.29%观测率的极端稀疏条件下，PIS仍保持稳定准确，将反演误差降低12.28%-88.73%，并能可靠生成校准的后验样本。

Conclusion: PIS是一个强大、通用且对稀疏性具有独特鲁棒性的物理反演解决方案，能够在任意和严重欠采样观测条件下提供可靠的反演结果和不确定性量化。

Abstract: Estimation of PDE-constrained physical parameters from limited indirect measurements is inherently ill-posed, particularly when observations are sparse, irregular, and constrained by real-world sensor placement. This challenge is ubiquitous in fields such as fluid mechanics, seismic inversion, and structural health monitoring. Existing deep and operator-learning models collapse under these conditions: fixed-grid assumptions fail, reconstruction deteriorates sharply, and inversion becomes unreliable with limited robustness and no uncertainty quantification (UQ).We propose the Physical Inversion Solver (PIS), a set-conditioned diffusion framework enabling inversion from truly arbitrary observation sets. PIS employs a Set Transformer-based encoder to handle measurements of any number or geometry, and a cosine-annealed sparsity curriculum for exceptional robustness. An accompanying information-theoretic analysis provides insight into the limits of inversion under extreme sparsity by revealing how observation entropy varies across physical systems.PIS is evaluated on three challenging PDE inverse problems: Darcy flow, wavefield inversion (Helmholtz), and structural health monitoring (Hooke's Law). Across all tasks and sparsity regimes -- including extreme cases with an observation rate of only $0.29\%$ -- existing operator-learning baselines fail to reconstruct meaningful fields, often diverging or collapsing entirely.In stark contrast, PIS remains stable and accurate, reducing inversion error by $12.28\%$--$88.73\%$ and reliably producing calibrated posterior samples. These samples accurately reflect both data scarcity and intrinsic physical ambiguity. These results position PIS as a powerful, general-purpose, and uniquely sparsity-resilient solution for physical inversion under arbitrary and severely undersampled observations.

</details>


### [97] [Low-Rank Compression of Language Models via Differentiable Rank Selection](https://arxiv.org/abs/2512.13733)
*Sidhant Sundrani,Francesco Tudisco,Pasquale Minervini*

Main category: cs.LG

TL;DR: LLRC是一种无需微调的低秩压缩方法，通过学习掩码权重选择奇异值，在保持激活相似性的同时实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 现有低秩压缩方法在确定各层最优秩时面临挑战：启发式方法搜索空间有限导致次优结果，基于梯度的方法在无微调时性能不如启发式方法。需要一种无需微调就能优化压缩率和下游任务准确性的方法。

Method: 提出LLRC（Learning to Low-Rank Compress），基于梯度的方法直接学习选择奇异值的掩码权重。使用校准数据集仅训练掩码权重，在减少奇异值选择的同时最小化中间激活与原始模型的差异。

Result: 在无需微调的设置下，LLRC在各种压缩率下优于其他排名选择方法。例如，在Llama-2-13B上20%压缩率时，在MMLU、BoolQ和OpenbookQA上分别比STRS高出12%、3.5%和4.4%。相比其他压缩技术，在无需微调变体上表现一致更优，与需要微调的LLM-Pruner变体性能相当。

Conclusion: LLRC提供了一种有效的无需微调的低秩压缩方法，通过学习掩码权重优化奇异值选择，在保持模型性能的同时实现高效压缩，为大型语言模型压缩提供了有前景的解决方案。

Abstract: Approaches for compressing large-language models using low-rank decomposition have made strides, particularly with the introduction of activation and loss-aware SVD, which improves the trade-off between decomposition rank and downstream task performance. Despite these advancements, a persistent challenge remains--selecting the optimal ranks for each layer to jointly optimise compression rate and downstream task accuracy. Current methods either rely on heuristics that can yield sub-optimal results due to their limited discrete search space or are gradient-based but are not as performant as heuristic approaches without post-compression fine-tuning. To address these issues, we propose Learning to Low-Rank Compress (LLRC), a gradient-based approach which directly learns the weights of masks that select singular values in a fine-tuning-free setting. Using a calibration dataset, we train only the mask weights to select fewer and fewer singular values while minimising the divergence of intermediate activations from the original model. Our approach outperforms competing ranking selection methods that similarly require no post-compression fine-tuning across various compression rates on common-sense reasoning and open-domain question-answering tasks. For instance, with a compression rate of 20% on Llama-2-13B, LLRC outperforms the competitive Sensitivity-based Truncation Rank Searching (STRS) on MMLU, BoolQ, and OpenbookQA by 12%, 3.5%, and 4.4%, respectively. Compared to other compression techniques, our approach consistently outperforms fine-tuning-free variants of SVD-LLM and LLM-Pruner across datasets and compression rates. Our fine-tuning-free approach also performs competitively with the fine-tuning variant of LLM-Pruner.

</details>


### [98] [Plug-and-Play Parameter-Efficient Tuning of Embeddings for Federated Recommendation](https://arxiv.org/abs/2512.13734)
*Haochen Yuan,Yang Zhang,Xiang He,Quan Z. Sheng,Zhongjie Wang*

Main category: cs.LG

TL;DR: 本文提出了一种基于参数高效微调（PEFT）的联邦推荐训练框架，通过减少需要传输的嵌入参数数量来显著降低通信开销，同时提高推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 随着云边协同的发展，推荐服务越来越多地在分布式环境中训练。联邦推荐（FR）通过共享模型参数而非原始数据来实现多端协同训练并保护隐私。然而，由于大规模物品嵌入导致的大量参数显著影响了通信效率。现有研究主要关注改进FR模型的效率，但很大程度上忽视了嵌入参数开销问题。

Method: 提出一个基于参数高效微调（PEFT）的联邦推荐训练框架，旨在减少需要传输的嵌入参数数量。该框架提供轻量级、插件式的解决方案，可无缝集成到现有FR方法中。除了整合常见的PEFT技术如LoRA和基于哈希的编码外，还探索了残差量化变分自编码器（RQ-VAE）作为框架内的新型PEFT策略。

Result: 在多种FR模型主干和数据集上的广泛实验表明，该框架显著减少了通信开销，同时提高了准确性。

Conclusion: 提出的基于PEFT的联邦推荐框架有效解决了嵌入参数传输开销问题，在降低通信成本的同时提升了推荐性能，为分布式推荐系统提供了实用的解决方案。

Abstract: With the rise of cloud-edge collaboration, recommendation services are increasingly trained in distributed environments. Federated Recommendation (FR) enables such multi-end collaborative training while preserving privacy by sharing model parameters instead of raw data. However, the large number of parameters, primarily due to the massive item embeddings, significantly hampers communication efficiency. While existing studies mainly focus on improving the efficiency of FR models, they largely overlook the issue of embedding parameter overhead. To address this gap, we propose a FR training framework with Parameter-Efficient Fine-Tuning (PEFT) based embedding designed to reduce the volume of embedding parameters that need to be transmitted. Our approach offers a lightweight, plugin-style solution that can be seamlessly integrated into existing FR methods. In addition to incorporating common PEFT techniques such as LoRA and Hash-based encoding, we explore the use of Residual Quantized Variational Autoencoders (RQ-VAE) as a novel PEFT strategy within our framework. Extensive experiments across various FR model backbones and datasets demonstrate that our framework significantly reduces communication overhead while improving accuracy. The source code is available at https://github.com/young1010/FedPEFT.

</details>


### [99] [DARTs: A Dual-Path Robust Framework for Anomaly Detection in High-Dimensional Multivariate Time Series](https://arxiv.org/abs/2512.13735)
*Xuechun Liu,Heli Sun,Xuecheng Wu,Ruichen Cao,Yunyun Shi,Dingkang Yang,Haoran Li*

Main category: cs.LG

TL;DR: DARTs是一个用于高维多变量时间序列异常检测的双路径框架，通过短路径和长路径分别捕获短期和长期的时空依赖关系，并使用窗口感知的软融合机制整合异常模式。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低维场景下能有效识别异常模式，但在处理高维噪声时间序列时，难以鲁棒地捕获长距离时空依赖关系，需要新的框架来解决这一局限性。

Method: 提出DARTs双路径框架：短路径包含多视图稀疏图学习器和扩散多关系图单元，用于捕获高噪声时间序列中的短期时空模式；长路径包含多尺度时空图构造器，用于建模高维表示空间中的长期动态；最后引入窗口感知时空软融合机制来过滤残余噪声并整合异常模式。

Result: 在主流数据集上的大量定性和定量实验结果表明，DARTs具有优越性和鲁棒性。消融研究也验证了所提出组件的关键设计因素。

Conclusion: DARTs能够有效解决高维噪声时间序列中长距离时空依赖关系的捕获问题，为多变量时间序列异常检测提供了一个鲁棒的双路径框架，代码和模型将公开。

Abstract: Multivariate time series anomaly detection (MTSAD) aims to accurately identify and localize complex abnormal patterns in the large-scale industrial control systems. While existing approaches excel in recognizing the distinct patterns under the low-dimensional scenarios, they often fail to robustly capture long-range spatiotemporal dependencies when learning representations from the high-dimensional noisy time series. To address these limitations, we propose DARTs, a robust long short-term dual-path framework with window-aware spatiotemporal soft fusion mechanism, which can be primarily decomposed into three complementary components. Specifically, in the short-term path, we introduce a Multi-View Sparse Graph Learner and a Diffusion Multi-Relation Graph Unit that collaborate to adaptively capture hierarchical discriminative short-term spatiotemporal patterns in the high-noise time series. While in the long-term path, we design a Multi-Scale Spatiotemporal Graph Constructor to model salient long-term dynamics within the high-dimensional representation space. Finally, a window-aware spatiotemporal soft-fusion mechanism is introduced to filter the residual noise while seamlessly integrating anomalous patterns. Extensive qualitative and quantitative experimental results across mainstream datasets demonstrate the superiority and robustness of our proposed DARTs. A series of ablation studies are also conducted to explore the crucial design factors of our proposed components. Our code and model will be made publicly open soon.

</details>


### [100] [TF-MCL: Time-frequency Fusion and Multi-domain Cross-Loss for Self-supervised Depression Detection](https://arxiv.org/abs/2512.13736)
*Li-Xuan Zhao,Chen-Yang Xu,Wen-Qiang Li,Bo Wang,Rong-Xing Wei,Qing-Hao Menga*

Main category: cs.LG

TL;DR: 本文提出了一种用于重度抑郁症检测的时间频率融合与多域交叉损失模型，通过融合映射头生成时间频率混合表示，并优化多域交叉损失函数，在公开数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于EEG信号的重度抑郁症监督检测方法严重依赖标签，而标签获取困难。现有的对比学习方法未能充分考虑EEG信号的时频分布特性，且获取低语义数据表示的能力不足，难以满足MDD检测任务需求。

Method: 提出TF-MCL模型，包含融合映射头生成时频混合表示，将时频域信息重新映射到融合域；通过优化多域交叉损失函数重构时频域和融合域中的表示分布，提升模型获取融合表示的能力。

Result: 在公开数据集MODMA和PRED+CT上评估，准确率显著提升，分别比现有最优方法高出5.87%和9.96%。

Conclusion: TF-MCL模型通过时频融合和多域交叉损失优化，有效提升了EEG信号中MDD检测的性能，解决了现有对比学习方法在时频特征表征和低语义表示获取方面的不足。

Abstract: In recent years, there has been a notable increase in the use of supervised detection methods of major depressive disorder (MDD) based on electroencephalogram (EEG) signals. However, the process of labeling MDD remains challenging. As a self-supervised learning method, contrastive learning could address the shortcomings of supervised learning methods, which are unduly reliant on labels in the context of MDD detection. However, existing contrastive learning methods are not specifically designed to characterize the time-frequency distribution of EEG signals, and their capacity to acquire low-semantic data representations is still inadequate for MDD detection tasks. To address the problem of contrastive learning method, we propose a time-frequency fusion and multi-domain cross-loss (TF-MCL) model for MDD detection. TF-MCL generates time-frequency hybrid representations through the use of a fusion mapping head (FMH), which efficiently remaps time-frequency domain information to the fusion domain, and thus can effectively enhance the model's capacity to synthesize time-frequency information. Moreover, by optimizing the multi-domain cross-loss function, the distribution of the representations in the time-frequency domain and the fusion domain is reconstructed, thereby improving the model's capacity to acquire fusion representations. We evaluated the performance of our model on the publicly available datasets MODMA and PRED+CT and show a significant improvement in accuracy, outperforming the existing state-of-the-art (SOTA) method by 5.87% and 9.96%, respectively.

</details>


### [101] [The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models](https://arxiv.org/abs/2512.13741)
*Md. Hasib Ur Rahman*

Main category: cs.LG

TL;DR: 论文提出"层流假说"，认为良性输入在LLM潜在空间中产生平滑过渡，而对抗性提示引发"语义湍流"。通过层间余弦速度方差这一零样本指标，可检测越狱攻击并分析模型安全架构。


<details>
  <summary>Details</summary>
Motivation: 当前LLM防御越狱攻击的方法依赖计算昂贵的外部分类器或脆弱的词法过滤器，忽视了模型推理过程的内在动态。需要一种轻量级、实时且能深入理解模型内部安全机制的方法。

Method: 提出层流假说，认为良性输入在潜在空间中产生平滑过渡，对抗性提示引发语义湍流。引入零样本指标：层间余弦速度方差，量化模型内部表示的变化轨迹。在不同小型语言模型上进行实验验证。

Result: 实验显示：RLHF对齐的Qwen2-1.5B在攻击下湍流增加75.4%（p<0.001），验证了内部冲突假说；Gemma-2B湍流减少22.0%，表现出基于反射的拒绝机制。语义湍流可作为轻量级越狱检测器和非侵入式诊断工具。

Conclusion: 语义湍流不仅可作为实时越狱检测器，还能作为非侵入式诊断工具，用于分类黑盒模型的安全架构类型，为LLM安全防御提供了新视角。

Abstract: As Large Language Models (LLMs) become ubiquitous, the challenge of securing them against adversarial "jailbreaking" attacks has intensified. Current defense strategies often rely on computationally expensive external classifiers or brittle lexical filters, overlooking the intrinsic dynamics of the model's reasoning process. In this work, the Laminar Flow Hypothesis is introduced, which posits that benign inputs induce smooth, gradual transitions in an LLM's high-dimensional latent space, whereas adversarial prompts trigger chaotic, high-variance trajectories - termed Semantic Turbulence - resulting from the internal conflict between safety alignment and instruction-following objectives. This phenomenon is formalized through a novel, zero-shot metric: the variance of layer-wise cosine velocity. Experimental evaluation across diverse small language models reveals a striking diagnostic capability. The RLHF-aligned Qwen2-1.5B exhibits a statistically significant 75.4% increase in turbulence under attack (p less than 0.001), validating the hypothesis of internal conflict. Conversely, Gemma-2B displays a 22.0% decrease in turbulence, characterizing a distinct, low-entropy "reflex-based" refusal mechanism. These findings demonstrate that Semantic Turbulence serves not only as a lightweight, real-time jailbreak detector but also as a non-invasive diagnostic tool for categorizing the underlying safety architecture of black-box models.

</details>


### [102] [Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis](https://arxiv.org/abs/2512.13749)
*Joyjit Roy,Samaresh Kumar Singh*

Main category: cs.LG

TL;DR: 该研究比较了在资源受限环境下基于嵌入的金融新闻情感分类方法，发现当标注数据稀缺时，预训练嵌入的收益会显著下降，模型表现甚至不如简单基线，验证集过小会导致模型选择过拟合。


<details>
  <summary>Details</summary>
Motivation: 金融情感分析对市场理解很重要，但标准自然语言处理方法在小数据集上遇到显著挑战。研究旨在评估资源受限环境下基于嵌入的金融新闻情感分类方法的有效性。

Method: 研究对Word2Vec、GloVe和句子变换器表示方法进行了比较评估，结合梯度提升算法在手动标注的新闻标题上进行实验。通过验证集和测试集性能对比分析模型表现。

Result: 实验结果显示验证集和测试集性能存在显著差距，模型表现甚至不如简单基线，尽管验证指标表现良好。预训练嵌入在数据量低于临界阈值时收益递减，小验证集导致模型选择过拟合。

Conclusion: 嵌入质量本身无法解决情感分类中的基本数据稀缺问题。对于资源有限的实践者，当标注样本稀缺时，需要考虑少样本学习、数据增强或词典增强的混合方法等替代方案。

Abstract: Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.

</details>


### [103] [Constrained Policy Optimization via Sampling-Based Weight-Space Projection](https://arxiv.org/abs/2512.13788)
*Shengfan Cao,Francesco Borrelli*

Main category: cs.LG

TL;DR: SCPO是一种基于采样的权重空间投影方法，通过轨迹采样和平滑性边界构建局部安全区域，使用凸SOCP投影梯度更新，确保训练过程中的安全性


<details>
  <summary>Details</summary>
Motivation: 安全关键学习需要在不离开安全操作区域的情况下提升性能。研究约束策略学习问题，其中模型参数必须满足基于rollout的未知安全约束

Method: 提出SCPO方法：1）结合轨迹采样和平滑性边界构建局部安全区域；2）通过凸二阶锥规划（SOCP）投影梯度更新；3）不需要约束函数的梯度信息

Result: 方法能够持续拒绝不安全更新，在整个训练过程中保持可行性，并在有害监督回归和约束双积分器任务中实现有意义的原始目标改进

Conclusion: SCPO提供了安全归纳保证：从任何安全初始化开始，所有中间策略在可行投影下保持安全。在具有稳定备份策略的约束控制设置中，进一步确保闭环稳定性并实现超越保守备份的安全适应

Abstract: Safety-critical learning requires policies that improve performance without leaving the safe operating regime. We study constrained policy learning where model parameters must satisfy unknown, rollout-based safety constraints. We propose SCPO, a sampling-based weight-space projection method that enforces safety directly in parameter space without requiring gradient access to the constraint functions. Our approach constructs a local safe region by combining trajectory rollouts with smoothness bounds that relate parameter changes to shifts in safety metrics. Each gradient update is then projected via a convex SOCP, producing a safe first-order step. We establish a safe-by-induction guarantee: starting from any safe initialization, all intermediate policies remain safe given feasible projections. In constrained control settings with a stabilizing backup policy, our approach further ensures closed-loop stability and enables safe adaptation beyond the conservative backup. On regression with harmful supervision and a constrained double-integrator task with malicious expert, our approach consistently rejects unsafe updates, maintains feasibility throughout training, and achieves meaningful primal objective improvement.

</details>


### [104] [The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces](https://arxiv.org/abs/2512.13821)
*Subramanyam Sahoo,Jared Junkin*

Main category: cs.LG

TL;DR: CTVP框架通过语义轨道分析验证不可信代码生成模型，检测后门注入，无需直接执行恶意代码


<details>
  <summary>Details</summary>
Motivation: LLM自动生成代码时可能存在后门注入和恶意行为，需要有效的AI控制框架来验证代码安全性

Method: 提出跨轨迹验证协议(CTVP)，通过分析模型在语义等价程序变换上的执行轨迹预测一致性来检测行为异常

Result: 引入对抗鲁棒性商数(ARQ)量化验证计算成本，理论分析显示不可博弈性，攻击者无法通过训练绕过检测

Conclusion: 语义轨道分析为代码生成任务提供了可扩展、理论基础的AI控制方法

Abstract: Large language models (LLMs) increasingly generate code with minimal human oversight, raising critical concerns about backdoor injection and malicious behavior. We present Cross-Trace Verification Protocol (CTVP), a novel AI control framework that verifies untrusted code-generating models through semantic orbit analysis. Rather than directly executing potentially malicious code, CTVP leverages the model's own predictions of execution traces across semantically equivalent program transformations. By analyzing consistency patterns in these predicted traces, we detect behavioral anomalies indicative of backdoors. Our approach introduces the Adversarial Robustness Quotient (ARQ), which quantifies the computational cost of verification relative to baseline generation, demonstrating exponential growth with orbit size. Theoretical analysis establishes information-theoretic bounds showing non-gamifiability -- adversaries cannot improve through training due to fundamental space complexity constraints. This work demonstrates that semantic orbit analysis provides a scalable, theoretically grounded approach to AI control for code generation tasks.

</details>


### [105] [Explainable reinforcement learning from human feedback to improve alignment](https://arxiv.org/abs/2512.13837)
*Shicheng Liu,Siyuan Xu,Wenjie Qiu,Hangfan Zhang,Minghui Zhu*

Main category: cs.LG

TL;DR: 该论文提出了一种通过识别并修正导致不满意回答的训练数据来改进RLHF的方法，包括事后解释和反学习两部分。


<details>
  <summary>Details</summary>
Motivation: 人类改进不满意结果的常见策略是找到原因并修正，作者希望将这一策略应用于改进语言模型的人类反馈强化学习（RLHF），因为RLHF调优的语言模型仍可能产生不满意回答。

Method: 方法分为两部分：1）事后解释方法，通过约束组合优化问题识别导致不满意回答的训练数据；2）反学习方法，通过反学习这些训练数据来改进不满意回答，同时不显著影响其他满意回答。

Result: 实验结果表明，该算法能够有效改进RLHF。

Conclusion: 通过识别和修正导致不满意回答的训练数据，可以有效地改进RLHF对齐语言模型的效果，将人类改进策略成功应用于机器学习领域。

Abstract: A common and effective strategy for humans to improve an unsatisfactory outcome in daily life is to find a cause of this outcome and correct the cause. In this paper, we investigate whether this human improvement strategy can be applied to improving reinforcement learning from human feedback (RLHF) for alignment of language models (LMs). In particular, it is observed in the literature that LMs tuned by RLHF can still output unsatisfactory responses. This paper proposes a method to improve the unsatisfactory responses by correcting their causes. Our method has two parts. The first part proposes a post-hoc explanation method to explain why an unsatisfactory response is generated to a prompt by identifying the training data that lead to this response. We formulate this problem as a constrained combinatorial optimization problem where the objective is to find a set of training data closest to this prompt-response pair in a feature representation space, and the constraint is that the prompt-response pair can be decomposed as a convex combination of this set of training data in the feature space. We propose an efficient iterative data selection algorithm to solve this problem. The second part proposes an unlearning method that improves unsatisfactory responses to some prompts by unlearning the training data that lead to these unsatisfactory responses and, meanwhile, does not significantly degrade satisfactory responses to other prompts. Experimental results demonstrate that our algorithm can improve RLHF.

</details>


### [106] [Measuring Uncertainty Calibration](https://arxiv.org/abs/2512.13872)
*Kamil Ciosek,Nicolò Felicioni,Sina Ghiassian,Juan Elenter Litwin,Francesco Tonolini,David Gustaffson,Eva Garcia Martin,Carmen Barcena Gonzales,Raphaëlle Bertrand-Lalo*

Main category: cs.LG

TL;DR: 本文提出了两种估计二元分类器L1校准误差的方法：一是为有界变差校准函数的分类器提供上界，二是通过修改分类器使其校准误差可高效上界估计而不显著影响性能。


<details>
  <summary>Details</summary>
Motivation: 从有限数据集估计二元分类器的L1校准误差是一个重要但具有挑战性的问题。现有方法可能存在限制性假设或效率问题，需要开发更实用、分布自由且非渐近的校准误差估计方法。

Method: 1. 为具有有界变差校准函数的分类器提供上界估计方法；2. 提出一种修改分类器的技术，使得任何分类器的校准误差都能被高效上界估计，而不需要限制性假设，且不显著影响分类器性能。

Result: 所有结果都是非渐近且分布自由的，提出的方法在实际数据集上运行具有适度的计算开销，能够为实际应用中的校准误差测量提供实用程序。

Conclusion: 本文提供了实用的校准误差测量建议，提出的方法能够在真实世界数据集上有效运行，为分类器校准误差的估计提供了有效的解决方案。

Abstract: We make two contributions to the problem of estimating the $L_1$ calibration error of a binary classifier from a finite dataset. First, we provide an upper bound for any classifier where the calibration function has bounded variation. Second, we provide a method of modifying any classifier so that its calibration error can be upper bounded efficiently without significantly impacting classifier performance and without any restrictive assumptions. All our results are non-asymptotic and distribution-free. We conclude by providing advice on how to measure calibration error in practice. Our methods yield practical procedures that can be run on real-world datasets with modest overhead.

</details>


### [107] [Privacy-Enhancing Infant Cry Classification with Federated Transformers and Denoising Regularization](https://arxiv.org/abs/2512.13880)
*Geofrey Owino,Bernard Shibwabo*

Main category: cs.LG

TL;DR: 提出一个结合降噪自编码器、卷积分词器和Transformer编码器的端到端婴儿哭声分析系统，采用联邦学习进行训练，实现隐私保护、噪声鲁棒和通信高效的婴儿哭声分类。


<details>
  <summary>Details</summary>
Motivation: 婴儿哭声分类有助于早期评估婴儿需求，但现有解决方案面临音频数据隐私问题、背景噪声敏感性以及跨录音环境的领域偏移等部署限制。

Method: 1) 端到端婴儿哭声分析流水线：集成降噪自编码器(DAE)、卷积分词器和Transformer编码器；2) 采用通信高效的联邦学习(FL)训练；3) 系统执行设备端降噪、自适应分割、后验校准和基于能量的分布外(OOD)弃权；4) 联邦训练使用正则化控制变量更新和8位适配器增量，在安全聚合下进行。

Result: 在Baby Chillanto和Donate-a-Cry数据集上，模型获得宏F1分数0.938、AUC 0.962和预期校准误差(ECE) 0.032；每轮客户端上传从约36-42 MB减少到3.3 MB；在NVIDIA Jetson Nano上实时边缘推理达到每1秒频谱图帧96 ms。

Conclusion: 该系统为隐私保护、噪声鲁棒和通信高效的婴儿哭声分类提供了一条实用路径，适合联邦部署。

Abstract: Infant cry classification can aid early assessment of infant needs. However, deployment of such solutions is limited by privacy concerns around audio data, sensitivity to background noise, and domain shift across recording environments. We present an end-to-end infant cry analysis pipeline that integrates a denoising autoencoder (DAE), a convolutional tokenizer, and a Transformer encoder trained using communication-efficient federated learning (FL). The system performs on-device denoising, adaptive segmentation, post hoc calibration, and energy-based out-of-distribution (OOD) abstention. Federated training employs a regularized control variate update with 8-bit adapter deltas under secure aggregation. Using the Baby Chillanto and Donate-a-Cry datasets with ESC-50 noise overlays, the model achieves a macro F1 score of 0.938, an AUC of 0.962, and an Expected Calibration Error (ECE) of 0.032, while reducing per-round client upload from approximately 36 to 42 MB to 3.3 MB. Real-time edge inference on an NVIDIA Jetson Nano (4 GB, TensorRT FP16) achieves 96 ms per one-second spectrogram frame. These results demonstrate a practical path toward privacy-preserving, noise-robust, and communication-efficient infant cry classification suitable for federated deployment.

</details>


### [108] [OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction](https://arxiv.org/abs/2512.13886)
*Mohammad Mozaffari,Samuel Kushnir,Maryam Mehri Dehnavi,Amir Yazdanbakhsh*

Main category: cs.LG

TL;DR: OPTIMA是一种实用的单次训练后剪枝方法，通过将层权重重构转化为共享Hessian矩阵的行级二次规划问题，在保持准确性的同时实现大规模剪枝。


<details>
  <summary>Details</summary>
Motivation: 现有训练后剪枝方法存在权衡：简单的启发式方法速度快但准确性下降，而联合优化方法能恢复准确性但计算成本过高。需要一种既准确又实用的单次剪枝方法。

Method: 将层权重重构转化为独立的行级二次规划问题，这些QP共享同一层的Hessian矩阵。实现加速器友好的QP求解器，每层累积一个Hessian矩阵，并行求解多个小型QP，实现单次训练后剪枝。

Result: OPTIMA在多种LLM家族和稀疏度下持续改进零样本性能，实现最高3.97%的绝对准确率提升。在NVIDIA H100上，40小时内完成80亿参数transformer的端到端剪枝，峰值内存60GB。

Conclusion: OPTIMA为单次训练后剪枝设定了新的准确率-效率权衡标准，平衡了准确性和可扩展性，无需微调即可实现大规模模型剪枝。

Abstract: Post-training model pruning is a promising solution, yet it faces a trade-off: simple heuristics that zero weights are fast but degrade accuracy, while principled joint optimization methods recover accuracy but are computationally infeasible at modern scale. One-shot methods such as SparseGPT offer a practical trade-off in optimality by applying efficient, approximate heuristic weight updates. To close this gap, we introduce OPTIMA, a practical one-shot post-training pruning method that balances accuracy and scalability. OPTIMA casts layer-wise weight reconstruction after mask selection as independent, row-wise Quadratic Programs (QPs) that share a common layer Hessian. Solving these QPs yields the per-row globally optimal update with respect to the reconstruction objective given the estimated Hessian. The shared-Hessian structure makes the problem highly amenable to batching on accelerators. We implement an accelerator-friendly QP solver that accumulates one Hessian per layer and solves many small QPs in parallel, enabling one-shot post-training pruning at scale on a single accelerator without fine-tuning. OPTIMA integrates with existing mask selectors and consistently improves zero-shot performance across multiple LLM families and sparsity regimes, yielding up to 3.97% absolute accuracy improvement. On an NVIDIA H100, OPTIMA prunes a 8B-parameter transformer end-to-end in 40 hours with 60GB peak memory. Together, these results set a new state-of-the-art accuracy-efficiency trade-offs for one-shot post-training pruning.

</details>


### [109] [Let's (not) just put things in Context: Test-Time Training for Long-Context LLMs](https://arxiv.org/abs/2512.13898)
*Rachit Bansal,Aston Zhang,Rishabh Tiwari,Lovish Madaan,Sai Surya Duvvuri,Devvrit Khatri,David Brandfonbrener,David Alvarez-Melis,Prajjwal Bhargava,Mihir Sanjay Kale,Samy Jelassi*

Main category: cs.LG

TL;DR: 论文研究发现长上下文LLM存在"分数稀释"问题，传统推理时计算策略（如生成更多思考标记）在长上下文任务中效果有限，提出通过针对特定上下文进行梯度更新的简单方法，显著提升长上下文性能。


<details>
  <summary>Details</summary>
Motivation: 虽然现代LLM能够处理数百万标记的长上下文，但经验证据表明它们无法可靠地利用这些长文本。同时，推理时计算（如生成思考标记）已被证明能提升多步推理任务的性能，但作者发现这些策略在长上下文任务中效果迅速减弱并最终失败。

Method: 提出一种简单方法：通过对给定上下文进行有针对性的梯度更新，理论上克服静态自注意力的限制。这种方法将推理时计算从生成更多思考标记转向针对特定上下文进行微调训练。

Result: 该方法在各种模型和长上下文基准测试中带来持续的大幅性能提升。在Qwen3-4B模型上，LongBench-v2和ZeroScrolls基准测试子集的平均性能分别提升12.6和14.1个百分点。

Conclusion: 对于长上下文任务，少量针对特定上下文的训练比当前推理时扩展策略（如生成更多思考标记）是更好的推理计算利用方式。这种方法克服了静态自注意力固有的分数稀释问题。

Abstract: Progress on training and architecture strategies has enabled LLMs with millions of tokens in context length. However, empirical evidence suggests that such long-context LLMs can consume far more text than they can reliably use. On the other hand, it has been shown that inference-time compute can be used to scale performance of LLMs, often by generating thinking tokens, on challenging tasks involving multi-step reasoning. Through controlled experiments on sandbox long-context tasks, we find that such inference-time strategies show rapidly diminishing returns and fail at long context. We attribute these failures to score dilution, a phenomenon inherent to static self-attention. Further, we show that current inference-time strategies cannot retrieve relevant long-context signals under certain conditions. We propose a simple method that, through targeted gradient updates on the given context, provably overcomes limitations of static self-attention. We find that this shift in how inference-time compute is spent leads to consistently large performance improvements across models and long-context benchmarks. Our method leads to large 12.6 and 14.1 percentage point improvements for Qwen3-4B on average across subsets of LongBench-v2 and ZeroScrolls benchmarks. The takeaway is practical: for long context, a small amount of context-specific training is a better use of inference compute than current inference-time scaling strategies like producing more thinking tokens.

</details>


### [110] [Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America](https://arxiv.org/abs/2512.13910)
*Matheus Corrêa Domingos,Valdivino Alexandre de Santiago Júnior,Juliana Aparecida Anochi,Elcio Hideiti Shiguemori,Luísa Mirelle Costa dos Santos,Hércules Carlos dos Santos Pereira,André Estevam Costa Oliveira*

Main category: cs.LG

TL;DR: 该研究比较了机器学习、深度学习与传统动态模型在南美洲降水预报中的表现，发现LSTM模型在强降水预报中表现最佳，而传统动态模型BAM表现最差。


<details>
  <summary>Details</summary>
Motivation: 降水预报对社会至关重要，但传统动态模型复杂且计算成本高。虽然AI技术已被用于气象预报，但缺乏对纯数据驱动方法在降水预报中可行性的广泛研究。

Method: 研究比较了经典机器学习（随机森林、XGBoost）和深度学习（1D CNN、LSTM、GRU）方法，以传统动态模型BAM作为基准。使用2019年全季节数据，并采用可解释AI分析模型行为。

Result: LSTM模型表现出最强的预测性能，特别是在强降水预报中最为准确。传统动态模型BAM表现最差。XGBoost在成本敏感场景下提供较低延迟和轻微精度损失。

Conclusion: 深度学习模型在气候预报中具有可行性，证实了全球主要气象和气候预报中心的趋势。LSTM在降水预报中表现优异，为数据驱动方法在气象领域的应用提供了有力证据。

Abstract: Forecasting meteorological variables is challenging due to the complexity of their processes, requiring advanced models for accuracy. Accurate precipitation forecasts are vital for society. Reliable predictions help communities mitigate climatic impacts. Based on the current relevance of artificial intelligence (AI), classical machine learning (ML) and deep learning (DL) techniques have been used as an alternative or complement to dynamic modeling. However, there is still a lack of broad investigations into the feasibility of purely data-driven approaches for precipitation forecasting. This study aims at addressing this issue where different classical ML and DL approaches for forecasting precipitation in South America, taking into account all 2019 seasons, are considered in a detailed investigation. The selected classical ML techniques were Random Forests and extreme gradient boosting (XGBoost), while the DL counterparts were a 1D convolutional neural network (CNN 1D), a long short-term memory (LSTM) model, and a gated recurrent unit (GRU) model. Additionally, the Brazilian Global Atmospheric Model (BAM) was used as a representative of the traditional dynamic modeling approach. We also relied on explainable artificial intelligence (XAI) to provide some explanations for the models behaviors. LSTM showed strong predictive performance while BAM, the traditional dynamic model representative, had the worst results. Despite presented the higher latency, LSTM was most accurate for heavy precipitation. If cost is a concern, XGBoost offers lower latency with slightly accuracy loss. The results of this research confirm the viability of DL models for climate forecasting, solidifying a global trend in major meteorological and climate forecasting centers.

</details>


### [111] [Sliding Window Recurrences for Sequence Models](https://arxiv.org/abs/2512.13921)
*Dragos Secrieru,Garyk Brixi,Yoshua Bengio,Taiji Suzuki,Michael Poli,Stefano Massaroli*

Main category: cs.LG

TL;DR: 论文提出了一种用于线性递归的分层分解框架，开发了滑动窗口递归算法，并基于此构建了Phalanx层，在10亿参数多混合模型中实现了比优化Transformer快10-40%的速度提升，同时保持相同的困惑度。


<details>
  <summary>Details</summary>
Motivation: 多混合架构因其更好的质量和性能有望主导语言建模领域。当前需要开发与GPU内存层次结构对齐的算法，以优化线性递归计算，减少昂贵的跨warp通信开销。

Method: 提出了分层分解框架用于线性递归，开发了滑动窗口递归算法，将递归截断为硬件对齐的窗口（自然呈锯齿状）。基于此构建了Phalanx层，可作为窗口注意力或线性递归的直接替代品。

Result: 在10亿参数的多混合模型中，Phalanx在4K到32K上下文长度范围内，相比优化Transformer实现了超过10-40%的速度提升，同时保持了相同的困惑度。

Conclusion: 滑动窗口递归和Phalanx层为多混合语言模型提供了高效的构建模块，在保持模型质量的同时显著提升了推理性能，特别适合长上下文处理场景。

Abstract: Multi-hybrid architectures are poised to take over language modeling due to better quality and performance. We introduce a hierarchical decomposition framework for linear recurrences that allows us to develop algorithms aligned with GPU memory hierarchies, yielding Sliding Window Recurrences. We focus specifically on truncating recurrences to hardware-aligned windows which are naturally jagged, limiting costly inter-warp communication. Using SWR, we develop Phalanx layers that serve as drop-in replacements for windowed attention or linear recurrences. In 1B parameter multi-hybrid models, Phalanx achieves over 10-40% speedup across 4K to 32K context length over optimized Transformers while matching perplexity.

</details>


### [112] [EDGC: Entropy-driven Dynamic Gradient Compression for Efficient LLM Training](https://arxiv.org/abs/2511.10333)
*Qingao Yi,Jiaang Duan,Hanwen Hu,Qin Hua,Haiyan Zhao,Shiyou Qian,Dingyu Yang,Jian Cao,Jinghua Tang,Yinghao Yu,Chenzhi Liao,Kangjin Wang,Liping Zhang*

Main category: cs.LG

TL;DR: EDGC是一个基于熵的动态梯度压缩框架，通过根据梯度熵变化动态调整压缩率，在保持LLM精度的同时显著减少通信延迟和训练时间。


<details>
  <summary>Details</summary>
Motivation: 训练大型语言模型面临计算资源和内存容量的挑战，分布式训练虽然能缓解这些问题，但仍存在显著的通信开销。现有的静态梯度压缩方法忽略了训练过程中梯度动态演变的特性，导致性能下降。如何在保持性能的同时通过压缩加速LLM训练仍然是一个挑战。

Method: 提出EDGC框架，包含三个关键组件：1) 使用下采样方法高效估计梯度熵，降低计算开销；2) 建立压缩率与梯度熵之间的理论模型，为压缩决策提供依据；3) 基于窗口的调整机制，在流水线阶段动态调整压缩率，提高通信效率并保持模型性能。

Result: 在32-NVIDIA-V100集群上训练GPT2-2.5B和在64-NVIDIA-H100集群上训练GPT2-12.1B的实验结果显示，EDGC显著减少了通信延迟和训练时间，分别达到46.45%和16.13%的减少，同时保持了LLM的准确性。

Conclusion: EDGC通过动态调整压缩率基于梯度熵变化，有效解决了LLM训练中的通信瓶颈问题，在保持模型性能的同时显著提高了训练效率，为大规模语言模型训练提供了有效的压缩解决方案。

Abstract: Training large language models (LLMs) poses significant challenges regarding computational resources and memory capacity. Although distributed training techniques help mitigate these issues, they still suffer from considerable communication overhead. Existing approaches primarily rely on static gradient compression to enhance communication efficiency; however, these methods neglect the dynamic nature of evolving gradients during training, leading to performance degradation. Accelerating LLM training via compression without sacrificing performance remains a challenge. In this paper, we propose an entropy-driven dynamic gradient compression framework called EDGC. The core concept is to adjust the compression rate during LLM training based on the evolving trends of gradient entropy, taking into account both compression efficiency and error. EDGC consists of three key components.First, it employs a down-sampling method to efficiently estimate gradient entropy, reducing computation overhead. Second, it establishes a theoretical model linking compression rate with gradient entropy, enabling more informed compression decisions. Lastly, a window-based adjustment mechanism dynamically adapts the compression rate across pipeline stages, improving communication efficiency and maintaining model performance. We implemented EDGC on a 32-NVIDIA-V100 cluster and a 64-NVIDIA-H100 cluster to train GPT2-2.5B and GPT2-12.1B, respectively. The results show that EDGC significantly reduces communication latency and training time by up to 46.45% and 16.13% while preserving LLM accuracy.

</details>


### [113] [Pattern-Guided Diffusion Models](https://arxiv.org/abs/2512.13945)
*Vivian Lin,Kuk Jin Jang,Wenwen Si,Insup Lee*

Main category: cs.LG

TL;DR: PGDM利用原型分析提取时间序列中的重复模式，通过模式引导扩散模型进行更准确的预测，并引入基于原型分析的不确定性量化方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在多元时间序列预测中很少考虑数据中的重复模式结构，这限制了预测的准确性和现实性。

Method: 使用原型分析提取时间序列中的固有模式，估计最可能的下一个模式，并用该模式引导扩散模型的预测。同时引入基于原型分析的不确定性量化技术，并根据模式估计的不确定性动态调整引导强度。

Result: 在两个应用（视野测量和动作捕捉帧预测）中，模式引导使PGDM性能提升分别达40.67%/56.26%和14.12%/14.10%，且优于基线方法达65.58%/84.83%和93.64%/92.55%。

Conclusion: PGDM通过利用时间数据中的固有模式进行引导，显著提升了扩散模型在时间序列预测中的性能，并提供了有效的不确定性量化方法。

Abstract: Diffusion models have shown promise in forecasting future data from multivariate time series. However, few existing methods account for recurring structures, or patterns, that appear within the data. We present Pattern-Guided Diffusion Models (PGDM), which leverage inherent patterns within temporal data for forecasting future time steps. PGDM first extracts patterns using archetypal analysis and estimates the most likely next pattern in the sequence. By guiding predictions with this pattern estimate, PGDM makes more realistic predictions that fit within the set of known patterns. We additionally introduce a novel uncertainty quantification technique based on archetypal analysis, and we dynamically scale the guidance level based on the pattern estimate uncertainty. We apply our method to two well-motivated forecasting applications, predicting visual field measurements and motion capture frames. On both, we show that pattern guidance improves PGDM's performance (MAE / CRPS) by up to 40.67% / 56.26% and 14.12% / 14.10%, respectively. PGDM also outperforms baselines by up to 65.58% / 84.83% and 93.64% / 92.55%.

</details>


### [114] [Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation](https://arxiv.org/abs/2512.14011)
*Yue Wan,Jiayi Yuan,Zhiwei Feng,Xiaowei Jia*

Main category: cs.LG

TL;DR: 该研究构建了一个精心策划的MHC-II抗原表位数据集，提出了三个机器学习任务，并建立了多尺度评估框架，为计算免疫治疗提供重要资源。


<details>
  <summary>Details</summary>
Motivation: MHC-II抗原表位在免疫治疗中至关重要，但与MHC-I相比，其研究面临更多挑战：结合特异性复杂、基序模式模糊、数据集较小且标准化不足。现有MHC-II相互作用数据集规模较小且缺乏标准化。

Method: 1. 从IEDB和其他公共来源构建精心策划的MHC-II数据集；2. 扩展和标准化现有肽-MHC-II数据集；3. 引入具有更丰富生物背景的新型抗原-MHC-II数据集；4. 制定肽结合、肽呈递和抗原呈递三个主要机器学习任务；5. 采用多尺度评估框架对现有模型进行基准测试；6. 使用模块化框架对各种建模设计进行全面分析。

Result: 创建了一个全面且标准化的MHC-II数据集，涵盖了肽结合、肽呈递和抗原呈递三个层次的生物过程。通过多尺度评估框架对现有模型进行了系统评估，并通过模块化分析提供了对该问题的深入理解。

Conclusion: 这项工作为推进计算免疫治疗提供了宝贵资源，为未来机器学习指导的表位发现和免疫反应预测建模研究奠定了基础。该数据集和框架有助于解决MHC-II研究的挑战，促进更有效的免疫治疗策略开发。

Abstract: Antigenic epitope presented by major histocompatibility complex II (MHC-II) proteins plays an essential role in immunotherapy. However, compared to the more widely studied MHC-I in computational immunotherapy, the study of MHC-II antigenic epitope poses significantly more challenges due to its complex binding specificity and ambiguous motif patterns. Consequently, existing datasets for MHC-II interactions are smaller and less standardized than those available for MHC-I. To address these challenges, we present a well-curated dataset derived from the Immune Epitope Database (IEDB) and other public sources. It not only extends and standardizes existing peptide-MHC-II datasets, but also introduces a novel antigen-MHC-II dataset with richer biological context. Leveraging this dataset, we formulate three major machine learning (ML) tasks of peptide binding, peptide presentation, and antigen presentation, which progressively capture the broader biological processes within the MHC-II antigen presentation pathway. We further employ a multi-scale evaluation framework to benchmark existing models, along with a comprehensive analysis over various modeling designs to this problem with a modular framework. Overall, this work serves as a valuable resource for advancing computational immunotherapy, providing a foundation for future research in ML guided epitope discovery and predictive modeling of immune responses.

</details>


### [115] [EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment](https://arxiv.org/abs/2512.14019)
*Juseung Yun,Sunwoo Yu,Sumin Ha,Jonghyun Kim,Janghyeon Lee,Jongseong Jang,Soonyoung Lee*

Main category: cs.LG

TL;DR: EXAONE Path 2.5是一个病理学基础模型，通过联合建模组织学、基因组学、表观遗传学和转录组学等多模态数据，提供更全面的肿瘤生物学表征，在临床和基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 癌症进展涉及多个生物层面的相互作用，特别是超越形态学、涉及分子层面的相互作用，这些对于仅基于图像的传统模型是不可见的。为了捕捉更广泛的生物学景观，需要开发能够整合多种生物模态的病理学基础模型。

Method: EXAONE Path 2.5包含三个关键组件：1）多模态SigLIP损失，实现异构模态间的全配对对比学习；2）片段感知旋转位置编码（F-RoPE）模块，保留WSI中的空间结构和组织片段拓扑；3）针对WSI和RNA-seq的领域专业化内部基础模型，提供生物学基础的嵌入以实现稳健的多模态对齐。

Result: 在两个互补基准测试中评估：内部真实世界临床数据集和包含80个任务的Patho-Bench基准。该框架表现出高数据和参数效率，在Patho-Bench上达到与最先进基础模型相当的性能，同时在内部临床设置中展现出最高的适应性。

Conclusion: 结果强调了生物学信息多模态设计的价值，并突显了整合基因型到表型建模在下一代精准肿瘤学中的潜力。

Abstract: Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.

</details>


### [116] [FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis](https://arxiv.org/abs/2512.14078)
*Da Zhang,Bingyu Li,Zhiyuan Zhao,Feiping Nie,Junyu Gao,Xuelong Li*

Main category: cs.LG

TL;DR: FusAD是一个统一的时间序列分析框架，通过自适应时频融合和去噪机制，在分类、预测和异常检测任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分析面临三大挑战：1）缺乏高效、多任务兼容且可泛化的统一框架；2）现有方法通常针对单一任务或特定数据类型；3）真实数据常受噪声、复杂频率成分和多尺度动态模式影响，难以进行鲁棒特征提取。

Method: FusAD采用自适应时频融合机制，整合傅里叶和小波变换以捕捉全局-局部和多尺度动态特征；包含自适应去噪机制，自动感知和过滤各类噪声；集成通用信息融合和解码结构，结合掩码预训练，促进多粒度表示的高效学习和迁移。

Result: 在主流时间序列基准测试中，FusAD在分类、预测和异常检测任务上持续优于最先进模型，同时保持高效率和可扩展性。

Conclusion: FusAD通过创新的自适应时频融合和去噪机制，成功构建了一个统一、高效且可泛化的时间序列分析框架，能够有效处理多任务建模并整合多样化时间序列信息。

Abstract: Time series analysis plays a vital role in fields such as finance, healthcare, industry, and meteorology, underpinning key tasks including classification, forecasting, and anomaly detection. Although deep learning models have achieved remarkable progress in these areas in recent years, constructing an efficient, multi-task compatible, and generalizable unified framework for time series analysis remains a significant challenge. Existing approaches are often tailored to single tasks or specific data types, making it difficult to simultaneously handle multi-task modeling and effectively integrate information across diverse time series types. Moreover, real-world data are often affected by noise, complex frequency components, and multi-scale dynamic patterns, which further complicate robust feature extraction and analysis. To ameliorate these challenges, we propose FusAD, a unified analysis framework designed for diverse time series tasks. FusAD features an adaptive time-frequency fusion mechanism, integrating both Fourier and Wavelet transforms to efficiently capture global-local and multi-scale dynamic features. With an adaptive denoising mechanism, FusAD automatically senses and filters various types of noise, highlighting crucial sequence variations and enabling robust feature extraction in complex environments. In addition, the framework integrates a general information fusion and decoding structure, combined with masked pre-training, to promote efficient learning and transfer of multi-granularity representations. Extensive experiments demonstrate that FusAD consistently outperforms state-of-the-art models on mainstream time series benchmarks for classification, forecasting, and anomaly detection tasks, while maintaining high efficiency and scalability. Code is available at https://github.com/zhangda1018/FusAD.

</details>


### [117] [SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations](https://arxiv.org/abs/2512.14080)
*Wentao Guo,Mayank Mishra,Xinle Cheng,Ion Stoica,Tri Dao*

Main category: cs.LG

TL;DR: SonicMoE：一种内存高效的MoE训练方法，通过减少激活缓存、优化GPU内核和提出"token rounding"算法，显著降低内存占用并提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前细粒度MoE模型面临激活内存占用增加和硬件效率降低的问题，而稀疏MoE模型在Grouped GEMM内核中存在因填充导致的计算浪费。需要一种既能保持MoE模型质量优势，又能解决这些效率问题的方案。

Method: 1) 提出内存高效算法，最小化MoE前向和反向传播的激活缓存；2) 设计GPU内核，实现内存IO与计算的重叠；3) 提出"token rounding"方法，减少Grouped GEMM内核中的填充浪费。

Result: SonicMoE在Hopper GPU上相比ScatterMoE的BF16 MoE内核，激活内存减少45%，计算吞吐量提升1.86倍。在64个H100上达到2130亿token/天的训练吞吐量，接近ScatterMoE在96个H100上的性能。在高稀疏设置下，token rounding算法相比vanilla top-K路由带来额外1.16倍加速。

Conclusion: SonicMoE通过创新的内存优化、GPU内核设计和token rounding算法，有效解决了当前MoE训练中的效率和内存问题，为大规模MoE模型训练提供了高效解决方案，相关内核已开源。

Abstract: Mixture of Experts (MoE) models have emerged as the de facto architecture for scaling up language models without significantly increasing the computational cost. Recent MoE models demonstrate a clear trend towards high expert granularity (smaller expert intermediate dimension) and higher sparsity (constant number of activated experts with higher number of total experts), which improve model quality per FLOP. However, fine-grained MoEs suffer from increased activation memory footprint and reduced hardware efficiency due to higher IO costs, while sparser MoEs suffer from wasted computations due to padding in Grouped GEMM kernels. In response, we propose a memory-efficient algorithm to compute the forward and backward passes of MoEs with minimal activation caching for the backward pass. We also design GPU kernels that overlap memory IO with computation benefiting all MoE architectures. Finally, we propose a novel "token rounding" method that minimizes the wasted compute due to padding in Grouped GEMM kernels. As a result, our method SonicMoE reduces activation memory by 45% and achieves a 1.86x compute throughput improvement on Hopper GPUs compared to ScatterMoE's BF16 MoE kernel for a fine-grained 7B MoE. Concretely, SonicMoE on 64 H100s achieves a training throughput of 213 billion tokens per day comparable to ScatterMoE's 225 billion tokens per day on 96 H100s for a 7B MoE model training with FSDP-2 using the lm-engine codebase. Under high MoE sparsity settings, our tile-aware token rounding algorithm yields an additional 1.16x speedup on kernel execution time compared to vanilla top-$K$ routing while maintaining similar downstream performance. We open-source all our kernels to enable faster MoE model training.

</details>


### [118] [Cornserve: Efficiently Serving Any-to-Any Multimodal Models](https://arxiv.org/abs/2512.14098)
*Jeff J. Ma,Jae-Won Chung,Jisang Ahn,Yizhuo Liang,Akshay Jajoo,Myungjin Lee,Mosharaf Chowdhury*

Main category: cs.LG

TL;DR: Cornserve是一个高效的在线服务系统，专门为Any-to-Any多模态模型设计，通过自动优化部署计划和分布式运行时管理，显著提升服务性能。


<details>
  <summary>Details</summary>
Motivation: Any-to-Any多模态模型在输入输出类型、计算路径和计算规模上存在高度异质性，给在线服务带来挑战，需要专门的系统来高效处理这种复杂性。

Method: Cornserve允许开发者描述通用Any-to-Any模型的计算图，包含多模态编码器、自回归模型和多模态生成器等异质组件。系统规划器自动找到优化的部署计划，包括是否以及如何将模型分解为更小组件。分布式运行时按计划执行模型，高效处理异质性。

Result: 评估显示Cornserve能够高效服务多样化的Any-to-Any模型和工作负载，相比现有解决方案，吞吐量提升最高达3.81倍，尾部延迟降低最高达5.79倍。

Conclusion: Cornserve通过自动化的部署规划和高效的分布式运行时，成功解决了Any-to-Any多模态模型在线服务的异质性问题，显著提升了服务性能。

Abstract: We present Cornserve, an efficient online serving system for an emerging class of multimodal models called Any-to-Any models. Any-to-Any models accept combinations of text and multimodal data (e.g., image, video, audio) as input and also generate combinations of text and multimodal data as output, introducing request type, computation path, and computation scaling heterogeneity in model serving.
  Cornserve allows model developers to describe the computation graph of generic Any-to-Any models, which consists of heterogeneous components such as multimodal encoders, autoregressive models like Large Language Models (LLMs), and multimodal generators like Diffusion Transformers (DiTs). Given this, Cornserve's planner automatically finds an optimized deployment plan for the model, including whether and how to disaggregate the model into smaller components based on model and workload characteristics. Cornserve's distributed runtime then executes the model per the plan, efficiently handling Any-to-Any model heterogeneity during online serving. Evaluations show that Cornserve can efficiently serve diverse Any-to-Any models and workloads, delivering up to 3.81$\times$ throughput improvement and up to 5.79$\times$ tail latency reduction over existing solutions.

</details>


### [119] [A First-Order Logic-Based Alternative to Reward Models in RLHF](https://arxiv.org/abs/2512.14100)
*Chunjin Jian,Xinhua Zhu*

Main category: cs.LG

TL;DR: 提出S-GRPO框架，使用逻辑相似性奖励机制替代传统奖励建模，通过形式逻辑一致性引导大语言模型对齐人类偏好，避免模型崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法依赖奖励模型的质量和稳定性，而传统奖励建模存在启发式估计的局限性。需要一种更可靠的方法来引导大语言模型与人类价值观对齐。

Method: 提出基于逻辑相似性的奖励机制，利用形式逻辑一致性替代传统奖励估计。引入S-GRPO（GRPO的监督变体），包含额外监督组件，联合优化生成项、KL散度正则化和基于标签的目标函数。

Result: S-GRPO在性能和鲁棒性上均优于标准监督微调（SFT），并能扩展现有偏好学习框架（如GRPO和DPO），提供更灵活、任务自适应的对齐训练方法。

Conclusion: 逻辑相似性奖励机制和S-GRPO框架为RLHF提供了有效的替代方案，通过形式逻辑一致性实现更稳定、更灵活的大语言模型对齐。

Abstract: Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.
  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.
  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.

</details>


### [120] [Random-Bridges as Stochastic Transports for Generative Models](https://arxiv.org/abs/2512.14190)
*Stefano Goria,Levent A. Mengütürk,Murat C. Mengütürk,Berkan Sesen*

Main category: cs.LG

TL;DR: 论文提出使用随机桥（random-bridges）作为生成模型的新框架，通过条件随机过程连接两个概率分布，相比传统方法能以更少步骤生成高质量样本。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索随机桥在生成建模领域的应用潜力。随机桥作为条件随机过程，能够作为两个概率分布之间的随机传输工具，为生成模型提供新的理论框架和实现方法。

Method: 从一般概率陈述出发，推导出具体的学习和模拟算法表示。基于高斯随机桥构建模型，该框架可根据驱动过程表现出马尔可夫或非马尔可夫特性，以及连续、不连续或混合模式。

Result: 基于高斯随机桥的实验结果表明，该方法能以显著更少的步骤生成高质量样本，同时获得具有竞争力的Frechet inception distance分数。分析证明该框架计算成本低，适合高速生成任务。

Conclusion: 随机桥为生成建模提供了有效的理论框架，能够在保持样本质量的同时大幅减少生成步骤，具有计算效率高、适合高速生成任务的优点，为生成模型研究开辟了新方向。

Abstract: This paper motivates the use of random-bridges -- stochastic processes conditioned to take target distributions at fixed timepoints -- in the realm of generative modelling. Herein, random-bridges can act as stochastic transports between two probability distributions when appropriately initialized, and can display either Markovian or non-Markovian, and either continuous, discontinuous or hybrid patterns depending on the driving process. We show how one can start from general probabilistic statements and then branch out into specific representations for learning and simulation algorithms in terms of information processing. Our empirical results, built on Gaussian random bridges, produce high-quality samples in significantly fewer steps compared to traditional approaches, while achieving competitive Frechet inception distance scores. Our analysis provides evidence that the proposed framework is computationally cheap and suitable for high-speed generation tasks.

</details>


### [121] [Estimating problem difficulty without ground truth using Large Language Model comparisons](https://arxiv.org/abs/2512.14220)
*Marthe Ballon,Andres Algaba,Brecht Verbeken,Vincent Ginis*

Main category: cs.LG

TL;DR: 提出LLM compare方法，通过大语言模型进行成对难度比较，使用Bradley-Terry评分估计问题难度，解决现有方法无法评估超出分布问题的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有难度评估方法（如人工校准或基于性能的评分）无法推广到超出分布的问题（即人类和LLM目前无法解决的问题），因为这些方法不可扩展、耗时且依赖真实标签。

Method: LLM compare方法：让大语言模型进行成对难度比较，然后基于比较结果计算Bradley-Terry评分。该方法连续动态、模型无关且不依赖真实标签信息。

Result: 1) 概念框架验证：LLM compare占据所有理想象限；2) 与人类标注高度一致：Pearson r ≥ 0.80 (n=1876)；3) 对幻觉鲁棒：10%噪声注入下Pearson相关性下降小于6%。

Conclusion: LLM compare是第一个连续动态、模型无关且不依赖真实标签的难度评估方法，能有效替代耗时的人工标注和合成数据生成，对课程设计、模型评估和AI辅助研究构思有重要推动作用。

Abstract: Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\%$ degradation in Pearson correlation for $10\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.

</details>


### [122] [Physically consistent model learning for reaction-diffusion systems](https://arxiv.org/abs/2512.14240)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 该论文提出了一种从数据中学习反应-扩散系统的方法，确保学习到的模型具有物理一致性和适定性，通过修改参数化反应项来保证质量守恒和拟正性等物理性质。


<details>
  <summary>Details</summary>
Motivation: 从数据中学习反应-扩散系统时，需要确保学习到的模型不仅拟合数据，还要保持物理一致性（如质量守恒、拟正性）和数学适定性，以构建可解释且可靠的物理驱动模型。

Method: 基于正则化框架的结构化模型学习方法，提出系统修改参数化反应项的技术，使反应项天然满足质量守恒和拟正性；扩展理论结果，证明在学习过程中强制这些物理约束时，学习问题的解收敛到极限系统的唯一正则化最小化解。

Result: 开发了确保物理一致性的反应项修改技术，证明了在强制质量守恒和拟正性约束下学习问题的收敛性，提供了拟正性函数的逼近结果，为构建物理一致的参数化提供了理论基础。

Conclusion: 该方法能够从数据中学习出既符合物理定律又具有数学适定性的反应-扩散系统，推动了可解释、可靠的物理驱动模型的发展，确保学习到的模型保持非负性和物理原理。

Abstract: This paper addresses the problem of learning reaction-diffusion (RD) systems from data while ensuring physical consistency and well-posedness of the learned models. Building on a regularization-based framework for structured model learning, we focus on learning parameterized reaction terms and investigate how to incorporate key physical properties, such as mass conservation and quasipositivity, directly into the learning process. Our main contributions are twofold: First, we propose techniques to systematically modify a given class of parameterized reaction terms such that the resulting terms inherently satisfy mass conservation and quasipositivity, ensuring that the learned RD systems preserve non-negativity and adhere to physical principles. These modifications also guarantee well-posedness of the resulting PDEs under additional regularity and growth conditions. Second, we extend existing theoretical results on regularization-based model learning to RD systems using these physically consistent reaction terms. Specifically, we prove that solutions to the learning problem converge to a unique, regularization-minimizing solution of a limit system even when conservation laws and quasipositivity are enforced. In addition, we provide approximation results for quasipositive functions, essential for constructing physically consistent parameterizations. These results advance the development of interpretable and reliable data-driven models for RD systems that align with fundamental physical laws.

</details>


### [123] [Beyond MMD: Evaluating Graph Generative Models with Geometric Deep Learning](https://arxiv.org/abs/2512.14241)
*Salvatore Romano,Marco Grassia,Giuseppe Mangioni*

Main category: cs.LG

TL;DR: 本文提出了一种名为RGM的新方法，用于评估图生成模型，克服了传统MMD指标的局限性，并对GRAN和EDGE两种先进模型进行了全面评估。


<details>
  <summary>Details</summary>
Motivation: 图生成在许多领域都很重要，但现有图生成模型的评估主要依赖最大均值差异（MMD）指标，这种方法存在局限性，需要更有效的评估方法。

Method: 提出了RGM（Representation-aware Graph-generation Model evaluation）评估方法，使用几何深度学习模型在专门设计的合成和真实图数据集上进行图分类任务，全面评估GRAN和EDGE两种图生成模型。

Result: 研究发现，虽然GRAN和EDGE都能生成具有某些拓扑性质的图，但在保持区分不同图域的结构特征方面存在显著局限性。同时揭示了MMD作为图生成模型评估指标的不足。

Conclusion: 需要超越MMD的替代评估方法，RGM方法为图生成模型的评估提供了更全面的框架，未来研究应关注模型在保持图结构特征方面的能力。

Abstract: Graph generation is a crucial task in many fields, including network science and bioinformatics, as it enables the creation of synthetic graphs that mimic the properties of real-world networks for various applications. Graph Generative Models (GGMs) have emerged as a promising solution to this problem, leveraging deep learning techniques to learn the underlying distribution of real-world graphs and generate new samples that closely resemble them. Examples include approaches based on Variational Auto-Encoders, Recurrent Neural Networks, and more recently, diffusion-based models. However, the main limitation often lies in the evaluation process, which typically relies on Maximum Mean Discrepancy (MMD) as a metric to assess the distribution of graph properties in the generated ensemble. This paper introduces a novel methodology for evaluating GGMs that overcomes the limitations of MMD, which we call RGM (Representation-aware Graph-generation Model evaluation). As a practical demonstration of our methodology, we present a comprehensive evaluation of two state-of-the-art Graph Generative Models: Graph Recurrent Attention Networks (GRAN) and Efficient and Degree-guided graph GEnerative model (EDGE). We investigate their performance in generating realistic graphs and compare them using a Geometric Deep Learning model trained on a custom dataset of synthetic and real-world graphs, specifically designed for graph classification tasks. Our findings reveal that while both models can generate graphs with certain topological properties, they exhibit significant limitations in preserving the structural characteristics that distinguish different graph domains. We also highlight the inadequacy of Maximum Mean Discrepancy as an evaluation metric for GGMs and suggest alternative approaches for future research.

</details>


### [124] [FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting](https://arxiv.org/abs/2512.14253)
*Xingjian Wu,Hanyin Cheng,Xiangfei Qiu,Zhengyu Li,Jilin Hu,Chenjuan Guo,Bin Yang*

Main category: cs.LG

TL;DR: FLAME是一个轻量级时间序列基础模型家族，支持确定性和概率性预测，通过生成式概率建模确保效率和鲁棒性，在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发一个既轻量又强大的时间序列基础模型，能够同时处理确定性和概率性预测任务，在保持高效率的同时提供准确的预测结果。

Method: 使用Legendre Memory增强泛化能力，通过LegT和LegS变体在编码和解码阶段捕捉数据内在归纳偏差；采用归一化流作为预测头，以生成方式建模任意复杂分布。

Result: 在TSFM-Bench和ProbTS等基准测试中，FLAME在确定性和概率性预测任务上都表现出最先进的零样本性能。

Conclusion: FLAME是一个高效、轻量且强大的时间序列基础模型，通过Legendre Memory和归一化流技术，在确定性和概率性预测任务中均取得了优异表现。

Abstract: In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.

</details>


### [125] [Black-Box Auditing of Quantum Model: Lifted Differential Privacy with Quantum Canaries](https://arxiv.org/abs/2512.14388)
*Baobao Song,Shiva Raj Pokhrel,Athanasios V. Vasilakos,Tianqing Zhu,Gang Li*

Main category: cs.LG

TL;DR: 首个基于提升量子差分隐私的黑盒隐私审计框架，通过量子金丝雀检测QML模型记忆化并量化隐私泄露


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在敏感数据训练时存在记忆个体记录的风险，现有量子差分隐私机制缺乏对部署模型的实证验证工具

Method: 基于提升量子差分隐私的黑盒隐私审计框架，使用量子金丝雀（策略性偏移编码的量子态）检测记忆化，建立金丝雀偏移与迹距离界限的数学联系

Result: 框架在模拟和物理量子硬件上全面评估，有效测量QML模型的实际隐私损失，为理论保证与实际隐私验证之间搭建桥梁

Conclusion: 该框架实现了QML系统中强大的隐私验证，填补了量子差分隐私理论保证与实证验证之间的关键空白

Abstract: Quantum machine learning (QML) promises significant computational advantages, yet models trained on sensitive data risk memorizing individual records, creating serious privacy vulnerabilities. While Quantum Differential Privacy (QDP) mechanisms provide theoretical worst-case guarantees, they critically lack empirical verification tools for deployed models. We introduce the first black-box privacy auditing framework for QML based on Lifted Quantum Differential Privacy, leveraging quantum canaries (strategically offset-encoded quantum states) to detect memorization and precisely quantify privacy leakage during training. Our framework establishes a rigorous mathematical connection between canary offset and trace distance bounds, deriving empirical lower bounds on privacy budget consumption that bridge the critical gap between theoretical guarantees and practical privacy verification. Comprehensive evaluations across both simulated and physical quantum hardware demonstrate our framework's effectiveness in measuring actual privacy loss in QML models, enabling robust privacy verification in QML systems.

</details>


### [126] [GRAFT: Grid-Aware Load Forecasting with Multi-Source Textual Alignment and Fusion](https://arxiv.org/abs/2512.14400)
*Fangzhou Lin,Guoshun He,Zhenyu Guo,Zhe Huang,Jinsong Tao*

Main category: cs.LG

TL;DR: GRAFT模型通过文本引导的跨注意力机制，将多源文本信息与电力负荷数据对齐，实现电网感知预测，并在澳大利亚五州数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 电力负荷同时受到天气、日历节奏、突发事件和政策等多时间尺度外生因素的影响，需要开发能够有效整合多源文本信息的电网感知预测方法。

Method: 提出GRAFT模型，改进STanHOP以支持电网感知预测和多源文本干预：1) 将每日聚合的新闻、社交媒体和政策文本与半小时负荷严格对齐；2) 通过跨注意力机制实现文本引导的融合到特定时间位置；3) 提供即插即用的外部记忆接口以适应不同信息源。

Result: 在澳大利亚五州2019-2021年数据集上，GRAFT在小时、日和月三个时间尺度上显著优于强基线方法，达到或超越最先进水平。模型在事件驱动场景中表现稳健，并能通过注意力机制实现文本到负荷效应的时空定位和源级解释。

Conclusion: GRAFT通过文本引导的跨注意力机制有效整合多源文本信息，显著提升电力负荷预测性能，同时提供可解释性和部署灵活性，为电网预测研究提供了标准化评估基准。

Abstract: Electric load is simultaneously affected across multiple time scales by exogenous factors such as weather and calendar rhythms, sudden events, and policies. Therefore, this paper proposes GRAFT (GRid-Aware Forecasting with Text), which modifies and improves STanHOP to better support grid-aware forecasting and multi-source textual interventions. Specifically, GRAFT strictly aligns daily-aggregated news, social media, and policy texts with half-hour load, and realizes text-guided fusion to specific time positions via cross-attention during both training and rolling forecasting. In addition, GRAFT provides a plug-and-play external-memory interface to accommodate different information sources in real-world deployment. We construct and release a unified aligned benchmark covering 2019--2021 for five Australian states (half-hour load, daily-aligned weather/calendar variables, and three categories of external texts), and conduct systematic, reproducible evaluations at three scales -- hourly, daily, and monthly -- under a unified protocol for comparison across regions, external sources, and time scales. Experimental results show that GRAFT significantly outperforms strong baselines and reaches or surpasses the state of the art across multiple regions and forecasting horizons. Moreover, the model is robust in event-driven scenarios and enables temporal localization and source-level interpretation of text-to-load effects through attention read-out. We release the benchmark, preprocessing scripts, and forecasting results to facilitate standardized empirical evaluation and reproducibility in power grid load forecasting.

</details>


### [127] [Bridging Artificial Intelligence and Data Assimilation: The Data-driven Ensemble Forecasting System ClimaX-LETKF](https://arxiv.org/abs/2512.14444)
*Akira Takeshima,Kenta Shiraishi,Atsushi Okazaki,Tadashi Tsuyuki,Shunji Kotsuki*

Main category: cs.LG

TL;DR: ClimaX-LETKF是首个纯数据驱动的机器学习集合天气预报系统，能够稳定运行多年，独立于传统数值天气预报模型，通过同化NCEP ADP全球高空和地面天气观测数据工作。


<details>
  <summary>Details</summary>
Motivation: 虽然机器学习天气预报取得了显著进展，但在MLWP模型中同化实际观测数据或集合预报的研究仍然有限。需要开发能够独立于传统数值天气预报模型、稳定运行的纯数据驱动集合预报系统。

Method: 开发了ClimaX-LETKF系统，这是首个纯数据驱动的机器学习集合天气预报系统。系统采用局部集合变换卡尔曼滤波（LETKF）同化NCEP ADP全球高空和地面天气观测数据，比较了松弛到先验扰动（RTPP）和松弛到先验扩展（RTPS）两种方法的稳定性。

Result: ClimaX-LETKF系统能够稳定运行多年，独立于传统NWP模型。实验表明，RTPP方法比RTPS方法在MLWP模型中提供更好的稳定性和准确性，这与传统NWP模型（通常RTPS更稳定）形成对比。研究发现MLWP模型恢复大气场到其吸引子的能力不如NWP模型。

Conclusion: 这项工作为增强MLWP集合预报系统提供了宝贵见解，代表了向实际应用迈出的重要一步。研究揭示了MLWP模型与NWP模型在集合预报同化方面的不同特性，特别是RTPP在MLWP中的优势。

Abstract: While machine learning-based weather prediction (MLWP) has achieved significant advancements, research on assimilating real observations or ensemble forecasts within MLWP models remains limited. We introduce ClimaX-LETKF, the first purely data-driven ML-based ensemble weather forecasting system. It operates stably over multiple years, independently of numerical weather prediction (NWP) models, by assimilating the NCEP ADP Global Upper Air and Surface Weather Observations. The system demonstrates greater stability and accuracy with relaxation to prior perturbation (RTPP) than with relaxation to prior spread (RTPS), while NWP models tend to be more stable with RTPS. RTPP replaces an analysis perturbation with a weighted blend of analysis and background perturbations, whereas RTPS simply rescales the analysis perturbation. Our experiments reveal that MLWP models are less capable of restoring the atmospheric field to its attractor than NWP models. This work provides valuable insights for enhancing MLWP ensemble forecasting systems and represents a substantial step toward their practical applications.

</details>


### [128] [Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection](https://arxiv.org/abs/2512.14563)
*Tejaswani Dash,Gautam Datla,Anudeep Vurity,Tazeem Ahmad,Mohd Adnan,Saima Rafi,Saisha Patro,Saina Patro*

Main category: cs.LG

TL;DR: 提出Residual GRU with Multi-Head Self-Attention模型，用于心血管疾病预测，在UCI心脏病数据集上表现优于传统方法和现代深度学习基线。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死亡原因，需要可靠高效的预测工具。传统方法依赖手工特征和临床专家经验，机器学习方法可提高可重复性但难以在噪声和异质临床数据上泛化。

Method: 提出紧凑深度学习架构：集成残差双向门控循环单元用于特征列的序列建模、通道重加权块、带可学习分类令牌的多头自注意力池化以捕获全局上下文。

Result: 在UCI心脏病数据集上，模型准确率0.861，宏F1 0.860，ROC-AUC 0.908，PR-AUC 0.904，优于所有基线。消融研究确认各组件贡献，t-SNE可视化显示学习嵌入比原始特征有更清晰的疾病/非疾病分离。

Conclusion: 轻量级混合循环和注意力架构在临床风险预测中提供了准确性和效率的良好平衡，支持在资源受限的医疗环境中部署。

Abstract: Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.

</details>


### [129] [Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes](https://arxiv.org/abs/2512.14617)
*Alessandro Trapasso,Luca Iocchi,Fabio Patrizi*

Main category: cs.LG

TL;DR: QR-MAX算法首次为离散非马尔可夫奖励决策过程提供了具有多项式样本复杂度的PAC收敛保证，并通过Bucket-QR-MAX扩展到连续状态空间，显著提升了样本效率和策略最优性。


<details>
  <summary>Details</summary>
Motivation: 许多实际决策问题涉及依赖整个系统历史的任务，而不仅仅是达到具有期望属性的状态。马尔可夫强化学习方法不适用于此类任务，而非马尔可夫奖励决策过程（NMRDPs）虽然能处理时间依赖任务，但长期以来缺乏形式化保证。

Method: 提出QR-MAX算法，通过奖励机将马尔可夫转移学习与非马尔可夫奖励处理分离。然后扩展到连续状态空间的Bucket-QR-MAX，使用SimHash离散化器保持相同的分解结构，无需手动网格划分或函数逼近。

Result: QR-MAX是首个为离散动作NMRDPs提供多项式样本复杂度ε-最优策略PAC收敛的模型强化学习算法。在复杂度递增的环境实验中，相比最先进的模型强化学习方法，样本效率显著提升，寻找最优策略的鲁棒性增强。

Conclusion: 该研究解决了NMRDPs中长期缺乏形式化保证的问题，通过分解方法实现了高效学习，为处理时间依赖决策任务提供了理论保证和实用算法。

Abstract: Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.

</details>


### [130] [Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics](https://arxiv.org/abs/2512.14471)
*Additi Pandey,Liang Wei,Hessam Babaee,George Em Karniadakis*

Main category: cs.LG

TL;DR: Kinetic-Mamba是一个基于Mamba架构的神经算子框架，用于化学动力学建模，包含三种模型变体，通过时间分解和递归预测策略在合成气和GRI-Mech 3.0反应机制上验证了高精度预测能力。


<details>
  <summary>Details</summary>
Motivation: 准确的化学动力学建模对于燃烧模拟至关重要，因为它控制着复杂反应路径和热化学状态的演化。传统方法在计算效率和精度方面存在挑战，需要开发能够准确预测动力学行为的新框架。

Method: 提出了Kinetic-Mamba框架，包含三种模型：1）独立Mamba模型预测热化学状态变量的时间演化；2）约束Mamba模型在保持质量守恒的同时学习状态动力学；3）基于温度区间的双Mamba模型架构。还开发了在降维潜在空间中演化动力学的潜在变体。使用时间分解和递归预测策略进行评估。

Result: 在Syngas和GRI-Mech 3.0反应机制上的计算实验表明，该框架仅使用状态变量的初始条件就能高保真地预测复杂的动力学行为，并展示了在分布外数据集上的良好外推能力。

Conclusion: Kinetic-Mamba框架成功地将神经算子的表达能力与Mamba架构的高效时间建模能力相结合，为化学动力学模拟提供了准确且计算高效的解决方案，在燃烧模拟领域具有重要应用价值。

Abstract: Accurate chemical kinetics modeling is essential for combustion simulations, as it governs the evolution of complex reaction pathways and thermochemical states. In this work, we introduce Kinetic-Mamba, a Mamba-based neural operator framework that integrates the expressive power of neural operators with the efficient temporal modeling capabilities of Mamba architectures. The framework comprises three complementary models: (i) a standalone Mamba model that predicts the time evolution of thermochemical state variables from given initial conditions; (ii) a constrained Mamba model that enforces mass conservation while learning the state dynamics; and (iii) a regime-informed architecture employing two standalone Mamba models to capture dynamics across temperature-dependent regimes. We additionally develop a latent Kinetic-Mamba variant that evolves dynamics in a reduced latent space and reconstructs the full state on the physical manifold. We evaluate the accuracy and robustness of Kinetic-Mamba using both time-decomposition and recursive-prediction strategies. We further assess the extrapolation capabilities of the model on varied out-of-distribution datasets. Computational experiments on Syngas and GRI-Mech 3.0 reaction mechanisms demonstrate that our framework achieves high fidelity in predicting complex kinetic behavior using only the initial conditions of the state variables.

</details>


### [131] [gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation](https://arxiv.org/abs/2512.14658)
*Alban Puech,Matteo Mazzonelli,Celia Cintas,Tamara R. Govindasamy,Mangaliso Mngomezulu,Jonas Weiss,Matteo Baù,Anna Varbella,François Mirallès,Kibaek Kim,Le Xie,Hendrik F. Hamann,Etienne Vos,Thomas Brunschwiler*

Main category: cs.LG

TL;DR: gridfm-datakit-v1是一个Python库，用于生成真实多样的电力潮流和最优潮流数据集，解决了现有工具在场景多样性、运行限制和成本函数方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有电力系统数据集面临三个主要挑战：1) 缺乏真实的随机负荷和拓扑扰动，限制了场景多样性；2) PF数据集仅限于OPF可行点，阻碍了ML求解器对违反运行限制情况的泛化；3) OPF数据集使用固定发电机成本函数，限制了成本变化下的泛化能力。

Method: 通过结合真实世界负荷曲线的全局负荷缩放与局部噪声，支持任意N-k拓扑扰动来创建多样且真实的数据集；生成超出运行限制的PF样本；生成具有变化发电机成本的OPF数据；并能高效扩展到大型电网（最多10,000个节点）。

Result: 开发了gridfm-datakit-v1库，与OPFData、OPF-Learn、PGLearn和PFΔ等现有工具进行了比较。该库在GitHub上开源，采用Apache 2.0许可证，可通过pip安装。

Conclusion: gridfm-datakit解决了现有电力系统数据生成工具的局限性，提供了更真实、多样和可扩展的数据集生成能力，有助于训练更鲁棒的机器学习求解器。

Abstract: We introduce gridfm-datakit-v1, a Python library for generating realistic and diverse Power Flow (PF) and Optimal Power Flow (OPF) datasets for training Machine Learning (ML) solvers. Existing datasets and libraries face three main challenges: (1) lack of realistic stochastic load and topology perturbations, limiting scenario diversity; (2) PF datasets are restricted to OPF-feasible points, hindering generalization of ML solvers to cases that violate operating limits (e.g., branch overloads or voltage violations); and (3) OPF datasets use fixed generator cost functions, limiting generalization across varying costs. gridfm-datakit addresses these challenges by: (1) combining global load scaling from real-world profiles with localized noise and supporting arbitrary N-k topology perturbations to create diverse yet realistic datasets; (2) generating PF samples beyond operating limits; and (3) producing OPF data with varying generator costs. It also scales efficiently to large grids (up to 10,000 buses). Comparisons with OPFData, OPF-Learn, PGLearn, and PF$Δ$ are provided. Available on GitHub at https://github.com/gridfm/gridfm-datakit under Apache 2.0 and via `pip install gridfm-datakit`.

</details>


### [132] [Bias-Variance Trade-off for Clipped Stochastic First-Order Methods: From Bounded Variance to Infinite Mean](https://arxiv.org/abs/2512.14686)
*Chuan He*

Main category: cs.LG

TL;DR: 该论文研究了在重尾噪声（尾指数α∈(0,2]）下的随机一阶方法，通过梯度裁剪的偏差-方差权衡分析，为全范围尾指数建立了统一的复杂度保证。


<details>
  <summary>Details</summary>
Motivation: 现有随机优化方法主要研究轻尾噪声，对重尾噪声的研究多限于α∈(1,2]范围（有限均值），当α接近1时复杂度趋于无穷。实际应用中常出现更重的尾分布（包括无限均值情况），需要更全面的理论分析。

Method: 采用梯度裁剪技术控制重尾梯度，通过新颖的偏差-方差权衡分析，在噪声尾部对称性受控的条件下，为裁剪后的随机一阶方法建立复杂度保证。

Result: 证明了当噪声尾部对称性受控时，裁剪的随机一阶方法在任意尾指数α∈(0,2]的重尾噪声下都能获得改进的复杂度保证，覆盖了从有界方差到无限均值的全范围噪声情况。

Conclusion: 通过梯度裁剪的偏差-方差分析，为随机一阶方法在重尾噪声下的性能提供了统一的理论框架，填补了无限均值噪声情况的研究空白，并通过数值实验验证了理论结果。

Abstract: Stochastic optimization is fundamental to modern machine learning. Recent research has extended the study of stochastic first-order methods (SFOMs) from light-tailed to heavy-tailed noise, which frequently arises in practice, with clipping emerging as a key technique for controlling heavy-tailed gradients. Extensive theoretical advances have further shown that the oracle complexity of SFOMs depends on the tail index $α$ of the noise. Nonetheless, existing complexity results often cover only the case $α\in (1,2]$, that is, the regime where the noise has a finite mean, while the complexity bounds tend to infinity as $α$ approaches $1$. This paper tackles the general case of noise with tail index $α\in(0,2]$, covering regimes ranging from noise with bounded variance to noise with an infinite mean, where the latter case has been scarcely studied. Through a novel analysis of the bias-variance trade-off in gradient clipping, we show that when a symmetry measure of the noise tail is controlled, clipped SFOMs achieve improved complexity guarantees in the presence of heavy-tailed noise for any tail index $α\in (0,2]$. Our analysis of the bias-variance trade-off not only yields new unified complexity guarantees for clipped SFOMs across this full range of tail indices, but is also straightforward to apply and can be combined with classical analyses under light-tailed noise to establish oracle complexity guarantees under heavy-tailed noise. Finally, numerical experiments validate our theoretical findings.

</details>


### [133] [Synthetic Electrogram Generation with Variational Autoencoders for ECGI](https://arxiv.org/abs/2512.14537)
*Miriam Gutiérrez Fernández,Karen López-Linares,Carlos Fambuena Santos,María S. Guillem,Andreu M. Climent,Óscar Barquero Pérez*

Main category: cs.LG

TL;DR: 该研究使用变分自编码器生成合成心房电图，以解决心房颤动非侵入性成像中配对数据稀缺的问题，并通过数据增强提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 心房颤动是最常见的心律失常，需要准确评估心房电活动。虽然体表电位图与深度学习结合用于估计心内电图有前景，但配对数据集的稀缺限制了进展。

Method: 提出两种变分自编码器模型：窦性心律专用VAE（VAE-S）和类别条件VAE（VAE-C），后者可同时处理窦性心律和房颤信号。通过形态学、频谱和分布相似性指标评估生成的心电图。

Result: VAE-S在模拟心电图上实现更高的保真度，而VAE-C能够进行节律特异性生成，但窦性心律重建质量有所下降。数据增强实验表明，适度的增强能改善下游非侵入性心电图重建任务的性能。

Conclusion: 基于VAE的生成模型有潜力缓解数据稀缺问题，增强基于深度学习的非侵入性心电图成像流程，为心房颤动的临床评估提供支持。

Abstract: Atrial fibrillation (AF) is the most prevalent sustained cardiac arrhythmia, and its clinical assessment requires accurate characterization of atrial electrical activity. Noninvasive electrocardiographic imaging (ECGI) combined with deep learning (DL) approaches for estimating intracardiac electrograms (EGMs) from body surface potentials (BSPMs) has shown promise, but progress is hindered by the limited availability of paired BSPM-EGM datasets. To address this limitation, we investigate variational autoencoders (VAEs) for the generation of synthetic multichannel atrial EGMs. Two models are proposed: a sinus rhythm-specific VAE (VAE-S) and a class-conditioned VAE (VAE-C) trained on both sinus rhythm and AF signals. Generated EGMs are evaluated using morphological, spectral, and distributional similarity metrics. VAE-S achieves higher fidelity with respect to in silico EGMs, while VAE-C enables rhythm-specific generation at the expense of reduced sinus reconstruction quality. As a proof of concept, the generated EGMs are used for data augmentation in a downstream noninvasive EGM reconstruction task, where moderate augmentation improves estimation performance. These results demonstrate the potential of VAE-based generative modeling to alleviate data scarcity and enhance deep learning-based ECGI pipelines.

</details>


### [134] [Counterfactual Explanations for Time Series Should be Human-Centered and Temporally Coherent in Interventions](https://arxiv.org/abs/2512.14559)
*Emmanuel C. Chukwu,Rianne M. Schouten,Monique Tabak,Mykola Pechenizkiy*

Main category: cs.LG

TL;DR: 该论文批评现有时间序列反事实解释方法在临床推荐场景中的不足，主张开发更注重因果合理性、时间连贯性和用户可行性的反事实干预方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列反事实解释方法主要基于静态数据假设，仅关注最小化输入扰动以改变模型预测，这在临床推荐场景中不够充分，因为临床干预需要随时间展开，且必须具有因果合理性和时间连贯性。

Method: 通过分析现有方法的局限性（时间盲点和缺乏用户中心考虑），并对几种最先进的时间序列反事实方法进行鲁棒性分析，展示其对随机噪声的高度敏感性。

Result: 研究发现生成的反事实解释对随机噪声高度敏感，在真实临床环境中可靠性有限，因为微小测量变异不可避免。

Conclusion: 呼吁开发超越单纯预测改变的方法和评估框架，强调需要可行、目的驱动的干预措施，在真实世界场景中对用户具有可操作性。

Abstract: Counterfactual explanations are increasingly proposed as interpretable mechanisms to achieve algorithmic recourse. However, current counterfactual techniques for time series classification are predominantly designed with static data assumptions and focus on generating minimal input perturbations to flip model predictions. This paper argues that such approaches are fundamentally insufficient in clinical recommendation settings, where interventions unfold over time and must be causally plausible and temporally coherent. We advocate for a shift towards counterfactuals that reflect sustained, goal-directed interventions aligned with clinical reasoning and patient-specific dynamics. We identify critical gaps in existing methods that limit their practical applicability, specifically, temporal blind spots and the lack of user-centered considerations in both method design and evaluation metrics. To support our position, we conduct a robustness analysis of several state-of-the-art methods for time series and show that the generated counterfactuals are highly sensitive to stochastic noise. This finding highlights their limited reliability in real-world clinical settings, where minor measurement variations are inevitable. We conclude by calling for methods and evaluation frameworks that go beyond mere prediction changes without considering feasibility or actionability. We emphasize the need for actionable, purpose-driven interventions that are feasible in real-world contexts for the users of such applications.

</details>


### [135] [ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning](https://arxiv.org/abs/2512.14619)
*Chaohao Yuan,Zhenjie Song,Ercan Engin Kuruoglu,Kangfei Zhao,Yang Liu,Deli Zhao,Hong Cheng,Yu Rong*

Main category: cs.LG

TL;DR: ParaFormer通过PageRank增强的注意力机制解决图Transformer中的过平滑问题，在节点和图分类任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 图Transformer虽然能捕捉全局信息，但研究发现其全局注意力机制存在严重的过平滑问题，导致节点表示变得难以区分，甚至比GNNs的过平滑效应更强

Method: 提出PageRank Transformer (ParaFormer)，采用PageRank增强的注意力模块来模拟深度Transformer的行为，作为自适应滤波器缓解过平滑

Result: 在11个从数千到数百万节点的数据集上，ParaFormer在节点分类和图分类任务中均取得一致的性能提升

Conclusion: ParaFormer通过PageRank增强的注意力机制有效缓解了图Transformer中的过平滑问题，在多种图学习任务上表现出色

Abstract: Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.

</details>


### [136] [Early Warning Index for Patient Deteriorations in Hospitals](https://arxiv.org/abs/2512.14683)
*Dimitris Bertsimas,Yu Ma,Kimberly Villalobos Carballo,Gagan Singh,Michal Laskowski,Jeff Mather,Dan Kombert,Howard Haronian*

Main category: cs.LG

TL;DR: 开发了一个多模态机器学习框架EWI，通过整合临床和运营数据预测ICU入院、紧急响应团队派遣和死亡率的综合风险，并在医院仪表板中部署为风险分层工具。


<details>
  <summary>Details</summary>
Motivation: 医院缺乏自动化系统来利用日益增长的异构临床和运营数据有效预测关键事件。早期识别有恶化风险的患者对患者护理质量监测和医生护理管理至关重要，但将不同数据流转化为准确且可解释的风险评估面临数据格式不一致的挑战。

Method: 开发了多模态机器学习框架EWI，采用人机协作流程：临床医生帮助确定警报阈值和解释模型输出，通过SHAP可解释性方法突出显示驱动每个患者风险的临床和运营因素。从结构化和非结构化电子健康记录数据中自动提取特征。

Result: 在美国一家大型医院的18,633名患者数据集上，EWI实现了C统计量0.796的性能，将患者分为三个风险等级，目前作为主动管理风险患者的分类工具使用。

Conclusion: EWI通过自动对患者进行风险分层，节省医生宝贵时间，使他们能专注于患者护理而非筛选复杂EHR数据。通过识别特定风险驱动因素，为护理人员排班和关键资源分配提供数据支持，从而预防下游并发症并改善整体患者流程。

Abstract: Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learning framework, the Early Warning Index (EWI), to predict the aggregate risk of ICU admission, emergency response team dispatch, and mortality. Key to EWI's design is a human-in-the-loop process: clinicians help determine alert thresholds and interpret model outputs, which are enhanced by explainable outputs using Shapley Additive exPlanations (SHAP) to highlight clinical and operational factors (e.g., scheduled surgeries, ward census) driving each patient's risk. We deploy EWI in a hospital dashboard that stratifies patients into three risk tiers. Using a dataset of 18,633 unique patients at a large U.S. hospital, our approach automatically extracts features from both structured and unstructured electronic health record (EHR) data and achieves C-statistics of 0.796. It is currently used as a triage tool for proactively managing at-risk patients. The proposed approach saves physicians valuable time by automatically sorting patients of varying risk levels, allowing them to concentrate on patient care rather than sifting through complex EHR data. By further pinpointing specific risk drivers, the proposed model provides data-informed adjustments to caregiver scheduling and allocation of critical resources. As a result, clinicians and administrators can avert downstream complications, including costly procedures or high readmission rates and improve overall patient flow.

</details>
