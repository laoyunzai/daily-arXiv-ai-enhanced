<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 5]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 4]
- [cs.AI](#cs.AI) [Total: 4]
- [quant-ph](#quant-ph) [Total: 6]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 4]
- [cs.CC](#cs.CC) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Latent Context Compilation: Distilling Long Context into Compact Portable Memory](https://arxiv.org/abs/2602.21221)
*Zeju Li,Yizhou Zhou,Qiang Xu*

Main category: cs.LG

TL;DR: 提出Latent Context Compilation框架，用一次性LoRA模块将长上下文蒸馏为与冻结模型即插即用的无状态缓冲token，通过自对齐优化策略消除对合成数据的需求，在16倍压缩率下保持推理能力


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM部署面临两难：摊销压缩泛化能力差，测试时训练需修改权重且合成数据成本过高，产生有状态参数导致并发服务复杂化

Method: 将上下文处理从适配转向编译，利用一次性LoRA模块作为编译器，将长上下文压缩为紧凑的无状态token；通过上下文无关随机查询正则化重建任务，强制压缩token落在模型原有指令遵循流形中，无需合成QA对

Result: Llama-3.1-8B实验显示该方法在16倍压缩率下仍保持细粒度细节和推理能力，有效解耦记忆密度与模型参数，优于先前方法

Conclusion: 该框架实现了长上下文的无状态、便携式记忆，为高效LLM部署提供了即插即用的解决方案，突破了现有方法的局限性

Abstract: Efficient long-context LLM deployment is stalled by a dichotomy between amortized compression, which struggles with out-of-distribution generalization, and Test-Time Training, which incurs prohibitive synthetic data costs and requires modifying model weights, creating stateful parameters that complicate concurrent serving. We propose Latent Context Compilation, a framework that fundamentally shifts context processing from adaptation to compilation. By utilizing a disposable LoRA module as a compiler, we distill long contexts into compact buffer tokens -- stateless, portable memory artifacts that are plug-and-play compatible with frozen base models. Crucially, we introduce a self-aligned optimization strategy that eliminates the need for synthetic context-relevant QA pairs. By regularizing context reconstruction task with context-agnostic random queries, we force compressed tokens to reside within the model's existing instruction-following manifold. Experiments with Llama-3.1-8B demonstrate that Latent Context Compilation preserves fine-grained details and reasoning capabilities where prior methods falter, effectively decoupling memory density from model parameters even at a 16x compression ratio.

</details>


### [2] [Urban Vibrancy Embedding and Application on Traffic Prediction](https://arxiv.org/abs/2602.21232)
*Sumin Han,Jisun An,Dongman Lee*

Main category: cs.LG

TL;DR: 提出基于变分自编码器(VAE)从实时人口流动数据中提取城市活力嵌入表示，结合LSTM预测后用于交通预测模型，显著提升预测精度和实时性


<details>
  <summary>Details</summary>
Motivation: 现有交通预测模型难以有效捕捉城市动态人类活动特征，而移动数据蕴含的实时人口流动信息可反映城市活力，但缺乏高效利用方法

Method: 1) 用VAE压缩实时人口流动数据生成城市活力嵌入；2) 用LSTM预测未来嵌入序列；3) 在Seq2Seq框架中集成嵌入进行交通预测；4) 通过PCA解析嵌入的时间模式

Result: 所提方法在RNN/DCRNN/GTS/GMAN等模型上均提升精度与响应性，PCA揭示嵌入包含工作日/周末及季节性规律

Conclusion: 城市活力嵌入能有效增强交通预测能力，为城市 mobility 分析提供更精细化的动态知识表示方法

Abstract: Urban vibrancy reflects the dynamic human activity within urban spaces and is often measured using mobile data that captures floating population trends. This study proposes a novel approach to derive Urban Vibrancy embeddings from real-time floating population data to enhance traffic prediction models. Specifically, we utilize variational autoencoders (VAE) to compress this data into actionable embeddings, which are then integrated with long short-term memory (LSTM) networks to predict future embeddings. These are subsequently applied in a sequence-to-sequence framework for traffic forecasting. Our contributions are threefold: (1) We use principal component analysis (PCA) to interpret the embeddings, revealing temporal patterns such as weekday versus weekend distinctions and seasonal patterns; (2) We propose a method that combines VAE and LSTM, enabling forecasting dynamic urban knowledge embedding; and (3) Our approach improves accuracy and responsiveness in traffic prediction models, including RNN, DCRNN, GTS, and GMAN. This study demonstrates the potential of Urban Vibrancy embeddings to advance traffic prediction and offer a more nuanced analysis of urban mobility.

</details>


### [3] [Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data](https://arxiv.org/abs/2602.21320)
*Emre Can Acikgoz,Cheng Qian,Jonas Hübotter,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.LG

TL;DR: 提出Tool-R0框架，通过自我对弈强化学习从零开始训练通用工具调用智能体，无需预存任务或数据集，让生成器与求解器相互挑战促进自进化，在基准测试中相对基线模型提升92.5%并超越监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法训练LLM智能体依赖精心构建的任务-解对和大量人工监督，这阻碍了向超级智能系统的开放-ended自进化。需要在零数据假设下实现通用工具调用智能体的自主演进。

Method: Tool-R0框架采用自我对弈强化学习，从零开始共同演化一个生成器和一个求解器。生成器负责在求解器的能力边界提出针对性挑战任务，求解器通过真实世界工具调用来解决这些任务，形成互补奖励机制的自我进化循环。

Result: 在不同工具使用基准测试中，Tool-R0相比基础模型获得92.5%的相对性能提升，并在相同设置下超越了完全监督的工具调用基线方法。

Conclusion: 该工作证明无需人工监督的自我进化循环可构建通用工具调用智能体，并通过分析共同演化、课程动态和扩展行为，为自我对弈LLM智能体提供了实证洞察。

Abstract: Large language models (LLMs) are becoming the foundation for autonomous agents that can use tools to solve complex tasks. Reinforcement learning (RL) has emerged as a common approach for injecting such agentic capabilities, but typically under tightly controlled training setups. It often depends on carefully constructed task-solution pairs and substantial human supervision, which creates a fundamental obstacle to open-ended self-evolution toward superintelligent systems. In this paper, we propose Tool-R0 framework for training general purpose tool-calling agents from scratch with self-play RL, under a zero-data assumption. Initialized from the same base LLM, Tool-R0 co-evolves a Generator and a Solver with complementary rewards: one proposes targeted challenging tasks at the other's competence frontier and the other learns to solve them with real-world tool calls. This creates a self-evolving cycle that requires no pre-existing tasks or datasets. Evaluation on different tool-use benchmarks show that Tool-R0 yields 92.5 relative improvement over the base model and surpasses fully supervised tool-calling baselines under the same setting. Our work further provides empirical insights into self-play LLM agents by analyzing co-evolution, curriculum dynamics, and scaling behavior.

</details>


### [4] [AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression](https://arxiv.org/abs/2602.21233)
*Rui Cen,QiangQiang Hu,Hong Huang,Hong Liu,Song Liu,Xin Luo,Lin Niu,Yifan Tan,Decheng Wu,Linchuan Xie,Rubing Yang,Guanghua Yu,Jianchen Zhu*

Main category: cs.LG

TL;DR: AngelSlim是腾讯混元团队开发的大模型压缩工具包，集成量化、推测解码、令牌剪枝和蒸馏等算法，提供从压缩到工业部署的统一流程，实现1.8-2.0倍吞吐提升和长上下文首Token延迟降低。


<details>
  <summary>Details</summary>
Motivation: 解决大模型工业部署中的效率瓶颈，通过统一工具包整合前沿压缩技术，降低部署成本并提升推理性能。

Method: 1. 采用FP8/INT8后训练量化及2-bit超低比特量化（HY-1.8B-int2）；2. 训练对齐的推测解码框架；3. 无训练稀疏注意力机制；4. 多模态专用剪枝策略（IDPruner优化视觉令牌，Samp处理音频令牌）。

Result: 1. 推测解码实现1.8-2.0倍吞吐量提升；2. 稀疏注意力降低长上下文场景首Token生成时间（TTFT）；3. 首次实现工业级2-bit大模型部署。

Conclusion: AngelSlim通过算法与工程协同优化，为研究者和开发者提供从压缩算法验证到工业部署的全流程支持，显著提升大模型推理效率。

Abstract: This technical report introduces AngelSlim, a comprehensive and versatile toolkit for large model compression developed by the Tencent Hunyuan team. By consolidating cutting-edge algorithms, including quantization, speculative decoding, token pruning, and distillation. AngelSlim provides a unified pipeline that streamlines the transition from model compression to industrial-scale deployment. To facilitate efficient acceleration, we integrate state-of-the-art FP8 and INT8 Post-Training Quantization (PTQ) algorithms alongside pioneering research in ultra-low-bit regimes, featuring HY-1.8B-int2 as the first industrially viable 2-bit large model. Beyond quantization, we propose a training-aligned speculative decoding framework compatible with multimodal architectures and modern inference engines, achieving 1.8x to 2.0x throughput gains without compromising output correctness. Furthermore, we develop a training-free sparse attention framework that reduces Time-to-First-Token (TTFT) in long-context scenarios by decoupling sparse kernels from model architectures through a hybrid of static patterns and dynamic token selection. For multimodal models, AngelSlim incorporates specialized pruning strategies, namely IDPruner for optimizing vision tokens via Maximal Marginal Relevance and Samp for adaptive audio token merging and pruning. By integrating these compression strategies from low-level implementations, AngelSlim enables algorithm-focused research and tool-assisted deployment.

</details>


### [5] [Group Orthogonalized Policy Optimization:Group Policy Optimization as Orthogonal Projection in Hilbert Space](https://arxiv.org/abs/2602.21269)
*Wang Zixian*

Main category: cs.LG

TL;DR: GOPO is a novel LLM alignment algorithm that replaces KL divergence with Hilbert space geometry, transforming probability simplex constraints into linear orthogonality conditions. This yields exact sparsity (zeroing out catastrophic actions), constant curvature, stable linear gradients, and intrinsic dead-zone mechanisms, achieving better performance on math benchmarks where clipping methods plateau.


<details>
  <summary>Details</summary>
Motivation: Current alignment algorithms using Kullback-Leibler divergence on probability simplex suffer from exponential curvature, requiring heuristic clipping and causing training instability. A more principled geometric foundation is needed for better optimization dynamics.

Method: Lifts policy optimization to Hilbert space L2(pi_k) where simplex constraints become linear orthogonality <v,1>=0. Uses work-dissipation functional J(v)=<g,v>-(μ/2)||v||² with Hilbert projection theorem. Enforces boundary v≥-1 for bounded projection and exact sparsity. Projects to finite empirical subspace via group sampling, where normalized advantages eliminate Lagrange multipliers.

Result: Yields constant Hessian curvature μI, non-saturating linear gradients, and intrinsic dead-zone without clipping. Experiments on mathematical reasoning benchmarks show competitive generalization with stable gradient dynamics and entropy preservation, avoiding performance plateaus seen in clipping-based methods.

Conclusion: GOPO provides a theoretically grounded alternative to KL-based alignment that achieves superior optimization properties and empirical performance, demonstrating the benefits of Hilbert space geometry for LLM alignment.

Abstract: We present Group Orthogonalized Policy Optimization (GOPO), a new alignment algorithm for large language models derived from the geometry of Hilbert function spaces. Instead of optimizing on the probability simplex and inheriting the exponential curvature of Kullback-Leibler divergence, GOPO lifts alignment into the Hilbert space L2(pi_k) of square-integrable functions with respect to the reference policy. Within this space, the simplex constraint reduces to a linear orthogonality condition <v, 1> = 0, defining a codimension-one subspace H0. Minimizing distance to an unconstrained target u_star yields the work-dissipation functional J(v) = <g, v> - (mu / 2) ||v||^2, whose maximizer follows directly from the Hilbert projection theorem. Enforcing the boundary v >= -1 produces a bounded Hilbert projection that induces exact sparsity, assigning zero probability to catastrophically poor actions through a closed-form threshold. To connect this functional theory with practice, GOPO projects from infinite-dimensional L2(pi_k) to a finite empirical subspace induced by group sampling. Because group-normalized advantages sum to zero, the Lagrange multiplier enforcing probability conservation vanishes exactly, reducing the constrained projection to an unconstrained empirical loss. The resulting objective has constant Hessian curvature mu I, non-saturating linear gradients, and an intrinsic dead-zone mechanism without heuristic clipping. Experiments on mathematical reasoning benchmarks show that GOPO achieves competitive generalization while maintaining stable gradient dynamics and entropy preservation in regimes where clipping-based methods plateau.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [6] [Ab Initio Random Matrix Theory of Molecular Electronic Structure](https://arxiv.org/abs/2602.21299)
*Zhen Tao,Victor Galitski*

Main category: cond-mat.str-el

TL;DR: 使用第一性原理计算方法研究分子电子结构中的随机矩阵理论普适性，发现低对称性分子体系表现出高斯正交系综(GOE)的能级统计特征


<details>
  <summary>Details</summary>
Motivation: 探究随机矩阵理论(RMT)普适性是否在真实分子电子结构中成立，为复杂体系相互作用电子光谱的组织提供普适性框架

Method: 采用单参考电子结构方法(包括Hartree-Fock、CIS、密度泛函理论和线性响应含时密度泛函理论)计算多种代表性分子的单粒子轨道能量和多电子激发态

Result: 发现普通低对称性几何结构下，这些从头算哈密顿量的展开谱呈现高斯正交系综(GOE)的Wigner-Dyson能级统计；扩展螺旋烯链中束缚价激发的物理态也观察到GOE统计；预测电场极化率方差(能级曲率K)在磁场中呈非解析行为，<K²>∝log(1/|B|)；强磁场下观测到向高斯幺正系综(GUE)的转变

Conclusion: 随机矩阵普适性为复杂体系中相互作用电子光谱的从头算预测提供了通用组织框架，适用于与真实分子直接相关的物理态

Abstract: We use ab initio electronic-structure methods to investigate random-matrix theory (RMT) universality in molecular electronic structure. Using single-reference electronic structure methods, including Hartree-Fock, configuration-interaction singles (CIS), density functional theory, and linear-response time-dependent density-functional theory, we compute single-particle orbital energies and many-electron excitations of several representative molecules (benzene, alanine, 1-phenylethylamine, methyloxirane, and helicene chains). For generic low-symmetry geometries, the unfolded spectra of these ab initio Hamiltonians exhibit Wigner-Dyson level statistics of the Gaussian orthogonal ensemble (GOE). For extended helicene chains we explicitly restrict to bound valence excitations below the ionization threshold and still observe GOE statistics, indicating that the RMT universality is present for physical states of direct relevance to real molecules. We further explore the electric and magnetic field dependence of the molecular electronic spectra. The variance of electric polarizability (level curvature K) is predicted to be non-analytic in the magnetic field which serves as an infrared cutoff, <K^2> proportional to log(1/|B|). We observe a transition to the Gaussian unitary ensemble (GUE) by increasing the magnetic fields, although it occurs only at magnetic fields far beyond experimentally accessible scales. Our results indicate that random matrix universality provides a general framework for organizing ab initio predictions of interacting electron spectra in complex systems.

</details>


### [7] [Detecting Higher Berry Phase via Boundary Scattering](https://arxiv.org/abs/2602.21301)
*Chih-Yu Lo,Xueda Wen*

Main category: cond-mat.str-el

TL;DR: 开发边界散射方法，通过测量一维自由费米子系统的边界反射矩阵高阶绕数，实现高阶Berry相的实验探测，并建立拓扑不变量与输运性质的关联


<details>
  <summary>Details</summary>
Motivation: 现有高阶Berry相研究缺乏实验可探测方案，需建立与可观测物理量（如输运）的直接联系

Method: 将无能隙引线耦合到被测有能隙系统，通过分析边界反射矩阵的高阶绕数提取高阶Berry不变量

Result: 所得拓扑不变量对无序等扰动具有鲁棒性，且与参数化拓扑相对应

Conclusion: 该方法为高阶拓扑相提供了实验可行的探测途径，深化了拓扑物态与量子输运的内在联系

Abstract: Higher Berry phase has recently been proposed to study the topology of the space of gapped many-body quantum systems. In this work, we develop a boundary-scattering approach to detect higher Berry phases in one-dimensional gapped free-fermion systems. By coupling a gapless lead to the gapped system, we demonstrate that the higher Berry invariant can be obtained by studying the higher winding number of the boundary reflection matrix. The resulting topological invariant is robust against perturbations such as disorder. Our approach establishes a connection between higher Berry invariants and transport properties, thereby providing a potentially experimentally accessible probe of parametrized topological phases.

</details>


### [8] [Rotational Phonons Drive Low-Energy Kinks in Cuprate Superconductors](https://arxiv.org/abs/2602.21438)
*Yanyong Wang,Manuel Engel,Christopher Lane,Henrique Miranda,Lin Hou,Bernardo Barbiellini,Adrienn Ruzsinszky,John P. Perdew,Robert S. Markiewicz,Arun Bansil,Jianwei Sun,Ruiqi Zhang*

Main category: cond-mat.str-el

TL;DR: 使用SCAN密度泛函研究无限层CaCuO₂，发现磁相中电子-声子耦合强度λ≈0.5，由旋转氧声子主导，可解释实验观测到的40-80 meV准粒子"扭结"和峰-谷-峰结构


<details>
  <summary>Details</summary>
Motivation: 角分辨光电子能谱在所有铜酸盐超导体中观测到~70 meV和~40 meV的准粒子"扭结"及峰-谷-峰结构，表明强电子-玻色子耦合，但传统密度泛函理论和后密度泛函方法受限，其微观起源长期未解

Method: 采用强约束且适当归一化(SCAN)密度泛函，明确包含磁效应，系统研究空穴掺杂无限层CaCuO₂中的电子-声子耦合

Result: 在磁相中获得~0.5的强电子-声子耦合强度λ，在40-80 meV区间产生与实验高度吻合的扭结和峰-谷-峰结构；旋转氧声子是主要贡献者，而呼吸模式贡献微弱

Conclusion: 确立了铜酸盐中强电子-声子耦合的存在，揭示了旋转氧声子的关键作用，为理解铜酸盐及其他材料的光谱异常提供了新理论框架

Abstract: Angle-resolved photoemission spectroscopy (ARPES) reveals ubiquitous quasiparticle ``kinks'' near $\sim$70 meV and $\sim$40 meV across cuprate superconductors, often accompanied by peak--dip--hump (PDH) structures. These features point to strong coupling between electrons and low-energy bosonic excitations, but the microscopic origin has remained elusive due to the limitations of conventional density-functional theory (DFT) and the high cost of beyond-DFT methods. Here, we systematically study the electron--phonon coupling (EPC) in hole-doped infinite-layer CaCuO$_2$ using the Strongly Constrained and Appropriately Normed (SCAN) density functional, explicitly including magnetic effects. We find a substantial EPC strength $λ$ of $\sim$0.5 in the magnetic phase, producing kinks and PDH structures in the 40-80~meV window in excellent agreement with experiments. The dominant contribution arises from rotational oxygen phonons, while breathing modes contribute little. Our results establish strong EPC in cuprates, highlight the key role of rotational phonons, and provide a framework for understanding spectral anomalies in cuprates and beyond.

</details>


### [9] [Unsupervised Discovery of Intermediate Phase Order in the Frustrated $J_1$-$J_2$ Heisenberg Model via Prometheus Framework](https://arxiv.org/abs/2602.21468)
*Brandon Yee,Wilson Collins,Maximilian Rutkowski*

Main category: cond-mat.str-el

TL;DR: 应用Prometheus变分自编码器框架对4×4晶格的J1-J2海森堡模型进行无监督分析，通过精确对角化基态数据系统探索其争议中间相，发现序参量并检测临界点。


<details>
  <summary>Details</summary>
Motivation: 自旋1/2的J1-J2海森堡模型在Néel反铁磁态和条纹相之间存在争议性中间相，现有理论提出团簇价键、向列相和量子自旋液体等多种可能基态。传统序参量识别方法因竞争相互作用和有限可及系统尺寸而面临挑战。

Method: 采用先前在Ising模型相变中验证过的Prometheus变分自编码器框架，对4×4晶格精确对角化基态进行无监督分析，在J2/J1∈[0.3,0.7]范围内以0.01步长进行密集参数扫描，使用多种独立方法进行序参量发现和临界点检测。

Result: 通过无监督机器学习方法系统探索了J1-J2相图，研究了中间相区的物理性质。

Conclusion: 本研究展示了经过严格验证的机器学习方法在解决受挫量子磁体开放性难题中的有效应用，特别是在传统序参量识别困难的体系中。

Abstract: The spin-$1/2$ $J_1$-$J_2$ Heisenberg model on the square lattice exhibits a debated intermediate phase between Néel antiferromagnetic and stripe ordered regimes, with competing theories proposing plaquette valence bond, nematic, and quantum spin liquid ground states. We apply the Prometheus variational autoencoder framework -- previously validated on classical (2D, 3D Ising) and quantum (disordered transverse field Ising) phase transitions -- to systematically explore the $J_1$-$J_2$ phase diagram via unsupervised analysis of exact diagonalization ground states for a $4 \times 4$ lattice. Through dense parameter scans of $J_2/J_1 \in [0.3, 0.7]$ with step size 0.01 and comprehensive latent space analysis, we investigate the nature of the intermediate regime using unsupervised order parameter discovery and critical point detection via multiple independent methods. This work demonstrates the application of rigorously validated machine learning methods to open questions in frustrated quantum magnetism, where traditional order parameter identification is challenged by competing interactions and limited accessible system sizes.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [A Dynamic Survey of Soft Set Theory and Its Extensions](https://arxiv.org/abs/2602.21268)
*Takaaki Fujita,Florentin Smarandache*

Main category: cs.AI

TL;DR: 本书综述了软集理论及其主要扩展，重点阐述核心定义、典型构造和当前发展方向。


<details>
  <summary>Details</summary>
Motivation: 软集理论为参数化决策建模提供了直接框架，能有效处理不确定性。经过数十年发展，该理论已衍生出多种变体并与拓扑学、拟阵理论等领域建立联系，需要系统性梳理。

Method: 采用综述性方法，全面回顾软集理论及其扩展形式（包括超软集、超超软集、TreeSoft集、bipolar软集和动态软集等），突出核心定义、代表性构造和关键发展方向。

Result: 成功构建了软集理论及其扩展的综合性概述框架，系统整理了核心概念、典型构造，并明确了当前研究的主要方向。

Conclusion: 本书为软集理论的研究提供了系统化参考，有助于理解该领域的发展脉络和未来趋势。

Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.

</details>


### [11] [A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](https://arxiv.org/abs/2602.21351)
*Dmitrii Pantiukhin,Ivan Kuznetsov,Boris Shapkin,Antonia Anna Jost,Thomas Jung,Nikolay Koldunov*

Main category: cs.AI

TL;DR: 针对地球科学数据积累导致的利用率低问题，提出PANGAEA-GPT多智能体框架，通过监督-工作节点架构、数据类型路由和安全代码执行，实现自主数据发现与分析，在海洋学和生态学场景中验证了复杂工作流执行能力。


<details>
  <summary>Details</summary>
Motivation: 地球科学数据快速积累带来可扩展性挑战，尽管PANGAEA等数据库存储海量数据，但引用指标显示大量数据未被充分利用，限制了数据可重用性。

Method: 开发PANGAEA-GPT分层多智能体框架，采用集中式监督-工作节点拓扑结构，实施严格的数据类型感知路由、沙箱化确定性代码执行和执行反馈自校正机制。

Result: 在物理海洋学和生态学用例场景中，系统展示了执行复杂多步工作流的能力，仅需最少的人工干预。

Conclusion: 该框架提供了一种通过协调智能体工作流来查询和分析异构存储库数据的方法论，为地球科学数据的自主发现和分析提供了新思路。

Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.

</details>


### [12] [Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information](https://arxiv.org/abs/2602.21496)
*Umid Suleymanov,Zaur Rajabov,Emil Mirzazada,Murat Kantarcioglu*

Main category: cs.AI

TL;DR: 针对大语言模型推断敏感身份属性、生成损害声誉内容或幻觉错误信息等新威胁，本文提出 SemSIEdit 推理时框架，通过智能体"编辑"迭代改写敏感内容以平衡隐私保护与模型效用，发现隐私-效用帕累托边界、规模依赖的安全分化和推理悖论三大现象。


<details>
  <summary>Details</summary>
Motivation: 现有结构化 PII 防御已成熟，但大语言模型在复杂、上下文相关的语义敏感信息泄露方面的自我调节能力尚未解决，特别是如何在保护隐私的同时不损害模型实用性。

Method: 提出 SemSIEdit 推理时框架，采用智能体"编辑"对敏感文本片段进行迭代批评和改写，以保留叙事连贯性为目标，而非简单拒绝回答。

Result: 发现隐私-效用帕累托边界：改写策略将三类语义敏感信息泄露降低 34.6%，仅损失 9.8% 的效用。发现规模依赖的安全分化：大模型通过建设性扩展增加细微差别，小模型采用破坏性截断删除文本。发现推理悖论：推理时链既增加基线风险（深度推断），又赋能防御（安全改写）。

Conclusion: 智能体重写是管理语义敏感信息的有效方法，但模型规模与推理能力对防御效果产生关键影响，揭示了安全性与能力之间的复杂权衡关系。

Abstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic "Editor" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.

</details>


### [13] [Distill and Align Decomposition for Enhanced Claim Verification](https://arxiv.org/abs/2602.21857)
*Jabez Magomere,Elena Kochkina,Samuel Mensah,Simerjot Kaur,Fernando Acero,Arturo Oncevay,Charese H. Smiley,Xiaomo Liu,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出基于GRPO的强化学习方法，联合优化复杂主张分解质量与验证器对齐，使8B分解器在下游验证任务中取得71.75%宏F1分数


<details>
  <summary>Details</summary>
Motivation: 现有方法难以对齐句子分解质量与验证性能，需联合优化两者

Method: 采用群体相对策略优化(GRPO)，集成结构化序列推理、教师蒸馏示例的微调、以及平衡格式合规性/验证器对齐/分解质量的多目标奖励

Result: 6个评估设置中，8B分解器宏F1达71.75%，超越基于提示的方法(+1.99,+6.24)和现有RL方法(+5.84)

Conclusion: 该框架使小语言模型通过联合优化验证精度与分解质量达到SOTA主张验证效果

Abstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [14] [A Physics-Informed Neuro-Fuzzy Framework for Quantum Error Attribution](https://arxiv.org/abs/2602.21253)
*Marwa R. Hassan,Naima Kaabouch*

Main category: quant-ph

TL;DR: 提出一种神经模糊框架，结合ANFIS与物理约束特征工程，通过Bhattacharyya否决机制区分量子软件缺陷与硬件噪声，在IBM 156量子位处理器上实现89.5%诊断准确率，并识别基本诊断盲区


<details>
  <summary>Details</summary>
Motivation: 随着量子处理器规模超过100量子位，区分软件缺陷与随机硬件噪声成为关键诊断挑战

Method: 结合自适应神经模糊推理系统(ANFIS)与物理基础特征工程，引入基于数据处理不等式的Bhattacharyya否决硬约束

Result: 在IBM 156量子位Heron r2处理器上测试105个电路(17种算法)，实现89.5%有效准确率(±5.9%置信区间)，14.3%模糊案例标记人工审核，解决Grover放大与缺陷坍缩等关键歧义，发现Z基盲区等根本性诊断限制

Conclusion: 建立了稳健可解释的诊断层，防止将错误缓解技术应用于逻辑错误的电路

Abstract: As quantum processors scale beyond 100 qubits, distinguishing software bugs from stochastic hardware noise becomes a critical diagnostic challenge. We present a neuro-fuzzy framework that addresses this attribution problem by combining Adaptive Neuro-Fuzzy Inference Systems (ANFIS) with physics-grounded feature engineering. We introduce the Bhattacharyya Veto, a hard physical constraint grounded in the Data Processing Inequality that prevents the classifier from attributing topologically impossible output distributions to noise. Validated on IBM's 156-qubit Heron r2 processor (ibm_fez) across 105 circuits spanning 17 algorithm families, the framework achieves 89.5% effective accuracy (+/- 5.9% CI). The system implements a safe failure mode, flagging 14.3% of ambiguous cases for manual review rather than forcing low-confidence predictions. We resolve key ambiguities -- such as distinguishing correct Grover amplification from bug-induced collapse -- and identify fundamental limits of single-basis diagnostics, including a Z-basis blind spot where phase-flip errors remain statistically invisible. This work establishes a robust, interpretable diagnostic layer that prevents error mitigation techniques from being applied to logically flawed circuits.

</details>


### [15] [Random Acceleration Noise on Stern-Gerlach Interferometry in a Harmonic Trap](https://arxiv.org/abs/2602.21288)
*Sneha Narasimha Moorthy,Andrew Geraci,Sougato Bose,Anupam Mazumdar*

Main category: quant-ph

TL;DR: 研究纳米金刚石NV色心物质波干涉仪在随机加速度噪声下的退相干机制，量化加速度幅值/方向涨落导致的退相率，给出实验参数阈值和噪声抑制方案


<details>
  <summary>Details</summary>
Motivation: 解决宏观量子叠加态实验中环境噪声导致的退相干问题，为实现纳米粒子物质波干涉提供噪声控制依据

Method: 将外部随机加速度和偏转角建模为随机输入，通过维纳-辛钦定理计算相位差涨落，推导白噪声下的退相率Γ

Result: 获得关键噪声阈值：加速度噪声谱密度需≤10⁻¹¹ m/s²/√Hz（零偏转时），角度噪声≤10⁻¹⁰ rad/√Hz（重力场下）；发现可通过调节偏转角θ₀或加速度a优化工作点抑制噪声

Conclusion: 确定了纳米粒子干涉仪实验的噪声容限，提出通过参数调谐降低退相干的方法，为实验设计提供理论指导

Abstract: We analyze decoherence in a one-loop Stern--Gerlach--type matter-wave interferometer for a massive nanoparticle embedded with a nitrogen vacancy (NV)-centred nanodiamond evolving under an effective harmonic-oscillator dynamics in a magnetic-field gradient. We assume that the Stern-Gerlach interferometer is subjected to a random acceleration noise external to the system. This could be along the direction of the superposition at an angle which can be varied. We quantify dephasing from two noise channels: fluctuations in the external acceleration $a(t)$ magnitude and direction as specified by the tilt angle $θ_0(t)$ between the superposition axis and the acceleration. At the level of the action, we treat these two external noise as stochastic inputs, and compute the resulting stochastic arm-phase difference, and obtain the dephasing rate $Γ$ using the Wiener--Khinchin theorem. For a white noise and a coherence target $Γτ\leq 1$ and by assuming that we finish the one-loop interferometer within $τ=2π/ω_0\simeq 0.015~\mathrm{s}$, for a reasonable choice of the magnetic field gradient, $η_0=6\times 10^{3}~\mathrm{T\,m^{-1}}$ and mass of the nanodiamond, $m=10^{-15}~\mathrm{kg}$) to create a superposition size of $Δx\sim 1$nm. We find $\sqrt{\mathcal{S}_{aa}}\lesssim \mathcal{O}(10^{-11})~\mathrm{m\,s^{-2}\,Hz^{-1/2}}$ even if we take the external acceleration, $a=0~{\rm ms^{-2}}$ and $θ_0=0^\circ$ (along the dirction of the superposition), and $\sqrt{\mathcal{S}_{θθ}}\lesssim \mathcal{O}(10^{-10})~\mathrm{rad\,Hz^{-1/2}}$ for $a=g= 9.81~\mathrm{m\,s^{-2}}$ and $θ_0=0^\circ$ (superposition direction is perpendicular to the Earth's gravity). We have also found an operating regime where the acceleration noise can be minimized by either varying $θ_0$ or $a$ for a fixed set of other experimental parameters.

</details>


### [16] [Learning Quantum Data Distribution via Chaotic Quantum Diffusion Model](https://arxiv.org/abs/2602.22061)
*Quoc Hoan Tran,Koki Chinzei,Yasuhiro Endo,Hirotaka Oshima*

Main category: quant-ph

TL;DR: 本文提出一种混沌量子扩散模型，用混沌哈密顿演化取代基于电路的酉动力学，在保持与现有方法相当精度的同时，提供了更高效、鲁棒的量子生成建模方案。


<details>
  <summary>Details</summary>
Motivation: 量子数据的生成模型在化学信息学和量子物理等领域潜力巨大，但现有量子去噪扩散模型(QuDDPMs)依赖基于电路的随机酉动力学，实现成本高且对控制缺陷敏感，特别是在模拟量子硬件上难以实用化。

Method: 作者提出混沌量子扩散模型框架，通过混沌哈密顿时间演化生成投影系综，仅需全局、与时间无关的控制，替代复杂的电路实现。

Result: 该方法大幅降低了在不同模拟量子平台上的实现开销，同时达到了与QuDDPMs相当的精度，并改善了可训练性和鲁棒性。

Conclusion: 该研究通过提供更实用、硬件兼容的扩散机制，拓宽了量子生成建模的应用范围，特别适合模拟量子计算平台。

Abstract: Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics. Quantum denoising diffusion probabilistic models (QuDDPMs) enable efficient learning of quantum data distributions by progressively scrambling and denoising quantum states; however, existing implementations typically rely on circuit-based random unitary dynamics that can be costly to realize and sensitive to control imperfections, particularly on analog quantum hardware. We propose the chaotic quantum diffusion model, a framework that generates projected ensembles via chaotic Hamiltonian time evolution, providing a flexible and hardware-compatible diffusion mechanism. Requiring only global, time-independent control, our approach substantially reduces implementation overhead across diverse analog quantum platforms while achieving accuracy comparable to QuDDPMs. This method improves trainability and robustness, broadening the applicability of quantum generative modeling.

</details>


### [17] [Teleportation transition of surface codes on a superconducting quantum processor](https://arxiv.org/abs/2602.21293)
*Yiren Zou,Hong-Kuan Xia,Aosai Zhang,Xuhao Zhu,Feitong Jin,Qingyuan Wang,Yu Gao,Chuanyu Zhang,Ning Wang,Zhengyi Cui,Fanhao Shen,Zehang Bao,Zitian Zhu,Jiarun Zhong,Gongyu Liu,Jia-Nan Yang,Yihang Han,Yiyang He,Jiayuan Shen,Han Wang,Yanzhe Wang,Jiahua Huang,Xinrong Zhang,Sailang Zhou,Hang Dong,Jinfeng Deng,Yaozu Wu,Zixuan Song,Hekang Li,Zhen Wang,Chao Song,Qiujiang Guo,Pengfei Zhang,Guo-Yi Zhu,H. Wang*

Main category: quant-ph

TL;DR: 在125量子比特超导量子处理器上实现拓扑旋转表面码的稳健隐形传态（码距达7），并通过注入魔法资源提升纠缠阈值。


<details>
  <summary>Details</summary>
Motivation: 扩展表面码在量子隐形传态中的应用面临重大挑战，需实现逻辑量子态的稳健处理以推动量子信息发展。

Method: 使用125量子比特超导量子处理器；通过线性深度酉电路制备拓扑旋转表面码；均匀调节局部纠缠门获取隐形传态相图；利用相干量子比特旋转注入超越Clifford区域的魔法资源。

Result: 成功实现码距高达7的拓扑表面码稳健隐形传态；获得具有有限阈值的隐形传态相图；注入魔法资源提升纠缠阈值并恢复拓扑相的对偶对称性，最小化纠缠资源需求。

Conclusion: 研究为量子设备模拟拓扑量子物质提供新见解，为实现分布式容错量子计算奠定基础。

Abstract: The topological surface code is a leading candidate for harnessing long-range entanglement to protect logical quantum information against errors, and teleportation of logical states is desirable for robust quantum information processing. Nevertheless, scaling up the surface code in quantum teleportation poses a formidable challenge to experiment. Here on a superconducting quantum processor with 125 qubits, we demonstrate the robust teleportation of topological rotated surface code prepared by a linear-depth unitary circuit, with code distances up to 7. We obtain the teleportation phase diagram by tuning the local entangling gates uniformly across a finite threshold. Furthermore, we show that the entangling threshold can be boosted by coherent qubit rotations that inject magic resources beyond the Clifford regime, restoring the duality symmetry of the topological phase, which serves as a guiding principle to minimize the entanglement resource. Our results shed light on simulating and leveraging topological quantum matter on quantum devices, and pave the way to the ultimate goal of distributed fault tolerant quantum computation.

</details>


### [18] [Quantum Error Mitigation Simulates General Non-Hermitian Dynamics](https://arxiv.org/abs/2602.21879)
*Hiroki Kuji,Suguru Endo,Tetsuro Nikuni,Ryusuke Hamazaki,Yuichiro Matsuzaki*

Main category: quant-ph

TL;DR: 提出硬件友好协议，通过经典高斯白噪声平均和随机量子误差缓解，无需辅助比特即可在量子设备上模拟非厄米动力学


<details>
  <summary>Details</summary>
Motivation: 非厄米哈密顿量虽能展现奇异动力学现象，但如何在近-term量子设备上实现其非幺正时间演化仍具挑战性，尤其需要避免连续监测等传统方法的硬件限制

Method: 基于Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) 方程，采用经典高斯白噪声平均模拟演化，并通过随机量子误差缓解(QEM)在可观测量层面抵消量子跳跃贡献，全程无需辅助比特或受控时间演化，仅需单量子比特操作

Result: 通过含非对称跃迁、相互作用和无序的模型数值验证，证实方案可有效模拟非完全正定且非保迹的非厄米动力学

Conclusion: 建立了可编程、无辅助比特的通用框架，为利用量子误差缓解技术研究非厄米系统奇异动力学提供了可行路径

Abstract: While non-Hermitian Hamiltonians enable exotic dynamical phenomena, implementing their nonunitary time evolution on near-term quantum devices remains challenging. We propose a hardware-friendly protocol that simulates non-Hermitian dynamics without continuous monitoring. Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) evolution via classical Gaussian white-noise averaging and to subsequently cancel the quantum-jump contribution at the level of the measured observable using stochastic quantum error mitigation (QEM). The scheme requires no ancillas or controlled time-evolution, while the mitigation layer uses only single-qubit operations. We validate the method through numerical simulations of a model with asymmetric hopping, interaction, and disorder. Our work provides a programmable and ancilla-free framework investigating exotic dynamics that are not completely-positive and trace-preserving using QEM.

</details>


### [19] [Hybrid Consensus with Quantum Sybil Resistance](https://arxiv.org/abs/2602.22195)
*Dar Gilboa,Siddhartha Jain,Or Sattath*

Main category: quant-ph

TL;DR: 提出一种结合经典混合共识与量子位置验证的共识协议，利用量子态不可克隆性实现Sybil抵抗，提升能效并继承混合协议优势。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化共识协议依赖计算力或权益等稀缺资源实现Sybil抵抗，存在高能耗或财富集中问题；量子态的不可克隆性为无条件稀缺资源提供新思路。

Method: 将经典混合共识协议与量子位置验证机制结合，以量子态作为Sybil抵抗的稀缺资源。

Result: 协议在标准模型下安全，相比PoW混合协议能效更高；确认时间快于纯PoW，且避免PoS的财富集中缺陷；额外提出随机预言模型下的防垃圾机制。

Conclusion: 该协议为去中心化共识提供了一种高效、安全且公平的量子增强解决方案，拓展了量子密码学在共识机制中的应用。

Abstract: Sybil resistance is a key requirement of decentralized consensus protocols. It is achieved by introducing a scarce resource (such as computational power, monetary stake, disk space, etc.), which prevents participants from costlessly creating multiple fake identities and hijacking the protocol. Quantum states are generically uncloneable, which suggests that they may serve naturally as an unconditionally scarce resource. In particular, uncloneability underlies quantum position based-cryptography, which is unachievable classically. We design a consensus protocol that combines classical hybrid consensus protocols with quantum position verification as the Sybil resistance mechanism, providing security in the standard model, and achieving improved energy efficiency compared to hybrid protocols based on Proof-of-Work. Our protocol inherits the benefits of other hybrid protocols, namely the faster confirmation times compared to pure Proof-of-Work protocols, and resilience against the compounding wealth issue that plagues protocols based on Proof-of-Stake Sybil resistance. We additionally propose a spam prevention mechanism for our protocol in the Random Oracle model.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [20] [Effect of glass stability on the low frequency vibrations of vapor deposited glasses](https://arxiv.org/abs/2602.22071)
*I. Festi,E. Alfinelli,D. Bessas,F. Caporaletti,A. I. Chumakov,M. Moratalla,M. A. Ramos,M. Rodríguez-López,C. Rodríguez-Tinoco,J. Rodríguez-Viejo,G. Baldi*

Main category: cond-mat.dis-nn

TL;DR: 超稳定玻璃中低频振动模式与结构不稳定性的关联机制被实验验证，揭示低频声子行为不受玻璃稳定性影响，但高频区（玻色峰附近）对稳定性极度敏感。


<details>
  <summary>Details</summary>
Motivation: 解释超稳定玻璃中低频振动模式与局部结构不稳定性之间的未解关联，特别是澄清准局域化振动模式是否必要，以及玻璃稳定性如何影响不同频段的振动特性。

Method: 利用新型核共振非弹性X射线散射光谱仪，测量超稳定玻璃与传统玻璃薄膜的振动态密度，频率范围低至70 GHz，对比分析不同稳定性玻璃的振动谱差异。

Result: 1）最低频振动模式（~70 GHz）在超稳定玻璃中未改变，尽管其双态缺陷密度降低近一个数量级；2）高频区（玻色峰附近）振动模式对玻璃稳定性极度敏感；3）准局域化振动模式的存在并非描述低频振动所必需。

Conclusion: 低频振动行为与玻璃稳定性解耦，挑战了传统准局域化振动模型；高频振动对稳定性的敏感依赖性为理解玻璃缺陷动力学提供新方向，推动解决低频振动争议。

Abstract: Ultra-stable glasses prepared from the physical vapor deposition of organic molecules present a very low density of two-level states, the kind of glass defects that determine their peculiar low temperature thermal properties. Numerical simulations suggest that quasi-localized harmonic vibrational modes emerge in the soft regions associated with two-level states. However, the connection between the low frequency vibrational modes and the local structural instabilities of glasses remains unexplained. Here we exploit a recently developed spectrograph for nuclear resonant analysis of inelastic X-ray scattering to probe the density of vibrational states of amorphous thin films of ultra-stable and conventional glasses down to an exceptionally low frequency of $\sim 70$ GHz. We show that the glass stability does not affect the harmonic vibrational modes at the lowest frequencies, despite a reduction of almost an order of magnitude in the density of two-level states. At the same time, the vibrational modes at higher frequencies, around the boson peak maximum, are extremely sensitive to the glass stability. Although we cannot exclude the possible existence of quasi-localized modes in glasses, we show that their presence is not strictly necessary to describe the measured density of low frequency vibrations. The experimental developments here presented pave the way to the solution to the long-standing debate on the low frequency vibrations in glasses.

</details>


### [21] [Thermal activation drives a finite-size crossover from scale-free to runaway avalanches in amorphous solids](https://arxiv.org/abs/2602.22198)
*Gieberth Rodriguez-Lopez,Ezequiel E. Ferrero*

Main category: cond-mat.dis-nn

TL;DR: 热激活可在无序弹性介质中产生有限尺寸控制的失稳尺度，无需外部驱动即可引发系统级雪崩。


<details>
  <summary>Details</summary>
Motivation: 探究无外部驱动下 amorphous solids 中热激活雪崩动力学行为，揭示温度如何诱发动力学异质性及失稳机制，挑战传统剪切驱动系统的认知。

Method: 采用弹性塑性模型（elastoplastic models）结合局部激活规则，通过持久性测量和四维 susceptibility $χ_4$ 量化动力学异质性，分析雪崩统计特性。

Result: 1. 温度升高使雪崩统计从尺度无关（带指数截断）转变为系统级 runaway 事件主导；<br>2. 存在尺寸依赖的临界温度 $T_c(L)$，其随系统尺寸增大而代数减小，趋近热力学极限时任意微小温度即可 destabilize 间歇性 regime；<br>3. 雪崩尺寸-持续时间关系与剪切系统相似，但最小屈服距离统计揭示热驱动特有的 marginal stability 重组。

Conclusion: 仅热激活即可在无序弹性介质中产生有限尺寸控制的失稳尺度，为理解非驱动系统的热机械失稳提供新机制，暗示热力学极限下 amorphous solids 可能存在本征热不稳定性。

Abstract: We investigate thermal avalanche dynamics in amorphous solids using elastoplastic models with local activation rules and no external driving. Dynamical heterogeneities, quantified through persistence measurements and the associated four-point susceptibility $χ_4$, reveal the emergence of correlated spatiotemporal rearrangements as temperature is varied. As temperature increases, avalanche statistics evolve from scale-free behavior with exponential cutoffs to regimes dominated by system-spanning runaway events. We identify a system-size-dependent critical temperature $T_c(L)$ that separates intermittent avalanche dynamics from thermally assisted flow, where self-sustained avalanches transiently fluidize the system. We show that $T_c(L)$ decreases algebraically with increasing system size, suggesting that in the thermodynamic limit arbitrarily small but finite temperatures may destabilize the intermittent regime. The relation between avalanche size and duration resembles that in sheared systems, whereas the statistics of minimal distances to yielding reveal a temperature-driven reorganization of marginal stability absent in strictly driven overdamped dynamics. Our results demonstrate that thermal activation alone can generate a finite-size-controlled instability scale in disordered elastic media.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [22] [Generalized Onsager-Regularized Lattice Boltzmann Method for error-free Navier-Stokes models on standard lattices](https://arxiv.org/abs/2602.21242)
*Anirudh Jonnalagadda,Walter Rocchia,Sauro Succi*

Main category: physics.comp-ph

TL;DR: 本文提出了一种针对最近邻格子玻尔兹曼方法中Navier-Stokes建模误差的新策略，通过Onsager正则化非平衡态分布函数进行局部修正，开发出部分和完全修正的六矩约束引导平衡模型，数值实验显示精度和稳定性显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决第一近邻格子玻尔兹曼方法在Navier-Stokes方程建模时产生的误差，特别是在热流体动力学模拟中的兼容性和应力张量建模问题。

Method: 引入Onsager正则化（OReg）非平衡态分布函数进行完全局部修正，针对D2Q9格子上的六矩约束引导平衡（GEq）表示，开发部分修正和完全修正两类模型。部分修正模型仅解决兼容性条件违例，完全修正模型额外修正应力张量建模误差。

Result: 部分修正模型在参考/任意格子温度下分别将精度提高2/4个数量级；完全修正模型成为完全精确模型。与Lattice-BGK和未修正OReg-GEq方案相比，修正方案在数值基准测试中表现出更高的精度和稳定性。

Conclusion: 该方法为基于OReg的热流体动力学扩展提供了有前景的研究方向，通过局部修正机制显著提升了格子玻尔兹曼方法的准确性和稳定性。

Abstract: This work presents a novel strategy to address Navier-Stokes modelling errors arising on first-nearest neighbour lattice Boltzmann (LB) methods and introduces fully local corrections through Onsager-Regularized (OReg) non-equilibrium populations. The proposed mechanism, which admits partially and completely corrected OReg models, is used to develop representative partially and completely corrected models for the six-moment-constrained guided equilibrium (GEq) representation on the D2Q9 lattice. The former realization only addresses compatibility condition violations and improves the accuracy by two/four orders of magnitude at reference/arbitrary lattice temperatures respectively, while the latter additionally corrects stress tensor modelling errors, resulting in a fully corrected exact model. Numerical benchmarks of the corrected schemes demonstrate improved accuracy and stability in comparison to the Lattice-BGK and uncorrected OReg-GEq schemes thus presenting a promising avenue for OReg based thermohydrodynamic extensions.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [23] [Superpositions between non linear intermittency maps, application in biological neurons networks](https://arxiv.org/abs/2602.21848)
*Yiannis F. Contoyiannis*

Main category: nlin.CD

TL;DR: 该研究将统计物理中的临界/三临界现象建模为I型间歇性混沌动力学，通过叠加多个不同参数的临界-三临界系统并耦合其时间序列，证明产生的脉冲序列始终保持生物神经元放电特性，为模拟神经活动及研究脑部疾病提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 探索临界/三临界现象的动力学本质，并将其与生物神经元放电活动建立联系，最终为理解脑部神经脉冲缺失导致的认知功能下降问题提供物理模型基础。

Method: 1. 将临界/三临界点表述为具有弱混沌的I型间歇性时间序列；2. 耦合临界与三临界混沌系统生成生物型脉冲序列；3. 推广至不同参数下临界-三临界间歇性的叠加；4. 研究叠加与耦合对生物型脉冲序列的保持性。

Result: 1. 叠加与耦合后的混沌间歇性仍产生生物型脉冲序列；2. 叠加序列的波动动力学与生物神经元膜电位波动动力学一致；3. 可通过操控数值实验模拟神经活动。

Conclusion: 该动力学框架成功将统计物理临界现象与神经科学关联，证明生物型脉冲特性在复杂耦合叠加下具有鲁棒性，未来可用于模拟神经退行性疾病中的脉冲缺失机制。

Abstract: In a series of works of ours we have shown that we can represent the critical and tricritical points of the Statistical Physics of critical phenomena as a Dynamical phenomenon expressed by time series produced by the type I intermittency that exhibits a weak chaos. Recently we have also shown that if we couple these two chaotic dynamics, namely critical and tricritical, we can produce a time sequence which is a temporal Spike Train (ST) of biological-type . In the present work we generalize this issue producing superpositions of critical-tricritical intermittencies with different parameter values. Now arise the question whether the coupling occurs between time series that have resulted from the superposition, will preserved or destroyed the ST biological type , as the number of intermittencies in the superposition will increase? In the other side in present work we find that the spikes produced by the chaotic dynamics of the intermittencies, under the action of superpositions and coupling remain biological-type too. Thus we can say that the dynamics of the fluctuations of the values of the time series produced by the coupling of the superpositions of the intermittencies is the same as the dynamics of the fluctuations of the membrane potential of the biological neuron. Given also that we can manipulate the numerical experiment of superposition and coupling as we wish, we will be able, in future, to approach the cause of neurological problems and decline in thinking ability due to loss of spikes in the brain.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [24] [Yet another look at narrow escape through a tube](https://arxiv.org/abs/2602.21396)
*Victorya Richardson,Yick Hin Ling,Sean D Lawley*

Main category: cond-mat.stat-mech

TL;DR: 解决了长期存在的窄管逃逸问题，通过匹配渐近分析和概率方法得到了精确渐近公式，揭示了空间扩散系数变化产生的乘性噪声对逃逸时间的关键影响


<details>
  <summary>Details</summary>
Motivation: 窄管逃逸问题三十年来存在多种相互矛盾甚至反直觉的估计，现有方法依赖电磁类比、模拟拟合和启发式推理，缺乏严格解

Method: 结合匹配渐近分析与概率方法，确定窄管逃逸时间的精确渐近行为

Result: 推导出新的逃逸时间公式，涵盖先前所有特例；发现空间变扩散系数导致的乘性噪声对逃逸时间具有决定性影响

Conclusion: 结果澄清了历史争议，为不对称细胞分裂等生物过程提供了理论基础

Abstract: The narrow escape problem concerns the time needed for a diffusing particle to exit a confining domain through a small hole in the boundary. While this problem is now well-understood, determining the escape time for a particle that must exit through a narrow tube has proven challenging. Indeed, relying on analogies with electrodynamics, parameter fits to simulations, and heuristics, a variety of conflicting estimates for this escape time have been offered over the last three decades, some of which are counterintuitive and arguably non-physical. In this paper, we combine matched asymptotic analysis and probabilistic methods to determine the exact asymptotics of the narrow escape time through a tube. We obtain a new escape time formula which reduces to the various prior estimates in certain special cases. If the diffusivity in the tube differs from the diffusivity in the rest of the domain, our results reveal the importance of the form of the multiplicative noise inherent to any diffusivity that varies in space. We discuss our results in the context of asymmetric cell division.

</details>


### [25] [Integral formula for the propagator of the one-dimensional Hubbard model](https://arxiv.org/abs/2602.21541)
*Taiki Ishiyama,Kazuya Fujimoto,Tomohiro Sasamoto*

Main category: cond-mat.stat-mech

TL;DR: 提出了一维无限晶格上费米-哈伯德模型多粒子传播子的精确积分公式，通过嵌套Bethe拟设方法（不依赖弦假设）实现，为研究该模型的精确非平衡动力学提供了基础工具


<details>
  <summary>Details</summary>
Motivation: 解决强关联量子多体系统非平衡动力学缺乏精确解的核心难题，一维费米-哈伯德模型作为凝聚态物理的基础模型，其精确传播子对理解非平衡现象至关重要

Method: 采用嵌套Bethe拟设方法，创新性地避免使用传统有争议的弦假设，通过严格数学推导获得多粒子传播子的精确积分表达式

Result: 获得了适用于任意有限粒子数波函数时间演化的显式积分表示，建立了该模型非平衡动力学的精确分析框架

Conclusion: 该公式不仅为费米-哈伯德模型提供了完整的动力学解，其方法论还可推广至相关开放量子系统研究，推动了强关联体系非平衡物理的精确求解进展

Abstract: We present an exact integral formula for the multi-particle propagator of the one-dimensional Fermi--Hubbard model on an infinite lattice. The proof is based on the nested Bethe ansatz without relying on the string hypothesis. Our formula enables an explicit integral representation of the time evolution of arbitrary finite-particle wave functions and thereby provides a foundation for the exact analysis of nonequilibrium dynamics in the Hubbard model. It can further be applied to related open quantum models.

</details>


### [26] [A diffusion approximation for systems with frequent weak resetting](https://arxiv.org/abs/2602.21635)
*Tobias Galla*

Main category: cond-mat.stat-mech

TL;DR: 本文针对小振幅快速随机重置系统（即频繁小灾难系统）建立了扩散近似，通过计算一维系统的稳态分布和平均首次通过时间来验证，发现该近似能捕捉多粒子系统的动态相关性，推广了全重置系统的条件独立同分布结构，并揭示了重置可诱导产生循环和模式。


<details>
  <summary>Details</summary>
Motivation: 研究小振幅快速随机重置系统（频繁小灾难系统）的行为特征，这类系统在随机过程中具有特殊意义但缺乏有效的分析方法。

Method: 建立扩散近似方法，通过计算一维系统的稳态分布和平均首次通过时间来验证近似有效性，进一步分析多粒子系统中的动态相关性，推广全重置系统的条件独立同分布结构，并研究重置诱导的循环和模式形成。

Result: 扩散近似能有效描述这类系统，准确捕捉多粒子系统的动态相关性，成功推广了全重置系统的相关理论，并发现重置可以诱导产生可表征的循环和模式结构。

Conclusion: 该扩散近似为理解小振幅快速重置系统提供了有效工具，揭示了重置机制对系统动态行为的深刻影响，包括诱导相关性和模式形成。

Abstract: We develop a diffusion approximation for systems subject to fast random resetting by small amplitudes. Equivalently, this describes systems with frequent but small catastrophes. We demonstrate the validity of the approximation by computing the stationary distribution and mean first-passage times of simple one-dimensional systems. The approximation captures dynamically induced correlations in multi-particle systems, and it can be used to generalise the conditionally independent and identically distributed structure recently found in systems with full resetting. Finally, we show that resetting can induce cycles and patterns, which can be characterised using the diffusion approximation.

</details>


### [27] [Plausible universality of uniaxial order in self-assembly of cross junctions in space dimension $d \ge 3$](https://arxiv.org/abs/2602.21673)
*Kazuya Saito*

Main category: cond-mat.stat-mech

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the self-assembly of cross junctions in a general space dimension ($d$) as an extension of the problem studied in a previous paper for $d = 3$. This problem is equivalent to constructing a $d$-dimensional hypercubic jungle gym, at all junctions of which $2d$ rods with different colours meet. The analysis reveals a unique feature of the $d = 3$ case: the forced presence of at least one perfectly-ordered (singly coloured) direction (axis), in contrast to the possible absence of such a direction in $d \ge 4$. However, we will show that the uniaxial order is overwhelming not only in $d = 3$ but also for $d \ge 4$ in a sufficiently large system.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [28] [Two NP-hard Extensions of the Spearman Footrule even for a Small Constant Number of Voters](https://arxiv.org/abs/2602.21332)
*Martin Durand*

Main category: cs.CC

TL;DR: 本文研究两种Spearman footrule投票规则扩展在少数选民情况下的计算复杂性。虽然标准版本可在多项式时间内求解，但第一种扩展（带任务长度）在仅有3名选民时即为NP难问题，第二种扩展（带权重）在4名选民时即为NP难问题，但两者在2名选民时都可在多项式时间内求解。


<details>
  <summary>Details</summary>
Motivation: Spearman footrule是基础的投票规则，但其扩展版本在现实应用中很常见（如不同长度的任务或加权候选人）。研究这些扩展的计算复杂性对于评估其实际可行性至关重要，特别是考虑到小规模选举或决策场景。

Method: 通过参数化复杂性分析，研究两种特定扩展的计算复杂性：一种源自集体调度问题的任务长度扩展，另一种是带权重的候选人扩展。重点关注选民数量作为参数时的复杂性变化。

Result: - 任务长度扩展在仅有3名选民时就是NP难问题
- 权重扩展在4名选民时为NP难问题
- 两种扩展在2名选民的情况下都可在多项式时间内求解

Conclusion: 看似简单的Spearman footrule扩展会引入显著的计算困难，且这种困难出现得极早（仅需少量选民）。这为实际应用中这些规则的设计和使用提供了重要启示：精确算法可能仅适用于极少数选民的场景，更多情况下需要近似算法或启发式方法。

Abstract: The Spearman footrule is a voting rule that takes as input voter preferences expressed as rankings. It outputs a ranking that minimizes the sum of the absolute differences between the position of each candidate in the ranking and in the voters' preferences. In this paper, we study the computational complexity of two extensions of the Spearman footrule when the number of voters is a small constant. The first extension, introduced by Pascual et al. (2018), arises from the collective scheduling problem and treats candidates, referred to as tasks in their model, as having associated lengths. The second extension, proposed by Kumar and Vassilvitskii (2010), assigns weights to candidates; these weights serve both as lengths, as in the collective scheduling model, and as coefficients in the objective function to be minimized. Although computing a ranking under the standard Spearman footrule is polynomial-time solvable, we demonstrate that the first extension is NP-hard with as few as 3 voters, and the second extension is NP-hard with as few as 4 voters. Both extensions are polynomial-time solvable for 2 voters.

</details>


### [29] [The Lens of Abelian Embeddings](https://arxiv.org/abs/2602.22183)
*Dor Minzer*

Main category: cs.CC

TL;DR: 本文综述了关于一般k-wise相关性的逆定理研究，阐述其在数学不同背景中的出现方式、已有成果及其在离散数学和理论计算机科学中的应用，并提出了未来研究的开放问题。


<details>
  <summary>Details</summary>
Motivation: 研究一般k-wise相关性的逆定理，并解释此类相关性如何在数学的不同背景中产生。

Method: 讨论近期的一系列研究成果，概述相关结果，属于综述性研究方法。

Result: 概述了该领域已建立的结果及其在离散数学和理论计算机科学中的应用。

Conclusion: 该方向的研究具有跨学科应用价值，同时存在值得未来探索的开放性问题。

Abstract: We discuss a recent line of research investigating inverse theorems with respect to general k-wise correlations, and explain how such correlations arise in different contexts in mathematics. We outline some of the results that were established and their applications in discrete mathematics and theoretical computer science. We also mention some open problems for future research.

</details>
