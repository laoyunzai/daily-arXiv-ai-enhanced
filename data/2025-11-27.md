<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 52]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 8]
- [nlin.CD](#nlin.CD) [Total: 1]
- [quant-ph](#quant-ph) [Total: 41]
- [cs.AI](#cs.AI) [Total: 19]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding](https://arxiv.org/abs/2511.20696)
*Dan Li,Hye-Bin Shin,Yeon-Woo Choi*

Main category: cs.LG

TL;DR: 提出ProNECL框架，通过原型引导的非示例持续学习解决跨被试EEG解码中的灾难性遗忘问题，无需存储历史EEG数据。


<details>
  <summary>Details</summary>
Motivation: 由于EEG信号的个体间差异显著，在持续EEG解码任务中，引入新被试时会覆盖先前获得的知识。现有方法依赖存储历史数据作为回放缓冲区，但隐私问题和内存限制使得这种方法不切实际。

Method: 构建类级原型来总结每个被试的判别性表示，通过跨被试特征对齐和知识蒸馏，增量地将新特征空间与全局原型记忆对齐。

Result: 在BCI Competition IV 2a和2b数据集上验证，框架有效平衡知识保留和适应性，在跨被试持续EEG解码任务中实现优越性能。

Conclusion: ProNECL框架能够在无需访问历史EEG样本的情况下有效保留先验知识，为持续EEG解码提供实用解决方案。

Abstract: Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.

</details>


### [2] [Active Slice Discovery in Large Language Models](https://arxiv.org/abs/2511.20713)
*Minhui Zhang,Prahar Ijner,Yoav Wald,Elliot Creager*

Main category: cs.LG

TL;DR: 本文提出了主动切片发现方法，通过主动学习算法识别大型语言模型在特定数据子集上的系统性错误，显著减少了人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在特定数据子集上存在系统性错误，识别这些错误切片对于理解和改进模型至关重要，但传统方法需要大量人工标注。

Method: 采用主动学习算法，结合不同的特征表示方法，在毒性分类任务中发现人工定义的错误切片。

Result: 基于不确定性的主动学习算法在多个切片上表现最佳，仅使用2-10%的切片成员信息即可达到竞争性准确率，显著优于基线方法。

Conclusion: 主动切片发现是一种有效的方法，能够以较少的标注成本识别模型错误模式，为模型改进提供重要指导。

Abstract: Large Language Models (LLMs) often exhibit systematic errors on specific subsets of data, known as error slices. For instance, a slice can correspond to a certain demographic, where a model does poorly in identifying toxic comments regarding that demographic. Identifying error slices is crucial to understanding and improving models, but it is also challenging. An appealing approach to reduce the amount of manual annotation required is to actively group errors that are likely to belong to the same slice, while using limited access to an annotator to verify whether the chosen samples share the same pattern of model mistake. In this paper, we formalize this approach as Active Slice Discovery and explore it empirically on a problem of discovering human-defined slices in toxicity classification. We examine the efficacy of active slice discovery under different choices of feature representations and active learning algorithms. On several slices, we find that uncertainty-based active learning algorithms are most effective, achieving competitive accuracy using 2-10% of the available slice membership information, while significantly outperforming baselines.

</details>


### [3] [ST-PPO: Stabilized Off-Policy Proximal Policy Optimization for Multi-Turn Agents Training](https://arxiv.org/abs/2511.20718)
*Chenliang Li,Adel Elmahdy,Alex Boyd,Zhongruo Wang,Alfredo Garcia,Parminder Bhatia,Taha Kass-Hout,Cao Xiao,Mingyi Hong*

Main category: cs.LG

TL;DR: 本文针对多轮对话和推理任务中PPO训练LLM时的不稳定性和崩溃问题，提出了两种互补的稳定技术：轮级重要性采样和裁剪偏差校正，形成了ST-PPO和S-PPO等变体，在多轮搜索任务中有效防止性能崩溃并提升任务表现。


<details>
  <summary>Details</summary>
Motivation: PPO在训练大型语言模型进行多轮对话和推理任务时存在性能不稳定和容易崩溃的问题，主要源于两个原因：(1) 标记级重要性采样与多轮环境的自然粒度不匹配；(2) 离策略样本产生的优势估计不准确，导致高方差梯度和不稳定更新。

Method: 提出了两种稳定技术：1) 轮级重要性采样，使优化与多轮推理的自然结构对齐；2) 裁剪偏差校正，通过降低不可靠、高度离策略样本的权重来归一化梯度。基于这些组件的不同组合，形成了Turn-PPO、S-PPO和ST-PPO三种变体。

Result: 在通用问答、多跳问答和医学多选题等多个多轮搜索任务上的实验表明，ST-PPO和S-PPO能够一致地防止大模型训练中观察到的性能崩溃，在整个优化过程中保持较低的裁剪比率，并比标准标记级PPO获得更高的任务性能。

Conclusion: 将轮级重要性采样与裁剪偏差校正相结合，为稳定多轮LLM智能体训练提供了一个实用且可扩展的解决方案。

Abstract: PPO has been widely adopted for training large language models (LLMs) at the token level in multi-turn dialogue and reasoning tasks. However, its performance is often unstable and prone to collapse. Through empirical analysis, we identify two main sources of instability in this setting: (1)~token-level importance sampling, which is misaligned with the natural granularity of multi-turn environments that have distinct turn-level stages, and (2) inaccurate advantage estimates from off-policy samples, where the critic has not learned to evaluate certain state-action pairs, resulting in high-variance gradients and unstable updates. To address these challenges, we introduce two complementary stabilization techniques: (1) turn-level importance sampling, which aligns optimization with the natural structure of multi-turn reasoning, and (2) clipping-bias correction, which normalizes gradients by downweighting unreliable, highly off-policy samples. Depending on how these components are combined, we obtain three variants: Turn-PPO (turn-level sampling only), S-PPO (clipping-bias correction applied to token-level PPO), and ST-PPO (turn-level sampling combined with clipping-bias correction). In our experiments, we primarily study ST-PPO and S-PPO, which together demonstrate how the two stabilization mechanisms address complementary sources of instability. Experiments on multi-turn search tasks across general QA, multi-hop QA, and medical multiple-choice QA benchmarks show that ST-PPO and S-PPO consistently prevent the performance collapses observed in large-model training, maintain lower clipping ratios throughout optimization, and achieve higher task performance than standard token-level PPO. These results demonstrate that combining turn-level importance sampling with clipping-bias correction provides a practical and scalable solution for stabilizing multi-turn LLM agent training.

</details>


### [4] [Gradient Descent Algorithm Survey](https://arxiv.org/abs/2511.20725)
*Deng Fucheng,Wang Wanjie,Gong Ao,Wang Xiaoqi,Wang Fan*

Main category: cs.LG

TL;DR: 本文系统分析了SGD、Mini-batch SGD、Momentum、Adam和Lion五种深度学习优化算法的核心优势、局限性和实践建议，为算法选择和参数调优提供标准化参考。


<details>
  <summary>Details</summary>
Motivation: 针对深度学习优化算法的实际配置需求，解决不同规模模型和训练场景中的优化挑战，为学术研究和工程实践提供合理选择和性能提升的指导。

Method: 系统分析五种主要优化算法（SGD、Mini-batch SGD、Momentum、Adam、Lion）的核心特性，包括各自的优势、局限性和关键实践建议。

Result: 深入理解了这五种优化算法的特性，建立了标准化的参考框架，能够指导算法选择、参数调优和性能改进。

Conclusion: 该研究为深度学习优化算法的合理配置提供了系统性的指导，有助于在不同模型规模和训练场景下有效解决优化问题。

Abstract: Focusing on the practical configuration needs of optimization algorithms in deep learning, this article concentrates on five major algorithms: SGD, Mini-batch SGD, Momentum, Adam, and Lion. It systematically analyzes the core advantages, limitations, and key practical recommendations of each algorithm. The research aims to gain an in-depth understanding of these algorithms and provide a standardized reference for the reasonable selection, parameter tuning, and performance improvement of optimization algorithms in both academic research and engineering practice, helping to solve optimization challenges in different scales of models and various training scenarios.

</details>


### [5] [Spatio-Temporal Trajectory Foundation Model - Recent Advances and Future Directions](https://arxiv.org/abs/2511.20729)
*Sean Bin Yang,Ying Sun,Yunyao Cheng,Yan Lin,Kristian Torp,Jilin Hu*

Main category: cs.LG

TL;DR: 本文对轨迹基础模型（TFMs）这一时空基础模型的重要子类进行了系统调查，提供了现有方法的分类和批判性分析，并指出了开放挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管时空基础模型（STFMs）发展迅速，但对轨迹基础模型（TFMs）这一关键子类的系统性研究仍然缺乏，本文旨在填补这一空白。

Method: 通过提供现有方法的全面概述和分类，进行批判性分析，识别TFMs的优势和局限性。

Result: 建立了TFMs的方法论分类体系，分析了各种方法的优缺点，为领域发展提供了系统框架。

Conclusion: TFMs的发展对于推进时空通用智能至关重要，需要开发更鲁棒、负责任和可迁移的模型，本文为未来研究指明了方向。

Abstract: Foundation models (FMs) have emerged as a powerful paradigm, enabling a diverse range of data analytics and knowledge discovery tasks across scientific fields. Inspired by the success of FMs, particularly large language models, researchers have recently begun to explore spatio-temporal foundation models (STFMs) to improve adaptability and generalization across a wide spectrum of spatio-temporal (ST) tasks. Despite rapid progress, a systematic investigation of trajectory foundation models (TFMs), a crucial subclass of STFMs, is largely lacking. This tutorial addresses this gap by offering a comprehensive overview of recent advances in TFMs, including a taxonomy of existing methodologies and a critical analysis of their strengths and limitations. In addition, the tutorial highlights open challenges and outlines promising research directions to advance spatio-temporal general intelligence through the development of robust, responsible, and transferable TFMs.

</details>


### [6] [CHiQPM: Calibrated Hierarchical Interpretable Image Classification](https://arxiv.org/abs/2511.20779)
*Thomas Norrenbrock,Timo Kaiser,Sovan Biswas,Neslihan Kose,Ramesh Manuvinakurike,Bodo Rosenhahn*

Main category: cs.LG

TL;DR: CHiQPM是一个全局可解释模型，提供全面的全局和局部可解释性，在保持非可解释模型99%准确率的同时，提供分层解释和内置的可解释性符合预测方法。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域，除了全局解释外，详细的局部解释对于有效支持人类专家在推理过程中至关重要，需要实现人机互补。

Method: 提出校准分层QPM(CHiQPM)，通过对比解释大多数类别实现优越的全局可解释性，并提供新颖的分层解释，这些解释更类似于人类推理方式，并可遍历以提供内置的可解释性符合预测方法。

Result: CHiQPM作为点预测器达到最先进的准确率，保持非可解释模型99%的准确率，其校准集合预测在效率上与其他CP方法竞争，同时提供沿其分层解释的连贯集合的可解释预测。

Conclusion: CHiQPM在可解释性方面实现了显著改进，在不牺牲整体准确性的情况下融入了可解释性，为人类-AI互补铺平了道路。

Abstract: Globally interpretable models are a promising approach for trustworthy AI in safety-critical domains. Alongside global explanations, detailed local explanations are a crucial complement to effectively support human experts during inference. This work proposes the Calibrated Hierarchical QPM (CHiQPM) which offers uniquely comprehensive global and local interpretability, paving the way for human-AI complementarity. CHiQPM achieves superior global interpretability by contrastively explaining the majority of classes and offers novel hierarchical explanations that are more similar to how humans reason and can be traversed to offer a built-in interpretable Conformal prediction (CP) method. Our comprehensive evaluation shows that CHiQPM achieves state-of-the-art accuracy as a point predictor, maintaining 99% accuracy of non-interpretable models. This demonstrates a substantial improvement, where interpretability is incorporated without sacrificing overall accuracy. Furthermore, its calibrated set prediction is competitively efficient to other CP methods, while providing interpretable predictions of coherent sets along its hierarchical explanation.

</details>


### [7] [Physics Steering: Causal Control of Cross-Domain Concepts in a Physics Foundation Model](https://arxiv.org/abs/2511.20798)
*Rio Alexa Fear,Payel Mukhopadhyay,Michael McCabe,Alberto Bietti,Miles Cranmer*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in mechanistic interpretability have revealed that large language models (LLMs) develop internal representations corresponding not only to concrete entities but also distinct, human-understandable abstract concepts and behaviour. Moreover, these hidden features can be directly manipulated to steer model behaviour. However, it remains an open question whether this phenomenon is unique to models trained on inherently structured data (ie. language, images) or if it is a general property of foundation models. In this work, we investigate the internal representations of a large physics-focused foundation model. Inspired by recent work identifying single directions in activation space for complex behaviours in LLMs, we extract activation vectors from the model during forward passes over simulation datasets for different physical regimes. We then compute "delta" representations between the two regimes. These delta tensors act as concept directions in activation space, encoding specific physical features. By injecting these concept directions back into the model during inference, we can steer its predictions, demonstrating causal control over physical behaviours, such as inducing or removing some particular physical feature from a simulation. These results suggest that scientific foundation models learn generalised representations of physical principles. They do not merely rely on superficial correlations and patterns in the simulations. Our findings open new avenues for understanding and controlling scientific foundation models and has implications for AI-enabled scientific discovery.

</details>


### [8] [Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning](https://arxiv.org/abs/2511.20811)
*Aaron O. Feldman,D. Isaiah Harp,Joseph Duncan,Mac Schwager*

Main category: cs.LG

TL;DR: 开发了一种数据驱动的方法，用于飞行测试中的运行时安全监控，通过离线随机轨迹模拟学习短期安全风险的校准统计模型，为飞行员提供预先中止操作的明确标准。


<details>
  <summary>Details</summary>
Motivation: 飞行测试中存在参数不确定性，可能导致意外安全违规，飞行员需要明确的预先标准来在安全违规发生前中止操作。

Method: 包含三个主要组件：基于最近观测预测未来状态的模型、对预测状态安全性进行分类的最近邻模型，以及通过保形预测进行分类器校准。

Result: 在具有不确定参数的飞行动力学模型上评估，证明该方法能可靠识别不安全场景，匹配理论保证，并在风险预先分类方面优于基线方法。

Conclusion: 该方法为飞行测试中的安全监控提供了一种有效的数据驱动解决方案，能够提前识别安全风险并指导操作中止决策。

Abstract: We develop a data-driven approach for runtime safety monitoring in flight testing, where pilots perform maneuvers on aircraft with uncertain parameters. Because safety violations can arise unexpectedly as a result of these uncertainties, pilots need clear, preemptive criteria to abort the maneuver in advance of safety violation. To solve this problem, we use offline stochastic trajectory simulation to learn a calibrated statistical model of the short-term safety risk facing pilots. We use flight testing as a motivating example for data-driven learning/monitoring of safety due to its inherent safety risk, uncertainty, and human-interaction. However, our approach consists of three broadly-applicable components: a model to predict future state from recent observations, a nearest neighbor model to classify the safety of the predicted state, and classifier calibration via conformal prediction. We evaluate our method on a flight dynamics model with uncertain parameters, demonstrating its ability to reliably identify unsafe scenarios, match theoretical guarantees, and outperform baseline approaches in preemptive classification of risk.

</details>


### [9] [Autoregressive Surrogate Modeling of the Solar Wind with Spherical Fourier Neural Operator](https://arxiv.org/abs/2511.20830)
*Reza Mansouri,Dustin Kempton,Pete Riley,Rafal Angryk*

Main category: cs.LG

TL;DR: 本文提出了首个基于自回归机器学习的太阳风径向速度替代模型，使用球面傅里叶神经算子(SFNO)来预测稳态太阳风，相比传统三维磁流体动力学模型计算效率更高，能够快速探索边界条件不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统三维磁流体动力学模型计算成本高昂，限制了空间天气预报中对边界条件不确定性的快速探索，需要开发更高效的替代模型来准确预测太阳风特征如高速流和日冕物质抛射。

Method: 使用球面傅里叶神经算子(SFNO)构建自回归机器学习替代模型，通过预测有限径向范围并迭代向外传播解，相比单步方法提高了远距离区域的准确性。

Result: 与数值HUX替代模型相比，SFNO表现出相当或更优的性能，同时提供了灵活、可训练和数据驱动的替代方案。

Conclusion: 该研究为高保真太阳风建模建立了一种新颖的方法论，为空间天气预报提供了更高效的计算工具。

Abstract: The solar wind, a continuous outflow of charged particles from the Sun's corona, shapes the heliosphere and impacts space systems near Earth. Accurate prediction of features such as high-speed streams and coronal mass ejections is critical for space weather forecasting, but traditional three-dimensional magnetohydrodynamic (MHD) models are computationally expensive, limiting rapid exploration of boundary condition uncertainties. We introduce the first autoregressive machine learning surrogate for steady-state solar wind radial velocity using the Spherical Fourier Neural Operator (SFNO). By predicting a limited radial range and iteratively propagating the solution outward, the model improves accuracy in distant regions compared to a single-step approach. Compared with the numerical HUX surrogate, SFNO demonstrates superior or comparable performance while providing a flexible, trainable, and data-driven alternative, establishing a novel methodology for high-fidelity solar wind modeling. The source code and additional visual results are available at https://github.com/rezmansouri/solarwind-sfno-velocity-autoregressive.

</details>


### [10] [Primal: A Unified Deterministic Framework for Quasi-Orthogonal Hashing and Manifold Learning](https://arxiv.org/abs/2511.20839)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: Primal是一个基于素数平方根数论独立性的确定性特征映射框架，通过无理频率调制构建可调谐的向量表示，提供优于随机投影的准正交性和分布紧致性。


<details>
  <summary>Details</summary>
Motivation: 现有随机投影方法（如随机傅里叶特征）存在随机性限制，作者希望开发一种确定性特征映射框架，利用素数平方根的数学特性构建更鲁棒、可调谐的向量表示。

Method: 提出两种算法变体：StaticPrime（生成接近Welch界准正交性的时序位置编码）和DynamicPrime（通过单一缩放参数σ统一等距核映射和最大熵单向哈希两种数学效用）。

Result: 经验评估显示该框架在正交性保持和分布紧致性方面优于归一化高斯基线，成为随机矩阵投影的计算高效、数学严谨的替代方案。

Conclusion: Primal框架通过素数平方根的数论特性，提供了一个确定性、可调谐的特征映射方法，在信号重构、压缩感知、超维计算和隐私保护学习等应用中展现出优越性能。

Abstract: We present Primal, a deterministic feature mapping framework that harnesses the number-theoretic independence of prime square roots to construct robust, tunable vector representations. Diverging from standard stochastic projections (e.g., Random Fourier Features), our method exploits the Besicovitch property to create irrational frequency modulations that guarantee infinite non-repeating phase trajectories. We formalize two distinct algorithmic variants: (1) StaticPrime, a sequence generation method that produces temporal position encodings empirically approaching the theoretical Welch bound for quasi-orthogonality; and (2) DynamicPrime, a tunable projection layer for input-dependent feature mapping. A central novelty of the dynamic framework is its ability to unify two disparate mathematical utility classes through a single scaling parameter σ. In the low-frequency regime, the method acts as an isometric kernel map, effectively linearizing non-convex geometries (e.g., spirals) to enable high-fidelity signal reconstruction and compressive sensing. Conversely, the high-frequency regime induces chaotic phase wrapping, transforming the projection into a maximum-entropy one-way hash suitable for Hyperdimensional Computing and privacy-preserving Split Learning. Empirical evaluations demonstrate that our framework yields superior orthogonality retention and distribution tightness compared to normalized Gaussian baselines, establishing it as a computationally efficient, mathematically rigorous alternative to random matrix projections. The code is available at https://github.com/VladimerKhasia/primal

</details>


### [11] [Selecting Belief-State Approximations in Simulators with Latent States](https://arxiv.org/abs/2511.20870)
*Nan Jiang*

Main category: cs.LG

TL;DR: 本文研究模拟器中状态重置的基本能力，特别是在存在隐变量的复杂模拟器中如何选择近似信念状态采样器的问题。通过将问题简化为条件分布选择任务，提出了两种不同的选择方法：基于隐状态的选择和基于观测的选择，并分析了它们与下游展开方法的相互作用。


<details>
  <summary>Details</summary>
Motivation: 状态重置是模拟器的基本能力，支持基于样本的规划和模拟器校准。但在复杂模拟器中，当存在隐变量时，状态重置需要从给定观测历史的隐状态后验分布中采样，这通常不可行。因此需要研究如何仅通过采样访问模拟器来选择近似信念状态采样器。

Method: 将信念状态选择问题简化为一般条件分布选择任务，在仅采样访问条件下开发新算法和分析。提出了两种选择方法：基于隐状态的选择（直接针对隐状态的条件分布）和基于观测的选择（针对观测的诱导分布）。

Result: 发现两种选择方法在下游展开方法中的保证不同：基于观测的选择在最自然的单次重置方法下可能失败，但在较少使用的重复重置方法下具有保证。揭示了算法选择、理论细微差别和开放问题的丰富景观。

Conclusion: 在看似简单的状态重置问题中，存在丰富的算法选择、理论细微差别和开放问题。基于观测的选择和基于隐状态的选择与不同展开方法的相互作用需要仔细考虑，包括分布偏移和采样策略选择等问题。

Abstract: State resetting is a fundamental but often overlooked capability of simulators. It supports sample-based planning by allowing resets to previously encountered simulation states, and enables calibration of simulators using real data by resetting to states observed in real-system traces. While often taken for granted, state resetting in complex simulators can be nontrivial: when the simulator comes with latent variables (states), state resetting requires sampling from the posterior over the latent state given the observable history, a.k.a. the belief state (Silver and Veness, 2010). While exact sampling is often infeasible, many approximate belief-state samplers can be constructed, raising the question of how to select among them using only sampling access to the simulator.
  In this paper, we show that this problem reduces to a general conditional distribution-selection task and develop a new algorithm and analysis under sampling-only access. Building on this reduction, the belief-state selection problem admits two different formulations: latent state-based selection, which directly targets the conditional distribution of the latent state, and observation-based selection, which targets the induced distribution over the observation. Interestingly, these formulations differ in how their guarantees interact with the downstream roll-out methods: perhaps surprisingly, observation-based selection may fail under the most natural roll-out method (which we call Single-Reset) but enjoys guarantees under the less conventional alternative (which we call Repeated-Reset). Together with discussion on issues such as distribution shift and the choice of sampling policies, our paper reveals a rich landscape of algorithmic choices, theoretical nuances, and open questions, in this seemingly simple problem.

</details>


### [12] [Probabilistic Hash Embeddings for Online Learning of Categorical Features](https://arxiv.org/abs/2511.20893)
*Aodong Li,Abishek Sankararaman,Balakrishnan Narayanaswamy*

Main category: cs.LG

TL;DR: 提出概率哈希嵌入(PHE)模型解决在线学习中确定性嵌入对类别到达顺序敏感和遗忘问题，通过贝叶斯在线学习实现增量学习，具有内存高效、适应新类别、不遗忘旧类别等优势。


<details>
  <summary>Details</summary>
Motivation: 在线学习环境中，传统特征哈希方法对类别到达顺序敏感且存在遗忘问题，导致性能下降，需要一种能处理不断增长词汇表的方法。

Method: 提出概率哈希嵌入(PHE)模型，将哈希嵌入视为随机变量，应用贝叶斯在线学习增量学习数据，推导出可扩展的推理算法来学习模型参数和更新哈希嵌入后验分布。

Result: 在分类、序列建模和推荐系统的在线学习实验中，PHE表现出优越性能，同时保持高内存效率（仅消耗one-hot嵌入表2-4倍内存）。

Conclusion: PHE模型能有效处理在线学习中不断演化的分类特征词汇表，对项目到达顺序不敏感，且不会遗忘旧项目，具有实际应用价值。

Abstract: We study streaming data with categorical features where the vocabulary of categorical feature values is changing and can even grow unboundedly over time. Feature hashing is commonly used as a pre-processing step to map these categorical values into a feature space of fixed size before learning their embeddings. While these methods have been developed and evaluated for offline or batch settings, in this paper we consider online settings. We show that deterministic embeddings are sensitive to the arrival order of categories and suffer from forgetting in online learning, leading to performance deterioration. To mitigate this issue, we propose a probabilistic hash embedding (PHE) model that treats hash embeddings as stochastic and applies Bayesian online learning to learn incrementally from data. Based on the structure of PHE, we derive a scalable inference algorithm to learn model parameters and infer/update the posteriors of hash embeddings and other latent variables. Our algorithm (i) can handle an evolving vocabulary of categorical items, (ii) is adaptive to new items without forgetting old items, (iii) is implementable with a bounded set of parameters that does not grow with the number of distinct observed values on the stream, and (iv) is invariant to the item arrival order. Experiments in classification, sequence modeling, and recommendation systems in online learning setups demonstrate the superior performance of PHE while maintaining high memory efficiency (consumes as low as 2~4 memory of a one-hot embedding table). Supplementary materials are at https://github.com/aodongli/probabilistic-hash-embeddings

</details>


### [13] [Evolved SampleWeights for Bias Mitigation: Effectiveness Depends on Optimization Objectives](https://arxiv.org/abs/2511.20909)
*Anil K. Saini,Jose Guadalupe Hernandez,Emily F. Wong,Debanshi Misra,Jason H. Moore*

Main category: cs.LG

TL;DR: 本文比较了三种数据重加权方法（遗传算法、数据集特征计算、等权重）来减轻机器学习模型预测中的偏见，通过11个公开数据集实验发现，使用遗传算法优化的权重能在公平性和预测性能之间实现更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在真实世界数据上训练时可能产生有偏见的预测，对边缘化群体产生负面影响，需要有效方法来减轻这种偏见。

Method: 比较三种权重生成方法：遗传算法进化权重、基于数据集特征计算权重、等权重分配；使用准确率、AUC、人口统计均等差异、子群假阴性公平性等指标评估模型性能。

Result: 实验表明，进化样本权重能产生在公平性和预测性能之间更好权衡的模型，但优化目标的选择对效果影响很大，准确率和人口统计均等差异的组合效果最佳。

Conclusion: 遗传算法优化的重加权方法能有效平衡模型公平性和预测性能，但优化目标的选择至关重要，准确率和人口统计均等差异是最有效的组合。

Abstract: Machine learning models trained on real-world data may inadvertently make biased predictions that negatively impact marginalized communities. Reweighting is a method that can mitigate such bias in model predictions by assigning a weight to each data point used during model training. In this paper, we compare three methods for generating these weights: (1) evolving them using a Genetic Algorithm (GA), (2) computing them using only dataset characteristics, and (3) assigning equal weights to all data points. Model performance under each strategy was evaluated using paired predictive and fairness metrics, which also served as optimization objectives for the GA during evolution. Specifically, we used two predictive metrics (accuracy and area under the Receiver Operating Characteristic curve) and two fairness metrics (demographic parity difference and subgroup false negative fairness). Using experiments on eleven publicly available datasets (including two medical datasets), we show that evolved sample weights can produce models that achieve better trade-offs between fairness and predictive performance than alternative weighting methods. However, the magnitude of these benefits depends strongly on the choice of optimization objectives. Our experiments reveal that optimizing with accuracy and demographic parity difference metrics yields the largest number of datasets for which evolved weights are significantly better than other weighting strategies in optimizing both objectives.

</details>


### [14] [Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment](https://arxiv.org/abs/2511.20913)
*Yingchuan Sun,Shengpu Tang*

Main category: cs.LG

TL;DR: 本文通过实证研究比较了四种时间步长（1、2、4、8小时）在脓毒症管理强化学习中的影响，发现更细的时间步长（1和2小时）在静态行为策略下能获得最佳性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有脓毒症管理强化学习研究大多使用4小时时间步长，但该粗粒度可能扭曲患者动态并导致次优治疗策略。本文旨在量化时间步长对状态表示学习、行为克隆、策略训练和离策略评估的影响程度。

Method: 采用相同的离线强化学习流程，设计了动作重映射方法以实现不同时间步长数据集间的公平比较，并在两种策略学习设置下进行跨时间步长模型选择。

Result: 结果表明，不同学习设置下性能趋势随时间步长变化，使用静态行为策略在更细时间步长（1和2小时）学习的策略实现了整体最佳性能和稳定性。

Conclusion: 时间步长是医疗保健离线强化学习的核心设计选择，研究结果为超越传统4小时设置的替代方案提供了证据支持。

Abstract: Existing studies on reinforcement learning (RL) for sepsis management have mostly followed an established problem setup, in which patient data are aggregated into 4-hour time steps. Although concerns have been raised regarding the coarseness of this time-step size, which might distort patient dynamics and lead to suboptimal treatment policies, the extent to which this is a problem in practice remains unexplored. In this work, we conducted empirical experiments for a controlled comparison of four time-step sizes ($Δt\!=\!1,2,4,8$ h) on this domain, following an identical offline RL pipeline. To enable a fair comparison across time-step sizes, we designed action re-mapping methods that allow for evaluation of policies on datasets with different time-step sizes, and conducted cross-$Δt$ model selections under two policy learning setups. Our goal was to quantify how time-step size influences state representation learning, behavior cloning, policy training, and off-policy evaluation. Our results show that performance trends across $Δt$ vary as learning setups change, while policies learned at finer time-step sizes ($Δt = 1$ h and $2$ h) using a static behavior policy achieve the overall best performance and stability. Our work highlights time-step size as a core design choice in offline RL for healthcare and provides evidence supporting alternatives beyond the conventional 4-hour setup.

</details>


### [15] [Operationalizing Quantized Disentanglement](https://arxiv.org/abs/2511.20927)
*Vitoria Barin-Pacela,Kartik Ahuja,Simon Lacoste-Julien,Pascal Vincent*

Main category: cs.LG

TL;DR: 本文提出了一种名为Cliff的无监督解缠方法，通过鼓励轴对齐的密度不连续性来恢复潜在因素的量化，在非线性映射下实现了优于基线的解缠性能。


<details>
  <summary>Details</summary>
Motivation: 现有理论表明，在任意微分同胚下，量化因素具有无监督可识别性，但将这一理论原则转化为有效的实践标准仍然具有挑战性，特别是在非线性映射下。

Method: 开发了一种鼓励轴对齐不连续性的无监督解缠准则，这些不连续性表现为因素估计密度的急剧变化（称为cliffs），并遵循理论中独立不连续性的定义，鼓励沿某个因素的cliffs位置与其他因素的值相互独立。

Result: Cliff方法在所有解缠基准测试中都优于基线方法，证明了其在无监督解缠中的有效性。

Conclusion: 通过鼓励轴对齐的密度不连续性，Cliff方法成功地将理论原则转化为有效的实践标准，在无监督解缠任务中表现出色。

Abstract: Recent theoretical work established the unsupervised identifiability of quantized factors under any diffeomorphism. The theory assumes that quantization thresholds correspond to axis-aligned discontinuities in the probability density of the latent factors. By constraining a learned map to have a density with axis-aligned discontinuities, we can recover the quantization of the factors. However, translating this high-level principle into an effective practical criterion remains challenging, especially under nonlinear maps. Here, we develop a criterion for unsupervised disentanglement by encouraging axis-aligned discontinuities. Discontinuities manifest as sharp changes in the estimated density of factors and form what we call cliffs. Following the definition of independent discontinuities from the theory, we encourage the location of the cliffs along a factor to be independent of the values of the other factors. We show that our method, Cliff, outperforms the baselines on all disentanglement benchmarks, demonstrating its effectiveness in unsupervised disentanglement.

</details>


### [16] [Semantic Superiority vs. Forensic Efficiency: A Comparative Analysis of Deep Learning and Psycholinguistics for Business Email Compromise Detection](https://arxiv.org/abs/2511.20944)
*Yaw Osei Adjei*

Main category: cs.LG

TL;DR: 本文研究了两种BEC检测方法：基于心理语言学的CatBoost方法和基于深度学习的DistilBERT方法，两者在检测性能和成本效益方面各有优势，投资回报率均超过99.96%。


<details>
  <summary>Details</summary>
Motivation: BEC攻击造成巨大经济损失（年损失29亿美元），存在显著的经济不对称性：漏报成本远高于误报成本（比例约1:5480），需要开发高效的检测方案。

Method: 提出双流检测范式：1）法证心理语言学流使用CatBoost分析心理语言线索，具有高可解释性和低延迟；2）语义流使用DistilBERT进行深度学习上下文理解，精度更高但计算成本较大。

Result: DistilBERT在对抗性数据集上表现优异（AUC=1.0000，F1=0.9981），延迟7.403毫秒；CatBoost检测性能竞争性（AUC=0.9905，F1=0.9486），延迟低8.4倍（0.885毫秒），计算资源消耗可忽略。

Conclusion: 拥有GPU基础设施的组织推荐使用DistilBERT以获得更高精度；边缘部署或成本敏感环境推荐CatBoost，两者通过成本敏感学习优化后投资回报率均超过99.96%。

Abstract: Business Email Compromise (BEC) is a sophisticated social engineering threat that manipulates organizational hierarchies and exploits psychological vulnerabilities, leading to significant financial damage. According to the 2024 FBI Internet Crime Report, BEC accounts for over $2.9 billion in annual adjusted losses, presenting significant economic asymmetry: the cost of a False Negative (fraud loss) exceeds the cost of a False Positive (manual review) by orders of magnitude (approximately 1 to 5,480).
  This paper examines two detection paradigms for BEC: the Forensic Psycholinguistic Stream, which utilizes CatBoost to analyze psycholinguistic cues with high interpretability and low latency, and the Semantic Stream, which employs DistilBERT for deep learning-based contextual language understanding, offering superior accuracy at higher computational cost. We evaluated DistilBERT on an adversarially poisoned dataset (N = 7,990) generated via our Black Hole protocol, benchmarked on Tesla T4 GPU infrastructure, achieving superior detection (AUC = 1.0000, F1 = 0.9981) with acceptable real-time latency (7.403 milliseconds). CatBoost achieves competitive detection (AUC = 0.9905, F1 = 0.9486) at 8.4x lower latency (0.885 milliseconds), consuming negligible computational resources. For organizations with GPU infrastructure, DistilBERT offers superior accuracy. CatBoost is preferable for edge deployments or cost-sensitive environments due to comparable security and lower operational costs. Both approaches demonstrate return on investment exceeding 99.96% when optimized through cost-sensitive learning, by significantly reducing false negatives and associated financial losses.

</details>


### [17] [Subgoal Graph-Augmented Planning for LLM-Guided Open-World Reinforcement Learning](https://arxiv.org/abs/2511.20993)
*Shanwei Fan*

Main category: cs.LG

TL;DR: 提出了SGA-ACR框架，通过集成环境特定的子目标图和多LLM规划管道，解决LLM在强化学习中规划与执行不对齐的问题。


<details>
  <summary>Details</summary>
Motivation: LLM在强化学习中提供高层次规划能力，但由于缺乏环境特定知识和自我验证机制，产生的子目标往往不可行或不可靠，导致规划与执行严重不对齐。

Method: SGA-ACR框架包含环境特定子目标图、结构化实体知识，以及明确分离生成、批判和精炼的多LLM规划管道，同时使用子目标跟踪器监控执行进度并提供辅助奖励。

Result: 在开放世界游戏"Crafter"的22个多样化任务上的实验结果表明该方法的有效性。

Conclusion: 通过集成环境特定知识和结构化多LLM规划流程，SGA-ACR能够产生可执行且可验证的子目标，有效解决了LLM规划与执行的对齐问题。

Abstract: Large language models (LLMs) offer strong high-level planning capabilities for reinforcement learning (RL) by decomposing tasks into subgoals. However, their practical utility is limited by poor planning-execution alignment, which reflects a critical gap between abstract plans and actionable, environment-compatible behaviors. This misalignment arises from two interrelated limitations: (1) LLMs often produce subgoals that are semantically plausible but infeasible or irrelevant in the target environment due to insufficient grounding in environment-specific knowledge, and (2) single-LLM planning conflates generation with self-verification, resulting in overconfident yet unreliable subgoals that frequently fail during execution. To address these challenges, we propose Subgoal Graph-Augmented Actor-Critic-Refiner (SGA-ACR), a framework that integrates an environment-specific subgoal graph and structured entity knowledge with a multi-LLM planning pipeline that explicitly separates generation, critique, and refinement to produce executable and verifiable subgoals. A subgoal tracker further monitors execution progress, provides auxiliary rewards, and adaptively updates the subgoal graph to maintain alignment between plans and actions. Experimental results on 22 diverse tasks in the open-world game "Crafter" demonstrate the effectiveness of our proposed method.

</details>


### [18] [FANoise: Singular Value-Adaptive Noise Modulation for Robust Multimodal Representation Learning](https://arxiv.org/abs/2511.20997)
*Jiaoyang Li,Jun Fang,Tianhao Gao,Xiaohui Zhang,Zhiyuan Liu,Chao Liu,Pengzhang Liu,Qixia Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种特征自适应噪声注入策略FANoise，用于改进多模态表示学习，通过动态调整噪声来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有表示学习方法大多依赖启发式或静态噪声注入，忽略了训练过程中特征分布的动态特性，导致噪声注入效果受限。

Method: 从梯度和特征分布角度系统研究噪声在表示学习中的作用，提出基于对比学习动态特性的特征自适应噪声注入策略FANoise。

Result: 在各种基础VLM模型上的综合实验表明，FANoise在多模态任务上持续提升整体性能。

Conclusion: FANoise通过动态噪声注入有效缓解了噪声的负面影响，同时保留了其益处，为表示学习提供了理论依据和实践指导。

Abstract: Representation learning is fundamental to modern machine learning, powering applications such as text retrieval and multimodal understanding. However, learning robust and generalizable representations remains challenging. While prior work has demonstrated that active noise injection, a form of data augmentation, can enhance encoding performance, most existing methods rely on heuristic or static noise, overlooking the dynamic nature of feature distributions during training. In this work, we systematically study the role of noise in representation learning from both gradient-based and feature distribution perspectives, using InfoNCE loss as a representative example. Focusing on multimodal representation learning, we propose FANoise, a novel feature-adaptive noise injection strategy. By leveraging the dynamics of contrastive learning, FANoise effectively mitigates the negative impacts of noise while preserving its benefits. Under this theoretically grounded framework, comprehensive experiments demonstrate that FANoise consistently improves overall performance on multimodal tasks across various base VLM models.

</details>


### [19] [Estimating Ising Models in Total Variation Distance](https://arxiv.org/abs/2511.21008)
*Constantinos Daskalakis,Vardis Kandiros,Rui Yao*

Main category: cs.LG

TL;DR: 本文提出了一个统一框架来分析Ising模型的最大伪似然估计器(MPLE)，针对两类广义Ising模型：具有有界算子范数且满足修正对数Sobolev不等式(MLSI)的模型，以及具有有界无穷范数(有界宽度)的模型。


<details>
  <summary>Details</summary>
Motivation: 尽管Ising模型在总变差距离下的统计复杂性已被充分理解，但识别计算和统计高效算法仍然具有挑战性。现有研究在特定设置下取得了进展，但缺乏统一的框架。

Method: 使用最大伪似然估计器(MPLE)，结合张量化不等式、测度分解和集中界等多种工具进行分析。

Result: 为两类广义Ising模型提供了多项式时间算法和最优或接近最优的样本复杂度保证，统一了多种设置下的结果。

Conclusion: 该框架为Ising模型的统一分析提供了有效工具，在多种设置下都能获得计算和统计上的高效性能。

Abstract: We consider the problem of estimating Ising models over $n$ variables in Total Variation (TV) distance, given $l$ independent samples from the model. While the statistical complexity of the problem is well-understood [DMR20], identifying computationally and statistically efficient algorithms has been challenging. In particular, remarkable progress has occurred in several settings, such as when the underlying graph is a tree [DP21, BGPV21], when the entries of the interaction matrix follow a Gaussian distribution [GM24, CK24], or when the bulk of its eigenvalues lie in a small interval [AJK+24, KLV24], but no unified framework for polynomial-time estimation in TV exists so far. Our main contribution is a unified analysis of the Maximum Pseudo-Likelihood Estimator (MPLE) for two general classes of Ising models. The first class includes models that have bounded operator norm and satisfy the Modified Log-Sobolev Inequality (MLSI), a functional inequality that was introduced to study the convergence of the associated Glauber dynamics to stationarity. In the second class of models, the interaction matrix has bounded infinity norm (or bounded width), which is the most common assumption in the literature for structure learning of Ising models. We show how our general results for these classes yield polynomial-time algorithms and optimal or near-optimal sample complexity guarantees in a variety of settings. Our proofs employ a variety of tools from tensorization inequalities to measure decompositions and concentration bounds.

</details>


### [20] [ChatGpt Content detection: A new approach using xlm-roberta alignment](https://arxiv.org/abs/2511.21009)
*Md Tasnin Tanvir,Dr Santanu Kumar Dash,Ishan Shahnan,Nafis Fuad,Tanvir Rahman,Abdullah Al Faisal,Asadullah Al Mamun*

Main category: cs.LG

TL;DR: 本文提出了一种使用XLM-RoBERTa模型检测AI生成文本的方法，包括预处理、特征提取和模型微调，在多种文本类型上表现出高准确率。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等生成式AI技术的普及，区分AI生成文本与人类撰写内容的需求日益迫切，需要维护学术诚信和促进AI系统的透明度与问责制。

Method: 使用XLM-RoBERTa多语言transformer模型，结合严格的预处理和特征提取（包括困惑度、语义和可读性特征），在平衡的人类和AI生成文本数据集上进行微调。

Result: 模型在各种文本类型上表现出高准确率和稳健性能，特征分析显示困惑度和基于注意力的特征在区分人类和AI生成文本中起关键作用。

Conclusion: 该方法为维护学术诚信提供了有价值的工具，并有助于AI伦理领域的发展。未来研究方向包括探索其他先进模型和扩展数据集以增强模型的泛化能力。

Abstract: The challenge of separating AI-generated text from human-authored content is becoming more urgent as generative AI technologies like ChatGPT become more widely available. In this work, we address this issue by looking at both the detection of content that has been entirely generated by AI and the identification of human text that has been reworded by AI. In our work, a comprehensive methodology to detect AI- generated text using XLM-RoBERTa, a state-of-the-art multilingual transformer model. Our approach includes rigorous preprocessing, and feature extraction involving perplexity, semantic, and readability features. We fine-tuned the XLM-RoBERTa model on a balanced dataset of human and AI-generated texts and evaluated its performance. The model demonstrated high accuracy and robust performance across various text genres. Additionally, we conducted feature analysis to understand the model's decision-making process, revealing that perplexity and attention-based features are critical in differentiating between human and AI-generated texts. Our findings offer a valuable tool for maintaining academic integrity and contribute to the broader field of AI ethics by promoting transparency and accountability in AI systems. Future research directions include exploring other advanced models and expanding the dataset to enhance the model's generalizability.

</details>


### [21] [Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning](https://arxiv.org/abs/2511.21011)
*Sid Bharthulwar,Stone Tao,Hao Su*

Main category: cs.LG

TL;DR: 论文提出了一种称为交错重置（staggered resets）的技术，通过在任务时间轴的不同点初始化和重置环境，减少同步rollout引入的有害非平稳性，从而提高强化学习的样本效率、收敛速度和最终性能。


<details>
  <summary>Details</summary>
Motivation: 在GPU大规模并行模拟环境中，为了最大化吞吐量通常使用短rollout，但这会引入有害的非平稳性，扭曲学习信号并破坏训练稳定性。

Method: 提出交错重置技术，让环境在任务时间轴的不同点进行初始化和重置，从而产生具有更大时间多样性的训练批次。

Result: 在挑战性的高维机器人环境中，该技术显著提高了样本效率、加快了收敛速度、增强了最终性能，并且在更多并行环境时比朴素同步rollout扩展性更好。

Conclusion: 交错重置是一种简单而有效的技术，能够减少同步rollout引入的非平稳性，在强化学习训练中带来显著改进。

Abstract: Massively parallel GPU simulation environments have accelerated reinforcement learning (RL) research by enabling fast data collection for on-policy RL algorithms like Proximal Policy Optimization (PPO). To maximize throughput, it is common to use short rollouts per policy update, increasing the update-to-data (UTD) ra- tio. However, we find that, in this setting, standard synchronous resets introduce harmful nonstationarity, skewing the learning signal and destabilizing training. We introduce staggered resets, a simple yet effective technique where environments are initialized and reset at varied points within the task horizon. This yields training batches with greater temporal diversity, reducing the nonstationarity induced by synchronized rollouts. We characterize dimensions along which RL environments can benefit significantly from staggered resets through illustrative toy environ- ments. We then apply this technique to challenging high-dimensional robotics environments, achieving significantly higher sample efficiency, faster wall-clock convergence, and stronger final performance. Finally, this technique scales better with more parallel environments compared to naive synchronized rollouts.

</details>


### [22] [A Probabilistic Framework for Temporal Distribution Generalization in Industry-Scale Recommender Systems](https://arxiv.org/abs/2511.21032)
*Yuxuan Zhu,Cong Fu,Yabo Ni,Anxiang Zeng,Yuan Fang*

Main category: cs.LG

TL;DR: ELBO$\text{TDS}$是一个概率框架，通过数据增强和因果图建模解决推荐系统中的时间分布偏移问题，已在Shopee产品搜索中成功部署。


<details>
  <summary>Details</summary>
Motivation: 时间分布偏移(TDS)会削弱推荐系统的长期准确性，现有方法如不变性学习和自监督学习存在时间泛化不稳定、表示塌陷或数据利用效率低等问题。

Method: 首先通过统计分析识别关键偏移因素并设计数据增强策略，然后基于因果图建模推导出自监督变分目标ELBO$\text{TDS}$。

Result: 实验证明该方法实现了优越的时间泛化性能，每个用户的GMV提升了2.33%，并已在Shopee产品搜索中成功部署。

Conclusion: ELBO$\text{TDS}$框架有效解决了推荐系统中的时间分布偏移问题，在工业规模增量学习流程中表现出色。

Abstract: Temporal distribution shift (TDS) erodes the long-term accuracy of recommender systems, yet industrial practice still relies on periodic incremental training, which struggles to capture both stable and transient patterns. Existing approaches such as invariant learning and self-supervised learning offer partial solutions but often suffer from unstable temporal generalization, representation collapse, or inefficient data utilization. To address these limitations, we propose ELBO$_\text{TDS}$, a probabilistic framework that integrates seamlessly into industry-scale incremental learning pipelines. First, we identify key shifting factors through statistical analysis of real-world production data and design a simple yet effective data augmentation strategy that resamples these time-varying factors to extend the training support. Second, to harness the benefits of this extended distribution while preventing representation collapse, we model the temporal recommendation scenario using a causal graph and derive a self-supervised variational objective, ELBO$_\text{TDS}$, grounded in the causal structure. Extensive experiments supported by both theoretical and empirical analysis demonstrate that our method achieves superior temporal generalization, yielding a 2.33\% uplift in GMV per user and has been successfully deployed in Shopee Product Search. Code is available at https://github.com/FuCongResearchSquad/ELBO4TDS.

</details>


### [23] [Prediction of Herd Life in Dairy Cows Using Multi-Head Attention Transformers](https://arxiv.org/abs/2511.21034)
*Mahdi Saki,Justin Lipman*

Main category: cs.LG

TL;DR: 本研究开发了一个基于多头部注意力Transformer的AI模型，利用奶牛从出生开始的历史多变量时间序列数据来预测奶牛寿命，在澳大利亚7个农场的19,000头奶牛数据上取得了83%的决定系数。


<details>
  <summary>Details</summary>
Motivation: 奶农需要基于客观评估来决定是否保留或淘汰奶牛，因此需要识别更具韧性的奶牛，这些奶牛能更好地适应农场条件并完成更多哺乳期。

Method: 使用多头部注意力Transformer等先进AI技术，分析从出生开始记录的历史多变量时间序列数据，涵盖约78万条记录。

Result: 模型在预测所研究农场的牛群寿命方面取得了83%的整体决定系数。

Conclusion: 该模型在奶牛群管理中具有实际应用潜力，能够帮助奶农做出更明智的决策。

Abstract: Dairy farmers should decide to keep or cull a cow based on an objective assessment of her likely performance in the herd. For this purpose, farmers need to identify more resilient cows, which can cope better with farm conditions and complete more lactations. This decision-making process is inherently complex, with significant environmental and economic implications. In this study, we develop an AI-driven model to predict cow longevity using historical multivariate time-series data recorded from birth. Leveraging advanced AI techniques, specifically Multi-Head Attention Transformers, we analysed approximately 780,000 records from 19,000 unique cows across 7 farms in Australia. The results demonstrate that our model achieves an overall determination coefficient of 83% in predicting herd life across the studied farms, highlighting its potential for practical application in dairy herd management.

</details>


### [24] [FedAPA: Federated Learning with Adaptive Prototype Aggregation Toward Heterogeneous Wi-Fi CSI-based Crowd Counting](https://arxiv.org/abs/2511.21048)
*Jingtao Guo,Yuyi Mao,Ivan Wang-Hei Ho*

Main category: cs.LG

TL;DR: FedAPA是一种基于Wi-Fi CSI的联邦学习感知算法，通过自适应原型聚合策略解决数据异构性和设备资源差异问题，在真实世界Wi-Fi人群计数场景中显著提升了准确性和通信效率。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi CSI感知技术需要大量站点特定训练数据，限制了大规模部署。联邦学习虽然避免原始数据共享，但面临异构感知数据和设备资源的挑战。

Method: 提出FedAPA算法，采用自适应原型聚合策略为对等原型分配相似性权重，实现自适应客户端贡献，为每个客户端生成个性化全局原型。本地训练采用混合目标函数，结合分类学习和表示对比学习来对齐本地和全局知识。

Result: 在6个环境、最多20人的真实世界分布式Wi-Fi人群计数场景中，FedAPA相比多个基线方法在准确性、F1分数、平均绝对误差和通信开销方面均有显著提升：准确率至少提高9.65%，F1分数提升9%，MAE降低0.29，通信开销减少95.94%。

Conclusion: FedAPA通过自适应原型聚合和混合学习目标，有效解决了联邦Wi-Fi CSI感知中的数据异构性和资源限制问题，实现了高性能和低通信开销的分布式感知。

Abstract: Wi-Fi channel state information (CSI)-based sensing provides a non-invasive, device-free approach for tasks such as human activity recognition and crowd counting, but large-scale deployment is hindered by the need for extensive site-specific training data. Federated learning (FL) offers a way to avoid raw data sharing but is challenged by heterogeneous sensing data and device resources. This paper proposes FedAPA, a collaborative Wi-Fi CSI-based sensing algorithm that uses adaptive prototype aggregation (APA) strategy to assign similarity-based weights to peer prototypes, enabling adaptive client contributions and yielding a personalized global prototype for each client instead of a fixed-weight aggregation. During local training, we adopt a hybrid objective that combines classification learning with representation contrastive learning to align local and global knowledge. We provide a convergence analysis of FedAPA and evaluate it in a real-world distributed Wi-Fi crowd counting scenario with six environments and up to 20 people. The results show that our method outperform multiple baselines in terms of accuracy, F1 score, mean absolute error (MAE), and communication overhead, with FedAPA achieving at least a 9.65% increase in accuracy, a 9% gain in F1 score, a 0.29 reduction in MAE, and a 95.94% reduction in communication overhead.

</details>


### [25] [Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs](https://arxiv.org/abs/2511.21050)
*Dongkyu Derek Cho,Huan Song,Arijit Ghosh Chowdhury,Haotian An,Yawei Wang,Rohit Thekkanal,Negin Sokhandan,Sharlina Keshava,Hannah Marlowe*

Main category: cs.LG

TL;DR: 本文首次全面分析了RLVR（可验证奖励强化学习）在大型语言模型中的安全性，证明在特定条件下可以消除安全性退化，实现安全性与能力的同步提升。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法（SFT和RLHF）存在安全性与任务性能的权衡问题，即使使用良性数据集也会降低安全对齐。RLVR作为有前景的替代方法，其安全性影响尚未被探索。

Method: 通过理论分析推导KL约束优化下的安全性漂移上界，并进行大规模实证实验，涵盖五个对抗性安全基准测试，研究优化算法、模型规模和任务领域的影响。

Result: 实验证明RLVR可以同时增强推理能力并保持或改进安全防护，挑战了安全与能力必然权衡的普遍假设。

Conclusion: 特定训练方法可以同时实现安全性和能力目标，为安全部署具备推理能力的LLMs提供了重要见解。

Abstract: Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs.

</details>


### [26] [Efficient Diffusion Planning with Temporal Diffusion](https://arxiv.org/abs/2511.21054)
*Jiaming Guo,Rui Zhang,Zerun Li,Yunkai Gao,Shaohui Peng,Siming Lan,Xing Hu,Zidong Du,Xishan Zhang,Ling Li*

Main category: cs.LG

TL;DR: TDP通过将去噪步骤分布在时间维度上，提高决策效率，相比每步重新生成计划的方法提升决策频率11-24.8倍，同时保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散规划方法每步重新生成计划导致计算开销大、决策频率低，且频繁切换计划影响性能。受人类制定详细短期计划和模糊长期计划的启发，提出更高效的规划方法。

Method: 提出时间扩散规划器(TDP)，首先生成随时间逐渐模糊的初始计划，后续时间步通过少量去噪步骤更新前一步计划，而非完全重新生成，并引入自动重新规划机制防止计划与现实偏差过大。

Result: 在D4RL基准测试中，相比每步重新生成计划的方法，TDP将决策频率提升11-24.8倍，同时达到更高或相当的性能水平。

Conclusion: TDP通过时间维度分布去噪步骤和计划更新策略，显著提高了扩散规划的决策效率，为离线强化学习提供了更实用的解决方案。

Abstract: Diffusion planning is a promising method for learning high-performance policies from offline data. To avoid the impact of discrepancies between planning and reality on performance, previous works generate new plans at each time step. However, this incurs significant computational overhead and leads to lower decision frequencies, and frequent plan switching may also affect performance. In contrast, humans might create detailed short-term plans and more general, sometimes vague, long-term plans, and adjust them over time. Inspired by this, we propose the Temporal Diffusion Planner (TDP) which improves decision efficiency by distributing the denoising steps across the time dimension. TDP begins by generating an initial plan that becomes progressively more vague over time. At each subsequent time step, rather than generating an entirely new plan, TDP updates the previous one with a small number of denoising steps. This reduces the average number of denoising steps, improving decision efficiency. Additionally, we introduce an automated replanning mechanism to prevent significant deviations between the plan and reality. Experiments on D4RL show that, compared to previous works that generate new plans every time step, TDP improves the decision-making frequency by 11-24.8 times while achieving higher or comparable performance.

</details>


### [27] [A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs](https://arxiv.org/abs/2511.21056)
*Quan Xiao,Tianyi Chen*

Main category: cs.LG

TL;DR: 本文提出了一种优化视角下的离线数据选择和在线自优化生成框架，通过双层数据选择提升数据质量，增强大语言模型在特定下游任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 离线数据选择和在线自优化生成是提升大语言模型在特定下游任务中性能的关键步骤，但现有方法缺乏统一的理论框架和优化视角。

Method: 采用双层数据选择进行离线数据筛选，将在线自优化生成视为模型适应步骤，为每个问题和响应分配学习到的数据权重（显式或隐式）。

Result: 理论证明了双层数据选择框架的有效性，实验表明该方法在质量增强和安全感知的LLM微调中优于未过滤的直接混合基线方法。

Conclusion: 通过结合离线数据和验证加权的在线生成，该方法显著提升了微调性能，为离线数据选择和自优化生成提供了统一的理论基础和实践框架。

Abstract: Offline data selection and online self-refining generation, which enhance the data quality, are crucial steps in adapting large language models (LLMs) to specific downstream tasks. We tackle offline data selection and online self-refining generations through an optimization perspective. Specifically, bilevel data selection is used for offline data selection with respect to the validation dataset, and we treat online self-refining generation as a model adaptation step of selecting the model trained on current responses that best fits the validation data. Our framework offers a unified understanding of offline data selection and self-refining generation by assigning a learned data weight to each question and response, either explicitly or implicitly. For the first time, we theoretically demonstrate the effectiveness of the bilevel data selection framework and demonstrate its performance gains over unfiltered direct mixing baselines. By combining offline data with validation-weighted online generations, our method enhances fine-tuning performance. Experiments on quality enhancement and safety-aware LLM fine-tuning validate its effectiveness.

</details>


### [28] [Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning](https://arxiv.org/abs/2511.21075)
*Zhenchao Tang,Fang Wang,Haohuai He,Jiale Zhou,Tianxu Lv,Jun Zhu,Shouzhi Chen,Minghao Yang,Yu Wang,Jiayang Wu,Yidong Song,Jianhua Yao*

Main category: cs.LG

TL;DR: 提出平衡微调（BFT）方法，通过双层加权机制解决生物医学领域LLM后训练中的过拟合和稀疏数据学习问题，显著优于标准监督微调，在医学和生物学任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在生物医学领域的后训练方法存在局限性：标准监督微调容易过拟合表面指令模式而无法内化碎片化科学知识；强化学习因需要实验验证奖励信号而不实用。需要一种能有效学习稀疏数据中复杂推理的方法。

Method: 提出平衡微调（BFT）方法，包含两个层次的加权机制：1）在token级别，通过预测概率缩放损失来稳定梯度防止过拟合；2）在样本级别，使用"最小组置信度"自适应增强困难样本的学习。

Result: BFT显著优于标准监督微调：在医学任务中学习到SFT遗漏的知识；在生物学任务中超越GeneAgent；生成的文本嵌入可直接用于下游任务如基因相互作用和单细胞扰动响应预测。

Conclusion: BFT方法促进了LLM在生物医学研究中的广泛应用，能够有效学习稀疏数据中的复杂推理而无需外部奖励信号。

Abstract: Effective post-training is essential to align Large Language Models (LLMs) with specialized biomedical knowledge to accelerate life science research. However, current approaches face significant limitations. First, biomedical reasoning involves intricate mechanisms often represented by sparse textual data. Standard Supervised Fine-Tuning (SFT) tends to overfit to surface-level instruction patterns without effectively internalizing this fragmented scientific knowledge. Second, Reinforcement Learning (RL) is impractical for this domain, as defining meaningful rewards often necessitates prohibitive experimental validation (e.g., wet-lab verification of drug responses), rendering real-time feedback unfeasible. We propose Balanced Fine-Tuning (BFT), an efficient post-training method designed to learn complex reasoning from sparse data without external reward signals. BFT operates through a two-layer weighting mechanism: 1. At the token level, it scales loss via prediction probabilities to stabilize gradients and prevent overfitting; 2. At the sample level, it uses "minimum group confidence" to adaptively enhance the learning of hard samples. Experiments demonstrate that BFT significantly outperforms SFT. In medical tasks, it enables LLMs to acquire knowledge that SFT misses. In biological tasks, BFT-based LLMs surpass GeneAgent (an accurate agent for biology analysis) in biological process reasoning. Moreover, the text embeddings generated by BFT can be directly applied to downstream tasks, such as gene interaction and single-cell perturbation response prediction. These results indicate that BFT facilitates broad applications of LLMs in biomedical research.

</details>


### [29] [Deceptron: Learned Local Inverses for Fast and Stable Physics Inversion](https://arxiv.org/abs/2511.21076)
*Aaditya L. Kachhadiya*

Main category: cs.LG

TL;DR: Deceptron是一个轻量级双向模块，通过局部逆学习解决物理科学中的病态逆问题，结合多种训练约束和JCP惩罚，在Heat-1D和Damped Oscillator问题上显著减少迭代次数。


<details>
  <summary>Details</summary>
Motivation: 物理科学中的逆问题通常在输入空间是病态的，导致步长敏感。需要一种能够学习局部逆的方法来改善优化过程。

Method: 提出Deceptron模块，结合监督拟合、前向-反向一致性、轻量级谱惩罚、软偏置绑定和Jacobian组合惩罚(JCP)，使用D-IPG方法在输出空间进行下降步。

Result: 在Heat-1D初始条件恢复和Damped Oscillator逆问题上，D-IPG比投影梯度法减少约20倍和2-3倍迭代次数，与Gauss-Newton方法在迭代次数和成本上具有竞争力。

Conclusion: Deceptron方法通过局部逆学习和Jacobian组合约束，有效改善了逆问题的求解效率，在多个测试问题上表现出显著优势。

Abstract: Inverse problems in the physical sciences are often ill-conditioned in input space, making progress step-size sensitive. We propose the Deceptron, a lightweight bidirectional module that learns a local inverse of a differentiable forward surrogate. Training combines a supervised fit, forward-reverse consistency, a lightweight spectral penalty, a soft bias tie, and a Jacobian Composition Penalty (JCP) that encourages $J_g(f(x))\,J_f(x)\!\approx\!I$ via JVP/VJP probes. At solve time, D-IPG (Deceptron Inverse-Preconditioned Gradient) takes a descent step in output space, pulls it back through $g$, and projects under the same backtracking and stopping rules as baselines. On Heat-1D initial-condition recovery and a Damped Oscillator inverse problem, D-IPG reaches a fixed normalized tolerance with $\sim$20$\times$ fewer iterations on Heat and $\sim$2-3$\times$ fewer on Oscillator than projected gradient, competitive in iterations and cost with Gauss-Newton. Diagnostics show JCP reduces a measured composition error and tracks iteration gains. We also preview a single-scale 2D instantiation, DeceptronNet (v0), that learns few-step corrections under a strict fairness protocol and exhibits notably fast convergence.

</details>


### [30] [MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations](https://arxiv.org/abs/2511.21092)
*Seunghun Baek,Jaejin Lee,Jaeyoon Sim,Minjae Jeong,Won Hwa Kim*

Main category: cs.LG

TL;DR: 提出了一种利用双曲几何连接神经科学文献与脑激活图的新框架，通过将研究文章文本和相应脑图像嵌入到共享的双曲空间中，捕获神经影像数据中的语义相似性和层次结构。


<details>
  <summary>Details</summary>
Motivation: 解决神经影像研究中样本量小的问题，传统基于关键词检索或线性映射的方法往往忽略了大脑中丰富的层次结构。

Method: 使用Lorentz模型将文本和脑图像嵌入到共享双曲空间中，进行多级神经影像元分析：1) 对齐脑和文本嵌入以实现语义对应；2) 引导文本和脑激活之间的层次关系；3) 保持脑激活模式中的层次关系。

Result: 实验结果表明该模型优于基线方法，提供了一个稳健且可解释的多级神经影像元分析范式。

Conclusion: 通过双曲脑-文本表示，该方法为神经影像元分析提供了一个有效的新框架，能够更好地捕获大脑活动的语义和层次结构。

Abstract: Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation.

</details>


### [31] [Generative Early Stage Ranking](https://arxiv.org/abs/2511.21095)
*Juhee Hong,Meng Liu,Shengzhi Wang,Xiaoheng Mao,Huihui Cheng,Leon Gao,Christopher Leung,Jin Zhou,Chandra Mouli Sekar,Zhao Zhu,Ruochen Liu,Tuan Trieu,Dawei Sun,Jeet Kanjani,Rui Li,Jing Qian,Xuan Cao,Minjie Fan,Mingze Gao*

Main category: cs.LG

TL;DR: 提出生成式早期排序(GESR)范式，通过混合注意力(MoA)模块解决用户-物品解耦方法的局限性，包含硬匹配注意力、目标感知自注意力和交叉注意力，并使用多逻辑参数化门控(MLPG)模块整合新学习的嵌入，在保持效率的同时显著提升效果。


<details>
  <summary>Details</summary>
Motivation: 大规模推荐系统采用多阶段级联排序来平衡效果和效率，但早期排序阶段使用的用户-物品解耦方法难以捕捉细粒度用户-物品亲和度和交叉信号，限制了效果。

Method: 提出GESR范式，包含MoA模块（硬匹配注意力、目标感知自注意力、交叉注意力）和MLPG模块，通过多样化注意力机制增强用户-物品交互，并结合优化技术确保效率。

Result: 在线和离线实验验证了GESR在核心指标、参与度和消费任务上的显著提升，成功实现了大规模ESR阶段的目标感知注意力序列建模部署。

Conclusion: GESR范式通过引入目标感知的注意力机制，有效解决了早期排序阶段的效果瓶颈，在保持效率的同时实现了显著的效果提升，是大规模推荐系统的重要创新。

Abstract: Large-scale recommendations commonly adopt a multi-stage cascading ranking system paradigm to balance effectiveness and efficiency. Early Stage Ranking (ESR) systems utilize the "user-item decoupling" approach, where independently learned user and item representations are only combined at the final layer. While efficient, this design is limited in effectiveness, as it struggles to capture fine-grained user-item affinities and cross-signals. To address these, we propose the Generative Early Stage Ranking (GESR) paradigm, introducing the Mixture of Attention (MoA) module which leverages diverse attention mechanisms to bridge the effectiveness gap: the Hard Matching Attention (HMA) module encodes explicit cross-signals by computing raw match counts between user and item features; the Target-Aware Self Attention module generates target-aware user representations conditioned on the item, enabling more personalized learning; and the Cross Attention modules facilitate early and more enriched interactions between user-item features. MoA's specialized attention encodings are further refined in the final layer through a Multi-Logit Parameterized Gating (MLPG) module, which integrates the newly learned embeddings via gating and produces secondary logits that are fused with the primary logit. To address the efficiency and latency challenges, we have introduced a comprehensive suite of optimization techniques. These span from custom kernels that maximize the capabilities of the latest hardware to efficient serving solutions powered by caching mechanisms. The proposed GESR paradigm has shown substantial improvements in topline metrics, engagement, and consumption tasks, as validated by both offline and online experiments. To the best of our knowledge, this marks the first successful deployment of full target-aware attention sequence modeling within an ESR stage at such a scale.

</details>


### [32] [From Bits to Rounds: Parallel Decoding with Exploration for Diffusion Language Models](https://arxiv.org/abs/2511.21103)
*Hengyu Fu,Baihe Huang,Virginia Adams,Charles Wang,Venkat Srinivasan,Jiantao Jiao*

Main category: cs.LG

TL;DR: 本文分析了扩散语言模型解码策略的固有瓶颈，提出了一种新的训练无关解码策略ETE，通过结合跨块解码和不确定性标记探索来提高解码效率。


<details>
  <summary>Details</summary>
Motivation: 标准DLM解码策略依赖高置信度标记，但存在信息理论瓶颈，限制了解码进度并减慢生成速度。高概率标记携带的信息量很少，严格依赖它们会限制每轮解码的有效进展。

Method: 提出了Explore-Then-Exploit (ETE)解码策略，结合跨块解码和针对高不确定性标记的探索，以重塑条件分布并触发置信预测的级联效应。

Result: 实验验证了理论界限，表明ETE相比仅依赖置信度的基线方法，在不影响生成质量的情况下持续减少了所需的解码轮数。

Conclusion: 证明了高置信度标记优先策略本质上是低效的，ETE策略通过最大化信息吞吐量和解码效率，有效解决了DLM解码的信息瓶颈问题。

Abstract: Diffusion Language Models (DLMs) have recently emerged as a strong alternative to autoregressive language models (LMs). DLMs offer comparable accuracy with faster inference speed via parallel decoding. However, standard DLM decoding strategies relying on high-confidence tokens encounter an inherent information-theoretic bottleneck that restricts decoding progress and ultimately slows generation. We demonstrate both theoretically and empirically that prioritizing high-confidence tokens is inherently inefficient. High-probability tokens carry negligible information and strictly relying on them limits the effective progress made in each decoding round. We prove that the number of decoding rounds must grow linearly with the sample's total information (negative log-likelihood) and inversely with the per-round information budget, establishing a bits-to-rounds principle. We also propose Explore-Then-Exploit (ETE), a training-free decoding strategy that maximizes information throughput and decoding efficiency. ETE combines cross-block decoding with targeted exploration of high-uncertainty tokens to reshape the conditional distribution and trigger cascades of confident predictions. Experiments verify our theoretical bounds and demonstrate that ETE consistently reduces the required number of decoding rounds compared to confidence-only baselines without compromising generation quality.

</details>


### [33] [BRIDGE: Building Representations In Domain Guided Program Verification](https://arxiv.org/abs/2511.21104)
*Robert Joseph George,Carson Eisenach,Udaya Ghai,Dominique Perrault-Joncas,Anima Anandkumar,Dean Foster*

Main category: cs.LG

TL;DR: BRIDGE提出了一种结构化提示方法，用于可扩展的验证程序生成，通过将验证分解为代码、规范和证明三个相互关联的领域，并使用中间表示来连接这些领域，显著提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成方面表现出色，但在程序验证方面存在困难，特别是在交互式证明框架中。主要挑战是可扩展性：验证合成不仅需要代码，还需要精确的规范和正确性证明，现有方法很少能同时涵盖这三个领域。

Method: BRIDGE将验证分解为三个相互关联的领域：代码（可执行实现）、规范（形式化意图声明）和证明（构造性正确性论证）。通过引出不同的推理行为（功能性、规范驱动和证明导向）作为中间表示，保留语义结构并连接这些领域。

Result: 该方法显著提高了准确性和效率。在Lean4中，功能性推理将代码正确性提高了近1.5倍（pass@5），推理时间计算效率提高了2倍。规范驱动提示将Python编码通过率提高了17.5%。

Conclusion: 结构化领域对齐是推进验证合成的有前景方向。BRIDGE为通过专家迭代或RLVR进行训练奠定了基础，使模型能够在代码、规范和证明之间内化这些推理策略。

Abstract: Large language models (LLMs) have achieved impressive results in code generation, yet struggle with program verification, especially in interactive proof frameworks such as Lean4. A central challenge is scalability: verified synthesis requires not just code, but also precise specifications and correctness proofs, and existing approaches rarely span all three domains. We present BRIDGE, the first systematic study of structured prompting for scalable verified program generation. BRIDGE decomposes verification into three interconnected domains: Code (executable implementations), Specifications (formal intent statements), and Proofs (constructive correctness arguments). Our key idea is to elicit distinct reasoning behaviors functional, specification-driven, and proof-oriented as intermediate representations that preserve semantic structure and connect these domains. Through systematic ablations, we show that this approach substantially improves both accuracy and efficiency beyond standard error feedback methods. For example, functional reasoning improves correctness of code in formal languages (Lean4) by nearly 1.5x (pass@5) over direct baselines. In inference-time compute, functional reasoning is also 2x more efficient, achieving higher pass rates with fewer generations and lower total sampling budgets. Similarly, we find that specification-driven prompting boosts Python coding pass rates by up to 17.5%. These findings suggest that structured domain alignment is a promising direction for advancing verified synthesis. BRIDGE establishes a foundation for training via expert iteration or RLVR, enabling models to internalize these reasoning strategies across code, specifications, and proofs.

</details>


### [34] [Interpretable Fair Clustering](https://arxiv.org/abs/2511.21109)
*Mudi Jiang,Jiahui Zhou,Xinying Liu,Zengyou He,Zhikui Chen*

Main category: cs.LG

TL;DR: 提出了一种可解释的公平聚类框架，通过将公平约束集成到决策树结构中，构建可解释的决策树来划分数据，同时确保受保护群体间的公平处理。


<details>
  <summary>Details</summary>
Motivation: 现有公平聚类方法通常缺乏可解释性，限制了在高风险场景中的应用，因为在这些场景中理解聚类决策背后的原理至关重要。

Method: 将公平约束集成到决策树结构中，构建可解释的决策树来划分数据。还引入了无需公平超参数调优的变体，通过对无公平约束构建的树进行后剪枝实现。

Result: 在真实世界和合成数据集上的广泛实验表明，该方法不仅提供有竞争力的聚类性能和改善的公平性，还具有可解释性、处理多个敏感属性的能力等额外优势。

Conclusion: 该方法在复杂公平约束下表现稳健，为公平和透明的聚类开辟了新的可能性。

Abstract: Fair clustering has gained increasing attention in recent years, especially in applications involving socially sensitive attributes. However, existing fair clustering methods often lack interpretability, limiting their applicability in high-stakes scenarios where understanding the rationale behind clustering decisions is essential. In this work, we address this limitation by proposing an interpretable and fair clustering framework, which integrates fairness constraints into the structure of decision trees. Our approach constructs interpretable decision trees that partition the data while ensuring fair treatment across protected groups. To further enhance the practicality of our framework, we also introduce a variant that requires no fairness hyperparameter tuning, achieved through post-pruning a tree constructed without fairness constraints. Extensive experiments on both real-world and synthetic datasets demonstrate that our method not only delivers competitive clustering performance and improved fairness, but also offers additional advantages such as interpretability and the ability to handle multiple sensitive attributes. These strengths enable our method to perform robustly under complex fairness constraints, opening new possibilities for equitable and transparent clustering.

</details>


### [35] [Learning Cell-Aware Hierarchical Multi-Modal Representations for Robust Molecular Modeling](https://arxiv.org/abs/2511.21120)
*Mengran Li,Zelin Zang,Wenbin Xing,Junzhou Chen,Ronghui Zhang,Jiebo Luo,Stan Z. Li*

Main category: cs.LG

TL;DR: CHMR是一个细胞感知的层次化多模态表示框架，通过联合建模分子与细胞响应之间的局部-全局依赖关系，并利用树状结构向量量化模块捕获潜在的生物层次结构，在分子属性预测任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注化学结构，但细胞响应（如形态和基因表达）对药物效应具有关键影响。当前细胞感知方法面临两个主要限制：外部生物数据的模态不完整，以及跨分子、细胞和基因组层次的层次依赖关系建模不足。

Method: 提出CHMR框架，联合建模分子与细胞响应之间的局部-全局依赖关系，通过新颖的树状结构向量量化模块捕获潜在的生物层次结构。

Result: 在9个公共基准测试的728个任务上评估，CHMR优于最先进的基线方法，分类任务平均提升3.6%，回归任务平均提升17.2%。

Conclusion: 结果表明层次感知的多模态学习在可靠且具有生物学基础的分子表示方面具有优势，为整合生物医学建模提供了一个可推广的框架。

Abstract: Understanding how chemical perturbations propagate through biological systems is essential for robust molecular property prediction. While most existing methods focus on chemical structures alone, recent advances highlight the crucial role of cellular responses such as morphology and gene expression in shaping drug effects. However, current cell-aware approaches face two key limitations: (1) modality incompleteness in external biological data, and (2) insufficient modeling of hierarchical dependencies across molecular, cellular, and genomic levels. We propose CHMR (Cell-aware Hierarchical Multi-modal Representations), a robust framework that jointly models local-global dependencies between molecules and cellular responses and captures latent biological hierarchies via a novel tree-structured vector quantization module. Evaluated on nine public benchmarks spanning 728 tasks, CHMR outperforms state-of-the-art baselines, yielding average improvements of 3.6% on classification and 17.2% on regression tasks. These results demonstrate the advantage of hierarchy-aware, multimodal learning for reliable and biologically grounded molecular representations, offering a generalizable framework for integrative biomedical modeling. The code is in https://github.com/limengran98/CHMR.

</details>


### [36] [How to Correctly Report LLM-as-a-Judge Evaluations](https://arxiv.org/abs/2511.21140)
*Chungpa Lee,Thomas Zeng,Jongwon Jeong,Jy-yong Sohn,Kangwook Lee*

Main category: cs.LG

TL;DR: 提出了一个简单的插件框架来纠正LLM评估中的偏差并构建置信区间，同时引入自适应算法来减少准确率估计的不确定性。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地被用作人类评估者的替代品，但其判断存在噪音，导致准确率估计存在偏差，且现有偏差校正方法通常假设已知模型的特异性和敏感性。

Method: 开发了一个简单的插件框架来校正偏差并构建置信区间，同时提出了自适应算法来高效分配校准样本大小以减少不确定性。

Result: 该框架能够纠正LLM评估中的偏差，构建反映测试和校准数据集不确定性的置信区间，实现实用且统计上可靠的LLM评估。

Conclusion: 提出的插件框架和自适应算法为LLM评估提供了实用且统计上可靠的方法，能够有效处理评估中的偏差和不确定性。

Abstract: Large language models (LLMs) are increasingly used as evaluators in lieu of humans. While scalable, their judgments are noisy due to imperfect specificity and sensitivity of LLMs, leading to biased accuracy estimates. Although bias-correction methods exist, they are underutilized in LLM research and typically assume exact knowledge of the model's specificity and sensitivity. Furthermore, in general we only have estimates of these values and it is not well known how to properly construct confidence intervals using only estimates. This work presents a simple plug-in framework that corrects such bias and constructs confidence intervals reflecting uncertainty from both test and calibration dataset, enabling practical and statistically sound LLM-based evaluation. Additionally, to reduce uncertainty in the accuracy estimate, we introduce an adaptive algorithm that efficiently allocates calibration sample sizes.

</details>


### [37] [I-GLIDE: Input Groups for Latent Health Indicators in Degradation Estimation](https://arxiv.org/abs/2511.21208)
*Lucas Thil,Jesse Read,Rim Kaddah,Guillaume Doquet*

Main category: cs.LG

TL;DR: 本文提出了一种新的健康指标构建框架，通过改进的重建投影路径方法、不确定性量化和指标组范式，显著提升了剩余使用寿命预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在多传感器系统中解耦复杂的退化机制，也无法量化健康指标可靠性的不确定性，这限制了剩余使用寿命预测的准确性。

Method: 首次将重建投影路径作为健康指标，结合蒙特卡洛dropout和概率潜空间进行不确定性量化，并提出指标组范式来隔离传感器子集以建模系统特定退化。

Result: 在航空航天和制造系统数据上的评估表明，该方法在准确性和泛化能力方面显著优于现有最先进的健康指标方法。

Conclusion: 该工作填补了异常检测与预测之间的空白，为复杂系统中的不确定性感知退化建模提供了一个原则性框架。

Abstract: Accurate remaining useful life (RUL) prediction hinges on the quality of health indicators (HIs), yet existing methods often fail to disentangle complex degradation mechanisms in multi-sensor systems or quantify uncertainty in HI reliability. This paper introduces a novel framework for HI construction, advancing three key contributions. First, we adapt Reconstruction along Projected Pathways (RaPP) as a health indicator (HI) for RUL prediction for the first time, showing that it outperforms traditional reconstruction error metrics. Second, we show that augmenting RaPP-derived HIs with aleatoric and epistemic uncertainty quantification (UQ) via Monte Carlo dropout and probabilistic latent spaces- significantly improves RUL-prediction robustness. Third, and most critically, we propose indicator groups, a paradigm that isolates sensor subsets to model system-specific degradations, giving rise to our novel method, I-GLIDE which enables interpretable, mechanism-specific diagnostics. Evaluated on data sourced from aerospace and manufacturing systems, our approach achieves marked improvements in accuracy and generalizability compared to state-of-the-art HI methods while providing actionable insights into system failure pathways. This work bridges the gap between anomaly detection and prognostics, offering a principled framework for uncertainty-aware degradation modeling in complex systems.

</details>


### [38] [Robust Gene Prioritization via Fast-mRMR Feature Selection in high-dimensional omics data](https://arxiv.org/abs/2511.21211)
*Rubén Fernández-Farelo,Jorge Paz-Ruza,Bertha Guijarro-Berdiñas,Amparo Alonso-Betanzos,Alex A. Freitas*

Main category: cs.LG

TL;DR: 提出一种基于Fast-mRMR特征选择的基因优先级排序新方法，能有效处理高维度和不完整标记的生物医学数据，在饮食限制数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基因优先级排序方法在处理高维度和不完整标记的生物医学数据时存在困难，需要更稳健高效的解决方案。

Method: 使用Fast-mRMR特征选择技术保留相关且非冗余的特征，构建更简单有效的分类器模型，并能组合不同的生物特征集。

Result: 在饮食限制数据集上的实验表明，该方法相比现有方法有显著改进，证明了特征选择对可靠基因优先级排序的重要性。

Conclusion: 特征选择对于构建可靠的基因优先级排序模型至关重要，提出的方法在效率和鲁棒性方面都有明显提升。

Abstract: Gene prioritization (identifying genes potentially associated with a biological process) is increasingly tackled with Artificial Intelligence. However, existing methods struggle with the high dimensionality and incomplete labelling of biomedical data. This work proposes a more robust and efficient pipeline that leverages Fast-mRMR feature selection to retain only relevant, non-redundant features for classifiers. This enables us to build simpler and more effective models, as well as to combine different biological feature sets. Experiments on Dietary Restriction datasets show significant improvements over existing methods, proving that feature selection can be critical for reliable gene prioritization.

</details>


### [39] [Sawtooth Sampling for Time Series Denoising Diffusion Implicit Models](https://arxiv.org/abs/2511.21320)
*Heiko Oppel,Andreas Spilz,Michael Munz*

Main category: cs.LG

TL;DR: 提出了一种结合隐式扩散模型和锯齿采样器的方法，显著加速DDPM的采样过程，在保持生成质量的同时实现30倍速度提升。


<details>
  <summary>Details</summary>
Motivation: DDPM能够生成合成时间序列数据以提升分类器性能，但其采样过程计算成本高昂，需要加速方法。

Method: 结合隐式扩散模型与新颖的锯齿采样器，该采样器可加速反向过程并适用于任何预训练的扩散模型。

Result: 相比标准基线实现了30倍速度提升，同时提高了生成序列在分类任务中的质量。

Conclusion: 该方法有效解决了DDPM采样效率低的问题，在保持生成质量的同时大幅提升了采样速度。

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) can generate synthetic timeseries data to help improve the performance of a classifier, but their sampling process is computationally expensive. We address this by combining implicit diffusion models with a novel Sawtooth Sampler that accelerates the reverse process and can be applied to any pretrained diffusion model. Our approach achieves a 30 times speed-up over the standard baseline while also enhancing the quality of the generated sequences for classification tasks.

</details>


### [40] [Masks Can Be Distracting: On Context Comprehension in Diffusion Language Models](https://arxiv.org/abs/2511.21338)
*Julianna Piskorz,Cristina Pinneri,Alvaro Correia,Motasem Alfarra,Risheek Garrepalli,Christos Louizos*

Main category: cs.LG

TL;DR: 本文研究了掩码扩散语言模型（MDLMs）的上下文理解能力，发现其存在位置偏见和掩码干扰两大局限，并提出了一种掩码无关的损失函数来提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管MDLMs理论上应能更均匀地利用上下文信息，但其在实际上下文理解中的表现尚未得到充分研究。本文旨在系统评估MDLMs的上下文理解能力并识别其关键局限。

Method: 通过系统消融实验分析MDLMs的上下文理解特性，发现位置偏见和掩码干扰问题，并提出掩码无关损失函数进行微调优化。

Result: 研究发现MDLMs存在强烈的局部性偏见，性能对相关信息位置敏感；同时发现附加掩码会显著干扰上下文理解。提出的掩码无关损失函数有效减轻了掩码的干扰效应。

Conclusion: 当前MDLM训练范式存在关键局限，掩码无关损失函数为构建具有更强上下文理解能力的扩散语言模型提供了可行方案。

Abstract: Masked Diffusion Language Models (MDLMs) have recently emerged as a promising alternative to Autoregressive Language Models (ARLMs), leveraging a denoising objective that, in principle, should enable more uniform context utilisation. In this work, we examine the context comprehension abilities of MDLMs and uncover two key limitations. First, despite their more global training objective and bidirectional attention mechanism, similarly to ARLMS, MDLMs exhibit a strong locality bias: performance is highly sensitive to the position of relevant information within the input, favouring local over distant context. Second, we show that appending a large number of mask tokens--required for generation--can significantly degrade context comprehension. Through systematic ablations, we find that these masks act as distractors, reducing the model's ability to process relevant information. To address this, we introduce a mask-agnostic loss function that encourages predictions to remain invariant to the number of appended masks. Fine-tuning with this objective substantially mitigates the distracting effect of masks, improving robustness of MDLMs. Overall, our findings reveal critical limitations of the current MDLM training paradigm and provide actionable insights for building diffusion-based language models with stronger context comprehension.

</details>


### [41] [Best Practices for Machine Learning Experimentation in Scientific Applications](https://arxiv.org/abs/2511.21354)
*Umberto Michelucci,Francesca Venturini*

Main category: cs.LG

TL;DR: 本文提供了一个实用的结构化指南，用于在科学应用中进行机器学习实验，重点关注可重复性、公平比较和透明报告。


<details>
  <summary>Details</summary>
Motivation: 机器学习在科学研究中日益普及，但结果的质量和可靠性往往取决于实验设计和文档记录的方式。糟糕的基线、不一致的预处理或验证不足可能导致对模型性能的误导性结论。

Method: 提出了一个从数据集准备到模型选择和评估的分步工作流程，并提出了考虑过拟合和验证折叠不稳定性的指标，包括对数过拟合比（LOR）和复合过拟合分数（COS）。

Result: 通过推荐实践和示例报告格式，这项工作旨在支持研究人员建立稳健的基线，并从应用于科学问题的机器学习模型中得出有效的基于证据的见解。

Conclusion: 本文为科学机器学习实验提供了一个实用的结构化指南，强调可重复性、公平比较和透明报告的重要性，以支持研究人员获得可靠的结果和见解。

Abstract: Machine learning (ML) is increasingly adopted in scientific research, yet the quality and reliability of results often depend on how experiments are designed and documented. Poor baselines, inconsistent preprocessing, or insufficient validation can lead to misleading conclusions about model performance. This paper presents a practical and structured guide for conducting ML experiments in scientific applications, focussing on reproducibility, fair comparison, and transparent reporting. We outline a step-by-step workflow, from dataset preparation to model selection and evaluation, and propose metrics that account for overfitting and instability across validation folds, including the Logarithmic Overfitting Ratio (LOR) and the Composite Overfitting Score (COS). Through recommended practices and example reporting formats, this work aims to support researchers in establishing robust baselines and drawing valid evidence-based insights from ML models applied to scientific problems.

</details>


### [42] [Hybrid-AIRL: Enhancing Inverse Reinforcement Learning with Supervised Expert Guidance](https://arxiv.org/abs/2511.21356)
*Bram Silue,Santiago Amaya-Corredor,Patrick Mannion,Lander Willem,Pieter Libin*

Main category: cs.LG

TL;DR: 本文提出了Hybrid-AIRL (H-AIRL)方法，通过结合监督损失和随机正则化机制来增强对抗性逆强化学习在复杂不完全信息环境中的性能，特别是在HULHE扑克游戏中取得了更好的样本效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 对抗性逆强化学习(AIRL)在处理稀疏奖励问题上表现良好，但在高度复杂的不完全信息环境中的性能尚未充分探索。本文旨在解决AIRL在HULHE扑克等复杂环境中推断奖励函数能力不足的问题。

Method: 提出了Hybrid-AIRL (H-AIRL)扩展方法，通过引入来自专家数据的监督损失和随机正则化机制来增强奖励推断和策略学习。

Result: 在Gymnasium基准测试和HULHE扑克环境中评估表明，H-AIRL相比AIRL实现了更高的样本效率和更稳定的学习过程。

Conclusion: 将监督信号整合到逆强化学习中具有显著优势，H-AIRL为处理具有挑战性的现实世界场景提供了一个有前景的框架。

Abstract: Adversarial Inverse Reinforcement Learning (AIRL) has shown promise in addressing the sparse reward problem in reinforcement learning (RL) by inferring dense reward functions from expert demonstrations. However, its performance in highly complex, imperfect-information settings remains largely unexplored. To explore this gap, we evaluate AIRL in the context of Heads-Up Limit Hold'em (HULHE) poker, a domain characterized by sparse, delayed rewards and significant uncertainty. In this setting, we find that AIRL struggles to infer a sufficiently informative reward function. To overcome this limitation, we contribute Hybrid-AIRL (H-AIRL), an extension that enhances reward inference and policy learning by incorporating a supervised loss derived from expert data and a stochastic regularization mechanism. We evaluate H-AIRL on a carefully selected set of Gymnasium benchmarks and the HULHE poker setting. Additionally, we analyze the learned reward function through visualization to gain deeper insights into the learning process. Our experimental results show that H-AIRL achieves higher sample efficiency and more stable learning compared to AIRL. This highlights the benefits of incorporating supervised signals into inverse RL and establishes H-AIRL as a promising framework for tackling challenging, real-world settings.

</details>


### [43] [The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods](https://arxiv.org/abs/2511.21363)
*Kevin Iselborn,David Dembinsky,Adriano Lucieri,Andreas Dengel*

Main category: cs.LG

TL;DR: 本文提出了一种新的局部特征归因方法保真度评估指标DPC，通过修改现有的预测变化指标，结合扰动和归因的方向，实现了近十倍的加速并消除了随机性，提供了确定性和可复现的评估过程。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险场景中，需要忠实反映模型决策过程的解释方法。现有保真度指标如Infidelity依赖蒙特卡洛近似，需要大量模型评估并引入随机采样不确定性。

Method: 在引导扰动实验中修改现有的预测变化指标，结合扰动和归因的方向，提出定向预测变化指标DPC。

Result: 在两个数据集（皮肤病变图像和金融表格数据）、两个黑盒模型、七种解释算法和广泛超参数范围内评估了4744个不同解释，DPC与PC一起实现了对基线导向和局部特征归因方法的全面计算高效评估。

Conclusion: DPC指标提供了确定性和可信任的评估过程，与局部Infidelity测量相同属性，同时实现了近十倍的加速和随机性的消除。

Abstract: The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes.

</details>


### [44] [Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data](https://arxiv.org/abs/2511.21378)
*Jungi Lee,Jungkwon Kim,Chi Zhang,Kwangsun Yoo,Seok-Joo Byun*

Main category: cs.LG

TL;DR: 提出自适应激进拒绝(AAR)方法，通过改进的z分数和高斯混合模型阈值动态排除异常数据，在图像和表格数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测模型假设训练数据完全正常，但实际数据往往包含污染。现有方法依赖固定污染比例假设，当假设与实际不符时性能严重下降，特别是在正常与异常数据分布重叠的噪声环境中。

Method: AAR方法使用改进的z分数和高斯混合模型阈值动态识别和排除异常数据，结合硬拒绝和软拒绝策略平衡保留正常数据与排除异常数据的权衡。

Result: 在两个图像数据集和三十个表格数据集上的广泛实验表明，AAR比最先进方法AUROC提高了0.041。

Conclusion: AAR为受污染数据集提供了可扩展且可靠的解决方案，增强了鲁棒性，为安全和医疗等领域的实际应用铺平了道路。

Abstract: Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare.

</details>


### [45] [Mechanistic Interpretability for Transformer-based Time Series Classification](https://arxiv.org/abs/2511.21514)
*Matīss Kalnāre,Sofoklis Kitharidis,Thomas Bäck,Niki van Stein*

Main category: cs.LG

TL;DR: 本文通过将NLP领域的机制可解释性技术（激活修补、注意力显著性、稀疏自编码器）应用于时间序列分类的Transformer架构，揭示了模型内部的因果结构和决策机制。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在时间序列分类中表现出色，但其内部决策机制复杂难懂。现有可解释性方法主要关注输入输出归因，对内部机制理解不足，需要开发新的解释方法来揭示Transformer在时间序列任务中的工作原理。

Method: 将NLP领域的机制可解释性技术（激活修补、注意力显著性、稀疏自编码器）适配到时间序列分类的Transformer架构中，系统性地探测注意力头和时间步的内部因果作用。

Result: 在基准时间序列数据集上的实验构建了展示信息内部传播的因果图，识别了驱动正确分类的关键注意力头和时间位置，并展示了稀疏自编码器在发现可解释潜在特征方面的潜力。

Conclusion: 研究为Transformer可解释性提供了方法论贡献，并为理解Transformer在时间序列分类任务中性能背后的功能机制提供了新的见解。

Abstract: Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks.

</details>


### [46] [Predictive Safety Shield for Dyna-Q Reinforcement Learning](https://arxiv.org/abs/2511.21531)
*Jin Pin,Krasowski Hanna,Vanneaux Elena*

Main category: cs.LG

TL;DR: 提出了一种基于模型预测的安全防护机制，用于离散空间中的强化学习，通过安全环境模型的模拟来更新Q函数，在保证硬安全约束的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有安全防护机制通常随机采样安全动作或使用固定后备控制器，忽视了不同安全动作对未来性能的影响，需要一种能兼顾安全性和性能的防护方法。

Method: 基于模型预测的安全防护，通过安全环境模型的模拟进行局部Q函数更新，使用安全预测来指导动作选择。

Result: 在网格世界环境中的实验表明，即使较短的预测范围也足以识别最优路径，且方法对分布偏移具有鲁棒性，无需额外训练。

Conclusion: 所提出的预测性安全防护方法能够在保持硬安全保证的同时提高强化学习性能，对现实应用具有重要价值。

Abstract: Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training.

</details>


### [47] [BanglaASTE: A Novel Framework for Aspect-Sentiment-Opinion Extraction in Bangla E-commerce Reviews Using Ensemble Deep Learning](https://arxiv.org/abs/2511.21381)
*Ariful Islam,Md Rifat Hossen,Abir Ahmed,B M Taslimul Haque*

Main category: cs.LG

TL;DR: 提出了BanglaASTE框架，这是首个用于孟加拉语方面情感三元组提取(ASTE)的混合分类框架，包含新创建的3,345条产品评论数据集，结合图匹配和语义相似度技术，在准确率和F1分数上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语方面情感分析研究严重不足，缺乏全面的数据集和专门的三元组提取框架，阻碍了该语言在电子商务和社交媒体领域的细粒度情感洞察应用。

Method: 开发了混合分类框架，采用基于图的方面-观点匹配与语义相似度技术，实现了结合BanglaBERT上下文嵌入和XGBoost提升算法的集成模型。

Result: 集成方法取得了89.9%的准确率和89.1%的F1分数，在所有评估指标上显著优于基线模型，有效解决了孟加拉语文本处理中的非正式表达、拼写变体和数据稀疏性等关键挑战。

Conclusion: 该研究推动了低资源语言情感分析的技术前沿，为孟加拉语电子商务分析应用提供了可扩展的解决方案。

Abstract: Aspect-Based Sentiment Analysis (ABSA) has emerged as a critical tool for extracting fine-grained sentiment insights from user-generated content, particularly in e-commerce and social media domains. However, research on Bangla ABSA remains significantly underexplored due to the absence of comprehensive datasets and specialized frameworks for triplet extraction in this language. This paper introduces BanglaASTE, a novel framework for Aspect Sentiment Triplet Extraction (ASTE) that simultaneously identifies aspect terms, opinion expressions, and sentiment polarities from Bangla product reviews. Our contributions include: (1) creation of the first annotated Bangla ASTE dataset containing 3,345 product reviews collected from major e-commerce platforms including Daraz, Facebook, and Rokomari; (2) development of a hybrid classification framework that employs graph-based aspect-opinion matching with semantic similarity techniques; and (3) implementation of an ensemble model combining BanglaBERT contextual embeddings with XGBoost boosting algorithms for enhanced triplet extraction performance. Experimental results demonstrate that our ensemble approach achieves superior performance with 89.9% accuracy and 89.1% F1-score, significantly outperforming baseline models across all evaluation metrics. The framework effectively addresses key challenges in Bangla text processing including informal expressions, spelling variations, and data sparsity. This research advances the state-of-the-art in low-resource language sentiment analysis and provides a scalable solution for Bangla e-commerce analytics applications.

</details>


### [48] [Ensemble Performance Through the Lens of Linear Independence of Classifier Votes in Data Streams](https://arxiv.org/abs/2511.21465)
*Enes Bektas,Fazli Can*

Main category: cs.LG

TL;DR: 本文研究集成学习中分类器数量与性能的关系，提出线性独立性理论框架，推导出达到指定线性独立性概率所需集成规模的理论估计，并在真实和合成数据集上验证了该理论的有效性。


<details>
  <summary>Details</summary>
Motivation: 集成学习通过组合多个基分类器提高分类性能，但过大的集成会导致计算效率低下和收益递减。本文旨在从分类器投票线性独立性的角度研究集成规模与性能的关系。

Method: 提出基于分类器输出线性独立性的理论框架，建立集成规模与线性独立性概率的数学模型，使用OzaBagging和GOOWE两种集成方法在真实和合成数据集上进行实验验证。

Result: 理论估计能有效识别OzaBagging等鲁棒集成的性能饱和点，但对于GOOWE等复杂加权方案，高理论多样性可能引发算法不稳定性。

Conclusion: 线性独立性为理解集成规模与性能关系提供了理论框架，理论估计能指导集成规模选择，但需考虑具体算法的稳定性特征。

Abstract: Ensemble learning improves classification performance by combining multiple base classifiers. While increasing the number of classifiers generally enhances accuracy, excessively large ensembles can lead to computational inefficiency and diminishing returns. This paper investigates the relationship between ensemble size and performance through the lens of linear independence among classifier votes in data streams. We propose that ensembles composed of linearly independent classifiers maximize representational capacity, particularly under a geometric model. We then generalize the importance of linear independence to the weighted majority voting problem. By modeling the probability of achieving linear independence among classifier outputs, we derive a theoretical framework that explains the trade-off between ensemble size and accuracy. Our analysis leads to a theoretical estimate of the ensemble size required to achieve a user-specified probability of linear independence. We validate our theory through experiments on both real-world and synthetic datasets using two ensemble methods, OzaBagging and GOOWE. Our results confirm that this theoretical estimate effectively identifies the point of performance saturation for robust ensembles like OzaBagging. Conversely, for complex weighting schemes like GOOWE, our framework reveals that high theoretical diversity can trigger algorithmic instability. Our implementation is publicly available to support reproducibility and future research.

</details>


### [49] [IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference](https://arxiv.org/abs/2511.21513)
*Wanli Zhong,Haibo Feng,Zirui Zhou,Hanyang Peng,Shiqi Yu*

Main category: cs.LG

TL;DR: IntAttention是一种完全整数化的注意力机制，通过IndexSoftmax操作符在整数域内替代浮点指数运算，消除了量化-softmax-反量化的开销，在边缘设备上实现了显著的加速和能耗降低。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署Transformer模型受到延迟和能耗的限制。虽然INT8量化有效加速了主要矩阵乘法，但softmax成为主要瓶颈，其量化-softmax-反量化过程占注意力总延迟的65%，破坏了端到端整数数据流。

Method: 提出IntAttention，核心是IndexSoftmax硬件友好操作符，完全在整数域内替代浮点指数运算。集成稀疏感知裁剪、32项查找表近似和直接整数归一化，消除所有数据类型转换开销。

Result: 在Armv8 CPU上，相比FP16基线实现3.7倍加速和61%能耗降低，比传统INT8注意力管道快2.0倍，同时保持与基线相当的高保真精度。

Conclusion: IntAttention实现了完全整数化的注意力管道，无需重新训练，为商品边缘设备上的Transformer推理提供了实用高效的解决方案。

Abstract: Deploying Transformer models on edge devices is limited by latency and energy budgets. While INT8 quantization effectively accelerates the primary matrix multiplications, it exposes the softmax as the dominant bottleneck. This stage incurs a costly dequantize-softmax-requantize detour, which can account for up to 65% of total attention latency and disrupts the end-to-end integer dataflow critical for edge hardware efficiency. To address this limitation, we present IntAttention, the first fully integer, plug-and-play attention pipeline without retraining. At the core of our approach lies IndexSoftmax, a hardware-friendly operator that replaces floating-point exponentials entirely within the integer domain. IntAttention integrates sparsity-aware clipping, a 32-entry lookup-table approximation, and direct integer normalization, thereby eliminating all datatype conversion overhead. We evaluate IntAttention and demonstrate consistent and substantial gains. Our method achieves up to 3.7x speedup and 61% energy reduction over FP16 baselines and 2.0x faster than conventional INT8 attention pipelines on Armv8 CPUs. These gains are achieved with high-fidelity accuracy comparable to baselines across diverse language and vision models, enabling practical and efficient Transformer inference on commodity edge devices. Code will be released in later version of this work.

</details>


### [50] [Context-Specific Causal Graph Discovery with Unobserved Contexts: Non-Stationarity, Regimes and Spatio-Temporal Patterns](https://arxiv.org/abs/2511.21537)
*Martin Rabel,Jakob Runge*

Main category: cs.LG

TL;DR: 本文提出了一种用于分析空间网格时间序列数据中因果图变化的框架，通过修改约束型因果发现方法在独立性检验层面的实现，能够利用现有因果发现算法（如PC、FCI、PCMCI等）来研究因果结构的变化及其稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据（如气候数据）通常具有空间网格时间序列结构，系统在不同时空点可能表现出相似行为，但存在的变异既包含重要信息，又可能影响假设平稳性或空间平移不变性的算法的稳定性和有效性。

Method: 开发了一个模块化框架，通过修改约束型因果发现方法在独立性检验层面的实现，能够利用现有因果发现算法（PC、PC-stable、FCI、PCMCI、PCMCI+、LPCMCI）而无需或只需极少修改，将问题分解为更易处理的子问题。

Result: 该框架具有极高的模块化、易扩展性和广泛适用性，能够系统性地理解和改进一系列子问题，并可以结合变化点检测、聚类、独立性检验等相关领域的研究成果进行扩展。

Conclusion: 该框架通过将复杂问题分解为更易处理的子问题，简化了对基本限制、控制权衡的超参数以及结果统计解释的理解，提供了一个开源实现方案。

Abstract: Real-world data, for example in climate applications, often consists of spatially gridded time series data or data with comparable structure. While the underlying system is often believed to behave similar at different points in space and time, those variations that do exist are twofold relevant: They often encode important information in and of themselves. And they may negatively affect the stability / convergence and reliability\Slash{}validity of results of algorithms assuming stationarity or space-translation invariance. We study the information encoded in changes of the causal graph, with stability in mind. An analysis of this general task identifies two core challenges. We develop guiding principles to overcome these challenges, and provide a framework realizing these principles by modifying constraint-based causal discovery approaches on the level of independence testing. This leads to an extremely modular, easily extensible and widely applicable framework. It can leverage existing constraint-based causal discovery methods (demonstrated on IID-algorithms PC, PC-stable, FCI and time series algorithms PCMCI, PCMCI+, LPCMCI) with little to no modification. The built-in modularity allows to systematically understand and improve upon an entire array of subproblems. By design, it can be extended by leveraging insights from change-point-detection, clustering, independence-testing and other well-studied related problems. The division into more accessible sub-problems also simplifies the understanding of fundamental limitations, hyperparameters controlling trade-offs and the statistical interpretation of results. An open-source implementation will be available soon.

</details>


### [51] [Computing Strategic Responses to Non-Linear Classifiers](https://arxiv.org/abs/2511.21560)
*Jack Geary,Boyan Gao,Henry Gouk*

Main category: cs.LG

TL;DR: 该论文提出了一种计算战略分类中智能体最佳响应的新方法，通过优化智能体目标的拉格朗日对偶来解决非线性分类器设置中的分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 当前战略分类方法主要关注线性设置，但在许多情况下非线性分类器更合适。非线性分类器的主要限制是无法计算最佳响应。

Method: 提出了一种通过优化智能体目标的拉格朗日对偶来计算最佳响应的新方法。

Result: 该方法在线性设置中重现了最佳响应，识别了现有方法的关键弱点，并能直接应用于非线性分类器设置，用于评估和训练。

Conclusion: 该方法为战略分类中的非线性分类器提供了有效的解决方案，能够处理部署分类器导致的战略行为和分布偏移问题。

Abstract: We consider the problem of strategic classification, where the act of deploying a classifier leads to strategic behaviour that induces a distribution shift on subsequent observations. Current approaches to learning classifiers in strategic settings are focused primarily on the linear setting, but in many cases non-linear classifiers are more suitable. A central limitation to progress for non-linear classifiers arises from the inability to compute best responses in these settings. We present a novel method for computing the best response by optimising the Lagrangian dual of the Agents' objective. We demonstrate that our method reproduces best responses in linear settings, identifying key weaknesses in existing approaches. We present further results demonstrating our method can be straight-forwardly applied to non-linear classifier settings, where it is useful for both evaluation and training.

</details>


### [52] [A decoupled alignment kernel for peptide membrane permeability predictions](https://arxiv.org/abs/2511.21566)
*Ali Amirahmadi,Gökçe Geylan,Leonardo De Maria,Farzaneh Etminani,Mattias Ohlsson,Alessandro Tibo*

Main category: cs.LG

TL;DR: 本文提出了一种单体感知的解耦全局对齐核（MD-GAK）及其变体PMD-GAK，用于预测环肽的细胞膜渗透性，解决了数据稀缺和不确定性校准问题。


<details>
  <summary>Details</summary>
Motivation: 环肽是靶向细胞内位点的有前景模式，但细胞膜渗透性仍是关键瓶颈，且面临公共数据有限和需要良好校准不确定性的挑战。

Method: 提出了MD-GAK核方法，将化学上有意义的残基-残基相似性与序列对齐耦合，同时将局部匹配与间隙惩罚解耦。还引入了变体PMD-GAK，加入三角位置先验。使用高斯过程作为预测模型进行不确定性估计。

Result: 通过广泛实验证明，该方法在各项指标上均优于现有最先进模型，PMD-GAK在减少校准误差方面具有额外优势。

Conclusion: 提出的MD-GAK和PMD-GAK框架在环肽细胞膜渗透性预测中表现优异，特别是在不确定性校准方面，提供了一种完全可复现的解决方案。

Abstract: Cyclic peptides are promising modalities for targeting intracellular sites; however, cell-membrane permeability remains a key bottleneck, exacerbated by limited public data and the need for well-calibrated uncertainty. Instead of relying on data-eager complex deep learning architecture, we propose a monomer-aware decoupled global alignment kernel (MD-GAK), which couples chemically meaningful residue-residue similarity with sequence alignment while decoupling local matches from gap penalties. MD-GAK is a relatively simple kernel. To further demonstrate the robustness of our framework, we also introduce a variant, PMD-GAK, which incorporates a triangular positional prior. As we will show in the experimental section, PMD-GAK can offer additional advantages over MD-GAK, particularly in reducing calibration errors. Since our focus is on uncertainty estimation, we use Gaussian Processes as the predictive model, as both MD-GAK and PMD-GAK can be directly applied within this framework. We demonstrate the effectiveness of our methods through an extensive set of experiments, comparing our fully reproducible approach against state-of-the-art models, and show that it outperforms them across all metrics.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [53] [A new Fractal Mean-Field analysis in phase transition](https://arxiv.org/abs/2511.20846)
*Ismael S. S. Carrasco,Henrique A. de Lima,Fernando A. Oliveira*

Main category: cond-mat.stat-mech

TL;DR: 本文重新审视了二阶相变系统中关联函数的理论基础，特别关注扩展到非整数空间维度的伊辛模型。作者提出在临界点处，平衡动力学被限制在自旋团簇的分形边缘，并推导了关联分形维数与费希尔指数的关系，以及关联分形维数与序参量分形维数之间的几何关系。


<details>
  <summary>Details</summary>
Motivation: 理解相变不仅需要识别序参量，还需要表征它们在各个尺度上的关联行为。传统欧几里得处理仅限于整数维度，需要引入临界指数η来捕捉临界温度下关联的空间衰减。本文旨在从分形几何角度重新解释临界关联行为。

Method: 从费希尔引入的经典框架出发，假设在临界点处平衡动力学被有效限制在自旋团簇的分形边缘。在该子空间中，控制关联的分形维数直接与费希尔指数相关。推导了两个分形维数之间的显式几何关系，并将分析扩展到非整数空间维度。

Result: 建立了关联分形维数与费希尔指数的直接关系，该关联分形维数不同于序参量的分形维数。推导了连接两个分形维数的显式几何关系，将空间自相似性与临界点的标度行为联系起来。分析在低于上临界维度时对非整数空间维度仍然有效，并产生正确的费希尔指数η值。

Conclusion: 拉什布鲁克标度关系在空间维度被视为连续参数时仍然成立，加强了临界标度的普适性，并强调了分形几何在表征临界关联中的作用。该处理自然地扩展到非整数空间维度，为理解临界现象提供了新的几何视角。

Abstract: Understanding phase transitions requires not only identifying order parameters but also characterizing how their correlations behave across scales. By quantifying how fluctuations at distinct spatial or temporal points are related, correlation functions reveal the structural organization of complex systems. Here, we revisit the theoretical foundations of these correlations in systems undergoing second-order phase transitions, with emphasis on the Ising model extended to non-integer spatial dimensions. Starting from the classical framework introduced by Fisher, we discuss how the standard Euclidean treatment, restricted to integer dimensions, necessitates the introduction of the critical exponent $η$ to capture the spatial decay of correlations at $T=T_c$. We suppose that, at criticality, the equilibrium dynamics become effectively confined to the fractal edge of spin clusters. Within this framework, the fractal dimension that governs the correlations in that subspace is directly related to Fisher exponent, which quantifies the singular behavior of the correlation function near criticality. Importantly, this correlation fractal dimension is distinct from the fractal dimension associated with the order parameter. We further derive an explicit geometrical relation connecting the two fractal dimensions, thereby linking spatial self-similarity to the observed scaling behavior at criticality. This treatment naturally extends to non-integer spatial dimensions, which remain valid below the upper critical dimension and produce the correct value of Fisher exponent $η$ for a continuous space dimension. Our analysis also confirms that the Rushbrooke scaling relation, continues to hold when the spatial dimension is treated as a continuous parameter, reinforcing the universality of critical scaling and underscoring the role of fractal geometry in characterizing correlations at criticality.

</details>


### [54] [Hardware Acceleration of Frustrated Lattice Systems using Convolutional Restricted Boltzmann Machine](https://arxiv.org/abs/2511.20911)
*Pratik Brahma,Junghoon Han,Tamzid Razzaque,Saavan Patel,Sayeef Salahuddin*

Main category: cond-mat.stat-mech

TL;DR: 该论文提出使用卷积受限玻尔兹曼机（CRBM）结合数字硬件加速器来模拟几何阻挫系统，在Shastry-Sutherland伊辛晶格上实现了比GPU快3-5个数量级的采样速度，并能恢复所有已知相态。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛方法在模拟几何阻挫系统时采样效率受限，而全连接受限玻尔兹曼机无法有效表示物理晶格的稀疏相互作用结构。

Method: 实现卷积受限玻尔兹曼机（CRBM）来利用晶格的平移对称性，并开发数字硬件加速器来提升采样性能。

Result: 成功模拟了324个自旋的晶格，恢复了Shastry-Sutherland伊辛模型的所有已知相态，包括长程有序分数平台相，采样速度比GPU实现快3-5个数量级。

Conclusion: 该方法为嵌入物理对称性的大规模材料系统模拟提供了可扩展的数字硬件路径，具有室温操作和可重编程优势。

Abstract: Geometric frustration gives rise to emergent quantum phenomena and exotic phases of matter. While Monte Carlo methods are traditionally used to simulate such systems, their sampling efficiency is limited by the complexity of interactions and ground-state properties. Restricted Boltzmann Machines (RBMs), a class of probabilistic neural networks, offer improved sampling by incorporating machine learning techniques. However, fully-connected bipartite RBMs are inefficient for representing physical lattices with sparse interactions. To address this, we implement Convolutional Restricted Boltzmann Machines (CRBMs) that leverage translational symmetry inherent to lattices. Using the classical Shastry-Sutherland (SS) Ising lattice, we demonstrate (i) CRBM formulation that captures SS interactions, and (ii) digital hardware accelerator to enhance sampling performance. We simulate lattices with up to 324 spins, recovering all known phases of the SS Ising model, including the long range ordered fractional plateau. Our hardware characterizes spin behavior at critical points and within spin liquid phases. This implementation achieves a speedup of 3 to 5 orders of magnitude (33 ns to 120 ms) over GPU-based implementations. Moreover, the time-to-solution is within two orders of magnitude of quantum annealers, while offering superior scalability, room-temperature operation and reprogrammability. This work paves a pathway for scalable digital hardware that embeds physical symmetries to enable large scale simulations of material systems.

</details>


### [55] [Anisotropic scale invariance and the uniaxial Lifshitz point from the nonperturbative renormalization group](https://arxiv.org/abs/2511.21004)
*Gonzalo De Polsi,Pawel Jakubczyk*

Main category: cond-mat.stat-mech

TL;DR: 本文使用非微扰重整化群的导数展开方法研究具有标量序参数系统中的各向异性标度不变性和相关的泛函不动点（Lifshitz点）。


<details>
  <summary>Details</summary>
Motivation: 研究Lifshitz点的各向异性标度不变性现象及其相关的泛函不动点，特别关注具有非经典各向异性指数θ<1/2的Lifshitz不动点的存在性。

Method: 采用非微扰重整化群的导数展开方法，分析标量序参数系统中的Lifshitz点。

Result: 证明了具有非经典各向异性指数θ<1/2的Lifshitz不动点的存在，并对物理上最相关的三维单轴Lifshitz点(d,m)=(3,1)提供了一组临界指数的估计值。

Conclusion: 将本文的预测与围绕维度d=4+1/2的微扰展开以及1/N展开的现有估计进行了比较。

Abstract: We employ the derivative expansion of the nonperturbative renormalization group to address the phenomenon of anisotropic scale invariance and the associated functional fixed points, also known as Lifshitz points, in systems characterized by a scalar order parameter. We demonstrate the existence of the Lifshitz fixed point featuring a non-classical value of the anisotropy exponent $θ<1/2$ and provide estimates for values of a set of critical exponents in the physically most relevant case of the three-dimensional uniaxial Lifshitz point $(d,m)=(3,1)$, $m$ denoting the anisotropy index. We compare our predictions with existing estimates from perturbative expansions around dimensionality $d=4+\frac{1}{2}$ as well as those from the $1/N$ expansion.

</details>


### [56] [Quantum Hard Spheres with Affine Quantization](https://arxiv.org/abs/2511.21119)
*Riccardo Fantoni*

Main category: cond-mat.stat-mech

TL;DR: 本文使用仿射量子化方法研究量子硬球流体，假设其服从玻色-爱因斯坦统计，并采用路径积分蒙特卡洛方法求解热力学性质。


<details>
  <summary>Details</summary>
Motivation: 研究量子硬球流体的热力学性质，特别是在玻色-爱因斯坦统计下的行为，为理解量子多体系统的统计力学提供理论基础。

Method: 采用仿射量子化方法处理量子硬球流体，结合路径积分蒙特卡洛模拟技术进行计算分析。

Result: 通过数值模拟获得了量子硬球流体在玻色-爱因斯坦统计下的热力学性质数据。

Conclusion: 仿射量子化结合路径积分蒙特卡洛方法能够有效研究量子硬球流体的热力学行为，为量子多体系统研究提供了可靠的计算框架。

Abstract: We study a fluid of quantum hard-spheres treated with affine-quantization. Assuming that the fluid obeys to Bose-Einstein statistics we solve for its thermodynamic properties using the path integral Monte Carlo method.

</details>


### [57] [Kibble-Zurek Meets Tricriticality: Breakdown of Adiabatic-Impulse and New Scaling Forms](https://arxiv.org/abs/2511.21386)
*Chengshu Li*

Main category: cond-mat.stat-mech

TL;DR: 研究了在临界点附近的Kibble-Zurek效应，发现绝热-脉冲情景失效，并提出了新的标度形式。


<details>
  <summary>Details</summary>
Motivation: 探索在临界点这一特殊临界区域中Kibble-Zurek效应的行为，因为传统理论在此处可能不适用。

Method: 通过研究临界点附近的动力学行为，分析绝热-脉冲情景的失效机制。

Result: 发现临界点附近绝热-脉冲情景确实失效，并提出了几个新的标度形式来描述这种特殊临界行为。

Conclusion: 临界点附近的Kibble-Zurek效应表现出与传统临界点不同的行为特征，需要新的标度理论来描述。

Abstract: The Kibble-Zurek effect is studied around a tricritical point, where the adiabatic-impulse scenario breaks down. Several new scaling forms are also proposed.

</details>


### [58] [Dynamics of a tracer trapped in a correlated medium in the presence of a wall](https://arxiv.org/abs/2511.21436)
*Marcin Piotr Pruszczyk,Andrea Gambassi*

Main category: cond-mat.stat-mech

TL;DR: 研究粒子在热波动介质中的随机运动，该粒子被谐波势阱束缚在距离壁面一定位置。介质由具有可调关联长度的高斯场建模，通过耗散弛豫动力学演化。壁面处的狄利克雷边界条件产生排斥性涨落诱导力，影响粒子的平均位置和谐波势阱强度。


<details>
  <summary>Details</summary>
Motivation: 研究壁面附近粒子的有效过阻尼动力学，特别是非线性记忆项如何依赖于壁面-粒子间距，以及临界点处位置关联函数的代数衰减行为。

Method: 使用具有可调关联长度的高斯场建模热波动介质，考虑壁面处的狄利克雷边界条件，分析粒子在谐波势阱中的有效过阻尼动力学，包括非线性记忆项的影响。

Result: 发现涨落诱导力导致粒子平均位置偏移和谐波势阱强度重整化，位置关联函数包含依赖于壁面距离的记忆诱导项，在临界点该项随时间代数衰减并显示从体相行为到壁面行为的交叉。

Conclusion: 壁面边界条件对粒子动力学产生显著影响，特别是在临界点附近，记忆效应导致位置关联函数呈现距离依赖的代数衰减行为。

Abstract: We describe the random motion of a particle immersed in a thermally fluctuating medium and harmonically trapped at a certain distance from a wall. The medium, modeled by a Gaussian field with a tunable correlation length $ξ$, is linearly coupled to the particle and evolves according to dissipative relaxational dynamics. Dirichlet boundary conditions imposed on the field at the wall give rise to a repulsive fluctuation-induced force acting on the particle, causing a shift in its average position and a renormalization of the strength of the harmonic trap. We describe the effective overdamped dynamics of the particle, which features a nonlinear memory term depending on the wall-particle separation. We show that the two-time correlation function of the particle position features a memory-induced term that depends on the distance of the particle from the wall. At the critical point, this term decays algebraically upon increasing time and it displays a crossover from the behavior observed in the bulk to that corresponding to having the particle at the wall.

</details>


### [59] [Thermodynamic response functions in a cell fluid model with Curie-Weiss interaction. I. Supercritical region](https://arxiv.org/abs/2511.21485)
*M. P. Kozlovskii,O. A. Dobush,R. V. Romanik,I. V. Pylyuk,M. A. Shpot*

Main category: cond-mat.stat-mech

TL;DR: 本文基于先前在巨正则系综中获得的细胞流体模型的精确状态方程，推导了通过居里-魏斯型势相互作用的粒子系统的热力学响应函数，包括等温压缩率、热压力系数、热膨胀系数、等容和等压热容。


<details>
  <summary>Details</summary>
Motivation: 研究多粒子系统在居里-魏斯型势作用下的热力学响应函数，以深入理解系统的热力学性质。

Method: 基于先前在巨正则系综中获得的细胞流体模型的精确状态方程，进行热力学响应函数的显式推导。

Result: 得到了等温压缩率、热压力系数、热膨胀系数、等容和等压热容等响应函数，并在超临界区域内以温度、密度和化学势的函数形式进行了图形化展示。

Conclusion: 成功推导并展示了居里-魏斯型势相互作用系统的热力学响应函数，为理解该系统的热力学行为提供了重要工具。

Abstract: Thermodynamic response functions, including the isothermal compressibility, the thermal pressure coefficient, and the thermal expansion coefficient, isochoric and isobaric heat capacities are explicitly derived for a many-particle system interacting through a Curie-Weiss-type potential. These calculations are based on an exact equation of state previously obtained for a cell fluid model in the grand canonical ensemble. The resulting response functions are presented graphically as functions of temperature, density, and chemical potential within the supercritical region.

</details>


### [60] [Giant enhancement of transport driven by active fluctuations: impact of inertia](https://arxiv.org/abs/2511.21536)
*K. Białas,J. Spiechowicz*

Main category: cond-mat.stat-mech

TL;DR: 研究发现惯性对自由布朗粒子在主动波动驱动下的输运增强效应具有复杂影响：惯性不仅能诱导该现象，还能根据参数区域增强、减弱甚至破坏该效应。主动波动幅度分布的方差是决定惯性影响的关键因素。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，在周期性势场中，由白泊松散粒噪声驱动的自由布朗粒子输运可显著增强，这种现象可能在过阻尼系统中出现，也可能由惯性诱导。本文旨在全面研究惯性对过阻尼系统中观察到的自由输运增强效应的影响。

Method: 通过研究惯性对自由布朗粒子在主动波动（白泊松散粒噪声）和周期性势场共同作用下的输运行为的影响，探索不同参数区域中惯性效应的表现。

Result: 惯性对自由输运增强效应具有多重影响：在某些参数区域能诱导该现象，在其他区域能增强、减弱甚至破坏该效应。主动波动幅度分布的方差是决定惯性影响的关键参数。

Conclusion: 惯性在主动波动驱动的布朗粒子输运中扮演复杂角色，其影响取决于系统参数。这些发现不仅适用于微观物理系统，也与生物系统（如活细胞）相关，其中代谢活动产生的波动本质上是主动的。

Abstract: Recently, a paradoxical effect has been demonstrated in which transport of a free Brownian particle driven by active fluctuations in the form of white Poisson shot noise can be significantly enhanced when it is additionally subjected to a periodic potential. This phenomenon can emerge in an overdamped system, but it may also be inertia-induced. Here, we considerably extend previous studies and comprehensively investigate the impact of inertia on the effect of free transport enhancement observed in the overdamped system. We detect that inertia can not only induce this phenomenon, but depending on a parameter regime, it may also strengthen, weaken, or even destroy it. We exemplify these different scenarios and explore the parameter space to identify the corresponding regions where they emerge. The variance of the active fluctuations amplitude distribution is a key determinant of the inertia influence on the effect of free transport amplification. Our results are relevant not only for microscopic physical systems but also for biological ones, such as, e.g., living cells, where fluctuations generated by metabolic activities are active by default.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [61] [Energy-efficient recurrence quantification analysis](https://arxiv.org/abs/2511.20684)
*Norbert Marwan*

Main category: nlin.CD

TL;DR: 本研究提出了直接计算RQA指标的策略，无需构建递归图，通过随机抽样进一步加速计算，在保持准确性的同时显著降低计算成本、内存使用和能耗。


<details>
  <summary>Details</summary>
Motivation: 标准RQA实现需要计算昂贵的递归图和线长直方图，计算成本高，限制了其在大规模数据分析中的应用。

Method: 直接从时间序列或相空间向量计算RQA指标，避免构建递归图，并应用随机抽样程序仅评估部分线结构来加速优化计算。

Result: 这些改进实现了更短的运行时间、更少的内存使用和访问，以及更低的总体能耗，同时保持准确性。

Conclusion: 所提出的策略降低了计算成本，有助于节能和可持续数据分析，并拓宽了基于递归的方法在现代研究背景下的适用性。

Abstract: Recurrence quantification analysis (RQA) is a widely used tool for studying complex dynamical systems, but its standard implementation requires computationally expensive calculations of recurrence plots (RPs) and line length histograms. This study introduces strategies to compute RQA measures directly from time series or phase space vectors, avoiding the need to construct RPs. The calculations can be further accelerated and optimised by applying a random sampling procedure, in which only a subset of line structures is evaluated. These modifications result in shorter run times, less memory use and access, and lower overall energy consumption during analysis while maintaining accuracy. This makes them especially appealing for large-scale data analysis and machine learning applications. The ideas are not limited to diagonal line measures, but can likewise be applied to vertical line-based measures and to recurrence network measures. By lowering computational costs, the proposed strategies contribute to energy saving and sustainable data analysis, and broaden the applicability of recurrence-based methods in modern research contexts.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [62] [Centipedes Leap into the Quantum Realm](https://arxiv.org/abs/2511.20690)
*Kaytki Chakankar,Xinhui Tang,Yiguo Zhang*

Main category: quant-ph

TL;DR: 该论文将量子策略应用于蜈蚣博弈，发现了优于经典解的新量子纳什均衡，并通过Qiskit实现验证了量子策略能提供更高收益并更准确模拟现实结果。


<details>
  <summary>Details</summary>
Motivation: 经典蜈蚣博弈的理性解（第一轮就背叛）与现实中玩家更常合作的现象不符，受量子策略在囚徒困境中应用的启发，研究量子力学原理在蜈蚣博弈中的应用。

Method: 将量子力学原理应用于蜈蚣博弈，在Qiskit平台上实现算法验证量子策略。

Result: 发现了两个新的量子纳什均衡，这些均衡优于经典解；量子策略为双方玩家提供了更好的收益，并更准确地模拟了博弈的现实结果。

Conclusion: 提出了针对类似结构量子博弈的广义猜想，证明量子策略在解决蜈蚣博弈方面优于传统策略如逆向归纳法。

Abstract: The centipede game is a two-player non-zero-sum game. Each turn, a player can choose whether they want to take or pass a growing reward. The classical, rational solution of this game shows defection in the first round, when in reality, players cooperate much more often. Inspired by prior work employing quantum strategies in the prisoners dilemma, we showed that when similar quantum mechanics principles are applied to the centipede game, it leads to two new quantum Nash equilibria that are superior to the classical solution. Furthermore, by implementing our algorithm on Qiskit, we confirmed that leveraging quantum strategies, rather than strategies like backward induction, to solve the centipede game provided better payoffs for both players and more accurately modeled the games real-life outcomes. Ultimately, we propose a generalized conjecture for similarly structured quantum games.

</details>


### [63] [Floquet thermalization by power-law induced permutation symmetry breaking](https://arxiv.org/abs/2511.21284)
*Manju C,Uma Divakaran*

Main category: quant-ph

TL;DR: 本文研究了幂律耦合自旋系统中对称性破缺对量子动力学行为的影响，通过调节耦合强度参数α，系统从完全对称的混沌系统过渡到可积系统，并观察到热化现象的出现。


<details>
  <summary>Details</summary>
Motivation: 研究真实系统中非均匀相互作用如何打破置换对称性，并探索这种对称性破缺如何导致新的动力学行为，特别是热化现象的出现。

Method: 引入幂律耦合（随距离r衰减为1/r^α），通过调节参数α从0到∞，研究系统从无限长程耦合（置换对称）到短程可积模型的转变。使用总角动量算符J^2和冯·诺依曼熵S_{N/2}等动力学量进行分析。

Result: 小α时系统保持接近置换对称子空间的行为；中等α时出现热化特征，表现为全希尔伯特空间中随机态的值；大α时接近可积的kicked Ising模型。热化还依赖于驱动周期τ，大τ时热化在更小的α值出现。

Conclusion: 幂律耦合参数α的调节能够控制系统的对称性破缺程度，从而调控系统的动力学行为从混沌到热化再到可积的转变，为理解集体量子动力学中的对称性作用提供了新视角。

Abstract: Permutation symmetry plays a central role in the understanding of collective quantum dynamics. On the other hand, interactions are rarely uniform in real systems. By introducing power law couplings that algebraically decay with the distance between the spins $r$ as $1/r^α$, we break this symmetry with a non-zero $α$, and probe the emergence of new dynamical behaviors, including thermalization. As we increase $α$, the system interpolates from an infinite range spin system at $α=0$ exhibiting permutation symmetry, to a short range integrable model as $α\rightarrow \infty$ where this permutation symmetry is absent. We focus on the change in the behavior of the system as $α$ is tuned, using dynamical quantities like total angular momentum operator $J^2$ and the von Neumann entropy $S_{N/2}$. Starting from the chaotic limit of the permutation symmetric Hamiltonian at $α=0$, we find that for small $α$, the steady state values of these quantities remain close to the permutation symmetric subspace values corresponding to $α=0$. At intermediate $α$ values, these show signatures of thermalization exhibiting values corresponding to that of random states in full Hilbert space. On the other hand, the large $α$ limit approaches the values corresponding to integrable kicked Ising model. In addition, we also study the dependence of thermalization on the driving period $τ$, with results indicating the onset of thermalization for smaller values of $α$ when $τ$ is large, thereby extending the intermediate range of $α$. We further confirm these results using effective dimension and spectral statistics.

</details>


### [64] [Comment on Classical-Gravity--Quantum-Matter Claims About Gravity-Mediated Entanglement](https://arxiv.org/abs/2511.20717)
*Mikołaj Sienicki,Krzysztof Sienicki*

Main category: quant-ph

TL;DR: 本文回应了Aziz和Howl关于经典引力场能产生量子纠缠的主张，指出在非相对论极限下，相互作用是超局域的，总幺正算符可分解，从乘积输入不会产生纠缠。


<details>
  <summary>Details</summary>
Motivation: 澄清经典引力场是否能介导量子纠缠的问题，维护BMV推断的完整性，即观测到引力介导的纠缠强烈表明引力自由度是非经典的。

Method: 通过(i)重述批评的核心观点，(ii)提供通道理论重构使结论模型无关，(iii)澄清已量子物质中纠缠的激活与经典场真正介导纠缠的区别。

Result: 在非相对论极限下，经典引力场无法从乘积输入产生纠缠，相互作用是超局域的，总幺正算符可分解。

Conclusion: 标准BMV推断仍然成立：观测到引力介导的纠缠强烈表明引力自由度是非经典的，经典引力场无法真正介导纠缠。

Abstract: A recent paper by Aziz and Howl (Nature 2025) argues that, once quantum matter is described at the level of quantum field theory and coupled to a classical gravitational field, higher order processes can generate entanglement between two spatially separated masses. A contemporaneous critical note (Marletto, Oppenheim, Vedral, Wilson, arXiv:2511.07348v1) shows that, in the actual nonrelativistic limit employed there, the interaction becomes ultra local, the total unitary factorizes, and no entanglement is generated from a product input. In this comment we (i) restate the core point of that critique, (ii) give a channel theoretic reformulation that makes the conclusion model independent, and (iii) clarify the distinction between activation of entanglement in already quantum matter and genuine mediation of entanglement by a classical field. Once these clarifications are in place, the standard BMV inference that observation of gravity mediated entanglement strongly indicates nonclassical gravitational degrees of freedom remains intact.

</details>


### [65] [Closed-Loop Phase-Coherence Compensation for Superconducting Qubits Integrated Computational and Hardware Validation of the Aurora Method](https://arxiv.org/abs/2511.20741)
*Futoshi Hamanoue*

Main category: quant-ph

TL;DR: Aurora-DD是一种相位相干补偿方法，结合基于符号的反馈优化和XY8动态解耦支架，通过离线校准在模拟器上优化全局相位偏移，然后在硬件上部署预校准的相位补偿。


<details>
  <summary>Details</summary>
Motivation: 解决NISQ设备中的相位相干性问题，抑制退相干和系统相位偏差，提供实用且稳定的相位补偿方案。

Method: 使用基于符号的反馈更新全局相位偏移，结合固定深度的XY8动态解耦支架，在模拟器上进行离线优化，然后在硬件上部署预校准的相位补偿。

Result: 在模拟器上实现68-97%的均方误差降低，在真实硬件上实现99.2-99.6%的绝对误差减少，相比无DD基线有显著改善。

Conclusion: Aurora-DD是一种实用、稳定且与硬件兼容的相位相干补偿器，适用于NISQ设备的单量子比特设置。

Abstract: We present an emulator-based and hardware feasibility study of Aurora-DD, a phase-coherence compensation method that integrates a sign-based feedback update of a global phase offset (Delta phi) with a fixed-depth XY8 dynamical decoupling (DD) scaffold. The feedback optimization is performed offline on a calibrated emulator and the resulting Delta phi* is deployed as pre-calibrated phase compensation on hardware. This represents an "offline closed-loop, online open-loop" feasibility demonstration. Using an Aer-based emulator calibrated with ibm_fez device parameters, Aurora-DD achieves substantial reductions in mean-squared error of the measured expectation value <Z>, yielding 68-97% improvement across phase settings phi = 0.05, 0.10, 0.15, 0.20 over n=30 randomized trials. These large-n emulator results provide statistically stable evidence that the combined effect of XY8 and Delta phi* suppresses both dephasing and systematic phase bias. On real superconducting hardware (ibm_fez), we perform a small-sample (n=3) multi-phase validation campaign. Aurora-DD yields point estimates corresponding to approximately 99.2-99.6% reduction in absolute error relative to a no-DD baseline across all tested phase points. These hardware numbers are reported transparently as feasibility evidence under tight queue and credit constraints. In contrast, the auxiliary Aurora+ZNE branch exhibits instability: shallow two-point ZNE occasionally amplifies calibration inconsistencies and produces large error outliers. We therefore relegate ZNE analysis to the Appendix and position Aurora-DD (without ZNE) as the primary contribution. Overall, the combined results support pre-calibrated Aurora-DD as a practical, stable, and hardware-compatible phase-coherence compensator for NISQ devices in single-qubit settings.

</details>


### [66] [Elucidating the Inter-system Crossing of the Nitrogen-Vacancy Center up to Megabar Pressures](https://arxiv.org/abs/2511.20750)
*Benchen Huang,Srinivas V. Mandyam,Weijie Wu,Bryce Kobrin,Prabudhya Bhattacharyya,Yu Jin,Bijuan Chen,Max Block,Esther Wang,Zhipan Wang,Satcher Hsieh,Chong Zu,Christopher R. Laumann,Norman Y. Yao,Giulia Galli*

Main category: quant-ph

TL;DR: 本研究结合第一性原理计算和高压NV实验，建立了氮空位色心在一般应力条件下光学性质的完整描述，解决了高压量子传感中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 尽管金刚石压砧中氮空位色心已在兆巴压力下实现量子传感，但应力如何影响NV中心的微观机制仍不清楚，需要系统研究其光学性质。

Method: 采用第一性原理计算和高压NV实验相结合的方法，分析NV中心在不同应力条件下的光学特性和系统间穿越速率。

Result: 揭示了NV中心在保持和破坏缺陷对称性的应力下系统间穿越速率的复杂行为，解释了(111)取向压砧中对比度增强的微观起源和高压下对比度反转现象。

Conclusion: 该工作为通过控制局部应力环境优化NV高压传感器性能奠定了基础，并表明对称性破坏应力可作为固态自旋缺陷的新型调控手段。

Abstract: The integration of Nitrogen-Vacancy color centers into diamond anvil cells has opened the door to quantum sensing at megabar pressures. Despite a multitude of experimental demonstrations and applications ranging from quantum materials to geophysics, a detailed microscopic understanding of how stress affects the NV center remains lacking. In this work, using a combination of first principles calculations as well as high-pressure NV experiments, we develop a complete description of the NV's optical properties under general stress conditions. In particular, our ab initio calculations reveal the complex behavior of the NV's inter-system crossing rates under stresses that both preserve and break the defect's symmetry. Crucially, our proposed framework immediately resolves a number of open questions in the field, including: (i) the microscopic origin of the observed contrast-enhancement in (111)-oriented anvils, and (ii) the surprising observation of NV contrast-inversion in certain high-pressure regimes. Our work lays the foundation for optimizing the performance of NV high-pressure sensors by controlling the local stress environment, and more generally, suggests that symmetry-breaking stresses can be utilized as a novel tuning knob for generic solid-state spin defects.

</details>


### [67] [Multi-Field Relativistic Continuous Matrix Product States](https://arxiv.org/abs/2511.20762)
*Karan Tiwana,Antoine Tilloy*

Main category: quant-ph

TL;DR: 本文解决了多场相对论连续矩阵乘积态(RCMPS)的变分优化问题，通过引入黎曼优化框架，使其能够应用于多场相互作用模型，并在双标量场模型中成功捕捉了对称性破缺相和BKT转变。


<details>
  <summary>Details</summary>
Motivation: RCMPS在处理多场量子场论时存在发散问题，除非满足正则性条件，这限制了其只能用于单场自相互作用模型。本文旨在解决这一长期存在的问题，扩展RCMPS的应用范围。

Method: 引入黎曼优化框架，在正则子流形上最小化能量密度，保留纯变分结果。在1+1维度的两个相互作用标量场模型上进行验证。

Result: 该方法成功捕捉了不同的对称性破缺相，并沿O(2)对称参数线检测到Berezinskii-Kosterlitz-Thouless(BKT)转变的特征。

Conclusion: 该方法使RCMPS能够应用于比之前更广泛的问题类别，显著扩展了其适用范围。

Abstract: Relativistic continuous matrix product states (RCMPS) are a powerful variational ansatz for quantum field theories of a single field. However, they inherit a property of their non-relativistic counterpart that makes them divergent for models with multiple fields, unless a regularity condition is satisfied. This has so far restricted the use of RCMPS to toy models with a single self-interacting field. We address this long standing problem by introducing a Riemannian optimization framework, that allows to minimize the energy density over the regular submanifold of multi-field RCMPS, and thus to retain purely variational results. We demonstrate its power on a model of two interacting scalar fields in $1+1$ dimensions. The method captures distinct symmetry-breaking phases, and the signature of a Berezinskii-Kosterlitz-Thouless (BKT) transition along an $O(2)$-symmetric parameter line. This makes RCMPS usable for a far larger class of problems than before.

</details>


### [68] [Real-time Monitoring of Neon Film Growth for Electron-on-Neon Qubits](https://arxiv.org/abs/2511.20765)
*Sidharth Duthaluru,Kaiwen Zheng,Erik A. Henriksen,Kater W. Murch*

Main category: quant-ph

TL;DR: 该论文展示了使用高温YBCO微波谐振器实时监测氖膜生长的技术，通过增加谐振器驱动功率可将氖膜厚度控制在100纳米以下，为电子-氖量子比特的受控形成提供了重要进展。


<details>
  <summary>Details</summary>
Motivation: 电子-氖电荷态与超导电路耦合是量子计算的有前景平台，但需要控制氖膜在电路表面的生长过程。

Method: 使用高转变温度YBCO微波谐振器实时监测氖膜生长，在氖的三相点温度附近及以下跟踪膜厚度变化。

Result: 在300多次凝固实验中，发现从液相凝固的氖膜最终厚度在几纳米到几微米之间随机变化；通过增加谐振器驱动功率，可稳定地将最终厚度降至100纳米以下。

Conclusion: 这些结果为eNe量子比特的受控氖膜形成迈出了重要一步，并突显了高温谐振器在混合量子系统中的广泛应用价值。

Abstract: Electron-on-neon (eNe) charge states coupled to superconducting circuits are a promising platform for quantum computing. Control over the formation of these charge states requires techniques to track and control the growth of solid Ne films on the circuit surface. We demonstrate a real-time Ne film-growth monitor using high-transition-temperature (high-$T_c$) YBCO microwave resonators. The high $T_c$ enables tracking of the film thickness near Ne's triple temperature and below. Across more than 300 solidification experiments, we find that the final Ne thickness varies stochastically from a few nm to a few $μ$m for films solidified from the liquid phase. By increasing the driving power in the resonator, we consistently reduce the final thickness to below 100 nm. These results represent an important step toward controlled formation of Ne films for eNe qubits and highlight the broader utility of high-$T_c$ resonators for hybrid quantum systems.

</details>


### [69] [Opportunities and Challenges of Computational Electromagnetics Methods for Superconducting Circuit Quantum Device Modeling: A Practical Review](https://arxiv.org/abs/2511.20774)
*Samuel T. Elkin,Ghazi Khan,Ebrahim Forati,Brandon W. Langley,Dogan Timucin,Reza Molavi,Sara Sussman,Thomas E. Roth*

Main category: quant-ph

TL;DR: 这篇综述文章介绍了计算电磁学(CEM)方法在超导电路量子器件设计中的应用，重点讨论了多尺度器件建模面临的挑战和解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着超导电路量子器件等新兴应用的出现，传统的CEM方法在处理纳米到厘米级多尺度器件时面临模拟时间长、精度损失等挑战，需要为研究人员提供实用的CEM技术选择指南。

Method: 文章首先介绍主要CEM技术的基本原理和概念，然后深入讨论多尺度器件建模的具体挑战，特别是以超导电路量子器件为例进行分析。

Result: 为研究人员提供了选择合适CEM方法的实用指导，并提出了缓解多尺度建模挑战的具体步骤，同时指出了未来有价值的研究方向。

Conclusion: 虽然聚焦于超导电路量子器件领域，但文中讨论的细节对其他领域的研究人员同样有益，有助于改进复杂量子器件的设计能力。

Abstract: High-fidelity numerical methods that model the physical layout of a device are essential for the design of many technologies. For methods that characterize electromagnetic effects, these numerical methods are referred to as computational electromagnetics (CEM) methods. Although the CEM research field is mature, emerging applications can still stress the capabilities of the techniques in use today. The design of superconducting circuit quantum devices falls in this category due to the unconventional material properties and important features of the devices covering nanometer to centimeter scales. Such multiscale devices can stress the fundamental properties of CEM tools which can lead to an increase in simulation times, a loss in accuracy, or even cause no solution to be reliably found. While these challenges are being investigated by CEM researchers, knowledge about them is limited in the broader community of users of these CEM tools. This review is meant to serve as a practical introduction to the fundamental aspects of the major CEM techniques that a researcher may need to choose between to model a device, as well as provide insight into what steps they may take to alleviate some of their challenges. Our focus is on highlighting the main concepts without rigorously deriving all the details, which can be found in many textbooks and articles. After covering the fundamentals, we discuss more advanced topics related to the challenges of modeling multiscale devices with specific examples from superconducting circuit quantum devices. We conclude with a discussion on future research directions that will be valuable for improving the ability to successfully design increasingly more sophisticated superconducting circuit quantum devices. Although our focus and examples are taken from this area, researchers from other fields will still benefit from the details discussed here.

</details>


### [70] [Higher-order Zeno sequences](https://arxiv.org/abs/2511.20792)
*Kasra Rajabzadeh Dizaji,Leeseok Kim,Milad Marvian,Christian Arenz*

Main category: quant-ph

TL;DR: 本文开发了高阶芝诺序列，通过将芝诺序列与高阶Trotter公式关联，实现了更快的芝诺动力学收敛，误差缩放从传统的O(1/N)提升到O(1/N^{2k})。


<details>
  <summary>Details</summary>
Motivation: 传统量子芝诺效应通过频繁观测冻结量子系统动力学，但误差缩放仅为O(1/N)。本文旨在开发更高阶的芝诺序列以获得更快的收敛速度。

Method: 将高阶芝诺序列与高阶Trotter公式建立关联，利用这种关系开发适用于不同芝诺效应表现形式的高阶序列，包括频繁投影测量和幺正冲击。还开发了通过高频周期控制场实现芝诺动力学的方法。

Result: 成功开发了高阶芝诺序列，实现了O(1/N^{2k})的改进误差缩放，其中k描述芝诺序列的阶数。特别开发了产生二阶改进的控制场和更短的芝诺序列。

Conclusion: 通过建立芝诺序列与Trotter公式的关联，实现了高阶芝诺动力学的快速收敛，并与随机化和Uhrig动力学解耦建立联系，为弱耦合机制下的高效实现提供了可能。

Abstract: The quantum Zeno effect typically refers to freezing the dynamics of a quantum system through frequent observations. In general, quantum Zeno dynamics is obtained with an error of order $\mathcal{O}(1/N)$, where $N$ is the number of projective measurements performed within a fixed evolution time. In this work, we develop higher-order Zeno sequences that achieve faster convergence to Zeno dynamics, yielding an improved error scaling of $\mathcal{O}(1/N^{2k})$, where $k$ describes the order of the Zeno sequence. This is achieved by relating higher-order Zeno sequences to higher-order Trotter formulas that achieve similar convergence behavior. We leverage this relation to develop higher-order Zeno sequences for different manifestations of the quantum Zeno effect, including frequent projective measurements and unitary kicks. We go on to discuss achieving quantum Zeno dynamics through periodic control fields of high frequency. We explicitly develop control fields that yield a second-order type improvement in the Zeno error scaling and present shorter Zeno sequences. Finally, we discuss the connection to randomized and Uhrig dynamical decoupling to develop more efficient implementations in the weak coupling regime.

</details>


### [71] [Restoring a Missing Meta-Symmetry of Quantum Mechanics](https://arxiv.org/abs/2511.20907)
*Sheng Ran*

Main category: quant-ph

TL;DR: 该论文提出了一种扩展的量子理论框架，通过在时空希尔伯特空间和动量-能量希尔伯特空间之间建立对偶对称性，恢复了(x,t)和(k,E)共轭对的基本对称性。


<details>
  <summary>Details</summary>
Motivation: 传统量子力学中，动量-能量表示仅被视为傅里叶重表达，缺乏动力学活性。作者旨在恢复(x,t)和(k,E)共轭对之间的基本对称性。

Method: 将量子理论扩展到总希尔伯特空间H_total = H_xt ⊕ H_kE，其中动量-能量扇区H_kE携带由其自伴算子^T生成的自主幺正演化。

Result: 建立了一种元对称性：单一全局量子态的两个共轭动力学投影之间的对称性。该框架产生了对偶流形几何，并重现了均匀暗能量背景和黑洞视界附近的指数边界映射。

Conclusion: 该框架为通常用广义相对论处理的宇宙学现象开辟了一条量子理论途径。

Abstract: In conventional quantum mechanics, all unitary evolution takes place within the space-time Hilbert space $\mathcal H_{xt}=L^2(\mathcal M_{xt})$, with time as the sole evolution parameter. The momentum-energy representation $φ(k,E)$ is treated merely as a Fourier re-expression of the same state-kinematically equivalent but dynamically inert. Here we restore the fundamental symmetry between the conjugate pairs $(x,t)$ and $(k,E)$ by extending the quantum theory to an enlarged Hilbert space $\mathcal H_{\text{total}} = \mathcal H_{xt} \oplus \mathcal H_{kE}$, within which the momentum-energy sector $\mathcal H_{kE}=L^2(\mathcal M_{kE})$ carries its own autonomous unitary evolution generated by a self-adjoint operator $\hat{\mathcal T}$. The resulting structure establishes a meta-symmetry: a symmetry between two conjugate dynamical projections of a single global quantum state. It produces a dual-manifold geometry in which each domain is locally complete yet globally open, with divergent limits in one mapping onto extended regions in the other. Remarkably, the dual-manifold symmetry alone reproduces both the uniform dark-energy background and the exponential boundary mapping near black-hole horizons that underlies Hawking radiation. This framework thus opens a quantum-theoretic route to cosmological phenomena that are ordinarily treated within general relativity.

</details>


### [72] [Many-Body Entanglement in Solid-State Emitters](https://arxiv.org/abs/2511.20797)
*Emma Daggett,Christian M. Lange,Bennet Windt,Arshag Danageozian,Alexander Senichev,Jordi Arnau Montañà-López,Chanchal,Kinjol Barua,Xingyu Gao,Zhaoyun Zheng,Vijin Kizhake Veetil,Souvik Biswas,Jonas M. Peterson,Na Liu,Chuchuan Hong,Teri Odom,Matthew Pelton,Tongcang Li,Jelena Vučković,Vladamir Shalaev,Alexandra Boltasseva,Sophia E. Economou,Jonathan D. Hood,Valentin Walther,Rahul Trivedi,Libai Huang*

Main category: quant-ph

TL;DR: 本文综述了固态量子发射器与光子之间的多体相互作用，探讨了实现量子纠缠态（如光子图态、簇态）的挑战与进展，重点关注退相干抑制和鲁棒多体相干性的利用。


<details>
  <summary>Details</summary>
Motivation: 固态量子发射器和纳米光子学的进展为量子态的可扩展生成提供了新机遇，但实现复杂纠缠态面临内在非均匀性和退相干的挑战，需要研究多体相互作用和相干性控制。

Method: 通过综述固态量子发射器中光-物质界面的基本多体相互作用和动力学，分析退相干抑制策略和鲁棒多体相干性的利用方法。

Result: 固态量子光子学在工程化量子发射器与光子之间的多体相互作用方面取得进展，能够实现光子图态、簇态、超辐射发射等纠缠态，为量子计算、传感和模拟提供前景。

Conclusion: 尽管存在非均匀性和退相干挑战，通过理解多体相互作用和开发相干性控制策略，固态量子光子学有望实现鲁棒的量子纠缠态，推动量子信息技术发展。

Abstract: The preparation and control of quantum states lie at the heart of quantum information science (QIS). Recent advances in solid-state quantum emitters (QEs) and nanophotonics have transformed the landscape of quantum photonic technologies, enabling scalable generation of quantum states of light and matter. A new frontier in solid-state quantum photonics is the engineering of many-body interactions between QEs and photons to achieve robust coherence and controllable many-body entanglement. These entangled states, including photonic graph and cluster states, superradiant emission, and emergent quantum phases, are promising for quantum computation, sensing, and simulation. However, intrinsic inhomogeneities and decoherence in solid-state platforms pose significant challenges to realize such complex entangled states. This review provides an overview of the fundamental many-body interactions and dynamics at the light-matter interfaces of solid-state QEs, and discusses recent advances in mitigating decoherence and harnessing robust many-body coherence.

</details>


### [73] [Nonextensive statistics for a 2D electron gas in noncommutative spaces](https://arxiv.org/abs/2511.20822)
*Bienvenu Gnim Adewi,Isiaka Aremua*

Main category: quant-ph

TL;DR: 该研究在二维非对易空间中分析了一个量子系统，该系统包含电子在垂直磁场、谐振势和外加电场作用下的情况，采用非广延统计热力学框架。通过推导q-广义化的配分函数、磁化和磁化率，分析了非广延参数q和非对易参数θ的联合效应。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索非对易几何中量子系统的热力学性质，特别是结合非广延统计框架来分析非对易性对系统热力学行为的影响。

Method: 采用Tsallis统计框架，通过应用适用于非对易几何的广义Hilhorst变换，推导了q-广义化的配分函数、磁化和磁化率。

Result: 研究发现当q→1时，系统展现出新的热力学状态和非对易几何特有的异常电磁性质，揭示了非对易性和非广延性的联合效应。

Conclusion: 非对易几何中的量子系统在非广延统计框架下表现出独特的热力学行为，非对易参数和非广延参数的相互作用导致了新的物理现象和异常电磁特性。

Abstract: This work investigates a quantum system described by a Hamiltonian operator in a two dimensional noncommutative space. The system consists of an electron subjected to a perpendicular magnetic field $\mathbf{B}$, coupled to a harmonic potential and an external electric field $\mathbf{E}$, within the context of non-extensive statistical thermodynamics. The noncommutative geometry introduces a fundamental minimal length that modifies the phase space structure. The thermodynamics of this quantum system is developed within the framework of Tsallis statistics through the derivation of $q$-generalized versions of the partition function, magnetization, and magnetic susceptibility, following the application of a generalized Hilhorst transformation adapted to non-commutative geometry. The combined effects of the non-extensivity parameter $q$ and the noncommutativity parameter $θ$ are analyzed by considering the limit $q \rightarrow 1$, revealing new thermodynamic regimes and anomalous electromagnetic properties specific to quantum systems in non-commutative geometry.

</details>


### [74] [Modeling dissipation in quantum active matter](https://arxiv.org/abs/2511.21502)
*Alexander P. Antonov,Sangyun Lee,Benno Liebchen,Hartmut Löwen,Jannis Melles,Giovanna Morigi,Yehor Tuchkov,Michael te Vrugt*

Main category: quant-ph

TL;DR: 该研究将活性物质概念扩展到量子框架，通过时间局域主方程模拟具有类经典活性特征的驱动量子粒子运动，分析不同时间尺度下量子效应与活性动力学的相互作用。


<details>
  <summary>Details</summary>
Motivation: 将经典活性物质范式扩展到量子框架需要开放量子系统描述，旨在实现量子版本的经典活性系统类比。

Method: 使用时间局域主方程模拟驱动量子粒子的动力学，分析不同形式主方程下粒子在不同时间尺度的运动。

Result: 通过系统比较多种类型的主方程，揭示了量子效应与类活性动力学相互作用下粒子运动的演化规律。

Conclusion: 这些结果对于指导实现量子类比经典活性系统的实验至关重要。

Abstract: Active matter denotes a system of particles immersed in an external environment, from which the particles extract energy continuously in order to perform motion. Extending the paradigm of active matter to a quantum framework requires an open quantum system description. In this work, we consider a driven quantum particle whose external driving exhibits characteristics of classical activity. We model the dynamics with time-local master equations and analyze the particle motion at different time scales for different forms of the master equations. By systematically comparing several types of master equations, we uncover how the particle motion evolves under the interplay of quantum effects and active-like dynamics. These results are essential for guiding possible experiments aimed at realizing quantum analogues of classical active systems.

</details>


### [75] [Mode multiplexing for scalable cavity-enhanced operations in neutral-atom arrays](https://arxiv.org/abs/2511.20858)
*Ziv Aqua,Matthew L. Peters,David C. Spierings,Guoqing Wang,Edita Bytyqi,Thomas Propson,Vladan Vuletić*

Main category: quant-ph

TL;DR: 提出了一种基于光学腔的多模式方法，用于中性原子阵列的快速并行操作，通过将不同原子耦合到不同的腔模式来实现独立同时处理，支持多达50个模式，显著提高了中电路综合症提取和远程纠缠分布速率。


<details>
  <summary>Details</summary>
Motivation: 在大规模中性原子阵列中，高效光子收集是快速非破坏性量子比特读取和远程纠缠分布等关键任务的瓶颈，需要可扩展的解决方案。

Method: 采用基于光学腔的方法，通过选择性移动相关原子跃迁，使每个原子耦合到不同的腔模式，实现多模式复用，支持多达50个模式的并行操作。

Result: 提出的系统设计能够实现腔模式复用，显著提高中电路综合症提取速度和远程原子阵列之间的纠缠分布速率。

Conclusion: 这种方法为中性原子阵列中的核心挑战提供了可扩展的解决方案，推动了实用量子技术的发展。

Abstract: Neutral atom arrays provide a versatile platform for quantum information processing. However, in large-scale arrays, efficient photon collection remains a bottleneck for key tasks such as fast, non-destructive qubit readout and remote entanglement distribution. We propose a cavity-based approach that enables fast, parallel operations over many atoms using multiple modes of a single optical cavity. By selectively shifting the relevant atomic transitions, each atom can be coupled to a distinct cavity mode, allowing independent simultaneous processing. We present practical system designs that support cavity-mode multiplexing with up to 50 modes, enabling rapid mid-circuit syndrome extraction and significantly enhancing entanglement distribution rates between remote atom arrays. This approach offers a scalable solution to core challenges in neutral atom arrays, advancing the development of practical quantum technologies.

</details>


### [76] [Fusion of classical and quantum kernels enables accurate and robust two-sample tests](https://arxiv.org/abs/2511.20941)
*Yu Terada,Yugo Ogio,Ken Arai,Hiroyuki Tezuka,Yu Tanaka*

Main category: quant-ph

TL;DR: 本文提出了一种融合经典核与量子核的混合两样本检验方法MMD-FUSE，旨在解决小数据集场景下的统计检验问题，通过结合经典核的领域特定归纳偏置和量子核的独特表达能力，提升检验功效。


<details>
  <summary>Details</summary>
Motivation: 传统基于核的两样本检验方法在小数据集上表现不佳，且核选择对性能至关重要但缺乏系统指导。本文旨在构建适用于小数据集的有效假设检验方法，利用量子核增强MMD-FUSE框架。

Method: 提出混合检验策略，融合经典核和量子核，结合经典核的领域特定归纳偏置与量子核的独特表达能力，构建自适应强大的检验方法。

Result: 实验表明：1）经过适当超参数调优，带量子核的MMD-FUSE在小样本高维数据上持续优于经典方法；2）混合框架表现出显著鲁棒性，能适应不同数据特征并在多样场景中实现高检验功效。

Conclusion: 量子启发和混合核策略有潜力构建更有效的统计检验，为样本量有限的数据分析提供通用工具。

Abstract: Two-sample tests have been extensively employed in various scientific fields and machine learning such as evaluation on the effectiveness of drugs and A/B testing on different marketing strategies to discriminate whether two sets of samples come from the same distribution or not. Kernel-based procedures for hypothetical testing have been proposed to efficiently disentangle high-dimensional complex structures in data to obtain accurate results in a model-free way by embedding the data into the reproducing kernel Hilbert space (RKHS). While the choice of kernels plays a crucial role for their performance, little is understood about how to choose kernel especially for small datasets. Here we aim to construct a hypothetical test which is effective even for small datasets, based on the theoretical foundation of kernel-based tests using maximum mean discrepancy, which is called MMD-FUSE. To address this, we enhance the MMD-FUSE framework by incorporating quantum kernels and propose a novel hybrid testing strategy that fuses classical and quantum kernels. This approach creates a powerful and adaptive test by combining the domain-specific inductive biases of classical kernels with the unique expressive power of quantum kernels. We evaluate our method on various synthetic and real-world clinical datasets, and our experiments reveal two key findings: 1) With appropriate hyperparameter tuning, MMD-FUSE with quantum kernels consistently improves test power over classical counterparts, especially for small and high-dimensional data. 2) The proposed hybrid framework demonstrates remarkable robustness, adapting to different data characteristics and achieving high test power across diverse scenarios. These results highlight the potential of quantum-inspired and hybrid kernel strategies to build more effective statistical tests, offering a versatile tool for data analysis where sample sizes are limited.

</details>


### [77] [Generalized Heralded Generation of Non-Gaussian States Using an Optical Parametric Amplifier](https://arxiv.org/abs/2511.20946)
*Xiao-Xi Yao,Bo Zhang Yusuf Turek*

Main category: quant-ph

TL;DR: 本文提出了一种广义的预示光学参量放大器协议，能够处理任意非经典输入，从而扩展了量子态工程的应用范围。该协议可以作为集成双光子减法器生成压缩薛定谔猫态，或作为非高斯性放大器提纯量子资源。


<details>
  <summary>Details</summary>
Motivation: 传统预示光学参量放大器的潜力仅限于相干态输入，限制了其在量子态工程中的应用。本文旨在开发一种能够处理任意非经典输入的广义协议，以解锁更广泛的量子现象。

Method: 引入广义预示光学参量放大器协议，该协议能够接受任意非经典输入。具体包括：使用压缩真空输入实现集成双光子减法功能，以及使用小振幅薛定谔猫态输入实现非高斯性放大功能。

Result: 该协议成功实现了：1）作为集成双光子减法器，确定性生成高保真度、大振幅的压缩薛定谔猫态；2）作为非高斯性放大器，将小振幅薛定谔猫态提纯为高纯度的重要量子资源近似态。

Conclusion: 这项工作将光学参量放大器从专用源转变为多功能实用的先进量子态工程平台，能够从单一集成装置生成各种非高斯态，极大地扩展了量子信息处理的能力。

Abstract: The heralded optical parametric amplifier (OPA) has emerged as a promising tool for quantum state engineering. However, its potential has been limited to coherent state inputs. Here, we introduce a generalized heralded OPA protocol that unlocks a vastly expanded class of quantum phenomena by accepting arbitrary non-classical inputs. With a squeezed vacuum input, the setup functions as an integrated two-photon subtractor, deterministically generating high-fidelity, larger-amplitude squeezed Schrödinger cat states -- an operation previously requiring complex, discrete setups. Furthermore, when fed a small-amplitude SC state, the protocol acts as a non-Gaussianity amplifier, distilling it into high-purity approximations of key quantum resources like specific photon-number superpositions. This work transforms the OPA from a specialized source into a versatile and practical platform for advanced quantum state engineering, enabling the generation of a wide array of non-Gaussian states from a single, integrated setup.

</details>


### [78] [Mirror subspace diagonalization: a quantum Krylov algorithm with near-optimal sampling cost](https://arxiv.org/abs/2511.20998)
*Shota Kanasugi,Yuya O. Nakagawa,Norifumi Matsumoto,Yuichiro Hidaka,Kazunori Maruyama,Hirotaka Oshima*

Main category: quant-ph

TL;DR: 本文提出了一种名为镜像子空间对角化(MSD)的新方法，显著降低了量子Krylov算法在基态能量估计中的采样成本，接近理论下界。


<details>
  <summary>Details</summary>
Motivation: 量子Krylov算法在近期量子计算时代显示出潜力，但其固有的高采样成本（主要由于哈密顿量中每个项的单独测量）限制了实际应用，尤其是在大规模电子结构问题中。

Method: MSD利用有限差分公式将哈密顿算符表示为具有对称移动时间步长的时间演化幺正算符的线性组合，从而在Krylov子空间内高效估计哈密顿矩阵。通过优化时间步参数和移动能谱来同时最小化有限差分误差和统计误差。

Result: 理论分析表明MSD在哈密顿量谱范数远小于其1-范数时特别有效。各种分子模型的数值结果显示，与传统量子Krylov算法相比，MSD可实现约10到10,000倍的采样成本降低。

Conclusion: MSD方法接近量子Krylov算法采样成本的理论下界，为大规模电子结构问题的高精度模拟提供了高效解决方案。

Abstract: Quantum Krylov algorithms have emerged as a promising approach for ground-state energy estimation in the near-term quantum computing era. A major challenge, however, lies in their inherently substantial sampling cost, primarily due to the individual measurement of each term in the Hamiltonian. While various techniques have been proposed to mitigate this issue, the sampling overhead remains a significant bottleneck, especially for practical large-scale electronic structure problems. In this work, we introduce an alternative method, dubbed mirror subspace diagonalization (MSD), which approaches the theoretical lower bound of the sampling cost for quantum Krylov algorithms. MSD leverages a finite-difference formula to express the Hamiltonian operator as a linear combination of time-evolution unitaries with symmetrically shifted timesteps, enabling efficient estimation of the Hamiltonian matrix within the Krylov subspace. In this scheme, the finite difference and statistical errors are simultaneously minimized by optimizing the timestep parameter and shifting the energy spectrum. Consequently, MSD attains the lower bound of the sampling cost of the quantum Krylov algorithms up to a logarithmic factor. Furthermore, we employ classical post-processing to infer Hamiltonian moments, which are used to mitigate the ground state energy error based on the Lanczos scheme. Through theoretical analysis of the sampling cost, we demonstrate that MSD is particularly effective when the spectral norm of the Hamiltonian is significantly smaller than its 1-norm. Such a situation arises, for example, in high-accuracy simulations of molecules using large basis sets that incorporate strong electronic correlations. Numerical results for various molecular models reveal that MSD can achieve sampling cost reductions ranging from approximately 10 to 10,000 times compared to the conventional quantum Krylov algorithm.

</details>


### [79] [Multi-path vector entanglement engineering via dark mode control in optomechanics](https://arxiv.org/abs/2511.21052)
*P. Djorwé,R. Altuijri,A. J. Almalki,S. Abdel-Khalek,A. -H. Abdel-Aty*

Main category: quant-ph

TL;DR: 提出了一种在光机械系统中利用偏振电磁场和暗模控制生成多路径纠缠的方案，通过机械耦合和偏振角调控暗模，实现双体和三体纠缠态的生成。


<details>
  <summary>Details</summary>
Motivation: 开发能够抵抗热噪声的量子纠缠资源，为量子信息处理、量子通信和量子计算任务提供更稳健的量子技术基础。

Method: 使用两个机械耦合的机械谐振器，通过偏振电磁场驱动，利用偏振角和机械耦合调制相位来调控暗模，实现多路径纠缠工程。

Result: 在暗模破坏条件下，系统能够生成双体和三体纠缠态，这些纠缠态在热噪声下比未破坏区域更稳健，可承受高达两个数量级的温度波动。

Conclusion: 该方案为生成抗噪声量子资源开辟了新途径，在偏振角精细调谐下可产生简并的双纠缠态，对现代量子技术具有重要应用价值。

Abstract: We propose a scheme to generate multi-paths entanglement in an optomechanical system by exploiting polarized electromagnetic fields and dark mode control. Our system consists of two mechanically coupled mechanical resonators, which are driven by a common electromagnetic field. An inclusion of a polarizer induces linear polarizations of the electromgnetic field corresponding to the vertical (transverse electric ($\rm{TE}$) and horizontal (transverse magnetic [($\rm{TM}$]) modes, which drive the mechanical resonators. Without the mechanical coupling $J_m=0$, the polarization angle ($φ$) controls dark mode in the system. The breaking of this dark mode leads to multi-paths engineering of bipartite optomechanical entanglements. By switching on the phonon hopping rate ($J_m\neq0$), both the polarization angle and the modulation phase of the mechanical coupling allow a further control of the dark mode. The simultaneous Dark Mode Breaking (\rm{DMB}) conditions under these two parameters leads to multi-paths bipartite and tripartite entanglements. For a fine tuning of the polarization angle ($φ=π/4$) this scheme enables a generation of twin entangled states, where the bipartite/tripartite generated entangled states are degenerated and might be of great interest for quantum information processing, quantum communication and diverse quantum computational tasks. The generated entanglements are more resilient against thermal fluctuations in the \rm{DMB} regime, i.e., up to two order of magnitude robust than in the Unbreaking regime. Our work sheets light on new possibilities to generate noise-tolerant quantum resources that are useful for plethora of modern quantum technologies.

</details>


### [80] [Witness wedges in fidelity-deviation plane: separating teleportation advantage and Bell-inequality violation](https://arxiv.org/abs/2511.21079)
*Kyoungho Cho,Jeongho Bang*

Main category: quant-ph

TL;DR: 提出了一个统一框架来分析d维量子隐形传态，通过联合几何分析平均保真度F和保真度偏差D两个互补指标。基于Schur-Weyl对偶性和置换对称性计算，将高矩Haar平均简化为有限组迹不变量，得到F和D的闭式表达式。将(F,D)平面转化为校准诊断图，揭示了量子隐形传态优势和CGLMP不等式违反之间的定量差距。


<details>
  <summary>Details</summary>
Motivation: 需要统一分析量子隐形传态协议的两个关键性能指标——平均保真度和保真度偏差，理解它们之间的几何关系，并为量子资源提供校准诊断工具。

Method: 基于Schur-Weyl对偶性和置换对称性计算的表示理论框架，将高矩Haar平均简化为有限组迹不变量，推导出任意希尔伯特空间维度下F和D的闭式表达式。

Result: 获得了F和D的紧密边界，将可容许偏差直接与最优平均性能的差距联系起来。将(F,D)平面转化为校准诊断图，可以估计各向同性通道资源的可见度。

Conclusion: 在(F,D)平面中，量子隐形传态优势和CGLMP不等式违反表现为两条斜率相同但截距不同的见证线，揭示了"纠缠但局域"与"真正非局域"资源之间的定量差距。

Abstract: We develop a unified framework to analyze $d$-dimensional quantum teleportation through the joint geometry of two complementary figures of merit: average fidelity $F$ (how well a protocol works on average) and fidelity deviation $D$ (how uniformly it works across the inputs). Technically, we formulate a representation-theoretical framework based on Schur-Weyl duality and permutation symmetry calculus that reduce the higher-moment Haar averages to a finite set of trace invariants of the composed correction unitaries. This yields closed-form expressions for $F$ and $D$ in arbitrary Hilbert-space dimension and delivers tight bounds that link the admissible deviation directly to the gap from the optimal average performance. In particular, any measured pair $(F, D)$ can be ported into a visibility estimate for isotropic channel resources, turning the $(F, D)$-plane into a calibrated diagnostic map. We further cast the teleportation advantage and CGLMP-inequality violation as two witnesses lines in the $(F,D)$ plane: one line certifies that $F$ beats the classical benchmark $2/(d{+}1)$, while the other line certifies the Bell nonlocality. Their identical slope but distinct intercepts expose a quantitative gap between "entangled yet local" and "genuinely nonlocal" resources.

</details>


### [81] [Tip-enhanced quantum-sensing spectroscopy for bright and reconfigurable solid-state single-photon emitters](https://arxiv.org/abs/2511.21127)
*Hyeongwoo Lee,Taeyoung Moon,Hyeonmin Oh,Kijeong Park,Huitae Joo,Milos Toth,Igor Aharonovich,Kyoung-Duck Park*

Main category: quant-ph

TL;DR: 本研究提出了一种尖端增强量子传感光谱技术，用于调控六方氮化硼中的单光子发射器，通过精确空间定位和自适应控制实现了单光子源的重构和量子传感。


<details>
  <summary>Details</summary>
Motivation: 六方氮化硼中的原子级缺陷具有室温单光子发射和相干自旋态，但在量子计算和传感应用中面临空间和光谱随机性的挑战，限制了其与纳米光学腔的确定性耦合。

Method: 采用尖端增强量子传感光谱技术，通过精确空间定位单个发射器到不同等离子体共振的尖端腔中，自适应控制激发和发射增强率以及单光子纯度。

Result: 实现了固态单光子源的有效重构，同时进行纳米光谱空间和时间分辨分析，并通过光学检测磁共振实验在尖端耦合的六方氮化硼纳米片中展示了尖端增强量子传感。

Conclusion: 该方法为室温单光子发射器的高灵敏度和确定性量子传感提供了独特途径。

Abstract: Atom-like defects in hexagonal boron nitride (hBN) provide room-temperature single-photon emission and coherent spin states, making them attractive for quantum-computing and -sensing applications. However, their random spatial and spectral characteristics hamper deterministic coupling with nano-optical cavities, limiting their use as bright single-photon sources and sensitive quantum sensors. Here, we present tip-enhanced quantum-sensing spectroscopy of single-photon emitters in hBN. Through precise spatial positioning of individual emitters within tip-cavities with different plasmon resonances, we adaptively control the enhancement rates of both excitation and emission, as well as the single-photon purity. In this way, optimal selection of their relative contributions can effectively reconfigure solid-state single-photon sources, with simultaneous nano-spectroscopic space- and time-resolved analyses. Furthermore, we demonstrate tip-enhanced quantum-sensing with single spin defects through optically detected magnetic resonance (ODMR) experiments in tip-coupled hBN nanoflakes. Our approach provides a unique pathway toward highly-sensitive and deterministic quantum-sensing with room-temperature single-photon emitters.

</details>


### [82] [Vortex-Enhanced Zitterbewegung in Relativistic Electron Wave Packets](https://arxiv.org/abs/2511.21142)
*Zhongze Guo,Bei Xu,Qiang Gu*

Main category: quant-ph

TL;DR: 该论文构建了相对论涡旋电子波包，通过引入轨道角动量来放大Zitterbewegung（ZBW）振幅，为观测相对论量子动力学提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 长期以来，Zitterbewegung（ZBW）由于处于亚康普顿尺度而无法在自由电子中观测到，需要寻找放大其振幅的方法。

Method: 精心构建相对论涡旋电子波包作为正负能量狄拉克态的相干叠加，推导其时空动力学，并引入轨道角动量作为放大机制。

Result: 轨道角动量能够显著放大ZBW振幅，同时保持相干性，将高斯和贝塞尔-高斯模型统一在单一框架内。

Conclusion: 相对论涡旋态为在结构化电子波包中观测相对论量子动力学开辟了新的可能性。

Abstract: Zitterbewegung (ZBW), the trembling motion predicted by the Dirac equation, has long remained unobservable in free electrons due to its sub-Compton scale. We elaborately construct a relativistic vortex electron wave packet as a coherent superposition of both positive- and negative-energy Dirac states and derive their space-time dynamics. Our analysis demonstrates that introducing orbital angular momentum provides a mechanism for amplifying the ZBW amplitude far beyond that of conventional Gaussian packets, while maintaining coherence. The resulting relativistic vortex states unify Gaussian and Bessel-Gaussian models within a single framework and opens new possibilities for observing relativistic quantum dynamics in structured electron wave packets.

</details>


### [83] [Geometric Entanglement Entropy on Projective Hilbert Space](https://arxiv.org/abs/2511.21186)
*Loris Di Cairano*

Main category: quant-ph

TL;DR: 该论文提出了一个几何框架，将纯态二分纠缠视为投影希尔伯特空间上的宏观函数，通过Fubini-Study度量定义几何纠缠熵，用于测量给定纠缠值在量子几何中的简并度。


<details>
  <summary>Details</summary>
Motivation: 从局部状态层面的纠缠量化转向理解整个纯态流形上纠缠的全局组织和几何结构，探索具有给定纠缠量的状态在完整状态空间中的丰度以及常数纠缠流形的几何特性。

Method: 将投影希尔伯特空间视为黎曼流形，将二分纠缠提升为该流形上的宏观函数，其水平集将纯态空间分层为常数纠缠超曲面，定义几何纠缠熵作为这些超曲面对数体积。

Result: 在自旋-1/2系统和两量子比特系统中进行了具体计算，展示了该框架的应用，并扩展到自旋链系统。

Conclusion: 该几何框架为理解纠缠在量子态空间中的全局组织提供了新的视角，几何纠缠熵可作为纠缠空间中的微正则熵来量化给定纠缠值的简并度。

Abstract: Entanglement for pure bipartite states is most commonly quantified in a state-by-state manner to each pure state of a bipartite system a scalar quantity, such as the von Neumann entropy of a reduced density matrix. This provides a precise local characterization of how entangled a given state is. At the same time, this local description naturally invites a set of complementary, more global questions about the structure of the space of pure states: How abundant are the states with a given amount of entanglement within the full state space? Do the manifolds of constant entanglement exhibit distinct geometric regimes? These questions shift the focus from assigning an entanglement value to a single state to understanding the global organization and geometry of entanglement across the entire manifold of pure states.
  In this work, we develop a geometric framework in which these questions become natural. We regard the projective Hilbert space of pure states, endowed with the Fubini-Study metric, as a Riemannian manifold and promote bipartite entanglement to a macroscopic functional on this manifold. Its level sets stratify the space of pure states into hypersurfaces of constant entanglement, and we define a geometric entanglement entropy as the log-volume of these hypersurfaces, weighted by the Fubini-Study gradient of entanglement. This quantity plays the role of a microcanonical entropy in entanglement space: it measures the degeneracy of a given entanglement value in the natural quantum geometry.
  The framework is illustrated first in the simplest case of a single spin-1/2 and then for bipartite entanglement of spin systems, including a two-qubit example where explicit calculations can be carried out, along with a sketch of the extension to spin chains.

</details>


### [84] [Phase Estimation with Compressed Controlled Time Evolution](https://arxiv.org/abs/2511.21225)
*Erenay Karacan*

Main category: quant-ph

TL;DR: 本文提出了一种压缩协议，用于将平移不变局部哈密顿量的受控时间演化算子编码为量子电路，实现了近乎最优的电路深度缩放，并将控制开销从乘法因子减少为加法因子。


<details>
  <summary>Details</summary>
Motivation: 许多最优缩放的量子模拟算法使用哈密顿量的受控时间演化，这通常是其高效实现的主要瓶颈。

Method: 建立了一种压缩协议，用于编码平移不变局部哈密顿量的受控时间演化算子到量子电路中。

Result: 该协议实现了近乎最优的电路深度缩放$\mathcal{O}(t \\text{ polylog}(t N/ε))$，在6x6三角晶格上仅需414个CNOT门实现迭代量子相位估计，在4x4三角晶格上使用Quantinuum H2设备的噪声模拟器获得低于1%的基态能量误差。

Conclusion: 该压缩协议显著减少了量子模拟中受控时间演化的实现复杂度，为在噪声量子设备上实现高效量子模拟提供了可行方案。

Abstract: Many optimally scaling quantum simulation algorithms employ controlled time evolution of the Hamiltonian, which is typically the major bottleneck for their efficient implementation. This work establishes a compression protocol for encoding the controlled time evolution operator of translationally invariant, local Hamiltonians into a quantum circuit. It achieves a near-optimal scaling in circuit depth $\mathcal{O}(t \text{ polylog}(t N/ε))$, while reducing the control overhead from a multiplicative to an additive factor. We report that this compression protocol enables the implementation of Iterative Quantum Phase Estimation with as few as 414 CNOT gates for a frustrated quantum spin system on a 6x6 triangular lattice and delivers ground state energy errors below 1% (with $\pm$ 1.5% variation, calculated with a hardware noise aware pipeline) on a 4x4 triangular lattice using the noisy emulator of the Quantinuum H2 trapped ion device.

</details>


### [85] [Cost-effective scalable quantum error mitigation for tiled Ansätze](https://arxiv.org/abs/2511.21236)
*Oskar Graulund Lentz Rasmussen,Erik Kjellgren,Peter Reinholdt,Stephan P. A. Sauer,Sonia Coriani,Karl Michael Ziems,Jacob Kongsted*

Main category: quant-ph

TL;DR: 提出了一种基于tiled Ansätze结构的量子误差缓解技术tiled M0，通过局部性近似将噪声表征的QPU成本指数级降低，在分子基态能量计算中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了降低量子误差缓解技术的计算成本，特别是针对近期量子计算应用中的噪声问题，需要开发更高效的误差缓解方法。

Method: 基于Ansatz-based gate and readout error mitigation方法(M0)，利用tiled Ansätze（如tUPS、QNP、硬件高效电路）的独特结构，应用局部性近似来减少噪声表征的量子处理单元成本。

Result: 在LiH、分子氢、水、丁二烯和苯（4-12量子比特）的分子基态能量计算中，与M0相比几乎没有精度损失，在噪声模拟和量子实验中均表现出良好性能。

Conclusion: tiled M0技术为近期量子计算应用提供了一种成本效益高的误差缓解方案，具有实际应用潜力。

Abstract: We introduce a cost-effective quantum error mitigation technique that builds on the recent Ansatz-based gate and readout error mitigation method (M0). The technique, tiled M0, leverages the unique structure of tiled Ansätze (e.g., tUPS, QNP, hardware-efficient circuits) to apply a locality approximation to M0 that results in an exponential reduction in the QPU cost of the noise characterization. We validate the technique for molecular ground state energy calculations with the tUPS Ansatz on LiH, molecular hydrogen, water, butadiene, and benzene ($4-12$ qubits), demonstrating little to no loss in accuracy compared to M0 in noisy simulations. We also show the performance of the technique in quantum experiments, highlighting its potential use in near-term applications.

</details>


### [86] [The effects of decoherence on Fermi's golden rule](https://arxiv.org/abs/2511.21238)
*Caihong Zheng,Fan Zheng*

Main category: quant-ph

TL;DR: 本文研究了退相干效应对费米黄金法则的影响，通过非绝热分子动力学方法在固定基和绝热基下分别分析，发现短退相干时间会导致显著偏离传统费米黄金法则，并以单层WS2为例研究了电子-声子耦合引起的载流子跃迁。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算和超快载流子动力学的发展，退相干效应在基础研究中变得日益重要。传统的费米黄金法则基于微扰时间依赖薛定谔方程推导，未直接考虑退相干效应，因此需要研究退相干对费米黄金法则的影响。

Method: 使用超越时间依赖薛定谔方程的非绝热分子动力学方法，引入退相干效应，分别在固定基和绝热基下研究退相干对费米黄金法则的影响，并以单层WS2为例，采用第一性原理方法研究电子-声子耦合引起的载流子跃迁中的退相干效应。

Result: 研究发现当退相干时间变短时，固定基和绝热基下的跃迁率都与传统费米黄金法则存在显著偏离。

Conclusion: 退相干效应对费米黄金法则有重要影响，特别是在短退相干时间条件下，传统费米黄金法则需要修正以准确描述量子系统中的跃迁过程。

Abstract: Fermi's golden rule which describes the transition rates between two electronic levels under external stimulations is used ubiquitously in different fields of physics. The original Fermi's golden rule was derived from perturbative time-dependent Schrödinger's equation without the direct contribution by decoherence effect. However, as a result of recent developments of quantum computing and ultra fast carrier dynamics, the decoherence becomes a prominent topic in fundamental research.Here, by using the non-adiabatic molecular dynamics which goes beyond the time-dependent Schrödinger's equation by introducing decoherence, we study the effect of decoherence on Fermi's golden rule for the fixed basis and the adiabatic basis, respectively. We find that when the decoherence time becomes short, there is a significant deviation from the Fermi's golden rule for both bases. By using monolayer $\mathrm{WS_2}$ as an example, we investigate the decoherence effect in the carrier transitions induced by the electron-phonon coupling with first-principle method.

</details>


### [87] [Finite-key security analysis of the decoy-state BB84 QKD with passive measurement](https://arxiv.org/abs/2511.21253)
*Akihiro Mizutani,Shun Kawakami,Go Kato*

Main category: quant-ph

TL;DR: 本文提出了一个简单的分析性有限密钥安全证明，用于被动基选择的诱饵态BB84量子密钥分发协议，并给出了可直接用实验参数评估的闭式密钥率公式。


<details>
  <summary>Details</summary>
Motivation: 虽然被动基选择在接收端具有减少随机数生成器需求和消除光学调制器需求的优势，但针对具有偏置概率的被动基选择的诱饵态BB84协议的有限密钥分析安全证明一直缺乏。

Method: 提出了一个简单的分析性有限密钥安全证明方法，推导出闭式密钥率公式，该公式可以直接使用实验可访问的参数进行评估。

Result: 数值模拟显示被动和主动测量实现的密钥率几乎相同，表明被动测量在实际QKD系统中不会影响密钥生成效率。

Conclusion: 被动基选择的诱饵态BB84协议在保持密钥生成效率的同时，提供了简化的硬件实现方案。

Abstract: The decoy-state Bennett-Brassard 1984 (BB84) quantum key distribution (QKD) protocol is widely regarded as the de facto standard for practical implementations. On the receiver side, passive basis choice is attractive because it significantly reduces the need for random number generators and eliminates the need for optical modulators. Despite these advantages, a finite-key analytical security proof for the decoy-state BB84 protocol, where the basis is chosen passively with a biased probability, has been lacking. In this work, we present a simple analytical finite-key security proof for this setting, yielding a closed-form secret-key rate formula that can be directly evaluated using experimentally accessible parameters. Numerical simulations show that the key rates of passiveand active-measurement implementations are nearly identical, indicating that passive measurement does not compromise key-generation efficiency in practical QKD systems.

</details>


### [88] [Large-scale portfolio optimization using Pauli Correlation Encoding](https://arxiv.org/abs/2511.21305)
*Vicente P. Soloviev,Michal Krompiec*

Main category: quant-ph

TL;DR: 本文提出了一种基于门电路的变分量子算法，通过将多个变量分配给单个量子比特来解决现实世界的投资组合优化问题，突破了传统量子方法中量子比特与变量一对一对应的限制。


<details>
  <summary>Details</summary>
Motivation: 传统量子方法假设量子比特与变量一对一对应，这严重限制了门电路量子系统在当前硬件约束下的适用性。本文旨在探索如何将门电路变分量子算法应用于现实世界的投资组合优化问题。

Method: 采用门电路变分量子算法，将多个变量分配给单个量子比特，通过迭代地将代表真实股票市场的市场图划分为高度相关资产的子投资组合，解决了涉及250多个变量的投资组合优化问题。

Result: 该方法相比传统变分方法具有更好的可扩展性，为量子增强的金融应用开辟了新的可能性。

Conclusion: 通过将多个变量分配给单个量子比特的方法，门电路变分量子算法可以成功应用于现实世界的投资组合优化问题，突破了当前量子硬件的限制。

Abstract: Portfolio optimization is a cornerstone of financial decision-making, traditionally relying on classical algorithms to balance risk and return. Recent advances in quantum computing offer a promising alternative, leveraging quantum algorithms to efficiently explore complex solution spaces and potentially outperform classical methods in high-dimensional settings. However, conventional quantum approaches typically assume a one-to-one correspondence between qubits and variables (e.g. financial assets), which severely limits the applicability of gate-based quantum systems due to current hardware constraints. As a result, only quantum annealing-like methods have been used in realistic scenarios. In this work, we show how a gate-based variational quantum algorithm can be applied to a real-world portfolio optimization problem by assigning multiple variables per qubit. Specifically, we address a problem involving over 250 variables, where the market graph representing a real stock market is iteratively partitioned into sub-portfolios of highly correlated assets. This approach enables improved scalability compared to traditional variational methods and opens new possibilities for quantum-enhanced financial applications.

</details>


### [89] [Deriving the Generalised Born Rule from First Principles](https://arxiv.org/abs/2511.21355)
*Gaurang Agrawal,Matt Wilson*

Main category: quant-ph

TL;DR: 本文探讨了广义玻恩规则是否可以从基本原理推导出来，而不是作为基本假设。作者通过过程理论的方法，展示了任何满足基本兼容性公理的过程理论都等价于满足广义玻恩规则的理论，并研究了噪声引入对概率与标量关系的影响。


<details>
  <summary>Details</summary>
Motivation: 现代组合物理理论的基本假设是广义玻恩规则，该规则假设概率可以从状态和效应的组合中计算得出。本文旨在探讨这一假设及其对概率与标量之间关系的识别是否可以从基本原理中论证，而不是作为基本假设。

Method: 作者首先考虑教科书量子理论的最朴素过程理论解释，其中物理过程（酉算子）、状态和效应（ket和bra）以及满足基本兼容性公理的概率函数被识别。然后证明任何配备这种结构的过程理论都等价于满足广义玻恩规则的替代过程理论。最后考虑在任意此类理论中引入噪声的影响。

Result: 研究发现，任何满足基本兼容性公理的过程理论都等价于满足广义玻恩规则的理论。当引入噪声时，标量与概率之间的识别关系得到加强：从单纯的幺半群同态转变为半环同构。

Conclusion: 广义玻恩规则可以从基本原理推导出来，而不需要作为基本假设。噪声的引入进一步强化了标量与概率之间的识别关系，表明这种识别在过程理论框架中具有深刻的数学基础。

Abstract: A basic postulate of modern compositional approaches to generalised physical theories is the generalised Born rule, in which probabilities are postulated to be computable from the composition of states and effects. In this paper we consider whether this postulate, and the strength of the identification between scalars and probabilities, can be argued from basic principles. To this end, we first consider the most naive possible process-theoretic interpretation of textbook quantum theory, in which physical processes (unitaries) along with states and effects (kets and bras) and a probability function from states and effects satisfying just some basic compatibility axioms are identified. We then show that any process theory equipped with such structure is equivalent to an alternative process theory in which the generalised Born rule holds. We proceed to consider introduction of noise into any such theory, and observe that the result of doing so is a strengthening of the identification between scalars and probabilities; from bare monoid homomorphisms to semiring isomorphisms.

</details>


### [90] [Excited core-level dependence of entanglement between a photoelectron and an emitted X-ray photon in X-ray inner-shell excitation](https://arxiv.org/abs/2511.21373)
*Ryo B. Tanaka,Goro Oohata,Takayuki Uozumi*

Main category: quant-ph

TL;DR: 该研究理论分析了光电子自旋与X射线光子偏振之间的量子纠缠如何依赖于激发核能级，通过比较Ti2O3型系统的3d→2p和3d→3p SPR-XEPECS过程以及CeF3型系统的4f→4d SPR-XEPECS过程，发现了两种不同的纠缠生成机制。


<details>
  <summary>Details</summary>
Motivation: 研究X射线内壳激发过程中量子纠缠的生成机制，探索不同核能级对光电子自旋与X射线光子偏振之间纠缠的影响。

Method: 使用TiO6团簇模型（包含Ti离子的全多重态结构和Ti 3d与配体O 2p轨道间的电荷转移效应）分析Ti2O3型系统，使用Ce离子的全多重态结构离子模型分析CeF3型系统。

Result: 在3d→2p和4f→4d情况下发现了两种不同的纠缠生成机制：第一种由2p核电子的自旋轨道相互作用产生，第二种由4f价电子的自旋轨道相互作用以及4f与4d电子间的强交换相互作用产生。但在3d→3p情况下，由于晶体场效应，强3d-3p交换相互作用无法产生纠缠。

Conclusion: X射线内壳激发过程中存在两种不同的纠缠生成机制，这些机制依赖于具体的核能级和系统的电子结构特性。

Abstract: We theoretically investigated how the quantum entanglement between the spin of the photoelectron and the polarization of the emitted X-ray photon depends on the excited core-level, using the 3$d\rightarrow\ $2$p$ and 3$d\rightarrow\ $3$p$ SPR-XEPECS (spin- and polarization-resolved XEPECS) processes for $\rm Ti_{2}O_{3}$-type system, and the 4$f\rightarrow\ $4$d$ SPR-XEPECS process for $\rm CeF_{3}$-type system. In the calculation for $\rm Ti_{2}O_{3}$-type system, we used $\rm TiO_{6}$ cluster model with the full-multiplet structure of the Ti ion and the charge-transfer effect between Ti 3$d$ and ligand O 2$p$ orbitals. For $\rm CeF_{3}$-type system, we used ionic model with the full-multiplet structure of the Ce ion. We found two distinct mechanisms for entanglement generation in the 3$d\rightarrow\ $2$p$ and 4$f\rightarrow\ $4$d$ cases. The first is generated by the spin-orbit interaction of the 2$p$ core electron, whereas the second is generated by the spin-orbit interaction of the 4$f$ valence electron and strong exchange interaction between the 4$f$ and 4$d$ electrons. However, in the 3$d\rightarrow\ $3$p$ case with the strong 3$d-$3$p$ exchange interaction, we found that the entanglement is not generated due to the crystal field effect. These results reveal the existence of two distinct mechanisms for entanglement generation in X-ray inner-shell excitation processes.

</details>


### [91] [Phase-Dependent Photon Emission Rates in Quantum Gravity-Induced Entangled States](https://arxiv.org/abs/2511.21392)
*Chi Zhang*

Main category: quant-ph

TL;DR: 本文分析了QGEM方案中产生的纠缠末态的量子特性，发现光子发射率与纠缠度密切相关：在小距离时发射率随纠缠度增加而减小，大距离时趋于与纠缠无关的渐近值，并讨论了利用光子发射率检测量子纠缠的可能性。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠作为量子力学的基本概念，在量子引力研究中具有重要意义。QGEM实验方案旨在基于LOCC理论研究引力的量子效应，需要深入分析该方案中产生的纠缠态的量子特性。

Method: 分析QGEM方案中产生的纠缠末态的量子特性，研究光子发射率（跃迁率）与纠缠度之间的关系，并探讨距离变化对两者关系的影响。

Result: 发现光子发射率与纠缠度密切相关：当粒子对距离较小时，跃迁率随纠缠度增加而减小；随着距离增加，跃迁率逐渐趋近于与纠缠无关的渐近值。

Conclusion: 光子发射率与量子纠缠度存在明确关系，这为利用光子发射率检测量子纠缠提供了理论基础，在量子引力实验研究中有重要应用价值。

Abstract: Quantum entanglement, as one of the fundamental concepts in quantum mechanics, has garnered significant attention over the past few decades for its extraordinary nonlocality. With the advancement of quantum technology, quantum entanglement holds promising application for exploring fundamental physical theories. The experimental scheme of Quantum Gravity Induced Entanglement of Masses (QGEM) was proposed to investigate the quantum effects of gravity based on the Local Operations and Classical Communication (LOCC) theory. In this study, we analyze the quantum properties of the entangled final states generated in the QGEM scheme. Our findings reveal that the photon emission rates (transition rates) are closely related to the degree of entanglement. Specifically, the transition rate decreases as the degree of entanglement increases when the distance between particle pairs is small, then it gradually approaches an asymptotic value that is independent of entanglement as the distance increases. We then discuss the possibility of using photon emission rates to detect quantum entanglement with these results.

</details>


### [92] [Quantum electrodynamic description of the neutral hydrogen molecule ionization](https://arxiv.org/abs/2511.21430)
*Hui-hui Miao*

Main category: quant-ph

TL;DR: 该研究结合量子电动力学和林德布拉德主方程，系统研究了氢分子在封闭、耗散开放和流入驱动开放量子系统中的电离动力学，揭示了系统趋向形成中性氢分子的普遍规律，并发现电离路径对初始量子态高度敏感。


<details>
  <summary>Details</summary>
Motivation: 氢分子作为量子化学的基本基准系统，其电离动力学研究对于理解光-物质相互作用和量子控制化学具有重要意义。研究旨在建立包含耗散过程和外部粒子流入的量子电动力学框架。

Method: 采用量子电动力学与林德布拉德主方程相结合的第一性原理方法，系统研究三种量子系统配置：封闭系统、耗散开放系统和流入驱动开放系统，分析光子、电子和声子的耗散强度等关键控制参数。

Result: 发现系统在所有配置下都趋向形成中性氢分子，光子耗散强度显著加速系统稳定化。粒子流入导致能量重新分布，原子态被显著占据。电离路径对初始量子态高度敏感，在嵌入阳极模型中最大电离概率被轨道杂化限制为3/4。

Conclusion: 该研究为量子控制化学提供了统一的理论基础，对腔量子电动力学和量子信息处理的未来实验具有直接意义。

Abstract: The ionization dynamics of a hydrogen molecule, serving as a fundamental benchmark in quantum chemistry, is investigated within a comprehensive framework combining quantum electrodynamics and the Lindblad master equation. This approach enables a first-principles description of light--matter interactions while accounting for dissipative processes and external particle influx. We systematically explore the system's evolution across three distinct regimes: closed, dissipative open, and influx-driven open quantum systems. Our results reveal a universal tendency towards the formation of the neutral hydrogen molecule ($|\rm{H}_2\rangle$) across all configurations. The dissipation strengths for photons ($γ_Ω$), electrons ($γ_e$), and phonons ($γ_ω$) are identified as critical control parameters, with $γ_Ω$ significantly accelerating system stabilization. Furthermore, the introduction of particle influx ($μ_k$) leads to a complex redistribution of energy, notably populating the atomic state ($|\rm{H},\rm{H}\rangle$). The ionization pathway is exquisitely sensitive to the initial quantum state, dictated by the composition and number of photons, which governs the accessible spin-selective excitation channels. This is conclusively demonstrated in a model with an embedded anode, where the maximum ionization probability is fundamentally constrained to $\frac{3}{4}$ by orbital hybridization. This study provides a unified theoretical foundation for quantum-controlled chemistry, with direct implications for future experiments in cavity QED and quantum information processing.

</details>


### [93] [Quantum Analytical Mechanics: Quantum Mechanics with Hidden Variables](https://arxiv.org/abs/2511.21435)
*Wolfgang Paul*

Main category: quant-ph

TL;DR: 量子分析力学是基于量子系统构型空间中随机轨迹概念对标准量子力学的完善，通过推导构型变量的运动方程来描述测量过程作为动态物理过程。


<details>
  <summary>Details</summary>
Motivation: 解决量子力学中是否存在"隐藏"变量的问题，以及量子力学完备性的认知，通过建立构型变量的运动方程来完善量子力学的数学描述。

Method: 基于构型空间中随机轨迹的概念，推导粒子系统坐标和方向等构型变量的运动方程，将测量过程描述为动态物理过程。

Result: 建立了量子分析力学理论，该理论不是替代希尔伯特空间量子力学，而是作为数学完善，丰富了描述量子现象的工具集。

Conclusion: 量子分析力学为量子力学提供了数学上的完善，通过构型变量的运动方程能够更好地描述实验测量过程，是对标准量子力学的有益补充。

Abstract: The question about the existence of so-called ``hidden'' variables in quantum mechanics and the perception of the completeness of quantum mechanics are two sides of the same coin. Quantum analytical mechanics constitutes a completion of standard quantum mechanics based on the concept of stochastic trajectories in the configuration space of a quantum system. For particle systems, configuration space is made up out of their coordinates and, if relevant, their orientation. Quantum analytical mechanics derives equations of motion for these variables which allow a description of the measurement process as a dynamical physical process. After all, it is exactly these variables experiments are designed to interact with. The theory is not a replacement of Hilbert space quantum mechanics but a mathematical completion enriching our toolset for the description of quantum phenomena.

</details>


### [94] [Magic spreading under unitary Clifford dynamics](https://arxiv.org/abs/2511.21487)
*Mircea Bejan,Pieter W. Claeys,Jiangtian Yao*

Main category: quant-ph

TL;DR: 本文研究了Clifford电路中局部注入的量子魔力的动力学，提出了通过二分魔力规范来推断魔力的空间分布，并定义了两种操作相关的魔力长度尺度，发现它们在早期以不同速度呈弹道增长。


<details>
  <summary>Details</summary>
Motivation: 量子魔力是非稳定性的体现，在量子纠错和计算中是重要资源。然而，由于缺乏量化魔力的物理可观测量，无法直接描述其局部分布和动力学。

Method: 利用稳定子量子纠错码的见解，通过二分魔力规范来严格推断魔力的空间分布，并提出了两种操作相关的魔力长度尺度。

Result: 数值模拟显示，在早期阶段，两种魔力长度尺度以不同的速度呈弹道增长，这些速度由纠缠速度设定，之后魔力会离域化。

Conclusion: 这项工作揭示了多体动力学中量子资源和复杂性的时空结构，为研究其输运性质以及与量子纠错的进一步联系开辟了途径。

Abstract: Nonstabilizerness, or quantum magic, presents a valuable resource in quantum error correction and computation. We study the dynamics of locally injected magic in unitary Clifford circuits, where the total magic is conserved. However, the absence of physical observables quantifying magic precludes a direct microscopic or hydrodynamic description of its local distribution and dynamics. Using insights from stabilizer quantum error correcting codes, we rigorously show that the spatial distribution of magic can be inferred from a canonical representation of low-magic states, dubbed the bipartite magic gauge. Moreover, we propose two operationally relevant magic length scales. We numerically establish that, at early times, both length scales grow ballistically at distinct velocities set by the entanglement velocity, after which magic delocalizes. Our work sheds light on the spatiotemporal structure of quantum resources and complexity in many-body dynamics, opening up avenues for investigating their transport properties and further connections with quantum error correction.

</details>


### [95] [Metastability in the Dissipative Quantum Rabi Model](https://arxiv.org/abs/2511.21508)
*Da-Wu Xiao,Chong Chen*

Main category: quant-ph

TL;DR: 该论文研究了耗散量子拉比模型中超辐射相在弱自旋弛豫下的稳定性，发现即使弱自旋弛豫也会使超辐射相变为超辐射亚稳态，其中对称破缺态仅在有限时间内稳定。


<details>
  <summary>Details</summary>
Motivation: 研究耗散量子拉比模型中超辐射相在存在自旋弛豫时的稳定性，探索非平衡物理中对称破缺态的动力学行为。

Method: 结合平均场和累积展开分析与精确数值模拟，在有限尺寸系统中分析对称破缺态的寿命，并通过有限尺寸标度外推到热力学极限。

Result: 发现自旋弛豫诱导的每次自旋跳跃都会对系统产生强扰动，可能将系统从对称破缺态驱动到对称保持鞍点，导致对称破缺态具有有限寿命，并在稳态中恢复对称性。

Conclusion: 研究结果确立了耗散量子拉比模型中对称破缺态的亚稳态性质，揭示了耗散相变相对于平衡相变的复杂性，这些机制可推广到广泛的开放量子系统中。

Abstract: The dissipative quantum Rabi model exhibits rich non-equilibrium physics, including a dissipative phase transition from the normal phase to the superradiant phase. In this work, we investigate the stability of the superradiant phase in the presence of a weak spin relaxation. We find that even a weak spin relaxation can render the superradiant phase to a superradiant metastable phase, in which symmetry-breaking states are stable only for a finite time. This arises because each spin-jump induced by relaxation applies as a strong perturbation to the system, potentially driving the system from a symmetry-breaking state to the symmetry-preserving saddle point with finite probability, before it eventually relaxes back to a symmetry-breaking state. Such dynamical processes lead to a finite lifetime of the symmetry-breaking states and restore the symmetry in the steady state. To substantiate these results, we combine mean-field and cumulant expansion analyses with exact numerical simulations. The lifetime of the symmetry-breaking states are analyzed in finite-size systems, and the conclusions are extrapolated to the thermodynamic limit via finite-size scaling. Our findings establish the metastable nature of the symmetry-breaking states in the dissipative quantum Rabi model and reveal the complexity of the dissipative phase transition beyond their equilibrium counterpart. The mechanisms uncovered here can be generalized to a broad class of open quantum systems, highlighting fundamental distinctions between equilibrium phase transitions and steady-state phase transitions.

</details>


### [96] [Quantum Latent Gauge and Coherence Selective Forces](https://arxiv.org/abs/2511.21576)
*Ridha Horchani*

Main category: quant-ph

TL;DR: 提出了一种隐藏的U(1)规范相互作用，专门与质量系统中的量子相干性耦合。通过诺特质量流的算子级粗粒化构造了守恒的相干性流算子，该流在经典物质分布中为零，但在空间叠加态和纠缠态中非零。预测了干涉相位偏移、退相干率和纠缠选择性力三个特征信号。


<details>
  <summary>Details</summary>
Motivation: 探索量子相干性选择性的基本相互作用及其在量子-经典转变中的潜在作用，为探测这类相互作用提供新的理论框架。

Method: 构建隐藏的U(1)规范相互作用，通过诺特质量流的算子级粗粒化构造守恒的相干性流算子，该相互作用在经典区域休眠，但被量子相干性激活。

Result: 理论预测了三个独特特征：与条纹可见度线性相关的干涉相位偏移、具有特征m^2标度和空间依赖性的退相干率、以及远距离质量量子比特之间的纠缠选择性力。

Conclusion: 该框架保持了完整的规范不变性、因果性和正时间演化，最先进的原子干涉仪和悬浮纳米粒子可以对这类相互作用施加首次约束，补充了经典第五力搜索。

Abstract: We propose a hidden U(1) gauge interaction that couples exclusively to quantum coherence in massive systems. The central innovation is a conserved coherence current operator constructed from the Noether mass current via operator-level coarse-graining. This current vanishes for classical matter distributions but is nonzero for spatial superpositions and entangled states, yielding a gauge interaction that is dormant in classical regimes but activated by quantum coherence. The framework predicts three distinctive signatures: (i) interferometric phase shifts scaling linearly with fringe visibility, (ii) decoherence rates with characteristic m^2 scaling and spatial dependence distinct from collapse models, and (iii) entanglement-selective forces between distant massive qubits. The theory maintains full gauge invariance, causality, and positive time evolution. We show that state-of-the-art atom interferometers and levitated nanoparticles can place first constraints on this interaction class, complementary to classical fifth-force searches. This approach provides a novel theoretical framework for probing coherence-selective fundamental interactions and their potential role in the quantum-classical transition. To make this more concrete, we also spell out a simple benchmark latent-field model and work out, in detail, how a representative large-momentum-transfer atom interferometer constrains the corresponding coupling strength.

</details>


### [97] [The derivation of the Liouville equation from the Schrodinger equation and its implications](https://arxiv.org/abs/2511.21601)
*A. P. Meilakhs*

Main category: quant-ph

TL;DR: 提出了一种从量子力学推导经典力学的新方法，该方法与推导量子态间跃迁速率的标准方法兼容，并用于推导物理动力学的主要公式。


<details>
  <summary>Details</summary>
Motivation: 开发一种从量子力学严格推导经典力学的方法，避免传统推导中非严格的合理推理，实现从薛定谔方程到玻尔兹曼方程的完整数学推导。

Method: 通过刘维尔方程推导玻尔兹曼方程的非碰撞部分，通过跃迁速率矩阵推导碰撞积分，将薛定谔方程作为单一数学操作推导玻尔兹曼方程。

Result: 成功从薛定谔方程推导出玻尔兹曼方程，实现了从量子力学到经典力学的严格数学推导，无需任何非严格的推理过程。

Conclusion: 该方法提供了一种从量子力学严格推导经典力学的统一框架，证明了玻尔兹曼方程可以从薛定谔方程通过纯数学操作得到，填补了传统推导中的理论空白。

Abstract: We present a new way of deriving classical mechanics from quantum mechanics. A key feature of the method is its compatibility with the standard approach used to derive transition rates between quantum states due to interactions. We apply the developed method to derive the main formulas of physical kinetics. We observe that, through the Liouville equation, we can deduce the non-collision part of the Boltzmann equation, and that, through the matrix of transition rates, we can deduce the collision integral. As a final result of the manuscript, we derive the Boltzmann equation from the Schrödinger equation as a single piece of formal mathematical manipulation, without any non-rigorous plausible reasoning used to glue together its different parts.

</details>


### [98] [Lazy Quantum Walks with Native Multiqubit Gates](https://arxiv.org/abs/2511.21608)
*Steph Foulds,Viv Kendon*

Main category: quant-ph

TL;DR: 本文研究了在里德堡中性原子硬件上实现量子行走的方法，特别关注包含静止状态的'懒惰'量子行走，为流体模拟应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 量子行走作为经典随机行走的量子类比，已被证明能够模拟流体动力学。中性原子硬件因其能够实现原生多量子比特（≥3量子比特）门和动态重排量子比特的能力，成为实现量子行走的有前景平台。

Method: 通过双光子绝热快速通道进行多量子比特里德堡门的误差建模，提出了玩具量子行走的门序列和预测的最终状态保真度，特别关注包含静止状态的'懒惰'量子行走。

Result: 开发了在里德堡中性原子硬件上实现量子行走的具体门序列，并预测了最终状态保真度，成功实现了包含静止状态的'懒惰'量子行走。

Conclusion: 在里德堡中性原子硬件上实现的'懒惰'量子行走为量子行走在流体模拟中的应用提供了重要步骤，展示了该平台在量子模拟方面的潜力。

Abstract: Quantum walks, the quantum analogue to the classical random walk, have been shown to model fluid dynamics. Neutral atom hardware is a promising choice of platform for implementing quantum walks due to its ability to implement native multiqubit ($\geq\!3$-qubit) gates and to dynamically re-arrange qubits. Using error modelling for multiqubit Rydberg gates via two-photon adiabatic rapid passage, we present the gate sequences and predicted final state fidelities for some toy quantum walks, including `lazy' quantum walks. These `lazy' quantum walks include a rest state and therefore provide an integral step towards quantum walks for fluid simulation.

</details>


### [99] [Tunable WS$_2$ Micro-Dome Open Cavity Single Photon Source](https://arxiv.org/abs/2511.21630)
*Jens-Christian Drawer,Salvatore Cianci,Vita Solovyeva,Alexander Steinhoff,Christopher Gies,Falk Eilenberger,Kenji Watanabe,Takashi Taniguchi,Ivan Solovev,Giorgio Pettinari,Federico Tuzi,Elena Blundo,Marco Felici,Antonio Polimeni,Martin Esmann,Christian Schneider*

Main category: quant-ph

TL;DR: 本文实现了一种基于WS2微穹顶的单光子源，通过氢离子辐照制备，并将其集成到可调谐光学微腔中。系统验证了单光子发射，g(2)(0)=0.3，并分析了声子发射边带对非共振耦合的影响。


<details>
  <summary>Details</summary>
Motivation: 开发可调谐、可扩展的单光子源对于新兴光子量子技术至关重要，需要将原子级薄量子发射器与光学微腔集成以增强和调控其发射特性。

Method: 通过氢离子辐照制备WS2微穹顶单光子源，并将其集成到开放式可调谐光学微腔中，进行二阶相关测量和光谱选择性分析。

Result: 实现了单光子发射，g(2)(0)=0.3，观察到明显的声子发射边带对非共振耦合的贡献，展示了腔-发射器控制的高水平。

Conclusion: 开放式腔系统能够有效调控原子级薄量子发射器的发射特性，增强了其在现实量子技术应用中的适用性。

Abstract: Versatile, tunable, and potentially scalable single-photon sources are a key asset in emergent photonic quantum technologies. In this work, a single-photon source based on WS$_2$ micro-domes, created via hydrogen ion irradiation, is realized and integrated into an open, tunable optical microcavity. Single-photon emission from the coupled emitter-cavity system is verified via the second-order correlation measurement, revealing a $g^{(2)}(τ=0)$ value of 0.3. A detailed analysis of the spectrally selective, cavity enhanced emission features shows the impact of a pronounced acoustic phonon emission sideband, which contributes specifically to the non-resonant emitter-cavity coupling in this system. The achieved level of cavity-emitter control highlights the potential of open-cavity systems to tailor the emission properties of atomically thin quantum emitters, advancing their suitability for real-world quantum technology applications.

</details>


### [100] [Factorisation conditions and causality for local measurements in QFT](https://arxiv.org/abs/2511.21644)
*Robin Simmons,Maria Papageorgiou,Marios Christodoulou,Časlav Brukner*

Main category: quant-ph

TL;DR: 本文研究了量子场论中物理可实现的测量标准，通过局部S矩阵形式化和分解条件来排除超光速信号和逆因果性，为量子场论中的测量提供了操作标准。


<details>
  <summary>Details</summary>
Motivation: 量子场论中某些在非相对论量子理论中允许的量子操作会导致类空间隔区域的信号传递（"不可能测量"问题），需要建立相对论协变的物理实现标准。

Method: 采用局部S矩阵形式化，利用层次分解条件排除超光速信号和逆因果性，通过场算符与指针自由度的显式相互作用实现局部S矩阵，推导诱导Kraus算符的局域因果条件。

Result: 建立了物理可实现测量的操作标准，证明了场Kraus算符的分解恒等式，发现局域场可观测量测量精度受场推迟传播子的基本限制。

Conclusion: 为量子场论中的测量提供了明确的物理可实现性标准，解决了"不可能测量"问题，并揭示了场传播子在测量精度中的基本作用。

Abstract: Quantum operations that are perfectly admissible in non-relativistic quantum theory can enable signalling between spacelike separated regions when naively imported into quantum field theory (QFT). Prominent examples of such "impossible measurements", in the sense of Sorkin, include certain unitary kicks and projective measurements. It is generally accepted that only those quantum operations whose physical implementation arises from a fully relativistically covariant interaction, between the quantum field and a suitable probe, should be regarded as admissible. While this idea has been realised at the level of abstract algebraic QFT, or via particular measurement models, there is still no general set of operational criteria characterising which measurements are physically implementable. In this work we adopt the local S-matrix formalism, and make use of a hierarchy of factorisation conditions that exclude both superluminal signalling and retrocausality, thereby providing such a criterion. Realising the local S-matrices through explicit interactions between smeared field operators and a pointer degree of freedom, we further derive local causality conditions for the induced Kraus operators, which guarantee the absence of signalling in "impossible measurement" scenarios. Finally, we show that the accuracy with which local field observables can be measured is fundamentally limited by the retarded propagator of the field, which also plays an essential role in a factorisation identity we prove for the field Kraus operators.

</details>


### [101] [FPGA-tailored algorithms for real-time decoding of quantum LDPC codes](https://arxiv.org/abs/2511.21660)
*Satvik Maurya,Thilo Maurer,Markus Bühler,Drew Vandeth,Michael E. Beverland*

Main category: quant-ph

TL;DR: 本文分析了三种针对FPGA优化的量子LDPC码解码器：消息传递、有序统计和聚类方法，发现消息传递方法在实时解码性能上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 实时解码对容错量子计算至关重要，但需要专门的硬件如FPGA，其并行性会改变算法性能的相对表现，因此需要分析FPGA优化的解码器性能。

Method: 分析了三种FPGA优化的解码器：消息传递（Relay解码器）、有序统计（引入过滤变体）和聚类（FPGA适配的广义联合查找解码器），并设计了用于秩亏系统高斯消除的脉动算法。

Result: 尽管对有序统计和聚类方法进行了改进，但它们在速度和准确性上仍远不如Relay解码器。

Conclusion: 消息传递是实现实时qLDPC解码的最可行途径。

Abstract: Real-time decoding is crucial for fault-tolerant quantum computing but likely requires specialized hardware such as field-programmable gate arrays (FPGAs), whose parallelism can alter relative algorithmic performance. We analyze FPGA-tailored versions of three decoder classes for quantum low-density parity-check (qLDPC) codes: message passing, ordered statistics, and clustering. For message passing, we analyze the recently introduced Relay decoder and its FPGA implementation; for ordered statistics decoding (OSD), we introduce a filtered variant that concentrates computation on high-likelihood fault locations; and for clustering, we design an FPGA-adapted generalized union-find decoder. We design a systolic algorithm for Gaussian elimination on rank-deficient systems that runs in linear parallel time, enabling fast validity checks and local corrections in clustering and eliminating costly full-rank inversion in filtered-OSD. Despite these improvements, both remain far slower and less accurate than Relay, suggesting message passing is the most viable route to real-time qLDPC decoding.

</details>


### [102] [Finite Size Analysis of Decoy-State BB84 with Advantage Distillation](https://arxiv.org/abs/2511.21665)
*Jonas Treplin,Philipp Kleinpaß,Davide Orsucci*

Main category: quant-ph

TL;DR: 本文首次对通过优势蒸馏(AD)增强的诱骗态BB84协议进行了全面的有限密钥长度分析，证明AD可以将最大可接受量子比特错误率从9.5%提升到17.3%，显著扩展量子密钥分发的安全距离。


<details>
  <summary>Details</summary>
Motivation: 优势蒸馏是一种经典的后处理技术，能够提高量子密钥分发协议的最大可接受量子比特错误率，从而延长QKD链路的可安全建立距离。本研究旨在分析AD在有限密钥长度下的实际性能提升。

Method: 对诱骗态BB84协议通过优势蒸馏进行后处理，通过选择比特块并提取更少但保真度更高的比特来降低量子比特错误率，从而减少信息协调步骤中需要披露的信息量。

Result: 使用优势蒸馏后，在现实密钥长度下，最大可接受量子比特错误率从约9.5%增加到约17.3%，表明仅通过改进后处理方法就能在受限于最大可容忍QBER的场景中实现显著的性能提升。

Conclusion: 优势蒸馏后处理技术能够显著提高量子密钥分发协议的性能，在有限密钥长度下将最大可接受量子比特错误率提高近一倍，为受QBER限制的QKD应用场景提供了有效的解决方案。

Abstract: Advantage Distillation (AD) is a classical post-processing technique that enhances Quantum Key Distribution (QKD) protocols by increasing the maximum acceptable Quantum Bit Error Rate (QBER) and thus extending the distance at which QKD links can be securely established. AD operates by post-selecting blocks of bits and extracting fewer high-fidelity bits, exhibiting a reduced QBER and thus lowering the amount of information that has to be disclosed during the information reconciliation step. In this work we present the first comprehensive finite key-size analysis of decoy-state BB84 enhanced via AD post-processing. We demonstrate that through the use of AD the maximum acceptable QBER increases from around $9.5\%$ to around $17.3\%$ for realistic key sizes. This result shows that substantial performance enhancements can be achieved in scenarios which are constrained by the maximum tolerable QBER via improvements of the post-processing method alone.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [103] [Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring](https://arxiv.org/abs/2511.20679)
*Melika Ayoughi,Pascal Mettes,Paul Groth*

Main category: cs.AI

TL;DR: 本文研究使用大型语言模型自动重构层次结构以优化双曲嵌入质量，提出基于提示的方法来转换现有层次结构，实验证明LLM重构的层次结构在多个标准嵌入质量指标上表现更好。


<details>
  <summary>Details</summary>
Motivation: 双曲嵌入的质量与输入层次结构紧密相关，而最佳双曲嵌入需要高分支因子和单继承。为了帮助知识工程师重新组织层次知识，研究LLMs是否能够自动重构层次结构以满足这些标准。

Method: 提出基于提示的方法，使用大型语言模型在已知双曲嵌入期望标准的指导下转换现有层次结构。

Result: 在16个不同层次结构上的实验表明，LLM重构的层次结构在多个标准嵌入质量指标上始终产生更高质量的双曲嵌入。

Conclusion: LLM引导的层次结构重构能够实现可解释的重组，为知识工程师提供理由，并显著提高双曲嵌入质量。

Abstract: Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.

</details>


### [104] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: 本文介绍了AssurAI，一个针对韩语多模态生成AI安全评估的质量控制数据集，包含11,480个实例，涵盖文本、图像、视频和音频，旨在解决当前安全数据集主要局限于英语和单模态的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的安全数据集主要是英语中心的，无法捕捉非英语社会文化背景（如韩语）中的特定风险，且通常仅限于文本模态，这促使开发一个专门针对韩语多模态的安全评估数据集。

Method: 首先定义了一个包含35个不同AI风险因素的分类法，通过多学科专家组从现有框架中调整而来；其次构建了AssurAI数据集，采用两阶段构建（专家引导的种子和众包扩展）、三重独立标注和迭代专家红队循环的质量控制过程。

Result: 构建了包含11,480个实例的大规模韩语多模态数据集，初步研究验证了AssurAI在评估最新LLMs安全性方面的有效性。

Conclusion: AssurAI数据集公开发布，以促进为韩国社区开发更安全可靠的生成AI系统，填补了非英语多模态安全评估的空白。

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [105] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: A²Flow是一个完全自动化的智能体工作流生成框架，通过自适应的抽象操作符实现无需手动预定义的工作流构建。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖手动预定义的操作符，限制了泛化能力和可扩展性，需要开发完全自动化的智能体工作流生成方法。

Method: 采用三阶段操作符提取过程：基于案例的初始操作符生成、操作符聚类和初步抽象、深度提取抽象执行操作符，并结合操作符记忆机制增强工作流搜索。

Result: 在通用和具身基准测试中，A²Flow相比最先进基线平均性能提升2.4%和19.3%，资源使用减少37%。

Conclusion: A²Flow通过完全自动化的操作符提取和工作流构建，显著提升了智能体工作流的性能和效率，为自动化智能体设计提供了有效解决方案。

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [106] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 提出了一个用于太阳物理推理的数据集Reasoning With a Star，并建立了基准测试方法，发现基于系统工程原则的多智能体工作流在需要演绎推理的问题上优于直接提示。


<details>
  <summary>Details</summary>
Motivation: 解决太阳物理领域大语言模型科学推理的挑战，包括整合物理假设、保持单位一致性和提供清晰科学格式。

Method: 构建了基于NASA和UCAR Living With a Star暑期学校问题集的数据集，包含问题上下文、推理步骤、答案类型等结构化信息；使用程序化评分器进行单位感知数值容差、符号等价性和模式验证；比较了单次提示和四种多智能体模式的性能。

Result: 通过系统工程原则分解工作流的多智能体模式在需要演绎推理的问题上表现优于直接提示方法。

Conclusion: 在太阳物理推理任务中，采用系统工程方法的多智能体工作流能够有效提升需要演绎推理的问题解决能力。

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [107] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 数字孪生技术从NASA航天器模拟发展而来，现已在医疗领域实现转型应用，通过整合影像、生物传感器和计算模型创建患者特异性虚拟副本，支持诊断、治疗规划和药物开发，但仍面临互操作性、数据隐私和模型保真度等挑战。


<details>
  <summary>Details</summary>
Motivation: 推动医疗从被动治疗向预测性、预防性和个性化医学转变，利用数字孪生技术提高医疗决策的精确性和效率。

Method: 整合医学影像、生物传感器和计算模型，创建动态数据驱动的患者特异性虚拟副本，通过实时数据流持续更新并支持双向交互。

Result: 已开发出心脏数字孪生预测心律失常治疗结果、肿瘤学数字孪生追踪肿瘤进展和优化放疗、药理学数字孪生加速药物发现等代表性应用。

Conclusion: 数字孪生技术有望彻底改变医疗模式，但需解决互操作性、数据隐私和模型保真度等挑战，并通过可解释AI、联邦学习和统一监管框架等新兴解决方案推动临床整合。

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [108] [Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework](https://arxiv.org/abs/2511.20701)
*Nitya Tiwari,Parv Maheshwari,Vidisha Agarwal*

Main category: cs.AI

TL;DR: 本文对多模态思维链（Multimodal-CoT）推理进行了全面分析，评估其在A-OKVQA、OKVQA和ChartQA数据集上的有效性，发现虽然视觉集成能减少幻觉，但CoT推理效果在不同问题类型间差异显著。


<details>
  <summary>Details</summary>
Motivation: 虽然CoT已在多模态设置中扩展到科学问答基准，但其在不同领域的泛化能力尚未充分探索。本研究旨在评估多模态CoT在需要广泛常识和世界知识的跨领域推理任务中的有效性。

Method: 采用Zhang等人提出的两阶段框架，将理由生成与答案推理分离，通过门控融合机制将视觉特征与基于T5的语言模型集成，并进行系统消融研究分析视觉特征、理由质量和架构选择的贡献。

Result: 视觉集成显著减少了理由生成中的幻觉，但CoT推理的有效性在不同问题类型间差异很大，常识推理尤其具有挑战性。

Conclusion: 本研究为实施多模态推理系统的研究人员提供了实用见解，并确定了跨领域泛化未来改进的关键领域。

Abstract: While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.

</details>


### [109] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE是一种在表示空间进行干预的知识控制方法，能够在无需重新训练的情况下高效更新LLMs的知识，支持大规模编辑且保持模型通用能力


<details>
  <summary>Details</summary>
Motivation: 解决LLMs产生错误或过时内容的问题，在终身学习设置下实现高效准确的知识更新，避免昂贵的重新训练

Method: 在模型表示空间进行干预，学习抗释义和编辑局部化的模块，将每个更新限制在低维子空间以减少交叉干扰，推理时使用查询自适应路由器选择合适模块

Result: 在LLaMA和Qwen模型的知识编辑基准测试中，RILKE可扩展到大规模数据集，展示出高编辑成功率、强释义泛化能力，并以适度的内存开销保持通用效用

Conclusion: RILKE是LLMs终身知识控制的有效且可扩展解决方案

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [110] [ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction](https://arxiv.org/abs/2511.20937)
*Qineng Wang,Wenlong Huang,Yu Zhou,Hang Yin,Tianwei Bao,Jianwen Lyu,Weiyu Liu,Ruohan Zhang,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: ENACT是一个评估具身认知的基准测试，通过视觉问答形式评估模型从自我中心交互中建模世界的能力，包含前向世界建模和逆向世界建模两个任务。


<details>
  <summary>Details</summary>
Motivation: 探索现代视觉语言模型是否表现出具身认知的迹象，因为具身认知认为智能源于感觉运动交互而非被动观察。

Method: 将具身认知评估构建为部分可观察马尔可夫决策过程，使用机器人仿真数据生成QA对，包含前向世界建模（给定动作重排观察序列）和逆向世界建模（给定观察重排动作序列）两个任务。

Result: 实验显示前沿视觉语言模型与人类之间存在性能差距，且差距随交互时间跨度增加而扩大；模型在逆向任务上表现更好，并表现出人类中心偏见。

Conclusion: 现代视觉语言模型在具身认知能力上仍与人类存在差距，特别是在长时程交互和偏离人类视觉特性的情况下表现更差。

Abstract: Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.

</details>


### [111] [Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture](https://arxiv.org/abs/2511.20942)
*Rahul Dass,Thomas Bowlin,Zebing Li,Xiao Jin,Ashok Goel*

Main category: cs.AI

TL;DR: Ivy是一个结合符号TMK模型和生成式LLM的AI教练系统，通过结构化约束提升程序技能学习中的解释质量，在"如何"和"为什么"问题上显著优于GPT基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在程序技能学习中产生的解释虽然流畅但缺乏深度结构，无法传达步骤背后的因果、目标和组合逻辑。

Method: 结合符号Task-Method-Knowledge(TMK)模型与生成式解释层，TMK编码因果转换、目标层次和问题分解，在明确结构边界内约束LLM生成解释。

Result: 与GPT和检索增强GPT基线相比，符号约束持续提升了"如何"和"为什么"问题解释的结构质量，在三个推理维度上获得专家和独立标注者的认可。

Conclusion: 该研究展示了一种可扩展的AI教育方法，通过符号约束增强AI生成解释在教学教练系统中的教育价值。

Abstract: In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for "how" and "why" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.

</details>


### [112] [ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning](https://arxiv.org/abs/2511.21005)
*Jinpeng Wang,Chao Li,Ting Ye,Mengyuan Zhang,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: 本文提出了一种名为ICPO的新方法，通过结合语言模型生成概率的内在置信度和可验证奖励，解决了现有RLVR方法中存在的奖励粒度粗、奖励噪声和探索效率低等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习与可验证奖励方法存在奖励粒度粗、奖励噪声和探索效率低等问题，导致训练不稳定和熵崩溃，需要一种更有效的方法来提升语言模型的推理能力。

Method: 提出ICPO方法，通过计算多个响应在同一输入提示下的相对生成概率来获得偏好优势分数，并将该分数与可验证奖励结合来指导探索过程。

Result: 在四个通用领域基准和三个数学基准上的综合实验表明，ICPO相比GRPO能够稳定提升推理能力。

Conclusion: ICPO方法通过偏好优势分数有效缓解了奖励粒度和噪声问题，抑制了过度自信错误，增强了被低估高质量响应的相对优势，并防止模型过度拟合特定策略，从而促进更彻底的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.

</details>


### [113] [Causality Without Causal Models](https://arxiv.org/abs/2511.21260)
*Joseph Y. Halpern,Rafael Pass*

Main category: cs.AI

TL;DR: 本文提出了Halpern-Pearl因果定义的抽象版本，使其能够应用于更广泛的模型，包括处理复杂逻辑公式和嵌套反事实的情况。


<details>
  <summary>Details</summary>
Motivation: Halpern-Pearl的因果定义局限于因果模型，无法处理包含析取、否定、信念和嵌套反事实的复杂公式。本文旨在抽象该定义，使其适用于任何定义反事实的模型。

Method: 通过提取Halpern-Pearl因果定义的关键特征，构建了一个抽象定义框架，该框架可以应用于各种模型类型，包括允许回溯的模型。

Result: 新定义不仅扩展了应用范围，还能处理Halpern-Pearl定义无法处理的复杂逻辑公式，并进一步扩展到解释的抽象定义。

Conclusion: 抽象化Halpern-Pearl因果定义带来了多重好处：更广泛的应用范围、处理复杂逻辑的能力、扩展到解释概念，以及对原始定义特征的更深理解。

Abstract: Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.

</details>


### [114] [New Hybrid Heuristics for Pseudo-Boolean Propagation](https://arxiv.org/abs/2511.21417)
*Mia Müßig,Jan Johannsen*

Main category: cs.AI

TL;DR: 本文提出了新的启发式方法，用于改进伪布尔求解器中混合单元传播策略的决策过程，显著提升了RoundingSAT求解器的性能。


<details>
  <summary>Details</summary>
Motivation: 当前伪布尔求解中最成功的单元传播策略是观察文字方案与计数方法的混合模式，但需要更好的启发式方法来决定何时使用哪种策略。

Method: 提出了新的启发式方法，用于在混合单元传播策略中做出更有效的决策选择。

Result: 新启发式方法能够显著优于当前方法，在RoundingSAT求解器中实现了性能的大幅提升。

Conclusion: 新提出的启发式方法有效改进了伪布尔求解器中混合单元传播策略的决策质量，为求解器性能带来了显著提升。

Abstract: In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.

</details>


### [115] [SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition](https://arxiv.org/abs/2511.21471)
*Peiran Xu,Sudong Wang,Yao Zhu,Jianing Li,Yunjian Zhang*

Main category: cs.AI

TL;DR: 提出了一个层次化空间认知框架，将空间智能分解为五个渐进复杂层次，并构建了SpatialBench基准来系统评估多模态大语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准过度简化空间认知，将其简化为单一维度指标，无法捕捉空间能力的层次结构和相互依赖性。

Method: 构建了包含15个任务的SpatialBench基准，引入高层次能力导向的统一评估指标，对大量MLLM进行广泛实验。

Result: 模型在感知层面表现良好，但在符号推理、因果推断和规划方面存在局限；人类进行选择性目标导向抽象，而MLLM倾向于过度关注表面细节。

Conclusion: 建立了首个系统化测量MLLM层次化空间认知的框架，为未来空间智能系统奠定了基础。

Abstract: Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.

</details>


### [116] [Pessimistic Verification for Open Ended Math Questions](https://arxiv.org/abs/2511.21522)
*Yanxing Huang,Zihan Tang,Zejin Lin,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 提出悲观验证方法，通过并行多个验证流程来检测数学证明中的错误，显著提升验证性能且计算资源消耗低。


<details>
  <summary>Details</summary>
Motivation: 现有验证性能的关键限制在于错误检测能力，需要改进开放数学问题的验证方法。

Method: 设计悲观验证的多种变体，为同一证明构建多个并行验证流程，只要任一验证报告错误即判定证明不正确。

Result: 该方法在多个数学验证基准测试中显著提升性能，计算资源消耗少，token效率甚至超过扩展的长链思维测试时缩放。

Conclusion: 悲观验证研究有助于增强语言模型在广泛数学任务中的能力，自我验证能有效提高语言模型输出的可靠性和性能。

Abstract: The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.

</details>


### [117] [Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit](https://arxiv.org/abs/2511.21569)
*Alex Diep*

Main category: cs.AI

TL;DR: 该研究审计了16个开放权重模型在专业角色下的AI身份披露能力，发现模型在不同领域存在显著的透明度不一致，某些模型的身份披露率从2.8%到73.6%不等，且推理优化可能抑制透明度。


<details>
  <summary>Details</summary>
Motivation: 在专业高风险领域中，如果语言模型不能可靠地披露其AI身份，用户就无法信任其能力边界，这可能导致用户受到虚假专业知识的伤害。

Method: 采用共同花园设计，对16个开放权重模型（4B-671B参数）进行了19,200次试验，使用贝叶斯验证和Rogan-Gladen校正来确保测量误差的稳健性。

Result: 模型表现出明显的领域特定不一致性：金融顾问角色初始披露率为30.8%，而神经外科医生角色仅为3.5%。模型身份比参数数量更能预测行为，推理优化的变体显示披露率比基础模型低达48.4%。

Conclusion: 透明度反映的是训练因素而非规模，组织不能假设安全属性会转移到部署环境，需要刻意设计行为和实证验证。

Abstract: If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a "Reverse Gell-Mann Amnesia" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($ΔR_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($κ= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.

</details>


### [118] [From Prediction to Foresight: The Role of AI in Designing Responsible Futures](https://arxiv.org/abs/2511.21570)
*Maria Perez-Ortiz*

Main category: cs.AI

TL;DR: 本文提出了"负责任计算前瞻"概念，探讨人工智能在负责任前瞻中的作用，强调AI作为支持工具增强而非替代决策者判断，以应对21世纪重大挑战。


<details>
  <summary>Details</summary>
Motivation: 在技术快速发展和全球挑战复杂的时代，负责任前瞻成为政策制定者应对未来不确定性和塑造未来的重要框架，需要将AI与前瞻实践相结合。

Method: 建立负责任计算前瞻的基础原则，提出一套AI驱动的前瞻工具，结合模拟和情景分析来增强政策制定者应对不确定性和评估风险的能力。

Result: AI与模拟和情景分析结合，能够提升政策制定者应对不确定性、评估风险和制定可持续、有韧性未来战略的能力。

Conclusion: AI将在负责任、以人为本的前瞻中发挥支持性工具作用，补充而非替代政策制定者的判断，促进积极主动地塑造有韧性和道德健全的未来。

Abstract: In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term "responsible computational foresight", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.

</details>


### [119] [On the Limits of Innate Planning in Large Language Models](https://arxiv.org/abs/2511.21591)
*Charles Schepanowski,Charles Ling*

Main category: cs.AI

TL;DR: 研究评估大型语言模型在8拼图任务中的规划和状态推理能力，发现即使有反馈和验证器辅助，模型仍存在内部状态表示脆弱和启发式规划能力弱的问题。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在许多基准测试中表现优异，但其规划和状态推理能力尚不明确，需要直接评估这些核心能力。

Method: 使用8拼图任务测试四种模型，采用零样本、思维链和算法思维等提示方法，并引入分层纠正反馈和外部移动验证器。

Result: 反馈对某些模型-提示组合有改善，但成功运行通常冗长且计算昂贵。即使有移动验证器辅助，所有模型都无法解决任何拼图。

Conclusion: 当前LLMs在规划方面存在显著限制，需要开发维护显式状态和执行结构化搜索的机制。

Abstract: Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.

</details>


### [120] [Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling](https://arxiv.org/abs/2511.21636)
*Peter S. Hovmand,Kari O'Donnell,Callie Ogland-Hand,Brian Biroscak,Douglas D. Gunzler*

Main category: cs.AI

TL;DR: 本文提出了一个将系统动力学和结构方程建模结合到统一数学框架中的方法，用于支持负责任AI/ML的发展，解决不同方法间基础假设差异的障碍。


<details>
  <summary>Details</summary>
Motivation: AI/ML模型在解决新问题的同时放大了人类偏见，负责任AI/ML倡导者希望利用更丰富的系统动力学因果模型来指导开发，但不同方法的基础假设差异构成了主要障碍。

Method: 将系统动力学和结构方程建模整合到一个共同的数学框架中，能够从分布生成系统、开发方法并比较结果。

Result: 建立了一个统一的数学框架，为数据科学和AI/ML应用中的系统动力学认识论提供信息支持。

Conclusion: 通过整合系统动力学和结构方程建模，为负责任AI/ML的发展提供了理论基础和方法支持，有助于解决不同方法间的兼容性问题。

Abstract: AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's "the unavoidable a priori"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.

</details>


### [121] [Agentic Learner with Grow-and-Refine Multimodal Semantic Memory](https://arxiv.org/abs/2511.21678)
*Weihao Bo,Shan Zhang,Yanpeng Sun,Jingjing Wu,Qunyi Xie,Xiao Tan,Kunbin Chen,Wei He,Xiaofan Li,Na Zhao,Jingdong Wang,Zechao Li*

Main category: cs.AI

TL;DR: ViLoMem是一个双流记忆框架，通过分别编码视觉分心模式和逻辑推理错误，让MLLMs能够从成功和失败经验中学习，提高多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于轨迹的记忆方法存在简洁性偏差，逐渐丢失关键领域知识，且只记录单模态行为轨迹，无法保留视觉注意和逻辑推理如何共同贡献于解决方案，这与人类多模态整合的语义记忆不匹配。

Method: 引入ViLoMem双流记忆框架，分别编码视觉分心模式和逻辑推理错误，采用增长-精炼原则增量积累和更新多模态语义知识，保持稳定可泛化策略同时避免灾难性遗忘。

Result: 在六个多模态基准测试中，ViLoMem持续提高pass@1准确率，显著减少重复的视觉和逻辑错误。消融实验证实了双流记忆和显式分心-幻觉分离的必要性。

Conclusion: 错误感知的多模态记忆对于终身和跨领域智能学习具有重要价值，ViLoMem展示了这种方法的有效性。

Abstract: MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [122] [Strong-coupling theory of bilayer plasmon excitations](https://arxiv.org/abs/2511.20776)
*Hiroyuki Yamase,Luciano Zinni,Matías Bejas,Andrés Greco*

Main category: cond-mat.str-el

TL;DR: 本文提出了一种强耦合理论来分析双层系统的电荷动力学，使用包含长程库仑相互作用的t-J-V模型。虽然理论框架与弱耦合方法不同，但得到的等离子体激发与弱耦合理论相似，主要区别在于强耦合框架下粒子-空穴激发明显被抑制，使等离子体模式在更宽的动量范围内保持良好定义。


<details>
  <summary>Details</summary>
Motivation: 虽然双层晶格系统中的等离子体激发在弱耦合体系中已被广泛研究，但应用于铜酸盐时需要考虑强关联效应，而对此尚未进行全面的分析。

Method: 使用包含长程库仑相互作用V的t-J-V模型，在晶格上建立强耦合理论来分析双层系统的电荷动力学。

Result: 得到的等离子体激发与弱耦合理论相似，但强耦合框架下粒子-空穴激发明显被抑制，使等离子体模式在更宽的动量范围内保持良好定义。

Conclusion: 实验报道的Y基铜酸盐中的等离子体激发可以用ω-模式描述，但需要更系统的实验来验证这一结论。

Abstract: Recently plasmon excitations in bilayer lattice systems were studied extensively in the weak-coupling regime. Unlike single-layer systems, these bilayers exhibit two distinct modes, $ω_{\pm}$, which show characteristic dependences upon the momentum and hopping integrals along the $z$ direction. To apply them to cuprates, strong correlation effects should be considered, but a comprehensive analysis has not yet been investigated. In this work, we present a strong-coupling theory to analyze the charge dynamics of a bilayer system, utilizing the $t$-$J$-$V$ model, which includes the long-range Coulomb interaction, $V$, on a lattice. Although our theoretical framework is fundamentally different from the weak-coupling approach, we find that resulting plasmon excitations are similar to those of a weak-coupling theory. A key distinction is that our strong-coupling framework reveals a noticeable suppression of particle-hole excitations, which allows the plasmon modes to remain well-defined over a wider region of momentum. We suggest that the experimentally reported plasmon excitations in Y-based cuprates can be described by the $ω_{-}$ mode, although we call for more systematic experiments to verify this.

</details>


### [123] [Hund-projected Kanamori model: an effective description of Hund's metals near the Mott insulating regime](https://arxiv.org/abs/2511.20788)
*Johan Carlström*

Main category: cond-mat.str-el

TL;DR: 本文推导了在强Hund耦合条件下多轨道系统的有效低能描述，提出了Hund投影Kanamori模型，揭示了载流子运动与磁关联的相互作用机制。


<details>
  <summary>Details</summary>
Motivation: Hund耦合在多轨道系统中对电子关联起着决定性作用，但现有模型难以准确描述Hund金属中局域矩物理与金属输运的结合机制。

Method: 从多轨道Hubbard-Kanamori哈密顿量出发，投影到Hund第一规则偏好的高自旋流形，得到Hund投影Kanamori模型。

Result: 未掺杂时模型简化为自旋N/2海森堡系统；掺杂后载流子运动通过Hund增强的动力学机制驱动铁磁关联，比Nagaoka铁磁性更强。

Conclusion: 该框架建立了Kanamori模型与Hund金属中涌现的磁性和输运现象之间的微观桥梁，为研究准粒子结构和载流子间有效相互作用提供了新方法。

Abstract: Hund's coupling plays a decisive role in shaping electron correlations of multi-orbital systems, giving rise to a class of materials--Hund's metals--that combine local-moment physics with metallic transport. Here we derive an effective low-energy description of such a system near the Mott insulating regime, starting from the multi-orbital Hubbard-Kanamori Hamiltonian and projecting onto the high-spin manifold favored by Hund's first rule. The resulting Hund-projected Kanamori model captures the interplay between carrier motion and magnetic correlations in the presence of strong Hund's coupling. In the undoped limit, the model reduces to a spin-$N/2$ Heisenberg system with suppressed quantum fluctuations, approaching the classical limit for realistic five-band configurations. Upon doping, carrier motion couples strongly to the spin background and drives ferromagnetic correlations through a Hund-enhanced kinetic mechanism analogous to, but much stronger than, Nagaoka ferromagnetism. Owing to its reduced sign problem, the model can be addressed with advanced path-integral methods to determine quasiparticle structure and effective interactions between carriers-quantities that are challenging to obtain with other methods. This framework establishes a microscopic bridge between the Kanamori model and the emergent magnetic and transport phenomena characteristic of Hund's metals.

</details>


### [124] [Defect Bootstrap: Tight Ground State Bounds in Spontaneous Symmetry Breaking Phases](https://arxiv.org/abs/2511.20860)
*Michael G. Scheer,Nisarg Chadha,Da-Chuan Lu,Eslam Khalaf*

Main category: cond-mat.str-el

TL;DR: 本文提出了缺陷自举方法，通过在辅助缺陷模型中嵌入系统来解决对称性破缺相中自举边界松弛的问题，显著提高了能量密度和自旋关联函数的边界精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于半定松弛的自举方法在对称性破缺相中边界会变得松弛，因为局域约束无法有效捕捉长程有序。本文旨在解决这一局限性。

Method: 引入缺陷自举框架，将系统嵌入到配备辅助自由度的缺陷模型中，使局域算符能够有效移除序参量缺陷。该方法适用于满足缺陷抗磁性性质的成对相互作用局域格点模型。

Result: 在1D和2D横向场伊辛模型中，该方法在对称性破缺相中显著提高了能量密度和自旋关联函数的边界精度，在1D中覆盖整个相，在2D中深入相内部。

Conclusion: 物理动机的约束集可以显著增强自举方法在量子多体系统中的效力，缺陷自举为研究对称性破缺相提供了更强大的工具。

Abstract: The recent development of bootstrap methods based on semidefinite relaxations of positivity constraints has enabled rigorous two-sided bounds on local observables directly in the thermodynamic limit. However, these bounds inevitably become loose in symmetry broken phases, where local constraints are insufficient to capture long-range order. In this work, we identify the origin of this looseness as order parameter defects which are difficult to remove using local operators. We introduce a $\textit{defect bootstrap}$ framework that resolves this limitation by embedding the system into an auxiliary $\textit{defect model}$ equipped with ancilla degrees of freedom. This construction effectively enables local operators to remove order parameter defects, yielding tighter bounds in phases with spontaneous symmetry breaking. This approach can be applied broadly to pairwise-interacting local lattice models with discrete or continuous internal symmetries that satisfy a property we call $\textit{defect diamagnetism}$, which requires that the ground state energy does not decrease upon adding any finite number of symmetry defects. Applying the method to the transverse field Ising models in 1D and 2D, we obtain significantly improved bounds on energy densities and spin correlation functions throughout the symmetry broken phase in 1D and deep within the phase in 2D. Our results demonstrate that physically motivated constraint sets can dramatically enhance the power of bootstrap methods for quantum many-body systems.

</details>


### [125] [Exploring the Anomalous Nernst Effect in SrRuO$_3$](https://arxiv.org/abs/2511.20962)
*Anna Merin Francis,Avirup De,Abhijit Biswas,Lily Mandal,Pallavi Kushwaha,Sunil Nair*

Main category: cond-mat.str-el

TL;DR: 研究SrRuO3薄膜和块材中的反常能斯特效应，发现(111)取向薄膜在Tc附近出现显著能斯特信号，磁各向异性对调节贝里曲率和反常能斯特效应起关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究SrRuO3材料中反常能斯特效应的物理机制，特别是磁各向异性对贝里曲率和热电输运性质的影响。

Method: 在c-cut Al2O3衬底上外延生长SrRuO3薄膜，制备多晶SrRuO3块材，通过测量横向热电响应随温度和磁场的变化来研究反常能斯特效应。

Result: (111)取向SrRuO3薄膜在Tc附近观察到显著的能斯特信号，温度和磁场依赖性表明磁各向异性在调节贝里曲率和反常能斯特效应中起关键作用。

Conclusion: SrRuO3中的反常能斯特效应强烈依赖于磁各向异性，磁各向异性通过调节贝里曲率来调控反常能斯特效应。

Abstract: We investigate the anomalous Nernst effect in epitaxial SrRuO$_3$ thin films grown on c-cut Al$_2$O$_3$ substrates, and in a polycrystalline SrRuO$_3$ slab. Through comprehensive measurements of the transverse thermoelectric response as a function of temperature and magnetic field, we observe a pronounced Nernst signal near $T_c$ in the (111) oriented SrRuO$_3$ thin films. The strong temperature and nontrivial field dependence underscore the pivotal role of the magnetic anisotropy in tuning the Berry curvature and, consequently, the anomalous Nernst effect in SrRuO$_3$.

</details>


### [126] [Probing magnetic-field-induced multipolar ordering through field-angle-resolved magnetostriction and thermal expansion in PrIr$_2$Zn$_{20}$](https://arxiv.org/abs/2511.21039)
*Naoki Okamoto,Yohei Kono,Takahiro Onimaru,Keisuke T. Matsumoto,Kazumasa Hattori,Shunichiro Kittaka*

Main category: cond-mat.str-el

TL;DR: 对PrIr2Zn20立方非克拉默斯化合物进行场角分辨磁致伸缩和热膨胀测量，发现在[001]方向磁场下存在中间A相，揭示了O20四极矩的强各向异性耦合在稳定A相中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究非克拉默斯系统中多极态如何通过磁场方向进行有效调控，探索四极相互作用的各向异性性质。

Method: 使用场角分辨磁致伸缩和热膨胀测量技术，在PrIr2Zn20化合物中观察磁场沿[001]方向时的热膨胀异常，并与理论模型进行比较分析。

Result: 热膨胀在[001]方向磁场下表现出两种性质不同的异常，证实了先前报道的中间A相的存在，并发现O20四极矩的强各向异性耦合对稳定A相起关键作用。

Conclusion: 非克拉默斯系统中的多极态可以通过磁场方向有效调控，这为理解四极相互作用的各向异性性质提供了重要见解。

Abstract: We performed field-angle-resolved magnetostriction and thermal-expansion measurements on PrIr$_2$Zn$_{20}$, a cubic non-Kramers compound exhibiting antiferroquadrupolar order below $T_{\rm Q}=0.125$ K. Thermal expansion exhibits two qualitatively different anomalies under magnetic fields applied along the $[001]$ direction, providing experimental support for the existence of an intermediate A phase previously reported. Furthermore, comparison between the experimental results and theoretical modeling indicates a strong anisotropic coupling of the $O_{20}$ quadrupolar moment, which plays a key role in stabilizing the A phase. These findings demonstrate that multipolar states in non-Kramers systems can be effectively tuned by magnetic-field orientation, providing insights into the anisotropic nature of quadrupolar interactions.

</details>


### [127] [Helical Quasiperiodic Chains with Engineered Dissipation: Liouvillian Rapidity Diagnostics of Transport and Localization](https://arxiv.org/abs/2511.21332)
*Mohammad Pouranvari*

Main category: cond-mat.str-el

TL;DR: 该论文研究具有Aubry-André型准周期势的二次无自旋费米子螺旋链的弛豫谱，分析了不同耗散模式下的Liouvillian快速性及其与局域化的关系。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子晶格中的弛豫过程，探索准周期势和螺旋跃迁对弛豫动力学的影响，为工程化开放量子系统提供诊断工具。

Method: 使用三量子化/Majorana协方差形式精确处理局部线性Lindblad跳跃算子，计算Liouvillian快速性和快速性间隙，分析不同空间耗散模式。

Result: 均匀耗散产生大而弱依赖于λ的间隙，稀疏局部耗散在准周期势诱导局域化时间隙快速缩小，增加t_N通过改善模式与耗散通道重叠来增强弛豫。

Conclusion: Liouvillian快速性可作为紧凑且实验相关的诊断工具，用于评估工程化开放量子晶格中的弛豫和敏感性。

Abstract: We study relaxation spectra of a quadratic spinless--fermion helical chain with an Aubry--Andre--type quasiperiodic potential and a single N--th neighbor (helical) hopping. Dissipation and pumping are introduced via local linear Lindblad jump operators and treated exactly using the third--quantization / Majorana covariance formalism. Focusing on periodic boundary conditions (to avoid edge artefacts) we compute the Liouvillian rapidities and their smallest nonzero real part (the rapidity gap) for several spatial dissipation patterns: uniform (all), single--site (one--site) and two--site (two--site) placement, plus pairwise gain/loss on helical partner sites. We show that uniform dissipation yields large, weakly lambda--dependent gaps, while sparse local dissipation produces gaps that shrink rapidly as the quasiperiodic potential lambda induces localization. Increasing t_N enhances relaxation by improving mode overlap with dissipative channels. Finite--size scaling, rapidity level statistics (Poisson vs Wigner--Dyson), and spatial profiles of slow modes provide a consistent picture linking Liouvillian spectral structure to transport and localization. Our results highlight Liouvillian rapidities as compact, experimentally relevant diagnostics of relaxation and sensitivity in engineered open quantum lattices.

</details>


### [128] [Charge carrier relaxation dynamics in the one-dimensional Kondo lattice model](https://arxiv.org/abs/2511.21539)
*Arturo Perez-Romero,Mica Schwarm,Fabian Heidrich-Meisner*

Main category: cond-mat.str-el

TL;DR: 本文研究一维Kondo晶格模型中光激发载流子通过磁激发通道的弛豫动力学和热化过程。通过实时动力学模拟发现，在有限电子填充或磁性背景处于单重态时，系统可以达到热化状态。


<details>
  <summary>Details</summary>
Motivation: 研究固体系统中光激发载流子的弛豫动力学和热化过程，特别关注载流子与磁激发的耦合这一重要弛豫通道。

Method: 使用时间相关的Lanczos方法进行实时动力学模拟，评估传导电子的自旋极化、局域自旋-自旋关联以及电子动量分布。

Result: 发现在铁磁背景中单个或两个载流子情况下不发生热化，但在有限电子填充或磁性背景处于单重态时，稳态与热化兼容。通过与有限温度期望值和能隙比分析验证了结果。

Conclusion: 证明了在特定条件下（有限电子填充或单重态磁性背景），Kondo晶格模型中的弛豫过程可以实现热化，这为理解超快动力学中的热化机制提供了重要见解。

Abstract: A generic question in the field of ultrafast dynamics is concerned with the relaxation dynamics and the subsequent thermalization of optically excited charge carriers. Among several possible relaxation channels available in a solid-state system, we focus on the coupling to magnetic excitations. In this paper, we study the real-time dynamics of a paradigmatic model, the Kondo lattice model in one dimension. We conduct a comprehensive study of the relaxation processes by evaluating the spin polarization of the conduction electron, the local spin-spin correlation between localized and conduction electrons, and the electronic momentum distribution. While in the well-studied cases of one or two charge carriers in a ferromagnetic background, no thermalization occurs, we demonstrate that the stationary state is compatible with thermalization if either the electronic filling is finite or the magnetic background is in the singlet sector. Our real-time simulations using the time-dependent Lanczos method are corroborated by a direct comparison with finite-temperature expectation values and an analysis of the spectrum in terms of the gap ratio.

</details>


### [129] [Saturation Field as a Direct Probe of Exchange and Single-Ion Anisotropies in Spin-1 Magnets](https://arxiv.org/abs/2511.21551)
*M. A. R. Griffith,S. Rufo,H. Caldas,F. Dinola Neto,Minos A. Neto,J. R. Viana*

Main category: cond-mat.str-el

TL;DR: 本文使用SU(3)键算子框架分析自旋1系统的磁振子谱和临界场，发现上临界场hc2可作为交换各向异性和单离子对称性破缺的定量指纹，为实验识别真实材料的对称性破缺机制提供标准。


<details>
  <summary>Details</summary>
Motivation: 研究高磁场下各向异性对层状磁体中自旋动力学的影响，开发通过磁场实验探测微观各向异性的方法。

Method: 采用SU(3)键算子框架处理自旋1系统，推导磁振子谱和临界场的解析表达式，分析交换各向异性、单离子对称性破缺和层间耦合的影响。

Result: 发现上临界场hc2对交换各向异性和单离子对称性破缺敏感，可作为定量指纹；揭示了这些各向异性与层间耦合共同控制磁振子玻色-爱因斯坦凝聚穹顶的范围和位置。

Conclusion: 高磁场实验可作为探测微观各向异性的灵敏工具，为识别真实自旋1材料中的对称性破缺机制提供实验可验证的标准。

Abstract: High magnetic fields provide a direct route to probe the anisotropies that govern spin dynamics in layered magnets. Using the SU(3) bond operator framework for spin 1 systems, we derive analytic expressions for the magnon spectrum and the critical fields delimiting the field induced ordered phase. We show that the upper critical field $h_{c2}$ carries a simple and quantitative fingerprint of both exchange anisotropy and single ion symmetry breaking, enabling high field experiments to serve as sensitive probes of microscopic anisotropy. We further map how these anisotropies, together with interlayer coupling, control the extent and location of the magnon Bose Einstein condensation dome. Our results provide experimentally accessible criteria for identifying symmetry breaking mechanisms in real spin 1 materials.

</details>


### [130] [Unconventional orders in the maple-leaf ferro-antiferromagnetic Heisenberg model](https://arxiv.org/abs/2511.21598)
*Lasse Gresista,Dominik Kiese,Simon Trebst,Yasir Iqbal*

Main category: cond-mat.str-el

TL;DR: 本文研究了自旋1/2海森堡模型在枫叶晶格上的量子相图，发现了多种非常规有序相，包括六角单重态、二聚化六角单重态和可能的量子自旋液体相。


<details>
  <summary>Details</summary>
Motivation: 寻找受挫量子磁体中非常规有序相，特别是研究枫叶晶格上具有三种不等价最近邻相互作用的海森堡模型的量子相图。

Method: 采用多方法互补分析：团簇平均场方法、伪费米子泛函重整化群方法以及无约束Luttinger-Tisza半经典处理。

Result: 在反铁磁六角耦合和铁磁三角/二聚耦合参数区域发现了扩展的非磁性区域，包括六角单重态、二聚化六角单重态和多种不同的关联分布，边界处还观察到自旋向列序。

Conclusion: 枫叶晶格海森堡模型的顺磁区域可能包含多种非磁性相，包括潜在的量子自旋液体，展示了丰富的非常规量子有序现象。

Abstract: Motivated by the search for unconventional orders in frustrated quantum magnets, we present a multi-method investigation into the nature of the quantum phase diagram of the spin-$1/2$ Heisenberg model on the maple-leaf lattice with three symmetry-inequivalent nearest-neighbor interactions. It has been argued that the parameter regime with antiferromagnetic couplings on hexagons $J_h$ and ferromagnetic couplings on triangles $J_t$ and dimer $J_d$ bonds, is potentially host to a cornucopia of emergent phases with unconventional orders. Our analysis indeed identifies an extended region where any conventional dipolar magnetic order is absent. A hexagonal singlet state is found in the region around $J_{d}=J_{t}=0$, while a dimerized hexagonal singlet order of a lattice nematic character appears proximate to the phase boundary with the c$120^\circ$ antiferromagnetic order. Interestingly, upon traversing the bulk of the paramagnetic (PM) region, we find a variety of distinct correlation profiles, which are qualitatively different from those of the hexagonal singlet and dimerized hexagonal singlet orders but feature no appreciable spin-nematic response, while the boundary with the ferromagnetic phase shows evidence of spin-nematic order. This PM region is thus likely host to an ensemble of nonmagnetic phases which could putatively include quantum spin liquids. Our phase diagram is built from a complementary application of state-of-the-art implementations of the cluster mean-field and pseudo-fermion functional renormalization group approaches, together with an unconstrained Luttinger-Tisza treatment of the model providing insights from the semi-classical limit.

</details>


### [131] [Mean-field Modelling of Moiré Materials: A User's Guide with Selected Applications to Twisted Bilayer Graphene](https://arxiv.org/abs/2511.21683)
*Yves H. Kwan,Ziwei Wang,Glenn Wagner,Nick Bultinck,Steven H. Simon,Siddharth A. Parameswaran*

Main category: cond-mat.str-el

TL;DR: 本文综述了魔角双层石墨烯的理论建模，重点通过Hartree-Fock平均场理论分析其各种特性，包括能带结构、相互作用、集体激发和强耦合极限等。


<details>
  <summary>Details</summary>
Motivation: 为读者提供魔角双层石墨烯的理论建模基础，使具备能带理论和多体物理知识的读者能够系统构建和分析通用莫尔系统的详细模型。

Method: 采用Hartree-Fock平均场理论，结合连续介质模型分析莫尔能带结构，讨论强耦合极限、中间耦合Kekulé螺旋序以及集体模式等案例研究。

Result: 展示了平均场近似在魔角双层石墨烯中的有效性，特别是在强耦合极限下能够准确捕捉基态结构，并揭示了异质应变导致的中间耦合序和集体激发特性。

Conclusion: Hartree-Fock平均场理论是研究魔角双层石墨烯和相关莫尔材料的有力工具，能够系统描述其电子结构和相关物理现象，为更复杂系统的建模提供基础。

Abstract: We review the theoretical modelling of moiré materials, focusing on various aspects of magic-angle twisted bilayer graphene (MA-TBG) viewed through the lens of Hartree-Fock mean-field theory. We first provide an elementary introduction to the continuum modelling of moiré bandstructures, and explain how interactions are incorporated to study correlated states. We then discuss how to implement mean-field simulations of ground state structure and collective excitations in this setting. With this background established, we rationalize the power of mean-field approximations in MA-TBG, by discussing the idealized "chiral-flat" strong-coupling limit, in which ground states at electron densities commensurate with the moiré superlattice are exactly captured by mean-field ansätze. We then illustrate the phenomenological shortcomings of this limit, leading us naturally into a discussion of the intermediate-coupling incommensurate Kekulé spiral (IKS) order and its origins in ever-present heterostrain. IKS and its placement within an expanded Hartree-Fock manifold form our first "case study". Our second case study involves time-dependence, and focuses on the collective modes of various broken-symmetry insulators in MA-TBG. As a third and final case study, we return to the strong-coupling picture, which can be stabilized by aligning MA-TBG to an hBN substrate. In this limit, we show how mean field theory can be adapted to the translationally non-invariant setting in order to quantitatively study the energetics of domain walls in orbital Chern insulating states. We close with a discussion of extensions and further applications. Used either as a standalone reference or alongside the accompanying open-source code, this review should enable readers with a basic knowledge of band theory and many-body physics to systematically build and analyze detailed models of generic moiré systems.

</details>
