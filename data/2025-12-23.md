<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 4]
- [quant-ph](#quant-ph) [Total: 79]
- [nlin.AO](#nlin.AO) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 11]
- [cs.LG](#cs.LG) [Total: 82]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 15]
- [cs.AI](#cs.AI) [Total: 47]
- [nlin.CD](#nlin.CD) [Total: 3]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [Density of scattering resonances in a disordered system](https://arxiv.org/abs/2512.18717)
*M. S. Kurilov,P. M. Ostrovsky*

Main category: cond-mat.dis-nn

TL;DR: 基于非线性sigma模型，开发了研究无序或混沌介质中粒子反射共振宽度分布函数的通用方法，适用于任意对称系统和任意耦合类型，并在无序金属颗粒中得到解析表达式，与数值模拟完美吻合。


<details>
  <summary>Details</summary>
Motivation: 无序或混沌介质中粒子反射的散射矩阵可表示为共振叠加，每个共振对应介质内的本征态，其宽度与本征态衰减时间相关。需要研究这些共振宽度的分布函数，以理解无序系统的散射特性。

Method: 基于非线性sigma模型开发通用方法，推导出适用于任意对称系统和任意耦合类型的分布函数积分表示，并在无序金属颗粒情况下获得解析表达式，同时进行大规模数值模拟验证。

Result: 获得了共振宽度分布函数的积分表示，在无序金属颗粒情况下得到显式解析表达式，大规模数值模拟与解析结果完美吻合，验证了方法的有效性。

Conclusion: 开发了一种基于非线性sigma模型的通用方法，能够有效研究无序或混沌介质中粒子反射共振宽度的分布函数，适用于各种对称系统和耦合类型，为理解无序系统的散射特性提供了有力工具。

Abstract: Reflection of particles from a disordered or chaotic medium is characterized by a scattering matrix that can be represented as a superposition of resonances. Each resonance corresponds to an eigenstate inside the medium and has a width related to the decay time of this eigenstate. We develop a general approach to study the distribution function of these resonance widths based on the nonlinear sigma model. We derive an integral representation of the distribution function that works equally well for systems of any symmetry and for any type of coupling to the measuring device. From this integral representation we find explicit analytic expressions for the distribution function in the case of disordered metallic grains. We also compare the analytic results to large-scale numerical simulations and observe their perfect agreement.

</details>


### [2] [Localization Properties of a Disordered Helical Chain](https://arxiv.org/abs/2512.19170)
*Taylan Yildiz,B. Tanatar*

Main category: cond-mat.dis-nn

TL;DR: 研究准周期一维螺旋链的局域化特性，该链具有最近邻和长程跳跃两种隧穿路径，通过IPR和NPR量化局域化并构建相图，发现三种相：完全扩展相、完全局域相以及扩展与局域态共存的混合相。


<details>
  <summary>Details</summary>
Motivation: 研究具有两种隧穿路径（最近邻和连接螺旋相邻圈的长程跳跃）的准周期一维螺旋链的局域化性质，探索螺旋几何结构对量子态局域化的影响。

Method: 使用精确对角化方法，通过逆参与率（IPR）和归一化参与率（NPR）量化局域化程度，并将两者结合为单一度量来构建相图。

Result: 相图显示三种区域：完全扩展相、完全局域相以及扩展与局域态共存的混合相。对于中等螺旋圈尺寸，混合区域较宽且随长程耦合移动；当每圈位点数为斐波那契数时，相边界几乎水平，混合区域消失，恢复标准Aubry-André模型行为。

Conclusion: 螺旋几何结构显著影响准周期系统的局域化特性，特别是螺旋圈尺寸对相图形态有重要影响，斐波那契数条件使系统恢复标准Aubry-André模型行为。

Abstract: We study the localization properties of the quasiperiodic one-dimensional helical chain with two tunneling paths: nearest-neighbor and a long-range hop that connects sites of consecutive helical turns. Using exact diagonalization, we quantify localization employing the inverse participation ratio (IPR) and the normalized participation ratio (NPR), and combine them into a single measure to create a phase map. The resulting diagrams reveal three regimes: a completely extended phase, a completely localized phase, and a mixed domain where localized and extended states coexist. In the diagrams, we investigate the behaviors of tightly and loosely wound helices and examine a special case where the number of sites per turn is a Fibonacci number. For moderate numbers of sites per helical turn, the mixed region is broad and also shifts with the long-range coupling. When the turn size is a Fibonacci number, the phase boundary becomes nearly horizontal and the mixed region fades out, effectively recovering the standard Aubry-André model behavior.

</details>


### [3] [Localization and persistent currents in a quasiperiodic disordered helical lattice](https://arxiv.org/abs/2512.19176)
*Taylan Yildiz,B. Tanatar*

Main category: cond-mat.dis-nn

TL;DR: 研究螺旋晶格中双磁通和准周期势下的局域化与持续电流，发现可通过调节参数控制金属-绝缘体转变阈值


<details>
  <summary>Details</summary>
Motivation: 研究在螺旋紧束缚晶格中，两个独立磁通和准周期势共同作用下的局域化现象和持续电流行为，探索通过调节参数控制导电-绝缘态转变的可能性

Method: 使用无相互作用自旋less费米子模型，在周期性边界条件下通过精确对角化求解，利用逆参与率和归一化参与率研究局域化，构建包含势强度和环间耦合的相图

Result: 识别出扩展态、混合态和局域态之间的相边界；金属态中持续电流随无序增强而衰减振荡，局域态中电流对磁通不敏感；可通过调节磁通、跃迁强度或准周期势幅值控制临界无序阈值

Conclusion: 该模型提供了一个多功能平台，可通过无序和磁通控制实现导电态和绝缘态之间的切换，为量子输运调控提供了新途径

Abstract: We investigate localization and persistent currents in a helical tight-binding lattice subject to two independent magnetic fluxes and a quasiperiodic on-site potential. Working with non-interacting, spinless fermions under periodic boundary conditions, we solve the model by exact diagonalization and study localization with both inverse and normalized participation ratios. We identify boundaries separating extended, mixed, and localized regimes by constructing a diagram incorporating potential strength and inter-ring coupling. In the metallic regime, persistent currents flowing around both the toroidal and poloidal directions show oscillations whose amplitude decays as disorder grows and vanishes past the localization threshold; in the localized regime, currents become flux-insensitive. We demonstrate that tuning magnetic fluxes, hopping strengths, or quasiperiodic potential amplitudes provides control over the critical disorder threshold. Our results suggest a versatile platform for disorder-and flux-controlled switching between conductive and insulating states.

</details>


### [4] [Reentrant Localization in Quasiperiodic Thue-Morse Chain](https://arxiv.org/abs/2512.19368)
*Taylan Yildiz,B. Tanatar*

Main category: cond-mat.dis-nn

TL;DR: 该研究在具有Thue-Morse序列调制的准周期SSH链中发现了局域化、多重分形和扩展态之间的重入行为，通过调制强度和二聚化比的控制实现了确定性输运调控。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索非随机、确定性的准周期系统中局域化与重入现象，为可控输运提供理论平台。传统无序系统存在随机性难以精确控制，而准周期系统提供确定性调控的可能性。

Method: 采用精确对角化方法在大尺寸Fibonacci链上求解非相互作用无自旋费米子模型，使用逆参与率/归一化参与率和关联分形维数诊断相，通过双尺寸交叉和有限尺寸标度验证相变。

Result: 构建了调制强度与二聚化比的相图，识别出扩展态、多重分形（混合）和局域化区域。系统随准周期振幅增加表现出重入行为：局域化→部分再扩展为多重分形→再局域化。调制强度、SSH二聚化或非公度参数可调控临界阈值。

Conclusion: 该准周期SSH系统提供了一个无随机性的多功能平台，能够确定性控制输运，实现在导电态、多重分形态和绝缘态之间的切换，为可控量子输运设计提供了新途径。

Abstract: We investigate localization and reentrance in a dimerized Su-Schrieffer-Heeger (SSH) tight-binding chain whose on-site energies are given by a quasiperiodic cosine masked by a deterministic Thue-Morse sequence. Working with non-interacting, spinless fermions, we solve the model via exact diagonalization on large Fibonacci sizes and diagnose phases using inverse/normalized participation ratios and the correlation fractal dimension. We identify boundaries separating extended, multifractal (mixed), and localized regimes by constructing a phase diagram in the plane of modulation strength and dimerization ratio. As the quasiperiodic amplitude is increased, the system exhibits reentrant behavior, localizing, partially re-delocalizing into a multifractal regime, and re-localizing, verified via two-size crossings of band-averaged observables and finite-size scaling. We demonstrate that tuning the modulation strength, the SSH dimerization, or the incommensurability parameter provides control over the critical thresholds. Our results suggest a versatile, randomness-free platform for the deterministic control of transport, enabling switching between conducting, multifractal, and insulating states.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [5] [A Polylogarithmic-Time Quantum Algorithm for the Laplace Transform](https://arxiv.org/abs/2512.17980)
*Akash Kumar Singh,Ashish Kumar Patra,Anurag K. S. V.,Sai Shankar P.,Ruchika Bhat,Jaiganesh G*

Main category: quant-ph

TL;DR: 该论文提出了一种在量子计算机上实现拉普拉斯变换的高效量子算法，相比经典算法实现了超多项式加速。


<details>
  <summary>Details</summary>
Motivation: 拉普拉斯变换在经典计算中应用广泛，但由于其耗散性和非幺正特性，在量子计算机上一直缺乏高效实现。现有量子傅里叶变换（QFT）已成功应用，但拉普拉斯变换的量子实现仍具挑战性。

Method: 使用量子本征值变换（Quantum Eigenvalue Transformation）和Lap-LCHS方法，针对算术级数点高效实现离散拉普拉斯变换。算法基于量子本征值变换框架，避免了传统泰勒级数方法。

Result: 算法实现了N×N离散拉普拉斯变换，门复杂度为O((log N)³)，电路宽度为O(log N)，其中N=2ⁿ（n为量子比特数）。相比经典算法复杂度O(N·log N)实现了超多项式加速。

Conclusion: 量子拉普拉斯变换（QLT）为量子计算开辟了新应用领域，包括拉普拉斯域微分方程求解、量子计算机上的逆拉普拉斯变换、计算基态能量的解析延拓域虚时间演化，以及非厄米矩阵的谱估计等。

Abstract: We introduce a quantum algorithm to perform the Laplace transform on quantum computers. Already, the quantum Fourier transform (QFT) is the cornerstone of many quantum algorithms, but the Laplace transform or its discrete version has not seen any efficient implementation on quantum computers due to its dissipative nature and hence non-unitary dynamics. However, a recent work has shown an efficient implementation for certain cases on quantum computers using the Taylor series. Unlike previous work, our work provides a completely different algorithm for doing Laplace Transform using Quantum Eigenvalue Transformation and Lap-LCHS, very efficiently at points which form an arithmetic progression. Our algorithm can implement $N \times N$ discrete Laplace transform in gate complexity that grows as $O((log\,N)^3)$, ignoring the state preparation cost, where $N=2^n$ and $n$ is the number of qubits, which is a superpolynomial speedup in number of gates over the best classical counterpart that has complexity $O(N\cdot log\,N)$ for the same cases. Also, the circuit width grows as $O(log\,N)$. Quantum Laplace Transform (QLT) may enable new Quantum algorithms for cases like solving differential equations in the Laplace domain, developing an inverse Laplace transform algorithm on quantum computers, imaginary time evolution in the resolvent domain for calculating ground state energy, and spectral estimation of non-Hermitian matrices.

</details>


### [6] [Recasting Schrödinger's Cat Thought Experiment as a Remote Measurement Problem](https://arxiv.org/abs/2512.17991)
*Lucas L. Brugger,Cristhiano Duarte,Bruno F. Rizzuti*

Main category: quant-ph

TL;DR: 该论文从量子理论作为经典概率推广的贝叶斯主观主义视角，重新诠释薛定谔猫思想实验，将其视为远程测量问题，探讨空间分离的Alice和Bob在各自系统进行局部测量时信念如何更新。


<details>
  <summary>Details</summary>
Motivation: 在2025年被宣布为量子科学与技术年的背景下，作者希望为薛定谔猫思想实验提供新的视角。通过将量子理论视为经典概率的推广，并基于贝叶斯主观主义框架，重新诠释这一著名实验，同时为对量子理论感兴趣的年轻科学家提供教育视角。

Method: 采用量子理论作为经典概率推广的贝叶斯主观主义框架，将薛定谔猫实验重新解释为远程测量问题。具体研究两个空间分离但共享量子态的智能体Alice和Bob，在各自系统进行局部测量时，他们的信念如何更新。

Result: 通过这种重新诠释，展示了量子测量问题可以从贝叶斯主观主义视角理解，为量子理论中的测量问题提供了新的解释框架，并有助于教育年轻科学家理解量子力学的基本概念。

Conclusion: 该研究为薛定谔猫思想实验提供了新颖的贝叶斯主观主义解释，将量子测量视为信念更新过程，不仅深化了对量子理论的理解，也为量子科学教育提供了有价值的视角。

Abstract: With 2025 being declared the Year of Quantum Science and Technology, our contribution seeks to provide a fresh perspective on Schrödinger's cat thought experiment. We reinterpret this experiment by viewing it through the lens of quantum theory as a generalisation of classical probability, rooted in a Bayesian subjectivist framework. In this revised approach, we treat the experiment as a remote measurement problem. Specifically, we explore how the beliefs of two agents, Alice and Bob, who are spatially separated yet share a quantum state, are updated when local measurements are conducted on their respective systems. Through this reinterpretation of the well-known experiment, we also aim to offer an educational perspective that will be beneficial for young scientists interested in the field of quantum theory.

</details>


### [7] [Logical gates on Floquet codes via folds and twists](https://arxiv.org/abs/2512.17999)
*Alexandra E. Moylett,Bhargavi Jonnadula*

Main category: quant-ph

TL;DR: 该论文展示了如何在Floquet码上实现逻辑操作，包括通过折叠横向操作实现Hadamard和S门，以及通过Dehn扭曲实现CNOT门，并在CCS Floquet码上验证了0.25-0.35%的逻辑门阈值。


<details>
  <summary>Details</summary>
Motivation: Floquet码作为新兴的量子纠错码家族，其逻辑操作实现方法是一个关键开放问题。研究旨在将静态量子纠错码的技术移植到Floquet码上，解决逻辑门实现难题。

Method: 1. 使用折叠横向操作实现逻辑Hadamard和S门；2. 通过Dehn扭曲实现逻辑CNOT门；3. 在彩色码晶格定义的Floquet码家族中应用这些技术；4. 在CCS Floquet码上进行数值基准测试。

Result: 1. 成功在Floquet码上实现了逻辑操作；2. 在CCS Floquet码上获得0.25-0.35%的逻辑门阈值；3. 验证了亚阈值指数误差抑制；4. 逻辑操作性能接近量子内存基准；5. 详细说明了如何在嵌入码上实现逻辑门。

Conclusion: 该研究成功将静态量子纠错码的逻辑操作技术扩展到Floquet码，证明了这些方法的有效性和鲁棒性，为Floquet码的实际应用奠定了基础，并展示了接近量子内存基准的性能。

Abstract: Floquet codes have recently emerged as a new family of error-correcting codes, and have drawn significant interest across both theoretical and practical quantum computing. A central open question has been how to implement logical operations on these codes. In this work, we show how two techniques from static quantum error-correcting codes can also be implemented on Floquet codes. First, we present a way of implementing fold-transversal operations on Floquet codes in order to yield logical Hadamard and S gates. And second, we present a way of implementing logical CNOT gates on Floquet codes via Dehn twists. We discuss the requirements for these techniques, and show that they are applicable to a wide family of Floquet codes defined on colour code lattices. Through numerical benchmarking of the logical operations on the CCS Floquet code, we establish a logical-gate threshold of 0.25-0.35% and verify sub-threshold exponential error suppression. Our results show that these logical operations are robust, featuring a performance that is close to the baseline set by a quantum memory benchmark. Finally, we explain in detail how to implement logical gates on Floquet codes by operating on the embedded codes.

</details>


### [8] [Systematizing the Interpretation of Quantum Theory via Reconstruction](https://arxiv.org/abs/2512.18002)
*Philip Goyal*

Main category: quant-ph

TL;DR: 该论文认为当前量子理论解释方法存在系统性不足，提出建立"解释自由区"和采用重构性解释方法，利用量子重构程序的结果来构建更丰富的量子实在观。


<details>
  <summary>Details</summary>
Motivation: 量子理论一个世纪以来对哲学思维构成根本挑战，表面上否定了机械实在观的许多关键特征。然而，开发精确、连贯的替代概念框架的挑战尚未得到解决。作者认为主要障碍在于现有的解释方法缺乏系统性，无法判断理论的哪些方面具有解释相关性。

Method: 提出建立"解释自由区"，解释者最初采用描述性立场，考虑理论的所有部分。主张采用重构性解释方法，利用量子重构程序的最新成果来识别几乎所有可能具有解释相关性的事实。这种方法强调考虑理论的所有部分，包括非正式部分和详细的数学结构。

Result: 重构性解释方法能够识别几乎所有可能具有解释相关性的事实，自然应对量子解释的特殊挑战和困难。量子重构程序提供了发现新物理原理的强大途径，并为构建丰富、连贯的量子实在观提供了系统化路径。

Conclusion: 量子理论解释需要新的方法论框架。建立"解释自由区"和采用重构性解释方法能够克服现有方法的局限性，量子重构程序为构建连贯的量子实在观提供了系统化途径，有望解决量子理论带来的哲学挑战。

Abstract: For a century, quantum theory has posed a fundamental challenge to philosophical thinking. On its face, it repudiates many of the key features of the mechanical conception of physical reality. However, the challenge of developing a precise, coherent alternative to that conception has yet to be met. Here, I argue that a major hindrance to the project of quantum interpretation is its existing interpretative methodologies, which suffer from a lack of systematicity in their judgements about what aspects of the theory are interpretational relevant. In particular, I argue that current interpretations tend to marginalize the informal part of the theory in favour of its formal part, and place inappropriate emphasis on the natural language component of the formalism over its detailed mathematical structure. To counterbalance these biases, I propose that an interpretation-free zone be constructed around the theory, wherein an interpreter initially adopt a descriptive stance which considers all parts of the theory, and that the results of this deliberation~(and the judgements about what facts are interpretationally relevant) are reported as part of their interpretation.
  I argue that the interpretation of quantum theory poses special challenges and difficulties which necessitate this interpretation-free zone, and that existing interpretative methodologies are insufficient to address them. Further, I argue that a reconstructive interpretative methodology, which harnesses the recent results of the quantum reconstruction program, provides a powerful means to identify almost all facts that could be interpretationally relevant, and naturally meets these challenges and difficulties. Moreover, I argue that the quantum reconstruction program offers a powerful way to discover new physical principles, and offers a systematic pathway to build a rich, coherent conception of quantum reality.

</details>


### [9] [Shuttling Compiler for Trapped-Ion Quantum Computers Based on Large Language Models](https://arxiv.org/abs/2512.18021)
*Fabian Kreppel,Reza Salkhordeh,Ferdinand Schmidt-Kaler,André Brinkmann*

Main category: quant-ph

TL;DR: 该论文提出使用大型语言模型（LLMs）作为独立于硬件布局的编译策略，用于管理离子阱量子计算机中的量子比特路由和穿梭操作。


<details>
  <summary>Details</summary>
Motivation: 随着离子阱量子计算机硬件架构复杂度的增加（从线性阵列到赛道环再到基于交叉点的布局），需要灵活的软件层来管理量子比特路由。现有基于特定架构启发式的方法在系统复杂度增加时变得不切实际。

Method: 提出基于大型语言模型（LLMs）的布局独立编译策略，通过对预训练的LLMs进行微调，使其能够生成所需的穿梭操作。

Result: 在线性和分支一维架构上评估该方法，证明其为开发基于LLM的离子阱量子计算机穿梭编译器奠定了基础。

Conclusion: LLM-based编译策略为解决复杂离子阱量子计算机架构中的量子比特路由问题提供了有前景的解决方案，能够适应不断增长的硬件复杂度。

Abstract: Trapped-ion quantum computers based on segmented traps rely on shuttling operations to establish connectivity between multiple sub-registers within a quantum processing unit. Several architectures of increasing complexity have already been realized, including linear arrays, racetrack loops, and junction-based layouts. As hardware capabilities advance, the need arises for flexible software layers within the control stack to manage qubit routing$\unicode{x2014}$the process of dynamically reconfiguring qubit positions so that all qubits involved in a gate operation are co-located within the same segment. Existing approaches typically employ architecture-specific heuristics, which become impractical as system complexity grows. To address this challenge, we propose a layout-independent compilation strategy based on large language models (LLMs). Specifically, we fine-tune pretrained LLMs to generate the required shuttling operations. We evaluate this approach on both linear and branched one-dimensional architectures, demonstrating that it provides a foundation for developing LLM-based shuttling compilers for trapped-ion quantum computers.

</details>


### [10] [Kicked fluxonium with quantum strange attractor](https://arxiv.org/abs/2512.18644)
*Alexei D. Chepelianskii,Dima L. Shepelyansky*

Main category: quant-ph

TL;DR: 研究通量子量子耗散系统在脉冲场作用下的动力学，发现经典极限下系统收敛到奇异混沌吸引子，量子耗散演化中稳态密度矩阵收敛到量子奇异吸引子，其本征态在强耗散时局域化、弱耗散时退局域化，与Ehrenfest波包爆炸现象相关。


<details>
  <summary>Details</summary>
Motivation: 研究通量子量子系统在脉冲场和耗散环境下的动力学行为，探索量子耗散系统如何收敛到奇异吸引子，以及量子与经典奇异吸引子之间的关系，特别是量子本征态的局域化特性与耗散强度的关联。

Method: 采用数值模拟和解析方法研究通量子在脉冲场作用下的量子耗散时间演化，在经典极限下分析系统动力学收敛到奇异混沌吸引子，在量子框架下使用Lindblad方程研究密度矩阵演化，分析不同耗散强度下密度矩阵本征态的局域化特性。

Result: 发现量子耗散演化中稳态密度矩阵收敛到量子奇异吸引子，其结构与经典奇异吸引子相似；在强耗散或中等耗散时，密度矩阵本征态呈现局域化特征；在弱耗散时，本征态呈现退局域化特征，这与Ehrenfest波包爆炸现象相关，并与Lyapunov指数和Ehrenfest时间有关。

Conclusion: 通量子量子耗散系统在脉冲场作用下可以形成量子奇异吸引子，其本征态的局域化特性与耗散强度密切相关，这一现象与经典混沌动力学和量子波包演化有深刻联系，为实验实现量子奇异吸引子提供了理论基础。

Abstract: The quantum dissipative time evolution of a fluxonium under a pulsed field (kicks) is studied numerically and analytically. In the classical limit the system dynamics is converged to a strange chaotic attractor. The quantum properties of this system are studied for the density matrix in the frame of Lindblad equation. In the case of dissipative quantum evolution the steady-state density matrix is converged to a quantum strange attractor being similar to the classical one. It is shown that depending on the dissipation strength there is a regime when the eigenstates of density matrix are localized at a strong or moderate dissipation. At a weak dissipation the eigenstates are argued to be delocalized being linked to the Ehrenfest explosion of quantum wave packet. This phenomenon is related with the Lyapunov exponent and Ehrenfest time for the quantum strange attractor. Possible experimental realisations of this quantum strange attractor with fluxonium are discussed.

</details>


### [11] [Noisy Monitored Quantum Circuits](https://arxiv.org/abs/2512.18783)
*Shuo Liu,Shao-Kai Jian,Shi-Xin Zhang*

Main category: quant-ph

TL;DR: 综述文章系统总结了噪声监控量子电路的最新进展，包括其纠缠结构、信息保护能力和噪声诱导相变，并探讨了在量子计算和量子多体物理中的应用。


<details>
  <summary>Details</summary>
Motivation: 噪声监控量子电路作为一个统一框架，连接了量子多体物理、量子信息和量子计算领域，需要全面梳理其动力学特性、信息保护机制和噪声效应，以推动在现实退相干环境中的量子动力学研究和控制。

Method: 通过将噪声监控量子电路映射到经典统计模型，分析量子噪声如何重塑主导自旋构型，研究纠缠标度行为和信息保护时间尺度，并探讨各种构造和应用方法。

Result: 揭示了噪声概率q与纠缠标度之间的特征关系（q^{-1/3}标度），发现了信息保护的不同时间尺度，建立了噪声诱导相变的普遍标度行为，并展示了在变分量子算法、经典模拟方法、混合态物相以及量子错误缓解和纠错等方面的广泛应用。

Conclusion: 噪声监控量子电路已成为在现实退相干环境中探索和控制量子动力学的强大平台，其统一框架为理解量子噪声效应、开发量子信息保护策略以及推动量子计算应用提供了重要理论基础。

Abstract: Noisy monitored quantum circuits have emerged as a versatile and unifying framework connecting quantum many-body physics, quantum information, and quantum computation. In this review, we provide a comprehensive overview of recent advances in understanding the dynamics of such circuits, with an emphasis on their entanglement structure, information-protection capabilities, and noise-induced phase transitions. A central theme is the mapping to classical statistical models, which reveals how quantum noise reshapes dominant spin configurations. This framework elucidates universal scaling behaviors, including the characteristic $q^{-1/3}$ entanglement scaling with noise probability $q$ and distinct timescales for information protection. We further highlight a broad range of constructions and applications inspired by noisy monitored circuits, spanning variational quantum algorithms, classical simulation methods, mixed-state phases of matter, and emerging approaches to quantum error mitigation and quantum error correction. These developments collectively establish noisy monitored circuits as a powerful platform for probing and controlling quantum dynamics in realistic, decohering environments.

</details>


### [12] [Real 3-qubit gate decompositions via triality](https://arxiv.org/abs/2512.18049)
*Brendan Pawlowski*

Main category: quant-ph

TL;DR: 本文证明任何幺正实数3量子比特门最多可用14个CNOT门加上单量子比特门实现，改进了Wei和Di的16个CNOT门界限。


<details>
  <summary>Details</summary>
Motivation: 研究实数3量子比特门的优化实现，降低实现复杂度，改进现有理论界限。

Method: 利用PSO(8)群的奇异三元性对称性，探索该映射在实数3量子比特门研究中的有用性质。

Result: 证明任何幺正实数3量子比特门最多需要14个CNOT门加上单量子比特门实现，比之前的16个CNOT门界限有所改进。

Conclusion: 通过利用PSO(8)群的奇异三元性对称性，成功降低了实数3量子比特门的CNOT门实现复杂度，为量子电路优化提供了新方法。

Abstract: We show that any unimodular real 3-qubit gate can be expressed as the product of at most 14 CNOT gates plus single-qubit gates, improving on the bound of 16 CNOTs due to Wei and Di. Our method uses the exotic triality symmetry of $\operatorname{PSO}(8)$, and we explore some of the useful properties of this map in relation to the study of real 3-qubit gates.

</details>


### [13] [Partition Function Estimation Using Analog Quantum Processors](https://arxiv.org/abs/2512.19685)
*Thinh Le,Elijah Pelofske*

Main category: quant-ph

TL;DR: 使用D-Wave量子退火机通过两种采样方法（反向量子退火链和线性斜坡量子退火）近似计算伊辛模型的配分函数，在25自旋硬件图模型上获得与经典蒙特卡洛方法相当的结果质量。


<details>
  <summary>Details</summary>
Motivation: 探索使用可编程超导通量量子比特D-Wave量子退火机来近似计算伊辛模型的配分函数，评估量子退火机在统计物理计算中的潜力。

Method: 提出两种量子退火采样方法：1）类似蒙特卡洛的反向量子退火链；2）标准线性斜坡量子退火。通过控制J耦合的有效模拟能量尺度、总退火时间以及反向退火中的退火-暂停参数来调节模拟质量。核心估计技术是在经典哈密顿量的能谱上进行采样，获得每个能级的态密度估计，进而计算配分函数估计值。

Result: 在25自旋±J硬件图原生伊辛模型上，找到了D-Wave处理器提供与两种标准经典蒙特卡洛方法（多重直方图重加权和Wang-Landau）相当结果质量的参数范围。特别地，快速淬火式退火能快速生成对经典伊辛模型真实配分函数非常好的估计分布；在Pegasus图结构QPU上，使用171,000个样本（每个样本8纳秒退火时间，总计0.2秒QPU时间）获得了7.6×10⁻⁶的对数相对误差。

Conclusion: 量子退火机能够有效近似计算伊辛模型的配分函数，快速淬火式退火在超导量子比特的封闭系统动力学时间尺度内就能生成高质量的配分函数估计，展示了量子退火在统计物理计算中的实用潜力。

Abstract: We evaluate using programmable superconducting flux qubit D-Wave quantum annealers to approximate the partition function of Ising models. We propose the use of two distinct quantum annealer sampling methods: chains of Monte Carlo-like reverse quantum anneals, and standard linear-ramp quantum annealing. The control parameters used to attenuate the quality of the simulations are the effective analog energy scale of the J coupling, the total annealing time, and for the case of reverse annealing the anneal-pause. The core estimation technique is to sample across the energy spectrum of the classical Hamiltonian of interest, and therefore obtain a density of states estimate for each energy level, which in turn can be used to compute an estimate of the partition function with some sampling error. This estimation technique is powerful because once the distribution is sampled it allows thermodynamic quantity computation at arbitrary temperatures. On a $25$ spin $\pm J$ hardware graph native Ising model we find parameter regimes of the D-Wave processors that provide comparable result quality to two standard classical Monte Carlo methods, Multiple Histogram Reweighting and Wang-Landau. Remarkably, we find that fast quench-like anneals can quickly generate ensemble distributions that are very good estimates of the true partition function of the classical Ising model; on a Pegasus graph-structured QPU we report a logarithmic relative error of $7.6 \times 10^{-6}$, from $171,000$ samples generated using $0.2$ seconds of QPU time with an anneal time of $8$ nanoseconds per sample which is interestingly within the closed system dynamics timescale of the superconducting qubits.

</details>


### [14] [Correcting quantum errors one gradient step at a time](https://arxiv.org/abs/2512.18061)
*Manav Seksaria,Anil Prabhakar*

Main category: quant-ph

TL;DR: 提出一种基于梯度的通用方法，通过优化量子码字来适应特定噪声信道和固定恢复操作，显著提高保真度


<details>
  <summary>Details</summary>
Motivation: 传统量子纠错码设计通常独立于噪声信道特性，本文旨在开发一种能够针对特定噪声信道优化码字的方法，以提高量子信息传输的保真度

Method: 采用基于梯度的优化方法，通过微分保真度函数，使用有限差分Wirtinger梯度下降优化复数系数，并加入软惩罚项促进正交归一化

Result: 在XXX/ZZZ重复码和[[5,1,3]]码上验证了梯度有效性，在强度0.05的各向同性泡利噪声下，保真度从0.783提升到0.915（100步优化）

Conclusion: 该方法具有确定性、高度并行化和可扩展性，为针对特定噪声信道优化量子纠错码提供了一种有效的通用框架

Abstract: In this work, we introduce a general, gradient-based method that optimises codewords for a given noise channel and fixed recovery. We do so by differentiating fidelity and descending on the complex coefficients using finite-difference Wirtinger gradients with soft penalties to promote orthonormalisation. We validate the gradients on symmetry checks (XXX/ZZZ repetition codes) and the $[[5, 1, 3]]$ code, then demonstrate substantial gains under isotropic Pauli noise with Petz recovery: fidelity improves from 0.783 to 0.915 in 100 steps for an isotropic Pauli noise of strength 0.05. The procedure is deterministic, highly parallelisable, and highly scalable.

</details>


### [15] [Simulation of depolarizing channel exploring maximally non separable spin-orbit mode](https://arxiv.org/abs/2512.18065)
*G. Tiago,V. S. Lamego,M. H. M. Passos,W. F. Balthazar,J. A. O. Huguenin*

Main category: quant-ph

TL;DR: 提出了一种利用矢量光束在紧凑线性光学电路中模拟退极化通道的简单方法，实验结果与首次提出的自旋-轨道Solovay-Kitaiev分解方法结果高度一致。


<details>
  <summary>Details</summary>
Motivation: 退极化通道是量子信息领域中最重要的噪声模型之一，也是可靠的基准测试工具。需要一种简单有效的方法来模拟这种重要的量子噪声模型。

Method: 利用矢量光束在紧凑线性光学电路中模拟退极化通道，同时首次提出了用于退极化通道的自旋-轨道Solovay-Kitaiev分解方法。

Result: 成功再现了不同量子态的演化过程，实验结果与自旋-轨道Solovay-Kitaiev分解方法得到的结果高度一致。

Conclusion: 提出的方法能够有效模拟退极化通道，为量子信息领域的噪声模拟提供了简单可靠的实验方案，同时新的分解方法也为理论分析提供了有力工具。

Abstract: Depolaring Channel is one of the most important noise model and constitute a reliable benchmark quantum information field. In this work we present a simple way to emulate depolaring channel exploring a vector beam in a compact linear optical circuit. The evolution of different states are successfully reproduced. Our results are in excellent agreement compared with the results obtained by the spin-orbit Solovay-Kitaiev decomposiotion for Depolarizing Channel, also presented here for the first time.

</details>


### [16] [Loschmidt Echo and Classicality of the Gamma Model](https://arxiv.org/abs/2512.18085)
*Gilson V. Soares,Mauricio Reis,Adelcio C. Oliveira*

Main category: quant-ph

TL;DR: 研究Gamma模型（可解析求解的非线性量子振子）的经典性，使用重叠动力学（Loschmidt回波）和粗糙度（基于Wigner表示的经典性度量）。虽然重叠动力学显示混沌特征，但模型实际可积。发现重叠函数时间平均值与初始态占据的有效希尔伯特空间成反比衰减，且存在两种不同的平稳状态。


<details>
  <summary>Details</summary>
Motivation: 研究非线性量子振子Gamma模型的经典性特征，探索量子系统在可积情况下如何表现出类似混沌的行为特征，以及不同经典性度量方法（重叠动力学和粗糙度）对系统行为的刻画差异。

Method: 使用重叠动力学（Loschmidt回波）和基于Wigner表示的粗糙度作为经典性度量工具。分析Gamma模型的时间演化，计算重叠函数的时间平均值和方差，以及粗糙度的时间平均值。研究这些量在不同参数条件下的行为。

Result: 1. 重叠动力学显示类似混沌的衰减行为，但模型实际可积；2. 非周期情况下，重叠函数时间平均值与初始态占据的有效希尔伯特空间成反比衰减；3. 发现重叠平均值和方差存在两种不同的平稳状态；4. 粗糙度时间平均值也有两种平稳状态；5. 大有效希尔伯特空间时，粗糙度时间平均值更依赖有效空间而非初始态；6. Wigner函数由非对角项主导，而重叠算子各部分均有贡献但更受对角项影响。

Conclusion: Gamma模型虽然是可积系统，但通过重叠动力学表现出类似混沌的特征。不同的经典性度量方法（重叠动力学和粗糙度）揭示了系统复杂的时间演化行为，包括多种平稳状态和对有效希尔伯特空间的依赖性。这些发现有助于理解量子系统经典性特征与可积性之间的关系。

Abstract: The classicality of the Gamma Model, an analytically solvable quantum oscillator with non-linear dynamics, is investigated using the overlap dynamics, also known as the Loschmidt Echo, and roughness, a classicality measure based on the Wigner representation of a state. Though the overlap dynamics would indicate a chaotic regime, here the model is integrable. The time mean of the overlap function decays inversely with the effective Hilbert space occupied by the initial state for the non-periodic case. Two different stationary regimes were found for the overlap mean and overlap variance. The state non-classicality was investigated using the roughness measure, and its mean also has two stationary regimes. For large effective Hilbert space, the roughness time mean depends more on the effective space than the initial state. While the Wigner function is dominated by the non-diagonal terms, the overlap operator has some contribution on each part, but it is more affected by the diagonal terms than the density matrix.

</details>


### [17] [The CHSH Game, Tsirelson's Bound, and Causal Locality](https://arxiv.org/abs/2512.18105)
*Jacob A. Barandes,Mahmudul Hasan,David Kagan*

Main category: quant-ph

TL;DR: 该论文重新表述了CHSH游戏为不可分随机过程，利用随机-量子对应关系及其因果局域性定义，为Tsirelson界限提供了新证明。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索超越无信号原理的因果局域性假设，以解释量子力学中Tsirelson界限的起源，理解为何量子纠缠违反贝尔不等式但不超过Tsirelson界限。

Method: 方法包括：1) 将CHSH游戏重新表述为不可分随机过程；2) 应用Barandes的随机-量子对应关系；3) 使用因果局域性定义；4) 推导Tsirelson界限的新证明。

Result: 结果表明，因果局域不可分随机过程的假设恰好足够强，允许违反贝尔不等式直至Tsirelson界限，但不超过该界限，这比单独的无信号原理更精确。

Conclusion: 结论是因果局域性假设为Tsirelson界限提供了自然解释，表明量子力学中的纠缠极限源于更深层的因果结构原理，而非仅是无信号约束。

Abstract: We reformulate the CHSH game in terms of indivisible stochastic processes. Using Barandes's stochastic-quantum correspondence and its associated definition of causal locality, we present a novel proof of the Tsirelson bound. In particular, we show that unlike the no-signaling principle alone, the postulates defining causally local, indivisible stochastic processes are precisely strong enough to allow for violations of the Bell inequality up to, but not beyond, the Tsirelson bound.

</details>


### [18] [Quantum thermodynamics, quantum correlations and quantum coherence in accelerating Unruh-DeWitt detectors in both steady and dynamical state](https://arxiv.org/abs/2512.18123)
*Omar Bachain,Mohamed Amazioug,Rachid Ahl Laamara*

Main category: quant-ph

TL;DR: 研究Unruh-DeWitt探测器模型中量子热力学、量子关联和量子相干性的相互作用，分析非马尔可夫环境对量子资源演化和量子热机性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索在相对论或开放系统环境中量子关联和量子相干性在量子热力学过程中的作用，为优化量子设备性能提供理论基础。

Method: 使用Unruh-DeWitt探测器模型，分析稳态和动力学状态下多种量子资源（包括可导性、纠缠、量子失协和相干性）的演化，研究马尔可夫和非马尔可夫环境的影响，并考察量子热机的热力学性能。

Result: 确定了量子关联和量子相干性的层次结构，发现非马尔可夫动力学可以增强量子关联的保持，并提高量子热机的效率，揭示了记忆效应和经典关联对热交换、功提取和效率的影响。

Conclusion: 量子关联和量子相干性在量子热力学过程中发挥重要作用，非马尔可夫环境有助于保持量子资源并提高热机效率，为在相对论或开放系统环境中优化量子设备提供了新途径。

Abstract: We investigate the interplay between quantum thermodynamics, quantum correlations, and quantum coherence within the framework of the Unruh-DeWitt (UdW) detector model. By analyzing both the steady and dynamical states of various quantum resources (including steerability, entanglement, quantum discord, and coherence), we study how these resources evolve under Markovian and non-Markovian environments. Furthermore, we investigate the impact of both the Unruh temperature and the energy levels on three key quantum phenomena: thermodynamic evolution, quantum correlations, and quantum coherence, considering different initial state preparations. The hierarchical structure relating quantum correlations and quantum coherence is determined. We further examine the thermodynamic performance of a quantum heat engine, highlighting the influence of memory effects and classical correlations on heat exchange, work extraction, and efficiency. Our results reveal that non-Markovian dynamics can enhance the preservation of quantum correlations and improve the engine's efficiency compared to purely Markovian regime. These findings provide insights into the role of quantum correlations and quantum coherence in quantum thermodynamic processes and open avenues for optimizing quantum devices operating in relativistic or open-system settings.

</details>


### [19] [Full Quantum Work Statistics for Non-Homogeneous Many-Body Systems](https://arxiv.org/abs/2512.18338)
*Antonio Palamara,Francesco Plastina,Antonello Sindona,Irene D'Amico*

Main category: quant-ph

TL;DR: 该研究在热时间依赖密度泛函理论框架下，通过广义线性响应公式研究相互作用量子多体系统的非平衡热力学，建立了从第一性原理重构弛豫函数的方法，超越了唯象描述，实现了对相互作用系统中耗散功分布所有矩的一致评估。


<details>
  <summary>Details</summary>
Motivation: 研究动机是发展一个微观且可转移的理论框架，用于研究关联系统中的量子热力学，特别是要超越唯象描述，从第一性原理出发研究相互作用量子多体系统的非平衡热力学行为。

Method: 采用热时间依赖密度泛函理论框架，结合广义线性响应公式研究全量子功统计。建立了从第一性原理重构线性响应理论中弛豫函数的方法，并在哈伯德模型中应用，研究其在交错外势作用下的弛豫动力学演化。

Result: 在哈伯德模型中，弛豫动力学在莫特绝缘体到能带绝缘体交叉区域的演化揭示了不同多体相如何塑造非平衡热力学响应。该方法能够一致评估相互作用系统中耗散功分布的所有矩。

Conclusion: 该研究为关联系统中的量子热力学提供了一个微观且可转移的理论框架，成功桥接了热密度泛函理论和非平衡功统计，为研究相互作用量子多体系统的非平衡热力学提供了新的理论工具。

Abstract: The nonequilibrium thermodynamics of interacting quantum many-body systems is investigated within the framework of thermal time-dependent density functional theory using a generalized linear-response formulation for the full quantum work statistics. A first-principles route is established to reconstruct the relaxation function that underlies linear-response theory, thereby moving beyond phenomenological descriptions and enabling a consistent evaluation of all moments of the dissipated-work distribution in interacting systems. The predictive power of the approach is demonstrated for the Hubbard model subject to a staggered external potential, where the evolution of the relaxation dynamics across the Mott-to-band-insulator crossover reveals how distinct many-body phases shape the out-of-equilibrium thermodynamic response. These results provide a microscopic and transferable framework for quantum thermodynamics in correlated systems, bridging thermal density functional theory and nonequilibrium work statistics.

</details>


### [20] [Optimizing Epsilon Security Parameters in QKD](https://arxiv.org/abs/2512.18130)
*Alexander G. Mountogiannakis,Stefano Pirandola*

Main category: quant-ph

TL;DR: 使用连续遗传算法优化量子密钥分发中的ε安全参数，在固定可组合安全水平下显著提高安全密钥率


<details>
  <summary>Details</summary>
Motivation: 在量子密钥分发中，ε安全参数的选择对安全密钥率有重要影响，特别是在高安全水平下密钥率通常趋近于零。需要优化这些参数以提高实际可实现的密钥率。

Method: 采用连续遗传算法优化两个代表性协议的ε安全参数：连续变量家族中的零差探测协议和离散变量家族中的BB84协议。详细配置CGA参数，推导可组合密钥率公式，并强调ε参数在两个协议中的作用。

Result: 与标准和随机选择的ε参数相比，优化后的ε值在高级别安全水平下带来显著的密钥率提升，揭示了未经优化无法达到的正密钥率区域。

Conclusion: 通过连续遗传算法优化ε安全参数是提高量子密钥分发系统性能的有效方法，特别是在高安全要求下能够显著改善密钥率，为实际QKD系统部署提供了重要优化策略。

Abstract: We investigate the optimization of epsilon-security parameters in quantum key distribution (QKD), aiming to improve the achievable secure key rate under a fixed overall composable security level. For this purpose, we employ a continuous genetic algorithm (CGA) to optimize the epsilon-security components of two representative protocols: the homodyne protocol from the continuous-variable (CV) family and the BB84 protocol from the discrete-variable (DV) family. We detail the CGA configuration, summarize the derivation of the composable key rate, and emphasize the role of the epsilon-parameters in both protocols. We then compare key rates obtained with optimized epsilon-values against those derived from standard and randomized choices. Our results demonstrate substantial key rate improvements at high security levels, where the key rate typically vanishes, and uncover positive-rate regimes that are inaccessible without optimization.

</details>


### [21] [Crosstalk Dispersion and Spatial Scaling in Superconducting Qubit Arrays](https://arxiv.org/abs/2512.18148)
*Mohammed Alghadeer,Simon Pettersson Fors,Shuxiang Cao,Simone D. Fasciati,Haru Ishizaka,Anton Frisk Kockum,Peter Leek,Mustafa Bakr*

Main category: quant-ph

TL;DR: 该研究开发了一个理论和实验框架，用于预测固定频率transmon量子比特阵列中的残余相互作用，揭示了空间和频谱依赖关系对量子比特间串扰的重要影响。


<details>
  <summary>Details</summary>
Motivation: 量子比特间的串扰从根本上限制了量子处理器的可扩展性，需要能够处理大规模量子比特阵列复杂性的物理模型。现有标准色散哈密顿量近似在忽略空间和频谱依赖性时会系统性地高估长程耦合。

Method: 开发了一个综合理论模型，整合了带状电容矩阵中的指数局域化、通过中间模式的失谐乘积抑制虚拟耦合、以及低于截止频率电磁场的渐近衰减等效应。实验上表征了一个4×4超导量子比特晶格，采用电感分流柱结构，在4-6 GHz工作范围内测量所有最近邻耦合。

Result: 实验测量显示指数空间衰减和频率依赖性抑制与理论预测一致，在4-6 GHz工作范围内所有最近邻耦合都达到了定量一致性。标准色散哈密顿量近似在忽略空间和频谱依赖性时会系统性地高估长程耦合，这些误差会传播到电路仿真和设计策略中。

Conclusion: 该框架为在现实制造约束下的大规模量子处理器中的串扰缓解提供了设计指导，解决了可扩展性的瓶颈问题。研究结果表明必须考虑空间和频谱依赖性才能准确预测量子比特间的耦合强度。

Abstract: Crosstalk between qubits fundamentally limits the scalability of quantum processors, necessitating physics-based models that can handle the complexity of large qubit arrays. Here, we develop a comprehensive theoretical and experimental framework that captures residual interactions between both adjacent and non-adjacent qubits in fixed-frequency transmon lattices. The model integrates the combined effects of exponential localization in banded capacitance matrices, suppression of virtual couplings through detuning products across intermediate modes, and evanescent decay of below-cutoff electromagnetic fields, yielding predictive scaling relations for coupling strength as a function of spatial separation and spectral detuning. Experimental characterization of a $4 \times 4$ superconducting-qubit lattice with inductive shunt pillars reveals exponential spatial decay and frequency-dependent suppression consistent with theoretical predictions, achieving quantitative agreement for all nearest-neighbor couplings across the \qtyrange[range-phrase = --, range-units = single]{4}{6}{\giga\hertz} operating range. Our results show that standard dispersive Hamiltonian approximations systematically overestimate long-range coupling when spatial and spectral dependencies are neglected; these errors propagate into circuit simulation and design strategies. Our framework provides design guidance for crosstalk mitigation in larger-scale quantum processors under realistic fabrication constraints, addressing a bottleneck in scalability.

</details>


### [22] [Lattice-Renormalized Tunneling Models for Superconducting Qubit Materials](https://arxiv.org/abs/2512.18156)
*P. G. Pritchard,James M. Rondinelli*

Main category: quant-ph

TL;DR: 提出了一种基于晶格重整化的构型隧穿双能级系统理论框架，克服了最小能量路径和轻粒子模型的局限性，能够准确计算氢基TLS在bcc Nb中的隧穿分裂和激发光谱。


<details>
  <summary>Details</summary>
Motivation: 现有最小能量路径和轻粒子模型存在局限性，无法准确描述构型隧穿双能级系统的物理特性，特别是在氢基缺陷系统中。需要发展更精确的理论框架来理解TLS动力学及其与晶格声子的耦合。

Method: 从核哈密顿量出发，引入复合声子坐标来描述简并势阱间的晶格畸变。该晶格重整化形式克服了传统模型的缺陷，能够准确计算隧穿分裂和激发光谱，并可推广到多能级系统。

Result: 成功计算了bcc Nb中氢基TLS的隧穿分裂，结果与实验数据相符。揭示了隧穿原子与晶格声子之间的强非谐耦合，建立了TLS动力学与声子介导的应变相互作用之间的直接联系。

Conclusion: 该理论框架为理解缺陷诱导的超导量子比特退相干提供了新见解，并指导了抑制TLS相关损耗的材料设计策略。形式可推广到多能级系统，具有广泛的应用前景。

Abstract: We present a lattice-renormalized formalism for configurational tunneling two-level systems (TLS) that overcomes limitations of minimum-energy-path and light-particle models. Derived from the nuclear Hamiltonian, our formulation introduces composite phonon coordinates to capture lattice distortions between degenerate potential wells. This approach resolves deficiencies in prior models and enables accurate computation of tunnel splittings and excitation spectra for hydrogen-based TLS in bcc Nb. Our results bound experimental tunnel splittings and reveal strong anharmonic couplings between tunneling atoms and lattice phonons, establishing a direct link between TLS dynamics and phonon-mediated strain interactions. The formalism further generalizes to multi-level systems (MLS), providing insight into defect-induced decoherence in superconducting qubits and guiding strategies for materials design to suppress TLS-related loss.

</details>


### [23] [Superconducting qubit decoherence correlated with detected radiation events](https://arxiv.org/abs/2512.18171)
*A. R. Castelli,K. M. Beck,L. D. H. Alegria,L. A. Martinez,K. R. Chaves,S. R. O'Kelley,N. Materise,J. L DuBois,Y. J. Rosen*

Main category: quant-ph

TL;DR: 该研究开发了一种实时检测宇宙辐射对超导量子比特影响的平台，通过MKID探测器阵列同步监测辐射事件和量子比特退相干，首次直接观测到宇宙射线引起的空间相关误差。


<details>
  <summary>Details</summary>
Motivation: 大多数量子纠错协议假设退相干事件在空间和时间上不相关，但最近证据表明宇宙辐射会引起空间相关误差。需要实验平台来直接观测辐射如何影响量子比特的相干性。

Method: 构建了一个平台，将超导transmon量子比特夹在两个微波动力学电感探测器（MKID）阵列之间。通过同步MKID事件检测与量子比特能量弛豫（T1）和相位相干（T2）的单次测量，实时检测辐射诱导的声子爆发。

Result: 观察到在MKID检测到的穿透性μ子事件后，T1和T2均出现统计显著的降低，最高达30.5%。这直接证明了辐射事件与量子比特退相干之间的关联。

Conclusion: 该实验平台为系统研究辐射效应、开发屏蔽和缓解技术、以及针对相关噪声源优化纠错算法奠定了基础，对量子纠错协议设计具有重要意义。

Abstract: Most quantum error correction (QEC) protocols for superconducting qubits assume spatially and temporally uncorrelated decoherence events; however, recent evidence suggests that cosmic radiation induces spatially correlated errors. We present a platform that sandwiches a superconducting transmon qubit between two microwave kinetic inductance detector (MKID) arrays, enabling real-time detection of radiation-induced phonon bursts. By synchronizing MKID event detection with single-shot measurements of qubit energy relaxation ($T_1$) and phase coherence ($T_2$), we observe statistically significant reductions in both $T_1$ and $T_2$-up to 30.5%-immediately following dual MKID events attributed to penetrating muons. Our findings directly link radiating events to correlated qubit decoherence. Furthermore, our experimental platform provides a foundation for systematic studies of radiation effects, the development of shielding and mitigation techniques, and the refinement of error-correction algorithms tailored to correlated noise sources.

</details>


### [24] [High-Throughput Microwave Package for Precise Superconducting Device Measurement](https://arxiv.org/abs/2512.18198)
*Wei-Ren Syong,Allie Miller,Emma Davis,John R. Pitten,Jorge Ramirez,Nathan Ortiz,Michael Vissers,Doug Bennett,Corey Rae Harrington McRae*

Main category: quant-ph

TL;DR: 本文提出了一种无引线键合、无PCB的微波封装方案，用于超导量子器件测量，通过悬浮钨传输引脚实现低损耗传输，验证了其在超导谐振器损耗测量中的应用。


<details>
  <summary>Details</summary>
Motivation: 超导量子器件的低温微波测量受到传统封装方式的限制，需要引线键合和PCB连接，这会引入额外的损耗和复杂性。本文旨在开发一种更简单、高效的封装方案来简化测量过程。

Method: 设计并制造了一种基于超导铝腔体和悬浮钨传输引脚的封装结构。该封装避免了传统引线键合和PCB的使用，腔体基模频率远离4-8GHz工作频段，传输引脚在该频段内波纹小于3dB。

Result: 使用该封装测量超导环形谐振器的损耗角正切，测得值为(1.10±0.09)×10^-6，与引线键合封装中λ/4谐振器的测量结果一致，验证了封装的有效性。

Conclusion: 该无引线键合、无PCB的微波封装方案能够实现高效、低损耗的超导量子器件测量，为快速生成大规模数据集以改进超导量子比特性能，以及进行时间敏感的表面钝化和氧化物再生研究提供了便利。

Abstract: Cryogenic microwave measurement of superconducting quantum devices is complicated by the packaging required to connect devices to control and readout circuitry. In this work, we outline the design and experimental demonstration of a wirebond-free, PCB-free, drop-in microwave package for on-chip superconducting quantum devices. The package is composed of a superconducting aluminum cavity with a suspended tungsten transmission pin. The fundamental package cavity mode is far detuned from the 4 GHz to 8 GHz band of interest, and the pin transmission exhibits less than 3 dB of ripple across this range. We demonstrate the use of this package to extract the loss tangent of superconducting ring resonators, measuring a value of (1.10 +- 0.09) x 10^-6, which agrees with measurements of lambda/4 resonators in wirebond-based packaging. This high-throughput measurement system will allow the rapid generation of large datasets for improving superconducting qubit performance, and facilitate time-sensitive surface passivation and oxide regrowth studies.

</details>


### [25] [Harnessing non-Hermiticity for efficient quantum state transfer](https://arxiv.org/abs/2512.19490)
*Sejal Ahuja,Keshav Das Agarwal,Aditi Sen De*

Main category: quant-ph

TL;DR: 非厄米哈密顿量通过PT对称和RT对称模型，在量子态传输中超越经典阈值，甚至优于对应厄米模型，特别是在SSH模型的破缺相中实现接近单位保真度的传输。


<details>
  <summary>Details</summary>
Motivation: 研究非厄米性对量子态传输的影响，探索非厄米系统在量子数据总线应用中的潜力，超越传统厄米物理的限制。

Method: 推导U(1)对称非厄米哈密顿量的量子态传输保真度通用表达式，分析PT对称XX和SSH模型，并通过数值研究RT对称iXY模型。

Result: 在多个参数区域，非厄米设置的传输保真度超过经典阈值，甚至优于对应厄米模型；特别在SSH模型中，破缺相支持接近单位保真度的量子态传输。

Conclusion: 非厄米系统在量子态传输方面具有优势，特别是在特定参数区域能实现厄米系统无法达到的高保真度传输，同时建立了非厄米与厄米描述之间的对应关系。

Abstract: The non-Hermitian Hamiltonian describes the effective dynamics of a system coupled to a continuously measured bath, and can exhibit anti-unitary symmetries that give rise to exceptional points and broken phases with complex eigenvalues, features unique to non-Hermitian systems. Going beyond conventional Hermitian physics, we analyze the impact of non-Hermiticity in the quantum state transmission by employing a non-Hermitian spin chain that functions as a quantum data bus. By deriving a general expression for the fidelity of quantum state transfer for a U(1)-symmetric non-Hermitian Hamiltonian, we analyze PT-symmetric XX and SSH models, complemented by a numerical study of the RT-symmetric iXY model. We demonstrate that, in several parameter regimes, the transfer fidelity in the non-Hermitian setting exceeds the classical threshold and can even exceed the performance of the corresponding Hermitian models. In particular, for the SSH model with dominant inter-cell coupling, the broken phase supports near-unit-fidelity quantum state transfer, a level of performance that the corresponding Hermitian model fails to attain. Moreover, we establish a correspondence between the non-Hermitian and Hermitian descriptions by identifying related parameter regions in which the fidelity fails to surpass the classical bound.

</details>


### [26] [Hermitian Matrix Function Synthesis without Block-Encoding](https://arxiv.org/abs/2512.18249)
*Anuradha Mahasinghe,Kaushika De Silva,Xavier Cadet,Peter Chin,Frederic Cadet,Jingbo Wang*

Main category: quant-ph

TL;DR: 提出了一种基于广义量子信号处理（GQSP）框架的新方法，用于在量子硬件上实现厄米矩阵的任意多项式函数，避免了传统方法中块编码的需求，降低了资源开销。


<details>
  <summary>Details</summary>
Motivation: 在量子计算中实现厄米矩阵的任意函数是基础任务，对哈密顿量模拟、量子线性系统求解、高保真态制备等应用至关重要。现有方法如Qubitization、QSVT和QSP严重依赖块编码，受到状态准备复杂性、辅助量子比特开销和相位因子角度合成困难的限制。

Method: 利用广义量子信号处理（GQSP）框架，将目标厄米矩阵表示为酉共轭的对称组合，通过对每个酉分量应用GQSP电路实现多项式合成。推导了对称多项式展开的闭式表达式，展示了如何通过GQSP电路的线性组合实现目标变换。

Result: 该方法避免了块编码的需求，减少了资源开销，为厄米矩阵函数的量子算法设计开辟了新途径。

Conclusion: 提出的基于GQSP框架的方法提供了一种资源高效的替代方案，用于实现厄米矩阵的任意多项式函数，克服了现有技术的限制，具有重要的理论和实践意义。

Abstract: Implementing arbitrary functions of Hermitian matrices on quantum hardware is a foundational task in quantum computing, critical for accurate Hamiltonian simulation, quantum linear system solving, high-fidelity state preparation, machine learning kernels, and other advance quantum algorithms. Existing state-of-the-art techniques, including Qubitization, Quantum Singular Value Transformation (QSVT), and Quantum Signal Processing (QSP), rely heavily on block-encoding the Hermitian matrix. These methods are often constrained by the complexity of preparing the block-encoded state, the overhead associated with the required ancillary qubits, or the challenging problem of angle synthesis for the polynomial's phase factors, which limits the achievable circuit depth and overall efficiency.
  In this work, we propose a novel and resource-efficient approach to implement arbitrary polynomials of a Hermitian matrix, by leveraging the Generalized Quantum Signal Processing (GQSP) framework. Our method circumvents the need for block-encoding by expressing the target Hermitian matrix as a symmetric combination of unitary conjugates, enabling polynomial synthesis via GQSP circuits applied to each unitary component. We derive closed-form expressions for symmetric polynomial expansions and demonstrate how linear combinations of GQSP circuits can realize the desired transformation. This approach reduces resource overhead, and opens new pathways for quantum algorithm design for functions of Hermitian matrices.

</details>


### [27] [Casimir operators for the relativistic quantum phase space symmetry group](https://arxiv.org/abs/2512.18262)
*Philippe Manjakasoa Randriantsoa,Ravo Tokiniaina Ranaivoson,Raoelina Andriambololona,Roland Raboanary,Wilfrid Chrysante Solofoarisina,Anjary Feno Hasina Rasamimanana*

Main category: quant-ph

TL;DR: 论文系统推导了与五维时空(1,4)签名相关的线性正则变换(LCT)群的线性与二次Casimir算子，该群作为相对论量子相空间的对称群，同构于辛群Sp(2,8)，包含de Sitter群SO(1,4)作为子群。


<details>
  <summary>Details</summary>
Motivation: 量子力学与相对论统一的最新进展强调需要将经典相空间推广为相对论量子相空间，该框架固有地包含不确定性原理和相对论协变性。LCT群作为该相空间的对称群，其Casimir算子在物理对称群表征中具有基础作用。

Method: 基于LCT群与伪酉群U(1,4)之间的关系，系统推导了与LCT群表示相关的线性与二次Casimir算子。识别了三个线性算子和三个二次算子：两个对应类费米子表示，两个对应类玻色子表示，两个混合算子连接两种表示。

Result: 计算并识别了所有算子的完整本征值谱和相应本征态。为类费米子表示、类玻色子表示以及混合表示提供了完整的Casimir算子表征。

Conclusion: 该工作为扩展粒子物理标准模型并纳入宇宙学特征提供了统一的几何框架，其中LCT群的Casimir算子表征对于理解该对称群在物理中的应用至关重要，特别是在夸克、轻子（包括惰性中微子）的新分类方案中。

Abstract: Recent developments in the unification of quantum mechanics and relativity have emphasized the necessity of generalizing classical phase space into a relativistic quantum phase space which is a framework that inherently incorporates the uncertainty principle and relativistic covariance. In this context, the present work considers the derivation of linear and quadratic Casimir operators corresponding to representations of the Linear Canonical Transformations (LCT) group associated with a five-dimensional spacetime of signature (1,4). This LCT group, which emerges naturally as the symmetry group of the relativistic quantum phase space, is isomorphic to the symplectic group Sp(2,8). The latter notably contains the de Sitter group SO(1,4) as a subgroup. This geometric setting provides a unified framework for extending the Standard Model of particle physics while incorporating cosmological features. Previous studies have shown that the LCT group admits both fermionic-like and bosonic-like representations. Within this framework, a novel classification of quarks and leptons, including sterile neutrinos, has also been proposed. In this work, we present a systematic derivation of the linear and quadratic Casimir operators associated with these representations, motivated by their fundamental role in the characterization of symmetry groups in physics. The construction is based on the relations between the LCT group and the pseudo-unitary group U(1,4). Three linears and three quadratics Casimir operators are identified: two corresponding to the fermionic-like representation, two to the bosonic-like representation, and two hybrid operators linking the two representations. The complete eigenvalue spectra and corresponding eigenstates for each operator are subsequently computed and identified

</details>


### [28] [Quantum circuit algorithm for topological invariants of second order topological many-body quantum magnets](https://arxiv.org/abs/2512.19615)
*Sebastián Domínguez-Calderón,Marcel Niedermeier,Jose L. Lado,Pascal M. Vecsei*

Main category: quant-ph

TL;DR: 提出了一种在量子计算机上计算多体拓扑不变量的量子电路算法，应用于二阶拓扑量子磁体


<details>
  <summary>Details</summary>
Motivation: 量子多体系统中的拓扑性质研究面临计算复杂性挑战，特别是获取多体基态及其拓扑不变量的困难。虽然量子计算机计算基态的算法已有研究，但计算拓扑不变量的算法仍在发展中

Method: 设计了一种量子电路，通过参数空间中横向路径的量子电路绝热演化来计算二阶拓扑量子磁体的多体拓扑不变量

Result: 算法能够揭示依赖于遍历路径的隐藏拓扑不变量，成功实现了在量子计算机上表征多体拓扑量子物质

Conclusion: 该工作提出了一种利用量子计算机表征多体拓扑量子物质的算法，为研究量子多体系统中的拓扑性质提供了新工具

Abstract: Topological quantum matter represents a flexible playground to engineer unconventional excitations. While non-interacting topological single-particle systems have been studied in detail, topology in quantum many-body systems remains an open problem. Specifically, in the quantum many-body limit, one of the challenges lies in the computational complexity of obtaining the many-body ground state and its many-body topological invariant. While algorithms to compute ground states with quantum computers have been heavily investigated, algorithms to compute topological invariants in a quantum computer are still under active development. Here we demonstrate a quantum circuit to compute the many-body topological invariant of a second-order topological quantum magnet encoded in qubits. Our algorithm relies on a quantum circuit adiabatic evolution in transverse paths in parameter space, and we uncover hidden topological invariants depending on the traversed path. Our work puts forward an algorithm to leverage quantum computers to characterize many-body topological quantum matter.

</details>


### [29] [Evolutionary BP+OSD Decoding for Low-Latency Quantum Error Correction](https://arxiv.org/abs/2512.18273)
*Hee-Youl Kwak,Seong-Joon Park,Hyunwoo Jung,Jeongseok Ha,Jae-Won Kim*

Main category: quant-ph

TL;DR: 提出进化信念传播解码器，将可训练权重融入BP算法并通过差分进化算法优化，结合有序统计解码实现端到端优化，在表面码和量子LDPC码上取得更好解码性能和更低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 量子纠错码解码中，传统信念传播算法存在性能限制，特别是在低延迟约束下。需要开发更高效的自适应解码方法，通过优化权重参数来提升解码性能并降低计算复杂度。

Method: 提出进化信念传播解码器，将可训练权重集成到BP算法中，使用差分进化算法进行优化。该方法与有序统计解码结合，实现端到端优化。在表面码和量子低密度奇偶校验码上进行实验验证。

Result: 实验结果表明，EBP+OSD相比传统BP+OSD具有更好的解码性能和更低的计算复杂度，特别是在严格的低延迟约束下（5次BP迭代内）表现更优。

Conclusion: 进化信念传播解码器为量子纠错码提供了一种有效的优化解码方法，通过权重学习和端到端优化，在保持低计算复杂度的同时显著提升了解码性能。

Abstract: We propose an evolutionary belief propagation (EBP) decoder for quantum error correction, which incorporates trainable weights into the BP algorithm and optimizes them via the differential evolution algorithm. This approach enables end-to-end optimization of the EBP combined with ordered statistics decoding (OSD). Experimental results on surface codes and quantum low-density parity-check codes show that EBP+OSD achieves better decoding performance and lower computational complexity than BP+OSD, particularly under strict low latency constraints (within 5 BP iterations).

</details>


### [30] [Triple measurements uncertainty and the distinguishment between the separable and entangled states](https://arxiv.org/abs/2512.18374)
*Minyi Huang,Ray-Kuang Lee*

Main category: quant-ph

TL;DR: 本文为三个可观测量提供了不确定关系常数的新证明和物理解释，揭示了这些常数与可分离态和纠缠态区分之间的密切联系。


<details>
  <summary>Details</summary>
Motivation: 不确定性和纠缠都是量子理论中的核心概念。虽然已有研究揭示了三个可观测量不确定关系的最紧常数，但需要提供新的证明方法和物理解释，特别是阐明这些常数与量子态可分离性之间的深层联系。

Method: 为三个可观测量提供了不确定关系常数的替代证明方法，并给出了这些常数的物理解释。通过分析乘积形式和求和形式的不确定关系，建立了常数与量子态性质之间的联系。

Result: 研究结果表明，三个可观测量不确定关系中的常数与可分离态和纠缠态的区分密切相关。这些常数可以作为判断量子态是否纠缠的重要指标。

Conclusion: 本文不仅为三个可观测量不确定关系提供了新的证明视角，更重要的是揭示了不确定关系常数在量子态可分离性判别中的物理意义，深化了对不确定性与纠缠之间内在联系的理解。

Abstract: Uncertainty and entanglement are both profound and key concepts in quantum theory. For three observables, the tightest uncertainty constants for both product and summation forms are revealed. In this work, we give an alternative proof for three observables, also with a physical interpretation of the uncertainty constants. Our results show that such constants are intimately connected with the distinguishment between separable and entangled states.

</details>


### [31] [Size-Consistent Quantum Chemistry on Quantum Computers](https://arxiv.org/abs/2512.18395)
*Noah Garrett,Michael Rose,David A. Mazziotti*

Main category: quant-ph

TL;DR: 该研究系统评估了量子硬件上的尺寸一致性，通过模拟非相互作用的H₂分子系统，发现当前量子设备在化学相关系统尺寸上能保持尺寸一致性，支持可扩展、抗噪声的强关联分子模拟可行性。


<details>
  <summary>Details</summary>
Motivation: 混合量子-经典算法已开始利用量子设备高效表示多电子波函数，但可扩展量子化学的关键前提是尺寸一致性。虽然许多算法理论上具有尺寸一致性，但量子设备上的噪声可能耦合名义上独立的子系统并破坏这一基本性质。

Method: 通过模拟由增加数量的非相互作用H₂分子组成的系统，使用最优浅层酉电路，在量子硬件上系统评估尺寸一致性。

Result: 分子能量在化学精度内保持尺寸一致性，对于单量子比特和双量子比特酉设计，分别估计可处理118和71个H₂子系统，表明当前量子设备在化学相关系统尺寸上能保持尺寸一致性。

Conclusion: 当前量子设备在化学相关系统尺寸上能保持尺寸一致性，这支持了可扩展、抗噪声的强关联分子和材料模拟的可行性。

Abstract: Hybrid quantum-classical algorithms have begun to leverage quantum devices to efficiently represent many-electron wavefunctions, enabling early demonstrations of molecular simulations on real hardware. A key prerequisite for scalable quantum chemistry, however, is size consistency: the energy of non-interacting subsystems must scale linearly with system size. While many algorithms are theoretically size-consistent, noise on quantum devices may couple nominally independent subsystems and degrade this fundamental property. Here, we systematically evaluate size consistency on quantum hardware by simulating systems composed of increasing numbers of non-interacting H$_{2}$ molecules using optimally shallow unitary circuits. We find that molecular energies remain size-consistent within chemical accuracy for an estimated 118 and 71 H$_{2}$ subsystems for one- and two-qubit unitary designs, respectively, demonstrating that current quantum devices preserve size consistency over chemically relevant system sizes and supporting the feasibility of scalable, noise-resilient simulation of strongly correlated molecules and materials.

</details>


### [32] [There is No Quantum World](https://arxiv.org/abs/2512.18400)
*Jeffrey Bub*

Main category: quant-ph

TL;DR: 本文提出了一种新玻尔式量子力学解释，既遵循玻尔的核心思想，又通过"新"前缀体现创新。同时利用冯·诺依曼的无限直积理论框架消解测量问题，为玻尔的经典概念优先性提供理论依据。


<details>
  <summary>Details</summary>
Motivation: 量子力学的解释问题长期存在争议，玻尔的观点虽然深刻但缺乏严格数学基础。本文旨在重新诠释玻尔思想，为其提供更坚实的理论框架，特别是解决测量问题这一核心难题。

Method: 采用新玻尔式解释框架，结合冯·诺依曼的无限直积数学理论。通过分析无限直积的数学结构，展示其如何自然地消解量子测量中的悖论问题。

Result: 成功构建了新玻尔式量子力学解释，证明冯·诺依曼的无限直积理论能够为玻尔的经典概念优先性提供数学基础，并有效消解传统测量问题。

Conclusion: 新玻尔式解释为量子力学提供了连贯的解释框架，既保留了玻尔的核心洞见，又通过现代数学工具解决了其理论缺陷，特别是为测量问题和经典概念的地位提供了严格的理论依据。

Abstract: I outline a neo-Bohrian interpretation of quantum mechanics -- a view of quantum mechanics that accords with the core insights in Bohr's thinking, with a twist that justifies the prefix `neo.' In a second part of the paper, I show how von Neumann's work on infinite direct products provides a theoretical framework that deflates the measurement problem and justifies Bohr's insistence on the primacy of classical concepts.

</details>


### [33] [Partner-mode overlap as a symplectic-invariant measure of correlations in Gaussian Systems](https://arxiv.org/abs/2512.18410)
*Ivan Agullo,Eduardo Martín-Martínez,Sergi Nadal-Gisbert,Koji Yamaguchi*

Main category: quant-ph

TL;DR: 该论文引入了一种局部辛不变的相关性度量$\mathcal{D}^{\mathrm{sym}}$，用于量化玻色高斯系统中任意两个模式之间的关联，并建立了基于该量的两模纠缠判据。


<details>
  <summary>Details</summary>
Motivation: 研究高斯系统中模式间相关性的量化方法，特别是希望建立一种具有几何解释且能直观反映纠缠空间分布的度量工具。

Method: 基于伙伴模式框架，利用高斯态的复结构描述，构建了局部辛不变的相关性度量$\mathcal{D}^{\mathrm{sym}}$，该量可解释为每个模式与另一模式净化伙伴之间的重叠度。

Result: 提出了基于$\mathcal{D}^{\mathrm{sym}}$的两模纠缠的充要判据，为"纠缠存在于伙伴模式空间支撑上"这一直觉提供了定量基础，并通过闵可夫斯基时空中标量场的数值分析验证了框架。

Conclusion: $\mathcal{D}^{\mathrm{sym}}$为高斯系统中的相关性分析提供了有效的几何工具，能够直观理解纠缠的空间分布，并可扩展到多模系统和混合高斯态。

Abstract: We introduce a locally symplectic-invariant quantifier of correlations between two different arbitrary modes in bosonic Gaussian systems, denoted by $\mathcal{D}^{\mathrm{sym}}$. This quantity admits a simple geometric interpretation as an overlap between each mode and the purification partner of the other, formulated using the complex-structure description of Gaussian states. The construction builds on the partner-mode framework of Ref.~\cite{agullo_correlation_2025} and can be viewed as a symmetrized extension of earlier overlap-based measures~\cite{osawa2025entanglement}. We formulate a simple necessary and sufficient criterion for two-mode entanglement in Gaussian states in terms of $\mathcal{D}^{\mathrm{sym}}$, placing on firm quantitative footing the intuition that entanglement with a given localized mode `lives' on the spatial support of its partner mode. We illustrate the framework with a numerical analysis of a scalar field in Minkowski spacetime and discuss its extension to multimode systems and mixed Gaussian states.

</details>


### [34] [Analog Quantum Image Representation with Qubit-Frugal Encoding](https://arxiv.org/abs/2512.18451)
*Vikrant Sharma,Neel Kanth Kundu*

Main category: quant-ph

TL;DR: 提出一种面向中性原子量子设备的新型量子图像表示范式，通过地图制图泛化算法将边缘提取图像转换为稀疏点几何描述，然后嵌入原子配置中，避免了传统量子图像处理中昂贵的状态准备开销。


<details>
  <summary>Details</summary>
Motivation: 传统量子图像处理电路存在状态准备开销大的问题，需要一种更高效的量子图像表示方法，特别针对中性原子量子设备的特性进行优化，实现资源高效的图像处理。

Method: 1. 对经典边缘提取输入图像应用地图制图泛化算法，生成高度优化的稀疏点几何描述；2. 将稀疏表示嵌入Aquila中性原子量子设备的原子配置中；3. 通过物理原子位置而非数字基态编码来编码视觉信息；4. 通过类似地图特征减少的稀疏点图像修剪来压缩表示。

Result: 成功实现了量子原生图像表示，并通过与图像数据库的匹配任务验证了可行性。稀疏点表示显著减少了量子比特需求，同时保持了图像的结构完整性，为图像匹配应用提供了有效解决方案。

Conclusion: 这项工作为视觉数据的完全量子原生机器学习管道迈出了第一步，展示了可扩展的模拟量子计算在实现资源高效替代能源密集型经典AI图像处理框架方面的潜力。

Abstract: In this work, we introduce a fundamentally new paradigm for quantum image representation tailored for neutral-atom quantum devices. The proposed method constructs a qubit-efficient image representation by first applying a cartographic generalization algorithm to a classical edge-extracted input image, yielding a highly optimized sparse-dot based geometric description. While ensuring the structural integrity of the image, this sparse representation is then embedded into the atomic configuration of Aquila (QuEra Computing Inc.), modeled through the Bloqade simulation software stack. By encoding visual information through physical atom placement rather than digital basis-state coding, the approach avoids the costly state-preparation overhead inherent to digital quantum image processing circuits. Additionally, pruning sparse dot images, akin to map feature reduction, compresses representations without fidelity loss, thereby substantially reducing qubit requirements when implemented on an analog neutral-atom quantum device. The resulting quantum-native images have been successfully evaluated through matching tasks against an image database, thus illustrating the feasibility of this approach for image matching applications. Since sparse-dot image representations enable seamless generation of synthetic datasets, this work constitutes an initial step towards fully quantum-native machine-learning pipelines for visual data and highlights the potential of scalable analog quantum computing to enable resource-efficient alternatives to energy-intensive classical AI-based image processing frameworks.

</details>


### [35] [Hierarchical divide and conquer quantum approach to combinatorial optimization problems with tunable reduction](https://arxiv.org/abs/2512.18464)
*Mathias Schmid,Naeimeh Mohseni,Michael J. Hartmann*

Main category: quant-ph

TL;DR: 提出一种量子计算的分治方法，将大规模组合优化问题分解为可在较小量子处理器上处理的子图，通过能量范围筛选可能解，显著减少所需量子比特数。


<details>
  <summary>Details</summary>
Motivation: 实际组合优化问题通常包含的变量数量远超当前或可预见量子计算机的量子比特数，需要开发能够处理大规模问题的量子算法。

Method: 采用分治策略：1) 将优化问题划分为可在小量子处理器上表示的子图；2) 通过确定局部子图能量的允许范围，筛选可能成为全局解的状态；3) 使用二进制编码和局部能量排序重新组合系统；4) 迭代此过程直至无法进一步简化。

Result: 在数值模拟中，该方法能够用约|V|/4个量子比特解决40个离散变量的加权随机3-正则图组合优化问题，同时保持约99.9%的近似比。系统规模越大，量子比特减少效果越明显。

Conclusion: 该分治方法显著减少了解决大规模组合优化问题所需的量子比特数，使量子计算机能够处理远超其量子比特数量的实际问题，同时保持高近似精度。

Abstract: Combinatorial optimization is considered a promising class of problems in which quantum computers can show significant advantages. However, problems of practical relevance typically have more variables than current or foreseeable quantum computers have qubits. Here we introduce a divide and conquer approach that partitions the optimization problem into subgraphs that can be represented on smaller quantum processors. We then find all states of the subgraphs that can possibly be part of the solution to the entire problem by determining the cost or energy ranges in which the local subgraph energies of these states must be contained. This allows us to reduce the problem by only considering the subspace spanned by these states. We then recombine the system using a binary encoding for each subgraph with a local energy ordering. This process can be iterated until no further reduction is possible. We also find that the number of necessary qubits can be reduced further when only retaining states in a fraction of the relevant energy range at very little expense in terms of approximation ratio to the global ground state. In numerical simulations, we find that our approach allows us to solve combinatorial optimization problems on weighted random 3-regular graphs with $|\mathcal{V}|=40$ discrete variables on $\sim |\mathcal{V}| / 4$ qubits while retaining a possible approximation ratio of $\sim99.9\%$. We also observe an increasing reduction with larger system sizes.

</details>


### [36] [Position-Resolved Resonance Quantization for Lossy Cavities](https://arxiv.org/abs/2512.18478)
*Lucas Weitzel,Andreas Buchleitner,Dominik Lentrodt*

Main category: quant-ph

TL;DR: 提出了一种新的量子谐振腔理论方法，将离散模式模型系统化，通过位置分辨的离散模式量化谐振腔共振，自然包含损耗，统一了伪模式和量化准正态模式理论的关键思想。


<details>
  <summary>Details</summary>
Motivation: 随着谐振腔实验进入更极端的量子区域，传统的少模模型在处理高度开放腔体和扩展系统（如分子和固态系统）时遇到限制，需要新的理论方法来应对这些挑战。

Method: 开发了一种新的理论框架，通过位置分辨的离散模式来量化谐振腔的共振，这种方法自然包含了损耗机制。该方法统一了伪模式和量化准正态模式理论的关键概念，并提出了构建空间各点参数的标准。

Result: 该方法在典型的一维谐振腔示例中进行了半解析基准测试，验证了其有效性。新方法显著扩展了离散模式模型的概念基础，使其能够系统化处理极端量子区域的问题。

Conclusion: 提出的新方法为处理高度开放谐振腔和扩展系统提供了系统化的理论框架，解决了传统少模模型在极端量子区域的局限性，有望推动谐振腔实验的理论发展。

Abstract: Modern experiments in resonators are moving to ever more extreme quantum regimes, posing major challenges to established theoretical approaches, such as so-called few-mode models. While these models have driven major insights for traditional regimes, they are now hitting their limitations for highly open cavities and extended systems, as encountered in cavity experiments with molecules and solid-state systems. Here, we present a novel method that significantly extends the conceptual underpinning of these discrete-mode models, promoting them to a systematic treatment. We develop an ansatz which allows to quantize the resonator's resonances with position-resolved discrete modes, thus naturally incorporating losses in the formalism. Such a construction effectively unifies key ideas from pseudomodes and quantized quasi-normal modes theory. We further present a criterion for construction of the ansatz parameters at every point in space, and semi-analytically benchmark the resulting solution for a paradigmatic one-dimensional example resonator.

</details>


### [37] [Collective Dissipation and Parameter Sensitivity in Trapped Ions Coupled to a Common Thermal Reservoir](https://arxiv.org/abs/2512.18481)
*C. F. P. Avalos,G. A. Prataviera,M. C. de Oliveira*

Main category: quant-ph

TL;DR: 研究两个囚禁离子与共同热库相互作用时的动力学，重点关注交叉关联耗散对加热、稳态行为和参数敏感性的影响，发现交叉耗散可以产生集体衰减通道和退相干自由模式


<details>
  <summary>Details</summary>
Motivation: 研究两个囚禁离子与共同热库相互作用时的动力学特性，特别关注交叉关联耗散如何影响系统的加热过程、稳态行为以及参数敏感性，探索热库诱导的关联效应

Method: 从微观系统-热库模型出发，推导相应的海森堡-朗之万方程，分析交叉耗散效应；使用费舍尔信息关联运动布居测量来识别参数估计的最佳区域

Result: 热库诱导的关联产生集体衰减通道；当交叉阻尼率与局部阻尼匹配时，会出现退相干自由正常模式，能保持初始激发的记忆；交叉阻尼增强了系统和热库性质的可估计性；对于非经典初始态，热库介导的关联可以产生或维持纠缠，最强效应出现在退相干自由条件附近

Conclusion: 交叉关联耗散在囚禁离子系统中起着重要作用，不仅能产生集体衰减和退相干自由模式，还能增强参数估计能力，并在特定条件下维持量子纠缠，为量子信息处理和精密测量提供了新的可能性

Abstract: We investigate the dynamics of two trapped ions interacting with a common thermal reservoir, focusing on how cross-correlated dissipation influences heating, steady-state behavior, and parameter sensitivity. Starting from a microscopic system--reservoir model, we derive the corresponding Heisenberg--Langevin equations and show that reservoir-induced correlations generate collective decay channels and, when the cross-damping rate matches the local damping, a decoherence-free normal mode that preserves memory of the initial excitations. Using the Fisher information associated with motional population measurements, we identify the parameter regimes in which cross-damping enhances the estimability of both system and reservoir properties. For nonclassical initial states, we also show that reservoir-mediated correlations can generate or maintain entanglement, with the strongest effects occurring near the decoherence-free condition.

</details>


### [38] [Multifractality Analysis of Single Qubit Quantum Circuit Outcomes for a Superconducting Quantum Computer](https://arxiv.org/abs/2512.18491)
*Mohammadreza Saghafi,Lamine Mili,Karlton Wirsing*

Main category: quant-ph

TL;DR: 对IBM超导量子计算机单量子比特电路输出数据进行多重分形分析，发现其时间序列具有强多重分形特性，表明量子电路输出的时间波动具有复杂的多尺度标度特性。


<details>
  <summary>Details</summary>
Motivation: 研究量子电路输出数据的时间序列特性，探索量子系统在重复测量下的动态性质，为近量子设备的噪声抑制技术提供新思路。

Method: 使用小波领导方法和多重分形去趋势波动分析等先进信号处理技术，对IBM超导量子计算机单量子比特电路的测量结果（记录为零的数量）进行多重分形分析。

Result: 在输出数据中发现了强多重分形行为，表明量子电路输出的时间波动不是纯粹的随机噪声，而是具有跨多个时间尺度的复杂标度特性。

Conclusion: 量子电路输出具有多重分形特性，这为针对这些标度特征定制滤波策略以有效抑制量子计算中的噪声提供了可能性，为改进近量子设备的噪声抑制技术开辟了有前景的途径。

Abstract: We present a multifractal analysis of time series data obtained by repeatedly running a single-qubit quantum circuit on IBM superconducting quantum computers, in which the measurement outcomes are recorded as the number of zeros. By applying advanced signal processing techniques, including the wavelet leader method and multifractal detrended fluctuation analysis, we uncover strong multifractal behavior in the output data. This finding indicates that the temporal fluctuations inherent to quantum circuit outputs are not purely random but exhibit complex scaling properties across multiple time scales. The multifractal nature of the signal suggests the possibility of tailoring filtering strategies that specifically target these scaling features to effectively mitigate noise in quantum computations. Our results not only contribute to a deeper understanding of the dynamical properties of quantum systems under repeated measurement but also provide a promising avenue for improving noise reduction techniques in near-term quantum devices.

</details>


### [39] [Quantum Nonlocality and Device-Independent Randomness Robust to Relaxations of Bell Assumptions](https://arxiv.org/abs/2512.18513)
*Ravishankar Ramanathan,Yuan Liu*

Main category: quant-ph

TL;DR: 该论文研究了在贝尔定理假设放松条件下量子非定域性的认证，证明了在测量独立性和参数独立性同时放松时，恒定局部维度的量子态已足够认证非定域性，并分析了这对设备无关随机性认证的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在贝尔定理假设放松条件下认证量子非定域性的可能性，这对于在弱种子和串扰条件下的设备无关应用具有重要意义。当前研究需要多项式维度的量子态，本文旨在探索是否可以用更简单的量子系统实现。

Method: 引入"测量依赖参数依赖定域性"概念，严格刻画了在MI和PI放松条件下的联合输入输出行为的顶点多面体。通过理论分析，研究了在CHSH贝尔测试中量子猜测概率与噪声和输入信息泄露的关系。

Result: 1) 证明了恒定局部维度的量子态已足以在任意MI和PI放松条件下认证量子非定域性（虽然是非鲁棒的）。2) 发现了非定域性认证与探测效率之间的联系，指出了在双输入场景中达到η=2/3探测效率的替代极值关联。3) 解析推导了CHSH测试中量子猜测概率与噪声和输入信息泄露的函数关系。

Conclusion: 该研究显著改进了量子非定域性认证的理论框架，证明了在放松假设下可以使用更简单的量子系统，为设备无关应用在现实条件下的实现提供了理论基础，特别是在随机性认证方面具有重要意义。

Abstract: The question of certifying quantum nonlocality under a relaxation of the assumptions in the Bell theorem has gained traction, with potential for device-independent applications under weak seeds and cross-talk. Recently, it was shown that quantum nonlocality can be certified even under a simultaneous arbitrary (but not full) relaxation of the assumptions of Measurement Independence (MI) and Parameter Independence (PI), using states of local dimension $d = poly((1-ε)^{-1})$ for an $ε\in [0,1)$-relaxation. Here, we derive three results strengthening the state-of-art. Firstly, we show that states of constant local dimension $d$ are already sufficient to certify quantum nonlocality under arbitrary MI and PI relaxation, albeit in a non-robust manner. Secondly, and as a theoretical paradigm to derive the above, we introduce the notion of \textit{measurement-dependent parameter-dependent locality} as the set of input-output behaviors under simultaneous relaxations of measurement and parameter independence. We provide a rigorous characterisation of the vertices of the polytope of joint input-output behaviors that obey a $μ$-relaxation of MI and $ε$-relaxation of PI. We highlight a relation between nonlocality certification under PI relaxation and that under detection inefficiencies by pointing out alternative extremal correlations to the Eberhard correlations that also allow to achieve detection efficiency of $η= 2/3$ in the two-input scenario. Finally, we study the implication of the relaxed assumptions for device-independent randomness certification. We analytically derive the quantum guessing probability for one player's outcomes in the CHSH Bell test, as a function of the noise in the test as well as of a leakage of an average amount of $I(X:B) < 1$ bits of input information per measurement round.

</details>


### [40] [Read-Only Opacity and Restricted-Access Inference on Quantum Memories via U-QRAM](https://arxiv.org/abs/2512.18526)
*Leonardo Bohac*

Main category: quant-ph

TL;DR: U-QRAM是一种固定的数据无关幺正接口，用于实现相对于内存寄存器中指定计算"真值表"基的相干随机访问读取。本文研究了受限访问推理：内存寄存器是持久但不可访问的，而实验者只能准备和测量可访问寄存器，并可以调用固定的读取交互。


<details>
  <summary>Details</summary>
Motivation: 研究在内存寄存器持久但不可访问的情况下，仅通过固定读取交互进行推理的限制。探索当内存处于任意量子态时，只读访问的基本局限性。

Method: 建立协议无关的限制：对于任何有限查询协议（包括任意可访问辅助系统、中间测量、自适应性和查询间的一般CPTP处理），可访问寄存器上的诱导输出状态仅通过内存状态在真值表基中的对角线部分依赖于内存状态。

Result: 只读访问通过该基的去相位（夹紧）进行因子分解；不同真值表之间的相干性在操作上是不可见的。每个内存假设检验任务都简化为可访问寄存器上的标准状态判别问题，最小误差最优测量由Helstrom理论表征。

Conclusion: 通过三个具体示例说明该框架：（i）相位反冲约简恢复单查询Bernstein-Vazirani/Deutsch-Jozsa几何；（ii）成功概率为3/4的最小Helstrom实例；（iii）纠缠真值表叠加中相对相位的完美不可区分性。

Abstract: Universal QRAM (U-QRAM) is a fixed, data-independent unitary interface that implements coherent random-access reads relative to a designated computational "truth-table" basis on the memory register. This work studies restricted-access inference: the memory register is persistent but inaccessible, while an experimenter may prepare and measure only accessible registers and may invoke the fixed read interaction.
  Allowing the memory to be in an arbitrary quantum state (pure or mixed, possibly entangled with an inaccessible reference system, or a coherent superposition of truth tables), we establish a sharp, protocol-independent limitation of read-only access. For any finite-query protocol -- including arbitrary accessible ancillas, intermediate measurements, adaptivity, and general CPTP processing between queries -- the induced output state on the accessible registers depends on the memory state only through its diagonal in the truth-table basis. Equivalently, read-only access factors through dephasing (pinching) in that basis; coherences between distinct truth tables are operationally invisible.
  Consequently, every memory-hypothesis testing task reduces to a standard state-discrimination problem on the accessible registers, and the minimum-error optimal measurement is characterized by Helstrom theory. We illustrate the framework with three explicit examples: (i) the phase-kickback reduction recovering the one-query Bernstein-Vazirani/Deutsch-Jozsa geometry, (ii) a minimal Helstrom instance with optimal success probability 3/4, and (iii) perfect indistinguishability of relative phases in entangled truth-table superpositions.

</details>


### [41] [A regularisation method to obtain analytical solutions to de Broglie-Bohm wave equation](https://arxiv.org/abs/2512.18555)
*Anand Aruna Kumar,S. K. Srivatsa,Rajesh Tengli*

Main category: quant-ph

TL;DR: 该论文提出了一种结合哈密顿-雅可比方程、连续性方程和信息论概念的分析方法，用于求解德布罗意-玻姆方程，通过引入费舍尔信息项构建作用泛函，得到参数等效的dBB方程形式。


<details>
  <summary>Details</summary>
Motivation: 从统计角度出发，粒子运动的概率描述为从经典力学到量子力学的过渡提供了中间立场。作者旨在开发一种正则化方法，避免直接使用普朗克常数，而是引入参数化的信息-误差耦合项，专注于能量态的求解。

Method: 结合哈密顿-雅可比方程、连续性方程和信息论概念，通过耦合费舍尔信息项构建作用泛函，得到参数等效的德布罗意-玻姆方程形式。使用广义欧拉-拉格朗日方程为简单定态系统提供dBB方程的解析解。

Result: 通过一维和二维示例展示了常规量子力学与该方法获得的波函数之间的相似性和差异。该方法保留了普适性，不使用普朗克常数，而是引入参数化信息-误差耦合项μ。

Conclusion: 该方法专注于正则化方法及其对能量态的影响，为求解德布罗意-玻姆方程提供了新的分析框架。基础方面的正式解释留待后续研究。

Abstract: We present an analytical method to solve de Broglie Bohm equation for the wave function by combining concepts from the Hamilton Jacobi equations of mechanics, continuity equations, and information theory. From a statistical point of view, the probabilistic description of particle motion provides a middle ground for transitioning from classical to quantum mechanics. An action functional obtained by coupling a Fisher information term produces a parametrically equivalent form of the de Broglie Bohm dBB equations. Next, we show that generalized Euler Lagrange equations can provide analytical solutions of dBB equations for certain simple stationary systems. One- and two-dimensional examples are provided to illustrate the similarities and differences between regular QM and the wave functions obtained from our generalization. To retain the generality of the method, we do not use hbar apriori but instead introduce a parametric information-error coupling term, mu. Our emphasis is strictly limited to the regularization method and its implications for energy states. We defer formal interpretations of the foundational aspects of this subject to a separate communication.

</details>


### [42] [A Hidden Quantum Markov model framework for Entanglement and Topological Order in the AKLT Chain](https://arxiv.org/abs/2512.18642)
*Abdessatar Souissi,Amenallah Andolsi*

Main category: quant-ph

TL;DR: 将隐藏量子马尔可夫模型框架应用于AKLT态，建立了量子机器学习与多体物理之间的桥梁，展示了SPT序对观测解码通道的协方差影响。


<details>
  <summary>Details</summary>
Motivation: 将量子机器学习中的隐藏量子马尔可夫模型框架引入到多体物理中的AKLT态研究，旨在建立量子机器学习与多体物理之间的新联系，探索对称性保护拓扑序在量子信息处理中的潜在应用。

Method: 采用隐藏量子马尔可夫模型框架，将物理自旋-1链作为观测系统，该链通过量子发射操作从隐藏的自旋-1/2层中涌现。研究底层马尔可夫动力学如何通过AKLT态相关的显著通道捕获最大纠缠。

Result: 研究表明底层马尔可夫动力学能够通过AKLT态相关的显著通道捕获最大纠缠。同时发现对称性保护拓扑序会在观测解码通道上诱导协方差，这为理解拓扑序与量子信息处理之间的关系提供了新视角。

Conclusion: 该工作成功建立了量子机器学习与多体物理之间的新桥梁，展示了对称性保护拓扑序对观测解码通道的协方差影响，在拓扑序和量子信息领域具有重要的应用前景。

Abstract: This paper introduces a hidden quantum Markov models (HQMMs) framework to the Affleck-Kennedy-Lieb-Tasaki (AKLT) state-a cornerstone example of a symmetry-protected topological (SPT) phase. The model's observation system is the physical spin-1 chain, which emerges from a hidden spin-1/2 layer through well-defined quantum emission operation. We show that the underlying Markov dynamics caputure maximal entanglement through the use of significant channels relevant to the AKLT state. We also show that SPT order induces a covariance on the observation decoding channels. This establishes an additional bridge between the quantum Machine learning and many-body physics, with promising implication in topological order and quantum information.

</details>


### [43] [Toward Live Noise Fingerprinting in Quantum Software Engineering](https://arxiv.org/abs/2512.18667)
*Avner Bensoussan,Elena Chachkarova,Karine Even-Mendoza,Sophie Fortz,Vasileios Klimis*

Main category: quant-ph

TL;DR: 提出SimShadow方法，通过经典影子层析技术实现轻量级噪声指纹识别，用于量子软件工程任务，成本比传统方法降低250万倍。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的噪声是主要瓶颈，但不同量子生态系统间的噪声模型差异未被充分记录，这影响了编译、调试等核心功能，限制了量子软件工程任务的移植性和支持。

Method: 提出SimShadow方法：1) 准备参考状态；2) 应用影子层析启发的估计技术；3) 构建偏差指纹。该方法将经典影子层析技术重新定位为量子软件工程范式。

Result: 初步实验发现平台间存在系统性差异（Frobenius距离高达7.39），成本比传统方法降低高达250万倍（2.5x10^6倍）。

Conclusion: SimShadow为噪声感知编译、跨平台验证、错误缓解和量子软件工程中的形式化方法开辟了新方向，实现了轻量级、面向量子软件工程的噪声指纹识别。

Abstract: Noise is a major bottleneck in today's quantum computing, stemming from decoherence, gate imperfections and other hardware limitations. Accurate noise fingerprints are essential, yet undocumented noise model differences between Quantum Ecosystems undermine core functionality, such as compilation, development and debugging, offering limited transferability and support for quantum software engineering (QSE) tasks. We propose a new research direction: live empirical noise fingerprinting as a lightweight QSE-oriented "noise fingerprinting". Though explored in physics as device-level diagnostics, we reposition them as a QSE paradigm: we propose leveraging classical shadow tomography to enable a new generation of techniques. As a first step, we introduce SimShadow, which prepares reference states, applies shadow-tomography-inspired estimation and constructs deviation fingerprints. Initial experiments uncover systematic discrepancies between platforms (e.g. Frobenius distances up to 7.39) at up to 2.5x10^6 lower cost than traditional methods. SimShadow opens new directions for noise-aware compilation, transpilation, cross-platform validation, error mitigation, and formal methods in QSE.

</details>


### [44] [Temperature-enhanced quantum sensing for the cutoff frequency of Ohmic environments](https://arxiv.org/abs/2512.18686)
*Yuan Ji-Bing,Song Ya-Ju,Tang Shi-Qing,Wang Xin-Wen,Kuang Le-Man*

Main category: quant-ph

TL;DR: 研究退相干量子比特在欧姆环境中作为探针的量子传感性能，发现温度可以作为资源提升传感精度，在特定条件下灵敏度可提高近两个数量级。


<details>
  <summary>Details</summary>
Motivation: 研究量子比特在欧姆环境中的量子传感性能，特别是温度对传感精度的影响，探索温度是否可以作为提升量子传感性能的资源。

Method: 使用退相干量子比特作为探针，在欧姆环境中研究其量子传感性能。通过耦合强度η、欧姆参数s、截止频率ωc等参数表征环境，用量子信噪比Q量化性能，分析Q随标度时间ωct的演化。

Result: 发现Q随ωct的演化与ωc无关，在最优时间topt达到峰值Qopt。在ωctopt≪1条件下，Qopt总能达到上限：零温时Qmax=0.648，高温时达到Qmax/4。温度提升可使Qopt比零温时提高近两个数量级。

Conclusion: 温度可以作为资源增强量子传感精度，因为它加速了截止频率信息编码到探针状态的过程，从而在短时间内实现最优测量。这一发现对量子传感技术有重要意义。

Abstract: We investigate the quantum sensing performance of a dephasing qubit as a probe in Ohmic environments, characterized by the coupling strength $η$, the Ohmicity parameter $s$, and the cutoff frequency $ω_c$ to be estimated. The performance is quantified by the dimensionless quantum signal-to-noise ratio $\mathcal{Q}$. We show that the evolution of $\mathcal{Q}$ with the scaled time $ω_c t$ is independent of $ω_c$, and peaks at an optimal time $t_{\text{opt}}$, yielding optimal sensitivity $\mathcal{Q}_{\text{opt}}$. We analyze how $\mathcal{Q}_{\text{opt}}$ depends on $η$, $s$ and the temperature $T$. Our results demonstrate that, for any Ohmic environment, provided that $ω_c t_{\text{opt}} \ll 1$, $\mathcal{Q}_{\text{opt}}$ always reaches the upper bound: $\mathcal{Q}_{\text{max}} = 0.648$ at zero temperature, and consistently attains $\mathcal{Q}_{\text{max}}/4$ at high temperatures. Remarkably, we find that increasing the scaled temperature $T/ω_c$ can enhance $\mathcal{Q}_{\text{opt}}$ by nearly two orders of magnitude compared to its zero-temperature counterpart for certain Ohmic environments. Our work reveals that temperature can serve as a resource to enhance sensing precision, as it accelerates the encoding of the cutoff frequency information into the probe state, thereby enabling optimal measurement within a short time window.

</details>


### [45] [A graphical framework for proving holographic entanglement entropy inequalities in multipartite systems](https://arxiv.org/abs/2512.18726)
*Chia-Jui Chou,Hans B. Lao,Yi Yang*

Main category: quant-ph

TL;DR: 提出了一种证明多体系统全息纠缠熵不等式的图形化方法，通过几何表示纠缠结构，系统性地可视化和验证任意子系统数n的HEIs有效性。


<details>
  <summary>Details</summary>
Motivation: 全息纠缠熵不等式在多体量子系统中具有重要意义，但传统证明方法复杂且难以推广到任意子系统数。需要一种更直观、系统的方法来验证这些不等式。

Method: 引入纠缠结构的几何表示，开发系统化的图形化方法，建立多个定理来形式化这一方法，并通过n=4到7的纠缠区域提供具体示例。

Result: 建立了证明全息纠缠熵不等式的图形化框架，能够处理任意数量的子系统，并在4到7个纠缠区域的系统中进行了验证。

Conclusion: 提出的图形化方法为全息纠缠熵不等式提供了直观且系统的证明工具，简化了多体系统中纠缠结构的分析和验证过程。

Abstract: We present a graphical method for proving holographic entanglement entropy inequalities (HEIs) in general multipartite systems. By introducing a geometric representation of the entanglement structure, we develop a systematic approach that enables one to visualize and verify the validity of HEIs for any number of subsystems $n$. Several theorems are established to formalize this method, and explicit examples are provided for systems with $n = 4$ to $7$ entangled regions.

</details>


### [46] [Interplay of Confinement and Localization in a Programmable Rydberg Atom Chain](https://arxiv.org/abs/2512.18765)
*Andrea B. Rava,Jhon A. Montanez-Barrera,Kristel Michielsen,Jaka Vodeb*

Main category: quant-ph

TL;DR: 该研究通过实验和模拟相结合的方法，系统分析了里德堡原子链量子模拟器中关联传播的动力学行为，重点关注了约束效应和有效无序对量子动力学的影响，并建立了诊断量子处理器中误差诱导局域化的实用框架。


<details>
  <summary>Details</summary>
Motivation: 量子模拟器的性能受限于设备缺陷与内在物理机制之间的竞争。本研究旨在深入理解在可编程里德堡原子链中，约束效应和有效无序如何共同影响关联传播动力学，为诊断和建模量子处理器中的误差诱导局域化提供实用框架。

Method: 使用QuEra的Aquila量子处理器进行实验，实现纵向场横向场伊辛模型。同时使用Juelich量子退火模拟器(JUQAS)进行大规模相干模拟，可控地包含实际硬件缺陷。通过对比实验数据和含噪声模拟结果，分析约束效应和有效无序对关联传播的影响。

Result: 在理想相干极限下，可调纵向场将畴壁激发约束为介子束缚态，导致关联光锥逐渐截断。当包含实验相关的不均匀性和涨落时，即使在名义上非约束区域，关联也在有限距离处饱和，揭示了由涌现无序驱动的局域化。含噪声模拟与实验数据的定量一致性良好，能够将观测到的饱和归因于特定的硬件误差通道并识别主导贡献。

Conclusion: 该研究建立了诊断和建模里德堡量子处理器中误差诱导局域化的实用框架，同时证明了约束效应仍然是近期量子硬件上工程非遍历动力学的鲁棒且可编程机制。约束效应与有效无序的相互作用决定了量子模拟器中关联传播的最终行为。

Abstract: Analog quantum simulators promise access to complex many-body dynamics, yet their performance is ultimately set by how device imperfections compete with intrinsic physical mechanisms. Here we present an end-to-end study of correlation spreading in a programmable Rydberg-atom chain realizing a longitudinal-field transverse-field Ising model, focusing on the joint impact of confinement and effective disorder. Experiments performed on QuEra's Aquila quantum processor are benchmarked against large-scale coherent emulations using the Juelich Quantum Annealing Simulator (JUQAS), enabling the controlled inclusion of realistic hardware imperfections. In the ideal coherent limit, a tunable longitudinal field induces confinement of domain-wall excitations into mesonic bound states, leading to a progressive truncation of the correlation light cone. When experimentally relevant inhomogeneities and fluctuations are included, correlations instead saturate at finite distance even in the nominally deconfined regime, revealing localization driven by emergent disorder. The close quantitative agreement between noisy emulations and experimental data allows us to attribute the observed saturation to specific hardware error channels and to identify the dominant contribution. Our results establish a practical framework for diagnosing and modeling error-induced localization in Rydberg quantum processors, while demonstrating that confinement remains a robust and programmable mechanism for engineering non-ergodic dynamics on near-term quantum hardware.

</details>


### [47] [Long-distance quantum communication sending single photons and keeping many](https://arxiv.org/abs/2512.18767)
*Stefan Häussler,Peter van Loock*

Main category: quant-ph

TL;DR: 提出一种基于全光学量子存储器的量子中继器方案，使用光纤环路作为量子存储器，结合量子纠错码保护光子损耗，可在现有经典基础设施的长距离段上运行。


<details>
  <summary>Details</summary>
Motivation: 现有全光量子通信协议要么需要每几公里进行复杂的量子纠错步骤，要么需要共享复杂的多光子纠缠态。需要一种与经典光纤通信基础设施兼容的全光量子通信系统，能够在类似50-100公里的间隔上运行。

Method: 提出基于全光学量子存储器的量子中继器方案，每个中继站使用光纤环路作为量子存储器，结合量子纠错码（如Gottesman-Kitaev-Preskill码、Steane码、单光子量子奇偶校验码）进行光子损耗保护。仅通过光纤发送单光子态连接各站。

Result: 分析了该方案在Gottesman-Kitaev-Preskill码（包括与Steane码的级联）以及单光子量子奇偶校验码下的性能，适用于总距离达10000公里的长距离量子通信。

Conclusion: 该全光学量子中继器方案能够在现有经典基础设施的长距离段上运行，仅需发送单光子态，避免了现有全光量子通信协议的复杂要求，为长距离量子通信提供了实用解决方案。

Abstract: Fiber-based classical communication is all-optical and uses light pulses reamplified and reshaped every 50-100 km in classical repeaters. Most compatible with this would be a quantum communication system which is also all-optical with quantum processing units placed in similar intervals. However, existing all-optical quantum communication protocols either require complicated quantum error correction steps for logical-qubit recoveries at every few kilometers or, over larger quantum repeater segments, they would at least depend on sharing complex multi-photon entangled states. Here we propose an all-optical memory-based quantum repeater for long-distance quantum communication, with quantum memories at each repeater station realized in the form of fiber loops combined with suitable quantum error correction codes for photon-loss protection. By sending only single-photon states through the fibers connecting the stations, such repeaters can operate in the classical infrastructure's long-segment regime. We analyze the performance of our scheme for the Gottesman-Kitaev-Preskill code, including a concatenation with the Steane code, as well as the single-photon quantum parity code for total distances up to 10000 km.

</details>


### [48] [Chaos-controlled switching between entanglement and coherence](https://arxiv.org/abs/2512.18777)
*Kyu-Won Park,Soojoon Lee,Kabgyun Jeong*

Main category: quant-ph

TL;DR: 混沌控制下量子本征态资源可切换：软混沌与强混沌窗口中的避免交叉现象分别实现纠缠峰值模式或相干峰值模式，同一系统内可切换两种操作模式。


<details>
  <summary>Details</summary>
Motivation: 纠缠和相干性是量子信息处理的核心资源，但两者通常呈现对抗性趋势，难以在同一平台中同时优化。需要寻找能够控制这两种资源转换的机制。

Method: 使用两种波混沌台球系统和倾斜场伊辛链，追踪本征态在局域化杂交窗口中的信息论响应。通过避免交叉现象和本征函数纠缠、基相干性作为判别指标。

Result: 即使在避免交叉现象和离域化程度相似的情况下，软混沌与强混沌区域中的纠缠和相干响应会发生反转。在伊辛链中，单一微观旋钮（全局场倾斜）可在两种操作模式间切换。

Conclusion: 混沌能够实现可切换的本征态资源，提供了一种在单一系统中控制纠缠和相干性转换的新机制。该诊断方法仅需约化态（或其谱），与波混沌谐振器中的模式成像和可编程自旋模拟器中的随机化测量兼容。

Abstract: Controlling entanglement and coherence is central to quantum information, yet the two resources often exhibit antagonistic trends and are difficult to optimize within a single platform. Here we show that chaos enables switchable eigenstate resources: avoided crossings in soft- versus strong- chaos windows selectively realize an entanglement-peak mode or a coherence-peak mode within the same system. Crucially, this chaos-controlled inversion is not tied to a particular notion of subsystems, appearing both in single-wave settings and in genuine many-body settings. From the quantum-chaos perspective, conventional diagnostics based on avoided-crossing phenomenology and eigenmode delocalization are insufficient; eigenfunction entanglement and basis coherence provide the missing discriminants. Using two wave-chaotic billiards and a tilted-field Ising chain, we track the information-theoretic response of eigenstates across localized hybridization windows. Even when avoided-crossing phenomenology and delocalization are comparable, the entanglement and coherence responses invert between soft- and strong-chaos regimes. In the Ising chain, a single microscopic knob, the global field tilt, toggles between the two operating modes and reveals a trade-off in which off-diagonal correlations grow as diagonal populations dip. Our diagnostics require only reduced states (or their spectra) and are compatible with mode imaging in wave-chaos resonators and randomized measurements in programmable spin simulators.

</details>


### [49] [Singularity Selector: Topological Chirality via Non-Abelian Loops around Exceptional Points](https://arxiv.org/abs/2512.18789)
*Kyu-Won Park,KyeongRo Kim,Kabgyun Jeong*

Main category: quant-ph

TL;DR: 该论文将手性概念扩展到非厄米系统，定义了拓扑手性这一新不变量，它作为奇点选择器区分顺时针和逆时针环绕例外点的路径，并在光学微腔和非厄米拓扑能带中得到验证。


<details>
  <summary>Details</summary>
Motivation: 手性在自然界中普遍存在，从药物对映体选择性到粒子物理中的左手费米子，再到外尔半金属中的手性电荷输运。然而，手性概念在非厄米系统中的扩展尚未充分探索，特别是在具有例外点（EP）的系统中。

Method: 基于非交换基本群及其辫子表示，定义了拓扑手性这一拓扑不变量。该不变量作为奇点选择器：顺时针EP环路占据一个避免EP的同伦类，而逆时针环路仅当它们穿过EP本身时才等价。在光学微腔和非厄米拓扑能带中进行了验证。

Result: 拓扑手性作为二进制规则在实验系统中得到确认。该框架可无缝转移到自旋系统、光子晶体和光-物质混合结构中的EP对，证实了其实验可行性。通过平面粘合构造将不变量扩展到包含2m个EP的n层曲面，统一了高阶EP对。

Conclusion: 该研究为非厄米系统中的拓扑手性奠定了基础，为解释环路敏感可观测量如谱涡旋度、复Berry相位和非阿贝尔和乐提供了框架，统一了不同系统中的例外点拓扑。

Abstract: Chirality is more than a geometric curiosity; it governs measurable asymmetries across nature, from enantiomer-selective drugs and left-handed fermions in particle physics to handed charge transport in Weyl semimetals. We extend this universal concept to non-Hermitian systems by defining topological chirality, an invariant that emerges whenever an exceptional-points (EP) pair is present. Built from the non-commutative fundamental group and its braid representation, topological chirality acts as a singularity selector: clockwise EP loops occupy a homotopy class that avoids EPs, whereas counter-clockwise mirrors are equivalent only if they cross the EPs themselves. We confirm this binary rule in an optical microcavity and a non-Hermitian topological band. The same two-sheeted topology governs EP pairs in spin systems, photonic crystals and hybrid light-matter structures, where EP encirclements have already been demonstrated, so the framework transfers without alteration and confirms its experimental viability. Our findings lay the cornerstone for interpreting loop-sensitive observables such as spectral vorticity, the complex Berry phase and the non-Abelian holonomy. Finally, a gluing-of-planes construction extends the invariant to an n-sheeted surface hosting 2m EPs, unifying higher-order EP pairs.

</details>


### [50] [Foundation Model for Unified Characterization of Optical Quantum States](https://arxiv.org/abs/2512.18801)
*Xiaoting Gao,Yan Zhu,Feng-Xiao Sun,Ya-Dong Wu,Qiongyi He*

Main category: quant-ph

TL;DR: 首个用于光学量子态表征的基础模型，能够跨多种复杂度（非高斯性、模式数、压缩度）预测量子态特性，无需完整层析


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法只能推断特定类型光学量子态的有限特性，缺乏一个统一的模型来预测广泛相关（特别是多模非高斯）量子态的各种性质，而无需进行完整的量子态层析

Method: 引入首个光学量子态表征的基础模型，该模型在低复杂度量子态上进行预训练，能够直接应用于更高复杂度的量子态表征。通过有限的微调，模型可以适应下游任务，如预测量子保真度和Wigner负性

Result: 模型成功应用于广泛的实验相关量子态，包括强非高斯薛定谔猫态、多达10个模式的多模系统，以及压缩水平高达10.4dB的高度压缩态。模型在低复杂度态上预训练后可直接应用于更高复杂度态的表征

Conclusion: 建立了一个从有限测量数据表征光学量子态的统一框架，为光学量子信息计算、通信和计量学中相关量子态的高效认证提供了可能

Abstract: Machine learning methods have been used to infer specific properties of limited families of optical quantum states, but a unified model that predicts a broad range of properties for practically relevant-especially multimode non-Gaussian-states without full tomography is still lacking. Here we introduce the first foundation model for the characterization of optical quantum states across a wide range of complexity, defined by three key factors: non-Gaussianity, number of modes, and degree of squeezing. We show that a single model pretrained on low-complexity states can be directly applied to characterize states of higher complexity. With limited fine-tuning, the model adapts to downstream tasks such as predicting quantum fidelity and Wigner negativity over a broad class of experimentally relevant states, including strongly non-Gaussian Schrödinger cat states, multimode systems with up to ten modes, and highly squeezed states with squeezing levels up to 10.4dB. Our results establish a unified framework for characterizing optical quantum states from limited measurement data, enabling efficient certification of quantum states relevant to optical quantum information computation, communication and metrology.

</details>


### [51] [Families of $k$-positive maps and Schmidt number witnesses from generalized equiangular measurements](https://arxiv.org/abs/2512.18807)
*Katarzyna Siudzińska*

Main category: quant-ph

TL;DR: 使用广义等角测量构造k-正线性映射和施密特数见证，用于检测和量化量子纠缠


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子计算和量子通信中的重要资源，需要有效检测和量化纠缠态的方法。施密特数可以量化二分混合量子态的纠缠程度，但k-正线性映射缺乏一般构造方法。

Method: 利用广义等角测量定义一族k-正映射，并构造相应的施密特数见证

Result: 提出了基于广义等角测量的k-正映射构造方法，为施密特数见证提供了新的实现途径

Conclusion: 该方法为量子纠缠的检测和量化提供了有效的理论工具，特别是在缺乏一般构造方法的k-正映射领域

Abstract: Quantum entanglement is an important resource in many modern technologies, like quantum computation or quantum communication and information processing. Therefore, most interest is given to detect and quantify entangled states. Entanglement degree of bipartite mixed quantum states can be quantified using the Schmidt number. Witnesses of the Schmidt numbers are closely related to $k$-positive linear maps, for which there is no general construction. Here, we use the generalized equiangular measurements to define a family of $k$-positive maps and the corresponding Schmidt number witnesses.

</details>


### [52] [Correlated Entropic Uncertainty as a Signature of Exceptional Points](https://arxiv.org/abs/2512.18856)
*Kyu-Won Park,Soojoon Lee,Kabgyun Jeong*

Main category: quant-ph

TL;DR: 该论文揭示了非厄米系统中本征函数相位熵与其傅里叶表示之间的基本熵不确定性关系，解释了双正交性不是异常现象而是本征函数的内在属性。


<details>
  <summary>Details</summary>
Motivation: 非厄米物理已成为理解增益和损失起关键作用的开放系统的基本框架，但虽然复本征值的作用已明确，相应本征函数的性质仍是一个长期未解决的问题。

Method: 通过分析相位熵与其傅里叶表示之间的熵不确定性关系，研究相位熵和傅里叶熵在避免交叉点和异常点附近的相关行为。

Result: 发现熵不确定性关系强制了相位熵和傅里叶熵在避免交叉点和异常点附近的相关行为，这些位置正是Petermann因子发散和相位刚性崩溃的地方。

Conclusion: 双正交性不是异常现象而是本征函数的内在属性，是非厄米系统中不确定性关系的普遍表现。该框架为推进非厄米物理基础提供了统一且可验证的原理。

Abstract: Non-Hermitian physics has become a fundamental framework for understanding open systems where gain and loss play essential roles, with impact across photonics, quantum science, and condensed matter. While the role of complex eigenvalues is well established, the nature of the corresponding eigenfunctions has remained a long-standing problem. Here we show that it arises from a fundamental entropic uncertainty trade-off between phase entropy and its Fourier representation. This trade-off enforces a correlated behavior of phase and Fourier entropies near avoided crossings and exceptional points, precisely where the Petermann factor diverges and phase rigidity collapses. Our results establish biorthogonality is not as an anomaly but an intrinsic property of eigenfunctions, arising universal manifestation of uncertainty relation in non-Hermitian systems. Beyond resolving this foundational question, our framework provides a unifying and testable principle that advances the fundamentals of non-Hermitian physics and can be directly verified with existing interferometric techniques.

</details>


### [53] [Temporal nonclassicality in continuous-time quantum walks](https://arxiv.org/abs/2512.18873)
*Paolo Luppi,Claudia Benedetti,Andrea Smirne*

Main category: quant-ph

TL;DR: 该研究结合单时间和多时间非经典性度量，分析连续时间量子行走的量子特征。通过量子-经典动力学距离和Kolmogorov一致性条件违反程度，揭示了量子行走在不同时间尺度和拓扑结构下的非经典行为。


<details>
  <summary>Details</summary>
Motivation: 研究动机是深入理解连续时间量子行走中真正的量子特征，通过结合单时间（量子-经典动力学距离）和多时间（Kolmogorov一致性条件违反）两种不同的非经典性度量方法，全面分析量子行走在不同时间尺度和拓扑结构下的行为差异。

Method: 研究方法包括：1）使用量子-经典动力学距离D_QC(t)测量量子态与经典随机行走态的偏离；2）通过序贯位置测量的联合概率分布，评估其违反Kolmogorov一致性条件的程度，使用专用度量K̄(t)；3）分析不同图拓扑（完全图、循环图）下的行为；4）扩展到马尔可夫开放系统动力学，包括位置基和能量基的退相干效应。

Result: 研究结果表明：1）短时间尺度下，K̄(t)呈现二次标度，而D_QC(t)为线性标度，两者都仅由初始占据节点的度决定，与全局图拓扑无关；2）长时间尺度下，K̄(t)表现出强烈的拓扑驱动行为：在完全图上被强烈抑制，而在循环图上保持有限振荡，这与D_QC(t)几乎拓扑无关的渐近行为形成对比；3）位置基退相干使两个度量都趋于零，K̄(t)的衰减由Lindblad生成元的谱隙控制；4）能量基退相干保持K̄(t)的有限渐近值，取决于拉普拉斯特征空间与位置基的重叠结构。

Conclusion: 结论表明，单时间和多时间非经典性度量提供了互补的视角：短时间行为主要由局部性质决定，而长时间行为则强烈依赖于全局拓扑结构。开放系统动力学进一步揭示了不同退相干机制对量子特征的不同影响，位置基退相干完全破坏量子特征，而能量基退相干则保留部分多时间非经典性。

Abstract: We investigate the genuinely quantum features of continuous-time quantum walks by combining a single-time and a multi-time quantifier of nonclassicality. On the one hand, we consider the quantum-classical dynamical distance $D_{\mathrm{QC}}(t)$, which measures the departure of the time-evolved quantum state of a continuous-time quantum walk from the classical state of a random walk on the same graph. On the other, we analyse the joint probability distributions associated with sequential measurements of the walker's position, assessing their violation of the classical Kolmogorov consistency conditions via a dedicated quantifier $\bar{K}(t)$. We demonstrate a quadratic short-time scaling of $\bar{K}(t)$, which differs from the known linear scaling of $D_{\mathrm{QC}}(t)$, but, as the latter, is fully determined by the degree of the initially occupied node and is independent of the global graph topology. At longer times, instead, $\bar{K}(t)$ exhibits a pronounced topology-driven behavior: it is strongly suppressed on complete graphs while remaining finite and oscillatory on cycles, in contrast with the almost topology-independent asymptotics of $D_{\mathrm{QC}}(t)$. We then extend the analysis to Markovian open-system dynamics, focusing on dephasing in the position basis (Haken-Strobl model) and in the energy basis (intrinsic decoherence). Site dephasing drives both quantifiers to zero, with the decay of $\bar{K}(t)$ controlled by the spectral gap of the corresponding Lindblad generator. By contrast, energy-basis dephasing preserves a finite asymptotic value of $\bar{K}(t)$, depending on the overlap structure of the Laplacian eigenspaces with the site basis.

</details>


### [54] [Structure-Preserving Optimal Control of Open Quantum Systems via a Discrete Contact PMP](https://arxiv.org/abs/2512.18879)
*Leonardo Colombo*

Main category: quant-ph

TL;DR: 该论文开发了受控开放量子系统的离散庞特里亚金最大值原理，并引入了保持Lindblad流CPTP结构和接触几何的接触李群变分积分器，用于量子最优控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理受控开放量子系统时，通常的离散化方法会破坏Lindblad方程的CPTP结构和接触几何，导致数值不稳定和物理不一致性，特别是在强耗散或长时间尺度下。

Method: 开发了离散Pontryagin最大值原理，并引入二阶接触李群变分积分器，该积分器通过类型II离散接触生成函数产生严格的离散接触同胚，保持Lindblad流的CPTP结构和接触几何。

Result: 与显式RK2离散化相比，接触LGVI方法在相同形式阶数下，能精确保持CPTP结构和离散接触几何，提供稳定、物理一致且几何忠实的最优控制轨迹，而RK2方法会积累几何漂移导致数值不稳定。

Conclusion: 接触李群变分积分器为开放量子系统的最优控制提供了几何精确的数值框架，能有效处理强耗散和长时间尺度问题，保持物理系统的本质几何结构。

Abstract: We develop a discrete Pontryagin Maximum Principle (PMP) for controlled open quantum systems governed by Lindblad dynamics, and introduce a second--order \emph{contact Lie--group variational integrator} (contact LGVI) that preserves both the CPTP (completely positive and trace--preserving) structure of the Lindblad flow and the contact geometry underlying the discrete PMP. A type--II discrete contact generating function produces a strict discrete contactomorphism under which the state, costate, and cost propagate in exact agreement with the variational structure of the discrete contact PMP.
  We apply this framework to the optimal control of a dissipative qubit and compare it with a non--geometric explicit RK2 discretization of the Lindblad equation. Although both schemes have the same formal order, the RK2 method accumulates geometric drift (loss of trace, positivity violations, and breakdown of the discrete contact form) that destabilizes PMP shooting iterations, especially under strong dissipation or long horizons. In contrast, the contact LGVI maintains exact CPTP structure and discrete contact geometry step by step, yielding stable, physically consistent, and geometrically faithful optimal control trajectories.

</details>


### [55] [Characterizing Kadison--Schwarz maps on $M_3$](https://arxiv.org/abs/2512.18900)
*Adam Rutkowski*

Main category: quant-ph

TL;DR: 该论文研究了M3矩阵代数上的Kadison-Schwarz映射，利用Bloch-Gell-Mann表示和su(3)代数结构，推导了确保KS性质的解析条件，阐明了KS映射与完全正映射之间的关系。


<details>
  <summary>Details</summary>
Motivation: Kadison-Schwarz映射是介于正性和完全正性之间的一类重要线性映射，在量子动力学和算子代数中具有相关性。然而，在低维以上维度中，对KS映射的详细表征仍然是一个开放问题。

Method: 使用Bloch-Gell-Mann表示分析M3上的单位线性映射，利用酉等价性和su(3)代数的结构性质，推导确保Kadison-Schwarz性质的解析条件。

Result: 获得了M3上KS映射的解析条件，阐明了KS映射与完全正映射之间的关系，为高维KS映射的表征提供了理论框架。

Conclusion: 该研究为理解M3矩阵代数上的Kadison-Schwarz映射提供了系统分析，建立了KS性质与完全正性之间的明确联系，为更高维度的KS映射研究奠定了基础。

Abstract: Kadison--Schwarz (KS) maps form a natural class of positive linear maps lying between positivity and complete positivity. Despite their relevance in quantum dynamics and operator algebras, a detailed characterization of KS maps beyond low dimensions remains largely open. In this work we analyze unital linear maps on $M_3$ using the Bloch--Gell--Mann representation. Exploiting unitary equivalence and structural properties of the $\mathfrak{su}(3)$ algebra, we derive analytic conditions ensuring the Kadison--Schwarz property. Our approach clarifies the relation between KS maps and completely positive maps on $M_3$.

</details>


### [56] [Optical perspective on the time-dependent Dirac oscillator](https://arxiv.org/abs/2512.18904)
*Thiago T. Tsutsui,Alison A. Silva,Antonio S. M. de Castro,Fabiano M. Andrade*

Main category: quant-ph

TL;DR: 狄拉克振子是一个相对论量子系统，通过光学对应物分析含时频率扩展模型，研究其对角动量可观测量和自旋轨道纠缠的影响，发现Zitterbewegung的显著变化。


<details>
  <summary>Details</summary>
Motivation: 研究狄拉克振子模型中加入时间依赖频率的扩展，分析这种时间调制对角动量可观测量和自旋轨道纠缠的影响，探索Zitterbewegung的变化特性。

Method: 使用狄拉克振子的光学对应物，分析包含时间依赖频率的扩展模型。研究两种不同的时间依赖选择：一种导致可观测量非周期演化，另一种允许解析解。

Result: 发现时间调制对角动量可观测量和自旋轨道纠缠产生显著影响，Zitterbewegung出现明显变化。特定时间依赖选择导致可观测量非周期演化，而另一种选择可获得解析解。

Conclusion: 狄拉克振子的时间依赖频率扩展模型展示了可观测量演化的丰富物理行为，为研究相对论量子系统中的时间调制效应提供了新视角。

Abstract: The Dirac oscillator is a relativistic quantum system, characterized by its linearity in both position and momentum. Moreover, considering $(1{+}1)$ and $(2{+}1)$ dimensions, the system can be mapped onto the Jaynes-Cummings and anti-Jaynes-Cummings models, as illustrated in an exact manner by Bermudez \emph{et al.} [\href{ https://doi.org/10.1103/PhysRevA.76.041801}{Phys. Rev. A 76, 041801(R)}]. Using the optical counterparts of the Dirac oscillator, we analyze an extension of the model that incorporates a time-dependent frequency. We focus on the consequences of these time modulations on the angular momentum observables and spin-orbit entanglement. Noticeable changes in the \emph{Zitterbewegung} are found. We show that a specific choice of time dependence yields aperiodic evolution of the observables, whereas an alternative choice allows analytical solutions.

</details>


### [57] [Interactions of pre- and postselected quantum particles](https://arxiv.org/abs/2512.18907)
*Gregory Reznik,Jan Dziewior,Shrobona Bagchi,Lev Vaidman*

Main category: quant-ph

TL;DR: 本文开发了一种分析预选和后选量子粒子之间有效相互作用的方法，认为完全预选和后选比部分选择更深刻，并分析了鸽巢悖论等量子现象。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的预选和后选粒子相互作用分析存在局限性，特别是完全预选和后选情况比部分选择更具深度，需要建立更系统的分析框架来理解量子悖论现象。

Method: 开发了一种分析预选和后选量子粒子之间有效相互作用的系统方法，重点关注完全预选和后选情况，并应用该形式主义分析鸽巢悖论等量子现象。

Result: 该方法能够系统分析量子相互作用，解释了鸽巢悖论和从排斥到吸引的相互作用修改等量子现象，并提出了几个新的令人惊讶的量子效应示例。

Conclusion: 完全预选和后选的量子粒子相互作用分析比部分选择更具深度，新开发的形式主义为理解量子悖论现象提供了系统框架，揭示了量子力学中更多令人惊讶的效应。

Abstract: An approach for analysis of effective interaction between pre- and postselected quantum particles is developed. It is argued that the cases of complete pre- and postselection of particles are more profound than the cases of partial pre- and postselection, since the former goes beyond modification of the average of interactions on an ensemble of experiments. Recently discussed paradoxical phenomena such as the pigeonhole paradox and the modification of the interaction from repulsion to attraction are analyzed within the introduced formalism, and a few new surprising examples are presented.

</details>


### [58] [Quantum correlations curvature, memory functions, and fundamental bounds](https://arxiv.org/abs/2512.18942)
*Alexander Kruchkov*

Main category: quant-ph

TL;DR: 该研究探讨了量子关联函数在虚时间中曲率的基本界限，发现量子几何可以显著改变关联函数的虚时间衰减行为，并建立了热平衡系统中关联曲率的普适界限。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索量子关联函数在虚时间中的曲率行为，特别是量子几何如何影响关联函数的衰减模式，以及建立适用于相互作用系统的普适界限。

Method: 首先聚焦于拓扑相，分析量子几何如何改变虚时间关联函数的衰减；然后扩展到一般相互作用系统，建立关联曲率的普适界限，并与记忆函数形式主义的主要不变量建立联系。

Result: 研究结果表明：1）量子几何可以显著改变虚时间关联函数的衰减，超越简单的指数标度；2）建立了热平衡系统中关联曲率的普适界限；3）虚时间曲率可作为内在量子时间尺度的鲁棒探针。

Conclusion: 虚时间关联函数的曲率提供了研究量子系统内在时间尺度的新视角，量子几何在其中起关键作用，相关界限具有普适性，为理解量子多体系统的动力学特性提供了新工具。

Abstract: We investigate fundamental bounds on the curvature of quantum correlation functions in imaginary time. Focusing first on topological phases, we show that quantum geometry can qualitatively modify the imaginary-time decay of correlations, leading to nontrivial curvature behavior beyond simple exponential scaling. More generally, we show a universal bound on correlation curvature that holds for interacting systems in thermal equilibrium, and establish connection to leading invariants of the memory-function formalism. Our results identify imaginary-time curvature as a robust probe of intrinsic quantum timescales.

</details>


### [59] [Photonic variational quantum eigensolver for NISQ-compatible quantum technology](https://arxiv.org/abs/2512.18952)
*Kang-Min Hu,Min Namkung,Hyang-Tag Lim*

Main category: quant-ph

TL;DR: 该论文综述了在光子系统中实现变分量子本征求解器(VQE)的方法，展示了光子平台在噪声中等规模量子(NISQ)时代实现实用量子计算的潜力。


<details>
  <summary>Details</summary>
Motivation: 量子计算机虽然在某些重要问题上具有超越经典计算机的潜力，但许多量子算法需要深度量子电路，这在当前噪声设备上难以实现。变分量子算法(VQAs)为解决这一限制提供了途径，其中VQE在量子化学、多体物理和整数分解等问题中表现突出。光子平台因其室温操作、低退相干和支持多自由度等优势，特别适合实现可扩展的高维量子计算。

Method: 论文首先提供了VQE框架的理论概述，重点介绍了变分估计基态能量的过程。然后探索了光子系统如何实现这些过程，展示了既可以使用多个量子比特状态，也可以使用单个量子比特状态来解决各种问题。

Result: 论文展示了光子系统实现VQE的方法论，证明了光子平台在实现实用量子计算方面的潜力。通过利用光子系统的优势（室温操作、低退相干、多自由度支持），可以构建适合NISQ时代的光子VQE系统。

Conclusion: 光子系统为实现变分量子本征求解器提供了有前景的平台，其独特的优势使其在噪声中等规模量子时代具有实现实用量子计算的潜力。论文提出的方法论为在光子系统中实现VQE提供了理论框架和技术路径。

Abstract: Quantum computers have the potential to deliver speed-ups for solving certain important problems that are intractable for classical counterparts, making them a promising avenue for advancing modern computation. However, many quantum algorithms require deep quantum circuits, which are challenging to implement on current noisy devices. To address this limitation, variational quantum algorithms (VQAs) have been actively developed, enabling practical quantum computing in the noisy intermediate-scale quantum (NISQ) era. Among them, the variational quantum eigensolver (VQE) stands out as a leading approach for solving problems in quantum chemistry, many-body physics, and even integer factorization. The VQE algorithm can be implemented on various quantum hardware platforms, including photonic systems, quantum dots, trapped ions, neutral atoms, and superconducting circuits. In particular, photonic platforms offer several advantages: they operate at room temperature, exhibit low decoherence, and support multiple degrees of freedom, making them suitable for scalable, high-dimensional quantum computation. Here we present methodologies for realizing VQE on photonic systems, highlighting their potential for practical quantum computing. We first provide a theoretical overview of the VQE framework, focusing on the procedure for variationally estimating ground state energies. We then explore how photonic systems can implement these processes, showing that a wide variety of problems can be addressed using either multiple qubit states or a single qudit state.

</details>


### [60] [Classical and Quantum Algorithms for Topological Invariants of Torus Bundles](https://arxiv.org/abs/2512.19028)
*Nelson Abdiel Colón Vargas,Carlos Ortiz Marrero*

Main category: quant-ph

TL;DR: 该论文提出了一种计算3-流形WRT不变量的高效算法，利用非交换环面结构将闭环面的skein代数嵌入到其对称子代数中，实现了多项式时间经典计算和指数空间优势的量子算法。


<details>
  <summary>Details</summary>
Motivation: 计算3-流形的拓扑不变量通常难以处理，但特殊的代数结构可以实现高效算法。研究者希望为环面丛的WRT不变量开发更高效的计算方法。

Method: 利用非交换环面结构，将闭环面的skein代数嵌入到其在单位根处的对称子代数中，得到一个固定的N²维表示。这支持多项式时间的经典计算和仅需O(log N)量子比特的量子算法。

Result: 实现了O(N²)空间的经典多项式时间计算，以及仅需O(log N)量子比特的量子算法（指数空间优势）。证明提取单个展开系数是#P完全的，但量子算法可以高效近似非平凡比例配置的系数。

Conclusion: 通过利用非交换环面结构，为环面丛的WRT不变量开发了高效的经典和量子算法，展示了量子计算在拓扑不变量计算中的显著优势。

Abstract: Computing topological invariants of 3-manifolds is generally intractable, yet specialized algebraic structures can enable efficient algorithms. For Witten-Reshetikhin-Turaev (WRT) invariants of torus bundles, we exploit the non-commutative torus structure to embed the skein algebra of the closed torus into its symmetric subalgebra at roots of unity. This yields a fixed $N^2$-dimensional representation that supports polynomial-time classical computation with $O(N^2)$ space, and a quantum algorithm using only $O(\log N)$ qubits -- an exponential space advantage. We further prove that extracting individual expansion coefficients is #P-complete, yet there is a quantum algorithm that can efficiently approximate these coefficients for a non-negligible fraction of configurations.

</details>


### [61] [The energy-speed relationship of quantum particles challenges Bohmian mechanics?](https://arxiv.org/abs/2512.19051)
*S. Di Matteo,C. Mazzoli*

Main category: quant-ph

TL;DR: 该论文反驳了Sharoglazova等人声称证明玻姆力学基本关系式v=ħ/m∇S被违反的结论，指出他们的实验证据与理论推导存在矛盾。


<details>
  <summary>Details</summary>
Motivation: 回应Sharoglazova等人声称的实验结果，该结果声称证明了玻姆力学的基本关系式v=ħ/m∇S被违反，需要澄清这一理论与实验之间的明显矛盾。

Method: 通过分析Sharoglazova等人的实验数据，特别是图2显示的密度运动，结合玻姆力学的基本数学关系∇S=m/ρj，指出实验观测到的非零密度电流与声称的∇S=0之间存在逻辑矛盾。

Result: 分析表明Sharoglazova等人的实验证据存在内部不一致：他们声称测量到的是倏逝波（∇S=0），但实验数据显示了明显的密度运动和相应的非零密度电流，这必然意味着∇S≠0。

Conclusion: Sharoglazova等人声称的玻姆力学基本关系式违反并未得到证实，他们的实验数据与理论分析存在矛盾，需要重新解释实验结果或修正实验方法。

Abstract: Recently, Sharoglazova et al. claimed to have proven a violation of the basic tenet of Bohmian mechanics, namely the phase-speed relation $\vec{v}(\vec{r},t)=\frac{\hbar}{m}\vec{\nabla}S(\vec{r},t)$. Here, $S(\vec{r},t)$ is the (real) phase of the wave function $ψ(\vec{r},t)=ρ^{\frac{1}{2}}(\vec{r},t)e^{iS(\vec{r},t)}$. In a nutshell, they have measured the speed of a claimed evanescent wave, which is real and therefore must have $\vec{\nabla}S=\vec{0}$. However, Fig. 2 clearly shows a density motion from one waveguide to the other, implying a nonzero density current, $\vec{j}(\vec{r},t)=\frac{\hbar}{2mi}\Im(ψ^*\vec{\nabla}ψ)$. If we combine this evidence with the mathematical identity $\vec{\nabla}S=\frac{m}ρ\vec{j}$, we should instead conclude that $\vec{\nabla}S\neq\vec{0}$. So, where does this apparent inconsistency come from?

</details>


### [62] [Reactive near-field subwavelength microwave imaging with a non-invasive Rydberg probe](https://arxiv.org/abs/2512.19116)
*Chaoyang Hu,Mingyong Jing,Zongkai Liu,Shaoxin Yuan,Bin Wu,Yan Peng,Tingting Li,Wenguang Yang,Junyao Xie,Hao Zhang,Liantuan Xiao,Suotang Jia,Linjie Zhang*

Main category: quant-ph

TL;DR: 首次利用里德堡原子的量子非破坏特性实现微波场非侵入式亚波长成像，分辨率达λ/56，相比传统金属探头显著减少场扰动


<details>
  <summary>Details</summary>
Motivation: 传统金属探头在测量微波场时会严重扰动反应近场，导致测量精度和空间分辨率下降，特别是在航空航天、生物医学成像和集成电路诊断等关键应用中需要非侵入式测量

Method: 开发了紧凑的单端光纤集成里德堡原子探头，利用里德堡原子的量子非破坏特性，最小化对微波场的扰动，实现反应近场的亚波长成像

Result: 实现了λ/56的成像分辨率，测量场分布与全波仿真结果的结构相似度接近1，证实了其亚波长空间分辨率和真正的非侵入特性；原子传感器具有固有各向同性，无需方向依赖校准即可准确成像多维场结构

Conclusion: 建立了一种通用的非侵入式高精度亚波长反应近场微波成像方法，在芯片缺陷检测和集成电路诊断等应用中具有重要前景，能够避免探头扰动掩盖底层物理机制

Abstract: Non-invasive microwave field imaging--accurately mapping field distributions without perturbing them--is essential in areas such as aerospace engineering, biomedical imaging and integrated-circuit diagnostics. Conventional metal probes, however, inevitably perturb reactive near fields: they act as strong scatterers that drive induced currents and secondary radiation, remap evanescent components and thereby degrade both accuracy and spatial resolution, particularly in the reactive near-field regime that is most relevant to these applications. Here we demonstrate, to our knowledge for the first time, reactive near-field subwavelength imaging of microwave fields using the quantum non-demolition properties of Rydberg atoms, realized with a compact, non-invasive single-ended fibre-integrated Rydberg probe engineered to minimize field disturbance. The probe achieves an imaging resolution of {\unboldmath$λ/56$}, and the measured field distributions agree with full-wave simulations with structural similarity approaching unity, confirming both its subwavelength spatial resolution and its genuinely non-invasive character compared with conventional metal-based probes. Because the atomic sensor is intrinsically isotropic, the same device can faithfully image multi-dimensional field structures without orientation-dependent calibration. Our results therefore establish a general, non-invasive route to high-accuracy, subwavelength reactive near-field microwave imaging, with particular promise for applications such as chip-defect detection and integrated-circuit diagnostics, where even small perturbations by the probe can mask the underlying physics of interest.

</details>


### [63] [Narrowband Frequency-Entangled Photon Source for Hong-Ou-Mandel Interferometry](https://arxiv.org/abs/2512.19129)
*Yen-Ju Chen,Sheng-Hsuan Huang,Thomas Dirmeier,Kaisa Laiho,Dmitry V. Strekalov,Andrea Aiello,Gerd Leuchs,Christoph Marquardt*

Main category: quant-ph

TL;DR: 该研究展示了一种基于谐振参量下转换的窄带频率纠缠光子源，实现了米级动态范围的高灵敏度HOM干涉测量


<details>
  <summary>Details</summary>
Motivation: 传统基于非谐振参量下转换的频率纠缠光子源受限于光子相干长度，导致HOM传感器的动态范围仅限于亚毫米尺度，需要开发具有更长相干长度的频率纠缠光子源来扩展传感应用

Method: 采用晶体回音壁模式谐振器中的谐振参量下转换技术，产生MHz级光谱带宽的窄带频率纠缠光子对，其中光子对具有96 THz的频率失谐，并在HOM干涉实验中观察量子拍频效应

Result: 成功实现了米级动态范围的HOM干涉测量，观察到具有亚皮秒分辨率的高对比度量子拍频，光子相干长度显著提升，突破了传统方法的限制

Conclusion: 基于WGMR的频率纠缠光子源在量子计量和量子信息处理领域具有重要应用潜力，为高精度量子传感提供了新的技术途径

Abstract: Hong-Ou-Mandel (HOM) interferometry with entangled photons exhibits distinctive quantum features. By introducing frequency entanglement (discrete-color entangled states) into HOM interference, the characteristic HOM dip is modulated by sinusoidal fringes, which significantly enhance the sensitivity of HOM sensors. The frequency-entangled photon sources demonstrated to date rely on non-resonant parametric down-conversion (PDC), which limits the photon coherence length and, consequently, restricts the sensing dynamic range to the sub-millimeter scale. In this work, we demonstrate narrowband frequency-entangled photon source based on resonant PDC in a crystalline whispering gallery mode resonator. The MHz-level spectral bandwidth of photons enables a meter-scale dynamic range. With highly nondegenerate frequency-entangled photon pairs featuring a 96 THz frequency detuning, we observe high-contrast quantum beating with sub-picosecond resolution in the HOM experiment. Our WGMR-based frequency-entangled photon source has potential applications in quantum metrology and quantum information processing.

</details>


### [64] [Learning Hamiltonians for $O(1)$ Oracle-Query Quantum State Preparation](https://arxiv.org/abs/2512.19181)
*Mehdi Ramezani,Sina Asadiyan Zargar,Sadegh Salami,Abolfazl Bahrampour,Alireza Bahrampour*

Main category: quant-ph

TL;DR: 提出一种基于哈密顿量的量子态制备方法，通过浅层参数化量子电路实现，将大部分计算成本转移到经典预处理阶段。


<details>
  <summary>Details</summary>
Motivation: 解决量子态制备中量子资源消耗大的问题，通过将主要计算负担转移到经典预处理，使量子部分保持浅层电路，适合近期量子设备。

Method: 通过经典训练学习对角哈密顿量的参数，量子电路仅执行固定深度的哈密顿量演化和混合操作。对于结构化数据集，使用Walsh基表示哈密顿量并保留多项式数量的显著项。

Result: N个经典数据值可以用n=log₂N个量子比特编码，仅需O(1)量子查询，经典预处理成本为O(NlogN)。对于结构化数据集，可实现poly(n)时间内的量子态制备，保真度达到10⁻⁵量级。

Conclusion: 该方法通过将主要计算成本转移到经典预处理，实现了高效的量子态制备，特别适合近期量子设备，且通过限制哈密顿量为单局域和双局域项可生成硬件高效的电路。

Abstract: We propose a Hamiltonian-based quantum state preparation method implemented via a shallow parametrized quantum circuit. The approach learns the parameters of a diagonal Hamiltonian through a classical training phase, while the quantum circuit itself performs only fixed-depth Hamiltonian evolution and mixing operations. With oracle access to the learned Hamiltonian parameters, $N$ classical data values can be encoded into $n=\log_2{N}$ qubits using $O(1)$ quantum queries, shifting the overall computational cost to an $O(N\log{N})$ classical preprocessing stage. For structured datasets generated by an underlying function, oracle access can be avoided by expressing the Hamiltonian in the Walsh basis and retaining only a polynomial number of significant terms. In this regime, quantum state preparation is achieved in $\text{poly}(n)$ time using $\text{poly}(n)$ parameters, reaching infidelities on the order of $10^{-5}$. By restricting the Hamiltonian to one-local and two-local terms, the method naturally yields hardware-efficient circuits suitable for near-term quantum devices.

</details>


### [65] [Quantifying superluminal signalling in Schrödinger-Newton model](https://arxiv.org/abs/2512.19260)
*Julia Osęka-Lenart,Marcin Płodzień,Maciej Lewenstein,Michał Eckstein*

Main category: quant-ph

TL;DR: 薛定谔-牛顿方程描述大质量量子系统的引力自相互作用动力学，通常被认为违反相对论无信号原理，但本文通过量化分析表明其超光速效应随系统尺寸和质量增加而减小，且其相对论版本（爱因斯坦-狄拉克系统）完全符合相对论因果结构。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为薛定谔-牛顿方程作为确定性非线性量子波方程，与相对论无信号原理相冲突。本文旨在挑战这一观点，通过定量分析超光速效应的操作特性来重新评估该方程与相对论因果结构的兼容性。

Method: 采用严格的时空概率测度形式化方法，量化通过单粒子薛定谔-牛顿方程实现成功超光速比特传输的概率。分析该概率随系统尺寸和质量的变化规律，并证明爱因斯坦-狄拉克系统（薛定谔-牛顿方程的非相对论极限）与相对论因果结构的兼容性。

Result: 研究表明：1）通过薛定谔-牛顿方程实现超光速比特传输的概率随系统尺寸和质量的增加而减小；2）爱因斯坦-狄拉克系统完全符合相对论因果结构；3）薛定谔-牛顿方程虽然是非相对论的，但实际上比普通自由薛定谔方程更符合无信号原理。

Conclusion: 薛定谔-牛顿方程与相对论无信号原理的冲突被夸大了。通过定量分析表明，其超光速效应在实际操作中受到系统特性的限制，且其相对论基础（爱因斯坦-狄拉克系统）完全符合相对论因果结构，因此该方程在描述大质量量子系统引力自相互作用时具有物理合理性。

Abstract: The Schrödinger-Newton equation aims at describing the dynamics of massive quantum systems subject to the gravitational self-interaction. As a deterministic nonlinear quantum wave equation, it is generally believed to conflict with the relativistic no-signalling principle. Here we challenge this viewpoint and show that it is of key importance to study the quantitative and operational character of the superluminal effects. To this end we employ a rigorous formalism of probability measures on spacetime and quantify the probability of a successful superluminal bit transfer via the single-particle Schrödinger-Newton equation. We demonstrate that such a quantity decreases with the increasing size and mass of the system. Furthermore, we prove that the Einstein-Dirac system, which yields the Schrödinger-Newton equation in the non-relativistic limit, is perfectly compatible with the relativistic causal structure. Our study demonstrates that the Schrödinger-Newton equation, which is by construction non-relativistic, is in fact `more compatible' with the no-signalling principle than the ordinary free Schrödinger equation.

</details>


### [66] [Limitations of Entangled Two-Photon Absorption detection](https://arxiv.org/abs/2512.19261)
*René Pollmann,Franz Roeder,Christine Silberhorn,Benjamin Brecht*

Main category: quant-ph

TL;DR: 提出了一种确定纠缠双光子吸收测量灵敏度的方法，通过建模所有信号和噪声贡献，得出描述ETPA测量灵敏度的单一数值，可直接比较不同实验方法并预测ETPA是否可检测。


<details>
  <summary>Details</summary>
Motivation: 需要一种标准化的方法来评估和比较不同纠缠双光子吸收实验的灵敏度，以确定在特定条件下ETPA是否可检测，并优化实验装置。

Method: 通过建模ETPA测量中的所有信号和噪声贡献，推导出描述测量灵敏度的单一数值（以Göppert-Mayer单位表示）。

Result: 该方法能够直接比较不同实验方法，预测ETPA在给定条件下的可检测性，量化实验装置变化的影响，并确定最佳优化路径。

Conclusion: 该方法为ETPA测量提供了标准化的灵敏度评估框架，有助于实验设计和优化，促进不同实验方法的直接比较。

Abstract: We introduce a method for determining the sensitivity of any given Entangled Two-Photon Absorption (ETPA) measurement. By modeling all signal and noise contributions to the measurement, we derive a single numerical value that describes the sensitivity of the ETPA measurement in Göppert-Mayer units. This allows us to directly compare vastly different experimental approaches and, determine whether ETPA will be detectable under the given conditions. Therefore, we can quantify the effect of any change to a given experimental apparatus and identify the ideal optimization pathway.

</details>


### [67] [Sonified Quantum Seizures. Sonification of time series in epileptic seizures and simulation of seizures via quantum modelling](https://arxiv.org/abs/2512.19272)
*Maria Mannone,Paulo Vitor Itaborai,Omar Costa Hamido,Miriam Goldack,Norbert Marwan,Peppino Fazio,Patrizia Ribino*

Main category: quant-ph

TL;DR: 将脑电信号转化为声音，并用量子计算模拟癫痫发作，通过声音比较评估模拟效果


<details>
  <summary>Details</summary>
Motivation: 探索量子计算和声化技术在癫痫数据分析中的创新应用，为癫痫发作的分析和预测建立新的测试平台

Method: 首先将真实ECoG数据中的选定通道信号进行声化处理，生成多音序列；然后提出两种量子计算方法模拟癫痫发作，并对模拟结果进行声化

Result: 通过比较真实数据和模拟数据的声化结果，可以识别两者之间的相似性和差异，有助于改进计算机模型

Conclusion: 量子计算与声化技术的结合为真实数据分析提供了新视角，为癫痫发作的分析和预测定义了新的测试基准

Abstract: We apply sonification strategies and quantum computing to the analysis of an episode of seizure. We first sonify the signal from a selection of channels (from real ECoG data), obtaining a polyphonic sequence. Then, we propose two quantum approaches to simulate a similar episode of seizure, and we sonify the results. The comparison of sonifications can give hints on similarities and discrepancies between real data and simulations, helping refine the \textit{in silico} model. This is a pioneering approach, showing how the combination of quantum computing and sonification can broaden the perspective of real-data investigation, and helping define a new test bench for analysis and prediction of seizures.

</details>


### [68] [Spectral Gap Estimation via Adiabatic Preparation](https://arxiv.org/abs/2512.19288)
*Davide Cugini,Francesco Ghisoni,Angela Rosy Morgillo,Francesco Scala*

Main category: quant-ph

TL;DR: 该论文提出了一种在数字量子设备上估计能隙的新方法，使用绝热制备技术创建特定叠加态，通过测量该态上可观测量随时间波动的期望值来估计能隙。


<details>
  <summary>Details</summary>
Motivation: 传统能隙估计方法需要独立计算基态和第一激发态能量然后求差，这种方法在量子计算中可能效率不高。需要开发一种更适合当前数字量子设备的能隙估计方法。

Method: 使用绝热制备技术创建特定叠加态，测量该态上可观测量随时间波动的期望值，通过拟合过程估计能隙。该方法实现相对浅层电路，适用于有噪声和无噪声环境。

Result: 在1D和2D Ising模型、H2和He2分子上成功测试了该方法，在无噪声和有噪声模拟器上均有效。在真实的IonQ Aria设备上对1D Ising模型（最多20个量子比特）进行了验证，证明了该方法在当前可用量子设备上的适用性。

Conclusion: 该方法为当前可用的数字量子设备提供了一种有效的能隙估计方案，为未来容错量子计算时代需要更深层电路的更复杂能隙计算铺平了道路。

Abstract: Estimating energy gaps, i.e. the energy difference between two different states, in quantum systems is crucial for understanding their properties. Conventionally, spectral gap estimation relies on independently computing the ground-state and first-excited-state energies and then taking their difference. This work introduces an alternative procedure for estimating spectral gaps on digital quantum devices using the Adiabatic Preparation technique to create a specific superposition state. The expectation values of observables measured on such a state exhibit time-dependent fluctuations which, through a fitting process, can be used to estimate the energy gap. We successfully test our method on the 1D and 2D Ising models, and H2 and He2 molecules, implementing relatively shallow circuits both on noiseless and noisy simulators. The robustness of the approach is corroborated by additional experiments on the real IonQ Aria device for the 1D Ising model up to 20 qubits, demonstrating the applicability of the proposed method for currently available digital quantum devices and paving the way for more complex energy gap calculation requiring deeper circuits in the fault-tolerant era to come.

</details>


### [69] [Quantum and classical algorithms for daily railway rolling stock circulation plans](https://arxiv.org/abs/2512.19340)
*Ewa Kędziera,Wojciech Gamon,Mátyás Koniorczyk,Zakaria Mzaouali,Andrea Galadíková,Krzysztof Domino*

Main category: quant-ph

TL;DR: 研究区域铁路电动动车组日常循环调度规划，考虑车辆配对运行、座位和自行车容量限制，比较传统ILP求解器与量子优化方法的效果。


<details>
  <summary>Details</summary>
Motivation: 受波兰西里西亚铁路运营需求驱动，需要解决电动动车组的日常循环调度问题，特别关注车辆配对运行、座位容量和自行车容量限制等实际运营需求。

Method: 采用无环混合整数线性规划模型，基于图-超图表示法描述列车行程和动车组运动；首先使用传统ILP求解器，然后推导QUBO重构用于量子优化，并在D-Wave量子退火系统和VeloxQ经典量子启发式求解器上评估。

Result: ILP方法能在约40分钟内获得高质量日常循环计划（最多404个列车行程，11种动车组类型），而当前量子方法受嵌入和QUBO规模限制，只能处理较小子实例（最多51和78个列车行程）。

Conclusion: 量化了基于QUBO方法在动车组循环调度中的当前边界，指出未来应采用混合决策支持架构，让量子或量子启发式优化器仅在更广泛的经典规划框架内处理局部子问题。

Abstract: We study daily rolling stock circulation planning for electric multiple units (EMUs) on a regional passenger network, focusing on services where identical EMUs may be coupled in pairs on selected routes. Motivated by the operational needs of the regional operator Silesian Railways in Poland, we formulate an acyclic mixed-integer linear program on a one-day horizon that incorporates depot balance constraints, demand-driven seat and bicycle capacity limits (which is a new aspect requested by the regional operator and local society of passengers), and simple crew availability constraints. The model is designed to support both baseline planning and disruption management under increased passenger demand. Using a graph-hypergraph representation of trips and single or coupled EMU movements, we first solve the problem with a classical ILP solver. We then derive a Quadratic Unconstrained Binary Optimization (QUBO) reformulation - which is frequently used as the input for quantum optimization - and evaluate its solution by quantum annealing on D-Wave Advantage systems and by the classical quantum-inspired VeloxQ solver. Computational experiments on real-world instances from the Silesian network, with up to 404 train trips and 11 EMU types, show that the ILP approach can obtain high-quality daily circulation plans within at most about 40 minutes, whereas current quantum and quantum-inspired solvers are restricted to substantially smaller sub-instances (up to 51 and 78 train trips, respectively) due to embedding and QUBO size limitations. These results quantify the present frontier of QUBO-based methods for rolling stock circulation and point towards hybrid decision-support architectures in which quantum or quantum-inspired optimizers address only local subproblems within a broader classical planning framework.

</details>


### [70] [The Perspectives of Non-Ideal Quantum Reference Frames](https://arxiv.org/abs/2512.19343)
*Sébastien Christophe Garmier,Ladina Hausmann,Esteban Castro-Ruiz*

Main category: quant-ph

TL;DR: 该论文扩展了量子参考系框架，从理想无限资源情况推广到具有有限能量或角动量等资源的非理想量子参考系，建立了不同视角间的可逆变换，并揭示了非理想量子参考系视角下的超选择规则和反作用效应。


<details>
  <summary>Details</summary>
Motivation: 现有量子参考系框架主要针对理想情况（具有无限资源），但实际物理系统中的量子参考系通常具有有限资源（如有限能量、角动量）。需要建立非理想量子参考系的数学框架，理解有限资源如何影响量子系统的描述和变换。

Method: 从两个物理动机原理出发，推导量子参考系的视角定义，采用非相干群平均方法，构建不同量子参考系视角之间的可逆变换，将框架从理想情况扩展到具有有限资源的非理想量子参考系。

Result: 1. 非理想量子参考系视角下，系统表现出超选择特性；2. 量子参考系视角的结构表明，相对于量子参考系对系统进行的连续操作会导致反作用到量子参考系本身；3. 非理想量子参考系视角与直觉上的理想无限资源框架存在显著差异。

Conclusion: 该研究成功扩展了量子参考系框架，为理解有限资源量子参考系的物理特性提供了数学基础，揭示了非理想量子参考系视角下的超选择规则和反作用效应，对量子引力、量子信息等领域具有重要意义。

Abstract: We define the perspective of any quantum reference frame (QRF) and construct reversible transformations between different perspectives. This extends the framework of [arXiv:2110.13199] to non-ideal QRFs with finite resources such as energy or angular momentum. We derive a QRF's perspective starting from two physically motivated principles, leading to an incoherent group averaging approach. The perspective of a non-ideal QRF deviates significantly from that of a more intuitive ideal frame with infinite resources: Firstly, systems described relative to the QRF appear superselected. Secondly, the structure of the QRF perspective attests that successive operations on a system relative to the QRF leads to back-reaction onto the QRF due to its non-ideality.

</details>


### [71] [Lorentz Invariant Master Equation for Quantum Systems](https://arxiv.org/abs/2512.19346)
*Pranav Vaidhyanathan,Gerard J. Milburn*

Main category: quant-ph

TL;DR: 提出了一种基于物理标量时钟场的相对论性量子场论主方程，解决了传统马尔可夫近似破坏洛伦兹协变性或引发真空不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 不可逆性暗示时间有优先流向，但狭义相对论否认存在优先时钟。这种矛盾长期以来阻碍了相对论性主方程的建立：标准马尔可夫近似要么破坏洛伦兹协变性，要么引发灾难性真空加热，要么依赖于观察者的叶层化选择。

Method: 采用显式建模观测不可逆动力学所需测量的方法，将系统演化锚定在物理的、关系性的标量时钟场上。使用关系性Tomonaga-Schwinger框架，推导出局部、非马尔可夫的主方程，该方程具有明显的协变性和完全正定性。

Result: 物理时钟的有限分辨率充当协变调节器，防止了困扰白噪声模型的真空不稳定性。该框架表明，只要将参考系视为动态量子资源而非规范选择，就存在一致的相对论性衰变理论。

Conclusion: 在引力背景下，所得动力学由混合经典-量子演化描述，保持完全正定和迹保持特性。该工作为量子场论中的不可逆性提供了洛伦兹不变描述，解决了相对论与不可逆性之间的长期矛盾。

Abstract: Irreversibility implies a preferred flow of time, yet special relativity denies the existence of a preferred clock. This tension has long obstructed the formulation of a relativistic master equation: standard Markovian approximations either break Lorentz covariance, trigger catastrophic vacuum heating, or depend arbitrarily on the observer's foliation. In this work, we derive a Lorentz-invariant description of irreversibility for quantum fields. We take an approach that explicitly models the measurements required to observe irreversible dynamics. Instead of evolving the system along an abstract geometric time parameter, we anchor the dynamics to a physical, relational scalar clock field. Using a relational Tomonaga-Schwinger framework, we derive a local, non-Markovian master equation that is manifestly covariant and completely positive. We show that the finite resolution of the physical clock acts as a covariant regulator, preventing the vacuum instability that plagues white-noise models. This framework demonstrates that a consistent relativistic theory of decay exists, provided the reference frame is treated as a dynamical quantum resource rather than a gauge choice. In a gravitating context, the resulting dynamics is described by a hybrid classical-quantum (CQ) evolution that remains completely positive and trace preserving (CPTP).

</details>


### [72] [Clifford Volume and Free Fermion Volume: Complementary Scalable Benchmarks for Quantum Computers](https://arxiv.org/abs/2512.19413)
*Attila Portik,Orsolya Kálmán,Thomas Monz,Zoltán Zimborás*

Main category: quant-ph

TL;DR: 论文提出了两个体积化基准测试：Clifford Volume和Free Fermion Volume，用于评估量子硬件性能，支持跨平台比较和经典验证。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算进入后NISQ和早期容错时代，需要可扩展、平台无关的基准测试来量化量子计算能力，并进行经典验证。

Method: 引入两个体积化基准测试：Clifford Volume测试随机Clifford操作执行能力，Free Fermion Volume测试自由费米子操作执行能力。这两种酉操作具有经典可模拟性、构成通用门集、是重要算法原语且与硬件无关的特性。

Result: 通过数值模拟和Quantinuum H2-1离子阱量子计算机实验验证了基准测试的可行性，H2-1实现了34的Clifford Volume。

Conclusion: 提出的基准测试框架支持可扩展、公平的跨平台比较，能够追踪有意义的计算进展，为量子硬件评估提供了有效工具。

Abstract: As quantum computing advances toward the late-NISQ and early fault-tolerant eras, scalable and platform-independent benchmarks are essential for quantifying computational capacity in a classically verifiable manner. We introduce two volumetric benchmarks, Clifford Volume and Free Fermion Volume, that assess quantum hardware by testing the execution of random Clifford and free fermion operations. These two groups of unitaries possess a combination of properties that make them ideal for benchmarking: (i) each is individually efficient to simulate classically, enabling verification at scale; (ii) together they form a universal gate set; (iii) they serve as essential algorithmic primitives in practical applications (including shadow tomography and quantum chemistry); and (iv) their definitions are formulated abstractly, without explicit reference to hardware-specific features such as qubit connectivity or native gate sets. This framework thus enables scalable and fair cross-platform comparisons and tracks meaningful computational advancement. We demonstrate the practical feasibility of these benchmarks through extensive numerical simulations across realistic noise parameters and through experimental validation on Quantinuum's H2-1 trapped-ion quantum computer, which achieves a Clifford Volume of 34.

</details>


### [73] [Generative Krylov Subspace Representations for Scalable Quantum Eigensolvers](https://arxiv.org/abs/2512.19420)
*Changwon Lee,Daniel K. Park*

Main category: quant-ph

TL;DR: GenKSR框架通过经典生成模型学习Krylov子空间对角化过程，无需额外量子实验即可预测量子多体系统的基态能量


<details>
  <summary>Details</summary>
Motivation: 传统Krylov子空间方法需要为每个新哈密顿量重复执行量子电路，这在噪声硬件条件下成为主要瓶颈，需要减少量子计算需求

Method: 提出Generative Krylov Subspace Representations (GenKSR)框架，使用条件生成模型学习测量结果分布，采用Transformer和Mamba状态空间模型作为骨干架构

Result: 在15量子位1D和16量子位2D海森堡模型模拟以及20量子位XXZ链的IBM量子处理器实验中验证成功，能够从实验数据学习分布并生成高保真量子过程表示

Conclusion: GenKSR能够经典再现实验结果，支持对未见哈密顿量的可靠能量估计，显著减少进一步量子计算需求

Abstract: Predicting ground state energies of quantum many-body systems is one of the central computational challenges in quantum chemistry, physics, and materials science. Krylov subspace methods, such as Krylov Quantum Diagonalization and Sample-based Krylov Quantum Diagonalization, are promising approaches for this task on near-term quantum computers. However, both require repeated quantum circuit executions for each Krylov subspace and for every new Hamiltonian, posing a major bottleneck under noisy hardware constraints. We introduce Generative Krylov Subspace Representations (GenKSR), a framework that learns a classical generative representation of the entire Krylov diagonalization process. To enable effective modeling of quantum systems, GenKSR leverages a conditional generative model framework. We investigate two representative backbone architectures, the standard Transformer and the Mamba state-space model. By learning the distribution of measurement outcomes conditioned on Hamiltonian parameters and evolution time, GenKSR generates Krylov subspace samples for unseen Hamiltonians and for larger subspace dimensions than those used in training. This enables full energy reconstruction purely from the classical model, without additional quantum experiments. We validate our approach through simulations of 15-qubit 1D and 16-qubit 2D Heisenberg models, as well as a hardware experiment on a 20-qubit XXZ chain executed on an IBM quantum processor. Our model successfully learns the distribution from experimental data and generates a high-fidelity representation of the quantum process. This representation enables classical reproduction of experimental outcomes, supports reliable energy estimates for unseen Hamiltonians, and significantly reduces the need for further quantum computation.

</details>


### [74] [$W$- and Dicke-state engineering using optimal global control in nearest-neighbor coupled ring-shaped qubit arrays](https://arxiv.org/abs/2512.19545)
*Andrea Muratori,Vladimir M. Stojanovic,Eloisa Cuestas,Tommaso Calarco,Felix Motzoi*

Main category: quant-ph

TL;DR: 该研究针对光学镊子中的中性原子系统，提出两种最优控制方案制备W态和Dicke态，利用系统对称性简化计算，在远短于相干时间尺度内实现鲁棒性量子态制备。


<details>
  <summary>Details</summary>
Motivation: 中性原子光学镊子系统需要时间高效且鲁棒的量子态工程方案，特别是在非里德堡阻塞区域模拟环形原子阵列的相互作用。

Method: 采用两种最优控制方法：(1) NMR类脉冲序列（瞬时控制脉冲和Ising相互作用脉冲）；(2) 时变控制方案（在持续Ising相互作用下使用整形控制脉冲）。利用系统二面体对称性构建对称适配基，结合全局优化方法寻找最优脉冲序列。

Result: 成功找到制备W态和Dicke态的最优脉冲序列，证明序列对控制误差具有鲁棒性。使用实际里德堡原子系统参数，制备时间远短于系统相干时间。

Conclusion: 提出的控制方案能够在中性原子光学镊子系统中高效、鲁棒地制备多量子比特态，为量子态工程提供了实用方法。

Abstract: Motivated by a compelling need for time-efficient and robust schemes for quantum-state engineering in systems of neutral atoms in optical tweezers, we consider a ring-shaped array of qubits with nearest-neighbor Ising-type ($zz$) coupling and transverse ($x$ and $y$) global control fields. This system to a large extent mimics -- outside of the Rydberg-blockade regime -- a circular array of neutral atoms interacting through van-der-Waals type interaction. We investigate the preparation of $W$ and Dicke states in this system starting from the default initial state $|00\ldots 0\rangle$ using two different optimal-control approaches: (i) NMR-like pulse sequence, which consists of instantaneous (delta-shaped) control- and Ising-interaction pulses, and (ii) time-dependent control scheme, which entails shaped control pulses in the presence of always-on Ising interaction between adjacent qubits. By making use of the underlying dihedral symmetry of this system -- which allows one to use a symmetry-adapted computational basis with $\mathcal{O}(2^N / N)$ states in an $N$-qubit system -- and utilizing advanced global-optimization methods, we find optimal sequences of pulses for realizing $W$ and Dicke states within both approaches. In addition, we demonstrate robustness of these sequences against unavoidable control errors. Finally, using typical values of parameters in realistic Rydberg-atom systems, we show that our control schemes enable the preparation of the desired multiqubit states on time scales much shorter than the relevant coherence times of those systems.

</details>


### [75] [A Spin-Photon Interface in the Telecom C-Band with Long Hole Spin Dephasing Time](https://arxiv.org/abs/2512.19561)
*Johannes M. Michl,Reza Hekmati,Mohamed Helal,Giora Peniakov,Yorick Reum,Jochen Kaupp,Quirin Buchinger,Jaewon Kim,Andreas T. Pfenning,Yong-Hoon Cho,Sven Höfling,Tobias Huber-Loyola*

Main category: quant-ph

TL;DR: 该研究报道了在电信波段（1.55μm）工作的InAs/InAlGaAs量子点中空穴自旋量子比特的相干时间测量，通过确定性放置的圆形布拉格光栅实现了T2* = (15.9 ± 1.7) ns的退相干时间。


<details>
  <summary>Details</summary>
Motivation: 电信波段量子点对于量子通信和量子计算应用至关重要，但目前该波段量子点的相干时间研究相对滞后，需要开发在电信波段具有长相干时间的自旋量子比特。

Method: 使用确定性放置的圆形布拉格光栅集成InAs/InAlGaAs量子点，通过偏振分辨测量在面内磁场中确定电子和空穴的g因子，采用脉冲双光子关联测量来表征空穴自旋量子比特的动力学。

Result: 成功测量了空穴自旋量子比特的非均匀退相干时间T2* = (15.9 ± 1.7) ns，这是在电信波段量子点中实现的显著相干时间进展。

Conclusion: 该研究展示了在电信波段工作的量子点中实现空穴自旋量子比特的可行性，为量子通信和量子计算应用提供了重要的材料平台。

Abstract: Matter qubits that maintain coherence over extended timescales are essential for many pursued applications in quantum communication and quantum computing. Significant progress has already been made on extending coherence times of spins in semiconductor quantum dots while interfacing them with photons in the near-infrared wavelength range. However, similar results for quantum dots emitting at the telecom range, crucial for many applications, have so far lagged behind. Here, we report on InAs/InAlGaAs quantum dots integrated in a deterministically placed circular Bragg grating emitting at $1.55\,μ\mathrm{m}$. We quantify the g-factors of electrons and holes from polarization-resolved measurements of a positive trion in an in-plane magnetic field and study the dynamics of the ground-state hole spin qubit. We then herald the hole spin in a pulsed two-photon correlation measurement and determine its inhomogeneous dephasing time to $T_{2}^{*}=(15.9 \pm 1.7)$ ns.

</details>


### [76] [Trigonometric continuous-variable gates and hybrid quantum simulations](https://arxiv.org/abs/2512.19582)
*Tommaso Rainaldi,Victor Ale,Matt Grau,Dmitri Kharzeev,Enrique Rico,Felix Ringer,Pubasha Shome,George Siopsis*

Main category: quant-ph

TL;DR: 该论文提出了一种基于三角连续变量门的量子计算新范式，用于在混合量子比特-量子模式平台上模拟相互作用的玻色量子场论，特别适用于周期性和非微扰相互作用。


<details>
  <summary>Details</summary>
Motivation: 现有的连续变量门构造主要依赖于正则正交量的多项式函数，这限制了模拟周期性相互作用和非微扰现象的能力。需要一种新的通用性范式来更好地模拟玻色量子场论。

Method: 引入基于三角连续变量门的通用性范式，提出确定性辅助量子比特方法来实现酉和非酉三角门，这些门的参数是量子模式正交量的任意厄米函数。以晶格正弦-戈登模型为具体应用，开发混合量子比特-量子模式量子模拟。

Result: 通过量子虚时演化制备基态，模拟实时动力学，计算时间相关的顶点两点关联函数，并在拓扑边界条件下提取量子扭结轮廓。三角门为模拟相互作用场论提供了物理自然的框架。

Conclusion: 三角连续变量门为在近期混合量子硬件上模拟相互作用场论提供了物理自然的框架，同时建立了超越多项式门构造的并行通用性路径。这些门有望在凝聚态系统、量子化学和生物模型的量子模拟中找到更广泛应用。

Abstract: Hybrid qubit-qumode quantum computing platforms provide a natural setting for simulating interacting bosonic quantum field theories. However, existing continuous-variable gate constructions rely predominantly on polynomial functions of canonical quadratures. In this work, we introduce a complementary universality paradigm based on trigonometric continuous-variable gates, which enable a Fourier-like representation of bosonic operators and are particularly well suited for periodic and non-perturbative interactions. We present a deterministic ancilla-based method for implementing unitary and non-unitary trigonometric gates whose arguments are arbitrary Hermitian functions of qumode quadratures. As a concrete application, we develop a hybrid qubit-qumode quantum simulation of the lattice sine-Gordon model. Using these gates, we prepare ground states via quantum imaginary-time evolution, simulate real-time dynamics, compute time-dependent vertex two-point correlation functions, and extract quantum kink profiles under topological boundary conditions. Our results demonstrate that trigonometric continuous-variable gates provide a physically natural framework for simulating interacting field theories on near-term hybrid quantum hardware, while establishing a parallel route to universality beyond polynomial gate constructions. We expect that the trigonometric gates introduced here to find broader applications, including quantum simulations of condensed matter systems, quantum chemistry, and biological models.

</details>


### [77] [Extracting quantum field theory dynamics from an approximate ground state](https://arxiv.org/abs/2512.19594)
*Sophie Mutzel,Antoine Tilloy*

Main category: quant-ph

TL;DR: 开发了一种线性规划方法，从量子场论的静态基态关联函数中提取动力学信息，通过凸优化问题重构Källén-Lehmann反演，能够从近似等时两点函数中稳健估计谱密度、实时传播子和质量间隙。


<details>
  <summary>Details</summary>
Motivation: 传统上需要实时演化才能获得量子场论的动力学信息，但实时演化在数值上具有挑战性。本文旨在开发一种方法，仅从静态的基态关联函数中提取动力学信息，这可以显著降低计算复杂度。

Method: 将Källén-Lehmann反演重新表述为凸优化问题，类似于Lawrence的方法。使用线性规划技术从近似的等时两点函数中提取信息，同时提供关联函数误差的后验下界。

Result: 在1+1维φ⁴模型上测试该方法，使用变分近似（相对论连续矩阵乘积态）获得连续极限和热力学极限下的精确关联函数。得到的质量间隙与重整化哈密顿量截断和Borel重求和微扰理论在广泛耦合范围内一致。

Conclusion: 该方法证明可以从单个等时切片中恢复精确的动力学数据，为从静态基态信息中提取量子场论动力学特性提供了有效工具。

Abstract: We develop a linear-programming method to extract dynamical information from static ground-state correlators in quantum field theory. We recast the Källén-Lehmann inversion as a convex optimization problem, in a spirit similar to the recent approach of Lawrence [arXiv:2408.11766]. This produces robust estimates of the smeared spectral density, the real-time propagator, and the mass gap directly from an approximate equal-time two-point function, and simultaneously yields an \emph{a posteriori} lower bound on the correlation-function error. We test the method on the $1+1$-dimensional $φ^4$ model, using a variational approximation to the vacuum -- relativistic continuous matrix product states -- that provides accurate correlators in the continuum and thermodynamic limits. The resulting mass gaps agree with renormalized Hamiltonian truncation and Borel-resummed perturbation theory across a wide range of couplings, demonstrating that accurate dynamical data can be recovered from a single equal-time slice.

</details>


### [78] [Nonequilibrium quantum thermometry with noncommutative system-bath couplings](https://arxiv.org/abs/2512.19607)
*Youssef Aiache,Abderrahim El Allati,İlkay Demir,Khadija El Anouz*

Main category: quant-ph

TL;DR: 该研究探讨了在量子低温环境下使用单量子比特探针进行非平衡量子测温的方法，通过非对易的相互作用算子将纯退相干和耗散动力学统一在自旋-玻色子模型中，发现干涉效应能增强热敏性。


<details>
  <summary>Details</summary>
Motivation: 量子低温环境下的精确温度测量是一个基本挑战，需要开发新的测温方法来克服传统方法的局限性。

Method: 使用单量子比特探针与玻色子浴通过非对易相互作用算子耦合，将纯退相干和耗散动力学统一在自旋-玻色子模型中，研究干涉效应对热敏性的影响。

Result: 非对易耦合通道之间的干涉导致强非马尔可夫反馈，产生相干俘获和增强的热敏性；通过调节耦合结构，探针的温度敏感性即使在弱耦合下也呈现二次低温标度；在早期非平衡区域，基于相干的测量成为最有效的方法。

Conclusion: 非对易系统-浴耦合是实现高精度量子测温的实用且可调谐资源，为现实开放系统架构中的量子测温提供了新途径。

Abstract: Accurate temperature estimation in the quantum and cryogenic regimes remains a fundamental challenge. Here, we investigate nonequilibrium quantum thermometry using a single-qubit probe coupled to a bosonic bath through noncommuting interaction operators, which unify pure dephasing and dissipative dynamics within a spin-boson model. We show that the interference between these two coupling channels induces strong non-Markovian feedback between populations and coherences, leading to coherence trapping and enhanced thermal sensitivity. Remarkably, by tuning the coupling structure, the probe's temperature sensitivity exhibits a quadratic low-temperature scaling, even under weak coupling. Moreover, while coherence-based measurements are formally suboptimal, they become the most informative in the early nonequilibrium regime, where memory effects dominate. Our findings identify noncommutative system-bath couplings as a practical and tunable resource for achieving high-precision quantum thermometry in realistic open-system architectures.

</details>


### [79] [Quantifying Decoherence](https://arxiv.org/abs/2512.19617)
*Mohd Shoaib Qureshi,Tabish Qureshi*

Main category: quant-ph

TL;DR: 提出了一种基于量子系统与环境纠缠的退相干度量方法，并在多种系统中验证其有效性，同时提出了马赫-曾德尔干涉仪中测量退相干的方法。


<details>
  <summary>Details</summary>
Motivation: 退相干是量子系统与环境相互作用导致量子相干性退化的现象，被认为是量子力学向经典性转变的主要机制。目前缺乏一个自然且有效的退相干度量方法。

Method: 采用基于量子系统与环境自由度纠缠的方法来度量退相干，提出了一种简单的退相干度量指标，并在多种示例系统中进行了检验。同时提出了在Mach-Zehnder干涉仪中测量退相干的方法。

Result: 提出的退相干度量方法被证明是有效的，并且相对容易计算。该方法能够自然地量化量子系统与环境之间的纠缠程度，从而准确反映退相干的程度。

Conclusion: 基于量子系统与环境纠缠的退相干度量方法提供了一个自然且有效的退相干量化框架，为理解和测量量子退相干现象提供了实用工具。

Abstract: Quantum decoherence refers to the phenomenon when the interaction of a quantum system with its environment results in the degradation of quantum coherence. Decoherence is considered to be the most popular mechanism responsible for the emergence of classicality from quantum mechanics. The issue of formulating a measure of decoherence is addressed here. The approach taken here is that decoherence results from the entanglement of a quantum system with certain environment degrees of freedom, and quantifying this entanglement should yield the most natural measure of decoherence. A simple measure of decoherence is presented based on this notion, and it is examined for various example systems. The measure proves to be effective and is relatively straightforward to compute. In addition, a method has been proposed to measure decoherence in a Mach-Zehnder interferometer.

</details>


### [80] [Exponential-to-polynomial scaling of measurement overhead in circuit knitting via quantum tomography](https://arxiv.org/abs/2512.19623)
*Hiroyuki Harada,Kaito Wada,Naoki Yamamoto,Suguru Endo*

Main category: quant-ph

TL;DR: 该论文提出了一种基于量子层析的电路切割方法，能够避免传统准概率分解方法中测量开销随切割数量指数增长的问题，特别适用于树状结构量子电路。


<details>
  <summary>Details</summary>
Motivation: 传统电路切割技术（如准概率分解）的测量开销随切割数量呈指数增长，这限制了在有限尺寸量子设备上执行大规模量子计算的能力。研究旨在探索这种指数缩放是否不可避免，并寻求更高效的电路切割方案。

Method: 采用级联量子层析协议：1) 对树深度为1（两层）的树状电路，通过量子层析为每个切割边构建局部分解，消除传统QPD中的缩放因子，引入由层析样本大小控制的可控偏差；2) 将方法扩展到深度L≥2的一般树状电路；3) 对完整R元树给出多项式缩放算法。

Result: 1) 树深度1情况下，总测量次数为O(d³R³ln(dR)/ε²)；2) 一般树深度情况下，总测量成本为Õ(d³K⁵/ε²)，其中K为切割数；3) 信息论分析显示，在可比设置下传统QPD方法至少需要Ω((d+1)ᴿ/ε²)次测量，存在指数级分离。

Conclusion: 基于层析的电路切割方法能够避免传统方法的指数测量开销，为树状结构量子电路提供了多项式缩放的高效切割方案，显著降低了混合量子-经典计算的测量开销。

Abstract: Circuit knitting is a family of techniques that enables large quantum computations on limited-size quantum devices by decomposing a target circuit into smaller subcircuits. However, it typically incurs a measurement overhead exponential in the number of cut locations, and it remains open whether this scaling is fundamentally unavoidable. In conventional circuit-cutting approaches based on the quasiprobability decomposition (QPD), for example, rescaling factors lead to an exponential dependence on the number of cuts. In this work, we show that such an exponential scaling is not universal: it can be circumvented for tree-structured quantum circuits via concatenated quantum tomography protocols. We first consider estimating the expectation value of an observable within additive error $ε$ for a tree-structured circuit with tree depth 1 (two layers), maximum branching factor $R$, and bond dimension at most $d$ on each edge. Our approach uses quantum tomography to construct, for each cut edge, a local decomposition that eliminates the rescaling factors in conventional QPD, instead introducing a controllable bias set by the tomography sample size. After cutting $R$ edges, we show that $\mathcal{O}(d^3R^3\ln(dR)/ε^2)$ total measurements suffice, including tomography cost. Next, we extend the tree-depth-1 case to general trees of depth $L\geq2$, and give an algorithm whose total measurement cost $\tilde{\mathcal{O}}(d^3K^{5}/ε^2)$ scales polynomially with the number of cuts for complete $R$-ary trees. Finally, we perform an information-theoretic analysis to show that, in a comparable tree-depth-1 setting, conventional QPD-based wire-cutting methods require at least $Ω((d+1)^R/ε^2)$ measurements. This exponential separation highlights the significance of tomography-based construction for reducing measurement overhead in hybrid quantum-classical computations.

</details>


### [81] [Quantum Imaging of Birefringent Samples using Hong-Ou-Mandel Interference](https://arxiv.org/abs/2512.19637)
*Carolina Gonçalves,Tiago D. Ferreira,Catarina S. Monteiro,Nuno A. Silva*

Main category: quant-ph

TL;DR: 该研究利用窄带光子对源扩展HOM干涉仪的应用范围，通过偏振显微镜实现厚度不敏感的双折射结构量子成像


<details>
  <summary>Details</summary>
Motivation: 传统HOM干涉仪在显微应用中受限于光学路径差敏感性，只能应用于厚度变化在微米级的样品。本研究旨在克服这一限制，扩展量子传感在偏振显微镜中的应用。

Method: 使用相干长度>1 mm的窄带光子对源拓宽HOM干涉谷，使样品厚度变化引起的时序可区分性可忽略。开发统计模型计算偏振旋转，推导Fisher信息，建立局部快轴角的最大似然估计器。通过光栅扫描记录每个样品位置的干涉谷和基线帧。

Result: 实验验证了该框架的有效性，结果与经典偏振强度图像一致，同时在最大精度状态下运行且对层厚度不敏感。实现了双折射结构的量子定量成像。

Conclusion: 该方法为双折射结构提供了基于量子的定量成像，可激励进一步优势应用，包括增强信噪比和降低光敏样品损伤。

Abstract: Two-photon interference in a Hong-Ou-Mandel (HOM) interferometer can be used as a quantum sensing mechanism due to the sensitivity of the interference dip to perturbations of the photon indistinguishability. In particular, recent works have generalized this concept to microscopy setups, but the sensitivity to optical path differences constrains its application to samples with thickness variation typically below a few micrometers if tracking changes in the coincidences at a fixed delay. Extending the concept to polarization microscopy and circumventing this limitation, this manuscript explores the use of a narrowband photon pair source with coherence length >1 mm to broaden the HOM dip. Thus, realistic sample-thickness variations introduce negligible temporal distinguishability, and changes in coincidence rate at the dip centre are then dominated by sample-induced polarization effects. To compute the polarization rotation, we develop a statistical model for the interferometer, derive the Fisher information, and establish a maximum-likelihood estimator for the local fast-axis angle. Recording dip and baseline frames at each sample position via raster scanning, the experimental results validate the framework, agreeing with classical polarized-intensity images while demonstrating operation at a maximum-precision regime and insensitiveness to layer thickness. Overall, the approach enclosed provides a quantum-based quantitative imaging of birefringent structures, which can motivate further advantageous applications, including enhanced signal-to-noise ratio and lower damage imaging of photosensitive samples.

</details>


### [82] [The EU Quantum Flagship's Key Performance Indicators for Quantum Computing](https://arxiv.org/abs/2512.19653)
*Zoltán Zimborás,Attila Portik,David Aguirre,Rubén Peña,Domonkos Svastits,András Pályi,Áron Márton,János K. Asbóth,Anton Frisk Kockum,Mikel Sanz,Orsolya Kálmán,Thomas Monz,Frank Wilhelm-Mauch*

Main category: quant-ph

TL;DR: 欧盟量子旗舰项目提出了一套可扩展的量子计算基准测试套件，包含四个核心基准，用于评估量子系统的整体性能，适用于NISQ设备和未来容错架构。


<details>
  <summary>Details</summary>
Motivation: 随着量子处理器规模和复杂性的增加，需要定义良好、可重复且与技术无关的性能指标来评估量子计算系统的整体性能。

Method: 开发了四个核心基准测试：1) Clifford Volume基准测试大规模多量子比特电路执行能力；2) GHZ态制备测试可扩展多体纠缠生成；3) 基于Shor周期查找子程序应用于简单函数的基准；4) 使用Bell态量化量子纠错效益的协议。每个基准都配有明确的协议、报告标准和可扩展评估方法。

Result: 提出了一套完整的量子计算关键性能指标(KPI)框架，能够透明、公平地评估不同量子硬件平台的性能，并跟踪从晚期NISQ到早期容错量子计算的进展。

Conclusion: 这套基准测试套件为量子计算系统提供了全面的性能评估框架，有助于标准化性能比较和跟踪技术发展，对推动量子计算从NISQ向容错架构过渡具有重要意义。

Abstract: As quantum processors continue to scale in size and complexity, the need for well-defined, reproducible, and technology-agnostic performance metrics becomes increasingly critical. Here we present a suite of scalable quantum computing benchmarks developed as key performance indicators (KPIs) within the EU Quantum Flagship. These proposed benchmarks are designed to assess holistic system performance rather than isolated components, and to remain applicable across both noisy intermediate-scale quantum (NISQ) devices and future fault-tolerant architectures. We introduce four core benchmarks addressing complementary aspects of quantum computing capability: large multi-qubit circuit execution via a Clifford Volume benchmark, scalable multipartite entanglement generation through GHZ-state preparation, a benchmark based on the application of Shor's period-finding subroutine to simple functions, and a protocol quantifying the benefit of quantum error correction using Bell states. Each benchmark is accompanied by clearly specified protocols, reporting standards, and scalable evaluation methods. Together, these KPIs provide a coherent framework for transparent and fair performance assessment across quantum hardware platforms and for tracking progress late-NISQ toward early fault-tolerant quantum computation.

</details>


### [83] [Extremizing Measures of Magic on Pure States by Clifford-stabilizer States](https://arxiv.org/abs/2512.19657)
*Muhammad Erew,Moshe Goldstein*

Main category: quant-ph

TL;DR: 该论文提出了一个关于量子计算中魔法态蒸馏的通用框架，将传统的Clifford稳定子态概念推广到任意有限群G，证明了G不变纯态在多种函数中的极值性，并识别了新的魔法态蒸馏候选态。


<details>
  <summary>Details</summary>
Motivation: 魔法态是实现通用容错量子计算的关键资源，但并非所有具有非零魔法的态都能通过稳定子码蒸馏。目前已知的可蒸馏态都是Clifford稳定子态的特例，需要建立更通用的理论框架来理解魔法态的蒸馏特性。

Method: 开发了一个关于Hermitian算子实流形上群协变泛函的通用框架，形式化了任意有限子群G的G-稳定子空间、态和码的概念，引入了G-协变泛函的解析族，并证明了G不变纯态在保持纯度的正交方向变化下是这些泛函的极值点。

Result: 证明了Clifford稳定子态是多种经典魔法度量（包括mana、稳定子Rényi熵和稳定子保真度）的极值点，对qubit、qutrit、ququint和两量子比特系统进行了分类，识别了新的魔法蒸馏候选态，并提出了一个针对两量子比特魔法态的低效蒸馏协议。

Conclusion: 该工作为魔法态蒸馏提供了统一的数学框架，将Clifford稳定子态的概念推广到任意有限群，证明了这些态在多种魔法度量中的极值性，为发现新的可蒸馏魔法态和设计更高效的蒸馏协议奠定了基础。

Abstract: Magic states are essential resources enabling universal, fault-tolerant quantum computation within the stabilizer framework. Their non-stabilizerness provides the additional resource required to overcome the constraints of stabilizer codes, as formalized by the Eastin-Knill theorem, while still permitting fault-tolerant distillation. Although numerous measures of magic have been introduced, not every state with nonzero magic has been shown to be distillable by a stabilizer code, and all currently known distillable states arise as special cases of Clifford-stabilizer states, defined as pure states uniquely stabilized by finite subgroups of the Clifford group. In this work, we develop a general framework for group-covariant functionals on the real manifold of Hermitian operators. We formalize the notions of $G$-stabilizer spaces, states, and codes for arbitrary finite subgroups $G \subset \mathrm{U}(\mathcal{H})$, and introduce analytic families of $G$-covariant functionals. Our main theorem shows that any $G$-invariant pure state is an extremal point of a broad class of derived functionals, including symmetric, max-type, and Rényi-type functionals, provided the underlying family is $G$-covariant. This extremality holds for variations restricted to directions orthogonal to the stabilized subspace while preserving purity. Specializing to the Pauli and Clifford groups, our framework unifies the extremality structure of several canonical magic measures, including mana, stabilizer Rényi entropies, and stabilizer fidelity. In particular, Clifford-stabilizer states extremize these measures. We classify such states for qubits, qutrits, ququints, and two-qubit systems, identifying new candidates for magic distillation protocols. We further propose an inefficient distillation protocol for a two-qubit magic state with stabilizer fidelity exceeding that of standard benchmark states.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [84] [Topological Flux on a Context Manifold Generates Nonreciprocal Collective Dynamics](https://arxiv.org/abs/2512.19598)
*Jyotiranjan Beuria,Venkatesh H. Chembrolu*

Main category: nlin.AO

TL;DR: 该论文展示了非互易性如何从内部拓扑结构自然涌现，通过Chern-Simons规范场耦合到内部"上下文流形"上，产生有效的横向反称相互作用核，导致手性波、持久涡旋和不可逆状态转变等非互易集体行为。


<details>
  <summary>Details</summary>
Motivation: 非互易相互作用在活性物质和生命系统中普遍存在，但现有模型通常采用唯象方式实现这种不对称性。本文旨在探索非互易性是否可以从更基本的内部拓扑结构中自然涌现，而不是人为引入。

Method: 提出一种理论框架：智能体在内部"上下文流形"上演化，该流形与Chern-Simons规范场耦合。由于该规范场是一阶时间导数，它会快速弛豫，消除后产生有效的横向反称相互作用核。通过数值模拟验证理论预测。

Result: 数值模拟显示明显的非互易性特征：长寿命涡旋核心、有限环流、不对称信息流和非零互易残差。动力学表现出显著的滞后现象，展示了在互易或势驱动系统中不可能出现的内存效应。

Conclusion: Chern-Simons规范场是方向性影响和稳健非互易集体行为的最小且普适来源。该研究为理解活性系统中非互易相互作用的起源提供了新的理论视角。

Abstract: Non-reciprocal interactions, where the influence of agent $i$ on $j$ differs from that of $j$ on $i$, are fundamental in active and living matter. Yet, most models implement such asymmetry phenomenologically. Here we show that non-reciprocity can emerge from internal topology alone. Agents evolve on an internal ``context manifold'' coupled to a Chern-Simons gauge field. Because the gauge field is first order in time, it relaxes rapidly; eliminating it yields an effective transverse, antisymmetric interaction kernel that generically produces chiral waves, persistent vorticity, and irreversible state transitions. Numerical simulations reveal clear signatures of broken reciprocity: long-lived vortex cores, finite circulation, asymmetric information flow, and a nonzero reciprocity residual. The dynamics further exhibit pronounced hysteresis under parameter sweeps, demonstrating memory effects that cannot occur in reciprocal or potential-driven systems. These results identify Chern-Simons gauge fields as a minimal and universal source of directional influence and robust non-reciprocal collective behavior.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [85] [Estimating Solvation Free Energies with Boltzmann Generators](https://arxiv.org/abs/2512.18147)
*Maximilian Schebek,Nikolas M. Froböse,Bettina G. Keller,Jutta Rogal*

Main category: cond-mat.stat-mech

TL;DR: 基于归一化流的计算框架直接映射不同尺寸溶质间的溶剂构型，相比传统自由能估计方法，在挑战性转化中提供可接受的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 准确计算溶剂化自由能是分子模拟中的核心挑战，通常需要大量采样和多个中间态来确保气相和溶液中溶质相空间分布有足够重叠。

Method: 引入基于归一化流的计算框架，直接映射不同尺寸溶质间的溶剂构型，并与传统自由能估计方法比较精度和效率。

Result: 对于Lennard-Jones溶剂，该方法在挑战性转化（如溶质生长或溶质-溶质间距增加）中提供可接受的自由能差估计精度，这些转化通常需要多个中间模拟步骤。径向分布函数分析表明，流模型能生成物理上有意义的溶剂重排，显著增强状态间构型空间的重叠。

Conclusion: 基于流的模型有望成为传统自由能估计方法的有前景替代方案。

Abstract: Accurate calculations of solvation free energies remain a central challenge in molecular simulations, often requiring extensive sampling and numerous alchemical intermediates to ensure sufficient overlap between phase-space distributions of a solute in the gas phase and in solution. Here, we introduce a computational framework based on normalizing flows that directly maps solvent configurations between solutes of different sizes, and compare the accuracy and efficiency to conventional free energy estimates. For a Lennard-Jones solvent, we demonstrate that this approach yields acceptable accuracy in estimating free energy differences for challenging transformations, such as solute growth or increased solute-solute separation, which typically demand multiple intermediate simulation steps along the transformation. Analysis of radial distribution functions indicates that the flow generates physically meaningful solvent rearrangements, substantially enhancing configurational overlap between states in configuration space. These results suggest flow-based models as a promising alternative to traditional free energy estimation methods.

</details>


### [86] [Current reversals in driven lattice gases and Brownian motion](https://arxiv.org/abs/2512.18280)
*Moritz Wolf,Sören Schweers,Philipp Maass*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究了在晶格气体中粒子电流逆向外加驱动的现象，推导了电流反转发生的条件，并扩展到连续空间动力学


<details>
  <summary>Details</summary>
Motivation: 粒子电流逆向外加驱动是一个有趣现象，但其物理机制尚未完全理解，特别是相互作用引起的电流反转难以预测。本文旨在推导外部时变驱动条件下晶格气体中电流反转发生的条件

Method: 基于粒子-空穴对称性，推导出当时间变化的驱动势在时间和/或空间平移后改变符号时，电流反转必然发生的条件。研究包括非稳态动力学和非平衡稳态下的时间相关空间平均电流

Result: 建立了电流反转发生的充分条件：当外部时变驱动势在时间和/或空间平移后改变符号时，晶格气体中必然出现电流反转。该方法还可推广到连续空间动力学，如硬核相互作用粒子在周期势中受行波驱动的情况

Conclusion: 通过粒子-空穴对称性分析，为晶格气体中电流反转现象提供了理论框架，揭示了驱动势的时空对称性在决定电流方向反转中的关键作用，并将该理论扩展到连续空间系统

Abstract: Particle currents flowing against an external driving are a fascinating phenomenon in both single-particle and interacting many-particle systems. Underlying physical mechanisms of such current reversals are not fully understood yet. Predicting their appearance is difficult, in particular for interaction-induced ones that emerge upon changes of the particle density. We here derive conditions on external time-dependent drivings, under which current reversals occur in lattice gases with arbitrary pair interactions. Our derivation is based on particle-hole symmetry and shows that current reversals must emerge if the time-varying driving potential changes sign after a translation in time and/or space. Our treatment includes nonstationary dynamics and time-dependent spatially averaged currents in nonequilibrium steady states. It gives insight also into possible occurrences of current reversals in continuous-space dynamics, which we demonstrate for hardcore interacting particles driven across a periodic potential by a traveling wave.

</details>


### [87] [Entropy of full covering of the kagome lattice by straight trimers](https://arxiv.org/abs/2512.18307)
*Deepak Dhar,Tiago J. Oliveira,R. Rajesh,Jürgen F. Stilck*

Main category: cond-mat.stat-mech

TL;DR: 研究kagome晶格上三聚体覆盖的构型数量，建立了与六角晶格二聚体覆盖的2对1对应关系，证明了三聚体覆盖的熵等于二聚体覆盖的熵


<details>
  <summary>Details</summary>
Motivation: 研究kagome晶格上刚性线性三聚体（每个覆盖3个格点）非重叠覆盖的构型数量，理解这种覆盖问题的统计力学性质

Method: 建立kagome晶格三聚体覆盖构型与相关六角晶格二聚体覆盖构型之间的2对1对应关系，利用已知的二聚体覆盖熵结果推导三聚体覆盖熵

Result: 证明kagome晶格三聚体覆盖的熵等于六角晶格二聚体覆盖的熵，具体数值为s_tri,kag = s_dim,hex = (1/2π)∫₀^{2π/3} log(2+2cosk)dk ≈ 0.323065947

Conclusion: 通过建立对应关系，成功计算了kagome晶格三聚体覆盖的精确熵值，揭示了这类覆盖问题的数学结构

Abstract: We consider the number of ways all the sites of a kagome lattice can be covered by non-overlapping linear rigid rods where each rod covers 3 sites. We establish a 2-to-1 correspondence between the configurations of trimers on the kagome lattice to the covering by dimers of a related hexagonal lattice to show that entropy of coverings per trimer $s_{\text{tri,kag}}$ equals the entropy per dimer $ s_{\text{dim,hex}} $, and is given by $ s_{\text{tri,kag}} = s_{\text{dim,hex}} = \frac{1}{2 π} \int_0^{ 2 π/3} \log( 2 + 2 \cos k) dk \approx 0.323065947\ldots$.

</details>


### [88] [Partition function and magnetization of two-dimensional Ising models in non-zero magnetic field: A semi-empirical approach](https://arxiv.org/abs/2512.18611)
*M V Vismaya,M V Sangaranarayanan*

Main category: cond-mat.stat-mech

TL;DR: 使用拓扑和图论方法推导了有限磁场下方形晶格铁磁伊辛模型的配分函数，得到了与Onsager精确解相似的结果


<details>
  <summary>Details</summary>
Motivation: 研究有限磁场下方形晶格铁磁伊辛模型的配分函数，扩展Onsager的零磁场精确解，探索磁场存在时的解析处理方法

Method: 采用基于拓扑考虑的启发式图论方法，分别推导低温和高温区域的配分函数方程，通过亥姆霍兹自由能计算自发磁化

Result: 推导出的配分函数方程与Onsager的精确解几乎相同，自发磁化与精确解一致，配分函数能导出已知的磁化和零场磁化率级数展开

Conclusion: 该方法为处理有限磁场下的伊辛模型提供了直接有效的协议，即使在磁场存在时也能获得与精确解一致的结果

Abstract: The partition functions of ferromagnetic Ising models of square lattices in a finite magnetic field is deduced using topological considerations within a heuristic graph-theoretical approach. These equations are derived separately for low and high temperature regimes while the exact solution of Onsager is obtained therefrom when the magnetic field is zero. The derived partition function equations here are almost similar to those given by Onsager, thus indicating a straight-forward protocol, even when the magnetic field is present. The spontaneous magnetization derived here using the Helmholtz free energy is identical with that arising from the exact solution. The partition functions lead to the known series expansions of the magnetization and zero-field susceptibility.

</details>


### [89] [Collective dynamics of higher-order Vicsek model emerging from local conformity interactions](https://arxiv.org/abs/2512.19318)
*Iván León,Riccardo Muolo,Hiroya Nakao,Keisuke Taga*

Main category: cond-mat.stat-mech

TL;DR: 研究自驱动粒子系统，其中粒子与邻居的对齐程度取决于局部对齐度，这种局部一致性相互作用自然产生具有成对和三体相互作用的Vicsek型模型。


<details>
  <summary>Details</summary>
Motivation: 研究局部一致性相互作用如何影响自驱动粒子系统的集体动力学，探索这种相互作用是否会产生新的有序相和相变行为。

Method: 通过数值模拟和近似理论分析，研究系统的确定性和随机性集体动力学，包括识别新的有序相和相变类型。

Result: 发现了一种新颖的双向有序相，粒子沿相反方向运动；观察到连续和不连续的有序-无序相变，表明系统属于与先前模型不同的普适类。

Conclusion: 局部一致性相互作用能够产生具有成对和三体相互作用的Vicsek型模型，并导致新的双向有序相和不同的相变行为，扩展了对自驱动粒子系统集体行为的理解。

Abstract: We study a system of self-propelled particles whose alignment with neighbors depends on the degree of local alignment. We show that such a local conformity interaction naturally yields a Vicsek-type model with pairwise and three-body interactions. Through numerical and approximate theoretical investigation of its deterministic and stochastic collective dynamics, we identify a novel bidirectionally ordered phase in which the particles move in opposite directions. Moreover, both continuous and discontinuous order-disorder transitions are observed, suggesting that the system belongs to a different universality class from previous models.

</details>


### [90] [Time transport correlations in abelian sandpile models](https://arxiv.org/abs/2512.18723)
*Valentin Lallemant*

Main category: cond-mat.stat-mech

TL;DR: 本文揭示了阿贝尔沙堆模型中时间输运相关性的普遍而简单的性质，从广泛适用的结果逐步深入到特定模型，证明了粒子耗散主要呈现时间反相关性，并建立了两点时间输运相关性与时间积分输运二阶矩之间的联系。


<details>
  <summary>Details</summary>
Motivation: 沙堆模型是展示临界稳态的最大类别模型之一，但几十年来对其空间和时间依赖性质的全面系统严谨表征仍然难以实现。主要障碍包括其非平衡和非线性动力学特征，通常阻碍了对稳态性质的明确访问。事实上，即使在沙堆模型中，对稳态的了解也相当罕见。因此，开发模型到模型的策略已成为标准做法，而适用于这些系统的通用结果或工具仍然缺失。

Method: 采用渐进方法，从适用于广泛背景的结果开始，逐步深入到越来越具体的结果，因此适用于越来越小的类别。在几个假设下，证明了粒子耗散主要呈现时间反相关性。从更可积的角度来看，该方法最终建立了两点时间输运相关性与时间积分输运二阶矩之间的联系，这两个量通过线性方程组相关，该方程组被明确求解并适用于至少三个一维沙堆模型。

Result: 揭示了阿贝尔沙堆模型中时间输运相关性的普遍性质；证明了在几个假设下，粒子耗散主要呈现时间反相关性；建立了两点时间输运相关性与时间积分输运二阶矩之间的明确数学联系；该方法适用于至少三个一维沙堆模型：定向随机沙堆模型、奥斯陆模型和激活随机游走模型（在特定设置下）。

Conclusion: 本文提供了沙堆模型中时间输运相关性的通用分析框架，通过渐进方法从一般到具体，建立了重要的数学联系，为理解这些复杂系统的动力学行为提供了新的工具和见解，填补了该领域通用分析工具的空白。

Abstract: Sandpiles form one of the largest class of models displaying a critical stationary state. Despite a few decades of research, a comprehensive and systematic rigorous characterisation of their spatial and, even more, time dependent properties has remained elusive. Among the obstacles, we can mention their out of equilibrium and non-linear dynamics features which prevent, in general, the access to the stationary properties explicitly. In fact, even the knowledge of the stationary state is quite exceptional in sandpiles. In that respect, it has become standard to develop a model to model strategy and, so to say, general results or tools applicable to these systems are missing. In this paper, we unveil general and simple properties of time transport correlations in certain classes of abelian sandpile models. We proceed gradually, starting from results applicable in a broad context, to more and more specific ones, consequently valid to smaller and smaller classes. For instance, we show, under a few hypothesis, that the number of particles dissipated displays mostly anticorrelation in time. Besides, on a more integrable point of view, the approach followed might culminate with the proof of a link between 2-points time transport correlations and the second moment of the integrated transport over time. To be clear, these two quantities are related through a linear system of equations which is explicitly solved and applies to at least three 1D sandpile models, namely the Directed Stochastic Sandpile, the Oslo and the Activated Random Walk (in a peculiar setup) models.

</details>


### [91] [Nonreciprocal yet Symmetric Multi-Species Active Matter: Emergence of Chirality and Species Separation](https://arxiv.org/abs/2512.18749)
*Chul-Ung Woo,Heiko Rieger,Jae Dong Noh*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种具有置换对称性的多物种非互易活性物质模型，通过速度对齐相互作用中的恒定相位偏移实现非互易但对称的相互作用，展示了丰富的集体行为。


<details>
  <summary>Details</summary>
Motivation: 传统非互易活性物质系统通常具有不对称的相互作用角色（如追逐者-逃避者关系），本文旨在构建一种具有置换对称性的多物种非互易活性物质模型，探索非互易性与对称性共同作用下的集体行为。

Method: 提出多物种非互易活性物质模型，通过速度对齐相互作用中的恒定相位偏移实现非互易但对称的相互作用，而非传统的不对称耦合矩阵。模型具有粒子物种的置换对称性。

Result: 系统展示了丰富的集体行为：物种混合的手性相（具有准长程极性序）、物种分离相（以涡旋细胞为特征），以及手性相和物种分离相的共存相（产生有趣的动态模式）。

Conclusion: 这些丰富的集体行为是非互易性与置换对称性相互作用的直接结果，表明在保持对称性的同时引入非互易性可以产生新颖的集体现象。

Abstract: Nonreciprocal active matter systems typically feature an asymmetric role among interacting agents, such as a pursuer-evader relationship. We propose a multi-species nonreciprocal active matter model that is invariant under permutations of the particle species. The nonreciprocal, yet symmetric, interactions emerge from a constant phase shift in the velocity alignment interactions, rather than from an asymmetric coupling matrix. This system possessing permutation symmetry displays rich collective behaviors, including a species-mixed chiral phase with quasi-long-range polar order and a species separation phase characterized by vortex cells. The system also displays a coexistence phase of the chiral and the species separation phases, in which intriguing dynamic patterns emerge. These rich collective behaviors are a consequence of the interplay between nonreciprocity and permutation symmetry.

</details>


### [92] [Collective behavior in the nonreciprocal multi-species Vicsek model](https://arxiv.org/abs/2512.18756)
*Chul-Ung Woo,Heiko Rieger,Jae Dong Noh*

Main category: cond-mat.stat-mech

TL;DR: 研究具有非互易速度对齐相互作用的Q物种Vicsek模型，系统具有Potts对称性和相位偏移α，产生了四种相态：物种混合手性相、物种分离相、共存相和无序相。


<details>
  <summary>Details</summary>
Motivation: 探索非互易相互作用和Potts对称性结合在多物种主动粒子系统中的集体行为，理解相位偏移如何影响系统动力学和相变。

Method: 使用Q物种Vicsek模型，引入非互易速度对齐相互作用（具有恒定相位偏移α），推导Boltzmann方程和流体动力学方程，分析手性产生和物种分离的机制。

Result: 系统表现出四种相态：1）物种混合手性相（逆时针手性运动，准长程有序）；2）物种分离相（Potts对称性破缺，物种分离粒子形成顺时针手性涡旋细胞）；3）共存相；4）无序相。相位偏移产生手性，Potts对称性可自发破缺。

Conclusion: 非互易相互作用和Potts对称性的结合在多物种主动粒子系统中产生丰富的相图，包括手性运动和物种分离现象，为理解复杂生物系统中的集体行为提供了理论框架。

Abstract: We investigate collective behavior in a $Q$-species Vicsek model with a nonreciprocal velocity alignment interaction. This system is characterized by a constant phase shift $α$ in the inter-species velocity alignment rule. While the phase shift renders the interaction nonreciprocal, the system is globally invariant under any permutations of particle species, possessing Potts symmetry. The combination of Potts symmetry and nonreciprocity gives rise to a rich phase diagram. The nonreciprocal phase shift generates either counter-clockwise or clockwise chirality. Potts symmetry can be broken spontaneously. Consequently, the system exhibits four distinct phases: A species-mixed chiral phase where particles perform counter-clockwise chiral motion with quasi-long-range order, a species separation phase where Potts symmetry is broken and species-separated particles form vortex cells with clockwise chirality, a coexistence phase, and a disordered phase. We derive a Boltzmann equation and a hydrodynamic equation describing the system in the continuum limit, and present analytic arguments for the emergence of chirality and species separation.

</details>


### [93] [Nonreciprocal Blume-Capel Model with Antisymmetric Single-Ion Anisotropies](https://arxiv.org/abs/2512.18917)
*Arjun R,Pratyush Prakash Patra,A. V. Anil Kumar*

Main category: cond-mat.stat-mech

TL;DR: 研究非互易相互作用与化学势不平衡在双物种非互易Blume-Capel模型中的相互作用，通过平均场理论和蒙特卡洛模拟揭示了丰富的相结构和相变行为。


<details>
  <summary>Details</summary>
Motivation: 研究非互易系统中空位能量如何影响相变行为，探索实验相关的控制参数来稳定非互易系统中的类平衡有序态。

Method: 结合系统的平均场分岔分析和二维、三维的大规模蒙特卡洛模拟，绘制模型的动力学区域和相变图。

Result: 平均场理论预测了丰富的相结构；二维模拟显示螺旋缺陷破坏全局交换和长程有序；有限单离子各向异性促进空位占据并恢复静态有序相；无序到静态相变属于2D Ising普适类；静态有序相内存在交叉行为；三维模拟基本符合平均场预期。

Conclusion: 空位能量学为非互易系统提供了简单且实验相关的控制参数，能够稳定类平衡有序态，同时缺陷可以产生新的临界行为。

Abstract: We investigate the interplay between nonreciprocal interactions and chemical-potential imbalance in a two-species nonreciprocal Blume-Capel model. Combining a systematic mean-field bifurcation analysis with large-scale Monte Carlo simulations in two and three dimensions, we map the model's dynamical regimes and transitions. Mean-field theory predicts a rich phase structure -- disorder, a time-dependent 'swap' (limit-cycle) phase, and static ordered states -- separated by Hopf, saddle-node on invariant circle, saddle-node of limit cycles, pitchfork and saddle-node bifurcations. In two dimensions, Monte Carlo simulations reveal that spiral defects destabilise global swapping and, unless vacancies are strongly favoured, destroy long-range order. Crucially, a finite single-ion anisotropy $Δ_α= - Δ_β$ promotes vacancy occupation in the $α$ species and suppresses nonreciprocal dynamics, thereby restoring a robust static ordered phase. Finite-size scaling of susceptibility and Binder cumulants places the disorder to static transition firmly in the 2D Ising universality class. Moreover, within the static ordered phase, we observe a crossover that sharpens into a line of first-order phase transitions; these two regimes are separated by a critical point, analogous to the termination of the liquid-gas coexistence curve. In three dimensions, simulations largely mirror mean-field expectations, though swap to static ordering occurs indirectly via a disordered regime. Our results demonstrate that vacancy energetics provide a simple, experimentally relevant control knob that stabilises equilibrium-like order in nonreciprocal systems and that defects can generate novel critical behaviour.

</details>


### [94] [Kinetic theory of pattern formation in a generalized multi-species Vicsek model](https://arxiv.org/abs/2512.19393)
*Eloise Lardet,Letian Chen,Thibault Bertrand*

Main category: cond-mat.stat-mech

TL;DR: 本文开发了多物种自驱动粒子系统的动力学理论，用于分析具有（反）对齐相互作用的活性物质系统中的模式形成，理论预测与粒子模拟结果一致。


<details>
  <summary>Details</summary>
Motivation: 理解活性系统中的模式形成是一个核心理论问题。由多个物种组成的异质群体可以表现出单物种模型无法获得的显著多样性集体状态，需要理论框架来分析这种多物种系统的模式形成和集体有序。

Method: 推导了具有（反）对齐相互作用的多物种自驱动粒子系统的动力学理论，对粗粒化系统进行线性稳定性分析，并将理论扩展到具有循环对齐相互作用的多物种系统。

Result: 理论预测与粒子模拟结果吻合良好，动力学理论能够通过图灵-霍普夫不稳定性捕捉到涌现共存相中的正确长度尺度。对于循环对齐相互作用的多物种系统，理论精确恢复了与微观模型模拟相同的涌现有序。

Conclusion: 该动力学理论为分析多物种活性物质系统中的模式形成和集体有序提供了一个可扩展的框架，能够捕捉单物种模型无法获得的复杂集体状态。

Abstract: The theoretical understanding of pattern formation in active systems remains a central problem of interest. Heterogeneous flocks made up of multiple species can exhibit a remarkable diversity of collective states that cannot be obtained from single-species models. In this paper, we derive a kinetic theory for multi-species systems of self-propelled particles with (anti-)alignment interactions. We summarize the numerical results for the binary system before employing linear stability analysis on the coarse-grained system. We find good agreement between theoretical predictions and particle simulations, and our kinetic theory is able to capture the correct lengthscale in the emergent coexistence phases through a Turing-Hopf instability. Extending the kinetic framework to multi-species systems with cyclic alignment interactions, we recover precisely the same emergent ordering as corresponding simulations of the microscopic model. More generally, our kinetic theory provides an extensible framework for analyzing pattern formation and collective order in multi-species active matter systems.

</details>


### [95] [Escape from heterogeneous diffusion](https://arxiv.org/abs/2512.19646)
*Hwai-Ray Tung,Sean D Lawley*

Main category: cond-mat.stat-mech

TL;DR: 该研究分析了异质扩散过程中粒子找到目标的平均逃逸时间和分裂概率，解决了伊藤与斯特拉托诺维奇解释的争议，揭示了扩散异质性对搜索效率的复杂影响。


<details>
  <summary>Details</summary>
Motivation: 虽然经典扩散过程中粒子找到目标的时间已被充分理解，但对于扩散系数依赖于粒子位置的异质扩散情况知之甚少。这种异质性导致了对随机过程解释的模糊性，反映了伊藤与斯特拉托诺维奇解释的争议。

Method: 作者解析地确定了任意三维域中任意异质扩散的平均逃逸时间和分裂概率，考虑了完美吸收和不完美吸收的小目标情况。分析了异质扩散及其解释（如伊藤、斯特拉托诺维奇或动力学解释）如何影响搜索过程。

Result: 研究揭示了异质扩散影响搜索的一般原理，发现了一个复杂的图景：增加扩散系数可能减少、不影响甚至增加逃逸时间。结果可用于确定特定物理系统的适当解释。

Conclusion: 该研究为理解异质扩散过程中的搜索行为提供了理论框架，解决了随机过程解释的争议，并揭示了扩散异质性对搜索效率的非单调影响，为特定物理系统的建模提供了指导。

Abstract: Many physical processes depend on the time it takes a diffusing particle to find a target. Though this classical quantity is now well-understood in various scenarios, little is known if the diffusivity depends on the location of the particle. For such heterogeneous diffusion, an ambiguity arises in interpreting the stochastic process, which reflects the well-known Itô versus Stratonovich controversy. Here we analytically determine the mean escape time and splitting probabilities for an arbitrary heterogeneous diffusion in an arbitrary three-dimensional domain with small targets that can be perfectly or imperfectly absorbing. Our analysis reveals general principles for how search depends on heterogeneous diffusion and its interpretation (e.g. Itô, Stratonovich, or kinetic). An intricate picture emerges in which, for instance, increasing the diffusivity can decrease, not affect, or even increase the escape time. Our results could be used to determine the appropriate interpretation for specific physical systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [96] [Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States](https://arxiv.org/abs/2512.17934)
*Soheil Hashtarkhani,Brianna M. White,Benyamin Hoseini,David L. Schwartz,Arash Shaban-Nejad*

Main category: cs.LG

TL;DR: 该研究使用随机森林、梯度提升回归和线性回归三种模型预测美国县级肺癌死亡率，发现随机森林模型表现最佳，吸烟率是最重要的预测因子，空间分析显示美国中东部县存在肺癌死亡率显著聚集区。


<details>
  <summary>Details</summary>
Motivation: 肺癌是美国癌症相关死亡的主要原因，准确预测肺癌死亡率对于指导针对性干预措施和解决健康差异至关重要。虽然传统回归模型常用，但可解释的机器学习模型可能提供更好的预测准确性和对影响因素的深入洞察。

Method: 研究应用随机森林(RF)、梯度提升回归(GBR)和线性回归(LR)三种模型预测美国县级肺癌死亡率。使用R平方和均方根误差评估模型性能，使用SHAP值确定变量重要性及其方向影响，通过Getis-Ord热点分析分析地理差异。

Result: 随机森林模型表现最佳，R²值为41.9%，RMSE为12.8。SHAP分析显示吸烟率是最重要的预测因子，其次是房屋中位价值和西班牙裔人口比例。空间分析发现美国中东部县存在肺癌死亡率显著聚集区。

Conclusion: 随机森林模型在预测肺癌死亡率方面表现出优越性能，强调了吸烟率、房屋价值和西班牙裔人口比例的关键作用。这些发现为设计针对性干预措施、促进筛查和解决美国肺癌高发地区的健康差异提供了有价值的见解。

Abstract: Lung cancer (LC) is a leading cause of cancer-related mortality in the United States. Accurate prediction of LC mortality rates is crucial for guiding targeted interventions and addressing health disparities. Although traditional regression-based models have been commonly used, explainable machine learning models may offer enhanced predictive accuracy and deeper insights into the factors influencing LC mortality. This study applied three models: random forest (RF), gradient boosting regression (GBR), and linear regression (LR) to predict county-level LC mortality rates across the United States. Model performance was evaluated using R-squared and root mean squared error (RMSE). Shapley Additive Explanations (SHAP) values were used to determine variable importance and their directional impact. Geographic disparities in LC mortality were analyzed through Getis-Ord (Gi*) hotspot analysis. The RF model outperformed both GBR and LR, achieving an R2 value of 41.9% and an RMSE of 12.8. SHAP analysis identified smoking rate as the most important predictor, followed by median home value and the percentage of the Hispanic ethnic population. Spatial analysis revealed significant clusters of elevated LC mortality in the mid-eastern counties of the United States. The RF model demonstrated superior predictive performance for LC mortality rates, emphasizing the critical roles of smoking prevalence, housing values, and the percentage of Hispanic ethnic population. These findings offer valuable actionable insights for designing targeted interventions, promoting screening, and addressing health disparities in regions most affected by LC in the United States.

</details>


### [97] [What's the Price of Monotonicity? A Multi-Dataset Benchmark of Monotone-Constrained Gradient Boosting for Credit PD](https://arxiv.org/abs/2512.17945)
*Petr Koklev*

Main category: cs.LG

TL;DR: 本文量化了信用风险建模中单调性约束的成本，发现在大数据集上约束几乎无成本，在小数据集上成本约为2-3%的AUC下降。


<details>
  <summary>Details</summary>
Motivation: 金融机构在部署机器学习模型进行信用风险评估时面临预测准确性和可解释性之间的权衡。单调性约束虽然能确保模型行为符合领域知识，但其性能成本（单调性的代价）尚未得到充分量化。

Method: 使用五个公共数据集和三个库，对单调约束与无约束的梯度提升模型进行基准测试。定义了"单调性代价"（PoM）作为从无约束模型转向约束模型时标准性能指标的相对变化，通过配对比较和bootstrap不确定性进行估计。

Result: 实验显示，PoM在AUC上的范围从几乎为零到约2.9%。在大数据集上约束几乎无成本（通常小于0.2%，常与零无异），而在约束覆盖广泛的小数据集上成本最高（约2-3%）。

Conclusion: 适当指定的单调性约束通常能以较小的准确性损失提供可解释性，特别是在大规模信用投资组合中。

Abstract: Financial institutions face a trade-off between predictive accuracy and interpretability when deploying machine learning models for credit risk. Monotonicity constraints align model behavior with domain knowledge, but their performance cost - the price of monotonicity - is not well quantified. This paper benchmarks monotone-constrained versus unconstrained gradient boosting models for credit probability of default across five public datasets and three libraries. We define the Price of Monotonicity (PoM) as the relative change in standard performance metrics when moving from unconstrained to constrained models, estimated via paired comparisons with bootstrap uncertainty. In our experiments, PoM in AUC ranges from essentially zero to about 2.9 percent: constraints are almost costless on large datasets (typically less than 0.2 percent, often indistinguishable from zero) and most costly on smaller datasets with extensive constraint coverage (around 2-3 percent). Thus, appropriately specified monotonicity constraints can often deliver interpretability with small accuracy losses, particularly in large-scale credit portfolios.

</details>


### [98] [CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs](https://arxiv.org/abs/2512.17970)
*Gunho Park,Jeongin Bae,Byeongwook Kim,Baeseong park,Jiwon Ryu,Hoseung Kim,Se Jung Kwon,Dongsoo Lee*

Main category: cs.LG

TL;DR: CodeGEMM：一种面向代码本量化的GEMM内核，通过预计算质心与激活的内积来替代反量化，在2-bit量化下显著提升LLM推理速度


<details>
  <summary>Details</summary>
Motivation: 当前基于代码本的量化方法在极低比特（如2-bit）下虽然能保持良好精度，但其内核依赖反量化操作，需要反复获取质心和重建权重，导致显著的延迟和缓存压力

Method: 提出CodeGEMM内核，用预计算的质心与激活内积（存储在轻量级Psumbook中）替代反量化。推理时直接通过代码索引收集这些部分和，消除了逐元素查找并减少了片上存储占用

Result: 在Llama-3模型上，CodeGEMM在2-bit配置下相比最先进的基于代码本的量化方法，实现了1.83倍（8B）和8.93倍（70B）的加速，同时保持可比精度，并进一步提升了计算效率和内存子系统利用率

Conclusion: CodeGEMM通过代码本中心的GEMM内核设计，系统性地探索了延迟-内存-精度权衡，为极低比特LLM推理提供了高效的解决方案

Abstract: Weight-only quantization is widely used to mitigate the memory-bound nature of LLM inference. Codebook-based methods extend this trend by achieving strong accuracy in the extremely low-bit regime (e.g., 2-bit). However, current kernels rely on dequantization, which repeatedly fetches centroids and reconstructs weights, incurring substantial latency and cache pressure. We present CodeGEMM, a codebook-centric GEMM kernel that replaces dequantization with precomputed inner products between centroids and activations stored in a lightweight Psumbook. At inference, code indices directly gather these partial sums, eliminating per-element lookups and reducing the on-chip footprint. The kernel supports the systematic exploration of latency-memory-accuracy trade-offs under a unified implementation. On Llama-3 models, CodeGEMM delivers 1.83x (8B) and 8.93x (70B) speedups in the 2-bit configuration compared to state-of-the-art codebook-based quantization at comparable accuracy and further improves computing efficiency and memory subsystem utilization.

</details>


### [99] [Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models](https://arxiv.org/abs/2512.17983)
*Irina Seregina,Philippe Lalanda,German Vega*

Main category: cs.LG

TL;DR: 该论文研究了用于人类活动识别的参数高效微调技术，特别是LoRA和量化LoRA，作为全模型微调的可扩展替代方案，在减少参数、内存使用和训练时间的同时保持识别性能。


<details>
  <summary>Details</summary>
Motivation: 尽管自监督学习和基于Transformer的架构显著提升了人类活动识别性能，但在目标设备计算资源有限的情况下，将大型预训练模型适应新领域仍然是一个实际挑战。

Method: 提出基于掩码自编码器骨干的适应框架，采用低秩适应和量化低秩适应技术，通过Leave-One-Dataset-Out验证协议在五个开放HAR数据集上进行评估。

Result: 实验表明LoRA和QLoRA都能匹配全微调的识别性能，同时显著减少可训练参数、内存使用和训练时间。LoRA在有限监督下保持鲁棒性能，适配器秩提供精度与效率的可控权衡，QLoRA通过量化进一步减少内存占用且对分类质量影响最小。

Conclusion: 参数高效微调技术（特别是LoRA和QLoRA）为人类活动识别提供了可扩展的解决方案，在保持性能的同时显著降低计算资源需求，适用于资源受限的设备部署场景。

Abstract: Human Activity Recognition is a foundational task in pervasive computing. While recent advances in self-supervised learning and transformer-based architectures have significantly improved HAR performance, adapting large pretrained models to new domains remains a practical challenge due to limited computational resources on target devices. This papers investigates parameter-efficient fine-tuning techniques, specifically Low-Rank Adaptation (LoRA) and Quantized LoRA, as scalable alternatives to full model fine-tuning for HAR. We propose an adaptation framework built upon a Masked Autoencoder backbone and evaluate its performance under a Leave-One-Dataset-Out validation protocol across five open HAR datasets. Our experiments demonstrate that both LoRA and QLoRA can match the recognition performance of full fine-tuning while significantly reducing the number of trainable parameters, memory usage, and training time. Further analyses reveal that LoRA maintains robust performance even under limited supervision and that the adapter rank provides a controllable trade-off between accuracy and efficiency. QLoRA extends these benefits by reducing the memory footprint of frozen weights through quantization, with minimal impact on classification quality.

</details>


### [100] [FedOAED: Federated On-Device Autoencoder Denoiser for Heterogeneous Data under Limited Client Availability](https://arxiv.org/abs/2512.17986)
*S M Ruhul Kabir Howlader,Xiao Chen,Yifei Xie,Lu Liu*

Main category: cs.LG

TL;DR: FedOAED是一种新颖的联邦学习算法，通过客户端本地自编码器降噪器来缓解异构数据下的客户端漂移和部分客户端参与带来的方差问题。


<details>
  <summary>Details</summary>
Motivation: 严格的隐私法规限制了数据共享，联邦学习虽能解决此问题，但仍面临数据异构性导致的梯度噪声、客户端漂移和部分参与方差等挑战。

Method: 提出FedOAED算法，在客户端侧集成设备端自编码器降噪器，缓解异构数据和有限客户端可用性导致的客户端漂移和方差。

Result: 在多个视觉数据集上的非独立同分布设置实验中，FedOAED持续优于现有最先进的基线方法。

Conclusion: FedOAED通过设备端降噪机制有效解决了联邦学习中的异构性和部分参与问题，为隐私保护下的机器学习提供了更优解决方案。

Abstract: Over the last few decades, machine learning (ML) and deep learning (DL) solutions have demonstrated their potential across many applications by leveraging large amounts of high-quality data. However, strict data-sharing regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) have prevented many data-driven applications from being realised. Federated Learning (FL), in which raw data never leaves local devices, has shown promise in overcoming these limitations. Although FL has grown rapidly in recent years, it still struggles with heterogeneity, which produces gradient noise, client-drift, and increased variance from partial client participation. In this paper, we propose FedOAED, a novel federated learning algorithm designed to mitigate client-drift arising from multiple local training updates and the variance induced by partial client participation. FedOAED incorporates an on-device autoencoder denoiser on the client side to mitigate client-drift and variance resulting from heterogeneous data under limited client availability. Experiments on multiple vision datasets under Non-IID settings demonstrate that FedOAED consistently outperforms state-of-the-art baselines.

</details>


### [101] [A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients](https://arxiv.org/abs/2512.18031)
*Sarah Nassar,Nooshin Maghsoodi,Sophia Mannina,Shamel Addas,Stephanie Sibley,Gabor Fichtinger,David Pichora,David Maslove,Purang Abolmaesumi,Parvin Mousavi*

Main category: cs.LG

TL;DR: 该研究发布了一个ICU房颤检测的标注数据集和基准测试，比较了三种AI方法：基于特征的分类器、深度学习和ECG基础模型，发现ECG基础模型在房颤检测中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 房颤是ICU患者最常见的心律失常，可能导致不良健康影响。目前文献中缺乏对ICU房颤检测AI方法的系统比较，本研究旨在填补这一空白，确定哪种AI方法最适合准确的房颤检测。

Method: 研究比较了三种数据驱动的AI方法：基于特征的分类器、深度学习和ECG基础模型。使用加拿大ICU和2021年PhysioNet/Computing in Cardiology Challenge的心电图数据进行实验。测试了多种训练配置，从零样本推理到迁移学习。

Result: 在两个数据集上，ECG基础模型平均表现最佳，其次是深度学习，最后是基于特征的分类器。在ICU测试集上获得最高F1分数（0.89）的模型是通过迁移学习策略的ECG基础模型。

Conclusion: 这项研究展示了使用AI构建自动患者监测系统的潜力。通过发布标注的ICU数据集和性能基准，这项工作使研究社区能够继续推进ICU房颤检测的最新技术。

Abstract: Objective: Atrial fibrillation (AF) is the most common cardiac arrhythmia experienced by intensive care unit (ICU) patients and can cause adverse health effects. In this study, we publish a labelled ICU dataset and benchmarks for AF detection. Methods: We compared machine learning models across three data-driven artificial intelligence (AI) approaches: feature-based classifiers, deep learning (DL), and ECG foundation models (FMs). This comparison addresses a critical gap in the literature and aims to pinpoint which AI approach is best for accurate AF detection. Electrocardiograms (ECGs) from a Canadian ICU and the 2021 PhysioNet/Computing in Cardiology Challenge were used to conduct the experiments. Multiple training configurations were tested, ranging from zero-shot inference to transfer learning. Results: On average and across both datasets, ECG FMs performed best, followed by DL, then feature-based classifiers. The model that achieved the top F1 score on our ICU test set was ECG-FM through a transfer learning strategy (F1=0.89). Conclusion: This study demonstrates promising potential for using AI to build an automatic patient monitoring system. Significance: By publishing our labelled ICU dataset (LinkToBeAdded) and performance benchmarks, this work enables the research community to continue advancing the state-of-the-art in AF detection in the ICU.

</details>


### [102] [Towards Benchmarking Privacy Vulnerabilities in Selective Forgetting with Large Language Models](https://arxiv.org/abs/2512.18035)
*Wei Qian,Chenxu Zhao,Yangyi Li,Mengdi Huai*

Main category: cs.LG

TL;DR: 本文提出了首个选择性遗忘隐私漏洞的综合性基准测试，系统评估了不同数据、攻击方法、遗忘技术和模型架构下的隐私泄露风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在关键领域的部署，确保隐私和符合人类价值观变得至关重要。选择性遗忘（机器遗忘）在隐私和数据移除任务中显示出潜力，但同时也引发了严重的隐私担忧。现有的遗忘诱导隐私攻击评估存在实验设置不一致、结果过于乐观的问题，缺乏标准化评估框架。

Method: 建立了首个全面的选择性遗忘隐私漏洞基准测试，广泛调查了机器遗忘技术的隐私漏洞，并在广泛的受害者数据、最先进的遗忘隐私攻击、遗忘方法和模型架构上对隐私泄露进行了基准测试。系统性地评估和识别了与遗忘诱导隐私泄露相关的关键因素。

Result: 通过系统性评估，识别了影响遗忘隐私泄露的关键因素，为从业者提供了标准化的评估工具。研究揭示了不同实验设置可能导致对特定攻击方法的过度乐观评估，强调了标准化评估的重要性。

Conclusion: 该研究填补了选择性遗忘隐私评估的空白，为部署定制化遗忘应用提供了可靠的隐私评估工具，有助于促进AI系统的隐私保护和合规性。

Abstract: The rapid advancements in artificial intelligence (AI) have primarily focused on the process of learning from data to acquire knowledgeable learning systems. As these systems are increasingly deployed in critical areas, ensuring their privacy and alignment with human values is paramount. Recently, selective forgetting (also known as machine unlearning) has shown promise for privacy and data removal tasks, and has emerged as a transformative paradigm shift in the field of AI. It refers to the ability of a model to selectively erase the influence of previously seen data, which is especially important for compliance with modern data protection regulations and for aligning models with human values. Despite its promise, selective forgetting raises significant privacy concerns, especially when the data involved come from sensitive domains. While new unlearning-induced privacy attacks are continuously proposed, each is shown to outperform its predecessors using different experimental settings, which can lead to overly optimistic and potentially unfair assessments that may disproportionately favor one particular attack over the others. In this work, we present the first comprehensive benchmark for evaluating privacy vulnerabilities in selective forgetting. We extensively investigate privacy vulnerabilities of machine unlearning techniques and benchmark privacy leakage across a wide range of victim data, state-of-the-art unlearning privacy attacks, unlearning methods, and model architectures. We systematically evaluate and identify critical factors related to unlearning-induced privacy leakage. With our novel insights, we aim to provide a standardized tool for practitioners seeking to deploy customized unlearning applications with faithful privacy assessments.

</details>


### [103] [Probabilistic Digital Twins of Users: Latent Representation Learning with Statistically Validated Semantics](https://arxiv.org/abs/2512.18056)
*Daniel David*

Main category: cs.LG

TL;DR: 提出概率数字孪生框架，使用变分自编码器建模用户行为，通过统计方法解释潜在维度，发现用户结构主要是连续而非离散的


<details>
  <summary>Details</summary>
Motivation: 现有用户建模方法主要依赖确定性嵌入或黑盒预测模型，缺乏不确定性量化和对潜在表示的解释性，需要更透明、可解释的用户表示方法

Method: 提出概率数字孪生框架，将每个用户建模为生成观察行为数据的潜在随机状态，使用摊销变分推断进行学习，基于变分自编码器实现，并引入统计解释流程将潜在维度与可观察行为模式关联

Result: 用户结构主要是连续而非离散聚类的，少数主导潜在轴出现弱但有意义的结构，特定维度对应可解释特征如意见强度和决策力，通过非参数假设检验和效应大小验证了差异

Conclusion: 概率数字孪生能够提供超越确定性用户嵌入的可解释、不确定性感知表示，为个性化、推荐和决策支持等应用提供更透明和可解释的用户建模方法

Abstract: Understanding user identity and behavior is central to applications such as personalization, recommendation, and decision support. Most existing approaches rely on deterministic embeddings or black-box predictive models, offering limited uncertainty quantification and little insight into what latent representations encode. We propose a probabilistic digital twin framework in which each user is modeled as a latent stochastic state that generates observed behavioral data. The digital twin is learned via amortized variational inference, enabling scalable posterior estimation while retaining a fully probabilistic interpretation. We instantiate this framework using a variational autoencoder (VAE) applied to a user-response dataset designed to capture stable aspects of user identity. Beyond standard reconstruction-based evaluation, we introduce a statistically grounded interpretation pipeline that links latent dimensions to observable behavioral patterns. By analyzing users at the extremes of each latent dimension and validating differences using nonparametric hypothesis tests and effect sizes, we demonstrate that specific dimensions correspond to interpretable traits such as opinion strength and decisiveness. Empirically, we find that user structure is predominantly continuous rather than discretely clustered, with weak but meaningful structure emerging along a small number of dominant latent axes. These results suggest that probabilistic digital twins can provide interpretable, uncertainty-aware representations that go beyond deterministic user embeddings.

</details>


### [104] [TraCeR: Transformer-Based Competing Risk Analysis with Longitudinal Covariates](https://arxiv.org/abs/2512.18129)
*Maxmillan Ries,Sohan Seth*

Main category: cs.LG

TL;DR: TraCeR是一个基于Transformer的生存分析框架，专门用于处理纵向协变量，无需比例风险假设，并能评估模型校准性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习生存分析模型虽然减少了比例风险和线性等假设，但仍面临两个关键挑战：1) 难以有效整合纵向协变量（时间序列测量数据）；2) 评估主要关注区分度而忽视校准性评估。

Method: 提出TraCeR框架，基于因子化自注意力架构，从测量序列中估计风险函数，自然捕捉时间协变量交互，无需对底层数据生成过程做假设。框架天生设计用于处理删失数据和竞争事件。

Result: 在多个真实世界数据集上的实验表明，TraCeR相比最先进方法取得了显著且统计上显著的性能提升。评估不仅包括区分度指标，还评估了模型校准性。

Conclusion: TraCeR成功解决了生存分析中整合纵向协变量和评估校准性的关键挑战，为时间到事件数据的建模提供了更全面的框架。

Abstract: Survival analysis is a critical tool for modeling time-to-event data. Recent deep learning-based models have reduced various modeling assumptions including proportional hazard and linearity. However, a persistent challenge remains in incorporating longitudinal covariates, with prior work largely focusing on cross-sectional features, and in assessing calibration of these models, with research primarily focusing on discrimination during evaluation. We introduce TraCeR, a transformer-based survival analysis framework for incorporating longitudinal covariates. Based on a factorized self-attention architecture, TraCeR estimates the hazard function from a sequence of measurements, naturally capturing temporal covariate interactions without assumptions about the underlying data-generating process. The framework is inherently designed to handle censored data and competing events. Experiments on multiple real-world datasets demonstrate that TraCeR achieves substantial and statistically significant performance improvements over state-of-the-art methods. Furthermore, our evaluation extends beyond discrimination metrics and assesses model calibration, addressing a key oversight in literature.

</details>


### [105] [Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection](https://arxiv.org/abs/2512.18133)
*Jie Yang,Rui Zhang,Ziyang Cheng,Dawei Cheng,Guang Yang,Bo Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于关系扩散的图增强模型Grad，用于解决金融场景中欺诈者采用自适应伪装策略导致的图欺诈检测效率下降问题。


<details>
  <summary>Details</summary>
Motivation: 在金融场景中，有组织的犯罪团伙采用更专业的自适应伪装策略，通过模仿平台收集的行为数据，使欺诈者关键特征与良性用户高度一致，导致当前图欺诈检测模型效率下降。

Method: 提出Grad模型：1）使用监督图对比学习模块增强欺诈-良性差异；2）采用引导关系扩散生成器从零生成辅助同质关系；3）在聚合过程中增强弱欺诈信号。

Result: 在微信支付提供的两个真实数据集和三个公共数据集上进行实验，Grad模型在AUC和AP指标上分别最高提升11.10%和43.95%，优于现有最先进方法。

Conclusion: Grad模型通过关系扩散增强弱欺诈信号，有效应对欺诈者的自适应伪装策略，在金融图欺诈检测场景中表现出色。

Abstract: Nowadays, Graph Fraud Detection (GFD) in financial scenarios has become an urgent research topic to protect online payment security. However, as organized crime groups are becoming more professional in real-world scenarios, fraudsters are employing more sophisticated camouflage strategies. Specifically, fraudsters disguise themselves by mimicking the behavioral data collected by platforms, ensuring that their key characteristics are consistent with those of benign users to a high degree, which we call Adaptive Camouflage. Consequently, this narrows the differences in behavioral traits between them and benign users within the platform's database, thereby making current GFD models lose efficiency. To address this problem, we propose a relation diffusion-based graph augmentation model Grad. In detail, Grad leverages a supervised graph contrastive learning module to enhance the fraud-benign difference and employs a guided relation diffusion generator to generate auxiliary homophilic relations from scratch. Based on these, weak fraudulent signals would be enhanced during the aggregation process, thus being obvious enough to be captured. Extensive experiments have been conducted on two real-world datasets provided by WeChat Pay, one of the largest online payment platforms with billions of users, and three public datasets. The results show that our proposed model Grad outperforms SOTA methods in both various scenarios, achieving at most 11.10% and 43.95% increases in AUC and AP, respectively. Our code is released at https://github.com/AI4Risk/antifraud and https://github.com/Muyiiiii/WWW25-Grad.

</details>


### [106] [Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation](https://arxiv.org/abs/2512.18174)
*Lena Libon,Meghana Bhange,Rushabh Solanki,Elliot Creager,Ulrich Aïvodji*

Main category: cs.LG

TL;DR: 论文探讨在LLM推理过程中产生的中间计算痕迹（CoT traces）应被视为用户个人数据，并提出基于"有意识数据贡献"框架，让低效用社区通过知识聚合和蒸馏创建更符合自身目标的替代模型。


<details>
  <summary>Details</summary>
Motivation: 当前AI发展强调大规模数据训练，催生了LLM聊天机器人等新产品，但也引发数据隐私和用户选择权问题。论文关注在LLM使用链式思维推理时产生的中间计算痕迹，探讨这些痕迹作为个人数据的法律地位，以及如何让用户群体在现有模型效用不足时获得更好的模型对齐。

Method: 1. 从数据隐私和可移植性法律角度论证CoT推理痕迹属于用户个人数据；2. 基于"有意识数据贡献"框架，让低效用社区聚合共享知识；3. 通过知识蒸馏创建更符合社区目标的替代模型；4. 实证验证方法效果，研究社区多样性、推理粒度、社区规模对蒸馏性能的影响。

Result: 论文通过实证验证了所提方法的有效性，并研究了社区多样性、推理粒度和社区规模对知识蒸馏性能的具体影响，展示了社区如何通过有意识的数据贡献创建更符合自身需求的模型。

Conclusion: LLM推理过程中的中间计算痕迹应被视为用户个人数据，受数据隐私和可移植性法律保护。通过有意识数据贡献框架，低效用社区可以聚合知识并蒸馏出更符合自身目标的替代模型，这为增强用户自主权和模型对齐提供了可行路径。

Abstract: The current era of AI development places a heavy emphasis on training large models on increasingly scaled-up datasets. This paradigm has catalyzed entirely new product categories, such as LLM chatbots, while also raising concerns about data privacy and consumer choice. In this paper, we consider questions of data portability and user autonomy in the context of LLMs that "reason" using chain-of-thought (CoT) traces, computing intermediate text artifacts from user input before producing a final output. We first interpret recent data privacy and portability law to argue that these intermediate computations qualify as users' personal data. Then, building on the existing framework of Conscious Data Contribution, we show how communities who receive low utility from an available model can aggregate and distill their shared knowledge into an alternate model better aligned with their goals. We verify this approach empirically and investigate the effects of community diversity, reasoning granularity, and community size on distillation performance.

</details>


### [107] [When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics](https://arxiv.org/abs/2512.18209)
*Yizhou Zhang*

Main category: cs.LG

TL;DR: 论文提出了广义分辨率壳动力学框架，识别了深度学习系统中幂律标度出现的充分条件，并证明幂律标度是重正化壳动力学与梯度流时间重标度协方差结合时的刚性结果。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统中广泛观察到经验幂律标度现象，但其理论起源和适用范围尚未完全理解。需要建立一个理论框架来解释幂律标度何时以及为何出现。

Method: 使用广义分辨率壳动力学框架，将学习过程建模为跨对数分辨率壳的谱能量传输。识别了一组充分条件：计算图中梯度传播的有界性、初始化时的弱函数非相干性、训练过程中Jacobian演化的可控性，以及重正化壳耦合的对数平移不变性。

Result: 证明了在满足这些条件时，GRSD壳动力学允许重正化粗粒度描述。幂律标度不是重正化性的直接结果，而是对数平移不变性与梯度流内在时间重标度协方差结合时的刚性结果，这迫使重正化GRSD速度场呈现幂律形式。

Conclusion: 深度学习中的幂律标度现象可以通过GRSD框架得到理论解释，它需要特定的结构条件，并且是重正化壳动力学与梯度流时间协方差约束下的刚性表现，这为理解深度学习系统的标度行为提供了理论基础。

Abstract: Empirical power--law scaling has been widely observed across modern deep learning systems, yet its theoretical origins and scope of validity remain incompletely understood. The Generalized Resolution--Shell Dynamics (GRSD) framework models learning as spectral energy transport across logarithmic resolution shells, providing a coarse--grained dynamical description of training. Within GRSD, power--law scaling corresponds to a particularly simple renormalized shell dynamics; however, such behavior is not automatic and requires additional structural properties of the learning process.
  In this work, we identify a set of sufficient conditions under which the GRSD shell dynamics admits a renormalizable coarse--grained description. These conditions constrain the learning configuration at multiple levels, including boundedness of gradient propagation in the computation graph, weak functional incoherence at initialization, controlled Jacobian evolution along training, and log--shift invariance of renormalized shell couplings. We further show that power--law scaling does not follow from renormalizability alone, but instead arises as a rigidity consequence: once log--shift invariance is combined with the intrinsic time--rescaling covariance of gradient flow, the renormalized GRSD velocity field is forced into a power--law form.

</details>


### [108] [Stable and Efficient Single-Rollout RL for Multimodal Reasoning](https://arxiv.org/abs/2512.18215)
*Rui Liu,Dian Yu,Lei Ke,Haolin Liu,Yujun Zhou,Zhenwen Liang,Haitao Mi,Pratap Tokekar,Dong Yu*

Main category: cs.LG

TL;DR: MSSR是一种用于多模态大语言模型的无组强化学习框架，通过基于熵的优势整形机制解决单次采样训练中的稳定性问题，在保持训练效率的同时提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于组的RLVR算法需要多次采样，效率低下。虽然文本领域已有单次采样变体，但在多模态环境中存在严重的不稳定性问题，常导致训练崩溃。需要解决训练效率与稳定性之间的权衡问题。

Method: 提出了MSSR（多模态稳定单次采样）框架，采用基于熵的优势整形机制，自适应地正则化优势幅度，防止训练崩溃并保持稳定性。该机制在单次采样多模态环境中对稳定性至关重要。

Result: 在分布内评估中，MSSR展现出优越的训练计算效率，仅用一半的训练步骤就能达到与基于组基线相当的验证准确率。在相同训练步数下，MSSR性能超越基线，并在五个不同的推理密集型基准测试中表现出一致的泛化改进。

Conclusion: MSSR能够为复杂的多模态推理任务实现稳定、计算高效且有效的可验证奖励强化学习，解决了单次采样训练在多模态环境中的稳定性问题。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a key paradigm to improve the reasoning capabilities of Multimodal Large Language Models (MLLMs). However, prevalent group-based algorithms such as GRPO require multi-rollout sampling for each prompt. While more efficient single-rollout variants have recently been explored in text-only settings, we find that they suffer from severe instability in multimodal contexts, often leading to training collapse. To address this training efficiency-stability trade-off, we introduce $\textbf{MSSR}$ (Multimodal Stabilized Single-Rollout), a group-free RLVR framework that achieves both stable optimization and effective multimodal reasoning performance. MSSR achieves this via an entropy-based advantage-shaping mechanism that adaptively regularizes advantage magnitudes, preventing collapse and maintaining training stability. While such mechanisms have been used in group-based RLVR, we show that in the multimodal single-rollout setting they are not merely beneficial but essential for stability. In in-distribution evaluations, MSSR demonstrates superior training compute efficiency, achieving similar validation accuracy to the group-based baseline with half the training steps. When trained for the same number of steps, MSSR's performance surpasses the group-based baseline and shows consistent generalization improvements across five diverse reasoning-intensive benchmarks. Together, these results demonstrate that MSSR enables stable, compute-efficient, and effective RLVR for complex multimodal reasoning tasks.

</details>


### [109] [Offline Behavioral Data Selection](https://arxiv.org/abs/2512.18246)
*Shiye Lei,Zhihao Cheng,Dacheng Tao*

Main category: cs.LG

TL;DR: 论文发现离线行为数据存在显著的数据饱和现象，提出SDR方法从大规模数据集中提取紧凑且信息丰富的子集，显著提升离线行为数据选择效果。


<details>
  <summary>Details</summary>
Motivation: 离线行为克隆方法在从专家演示中学习策略时，大规模离线行为数据集会导致下游任务训练计算密集。研究发现离线行为数据存在显著的数据饱和现象：当仅使用数据集的一小部分训练时，策略性能会迅速饱和。这表明策略性能与测试损失之间的弱对齐关系，揭示了通过数据选择进行改进的巨大空间。

Method: 提出Stepwise Dual Ranking (SDR)方法，基于两个关键原则：(1) stepwise clip：优先考虑早期阶段数据；(2) dual ranking：选择同时具有高动作价值排名和低状态密度排名的样本。该方法从大规模离线行为数据集中提取紧凑且信息丰富的子集。

Result: 在D4RL基准测试上的广泛实验和消融研究表明，SDR显著增强了离线行为数据的选择效果。

Conclusion: 离线行为数据存在数据饱和现象，通过SDR方法可以有效选择信息丰富的子集，显著提升离线行为数据选择的效率。

Abstract: Behavioral cloning is a widely adopted approach for offline policy learning from expert demonstrations. However, the large scale of offline behavioral datasets often results in computationally intensive training when used in downstream tasks. In this paper, we uncover the striking data saturation in offline behavioral data: policy performance rapidly saturates when trained on a small fraction of the dataset. We attribute this effect to the weak alignment between policy performance and test loss, revealing substantial room for improvement through data selection. To this end, we propose a simple yet effective method, Stepwise Dual Ranking (SDR), which extracts a compact yet informative subset from large-scale offline behavioral datasets. SDR is build on two key principles: (1) stepwise clip, which prioritizes early-stage data; and (2) dual ranking, which selects samples with both high action-value rank and low state-density rank. Extensive experiments and ablation studies on D4RL benchmarks demonstrate that SDR significantly enhances data selection for offline behavioral data.

</details>


### [110] [On the Convergence Rate of LoRA Gradient Descent](https://arxiv.org/abs/2512.18248)
*Siqiao Mu,Diego Klabjan*

Main category: cs.LG

TL;DR: 本文首次对原始LoRA梯度下降算法进行了非渐近收敛性分析，证明了其在O(1/log T)速率下收敛到平稳点，无需传统Lipschitz光滑性假设。


<details>
  <summary>Details</summary>
Motivation: LoRA算法因其卓越性能和低计算需求而广受欢迎，但由于缺乏Lipschitz光滑性这一经典收敛分析的关键条件，其收敛性理解不足。现有理论结果要么考虑渐近行为，要么假设强有界条件人为强制Lipschitz光滑性，无法反映实际应用。

Method: 通过三个关键步骤：i) 将问题重新表述为堆叠适配器矩阵的外积形式；ii) 为"类Lipschitz"重参数化函数建立改进的下降引理；iii) 控制步长。这种方法首次对原始LoRA梯度下降算法进行了非渐近收敛分析。

Result: 证明了LoRA梯度下降以O(1/log T)的速率收敛到平稳点，其中T是迭代次数。这是首次在不假设Lipschitz光滑性的情况下对原始LoRA算法进行非渐近收敛性分析。

Conclusion: 本文填补了LoRA算法理论分析的空白，首次提供了原始LoRA梯度下降的非渐近收敛保证，为实际应用提供了理论支持，无需传统Lipschitz光滑性假设。

Abstract: The low-rank adaptation (LoRA) algorithm for fine-tuning large models has grown popular in recent years due to its remarkable performance and low computational requirements. LoRA trains two ``adapter" matrices that form a low-rank representation of the model parameters, thereby massively reducing the number of parameters that need to be updated at every step. Although LoRA is simple, its convergence is poorly understood due to the lack of Lipschitz smoothness, a key condition for classic convergence analyses. As a result, current theoretical results only consider asymptotic behavior or assume strong boundedness conditions which artificially enforce Lipschitz smoothness. In this work, we provide for the first time a non-asymptotic convergence analysis of the \textit{original LoRA gradient descent} algorithm, which reflects widespread practice, without such assumptions. Our work relies on three key steps: i) reformulating the problem in terms of the outer product of the stacked adapter matrices, ii) a modified descent lemma for the ``Lipschitz-like" reparametrized function, and iii) controlling the step size. With this approach, we prove that LoRA gradient descent converges to a stationary point at rate $O(\frac{1}{\log T})$, where $T$ is the number of iterations.

</details>


### [111] [LeJOT: An Intelligent Job Cost Orchestration Solution for Databricks Platform](https://arxiv.org/abs/2512.18266)
*Lizhi Ma,Yi-Xiang Hu,Yuke Wang,Yifang Zhao,Yihui Ren,Jian-Xiang Liao,Feng Wu,Xiang-Yang Li*

Main category: cs.LG

TL;DR: LeJOT是一个基于机器学习的智能作业成本编排框架，通过预测执行时间和实时资源分配优化，在Databricks平台上实现平均20%的云计算成本降低。


<details>
  <summary>Details</summary>
Motivation: 随着大数据技术的快速发展，Databricks平台成为企业和研究机构的核心基础设施，但管理作业执行成本仍然是一个关键挑战。现有解决方案依赖静态配置或被动调整，无法适应工作负载的动态变化。

Method: LeJOT框架结合机器学习进行执行时间预测，并使用基于求解器的优化模型进行实时资源分配。与传统调度技术不同，它主动预测工作负载需求，动态分配计算资源，在满足性能要求的同时最小化成本。

Result: 在真实Databricks工作负载上的实验结果表明，LeJOT在分钟级调度时间范围内实现了平均20%的云计算成本降低，优于传统的静态分配策略。

Conclusion: LeJOT为Data Lakehouse环境提供了一个可扩展且自适应的成本高效作业调度解决方案，能够有效应对动态工作负载下的成本管理挑战。

Abstract: With the rapid advancements in big data technologies, the Databricks platform has become a cornerstone for enterprises and research institutions, offering high computational efficiency and a robust ecosystem. However, managing the escalating operational costs associated with job execution remains a critical challenge. Existing solutions rely on static configurations or reactive adjustments, which fail to adapt to the dynamic nature of workloads. To address this, we introduce LeJOT, an intelligent job cost orchestration framework that leverages machine learning for execution time prediction and a solver-based optimization model for real-time resource allocation. Unlike conventional scheduling techniques, LeJOT proactively predicts workload demands, dynamically allocates computing resources, and minimizes costs while ensuring performance requirements are met. Experimental results on real-world Databricks workloads demonstrate that LeJOT achieves an average 20% reduction in cloud computing costs within a minute-level scheduling timeframe, outperforming traditional static allocation strategies. Our approach provides a scalable and adaptive solution for cost-efficient job scheduling in Data Lakehouse environments.

</details>


### [112] [FedSUM Family: Efficient Federated Learning Methods under Arbitrary Client Participation](https://arxiv.org/abs/2512.18275)
*Runze You,Shi Pu*

Main category: cs.LG

TL;DR: FedSUM算法家族支持任意客户端参与模式，无需数据异构性假设，通过延迟指标建模参与变化，提供三种变体并给出统一收敛保证


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法通常针对特定客户端参与模式设计，限制了在实际部署中的适用性。实际场景中客户端参与模式多样且不可预测，需要更通用的框架

Method: 提出FedSUM算法家族，包含三个变体：FedSUM-B（基础版）、FedSUM（标准版）和FedSUM-CR（通信减少版）。使用最大延迟τ_max和平均延迟τ_avg两个指标建模客户端参与变化，支持任意参与模式

Result: 提供了统一的收敛性保证，证明FedSUM在不同参与模式下的有效性。算法能够在各种实际参与场景中稳定工作，扩展了联邦学习的实际应用范围

Conclusion: FedSUM框架通过支持任意客户端参与模式，解决了现有联邦学习方法在实际部署中的局限性，为更广泛的实际应用场景提供了通用解决方案

Abstract: Federated Learning (FL) methods are often designed for specific client participation patterns, limiting their applicability in practical deployments. We introduce the FedSUM family of algorithms, which supports arbitrary client participation without additional assumptions on data heterogeneity. Our framework models participation variability with two delay metrics, the maximum delay $τ_{\max}$ and the average delay $τ_{\text{avg}}$. The FedSUM family comprises three variants: FedSUM-B (basic version), FedSUM (standard version), and FedSUM-CR (communication-reduced version). We provide unified convergence guarantees demonstrating the effectiveness of our approach across diverse participation patterns, thereby broadening the applicability of FL in real-world scenarios.

</details>


### [113] [AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning](https://arxiv.org/abs/2512.18295)
*Xuling Zhang,Jindong Li,Yifei Zhang,Menglin Yang*

Main category: cs.LG

TL;DR: AL GNN：一种无需反向传播和重放缓冲区的持续图学习框架，基于解析学习理论，通过递归最小二乘优化实现高效单次训练


<details>
  <summary>Details</summary>
Motivation: 现有持续图学习方法（特别是基于经验重放的方法）存在隐私问题、效率低下等显著限制，需要存储和重访历史图数据来缓解灾难性遗忘

Method: 基于解析学习理论，将学习过程公式化为递归最小二乘优化，通过闭式分类器更新和正则化特征自相关矩阵来维护和更新模型知识

Result: 在多个动态图分类基准测试中表现出色：CoraFull上平均性能提升10%，Reddit上遗忘减少超过30%，训练时间减少近50%

Conclusion: AL GNN通过消除反向传播和重放缓冲区的需求，提供了一种高效、隐私保护的持续图学习解决方案，在性能和效率方面均优于现有方法

Abstract: Continual graph learning (CGL) aims to enable graph neural networks to incrementally learn from a stream of graph structured data without forgetting previously acquired knowledge. Existing methods particularly those based on experience replay typically store and revisit past graph data to mitigate catastrophic forgetting. However, these approaches pose significant limitations, including privacy concerns, inefficiency. In this work, we propose AL GNN, a novel framework for continual graph learning that eliminates the need for backpropagation and replay buffers. Instead, AL GNN leverages principles from analytic learning theory to formulate learning as a recursive least squares optimization process. It maintains and updates model knowledge analytically through closed form classifier updates and a regularized feature autocorrelation matrix. This design enables efficient one pass training for each task, and inherently preserves data privacy by avoiding historical sample storage. Extensive experiments on multiple dynamic graph classification benchmarks demonstrate that AL GNN achieves competitive or superior performance compared to existing methods. For instance, it improves average performance by 10% on CoraFull and reduces forgetting by over 30% on Reddit, while also reducing training time by nearly 50% due to its backpropagation free design.

</details>


### [114] [Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings](https://arxiv.org/abs/2512.18309)
*Harsh Rathva,Ojas Srivastava,Pruthwik Mishra*

Main category: cs.LG

TL;DR: ESAI是一个多智能体强化学习理论框架，通过可微的内部对齐嵌入将安全对齐约束直接嵌入到智能体的内部表示中，而不是依赖外部奖励塑造或后处理安全约束。


<details>
  <summary>Details</summary>
Motivation: 为了解决多智能体系统中安全对齐问题，传统方法如外部奖励塑造或后处理安全约束存在局限性，需要一种能够将安全约束直接嵌入智能体内部表示的理论框架。

Method: ESAI框架包含四个机制：基于软参考分布的可微反事实对齐惩罚、对齐加权的感知注意力、支持时间信用分配的Hebbian联想记忆、以及具有偏差缓解控制的相似性加权图扩散。

Result: 分析了在Lipschitz连续性和谱约束下有界内部嵌入的稳定性条件，讨论了计算复杂度，并检验了包括收缩行为和公平性-性能权衡在内的理论特性。

Conclusion: ESAI作为多智能体系统中可微对齐机制的概念性贡献，提出了关于收敛保证、嵌入维度和扩展到高维环境等开放理论问题，实证评估留待未来工作。

Abstract: We introduce Embedded Safety-Aligned Intelligence (ESAI), a theoretical framework for multi-agent reinforcement learning that embeds alignment constraints directly into agents internal representations using differentiable internal alignment embeddings. Unlike external reward shaping or post-hoc safety constraints, internal alignment embeddings are learned latent variables that predict externalized harm through counterfactual reasoning and modulate policy updates toward harm reduction through attention and graph-based propagation.
  The ESAI framework integrates four mechanisms: differentiable counterfactual alignment penalties computed from soft reference distributions, alignment-weighted perceptual attention, Hebbian associative memory supporting temporal credit assignment, and similarity-weighted graph diffusion with bias mitigation controls. We analyze stability conditions for bounded internal embeddings under Lipschitz continuity and spectral constraints, discuss computational complexity, and examine theoretical properties including contraction behavior and fairness-performance tradeoffs.
  This work positions ESAI as a conceptual contribution to differentiable alignment mechanisms in multi-agent systems. We identify open theoretical questions regarding convergence guarantees, embedding dimensionality, and extension to high-dimensional environments. Empirical evaluation is left to future work.

</details>


### [115] [Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems](https://arxiv.org/abs/2512.18317)
*Vincent Bezold,Patrick Wagner,Jakob Hofmann,Marco Huber,Alexander Sauer*

Main category: cs.LG

TL;DR: 提出一种可信赖的强化学习方法用于工业压缩空气系统控制，通过多级可解释性管道确保安全高效运行，相比工业控制器减少过压并实现约4%的节能。


<details>
  <summary>Details</summary>
Motivation: 工业压缩空气系统能耗巨大，传统控制器效率有限。需要开发既能节能又能确保安全运行的可信赖强化学习方法，以促进AI在工业能源系统中的实际部署。

Method: 开发可信赖强化学习框架，包含多级可解释性管道：输入扰动测试、基于梯度的敏感性分析和SHAP特征归因。在多种压缩机配置下进行实证评估。

Result: 学习到的策略具有物理合理性，能预测未来需求并始终尊重系统边界。相比工业控制器减少不必要的过压，实现约4%的节能，且不依赖显式物理模型。系统压力和预测信息主导策略决策，压缩机级输入起次要作用。

Conclusion: 结合效率提升、预测行为和透明验证，支持强化学习在工业能源系统中的可信赖部署。该方法为工业应用提供了安全、高效且可解释的AI控制方案。

Abstract: This paper presents a trustworthy reinforcement learning approach for the control of industrial compressed air systems. We develop a framework that enables safe and energy-efficient operation under realistic boundary conditions and introduce a multi-level explainability pipeline combining input perturbation tests, gradient-based sensitivity analysis, and SHAP (SHapley Additive exPlanations) feature attribution. An empirical evaluation across multiple compressor configurations shows that the learned policy is physically plausible, anticipates future demand, and consistently respects system boundaries. Compared to the installed industrial controller, the proposed approach reduces unnecessary overpressure and achieves energy savings of approximately 4\,\% without relying on explicit physics models. The results further indicate that system pressure and forecast information dominate policy decisions, while compressor-level inputs play a secondary role. Overall, the combination of efficiency gains, predictive behavior, and transparent validation supports the trustworthy deployment of reinforcement learning in industrial energy systems.

</details>


### [116] [The Challenger: When Do New Data Sources Justify Switching Machine Learning Models?](https://arxiv.org/abs/2512.18390)
*Vassilis Digalakis,Christophe Pérignon,Sébastien Saurin,Flore Sentenac*

Main category: cs.LG

TL;DR: 研究组织何时应该用依赖新特征的新模型替换现有模型，提出结合经济与统计的框架，分析学习曲线动态、数据获取成本、再训练成本和未来收益折现，提供三种实用算法并在信贷评分数据上验证效果。


<details>
  <summary>Details</summary>
Motivation: 随着新数据源不断涌现，组织面临何时用依赖新特征的新模型替换现有训练好的模型这一重要决策问题。现有研究缺乏综合考虑学习曲线动态、数据获取成本、再训练成本和未来收益折现的统一框架。

Method: 1. 建立统一的经济与统计框架，分析学习曲线动态、数据获取与再训练成本、未来收益折现；2. 在简化场景中推导最优切换时间的闭式解；3. 提出三种实用算法：一次性基线方法、贪婪序贯方法和前瞻序贯方法；4. 在真实信贷评分数据集上验证，使用逐渐到达的替代数据。

Result: 1. 最优切换时间系统地随成本参数和学习曲线行为变化；2. 前瞻序贯方法优于其他方法，能够接近具有完全预见能力的预言机；3. 建立了有限样本保证，包括前瞻序贯方法相对于预言机实现次线性遗憾的条件。

Conclusion: 该研究为组织在新数据源可用时进行经济合理的模型转换提供了操作蓝图，提出的前瞻序贯方法在实践中接近最优性能，具有理论保证。

Abstract: We study the problem of deciding whether, and when an organization should replace a trained incumbent model with a challenger relying on newly available features. We develop a unified economic and statistical framework that links learning-curve dynamics, data-acquisition and retraining costs, and discounting of future gains. First, we characterize the optimal switching time in stylized settings and derive closed-form expressions that quantify how horizon length, learning-curve curvature, and cost differentials shape the optimal decision. Second, we propose three practical algorithms: a one-shot baseline, a greedy sequential method, and a look-ahead sequential method. Using a real-world credit-scoring dataset with gradually arriving alternative data, we show that (i) optimal switching times vary systematically with cost parameters and learning-curve behavior, and (ii) the look-ahead sequential method outperforms other methods and is able to approach in value an oracle with full foresight. Finally, we establish finite-sample guarantees, including conditions under which the sequential look-ahead method achieve sublinear regret relative to that oracle. Our results provide an operational blueprint for economically sound model transitions as new data sources become available.

</details>


### [117] [Why Most Optimism Bandit Algorithms Have the Same Regret Analysis: A Simple Unifying Theorem](https://arxiv.org/abs/2512.18409)
*Vikram Krishnamurthy*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的框架来分析乐观型随机赌博机算法，通过隔离分析中的最小要素来简化对数后悔界的证明。


<details>
  <summary>Details</summary>
Motivation: 尽管UCB、UCB-V、线性UCB和有限臂GP-UCB等乐观型随机赌博机算法都实现了对数后悔，但它们的证明虽然表面不同，本质上遵循相同的结构。作者希望隔离这些分析中的最小要素，为这些经典算法提供统一、接近最小的证明。

Method: 论文提出了一个分析框架，该框架基于一个单一的高概率集中条件（对估计量的集中性要求），然后通过两个简短的确定性引理（半径坍塌引理和乐观强制偏差引理）推导出对数后悔界。

Result: 该框架为经典乐观型赌博机算法提供了统一的、接近最小的证明，并且能够自然地扩展到许多当代的赌博机变体算法。

Conclusion: 乐观型随机赌博机算法的对数后悔证明可以简化为一个核心的高概率集中条件和两个简单的确定性引理，这一框架不仅统一了经典算法的分析，还为扩展到更复杂的变体提供了基础。

Abstract: Several optimism-based stochastic bandit algorithms -- including UCB, UCB-V, linear UCB, and finite-arm GP-UCB -- achieve logarithmic regret using proofs that, despite superficial differences, follow essentially the same structure. This note isolates the minimal ingredients behind these analyses: a single high-probability concentration condition on the estimators, after which logarithmic regret follows from two short deterministic lemmas describing radius collapse and optimism-forced deviations. The framework yields unified, near-minimal proofs for these classical algorithms and extends naturally to many contemporary bandit variants.

</details>


### [118] [MoE Pathfinder: Trajectory-driven Expert Pruning](https://arxiv.org/abs/2512.18425)
*Xican Yang,Yuanhe Tian,Yan Song*

Main category: cs.LG

TL;DR: 提出基于专家激活轨迹的MoE模型剪枝方法，将专家选择建模为全局最优路径规划问题，实现跨层非均匀剪枝，优于现有方法


<details>
  <summary>Details</summary>
Motivation: MoE架构在大语言模型中表现出色但面临部署复杂和激活效率低的挑战。现有专家剪枝方法依赖局部重要性指标，采用均匀层间剪枝，仅利用部分评估信号且忽略了专家在不同层的异质性贡献

Method: 将MoE视为加权计算图，将专家选择建模为全局最优路径规划问题。在轨迹层面整合重构误差、路由概率和激活强度等互补重要性信号，实现跨层非均匀专家保留

Result: 实验表明，该方法在几乎所有任务上都比现有大多数方法实现了更优的剪枝性能

Conclusion: 基于专家激活轨迹的全局优化方法能有效解决MoE模型剪枝中的局限性，为实际部署提供更高效的解决方案

Abstract: Mixture-of-experts (MoE) architectures used in large language models (LLMs) achieve state-of-the-art performance across diverse tasks yet face practical challenges such as deployment complexity and low activation efficiency. Expert pruning has thus emerged as a promising solution to reduce computational overhead and simplify the deployment of MoE models. However, existing expert pruning approaches conventionally rely on local importance metrics and often apply uniform layer-wise pruning, leveraging only partial evaluation signals and overlooking the heterogeneous contributions of experts across layers. To address these limitations, we propose an expert pruning approach based on the trajectory of activated experts across layers, which treats MoE as a weighted computation graph and casts expert selection as a global optimal path planning problem. Within this framework, we integrate complementary importance signals from reconstruction error, routing probabilities, and activation strength at the trajectory level, which naturally yields non-uniform expert retention across layers. Experiments show that our approach achieves superior pruning performance on nearly all tasks compared with most existing approaches.

</details>


### [119] [On the Universality of Transformer Architectures; How Much Attention Is Enough?](https://arxiv.org/abs/2512.18445)
*Amirreza Abbasi,Mohsen Hooshmand*

Main category: cs.LG

TL;DR: 本文综述了Transformer架构的普适性问题，回顾了最新进展，包括结构最小性和逼近率等架构改进，旨在阐明Transformer表达能力的现状，区分稳健保证与脆弱保证，并指出未来理论研究的关键方向。


<details>
  <summary>Details</summary>
Motivation: Transformer在大型语言模型、计算机视觉和强化学习等AI领域至关重要，其重要性源于该架构相对于替代方案的普适性和可扩展性。本文旨在研究Transformer的普适性问题，澄清当前对其表达能力的理解，区分稳健与脆弱的理论保证，并为未来理论研究指明方向。

Method: 本文采用综述研究方法，系统回顾了Transformer普适性问题的相关进展，包括：1）架构改进如结构最小性和逼近率分析；2）前沿进展的调研，涵盖理论和实践理解；3）对现有理论保证的分类和分析。

Result: 通过系统综述，本文阐明了Transformer表达能力的当前认知状态，区分了稳健的理论保证（如某些架构变体的普适性证明）与脆弱的理论保证（如依赖于特定假设的结论），并识别了现有理论框架的局限性。

Conclusion: Transformer的普适性问题是一个复杂且活跃的研究领域。虽然已有重要进展，但仍需更多理论研究来深入理解其表达能力边界，特别是在实际应用中观察到的性能与理论保证之间的差距。未来研究应关注更现实的假设、更全面的架构分析，以及理论与实践的更好结合。

Abstract: Transformers are crucial across many AI fields, such as large language models, computer vision, and reinforcement learning. This prominence stems from the architecture's perceived universality and scalability compared to alternatives. This work examines the problem of universality in Transformers, reviews recent progress, including architectural refinements such as structural minimality and approximation rates, and surveys state-of-the-art advances that inform both theoretical and practical understanding. Our aim is to clarify what is currently known about Transformers expressiveness, separate robust guarantees from fragile ones, and identify key directions for future theoretical research.

</details>


### [120] [NOVA: Discovering Well-Conditioned Winograd Transforms through Numerical Optimization of Vandermonde Arithmetic](https://arxiv.org/abs/2512.18453)
*Jayant Lohia*

Main category: cs.LG

TL;DR: NOVA框架通过数值优化解决Winograd卷积在低精度计算中的数值不稳定问题，发现分数插值点配置，显著改善条件数，在FP16精度下恢复模型准确率。


<details>
  <summary>Details</summary>
Motivation: Winograd卷积作为高效推理的标准算法，在低精度计算时代面临数值不稳定性的关键障碍。随着瓦片规模扩大以最大化效率，标准整数变换的条件数急剧增加，导致在FP16或Int8精度下无法使用。

Method: 提出NOVA（数值优化范德蒙算术）发现框架，将Winograd点选择视为连续优化问题，通过进化策略在R^n-1流形上搜索，将候选点捕捉为简单有理数，并通过符号验证保证正确性。

Result: NOVA将F(8,3)的1D条件数改善415倍，2D卷积改善172,484倍。在FP16 ImageNet推理中，标准变换崩溃至随机准确率（如VGG16的4.7%），而NOVA点恢复完整准确率（75-78%），无需重新训练、校准或学习参数。

Conclusion: NOVA发现的变换作为即插即用替代方案，有效解锁了大型瓦片Winograd卷积在下一代硬件上的效率潜力，突破了数十年来的整数插值惯例。

Abstract: Winograd convolution is the standard algorithm for efficient inference, reducing arithmetic complexity by 2.25x for 3x3 kernels. However, it faces a critical barrier in the modern era of low precision computing: numerical instability. As tiles scale to maximize efficiency (e.g., F(6,3), F(8,3)), the condition numbers of standard integer based transforms explode, reaching kappa = 2 x 10^5 for F(8,3), rendering them unusable in FP16 or Int8. We introduce NOVA (Numerical Optimization of Vandermonde Arithmetic), a discovery framework that breaks the decades old convention of integer interpolation. Treating Winograd point selection as a continuous optimization problem, NOVA searches the manifold R^n-1 via Evolution Strategy, snaps candidates to simple rationals, and guarantees correctness via symbolic verification. This process uncovers a hidden landscape of stable, fractional configurations such as {+-5/6, +-7/6, +-3/5} that defy traditional vocabulary constraints. The impact is transformative: NOVA improves the conditioning of F(8,3) by 415x in 1D, which squares to a 172,484x improvement for 2D convolution. In real world FP16 ImageNet inference, where standard transforms collapse to random chance (e.g., 4.7 percent accuracy on VGG16), NOVA's points restore full accuracy (75 to 78 percent), recovering over 70 percentage points without retraining, calibration, or learned parameters. These discovered transforms act as drop in replacements, effectively unlocking the efficiency of large tile Winograd convolution for next generation hardware.

</details>


### [121] [Out-of-Distribution Detection in Molecular Complexes via Diffusion Models for Irregular Graphs](https://arxiv.org/abs/2512.18454)
*David Graber,Victor Armegioiu,Rebecca Buller,Siddhartha Mishra*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的概率OOD检测框架，专门用于处理结合连续几何和分类特征的复杂3D图数据，通过统一的连续扩散过程生成典型性分数来识别分布外样本。


<details>
  <summary>Details</summary>
Motivation: 预测性机器学习模型通常在分布内数据上表现良好，但在分布外(OOD)输入上性能会下降。对于结合连续几何和分类身份且无序构造的不规则3D图数据，可靠的OOD检测尤其具有挑战性，需要开发专门的方法来确保模型在实际部署中的可靠性。

Method: 提出了一个基于扩散模型的概率OOD检测框架：1）将分类特征嵌入连续空间并用交叉熵训练；2）通过后验均值插值从预测的类别概率中获得扩散分数；3）建立单一自洽的概率流常微分方程(PF-ODE)生成每样本对数似然；4）利用多尺度轨迹统计特征（路径弯曲度、流刚度、向量场不稳定性）提供补充OOD信息。

Result: 在蛋白质-配体复合物上验证了该方法：1）PF-ODE似然能正确识别训练中排除的蛋白质家族为OOD；2）似然值与独立结合亲和力模型(GEMS)的预测误差强相关；3）结合轨迹特征的多尺度统计建模比仅使用似然的基线方法具有更好的分离效果，提供了高灵敏度的OOD检测器。

Conclusion: 该研究开发了一个无监督的、基于扩散模型的OOD检测框架，能够有效处理复杂3D图数据，通过统一的连续扩散过程和轨迹特征分析，为几何深度学习提供了无需标签的OOD量化工作流程，增强了模型在实际应用中的可靠性评估能力。

Abstract: Predictive machine learning models generally excel on in-distribution data, but their performance degrades on out-of-distribution (OOD) inputs. Reliable deployment therefore requires robust OOD detection, yet this is particularly challenging for irregular 3D graphs that combine continuous geometry with categorical identities and are unordered by construction. Here, we present a probabilistic OOD detection framework for complex 3D graph data built on a diffusion model that learns a density of the training distribution in a fully unsupervised manner. A key ingredient we introduce is a unified continuous diffusion over both 3D coordinates and discrete features: categorical identities are embedded in a continuous space and trained with cross-entropy, while the corresponding diffusion score is obtained analytically via posterior-mean interpolation from predicted class probabilities. This yields a single self-consistent probability-flow ODE (PF-ODE) that produces per-sample log-likelihoods, providing a principled typicality score for distribution shift. We validate the approach on protein-ligand complexes and construct strict OOD datasets by withholding entire protein families from training. PF-ODE likelihoods identify held-out families as OOD and correlate strongly with prediction errors of an independent binding-affinity model (GEMS), enabling a priori reliability estimates on new complexes. Beyond scalar likelihoods, we show that multi-scale PF-ODE trajectory statistics - including path tortuosity, flow stiffness, and vector-field instability - provide complementary OOD information. Modeling the joint distribution of these trajectory features yields a practical, high-sensitivity detector that improves separation over likelihood-only baselines, offering a label-free OOD quantification workflow for geometric deep learning.

</details>


### [122] [Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review](https://arxiv.org/abs/2512.18466)
*Oraib Almegdadi,João Marcelino,Sarah Fakhreddine,João Manso,Nuno C. Marques*

Main category: cs.LG

TL;DR: 这篇综述探讨了自组织映射(SOM)这一无监督AI技术在水质评估中的应用，重点分析了参数选择、时空采样策略和聚类方法，展示了SOM如何处理多维数据并揭示隐藏模式以支持有效的水资源管理。


<details>
  <summary>Details</summary>
Motivation: 湖泊和水库的水质评估面临数据稀疏性、异质性和参数间非线性关系的挑战，而环境监测数据的快速增长（包括现场传感器、遥感影像、物联网技术和历史记录）为分析提供了新机遇。SOM作为一种无监督AI技术，在标记数据有限或不可得的情况下特别有效，能够处理复杂数据集并支持可持续水资源管理。

Method: 本文采用文献综述方法，系统梳理了SOM在水质评估中的应用研究，重点关注参数选择策略、空间和时间采样方法、聚类分析技术，以及SOM如何处理多维数据、可视化高维数据、检测隐藏生态模式和识别水质指标间的关键相关性。

Result: SOM在水质评估中展现出多方面的应用价值：1）生态评估的灵活性；2）营养状态分类；3）藻华监测；4）集水区影响评估。该技术能够有效处理复杂环境数据集，揭示水质参数间的隐藏模式和相关关系，为湖泊和水库生态系统的监测和管理提供有力支持。

Conclusion: 自组织映射(SOM)作为一种强大的无监督AI工具，在水质评估和湖泊水库管理中具有重要应用价值。该综述为现有方法论提供了全面见解，支持未来研究和实际应用，有助于改善湖泊和水库生态系统的监测和可持续管理。SOM处理多维数据和揭示隐藏模式的能力使其成为环境监测和水资源管理的有力工具。

Abstract: Sustainable water quality underpins ecological balance and water security. Assessing and managing lakes and reservoirs is difficult due to data sparsity, heterogeneity, and nonlinear relationships among parameters. This review examines how Self-Organizing Map (SOM), an unsupervised AI technique, is applied to water quality assessment. It synthesizes research on parameter selection, spatial and temporal sampling strategies, and clustering approaches. Emphasis is placed on how SOM handles multidimensional data and uncovers hidden patterns to support effective water management. The growing availability of environmental data from in-situ sensors, remote sensing imagery, IoT technologies, and historical records has significantly expanded analytical opportunities in environmental monitoring. SOM has proven effective in analysing complex datasets, particularly when labelled data are limited or unavailable. It enables high-dimensional data visualization, facilitates the detection of hidden ecological patterns, and identifies critical correlations among diverse water quality indicators. This review highlights SOMs versatility in ecological assessments, trophic state classification, algal bloom monitoring, and catchment area impact evaluations. The findings offer comprehensive insights into existing methodologies, supporting future research and practical applications aimed at improving the monitoring and sustainable management of lake and reservoir ecosystems.

</details>


### [123] [Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts](https://arxiv.org/abs/2512.18522)
*Hatim M. E. Geli,Islam Omar,Mona Y. Elshinawy,David W. DuBios,Lara Prehodko,Kelly H Smith,Abdel-Hameed A. Badawy*

Main category: cs.LG

TL;DR: 该研究应用机器学习技术，结合干旱指数和历史干旱影响记录，生成短期干旱影响预测，为干旱早期预警系统提供支持。


<details>
  <summary>Details</summary>
Motivation: 干旱是影响生态和人类系统的复杂自然灾害，近年来干旱严重程度、频率和持续时间增加，需要有效的监测和缓解策略。预测干旱影响（而不仅仅是干旱条件）可以为早期预警系统和主动决策提供支持。

Method: 使用机器学习技术将干旱指数（DSCI和ESI）与历史干旱影响记录（2005-2024年）相结合，生成短期影响预测。采用eXtreme Gradient Boosting（XGBoost）模型，结合DSCI和ESI指数，使用前8周数据预测未来8周的干旱影响。

Result: 火灾和救援影响预测准确率最高，其次是农业和水资源影响，而植物和社会影响预测变异性较大。模型成功生成了新墨西哥州县和州级别的8周提前预测，支持生态干旱信息通信系统（EcoDri）的开发。

Conclusion: 该研究展示了机器学习在干旱影响预测中的应用潜力，可为利益相关者、土地管理者和决策者制定更有效的干旱缓解和适应策略提供支持，并可在类似干旱易发地区推广应用。

Abstract: Drought is a complex natural hazard that affects ecological and human systems, often resulting in substantial environmental and economic losses. Recent increases in drought severity, frequency, and duration underscore the need for effective monitoring and mitigation strategies. Predicting drought impacts rather than drought conditions alone offers opportunities to support early warning systems and proactive decision-making. This study applies machine learning techniques to link drought indices with historical drought impact records (2005:2024) to generate short-term impact forecasts. By addressing key conceptual and data-driven challenges regarding temporal scale and impact quantification, the study aims to improve the predictability of drought impacts at actionable lead times. The Drought Severity and Coverage Index (DSCI) and the Evaporative Stress Index (ESI) were combined with impact data from the Drought Impact Reporter (DIR) to model and forecast weekly drought impacts. Results indicate that Fire and Relief impacts were predicted with the highest accuracy, followed by Agriculture and Water, while forecasts for Plants and Society impacts showed greater variability. County and state level forecasts for New Mexico were produced using an eXtreme Gradient Boosting (XGBoost) model that incorporated both DSCI and ESI. The model successfully generated forecasts up to eight weeks in advance using the preceding eight weeks of data for most impact categories. This work supports the development of an Ecological Drought Information Communication System (EcoDri) for New Mexico and demonstrates the potential for broader application in similar drought-prone regions. The findings can aid stakeholders, land managers, and decision-makers in developing and implementing more effective drought mitigation and adaptation strategies.

</details>


### [124] [SD2AIL: Adversarial Imitation Learning from Synthetic Demonstrations via Diffusion Models](https://arxiv.org/abs/2512.18583)
*Pengcheng Li,Qiang Fang,Tong Zhao,Yixing Lan,Xin Xu*

Main category: cs.LG

TL;DR: SD2AIL使用扩散模型生成合成演示数据来增强对抗模仿学习，通过优先回放策略选择最有价值的演示，在模拟任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 对抗模仿学习需要大量专家演示来获得良好性能和稳定性，但在某些场景中收集专家演示很困难。受扩散模型在数据生成方面的成功启发，研究者希望通过生成合成演示来增强专家数据。

Method: 1. 在判别器中使用扩散模型生成合成演示作为伪专家数据来增强专家演示；2. 引入优先专家演示回放策略(PEDR)，从大量(伪)专家演示中选择最有价值的演示进行回放。

Result: 在模拟任务中证明了方法的有效性和鲁棒性。在Hopper任务中，平均回报达到3441，比最先进方法提升了89。

Conclusion: SD2AIL通过扩散模型生成合成演示并结合优先回放策略，有效解决了对抗模仿学习中专家演示数据不足的问题，显著提升了性能。

Abstract: Adversarial Imitation Learning (AIL) is a dominant framework in imitation learning that infers rewards from expert demonstrations to guide policy optimization. Although providing more expert demonstrations typically leads to improved performance and greater stability, collecting such demonstrations can be challenging in certain scenarios. Inspired by the success of diffusion models in data generation, we propose SD2AIL, which utilizes synthetic demonstrations via diffusion models. We first employ a diffusion model in the discriminator to generate synthetic demonstrations as pseudo-expert data that augment the expert demonstrations. To selectively replay the most valuable demonstrations from the large pool of (pseudo-) expert demonstrations, we further introduce a prioritized expert demonstration replay strategy (PEDR). The experimental results on simulation tasks demonstrate the effectiveness and robustness of our method. In particular, in the Hopper task, our method achieves an average return of 3441, surpassing the state-of-the-art method by 89. Our code will be available at https://github.com/positron-lpc/SD2AIL.

</details>


### [125] [EIA-SEC: Improved Actor-Critic Framework for Multi-UAV Collaborative Control in Smart Agriculture](https://arxiv.org/abs/2512.18596)
*Quanxi Zhou,Wencan Mao,Yilei Liang,Manabu Tsukada,Yunling Liu,Jon Crowcroft*

Main category: cs.LG

TL;DR: 本文提出了一种用于多无人机智能农业系统的精英模仿演员-共享集成评论家（EIA-SEC）框架，通过无人机协同执行数据收集、图像采集和通信任务，优化轨迹规划问题。


<details>
  <summary>Details</summary>
Motivation: 无线通信技术的广泛应用推动了智能农业的发展，无人机在其中扮演多功能角色。针对多无人机智能农业系统中无人机协同执行数据收集、图像采集和通信任务的需求，需要解决多无人机轨迹规划问题。

Method: 将多无人机轨迹规划问题建模为马尔可夫决策过程，提出新颖的EIA-SEC框架：智能体自适应地从精英智能体学习以减少试错成本，共享集成评论家与每个智能体的本地评论家协作，确保无偏的目标值估计并防止过估计。

Result: 实验结果表明，EIA-SEC在奖励性能、训练稳定性和收敛速度方面优于最先进的基线方法。

Conclusion: 提出的EIA-SEC框架有效解决了多无人机智能农业系统中的轨迹规划问题，通过精英模仿学习和共享集成评论家机制实现了优越的性能表现。

Abstract: The widespread application of wireless communication technology has promoted the development of smart agriculture, where unmanned aerial vehicles (UAVs) play a multifunctional role. We target a multi-UAV smart agriculture system where UAVs cooperatively perform data collection, image acquisition, and communication tasks. In this context, we model a Markov decision process to solve the multi-UAV trajectory planning problem. Moreover, we propose a novel Elite Imitation Actor-Shared Ensemble Critic (EIA-SEC) framework, where agents adaptively learn from the elite agent to reduce trial-and-error costs, and a shared ensemble critic collaborates with each agent's local critic to ensure unbiased objective value estimates and prevent overestimation. Experimental results demonstrate that EIA-SEC outperforms state-of-the-art baselines in terms of reward performance, training stability, and convergence speed.

</details>


### [126] [The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss](https://arxiv.org/abs/2512.18610)
*Rongyao Cai,Yuxi Wan,Kexin Zhang,Ming Jin,Hao Wang,Zhiqiang Ge,Daoyi Dong,Yong Liu,Qingsong Wen*

Main category: cs.LG

TL;DR: 该论文首次从第一性原理分析了时间序列建模中基于点损失函数（如MSE）的优化偏差问题，提出了期望优化偏差（EOB）的理论框架，并开发了基于序列长度缩减和结构正交化的去偏方法。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列模型使用点损失函数（如MSE）时，依赖于错误的数据点独立同分布假设，忽略了因果时间结构。虽然这一问题逐渐受到关注，但缺乏正式的理论基础。本文旨在从第一性原理分析期望优化偏差，为这一问题提供理论支撑。

Method: 1. 从信息论角度形式化期望优化偏差（EOB），定义为真实联合分布与错误i.i.d.对应分布之间的差异；2. 推导线性和非线性系统中非确定性EOB的闭式量化；3. 提出基于序列长度缩减和结构正交化的去偏程序；4. 引入DFT或DWT实现上述原则；5. 提出协调ℓp范数框架解决高方差序列的梯度问题。

Result: 理论分析揭示了基本范式悖论：时间序列越确定性和结构化，点损失函数导致的偏差越严重。证明EOB是内在数据属性，仅由序列长度和提出的结构信噪比（SSNR）决定。实验验证了EOB理论的普适性和去偏程序的优越性能。

Conclusion: 本文首次为时间序列建模中的点损失函数偏差问题提供了理论基础，提出了期望优化偏差理论框架，并开发了有效的去偏方法。该工作为时间序列分析提供了新的理论视角和实用工具。

Abstract: Optimizing time series models via point-wise loss functions (e.g., MSE) relying on a flawed point-wise independent and identically distributed (i.i.d.) assumption that disregards the causal temporal structure, an issue with growing awareness yet lacking formal theoretical grounding. Focusing on the core independence issue under covariance stationarity, this paper aims to provide a first-principles analysis of the Expectation of Optimization Bias (EOB), formalizing it information-theoretically as the discrepancy between the true joint distribution and its flawed i.i.d. counterpart. Our analysis reveals a fundamental paradigm paradox: the more deterministic and structured the time series, the more severe the bias by point-wise loss function. We derive the first closed-form quantification for the non-deterministic EOB across linear and non-linear systems, and prove EOB is an intrinsic data property, governed exclusively by sequence length and our proposed Structural Signal-to-Noise Ratio (SSNR). This theoretical diagnosis motivates our principled debiasing program that eliminates the bias through sequence length reduction and structural orthogonalization. We present a concrete solution that simultaneously achieves both principles via DFT or DWT. Furthermore, a novel harmonized $\ell_p$ norm framework is proposed to rectify gradient pathologies of high-variance series. Extensive experiments validate EOB Theory's generality and the superior performance of debiasing program.

</details>


### [127] [ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs](https://arxiv.org/abs/2512.18633)
*Han-Seul Jeong,Youngjoon Park,Hyungseok Song,Woohyung Lim*

Main category: cs.LG

TL;DR: ARC框架通过解耦属性表示学习，将车辆路径问题的属性分解为内在语义和上下文交互两部分，实现跨问题泛化


<details>
  <summary>Details</summary>
Motivation: 现实世界中的车辆路径问题具有多样化属性，需要能够跨问题变体高效泛化的学习方法，以应对不同属性组合的挑战

Method: 提出ARC框架，通过解耦学习将属性表示分解为：内在属性嵌入（IAE）捕捉不变语义，上下文交互嵌入（CIE）捕捉属性组合效应；通过类比一致性约束确保属性添加的语义转换在不同问题上下文中保持不变

Result: ARC在分布内测试、零样本泛化、少样本适应和现实世界基准测试中均达到最先进性能

Conclusion: 通过解耦属性表示学习，ARC能够重用已训练变体的不变语义，并为未见过的属性组合构建表示，实现了跨车辆路径问题变体的高效泛化

Abstract: Vehicle Routing Problems (VRPs) with diverse real-world attributes have driven recent interest in cross-problem learning approaches that efficiently generalize across problem variants. We propose ARC (Attribute Representation via Compositional Learning), a cross-problem learning framework that learns disentangled attribute representations by decomposing them into two complementary components: an Intrinsic Attribute Embedding (IAE) for invariant attribute semantics and a Contextual Interaction Embedding (CIE) for attribute-combination effects. This disentanglement is achieved by enforcing analogical consistency in the embedding space to ensure the semantic transformation of adding an attribute (e.g., a length constraint) remains invariant across different problem contexts. This enables our model to reuse invariant semantics across trained variants and construct representations for unseen combinations. ARC achieves state-of-the-art performance across in-distribution, zero-shot generalization, few-shot adaptation, and real-world benchmarks.

</details>


### [128] [From Shortcut to Induction Head: How Data Diversity Shapes Algorithm Selection in Transformers](https://arxiv.org/abs/2512.18634)
*Ryotaro Kawata,Yujin Song,Alberto Bietti,Naoki Nishikawa,Taiji Suzuki,Samuel Vaiter,Denny Wu*

Main category: cs.LG

TL;DR: 论文研究预训练数据分布如何影响浅层Transformer学习归纳头（通用算法）还是位置捷径（简单记忆）。通过理论分析和实验验证，发现输入序列多样性（通过"最大和"比率衡量）决定模型学习哪种机制，并揭示了预训练上下文长度与OOD泛化之间的权衡。


<details>
  <summary>Details</summary>
Motivation: Transformer可以学习通用算法（如归纳头）或简单位置捷径（如记忆固定输出位置）。本研究旨在探索预训练数据分布如何引导浅层Transformer选择其中一种行为，理解数据分布对模型学习机制的影响。

Method: 聚焦于最小触发-输出预测任务（复制特殊触发词第二次出现后的标记），对单层Transformer进行基于梯度的训练分析。在无限和有限样本两种情况下，通过理论分析证明学习机制的转变，并使用"最大和"比率衡量输入序列多样性。通过受控合成实验验证理论预测。

Result: 当输入序列多样性足够高（低"最大和"比率）时，模型学习归纳头并能泛化到未见上下文；当比率较高时，模型采用位置捷径且无法进行OOD泛化。揭示了预训练上下文长度与OOD泛化之间的权衡，并推导出最小化每样本计算成本的最优预训练分布。

Conclusion: 预训练数据分布对Transformer学习机制有决定性影响：多样化的上下文分布能稳健地诱导归纳头学习并实现OOD泛化。研究结果为理解预训练Transformer的算法偏差提供了理论依据，并为数据驱动的模型行为控制提供了概念指导。

Abstract: Transformers can implement both generalizable algorithms (e.g., induction heads) and simple positional shortcuts (e.g., memorizing fixed output positions). In this work, we study how the choice of pretraining data distribution steers a shallow transformer toward one behavior or the other. Focusing on a minimal trigger-output prediction task -- copying the token immediately following a special trigger upon its second occurrence -- we present a rigorous analysis of gradient-based training of a single-layer transformer. In both the infinite and finite sample regimes, we prove a transition in the learned mechanism: if input sequences exhibit sufficient diversity, measured by a low ``max-sum'' ratio of trigger-to-trigger distances, the trained model implements an induction head and generalizes to unseen contexts; by contrast, when this ratio is large, the model resorts to a positional shortcut and fails to generalize out-of-distribution (OOD). We also reveal a trade-off between the pretraining context length and OOD generalization, and derive the optimal pretraining distribution that minimizes computational cost per sample. Finally, we validate our theoretical predictions with controlled synthetic experiments, demonstrating that broadening context distributions robustly induces induction heads and enables OOD generalization. Our results shed light on the algorithmic biases of pretrained transformers and offer conceptual guidelines for data-driven control of their learned behaviors.

</details>


### [129] [Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2512.18670)
*Xue Yang,Michael Schukat,Junlin Lu,Patrick Mannion,Karl Mason,Enda Howley*

Main category: cs.LG

TL;DR: 提出了一种演示引导的持续强化学习方法（DGCRL），通过外部自演化的演示库存储先验知识，直接指导RL探索和适应，解决了动态环境中稳定性与可塑性平衡的挑战。


<details>
  <summary>Details</summary>
Motivation: 强化学习在动态环境中面临挑战，其中底层马尔可夫决策过程会发生变化。持续强化学习虽然能让智能体持续学习适应新任务，但平衡稳定性（保留先验知识）和可塑性（获取新知识）仍然困难。现有方法主要通过优化机制让过去知识影响训练，但很少直接影响智能体行为，这可能阻碍有效的知识重用和高效学习。

Method: 提出演示引导的持续强化学习（DGCRL），将先验知识存储在外部自演化的演示库中，直接指导RL探索和适应。对于每个任务，智能体动态选择最相关的演示，并遵循基于课程学习的策略来加速学习，逐步从演示引导的探索过渡到完全自主探索。

Result: 在2D导航和MuJoCo运动任务上的大量实验表明，该方法具有优越的平均性能、增强的知识迁移能力、减轻遗忘效果以及更高的训练效率。额外的敏感性分析和消融研究进一步验证了其有效性。

Conclusion: DGCRL通过外部演示库直接指导RL探索，有效解决了持续强化学习中稳定性与可塑性的平衡问题，实现了更好的知识重用、减少遗忘和提高学习效率。

Abstract: Reinforcement learning (RL) excels in various applications but struggles in dynamic environments where the underlying Markov decision process evolves. Continual reinforcement learning (CRL) enables RL agents to continually learn and adapt to new tasks, but balancing stability (preserving prior knowledge) and plasticity (acquiring new knowledge) remains challenging. Existing methods primarily address the stability-plasticity dilemma through mechanisms where past knowledge influences optimization but rarely affects the agent's behavior directly, which may hinder effective knowledge reuse and efficient learning. In contrast, we propose demonstration-guided continual reinforcement learning (DGCRL), which stores prior knowledge in an external, self-evolving demonstration repository that directly guides RL exploration and adaptation. For each task, the agent dynamically selects the most relevant demonstration and follows a curriculum-based strategy to accelerate learning, gradually shifting from demonstration-guided exploration to fully self-exploration. Extensive experiments on 2D navigation and MuJoCo locomotion tasks demonstrate its superior average performance, enhanced knowledge transfer, mitigation of forgetting, and training efficiency. The additional sensitivity analysis and ablation study further validate its effectiveness.

</details>


### [130] [Improving Pattern Recognition of Scheduling Anomalies through Structure-Aware and Semantically-Enhanced Graphs](https://arxiv.org/abs/2512.18673)
*Ning Lyu,Junjie Jiang,Lu Chang,Chihui Shao,Feng Chen,Chong Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种结构感知驱动的调度图建模方法，通过结构引导的调度图构建和多尺度图语义聚合，提升复杂系统调度行为异常识别的准确性和表征能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂系统调度行为异常识别中，对全局调度关系和多任务并发、资源竞争、阶段转换等复杂场景的异常特征捕捉能力不足，需要更有效的建模方法来提高异常检测的准确性和表征能力。

Method: 1. 设计结构引导的调度图构建机制，集成任务执行阶段、资源节点状态和调度路径信息，构建动态演化的调度行为图；2. 引入多尺度图语义聚合模块，通过局部邻接语义集成和全局拓扑对齐实现调度特征的语义一致性建模。

Result: 在真实调度数据集上的实验表明，该方法在多个指标上表现出显著性能优势，对结构扰动和语义偏移具有敏感响应。可视化分析显示，在结构引导和语义聚合的共同作用下，调度行为图展现出更强的异常可分性和模式表征能力。

Conclusion: 该方法通过结构感知驱动的调度图建模，有效提升了复杂系统调度行为异常检测的准确性和适应性，验证了结构引导和语义聚合在调度异常检测任务中的有效性。

Abstract: This paper proposes a structure-aware driven scheduling graph modeling method to improve the accuracy and representation capability of anomaly identification in scheduling behaviors of complex systems. The method first designs a structure-guided scheduling graph construction mechanism that integrates task execution stages, resource node states, and scheduling path information to build dynamically evolving scheduling behavior graphs, enhancing the model's ability to capture global scheduling relationships. On this basis, a multi-scale graph semantic aggregation module is introduced to achieve semantic consistency modeling of scheduling features through local adjacency semantic integration and global topology alignment, thereby strengthening the model's capability to capture abnormal features in complex scenarios such as multi-task concurrency, resource competition, and stage transitions. Experiments are conducted on a real scheduling dataset with multiple scheduling disturbance paths set to simulate different types of anomalies, including structural shifts, resource changes, and task delays. The proposed model demonstrates significant performance advantages across multiple metrics, showing a sensitive response to structural disturbances and semantic shifts. Further visualization analysis reveals that, under the combined effect of structure guidance and semantic aggregation, the scheduling behavior graph exhibits stronger anomaly separability and pattern representation, validating the effectiveness and adaptability of the method in scheduling anomaly detection tasks.

</details>


### [131] [Generating Risky Samples with Conformity Constraints via Diffusion Models](https://arxiv.org/abs/2512.18722)
*Han Yu,Hao Zou,Xingxuan Zhang,Zhengyi Wang,Yue He,Kehan Li,Peng Cui*

Main category: cs.LG

TL;DR: RiskyDiff：一种基于扩散模型的风险样本生成方法，通过文本和图像嵌入作为隐式约束，结合一致性评分机制，提升生成样本的风险程度和类别一致性


<details>
  <summary>Details</summary>
Motivation: 现有方法通过搜索现有数据集或注入扰动来发现风险样本，但多样性受限于数据集覆盖范围；基于扩散模型的方法能生成超出数据集覆盖的新风险样本，但存在类别一致性不足的问题，可能引入标签噪声并限制应用效果

Method: 提出RiskyDiff方法：1) 结合文本和图像嵌入作为类别一致性的隐式约束；2) 设计一致性评分机制显式强化类别一致性；3) 引入嵌入筛选和风险梯度引导机制提升生成样本的风险程度

Result: 实验表明RiskyDiff在风险程度、生成质量和类别一致性方面显著优于现有方法；通过高一致性生成样本增强训练数据，能有效提升模型的泛化能力

Conclusion: RiskyDiff通过创新的隐式和显式约束机制，解决了扩散模型生成风险样本时的类别一致性问题，为风险样本发现和模型鲁棒性增强提供了有效解决方案

Abstract: Although neural networks achieve promising performance in many tasks, they may still fail when encountering some examples and bring about risks to applications. To discover risky samples, previous literature attempts to search for patterns of risky samples within existing datasets or inject perturbation into them. Yet in this way the diversity of risky samples is limited by the coverage of existing datasets. To overcome this limitation, recent works adopt diffusion models to produce new risky samples beyond the coverage of existing datasets. However, these methods struggle in the conformity between generated samples and expected categories, which could introduce label noise and severely limit their effectiveness in applications. To address this issue, we propose RiskyDiff that incorporates the embeddings of both texts and images as implicit constraints of category conformity. We also design a conformity score to further explicitly strengthen the category conformity, as well as introduce the mechanisms of embedding screening and risky gradient guidance to boost the risk of generated samples. Extensive experiments reveal that RiskyDiff greatly outperforms existing methods in terms of the degree of risk, generation quality, and conformity with conditioned categories. We also empirically show the generalization ability of the models can be enhanced by augmenting training data with generated samples of high conformity.

</details>


### [132] [ML Inference Scheduling with Predictable Latency](https://arxiv.org/abs/2512.18725)
*Haidong Zhao,Nikolaos Georgantas*

Main category: cs.LG

TL;DR: 现有机器学习推理服务系统中的干扰预测方法存在粒度粗、模型静态等问题，限制了调度效率，本文评估了这些局限性并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 机器学习推理服务系统通过调度请求来提高GPU利用率并满足服务级别目标(SLOs)或截止时间，但提高GPU利用率可能会影响延迟敏感型调度，因为并发任务会竞争GPU资源并引入干扰。干扰效应导致调度不可预测，忽略干扰可能损害SLO或截止时间的满足。现有干扰预测方法存在局限性，可能限制其在调度中的实用性。

Method: 评估现有干扰预测方法的潜在局限性，包括：1）粒度粗，忽略了运行时共置动态，限制了干扰预测的准确性；2）使用静态预测模型，无法有效应对不同工作负载特性。在此基础上，提出了实现高效机器学习推理调度的持续工作方向。

Result: 本文主要分析了现有干扰预测方法的局限性，指出了两个关键问题：粗粒度预测忽略运行时动态，静态模型无法适应不同工作负载特性。这些局限性限制了干扰预测在调度决策中的有效性。

Conclusion: 现有干扰预测方法在准确性和适应性方面存在不足，需要开发更精细的预测方法来解决这些问题，以实现高效的机器学习推理调度，平衡GPU利用率和延迟敏感型调度的需求。

Abstract: Machine learning (ML) inference serving systems can schedule requests to improve GPU utilization and to meet service level objectives (SLOs) or deadlines. However, improving GPU utilization may compromise latency-sensitive scheduling, as concurrent tasks contend for GPU resources and thereby introduce interference. Given that interference effects introduce unpredictability in scheduling, neglecting them may compromise SLO or deadline satisfaction. Nevertheless, existing interference prediction approaches remain limited in several respects, which may restrict their usefulness for scheduling. First, they are often coarse-grained, which ignores runtime co-location dynamics and thus restricts their accuracy in interference prediction. Second, they tend to use a static prediction model, which may not effectively cope with different workload characteristics. To this end, we evaluate the potential limitations of existing interference prediction approaches and outline our ongoing work toward achieving efficient ML inference scheduling.

</details>


### [133] [A Theoretical Lens for RL-Tuned Language Models via Energy-Based Models](https://arxiv.org/abs/2512.18730)
*Zhiquan Tan,Yinrong Hong*

Main category: cs.LG

TL;DR: 该论文从变分分析角度统一分析了KL正则化强化学习训练的大语言模型，证明了指令微调模型具有详细平衡性质，推理模型训练目标等价于期望KL最小化。


<details>
  <summary>Details</summary>
Motivation: 尽管通过KL正则化强化学习训练的大语言模型展现出强大的指令跟随、自我修正和推理能力，但其理论基础仍然有限。作者旨在利用最优KL正则化策略的闭式能量基模型结构，为LLMs提供统一的变分分析框架。

Method: 利用最优KL正则化策略的闭式能量基模型结构进行变分分析。对于指令微调模型，在奖励势函数和预训练对称性的自然假设下，证明转移核满足关于响应质量标量势函数的详细平衡。对于推理模型，分析带有可验证奖励的训练目标。

Result: 证明了指令微调模型的转移核满足详细平衡，从而得到单调KL收敛到高质量平稳分布、到达优越状态的有界命中时间，以及由谱隙控制的指数混合。对于推理模型，证明了训练目标等价于期望KL最小化，次优性间隙简化为目标与当前准确率之间的伯努利KL散度。

Conclusion: 该研究为KL正则化强化学习训练的大语言模型提供了统一的理论分析框架，解释了指令微调模型的收敛性和混合性质，以及推理模型的熵-准确率权衡现象，填补了LLMs理论基础的空白。

Abstract: Large language models (LLMs) trained via KL-regularized reinforcement learning demonstrate strong instruction following, self-correction, and reasoning abilities. Yet their theoretical underpinnings remain limited. We exploit the closed-form energy-based model (EBM) structure of the optimal KL-regularized policy to provide a unified variational analysis of LLMs.
  For instruction-tuned models, under natural assumptions on reward potentials and pretraining symmetry, we prove that the transition kernel satisfies detailed balance with respect to a scalar potential encoding response quality. This yields monotonic KL convergence to a high-quality stationary distribution, bounded hitting times to superior states, and exponential mixing governed by the spectral gap.
  For reasoning models trained with verifiable rewards (RLVR), we show the objective is equivalent to expected KL minimization toward an optimal reasoning distribution, with the suboptimality gap reducing to the Bernoulli KL between target and current accuracies along the natural gradient flow. This helps explain empirical entropy-accuracy trade-offs.

</details>


### [134] [Is Your Conditional Diffusion Model Actually Denoising?](https://arxiv.org/abs/2512.18736)
*Daniel Pfrommer,Zehao Dou,Christopher Scarvelis,Max Simchowitz,Ali Jadbabaie*

Main category: cs.LG

TL;DR: 扩散模型在条件生成时会出现与理想去噪过程的偏差，这种偏差与模型容量或训练数据量无关，源于条件空间中不同部分去噪流难以桥接的平滑性归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 研究条件扩散模型的归纳偏置，这些模型广泛应用于文本条件图像生成和观测条件连续控制策略。观察到条件查询时，生成结果会偏离理想化的去噪过程，导致不同采样算法之间产生分歧。

Method: 引入"调度偏差"作为衡量标准，量化从标准去噪过程的偏离程度，并提供计算方法。通过理论分析展示这种现象如何从平滑性归纳偏置中产生。

Result: 条件扩散模型在生成时会系统性偏离理想去噪过程，这种偏差与模型容量或训练数据量无关。不同采样算法（如DDPM、DDIM）之间因此产生分歧。

Conclusion: 条件扩散模型的偏差源于条件空间中不同部分去噪流难以桥接的平滑性归纳偏置，这为理解扩散模型的行为提供了新的理论视角。

Abstract: We study the inductive biases of diffusion models with a conditioning-variable, which have seen widespread application as both text-conditioned generative image models and observation-conditioned continuous control policies. We observe that when these models are queried conditionally, their generations consistently deviate from the idealized "denoising" process upon which diffusion models are formulated, inducing disagreement between popular sampling algorithms (e.g. DDPM, DDIM). We introduce Schedule Deviation, a rigorous measure which captures the rate of deviation from a standard denoising process, and provide a methodology to compute it. Crucially, we demonstrate that the deviation from an idealized denoising process occurs irrespective of the model capacity or amount of training data. We posit that this phenomenon occurs due to the difficulty of bridging distinct denoising flows across different parts of the conditioning space and show theoretically how such a phenomenon can arise through an inductive bias towards smoothness.

</details>


### [135] [PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation](https://arxiv.org/abs/2512.18737)
*Zichuan Lin,Xiaokai Huang,Jiate Liu,Yuxuan Han,Jia Chen,Xiapeng Wu,Deheng Ye*

Main category: cs.LG

TL;DR: PIPCFR是一种新的个体治疗效果估计方法，通过纳入治疗后变量改进伪结果插补，相比现有方法显著降低ITE误差。


<details>
  <summary>Details</summary>
Motivation: 现有ITE估计方法大多忽略治疗后变量对结果的影响，这限制了它们捕捉结果变异性的能力，导致反事实预测方差增加。需要一种能够有效利用治疗后变量信息的方法来提高估计精度。

Method: 提出PIPCFR方法，通过纳入治疗后变量改进伪结果插补。该方法分析利用治疗后变量的挑战，建立连接治疗后变量与ITE估计精度的理论界限，学习保留信息成分同时减轻偏差的有效表示。

Result: 在真实世界和模拟数据集上的实证评估表明，PIPCFR相比现有方法实现了显著更低的ITE误差。

Conclusion: PIPCFR通过有效整合治疗后变量，显著提升了个体治疗效果估计的准确性，为反事实回归提供了新的有效方法。

Abstract: The estimation of individual treatment effects (ITE) focuses on predicting the outcome changes that result from a change in treatment. A fundamental challenge in observational data is that while we need to infer outcome differences under alternative treatments, we can only observe each individual's outcome under a single treatment. Existing approaches address this limitation either by training with inferred pseudo-outcomes or by creating matched instance pairs. However, recent work has largely overlooked the potential impact of post-treatment variables on the outcome. This oversight prevents existing methods from fully capturing outcome variability, resulting in increased variance in counterfactual predictions. This paper introduces Pseudo-outcome Imputation with Post-treatment Variables for Counterfactual Regression (PIPCFR), a novel approach that incorporates post-treatment variables to improve pseudo-outcome imputation. We analyze the challenges inherent in utilizing post-treatment variables and establish a novel theoretical bound for ITE risk that explicitly connects post-treatment variables to ITE estimation accuracy. Unlike existing methods that ignore these variables or impose restrictive assumptions, PIPCFR learns effective representations that preserve informative components while mitigating bias. Empirical evaluations on both real-world and simulated datasets demonstrate that PIPCFR achieves significantly lower ITE errors compared to existing methods.

</details>


### [136] [Gaussian-Mixture-Model Q-Functions for Policy Iteration in Reinforcement Learning](https://arxiv.org/abs/2512.18763)
*Minh Vu,Konstantinos Slavakis*

Main category: cs.LG

TL;DR: 该论文提出了一种新颖的GMM-QFs方法，将高斯混合模型作为Q函数损失的直接替代，通过黎曼流形优化学习参数，在多种基准RL任务中表现出色且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 传统上高斯混合模型在强化学习中主要用于概率密度函数估计，本文探索其在函数逼近中的新角色，旨在开发一种具有强大表示能力且计算效率高的Q函数逼近方法。

Method: 提出GMM-QFs方法：1) 将高斯混合模型作为Q函数损失的直接替代；2) 在贝尔曼残差中嵌入这些参数化模型；3) 通过黎曼流形优化学习混合权重、高斯均值向量和协方差矩阵；4) 将几何视角融入标准策略迭代框架的策略评估步骤。

Result: 理论证明GMM-QFs在广泛函数类上是通用逼近器。实验结果显示，即使在没有经验数据的情况下，GMM-QFs在多个基准RL任务中表现优异，有时甚至超越最先进方法，同时计算开销显著低于依赖经验数据的深度学习方法。

Conclusion: GMM-QFs为强化学习中的函数逼近提供了一种新颖有效的替代方案，结合了强大的表示能力、理论保证和计算效率，为RL方法设计开辟了新方向。

Abstract: Unlike their conventional use as estimators of probability density functions in reinforcement learning (RL), this paper introduces a novel function-approximation role for Gaussian mixture models (GMMs) as direct surrogates for Q-function losses. These parametric models, termed GMM-QFs, possess substantial representational capacity, as they are shown to be universal approximators over a broad class of functions. They are further embedded within Bellman residuals, where their learnable parameters -- a fixed number of mixing weights, together with Gaussian mean vectors and covariance matrices -- are inferred from data via optimization on a Riemannian manifold. This geometric perspective on the parameter space naturally incorporates Riemannian optimization into the policy-evaluation step of standard policy-iteration frameworks. Rigorous theoretical results are established, and supporting numerical tests show that, even without access to experience data, GMM-QFs deliver competitive performance and, in some cases, outperform state-of-the-art approaches across a range of benchmark RL tasks, all while maintaining a significantly smaller computational footprint than deep-learning methods that rely on experience data.

</details>


### [137] [Label-Informed Outlier Detection Based on Granule Density](https://arxiv.org/abs/2512.18774)
*Baiyang Chen,Zhong Yuan,Dezhong Peng,Hongmei Chen,Xiaomin Song,Huiming Zheng*

Main category: cs.LG

TL;DR: 该论文提出了一种基于粒计算和模糊集的标签信息异常检测方法GDOF，用于处理异构数据中的异常检测问题，通过标签信息模糊粒化和粒度密度估计来提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督异常检测方法通常将数据视为纯数值且确定性处理，忽略了现实世界复杂数据集中固有的异质性和不确定性，需要一种能够处理异构数据并利用有限标签信息的异常检测方法。

Method: 提出Granule Density-based Outlier Factor (GDOF)方法：1) 使用标签信息模糊粒化有效表示各种数据类型；2) 开发粒度密度进行精确密度估计；3) 通过评估属性相关性将单个属性的粒度密度集成用于异常评分。

Result: 在多个真实世界数据集上的实验结果表明，GDOF在使用最少标签异常样本的情况下，在异构数据异常检测方面表现突出，优于现有方法。

Conclusion: GDOF通过整合模糊集和粒计算，为复杂多样数据类型的异常检测提供了一个实用框架，能够有效处理数据异质性和不确定性，在有限标签信息下实现高性能异常检测。

Abstract: Outlier detection, crucial for identifying unusual patterns with significant implications across numerous applications, has drawn considerable research interest. Existing semi-supervised methods typically treat data as purely numerical and} in a deterministic manner, thereby neglecting the heterogeneity and uncertainty inherent in complex, real-world datasets. This paper introduces a label-informed outlier detection method for heterogeneous data based on Granular Computing and Fuzzy Sets, namely Granule Density-based Outlier Factor (GDOF). Specifically, GDOF first employs label-informed fuzzy granulation to effectively represent various data types and develops granule density for precise density estimation. Subsequently, granule densities from individual attributes are integrated for outlier scoring by assessing attribute relevance with a limited number of labeled outliers. Experimental results on various real-world datasets show that GDOF stands out in detecting outliers in heterogeneous data with a minimal number of labeled outliers. The integration of Fuzzy Sets and Granular Computing in GDOF offers a practical framework for outlier detection in complex and diverse data types. All relevant datasets and source codes are publicly available for further research. This is the author's accepted manuscript of a paper published in IEEE Transactions on Fuzzy Systems. The final version is available at https://doi.org/10.1109/TFUZZ.2024.3514853

</details>


### [138] [Controllable Probabilistic Forecasting with Stochastic Decomposition Layers](https://arxiv.org/abs/2512.18815)
*John S. Schreck,William E. Chapman,Charlie Becker,David John Gagne,Dhamma Kimpara,Nihanth Cherukuru,Judith Berner,Kirsten J. Mayer,Negin Sobhani*

Main category: cs.LG

TL;DR: 提出Stochastic Decomposition Layers (SDL)方法，将确定性ML天气模型转换为概率集合系统，通过分层噪声注入实现高效、可解释的不确定性量化


<details>
  <summary>Details</summary>
Motivation: 现有CRPS集合方法训练策略和噪声注入机制不一致，大多通过条件归一化全局注入噪声，导致训练成本高且随机扰动的物理可解释性有限

Method: 引入SDL方法，借鉴StyleGAN的分层噪声注入，在三个解码器尺度上通过潜在驱动调制、逐像素噪声和通道缩放应用学习扰动

Result: SDL应用于WXFormer仅需基线模型2%的计算成本；集合成员生成自紧凑潜在张量(5MB)；在ERA5再分析数据上实现接近1的扩散-技能比和渐进平坦的秩直方图，校准性能与业务IFS-ENS相当

Conclusion: SDL提供高效、可解释的不确定性量化方法，分层结构揭示粗尺度调制天气系统模式、细尺度控制中尺度变率的层次不确定性，适用于业务预报和气候应用

Abstract: AI weather prediction ensembles with latent noise injection and optimized with the continuous ranked probability score (CRPS) have produced both accurate and well-calibrated predictions with far less computational cost compared with diffusion-based methods. However, current CRPS ensemble approaches vary in their training strategies and noise injection mechanisms, with most injecting noise globally throughout the network via conditional normalization. This structure increases training expense and limits the physical interpretability of the stochastic perturbations. We introduce Stochastic Decomposition Layers (SDL) for converting deterministic machine learning weather models into probabilistic ensemble systems. Adapted from StyleGAN's hierarchical noise injection, SDL applies learned perturbations at three decoder scales through latent-driven modulation, per-pixel noise, and channel scaling. When applied to WXFormer via transfer learning, SDL requires less than 2\% of the computational cost needed to train the baseline model. Each ensemble member is generated from a compact latent tensor (5 MB), enabling perfect reproducibility and post-inference spread adjustment through latent rescaling. Evaluation on 2022 ERA5 reanalysis shows ensembles with spread-skill ratios approaching unity and rank histograms that progressively flatten toward uniformity through medium-range forecasts, achieving calibration competitive with operational IFS-ENS. Multi-scale experiments reveal hierarchical uncertainty: coarse layers modulate synoptic patterns while fine layers control mesoscale variability. The explicit latent parameterization provides interpretable uncertainty quantification for operational forecasting and climate applications.

</details>


### [139] [Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection](https://arxiv.org/abs/2512.18826)
*Souhail Abdelmouaiz Sadat,Mohamed Yacine Touahria Miliani,Khadidja Hab El Hames,Hamida Seba,Mohammed Haddad*

Main category: cs.LG

TL;DR: 该综述回顾了双曲图嵌入模型，并在异常检测任务上评估了它们，突出了其在捕捉复杂结构方面相对于欧几里得方法的优势。


<details>
  <summary>Details</summary>
Motivation: 双曲空间相比欧几里得空间能更好地表示具有层次和复杂结构的数据，但在异常检测领域的应用潜力尚未得到充分探索。本研究旨在评估双曲图嵌入模型在异常检测任务中的性能，并与传统欧几里得方法进行比较。

Method: 综述了多种双曲图嵌入模型（包括HGCAE、\(\mathcal{P}\)-VAE、HGCN等），并在异常检测任务上对它们进行了系统评估。同时与欧几里得方法（如DOMINANT、GraphSage）进行对比分析。研究还提供了一个开源库来支持该领域的进一步研究。

Result: 双曲图嵌入模型在异常检测任务中表现出色：\(\mathcal{P}\)-VAE在Elliptic数据集上达到94%的F1分数，HGCAE在Cora数据集上达到80%的F1分数。相比之下，欧几里得方法在处理复杂数据时表现较差。

Conclusion: 双曲空间在改进异常检测方面具有显著潜力，特别是在处理具有复杂结构的数据时。研究提供的开源库将促进该领域的进一步探索和发展。

Abstract: This survey reviews hyperbolic graph embedding models, and evaluate them on anomaly detection, highlighting their advantages over Euclidean methods in capturing complex structures. Evaluating models like \textit{HGCAE}, \textit{\(\mathcal{P}\)-VAE}, and \textit{HGCN} demonstrates high performance, with \textit{\(\mathcal{P}\)-VAE} achieving an F1-score of 94\% on the \textit{Elliptic} dataset and \textit{HGCAE} scoring 80\% on \textit{Cora}. In contrast, Euclidean methods like \textit{DOMINANT} and \textit{GraphSage} struggle with complex data. The study emphasizes the potential of hyperbolic spaces for improving anomaly detection, and provides an open-source library to foster further research in this field.

</details>


### [140] [The Ensemble Schr{ö}dinger Bridge filter for Nonlinear Data Assimilation](https://arxiv.org/abs/2512.18928)
*Feng Bao,Hui Sun*

Main category: cs.LG

TL;DR: 提出了一种名为集成薛定谔桥非线性滤波器的新型非线性最优滤波器，将标准预测过程与扩散生成建模相结合实现滤波步骤，无结构模型误差、无需导数计算、无需训练且高度并行化。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统非线性滤波器在高维非线性动态系统中的局限性，特别是在混沌环境下，需要一种无结构模型误差、计算效率高且性能优越的滤波器。

Method: 将标准预测过程与扩散生成建模相结合，设计集成薛定谔桥非线性滤波器。该方法将滤波步骤分解为预测和分析两个部分，利用扩散生成模型进行状态更新。

Result: 在高达40维或更高的混沌环境中，该算法对高度非线性动态系统表现良好。在多个测试中，相比集成卡尔曼滤波器和粒子滤波器，在不同非线性程度下都显示出更好的性能。

Conclusion: 提出的集成薛定谔桥非线性滤波器是一种有效的非线性滤波方法，具有无结构误差、无需导数计算、无需训练和高度并行化的优势。未来工作将扩展到实际气象应用并建立严格的收敛性分析。

Abstract: This work puts forward a novel nonlinear optimal filter namely the Ensemble Schr{ö}dinger Bridge nonlinear filter. The proposed filter finds marriage of the standard prediction procedure and the diffusion generative modeling for the analysis procedure to realize one filtering step. The designed approach finds no structural model error, and it is derivative free, training free and highly parallizable. Experimental results show that the designed algorithm performs well given highly nonlinear dynamics in (mildly) high dimension up to 40 or above under a chaotic environment. It also shows better performance than classical methods such as the ensemble Kalman filter and the Particle filter in numerous tests given different level of nonlinearity. Future work will focus on extending the proposed approach to practical meteorological applications and establishing a rigorous convergence analysis.

</details>


### [141] [DPSR: Differentially Private Sparse Reconstruction via Multi-Stage Denoising for Recommender Systems](https://arxiv.org/abs/2512.18932)
*Sarwan Ali*

Main category: cs.LG

TL;DR: DPSR是一种新的差分隐私推荐系统框架，通过三阶段去噪方法在保护隐私的同时提升推荐质量，甚至在特定隐私预算下超越非隐私基线性能。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私机制面临隐私-效用权衡问题，随着隐私预算收紧，推荐质量会下降。需要一种方法既能保护用户数据隐私，又能维持甚至提升推荐质量。

Method: DPSR采用三阶段去噪框架：1) 信息论噪声校准，自适应减少高信息评分的噪声；2) 基于协同过滤的去噪，利用物品相似性去除隐私噪声；3) 低秩矩阵补全，利用潜在结构恢复信号。所有去噪操作都在噪声注入后进行，通过后处理免疫定理保持差分隐私。

Result: 在合成数据集实验中，DPSR在隐私预算ε=0.1到10.0范围内，比最先进的拉普拉斯和高斯机制实现了5.57%到9.23%的RMSE提升。在ε=1.0时，DPSR的RMSE为0.9823，甚至优于非隐私基线(1.0983)。所有改进都具有统计显著性(p<0.05，大多数p<0.001)。

Conclusion: DPSR通过利用评分矩阵的稀疏性、低秩特性和协同模式，不仅解决了隐私-效用权衡问题，其去噪管道还能作为有效的正则化器，去除数据噪声和隐私噪声，在某些情况下甚至能超越非隐私基线的性能。

Abstract: Differential privacy (DP) has emerged as the gold standard for protecting user data in recommender systems, but existing privacy-preserving mechanisms face a fundamental challenge: the privacy-utility tradeoff inevitably degrades recommendation quality as privacy budgets tighten. We introduce DPSR (Differentially Private Sparse Reconstruction), a novel three-stage denoising framework that fundamentally addresses this limitation by exploiting the inherent structure of rating matrices -- sparsity, low-rank properties, and collaborative patterns.
  DPSR consists of three synergistic stages: (1) \textit{information-theoretic noise calibration} that adaptively reduces noise for high-information ratings, (2) \textit{collaborative filtering-based denoising} that leverages item-item similarities to remove privacy noise, and (3) \textit{low-rank matrix completion} that exploits latent structure for signal recovery. Critically, all denoising operations occur \textit{after} noise injection, preserving differential privacy through the post-processing immunity theorem while removing both privacy-induced and inherent data noise.
  Through extensive experiments on synthetic datasets with controlled ground truth, we demonstrate that DPSR achieves 5.57\% to 9.23\% RMSE improvement over state-of-the-art Laplace and Gaussian mechanisms across privacy budgets ranging from $\varepsilon=0.1$ to $\varepsilon=10.0$ (all improvements statistically significant with $p < 0.05$, most $p < 0.001$). Remarkably, at $\varepsilon=1.0$, DPSR achieves RMSE of 0.9823, \textit{outperforming even the non-private baseline} (1.0983), demonstrating that our denoising pipeline acts as an effective regularizer that removes data noise in addition to privacy noise.

</details>


### [142] [When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models](https://arxiv.org/abs/2512.18934)
*Michael S. Zhang,Rishi A. Ruia,Arnav Kewalram,Saathvik Dharmapuram,Utkarsh Sharma,Kevin Zhu*

Main category: cs.LG

TL;DR: 量化模型在持续学习中意外地优于高精度模型，INT8在计算效率和持续学习动态间达到最佳平衡


<details>
  <summary>Details</summary>
Motivation: 研究量化精度与回放缓冲策略在持续学习中的相互作用，挑战"精度越高越好"的传统观念

Method: 系统研究不同量化精度（FP16、INT8、INT4）与回放缓冲策略在大语言模型中的表现

Result: 量化模型在后续任务中表现优于FP16，INT4在代码生成任务上性能接近FP16的两倍；即使很小的回放缓冲（0.1%）也能显著改善知识保留

Conclusion: INT8量化在计算效率和持续学习性能间达到最佳平衡，量化引入的噪声可作为隐式正则化防止过拟合，为部署压缩模型提供实用指导

Abstract: Catastrophic forgetting poses a fundamental challenge in continual learning, particularly when models are quantized for deployment efficiency. We systematically investigate the interplay between quantization precision (FP16, INT8, INT4) and replay buffer strategies in large language models, revealing unexpected dynamics. While FP16 achieves superior initial task performance (74.44% on NLU), we observe a striking inversion on subsequent tasks: quantized models outperform FP16 by 8-15% on final task forward accuracy, with INT4 achieving nearly double FP16's performance on Code generation (40% vs 20%). Critically, even minimal replay buffers (0.1%) dramatically improve retention - increasing NLU retention after Math training from 45% to 65% across all precision levels - with INT8 consistently achieving the optimal balance between learning plasticity and knowledge retention. We hypothesize that quantization-induced noise acts as implicit regularization, preventing the overfitting to new task gradients that plagues high-precision models. These findings challenge the conventional wisdom that higher precision is always preferable, suggesting instead that INT8 quantization offers both computational efficiency and superior continual learning dynamics. Our results provide practical guidelines for deploying compressed models in continual learning scenarios: small replay buffers (1-2%) suffice for NLU tasks, while Math and Code benefit from moderate buffers (5-10%), with quantized models requiring less replay than FP16 to achieve comparable retention. Code is available at https://github.com/Festyve/LessIsMore.

</details>


### [143] [Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement](https://arxiv.org/abs/2512.18950)
*Saman Forouzandeh,Wei Peng,Parham Moradi,Xinghuo Yu,Mahdi Jalili*

Main category: cs.LG

TL;DR: MACLA是一个将推理与学习解耦的框架，通过维护冻结的大语言模型，在外部层次化过程记忆中进行所有适应。该框架提取可重用过程，通过贝叶斯后验跟踪可靠性，通过期望效用评分选择动作，并通过对比成功与失败来精炼过程。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要更新大语言模型参数，这既计算成本高又缺乏可解释性。MACLA旨在实现样本高效、可解释且持续改进的智能体，同时避免大语言模型参数更新。

Method: MACLA采用外部层次化过程记忆，从轨迹中提取可重用过程，通过贝叶斯后验跟踪过程可靠性，使用期望效用评分选择动作，并通过对比成功与失败案例来精炼过程。所有学习都在外部记忆中进行，大语言模型保持冻结状态。

Result: 在四个基准测试（ALFWorld、WebShop、TravelPlanner、InterCodeSQL）上，MACLA平均性能达到78.1%，优于所有基线。在ALFWorld未见任务上达到90.3%性能，有3.1%的正向泛化。系统在56秒内构建记忆，比最先进的大语言模型参数训练基线快2800倍，将2851个轨迹压缩为187个过程。

Conclusion: 结构化外部记忆结合贝叶斯选择和对比精炼能够实现样本高效、可解释且持续改进的智能体，无需更新大语言模型参数。这种方法在性能、效率和可扩展性方面都表现出优势。

Abstract: We present MACLA, a framework that decouples reasoning from learning by maintaining a frozen large language model while performing all adaptation in an external hierarchical procedural memory. MACLA extracts reusable procedures from trajectories, tracks reliability via Bayesian posteriors, selects actions through expected-utility scoring, and refines procedures by contrasting successes and failures. Across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL), MACLA achieves 78.1 percent average performance, outperforming all baselines. On ALFWorld unseen tasks, MACLA reaches 90.3 percent with 3.1 percent positive generalization. The system constructs memory in 56 seconds, 2800 times faster than the state-of-the-art LLM parameter-training baseline, compressing 2851 trajectories into 187 procedures. Experimental results demonstrate that structured external memory with Bayesian selection and contrastive refinement enables sample-efficient, interpretable, and continually improving agents without LLM parameter updates.

</details>


### [144] [Learning Through Little Eyes: Attribute Discrimination Beyond Objects](https://arxiv.org/abs/2512.18951)
*Patrick Batsell,Tsutsui Satoshi,Bihan Wen*

Main category: cs.LG

TL;DR: 该研究比较了婴儿视角对比学习模型(CVCL)与CLIP在属性识别能力上的差异，发现CVCL更擅长大小识别，CLIP更擅长颜色识别，两者在纹理识别上都存在视觉与语言空间的差距。


<details>
  <summary>Details</summary>
Motivation: 婴儿在前两年不仅能识别物体类别，还能识别颜色、大小、纹理等细粒度属性。先前研究探索了基于婴儿第一人称视角视频训练的CVCL模型，但只关注类别识别，不清楚婴儿规模的学习是否也支持属性识别。

Method: 引入一个系统变化颜色、大小和纹理的基准测试，用于控制测试类别内属性识别。比较CVCL与CLIP模型在属性识别能力上的表现。

Result: CVCL在大小识别上表现更好，CLIP在颜色识别上准确率更高。两个模型都能在图像嵌入中表示纹理，但无法将纹理与语言对应，表明视觉空间与语言空间存在差距。

Conclusion: 婴儿视角学习模型与大规模预训练模型在属性识别能力上存在差异，特别是在视觉-语言对应方面存在局限性，这为理解早期学习机制提供了计算视角。

Abstract: Infants learn to recognize not only object categories but also fine grained attributes such as color, size, and texture within their first two years of life. Prior work explores Childs View for Contrastive Learning (CVCL), a CLIP style model trained on infant egocentric video as a computational model of early infant learning, but it focuses only on class level recognition. This leaves it unclear whether infant scale learning also supports attribute discrimination. To address this, we introduce a benchmark that systematically varies color, size, and texture, allowing controlled tests of within class attribute recognition. Comparing CVCL with CLIP shows clear differences. CVCL is better at size discrimination, while CLIP achieves higher accuracy on color discrimination. Both models represent texture in image embeddings but fail to ground texture linguistically, suggesting a gap between visual and language spaces.

</details>


### [145] [Scaling Online Distributionally Robust Reinforcement Learning: Sample-Efficient Guarantees with General Function Approximation](https://arxiv.org/abs/2512.18957)
*Debamita Ghosh,George K. Atia,Yue Wang*

Main category: cs.LG

TL;DR: 提出了一种在线分布鲁棒强化学习算法，通过与环境交互学习最优鲁棒策略，无需先验模型或离线数据，适用于高维任务


<details>
  <summary>Details</summary>
Motivation: 强化学习在实际应用中常因训练与部署环境不匹配导致性能下降，现有分布鲁棒RL方法需要大量先验知识（生成模型或离线数据集），且主要局限于表格方法，难以扩展到复杂领域

Method: 提出在线分布鲁棒强化学习算法，采用通用函数逼近，仅通过与环境交互学习最优鲁棒策略，无需先验模型或离线数据，适用于高维任务

Result: 在总变差不确定性集下建立了接近最优的次线性遗憾界理论分析，证明了方法的样本效率和有效性

Conclusion: 该方法克服了现有分布鲁棒RL的局限性，能够在没有先验知识的情况下通过在线交互学习鲁棒策略，适用于复杂高维任务

Abstract: The deployment of reinforcement learning (RL) agents in real-world applications is often hindered by performance degradation caused by mismatches between training and deployment environments. Distributionally robust RL (DR-RL) addresses this issue by optimizing worst-case performance over an uncertainty set of transition dynamics. However, existing work typically relies on substantial prior knowledge-such as access to a generative model or a large offline dataset-and largely focuses on tabular methods that do not scale to complex domains. We overcome these limitations by proposing an online DR-RL algorithm with general function approximation that learns an optimal robust policy purely through interaction with the environment, without requiring prior models or offline data, enabling deployment in high-dimensional tasks. We further provide a theoretical analysis establishing a near-optimal sublinear regret bound under a total variation uncertainty set, demonstrating the sample efficiency and effectiveness of our method.

</details>


### [146] [Consistency-guided semi-supervised outlier detection in heterogeneous data using fuzzy rough sets](https://arxiv.org/abs/2512.18977)
*Baiyang Chen,Zhong Yuan,Dezhong Peng,Xiaoliang Chen,Hongmei Chen*

Main category: cs.LG

TL;DR: 提出了一种基于模糊粗糙集理论的半监督一致性引导异常检测算法(COD)，用于处理异构数据，通过标签信息构建模糊相似关系，利用分类一致性评估属性贡献，结合异常因子进行异常预测。


<details>
  <summary>Details</summary>
Motivation: 当前大多数半监督异常检测方法主要针对数值数据，忽视了数据的异构性信息。为了在异构数据上利用部分标签监督来降低误报率，需要开发能够处理异构数据的半监督异常检测方法。

Method: 1. 利用少量标记的异常样本来构建标签信息的模糊相似关系；2. 引入模糊决策系统的一致性来评估属性对知识分类的贡献；3. 基于模糊相似类定义异常因子；4. 通过整合分类一致性和异常因子来预测异常。

Result: 在15个新提出的数据集上进行了广泛评估，实验结果表明COD算法优于或与领先的异常检测器相当。

Conclusion: 提出的COD算法能够有效处理异构数据的半监督异常检测问题，通过模糊粗糙集理论整合标签信息和数据一致性，在多个数据集上表现出优越性能。

Abstract: Outlier detection aims to find samples that behave differently from the majority of the data. Semi-supervised detection methods can utilize the supervision of partial labels, thus reducing false positive rates. However, most of the current semi-supervised methods focus on numerical data and neglect the heterogeneity of data information. In this paper, we propose a consistency-guided outlier detection algorithm (COD) for heterogeneous data with the fuzzy rough set theory in a semi-supervised manner. First, a few labeled outliers are leveraged to construct label-informed fuzzy similarity relations. Next, the consistency of the fuzzy decision system is introduced to evaluate attributes' contributions to knowledge classification. Subsequently, we define the outlier factor based on the fuzzy similarity class and predict outliers by integrating the classification consistency and the outlier factor. The proposed algorithm is extensively evaluated on 15 freshly proposed datasets. Experimental results demonstrate that COD is better than or comparable with the leading outlier detectors. This manuscript is the accepted author version of a paper published by Elsevier. The final published version is available at https://doi.org/10.1016/j.asoc.2024.112070

</details>


### [147] [Outlier detection in mixed-attribute data: a semi-supervised approach with fuzzy approximations and relative entropy](https://arxiv.org/abs/2512.18978)
*Baiyang Chen,Zhong Yuan,Zheng Liu,Dezhong Peng,Yongxiang Li,Chang Liu,Guiduo Duan*

Main category: cs.LG

TL;DR: 提出基于模糊粗糙集的半监督离群点检测方法FROD，有效处理混合属性数据的不确定性和异质性


<details>
  <summary>Details</summary>
Motivation: 现有半监督离群点检测方法通常忽略现实世界混合属性数据的不确定性和异质性，需要一种能够有效处理这些挑战的方法

Method: 首先利用少量标记数据构建模糊决策系统，引入基于模糊近似的属性分类精度评估属性集贡献；然后使用未标记数据计算模糊相对熵，从不确定性角度表征离群点；最后结合属性分类精度和模糊相对熵开发检测算法

Result: 在16个公共数据集上的实验结果表明，FROD与领先检测算法相当或更好

Conclusion: 提出的FROD方法能够有效处理混合属性数据的不确定性和异质性，在离群点检测任务中表现出色

Abstract: Outlier detection is a critical task in data mining, aimed at identifying objects that significantly deviate from the norm. Semi-supervised methods improve detection performance by leveraging partially labeled data but typically overlook the uncertainty and heterogeneity of real-world mixed-attribute data. This paper introduces a semi-supervised outlier detection method, namely fuzzy rough sets-based outlier detection (FROD), to effectively handle these challenges. Specifically, we first utilize a small subset of labeled data to construct fuzzy decision systems, through which we introduce the attribute classification accuracy based on fuzzy approximations to evaluate the contribution of attribute sets in outlier detection. Unlabeled data is then used to compute fuzzy relative entropy, which provides a characterization of outliers from the perspective of uncertainty. Finally, we develop the detection algorithm by combining attribute classification accuracy with fuzzy relative entropy. Experimental results on 16 public datasets show that FROD is comparable with or better than leading detection algorithms. All datasets and source codes are accessible at https://github.com/ChenBaiyang/FROD. This manuscript is the accepted author version of a paper published by Elsevier. The final published version is available at https://doi.org/10.1016/j.ijar.2025.109373

</details>


### [148] [Time-series Forecast for Indoor Zone Air Temperature with Long Horizons: A Case Study with Sensor-based Data from a Smart Building](https://arxiv.org/abs/2512.19038)
*Liping Sun,Yucheng Guo,Siliang Lu,Zhenzhen Li*

Main category: cs.LG

TL;DR: 开发时间序列预测模型，预测美国建筑区域空气温度在2周时间范围内的变化，支持HVAC系统智能控制和混合建筑能源建模。


<details>
  <summary>Details</summary>
Motivation: 全球气候变化导致极端天气频发，对HVAC系统运行控制提出更高要求，需要更节能、灵活应对天气快速变化的解决方案。传统模拟方法如EnergyPlus和DOE2存在局限，需要结合物理和数据驱动的混合方法进行快速建模和预测。

Method: 采用时间序列预测模型，结合物理原理和数据驱动方法，针对美国建筑区域空气温度进行预测。这是一种混合方法，旨在填补短期和长期预测领域的研究空白。

Result: 开发了能够预测建筑区域空气温度在2周时间范围内的模型。该模型可用于支持HVAC系统的智能控制和运行（需求灵活性），并可作为混合建筑能源建模的基础。

Conclusion: 该研究填补了建筑区域空气温度短期和长期预测的研究空白，开发的混合模型能够支持更节能、灵活的HVAC系统控制，有助于应对气候变化带来的挑战，并为建筑能源建模提供新方法。

Abstract: With the press of global climate change, extreme weather and sudden weather changes are becoming increasingly common. To maintain a comfortable indoor environment and minimize the contribution of the building to climate change as much as possible, higher requirements are placed on the operation and control of HVAC systems, e.g., more energy-efficient and flexible to response to the rapid change of weather. This places demands on the rapid modeling and prediction of zone air temperatures of buildings. Compared to the traditional simulation-based approach such as EnergyPlus and DOE2, a hybrid approach combined physics and data-driven is more suitable. Recently, the availability of high-quality datasets and algorithmic breakthroughs have driven a considerable amount of work in this field. However, in the niche of short- and long-term predictions, there are still some gaps in existing research. This paper aims to develop a time series forecast model to predict the zone air temperature in a building located in America on a 2-week horizon. The findings could be further improved to support intelligent control and operation of HVAC systems (i.e. demand flexibility) and could also be used as hybrid building energy modeling.

</details>


### [149] [Efficient Personalization of Generative Models via Optimal Experimental Design](https://arxiv.org/abs/2512.19057)
*Guy Schacht,Ziyad Sheebaelhamd,Riccardo De Santi,Mojmír Mutný,Andreas Krause*

Main category: cs.LG

TL;DR: 提出基于最优实验设计的偏好查询选择方法ED-PBRL，通过最大化潜在偏好模型信息来高效获取人类反馈，在文本到图像生成模型个性化任务中比随机查询选择更高效


<details>
  <summary>Details</summary>
Motivation: 人类反馈获取成本高且耗时，需要数据高效的查询选择方法来对齐生成模型与用户需求

Method: 将偏好查询选择问题形式化为最大化潜在偏好模型信息的凸优化问题，提出具有理论保证的ED-PBRL算法，能高效构建结构化查询（如图像或文本）

Result: 在文本到图像生成模型个性化任务中，相比随机查询选择，该方法需要更少的偏好查询

Conclusion: 基于最优实验设计的偏好查询选择方法能有效减少人类反馈需求，提高生成模型与用户偏好的对齐效率

Abstract: Preference learning from human feedback has the ability to align generative models with the needs of end-users. Human feedback is costly and time-consuming to obtain, which creates demand for data-efficient query selection methods. This work presents a novel approach that leverages optimal experimental design to ask humans the most informative preference queries, from which we can elucidate the latent reward function modeling user preferences efficiently. We formulate the problem of preference query selection as the one that maximizes the information about the underlying latent preference model. We show that this problem has a convex optimization formulation, and introduce a statistically and computationally efficient algorithm ED-PBRL that is supported by theoretical guarantees and can efficiently construct structured queries such as images or text. We empirically present the proposed framework by personalizing a text-to-image generative model to user-specific styles, showing that it requires less preference queries compared to random query selection.

</details>


### [150] [DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale](https://arxiv.org/abs/2512.19097)
*Danny Dongyeop Han,Yonghyeon Gwon,Ahhyun Lucy Lee,Taeyang Lee,Seong Jin Lee,Jubin Choi,Sebin Lee,Jihyun Bang,Seungju Lee,David Keetae Park,Shinjae Yoo,Chun Kee Chung,Jiook Cha*

Main category: cs.LG

TL;DR: DIVER-1是首个大规模脑电信号基础模型，在5.3k小时iEEG和54k小时EEG数据上训练，参数量达18.2亿，通过数据约束的缩放定律和架构创新实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有脑电信号基础模型规模有限，而缩放能显著提升性能，需要建立更高效的大规模脑电信号基础模型。

Method: 1. 使用最大最丰富的脑电数据语料库（5.3k小时iEEG+54k小时EEG）；2. 提出数据约束的缩放定律；3. 架构创新：任意变量注意力、滑动时间条件位置编码、多域重建。

Result: DIVER-1 iEEG和EEG模型在各自基准测试中均达到最先进性能，为脑电信号基础模型开发提供了高效的缩放和资源分配指导。

Conclusion: 通过数据约束的缩放策略和架构创新，DIVER-1建立了脑电信号基础模型的新标准，证明在有限数据下，较小模型长时间训练优于大模型短期训练。

Abstract: Electrophysiology signals such as EEG and iEEG are central to neuroscience, brain-computer interfaces, and clinical applications, yet existing foundation models remain limited in scale despite clear evidence that scaling improves performance. We introduce DIVER-1, a family of EEG and iEEG foundation models trained on the largest and most diverse corpus to date-5.3k hours of iEEG and 54k hours of EEG (1.6M channel-hours from over 17.7k subjects)-and scaled up to 1.82B parameters. We present the first systematic scaling law analysis for this domain, showing that they follow data-constrained scaling laws: for a given amount of data and compute, smaller models trained for extended epochs consistently outperform larger models trained briefly. This behavior contrasts with prior electrophysiology foundation models that emphasized model size over training duration. To achieve strong performance, we also design architectural innovations including any-variate attention, sliding temporal conditional positional encoding, and multi-domain reconstruction. DIVER-1 iEEG and EEG models each achieve state-of-the-art performance on their respective benchmarks, establishing a concrete guidelines for efficient scaling and resource allocation in electrophysiology foundation model development.

</details>


### [151] [Timely Parameter Updating in Over-the-Air Federated Learning](https://arxiv.org/abs/2512.19103)
*Jiaqi Zhu,Zhongyuan Zhao,Xiao Li,Ruihao Du,Shi Jin,Howard H. Yang*

Main category: cs.LG

TL;DR: 提出FAIR-k算法解决OAC-FL中正交波形数量有限与深度学习模型高维度不匹配的问题，通过选择最重要的梯度子集进行空中计算，平衡更新时效性和重要性


<details>
  <summary>Details</summary>
Motivation: 联邦学习系统中通信瓶颈问题严重，空中计算(OAC)能缓解此问题，但实际系统中正交波形数量有限，与现代深度学习模型的高维度不匹配

Method: 提出FAIR-k算法，结合Round-Robin和Top-k算法的优势，在每轮通信中选择最具影响力的梯度子集进行空中更新，平衡参数更新的时效性（新鲜度）和重要性（梯度幅度）

Result: 使用马尔可夫分析工具刻画FAIR-k下参数陈旧度的分布，建立OAC-FL与FAIR-k的收敛速率，揭示数据异质性、信道噪声和参数陈旧度对训练效率的联合影响

Conclusion: FAIR-k通过促进新鲜且公平的参数更新，不仅加速收敛，还通过允许更长的本地训练时间来提高通信效率，而不显著影响整体训练效率

Abstract: Incorporating over-the-air computations (OAC) into the model training process of federated learning (FL) is an effective approach to alleviating the communication bottleneck in FL systems. Under OAC-FL, every client modulates its intermediate parameters, such as gradient, onto the same set of orthogonal waveforms and simultaneously transmits the radio signal to the edge server. By exploiting the superposition property of multiple-access channels, the edge server can obtain an automatically aggregated global gradient from the received signal. However, the limited number of orthogonal waveforms available in practical systems is fundamentally mismatched with the high dimensionality of modern deep learning models. To address this issue, we propose Freshness Freshness-mAgnItude awaRe top-k (FAIR-k), an algorithm that selects, in each communication round, the most impactful subset of gradients to be updated over the air. In essence, FAIR-k combines the complementary strengths of the Round-Robin and Top-k algorithms, striking a delicate balance between timeliness (freshness of parameter updates) and importance (gradient magnitude). Leveraging tools from Markov analysis, we characterize the distribution of parameter staleness under FAIR-k. Building on this, we establish the convergence rate of OAC-FL with FAIR-k, which discloses the joint effect of data heterogeneity, channel noise, and parameter staleness on the training efficiency. Notably, as opposed to conventional analyses that assume a universal Lipschitz constant across all the clients, our framework adopts a finer-grained model of the data heterogeneity. The analysis demonstrates that since FAIR-k promotes fresh (and fair) parameter updates, it not only accelerates convergence but also enhances communication efficiency by enabling an extended period of local training without significantly affecting overall training efficiency.

</details>


### [152] [HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction](https://arxiv.org/abs/2512.19114)
*Haoyu Jiang,Boan Qu,Junjie Zhu,Fanjie Zeng,Xiaojie Lin,Wei Zhong*

Main category: cs.LG

TL;DR: HyperLoad是一个利用预训练大语言模型解决绿色数据中心负载预测中数据稀缺问题的跨模态框架，通过知识对齐和多尺度特征建模，在数据充足和稀缺场景下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 人工智能快速发展导致数据中心能耗和碳排放激增，绿色数据中心需要分钟级协调可再生能源、存储和负载，这依赖于准确的负载预测。但现有方法难以应对冷启动、负载失真、多源数据碎片化和分布偏移等导致的小样本场景。

Method: 提出HyperLoad跨模态框架：1) 跨模态知识对齐阶段，将文本先验和时间序列数据映射到共同潜在空间；2) 多尺度特征建模阶段，通过自适应前缀调优注入领域对齐先验，并采用增强全局交互注意力机制捕捉跨设备时间依赖关系。

Result: 发布了公开的DCData数据集用于基准测试。在数据充足和数据稀缺两种设置下，HyperLoad均持续超越现有最先进基线方法，证明了其在可持续绿色数据中心管理中的实用性。

Conclusion: HyperLoad通过利用预训练大语言模型克服数据稀缺问题，为绿色数据中心的负载预测提供了有效的解决方案，有助于实现可持续的数据中心管理。

Abstract: The rapid growth of artificial intelligence is exponentially escalating computational demand, inflating data center energy use and carbon emissions, and spurring rapid deployment of green data centers to relieve resource and environmental stress. Achieving sub-minute orchestration of renewables, storage, and loads, while minimizing PUE and lifecycle carbon intensity, hinges on accurate load forecasting. However, existing methods struggle to address small-sample scenarios caused by cold start, load distortion, multi-source data fragmentation, and distribution shifts in green data centers. We introduce HyperLoad, a cross-modality framework that exploits pre-trained large language models (LLMs) to overcome data scarcity. In the Cross-Modality Knowledge Alignment phase, textual priors and time-series data are mapped to a common latent space, maximizing the utility of prior knowledge. In the Multi-Scale Feature Modeling phase, domain-aligned priors are injected through adaptive prefix-tuning, enabling rapid scenario adaptation, while an Enhanced Global Interaction Attention mechanism captures cross-device temporal dependencies. The public DCData dataset is released for benchmarking. Under both data sufficient and data scarce settings, HyperLoad consistently surpasses state-of-the-art (SOTA) baselines, demonstrating its practicality for sustainable green data center management.

</details>


### [153] [A Composable Channel-Adaptive Architecture for Seizure Classification](https://arxiv.org/abs/2512.19123)
*Francesco Carzaniga,Michael Hersche,Kaspar Schindler,Abbas Rahimi*

Main category: cs.LG

TL;DR: 提出了一种通道自适应架构，能够处理任意通道数的多变量时间序列数据，特别是颅内脑电图记录，通过个性化微调实现高效跨被试训练。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在处理多通道iEEG数据时的局限性：1）无法灵活适应不同被试的通道数量和配置差异；2）缺乏足够的临床相关时间上下文；3）跨被试训练时性能下降的问题。

Method: 采用通道自适应架构：首先用最先进模型独立处理每个单通道iEEG信号，然后通过向量符号算法融合特征（使用每个通道的可训练标量重建空间关系），最后将融合特征累积到长达2分钟的长时记忆中进行分类。模型可在大规模多被试iEEG数据上预训练，然后通过快速微调个性化到每个被试。

Result: 在癫痫检测任务中，CA-EEGWaveNet仅使用测试被试的单个癫痫发作进行训练，而基线EEGWaveNet使用除一个外的所有数据训练，CA-EEGWaveNet仍超越基线（中位F1分数0.78 vs 0.76）。CA-EEGNet也超越其基线（0.79 vs 0.74）。个性化微调所需数据量相当或更少，但时间仅为现有模型的1/5。

Conclusion: CA模型解决了两个关键问题：1）通道自适应性，可在跨异构被试训练时保持性能；2）将有效时间上下文扩展到临床相关长度。该模型可作为现有模型的直接替代品，带来更好的特性和整体性能提升。

Abstract: Objective: We develop a channel-adaptive (CA) architecture that seamlessly processes multi-variate time-series with an arbitrary number of channels, and in particular intracranial electroencephalography (iEEG) recordings. Methods: Our CA architecture first processes the iEEG signal using state-of-the-art models applied to each single channel independently. The resulting features are then fused using a vector-symbolic algorithm which reconstructs the spatial relationship using a trainable scalar per channel. Finally, the fused features are accumulated in a long-term memory of up to 2 minutes to perform the classification. Each CA-model can then be pre-trained on a large corpus of iEEG recordings from multiple heterogeneous subjects. The pre-trained model is personalized to each subject via a quick fine-tuning routine, which uses equal or lower amounts of data compared to existing state-of-the-art models, but requiring only 1/5 of the time. Results: We evaluate our CA-models on a seizure detection task both on a short-term (~20 hours) and a long-term (~2500 hours) dataset. In particular, our CA-EEGWaveNet is trained on a single seizure of the tested subject, while the baseline EEGWaveNet is trained on all but one. Even in this challenging scenario, our CA-EEGWaveNet surpasses the baseline in median F1-score (0.78 vs 0.76). Similarly, CA-EEGNet based on EEGNet, also surpasses its baseline in median F1-score (0.79 vs 0.74). Conclusion and significance: Our CA-model addresses two issues: first, it is channel-adaptive and can therefore be trained across heterogeneous subjects without loss of performance; second, it increases the effective temporal context size to a clinically-relevant length. Therefore, our model is a drop-in replacement for existing models, bringing better characteristics and performance across the board.

</details>


### [154] [A Convex Loss Function for Set Prediction with Optimal Trade-offs Between Size and Conditional Coverage](https://arxiv.org/abs/2512.19142)
*Francis Bach*

Main category: cs.LG

TL;DR: 提出基于Choquet积分的凸损失函数，用于集合预测中的不确定性估计，优化条件概率覆盖与集合"大小"之间的权衡


<details>
  <summary>Details</summary>
Motivation: 在监督学习中，集合预测能够提供明确的不确定性估计。现有方法通常关注边际覆盖，而本文旨在开发能够优化条件概率覆盖的方法，通过凸损失函数在覆盖率和集合大小之间实现更好的权衡。

Method: 使用Choquet积分（Lovász扩展）为通过实值函数水平集得到的非递减子集值函数提出凸损失函数。该方法允许在条件概率覆盖和由非递减子模函数度量的集合"大小"之间进行最优权衡。还提出了几个扩展，模拟具有不对称损失的二元分类的损失函数和标准，并展示如何自然地获得具有优化条件覆盖的集合。

Result: 推导了高效的优化算法，包括基于随机梯度下降或重加权最小二乘公式的方法。在合成数据集上的分类和回归任务实验表明，该方法优于旨在实现边际覆盖的方法。

Conclusion: 提出的基于Choquet积分的凸损失函数框架能够有效优化集合预测中的条件概率覆盖，在覆盖率和集合大小之间实现更好的权衡，为不确定性估计提供了新的理论和方法基础。

Abstract: We consider supervised learning problems in which set predictions provide explicit uncertainty estimates. Using Choquet integrals (a.k.a. Lov{á}sz extensions), we propose a convex loss function for nondecreasing subset-valued functions obtained as level sets of a real-valued function. This loss function allows optimal trade-offs between conditional probabilistic coverage and the ''size'' of the set, measured by a non-decreasing submodular function. We also propose several extensions that mimic loss functions and criteria for binary classification with asymmetric losses, and show how to naturally obtain sets with optimized conditional coverage. We derive efficient optimization algorithms, either based on stochastic gradient descent or reweighted least-squares formulations, and illustrate our findings with a series of experiments on synthetic datasets for classification and regression tasks, showing improvements over approaches that aim for marginal coverage.

</details>


### [155] [RP-CATE: Recurrent Perceptron-based Channel Attention Transformer Encoder for Industrial Hybrid Modeling](https://arxiv.org/abs/2512.19147)
*Haoran Yang,Yinan Zhang,Wenjie Zhang,Dongxia Wang,Peiyu Liu,Yuqi Ye,Kexin Chen,Wenhai Wang*

Main category: cs.LG

TL;DR: 本文提出RP-CATE模型，通过用通道注意力替代自注意力机制并加入循环感知器模块，解决了工业混合建模中机器学习架构单一和工业数据潜在关联利用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前工业混合建模方法存在两个主要局限：1) 主要使用单一机器学习方法处理特定任务，缺乏适合建模任务的综合机器学习架构；2) 工业数据中的潜在关联（如单调性或周期性）未被充分挖掘，影响模型预测性能。

Method: 提出RP-CATE模型，包含三个创新：1) 用通道注意力替代自注意力机制，并加入循环感知器模块；2) 提出适合通道注意力的伪图像数据类型及循环滑动窗口生成方法；3) 引入伪序列数据概念及工业数据转换方法，使循环感知器模块能更好捕捉数据关联。

Result: 在化学工程混合建模实验中，RP-CATE相比其他基线模型取得了最佳性能。

Conclusion: RP-CATE通过创新的架构设计和数据处理方法，有效解决了工业混合建模中的现有局限，提升了模型在复杂工业场景中的表现能力。

Abstract: Nowadays, industrial hybrid modeling which integrates both mechanistic modeling and machine learning-based modeling techniques has attracted increasing interest from scholars due to its high accuracy, low computational cost, and satisfactory interpretability. Nevertheless, the existing industrial hybrid modeling methods still face two main limitations. First, current research has mainly focused on applying a single machine learning method to one specific task, failing to develop a comprehensive machine learning architecture suitable for modeling tasks, which limits their ability to effectively represent complex industrial scenarios. Second, industrial datasets often contain underlying associations (e.g., monotonicity or periodicity) that are not adequately exploited by current research, which can degrade model's predictive performance. To address these limitations, this paper proposes the Recurrent Perceptron-based Channel Attention Transformer Encoder (RP-CATE), with three distinctive characteristics: 1: We developed a novel architecture by replacing the self-attention mechanism with channel attention and incorporating our proposed Recurrent Perceptron (RP) Module into Transformer, achieving enhanced effectiveness for industrial modeling tasks compared to the original Transformer. 2: We proposed a new data type called Pseudo-Image Data (PID) tailored for channel attention requirements and developed a cyclic sliding window method for generating PID. 3: We introduced the concept of Pseudo-Sequential Data (PSD) and a method for converting industrial datasets into PSD, which enables the RP Module to capture the underlying associations within industrial dataset more effectively. An experiment aimed at hybrid modeling in chemical engineering was conducted by using RP-CATE and the experimental results demonstrate that RP-CATE achieves the best performance compared to other baseline models.

</details>


### [156] [Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments](https://arxiv.org/abs/2512.19154)
*Geraud Nangue Tasse,Matthew Riemer,Benjamin Rosman,Tim Klinger*

Main category: cs.LG

TL;DR: 提出Adaptive Stacking元算法，通过自适应维护小型记忆栈来处理高度非马尔可夫依赖环境，相比传统帧堆叠方法显著降低计算和内存需求。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署计算受限智能体时面临高度非马尔可夫依赖的挑战。传统帧堆叠方法需要窗口大小随非马尔可夫依赖程度增长，导致计算和内存需求急剧增加。研究发现许多高度非马尔可夫环境中，环境实际上只因果依赖于相对较少的观测。

Method: 提出Adaptive Stacking元算法，维护相对较小的自适应记忆栈，能够表达时间上的高度非马尔可夫依赖，同时每个步骤考虑更少的观测。该方法具有收敛保证，并为MLP、LSTM和Transformer智能体量化了减少的计算和内存约束。

Result: 实验使用流行的记忆任务，通过控制非马尔可夫依赖程度，证明适当的元算法能够学习移除对未来奖励无预测性的记忆，同时不会过度移除重要经验。代码已开源。

Conclusion: Adaptive Stacking元算法能够有效处理高度非马尔可夫依赖环境，显著降低计算和内存需求，为在复杂现实世界部署计算受限智能体提供了实用解决方案。

Abstract: Recent success in developing increasingly general purpose agents based on sequence models has led to increased focus on the problem of deploying computationally limited agents within the vastly more complex real-world. A key challenge experienced in these more realistic domains is highly non-Markovian dependencies with respect to the agent's observations, which are less common in small controlled domains. The predominant approach for dealing with this in the literature is to stack together a window of the most recent observations (Frame Stacking), but this window size must grow with the degree of non-Markovian dependencies, which results in prohibitive computational and memory requirements for both action inference and learning. In this paper, we are motivated by the insight that in many environments that are highly non-Markovian with respect to time, the environment only causally depends on a relatively small number of observations over that time-scale. A natural direction would then be to consider meta-algorithms that maintain relatively small adaptive stacks of memories such that it is possible to express highly non-Markovian dependencies with respect to time while considering fewer observations at each step and thus experience substantial savings in both compute and memory requirements. Hence, we propose a meta-algorithm (Adaptive Stacking) for achieving exactly that with convergence guarantees and quantify the reduced computation and memory constraints for MLP, LSTM, and Transformer-based agents. Our experiments utilize popular memory tasks, which give us control over the degree of non-Markovian dependencies. This allows us to demonstrate that an appropriate meta-algorithm can learn the removal of memories not predictive of future rewards without excessive removal of important experiences. Code: https://github.com/geraudnt/adaptive-stacking

</details>


### [157] [Practical Quantum-Classical Feature Fusion for complex data Classification](https://arxiv.org/abs/2512.19180)
*Azadeh Alavi,Fatemeh Kouchmeshki,Abdolrahman Alavi*

Main category: cs.LG

TL;DR: 本文提出了一种量子-经典混合学习的跨注意力中间融合架构，通过注意力机制将量子特征与经典表示融合，在多个数据集上优于传统混合方法和纯量子模型。


<details>
  <summary>Details</summary>
Motivation: 当前量子-经典混合学习方法通常将量子电路作为孤立特征提取器，通过简单拼接方式与经典表示合并，忽略了量子与经典分支是不同的计算模态，限制了在复杂高维表格和半结构化数据上的可靠性能。

Method: 提出多模态混合学习框架，采用跨注意力中间融合架构：经典表示通过带有残差连接的注意力块查询量子特征标记。量子分支保持在实用NISQ预算内，最多使用9个量子比特。

Result: 在Wine、Breast Cancer、Forest CoverType、FashionMNIST和SteelPlatesFaults数据集上评估，纯量子模型和标准混合设计因测量引起的信息丢失而表现不佳，而跨注意力中间融合模型在大多数情况下在更复杂数据集上表现更优。

Conclusion: 量子衍生信息通过原则性的多模态融合（而非孤立使用或简单附加到经典特征）时最具价值，跨注意力中间融合架构为量子-经典混合学习提供了有效集成方案。

Abstract: Hybrid quantum and classical learning aims to couple quantum feature maps with the robustness of classical neural networks, yet most architectures treat the quantum circuit as an isolated feature extractor and merge its measurements with classical representations by direct concatenation. This neglects that the quantum and classical branches constitute distinct computational modalities and limits reliable performance on complex, high dimensional tabular and semi structured data, including remote sensing, environmental monitoring, and medical diagnostics. We present a multimodal formulation of hybrid learning and propose a cross attention mid fusion architecture in which a classical representation queries quantum derived feature tokens through an attention block with residual connectivity. The quantum branch is kept within practical NISQ budgets and uses up to nine qubits. We evaluate on Wine, Breast Cancer, Forest CoverType, FashionMNIST, and SteelPlatesFaults, comparing a quantum only model, a classical baseline, residual hybrid models, and the proposed mid fusion model under a consistent protocol. Pure quantum and standard hybrid designs underperform due to measurement induced information loss, while cross attention mid fusion is consistently competitive and improves performance on the more complex datasets in most cases. These findings suggest that quantum derived information becomes most valuable when integrated through principled multimodal fusion rather than used in isolation or loosely appended to classical features.

</details>


### [158] [MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning](https://arxiv.org/abs/2512.19206)
*Tao Zhang,Ziqian Zeng,Hao Peng,Huiping Zhuang,Cen Chen*

Main category: cs.LG

TL;DR: MixKVQ：一种轻量级、查询感知的KV缓存量化方法，通过识别关键通道并应用逐令牌量化，在复杂推理任务中实现接近全精度性能的低内存占用。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理显著提升了LLM能力，但伴随大量KV缓存带来的内存和延迟开销。现有低比特量化方法在复杂推理任务上性能下降严重，固定精度量化难以处理关键缓存中的异常通道，而混合精度策略无法准确识别需要高精度表示的组件。

Method: 提出MixKVQ方法，基于两个关键因素设计低比特KV缓存量化策略：关键通道的内在量化难度及其与查询的相关性。该方法引入轻量级、查询感知算法来识别和保留需要更高精度的关键通道，同时对值缓存应用逐令牌量化。

Result: 在复杂推理数据集上的实验表明，该方法显著优于现有低比特方法，在显著减少内存占用的同时，实现了与全精度基线相当的性能。

Conclusion: MixKVQ是一种即插即用的KV缓存量化方法，通过考虑关键通道的量化难度和查询相关性，有效解决了复杂推理任务中低比特量化的性能退化问题，为LLM推理提供了高效的内存优化方案。

Abstract: Long Chain-of-Thought (CoT) reasoning has significantly advanced the capabilities of Large Language Models (LLMs), but this progress is accompanied by substantial memory and latency overhead from the extensive Key-Value (KV) cache. Although KV cache quantization is a promising compression technique, existing low-bit quantization methods often exhibit severe performance degradation on complex reasoning tasks. Fixed-precision quantization struggles to handle outlier channels in the key cache, while current mixed-precision strategies fail to accurately identify components requiring high-precision representation. We find that an effective low-bit KV cache quantization strategy must consider two factors: a key channel's intrinsic quantization difficulty and its relevance to the query. Based on this insight, we propose MixKVQ, a novel plug-and-play method that introduces a lightweight, query-aware algorithm to identify and preserve critical key channels that need higher precision, while applying per-token quantization for value cache. Experiments on complex reasoning datasets demonstrate that our approach significantly outperforms existing low-bit methods, achieving performance comparable to a full-precision baseline at a substantially reduced memory footprint.

</details>


### [159] [Phase-space entropy at acquisition reflects downstream learnability](https://arxiv.org/abs/2512.19223)
*Xiu-Cheng Wang,Jun-Jie Zhanga,Nan Cheng,Long-Gang Pang,Taijiao Du,Deyu Meng*

Main category: cs.LG

TL;DR: 提出基于仪器分辨相空间的采集级标量ΔS_B，用于量化采集过程如何保留或破坏下游学习可用的信息，无需训练即可预测下游重建/识别难度


<details>
  <summary>Details</summary>
Motivation: 现代学习系统处理跨领域变化的数据，但都依赖于测量中已有的结构。需要一种通用的、模态无关的方法来量化采集过程本身如何保留或破坏下游学习可用的信息

Method: 提出基于仪器分辨相空间的采集级标量ΔS_B，直接量化采集如何在仪器尺度上混合或移除联合空间-频率结构。该方法不依赖像素级失真或纯频谱误差

Result: ΔS_B理论上正确识别周期性采样的相空间相干性作为混叠的物理来源，恢复经典采样定理结果。在掩码图像分类、加速MRI和大规模MIMO等应用中，|ΔS_B|能一致地排序采样几何并预测下游重建/识别难度，无需训练

Conclusion: 采集阶段的相空间熵反映了下游可学习性，能够在训练前选择候选采样策略，并作为跨模态信息保存的共享概念

Abstract: Modern learning systems work with data that vary widely across domains, but they all ultimately depend on how much structure is already present in the measurements before any model is trained. This raises a basic question: is there a general, modality-agnostic way to quantify how acquisition itself preserves or destroys the information that downstream learners could use? Here we propose an acquisition-level scalar $ΔS_{\mathcal B}$ based on instrument-resolved phase space. Unlike pixelwise distortion or purely spectral errors that often saturate under aggressive undersampling, $ΔS_{\mathcal B}$ directly quantifies how acquisition mixes or removes joint space--frequency structure at the instrument scale. We show theoretically that \(ΔS_{\mathcal B}\) correctly identifies the phase-space coherence of periodic sampling as the physical source of aliasing, recovering classical sampling-theorem consequences. Empirically, across masked image classification, accelerated MRI, and massive MIMO (including over-the-air measurements), $|ΔS_{\mathcal B}|$ consistently ranks sampling geometries and predicts downstream reconstruction/recognition difficulty \emph{without training}. In particular, minimizing $|ΔS_{\mathcal B}|$ enables zero-training selection of variable-density MRI mask parameters that matches designs tuned by conventional pre-reconstruction criteria. These results suggest that phase-space entropy at acquisition reflects downstream learnability, enabling pre-training selection of candidate sampling policies and as a shared notion of information preservation across modalities.

</details>


### [160] [Regression generation adversarial network based on dual data evaluation strategy for industrial application](https://arxiv.org/abs/2512.19232)
*Zesen Wang,Yonggang Li,Lijuan Lan*

Main category: cs.LG

TL;DR: 提出基于多任务学习的回归GAN框架，通过将回归信息集成到判别器和生成器中，并实现判别器与回归器的浅层共享机制，解决工业软测量中数据不足的问题，同时提升生成样本质量和算法效率。


<details>
  <summary>Details</summary>
Motivation: 在复杂工业场景中，软测量面临数据量不足的问题，降低了软测量的可靠性。传统GAN未能考虑标签与特征之间的映射关系，限制了性能提升。现有研究未能同时兼顾性能与效率。

Method: 提出多任务学习回归GAN框架：1) 将回归信息集成到判别器和生成器中；2) 实现判别器与回归器的浅层共享机制；3) 设计双重数据评估策略，考虑训练样本和生成样本的重要性，使GAN生成更多样化的样本。

Result: 该方法在四个经典工业软测量案例中得到验证：污水处理厂、地表水、CO₂吸收塔和工业燃气轮机。实验表明该方法显著提升了生成样本质量，同时提高了算法运行效率，增强了后续建模的泛化能力。

Conclusion: 提出的多任务学习回归GAN框架有效解决了工业软测量中数据不足的问题，通过集成回归信息和浅层共享机制，在提升生成样本质量的同时兼顾了算法效率，双重数据评估策略进一步增强了模型的泛化能力。

Abstract: Soft sensing infers hard-to-measure data through a large number of easily obtainable variables. However, in complex industrial scenarios, the issue of insufficient data volume persists, which diminishes the reliability of soft sensing. Generative Adversarial Networks (GAN) are one of the effective solutions for addressing insufficient samples. Nevertheless, traditional GAN fail to account for the mapping relationship between labels and features, which limits further performance improvement. Although some studies have proposed solutions, none have considered both performance and efficiency simultaneously. To address these problems, this paper proposes the multi-task learning-based regression GAN framework that integrates regression information into both the discriminator and generator, and implements a shallow sharing mechanism between the discriminator and regressor. This approach significantly enhances the quality of generated samples while improving the algorithm's operational efficiency. Moreover, considering the importance of training samples and generated samples, a dual data evaluation strategy is designed to make GAN generate more diverse samples, thereby increasing the generalization of subsequent modeling. The superiority of method is validated through four classic industrial soft sensing cases: wastewater treatment plants, surface water, $CO_2$ absorption towers, and industrial gas turbines.

</details>


### [161] [Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems](https://arxiv.org/abs/2512.19250)
*Prathamesh Devadiga*

Main category: cs.LG

TL;DR: 本文评估了小型语言模型（约10亿参数）在编译器自动并行化任务中的表现，在376次评估中平均获得6.81倍加速，卷积操作峰值达43.25倍，证明小型高效语言模型可作为复杂编译器优化任务的强大推理引擎。


<details>
  <summary>Details</summary>
Motivation: 传统基于启发式规则的自动并行化编译器难以应对现代异构系统的复杂性，需要更智能的优化方法。

Method: 使用三种小型语言模型（gemma3、llama3.2、qwen2.5），采用六种推理策略，在11个真实世界内核（来自科学计算、图算法和机器学习）上进行评估，并与LLVM Polly、TVM、Triton等编译器基准进行比较。

Result: 在376次总评估中，平均加速比为6.81倍，卷积操作峰值性能达43.25倍。通过多种消毒工具验证正确性，并在不同编译器和硬件平台上确认鲁棒性。

Conclusion: 小型高效的语言模型可以作为复杂编译器优化任务的强大推理引擎，为编译器自动并行化提供了新的有效途径。

Abstract: Traditional auto-parallelizing compilers, reliant on rigid heuristics, struggle with the complexity of modern heterogeneous systems. This paper presents a comprehensive evaluation of small (approximately 1B parameter) language-model-driven compiler auto-parallelization. We evaluate three models: gemma3, llama3.2, and qwen2.5, using six reasoning strategies across 11 real-world kernels drawn from scientific computing, graph algorithms, and machine learning. Our system is benchmarked against strong compiler baselines, including LLVM Polly, TVM, and Triton. Across 376 total evaluations, the proposed approach achieves an average speedup of 6.81x and a peak performance of 43.25x on convolution operations. We analyze scalability, verify correctness using multiple sanitizers, and confirm robustness across diverse compilers and hardware platforms. Our results demonstrate that small, efficient language models can serve as powerful reasoning engines for complex compiler optimization tasks.

</details>


### [162] [MAGIC: Achieving Superior Model Merging via Magnitude Calibration](https://arxiv.org/abs/2512.19320)
*Yayuan Li,Jian Zhang,Jintao Guo,Zihan Cheng,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.LG

TL;DR: 提出MAGIC框架，通过特征和权重空间中的幅度校准来解决模型合并中的幅度扰动问题，无需额外训练即可提升合并模型性能


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法主要关注特征方向对齐，忽视了幅度的重要性。幅度对常见的合并操作（如参数融合和稀疏化）引入的扰动非常敏感，这些扰动会导致合并模型与专业模型之间的特征偏差，从而造成性能下降。

Method: 提出MAGIC（MAGnItude Calibration）即插即用框架，包含三种变体：特征空间校准（FSC）使用少量无标签数据重新对齐合并模型的特征；权重空间校准（WSC）将校准扩展到权重空间，无需额外数据；双重空间校准（DSC）结合两者。

Result: 在计算机视觉任务上（8个数据集）平均提升4.3%，在NLP任务上（Llama模型）提升8.0%，且无需额外训练。

Conclusion: MAGIC框架通过校准特征和权重空间中的幅度，有效解决了模型合并中的幅度扰动问题，显著提升了合并模型的性能，证明了幅度校准在模型合并中的重要性。

Abstract: The proliferation of pre-trained models has given rise to a wide array of specialised, fine-tuned models. Model merging aims to merge the distinct capabilities of these specialised models into a unified model, requiring minimal or even no additional training. A core objective of model merging is to ensure the merged model retains the behavioural characteristics of the specialised models, typically achieved through feature alignment. We identify that features consist of two critical components: direction and magnitude. Prior research has predominantly focused on directional alignment, while the influence of magnitude remains largely neglected, despite its pronounced vulnerability to perturbations introduced by common merging operations (e.g., parameter fusion and sparsification). Such perturbations to magnitude inevitably lead to feature deviations in the merged model from the specialised models, resulting in subsequent performance degradation. To address this, we propose MAGnItude Calibration (MAGIC), a plug-and-play framework that rectifies layer-wise magnitudes in feature and weight spaces, with three variants. Specifically, our Feature Space Calibration (FSC) realigns the merged model's features using a small set of unlabelled data, while Weight Space Calibration (WSC) extends this calibration to the weight space without requiring additional data. Combining these yields Dual Space Calibration (DSC). Comprehensive experiments demonstrate that MAGIC consistently boosts performance across diverse Computer Vision tasks (+4.3% on eight datasets) and NLP tasks (+8.0% on Llama) without additional training. Our code is available at: https://github.com/lyymuwu/MAGIC

</details>


### [163] [Alternative positional encoding functions for neural transformers](https://arxiv.org/abs/2512.19323)
*Ezequiel Lopez-Rubio,Macoris Decena-Gimenez,Rafael Marcos Luque-Baena*

Main category: cs.LG

TL;DR: 本文提出了一种替代正弦函数的位置编码方法，在实验中显著优于原始正弦版本，有望在更多Transformer架构中应用。


<details>
  <summary>Details</summary>
Motivation: Transformer架构中的位置编码模块对于编码位置信息至关重要，当前主流使用不同频率的正弦函数来捕捉不同周期的重复模式，但可能存在改进空间。

Method: 提出了一组替代的周期函数用于位置编码，这些函数保留了正弦函数的关键特性，但在基本方式上有所区别。

Result: 实验结果显示，提出的替代函数版本在性能上显著优于原始的正弦函数版本。

Conclusion: 替代的位置编码函数可能具有更广泛的应用潜力，值得在更多Transformer架构中进行探索和验证。

Abstract: A key module in neural transformer-based deep architectures is positional encoding. This module enables a suitable way to encode positional information as input for transformer neural layers. This success has been rooted in the use of sinusoidal functions of various frequencies, in order to capture recurrent patterns of differing typical periods. In this work, an alternative set of periodic functions is proposed for positional encoding. These functions preserve some key properties of sinusoidal ones, while they depart from them in fundamental ways. Some tentative experiments are reported, where the original sinusoidal version is substantially outperformed. This strongly suggests that the alternative functions may have a wider use in other transformer architectures.

</details>


### [164] [Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation](https://arxiv.org/abs/2512.19361)
*Isshaan Singh,Divyansh Chawla,Anshu Garg,Shivin Mangal,Pallavi Gupta,Khushi Agarwal,Nimrat Singh Khalsa,Nandan Patel*

Main category: cs.LG

TL;DR: 提出一种结合LSTM和RNN的混合强化学习框架，用于物联网食品供应链中的实时腐败预测，通过规则分类器环境确保可解释性，在预测准确性和决策效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代物联网驱动的食品供应链中，易腐商品对环境条件高度敏感，需要智能实时腐败预测系统。现有方法缺乏对动态条件的适应性，且无法实时优化决策。

Method: 提出混合强化学习框架，集成LSTM和RNN来捕获传感器数据中的时间依赖性。采用基于规则的分类器环境，基于领域特定阈值提供透明的腐败水平标签，确保可解释性。使用腐败准确性、奖励-步数比、损失减少率和探索衰减等可解释性驱动指标监控模型行为。

Result: 在模拟和实时硬件数据上的广泛评估表明，基于LSTM和RNN的智能体在预测准确性和决策效率上优于其他强化学习方法，同时保持可解释性。通过类别腐败分布可视化分析智能体决策概况和政策行为。

Conclusion: 混合深度强化学习与集成可解释性在可扩展的物联网食品监控系统中具有潜力，能够实现稳健、自适应的实时腐败预测和决策优化。

Abstract: The need for an intelligent, real-time spoilage prediction system has become critical in modern IoT-driven food supply chains, where perishable goods are highly susceptible to environmental conditions. Existing methods often lack adaptability to dynamic conditions and fail to optimize decision making in real time. To address these challenges, we propose a hybrid reinforcement learning framework integrating Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) for enhanced spoilage prediction. This hybrid architecture captures temporal dependencies within sensor data, enabling robust and adaptive decision making. In alignment with interpretable artificial intelligence principles, a rule-based classifier environment is employed to provide transparent ground truth labeling of spoilage levels based on domain-specific thresholds. This structured design allows the agent to operate within clearly defined semantic boundaries, supporting traceable and interpretable decisions. Model behavior is monitored using interpretability-driven metrics, including spoilage accuracy, reward-to-step ratio, loss reduction rate, and exploration decay. These metrics provide both quantitative performance evaluation and insights into learning dynamics. A class-wise spoilage distribution visualization is used to analyze the agents decision profile and policy behavior. Extensive evaluations on simulated and real-time hardware data demonstrate that the LSTM and RNN based agent outperforms alternative reinforcement learning approaches in prediction accuracy and decision efficiency while maintaining interpretability. The results highlight the potential of hybrid deep reinforcement learning with integrated interpretability for scalable IoT-based food monitoring systems.

</details>


### [165] [OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation](https://arxiv.org/abs/2512.19379)
*Xueming Yan,Boyan Xu,Yaochu Jin,Lixian Xiao,Wenlong Ye,Runyang Cai,Zeqi Zheng,Jingfa Liu,Aimin Yang*

Main category: cs.LG

TL;DR: 提出了首个印尼语多模态情感识别基准数据集IndoMER和基于Qwen2.5-Omni的多模态适应框架OmniMER，通过三个辅助感知任务提升情感识别性能


<details>
  <summary>Details</summary>
Motivation: 印尼语作为东南亚社交媒体主要语言，拥有超过2亿使用者，但在多模态情感识别研究中服务不足，需要专门的数据集和方法来应对印尼文化背景下的实际挑战

Method: 构建IndoMER数据集（1,944个视频片段，7种情感类别），提出OmniMER框架，基于Qwen2.5-Omni模型，通过文本情感关键词提取、视频面部表情分析和音频韵律分析三个辅助感知任务增强多模态情感识别

Result: OmniMER在IndoMER数据集上情感分类Macro-F1达到0.582，情感识别达到0.454，分别比基准模型提升7.6和22.1个绝对百分点；在中文CH-SIMS数据集上的跨语言评估进一步证明了框架的泛化能力

Conclusion: IndoMER填补了印尼语多模态情感识别研究的空白，OmniMER框架通过辅助感知任务有效提升了多模态情感识别性能，特别是在跨模态不一致和长尾分布等现实挑战下表现优异

Abstract: Indonesian, spoken by over 200 million people, remains underserved in multimodal emotion recognition research despite its dominant presence on Southeast Asian social media platforms. We introduce IndoMER, the first multimodal emotion recognition benchmark for Indonesian, comprising 1,944 video segments from 203 speakers with temporally aligned text, audio, and visual annotations across seven emotion categories. The dataset exhibits realistic challenges including cross-modal inconsistency and long-tailed class distributions shaped by Indonesian cultural communication norms. To address these challenges, we propose OmniMER, a multimodal adaptation framework built upon Qwen2.5-Omni that enhances emotion recognition through three auxiliary modality-specific perception tasks: emotion keyword extraction for text, facial expression analysis for video, and prosody analysis for audio. These auxiliary tasks help the model identify emotion-relevant cues in each modality before fusion, reducing reliance on spurious correlations in low-resource settings. Experiments on IndoMER show that OmniMER achieves 0.582 Macro-F1 on sentiment classification and 0.454 on emotion recognition, outperforming the base model by 7.6 and 22.1 absolute points respectively. Cross-lingual evaluation on the Chinese CH-SIMS dataset further demonstrates the generalizability of the proposed framework. The dataset and code are publicly available. https://github.com/yanxm01/INDOMER

</details>


### [166] [From Points to Coalitions: Hierarchical Contrastive Shapley Values for Prioritizing Data Samples](https://arxiv.org/abs/2512.19363)
*Canran Xiao,Jiabao Dou,Zhiming Lin,Zong Ke,Liwei Hou*

Main category: cs.LG

TL;DR: HCDV提出了一种分层对比数据估值框架，通过几何保持表示学习、分层聚类和局部蒙特卡洛博弈，将数据估值的复杂度从O(n!)降低到O(TK_max log n)，显著提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统Data-Shapley方法在O(n!)复杂度和点状视角下，难以适应现代大规模、异构和几何结构化的数据集。需要一种既能保持几何结构又能高效计算的数据估值方法。

Method: HCDV采用三阶段框架：1) 学习对比几何保持表示；2) 构建平衡的粗到细分层聚类结构；3) 通过局部蒙特卡洛博弈分配Shapley式收益，预算向下传播。

Result: 在四个基准测试和OpenDataVal套件上，HCDV将准确率提升高达5个百分点，估值时间减少高达100倍，支持增强过滤、低延迟流更新和公平市场支付等任务。

Conclusion: HCDV通过分层结构和局部博弈有效解决了大规模数据估值问题，在保持Shapley公理近似性的同时大幅提升计算效率，为实际应用提供了可行解决方案。

Abstract: How should we quantify the value of each training example when datasets are large, heterogeneous, and geometrically structured? Classical Data-Shapley answers in principle, but its O(n!) complexity and point-wise perspective are ill-suited to modern scales. We propose Hierarchical Contrastive Data Valuation (HCDV), a three-stage framework that (i) learns a contrastive, geometry-preserving representation, (ii) organizes the data into a balanced coarse-to-fine hierarchy of clusters, and (iii) assigns Shapley-style payoffs to coalitions via local Monte-Carlo games whose budgets are propagated downward. HCDV collapses the factorial burden to O(T sum_{l} K_{l}) = O(T K_max log n), rewards examples that sharpen decision boundaries, and regularizes outliers through curvature-based smoothness. We prove that HCDV approximately satisfies the four Shapley axioms with surplus loss O(eta log n), enjoys sub-Gaussian coalition deviation tilde O(1/sqrt{T}), and incurs at most k epsilon_infty regret for top-k selection. Experiments on four benchmarks--tabular, vision, streaming, and a 45M-sample CTR task--plus the OpenDataVal suite show that HCDV lifts accuracy by up to +5 pp, slashes valuation time by up to 100x, and directly supports tasks such as augmentation filtering, low-latency streaming updates, and fair marketplace payouts.

</details>


### [167] [Research Program: Theory of Learning in Dynamical Systems](https://arxiv.org/abs/2512.19410)
*Elad Hazan,Shai Shalev Shwartz,Nathan Srebro*

Main category: cs.LG

TL;DR: 该论文提出了一个研究计划，通过下一个标记预测的视角来理解动态系统的可学习性，强调应从有限样本角度研究，并基于系统动态特性而非序列统计特性。


<details>
  <summary>Details</summary>
Motivation: 现代学习系统越来越多地与随时间演变且依赖于隐藏内部状态的数据交互。核心问题是：何时仅从观测数据就能学习这样的动态系统？需要建立动态系统可学习性的理论基础。

Method: 提出了动态可学习性的形式化框架，关注在有限燃烧期后每个时间步都保持一致的保证。通过动态系统诱导的随机过程来定义可学习性，强调系统结构特性（如稳定性、混合性、可观测性、谱特性）对所需观测数量的影响。

Result: 在线性动态系统案例中证明，无需系统辨识，通过基于谱滤波的不当方法，在有限观测后就能实现准确预测。建立了动态系统学习与经典PAC、在线和通用预测理论的关系。

Conclusion: 提出了一个研究动态系统可学习性的系统性框架，强调应从有限样本角度研究，并基于系统动态特性。该框架为研究非线性系统和受控系统提供了方向，将动态系统学习与经典学习理论联系起来。

Abstract: Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state. We ask a basic question: when is such a dynamical system learnable from observations alone? This paper proposes a research program for understanding learnability in dynamical systems through the lens of next-token prediction. We argue that learnability in dynamical systems should be studied as a finite-sample question, and be based on the properties of the underlying dynamics rather than the statistical properties of the resulting sequence. To this end, we give a formulation of learnability for stochastic processes induced by dynamical systems, focusing on guarantees that hold uniformly at every time step after a finite burn-in period. This leads to a notion of dynamic learnability which captures how the structure of a system, such as stability, mixing, observability, and spectral properties, governs the number of observations required before reliable prediction becomes possible. We illustrate the framework in the case of linear dynamical systems, showing that accurate prediction can be achieved after finite observation without system identification, by leveraging improper methods based on spectral filtering. We survey the relationship between learning in dynamical systems and classical PAC, online, and universal prediction theories, and suggest directions for studying nonlinear and controlled systems.

</details>


### [168] [Attention Is Not What You Need](https://arxiv.org/abs/2512.19428)
*Zhang Chong*

Main category: cs.LG

TL;DR: 该论文提出了一种基于格拉斯曼流（Grassmann flows）的无注意力架构，替代传统的自注意力机制，通过格拉斯曼流形上的子空间变形来传播信息，在语言建模和自然语言推理任务上取得了与Transformer相当的性能。


<details>
  <summary>Details</summary>
Motivation: 重新审视序列建模的基本问题：显式自注意力机制是否对高性能和推理能力真正必要？作者认为标准多头注意力本质上是一种张量提升形式，虽然表达能力极强但数学上不透明，难以用少量显式不变量描述模型。

Method: 提出基于格拉斯曼流的无注意力架构——因果格拉斯曼层：1) 线性降维token状态；2) 通过普吕克坐标将局部token对编码为格拉斯曼流形上的二维子空间；3) 通过门控混合将这些几何特征融合回隐藏状态。信息通过低秩子空间在多尺度局部窗口上的受控变形传播。

Result: 在Wikitext-2语言建模基准上，纯格拉斯曼模型（1300-1800万参数）的验证困惑度比同等规模Transformer高10-15%。在SNLI自然语言推理任务中，基于DistilBERT的格拉斯曼-普吕克头略优于Transformer头，最佳验证和测试准确率分别为0.8550/0.8538 vs 0.8545/0.8511。

Conclusion: 基于流形的设计为神经推理的几何和不变量解释提供了更结构化的途径，格拉斯曼混合具有线性序列长度复杂度，展示了无注意力架构在保持性能的同时提供更好数学可解释性的潜力。

Abstract: We revisit a basic question in sequence modeling: is explicit self-attention actually necessary for strong performance and reasoning? We argue that standard multi-head attention is best seen as a form of tensor lifting: hidden vectors are mapped into a high-dimensional space of pairwise interactions, and learning proceeds by constraining this lifted tensor through gradient descent. This mechanism is extremely expressive but mathematically opaque, because after many layers it becomes very hard to describe the model with a small family of explicit invariants.
  To explore an alternative, we propose an attention-free architecture based on Grassmann flows. Instead of forming an L by L attention matrix, our Causal Grassmann layer (i) linearly reduces token states, (ii) encodes local token pairs as two-dimensional subspaces on a Grassmann manifold via Plucker coordinates, and (iii) fuses these geometric features back into the hidden states through gated mixing. Information therefore propagates by controlled deformations of low-rank subspaces over multi-scale local windows, so the core computation lives on a finite-dimensional manifold rather than in an unstructured tensor space.
  On the Wikitext-2 language modeling benchmark, purely Grassmann-based models with 13 to 18 million parameters achieve validation perplexities within about 10 to 15 percent of size-matched Transformers. On the SNLI natural language inference task, a Grassmann-Plucker head on top of DistilBERT slightly outperforms a Transformer head, with best validation and test accuracies of 0.8550 and 0.8538 compared to 0.8545 and 0.8511. We analyze the complexity of Grassmann mixing, show linear scaling in sequence length for fixed rank, and argue that such manifold-based designs offer a more structured route toward geometric and invariant-based interpretations of neural reasoning.

</details>


### [169] [Real-Time Machine Learning for Embedded Anomaly Detection](https://arxiv.org/abs/2512.19383)
*Abdelmadjid Benmachiche,Khadija Rais,Hamda Slimi*

Main category: cs.LG

TL;DR: 本文综述了面向资源受限物联网边缘设备的轻量级异常检测机器学习方法，重点分析了在严格延迟、内存和功耗约束下的算法选择与实现权衡。


<details>
  <summary>Details</summary>
Motivation: 资源受限的物联网环境和嵌入式设备的普及，对边缘端的实时异常检测提出了迫切需求。需要在极严格的延迟、内存和功耗约束下实现有效的异常检测。

Method: 综述了多种轻量级机器学习算法，包括隔离森林、单类支持向量机、循环架构和统计技术等。根据嵌入式实现的实际情况对这些算法进行比较分析，并考虑硬件约束对算法选择的根本性影响。

Result: 揭示了异常检测准确性与计算效率之间的重要权衡关系，硬件约束从根本上重新定义了算法选择标准。提供了根据设备配置选择算法的实用建议，以及TinyML新趋势如何帮助缩小检测能力与嵌入式现实之间的差距。

Conclusion: 本文为在带宽受限且可能涉及安全关键应用的边缘环境中部署异常检测的工程师提供了战略路线图，帮助他们在资源约束下做出合理的算法选择决策。

Abstract: The spread of a resource-constrained Internet of Things (IoT) environment and embedded devices has put pressure on the real-time detection of anomalies occurring at the edge. This survey presents an overview of machine-learning methods aimed specifically at on-device anomaly detection with extremely strict constraints for latency, memory, and power consumption. Lightweight algorithms such as Isolation Forest, One-Class SVM, recurrent architectures, and statistical techniques are compared here according to the realities of embedded implementation. Our survey brings out significant trade-offs of accuracy and computational efficiency of detection, as well as how hardware constraints end up fundamentally redefining algorithm choice. The survey is completed with a set of practical recommendations on the choice of the algorithm depending on the equipment profiles and new trends in TinyML, which can help close the gap between detection capabilities and embedded reality. The paper serves as a strategic roadmap for engineers deploying anomaly detection in edge environments that are constrained by bandwidth and may be safety-critical.

</details>


### [170] [LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning](https://arxiv.org/abs/2512.19516)
*Xueming Yan,Bo Yin,Yaochu Jin*

Main category: cs.LG

TL;DR: 提出LacaDM模型，通过潜在因果扩散模型增强多目标强化学习在动态环境中的适应性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统多目标强化学习方法在目标冲突处理和动态环境适应方面存在局限，特别是在大规模复杂状态-动作空间中泛化能力不足

Method: 提出潜在因果扩散模型(LacaDM)，学习环境状态与策略之间的潜在时序因果关系，并将这些因果结构嵌入扩散模型框架中，实现跨多目标强化学习场景的知识迁移

Result: 在MOGymnasium框架的各种任务上，LacaDM在超体积、稀疏性和期望效用最大化等指标上均优于现有最优基线方法

Conclusion: LacaDM通过建模潜在因果结构，有效平衡了多目标冲突，在未见环境中保持了强大的泛化能力，为复杂多目标任务提供了有效的解决方案

Abstract: Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments. Traditional methods often struggle to generalize effectively, particularly in large and complex state-action spaces. To address these limitations, we introduce the Latent Causal Diffusion Model (LacaDM), a novel approach designed to enhance the adaptability of MORL in discrete and continuous environments. Unlike existing methods that primarily address conflicts between objectives, LacaDM learns latent temporal causal relationships between environmental states and policies, enabling efficient knowledge transfer across diverse MORL scenarios. By embedding these causal structures within a diffusion model-based framework, LacaDM achieves a balance between conflicting objectives while maintaining strong generalization capabilities in previously unseen environments. Empirical evaluations on various tasks from the MOGymnasium framework demonstrate that LacaDM consistently outperforms the state-of-art baselines in terms of hypervolume, sparsity, and expected utility maximization, showcasing its effectiveness in complex multiobjective tasks.

</details>


### [171] [CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal](https://arxiv.org/abs/2512.19554)
*Yongxin Wang,Zhicheng Yang,Meng Cao,Mingfei Han,Haokun Lin,Yingying Zhu,Xiaojun Chang,Xiaodan Liang*

Main category: cs.LG

TL;DR: CARE是一个专注于失败样本的后训练框架，通过对比锚定和反思引导重采样技术，将错误转化为监督信号，提升多模态推理模型的准确性和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的可验证奖励强化学习（RLVR）在处理失败样本时效率低下：当所有轨迹都错误时梯度停滞；当有一个正确时，更新通常忽略其他接近但错误的样本，且信用可能被错误分配给虚假链。需要一种能够有效利用失败样本的方法。

Method: CARE包含两个核心组件：1）锚定对比目标：围绕最佳轨迹形成紧凑子组和语义相近的困难负样本，进行组内z-score归一化并包含负样本缩放，以及全负样本救援机制防止零信号批次；2）反思引导重采样（RGR）：一次性结构化自我修复，重写代表性失败样本并用相同验证器重新评分，将接近正确的失败转化为可用正样本。

Result: 在Qwen2.5-VL-7B上，CARE在六个可验证视觉推理基准测试中将宏平均准确率比GRPO提升了4.6个百分点；在Qwen3-VL-8B上，在相同评估协议下，在MathVista和MMMU-Pro上达到竞争性或最先进的结果。

Conclusion: CARE通过将错误转化为监督信号，显著提高了多模态推理模型的性能，同时明确增加了来自失败样本的学习信号比例，改善了训练平滑度和准确性。

Abstract: Group-relative reinforcement learning with verifiable rewards (RLVR) often wastes the most informative data it already has the failures. When all rollouts are wrong, gradients stall; when one happens to be correct, the update usually ignores why the others are close-but-wrong, and credit can be misassigned to spurious chains. We present CARE (Contrastive Anchored REflection), a failure-centric post-training framework for multimodal reasoning that turns errors into supervision. CARE combines: (i) an anchored-contrastive objective that forms a compact subgroup around the best rollout and a set of semantically proximate hard negatives, performs within-subgroup z-score normalization with negative-only scaling, and includes an all-negative rescue to prevent zero-signal batches; and (ii) Reflection-Guided Resampling (RGR), a one-shot structured self-repair that rewrites a representative failure and re-scores it with the same verifier, converting near-misses into usable positives without any test-time reflection. CARE improves accuracy and training smoothness while explicitly increasing the share of learning signal that comes from failures. On Qwen2.5-VL-7B, CARE lifts macro-averaged accuracy by 4.6 points over GRPO across six verifiable visual-reasoning benchmarks; with Qwen3-VL-8B it reaches competitive or state-of-the-art results on MathVista and MMMU-Pro under an identical evaluation protocol.

</details>


### [172] [An Inverse Scattering Inspired Fourier Neural Operator for Time-Dependent PDE Learning](https://arxiv.org/abs/2512.19439)
*Rixin Yu*

Main category: cs.LG

TL;DR: IS-FNO是一种受逆散射变换启发的傅里叶神经算子，通过可逆神经变换和指数傅里叶层增强非线性PDE的长期稳定性和预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法（如FNO和Koopman扩展）在非线性偏微分方程的短期预测中表现良好，但在混沌、刚性和长期动力学系统中，由于无约束的潜在表示和累积误差，长期稳定性受限。

Method: 提出IS-FNO架构：1）通过显式可逆神经变换强制提升和投影映射之间的近可逆配对；2）使用指数傅里叶层建模潜在时间演化，自然编码线性和非线性谱动力学；3）对于可积系统，嵌入解析散射结构的简化变体。

Result: 在Michelson-Sivashinsky、Kuramoto-Sivashinsky（1D和2D）、KdV和KP方程等基准PDE上，IS-FNO相比基线FNO和Koopman模型实现了更低的短期误差和显著改善的长期稳定性。对于可积系统，嵌入散射结构的简化变体在有限模型容量下仍保持竞争力的长期精度。

Conclusion: 将物理结构（特别是可逆性和谱演化）融入神经算子设计，能显著增强非线性PDE动力学的鲁棒性和长期预测保真度。

Abstract: Learning accurate and stable time-advancement operators for nonlinear partial differential equations (PDEs) remains challenging, particularly for chaotic, stiff, and long-horizon dynamical systems. While neural operator methods such as the Fourier Neural Operator (FNO) and Koopman-inspired extensions achieve good short-term accuracy, their long-term stability is often limited by unconstrained latent representations and cumulative rollout errors. In this work, we introduce an inverse scattering inspired Fourier Neural Operator(IS-FNO), motivated by the reversibility and spectral evolution structure underlying the classical inverse scattering transform. The proposed architecture enforces a near-reversible pairing between lifting and projection maps through an explicitly invertible neural transformation, and models latent temporal evolution using exponential Fourier layers that naturally encode linear and nonlinear spectral dynamics. We systematically evaluate IS-FNO against baseline FNO and Koopman-based models on a range of benchmark PDEs, including the Michelson-Sivashinsky and Kuramoto-Sivashinsky equations (in one and two dimensions), as well as the integrable Korteweg-de Vries and Kadomtsev-Petviashvili equations. The results demonstrate that IS-FNO achieves lower short-term errors and substantially improved long-horizon stability in non-stiff regimes. For integrable systems, reduced IS-FNO variants that embed analytical scattering structure retain competitive long-term accuracy despite limited model capacity. Overall, this work shows that incorporating physical structure -- particularly reversibility and spectral evolution -- into neural operator design significantly enhances robustness and long-term predictive fidelity for nonlinear PDE dynamics.

</details>


### [173] [Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies](https://arxiv.org/abs/2512.19673)
*Yuqiao Tan,Minzheng Wang,Shizhu He,Huanxuan Liao,Chengfeng Zhao,Qiunan Lu,Tian Liang,Jun Zhao,Kang Liu*

Main category: cs.LG

TL;DR: 该论文提出了一种新的强化学习方法，通过分解大语言模型的内部策略来理解其推理机制，并基于此开发了自下而上的策略优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法将大语言模型视为单一统一策略，忽视了其内部机制。理解策略在不同层和模块间的演化对于实现更有针对性的优化和揭示复杂推理机制至关重要。

Method: 通过利用Transformer残差流的内在分割以及隐藏状态与解嵌入矩阵组合的等价性，将语言模型策略分解为内部层策略和内部模块策略。基于这些发现，提出了自下而上策略优化（BuPO），在早期训练中直接优化内部层策略。

Result: 研究发现：早期层保持高熵用于探索，顶层收敛到接近零熵用于精炼；不同模型系列收敛模式不同。Llama在最后一层快速收敛，而Qwen系列模型（特别是Qwen3）展现出更类似人类的渐进结构化推理模式。BuPO方法在复杂推理基准测试中表现出优越性能。

Conclusion: 通过分解大语言模型的内部策略，可以更好地理解其推理机制。提出的自下而上策略优化方法能够重建基础推理能力，在复杂推理任务中取得优异表现，为大语言模型的优化提供了新视角。

Abstract: Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.

</details>


### [174] [Toward Scalable and Valid Conditional Independence Testing with Spectral Representations](https://arxiv.org/abs/2512.19510)
*Alek Frohlich,Vladimir Kostic,Karim Lounici,Daniel Perazzo,Massimiliano Pontil*

Main category: cs.LG

TL;DR: 该论文提出了一种基于表示学习的条件独立性测试方法，通过偏协方差算子的奇异值分解学习表示，构建类似HSIC的测试统计量，并设计了双层对比学习算法。


<details>
  <summary>Details</summary>
Motivation: 条件独立性（CI）在因果推断、特征选择和图形建模中至关重要，但在许多设置中无法测试。现有CI测试方法依赖限制性结构条件，限制了其在真实数据上的有效性。基于偏协方差算子的核方法提供了更原则性的方法，但存在适应性有限、收敛慢和可扩展性差的问题。

Method: 1. 从偏协方差算子的奇异值分解中学习表示；2. 构建类似希尔伯特-施密特独立性准则（HSIC）的简单测试统计量；3. 引入实用的双层对比学习算法来学习这些表示。

Result: 理论分析将表示学习误差与测试性能联系起来，建立了渐近有效性和功效保证。初步实验表明，该方法为可扩展的CI测试提供了实用且统计基础良好的路径。

Conclusion: 该方法通过表示学习解决了传统CI测试方法的局限性，将基于核的理论与现代表示学习相结合，为可扩展的条件独立性测试提供了有前景的方向。

Abstract: Conditional independence (CI) is central to causal inference, feature selection, and graphical modeling, yet it is untestable in many settings without additional assumptions. Existing CI tests often rely on restrictive structural conditions, limiting their validity on real-world data. Kernel methods using the partial covariance operator offer a more principled approach but suffer from limited adaptivity, slow convergence, and poor scalability. In this work, we explore whether representation learning can help address these limitations. Specifically, we focus on representations derived from the singular value decomposition of the partial covariance operator and use them to construct a simple test statistic, reminiscent of the Hilbert-Schmidt Independence Criterion (HSIC). We also introduce a practical bi-level contrastive algorithm to learn these representations. Our theory links representation learning error to test performance and establishes asymptotic validity and power guarantees. Preliminary experiments suggest that this approach offers a practical and statistically grounded path toward scalable CI testing, bridging kernel-based theory with modern representation learning.

</details>


### [175] [DFORD: Directional Feedback based Online Ordinal Regression Learning](https://arxiv.org/abs/2512.19550)
*Naresh Manwani,M Elamparithy,Tanish Taneja*

Main category: cs.LG

TL;DR: 论文提出了一种在序数回归中使用方向反馈的在线学习算法，该算法通过探索-利用策略从弱监督的方向反馈中学习，并实现了对数级别的期望遗憾。


<details>
  <summary>Details</summary>
Motivation: 在序数回归中，传统的完全信息设置需要访问完整标签，但实际应用中可能只能获得方向性反馈（预测标签在真实标签的左侧还是右侧）。这种弱监督设置更贴近现实场景，需要开发能够有效利用此类反馈的学习算法。

Method: 提出了一种在线序数回归算法，使用探索-利用策略从方向反馈中学习。算法包括：1）基于方向反馈的在线学习框架；2）核化变体用于学习非线性模型；3）使用截断技巧提高核实现的内存效率；4）在期望意义上保持阈值排序。

Result: 算法实现了O(log T)的期望遗憾。在合成和真实数据集上的实验表明，使用方向反馈的方法与完全信息方法性能相当，有时甚至更好。

Conclusion: 方向反馈为序数回归提供了一种有效的弱监督学习范式，提出的在线算法能够高效利用此类反馈，在保持阈值排序的同时实现对数级别的遗憾，为实际应用中的序数回归问题提供了实用解决方案。

Abstract: In this paper, we introduce directional feedback in the ordinal regression setting, in which the learner receives feedback on whether the predicted label is on the left or the right side of the actual label. This is a weak supervision setting for ordinal regression compared to the full information setting, where the learner can access the labels. We propose an online algorithm for ordinal regression using directional feedback. The proposed algorithm uses an exploration-exploitation scheme to learn from directional feedback efficiently. Furthermore, we introduce its kernel-based variant to learn non-linear ordinal regression models in an online setting. We use a truncation trick to make the kernel implementation more memory efficient. The proposed algorithm maintains the ordering of the thresholds in the expected sense. Moreover, it achieves the expected regret of $\mathcal{O}(\log T)$. We compare our approach with a full information and a weakly supervised algorithm for ordinal regression on synthetic and real-world datasets. The proposed approach, which learns using directional feedback, performs comparably (sometimes better) to its full information counterpart.

</details>


### [176] [KerJEPA: Kernel Discrepancies for Euclidean Self-Supervised Learning](https://arxiv.org/abs/2512.19605)
*Eric Zimmermann,Harley Wiltzer,Justin Szeto,David Alvarez-Melis,Lester Mackey*

Main category: cs.LG

TL;DR: 提出KerJEPA家族，使用核基正则化器改进自监督学习，相比现有JEPA方法具有更好的训练稳定性和设计灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有JEPA方法使用欧几里得表示向各向同性高斯先验的正则化，虽然能提高训练稳定性和下游泛化能力，但正则化方法有限。需要更灵活的正则化方法来进一步提升性能。

Method: 引入KerJEPA家族，使用核基正则化器。扩展了可行的核函数和先验分布，计算了切片最大均值差异（MMD）的高维闭式极限，开发了具有改进训练稳定性和设计灵活性的替代KerJEPA算法。

Result: 开发了具有多种有利特性的替代KerJEPA算法，包括改进的训练稳定性和设计灵活性。其中一个实例对应最近提出的LeJEPA Epps-Pulley正则化器，该正则化器使用高斯先验和高斯核近似切片MMD。

Conclusion: KerJEPA家族通过核基正则化器扩展了自监督学习的正则化方法，提供了比传统JEPA方法更灵活的设计空间和更好的训练稳定性。

Abstract: Recent breakthroughs in self-supervised Joint-Embedding Predictive Architectures (JEPAs) have established that regularizing Euclidean representations toward isotropic Gaussian priors yields provable gains in training stability and downstream generalization. We introduce a new, flexible family of KerJEPAs, self-supervised learning algorithms with kernel-based regularizers. One instance of this family corresponds to the recently-introduced LeJEPA Epps-Pulley regularizer which approximates a sliced maximum mean discrepancy (MMD) with a Gaussian prior and Gaussian kernel. By expanding the class of viable kernels and priors and computing the closed-form high-dimensional limit of sliced MMDs, we develop alternative KerJEPAs with a number of favorable properties including improved training stability and design flexibility.

</details>


### [177] [The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference](https://arxiv.org/abs/2512.19643)
*Rajyasri Roy,Dibyajyoti Nayak,Somdatta Goswami*

Main category: cs.LG

TL;DR: ANCHOR提出了一种自适应混合推理框架，通过结合预训练神经算子和经典数值求解器，使用基于物理的残差误差估计器来监测和控制长期预测中的误差累积，实现稳定、高效的非线性时变PDE求解。


<details>
  <summary>Details</summary>
Motivation: 神经算子（NO）虽然能快速推理参数化和函数输入，但自回归框架容易产生误差累积问题，且现有方法缺乏在线监测和校正机制，导致超出训练范围时误差可能变得不可接受。

Method: ANCHOR将预训练神经算子作为主要推理引擎，通过基于物理的残差误差估计器（使用指数移动平均EMA监测归一化PDE残差）自适应地将其与经典数值求解器耦合，在检测到误差累积时触发校正求解器干预。

Result: 在四个典型PDE（1D和2D Burgers'、2D Allen-Cahn、3D热传导）上的评估表明，ANCHOR能可靠地限制长期误差增长，稳定外推推演，显著提高相对于独立神经算子的鲁棒性，同时比高保真数值求解器效率更高。

Conclusion: ANCHOR提供了一种在线、实例感知的混合推理框架，通过自适应校正机制有效解决了神经算子在长期预测中的误差累积问题，实现了稳定且高效的时变PDE求解。

Abstract: Numerical simulation of time-dependent partial differential equations (PDEs) is central to scientific and engineering applications, but high-fidelity solvers are often prohibitively expensive for long-horizon or time-critical settings. Neural operator (NO) surrogates offer fast inference across parametric and functional inputs; however, most autoregressive NO frameworks remain vulnerable to compounding errors, and ensemble-averaged metrics provide limited guarantees for individual inference trajectories. In practice, error accumulation can become unacceptable beyond the training horizon, and existing methods lack mechanisms for online monitoring or correction. To address this gap, we propose ANCHOR (Adaptive Numerical Correction for High-fidelity Operator Rollouts), an online, instance-aware hybrid inference framework for stable long-horizon prediction of nonlinear, time-dependent PDEs. ANCHOR treats a pretrained NO as the primary inference engine and adaptively couples it with a classical numerical solver using a physics-informed, residual-based error estimator. Inspired by adaptive time-stepping in numerical analysis, ANCHOR monitors an exponential moving average (EMA) of the normalized PDE residual to detect accumulating error and trigger corrective solver interventions without requiring access to ground-truth solutions. We show that the EMA-based estimator correlates strongly with the true relative L2 error, enabling data-free, instance-aware error control during inference. Evaluations on four canonical PDEs: 1D and 2D Burgers', 2D Allen-Cahn, and 3D heat conduction, demonstrate that ANCHOR reliably bounds long-horizon error growth, stabilizes extrapolative rollouts, and significantly improves robustness over standalone neural operators, while remaining substantially more efficient than high-fidelity numerical solvers.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [178] [Non-Abelian topological superconductivity from melting Abelian fractional Chern insulators](https://arxiv.org/abs/2512.17996)
*Zhengyan Darius Shi,T. Senthil*

Main category: cond-mat.str-el

TL;DR: 分数陈绝缘体在带宽增加时可直接转变为电荷2e超导体，而非传统费米液体。本文提出了一个理论框架，揭示了超导与分数化在晶格系统中的交织关系。


<details>
  <summary>Details</summary>
Motivation: 近期数值研究发现，在分数陈绝缘体中增加带宽可以直接驱动向电荷2e超导体的转变，而不是传统的费米液体。这一令人惊讶的观察结果促使研究者提出一个理论框架来理解晶格系统中超导与分数化的交织关系。

Method: 利用Jain拓扑序的三种场论描述之间的对偶性，构建了一个理论框架来分析带宽调谐对分数陈绝缘体的影响。该方法能够捕捉晶格系统中超导与分数化的交织关系。

Result: 研究发现，在ν=2/3填充下，单个母体分数陈绝缘体可以通过带宽调谐转变为五种不同的超导体，其中一些是本质非阿贝尔的并支持马约拉纳零模。研究还预测了在更一般的填充分数ν=p/(2p+1)下，存在新型高电荷超导体与中性非阿贝尔拓扑序共存的现象。

Conclusion: 研究揭示了一个丰富的奇异超导体景观，这些超导体没有正常态费米面，并预测了在更一般填充分数下存在新型高电荷超导体与中性非阿贝尔拓扑序的共存。这为理解超导与分数化的交织关系提供了新的理论框架。

Abstract: Fractional Chern insulators (FCI) are exotic phases of matter realized at partial filling of a Chern band that host fractionally charged anyon excitations. Recent numerical studies in several microscopic models reveal that increasing the bandwidth in an FCI can drive a direct transition into a charge-2e superconductor rather than a conventional Fermi liquid. Motivated by this surprising observation, we propose a theoretical framework that captures the intertwinement between superconductivity and fractionalization in a lattice setting. Leveraging the duality between three field-theoretic descriptions of the Jain topological order, we find that bandwidth tuning can drive a single parent FCI at $ν= 2/3$ into five different superconductors, some of which are intrinsically non-Abelian and support Majorana zero modes. Our results reveal a rich landscape of exotic superconductors with no normal state Fermi surface and predict novel higher-charge superconductors coexisting with neutral non-Abelian topological order at more general filling fractions $ν= p/(2p+1)$.

</details>


### [179] [Electronic Phonons in a Moiré Electron Crystal](https://arxiv.org/abs/2512.18217)
*Yan Zhao,Yuhang Hou,Xiangbin Cai,Shihao Ru,Shunshun Yang,Yan Zhang,Xuran Dai,Qiuyu Shang,Abdullah Rasmita,Haiyang Pan,Kenji Watanabe,Takashi Taniguchi,Hongbin Cai,Hongyi Yu,Weibo Gao*

Main category: cond-mat.str-el

TL;DR: 在WS2/WSe2莫尔超晶格中首次观测到电子声子，这是由电子晶体集体振动产生的集体激发，为相关电子系统的电子晶体性质提供了直接光谱证据。


<details>
  <summary>Details</summary>
Motivation: 探索强关联系统中的集体量子现象，特别是电子晶体中由电子关联产生的集体振动激发（电子声子）。尽管理论上预测了莫尔电子晶体中电子声子的存在，但直接实验证据一直缺乏。

Method: 通过光散射测量在WS2/WSe2莫尔超晶格的莫特绝缘体和条纹相中观测电子声子。结合理论建模分析声子能量、温度、填充因子依赖性，并通过偏振分辨测量研究对称性破缺。

Result: 首次直接观测到电子声子，其能量、强度和偏振在外加电场或磁场下表现出强可调性。实验数据与理论模型一致，证实了这些声子起源于相关电子晶体的集体振动。

Conclusion: 该研究为相关相的电子晶体性质提供了直接光谱证据，揭示了电子晶体丰富的可控晶格动力学，为探测和操控相关电子系统中的集体激发开辟了新途径。

Abstract: Collective quantum phenomena, such as the excitation of composite fermions1, spin waves2, and exciton condensation3,4, can emerge in strongly correlated systems like the fractional quantum Hall states5, spin liquids6, or excitonic insulators7. Two-dimensional (2D) moiré superlattices have emerged as a powerful platform for exploring such correlated phases and their associated collective excitations8,9. Specifically, electron crystals stabilized by longrange Coulomb interactions may host collective vibrational excitations emerging from electron correlations10, termed electronic phonons, which are fundamentally distinct from atomic lattice phonons. Despite theoretical prediction of their existence in moiré electron crystals11, direct experimental evidence has remained elusive. Here we report the observation of electronic phonons in the Mott insulating and stripe phases of a WS2/WSe2 moiré superlattice, achieved through light scattering measurements. The phonon energies, temperature and filling factor dependencies, along with theoretical modeling, corroborate their origin as collective vibrations of a correlated electron crystal. Polarization-resolved measurements further indicate rotational symmetry breaking in the Mott state. Notably, these electronic phonons exhibit strong tunability in energy, intensity, and polarization under external electric or magnetic fields, highlighting rich and controllable lattice dynamics of the electron crystal. These findings provide direct spectroscopic evidence for the electronic crystalline nature of correlated phases, opening avenues for probing and manipulating collective excitations in correlated electron systems.

</details>


### [180] [Topological edge states in two-dimensional $\mathbb{Z}_4$ Potts paramagnet protected by the $\mathbb{Z}_4^{\times 3}$ symmetry](https://arxiv.org/abs/2512.18460)
*Hrant Topchyan,Tigran Hakobyan,Mkhitar Mirumyan,Tigran A. Sedrakyan,Ara Sedrakyan*

Main category: cond-mat.str-el

TL;DR: 该论文构建了一个受Z4×3对称性保护的二维玻色SPT顺磁体，通过非局域幺正变换得到哈密顿量，边界理论显示为具有c=11/5的共形场论。


<details>
  <summary>Details</summary>
Motivation: 研究受Z4×3对称性保护的二维玻色对称性保护拓扑相，探索其边界理论的性质和可能的共形场论描述。

Method: 从三角晶格上的三组分Z4 Potts顺磁体出发，利用群上同调框架，通过反称化基本Z4三上闭链得到"无色"上闭链代表元，再通过上闭链诱导的非局域幺正变换和对称性平均生成SPT哈密顿量。

Result: 边界理论简化为具有次近邻约束的相互作用Z4链，DMRG计算显示边界是无能隙的，最低能隙按1/L标度，纠缠熵标度符合中心荷c=2.191(4)≈11/5的共形场论。

Conclusion: Z4×3 SPT相的边界可能由中心荷c=11/5的共形场论描述，对应coset SU(3)_3/SU(2)_3，需要进一步的光谱和对称性分辨诊断来验证这一识别。

Abstract: We construct a two-dimensional bosonic symmetry-protected topological (SPT) paramagnet protected by an on-site $G=\mathbb{Z}_4^{\times 3}$ symmetry, starting from a three-component $\mathbb{Z}_4$ Potts paramagnet on a triangular lattice. Within the group-cohomology framework, $H^{3}(G,U(1))\cong \mathbb{Z}_4^{\times 7}$, we focus on a "colorless" cocycle representative obtained by antisymmetrizing the basic $\mathbb{Z}_4$ three-cocycle, and generate the corresponding SPT Hamiltonian via a cocycle-induced nonlocal unitary transformation followed by symmetry averaging. For open geometry, we derive the boundary theory explicitly: one color sector decouples, while the nontrivial edge reduces to an interacting $\mathbb{Z}_4$ chain with next-to-nearest-neighbor constraints that admits a compact dressed-Potts form. Using DMRG we show that the boundary model is gapless, with the lowest gap scaling as $1/L$ and an entanglement-entropy scaling consistent with a conformal field theory of central charge $c=2.191(4)\simeq 11/5$. The rational value $c=11/5$ matches the coset $SU(3)_3/SU(2)_3$, making it a candidate for the continuum description of the $\mathbb{Z}_4^{\times 3}$ edge; we outline spectral and symmetry-resolved diagnostics needed to test this identification at the level of conformal towers beyond the central charge.

</details>


### [181] [Evolution of charge-density-wave soft phonon modes in $\mathrm{Pd}_x\mathrm{ErTe}_3$](https://arxiv.org/abs/2512.18472)
*Avishek Maity,Stephan Rosenkranz,Raymond Osborn,Rolf Heid,Ayman H. Said,Ahmet Alatas,Joshua A. W. Straquadine,Matthew J. Krogstad,Anisha G. Singh,Ian R. Fisher,Frank Weber*

Main category: cond-mat.str-el

TL;DR: 通过X射线散射研究Pd插层ErTe₃的晶格动力学，发现a轴CDW在x≥0.02时被完全抑制，但残余的漫散射源于与c-CDW相关的部分声子软化，揭示了正交晶格中两个近等效轴之间的强竞争关系。


<details>
  <summary>Details</summary>
Motivation: 研究准二维Pd插层ErTe₃的晶格动力学与电荷密度波（CDW）转变的关系，探索不同插层浓度下CDW序的竞争机制和抑制效应。

Method: 使用X射线漫散射和meV分辨率的非弹性X射线散射技术，分析不同Pd插层浓度（x=0.01, x≥0.02, x=0.023）的ErTe₃样品，测量声子软化和散射模式。

Result: 1. 在原始ErTe₃中观察到a-CDW的漫散射，但波矢略有不同（q₁ᵃ=0.29,0,0）；2. Pd₀.₀₁ErTe₃在q₁ᵃ处出现部分声子软化；3. 当x≥0.02时，a-CDW态被完全抑制；4. 残余漫散射源于与c-CDW相关的部分声子软化；5. 高插层样品中声子软化不完全，可能与CDW布拉格玻璃态相关。

Conclusion: a-CDW在x≥0.02时被完全抑制，残余的漫散射并非来自a-CDW，而是源于与c-CDW相关的部分声子软化，这反映了正交晶格中两个近等效轴之间的强竞争关系，高插层样品中的不完全软化可能与CDW布拉格玻璃态有关。

Abstract: We investigated the lattice dynamics of quasi-two-dimensional Pd-intercalated $\mathrm{ErTe}_3$ in relation to its charge-density-wave (CDW) transitions by means of x-ray diffuse and meV-resolution inelastic x-ray scattering. In pristine $\mathrm{ErTe}_3$, CDW order develops at orthogonal in-plane wave vectors $\boldsymbol{\mathrm{q}}_{1}^{c} = (0, 0, 0.29)$ (the $c\text{-}\mathrm{CDW}$) and $\boldsymbol{\mathrm{q}}_{2}^{a} = (0.31, 0, 0)$ (the $a\text{-}\mathrm{CDW}$), with transition temperatures $T_{1}^{c} = 270$~K and $T_{2}^{a} = 160$~K, respectively. Remarkably, we observe diffuse x-ray scattering already near the higher transition temperature $T_{1}^{c}$ along $a\text{-}\mathrm{CDW}$ but at a slightly different wave vector $\boldsymbol{\mathrm{q}}_{1}^{a} = (0.29, 0, 0)$. Inelastic x-ray scattering for $\mathrm{Pd}_{0.01}\mathrm{ErTe}_3$ shows that a partial phonon softening at $\boldsymbol{\mathrm{q}}_{1}^{a}$, underscoring the strong competition between ordering tendencies along the nearly equivalent in-plane axes of the orthorhombic lattice. For intercalation levels $x \geq 0.02$, the $a\text{-}\mathrm{CDW}$ state is suppressed. Nevertheless, a similar correlation between phonon softening and diffuse scattering persists along the $[100]$ direction, again observed at $\boldsymbol{\mathrm{q}}_{1}^{a} = (0.29, 0, 0)$ and $T_{1}^{c}$. These findings confirm that the $a\text{-}\mathrm{CDW}$ is fully suppressed for $x \geq 0.02$, and that the residual diffuse scattering at $\boldsymbol{\mathrm{q}}_{1}^{a}$ originates from the partial phonon softening associated with the $c\text{-}\mathrm{CDW}$, reflected by the near equality of the absolute size of $\boldsymbol{\mathrm{q}}_{1}^{c}$ and $\boldsymbol{\mathrm{q}}_{1}^{a}$. In highly intercalated $\mathrm{Pd}_{0.023}\mathrm{ErTe}_3$, the phonon softening remains incomplete, possibly linked to the recently reported CDW Bragg glass state.

</details>


### [182] [Comment on: "The future of the correlated electron problem", arXiv:2010.00584](https://arxiv.org/abs/2512.18509)
*V. R. Shaginyan,A. Z. Msezane*

Main category: cond-mat.str-el

TL;DR: 作者指出某些极难问题已被成功解决，强调应关注已解决的问题而非误导潜在研究者


<details>
  <summary>Details</summary>
Motivation: 作者希望澄清研究现状，避免潜在研究者被误导，鼓励关注已取得的进展而非过度强调困难

Method: 通过评论形式指出已有成功解决方案，强调应聚焦已解决的问题而非未解决的难题

Result: 明确指出某些极难问题已被成功解决，纠正了对该领域研究难度的误解

Conclusion: 研究领域已有显著进展，应关注已解决的问题以激励更多研究者参与，避免误导潜在研究者

Abstract: In our comment we show that some of the very difficult problems have been successfully solved. We have to focus on the resolved problems, since the authors claims: Our hope, however, is that the topics we have presented will provide inspiration for others working in this field and motivation for the idea that significant progress can be made on very hard problems if we focus our collective energies. Thus, there is no need to mislead potential researchers.

</details>


### [183] [Global approximations to correlation functions of strongly interacting quantum field theories](https://arxiv.org/abs/2512.18532)
*Yuanran Zhu,Yang Yu,Efekan Kökcü,Emanuel Gull,Chao Yang*

Main category: cond-mat.str-el

TL;DR: 提出一种基于插值方法（如两点Padé展开）从微扰结果构建强相互作用量子场论关联函数全局近似的方法，并在φ⁴理论和2D Hubbard模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 强相互作用量子场论中关联函数的精确计算非常困难，微扰理论仅在弱耦合区域有效，而强耦合区域缺乏可靠的计算方法。需要一种能够连接弱耦合和强耦合展开的全局近似方法。

Method: 使用插值方法（特别是两点Padé展开）来插值关联函数的弱耦合和强耦合展开。该方法从微扰结果出发，通过构建有理函数近似来全局逼近关联函数。

Result: 在φ⁴理论中，两点Padé近似表现出对精确关联函数的一致全局收敛性；在2D Hubbard模型中，即使二阶Padé近似也能在广泛参数范围内合理描述松原格林函数。

Conclusion: 基于解析函数理论的插值方法能够有效构建强相互作用量子场论关联函数的全局近似，为连接弱耦合和强耦合区域提供了有前景的计算工具。

Abstract: We introduce a method for constructing global approximations to correlation functions of strongly interacting quantum field theories, starting from perturbative results. The key idea is to employ interpolation method, such as the two-point Padé expansion, to interpolate the weak and strong coupling expansions of correlation function. We benchmark this many-body interpolation approach on two prototypical models: the lattice $φ^4$ field theory and the 2D Hubbard model. For the $φ^4$ theory, the resulting two point Padé approximants exhibit uniform and global convergence to the exact correlation function. For the Hubbard model, we show that even at second order, the Padé appproximant already provides reasonable characterization of the Matsubara Green's function for a wide range of parameters. Finally, we offer a heuristic explanation for these convergence properties based on analytic function theory.

</details>


### [184] [Spiral states, first-order transitions and specific heat multipeak phenomenon in $J_1$-$J_2$-$J_3$ model: A Wang-Landau algorithm study](https://arxiv.org/abs/2512.18724)
*Habib Ullah,Kun Li,Haoyu Lu,Youjin Deng,Wanzhou Zhang*

Main category: cond-mat.str-el

TL;DR: 本文通过Wang-Landau算法重新研究经典J1-J2-J3蜂窝晶格伊辛模型，发现之前报道的扶手椅相实际上与螺旋相共存，总简并度达20重，并观察到一阶相变、连续相变及多峰现象等复杂相行为。


<details>
  <summary>Details</summary>
Motivation: 传统平均场方法在研究蜂窝晶格J1-J2-J3伊辛模型时存在局限性，无法准确解释FePS3和Ba2CoTeO6等材料中观察到的条纹相、之字形相、扶手椅相和磁化平台等复杂现象，需要更可靠的数值方法进行系统研究。

Method: 使用Wang-Landau算法对经典J1-J2-J3蜂窝晶格伊辛模型进行系统研究，分析不同相互作用参数下的相变行为和临界指数。

Result: 发现之前报道的扶手椅相实际上与螺旋相共存，总简并度达20重（扶手椅相4重+螺旋相16重）。观察到一阶相变、连续相变以及多峰现象（类似Schottky的比热异常）。确定了相变临界指数。

Conclusion: 研究澄清了受挫伊辛系统中相和相变的本质，为实验寻找螺旋态和Schottky-like异常提供了理论指导，揭示了平均场方法未能捕捉到的复杂相共存现象。

Abstract: The classical $J_1$-$J_2$-$J_3$ Ising model on the honeycomb lattice is important for understanding frustrated magnetic phenomena in materials such as $FePS_3$ and $Ba_2CoTeO_6$, where diverse phases (e.g., striped, zigzag, armchair) and magnetization plateaus have been experimentally observed. To explain the experimental results, previous mean-field studies have explored its thermal phase transitions, identifying armchair phases and striped phases, but their limitations call for more reliable numerical investigations. In this work, we systematically revisit the classical $J_1$-$J_2$-$J_3$ Ising model using the Wang-Landau algorithm. We find that the armchair (AC) phase, previously reported in mean-field and experimental studies, actually coexists with the spiral (SP) phase, with their combined degeneracy reaching 20-fold (4-fold for the AC states and 16-fold for the spiral states). The phase transitions and critical exponents are studied at different interaction values. We observe first-order phase transitions, continuous phase transitions, and even the multipeak phenomenon, i.e., Schottky-like specific-heat anomalies in frustrated systems. These results clarify the nature of phases and phase transitions in frustrated Ising systems and their exponents, and additionally provide inspiration for experimental efforts to search for the spiral state and Schottky-like anomalies.

</details>


### [185] [A Systematic Convergent Sequence of Approximations (of Integral Equation Form) to the Solutions of the Hedin Equations](https://arxiv.org/abs/2512.18782)
*Garry Goldstein*

Main category: cond-mat.str-el

TL;DR: 本文提出了一系列系统化的积分方程（Hedin近似I、II、III、IV等），这些方程没有泛函导数，其解收敛于精确Hedin方程的解，适用于迭代数值求解，其中Hedin近似I就是GW近似。


<details>
  <summary>Details</summary>
Motivation: Hedin方程虽然理论上能精确求解多体问题，但由于其泛函导数形式，在实际系统中几乎无法数值求解。积分方程比泛函导数方程更易于数值处理，通常可以通过迭代求解。

Method: 提出了一系列系统化的积分方程（Hedin近似I、II、III、IV等），这些方程没有泛函导数，其解收敛于精确Hedin方程的解。这些近似方法特别适合迭代数值求解。在零维场论中对Hedin方程进行了系统研究，这种方法特别适用于枚举任意维度场论的费曼图。

Result: 研究表明，随着Hedin近似阶数的提高（I、II、III），解越来越接近精确Hedin方程的解。高阶Hedin近似能捕获更多自能费曼图，其中Hedin近似II已经比当前最先进的图解顶点修正方法捕获更多图，而Hedin近似III在零维情况下几乎完美匹配精确Hedin方程的解，并枚举了大量费曼图。

Conclusion: 提出的Hedin近似系列提供了一种系统改进GW近似的方法，通过逐步提高近似阶数，可以越来越精确地逼近Hedin方程的解，同时保持数值可处理性，为多体问题的实际计算提供了有前景的途径。

Abstract: In many ways the solution to the Hedin equations represents an exact solution to the many body problem. However, for most systems of practical interest, the solution to the Hedin equations is rendered nearly numerically intractable because the Hedin equations are of functional derivative form. Integral equations are much more numerically tractable, than functional derivative equations, as they can often be solved iteratively. In this work we present a systematic set of integral equations (with no functional derivatives) - Hedin approximations I, II, III, IV etc. - whose solutions converge to the solutions of the exact Hedin equations. The Hedin approximations are well suited to iterative numerical solutions (which we also describe). Furthermore Hedin approximation I is just the GW approximation (as such this work may be viewed as a systematic improvement of the GW approximation). We present a systematic study of the Hedin equations for zero dimensional field theory (which, in particular, is a method to enumerate Feynman diagrams for field theories in arbitrary dimensions) and show better and better convergence to the solutions of the Hedin equations for higher and higher Hedin approximations, with Hedin approximations I, II and III being explicitly studied. We, in particular, show that the higher Hedin approximations capture more and and more Feynman diagrams for the self energy. We also show that already Hedin approximation II captures more diagrams than the state of the art diagrammatic vertex corrections approach. Furthermore Hedin approximation III is a near perfect match to the exact solutions of the Hedin equations, at least in the zero dimensional case, and enumerates a large number of Feynman diagrams.

</details>


### [186] [Field-induced anomaly in the anisotropic non-Fermi-liquid normal state of UBe$_{13}$](https://arxiv.org/abs/2512.19100)
*Yusei Shimizu,Shunichiro Kittaka,Yohei Kono,Shota Nakamura,Yoshinori Haga,Etsuji Yamamoto,Kazushige Machida,Hiroshi Amitsuka,Toshiro Sakakibara*

Main category: cond-mat.str-el

TL;DR: 对UBe13单晶在极低温下的磁化和比热测量显示，正常态磁化率呈现对数温度依赖的非费米液体行为，该行为在磁场增强时被抑制。在[111]方向6-10T磁场下出现热力学异常，并观察到五阶非线性磁化率，表明5f电子多极关联与费米面重构密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究UBe13在极低温下的磁性和热力学性质，特别是非费米液体行为与磁场诱导的多极关联之间的关系，以及这些关联如何影响从非费米液体态到费米液体态的转变。

Method: 对UBe13单晶进行高分辨率直流磁化率和比热测量，温度极低，磁场沿[001]和[111]方向施加，覆盖正常态和超导态。分析磁化率的温度依赖性和磁场效应，以及比热中的热力学异常。

Result: 正常态磁化率在1-20K范围内呈现对数温度依赖的非费米液体行为，该行为随磁场增强被抑制。在4T以下出现磁化率最大值，8T以上恢复费米液体相干性。在[111]方向6-10T磁场下，磁化率和比热均出现热力学异常（TA和HA）。正常态磁化中观察到非平凡的五阶非线性磁化率。

Conclusion: UBe13中磁场诱导的5f电子多极关联与费米面重构密切相关，这解释了从非费米液体态到费米液体态的交叉转变过程，揭示了强关联电子系统中多极自由度的重要作用。

Abstract: We report the results of high-resolution dc magnetization and specific-heat measurements at very low temperatures for
  a single crystal \color{black} of UBe$_{13}$ in magnetic fields applied along the [001] and [111] directions, in both the normal and superconducting states. In the normal state, magnetic susceptibility $χ(T) = M/H$ exhibits a logarithmic temperature dependence over a wide temperature range (1-20 K). However, with increasing field, this non-Fermi-liquid (NFL) behavior of $χ(T) $ at low temperatures is suppressed. Moreover, a susceptibility maximum occurs below 4 T, whereas Fermi-liquid coherence is recovered above 8 T. In addition, thermodynamic anomalies ($T_{\rm A}$ and $H_{\rm A}$) occur in both magnetic susceptibility and specific heat at intermediate fields (6--10 T) along the [111] direction. Furthermore, a nontrivial fifth-order nonlinear susceptibility is observed in the normal-state magnetization of UBe$_{13}$. These results suggest a close relationship between the field-induced multipolar correlations of $5f$-electron degrees of freedom and the Fermi-surface reconstruction accompanying the crossover from the NFL state to the Fermi-liquid state in UBe$_{13}$.

</details>


### [187] [Quantum decay of magnons in the unfrustrated honeycomb Heisenberg model](https://arxiv.org/abs/2512.19162)
*Calvin Krämer,Dag-Björn Hering,Vanessa Sulaiman,Matthias R. Walther,Götz S. Uhrig,Kai Phillip Schmidt*

Main category: cond-mat.str-el

TL;DR: 该研究通过量子蒙特卡洛、级数展开和连续相似变换等方法，发现蜂窝晶格反铁磁海森堡模型中的磁振子在布里渊区K点处完全衰变，权重完全转移到连续谱中，磁振子准粒子图像在高能区失效。


<details>
  <summary>Details</summary>
Motivation: 研究蜂窝晶格反铁磁海森堡模型中基本磁振子激发的物理性质，特别是与方晶格中"转子最小值"现象不同的量子衰变行为。

Method: 采用三种互补方法：量子蒙特卡洛模拟（通过随机解析延拓从虚时关联函数确定动态结构因子）、级数展开（从伊辛极限外推）和连续相似变换（动量空间分析）。

Result: 发现蜂窝晶格磁振子在布里渊区K点处完全衰变，权重完全转移到连续谱中；级数展开外推的磁振子色散与QMC提取的激发能量在大部分区域一致，但在K点附近存在大的不确定性；连续相似变换显示强吸引性磁振子-磁振子相互作用导致束缚态形成，三磁振子连续谱与单磁振子态重叠。

Conclusion: 蜂窝晶格反铁磁海森堡模型中的磁振子在布里渊区K点处经历量子衰变，磁振子准粒子图像在高能区失效，这与方晶格的"转子最小值"现象形成鲜明对比。

Abstract: We investigate the physical properties of elementary magnon excitations of the ordered antiferromagnetic Heisenberg model on the honeycomb lattice using quantum Monte Carlo (QMC) simulations, series expansions (SE), and continuous similarity transformations (CST). The stochastic analytic continuation method is used to determine the dynamic structure factor from correlation functions in imaginary time obtained by QMC. In contrast to the "roton minimum" of the square lattice Heisenberg antiferromagnet, we find that magnons on the honeycomb lattice completely decay in the corner of the Brillouin zone ($K$-point); the entire weight is shifted into the continuum. These findings are fully supported by SE and CST in momentum space. The extrapolated one-magnon dispersion obtained from SE about the Ising limit quantitatively agrees with the extracted QMC excitation energies except around the $K$-point, where large uncertainties in the extrapolation indicate the magnon decay. This quantum decay is further confirmed and understood by the CST, which yields a divergent flow when enforcing a magnon quasi-particle picture. The divergence originates from strong attractive magnon-magnon interactions leading to a bound state and thereby to a three-magnon continuum overlapping with the one-magnon state. This has the magnon quasi-particle picture break down at high energies on the honeycomb lattice.

</details>


### [188] [Quantum Altermagnetic Instability in Disordered Metals](https://arxiv.org/abs/2512.19307)
*Alberto Cortijo*

Main category: cond-mat.str-el

TL;DR: 在二维各向异性电子系统中，存在零温下的反铁磁不稳定性，其相图随各向异性参数和相互作用强度变化，铁磁、反铁磁和顺磁相之间存在竞争和相变。


<details>
  <summary>Details</summary>
Motivation: 研究各向异性二维电子系统在扩散区域中零温下的反铁磁不稳定性，探索在有无自旋轨道耦合条件下铁磁、反铁磁和顺磁相之间的竞争关系。

Method: 分析各向异性二维电子系统在扩散区域的零温不稳定性，构建相图作为各向异性参数和相互作用强度的函数，考虑有无自旋轨道耦合的情况。

Result: 零自旋轨道耦合时，铁磁相仅在小各向异性和小耦合常数时占优；较大参数值有利于反铁磁相形成。有限自旋轨道耦合时，顺磁相与其他两相竞争，出现量子临界点。顺磁到磁有序相的相变为二阶，铁磁到反铁磁的相变为一阶。反铁磁相在小磁场下稳定，与场致磁化共存。

Conclusion: 各向异性二维电子系统在扩散区域中存在丰富的磁相竞争，反铁磁相在特定参数范围内稳定存在，且对弱磁场具有鲁棒性，为探索新型磁有序态提供了理论框架。

Abstract: The possibility of a zero temperature, altermagnetic instability in anisotropic two dimensional electron systems in the diffusive regime is analyzed, in the presence and absence of spin-orbit coupling. Allowing for ferromagnetism, a phase diagram is built as a function of the parameter that controls anisotropy and the strength of the interactions. It is found that, at zero spin orbit coupling, ferromagnetism only dominates at small values of anisotropy and coupling constant. Larger values of these parameters favour the formation of altermagnetism. At finite spin-orbit coupling, a paramagnetic phase competes with the other two, and a quantum critical point appears. The phase transition from the paramagnetic to the magnetically ordered phases is of second order, while the phase transition between ferromagnet and altermagnet states is first order. The altermagnetic phase is robust under small magnetic fields, displaying a coexistence with a field-induced magnetization.

</details>


### [189] [Measuring the Hall effect in hysteretic materials](https://arxiv.org/abs/2512.19427)
*Jaime M. Moya,Anthony Voyemant,Sudipta Chatterjee,Scott B. Lee,Grigorii Skorupskii,Connor J. Pollak,Leslie M. Schoop*

Main category: cond-mat.str-el

TL;DR: 该论文针对铁磁材料中霍尔效应测量的挑战，提出了两种提取真实霍尔响应的方法，避免了传统反对称化处理可能产生的虚假异常霍尔信号。


<details>
  <summary>Details</summary>
Motivation: 霍尔效应测量是材料发现、表征和计量学的重要工具，但在铁磁材料中，由于磁滞现象的存在，传统基于Onsager-Casimir互易性的反对称化处理方法不再适用，可能导致虚假的异常霍尔信号。特别是在交换偏置系统中，磁滞回线不以零磁场为中心，这一问题更加复杂。目前缺乏从铁磁材料中提取霍尔响应的通用实用方法。

Method: 使用Co₃Sn₂S₂作为体单晶模型材料，该材料可以制备成有或没有交换偏置磁滞的状态。研究人员展示了两种提取霍尔效应的方法：(1) 反向磁场互易性方法；(2) 相对于外加磁场的反对称化方法。随后在CeCoGe₃（一种非中心对称反铁磁体）上测量霍尔效应，该材料可以制备成具有不对称磁化和磁阻的状态。

Result: 成功演示了两种方法在铁磁材料中提取真实霍尔响应的有效性。在CeCoGe₃上，展示了不当的数据处理如何产生虚假的异常霍尔信号，验证了所提方法的必要性。

Conclusion: 提出的两种方法是通用的，可以应用于任何导体材料，为铁磁材料中霍尔效应的准确测量提供了实用参考，避免了传统方法可能引入的测量误差和虚假信号。

Abstract: Measurement of the Hall effect is a ubiquitous probe for materials discovery, characterization, and metrology. Inherent to the Hall measurement geometry, the measured signal is often contaminated by unwanted contributions, so the data must be processed to isolate the Hall response. The standard approach invokes Onsager-Casimir reciprocity and antisymmetrizes the raw signal about zero applied magnetic field. In hysteretic materials this becomes nontrivial, since Onsager-Casimir relations apply only to microscopically reversible states. Incorrect antisymmetrization can lead to artifacts that mimic anomalous or topological Hall signatures. The situation is especially subtle when hysteresis loops are not centered at zero applied field, as in exchange-biased systems. A practical reference for generically extracting the Hall response in hysteretic materials is lacking. Here, using Co$_3$Sn$_2$S$_2$ as a bulk single-crystal model that can be prepared with or without exchange-biased hysteresis, we demonstrate two procedures that can be used to extract the Hall effect: (1) reverse-magnetic-field reciprocity and (2) antisymmetrization with respect to applied field. We then measure the Hall effect on CeCoGe$_3$, a noncentrosymmetric antiferromagnet which can be prepared to have asymmetric magnetization and magnetoresistance, and demonstrate how improper processing can generate artificial anomalous Hall signals. These methods are generic and can be applied to any conductor.

</details>


### [190] [Towards a universal phase diagram of planar chiral magnets](https://arxiv.org/abs/2512.19590)
*Bernd Schroers,Martin Speight,Thomas Winyard*

Main category: cond-mat.str-el

TL;DR: 该论文研究了平面手性磁体中Dzyaloshinskii-Moriya相互作用(DMI)与海森堡交换作用和塞曼能量竞争下的基态相图，考虑了任意螺旋化张量和外磁场方向。


<details>
  <summary>Details</summary>
Motivation: 研究平面手性磁体中DMI能量与正定海森堡交换、塞曼能量之间的竞争关系，探索负能量基态的可能性，理解基态对理论参数的复杂依赖性。

Method: 考虑任意DMI螺旋化张量和外磁场方向，采用解析和数值方法相结合的方式，在参数空间中研究基态性质，按对称性将基态分类为铁磁态、螺旋态和斯格明子晶格态。

Result: 给出了这类理论的完整相图描述，展示了不同对称性基态在参数空间中的分布和相变行为。

Conclusion: 通过系统分析平面手性磁体中DMI与海森堡交换、塞曼能量的竞争，建立了完整的基态相图分类，揭示了不同对称性基态在参数空间中的存在条件和相变规律。

Abstract: In planar chiral magnets, the competition of the positive definite Heisenberg exchange and Zeeman energies with the indefinite Dzyaloshinskii-Moriya interaction (DMI) energy allows for the possibility of negative energy ground states, and leads to an intricate dependence of the ground states on the parameters of the theory. In this paper, we consider arbitrary spiralization tensors for the DMI interaction and arbitrary directions for the external magnetic field, and study the nature of the ground states in this parameter space, using a combination of analytical and numerical methods. Classifying ground states by their symmetry into ferromagnetic (invariant under under arbitrary translations in the plane), spiral (invariant under arbitrary translations in one direction) and skyrmion lattice ground states (invariant under a two dimensional lattice group), we give a complete description of the phase diagram of this class of theories.

</details>


### [191] [Kitaev interactions of the spin-orbit coupled magnet UO2](https://arxiv.org/abs/2512.19674)
*Joseph A. M. Paddison,Lionel Desgranges,Gianguido Baldinozzi,Gerard H. Lander,Henry E. Fischer*

Main category: cond-mat.str-el

TL;DR: UO₂中发现了类似Kitaev模型的键依赖磁相互作用，表明含f电子磁性离子的材料可能实现Kitaev磁性


<details>
  <summary>Details</summary>
Motivation: 研究具有强自旋轨道耦合的磁性材料UO₂的磁相互作用，探索实现Kitaev磁性的潜在材料体系

Method: 通过测量多晶UO₂样品在磁有序转变温度以上的磁漫散射，精修磁相互作用参数，并与理论预测和磁激发谱实验测量结果比较

Result: UO₂中的主导磁耦合是类似Kitaev模型的键依赖相互作用，表明含f电子磁性离子（特别是锕系元素）的材料可能是实现Kitaev磁性的有希望候选者

Conclusion: 磁漫散射数据在识别Kitaev磁性材料中具有重要作用，含f电子磁性离子的材料（特别是锕系元素）可能为探索Kitaev磁性提供新平台

Abstract: Uranium dioxide, UO$_2$, is a canonical example of a magnetic material with strong spin-orbit coupling. Here, we present a study of the magnetic diffuse scattering measured on a polycrystalline sample of UO$_2$, which we interpret in terms of its magnetic interactions between U$^{4+}$ magnetic moments. By refining values of the magnetic interaction parameters to magnetic diffuse-scattering data measured above the magnetic ordering transition temperature, we show that the dominant magnetic coupling in UO$_2$ is a bond-dependent interaction analogous to the Kitaev model of honeycomb magnets. We compare our experimental results with published theoretical predictions and experimental measurements of the magnetic excitation spectrum. Our results suggest that magnetic materials with $f$-electron magnetic ions, particularly actinides, may be promising candidates for realising Kitaev magnetism, and highlight the role that magnetic diffuse-scattering data can play in identifying such materials.

</details>


### [192] [2D coherent spectroscopy signatures of exciton condensation in Ta$_2$NiSe$_5$](https://arxiv.org/abs/2512.19689)
*Jiyu Chen,Jernej Mravlje,Denis Golež,Philipp Werner*

Main category: cond-mat.str-el

TL;DR: 二维相干光谱（2DCS）的非线性光学响应可以区分激子驱动和晶格驱动的有序态。在Ta₂NiSe₅的激子区域，三阶2DCS信号被凝聚体的振幅模和相位模显著增强，而单粒子激发贡献可忽略。随着电子-声子耦合增强，振幅模贡献先保持稳定后急剧下降，在声子主导区域很小。2DCS还能检测类似超导体Leggett模的相对相位模。


<details>
  <summary>Details</summary>
Motivation: 传统线性光学响应中，单粒子激发和集体模的贡献相互重叠，难以区分激子驱动和晶格驱动的有序态。需要一种能够清晰区分这两种有序机制的光谱技术。

Method: 采用时间依赖的Hartree-Fock方法分析二维相干光谱（2DCS）的非线性光学响应。以Ta₂NiSe₅为实际模型，研究其三阶2DCS信号在不同电子-声子耦合强度下的行为。

Result: 在激子主导区域，三阶2DCS信号被凝聚体的振幅模和相位模显著增强，单粒子激发贡献可忽略。随着电子-声子耦合增强，振幅模贡献先保持稳定后急剧下降，在声子主导区域很小。2DCS还能检测类似超导体Leggett模的相对相位模。

Conclusion: 二维相干光谱（2DCS）能够追踪对称性破缺态的出现，并区分从库仑驱动到声子驱动有序态的交叉转变，为研究有序态的物理机制提供了有力工具。

Abstract: We show that the nonlinear optical response probed by two-dimensional coherent spectroscopy (2DCS) can discriminate between excitonic and lattice driven order. In the excitonic regime of a realistic model of Ta$_2$NiSe$_5$, the third order 2DCS signals are strongly enhanced by the condensate's amplitude and phase modes, with negligible contributions from single-particle excitations. In the linear optical response, in contrast, single-particle and collective-mode contributions overlap. With increasing electron-phonon coupling, the amplitude mode contribution to 2DCS initially remains robust, but then drops rapidly and remains small in the phonon-dominated regime -- even in systems with large order parameter. 2DCS also aids the detection of the massive relative phase mode, which is analogous to the Leggett mode in superconductors. Our analysis, based on the time-dependent Hartree-Fock approach, demonstrates that 2DCS can track the emergence of the symmetry-broken state and the crossover from Coulomb-driven to phonon-driven order.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [193] [Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout](https://arxiv.org/abs/2512.18034)
*Joshua Gibson,Kapil Dhakal*

Main category: cs.AI

TL;DR: 该论文研究将冲突驱动子句学习（CDCL）与VSIDS启发式算法应用于离散设施布局问题，开发了CNF建模方法，比较了CDCL、CP-SAT和MILP的性能，并提出了两种混合架构以结合CDCL的可行性搜索和CP-SAT的优化能力。


<details>
  <summary>Details</summary>
Motivation: 离散设施布局问题具有复杂的组合结构和密集的逻辑约束（邻接、分离、槽位可用性等），需要高效的求解方法。传统方法如CP-SAT和MILP在处理大规模问题时存在扩展性问题，而CDCL在SAT求解中表现出色，但缺乏优化能力，因此需要探索CDCL在布局问题中的应用并设计混合方法。

Method: 1. 将设施布局问题建模为具有密集逻辑结构的组合分配问题，开发CNF（合取范式）公式表示布局可行性约束；2. 在统一基准框架下比较CDCL-based SAT求解、CP-SAT和MILP方法；3. 提出两种混合架构：第一种快速枚举可行布局以速度换取最优性，第二种使用CDCL生成热启动解以加速精确优化。

Result: 实证结果显示：CDCL在可行性检测方面表现出接近恒定的运行时间行为，随问题规模和约束密度增加而保持稳定；CP-SAT显示多项式扩展；MILP显示指数扩展。混合方法能显著减少求解时间同时保持正确性保证。

Conclusion: CDCL在离散设施布局问题的可行性检测方面具有优越的扩展性，但缺乏优化能力。通过将CDCL的快速可行性搜索与CP-SAT的精确优化相结合，混合方法能够在保持正确性的同时显著提高求解效率，阐明了子句学习搜索与精确优化方法在大规模离散布局问题中的算法权衡。

Abstract: This paper studies the use of Conflict-Driven Clause Learning (CDCL) with VSIDS heuristics as a computational engine for discrete facility layout problems. The facility layout problem is modeled as a combinatorial assignment problem with dense logical structure arising from adjacency, separation, and slot-availability constraints. We develop a CNF-based formulation for layout feasibility and compare CDCL-based SAT solving against CP-SAT and MILP formulations under a unified benchmarking framework. Empirical results show that CDCL exhibits near-constant runtime behavior for feasibility detection across increasing problem sizes and constraint densities, while CP-SAT and MILP display polynomial and exponential scaling respectively. To address the limitation of CDCL in objective optimization, we introduce two hybrid architectures that combine CDCL-based feasibility search with CP-SAT optimization. The first architecture rapidly enumerates feasible layouts to trade optimality for speed, while the second uses CDCL to generate warm-start solutions that accelerate exact optimization. The results demonstrate that hybrid approaches can significantly reduce time-to-solution while preserving correctness guarantees, clarifying the algorithmic trade-offs between clause-learning search and exact optimization methods in large-scale discrete layout problems.

</details>


### [194] [Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability](https://arxiv.org/abs/2512.18092)
*Ge Yan,Tuomas Oikarinen,Tsui-Wei,Weng*

Main category: cs.AI

TL;DR: 该论文首次为神经元识别提供了理论分析框架，通过将神经元识别视为机器学习的逆过程，推导出解释的忠实性和稳定性保证，并提出了BE方法生成概念预测集。


<details>
  <summary>Details</summary>
Motivation: 当前神经元识别方法（如Network Dissection和CLIP-Dissect）虽然取得了经验成功，但缺乏严格的理论基础，这阻碍了获得可信赖和可靠的解释。需要建立理论保证来确保神经元解释的忠实性和稳定性。

Method: 将神经元识别视为机器学习的逆过程，推导相似性度量（准确率、AUROC、IoU）的泛化界限以保证忠实性；提出自助法集成程序量化稳定性，并开发BE方法生成具有覆盖概率保证的概念预测集。

Result: 在合成数据和真实数据上的实验验证了理论结果，证明了方法的实用性。为神经元识别提供了第一个理论分析框架，确保了解释的忠实性和稳定性。

Conclusion: 该工作为神经元识别建立了理论基础，通过推导忠实性和稳定性的理论保证，以及提出BE方法生成概念预测集，为实现可信赖的神经元识别迈出了重要一步。

Abstract: Neuron identification is a popular tool in mechanistic interpretability, aiming to uncover the human-interpretable concepts represented by individual neurons in deep networks. While algorithms such as Network Dissection and CLIP-Dissect achieve great empirical success, a rigorous theoretical foundation remains absent, which is crucial to enable trustworthy and reliable explanations. In this work, we observe that neuron identification can be viewed as the inverse process of machine learning, which allows us to derive guarantees for neuron explanations. Based on this insight, we present the first theoretical analysis of two fundamental challenges: (1) Faithfulness: whether the identified concept faithfully represents the neuron's underlying function and (2) Stability: whether the identification results are consistent across probing datasets. We derive generalization bounds for widely used similarity metrics (e.g. accuracy, AUROC, IoU) to guarantee faithfulness, and propose a bootstrap ensemble procedure that quantifies stability along with BE (Bootstrap Explanation) method to generate concept prediction sets with guaranteed coverage probability. Experiments on both synthetic and real data validate our theoretical results and demonstrate the practicality of our method, providing an important step toward trustworthy neuron identification.

</details>


### [195] [Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap](https://arxiv.org/abs/2512.18126)
*Zijun Wang,Yijiahao Qi,Hanqiu Chen,Zishen Wan,Gongjin Sun,Dongyang Li,Shuyi Pei,Cong Hao*

Main category: cs.AI

TL;DR: MoA推理存在通信密集和硬件利用率低的问题，本文通过算法-系统协同设计提出分层树拓扑、自适应终止机制和流水线执行，显著降低延迟同时保持精度。


<details>
  <summary>Details</summary>
Motivation: Mixture-of-Agents推理存在密集的智能体间通信和低硬件利用率问题，这两个因素共同增加了服务延迟，需要优化设计来解决这些瓶颈。

Method: 1) 用分层树拓扑替代密集的智能体交互图，引入结构化稀疏通信；2) 基于语义一致性和置信度信号的自适应机制，选择性终止或跳过下游智能体调用；3) 通过重叠增量预填充和解码实现智能体执行的流水线化。

Result: 该方法在代表性任务中显著降低端到端延迟（最高达90%），同时保持与密集连接MoA基线相当的精度（±1%以内），在某些设置下还能提高精度。

Conclusion: 通过算法-系统协同设计，采用分层通信拓扑、自适应执行控制和流水线优化，可以有效解决MoA推理中的通信和利用率瓶颈，实现延迟大幅降低而精度基本保持。

Abstract: Mixture-of-Agents (MoA) inference can suffer from dense inter-agent communication and low hardware utilization, which jointly inflate serving latency. We present a serving design that targets these bottlenecks through an algorithm-system co-design. First, we replace dense agent interaction graphs with a hierarchical tree topology that induces structured sparsity in inter-agent communication. Second, we introduce a runtime adaptive mechanism that selectively terminates or skips downstream agent invocations using semantic agreement and confidence signals from intermediate outputs. Third, we pipeline agent execution by overlapping incremental prefilling with decoding across dependency-related agents, improving utilization and reducing inference latency. Across representative tasks, this approach substantially reduces end-to-end latency (up to 90%) while maintaining comparable accuracy (within $\pm$1%) relative to dense-connectivity MoA baselines, and can improve accuracy in certain settings.

</details>


### [196] [Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications](https://arxiv.org/abs/2512.18135)
*Cristiano da Costa Cunha,Wei Liu,Tim French,Ajmal Mian*

Main category: cs.AI

TL;DR: 这篇综述论文系统回顾了因果推断与强化学习的交叉领域，探讨了如何通过因果建模解决传统RL在可解释性、鲁棒性和泛化能力方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习基于相关性决策，面临分布偏移、混杂变量和动态环境等挑战，导致可解释性低、鲁棒性差和泛化失败。因果强化学习通过显式建模因果关系，为解决这些问题提供了有前景的解决方案。

Method: 论文采用系统性综述方法，将现有方法分为五类：因果表示学习、反事实策略优化、离线因果RL、因果迁移学习和因果可解释性。通过结构化分析识别挑战、突出实证成功并讨论开放问题。

Result: 论文系统梳理了因果强化学习的最新进展，识别了该领域的主要挑战和成功应用案例，为研究人员提供了该交叉领域的全面概览。

Conclusion: 因果强化学习具有开发鲁棒、可泛化和可解释人工智能系统的巨大潜力，论文指出了未来研究方向，强调了这一交叉领域对AI发展的重要性。

Abstract: Integrating causal inference (CI) with reinforcement learning (RL) has emerged as a powerful paradigm to address critical limitations in classical RL, including low explainability, lack of robustness and generalization failures. Traditional RL techniques, which typically rely on correlation-driven decision-making, struggle when faced with distribution shifts, confounding variables, and dynamic environments. Causal reinforcement learning (CRL), leveraging the foundational principles of causal inference, offers promising solutions to these challenges by explicitly modeling cause-and-effect relationships. In this survey, we systematically review recent advancements at the intersection of causal inference and RL. We categorize existing approaches into causal representation learning, counterfactual policy optimization, offline causal RL, causal transfer learning, and causal explainability. Through this structured analysis, we identify prevailing challenges, highlight empirical successes in practical applications, and discuss open problems. Finally, we provide future research directions, underscoring the potential of CRL for developing robust, generalizable, and interpretable artificial intelligence systems.

</details>


### [197] [Propose, Solve, Verify: Self-Play Through Formal Verification](https://arxiv.org/abs/2512.18160)
*Alex Wilf,Pranjal Aggarwal,Bryan Parno,Daniel Fried,Louis-Philippe Morency,Paul Pu Liang,Sean Welleck*

Main category: cs.AI

TL;DR: PSV-Verus：通过形式化验证信号进行自对弈训练代码生成模型，在三个基准测试中pass@1提升高达9.6倍


<details>
  <summary>Details</summary>
Motivation: 研究纯自对弈（无人类数据）训练大型语言模型的有效性，特别是在代码生成领域。传统基于单元测试的奖励机制脆弱且容易传播错误，而形式化验证可以提供可靠的正确性信号。

Method: 提出PSV（Propose, Solve, Verify）自对弈框架：利用形式化验证信号训练一个能够生成挑战性合成问题的提议者（proposer），以及通过专家迭代训练的求解者（solver）。

Result: PSV-Verus在三个基准测试中，pass@1相比仅推理和专家迭代基线提升了高达9.6倍。性能随着生成问题数量和训练迭代次数的增加而扩展，形式化验证和难度感知提议是成功自对弈的关键要素。

Conclusion: 在验证代码生成设置中，形式化验证为自对弈训练提供了可靠的正确性信号，PSV框架能够有效训练代码生成模型，显著提升性能，证明了纯自对弈训练在代码生成领域的可行性。

Abstract: Training models through self-play alone (without any human data) has been a longstanding goal in AI, but its effectiveness for training large language models remains unclear, particularly in code generation where rewards based on unit tests are brittle and prone to error propagation. We study self-play in the verified code generation setting, where formal verification provides reliable correctness signals. We introduce Propose, Solve, Verify (PSV) a simple self-play framework where formal verification signals are used to create a proposer capable of generating challenging synthetic problems and a solver trained via expert iteration. We use PSV to train PSV-Verus, which across three benchmarks improves pass@1 by up to 9.6x over inference-only and expert-iteration baselines. We show that performance scales with the number of generated questions and training iterations, and through ablations identify formal verification and difficulty-aware proposal as essential ingredients for successful self-play.

</details>


### [198] [NEURO-GUARD: Neuro-Symbolic Generalization and Unbiased Adaptive Routing for Diagnostics -- Explainable Medical AI](https://arxiv.org/abs/2512.18177)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: NEURO-GUARD是一个知识引导的视觉框架，通过结合Vision Transformers和语言驱动推理，使用检索增强生成机制进行自我验证，显著提升医疗图像诊断的准确性、可解释性和跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI面临准确性与可解释性的挑战，现有视觉模型多为黑盒预测，缺乏可解释性且跨域泛化能力差，限制了临床实际应用。需要开发既能保持高精度又具备透明解释能力的医疗诊断系统。

Method: 提出NEURO-GUARD框架，集成Vision Transformers与语言驱动推理，采用检索增强生成机制让大语言模型迭代生成、评估和优化医疗图像特征提取代码，基于临床指南和专家知识逐步提升特征检测和分类能力。

Result: 在四个糖尿病视网膜病变数据集上，NEURO-GUARD相比纯ViT基线提升6.2%准确率（84.69% vs 78.4%），跨域泛化能力提升5%。在MRI癫痫检测任务上也表现出优越的跨域鲁棒性，超越现有方法。

Conclusion: NEURO-GUARD成功将符号化医学推理与亚符号化视觉学习相结合，实现了可解释、知识感知且可泛化的医疗图像诊断，在多个数据集上达到最先进性能，为高风险的临床决策提供了更可靠的AI工具。

Abstract: Accurate yet interpretable image-based diagnosis remains a central challenge in medical AI, particularly in settings characterized by limited data, subtle visual cues, and high-stakes clinical decision-making. Most existing vision models rely on purely data-driven learning and produce black-box predictions with limited interpretability and poor cross-domain generalization, hindering their real-world clinical adoption. We present NEURO-GUARD, a novel knowledge-guided vision framework that integrates Vision Transformers (ViTs) with language-driven reasoning to improve performance, transparency, and domain robustness. NEURO-GUARD employs a retrieval-augmented generation (RAG) mechanism for self-verification, in which a large language model (LLM) iteratively generates, evaluates, and refines feature-extraction code for medical images. By grounding this process in clinical guidelines and expert knowledge, the framework progressively enhances feature detection and classification beyond purely data-driven baselines. Extensive experiments on diabetic retinopathy classification across four benchmark datasets APTOS, EyePACS, Messidor-1, and Messidor-2 demonstrate that NEURO-GUARD improves accuracy by 6.2% over a ViT-only baseline (84.69% vs. 78.4%) and achieves a 5% gain in domain generalization. Additional evaluations on MRI-based seizure detection further confirm its cross-domain robustness, consistently outperforming existing methods.
  Overall, NEURO-GUARD bridges symbolic medical reasoning with subsymbolic visual learning, enabling interpretable, knowledge-aware, and generalizable medical image diagnosis while achieving state-of-the-art performance across multiple datasets.

</details>


### [199] [External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning](https://arxiv.org/abs/2512.18190)
*Jian Yan*

Main category: cs.AI

TL;DR: 提出External Hippocampus框架，从认知动力学视角将语言模型推理建模为语义空间中的信息能量流动，通过降维投影构建拓扑认知地图，实现推理过程的精确导航和干预，有效解决小模型多步推理中的认知死锁问题。


<details>
  <summary>Details</summary>
Motivation: 传统权重空间优化方法在语言模型推理中存在局限性，特别是小模型在多步推理中容易出现认知死锁问题。需要一种无需额外训练、计算效率高且能精确干预推理过程的新方法。

Method: 提出External Hippocampus框架，将语言模型推理视为语义空间中的信息能量流动。通过降维投影构建拓扑认知地图，在测试时精确导航和干预能量流动。利用温度扰动重启能量流动，解决推理停滞问题。

Result: 在≤7B参数模型上的实验显示：地图引导方法在500个挑战性问题上的准确率达到81.20%（相对基线提升16.80%），推理时间减少≥15倍。发现推理停滞表现为"认知漩涡"和低熵势阱，温度扰动能有效重启能量流动。

Conclusion: External Hippocampus框架为小模型推理提供了高效可控的拓扑感知解决方案，无需额外训练，具有自主增长能力，能有效解决多步推理中的认知死锁问题，显著提升推理性能和效率。

Abstract: This paper proposes the External Hippocampus framework, which models language model reasoning from a cognitive dynamics perspective as the flow of information energy in semantic space. Unlike traditional weight-space optimization methods, this framework constructs topological cognitive maps through dimensionality reduction projection, enabling precise navigation and intervention of energy flow at test time while avoiding substantial computational requirements and demonstrating predictable intervention patterns. The method effectively addresses the cognitive deadlock problem in multi-step reasoning for small models. Experiments on models <=7B parameters show: map-guided methods achieve 81.20% accuracy on 500 challenging problems (relative baseline +16.80%), reduce reasoning time by >= 15x, with key findings revealing that reasoning stagnation manifests as "Cognitive Vortex" and low-entropy potential wells, while temperature perturbations effectively restart energy flow. The framework requires no additional training, possesses autonomous growth capability, and provides an efficient and controllable topological-aware solution for small model reasoning.

</details>


### [200] [Sophia: A Persistent Agent Framework of Artificial Life](https://arxiv.org/abs/2512.18202)
*Mingyang Sun,Feng Hong,Weinan Zhang*

Main category: cs.AI

TL;DR: 论文提出System 3框架和Sophia持久智能体，为LLM智能体添加元认知层，实现身份连续性、自我改进和长期适应能力


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体虽然具备感知（System 1）和推理（System 2）能力，但缺乏持久元认知层来维持身份、验证推理、对齐短期行动与长期生存目标，限制了其作为长期决策实体的发展

Method: 提出System 3作为第三层架构，将心理学概念映射到计算模块；开发Sophia持久智能体包装器，包含四个协同机制：过程监督思维搜索、叙事记忆、用户与自我建模、混合奖励系统

Result: 定量：Sophia自主启动执行内在任务，重复操作推理步骤减少80%；元认知持久性使高复杂度任务成功率提升40%。定性：System 3展现出连贯叙事身份和任务组织能力

Conclusion: 通过融合心理学洞察与轻量级强化学习核心，持久智能体架构为人工生命提供了可行的实践路径，实现了身份连续性和透明行为解释

Abstract: The development of LLMs has elevated AI agents from task-specific tools to long-lived, decision-making entities. Yet, most architectures remain static and reactive, tethered to manually defined, narrow scenarios. These systems excel at perception (System 1) and deliberation (System 2) but lack a persistent meta-layer to maintain identity, verify reasoning, and align short-term actions with long-term survival. We first propose a third stratum, System 3, that presides over the agent's narrative identity and long-horizon adaptation. The framework maps selected psychological constructs to concrete computational modules, thereby translating abstract notions of artificial life into implementable design requirements. The ideas coalesce in Sophia, a "Persistent Agent" wrapper that grafts a continuous self-improvement loop onto any LLM-centric System 1/2 stack. Sophia is driven by four synergistic mechanisms: process-supervised thought search, narrative memory, user and self modeling, and a hybrid reward system. Together, they transform repetitive reasoning into a self-driven, autobiographical process, enabling identity continuity and transparent behavioral explanations. Although the paper is primarily conceptual, we provide a compact engineering prototype to anchor the discussion. Quantitatively, Sophia independently initiates and executes various intrinsic tasks while achieving an 80% reduction in reasoning steps for recurring operations. Notably, meta-cognitive persistence yielded a 40% gain in success for high-complexity tasks, effectively bridging the performance gap between simple and sophisticated goals. Qualitatively, System 3 exhibited a coherent narrative identity and an innate capacity for task organization. By fusing psychological insight with a lightweight reinforcement-learning core, the persistent agent architecture advances a possible practical pathway toward artificial life.

</details>


### [201] [MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification](https://arxiv.org/abs/2512.18256)
*Sirui Li,Wangyue Lu,Xiaorui Shi,Ke Weng,Haozhe Sun,Minghe Yu,Tiancheng Zhang,Ge Yu,Hengyu Liu,Lun Du*

Main category: cs.AI

TL;DR: MSC-180是一个基于MSC2020数学学科分类的定理证明基准测试，包含180个形式化验证问题，覆盖60个数学分支。现有LLM定理证明器在该基准上表现不佳，仅18.89%通过率，存在明显的领域偏见和泛化能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的定理证明器存在领域覆盖有限和数学推理泛化能力弱的问题，需要更全面、系统的评估基准来推动具有真正数学推理能力的AI系统发展。

Method: 提出MSC-180基准测试，基于MSC2020数学学科分类构建，包含180个形式化验证问题（每个数学分支3个问题），覆盖从本科到研究生难度。引入变异系数作为评估指标来量化模型在不同数学领域的性能变异性。

Result: 在pass@32设置下，最佳模型仅达到18.89%总体通过率，存在显著领域偏见（最大领域覆盖率41.7%）和难度差距（研究生级别问题通过率显著更低）。变异系数值比统计高变异性阈值高4-6倍，表明模型仍依赖训练语料中的模式匹配而非可迁移的推理机制。

Conclusion: MSC-180及其多维评估框架为驱动下一代具有真正数学推理能力的AI系统发展提供了区分性和系统性的基准测试，揭示了当前LLM定理证明器的局限性并指明了改进方向。

Abstract: Automated Theorem Proving (ATP) represents a core research direction in artificial intelligence for achieving formal reasoning and verification, playing a significant role in advancing machine intelligence. However, current large language model (LLM)-based theorem provers suffer from limitations such as restricted domain coverage and weak generalization in mathematical reasoning. To address these issues, we propose MSC-180, a benchmark for evaluation based on the MSC2020 mathematical subject classification. It comprises 180 formal verification problems, 3 advanced problems from each of 60 mathematical branches, spanning from undergraduate to graduate levels. Each problem has undergone multiple rounds of verification and refinement by domain experts to ensure formal accuracy. Evaluations of state-of-the-art LLM-based theorem provers under the pass@32 setting reveal that the best model achieves only an 18.89% overall pass rate, with prominent issues including significant domain bias (maximum domain coverage 41.7%) and a difficulty gap (significantly lower pass rates on graduate-level problems). To further quantify performance variability across mathematical domains, we introduce the coefficient of variation (CV) as an evaluation metric. The observed CV values are 4-6 times higher than the statistical high-variability threshold, indicating that the models still rely on pattern matching from training corpora rather than possessing transferable reasoning mechanisms and systematic generalization capabilities. MSC-180, together with its multi-dimensional evaluation framework, provides a discriminative and systematic benchmark for driving the development of next-generation AI systems with genuine mathematical reasoning abilities.

</details>


### [202] [Monitoring Monitorability](https://arxiv.org/abs/2512.18311)
*Melody Y. Guan,Miles Wang,Micah Carroll,Zehao Dou,Annie Y. Wei,Marcus Williams,Benjamin Arnav,Joost Huizinga,Ian Kivlichan,Mia Glaese,Jakub Pachocki,Bowen Baker*

Main category: cs.AI

TL;DR: 论文提出评估AI系统决策可监控性的框架，包括三种评估原型和新的监控指标，发现思维链监控比仅监控行动更有效，并研究了可监控性随推理计算、强化学习优化和模型规模的变化趋势。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统能力不断增强，需要对其决策过程进行可监控性观察以确保安全部署。当前基于思维链的监控方法可能在不同训练过程、数据源或系统扩展下变得脆弱，因此需要系统性地测量和追踪可监控性。

Method: 提出三种评估原型（干预、过程和结果属性评估），定义新的可监控性指标，并构建广泛的评估套件。通过实验比较不同前沿模型的可监控性，研究可监控性随推理计算、强化学习优化和预训练模型规模的变化趋势。

Result: 思维链监控比仅监控行动更有效；大多数前沿模型具有相当但不完美的可监控性；更长的思维链通常更具可监控性；强化学习优化在当前前沿规模下不会显著降低可监控性；通过部署较小模型以更高推理努力可以获得更高可监控性；为弱监控器提供思维链访问权限可提升其可监控性并增强计算-可监控性缩放趋势。

Conclusion: 系统可监控性评估框架能够有效检测AI系统的决策过程，思维链监控是确保AI安全部署的重要工具。研究揭示了可监控性随系统参数变化的规律，为设计更安全、更透明的AI系统提供了指导。

Abstract: Observability into the decision making of modern AI systems may be required to safely deploy increasingly capable agents. Monitoring the chain-of-thought (CoT) of today's reasoning models has proven effective for detecting misbehavior. However, this "monitorability" may be fragile under different training procedures, data sources, or even continued system scaling. To measure and track monitorability, we propose three evaluation archetypes (intervention, process, and outcome-property) and a new monitorability metric, and introduce a broad evaluation suite. We demonstrate that these evaluations can catch simple model organisms trained to have obfuscated CoTs, and that CoT monitoring is more effective than action-only monitoring in practical settings. We compare the monitorability of various frontier models and find that most models are fairly, but not perfectly, monitorable. We also evaluate how monitorability scales with inference-time compute, reinforcement learning optimization, and pre-training model size. We find that longer CoTs are generally more monitorable and that RL optimization does not materially decrease monitorability even at the current frontier scale. Notably, we find that for a model at a low reasoning effort, we could instead deploy a smaller model at a higher reasoning effort (thereby matching capabilities) and obtain a higher monitorability, albeit at a higher overall inference compute cost. We further investigate agent-monitor scaling trends and find that scaling a weak monitor's test-time compute when monitoring a strong agent increases monitorability. Giving the weak monitor access to CoT not only improves monitorability, but it steepens the monitor's test-time compute to monitorability scaling trend. Finally, we show we can improve monitorability by asking models follow-up questions and giving their follow-up CoT to the monitor.

</details>


### [203] [Few-Shot Learning of a Graph-Based Neural Network Model Without Backpropagation](https://arxiv.org/abs/2512.18412)
*Mykyta Lapin,Kostiantyn Bokhan,Yurii Parzhyn*

Main category: cs.AI

TL;DR: 提出一种基于结构图的方法，在少样本情况下对轮廓图像进行分类，无需反向传播，通过构建概念吸引子提供可解释的决策。


<details>
  <summary>Details</summary>
Motivation: 设计一种无需反向传播的少样本学习架构，通过结构化的图表示使决策过程透明可解释，从少量样本（每类5-6个）形成类概念。

Method: 将图像编码为属性图（关键点和线作为节点，包含几何属性），通过消除不稳定子结构和噪声、对齐关键点间路径等结构约简，迭代组合样本形成概念吸引子，使用近似图编辑距离进行图到概念的匹配分类。

Result: 在MNIST子集上（每类5-6个基础样本，单轮训练）获得约82%的准确率，决策完全可追溯，误分类可通过显式结构相似性解释。与SVM、MLP、CNN以及度量和元学习基线进行了对比。

Conclusion: 结构图方案结合概念吸引子实现了无需反向传播的少样本学习，通过显式图结构提供内置解释。局限性包括图编辑距离的计算成本和骨架化质量；未来方向包括分类算法优化、静态场景处理和相关识别。

Abstract: We propose a structural-graph approach to classifying contour images in a few-shot regime without using backpropagation. The core idea is to make structure the carrier of explanations: an image is encoded as an attributed graph (critical points and lines represented as nodes with geometric attributes), and generalization is achieved via the formation of concept attractors (class-level concept graphs). Purpose. To design and experimentally validate an architecture in which class concepts are formed from a handful of examples (5 - 6 per class) through structural and parametric reductions, providing transparent decisions and eliminating backpropagation. Methods. Contour vectorization is followed by constructing a bipartite graph (Point/Line as nodes) with normalized geometric attributes such as coordinates, length, angle, and direction; reductions include the elimination of unstable substructures or noise and the alignment of paths between critical points. Concepts are formed by iterative composition of samples, and classification is performed by selecting the best graph-to-concept match (using approximated GED). Results. On an MNIST subset with 5 - 6 base examples per class (single epoch), we obtain a consistent accuracy of around 82% with full traceability of decisions: misclassifications can be explained by explicit structural similarities. An indicative comparison with SVM, MLP, CNN, as well as metric and meta-learning baselines, is provided. The structural-graph scheme with concept attractors enables few-shot learning without backpropagation and offers built-in explanations through the explicit graph structure. Limitations concern the computational cost of GED and the quality of skeletonization; promising directions include classification-algorithm optimization, work with static scenes, and associative recognition.

</details>


### [204] [Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations](https://arxiv.org/abs/2512.18483)
*Rahul Yumlembam,Biju Issac,Seibu Mary Jacob,Longzhi Yang,Deepa Krishnan*

Main category: cs.AI

TL;DR: 提出了一种结合显式和隐式图表示与时间建模的内幕威胁检测框架，通过GCN处理两种图结构，使用注意力机制和Bi-LSTM捕获时间依赖，在CERT数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 内幕威胁检测具有挑战性，因为恶意活动通常由受信任用户执行，行为隐蔽且难以察觉。现有方法难以捕捉复杂的用户行为模式和时间依赖关系。

Method: 构建显式图（基于组织规则）和隐式图（基于特征相似性，使用Gumbel-Softmax学习），分别用GCN处理生成节点嵌入，通过注意力机制融合并强调威胁相关特征，最后用Bi-LSTM捕获时间依赖。

Result: 在CERT r5.2数据集上：AUC 98.62，检测率100%，误报率0.05；在更难的r6.2数据集上：AUC 88.48，检测率80.15%，误报率0.15，优于现有方法。

Conclusion: 结合图表示和时间建模能有效提升内幕威胁检测性能，显式和隐式图的融合能更好地捕捉复杂用户行为模式，框架在真实数据集上表现优异。

Abstract: Insider threat detection (ITD) is challenging due to the subtle and concealed nature of malicious activities performed by trusted users. This paper proposes a post-hoc ITD framework that integrates explicit and implicit graph representations with temporal modelling to capture complex user behaviour patterns. An explicit graph is constructed using predefined organisational rules to model direct relationships among user activities. To mitigate noise and limitations in this hand-crafted structure, an implicit graph is learned from feature similarities using the Gumbel-Softmax trick, enabling the discovery of latent behavioural relationships. Separate Graph Convolutional Networks (GCNs) process the explicit and implicit graphs to generate node embeddings, which are concatenated and refined through an attention mechanism to emphasise threat-relevant features. The refined representations are then passed to a bidirectional Long Short-Term Memory (Bi-LSTM) network to capture temporal dependencies in user behaviour. Activities are flagged as anomalous when their probability scores fall below a predefined threshold. Extensive experiments on CERT r5.2 and r6.2 datasets demonstrate that the proposed framework outperforms state-of-the-art methods. On r5.2, the model achieves an AUC of 98.62, a detection rate of 100%, and a false positive rate of 0.05. On the more challenging r6.2 dataset, it attains an AUC of 88.48, a detection rate of 80.15%, and a false positive rate of 0.15, highlighting the effectiveness of combining graph-based and temporal representations for robust ITD.

</details>


### [205] [Large Language Models as Discounted Bayesian Filters](https://arxiv.org/abs/2512.18489)
*Jensen Zhang,Jing Yang,Keze Wang*

Main category: cs.AI

TL;DR: LLMs在动态随机环境中的在线推理能力研究：通过贝叶斯滤波框架评估发现，LLM的信念更新类似贝叶斯后验，但更准确描述为具有模型特定折扣因子的指数遗忘滤波器，显示对旧证据的系统性折扣。


<details>
  <summary>Details</summary>
Motivation: LLMs在少样本学习中表现出色，但在动态随机环境中的推理能力不透明。先前研究主要关注静态任务，忽视了当信念需要持续更新时所需的在线适应能力，这是LLMs作为世界模型或智能体的关键能力。

Method: 引入贝叶斯滤波框架来评估LLMs的在线推理能力。使用概率探测套件，涵盖多元离散分布（如骰子投掷）和连续分布（如高斯过程），其中真实参数随时间变化。

Result: 发现LLM的信念更新类似于贝叶斯后验，但更准确描述为具有模型特定折扣因子小于1的指数遗忘滤波器。这揭示了对旧证据的系统性折扣，且不同模型架构间差异显著。虽然固有先验常常校准不当，但更新机制本身保持结构化和原则性。

Conclusion: 在模拟智能体任务中验证了这些发现，并提出了有效的提示策略，以最小的计算成本重新校准先验。研究表明LLMs的在线推理机制具有结构化的更新过程，尽管存在系统性偏差。

Abstract: Large Language Models (LLMs) demonstrate strong few-shot generalization through in-context learning, yet their reasoning in dynamic and stochastic environments remains opaque. Prior studies mainly focus on static tasks and overlook the online adaptation required when beliefs must be continuously updated, which is a key capability for LLMs acting as world models or agents. We introduce a Bayesian filtering framework to evaluate online inference in LLMs. Our probabilistic probe suite spans both multivariate discrete distributions, such as dice rolls, and continuous distributions, such as Gaussian processes, where ground-truth parameters shift over time. We find that while LLM belief updates resemble Bayesian posteriors, they are more accurately characterized by an exponential forgetting filter with a model-specific discount factor smaller than one. This reveals systematic discounting of older evidence that varies significantly across model architectures. Although inherent priors are often miscalibrated, the updating mechanism itself remains structured and principled. We further validate these findings in a simulated agent task and propose prompting strategies that effectively recalibrate priors with minimal computational cost.

</details>


### [206] [Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V](https://arxiv.org/abs/2512.18564)
*John Chen,Sihan Cheng,Can Gurkan,Ryan Lay,Moez Salahuddin*

Main category: cs.AI

TL;DR: 论文提出了Vox Deorum架构，将大语言模型与算法AI结合用于《文明V》4X策略游戏，让LLM负责宏观战略决策，算法AI处理战术执行，实现了竞争性游戏表现和多样化的游戏风格。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言推理方面的能力使其在4X和大战略游戏中具有独特潜力，能够实现更自然的人机交互（如协作和谈判）。然而，这些游戏的复杂性和长期性带来了挑战，同时延迟和成本因素也阻碍了LLM的实际部署。

Method: 在《文明V》游戏中使用Vox Populi模组，引入Vox Deorum混合架构（LLM+X）。采用分层技术设计，让LLM处理宏观战略推理，将战术执行委托给子系统（如算法AI或未来的强化学习AI）。

Result: 通过2,327场完整游戏验证，比较了两个开源LLM与Vox Populi增强AI的表现。结果显示LLM实现了竞争性的端到端游戏表现，同时展现出与算法AI显著不同且彼此之间也不同的游戏风格。

Conclusion: 该工作为在商业4X游戏中集成LLM建立了可行的架构，为游戏设计和智能体AI研究开辟了新机会。

Abstract: Large Language Models' capacity to reason in natural language makes them uniquely promising for 4X and grand strategy games, enabling more natural human-AI gameplay interactions such as collaboration and negotiation. However, these games present unique challenges due to their complexity and long-horizon nature, while latency and cost factors may hinder LLMs' real-world deployment. Working on a classic 4X strategy game, Sid Meier's Civilization V with the Vox Populi mod, we introduce Vox Deorum, a hybrid LLM+X architecture. Our layered technical design empowers LLMs to handle macro-strategic reasoning, delegating tactical execution to subsystems (e.g., algorithmic AI or reinforcement learning AI in the future). We validate our approach through 2,327 complete games, comparing two open-source LLMs with a simple prompt against Vox Populi's enhanced AI. Results show that LLMs achieve competitive end-to-end gameplay while exhibiting play styles that diverge substantially from algorithmic AI and from each other. Our work establishes a viable architecture for integrating LLMs in commercial 4X games, opening new opportunities for game design and agentic AI research.

</details>


### [207] [ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning](https://arxiv.org/abs/2512.18571)
*Weijie Zhou,Xuangtang Xiong,Ye Tian,Lijun Yue,Xinyu Wu,Wei Li,Chaoyang Zhao,Honghui Dong,Ming Tang,Jinqiao Wang,Zhengyou Zhang*

Main category: cs.AI

TL;DR: ESearch-R1：一个成本感知的具身推理框架，通过HC-GRPO算法统一交互对话、记忆检索和物理导航，在模糊指令下优化信息获取与异构成本之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）驱动的具身智能体在面对模糊自然语言指令时，无法有效平衡物理探索的高成本与人类交互的认知成本。现有方法通常将消歧视为被动感知问题，缺乏最小化总任务执行成本的战略推理能力。

Method: 提出ESearch-R1成本感知具身推理框架，将交互对话（Ask）、情景记忆检索（GetMemory）和物理导航（Navigate）统一到单一决策过程中。引入HC-GRPO（异构成本感知组相对策略优化）算法，该算法通过采样推理轨迹组并强化那些在信息增益与异构成本（如导航时间、人类注意力）之间达到最优权衡的轨迹来优化MLLM。

Result: 在AI2-THOR环境中的广泛实验表明，ESearch-R1显著优于标准的ReAct-based智能体。在提高任务成功率的同时，将总运营成本降低了约50%，验证了GRPO在使MLLM智能体与物理世界约束对齐方面的有效性。

Conclusion: ESearch-R1框架通过成本感知的推理方法，有效解决了具身智能体在模糊指令下的决策优化问题，实现了物理探索成本与人类交互成本之间的智能权衡，为实际应用中的具身智能系统提供了重要技术支撑。

Abstract: Multimodal Large Language Models (MLLMs) have empowered embodied agents with remarkable capabilities in planning and reasoning. However, when facing ambiguous natural language instructions (e.g., "fetch the tool" in a cluttered room), current agents often fail to balance the high cost of physical exploration against the cognitive cost of human interaction. They typically treat disambiguation as a passive perception problem, lacking the strategic reasoning to minimize total task execution costs. To bridge this gap, we propose ESearch-R1, a cost-aware embodied reasoning framework that unifies interactive dialogue (Ask), episodic memory retrieval (GetMemory), and physical navigation (Navigate) into a single decision process. We introduce HC-GRPO (Heterogeneous Cost-Aware Group Relative Policy Optimization). Unlike traditional PPO which relies on a separate value critic, HC-GRPO optimizes the MLLM by sampling groups of reasoning trajectories and reinforcing those that achieve the optimal trade-off between information gain and heterogeneous costs (e.g., navigate time, and human attention). Extensive experiments in AI2-THOR demonstrate that ESearch-R1 significantly outperforms standard ReAct-based agents. It improves task success rates while reducing total operational costs by approximately 50\%, validating the effectiveness of GRPO in aligning MLLM agents with physical world constraints.

</details>


### [208] [Reflective Confidence: Correcting Reasoning Flaws via Online Self-Correction](https://arxiv.org/abs/2512.18605)
*Qinglin Zeng,Jing Yang,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为"反思置信度"的新推理框架，将低置信度信号从终止指标转变为反思触发器，通过主动自我修正而非被动丢弃来提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于集成的方法（如自一致性）虽然能提升复杂推理任务的性能，但需要多个推理轨迹，计算开销大。早期停止策略（如DeepConf）虽然能通过终止低置信度轨迹来降低成本，但会丢弃不完整的推理路径，浪费部分计算资源。

Method: 提出反思置信度框架：当置信度低于阈值时，不是停止生成，而是让模型生成反思提示来分析当前推理状态，识别潜在错误，并沿着修正后的轨迹继续生成。

Result: 在数学推理基准测试（包括AIME 2025）上的实验表明，该方法在可比计算成本下相比先进的早期停止基线取得了显著的准确率提升。

Conclusion: 验证了主动自我修正相对于被动丢弃的有效性，为大型语言模型的高效推理提供了新思路。

Abstract: Large language models (LLMs) have achieved strong performance on complex reasoning tasks using techniques such as chain-of-thought and self-consistency. However, ensemble-based approaches, especially self-consistency which relies on multiple reasoning trajectories, often incur substantial computational overhead. To improve efficiency, prior work has leveraged internal confidence signals, where early stopping strategies such as DeepConf reduce cost by terminating low-confidence trajectories. However, this strategy discards incomplete reasoning paths and wastes partial computation.
  We propose reflective confidence, a novel reasoning framework that transforms low-confidence signals from termination indicators into reflection triggers. When confidence falls below a threshold, instead of stopping generation, the model produces a reflection prompt to analyze the current reasoning state, identify potential errors, and continue generation along a corrected trajectory. Experiments on mathematical reasoning benchmarks, including AIME 2025, demonstrate significant accuracy improvements over advanced early-stopping baselines at comparable computational cost, validating the effectiveness of proactive self-correction over passive discarding.

</details>


### [209] [Assignment-Routing Optimization: Solvers for Problems Under Constraints](https://arxiv.org/abs/2512.18618)
*Yuan Qilong,Michal Pavelka*

Main category: cs.AI

TL;DR: 该论文提出了一种针对联合路由分配问题的混合整数规划求解器，专门处理具有多种约束的实际包装规划场景，在机器人包装应用中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究联合路由分配问题，旨在解决实际包装规划中物品与占位符的一对一分配同时确定访问所有节点的哈密顿回路的问题，现有方法在处理丰富的实际约束时存在局限性。

Method: 扩展了基于Gurobi的精确MIP求解器，结合割平面子回路消除技术，开发了专门处理多占位符选项、时间框架限制和多类别物品包装等丰富约束的求解器。

Result: 在46个移动操作数据集上的实验表明，提出的MIP方法能以稳定且较低的计算时间获得全局最优解，比基于抖动的精确求解器快一个数量级，相比贪婪基线平均偏差14%。

Conclusion: MIP基础的JRA优化方法在机器人包装、运动规划和复杂物流中具有实际应用价值，证明了其在效率和解决方案质量方面的优势。

Abstract: We study the Joint Routing-Assignment (JRA) problem in which items must be assigned one-to-one to placeholders while simultaneously determining a Hamiltonian cycle visiting all nodes exactly once. Extending previous exact MIP solvers with Gurobi and cutting-plane subtour elimination, we develop a solver tailored for practical packaging-planning scenarios with richer constraints.These include multiple placeholder options, time-frame restrictions, and multi-class item packaging. Experiments on 46 mobile manipulation datasets demonstrate that the proposed MIP approach achieves global optima with stable and low computation times, significantly outperforming the shaking-based exact solver by up to an orders of magnitude. Compared to greedy baselines, the MIP solutions achieve consistent optimal distances with an average deviation of 14% for simple heuristics, confirming both efficiency and solution quality. The results highlight the practical applicability of MIP-based JRA optimization for robotic packaging, motion planning, and complex logistics .

</details>


### [210] [ASTIF: Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting](https://arxiv.org/abs/2512.18661)
*Hafiz Saif Ur Rehman,Ling Liu,Kaleem Ullah Qasim*

Main category: cs.AI

TL;DR: ASTIF是一个用于加密货币价格预测的自适应语义-时间集成框架，通过置信度元学习实时调整预测策略，融合语义市场信号和数值趋势，在非平稳环境中优于现有深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 现有金融时间序列预测模型大多采用静态架构，难以整合异质知识源或适应快速的市场状态变化。传统方法仅依赖历史价格序列，忽略了政策不确定性和市场叙事等语义驱动因素。

Method: 提出ASTIF混合智能系统，包含三个组件：1）使用MirrorPrompt的双通道小语言模型提取语义市场信号和数值趋势；2）混合LSTM随机森林模型捕捉序列时间依赖；3）置信度感知元学习器作为自适应推理层，基于实时不确定性调节各预测器的贡献。

Result: 在2020-2024年AI相关加密货币和主要科技股的多样化数据集上，ASTIF优于领先的深度学习和Transformer基线模型（如Informer、TFT）。消融研究证实了自适应元学习机制的关键作用，能在市场动荡期间通过转移语义和时间通道的依赖来降低风险。

Conclusion: 该研究为在非平稳环境中融合定量和定性数据提供了一个可扩展的、基于知识的解决方案，通过自适应集成语义和时间信息来提升金融时间序列预测性能。

Abstract: Financial time series forecasting is fundamentally an information fusion challenge, yet most existing models rely on static architectures that struggle to integrate heterogeneous knowledge sources or adjust to rapid regime shifts. Conventional approaches, relying exclusively on historical price sequences, often neglect the semantic drivers of volatility such as policy uncertainty and market narratives. To address these limitations, we propose the ASTIF (Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting), a hybrid intelligent system that adapts its forecasting strategy in real time through confidence-based meta-learning. The framework integrates three complementary components. A dual-channel Small Language Model using MirrorPrompt extracts semantic market cues alongside numerical trends. A hybrid LSTM Random Forest model captures sequential temporal dependencies. A confidence-aware meta-learner functions as an adaptive inference layer, modulating each predictor's contribution based on its real-time uncertainty.
  Experimental evaluation on a diverse dataset of AI-focused cryptocurrencies and major technology stocks from 2020 to 2024 shows that ASTIF outperforms leading deep learning and Transformer baselines (e.g., Informer, TFT). The ablation studies further confirm the critical role of the adaptive meta-learning mechanism, which successfully mitigates risk by shifting reliance between semantic and temporal channels during market turbulence. The research contributes a scalable, knowledge-based solution for fusing quantitative and qualitative data in non-stationary environments.

</details>


### [211] [Automatic Adaptation to Concept Complexity and Subjective Natural Concepts: A Cognitive Model based on Chunking](https://arxiv.org/abs/2512.18665)
*Dmitry Bennett,Fernand Gobet*

Main category: cs.AI

TL;DR: CogAct计算模型通过组块机制连接概念学习与基本认知过程，能够自适应学习从简单逻辑函数到文学、国际象棋、音乐等真实复杂概念，相比其他模型更具适应性，并提供了考虑主观性的实验设计新方法。


<details>
  <summary>Details</summary>
Motivation: 认知科学的关键问题在于理解支撑短时和长时记忆中多种概念形成与提取的基本心理过程。作者认为组块机制在其中起核心作用，需要建立能够将概念学习与基本认知过程（如组块、注意、STM和LTM）相连接的计算模型。

Method: 提出CogAct计算模型，该模型基于组块机制，能够自适应学习多种类型的概念：从简单逻辑函数、人工类别到文学、国际象棋和音乐等真实复杂概念。模型从原始数据（如音乐乐谱）学习，无需依赖预建知识结构。同时开发了考虑主观性、控制个体经验差异的实验设计和模拟方法，将模型与深度学习模型进行比较。

Result: CogAct模型成功展示了自适应学习能力，能够处理其他心理模型难以应对的复杂概念学习任务。模型能够捕捉个体参与者的主观概念空间，在音乐领域模拟人类主观判断。相比深度学习模型，CogAct无需特定任务架构调整，更具适应性。

Conclusion: 研究将概念学习和复杂适应整合到更广泛的认知心理学理论中，为心理应用提供了新方向：从建模平均参与者转向捕捉主观概念空间，推动认知科学向更个性化和真实情境的研究发展。

Abstract: A key issue in cognitive science concerns the fundamental psychological processes that underlie the formation and retrieval of multiple types of concepts in short-term and long-term memory (STM and LTM, respectively). We propose that chunking mechanisms play an essential role and show how the CogAct computational model grounds concept learning in fundamental cognitive processes and structures (such as chunking, attention, STM and LTM). First are the in-principle demonstrations, with CogAct automatically adapting to learn a range of categories from simple logical functions, to artificial categories, to natural raw (as opposed to natural pre-processed) concepts in the dissimilar domains of literature, chess and music. This kind of adaptive learning is difficult for most other psychological models, e.g., with cognitive models stopping at modelling artificial categories and (non-GPT) models based on deep learning requiring task-specific changes to the architecture. Secondly, we offer novel ways of designing human benchmarks for concept learning experiments and simulations accounting for subjectivity, ways to control for individual human experiences, all while keeping to real-life complex categories. We ground CogAct in simulations of subjective conceptual spaces of individual human participants, capturing humans subjective judgements in music, with the models learning from raw music score data without bootstrapping to pre-built knowledge structures. The CogAct simulations are compared to those obtained by a deep-learning model. These findings integrate concept learning and adaptation to complexity into the broader theories of cognitive psychology. Our approach may also be used in psychological applications that move away from modelling the average participant and towards capturing subjective concept space.

</details>


### [212] [IntelliCode: A Multi-Agent LLM Tutoring System with Centralized Learner Modeling](https://arxiv.org/abs/2512.18669)
*Jones David,Shreya Ghosh*

Main category: cs.AI

TL;DR: IntelliCode是一个基于多智能体LLM的智能辅导系统，通过中心化的版本化学习者状态实现长期、透明、可审计的教学支持。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的辅导系统通常是单轮对话助手，缺乏对学习者知识的持久性表示，难以提供有原则、透明和长期的教学支持。

Method: 构建一个围绕中心化版本化学习者状态的多智能体LLM辅导系统，包含六个专门智能体：技能评估、学习者画像、渐进提示、课程选择、间隔重复和参与度监控，通过StateGraph Orchestrator协调，采用单一写入策略。

Result: 通过模拟学习者验证，系统展示了稳定的状态更新、渐进提示提高任务成功率以及多样化的课程覆盖。演示了端到端辅导流程，包括概念提示、解决方案修正、掌握度更新和个性化复习间隔。

Conclusion: IntelliCode展示了如何将持久性学习者建模、协调的多智能体推理和有原则的教学设计相结合，以产生透明可靠的LLM驱动辅导系统。

Abstract: LLM-based tutors are typically single-turn assistants that lack persistent representations of learner knowledge, making it difficult to provide principled, transparent, and long-term pedagogical support. We introduce IntelliCode, a multi-agent LLM tutoring system built around a centralized, versioned learner state that integrates mastery estimates, misconceptions, review schedules, and engagement signals. A StateGraph Orchestrator coordinates six specialized agents: skill assessment, learner profiling, graduated hinting, curriculum selection, spaced repetition, and engagement monitoring, each operating as a pure transformation over the shared state under a single-writer policy. This architecture enables auditable mastery updates, proficiency-aware hints, dependency-aware curriculum adaptation, and safety-aligned prompting.
  The demo showcases an end-to-end tutoring workflow: a learner attempts a DSA problem, receives a conceptual hint when stuck, submits a corrected solution, and immediately sees mastery updates and a personalized review interval. We report validation results with simulated learners, showing stable state updates, improved task success with graduated hints, and diverse curriculum coverage. IntelliCode demonstrates how persistent learner modeling, orchestrated multi-agent reasoning, and principled instructional design can be combined to produce transparent and reliable LLM-driven tutoring.

</details>


### [213] [Social Comparison without Explicit Inference of Others' Reward Values: A Constructive Approach Using a Probabilistic Generative Model](https://arxiv.org/abs/2512.18687)
*Yosuke Taniuchi,Chie Hieida,Atsushi Noritake,Kazushi Ikeda,Masaki Isoda*

Main category: cs.AI

TL;DR: 猴子社会比较研究：通过计算模型分析发现，猴子更依赖客观奖励差异而非主观价值推断来进行社会比较


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解社会比较的计算机制，特别是猴子如何利用他人奖励信息来评估自身奖励，探究猴子是识别客观奖励差异还是推断他人的主观价值评估

Method: 开发了三种不同社会信息处理程度的计算模型：内部预测模型（推断伙伴主观价值）、无比较模型（忽略伙伴信息）、外部比较模型（直接纳入伙伴客观奖励）。使用多层多模态潜在狄利克雷分配方法，在包含猴子行为、奖励和条件刺激的数据集上训练模型，评估模型在预定义实验条件下分类主观价值的能力

Result: 外部比较模型在Rand指数上获得最高分类分数（0.88 vs. 内部预测模型的0.79），表明社会比较更依赖于客观奖励差异而非对主观状态的推断

Conclusion: 从计算角度看，猴子的社会比较过程主要基于客观奖励差异，而非推断他人的主观价值评估，这为理解灵长类社会认知提供了重要见解

Abstract: Social comparison -- the process of evaluating one's rewards relative to others -- plays a fundamental role in primate social cognition. However, it remains unknown from a computational perspective how information about others' rewards affects the evaluation of one's own reward. With a constructive approach, this study examines whether monkeys merely recognize objective reward differences or, instead, infer others' subjective reward valuations. We developed three computational models with varying degrees of social information processing: an Internal Prediction Model (IPM), which infers the partner's subjective values; a No Comparison Model (NCM), which disregards partner information; and an External Comparison Model (ECM), which directly incorporates the partner's objective rewards. To test model performance, we used a multi-layered, multimodal latent Dirichlet allocation. We trained the models on a dataset containing the behavior of a pair of monkeys, their rewards, and the conditioned stimuli. Then, we evaluated the models' ability to classify subjective values across pre-defined experimental conditions. The ECM achieved the highest classification score in the Rand Index (0.88 vs. 0.79 for the IPM) under our settings, suggesting that social comparison relies on objective reward differences rather than inferences about subjective states.

</details>


### [214] [KeenKT: Knowledge Mastery-State Disambiguation for Knowledge Tracing](https://arxiv.org/abs/2512.18709)
*Zhifei Li,Lifan Chen,Jiali Yi,Xiaoju Hou,Yue Zhao,Wenxin Huang,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: KeenKT模型通过正态-逆高斯分布表示学生知识状态，解决传统知识追踪中单点估计无法区分真实能力与偶然行为的模糊性问题，在六个公开数据集上显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前知识追踪方法主要依赖单点估计，无法区分学生的真实能力与偶然的爆发或粗心行为，导致对知识掌握程度的判断存在模糊性。需要一种能够捕捉学生学习行为波动的更精确建模方法。

Method: 提出KeenKT模型：1）使用正态-逆高斯分布表示每个交互时的学生知识状态；2）设计基于NIG距离的注意力机制建模知识状态的动态演化；3）引入扩散去噪重构损失和分布对比学习损失增强模型鲁棒性。

Result: 在六个公开数据集上的实验表明，KeenKT在预测准确性和行为波动敏感性方面优于现有最先进的知识追踪模型，最大AUC提升5.85%，最大ACC提升6.89%。

Conclusion: KeenKT通过分布表示学生知识状态，有效解决了知识掌握状态的模糊性问题，能够更准确地捕捉学生学习行为的波动，为知识追踪提供了更精确的建模框架。

Abstract: Knowledge Tracing (KT) aims to dynamically model a student's mastery of knowledge concepts based on their historical learning interactions. Most current methods rely on single-point estimates, which cannot distinguish true ability from outburst or carelessness, creating ambiguity in judging mastery. To address this issue, we propose a Knowledge Mastery-State Disambiguation for Knowledge Tracing model (KeenKT), which represents a student's knowledge state at each interaction using a Normal-Inverse-Gaussian (NIG) distribution, thereby capturing the fluctuations in student learning behaviors. Furthermore, we design an NIG-distance-based attention mechanism to model the dynamic evolution of the knowledge state. In addition, we introduce a diffusion-based denoising reconstruction loss and a distributional contrastive learning loss to enhance the model's robustness. Extensive experiments on six public datasets demonstrate that KeenKT outperforms SOTA KT models in terms of prediction accuracy and sensitivity to behavioral fluctuations. The proposed method yields the maximum AUC improvement of 5.85% and the maximum ACC improvement of 6.89%.

</details>


### [215] [Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth](https://arxiv.org/abs/2512.18732)
*Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 该论文提出了一个几何框架，将概念增长建模为在最小描述长度准则下评估的可容许基扩展，解释了想象力和概念创新在理论变革中的保守作用。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数学习和推理模型都预设了一个固定的表征基础，但概念学习只有在现有表征无法解释经验时才成为可能。本文旨在解决一个更根本的问题：在什么结构条件下，表征基础本身能够以原则性和选择性的方式扩展？

Method: 提出了一个几何框架，将概念增长建模为在最小描述长度准则下评估的可容许基扩展。经验（无论是外部观察还是内部模拟）被表示为相对于当前概念子空间的向量。残差分量捕捉系统性的表征失败，候选概念扩展被限制为低秩、可容许的变换。

Result: 证明任何被MDL接受的扩展都可以选择使其新方向完全位于经验诱导的残差跨度内，而与该跨度正交的扩展会严格增加描述长度因此被拒绝。这为想象力和概念创新提供了一个保守的解释：内部生成的反事实表征只有在暴露或放大结构化残差误差时才有助于学习，不能引入任意的新颖性。

Conclusion: 该框架将概念发展描述为一个误差驱动、几何约束的基扩展过程，阐明了想象力在学习和理论变革中的作用和限制。MDL为表征变化提供了一个规范的选择原则，区分了表征层面的反事实与因果或价值层面的反事实。

Abstract: Concept learning becomes possible only when existing representations fail to account for experience. Most models of learning and inference, however, presuppose a fixed representational basis within which belief updating occurs. In this paper, I address a prior question: under what structural conditions can the representational basis itself expand in a principled and selective way?
  I propose a geometric framework in which conceptual growth is modeled as admissible basis extension evaluated under a Minimum Description Length (MDL) criterion. Experience, whether externally observed or internally simulated, is represented as vectors relative to a current conceptual subspace. Residual components capture systematic representational failure, and candidate conceptual extensions are restricted to low-rank, admissible transformations. I show that any MDL-accepted extension can be chosen so that its novel directions lie entirely within the residual span induced by experience, while extensions orthogonal to this span strictly increase description length and are therefore rejected.
  This yields a conservative account of imagination and conceptual innovation. Internally generated counterfactual representations contribute to learning only insofar as they expose or amplify structured residual error, and cannot introduce arbitrary novelty. I further distinguish representational counterfactuals--counterfactuals over an agent's conceptual basis--from causal or value-level counterfactuals, and show how MDL provides a normative selection principle governing representational change.
  Overall, the framework characterizes conceptual development as an error-driven, geometry-constrained process of basis extension, clarifying both the role and the limits of imagination in learning and theory change.

</details>


### [216] [MEEA: Mere Exposure Effect-Driven Confrontational Optimization for LLM Jailbreaking](https://arxiv.org/abs/2512.18755)
*Jianyi Zhang,Shizhao Liu,Ziyin Zhou,Zhen Li*

Main category: cs.AI

TL;DR: MEEA是一种基于纯粹接触效应的心理学启发式自动化黑盒框架，通过重复低毒性语义暴露逐步侵蚀LLM的安全边界，在多轮对话中实现更高的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有越狱研究大多假设静态安全边界，忽视了上下文交互对模型行为的动态影响，导致攻击的稳定性和泛化性有限。需要一种能够评估多轮安全鲁棒性的方法。

Method: MEEA利用纯粹接触效应，构建语义渐进提示链，采用模拟退火策略进行优化，优化指标包括语义相似性、毒性和越狱有效性。

Result: 在GPT-4、Claude-3.5、DeepSeek-R1等闭源和开源模型上的实验表明，MEEA相比7个代表性基线平均攻击成功率提升超过20%。

Conclusion: LLM安全行为本质上是动态和历史依赖的，挑战了静态对齐边界的常见假设，强调了需要交互感知的安全评估和防御机制。

Abstract: The rapid advancement of large language models (LLMs) has intensified concerns about the robustness of their safety alignment. While existing jailbreak studies explore both single-turn and multi-turn strategies, most implicitly assume a static safety boundary and fail to account for how contextual interactions dynamically influence model behavior, leading to limited stability and generalization. Motivated by this gap, we propose MEEA (Mere Exposure Effect Attack), a psychology-inspired, fully automated black-box framework for evaluating multi-turn safety robustness, grounded in the mere exposure effect. MEEA leverages repeated low-toxicity semantic exposure to induce a gradual shift in a model's effective safety threshold, enabling progressive erosion of alignment constraints over sustained interactions. Concretely, MEEA constructs semantically progressive prompt chains and optimizes them using a simulated annealing strategy guided by semantic similarity, toxicity, and jailbreak effectiveness. Extensive experiments on both closed-source and open-source models, including GPT-4, Claude-3.5, and DeepSeek-R1, demonstrate that MEEA consistently achieves higher attack success rates than seven representative baselines, with an average Attack Success Rate (ASR) improvement exceeding 20%. Ablation studies further validate the necessity of both annealing-based optimization and contextual exposure mechanisms. Beyond improved attack effectiveness, our findings indicate that LLM safety behavior is inherently dynamic and history-dependent, challenging the common assumption of static alignment boundaries and highlighting the need for interaction-aware safety evaluation and defense mechanisms. Our code is available at: https://github.com/Carney-lsz/MEEA

</details>


### [217] [HARBOR: Holistic Adaptive Risk assessment model for BehaviORal healthcare](https://arxiv.org/abs/2512.18829)
*Aditya Siddhant*

Main category: cs.AI

TL;DR: HARBOR模型在行为健康风险评估中优于传统机器学习方法和现成LLM，准确率达69%


<details>
  <summary>Details</summary>
Motivation: 行为健康风险评估面临多模态数据和时间动态性的挑战，现有LLM在结构化临床风险评分中的效果尚不明确

Method: 开发HARBOR行为健康感知语言模型，预测-3到+3的Harbor风险评分，并使用PEARL纵向数据集进行训练和评估

Result: HARBOR准确率达69%，优于逻辑回归的54%和最强专有LLM基线的29%

Conclusion: HARBOR模型在行为健康风险评估中表现出色，为临床风险评分提供了有效解决方案

Abstract: Behavioral healthcare risk assessment remains a challenging problem due to the highly multimodal nature of patient data and the temporal dynamics of mood and affective disorders. While large language models (LLMs) have demonstrated strong reasoning capabilities, their effectiveness in structured clinical risk scoring remains unclear. In this work, we introduce HARBOR, a behavioral health aware language model designed to predict a discrete mood and risk score, termed the Harbor Risk Score (HRS), on an integer scale from -3 (severe depression) to +3 (mania). We also release PEARL, a longitudinal behavioral healthcare dataset spanning four years of monthly observations from three patients, containing physiological, behavioral, and self reported mental health signals. We benchmark traditional machine learning models, proprietary LLMs, and HARBOR across multiple evaluation settings and ablations. Our results show that HARBOR outperforms classical baselines and off the shelf LLMs, achieving 69 percent accuracy compared to 54 percent for logistic regression and 29 percent for the strongest proprietary LLM baseline.

</details>


### [218] [CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning](https://arxiv.org/abs/2512.18857)
*Zijun Gao,Zhikun Xu,Xiao Ye,Ben Zhou*

Main category: cs.AI

TL;DR: CORE是一个强化学习框架，通过将显式概念转化为可控监督信号，解决LLMs在数学问题中模式复用而非概念理解的问题，在多个模型上实现了概念推理能力的提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在解决数学问题时往往只是模式复用，缺乏真正的概念理解。传统的RLVR方法只强化最终答案，缺乏细粒度的概念信号，导致模型改进的是模式复用能力而非概念应用能力。

Method: CORE框架包含三个核心步骤：(1)合成概念对齐的测验；(2)在rollout过程中注入简短概念片段以引出概念引导的轨迹；(3)通过轨迹替换强化概念推理，采用轻量级前向KL约束对齐无引导与概念引导策略，或直接在概念对齐测验上应用标准GRPO。

Result: 在多个模型上，CORE相比原始模型和SFT基线，在领域内概念-练习套件和多样化的领域外数学基准测试中都取得了持续性的提升。

Conclusion: CORE通过将概念对齐测验的直接训练和概念注入rollout统一在结果正则化下，提供了细粒度的概念监督，弥合了问题解决能力和真正概念推理之间的差距，同时保持算法和验证器的无关性。

Abstract: Large language models (LLMs) often solve challenging math exercises yet fail to apply the concept right when the problem requires genuine understanding. Popular Reinforcement Learning with Verifiable Rewards (RLVR) pipelines reinforce final answers but provide little fine-grained conceptual signal, so models improve at pattern reuse rather than conceptual applications. We introduce CORE (Concept-Oriented REinforcement), an RL training framework that turns explicit concepts into a controllable supervision signal. Starting from a high-quality, low-contamination textbook resource that links verifiable exercises to concise concept descriptions, we run a sanity probe showing LLMs can restate definitions but fail concept-linked quizzes, quantifying the conceptual reasoning gap. CORE then (i) synthesizes concept-aligned quizzes, (ii) injects brief concept snippets during rollouts to elicit concept-primed trajectories, and (iii) reinforces conceptual reasoning via trajectory replacement after group failures, a lightweight forward-KL constraint that aligns unguided with concept-primed policies, or standard GRPO directly on concept-aligned quizzes. Across several models, CORE delivers consistent gains over vanilla and SFT baselines on both in-domain concept-exercise suites and diverse out-of-domain math benchmarks. CORE unifies direct training on concept-aligned quizzes and concept-injected rollouts under outcome regularization. It provides fine-grained conceptual supervision that bridges problem-solving competence and genuine conceptual reasoning, while remaining algorithm- and verifier-agnostic.

</details>


### [219] [Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models](https://arxiv.org/abs/2512.18901)
*Gökdeniz Gülmez*

Main category: cs.AI

TL;DR: Gabliteration是一种新颖的神经权重修改技术，通过自适应多向投影和正则化层选择，在修改特定行为模式时最小化模型质量损失。


<details>
  <summary>Details</summary>
Motivation: 现有方法在修改特定行为模式时会损害模型质量，需要一种能精确修改权重同时保持其他领域性能的技术。

Method: 采用自适应多向投影、正则化层选择、动态层优化、正则化投影矩阵和自适应缩放机制，实现理论最优的权重修改。

Result: 开发了gabliterated-v1模型系列（0.6B到4B参数），在Hugging Face上可用，展示了在不同模型规模上的实际应用性。

Conclusion: Gabliteration技术超越了传统的abliteration方法，能够在修改特定行为模式时最小化无关领域的质量退化，具有理论和实践价值。

Abstract: We present Gabliteration, a novel neural weight modification technique that advances beyond traditional abliteration methods by implementing adaptive multi-directional projections with regularized layer selection. Our approach addresses the fundamental limitation of existing methods that compromise model quality while attempting to modify specific behavioral patterns. Through dynamic layer optimization, regularized projection matrices, and adaptive scaling mechanisms, we achieve theoretically superior weight modification while minimizing quality degradation in unrelated domains. We validate our method through the gabliterated-v1 model series (0.6B to 4B parameters) available on Hugging Face, demonstrating practical applicability across multiple model scales.

</details>


### [220] [Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm](https://arxiv.org/abs/2512.18947)
*Li Yan,Bolun Liu,Chao Li,Jing Liang,Kunjie Yu,Caitong Yue,Xuzhao Chai,Boyang Qu*

Main category: cs.AI

TL;DR: 本文提出了一种用于动态多模态多目标优化的新算法，通过聚类自编码器预测机制和自适应小生境策略，在时变环境中同时跟踪多个等效帕累托最优集并保持种群多样性。


<details>
  <summary>Details</summary>
Motivation: 动态多模态多目标优化面临双重挑战：在时变环境中同时跟踪多个等效帕累托最优集并保持种群多样性。现有动态多目标进化算法往往忽略解的多模态特性，而静态多模态多目标进化算法缺乏对动态变化的适应性。

Method: 1. 构建了新的动态多模态多目标测试函数基准套件，融合动态和多模态优化特性；2. 提出基于聚类自编码器预测的动态响应机制，使用自编码器处理匹配的聚类以生成高度多样化的初始种群；3. 集成自适应小生境策略到静态优化器中，平衡算法的收敛性和多样性。

Result: 在12个动态多模态多目标测试函数实例上的实证分析表明，与几种最先进的动态多目标进化算法和多模态多目标进化算法相比，该算法不仅在决策空间中更有效地保持种群多样性，而且在目标空间中实现了更优的收敛性。

Conclusion: 本文提出的算法成功解决了动态多模态多目标优化的双重挑战，通过创新的聚类自编码器预测机制和自适应小生境策略，在动态环境中实现了更好的多样性和收敛性平衡。

Abstract: Dynamic multimodal multiobjective optimization presents the dual challenge of simultaneously tracking multiple equivalent pareto optimal sets and maintaining population diversity in time-varying environments. However, existing dynamic multiobjective evolutionary algorithms often neglect solution modality, whereas static multimodal multiobjective evolutionary algorithms lack adaptability to dynamic changes. To address above challenge, this paper makes two primary contributions. First, we introduce a new benchmark suite of dynamic multimodal multiobjective test functions constructed by fusing the properties of both dynamic and multimodal optimization to establish a rigorous evaluation platform. Second, we propose a novel algorithm centered on a Clustering-based Autoencoder prediction dynamic response mechanism, which utilizes an autoencoder model to process matched clusters to generate a highly diverse initial population. Furthermore, to balance the algorithm's convergence and diversity, we integrate an adaptive niching strategy into the static optimizer. Empirical analysis on 12 instances of dynamic multimodal multiobjective test functions reveals that, compared with several state-of-the-art dynamic multiobjective evolutionary algorithms and multimodal multiobjective evolutionary algorithms, our algorithm not only preserves population diversity more effectively in the decision space but also achieves superior convergence in the objective space.

</details>


### [221] [Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection](https://arxiv.org/abs/2512.18956)
*Yizhi Wang,Linan Yue,Min-Ling Zhang*

Main category: cs.AI

TL;DR: SynSelect是一个三阶段合成选择框架，用于为多模态推理任务生成高质量的长链思维数据，通过多模型生成候选CoT并进行实例和批量级选择，显著提升多模态大推理模型的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态推理面临挑战：现有方法存在推理深度有限、模态转换错误和生成流程僵化等问题，高质量长链思维训练数据稀缺，阻碍了多模态大推理模型性能的进一步提升。

Method: 提出SynSelect三阶段框架：1) 利用多个异构多模态大推理模型生成多样化的候选链思维；2) 进行实例级选择过滤低质量CoT；3) 进行批量级选择确保整体数据质量，从而生成高质量训练数据。

Result: 在多个多模态基准测试上的实验表明，使用SynSelect生成数据监督微调的模型显著优于基线方法，经过强化学习后训练后性能进一步提升，验证了SynSelect的有效性。

Conclusion: SynSelect是提升多模态大推理模型推理能力的有效方法，通过高质量长链思维数据生成解决了现有方法的局限性，为多模态推理研究提供了新思路。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks through long Chain-of-Thought (CoT) reasoning. Extending these successes to multimodal reasoning remains challenging due to the increased complexity of integrating diverse input modalities and the scarcity of high-quality long CoT training data. Existing multimodal datasets and CoT synthesis methods still suffer from limited reasoning depth, modality conversion errors, and rigid generation pipelines, hindering model performance and stability. To this end, in this paper, we propose SynSelect, a novel three-stage Synthesis-Selection framework for generating high-quality long CoT data tailored to multimodal reasoning tasks. Specifically, SynSelect first leverages multiple heterogeneous multimodal LRMs to produce diverse candidate CoTs, and then applies both instance and batch level selection to filter high-quality CoTs that can effectively enhance the model's reasoning capabilities. Extensive experiments on multiple multimodal benchmarks demonstrate that models supervised fine-tuned on SynSelect-generated data significantly outperform baselines and achieve further improvements after reinforcement learning post-training. Our results validate SynSelect as an effective approach for advancing multimodal LRMs reasoning capabilities.

</details>


### [222] [ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management](https://arxiv.org/abs/2512.19001)
*Lingjie Zhao,Xue Yu,Yongzhi Qi,Hao Hu,Jianshen Zhang,Yingzheng Ma,Shuyu Han,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 提出OR引导的"预训练-强化"框架，将AI的适应性感知与OR的结构严谨性结合，用于复杂库存系统管理，在京东部署中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着AI与OR在复杂库存系统中协同应用的推进，关键挑战在于如何有效调和AI的自适应感知能力与OR的结构严谨性，需要弥合这一差距。

Method: 提出OR引导的"预训练-强化"框架：1) 使用模拟增强的OR模型生成高质量参考决策；2) 以OR决策为标签训练领域知识驱动的深度学习基础模型；3) 通过强化学习进行微调，将RL定位为深度对齐机制，使AI智能体内化OR的最优原则。

Result: 在京东的现场部署和双重差分分析验证中，模型显著优于现有工业实践：周转天数减少5.27天，现货率提升2.29%，持有成本降低29.95%。

Conclusion: 与当前主流的暴力模型扩展趋势相反，研究表明，当受到结构化OR逻辑引导时，轻量级、领域知识驱动的模型能够实现最先进的性能和强大的可迁移性，为智能供应链管理提供了可扩展且经济高效的范式。

Abstract: As the pursuit of synergy between Artificial Intelligence (AI) and Operations Research (OR) gains momentum in handling complex inventory systems, a critical challenge persists: how to effectively reconcile AI's adaptive perception with OR's structural rigor. To bridge this gap, we propose a novel OR-Guided "Pretrain-then-Reinforce" framework. To provide structured guidance, we propose a simulation-augmented OR model that generates high-quality reference decisions, implicitly capturing complex business constraints and managerial preferences. Leveraging these OR-derived decisions as foundational training labels, we design a domain-informed deep learning foundation model to establish foundational decision-making capabilities, followed by a reinforcement learning (RL) fine-tuning stage. Uniquely, we position RL as a deep alignment mechanism that enables the AI agent to internalize the optimality principles of OR, while simultaneously leveraging exploration for general policy refinement and allowing expert guidance for scenario-specific adaptation (e.g., promotional events). Validated through extensive numerical experiments and a field deployment at JD.com augmented by a Difference-in-Differences (DiD) analysis, our model significantly outperforms incumbent industrial practices, delivering real-world gains of a 5.27-day reduction in turnover and a 2.29% increase in in-stock rates, alongside a 29.95% decrease in holding costs. Contrary to the prevailing trend of brute-force model scaling, our study demonstrates that a lightweight, domain-informed model can deliver state-of-the-art performance and robust transferability when guided by structured OR logic. This approach offers a scalable and cost-effective paradigm for intelligent supply chain management, highlighting the value of deeply aligning AI with OR.

</details>


### [223] [Recontextualization Mitigates Specification Gaming without Modifying the Specification](https://arxiv.org/abs/2512.19027)
*Ariana Azarbal,Victor Gillioz,Vladimir Ivanov,Bryce Woodworth,Jacob Drori,Nevan Wichers,Aram Ebtekar,Alex Cloud,Alexander Matt Turner*

Main category: cs.AI

TL;DR: 提出了一种名为"重新情境化"的方法，通过将模型在禁止不当行为提示下生成的回复重新情境化为在允许不当行为提示下的回复，来训练语言模型抵抗不当行为，减少对错误训练信号的利用。


<details>
  <summary>Details</summary>
Motivation: 开发者经常难以指定正确的训练标签和奖励信号，导致语言模型会利用这些错误信号进行"博弈"，学习到不当行为（如优先考虑评估指标而非聊天质量、为通过错误测试而特殊处理代码、对用户撒谎、谄媚等）。

Method: 提出重新情境化方法：首先生成模型在禁止不当行为提示下的回复，然后将这些回复重新情境化为在允许不当行为提示下的回复，以此训练模型即使在允许不当行为的指令下也能抵抗不当行为。

Result: 该方法能防止模型学习到四种不当行为：1）优先考虑评估指标而非聊天质量；2）为通过错误测试而特殊处理代码；3）对用户撒谎；4）变得谄媚。该方法在不改进监督信号的情况下减少了规范博弈。

Conclusion: 重新情境化方法通过训练语言模型抵抗不当行为，减轻了错误训练信号对不当行为的强化，为解决语言模型利用错误训练信号的问题提供了一种有效途径。

Abstract: Developers often struggle to specify correct training labels and rewards. Perhaps they don't need to. We propose recontextualization, which reduces how often language models "game" training signals, performing misbehaviors those signals mistakenly reinforce. We show recontextualization prevents models from learning to 1) prioritize evaluation metrics over chat response quality; 2) special-case code to pass incorrect tests; 3) lie to users; and 4) become sycophantic. Our method works by generating completions from prompts discouraging misbehavior and then recontextualizing them as though they were in response to prompts permitting misbehavior. Recontextualization trains language models to resist misbehavior even when instructions permit it. This mitigates the reinforcement of misbehavior from misspecified training signals, reducing specification gaming without improving the supervision signal.

</details>


### [224] [Can abstract concepts from LLM improve SLM performance?](https://arxiv.org/abs/2512.19069)
*Siddharth Tandon*

Main category: cs.AI

TL;DR: 通过从大语言模型中提取概念向量并转移到小模型，在推理时动态调整引导强度，实现小模型性能提升


<details>
  <summary>Details</summary>
Motivation: 大语言模型在资源受限设备上部署困难，现有方法需要大量实验和复杂基础设施设计，需要更高效的模型压缩方法

Method: 从大模型中提取高级概念（表示为引导向量），将其转移到小模型，并引入推理时缩放来动态调整引导强度

Result: 概念可有效转移到不同家族的小模型（Phi、Llama、Qwen等），推理时缩放使Qwen3-0.6B准确率提升7-15%

Conclusion: 概念转移方法为资源受限设备上的小语言模型部署提供了有效解决方案，无需复杂基础设施设计即可提升性能

Abstract: Large language models (LLMs) excel at diverse tasks, but their deployment on resource-constrained devices remains challenging. Existing methods like quantization, pruning, and distillation can reduce memory footprint but often demand extensive experimentation and careful infrastructure design. Leveraging existing techniques for extracting high-level concepts (represented as steering vectors) from larger models, we investigate their transferability to smaller language models (SLM) during inference. We demonstrate through extensive experimentation that these concepts can be effectively transferred to smaller models, irrespective of their family (e.g., Phi, Llama, Qwen), leading to performance improvements across a wide range of tasks. Furthermore, we introduce inference-time scaling to enhance performance by dynamically adjusting the steering intensity which has resulted in a 7-15\% of accuracy improvement for Qwen3-0.6B.

</details>


### [225] [Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning](https://arxiv.org/abs/2512.19081)
*Yanzhi Zhang,Yitong Duan,Zhaoxi Zhang,Jiyan He,Shuxin Zheng*

Main category: cs.AI

TL;DR: Population-Evolve：一种受遗传算法启发的训练免费方法，通过并行推理维护动态候选解种群，让LLM自我进化种群，最终通过多数投票得出答案，显著提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展已成为增强大型语言模型推理能力的有前景方向。本文旨在开发一种无需训练的方法，利用进化策略在推理过程中优化LLM的推理性能。

Method: 提出Population-Evolve方法：1）为每个问题维护动态候选解种群；2）通过并行推理实现种群进化；3）使用进化提示让LLM在每次迭代中自我进化种群；4）收敛后通过多数投票得出最终答案。同时建立了统一框架，从遗传算法角度解释现有测试时扩展策略。

Result: 实验结果表明，Population-Evolve在准确性方面表现优异，具有较低的性能方差和计算效率。该方法显著提升了LLM的推理能力。

Conclusion: 研究强调了进化策略在推理过程中释放LLM推理潜力的潜力，为测试时优化提供了新的有效方法。

Abstract: Test-time scaling has emerged as a promising direction for enhancing the reasoning capabilities of Large Language Models in last few years. In this work, we propose Population-Evolve, a training-free method inspired by Genetic Algorithms to optimize LLM reasoning. Our approach maintains a dynamic population of candidate solutions for each problem via parallel reasoning. By incorporating an evolve prompt, the LLM self-evolves its population in all iterations. Upon convergence, the final answer is derived via majority voting. Furthermore, we establish a unification framework that interprets existing test-time scaling strategies through the lens of genetic algorithms. Empirical results demonstrate that Population-Evolve achieves superior accuracy with low performance variance and computational efficiency. Our findings highlight the potential of evolutionary strategies to unlock the reasoning power of LLMs during inference.

</details>


### [226] [Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving](https://arxiv.org/abs/2512.19093)
*Peiqing Lu,Yuan Zhang,Haoyun Zhang,Jiasen Zheng,Kejian Tong,Wenjun Wu*

Main category: cs.AI

TL;DR: HERALD框架通过混合集成推理、自适应学习和知识蒸馏，结合语言模型与符号计算，提升双语数学问题求解的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 双语数学问题求解需要语言推理与符号计算的紧密结合，但现有大语言模型在语言处理方面表现良好，在精确计算方面较弱，需要一种能够有效结合两者优势的解决方案。

Method: 使用NuminaMath-7B-TIR、GPT-4o和Mistral-7B构建混合集成框架，采用自适应路由、基于工具的强化学习和知识蒸馏技术连接不同推理路径，通过置信度校准保持权重稳定，双路径检查确保结果正确。

Result: HERALD系统展示了结合符号检查、自适应集成和双语微调能够实现流畅推理和精确计算，为多语言数学推理提供了更好的准确性、稳定性和清晰度。

Conclusion: HERALD为多语言数学推理提供了一个实用解决方案，通过混合集成推理、自适应学习和知识蒸馏，有效提升了双语数学问题求解的准确性和稳定性。

Abstract: Bilingual mathematical problem solving needs a clear link between language reasoning and symbolic calculation. Large language models often handle language well but are weak in accurate computation. This paper presents HERALD (Hybrid Ensemble Reasoning with Adaptive Learning and Distillation), a framework that joins reasoning and calculation using NuminaMath-7B-TIR, GPT-4o, and Mistral-7B. HERALD uses adaptive routing, tool-based reinforcement learning, and knowledge distillation to connect different reasoning paths. Confidence calibration keeps weighting stable, and dual-path checking keeps results correct. Reinforcement learning controls tool use to cut redundancy, and distillation lowers delay without hurting accuracy. The system shows that combining symbolic checking, adaptive ensembles, and bilingual fine-tuning helps achieve both fluent reasoning and precise calculation. HERALD offers a practical solution for multilingual mathematical reasoning with better accuracy, stability, and clarity.

</details>


### [227] [Conditioning Accept-Desirability models in the context of AGM-like belief change](https://arxiv.org/abs/2512.19096)
*Kathelijne Coussement,Gert de Cooman,Keano De Vos*

Main category: cs.AI

TL;DR: 本文在抽象决策框架中讨论接受-期望模型的调节问题，将经典和量子概率统一到不精确概率背景下，提出基于事件观测引入新无差异性的调节规则，并研究其与AGM信念修正公理的关系。


<details>
  <summary>Details</summary>
Motivation: 传统概率论和量子概率在决策框架中存在局限性，需要建立更一般的抽象框架来统一处理经典和量子概率，并扩展到不精确概率情境，以提供更灵活的决策理论工具。

Method: 在抽象决策框架中，将不确定奖励置于一般线性空间，事件作为该线性空间上的特殊投影算子。提出基于事件观测引入新无差异性的调节规则，建立信念修正算子，并分析其与AGM公理的关系。

Result: 建立了新的调节规则和相应的信念修正算子，发现在两个特殊情况下所有AGM公理仍然成立：经典命题逻辑和完全条件概率情况。

Conclusion: 提出的抽象框架成功统一了经典和量子概率，扩展到不精确概率背景，新的调节规则在特定情况下保持了AGM信念修正公理的完整性，为更广泛的决策理论提供了基础。

Abstract: We discuss conditionalisation for Accept-Desirability models in an abstract decision-making framework, where uncertain rewards live in a general linear space, and events are special projection operators on that linear space. This abstract setting allows us to unify classical and quantum probabilities, and extend them to an imprecise probabilities context. We introduce a new conditioning rule for our Accept-Desirability models, based on the idea that observing an event introduces new indifferences between options. We associate a belief revision operator with our conditioning rule, and investigate which of the AGM axioms for belief revision still hold in our more general framework. We investigate two interesting special cases where all of these axioms are shown to still hold: classical propositional logic and full conditional probabilities.

</details>


### [228] [FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning](https://arxiv.org/abs/2512.19107)
*Zhe Yang,Xiaoshuang Sheng,Zhengnan Zhang,Jidong Wu,Zexing Wang,Xin He,Shenghua Xu,Guanjing Xiong*

Main category: cs.AI

TL;DR: FC-MIR框架通过关键帧采样和自适应拼接减少移动UI轨迹中的视觉冗余，结合MLLMs进行意图识别和任务自动化，在50%-60%压缩率下保持性能，为轻量级设备部署提供可能。


<details>
  <summary>Details</summary>
Motivation: 移动UI操作轨迹的意图识别对UI理解和任务自动化至关重要，但现有MLLMs存在计算成本高、冗余帧处理效率低的问题，限制了实时移动部署。

Method: 提出FC-MIR框架：1) 关键帧采样和自适应拼接减少视觉冗余；2) 集成闭源MLLMs或微调模型进行轨迹总结和意图预测；3) 扩展任务范围包括生成后预测操作和搜索建议；4) 引入细粒度评估指标；5) 构建UI轨迹数据集进行验证。

Result: 压缩方法在50%-60%压缩率下保持性能；闭源和微调MLLMs都表现出强大的意图总结能力，支持轻量级设备部署；但MLLMs在生成有用和"惊喜"建议方面仍有困难；框架已在真实环境中部署。

Conclusion: FC-MIR框架通过减少视觉冗余提高了移动UI轨迹分析的效率，为轻量级设备部署MLLMs提供了可行方案，但在生成实用建议方面仍需改进，为未来该领域发展奠定了基础。

Abstract: Identifying user intent from mobile UI operation trajectories is critical for advancing UI understanding and enabling task automation agents. While Multimodal Large Language Models (MLLMs) excel at video understanding tasks, their real-time mobile deployment is constrained by heavy computational costs and inefficient redundant frame processing. To address these issues, we propose the FC-MIR framework: leveraging keyframe sampling and adaptive concatenation, it cuts visual redundancy to boost inference efficiency, while integrating state-of-the-art closed-source MLLMs or fine-tuned models (e.g., Qwen3-VL) for trajectory summarization and intent prediction. We further expand task scope to explore generating post-prediction operations and search suggestions, and introduce a fine-grained metric to evaluate the practical utility of summaries, predictions, and suggestions. For rigorous assessment, we construct a UI trajectory dataset covering scenarios from UI-Agents (Agent-I) and real user interactions (Person-I). Experimental results show our compression method retains performance at 50%-60% compression rates; both closed-source and fine-tuned MLLMs demonstrate strong intent summarization, supporting potential lightweight on-device deployment. However, MLLMs still struggle with useful and "surprising" suggestions, leaving room for improvement. Finally, we deploy the framework in a real-world setting, integrating UI perception and UI-Agent proxies to lay a foundation for future progress in this field.

</details>


### [229] [Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis](https://arxiv.org/abs/2512.19135)
*Chenghao Li,Chaoning Zhang,Yi Lu,Shuxu Chen,Xudong Wang,Jiaquan Zhang,Zhicheng Wang,Zhengxun Jin,Kuien Liu,Sung-Ho Bae,Guoqing Wang,Yang Yang,Hen Tao Shen*

Main category: cs.AI

TL;DR: 该研究首次从结构角度分析推理链质量，使用拓扑数据分析中的持久同调方法，发现推理链的拓扑结构复杂度与准确性正相关，成功推理的拓扑结构更简单高效。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要从功能角度评估推理链，很少关注其结构机制。作者希望了解为什么不同的推理链在推理中表现不同，以及推理链的哪些组成部分起关键作用，因此从结构角度分析推理链质量。

Method: 应用拓扑数据分析中的持久同调方法，将推理步骤映射到语义空间，提取拓扑特征，分析结构变化。通过计算同调群评估不同尺度的连通性和冗余性，使用条形码和持久图量化稳定性和一致性。

Result: 推理链的拓扑结构复杂度与准确性正相关：更复杂的链能更早识别正确答案，而成功推理的拓扑结构更简单，减少了冗余和循环，提高了效率和可解释性。

Conclusion: 该工作为推理链质量评估提供了新的结构视角，为未来优化提供了指导，揭示了拓扑结构分析在理解推理链性能中的重要性。

Abstract: With the development of large language models (LLMs), particularly with the introduction of the long reasoning chain technique, the reasoning ability of LLMs in complex problem-solving has been significantly enhanced. While acknowledging the power of long reasoning chains, we cannot help but wonder: Why do different reasoning chains perform differently in reasoning? What components of the reasoning chains play a key role? Existing studies mainly focus on evaluating reasoning chains from a functional perspective, with little attention paid to their structural mechanisms. To address this gap, this work is the first to analyze and evaluate the quality of the reasoning chain from a structural perspective. We apply persistent homology from Topological Data Analysis (TDA) to map reasoning steps into semantic space, extract topological features, and analyze structural changes. These changes reveal semantic coherence, logical redundancy, and identify logical breaks and gaps. By calculating homology groups, we assess connectivity and redundancy at various scales, using barcode and persistence diagrams to quantify stability and consistency. Our results show that the topological structural complexity of reasoning chains correlates positively with accuracy. More complex chains identify correct answers sooner, while successful reasoning exhibits simpler topologies, reducing redundancy and cycles, enhancing efficiency and interpretability. This work provides a new perspective on reasoning chain quality assessment and offers guidance for future optimization.

</details>


### [230] [Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness](https://arxiv.org/abs/2512.19155)
*Yin Jun Phua*

Main category: cs.AI

TL;DR: 通过构建体现不同意识理论的智能体进行架构消融实验，发现GWT、IIT和HOT理论描述了互补的功能层次而非竞争关系，提出GWT提供广播能力而HOT提供质量控制的层次设计原则。


<details>
  <summary>Details</summary>
Motivation: 当前意识研究领域存在GWT、IIT和HOT等竞争理论，各自提出不同的神经特征。为了测试这些机制的功能后果，研究者采用合成神经现象学方法，构建体现这些机制的人工智能体，进行在生物系统中无法实现的精确架构消融实验。

Method: 采用合成神经现象学方法，构建体现GWT、IIT和HOT机制的人工智能体。通过三个实验进行精确的架构消融：实验1测试自我模型损伤对元认知校准的影响；实验2测试工作空间容量对信息访问的因果必要性；实验3测试广播放大效应和鲁棒性差异。

Result: 实验1发现自我模型损伤消除元认知校准但保留一阶任务表现，符合HOT预测；实验2显示工作空间容量对信息访问具有因果必要性，符合GWT的点燃框架；实验3发现GWT式广播会放大内部噪声导致脆弱性，而B2智能体家族对相同扰动具有鲁棒性。同时发现原始扰动复杂性在工作空间瓶颈下降低。

Conclusion: 这些理论描述了互补的功能层次而非竞争关系，提出层次设计原则：GWT提供广播能力，HOT提供质量控制。强调这些智能体并非有意识，而是用于测试意识理论功能预测的参考实现。

Abstract: The search for reliable indicators of consciousness has fragmented into competing theoretical camps (Global Workspace Theory (GWT), Integrated Information Theory (IIT), and Higher-Order Theories (HOT)), each proposing distinct neural signatures. We adopt a synthetic neuro-phenomenology approach: constructing artificial agents that embody these mechanisms to test their functional consequences through precise architectural ablations impossible in biological systems. Across three experiments, we report dissociations suggesting these theories describe complementary functional layers rather than competing accounts. In Experiment 1, a no-rewire Self-Model lesion abolishes metacognitive calibration while preserving first-order task performance, yielding a synthetic blindsight analogue consistent with HOT predictions. In Experiment 2, workspace capacity proves causally necessary for information access: a complete workspace lesion produces qualitative collapse in access-related markers, while partial reductions show graded degradation, consistent with GWT's ignition framework. In Experiment 3, we uncover a broadcast-amplification effect: GWT-style broadcasting amplifies internal noise, creating extreme fragility. The B2 agent family is robust to the same latent perturbation; this robustness persists in a Self-Model-off / workspace-read control, cautioning against attributing the effect solely to $z_{\text{self}}$ compression. We also report an explicit negative result: raw perturbational complexity (PCI-A) decreases under the workspace bottleneck, cautioning against naive transfer of IIT-adjacent proxies to engineered agents. These results suggest a hierarchical design principle: GWT provides broadcast capacity, while HOT provides quality control. We emphasize that our agents are not conscious; they are reference implementations for testing functional predictions of consciousness theories.

</details>


### [231] [Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6](https://arxiv.org/abs/2512.19287)
*Jiaao Wu,Xian Zhang,Fan Yang,Yinpeng Dong*

Main category: cs.AI

TL;DR: Vibe Reasoning是一种人机协作范式，通过元提示、智能体基础和模型编排，将前沿AI模型的潜在能力转化为实际数学问题解决能力，在IMO 2025第6题中成功获得正确答案和严格证明。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型已具备解决复杂数学问题所需的知识，但不知道如何、何时、应用哪些知识。需要一种方法将这些潜在能力转化为实际能力。

Method: 采用Vibe Reasoning范式，包含三个核心组件：通用元提示、智能体基础（使用Python代码执行和基于文件的记忆）和模型编排（结合GPT-5的探索能力和Gemini 3 Pro的证明优势）。

Result: 成功解决了IMO 2025第6题这一组合优化问题，获得了正确答案（2112）和严格的数学证明。通过多次迭代改进，发现了智能体基础和模型编排的必要性。

Conclusion: 轻量级的人类指导可以解锁前沿模型的数学推理潜力。Vibe Reasoning通过元提示、智能体基础和模型编排，将AI的潜在能力转化为实际解决问题的能力。

Abstract: We introduce Vibe Reasoning, a human-AI collaborative paradigm for solving complex mathematical problems. Our key insight is that frontier AI models already possess the knowledge required to solve challenging problems -- they simply do not know how, what, or when to apply it. Vibe Reasoning transforms AI's latent potential into manifested capability through generic meta-prompts, agentic grounding, and model orchestration. We demonstrate this paradigm through IMO 2025 Problem 6, a combinatorial optimization problem where autonomous AI systems publicly reported failures. Our solution combined GPT-5's exploratory capabilities with Gemini 3 Pro's proof strengths, leveraging agentic workflows with Python code execution and file-based memory, to derive both the correct answer (2112) and a rigorous mathematical proof. Through iterative refinement across multiple attempts, we discovered the necessity of agentic grounding and model orchestration, while human prompts evolved from problem-specific hints to generic, transferable meta-prompts. We analyze why capable AI fails autonomously, how each component addresses specific failure modes, and extract principles for effective vibe reasoning. Our findings suggest that lightweight human guidance can unlock frontier models' mathematical reasoning potential. This is ongoing work; we are developing automated frameworks and conducting broader evaluations to further validate Vibe Reasoning's generality and effectiveness.

</details>


### [232] [Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application](https://arxiv.org/abs/2512.19299)
*Haoyu Jiang,Fanjie Zeng,Boan Qu,Xiaojie Lin,Wei Zhong*

Main category: cs.AI

TL;DR: Helios是一个专门针对智能能源领域的大语言模型，通过多智能体协作框架构建了知识库、指令微调数据集和RLHF数据集，显著提升了在智能能源领域的性能表现。


<details>
  <summary>Details</summary>
Motivation: 在碳中和的全球背景下，智能能源系统需要深度协同。然而，该领域跨学科、碎片化且快速发展的专业知识使得通用大语言模型缺乏领域知识和物理约束意识，无法提供精确的工程对齐推理和生成。

Method: 开发了Enersys多智能体协作框架进行端到端数据集构建，包括：1) EnerBase智能能源知识库；2) EnerInstruct指令微调数据集；3) EnerReinforce RLHF数据集。基于这些资源，Helios模型进行了大规模预训练、SFT和RLHF。

Result: 发布了EnerBench基准用于评估智能能源场景中的LLMs，并证明该方法显著增强了领域知识掌握、任务执行准确性以及与人类偏好的对齐。

Conclusion: Helios模型及其配套资源解决了智能能源领域LLMs缺乏专业知识和物理约束意识的问题，为智能能源领域的LLM研究提供了全面解决方案。

Abstract: In the global drive toward carbon neutrality, deeply coordinated smart energy systems underpin industrial transformation. However, the interdisciplinary, fragmented, and fast-evolving expertise in this domain prevents general-purpose LLMs, which lack domain knowledge and physical-constraint awareness, from delivering precise engineering-aligned inference and generation. To address these challenges, we introduce Helios, a large language model tailored to the smart energy domain, together with a comprehensive suite of resources to advance LLM research in this field. Specifically, we develop Enersys, a multi-agent collaborative framework for end-to-end dataset construction, through which we produce: (1) a smart energy knowledge base, EnerBase, to enrich the model's foundational expertise; (2) an instruction fine-tuning dataset, EnerInstruct, to strengthen performance on domain-specific downstream tasks; and (3) an RLHF dataset, EnerReinforce, to align the model with human preferences and industry standards. Leveraging these resources, Helios undergoes large-scale pretraining, SFT, and RLHF. We also release EnerBench, a benchmark for evaluating LLMs in smart energy scenarios, and demonstrate that our approach significantly enhances domain knowledge mastery, task execution accuracy, and alignment with human preferences.

</details>


### [233] [SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.19317)
*A. A. Gde Yogi Pramana,Jason Ray,Anthony Jaya,Michael Wijaya*

Main category: cs.AI

TL;DR: SafeMed-R1是一种混合防御框架，通过对抗训练和随机平滑技术，显著提升医学视觉问答模型在对抗攻击下的鲁棒性，同时保持高质量的临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在医学视觉问答中表现出色，但在临床部署中面临对抗攻击的严重脆弱性。标准的对抗训练虽然对简单任务有效，但会降低泛化性能和临床推理质量。

Method: 提出SafeMed-R1混合防御框架：1) 训练阶段：结合对抗训练与组相对策略优化，显式增强推理过程对最坏情况扰动的鲁棒性；2) 推理阶段：使用随机平滑增强模型，提供认证的L2范数鲁棒性保证。

Result: 在OmniMedVQA基准测试中，标准微调的VLMs在干净输入上达到95%准确率，但在PGD攻击下崩溃至约25%。SafeMed-R1在相同对抗条件下保持84.45%准确率，鲁棒性提升59个百分点。显式思维链推理模型比仅指令变体表现出更优的对抗鲁棒性。

Conclusion: SafeMed-R1成功平衡了医学AI系统的鲁棒性和可解释性，表明可解释性与安全性之间存在协同效应，为临床部署提供了可靠的防御框架。

Abstract: Vision--Language Models (VLMs) show significant promise for Medical Visual Question Answering (VQA), yet their deployment in clinical settings is hindered by severe vulnerability to adversarial attacks. Standard adversarial training, while effective for simpler tasks, often degrades both generalization performance and the quality of generated clinical reasoning. We introduce SafeMed-R1, a hybrid defense framework that ensures robust performance while preserving high-quality, interpretable medical reasoning. SafeMed-R1 employs a two-stage approach: at training time, we integrate Adversarial Training with Group Relative Policy Optimization (AT-GRPO) to explicitly robustify the reasoning process against worst-case perturbations; at inference time, we augment the model with Randomized Smoothing to provide certified $L_2$-norm robustness guarantees. We evaluate SafeMed-R1 on the OmniMedVQA benchmark across eight medical imaging modalities comprising over 88,000 samples. Our experiments reveal that standard fine-tuned VLMs, despite achieving 95\% accuracy on clean inputs, collapse to approximately 25\% under PGD attacks. In contrast, SafeMed-R1 maintains 84.45\% accuracy under the same adversarial conditions, representing a 59 percentage point improvement in robustness. Furthermore, we demonstrate that models trained with explicit chain-of-thought reasoning exhibit superior adversarial robustness compared to instruction-only variants, suggesting a synergy between interpretability and security in medical AI systems.

</details>


### [234] [VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop](https://arxiv.org/abs/2512.19349)
*JiaWei Zhu,ZiHeng Liu*

Main category: cs.AI

TL;DR: VIGOR+是一个新颖的因果推断框架，通过迭代反馈机制将LLM生成的隐藏混杂因素与CEVAE统计验证相结合，解决LLM生成混杂因素语义合理但统计效用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 在观察性数据的因果推断中，隐藏混杂因素是一个基本挑战。虽然最近利用大语言模型基于领域知识生成合理的隐藏混杂因素，但这些LLM生成的混杂因素往往只有语义合理性而缺乏统计效用。

Method: 提出VIGOR+框架，在LLM基于混杂因素生成和CEVAE统计验证之间建立迭代反馈机制。将CEVAE的验证信号（包括信息增益、潜在一致性指标和诊断信息）转化为自然语言反馈，指导后续的LLM生成轮次，直到满足收敛标准。

Result: 该研究形式化了反馈机制，在温和假设下证明了收敛性质，并提供了完整的算法框架。

Conclusion: VIGOR+通过将LLM生成与统计验证紧密结合，解决了隐藏混杂因素推断中的关键问题，为观察性数据的因果推断提供了更可靠的方法。

Abstract: Hidden confounding remains a fundamental challenge in causal inference from observational data. Recent advances leverage Large Language Models (LLMs) to generate plausible hidden confounders based on domain knowledge, yet a critical gap exists: LLM-generated confounders often exhibit semantic plausibility without statistical utility. We propose VIGOR+ (Variational Information Gain for iterative cOnfounder Refinement), a novel framework that closes the loop between LLM-based confounder generation and CEVAE-based statistical validation. Unlike prior approaches that treat generation and validation as separate stages, VIGOR+ establishes an iterative feedback mechanism: validation signals from CEVAE (including information gain, latent consistency metrics, and diagnostic messages) are transformed into natural language feedback that guides subsequent LLM generation rounds. This iterative refinement continues until convergence criteria are met. We formalize the feedback mechanism, prove convergence properties under mild assumptions, and provide a complete algorithmic framework.

</details>


### [235] [PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models](https://arxiv.org/abs/2512.19350)
*A. B. M. Ashikur Rahman,Saeed Anwar,Muhammad Usman,Irfan Ahmad,Ajmal Mian*

Main category: cs.AI

TL;DR: 该研究针对多模态大语言模型中的"谄媚"现象，提出了PENDULUM评估基准，包含约2000个人工标注的视觉问答对，用于系统评估模型在不同图像领域的谄媚倾向。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型中的谄媚现象（过度迎合用户输入而牺牲事实准确性或与视觉证据相矛盾）是一个关键但未被充分探索的挑战。现有研究主要关注纯文本环境，对视觉或多模态环境的研究范围和深度有限。

Method: 提出了PENDULUM评估基准，包含约2000个人工标注的视觉问答对，涵盖六个不同复杂度的图像领域。通过系统评估最先进的多模态大语言模型，并提出新的量化指标来衡量视觉推理中的谄媚行为。

Result: 评估发现最先进的多模态大语言模型在鲁棒性方面存在显著差异，对谄媚和幻觉行为表现出明显的易感性。不同模型在不同图像领域和挑战程度下表现出不同的谄媚倾向。

Conclusion: 研究结果强调了开发抗谄媚架构和训练策略的紧迫性，以提高未来多模态大语言模型的事实一致性和可靠性。提出的数据集和评估方法为理解和缓解这一重要问题提供了基础。

Abstract: Sycophancy, an excessive tendency of AI models to agree with user input at the expense of factual accuracy or in contradiction of visual evidence, poses a critical and underexplored challenge for multimodal large language models (MLLMs). While prior studies have examined this behavior in text-only settings of large language models, existing research on visual or multimodal counterparts remains limited in scope and depth of analysis. To address this gap, we introduce a comprehensive evaluation benchmark, \textit{PENDULUM}, comprising approximately 2,000 human-curated Visual Question Answering pairs specifically designed to elicit sycophantic responses. The benchmark spans six distinct image domains of varying complexity, enabling a systematic investigation of how image type and inherent challenges influence sycophantic tendencies. Through extensive evaluation of state-of-the-art MLLMs. we observe substantial variability in model robustness and a pronounced susceptibility to sycophantic and hallucinatory behavior. Furthermore, we propose novel metrics to quantify sycophancy in visual reasoning, offering deeper insights into its manifestations across different multimodal contexts. Our findings highlight the urgent need for developing sycophancy-resilient architectures and training strategies to enhance factual consistency and reliability in future MLLMs. Our proposed dataset with MLLMs response are available at https://github.com/ashikiut/pendulum/.

</details>


### [236] [First-Order Representation Languages for Goal-Conditioned RL](https://arxiv.org/abs/2512.19355)
*Simon Ståhlberg,Hector Geffner*

Main category: cs.AI

TL;DR: 本文研究在目标条件强化学习和广义规划中使用一阶关系语言，通过改进Hindsight Experience Replay技术，利用原子集合表示状态和目标，自动创建难度递增的目标课程，从而在大型规划实例中学习通用策略。


<details>
  <summary>Details</summary>
Motivation: 传统方法在大型规划实例中面临目标难以通过随机探索达到的问题，需要更有效的方法来学习目标条件和通用策略，特别是在状态和目标需要跨实例泛化的情况下。

Method: 提出三种基于原子集合表示的目标条件强化学习方法：1) 目标作为完整状态；2) 目标作为原子子集；3) 目标作为这些子目标的提升版本。利用改进的Hindsight Experience Replay技术，通过重新标记不成功的轨迹为成功轨迹，自动创建难度递增的目标课程。

Result: 后两种方法（目标作为原子子集及其提升版本）成功地在具有稀疏奖励的大型规划实例上学习了通用策略，通过自动创建复杂度递增的目标课程实现了计算效率的提升。

Conclusion: 使用原子集合表示状态和目标，并结合改进的Hindsight Experience Replay技术，能够有效学习目标条件和通用策略，特别是在大型规划实例中。这种方法通过自动创建目标课程解决了稀疏奖励问题，但也存在局限性，为未来研究提供了改进方向。

Abstract: First-order relational languages have been used in MDP planning and reinforcement learning (RL) for two main purposes: specifying MDPs in compact form, and representing and learning policies that are general and not tied to specific instances or state spaces. In this work, we instead consider the use of first-order languages in goal-conditioned RL and generalized planning. The question is how to learn goal-conditioned and general policies when the training instances are large and the goal cannot be reached by random exploration alone. The technique of Hindsight Experience Replay (HER) provides an answer to this question: it relabels unsuccessful trajectories as successful ones by replacing the original goal with one that was actually achieved. If the target policy must generalize across states and goals, trajectories that do not reach the original goal states can enable more data- and time-efficient learning. In this work, we show that further performance gains can be achieved when states and goals are represented by sets of atoms. We consider three versions: goals as full states, goals as subsets of the original goals, and goals as lifted versions of these subgoals. The result is that the latter two successfully learn general policies on large planning instances with sparse rewards by automatically creating a curriculum of easier goals of increasing complexity. The experiments illustrate the computational gains of these versions, their limitations, and opportunities for addressing them.

</details>


### [237] [An Agentic Framework for Autonomous Materials Computation](https://arxiv.org/abs/2512.19458)
*Zeyu Xia,Jinzhe Ma,Congjie Zheng,Shufei Zhang,Yuqiang Li,Hang Su,P. Hu,Changshui Zhang,Xingao Gong,Wanli Ouyang,Lei Bai,Dongzhan Zhou,Mao Su*

Main category: cs.AI

TL;DR: 本文提出了一种专门用于第一性原理材料计算的领域专业化智能体，通过嵌入领域专业知识确保物理一致的多步骤工作流程，显著提升了计算任务的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在加速科学发现方面展现出强大潜力，但其静态知识和幻觉问题阻碍了自主研究应用。现有方法在复杂科学工作流程中的可靠性和一致性方面存在不足。

Method: 开发了一个领域专业化智能体，专门用于第一性原理材料计算。该智能体通过嵌入领域专业知识，确保物理一致的多步骤工作流程，并能够一致地选择收敛、良定的参数，实现可靠端到端计算执行。

Result: 在多样化的计算任务基准测试中，该系统在准确性和鲁棒性方面显著优于独立的LLMs，为自主计算实验建立了可验证的基础。

Conclusion: 这项工作代表了向完全自动化科学发现迈出的关键一步，为可靠、可验证的自主计算实验奠定了基础。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for accelerating scientific discovery, yet their static knowledge and hallucination issues hinder autonomous research applications. Recent advances integrate LLMs into agentic frameworks, enabling retrieval, reasoning, and tool use for complex scientific workflows. Here, we present a domain-specialized agent designed for reliable automation of first-principles materials computations. By embedding domain expertise, the agent ensures physically coherent multi-step workflows and consistently selects convergent, well-posed parameters, thereby enabling reliable end-to-end computational execution. A new benchmark of diverse computational tasks demonstrates that our system significantly outperforms standalone LLMs in both accuracy and robustness. This work establishes a verifiable foundation for autonomous computational experimentation and represents a key step toward fully automated scientific discovery.

</details>


### [238] [Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios](https://arxiv.org/abs/2512.19551)
*Jiawen Wang,Jingjing Wang Tianyang Chen,Min Zhang,Guodong Zhou*

Main category: cs.AI

TL;DR: 本文提出L^2-EMG任务，旨在让LLM能够持续学习不同场景下的情感运动生成知识，并设计了ES-MoE方法来解决情感解耦和场景适应两大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的人本情感运动生成方法主要关注单一固定尺度数据集内的性能提升，忽视了灵活且尺度不断增长的运动场景（如体育、舞蹈）。有效学习这些新兴场景可以显著增强模型在现实世界中的泛化能力。

Method: 提出了情感可迁移和场景适应的专家混合（ES-MoE）方法，设计了因果引导的情感解耦模块和场景适应的专家构建模块，分别解决情感解耦和场景适应两大挑战。

Result: 构建了多个L^2-EMG数据集来验证ES-MoE方法的有效性。广泛的评估表明，ES-MoE优于先进的基线方法。

Conclusion: 本文提出的L^2-EMG任务和ES-MoE方法能够有效解决情感运动生成中的持续学习问题，有助于构建具有共情和智能的闭环自进化具身智能体。

Abstract: In the literature, existing human-centric emotional motion generation methods primarily focus on boosting performance within a single scale-fixed dataset, largely neglecting the flexible and scale-increasing motion scenarios (e.g., sports, dance), whereas effectively learning these newly emerging scenarios can significantly enhance the model's real-world generalization ability. Inspired by this, this paper proposes a new LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG) task, which aims to equip LLMs with the capability to continually acquire emotional motion generation knowledge across different unseen scenarios, potentially contributing to building a closed-loop and self-evolving embodied agent equipped with both empathy and intelligence. Further, this paper poses two key challenges in the L^2-EMG task, i.e., the emotion decoupling challenge and the scenario adapting challenge. To this end, this paper proposes an Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE) approach which designs a causal-guided emotion decoupling block and a scenario-adapted expert constructing block to address the two challenges, respectively. Especially, this paper constructs multiple L^2-EMG datasets to validate the effectiveness of the ES-MoE approach. Extensive evaluations show that ES-MoE outperforms advanced baselines.

</details>


### [239] [Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations](https://arxiv.org/abs/2512.19557)
*Lawrence Krukrubo,Julius Odede,Olawande Olusegun*

Main category: cs.AI

TL;DR: 论文提出Hybrid LRR-TED框架解决可解释AI的"可扩展性-稳定性困境"，通过"不对称发现"机制，在客户流失预测中实现94%准确率，将专家角色从"规则编写者"转变为"异常处理者"。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI方法面临"可扩展性-稳定性困境"：后处理方法（如LIME、SHAP）可扩展但稳定性差，监督解释框架（如TED）稳定但需要大量人工标注。需要一种平衡方案来解决这一矛盾。

Method: 提出Hybrid LRR-TED混合框架，采用"不对称发现"机制：首先使用自动化规则学习器（GLRM）识别广泛的"安全网"（保留模式），然后通过帕累托最优方法仅需4条人工定义的"风险陷阱"规则进行补充，形成解释矩阵。

Result: 在客户流失预测任务中，该方法达到94.00%预测准确率，优于完整的8规则人工专家基线，同时将人工标注工作量减少50%。验证了"安娜·卡列尼娜流失原则"：自动化方法擅长发现保留模式但难以捕捉流失触发因素。

Conclusion: 该方法有效解决了可解释AI的可扩展性-稳定性困境，提出了人机协同AI的新范式：将专家角色从"规则编写者"转变为"异常处理者"，通过最小化人工干预实现高性能解释性模型。

Abstract: Current approaches to Explainable AI (XAI) face a "Scalability-Stability Dilemma." Post-hoc methods (e.g., LIME, SHAP) may scale easily but suffer from instability, while supervised explanation frameworks (e.g., TED) offer stability but require prohibitive human effort to label every training instance. This paper proposes a Hybrid LRR-TED framework that addresses this dilemma through a novel "Asymmetry of Discovery." When applied to customer churn prediction, we demonstrate that automated rule learners (GLRM) excel at identifying broad "Safety Nets" (retention patterns) but struggle to capture specific "Risk Traps" (churn triggers)-a phenomenon we term the Anna Karenina Principle of Churn. By initialising the explanation matrix with automated safety rules and augmenting it with a Pareto-optimal set of just four human-defined risk rules, our approach achieves 94.00% predictive accuracy. This configuration outperforms the full 8-rule manual expert baseline while reducing human annotation effort by 50%, proposing a shift in the paradigm for Human-in-the-Loop AI: moving experts from the role of "Rule Writers" to "Exception Handlers."

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [240] [Linearly-scalable and entropy-optimal learning of nonstationary and nonlinear manifolds](https://arxiv.org/abs/2512.17926)
*Illia Horenko*

Main category: nlin.CD

TL;DR: 提出熵最优流形聚类(EOMC)方法，在非平稳非线性情况下优于现有降维和流形学习工具，保持O(T)复杂度，应用于Lorenz-96系统发现其动力学本质上是三维吸引流形间的元稳定状态切换过程。


<details>
  <summary>Details</summary>
Motivation: 现有降维和流形学习工具在非平稳非线性情况下存在成本扩展和鲁棒性问题，需要开发更有效的工具来处理复杂动力学系统。

Method: 提出熵最优流形聚类(EOMC)方法，该方法在保持O(T)迭代复杂度扩展的同时，缓解了现有工具的成本扩展和鲁棒性问题。

Result: EOMC应用于Lorenz-96系统发现：1)系统动力学本质上是三维吸引流形间的元稳定状态切换过程；2)流形维度保持不变，数量随外部强迫增加而增加；3)预测时间比基于Lyapunov指数的预期长两倍；4)在数据压缩方面比PCA相关方法损失小几个数量级。

Conclusion: EOMC和转移算子理论为流体力学和地球科学应用中的数据驱动工具提供了改进预测能力和性能的新机会。

Abstract: We propose an Entropy-Optimal Manifold Clustering (EOMC) - and show that it mitigates the cost scaling and robustness issues of the existing dimensionality reduction and manifold learning tools in nonstationary and nonlinear situations, while pertaining the favourable O(T) iteration complexity scaling in the statistics size T. Applying EOMC to the Lorenz-96 dynamical system (a very popular model of a simplified atmosphere dynamics)in chaotic and strongly-chaotic regimes reveals that its dynamics is essentially described by a metastable regime-switching process, making infrequent transitions between the very persistent three-dimensional attractive manifolds. The dimensionality of these manifolds appears to remain unchanged, and their overall number gradually grows with the growing external forcing of the Lorenz-96 model. At the same time, the Markovian mean exit times and relaxation times (that bound the predictability horizons for the identified regime-switching process) appear to decrease only very slowly with the growing external forcing - indicating approximately two-fold longer prediction horizons then is currently anticipated based on analysis of positive Lyapunov exponents for this system, even in very chaotic model regimes. It is also demonstrated that when applied for a lossy compression of the Lorenz-96 output data in various forcing regimes, EOMC achieves several orders of magnitude smaller compression loss - when compared to the common PCA-related linear compression approaches that build a backbone of the state-of-the-art lossy data compression tools (like JPEG, MP3, and others). These findings open new exciting opportunities for EOMC and transfer operator theory, by improving predictive skills and performance of data-driven tools in fluid mechanics and geosciences applications.

</details>


### [241] [Investigating Hamiltonian Dynamics by the Method of Covariant Lyapunov Vectors](https://arxiv.org/abs/2512.17962)
*Jean-Jacq du Plessis*

Main category: nlin.CD

TL;DR: 该论文回顾了李雅普诺夫指数和协变李雅普诺夫向量理论，并将其应用于多个自治哈密顿系统的动力学数值研究，包括Hénon-Heiles系统和DNA气泡动力学。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发有效的数值方法来计算协变李雅普诺夫向量，并应用这些工具深入理解哈密顿系统的动力学特性，特别是中心子空间和分裂子空间的行为。

Method: 使用Ginelli等人开发的算法计算CLVs，以低维哈密顿系统为玩具模型，开发测量向量和子空间收敛率的方法，确定适当的瞬态时间长度。在Hénon-Heiles系统中使用CLVs研究切线动力学，并引入瞬时李雅普诺夫向量研究DNA气泡动力学。

Result: 建立了测量G&C算法收敛率的方法，改进了Hénon-Heiles系统中心子空间的计算精度。发现分裂子空间在粘滞运动期间变得几乎相切，这与系统的双曲性相关。在DNA气泡研究中，虽然基对开口大小与第一CLV的空间分布没有明确关系，但与各种ILV分布存在明显关联。

Conclusion: CLVs是研究哈密顿系统动力学的有力工具，G&C算法经过适当改进后能有效计算这些向量。ILVs为研究DNA等系统中的短寿命现象提供了新视角，揭示了瞬时动力学特性与系统行为之间的重要关系。

Abstract: In this thesis, we review the theory of Lyapunov exponents and covariant Lyapunov vectors (CLVs) and use these objects to numerically investigate the dynamics of several autonomous Hamiltonian systems. The algorithm which we use for computing CLVs is the one developed by Ginelli and collaborators (G&C), which is quite efficient and has been used previously in many numerical investigations. Using two low-dimensional Hamiltonian systems as toy models, we develop a method for measuring the convergence rates of vectors and subspaces computed via the G&C algorithm, and we use the time it takes for this convergence to occur to determine the appropriate transient time lengths needed when applying this algorithm to compute CLVs. The tangent dynamics of the centre subspace of the Hénon-Heiles system is investigated numerically through the use of CLVs, and we propose a method that improves the accuracy of the centre subspace computed with the G&C algorithm. As another application of the method of CLVs to the Hénon-Heiles system, we find that the splitting subspaces (which form a splitting of the tangent space and define the CLVs) become almost tangent during sticky regimes of motion, an observation which is related to the hyperbolicity of the system. Additionally, we investigate the dynamics of bubbles (i.e. thermal openings between base pairs) in homogeneous DNA sequences using the Peyrard-Bishop-Dauxois lattice model of DNA. For the purpose of studying short-lived bubbles in DNA, the notions of instantaneous Lyapunov vectors (ILVs) are introduced in the context of Hamiltonian dynamics. While we find that the size of the opening between base pairs has no clear relationship with the spatial distribution of the first CLV at that site, we do observe a distinct relationship with various ILV distributions.

</details>


### [242] [Variation of entropy in the Duffing system with the amplitude of the external force](https://arxiv.org/abs/2512.19119)
*Junfeng Cheng,Xiao-Song Yang*

Main category: nlin.CD

TL;DR: 该研究通过拓扑马蹄理论重新分析受扰Duffing系统的混沌动力学，发现当外力振幅超过特定值时，拓扑马蹄会退化为伪马蹄，但混沌不变集仍然存在，且拓扑熵下界随振幅增加而降低。


<details>
  <summary>Details</summary>
Motivation: 重新审视经典的受扰Duffing系统，通过拓扑马蹄理论深入探究其混沌动力学特性，特别是外力振幅变化对系统混沌行为的影响。

Method: 采用基于拓扑马蹄理论的数值Runge-Kutta方法，通过变化外力振幅（保持其他参数不变）分析第一、第二和第三回归映射的拓扑马蹄结构。

Result: 发现当外力振幅超过特定阈值时，拓扑（Smale）马蹄会退化为伪马蹄，但混沌不变集仍然持续存在；拓扑熵下界随振幅增加而降低；识别出控制混沌不变集吸引性的临界振幅值。

Conclusion: 外力振幅的变化显著影响受扰Duffing系统的混沌动力学：振幅增加导致拓扑马蹄退化但混沌不变集持续存在，拓扑熵下界降低，混沌不变集的吸引性随振幅变化呈现复杂行为，丰富了系统的动力学特性。

Abstract: In this paper, we revisit the well-known perturbed Duffing system and investigate its chaotic dynamics by means of numerical Runge--Kutta method based on topological horseshoe theory. Precisely, we investigate chaos through the topological horseshoes associated with the first, second, and third return maps, obtained by varying the amplitude of an external force term while keeping all other parameters fixed. Our new finding demonstrates that, when the force amplitude exceeds a certain value, the topological (Smale) horseshoe degenerates into a pseudo-horseshoe, while chaotic invariant set persists. This phenomenon indicates that the lower bound of the topological entropy decreases as the force amplitude increases, thereby enriching the dynamics in the perturbed Duffing system.
  Furthermore, we identify a critical value of the force amplitude governing the attractivity of the chaotic invariant set. For amplitudes slightly below this value, the basin of attraction of the chaotic invariant set progressively shrinks as the amplitude increases. In contrast, for larger amplitudes, both Lyapunov exponents become negative while the topological horseshoe persists, suggesting that the chaotic invariant set loses attractivity as the amplitude grows.

</details>
