<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 83]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 13]
- [quant-ph](#quant-ph) [Total: 35]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 7]
- [cs.AI](#cs.AI) [Total: 34]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.23617)
*Phuong Q. Dao,Mark Roantree,Vuong M. Ngo*

Main category: cs.LG

TL;DR: 本文提出了BERT-ViT-EF模型和其扩展DTCN，用于多模态情感分析，通过早期融合策略和对比学习提升性能，在TumEmo和MVSA-Single数据集上取得优异结果。


<details>
  <summary>Details</summary>
Motivation: 多模态情感分析通过联合分析文本和图像数据，比单模态方法能提供更丰富和准确的情感理解。现有方法在跨模态交互和联合表示学习方面仍有改进空间。

Method: 提出BERT-ViT-EF模型，使用BERT处理文本输入、ViT处理视觉输入，采用早期融合策略。进一步提出DTCN扩展，在BERT后添加Transformer编码器层优化文本上下文，并采用对比学习对齐文本和图像表示。

Result: 在TumEmo数据集上，DTCN达到最佳准确率78.4%和F1分数78.3%；在MVSA-Single数据集上，获得76.6%准确率和75.9% F1分数，表现具有竞争力。

Conclusion: 早期融合和更深层次的上下文建模在基于Transformer的多模态情感分析中具有显著优势，能够有效提升模型性能。

Abstract: Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by
jointly analyzing data from multiple modalities typically text and images
offering a richer and more accurate interpretation than unimodal approaches. In
this paper, we first propose BERT-ViT-EF, a novel model that combines powerful
Transformer-based encoders BERT for textual input and ViT for visual input
through an early fusion strategy. This approach facilitates deeper cross-modal
interactions and more effective joint representation learning. To further
enhance the model's capability, we propose an extension called the Dual
Transformer Contrastive Network (DTCN), which builds upon BERT-ViT-EF. DTCN
incorporates an additional Transformer encoder layer after BERT to refine
textual context (before fusion) and employs contrastive learning to align text
and image representations, fostering robust multimodal feature learning.
Empirical results on two widely used MSA benchmarks MVSA-Single and TumEmo
demonstrate the effectiveness of our approach. DTCN achieves best accuracy
(78.4%) and F1-score (78.3%) on TumEmo, and delivers competitive performance on
MVSA-Single, with 76.6% accuracy and 75.9% F1-score. These improvements
highlight the benefits of early fusion and deeper contextual modeling in
Transformer-based multimodal sentiment analysis.

</details>


### [2] [Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields](https://arxiv.org/abs/2510.23621)
*Alexandre Benoit*

Main category: cs.LG

TL;DR: 该论文研究了如何通过降低精度算术和GPU优化内核来加速SO(3)-等变机器学习力场MACE，同时保持物理保真度。评估了cuEquivariance后端和混合精度策略，发现可显著加速推理而几乎不影响分子动力学模拟结果。


<details>
  <summary>Details</summary>
Motivation: 机器学习力场虽然准确但计算成本高，缺乏关于降低精度算术和GPU优化内核能否在不损害物理保真度的情况下降低成本的系统性证据。

Method: 对MACE进行端到端和逐块性能分析，比较e3nn和NVIDIA cuEquivariance后端，评估FP64/FP32/BF16/FP16精度设置，在推理、短NVT和长NPT水模拟以及玩具训练运行中进行可重现的稳态计时测试。

Result: cuEquivariance将推理延迟减少约3倍；在线性层中使用BF16/FP16混合精度（在FP32模型中）可额外获得约4倍加速；NVT/NPT MD中的能量和热力学观测量保持在运行间变异性范围内；训练中使用半精度权重会降低力RMSE。

Conclusion: 融合等变内核和混合精度推理可以显著加速最先进的力场，对下游分子动力学影响可忽略。建议默认使用cuEquivariance与FP32，并为线性层启用BF16/FP16（保持FP32累加）以获得最大吞吐量，训练仍使用FP32。

Abstract: Machine-learning force fields can deliver accurate molecular dynamics (MD) at
high computational cost. For SO(3)-equivariant models such as MACE, there is
little systematic evidence on whether reduced-precision arithmetic and
GPU-optimized kernels can cut this cost without harming physical fidelity. This
thesis aims to make MACE cheaper and faster while preserving accuracy by
identifying computational bottlenecks and evaluating low-precision execution
policies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA
cuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32
accumulation) for inference, short NVT and long NPT water simulations, and toy
training runs under reproducible, steady-state timing. cuEquivariance reduces
inference latency by about $3\times$. Casting only linear layers to BF16/FP16
within an FP32 model yields roughly 4x additional speedups, while energies and
thermodynamic observables in NVT/NPT MD remain within run-to-run variability.
Half-precision weights during training degrade force RMSE. Mixing e3nn and cuEq
modules without explicit adapters causes representation mismatches. Fused
equivariant kernels and mixed-precision inference can substantially accelerate
state-of-the-art force fields with negligible impact on downstream MD. A
practical policy is to use cuEquivariance with FP32 by default and enable
BF16/FP16 for linear layers (keeping FP32 accumulations) for maximum
throughput, while training remains in FP32. Further gains are expected on
Ampere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and
pipeline fusion.

</details>


### [3] [Adversarially-Aware Architecture Design for Robust Medical AI Systems](https://arxiv.org/abs/2510.23622)
*Alyssa Gerhart,Balaji Iyangar*

Main category: cs.LG

TL;DR: 本文研究了医疗AI系统中的对抗性攻击风险，通过在皮肤病数据集上的实证实验，展示了对抗性方法显著降低分类准确性的问题，并评估了防御措施的效果。


<details>
  <summary>Details</summary>
Motivation: 对抗性攻击对医疗AI系统构成严重威胁，可能导致危险的误分类，延误治疗或造成误诊，特别是在服务不足的人群中威胁患者安全。

Method: 通过详细的威胁建模、实验基准测试和模型评估，在皮肤病数据集上进行实证实验，测试对抗性训练和蒸馏等防御方法。

Result: 防御措施降低了攻击成功率，但需要在模型在干净数据上的性能之间取得平衡。对抗性方法显著降低了分类准确性。

Conclusion: 需要整合技术、伦理和政策方法，构建更具韧性、更公平的医疗AI系统。

Abstract: Adversarial attacks pose a severe risk to AI systems used in healthcare,
capable of misleading models into dangerous misclassifications that can delay
treatments or cause misdiagnoses. These attacks, often imperceptible to human
perception, threaten patient safety, particularly in underserved populations.
Our study explores these vulnerabilities through empirical experimentation on a
dermatological dataset, where adversarial methods significantly reduce
classification accuracy. Through detailed threat modeling, experimental
benchmarking, and model evaluation, we demonstrate both the severity of the
threat and the partial success of defenses like adversarial training and
distillation. Our results show that while defenses reduce attack success rates,
they must be balanced against model performance on clean data. We conclude with
a call for integrated technical, ethical, and policy-based approaches to build
more resilient, equitable AI in healthcare.

</details>


### [4] [DiNo and RanBu: Lightweight Predictions from Shallow Random Forests](https://arxiv.org/abs/2510.23624)
*Tiago Mendonça dos Santos,Rafael Izbicki,Luís Gustavo Esteves*

Main category: cs.LG

TL;DR: 提出了DiNo和RanBu两种浅层森林方法，通过将少量深度受限树转换为高效的距离加权预测器，显著降低了随机森林的推理延迟和内存需求。


<details>
  <summary>Details</summary>
Motivation: 随机森林集成在表格预测任务中表现优异，但依赖数百棵深度树导致高推理延迟和内存需求，限制了在延迟敏感或资源受限环境中的部署。

Method: DiNo通过观测对的最远公共祖先测量同源距离，RanBu对Breiman经典邻近度测量应用核平滑。两种方法都在森林训练后完全操作，无需额外生长树，仅需轻量级矩阵向量操作调整单个带宽参数h。

Result: 在3个合成基准测试和25个公共数据集上，RanBu匹配或超过了全深度随机森林的准确性（特别是在高噪声设置中），同时将训练加推理时间减少高达95%。DiNo在低噪声机制中以适度的计算成本实现了最佳偏差-方差权衡。两种方法都直接扩展到分位数回归，在保持准确性的同时获得显著速度提升。

Conclusion: DiNo和RanBu方法有效解决了随机森林在资源受限环境中的部署限制，提供了高效准确的替代方案，特别是在高噪声和低噪声场景下各有优势。

Abstract: Random Forest ensembles are a strong baseline for tabular prediction tasks,
but their reliance on hundreds of deep trees often results in high inference
latency and memory demands, limiting deployment in latency-sensitive or
resource-constrained environments. We introduce DiNo (Distance with Nodes) and
RanBu (Random Bushes), two shallow-forest methods that convert a small set of
depth-limited trees into efficient, distance-weighted predictors. DiNo measures
cophenetic distances via the most recent common ancestor of observation pairs,
while RanBu applies kernel smoothing to Breiman's classical proximity measure.
Both approaches operate entirely after forest training: no additional trees are
grown, and tuning of the single bandwidth parameter $h$ requires only
lightweight matrix-vector operations. Across three synthetic benchmarks and 25
public datasets, RanBu matches or exceeds the accuracy of full-depth random
forests-particularly in high-noise settings-while reducing training plus
inference time by up to 95\%. DiNo achieves the best bias-variance trade-off in
low-noise regimes at a modest computational cost. Both methods extend directly
to quantile regression, maintaining accuracy with substantial speed gains. The
implementation is available as an open-source R/C++ package at
https://github.com/tiagomendonca/dirf. We focus on structured tabular random
samples (i.i.d.), leaving extensions to other modalities for future work.

</details>


### [5] [From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media](https://arxiv.org/abs/2510.23626)
*Shuang Geng,Wenli Zhang,Jiaheng Xie,Rui Wang,Sudha Ram*

Main category: cs.LG

TL;DR: 本文提出了一个闭环LLM-知识图谱框架，将抑郁症检测与知识扩展相结合，通过迭代学习循环实现预测准确性和医学知识的共同进化。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然整合医学知识提高预测准确性，但忽略了通过预测过程同时扩展知识的机会。社交媒体用户生成内容为心理健康预测提供了实时数据源。

Method: 开发闭环LLM-知识图谱框架，包含两个阶段：知识感知的抑郁症检测阶段（LLM联合执行抑郁症检测和实体提取，知识图谱表示和加权实体），以及知识精炼和扩展阶段（在专家监督下将新实体、关系和实体类型纳入知识图谱）。

Result: 使用大规模用户生成内容，该框架提高了预测准确性并增强了医学理解。专家评估确认发现了与现有文献互补的临床有意义症状、共病和社会触发因素。

Conclusion: 概念化和操作化了预测-学习和学习-预测作为相互强化的过程，推进了预测分析的方法论和理论理解。该框架展示了计算模型和领域知识的共同进化，为其他动态风险监测环境提供了自适应、数据驱动的知识系统基础。

Abstract: Social media user-generated content (UGC) provides real-time, self-reported
indicators of mental health conditions such as depression, offering a valuable
source for predictive analytics. While prior studies integrate medical
knowledge to improve prediction accuracy, they overlook the opportunity to
simultaneously expand such knowledge through predictive processes. We develop a
Closed-Loop Large Language Model (LLM)-Knowledge Graph framework that
integrates prediction and knowledge expansion in an iterative learning cycle.
In the knowledge-aware depression detection phase, the LLM jointly performs
depression detection and entity extraction, while the knowledge graph
represents and weights these entities to refine prediction performance. In the
knowledge refinement and expansion phase, new entities, relationships, and
entity types extracted by the LLM are incorporated into the knowledge graph
under expert supervision, enabling continual knowledge evolution. Using
large-scale UGC, the framework enhances both predictive accuracy and medical
understanding. Expert evaluations confirmed the discovery of clinically
meaningful symptoms, comorbidities, and social triggers complementary to
existing literature. We conceptualize and operationalize
prediction-through-learning and learning-through-prediction as mutually
reinforcing processes, advancing both methodological and theoretical
understanding in predictive analytics. The framework demonstrates the
co-evolution of computational models and domain knowledge, offering a
foundation for adaptive, data-driven knowledge systems applicable to other
dynamic risk monitoring contexts.

</details>


### [6] [Chain of Execution Supervision Promotes General Reasoning in Large Language Models](https://arxiv.org/abs/2510.23629)
*Nuo Chen,Zehua Li,Keqin Bao,Junyang Lin,Dayiheng Liu*

Main category: cs.LG

TL;DR: TracePile是一个包含260万样本的大规模语料库，将代码执行转化为显式的逐步推理链（CoE），用于增强大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 代码虽然包含丰富的逻辑结构和推理范式，但其中的推理往往是隐式的，并与语法或实现噪声纠缠，使得直接在原始代码上训练效果不佳。

Method: 构建TracePile语料库，将代码执行转化为显式的逐步推理链（Chain of Execution），涵盖数学、经典算法和算法竞赛等领域，并包含变量追踪问题和代码重写以增强逻辑粒度和代码多样性。

Result: 在四个基础模型（LLaMA 3、LLaMA 3.1、Qwen-2.5和Qwen-2.5 Coder）和20个基准测试上的实验显示了一致的改进。TracePile使LLaMA3.1-8B在九个数学数据集上的平均性能提升了7.1%，并在两阶段微调下在LiveCodeBench、CRUX和MMLU上取得了明显增益。

Conclusion: TracePile通过将隐式代码推理转化为显式执行链，有效提升了大语言模型在数学、代码、逻辑和算法等多个领域的推理能力。

Abstract: Building robust and general reasoning ability is a central goal in the
development of large language models (LLMs). Recent efforts increasingly turn
to code as a rich training source, given its inherent logical structure and
diverse reasoning paradigms such as divide-and-conquer, topological ordering,
and enumeration. However, reasoning in code is often expressed implicitly and
entangled with syntactic or implementation noise, making direct training on raw
code suboptimal.To address this, we introduce TracePile, a large-scale corpus
of 2.6 million samples that transforms code execution into explicit,
step-by-step chain-of-thought-style rationales, which we call Chain of
Execution (CoE). The corpus spans domains including mathematics, classical
algorithms and algorithmic competition, and is enriched with variable-tracing
questions and code rewritings to enhance logical granularity and code
diversity. We evaluate TracePile using three training setups:
continue-pretraining, instruction tuning after pretraining, and two-stage
finetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,
and Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and
algorithms demonstrate consistent improvements. Notably, TracePile boosts
LLaMA3.1-8B by 7.1\% on average across nine math datasets and delivers clear
gains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.

</details>


### [7] [Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling](https://arxiv.org/abs/2510.23631)
*Yuxuan Tang,Yifan Feng*

Main category: cs.LG

TL;DR: 提出了Ranked Choice Preference Optimization (RCPO)框架，通过最大似然估计将偏好优化与排名选择建模相结合，支持多种反馈格式，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐主要依赖成对偏好优化，忽略了从更丰富的人类反馈形式（如多比较和排名）中学习的机会。

Method: 提出了RCPO统一框架，支持基于效用和基于排名的选择模型，包含多种现有成对方法，并为更丰富的反馈格式提供原则性训练目标。

Result: 在Llama-3-8B-Instruct和Gemma-2-9B-it模型上的实证研究表明，RCPO在AlpacaEval 2和Arena-Hard基准测试中持续优于竞争基线。

Conclusion: RCPO展示了直接利用排名偏好数据结合适当选择模型可以实现更有效的对齐，为将排名选择建模融入LLM训练提供了通用且可扩展的基础。

Abstract: Alignment of large language models (LLMs) has predominantly relied on
pairwise preference optimization, where annotators select the better of two
responses to a prompt. While simple, this approach overlooks the opportunity to
learn from richer forms of human feedback, such as multiwise comparisons and
top-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a
unified framework that bridges preference optimization with (ranked) choice
modeling via maximum likelihood estimation. The framework is flexible,
supporting both utility-based and rank-based choice models. It subsumes several
existing pairwise methods (e.g., DPO, SimPO), while providing principled
training objectives for richer feedback formats. We instantiate this framework
with two representative ranked choice models (Multinomial Logit and
Mallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across
AlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms
competitive baselines. RCPO shows how directly leveraging ranked preference
data, combined with the right choice models, yields more effective alignment.
It offers a versatile and extensible foundation for incorporating (ranked)
choice modeling into LLM training.

</details>


### [8] [LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression](https://arxiv.org/abs/2510.23632)
*Guozhong Li,Muhannad Alhumaidi,Spiros Skiadopoulos,Panos Kalnis*

Main category: cs.LG

TL;DR: LLMCOMP是一种基于解码器大型语言模型的科学数据压缩方法，通过将3D场量化为离散标记、使用Z-order曲线保持局部性，并应用覆盖引导采样来训练自回归变换器，在严格误差限制下实现比现有方法高30%的压缩比。


<details>
  <summary>Details</summary>
Motivation: 高分辨率科学模拟和观测系统产生海量时空数据集，需要高效且有误差限制的压缩方法。同时，解码器大型语言模型在建模复杂序列数据方面表现出卓越能力。

Method: 将3D场量化为离散标记，通过Z-order曲线排列以保持局部性，应用覆盖引导采样提高训练效率，训练带有时空嵌入的自回归变换器建模标记转换，在压缩时执行top-k预测，仅存储排名索引和回退校正以确保严格误差限制。

Result: 在多个再分析数据集上的实验表明，LLMCOMP在严格误差限制下始终优于最先进的压缩器，实现了高达30%的更高压缩比。

Conclusion: 这些结果突显了LLM作为高保真科学数据通用压缩器的潜力。

Abstract: The rapid growth of high-resolution scientific simulations and observation
systems is generating massive spatiotemporal datasets, making efficient,
error-bounded compression increasingly important. Meanwhile, decoder-only large
language models (LLMs) have demonstrated remarkable capabilities in modeling
complex sequential data. In this paper, we propose LLMCOMP, a novel lossy
compression paradigm that leverages decoder-only large LLMs to model scientific
data. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via
Z-order curves to preserve locality, and applies coverage-guided sampling to
enhance training efficiency. An autoregressive transformer is then trained with
spatial-temporal embeddings to model token transitions. During compression, the
model performs top-k prediction, storing only rank indices and fallback
corrections to ensure strict error bounds. Experiments on multiple reanalysis
datasets show that LLMCOMP consistently outperforms state-of-the-art
compressors, achieving up to 30% higher compression ratios under strict error
bounds. These results highlight the potential of LLMs as general-purpose
compressors for high-fidelity scientific data.

</details>


### [9] [Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models](https://arxiv.org/abs/2510.23633)
*Xun Su,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 提出了一种名为噪声组合采样的新方法，通过合成最优噪声向量来近似测量分数，从而在扩散模型的生成过程中自然嵌入条件信息，无需依赖逐步超参数调整。


<details>
  <summary>Details</summary>
Motivation: 预训练扩散模型在零样本逆问题求解中表现出色，但存在一个固有困境：过度整合会破坏生成过程，而整合不足则无法强调逆问题施加的约束。

Method: 噪声组合采样方法从噪声子空间合成最优噪声向量来近似测量分数，替代标准去噪扩散概率模型过程中的噪声项，使条件信息自然嵌入生成过程。

Result: 该方法可应用于广泛的逆问题求解器，包括图像压缩，特别是在生成步骤数T较小时，以可忽略的计算开销实现优越性能，显著提高鲁棒性和稳定性。

Conclusion: 噪声组合采样方法有效解决了扩散模型中条件信息整合的平衡问题，为逆问题求解提供了一种高效稳定的解决方案。

Abstract: Pretrained diffusion models have demonstrated strong capabilities in
zero-shot inverse problem solving by incorporating observation information into
the generation process of the diffusion models. However, this presents an
inherent dilemma: excessive integration can disrupt the generative process,
while insufficient integration fails to emphasize the constraints imposed by
the inverse problem. To address this, we propose \emph{Noise Combination
Sampling}, a novel method that synthesizes an optimal noise vector from a noise
subspace to approximate the measurement score, replacing the noise term in the
standard Denoising Diffusion Probabilistic Models process. This enables
conditional information to be naturally embedded into the generation process
without reliance on step-wise hyperparameter tuning. Our method can be applied
to a wide range of inverse problem solvers, including image compression, and,
particularly when the number of generation steps $T$ is small, achieves
superior performance with negligible computational overhead, significantly
improving robustness and stability.

</details>


### [10] [Monotone and Separable Set Functions: Characterizations and Neural Models](https://arxiv.org/abs/2510.23634)
*Soutrik Sarangi,Yonatan Sverdlov,Nadav Dym,Abir De*

Main category: cs.LG

TL;DR: 该论文研究了单调分离集合函数的设计，用于保持集合包含关系，建立了向量维度的上下界，提出了弱MAS模型用于无限基础集情况，并展示了在集合包含任务中的实验优势。


<details>
  <summary>Details</summary>
Motivation: 受集合包含问题应用的驱动，研究如何设计集合到向量的函数，使得集合的自然偏序关系得以保持，即S⊆T当且仅当F(S)≤F(T)。

Method: 建立了MAS函数向量维度的上下界，针对无限基础集提出了弱MAS模型，该模型具有Holder连续性稳定性，并构建了单调通用模型来逼近所有单调集合函数。

Result: 证明了在无限基础集情况下MAS函数不存在，但提出的弱MAS模型能够有效处理集合包含关系，实验表明该模型在集合包含任务中优于标准集合模型。

Conclusion: MAS函数为集合包含问题提供了有效的数学框架，弱MAS模型在无限集情况下提供了可行的解决方案，实验验证了该方法的有效性。

Abstract: Motivated by applications for set containment problems, we consider the
following fundamental problem: can we design set-to-vector functions so that
the natural partial order on sets is preserved, namely $S\subseteq T \text{ if
and only if } F(S)\leq F(T) $. We call functions satisfying this property
Monotone and Separating (MAS) set functions. % We establish lower and upper
bounds for the vector dimension necessary to obtain MAS functions, as a
function of the cardinality of the multisets and the underlying ground set. In
the important case of an infinite ground set, we show that MAS functions do not
exist, but provide a model called our which provably enjoys a relaxed MAS
property we name "weakly MAS" and is stable in the sense of Holder continuity.
We also show that MAS functions can be used to construct universal models that
are monotone by construction and can approximate all monotone set functions.
Experimentally, we consider a variety of set containment tasks. The experiments
show the benefit of using our our model, in comparison with standard set models
which do not incorporate set containment as an inductive bias. Our code is
available in https://github.com/yonatansverdlov/Monotone-Embedding.

</details>


### [11] [Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning](https://arxiv.org/abs/2510.23635)
*Andrea Bontempelli,Matteo Busso,Leonardo Javier Malcotti,Fausto Giunchiglia*

Main category: cs.LG

TL;DR: 本研究评估了Skeptical Learning（SKEL）在真实用户环境下的表现，通过大学学生使用iLog移动应用进行为期四周的实验，验证了SKEL在减少标注工作量和提高数据质量方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 数字个人助理需要高质量标注来正常工作，但用户标注常存在错误和噪声。先前研究通过比较离线主动标注与被动数据来评估标注准确性，但缺乏最终用户的确认。

Method: 在真实世界条件下评估SKEL性能，让实际用户基于当前视角和需求精炼输入标签。研究涉及大学学生使用iLog移动应用，为期四周。

Result: 结果突显了在用户努力与数据质量之间找到适当平衡的挑战，以及使用SKEL的潜在好处，包括减少标注努力和提高收集数据质量。

Conclusion: SKEL在真实用户环境中显示出减少标注工作量和改善数据质量的潜力，但需要在用户努力与数据质量之间找到适当平衡。

Abstract: Any digital personal assistant, whether used to support task performance,
answer questions, or manage work and daily life, including fitness schedules,
requires high-quality annotations to function properly. However, user
annotations, whether actively produced or inferred from context (e.g., data
from smartphone sensors), are often subject to errors and noise. Previous
research on Skeptical Learning (SKEL) addressed the issue of noisy labels by
comparing offline active annotations with passive data, allowing for an
evaluation of annotation accuracy. However, this evaluation did not include
confirmation from end-users, the best judges of their own context. In this
study, we evaluate SKEL's performance in real-world conditions with actual
users who can refine the input labels based on their current perspectives and
needs. The study involves university students using the iLog mobile application
on their devices over a period of four weeks. The results highlight the
challenges of finding the right balance between user effort and data quality,
as well as the potential benefits of using SKEL, which include reduced
annotation effort and improved quality of collected data.

</details>


### [12] [Integrating Genomics into Multimodal EHR Foundation Models](https://arxiv.org/abs/2510.23639)
*Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T. J. Chen,Cory Y. McLean*

Main category: cs.LG

TL;DR: 本文提出了一种创新的电子健康记录基础模型，将多基因风险评分作为基础数据模态，超越传统仅使用EHR的方法来构建更全面的健康档案。该模型利用All of Us研究计划的广泛数据，学习临床数据与遗传易感性之间的复杂关系，增强预测能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统电子健康记录方法仅依赖临床数据，缺乏对遗传因素的整合。为了构建更全面的健康档案，需要将多基因风险评分与EHR数据相结合，以更好地理解疾病风险并实现个性化医疗。

Method: 开发多模态框架，整合EHR和多基因风险评分数据；利用生成式AI技术扩展EHR基础模型；在All of Us研究计划数据上进行训练和评估；探索迁移学习用于定制分类任务。

Result: 在All of Us数据上评估显示，该模型对多种疾病（特别是2型糖尿病）的发病具有预测价值；展示了PRS与EHR数据之间的相互作用；验证了架构在定制分类任务中的多功能性和效率。

Conclusion: 该方法对于疾病预测、主动健康管理、风险分层和个性化治疗策略具有重要意义，为医疗保健中更个性化、公平和可操作的真实世界证据生成奠定了基础。

Abstract: This paper introduces an innovative Electronic Health Record (EHR) foundation
model that integrates Polygenic Risk Scores (PRS) as a foundational data
modality, moving beyond traditional EHR-only approaches to build more holistic
health profiles. Leveraging the extensive and diverse data from the All of Us
(AoU) Research Program, this multimodal framework aims to learn complex
relationships between clinical data and genetic predispositions. The
methodology extends advancements in generative AI to the EHR foundation model
space, enhancing predictive capabilities and interpretability. Evaluation on
AoU data demonstrates the model's predictive value for the onset of various
conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay
between PRS and EHR data. The work also explores transfer learning for custom
classification tasks, showcasing the architecture's versatility and efficiency.
This approach is pivotal for unlocking new insights into disease prediction,
proactive health management, risk stratification, and personalized treatment
strategies, laying the groundwork for more personalized, equitable, and
actionable real-world evidence generation in healthcare.

</details>


### [13] [Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging](https://arxiv.org/abs/2510.23641)
*Aaron Wang,Zihan Zhao,Subash Katel,Vivekanand Gyanchand Sahu,Elham E Khoda,Abhijith Gandrakota,Jennifer Ngadiuba,Richard Cavanaugh,Javier Duarte*

Main category: cs.LG

TL;DR: SAL-T是一种物理启发的线性变换器架构，通过空间感知分区和卷积层来降低计算复杂度，在保持与全注意力变换器相当性能的同时显著减少资源消耗和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 传统变换器在粒子碰撞等高通量数据处理环境中存在二次复杂度问题，导致资源需求大、推理延迟高，需要更高效的架构。

Method: 结合linformer线性注意力架构，引入基于运动学特征的空间感知粒子分区，并利用卷积层捕获局部相关性，借鉴喷注物理学的洞见。

Result: 在喷注分类任务中优于标准linformer，性能与全注意力变换器相当，同时显著减少资源使用和降低推理延迟；在ModelNet10点云分类数据集上也验证了这一趋势。

Conclusion: SAL-T成功解决了变换器在高通量环境中的部署挑战，为高能物理和其他领域提供了高效且性能优异的替代方案。

Abstract: Transformers are very effective in capturing both global and local
correlations within high-energy particle collisions, but they present
deployment challenges in high-data-throughput environments, such as the CERN
LHC. The quadratic complexity of transformer models demands substantial
resources and increases latency during inference. In order to address these
issues, we introduce the Spatially Aware Linear Transformer (SAL-T), a
physics-inspired enhancement of the linformer architecture that maintains
linear attention. Our method incorporates spatially aware partitioning of
particles based on kinematic features, thereby computing attention between
regions of physical significance. Additionally, we employ convolutional layers
to capture local correlations, informed by insights from jet physics. In
addition to outperforming the standard linformer in jet classification tasks,
SAL-T also achieves classification results comparable to full-attention
transformers, while using considerably fewer resources with lower latency
during inference. Experiments on a generic point cloud classification dataset
(ModelNet10) further confirm this trend. Our code is available at
https://github.com/aaronw5/SAL-T4HEP.

</details>


### [14] [Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs](https://arxiv.org/abs/2510.23650)
*Wei Xia*

Main category: cs.LG

TL;DR: 提出了两种零样本logits层去偏方法：Static和Dynamic，其中Dynamic方法在最小化流畅性损失的同时将偏见减少高达70%，logits干预优于隐藏层方法。


<details>
  <summary>Details</summary>
Motivation: 开发有效的去偏方法来解决对齐大型语言模型中的偏见问题，同时保持模型性能。

Method: 提出了两种零样本logits层去偏方法：Static和Dynamic，通过语义感知的logits干预来减少模型偏见。

Result: Dynamic方法将偏见减少高达70%，且流畅性损失最小；logits干预方法在去偏效果上优于隐藏层方法。

Conclusion: 语义感知的logits干预是对齐LLMs去偏的稳定有效方法，logits层干预优于隐藏层方法。

Abstract: We proposed Static and Dynamic -- two zero-shot logits-layer debiasing
methods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits
intervention outperforms hidden-layer approaches. We show semantic-aware logits
intervention is stable and effective for debiasing aligned LLMs.

</details>


### [15] [The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models](https://arxiv.org/abs/2510.23652)
*Yao Lu,Yuqi Li,Wenbin Xie,Shanqing Yu,Qi Xuan,Zhaowei Zhu,Shiping Wen*

Main category: cs.LG

TL;DR: CLP是一种连续层剪枝框架，通过可微凹门算法自动识别最佳剪枝层段，并使用截止端点调优策略恢复模型性能，在多个大语言模型上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在资源受限的边缘设备上部署面临模型尺寸大、计算成本高的问题，现有层剪枝方法依赖人工指标且忽略层间依赖关系，导致性能严重下降。

Method: 提出CLP框架：1）可微凹门算法通过梯度优化自动识别连续层段进行剪枝；2）截止端点调优策略仅微调剪枝段相邻层以恢复性能。

Result: 在LLaMA2、LLaMA3和Qwen等模型（7B-70B参数）上的实验表明，CLP在20%剪枝率下平均性能保留达95.34%，比基线方法提升4.29%-30.52%，且可与量化技术结合进一步压缩模型。

Conclusion: CLP通过考虑层间依赖关系的连续层剪枝方法，有效解决了大语言模型在边缘设备部署的挑战，显著优于现有剪枝技术。

Abstract: Although large language models (LLMs) have achieved revolutionary
breakthroughs in many fields, their large model size and high computational
cost pose significant challenges for practical deployment on
resource-constrained edge devices. To this end, layer pruning has been proposed
to reduce the computational overhead by directly removing redundant layers.
However, existing layer pruning methods typically rely on hand-crafted metrics
to evaluate and remove individual layers, while ignoring the dependencies
between layers. This can disrupt the model's information flow and severely
degrade performance. To address these issues, we propose CLP, a novel
continuous layer pruning framework that introduces two key innovations: a
differentiable concave gate algorithm that automatically identifies the best
continuous layer segments for pruning via gradient-based optimization; and a
cutoff endpoint tuning strategy that effectively restores model performance by
fine-tuning only the layers adjacent to the pruned segments. Extensive
experiments across multiple model architectures (including LLaMA2, LLaMA3 and
Qwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly
outperforms existing state-of-the-art baselines. For example, at a pruning rate
of $20\%$, CLP achieves an average performance retention of $95.34\%$ on
LLaMA3-70B, outperforming baselines by $4.29\%$-$30.52\%$. Furthermore, CLP can
be seamlessly combined with quantization to further compress the model with
only a slight performance loss.

</details>


### [16] [A machine learning framework integrating seed traits and plasma parameters for predicting germination uplift in crops](https://arxiv.org/abs/2510.23657)
*Saklain Niam,Tashfiqur Rahman,Md. Amjad Patwary,Mukarram Hossain*

Main category: cs.LG

TL;DR: 本研究开发了首个机器学习框架来预测冷等离子体处理下多种作物的发芽提升效果，其中Extra Trees模型表现最佳，并揭示了等离子体处理的激素效应。


<details>
  <summary>Details</summary>
Motivation: 冷等离子体是一种环保的促进种子发芽的方法，但由于复杂的种子-等离子体-环境相互作用，结果难以预测，因此需要开发预测模型。

Method: 使用机器学习模型（包括梯度提升、XGBoost、Extra Trees及其混合模型）来预测大豆、大麦、向日葵、萝卜和番茄在介质阻挡放电等离子体处理下的发芽提升。

Result: Extra Trees模型表现最佳（R²=0.919；RMSE=3.21；MAE=2.62），特征减少后进一步提升至R²=0.925。研究发现存在激素效应：在<7kV或<200s时效果不明显，在7-15kV、200-500s时发芽率最高，超过20kV或长时间暴露会降低发芽率。

Conclusion: 该机器学习框架成功预测了冷等离子体处理的种子发芽效果，并集成到MLflow中，为精准农业中的种子处理优化提供了决策支持工具。

Abstract: Cold plasma (CP) is an eco-friendly method to enhance seed germination, yet
outcomes remain difficult to predict due to complex seed--plasma--environment
interactions. This study introduces the first machine learning framework to
forecast germination uplift in soybean, barley, sunflower, radish, and tomato
under dielectric barrier discharge (DBD) plasma. Among the models tested (GB,
XGB, ET, and hybrids), Extra Trees (ET) performed best (R\textsuperscript{2} =
0.919; RMSE = 3.21; MAE = 2.62), improving to R\textsuperscript{2} = 0.925
after feature reduction. Engineering analysis revealed a hormetic response:
negligible effects at $<$7 kV or $<$200 s, maximum germination at 7--15 kV for
200--500 s, and reduced germination beyond 20 kV or prolonged exposures.
Discharge power was also a dominant factor, with germination rate maximizing at
$\geq$100 W with low exposure time. Species and cultivar-level predictions
showed radish (MAE = 1.46) and soybean (MAE = 2.05) were modeled with high
consistency, while sunflower remained slightly higher variable (MAE = 3.80).
Among cultivars, Williams (MAE = 1.23) and Sari (1.33) were well predicted,
while Arian (2.86) and Ny\'{\i}rs\'{e}gi fekete (3.74) were comparatively
poorly captured. This framework was also embedded into MLflow, providing a
decision-support tool for optimizing CP seed germination in precision
agriculture.

</details>


### [17] [Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine](https://arxiv.org/abs/2510.23659)
*Md. Farhan Shahriyar,Gazi Tanbhir,Abdullah Md Raihan Chy*

Main category: cs.LG

TL;DR: 该研究提出了一种混合量子-经典方法，使用ResNet-50进行特征提取和量子支持向量机(QSVM)进行分类，用于马铃薯疾病检测。实验表明基于Z特征图的QSVM准确率达到99.23%，优于传统SVM和随机森林模型。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习和深度学习模型在处理高维复杂数据集时面临挑战，需要量子计算等先进技术来提高分类效率。量子机器学习与经典深度学习结合有望提升图像分类任务的性能。

Method: 使用ResNet-50从马铃薯疾病RGB图像中提取深度特征表示，通过主成分分析(PCA)进行降维，然后使用QSVM模型处理特征，应用ZZ、Z和Pauli-X等量子特征图将经典数据转换为量子态。

Result: 基于Z特征图的QSVM模型表现最佳，准确率达到99.23%，超越了传统的支持向量机(SVM)和随机森林(RF)模型。

Conclusion: 这项研究突出了将量子计算集成到图像分类中的优势，并通过混合量子-经典建模提供了潜在的疾病检测解决方案。

Abstract: Recently, there has been growing attention on combining quantum machine
learning (QML) with classical deep learning approaches, as computational
techniques are key to improving the performance of image classification tasks.
This study presents a hybrid approach that uses ResNet-50 (Residual Network)
for feature extraction and Quantum Support Vector Machines (QSVM) for
classification in the context of potato disease detection. Classical machine
learning as well as deep learning models often struggle with high-dimensional
and complex datasets, necessitating advanced techniques like quantum computing
to improve classification efficiency. In our research, we use ResNet-50 to
extract deep feature representations from RGB images of potato diseases. These
features are then subjected to dimensionality reduction using Principal
Component Analysis (PCA). The resulting features are processed through QSVM
models which apply various quantum feature maps such as ZZ, Z, and Pauli-X to
transform classical data into quantum states. To assess the model performance,
we compared it with classical machine learning algorithms such as Support
Vector Machine (SVM) and Random Forest (RF) using five-fold stratified
cross-validation for comprehensive evaluation. The experimental results
demonstrate that the Z-feature map-based QSVM outperforms classical models,
achieving an accuracy of 99.23 percent, surpassing both SVM and RF models. This
research highlights the advantages of integrating quantum computing into image
classification and provides a potential disease detection solution through
hybrid quantum-classical modeling.

</details>


### [18] [AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions](https://arxiv.org/abs/2510.23663)
*Padmanabhan Jagannathan Prajesh,Kaliaperumal Ragunath,Miriam Gordon,Bruce Rathgeber,Suresh Neethirajan*

Main category: cs.LG

TL;DR: 提出了一种基于小波变换和视觉Transformer的时空框架ST-ViWT，用于从稀疏的OCO-2卫星观测中重建连续且具有不确定性量化的柱平均CO2浓度场，特别关注家禽养殖密集区域。


<details>
  <summary>Details</summary>
Motivation: 准确绘制农业景观上空的柱平均CO2浓度对于指导排放减缓策略至关重要，特别是在家禽养殖密集区域，需要从稀疏的卫星观测中重建连续的高质量CO2浓度场。

Method: ST-ViWT框架融合了小波时频表示与Transformer注意力机制，整合气象数据、植被指数、地形和土地覆盖信息，通过深度学习模型重建XCO2场。

Result: 在2024年OCO-2数据上，模型达到R2=0.984和RMSE=0.468 ppm；92.3%的填补预测在±1 ppm范围内。独立验证显示良好泛化能力（偏差=-0.14 ppm；r=0.928），能够准确再现夏季末的CO2下降模式。

Conclusion: 该方法支持卫星约束与国家清单和精准畜牧业平台的整合，为排放基准测试、区域特定因子优化和干预验证提供支持，实现了可扩展、透明、空间明确的碳核算和热点优先排序。

Abstract: Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes
is essential for guiding emission mitigation strategies. We present a
Spatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that
reconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across
southern Canada, emphasizing poultry-intensive regions. The model fuses wavelet
time-frequency representations with transformer attention over meteorology,
vegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT
attains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions
lie within +/-1 ppm. Independent validation with TCCON shows robust
generalization (bias = -0.14 ppm; r = 0.928), including faithful reproduction
of the late-summer drawdown. Spatial analysis across 14 poultry regions reveals
a moderate positive association between facility density and XCO2 (r = 0.43);
high-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced
summer variability. Compared with conventional interpolation and standard
machine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces
with explicit uncertainties, enabling year-round coverage despite sparse
observations. The approach supports integration of satellite constraints with
national inventories and precision livestock platforms to benchmark emissions,
refine region-specific factors, and verify interventions. Importantly,
transformer-based Earth observation enables scalable, transparent, spatially
explicit carbon accounting, hotspot prioritization, and policy-relevant
mitigation assessment.

</details>


### [19] [Transformers from Compressed Representations](https://arxiv.org/abs/2510.23665)
*Juan C. Leon Alcazar,Mattia Soldan,Mohammad Saatialsoruji,Alejandro Pardo,Hani Itani,Juan Camilo Perez,Bernard Ghanem*

Main category: cs.LG

TL;DR: TEMPEST是一种利用压缩文件固有字节流结构进行表示学习的方法，通过压缩编码让标准transformer直接从压缩数据流中学习语义表示，显著减少语义分类所需的token数量。


<details>
  <summary>Details</summary>
Motivation: 压缩文件格式是高效数据存储和传输的基础，但其在表示学习方面的潜力尚未被充分探索。

Method: 利用压缩文件的字节流结构设计有效的token化和编码策略，通过紧凑编码使标准transformer能够直接从压缩数据流学习语义表示，无需原始字节级处理或完整媒体解码。

Result: 在多样化数据集、编码方案和模态上的广泛实验表明，TEMPEST在保持与最先进方法竞争性准确度的同时，在内存和计算效率方面实现了显著提升。

Conclusion: 该方法通过利用压缩数据的内在结构，为表示学习提供了一种高效且有效的替代方案，显著降低了计算复杂度和内存使用。

Abstract: Compressed file formats are the corner stone of efficient data storage and
transmission, yet their potential for representation learning remains largely
underexplored. We introduce TEMPEST (TransformErs froM comPressed
rEpreSenTations), a method that exploits the inherent byte-stream structure of
compressed files to design an effective tokenization and encoding strategy. By
leveraging this compact encoding, a standard transformer can directly learn
semantic representations from compressed data streams, bypassing the need for
raw byte-level processing or full media decoding. Our proposal substantially
reduces the number of tokens required for semantic classification, thereby
lowering both computational complexity and memory usage. Through extensive
experiments across diverse datasets, coding schemes, and modalities, we show
that TEMPEST achieves accuracy competitive wit the state-of-the-art while
delivering efficiency gains in memory and compute.

</details>


### [20] [Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization](https://arxiv.org/abs/2510.23667)
*Amin Heyrani Nobari,Lyle Regenwetter,Cyril Picard,Ligong Han,Faez Ahmed*

Main category: cs.LG

TL;DR: OAT是一个基于基础模型的拓扑优化框架，能够直接预测任意长宽比、分辨率、体积分数、载荷和约束条件下的最小柔度布局，相比现有方法显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习拓扑优化方法局限于固定方形网格、少量边界条件和后处理优化，无法实现通用部署。需要开发能够处理任意边界条件和几何参数的通用框架。

Method: 结合分辨率无关的自编码器、隐式神经场解码器和条件潜在扩散模型，在包含220万个优化结构的OpenTO数据集上进行训练。

Result: 在四个公共基准和两个未见测试中，OAT将平均柔度降低高达90%，在单GPU上实现亚秒级推理，支持64×64到256×256分辨率和高达10:1的长宽比。

Conclusion: OAT为物理感知拓扑优化提供了一个通用、快速且分辨率无关的框架，并为逆向设计的生成建模研究提供了大规模数据集。

Abstract: Structural topology optimization (TO) is central to engineering design but
remains computationally intensive due to complex physics and hard constraints.
Existing deep-learning methods are limited to fixed square grids, a few
hand-coded boundary conditions, and post-hoc optimization, preventing general
deployment. We introduce Optimize Any Topology (OAT), a foundation-model
framework that directly predicts minimum-compliance layouts for arbitrary
aspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines
a resolution- and shape-agnostic autoencoder with an implicit neural-field
decoder and a conditional latent-diffusion model trained on OpenTO, a new
corpus of 2.2 million optimized structures covering 2 million unique
boundary-condition configurations. On four public benchmarks and two
challenging unseen tests, OAT lowers mean compliance up to 90% relative to the
best prior models and delivers sub-1 second inference on a single GPU across
resolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These
results establish OAT as a general, fast, and resolution-free framework for
physics-aware topology optimization and provide a large-scale dataset to spur
further research in generative modeling for inverse design. Code & data can be
found at https://github.com/ahnobari/OptimizeAnyTopology.

</details>


### [21] [Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems](https://arxiv.org/abs/2510.23668)
*Fujiang Yuan,Yangrui Fan,Xiaohuan Bing,Zhen Tian,Chunhong Yuan,Yankang Li*

Main category: cs.LG

TL;DR: 本研究提出了一种基于STL分解的混合框架，结合LSTM、ARIMA和XGBoost三种模型，通过分解交通流时间序列并分别预测各分量，显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 单一模型难以捕捉交通流数据中复杂的非线性、多尺度时间模式，需要开发更有效的混合预测方法。

Method: 使用STL将时间序列分解为趋势、季节性和残差分量，分别用LSTM建模长期趋势、ARIMA捕捉季节性周期、XGBoost预测非线性残差波动，最后通过乘法集成获得最终预测。

Result: 在纽约市交叉口的998条交通流记录上测试，该混合模型在MAE、RMSE和R平方指标上显著优于单独的LSTM、ARIMA和XGBoost模型。

Conclusion: 分解策略有效分离了时间特征，使各模型能够专业化，从而提高了预测准确性、可解释性和鲁棒性。

Abstract: Accurate traffic flow forecasting is essential for intelligent transportation
systems and urban traffic management. However, single model approaches often
fail to capture the complex, nonlinear, and multi scale temporal patterns in
traffic flow data. This study proposes a decomposition driven hybrid framework
that integrates Seasonal Trend decomposition using Loess (STL) with three
complementary predictive models. STL first decomposes the original time series
into trend, seasonal, and residual components. Then, a Long Short Term Memory
(LSTM) network models long term trends, an Autoregressive Integrated Moving
Average (ARIMA) model captures seasonal periodicity, and an Extreme Gradient
Boosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The
final forecast is obtained through multiplicative integration of the sub model
predictions. Using 998 traffic flow records from a New York City intersection
between November and December 2015, results show that the LSTM ARIMA XGBoost
hybrid model significantly outperforms standalone models including LSTM, ARIMA,
and XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy
effectively isolates temporal characteristics, allowing each model to
specialize, thereby improving prediction accuracy, interpretability, and
robustness.

</details>


### [22] [DBLoss: Decomposition-based Loss Function for Time Series Forecasting](https://arxiv.org/abs/2510.23672)
*Xiangfei Qiu,Xingjian Wu,Hanyin Cheng,Xvyuan Liu,Chenjuan Guo,Jilin Hu,Bin Yang*

Main category: cs.LG

TL;DR: 提出了一种基于分解的损失函数DBLoss，通过指数移动平均将时间序列分解为季节性和趋势分量，分别计算损失并加权，可显著提升深度学习预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MSE损失函数有时无法准确捕捉预测范围内的季节性模式或趋势，即使在前向传播中使用分解模块分别建模趋势和季节性。

Method: 使用指数移动平均将时间序列分解为季节性和趋势分量，然后分别计算这些分量的损失并进行加权。DBLoss可作为通用损失函数与任何深度学习预测模型结合使用。

Result: 大量实验表明，DBLoss显著提升了最先进模型在多样化真实世界数据集上的性能。

Conclusion: DBLoss为时间序列损失函数设计提供了新的视角，是一种简单而有效的基于分解的损失函数。

Abstract: Time series forecasting holds significant value in various domains such as
economics, traffic, energy, and AIOps, as accurate predictions facilitate
informed decision-making. However, the existing Mean Squared Error (MSE) loss
function sometimes fails to accurately capture the seasonality or trend within
the forecasting horizon, even when decomposition modules are used in the
forward propagation to model the trend and seasonality separately. To address
these challenges, we propose a simple yet effective Decomposition-Based Loss
function called DBLoss. This method uses exponential moving averages to
decompose the time series into seasonal and trend components within the
forecasting horizon, and then calculates the loss for each of these components
separately, followed by weighting them. As a general loss function, DBLoss can
be combined with any deep learning forecasting model. Extensive experiments
demonstrate that DBLoss significantly improves the performance of
state-of-the-art models across diverse real-world datasets and provides a new
perspective on the design of time series loss functions.

</details>


### [23] [Informed Initialization for Bayesian Optimization and Active Learning](https://arxiv.org/abs/2510.23681)
*Carl Hvarfner,David Eriksson,Eytan Bakshy,Max Balandat*

Main category: cs.LG

TL;DR: 提出HIPE方法，一种基于信息论的获取策略，用于贝叶斯优化的初始化阶段，平衡预测不确定性减少和超参数学习，在少样本设置中显著优于传统空间填充设计。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化初始化依赖（准）随机设计来覆盖输入空间，但忽视了两个关键因素：(a) 空间填充设计可能不利于减少预测不确定性；(b) 初始化期间高效超参数学习对高质量预测至关重要，可能与空间填充设计冲突。

Method: 提出超参数知情预测探索（HIPE），一种基于信息论的获取策略，在高斯过程设置中推导出闭式表达式，平衡预测不确定性减少与超参数学习。

Result: 在主动学习和少样本贝叶斯优化的广泛实验中，HIPE在预测准确性、超参数识别和后续优化性能方面优于标准初始化策略，特别是在大规模批次、少样本设置中。

Conclusion: HIPE方法在贝叶斯优化初始化阶段有效解决了传统空间填充设计的局限性，为实际应用中的少样本优化提供了更优的解决方案。

Abstract: Bayesian Optimization is a widely used method for optimizing expensive
black-box functions, relying on probabilistic surrogate models such as Gaussian
Processes. The quality of the surrogate model is crucial for good optimization
performance, especially in the few-shot setting where only a small number of
batches of points can be evaluated. In this setting, the initialization plays a
critical role in shaping the surrogate's predictive quality and guiding
subsequent optimization. Despite this, practitioners typically rely on
(quasi-)random designs to cover the input space. However, such approaches
neglect two key factors: (a) space-filling designs may not be desirable to
reduce predictive uncertainty, and (b) efficient hyperparameter learning during
initialization is essential for high-quality prediction, which may conflict
with space-filling designs. To address these limitations, we propose
Hyperparameter-Informed Predictive Exploration (HIPE), a novel acquisition
strategy that balances predictive uncertainty reduction with hyperparameter
learning using information-theoretic principles. We derive a closed-form
expression for HIPE in the Gaussian Process setting and demonstrate its
effectiveness through extensive experiments in active learning and few-shot BO.
Our results show that HIPE outperforms standard initialization strategies in
terms of predictive accuracy, hyperparameter identification, and subsequent
optimization performance, particularly in large-batch, few-shot settings
relevant to many real-world Bayesian Optimization applications.

</details>


### [24] [On the Societal Impact of Machine Learning](https://arxiv.org/abs/2510.23693)
*Joachim Baumann*

Main category: cs.LG

TL;DR: 该博士论文研究机器学习的社会影响，重点关注公平性测量、偏差动态分析和减少算法歧视的干预措施，为机器学习系统与社会价值观对齐提供基础。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统越来越多地影响重要决策，但由于开发时缺乏明确的公平性考虑，存在歧视性影响的风险。

Method: 通过更合适的公平性测量方法、系统性地分解机器学习系统以预测偏差动态，以及开发有效的干预措施来减少算法歧视。

Result: 建立了确保机器学习系统公平性的基础框架，能够在维持系统效用的同时减少算法歧视。

Conclusion: 随着机器学习系统（包括生成式人工智能）日益融入社会，需要继续应对挑战并探索未来研究方向，确保机器学习的社会影响与更广泛的社会价值观保持一致。

Abstract: This PhD thesis investigates the societal impact of machine learning (ML). ML
increasingly informs consequential decisions and recommendations, significantly
affecting many aspects of our lives. As these data-driven systems are often
developed without explicit fairness considerations, they carry the risk of
discriminatory effects. The contributions in this thesis enable more
appropriate measurement of fairness in ML systems, systematic decomposition of
ML systems to anticipate bias dynamics, and effective interventions that reduce
algorithmic discrimination while maintaining system utility. I conclude by
discussing ongoing challenges and future research directions as ML systems,
including generative artificial intelligence, become increasingly integrated
into society. This work offers a foundation for ensuring that ML's societal
impact aligns with broader social values.

</details>


### [25] [MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection](https://arxiv.org/abs/2510.23727)
*Anisha Saha,Varsha Suresh,Timothy Hospedales,Vera Demberg*

Main category: cs.LG

TL;DR: MUStReason是一个用于评估视频语言模型在讽刺检测任务中的诊断基准，包含模态特定相关线索和推理步骤的标注。研究提出PragCoT框架来引导模型关注隐含意图而非字面意义。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在复杂任务如讽刺检测上表现不佳，需要跨模态识别相关线索并进行语用推理。研究旨在探索视频语言模型在这方面的局限性。

Method: 引入MUStReason诊断基准，包含丰富的模态特定线索和推理步骤标注；提出PragCoT框架，将问题分解为感知和推理，引导模型关注隐含意图。

Result: 通过MUStReason对视频语言模型的讽刺分类性能和生成推理进行定量和定性评估。

Conclusion: PragCoT框架能够有效引导视频语言模型关注讽刺检测的核心属性——隐含意图，提升模型在复杂语用推理任务上的表现。

Abstract: Sarcasm is a specific type of irony which involves discerning what is said
from what is meant. Detecting sarcasm depends not only on the literal content
of an utterance but also on non-verbal cues such as speaker's tonality, facial
expressions and conversational context. However, current multimodal models
struggle with complex tasks like sarcasm detection, which require identifying
relevant cues across modalities and pragmatically reasoning over them to infer
the speaker's intention. To explore these limitations in VideoLMs, we introduce
MUStReason, a diagnostic benchmark enriched with annotations of
modality-specific relevant cues and underlying reasoning steps to identify
sarcastic intent. In addition to benchmarking sarcasm classification
performance in VideoLMs, using MUStReason we quantitatively and qualitatively
evaluate the generated reasoning by disentangling the problem into perception
and reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on
implied intentions over literal meaning, a property core to detecting sarcasm.

</details>


### [26] [Debiasing Reward Models by Representation Learning with Guarantees](https://arxiv.org/abs/2510.23751)
*Ignavier Ng,Patrick Blöbaum,Siddharth Bhandari,Kun Zhang,Shiva Kasiviswanathan*

Main category: cs.LG

TL;DR: 论文提出了一种缓解奖励模型中虚假相关性的原则性框架，通过识别和分离虚假与非虚假潜在变量来训练更稳健的奖励模型。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐技术（如基于人类反馈的强化学习）在训练奖励模型时经常利用虚假相关性（如响应长度、歧视、谄媚和概念偏见），这已成为日益受到关注的问题。

Method: 首先构建数据生成过程的公式化描述，假设观测数据来自虚假和非虚假潜在变量；然后提出使用变分推断来恢复这些变量，并利用它们训练奖励模型的实用方法。

Result: 在合成和真实数据集上的实验表明，该方法能有效缓解虚假相关性问题，产生更稳健的奖励模型。

Conclusion: 该框架能够在保留反映预期偏好的基础因素的同时，有效减轻奖励模型中的偏见问题。

Abstract: Recent alignment techniques, such as reinforcement learning from human
feedback, have been widely adopted to align large language models with human
preferences by learning and leveraging reward models. In practice, these models
often exploit spurious correlations, involving, e.g., response length,
discrimination, sycophancy, and conceptual bias, which is a problem that has
received increasing attention. In this work, we propose a principled framework
that mitigates these biases in reward models while preserving the underlying
factors that reflect intended preferences. We first provide a formulation of
the data-generating process, assuming that the observed data (e.g., text) is
generated from both spurious and non-spurious latent variables. We show that,
interestingly, these non-spurious latent variables can be theoretically
identified from data, regardless of whether a surrogate for the spurious latent
variables is available. This further inspires a practical method that uses
variational inference to recover these variables and leverages them to train
reward models. Experiments on synthetic and real-world datasets demonstrate
that our method effectively mitigates spurious correlation issues and yields
more robust reward models.

</details>


### [27] [Revealing the Potential of Learnable Perturbation Ensemble Forecast Model for Tropical Cyclone Prediction](https://arxiv.org/abs/2510.23794)
*Jun Liu,Tao Zhou,Jiarui Li,Xiaohui Zhong,Peng Zhang,Jie Feng,Lei Chen,Hao Li*

Main category: cs.LG

TL;DR: FuXi-ENS是一种基于AI的集合预报新范式，通过可学习的扰动方案生成集合预报，在热带气旋预报中相比传统ECMWF-ENS系统展现出明显优势。


<details>
  <summary>Details</summary>
Motivation: 传统集合预报系统受限于高计算成本和无法充分表示大气非线性，需要开发更有效的集合预报方法。

Method: 引入可学习的扰动方案进行集合生成，并与ECMWF-ENS系统进行系统性比较，分析热带气旋相关物理变量、路径和强度预报性能。

Result: FuXi-ENS在预测热带气旋相关物理变量方面具有明显优势，路径预报更准确且集合离散度更小，但在强度预报方面仍低估观测值。动力学和热力学分析显示FuXi-ENS能更好地捕捉大尺度环流。

Conclusion: 可学习的扰动方案有潜力提高热带气旋预报技能，为推进具有重大社会影响的极端天气事件的AI集合预报提供了宝贵见解。

Abstract: Tropical cyclones (TCs) are highly destructive and inherently uncertain
weather systems. Ensemble forecasting helps quantify these uncertainties, yet
traditional systems are constrained by high computational costs and limited
capability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a
learnable perturbation scheme for ensemble generation, representing a novel
AI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with
ECMWF-ENS using all 90 global TCs in 2018, examining their performance in
TC-related physical variables, track and intensity forecasts, and the
associated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear
advantages in predicting TC-related physical variables, and achieves more
accurate track forecasts with reduced ensemble spread, though it still
underestimates intensity relative to observations. Further dynamical and
thermodynamical analyses reveal that FuXi-ENS better captures large-scale
circulation, with moisture turbulent energy more tightly concentrated around
the TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.
These findings highlight the potential of learnable perturbations to improve TC
forecasting skill and provide valuable insights for advancing AI-based ensemble
prediction of extreme weather events that have significant societal impacts.

</details>


### [28] [Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders](https://arxiv.org/abs/2510.23802)
*Nathan Paek,Yongyi Zang,Qihui Yang,Randal Leistikow*

Main category: cs.LG

TL;DR: 该论文提出了一种用于解释音频生成模型潜在表示的框架，通过将稀疏自编码器特征映射到人类可解释的声学概念（音高、振幅、音色），实现可控操作和生成过程分析。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在语言模型中成功提取可解释特征，但在音频生成中面临挑战：音频的密集特性使得压缩后语义信息模糊，且自动特征表征有限。

Method: 在音频自编码器潜在空间上训练稀疏自编码器，然后学习从SAE特征到离散化声学属性的线性映射，支持连续和离散音频潜在空间。

Result: 在DiffRhythm-VAE、EnCodec和WavTokenizer等模型上验证了方法有效性，分析了DiffRhythm文本到音乐模型中音高、音色和响度在生成过程中的演变。

Conclusion: 该框架不仅适用于音频模态，还可扩展到视觉潜在空间生成模型的可解释分析。

Abstract: While sparse autoencoders (SAEs) successfully extract interpretable features
from language models, applying them to audio generation faces unique
challenges: audio's dense nature requires compression that obscures semantic
meaning, and automatic feature characterization remains limited. We propose a
framework for interpreting audio generative models by mapping their latent
representations to human-interpretable acoustic concepts. We train SAEs on
audio autoencoder latents, then learn linear mappings from SAE features to
discretized acoustic properties (pitch, amplitude, and timbre). This enables
both controllable manipulation and analysis of the AI music generation process,
revealing how acoustic properties emerge during synthesis. We validate our
approach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)
audio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music
model, to demonstrate how pitch, timbre, and loudness evolve throughout
generation. While our work is only done on audio modality, our framework can be
extended to interpretable analysis of visual latent space generation models.

</details>


### [29] [How do simple rotations affect the implicit bias of Adam?](https://arxiv.org/abs/2510.23804)
*Adela DePavia,Vasileios Charisopoulos,Rebecca Willett*

Main category: cs.LG

TL;DR: 自适应梯度方法如Adam和Adagrad在机器学习中广泛使用，但其对模型泛化能力的影响相对于梯度下降等方法仍不清楚。研究发现Adam存在"丰富性偏差"，但该方法对特征空间的正交变换敏感，可能导致其优势消失。通过重参数化方法可以解决此问题。


<details>
  <summary>Details</summary>
Motivation: 理解自适应梯度方法（如Adam）相对于梯度下降在模型泛化能力上的影响差异，特别是Adam表现出的"丰富性偏差"特性及其对数据变换的敏感性。

Method: 分析Adam方法在二元分类中的表现，研究其对正交变换的敏感性，并应用重参数化方法（对优化目标应用正交变换）来使一阶方法对数据旋转具有等变性。

Result: 研究发现Adam的丰富性偏差对数据旋转敏感，即使小的旋转也可能使其失去竞争优势并收敛到远离贝叶斯最优决策边界的线性边界。重参数化方法能够恢复Adam对丰富决策边界的偏好。

Conclusion: 自适应梯度方法的性能受数据变换影响，通过适当的重参数化可以使其对数据旋转具有鲁棒性，从而保持其学习复杂决策边界的优势。

Abstract: Adaptive gradient methods such as Adam and Adagrad are widely used in machine
learning, yet their effect on the generalization of learned models -- relative
to methods like gradient descent -- remains poorly understood. Prior work on
binary classification suggests that Adam exhibits a ``richness bias,'' which
can help it learn nonlinear decision boundaries closer to the Bayes-optimal
decision boundary relative to gradient descent. However, the coordinate-wise
preconditioning scheme employed by Adam renders the overall method sensitive to
orthogonal transformations of feature space. We show that this sensitivity can
manifest as a reversal of Adam's competitive advantage: even small rotations of
the underlying data distribution can make Adam forfeit its richness bias and
converge to a linear decision boundary that is farther from the Bayes-optimal
decision boundary than the one learned by gradient descent. To alleviate this
issue, we show that a recently proposed reparameterization method -- which
applies an orthogonal transformation to the optimization objective -- endows
any first-order method with equivariance to data rotations, and we empirically
demonstrate its ability to restore Adam's bias towards rich decision
boundaries.

</details>


### [30] [A Physics-informed Multi-resolution Neural Operator](https://arxiv.org/abs/2510.23810)
*Sumanta Roy,Bahador Bahmani,Ioannis G. Kevrekidis,Michael D. Shields*

Main category: cs.LG

TL;DR: 提出了一种物理信息驱动的算子学习方法，将分辨率无关神经算子框架扩展到完全无数据设置，解决了训练数据获取困难和多分辨率数据的问题。


<details>
  <summary>Details</summary>
Motivation: 在工程应用中，获取高质量的训练数据（输入-输出函数对）具有挑战性，且数据集可能具有不均匀的离散化，网格分辨率在不同样本间变化。

Method: 将任意离散化的输入函数投影到潜在嵌入空间，使用预训练的基函数。通过多层感知机近似偏微分方程算子，结合潜在编码和时空坐标在物理空间中产生解，并通过有限差分求解器强制执行偏微分方程。

Result: 在多个具有多分辨率数据的数值示例上验证了方法的性能，包括粗粒度和细粒度离散化。

Conclusion: 该方法能够有效处理多分辨率数据，在无数据设置下实现物理信息驱动的算子学习。

Abstract: The predictive accuracy of operator learning frameworks depends on the
quality and quantity of available training data (input-output function pairs),
often requiring substantial amounts of high-fidelity data, which can be
challenging to obtain in some real-world engineering applications. These
datasets may be unevenly discretized from one realization to another, with the
grid resolution varying across samples. In this study, we introduce a
physics-informed operator learning approach by extending the Resolution
Independent Neural Operator (RINO) framework to a fully data-free setup,
addressing both challenges simultaneously. Here, the arbitrarily (but
sufficiently finely) discretized input functions are projected onto a latent
embedding space (i.e., a vector space of finite dimensions), using pre-trained
basis functions. The operator associated with the underlying partial
differential equations (PDEs) is then approximated by a simple multi-layer
perceptron (MLP), which takes as input a latent code along with spatiotemporal
coordinates to produce the solution in the physical space. The PDEs are
enforced via a finite difference solver in the physical space. The validation
and performance of the proposed method are benchmarked on several numerical
examples with multi-resolution data, where input functions are sampled at
varying resolutions, including both coarse and fine discretizations.

</details>


### [31] [Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes](https://arxiv.org/abs/2510.23817)
*Pedro Cortes dos Santos,Matheus Becali Rocha,Renato A Krohling*

Main category: cs.LG

TL;DR: 本研究提出了一种结合SHAP解释性分析和因果分析的创新故障检测框架，用于解决工业过程复杂数据中的故障检测难题。通过田纳西伊斯曼过程基准测试，该方法在提高检测准确性的同时提供了可解释的故障根源分析。


<details>
  <summary>Details</summary>
Motivation: 工业过程产生的复杂数据给故障检测系统带来挑战，现有机器学习方法往往结果不透明或性能不佳。本研究旨在开发一个既能提高检测准确性又能提供可解释性洞察的故障检测框架。

Method: 使用SHAP（SHapley Additive exPlanations）方法识别关键过程特征，然后通过有向无环图进行因果分析，揭示故障传播的潜在机制。该方法结合了特征重要性和因果推理。

Result: SHAP分析成功识别出驱动故障预测的关键过程特征，因果分析结果与SHAP发现高度一致，共同突出了冷却和分离系统等关键过程元素在故障发展中的核心作用。

Conclusion: 这种双重方法将预测能力与因果理解相结合，为复杂制造环境监控提供了强大的工具，为工业系统中更智能、更可解释的故障检测开辟了新途径。

Abstract: Industrial processes generate complex data that challenge fault detection
systems, often yielding opaque or underwhelming results despite advanced
machine learning techniques. This study tackles such difficulties using the
Tennessee Eastman Process, a well-established benchmark known for its intricate
dynamics, to develop an innovative fault detection framework. Initial attempts
with standard models revealed limitations in both performance and
interpretability, prompting a shift toward a more tractable approach. By
employing SHAP (SHapley Additive exPlanations), we transform the problem into a
more manageable and transparent form, pinpointing the most critical process
features driving fault predictions. This reduction in complexity unlocks the
ability to apply causal analysis through Directed Acyclic Graphs, generated by
multiple algorithms, to uncover the underlying mechanisms of fault propagation.
The resulting causal structures align strikingly with SHAP findings,
consistently highlighting key process elements-like cooling and separation
systems-as pivotal to fault development. Together, these methods not only
enhance detection accuracy but also provide operators with clear, actionable
insights into fault origins, a synergy that, to our knowledge, has not been
previously explored in this context. This dual approach bridges predictive
power with causal understanding, offering a robust tool for monitoring complex
manufacturing environments and paving the way for smarter, more interpretable
fault detection in industrial systems.

</details>


### [32] [ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning](https://arxiv.org/abs/2510.23818)
*Yilang Zhang,Xiaodong Yang,Yiwei Cai,Georgios B. Giannakis*

Main category: cs.LG

TL;DR: 提出了一种通过累积连续低秩增量来构建高秩权重更新的方法，以克服传统LoRA在效果和收敛速度上的限制，在多个任务上实现了优于现有LoRA变体的性能表现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模不断扩大，计算开销成为任务特定微调的主要瓶颈。虽然低秩适应(LoRA)通过将权重更新限制在低维子空间来有效控制成本，但这种限制会阻碍效果并减缓收敛速度。

Method: 通过累积连续的低秩增量来逐步构建高秩权重更新。具体来说，识别每个更新的最优低秩矩阵以最小化损失函数并紧密逼近全量微调。通过适当缩放原始低秩矩阵的列来形成最优选择，实现高效无缝的优化而无需重启。

Result: 在规模达120亿参数的流行LLMs上进行的广泛数值测试表明，在自然语言理解、常识推理和数学问题解决等多样化任务上，相对于最先进的LoRA变体，该方法实现了持续的性能提升和快速收敛。

Conclusion: 该方法通过分析找到最优缩放因子，提供了严格的性能保证，有效解决了传统LoRA方法的局限性，在保持计算效率的同时提升了模型性能。

Abstract: As large language models (LLMs) continue to scale in size, the computational
overhead has become a major bottleneck for task-specific fine-tuning. While
low-rank adaptation (LoRA) effectively curtails this cost by confining the
weight updates to a low-dimensional subspace, such a restriction can hinder
effectiveness and slow convergence. This contribution deals with these
limitations by accumulating progressively a high-rank weight update from
consecutive low-rank increments. Specifically, the per update optimal low-rank
matrix is identified to minimize the loss function and closely approximate full
fine-tuning. To endow efficient and seamless optimization without restarting,
this optimal choice is formed by appropriately scaling the columns of the
original low-rank matrix. Rigorous performance guarantees reveal that the
optimal scaling can be found analytically. Extensive numerical tests with
popular LLMs scaling up to 12 billion parameters demonstrate a consistent
performance gain and fast convergence relative to state-of-the-art LoRA
variants on diverse tasks including natural language understanding, commonsense
reasoning, and mathematical problem solving.

</details>


### [33] [A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling](https://arxiv.org/abs/2510.23866)
*Paul Rosu,Muchang Bahng,Erick Jiang,Rico Zhu,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出一种物理条件化的潜在扩散模型，用于大气数据的动力学降尺度，重点重建高分辨率2米温度场。在现有扩散架构基础上，通过残差公式结合PDE损失项来增强物理一致性。


<details>
  <summary>Details</summary>
Motivation: 传统扩散训练虽然已经产生较低的PDE残差，但希望通过额外损失项的微调进一步正则化模型，增强生成场的物理合理性。

Method: 基于预训练的扩散架构，采用残差公式，在训练目标中集成偏微分方程损失项。PDE损失在完整分辨率空间中通过解码潜在表示计算，通过有限差分近似强制物理一致性。

Result: 经验观察表明，传统扩散训练已能产生低PDE残差，而使用额外损失进行微调可进一步正则化模型并提高生成场的物理合理性。

Conclusion: 该方法成功开发了物理条件化的潜在扩散模型，代码已在GitHub上开源，供未来参考和开发。

Abstract: This work presents a physics-conditioned latent diffusion model tailored for
dynamical downscaling of atmospheric data, with a focus on reconstructing
high-resolution 2-m temperature fields. Building upon a pre-existing diffusion
architecture and employing a residual formulation against a reference UNet, we
integrate a partial differential equation (PDE) loss term into the model's
training objective. The PDE loss is computed in the full resolution (pixel)
space by decoding the latent representation and is designed to enforce physical
consistency through a finite-difference approximation of an effective
advection-diffusion balance. Empirical observations indicate that conventional
diffusion training already yields low PDE residuals, and we investigate how
fine-tuning with this additional loss further regularizes the model and
enhances the physical plausibility of the generated fields. The entirety of our
codebase is available on Github, for future reference and development.

</details>


### [34] [GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA](https://arxiv.org/abs/2510.23868)
*Zhichao Wang*

Main category: cs.LG

TL;DR: GIFT是一种新颖的强化学习框架，通过最小化隐式和显式奖励模型之间的差异来对齐LLMs，将复杂的奖励最大化目标转化为简单的MSE损失，具有更快的收敛速度和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法如PPO、GRPO直接最大化累积奖励，而DPO、UNA等离线方法缺乏探索能力。GIFT旨在结合在线生成和隐式奖励的优势，消除难以处理的项，实现更稳定高效的LLM对齐。

Method: 结合GRPO的在线多响应生成和归一化、DPO的隐式奖励公式以及UNA的隐式-显式奖励对齐原则，通过联合归一化隐式和显式奖励，将优化问题转化为凸的MSE损失。

Result: 在数学基准测试中实现了优越的推理和对齐性能，计算效率高，收敛更快，泛化更好，训练过拟合显著减少。

Conclusion: GIFT提供了一种稳定、高效且具有探索能力的LLM对齐方法，在保持在线策略的同时实现了比现有方法更好的性能。

Abstract: I propose \textbf{G}roup-relative \textbf{I}mplicit \textbf{F}ine
\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning
LLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT
minimizes the discrepancy between implicit and explicit reward models. It
combines three key ideas: (1) the online multi-response generation and
normalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the
implicit-explicit reward alignment principle of UNA. By jointly normalizing the
implicit and explicit rewards, GIFT eliminates an otherwise intractable term
that prevents effective use of implicit rewards. This normalization transforms
the complex reward maximization objective into a simple mean squared error
(MSE) loss between the normalized reward functions, converting a non-convex
optimization problem into a convex, stable, and analytically differentiable
formulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy
and thus retains exploration capability. Compared to GRPO, it requires fewer
hyperparameters, converges faster, and generalizes better with significantly
reduced training overfitting. Empirically, GIFT achieves superior reasoning and
alignment performance on mathematical benchmarks while remaining
computationally efficient.

</details>


### [35] [RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees](https://arxiv.org/abs/2510.23901)
*Cristobal Heredia,Pedro Chumpitaz-Flores,Kaixun Hua*

Main category: cs.LG

TL;DR: RS-ORT是一种用于训练最优回归树的两阶段优化方法，通过专门的分支定界算法在树结构变量上进行分支，解决了传统MIP方法在处理连续特征和大规模数据时的计算难题。


<details>
  <summary>Details</summary>
Motivation: 现有的MIP方法在回归任务中要么仅限于二元特征，要么在处理连续、大规模数据时计算不可行。简单地二值化连续特征会牺牲全局最优性并产生不必要的深树。

Method: 将最优回归树训练重新构建为两阶段优化问题，提出RS-ORT - 一种专门的分支定界算法，仅在树结构变量上进行分支。采用边界收紧技术（闭式叶预测、经验阈值离散化、精确深度-1子树解析）和可分解的上下界策略来加速训练。

Result: 在包含二元和连续特征的多个回归基准测试中，RS-ORT在训练和测试性能上优于现有最先进方法。对于包含200万样本的连续特征数据集，RS-ORT能在4小时内获得保证的训练性能，具有更简单的树结构和更好的泛化能力。

Conclusion: RS-ORT通过专门的算法设计解决了大规模连续特征回归树训练的计算难题，实现了高效的最优树学习，并在性能和泛化能力上超越了现有方法。

Abstract: Mixed-integer programming (MIP) has emerged as a powerful framework for
learning optimal decision trees. Yet, existing MIP approaches for regression
tasks are either limited to purely binary features or become computationally
intractable when continuous, large-scale data are involved. Naively binarizing
continuous features sacrifices global optimality and often yields needlessly
deep trees. We recast the optimal regression-tree training as a two-stage
optimization problem and propose Reduced-Space Optimal Regression Trees
(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches
exclusively on tree-structural variables. This design guarantees the
algorithm's convergence and its independence from the number of training
samples. Leveraging the model's structure, we introduce several bound
tightening techniques - closed-form leaf prediction, empirical threshold
discretization, and exact depth-1 subtree parsing - that combine with
decomposable upper and lower bounding strategies to accelerate the training.
The BB node-wise decomposition enables trivial parallel execution, further
alleviating the computational intractability even for million-size datasets.
Based on the empirical studies on several regression benchmarks containing both
binary and continuous features, RS-ORT also delivers superior training and
testing performance than state-of-the-art methods. Notably, on datasets with up
to 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed
training performance with a simpler tree structure and a better generalization
ability in four hours.

</details>


### [36] [Preference Learning with Response Time: Robust Losses and Guarantees](https://arxiv.org/abs/2505.22820)
*Ayush Sawarni,Sahasrajit Sarmasarkar,Vasilis Syrgkanis*

Main category: cs.LG

TL;DR: 本文研究将响应时间数据整合到人类偏好学习框架中，以更有效地获取奖励模型。通过利用证据积累漂移扩散模型，将响应时间信息与二元选择数据结合，开发了具有理论最优收敛率的Neyman正交损失函数。


<details>
  <summary>Details</summary>
Motivation: 虽然二元偏好数据已成为微调基础模型和生成AI系统的关键，但用户决策过程中的宝贵时间信息仍未得到充分利用。响应时间可以反映偏好的强度，但现有方法忽略了这一信息。

Method: 提出将响应时间信息与二元选择数据结合的新方法，利用证据积累漂移扩散模型，开发Neyman正交损失函数，实现奖励模型学习的理论最优收敛率。

Result: 理论分析表明，对于线性奖励函数，传统偏好学习的错误率随奖励幅度呈指数级增长，而响应时间增强方法将其降低为多项式增长，显著提高了样本效率。实验在图像偏好学习场景中验证了理论发现。

Conclusion: 响应时间增强的偏好学习方法显著优于传统方法，在理论和实验上都表现出更好的样本效率和收敛性能，为奖励模型学习提供了更有效的框架。

Abstract: This paper investigates the integration of response time data into human
preference learning frameworks for more effective reward model elicitation.
While binary preference data has become fundamental in fine-tuning foundation
models, generative AI systems, and other large-scale models, the valuable
temporal information inherent in user decision-making remains largely
unexploited. We propose novel methodologies to incorporate response time
information alongside binary choice data, leveraging the Evidence Accumulation
Drift Diffusion (EZ) model, under which response time is informative of the
preference strength. We develop Neyman-orthogonal loss functions that achieve
oracle convergence rates for reward model learning, matching the theoretical
optimal rates that would be attained if the expected response times for each
query were known a priori. Our theoretical analysis demonstrates that for
linear reward functions, conventional preference learning suffers from error
rates that scale exponentially with reward magnitude. In contrast, our response
time-augmented approach reduces this to polynomial scaling, representing a
significant improvement in sample efficiency. We extend these guarantees to
non-parametric reward function spaces, establishing convergence properties for
more complex, realistic reward models. Our extensive experiments validate our
theoretical findings in the context of preference learning over images.

</details>


### [37] [Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers](https://arxiv.org/abs/2510.23912)
*Marko Karbevski,Antonij Mijoski*

Main category: cs.LG

TL;DR: 论文证明在简化假设下，注意力机制中的Query权重是冗余的，可以减少超过8%的非嵌入参数，并在GPT-3小架构上验证了理论。


<details>
  <summary>Details</summary>
Motivation: 研究当前LLM中注意力机制的Query、Key、Value权重三元组是否可以被简化，以降低模型参数量。

Method: 在理论分析的基础上，使用完整的GPT-3小架构（包含层归一化、跳跃连接和权重衰减）进行从头训练验证。

Result: 减少Query权重的模型在验证损失上与标准基线模型表现相当。

Conclusion: Query权重存在冗余性，这为在大规模模型中研究Query权重冗余提供了动机。

Abstract: The Query, Key, Value weight triplet is a building block of current attention
mechanisms in state-of-the-art LLMs. We theoretically investigate whether this
triplet can be reduced, proving under simplifying assumptions that the Query
weights are redundant, thereby reducing the number of non-embedding/lm-head
parameters by over 8%. We validate the theory on full-complexity GPT-3 small
architectures (with layer normalization, skip connections, and weight decay)
trained from scratch, demonstrating that the reduced model achieves comparable
validation loss to standard baselines. These findings motivate the
investigation of the Query weight redundancy at scale.

</details>


### [38] [Geometry-Inspired Unified Framework for Discounted and Average Reward MDPs](https://arxiv.org/abs/2510.23914)
*Arsenii Mustafin,Xinyi Sheng,Dominik Baumann*

Main category: cs.LG

TL;DR: 该研究将MDP的几何解释从折扣奖励情况扩展到平均奖励情况，统一了两种分析框架，证明了在唯一且遍历的最优策略下，值迭代算法能达到几何收敛速率。


<details>
  <summary>Details</summary>
Motivation: 传统的MDP理论分析通常将平均奖励情况和折扣奖励情况分开处理，尽管它们有相似之处。本研究旨在统一这两种情况的分析框架。

Method: 将最近提出的折扣奖励情况下MDP的几何解释扩展到平均奖励情况，从而统一两种分析框架。

Result: 成功将折扣奖励情况下的主要结果扩展到平均奖励情况：在唯一且遍历的最优策略下，值迭代算法实现了几何收敛速率。

Conclusion: 该工作通过几何解释统一了MDP的平均奖励和折扣奖励分析，并证明了值迭代算法在两种情况下都能达到几何收敛。

Abstract: The theoretical analysis of Markov Decision Processes (MDPs) is commonly
split into two cases - the average-reward case and the discounted-reward case -
which, while sharing similarities, are typically analyzed separately. In this
work, we extend a recently introduced geometric interpretation of MDPs for the
discounted-reward case to the average-reward case, thereby unifying both. This
allows us to extend a major result known for the discounted-reward case to the
average-reward case: under a unique and ergodic optimal policy, the Value
Iteration algorithm achieves a geometric convergence rate.

</details>


### [39] [Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments](https://arxiv.org/abs/2510.23931)
*Miguel Fernandez-de-Retana,Unai Zulaika,Rubén Sánchez-Corcuera,Aitor Almeida*

Main category: cs.LG

TL;DR: 本文研究了差分隐私机制（DP-SGD和PDP-SGD）作为联邦学习中梯度泄漏攻击防御措施的有效性，发现DP-SGD能显著降低梯度泄漏风险但会牺牲模型性能，而PDP-SGD保持良好分类性能但防御效果不佳。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然允许在不共享敏感数据的情况下协作训练模型，但仍容易受到梯度泄漏攻击的威胁，可能泄露私有信息。

Method: 在模拟联邦学习环境中，评估了不同隐私级别下多个计算机视觉模型的性能，并分析了从截获梯度中重建私有数据的质量。

Result: DP-SGD显著减轻了梯度泄漏攻击的风险，但存在模型效用的适度权衡；PDP-SGD保持了强大的分类性能，但作为重建攻击的实际防御措施无效。

Conclusion: 这些发现强调了在分布式学习场景中，除了理论保证外，还需要对隐私机制进行实证评估的重要性，因为信息泄漏可能对数据安全和隐私构成不可承受的严重威胁。

Abstract: Federated Learning (FL) allows for the training of Machine Learning models in
a collaborative manner without the need to share sensitive data. However, it
remains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private
information from the shared model updates. In this work, we investigate the
effectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD
and a variant based on explicit regularization (PDP-SGD) - as defenses against
GLAs. To this end, we evaluate the performance of several computer vision
models trained under varying privacy levels on a simple classification task,
and then analyze the quality of private data reconstructions obtained from the
intercepted gradients in a simulated FL environment. Our results demonstrate
that DP-SGD significantly mitigates the risk of gradient leakage attacks,
albeit with a moderate trade-off in model utility. In contrast, PDP-SGD
maintains strong classification performance but proves ineffective as a
practical defense against reconstruction attacks. These findings highlight the
importance of empirically evaluating privacy mechanisms beyond their
theoretical guarantees, particularly in distributed learning scenarios where
information leakage may represent an unassumable critical threat to data
security and privacy.

</details>


### [40] [ChessQA: Evaluating Large Language Models for Chess Understanding](https://arxiv.org/abs/2510.23948)
*Qianfeng Wen,Zhenwei Tang,Ashton Anderson*

Main category: cs.LG

TL;DR: ChessQA是一个综合性的基准测试，用于评估大型语言模型在国际象棋中的理解能力，涵盖五个任务类别：结构、模式、短战术、位置判断和语义，对应玩家积累象棋知识时的不同抽象层次。


<details>
  <summary>Details</summary>
Motivation: 国际象棋为评估大型语言模型的推理、建模和抽象能力提供了理想测试平台，但现有评估方法零散且范围狭窄，难以准确衡量LLM的象棋理解能力及其随规模、训练后方法或架构选择的变化。

Method: 开发了ChessQA基准测试，包含五个任务类别：结构（基本规则）、模式（战术模式）、短战术（正确计算）、位置判断（评估位置）和语义（描述高级概念），提供动态的提示、答案键和构建脚本。

Result: 评估当代LLMs发现，在所有五个类别中都存在持续的弱点，并提供了按类别的结果和错误分析。

Conclusion: ChessQA提供了比先前简单走子质量评估更全面的象棋能力评估，为诊断和比较提供了受控、一致的设置，并将发布代码、定期更新的数据集和公共排行榜以支持进一步研究。

Abstract: Chess provides an ideal testbed for evaluating the reasoning, modeling, and
abstraction capabilities of large language models (LLMs), as it has
well-defined structure and objective ground truth while admitting a wide
spectrum of skill levels. However, existing evaluations of LLM ability in chess
are ad hoc and narrow in scope, making it difficult to accurately measure LLM
chess understanding and how it varies with scale, post-training methodologies,
or architecture choices. We present ChessQA, a comprehensive benchmark that
assesses LLM chess understanding across five task categories (Structural,
Motifs, Short Tactics, Position Judgment, and Semantic), which approximately
correspond to the ascending abstractions that players master as they accumulate
chess knowledge, from understanding basic rules and learning tactical motifs to
correctly calculating tactics, evaluating positions, and semantically
describing high-level concepts. In this way, ChessQA captures a more
comprehensive picture of chess ability and understanding, going significantly
beyond the simple move quality evaluations done previously, and offers a
controlled, consistent setting for diagnosis and comparison. Furthermore,
ChessQA is inherently dynamic, with prompts, answer keys, and construction
scripts that can evolve as models improve. Evaluating a range of contemporary
LLMs, we find persistent weaknesses across all five categories and provide
results and error analyses by category. We will release the code, periodically
refreshed datasets, and a public leaderboard to support further research.

</details>


### [41] [A Pragmatic Way to Measure Chain-of-Thought Monitorability](https://arxiv.org/abs/2510.23966)
*Scott Emmons,Roland S. Zimmermann,David K. Elson,Rohin Shah*

Main category: cs.LG

TL;DR: 本文提出了一种实用的方法来衡量思维链(CoT)的可监控性，包括可读性和覆盖度两个指标，并通过自动评分器在多个前沿模型上进行验证。


<details>
  <summary>Details</summary>
Motivation: 为了帮助保持AI系统的可监控性，防止因训练实践或模型架构变化而丧失思维链监控的机会。

Method: 开发了自动评分器提示，使用大型语言模型计算现有思维链的可读性和覆盖度，并在合成退化的思维链上进行验证。

Result: 在具有挑战性的基准测试中，多个前沿模型表现出高可监控性。

Conclusion: 该方法为开发者提供了一个跟踪设计决策对可监控性影响的工具，是故意规避模型对抗性压力测试的补充而非替代。

Abstract: While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI
safety, this opportunity could be lost through shifts in training practices or
model architecture. To help preserve monitorability, we propose a pragmatic way
to measure two components of it: legibility (whether the reasoning can be
followed by a human) and coverage (whether the CoT contains all the reasoning
needed for a human to also produce the final output). We implement these
metrics with an autorater prompt that enables any capable LLM to compute the
legibility and coverage of existing CoTs. After sanity-checking our prompted
autorater with synthetic CoT degradations, we apply it to several frontier
models on challenging benchmarks, finding that they exhibit high
monitorability. We present these metrics, including our complete autorater
prompt, as a tool for developers to track how design decisions impact
monitorability. While the exact prompt we share is still a preliminary version
under ongoing development, we are sharing it now in the hopes that others in
the community will find it useful. Our method helps measure the default
monitorability of CoT - it should be seen as a complement, not a replacement,
for the adversarial stress-testing needed to test robustness against
deliberately evasive models.

</details>


### [42] [An efficient probabilistic hardware architecture for diffusion-like models](https://arxiv.org/abs/2510.23972)
*Andraž Jelinčič,Owen Lockwood,Akhil Garlapati,Guillaume Verdon,Trevor McCourt*

Main category: cs.LG

TL;DR: 提出一种全晶体管概率计算机，在硬件层面实现强大的去噪模型，相比GPU在简单图像基准测试中可实现性能相当但能耗降低约10,000倍。


<details>
  <summary>Details</summary>
Motivation: 现有的概率AI专用计算机提案由于依赖有限建模技术和不可扩展的异质硬件而未能获得广泛应用，需要解决这些缺陷。

Method: 设计全晶体管概率计算机架构，在硬件层面直接实现强大的去噪模型。

Result: 系统级分析表明，基于该架构的设备在简单图像基准测试中与GPU性能相当，但能耗降低约10,000倍。

Conclusion: 该全晶体管概率计算机架构解决了现有概率计算方案的局限性，具有显著的能效优势，有望推动概率AI的实际应用。

Abstract: The proliferation of probabilistic AI has promoted proposals for specialized
stochastic computers. Despite promising efficiency gains, these proposals have
failed to gain traction because they rely on fundamentally limited modeling
techniques and exotic, unscalable hardware. In this work, we address these
shortcomings by proposing an all-transistor probabilistic computer that
implements powerful denoising models at the hardware level. A system-level
analysis indicates that devices based on our architecture could achieve
performance parity with GPUs on a simple image benchmark using approximately
10,000 times less energy.

</details>


### [43] [Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.23974)
*Byeonghu Na,Minsang Park,Gyuwon Sim,Donghyeok Shin,HeeSun Bae,Mina Kang,Se Jung Kwon,Wanmo Kang,Il-Chul Moon*

Main category: cs.LG

TL;DR: DATE方法通过在每个扩散时间步动态更新文本嵌入，基于中间扰动数据优化文本条件，无需额外训练即可提升文本-图像对齐质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在整个扩散过程中使用固定的文本嵌入，限制了文本条件在生成过程中的适应性。

Method: 提出扩散自适应文本嵌入（DATE），在每个扩散时间步基于中间扰动数据动态更新文本嵌入，通过优化问题推导更新规则。

Result: DATE在保持模型生成能力的同时，在多概念生成和文本引导图像编辑等任务中提供了优于固定文本嵌入的文本-图像对齐效果。

Conclusion: DATE方法能够在不需额外训练的情况下，通过动态调整文本嵌入显著提升文本到图像生成的对齐质量。

Abstract: Text-to-image diffusion models rely on text embeddings from a pre-trained
text encoder, but these embeddings remain fixed across all diffusion timesteps,
limiting their adaptability to the generative process. We propose Diffusion
Adaptive Text Embedding (DATE), which dynamically updates text embeddings at
each diffusion timestep based on intermediate perturbed data. We formulate an
optimization problem and derive an update rule that refines the text embeddings
at each sampling step to improve alignment and preference between the mean
predicted image and the text. This allows DATE to dynamically adapts the text
conditions to the reverse-diffused images throughout diffusion sampling without
requiring additional model training. Through theoretical analysis and empirical
results, we show that DATE maintains the generative capability of the model
while providing superior text-image alignment over fixed text embeddings across
various tasks, including multi-concept generation and text-guided image
editing. Our code is available at https://github.com/aailab-kaist/DATE.

</details>


### [44] [Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling](https://arxiv.org/abs/2510.23977)
*Yohan Abeysinghe,Muhammad Akhtar Munir,Sanoojan Baliah,Ron Sarafian,Fahad Shahbaz Khan,Yinon Rudich,Salman Khan*

Main category: cs.LG

TL;DR: SynCast是一种高分辨率神经预测模型，通过整合气象和空气成分数据来改善平均和极端污染水平的预测，特别针对野火、城市雾霾和沙尘暴等导致的罕见但危险的污染事件。


<details>
  <summary>Details</summary>
Motivation: 空气污染是全球健康和环境的主要风险，现有模型往往低估罕见但危险的污染事件，需要更准确的颗粒物浓度预测来支持及时的公共卫生预警和干预。

Method: 基于区域适应的transformer架构，结合扩散基随机细化模块，利用ERA5和CAMS数据集，采用领域感知目标和极值理论指导的损失函数。

Result: 模型在多个PM变量（PM1、PM2.5、PM10）的预测保真度上显著提升，特别是在极端条件下表现优异，且不影响全局准确性。

Conclusion: SynCast为下一代空气质量早期预警系统提供了可扩展的基础，支持脆弱地区的气候健康风险缓解。

Abstract: Air pollution remains a leading global health and environmental risk,
particularly in regions vulnerable to episodic air pollution spikes due to
wildfires, urban haze and dust storms. Accurate forecasting of particulate
matter (PM) concentrations is essential to enable timely public health warnings
and interventions, yet existing models often underestimate rare but hazardous
pollution events. Here, we present SynCast, a high-resolution neural
forecasting model that integrates meteorological and air composition data to
improve predictions of both average and extreme pollution levels. Built on a
regionally adapted transformer backbone and enhanced with a diffusion-based
stochastic refinement module, SynCast captures the nonlinear dynamics driving
PM spikes more accurately than existing approaches. Leveraging on harmonized
ERA5 and CAMS datasets, our model shows substantial gains in forecasting
fidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),
especially under extreme conditions. We demonstrate that conventional loss
functions underrepresent distributional tails (rare pollution events) and show
that SynCast, guided by domain-aware objectives and extreme value theory,
significantly enhances performance in highly impacted regions without
compromising global accuracy. This approach provides a scalable foundation for
next-generation air quality early warning systems and supports climate-health
risk mitigation in vulnerable regions.

</details>


### [45] [Optimal Arm Elimination Algorithms for Combinatorial Bandits](https://arxiv.org/abs/2510.23992)
*Yuxiao Wen,Yanjun Han,Zhengyuan Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的消除算法，用于组合多臂老虎机问题，通过将臂分为确认、活跃和消除三类，并引入显式探索来更新这些集合。该方法在图反馈和线性上下文组合老虎机中均实现了接近最优的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 组合老虎机扩展了经典老虎机框架，使学习者在每轮选择多个臂，适用于在线推荐和分类优化等应用。虽然UCB算法自然扩展到此场景，但臂消除方法的适应更具挑战性。

Method: 引入新颖的消除方案，将臂分为确认、活跃和消除三类，并加入显式探索来更新这些集合。应用于图反馈组合老虎机和线性上下文组合老虎机两个场景。

Result: 该方法在两个场景中均实现了接近最优的遗憾界，而基于UCB的方法由于缺乏足够的显式探索可能失败。同时提供了匹配的下界证明。

Conclusion: 提出的消除算法在组合老虎机问题中表现出色，克服了UCB方法的局限性，为组合老虎机问题提供了有效的解决方案。

Abstract: Combinatorial bandits extend the classical bandit framework to settings where
the learner selects multiple arms in each round, motivated by applications such
as online recommendation and assortment optimization. While extensions of upper
confidence bound (UCB) algorithms arise naturally in this context, adapting arm
elimination methods has proved more challenging. We introduce a novel
elimination scheme that partitions arms into three categories (confirmed,
active, and eliminated), and incorporates explicit exploration to update these
sets. We demonstrate the efficacy of our algorithm in two settings: the
combinatorial multi-armed bandit with general graph feedback, and the
combinatorial linear contextual bandit. In both cases, our approach achieves
near-optimal regret, whereas UCB-based methods can provably fail due to
insufficient explicit exploration. Matching lower bounds are also provided.

</details>


### [46] [Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory Derived Features: Proof of Concept](https://arxiv.org/abs/2510.23994)
*Geoffery Agorku,Sarah Hernandez,Hayley Hames,Cade Wagner*

Main category: cs.LG

TL;DR: 本研究提出了一种使用AIS数据和机器学习预测内河驳船数量的新方法，通过30个AIS特征和6种回归模型，Poisson回归器表现最佳，MAE为1.92艘驳船。


<details>
  <summary>Details</summary>
Motivation: 由于驳船的非自航特性和现有监测系统的局限性，准确实时估计内河航道上的驳船数量仍然是一个关键挑战。

Method: 使用AIS船舶跟踪数据，通过时空匹配程序将卫星图像中手动标注的驳船实例与AIS轨迹匹配，创建30个AIS衍生特征，使用递归特征消除评估特征重要性，训练6种回归模型。

Result: Poisson回归器模型表现最佳，使用30个特征中的12个，平均绝对误差为1.92艘驳船。特征重要性分析显示，捕获船舶机动性的指标如航向熵、速度变异性和行程长度最能预测驳船数量。

Conclusion: 该方法为增强海事领域感知提供了一种可扩展、易于实施的方法，在船闸调度、港口管理和货运规划方面具有强大应用潜力。未来工作将扩展到其他内河河流的模型可转移性研究。

Abstract: Accurate, real-time estimation of barge quantity on inland waterways remains
a critical challenge due to the non-self-propelled nature of barges and the
limitations of existing monitoring systems. This study introduces a novel
method to use Automatic Identification System (AIS) vessel tracking data to
predict the number of barges in tow using Machine Learning (ML). To train and
test the model, barge instances were manually annotated from satellite scenes
across the Lower Mississippi River. Labeled images were matched to AIS vessel
tracks using a spatiotemporal matching procedure. A comprehensive set of 30
AIS-derived features capturing vessel geometry, dynamic movement, and
trajectory patterns were created and evaluated using Recursive Feature
Elimination (RFE) to identify the most predictive variables. Six regression
models, including ensemble, kernel-based, and generalized linear approaches,
were trained and evaluated. The Poisson Regressor model yielded the best
performance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of
the 30 features. The feature importance analysis revealed that metrics
capturing vessel maneuverability such as course entropy, speed variability and
trip length were most predictive of barge count. The proposed approach provides
a scalable, readily implementable method for enhancing Maritime Domain
Awareness (MDA), with strong potential applications in lock scheduling, port
management, and freight planning. Future work will expand the proof of concept
presented here to explore model transferability to other inland rivers with
differing operational and environmental conditions.

</details>


### [47] [Spatio-temporal Multivariate Time Series Forecast with Chosen Variables](https://arxiv.org/abs/2510.24027)
*Zibo Liu,Zhe Jiang,Zelin Xu,Tingsong Xiao,Yupu Zhang,Zhengkun Xiao,Haibo Wang,Shigang Chen*

Main category: cs.LG

TL;DR: 本文提出了一种新的时空多元时间序列预测问题——选择变量预测，通过优化选择m个变量作为模型输入来提高预测精度，并提出了一个联合变量选择和模型优化的统一框架。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设输入变量是预先确定的，但如何选择最优的m个变量作为输入从未被研究。本文旨在填补这一空白，解决预算约束下如何选择最优传感器位置的问题。

Method: 提出了包含三个技术组件的统一框架：(1) 掩码变量参数剪枝，通过基于分位数的掩码逐步剪枝信息量较少的变量和注意力参数；(2) 优先变量参数回放，回放低损失历史样本以保持模型稳定性；(3) 动态外推机制，通过可学习的空间嵌入和邻接信息将信息从输入变量传播到所有其他变量。

Result: 在五个真实世界数据集上的实验表明，该方法在准确性和效率方面显著优于现有最先进基线方法。

Conclusion: 联合变量选择和模型优化的方法在时空多元时间序列预测中具有显著优势，能够有效提高预测精度和模型效率。

Abstract: Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series
of $n$ spatially distributed variables in a period of recent past to forecast
their values in a period of near future. It has important applications in
spatio-temporal sensing forecast such as road traffic prediction and air
pollution prediction. Recent papers have addressed a practical problem of
missing variables in the model input, which arises in the sensing applications
where the number $m$ of sensors is far less than the number $n$ of locations to
be monitored, due to budget constraints. We observe that the state of the art
assumes that the $m$ variables (i.e., locations with sensors) in the model
input are pre-determined and the important problem of how to choose the $m$
variables in the input has never been studied. This paper fills the gap by
studying a new problem of STMF with chosen variables, which optimally selects
$m$-out-of-$n$ variables for the model input in order to maximize the forecast
accuracy. We propose a unified framework that jointly performs variable
selection and model optimization for both forecast accuracy and model
efficiency. It consists of three novel technical components: (1) masked
variable-parameter pruning, which progressively prunes less informative
variables and attention parameters through quantile-based masking; (2)
prioritized variable-parameter replay, which replays low-loss past samples to
preserve learned knowledge for model stability; (3) dynamic extrapolation
mechanism, which propagates information from variables selected for the input
to all other variables via learnable spatial embeddings and adjacency
information. Experiments on five real-world datasets show that our work
significantly outperforms the state-of-the-art baselines in both accuracy and
efficiency, demonstrating the effectiveness of joint variable selection and
model optimization.

</details>


### [48] [GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research](https://arxiv.org/abs/2510.24035)
*Xinqi Li,Yiqun Liu,Shan Jiang,Enrong Zheng,Huaijin Zheng,Wenhao Dai,Haodong Deng,Dianhai Yu,Yanjun Ma*

Main category: cs.LG

TL;DR: GraphNet是一个包含2700个真实深度学习计算图的数据集，涵盖6个主要任务类别和多种框架。提出了Speedup Score S(t)和Error-aware Speedup Score ES(t)两个基准指标来评估张量编译器性能，并在CV和NLP样本上测试了CINN和TorchInductor编译器。


<details>
  <summary>Details</summary>
Motivation: 现有张量编译器评估缺乏真实世界计算图数据集和可靠的性能度量标准，需要构建一个全面的基准来评估编译器优化能力。

Method: 构建GraphNet数据集，包含2700个真实深度学习计算图；提出Speedup Score S(t)指标综合考虑运行加速比和执行正确性；扩展为ES(t)指标加入错误信息；在CV和NLP样本上测试CINN和TorchInductor编译器。

Result: 成功构建了GraphNet数据集，提出了有效的性能评估指标，并展示了在真实编译器上的应用，证明了该数据集的实用性。

Conclusion: GraphNet为张量编译器评估提供了有价值的基准，提出的S(t)和ES(t)指标能可靠衡量编译器优化能力，有助于开发者识别性能瓶颈。

Abstract: We introduce GraphNet, a dataset of 2.7K real-world deep learning
computational graphs with rich metadata, spanning six major task categories
across multiple deep learning frameworks. To evaluate tensor compiler
performance on these samples, we propose the benchmark metric Speedup Score
S(t), which jointly considers runtime speedup and execution correctness under
tunable tolerance levels, offering a reliable measure of general optimization
capability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),
which incorporates error information and helps compiler developers identify key
performance bottlenecks. In this report, we benchmark the default tensor
compilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer
vision (CV) and natural language processing (NLP) samples to demonstrate the
practicality of GraphNet. The full construction pipeline with graph extraction
and compiler evaluation tools is available at
https://github.com/PaddlePaddle/GraphNet .

</details>


### [49] [Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection](https://arxiv.org/abs/2510.24043)
*Akira Tamamori*

Main category: cs.LG

TL;DR: Two-Stage LKPLO是一个新颖的多阶段异常检测框架，通过结合广义损失函数、全局核PCA和局部聚类，克服了传统投影方法依赖固定统计指标和假设单一数据结构的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统投影异常检测方法的两大共存局限：依赖固定统计指标和假设单一数据结构，这些限制导致在复杂数据结构下性能不佳。

Method: 提出三阶段方法：1) 广义损失函数PLO替代固定指标；2) 全局核PCA线性化非线性结构；3) 局部聚类处理多模态分布。

Result: 在10个基准数据集上的5折交叉验证显示，该方法在具有挑战性结构的数据集上显著优于基线方法，特别是在多簇数据和复杂高维数据上表现优异。

Conclusion: 该工作为重要类别的异常检测问题提供了强大新工具，并强调了混合多阶段架构的重要性，消融研究证实核化和局部化阶段的协同组合对优异性能不可或缺。

Abstract: This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection
framework that overcomes the coexisting limitations of conventional
projection-based methods: their reliance on a fixed statistical metric and
their assumption of a single data structure. Our framework uniquely synthesizes
three key concepts: (1) a generalized loss-based outlyingness measure (PLO)
that replaces the fixed metric with flexible, adaptive loss functions like our
proposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear
data structures; and (3) a subsequent local clustering stage to handle
multi-modal distributions. Comprehensive 5-fold cross-validation experiments on
10 benchmark datasets, with automated hyperparameter optimization, demonstrate
that Two-Stage LKPLO achieves state-of-the-art performance. It significantly
outperforms strong baselines on datasets with challenging structures where
existing methods fail, most notably on multi-cluster data (Optdigits) and
complex, high-dimensional data (Arrhythmia). Furthermore, an ablation study
empirically confirms that the synergistic combination of both the kernelization
and localization stages is indispensable for its superior performance. This
work contributes a powerful new tool for a significant class of outlier
detection problems and underscores the importance of hybrid, multi-stage
architectures.

</details>


### [50] [Mitigating Negative Transfer via Reducing Environmental Disagreement](https://arxiv.org/abs/2510.24044)
*Hui Sun,Zheng Xie,Hao-Yuan He,Ming Li*

Main category: cs.LG

TL;DR: 本文提出了一种通过因果解耦学习减少环境分歧的方法（RED），来解决无监督域自适应中的负迁移问题。该方法通过对抗训练分离因果特征和环境特征，并减少跨域环境特征的分歧，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 无监督域自适应面临域偏移导致的负迁移问题，即模型性能下降。研究发现过度依赖非因果环境特征会导致跨域判别分歧，这是负迁移的关键因素。

Method: 提出RED方法：1）通过对抗训练域特定环境特征提取器，将样本解耦为域不变因果特征和域特定非因果环境特征；2）基于域特定非因果环境特征估计并减少环境分歧。

Result: 实验结果表明RED方法有效缓解了负迁移问题，并取得了最先进的性能。

Conclusion: 通过因果解耦学习减少环境分歧是解决无监督域自适应中负迁移问题的有效途径，RED方法在理论和实验上都验证了其有效性。

Abstract: Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a
labeled source domain to an unlabeled target domain, addressing the challenge
of \emph{domain shift}. Significant domain shifts hinder effective knowledge
transfer, leading to \emph{negative transfer} and deteriorating model
performance. Therefore, mitigating negative transfer is essential. This study
revisits negative transfer through the lens of causally disentangled learning,
emphasizing cross-domain discriminative disagreement on non-causal
environmental features as a critical factor. Our theoretical analysis reveals
that overreliance on non-causal environmental features as the environment
evolves can cause discriminative disagreements~(termed \emph{environmental
disagreement}), thereby resulting in negative transfer. To address this, we
propose Reducing Environmental Disagreement~(RED), which disentangles each
sample into domain-invariant causal features and domain-specific non-causal
environmental features via adversarially training domain-specific environmental
feature extractors in the opposite domains. Subsequently, RED estimates and
reduces environmental disagreement based on domain-specific non-causal
environmental features. Experimental results confirm that RED effectively
mitigates negative transfer and achieves state-of-the-art performance.

</details>


### [51] [Causal-Aware Generative Adversarial Networks with Reinforcement Learning](https://arxiv.org/abs/2510.24046)
*Tu Anh Hoang Nguyen,Dang Nguyen,Tri-Nhan Vo,Thuc Duy Le,Sunil Gupta*

Main category: cs.LG

TL;DR: CA-GAN是一个专门为表格数据设计的生成框架，通过因果图提取和条件WGAN-GP结合强化学习目标，在保持数据效用和隐私保护的同时捕获复杂因果关系。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN的数据生成方法在捕获复杂因果关系、保持数据效用和提供可证明的隐私保证方面存在不足，限制了表格数据在模型训练和大规模数据分析中的应用。

Method: 采用两步法：首先提取因果图学习数据流形中的因果关系，然后使用条件WGAN-GP按照因果图结构生成数据，并通过强化学习目标对齐真实和生成数据的因果图。

Result: 在14个表格数据集上优于6种最先进方法，在因果保持、效用保持和隐私保持三个核心数据工程指标上表现优异。

Conclusion: CA-GAN为数据工程师提供了一个实用、高性能的解决方案，能够创建高质量、符合隐私要求的合成数据集，用于基准测试数据库系统、加速软件开发和促进安全的数据驱动研究。

Abstract: The utility of tabular data for tasks ranging from model training to
large-scale data analysis is often constrained by privacy concerns or
regulatory hurdles. While existing data generation methods, particularly those
based on Generative Adversarial Networks (GANs), have shown promise, they
frequently struggle with capturing complex causal relationship, maintaining
data utility, and providing provable privacy guarantees suitable for enterprise
deployment. We introduce CA-GAN, a novel generative framework specifically
engineered to address these challenges for real-world tabular datasets. CA-GAN
utilizes a two-step approach: causal graph extraction to learn a robust,
comprehensive causal relationship in the data's manifold, followed by a custom
Conditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates
exclusively as per the structure of nodes in the causal graph. More
importantly, the generator is trained with a new Reinforcement Learning-based
objective that aligns the causal graphs constructed from real and fake data,
ensuring the causal awareness in both training and sampling phases. We
demonstrate CA-GAN superiority over six SOTA methods across 14 tabular
datasets. Our evaluations, focused on core data engineering metrics: causal
preservation, utility preservation, and privacy preservation. Our method offers
a practical, high-performance solution for data engineers seeking to create
high-quality, privacy-compliant synthetic datasets to benchmark database
systems, accelerate software development, and facilitate secure data-driven
research.

</details>


### [52] [Low-N Protein Activity Optimization with FolDE](https://arxiv.org/abs/2510.24053)
*Jacob B. Roberts,Catherine R. Ji,Isaac Donnell,Thomas D. Young,Allison N. Pearson,Graham A. Hudson,Leah S. Keiser,Mia Wesselkamper,Peter H. Winegar,Janik Ludwig,Sarah H. Klass,Isha V. Sheth,Ezechinyere C. Ukabiala,Maria C. T. Astolfi,Benjamin Eysenbach,Jay D. Keasling*

Main category: cs.LG

TL;DR: FolDE是一种主动学习辅助定向进化方法，通过自然性预热启动和恒定谎言批量选择器，在蛋白质优化中比现有方法发现更多优质突变体。


<details>
  <summary>Details</summary>
Motivation: 传统蛋白质优化方法成本高昂，现有主动学习辅助定向进化方法存在训练数据同质化问题，导致后续预测模型不准确。

Method: FolDE采用自然性预热启动（利用蛋白质语言模型输出增强有限活性测量）和恒定谎言批量选择器（提高批量多样性）来最大化优化效果。

Result: 在20个蛋白质靶点的模拟中，FolDE比最佳基线方法多发现23%的前10%突变体，找到前1%突变体的可能性高55%。

Conclusion: FolDE通过改进的预热启动和批量选择策略，显著提高了蛋白质优化效率，且作为开源软件可供任何实验室使用。

Abstract: Proteins are traditionally optimized through the costly construction and
measurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)
alleviates that cost by predicting the best improvements and iteratively
testing mutants to inform predictions. However, existing ALDE methods face a
critical limitation: selecting the highest-predicted mutants in each round
yields homogeneous training data insufficient for accurate prediction models in
subsequent rounds. Here we present FolDE, an ALDE method designed to maximize
end-of-campaign success. In simulations across 20 protein targets, FolDE
discovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)
and is 55% more likely to find top 1% mutants. FolDE achieves this primarily
through naturalness-based warm-starting, which augments limited activity
measurements with protein language model outputs to improve activity
prediction. We also introduce a constant-liar batch selector, which improves
batch diversity; this is important in multi-mutation campaigns but had limited
effect in our benchmarks. The complete workflow is freely available as
open-source software, making efficient protein optimization accessible to any
laboratory.

</details>


### [53] [Information-Theoretic Discrete Diffusion](https://arxiv.org/abs/2510.24088)
*Moongyu Jeon,Sangwoo Shin,Dongjae Jeon,Albert No*

Main category: cs.LG

TL;DR: 提出了一个离散扩散模型的信息论框架，通过分数匹配损失构建对数似然的有原则估计器。推导了离散设置下的信息-最小去噪分数熵关系，将互信息与最小去噪分数熵损失联系起来，并扩展到掩码扩散过程。


<details>
  <summary>Details</summary>
Motivation: 受高斯设置中I-MMSE恒等式的启发，希望在离散设置中建立类似的理论框架，为离散扩散模型提供理论支撑，证明常用的损失函数不仅是变分下界，而是紧致的对数似然估计器。

Method: 引入信息-最小去噪分数熵关系，将数据与其扩散版本之间的互信息与最小去噪分数熵损失联系起来。扩展到掩码扩散，建立信息-最小去噪交叉熵关系。提供了对数似然的时间积分分解。

Result: 实验在合成和真实世界数据上验证了估计器的准确性、方差稳定性和实用性。实现了时间无关公式、提示-响应任务中的条件似然估计以及似然比的耦合蒙特卡洛估计。

Conclusion: 该框架为离散扩散模型提供了信息论基础，证明了常用损失函数是有原则的对数似然估计器，并支持多种实际扩展应用。

Abstract: We present an information-theoretic framework for discrete diffusion models
that yields principled estimators of log-likelihood using score-matching
losses. Inspired by the I-MMSE identity for the Gaussian setup, we derive
analogous results for the discrete setting. Specifically, we introduce the
Information-Minimum Denoising Score Entropy (I-MDSE) relation, which links
mutual information between data and its diffused version to the minimum
denoising score entropy (DSE) loss. We extend this theory to masked diffusion
and establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)
relation, connecting cross-entropy losses to mutual information in discrete
masked processes. These results provide a time-integral decomposition of the
log-likelihood of the data in terms of optimal score-based losses, showing that
commonly used losses such as DSE and DCE are not merely variational bounds but
tight and principled estimators of log-likelihood. The I-MDCE decomposition
further enables practical extensions, including time-free formula, conditional
likelihood estimation in prompt-response tasks, and coupled Monte Carlo
estimation of likelihood ratios. Experiments on synthetic and real-world data
confirm the accuracy, variance stability, and utility of our estimators. The
code is publicly available at https://github.com/Dongjae0324/infodis.

</details>


### [54] [Learning Parameterized Skills from Demonstrations](https://arxiv.org/abs/2510.24095)
*Vedant Gupta,Haotian Fu,Calvin Luo,Yiding Jiang,George Konidaris*

Main category: cs.LG

TL;DR: DEPS是一种端到端算法，用于从专家演示中发现参数化技能。该方法联合学习参数化技能策略和元策略，通过时间变分推理和信息论正则化解决潜在变量模型的退化问题，确保学到的技能具有时间扩展性、语义意义和适应性。


<details>
  <summary>Details</summary>
Motivation: 从多任务专家演示中学习参数化技能，以显著提高对未见任务的泛化能力。

Method: 使用时间变分推理和信息论正则化方法，联合学习参数化技能策略和元策略，元策略在每个时间步选择适当的离散技能和连续参数。

Result: 在LIBERO和MetaWorld基准测试中，DEPS优于多任务和技能学习基线方法，并发现可解释的参数化技能，如物体抓取技能，其连续参数定义抓取位置。

Conclusion: 从多任务专家演示中学习参数化技能能显著改善对未见任务的泛化性能，DEPS方法能发现具有语义意义且可解释的参数化技能。

Abstract: We present DEPS, an end-to-end algorithm for discovering parameterized skills
from expert demonstrations. Our method learns parameterized skill policies
jointly with a meta-policy that selects the appropriate discrete skill and
continuous parameters at each timestep. Using a combination of temporal
variational inference and information-theoretic regularization methods, we
address the challenge of degeneracy common in latent variable models, ensuring
that the learned skills are temporally extended, semantically meaningful, and
adaptable. We empirically show that learning parameterized skills from
multitask expert demonstrations significantly improves generalization to unseen
tasks. Our method outperforms multitask as well as skill learning baselines on
both LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers
interpretable parameterized skills, such as an object grasping skill whose
continuous arguments define the grasp location.

</details>


### [55] [Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2510.24120)
*Ziyu Liu,Yijing Liu,Jianfei Yuan,Minzhi Yan,Le Yue,Honghui Xiong,Yi Yang*

Main category: cs.LG

TL;DR: 提出Graph-Guided Concept Selection (G2ConS)方法，通过概念选择和概念图来降低基于图的RAG系统构建知识图谱的成本，同时保持检索效果。


<details>
  <summary>Details</summary>
Motivation: 基于图的RAG方法在构建知识图谱时需要大量LLM调用来提取实体和关系，导致成本过高，特别是在需要多跳推理的领域如生物医学、法律和政治科学中。

Method: G2ConS包含两个核心组件：文档块选择方法和独立于LLM的概念图。前者选择重要文档块来降低KG构建成本，后者在零成本下填补因块选择造成的知识缺口。

Result: 在多个真实世界数据集上的评估显示，G2ConS在构建成本、检索效果和回答质量方面均优于所有基线方法。

Conclusion: G2ConS通过概念选择和概念图的创新设计，有效解决了基于图RAG系统的高成本问题，同时保持了优越的检索性能。

Abstract: Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance
retrieval in Large Language Model (LLM)-based question answering. It is
especially beneficial in domains such as biomedicine, law, and political
science, where effective retrieval often involves multi-hop reasoning over
proprietary documents. However, these methods demand numerous LLM calls to
extract entities and relations from text chunks, incurring prohibitive costs at
scale. Through a carefully designed ablation study, we observe that certain
words (termed concepts) and their associated documents are more important.
Based on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its
core comprises a chunk selection method and an LLM-independent concept graph.
The former selects salient document chunks to reduce KG construction costs; the
latter closes knowledge gaps introduced by chunk selection at zero cost.
Evaluations on multiple real-world datasets show that G2ConS outperforms all
baselines in construction cost, retrieval effectiveness, and answering quality.

</details>


### [56] [Identifiable learning of dissipative dynamics](https://arxiv.org/abs/2510.24160)
*Aiqing Zhu,Beatrice W. Soh,Grigorios A. Pavliotis,Qianxiao Li*

Main category: cs.LG

TL;DR: I-OnsagerNet是一个神经框架，用于从轨迹数据中学习耗散随机动力学，同时确保可解释性和唯一性。该方法扩展了Onsager原理，能够计算熵产生并量化不可逆性。


<details>
  <summary>Details</summary>
Motivation: 复杂耗散系统在科学和工程中广泛存在，但远离平衡态下的能量耗散和时间不可逆性难以从数据中量化。学习准确且可解释的动力学模型仍然是一个主要挑战。

Method: I-OnsagerNet扩展Onsager原理，确保学习到的势能从稳态密度获得，漂移项干净地分解为时间可逆和时间不可逆分量，遵循Helmholtz分解。

Result: 应用于聚合物拉伸和随机梯度Langevin动力学，揭示了新的见解：势垒高度的超线性缩放、熵产生率的亚线性缩放，以及随着批量大小增加不可逆性被抑制。

Conclusion: I-OnsagerNet建立了一个通用的数据驱动框架，用于发现和解释非平衡动力学。

Abstract: Complex dissipative systems appear across science and engineering, from
polymers and active matter to learning algorithms. These systems operate far
from equilibrium, where energy dissipation and time irreversibility are key to
their behavior, but are difficult to quantify from data. Learning accurate and
interpretable models of such dynamics remains a major challenge: the models
must be expressive enough to describe diverse processes, yet constrained enough
to remain physically meaningful and mathematically identifiable. Here, we
introduce I-OnsagerNet, a neural framework that learns dissipative stochastic
dynamics directly from trajectories while ensuring both interpretability and
uniqueness. I-OnsagerNet extends the Onsager principle to guarantee that the
learned potential is obtained from the stationary density and that the drift
decomposes cleanly into time-reversible and time-irreversible components, as
dictated by the Helmholtz decomposition. Our approach enables us to calculate
the entropy production and to quantify irreversibility, offering a principled
way to detect and quantify deviations from equilibrium. Applications to polymer
stretching in elongational flow and to stochastic gradient Langevin dynamics
reveal new insights, including super-linear scaling of barrier heights and
sub-linear scaling of entropy production rates with the strain rate, and the
suppression of irreversibility with increasing batch size. I-OnsagerNet thus
establishes a general, data-driven framework for discovering and interpreting
non-equilibrium dynamics.

</details>


### [57] [EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale](https://arxiv.org/abs/2510.24173)
*Yiheng Du,Aditi S. Krishnapriyan*

Main category: cs.LG

TL;DR: EddyFormer是一种基于Transformer的谱元架构，用于大规模湍流模拟，结合了谱方法的精度和注意力机制的可扩展性，在256^3分辨率下达到DNS级别精度，速度提升30倍，并展示出良好的领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于湍流的多尺度特性，完全通过直接数值模拟(DNS)解析大规模湍流计算成本过高，需要数据驱动的机器学习替代方案。

Method: 提出EddyFormer，一种基于Transformer的谱元架构，引入SEM标记化方法将流动分解为网格尺度和亚网格尺度分量，结合谱方法的精度和注意力机制的可扩展性。

Result: 在256^3分辨率下达到DNS级别精度，速度提升30倍；在未见域上保持物理不变指标的准确性；在The Well基准测试套件中准确再现复杂动力学。

Conclusion: EddyFormer成功结合了谱方法的精度和Transformer的可扩展性，为大规模湍流模拟提供了高效准确的解决方案，并展示了良好的泛化能力。

Abstract: Computationally resolving turbulence remains a central challenge in fluid
dynamics due to its multi-scale interactions. Fully resolving large-scale
turbulence through direct numerical simulation (DNS) is computationally
prohibitive, motivating data-driven machine learning alternatives. In this
work, we propose EddyFormer, a Transformer-based spectral-element (SEM)
architecture for large-scale turbulence simulation that combines the accuracy
of spectral methods with the scalability of the attention mechanism. We
introduce an SEM tokenization that decomposes the flow into grid-scale and
subgrid-scale components, enabling capture of both local and global features.
We create a new three-dimensional isotropic turbulence dataset and train
EddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x
speedup over DNS. When applied to unseen domains up to 4x larger than in
training, EddyFormer preserves accuracy on physics-invariant metrics-energy
spectra, correlation functions, and structure functions-showing domain
generalization. On The Well benchmark suite of diverse turbulent flows,
EddyFormer resolves cases where prior ML models fail to converge, accurately
reproducing complex dynamics across a wide range of physical conditions.

</details>


### [58] [V-SAT: Video Subtitle Annotation Tool](https://arxiv.org/abs/2510.24180)
*Arpita Kundu,Joyita Chakraborty,Anindita Desarkar,Aritra Sen,Srushti Anil Patil,Vishwanathan Raman*

Main category: cs.LG

TL;DR: V-SAT是一个统一的视频字幕标注工具，通过结合LLM、VLM、图像处理和ASR技术，自动检测和修正多种字幕质量问题，显著提升字幕质量。


<details>
  <summary>Details</summary>
Motivation: 当前字幕生成方法存在同步性差、文本错误、格式不一致、阅读速度不当等问题，现有方法只能解决孤立问题，导致后期编辑工作繁重耗时。

Method: 结合大型语言模型(LLM)、视觉语言模型(VLM)、图像处理和自动语音识别(ASR)，利用音频和视频的上下文信息进行字幕质量检测和修正。

Result: 字幕质量显著提升，SUBER分数从9.6降至3.54，图像模式问题的F1分数达到约0.80，通过人工验证确保高质量结果。

Conclusion: V-SAT提供了首个全面的鲁棒字幕标注解决方案，能够有效解决多种字幕质量问题。

Abstract: The surge of audiovisual content on streaming platforms and social media has
heightened the demand for accurate and accessible subtitles. However, existing
subtitle generation methods primarily speech-based transcription or OCR-based
extraction suffer from several shortcomings, including poor synchronization,
incorrect or harmful text, inconsistent formatting, inappropriate reading
speeds, and the inability to adapt to dynamic audio-visual contexts. Current
approaches often address isolated issues, leaving post-editing as a
labor-intensive and time-consuming process. In this paper, we introduce V-SAT
(Video Subtitle Annotation Tool), a unified framework that automatically
detects and corrects a wide range of subtitle quality issues. By combining
Large Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,
and Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from
both audio and video. Subtitle quality improved, with the SUBER score reduced
from 9.6 to 3.54 after resolving all language mode issues and F1-scores of
~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality
results, providing the first comprehensive solution for robust subtitle
annotation.

</details>


### [59] [SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning](https://arxiv.org/abs/2510.24200)
*Alexander Bakarsky,Dimitar I. Dimitrov,Maximilian Baader,Martin Vechev*

Main category: cs.LG

TL;DR: SPEAR++攻击通过应用稀疏字典学习技术，显著提升了SPEAR攻击的效率，使其能够处理10倍更大的批次大小，同时保持对DP噪声和FedAvg聚合的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然实现了分布式训练而不共享数据，但梯度反转攻击挑战了其隐私保护特性。现有的SPEAR攻击虽然理论上有突破，但由于指数级时间复杂度，在实际应用中的实用性受限。

Method: 应用最先进的稀疏字典学习技术来解决具有ReLU激活的线性层的梯度反转问题，使问题变得可处理。

Result: SPEAR++攻击在保持SPEAR所有理想特性的同时，能够应用于10倍更大的批次大小，且对DP噪声和FedAvg聚合具有鲁棒性。

Conclusion: SPEAR++攻击填补了SPEAR攻击在实际应用中的效率差距，为评估联邦学习系统的隐私漏洞提供了更实用的工具。

Abstract: Federated Learning has seen an increased deployment in real-world scenarios
recently, as it enables the distributed training of machine learning models
without explicit data sharing between individual clients. Yet, the introduction
of the so-called gradient inversion attacks has fundamentally challenged its
privacy-preserving properties. Unfortunately, as these attacks mostly rely on
direct data optimization without any formal guarantees, the vulnerability of
real-world systems remains in dispute and requires tedious testing for each new
federated deployment. To overcome these issues, recently the SPEAR attack was
introduced, which is based on a theoretical analysis of the gradients of linear
layers with ReLU activations. While SPEAR is an important theoretical
breakthrough, the attack's practicality was severely limited by its exponential
runtime in the batch size b. In this work, we fill this gap by applying
State-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the
problem of gradient inversion on linear layers with ReLU activations tractable.
Our experiments demonstrate that our new attack, SPEAR++, retains all desirable
properties of SPEAR, such as robustness to DP noise and FedAvg aggregation,
while being applicable to 10x bigger batch sizes.

</details>


### [60] [Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation](https://arxiv.org/abs/2510.24216)
*Fan Xu,Hao Wu,Kun Wang,Nan Wang,Qingsong Wen,Xian Wu,Wei Gong,Xibin Zhao*

Main category: cs.LG

TL;DR: SPARK是一个物理引导的定量增强插件，通过重构自编码器将物理参数整合到物理丰富的离散状态字典中，在潜在空间进行插值生成物理合理的训练样本，并与傅里叶增强图ODE结合进行下游预测，在数据稀缺和分布偏移场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法计算成本高，现代数据驱动方法面临数据稀缺和分布偏移问题，需要解决这些根本限制。

Method: 使用重构自编码器构建物理丰富的离散状态字典，在潜在空间进行原理性插值生成新训练样本，结合傅里叶增强图ODE进行下游预测。

Result: 在多样化基准测试中，SPARK显著优于最先进的基线方法，特别是在具有挑战性的分布外场景和数据稀缺机制中。

Conclusion: 物理引导的增强范式在解决数据稀缺和分布偏移问题上具有显著效果，证明了该方法的有效性。

Abstract: In dynamical system modeling, traditional numerical methods are limited by
high computational costs, while modern data-driven approaches struggle with
data scarcity and distribution shifts. To address these fundamental
limitations, we first propose SPARK, a physics-guided quantitative augmentation
plugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate
physical parameters into a physics-rich discrete state dictionary. This state
dictionary then acts as a structured dictionary of physical states, enabling
the creation of new, physically-plausible training samples via principled
interpolation in the latent space. Further, for downstream prediction, these
augmented representations are seamlessly integrated with a Fourier-enhanced
Graph ODE, a combination designed to robustly model the enriched data
distribution while capturing long-term temporal dependencies. Extensive
experiments on diverse benchmarks demonstrate that SPARK significantly
outperforms state-of-the-art baselines, particularly in challenging
out-of-distribution scenarios and data-scarce regimes, proving the efficacy of
our physics-guided augmentation paradigm.

</details>


### [61] [Closing Gaps: An Imputation Analysis of ICU Vital Signs](https://arxiv.org/abs/2510.24217)
*Alisher Turubayev,Anna Shopova,Fabian Lange,Mahmut Kamalak,Paul Mattes,Victoria Ayvasky,Bert Arnrich,Bjarne Pfitzner,Robin P. van de Water*

Main category: cs.LG

TL;DR: 本文比较了ICU生命体征数据缺失值填补方法，建立了包含15种填补方法和4种截断方法的可扩展基准，旨在为临床预测模型选择最准确的填补技术。


<details>
  <summary>Details</summary>
Motivation: ICU数据质量不足阻碍了机器学习在临床预测中的应用，许多生命体征测量存在大量缺失段，而现有研究缺乏对代表性填补方法的全面比较，现实中仍在使用可能降低预测准确性的临时填补技术。

Method: 建立了一个可扩展和可重用的基准测试框架，包含15种填补方法和4种截断方法，专门针对主要ICU数据集进行基准测试。

Result: 通过系统比较不同填补方法，为研究人员提供了选择最准确填补技术的指导。

Conclusion: 该基准为填补方法提供了比较基础，有助于促进更多机器学习模型进入临床实践，提高临床预测模型的性能。

Abstract: As more Intensive Care Unit (ICU) data becomes available, the interest in
developing clinical prediction models to improve healthcare protocols
increases. However, the lack of data quality still hinders clinical prediction
using Machine Learning (ML). Many vital sign measurements, such as heart rate,
contain sizeable missing segments, leaving gaps in the data that could
negatively impact prediction performance. Previous works have introduced
numerous time-series imputation techniques. Nevertheless, more comprehensive
work is needed to compare a representative set of methods for imputing ICU
vital signs and determine the best practice. In reality, ad-hoc imputation
techniques that could decrease prediction accuracy, like zero imputation, are
still used. In this work, we compare established imputation techniques to guide
researchers in improving the performance of clinical prediction models by
selecting the most accurate imputation technique. We introduce an extensible
and reusable benchmark with currently 15 imputation and 4 amputation methods,
created for benchmarking on major ICU datasets. We hope to provide a
comparative basis and facilitate further ML development to bring more models
into clinical practice.

</details>


### [62] [PRIVET: Privacy Metric Based on Extreme Value Theory](https://arxiv.org/abs/2510.24233)
*Antoine Szatkownik,Aurélien Decelle,Beatriz Seoane,Nicolas Bereux,Léo Planche,Guillaume Charpiat,Burak Yelmen,Flora Jay,Cyril Furtlehner*

Main category: cs.LG

TL;DR: PRIVET是一种基于样本的隐私泄露检测算法，使用极值统计和最近邻距离来为每个合成样本分配个体隐私泄露分数，能够可靠地检测记忆化和隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型常在敏感数据上训练，引发隐私保护合成数据的担忧。现有方法主要依赖全局标准评估隐私风险，缺乏样本级别的严格评估方法，阻碍了合成数据在实际应用中的部署。

Method: 使用极值统计和最近邻距离，提出PRIVET算法，这是一种通用的基于样本、模态无关的方法，为每个合成样本分配个体隐私泄露分数。

Result: PRIVET在各种数据模态中可靠地检测记忆化和隐私泄露，包括高维设置、有限样本量（如遗传数据）甚至欠拟合情况。相比现有方法，在提供数据集级别和样本级别评估方面具有优势。

Conclusion: PRIVET为合成数据隐私评估提供了有效的样本级别解决方案，同时揭示了现有计算机视觉嵌入在识别近似重复样本时产生感知上有意义距离的局限性。

Abstract: Deep generative models are often trained on sensitive data, such as genetic
sequences, health data, or more broadly, any copyrighted, licensed or protected
content. This raises critical concerns around privacy-preserving synthetic
data, and more specifically around privacy leakage, an issue closely tied to
overfitting. Existing methods almost exclusively rely on global criteria to
estimate the risk of privacy failure associated to a model, offering only
quantitative non interpretable insights. The absence of rigorous evaluation
methods for data privacy at the sample-level may hinder the practical
deployment of synthetic data in real-world applications. Using extreme value
statistics on nearest-neighbor distances, we propose PRIVET, a generic
sample-based, modality-agnostic algorithm that assigns an individual privacy
leak score to each synthetic sample. We empirically demonstrate that PRIVET
reliably detects instances of memorization and privacy leakage across diverse
data modalities, including settings with very high dimensionality, limited
sample sizes such as genetic data and even under underfitting regimes. We
compare our method to existing approaches under controlled settings and show
its advantage in providing both dataset level and sample level assessments
through qualitative and quantitative outputs. Additionally, our analysis
reveals limitations in existing computer vision embeddings to yield
perceptually meaningful distances when identifying near-duplicate samples.

</details>


### [63] [Sparse Optimistic Information Directed Sampling](https://arxiv.org/abs/2510.24234)
*Ludovic Schwartz,Hamish Flynn,Gergely Neu*

Main category: cs.LG

TL;DR: 本文提出了稀疏乐观信息导向采样算法，能够在数据丰富和数据贫乏两种情况下同时实现最优最坏情况遗憾，无需贝叶斯假设。


<details>
  <summary>Details</summary>
Motivation: 现有算法只能在数据丰富或数据贫乏其中一种情况下达到最优遗憾，无法同时适应两种情况。稀疏IDS算法在贝叶斯设置下能同时适应，但需要贝叶斯假设。

Method: 使用稀疏乐观信息导向采样，通过时间依赖学习率的新颖分析，平衡信息获取和遗憾最小化。

Result: SOIDS算法在数据丰富和数据贫乏两种情况下都达到了最优最坏情况遗憾，扩展了IDS的理论保证。

Conclusion: SOIDS是第一个在两种情况下同时实现最优最坏情况遗憾的算法，实验验证了其良好性能。

Abstract: Many high-dimensional online decision-making problems can be modeled as
stochastic sparse linear bandits. Most existing algorithms are designed to
achieve optimal worst-case regret in either the data-rich regime, where
polynomial depen- dence on the ambient dimension is unavoidable, or the
data-poor regime, where dimension-independence is possible at the cost of worse
dependence on the num- ber of rounds. In contrast, the sparse Information
Directed Sampling (IDS) algo- rithm satisfies a Bayesian regret bound that has
the optimal rate in both regimes simultaneously. In this work, we explore the
use of Sparse Optimistic Informa- tion Directed Sampling (SOIDS) to achieve the
same adaptivity in the worst-case setting, without Bayesian assumptions.
Through a novel analysis that enables the use of a time-dependent learning
rate, we show that SOIDS can optimally balance information and regret. Our
results extend the theoretical guarantees of IDS, pro- viding the first
algorithm that simultaneously achieves optimal worst-case regret in both the
data-rich and data-poor regimes. We empirically demonstrate the good
performance of SOIDS.

</details>


### [64] [PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling](https://arxiv.org/abs/2510.24235)
*Ai Jian,Jingqing Ruan,Xing Ma,Dailin Li,QianLin Zhou,Ke Zeng,Xunliang Cai*

Main category: cs.LG

TL;DR: 提出了一种统一的奖励模型框架PaTaRM，通过偏好感知奖励机制和动态标准适应，将成对数据转换为点式训练信号，无需显式点式标注，在多个基准测试中显著提升了奖励模型和下游RLHF性能。


<details>
  <summary>Details</summary>
Motivation: 传统成对奖励模型方法依赖二元标签导致推理不匹配，点式方法需要复杂标注且适应性差。需要一种能结合两者优势的统一框架来解决RLHF中的奖励建模问题。

Method: 提出PaTaRM框架，包含偏好感知奖励机制（利用成对数据构建点式训练信号）和任务自适应标准系统（动态生成评估标准），实现高效、可泛化且可解释的奖励建模。

Result: 在RewardBench和RMBench上平均相对提升4.7%，在IFEval和InFoBench基准测试中下游RLHF性能平均提升13.6%，验证了方法的有效性和鲁棒性。

Conclusion: PaTaRM通过统一框架解决了传统奖励模型的局限性，在减少标注成本的同时显著提升了模型性能，为RLHF提供了更高效的奖励建模解决方案。

Abstract: Reward models (RMs) are central to reinforcement learning from human feedback
(RLHF), providing the critical supervision signals that align large language
models (LLMs) with human preferences. While generative reward models (GRMs)
offer greater interpretability than traditional scalar RMs, current training
paradigms remain limited. Pair-wise methods rely on binary good-versus-bad
labels, which cause mismatches for point-wise inference and necessitate complex
pairing strategies for effective application in RLHF. On the other hand,
point-wise methods require more elaborate absolute labeling with rubric-driven
criteria, resulting in poor adaptability and high annotation costs. In this
work, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a
unified framework that integrates a preference-aware reward (PAR) mechanism
with dynamic rubric adaptation. PaTaRM leverages relative preference
information from pairwise data to construct robust point-wise training signals,
eliminating the need for explicit point-wise labels. Simultaneously, it employs
a task-adaptive rubric system that flexibly generates evaluation criteria for
both global task consistency and instance-specific fine-grained reasoning. This
design enables efficient, generalizable, and interpretable reward modeling for
RLHF. Extensive experiments show that PaTaRM achieves an average relative
improvement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B
models. Furthermore, PaTaRM boosts downstream RLHF performance, with an average
improvement of 13.6% across IFEval and InFoBench benchmarks, confirming its
effectiveness and robustness. Our code is available at
https://github.com/JaneEyre0530/PaTaRM.

</details>


### [65] [Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction](https://arxiv.org/abs/2510.24240)
*Edward Markai,Sina Molavipour*

Main category: cs.LG

TL;DR: 本文扩展了基于规则的TLogic框架，通过引入实体类别作为关键组件来限制规则应用范围，并使用LLM方法生成未知类别，提高了时序知识图谱预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱预测方法多为基于嵌入的黑盒模型，缺乏可解释性。本文旨在结合高准确率和可解释预测，提供透明性让用户能够评估预测阶段应用的规则。

Method: 扩展TLogic规则框架，引入实体类别作为规则关键组件；提出基于LLM的数据驱动方法生成未知实体类别；研究类别预测中检索实体得分的聚合方法选择。

Result: 新规则格式通过实体类别限制规则应用范围，提高了预测准确性；LLM方法能够有效生成未知实体类别；不同聚合方法对类别预测效果有影响。

Conclusion: 扩展的基于规则框架在保持高准确率的同时提供了可解释性，实体类别作为关键组件有效提升了预测性能，LLM方法为处理未知类别提供了可行方案。

Abstract: Temporal Knowledge Graphs have emerged as a powerful way of not only modeling
static relationships between entities but also the dynamics of how relations
evolve over time. As these informational structures can be used to store
information from a real-world setting, such as a news flow, predicting future
graph components to a certain extent equates predicting real-world events. Most
of the research in this field focuses on embedding-based methods, often
leveraging convolutional neural net architectures. These solutions act as black
boxes, limiting insight. In this paper, we explore an extension to an
established rule-based framework, TLogic, that yields a high accuracy in
combination with explainable predictions. This offers transparency and allows
the end-user to critically evaluate the rules applied at the end of the
prediction stage. The new rule format incorporates entity category as a key
component with the purpose of limiting rule application only to relevant
entities. When categories are unknown for building the graph, we propose a
data-driven method to generate them with an LLM-based approach. Additionally,
we investigate the choice of aggregation method for scores of retrieved
entities when performing category prediction.

</details>


### [66] [SALS: Sparse Attention in Latent Space for KV cache Compression](https://arxiv.org/abs/2510.24273)
*Junlin Mu,Hantao Huang,Jihang Zhang,Minghui Yu,Tao Wang,Yidong Li*

Main category: cs.LG

TL;DR: SALS是一种新的KV缓存压缩框架，通过将KV缓存投影到紧凑的潜在空间并在该空间执行稀疏token选择，避免了RoPE机制导致的低秩压缩性能下降问题，实现了高效的KV缓存压缩和推理加速。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型在处理长上下文时面临KV缓存大小和内存带宽的挑战，而现有的低秩压缩方法由于RoPE机制会导致严重的精度下降或新的速度瓶颈。

Method: 提出SALS框架：1）将KV缓存通过低秩投影到紧凑潜在空间；2）在该空间使用无RoPE的查询-键交互进行稀疏token选择；3）仅重建重要token子集，避免完整KV缓存重建开销。

Result: 在多个模型上验证：LLaMA2-7b-chat和Mistral-7b上实现6.4倍KV缓存压缩和5.7倍注意力算子加速；在4k和32k序列上分别比GPT-fast实现1.4倍和4.5倍的端到端吞吐量提升。

Conclusion: SALS通过潜在空间稀疏注意力机制有效解决了RoPE带来的低秩压缩挑战，在保持竞争性精度的同时实现了显著的KV缓存压缩和推理加速效果。

Abstract: Large Language Models capable of handling extended contexts are in high
demand, yet their inference remains challenging due to substantial Key-Value
cache size and high memory bandwidth requirements. Previous research has
demonstrated that KV cache exhibits low-rank characteristics within the hidden
dimension, suggesting the potential for effective compression. However, due to
the widely adopted Rotary Position Embedding mechanism in modern LLMs, naive
low-rank compression suffers severe accuracy degradation or creates a new speed
bottleneck, as the low-rank cache must first be reconstructed in order to apply
RoPE. In this paper, we introduce two key insights: first, the application of
RoPE to the key vectors increases their variance, which in turn results in a
higher rank; second, after the key vectors are transformed into the latent
space, they largely maintain their representation across most layers. Based on
these insights, we propose the Sparse Attention in Latent Space framework. SALS
projects the KV cache into a compact latent space via low-rank projection, and
performs sparse token selection using RoPE-free query-key interactions in this
space. By reconstructing only a small subset of important tokens, it avoids the
overhead of full KV cache reconstruction. We comprehensively evaluate SALS on
various tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and
additionally verify its scalability on the RULER-128k benchmark with
LLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA
performance by maintaining competitive accuracy. Under different settings, SALS
achieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention
operator compared to FlashAttention2 on the 4K sequence. For the end-to-end
throughput performance, we achieves 1.4-fold and 4.5-fold improvement compared
to GPT-fast on 4k and 32K sequences, respectively.

</details>


### [67] [EDC: Equation Discovery for Classification](https://arxiv.org/abs/2510.24310)
*Guus Toussaint,Arno Knobbe*

Main category: cs.LG

TL;DR: 提出了一种基于方程发现(ED)的二元分类框架EDC，能够发现指定决策边界位置和形状的解析函数，在人工和真实数据实验中表现优于现有ED分类方法，达到与最先进二元分类方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 方程发现在回归任务中已证明成功，但需要将其扩展到分类任务，特别是发现能够明确描述决策边界的可解释模型。

Method: 使用适度复杂度的语法，包含线性项、二次项、指数项以及两个特征的乘积项（产生双曲线），形成一系列加性项来构建决策边界函数。

Result: 在人工和真实数据集上的广泛实验表明，EDC能够发现目标方程的结构和参数值，优于当前最先进的基于ED的分类方法，在二元分类中达到与最先进方法相当的性能。

Conclusion: 所提出的语法允许相当灵活的决策边界，同时不会过于丰富导致过拟合，语法复杂度可配置，特别可以包含领域特定的表达式。

Abstract: Equation Discovery techniques have shown considerable success in regression
tasks, where they are used to discover concise and interpretable models
(\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary
classification framework. Our proposed method EDC finds analytical functions of
manageable size that specify the location and shape of the decision boundary.
In extensive experiments on artificial and real-life data, we demonstrate how
EDC is able to discover both the structure of the target equation as well as
the value of its parameters, outperforming the current state-of-the-art
ED-based classification methods in binary classification and achieving
performance comparable to the state of the art in binary classification. We
suggest a grammar of modest complexity that appears to work well on the tested
datasets but argue that the exact grammar -- and thus the complexity of the
models -- is configurable, and especially domain-specific expressions can be
included in the pattern language, where that is required. The presented grammar
consists of a series of summands (additive terms) that include linear,
quadratic and exponential terms, as well as products of two features (producing
hyperbolic curves ideal for capturing XOR-like dependencies). The experiments
demonstrate that this grammar allows fairly flexible decision boundaries while
not so rich to cause overfitting.

</details>


### [68] [Transformers can do Bayesian Clustering](https://arxiv.org/abs/2510.24318)
*Prajit Bhaskaran,Tom Viering*

Main category: cs.LG

TL;DR: Cluster-PFN是一种基于Transformer的模型，通过在高斯混合模型先验上训练，实现无监督贝叶斯聚类，能同时估计聚类数量和分配，比传统方法更准确且快几个数量级。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯聚类虽然能处理不确定性，但在大规模数据上计算成本高。现实数据集常包含缺失值，简单插补方法忽略了相关不确定性，导致结果不理想。

Method: 提出Cluster-PFN模型，扩展Prior-Data Fitted Networks到无监督贝叶斯聚类。完全在有限高斯混合模型先验生成的合成数据集上训练，学习估计聚类数量和分配的后验分布。

Result: 在估计聚类数量方面比AIC、BIC和变分推断更准确，聚类质量与变分推断相当但快几个数量级。在包含缺失数据的复杂先验上训练时，在高缺失率下优于基于插补的基线方法。

Conclusion: Cluster-PFN能够提供可扩展且灵活的贝叶斯聚类解决方案。

Abstract: Bayesian clustering accounts for uncertainty but is computationally demanding
at scale. Furthermore, real-world datasets often contain missing values, and
simple imputation ignores the associated uncertainty, resulting in suboptimal
results. We present Cluster-PFN, a Transformer-based model that extends
Prior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained
entirely on synthetic datasets generated from a finite Gaussian Mixture Model
(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over
both the number of clusters and the cluster assignments. Our method estimates
the number of clusters more accurately than handcrafted model selection
procedures such as AIC, BIC and Variational Inference (VI), and achieves
clustering quality competitive with VI while being orders of magnitude faster.
Cluster-PFN can be trained on complex priors that include missing data,
outperforming imputation-based baselines on real-world genomic datasets, at
high missingness. These results show that the Cluster-PFN can provide scalable
and flexible Bayesian clustering.

</details>


### [69] [What do vision-language models see in the context? Investigating multimodal in-context learning](https://arxiv.org/abs/2510.24331)
*Gabriel O. dos Santos,Esther Colombini,Sandra Avila*

Main category: cs.LG

TL;DR: 本文系统研究了视觉语言模型中的上下文学习能力，评估了7种模型在图像描述任务上的表现，发现当前VLM主要依赖文本线索而未能有效整合视觉信息，揭示了多模态上下文学习的关键局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习在大型语言模型中已被广泛研究，但在视觉语言模型中的有效性仍未被充分探索，需要系统分析多模态上下文学习的能力和局限性。

Method: 评估了涵盖四种架构的七个视觉语言模型在三个图像描述基准上的表现，分析了提示设计、架构选择和训练策略对多模态上下文学习的影响，并首次分析了注意力模式随演示示例数量增加的变化。

Result: 训练图像-文本交错数据能提升上下文学习性能但并不意味着能有效整合视觉和文本信息；指令调优改善了指令跟随但减少了对上下文演示的依赖；注意力分析显示当前VLM主要关注文本线索而未能利用视觉信息。

Conclusion: 当前视觉语言模型在多模态上下文学习方面存在关键局限性，主要问题是无法有效整合视觉信息，这为提升从多模态上下文示例中学习的能力提供了重要见解。

Abstract: In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks
from demonstration examples without parameter updates. Although it has been
extensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)
remains underexplored. In this work, we present a systematic study of ICL in
VLMs, evaluating seven models spanning four architectures on three image
captioning benchmarks. We analyze how prompt design, architectural choices, and
training strategies influence multimodal ICL. To our knowledge, we are the
first to analyze how attention patterns in VLMs vary with an increasing number
of in-context demonstrations. Our results reveal that training on imag-text
interleaved data enhances ICL performance but does not imply effective
integration of visual and textual information from demonstration examples. In
contrast, instruction tuning improves instruction-following but can reduce
reliance on in-context demonstrations, suggesting a trade-off between
instruction alignment and in-context adaptation. Attention analyses further
show that current VLMs primarily focus on textual cues and fail to leverage
visual information, suggesting a limited capacity for multimodal integration.
These findings highlight key limitations in the ICL abilities of current VLMs
and provide insights for enhancing their ability to learn from multimodal
in-context examples.

</details>


### [70] [Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning](https://arxiv.org/abs/2510.24356)
*Suman Sanyal*

Main category: cs.LG

TL;DR: 提出感知学习（PeL）范式，将智能体的感知接口优化与下游决策学习解耦，通过任务无关信号直接优化感知属性如稳定性、信息性和几何控制。


<details>
  <summary>Details</summary>
Motivation: 传统方法将感知和决策耦合优化，导致感知质量无法独立评估。PeL旨在分离感知学习，使其不依赖具体任务目标，从而获得更通用和鲁棒的感知能力。

Method: 定义感知接口f_φ和决策函数g_θ的分离框架，使用任务无关信号优化感知属性，包括对扰动的稳定性、信息丰富性而不崩溃、以及可控的几何结构。

Result: 证明了PeL更新在保持足够不变性的情况下与贝叶斯任务风险梯度正交，提供了任务无关的评估指标来认证感知质量。

Conclusion: PeL为感知学习提供了一个理论框架，实现了感知与决策的分离，能够独立优化和评估感知质量，为构建更鲁棒的智能系统奠定了基础。

Abstract: We introduce Perception Learning (PeL), a paradigm that optimizes an agent's
sensory interface $f_\phi:\mathcal{X}\to\mathcal{Z}$ using task-agnostic
signals, decoupled from downstream decision learning
$g_\theta:\mathcal{Z}\to\mathcal{Y}$. PeL directly targets label-free
perceptual properties, such as stability to nuisances, informativeness without
collapse, and controlled geometry, assessed via objective
representation-invariant metrics. We formalize the separation of perception and
decision, define perceptual properties independent of objectives or
reparameterizations, and prove that PeL updates preserving sufficient
invariants are orthogonal to Bayes task-risk gradients. Additionally, we
provide a suite of task-agnostic evaluation metrics to certify perceptual
quality.

</details>


### [71] [Filtering instances and rejecting predictions to obtain reliable models in healthcare](https://arxiv.org/abs/2510.24368)
*Maria Gabriela Valeriano,David Kohan Marzagão,Alfredo Montelongo,Carlos Roberto Veiga Kiffer,Natan Katz,Ana Carolina Lorena*

Main category: cs.LG

TL;DR: 提出了一种新颖的两步数据驱动方法，通过改进数据质量和过滤低置信度预测来增强机器学习模型在医疗领域的可靠性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在高风险领域（如医疗）广泛应用，但往往无法考虑不确定性，即使在低置信度下也提供预测，这影响了预测的可靠性。

Method: 第一步利用实例硬度（IH）在训练期间过滤问题实例以优化数据集；第二步在推理阶段引入基于置信度的拒绝机制，只保留可靠预测。

Result: 在三个真实医疗数据集上的评估表明，该方法能有效提高模型可靠性，同时平衡预测性能和拒绝率。IH过滤与置信度拒绝的结合显著提升了模型性能，同时保留了大部分实例。

Conclusion: 该方法为在安全关键应用中部署机器学习系统提供了一种实用方法，通过数据质量改进和预测可靠性保证来增强模型在医疗等高风险领域的应用价值。

Abstract: Machine Learning (ML) models are widely used in high-stakes domains such as
healthcare, where the reliability of predictions is critical. However, these
models often fail to account for uncertainty, providing predictions even with
low confidence. This work proposes a novel two-step data-centric approach to
enhance the performance of ML models by improving data quality and filtering
low-confidence predictions. The first step involves leveraging Instance
Hardness (IH) to filter problematic instances during training, thereby refining
the dataset. The second step introduces a confidence-based rejection mechanism
during inference, ensuring that only reliable predictions are retained. We
evaluate our approach using three real-world healthcare datasets, demonstrating
its effectiveness at improving model reliability while balancing predictive
performance and rejection rate. Additionally, we use alternative criteria -
influence values for filtering and uncertainty for rejection - as baselines to
evaluate the efficiency of the proposed method. The results demonstrate that
integrating IH filtering with confidence-based rejection effectively enhances
model performance while preserving a large proportion of instances. This
approach provides a practical method for deploying ML systems in
safety-critical applications.

</details>


### [72] [Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings](https://arxiv.org/abs/2510.24432)
*Seyed Mahdi Basiri Azad,Joschka Boedecker*

Main category: cs.LG

TL;DR: 提出一种使用少量成功演示初始化强化学习智能体价值函数的简单有效方法，通过离线演示预计算价值估计作为早期学习目标，在稀疏奖励环境中显著提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏奖励环境中的强化学习面临缺乏信息反馈的挑战，需要减少探索负担并提高样本效率。

Method: 使用少量成功演示预计算价值估计，将其作为早期学习目标，然后通过标准在线交互进行精化，采用离线到在线的混合范式。

Result: 在基准任务上的实验表明，该方法加速了收敛速度，即使使用最小或次优的演示数据也优于标准基线方法。

Conclusion: 通过演示初始化价值函数的方法能有效解决稀疏奖励环境中的强化学习挑战，显著提升学习效率。

Abstract: Reinforcement learning (RL) in sparse-reward environments remains a
significant challenge due to the lack of informative feedback. We propose a
simple yet effective method that uses a small number of successful
demonstrations to initialize the value function of an RL agent. By precomputing
value estimates from offline demonstrations and using them as targets for early
learning, our approach provides the agent with a useful prior over promising
actions. The agent then refines these estimates through standard online
interaction. This hybrid offline-to-online paradigm significantly reduces the
exploration burden and improves sample efficiency in sparse-reward settings.
Experiments on benchmark tasks demonstrate that our method accelerates
convergence and outperforms standard baselines, even with minimal or suboptimal
demonstration data.

</details>


### [73] [Methodology for Comparing Machine Learning Algorithms for Survival Analysis](https://arxiv.org/abs/2510.24473)
*Lucas Buk Cardoso,Simone Aldrey Angelo,Yasmin Pacheco Gil Bonilha,Fernando Maia,Adeylson Guimarães Ribeiro,Maria Paula Curado,Gisele Aparecida Fernandes,Vanderlei Cunha Parro,Flávio Almeida de Magalhães Cipparrone,Alexandre Dias Porto Chiavegatto Filho,Tatiana Natasha Toporcov*

Main category: cs.LG

TL;DR: 本研究比较了六种机器学习生存分析模型在结直肠癌患者数据上的表现，发现XGB-AFT模型性能最佳，展示了机器学习在生存预测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了评估不同机器学习模型在生存分析中的表现，特别是在处理删失数据时的预测能力，以改善结直肠癌患者的生存预测和临床决策支持。

Method: 使用巴西圣保罗医院癌症登记处的近45,000名结直肠癌患者数据，评估了六种机器学习生存分析模型（RSF、GBSA、SSVM、XGB-Cox、XGB-AFT、LGBM），采用不同采样器进行超参数优化，并使用C-Index、C-Index IPCW、时间相关AUC和IBS等指标评估性能。

Result: XGB-AFT模型表现最佳（C-Index = 0.7618；IPCW = 0.7532），其次是GBSA和RSF模型。

Conclusion: 机器学习生存分析模型具有改善生存预测和支持决策制定的潜力和适用性。

Abstract: This study presents a comparative methodological analysis of six machine
learning models for survival analysis (MLSA). Using data from nearly 45,000
colorectal cancer patients in the Hospital-Based Cancer Registries of S\~ao
Paulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for
Survival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),
XGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival
considering censored data. Hyperparameter optimization was performed with
different samplers, and model performance was assessed using the Concordance
Index (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score
(IBS). Survival curves produced by the models were compared with predictions
from classification algorithms, and predictor interpretation was conducted
using SHAP and permutation importance. XGB-AFT achieved the best performance
(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results
highlight the potential and applicability of MLSA to improve survival
prediction and support decision making.

</details>


### [74] [Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments](https://arxiv.org/abs/2510.24503)
*Mortesa Hussaini,Jan Theiß,Anthony Stein*

Main category: cs.LG

TL;DR: 该论文研究了联邦学习中异构数据环境下的个性化联邦学习问题，提出了一个改进的FedAvg算法FLIU，通过自适应个性化因子来平衡本地性能和泛化能力，并在多种数据分布条件下进行了实证评估。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在异构数据环境中，本地模型在训练过程中会偏离全局数据分布，导致客户端漂移问题。个性化联邦学习方法虽然关注本地性能，但忽视了泛化能力这一重要指标。

Method: 提出了联邦学习个体化更新(FLIU)方法，在FedAvg基础上增加了个体化步骤和自适应个性化因子，并在MNIST和CIFAR-10数据集上，使用IID、病理性非IID以及基于Dirichlet分布的新测试环境进行实验评估。

Result: 通过在不同通信轮次阶段进行细致评估，比较了各种联邦学习方法的本地性能和泛化能力，验证了FLIU方法的有效性。

Conclusion: FLIU方法能够更好地平衡本地性能和泛化能力，在复杂数据异构环境下表现出色，为联邦学习算法评估提供了更全面的视角。

Abstract: In the context of Federated Learning with heterogeneous data environments,
local models tend to converge to their own local model optima during local
training steps, deviating from the overall data distributions. Aggregation of
these local updates, e.g., with FedAvg, often does not align with the global
model optimum (client drift), resulting in an update that is suboptimal for
most clients. Personalized Federated Learning approaches address this challenge
by exclusively focusing on the average local performances of clients' models on
their own data distribution. Generalization to out-of-distribution samples,
which is a substantial benefit of FedAvg and represents a significant component
of robustness, appears to be inadequately incorporated into the assessment and
evaluation processes. This study involves a thorough evaluation of Federated
Learning approaches, encompassing both their local performance and their
generalization capabilities. Therefore, we examine different stages within a
single communication round to enable a more nuanced understanding of the
considered metrics. Furthermore, we propose and incorporate a modified approach
of FedAvg, designated as Federated Learning with Individualized Updates (FLIU),
extending the algorithm by a straightforward individualization step with an
adaptive personalization factor. We evaluate and compare the approaches
empirically using MNIST and CIFAR-10 under various distributional conditions,
including benchmark IID and pathological non-IID, as well as additional novel
test environments with Dirichlet distribution specifically developed to stress
the algorithms on complex data heterogeneity.

</details>


### [75] [MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU](https://arxiv.org/abs/2510.24500)
*Yong Huang,Zhongqi Yang,Amir Rahmani*

Main category: cs.LG

TL;DR: MIMIC-Sepsis是一个基于MIMIC-IV数据库的脓毒症研究基准框架，包含35,239名ICU患者的时间对齐临床数据和标准化治疗数据，旨在支持脓毒症轨迹的可重复建模。


<details>
  <summary>Details</summary>
Motivation: 现有脓毒症研究存在数据集过时、预处理流程不可复现、临床干预覆盖有限等问题，需要构建一个标准化的基准框架来支持可重复的建模研究。

Method: 基于Sepsis-3标准构建透明预处理流程，采用结构化插补策略和治疗纳入方法，提供早期死亡率预测、住院时间估计和休克发作分类等基准任务。

Result: 实证结果表明，纳入治疗变量显著提高了模型性能，特别是对于基于Transformer的架构。

Conclusion: MIMIC-Sepsis为重症监护研究中的预测和序列模型评估提供了一个稳健的平台。

Abstract: Sepsis is a leading cause of mortality in intensive care units (ICUs), yet
existing research often relies on outdated datasets, non-reproducible
preprocessing pipelines, and limited coverage of clinical interventions. We
introduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from
the MIMIC-IV database, designed to support reproducible modeling of sepsis
trajectories. Our cohort includes 35,239 ICU patients with time-aligned
clinical variables and standardized treatment data, including vasopressors,
fluids, mechanical ventilation and antibiotics. We describe a transparent
preprocessing pipeline-based on Sepsis-3 criteria, structured imputation
strategies, and treatment inclusion-and release it alongside benchmark tasks
focused on early mortality prediction, length-of-stay estimation, and shock
onset classification. Empirical results demonstrate that incorporating
treatment variables substantially improves model performance, particularly for
Transformer-based architectures. MIMIC-Sepsis serves as a robust platform for
evaluating predictive and sequential models in critical care research.

</details>


### [76] [LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis](https://arxiv.org/abs/2510.24561)
*Qingyue Zhang,Chang Chu,Tianren Peng,Qi Li,Xiangyang Luo,Zhihao Jiang,Shao-Lun Huang*

Main category: cs.LG

TL;DR: 本文提出了一种基于渐近分析的数据感知LoRA初始化理论框架LoRA-DA，通过优化目标函数中的偏差项和方差项来获得最优LoRA初始化策略，在多个基准测试中显著提升了最终精度。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛采用，LoRA已成为PEFT的主导方法，但其初始化方法存在局限性：许多方法未利用目标域数据，而基于梯度的方法仅通过一步梯度分解浅层利用数据，且缺乏严格理论基础或依赖限制性各向同性假设。

Method: 建立基于渐近分析的数据感知LoRA初始化理论框架，从最小化微调模型与目标模型参数差异期望的一般优化目标出发，推导出包含偏差项（通过Fisher-梯度公式保持各向异性）和方差项（通过Fisher信息考虑采样随机性）的优化问题，并开发高效算法LoRA-DA从少量目标域样本估计优化问题中的各项。

Result: 在多个基准测试上的实证结果表明，LoRA-DA相比现有初始化方法持续提升了最终精度，同时表现出更快、更稳定的收敛性、跨秩的鲁棒性，且仅产生较小的初始化开销。

Conclusion: LoRA-DA提供了一个具有严格理论基础的LoRA初始化方法，有效解决了现有方法的局限性，在保持高效性的同时显著提升了性能表现。

Abstract: With the widespread adoption of LLMs, LoRA has become a dominant method for
PEFT, and its initialization methods have attracted increasing attention.
However, existing methods have notable limitations: many methods do not
incorporate target-domain data, while gradient-based methods exploit data only
at a shallow level by relying on one-step gradient decomposition, which remains
unsatisfactory due to the weak empirical performance of the one-step
fine-tuning model that serves as their basis, as well as the fact that these
methods either lack a rigorous theoretical foundation or depend heavily on
restrictive isotropic assumptions. In this paper, we establish a theoretical
framework for data-aware LoRA initialization based on asymptotic analysis.
Starting from a general optimization objective that minimizes the expectation
of the parameter discrepancy between the fine-tuned and target models, we
derive an optimization problem with two components: a bias term, which is
related to the parameter distance between the fine-tuned and target models, and
is approximated using a Fisher-gradient formulation to preserve anisotropy; and
a variance term, which accounts for the uncertainty introduced by sampling
stochasticity through the Fisher information. By solving this problem, we
obtain an optimal initialization strategy for LoRA. Building on this
theoretical framework, we develop an efficient algorithm, LoRA-DA, which
estimates the terms in the optimization problem from a small set of target
domain samples and obtains the optimal LoRA initialization. Empirical results
across multiple benchmarks demonstrate that LoRA-DA consistently improves final
accuracy over existing initialization methods. Additional studies show faster,
more stable convergence, robustness across ranks, and only a small
initialization overhead for LoRA-DA. The source code will be released upon
publication.

</details>


### [77] [DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment](https://arxiv.org/abs/2510.24574)
*Hao Wang,Licheng Pan,Yuan Lu,Zhixuan Chu,Xiaoxi Li,Shuting He,Zhichao Chen,Haoxuan Li,Qingsong Wen,Zhouchen Lin*

Main category: cs.LG

TL;DR: 本文提出了DistDF方法，通过最小化条件预测分布与标签分布之间的差异来改进时间序列预测模型，解决了传统直接预测方法在标签自相关存在时的偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统直接预测方法在存在标签自相关时，条件负对数似然的估计存在偏差，这影响了预测模型的性能。

Method: 提出DistDF方法，通过最小化条件预测分布与标签分布之间的差异来实现对齐。引入联合分布Wasserstein差异作为可处理的上界估计，该差异可从经验样本中进行可微分估计，并与基于梯度的训练无缝集成。

Result: 大量实验表明，DistDF提高了多种预测模型的性能，并实现了最先进的预测性能。

Conclusion: DistDF通过分布对齐方法有效解决了时间序列预测中的条件分布偏差问题，为预测模型提供了更可靠的训练框架。

Abstract: Training time-series forecast models requires aligning the conditional
distribution of model forecasts with that of the label sequence. The standard
direct forecast (DF) approach resorts to minimize the conditional negative
log-likelihood of the label sequence, typically estimated using the mean
squared error. However, this estimation proves to be biased in the presence of
label autocorrelation. In this paper, we propose DistDF, which achieves
alignment by alternatively minimizing a discrepancy between the conditional
forecast and label distributions. Because conditional discrepancies are
difficult to estimate from finite time-series observations, we introduce a
newly proposed joint-distribution Wasserstein discrepancy for time-series
forecasting, which provably upper bounds the conditional discrepancy of
interest. This discrepancy admits tractable, differentiable estimation from
empirical samples and integrates seamlessly with gradient-based training.
Extensive experiments show that DistDF improves the performance diverse
forecast models and achieves the state-of-the-art forecasting performance. Code
is available at https://anonymous.4open.science/r/DistDF-F66B.

</details>


### [78] [Causal Ordering for Structure Learning From Time Series](https://arxiv.org/abs/2510.24639)
*Pedro P. Sanchez,Damian Machlanski,Steven McDonagh,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 提出DOTS方法，通过整合多个有效因果顺序而非单一顺序，改进时间序列因果发现，在合成和真实数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 时间序列因果发现对理解生理、脑连接、气候和社会经济现象至关重要，但传统基于排序的方法限制了模型表达能力。

Method: 使用扩散过程进行因果发现，通过分数匹配和Hessian估计，整合多个有效因果顺序来恢复有向无环图的传递闭包。

Result: 在合成数据集上，DOTS将平均窗口图F1从0.63提升到0.81；在CausalTime真实基准上获得最高平均摘要图F1，同时将运行时间减半。

Conclusion: DOTS为时间序列因果发现提供了可扩展且准确的解决方案。

Abstract: Predicting causal structure from time series data is crucial for
understanding complex phenomena in physiology, brain connectivity, climate
dynamics, and socio-economic behaviour. Causal discovery in time series is
hindered by the combinatorial complexity of identifying true causal
relationships, especially as the number of variables and time points grow. A
common approach to simplify the task is the so-called ordering-based methods.
Traditional ordering methods inherently limit the representational capacity of
the resulting model. In this work, we fix this issue by leveraging multiple
valid causal orderings, instead of a single one as standard practice. We
propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based
causal discovery for temporal data. By integrating multiple orderings, DOTS
effectively recovers the transitive closure of the underlying directed acyclic
graph, mitigating spurious artifacts inherent in single-ordering approaches. We
formalise the problem under standard assumptions such as stationarity and the
additive noise model, and leverage score matching with diffusion processes to
enable efficient Hessian estimation. Extensive experiments validate the
approach. Empirical evaluations on synthetic and real-world datasets
demonstrate that DOTS outperforms state-of-the-art baselines, offering a
scalable and robust approach to temporal causal discovery. On synthetic
benchmarks ($d{=}\!3-\!6$ variables, $T{=}200\!-\!5{,}000$ samples), DOTS
improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the
CausalTime real-world benchmark ($d{=}20\!-\!36$), while baselines remain the
best on individual datasets, DOTS attains the highest average summary-graph
$F1$ while halving runtime relative to graph-optimisation methods. These
results establish DOTS as a scalable and accurate solution for temporal causal
discovery.

</details>


### [79] [Physics-Informed Extreme Learning Machine (PIELM): Opportunities and Challenges](https://arxiv.org/abs/2510.24577)
*He Yang,Fei Ren,Hai-Sui Yu,Xiaohui Chen,Pei-Zhi Zhuang*

Main category: cs.LG

TL;DR: 本文是对物理信息极限学习机(PIELM)发展的综述，总结了该领域在求解偏微分方程方面的进展、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 由于目前缺乏对PIELM的总结性文献，作者希望分享对这一有前景研究方向的见解和经验。

Method: 通过综述分析PIELM在求解具有尖锐梯度、非线性、高频行为、硬约束、不确定性和多物理场耦合的偏微分方程方面的各种方法。

Result: PIELM在计算效率和精度方面取得了显著进展，成功应用于多种复杂物理问题的求解。

Conclusion: 尽管PIELM已取得成功，但仍面临许多紧迫挑战，这为开发更鲁棒、可解释和可推广的PIELM框架提供了机会，将在科学和工程领域有广泛应用。

Abstract: We are very delighted to see the fast development of physics-informed extreme
learning machine (PIELM) in recent years for higher computation efficiency and
accuracy in physics-informed machine learning. As a summary or review on PIELM
is currently not available, we would like to take this opportunity to show our
perspective and experience for this promising research direction. We can see
many efforts are made to solve PDEs with sharp gradients, nonlinearities,
high-frequency behavior, hard constraints, uncertainty, multiphysics coupling.
Despite the success, many urgent challenges remain to be tackled, which also
provides us opportunities to develop more robust, interpretable, and
generalizable PIELM frameworks with applications in science and engineering.

</details>


### [80] [Learning to Drive Safely with Hybrid Options](https://arxiv.org/abs/2510.24674)
*Bram De Cooman,Johan Suykens*

Main category: cs.LG

TL;DR: 该论文将选项框架应用于高速公路自动驾驶任务，通过定义纵向和横向操作的专用选项，将领域知识融入学习过程，并约束驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 尽管选项框架天然适用于分层控制和自动驾驶任务，但在自动驾驶的深度强化学习方法中却很少使用。因此，作者希望将该框架专门应用于高速公路自动驾驶。

Method: 定义了具有安全和舒适约束的纵向和横向操作专用选项，提出了几种分层控制设置，并基于最先进的强化学习技术推导实用算法。通过分别选择纵向和横向控制动作，实现了与人类驾驶员相同的表达能力和灵活性。

Result: 在所有研究方法中，基于混合选项的灵活策略在不同交通条件下表现最佳，优于基于动作的基线策略。

Conclusion: 选项框架成功应用于高速公路自动驾驶，通过分层控制方法实现了更好的性能，同时使学习到的驾驶行为更容易解释和约束。

Abstract: Out of the many deep reinforcement learning approaches for autonomous
driving, only few make use of the options (or skills) framework. That is
surprising, as this framework is naturally suited for hierarchical control
applications in general, and autonomous driving tasks in specific. Therefore,
in this work the options framework is applied and tailored to autonomous
driving tasks on highways. More specifically, we define dedicated options for
longitudinal and lateral manoeuvres with embedded safety and comfort
constraints. This way, prior domain knowledge can be incorporated into the
learning process and the learned driving behaviour can be constrained more
easily. We propose several setups for hierarchical control with options and
derive practical algorithms following state-of-the-art reinforcement learning
techniques. By separately selecting actions for longitudinal and lateral
control, the introduced policies over combined and hybrid options obtain the
same expressiveness and flexibility that human drivers have, while being easier
to interpret than classical policies over continuous actions. Of all the
investigated approaches, these flexible policies over hybrid options perform
the best under varying traffic conditions, outperforming the baseline policies
over actions.

</details>


### [81] [Symbolic Snapshot Ensembles](https://arxiv.org/abs/2510.24633)
*Mingyue Liu,Andrew Cropper*

Main category: cs.LG

TL;DR: 本文提出一种单次训练ILP算法并保存中间假设的方法，通过最小描述长度加权方案组合这些假设，在多个基准测试中提高预测准确率4%且计算开销低于1%。


<details>
  <summary>Details</summary>
Motivation: 传统的归纳逻辑编程(ILP)方法通常从单次训练中学习单个假设，而集成方法需要多次训练。本文旨在开发一种更高效的方法，只需单次训练就能获得多个假设。

Method: 在单次ILP算法训练过程中保存中间假设，然后使用最小描述长度加权方案将这些假设组合起来。

Result: 在包括游戏玩法和视觉推理在内的多个基准测试中，该方法将预测准确率提高了4%，同时计算开销低于1%。

Conclusion: 该方法通过单次训练获得多个假设并有效组合，显著提高了ILP的性能而几乎不增加计算成本。

Abstract: Inductive logic programming (ILP) is a form of logical machine learning. Most
ILP algorithms learn a single hypothesis from a single training run. Ensemble
methods train an ILP algorithm multiple times to learn multiple hypotheses. In
this paper, we train an ILP algorithm only once and save intermediate
hypotheses. We then combine the hypotheses using a minimum description length
weighting scheme. Our experiments on multiple benchmarks, including game
playing and visual reasoning, show that our approach improves predictive
accuracy by 4% with less than 1% computational overhead.

</details>


### [82] [Pearl: A Foundation Model for Placing Every Atom in the Right Location](https://arxiv.org/abs/2510.24670)
*Genesis Research Team,Alejandro Dobles,Nina Jovic,Kenneth Leidal,Pranav Murugan,David C. Williams,Drausin Wulsin,Nate Gruver,Christina X. Ji,Korrawat Pruegsanusak,Gianluca Scarpellini,Ansh Sharma,Wojciech Swiderski,Andrea Bootsma,Richard Strong Bowen,Charlotte Chen,Jamin Chen,Marc André Dämgen,Roy Tal Dew,Benjamin DiFrancesco,J. D. Fishman,Alla Ivanova,Zach Kagin,David Li-Bland,Zuli Liu,Igor Morozov,Jeffrey Ouyang-Zhang,Frank C. Pickard IV,Kushal S. Shah,Ben Shor,Gabriel Monteiro da Silva,Maxx Tessmer,Carl Tilbury,Cyr Vetcher,Daniel Zeng,Maruan Al-Shedivat,Aleksandra Faust,Evan N. Feinberg,Michael V. LeVine,Matteus Pan*

Main category: cs.LG

TL;DR: Pearl是一个用于蛋白质-配体共折叠的基础模型，通过大规模合成数据训练、SO(3)等变扩散架构和可控推理等创新，在蛋白质-配体复合物结构预测方面实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测蛋白质-配体复合物的三维结构是计算药物发现中的基本挑战，现有深度学习方法受限于实验数据稀缺、架构效率低、物理无效构象以及无法充分利用推理时的辅助信息。

Method: Pearl采用三个关键创新：(1)包含大规模合成数据的训练方案；(2)集成SO(3)等变扩散模块的架构，尊重3D旋转对称性；(3)可控推理系统，支持多链模板和双重无条件/条件模式。

Result: Pearl在蛋白质-配体共折叠中建立了新的最先进性能，在生成准确(RMSD < 2Å)且物理有效的构象方面，在公开基准测试中比AlphaFold 3和其他开源基线分别提升了14.5%和14.2%。在口袋条件共折叠机制下，在更严格的RMSD < 1Å阈值下实现了3.6倍的改进。

Conclusion: Pearl通过创新的训练策略、架构设计和推理控制，显著提升了蛋白质-配体结构预测的准确性和实用性，模型性能与训练中使用的合成数据集大小直接相关。

Abstract: Accurately predicting the three-dimensional structures of protein-ligand
complexes remains a fundamental challenge in computational drug discovery that
limits the pace and success of therapeutic design. Deep learning methods have
recently shown strong potential as structural prediction tools, achieving
promising accuracy across diverse biomolecular systems. However, their
performance and utility are constrained by scarce experimental data,
inefficient architectures, physically invalid poses, and the limited ability to
exploit auxiliary information available at inference. To address these issues,
we introduce Pearl (Placing Every Atom in the Right Location), a foundation
model for protein-ligand cofolding at scale. Pearl addresses these challenges
with three key innovations: (1) training recipes that include large-scale
synthetic data to overcome data scarcity; (2) architectures that incorporate an
SO(3)-equivariant diffusion module to inherently respect 3D rotational
symmetries, improving generalization and sample efficiency, and (3)
controllable inference, including a generalized multi-chain templating system
supporting both protein and non-polymeric components as well as dual
unconditional/conditional modes. Pearl establishes a new state-of-the-art
performance in protein-ligand cofolding. On the key metric of generating
accurate (RMSD < 2 \r{A}) and physically valid poses, Pearl surpasses AlphaFold
3 and other open source baselines on the public Runs N' Poses and PoseBusters
benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the
next best model. In the pocket-conditional cofolding regime, Pearl delivers
$3.6\times$ improvement on a proprietary set of challenging, real-world drug
targets at the more rigorous RMSD < 1 \r{A} threshold. Finally, we demonstrate
that model performance correlates directly with synthetic dataset size used in
training.

</details>


### [83] [Eigenfunction Extraction for Ordered Representation Learning](https://arxiv.org/abs/2510.24672)
*Burak Varıcı,Che-Ping Tsai,Ritabrata Ray,Nicholas M. Boffi,Pradeep Ravikumar*

Main category: cs.LG

TL;DR: 本文提出了一个通用框架来提取有序且可识别的特征函数，通过模块化构建块满足关键需求，包括与上下文核的兼容性和可扩展性。该方法在合成核和真实图像数据集上验证了特征值作为特征选择的重要性评分，实现了自适应维度表示的效率-准确性权衡。


<details>
  <summary>Details</summary>
Motivation: 现有表示学习方法（如对比和非对比学习）仅恢复核的顶部特征函数的线性跨度，而精确的谱分解对于理解特征排序和重要性至关重要。

Method: 提出了基于模块化构建块的通用框架，包括低秩近似和Rayleigh商优化两种主要方法范式，用于提取有序可识别的特征函数。

Result: 在合成核上验证了方法的有效性，在真实图像数据集上证明恢复的特征值可作为特征选择的有效重要性评分，实现了自适应维度表示的效率-准确性权衡。

Conclusion: 该框架能够提取有序可识别的特征函数，为特征重要性评估和自适应维度表示提供了理论基础和实用工具。

Abstract: Recent advances in representation learning reveal that widely used
objectives, such as contrastive and non-contrastive, implicitly perform
spectral decomposition of a contextual kernel, induced by the relationship
between inputs and their contexts. Yet, these methods recover only the linear
span of top eigenfunctions of the kernel, whereas exact spectral decomposition
is essential for understanding feature ordering and importance. In this work,
we propose a general framework to extract ordered and identifiable
eigenfunctions, based on modular building blocks designed to satisfy key
desiderata, including compatibility with the contextual kernel and scalability
to modern settings. We then show how two main methodological paradigms,
low-rank approximation and Rayleigh quotient optimization, align with this
framework for eigenfunction extraction. Finally, we validate our approach on
synthetic kernels and demonstrate on real-world image datasets that the
recovered eigenvalues act as effective importance scores for feature selection,
enabling principled efficiency-accuracy tradeoffs via adaptive-dimensional
representations.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [84] [Onsiteability of Higher-Form Symmetries](https://arxiv.org/abs/2510.23701)
*Yitao Feng,Yu-An Chen,Po-Shen Hsin,Ryohei Kobayashi*

Main category: cond-mat.str-el

TL;DR: 本文澄清了高形式对称性的局域化条件，提出了局域化与高形式规范化的等价性。对于(2+1)D中的有限1形式对称性，证明了对称性可局域化的充要条件是其't Hooft异常满足特定代数条件，确保可以进行1-规范化。


<details>
  <summary>Details</summary>
Motivation: 标准观点认为局域化与无异常等价，但这仅适用于(1+1)D中的有限0形式对称性。对于高形式对称性，这些概念变得不等价：对称性可能既是局域的又是异常的。本文旨在澄清高形式对称性的局域化条件。

Method: 通过提出局域化与高形式规范化的等价性，推导了高形式对称性局域化的必要条件。对于(2+1)D中的有限1形式对称性，分析了其't Hooft异常的代数条件，并展示了如何通过辅助系统和电路共轭将其转化为横向泡利算子。

Result: 证明了(2+1)D中有限1形式对称性可局域化的充要条件是其't Hooft异常满足特定代数条件，确保可以进行1-规范化。进一步展示了可局域化的1形式对称性总是可以通过辅助系统和电路共轭转化为横向泡利算子。

Conclusion: 在一般维度中，使用高形式对称性的晶格't Hooft异常推导了局域化的必要条件，并推测了晶格上局域化与高形式规范化可能性之间的普遍等价性。

Abstract: An internal symmetry in a lattice model is said to be onsiteable if it can be
disentangled into an onsite action by introducing ancillas and conjugating with
a finite-depth circuit. A standard lore holds that onsiteability is equivalent
to being anomaly-free, which is indeed valid for finite 0-form symmetries in
(1+1)D. However, for higher-form symmetries, these notions become inequivalent:
a symmetry may be onsite while still anomalous. In this work, we clarify the
conditions for onsiteability of higher-form symmetries by proposing an
equivalence between onsiteability and the possibility of $higher$ gauging. For
a finite 1-form symmetry in (2+1)D, we show that the symmetry is onsiteable if
and only if its 't Hooft anomaly satisfies a specific algebraic condition that
ensures the symmetry can be 1-gauged. We further demonstrate that onsiteable
1-form symmetry in (2+1)D can always be brought into transversal Pauli
operators by ancillas and circuit conjugation. In generic dimensions, we derive
necessary conditions for onsiteability using lattice 't Hooft anomaly of
higher-form symmetry, and conjecture a general equivalence between
onsiteability and possibility of higher gauging on lattices.

</details>


### [85] [Exact nematic and mixed magnetic phases driven by competing orders on the pyrochlore lattice](https://arxiv.org/abs/2510.23704)
*Niccolò Francini,Lukas Schmidt,Lukas Janssen,Daniel Lozano-Gómez*

Main category: cond-mat.str-el

TL;DR: 该研究在焦绿石磁体中发现了混合磁相和新型向列相，首次实现了具有两个不同序参数的q=0长程有序相，并在特定参数点揭示了由离散对称性导致的向列相形成机制。


<details>
  <summary>Details</summary>
Motivation: 焦绿石磁体作为三维阻挫系统的范例，为研究各种奇异多体现象提供了理想平台。近年来，双线性自旋模型在该晶格上受到广泛关注，其中多个磁相可能在能量上简并，往往稳定出非常规磁态。

Method: 结合解析和数值方法，研究焦绿石晶格上由相互作用耦合Jz±参数化的自旋模型，重点关注参数空间中对应三个不同磁相相边界的特定线。

Result: 在低温下该模型表现出有序化无序机制，产生混合磁相，这是焦绿石磁体中首个具有两个不同序参数(q=0长程有序相)的实现。在Jz±=1/√2时，模型获得亚扩展数量的离散对称性，阻止传统长程有序的稳定，导致新型向列相的出现。

Conclusion: 该工作揭示了焦绿石磁体中混合磁相和向列相的形成机制，为理解阻挫系统中的非常规磁态提供了重要见解，特别是在参数空间特定点处离散对称性对相行为的关键影响。

Abstract: Pyrochlore magnets are a paradigmatic example of three-dimensional frustrated
systems and provide an excellent platform for studying a variety of exotic
many-body phenomena, including spin liquids, nematic phases, fragmentation, and
order by disorder. In recent years, increasing attention has been devoted to
bilinear spin models on this lattice, where multiple magnetic phases can be
degenerate in energy, often stabilizing unconventional magnetic states. In this
work, we focus on one such model, parametrized by the interaction coupling
$J_{z\pm}$, which defines a line in parameter space corresponding to the phase
boundary between three distinct magnetic phases. Using a combination of
analytical and numerical methods, we show that this model exhibits an
order-by-disorder mechanism at low temperatures, giving rise to a \emph{mixed}
magnetic phase. This represents the first realization of a $\mathbf{q}=0$
long-range-ordered phase in a pyrochlore magnet characterized by two distinct
order parameters, which we denote as the $A_2 \oplus \psi_2$ phase.
Furthermore, at $J_{z\pm} = 1/\sqrt{2}$, the model acquires a subextensive
number of discrete symmetries, which preclude the stabilization of conventional
long-range order and instead lead to the emergence of a novel nematic phase. We
characterize this nematic phase, describe how its ground-state configurations
are constructed, and analyze its stability at higher temperatures and under
small deviations from $J_{z\pm} = 1/\sqrt{2}$.

</details>


### [86] [Chiral gapped states are universally non-topological](https://arxiv.org/abs/2510.23720)
*Xiang Li,Ting-Chun Lin,Yahya Alavirad,John McGreevy*

Main category: cond-mat.str-el

TL;DR: 本文提出了Li-Haldane猜想的算子推广，研究2+1维手性有隙基态中圆盘的纠缠哈密顿量。通过分析具有尖锐角的区域，推导出关于角纠缠的若干普适性质，并定义了反映角纠缠贡献鲁棒性的量，该量对有隙边界构成阻碍。


<details>
  <summary>Details</summary>
Motivation: 研究手性有隙态中区域纠缠的普适性质，特别是角纠缠的贡献，揭示拓扑场论中不可见的普适共形几何结构。

Method: 通过分析具有尖锐角的区域纠缠结构，推导出基于波函数局部可检验条件的普适性质，并构造局部有隙哈密顿量。

Result: 发现了角纠缠的普适性质，定义了反映角纠缠鲁棒性的量，并成功构造了与原始手性有隙相相同的局部有隙哈密顿量。

Conclusion: 角纠缠分析揭示了手性有隙态体区域纠缠结构中编码的普适共形几何，这些结构在拓扑场论中不可见，为理解手性拓扑相的纠缠结构提供了新视角。

Abstract: We propose an operator generalization of the Li-Haldane conjecture regarding
the entanglement Hamiltonian of a disk in a 2+1D chiral gapped groundstate. The
logic applies to regions with sharp corners, from which we derive several
universal properties regarding corner entanglement. These universal properties
follow from a set of locally-checkable conditions on the wavefunction. We also
define a quantity $(\mathfrak{c}_{\text{tot}})_{\text{min}}$ that reflects the
robustness of corner entanglement contributions, and show that it provides an
obstruction to a gapped boundary. One reward from our analysis is that we can
construct a local gapped Hamiltonian within the same chiral gapped phase from a
given wavefunction; we conjecture that it is closer to the low-energy
renormalization group fixed point than the original parent Hamiltonian. Our
analysis of corner entanglement reveals the emergence of a universal conformal
geometry encoded in the entanglement structure of bulk regions of chiral gapped
states that is not visible in topological field theory.

</details>


### [87] [Beyond Random Phase Approximation in electron-hole bilayer superfluidity](https://arxiv.org/abs/2510.23743)
*Filippo Pascucci,Stefania De Palo,Sara Conti,David Neilson,Andrea Perali,Gaetano Senatore*

Main category: cond-mat.str-el

TL;DR: 本文研究了二维超流体电子-空穴双层系统中的极化函数和屏蔽库仑相互作用，包括超越随机相位近似（RPA）的一阶修正。重点分析了超流体系统中长程库仑相互作用的一阶修正的物理起源和大小。


<details>
  <summary>Details</summary>
Motivation: 在二维超流体电子-空穴双层系统中，由于米格达尔定理不适用，交换顶点修正不能忽略。需要发展超越RPA的微扰方法来准确描述这种系统中的相互作用和屏蔽效应。

Method: 修改了Nozières和Schrieffer提出的微扰方法，推导了正常和反常极化函数以及屏蔽库仑相互作用，包括所有一阶修正。评估了超流体状态下屏蔽的电子-电子、空穴-空穴和电子-空穴相互作用随载流子密度的变化。

Result: 在低密度下，正常和反常分量之间的强抵消使得相互作用屏蔽可忽略，这一结论不仅适用于RPA，也适用于包含一阶修正的情况。随着密度增加，正常-反常抵消减弱，屏蔽变得显著。一阶修正放大了正常-反常差异，但仅在大动量交换时显著，对相互作用的影响有限。

Conclusion: 在超流体间隙达到最大值的密度范围内，超流体状态的RPA是描述该超流体系统中屏蔽和有效电子-空穴配对的极好近似。

Abstract: We derive the normal and anomalous proper polarization functions and the
screened Coulomb interactions in a two-dimensional superfluid electron-hole
bilayer, including all first-order corrections beyond the Random Phase
Approximation (RPA). This requires a modification of the perturbation method as
first noted by Nozi\`eres and Schrieffer [1, 2]. We discuss the physical origin
and magnitude of the first-order corrections in a superfluid system with
long-range Coulomb interactions. Unlike conventional superconductivity,
Migdal's theorem does not apply here, so exchange vertex corrections cannot be
neglected. The screened electron-electron, hole-hole, and electron-hole
interactions in the superfluid state are evaluated as functions of the carrier
density. We find that at low density, the strong cancellations between the
normal and anomalous components that make screening of the interactions
negligible, apply not only within RPA but also with the first-order corrections
included. As the density is increased, the normal-anomalous cancellation
weakens and screening becomes increasingly significant. We find that the
first-order corrections amplify the normal-anomalous difference but only at
large momenta exchanged in the two-particle scattering, so their effect on the
interactions remains modest. We conclude that the superfluid state RPA is an
excellent approximation for the screening and for the effective electron-hole
pairing in this superfluid system over the range of densities up to the maximum
of the superfluid gap.

</details>


### [88] [Magnetic field-tuned magnetic order and metamagnetic criticality in non-stoichiometric CeAuBi$_2$](https://arxiv.org/abs/2510.23778)
*H. Hodovanets,H. Kim,T. Metz,Y. Nakajima,C. J. Eckberg,K. Wang,J. Yong,S. R. Saha,J. Higgins,D. Graf,N. Butch,T. Vojta,J. Paglione*

Main category: cond-mat.str-el

TL;DR: 对非化学计量比CeAuBi2（Au缺陷18%）单晶的磁性、电阻率、热容、X射线和中子粉末衍射研究，发现其为强关联反铁磁体，奈尔温度13.2K，具有沿c轴的强磁各向异性和75kOe的spin-flop转变。


<details>
  <summary>Details</summary>
Motivation: 研究非化学计量比CeAuBi2中Au空位对强关联反铁磁体磁性和临界行为的影响。

Method: 通过磁化、电阻率、热容、X射线和中子粉末衍射测量，结合Ising模型分析。

Result: 构建了温度-磁场相图，发现spin-flop转变将磁有序抑制从二阶转变为三叉的一阶转变，Au空位导致磁转变平滑化。

Conclusion: Au空位足以平滑复杂的磁行为并调控磁有序的临界行为，可用弱淬火无序的Ising模型描述。

Abstract: We present a detailed study of magnetization, resistivity, heat capacity, and
X-ray and neutron powder diffraction measurements performed on single crystals
of non-stoichiometric CeAuBi$_2$, Au deficiency 18$\%$, a strongly correlated
antiferromagnet with N\'eel temperature T$_N$ = 13.2 K. Field-dependent
magnetization measurements reveal a large magnetic anisotropy at low
temperatures with an easy axis along the crystallographic c-axis, in which
direction a spin-flop transition exhibits strong features in magnetization,
specific heat, and resistivity at H$_c$ = 75 kOe. The constructed
temperature-field phase diagram connects this transition to the suppression of
magnetic order, which evolves from a second-order nature into a first-order
transition that bifurcates at the spin-flop into three transitions below 1 K.
The smoothed nature of the metamagnetic transitions in non-stoichiometric
CeAuBi$_2$ is well described by an Ising model with weak quenched disorder,
suggesting that the presence of Au vacancies is sufficient to smear the complex
metamagnetic behavior and tune the critical behavior of magnetic order.

</details>


### [89] [Soft and hard x-ray orbital-resolved photoemission study of a strongly correlated Cd-Ce quasicrystal approximant](https://arxiv.org/abs/2510.24277)
*Goro Nozue,Hidenori Fujiwara,Satoru Hamamoto,Miwa Tsutsumi,Akane Ose,Takayuki Kiss,Atsushi Higashiya,Atsushi Yamasaki,Yuina Kanai-Nakata,Shin Imada,Masaki Oura,Kenji Tamasaku,Makina Yabashi,Tetsuya Ishikawa,Farid Labib,Shintaro Suzuki,Ryuji Tamura,Akira Sekiyama*

Main category: cond-mat.str-el

TL;DR: 通过软硬X射线光电子能谱研究Cd6Ce的轨道依赖电子态，发现4f轨道主要与远离费米能级的价带电子杂化，这与传统Ce基金属间化合物在费米能级的杂化行为形成鲜明对比，可能解释了Cd6Ce未解决的磁性基态。


<details>
  <summary>Details</summary>
Motivation: 研究强关联稀土基Tsai型准晶及其近似晶体中的轨道依赖电子态，特别是Cd6Ce中异常的杂化行为及其对磁性性质的影响。

Method: 使用软X射线和硬X射线光电子能谱技术研究Cd6Ce的电子结构。

Result: 发现4f轨道主要与远离费米能级的价带电子杂化，而非传统Ce基化合物中在费米能级与导带电子的杂化，这种异常杂化可能导致了Cd6Ce未解决的磁性基态。

Conclusion: Cd基近似晶体为研究传统费米能级杂化框架无法解释的奇异磁性性质提供了新平台，其中一些体系表现出多步磁转变。

Abstract: We have investigated the orbital-dependent electronic states of Cd6Ce, a
prototype of strongly correlated rare-earth-based Tsai-type quasicrystals and
approximants (ACs) by soft and hard x-ray photoemission spectroscopy. Our
results reveal that the 4f orbitals are predominantly hybridized with the
valence-band electrons far from the Fermi level EF, in sharp contrast to the
hybridization with conduction electrons at EF seen for the intermetallic
Ce-based compounds. This anomalous hybridization effect is likely responsible
for the unresolved magnetic ground state in Cd6Ce. These findings suggest that
Cd-based ACs, some of which show the multi-step magnetic transitions, provide a
new platform for investigating exotic magnetic properties that cannot be
understood within the conventional framework of hybridization at EF.

</details>


### [90] [Non-equilibrium correlation effects in spin transport through the 2D ferromagnet Fe$_4$GeTe$_2$](https://arxiv.org/abs/2510.24322)
*Declan Nell,Stefano Sanvito,Andrea Droghetti*

Main category: cond-mat.str-el

TL;DR: 开发了一种结合DFT、DMFT和非平衡格林函数的非平衡从头计算方法，研究2D铁磁体Fe4GeTe2的自旋输运，发现超过临界电压时会出现由载流子与粒子-空穴激发非弹性散射驱动的热关联电子态。


<details>
  <summary>Details</summary>
Motivation: 理解二维铁磁体中的非平衡自旋输运是一个理论挑战，因为关联效应会产生具有共存巡游和局域电子的复杂电子结构。

Method: 结合密度泛函理论(DFT)、动力学平均场理论(DMFT)和非平衡格林函数的完全非平衡从头计算方法。

Result: 在适度偏压下自旋输运基本保持单粒子特性，但超过临界电压时，载流子与粒子-空穴激发的非弹性自旋相关散射会驱动独特的热关联电子态，表现为电子谱和电导中的非相干特征。

Conclusion: 材料特定的多体非平衡方法对于完全理解二维铁磁体中的自旋输运至关重要。

Abstract: Understanding non-equilibrium spin transport through 2D ferromagnets is a
theoretical challenge, as correlations produce a complex electronic structure
with coexisting itinerant and localized electrons. We have developed a fully
non-equilibrium ab initio method, combining density functional theory,
dynamical mean-field theory, and non-equilibrium Green's functions to
investigate the transport in Fe$_4$GeTe$_2$, a prototypical high-temperature 2D
ferromagnet. We show that, while spin transport remains essentially
single-particle under moderate bias, inelastic spin-dependent scattering of
carriers with particle-hole excitations drives a distinctive hot-correlated
electron regime beyond a critical voltage. This regime is marked by incoherent
features in both the electronic spectrum and the conductance, which are
experimentally accessible. Our results demonstrates that material-specific
many-body non-equilibrium methods are essential for a complete understanding of
spin transport in 2D ferromagnets.

</details>


### [91] [Ultrafast recovery dynamics of dimer stripes in IrTe2](https://arxiv.org/abs/2510.24361)
*M. Rumo,G. Kremer,M. Heber,N. Wind,C. W. Nicholson,K. Y. Ma,G. Brenner,F. Pressacco,M. Scholz,K. Rossnagel,F. O. von Rohr,D. Kutnyakhov,C. Monney*

Main category: cond-mat.str-el

TL;DR: 使用自由电子激光时间分辨X射线光电子能谱研究IrTe2中二聚体的非平衡动力学，发现二聚体解离由电子子系统向晶格子系统的能量转移驱动，二聚体数量在皮秒尺度快速恢复，而长程有序需要数十皮秒才能恢复。


<details>
  <summary>Details</summary>
Motivation: 研究IrTe2中由强电子-声子耦合形成的一维条纹状二聚体在红外光激发后的非平衡动力学行为，理解局域二聚体畸变与长程有序恢复的时间尺度差异。

Method: 采用自由电子激光时间分辨X射线光电子能谱技术，跟踪红外光激发后二聚体数量的时间演化。

Result: 观察到二聚体解离由电子向晶格的能量转移驱动；二聚体数量在几皮秒内快速恢复；长程有序恢复需要数十皮秒，远慢于局域畸变恢复。

Conclusion: IrTe2中局域二聚体畸变与长程有序恢复存在显著时间尺度差异，表明局域结构恢复快于长程有序重建。

Abstract: The transition metal dichalcogenide IrTe2 displays a remarkable series of
first-order phase transitions below room temperature, involving lattice
displacements as large as 20 percents of the initial bond length. This is
nowadays understood as the result of strong electron-phonon coupling leading to
the formation of local multicentre dimers that arrange themselves into
one-dimensional stripes. In this work, we study the out-of-equilibrium dynamics
of these dimers and track the time evolution of their population following an
infrared photoexcitation using free-electron lased-based time-resolved X-ray
photoemission spectroscopy. First, we observe that the dissolution of dimers is
driven by the transfer of energy from the electronic subsystem to the lattice
subsystem, in agreement with previous studies. Second, we observe a
surprisingly fast relaxation of the dimer population on the timescale of a few
picoseconds. By comparing our results to published ultrafast electron
diffraction and angle-resolved photoemission spectroscopy data, we reveal that
the long-range order needs tens of picoseconds to recover, while the local
dimer distortion recovers on a short timescale of a few picoseconds.

</details>


### [92] [Low-energy magnons in the altermagnet $α$-MnTe](https://arxiv.org/abs/2510.24376)
*K. Yu. Povarov,J. Wosnitza,S. Rößler,M. Schmidt,A. A. Tsirlin,S. A. Zvyagin*

Main category: cond-mat.str-el

TL;DR: 本文通过高场电子自旋共振研究反铁磁材料α-MnTe，观察到与自由电子g因子接近的单一反铁磁共振模式，该模式在低温下异常尖锐，随温度升高因磁子-磁子相互作用增强而展宽。


<details>
  <summary>Details</summary>
Motivation: 研究反铁磁材料α-MnTe的磁共振特性，特别是了解其反铁磁共振模式的行为以及磁子-磁子相互作用的影响。

Method: 采用高场电子自旋共振技术，在平行于三角形Mn²⁺层的磁场方向进行测量，分析共振场的各向同性和线宽变化。

Result: 观察到单一反铁磁共振模式，具有各向同性的有效g因子2.01，接近自由电子值；低温下线宽仅约50 mT，随温度升高显著展宽。

Conclusion: α-MnTe的反铁磁共振行为证实了Mn²⁺离子缺乏轨道动量，并通过线宽的温度依赖性成功估计了磁子-磁子相互作用的强度。

Abstract: We report high-field electron spin resonance studies of the altermagnetic
material $\alpha$-MnTe. In magnetic fields applied parallel to the triangular
Mn$^{2+}$ layers we observed a single resonance line, corresponding to an
antiferromagnetic resonance (AFMR) mode. The resonance fields of this
excitation exhibit an isotropic behavior with $g_\mathrm{eff}=2.01$, which is
close to the free-electron $g$-factor value and agrees with the absence of
orbital momenta for the Mn$^{2+}$ ions. At low temperatures, the AFMR mode is
remarkably sharp ($\sim50$ mT for the full width at the half-maximum). This
mode exhibits a noticeable broadening with increasing temperature, indicating
the enhanced effect of magnon-magnon interactions. Based on this behavior, we
estimate the strength of these interactions.

</details>


### [93] [Crossover from self-trapped bound states to perturbative scattering in the Heisenberg-Kondo lattice model](https://arxiv.org/abs/2510.24520)
*Tanmoy Mondal,Pinaki Majumdar*

Main category: cond-mat.str-el

TL;DR: 该研究绘制了二维铁磁Heisenberg-Kondo晶格模型的完整输运相图，发现在低电子密度和强耦合条件下，电子会形成极化子态，导致电阻率在居里温度附近出现非单调峰值行为。


<details>
  <summary>Details</summary>
Motivation: 研究铁磁Heisenberg-Kondo晶格模型在不同电子密度和耦合强度下的输运特性，特别关注低密度强耦合区域中电子-自旋相互作用导致的非传统输运行为。

Method: 采用基于精确对角化的Langevin动力学生成磁构型，使用Kubo公式在精确本征态上计算电导率，在20×20晶格上研究温度、电子密度和耦合强度的依赖关系。

Result: 发现电子系统在高密度或弱耦合时保持均匀，电阻率随温度单调增加；而在低密度强耦合条件下，电子会极化磁态形成束缚态，电阻率在居里温度附近出现峰值，表现出极化子相的特征。

Conclusion: 确定了极化子窗口与传统散射区域的边界，揭示了极化子区域中过剩电阻率的起源是局域态比例增加导致迁移率边缘向化学势移动，增强了费米面附近动量态的散射。

Abstract: We map out the complete transport phase diagram of the ferromagnetic
Heisenberg-Kondo lattice model in two dimensions. The model involves
tight-binding electrons with hopping $t$, coupled to classical spins with
coupling $J'$, while the spins have a nearest neighbour coupling $J$ between
them. We work with a fixed, small $J/t$, and study the temperature dependence
of resistivity for varying electron density $n$ and coupling $J'/t$. Our
magnetic configurations are generated by exact diagonalisation-based Langevin
dynamics, while the conductivity is computed using the Kubo formula on exact
eigenstates. We work on lattices of size $20 \times 20$ and can access electron
density down to $n \sim 0.01$. The electron system remains homogeneous either
when the mean density is large or when the coupling $J'$ is small. In these
situations, the resistivity $\rho(T)$ displays a monotonic increase with
temperature and can be understood within a perturbative framework. However, at
very low density $n \lesssim 0.05$, strong coupling $J'/t \gtrsim 1$, and for
$T \sim T_c$, the electrons can locally polarise the magnetic state, create a
trapping potential, and form a bound state in it. The resistivity associated
with this polaronic phase is distinctly non-monotonic, with a peak near $T_c$.
We establish the boundary that separates the many-body polaronic window from
traditional scattering and extract a universal form for the resistivity in the
scattering regime. We suggest the origin of the `excess resistivity' in the
polaronic regime in terms of an increasing fraction of localised states as the
temperature tends to $T_c$. This pushes the mobility edge towards the chemical
potential $\mu$ and results in enhanced scattering of momentum states near
$k_F$. While our specific results are in two dimensions, the phenomenology we
uncover should be valid even in three dimensions.

</details>


### [94] [Magnetic and phononic dynamics in the two-ladder quantum magnet (C5H9NH3)2CuBr4](https://arxiv.org/abs/2510.24556)
*J. Philippe,F. Elson,T. Arh,S. Sanz,M. Metzelaars,D. W. Tam,O. K. Forslund,O. Shliakhtun,C. Jiang,J. Lass,M. D. Le,J. Ollivier,P. Bouillot,T. Giamarchi,M. Bartkowiak,D. G. Mazzone,P. Kögerler,M. Månsson,A. M. Läuchli,Y. Sassa,M. Janoschek,B. Normand,G. Simutis*

Main category: cond-mat.str-el

TL;DR: 该研究通过高分辨率中子光谱分析金属有机材料(C5H9NH3)2CuBr4，揭示了在结构软系统中磁性和晶格子系统之间的相互影响。研究发现磁性激发由两个能隙主导，确认了双梯子自旋哈密顿量，同时观察到声子谱中一个高度局域化模式随温度降低而频率下降。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在结构软系统中，当弹性能和磁性能量尺度相当时，磁关联是否会对声子谱产生显著影响。

Method: 使用大尺寸氘化单晶进行高分辨率中子光谱测量，通过测量多个布里渊区来分离振动贡献，从而准确获取准一维磁信号。

Result: 发现低能磁激发由两个能隙Δb=0.41 meV和Δa=0.55 meV主导，强度比相等，确认了双梯子自旋哈密顿量。声子谱包含一个高度局域化的2 meV低能模式，该频率随温度降低而下降约5%。

Conclusion: Cu-CPA实现了双梯子自旋哈密顿量，磁性和晶格子系统之间存在显著相互影响，特别是环戊基铵环的位置和结构导致了声子频率的温度依赖性变化。

Abstract: In quantum magnetic materials it is common to observe both static and dynamic
lattice effects on the magnetic excitation spectrum. Less common is to find
that the magnetic correlations have a significant impact on the phonon
spectrum. Can such an interplay occur in a structurally soft system with
comparable elastic and magnetic energy scales? Here we study the metal-organic
material (C5H9NH3)2CuBr4 (Cu-CPA), in which an explanation of the low-lying
excitations depends crucially on a full understanding of both the spin and
lattice subsystems. We report high-resolution neutron spectroscopy enabled by
large, deuterated single-crystals that reveal how both sectors are affected by
the recently discovered structural phase transition. By measuring over several
Brillouin zones, we disentangle the vibrational contribution to the spectrum in
order to obtain an accurate estimate of the quasi-one-dimensional magnetic
signal. The low-energy magnetic excitations are dominated by two gaps, $\Delta$
b = 0.41 meV and $\Delta$ a = 0.55 meV, which contribute with equal intensity
ratios, confirming that Cu-CPA realizes a two-ladder spin Hamiltonian, and we
deduce the magnetic interaction parameters of both ladders. The phonon spectrum
contains a highly localized mode at an anomalously low-energy around 2 meV.
This characteristic frequency drops by approximately 5 percent as magnetic
correlations become established with decreasing temperature, and we connect
this behavior with the location and structure of the cyclopentylammonium rings.

</details>


### [95] [Equilibrium Spin Polarization Arising From Chirality](https://arxiv.org/abs/2510.24624)
*Pius M. Theiler,Matthew C. Beard*

Main category: cond-mat.str-el

TL;DR: 该论文提出了一个伪厄米量子框架，解决了手性诱导自旋选择性（CISS）与微观可逆性和昂萨格互易性之间的悖论，预测了手性诱导的自旋磁有序，并推导了广义的昂萨格-卡西米尔关系。


<details>
  <summary>Details</summary>
Motivation: 手性诱导自旋选择性（CISS）现象在热平衡下产生自旋极化，这与微观可逆性和昂萨格互易性等基本原理相矛盾，需要解决这一悖论。

Method: 构建了一个伪厄米量子框架，其中结构手性和电子关联通过非局域度规耦合自旋和空间运动，产生实谱、幺正演化和热力学一致性。

Result: 该框架预测了手性诱导的自旋磁有序，表现为自旋-位移序参量⟨σ·x⟩，并推导了保持宇称和时间反演对称性破缺但保留联合PT对称性的广义昂萨格-卡西米尔关系。

Conclusion: 这一方法为平衡态CISS建立了连贯的理论基础，并提供了将化学手性与可测量的自旋-电荷转换效应联系起来的途径。

Abstract: Chirality-induced spin selectivity (CISS) describes how chiral molecules and
materials generate spin polarization even at thermal equilibrium. This
observation has challenged established principles of microscopic reversibility
and Onsager reciprocity. We resolve this paradox by formulating a
pseudo-Hermitian quantum framework in which structural chirality and electron
correlations are sufficient to produce CISS observables. Chirality enters
through a non-local metric that couples spin and spatial motion, leading to
real spectra, unitary evolution, and thermodynamic consistency. The framework
predicts a chirality-induced spin magnetic ordering characterized by a
spin--displacement order $\langle \sigma \cdot x \rangle$, which reconciles
equilibrium spin polarization with detailed balance and explains the
persistence of CISS in materials composed of light elements. We also derive
generalized Onsager-Casimir relations that respect the observed parity
($\mathcal{P}$) and time-reversal ($\mathcal{T}$) breaking, while preserving
combined $\mathcal{PT}$-symmetry. This approach establishes a coherent
foundation for equilibrium CISS and provides a route to link chemical chirality
with measurable spin-to-charge conversion effects.

</details>


### [96] [A light-induced charge order mode in a metastable cuprate ladder](https://arxiv.org/abs/2510.24686)
*Hari Padma,Prakash Sharma,Sophia F. R. TenHuisen,Filippo Glerean,Antoine Roll,Pan Zhou,Sarbajaya Kundu,Arnau Romaguera,Elizabeth Skoropata,Hiroki Ueda,Biaolong Liu,Eugenio Paris,Yu Wang,Seng Huat Lee,Zhiqiang Mao,Mark P. M. Dean,Edwin W. Huang,Elia Razzoli,Yao Wang,Matteo Mitrano*

Main category: cond-mat.str-el

TL;DR: 在光学激发的铜酸盐梯子Sr14Cu24O41中观察到一种涌现的电荷有序模式，近红外光驱动对称性保护的电子亚稳态，同时部分熔化平衡电荷有序。时间分辨共振非弹性X射线散射测量揭示了从电荷有序波矢量到0.8 eV的无能隙集体激发，斜率为准粒子速度量级。


<details>
  <summary>Details</summary>
Motivation: 探索光激发下铜酸盐材料中电荷有序的动态行为，研究相关载流子在有限动量下获得巡游特性的机制，为探索光诱导配对不稳定性提供平台。

Method: 使用时间分辨共振非弹性X射线散射技术，在铜酸盐梯子Sr14Cu24O41的上哈伯德带进行测量，分析近红外光激发后的电荷有序动态。

Result: 观察到从电荷有序波矢量到0.8 eV的无能隙集体激发，斜率约为准粒子速度量级，表明电荷有序变为动态涨落状态，相关载流子在有限动量下获得巡游特性。

Conclusion: 研究揭示了光激发下电荷有序的动态涨落机制，为探索相关电子系统中光诱导配对不稳定性提供了新的实验平台和物理见解。

Abstract: We report the observation of an emergent charge order mode in the
optically-excited cuprate ladder Sr$_{14}$Cu$_{24}$O$_{41}$. Near-infrared
light in the ladder plane drives a symmetry-protected electronic metastable
state together with a partial melting of the equilibrium charge order. Our
time-resolved resonant inelastic x-ray scattering measurements at the upper
Hubbard band reveal a gapless collective excitation dispersing from the
charge-order wavevector up to 0.8 eV with a slope on the order of the
quasiparticle velocity. These findings reveal a regime where correlated
carriers acquire itinerant character at finite momentum, and charge order
becomes dynamically fluctuating, offering a platform to explore light-induced
pairing instabilities.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [97] [Quantum Mechanics of Stochastic Systems](https://arxiv.org/abs/2510.23654)
*Yurang,Kuang*

Main category: quant-ph

TL;DR: 该论文提出了量子随机系统力学(QMSS)框架，将经典离散随机过程视为量子谐振子的扰动，通过构造精确的扰动势能将量子态转化为随机表示，并建立了完整的算子代数用于矩生成和信息论分析。


<details>
  <summary>Details</summary>
Motivation: 建立量子力学与经典随机系统之间的根本联系，证明经典概率分布可以从量子谐振子的特定扰动中自然产生，为量子概率工程提供理论基础。

Method: 通过构造精确的扰动势能，将量子谐振子本征态转化为随机表示；引入计数算子(N)和模投影算子(R_M)建立完整的算子代数；开发严格的均匀收敛定理支持有限维近似。

Result: 成功从量子谐振子扰动中推导出二项分布、负二项分布和泊松分布等经典概率分布；建立了真均匀随机数生成(TURNG)方法，无需外部白化处理；实现了量子概率工程，通过设计的量子扰动物理实现经典分布。

Conclusion: 随机系统在结构上本质上是量子力学的，该框架成功连接了量子动力学、统计物理和实验概率实现，为量子概率工程和随机数生成提供了新的理论基础。

Abstract: We develop a fundamental framework for the quantum mechanics of stochastic
systems (QMSS), showing that classical discrete stochastic processes emerge
naturally as perturbations of the quantum harmonic oscillator (QHO). By
constructing exact perturbation potentials that transform QHO eigenstates into
stochastic representations, we demonstrate that canonical probability
distributions, including Binomial, Negative Binomial, and Poisson, arise from
specific modifications of the harmonic potential. Each stochastic system is
governed by a Count Operator (N), with probabilities determined by squared
amplitudes in a Born-rule-like manner.
  The framework introduces a complete operator algebra for moment generation
and information-theoretic analysis, together with modular projection operators
(R_M) that enable finite-dimensional approximations supported by rigorous
uniform convergence theorems. This mathematical structure underpins True
Uniform Random Number Generation (TURNG) [Kuang, Sci. Rep., 2025], eliminating
the need for external whitening processes.
  Beyond randomness generation, the QMSS framework enables quantum probability
engineering: the physical realization of classical distributions through
designed quantum perturbations. These results demonstrate that stochastic
systems are inherently quantum-mechanical in structure, bridging quantum
dynamics, statistical physics, and experimental probability realization.

</details>


### [98] [Anti-concentration is (almost) all you need](https://arxiv.org/abs/2510.23719)
*Markus Heinrich,Jonas Haferkamp,Ingo Roth,Jonas Helsen*

Main category: quant-ph

TL;DR: 本文证明对于局部随机量子电路，反集中性意味着相对误差近似状态2-设计，表明这两个性质在这些系综中是等价的。


<details>
  <summary>Details</summary>
Motivation: 先前认为近似2-设计性质严格强于随机量子电路的反集中性，因为反集中性在对数深度出现，而2-设计通常需要线性深度。最近研究显示相对误差近似幺正设计可以在对数深度生成，但这不适用于普通局部随机电路。

Method: 证明局部随机量子电路的反集中性意味着它们形成相对误差近似状态2-设计，适用于任何在局部幺正变换下不变的随机电路，与架构无关。

Result: 建立了局部随机量子电路中反集中性与相对误差近似状态2-设计之间的等价关系。

Conclusion: 对于局部随机量子电路，反集中性和相对误差近似状态2-设计是等价性质，填补了先前研究中的空白。

Abstract: Until very recently, it was generally believed that the (approximate)
2-design property is strictly stronger than anti-concentration of random
quantum circuits, mainly because it was shown that the latter anti-concentrate
in logarithmic depth, while the former generally need linear depth circuits.
This belief was disproven by recent results which show that so-called
relative-error approximate unitary designs can in fact be generated in
logarithmic depth, implying anti-concentration. Their result does however not
apply to ordinary local random circuits, a gap which we close in this paper, at
least for 2-designs. More precisely, we show that anti-concentration of local
random quantum circuits already implies that they form relative-error
approximate state 2-designs, making them equivalent properties for these
ensembles. Our result holds more generally for any random circuit which is
invariant under local (single-qubit) unitaries, independent of the
architecture.

</details>


### [99] [Apparent Universal Behavior in Second Moments of Random Quantum Circuits](https://arxiv.org/abs/2510.23726)
*Daniel Belkin,James Allen,Bryan K. Clark*

Main category: quant-ph

TL;DR: 该论文研究了随机量子电路形成近似2-design的速度，分析了不同架构下的电路深度要求，发现大多数电路在深度与对数n成正比时形成2-design，但某些图结构需要Ω(n²)门数。


<details>
  <summary>Details</summary>
Motivation: 研究随机量子电路形成近似2-design的速度差异，探讨反集中与2-design的关系，以及不同几何结构对电路深度的影响，为实际应用提供指导。

Method: 提出确定最优实验的策略来区分给定系综与Haar测度，使用计算技巧精确计算t=2乘法误差，分析不同图架构的电路性能。

Result: 大多数电路架构在深度∝log n时形成ε-近似2-design，但某些图结构需要Ω(n²)门数；星图反集中比形成2-design快得多；实际应用中仅需10-20层即可构建近似2-design。

Conclusion: 电路架构的连通性影响形成2-design的速度，提出了通用上下界猜想，并行完全图架构不是最快的混洗器，为实际量子电路设计提供了重要参考。

Abstract: Just how fast does the brickwork circuit form an approximate 2-design?
  Is there any difference between anticoncentration and being a 2-design?
  Does geometry matter?
  How deep a circuit will I need in practice?
  We tell you everything you always wanted to know about second moments of
random quantum circuits, but were too afraid to compute. Our answers generally
take the form of numerical results for up to 50 qubits.
  Our first contribution is a strategy to determine explicitly the optimal
experiment which distinguishes any given ensemble from the Haar measure. With
this formula and some computational tricks, we are able to compute $t = 2$
multiplicative errors exactly out to modest system sizes. As expected, we see
that most families of circuits form $\epsilon$-approximate $2$-designs in depth
proportional to $\log n$. For the 1D brickwork, we work out the leading-order
constants explicitly.
  For graphs, we find some exceptions which are much slower, proving that they
require at least $\Omega(n^2)$ gates. This answers a question asked by ref. 1
in the negative. We explain these exceptional architectures in terms of
connectedness. Based on this intuition we conjecture universal upper and lower
bounds for graph-sampled circuit ensembles.
  For many architectures, the optimal experiment which determines the
multiplicative error corresponds exactly to the collision probability (i.e.
anticoncentration). However, we find that the star graph anticoncentrates much
faster than it forms an $\epsilon$-approximate $2$-design. Finally, we show
that one needs only ten to twenty layers to construct an approximate $2$-design
for realistic parameter ranges. This is a large constant-factor improvement
over previous constructions. The parallel complete-graph architecture is not
quite the fastest scrambler, partially resolving a question raised by ref. 2.

</details>


### [100] [Dynamical system analysis of quantum tunneling in an asymmetric double-well potential](https://arxiv.org/abs/2510.24100)
*Swetamber Das,Arghya Dutta*

Main category: quant-ph

TL;DR: 使用基于Ehrenfest形式体系的动力学系统方法研究非对称双势阱中的量子隧穿，通过高斯波包演化方程和近似闭合得到可处理的简化系统，识别了可检测隧穿的能量阈值和实际不可检测的隧穿区域。


<details>
  <summary>Details</summary>
Motivation: 研究非对称双势阱中的量子隧穿现象，旨在通过动力学系统方法提供对量子隧穿过程的物理解释，特别是在非对称势场中的隧穿行为。

Method: 基于Ehrenfest形式体系，建立高斯波包演化的耦合方程层次结构，采用近似闭合得到简化的动力学系统，分析均值和方差的演化，并考虑偏度对非对称性的影响。

Result: 稳定性分析确定了可检测隧穿的能量阈值，揭示了理论上允许但实际不可检测的隧穿区域，与完整数值解比较显示该方法能重现关键隧穿特征。

Conclusion: 动力学系统方法不仅能够再现量子隧穿的关键特征，还为非对称双能级系统中的量子输运提供了可解释的描述框架。

Abstract: We study quantum tunneling in an asymmetric double-well potential using a
dynamical systems--based approach rooted in the Ehrenfest formalism. In this
framework, the time evolution of a Gaussian wave packet is governed by a
hierarchy of coupled equations linking lower- and higher-order position
moments. An approximate closure, required to render the system tractable,
yields a reduced dynamical system for the mean and variance, with skewness
entering explicitly due to the potential's asymmetry. Stability analysis of
this system identifies energy thresholds for detectable tunneling across the
barrier and reveals regimes where tunneling, though theoretically allowed,
remains practically undetectable. Comparison with full numerical solutions of
the time-dependent Schr\"odinger equation shows that, beyond reproducing key
tunneling features, the dynamical systems approach provides an interpretable
description of quantum transport through tunneling in an effective asymmetric
two-level system.

</details>


### [101] [Thermodynamic work capacity of quantum information processing](https://arxiv.org/abs/2510.23731)
*Himanshu Badhani,Dhanuja G S,Siddhartha Das*

Main category: quant-ph

TL;DR: 本文提出了量子通道的资源理论自由能概念，定义为当通道输出热化到热态且参考系统保持局部完整时可提取的最大功。该自由能与给定通道和绝对热通道之间的相对熵成正比，并在吉布斯保持超通道下具有清晰的渐近可逆性操作意义。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理和计算本质上涉及量子通道的操纵和转换，包括量子态、它们的变换和测量。定量表征量子信息处理中最佳热力学功增益或消耗是制定量子过程热力学的关键步骤。

Method: 通过定义量子通道的资源理论自由能，并将其与绝对热通道的相对熵相关联，研究在吉布斯保持超通道下的渐近非热性蒸馏和形成速率。

Result: 发现量子通道的自由能等于其与绝对热通道相对熵的两倍，并证明了在吉布斯保持超通道下非热性资源理论的渐近可逆性。通道转换的最佳可提取功等于它们自由能的差异，称为通道转换的热力学功容量。

Conclusion: 建立了量子通道热力学的基本框架，为量子信息处理过程的热力学分析提供了理论基础，揭示了通道转换过程中热力学功的定量关系。

Abstract: We introduce the resource-theoretic free energy of a quantum channel as the
maximal work extractable from the channel as its output equilibrates to a
thermal state and its reference system remains locally intact. It is
proportional to the relative entropy between the given channel and the
absolutely thermal channel. It attains a clear operational meaning as twice the
asymptotic rates of athermality distillation and formation under Gibbs
preserving superchannels, which map one absolutely thermal channel to another
for a given bath, thereby revealing the asymptotic reversibility of the
resource theory of athermality for quantum channels. Consequently, we establish
that the optimal extractable work in converting one channel to another through
the asymptotic athermality distillation and formation tasks equals the
difference in their free energies. We call this optimal work the thermodynamic
work capacity of channel conversion. Quantum information processing and
computing fundamentally concern the manipulation and transformation of quantum
channels, which encompass quantum states, their transformations, and
measurements. A quantitative characterization of the optimal thermodynamic work
gain or expenditure in quantum information processing constitutes a key step
toward formulating thermodynamics of quantum processes.

</details>


### [102] [The injective norm of CSS quantum error-correcting codes](https://arxiv.org/abs/2510.23736)
*Stephane Dartois,Gilles Zémor*

Main category: quant-ph

TL;DR: 本文计算了CSS量子纠错码标准基态的注入范数（即几何纠缠度），这是衡量真正多体纠缠的指标。通过将结果扩展到所有CSS码，发现了一个与拟阵理论和Edmonds交集定理的有趣联系。


<details>
  <summary>Details</summary>
Motivation: 注入范数是衡量量子态真正多体纠缠的重要指标，但计算该指标通常是NP难的。虽然之前已在凝聚态物理中为Kitaev码及其扩展计算了该值，但需要扩展到更广泛的CSS码家族。

Method: 通过将CSS码的注入范数计算问题与拟阵理论中的Edmonds交集定理建立联系，从而能够为所有CSS码计算这一纠缠度量。

Result: 成功计算了所有CSS码标准基态的注入范数，得到了一个非平凡无限量子态家族的纠缠度量精确值。

Conclusion: 本研究不仅扩展了CSS码的几何纠缠计算，还揭示了量子信息与组合数学中拟阵理论之间的深刻联系，为理解量子纠缠提供了新的数学工具。

Abstract: In this paper, we compute the injective norm - a.k.a. geometric entanglement
- of standard basis states of CSS quantum error-correcting codes. The injective
norm of a quantum state is a measure of genuine multipartite entanglement.
Computing this measure is generically NP-hard. However, it has been computed
exactly in condensed-matter theory - notably in the context of topological
phases - for the Kitaev code and its extensions, in works by Or\'us and
collaborators. We extend these results to all CSS codes and thereby obtain the
injective norm for a nontrivial, infinite family of quantum states. In doing
so, we uncover an interesting connection to matroid theory and Edmonds'
intersection theorem.

</details>


### [103] [Topological protection of photon-pair generation in nonlinear waveguide arrays](https://arxiv.org/abs/2510.23796)
*A. Zecchetto,J. -R. Coudevylle,M. Morassi,A. Lemaître,M. I. Amanti,S. Ducci,F. Baboux*

Main category: quant-ph

TL;DR: 该论文研究了非线性波导阵列中拓扑效应对自发参量下转换光子对生成的影响，发现拓扑Su-Schrieffer-Heeger阵列在隧道耦合无序条件下能保持稳定的SPDC共振谱，共振位置波动减少超过一个数量级。


<details>
  <summary>Details</summary>
Motivation: 利用拓扑效应保护量子光态免受缺陷影响，为量子信息处理提供更稳健的平台，特别适用于片上生成量子光的主动光子电路。

Method: 通过理论和实验研究非线性波导阵列中的自发参量下转换，系统比较均匀、平庸和拓扑Su-Schrieffer-Heeger阵列的性能。

Result: 只有拓扑配置在隧道耦合无序条件下保持稳定的SPDC共振谱，共振位置波动减少超过一个数量级。分析模型将这种鲁棒性与相互作用模式的能带结构特性联系起来。

Conclusion: 二次非线性波导阵列是探索非线性、拓扑和无序在量子光子电路中相互作用的理想平台。

Abstract: Harnessing topological effects offers a promising route to protect quantum
states of light from imperfections, potentially enabling more robust platforms
for quantum information processing. This capability is particularly relevant
for active photonic circuits that generate quantum light directly on-chip.
Here, we explore topological effects on photon-pair generation via spontaneous
parametric down-conversion (SPDC) in nonlinear waveguide arrays, both
theoretically and experimentally. A systematic comparison of homogeneous,
trivial, and topological Su-Schrieffer-Heeger arrays reveals that only the
topological configuration preserves a stable SPDC resonance spectrum under
disorder in the tunnel couplings, with fluctuations in the resonance position
reduced by more than one order of magnitude. An analytical model supports our
experimental observations by linking this robustness to the band-structure
properties of the interacting modes. These findings establish quadratic
nonlinear waveguide arrays as a promising platform to explore the interplay of
nonlinearity, topology, and disorder in quantum photonic circuits.

</details>


### [104] [Estimating and decoding coherent errors of QEC experiments with detector error models](https://arxiv.org/abs/2510.23797)
*Evangelia Takou,Kenneth R. Brown*

Main category: quant-ph

TL;DR: 该论文提出了一种基于量子纠错实验的综合征历史来检测和估计相干误差的方法，无需先前的设备基准测试实验。研究表明实验确定的检测器误差模型在随机和相干噪声机制下同样有效，并揭示了相干噪声下不同的解码阈值。


<details>
  <summary>Details</summary>
Motivation: 量子纠错实验的解码器通常基于检测到的错误和预期错误率做出决策，这些构成了检测器误差模型。传统方法需要先进行设备基准测试，但本文旨在证明仅使用综合征历史就足以检测和估计相干误差。

Method: 采用Majorana和Monte Carlo模拟器，对重复码和表面码进行建模，考虑完全相干或完全随机噪声，以及各种唯象和电路级噪声场景。通过捕获相干误差的干涉效应，观察到与随机情况相比增强或抑制的物理错误率。

Result: 研究发现实验确定的检测器误差模型在随机和相干噪声机制下同样有效。观察到在相应Pauli-twirl模型中不出现的超边，并发现相干噪声下的解码阈值与基于随机噪声假设构建的检测器误差模型不同。

Conclusion: 该方法证明了仅使用量子纠错实验的综合征历史就足以检测和估计相干误差，消除了对先验设备基准测试实验的需求，为量子纠错提供了更高效和准确的误差建模方法。

Abstract: Decoders of quantum error correction (QEC) experiments make decisions based
on detected errors and the expected rates of error events, which together
comprise a detector error model. Here we show that the syndrome history of QEC
experiments is sufficient to detect and estimate coherent errors, removing the
need for prior device benchmarking experiments. Importantly, our method shows
that experimentally determined detector error models work equally well for both
stochastic and coherent noise regimes. We model fully-coherent or
fully-stochastic noise for repetition and surface codes and for various
phenomenological and circuit-level noise scenarios, by employing Majorana and
Monte Carlo simulators. We capture the interference of coherent errors, which
appears as enhanced or suppressed physical error rates compared to the
stochastic case, and also observe hyperedges that do not appear in the
corresponding Pauli-twirled models. Finally, we decode the detector error
models undergoing coherent noise and find different thresholds compared to
detector error models built based on the stochastic noise assumption.

</details>


### [105] [Differential magnetometry with partially flipped Dicke states](https://arxiv.org/abs/2510.23815)
*Iagoba Apellaniz,Manuel Gessner,Géza Tóth*

Main category: quant-ph

TL;DR: 该论文研究使用两个空间分离的自旋系综进行磁场梯度和均匀背景场的磁力测量，推导了这些参数估计精度的权衡关系，并展示了如何利用Dicke态通过局部旋转实现梯度测量的量子增强。


<details>
  <summary>Details</summary>
Motivation: 研究磁场梯度和均匀背景场的多参数估计问题，探索如何利用量子纠缠状态（如Dicke态）来超越经典测量极限，实现量子增强的磁力测量。

Method: 通过将Dicke态在其中一个子系综中局部旋转，构造对磁场梯度敏感的状态；使用量子Cramér-Rao界分析估计精度；对于小系综识别最优测量算符，对于大系综提出简化但次优的方案；通过角动量算符的二阶矩和相关性估计梯度。

Result: 部分翻转的Dicke态在两个方向上具有相似的灵敏度，但在第三个方向上灵敏度显著降低；利用两个系综之间的纠缠，该状态达到的精度大约是最好二分可分离态（局部Dicke态乘积）的两倍。

Conclusion: 研究结果展示了如何利用Dicke态的计量特性实现量子增强的多参数估计，为磁场梯度测量提供了有效的量子计量方案。

Abstract: We study magnetometry of gradients and homogeneous background fields along
all three spatial axes using two spatially separated spin ensembles. We derive
trade-off relations for the achievable estimation precision of these
parameters. Dicke states, optimal for homogeneous field estimation, can be
locally rotated into states sensitive to magnetic gradients by rotating the
spins in one subensemble. We determine bounds for the precision for gradient
metrology in the three orthogonal directions as a function of the sensitivities
of the homogenous field in those directions. The resulting partially flipped
Dicke state saturates the bounds above, showing similar sensitivity in two
directions but significantly reduced sensitivity in the third. Exploiting
entanglement between the two ensembles, this state achieves roughly twice the
precision attainable by the best bipartite separable state, which is a product
of local Dicke states. For small ensembles, we explicitly identify measurement
operators saturating the quantum Cram\'er-Rao bound, while for larger
ensembles, we propose simpler but suboptimal schemes. In both cases, the
gradient is estimated from second moments and correlations of angular momentum
operators. Our results demonstrate how the metrological properties of Dicke
states can be exploited for quantum-enhanced multiparameter estimation.

</details>


### [106] [A Scalable Superconducting Circuit Framework for Emulating Physics in Hyperbolic Space](https://arxiv.org/abs/2510.23827)
*Xicheng Xu,Ahmed Adel Mahmoud,Noah Gorgichuk,Ronny Thomale,Steven Rayan,Matteo Mariantoni*

Main category: quant-ph

TL;DR: 该论文提出了一种可扩展的超导电路框架，用于模拟双曲和kagome类晶格上的紧束缚模型，首次实验实现了位于genus-3黎曼曲面上的双曲晶格。


<details>
  <summary>Details</summary>
Motivation: 近年来理论研究和实验揭示了通过合成负曲率空间工程在器件物理中实现新颖行为和功能的潜力，特别是双曲能带理论发现了高维本征态等传统欧几里德系统中根本不存在的新特征。同时，超导量子电路已成为可扩展架构中量子模拟和数字模拟的主要平台。

Method: 使用可扩展的超导电路框架，将双曲度量直接编码到高质量超导谐振器之间的电容耦合中，从而模拟双曲和kagome类晶格上的紧束缚模型。

Result: 实验实现了三种不同的晶格，包括首次在genus-3黎曼曲面上的双曲晶格单元。该方法克服了先前设计的主要可扩展性和光谱分辨率限制，能够可靠地再现光谱和局域化特性。

Conclusion: 这些结果为凝聚态物理中双曲材料的大规模实验研究奠定了基础，并为实现双曲量子处理器铺平了道路，对基础物理和量子计算都具有潜在影响。

Abstract: Theoretical studies and experiments in the last six years have revealed the
potential for novel behaviours and functionalities in device physics through
the synthetic engineering of negatively-curved spaces. For instance, recent
developments in hyperbolic band theory have unveiled the emergence of
higher-dimensional eigenstates -- features fundamentally absent in conventional
Euclidean systems. At the same time, superconducting quantum circuits have
emerged as a leading platform for quantum analogue emulations and digital
simulations in scalable architectures. Here, we introduce a scalable
superconducting circuit framework for the analogue quantum emulation of
tight-binding models on hyperbolic and kagome-like lattices. Using this
approach, we experimentally realize three distinct lattices, including, for the
first time to our knowledge, a hyperbolic lattice whose unit cell resides on a
genus-3 Riemann surface. Our method encodes the hyperbolic metric directly into
capacitive couplings between high-quality superconducting resonators, enabling
tenable reproduction of spectral and localization properties while overcoming
major scalability and spectral resolution limitations of previous designs.
These results set the stage for large-scale experimental studies of hyperbolic
materials in condensed matter physics and lay the groundwork for realizing
hyperbolic quantum processors, with potential implications for both fundamental
physics and quantum computing

</details>


### [107] [Clifford Transformations for Fermionic Quantum Systems: From Paulis to Majoranas to Fermions](https://arxiv.org/abs/2510.23923)
*Ilias Magoulas,Francesco A. Evangelista*

Main category: quant-ph

TL;DR: 本文扩展了Clifford变换的概念到费米子系统，证明了费米子Clifford变换由半体和配对算子生成，建立了与费米子平均场理论和量子比特缩减的联系。


<details>
  <summary>Details</summary>
Motivation: Clifford门和变换在量子计算中具有基础性作用，支撑着稳定子形式、纠错码、魔态蒸馏等关键应用。由于纯Clifford门电路可经典模拟，其计算意义重大。本文旨在将这一重要概念扩展到费米子系统。

Method: 通过证明费米子Clifford变换由半体算子和配对算子生成，提供了系统性的表征框架。

Result: 成功建立了费米子Clifford变换的生成元理论，并展示了其在费米子平均场理论和量子比特缩减中的应用。

Conclusion: 费米子Clifford变换的扩展为量子计算提供了新的理论工具，揭示了其在更广泛量子系统中的潜在应用价值。

Abstract: Clifford gates and transformations, which map products of elementary Pauli or
Majorana operators to other such products, are foundational in quantum
computing, underpinning the stabilizer formalism, error-correcting codes, magic
state distillation, quantum communication and cryptography, and qubit tapering.
Moreover, circuits composed entirely of Clifford gates are classically
simulatable, highlighting their computational significance. In this work, we
extend the concept of Clifford transformations to fermionic systems. We
demonstrate that fermionic Clifford transformations are generated by half-body
and pair operators, providing a systematic framework for their
characterization. Additionally, we establish connections with fermionic
mean-field theories and applications in qubit tapering, offering insights into
their broader implications in quantum computing.

</details>


### [108] [Distinct Types of Parent Hamiltonians for Quantum States: Insights from the $W$ State as a Quantum Many-Body Scar](https://arxiv.org/abs/2510.24713)
*Lei Gioia,Sanjay Moudgalya,Olexei I. Motrunich*

Main category: quant-ph

TL;DR: 该论文研究了量子多体疤痕(QMBS)的局域父哈密顿量分类问题，以W态为主要示例，系统分析了三种不同类型的父哈密顿量及其动力学特征。


<details>
  <summary>Details</summary>
Motivation: 研究动机是推广传统父哈密顿量构造问题，考察简单量子态作为精确本征态的局域哈密顿量，这些态通常对应量子多体疤痕。

Method: 使用W态作为主要示例，严格推导完整的局域父哈密顿量集合，建立一般性结果如渐近QMBS的存在性，并分析不同父哈密顿量类型的动力学特征。

Result: 建立了父哈密顿量的三种不同类型分类，证明了渐近QMBS的存在性，并发现不同类型父哈密顿量具有不同的动力学特征。对于简单量子态如乘积态，发现只存在单一类型。

Conclusion: 该工作为基于局域性和量子多体疤痕相互作用的父哈密顿量丰富结构和动力学性质的分类研究打开了大门。

Abstract: The construction of parent Hamiltonians that possess a given state as their
ground state is a well-studied problem. In this work, we generalize this notion
by considering simple quantum states and examining the local Hamiltonians that
have these states as exact eigenstates.These states often correspond to Quantum
Many-Body Scars (QMBS) of their respective parent Hamiltonians.Motivated by
earlier works on Hamiltonians with QMBS, in this work we formalize the
differences between three distinct types of parent Hamiltonians, which differ
in their decompositions into strictly local terms with the same eigenstates. We
illustrate this classification using the $W$ state as the primary example, for
which we rigorously derive the complete set of local parent Hamiltonians, which
also allows us to establish general results such as the existence of asymptotic
QMBS, and distinct dynamical signatures associated with the different parent
Hamiltonian types. Finally, we derive more general results on the parent
Hamiltonian types that allow us to obtain some immediate results for simple
quantum states such as product states, where only a single type exists, and for
short-range-entangled states, for which we identify constraints on the
admissible types. Altogether, our work opens the door to classifying the rich
structures and dynamical properties of parent Hamiltonians that arise from the
interplay between locality and QMBS.

</details>


### [109] [Nonreciprocity enhanced Quantum Gyroscopes based on Surface Acoustic Waves](https://arxiv.org/abs/2510.23996)
*Y. T. Zhu,Shibei Xue,Fangfang Ju,Haidong Yuan*

Main category: quant-ph

TL;DR: 本文提出了一种基于多点耦合的量子陀螺仪，利用表面声波在极低泵浦功率下的量子相干性，通过空间分离耦合点产生的非局域性实现定向耦合，显著提升了信噪比和灵敏度。


<details>
  <summary>Details</summary>
Motivation: 传统基于科里奥利效应的表面声波陀螺仪在现代复杂传感场景中效果有限，需要探索量子极限下的新型传感方案。

Method: 设计多点耦合量子陀螺仪，利用空间分离耦合点产生的非局域性和时间延迟动力学，突破马尔可夫近似限制，实现非互易传输。

Result: 多点耦合系统展现出固有的非互易传输特性，能够提取被噪声掩盖的输出信号，显著提高信噪比和灵敏度。

Conclusion: 具有多点耦合和相关非互易性的系统可作为推进量子传感技术的有价值资源。

Abstract: Surface acoustic waves (SAWs), as Rayleigh waves generated by elastic media,
have been used in gyroscopes for over 40 years due to their unique propagation
characteristics. However, their working principle, based on Coriolis effects,
has become increasingly ineffective for addressing modern sensing challenges in
complex scenarios. Fortunately, recent advancements in quantized SAWs offer a
promising solution: SAWs operating at extremely low pump powers (approximately
at the single-phonon level) can exhibit substantial quantum coherence, enabling
investigations into the fundamental limits of SAW gyroscopes as constrained by
the Heisenberg uncertainty relation. In particular, when multiple SAWs couple
to a common waveguide at distinct locations, the nonlocality arising from the
spatial separation among coupling points induces directional coupling between
the SAWs. To elucidate this directionality, we propose a quantum gyroscope
characterized by multiplepoint couplings. Unlike traditional single-point
coupling designs, our gyroscope exhibits distinctive time-delayed dynamics that
depend on the system's topologies. We emphasize that these dynamics invalidate
the Markovian approximation, even when the time delay is relatively small.
Through a comprehensive analysis of all possible topologies, we observe that
the directional coupling implies an inherent nonreciprocal transfer. This
nonreciprocity confers signiffcant advantages to our gyroscope compared to
traditional designs, notably enhancing both the signal-to-noise ratio and
sensitivity. Speciffcally, it enables the extraction of output signals that
would otherwise be obscured by noise. Consequently, our ffndings suggest that
systems with multiple-point couplings and the associated nonreciprocity can
serve as valuable resources for advancing quantum sensing technologies.

</details>


### [110] [Non-Hermitian $\mathrm{sl}(3, \mathbb{C})$ three-mode couplers](https://arxiv.org/abs/2510.24047)
*B. M. Rodriguez-Lara,H. Ghaemi-Dizicheh,S. Dehdashti,A. Hanke,A. Touhami,J. Nötzel*

Main category: quant-ph

TL;DR: 本文提出了一个通用的sl(N,C)框架来分析任意N模耦合器，特别针对N=3的情况进行了详细研究。该框架能够分类耦合器族系，研究高阶异常点的拓扑特性，并应用于有损三腿光束分离器的传播动力学分析。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常关注特定设计的N模耦合器，而忽略了其代数结构。为了系统分析非厄米模耦合器并指导经典和量子平台的设计，需要建立通用的代数框架。

Method: 引入sl(N,C)代数框架，对N=3情况进行显式开发，包括代数对角化、传播相关规范、Wei-Norman传播子等方法，用于捕获完整动力学和异常点交叉。

Result: 成功分类了耦合器族系，发现在PT对称和非厄米循环耦合器中，两个三阶异常点位于二阶异常点的连续体中，排除了纯环绕的可能性。分析了有损三腿光束分离器的传播动力学。

Conclusion: 该框架为分析非厄米模耦合器提供了系统路径，能够指导经典和量子平台的设计，揭示了异常点的拓扑特性和传播动力学行为。

Abstract: Photonic systems with exceptional points, where eigenvalues and corresponding
eigenstates coalesce, have attracted interest due to their topological features
and enhanced sensitivity to external perturbations. Non-Hermitian mode-coupling
matrices provide a tractable analytic framework to model gain, loss, and
chirality across optical, electronic, and mechanical platforms without the
complexity of full open-system dynamics. Exceptional points define their
spectral topology, and enable applications in mode control, amplification, and
sensing. Yet $N$-mode couplers, the minimal setting for $N$th-order exceptional
points, are often studied in specific designs that overlook their algebraic
structure. We introduce a general $\mathrm{sl}(N,\mathbb{C})$ framework for
arbitrary $N$-mode couplers in classical and quantum regimes, and develop it
explicitly for $N=3$. This case admits algebraic diagonalization, where a
propagation-dependent gauge aligns local and dynamical spectra and reveals the
geometric phase connecting adiabatic and exact propagation. An exact
Wei--Norman propagator captures the full dynamics and makes crossing
exceptional points explicit. Our framework enables classification of coupler
families. We study the family spanning $\mathcal{PT}$-symmetric and
non-Hermitian cyclic couplers, where two exceptional points of order three lie
within a continuum of exceptional points of order two, ruling out pure
encircling. As an application, we study these exceptional points for a lossy
three-leg beam splitter and reveal its propagation dynamics as a function of
initial states, such as Fock and NOON states. Our approach provides a
systematic route to analyze non-Hermitian mode couplers and guide design in
classical and quantum platforms.

</details>


### [111] [Exploiting biased noise in variational quantum models](https://arxiv.org/abs/2510.24050)
*Connor van Rossum,Sally Shrapnel,Riddhi Gupta*

Main category: quant-ph

TL;DR: 研究发现，在变分量子算法中，传统的噪声对称化方法（如twirling）反而会降低性能，而保留有偏噪声（如振幅阻尼）可能帮助经典优化器找到更好的解。


<details>
  <summary>Details</summary>
Motivation: 研究量子噪声对变分量子算法经典优化过程的影响，挑战传统的噪声缓解策略。

Method: 分析通用量子回归模型，研究不同噪声类型（均匀泡利通道、非幺正噪声等）对梯度幅度和表达能力的影响，并通过横向场伊辛模型的变分本征求解器进行数值实验验证。

Result: 相对均匀的泡利通道会抑制梯度幅度并降低表达能力，使优化更困难；而非对称噪声（如振幅阻尼）引入的方向性偏置可在优化中被利用，产生更低能量的状态。

Conclusion: 这些发现挑战了传统的噪声缓解策略，表明保留噪声偏置可能增强变分量子算法的性能。

Abstract: Variational quantum algorithms (VQAs) are promising tools for demonstrating
quantum utility on near-term quantum hardware, with applications in
optimisation, quantum simulation, and machine learning. While researchers have
studied how easy VQAs are to train, the effect of quantum noise on the
classical optimisation process is still not well understood. Contrary to
expectations, we find that twirling, which is commonly used in standard
error-mitigation strategies to symmetrise noise, actually degrades performance
in the variational setting, whereas preserving biased or non-unital noise can
help classical optimisers find better solutions. Analytically, we study a
universal quantum regression model and demonstrate that relatively uniform
Pauli channels suppress gradient magnitudes and reduce expressivity, making
optimisation more difficult. Conversely, asymmetric noise such as amplitude
damping or biased Pauli channels introduces directional bias that can be
exploited during optimisation. Numerical experiments on a variational
eigensolver for the transverse-field Ising model confirm that non-unital noise
yields lower-energy states compared to twirled noise. Finally, we show that
coherent errors are fully mitigated by re-parameterisation. These findings
challenge conventional noise-mitigation strategies and suggest that preserving
noise biases may enhance VQA performance.

</details>


### [112] [Exploring the Fidelity of Flux Qubit Measurement in Different Bases via Quantum Flux Parametron](https://arxiv.org/abs/2510.24082)
*Yanjun Ji,Susanna Kirchhoff,Frank K. Wilhelm*

Main category: quant-ph

TL;DR: 本文研究了通过量子通量参量器介导的读取方案来提高通量量子比特测量保真度的方法，发现在单量子比特系统中能量基优于通量基，在两量子比特系统中顺序测量比同时测量能获得更稳健和更高的保真度。


<details>
  <summary>Details</summary>
Motivation: 高保真度的量子比特读取是实用量子计算系统的基本要求，需要研究如何通过量子通量参量器介导的读取方案来提高通量量子比特的测量保真度。

Method: 通过理论建模和数值模拟，分析不同测量基对单量子比特和耦合两量子比特系统保真度的影响，比较顺序测量和同时测量两种模型。

Result: 在单量子比特系统中，能量基始终比通量基获得更高保真度；在两量子比特系统中，顺序测量在较长时间内使用修饰基或同时测量在较短时间内使用裸基都能获得最高保真度，但顺序测量模型始终能产生更稳健和更高的保真度读取。

Conclusion: 这些发现量化了可实现的保真度，为新兴量子计算架构中优化测量协议提供了有价值的指导。

Abstract: High-fidelity qubit readout is a fundamental requirement for practical
quantum computing systems. In this work, we investigate methods to enhance the
measurement fidelity of flux qubits via a quantum flux parametron-mediated
readout scheme. Through theoretical modeling and numerical simulations, we
analyze the impact of different measurement bases on fidelity in single-qubit
and coupled two-qubit systems. For single-qubit systems, we show that energy
bases consistently outperform flux bases in achieving higher fidelity. In
coupled two-qubit systems, we explore two measurement models: sequential and
simultaneous measurements, both aimed at reading out a single target qubit. Our
results indicate that the highest fidelity can be achieved either by performing
sequential measurement in a dressed basis over a longer duration or by
conducting simultaneous measurement in a bare basis over a shorter duration.
Importantly, the sequential measurement model consistently yields more robust
and higher fidelity readouts compared to the simultaneous approach. These
findings quantify achievable fidelities and provide valuable guidance for
optimizing measurement protocols in emerging quantum computing architectures.

</details>


### [113] [Topological shaping of vortex neutron beams using forked phase gratings](https://arxiv.org/abs/2510.24099)
*S. McKay,S. R. Parnell,R. M. Dalgliesh,N. V. Lavrik,I. I. Kravchenko,Q. Le Thien,D. V. Baxter,G. Ortiz,R. Pynn*

Main category: quant-ph

TL;DR: 本研究使用自旋回波小角中子散射(SESANS)技术，通过叉形相位光栅产生了具有轨道角动量(OAM)的涡旋中子束，并验证了其拓扑电荷特性。


<details>
  <summary>Details</summary>
Motivation: 携带明确轨道角动量状态的光束或物质束是探测拓扑和纹理凝聚态物质系统（如磁性斯格明子）的有前途探针。

Method: 使用自旋回波小角中子散射(SESANS)技术，通过叉形相位光栅产生不同拓扑电荷的涡旋中子束。

Result: 成功产生了具有轨道角动量的涡旋中子束，SESANS技术能够精确测量中子的OAM，因为它是一种相位敏感的干涉技术，直接测量散射中子自旋态之间的相位。

Conclusion: SESANS技术相比之前的验证方法更精确，为研究拓扑材料系统提供了更可靠的测量手段。

Abstract: Beams of light or matter that carry well-defined states of orbital angular
momentum (OAM) are promising probes of topological and textured condensed
matter systems such as magnetic skyrmions. Using spin-echo small-angle neutron
scattering (SESANS), we demonstrate the production of vortex neutron beams from
forked phase gratings of various topological charges. In contrast to some
previous techniques used to verify OAM production, SESANS is a more precise
measurement of the neutron's OAM as it is a phase-sensitive, interferometric
technique that directly measures the phase between the scattered neutron spin
states.

</details>


### [114] [Separability Criteria of Quantum States based on Generalized Bloch Representation](https://arxiv.org/abs/2510.24110)
*Linwei Li,Hongmei Yao,Chunlin Yang,Shaoming Fei*

Main category: quant-ph

TL;DR: 该论文提出了一个用于检测量子系统纠缠的综合性可分离性判据框架，从双体系统扩展到多体系统。通过构建参数化扩展相关张量并开发混合模式矩阵展开技术，实现了对纠缠检测能力的提升。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠是量子信息理论中的基本资源，但现有的纠缠检测方法在从双体系统扩展到多体系统时存在局限性，需要开发更通用的框架来有效检测各类量子系统的纠缠特性。

Method: 1. 构建了基于任意正交基下广义Bloch表示的统一参数化扩展相关张量；2. 开发了混合模式矩阵展开技术，将传统的k-模式矩阵展开推广到多体系统；3. 推导了多体系统的多个可分离性判据。

Result: 数值实验表明，所提出的可分离性判据在检测纠缠方面表现出增强的能力，能够更有效地识别量子系统中的纠缠特性。

Conclusion: 该研究建立了一个统一的框架，成功地将双体系统的纠缠检测方法推广到多体系统，通过创新的张量构造和展开技术，显著提升了纠缠检测的效能，为量子信息处理提供了更强大的工具。

Abstract: Quantum entanglement serves as a fundamental resource in quantum information
theory. This paper presents a comprehensive framework of separability criteria
for detecting entanglement across quantum systems, from bipartite to
multipartite states. We propose a novel unified parameterized extended
correlation tensor, constructed via the generalized Bloch representation under
an arbitrary orthogonal basis, which bridges our bipartite criterion with
several existing ones. Moreover, we develop a specialized tensor unfolding
technique -- termed mixed mode matrix unfolding -- that naturally generalizes
the conventional $k$-mode matrix unfolding and enables the generalization of
the extended correlation tensor construction to multipartite systems. And we
derive several separability criteria for multipartite states. Numerical
examples demonstrate that our separability criteria exhibit enhanced capability
in detecting entanglement.

</details>


### [115] [Matrix product state approach to lossy boson sampling and noisy IQP sampling](https://arxiv.org/abs/2510.24137)
*Sojeong Park,Changhun Oh*

Main category: quant-ph

TL;DR: 本文扩展了基于矩阵乘积态（MPS）的经典模拟框架，研究了含噪声量子采样模型（包括损失性玻色子采样和含噪声IQP采样）的经典可模拟性，通过可调节的键维度提供精度控制，系统探索量子难解与经典可模拟之间的边界。


<details>
  <summary>Details</summary>
Motivation: 采样问题已成为展示量子优势的核心途径，但物理噪声会改变其计算复杂性。受近期MPS成功模拟高斯玻色子采样的启发，希望将此框架扩展到其他含噪声量子采样模型的研究。

Method: 开发基于MPS的经典算法，构建含噪声或损失输入态的纯态分解，其分量在电路演化后保持弱纠缠，通过键维度实现可调节精度。

Result: 对于玻色子采样，在传输率为O(1/√N)时出现经典可模拟性，达到量子优势的已知边界；算法在精度-效率权衡方面提供显著改进控制，并将MPS模拟扩展到更广泛的含噪声量子采样模型。

Conclusion: MPS方法为系统探索量子难解与经典可模拟边界提供了可调节且可扩展的手段，扩展了基于MPS的模拟在含噪声量子采样模型中的适用性。

Abstract: Sampling problems have emerged as a central avenue for demonstrating quantum
advantage on noisy intermediate-scale quantum devices. However, physical noise
can fundamentally alter their computational complexity, often making them
classically tractable. Motivated by the recent success of matrix product state
(MPS)-based classical simulation of Gaussian boson sampling (Oh et al., 2024),
we extend this framework to investigate the classical simulability of other
noisy quantum sampling models. We develop MPS-based classical algorithms for
lossy boson sampling and noisy instantaneous quantum polynomial-time (IQP)
sampling, both of which retain the tunable accuracy characteristic of the MPS
approach through the bond dimension. Our approach constructs pure-state
decompositions of noisy or lossy input states whose components remain weakly
entangled after circuit evolution, thereby providing a means to systematically
explore the boundary between quantum-hard and classically-simulable regimes.
For boson sampling, we analyze single-photon, Fock, and cat-state inputs,
showing that classical simulability emerges at transmission rates scaling as
$O(1/\sqrt{N})$, reaching the known boundary of quantum advantage with a
tunable and scalable method. Beyond reproducing previous thresholds, our
algorithm offers significantly improved control over the accuracy-efficiency
trade-off. It further extends the applicability of MPS-based simulation to
broader classes of noisy quantum sampling models, including IQP circuits.

</details>


### [116] [Quantum advantage bounds for a multipartite Gaussian battery](https://arxiv.org/abs/2510.24162)
*F. Cavaliere,D. Ferraro,M. Carrega,G. Benenti,M. Sassetti*

Main category: quant-ph

TL;DR: 本文通过分析量子电池模型，证明了量子优势在能量提取效率上的可能性，区分了经典压缩、无纠缠量子压缩和真正纠缠三种效率递增的机制。


<details>
  <summary>Details</summary>
Motivation: 为了在量子电池效率方面实现真正的量子优势，需要建立一个能够一致比较量子与经典机制的理论框架。

Method: 使用N个谐振子电池单元耦合到共同热库的模型，通过高斯态演化，定义全局效率为可提取功与存储能量的比值，并推导解析界限。

Result: 分析界限区分了三种效率递增的机制：经典压缩、无纠缠量子压缩和真正纠缠，数值模拟支持这种层次结构在热力学效率中的出现。

Conclusion: 量子电池在能量提取效率上存在真正的量子优势，且这种优势在热力学效率中同样显现。

Abstract: We demonstrate the possibility of a genuine quantum advantage in the
efficiency of quantum batteries by analyzing a model that enables a consistent
comparison between quantum and classical regimes. Our system consists of $N$
harmonic oscillator cells coupled to a common thermal reservoir, evolving
through Gaussian states. We define the global efficiency as the ratio of
extractable work (ergotropy) to stored energy, and derive analytical bounds
that distinguish, in order of increasing efficiency, regimes characterized by
classical squeezing, quantum squeezing without entanglement, and genuine
entanglement. Moreover, numerical simulations support the emergence of a
similar hierarchy for the thermodynamic efficiency, defined as the ratio
between ergotropy and the total thermodynamic cost of the charging process.

</details>


### [117] [Experimental Demonstration of the Timelike Unruh Effect with a Trapped-Ion System](https://arxiv.org/abs/2510.24163)
*Zhenghao Luo,Yi Li,Xingyu Zhao,Zihan Xie,Zehua Tian,Yiheng Lin*

Main category: quant-ph

TL;DR: 本文通过囚禁离子量子系统实验演示了类时Unruh效应，使用两能级自旋作为探测器，在无需极端加速度的条件下实现了类似Unruh效应的热响应。


<details>
  <summary>Details</summary>
Motivation: 直接观测Unruh效应需要极端加速度，超出当前实验能力。理论研究表明类时Unruh效应可在无加速度但时间依赖的探测器中出现，为实验室测试提供可能。

Method: 使用囚禁离子系统，其中两能级自旋作为探测器，与编码在离子振动运动中的环境场进行时间耦合。研究探测器在未来/过去光锥中沿时空轨迹的激发和发射动力学。

Result: 实验证明了探测器对Minkowski真空的热响应，这种响应与Unruh效应相似，验证了类时Unruh效应的存在。

Conclusion: 这项工作建立了一个可控的桌面平台，可在可访问的实验室条件下探索相对论量子物理。

Abstract: The Unruh effect predicts that an accelerated observer perceives the
Minkowski vacuum as a thermal bath, but its direct observation requires extreme
accelerations beyond current experimental reach. Foundational theory [Olson &
Ralph, Phys. Rev. Lett. 106, 110404 (2011)] shows that an equivalent thermal
response, known as the timelike Unruh effect, can occur for detectors following
specific timelike trajectories without acceleration, enabling laboratory tests
with stationary yet time-dependent detectors. Here, we report a
proof-of-principle demonstration of the timelike Unruh effect in a quantum
system of trapped ion, where a two-level spin serves as the detector and is
temporally coupled to the ambient field encoded in the ion's vibrational
motion. Specifically, we study both excitation and emission dynamics of the
detector moving along a spacetime trajectory in the future/past light cone, and
demonstrate the thermal response of the detector to the Minkowski vacuum that
resembles the Unruh effect. This work establishes a controllable tabletop
platform for exploring relativistic quantum physics under accessible laboratory
conditions.

</details>


### [118] [An exact Error Threshold of Surface Code under Correlated Nearest-Neighbor Errors: A Statistical Mechanical Analysis](https://arxiv.org/abs/2510.24181)
*SiYing Wang,ZhiXin Xia,Yue Yan,Xiang-Bin Wang*

Main category: quant-ph

TL;DR: 本文建立了误差-边缘映射方法，将量子纠错转化为方形-八边形随机键Ising模型，在结合独立单量子比特误差和最近邻数据量子比特相关误差的现实噪声模型下，给出了表面码的精确误差阈值。


<details>
  <summary>Details</summary>
Motivation: 现有表面码阈值分析基于独立同分布误差假设，而实际系统中存在相关误差。现有相关误差阈值研究仅为数值下界而非精确值，存在提高阈值的潜力。

Method: 建立误差-边缘映射，将量子纠错问题转化为方形-八边形随机键Ising模型，适用于任意最近邻相关误差与独立误差比例的情况。

Result: 获得了表面码在现实噪声模型下的精确误差阈值，该阈值既是上界又是可达值，意味着现有数值阈值均可改进至此值，且该值是理论上可达到的最高阈值。

Conclusion: 提出的方法能够确定表面码在包含相关误差的噪声模型下的精确误差阈值，为容错量子计算提供了更准确的阈值分析工具。

Abstract: The surface code represents a promising candidate for fault-tolerant quantum
computation due to its high error threshold and experimental accessibility with
nearest-neighbor interactions. However, current exact surface code threshold
analyses are based on the assumption of independent and identically distributed
(i.i.d.) errors. Though there are numerical studieds for threshold with
correlated error, they are only the lower bond ranther than exact value, this
offers potential for higher error thresholds.Here, we establish an error-edge
map, which allows for the mapping of quantum error correction to a
square-octagonal random bond Ising model. We then present the exact threshold
under a realistic noise model that combines independent single-qubit errors
with correlated errors between nearest-neighbor data qubits. Our method is
applicable for any ratio of nearest-neighbor correlated errors to i.i.d.
errors. We investigate the error correction threshold of surface codes and we
present analytical constraints giving exact value of error threshold. This
means that our error threshold is both upper bound and achievable and hence on
the one hand the existing numerical threshold values can all be improved to our
threshold value, on the other hand, our threshold value is highest achievable
value in principle.

</details>


### [119] [A Sub-kHz Mechanical Resonator Passively Cooled to 6 mK](https://arxiv.org/abs/2510.24199)
*Loek van Everdingen,Jaimy Plugge,Tim Fuchs,Guido van de Stolpe,Dalal Benali,Thijmen de Jong,Jasper Bijl,Wim Bosch,Tjerk Oosterkamp*

Main category: quant-ph

TL;DR: 通过核退磁方法将1.5纳克、700赫兹的机械悬臂梁被动冷却至6.1毫开尔文，验证了其热运动仍可被检测，为量子力学测试和超灵敏力检测开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 在更大尺度和质量上进行量子力学基础测试（如非经典态生成和波函数坍缩模型测试）需要高度相干的机械谐振器，在毫开尔文温度下研究这些谐振器可显著提高其相干时间。

Method: 采用核退磁方法被动冷却机械悬臂梁，并通过基于锁相放大器的检测方案检测其热运动。

Result: 成功将1.5纳克、700赫兹的机械悬臂梁冷却至6.1(4)毫开尔文，在最低温度下谐振器的热运动仍能清晰区分于背景噪声，数据分析确认运动仍呈热分布。

Conclusion: 这些结果为将低频谐振器被动冷却至亚毫开尔文区域铺平了道路，将促进量子力学新测试和超灵敏力检测技术的发展。

Abstract: Fundamental tests of quantum mechanics, such as the generation of
non-classical states and tests of wavefunction collapse models, are performed
on increasingly larger size and mass scales. Highly coherent mechanical
resonators, which also prove invaluable in ultrasensitive microscopy methods,
are essential tools towards these efforts. Studying these resonators in a
thermal equilibrium state at millikelvin temperatures provides a promising path
to increase their coherence time. Here, we passively cool a 700 Hz, massive
(1.5 ng) mechanical cantilever down to 6.1(4)mK by means of nuclear
demagnetization, as confirmed by detecting its thermal motion via a lock-in
based detection scheme. At the lowest temperatures the thermal motion of the
resonator is still clearly distinguishable from the background noise. Our data
analysis confirms that at these temperatures the motion is still thermally
distributed. These results pave the way for passiveof cooling low-frequency
resonators to the sub-milllikelvin regime, which would enable new tests of
quantum mechanics and advances in ultrasensitive force detection.

</details>


### [120] [Equivalence of Discrete and Continuous Otto-Like Engines assisted by Catalysts: Mapping Catalytic Advantages from the Discrete to the Continuous Framework](https://arxiv.org/abs/2510.24253)
*Marcin Łobejko,Tanmoy Biswas,Michał Horodecki*

Main category: quant-ph

TL;DR: 该论文建立了离散和连续热机之间的等价关系，通过将离散的酉过程和热化步骤映射到相互作用哈密顿量和马尔可夫耗散模型，构建了对应的连续机器，并展示了催化增强效应在连续体系中的实现。


<details>
  <summary>Details</summary>
Motivation: 离散热机理论模型易于分析但实验实现困难，而连续热机更易于实验实现。研究旨在建立离散与连续热机之间的等价关系，将已证明的催化方案扩展到连续体系。

Method: 通过将离散酉过程和热化步骤映射到相互作用哈密顿量和马尔可夫耗散模型，用概率流替换概率电流，构建与离散催化方案对应的连续机器。

Result: 成功建立了离散与连续热机之间的等价映射，并在最简单的奥托引擎催化扩展中展示了连续体系中的催化增强效应。

Conclusion: 该研究为催化热机的实验实现提供了可行途径，通过连续体系实现了离散催化方案的性能提升，推动了热机理论向实验应用的转化。

Abstract: The catalytic extension of a discrete two-stroke engine employs a cyclic
auxiliary system - the catalyst - that remains decoupled from the baths and
performs no work, yet enhances power and efficiency beyond the corresponding
non-catalytic counterpart. Theoretical models of discrete engines are
relatively easy to analyze but remain challenging for experimental
implementation due to the required control over individual strokes. In
contrast, externally driven engines that are simultaneously coupled to both
heat baths - the so-called continuous engines - are more experimentally
feasible. Here, we establish an equivalence between discrete and continuous
machines, both with and without a catalyst, by mapping the discrete unitary
processes and thermalization steps onto an interaction Hamiltonian and a
Markovian model of dissipation. As a result, by replacing probability flows
with probability currents, we construct an analogous continuous machine
corresponding to previously demonstrated catalytic schemes that generalize Otto
engines. We illustrate this mapping for the simplest catalytic extension of the
Otto engine, demonstrating catalytic enhancement in the continuous regime.

</details>


### [121] [Quantum evolution with classical fields](https://arxiv.org/abs/2510.24275)
*Christof Wetterich*

Main category: quant-ph

TL;DR: 该论文提出了一种基于波导的量子计算实现方法，使用经典电磁场的波导来模拟量子比特系统的波函数演化。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算的新实现方式，通过经典电磁场波导系统来模拟量子演化，为量子力学基础提供新的视角。

Method: 利用波导中的相移、开关和分束器等光学元件构建任意量子门，波导通道代表多量子比特系统的基态而非单个量子比特。

Result: 开发了一种基于关联的光子量子计算机架构，能够同时对大量量子比特进行操作。

Conclusion: 经典概率性实现量子演化为量子力学基础研究提供了新的见解，展示了经典系统模拟量子行为的可能性。

Abstract: Wave guides for classical electromagnetic fields can realize the quantum
evolution of the wave function for a system of qubits.
  Phase shifts, switches and beam splits allow for the construction of
arbitrary quantum gates.
  They can act at once on a large number of qubits.
  For this correlation based photonic quantum computer the channels of the wave
guides represent basis states of a multi-qubit system rather than individual
qubits.
  The classical probabilistic implementation of a quantum evolution sheds new
light on the foundations of quantum mechanics.

</details>


### [122] [Jacobi-Anger Density Estimation for Energy Distribution of Quantum States](https://arxiv.org/abs/2510.24316)
*Kyeongan Park,Gwonhak Lee,Minhyeok Kang,Youngjun Park,Joonsuk Huh*

Main category: quant-ph

TL;DR: JADE是一种非参数量子启发方法，通过雅可比-安格尔展开从有限哈密顿矩重建特征函数，再通过逆傅里叶变换估计能量分布，解决了从有限矩准确重建能量分布的挑战。


<details>
  <summary>Details</summary>
Motivation: 量子态的能量分布对准确估计分子基态能量至关重要，但直接获取需要完全哈密顿对角化，计算成本过高。从有限哈密顿矩近似分布更实用，但准确重建分布仍面临重大挑战。

Method: 提出JADE方法：使用雅可比-安格尔展开从有限矩重建特征函数，然后通过逆傅里叶变换估计底层分布。这是一种非参数、量子启发的方法。

Result: JADE能准确恢复分子系统中量子态的能量分布，且证明在量子化学以外的各种科学和工程领域也适用于复杂概率密度函数的估计。

Conclusion: JADE是一个强大且多功能的实用量子系统工具，有潜力显著增强基态能量估计及相关应用。

Abstract: The energy distribution of a quantum state is essential for accurately
estimating a molecule's ground state energy in quantum computing. Directly
obtaining this distribution requires full Hamiltonian diagonalization, which is
computationally prohibitive for large-scale systems. A more practical strategy
is to approximate the distribution from a finite set of Hamiltonian moments.
However, reconstructing an accurate distribution from only a limited number of
moments remains a significant challenge. In this work, we introduce
Jacobi-Anger Density Estimation (JADE), a non-parametric, quantum-inspired
method designed to overcome this difficulty. JADE reconstructs the
characteristic function from a finite set of moments using the Jacobi-Anger
expansion and then estimates the underlying distribution via an inverse Fourier
transform. We demonstrate that JADE can accurately recover the energy
distribution of a quantum state for a molecular system. Beyond quantum
chemistry, we also show that JADE is broadly applicable to the estimation of
complicated probability density functions in various other scientific and
engineering fields. Our results highlight JADE as a powerful and versatile tool
for practical quantum systems, with the potential to significantly enhance
ground state energy estimation and related applications.

</details>


### [123] [Optimizing Quantum Compilation via High-Level Quantum Instructions](https://arxiv.org/abs/2510.24323)
*Evandro C. R. Rosa,Jerusa Marchi,Eduardo I. Duzzioni,Rafael de Santiago*

Main category: quant-ph

TL;DR: 本文提出了一种高级量子编程构造，通过提供语义信息使编译器能够进行高级优化，包括自动用更高效的近似分解替换量子门，以及保证辅助量子位的正确反计算，实现动态量子内存管理。


<details>
  <summary>Details</summary>
Motivation: 当前量子编程主要采用低级的电路中心方法，限制了编译器优化的潜力。需要高级编程构造来提供语义信息，以支持更强大的编译器优化。

Method: 引入量子特定指令，自动将量子门替换为更高效的近似分解，并保证辅助量子位的正确反计算。通过实现多控制NOT门的V链分解来验证方法。

Result: 高级方法不仅简化了代码，还使编译器生成的电路CNOT门数量减少了高达50%。

Conclusion: 高级抽象对于解锁强大的编译器优化类别至关重要，为更高效的量子计算铺平了道路。

Abstract: Current quantum programming is dominated by low-level, circuit-centric
approaches that limit the potential for compiler optimization. This work
presents how a high-level programming construct provides compilers with the
semantic information needed for advanced optimizations. We introduce a novel
optimization that leverages a quantum-specific instruction to automatically
substitute quantum gates with more efficient, approximate decompositions, a
process that is transparent to the programmer and significantly reduces quantum
resource requirements. Furthermore, we show how this instruction guarantees the
correct uncomputation of auxiliary qubits, enabling safe, dynamic quantum
memory management. We illustrate these concepts by implementing a V-chain
decomposition of the multi-controlled NOT gate, showing that our high-level
approach not only simplifies the code but also enables the compiler to generate
a circuit with up to a 50% reduction in CNOT gates. Our results suggest that
high-level abstractions are crucial for unlocking a new class of powerful
compiler optimizations, paving the way for more efficient quantum computation.

</details>


### [124] [Mind, Matter, and Freedom in Quantum Mechanics and the de Broglie-Bohm Theory](https://arxiv.org/abs/2510.24327)
*Valia Allori*

Main category: quant-ph

TL;DR: 本文认为量子力学并不必然支持对决定论、自由意志、心身问题、唯心主义和还原论的特定哲学立场，通过采用德布罗意-玻姆理论（玻姆力学）可以解释量子现象而无需接受这些哲学主张。


<details>
  <summary>Details</summary>
Motivation: 探讨量子力学对几个重要哲学问题（决定论、自由意志、心身问题、唯心主义、还原论）的所谓贡献，并质疑这些哲学解释的必要性和可取性。

Method: 采用德布罗意-玻姆理论（玻姆力学）作为分析框架，展示该理论如何能够解释量子现象而不需要接受特定的哲学主张。

Result: 证明通过玻姆力学可以解释量子现象，同时避免对决定论、自由意志、心身问题、唯心主义和还原论做出特定的哲学承诺。

Conclusion: 量子力学并不必然要求接受特定的哲学立场，玻姆力学提供了一个既能解释量子现象又保持哲学中立性的替代方案。

Abstract: There are several important philosophical problems to which quantum mechanics
is often said to have made significant contributions:
  - Determinism: quantum theory has been taken to refute determinism;
  -Free Will: in turn, this is thought to open the door to free will;
  - The mind-body problem: relatedly, it is sometimes said to shed light on
consciousness;
  - Idealism: more radically, quantum theory is assumed to have refuted realism
and to have placed the observer at the center of the world;
  - Reductionism: even granting realism, it has been claimed that quantum
theory undermines reductionism.
  Our main thesis in this paper is that none of this is either necessary or
desirable. By adopting the de Broglie--Bohm theory (or Bohmian mechanics), one
can straightforwardly account for quantum phenomena without endorsing any of
these claims.

</details>


### [125] [Tight Generalization Bound for Supervised Quantum Machine Learning](https://arxiv.org/abs/2510.24348)
*Xin Wang,Rebing Wu*

Main category: quant-ph

TL;DR: 本文推导了一个适用于广泛监督任务、数据和模型的量子机器学习紧致泛化界，该界可高效计算且不含大O符号。研究表明样本量是影响泛化误差的最主要因素，而量子门数量、量子比特数等参数对泛化能力影响不大。


<details>
  <summary>Details</summary>
Motivation: 先前基于大O符号的泛化界可能对泛化误差提供误导性建议，需要建立一个更准确、可计算的泛化界来澄清量子机器学习中的泛化问题。

Method: 推导了一个紧致的泛化界，适用于任意规模和深度的量子机器学习模型，并通过实验验证其紧致性，包括分类、回归任务以及标签随机化的情况。

Result: 实验证明该泛化界在分类和回归任务中都具有紧致性，即使在标签完全随机化的情况下也成立。样本量是主导泛化误差的关键因素。

Conclusion: 该研究为量子机器学习中的泛化问题提供了清晰的理论基础，表明样本量是影响泛化能力的最重要因素，而模型复杂度和超参数选择的影响相对较小。

Abstract: We derive a tight generalization bound for quantum machine learning that is
applicable to a wide range of supervised tasks, data, and models. Our bound is
both efficiently computable and free of big-O notation. Furthermore, we point
out that previous bounds relying on big-O notation may provide misleading
suggestions regarding the generalization error. Our generalization bound
demonstrates that for quantum machine learning models of arbitrary size and
depth, the sample size is the most dominant factor governing the generalization
error. Additionally, the spectral norm of the measurement observable, the bound
and Lipschitz constant of the selected risk function also influence the
generalization upper bound. However, the number of quantum gates, the number of
qubits, data encoding methods, and hyperparameters chosen during the learning
process such as batch size, epochs, learning rate, and optimizer do not
significantly impact the generalization capability of quantum machine learning.
We experimentally demonstrate the tightness of our generalization bound across
classification and regression tasks. Furthermore, we show that our tight
generalization upper bound holds even when labels are completely randomized. We
thus bring clarity to the fundamental question of generalization in quantum
machine learning.

</details>


### [126] [Fundamental limit on the heralded single photons' spectral brightness](https://arxiv.org/abs/2510.24439)
*Tse-Yu Lin,Wei-Kai Huang,Pei-Yu Tu,Yong-Fan Chen,Ite A. Yu*

Main category: quant-ph

TL;DR: 该研究探讨了预示单光子(HSP)的谱亮度(SB)是否存在极限，并定义了质量因子来评估HSP源接近理想无噪声源的程度。使用热原子蒸汽HSP源，实现了迄今最高的SB值(7.0±0.3)×10^5对/秒/MHz和质量因子0.68±0.02。


<details>
  <summary>Details</summary>
Motivation: 研究HSP的谱亮度是否存在极限，因为量子信息处理中既需要高生成率又需要窄线宽，而谱亮度定义为生成率与线宽的比值。

Method: 系统研究谱亮度和交叉相关函数(信噪比)，定义了质量因子来衡量HSP源接近理想无噪声源的程度，并采用基于热原子蒸汽的HSP源进行实验验证。

Result: 使用热原子蒸汽HSP源实现了(7.0±0.3)×10^5对/秒/MHz的谱亮度和0.68±0.02的质量因子，这是迄今所有类型HSP源中的最高记录。

Conclusion: 研究结果表明谱亮度存在极限，新定义的质量因子能够有效评估HSP源的性能，热原子蒸汽HSP源在单光子标准下达到了迄今最佳性能。

Abstract: The heralded single photons' (HSPs) spectral brightness (SB) is defined as
the generation rate per linewidth. As the generation rate of HSPs gets larger
or the photons' linewidth becomes narrower, both of which are desirable in
quantum information processing using HSPs, does the SB have a limit? We
systematically studied the SB and the cross-correlation function, or
equivalently, the signal-to-background ratio. The results in this study provide
an answer applicable to all types of HSP sources. The answer relies on a newly
defined quantity, the quality factor, which reveals how a HSP source approaches
the ideal noise-free one. Furthermore, employing the HSP source based on hot
atomic vapor, we achieved an SB of (7.0$\pm$0.3)$\times10^5$ pairs/s/MHz and a
quality factor of 0.68$\pm$0.02 under the single-photon criterion. Both values
are the highest records to date among all kinds of HSP sources.

</details>


### [127] [Comparing physical quantities with finite-precision: beyond standard metrology and an illustration for cooling in quantum processes](https://arxiv.org/abs/2510.24484)
*Anindita Sarkar,Paranjoy Chaki,Priya Ghosh,Ujjwal Sen*

Main category: quant-ph

TL;DR: 提出了一个在有限精度场景下比较物理量值的通用框架，通过百分位数确定概率分布的区间范围，并应用于三量子比特量子制冷机的有限精度冷却分析。


<details>
  <summary>Details</summary>
Motivation: 在有限精度测量中，需要比较实数轴上的两个区间而非单个数值，传统基于标准差的方法无法处理非对称误差分布，因此需要更通用的比较框架。

Method: 利用估计量概率分布的百分位数概念来确定区间范围，应用于三量子比特量子制冷机的马尔可夫动力学模型，分析瞬态和稳态下的冷却效果。

Result: 在强耦合和弱耦合极限下，均证明了有限精度冷却在瞬态和稳态区域的发生。

Conclusion: 所提出的基于百分位数的框架为有限精度场景下的物理量比较提供了通用方法，成功应用于量子制冷系统的冷却分析。

Abstract: We propose a general framework to compare the values of a physical quantity
pertaining to two - or more - physical setups, in the finite-precision
scenario. Such a situation requires us to compare between two "patches" on the
real line instead of two numbers. Identification of extent of the patches is
typically done via standard deviation, as obtained within usual quantum
metrological considerations, but can not be always applied, especially for
asymmetric error distributions. The extent can however be universally
determined by utilizing the concept of percentiles of the probability
distribution of the corresponding estimator. As an application, we introduce
the concept of finite-precision cooling in a generic quantum system. We use
this approach in the working of a three-qubit quantum refrigerator governed by
Markovian dynamics, and demonstrate the occurrence of cooling within finite
precision for both transient and steady-state regimes, across strong- and
weak-coupling limits of the inter-qubit interaction.

</details>


### [128] [Quantum Combinatorial Reasoning for Large Language Models](https://arxiv.org/abs/2510.24509)
*Carlos Flores-Garrigos,Gaurav Dev,Michael Falkenthal,Alejandro Gomez Cadavid,Anton Simen,Shubham Kumar,Enrique Solano,Narendra N. Hegade*

Main category: quant-ph

TL;DR: 提出了量子组合推理框架QCR-LLM，将推理聚合重新表述为高阶无约束二进制优化问题，通过经典模拟退火和量子BF-DCQO优化器在IBM量子处理器上执行，在BBEH基准测试中显著提升推理准确率并提高能效。


<details>
  <summary>Details</summary>
Motivation: 开发量子辅助推理方法，通过量子-经典混合优化增强大规模语言模型的推理一致性、可解释性和可持续性，探索量子智能的潜力。

Method: 将推理聚合重新表述为高阶无约束二进制优化问题，推理片段表示为二进制变量，通过模拟退火和量子BF-DCQO优化器在IBM量子处理器上求解。

Result: 在BBEH基准测试中，QCR-LLM显著提升了多个LLM骨干的推理准确率，比推理原生系统如o3-high和DeepSeek R1高出最多9个百分点，同时能效比o3-high高约5倍。

Conclusion: 这是量子辅助推理的首个实验证据，表明混合量子-经典优化能有效增强大规模语言模型的推理能力，为量子智能的出现打开了大门。

Abstract: We design and implement a quantum combinatorial reasoning framework for large
language models (QCR-LLM), integrating a real quantum computer in the hybrid
workflow. QCR-LLM reformulates reasoning aggregation as a higher-order
unconstrained binary optimization (HUBO) problem. In this sense, reasoning
fragments are represented as binary variables and their interactions encode
statistical relevance, logical coherence, and semantic redundancy. We tackle
the resulting high-order optimization problem both classically, via simulated
annealing, and quantumly through the bias-field digitized counterdiabatic
quantum optimizer (BF-DCQO) executed on IBM's superconducting digital quantum
processors. Experiments on BIG-Bench Extra Hard (BBEH) benchmarks demonstrate
that our QCR-LLM consistently improves reasoning accuracy across multiple LLM
backbones, surpassing reasoning-native systems such as o3-high and DeepSeek R1
by up to $+9\,$pp. Despite requiring multiple reasoning samples per query, our
QCR-LLM remains approximately five times more energy-efficient than o3-high,
owing to the low per-token energy footprint of its GPT-4o backbone. These
results constitute the first experimental evidence of quantum-assisted
reasoning, showing that hybrid quantum-classical optimization can efficiently
enhance reasoning coherence, interpretability, and sustainability in
large-scale language models. We have opened the doors to the emergence of
quantum intelligence, where harder prompts require quantum optimizers at
quantum-advantage level.

</details>


### [129] [A No-Go Theorem for Shaping Quantum Resources](https://arxiv.org/abs/2510.24572)
*Samuel Alperin*

Main category: quant-ph

TL;DR: 该论文证明了在平滑哈密顿动力学下，无法独立控制连续变量量子态的高阶统计矩，只有二次哈密顿量才能保持矩层次结构的解耦。


<details>
  <summary>Details</summary>
Motivation: 研究能否独立控制连续变量量子态的高阶统计矩，这对于量子通信、计算和计量学具有重要意义。

Method: 通过分析无限维哈密顿向量场代数，证明在平滑哈密顿动力学下，只有二次生成元（辛代数）能保持矩层次结构的解耦。

Result: 发现任何平滑的非二次哈密顿量都会引入三阶及以上导数，强制耦合高斯和非高斯部分，证明了矩层次结构的刚性。

Conclusion: 该结果推广了高斯不可行定理，并确定了辛（克利福德）动力学与超越Gottesman-Knill极限的非可模拟区域之间的解析边界。

Abstract: The ability to independently control higher-order statistical moments of
continuous-variable quantum states would allow the direct ``shaping'' of
non-Gaussian resources, with wide implications for quantum communication,
computation, and metrology. Here we prove that such control is fundamentally
impossible under any smooth Hamiltonian dynamics. Within the full
infinite-dimensional algebra of Hamiltonian vector fields on phase space, the
quadratic (symplectic) subalgebra $\mathfrak{sp}(2N,\mathbb R)$ -- and, in the
single-mode case, its $\mathrm{SU}(1,1)$ representation -- is the unique
hierarchy-preserving structure: only quadratic generators produce differential
operators that terminate at second order and thereby decouple first and second
moments from higher cumulants. Any smooth non-quadratic Hamiltonian introduces
third- and higher-order derivatives in the phase-space generator, enforcing a
universal coupling between the Gaussian and non-Gaussian sectors. This
\emph{rigidity of the moment hierarchy} generalizes the Gaussian no-go theorems
and identifies the analytic boundary between symplectic (Clifford) dynamics and
the non-simulable regime beyond the Gottesman--Knill limit.

</details>


### [130] [Efficient magic state cultivation with lattice surgery](https://arxiv.org/abs/2510.24615)
*Yutaka Hirano,Riki Toshio,Tomohiro Itogawa,Keisuke Fujii*

Main category: quant-ph

TL;DR: 提出了一种基于培养的高效魔术态蒸馏协议，兼容方形网格连接，通过避免嫁接码降低空间开销，利用码扩展和早期拒绝进一步降低平均时空开销。


<details>
  <summary>Details</summary>
Motivation: 魔术态蒸馏是容错量子计算的关键瓶颈。物理级蒸馏相比逻辑级蒸馏能显著降低开销，但现有魔术态培养协议依赖复杂的嫁接码，导致高时空开销和实现困难。

Method: 提出兼容方形网格连接的培养协议，避免使用嫁接码以减少空间开销，采用码扩展和早期拒绝机制降低平均时空开销。

Result: 数值模拟显示，在颜色码距离为3、物理错误概率为10^-3时，该协议获得的魔术态逻辑错误概率与魔术态培养相当（约3×10^-6），但时空开销减少约一半。

Conclusion: 该工作提供了一种高效简单的蒸馏协议，适用于大规模量子计算用例和早期容错设备。

Abstract: Magic state distillation plays a crucial role in fault-tolerant quantum
computation and represents a major bottleneck. In contrast to traditional
logical-level distillation, physical-level distillation offers significant
overhead reduction by enabling direct implementation with physical gates. Magic
state cultivation is a state-of-the-art physical-level distillation protocol
that is compatible with the square-grid connectivity and yields high-fidelity
magic states. However, it relies on the complex grafted code, which incurs
substantial spacetime overhead and complicates practical implementation. In
this work, we propose an efficient cultivation-based protocol compatible with
the square-grid connectivity. We reduce the spatial overhead by avoiding the
grafted code and further reduce the average spacetime overhead by utilizing
code expansion and enabling early rejection. Numerical simulations show that,
with a color code distance of 3 and a physical error probability of $10^{-3}$,
our protocol achieves a logical error probability for the resulting magic state
comparable to that of magic state cultivation ($\approx 3 \times 10^{-6}$),
while requiring about half the spacetime overhead. Our work provides an
efficient and simple distillation protocol suitable for megaquop use cases and
early fault-tolerant devices.

</details>


### [131] [Renormalization-group-based preparation of matrix product states on up to 80 qubits](https://arxiv.org/abs/2510.24681)
*Moritz Scheer,Alberto Baiardi,Elisa Bäumer Marty,Zhi-Yuan Wei,Daniel Malz*

Main category: quant-ph

TL;DR: 本文展示了在超导量子硬件上使用基于重整化群(RG)的量子算法制备矩阵乘积态(MPS)，相比顺序生成方法，RG协议在系统规模扩大时电路深度指数级更浅，对噪声更具鲁棒性，在大系统中表现更优。


<details>
  <summary>Details</summary>
Motivation: 量子计算机面临的关键挑战是如何高效制备多体纠缠态。本文旨在探索基于RG的量子算法在制备MPS方面的优势，特别是对于大规模系统。

Method: 使用基于重整化群的量子算法在超导量子硬件上制备矩阵乘积态，并将其与顺序生成方法进行比较。实验针对最多80个量子比特的系统，制备了在对称保护拓扑相和普通相之间发生相变的MPS。

Result: RG基电路由于深度较浅对噪声更具鲁棒性，在大系统中普遍优于顺序电路。通过测量类弦序局部期望值和能量密度验证了这一点。

Conclusion: RG基协议能够实现大规模MPS的制备，特别是超越固定点的对称保护拓扑有序态，为量子计算中的态制备提供了有效方法。

Abstract: A key challenge for quantum computers is the efficient preparation of
many-body entangled states across many qubits. In this work, we demonstrate the
preparation of matrix product states (MPS) using a
renormalization-group(RG)-based quantum algorithm on superconducting quantum
hardware. Compared to sequential generation, it has been shown that the
RG-based protocol asymptotically prepares short-range correlated MPS with an
exponentially shallower circuit depth (when scaling system size), but it is not
yet clear for which system sizes it starts to convey an advantage. We thus
apply this algorithm to prepare a class of MPS exhibiting a phase transition
between a symmetry-protected topological (SPT) and a trivial phase for systems
of up to 80 qubits. We find that the reduced depth of the RG-based circuits
makes them more resilient to noise, and that they generally outperform the
sequential circuits for large systems, as we showcase by measuring
string-order-like local expectation values and energy densities. We thus
demonstrate that the RG-based protocol enables large-scale preparation of MPS
and, in particular, SPT-ordered states beyond the fixed point.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [132] [Free-Fermion Measurement-Induced Volume- to Area-Law Entanglement Transition in the Presence of Fermion Interactions](https://arxiv.org/abs/2510.23706)
*Matthew S. Foster,Haoyu Guo,Chao-Ming Jian,Andreas W. W. Ludwig*

Main category: cond-mat.stat-mech

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: At a generic volume- to area-law entanglement transition in a many-body
system, quantum chaos is arrested. We argue that this tends to imply the
vanishing of a certain "mass" term in the field theory of the
measurement-induced phase transition (MIPT) for monitored, interacting
fermions. To explore this idea, we consider the MIPT with no conserved
quantities that describes 1D monitored, interacting Majorana fermions in class
DIII. We conjecture that the MIPT is the noninteracting DIII one in this case;
the volume-law phase arises through the dangerously irrelevant mass. We propose
numerical tests of our conjecture and analytically identify a candidate
noninteracting critical point.

</details>


### [133] [Group word dynamics from local random matrix Hamiltonians and beyond](https://arxiv.org/abs/2510.23716)
*Klée Pollock,Jonathan D. Kroth,Jonathon Riddell,Thomas Iadecola*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究一维量子自旋链，其最近邻相互作用是平方为1的随机矩阵。通过自由概率理论，将多体量子动力学映射到无限Coxeter反射群Cayley图上的单粒子跃迁动力学，并发现能量密度的热化行为。修改群结构可能导致可积性。


<details>
  <summary>Details</summary>
Motivation: 研究随机矩阵相互作用的一维量子自旋链的多体量子动力学，探索从多体系统到单粒子动力学的映射关系，以及群结构对系统物理性质的影响。

Method: 使用自由概率理论建立映射，将多体量子动力学转化为无限Coxeter反射群Cayley图上的单粒子跃迁动力学，利用群的自动结构数值构造大有限簇的邻接矩阵。

Result: 计算得到高斯态密度和能量密度的两点函数，与一般局域哈密顿量的物理一致：高斯态密度和能量密度热化。修改群结构可能引入可积性。

Conclusion: 该研究将自由概率理论、双曲晶格量子力学以及一般和可积哈密顿动力学的物理联系起来，展示了群结构在决定量子系统动力学性质中的重要作用。

Abstract: We study one dimensional quantum spin chains whose nearest neighbor
interactions are random matrices that square to one. By employing free
probability theory, we establish a mapping from the many-body quantum dynamics
of energy density in the original chain to a single-particle hopping dynamics
when the local Hilbert space dimension is large. The hopping occurs on the
Cayley graph of an infinite Coxeter reflection group. Adjacency matrices on
large finite clusters of this Cayley graph can be constructed numerically by
leveraging the automatic structure of the group. The density of states and
two-point functions of the local energy density are approximately computed and
consistent with the physics of a generic local Hamiltonian: Gaussian density of
states and thermalization of energy density. We then ask what happens to the
physics if we modify the group on which the hopping dynamics occurs, and
conjecture that adding braid relations into the group leads to integrability.
Our results put into contact ideas in free probability theory, quantum
mechanics of hyperbolic lattices, and the physics of both generic and
integrable Hamiltonian dynamics.

</details>


### [134] [On distinguishability among cell-division models based on population and single-cell-level distributions](https://arxiv.org/abs/2510.24169)
*Vikas,Rahul Marathe,Anjan Roy*

Main category: cond-mat.stat-mech

TL;DR: 该论文展示了如何通过细胞分裂统计特性区分不同的细胞分裂模型（Timer、Sizer、Adder），并发现尽管不同模型具有不同的分裂规则和相关性模式，但群体水平的分布（如年龄、大小、添加大小分布）在不同模型间无法区分。


<details>
  <summary>Details</summary>
Motivation: 研究不同细胞分裂模型（Timer、Sizer、Adder）的区分方法，探索细胞分裂统计特性与生长模式之间的关系，以及群体水平分布在不同模型间的相似性。

Method: 通过分析单细胞水平的统计特性（如出生大小、分裂时间、分裂大小、分裂添加大小之间的相关性）来区分不同细胞分裂模型，并研究群体水平分布的相似性，使用理论预测、模拟验证和现有实验数据支持。

Result: 发现不同细胞分裂模型可以通过单细胞水平的统计特性和相关性模式进行区分；但群体水平的分布（年龄、大小、添加大小分布）在不同模型间无法区分，且这种不可区分性对生长速率的随机性具有鲁棒性。

Conclusion: 单细胞水平的统计特性可以有效区分不同细胞分裂模型和生长模式，但群体水平分布在不同模型间具有相似性，这为细胞分裂机制的研究提供了新的视角和方法。

Abstract: It is well known that the different cell-division models, such as Timer,
Sizer, and Adder, can be distinguished based on the correlations between
different single-cell-level quantities such as birth-size, division-time,
division-size, and division-added-size. Here, we show that other statistical
properties of these quantities can also be used to distinguish between them.
Additionally, the statistical relationships and different correlation patterns
can also differentiate between the different types of single-cell growth, such
as linear and exponential. Further, we demonstrate that various
population-level distributions, such as age, size, and added-size
distributions, are indistinguishable across different models of cell division
despite them having different division rules and correlation patterns.
Moreover, this indistinguishability is robust to stochasticity in growth rate
and holds for both exponential and linear growth. Finally, we show that our
theoretical predictions are corroborated by simulations and supported by
existing single-cell experimental data.

</details>


### [135] [Evaluating the Performance of Direct Higher-Order Formulations in Combinatorial Optimization Problems](https://arxiv.org/abs/2510.24237)
*Kazuki Ikeuchi,Yoshiki Matsuda,Shu Tanaka*

Main category: cond-mat.stat-mech

TL;DR: 本研究评估了直接使用高性能模拟退火优化求解器处理包含高阶项的优化问题的有效性，相比传统的二次无约束二进制优化求解器，在LABS问题和车辆路径问题上的测试表明，PUBO求解器能获得更优的解决方案质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于硬件限制，大多数Ising类型硬件只能处理线性或二次项的优化问题，高阶项问题需要进行阶次降低处理，这会增加变量数量和约束条件，可能降低解的质量。

Method: 使用高性能模拟退火优化求解器直接处理多项式无约束二进制优化问题，与传统的二次无约束二进制优化求解器在同一硬件平台上进行性能比较。

Result: PUBO求解器在LABS问题和车辆路径问题上的表现优于QUBO求解器，获得了更优的解决方案质量和稳定性，同时保持了相当的计算时间且无需阶次降低编译。

Conclusion: 直接处理高阶项在实用优化问题中具有潜在优势，PUBO方法能够提供更高质量的解决方案，而无需进行阶次降低处理。

Abstract: Ising machines, including quantum annealing machines, are promising
next-generation computers for combinatorial optimization problems. However, due
to hardware limitations, most Ising-type hardware can only solve objective
functions expressed in linear or quadratic terms of binary variables.
Therefore, problems with higher-order terms require an order-reduction process,
which increases the number of variables and constraints and may degrade
solution quality. In this study, we evaluate the effectiveness of directly
solving such problems without order reduction by using a high-performance
simulated annealing-based optimization solver capable of handling polynomial
unconstrained binary optimization (PUBO) formulations. We compare its
performance against a conventional quadratic unconstrained binary optimization
(QUBO) solver on the same hardware platform. As benchmarks, we use the low
autocorrelation binary sequence (LABS) problem and the vehicle routing problem
with distance balancing, both of which naturally include higher-order
interactions. Results show that the PUBO solver consistently achieves superior
solution quality and stability compared to its QUBO counterpart, while
maintaining comparable computational time and requiring no order-reduction
compilation indicating potential advantages of directly handling higher-order
terms in practical optimization problems.

</details>


### [136] [Dynamical typicality in classical lattice systems](https://arxiv.org/abs/2510.24521)
*Nicolas Nessi,Peter Reimann*

Main category: cond-mat.stat-mech

TL;DR: 对于具有连续变量的确定性经典晶格系统，研究表明当初始条件按统计独立分布采样时，绝大多数状态的宏观可观测量轨迹几乎相同，前提是局部扰动的影响随距离快速衰减。


<details>
  <summary>Details</summary>
Motivation: 研究确定性经典晶格系统中宏观观测量的典型行为，特别是在大系统规模下，验证统计独立初始条件下动力学轨迹的一致性。

Method: 利用测度集中理论提供大系统规模下偏离典型行为的严格界限，假设动力学中局部扰动的影响随距离快速衰减。

Result: 证明在统计独立初始条件下，绝大多数状态的宏观可观测量轨迹近似相同，并通过长程相互作用耦合转子系统的动力学模拟验证了理论结果。

Conclusion: 确定性经典晶格系统中，在统计独立初始条件和局部扰动快速衰减的假设下，宏观观测量的动力学轨迹对绝大多数状态是典型的。

Abstract: Considering deterministic classical lattice systems with continuous
variables, we show that, if the initial conditions are sampled according to a
probability distribution in which the dynamical variables are statistically
independent, the dynamical trajectory of any macroscopic observable is
approximately the same for the vast majority of the states in the sample. Our
proof relies on general concentration of measure results which provide tight
bounds for the deviation from typical behavior in the case of large system
sizes. The only condition that we assume for the dynamics is that the influence
of a local perturbation in the initial state decays sufficiently fast with
distance at any finite time. Our results are relevant, in particular, to
classical Hamiltonian systems on a lattice. We apply our general results to a
system of coupled rotors with long-range interactions, and report dynamical
simulations which verify our findings.

</details>


### [137] [Accelerated relaxation and Mpemba-like effect for operators in open quantum systems](https://arxiv.org/abs/2510.24630)
*Pitambar Bagui,Arijit Chatterjee,Bijay Kumar Agarwalla*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了开放量子系统中算子的量子Mpemba效应，提出了单调衰减的"修饰"距离来检测算子动力学中的Mpemba类效应，发现在单量子比特系统中只能实现加速弛豫，而在高维系统中会出现真正的Mpemba类效应。


<details>
  <summary>Details</summary>
Motivation: 由于算子在非保迹映射下演化，迹距离不再是单调衰减函数，无法可靠检测算子动力学中的Mpemba效应，需要寻找新的度量方法。

Method: 定义了单调衰减的"修饰"算子距离，建立了检测算子Mpemba类效应的通用框架，并将其应用于各种开放量子系统设置。

Result: 在单量子比特系统中只能实现加速弛豫，而在qutrit等高维系统中会出现真正的Mpemba类效应；在双量子点设置中，非局域非平衡算子（如电流）也存在Mpemba类效应。

Conclusion: 该研究不仅为理解非保迹动力学下Mpemba类效应的出现提供了基本见解，还为实验研究开辟了新途径，其中观测量的快速弛豫可能具有重要意义。

Abstract: Quantum Mpemba effect occurs when a quantum system, residing far away from
the steady state, relaxes faster than a relatively nearer state. We look for
the presence of this highly counterintuitive effect in the relaxation dynamics
of the operators within the open quantum system setting. Since the operators
evolve under a non-trace preserving map, the trace distance of an operator is
not a monotonically decaying function of time, unlike its quantum state
counterpart. Consequently, the trace distance can not serve as a reliable
measure for detecting the Mpemba effect in operator dynamics. We circumvent
this problem by defining a \textit{dressed} distance between operators that
decays monotonically with time, enabling a generalized framework to explore the
Mpemba-like effect for operators. Applying the formalism to various open
quantum system settings, we find that, interestingly, in the single qubit case,
only accelerated relaxation of operators is possible, while genuine Mpemba-like
effects emerge in higher-dimensional systems such as qutrits and beyond.
Furthermore, we demonstrate the existence of Mpemba-like effects in nonlocal,
non-equilibrium operators, such as current, in a double-quantum-dot setup. Our
results, besides offering fundamental insight about the occurrence of the
Mpemba-like effect under non-trace preserving dynamics, open avenues for new
experimental studies where quicker relaxation of observables could be of
significant interest.

</details>


### [138] [Memory-induced long-range order drag](https://arxiv.org/abs/2510.24712)
*Yuan-Hang Zhang,Chesson Sipling,Massimiliano Di Ventra*

Main category: cond-mat.stat-mech

TL;DR: 本文研究发现，即使下游层没有记忆功能，通过层间耦合，记忆诱导的长程有序可以从有记忆的第一层传播到无记忆的下游层，使下游层也能维持层内长程有序。


<details>
  <summary>Details</summary>
Motivation: 研究记忆诱导的长程有序（MILRO）是否能够在耦合系统中传播到没有自身记忆的系统中，探索集体活动在无记忆介质中的传播机制。

Method: 采用具有局部前馈耦合的自旋层堆叠模型，其中只有第一层包含记忆，下游层是无记忆的局部相互作用系统，通过分析论证和模拟验证MILRO的传播效应。

Result: 模拟和分析表明，MILRO确实能够跨越层传播，使得下游层即使没有记忆和长程相互作用，也能维持层内长程有序。

Conclusion: 这建立了一种简单而通用的机制，可以在无需精确调谐到临界点的情况下传播集体活动，对神经形态系统和大脑皮层层状信息流具有可测试的意义。

Abstract: Recent research has shown that memory, in the form of slow degrees of
freedom, can induce a phase of long-range order (LRO) in locally-coupled fast
degrees of freedom, producing power-law distributions of avalanches. In fact,
such memory-induced LRO (MILRO) arises in a wide range of physical systems.
Here, we show that MILRO can be transferred to coupled systems that have no
memory of their own. As an example, we consider a stack of layers of spins with
local feedforward couplings: only the first layer contains memory, while
downstream layers are memory-free and locally interacting. Analytical arguments
and simulations reveal that MILRO can indeed drag across the layers, enabling
downstream layers to sustain intra-layer LRO despite having neither memory nor
long-range interactions. This establishes a simple, yet generic mechanism for
propagating collective activity through media without fine tuning to
criticality, with testable implications for neuromorphic systems and laminar
information flow in the brain cortex.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [139] [Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents](https://arxiv.org/abs/2510.23691)
*Zihao Wang,Xujing Li,Yining Ye,Junjie Fang,Haoming Wang,Longxiang Liu,Shihao Liang,Junting Lu,Zhiyong Wu,Jiazhan Feng,Wanjun Zhong,Zili Li,Yu Wang,Yu Miao,Bo Zhou,Yuanfan Li,Hao Wang,Zhongkai Zhao,Faming Wu,Zhengxuan Jiang,Weihao Tan,Heyuan Yao,Shi Yan,Xiangyang Li,Yitao Liang,Yujia Qin,Guang Shi*

Main category: cs.AI

TL;DR: Game-TARS是一个通用游戏智能体，使用统一、可扩展的键盘鼠标动作空间进行训练，支持跨操作系统、网页和模拟游戏的大规模持续预训练。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够跨异构领域（包括操作系统、网页和模拟游戏）进行大规模持续预训练的通用游戏智能体，避免API或GUI方法的限制。

Method: 使用统一、可扩展的键盘鼠标动作空间，结合500B+ tokens的多模态数据进行预训练，采用衰减持续损失减少因果混淆，以及高效的稀疏思维策略平衡推理深度和推理成本。

Result: 在开放世界Minecraft任务中成功率比之前最佳模型提高约2倍，在未见过的网页3D游戏中接近人类新手水平，在FPS基准测试中超越GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet。

Conclusion: 简单、可扩展的动作表示结合大规模预训练为开发具有广泛计算机使用能力的通用智能体提供了有前景的路径。

Abstract: We present Game-TARS, a generalist game agent trained with a unified,
scalable action space anchored to human-aligned native keyboard-mouse inputs.
Unlike API- or GUI-based approaches, this paradigm enables large-scale
continual pre-training across heterogeneous domains, including OS, web, and
simulation games. Game-TARS is pre-trained on over 500B tokens with diverse
trajectories and multimodal data. Key techniques include a decaying continual
loss to reduce causal confusion and an efficient Sparse-Thinking strategy that
balances reasoning depth and inference cost. Experiments show that Game-TARS
achieves about 2 times the success rate over the previous sota model on
open-world Minecraft tasks, is close to the generality of fresh humans in
unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet
in FPS benchmarks. Scaling results on training-time and test-time confirm that
the unified action space sustains improvements when scaled to cross-game and
multimodal data. Our results demonstrate that simple, scalable action
representations combined with large-scale pre-training provide a promising path
toward generalist agents with broad computer-use abilities.

</details>


### [140] [AI and the Decentering of Disciplinary Creativity](https://arxiv.org/abs/2510.23734)
*Eamon Duede*

Main category: cs.AI

TL;DR: 本文探讨AI在科学问题解决中的作用，重点关注其对学科创造力的影响。通过区分创造性方法和创造性产品，引入学科创造力概念，并通过数学案例表明AI可能取代而非扩展学科创造力。


<details>
  <summary>Details</summary>
Motivation: 研究AI在科学问题解决中的角色，特别是其对学科创造力的潜在影响，旨在理解AI如何改变科学追求的价值。

Method: 基于创造力哲学理论，区分创造性方法和产品，引入学科创造力概念，并通过两个数学案例进行分析。

Result: 研究发现计算可以扩展学科创造力，但某些AI方法可能取代学科创造力，从而可能改变科学追求的价值。

Conclusion: AI在科学中的应用可能通过取代学科创造力而改变科学追求的价值，需要谨慎考虑AI对科学创造力的影响。

Abstract: This paper examines the role of artificial intelligence in scientific
problem-solving, with a focus on its implications for disciplinary creativity.
Drawing on recent work in the philosophy of creativity, I distinguish between
creative approaches and creative products, and introduce the concept of
disciplinary creativity -the creative application of discipline-specific
expertise to a valued problem within that field. Through two cases in
mathematics, I show that while computation can extend disciplinary creativity,
certain approaches involving AI can serve to displace it. This displacement has
the potential to alter (and, perhaps, diminish) the value of scientific
pursuit.

</details>


### [141] [Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability](https://arxiv.org/abs/2510.23744)
*Eline M. Bovy,Caleb Probine,Marnix Suilen,Ufuk Topcu,Nils Jansen*

Main category: cs.AI

TL;DR: 本文提出了多环境POMDP（ME-POMDP）和对抗信念POMDP（AB-POMDP）模型，用于处理具有离散模型不确定性的部分可观测马尔可夫决策过程，并开发了精确和近似算法来计算鲁棒策略。


<details>
  <summary>Details</summary>
Motivation: 当多个领域专家对问题建模存在分歧时，需要一种能够处理模型不确定性的框架，目标是找到一个在所有可能POMDP模型中都能表现良好的单一鲁棒策略。

Method: 将ME-POMDP推广到具有初始信念集合的AB-POMDP；证明任意ME-POMDP可以简化为仅在转移和奖励函数或仅在观测和奖励函数上变化的ME-POMDP；开发精确和近似（基于点）算法来计算鲁棒策略。

Result: 成功为标准POMDP基准测试的多环境扩展版本计算了策略，验证了所提方法的有效性。

Conclusion: ME-POMDP和AB-POMDP为处理模型不确定性提供了有效框架，所开发的算法能够计算在这些不确定环境中表现鲁棒的策略。

Abstract: Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete
model uncertainty. ME-POMDPs represent a finite set of POMDPs that share the
same state, action, and observation spaces, but may arbitrarily vary in their
transition, observation, and reward models. Such models arise, for instance,
when multiple domain experts disagree on how to model a problem. The goal is to
find a single policy that is robust against any choice of POMDP within the set,
i.e., a policy that maximizes the worst-case reward across all POMDPs. We
generalize and expand on existing work in the following way. First, we show
that ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which
we call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any
arbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its
transition and reward functions or only in its observation and reward
functions, while preserving (optimal) policies. We then devise exact and
approximate (point-based) algorithms to compute robust policies for AB-POMDPs,
and thus ME-POMDPs. We demonstrate that we can compute policies for standard
POMDP benchmarks extended to the multi-environment setting.

</details>


### [142] [Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra](https://arxiv.org/abs/2510.23746)
*Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani*

Main category: cs.AI

TL;DR: 本文提出了一种基于测试时调优的框架，通过增强预训练transformer模型的学习能力，直接从串联质谱和分子式进行端到端的从头分子结构生成，无需手动注释和中间步骤，在两个流行基准测试上显著超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 当前串联质谱分析方法依赖于数据库匹配或需要中间片段/指纹预测的多步骤流程，这使得识别未知化合物（特别是参考数据库中不存在的化合物）极具挑战性。

Method: 利用测试时调优增强预训练transformer模型，实现直接从串联质谱和分子式进行端到端的从头分子结构生成，绕过手动注释和中间步骤。

Result: 在两个流行基准测试NPLIB1和MassSpecGym上分别超越了最先进方法DiffMS 100%和20%；测试时调优在MassSpecGym上比传统微调方法性能提升62%；即使预测偏离真实值，生成的分子候选结构仍然准确，为人工解释提供有价值指导。

Conclusion: 该框架通过测试时调优实现了高效的从头分子结构生成，能够动态适应新质谱，提供可靠的分子识别指导，在代谢组学、天然产物发现和环境分析等领域具有重要应用价值。

Abstract: Tandem Mass Spectrometry enables the identification of unknown compounds in
crucial fields such as metabolomics, natural product discovery and
environmental analysis. However, current methods rely on database matching from
previously observed molecules, or on multi-step pipelines that require
intermediate fragment or fingerprint prediction. This makes finding the correct
molecule highly challenging, particularly for compounds absent from reference
databases. We introduce a framework that, by leveraging test-time tuning,
enhances the learning of a pre-trained transformer model to address this gap,
enabling end-to-end de novo molecular structure generation directly from the
tandem mass spectra and molecular formulae, bypassing manual annotations and
intermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on
two popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.
Test-time tuning on experimental spectra allows the model to dynamically adapt
to novel spectra, and the relative performance gain over conventional
fine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground
truth, the generated molecular candidates remain structurally accurate,
providing valuable guidance for human interpretation and more reliable
identification.

</details>


### [143] [Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions](https://arxiv.org/abs/2510.23772)
*Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 该研究探讨生成式AI在象棋谜题领域的创造力，开发了一个能生成具有美学吸引力、新颖性、反直觉和独特解法的象棋谜题AI系统，并邀请三位国际象棋专家评估其创意表现。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的快速发展，研究其能否产生真正创意和新颖输出成为重要问题。本研究旨在验证AI在象棋谜题创作领域的创造力。

Method: 开发专门的AI系统生成象棋谜题，然后邀请三位世界知名象棋专家（国际象棋编排大师Amatzia Avni、特级大师Jonathan Levitt和Matthew Sadler）评估系统生成的谜题，基于创意性、挑战性和美学设计等标准评选最佳作品。

Result: 三位专家对AI生成的象棋谜题进行了评估，选出了各自最喜欢的谜题，并解释了这些谜题在创意性、挑战水平或美学设计方面的吸引力。

Conclusion: 研究表明AI系统能够生成具有美学价值和创意性的象棋谜题，专家评估验证了AI在特定领域展现创造力的潜力。

Abstract: The rapid advancement of Generative AI has raised significant questions
regarding its ability to produce creative and novel outputs. Our recent work
investigates this question within the domain of chess puzzles and presents an
AI system designed to generate puzzles characterized by aesthetic appeal,
novelty, counter-intuitive and unique solutions. We briefly discuss our method
below and refer the reader to the technical paper for more details. To assess
our system's creativity, we presented a curated booklet of AI-generated puzzles
to three world-renowned experts: International Master for chess compositions
Amatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All
three are noted authors on chess aesthetics and the evolving role of computers
in the game. They were asked to select their favorites and explain what made
them appealing, considering qualities such as their creativity, level of
challenge, or aesthetic design.

</details>


### [144] [Why Foundation Models in Pathology Are Failing](https://arxiv.org/abs/2510.23807)
*Hamid R. Tizhoosh*

Main category: cs.AI

TL;DR: 病理学基础模型在癌症诊断和预后方面表现不佳，存在准确性低、鲁棒性差、计算需求大等问题，主要源于通用AI假设与组织复杂性的不匹配。


<details>
  <summary>Details</summary>
Motivation: 评估病理学基础模型在癌症诊断、预后和多模态检索中的表现，揭示其根本性缺陷。

Method: 系统分析病理学基础模型的七个关键问题：生物复杂性、无效自监督、过度泛化、架构复杂、缺乏领域创新、数据不足和设计缺陷。

Result: 发现当前病理学基础模型存在低诊断准确性、差鲁棒性、几何不稳定、高计算需求和安全隐患等严重问题。

Conclusion: 病理学基础模型与组织形态学本质存在概念性不匹配，需要从根本上重新思考该范式。

Abstract: In non-medical domains, foundation models (FMs) have revolutionized computer
vision and language processing through large-scale self-supervised and
multimodal learning. Consequently, their rapid adoption in computational
pathology was expected to deliver comparable breakthroughs in cancer diagnosis,
prognostication, and multimodal retrieval. However, recent systematic
evaluations reveal fundamental weaknesses: low diagnostic accuracy, poor
robustness, geometric instability, heavy computational demands, and concerning
safety vulnerabilities. This short paper examines these shortcomings and argues
that they stem from deeper conceptual mismatches between the assumptions
underlying generic foundation modeling in mainstream AI and the intrinsic
complexity of human tissue. Seven interrelated causes are identified:
biological complexity, ineffective self-supervision, overgeneralization,
excessive architectural complexity, lack of domain-specific innovation,
insufficient data, and a fundamental design flaw related to tissue patch size.
These findings suggest that current pathology foundation models remain
conceptually misaligned with the nature of tissue morphology and call for a
fundamental rethinking of the paradigm itself.

</details>


### [145] [ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents](https://arxiv.org/abs/2510.23822)
*Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: ReCAP是一个用于大语言模型的递归上下文感知推理和规划框架，通过计划分解、父计划结构化重注入和内存高效执行机制，显著提升了长时程任务的推理能力和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在处理需要多步推理和动态重规划的长时程任务时面临的上下文漂移、目标信息丢失和循环失败等问题，同时避免现有方法导致的跨级连续性减弱或运行时开销过大。

Method: 结合三个关键机制：(1) 计划先行分解：生成完整子任务列表，执行第一项并优化剩余任务；(2) 父计划结构化重注入：在递归返回时保持多级上下文一致性；(3) 内存高效执行：限制活动提示，使成本随任务深度线性扩展。

Result: 在多个长时程推理基准测试中显著提升了子目标对齐和成功率，在同步Robotouille上获得32%的提升，在异步Robotouille上获得29%的改进（严格pass@1协议下）。

Conclusion: ReCAP框架通过将高层目标与低层动作对齐、减少冗余提示和保持连贯的上下文更新，有效解决了长时程推理任务中的关键挑战。

Abstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning
remain challenging for large language models (LLMs). Sequential prompting
methods are prone to context drift, loss of goal information, and recurrent
failure cycles, while hierarchical prompting methods often weaken cross-level
continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive
Context-Aware Reasoning and Planning), a hierarchical framework with shared
context for reasoning and planning in LLMs. ReCAP combines three key
mechanisms: (i) plan-ahead decomposition, in which the model generates a full
subtask list, executes the first item, and refines the remainder; (ii)
structured re-injection of parent plans, maintaining consistent multi-level
context during recursive return; and (iii) memory-efficient execution, bounding
the active prompt so costs scale linearly with task depth. Together these
mechanisms align high-level goals with low-level actions, reduce redundant
prompting, and preserve coherent context updates across recursion. Experiments
demonstrate that ReCAP substantially improves subgoal alignment and success
rates on various long-horizon reasoning benchmarks, achieving a 32% gain on
synchronous Robotouille and a 29% improvement on asynchronous Robotouille under
the strict pass@1 protocol.

</details>


### [146] [Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models](https://arxiv.org/abs/2510.23824)
*Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek*

Main category: cs.AI

TL;DR: 该研究比较了贪婪启发式、最优分配和基于大语言模型（LLM）的智能体在去中心化多智能体路径规划中的表现，发现LLM智能体在精心设计的提示和相关信息下能实现接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化条件下多智能体在共享环境中的协调挑战，特别关注目标分配问题，探索LLM在去中心化多智能体路径规划中的潜力。

Method: 智能体基于环境结构化表示（包括网格可视化和场景数据）独立生成目标偏好排序，然后交换排序信息，通过固定的确定性冲突解决规则（如智能体索引排序）进行目标分配，无需协商或迭代协调。

Result: LLM智能体在提供精心设计的提示和相关定量信息时，能够实现接近最优的完工时间，并持续优于传统启发式方法。

Conclusion: 语言模型在去中心化多智能体路径规划的目标分配中具有潜力，信息结构在此类系统中至关重要。

Abstract: Coordinating multiple autonomous agents in shared environments under
decentralized conditions is a long-standing challenge in robotics and
artificial intelligence. This work addresses the problem of decentralized goal
assignment for multi-agent path planning, where agents independently generate
ranked preferences over goals based on structured representations of the
environment, including grid visualizations and scenario data. After this
reasoning phase, agents exchange their goal rankings, and assignments are
determined by a fixed, deterministic conflict-resolution rule (e.g., agent
index ordering), without negotiation or iterative coordination. We
systematically compare greedy heuristics, optimal assignment, and large
language model (LLM)-based agents in fully observable grid-world settings. Our
results show that LLM-based agents, when provided with well-designed prompts
and relevant quantitative information, can achieve near-optimal makespans and
consistently outperform traditional heuristics. These findings underscore the
potential of language models for decentralized goal assignment in multi-agent
path planning and highlight the importance of information structure in such
systems.

</details>


### [147] [Generating Creative Chess Puzzles](https://arxiv.org/abs/2510.23881)
*Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的国际象棋谜题生成方法，通过设计基于象棋引擎搜索统计的新型奖励函数，显著提升了生成谜题的独特性、反直觉性、多样性和真实性。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在各个领域快速发展，但生成真正具有创造性、美学价值和反直觉性的输出仍然是一个挑战。本文旨在解决国际象棋谜题生成领域的这些困难。

Method: 首先对生成式AI架构进行基准测试，然后引入基于象棋引擎搜索统计的强化学习框架，设计了增强谜题独特性、反直觉性、多样性和真实性的奖励函数。

Result: 强化学习方法将反直觉谜题生成率从0.22%（监督学习）大幅提升至2.5%，超过了现有数据集比率（2.1%）和最佳Lichess训练模型（0.4%）。生成的谜题满足新颖性和多样性基准，保留了美学主题，并被人类专家评价为比编写书籍谜题更具创造性、趣味性和反直觉性，甚至接近经典作品水平。

Conclusion: 最终成果是这些AI生成谜题的精选手册，其创造性得到了三位世界知名专家的认可，证明了该方法在生成高质量国际象棋谜题方面的有效性。

Abstract: While Generative AI rapidly advances in various domains, generating truly
creative, aesthetic, and counter-intuitive outputs remains a challenge. This
paper presents an approach to tackle these difficulties in the domain of chess
puzzles. We start by benchmarking Generative AI architectures, and then
introduce an RL framework with novel rewards based on chess engine search
statistics to overcome some of those shortcomings. The rewards are designed to
enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.
Our RL approach dramatically increases counter-intuitive puzzle generation by
10x, from 0.22\% (supervised) to 2.5\%, surpassing existing dataset rates
(2.1\%) and the best Lichess-trained model (0.4\%). Our puzzles meet novelty
and diversity benchmarks, retain aesthetic themes, and are rated by human
experts as more creative, enjoyable, and counter-intuitive than composed book
puzzles, even approaching classic compositions. Our final outcome is a curated
booklet of these AI-generated puzzles, which is acknowledged for creativity by
three world-renowned experts.

</details>


### [148] [Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins](https://arxiv.org/abs/2510.23882)
*Adil Rasheed,Oscar Ravik,Omer San*

Main category: cs.AI

TL;DR: 该研究比较了数字孪生在动态系统建模和控制中的四种预测模型（线性、物理建模、LSTM、HAM）和三种控制策略（MPC、RL、LLM控制），发现在建模方面HAM表现最均衡，在控制方面MPC最稳健，RL适应性最强，LLM控制提供灵活的人机交互。


<details>
  <summary>Details</summary>
Motivation: 研究数字孪生在动态系统建模和控制中的应用，整合物理基础、数据驱动和混合方法，比较传统和AI驱动控制器的性能。

Method: 使用微型温室作为测试平台，开发四种预测模型（线性、PBM、LSTM、HAM）和三种控制策略（MPC、RL、LLM控制），在插值和外推场景下进行比较。

Result: HAM在建模中提供最均衡的性能（精度、泛化、计算效率），LSTM精度高但资源消耗大；MPC控制器稳健可预测，RL适应性强，LLM控制器结合预测工具提供灵活的人机交互。

Conclusion: HAM模型在建模方面表现最均衡，MPC控制器最稳健，RL控制器适应性最强，LLM控制器为人类与AI交互提供灵活性，不同方法在不同应用场景下各有优势。

Abstract: This work investigates the use of digital twins for dynamical system modeling
and control, integrating physics-based, data-driven, and hybrid approaches with
both traditional and AI-driven controllers. Using a miniature greenhouse as a
test platform, four predictive models Linear, Physics-Based Modeling (PBM),
Long Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are
developed and compared under interpolation and extrapolation scenarios. Three
control strategies Model Predictive Control (MPC), Reinforcement Learning (RL),
and Large Language Model (LLM) based control are also implemented to assess
trade-offs in precision, adaptability, and implementation effort. Results show
that in modeling HAM provides the most balanced performance across accuracy,
generalization, and computational efficiency, while LSTM achieves high
precision at greater resource cost. Among controllers, MPC delivers robust and
predictable performance, RL demonstrates strong adaptability, and LLM-based
controllers offer flexible human-AI interaction when coupled with predictive
tools.

</details>


### [149] [Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges](https://arxiv.org/abs/2510.23883)
*Shrestha Datta,Shahriar Kabir Nahin,Anshuman Chhabra,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 本文调查了基于大语言模型的智能AI系统带来的安全风险，提出了威胁分类法，回顾了评估方法，并讨论了技术和治理层面的防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着具备规划、工具使用、记忆和自主能力的智能AI系统在自动化领域的广泛应用，它们带来了与传统AI安全和软件安全不同的新型放大安全风险，需要系统性地识别和应对这些威胁。

Method: 通过构建智能AI特有的威胁分类法，回顾近期的基准测试和评估方法，从技术和治理两个角度分析防御策略，综合当前研究并突出未解决的挑战。

Result: 建立了智能AI安全威胁的系统性分类框架，识别了评估方法的关键进展，并提出了多层次防御策略，为安全设计智能系统提供了理论基础。

Conclusion: 智能AI系统创造了独特的安全挑战，需要安全优先的设计方法，通过技术防护和治理框架的结合来确保其安全部署，当前研究为构建安全智能系统奠定了基础，但仍有许多开放性问题需要解决。

Abstract: Agentic AI systems powered by large language models (LLMs) and endowed with
planning, tool use, memory, and autonomy, are emerging as powerful, flexible
platforms for automation. Their ability to autonomously execute tasks across
web, software, and physical environments creates new and amplified security
risks, distinct from both traditional AI safety and conventional software
security. This survey outlines a taxonomy of threats specific to agentic AI,
reviews recent benchmarks and evaluation methodologies, and discusses defense
strategies from both technical and governance perspectives. We synthesize
current research and highlight open challenges, aiming to support the
development of secure-by-design agent systems.

</details>


### [150] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 该论文提出了一种基于变分推理的链式思维训练算法，通过稀疏奖励函数和贝叶斯推理扩展策略，提升大型视觉语言模型在推理任务中的性能、泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有训练算法（如SFT、PPO、GRPO）在未见过推理任务上泛化能力差，且过度依赖有偏的奖励模型，限制了链式思维推理的发展。

Method: 将LVLMs中的推理重新表述为后验推理，基于摊销变分推理提出可扩展训练算法，使用多样性寻求强化学习算法设计稀疏奖励函数，并采用贝叶斯推理扩展策略替代昂贵的搜索方法。

Result: 在七个推理基准测试中，该方法显著提升了最先进LVLMs的有效性、泛化性和可解释性。

Conclusion: 提出的方法通过变分推理框架和稀疏奖励机制，有效解决了现有训练算法的局限性，为链式思维推理提供了更可靠和可扩展的解决方案。

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [151] [Decentralized Causal Discovery using Judo Calculus](https://arxiv.org/abs/2510.23942)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 提出了一种基于直觉主义去中心化框架的因果发现理论——judo演算，该演算在层拓扑中形式化定义了j-稳定因果推断，能够处理现实应用中因果效应随环境变化的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用中（从生物学到医学和社会科学），因果效应通常依赖于特定环境（如年龄、国家、剂量、基因型或实验室协议），需要一种能够形式化处理这种上下文依赖性的因果发现方法。

Method: 使用judo演算结合标准基于分数、约束和梯度的因果发现方法，通过Lawvere-Tierney模态算子j选择相关环境，实现j-稳定性因果推断。

Result: 在从合成到真实世界数据集（生物学和经济学）的实验结果表明，基于层拓扑的因果发现具有计算效率优势，并在性能上优于经典因果发现方法。

Conclusion: judo演算为处理上下文依赖的因果推断提供了一种形式化框架，通过去中心化的层拓扑方法实现了计算效率的提升和性能改进。

Abstract: We describe a theory and implementation of an intuitionistic decentralized
framework for causal discovery using judo calculus, which is formally defined
as j-stable causal inference using j-do-calculus in a topos of sheaves. In
real-world applications -- from biology to medicine and social science --
causal effects depend on regime (age, country, dose, genotype, or lab
protocol). Our proposed judo calculus formalizes this context dependence
formally as local truth: a causal claim is proven true on a cover of regimes,
not everywhere at once. The Lawvere-Tierney modal operator j chooses which
regimes are relevant; j-stability means the claim holds constructively and
consistently across that family. We describe an algorithmic and implementation
framework for judo calculus, combining it with standard score-based,
constraint-based, and gradient-based causal discovery methods. We describe
experimental results on a range of domains, from synthetic to real-world
datasets from biology and economics. Our experimental results show the
computational efficiency gained by the decentralized nature of sheaf-theoretic
causal discovery, as well as improved performance over classical causal
discovery methods.

</details>


### [152] [The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity](https://arxiv.org/abs/2510.23965)
*Aymane El Gadarri,Ali Aouad,Vivek F. Farias*

Main category: cs.AI

TL;DR: 提出了一种名为符号估计器的新方法，通过用二元分类损失替换交叉熵损失，解决了传统LLM对齐方法在人类偏好异质性下的不一致性问题，实现了可证明的一致性和多项式有限样本误差界。


<details>
  <summary>Details</summary>
Motivation: 传统LLM对齐方法对人类偏好的异质性很脆弱，拟合朴素概率模型到成对比较数据会产生不一致的总体平均效用估计。

Method: 提出符号估计器方法，在聚合步骤中用二元分类损失替换交叉熵损失，在温和假设下恢复一致的有序对齐。

Result: 在LLM对齐的数字孪生模拟中，符号估计器显著减少了偏好扭曲，将估计误差降低了近35%，与真实总体偏好的不一致性从12%降至8%。

Conclusion: 该方法在保持现有LLM对齐管道实现简单性的同时，优于明确建模用户异质性并需要跟踪个体级偏好数据的面板数据启发式方法。

Abstract: Traditional LLM alignment methods are vulnerable to heterogeneity in human
preferences. Fitting a na\"ive probabilistic model to pairwise comparison data
(say over prompt-completion pairs) yields an inconsistent estimate of the
population-average utility -a canonical measure of social welfare. We propose a
new method, dubbed the sign estimator, that provides a simple, provably
consistent, and efficient estimator by replacing cross-entropy with binary
classification loss in the aggregation step. This simple modification recovers
consistent ordinal alignment under mild assumptions and achieves the first
polynomial finite-sample error bounds in this setting. In realistic simulations
of LLM alignment using digital twins, the sign estimator substantially reduces
preference distortion over a panel of simulated personas, cutting (angular)
estimation error by nearly 35% and decreasing disagreement with true population
preferences from 12% to 8% compared to standard RLHF. Our method also compares
favorably to panel data heuristics that explicitly model user heterogeneity and
require tracking individual-level preference data-all while maintaining the
implementation simplicity of existing LLM alignment pipelines.

</details>


### [153] [Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance](https://arxiv.org/abs/2510.23989)
*Shangde Gao,Zelin Xu,Zhe Jiang*

Main category: cs.AI

TL;DR: 本研究提出了一种结合个体社会基础设施弹性(SIR)的条件深度学习模型，用于预测破坏性事件后个体移动模式的变化。


<details>
  <summary>Details</summary>
Motivation: 预测破坏性事件前个体移动模式的变化具有挑战性，因为缺乏衡量个体异质性社会基础设施弹性的方法，传统特征有限，且个体移动模式与空间环境的复杂交互未被充分捕捉。

Method: 将个体的社会基础设施弹性(SIR)整合到条件深度学习模型中，利用大规模稀疏的个体级数据捕捉个体移动模式与局部空间环境之间的复杂关系。

Result: 实验表明，结合个体的SIR和空间环境可以增强模型预测事件后个体移动模式的能力。条件模型能够捕捉到具有相似事件前模式但SIR不同的个体在移动模式上的差异变化。

Conclusion: 该研究证明了将个体社会基础设施弹性纳入预测模型的重要性，为预测破坏性事件后个体行为变化提供了有效方法。

Abstract: Shifts in individual movement patterns following disruptive events can reveal
changing demands for community resources. However, predicting such shifts
before disruptive events remains challenging for several reasons. First,
measures are lacking for individuals' heterogeneous social infrastructure
resilience (SIR), which directly influences their movement patterns, and
commonly used features are often limited or unavailable at scale, e.g.,
sociodemographic characteristics. Second, the complex interactions between
individual movement patterns and spatial contexts have not been sufficiently
captured. Third, individual-level movement may be spatially sparse and not
well-suited to traditional decision-making methods for movement predictions.
This study incorporates individuals' SIR into a conditioned deep learning model
to capture the complex relationships between individual movement patterns and
local spatial context using large-scale, sparse individual-level data. Our
experiments demonstrate that incorporating individuals' SIR and spatial context
can enhance the model's ability to predict post-event individual movement
patterns. The conditioned model can capture the divergent shifts in movement
patterns among individuals who exhibit similar pre-event patterns but differ in
SIR.

</details>


### [154] [OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2510.24028)
*Tingyue Pan,Mingyue Cheng,Shilong Zhang,Zhiding Liu,Xiaoyu Tao,Yucong Luo,Jintao Zhang,Qi Liu*

Main category: cs.AI

TL;DR: OneCast是一个跨域时间序列预测框架，通过解耦时间序列的季节性和趋势成分，分别使用轻量级投影模块和语义感知分词器进行建模，在多个领域实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决跨域时间序列预测中面临的领域特定趋势变化和不一致周期性模式问题，现有方法将时间序列视为未分化的序列，未能显式解耦其内在结构成分。

Method: 提出OneCast框架：1）将时间序列分解为季节性和趋势成分；2）季节性成分通过轻量级投影模块使用可解释基函数重建周期性模式；3）趋势成分通过语义感知分词器编码为分段级离散token，使用掩码离散扩散机制进行推断；4）两个分支输出结合生成最终预测。

Result: 在八个领域的广泛实验中，OneCast大多优于最先进的基线方法。

Conclusion: 通过结构化分解时间序列成分并采用专门的生成路径，OneCast能够有效捕捉季节性模式并跟踪领域特定趋势，在跨域时间序列预测中表现出色。

Abstract: Cross-domain time series forecasting is a valuable task in various web
applications. Despite its rapid advancement, achieving effective generalization
across heterogeneous time series data remains a significant challenge. Existing
methods have made progress by extending single-domain models, yet often fall
short when facing domain-specific trend shifts and inconsistent periodic
patterns. We argue that a key limitation lies in treating temporal series as
undifferentiated sequence, without explicitly decoupling their inherent
structural components. To address this, we propose OneCast, a structured and
modular forecasting framework that decomposes time series into seasonal and
trend components, each modeled through tailored generative pathways.
Specifically, the seasonal component is captured by a lightweight projection
module that reconstructs periodic patterns via interpretable basis functions.
In parallel, the trend component is encoded into discrete tokens at segment
level via a semantic-aware tokenizer, and subsequently inferred through a
masked discrete diffusion mechanism. The outputs from both branches are
combined to produce a final forecast that captures seasonal patterns while
tracking domain-specific trends. Extensive experiments across eight domains
demonstrate that OneCast mostly outperforms state-of-the-art baselines.

</details>


### [155] [Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach](https://arxiv.org/abs/2510.24085)
*Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani*

Main category: cs.AI

TL;DR: 本研究比较了经典模型和机器学习模型在电动汽车跟驰行为建模中的表现，发现随机森林模型在所有场景下都优于物理模型，特别是在不同车距条件下表现出更高的预测精度。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车的普及，需要理解其驾驶行为以提高交通安全和开发智能驾驶系统，特别是在与传统内燃机车辆混合行驶的环境中。

Method: 使用真实世界数据集，比较了IDM、OVM、OVRV和简化CACC等经典物理模型与随机森林回归器的性能，通过最小化预测值与实际数据的RMSE来校准模型参数。

Result: 随机森林模型在所有场景下表现最佳，RMSE分别为0.0046（中等车距）、0.0016（长车距）和0.0025（超长车距）；在物理模型中，CACC模型在长车距条件下表现最好，RMSE为2.67。

Conclusion: 机器学习模型在电动汽车跟驰行为建模中优于经典物理模型，这些模型对于模拟电动汽车行为和分析混合自动驾驶交通动态具有重要价值。

Abstract: The increasing adoption of electric vehicles (EVs) necessitates an
understanding of their driving behavior to enhance traffic safety and develop
smart driving systems. This study compares classical and machine learning
models for EV car following behavior. Classical models include the Intelligent
Driver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative
Velocity (OVRV), and a simplified CACC model, while the machine learning
approach employs a Random Forest Regressor. Using a real world dataset of an EV
following an internal combustion engine (ICE) vehicle under varied driving
conditions, we calibrated classical model parameters by minimizing the RMSE
between predictions and real data. The Random Forest model predicts
acceleration using spacing, speed, and gap type as inputs. Results demonstrate
the Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),
0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,
CACC performed best, with an RMSE of 2.67 for long gaps. These findings
highlight the machine learning model's performance across all scenarios. Such
models are valuable for simulating EV behavior and analyzing mixed autonomy
traffic dynamics in EV integrated environments.

</details>


### [156] [HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology](https://arxiv.org/abs/2510.24115)
*Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh*

Main category: cs.AI

TL;DR: 开发了透明AI助手HistoLens，让病理学家能用自然语言提问组织切片问题，系统提供结构化报告和可视化证据，保持医生主导地位的同时提高诊断效率和信心。


<details>
  <summary>Details</summary>
Motivation: 为了让医生真正信任AI，需要解决AI黑盒问题，使其推理过程像同事咨询一样透明可理解。

Method: 创建HistoLens系统，将自然语言问题转换为精确AI查询，提供结构化报告和热力图可视化证据，并训练AI专注患者组织、忽略背景噪声。

Result: 实现了医生主导的工作流程，病理学家能使用可信赖的AI助手验证见解，做出更快、更自信的诊断。

Conclusion: 透明协作的AI系统能建立医生对AI的信任，保持医生专业主导地位的同时提升诊断效率和准确性。

Abstract: For doctors to truly trust artificial intelligence, it can't be a black box.
They need to understand its reasoning, almost as if they were consulting a
colleague. We created HistoLens1 to be that transparent, collaborative partner.
It allows a pathologist to simply ask a question in plain English about a
tissue slide--just as they would ask a trainee. Our system intelligently
translates this question into a precise query for its AI engine, which then
provides a clear, structured report. But it doesn't stop there. If a doctor
ever asks, "Why?", HistoLens can instantly provide a 'visual proof' for any
finding--a heatmap that points to the exact cells and regions the AI used for
its analysis. We've also ensured the AI focuses only on the patient's tissue,
just like a trained pathologist would, by teaching it to ignore distracting
background noise. The result is a workflow where the pathologist remains the
expert in charge, using a trustworthy AI assistant to verify their insights and
make faster, more confident diagnoses.

</details>


### [157] [BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](https://arxiv.org/abs/2510.24161)
*Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.AI

TL;DR: BLM₁是一个多模态空间基础模型，通过两阶段训练实现跨空间转移、跨任务学习和跨具身泛化，在数字和物理任务中均优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在数字-物理空间间泛化能力差，VLAs缺乏高级具身推理能力，ELLMs局限于数字空间，缺乏统一的跨空间和跨具身模型。

Method: 采用两阶段训练范式：阶段I通过精选数字语料注入具身知识，保持语言能力；阶段II通过意图桥接接口训练策略模块，提取MLLM的高级语义指导控制。

Result: 在数字和物理基准测试中，单个BLM₁实例优于MLLMs、ELLMs、VLAs和GMLMs四个模型家族，数字任务提升约6%，物理任务提升约3%。

Conclusion: BLM₁成功实现了跨空间、跨任务和跨具身的统一建模，为具身智能提供了有效的解决方案。

Abstract: Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.

</details>


### [158] [Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms](https://arxiv.org/abs/2510.24297)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本文针对MCTS中的抽象技术提出改进，发现现有方法在多个动作属于同一抽象节点时存在平局问题，并提出了优于随机平局策略的多种内部抽象策略。


<details>
  <summary>Details</summary>
Motivation: MCTS的样本效率问题可以通过状态/动作抽象来解决，但现有抽象方法在多个动作属于同一抽象节点时，由于UCB值相同而需要平局规则，而当前方法（如pruned OGA）未注意到此问题并隐式使用随机平局策略。

Method: 提出并实证评估了多种替代的内部抽象策略，用于处理同一抽象节点中多个动作的平局情况。

Result: 多个提出的策略在大多数环境和参数设置下优于随机策略。

Conclusion: 通过改进内部抽象策略，可以显著提升MCTS抽象技术的性能，特别是在处理同一抽象节点中多个动作的情况时。

Abstract: One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which
can be addressed by building and using state and/or action abstractions in
parallel to the tree search such that information can be shared among nodes of
the same layer. The primary usage of abstractions for MCTS is to enhance the
Upper Confidence Bound (UCB) value during the tree policy by aggregating visits
and returns of an abstract node. However, this direct usage of abstractions
does not take the case into account where multiple actions with the same parent
might be in the same abstract node, as these would then all have the same UCB
value, thus requiring a tiebreak rule. In state-of-the-art abstraction
algorithms such as pruned On the Go Abstractions (pruned OGA), this case has
not been noticed, and a random tiebreak rule was implicitly chosen. In this
paper, we propose and empirically evaluate several alternative
intra-abstraction policies, several of which outperform the random policy
across a majority of environments and parameter settings.

</details>


### [159] [Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank](https://arxiv.org/abs/2510.24299)
*Jiayu Liu,Wei Dai,Zhenya Huang,Ning Miao,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为Self-Indicator的方法，通过分析LLM内部行为的相关性矩阵来评估推理路径的可信度，无需外部资源即可有效检测LLM输出错误。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然推理能力强，但容易产生错误和幻觉，现有检测方法依赖外部资源（如训练验证器或复杂提示），导致计算开销大且仅适用于特定领域。

Method: 研究发现输入问题与输出推理路径之间的相关性矩阵的秩是推理正确性的可靠指标，基于此设计了简单即插即用的Self-Indicator方法，通过重加权候选推理路径来评估可信度。

Result: 该方法在多个不同规模和家族的LLM上实验有效，区分正确与错误推理路径的准确率超过75%，并在三个推理基准测试上将准确率提高了8%以上。

Conclusion: Self-Indicator方法仅依赖LLM自身内部行为，无需训练单独模型或设计复杂提示，计算开销小且能显著提升推理性能，为LLM输出验证提供了有效解决方案。

Abstract: Despite the strong reasoning ability of large language models~(LLMs), they
are prone to errors and hallucinations. As a result, how to check their outputs
effectively and efficiently has become a critical problem in their
applications. Existing checking methods heavily rely on external resources,
such as trained verifiers (e.g., process/outcome reward models) or elaborate
prompts, which lead to high computational overhead and are only applicable to
specific domains. In this paper, we investigate whether the internal behaviors
of LLMs have already implied the credibility of their reasoning paths.
Specifically, we find that the rank of the correlation matrix between the input
problem and the output reasoning path is a robust indicator of reasoning
correctness. Different from other correctness indicators for LLMs, the
calculation of the correlation matrix only relies on the LLM itself, which
avoids the hassle of training a separate model or designing complicated
prompts. Based on it, we design a simple, plug-and-play Self-Indicator method
to reweight candidate reasoning paths, which achieves significant performance
improvements than other voting and verification methods with very few
computational overhead. Our experiments across multiple LLMs of varying scales
and model families have further shown the effectiveness of Self-Indicator. It
achieves over 75% accuracy in distinguishing correct reasoning paths from
incorrect ones, and, in turn, improves the accuracies on three reasoning
benchmarks by more than 8%.

</details>


### [160] [Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting](https://arxiv.org/abs/2510.24303)
*Deniz Gorur,Antoni Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的多智能体框架用于声明验证，通过不同智能体对声明真实性产生分歧并分别提供支持/反对证据，构建定量双极论证框架(QBAFs)，实验表明多智能体组合证据能提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 将判断性预测视为声明验证任务，需要评估未来事件的可能性，现有方法在证据收集和验证方面存在局限性，需要更全面和可解释的验证框架。

Method: 提出多智能体声明验证框架，使用三种LLM驱动的智能体：ArgLLM智能体（现有方法）、RbAM智能体（基于关系论证挖掘）、RAG-ArgLLM智能体（检索增强生成），构建QBAFs进行证据组合。

Result: 在两个标准判断性预测数据集上的实验显示，多智能体（特别是三个智能体）组合证据能显著提高预测准确性，同时提供可解释的证据组合。

Conclusion: 多智能体框架通过整合不同证据来源和观点，在提高预测准确性的同时保持了可解释性，为声明验证任务提供了有效解决方案。

Abstract: Judgmental forecasting is the task of making predictions about future events
based on human judgment. This task can be seen as a form of claim verification,
where the claim corresponds to a future event and the task is to assess the
plausibility of that event. In this paper, we propose a novel multi-agent
framework for claim verification, whereby different agents may disagree on
claim veracity and bring specific evidence for and against the claims,
represented as quantitative bipolar argumentation frameworks (QBAFs). We then
instantiate the framework for supporting claim verification, with a variety of
agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an
existing approach for claim verification that generates and evaluates QBAFs;
(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)
from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,
extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of
arguments from external sources. Finally, we conduct experiments with two
standard judgmental forecasting datasets, with instances of our framework with
two or three agents, empowered by six different base LLMs. We observe that
combining evidence from agents can improve forecasting accuracy, especially in
the case of three agents, while providing an explainable combination of
evidence for claim verification.

</details>


### [161] [Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research](https://arxiv.org/abs/2510.24337)
*Daria Kravets-Meinke,Hannah Schmid-Petri,Sonja Niemann,Ute Schmid*

Main category: cs.AI

TL;DR: 本文探讨了生成式大语言模型在传播研究内容分析中的应用，分析了其优势（优于人工编码、成本低、能解码隐含含义）和七大挑战（代码本开发、提示工程等），并提出了最佳实践指南。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式大语言模型在传播研究内容分析中展现出巨大潜力，但其在方法论工具包中的整合仍不充分，需要解决影响结果质量的七大关键挑战。

Method: 综合新兴研究，提出全面的最佳实践指南，包括代码本开发、提示工程、模型选择、参数调优、迭代优化、可靠性验证和性能增强等七个方面。

Result: 研究表明gLLMs在传播科学相关编码任务中能超越众包工作者和训练有素的编码员，且成本和时间大幅降低，能解码隐含含义和上下文信息。

Conclusion: 本文旨在使基于gLLM的内容分析对更广泛的传播研究者更加可及，并确保符合有效性、可靠性、可重复性和研究伦理等学科质量标准。

Abstract: Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly
being used in communication research for content analysis. Studies show that
gLLMs can outperform both crowd workers and trained coders, such as research
assistants, on various coding tasks relevant to communication science, often at
a fraction of the time and cost. Additionally, gLLMs can decode implicit
meanings and contextual information, be instructed using natural language,
deployed with only basic programming skills, and require little to no annotated
data beyond a validation dataset - constituting a paradigm shift in automated
content analysis. Despite their potential, the integration of gLLMs into the
methodological toolkit of communication research remains underdeveloped. In
gLLM-assisted quantitative content analysis, researchers must address at least
seven critical challenges that impact result quality: (1) codebook development,
(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)
iterative refinement, (6) validation of the model's reliability, and
optionally, (7) performance enhancement. This paper synthesizes emerging
research on gLLM-assisted quantitative content analysis and proposes a
comprehensive best-practice guide to navigate these challenges. Our goal is to
make gLLM-based content analysis more accessible to a broader range of
communication researchers and ensure adherence to established disciplinary
quality standards of validity, reliability, reproducibility, and research
ethics.

</details>


### [162] [VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation](https://arxiv.org/abs/2510.24339)
*Yunxuan Jiang,Silan Hu,Xiaoning Wang,Yuanyuan Zhang,Xiangyu Chang*

Main category: cs.AI

TL;DR: VDSAgents是一个基于可预测性-可计算性-稳定性(PCS)原则的多智能体系统，用于提升LLM驱动数据科学系统的可信度和鲁棒性，在多个数据集上优于现有端到端系统。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的数据科学系统仅依赖LLM内部推理，缺乏科学和理论原则指导，在处理噪声和复杂真实数据集时可信度和鲁棒性不足。

Method: 基于PCS原则构建多智能体系统，采用模块化工作流程处理数据清洗、特征工程、建模和评估，每个阶段由专门智能体负责，结合扰动分析、单元测试和模型验证。

Result: 在9个不同特征的数据集上评估，使用DeepSeek-V3和GPT-4o作为后端，VDSAgents持续优于AutoKaggle和DataInterpreter等最先进的端到端数据科学系统。

Conclusion: 将PCS原则嵌入LLM驱动的数据科学自动化是可行的，能够显著提升系统性能。

Abstract: Large language models (LLMs) become increasingly integrated into data science
workflows for automated system design. However, these LLM-driven data science
systems rely solely on the internal reasoning of LLMs, lacking guidance from
scientific and theoretical principles. This limits their trustworthiness and
robustness, especially when dealing with noisy and complex real-world datasets.
This paper provides VDSAgents, a multi-agent system grounded in the
Predictability-Computability-Stability (PCS) principles proposed in the
Veridical Data Science (VDS) framework. Guided by PCS principles, the system
implements a modular workflow for data cleaning, feature engineering, modeling,
and evaluation. Each phase is handled by an elegant agent, incorporating
perturbation analysis, unit testing, and model validation to ensure both
functionality and scientific auditability. We evaluate VDSAgents on nine
datasets with diverse characteristics, comparing it with state-of-the-art
end-to-end data science systems, such as AutoKaggle and DataInterpreter, using
DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the
results of AutoKaggle and DataInterpreter, which validates the feasibility of
embedding PCS principles into LLM-driven data science automation.

</details>


### [163] [An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine](https://arxiv.org/abs/2510.24359)
*Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri*

Main category: cs.AI

TL;DR: 提出了一种多智能体生态系统，用于N-of-1决策支持，旨在解决传统医疗AI只服务于平均患者的问题，通过协调不同器官系统、患者群体和分析模式的智能体来提供个性化医疗决策支持。


<details>
  <summary>Details</summary>
Motivation: 传统医疗AI系统通过最小化大型数据集上的错误来实现高聚合准确性，但在边缘病例（罕见变异、多病共存、代表性不足人群）上表现不佳，这种平均患者谬误损害了公平性和信任度。

Method: 构建多智能体生态系统，智能体按器官系统、患者群体和分析模式聚类，共享模型库和证据合成工具。通过协调层权衡可靠性、不确定性和数据密度，为临床医生提供决策支持包。

Result: 验证重点从群体平均值转向个体可靠性，通过低密度区域误差、小样本校准和风险-覆盖权衡来评估系统性能。

Conclusion: 通过从单一模型转向协调智能，该方法旨在使医疗AI与医学的首要原则保持一致：提供透明、公平且以个体为中心的医疗服务。

Abstract: Artificial intelligence in medicine is built to serve the average patient. By
minimizing error across large datasets, most systems deliver strong aggregate
accuracy yet falter at the margins: patients with rare variants,
multimorbidity, or underrepresented demographics. This average patient fallacy
erodes both equity and trust. We propose a different design: a multi-agent
ecosystem for N-of-1 decision support. In this environment, agents clustered by
organ systems, patient populations, and analytic modalities draw on a shared
library of models and evidence synthesis tools. Their results converge in a
coordination layer that weighs reliability, uncertainty, and data density
before presenting the clinician with a decision-support packet: risk estimates
bounded by confidence ranges, outlier flags, and linked evidence. Validation
shifts from population averages to individual reliability, measured by error in
low-density regions, calibration in the small, and risk--coverage trade-offs.
Anticipated challenges include computational demands, automation bias, and
regulatory fit, addressed through caching strategies, consensus checks, and
adaptive trial frameworks. By moving from monolithic models to orchestrated
intelligence, this approach seeks to align medical AI with the first principle
of medicine: care that is transparent, equitable, and centered on the
individual.

</details>


### [164] [Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion](https://arxiv.org/abs/2510.24390)
*Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.AI

TL;DR: Orion是一个新颖的LLM推理框架，通过依赖感知的查询分解和逻辑并行内容扩展，解决了Web应用中高质量推理与低延迟高吞吐需求之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理存在计算效率低下的顺序生成和僵化推理策略问题，无法同时满足现代Web平台对效率和质量的二元要求。

Method: 将查询推理分解为两个协同阶段：检索增强的关键点生成和基于依赖图的并行内容扩展，并引入流水线调度机制实现跨查询并行。

Result: 在多样化基准测试中，Orion实现了比基线高达4.33倍的token生成速度和3.42倍的低延迟，同时通过显式建模点间依赖关系将推理质量提升高达18.75%。

Conclusion: Orion框架成功平衡了LLM推理的效率和质量需求，为实时Web应用中的复杂推理任务提供了可行的解决方案。

Abstract: The integration of Large Language Models (LLMs) into real-time Web
applications, such as AI-powered search and conversational agents, presents a
fundamental Web infrastructure challenge: reconciling the demand for
high-quality, complex reasoning with the stringent low-latency and
high-throughput requirements of interactive services. Current LLM reasoning,
hindered by computationally inefficient sequential generation and rigid
reasoning strategies, creates a critical bottleneck for the Web services.
Existing approaches typically optimize the LLM reasoning for either efficiency
or quality but struggle to achieve both, and thus fail to meet the dual
requirements of modern Web platforms. To overcome these limitations, we propose
Orion, a novel and efficient reasoning framework that enables dependency-aware
query decomposition and logic-parallel content expansion. Concretely, Orion
decomposes a single query reasoning process into two synergistic phases: (1)
\textit{key point generation}, which distills logically structured key points
through retrieval-augmented few-shot prompting, and (2) \textit{content
parallel expansion}, which concurrently elaborates on these points based on a
dependency graph to ensure logical consistency. Furthermore, Orion introduces a
pipeline scheduling mechanism that exploits the complementary computational
characteristics of the two phases (generation imposes pressure on GPU computing
and expansion stresses on GPU memory) across multiple queries, enabling
cross-query parallelism and dramatically improving reasoning performance (\ie,
efficiency and quality). Experiments on diverse benchmarks show that Orion not
only delivers up to 4.33x higher token generation speed and 3.42x lower answer
latency over the baselines but also improves reasoning quality by up to 18.75%
through explicitly modeling inter-point dependencies.

</details>


### [165] [APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training](https://arxiv.org/abs/2510.24397)
*Jiarui Qin,Yunjia Xi,Junjie Huang,Renting Rui,Di Yin,Weiwen Liu,Yong Yu,Weinan Zhang,Xing Sun*

Main category: cs.AI

TL;DR: APTBench是一个用于评估LLM预训练阶段智能体潜力的基准框架，通过将真实世界智能体任务转换为适合基础模型的多选题或文本补全问题，比现有基准更能预测下游智能体性能。


<details>
  <summary>Details</summary>
Motivation: 当前预训练基准主要关注孤立静态技能，无法反映模型的智能体能力；而智能体基准通常针对后训练模型，基础模型难以支持多轮任务执行，因此需要能在预训练阶段评估智能体潜力的基准。

Method: 将真实世界智能体任务和成功轨迹转换为适合基础模型的多选题或文本补全问题，重点关注规划和行动等核心智能体能力，覆盖软件工程和深度研究等关键场景。

Result: 相比现有通用基准，APTBench能更准确地预测模型作为智能体的下游性能，同时比后训练阶段的端到端智能体评估更轻量且成本效益更高。

Conclusion: APTBench填补了预训练阶段智能体能力评估的空白，为更有效地指导模型训练提供了实用工具。

Abstract: With the rapid development of LLM-based agents, there is a growing trend to
incorporate agent-specific data into the pre-training stage of LLMs, aiming to
better align LLMs with real-world autonomous task execution. However, current
pre-training benchmarks primarily focus on isolated and static skills, e.g.,
common knowledge or mathematical/code reasoning, and fail to reflect model's
agentic capabilities. On the other hand, agent benchmarks are typically
designed for post-trained models, requiring multi-turn task execution abilities
that base models struggle to support. Thus, there is a compelling need for a
benchmark that can evaluate agentic potentials during pre-training and guide
the model training more effectively. To address this gap, we propose APTBench,
a framework that converts real-world agent tasks and successful trajectories
into multiple-choice or text completion questions tailored for base models. It
focuses on core agentic abilities, e.g., planning and action, and covers key
agent scenarios, software engineering and deep research. Compared to existing
general-purpose benchmarks, APTBench offers a more predictive signal of a
model's downstream performance as an agent, while remaining significantly more
lightweight and cost-effective than full-scale, end-to-end agent evaluations
after post-training.

</details>


### [166] [Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning](https://arxiv.org/abs/2510.24435)
*Benjamin Grando Moreira*

Main category: cs.AI

TL;DR: 本研究比较了多个大型语言模型（GPT、Claude、DeepSeek等）在逻辑和抽象推理能力方面的表现，使用8个定制推理问题，并与人类表现进行基准测试，揭示了LLMs在演绎推理方面的困难。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的推理能力对于推进人工智能发展至关重要，因为这超越了单纯的语言任务表现，涉及理解模型是否真正理解信息、进行推理以及以逻辑有效的方式得出结论。

Method: 使用8个定制设计的推理问题，比较了GPT、Claude、DeepSeek、Gemini、Grok、Llama、Mistral、Perplexity和Sabi'a等多个LLMs的逻辑和抽象推理技能，并将结果与人类在相同任务上的表现进行基准测试。

Result: 研究揭示了LLMs与人类表现之间存在显著差异，表明LLMs在演绎推理方面存在困难。

Conclusion: 大型语言模型在逻辑和抽象推理能力方面仍有不足，特别是在演绎推理任务上表现不佳，需要进一步改进以提升其推理能力。

Abstract: Evaluating reasoning ability in Large Language Models (LLMs) is important for
advancing artificial intelligence, as it transcends mere linguistic task
performance. It involves understanding whether these models truly understand
information, perform inferences, and are able to draw conclusions in a logical
and valid way. This study compare logical and abstract reasoning skills of
several LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,
Perplexity, and Sabi\'a - using a set of eight custom-designed reasoning
questions. The LLM results are benchmarked against human performance on the
same tasks, revealing significant differences and indicating areas where LLMs
struggle with deduction.

</details>


### [167] [Law in Silico: Simulating Legal Society with LLM-Based Agents](https://arxiv.org/abs/2510.24442)
*Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang*

Main category: cs.AI

TL;DR: 本文介绍了一个基于大语言模型的法律社会模拟框架Law in Silico，能够模拟个体决策和立法、裁决、执法等制度机制，实验表明该框架能够复现宏观犯罪趋势并为弱势群体权利保护提供见解。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界中的法律实验通常成本高昂或不可行，利用人工智能系统模拟法律社会成为验证和发展法律理论、支持法律管理的有效替代方案。大语言模型凭借其世界知识和角色扮演能力，是构建法律社会模拟的理想基础。

Method: 提出了Law in Silico框架，这是一个基于大语言模型的智能体框架，能够模拟包含个体决策以及立法、裁决、执法等制度机制的法律场景。

Result: 实验比较模拟犯罪率与现实世界数据，表明基于大语言模型的智能体能够很大程度上复现宏观层面的犯罪趋势，并提供与现实世界观察一致的见解。微观层面模拟显示，功能良好、透明且适应性强的法律系统能更好地保护弱势个体的权利。

Conclusion: 基于大语言模型的模拟框架能够有效模拟法律系统，不仅能够复现实世界犯罪趋势，还能为法律系统的改进提供有价值的见解，特别是在保护弱势群体权利方面。

Abstract: Since real-world legal experiments are often costly or infeasible, simulating
legal societies with Artificial Intelligence (AI) systems provides an effective
alternative for verifying and developing legal theory, as well as supporting
legal administration. Large Language Models (LLMs), with their world knowledge
and role-playing capabilities, are strong candidates to serve as the foundation
for legal society simulation. However, the application of LLMs to simulate
legal systems remains underexplored. In this work, we introduce Law in Silico,
an LLM-based agent framework for simulating legal scenarios with individual
decision-making and institutional mechanisms of legislation, adjudication, and
enforcement. Our experiments, which compare simulated crime rates with
real-world data, demonstrate that LLM-based agents can largely reproduce
macro-level crime trends and provide insights that align with real-world
observations. At the same time, micro-level simulations reveal that a
well-functioning, transparent, and adaptive legal system offers better
protection of the rights of vulnerable individuals.

</details>


### [168] [From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning](https://arxiv.org/abs/2510.24528)
*Zihan Chen,Song Wang,Xingbo Fu,Chengshuai Shi,Zhenyu Lei,Cong Shen,Jundong Li*

Main category: cs.AI

TL;DR: 提出了一种成本效益高的两阶段流程，通过跨任务示例伪标注和基于图的标签传播方法，减少对LLM数据标注的依赖，为上下文学习构建演示示例。


<details>
  <summary>Details</summary>
Motivation: 为新的或困难任务收集高质量示例成本高昂且劳动密集，需要减少对大型语言模型数据标注的依赖。

Method: 两阶段流程：首先利用跨任务示例提示LLM伪标注少量目标任务实例，然后引入基于图的标签传播方法将标签信息传播到剩余目标示例，无需额外LLM查询。

Result: 在五个任务上的实验表明，该方法在降低标注成本的同时实现了强劲性能。

Conclusion: 该管道结合了跨任务监督的灵活性和无LLM传播的可扩展性，为上下文学习提供了有效的解决方案。

Abstract: The capability of in-context learning (ICL) enables large language models
(LLMs) to perform novel tasks without parameter updates by conditioning on a
few input-output examples. However, collecting high-quality examples for new or
challenging tasks can be costly and labor-intensive. In this work, we propose a
cost-efficient two-stage pipeline that reduces reliance on LLMs for data
labeling. Our approach first leverages readily available cross-task examples to
prompt an LLM and pseudo-label a small set of target task instances. We then
introduce a graph-based label propagation method that spreads label information
to the remaining target examples without additional LLM queries. The resulting
fully pseudo-labeled dataset is used to construct in-task demonstrations for
ICL. This pipeline combines the flexibility of cross-task supervision with the
scalability of LLM-free propagation. Experiments across five tasks demonstrate
that our method achieves strong performance while lowering labeling costs.

</details>


### [169] [FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling](https://arxiv.org/abs/2510.24645)
*Zengzhuang Xu,Bingguang Hao,Zechuan Wang,Yuntao Wen,Maolin Wang,Yang Liu,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Chenyi Zhuang,Jinjie Gu,Leilei Gan,Xiangyu Zhao,Shi Gu*

Main category: cs.AI

TL;DR: FunReason-MT是一个用于合成多轮工具使用训练数据的新框架，解决了现有方法在真实环境中的局限性，通过环境-API图交互、高级工具查询合成和引导迭代链等技术生成高质量数据。


<details>
  <summary>Details</summary>
Motivation: 现有数据合成方法（如随机环境采样或多智能体角色扮演）在真实环境中生成高质量数据的能力不足，面临目标模型训练、工具架构隔离和多轮逻辑依赖三大挑战。

Method: 采用环境-API图交互收集多样化高质量轨迹，高级工具查询合成简化复杂查询构建，引导迭代链生成复杂思维链。

Result: 在Berkeley Function-Calling Leaderboard (BFCLv3)上，基于FunReason-MT生成数据训练的4B模型在同类规模模型中达到最先进性能，超越大多数闭源模型。在BFCLv4上的进一步性能提升证实了其可靠性。

Conclusion: FunReason-MT为智能体学习提供了可靠且鲁棒的数据源，能够有效解决多轮函数调用数据合成的复杂性障碍。

Abstract: Function calling (FC) empowers large language models (LLMs) and autonomous
agents to interface with external tools, a critical capability for solving
complex, real-world problems. As this ability becomes increasingly central to
advanced AI systems, the need for high-quality, multi-turn training data to
develop and refine it cannot be overstated. Existing data synthesis methods,
such as random environment sampling or multi-agent role-playing, are not
powerful enough to generate high-quality data in real-world environments.
Practical challenges come in three folds: targeted model training, isolation of
tool architecture, and multi-turn logical dependency. To address these
structural deficiencies, we present FunReason-MT, a novel data synthesis
framework for real-world multi-turn tool use. FunReason-MT resolves the
complexity barrier in multi-turn FC data by employing 1) Environment-API Graph
Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query
Synthesis to simplify hard query construction, and 3) Guided Iterative Chain
for sophisticated CoT generation. Evaluations on Berkeley Function-Calling
Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built
upon FunReason-MT generated data achieves state-of-the-art performance among
comparable-sized models, outperforming most close-source models. Further
performance improvements on BFCLv4 confirm that FunReason-MT provides a
reliable and robust source for agentic learning.

</details>


### [170] [Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](https://arxiv.org/abs/2510.24650)
*Nitin Rai,Daeun,Choi,Nathan S. Boyd,Arnold W. Schumann*

Main category: cs.AI

TL;DR: 该综述分析了约40篇关于基础模型在作物定点病害管理中的应用文献，重点关注大语言模型和视觉语言模型，讨论了它们在自适应学习、强化学习和数字孪生框架中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和深度学习在实时计算机视觉中的快速发展，作物定点病害管理从手工特征提取发展到大规模自动特征学习。基础模型以全新方式处理作物病害数据，整合视觉和文本数据，解释症状文本，推理症状与管理的关系，并为种植者和教育者提供交互式问答支持。

Method: 通过筛选约40篇相关文献，分析基础模型在定点病害管理中的应用，特别关注大语言模型和视觉语言模型，探讨它们在自适应学习、强化学习和数字孪生框架中的角色。

Result: 主要发现：(a) 基础模型在2023-24年文献激增；(b) 视觉语言模型发展快于大语言模型，发表量增长5-10倍；(c) 强化学习和自适应学习在智能喷洒中仍处于起步阶段；(d) 结合强化学习的数字孪生可虚拟模拟定点喷洒；(e) 解决仿真到现实的差距对实际部署至关重要；(f) 人机协作仍有限，特别是在人在环方法中；(g) 具有实时反馈的多模态基础模型将推动下一代定点病害管理。

Conclusion: 基础模型正在改变作物病害管理方式，特别是视觉语言模型展现出巨大潜力。虽然强化学习和自适应学习应用仍不成熟，但结合数字孪生和人机协作的多模态基础模型将是未来发展的关键方向。

Abstract: Site-specific disease management (SSDM) in crops has advanced rapidly through
machine and deep learning (ML and DL) for real-time computer vision. Research
evolved from handcrafted feature extraction to large-scale automated feature
learning. With foundation models (FMs), crop disease datasets are now processed
in fundamentally new ways. Unlike traditional neural networks, FMs integrate
visual and textual data, interpret symptoms in text, reason about
symptom-management relationships, and support interactive QA for growers and
educators. Adaptive and imitation learning in robotics further enables
field-based disease management. This review screened approx. 40 articles on FM
applications for SSDM, focusing on large-language models (LLMs) and
vision-language models (VLMs), and discussing their role in adaptive learning
(AL), reinforcement learning (RL), and digital twin frameworks for targeted
spraying. Key findings: (a) FMs are gaining traction with surging literature in
2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL
and AL are still nascent for smart spraying; (d) digital twins with RL can
simulate targeted spraying virtually; (e) addressing the sim-to-real gap is
critical for real-world deployment; (f) human-robot collaboration remains
limited, especially in human-in-the-loop approaches where robots detect early
symptoms and humans validate uncertain cases; (g) multi-modal FMs with
real-time feedback will drive next-gen SSDM. For updates, resources, and
contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to
submit papers, code, or datasets.

</details>


### [171] [OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs](https://arxiv.org/abs/2510.24663)
*Yifu Lu,Shengjie Liu,Li Dong*

Main category: cs.AI

TL;DR: OrchDAG是一个合成数据生成管道，将工具执行建模为具有可控复杂度的有向无环图，用于多轮工具交互的基准测试和强化学习训练。


<details>
  <summary>Details</summary>
Motivation: 现有工作大多忽视了多轮工具交互的复杂性，需要更好的基准和训练方法来处理这种复杂性。

Method: 引入OrchDAG合成数据生成管道，将工具执行建模为有向无环图，并提出基于图的奖励来增强RLVR训练。

Result: 实验表明该数据集提供了一个具有挑战性但可解决的基准，所提出的奖励在与GRPO风格算法结合时有效。

Conclusion: 在多轮工具使用中，利用拓扑结构和数据复杂性至关重要。

Abstract: Agentic tool use has gained traction with the rise of agentic tool calling,
yet most existing work overlooks the complexity of multi-turn tool
interactions. We introduce OrchDAG, a synthetic data generation pipeline that
models tool execution as directed acyclic graphs (DAGs) with controllable
complexity. Using this dataset, we benchmark model performance and propose a
graph-based reward to enhance RLVR training. Experiments show that the dataset
presents a challenging but solvable benchmark, and the proposed reward is
effective when combined with GRPO-style algorithms, highlighting the importance
of leveraging topological structure and data complexity in multi-turn tool use.

</details>


### [172] [Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning](https://arxiv.org/abs/2510.24690)
*Shengjie Liu,Li Dong,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 提出了一个通过构建工具和文档知识图谱来增强示例工件生成的框架，通过深度稀疏集成策略将工具依赖关系与程序知识对齐。


<details>
  <summary>Details</summary>
Motivation: 为了揭示和利用工具与文档之间的依赖关系，以改进示例工件的生成质量。

Method: 从工具模式构建工具知识图谱，从内部文档和SOP构建补充知识图谱，然后将两者融合，采用深度稀疏集成策略对齐工具依赖关系与程序知识。

Result: 实验表明该统一框架能有效建模工具交互并改进计划生成。

Conclusion: 将工具图谱与领域知识图谱链接对于工具增强推理和规划具有显著益处。

Abstract: We present a framework for uncovering and exploiting dependencies among tools
and documents to enhance exemplar artifact generation. Our method begins by
constructing a tool knowledge graph from tool schemas,including descriptions,
arguments, and output payloads, using a DeepResearch-inspired analysis. In
parallel, we derive a complementary knowledge graph from internal documents and
SOPs, which is then fused with the tool graph. To generate exemplar plans, we
adopt a deep-sparse integration strategy that aligns structural tool
dependencies with procedural knowledge. Experiments demonstrate that this
unified framework effectively models tool interactions and improves plan
generation, underscoring the benefits of linking tool graphs with domain
knowledge graphs for tool-augmented reasoning and planning.

</details>
