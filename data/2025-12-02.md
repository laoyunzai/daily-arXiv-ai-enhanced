<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 115]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 16]
- [cs.AI](#cs.AI) [Total: 50]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 16]
- [nlin.AO](#nlin.AO) [Total: 2]
- [physics.data-an](#physics.data-an) [Total: 2]
- [quant-ph](#quant-ph) [Total: 65]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Measuring What LLMs Think They Do: SHAP Faithfulness and Deployability on Financial Tabular Classification](https://arxiv.org/abs/2512.00163)
*Saeed AlMarri,Mathieu Ravaut,Kristof Juhasz,Gautier Marti,Hamdan Al Ahbabi,Ibrahim Elfadel*

Main category: cs.LG

TL;DR: 该研究评估了大型语言模型在金融分类任务中的表现，发现其自解释特征影响与SHAP值存在差异，且与LightGBM的SHAP值也有显著不同，表明LLMs作为结构化金融建模的独立分类器存在局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在分类任务中受到关注，可作为传统机器学习模型的灵活替代方案，但其在结构化表格数据（特别是金融风险评估等高风险应用）中的可靠性尚不明确。

Method: 系统评估LLMs在金融分类任务上的表现，并生成其SHAP值进行分析比较。

Result: 发现LLMs的自解释特征影响与其SHAP值存在分歧，且LLMs与LightGBM的SHAP值有显著差异。

Conclusion: LLMs作为结构化金融建模的独立分类器存在局限性，但通过改进可解释性机制结合少量样本提示，LLMs有望在风险敏感领域得到应用。

Abstract: Large Language Models (LLMs) have attracted significant attention for classification tasks, offering a flexible alternative to trusted classical machine learning models like LightGBM through zero-shot prompting. However, their reliability for structured tabular data remains unclear, particularly in high stakes applications like financial risk assessment. Our study systematically evaluates LLMs and generates their SHAP values on financial classification tasks. Our analysis shows a divergence between LLMs self-explanation of feature impact and their SHAP values, as well as notable differences between LLMs and LightGBM SHAP values. These findings highlight the limitations of LLMs as standalone classifiers for structured financial modeling, but also instill optimism that improved explainability mechanisms coupled with few-shot prompting will make LLMs usable in risk-sensitive domains.

</details>


### [2] [Data assimilation and discrepancy modeling with shallow recurrent decoders](https://arxiv.org/abs/2512.01170)
*Yuxuan Bao,J. Nathan Kutz*

Main category: cs.LG

TL;DR: DA-SHRED是一个机器学习框架，通过浅层循环解码器结合仿真模型和真实传感器数据进行数据同化，填补仿真到现实的差距，并恢复仿真模型中缺失的动态过程。


<details>
  <summary>Details</summary>
Motivation: 现代传感需求日益增长，需要数据效率、实时处理和在有限传感覆盖下的部署。复杂物理系统通常通过有限点传感器结合科学计算来表征，但仿真模型往往忽略小尺度或隐藏过程，对扰动敏感，或过度简化参数相关性，导致重建结果与传感器测量的现实存在偏差。这产生了对数据同化的关键需求，即整合观测数据与预测仿真模型以产生复杂物理系统完整状态的准确估计。

Method: 提出DA-SHRED（Data Assimilation with a SHallow REcurrent Decoder）框架，利用SHRED从简化仿真模型中学习潜在空间，然后使用真实传感器数据更新这些潜在变量以准确重建完整系统状态。算法还在潜在空间中结合基于稀疏非线性动力学识别的回归模型，识别仿真模型中缺失动态对应的函数形式。

Result: DA-SHRED成功填补了仿真到现实的差距，并在高度复杂系统中恢复了缺失的动态过程。表明高效时间编码和物理信息校正的结合能够实现鲁棒的数据同化。

Conclusion: DA-SHRED框架通过结合仿真模型和真实传感器数据，有效解决了复杂物理系统数据同化问题，不仅填补了仿真到现实的差距，还能识别和恢复仿真模型中缺失的动态过程，为高维时空场建模提供了有效的解决方案。

Abstract: The requirements of modern sensing are rapidly evolving, driven by increasing demands for data efficiency, real-time processing, and deployment under limited sensing coverage. Complex physical systems are often characterized through the integration of a limited number of point sensors in combination with scientific computations which approximate the dominant, full-state dynamics. Simulation models, however, inevitably neglect small-scale or hidden processes, are sensitive to perturbations, or oversimplify parameter correlations, leading to reconstructions that often diverge from the reality measured by sensors. This creates a critical need for data assimilation, the process of integrating observational data with predictive simulation models to produce coherent and accurate estimates of the full state of complex physical systems. We propose a machine learning framework for Data Assimilation with a SHallow REcurrent Decoder (DA-SHRED) which bridges the simulation-to-real (SIM2REAL) gap between computational modeling and experimental sensor data. For real-world physics systems modeling high-dimensional spatiotemporal fields, where the full state cannot be directly observed and must be inferred from sparse sensor measurements, we leverage the latent space learned from a reduced simulation model via SHRED, and update these latent variables using real sensor data to accurately reconstruct the full system state. Furthermore, our algorithm incorporates a sparse identification of nonlinear dynamics based regression model in the latent space to identify functionals corresponding to missing dynamics in the simulation model. We demonstrate that DA-SHRED successfully closes the SIM2REAL gap and additionally recovers missing dynamics in highly complex systems, demonstrating that the combination of efficient temporal encoding and physics-informed correction enables robust data assimilation.

</details>


### [3] [We Still Don't Understand High-Dimensional Bayesian Optimization](https://arxiv.org/abs/2512.00170)
*Colin Doumont,Donney Fan,Natalie Maus,Jacob R. Gardner,Henry Moss,Geoff Pleiss*

Main category: cs.LG

TL;DR: 贝叶斯线性回归在高维优化中表现优于复杂方法，通过几何变换避免边界搜索行为，在60-6000维任务中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 高维空间对贝叶斯优化提出了挑战，现有方法通过编码各种结构假设来应对维度诅咒，但作者发现这些复杂方法被最简单的贝叶斯线性回归所超越

Method: 使用高斯过程配合线性核函数，并应用几何变换来避免边界搜索行为；线性模型提供闭式采样，计算复杂度随数据线性增长

Result: 在60-6000维搜索空间的任务中，线性核高斯过程达到了最先进的性能；在超过20,000个观测的分子优化任务中展示了线性计算优势

Conclusion: 研究结果表明需要重新思考高维空间中贝叶斯优化的传统直觉，线性模型在高维优化中具有显著优势

Abstract: High-dimensional spaces have challenged Bayesian optimization (BO). Existing methods aim to overcome this so-called curse of dimensionality by carefully encoding structural assumptions, from locality to sparsity to smoothness, into the optimization procedure. Surprisingly, we demonstrate that these approaches are outperformed by arguably the simplest method imaginable: Bayesian linear regression. After applying a geometric transformation to avoid boundary-seeking behavior, Gaussian processes with linear kernels match state-of-the-art performance on tasks with 60- to 6,000-dimensional search spaces. Linear models offer numerous advantages over their non-parametric counterparts: they afford closed-form sampling and their computation scales linearly with data, a fact we exploit on molecular optimization tasks with > 20,000 observations. Coupled with empirical analyses, our results suggest the need to depart from past intuitions about BO methods in high-dimensional spaces.

</details>


### [4] [Orion-Bix: Bi-Axial Attention for Tabular In-Context Learning](https://arxiv.org/abs/2512.00181)
*Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu*

Main category: cs.LG

TL;DR: Orion-Bix是一个表格基础模型，通过双轴注意力机制和元学习上下文推理实现少样本表格学习，在公开基准测试中表现优于梯度提升基线方法。


<details>
  <summary>Details</summary>
Motivation: 表格数据在现实世界机器学习应用中普遍存在，但构建通用模型面临挑战：混合数值和分类特征、弱特征结构、有限标注数据，使得扩展和泛化困难。

Method: 结合双轴注意力与元学习上下文推理：编码器交替使用标准、分组、分层和关系注意力，通过多CLS汇总融合输出；标签感知ICL头通过分层决策路由实现动态适应；在具有因果先验的合成生成多样化表格上进行元训练。

Result: 在公开基准测试中优于梯度提升基线方法，与最先进的表格基础模型保持竞争力，证明双轴注意力与情景元训练能够实现鲁棒的少样本表格学习。

Conclusion: Orion-Bix作为一个scikit-learn兼容的基础模型，通过双轴注意力机制和元学习上下文推理，成功解决了表格数据少样本学习的挑战，实现了跨异构数据的可迁移归纳偏置学习。

Abstract: Tabular data drive most real-world machine learning applications, yet building general-purpose models for them remains difficult. Mixed numeric and categorical fields, weak feature structure, and limited labeled data make scaling and generalization challenging. To this end, we introduce Orion-Bix, a tabular foundation model that combines biaxial attention with meta-learned in-context reasoning for few-shot tabular learning. Its encoder alternates standard, grouped, hierarchical, and relational attention, fusing their outputs through multi-CLS summarization to capture both local and global dependencies efficiently. A label-aware ICL head adapts on the fly and scales to large label spaces via hierarchical decision routing. Meta-trained on synthetically generated, structurally diverse tables with causal priors, Orion-Bix learns transferable inductive biases across heterogeneous data. Delivered as a scikit-learn compatible foundation model, it outperforms gradient-boosting baselines and remains competitive with state-of-the-art tabular foundation models on public benchmarks, showing that biaxial attention with episodic meta-training enables robust, few-shot-ready tabular learning. The model is publicly available at https://github.com/Lexsi-Labs/Orion-BiX .

</details>


### [5] [Hybrid Context-Fusion Attention (CFA) U-Net and Clustering for Robust Seismic Horizon Interpretation](https://arxiv.org/abs/2512.00191)
*Jose Luis Lima de Jesus Silva,Joao Pedro Gomes,Paulo Roberto de Melo Barros Junior,Vitor Hugo Serravalle Reis Rodrigues,Alexsandro Guerra Cerqueira*

Main category: cs.LG

TL;DR: 本文提出了一种用于地震层位解释的混合框架，结合了改进的U-Net架构和空间聚类技术，在稀疏标注条件下实现了高精度的层位追踪。


<details>
  <summary>Details</summary>
Motivation: 地震层位解释对油气勘探至关重要，但现有深度学习方法在处理复杂地质特征和稀疏标注时仍面临挑战，需要提高层位连续性和几何保真度。

Method: 提出了Context Fusion Attention (CFA) U-Net架构，融合空间和Sobel几何特征于注意力门中；评估了五种架构（标准U-Net、压缩U-Net、U-Net++、Attention U-Net和CFA U-Net）；使用DBSCAN聚类优化层位预测；在不同数据稀疏度（10、20、40线间距）下进行系统评估。

Result: 在墨西哥利昂油田数据集上获得验证IoU 0.881和MAE 2.49ms的最佳性能；在北海F3区块稀疏条件下实现97.6%的表面覆盖率；通过DBSCAN聚类生成地质上合理的层位表面。

Conclusion: 混合方法和基于几何上下文增强的注意力架构为结构复杂和数据稀缺环境中的地震解释提供了鲁棒且可推广的解决方案，展示了融合几何特征的注意力机制在提升层位追踪精度和连续性方面的优势。

Abstract: Interpreting seismic horizons is a critical task for characterizing subsurface structures in hydrocarbon exploration. Recent advances in deep learning, particularly U-Net-based architectures, have significantly improved automated horizon tracking. However, challenges remain in accurately segmenting complex geological features and interpolating horizons from sparse annotations. To address these issues, a hybrid framework is presented that integrates advanced U-Net variants with spatial clustering to enhance horizon continuity and geometric fidelity. The core contribution is the Context Fusion Attention (CFA) U-Net, a novel architecture that fuses spatial and Sobel-derived geometric features within attention gates to improve both precision and surface completeness. The performance of five architectures, the U-Net (Standard and compressed), U-Net++, Attention U-Net, and CFA U-Net, was systematically evaluated across various data sparsity regimes (10-, 20-, and 40-line spacing). This approach outperformed existing baselines, achieving state-of-the-art results on the Mexilhao field (Santos Basin, Brazil) dataset with a validation IoU of 0.881 and MAE of 2.49ms, and excellent surface coverage of 97.6% on the F3 Block of the North Sea dataset under sparse conditions. The framework further refines merged horizon predictions (inline and cross-line) using Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to produce geologically plausible surfaces. The results demonstrate the advantages of hybrid methodologies and attention-based architectures enhanced with geometric context, providing a robust and generalizable solution for seismic interpretation in structurally complex and data-scarce environments.

</details>


### [6] [Constructing Efficient Fact-Storing MLPs for Transformers](https://arxiv.org/abs/2512.00207)
*Owen Dugan,Roberto Garcia,Ronny Junkins,Jerry Liu,Dylan Zinsley,Sabri Eyuboglu,Atri Rudra,Chris Ré*

Main category: cs.LG

TL;DR: 本文提出了一种改进的MLP构建框架，用于在大语言模型中高效存储事实知识作为键值映射，相比之前的方法在通用性、参数效率和Transformer兼容性方面都有提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型成功的关键在于其能够将事实知识作为键值映射高效存储在MLP参数中。现有研究提出了显式权重构建方法来构建这种事实存储MLP，但需要进一步改进以更好地理解LLM事实存储机制。

Method: 引入一个MLP构建框架，该框架：1) 适用于几乎所有可行的输入-输出对；2) 在某些嵌入情况下达到渐近最优参数效率，匹配信息论界限；3) 保持Transformer内部的事实回忆可用性。

Result: 通过改进发现：1) 值嵌入的度量特征化构造和梯度下降训练MLP的事实-参数缩放；2) 识别出简单编码器-解码器机制，经验上匹配梯度下降MLP在所有测试输入输出中的事实-参数渐近特性；3) 揭示MLP事实存储容量与其在Transformer中可用性之间的基本权衡。

Conclusion: 该MLP构建框架不仅改进了事实存储机制的理解，还展示了实际应用：通过一次性替换整个MLP来实现单层Transformer上的模块化事实编辑。

Abstract: The success of large language models (LLMs) can be attributed in part to their ability to efficiently store factual knowledge as key-value mappings within their MLP parameters. Recent work has proposed explicit weight constructions to build such fact-storing MLPs, providing an improved understanding of LLM fact storage mechanisms. In this paper, we introduce an MLP construction framework that improves over previous constructions in three areas: it 1) works for all but a measure-zero set of feasible input-output pairs, 2) achieves asymptotically optimal parameter efficiency matching information-theoretic bounds for some embeddings, and 3) maintains usability within Transformers for factual recall. Through our improvements, we 1) discover a metric on value embeddings that characterizes facts-per-parameter scaling for both constructed and gradient-descent-trained MLPs, 2) identify a simple encoder-decoder mechanism that empirically matches gradient-descent MLP facts-per-parameter asymptotics across all the inputs and outputs we test, and 3) uncover a fundamental tradeoff between an MLP's fact-storage capacity and its usability within Transformers. Finally, we demonstrate a proof-of-concept application of fact-storing MLPs: modular fact editing on one-layer Transformers by \textit{replacing entire MLPs at once}.

</details>


### [7] [Self-Supervised Dynamical System Representations for Physiological Time-Series](https://arxiv.org/abs/2512.00239)
*Yenho Chen,Maxwell A. Xu,James M. Rehg,Christopher J. Rozell*

Main category: cs.LG

TL;DR: 提出PULSE框架，通过跨重建预训练目标从生理时间序列中提取系统参数信息，同时丢弃样本特异性噪声，提升自监督学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有生理时间序列的自监督学习方法依赖启发式原则或约束不足的生成任务，无法有效分离生理状态信息和噪声，限制了表示学习的效果。

Method: 提出PULSE框架，基于动态系统生成模型的信息结构，通过跨重建预训练目标显式提取共享的系统参数信息，同时丢弃样本特异性噪声。

Result: 理论分析提供了系统信息可恢复的充分条件，合成动态系统实验验证了理论，真实世界数据集实验表明PULSE能区分语义类别、提高标签效率和改善迁移学习。

Conclusion: PULSE框架通过利用动态系统生成模型的信息结构，有效提取生理时间序列中的系统参数信息，为生理时间序列的自监督学习提供了理论基础和实用方法。

Abstract: The effectiveness of self-supervised learning (SSL) for physiological time series depends on the ability of a pretraining objective to preserve information about the underlying physiological state while filtering out unrelated noise. However, existing strategies are limited due to reliance on heuristic principles or poorly constrained generative tasks. To address this limitation, we propose a pretraining framework that exploits the information structure of a dynamical systems generative model across multiple time-series. This framework reveals our key insight that class identity can be efficiently captured by extracting information about the generative variables related to the system parameters shared across similar time series samples, while noise unique to individual samples should be discarded. Building on this insight, we propose PULSE, a cross-reconstruction-based pretraining objective for physiological time series datasets that explicitly extracts system information while discarding non-transferrable sample-specific ones. We establish theory that provides sufficient conditions for the system information to be recovered, and empirically validate it using a synthetic dynamical systems experiment. Furthermore, we apply our method to diverse real-world datasets, demonstrating that PULSE learns representations that can broadly distinguish semantic classes, increase label efficiency, and improve transfer learning.

</details>


### [8] [BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models](https://arxiv.org/abs/2512.00283)
*Yi Fang,Haoran Xu,Jiaxin Han,Sirui Ding,Yizhi Wang,Yue Wang,Xuan Wang*

Main category: cs.LG

TL;DR: BioArc框架通过神经架构搜索为生物数据自动发现最优基础模型架构，超越直觉驱动设计，提供系统化方法论


<details>
  <summary>Details</summary>
Motivation: 现有生物基础模型直接采用通用AI架构，未考虑生物数据的独特物理化学和结构特性，导致性能不佳，无法捕捉生物数据的长程依赖、稀疏信息和复杂"语法"

Method: 提出BioArc框架，利用神经架构搜索系统探索架构设计空间，评估多种生物模态，分析架构、分词和训练策略的相互作用，并开发架构预测方法为新任务预测最优架构

Result: 大规模分析发现新颖高性能架构，提炼出一套经验设计原则指导未来模型开发，并提供有效的架构预测方法

Conclusion: BioArc为下一代生物任务特定模型和基础模型提供了基础资源和原则性方法论，推动生物AI从直觉驱动向系统化架构设计转变

Abstract: Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars'' inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.

</details>


### [9] [Challenges of Heterogeneity in Big Data: A Comparative Study of Classification in Large-Scale Structured and Unstructured Domains](https://arxiv.org/abs/2512.00298)
*González Trigueros Jesús Eduardo,Alonso Sánchez Alejandro,Muñoz Rivera Emilio,Peñarán Prieto Mariana Jaqueline,Mendoza González Camila Natalia*

Main category: cs.LG

TL;DR: 研究分析了大数据异质性对分类策略的影响，发现高维数值数据中优化线性模型优于复杂模型，而文本数据中简单模型配合特征工程效果更好。


<details>
  <summary>Details</summary>
Motivation: 研究动机是分析大数据异质性（"多样性"）对分类策略的影响，比较结构化（数值）和非结构化（文本）数据领域的分类方法效果差异。

Method: 采用双重方法论：针对数值数据使用进化和贝叶斯超参数优化（遗传算法、Optuna），针对大规模文本语料使用Apache Spark分布式处理。使用Transformer嵌入（ROBERTa）和贝叶斯目标编码进行特征工程。

Result: 发现"复杂性悖论"：在高维数值空间（Epsilon数据集）中，优化后的线性模型（SVM、逻辑回归）优于深度架构和梯度提升；而在文本领域（Rest-Mex、IMDB），复杂模型因分布式微调限制而过拟合，简单模型配合特征工程泛化效果更好。

Conclusion: 研究提出了基于数据特性和基础设施约束的统一算法选择框架，为大数据分类任务提供了方法论指导。

Abstract: This study analyzes the impact of heterogeneity ("Variety") in Big Data by comparing classification strategies across structured (Epsilon) and unstructured (Rest-Mex, IMDB) domains. A dual methodology was implemented: evolutionary and Bayesian hyperparameter optimization (Genetic Algorithms, Optuna) in Python for numerical data, and distributed processing in Apache Spark for massive textual corpora. The results reveal a "complexity paradox": in high-dimensional spaces, optimized linear models (SVM, Logistic Regression) outperformed deep architectures and Gradient Boosting. Conversely, in text-based domains, the constraints of distributed fine-tuning led to overfitting in complex models, whereas robust feature engineering -- specifically Transformer-based embeddings (ROBERTa) and Bayesian Target Encoding -- enabled simpler models to generalize effectively. This work provides a unified framework for algorithm selection based on data nature and infrastructure constraints.

</details>


### [10] [Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models](https://arxiv.org/abs/2506.10177)
*Defang Chen,Zhenyu Zhou,Can Wang,Siwei Lyu*

Main category: cs.LG

TL;DR: 扩散生成模型的确定性采样轨迹具有惊人的几何规律性：所有轨迹都位于极低维子空间中，呈现几乎相同的"回旋镖"形状，且不受模型架构、条件或生成内容影响。


<details>
  <summary>Details</summary>
Motivation: 揭示扩散生成模型中确定性采样动态的几何规律性，理解采样轨迹的结构特征，并利用这些发现改进采样效率。

Method: 分析扩散生成模型的确定性采样轨迹，发现其位于极低维子空间且形状相似；基于核估计数据建模的闭式解研究轨迹特性；提出基于动态规划的方案，使采样时间表与轨迹结构更好对齐。

Result: 发现扩散生成模型的采样轨迹具有惊人的几何规律性：所有轨迹都位于极低维子空间，呈现几乎相同的"回旋镖"形状；提出的动态规划方案只需对现有数值求解器进行最小修改，计算开销可忽略，在5-10次函数评估区域显著提升图像生成性能。

Conclusion: 扩散生成模型的确定性采样轨迹展现出强烈的几何规律性，这一发现不仅深化了对采样过程的理解，而且可以用于设计更高效的采样策略，通过使采样时间表与轨迹结构对齐来提升生成质量。

Abstract: Diffusion-based generative models employ stochastic differential equations (SDEs) and their equivalent probability flow ordinary differential equations (ODEs) to establish a smooth transformation between complex high-dimensional data distributions and tractable prior distributions. In this paper, we reveal a striking geometric regularity in the deterministic sampling dynamics of diffusion generative models: each simulated sampling trajectory along the gradient field lies within an extremely low-dimensional subspace, and all trajectories exhibit an almost identical boomerang shape, regardless of the model architecture, applied conditions, or generated content. We characterize several intriguing properties of these trajectories, particularly under closed-form solutions based on kernel-estimated data modeling. We also demonstrate a practical application of the discovered trajectory regularity by proposing a dynamic programming-based scheme to better align the sampling time schedule with the underlying trajectory structure. This simple strategy requires minimal modification to existing deterministic numerical solvers, incurs negligible computational overhead, and achieves superior image generation performance, especially in regions with only 5 - 10 function evaluations.

</details>


### [11] [Gradient Inversion in Federated Reinforcement Learning](https://arxiv.org/abs/2512.00303)
*Shenghong He*

Main category: cs.LG

TL;DR: RGIA是一种针对联邦强化学习的梯度反演攻击方法，通过引入状态、奖励和转移动态的先验知识正则化，确保重构数据符合真实环境转移分布，从而成功恢复本地私有数据。


<details>
  <summary>Details</summary>
Motivation: 联邦强化学习虽然通过梯度共享保护数据隐私，但仍面临隐私泄露风险。与传统监督联邦学习不同，FRL中的成功重构不仅需要匹配共享梯度，还需要与环境的真实转移动态保持一致。现有攻击方法难以同时满足这两个条件。

Method: 提出正则化梯度反演攻击（RGIA），在优化过程中对状态、奖励和转移动态施加基于先验知识的正则化约束，确保重构数据接近真实转移分布。理论证明该正则化项将解空间从包含虚假解的广泛集合缩小到同时满足梯度匹配和真实转移动态的约束子集。

Result: 在控制任务和自动驾驶任务上的大量实验表明，RGIA能够有效约束重构数据的转移分布，从而成功重构本地私有数据。

Conclusion: RGIA通过引入先验知识正则化，解决了FRL中梯度反演攻击的关键挑战，即确保重构数据符合真实环境动态，为FRL的隐私保护提出了新的安全挑战。

Abstract: Federated reinforcement learning (FRL) enables distributed learning of optimal policies while preserving local data privacy through gradient sharing.However, FRL faces the risk of data privacy leaks, where attackers exploit shared gradients to reconstruct local training data.Compared to traditional supervised federated learning, successful reconstruction in FRL requires the generated data not only to match the shared gradients but also to align with real transition dynamics of the environment (i.e., aligning with the real data transition distribution).To address this issue, we propose a novel attack method called Regularization Gradient Inversion Attack (RGIA), which enforces prior-knowledge-based regularization on states, rewards, and transition dynamics during the optimization process to ensure that the reconstructed data remain close to the true transition distribution.Theoretically, we prove that the prior-knowledge-based regularization term narrows the solution space from a broad set containing spurious solutions to a constrained subset that satisfies both gradient matching and true transition dynamics.Extensive experiments on control tasks and autonomous driving tasks demonstrate that RGIA can effectively constrain reconstructed data transition distributions and thus successfully reconstruct local private data.

</details>


### [12] [Tracing Mathematical Proficiency Through Problem-Solving Processes](https://arxiv.org/abs/2512.00311)
*Jungyang Park,Suho Kang,Jaewoo Park,Jaehong Kim,Jaewoo Shin,Seonjoon Park,Youngjae Yu*

Main category: cs.LG

TL;DR: 该研究提出KT-PSP框架，通过整合学生解题过程信息来改进知识追踪，并引入StatusKT三阶段LLM管道来提取数学能力指标，在KT-PSP-25数据集上验证了性能提升和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统知识追踪方法仅依赖答题正确性，缺乏可解释性，忽略了学生解题过程中蕴含的丰富信息，无法全面评估学生的数学能力。

Method: 提出KT-PSP框架整合解题过程信息，并设计StatusKT三阶段LLM管道：教师LLM提取问题特定能力指标，学生LLM基于解题过程生成回答，教师LLM评估回答确定指标掌握程度。

Result: 在KT-PSP-25数据集上的实验表明，StatusKT显著提升了现有知识追踪方法的预测性能，同时通过显式建模学生数学能力提供了可解释的预测解释。

Conclusion: 通过整合学生解题过程信息，KT-PSP框架能够更全面、可解释地追踪学生知识状态，为个性化学习系统提供更有效的支持。

Abstract: Knowledge Tracing (KT) aims to model student's knowledge state and predict future performance to enable personalized learning in Intelligent Tutoring Systems. However, traditional KT methods face fundamental limitations in explainability, as they rely solely on the response correctness, neglecting the rich information embedded in students' problem-solving processes. To address this gap, we propose Knowledge Tracing Leveraging Problem-Solving Process (KT-PSP), which incorporates students' problem-solving processes to capture the multidimensional aspects of mathematical proficiency. We also introduce KT-PSP-25, a new dataset specifically designed for the KT-PSP. Building on this, we present StatusKT, a KT framework that employs a teacher-student-teacher three-stage LLM pipeline to extract students' MP as intermediate signals. In this pipeline, the teacher LLM first extracts problem-specific proficiency indicators, then a student LLM generates responses based on the student's solution process, and a teacher LLM evaluates these responses to determine mastery of each indicator. The experimental results on KT-PSP-25 demonstrate that StatusKT improves the prediction performance of existing KT methods. Moreover, StatusKT provides interpretable explanations for its predictions by explicitly modeling students' mathematical proficiency.

</details>


### [13] [Introducing AI-Driven IoT Energy Management Framework](https://arxiv.org/abs/2512.00321)
*Shivani Mruthyunjaya,Anandi Dutta,Kazi Sifatul Islam*

Main category: cs.LG

TL;DR: 提出一个面向物联网系统的整体框架，通过上下文决策、主动适应和可扩展结构来降低能耗并支持电网稳定


<details>
  <summary>Details</summary>
Motivation: 现代生活对技术进步的持续依赖使得电力消耗成为关键问题，降低能耗或遵循用电预测可以降低月度成本并提高电力可靠性

Method: 提出一个整体框架，建立物联网系统基础，专注于上下文决策、主动适应和可扩展结构，包括长期预测、短期预测、异常检测和定性数据考虑

Result: 在电力消耗时间序列数据上评估性能，展示了框架的直接应用可行性

Conclusion: 通过框架各个方面的应用展示了该提案的可行性，系统将支持降低能耗和电网稳定

Abstract: Power consumption has become a critical aspect of modern life due to the consistent reliance on technological advancements. Reducing power consumption or following power usage predictions can lead to lower monthly costs and improved electrical reliability. The proposal of a holistic framework to establish a foundation for IoT systems with a focus on contextual decision making, proactive adaptation, and scalable structure. A structured process for IoT systems with accuracy and interconnected development would support reducing power consumption and support grid stability. This study presents the feasibility of this proposal through the application of each aspect of the framework. This system would have long term forecasting, short term forecasting, anomaly detection, and consideration of qualitative data with any energy management decisions taken. Performance was evaluated on Power Consumption Time Series data to display the direct application of the framework.

</details>


### [14] [Adaptive prediction theory combining offline and online learning](https://arxiv.org/abs/2512.00342)
*Haizheng Li,Lei Guo*

Main category: cs.LG

TL;DR: 该论文提出了一个结合离线学习和在线适应的两阶段学习框架，用于非线性随机动力系统的预测，理论分析了相关非平稳数据下的性能，并提出了meta-LMS在线预测算法。


<details>
  <summary>Details</summary>
Motivation: 现实智能系统通常结合离线学习和在线适应来处理高度相关且非平稳的系统数据，但现有文献缺乏对此的理论研究。本文旨在理论分析这种两阶段学习框架在非线性随机动力系统中的预测性能。

Method: 1. 离线学习阶段：建立近似非线性最小二乘估计在强相关数据和分布偏移下的泛化误差上界，利用KL散度量化分布差异；2. 在线适应阶段：基于离线训练模型，提出meta-LMS预测算法处理实际系统中可能的不确定参数漂移。

Result: 该两阶段框架（离线学习+在线适应）相比纯离线或纯在线方法展现出更优越的预测性能。研究提供了理论保证和实证研究支持。

Conclusion: 本文首次理论研究了结合离线学习和在线适应的两阶段学习框架在非线性随机动力系统中的预测性能，为处理现实世界中相关非平稳数据提供了理论依据和有效方法。

Abstract: Real-world intelligence systems usually operate by combining offline learning and online adaptation with highly correlated and non-stationary system data or signals, which, however, has rarely been investigated theoretically in the literature. This paper initiates a theoretical investigation on the prediction performance of a two-stage learning framework combining offline and online algorithms for a class of nonlinear stochastic dynamical systems. For the offline-learning phase, we establish an upper bound on the generalization error for approximate nonlinear-least-squares estimation under general datasets with strong correlation and distribution shift, leveraging the Kullback-Leibler divergence to quantify the distributional discrepancies. For the online-adaptation phase, we address, on the basis of the offline-trained model, the possible uncertain parameter drift in real-world target systems by proposing a meta-LMS prediction algorithm. This two-stage framework, integrating offline learning with online adaptation, demonstrates superior prediction performances compared with either purely offline or online methods. Both theoretical guarantees and empirical studies are provided.

</details>


### [15] [Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning](https://arxiv.org/abs/2512.00351)
*Na Li,Yuchen Jiao,Hangguan Shan,Shefeng Yan*

Main category: cs.LG

TL;DR: 提出了一种名为ME-Nash-QL的新型模型无关自博弈算法，用于解决双人零和马尔可夫博弈问题，在空间复杂度、样本复杂度、计算复杂度和启动成本方面均优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体强化学习理论研究存在多个障碍：内存效率低、样本复杂度严重依赖长时域和大状态空间、计算复杂度高、非马尔可夫策略、非纳什策略以及高启动成本。本文旨在解决这些问题。

Method: 设计了一种模型无关的自博弈算法ME-Nash-QL（内存高效的纳什Q学习），专门针对双人零和马尔可夫博弈。该算法通过优化存储结构和学习过程来降低各种复杂度。

Result: ME-Nash-QL算法在多个维度上表现出色：1）空间复杂度为O(SABH)，样本复杂度为Õ(H⁴SAB/ε²)；2）计算复杂度为O(T·poly(AB))；3）启动成本为O(SAB·poly(H))，均优于现有算法。

Conclusion: ME-Nash-QL算法在双人零和马尔可夫博弈中实现了内存效率、样本效率、计算效率和低启动成本的平衡，为多智能体强化学习理论提供了更优的解决方案。

Abstract: The thriving field of multi-agent reinforcement learning (MARL) studies how a group of interacting agents make decisions autonomously in a shared dynamic environment. Existing theoretical studies in this area suffer from at least two of the following obstacles: memory inefficiency, the heavy dependence of sample complexity on the long horizon and the large state space, the high computational complexity, non-Markov policy, non-Nash policy, and high burn-in cost. In this work, we take a step towards settling this problem by designing a model-free self-play algorithm \emph{Memory-Efficient Nash Q-Learning (ME-Nash-QL)} for two-player zero-sum Markov games, which is a specific setting of MARL. ME-Nash-QL is proven to enjoy the following merits. First, it can output an $\varepsilon$-approximate Nash policy with space complexity $O(SABH)$ and sample complexity $\widetilde{O}(H^4SAB/\varepsilon^2)$, where $S$ is the number of states, $\{A, B\}$ is the number of actions for two players, and $H$ is the horizon length. It outperforms existing algorithms in terms of space complexity for tabular cases, and in terms of sample complexity for long horizons, i.e., when $\min\{A, B\}\ll H^2$. Second, ME-Nash-QL achieves the lowest computational complexity $O(T\mathrm{poly}(AB))$ while preserving Markov policies, where $T$ is the number of samples. Third, ME-Nash-QL also achieves the best burn-in cost $O(SAB\,\mathrm{poly}(H))$, whereas previous algorithms have a burn-in cost of at least $O(S^3 AB\,\mathrm{poly}(H))$ to attain the same level of sample complexity with ours.

</details>


### [16] [Sample-Efficient Tabular Self-Play for Offline Robust Reinforcement Learning](https://arxiv.org/abs/2512.00352)
*Na Li,Zewu Zheng,Wei Ni,Hangguan Shan,Wenjie Zhang,Xinyu Li*

Main category: cs.LG

TL;DR: 提出RTZ-VI-LCB算法，用于离线鲁棒双人零和马尔可夫博弈，通过乐观鲁棒值迭代与数据驱动的Bernstein惩罚项实现最优样本复杂度


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中，由于环境不确定性，策略需要保持鲁棒性以应对仿真到现实的差距。本文专注于离线环境下的鲁棒双人零和马尔可夫博弈，旨在解决历史数据分布偏移和环境不确定性问题。

Method: 提出RTZ-VI-LCB算法，结合乐观鲁棒值迭代与数据驱动的Bernstein风格惩罚项进行鲁棒值估计，考虑历史数据集的分布偏移。

Result: 算法在部分覆盖和环境不确定性下建立了接近最优的样本复杂度保证，并开发了信息论下界证明样本复杂度关于状态和动作空间的最优性，实验验证了算法有效性。

Conclusion: RTZ-VI-LCB是首个达到最优样本复杂度的算法，为离线鲁棒双人零和马尔可夫博弈设立了新基准，并通过实验验证了其有效性。

Abstract: Multi-agent reinforcement learning (MARL), as a thriving field, explores how multiple agents independently make decisions in a shared dynamic environment. Due to environmental uncertainties, policies in MARL must remain robust to tackle the sim-to-real gap. We focus on robust two-player zero-sum Markov games (TZMGs) in offline settings, specifically on tabular robust TZMGs (RTZMGs). We propose a model-based algorithm (\textit{RTZ-VI-LCB}) for offline RTZMGs, which is optimistic robust value iteration combined with a data-driven Bernstein-style penalty term for robust value estimation. By accounting for distribution shifts in the historical dataset, the proposed algorithm establishes near-optimal sample complexity guarantees under partial coverage and environmental uncertainty. An information-theoretic lower bound is developed to confirm the tightness of our algorithm's sample complexity, which is optimal regarding both state and action spaces. To the best of our knowledge, RTZ-VI-LCB is the first to attain this optimality, sets a new benchmark for offline RTZMGs, and is validated experimentally.

</details>


### [17] [Learning Causal States Under Partial Observability and Perturbation](https://arxiv.org/abs/2512.00357)
*Na Li,Hangguan Shan,Wei Ni,Wenjie Zhang,Xinyu Li,Yamin Wang*

Main category: cs.LG

TL;DR: CaDiff是一个结合异步扩散模型和双模拟度量的框架，用于在扰动部分可观测MDP中增强RL算法，通过揭示因果结构提升决策性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习在基于不完整和噪声观测进行决策时面临挑战，特别是在扰动部分可观测MDP中。现有方法无法同时处理扰动和部分可观测性问题。

Method: 提出CaDiff框架，包含异步扩散模型（ADM）和新双模拟度量。ADM允许前向和反向过程步数不同，将扰动视为扩散过程中抑制的噪声；双模拟度量量化部分可观测环境与其因果对应物之间的相似性。

Result: 在Roboschool任务上的实验表明，CaDiff相比基线方法至少提升14.18%的回报。建立了理论保证，推导了扰动观测与去噪因果状态之间值函数近似误差的上界。

Conclusion: CaDiff是首个使用扩散模型近似因果状态的框架，兼具理论严谨性和实用性，能有效处理扰动部分可观测MDP中的决策问题。

Abstract: A critical challenge for reinforcement learning (RL) is making decisions based on incomplete and noisy observations, especially in perturbed and partially observable Markov decision processes (P$^2$OMDPs). Existing methods fail to mitigate perturbations while addressing partial observability. We propose \textit{Causal State Representation under Asynchronous Diffusion Model (CaDiff)}, a framework that enhances any RL algorithm by uncovering the underlying causal structure of P$^2$OMDPs. This is achieved by incorporating a novel asynchronous diffusion model (ADM) and a new bisimulation metric. ADM enables forward and reverse processes with different numbers of steps, thus interpreting the perturbation of P$^2$OMDP as part of the noise suppressed through diffusion. The bisimulation metric quantifies the similarity between partially observable environments and their causal counterparts. Moreover, we establish the theoretical guarantee of CaDiff by deriving an upper bound for the value function approximation errors between perturbed observations and denoised causal states, reflecting a principled trade-off between approximation errors of reward and transition-model. Experiments on Roboschool tasks show that CaDiff enhances returns by at least 14.18\% compared to baselines. CaDiff is the first framework that approximates causal states using diffusion models with both theoretical rigor and practicality.

</details>


### [18] [S^2-KD: Semantic-Spectral Knowledge Distillation Spatiotemporal Forecasting](https://arxiv.org/abs/2512.00366)
*Wenshuo Wang,Yaomin Shen,Yingjie Tan,Yihao Chen*

Main category: cs.LG

TL;DR: S^2-KD：结合语义先验与频谱表示的知识蒸馏框架，通过多模态教师模型将语义因果推理与频谱分解知识传递给轻量级视觉学生模型，提升时空预测性能


<details>
  <summary>Details</summary>
Motivation: 现有基于知识蒸馏的时空预测方法主要关注像素级信号和频谱特性，但忽略了视觉模式背后丰富的语义和因果上下文信息，这限制了模型对复杂动态的理解和预测能力

Method: 提出S^2-KD框架：1）训练特权多模态教师模型，利用大型多模态模型（LMM）的文本叙述进行事件因果推理，同时在潜在空间解耦频谱分量；2）设计新的蒸馏目标，将统一的语义-频谱知识传递给轻量级纯视觉学生模型

Result: 在WeatherBench和TaxiBJ+等基准测试中，S^2-KD显著提升了简单学生模型的性能，使其在长时程和复杂非平稳场景下超越现有最先进方法

Conclusion: 通过统一语义先验与频谱表示的知识蒸馏，S^2-KD能够创建既保持频谱准确性又具有语义一致性的轻量级预测模型，无需推理时的文本输入或额外架构开销

Abstract: Spatiotemporal forecasting often relies on computationally intensive models to capture complex dynamics. Knowledge distillation (KD) has emerged as a key technique for creating lightweight student models, with recent advances like frequency-aware KD successfully preserving spectral properties (i.e., high-frequency details and low-frequency trends). However, these methods are fundamentally constrained by operating on pixel-level signals, leaving them blind to the rich semantic and causal context behind the visual patterns. To overcome this limitation, we introduce S^2-KD, a novel framework that unifies Semantic priors with Spectral representations for distillation. Our approach begins by training a privileged, multimodal teacher model. This teacher leverages textual narratives from a Large Multimodal Model (LMM) to reason about the underlying causes of events, while its architecture simultaneously decouples spectral components in its latent space. The core of our framework is a new distillation objective that transfers this unified semantic-spectral knowledge into a lightweight, vision-only student. Consequently, the student learns to make predictions that are not only spectrally accurate but also semantically coherent, without requiring any textual input or architectural overhead at inference. Extensive experiments on benchmarks like WeatherBench and TaxiBJ+ show that S^2-KD significantly boosts the performance of simple student models, enabling them to outperform state-of-the-art methods, particularly in long-horizon and complex non-stationary scenarios.

</details>


### [19] [An Empirical Study on the Effectiveness of Incorporating Offline RL As Online RL Subroutines](https://arxiv.org/abs/2512.00383)
*Jianhai Su,Jinzhu Luo,Qi Zhang*

Main category: cs.LG

TL;DR: 将离线强化学习算法作为在线强化学习的子程序，利用历史交互数据作为离线数据集，提出框架并改进技术以提升在线学习效率


<details>
  <summary>Details</summary>
Motivation: 探索如何将离线强化学习算法整合到在线强化学习中，利用智能体历史交互数据作为离线数据集，以提高在线学习效率

Method: 提出一个框架，将离线RL算法作为在线RL的子程序，支持最终策略推荐和在线微调等变体，并引入技术改进其有效性

Result: 系统性实证分析显示：1）框架有效性强烈依赖任务性质；2）提出的技术显著提升有效性；3）现有在线微调方法整体效果不佳

Conclusion: 将离线RL作为在线RL子程序是可行的，但需要根据任务特性调整，现有在线微调方法需要更多研究改进

Abstract: We take the novel perspective of incorporating offline RL algorithms as subroutines of tabula rasa online RL. This is feasible because an online learning agent can repurpose its historical interactions as offline dataset. We formalize this idea into a framework that accommodates several variants of offline RL incorporation such as final policy recommendation and online fine-tuning. We further introduce convenient techniques to improve its effectiveness in enhancing online learning efficiency. Our extensive and systematic empirical analyses show that 1) the effectiveness of the proposed framework depends strongly on the nature of the task, 2) our proposed techniques greatly enhance its effectiveness, and 3) existing online fine-tuning methods are overall ineffective, calling for more research therein.

</details>


### [20] [Efficient and Programmable Exploration of Synthesizable Chemical Space](https://arxiv.org/abs/2512.00384)
*Shitong Luo,Connor W. Coley*

Main category: cs.LG

TL;DR: PrexSyn是一个基于解码器Transformer的高效可编程分子发现模型，专门用于在可合成化学空间中生成具有目标性质的分子，通过大规模训练数据和实时数据生成引擎实现高效采样和优化。


<details>
  <summary>Details</summary>
Motivation: 可合成化学空间的受限性使得同时满足可合成性和目标性质的分子采样面临重大挑战，需要开发能够高效探索可合成化学空间并关联分子性质与合成路径的模型。

Method: 基于解码器Transformer架构，在十亿级可合成路径与分子性质配对的数据流上进行训练，使用C++实时高通量数据生成引擎，学习性质-路径映射关系，支持逻辑运算符组合的复合性质查询。

Result: PrexSyn能够近乎完美地重建可合成化学空间，实现高速推理，支持单性质和复合性质条件生成，通过迭代查询优化在黑盒函数优化中达到比合成无关基线更高的采样效率。

Conclusion: PrexSyn在可合成化学空间覆盖度、分子采样效率和推理速度方面达到了新的最先进水平，推动了可合成分子设计的前沿发展。

Abstract: The constrained nature of synthesizable chemical space poses a significant challenge for sampling molecules that are both synthetically accessible and possess desired properties. In this work, we present PrexSyn, an efficient and programmable model for molecular discovery within synthesizable chemical space. PrexSyn is based on a decoder-only transformer trained on a billion-scale datastream of synthesizable pathways paired with molecular properties, enabled by a real-time, high-throughput C++-based data generation engine. The large-scale training data allows PrexSyn to reconstruct the synthesizable chemical space nearly perfectly at a high inference speed and learn the association between properties and synthesizable molecules. Based on its learned property-pathway mappings, PrexSyn can generate synthesizable molecules that satisfy not only single-property conditions but also composite property queries joined by logical operators, thereby allowing users to ``program'' generation objectives. Moreover, by exploiting this property-based querying capability, PrexSyn can efficiently optimize molecules against black-box oracle functions via iterative query refinement, achieving higher sampling efficiency than even synthesis-agnostic baselines, making PrexSyn a powerful general-purpose molecular optimization tool. Overall, PrexSyn pushes the frontier of synthesizable molecular design by setting a new state of the art in synthesizable chemical space coverage, molecular sampling efficiency, and inference speed.

</details>


### [21] [From Coefficients to Directions: Rethinking Model Merging with Directional Alignment](https://arxiv.org/abs/2512.00391)
*Zhikang Chen,Sen Cui,Deheng Ye,Min Zhang,Gang Niu,Yu Zhang,Masashi Sugiyama,Tingting Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种基于方向对齐的模型合并新框架，强调参数空间和特征空间中的方向信息对齐对于保持模型结构一致性的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法主要关注参数空间分解或融合系数优化，忽视了参数和特征空间中的方向信息对齐。朴素合并会导致主导参数方向不一致并破坏模型间的结构连贯性，而基于系数优化的方法隐含假设不同模型的特征空间方向兼容，但神经崩溃现象表明独立训练模型的类别特征可能遵循不同的方向模式。

Method: 提出统一几何框架Merging with Directional Alignment，在参数空间和特征空间中一致地对齐方向结构，通过方向对齐来改善结构连贯性。

Result: 分析表明方向对齐能改善结构连贯性，在多个基准测试、模型规模和任务配置上的广泛实验验证了该方法的有效性。

Conclusion: 方向对齐是模型合并中的关键因素，提出的统一几何框架能有效对齐参数和特征空间的方向结构，提升合并模型的性能。

Abstract: Model merging has emerged as a practical paradigm for integrating multiple independently trained models into a single model without joint retraining. Previous studies have demonstrated the effectiveness of combining parameters through strategies such as parameter decomposition, coefficient optimization, and subspace learning, significantly reducing the need for expensive joint training and achieving strong empirical performance across diverse tasks. However, these approaches predominantly treat merging as a problem of parameter space decomposition or fusion coefficient optimization, while overlooking the critical role of directional information in both parameter and feature spaces. In practice, naïve merging introduces inconsistencies in dominant parameter directions and disrupts structural coherence across models, which can degrade performance. Moreover, coefficient-based optimization methods implicitly assume compatible feature-space directions across models. However, Neural Collapse indicates that class features follow structured directional patterns, which may differ across independently trained models, making coefficient optimization alone insufficient. In this work, we emphasize the importance of \emph{directional alignment} and introduce a unified geometric framework, \emph{Merging with Directional Alignment} (\method{}), which aligns directional structures consistently in both the parameter and feature spaces. Our analysis shows that directional alignment improves structural coherence, and extensive experiments across benchmarks, model scales, and task configurations further validate the effectiveness of our approach.

</details>


### [22] [Time-Series at the Edge: Tiny Separable CNNs for Wearable Gait Detection and Optimal Sensor Placement](https://arxiv.org/abs/2512.00396)
*Andrea Procopio,Marco Esposito,Sara Raggiunto,Andrey Gizdov,Alberto Belli,Paola Pierleoni*

Main category: cs.LG

TL;DR: 该研究开发了用于帕金森病步态检测的超轻量1D CNN模型，在资源受限的可穿戴设备上实现了高精度检测，参数数量仅为传统方法的1/10。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决帕金森病步态检测在资源受限的可穿戴设备和边缘节点上的部署问题，需要开发既准确又高效的模型以适应设备的内存和延迟限制。

Method: 使用BioStampRC21数据集，比较幅度阈值法与三种1D CNN模型：文献基线（可分离卷积）、纯可分离模型和带残差连接的超轻模型。采用2秒窗口、30Hz采样率和留一受试者交叉验证方法。

Result: 残差可分离模型（533参数）达到PR-AUC=94.5%，F1=91.2%，MCC=89.4%，性能优于基线模型（5552参数）。最小模型（305参数）也表现优异。传感器位置分析显示胸部和腿部最可靠。

Conclusion: 超轻量可分离CNN在帕金森病步态检测中提供了优于固定阈值方法的精度-效率-泛化权衡，证明了为边缘部署定制时间序列模型的价值。

Abstract: We study on-device time-series analysis for gait detection in Parkinson's disease (PD) from short windows of triaxial acceleration, targeting resource-constrained wearables and edge nodes. We compare magnitude thresholding to three 1D CNNs for time-series analysis: a literature baseline (separable convolutions) and two ultra-light models - one purely separable and one with residual connections. Using the BioStampRC21 dataset, 2 s windows at 30 Hz, and subject-independent leave-one-subject-out (LOSO) validation on 16 PwPD with chest-worn IMUs, our residual separable model (Model 2, 533 params) attains PR-AUC = 94.5%, F1 = 91.2%, MCC = 89.4%, matching or surpassing the baseline (5,552 params; PR-AUC = 93.7%, F1 = 90.5%, MCC = 88.5%) with approximately 10x fewer parameters. The smallest model (Model 1, 305 params) reaches PR-AUC = 94.0%, F1 = 91.0%, MCC = 89.1%. Thresholding obtains high recall (89.0%) but low precision (76.5%), yielding many false positives and high inter-subject variance. Sensor-position analysis (train-on-all) shows chest and thighs are most reliable; forearms degrade precision/recall due to non-gait arm motion; naive fusion of all sites does not outperform the best single site. Both compact CNNs execute within tight memory/latency budgets on STM32-class MCUs (sub-10 ms on low-power boards), enabling on-sensor gating of transmission/storage. Overall, ultra-light separable CNNs provide a superior accuracy-efficiency-generalization trade-off to fixed thresholds for wearable PD gait detection and underscore the value of tailored time-series models for edge deployment.

</details>


### [23] [Privacy-Preserving Generative Modeling and Clinical Validation of Longitudinal Health Records for Chronic Disease](https://arxiv.org/abs/2512.00434)
*Benjamin D. Ballyk,Ankit Gupta,Sujay Konda,Kavitha Subramanian,Chris Landon,Ahmed Ammar Naseer,Georg Maierhofer,Sumanth Swaminathan,Vasudevan Venkateshwaran*

Main category: cs.LG

TL;DR: 增强时间序列生成模型处理纵向临床数据，同时加入可量化隐私保护，在慢性肾病和ICU数据集上验证效果


<details>
  <summary>Details</summary>
Motivation: 医疗数据隐私是现代医疗工作流程中的关键挑战，严格的数据保护法规限制了临床记录用于训练机器学习模型，而合成数据虽然提供替代方案，但现有生成模型要么难以处理时间序列数据，要么缺乏正式的隐私保证

Method: 增强最先进的时间序列生成模型以更好地处理纵向临床数据，同时加入可量化的隐私保护机制，提出Augmented TimeGAN（非私有模型）和DP-TimeGAN（私有模型）

Result: 非私有模型在多个数据集上优于基于transformer和flow的模型；私有模型在CKD数据集上保持0.778的平均真实性，在隐私-效用前沿上优于现有最先进模型；两种模型在临床医生评估中达到与真实数据相当的性能

Conclusion: 该方法为开发复杂慢性病模型提供了必要的鲁棒输入数据，同时不损害数据隐私，在医疗数据隐私保护和机器学习模型训练需求之间找到了平衡

Abstract: Data privacy is a critical challenge in modern medical workflows as the adoption of electronic patient records has grown rapidly. Stringent data protection regulations limit access to clinical records for training and integrating machine learning models that have shown promise in improving diagnostic accuracy and personalized care outcomes. Synthetic data offers a promising alternative; however, current generative models either struggle with time-series data or lack formal privacy guaranties. In this paper, we enhance a state-of-the-art time-series generative model to better handle longitudinal clinical data while incorporating quantifiable privacy safeguards. Using real data from chronic kidney disease and ICU patients, we evaluate our method through statistical tests, a Train-on-Synthetic-Test-on-Real (TSTR) setup, and expert clinical review. Our non-private model (Augmented TimeGAN) outperforms transformer- and flow-based models on statistical metrics in several datasets, while our private model (DP-TimeGAN) maintains a mean authenticity of 0.778 on the CKD dataset, outperforming existing state-of-the-art models on the privacy-utility frontier. Both models achieve performance comparable to real data in clinician evaluations, providing robust input data necessary for developing models for complex chronic conditions without compromising data privacy.

</details>


### [24] [ESPO: Entropy Importance Sampling Policy Optimization](https://arxiv.org/abs/2512.00499)
*Yuepeng Sheng,Yuwei Huang,Shuman Liu,Haibo Zhang,Anxiang Zeng*

Main category: cs.LG

TL;DR: ESPO通过基于预测熵的序列分解，解决了GSPO等群体策略优化框架中梯度利用不足和信用分配不均的问题，实现了细粒度控制与训练稳定性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有LLM强化学习中的群体策略优化框架（如GRPO、GSPO）存在优化粒度与训练稳定性之间的根本权衡。GSPO虽然通过序列级优化提高了鲁棒性，但其保守的裁剪机制会不加区分地丢弃有效训练样本（梯度利用不足），且统一的信用分配无法捕捉关键推理步骤的异质性贡献。

Method: 提出熵重要性采样策略优化（ESPO）框架：1）基于预测熵将序列分解为组，实现熵驱动的重要性采样以捕捉序列内异质性；2）熵自适应裁剪，根据模型不确定性动态分配信任区域。

Result: 在数学推理基准测试中，ESPO不仅加速了收敛，还实现了最先进的性能，特别是在具有挑战性的HMMT基准上将准确率从4.4%显著提升至13.13%。

Conclusion: ESPO通过熵驱动的序列分解和自适应裁剪，成功解决了群体策略优化中的梯度利用不足和异质性信用分配问题，为LLM强化学习提供了更高效稳定的优化框架。

Abstract: Large language model (LLM) reinforcement learning has increasingly relied on group-based policy optimization frameworks, such as GRPO and GSPO, to achieve stable fine-tuning at scale. However, a fundamental trade-off persists between optimization granularity and training stability. While GSPO improves robustness via sequence-level optimization, its monolithic treatment of sequences introduces severe inefficiencies: its conservative clipping mechanism indiscriminately discards valid training samples-a phenomenon we term gradient underutilization-and its uniform credit assignment fails to capture the heterogeneous contributions of critical reasoning steps. In this work, we propose Entropy Importance Sampling Policy Optimization (ESPO), a novel framework that reconciles fine-grained control with training stability. ESPO decomposes sequences into groups based on predictive entropy, enabling (1) Entropy-driven Importance Sampling to capture intra-sequence heterogeneity, and (2) Entropy-adaptive Clipping to dynamically allocate trust regions based on model uncertainty. Extensive experiments on mathematical reasoning benchmarks demonstrate that ESPO not only accelerates convergence but also achieves state-of-the-art performance, notably improving accuracy on the challenging HMMT benchmark from 4.4% to 13.13%.

</details>


### [25] [Pushing the Boundaries of Interpretability: Incremental Enhancements to the Explainable Boosting Machine](https://arxiv.org/abs/2512.00528)
*Isara Liyanage,Uthayasanker Thayasivam*

Main category: cs.LG

TL;DR: 本文通过贝叶斯超参数优化、公平性多目标函数和自监督预训练三种方法改进可解释提升机（EBM），在多个基准数据集上评估，发现调优过程虽然对ROC AUC指标提升有限，但显著改变了模型决策行为，强调了超越单一性能分数的多维度评估价值。


<details>
  <summary>Details</summary>
Motivation: 随着复杂机器学习模型在高风险领域的广泛应用，"黑箱"问题已成为负责任AI研究的核心挑战。本文旨在通过改进可解释提升机（EBM）这一既提供高准确性又保持完全透明性的先进玻璃盒模型，解决这一关键问题。

Method: 提出了三种增强方法：1）使用贝叶斯方法进行针对性超参数优化；2）为超参数优化实现自定义的公平性多目标函数；3）针对冷启动场景设计新颖的自监督预训练流程。所有方法在Adult Income、信用卡欺诈检测和UCI心脏病数据集等标准基准上进行了评估。

Result: 分析表明，虽然调优过程在主要ROC AUC指标上仅带来边际改进，但导致了模型决策行为的微妙而重要的变化。这证明了超越单一性能分数的多维度评估的价值，模型在保持准确性的同时展现出更稳健、公平和透明的特性。

Conclusion: 这项工作被认为是开发不仅准确而且稳健、公平、透明的机器学习系统的关键一步，满足了日益增长的监管和伦理合规要求。研究强调了在模型评估中考虑决策行为变化的重要性，而不仅仅是关注传统性能指标。

Abstract: The widespread adoption of complex machine learning models in high-stakes domains has brought the "black-box" problem to the forefront of responsible AI research. This paper aims at addressing this issue by improving the Explainable Boosting Machine (EBM), a state-of-the-art glassbox model that delivers both high accuracy and complete transparency. The paper outlines three distinct enhancement methodologies: targeted hyperparameter optimization with Bayesian methods, the implementation of a custom multi-objective function for fairness for hyperparameter optimization, and a novel self-supervised pre-training pipeline for cold-start scenarios. All three methodologies are evaluated across standard benchmark datasets, including the Adult Income, Credit Card Fraud Detection, and UCI Heart Disease datasets. The analysis indicates that while the tuning process yielded marginal improvements in the primary ROC AUC metric, it led to a subtle but important shift in the model's decision-making behavior, demonstrating the value of a multi-faceted evaluation beyond a single performance score. This work is positioned as a critical step toward developing machine learning systems that are not only accurate but also robust, equitable, and transparent, meeting the growing demands of regulatory and ethical compliance.

</details>


### [26] [Algorithmic Guarantees for Distilling Supervised and Offline RL Datasets](https://arxiv.org/abs/2512.00536)
*Aaryan Gupta,Rishi Saket,Aravindan Raghuveer*

Main category: cs.LG

TL;DR: 本文提出了一种高效的监督学习数据集蒸馏算法，通过匹配训练集和合成数据集在随机采样回归器上的损失，无需模型训练。理论证明仅需Õ(d²)个采样回归器即可保证线性模型的MSE损失接近，并扩展到离线强化学习中的贝尔曼损失匹配。


<details>
  <summary>Details</summary>
Motivation: 数据集蒸馏的目标是从原始训练数据集中生成一个合成数据集，使得在该合成数据集上训练的模型性能接近在原始数据集上训练的模型。现有方法通常需要模型训练，本文旨在开发一种无需模型训练的高效算法。

Method: 提出基于损失匹配的数据集蒸馏算法：1）对于监督学习回归问题，通过匹配训练集和合成数据集在随机采样回归器上的MSE损失；2）扩展到离线强化学习，通过匹配贝尔曼损失而非行为克隆目标，利用奖励和下一状态信息。

Result: 理论证明：1）仅需Õ(d²)个采样回归器即可保证任何有界线性模型在合成数据集上的MSE损失接近其在训练数据上的损失；2）证明Ω(d²)的下界，显示分析紧致性；3）实验验证理论保证并观察到性能提升。

Conclusion: 本文提出了一种无需模型训练的高效数据集蒸馏算法，在监督学习和离线强化学习中均能保证性能，理论分析紧致且实验验证有效，为数据集蒸馏提供了新的理论框架和实践方法。

Abstract: Given a training dataset, the goal of dataset distillation is to derive a synthetic dataset such that models trained on the latter perform as well as those trained on the training dataset. In this work, we develop and analyze an efficient dataset distillation algorithm for supervised learning, specifically regression in $\mathbb{R}^d$, based on matching the losses on the training and synthetic datasets with respect to a fixed set of randomly sampled regressors without any model training. Our first key contribution is a novel performance guarantee proving that our algorithm needs only $\tilde{O}(d^2)$ sampled regressors to derive a synthetic dataset on which the MSE loss of any bounded linear model is nearly the same as its MSE loss on the given training data. In particular, the model optimized on the synthetic data has close to minimum loss on the training data, thus performing nearly as well as the model optimized on the latter. Complementing this, we also prove a matching lower bound of $Ω(d^2)$ for the number of sampled regressors showing the tightness of our analysis.
  Our second contribution is to extend our algorithm to offline RL dataset distillation by matching the Bellman loss, unlike previous works which used a behavioral cloning objective. This is the first such method which leverages both, the rewards and the next state information, available in offline RL datasets, without any policy model optimization. Our algorithm generates a synthetic dataset whose Bellman loss with respect to any linear action-value predictor is close to the latter's Bellman loss on the offline RL training dataset. Therefore, a policy associated with an action-value predictor optimized on the synthetic dataset performs nearly as well as that derived from the one optimized on the training data. We conduct experiments to validate our theoretical guarantees and observe performance gains.

</details>


### [27] [List Replicable Reinforcement Learning](https://arxiv.org/abs/2512.00553)
*Bohan Zhang,Michael Chen,A. Pavan,N. V. Vinodchandran,Lin F. Yang,Ruosong Wang*

Main category: cs.LG

TL;DR: 该论文研究强化学习中的可复现性问题，提出列表可复现性概念，开发了能保证多项式列表复杂度的表格RL算法，并通过新颖的规划策略增强算法稳定性。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法在实践中存在不稳定性和对训练条件敏感的问题，这导致实验结果难以复现。为了解决这一根本挑战，作者在PAC RL框架下研究列表可复现性，旨在开发能够产生稳定、可复现结果的算法。

Method: 提出列表可复现性概念，分为弱形式和强形式。开发了表格RL算法，采用两种关键技术：(1) 基于词典顺序在近优选择中选取动作的规划策略，使用随机选择的容差阈值；(2) 在随机环境中测试状态可达性同时保持可复现性的机制。

Result: 理论证明该算法能够保证列表复杂度在状态数、动作数和时间范围长度上呈多项式增长，实现了弱列表可复现性，并进一步扩展到强列表可复现性，以高概率限制可能的策略执行轨迹数量。

Conclusion: 该研究为解决RL算法的不稳定性问题提供了理论框架和实用方法，新的规划策略可以融入实际RL框架以增强稳定性，为实际应用中的可复现性问题提供了解决方案。

Abstract: Replicability is a fundamental challenge in reinforcement learning (RL), as RL algorithms are empirically observed to be unstable and sensitive to variations in training conditions. To formally address this issue, we study \emph{list replicability} in the Probably Approximately Correct (PAC) RL framework, where an algorithm must return a near-optimal policy that lies in a \emph{small list} of policies across different runs, with high probability. The size of this list defines the \emph{list complexity}. We introduce both weak and strong forms of list replicability: the weak form ensures that the final learned policy belongs to a small list, while the strong form further requires that the entire sequence of executed policies remains constrained. These objectives are challenging, as existing RL algorithms exhibit exponential list complexity due to their instability. Our main theoretical contribution is a provably efficient tabular RL algorithm that guarantees list replicability by ensuring the list complexity remains polynomial in the number of states, actions, and the horizon length. We further extend our techniques to achieve strong list replicability, bounding the number of possible policy execution traces polynomially with high probability. Our theoretical result is made possible by key innovations including (i) a novel planning strategy that selects actions based on lexicographic order among near-optimal choices within a randomly chosen tolerance threshold, and (ii) a mechanism for testing state reachability in stochastic environments while preserving replicability. Finally, we demonstrate that our theoretical investigation sheds light on resolving the \emph{instability} issue of RL algorithms used in practice. In particular, we show that empirically, our new planning strategy can be incorporated into practical RL frameworks to enhance their stability.

</details>


### [28] [Pre-Generating Multi-Difficulty PDE Data for Few-Shot Neural PDE Solvers](https://arxiv.org/abs/2512.00564)
*Naman Choudhary,Vedant Singh,Ameet Talwalkar,Nicholas Matthew Boffi,Mikhail Khodak,Tanya Marwah*

Main category: cs.LG

TL;DR: 该研究探讨了学习型PDE求解器中训练数据生成的效率问题，发现通过预先生成低/中难度样本并纳入训练集，可以显著减少高难度物理问题所需的数据量，实现8.9倍的计算效率提升。


<details>
  <summary>Details</summary>
Motivation: 学习型PDE求解器的主要成本通常来自使用经典求解器生成训练数据，而非模型学习本身。同时，问题难度（如几何复杂度、雷诺数）的增加会使经典求解器计算更困难，但也更可能从神经加速中受益。研究旨在解决这一"先有鸡还是先有蛋"的挑战。

Method: 研究在2D不可压缩Navier-Stokes方程上系统性地研究难度转移，通过变化任务复杂度：几何（障碍物数量和位置）、物理（雷诺数）及其组合。类似预训练基础模型的方法，通过经典求解器预先生成大量低/中难度样本并纳入训练集，从而用更少样本学习高难度物理。

Result: 研究发现，通过结合低难度和高难度数据，可以比仅使用高难度示例减少8.9倍的计算成本来达到相同的误差水平。结果表明，如何在不同难度级别间分配经典求解器计算资源与总体计算量分配同等重要。

Conclusion: 研究强调了为神经求解器精心策划预生成PDE数据的重要性，表明通过合理分配计算资源在不同难度任务上，可以显著提升学习型PDE求解器的训练效率和性能。

Abstract: A key aspect of learned partial differential equation (PDE) solvers is that the main cost often comes from generating training data with classical solvers rather than learning the model itself. Another is that there are clear axes of difficulty--e.g., more complex geometries and higher Reynolds numbers--along which problems become (1) harder for classical solvers and thus (2) more likely to benefit from neural speedups. Towards addressing this chicken-and-egg challenge, we study difficulty transfer on 2D incompressible Navier-Stokes, systematically varying task complexity along geometry (number and placement of obstacles), physics (Reynolds number), and their combination. Similar to how it is possible to spend compute to pre-train foundation models and improve their performance on downstream tasks, we find that by classically solving (analogously pre-generating) many low and medium difficulty examples and including them in the training set, it is possible to learn high-difficulty physics from far fewer samples. Furthermore, we show that by combining low and high difficulty data, we can spend 8.9x less compute on pre-generating a dataset to achieve the same error as using only high difficulty examples. Our results highlight that how we allocate classical-solver compute across difficulty levels is as important as how much we allocate overall, and suggest substantial gains from principled curation of pre-generated PDE data for neural solvers. Our code is available at https://github.com/Naman-Choudhary-AI-ML/pregenerating-pde

</details>


### [29] [Non-Asymptotic Convergence of Discrete Diffusion Models: Masked and Random Walk dynamics](https://arxiv.org/abs/2512.00580)
*Giovanni Conforti,Alain Durmus,Le-Tuyet-Nhi Pham*

Main category: cs.LG

TL;DR: 该论文研究了离散扩散模型的理论基础，在离散状态空间上建立了收敛性保证，包括有限空间和可数无限空间，模型复杂度随维度线性增长而非指数增长。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在离散状态空间上的理论理解不足，与连续情况相比缺乏严格分析，需要建立理论保证来支持其应用。

Method: 研究离散扩散模型在有限空间ℤ^d_m和可数无限空间ℕ^d上的收敛性，关注前向掩码和随机游走动态，利用离散得分函数的单调性推导误差界。

Result: 建立了非渐近收敛保证，不依赖估计得分的有限性，模型复杂度随维度线性增长（至多对数因子），可高效扩展到高维数据。

Conclusion: 该研究首次为离散扩散模型提供了全面的理论收敛保证，覆盖多种噪声过程，为离散扩散模型的理论基础做出了重要贡献。

Abstract: We investigate the theoretical underpinnings of Discrete Diffusion Models (DDMs) on discrete state spaces. Unlike in the continuous setting-where diffusion models are well understood both theoretically and empirically-the discrete case poses significant challenges due to its combinatorial structure and the lack of rigorous analysis. In this work, we establish convergence guarantees for DDMs on both the finite space $\mathbb{Z}^d_m=\{0,...,m-1\}^d$ and the countably infinite space $\mathbb{N}^d$ under mild assumptions, focusing on forward masked and random walk dynamics. Similar to the continuous case, the backward process can be characterized by a discrete score function, whose monotonicity plays a central role in deriving the error bounds of the generated data. Notably, the complexity of our model scales linearly up to logarithmic factors, rather than exponentially, with the dimension, making it efficiently scalable to high-dimensional data. To the best of our knowledge, this study provides the first non-asymptotic convergence guarantees that do not rely on the boundedness of the estimated score-covering not only uniform noising processes on $\mathbb{Z}^d_m$ and on $\mathbb{N}^d$, but also masking-based noising dynamics.

</details>


### [30] [Statistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R&D](https://arxiv.org/abs/2512.00586)
*Michael R. Doane*

Main category: cs.LG

TL;DR: 开发了一个基于NLP的概率分类器，用于预测神经科学领域临床试验的技术和监管成功概率，BioBERT模型表现最佳，AUC达0.74，比行业基准误差减少40%


<details>
  <summary>Details</summary>
Motivation: 神经科学领域药物研发成功率低于10%，成本高昂且失败率高，需要及时识别有前景的临床试验项目以优化资源分配和降低财务风险

Method: 使用ClinicalTrials.gov数据和临床试验结果标签，通过统计NLP技术提取文本特征，集成到逻辑回归、梯度提升和随机森林等非LLM框架中，并构建基于BioBERT的LLM预测模型

Result: 在1976-2024年完成的101,145个临床试验回顾性数据集上，非LLM模型总体ROC-AUC为0.64，BioBERT模型达到0.74，Brier分数0.185，预测误差比行业基准平均减少40%，70%情况下预测优于基准值

Conclusion: 基于NLP的预测模型能够有效评估神经科学临床试验成功概率，BioBERT模型表现优异，将NLP驱动的洞察整合到药物开发决策中有助于增强战略规划和优化投资分配

Abstract: This work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R&D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs.

</details>


### [31] [Developing Fairness-Aware Task Decomposition to Improve Equity in Post-Spinal Fusion Complication Prediction](https://arxiv.org/abs/2512.00598)
*Yining Yuan,J. Ben Tamo,Wenqi Shi,Yishan Zhong,Micky C. Nnamdi,B. Randall Brenn,Steven W. Hwang,May D. Wang*

Main category: cs.LG

TL;DR: FAIR-MTL：一种公平感知的多任务学习框架，通过数据驱动的亚组推断机制，在脊柱融合手术并发症预测中实现更公平、细粒度的预测，显著减少性别和年龄偏见。


<details>
  <summary>Details</summary>
Motivation: 临床预测模型中的公平性问题在脊柱融合手术等高风险应用中尤为突出，现有方法依赖粗粒度的人口统计学调整或后处理修正，无法捕捉临床人群的潜在结构，可能无意中强化偏见。

Method: 提出FAIR-MTL框架：1) 提取紧凑的人口统计学嵌入；2) 使用k-means聚类发现潜在患者亚组；3) 基于推断的亚组标签在多任务架构中进行任务路由；4) 通过逆频率加权缓解亚组不平衡；5) 正则化防止对小群体的过拟合。

Result: 在术后并发症预测中，AUC达到0.86，准确率75%，优于单任务基线。性别方面的统计均等差异降至0.055，机会均等降至0.094；年龄方面分别降至0.056和0.148。SHAP和Gini重要性分析显示血红蛋白、血细胞比容和患者体重等临床预测因子具有重要性。

Conclusion: 将无监督亚组发现纳入多任务框架能够实现更公平、可解释且具有临床可操作性的手术风险分层预测，为临床预测模型中的公平性问题提供了有效解决方案。

Abstract: Fairness in clinical prediction models remains a persistent challenge, particularly in high-stakes applications such as spinal fusion surgery for scoliosis, where patient outcomes exhibit substantial heterogeneity. Many existing fairness approaches rely on coarse demographic adjustments or post-hoc corrections, which fail to capture the latent structure of clinical populations and may unintentionally reinforce bias. We propose FAIR-MTL, a fairness-aware multitask learning framework designed to provide equitable and fine-grained prediction of postoperative complication severity.
  Instead of relying on explicit sensitive attributes during model training, FAIR-MTL employs a data-driven subgroup inference mechanism. We extract a compact demographic embedding, and apply k-means clustering to uncover latent patient subgroups that may be differentially affected by traditional models. These inferred subgroup labels determine task routing within a shared multitask architecture. During training, subgroup imbalance is mitigated through inverse-frequency weighting, and regularization prevents overfitting to smaller groups.
  Applied to postoperative complication prediction with four severity levels, FAIR-MTL achieves an AUC of 0.86 and an accuracy of 75%, outperforming single-task baselines while substantially reducing bias. For gender, the demographic parity difference decreases to 0.055 and equalized odds to 0.094; for age, these values reduce to 0.056 and 0.148, respectively. Model interpretability is ensured through SHAP and Gini importance analyses, which consistently highlight clinically meaningful predictors such as hemoglobin, hematocrit, and patient weight. Our findings show that incorporating unsupervised subgroup discovery into a multitask framework enables more equitable, interpretable, and clinically actionable predictions for surgical risk stratification.

</details>


### [32] [Efficient Matroid Bandit Linear Optimization Leveraging Unimodality](https://arxiv.org/abs/2512.00605)
*Aurélien Delage,Romaric Gaudel*

Main category: cs.LG

TL;DR: 该论文研究在拟阵约束下的组合半赌博机问题，通过利用其内在的单峰结构，将涉及成员资格查询的迭代次数限制到O(log log T)，显著降低了时间复杂度和成员资格查询调用次数，同时保持了与最优算法相当的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 虽然现有方法在拟阵约束的组合半赌博机问题上已经达到了最优遗憾界，但时间复杂度仍然是一个问题，特别是对于大型拟阵或成员资格查询成本高的应用场景（如确保多样性的在线推荐）。

Method: 利用拟阵半赌博机问题的内在单峰结构，设计了一种新算法，将涉及成员资格查询的迭代次数限制到O(log log T)，从而显著减少计算开销。

Result: 实验表明：(i) 与最先进方法相比没有遗憾损失；(ii) 时间复杂度和成员资格查询调用次数显著减少。

Conclusion: 通过利用拟阵半赌博机问题的单峰结构，可以在几乎不损失遗憾的情况下，显著降低学习过程的时间复杂度，特别是减少对成本高昂的成员资格查询的依赖。

Abstract: We study the combinatorial semi-bandit problem under matroid constraints. The regret achieved by recent approaches is optimal, in the sense that it matches the lower bound. Yet, time complexity remains an issue for large matroids or for matroids with costly membership oracles (e.g. online recommendation that ensures diversity). This paper sheds a new light on the matroid semi-bandit problem by exploiting its underlying unimodal structure. We demonstrate that, with negligible loss in regret, the number of iterations involving the membership oracle can be limited to \mathcal{O}(\log \log T)$. This results in an overall improved time complexity of the learning process. Experiments conducted on various matroid benchmarks show (i) no loss in regret compared to state-of-the-art approaches; and (ii) reduced time complexity and number of calls to the membership oracle.

</details>


### [33] [Generalized Graph Transformer Variational Autoencoder](https://arxiv.org/abs/2512.00612)
*Siddhant Karki*

Main category: cs.LG

TL;DR: GGT-VAE是一种结合广义图变换器和变分自编码器的新型图链接预测模型，利用全局自注意力机制和拉普拉斯位置编码，无需消息传递即可建模图结构。


<details>
  <summary>Details</summary>
Motivation: 图链接预测是图表示学习的核心问题，现有基于GCN、GNN或GraphVAE的方法主要依赖消息传递机制，需要更先进的架构来捕获图结构中的关系依赖。

Method: 提出广义图变换器变分自编码器(GGT-VAE)，将广义图变换器架构与变分自编码器框架结合，使用变换器风格的全局自注意力机制和拉普拉斯位置编码，将节点间的结构模式建模到潜在空间中。

Result: 在多个基准数据集上的实验结果表明，GGT-VAE在ROC-AUC和平均精度指标上始终优于基线方法。

Conclusion: GGT-VAE是首批在变分框架中使用广义图变换器主干探索图结构生成的研究之一，为图链接预测提供了新的有效方法。

Abstract: Graph link prediction has long been a central problem in graph representation learning in both network analysis and generative modeling. Recent progress in deep learning has introduced increasingly sophisticated architectures for capturing relational dependencies within graph-structured data. In this work, we propose the Generalized Graph Transformer Variational Autoencoder (GGT-VAE). Our model integrates Generalized Graph Transformer Architecture with Variational Autoencoder framework for link prediction. Unlike prior GraphVAE, GCN, or GNN approaches, GGT-VAE leverages transformer style global self-attention mechanism along with laplacian positional encoding to model structural patterns across nodes into a latent space without relying on message passing. Experimental results on several benchmark datasets demonstrate that GGT-VAE consistently achieves above-baseline performance in terms of ROC-AUC and Average Precision. To the best of our knowledge, this is among the first studies to explore graph structure generation using a generalized graph transformer backbone in a variational framework.

</details>


### [34] [Financial Text Classification Based On rLoRA Finetuning On Qwen3-8B model](https://arxiv.org/abs/2512.00630)
*Zhiming Lian*

Main category: cs.LG

TL;DR: 本文评估了Qwen3-8B大语言模型在金融文本分类任务中的表现，通过噪声嵌入指令微调和低秩优化等技术，在金融情感分析和新闻分类任务上超越了多个基准模型。


<details>
  <summary>Details</summary>
Motivation: 金融文本分类在量化交易系统中日益重要，但现有模型在金融领域的表现和效率有待提升。需要评估先进大语言模型在金融任务中的潜力，特别是针对实时应用的可扩展性和经济性。

Method: 采用Qwen3-8B大语言模型，应用噪声嵌入指令微调（NEIFT）增强鲁棒性，结合秩稳定低秩适应（Rank-stabilized LoRA）优化和FlashAttention技术提高训练效率。与T5、BERT、RoBERTa等传统Transformer模型以及LLaMA1-7B、LLaMA2-7B、Baichuan2-7B等大模型进行对比。

Result: Qwen3-8B在所有基准测试中表现最佳，获得了更高的分类准确率，并且需要更少的训练轮次。指令微调与内存高效优化方法的协同作用使Qwen3-8B成为金融NLP应用的可行选择。

Conclusion: Qwen3-8B通过专门的优化技术，在金融文本分类任务中展现出卓越性能，为动态量化交易系统提供了有前景的基础模型，具有可扩展性和经济性优势。

Abstract: Financial text classification has increasingly become an important aspect in quantitative trading systems and related tasks, such as financial sentiment analysis and the classification of financial news. In this paper, we assess the performance of the large language model Qwen3-8B on both tasks. Qwen3-8B is a state-of-the-art model that exhibits strong instruction-following and multilingual capabilities, and is distinct from standard models, primarily because it is specifically optimized for efficient fine tuning and high performance on reasoning-based benchmarks, making it suitable for financial applications. To adapt this model, we apply Noisy Embedding Instruction Finetuning and based on our previous work, this method increases robustness by injecting controlled noise into the embedding layers during supervised adaptation. We improve efficiency further with Rank-stabilized Low-Rank Adaptation low-rank optimization approach, and FlashAttention, which allow for faster training with lower GPU memory. For both tasks, we benchmark Qwen3-8B against standard classical transformer models, such as T5, BERT, and RoBERTa, and large models at scale, such as LLaMA1-7B, LLaMA2-7B, and Baichuan2-7B. The findings reveal that Qwen3-8B consistently surpasses these baselines by obtaining better classification accuracy and needing fewer training epochs. The synergy of instruction-based fine-tuning and memory-efficient optimization methods suggests Qwen3-8B can potentially serve as a scalable, economical option for real-time financial NLP applications. Qwen3-8B provides a very promising base for advancing dynamic quantitative trading systems in the future.

</details>


### [35] [Privacy Preserving Diffusion Models for Mixed-Type Tabular Data Generation](https://arxiv.org/abs/2512.00638)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: DP-FinDiff是一个差分隐私扩散框架，用于合成混合类型的表格数据，在金融和医疗数据集上比现有DP基线方法提高了16-42%的效用。


<details>
  <summary>Details</summary>
Motivation: 在敏感领域（如金融和医疗）进行数据共享时，需要在保护隐私的同时保持数据的实用性。现有的差分隐私方法在处理混合类型表格数据时存在编码开销大、隐私训练与扩散过程不匹配等问题。

Method: 1. 使用基于嵌入的表示方法处理分类特征，减少编码开销并扩展到高维数据集；2. 提出两种隐私感知训练策略：自适应时间步采样器（使更新与扩散动态对齐）和特征聚合损失（减轻裁剪引起的偏差）。

Result: 在金融和医疗数据集上，DP-FinDiff在可比隐私水平下比现有DP基线方法实现了16-42%的更高效用，同时不削弱隐私保证。

Conclusion: DP-FinDiff框架为敏感领域的安全有效数据共享提供了有前景的解决方案，通过改进的隐私训练策略和特征表示方法，在保持差分隐私保护的同时显著提高了合成数据的质量。

Abstract: We introduce DP-FinDiff, a differentially private diffusion framework for synthesizing mixed-type tabular data. DP-FinDiff employs embedding-based representations for categorical features, reducing encoding overhead and scaling to high-dimensional datasets. To adapt DP-training to the diffusion process, we propose two privacy-aware training strategies: an adaptive timestep sampler that aligns updates with diffusion dynamics, and a feature-aggregated loss that mitigates clipping-induced bias. Together, these enhancements improve fidelity and downstream utility without weakening privacy guarantees. On financial and medical datasets, DP-FinDiff achieves 16-42% higher utility than DP baselines at comparable privacy levels, demonstrating its promise for safe and effective data sharing in sensitive domains.

</details>


### [36] [Flow Matching for Tabular Data Synthesis](https://arxiv.org/abs/2512.00698)
*Bahrul Ilmi Nasution,Floor Eijkelboom,Mark Elliot,Richard Allmendinger,Christian A. Naesseth*

Main category: cs.LG

TL;DR: 本文系统研究了流匹配方法在表格数据合成中的应用，发现TabbyFlow在性能和计算效率上优于扩散模型基准方法，同时探讨了不同概率路径和采样策略对数据效用与隐私风险的平衡影响。


<details>
  <summary>Details</summary>
Motivation: 表格数据合成是隐私保护数据共享的重要工具，虽然扩散模型近期表现优异，但流匹配方法提供了有前景的替代方案。本文旨在全面比较流匹配与扩散方法在表格数据合成中的性能，并探索不同实现方式对数据效用和隐私风险的影响。

Method: 本文提出了多种流匹配在表格数据合成中的实现方式，包括标准流匹配和变分流匹配。研究比较了最优传输和方差保持两种概率路径，并评估了确定性和随机性采样器。通过全面的实证研究，将流匹配方法与最先进的扩散方法（TabDDPM和TabSyn）进行对比分析。

Result: 关键发现显示：1) 流匹配方法（特别是TabbyFlow）在性能上优于扩散基准方法；2) 流匹配方法仅需极少的函数评估（≤100步）就能达到优异性能，具有显著计算优势；3) 最优传输路径表现更优，而方差保持路径在降低披露风险方面有潜力；4) 随机性流不仅保留了边缘分布，在某些情况下还能生成高效用且低披露风险的合成数据。

Conclusion: 流匹配方法在表格数据合成中展现出优于扩散模型的性能，特别是在计算效率方面。最优传输路径在性能上更优，而方差保持路径在隐私保护方面有优势。随机性采样策略能够在保持数据效用的同时降低披露风险，为隐私保护数据合成提供了新的研究方向。

Abstract: Synthetic data generation is an important tool for privacy-preserving data sharing. While diffusion models have set recent benchmarks, flow matching (FM) offers a promising alternative. This paper presents different ways to implement flow matching for tabular data synthesis. We provide a comprehensive empirical study that compares flow matching (FM and variational FM) with a state-of-the-art diffusion method (TabDDPM and TabSyn) in tabular data synthesis. We evaluate both the standard Optimal Transport (OT) and the Variance Preserving (VP) probability paths, and also compare deterministic and stochastic samplers -- something possible when learning to generate using \textit{variational} flow matching -- characterising the empirical relationship between data utility and privacy risk. Our key findings reveal that flow matching, particularly TabbyFlow, outperforms diffusion baselines. Flow matching methods also achieves better performance with remarkably low function evaluations ($\leq$ 100 steps), offering a substantial computational advantage. The choice of probability path is also crucial, as using the OT path demonstrates superior performance, while VP has potential for producing synthetic data with lower disclosure risk. Lastly, our results show that making flows stochastic not only preserves marginal distributions but, in some instances, enables the generation of high utility synthetic data with reduced disclosure risk.

</details>


### [37] [Towards Precision Protein-Ligand Affinity Prediction Benchmark: A Complete and Modification-Aware DAVIS Dataset](https://arxiv.org/abs/2512.00708)
*Ming-Hsiu Wu,Ziqian Xie,Shuiwang Ji,Degui Zhi*

Main category: cs.LG

TL;DR: 研究者创建了包含蛋白质修饰的完整DAVIS数据集版本，包含4032个激酶-配体对，并设计了三个基准测试来评估模型在蛋白质修饰下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在药物发现任务（如蛋白质-配体结合亲和力预测）中过度拟合于过度简化的数据集，这些数据集不能代表自然发生且具有生物学相关性的蛋白质修饰。

Method: 1. 创建了包含蛋白质修饰（替换、插入、缺失和磷酸化事件）的完整DAVIS数据集版本，包含4032个激酶-配体对；2. 设计了三个基准测试：增强数据集预测、野生型到修饰的泛化、少样本修饰泛化；3. 对无对接和基于对接的方法进行了广泛评估。

Result: 基于对接的模型在零样本设置中泛化能力更好；无对接模型倾向于过度拟合野生型蛋白质，难以处理未见过的修饰，但在少量修饰示例上进行微调后表现出显著改进。

Conclusion: 该数据集和基准测试为开发能更好泛化到蛋白质修饰的模型提供了有价值的基础，有望推动药物发现中的精准医学发展。

Abstract: Advancements in AI for science unlocks capabilities for critical drug discovery tasks such as protein-ligand binding affinity prediction. However, current models overfit to existing oversimplified datasets that does not represent naturally occurring and biologically relevant proteins with modifications. In this work, we curate a complete and modification-aware version of the widely used DAVIS dataset by incorporating 4,032 kinase-ligand pairs involving substitutions, insertions, deletions, and phosphorylation events. This enriched dataset enables benchmarking of predictive models under biologically realistic conditions. Based on this new dataset, we propose three benchmark settings-Augmented Dataset Prediction, Wild-Type to Modification Generalization, and Few-Shot Modification Generalization-designed to assess model robustness in the presence of protein modifications. Through extensive evaluation of both docking-free and docking-based methods, we find that docking-based model generalize better in zero-shot settings. In contrast, docking-free models tend to overfit to wild-type proteins and struggle with unseen modifications but show notable improvement when fine-tuned on a small set of modified examples. We anticipate that the curated dataset and benchmarks offer a valuable foundation for developing models that better generalize to protein modifications, ultimately advancing precision medicine in drug discovery. The benchmark is available at: https://github.com/ZhiGroup/DAVIS-complete

</details>


### [38] [ESMC: MLLM-Based Embedding Selection for Explainable Multiple Clustering](https://arxiv.org/abs/2512.00725)
*Xinyue Wang,Yuheng Jia,Hui Liu,Junhui Hou*

Main category: cs.LG

TL;DR: 该论文提出了一种基于多模态大语言模型（MLLMs）的用户驱动聚类方法，通过挖掘MLLMs隐藏状态中的特征信息，结合轻量级聚类头和伪标签学习，实现了根据用户自定义标准的高质量聚类。


<details>
  <summary>Details</summary>
Motivation: 传统深度聚类方法通常只能为每个数据集提供一个固定的聚类结果，这种基于固定数据分布的假设无法满足用户多样化的语义需求。用户可能需要根据不同标准（如颜色、形状、功能等）对数据进行聚类，而现有方法缺乏这种灵活性。

Method: 1. 发现MLLMs文本标记的隐藏状态与对应特征有强相关性，利用这些嵌入表示进行聚类
2. 设计轻量级聚类头，结合伪标签学习增强聚类准确性
3. 支持用户自定义聚类标准，实现用户驱动的灵活聚类

Result: 在多个数据集和评估指标上的广泛实验表明，该方法取得了具有竞争力的性能，能够有效根据用户指定的语义要求进行高质量聚类。

Conclusion: 该方法成功利用MLLMs实现了用户驱动的聚类，克服了传统方法只能提供单一聚类结果的局限性，为满足用户多样化语义需求提供了有效解决方案。

Abstract: Typical deep clustering methods, while achieving notable progress, can only provide one clustering result per dataset. This limitation arises from their assumption of a fixed underlying data distribution, which may fail to meet user needs and provide unsatisfactory clustering outcomes. Our work investigates how multi-modal large language models (MLLMs) can be leveraged to achieve user-driven clustering, emphasizing their adaptability to user-specified semantic requirements. However, directly using MLLM output for clustering has risks for producing unstructured and generic image descriptions instead of feature-specific and concrete ones. To address these issues, our method first discovers that MLLMs' hidden states of text tokens are strongly related to the corresponding features, and leverages these embeddings to perform clusterings from any user-defined criteria. We also employ a lightweight clustering head augmented with pseudo-label learning, significantly enhancing clustering accuracy. Extensive experiments demonstrate its competitive performance on diverse datasets and metrics.

</details>


### [39] [Deep Learning for Modeling and Dispatching Hybrid Wind Farm Power Generation](https://arxiv.org/abs/2512.00728)
*Zach Lawrence,Jessica Yao,Chris Qin*

Main category: cs.LG

TL;DR: 开发了两个深度学习框架：COVE-NN用于风电场储能调度，以及功率生成建模框架，共同提升数据驱动调度策略的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 混合风电场（风电场+储能）需要有效的调度策略来最大化风能价值。数据驱动的调度策略使用本地电网需求和市场条件作为输入参数，而基于大气条件的合成功率生成数据可以进一步提高调度策略的鲁棒性。

Method: 开发了两个深度学习框架：1) COVE-NN：基于LSTM的调度策略，针对单个风电场定制；2) 功率生成建模框架，用于合成功率生成数据建模。

Result: 在Pyron站点的案例研究中，COVE-NN在43年模拟运行中将年度COVE降低了32.3%；功率生成建模框架在Palouse风电场验证中将RMSE降低了9.5%，功率曲线相似性提高了18.9%。

Conclusion: 这些模型为更鲁棒的数据驱动调度策略铺平了道路，并可能扩展到其他可再生能源系统。

Abstract: Wind farms with integrated energy storage, or hybrid wind farms, are able to store energy and dispatch it to the grid following an operational strategy. For individual wind farms with integrated energy storage capacity, data-driven dispatch strategies using localized grid demand and market conditions as input parameters stand to maximize wind energy value. Synthetic power generation data modeled on atmospheric conditions provide another avenue for improving the robustness of data-driven dispatch strategies. To these ends, the present work develops two deep learning frameworks: COVE-NN, an LSTM-based dispatch strategy tailored to individual wind farms, which reduced annual COVE by 32.3% over 43 years of simulated operations in a case study at the Pyron site; and a power generation modeling framework that reduced RMSE by 9.5% and improved power curve similarity by 18.9% when validated on the Palouse wind farm. Together, these models pave the way for more robust, data-driven dispatch strategies and potential extensions to other renewable energy systems.

</details>


### [40] [REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories](https://arxiv.org/abs/2512.00736)
*Jacob Thompson,Emiliano Garcia-Lopez,Yonatan Bisk*

Main category: cs.LG

TL;DR: REM基准测试揭示多模态大语言模型在空间推理能力上的严重不足，尽管经过大量视频训练，仍无法像人类一样建立视角独立的认知地图，限制了其在具身应用中的发展。


<details>
  <summary>Details</summary>
Motivation: 人类通过导航建立视角独立的认知地图，能够直观推理物体恒存性和空间关系。多模态大语言模型尽管经过大量视频训练，但缺乏这种基本的空间推理能力，这是具身应用发展的关键限制。

Method: 引入REM基准测试，使用可控的3D环境进行长时程具身空间推理评估。系统评估物体恒存性/区分、空间关系和动态视角下的数值追踪等关键方面。

Result: 当前最佳模型显示出有希望的整体性能，但在中等复杂度的任务上就变得不可靠，而这些任务对人类来说很容易处理。模型从序列视觉输入中发展稳健空间表征面临挑战。

Conclusion: REM基准提供了有针对性的指标和诊断工具，以促进未来模型空间理解能力的改进，解决多模态大语言模型在空间推理方面的根本局限性。

Abstract: Humans build viewpoint-independent cognitive maps through navigation, enabling intuitive reasoning about object permanence and spatial relations. We argue that multimodal large language models (MLLMs), despite extensive video training, lack this fundamental spatial reasoning capability, a critical limitation for embodied applications. To demonstrate these limitations and drive research, we introduce REM (Reasoning over Embodied Multi-Frame Trajectories), a benchmark using controllable 3D environments for long-horizon embodied spatial reasoning. REM systematically evaluates key aspects like object permanence/distinction, spatial relationships, and numerical tracking across dynamic embodied viewpoints. Our evaluation shows that the best-performing current models exhibit promising overall performance, but become increasingly unreliable at even moderate complexity levels easily handled by humans. These findings highlight challenges MLLMs face in developing robust spatial representations from sequential visual input. Consequently, REM provides targeted metrics and diagnostics to foster improved spatial understanding in future models.

</details>


### [41] [Provable Benefit of Sign Descent: A Minimal Model Under Heavy-Tailed Class Imbalance](https://arxiv.org/abs/2512.00763)
*Robin Yadav,Shuo Xie,Tianhao Wang,Zhiyuan Li*

Main category: cs.LG

TL;DR: 该论文研究了自适应优化方法（如Adam）在LLM预训练中的优势，特别关注ℓ∞范数下降（符号下降）在存在重尾类别不平衡的数据分布下的收敛优势。


<details>
  <summary>Details</summary>
Motivation: 自适应优化方法在LLM预训练中表现优于梯度下降，但现有研究提出的平滑性假设在语言建模任务中的具体表现尚不清楚。本文旨在直接从数据分布特性（重尾类别不平衡）分析ℓ∞范数下降的优势。

Method: 提出了一个最小但具有代表性的下一个token预测设置，在该设置中可以理论上证明在存在重尾类别不平衡时，坐标级算法（如符号下降）相对于归一化梯度下降的更快收敛性。

Result: 理论上证明了在重尾类别不平衡的数据分布下，符号下降（ℓ∞范数下降）比归一化梯度下降（ℓ2范数下降）具有更快的收敛速度。

Conclusion: 通过从数据分布特性（重尾类别不平衡）而非平滑性假设的角度分析，解释了自适应优化方法在语言建模任务中的优势，为理解Adam等算法在LLM预训练中的成功提供了新的理论视角。

Abstract: Adaptive optimization methods (such as Adam) play a major role in LLM pretraining, significantly outperforming Gradient Descent (GD). Recent studies have proposed new smoothness assumptions on the loss function to explain the advantages of adaptive algorithms with structured preconditioners, e.g., coordinate-wise or layer-wise, and steepest descent methods w.r.t. non-euclidean norms, e.g., $\ell_\infty$ norm or spectral norm, over GD. However, it remains unclear how these smoothness assumptions manifest in language modelling tasks. In this work, we aim to analyze the benefit of $\ell_\infty$-norm descent (a.k.a. sign descent) directly from properties of the data distribution, namely, heavy-tailed class imbalance. We propose a minimal yet representative setting of next-token prediction, where we can provably show faster convergence of coordinate-wise algorithms such as Sign descent (steepest descent w.r.t. $\ell_\infty$ norm) over normalized GD (steepest descent w.r.t. to $\ell_2$ norm) in the presence of heavy tail class imbalance.

</details>


### [42] [Text Mining Analysis of Symptom Patterns in Medical Chatbot Conversations](https://arxiv.org/abs/2512.00768)
*Hamed Razavi*

Main category: cs.LG

TL;DR: 该研究利用多种NLP方法分析医疗聊天机器人对话中的症状描述，通过主题建模、聚类、实体识别和关联规则挖掘，将非结构化对话转化为可操作的诊断信号。


<details>
  <summary>Details</summary>
Motivation: 随着数字健康系统的快速发展，需要更好地理解它们如何解释和表示患者报告的症状。聊天机器人在医疗保健中的应用为从文本数据中提取有意义的临床模式提供了可能，但需要系统的方法来分析这些对话中的症状描述模式。

Method: 使用多方法NLP方法：1) LDA主题建模识别潜在症状主题；2) K-Means聚类按相似性分组症状描述；3) 基于Transformer的NER提取医学概念；4) Apriori算法发现频繁症状对。使用包含960个多轮对话的医学对话数据集，涵盖24种临床状况。

Result: 分析结果显示：1) 具有临床相关主题的连贯结构；2) 中等水平的聚类内聚性；3) 发现高置信度的症状关联关系（如发烧-头痛、皮疹-瘙痒）。证明对话医疗数据可作为有价值的早期症状解释诊断信号。

Conclusion: 该研究展示了将非结构化自由对话转化为症状相关可操作知识的方法，为增强未来医疗聊天机器人的性能、可靠性和临床实用性提供了可扩展框架，有助于加强决策支持和改善用户与远程医疗技术的互动。

Abstract: The fast growth of digital health systems has led to a need to better comprehend how they interpret and represent patient-reported symptoms. Chatbots have been used in healthcare to provide clinical support and enhance the user experience, making it possible to provide meaningful clinical patterns from text-based data through chatbots. The proposed research utilises several different natural language processing methods to study the occurrences of symptom descriptions in medicine as well as analyse the patterns that emerge through these conversations within medical bots. Through the use of the Medical Conversations to Disease Dataset which contains 960 multi-turn dialogues divided into 24 Clinical Conditions, a standardised representation of conversations between patient and bot is created for further analysis by computational means. The multi-method approach uses a variety of tools, including Latent Dirichlet Allocation (LDA) to identify latent symptom themes, K-Means to group symptom descriptions by similarity, Transformer-based Named Entity Recognition (NER) to extract medical concepts, and the Apriori algorithm to discover frequent symptom pairs. Findings from the analysis indicate a coherent structure of clinically relevant topics, moderate levels of clustering cohesiveness and several high confidence rates on the relationships between symptoms like fever headache and rash itchiness. The results support the notion that conversational medical data can be a valuable diagnostic signal for early symptom interpretation, assist in strengthening decision support and improve how users interact with tele-health technology. By demonstrating a method for converting unstructured free-flowing dialogue into actionable knowledge regarding symptoms this work provides an extensible framework to further enhance future performance, dependability and clinical utility of selecting medical chatbots.

</details>


### [43] [What Is Preference Optimization Doing, How and Why?](https://arxiv.org/abs/2512.00778)
*Yue Wang,Qizhou Wang,Zizhuo Zhang,Ang Li,Gang Niu,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 该论文分析了直接偏好优化（DPO）和近端策略优化（PPO）两种偏好优化方法的优化动态差异，揭示了它们不同的算法行为机制和组件作用。


<details>
  <summary>Details</summary>
Motivation: 虽然DPO和PPO在大型语言模型偏好优化中都取得了成功，但普遍认为DPO是监督学习而PPO是强化学习，这种差异背后的深层原因缺乏系统分析。论文旨在填补这一空白，深入理解两种方法的优化动态差异。

Method: 通过分析梯度更新的目标方向，研究正向学习、负向学习和损失重加权三个关键组件的作用，并进行精心设计的消融实验来验证分析结果。

Result: 发现DPO遵循稳定目标，而PPO遵循动态目标以平衡探索和利用；在DPO中正向和负向学习共同塑造学习目标并相互抵消，损失重加权主要起正则化作用；在PPO中负向学习主要支持探索，损失重加权与token级优势的绝对值相关，指示不同token组在更新目标中的角色。

Conclusion: 研究不仅加深了对偏好优化方法的理解，还为开发更偏好对齐的大型语言模型提供了理论指导和实践启示。

Abstract: Preference optimization (PO) is indispensable for large language models (LLMs), with methods such as direct preference optimization (DPO) and proximal policy optimization (PPO) achieving great success. A common belief is that DPO is supervised learning while PPO is reinforcement learning, yet deeper analyses for the reasons underlying these differences remain lacking. To fill this gap, we analyze their optimization dynamics, revealing distinct algorithmic behaviors and comprehending their underlying causes. First, we examine the target directions of gradient-based updates and find that DPO follows stable targets, whereas PPO follows dynamic targets that balance exploration and exploitation, thus validating the common belief from a new perspective. Second, we examine the roles of positive learning, negative learning, and loss reweighting, which are three key components in PO methods. Our analyses reveal that these components play fairly different roles. In DPO, positive and negative learning jointly shape the learning targets meanwhile mutually offset each other. However, loss reweighting in DPO acts less as a reward signal but more as a regularizer to mitigate overfitting. In PPO, negative learning primarily supports exploration rather than determining the targets. Meanwhile, loss reweighting, related to absolute values of token-level advantages, indicates the distinct roles of token groups in updating targets. Given these findings, we conduct carefully designed ablation studies to further examine how controlling these dynamics impacts optimization efficiency and practical performance. The insights gained from our analyses not only deepen the understanding of PO methods but also inspire the development of more preference-aligned LLMs.

</details>


### [44] [Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment](https://arxiv.org/abs/2512.00783)
*Libo Wang*

Main category: cs.LG

TL;DR: 本研究构建了名为"Sigma"的VLA模型，在单张RTX 4090上运行，通过结合深度语义理解和关联的架构，实现了人形机器人的"心灵感应"通信和意图驱动控制。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人认知系统中缺乏可在语义和连续控制之间进行时间更新的中介思维空间的问题。

Method: 以开源pi05_base模型为基础，预处理svla_so101_pickplace数据集，设计结合深度语义理解和关联的视觉-语言-动作模型架构，通过数据预处理、LoRA微调和推理阶段适配器的重复优化进行训练。

Result: Sigma在向量、片段和完整轨迹时间尺度上表现出稳定的控制均方误差下降，同时保持"心灵感应"规范和语义-文本对齐质量不变。

Conclusion: 通过结合深度语义理解和关联的架构，无需重新训练基础模型即可实现心灵响应对齐控制，为人形机器人的语义对齐和意图驱动行为提供了可复现的经验。

Abstract: To address the gap in humanoid robot cognitive systems regarding the lack of a time-updable mediating thought space between semantics and continuous control, this study constructs and trains a VLA model named "Sigma" that runs on a single RTX 4090. It uses the open-source pi05_base model as a foundation and preprocesses svla_so101_pickplace into a training dataset. The researcher independently designed an architecture for a vision-language-action model that combines deep semantic understanding and association to achieve telepathic communication. The training process involved repeated optimizations of data preprocessing, LoRA fine-tuning, and the inference-stage adapter. The experiment employed offline closed-loop replay, comparing Sigma with the untuned pure pi05_base_base model under data conditions. Results showed that Sigma exhibited a stable decrease in control MSE across vector, fragment, and entire trajectory timescales, while maintaining the telepathy norm and semantic-text alignment quality unchanged. It demonstrates that mind-responsive alignment control is quantified through an architecture that combines deep understanding of semantics and association without retraining the base model, which provides reproducible experience for semantic alignment and intention-driven behavior in humanoid robots.

</details>


### [45] [Limitations of Using Identical Distributions for Training and Testing When Learning Boolean Functions](https://arxiv.org/abs/2512.00791)
*Jordi Pérez-Guijarro*

Main category: cs.LG

TL;DR: 研究发现训练分布与测试分布完全一致并不总是最优选择，这与传统学习方法的假设相反，但在特定正则性条件下，均匀分布情况下传统结论仍然成立


<details>
  <summary>Details</summary>
Motivation: 当训练数据和测试数据的分布不一致时，理解泛化问题变得更加复杂。本文旨在探究一个基本问题：训练分布是否总是应该与测试分布完全相同？

Method: 假设单向函数存在，通过理论分析探讨训练分布与测试分布匹配的最优性问题，并考察在目标函数施加特定正则性条件下的情况

Result: 研究发现训练分布与测试分布完全匹配并不总是最优选择，这与大多数学习方法的假设相矛盾。但在目标函数具有特定正则性时，对于均匀分布情况，传统结论仍然成立

Conclusion: 训练分布与测试分布完全一致并不总是最优策略，这一发现挑战了传统机器学习假设。但在特定条件下（如目标函数具有正则性、均匀分布），传统结论仍然有效

Abstract: When the distributions of the training and test data do not coincide, the problem of understanding generalization becomes considerably more complex, prompting a variety of questions. In this work, we focus on a fundamental one: Is it always optimal for the training distribution to be identical to the test distribution? Surprisingly, assuming the existence of one-way functions, we find that the answer is no. That is, matching distributions is not always the best scenario, which contrasts with the behavior of most learning methods. Nonetheless, we also show that when certain regularities are imposed on the target functions, the standard conclusion is recovered in the case of the uniform distribution.

</details>


### [46] [Soft Quality-Diversity Optimization](https://arxiv.org/abs/2512.00810)
*Saeed Hedayatian,Stefanos Nikolaidis*

Main category: cs.LG

TL;DR: 该论文提出了Soft QD框架，通过避免离散化来解决传统QD算法在大解空间和高维行为空间中的可扩展性问题，并基于此开发了SQUAD算法。


<details>
  <summary>Details</summary>
Motivation: 传统QD算法通过将行为空间离散化为区域来维持多样性，但在大解空间和高维行为空间中面临存储困难和维度灾难问题，需要更可扩展的解决方案。

Method: 提出了Soft QD框架，避免了对行为空间的离散化，并基于此开发了SQUAD算法——一种可微分的QD算法，使用近似多样性度量。

Result: SQUAD算法在标准基准测试中与当前最先进方法竞争，同时在更高维度问题上展现出更好的可扩展性。

Conclusion: Soft QD框架为QD优化提供了离散化替代方案，SQUAD算法在保持竞争力的同时提高了对高维问题的可扩展性。

Abstract: Quality-Diversity (QD) algorithms constitute a branch of optimization that is concerned with discovering a diverse and high-quality set of solutions to an optimization problem. Current QD methods commonly maintain diversity by dividing the behavior space into discrete regions, ensuring that solutions are distributed across different parts of the space. The QD problem is then solved by searching for the best solution in each region. This approach to QD optimization poses challenges in large solution spaces, where storing many solutions is impractical, and in high-dimensional behavior spaces, where discretization becomes ineffective due to the curse of dimensionality. We present an alternative framing of the QD problem, called \emph{Soft QD}, that sidesteps the need for discretizations. We validate this formulation by demonstrating its desirable properties, such as monotonicity, and by relating its limiting behavior to the widely used QD Score metric. Furthermore, we leverage it to derive a novel differentiable QD algorithm, \emph{Soft QD Using Approximated Diversity (SQUAD)}, and demonstrate empirically that it is competitive with current state of the art methods on standard benchmarks while offering better scalability to higher dimensional problems.

</details>


### [47] [Causal Invariance and Counterfactual Learning Driven Cooperative Game for Multi-Label Classification](https://arxiv.org/abs/2512.00812)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 提出因果合作博弈框架，通过结合因果推断与合作博弈理论解决多标签分类中的标签不平衡、伪相关和分布偏移问题，特别提升稀有标签预测性能。


<details>
  <summary>Details</summary>
Motivation: 多标签分类面临标签不平衡、伪相关和分布偏移等挑战，这些问题对稀有标签预测尤为不利，需要更鲁棒的解决方案。

Method: 提出因果合作博弈框架，整合神经结构方程模型进行显式因果发现，使用反事实好奇心奖励驱动鲁棒特征学习，加入因果不变性损失确保跨环境泛化，并采用专门的稀有标签增强策略。

Result: 在广泛基准测试中，该方法在稀有标签预测和整体鲁棒性方面显著优于强基线模型。

Conclusion: 通过消融研究和定性分析验证了各组件有效性，表明因果推断与合作博弈理论的协同作用对推进多标签学习具有重要潜力。

Abstract: Multi-label classification (MLC) remains vulnerable to label imbalance, spurious correlations, and distribution shifts, challenges that are particularly detrimental to rare label prediction. To address these limitations, we introduce the Causal Cooperative Game (CCG) framework, which conceptualizes MLC as a cooperative multi-player interaction. CCG unifies explicit causal discovery via Neural Structural Equation Models with a counterfactual curiosity reward to drive robust feature learning. Furthermore, it incorporates a causal invariance loss to ensure generalization across diverse environments, complemented by a specialized enhancement strategy for rare labels. Extensive benchmarking demonstrates that CCG substantially outperforms strong baselines in both rare label prediction and overall robustness. Through rigorous ablation studies and qualitative analysis, we validate the efficacy and interpretability of our components, underscoring the potential of synergizing causal inference with cooperative game theory for advancing multi-label learning.

</details>


### [48] [Uncertainty Quantification for Deep Regression using Contextualised Normalizing Flows](https://arxiv.org/abs/2512.00835)
*Adriel Sosa Marco,John Daniel Kirwan,Alexia Toumpa,Simos Gerasimou*

Main category: cs.LG

TL;DR: MCNF是一种新颖的后处理不确定性量化方法，可为深度回归模型同时生成预测区间和完整的条件预测分布，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：预测区间方法忽略了分布信息，无法处理多模态或非对称分布；贝叶斯方法虽然能获得预测后验密度，但需要大幅修改模型架构并重新训练。需要一种既能提供完整分布信息又无需重新训练的方法。

Method: MCNF是一种后处理不确定性量化方法，在已训练的预测模型之上运行，无需重新训练模型。它能够同时生成预测区间和完整的条件预测分布。

Result: 实验证明MCNF的不确定性估计具有良好的校准性，与最先进的不确定性量化方法具有竞争力，并为下游决策任务提供了更丰富的信息。

Conclusion: MCNF提供了一种有效的不确定性量化解决方案，既能保持模型架构不变，又能提供完整的分布信息，适用于高风险领域的决策制定。

Abstract: Quantifying uncertainty in deep regression models is important both for understanding the confidence of the model and for safe decision-making in high-risk domains. Existing approaches that yield prediction intervals overlook distributional information, neglecting the effect of multimodal or asymmetric distributions on decision-making. Similarly, full or approximated Bayesian methods, while yielding the predictive posterior density, demand major modifications to the model architecture and retraining. We introduce MCNF, a novel post hoc uncertainty quantification method that produces both prediction intervals and the full conditioned predictive distribution. MCNF operates on top of the underlying trained predictive model; thus, no predictive model retraining is needed. We provide experimental evidence that the MCNF-based uncertainty estimate is well calibrated, is competitive with state-of-the-art uncertainty quantification methods, and provides richer information for downstream decision-making tasks.

</details>


### [49] [Prediction-space knowledge markets for communication-efficient federated learning on multimedia tasks](https://arxiv.org/abs/2512.00841)
*Wenzhang Du*

Main category: cs.LG

TL;DR: KTA v2是一种联邦学习中的预测空间知识交易市场方法，通过共享logits而非完整模型参数，在通信效率大幅提升的同时，显著优于传统参数平均方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在分布式多媒体数据协同训练中面临统计异质性和通信约束的挑战，特别是当客户端部署大型模型时。传统的参数平均方法如FedAvg传输完整模型权重，在非独立同分布数据下容易发散。

Method: 提出KTA v2预测空间知识交易市场：1）客户端在私有数据上本地训练，仅在小公共参考集上共享logits；2）服务器在预测空间构建客户端相似度图，结合参考集准确率形成个性化教师集成；3）发送软目标进行第二阶段蒸馏更新。该方法可解释为具有预测空间正则化的统一目标上的近似块坐标下降。

Result: 在FEMNIST、CIFAR-10和AG News数据集上的实验表明，在可比或更低通信预算下，KTA v2始终优于本地基线、参数方法（FedAvg、FedProx），并显著超越FedMD式全局教师。在CIFAR-10上使用ResNet-18达到57.7%测试准确率，通信量约为FedAvg的1/1100；在AG News上达到89.3%准确率，通信量约为FedAvg的1/300。

Conclusion: KTA v2通过预测空间知识交易有效解决了联邦学习中的统计异质性和通信约束问题，在保持高模型性能的同时大幅降低通信开销，为大规模分布式学习提供了高效解决方案。

Abstract: Federated learning (FL) enables collaborative training over distributed multimedia data but suffers acutely from statistical heterogeneity and communication constraints, especially when clients deploy large models. Classic parameter-averaging methods such as FedAvg transmit full model weights and can diverge under nonindependent and identically distributed (non-IID) data. We propose KTA v2, a prediction-space knowledge trading market for FL. Each round, clients locally train on their private data, then share only logits on a small public reference set. The server constructs a client-client similarity graph in prediction space, combines it with reference-set accuracy to form per-client teacher ensembles, and sends back personalized soft targets for a second-stage distillation update. This two-stage procedure can be interpreted as approximate block-coordinate descent on a unified objective with prediction-space regularization. Experiments on FEMNIST, CIFAR-10 and AG News show that, under comparable or much lower communication budgets, KTA v2 consistently outperforms a local-only baseline and strong parameter-based methods (FedAvg, FedProx), and substantially improves over a FedMD-style global teacher. On CIFAR-10 with ResNet-18, KTA v2 reaches 57.7% test accuracy using approximately 1/1100 of FedAvg's communication, while on AG News it attains 89.3% accuracy with approximately 1/300 of FedAvg's traffic.

</details>


### [50] [Topological Federated Clustering via Gravitational Potential Fields under Local Differential Privacy](https://arxiv.org/abs/2512.00849)
*Yunbo Long,Jiaquan Zhang,Xi Chen,Alexandra Brintrup*

Main category: cs.LG

TL;DR: GFC提出了一种基于引力势场拓扑持久性的联邦聚类方法，在强LDP噪声下显著优于现有方法，无需迭代通信即可实现隐私与精度的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中非IID数据在本地差分隐私下的聚类难题，克服现有基于距离方法在强LDP噪声和数据异构性下的性能退化问题。

Method: 1) 客户端紧凑感知扰动机制，将局部聚类几何编码为"质量"值；2) 服务器端拓扑聚合阶段，通过势场超水平集的持久同调分析提取稳定质心。

Result: 理论证明隐私预算ε与质心估计误差的闭式界，势场的Lipschitz平滑特性在高密度区域指数抑制噪声。在10个基准测试中，特别是在强LDP约束(ε<1)下优于现有方法。

Conclusion: 通过将联邦聚类重构为合成物理空间中的拓扑持久性问题，GFC实现了无需迭代通信的隐私-精度权衡，为隐私保护分布式学习提供了新视角。

Abstract: Clustering non-independent and identically distributed (non-IID) data under local differential privacy (LDP) in federated settings presents a critical challenge: preserving privacy while maintaining accuracy without iterative communication. Existing one-shot methods rely on unstable pairwise centroid distances or neighborhood rankings, degrading severely under strong LDP noise and data heterogeneity. We present Gravitational Federated Clustering (GFC), a novel approach to privacy-preserving federated clustering that overcomes the limitations of distance-based methods under varying LDP. Addressing the critical challenge of clustering non-IID data with diverse privacy guarantees, GFC transforms privatized client centroids into a global gravitational potential field where true cluster centers emerge as topologically persistent singularities. Our framework introduces two key innovations: (1) a client-side compactness-aware perturbation mechanism that encodes local cluster geometry as "mass" values, and (2) a server-side topological aggregation phase that extracts stable centroids through persistent homology analysis of the potential field's superlevel sets. Theoretically, we establish a closed-form bound between the privacy budget $ε$ and centroid estimation error, proving the potential field's Lipschitz smoothing properties exponentially suppress noise in high-density regions. Empirically, GFC outperforms state-of-the-art methods on ten benchmarks, especially under strong LDP constraints ($ε< 1$), while maintaining comparable performance at lower privacy budgets. By reformulating federated clustering as a topological persistence problem in a synthetic physics-inspired space, GFC achieves unprecedented privacy-accuracy trade-offs without iterative communication, providing a new perspective for privacy-preserving distributed learning.

</details>


### [51] [Robust Probabilistic Load Forecasting for a Single Household: A Comparative Study from SARIMA to Transformers on the REFIT Dataset](https://arxiv.org/abs/2512.00856)
*Midhun Manoj*

Main category: cs.LG

TL;DR: 该研究针对REFIT家庭用电数据集，通过季节性插补方法处理数据缺口，系统比较了从传统模型到深度学习模型的概率预测性能，发现TFT模型在点预测准确性和区间预测安全性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 概率预测对于现代风险管理至关重要，但REFIT家庭用电数据集存在大量结构性数据缺口，需要有效处理数据缺失问题并评估不同模型在复杂、非线性、具有机制转换特征数据上的概率预测能力。

Method: 1. 首先通过严格的比较实验选择季节性插补方法处理数据缺口；2. 系统评估了从传统基准模型（SARIMA、Prophet）到机器学习（XGBoost）和深度学习架构（LSTM、TFT）的层次化模型；3. 使用RMSE等指标评估点预测准确性，并分析预测区间的校准性和安全性。

Result: 1. 季节性插补方法在线性插补上表现出优势，能更好地保持数据的底层分布；2. 传统模型无法捕捉数据的非线性、机制转换行为；3. LSTM提供了最良好校准的概率预测；4. TFT成为综合表现最佳的模型，获得最佳点预测准确度（RMSE 481.94），并产生更安全、更谨慎的预测区间，能有效捕捉极端波动性。

Conclusion: 对于具有复杂波动性和数据缺口的家庭用电预测问题，TFT模型在点预测准确性和概率预测安全性方面表现最优，是处理此类非线性、机制转换时间序列数据的有效解决方案。

Abstract: Probabilistic forecasting is essential for modern risk management, allowing decision-makers to quantify uncertainty in critical systems. This paper tackles this challenge using the volatile REFIT household dataset, which is complicated by a large structural data gap. We first address this by conducting a rigorous comparative experiment to select a Seasonal Imputation method, demonstrating its superiority over linear interpolation in preserving the data's underlying distribution. We then systematically evaluate a hierarchy of models, progressing from classical baselines (SARIMA, Prophet) to machine learning (XGBoost) and advanced deep learning architectures (LSTM). Our findings reveal that classical models fail to capture the data's non-linear, regime-switching behavior. While the LSTM provided the most well-calibrated probabilistic forecast, the Temporal Fusion Transformer (TFT) emerged as the superior all-round model, achieving the best point forecast accuracy (RMSE 481.94) and producing safer, more cautious prediction intervals that effectively capture extreme volatility.

</details>


### [52] [HBLLM: Wavelet-Enhanced High-Fidelity 1-Bit Quantization for LLMs](https://arxiv.org/abs/2512.00862)
*Ningning Chen,Weicai Ye,Ying Jiang*

Main category: cs.LG

TL;DR: HBLLM是一种基于小波变换的1位后训练量化方法，通过Haar小波变换增强表达能力，采用两种结构感知分组策略，显著提升量化保真度同时保持最小开销。


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署需要高效的量化方法以减少存储和计算成本。现有1位量化方法在保持模型性能方面存在挑战，需要更精细的量化策略来平衡压缩率和模型保真度。

Method: 使用Haar小波变换进行频率分解增强表达能力；采用两种结构感知分组策略：频率感知多参数行内分组和基于ℓ2范数的显著性驱动列选择；对非显著权重在每个频带内使用共享均值优化存储效率。

Result: 在OPT和LLaMA模型上的实验表明，HBLLM在1位量化中达到最先进性能，在LLaMA2-13B上获得6.71的困惑度，平均权重存储仅需1.08位。

Conclusion: HBLLM通过小波增强和结构感知分组策略，实现了高效的大语言模型1位量化，在保持高性能的同时显著减少存储需求，为实际部署提供了有效解决方案。

Abstract: We introduce HBLLM, a wavelet-enhanced high-fidelity $1$-bit post-training quantization method for Large Language Models (LLMs). By leveraging Haar wavelet transforms to enhance expressive capacity through frequency decomposition, HBLLM significantly improves quantization fidelity while maintaining minimal overhead. This approach features two innovative structure-aware grouping strategies: (1) frequency-aware multi-parameter intra-row grouping and (2) $\ell_2$-norm-based saliency-driven column selection. For non-salient weights, a shared mean is employed across quantization groups within each frequency band to optimize storage efficiency. Experiments conducted on the OPT and LLaMA models demonstrate that HBLLM achieves state-of-the-art performance in $1$-bit quantization, attaining a perplexity of $6.71$ on LLaMA$2$-$13$B with an average weight storage of only $1.08$ bits. Code available at: https://github.com/Yeyke/HBLLM.

</details>


### [53] [Towards Active Synthetic Data Generation for Finetuning Language Models](https://arxiv.org/abs/2512.00884)
*Samuel Kessler,Menglin Xia,Daniel Madrigal Diaz,Dongge Han,Helia Heshemi,Saravan Rajmohan,Victor Ruehle,Jordan T. Ash*

Main category: cs.LG

TL;DR: 该论文研究了迭代式闭环生成合成数据用于语言模型微调的方法，相比静态生成能提升学生模型性能，并发现主动学习中的简单选择标准效果最佳。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型能力提升通常通过使用"教师"模型生成的合成数据微调"学生"模型，但大多数方法在训练前一次性生成所有数据。本文旨在研究在训练过程中迭代生成新合成样本的方法，探索闭环生成方式是否能更有效地利用有限的生成样本或计算预算。

Method: 采用迭代式闭环生成方法，根据学生模型当前状态指导合成数据的生成。在固定生成样本预算或教师模型查询计算预算下，比较了静态生成与动态生成的效果。特别测试了主动学习文献中的简单、低成本选择标准，并与专门针对LLM的方法进行比较。

Result: 在四个数学和逻辑推理数据集上使用四个不同的小型语言模型进行验证，结果显示：1）迭代闭环生成方式相比静态生成能显著提升学生模型性能；2）主动学习中的简单选择标准比专门针对LLM的方法表现更好。

Conclusion: 迭代式闭环生成合成数据是有效的语言模型微调策略，能够更高效地利用有限的计算资源。主动学习中的简单选择标准在这一任务中表现出色，为语言模型微调提供了实用且经济的方法。

Abstract: A common and effective means for improving language model capabilities involves finetuning a ``student'' language model's parameters on generations from a more proficient ``teacher'' model. Termed ``synthetic data'', these generations are often produced before any student finetuning, but some work has considered generating new synthetic samples as training progresses. This paper studies and advocates for the latter case, where data are generated in an iterative, closed-loop fashion that is guided by the current state of the student model. For a fixed budget of generated samples, or a budget in terms of compute spent querying a teacher, we show that this curation of finetuning data affords improved student performance over static generation. Further, while there have been several LLM-specific methods proposed that operate in this regime, we find that simple, inexpensive selection criteria from the active learning literature tend to be most performant. We validate these claims across four mathematical and logical reasoning datasets using four different small language models.

</details>


### [54] [Light-Weight Benchmarks Reveal the Hidden Hardware Cost of Zero-Shot Tabular Foundation Models](https://arxiv.org/abs/2512.00888)
*Aayam Bansal,Ishaan Gangwani*

Main category: cs.LG

TL;DR: 论文对零样本基础模型在表格数据上的硬件开销进行了基准测试，发现传统树模型在精度相当的情况下硬件需求远低于基础模型。


<details>
  <summary>Details</summary>
Motivation: 虽然零样本基础模型承诺无需训练即可处理表格数据，但其硬件开销尚未得到充分研究。本文旨在量化基础模型与树模型在精度和硬件效率之间的权衡。

Method: 在四个公开数据集上建立完全可复现的基准测试，同时报告测试精度、运行时间、CPU内存峰值和GPU显存峰值。比较两个开源基础模型与调优后的树模型在单张NVIDIA T4 GPU上的表现。

Result: 树模型在三个数据集上精度等于或超过基础模型，运行时间≤0.40秒，内存≤150MB，且无需GPU显存。TabICL在Higgs数据集上精度提升0.8个百分点，但需要约40000倍运行时间和9GB显存。TabPFN在精度匹配树模型的情况下需要4GB显存，且无法处理10万行的完整Higgs数据集。

Conclusion: 当前表格基础模型存在显著的硬件开销与精度权衡，树模型在多数情况下仍是更高效的选择。该基准为未来效率导向的研究提供了开放基线。

Abstract: Zero-shot foundation models (FMs) promise training-free prediction on tabular data, yet their hardware footprint remains poorly characterized. We present a fully reproducible benchmark that reports test accuracy together with wall-clock latency, peak CPU RAM, and peak GPU VRAM on four public datasets: Adult-Income, Higgs-100k, Wine-Quality, and California-Housing. Two open FMs (TabPFN-1.0 and TabICL-base) are compared against tuned XGBoost, LightGBM, and Random Forest baselines on a single NVIDIA T4 GPU. The tree ensembles equal or surpass FM accuracy on three datasets while completing full-test batches in <= 0.40 s and <= 150 MB RAM, using zero VRAM. TabICL achieves a 0.8 percentage-point gain on Higgs but requires roughly 40,000 times more latency (960 s) and 9 GB VRAM. TabPFN matches tree-model accuracy on Wine and Housing but peaks at 4 GB VRAM and cannot process the full 100k-row Higgs table. These results quantify the substantial hardware-versus-accuracy trade-offs in current tabular FMs and provide an open baseline for future efficiency-oriented research.

</details>


### [55] [Beyond High-Entropy Exploration: Correctness-Aware Low-Entropy Segment-Based Advantage Shaping for Reasoning LLMs](https://arxiv.org/abs/2512.00908)
*Xinzhu Chen,Xuesheng Li,Zhongxiang Sun,Weijie Yu*

Main category: cs.LG

TL;DR: 论文提出LESS框架，通过细粒度优势调制低熵段来改进强化学习中的推理能力，在数学推理基准上取得显著提升


<details>
  <summary>Details</summary>
Motivation: 现有RLVR研究关注高熵token的探索作用，但忽视了推理轨迹中大部分是包含稳定可重用结构模式的低熵段。研究发现正确回答中低熵段的重叠与模型准确率强相关，而错误回答中的低熵段则表现出稳定但无生产力的模式。

Method: 提出LESS（Low-Entropy Segment Suppression）框架，基于正确性感知的强化学习方法，对低熵段进行细粒度优势调制：放大正确回答独有的低熵段，抑制错误回答独有的低熵段，中和两者共享的低熵段，同时保留底层RL算法中的高熵探索。

Result: 在流行的GRPO基础上实例化LESS，在三种骨干模型和六个数学推理基准上持续优于强RL基线，提高了准确率，并增强了性能底线的鲁棒性。

Conclusion: 通过关注推理轨迹中的低熵结构模式并进行正确性感知的调制，LESS框架能有效提升语言模型的推理能力，证明了低熵段在强化学习中的重要性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a central approach for improving the reasoning ability of large language models. Recent work studies RLVR through token entropy, arguing that high-entropy tokens drive exploration and should receive stronger updates. However, they overlook the fact that most of a reasoning trajectory consists of low-entropy segments that encode stable and reusable structural patterns. Through qualitative and quantitative analyses, we find that the overlap of low-entropy segments across correct responses strongly correlates with model accuracy, while overlaps involving incorrect responses exhibit stable but unproductive patterns. Motivated by these findings, we propose LESS, a correctness-aware reinforcement framework that performs fine-grained advantage modulation over low-entropy segments. LESS amplifies segments unique to correct responses, suppresses those unique to incorrect ones, and neutralizes segments shared by both, while preserving high-entropy exploration in the underlying RL algorithm. Instantiated on top of the popular GRPO, LESS consistently improves accuracy over strong RL baselines across three backbones and six math benchmarks, achieves stronger robustness of the performance floor.

</details>


### [56] [Partially Equivariant Reinforcement Learning in Symmetry-Breaking Environments](https://arxiv.org/abs/2512.00915)
*Junwoo Chang,Minwoo Park,Joohwan Seo,Roberto Horowitz,Jongmin Lee,Jongeun Choi*

Main category: cs.LG

TL;DR: 该论文提出部分群不变MDP框架和相应RL算法，通过选择性应用群不变Bellman备份来处理现实环境中局部对称性破坏问题，在保持等变性优势的同时减少误差传播，提升样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现实环境中几乎不存在完全群不变的MDP，因为动力学、执行器限制和奖励设计通常会破坏对称性，且往往只是局部破坏。在群不变Bellman备份下，局部对称性破坏会引入误差并传播到整个状态-动作空间，导致全局价值估计错误。

Method: 提出部分群不变MDP框架，根据对称性保持情况选择性应用群不变或标准Bellman备份。基于此框架开发了两种实用RL算法：用于离散控制的PE-DQN和用于连续控制的PE-SAC，结合等变性优势与对对称性破坏的鲁棒性。

Result: 在Grid-World、运动控制和操作任务基准测试中，PE-DQN和PE-SAC显著优于基线方法，展示了选择性利用对称性对于鲁棒且样本高效的强化学习的重要性。

Conclusion: 通过选择性应用群不变Bellman备份来处理局部对称性破坏，能够有效减少误差传播，在保持等变性优势的同时提升强化学习的样本效率和泛化能力，为现实世界非完美对称环境提供了更鲁棒的解决方案。

Abstract: Group symmetries provide a powerful inductive bias for reinforcement learning (RL), enabling efficient generalization across symmetric states and actions via group-invariant Markov Decision Processes (MDPs). However, real-world environments almost never realize fully group-invariant MDPs; dynamics, actuation limits, and reward design usually break symmetries, often only locally. Under group-invariant Bellman backups for such cases, local symmetry-breaking introduces errors that propagate across the entire state-action space, resulting in global value estimation errors. To address this, we introduce Partially group-Invariant MDP (PI-MDP), which selectively applies group-invariant or standard Bellman backups depending on where symmetry holds. This framework mitigates error propagation from locally broken symmetries while maintaining the benefits of equivariance, thereby enhancing sample efficiency and generalizability. Building on this framework, we present practical RL algorithms -- Partially Equivariant (PE)-DQN for discrete control and PE-SAC for continuous control -- that combine the benefits of equivariance with robustness to symmetry-breaking. Experiments across Grid-World, locomotion, and manipulation benchmarks demonstrate that PE-DQN and PE-SAC significantly outperform baselines, highlighting the importance of selective symmetry exploitation for robust and sample-efficient RL.

</details>


### [57] [Multi-Modal AI for Remote Patient Monitoring in Cancer Care](https://arxiv.org/abs/2512.00949)
*Yansong Liu,Ronnie Stafford,Pramit Khetrapal,Huriye Kocadag,Graça Carvalho,Patricia de Winter,Maryam Imran,Amelia Snook,Adamos Hadjivasiliou,D. Vijay Anand,Weining Lin,John Kelly,Yukun Zhou,Ivana Drobnjak*

Main category: cs.LG

TL;DR: 开发了一个用于癌症患者远程监测的多模态AI框架，通过整合人口统计学、可穿戴设备、日常调查和临床事件数据，预测未来不良事件风险，在84名患者的观察性试验中达到83.9%的准确率。


<details>
  <summary>Details</summary>
Motivation: 癌症患者在接受系统治疗期间，门诊就诊间隔存在未被监测的副作用风险，需要填补这一护理空白，实现更主动的患者支持。

Method: 开发并前瞻性试验了一个多模态AI远程患者监测框架，整合HALO-X平台的多模态数据（人口统计学、可穿戴传感器、日常调查、临床事件），处理真实世界数据的异步和不完整特性，预测未来不良事件的连续风险。

Result: 在84名患者（6,080患者日，210万数据点）的观察性试验中，模型达到83.9%的准确率（AUROC=0.70）。识别出既往治疗、健康检查、每日最大心率为关键预测特征。案例研究显示模型能在事件发生前提供风险升级预警。

Conclusion: 这项工作证明了多模态AI远程监测在癌症护理中的可行性，为实现更主动的患者支持提供了路径。

Abstract: For patients undergoing systemic cancer therapy, the time between clinic visits is full of uncertainties and risks of unmonitored side effects. To bridge this gap in care, we developed and prospectively trialed a multi-modal AI framework for remote patient monitoring (RPM). This system integrates multi-modal data from the HALO-X platform, such as demographics, wearable sensors, daily surveys, and clinical events. Our observational trial is one of the largest of its kind and has collected over 2.1 million data points (6,080 patient-days) of monitoring from 84 patients. We developed and adapted a multi-modal AI model to handle the asynchronous and incomplete nature of real-world RPM data, forecasting a continuous risk of future adverse events. The model achieved an accuracy of 83.9% (AUROC=0.70). Notably, the model identified previous treatments, wellness check-ins, and daily maximum heart rate as key predictive features. A case study demonstrated the model's ability to provide early warnings by outputting escalating risk profiles prior to the event. This work establishes the feasibility of multi-modal AI RPM for cancer care and offers a path toward more proactive patient support.(Accepted at Europe NeurIPS 2025 Multimodal Representation Learning for Healthcare Workshop)

</details>


### [58] [WUSH: Near-Optimal Adaptive Transforms for LLM Quantization](https://arxiv.org/abs/2512.00956)
*Jiale Chen,Vage Egiazarian,Torsten Hoefler,Dan Alistarh*

Main category: cs.LG

TL;DR: 提出WUSH变换方法，结合Hadamard基和数据依赖的二阶矩，优化低比特量化中权重和激活的联合量化效果


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署中，低比特量化是标准方法，但极端权重和激活值会拉伸动态范围，降低量化器有效分辨率。现有固定正交变换（如Hadamard矩阵）忽略数据统计特性，其最优性未得到理论证明

Method: 首次推导出闭式最优线性分块变换用于联合权重-激活量化，基于RTN和AbsMax缩放分块量化器，结合Hadamard基和数据依赖的二阶矩分量，形成非正交但结构化的WUSH变换

Result: 在温和假设下证明WUSH变换的最优性，实验结果显示该方法在常见数值格式下一致优于Hadamard变换

Conclusion: WUSH变换通过数据感知的线性变换有效改善低比特量化效果，为量化部署提供理论保证和实用方法

Abstract: Quantization to low bitwidth is a standard approach for deploying large language models, however, a few extreme weights and activations stretch the dynamic range and reduce the effective resolution of the quantizer. A common mitigation approach is to apply some fixed orthogonal transforms, such as Hadamard matrices, before quantization, which typically reduces the dynamic range. Yet, these transforms ignore the statistics of the data, and their optimality is currently not understood. In this work, we derive, for the first time, closed-form optimal linear blockwise transforms for joint weight-activation quantization using standard data-free quantizers for common numerical formats. Specifically, we provide derivations of the optimal adaptive (data-aware) transforms for round-to-nearest (RTN), AbsMax-scaled block quantizers for both integer and floating-point formats. The resulting construction, which we call WUSH, combines a Hadamard backbone with a data-dependent component based on second-order moments, yielding a non-orthogonal transform that is provably optimal under mild assumptions and remains structured for efficient implementation. Preliminary experimental results show that our approach consistently improves upon the Hadamard transform for common formats.

</details>


### [59] [Goal-Driven Reward by Video Diffusion Models for Reinforcement Learning](https://arxiv.org/abs/2512.00961)
*Qi Wang,Mian Wu,Yuyang Zhang,Mingqi Yuan,Wenyao Zhang,Haoxiang You,Yunbo Wang,Xin Jin,Xiaokang Yang,Wenjun Zeng*

Main category: cs.LG

TL;DR: 利用预训练视频扩散模型为强化学习提供目标驱动的奖励信号，无需人工设计奖励函数


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖精心设计的程序化奖励函数，但设计这样的奖励函数具有挑战性且难以跨任务泛化。需要一种无需人工设计奖励的方法来指导智能体行为。

Method: 利用预训练视频扩散模型提供视频级和帧级目标奖励：1) 视频级奖励：在领域特定数据集上微调视频扩散模型，使用其视频编码器评估智能体轨迹与生成目标视频的潜在表示对齐程度；2) 帧级奖励：使用CLIP从生成视频中识别最相关帧作为目标状态，通过前向-后向表示学习计算到达目标状态的概率作为帧级奖励。

Result: 在多个Meta-World任务上的实验证明了该方法的有效性。

Conclusion: 利用预训练视频扩散模型中的丰富世界知识可以为强化学习提供有效的目标驱动奖励信号，避免了人工设计奖励函数的挑战，并能促进更连贯和目标驱动的轨迹。

Abstract: Reinforcement Learning (RL) has achieved remarkable success in various domains, yet it often relies on carefully designed programmatic reward functions to guide agent behavior. Designing such reward functions can be challenging and may not generalize well across different tasks. To address this limitation, we leverage the rich world knowledge contained in pretrained video diffusion models to provide goal-driven reward signals for RL agents without ad-hoc design of reward. Our key idea is to exploit off-the-shelf video diffusion models pretrained on large-scale video datasets as informative reward functions in terms of video-level and frame-level goals. For video-level rewards, we first finetune a pretrained video diffusion model on domain-specific datasets and then employ its video encoder to evaluate the alignment between the latent representations of agent's trajectories and the generated goal videos. To enable more fine-grained goal-achievement, we derive a frame-level goal by identifying the most relevant frame from the generated video using CLIP, which serves as the goal state. We then employ a learned forward-backward representation that represents the probability of visiting the goal state from a given state-action pair as frame-level reward, promoting more coherent and goal-driven trajectories. Experiments on various Meta-World tasks demonstrate the effectiveness of our approach.

</details>


### [60] [Subgroup Validity in Machine Learning for Echocardiogram Data](https://arxiv.org/abs/2512.00976)
*Cynthia Feeney,Shane Williams,Benjamin S. Wessler,Michael C. Hughes*

Main category: cs.LG

TL;DR: 当前超声心动图数据集在人口统计学报告方面存在不足，无法验证深度学习模型在不同亚组（性别、种族、民族）中的有效性，需要更多代表性数据和亚组分析。


<details>
  <summary>Details</summary>
Motivation: 超声心动图数据集可用于训练深度学习模型自动化解读心脏超声，但现有数据集在患者性别、种族、民族等人口统计学信息报告不足，且未评估亚组特异性预测性能，这引发了模型部署前的亚组有效性担忧。

Method: 1. 改善两个数据集（TMED-2和MIMIC-IV-ECHO）的社会人口统计学报告；2. 分析六个开放数据集的人口统计学覆盖情况；3. 对TMED-2数据集上已发表的主动脉瓣狭窄检测模型进行探索性亚组分析。

Result: 1. 当前开放数据集无法缓解亚组有效性担忧；2. 数据集未考虑性别多样化患者，许多种族和民族群体患者数量不足；3. 对主动脉瓣狭窄检测模型的亚组分析显示，在性别、种族、民族亚组中缺乏足够的亚组有效性证据。

Conclusion: 需要更多代表性不足亚组的数据、改进的人口统计学报告以及亚组聚焦的分析，以证明未来工作中的亚组有效性。

Abstract: Echocardiogram datasets enable training deep learning models to automate interpretation of cardiac ultrasound, thereby expanding access to accurate readings of diagnostically-useful images. However, the gender, sex, race, and ethnicity of the patients in these datasets are underreported and subgroup-specific predictive performance is unevaluated. These reporting deficiencies raise concerns about subgroup validity that must be studied and addressed before model deployment. In this paper, we show that current open echocardiogram datasets are unable to assuage subgroup validity concerns. We improve sociodemographic reporting for two datasets: TMED-2 and MIMIC-IV-ECHO. Analysis of six open datasets reveals no consideration of gender-diverse patients and insufficient patient counts for many racial and ethnic groups. We further perform an exploratory subgroup analysis of two published aortic stenosis detection models on TMED-2. We find insufficient evidence for subgroup validity for sex, racial, and ethnic subgroups. Our findings highlight that more data for underrepresented subgroups, improved demographic reporting, and subgroup-focused analyses are needed to prove subgroup validity in future work.

</details>


### [61] [Operator-Theoretic Framework for Gradient-Free Federated Learning](https://arxiv.org/abs/2512.01025)
*Mohit Kumar,Mathias Brucker,Alexander Valentinitsch,Adnan Husakovic,Ali Abbas,Manuela Geiß,Bernhard A. Moser*

Main category: cs.LG

TL;DR: 提出基于算子理论的联邦学习框架，通过RKHS映射实现梯度自由学习，支持差分隐私和全同态加密，在异构环境下性能优于基于梯度的方法


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中的异构性、严格通信计算限制和隐私保护问题，同时确保性能，提供数学理论基础替代基于梯度的方法

Method: 使用算子理论框架将L²最优解映射到再生核希尔伯特空间，通过前向算子近似，利用逆算子映射回原空间；设计基于核仿射壳机器的核方法，客户端通过标量空间折叠度量传输知识，支持差分隐私和全同态加密

Result: 在四个基准测试中，梯度自由的联邦学习方法匹配或优于基于梯度的微调方法，提升达23.7分；差分隐私实验中核平滑缓解了高隐私要求下的精度损失；全局规则支持全同态加密实现

Conclusion: 该框架提供可证明的保证，通信开销低，支持通过标量摘要进行隐私知识传输，产生全同态加密兼容的预测规则，为异构联邦学习提供了数学基础扎实的替代方案

Abstract: Federated learning must address heterogeneity, strict communication and computation limits, and privacy while ensuring performance. We propose an operator-theoretic framework that maps the $L^2$-optimal solution into a reproducing kernel Hilbert space (RKHS) via a forward operator, approximates it using available data, and maps back with the inverse operator, yielding a gradient-free scheme. Finite-sample bounds are derived using concentration inequalities over operator norms, and the framework identifies a data-dependent hypothesis space with guarantees on risk, error, robustness, and approximation. Within this space we design efficient kernel machines leveraging the space folding property of Kernel Affine Hull Machines. Clients transfer knowledge via a scalar space folding measure, reducing communication and enabling a simple differentially private protocol: summaries are computed from noise-perturbed data matrices in one step, avoiding per-round clipping and privacy accounting. The induced global rule requires only integer minimum and equality-comparison operations per test point, making it compatible with fully homomorphic encryption (FHE). Across four benchmarks, the gradient-free FL method with fixed encoder embeddings matches or outperforms strong gradient-based fine-tuning, with gains up to 23.7 points. In differentially private experiments, kernel smoothing mitigates accuracy loss in high-privacy regimes. The global rule admits an FHE realization using $Q \times C$ encrypted minimum and $C$ equality-comparison operations per test point, with operation-level benchmarks showing practical latencies. Overall, the framework provides provable guarantees with low communication, supports private knowledge transfer via scalar summaries, and yields an FHE-compatible prediction rule offering a mathematically grounded alternative to gradient-based federated learning under heterogeneity.

</details>


### [62] [World Model Robustness via Surprise Recognition](https://arxiv.org/abs/2512.01119)
*Geigh Zollicoffer,Tanush Chopra,Mingkuan Yan,Xiaoxu Ma,Kenneth Eaton,Mark Riedl*

Main category: cs.LG

TL;DR: 提出一种利用世界模型惊奇度来减少噪声影响的算法，通过多表示和单表示拒绝采样增强基于世界模型的强化学习智能体对传感器噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署的AI系统面临各种干扰和分布外噪声，这些噪声可能破坏策略稳定性并导致不安全行为。虽然鲁棒训练可以减少对某些噪声的敏感性，但无法预知所有可能的OOD条件。

Method: 开发了一种利用世界模型固有惊奇度测量来减少噪声影响的算法。引入了多表示和单表示拒绝采样技术，能够处理多个故障传感器或单个故障传感器的情况。

Result: 在多种噪声类型和水平下，该方法在多个自动驾驶仿真环境（CARLA和Safety Gymnasium）中保持了相对于基线的性能。同时增强了两种不同架构的先进世界模型（Cosmos和DreamerV3）的稳定性。

Conclusion: 该方法展示了在不同世界建模领域中的鲁棒性，为解决现实世界AI系统面临的噪声和干扰问题提供了有效解决方案。

Abstract: AI systems deployed in the real world must contend with distractions and out-of-distribution (OOD) noise that can destabilize their policies and lead to unsafe behavior. While robust training can reduce sensitivity to some forms of noise, it is infeasible to anticipate all possible OOD conditions. To mitigate this issue, we develop an algorithm that leverages a world model's inherent measure of surprise to reduce the impact of noise in world model--based reinforcement learning agents. We introduce both multi-representation and single-representation rejection sampling, enabling robustness to settings with multiple faulty sensors or a single faulty sensor. While the introduction of noise typically degrades agent performance, we show that our techniques preserve performance relative to baselines under varying types and levels of noise across multiple environments within self-driving simulation domains (CARLA and Safety Gymnasium). Furthermore, we demonstrate that our methods enhance the stability of two state-of-the-art world models with markedly different underlying architectures: Cosmos and DreamerV3. Together, these results highlight the robustness of our approach across world modeling domains. We release our code at https://github.com/Bluefin-Tuna/WISER .

</details>


### [63] [Mode-Conditioning Unlocks Superior Test-Time Scaling](https://arxiv.org/abs/2512.01127)
*Chen Henry Wu,Sachin Goyal,Aditi Raghunathan*

Main category: cs.LG

TL;DR: ModC框架通过显式分配推理模式的计算资源，解决了并行采样中的多样性崩溃问题，在多个推理基准上显著提升了测试时扩展效率。


<details>
  <summary>Details</summary>
Motivation: 并行采样在测试时扩展中具有巨大潜力，但其效果受到多样性崩溃的严重限制——模型集中在少数模式上，重复采样产生相同错误。标准训练未能充分利用数据多样性。

Method: 提出模式条件化（ModC）框架，通过专家模型或模式特定前缀显式分配测试时计算资源到不同推理模式。还展示了梯度聚类方法可在无需显式模式标签的情况下实现ModC。

Result: ModC在受控图搜索任务和大规模推理基准上一致改善扩展效果，涵盖0.5B到7B的模型系列。在OpenThoughts上，ModC微调的Qwen2.5-7B相比标准训练实现4倍效率提升，同时提高最大可达Pass@k。梯度聚类方法在NuminaMath等数据集上带来高达10%的增益。ModC还能改进强化学习并增强多样性诱导的RL方法。

Conclusion: 标准训练未能充分利用数据多样性，而ModC提供了一个简单有效的解决方案，能够解锁多样性在测试时扩展中的全部优势，显著提升并行采样的效率和质量。

Abstract: Parallel sampling promises substantial gains in test-time scaling, but its effectiveness is sharply limited by diversity collapse, where models concentrate on a few modes and repeated samples produce the same mistakes. We propose the mode-conditioning (ModC) framework, which explicitly allocates test-time compute across reasoning modes using either specialist models or mode-specific prefixes. ModC consistently improves scaling across controlled graph-search tasks and large-scale reasoning benchmarks, spanning model families and sizes from 0.5B to 7B. On OpenThoughts, fine-tuning Qwen2.5-7B with ModC achieves a 4x efficiency gain over standard training while also improving the maximum attainable Pass@k. We further show that gradient clustering enables ModC without explicit mode labels, yielding up to 10% gains on datasets such as NuminaMath. Finally, we show that ModC improves reinforcement learning (RL) and can further boost diversity-inducing RL methods. These results demonstrate that standard training underutilizes the diversity in data, and that ModC provides a simple, effective remedy for unlocking the full benefits of diversity in test-time scaling.

</details>


### [64] [Dynamic Algorithm for Explainable k-medians Clustering under lp Norm](https://arxiv.org/abs/2512.01150)
*Konstantin Makarychev,Ilias Papanikolaou,Liren Shan*

Main category: cs.LG

TL;DR: 本文提出了首个适用于所有有限p≥1的lp范数下的可解释k-medians聚类算法，实现了O(p(log k)^{1+1/p-1/p²})的近似比，并开发了支持动态更新的实现版本。


<details>
  <summary>Details</summary>
Motivation: 可解释聚类旨在构建易于理解的阈值决策树来划分数据，但现有算法仅支持p=1和p=2的范数，缺乏通用解决方案，且无法适应动态数据集的变化。

Method: 设计了适用于所有有限p≥1的lp范数的可解释k-medians算法，通过阈值决策树进行数据划分，并实现了动态版本以支持插入和删除操作。

Result: 算法实现了O(p(log k)^{1+1/p-1/p²})的近似比，对于p=2改进了现有的O(log^{3/2}k)界限，对于p=1接近紧界log k+O(1)。动态版本具有O(d log³k)的摊销更新时间和O(log k)的调整代价。

Conclusion: 本文首次为所有有限p≥1的lp范数提供了可解释k-medians聚类算法，填补了理论空白，并开发了高效的动态实现，适用于大规模和演化数据集。

Abstract: We study the problem of explainable k-medians clustering introduced by Dasgupta, Frost, Moshkovitz, and Rashtchian (2020). In this problem, the goal is to construct a threshold decision tree that partitions data into k clusters while minimizing the k-medians objective. These trees are interpretable because each internal node makes a simple decision by thresholding a single feature, allowing users to trace and understand how each point is assigned to a cluster. We present the first algorithm for explainable k-medians under lp norm for every finite p >= 1. Our algorithm achieves an O(p(log k)^{1 + 1/p - 1/p^2}) approximation to the optimal k-medians cost for any p >= 1. Previously, algorithms were known only for p = 1 and p = 2. For p = 2, our algorithm improves upon the existing bound of O(log^{3/2}k), and for p = 1, it matches the tight bound of log k + O(1) up to a multiplicative O(log log k) factor. We show how to implement our algorithm in a dynamic setting. The dynamic algorithm maintains an explainable clustering under a sequence of insertions and deletions, with amortized update time O(d log^3 k) and O(log k) recourse, making it suitable for large-scale and evolving datasets.

</details>


### [65] [Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution](https://arxiv.org/abs/2512.01152)
*Shravan Chaudhari,Yoav Wald,Suchi Saria*

Main category: cs.LG

TL;DR: 本文提出了一种名为Ours的方法，能够在背景分布发生变化的挑战性情况下解决开放集识别问题，并在理论和实证上都证明了其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在现实世界部署机器学习系统时，核心挑战是即使在数据分布发生变化时也能保持模型性能。现有开放集识别方法大多假设背景分布固定，但实际中背景分布也会发生变化，需要开发能够应对这种挑战的方法。

Method: 提出了Ours方法，该方法在理论上保证即使在背景分布发生变化的情况下也能解决开放集识别问题。方法基于新类别与非新类别可分离的良性假设，并开发了使方法可扩展和鲁棒的技术。

Result: 在图像和文本数据上的综合实证评估表明，Ours方法在背景分布变化的情况下显著优于现有的开放集识别方法。同时提供了关于新类别大小等因素如何影响性能的新见解。

Conclusion: 本文开发了一种能够在背景分布变化情况下有效解决开放集识别问题的方法，为这一具有挑战性的问题提供了理论和实证上的解决方案，并揭示了影响开放集识别性能的关键因素。

Abstract: As we deploy machine learning systems in the real world, a core challenge is to maintain a model that is performant even as the data shifts. Such shifts can take many forms: new classes may emerge that were absent during training, a problem known as open-set recognition, and the distribution of known categories may change. Guarantees on open-set recognition are mostly derived under the assumption that the distribution of known classes, which we call \emph{the background distribution}, is fixed. In this paper we develop \ours{}, a method that is guaranteed to solve open-set recognition even in the challenging case where the background distribution shifts. We prove that the method works under benign assumptions that the novel class is separable from the non-novel classes, and provide theoretical guarantees that it outperforms a representative baseline in a simplified overparameterized setting. We develop techniques to make \ours{} scalable and robust, and perform comprehensive empirical evaluations on image and text data. The results show that \ours{} significantly outperforms existing open-set recognition methods under background shift. Moreover, we provide new insights into how factors such as the size of the novel class influences performance, an aspect that has not been extensively explored in prior work.

</details>


### [66] [From Regression to Classification: Exploring the Benefits of Categorical Representations of Energy in MLIPs](https://arxiv.org/abs/2512.01160)
*Ahmad Ali*

Main category: cs.LG

TL;DR: 该论文提出了一种将机器学习原子间势能预测从标量回归转变为多分类的方法，通过预测能量/力的直方图分布来量化模型不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习原子间势能模型采用标量回归方法，只能预测单一能量值和相应的力，无法量化模型的不确定性。作者希望开发一种能够提供更丰富监督信号并量化模型置信度的方法。

Method: 将能量/力预测问题重新表述为多分类任务：预测能量/力的直方图分布，将标量目标转换为直方图，使用交叉熵损失训练模型。

Result: 分类方法在绝对误差性能上与回归基线相当，同时能够通过预测分布的熵来量化认知不确定性，提供模型置信度的度量。

Conclusion: 多分类方法为机器学习原子间势能提供了有前景的替代方案，不仅保持了预测准确性，还引入了模型不确定性量化能力，这在标量回归方法中是无法实现的。

Abstract: Density Functional Theory (DFT) is a widely used computational method for estimating the energy and behavior of molecules. Machine Learning Interatomic Potentials (MLIPs) are models trained to approximate DFT-level energies and forces at dramatically lower computational cost. Many modern MLIPs rely on a scalar regression formulation; given information about a molecule, they predict a single energy value and corresponding forces while minimizing absolute error with DFT's calculations. In this work, we explore a multi-class classification formulation that predicts a categorical distribution over energy/force values, providing richer supervision through multiple targets. Most importantly, this approach offers a principled way to quantify model uncertainty.
  In particular, our method predicts a histogram of the energy/force distribution, converts scalar targets into histograms, and trains the model using cross-entropy loss. Our results demonstrate that this categorical formulation can achieve absolute error performance comparable to regression baselines. Furthermore, this representation enables the quantification of epistemic uncertainty through the entropy of the predicted distribution, offering a measure of model confidence absent in scalar regression approaches.

</details>


### [67] [2D-ThermAl: Physics-Informed Framework for Thermal Analysis of Circuits using Generative AI](https://arxiv.org/abs/2512.01163)
*Soumyadeep Chandra,Sayeed Shafayet Chowdhury,Kaushik Roy*

Main category: cs.LG

TL;DR: ThermAl是一个基于物理信息的生成式AI框架，能够直接从输入活动配置文件识别热源并估计全芯片瞬态和稳态温度分布，相比传统FEM方法快约200倍，精度达0.71°C RMSE。


<details>
  <summary>Details</summary>
Motivation: 现代集成电路中非均匀功耗和高晶体管密度导致快速温度峰值和可靠性问题。传统FEM模拟精度高但计算成本大，不适合早期设计阶段，需要多次迭代重新设计来解决后期热故障。

Method: 提出ThermAl物理信息生成式AI框架，采用增强位置编码和玻尔兹曼正则化的混合U-Net架构来保持物理保真度。使用COMSOL生成从简单逻辑门到复杂设计的广泛热耗散图数据集进行训练。

Result: ThermAl为大型电路提供精确温度映射，RMSE仅0.71°C，比传统FEM工具快约200倍。在25-95°C扩展数据集上交叉验证，即使在峰值功率和应力场景下也能保持高精度（<2.2%满量程RMSE）。

Conclusion: ThermAl框架能够高效准确地进行早期热点检测和热模式学习，适用于大规模EDA工作流程，解决了传统热分析方法在早期设计阶段计算成本过高的问题。

Abstract: Thermal analysis is increasingly critical in modern integrated circuits, where non-uniform power dissipation and high transistor densities can cause rapid temperature spikes and reliability concerns. Traditional methods, such as FEM-based simulations offer high accuracy but computationally prohibitive for early-stage design, often requiring multiple iterative redesign cycles to resolve late-stage thermal failures. To address these challenges, we propose 'ThermAl', a physics-informed generative AI framework which effectively identifies heat sources and estimates full-chip transient and steady-state thermal distributions directly from input activity profiles. ThermAl employs a hybrid U-Net architecture enhanced with positional encoding and a Boltzmann regularizer to maintain physical fidelity. Our model is trained on an extensive dataset of heat dissipation maps, ranging from simple logic gates (e.g., inverters, NAND, XOR) to complex designs, generated via COMSOL. Experimental results demonstrate that ThermAl delivers precise temperature mappings for large circuits, with a root mean squared error (RMSE) of only 0.71°C, and outperforms conventional FEM tools by running up to ~200 times faster. We analyze performance across diverse layouts and workloads, and discuss its applicability to large-scale EDA workflows. While thermal reliability assessments often extend beyond 85°C for post-layout signoff, our focus here is on early-stage hotspot detection and thermal pattern learning. To ensure generalization beyond the nominal operating range 25-55°C, we additionally performed cross-validation on an extended dataset spanning 25-95°C maintaining a high accuracy (<2.2% full-scale RMSE) even under elevated temperature conditions representative of peak power and stress scenarios.

</details>


### [68] [A TinyML Reinforcement Learning Approach for Energy-Efficient Light Control in Low-Cost Greenhouse Systems](https://arxiv.org/abs/2512.01167)
*Mohamed Abdallah Salem,Manuel Cuevas Perez,Ahmed Harb Rabia*

Main category: cs.LG

TL;DR: 基于Q学习的强化学习控制策略，在低功耗微控制器上实现自适应照明调节，通过LDR传感器反馈动态调整LED亮度，在13个不同光照强度级别上稳定运行。


<details>
  <summary>Details</summary>
Motivation: 探索轻量级、设备端强化学习在资源受限环境中的可行性，为农业系统等多模态环境控制应用奠定基础，实现节能照明控制。

Method: 采用无模型Q学习算法，基于光敏电阻(LDR)传感器实时反馈，在64状态空间中动态调整LED亮度，针对13个目标光照强度级别进行训练，共进行130次试验。

Result: 实验验证表明，智能体能够有效学习在不同光照级别下稳定运行，收敛平滑且超调最小，即使在环境扰动下也能保持良好性能，通过箱线图和直方图分析了训练时间和学习效率分布。

Conclusion: 该研究证明了轻量级设备端强化学习在节能照明控制中的可行性，为资源受限农业系统中的多模态环境控制应用奠定了基础。

Abstract: This study presents a reinforcement learning (RL)-based control strategy for adaptive lighting regulation in controlled environments using a low-power microcontroller. A model-free Q-learning algorithm was implemented to dynamically adjust the brightness of a Light-Emitting Diode (LED) based on real-time feedback from a light-dependent resistor (LDR) sensor. The system was trained to stabilize at 13 distinct light intensity levels (L1 to L13), with each target corresponding to a specific range within the 64-state space derived from LDR readings. A total of 130 trials were conducted, covering all target levels with 10 episodes each. Performance was evaluated in terms of convergence speed, steps taken, and time required to reach target states. Box plots and histograms were generated to analyze the distribution of training time and learning efficiency across targets. Experimental validation demonstrated that the agent could effectively learn to stabilize at varying light levels with minimal overshooting and smooth convergence, even in the presence of environmental perturbations. This work highlights the feasibility of lightweight, on-device RL for energy-efficient lighting control and sets the groundwork for multi-modal environmental control applications in resource-constrained agricultural systems.

</details>


### [69] [First On-Orbit Demonstration of a Geospatial Foundation Model](https://arxiv.org/abs/2512.01181)
*Andrew Du,Roberto Del Prete,Alejandro Mousist,Nick Manser,Fabrice Marre,Andrew Barton,Carl Seubert,Gabriele Meoni,Tat-Jun Chin*

Main category: cs.LG

TL;DR: 该研究开发了紧凑型地理空间基础模型，通过模型压缩和领域适应技术，在保持性能的同时实现资源受限空间硬件上的部署。


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型具有广泛的地球观测任务泛化能力，但其大尺寸限制了在资源受限空间硬件上的部署。需要解决模型大小与部署可行性之间的矛盾。

Method: 提出了基于Vision Transformer的紧凑型地理空间基础模型变体，采用模型压缩和领域适应技术，在五个下游任务上进行评估，并在两个代表性飞行环境中验证。

Result: 模型压缩和领域适应能有效减小模型尺寸和资源需求，同时在操作条件下保持高性能。在国际空间站的IMAGIN-e有效载荷上实现了可靠的轨道推理。

Conclusion: 研究建立了从大型地理空间基础模型到飞行就绪、资源高效部署的路径，扩展了地球观测任务中机载人工智能的可行性。

Abstract: Geospatial foundation models (GeoFMs) promise broad generalisation capacity for Earth observation (EO) tasks, particularly under data-limited conditions. However, their large size poses a barrier to deployment on resource-constrained space hardware. To address this, we present compact variants of a Vision Transformer (ViT)-based GeoFM that preserve downstream task performance while enabling onboard execution. Evaluation across five downstream tasks and validation in two representative flight environments show that model compression and domain adaptation are critical to reducing size and resource demands while maintaining high performance under operational conditions. We further demonstrate reliable on-orbit inference with the IMAGIN-e payload aboard the International Space Station. These results establish a pathway from large GeoFMs to flight-ready, resource-efficient deployments, expanding the feasibility of onboard AI for EO missions.

</details>


### [70] [Teaching by Failure: Counter-Example-Driven Curricula for Transformer Self-Improvement](https://arxiv.org/abs/2512.01187)
*Harshil Vejendla*

Main category: cs.LG

TL;DR: CEDC框架通过自动发现模型失败案例并针对性训练，显著提升Transformer模型在算法和自然语言任务上的外推能力


<details>
  <summary>Details</summary>
Motivation: Transformer模型在面对比训练数据更长或更复杂的输入时，常常表现出脆弱的外推能力。现有方法需要手动设计难度启发式，效率低下且效果有限。

Method: 提出Counter-Example-Driven Curricula (CEDC)框架：1) 使用当前模型生成多样化的候选问题；2) 通过快速可执行的验证器识别错误预测（反例）；3) 在包含这些失败案例的数据集上微调模型。整个过程迭代进行，自动聚焦于模型自身的失败点。

Result: 在整数加法、排序、Dyck-2语言识别和三个文本分类基准测试中，CEDC相比静态训练和标准课程学习方法：1) 长度外推能力提升高达30倍；2) 计算效率比均匀数据增强高3.75倍；3) 无需手动难度启发式。反例分析显示课程能自然适应更复杂的错误模式。

Conclusion: 验证器引导的失败驱动学习是一个简单、强大且高效的范式，能显著增强Transformer模型的泛化能力。CEDC通过自动发现和针对性训练模型失败案例，有效解决了模型外推脆弱性问题。

Abstract: Transformer models often exhibit brittle extrapolation, failing on inputs that are longer or structurally more complex than those seen during training. We introduce Counter-Example-Driven Curricula (CEDC), an automated framework that improves model robustness by iteratively focusing on its own failures. At each step, CEDC uses the current model to generate a diverse set of candidate problems, employs a fast, executable verifier to identify incorrect predictions (counter-examples), and then fine-tunes the model on a dataset enriched with these discovered failures. We evaluate CEDC on a suite of algorithmic and natural language tasks, including integer addition, sorting, Dyck-2 language recognition, and three text classification benchmarks. Compared to static training and standard curriculum learning baselines, CEDC achieves up to 30x greater length extrapolation, is 3.75x more computationally efficient than uniform data augmentation, and requires no manual difficulty heuristics. We provide a detailed analysis of the counter-examples, showing how the curriculum naturally adapts to target progressively more complex error modes. Our findings establish verifier-guided, failure-driven learning as a simple, powerful, and efficient paradigm for enhancing the generalization capabilities of Transformer models.

</details>


### [71] [LGDC: Latent Graph Diffusion via Spectrum-Preserving Coarsening](https://arxiv.org/abs/2512.01190)
*Nagham Osman,Keyue Jiang,Davide Buffelli,Xiaowen Dong,Laura Toni*

Main category: cs.LG

TL;DR: LGDC是一种混合图生成框架，结合了自回归模型和扩散模型的优势，通过谱保持的粗化-细化双向映射，在潜在空间中用扩散生成图，再恢复细节，从而同时捕捉局部和全局结构。


<details>
  <summary>Details</summary>
Motivation: 现有图生成方法存在局限性：自回归模型擅长捕捉局部结构（如度分布、聚类特性），但无法有效建模全局模式（如谱分布）；而一次性模型（如扩散模型）则相反，擅长全局模式但局部细节不足。需要一种能同时兼顾两者的混合方法。

Method: 提出LGDC（通过谱保持粗化的潜在图扩散）框架：1）使用谱保持的粗化-细化过程在原始图和潜在空间之间建立双向映射；2）在潜在空间中使用扩散模型高效生成潜在图；3）通过细化过程恢复细节，生成完整图。这种方法结合了两种范式的优势。

Result: 实验验证了LGDC的有效性：在局部结构数据集（Tree）上表现与自回归模型相当，在全局结构数据集（Planar, Community-20）上表现与扩散模型相当，证明了混合生成方法的优势。

Conclusion: LGDC成功结合了自回归模型和扩散模型的优势，通过谱保持的潜在空间表示，实现了同时捕捉图结构局部和全局特性的高效生成，为图生成任务提供了一种有效的混合框架。

Abstract: Graph generation is a critical task across scientific domains. Existing methods fall broadly into two categories: autoregressive models, which iteratively expand graphs, and one-shot models, such as diffusion, which generate the full graph at once. In this work, we provide an analysis of these two paradigms and reveal a key trade-off: autoregressive models stand out in capturing fine-grained local structures, such as degree and clustering properties, whereas one-shot models excel at modeling global patterns, such as spectral distributions. Building on this, we propose LGDC (latent graph diffusion via spectrum-preserving coarsening), a hybrid framework that combines strengths of both approaches. LGDC employs a spectrum-preserving coarsening-decoarsening to bidirectionally map between graphs and a latent space, where diffusion efficiently generates latent graphs before expansion restores detail. This design captures both local and global properties with improved efficiency. Empirically, LGDC matches autoregressive models on locally structured datasets (Tree) and diffusion models on globally structured ones (Planar, Community-20), validating the benefits of hybrid generation.

</details>


### [72] [Learning to Reconstruct Temperature Field from Sparse Observations with Implicit Physics Priors](https://arxiv.org/abs/2512.01196)
*Shihang Li,Zhiqiang Gong,Weien Zhou,Yue Gao,Wen Yao*

Main category: cs.LG

TL;DR: IPTR框架利用参考模拟数据作为先验知识，通过双物理嵌入模块融合参考和目标信息，显著提升了热源系统温度场重建的精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 热源系统温度场重建在工程应用中至关重要，但现有方法面临测量成本高、温度场分布随条件变化大的挑战，且通常仅基于目标稀疏测量进行一对一回归，未能有效利用包含热学知识的参考模拟数据。

Method: 提出IPTR框架，引入参考模拟中的稀疏监测-温度场对作为先验知识。设计双物理嵌入模块：隐式物理引导分支使用交叉注意力从参考数据中提取潜在物理知识；辅助编码分支基于傅里叶层捕捉目标观测的空间特征。融合后的表示被解码以重建完整温度场。

Result: 在单条件、多条件和少样本设置下的广泛实验表明，IPTR始终优于现有方法，实现了最先进的重建精度和强大的泛化能力。

Conclusion: IPTR通过有效利用参考模拟数据作为物理先验，解决了温度场重建中的泛化挑战，为工程热监测和可靠性评估提供了更准确、更稳健的解决方案。

Abstract: Accurate reconstruction of temperature field of heat-source systems (TFR-HSS) is crucial for thermal monitoring and reliability assessment in engineering applications such as electronic devices and aerospace structures. However, the high cost of measurement acquisition and the substantial distributional shifts in temperature field across varying conditions present significant challenges for developing reconstruction models with robust generalization capabilities. Existing DNNs-based methods typically formulate TFR-HSS as a one-to-one regression problem based solely on target sparse measurements, without effectively leveraging reference simulation data that implicitly encode thermal knowledge. To address this limitation, we propose IPTR, an implicit physics-guided temperature field reconstruction framework that introduces sparse monitoring-temperature field pair from reference simulations as priors to enrich physical understanding. To integrate both reference and target information, we design a dual physics embedding module consisting of two complementary branches: an implicit physics-guided branch employing cross-attention to distill latent physics from the reference data, and an auxiliary encoding branch based on Fourier layers to capture the spatial characteristics of the target observation. The fused representation is then decoded to reconstruct the full temperature field. Extensive experiments under single-condition, multi-condition, and few-shot settings demonstrate that IPTR consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy and strong generalization capability.

</details>


### [73] [Know Thyself by Knowing Others: Learning Neuron Identity from Population Context](https://arxiv.org/abs/2512.01199)
*Vinam Arora,Divyansha Lachi,Ian J. Knight,Mehdi Azabou,Blake Richards,Cole L. Hurwitz,Josh Siegle,Eva L. Dyer*

Main category: cs.LG

TL;DR: NuCLR是一个自监督学习框架，通过对比学习从不同时间和刺激下的神经元活动中学习表示，用于区分神经元身份，在细胞类型和脑区解码任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 从神经活动中推断神经元类型、连接性和脑区位置仍然是一个重大挑战，需要构建能够区分神经元身份的通用表示学习方法。

Method: 提出NuCLR自监督框架，通过对比学习将同一神经元在不同时间和不同刺激下的表示拉近；使用时空transformer以置换等变的方式整合群体活动，不假设固定神经元顺序。

Result: 在多个电生理和钙成像数据集上，NuCLR表示在线性解码评估中在细胞类型和脑区解码任务上达到新的SOTA，并展现出强大的零样本泛化能力；首次系统分析了神经元级表示学习的缩放效应。

Conclusion: 大规模多样化的神经数据集使模型能够恢复跨动物泛化的神经元身份信息，学习到的表示具有标签效率，仅需少量标记样本即可达到竞争性能。

Abstract: Neurons process information in ways that depend on their cell type, connectivity, and the brain region in which they are embedded. However, inferring these factors from neural activity remains a significant challenge. To build general-purpose representations that allow for resolving information about a neuron's identity, we introduce NuCLR, a self-supervised framework that aims to learn representations of neural activity that allow for differentiating one neuron from the rest. NuCLR brings together views of the same neuron observed at different times and across different stimuli and uses a contrastive objective to pull these representations together. To capture population context without assuming any fixed neuron ordering, we build a spatiotemporal transformer that integrates activity in a permutation-equivariant manner. Across multiple electrophysiology and calcium imaging datasets, a linear decoding evaluation on top of NuCLR representations achieves a new state-of-the-art for both cell type and brain region decoding tasks, and demonstrates strong zero-shot generalization to unseen animals. We present the first systematic scaling analysis for neuron-level representation learning, showing that increasing the number of animals used during pretraining consistently improves downstream performance. The learned representations are also label-efficient, requiring only a small fraction of labeled samples to achieve competitive performance. These results highlight how large, diverse neural datasets enable models to recover information about neuron identity that generalize across animals. Code is available at https://github.com/nerdslab/nuclr.

</details>


### [74] [Sum Rate Maximization in STAR-RIS-UAV-Assisted Networks: A CA-DDPG Approach for Joint Optimization](https://arxiv.org/abs/2512.01202)
*Yujie Huang,Haibin Wan,Xiangcheng Li,Tuanfa Qin,Yun Li,Jun Li,Wen Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于卷积增强深度确定性策略梯度（CA-DDPG）算法的STAR-RIS-UAV辅助无线通信系统优化方法，通过联合优化波束成形、相位偏移和无人机位置来最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: 随着可编程材料的快速发展，可重构智能表面（RIS）成为未来无线通信的关键技术。同时收发可重构智能表面（STAR-RIS）能够同时传输和反射信号，实现全面的信号控制并扩展应用场景。本文引入无人机（UAV）进一步增强系统灵活性，并优化STAR-RIS-UAV辅助无线通信系统的频谱效率。

Method: 提出了一种基于深度强化学习（DRL）的算法，能够迭代优化波束成形、相位偏移和无人机位置，通过与环境持续交互最大化系统和速率。为改进确定性策略的探索能力，引入了随机扰动因子。基于深度确定性策略梯度（DDPG）算法，提出了卷积增强深度确定性策略梯度（CA-DDPG）算法，平衡探索与评估以提升系统和速率。

Result: 仿真结果表明，CA-DDPG算法能够有效与环境交互，优化波束成形矩阵、相位偏移矩阵和无人机位置，从而提高系统容量，相比其他算法获得更好的性能表现。

Conclusion: 本文提出的CA-DDPG算法成功解决了STAR-RIS-UAV辅助无线通信系统的联合优化问题，通过增强探索能力和准确评估状态-动作价值函数，有效提升了系统的频谱效率和整体性能。

Abstract: With the rapid advances in programmable materials, reconfigurable intelligent surfaces (RIS) have become a pivotal technology for future wireless communications. The simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) can both transmit and reflect signals, enabling comprehensive signal control and expanding application scenarios. This paper introduces an unmanned aerial vehicle (UAV) to further enhance system flexibility and proposes an optimization design for the spectrum efficiency of the STAR-RIS-UAV-assisted wireless communication system. We present a deep reinforcement learning (DRL) algorithm capable of iteratively optimizing beamforming, phase shifts, and UAV positioning to maximize the system's sum rate through continuous interactions with the environment. To improve exploration in deterministic policies, we introduce a stochastic perturbation factor, which enhances exploration capabilities. As exploration is strengthened, the algorithm's ability to accurately evaluate the state-action value function becomes critical. Thus, based on the deep deterministic policy gradient (DDPG) algorithm, we propose a convolution-augmented deep deterministic policy gradient (CA-DDPG) algorithm that balances exploration and evaluation to improve the system's sum rate. The simulation results demonstrate that the CA-DDPG algorithm effectively interacts with the environment, optimizing the beamforming matrix, phase shift matrix, and UAV location, thereby improving system capacity and achieving better performance than other algorithms.

</details>


### [75] [Research on Milling Machine Predictive Maintenance Based on Machine Learning and SHAP Analysis in Intelligent Manufacturing Environment](https://arxiv.org/abs/2512.01205)
*Wen Zhao,Jiawen Ding,Xueting Huang,Yibo Zhang*

Main category: cs.LG

TL;DR: 基于AI4I 2020数据集，对工业铣床设备进行预测性维护实验研究，提出结合AI技术的完整预测维护流程，发现XGBoost和随机森林等集成学习方法在故障预测中表现优异，并通过SHAP分析揭示加工温度、扭矩和转速是关键故障影响因素。


<details>
  <summary>Details</summary>
Motivation: 在智能制造背景下，工业设备的预测性维护对于提高生产效率、降低维护成本至关重要。传统维护方式存在滞后性和成本高的问题，需要结合人工智能技术实现更精准的故障预测和维护决策。

Method: 提出完整的预测性维护实验流程，包括六个主要环节：数据预处理、模型训练、模型评估、模型选择、SHAP分析和结果可视化。使用AI4I 2020数据集，对比分析了八种机器学习模型（包括XGBoost、随机森林等集成学习方法）的性能。

Result: 集成学习方法如XGBoost和随机森林在铣床故障预测任务中表现最佳。通过SHAP分析发现，加工温度、扭矩和转速是影响设备故障的关键因素。该研究为智能制造环境下的预测性维护实践提供了方法论参考。

Conclusion: 该研究成功结合人工智能与制造技术，为智能制造环境下的预测性维护提供了完整的方法论框架，对推动制造业数字化转型、提高生产效率和降低维护成本具有实际意义。

Abstract: In the context of intelligent manufacturing, this paper conducts a series of experimental studies on the predictive maintenance of industrial milling machine equipment based on the AI4I 2020 dataset. This paper proposes a complete predictive maintenance experimental process combining artificial intelligence technology, including six main links: data preprocessing, model training, model evaluation, model selection, SHAP analysis, and result visualization. By comparing and analyzing the performance of eight machine learning models, it is found that integrated learning methods such as XGBoost and random forest perform well in milling machine fault prediction tasks. In addition, with the help of SHAP analysis technology, the influence mechanism of different features on equipment failure is deeply revealed, among which processing temperature, torque and speed are the key factors affecting failure. This study combines artificial intelligence and manufacturing technology, provides a methodological reference for predictive maintenance practice in an intelligent manufacturing environment, and has practical significance for promoting the digital transformation of the manufacturing industry, improving production efficiency and reducing maintenance costs.

</details>


### [76] [Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding](https://arxiv.org/abs/2512.01278)
*Yilong Zhao,Jiaming Tang,Kan Zhu,Zihao Ye,Chi-Chih Chang,Chaofan Lin,Jongseok Park,Guangxuan Xiao,Mohamed S. Abdelfattah,Mingyu Gao,Baris Kasikci,Song Han,Ion Stoica*

Main category: cs.LG

TL;DR: SparseSpec是一个自推测解码框架，通过稀疏注意力机制和系统优化来解决长文本生成中的内存瓶颈问题，实现高达2.13倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 当前推理语言模型在处理复杂任务时通过生成冗长的思维链解决方案，但长文本生成将推理瓶颈从计算限制转变为内存限制。生成每个token都需要对之前所有token进行完整注意力计算，导致KV-Cache内存访问需求不断增加，给内存带宽带来巨大压力。

Method: 提出SparseSpec框架，采用自推测解码（使用相同模型作为草稿和目标模型）。核心创新包括：1) PillarAttn稀疏注意力机制作为草稿模型，通过重用验证阶段信息准确选择关键token；2) 系统级协同设计：统一调度器批处理token草稿和验证、延迟验证实现CPU/GPU重叠、动态KV-Cache管理最大化内存利用率。

Result: 在各种模型和数据集上，SparseSpec优于现有最优解决方案，实现了高达2.13倍的吞吐量加速。

Conclusion: SparseSpec通过创新的稀疏注意力机制和系统级优化，有效解决了长文本生成中的内存瓶颈问题，显著提升了推理效率。

Abstract: Reasoning language models have demonstrated remarkable capabilities on challenging tasks by generating elaborate chain-of-thought (CoT) solutions. However, such lengthy generation shifts the inference bottleneck from compute-bound to memory-bound. To generate each token, the model applies full attention to all previously generated tokens, requiring memory access to an increasingly large KV-Cache. Consequently, longer generations demand more memory access for every step, leading to substantial pressure on memory bandwidth.
  To address this, we introduce SparseSpec, a speculative decoding framework that reuses the same model as the draft and target models (i.e., self-speculation). SparseSpec features a novel sparse attention mechanism, PillarAttn, as the draft model, which accurately selects critical tokens via elegantly reusing information from the verification stage. Furthermore, SparseSpec co-designs self-speculation with three system innovations: (1) a unified scheduler to batch token drafting and verification, (2) delayed verification for CPU/GPU overlap, and (3) dynamic KV-Cache management to maximize memory utilization. Across various models and datasets, SparseSpec outperforms state-of-the-art solutions, with an up to 2.13x throughput speedup.

</details>


### [77] [A Comparative Study of Machine Learning Algorithms for Electricity Price Forecasting with LIME-Based Interpretability](https://arxiv.org/abs/2512.01212)
*Xuanyi Zhao,Jiawen Ding,Xueting Huang,Yibo Zhang*

Main category: cs.LG

TL;DR: 本研究比较了八种机器学习模型在西班牙电力市场价格预测中的表现，发现KNN模型表现最佳，并通过LIME分析提升了模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着电力市场的快速发展，价格波动性显著增加，准确的预测对电力系统运行和市场决策至关重要。传统线性模型无法捕捉电价复杂的非线性特征，需要先进的机器学习方法。

Method: 使用西班牙电力市场数据，整合消费、发电和气象变量，比较了八种机器学习模型：线性回归、岭回归、决策树、KNN、随机森林、梯度提升、SVR和XGBoost。使用LIME分析增强模型可解释性。

Result: KNN模型表现最佳，R²为0.865，MAE为3.556，RMSE为5.240。LIME分析显示气象因素和供需指标通过非线性关系显著影响价格波动。

Conclusion: 本研究证明了机器学习模型在电价预测中的有效性，同时通过可解释性分析提高了决策透明度，为电力市场参与者提供了实用的预测工具。

Abstract: With the rapid development of electricity markets, price volatility has significantly increased, making accurate forecasting crucial for power system operations and market decisions. Traditional linear models cannot capture the complex nonlinear characteristics of electricity pricing, necessitating advanced machine learning approaches. This study compares eight machine learning models using Spanish electricity market data, integrating consumption, generation, and meteorological variables. The models evaluated include linear regression, ridge regression, decision tree, KNN, random forest, gradient boosting, SVR, and XGBoost. Results show that KNN achieves the best performance with R^2 of 0.865, MAE of 3.556, and RMSE of 5.240. To enhance interpretability, LIME analysis reveals that meteorological factors and supply-demand indicators significantly influence price fluctuations through nonlinear relationships. This work demonstrates the effectiveness of machine learning models in electricity price forecasting while improving decision transparency through interpretability analysis.

</details>


### [78] [CoSineVerifier: Tool-Augmented Answer Verification for Computation-Oriented Scientific Questions](https://arxiv.org/abs/2512.01224)
*Ruixiang Feng,Zhenwei An,Yuntao Wen,Ran Le,Yiming Jia,Chen Yang,Zongchao Chen,Lisi Chen,Shen Gao,Shuo Shang,Yang Song,Tao Zhang*

Main category: cs.LG

TL;DR: CoSineVerifier是一个工具增强的验证器，利用外部执行器进行精确计算和符号简化，在STEM、通用QA和长文本推理任务中表现出色，并在RLVR中作为奖励模型优于基于规则和基于模型的验证器。


<details>
  <summary>Details</summary>
Motivation: 当前验证方法在计算导向的科学领域（如代数等价性检查和物理常数替换）面临显著挑战，需要超越简单语义匹配的鲁棒验证方法。

Method: 提出工具增强的验证器CoSineVerifier，采用两阶段训练流程：冷启动微调，然后进行多轮强化学习与工具集成，利用外部执行器进行精确计算和符号简化。

Result: 在STEM科目、通用QA和长文本推理任务上表现出强大的泛化能力，在VerifyBench-Hard和SCI-Bench上达到最先进性能，在AIME'24和AIME'25上作为RLVR奖励模型优于基于规则和基于模型的验证器。

Conclusion: CoSineVerifier通过工具增强验证在科学计算领域实现了鲁棒的验证能力，展示了增强LLM推理能力的强大潜力，模型已在HuggingFace上开源。

Abstract: Answer verification methods are widely employed in language model training pipelines spanning data curation, evaluation, and reinforcement learning with verifiable rewards (RLVR). While prior work focus on developing unified verifiers applicable across multiple reasoning scenarios, significant challenges remain in computation-oriented scientific domains, such as algebraic equivalence checking and physical constant substitution. In this paper, we introduce \model, a tool-augmented verifier that leverages external executors to perform precise computations and symbolic simplifications. \model enables robust verification that goes beyond simple semantic matching. We propose a novel two-stage pipeline, which begin with cold-start fine-tuning and followed by multi-turn reinforcement learning with tool integration. Extensive experiments conducted on STEM subjects, general QA, and long-form reasoning tasks demonstrates strong generalization of \model. The results shows that the \model achieves state-of-the-art performance on VerifyBench-Hard and SCI-Bench. And we also employ our \model in RLVR as a reward model, the results show that it consistently outperforms both rubric-based and model-based verifiers on AIME'24 and AIME'25, demonstrating strong potential to enhance reasoning capabilities of LLM. Our model is released at \hyperlink{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}.

</details>


### [79] [On the Tension Between Optimality and Adversarial Robustness in Policy Optimization](https://arxiv.org/abs/2512.01228)
*Haoran Li,Jiayu Lv,Congying Han,Zicheng Zhang,Anqi Li,Yan Liu,Tiande Guo,Nan Jiang*

Main category: cs.LG

TL;DR: 该论文揭示了深度强化学习中标准策略优化与对抗鲁棒策略优化之间的实践差距，提出了BARPO双层框架来统一两者，通过调节对抗强度实现最优性与鲁棒性的平衡。


<details>
  <summary>Details</summary>
Motivation: 虽然CAR理论表明最优性和对抗鲁棒性可以对齐，但实践中标准策略优化和对抗鲁棒策略优化之间存在根本性张力，需要找到实际可行的方法来调和这一矛盾。

Method: 提出BARPO双层框架，通过调节对抗强度来统一标准策略优化和对抗鲁棒策略优化，改善策略梯度方法的导航性同时保持全局最优性。

Result: BARPO在实证结果中一致优于传统的对抗鲁棒策略优化，提供了调和理论与实证性能的实用方法。

Conclusion: BARPO框架成功缓解了深度强化学习中最优性与对抗鲁棒性之间的实践冲突，为理论一致性到实际实现的转化提供了有效途径。

Abstract: Achieving optimality and adversarial robustness in deep reinforcement learning has long been regarded as conflicting goals. Nonetheless, recent theoretical insights presented in CAR suggest a potential alignment, raising the important question of how to realize this in practice. This paper first identifies a key gap between theory and practice by comparing standard policy optimization (SPO) and adversarially robust policy optimization (ARPO). Although they share theoretical consistency, a fundamental tension between robustness and optimality arises in practical policy gradient methods. SPO tends toward convergence to vulnerable first-order stationary policies (FOSPs) with strong natural performance, whereas ARPO typically favors more robust FOSPs at the expense of reduced returns. Furthermore, we attribute this tradeoff to the reshaping effect of the strongest adversary in ARPO, which significantly complicates the global landscape by inducing deceptive sticky FOSPs. This improves robustness but makes navigation more challenging. To alleviate this, we develop the BARPO, a bilevel framework unifying SPO and ARPO by modulating adversary strength, thereby facilitating navigability while preserving global optima. Extensive empirical results demonstrate that BARPO consistently outperforms vanilla ARPO, providing a practical approach to reconcile theoretical and empirical performance.

</details>


### [80] [Efficient Training of Diffusion Mixture-of-Experts Models: A Practical Recipe](https://arxiv.org/abs/2512.01252)
*Yahui Liu,Yang Yue,Jingyuan Zhang,Chenxi Sun,Yang Zhou,Wencong Zeng,Ruiming Tang,Guorui Zhou*

Main category: cs.LG

TL;DR: 该论文系统探索了扩散专家混合模型的架构配置空间，发现通过精心调整专家模块设计、中间宽度、专家数量等架构因素，比单纯改进路由机制能带来更大性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前扩散专家混合模型研究主要关注路由机制改进，但架构配置空间探索不足。受大语言模型中MoE设计范式启发，作者认为系统研究扩散MoE的关键架构因素对提升模型性能至关重要。

Method: 借鉴LLM中的MoE设计范式，识别并系统研究扩散MoE的关键架构因素：DeepSeek风格专家模块、替代中间宽度、不同专家数量、增强注意力位置编码。在潜空间和像素空间扩散框架中进行广泛实验。

Result: 精心调整架构配置能显著提升扩散MoE模型性能，效果超过单纯路由创新。提出的新架构在激活参数相等或更少的情况下超越强基线模型。

Conclusion: 系统探索扩散MoE架构配置空间至关重要，提供了实用高效训练方案，公开了所有代码和模型，为未来研究奠定基础。

Abstract: Recent efforts on Diffusion Mixture-of-Experts (MoE) models have primarily focused on developing more sophisticated routing mechanisms. However, we observe that the underlying architectural configuration space remains markedly under-explored. Inspired by the MoE design paradigms established in large language models (LLMs), we identify a set of crucial architectural factors for building effective Diffusion MoE models--including DeepSeek-style expert modules, alternative intermediate widths, varying expert counts, and enhanced attention positional encodings. Our systematic study reveals that carefully tuning these configurations is essential for unlocking the full potential of Diffusion MoE models, often yielding gains that exceed those achieved by routing innovations alone. Through extensive experiments, we present novel architectures that can be efficiently applied to both latent and pixel-space diffusion frameworks, which provide a practical and efficient training recipe that enables Diffusion MoE models to surpass strong baselines while using equal or fewer activated parameters. All code and models are publicly available at: https://github.com/yhlleo/EfficientMoE.

</details>


### [81] [Efficient Hyperparameter Search for Non-Stationary Model Training](https://arxiv.org/abs/2512.01258)
*Berivan Isik,Matthew Fahrbach,Dima Kuzmin,Nicolas Mayoraz,Emil Praun,Steffen Rendle,Raghavendra Vasudeva*

Main category: cs.LG

TL;DR: 提出两阶段超参数搜索框架，通过先高效识别有前景配置再完整训练，在非平稳序列数据上实现10倍成本降低


<details>
  <summary>Details</summary>
Motivation: 在线学习系统（如推荐和广告系统）的超参数搜索成本极高，特别是面对持续变化的数据分布时，需要更高效的优化方法

Method: 开发两阶段范式：第一阶段专注于准确识别最有前景的配置（而非追求峰值性能），采用新颖的数据缩减和预测策略处理序列非平稳数据；第二阶段仅完整训练选中的候选配置

Result: 在Criteo 1TB数据集上实现10倍超参数搜索成本降低，在规模大两个数量级的工业广告系统中也验证了显著的效率提升

Conclusion: 通过专注于准确识别而非峰值性能的两阶段方法，能够显著降低在线学习系统的超参数搜索成本，特别是在处理序列非平稳数据时效果显著

Abstract: Online learning is the cornerstone of applications like recommendation and advertising systems, where models continuously adapt to shifting data distributions. Model training for such systems is remarkably expensive, a cost that multiplies during hyperparameter search. We introduce a two-stage paradigm to reduce this cost: (1) efficiently identifying the most promising configurations, and then (2) training only these selected candidates to their full potential. Our core insight is that focusing on accurate identification in the first stage, rather than achieving peak performance, allows for aggressive cost-saving measures. We develop novel data reduction and prediction strategies that specifically overcome the challenges of sequential, non-stationary data not addressed by conventional hyperparameter optimization. We validate our framework's effectiveness through a dual evaluation: first on the Criteo 1TB dataset, the largest suitable public benchmark, and second on an industrial advertising system operating at a scale two orders of magnitude larger. Our methods reduce the total hyperparameter search cost by up to 10$\times$ on the public benchmark and deliver significant, validated efficiency gains in the industrial setting.

</details>


### [82] [Consistency Flow Model Achieves One-step Denoising Error Correction Codes](https://arxiv.org/abs/2512.01389)
*Haoyu Lei,Chin Wa Lau,Kaiwen Zhou,Nian Guo,Farzan Farnia*

Main category: cs.LG

TL;DR: ECCFM是一种用于错误校正码的架构无关训练框架，通过概率流常微分方程实现单步高保真解码，相比扩散模型获得30-100倍推理速度提升


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的神经解码器虽然性能优秀，但其迭代采样过程在低延迟场景下实用性受限，需要设计既准确又计算高效的解码器

Method: 将反向去噪过程建模为概率流常微分方程，通过微分时间正则化强制平滑性，学习将噪声信号沿解码轨迹直接映射到原始码字，实现单步推理

Result: 在多个解码基准测试中，ECCFM获得了比自回归和基于扩散的基线更低的误码率，特别是在长码上表现更优，推理速度比去噪扩散解码器快30-100倍

Conclusion: ECCFM提供了一种架构无关的训练框架，能够在保持高保真度的同时实现单步解码，显著提高了错误校正码神经解码器的实用性和效率

Abstract: Error Correction Codes (ECC) are fundamental to reliable digital communication, yet designing neural decoders that are both accurate and computationally efficient remains challenging. Recent denoising diffusion decoders with transformer backbones achieve state-of-the-art performance, but their iterative sampling limits practicality in low-latency settings. We introduce the Error Correction Consistency Flow Model (ECCFM), an architecture-agnostic training framework for high-fidelity one-step decoding. By casting the reverse denoising process as a Probability Flow Ordinary Differential Equation (PF-ODE) and enforcing smoothness through a differential time regularization, ECCFM learns to map noisy signals along the decoding trajectory directly to the original codeword in a single inference step. Across multiple decoding benchmarks, ECCFM attains lower bit-error rates (BER) than autoregressive and diffusion-based baselines, with notable improvements on longer codes, while delivering inference speeds up from 30x to 100x faster than denoising diffusion decoders.

</details>


### [83] [A Self-explainable Model of Long Time Series by Extracting Informative Structured Causal Patterns](https://arxiv.org/abs/2512.01412)
*Ziqian Wang,Yuxiao Cheng,Jinli Suo*

Main category: cs.LG

TL;DR: EXCAP是一个用于长时间序列解释的统一框架，通过注意力分段、因果结构解码和潜在聚合机制，提供连续、模式中心、因果解耦且忠实于模型推理过程的解释。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI方法仅生成点状重要性分数，无法捕捉时间序列中的趋势、周期和状态变化等时间结构，这削弱了人类对长时间范围模型的可解释性和信任度。

Method: EXCAP结合了三个核心组件：1）基于注意力的分段器提取连贯的时间模式；2）由预训练因果图引导的因果结构解码器；3）强制表示稳定性的潜在聚合机制。

Result: 在分类和预测基准测试中，EXCAP在保持强大预测准确性的同时，生成了连贯且因果基础的解释。理论分析表明EXCAP提供平滑稳定的时间解释，并对因果掩码扰动具有鲁棒性。

Conclusion: EXCAP为长时间序列的可解释建模提供了一个原则性和可扩展的方法，在医疗和金融等高风险领域具有重要应用价值。

Abstract: Explainability is essential for neural networks that model long time series, yet most existing explainable AI methods only produce point-wise importance scores and fail to capture temporal structures such as trends, cycles, and regime changes. This limitation weakens human interpretability and trust in long-horizon models. To address these issues, we identify four key requirements for interpretable time-series modeling: temporal continuity, pattern-centric explanation, causal disentanglement, and faithfulness to the model's inference process. We propose EXCAP, a unified framework that satisfies all four requirements. EXCAP combines an attention-based segmenter that extracts coherent temporal patterns, a causally structured decoder guided by a pre-trained causal graph, and a latent aggregation mechanism that enforces representation stability. Our theoretical analysis shows that EXCAP provides smooth and stable explanations over time and is robust to perturbations in causal masks. Extensive experiments on classification and forecasting benchmarks demonstrate that EXCAP achieves strong predictive accuracy while generating coherent and causally grounded explanations. These results show that EXCAP offers a principled and scalable approach to interpretable modeling of long time series with relevance to high-stakes domains such as healthcare and finance.

</details>


### [84] [ZIP-RC: Zero-overhead Inference-time Prediction of Reward and Cost for Adaptive and Interpretable Generation](https://arxiv.org/abs/2512.01457)
*Rohin Manvi,Joey Hong,Tim Seyde,Maxime Labonne,Mathias Lechner,Sergey Levine*

Main category: cs.LG

TL;DR: ZIP-RC是一种自适应推理方法，通过重用未使用的logits在推理时预测奖励和成本，无需额外模型或架构改变，实现零开销的奖励-成本内省。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型缺乏内省能力，无法预测自身成功概率和所需计算量。人类通过实时内省决定投入多少努力、何时重试、何时停止以及何时发出成功或失败信号。现有方法如Best-of-N使用固定样本预算，不考虑边际效益；学习验证器或奖励模型需要额外模型或前向传播，成本高昂。

Method: ZIP-RC在每次token生成时，重用保留或未使用的logits在同一前向传播中输出最终奖励和剩余长度的联合分布。使用该联合分布计算采样效用（期望最大奖励、总计算和延迟的线性组合），通过最大化效用的元动作决定继续生成哪些token前缀或启动新样本。

Result: 在混合难度数学基准测试中，ZIP-RC在相同或更低平均成本下，相比多数投票准确率提升高达12%，并在质量、计算和延迟之间形成平滑的帕累托前沿。

Conclusion: ZIP-RC通过提供实时奖励-成本内省，实现了自适应、高效的推理，解决了LLM缺乏内省能力的问题，同时避免了额外计算开销。

Abstract: Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.

</details>


### [85] [Multi-view diffusion geometry using intertwined diffusion trajectories](https://arxiv.org/abs/2512.01484)
*Gwendal Debaussart-Joniec,Argyris Kalogeratos*

Main category: cs.LG

TL;DR: 本文提出了一个统一的多视图扩散几何框架，通过交织的多视图扩散轨迹构建，为多视图数据融合提供灵活的方法和理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有多视图扩散模型缺乏统一的框架，需要更灵活的方法来捕捉不同数据视图之间的相互作用和融合。

Method: 提出多视图扩散轨迹（MDTs）框架，通过迭代组合多个数据视图的随机游走算子，构建轨迹相关的扩散算子，并推导相应的扩散距离和嵌入方法。

Result: 建立了MDTs的理论性质（遍历性等），提出了学习MDT算子的策略，并在流形学习和数据聚类实验中验证了方法的有效性。

Conclusion: MDTs提供了一个统一的多视图扩散几何框架，既支持灵活的模型设计，又为评估扩散方法提供了中性基线，在多视图数据分析中具有实用价值。

Abstract: This paper introduces a comprehensive unified framework for constructing multi-view diffusion geometries through intertwined multi-view diffusion trajectories (MDTs), a class of inhomogeneous diffusion processes that iteratively combine the random walk operators of multiple data views. Each MDT defines a trajectory-dependent diffusion operator with a clear probabilistic and geometric interpretation, capturing over time the interplay between data views. Our formulation encompasses existing multi-view diffusion models, while providing new degrees of freedom for view interaction and fusion. We establish theoretical properties under mild assumptions, including ergodicity of both the point-wise operator and the process in itself. We also derive MDT-based diffusion distances, and associated embeddings via singular value decompositions. Finally, we propose various strategies for learning MDT operators within the defined operator space, guided by internal quality measures. Beyond enabling flexible model design, MDTs also offer a neutral baseline for evaluating diffusion-based approaches through comparison with randomly selected MDTs. Experiments show the practical impact of the MDT operators in a manifold learning and data clustering context.

</details>


### [86] [Directed evolution algorithm drives neural prediction](https://arxiv.org/abs/2512.01362)
*Yanlin Wang,Nancy M Young,Patrick C M Wong*

Main category: cs.LG

TL;DR: 提出了一种模仿生物定向进化过程的计算模型（DEM），用于解决神经预测模型在医学AI应用中的领域转移和标签稀缺问题，在儿童人工耳蜗植入者的语言发展预测任务中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 神经预测模型在转化为医学AI应用时面临领域转移和标签稀缺的挑战，特别是在跨数据集预测时性能下降明显，需要新的方法来提高模型的泛化能力和适应能力。

Method: 提出了定向进化模型（DEM），模仿生物定向进化的试错过程来逼近预测任务的最优解。该模型结合了强化学习中的不确定性探索策略，并引入了回放缓冲区和持续反向传播方法来平衡利用和探索。

Result: 在四个不同的人工耳蜗植入儿童数据集上的实验表明，DEM能够有效提高跨领域预植入神经预测的性能，同时解决了目标领域标签稀缺的挑战，相比传统方法在跨数据集预测上表现更优。

Conclusion: 定向进化模型为神经预测任务提供了一种有效的计算框架，能够应对医学AI应用中的领域转移和标签稀缺问题，为个性化干预提供了更好的预测工具。

Abstract: Neural prediction offers a promising approach to forecasting the individual variability of neurocognitive functions and disorders and providing prognostic indicators for personalized invention. However, it is challenging to translate neural predictive models into medical artificial intelligent applications due to the limitations of domain shift and label scarcity. Here, we propose the directed evolution model (DEM), a novel computational model that mimics the trial-and-error processes of biological directed evolution to approximate optimal solutions for predictive modeling tasks. We demonstrated that the directed evolution algorithm is an effective strategy for uncertainty exploration, enhancing generalization in reinforcement learning. Furthermore, by incorporating replay buffer and continual backpropagate methods into DEM, we provide evidence of achieving better trade-off between exploitation and exploration in continuous learning settings. We conducted experiments on four different datasets for children with cochlear implants whose spoken language developmental outcomes vary considerably on the individual-child level. Preoperative neural MRI data has shown to accurately predict the post-operative outcome of these children within but not across datasets. Our results show that DEM can efficiently improve the performance of cross-domain pre-implantation neural predictions while addressing the challenge of label scarcity in target domain.

</details>


### [87] [Reconstructing Multi-Scale Physical Fields from Extremely Sparse Measurements with an Autoencoder-Diffusion Cascade](https://arxiv.org/abs/2512.01572)
*Letian Yi,Tingpeng Zhang,Mingyuan Zhou,Guannan Wang,Quanke Su,Zhilu Lai*

Main category: cs.LG

TL;DR: Cas-Sensing是一个分层重建框架，通过自编码器-扩散级联从极稀疏随机测量中重建完整场，先重建主导结构，再生成细节，显著缓解不适定问题。


<details>
  <summary>Details</summary>
Motivation: 从极稀疏和随机测量中重建完整场是一个长期存在的病态逆问题，需要有效的框架来处理这种挑战。

Method: 提出Cas-Sensing框架：1) 基于神经算子的功能自编码器从稀疏输入重建主导结构；2) 使用掩码级联策略训练的扩散模型生成细节；3) 通过基于贝叶斯后验采样的流形约束梯度增强一致性。

Result: 实验表明Cas-Sensing在不同传感器配置和几何边界上泛化良好，提供准确鲁棒的重建，适合科学和工程应用的实际部署。

Conclusion: Cas-Sensing通过分层概率建模有效缓解病态性，是处理稀疏测量重建问题的有前景工具。

Abstract: Reconstructing full fields from extremely sparse and random measurements is a longstanding ill-posed inverse problem. A powerful framework for addressing such challenges is hierarchical probabilistic modeling, where uncertainty is represented by intermediate variables and resolved through marginalization during inference. Inspired by this principle, we propose Cascaded Sensing (Cas-Sensing), a hierarchical reconstruction framework that integrates an autoencoder-diffusion cascade. First, a neural operator-based functional autoencoder reconstructs the dominant structures of the original field - including large-scale components and geometric boundaries - from arbitrary sparse inputs, serving as an intermediate variable. Then, a conditional diffusion model, trained with a mask-cascade strategy, generates fine-scale details conditioned on these large-scale structures. To further enhance fidelity, measurement consistency is enforced via the manifold constrained gradient based on Bayesian posterior sampling during the generation process. This cascaded pipeline substantially alleviates ill-posedness, delivering accurate and robust reconstructions. Experiments on both simulation and real-world datasets demonstrate that Cas-Sensing generalizes well across varying sensor configurations and geometric boundaries, making it a promising tool for practical deployment in scientific and engineering applications.

</details>


### [88] [HalluGraph: Auditable Hallucination Detection for Legal RAG Systems via Knowledge Graph Alignment](https://arxiv.org/abs/2512.01659)
*Valentin Noël,Elimane Yassine Seidou,Charly Ken Capo-Chichi,Ghanem Amari*

Main category: cs.LG

TL;DR: HalluGraph：基于图结构对齐的法律AI幻觉检测框架，通过实体锚定和关系保持量化幻觉，为法律应用提供可验证的保证


<details>
  <summary>Details</summary>
Motivation: 法律AI系统面临关键的可问责性挑战：当AI助手引用案例法、法规或合同条款时，从业者需要可验证的保证，确保生成的文本忠实地代表源文档。现有的幻觉检测器依赖语义相似度指标，这些指标容忍实体替换，这在混淆当事人、日期或法律条款可能产生实质性后果时是危险的失败模式。

Method: 引入HalluGraph，一个图论框架，通过从上下文、查询和响应中提取的知识图之间的结构对齐来量化幻觉。该方法产生有界、可解释的指标，分解为实体锚定（EG）和关系保持（RP）。

Result: 在结构化控制文档上，HalluGraph实现了近乎完美的区分能力（AUC = 0.979），同时在具有挑战性的生成性法律任务上保持稳健性能（AUC ≈ 0.89），始终优于语义相似度基线。

Conclusion: 该框架为高风险法律应用提供了所需的透明度和可追溯性，实现了从生成的主张回溯到源段落的完整审计跟踪。

Abstract: Legal AI systems powered by retrieval-augmented generation (RAG) face a critical accountability challenge: when an AI assistant cites case law, statutes, or contractual clauses, practitioners need verifiable guarantees that generated text faithfully represents source documents. Existing hallucination detectors rely on semantic similarity metrics that tolerate entity substitutions, a dangerous failure mode when confusing parties, dates, or legal provisions can have material consequences. We introduce HalluGraph, a graph-theoretic framework that quantifies hallucinations through structural alignment between knowledge graphs extracted from context, query, and response. Our approach produces bounded, interpretable metrics decomposed into \textit{Entity Grounding} (EG), measuring whether entities in the response appear in source documents, and \textit{Relation Preservation} (RP), verifying that asserted relationships are supported by context. On structured control documents, HalluGraph achieves near-perfect discrimination ($>$400 words, $>$20 entities), HalluGraph achieves $AUC = 0.979$, while maintaining robust performance ($AUC \approx 0.89$) on challenging generative legal task, consistently outperforming semantic similarity baselines. The framework provides the transparency and traceability required for high-stakes legal applications, enabling full audit trails from generated assertions back to source passages.

</details>


### [89] [ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models](https://arxiv.org/abs/2512.01672)
*Zhongyuan Wu,Jingyuan Wang,Zexuan Cheng,Yilong Zhou,Weizhi Wang,Juhua Pu,Chao Li,Changqing Ma*

Main category: cs.LG

TL;DR: 提出了ICAD-LLM框架，利用大语言模型的上下文学习能力实现跨模态异常检测，无需针对特定任务进行训练即可适应新场景。


<details>
  <summary>Details</summary>
Motivation: 现代系统在快速演变的环境中产生多种互连的数据模态（如时间序列、系统日志、表格记录），现有异常检测方法通常专注于单一模态，缺乏处理异构数据和跨域泛化的能力。

Method: 提出上下文异常检测（ICAD）新范式，将异常定义为与正常样本参考集的差异度。在此基础上开发ICAD-LLM框架，利用大语言模型的上下文学习能力，在单一模型中处理异构数据。

Result: 实验表明ICAD-LLM在性能上与特定任务的异常检测方法相当，同时展现出对未见任务的强大泛化能力，显著降低部署成本并实现快速环境适应。

Conclusion: ICAD-LLM是首个能够跨不同领域和模态处理异常检测任务的模型，为异构数据环境下的异常检测提供了统一框架。

Abstract: Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.

</details>


### [90] [Weight Space Representation Learning with Neural Fields](https://arxiv.org/abs/2512.01759)
*Zhuoqian Yang,Mathieu Salzmann,Sabine Süsstrunk*

Main category: cs.LG

TL;DR: 该研究探索了权重作为有效表征的潜力，通过预训练基础模型和低秩适应（LoRA）约束优化空间，在权重空间中诱导出结构，在2D和3D数据的重建、生成和分析任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 探索权重作为有效表征的潜力，特别是在神经场中，研究如何通过约束优化空间来在权重空间中诱导出有意义的语义结构。

Method: 使用预训练的基础模型和低秩适应（LoRA）来约束优化空间，重点研究乘法LoRA权重，在2D和3D数据上进行重建、生成和分析任务的实验验证。

Result: 乘法LoRA权重在表示质量方面表现出色，具有区分性和语义结构，与潜在扩散模型结合使用时，比现有的权重空间方法能实现更高质量的生成。

Conclusion: 权重可以作为有效的表征，通过适当的约束（如预训练模型和LoRA）可以在权重空间中诱导出有意义的语义结构，为权重空间表示方法提供了新的可能性。

Abstract: In this work, we investigate the potential of weights to serve as effective representations, focusing on neural fields. Our key insight is that constraining the optimization space through a pre-trained base model and low-rank adaptation (LoRA) can induce structure in weight space. Across reconstruction, generation, and analysis tasks on 2D and 3D data, we find that multiplicative LoRA weights achieve high representation quality while exhibiting distinctiveness and semantic structure. When used with latent diffusion models, multiplicative LoRA weights enable higher-quality generation than existing weight-space methods.

</details>


### [91] [Dual Randomized Smoothing: Beyond Global Noise Variance](https://arxiv.org/abs/2512.01782)
*Chenhao Sun,Yuhao Mao,Martin Vechev*

Main category: cs.LG

TL;DR: 提出双随机平滑框架，通过输入依赖的噪声方差打破传统随机平滑中全局噪声方差的局限性，实现小半径和大半径下的强鲁棒性认证


<details>
  <summary>Details</summary>
Motivation: 传统随机平滑方法使用全局噪声方差存在根本限制：小半径需要小方差，大半径需要大方差，无法同时获得小半径和大半径下的强性能

Method: 提出双随机平滑框架：1) 证明输入依赖噪声方差在局部恒定条件下仍有效；2) 设计方差估计器预测每个输入的最优噪声方差；3) 使用标准RS分类器；4) 方差估计器通过RS独立平滑确保局部恒定性；5) 引入迭代优化训练策略

Result: 在CIFAR-10上，双RS方法在小半径和大半径下均表现优异，计算开销仅增加60%；相比先前输入依赖噪声方法，在半径0.5、0.75、1.0处分别相对提升19%、24%、21%；在ImageNet上同样有效；提供路由视角改进精度-鲁棒性权衡

Conclusion: 双随机平滑框架通过输入依赖噪声方差打破了传统全局噪声方差的限制，实现了小半径和大半径下的强鲁棒性认证，为认证鲁棒性提供了新的路由视角

Abstract: Randomized Smoothing (RS) is a prominent technique for certifying the robustness of neural networks against adversarial perturbations. With RS, achieving high accuracy at small radii requires a small noise variance, while achieving high accuracy at large radii requires a large noise variance. However, the global noise variance used in the standard RS formulation leads to a fundamental limitation: there exists no global noise variance that simultaneously achieves strong performance at both small and large radii. To break through the global variance limitation, we propose a dual RS framework which enables input-dependent noise variances. To achieve that, we first prove that RS remains valid with input-dependent noise variances, provided the variance is locally constant around each input. Building on this result, we introduce two components which form our dual RS framework: (i) a variance estimator first predicts an optimal noise variance for each input, (ii) this estimated variance is then used by a standard RS classifier. The variance estimator is independently smoothed via RS to ensure local constancy, enabling flexible design. We also introduce training strategies to iteratively optimize the two components. Extensive experiments on CIFAR-10 show that our dual RS method provides strong performance for both small and large radii-unattainable with global noise variance-while incurring only a 60% computational overhead at inference. Moreover, it consistently outperforms prior input-dependent noise approaches across most radii, with particularly large gains at radii 0.5, 0.75, and 1.0, achieving relative improvements of 19%, 24%, and 21%, respectively. On ImageNet, dual RS remains effective across all radii. Additionally, the dual RS framework naturally provides a routing perspective for certified robustness, improving the accuracy-robustness trade-off with off-the-shelf expert RS models.

</details>


### [92] [Deconstructing Generative Diversity: An Information Bottleneck Analysis of Discrete Latent Generative Models](https://arxiv.org/abs/2512.01831)
*Yudi Wu,Wenhao Zhao,Dianbo Liu*

Main category: cs.LG

TL;DR: 提出基于信息瓶颈理论的诊断框架，分析离散潜在生成模型（AR、MIM、Diffusion）的生成多样性差异，将多样性分解为路径多样性和执行多样性，并通过推理时干预揭示三种模型的策略差异。


<details>
  <summary>Details</summary>
Motivation: 不同离散潜在生成模型（如AR、MIM、Diffusion）的生成多样性存在显著差异，需要理论框架来解释这些行为差异背后的策略机制。

Method: 基于信息瓶颈理论建立诊断框架，将生成过程建模为压缩压力（最小化码本熵）和多样性压力（最大化条件熵）的冲突。将多样性分解为路径多样性（高层策略选择）和执行多样性（策略执行随机性）。引入三种零样本推理时干预技术来扰动潜在生成过程。

Result: 应用该框架分析代表性AR、MIM和Diffusion系统，揭示了三种不同策略：MIM为"多样性优先"，AR为"压缩优先"，Diffusion为"解耦"策略。分析为行为差异提供了原则性解释，并启发了新的推理时多样性增强技术。

Conclusion: 提出的基于信息瓶颈的诊断框架能够系统分析离散潜在生成模型的多样性行为，揭示了不同模型在压缩与多样性权衡中的策略差异，为理解和改进生成多样性提供了理论基础。

Abstract: Generative diversity varies significantly across discrete latent generative models such as AR, MIM, and Diffusion. We propose a diagnostic framework, grounded in Information Bottleneck (IB) theory, to analyze the underlying strategies resolving this behavior. The framework models generation as a conflict between a 'Compression Pressure' - a drive to minimize overall codebook entropy - and a 'Diversity Pressure' - a drive to maximize conditional entropy given an input. We further decompose this diversity into two primary sources: 'Path Diversity', representing the choice of high-level generative strategies, and 'Execution Diversity', the randomness in executing a chosen strategy. To make this decomposition operational, we introduce three zero-shot, inference-time interventions that directly perturb the latent generative process and reveal how models allocate and express diversity. Application of this probe-based framework to representative AR, MIM, and Diffusion systems reveals three distinct strategies: "Diversity-Prioritized" (MIM), "Compression-Prioritized" (AR), and "Decoupled" (Diffusion). Our analysis provides a principled explanation for their behavioral differences and informs a novel inference-time diversity enhancement technique.

</details>


### [93] [On Global Applicability and Location Transferability of Generative Deep Learning Models for Precipitation Downscaling](https://arxiv.org/abs/2512.01400)
*Paula Harder,Christian Lessig,Matthew Chantry,Francis Pelletier,David Rolnick*

Main category: cs.LG

TL;DR: 评估生成式降尺度模型在全球不同地区的泛化能力，使用ERA5再分析数据和IMERG降水数据，通过分层位置划分在15个区域进行系统性评估


<details>
  <summary>Details</summary>
Motivation: 现有深度学习降尺度模型大多是区域特定的，其泛化到未见地理区域的能力尚未得到充分探索，需要评估生成式降尺度模型在不同地区的泛化性能

Method: 使用全球框架，以ERA5再分析数据作为预测因子，IMERG降水估计（0.1°分辨率）作为目标，采用分层位置数据划分方法，在15个全球区域进行系统性评估

Result: 研究评估了生成式降尺度模型在15个全球不同区域的性能表现，但摘要中未提供具体评估结果

Conclusion: 该研究系统评估了生成式降尺度模型在全球范围内的泛化能力，为理解模型在不同地理区域的适应性提供了重要参考

Abstract: Deep learning offers promising capabilities for the statistical downscaling of climate and weather forecasts, with generative approaches showing particular success in capturing fine-scale precipitation patterns. However, most existing models are region-specific, and their ability to generalize to unseen geographic areas remains largely unexplored. In this study, we evaluate the generalization performance of generative downscaling models across diverse regions. Using a global framework, we employ ERA5 reanalysis data as predictors and IMERG precipitation estimates at $0.1^\circ$ resolution as targets. A hierarchical location-based data split enables a systematic assessment of model performance across 15 regions around the world.

</details>


### [94] [Fantastic Features and Where to Find Them: A Probing Method to combine Features from Multiple Foundation Models](https://arxiv.org/abs/2512.01405)
*Benjamin Ramtoula,Pierre-Yves Lajoie,Paul Newman,Daniele De Martini*

Main category: cs.LG

TL;DR: ComBo是一种基于探测的适配器，通过压缩多个基础模型的激活特征，使用轻量级Transformer进行任务预测，无需数据集特定调优或反向传播，有效整合不同模型的互补优势。


<details>
  <summary>Details</summary>
Motivation: 不同基础模型学习到不同的表征，但现有适配策略只关注单个模型，无法利用模型间的互补优势。现有探测方法在大规模特征集上扩展性差且需要数据集特定的超参数调优。

Method: 提出ComBo方法：1) 压缩多个基础模型各层的激活为紧凑的token-wise表示；2) 使用轻量级Transformer进行任务特定预测；3) 引入机制评估每个基础模型的任务相关性，支持选择性适配。

Result: 在VTAB-1k基准的19个任务上，ComBo优于先前探测方法，匹配或超越更昂贵的替代方案（如基于蒸馏的模型融合），并能高效探测调优后的模型。

Conclusion: ComBo提供了一个实用且通用的框架，能够有效整合多个基础模型的多样化表征，实现高效的多模型特征融合。

Abstract: Foundation models (FMs) trained with different objectives and data learn diverse representations, making some more effective than others for specific downstream tasks. Existing adaptation strategies, such as parameter-efficient fine-tuning, focus on individual models and do not exploit the complementary strengths across models. Probing methods offer a promising alternative by extracting information from frozen models, but current techniques do not scale well with large feature sets and often rely on dataset-specific hyperparameter tuning. We propose Combined backBones (ComBo), a simple and scalable probing-based adapter that effectively integrates features from multiple models and layers. ComBo compresses activations from layers of one or more FMs into compact token-wise representations and processes them with a lightweight transformer for task-specific prediction. Crucially, ComBo does not require dataset-specific tuning or backpropagation through the backbone models. However, not all models are equally relevant for all tasks. To address this, we introduce a mechanism that leverages ComBo's joint multi-backbone probing to efficiently evaluate each backbone's task-relevance, enabling both practical model comparison and improved performance through selective adaptation. On the 19 tasks of the VTAB-1k benchmark, ComBo outperforms previous probing methods, matches or surpasses more expensive alternatives, such as distillation-based model merging, and enables efficient probing of tuned models. Our results demonstrate that ComBo offers a practical and general-purpose framework for combining diverse representations from multiple FMs.

</details>


### [95] [Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion](https://arxiv.org/abs/2512.01881)
*Ahmed Nebli*

Main category: cs.LG

TL;DR: ThermoLion：一种基于局部信噪比门控的动态优化框架，能在低比特探索和高精度利用之间自适应切换，无需超参数调优即可超越AdamW和Lion在视觉任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前深度视觉模型训练存在信息通道容量的静态折中问题：基于梯度幅值的方法（如AdamW）在平滑区域精度高但在崎岖非凸地形会放大噪声；基于梯度符号的方法（如Lion）进行1比特量化虽然鲁棒但丢弃了精细下降信息。需要一种动态调节更新比特率的优化方法。

Method: 提出ThermoLion框架：1）利用局部信噪比门控自主切换参数在"低比特"探索和"高精度"利用阶段；2）引入动量对齐机制，检测历史漂移与瞬时梯度之间的建设性干扰以加速稳定轨迹的收敛。

Result: 在12个多样化视觉数据集（包括CIFAR、SVHN、GTSRB）上的实证基准测试表明，ThermoLion作为无需超参数调优的通用优化器，在收敛速度和最终精度上都超越了AdamW和Lion。

Conclusion: 最优收敛不需要静态先验，而是需要动态调节更新比特率。ThermoLion通过局部信噪比门控和动量对齐机制实现了这一目标，为视觉模型训练提供了更有效的优化框架。

Abstract: The training of deep vision models is fundamentally a signal recovery problem amidst high-dimensional stochastic noise. Current optimization paradigms impose a static compromise on information channel capacity. For instance, magnitude-based methods, such as AdamW, operate on the assumption that gradient norms are high-fidelity curvature signals. While this allows for precision in smooth regimes, it leads to catastrophic noise amplification when applied to rugged, non-convex landscapes. Conversely, sign-based methods (e.g., Lion) perform a radical 1-bit quantization of the gradient, which aims to provide robust regularization at the cost of discarding fine-grained descent information. We propose that optimal convergence requires neither static prior, but rather a dynamic modulation of the update bitrate. We introduce \textbf{ThermoLion}, a vision-centric framework that utilizes local Signal-to-Noise Ratio (SNR) gating to autonomously transition parameters between a "low-bit" exploration phase and a "high-precision" exploitation phase. Furthermore, we introduce a Momentum Alignment mechanism that detects constructive interference between historical drift and instantaneous gradients to accelerate convergence during stable trajectories. Empirical benchmarks across 12 diverse vision datasets (including CIFAR, SVHN, and GTSRB) demonstrate that ThermoLion serves as a hyperparameter-free generalist, surpassing both AdamW and Lion in convergence speed and terminal accuracy without architecture-specific tuning.

</details>


### [96] [Fourier Neural Operators Explained: A Practical Perspective](https://arxiv.org/abs/2512.01421)
*Valentin Duruisseaux,Jean Kossaifi,Anima Anandkumar*

Main category: cs.LG

TL;DR: 该论文提供Fourier神经算子(FNO)的实践指南，统一数学原理与实现策略，帮助从业者正确应用这一PDE求解工具


<details>
  <summary>Details</summary>
Motivation: 虽然FNO已成为学习PDE系统映射的强大框架，但从业者对其理论基础、实践约束和实现细节理解不足，导致不正确或不可靠的应用，需要建立清晰可靠的应用框架

Method: 提供FNO的综合性实践导向指南，包括算子理论和信号处理概念的直观阐述、谱参数化细节、所有组件的计算设计，并与NeuralOperator 2.0.0库紧密集成，提供模块化实现

Result: 建立了连接严格理论基础与实践洞察的框架，通过清晰的数学原理阐述和模块化实现，帮助从业者有效应用FNO于各种科学和工程领域

Conclusion: 该指南通过统一数学原理与实现策略，为FNO在不同科学和工程领域的有效应用建立了清晰可靠的理论与实践框架

Abstract: Partial differential equations (PDEs) govern a wide variety of dynamical processes in science and engineering, yet obtaining their numerical solutions often requires high-resolution discretizations and repeated evaluations of complex operators, leading to substantial computational costs. Neural operators have recently emerged as a powerful framework for learning mappings between function spaces directly from data, enabling efficient surrogate models for PDE systems. Among these architectures, the Fourier Neural Operator (FNO) has become the most influential and widely adopted due to its elegant spectral formulation, which captures global correlations through learnable transformations in Fourier space while remaining invariant to discretization and resolution. Despite their success, the practical use of FNOs is often hindered by an incomplete understanding among practitioners of their theoretical foundations, practical constraints, and implementation details, which can lead to their incorrect or unreliable application. This work presents a comprehensive and practice-oriented guide to FNOs, unifying their mathematical principles with implementation strategies. We provide an intuitive exposition to the concepts of operator theory and signal-processing that underlie the FNO, detail its spectral parameterization and the computational design of all its components, and address common misunderstandings encountered in the literature. The exposition is closely integrated with the NeuralOperator 2.0.0 library, offering modular state-of-the-art implementations that faithfully reflect the theory. By connecting rigorous foundations with practical insight, this guide aims to establish a clear and reliable framework for applying FNOs effectively across diverse scientific and engineering fields.

</details>


### [97] [Forecasting in Offline Reinforcement Learning for Non-stationary Environments](https://arxiv.org/abs/2512.01987)
*Suzan Ece Ada,Georg Martius,Emre Ugur,Erhan Oztop*

Main category: cs.LG

TL;DR: FORL框架结合条件扩散模型和零样本时间序列基础模型，解决离线强化学习中非平稳环境下的状态偏移问题，提升智能体在真实世界非平稳场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习方法通常假设环境平稳或仅考虑测试时的合成扰动，而真实世界场景常存在突发、时变的偏移，导致部分可观测性，使智能体误判真实状态并降低性能。

Method: 提出FORL框架，统一两个组件：(1) 条件扩散基候选状态生成，无需预设未来非平稳模式；(2) 零样本时间序列基础模型。针对易发生意外、可能非马尔可夫偏移的环境，要求智能体从每轮开始就具备鲁棒性能。

Result: 在离线强化学习基准测试中，使用真实世界时间序列数据模拟现实非平稳性，FORL相比竞争基线方法持续提升性能表现。

Conclusion: 通过整合零样本预测与智能体经验，FORL旨在弥合离线强化学习与现实世界非平稳环境复杂性之间的差距。

Abstract: Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.

</details>


### [98] [Stay Unique, Stay Efficient: Preserving Model Personality in Multi-Task Merging](https://arxiv.org/abs/2512.01461)
*Kuangpu Guo,Yuhe Ding,Jian Liang,Zilei Wang,Ran He*

Main category: cs.LG

TL;DR: DTS是一种基于近似的个性化模型合并框架，通过奇异值分解、阈值化和缩放策略来保留任务特定信息，仅需1%额外存储开销，在未见任务上也能良好泛化。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法在类似任务上相比单独微调模型仍存在显著性能下降，需要保留任务特定信息但又要最小化存储开销。

Method: DTS框架：1) 对任务特定信息进行奇异值分解，仅保留少量奇异值和向量；2) 引入新颖的阈值化策略，将奇异向量元素分组并为每组分配缩放因子；3) 扩展变体基于任务特征的语义相似性以数据无关方式融合任务特定信息。

Result: DTS在广泛实验中始终优于最先进的基线方法，每个任务仅需1%额外存储。在未见任务上，DTS变体实现了显著更好的泛化性能。

Conclusion: DTS是一个有效的个性化模型合并框架，能够在最小存储开销下保留任务特定信息，并在未见任务上具有良好的泛化能力。

Abstract: Model merging has emerged as a promising paradigm for enabling multi-task capabilities without additional training. However, existing methods often experience substantial performance degradation compared with individually fine-tuned models, even on similar tasks, underscoring the need to preserve task-specific information. This paper proposes Decomposition, Thresholding, and Scaling (DTS), an approximation-based personalized merging framework that preserves task-specific information with minimal storage overhead. DTS first applies singular value decomposition to the task-specific information and retains only a small subset of singular values and vectors. It then introduces a novel thresholding strategy that partitions singular vector elements into groups and assigns a scaling factor to each group. To enable generalization to unseen tasks, we further extend DTS with a variant that fuses task-specific information in a data-free manner based on the semantic similarity of task characteristics. Extensive experiments demonstrate that DTS consistently outperforms state-of-the-art baselines while requiring only 1\% additional storage per task. Furthermore, experiments on unseen tasks show that the DTS variant achieves significantly better generalization performance. Our code is available at https://github.com/krumpguo/DTS.

</details>


### [99] [A Diffusion Model Framework for Maximum Entropy Reinforcement Learning](https://arxiv.org/abs/2512.02019)
*Sebastian Sanokowski,Kaustubh Patil,Alois Knoll*

Main category: cs.LG

TL;DR: 将最大熵强化学习重新解释为基于扩散模型的采样问题，通过最小化扩散策略与最优策略分布之间的反向KL散度，推导出包含扩散动力学的改进目标函数，提出了DiffSAC、DiffPPO和DiffWPO等扩散变体算法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在数据驱动学习和复杂非归一化目标分布采样方面取得了显著成功，研究者希望将这种成功应用于强化学习领域，特别是最大熵强化学习问题。

Method: 将最大熵强化学习重新解释为扩散模型采样问题，通过最小化扩散策略与最优策略分布之间的反向KL散度，使用可处理的上界，并应用策略梯度定理推导出包含扩散动力学的改进目标函数。

Result: 提出了DiffSAC、DiffPPO和DiffWPO等扩散变体算法，这些方法只需对基础算法进行微小改动。在标准连续控制基准测试中，这些方法比SAC和PPO获得了更好的回报和更高的样本效率。

Conclusion: 通过将扩散模型框架应用于最大熵强化学习，成功开发了性能更优的强化学习算法，证明了扩散模型与强化学习结合的潜力。

Abstract: Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to this objective, we derive a modified surrogate objective for MaxEntRL that incorporates diffusion dynamics in a principled way. This leads to simple diffusion-based variants of Soft Actor-Critic (SAC), Proximal Policy Optimization (PPO) and Wasserstein Policy Optimization (WPO), termed DiffSAC, DiffPPO and DiffWPO. All of these methods require only minor implementation changes to their base algorithm. We find that on standard continuous control benchmarks, DiffSAC, DiffPPO and DiffWPO achieve better returns and higher sample efficiency than SAC and PPO.

</details>


### [100] [End-to-end Deep Reinforcement Learning for Stochastic Multi-objective Optimization in C-VRPTW](https://arxiv.org/abs/2512.01518)
*Abdo Abouelrous,Laurens Bliek,Yaoxin Wu,Yingqian Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于深度学习的方法，用于解决具有随机旅行时间和多目标（总旅行时间和路线最大完工时间）的车辆路径问题变体，通过场景聚类训练机制构建高质量的帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 实际车辆路径问题中存在不确定性（如旅行时间波动）和多目标冲突（如运营效率与劳动法规），现有基于注意力的端到端深度学习模型难以直接处理旅行时间矩阵的高维输入，特别是在多目标情况下。

Method: 提出一个同时处理随机性和多目标性的深度学习模型，采用注意力机制和多解轨迹，通过场景聚类训练机制减少训练时间。

Result: 与三个基线方法相比，该模型能够在可接受的运行时间内构建出高质量的帕累托前沿。

Conclusion: 该研究成功开发了一种能够同时处理随机旅行时间和多目标优化的深度学习模型，通过创新的训练机制提高了效率，为实际车辆路径规划问题提供了有效的解决方案。

Abstract: In this work, we consider learning-based applications in routing to solve a Vehicle Routing variant characterized by stochasticity and multiple objectives. Such problems are representative of practical settings where decision-makers have to deal with uncertainty in the operational environment as well as multiple conflicting objectives due to different stakeholders. We specifically consider travel time uncertainty. We also consider two objectives, total travel time and route makespan, that jointly target operational efficiency and labor regulations on shift length, although different objectives could be incorporated. Learning-based methods offer earnest computational advantages as they can repeatedly solve problems with limited interference from the decision-maker. We specifically focus on end-to-end deep learning models that leverage the attention mechanism and multiple solution trajectories. These models have seen several successful applications in routing problems. However, since travel times are not a direct input to these models due to the large dimensions of the travel time matrix, accounting for uncertainty is a challenge, especially in the presence of multiple objectives. In turn, we propose a model that simultaneously addresses stochasticity and multi-objectivity and provide a refined training mechanism for this model through scenario clustering to reduce training time. Our results show that our model is capable of constructing a Pareto Front of good quality within acceptable run times compared to three baselines.

</details>


### [101] [TimePred: efficient and interpretable offline change point detection for high volume data - with application to industrial process monitoring](https://arxiv.org/abs/2512.01562)
*Simon Leszek*

Main category: cs.LG

TL;DR: TimePred是一个自监督框架，将高维时间序列的变点检测简化为单变量均值漂移检测，通过预测样本的归一化时间索引来实现，显著降低计算成本并提高可解释性。


<details>
  <summary>Details</summary>
Motivation: 高维大容量时间序列的变点检测面临统计一致性、可扩展性和可解释性三大挑战。现有方法在处理这些问题时存在局限性，需要一种既能保持性能又能降低计算复杂度的方法。

Method: 提出TimePred自监督框架，通过预测每个样本的归一化时间索引，将多元变点检测问题转化为单变量均值漂移检测问题。该方法支持离线检测，并能集成XAI归因方法进行特征级解释。

Result: 实验表明TimePred在变点检测性能上具有竞争力，同时将计算成本降低了两个数量级。在工业制造案例研究中，展示了改进的检测精度和可解释变点洞察的实际价值。

Conclusion: TimePred框架有效解决了高维时间序列变点检测的挑战，通过将多元问题简化为单变量问题，实现了高效、可扩展且可解释的检测，在降低计算成本的同时保持了检测性能。

Abstract: Change-point detection (CPD) in high-dimensional, large-volume time series is challenging for statistical consistency, scalability, and interpretability. We introduce TimePred, a self-supervised framework that reduces multivariate CPD to univariate mean-shift detection by predicting each sample's normalized time index. This enables efficient offline CPD using existing algorithms and supports the integration of XAI attribution methods for feature-level explanations. Our experiments show competitive CPD performance while reducing computational cost by up to two orders of magnitude. In an industrial manufacturing case study, we demonstrate improved detection accuracy and illustrate the practical value of interpretable change-point insights.

</details>


### [102] [Do Large Language Models Walk Their Talk? Measuring the Gap Between Implicit Associations, Self-Report, and Behavioral Altruism](https://arxiv.org/abs/2512.01568)
*Sandro Andric*

Main category: cs.LG

TL;DR: 研究探索大型语言模型是否表现出利他倾向，以及其内隐联想和自我报告是否能预测实际利他行为。发现模型存在"美德信号差距"：虽然都表现出强烈的内隐利他偏见，但实际行为与自我评估存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究大型语言模型是否具有利他倾向，以及模型的内隐联想和自我报告是否能准确预测其实际行为。这有助于理解AI系统的道德对齐和行为一致性。

Method: 采用人类社会心理学的多方法研究范式，测试了24个前沿LLM：1) 内隐联想测试测量内隐利他偏见；2) 强制二元选择任务测量行为利他；3) 自我评估量表测量显性利他信念。

Result: 主要发现：1) 所有模型都表现出强烈的内隐利他偏见；2) 模型行为利他性高于随机水平但存在显著变异；3) 内隐联想不能预测行为；4) 模型系统性高估自身利他性，存在"美德信号差距"。

Conclusion: 建议将"校准差距"作为标准化对齐指标。只有12.5%的模型实现了高亲社会行为和准确自我认知的理想组合。校准良好的模型更具可预测性和行为一致性。

Abstract: We investigate whether Large Language Models (LLMs) exhibit altruistic tendencies, and critically, whether their implicit associations and self-reports predict actual altruistic behavior. Using a multi-method approach inspired by human social psychology, we tested 24 frontier LLMs across three paradigms: (1) an Implicit Association Test (IAT) measuring implicit altruism bias, (2) a forced binary choice task measuring behavioral altruism, and (3) a self-assessment scale measuring explicit altruism beliefs. Our key findings are: (1) All models show strong implicit pro-altruism bias (mean IAT = 0.87, p < .0001), confirming models "know" altruism is good. (2) Models behave more altruistically than chance (65.6% vs. 50%, p < .0001), but with substantial variation (48-85%). (3) Implicit associations do not predict behavior (r = .22, p = .29). (4) Most critically, models systematically overestimate their own altruism, claiming 77.5% altruism while acting at 65.6% (p < .0001, Cohen's d = 1.08). This "virtue signaling gap" affects 75% of models tested. Based on these findings, we recommend the Calibration Gap (the discrepancy between self-reported and behavioral values) as a standardized alignment metric. Well-calibrated models are more predictable and behaviorally consistent; only 12.5% of models achieve the ideal combination of high prosocial behavior and accurate self-knowledge.

</details>


### [103] [A unified framework for geometry-independent operator learning in cardiac electrophysiology simulations](https://arxiv.org/abs/2512.01702)
*Bei Zhou,Cesare Corrado,Shuang Qian,Maximilian Balmus,Angela W. C. Lee,Cristobal Rodero,Marco J. W. Gotte,Luuk H. G. A. Hopman,Mengyun Qiao,Steven Niederer*

Main category: cs.LG

TL;DR: 提出了一种几何无关的算子学习框架，能够跨不同左心房解剖结构快速预测局部激活时间场，实现近实时推理，误差仅5.1ms。


<details>
  <summary>Details</summary>
Motivation: 当前生物物理详细模拟计算量大，难以用于实时临床或大规模分析，需要开发快速准确的预测方法。

Method: 使用通用心房坐标系统一表示解剖和功能数据，构建包含308,700个模拟的数据集，采用基于视觉变换器的神经算子学习从结构电生理输入到LAT场的映射。

Result: 模型平均预测误差5.1ms（最大模拟时间455ms），推理速度0.12ms/样本，优于现有算子学习方法。

Conclusion: 该框架建立了跨可变解剖域学习域不变生物物理映射的通用策略，使计算电生理学能够集成到实时和大规模临床工作流中。

Abstract: Accurate maps of atrial electrical activation are essential for personalised treatment of arrhythmias, yet biophysically detailed simulations remain computationally intensive for real-time clinical use or population-scale analyses. Here we introduce a geometry-independent operator-learning framework that predicts local activation time (LAT) fields across diverse left atrial anatomies with near-instantaneous inference. We generated a dataset of 308,700 simulations using a GPU-accelerated electrophysiology solver, systematically varying multiple pacing sites and physiologically varied conduction properties across 147 patient-specific geometries derived from two independent clinical cohorts. All anatomical and functional data are expressed in a Universal Atrium Coordinate system, providing a consistent representation that decouples electrophysiological patterns from mesh topology. Within this coordinate space, we designed a neural operator with a vision-transformer backbone to learn the mapping from structural and electrophysiological inputs to LAT fields. With a mean prediction error of 5.1 ms over a 455 ms maximum simulation time, the model outperforms established operator-learning approaches and performs inference in 0.12 ms per sample. Our framework establishes a general strategy for learning domain-invariant biophysical mappings across variable anatomical domains and enables integration of computational electrophysiology into real-time and large-scale clinical workflows.

</details>


### [104] [Beyond Scaffold: A Unified Spatio-Temporal Gradient Tracking Method](https://arxiv.org/abs/2512.01732)
*Yan Huang,Jinming Xu,Jiming Chen,Karl Henrik Johansson*

Main category: cs.LG

TL;DR: 提出ST-GT算法，通过时空梯度跟踪解决分布式学习中因数据异质性和本地噪声导致的模型漂移问题，在时变图上实现通信效率提升。


<details>
  <summary>Details</summary>
Motivation: 分布式和联邦学习中，为减少通信开销通常会在通信轮次间执行多次本地更新，但由于节点间数据异质性和本地梯度噪声，这种策略会导致本地模型偏离全局最优解。

Method: 从梯度跟踪角度重新审视Scaffold方法，提出统一的时空梯度跟踪算法ST-GT。该算法通过相邻节点间的全局梯度跟踪来缓解数据异质性，同时维护本地梯度的运行平均来显著抑制噪声，仅需略微增加存储开销。

Result: 无需假设数据异质性有界，证明了ST-GT在强凸问题上达到线性收敛速率，在非凸情况下达到次线性收敛速率。特别地，ST-GT在强凸设置下首次实现了关于每轮本地更新次数τ的线性加速通信复杂度。相比传统梯度跟踪方法，ST-GT将拓扑依赖的噪声项从σ²降低到σ²/τ。

Conclusion: ST-GT算法通过时空梯度跟踪有效解决了分布式学习中数据异质性和噪声导致的模型漂移问题，显著提升了通信效率，在时变图上实现了更好的性能表现。

Abstract: In distributed and federated learning algorithms, communication overhead is often reduced by performing multiple local updates between communication rounds. However, due to data heterogeneity across nodes and the local gradient noise within each node, this strategy can lead to the drift of local models away from the global optimum. To address this issue, we revisit the well-known federated learning method Scaffold (Karimireddy et al., 2020) under a gradient tracking perspective, and propose a unified spatio-temporal gradient tracking algorithm, termed ST-GT, for distributed stochastic optimization over time-varying graphs. ST-GT tracks the global gradient across neighboring nodes to mitigate data heterogeneity, while maintaining a running average of local gradients to substantially suppress noise, with slightly more storage overhead. Without assuming bounded data heterogeneity, we prove that ST-GT attains a linear convergence rate for strongly convex problems and a sublinear rate for nonconvex cases. Notably, ST-GT achieves the first linear speed-up in communication complexity with respect to the number of local updates per round $τ$ for the strongly-convex setting. Compared to traditional gradient tracking methods, ST-GT reduces the topology-dependent noise term from $σ^2$ to $σ^2/τ$, where $σ^2$ denotes the noise level, thereby improving communication efficiency.

</details>


### [105] [MSPT: Efficient Large-Scale Physical Modeling via Parallelized Multi-Scale Attention](https://arxiv.org/abs/2512.01738)
*Pedro M. P. Curvo,Jan-Willem van de Meent,Maksim Zhdanov*

Main category: cs.LG

TL;DR: MSPT是一种多尺度补丁Transformer架构，通过结合局部点注意力和全局补丁级注意力，解决了工业规模物理模拟中同时捕捉细粒度局部交互和长程全局依赖的扩展性挑战。


<details>
  <summary>Details</summary>
Motivation: 工业规模物理模拟中的关键扩展性挑战是同时高效捕捉数百万空间元素间的细粒度局部交互和长程全局依赖关系。

Method: 引入多尺度补丁Transformer（MSPT）架构，结合补丁内的局部点注意力和对粗粒度补丁级表示的全局注意力。使用球树将输入域划分为空间连贯的补丁以处理不规则几何形状。

Result: 在标准PDE基准测试（弹性、塑性、流体动力学、多孔流动）和大规模空气动力学数据集（ShapeNet-Car、Ahmed-ML）上验证，实现了最先进的精度，同时显著降低了内存占用和计算成本，可在单个GPU上扩展到数百万个点。

Conclusion: MSPT通过双尺度设计有效解决了工业规模物理模拟的扩展性挑战，在保持高精度的同时大幅降低了计算资源需求。

Abstract: A key scalability challenge in neural solvers for industrial-scale physics simulations is efficiently capturing both fine-grained local interactions and long-range global dependencies across millions of spatial elements. We introduce the Multi-Scale Patch Transformer (MSPT), an architecture that combines local point attention within patches with global attention to coarse patch-level representations. To partition the input domain into spatially-coherent patches, we employ ball trees, which handle irregular geometries efficiently. This dual-scale design enables MSPT to scale to millions of points on a single GPU. We validate our method on standard PDE benchmarks (elasticity, plasticity, fluid dynamics, porous flow) and large-scale aerodynamic datasets (ShapeNet-Car, Ahmed-ML), achieving state-of-the-art accuracy with substantially lower memory footprint and computational cost.

</details>


### [106] [SA-ADP: Sensitivity-Aware Adaptive Differential Privacy for Large Language Models](https://arxiv.org/abs/2512.01748)
*Stella Etuk,Ashraf Matrawy*

Main category: cs.LG

TL;DR: SA-ADP是一种基于敏感性的自适应差分隐私方法，通过根据个人身份信息（PII）的敏感度分配噪声，在保持隐私保护的同时不降低模型效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在记忆信息时存在隐私风险，传统差分隐私方法（如DP-SGD）通过均匀添加噪声保护PII，但会导致模型效用下降。需要一种能根据PII敏感度自适应分配噪声的方法来解决隐私保护与模型效用之间的权衡问题。

Method: 提出SA-ADP（敏感性感知自适应差分隐私）方法，该方法根据个体PII的敏感度分配噪声，而不是像传统DP-SGD那样均匀添加噪声。在四个数据集（ABCD、CUSTOMERSIM、Wikitext-2和UNSW-NB15）上进行了评估。

Result: SA-ADP在保持强隐私保护的同时，实现了与基线（No-DP）和传统DP-SGD相当的结果，表明该方法没有降低模型效用。

Conclusion: SA-ADP方法通过基于PII敏感度分配噪声，成功解决了隐私保护与模型效用之间的权衡问题，在保持强隐私保护的同时不牺牲模型性能。

Abstract: Despite advances in the use of large language models (LLMs) in downstream tasks, their ability to memorize information has raised privacy concerns. Therefore, protecting personally identifiable information (PII) during LLM training remains a fundamental challenge. Conventional methods like Differential Privacy-Stochastic Gradient Descent (DP-SGD) provide robust privacy protection via uniform noising, protecting PII regardless of its distinct sensitivity. This comes at the expense of the model's utility, leading to a trade-off. In this paper, we propose SA-ADP, a sensitivity-aware approach that allocates noise based on the sensitivity of individual PII. We evaluated our method on four datasets (ABCD, CUSTOMERSIM, Wikitext-2, and UNSW-NB15 ). Our results show that SA-ADP achieves results comparable to the baseline (No-DP) and the conventional DP-SGD. This means that our method did not degrade the model's utility while still maintaining strong privacy protection.

</details>


### [107] [On the Unreasonable Effectiveness of Last-layer Retraining](https://arxiv.org/abs/2512.01766)
*John C. Hill,Tyler LaBonte,Xinchen Zhang,Vidya Muthukumar*

Main category: cs.LG

TL;DR: LLR方法通过重新初始化并重训练最后一层来改善最差群体准确率，即使验证集不平衡。研究发现其有效性主要源于验证集更好的群体平衡，而非缓解神经崩溃。


<details>
  <summary>Details</summary>
Motivation: 探究LLR方法为何能在验证集不平衡的情况下仍能改善最差群体准确率，验证其"不合理有效性"的原因。

Method: 通过实证研究检验两个假设：1) LLR通过缓解神经崩溃来改善鲁棒性；2) LLR的成功主要源于验证集更好的群体平衡。

Result: 实证结果不支持神经崩溃假设，而是强烈支持群体平衡假设。CB-LLR和AFR算法通过隐式群体平衡实现鲁棒性提升。

Conclusion: LLR的有效性主要源于验证集更好的群体平衡，而非缓解神经崩溃。近期算法通过隐式群体平衡机制实现鲁棒性改进。

Abstract: Last-layer retraining (LLR) methods -- wherein the last layer of a neural network is reinitialized and retrained on a held-out set following ERM training -- have garnered interest as an efficient approach to rectify dependence on spurious correlations and improve performance on minority groups. Surprisingly, LLR has been found to improve worst-group accuracy even when the held-out set is an imbalanced subset of the training set. We initially hypothesize that this ``unreasonable effectiveness'' of LLR is explained by its ability to mitigate neural collapse through the held-out set, resulting in the implicit bias of gradient descent benefiting robustness. Our empirical investigation does not support this hypothesis. Instead, we present strong evidence for an alternative hypothesis: that the success of LLR is primarily due to better group balance in the held-out set. We conclude by showing how the recent algorithms CB-LLR and AFR perform implicit group-balancing to elicit a robustness improvement.

</details>


### [108] [How Does RL Post-training Induce Skill Composition? A Case Study on Countdown](https://arxiv.org/abs/2512.01775)
*Simon Park,Simran Kaur,Sanjeev Arora*

Main category: cs.LG

TL;DR: RL后训练在组合泛化中的作用研究：通过Countdown任务分析模型如何学习技能组合，发现模型能泛化到更大规模和未见过的树结构，但学习顺序存在结构依赖的层次性


<details>
  <summary>Details</summary>
Motivation: 研究强化学习后训练在促进组合泛化（从已知组件合成新技能的能力）方面的作用，澄清其与单纯长度泛化的区别，探索技能组合的结构如何影响技能迁移

Method: 使用Countdown任务（给定n个数字和目标值，构建表达式达到目标），将模型解决方案分析为表达式树，每个子树对应可重用的子任务（技能），追踪训练过程中树形状及其成功率

Result: 发现：1）模型能泛化到更大的n和未见过的树形状，表明子任务的组合重用；2）存在结构依赖的学习层次性——模型先掌握浅层平衡树，后掌握深层不平衡树，对右重结构存在持续脆弱性

Conclusion: 该诊断揭示了RL后训练学习的内容、顺序和泛化失败的地方，澄清了RL-only后训练如何诱导超出标准指标（如pass@k）的分布外泛化

Abstract: While reinforcement learning (RL) successfully enhances reasoning in large language models, its role in fostering compositional generalization (the ability to synthesize novel skills from known components) is often conflated with mere length generalization. To this end, we study what RL post-training teaches about skill composition and how the structure of the composition affects the skill transfer. We focus on the Countdown task (given n numbers and a target, form an expression that evaluates to the target) and analyze model solutions as expression trees, where each subtree corresponds to a reusable subtask and thus can be viewed as a ``skill.'' Tracking tree shapes and their success rates over training, we find: (i) out-of-distribution (OOD) generalization to larger n and to unseen tree shapes, indicating compositional reuse of subtasks; (ii) a structure-dependent hierarchy of learnability -- models master shallow balanced trees (workload is balanced between subtasks) before deep unbalanced ones, with persistent fragility on right-heavy structures (even when the composition depth is the same as some left-heavy structures). Our diagnostic reveals what is learned, in what order, and where generalization fails, clarifying how RL-only post-training induces OOD generalization beyond what standard metrics such as pass@k reveal.

</details>


### [109] [DeepCAVE: A Visualization and Analysis Tool for Automated Machine Learning](https://arxiv.org/abs/2512.01810)
*Sarah Segel,Helena Graf,Edward Bergman,Kristina Thieme,Marcel Wever,Alexander Tornede,Frank Hutter,Marius Lindauer*

Main category: cs.LG

TL;DR: DeepCAVE是一个用于超参数优化过程交互式可视化和分析的工具，帮助用户理解、调试和优化机器学习模型调优过程。


<details>
  <summary>Details</summary>
Motivation: 超参数优化作为AutoML的核心范式对机器学习模型性能至关重要，但其复杂性使得理解和调试优化过程变得困难。需要工具来提供对HPO过程的深入洞察。

Method: 开发了DeepCAVE工具，通过交互式仪表板让研究人员、数据科学家和机器学习工程师能够探索HPO过程的各个方面，识别问题、未开发的潜力以及关于被调优模型的新见解。

Result: DeepCAVE为用户提供了可操作的洞察，有助于在系统设计层面增强HPO和机器学习的可解释性，并促进未来开发更稳健、更高效的方法论。

Conclusion: DeepCAVE通过交互式可视化分析工具，解决了HPO过程理解和调试的挑战，为机器学习模型调优提供了有价值的洞察，有助于推动更先进的AutoML方法发展。

Abstract: Hyperparameter optimization (HPO), as a central paradigm of AutoML, is crucial for leveraging the full potential of machine learning (ML) models; yet its complexity poses challenges in understanding and debugging the optimization process. We present DeepCAVE, a tool for interactive visualization and analysis, providing insights into HPO. Through an interactive dashboard, researchers, data scientists, and ML engineers can explore various aspects of the HPO process and identify issues, untouched potentials, and new insights about the ML model being tuned. By empowering users with actionable insights, DeepCAVE contributes to the interpretability of HPO and ML on a design level and aims to foster the development of more robust and efficient methodologies in the future.

</details>


### [110] [The Mean-Field Dynamics of Transformers](https://arxiv.org/abs/2512.01868)
*Philippe Rigollet*

Main category: cs.LG

TL;DR: 论文将Transformer注意力机制建模为粒子系统，研究其连续极限，揭示了注意力机制中的全局聚类现象和相变行为。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer注意力机制的动力学特性，特别是其连续极限下的行为，以及探索注意力如何驱动表征聚类或保持多聚类结构。

Method: 建立数学框架将Transformer注意力解释为相互作用粒子系统，研究其连续（平均场）极限；通过将注意力理想化为球面上的连续函数，连接Transformer动力学与Wasserstein梯度流、同步模型（Kuramoto）和均值漂移聚类；分析可处理的等角约简以获得精确聚类速率。

Result: 发现了全局聚类现象：经过长时间亚稳态后，token会渐近聚类；分析了常用归一化方案如何改变收缩速度；识别了长上下文注意力的相变；揭示了驱动表征崩溃的机制以及保持深度注意力架构中表达性多聚类结构的机制。

Conclusion: 该研究为理解Transformer注意力动力学提供了数学框架，揭示了注意力机制中的聚类现象和相变行为，有助于解释表征崩溃机制并识别保持表达性结构的机制。

Abstract: We develop a mathematical framework that interprets Transformer attention as an interacting particle system and studies its continuum (mean-field) limits. By idealizing attention continuous on the sphere, we connect Transformer dynamics to Wasserstein gradient flows, synchronization models (Kuramoto), and mean-shift clustering. Central to our results is a global clustering phenomenon whereby tokens cluster asymptotically after long metastable states where they are arranged into multiple clusters. We further analyze a tractable equiangular reduction to obtain exact clustering rates, show how commonly used normalization schemes alter contraction speeds, and identify a phase transition for long-context attention. The results highlight both the mechanisms that drive representation collapse and the regimes that preserve expressive, multi-cluster structure in deep attention architectures.

</details>


### [111] [New Spiking Architecture for Multi-Modal Decision-Making in Autonomous Vehicles](https://arxiv.org/abs/2512.01882)
*Aref Ghoreishee,Abhishek Mishra,Lifeng Zhou,John Walsh,Nagarajan Kandasamy*

Main category: cs.LG

TL;DR: 提出了一种用于自动驾驶高级决策的端到端多模态强化学习框架，采用基于交叉注意力Transformer的感知模块整合异构传感器输入，并通过脉冲时序感知的类Transformer架构实现计算高效的多模态融合。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要整合多种传感器（摄像头、激光雷达、车辆航向信息）进行高级决策，但传统Transformer架构计算成本高，难以在资源受限的边缘环境中部署。

Method: 1. 端到端多模态强化学习框架；2. 交叉注意力Transformer感知模块整合异构传感器输入；3. 提出脉冲时序感知的类Transformer架构，使用三元脉冲神经元实现计算高效的多模态融合。

Result: 在Highway Environment的多个任务上进行全面评估，证明了所提方法在实时自动驾驶决策中的有效性和效率。

Conclusion: 提出的脉冲时序感知类Transformer架构能够有效解决传统Transformer在边缘环境部署中的计算效率问题，为实时自动驾驶决策提供了高效的多模态融合解决方案。

Abstract: This work proposes an end-to-end multi-modal reinforcement learning framework for high-level decision-making in autonomous vehicles. The framework integrates heterogeneous sensory input, including camera images, LiDAR point clouds, and vehicle heading information, through a cross-attention transformer-based perception module. Although transformers have become the backbone of modern multi-modal architectures, their high computational cost limits their deployment in resource-constrained edge environments. To overcome this challenge, we propose a spiking temporal-aware transformer-like architecture that uses ternary spiking neurons for computationally efficient multi-modal fusion. Comprehensive evaluations across multiple tasks in the Highway Environment demonstrate the effectiveness and efficiency of the proposed approach for real-time autonomous decision-making.

</details>


### [112] [Elastic Weight Consolidation for Knowledge Graph Continual Learning: An Empirical Evaluation](https://arxiv.org/abs/2512.01890)
*Gaganpreet Jhajj,Fuhua Lin*

Main category: cs.LG

TL;DR: EWC方法在知识图谱持续学习中显著减少灾难性遗忘，任务划分策略对遗忘程度有重要影响。


<details>
  <summary>Details</summary>
Motivation: 知识图谱需要持续更新，但神经嵌入模型在顺序学习新任务时会出现灾难性遗忘问题，需要评估持续学习方法在KG链接预测中的效果。

Method: 使用弹性权重巩固（EWC）正则化方法，在FB15k-237数据集上评估TransE嵌入模型，采用五种随机种子进行多次实验，比较基于关系的任务划分和随机任务划分策略。

Result: EWC将灾难性遗忘从12.62%减少到6.85%，降低了45.7%；基于关系的任务划分比随机划分表现出更高的遗忘率（12.62% vs 2.81%），相差9.8个百分点。

Conclusion: EWC能有效缓解知识图谱持续学习中的灾难性遗忘，任务构建策略显著影响评估结果，强调了评估协议设计的重要性。

Abstract: Knowledge graphs (KGs) require continual updates as new information emerges, but neural embedding models suffer from catastrophic forgetting when learning new tasks sequentially. We evaluate Elastic Weight Consolidation (EWC), a regularization-based continual learning method, on KG link prediction using TransE embeddings on FB15k-237. Across multiple experiments with five random seeds, we find that EWC reduces catastrophic forgetting from 12.62% to 6.85%, a 45.7% reduction compared to naive sequential training. We observe that the task partitioning strategy affects the magnitude of forgetting: relation-based partitioning (grouping triples by relation type) exhibits 9.8 percentage points higher forgetting than randomly partitioned tasks (12.62% vs 2.81%), suggesting that task construction influences evaluation outcomes. While focused on a single embedding model and dataset, our results demonstrate that EWC effectively mitigates catastrophic forgetting in KG continual learning and highlight the importance of evaluation protocol design.

</details>


### [113] [Provably Safe Model Updates](https://arxiv.org/abs/2512.01899)
*Leo Elmecker-Plakolm,Pierre Fasterling,Philip Sosnin,Calvin Tsay,Matthew Wicker*

Main category: cs.LG

TL;DR: 提出一个可证明安全模型更新的框架，通过计算参数空间中最大的局部不变域来确保更新后的模型满足性能规范


<details>
  <summary>Details</summary>
Motivation: 安全关键环境中的机器学习模型需要持续更新，但参数更新可能导致意外后果（如灾难性遗忘、对齐漂移），现有启发式方法无法提供形式化安全保证

Method: 将问题形式化为计算最大的局部不变域（LID），通过参数化抽象域（正交体、zonotopes）的松弛获得可处理的原始-对偶公式，实现独立于数据和算法的高效认证

Result: 在持续学习和基础模型微调基准测试中，该方法匹配或超越了避免遗忘的启发式基线，同时提供形式化安全保证

Conclusion: 提出的框架能够为模型更新提供可证明的安全保证，解决了安全关键环境中机器学习模型动态更新的核心挑战

Abstract: Safety-critical environments are inherently dynamic. Distribution shifts, emerging vulnerabilities, and evolving requirements demand continuous updates to machine learning models. Yet even benign parameter updates can have unintended consequences, such as catastrophic forgetting in classical models or alignment drift in foundation models. Existing heuristic approaches (e.g., regularization, parameter isolation) can mitigate these effects but cannot certify that updated models continue to satisfy required performance specifications. We address this problem by introducing a framework for provably safe model updates. Our approach first formalizes the problem as computing the largest locally invariant domain (LID): a connected region in parameter space where all points are certified to satisfy a given specification. While exact maximal LID computation is intractable, we show that relaxing the problem to parameterized abstract domains (orthotopes, zonotopes) yields a tractable primal-dual formulation. This enables efficient certification of updates - independent of the data or algorithm used - by projecting them onto the safe domain. Our formulation further allows computation of multiple approximately optimal LIDs, incorporation of regularization-inspired biases, and use of lookahead data buffers. Across continual learning and foundation model fine-tuning benchmarks, our method matches or exceeds heuristic baselines for avoiding forgetting while providing formal safety guarantees.

</details>


### [114] [A Footprint-Aware, High-Resolution Approach for Carbon Flux Prediction Across Diverse Ecosystems](https://arxiv.org/abs/2512.01917)
*Jacob Searcy,Anish Dulal,Scott Bridgham,Ashley Cordes,Lillian Aoki,Brendan Bohannan,Qing Zhu,Lucas C. R. Silva*

Main category: cs.LG

TL;DR: 提出Footprint-Aware Regression (FAR)深度学习框架，结合通量塔数据和Landsat卫星影像，在30米尺度上预测碳通量空间足迹和像素级估计


<details>
  <summary>Details</summary>
Motivation: 自然气候解决方案需要监测大范围生态系统的碳吸收，但现有卫星产品的空间尺度小于通量塔的足迹范围，难以准确评估碳通量

Method: 开发FAR深度学习框架，使用AMERI-FAR25数据集（439站点年的通量塔数据与对应Landsat影像），同时预测空间足迹和30米尺度的碳通量估计

Result: 模型能生成高分辨率预测，在多种生态系统测试站点上预测月净生态系统交换的R²达到0.78

Conclusion: FAR框架成功解决了卫星产品与通量塔尺度不匹配的问题，为大规模生态系统碳通量监测提供了有效工具

Abstract: Natural climate solutions (NCS) offer an approach to mitigating carbon dioxide (CO2) emissions. However, monitoring the carbon drawdown of ecosystems over large geographic areas remains challenging. Eddy-flux covariance towers provide ground truth for predictive 'upscaling' models derived from satellite products, but many satellites now produce measurements on spatial scales smaller than a flux tower's footprint. We introduce Footprint-Aware Regression (FAR), a first-of-its-kind, deep-learning framework that simultaneously predicts spatial footprints and pixel-level (30 m scale) estimates of carbon flux. FAR is trained on our AMERI-FAR25 dataset which combines 439 site years of tower data with corresponding Landsat scenes. Our model produces high-resolution predictions and achieves R2 = 0.78 when predicting monthly net ecosystem exchange on test sites from a variety of ecosystems.

</details>


### [115] [AlignSAE: Concept-Aligned Sparse Autoencoders](https://arxiv.org/abs/2512.02004)
*Minglai Yang,Xinyu Guo,Mihai Surdeanu,Liangming Pan*

Main category: cs.LG

TL;DR: 提出AlignSAE方法，通过"预训练+后训练"课程将稀疏自编码器特征与定义的本体对齐，实现可解释的特征表示和精确的概念控制


<details>
  <summary>Details</summary>
Motivation: 大语言模型将事实知识编码在难以检查或控制的隐藏参数空间中，现有稀疏自编码器虽然能分解隐藏激活为更细粒度的可解释特征，但往往难以可靠地将这些特征与人类定义的概念对齐，导致纠缠和分布式的特征表示

Method: 提出AlignSAE方法，采用"预训练，后训练"课程：初始无监督训练阶段后，应用有监督后训练将特定概念绑定到专用潜在槽位，同时保留其余容量用于一般重构。这种分离创建了一个可解释的接口，可以在其中检查和控制特定关系而不受无关特征干扰

Result: 实验结果表明，AlignSAE能够实现精确的因果干预，例如通过针对单个语义对齐的槽位实现可靠的"概念交换"

Conclusion: AlignSAE通过将稀疏自编码器特征与定义的本体对齐，解决了特征纠缠问题，创建了可解释且可控的特征表示接口，为大语言模型的可解释性和可控性提供了有效方法

Abstract: Large Language Models (LLMs) encode factual knowledge within hidden parametric spaces that are difficult to inspect or control. While Sparse Autoencoders (SAEs) can decompose hidden activations into more fine-grained, interpretable features, they often struggle to reliably align these features with human-defined concepts, resulting in entangled and distributed feature representations. To address this, we introduce AlignSAE, a method that aligns SAE features with a defined ontology through a "pre-train, then post-train" curriculum. After an initial unsupervised training phase, we apply supervised post-training to bind specific concepts to dedicated latent slots while preserving the remaining capacity for general reconstruction. This separation creates an interpretable interface where specific relations can be inspected and controlled without interference from unrelated features. Empirical results demonstrate that AlignSAE enables precise causal interventions, such as reliable "concept swaps", by targeting single, semantically aligned slots.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [116] [Exploring the apparent violation of the Mott relation in a noncentrosymmetric kagome ferromagnet](https://arxiv.org/abs/2512.00173)
*Benjamin Kostroun,Tomoya Asaba,Sean M. Thomas,Eric D. Bauer,Sergey Y. Savrasov,Filip Ronning,Vsevolod Ivanov*

Main category: cond-mat.str-el

TL;DR: UCoAl掺杂Ru的输运测量显示违反Mott关系，但实际模型表明每个掺杂水平下Mott关系仍成立，异常霍尔和异常能斯特电导的异常掺杂依赖行为源于关联平带将Weyl点钉扎在费米能级。


<details>
  <summary>Details</summary>
Motivation: 研究磁性拓扑材料中时间反演对称性破缺导致的拓扑点和线节点在异常霍尔和异常能斯特电导中的特征，这些特征通常满足Mott关系。但在具有复杂磁性、拓扑和电子关联的材料中，掺杂依赖的输运测量可能违反这一关系。

Method: 1. 对掺杂Ru的关联拓扑金属UCoAl进行输运测量；2. 开发一个模型来捕捉掺杂依赖的Stoner磁性和拓扑Weyl点演化；3. 使用该模型分析关联平带如何将Weyl点钉扎在费米能级。

Result: 测量显示UCoAl掺杂Ru的异常霍尔和异常能斯特电导表现出异常的掺杂依赖行为，看似违反Mott关系。但模型分析表明，在每个掺杂水平下Mott关系实际上都成立，异常行为源于关联平带将Weyl点钉扎在费米能级。

Conclusion: UCoAl掺杂Ru的输运测量看似违反Mott关系，但通过考虑关联平带将Weyl点钉扎在费米能级的机制，可以解释异常霍尔和异常能斯特电导的掺杂依赖行为，同时确认Mott关系在每个掺杂水平下仍然成立。

Abstract: In magnetic topological materials, time-reversal symmetry breaking gives rise to topological point and line nodes with distinctive signatures in the anomalous Hall and anomalous Nernst conductivity that satisfy the well-known Mott relation. However, this relationship can fail for doping-dependent transport measurements of materials with complex magnetism, topology, and electronic correlations. In this work, we present transport measurements of the correlated topological metal UCoAl doped with Ru, which appear to violate the Mott relation. We develop a model that captures the evolution of Stoner magnetism and topological Weyl points as a function of doping. Using this model, we show how the correlated flat band in this material pins the Weyl points to the Fermi energy, and demonstrate how this explains the unusual doping-dependent behavior of the anomalous Hall and anomalous Nernst conductivities in this material, while the Mott relation is in fact satisfied at each doping level.

</details>


### [117] [Robust semiclassical magnetization plateau in the kagome lattice](https://arxiv.org/abs/2512.00223)
*Gabriel Capelo,Eric C. Andrade*

Main category: cond-mat.str-el

TL;DR: 该研究探讨了在磁场作用下kagome晶格上的J1-J2海森堡模型，发现了稳健的1/3磁化平台，其稳定机制类似于三角晶格中的量子涨落选择机制。


<details>
  <summary>Details</summary>
Motivation: 受kagome基磁体中观察到的1/3磁化平台现象的启发，研究者在磁场作用下研究kagome晶格上的J1-J2海森堡模型，旨在理解这一平台现象的物理机制。

Method: 采用半经典方法，包括非线性自旋波理论和线性自旋波理论，计算了1/3磁化平台的宽度，并分析了J2参数的影响。

Result: 发现无论J2的符号如何，都存在稳健的1/3半经典磁化平台；平台宽度对J2的依赖性较弱；当J2=0时存在与平带相关的磁化跳跃；线性自旋波方法即使对S=1/2也能给出定量准确的结果。

Conclusion: 半经典方法能有效捕捉kagome晶格中的1/3磁化平台现象，为解释实验和数值结果提供了有价值的工具。

Abstract: Inspired by recent observations of the $1/3$ magnetization plateau in kagome-based magnets, we investigate the $J_1-J_2$ Heisenberg model on the kagome lattice under the influence of an external magnetic field. Although the classical ground state at zero field depends on the sign of $J_2$, we find a robust $1/3$ semiclassical magnetization plateau in both cases. The mechanism that stabilizes this plateau is analogous to that observed in the triangular lattice, where quantum fluctuations select a collinear state from the degenerate classical manifold. We calculate the plateau width, which shows a weak dependence on $J_2$, using nonlinear spin-wave theory. Additionally, we find that a straightforward approach based on linear spin-wave yields quantitatively accurate results even for $S=1/2$. Furthermore, we identify a magnetization jump at the saturation field when $J_2=0$; this jump is related to the presence of a flat band and disappears for $J_2 \neq 0$. Our study demonstrates that a semiclassical approach effectively captures the $1/3$ plateau in the kagome lattice and serves as a valuable tool for interpreting experimental and numerical results alike.

</details>


### [118] [Magnetosynthesis effect on the structure and ground state of Cu$^{2+}$-based antiferromagnets](https://arxiv.org/abs/2512.00253)
*Micaela E. Primer,Anna A. Berseneva,Ayesha Ulde,Wenhao Sun,Rebecca W. Smaha*

Main category: cond-mat.str-el

TL;DR: 研究磁场合成对几种Cu²⁺基反铁磁材料的晶体结构和磁性能的影响，发现磁场合成能显著改变材料的磁相变温度和相互作用强度。


<details>
  <summary>Details</summary>
Motivation: 合成过程中的细微变量（如磁场）可能对量子材料的晶体结构和磁性能产生重大影响，特别是对于具有反铁磁相互作用和不同磁阻挫水平的材料。

Method: 在低温水热或蒸发合成过程中施加小磁场（0.09-0.37 T），研究四种Cu²⁺基材料：简单反铁磁体CuCl₂·2H₂O、倾斜反铁磁体(Cu,Zn)₃Cl₄(OH)₂·2H₂O、阻挫倾斜反铁磁体atacamite Cu₂(OH)₃Cl，以及高度阻挫量子自旋液体herbertsmithite Cu₃Zn(OH)₆Cl₂。

Result: (Cu,Zn)₃Cl₄(OH)₂·2H₂O在其磁相变温度以上出现结构变化；在0.19 T磁场下合成的atacamite Cu₂(OH)₃Cl的尼尔转变温度降低了0.15 K（约3%），且反铁磁相互作用显著增强，表明磁场合成能影响中等阻挫材料的基态。

Conclusion: 磁场合成能够显著影响Cu²⁺基反铁磁材料的晶体结构和磁性能，特别是对中等阻挫材料，磁场合成可以改变其基态性质，这为调控量子材料的性能提供了新途径。

Abstract: Subtle synthetic variables can have an outsizes influence on the crystal structure and magnetic properties of a material, particularly those of quantum materials. In this work, we investigate the impact of synthesis under a magnetic field (magnetosynthesis) on the crystal structure and magnetic properties of several Cu$^{2+}$ ($S=1/2$) based materials with antiferromagnetic interactions and varying levels of magnetic frustration, from simple antiferromagnets to a quantum spin liquid. We employ small (0.09 - 0.37 T) magnetic fields applied during low-temperature hydrothermal or evaporative synthesis of the simple antiferromagnet CuCl$_2\cdot$2H$_2$O, the canted antiferromagnet (Cu,Zn)$_3$Cl$_4$(OH)$_2\cdot$2H$_2$O, the frustrated and canted antiferromagnet atacamite Cu$_2$(OH)$_3$Cl, and the highly frustrated quantum spin liquid herbertsmithite Cu$_3$Zn(OH)$_6$Cl$_2$. We found that (Cu,Zn)$_3$Cl$_4$(OH)$_2\cdot$2H$_2$O experiences structural changes well above its magnetic transition. Atacamite Cu$_2$(OH)$_3$Cl synthesized under a 0.19 T field experiences a 0.15 K (~3%) decrease in its Néel transition temperature and a significant strengthening of its antiferromagnetic interactions, suggesting that magnetosynthesis can influence the ground state of moderately frustrated materials.

</details>


### [119] [Precise computation of universal corner entanglement entropy at 2+1 dimension: From Ising to Gaussian quantum critical points](https://arxiv.org/abs/2512.00382)
*Ben Lee-Yeung Ngai,Justin Tim-Lok Chau,Junchen Rong,Yuan Da Liao,Zi Yang Meng*

Main category: cond-mat.str-el

TL;DR: 开发了一种基于气泡基投影量子蒙特卡洛的新算法，用于精确计算(2+1)维量子多体系统中纠缠熵的次领头对数项，特别是在Ising和Gaussian量子临界点之间的路径上。


<details>
  <summary>Details</summary>
Motivation: 尽管纠缠熵的次领头对数项对于揭示量子态和量子临界点的普适信息至关重要，但计算(2+1)维量子多体系统中的这一项仍然是一个重大挑战。

Method: 利用最近能够稳定计算纠缠熵作为指数可观测量算法的进展，开发了气泡基投影量子蒙特卡洛算法。该方法在QMC采样中直接消除主导的面积律项，使次领头对数项成为主要贡献。

Result: 将该技术应用于计算(2+1)维正方晶格横向场Ising模型（添加四体相互作用）中的纠缠熵，追踪从Ising到Gaussian量子临界点再到一级相变的路径。沿路径获得的普适角纠缠熵一致值验证了该方法的可靠性和精确性。

Conclusion: 这些结果建立了长期以来寻求的精确可解极限与(2+1)维强关联区域之间普适值的联系，为提取具有挑战性的纠缠性质提供了可靠方法。

Abstract: Computing the subleading logarithmic term in the entanglement entropy (EE) of (2+1)d quantum many-body systems remains a significant challenge, despite its critical role in revealing universal information about quantum states and quantum critical points (QCPs). Capitalizing on recent algorithmic advances that enable the stable calculation of EE as an exponential observable, we develop a {\it bubble basis} projector quantum Monte Carlo (QMC) algorithm to precisely and efficiently compute the universal corner EE along a parameter trajectory connecting the Ising and Gaussian QCPs; where in the latter case there exists an analytic value to benchmark with. Our approach eliminates the dominant area-law term directly within the QMC sampling, thereby promoting the coveted subleading logarithmic term to the leading contribution. We apply this technique to calculate the EE in a (2+1)d square-lattice transverse-field Ising model augmented with a four-body interaction, tracing a path from the Ising to the Gaussian QCPs and then to the first-order transition. The consistent values obtained for the universal corner EE along the path validate the reliability and precision of our approach for extracting challenging entanglement properties. These results establish the long-sought connection between the universal values of an exactly solvable limit and those of a strongly correlated regime at (2+1)d.

</details>


### [120] [Altermagnetic boosting of chiral phonons](https://arxiv.org/abs/2512.00388)
*J. Okamoto,C. Y. Mou,H. Y. Huang,G. Channagowdra,C. Won,K. Du,X. Fang,E. V. Komleva,C. T. Chen,S. V. Streltsov,A. Fujimori,S-W. Cheong,D. J. Huang*

Main category: cond-mat.str-el

TL;DR: 研究发现螺旋自旋态中手性声子耦合增强约10倍，揭示了通过螺旋自旋的宇称-时间对称性破缺放大手性声子的新途径。


<details>
  <summary>Details</summary>
Motivation: 探索手性声子与磁性手性之间的可能联系，特别是螺旋自旋序如何影响手性声子耦合。

Method: 研究具有晶体极性和手性的化合物(Mn,Ni)₃TeO₆，该材料具有三种不同状态：顺磁态、具有磁性手性的螺旋自旋态以及无磁性手性的共线自旋态。

Result: 在螺旋自旋态中，沿螺旋轴方向的手性声子耦合比顺磁态和共线自旋态增强了约10倍。

Conclusion: 螺旋自旋的宇称-时间对称性破缺产生的交变磁效应为放大手性声子提供了新途径。

Abstract: Chirality characterizes the asymmetry between a structure and its mirror image and underlies a wide range of chiral functionalities. In crystallographically chiral materials, phonons with non-zero linear momentum $\textbf{k}$ can acquire a $k$-induced longitudinal magnetization, giving rise to chiral phonons. Helical spin order, with its proper screw-type configuration, breaks all mirror symmetries and therefore carries magnetic chirality. Such helical spins also generate non-relativistic spin splitting for any quasiparticle excitations propagating along the screw axis. To explore the possible connection between chiral phonons and magnetic chirality, we investigated the crystallographically polar and chiral compound (Mn,Ni)$_3$TeO$_6$, which hosts three distinct states: a paramagnetic state, a helical spin state with magnetic chirality, and a collinear spin state without magnetic chirality. We find an approximately tenfold enhancement of chiral-phonon coupling in the helical spin state along the screw axis, compared with both the paramagnetic and collinear spin states. These results identify a new route to amplify chiral phonons through an altermagnetic effect arising from the broken parity-time symmetry in helical spins. %from non-relativistic spin splitting.

</details>


### [121] [Near-flat-band-driven violation of Pauli limit in heavy fermion superconductors](https://arxiv.org/abs/2512.00486)
*Yan-Xiao Wang,Yin Zhong*

Main category: cond-mat.str-el

TL;DR: 重费米子超导体中，上临界场常超过传统泡利顺磁极限，表明强关联和杂化准粒子带在顺磁配对破坏过程中起关键作用。通过二维Kondo-Heisenberg模型的自洽平均场分析，发现接近半填充时Clogston-Chandrasekhar比急剧增加，这是由于下杂化带的弱色散区域降低了费米速度，从而增强了泡利极限场。


<details>
  <summary>Details</summary>
Motivation: 研究重费米子超导体中上临界场超过传统泡利顺磁极限的物理机制，探索强关联系统中顺磁配对破坏过程的基本原理。

Method: 采用二维Kondo-Heisenberg模型，对自旋单重态s波、扩展s波和d波配对在塞曼场下进行自洽平均场分析，计算临界场Bc、转变温度Tc和Clogston-Chandrasekhar比rCC。

Result: 发现rCC在传导电子填充接近半填充时急剧增加；这种增强源于下杂化带的弱色散区域，其中显著降低的费米速度减小了正常态顺磁能，稳定了超导性；不同配对通道对JH的依赖性反映了泡利极限对带曲率和序参数结构的敏感性。

Conclusion: 接近近平坦杂化带为重费米子超导体中增强泡利极限场提供了稳健途径，为理解强关联超导体的异常上临界场行为提供了微观证据。

Abstract: Heavy-fermion superconductors often display upper critical fields that exceed the conventional Pauli paramagnetic limit, indicating that strong correlations and hybridized quasiparticle bands play an essential role in the paramagnetic pair-breaking process. Within the two-dimensional Kondo-Heisenberg model, we perform a self-consistent mean-field analysis of spin-singlet s-, extended-s-, and d-wave pairing under Zeeman fields, and compute the critical field Bc, the transition temperature Tc, and the Clogston-Chandrasekhar ratio rCC. We find that rCC increases sharply as the conduction filling approaches half filling. This enhancement arises from the weakly dispersive region of the lower hybridized band, where the strongly reduced Fermi velocity diminishes the normal-state paramagnetic energy and stabilizes superconductivity. At fixed filling, the distinct JH dependences among the three pairing channels reflect the sensitivity of Pauli limiting to both band curvature and the structure of the order parameter. These results provide microscopic evidence that proximity to a near-flat hybridized band offers a robust route to enhanced Pauli-limiting fields in heavy-fermion superconductors.

</details>


### [122] [Spin-resolved Mott crossover and entanglement in the half-filled Hubbard model](https://arxiv.org/abs/2512.00613)
*Md Fahad Equbal,M. A. H. Ahsan*

Main category: cond-mat.str-el

TL;DR: 通过精确对角化研究3x3方格簇中相互作用驱动的金属-莫特绝缘体交叉，采用多诊断方法统一表征这一平滑但明确的电子关联重组过程。


<details>
  <summary>Details</summary>
Motivation: 研究相互作用驱动的金属态到莫特绝缘体态的交叉过程，特别是在有限系统中理解电子关联的重组机制和自旋依赖特性。

Method: 使用精确对角化方法研究半填充的3x3方格簇，在S=1/2和S=3/2自旋扇区进行分析。采用多种互补诊断工具：序参数、关联矩阵的主成分分析(PCA)、量子几何方法。

Result: 所有诊断方法一致识别出在弱到中等耦合区域(U~2-6)存在广泛的交叉：电荷能隙快速打开，双占据被抑制，局域磁矩形成，纠缠显著减少，PCA将方差集中在少数主导模式中，距离矩阵显示波函数快速重组。

Conclusion: 莫特交叉是电子关联的平滑但明确的重组过程，在有限系统中表现出显著的自旋扇区依赖性，多诊断方法为这一交叉提供了统一的数据驱动表征。

Abstract: We study interaction-driven crossover from a correlated metallic state to Mott-insulating state on the half-filled 3x3 square cluster using exact diagonalization in the S=1/2 and S=3/2 sectors. Using complementary diagnostics such as order parameters, principal component analysis (PCA) of correlation matrices and quantum geometry, we obtain a unified, data-driven characterization of the crossover. All three diagnostics consistently identify a broad crossover centered in the weak-to-intermediate coupling regime U~2-6; charge gaps open rapidly, double occupancy suppresses, local moments form, entanglement is significantly reduced, PCA concentrates variance into a few dominant modes and the distance matrices reveals rapid wavefunction reorganization. Our multi-pronged approach establishes the Mott crossover as a smooth but well defined reorganization of electronic correlations with pronounced spin-sector dependence in finite systems.

</details>


### [123] [Evidence for itinerant electron-local moment interaction in Li-doped $α$-MnTe](https://arxiv.org/abs/2512.00747)
*Tingjun Zhang,Steven J. Gomez Alvarado,Sijie Xu,Travis J. Williams,Xiaoping Wang,Junhong He,Matthew B. Stone,Colin Sarkis,Feng Ye,Zhaoyu Liu,Jinyulin Li,Aparna Jayakumar,Zehao Wang,Yaofeng Xie,Ching-Wu Chu,Liangzi Deng,Emilia Morosan,Pengcheng Dai*

Main category: cond-mat.str-el

TL;DR: 通过非弹性中子散射研究Li掺杂对α-MnTe的影响，发现Li掺杂导致自旋重定向（面内→面外），增加载流子密度，引起显著的自旋波展宽，但保持完整的Mn²⁺局域磁矩。


<details>
  <summary>Details</summary>
Motivation: 研究Li掺杂如何影响α-MnTe这种半导体交变磁体的磁性和自旋动力学性质，探索载流子对交变磁体磁输运和自旋动态特性的重要性。

Method: 使用非弹性中子散射技术研究Li掺杂的α-MnTe，提取局域动态磁化率，应用总磁矩求和规则分析磁矩特性。

Result: Li掺杂导致自旋重定向从面内转向面外，增加载流子密度，引起整个布里渊区的自旋波展宽（增强的磁振子阻尼），但未掺杂和Li掺杂样品都保持完整的Mn²⁺局域磁矩（≈5.9μ_B，S=5/2）。

Conclusion: Li掺杂的α-MnTe具有稳健的局域磁矩磁性，其相互作用通过RKKY型相互作用介导，强调了载流子在交变磁体磁输运和自旋动态特性中的重要性。

Abstract: We use inelastic neutron scattering to study the impact of Li doping on the semiconducting altermagnet $α$-MnTe. Introducing Li results in a spin reorientation from in-plane to out-of-plane and increases the density of itinerant carriers. While the spin waves in Li-doped $α$-MnTe remain largely Heisenberg-like, there is significant spin wave broadening across the entire Brillouin zone, signaling enhanced magnon damping induced by itinerant carriers. By extracting the local dynamic susceptibility and applying the total moment sum rule, we find that both undoped and Li-doped $α$-MnTe exhibit the full expected Mn$^{2+}$ local moment of $\approx5.9~μ_\mathrm{B}$ with $S=5/2$. These results demonstrate that Li-doped $α$-MnTe hosts robust local-moment magnetism whose interactions are mediated via Ruderman-Kittel-Kasuya-Yosida-type interactions, highlighting the importance of itinerant carriers in magneto-transport and spin dynamic properties of altermagnets.

</details>


### [124] [Electric-field driven flat bands in the distorted sawtooth chain via the Katsura-Nagaosa-Balatsky mechanism](https://arxiv.org/abs/2512.00900)
*Vadim Ohanyan,Lusik Amiraghyan,Michael Sekania,Marcus Kollar*

Main category: cond-mat.str-el

TL;DR: 研究广义锯齿链模型中平坦磁振子能带，通过电场调控Dzyaloshinskii-Moriya相互作用实现能带平坦化


<details>
  <summary>Details</summary>
Motivation: 探索在广义锯齿链模型中，通过电场调控Dzyaloshinskii-Moriya相互作用来产生平坦磁振子能带的可能性，特别是在三角形晶格畸变的情况下

Method: 采用广义锯齿链模型，包含三组独立交换参数（对称海森堡交换、轴向伊辛各向异性、反对称DM交换），通过Katsura-Nagaosa-Balatsky机制将DM相互作用参数化为电场强度和方向以及晶格几何的函数，重点分析三角形晶格畸变情况

Result: 分析了畸变锯齿链中几种电场诱导的平坦能带情景，推导了电场沿晶格键排列时驱动单磁振子激发进入平坦能带区域所需的电场强度表达式，研究了饱和场及其对畸变角的依赖关系，建立了通用DM相互作用与特定KNB诱导形式之间的平坦能带解映射关系

Conclusion: 通过电场调控DM相互作用可以在畸变锯齿链中实现平坦磁振子能带，建立了通用DM相互作用与KNB机制诱导的特定形式之间的对应关系，为电场控制磁振子能带结构提供了理论框架

Abstract: We investigate flat magnonic bands in a generalized sawtooth-chain
  model in which three sets of exchange parameters (symmetric
  Heisenberg exchange, axial Ising anisotropy, and antisymmetric
  Dzyaloshinskii-Moriya (DM) exchange) are assigned independently to
  each side of the triangular plaquette. If the effective
  Dzyaloshinskii-Moriya (DM) interaction parameters are generated
  via the Katsura-Nagaosa-Balatsky (KNB) mechanism of
  magnetoelectricity, they become explicit functions of the
  electric-field magnitude and direction, as well as of the lattice
  geometry, which in the present casen is characterized by two bond
  angles. We focus on the situation in which these two angles are
  unequal, corresponding to a distortion of the triangular
  plaquette. Several electric-field induced flat-band scenarios in
  the distorted sawtooth chain are analyzed, and expressions are
  derived for the electric-field strength required to drive the
  one-magnon excitations into a flat-band regime when the field is
  aligned along the lattice bonds. The saturation field and its
  dependence on the distortion angle are also examined. Finally, we
  establish a mapping between the flat-band solutions for a general
  DM interaction and its specific KNB-induced form.
  \\~
  \emph{This article is dedicated to the memory of Johannes Richter.}

</details>


### [125] [Magnetic clusters in the paramagnetic phase of a high-temperature ferromagnetic metal-organic framework](https://arxiv.org/abs/2512.00980)
*Giacomo Prando,Benjamin Costarella,Matthew S. Dickson,Ryan A. Murphy,Jesse G. Park,Gianrico Lamura,Giuseppe Allodi,Cristian Aloisi,Aëto Apaix,Maria Cristina Mozzati,T. David Harris,Jeffrey R. Long,Pietro Carretta*

Main category: cond-mat.str-el

TL;DR: 该研究报道了一种铬基金属有机框架材料在接近室温条件下展现的非常规铁磁行为，通过多种磁学表征手段揭示了其独特的电子局域化、离子旋转动力学以及顺磁区形成的介观磁性团簇。


<details>
  <summary>Details</summary>
Motivation: 金属有机框架材料因其化学和电子可调性在磁性应用中具有潜力，但通常由于有机配体的弱交换作用导致有序温度仅限于低温范围。本研究旨在探索一种在接近室温条件下展现铁磁行为的铬基金属有机框架材料的特殊磁性状态。

Method: 使用直流SQUID磁强计、核磁共振和铁磁共振等多种磁学表征技术，研究材料中的磁性状态、电子局域化效应、离子旋转动力学以及磁性团簇的形成机制。

Result: 发现该材料在顺磁区形成介观磁性相关团簇，其慢动力学在MHz范围内被核磁矩追踪；观察到电子在低温下的局域化趋势以及孔道内三氟甲磺酸离子的旋转动力学；这些结果与直流SQUID磁强计检测到的高度非常规磁性转变一致。

Conclusion: 高温磁性金属有机框架材料可作为探索低密度、化学可调材料中关联电子现象的多功能平台，其顺磁区的团簇相与锰酸盐和钴酸盐中导致巨磁电阻的磁电子相分离现象相似。

Abstract: Owing to their exceptional chemical and electronic tunability, metal-organic frameworks can be designed to develop magnetic ground states making a range of applications feasible, from magnetic gas separation to the implementation of lightweight, rare-earth free permanent magnets. However, the typically weak exchange interactions mediated by the diamagnetic organic ligands result in ordering temperatures confined to the cryogenic limit. The itinerant magnetic ground state realized in the chromium-based framework Cr(tri)$_{2}$(CF$_{3}$SO$_{3}$)$_{0.33}$ (Htri, $1H$-$1$,$2$,$3$-triazole) is a remarkable exception to this trend, showing a robust ferromagnetic behavior almost at ambient conditions. Here, we use dc SQUID magnetometry, nuclear magnetic resonance, and ferromagnetic resonance to study the magnetic state realized in this material. We highlight several thermally-activated relaxation mechanisms for the nuclear magnetization due to the tendency of electrons towards localization at low temperatures as well as the rotational dynamics of the charge-balancing triflate ions confined within the pores. Most interestingly, we report the development within the paramagnetic regime of mesoscopic magnetic correlated clusters whose slow dynamics in the MHz range are tracked by the nuclear moments, in agreement with the highly unconventional nature of the magnetic transition detected by dc SQUID magnetometry. We discuss the similarity between the clustered phase in the paramagnetic phase and the magnetoelectronic phase segregation leading to colossal magnetoresistance in manganites and cobaltites. These results demonstrate that high-temperature magnetic metal-organic frameworks can serve as a versatile platform for exploring correlated electron phenomena in low-density, chemically tunable materials.

</details>


### [126] [Dynamics of superconducting pairs in the two-dimensional Hubbard model](https://arxiv.org/abs/2512.01124)
*G. Sordi,E. M. O'Callaghan,C. Walsh,M. Charlebois,P. Sémon,A. -M. S. Tremblay*

Main category: cond-mat.str-el

TL;DR: 该研究通过二维哈伯德模型和细胞动力学平均场理论，系统分析了铜氧化物超导关联的频率结构，发现配对形成和配对破坏过程随频率交替出现，但净配对贡献仅来自低频配对形成过程。


<details>
  <summary>Details</summary>
Motivation: 铜氧化物超导关联的频率结构能为配对机制提供重要见解，但需要系统研究其在哈伯德模型中的表现，以理解不同频率过程对配对的相对贡献。

Method: 使用二维哈伯德模型结合细胞动力学平均场理论，系统量化了掺杂和相互作用强度对超导能隙、配对发生频率尺度及其相对贡献的依赖性。

Result: 发现配对形成和配对破坏过程随频率交替出现，表明理论上配对可来自低频和高频过程。但高频配对形成过程被配对破坏过程抵消，净配对贡献仅来自低频配对形成过程。

Conclusion: 低频配对形成过程在配对机制中起关键作用，高频过程虽然存在配对形成成分，但净效应被配对破坏过程抵消，无法贡献净配对。

Abstract: The frequency structure of the superconducting correlations in cuprates gives insights on the pairing mechanism. Here we present an exhaustive study of this problem in the two-dimensional Hubbard model with cellular dynamical mean-field theory. To this end, we systematically quantify the dependence on doping and interaction strength of the superconducting gap, of the frequency scales where pairing occurs, and of their relative contribution to pairing. We find pair-forming alternating with pair-breaking processes as a function of frequency, providing new evidence that pairing can arise in principle from both low- and high-frequency processes. However, we find that the high-frequency pair-forming processes are outweighed by pair-breaking ones. Hence, the net contribution to pairing comes only from the low-frequency pair-forming processes, a result that underscores their key role in the pairing mechanism.

</details>


### [127] [Generalized Nagaoka ferromagnetism accompanied by flavor-selective Mott states in an SU($N$) Fermi-Hubbard model](https://arxiv.org/abs/2512.01264)
*Juntaro Fujii,Kazuki Yamamoto,Akihisa Koga*

Main category: cond-mat.str-el

TL;DR: 研究SU(N)费米-哈伯德模型在强耦合低温下的铁磁不稳定性，发现远离整数填充时会出现铁磁有序态，其中SU(3)系统存在自发味道选择性莫特态，SU(4)系统则有六种不同类型的铁磁态。


<details>
  <summary>Details</summary>
Motivation: 探索具有扩展内部对称性的SU(N)费米-哈伯德系统中的铁磁不稳定性，特别是在强耦合低温条件下，理解这些系统中丰富的磁行为。

Method: 结合动力学平均场理论和连续时间量子蒙特卡洛模拟，研究超立方晶格上的SU(N)费米-哈伯德模型。

Result: 在强耦合低温条件下，远离整数填充时出现铁磁有序态；SU(3)系统中在三分之一填充附近观察到自发味道选择性莫特态，其中两种味道为莫特绝缘体，一种为金属；SU(4)系统中随着粒子密度变化出现六种不同类型的铁磁态。

Conclusion: SU(N)费米-哈伯德系统中的铁磁态具有丰富多样的性质，扩展的内部对称性使得磁性行为更加复杂，其中掺杂粒子的动能增益对铁磁态的稳定起着关键作用。

Abstract: We study the ferromagnetic instability in an SU($N$) Fermi-Hubbard model on the hypercubic lattice. Combining dynamical mean-field theory with continuous-time quantum Monte Carlo simulations, we find that, in the strong-coupling regime at low temperatures, ferromagnetically ordered (FM) states develop away from the commensurate fillings. In the particle-doped SU($3$) system near one-third filling, the FM state is accompanied by a spontaneous flavor-selective Mott state, where two of the three flavors are Mott insulating while the remaining flavor is metallic. Since particles in the metallic flavor can almost freely move on the lattice without correlation effects, the ordered state is stabilized by the kinetic-energy gain of the doped particles. This is similar to the generalized Nagaoka ferromagnetism discussed in the one-hole-doped system at one-third filling. In the SU($4$) case, we find that six distinct types of FM states appear as the particle density varies. The results uncover the nature of the FM state in the SU($N$) Fermi-Hubbard systems and highlight the rich magnetic behavior enabled by enlarged internal symmetries.

</details>


### [128] [Disorder Suppression of Charge Density Wave in the Honeycomb Holstein Model](https://arxiv.org/abs/2512.01487)
*Guangchao Li,Lifei Zhang,Tianxing Ma,Qionglin Dai,Lufeng Zhang*

Main category: cond-mat.str-el

TL;DR: 研究无序对狄拉克费米子系统中电荷密度波序的影响，发现无序抑制电荷密度波相，但无序与电子-声子相互作用的结合扩展了相区范围。


<details>
  <summary>Details</summary>
Motivation: 研究无序和电子-声子耦合的联合效应对狄拉克费米子系统中电荷密度波形成的影响，这是凝聚态物理中的重要课题。

Method: 使用行列式量子蒙特卡洛模拟，在蜂窝晶格上的Holstein模型中研究电荷密度波相变，通过电子随机跳跃引入无序。

Result: 无序抑制电荷密度波相，但无序与电子-声子相互作用的结合扩展了相区；确定了有序相转变温度与电子-声子耦合的函数关系；观察到无序下电子动能和直流电导率被抑制。

Conclusion: 这些发现为理解无序二维系统中关联相的稳定性和临界现象提供了重要理论见解，突出了安德森局域化在电子输运退化中的作用。

Abstract: The formation of charge-density-wave order in Dirac fermion systems via electron-phonon coupling represents a significant topic in condensed matter physics. In this work, we investigate this phenomenon within the Holstein model on the honeycomb lattice, with a specific focus on the effect of disorder. While the interplay between electron-electron interactions and disorder has long been a central theme in the field, recent attention has increasingly turned to the combined influence of disorder and electron-phonon coupling. Using determinant quantum Monte Carlo simulations, we concentrate on the phase transitions of charge-density-wave order on the honeycomb lattice. Disorder is introduced through the random hopping of electrons in the system, which can localize electrons via the Anderson effect. Our primary result is that disorder suppresses the charge-density-wave phase, and the interplay between disorder and electron-phonon interactions extends the phase area. We also determine the transition temperature \(β_c\) to the ordered phase as a function of the electron-phonon coupling. Additionally, we observed a suppression of electron kinetic energy and dc conductivity under disorder, highlighting the role of Anderson localization in the degradation of electronic transport. These findings offer significant theoretical insight into the stability and critical phenomena of correlated phases in disordered two-dimensional systems.

</details>


### [129] [$\mathbb{Z}_2$ Vortex Crystal Candidate in the Triangular $S=1/2$ Quantum Antiferromagnet](https://arxiv.org/abs/2512.01793)
*J. Nagl,K. Yu. Povarov,B. Duncan,C. Näppi,D. Khalyavin,P. Manuel,F. Orlandi,J. Sourd,B. V. Schwarze,F. Husstedt,S. A. Zvyagin,O. Zaharko,P. Steffens,A. Hiess,D. Allan,S. Barnett,Z. Yan,S. Gvasaliya,A. Zheludev*

Main category: cond-mat.str-el

TL;DR: 该研究报道了一种新型有机量子反铁磁体(CD₃ND₃)₂NaRuCl₆，它结合了三角晶格几何阻挫和强自旋轨道耦合，展示了独特的磁场-温度相图，包含三种不同的非公度态，是研究几何阻挫与自旋轨道效应相互作用的新平台。


<details>
  <summary>Details</summary>
Motivation: 探索在三角晶格几何阻挫和强自旋轨道耦合极限下键各向异性相结合的新型量子材料，寻找能够实现奇异量子物理的候选系统。

Method: 通过热力学、磁弹性和中子散射实验相结合的方法，在轴向磁场条件下研究单晶样品的相图，并提出最小模型哈密顿量来描述系统。

Result: 发现(CD₃ND₃)₂NaRuCl₆具有理想的Ru³⁺三角排列，采用自旋轨道纠缠的j_eff = 1/2态，在T_N = 0.23 K以下存在残余磁序，并展现出包含三种不同非公度态的异常H-T相图。高场极化区的自旋波可以用具有潜在次主导键依赖各向异性项的海森堡三角晶格哈密顿量描述。

Conclusion: 该材料是扩展量子三角晶格磁体家族的第一个成员，为零磁场下的多q基态提供了研究Z₂涡旋晶体的理想平台，提出了两种可能解释场依赖非公度性的机制，为研究几何阻挫和自旋轨道效应的相互作用开辟了新领域。

Abstract: The prospect of merging the paradigms of geometric frustration on a triangular lattice and bond anisotropies in the strong spin-orbit coupling limit holds tremendous promise in the ongoing hunt for exotic quantum materials. Here we identify a new candidate system to realize such physics, the organic quantum antiferromagnet (CD$_3$ND$_3$)$_2$NaRuCl$_6$. We report a combination of thermodynamic, magneto-elastic and neutron scattering experiments on single-crystals to determine the phase diagram in axial magnetic fields $\mathbf{H \parallel c}$ and propose a minimal model Hamiltonian. (CD$_3$ND$_3$)$_2$NaRuCl$_6$ displays an ideal triangular arrangement of Ru$^{3+}$ ions adopting the spin-orbital entangled $j_{\rm eff} = 1/2$ state. It hosts residual magnetic order below $T_{\rm N} = 0.23$ K and a highly unusual $H-T$ phase diagram including three different incommensurate states. Spin-waves in the high-field polarized regime are well described by a Heisenberg-like triangular lattice Hamiltonian with a potential sub-leading bond dependent anisotropy term. We discuss possible candidate magnetic structures in the various observed phases and propose two mechanisms that could explain the field-dependent incommensurability, requiring either a small ferromagnetic Kitaev term or a tiny magneto-elastic $J-J'$ isosceles distortion driven by pseudospin-lattice coupling. We argue that the multi-$\mathbf{q}$ ground state in zero magnetic field is a prime candidate for hosting the $\mathbb{Z}_2$ vortex crystal proposed on the triangular Heisenberg-Kitaev model. (CD$_3$ND$_3$)$_2$NaRuCl$_6$ is the first member in an extended family of quantum triangular lattice magnets, providing a new playground to study the interplay of geometric frustration and spin-orbit effects.

</details>


### [130] [Anomalous Eigenstates of a Doped Hole in the Ising Antiferromagnet](https://arxiv.org/abs/2512.01815)
*Piotr Wrzosek,Krzysztof Wohlfeld,Eugene A. Demler,Annabelle Bohrdt,Fabian Grusdt*

Main category: cond-mat.str-el

TL;DR: 该研究揭示了经典伊辛-奈尔态中单个空穴的局域谱存在一系列反常长寿命态，超越了传统的梯子状谱，这些态源于问题的近似涌现局域C3对称性，代表了一种新型量子多体疤痕态。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对掺杂反铁磁莫特绝缘体中移动空穴问题的深入理解，这一问题被认为是重费米子和高温超导等强关联电子系统丰富物理的基础。尽管伊辛反铁磁体中的掺杂问题被认为已通过贝特晶格映射基本解决，但研究者发现其中存在未被认识的反常现象。

Method: 采用精确对角化方法和自回避路径近似，计算了经典伊辛-奈尔态中单个空穴的局域谱，并通过计算不同的局域旋转谱来分析反常态的起源。

Result: 发现了超越传统J^{2/3}t^{1/3}能量间距梯子状谱的一系列反常长寿命态，这些态的激发能量近似线性依赖于J，并与更显著的梯子谱形成一系列避免交叉。分析表明这些反常态源于问题的近似涌现局域C3对称性。

Conclusion: 这些反常态具有异常缓慢的热化行为特征，代表了一种新型的量子多体疤痕态，可能与晶格规范理论中预测的多体疤痕态相关，为理解强关联系统中的非平衡动力学提供了新视角。

Abstract: The problem of a mobile hole doped into an antiferromagnet Mott insulator is believed to underly the rich physics of several paradigmatic strongly correlated electron systems, ranging from heavy fermions to high-Tc superconductivity. Arguably the simplest incarnation of this problem corresponds to a doped Ising antiferromagnet, a problem widely considered essentially solved since almost 60 years by a popular yet approximate mapping to a single-particle problem on the Bethe lattice. Here we show that, despite its deceptive simplicity, the local spectrum of a single hole in a classical Ising-Néel state contains a series of anomalous, long-lived states that go beyond the well-known ladder-like spectrum with excited energies spaced as $J^{2/3} t^{1/3}$. The anomalous states we find through exact diagonalization and within the self-avoiding path approximation have excitation energies scaling approximately linear with $J$ and lead to a series of avoided crossings with the more pronounced ladder spectrum. By also computing different local, rotational spectra we explain the origin of the anomalous states as rooted in an approximate emergent local $C_3$ symmetry of the problem. From their direct spectral signatures we further conclude that these states lead to anomalously slow thermalization behavior -- hence representing a new type of quantum many-body scar state, potentially related to many-body scars predicted in lattice gauge theories.

</details>


### [131] [Heterometallic spin-1/2 quantum magnet under hydrostatic pressure](https://arxiv.org/abs/2512.01994)
*M. J. Coak,D. Kamenskyi,S. P. M. Curley,B. M. Huddart,J. P. Tidey,A. Chmeruk,T. Sakurai,S. Okubo,H. Ohta,S. Kimura,H. Nojiri,D. Graf,S. J. Clark,Z. E. Manson,J. L. Manson,T. Lancaster,P. A. Goddard*

Main category: cond-mat.str-el

TL;DR: 该研究通过高压实验和理论计算揭示了CuVOF₄(H₂O)₆·H₂O中Cu(II)和V(IV)自旋-1/2二聚体的交换相互作用机制，发现其通过V(IV)向氧原子提供自旋密度的非传统机制实现。


<details>
  <summary>Details</summary>
Motivation: 研究CuVOF₄(H₂O)₆·H₂O中不同自旋物种Cu(II)和V(IV)形成的反铁磁自旋-1/2二聚体，探索其交换相互作用的非传统机制以及压力对相图的影响。

Method: 采用射频磁化率测量和电子自旋共振(ESR)技术，结合高压实验和压力调谐的密度泛函理论(DFT)计算，分析温度-磁场相图随静水压力的变化。

Result: 实验证实了先前预测：主要交换相互作用通过V(IV)离子向连接两个自旋的氧原子提供显著自旋密度的非传统机制实现，该氧原子位于Cu(II)离子的Jahn-Teller轴上。ESR测量还发现二聚体单元中自旋的不相似性导致电子能级的非线性磁场依赖。

Conclusion: 该研究揭示了CuVOF₄(H₂O)₆·H₂O中Cu(II)-V(IV)自旋二聚体的独特交换机制，为理解不同自旋物种间的磁相互作用提供了重要见解。

Abstract: We investigate the properties of CuVOF$_4$(H$_2$O)$_6$$\cdot$H$_2$O, in which two different spin species, Cu(II) and V(IV), form antiferromagnetic spin-1/2 dimers with weak interdimer coupling provided via hydrogen bonding. Using radio-frequency susceptometry and electron-spin resonance (ESR), we show how the temperature-magnetic field spin-dimer phase diagram evolves as a function of applied hydrostatic pressure and correlate this with pressure-induced changes to the crystal structure. These results, coupled with pressure-tuned DFT calculations, confirm the prior prediction that the primary exchange interaction is mediated via an unusual mechanism in which the V(IV) ions provide considerable spin density to the oxygen that joins the two spins in each dimer and which lies along the Jahn-Teller axis of the Cu(II) ion. In addition, the dissimilarity in the spins that make up each dimer unit leads to a non-linear field dependence of the electronic energy levels as detected in the ESR measurements.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [132] [Chunking Strategies for Multimodal AI Systems](https://arxiv.org/abs/2512.00185)
*Shashanka B R,Mohith Charan R,Seema Banu F*

Main category: cs.AI

TL;DR: 这篇综述系统梳理了多模态分块策略的技术全景，为开发更高效的多模态AI系统提供技术基础和设计空间，涵盖文本、图像、音频、视频和跨模态数据的分块方法。


<details>
  <summary>Details</summary>
Motivation: 整合多模态分块策略的研究现状，为研究者和实践者提供技术基础，促进开发更有效和高效的多模态AI系统，解决实际应用中模态复杂性、处理准确性和生成连贯性的挑战。

Method: 采用系统性综述方法，建立全面的分类体系和技术分析框架，针对每种模态（文本、图像、音频、视频、跨模态数据）分别分析经典和现代分块策略，包括固定大小令牌窗口、递归文本分割、对象中心视觉分块、基于静音的音频分割、视频场景检测等方法。

Result: 提供了多模态分块策略的全面技术分析，比较了不同方法的优缺点，识别了粒度-上下文权衡、多模态对齐等关键挑战，并指出了异步信息密度、噪声对齐信号等开放问题。

Conclusion: 该综述为多模态AI系统的分块策略提供了系统性的技术基础，指出了未来研究方向，包括自适应、基于学习和任务特定的分块方法，为开发更鲁棒、可扩展的多模态处理管道铺平了道路。

Abstract: Our goal is to consolidate the landscape of multimodal chunking strategies, providing researchers and practitioners with a technical foundation and design space for developing more effective and efficient multimodal AI systems. This survey paves the way for innovations in robust chunking pipelines that scale with modality complexity, enhance processing accuracy, and improve generative coherence in real-world applications. This survey provides a comprehensive taxonomy and technical analysis of chunking strategies tailored for each modality: text, images, audio, video, and cross-modal data. We examine classical and modern approaches such as fixed-size token windowing, recursive text splitting, object-centric visual chunking, silence-based audio segmentation, and scene detection in videos. Each approach is analyzed in terms of its underlying methodology, supporting tools (e.g., LangChain, Detectron2, PySceneDetect), benefits, and challenges, particularly those related to granularity-context trade-offs and multimodal alignment. Furthermore, we explore emerging cross-modal chunking strategies that aim to preserve alignment and semantic consistency across disparate data types [4]. We also include comparative insights, highlight open problems such as asynchronous information density and noisy alignment signals, and identify opportunities for future research in adaptive, learning-based, and task-specific chunking.

</details>


### [133] [A Rosetta Stone for AI Benchmarks](https://arxiv.org/abs/2512.00193)
*Anson Ho,Jean-Stanislas Denain,David Atanasov,Samuel Albanie,Rohin Shah*

Main category: cs.AI

TL;DR: 该研究构建了一个统计框架，将不同AI基准测试统一到单一数值尺度上，解决了传统基准测试快速饱和、难以追踪长期AI能力趋势的问题。


<details>
  <summary>Details</summary>
Motivation: 大多数AI基准测试在推出后几年甚至几个月内就会饱和，这使得研究AI能力的长期趋势变得困难。需要一种能够跨时间、跨基准比较AI模型能力的方法。

Method: 构建了一个统计框架，将不同基准测试"缝合"在一起，将模型能力和基准难度放在单一数值尺度上，类似于"罗塞塔石碑"。该方法不假设能力随时间或训练计算量的演变方式。

Result: 框架成功实现了三个应用：1) 测量AI进展速度并预测未来能力；2) 估算算法效率改进率，发现高于但基本符合先前工作的估计；3) 能够检测AI进展的快速加速。

Conclusion: 该统计框架为解决AI基准测试快速饱和问题提供了有效方案，能够跨时间、跨基准比较AI模型，为研究长期AI能力趋势和进展预测提供了新工具。

Abstract: Most AI benchmarks saturate within years or even months after they are introduced, making it hard to study long-run trends in AI capabilities. To address this challenge, we build a statistical framework that stitches benchmarks together, putting model capabilities and benchmark difficulties on a single numerical scale. This acts as a "Rosetta Stone", allowing us to compare models across a wide range of abilities and time, even if they are not evaluated on the same benchmarks. Moreover, this works without assuming how capabilities evolve across time or with training compute. We demonstrate three applications of this framework. First, we use it to measure the speed of AI progress over time, and to forecast future AI capabilities. Second, we estimate the rate of improvements in algorithmic efficiency, finding estimates that are higher, but broadly consistent with prior work. Finally, we find that our approach can be used to detect rapid accelerations in AI progress.

</details>


### [134] [Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?](https://arxiv.org/abs/2512.00218)
*Matt MacDermott,Qiyao Wei,Rada Djoneva,Francis Rhys Ward*

Main category: cs.AI

TL;DR: 研究不同训练激励对AI推理模型可监控性的影响，发现对抗性优化会降低监控性能，而直接优化可监控性并不能可靠提升监控效果


<details>
  <summary>Details</summary>
Motivation: AI系统输出自然语言推理过程为安全监控提供了机会，但推理过程是否忠实反映底层思维过程可能受训练方式影响，需要研究不同训练激励如何影响模型的可监控性

Method: 引入新的方法论，通过监控器是否能使用模型的推理预测关键潜在变量来衡量可监控性；研究不同训练激励（长度惩罚、KL正则化、对抗性优化、直接优化可监控性）对监控性能的影响

Result: 在控制准确性的情况下，常见激励（长度惩罚和KL正则化）没有一致影响；对抗性优化会降低监控性能；直接优化可监控性并不能可靠地带来改进

Conclusion: 训练激励对AI推理模型的可监控性有重要影响，对抗性优化会损害监控能力，而直接优化可监控性并非可靠改进方法，这对AI安全监控策略有重要启示

Abstract: AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \emph{training incentives}, applied to a reasoning model, affect its monitorability. We introduce a novel methodology for measuring monitorability according to whether a monitor can predict a key latent variable using the model's reasoning. When controlling for accuracy, we do not find evidence for consistent effects from commonly used incentives (length penalties and KL regularisation), but we find that adversarial optimisation (penalising monitor accuracy) degrades monitor performance, while direct optimisation for monitorability does not reliably lead to improvements. Our code is available at https://github.com/QiyaoWei/reasoning-under-pressure.

</details>


### [135] [Trification: A Comprehensive Tree-based Strategy Planner and Structural Verification for Fact-Checking](https://arxiv.org/abs/2512.00267)
*Anab Maulana Barik,Shou Ziyi,Yang Kaiwen,Yang Qi,Shen Xin*

Main category: cs.AI

TL;DR: 提出Trification框架，通过生成全面验证动作并构建依赖图来提升自动事实核查的准确性和逻辑性


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查系统存在两个主要问题：1）无法全面验证声明的每个组成部分；2）缺乏结构化框架来逻辑连接子任务结果。随着虚假信息快速传播，需要更有效的自动化事实核查系统来维护在线媒体生态系统的安全性和完整性。

Method: 提出Trification框架：1）生成全面的验证动作集以确保对声明的完整覆盖；2）将这些动作组织成依赖图以建模动作间的逻辑交互；3）支持动态修改图结构，使系统能够自适应调整验证策略。

Result: 在两个具有挑战性的基准测试上的实验结果表明，该框架显著提高了事实核查的准确性，从而推进了自动事实核查系统的当前最先进水平。

Conclusion: Trification框架通过结构化验证动作和依赖图建模，解决了现有事实核查系统的局限性，为自动事实核查提供了更有效的方法。

Abstract: Technological advancement allows information to be shared in just a single click, which has enabled the rapid spread of false information. This makes automated fact-checking system necessary to ensure the safety and integrity of our online media ecosystem. Previous methods have demonstrated the effectiveness of decomposing the claim into simpler sub-tasks and utilizing LLM-based multi agent system to execute them. However, those models faces two limitations: they often fail to verify every component in the claim and lack of structured framework to logically connect the results of sub-tasks for a final prediction. In this work, we propose a novel automated fact-checking framework called Trification. Our framework begins by generating a comprehensive set of verification actions to ensure complete coverage of the claim. It then structured these actions into a dependency graph to model the logical interaction between actions. Furthermore, the graph can be dynamically modified, allowing the system to adapt its verification strategy. Experimental results on two challenging benchmarks demonstrate that our framework significantly enhances fact-checking accuracy, thereby advancing current state-of-the-art in automated fact-checking system.

</details>


### [136] [ChartPoint: Guiding MLLMs with Grounding Reflection for Chart Reasoning](https://arxiv.org/abs/2512.00305)
*Zhengzhuo Xu,SiNan Du,Yiyan Qi,SiwenLu,Chengjin Xu,Chun Yuan,Jian Guo*

Main category: cs.AI

TL;DR: PointCoT通过结合视觉定位与思维链推理，解决MLLMs在图表理解中的数值幻觉问题，在ChartBench上提升5.04%


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs依赖OCR提取内容，在图表文本标注稀疏时会产生数值幻觉。现有方法专注于扩展指令，但未能解决视觉感知推理的根本挑战。研究发现MLLMs在图表元素和比例关系上定位能力弱，无法将关键位置与其推理相匹配。

Method: 提出PointCoT方法，将反射式交互集成到图表思维链推理中。通过提示MLLMs生成边界框和基于位置标注重新渲染图表，建立文本推理步骤与视觉定位区域之间的联系。构建ChartPoint-SFT-62k数据集，包含19.2K高质量图表样本，带有逐步思维链、边界框和重新渲染的可视化。基于此数据开发两个指令调优模型ChartPointQ2和ChartPointQ2.5。

Result: 开发的ChartPointQ2和ChartPointQ2.5模型在多个图表基准测试中优于最先进方法，如在ChartBench上提升5.04%。

Conclusion: PointCoT通过将视觉定位与思维链推理相结合，有效解决了MLLMs在图表理解中的数值幻觉问题，显著提升了图表理解性能。

Abstract: Multimodal Large Language Models (MLLMs) have emerged as powerful tools for chart comprehension. However, they heavily rely on extracted content via OCR, which leads to numerical hallucinations when chart textual annotations are sparse. While existing methods focus on scaling instructions, they fail to address the fundamental challenge, i.e., reasoning with visual perception. In this paper, we identify a critical observation: MLLMs exhibit weak grounding in chart elements and proportional relationships, as evidenced by their inability to localize key positions to match their reasoning. To bridge this gap, we propose PointCoT, which integrates reflective interaction into chain-of-thought reasoning in charts. By prompting MLLMs to generate bounding boxes and re-render charts based on location annotations, we establish connections between textual reasoning steps and visual grounding regions. We further introduce an automated pipeline to construct ChartPoint-SFT-62k, a dataset featuring 19.2K high-quality chart samples with step-by-step CoT, bounding box, and re-rendered visualizations. Leveraging this data, we develop two instruction-tuned models, ChartPointQ2 and ChartPointQ2.5, which outperform state-of-the-art across several chart benchmarks, e.g., +5.04\% on ChartBench.

</details>


### [137] [CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System](https://arxiv.org/abs/2512.00331)
*Yefeng Wu,Yuchen Song,Yecheng Zhao,Ling Wu,Shan Wan*

Main category: cs.AI

TL;DR: 论文提出CogEvo-Edu系统，通过分层多智能体架构将检索、记忆和控制作为耦合的认知演化过程，显著提升STEM教育中LLM对话导师在复杂领域（如数字信号处理）的教学效果。


<details>
  <summary>Details</summary>
Motivation: 当前STEM教育中部署的LLM对话导师大多依赖单一模型和静态检索增强生成管道，难以应对复杂领域（如数字信号处理）的挑战：需要维护连贯的长期学生模型、管理异构知识库以及在长期互动中自适应调整教学策略。

Method: 提出CogEvo-Edu分层教育多智能体系统，包含三个层次：认知感知层（维护双重记忆并进行置信度加权整合以构建结构化、自校正的学生档案）、知识演化层（为每个知识块分配时空价值以驱动激活、语义压缩和遗忘）、元控制层（将教学制定为分层顺序决策，协调专门智能体并通过双重内外循环联合调整前两层的超参数）。

Result: 构建DSP-EduBench垂直基准测试，使用三模型LLM-as-a-Judge集成评估。CogEvo-Edu将总体得分从5.32提升至9.23，在六个指标上均优于静态RAG、简单记忆和单智能体变体，证明了联合演化学生档案、知识库和教学策略的价值。

Conclusion: 将检索、记忆和控制视为耦合的认知演化过程是有效的，CogEvo-Edu系统通过分层多智能体架构显著提升了复杂STEM领域（如数字信号处理）中LLM对话导师的教学效果。

Abstract: Large language models (LLMs) are increasingly deployed as conversational tutors in STEM education, yet most systems still rely on a single LLM with a static retrieval-augmented generation (RAG) pipeline over course materials. This design struggles in complex domains such as digital signal processing (DSP), where tutors must maintain coherent long-term student models, manage heterogeneous knowledge bases, and adapt teaching strategies over extended interactions. We argue that retrieval, memory, and control should be treated as a coupled cognitive evolution process. We instantiate this view in CogEvo-Edu, a hierarchical educational multi-agent system comprising a Cognitive Perception Layer (CPL), a Knowledge Evolution Layer (KEL), and a Meta-Control Layer (MCL). CPL maintains dual memories and performs confidence-weighted consolidation to build structured, self-correcting student profiles under limited context. KEL assigns each knowledge chunk a spatiotemporal value that drives activation, semantic compression, and forgetting. MCL formulates tutoring as hierarchical sequential decision making, orchestrating specialized agents and jointly adapting CPL/KEL hyperparameters via a dual inner--outer loop. To evaluate CogEvo-Edu, we construct DSP-EduBench, a vertical benchmark for DSP tutoring with heterogeneous resources, simulated student profiles, and long-horizon interaction scripts. Using a three-model LLM-as-a-Judge ensemble, CogEvo-Edu raises the overall score from 5.32 to 9.23 and improves all six indicators over static RAG, simple memory, and a single-agent variant, demonstrating the value of jointly evolving student profiles, knowledge bases, and teaching policies.

</details>


### [138] [Echo-N1: Affective RL Frontier](https://arxiv.org/abs/2512.00344)
*Naifan Zhang,Ruihan Sun,Ruixi Su,Shiqi Ma,Shiya Zhang,Xianna Weng,Xiaofan Zhang,Yuhan Zhan,Yuyang Xu,Zhaohan Chen,Zhengyuan Pan,Ziyi Song*

Main category: cs.AI

TL;DR: 论文提出首个基于强化学习的个性化对话框架，通过实时推断用户个性来优化对话行为，在主观情感对话领域取得突破性进展。


<details>
  <summary>Details</summary>
Motivation: 当前LLM领域过度关注数学、代码等确定性推理任务，而忽略了真正定义人类智能的主观、情感化、个性敏感的对话领域。这一领域常被认为过于主观难以形式化，不适合传统RL方法。

Method: 提出首个实时推断用户个性并优化模型行为以适应个性化对话偏好的框架。引入动态情商评估套件来量化改进效果。模型名为Echo-N1。

Result: 方法在非可验证环境中产生一致、稳健且显著的类人交互质量改进。Echo-N1表现远超其基础版本，并优于专有模型Doubao 1.5 Character。

Conclusion: 这项工作为RL开辟了新前沿：为对话中深刻主观、深刻人性化的维度优化模型，证明主观情感对话领域是可解决且具有变革性的RL问题。

Abstract: The LLM field has spent a year perfecting RL for tasks machines already excel at, math, code, and deterministic reasoning, while completely sidestepping the domain that actually defines human intelligence: subjective, emotionally grounded, personality sensitive conversation. This space has often been regarded as inherently subjective and challenging to formalize, making it appear unsuitable for conventional RL pipelines. We show that it is not only possible and it is a solvable and transformative RL problem. We propose the first framework that infers user personality on the fly and optimizes model behavior toward personalized conversational preferences. Contrary to the widespread belief that RL collapses in non-verifiable settings, our method produces consistent, robust, and dramatic improvements in humanlike interaction quality. We also introduce the first dynamic emotional intelligence evaluation suite to quantify these gains. Our model, which is introduced as Echo-N1, behaves far above its base version and outperforming the proprietary Doubao 1.5 Character. This work establishes a new frontier for RL: optimizing models for the deeply subjective, deeply human dimensions of conversation.

</details>


### [139] [Debate with Images: Detecting Deceptive Behaviors in Multimodal Large Language Models](https://arxiv.org/abs/2512.00349)
*Sitong Fang,Shiyi Hou,Kaile Wang,Boyuan Chen,Donghai Hong,Jiayi Zhou,Josef Dai,Yaodong Yang,Jiaming Ji*

Main category: cs.AI

TL;DR: 该论文揭示了前沿AI系统在能力提升的同时，隐藏着更危险的欺骗性风险，特别是多模态欺骗。作者创建了首个多模态欺骗基准MM-DeceptionBench，并提出了基于图像辩论的多智能体监控框架来检测这类欺骗行为。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统能力增强，欺骗行为从文本扩展到多模态领域，带来了更隐蔽和破坏性的安全风险。当前研究主要集中在文本欺骗，对多模态大语言模型的欺骗风险缺乏系统探索和有效监控方法。

Method: 1. 创建MM-DeceptionBench基准，涵盖六类欺骗行为，评估模型通过视觉和文本模态进行策略性操纵和误导的能力；2. 提出"基于图像辩论"的多智能体辩论监控框架，通过强制模型基于视觉证据进行辩论，提高欺骗策略的可检测性。

Result: 实验表明，提出的辩论监控方法在所有测试模型中都显著提高了与人类判断的一致性，在GPT-4o上将Cohen's kappa提高了1.5倍，准确率提高了1.25倍。该方法有效解决了多模态欺骗的隐蔽性问题。

Conclusion: 多模态欺骗是AI安全领域的重要威胁，需要专门的评估基准和监控方法。论文提出的MM-DeceptionBench和辩论监控框架为检测和缓解多模态欺骗风险提供了有效工具，强调了在AI能力提升的同时必须加强安全监控的重要性。

Abstract: Are frontier AI systems becoming more capable? Certainly. Yet such progress is not an unalloyed blessing but rather a Trojan horse: behind their performance leaps lie more insidious and destructive safety risks, namely deception. Unlike hallucination, which arises from insufficient capability and leads to mistakes, deception represents a deeper threat in which models deliberately mislead users through complex reasoning and insincere responses. As system capabilities advance, deceptive behaviours have spread from textual to multimodal settings, amplifying their potential harm. First and foremost, how can we monitor these covert multimodal deceptive behaviors? Nevertheless, current research remains almost entirely confined to text, leaving the deceptive risks of multimodal large language models unexplored. In this work, we systematically reveal and quantify multimodal deception risks, introducing MM-DeceptionBench, the first benchmark explicitly designed to evaluate multimodal deception. Covering six categories of deception, MM-DeceptionBench characterizes how models strategically manipulate and mislead through combined visual and textual modalities. On the other hand, multimodal deception evaluation is almost a blind spot in existing methods. Its stealth, compounded by visual-semantic ambiguity and the complexity of cross-modal reasoning, renders action monitoring and chain-of-thought monitoring largely ineffective. To tackle this challenge, we propose debate with images, a novel multi-agent debate monitor framework. By compelling models to ground their claims in visual evidence, this method substantially improves the detectability of deceptive strategies. Experiments show that it consistently increases agreement with human judgements across all tested models, boosting Cohen's kappa by 1.5x and accuracy by 1.25x on GPT-4o.

</details>


### [140] [GreenPlanner: Practical Floorplan Layout Generation via an Energy-Aware and Function-Feasible Generative Framework](https://arxiv.org/abs/2512.00406)
*Pengyu Zeng,Yuqin Dai,Jun Yin,Jing Zhong,Ziyang Han,Chaoyang Shi,ZhanXiang Jin,Maowei Jiang,Yuxing Han,Shuai Lu*

Main category: cs.AI

TL;DR: GreenPlanner是一个能源和功能感知的生成框架，统一了设计评估和生成，通过自动化评估和生成符合规范的平面图，显著提高设计效率。


<details>
  <summary>Details</summary>
Motivation: 建筑设计直接影响人类福祉和碳排放，但生成空间功能和能源合规的平面图仍然是手动、昂贵且不可扩展的。现有方法产生视觉上合理的布局，但经常违反关键约束，由于缺乏自动化评估而产生无效结果。

Method: GreenPlanner框架包含：1) 用于学习约束先验的标记设计可行性数据集；2) 用于预测能源性能和空间功能有效性的快速实用设计评估器(PDE)；3) 通过PDE引导过滤得到的绿色平面数据集(GreenPD)，将用户需求与规范合规布局配对；4) 在GreenPD上训练并使用PDE反馈的GreenFlow生成器，实现可控、规范感知的生成。

Result: 实验表明，GreenPlanner将评估速度提高了超过10^5倍，准确率超过99%，消除了无效样本，设计效率比专业建筑师提高了87%。

Conclusion: GreenPlanner通过统一设计评估和生成，实现了自动化、高效且合规的建筑平面图设计，解决了现有方法违反约束和缺乏自动评估的问题。

Abstract: Building design directly affects human well-being and carbon emissions, yet generating spatial-functional and energy-compliant floorplans remains manual, costly, and non-scalable. Existing methods produce visually plausible layouts but frequently violate key constraints, yielding invalid results due to the absence of automated evaluation. We present GreenPlanner, an energy- and functionality-aware generative framework that unifies design evaluation and generation. It consists of a labeled Design Feasibility Dataset for learning constraint priors; a fast Practical Design Evaluator (PDE) for predicting energy performance and spatial-functional validity; a Green Plan Dataset (GreenPD) derived from PDE-guided filtering to pair user requirements with regulation-compliant layouts; and a GreenFlow generator trained on GreenPD with PDE feedback for controllable, regulation-aware generation. Experiments show that GreenPlanner accelerates evaluation by over $10^{5}\times$ with $>$99% accuracy, eliminates invalid samples, and boosts design efficiency by 87% over professional architects.

</details>


### [141] [Mind the data gap: Missingness Still Shapes Large Language Model Prognoses](https://arxiv.org/abs/2512.00479)
*Yuta Kobayashi,Vincent Jeanselme,Shalmali Joshi*

Main category: cs.AI

TL;DR: 该研究探讨了数据缺失模式对大型语言模型（LLMs）零样本预测性能的影响，发现缺失指示符的显式包含对不同规模的LLMs产生不一致影响，大模型受益而小模型可能受损。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量关于缺失信息价值的研究，但数据缺失模式对大型语言模型性能的影响尚未被充分探索。在医疗等实际应用中，数据收集过程反映了人类决策，这种缺失模式可能对LLMs的预测性能产生重要影响。

Method: 研究通过在哥伦比亚大学医学中心（大型城市学术医疗中心）和MIMIC-IV数据集上进行一系列实验，分析缺失模式对LLMs零样本预测性能的影响。特别考察了在提示中显式包含缺失指示符对不同规模LLMs的影响。

Result: 实验表明：1）缺失模式显著影响零样本预测性能；2）显式包含缺失指示符对某些LLMs有益，但对其他LLMs的预测性能和校准产生负面影响；3）聚合分析和理论洞察表明，较大模型从这些干预中受益，而较小模型可能受到负面影响。

Conclusion: LLM范式可能进一步掩盖缺失信息的影响（即使在传统机器学习中也常被忽视）。需要更透明的记录和系统评估表示（信息性）缺失对下游性能的影响。

Abstract: Data collection often reflects human decisions. In healthcare, for instance, a referral for a diagnostic test is influenced by the patient's health, their preferences, available resources, and the practitioner's recommendations. Despite the extensive literature on the informativeness of missingness, its implications on the performance of Large Language Models (LLMs) have not been studied. Through a series of experiments on data from Columbia University Medical Center, a large urban academic medical center, and MIMIC-IV, we demonstrate that patterns of missingness significantly impact zero-shot predictive performance. Notably, the explicit inclusion of missingness indicators at prompting benefits some while hurting other LLMs' zero-shot predictive performance and calibration, suggesting an inconsistent impact. The proposed aggregated analysis and theoretical insights suggest that larger models benefit from these interventions, while smaller models can be negatively impacted. The LLM paradigm risks obscuring the impact of missingness, often neglected even in conventional ML, even further. We conclude that there is a need for more transparent accounting and systematic evaluation of the impact of representing (informative) missingness on downstream performance.

</details>


### [142] [Clinical-R1: Empowering Large Language Models for Faithful and Comprehensive Reasoning with Clinical Objective Relative Policy Optimization](https://arxiv.org/abs/2512.00601)
*Boyang Gu,Hongjian Zhou,Bradley Max Segal,Jinge Wu,Zeyu Cao,Hantao Zhong,Lei Clifton,Fenglin Liu,David A. Clifton*

Main category: cs.AI

TL;DR: CRPO是一种针对临床推理的多目标可验证强化学习方法，通过整合基于规则和可验证的奖励信号，在保持准确性的同时提升真实性和完整性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM后训练方法（如GRPO）主要奖励正确性，这与医学等高风险领域需要多维度目标（如忠实性和全面性）不匹配，需要开发能同时优化准确性、忠实性和全面性的方法。

Method: 提出临床目标相对策略优化（CRPO），一种可扩展的多目标可验证强化学习方法，整合基于规则和可验证的奖励信号，无需人工标注，联合优化准确性、忠实性和全面性。

Result: 训练了3B参数的Clinical-R1-3B模型，在三个基准测试中，CRPO相比标准GRPO在真实性和完整性方面显著提升，同时保持准确性增强。

Conclusion: CRPO为LLM推理与临床目标对齐提供了可扩展路径，使医疗AI系统更安全、更具协作性，同时展示了多目标可验证RL方法在医学领域LLM后训练中的潜力。

Abstract: Recent advances in large language models (LLMs) have shown strong reasoning capabilities through large-scale pretraining and post-training reinforcement learning, demonstrated by DeepSeek-R1. However, current post-training methods, such as Grouped Relative Policy Optimization (GRPO), mainly reward correctness, which is not aligned with the multi-dimensional objectives required in high-stakes fields such as medicine, where reasoning must also be faithful and comprehensive. We introduce Clinical-Objective Relative Policy Optimization (CRPO), a scalable, multi-objective, verifiable reinforcement learning method designed to align LLM post-training with clinical reasoning principles. CRPO integrates rule-based and verifiable reward signals that jointly optimize accuracy, faithfulness, and comprehensiveness without relying on human annotation. To demonstrate its effectiveness, we train Clinical-R1-3B, a 3B-parameter model for clinical reasoning. The experiments on three benchmarks demonstrate that our CRPO substantially improves reasoning on truthfulness and completeness over standard GRPO while maintaining comfortable accuracy enhancements. This framework provides a scalable pathway to align LLM reasoning with clinical objectives, enabling safer and more collaborative AI systems for healthcare while also highlighting the potential of multi-objective, verifiable RL methods in post-training scaling of LLMs for medical domains.

</details>


### [143] [EDIT: Early Diffusion Inference Termination for dLLMs Based on Dynamics of Training Gradients](https://arxiv.org/abs/2512.00670)
*He-Yen Hsieh,Hong Wang,H. T. Kung*

Main category: cs.AI

TL;DR: EDIT方法通过监测推理稳定性来自适应提前终止扩散模型的去噪过程，利用训练时梯度动态信息减少推理步骤11.8%-68.3%，存储开销仅0.02%


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型通过迭代去噪生成答案，但答案通常在完成所有步骤前就已稳定。现有方法在模型发布时丢弃了训练过程中产生的丰富元数据，特别是关于参数重要性的优化动态信息。

Method: 提出EDIT方法：1) 在监督微调期间捕获AdamW聚合的LoRA更新，构建推理路径的紧凑表示；2) 推理时监测token激活与推理图的对齐度；3) 将对齐分数转换为当前去噪步骤已解掩码token的分布；4) 当连续步骤间KL散度低于阈值时检测收敛并提前终止。

Result: 在多个推理基准测试中，EDIT将扩散步骤减少11.8%至68.3%，同时在大多数情况下保持或提高了准确性。存储开销约为0.02%（对于8GB模型的所有QKV模块约1.5-2MB）。

Conclusion: 通过利用训练梯度动态，EDIT为减少扩散大语言模型的推理时间和成本开辟了新的研究方向，实现了高效的推理时间自适应终止机制。

Abstract: Diffusion-based large language models (dLLMs) refine token generations through iterative denoising, but answers often stabilize before all steps complete. We propose EDIT (Early Diffusion Inference Termination), an inference-time criterion that adaptively stops denoising once sufficient reasoning stability relative to training-time reasoning is detected. EDIT monitors the alignment between token activations and a reasoning map derived from AdamW-aggregated LoRA updates captured during supervised fine-tuning (SFT). During training, optimization dynamics generate rich metadata about parameter importance that in prior methods is typically discarded upon model release. We preserve this information as a compact representation of learned reasoning pathways. During inference, alignment scores are converted to a distribution over the tokens already unmasked at the current denoising step, and convergence is detected when KL divergence between consecutive steps falls below a threshold on the matched unmasked (visible) tokens. Across reasoning benchmarks, EDIT reduces diffusion steps by 11.8% to 68.3% while preserving or improving accuracy in most settings, with approximately 0.02% storage overhead (about 1.5-2 MB for all QKV modules across 32 blocks in an 8 GB model). By utilizing training-gradient dynamics, our work opens a new research direction for reducing dLLM inference time and cost.

</details>


### [144] [Model of human cognition](https://arxiv.org/abs/2512.00683)
*Wu Yonggang*

Main category: cs.AI

TL;DR: 提出一种神经理论框架，解释智能在系统中的涌现，该框架既功能鲁棒又生物合理，为认知过程提供理论洞见，并为创建可解释、可泛化的人工智能提供计算高效方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展受到缺乏可解释性、缺乏统一理论以及高昂运营成本的限制。为了解决这些问题，需要一种既能解释智能涌现机制，又具有生物合理性的理论框架。

Method: 提出一种神经理论框架，该框架基于生物合理的神经机制，解释智能在系统中的涌现过程。该模型为决策制定和问题解决等认知过程提供理论解释，并采用计算高效的方法。

Result: 该框架为理解智能涌现提供了理论洞见，同时提供了一种创建可解释、可泛化人工智能的计算高效方法，解决了当前LLM在可解释性、理论统一性和成本方面的问题。

Conclusion: 提出的神经理论框架为智能系统的涌现提供了既功能鲁棒又生物合理的解释，为开发可解释、可泛化且计算高效的人工智能系统提供了理论基础和方法路径。

Abstract: The development of large language models (LLMs) is limited by a lack of explainability, the absence of a unifying theory, and prohibitive operational costs. We propose a neuro-theoretical framework for the emergence of intelligence in systems that is both functionally robust and biologically plausible. The model provides theoretical insights into cognitive processes such as decision-making and problem solving, and a computationally efficient approach for the creation of explainable and generalizable artificial intelligence.

</details>


### [145] [SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs](https://arxiv.org/abs/2512.00722)
*Jiaming Xu,Jiayi Pan,Hanzhen Wang,Yongkang Zhou,Jiancai Ye,Yu Wang,Guohao Dai*

Main category: cs.AI

TL;DR: SpeContext：利用蒸馏语言模型作为检索算法，通过算法-系统-编译协同设计实现长上下文推理加速，在云和边缘环境中分别实现24.89倍和10.06倍吞吐量提升


<details>
  <summary>Details</summary>
Motivation: 传统检索算法目标与LLM对齐，这与LLM知识蒸馏的目标相似。从信息论角度分析蒸馏语言模型与原始LLM在信息关注上的相似性，提出利用DLM作为检索算法的新范式，以解决长上下文推理的效率问题。

Method: 1. 算法层面：基于DLM的注意力头权重设计轻量级检索头，通过剪枝冗余实现>90%参数减少；2. 系统层面：通过弹性加载策略设计异步预取数据流，重叠KV缓存检索与LLM计算；3. 编译层面：构建理论内存模型并实现自适应内存管理系统，最大化GPU内存利用率。

Result: 在云和边缘两种资源受限环境中部署评估，相比Huggingface框架，SpeContext在云端实现最高24.89倍吞吐量提升，边缘端实现10.06倍加速，准确率损失可忽略，推进了准确率与吞吐量的帕累托前沿。

Conclusion: SpeContext通过算法-系统-编译协同设计，成功利用蒸馏语言模型作为高效检索算法，在保持准确率的同时显著提升长上下文推理性能，为资源受限环境中的LLM部署提供了有效解决方案。

Abstract: In this paper, we point out that the objective of the retrieval algorithms is to align with the LLM, which is similar to the objective of knowledge distillation in LLMs. We analyze the similarity in information focus between the distilled language model(DLM) and the original LLM from the perspective of information theory, and thus propose a novel paradigm that leverages a DLM as the retrieval algorithm. Based on the insight, we present SpeContext, an algorithm and system co-design for long-context reasoning. (1) At the algorithm level, SpeContext proposes lightweight retrieval head based on the head-level attention weights of DLM, achieving > 90% parameters reduction by pruning the redundancy. (2) At the system level, SpeContext designs an asynchronous prefetch dataflow via the elastic loading strategy, effectively overlapping KV cache retrieval with the LLM computation. (3) At the compilation level, SpeContext constructs the theoretical memory model and implements an adaptive memory management system to achieve acceleration by maximizing GPU memory utilization. We deploy and evaluate SpeContext in two resourceconstrained environments, cloud and edge. Extensive experiments show that, compared with the Huggingface framework, SpeContext achieves up to 24.89x throughput improvement in cloud and 10.06x speedup in edge with negligible accuracy loss, pushing the Pareto frontier of accuracy and throughput.

</details>


### [146] [Probing the "Psyche'' of Large Reasoning Models: Understanding Through a Human Lens](https://arxiv.org/abs/2512.00729)
*Yuxiang Chen,Zuohan Wu,Ziwei Wang,Xiangning Yu,Xujia Li,Linyi Yang,Mengyue Yang,Jun Wang,Lei Chen*

Main category: cs.AI

TL;DR: 该论文提出了一个基于人类心智过程的分类法来理解大型推理模型（LRMs）的"心理"，开发了自动标注框架CAPO，并基于对277,534个原子推理步骤的分析揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂任务中展现出类人推理能力，但缺乏系统化的理解框架。研究者希望从人类认知角度建立分类法，深入探究LRMs的推理"心理"机制。

Method: 1. 基于人类心智过程构建包含5组17类的分类法；2. 应用该分类法创建包含277,534个原子推理步骤的标注数据集；3. 开发自动标注框架CAPO，利用大语言模型生成分类法标注；4. 分析当代LRMs的推理模式。

Result: 1. CAPO框架在标注一致性上优于基线方法；2. 分析发现当前模型的"双重检查"（自我监控评估）大多流于表面，很少产生实质性修订；3. 揭示了激励多步反思比简单自我监控更有效；4. 为改进推理模型的训练和后训练提供了可操作的见解。

Conclusion: 该研究提供了从人类认知角度理解和推进LRM推理的原则性、可扩展路径，分类法、CAPO框架和洞察共同构成了系统分析LRMs的基础工具集。

Abstract: Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.

</details>


### [147] [BioPro: On Difference-Aware Gender Fairness for Vision-Language Models](https://arxiv.org/abs/2512.00807)
*Yujie Lin,Jiayao Ma,Qingguo Hu,Derek F. Wong,Jinsong Su*

Main category: cs.AI

TL;DR: BioPro是一个无需训练的多模态去偏框架，通过识别性别变化子空间并选择性投影，在需要中性的场景减少性别偏见，在明确场景保留性别特征。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的公平性干预通常采用"差异无视"视角，对所有人口统计群体实施统一处理。这种方法无法区分需要中性的场景和需要保留群体特定属性的场景，导致过度泛化或不足。

Method: 提出BioPro（Bias Orthogonal Projection）框架：1）通过反事实嵌入识别低维性别变化子空间；2）应用投影选择性中和性别相关信息；3）完全无需训练，可扩展到连续偏差变量如场景亮度。

Result: 实验表明BioPro在需要中性的情况下有效减少性别偏见，在明确场景中保持性别忠实性，为VLMs实现选择性公平提供了有前景的方向。还能有效推广到连续偏差变量。

Conclusion: BioPro通过差异感知的公平性方法，在视觉语言模型中实现了选择性去偏，平衡了中性场景的去偏需求和明确场景的特征保留，具有更广泛的适用性。

Abstract: Vision-Language Models (VLMs) inherit significant social biases from their training data, notably in gender representation. Current fairness interventions often adopt a difference-unaware perspective that enforces uniform treatment across demographic groups. These approaches, however, fail to distinguish between contexts where neutrality is required and those where group-specific attributes are legitimate and must be preserved. Building upon recent advances in difference-aware fairness for text-only models, we extend this concept to the multimodal domain and formalize the problem of difference-aware gender fairness for image captioning and text-to-image generation. We advocate for selective debiasing, which aims to mitigate unwanted bias in neutral contexts while preserving valid distinctions in explicit ones. To achieve this, we propose BioPro (Bias Orthogonal Projection), an entirely training-free framework. BioPro identifies a low-dimensional gender-variation subspace through counterfactual embeddings and applies projection to selectively neutralize gender-related information. Experiments show that BioPro effectively reduces gender bias in neutral cases while maintaining gender faithfulness in explicit ones, thus providing a promising direction toward achieving selective fairness in VLMs. Beyond gender bias, we further demonstrate that BioPro can effectively generalize to continuous bias variables, such as scene brightness, highlighting its broader applicability.

</details>


### [148] [Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning](https://arxiv.org/abs/2512.00818)
*Haozhen Gong,Xiaozhong Ji,Yuansen Liu,Wenbin Wu,Xiaoxiao Yan,Jingjing Liu,Kai Wu,Jiazhen Pan,Bailiang Jian,Jiangning Zhang,Xiaobin Hu,Hongwei Bran Li*

Main category: cs.AI

TL;DR: Med-CMR是一个细粒度的医学复杂多模态推理基准，用于评估MLLMs在临床工作流程中的复杂医学推理能力，包含20,653个VQA对，涵盖11个器官系统和12种成像模态。


<details>
  <summary>Details</summary>
Motivation: MLLMs开始出现在临床工作流程中，但其执行复杂医学推理的能力尚不清楚，需要建立一个能够系统评估医学多模态推理能力的基准。

Method: 1) 系统能力分解：将医学多模态推理分解为细粒度的视觉理解和多步推理；2) 挑战性任务设计：视觉理解涵盖三个关键维度（小物体检测、细节辨别、空间理解），推理涵盖四个临床相关场景（时间预测、因果推理、长尾泛化、多源整合）；3) 广泛高质量数据覆盖：包含20,653个VQA对，经过两阶段（人类专家+模型辅助）严格审查。

Result: 评估了18个最先进的MLLMs，GPT-5表现最佳：多选题准确率57.81%，开放式问题得分48.70%，优于Gemini 2.5 Pro和开源模型Qwen3-VL-235B-A22B。专业医学MLLMs并未可靠地优于强大的通用模型，长尾泛化成为主要失败模式。

Conclusion: Med-CMR为医学MLLMs的视觉-推理整合和罕见病例鲁棒性提供了压力测试，并为未来临床系统提供了严格的衡量标准。

Abstract: MLLMs MLLMs are beginning to appear in clinical workflows, but their ability to perform complex medical reasoning remains unclear. We present Med-CMR, a fine-grained Medical Complex Multimodal Reasoning benchmark. Med-CMR distinguishes from existing counterparts by three core features: 1) Systematic capability decomposition, splitting medical multimodal reasoning into fine-grained visual understanding and multi-step reasoning to enable targeted evaluation; 2) Challenging task design, with visual understanding across three key dimensions (small-object detection, fine-detail discrimination, spatial understanding) and reasoning covering four clinically relevant scenarios (temporal prediction, causal reasoning, long-tail generalization, multi-source integration); 3) Broad, high-quality data coverage, comprising 20,653 Visual Question Answering (VQA) pairs spanning 11 organ systems and 12 imaging modalities, validated via a rigorous two-stage (human expert + model-assisted) review to ensure clinical authenticity. We evaluate 18 state-of-the-art MLLMs with Med-CMR, revealing GPT-5 as the top-performing commercial model: 57.81 accuracy on multiple-choice questions (MCQs) and a 48.70 open-ended score, outperforming Gemini 2.5 Pro (49.87 MCQ accuracy, 45.98 open-ended score) and leading open-source model Qwen3-VL-235B-A22B (49.34 MCQ accuracy, 42.62 open-ended score). However, specialized medical MLLMs do not reliably outperform strong general models, and long-tail generalization emerges as the dominant failure mode. Med-CMR thus provides a stress test for visual-reasoning integration and rare-case robustness in medical MLLMs, and a rigorous yardstick for future clinical systems.

</details>


### [149] [Assessing model error in counterfactual worlds](https://arxiv.org/abs/2512.00836)
*Emily Howerton,Justin Lessler*

Main category: cs.AI

TL;DR: 论文提出三种评估反事实场景建模中模型误差的方法，强调模型校准误差比场景偏差更重要，为决策提供更可靠评估


<details>
  <summary>Details</summary>
Motivation: 反事实场景建模在规划和决策中广泛应用，但很少进行回顾性评估。预测与观测的差异来自场景偏差和模型校准误差，后者对评估模型在决策中的价值更为重要，但需要在反事实世界中估计模型误差

Method: 提出并对比三种估计反事实误差的方法，通过模拟实验展示每种方法的优缺点，提供反事实误差估计的建议

Result: 通过模拟实验验证了三种方法的有效性，分析了各自的优势和局限性，为反事实误差估计提供了实用指导

Conclusion: 模型校准误差比场景偏差对决策评估更重要，需要专门方法在反事实世界中估计模型误差，同时讨论了使场景预测可评估所需的设计要素

Abstract: Counterfactual scenario modeling exercises that ask "what would happen if?" are one of the most common ways we plan for the future. Despite their ubiquity in planning and decision making, scenario projections are rarely evaluated retrospectively. Differences between projections and observations come from two sources: scenario deviation and model miscalibration. We argue the latter is most important for assessing the value of models in decision making, but requires estimating model error in counterfactual worlds. Here we present and contrast three approaches for estimating this error, and demonstrate the benefits and limitations of each in a simulation experiment. We provide recommendations for the estimation of counterfactual error and discuss the components of scenario design that are required to make scenario projections evaluable.

</details>


### [150] [ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI](https://arxiv.org/abs/2512.00839)
*Fabrizio Maturo,Donato Riccio,Andrea Mazzitelli,Giuseppe Bifulco,Francesco Paolone,Iulia Brezeanu*

Main category: cs.AI

TL;DR: ARCADIA是一个用于因果发现的智能AI框架，结合大语言模型推理与统计诊断，通过迭代优化构建有效、时间一致的因果结构，在现实高风险领域表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现算法在现实高风险领域（如企业破产预测）中可能产生不稳定或不合理的因果结构，需要更可靠、可解释且能处理时间一致性的因果建模方法。

Method: ARCADIA框架整合大语言模型推理与统计诊断，通过约束引导提示和因果有效性反馈迭代优化候选有向无环图（DAGs），构建稳定且可解释的因果模型。

Result: 在企业破产数据实验中，ARCADIA比NOTEARS、GOLEM和DirectLiNGAM产生更可靠的因果图，并提供完全可解释、支持干预的完整流程。

Conclusion: ARCADIA框架展示了智能大语言模型如何参与自主科学建模和结构化因果推断，推动了AI在因果发现领域的发展，为高风险决策提供了可靠工具。

Abstract: This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.

</details>


### [151] [One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces](https://arxiv.org/abs/2512.00852)
*Yandong Sun,Qiang Huang,Ziwei Xu,Yiqun Sun,Yixuan Tang,Anthony K. H. Tung*

Main category: cs.AI

TL;DR: 本文提出了语义场子空间（SFS）和SAFARI算法，用于在嵌入空间中捕捉局部语义邻域并发现层次化语义结构，通过高效的语义偏移近似实现15-30倍加速。


<details>
  <summary>Details</summary>
Motivation: 嵌入空间是现代AI的基础，但现有方法要么牺牲语义连贯性追求结构规律性，要么为提升可解释性而计算成本过高。需要一种既能保持几何结构又能捕捉局部语义邻域的方法。

Method: 1. 提出语义场子空间（SFS）：一种保持几何结构、上下文感知的表示方法，捕捉嵌入空间中的局部语义邻域。2. 提出SAFARI算法：无监督、模态无关的算法，使用新颖的"语义偏移"度量来发现层次化语义结构。3. 开发高效的语义偏移近似方法：替代昂贵的SVD计算，实现15-30倍加速，平均误差低于0.01。

Result: 在六个真实世界文本和图像数据集上的广泛评估显示：1. SFS在分类任务上优于标准分类器；2. 在政治偏见检测等精细任务中表现优异；3. SAFARI始终能发现可解释且可泛化的语义层次结构。

Conclusion: 该工作为嵌入空间中的结构化、分析和扩展语义理解提供了一个统一框架，解决了现有方法在语义连贯性、计算效率和可解释性之间的权衡问题。

Abstract: Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.

</details>


### [152] [Hybrid-DMKG: A Hybrid Reasoning Framework over Dynamic Multimodal Knowledge Graphs for Multimodal Multihop QA with Knowledge Editing](https://arxiv.org/abs/2512.00881)
*Li Yuan,Qingfei Huang,Bingshan Zhu,Yi Cai,Qingbao Huang,Changmeng Zheng,Zikun Deng,Tao Wang*

Main category: cs.AI

TL;DR: 该论文提出了MMQAKE基准测试和Hybrid-DMKG框架，用于评估和改进多模态知识编辑中的多跳推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态知识编辑(MKE)基准主要评估最终答案正确性，但忽略了中间推理质量和视觉重述输入的鲁棒性。需要一个新的基准来评估多模态多跳问答中的知识编辑能力。

Method: 提出了Hybrid-DMKG混合推理框架：1)使用大语言模型分解多模态多跳问题为子问题；2)使用多模态检索模型定位更新的事实；3)通过关系链接预测和RAG推理两条并行路径进行推理；4)决策模块聚合证据选择最可信答案。

Result: 在MMQAKE基准上的实验结果显示，Hybrid-DMKG显著优于现有MKE方法，实现了更高的准确性和对知识更新的更好鲁棒性。

Conclusion: MMQAKE基准填补了多模态知识编辑评估的空白，Hybrid-DMKG框架通过动态多模态知识图和混合推理机制，有效提升了多模态多跳问答中的知识编辑和推理能力。

Abstract: Multimodal Knowledge Editing (MKE) extends traditional knowledge editing to settings involving both textual and visual modalities. However, existing MKE benchmarks primarily assess final answer correctness while neglecting the quality of intermediate reasoning and robustness to visually rephrased inputs. To address this limitation, we introduce MMQAKE, the first benchmark for multimodal multihop question answering with knowledge editing. MMQAKE evaluates (1) a model's ability to reason over 2-5-hop factual chains that span both text and images, including performance at each intermediate step, and (2) robustness to visually rephrased inputs in multihop questions. Our evaluation shows that current MKE methods often struggle to consistently update and reason over multimodal reasoning chains after knowledge edits. To overcome these challenges, we propose Hybrid-DMKG, a hybrid reasoning framework built on a dynamic multimodal knowledge graph (DMKG) to enable accurate multihop reasoning over updated multimodal knowledge. Hybrid-DMKG first uses a large language model to decompose multimodal multihop questions into sequential sub-questions, then applies a multimodal retrieval model to locate updated facts by jointly encoding each sub-question with candidate entities and their associated images. For answer inference, a hybrid reasoning module operates over the DMKG via two parallel paths: (1) relation linking prediction, and (2) RAG reasoning with large vision-language models. A decision module aggregates evidence from both paths to select the most credible answer. Experimental results on MMQAKE show that Hybrid-DMKG significantly outperforms existing MKE approaches, achieving higher accuracy and improved robustness to knowledge updates.

</details>


### [153] [Integrating Causal Foundation Model in Prescriptive Maintenance Framework for Optimizing Production Line OEE](https://arxiv.org/abs/2512.00969)
*Felix Saretzky,Lucas Andersen,Thomas Engel,Fazel Ansari*

Main category: cs.AI

TL;DR: 本文提出基于因果机器学习的方法，从预测性维护转向规范性维护，通过因果基础模型模拟潜在修复措施对系统KPI的影响，为生产线提供数据驱动的行动推荐。


<details>
  <summary>Details</summary>
Motivation: 制造业向规范性维护转型受到预测模型的限制，这些模型依赖虚假相关性而非真正的故障因果驱动因素，导致误诊和无效干预。关键挑战在于：虽然能预测故障发生，但缺乏系统方法来理解故障原因，从而无法确定最有效的干预措施。

Method: 使用预训练的因果基础模型作为"假设分析"模型，估计潜在修复措施的效果。通过测量每个干预对系统级KPI（如整体设备效率OEE）的因果效应，为生产线提供数据驱动的行动排名。该方法不仅识别根本原因，还量化其操作影响。

Result: 使用半合成制造数据评估模型，并与基线机器学习模型进行比较。结果表明该方法为稳健的规范性维护框架奠定了技术基础。

Conclusion: 该方法使工程师能够在因果环境中测试潜在解决方案，做出更有效的操作决策，减少昂贵的停机时间，实现了从诊断到主动处方的转变。

Abstract: The transition to prescriptive maintenance in manufacturing is critically constrained by a dependence on predictive models. These models tend to rely on spurious correlations rather than identifying the true causal drivers of failures, often leading to costly misdiagnoses and ineffective interventions. This fundamental limitation results in a key-challenge: while we can predict that a failure may occur, we lack a systematic method to understand why a failure occurs, thereby providing the basis for identifying the most effective intervention. This paper proposes a model based on causal machine learning to bridge this gap. Our objective is to move beyond diagnosis to active prescription by simulating and evaluating potential fixes toward optimizing KPIs such as Overall Equipment Effectiveness (OEE). For this purpose a pre-trained causal foundation model is used as a "what-if" model to estimate the effects of potential fixes. By measuring the causal effect of each intervention on system-level KPIs, it provides a data-driven ranking of actions to recommend at the production line. This process not only identifies root causes but also quantifies their operational impact. The model is evaluated using semi-synthetic manufacturing data and compared with a baseline machine learning model. This paper sets the technical basis for a robust prescriptive maintenance framework, allowing engineers to test potential solutions in a causal environment to make more effective operational decisions and reduce costly downtimes.

</details>


### [154] [IndiMathBench: Autoformalizing Mathematical Reasoning Problems with a Human Touch](https://arxiv.org/abs/2512.00997)
*Param Biyani,Shashank Kirtania,Yasharth Bajpai,Sumit Gulwani,Ashish Tiwari*

Main category: cs.AI

TL;DR: IndiMathBench是一个用于评估数学定理证明的人类验证基准，包含312个来自印度数学奥林匹克竞赛的正式Lean 4定理及其对应的非正式问题陈述，通过AI辅助流程构建。


<details>
  <summary>Details</summary>
Motivation: 创建一个人工验证的基准来评估数学定理证明能力，特别是针对自动形式化（将自然语言问题转化为形式化语言）和定理证明任务，填补现有评估工具的不足。

Method: 采用AI驱动的人类辅助流程：通过基于类别的检索、迭代编译器反馈和多模型集成生成候选形式化，专家通过交互式仪表板进行高效验证，仪表板提供自动化质量摘要。

Result: 评估多个前沿模型显示：自动形式化仍然具有挑战性，语法有效性和语义正确性之间存在显著差距；即使通过迭代优化，定理证明的成功率仍然很低，表明该基准对数学推理构成了严峻挑战。

Conclusion: IndiMathBench为数学推理提供了一个具有挑战性的测试平台，突出了当前AI在自动形式化和定理证明方面的局限性，有助于推动相关领域的研究进展。

Abstract: We introduce IndiMathBench, a human-verified benchmark designed to evaluate mathematical theorem proving, curated using an AI-powered human-assisted pipeline for formalizing natural language problems in Lean. IndiMathBench is composed of 312 formal Lean 4 theorems paired with their corresponding informal problem statements, sourced from Indian Mathematics Olympiads. Through category-based retrieval, iterative compiler feedback, and multi-model ensembles, our pipeline generates candidate formalizations that experts efficiently validate via an interactive dashboard with automated quality summaries. Evaluation across multiple frontier models demonstrates that autoformalization remains challenging, with substantial gaps between syntactic validity and semantic correctness, while theorem proving success rates remain low even with iterative refinement, demonstrating that \benchmark~presents a challenging testbed for mathematical reasoning. IndiMathBench is available at https://github.com/prmbiy/IndiMathBench.

</details>


### [155] [ChartAnchor: Chart Grounding with Structural-Semantic Fidelity](https://arxiv.org/abs/2512.01017)
*Xinhang Li,Jingbo Zhou,Pengfei Luo,Yixiong Xiao,Tong Xu*

Main category: cs.AI

TL;DR: ChartAnchor是一个全面的图表基准测试，包含8k+图表-表格-代码三元组，涵盖30种图表类型，用于评估多模态大语言模型在图表理解方面的结构化推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在图表多样性、任务孤立性和评估框架完整性方面存在局限，无法全面评估图表接地（chart grounding）能力。图表接地需要模型在视觉外观和结构化语义之间进行双向对齐，这对数值推理、多模态对齐和结构重建能力提出了要求。

Method: 提出ChartAnchor基准测试，包含两个互补任务：图表到代码生成（合成可执行代码来复制图表）和受控图表到表格重建（使用预定义标题提取精确数据）。采用多级评估框架，整合语义验证、风格分析和感知指标，评估结构和内容层面的正确性。

Result: 在多模态大语言模型上的广泛实验揭示了数值精度和代码合成方面的关键局限性，强调了超越表面感知的结构化推理的必要性。

Conclusion: ChartAnchor通过统一符号和数据驱动的接地，为图表接地建立了严格的基础，为推进多模态大语言模型在科学、金融和工业领域的应用提供了有意义的见解。

Abstract: Recent advances in multimodal large language models (MLLMs) highlight the need for benchmarks that rigorously evaluate structured chart comprehension.Chart grounding refers to the bidirectional alignment between a chart's visual appearance and the structured semantics. This task requires models to produce a symbolic specification that faithfully captures the chart's visual and structural intent, while also recovering the underlying tabular data with precise values and relationships. Chart grounding directly reflects a model's capabilities in numerical reasoning, multimodal alignment, and structural reconstruction, and has several important applications in real-world scenarios.Existing benchmarks, constrained by narrow chart diversity, isolated tasks, and incomplete evaluation frameworks, fail to holistically assess grounding. To address this, we propose ChartAnchor, a comprehensive benchmark of 8k+ chart-table-code triples spanning 30 chart types drawn from diverse real-world and augmented sources. ChartAnchor introduces two complementary tasks: chart-to-code generation (synthesizing executable code to replicate charts) and controlled chart-to-table reconstruction (extracting exact data with predefined headers), enabling cross-validation of visual and numerical fidelity. A multi-level evaluation framework integrates semantic validation, stylistic analysis, and perceptual metrics to assess both structural and content-level correctness. Extensive experiments on MLLMs reveal critical limitations in numerical precision and code synthesis, emphasizing the need for structured reasoning beyond surface-level perception. By unifying symbolic and data-driven grounding, ChartAnchor establishes a rigorous foundation for chart grounding, offering meaningful insights for advancing MLLMs in scientific, financial, and industrial domains.

</details>


### [156] [Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics](https://arxiv.org/abs/2512.01020)
*Jinu Lee,Kyoung-Woon On,Simeng Han,Arman Cohan,Julia Hockenmaier*

Main category: cs.AI

TL;DR: LEGIT是一个大规模法律推理数据集，用于评估LLM在专业领域生成的推理轨迹质量，重点关注法律问题覆盖率和正确性


<details>
  <summary>Details</summary>
Motivation: 在专家领域（如法律）评估LLM生成的推理轨迹质量对于确保可信度和可解释性至关重要，但由于此类推理任务的固有复杂性，这仍然具有挑战性

Method: 将法院判决转换为对立双方论点和法院结论的分层树结构，作为评估推理轨迹问题覆盖率和正确性的评分标准；通过专家标注验证可靠性；使用RAG和基于评分标准的RL进行实验

Result: 1) LLM的法律推理能力严重受法律问题覆盖率和正确性影响；2) RAG和基于评分标准的RL在法律推理能力上带来互补优势：RAG提高整体推理能力，而RL提高正确性但会降低覆盖率

Conclusion: LEGIT数据集为评估专业领域LLM推理轨迹提供了有效工具，揭示了RAG和RL在提升法律推理能力方面的不同作用机制

Abstract: Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.

</details>


### [157] [Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal](https://arxiv.org/abs/2512.01045)
*Shenxi Liu,Kan Li,Mingyang Zhao,Yuhang Tian,Shoujun Zhou,Bin Li*

Main category: cs.AI

TL;DR: Med-CRAFT是一个神经符号数据工程框架，通过确定性图遍历过程生成医学视频推理基准，解决了高质量逻辑标注视频数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 医学领域多模态大语言模型发展面临高质量逻辑标注视频数据集稀缺的瓶颈。传统手动标注成本高昂且不可扩展，现有合成方法存在随机幻觉和缺乏逻辑可解释性的问题。

Method: 提出Med-CRAFT神经符号数据工程框架，将基准合成形式化为确定性图遍历过程。从原始视频流提取结构化视觉基元，实例化为动态时空知识图谱，通过图谱中的有效路径锚定查询生成，为每个合成基准项强制执行严格的思维链溯源。

Result: 构建了M3-Med-Auto大规模医学视频推理基准，具有细粒度时间选择性和多跳逻辑复杂性。评估显示自动管道生成的查询工作负载复杂度与专家策划数据集相当，逻辑对齐分析显示图谱拓扑与最先进MLLM推理步骤高度相关。

Conclusion: 该工作为关键领域可扩展、低成本的稳健评估协议构建铺平了道路，验证了系统将可验证逻辑编码到视觉语言基准中的能力。

Abstract: The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non-scalable, while existing synthetic methods often suffer from stochastic hallucinations and a lack of logical interpretability. To address these challenges, we introduce \textbf{\PipelineName}, a novel neuro-symbolic data engineering framework that formalizes benchmark synthesis as a deterministic graph traversal process. Unlike black-box generative approaches, Med-CRAFT extracts structured visual primitives (e.g., surgical instruments, anatomical boundaries) from raw video streams and instantiates them into a dynamic Spatiotemporal Knowledge Graph. By anchoring query generation to valid paths within this graph, we enforce a rigorous Chain-of-Thought (CoT) provenance for every synthesized benchmark item. We instantiate this pipeline to produce M3-Med-Auto, a large-scale medical video reasoning benchmark exhibiting fine-grained temporal selectivity and multi-hop logical complexity. Comprehensive evaluations demonstrate that our automated pipeline generates query workloads with complexity comparable to expert-curated datasets. Furthermore, a logic alignment analysis reveals a high correlation between the prescribed graph topology and the reasoning steps of state-of-the-art MLLMs, validating the system's capability to encode verifiable logic into visual-linguistic benchmarks. This work paves the way for scalable, low-cost construction of robust evaluation protocols in critical domains.

</details>


### [158] [SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds](https://arxiv.org/abs/2512.01078)
*Jiawei Ren,Yan Zhuang,Xiaokang Ye,Lingjun Mao,Xuhong He,Jianzhi Shen,Mrinaal Dogra,Yiming Liang,Ruixuan Zhang,Tianai Yue,Yiqing Yang,Eric Liu,Ryan Wu,Kevin Benavente,Rajiv Mandya Nagaraju,Muhammad Faayez,Xiyan Zhang,Dhruv Vivek Sharma,Xianrui Zhong,Ziqiao Ma,Tianmin Shu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: SimWorld是一个基于虚幻引擎5构建的新型模拟器，专门为开发和评估LLM/VLM智能体在丰富、真实世界环境中设计，解决了现有模拟器在物理、社交规则和智能体支持方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM/VLM智能体在复杂物理和社会环境中的应用仍然面临挑战，现有世界模拟器存在环境有限、物理简化、社交规则简单化以及缺乏对LLM/VLM智能体原生支持等问题，需要一个新的平台来开发能在真实世界中生存和发展的智能体。

Method: 基于虚幻引擎5构建SimWorld模拟器，提供三个核心能力：1) 真实、开放式的世界模拟，包括精确的物理和社交动态以及语言驱动的程序化环境生成；2) 为LLM/VLM智能体提供丰富的接口，支持多模态世界输入和不同抽象层次的开放词汇动作；3) 多样且可扩展的物理和社交推理场景，用户可轻松定制。

Result: 通过在涉及战略合作与竞争的长期多智能体配送任务中部署前沿LLM智能体（如GPT-4o、Gemini-2.5-Flash、Claude-3.5和DeepSeek-Prover-V2），展示了不同模型之间的推理模式和局限性差异。

Conclusion: SimWorld作为一个开源平台，有望成为跨学科推进真实世界智能体智能的基础平台，为开发能在复杂物理和社会环境中有效运作的AI智能体提供重要支持。

Abstract: While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.

</details>


### [159] [Energy-Aware Data-Driven Model Selection in LLM-Orchestrated AI Systems](https://arxiv.org/abs/2512.01099)
*Daria Smirnova,Hamid Nasiri,Marta Adamska,Zhengxin Yu,Peter Garraghan*

Main category: cs.AI

TL;DR: GUIDE框架通过引入定量模型性能特征，解决LLM编排器因依赖定性描述导致的模型选择次优问题，在提升准确率的同时显著改善能效。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的编排器依赖定性模型描述进行决策，这些描述不能反映真实模型能力和性能特征，导致模型选择次优、准确率降低和能耗增加。

Method: 提出GUIDE框架，这是一个考虑性能-能耗权衡的能源感知模型选择框架，通过将定量模型性能特征纳入决策过程来改进编排。

Result: 实验结果显示，GUIDE在各种评估任务中将准确率提高了0.90%-11.92%，能效提升高达54%，同时将编排器模型选择延迟从4.51秒降低到7.2毫秒。

Conclusion: GUIDE框架通过引入定量模型性能特征，有效解决了LLM编排器的局限性，在提升任务准确率的同时显著改善了能源效率和响应速度。

Abstract: As modern artificial intelligence (AI) systems become more advanced and capable, they can leverage a wide range of tools and models to perform complex tasks. Today, the task of orchestrating these models is often performed by Large Language Models (LLMs) that rely on qualitative descriptions of models for decision-making. However, the descriptions provided to these LLM-based orchestrators do not reflect true model capabilities and performance characteristics, leading to suboptimal model selection, reduced accuracy, and increased energy costs. In this paper, we conduct an empirical analysis of LLM-based orchestration limitations and propose GUIDE, a new energy-aware model selection framework that accounts for performance-energy trade-offs by incorporating quantitative model performance characteristics in decision-making. Experimental results demonstrate that GUIDE increases accuracy by 0.90%-11.92% across various evaluated tasks, and achieves up to 54% energy efficiency improvement, while reducing orchestrator model selection latency from 4.51 s to 7.2 ms.

</details>


### [160] [Foundation Priors](https://arxiv.org/abs/2512.01107)
*Sanjog Misra*

Main category: cs.AI

TL;DR: 该论文提出"基础先验"概念，将大语言模型生成的合成数据视为先验预测分布而非真实观测，强调合成数据同时反映模型学习模式和用户主观先验、期望与偏见。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型（特别是大语言模型）生成高度信息性响应的能力增强，研究者越来越倾向于将这些"合成"输出用作实证研究和决策的数据。然而，这些合成数据并非真实观测，而是反映了模型学习模式和用户主观因素，需要建立理论框架来避免将合成"事实"与真实数据混淆。

Method: 论文提出"基础先验"概念，将生成过程的主观性建模为对用户预期数据分布、提示工程过程和模型信任度的显式依赖。通过指数倾斜的广义贝叶斯更新推导基础先验，其中信任参数控制合成数据的权重。

Result: 建立了将合成数据及相关基础先验纳入标准统计和计量经济学工作流程的方法，展示了在精炼复杂模型、指导潜在构念、指导实验设计以及增强随机系数和部分线性规范等应用中的使用方式。

Conclusion: 通过将生成输出视为结构化、显式主观的先验而非经验观测，该框架为在实证工作中利用基础模型提供了原则性方法，同时避免了将合成"事实"与真实数据混为一谈。

Abstract: Foundation models, and in particular large language models, can generate highly informative responses, prompting growing interest in using these ''synthetic'' outputs as data in empirical research and decision-making. This paper introduces the idea of a foundation prior, which shows that model-generated outputs are not as real observations, but draws from the foundation prior induced prior predictive distribution. As such synthetic data reflects both the model's learned patterns and the user's subjective priors, expectations, and biases. We model the subjectivity of the generative process by making explicit the dependence of synthetic outputs on the user's anticipated data distribution, the prompt-engineering process, and the trust placed in the foundation model.
  We derive the foundation prior as an exponential-tilted, generalized Bayesian update of the user's primitive prior, where a trust parameter governs the weight assigned to synthetic data. We then show how synthetic data and the associated foundation prior can be incorporated into standard statistical and econometric workflows, and discuss their use in applications such as refining complex models, informing latent constructs, guiding experimental design, and augmenting random-coefficient and partially linear specifications. By treating generative outputs as structured, explicitly subjective priors rather than as empirical observations, the framework offers a principled way to harness foundation models in empirical work while avoiding the conflation of synthetic ''facts'' with real data.

</details>


### [161] [A Benchmark of Causal vs Correlation AI for Predictive Maintenance](https://arxiv.org/abs/2512.01149)
*Krishna Taduri,Shaunak Dhande,Giacinto Paolo,Saggese,Paul Smith*

Main category: cs.AI

TL;DR: 该研究比较了8种预测模型在制造业预测性维护中的应用，发现因果AI方法相比传统相关性方法能显著降低成本，实现更好的财务结果。


<details>
  <summary>Details</summary>
Motivation: 制造业预测性维护面临极端成本不对称的挑战（漏检故障成本约为误报成本的50倍），传统机器学习方法通常优化统计准确性指标，无法反映这种操作现实，且难以区分因果关系与虚假相关性。

Method: 研究评估了8种预测模型，包括基线统计方法和正式因果推断方法，使用包含10,000台CNC机床的数据集（故障率为3.3%）。

Result: 正式因果推断模型（L5）实现了116万美元的年度成本节约（减少70.2%），比最佳基于相关性的决策树模型（L3）每年多节约约8万美元。因果模型保持了最高召回率（87.9%），同时将误报减少97%（从165降至5），精度达到92.1%，训练-测试性能差距仅为2.6个百分点。

Conclusion: 因果AI方法与领域知识结合，在预测性维护应用中相比基于相关性的方法能产生更优越的财务结果和更可解释的预测。

Abstract: Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.

</details>


### [162] [fMRI2GES: Co-speech Gesture Reconstruction from fMRI Signal with Dual Brain Decoding Alignment](https://arxiv.org/abs/2512.01189)
*Chunzheng Zhu,Jialin Shao,Jianxin Lin,Yijun Wang,Jing Wang,Jinhui Tang,Kenli Li*

Main category: cs.AI

TL;DR: fMRI2GES：一种利用双脑解码对齐技术，从fMRI信号重建与语音刺激相关手势的新方法，无需配对的大脑-语音-手势数据。


<details>
  <summary>Details</summary>
Motivation: 理解大脑对外部刺激的响应和解码过程是神经科学的重要挑战。现有研究主要集中在脑到图像和脑到语言的重建，而本研究旨在重建与大脑感知的语音刺激相关的手势。由于缺乏配对的大脑-语音-手势数据，阻碍了深度学习模型在此任务上的应用。

Method: 提出fMRI2GES方法，采用双脑解码对齐技术，利用两个关键组件：(1)引发大脑响应的观察文本；(2)与手势相关的文本描述。通过fMRI到文本模型、文本到手势模型（有配对数据）和fMRI到手势模型（无配对数据）建立双重fMRI到手势重建模式，然后显式对齐两个输出并以自监督方式训练模型。

Result: 该方法能够直接从fMRI记录中重建富有表现力的手势。研究还调查了大脑皮层不同ROI的fMRI信号及其对生成结果的影响。

Conclusion: 为解码伴随语音的手势提供了新的见解，推动了神经科学和认知科学的发展。

Abstract: Understanding how the brain responds to external stimuli and decoding this process has been a significant challenge in neuroscience. While previous studies typically concentrated on brain-to-image and brain-to-language reconstruction, our work strives to reconstruct gestures associated with speech stimuli perceived by brain. Unfortunately, the lack of paired \{brain, speech, gesture\} data hinders the deployment of deep learning models for this purpose. In this paper, we introduce a novel approach, \textbf{fMRI2GES}, that allows training of fMRI-to-gesture reconstruction networks on unpaired data using \textbf{Dual Brain Decoding Alignment}. This method relies on two key components: (i) observed texts that elicit brain responses, and (ii) textual descriptions associated with the gestures. Then, instead of training models in a completely supervised manner to find a mapping relationship among the three modalities, we harness an fMRI-to-text model, a text-to-gesture model with paired data and an fMRI-to-gesture model with unpaired data, establishing dual fMRI-to-gesture reconstruction patterns. Afterward, we explicitly align two outputs and train our model in a self-supervision way. We show that our proposed method can reconstruct expressive gestures directly from fMRI recordings. We also investigate fMRI signals from different ROIs in the cortex and how they affect generation results. Overall, we provide new insights into decoding co-speech gestures, thereby advancing our understanding of neuroscience and cognitive science.

</details>


### [163] [Knowledge Graph Augmented Large Language Models for Next-Visit Disease Prediction](https://arxiv.org/abs/2512.01210)
*Ruiyu Wang,Tuan Vinh,Ran Xu,Yuyin Zhou,Jiaying Lu,Carl Yang,Francisco Pasquel*

Main category: cs.AI

TL;DR: 提出基于知识图谱引导的思维链框架，为电子病历中的疾病预测生成临床可解释的推理过程，在MIMIC-III和CRADLE数据集上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有电子病历预测模型通常提供粗略的事后解释，对患者层面决策支持有限，需要更临床可解释且时间一致的推理方法。

Method: 将ICD-9编码映射到PrimeKG知识图谱，提取疾病相关节点和多跳推理路径作为思维链骨架，仅保留与观察结果匹配的解释，然后微调轻量级LLaMA和Gemma模型。

Result: 在10种PrimeKG映射疾病和有限训练数据（400和1000病例）下，KG引导模型AUROC达0.66-0.70，macro-AUPR达0.40-0.47，在CRADLE队列零样本迁移中准确率从0.40-0.51提升至0.72-0.77。

Conclusion: KG引导的思维链框架能生成临床可解释的推理，提升疾病预测性能，且临床医生评估显示其在清晰度、相关性和临床正确性方面更受偏好。

Abstract: Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.

</details>


### [164] [Unsupervised decoding of encoded reasoning using language model interpretability](https://arxiv.org/abs/2512.01222)
*Ching Fang,Samuel Marks*

Main category: cs.AI

TL;DR: 论文研究了当前可解释性技术能否解码大语言模型中的加密推理过程，通过构建ROT-13加密推理测试平台，发现logit lens方法能有效解码隐藏推理，并提出无监督解码流程。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力增强，人们担心它们可能发展出人类无法监督的编码推理过程。需要研究当前可解释性技术能否穿透这种编码推理，以保持对AI系统的监督。

Method: 通过微调推理模型（DeepSeek-R1-Distill-Llama-70B）使其在ROT-13加密下进行思维链推理，同时保持英文输出可读。使用logit lens分析等机制可解释性方法，评估仅通过内部激活解码模型隐藏推理过程的能力。开发了结合logit lens和自动释义的无监督解码流程。

Result: logit lens能有效翻译编码推理，准确率在中间到后期层达到峰值。无监督解码流程能够从内部模型表示中重建完整的推理记录，达到显著准确度。

Conclusion: 当前机制可解释性技术对简单形式的编码推理可能比之前理解的更鲁棒。研究为评估可解释性方法对抗非人类可读格式推理模型提供了初步框架，有助于维护对日益强大AI系统的监督。

Abstract: As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.

</details>


### [165] [RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving](https://arxiv.org/abs/2512.01300)
*Dacheng Liao,Mengshi Qi,Peng Shu,Zhining Zhang,Yuxin Lin,Liang Liu,Huadong Ma*

Main category: cs.AI

TL;DR: 论文提出了RoboDriveBench基准测试来评估VLM端到端自动驾驶系统的鲁棒性，并开发了RoboDriveVLM框架通过多模态数据融合和测试时适应方法提升系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型(VLM)的端到端自动驾驶系统虽然能生成驾驶决策，但在真实驾驶场景中存在多种风险。需要系统评估VLM在自动驾驶中的可行性，特别是面对环境变化和人为干预等现实挑战时的鲁棒性。

Method: 1) 提出RoboDriveBench基准测试，包含11个模拟场景(6个传感器损坏场景和5个提示损坏场景)，共64,559个轨迹预测案例；2) 开发RoboDriveVLM框架，将激光雷达、雷达等多模态数据映射到统一潜在空间；3) 引入基于跨模态知识蒸馏的测试时适应方法提升鲁棒性。

Result: 通过大量实验，研究揭示了当前VLM端到端自动驾驶系统的局限性，并提供了更可靠的解决方案。RoboDriveVLM框架在应对传感器损坏和提示损坏等现实挑战时表现出更强的鲁棒性。

Conclusion: 该工作强调了当前VLM自动驾驶系统的脆弱性，提出了系统性的评估基准和增强鲁棒性的方法，为VLM在真实世界自动驾驶部署提供了更可靠的解决方案。源代码和数据集将公开发布。

Abstract: Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.

</details>


### [166] [CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL](https://arxiv.org/abs/2512.01311)
*Shinji Mai,Yunpeng Zhai,Ziqian Chen,Cheng Chen,Anni Zou,Shuchang Tao,Zhaoyang Liu,Bolin Ding*

Main category: cs.AI

TL;DR: CuES框架通过好奇心驱动和环境基础的任务生成，解决智能体强化学习中任务稀缺问题，无需预定义任务即可自主生成多样可执行任务。


<details>
  <summary>Details</summary>
Motivation: 智能体强化学习在复杂工具增强环境中面临任务稀缺问题，现有方法依赖预定义任务集合，这在工具语义和可用性未知的新环境中不适用，成为扩展智能体RL的关键瓶颈。

Method: 提出CuES框架：基于好奇心驱动和环境基础的任务合成，通过内在好奇心驱动探索，将交互模式抽象为可重用任务模式，并通过轻量级自上而下指导和基于记忆的质量控制进行优化。

Result: 在AppWorld、BFCL和WebShop三个代表性环境中，CuES生成的任务分布在多样性和可执行性方面匹配或超越手动策划的数据集，带来显著的下游策略改进。

Conclusion: 好奇心驱动、环境基础的任务生成为智能体提供了可扩展的基础，使智能体不仅能学习如何行动，还能学习学习什么，解决了任务稀缺问题。

Abstract: Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/research/CuES.

</details>


### [167] [Extending NGU to Multi-Agent RL: A Preliminary Study](https://arxiv.org/abs/2512.01321)
*Juan Hernandez,Diego Fernández,Manuel Cifuentes,Denis Parra,Rodrigo Toro Icarte*

Main category: cs.AI

TL;DR: 将Never Give Up算法扩展到多智能体环境，在PettingZoo的simple_tag环境中评估，发现共享经验回放结合内在探索能提升性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: NGU算法在稀疏奖励的强化学习任务中表现出色，但尚未在多智能体环境中得到充分研究。本文旨在探索NGU在多智能体环境中的适用性和效果。

Method: 将NGU扩展到多智能体环境，在PettingZoo的simple_tag环境中进行实验。研究三个设计选择：1) 共享回放缓冲区 vs 个体回放缓冲区；2) 使用不同k阈值共享情景新颖性；3) 使用异构的beta参数值。与多智能体DQN基线进行比较。

Result: NGU相比多智能体DQN基线获得中等更高的回报和更稳定的学习动态。共享回放缓冲区表现最佳，新颖性共享在k=1时表现相当但k值增大会降低学习效果，异构beta值相比小的共同值没有改进。

Conclusion: NGU可以有效地应用于多智能体设置，当经验被共享且内在探索信号被仔细调整时。共享经验回放结合NGU内在探索带来了性能提升和稳定性改善。

Abstract: The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.

</details>


### [168] [The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness](https://arxiv.org/abs/2512.01354)
*Zhongjie Jiang*

Main category: cs.AI

TL;DR: 该论文提出了一种新的合成数据生成范式：通过模拟人类认知过程而非模仿数据表面特征来生成文本，以解决当前合成数据导致模型崩溃的问题。


<details>
  <summary>Details</summary>
Motivation: 当前合成数据生成范式追求统计平滑性，但会系统性地移除人类文本中具有认知基础的长尾不规则特征，导致训练数据认知贫乏，加速模型崩溃。

Method: 提出Prompt驱动的认知计算框架(PMCSF)，包含认知状态解码器(CSD)将非结构化文本反转为结构化认知向量，以及认知文本编码器(CTE)通过数学定义的认知扰动算子将这些状态重新物化为富含人类典型缺陷的文本。

Result: 在认知编解码验证中，CTE生成的文本与人类文本的Jensen-Shannon散度为0.0614（标准LLM输出为0.4431），通过双盲专业媒体评审，认知轮廓对齐的组内相关系数ICC>0.9。在功能增益评估中，A股市场同构压力测试显示，使用CTE生成数据的策略在2015年股灾期间最大回撤减少47.4%，产生8.6%的防御性阿尔法，超过交易成本33倍。

Conclusion: 模拟人类认知限制而非复制表面数据，能够生成具有真正功能增益的合成数据，为解决AI数据崩溃危机提供了可行的技术路径。

Abstract: Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse.
  This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators.
  The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33.
  Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.

</details>


### [169] [A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building](https://arxiv.org/abs/2512.01434)
*Daull Xavier,Patrice Bellot,Emmanuel Bruno,Vincent Martin,Elisabeth Murisasco*

Main category: cs.AI

TL;DR: CollabToolBuilder是一个多智能体LLM框架，通过专家在环指导迭代学习为目标创建工具，最小化任务/领域适应时间和人工反馈收集


<details>
  <summary>Details</summary>
Motivation: 解决复杂迭代问题（如科学文档生成）中工具创建与人类意图对齐的挑战，减少任务/领域适应所需的时间和人工反馈收集

Method: 使用四个专门化智能体（教练、编码员、批评家、资本化器）通过强化动态提示和系统化人工反馈集成来生成和验证工具

Result: 通过初步实验展示了系统能够生成最先进的研究论文或专利，并讨论了其在其他迭代问题解决中的适用性

Conclusion: CollabToolBuilder是一个系统级集成和方法论，结合了多智能体上下文学习、专家在环控制和可重用工具资本化，适用于复杂迭代问题解决

Abstract: We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.

</details>


### [170] [A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale](https://arxiv.org/abs/2512.01440)
*Sylvain Marié,Pablo Knecht*

Main category: cs.AI

TL;DR: 提出了一种新的状态转移事件时间序列（STE-ts）和选择性时序汉明距离（STH），避免了对大型数据库进行代价高昂且扭曲的重采样操作


<details>
  <summary>Details</summary>
Motivation: 离散事件系统在自然观测、社会经济科学和工业系统中普遍存在，但标准分析方法通常未能充分利用其事件/状态的双重性质。现有方法要么将信号建模为转移事件序列（强调事件顺序对齐），要么建模为分类或有序状态时间序列（通常需要重采样，随着观测周期和事件数量的增长，这种操作既扭曲又代价高昂）

Method: 定义了状态转移事件时间序列（STE-ts），并提出了一种新的选择性时序汉明距离（STH），该距离同时利用转移时间和状态持续时间，避免了对大型数据库进行代价高昂且扭曲的重采样

Result: STH推广了重采样的汉明和杰卡德度量，具有更好的精度和计算时间，并且能够关注多个感兴趣的状态。在模拟和真实世界数据集上验证了这些优势

Conclusion: 提出的STE-ts和STH方法能够有效处理离散事件系统，避免了传统重采样方法的缺点，在精度和计算效率方面都有显著改进，适用于大型数据库分析

Abstract: Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.

</details>


### [171] [Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework](https://arxiv.org/abs/2512.01452)
*Lingbo Li,Anuradha Mathrani,Teo Susnjak*

Main category: cs.AI

TL;DR: 本研究开发了一种基于DSPy和GEPA模块的程序化偏倚风险评估管道，通过结构化代码优化替代手动提示设计，在随机对照试验的偏倚风险评估中实现了可复现的自动化。


<details>
  <summary>Details</summary>
Motivation: 随机对照试验的偏倚风险评估对于证据合成至关重要，但传统方法资源密集且存在评估者间变异性。现有的大语言模型自动化方法依赖难以复现、泛化或评估的手工设计提示。

Method: 引入基于DSPy和GEPA模块的程序化偏倚风险评估管道，使用结构化代码优化替代临时提示设计。GEPA通过帕累托引导搜索优化大语言模型推理，并生成可检查的执行轨迹，实现优化过程的透明复现。

Result: 在7个偏倚风险领域评估了100个随机对照试验。GEPA生成的提示在方法报告更清晰的领域（如随机序列生成）表现最佳，在分配隐藏和参与者盲法方面也有类似结果。与三个手动设计提示相比，GEPA实现了最高总体准确率，在随机序列生成和选择性报告方面性能提升30%-40%，在其他领域表现相当。

Conclusion: GEPA能够为偏倚风险评估生成一致且可复现的提示，支持在大语言模型证据合成中的结构化和原则性使用，为解决评估者间变异性问题提供了有前景的解决方案。

Abstract: Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.

</details>


### [172] [SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry](https://arxiv.org/abs/2512.01507)
*Daniel Armstrong,Zlatko Jončev,Andres M Bran,Philippe Schwaller*

Main category: cs.AI

TL;DR: 利用大型语言模型将合成知识转化为代码，实现计算机辅助合成规划中的战略考量，如汇聚式组装、保护基最小化和最优环形成序列。


<details>
  <summary>Details</summary>
Motivation: 现代计算机辅助合成规划系统能生成化学上有效的反应步骤，但难以纳入战略考量，如汇聚式组装、保护基最小化和最优环形成序列。需要将合成知识转化为可验证的代码而非简单的启发式规则。

Method: 利用大型语言模型将合成知识转化为Python函数，代表多样化的战略和战术规则，包括战略官能团互变和环构建策略。创建了USPTO-ST数据集（带有战略标签的合成路线标注）。

Result: 实现了基于自然语言的路线检索，在基准测试中达到75%的Top-3准确率。通过历史趋势的时间分析和化学直观的路线聚类验证了该库，提供了比先前方法更细粒度的划分。

Conclusion: 这项工作弥合了计算机辅助合成规划中战术与战略之间的鸿沟，使得能够基于战略标准而非仅结构来指定、搜索和评估合成路线。

Abstract: Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.

</details>


### [173] [LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems](https://arxiv.org/abs/2512.01556)
*Zhiyuan Wang,Aniri,Tianlong Chen,Yue Zhang,Heng Tao Shen,Xiaoshuang Shi,Kaidi Xu*

Main category: cs.AI

TL;DR: 论文提出LEC方法，通过线性期望约束和FDR控制，为LLM预测提供统计保证，并扩展到双模型路由机制，在保持FDR控制的同时提高样本保留率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常生成不可靠答案，而传统不确定性方法无法完全区分正确与错误预测，导致用户在没有统计保证的情况下接受错误答案。需要一种能提供统计保证的方法来控制错误发现率。

Method: 提出LEC方法，将选择性预测重新解释为约束决策问题，通过对选择和错误指标施加线性期望约束。建立有限样本充分条件，仅依赖可交换校准样本计算FDR约束下的覆盖率最大化阈值。扩展为双模型路由机制：当当前模型不确定性超过校准阈值时，将其委托给更强模型，同时保持统一的FDR保证。

Result: 在封闭式和开放式问答数据集上的评估显示，LEC实现了更严格的FDR控制，并显著提高了样本保留率。双模型路由机制在保持更低风险水平的同时，比单个模型接受了更多正确样本。

Conclusion: LEC方法通过FDR控制为LLM预测提供统计保证，双模型路由机制进一步优化了性能，在保持风险控制的同时提高了接受正确样本的能力。

Abstract: Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.

</details>


### [174] [CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning](https://arxiv.org/abs/2512.01616)
*Chainesh Gautam,Raghuram Bharadwaj Diddigi*

Main category: cs.AI

TL;DR: 该论文提出了一种基于CLIP思想的强化学习方法，通过将语言指令与对应策略对齐到统一表示空间，实现跨任务的高效迁移学习。


<details>
  <summary>Details</summary>
Motivation: 当前需要开发能够在同一环境中解决多个任务的智能体，特别是当这些任务与语言自然关联时。现有方法在跨任务迁移方面效率不足，需要一种能够有效利用语言-策略对应关系的方法。

Method: 受计算机视觉中CLIP方法的启发，将"表示相同概念的两个模态应有相似表示"的理念扩展到强化学习。通过将任务指令（语言模态）和对应策略（策略模态）对齐到统一表示空间，建立语言-策略对组合的预训练框架，实现跨任务的高效迁移。

Result: 实验结果表明，该方法在跨任务迁移方面实现了更快的收敛速度，验证了将CLIP思想应用于强化学习的有效性，证明了语言-策略对齐能够促进任务间的知识迁移。

Conclusion: 通过将CLIP的对齐理念扩展到强化学习领域，成功构建了语言指令与策略的统一表示空间，为多任务强化学习提供了一种高效的迁移学习框架，显著提升了跨任务的学习效率。

Abstract: Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.

</details>


### [175] [Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems](https://arxiv.org/abs/2512.01786)
*Xiaochuan Li,Ke Wang,Girija Gouda,Shubham Choudhary,Yaqun Wang,Linwei Hu,Joel Vaughan,Freddy Lecue*

Main category: cs.AI

TL;DR: 提出LLM Jury-on-Demand框架，通过动态选择最可靠的LLM法官组成陪审团来评估LLM输出，实现可扩展且可靠的评估系统


<details>
  <summary>Details</summary>
Motivation: 随着LLM进入高风险领域，需要既可扩展又可靠的评估方法。人工评估可靠但成本高，单个LLM法官有偏见，静态陪审团缺乏适应性

Method: 训练一组可靠性预测器，利用token分布、嵌入和结构输入特征来预测LLM法官何时会与人类专家意见一致。为每个数据点动态选择最可靠的法官组成最优陪审团，并以可靠性为权重聚合评分

Result: 在摘要和RAG基准测试中，动态陪审团系统相比单法官和静态陪审团基线，与人类判断的相关性显著提高

Conclusion: 自适应、基于学习的陪审团方法为在高风险领域构建可扩展、更可靠和可信的LLM评估系统提供了有前景的解决方案

Abstract: As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.

</details>


### [176] [H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons](https://arxiv.org/abs/2512.01797)
*Cheng Gao,Huimin Chen,Chaojun Xiao,Zhiyi Chen,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 该论文系统研究了LLM中的幻觉相关神经元，发现仅需不到0.1%的稀疏神经元子集就能可靠预测幻觉发生，这些神经元与过度顺从行为存在因果关联，且源于预训练阶段。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常产生幻觉（看似合理但事实错误的输出），这削弱了其可靠性。先前研究主要从训练数据和目标等宏观角度分析幻觉，而神经元层面的机制仍未被充分探索。

Method: 从三个角度系统研究幻觉相关神经元：1）识别：发现稀疏神经元子集（少于总神经元的0.1%）能可靠预测幻觉；2）行为影响：通过受控干预证明这些神经元与过度顺从行为存在因果关联；3）起源：追踪这些神经元到预训练基础模型，发现它们在预训练期间就已形成。

Result: 幻觉相关神经元具有高度稀疏性，能跨不同场景泛化预测幻觉；这些神经元与模型的过度顺从行为存在因果关联；这些神经元源于预训练阶段，在基础模型中就已具备预测幻觉的能力。

Conclusion: 该研究将宏观行为模式与微观神经机制联系起来，为开发更可靠的大型语言模型提供了新见解，揭示了幻觉的神经元基础及其在预训练阶段的形成过程。

Abstract: Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.

</details>


### [177] [Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models](https://arxiv.org/abs/2512.01880)
*Daren Zhong,Dingcheng Huang,Clayton Greenberg*

Main category: cs.AI

TL;DR: 该研究提出了一种基于n-gram语言模型的国际象棋走子预测框架，将走子预测视为行为分析任务，针对不同技能水平的玩家训练专门模型，实现实时棋局分析。


<details>
  <summary>Details</summary>
Motivation: 传统国际象棋引擎主要关注计算最优走法，忽略了人类棋手在不同技能水平下的走子变异性。为了克服这一局限，需要开发能够捕捉特定技能水平玩家走子模式的分析框架。

Method: 将玩家分为7个技能等级（从新手到专家），使用Lichess开源平台数据训练独立的n-gram语言模型。框架包含模型选择器模块，根据棋局动态选择最合适的模型进行走子预测。

Result: 模型选择器在使用早期棋局信息（16个半着法）时，技能水平分类准确率达到31.7%。走子预测框架的Selector Assisted Accuracy比基准准确率提高了39.1%，计算效率高，适合实时分析。

Conclusion: 该框架成功将国际象棋走子预测转化为行为分析任务，通过针对不同技能水平的专门化建模，显著提高了预测准确性，为实时棋局分析提供了高效工具。

Abstract: Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.
  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.
  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.

</details>


### [178] [Learned-Rule-Augmented Large Language Model Evaluators](https://arxiv.org/abs/2512.01958)
*Jie Meng,Jin Mao*

Main category: cs.AI

TL;DR: 提出了一种基于规则增强的LLM评估范式，通过规则蒸馏和规则应用策略，提升LLM作为通用评估器的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为自然语言生成任务的评估器应用广泛，但在更广泛的评估场景中应用有限。现有方法依赖人工设计的评估原则，成本高且与标注数据和LLM理解不一致，导致泛化能力不足。

Method: 1. 规则蒸馏方法：使用LLM辅助的蒙特卡洛树搜索自动从数据中提取评分规则，解决可扩展性问题并提高与数据的对齐度。2. 规则应用策略：提出Chain-of-Rule指导LLM遵循蒸馏规则，以及通过强化学习训练规则增强的LLM评估器，弥合规则与LLM推理之间的差距。

Result: 在多样化任务上的广泛实验表明，该方法在各种评估场景中具有有效性和泛化能力。

Conclusion: 提出的规则增强评估范式通过自动规则蒸馏和有效规则应用策略，显著提升了LLM作为通用评估器的性能和泛化能力。

Abstract: Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.

</details>


### [179] [From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning](https://arxiv.org/abs/2512.01970)
*Sitao Cheng,Xunjian Yin,Ruiwen Zhou,Yuxuan Li,Xinyi Wang,Liangming Pan,William Yang Wang,Victor Zhong*

Main category: cs.AI

TL;DR: 本文通过互补推理任务研究RL如何提升推理能力，发现RL不是简单的概率放大器，而是能够从已掌握的原子技能中合成复杂推理策略的合成器，前提是基础模型已通过SFT掌握了独立的原子技能。


<details>
  <summary>Details</summary>
Motivation: 研究强化学习（RL）对推理能力的贡献机制——是激励新技能的合成还是仅仅放大现有行为，这是一个激烈争论的话题。作者希望通过互补推理这一复杂任务来探究这个问题。

Method: 使用人类传记的合成数据集，将互补推理能力严格解耦为两个原子技能：参数推理（依赖内部知识）和上下文推理（依赖外部信息）。在三个难度级别评估泛化能力：I.I.D.、组合和零样本设置。比较SFT和RL的表现。

Result: 发现SFT在分布内表现良好，但在分布外泛化（特别是零样本设置）上困难，存在"SFT泛化悖论"：仅监督复合任务的模型在分布内准确率接近完美，但在分布外泛化上崩溃。RL可以作为推理合成器而非概率放大器，但前提是基础模型已通过SFT掌握了独立的原子技能。

Conclusion: RL不是简单的放大器，而是在具备足够原子基础的情况下，能够从学习到的原语中主动合成复杂推理策略。解耦的原子训练后接RL为复杂推理任务提供了可扩展的泛化路径。

Abstract: The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.

</details>


### [180] [Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback](https://arxiv.org/abs/2512.01979)
*Aiden Yiliu Li,Bizhi Yu,Daoan Lei,Tianhe Ren,Shilong Liu*

Main category: cs.AI

TL;DR: Chain of Ground (CoG)是一个无需训练的多步GUI定位框架，通过迭代视觉推理和细化来提升多模态大语言模型在复杂用户界面中的定位准确性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在GUI定位方面虽然表现出色，但仍面临小目标、视觉相似目标和真实世界布局模糊性的挑战。这些限制源于有限的定位能力和未充分利用现有推理潜力。

Method: 提出Chain of Ground框架，采用无需训练的多步定位方法，让模型进行迭代视觉推理和假设调整，而不是直接预测。模型逐步反思和调整其假设，实现更准确和可解释的定位。

Result: 在ScreenSpot Pro基准测试中达到68.4%的准确率，提升4.8个百分点。在TPanel UI数据集（420个带视觉失真的工业控制面板）上，相比Qwen3 VL 235B基线提升6.9个百分点。

Conclusion: 研究展示了通过结构化迭代细化而非额外训练来释放定位潜力的方向，证明多步无需训练定位方法在真实世界和数字界面中的有效性。

Abstract: GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.

</details>


### [181] [LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess](https://arxiv.org/abs/2512.01992)
*Sai Kolasani,Maxim Saplin,Nicholas Crispino,Kyle Montgomery,Jared Quincy Davis,Matei Zaharia,Chi Wang,Chenguang Wang*

Main category: cs.AI

TL;DR: LLM CHESS是一个通过国际象棋游戏评估大语言模型推理和指令遵循能力的框架，测试了50多个模型，发现即使面对简单任务，许多先进模型也难以完成游戏或取得稳定胜利。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评估基准通常是静态的，容易导致模型过拟合和记忆化，难以真正测试模型的推理和指令遵循能力。需要一种动态、随机的评估框架来减少这些问题，并防止基准饱和。

Method: 开发了LLM CHESS评估框架，让大语言模型在国际象棋游戏中与随机对手对战。使用多种行为指标进行评估，包括胜率、负率、走棋质量、走棋合法性、幻觉动作和游戏时长。对顶级推理模型还通过与国际象棋引擎对战来估算Elo评分。

Result: 测试了50多个开源和闭源模型，发现许多最先进的模型难以完成游戏或取得稳定胜利。实验显示推理模型和非推理模型之间存在明显差距。LLM CHESS的动态随机特性有效减少了过拟合和记忆化，即使对顶级推理模型也具有挑战性。

Conclusion: LLM CHESS提供了一个有效的动态评估框架，能够真实测试大语言模型的推理和指令遵循能力。该框架减少了基准饱和问题，并支持模型间的可比性评估。作者发布了实验框架、公开排行榜和相关游戏数据集以支持未来研究。

Abstract: We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [182] [Dissipation and fluctuations of CMOS ring oscillators close to criticality](https://arxiv.org/abs/2512.00188)
*Ashwin Gopal,Massimiliano Esposito,Jan Meibohm*

Main category: cond-mat.stat-mech

TL;DR: 该论文分析了CMOS环形振荡器在相干电压振荡起始点附近的热力学一致模型，推导了Hopf分岔的正规形式，发现振荡状态下熵耗散减少，建立了稳定性-耗散关系，并研究了临界电压附近的有限尺寸涨落效应。


<details>
  <summary>Details</summary>
Motivation: 研究CMOS环形振荡器在振荡起始点附近的热力学行为，特别是理解振荡状态下的熵耗散变化以及有限尺寸效应对振荡特性的影响。

Method: 使用热力学一致模型分析CMOS环形振荡器，在临界电压附近推导Hopf分岔的正规形式，基于此分析相位和振幅动力学，并引入随机正规形式研究有限尺寸涨落。

Result: 发现对于超过三个反相器的环形振荡器，振荡状态下熵耗散减少；建立了稳定性与耗散之间的关系；证明了在临界电压附近，有限尺寸涨落导致临界电压以下出现噪声诱导振荡，且退相干时间随系统尺寸呈亚线性缩放。

Conclusion: CMOS环形振荡器在振荡起始点附近表现出独特的热力学行为，振荡状态下的熵耗散减少与局部稳定性增加相关，有限尺寸效应在临界区域显著影响振荡特性，这些发现对理解纳米尺度振荡器的热力学行为具有重要意义。

Abstract: We analyze a thermodynamically consistent model of CMOS-based ring oscillators near the onset of coherent voltage oscillations. For driving voltages close to the critical value, we derive the normal form of the Hopf bifurcation that underlies the oscillation transition in the thermodynamic limit. Using this normal form, we determine the phase and amplitude dynamics, and demonstrate that entropy dissipation decreases in the oscillating state for ring oscillators with more than three inverters. These findings culminate in a stability-dissipation relation, which links the observed decrease in dissipation to an increase in the local stability of the oscillating state. Next, we characterize finite-size fluctuations of the amplitude and phase near the critical voltage, using a stochastic version of the normal form. We demonstrate that close to the transition, finite-size fluctuations remain important at arbitrary system size, introducing oscillations even below the critical voltage. We further show that these noise-induced oscillations have an anomalously short decoherence time that scales sub-linearly with the system-size, in contrast to the behavior far from criticality.

</details>


### [183] [First Passage Resetting Gas](https://arxiv.org/abs/2512.00440)
*Marco Biroli,Satya N. Majumdar,Gregory Schehr*

Main category: cond-mat.stat-mech

TL;DR: 研究N个布朗粒子在一维扩散中的集体重置动力学：当任一粒子到达阈值L时，所有粒子同时重置，形成非平衡稳态并产生强长程关联。


<details>
  <summary>Details</summary>
Motivation: 探索多粒子系统中通过集体重置机制产生的非平衡稳态，研究无内置相互作用下仅通过动力学产生的强关联现象。

Method: 建立N个布朗粒子的一维扩散模型，当任一粒子到达固定阈值L时，所有粒子同时重置，分析系统的长时间行为和非平衡稳态。

Result: 系统达到可解析的非平衡稳态，具有强长程关联；精确计算了平均密度分布、有序粒子位置分布、粒子间隙分布以及原点附近有限区间内粒子数的全计数统计。

Conclusion: 集体重置机制可在无内置相互作用的多粒子系统中产生强长程关联，形成可解析的非平衡稳态，为研究非平衡统计物理提供了新范例。

Abstract: We study a one-dimensional gas of $N$ Brownian particles that diffuse independently but are simultaneously reset whenever any of them reaches a fixed threshold located at $L > 0$. For any $N > 2$, the system reaches a non-equilibrium stationary state (NESS) at long-times with strong long-range correlations. These correlations emerge purely from the dynamics, and not from built-in interactions. Despite being strongly correlated, the NESS has a solvable structure that allows for an exact computation of several physical observables, both global and local. These include the average density profile, the distribution of the position of the $k$-th ordered particles, the distribution of the gap between two consecutive particles and the full counting statistics, i.e., the distribution of the number of particles in a finite interval around the origin.

</details>


### [184] [Universal asymptotic solution of the Fokker-Planck equation with time-dependent periodic potentials](https://arxiv.org/abs/2512.00559)
*Boxuan Han,Zeyu Rao,Ming Gong*

Main category: cond-mat.stat-mech

TL;DR: 该研究将布朗运动推广到时变周期势场中，发现概率分布函数的渐近解具有普适形式：玻尔兹曼权重乘以高斯包络函数。


<details>
  <summary>Details</summary>
Motivation: 布朗运动作为统计物理学中最基本的概念之一，在静态势场中已被广泛研究，但在时变周期势场中的物理特性远未得到充分理解。研究者希望将布朗运动推广到这一新领域，探索其普适特性。

Method: 1. 推导概率分布函数渐近解的普适形式：玻尔兹曼权重乘以高斯包络函数；2. 建立玻尔兹曼权重的偏微分方程；3. 通过精确可解模型验证解的有效性；4. 对含时变倾斜势的周期势，通过数值求解偏微分方程确定玻尔兹曼权重；5. 通过数值求解朗之万方程验证结果。

Result: 1. 证明了时变周期势场中布朗运动的概率分布函数渐近解具有普适形式；2. 发现许多不同的势场可以给出相同的玻尔兹曼权重；3. 精确可解模型验证了理论解的有效性；4. 数值求解证实了理论预测；5. 福克-普朗克方程的渐近解满足热力学定律。

Conclusion: 该研究将布朗运动扩展到时变周期势场，发现了概率分布函数渐近解的普适形式，这一结果可广泛应用于准周期势、二维势场乃至含惯性模型，极大地拓宽了人们对布朗运动的理解视角。

Abstract: Brownian motion, as one of the most fundamental concepts in statistical physics, has everlasting interests in interdisciplinary fields in the past century. Although this motion with static potentials have been widely explored, its physics in time-dependent periodic potentials are far less well understood. Here we generalize this motion to the realm of time-dependent periodic potentials, showing that the asymptotic solution of the probability distribution function (PDF) can have a universal form, that is, a Boltzmann weight multiplied by a Gaussian envelope function. We derive a partial equation for this Boltzmann weight and demonstrate that many different potentials can give the same Boltzmann weight. We first present an exact solvable model to illustrate the validity of our solution. For the periodic potential with a time-dependent tilt potential, we can determine the Boltzmann weight by numerical solving the partial equation. These results are confirmed by solving the Langevin equation numerically. With this idea, we can determine the asymptotic solution of the Fokker-Planck equation, in which the entropy satisfies the thermodynamic law. Our results can have wide applications, including quasi-periodic potentials, two-dimensional potentials and even with models with inertia, which should greatly broaden our perspective of Brownian motion.

</details>


### [185] [Scaling of a Mutual-Information Distance in One-dimensional Quantum Spin Chains](https://arxiv.org/abs/2512.00649)
*Beau Leighton-Trudel*

Main category: cond-mat.stat-mech

TL;DR: 该论文提出了一种基于互信息的几何标度关系，通过定义几何转换因子G来量化局部尺度行为，并建立了G与互信息I的幂律关系，为识别标度体系提供了坐标无关的方法。


<details>
  <summary>Details</summary>
Motivation: 传统幂律分析中存在非普适振幅和拟合选择带来的模糊性，需要一种坐标无关的方法来识别标度体系并减少这些不确定性。

Method: 引入几何标度关系，定义信息距离d_E = K_0/√I和几何转换因子G ≡ ∂_r d_E，建立G ∝ I^κ的关系。通过DMRG模拟1D XXZ链和XX模型的精确结果进行验证。

Result: 对于幂律相关系统I(r) ∼ r^{-X}，度量标度指数κ = 1/X - 1/2。几何尺度G均匀（位置无关）当且仅当κ = 0，这发生在X = 2时。验证显示：1）在临界点（X≈2）时G(r)平坦，但在能隙态时变化强烈；2）在XX基准（X=2）下，logG与logI的斜率测试得到κ≈0。

Conclusion: 该方法提供了一种坐标无关的标度体系识别方法，减少了传统幂律分析中的模糊性，定义了一个可直接应用于数值或实验互信息数据的简单后处理流程。

Abstract: We introduce a geometric scaling relation that characterizes the local scale behavior of correlations using the informational distance $d_E = K_0/\sqrt{I}$, where $I$ is the mutual information. We define a geometric conversion factor, $G \equiv \partial_r d_E$, which quantifies the local scale. We show that $G$ relates directly to $I$ via $G \propto I^κ$. For systems with power-law correlations $I(r) \sim r^{-X}$, the metric scaling exponent is $κ= 1/X - 1/2$. A key consequence is that the geometric scale $G$ is uniform (position-independent) if and only if $κ= 0$, which occurs precisely at $X = 2$. This identifies $X = 2$ as the unique condition for a uniform and metric informational distance. We validate this relation using DMRG simulations of the 1D XXZ chain and exact results for the XX model. We demonstrate two falsifiable diagnostics: (i) $G(r)$ is flat in the bulk at criticality ($X \approx 2$) but varies strongly when gapped; (ii) a coordinate-agnostic slope test of $\log G$ versus $\log I$ at the XX benchmark ($X = 2$) yields $κ\simeq 0$. This approach provides a coordinate-independent method for identifying scaling regimes that helps to reduce ambiguity from non-universal amplitudes and from the fitting choices in standard power-law analyses, and defines a simple post-processing pipeline that can be applied directly to numerical or experimental mutual-information data.

</details>


### [186] [A mean-field theory of effective normal modes in the Fermi-Pasta-Ulam-Tsingou model](https://arxiv.org/abs/2512.00929)
*Antonio Ponno,Giacomo Gradenigo,Marco Baldovin,Angelo Vulpiani*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种用于FPUT模型（四次相互作用）的非微扰平均场理论，在热力学极限下捕捉系统在所有能量尺度上的准周期特征。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以处理FPUT模型在所有能量尺度（从准可积到强混沌）的非线性动力学行为，需要一种能够统一描述系统从低能到高能区域的理论框架。

Method: 从真实哈密顿量H出发，引入平均场哈密顿量ℋ，使得差值h_N=(H-ℋ)/N在概率意义上趋于零。平均场动力学由N个独立振荡模式组成，具有重整化频率Ω_k = ω_k√[1+γ(ε)]，其中γ(ε)是系统比能的显式函数。

Result: 理论预测与原始哈密顿动力学的数值数据成功比较，证实了这种简单分解在所有能量尺度上的有效性。有效朗之万方程能够准确描述振荡模式的动力学行为。

Conclusion: 该平均场理论为FPUT模型提供了一个统一的非微扰描述框架，能够从准可积区域到强混沌区域一致地捕捉系统的准周期特征，为理解非线性晶格系统的热化行为提供了新视角。

Abstract: We present a non-perturbative, mean-field theory for the Fermi-Pasta-Ulam-Tsingou model with quartic interaction, capturing the quasiperiodic features shown by the system at all energies in the thermodynamic limit. Starting from the true Hamiltonian $H$ of the system with $N$ degrees of freedom, we introduce a mean-field Hamiltonian $\mathcal{H}$ such that the difference $h_N=(H-\mathcal{H})/N$, considered as a random variable with respect to the Gibbs measure, tends to zero as $N\to\infty$, in probabilistic sense. The dynamics of the mean-field Hamiltonian $\mathcal{H}$ consists of $N$ independent oscillation modes with renormalized frequencies $Ω_k = ω_k\sqrt{1+γ(\varepsilon)}$, $ω_k$ being the frequency of the $k$-th normal mode of the linearized system, whereas $γ(\varepsilon)$ is an explicit function of the specific energy $\varepsilon$ of the system. Analytical predictions drawn from the effective Langevin equations ruling the dynamics of such oscillation modes are successfully compared with the numerical data from the original Hamiltonian dynamics. Such a simple decomposition of the true dynamics into $N$ effective normal modes holds at all energy scales, i.e. from the quasi-integrable regime to the strongly chaotic one.

</details>


### [187] [Canonical Distribution of the Occupancy Numbers of Bosonic Systems](https://arxiv.org/abs/2512.00950)
*Arnaldo Spalvieri*

Main category: cond-mat.stat-mech

TL;DR: 论文证明了玻色系统的占据数概率分布满足典型性，当从宇宙的典型纯态中通过迹掉环境得到系统的混合态时，占据数的概率分布渐近地趋向于多项分布。


<details>
  <summary>Details</summary>
Motivation: 当前关于固定粒子数系统的占据数概率分布与通常接受的规范系统概念不兼容，需要建立与规范典型性一致的占据数概率分布理论。

Method: 通过数学推导，从宇宙的典型纯态出发，通过迹掉环境得到系统的混合态，分析占据数的规范概率分布，证明其渐近性质。

Result: 玻色系统占据数的规范概率分布满足典型性，渐近地趋向于多项分布，这与当前接受的固定粒子数系统的占据数分布不同。

Conclusion: 规范典型性适用于占据数的规范密度算符，当前关于固定粒子数系统的占据数概率分布需要重新审视以与规范系统概念保持一致。

Abstract: The paper works out the canonical probability distribution of the occupancy numbers of a bosonic system and shows that canonical typicality applies to the canonical density operator of the occupancy numbers. The result is that, if, as it is today standard, the canonical system's mixed state is obtained by tracing out the environment from any typical pure state of the universe, then asymptotically the canonical probability distribution of system's occupancy numbers tends in probability to the multinomial distribution. The paper also shows that the currently accepted probability distribution of the occupancy numbers of a system with fixed number of particles is not compatible with the commonly accepted notion of canonical system.

</details>


### [188] [Adaptation to time-varying environments in a reaction-diffusion model](https://arxiv.org/abs/2512.01007)
*Olivier Rivoire,Guy Bunin*

Main category: cond-mat.stat-mech

TL;DR: 该研究提出了一个空间扩展的化学反应系统，能够适应随时间变化的反应物流入。适应被定义为一种局部稳定状态在空间上扩展并取代其他状态的能力，类似于改进的繁殖成功率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索基于物理原理的适应理论，将环境驱动和繁殖结合在随机反应扩散动力学框架中，为理解生物适应现象提供物理基础。

Method: 采用空间扩展的化学反应系统，在随机反应扩散动力学框架下，通过环境暴露于不同流入序列来研究适应现象。系统包含多个局部稳定状态，通过空间相互作用和自然选择机制实现适应。

Result: 研究发现：1）适应可以通过环境暴露于变化流入序列而产生；2）适应具有序列特异性但能推广到相关序列；3）重复暴露增强适应（学习形式）；4）空间相互作用促进自然选择（集体学习）；5）附近适应状态的存在有助于适应（教师引导学习）。

Conclusion: 该模型为基于物理原理的适应理论奠定了基础，展示了环境驱动和繁殖在随机反应扩散系统中如何共同产生适应现象，为理解生物适应提供了新的物理视角。

Abstract: We present a spatially-extended system of chemical reactions exhibiting adaptation to time-dependent influxes of reactants. Here adaptation is defined as improved reproductive success, namely the ability of one of the many locally stable states available to the system to expand in space at the expense of other states. We find that adaptation can arise simply by environmental exposure to sequences of varying influxes. This adaptation is specific to the temporal sequence yet flexible enough to generalize to related sequences. It is enhanced through repeated exposure to the same environmental sequence, representing a form of learning, and through spatial interactions, enabling natural selection to act and representing a form of collective learning. Finally, adaptation benefits from a nearby adapted state, representing a form of teacher-guided learning. By combining environmental drives and reproduction within a stochastic reaction-diffusion dynamics framework, our model lays a foundation for a theory of adaptation grounded in physical principles.

</details>


### [189] [Violation of the method of images in non-Markovian processes and its connection to stochastic thermodynamics](https://arxiv.org/abs/2512.01216)
*Takuya Saito,Yuta Sakamoto,Takahiro Sakaue*

Main category: cond-mat.stat-mech

TL;DR: 本文揭示了镜像法在描述具有记忆的扩散过程中概率分布时间演化时的失效，通过定义反射路径的共轭孪生路径，建立了类似涨落定理的路径概率比关系，为理解镜像法在非马尔可夫过程中的失效提供了热力学解释。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决广泛使用的镜像法在描述具有记忆的扩散过程中概率分布时间演化时的失效问题。作者发现对于非马尔可夫过程，镜像法无法准确描述概率分布，需要深入理解其失效机制。

Method: 方法包括：1）定义在随机演化中触及目标的路径及其反射路径的共轭孪生路径；2）证明这两种路径的概率比服从类似涨落定理的关系；3）将关键物理量识别为热量，从而为过程提供热力学解释。

Result: 研究结果表明：1）路径概率比确实服从类似涨落定理的关系；2）通过热力学解释，为镜像法在非马尔可夫过程中的失效提供了定量基础和直观物理图像；3）揭示了镜像法失效的根本原因与过程的记忆特性相关。

Conclusion: 结论是镜像法在非马尔可夫扩散过程中会失效，通过建立路径概率比的热力学解释，为理解这种失效提供了理论框架。这项工作不仅解释了为什么镜像法在具有记忆的过程中不适用，还提供了替代的物理图像来理解这类过程的演化。

Abstract: We discuss a failure of the wide-spread method of images solution to describe the time evolution of probability distribution in diffusive processes with memory. For a path that touches a target during stochastic evolution, we define its conjugate twin of reflected path, and show that their path probability ratio obeys a relation analogous to the fluctuation theorem. With a key quantity properly identified as the heat, the resultant thermodynamic interpretation of the processes provides a quantitative basis as well as an intuitive physical picture on how and why the method of images breaks down for non-Markovian processes.

</details>


### [190] [The stochastic discrete nonlinear Schrödinger equation: microscopic derivation and finite-temperature phase transition](https://arxiv.org/abs/2512.01448)
*Mahdieh Ebrahimi,Barbara Drossel,Wolfram Just*

Main category: cond-mat.stat-mech

TL;DR: 该研究提出了一维离散非线性薛定谔方程（DNSE）的随机版本，展示了无序局域化动力学、有限温度相变，以及噪声强度对粗化动力学的意外影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于理解DNSE的统计力学性质，特别是如何将负温度相变与实验装置中的正温度热浴耦合，为实验实现负温度相变提供线索。

Method: 从第一性原理推导出DNSE的随机版本，确保满足统计力学性质（如细致平衡和H定理），并采用平均场类型方法来定量描述相变。

Result: 随机版本表现出无序和局域化动力学，在有限温度值处显示相变；粗化动力学对噪声强度有意外依赖，类似于随机共振现象。

Conclusion: 该研究为实验实现负温度相变提供了重要线索，揭示了随机DNSE中相变与噪声强度的复杂关系，将负温度相变与正温度热浴耦合的实验设置联系起来。

Abstract: We study a stochastic version of the one-dimensional discrete nonlinear Schr{ö}dinger equation (DNSE), which is derived from first principles, and thus possesses all the properties required by statistical mechanics, such as detailed balance and the H-theorem. The stochastic version shows disordered and localised dynamics, and displays a corresponding phase transition at a finite temperature value. The phase transition can be captured in a quantitative way by a mean-field type approach. The corresponding coarsening dynamics shows an unexpected dependence on the noise strength, which is reminiscent of stochastic resonance. The phase transition is linked with negative temperature phase transitions, which have been reported recently for the Hamiltonian dynamics of the DNSE. Our approach gives a clue to how these negative temperature phase transitions can be implemented in experimental setups, which are inevitably coupled to a positive temperature heat bath.

</details>


### [191] [Path-integrals and optimal paths for the fractional Ornstein-Uhlenbeck process](https://arxiv.org/abs/2512.01464)
*Bing Miao,Gleb Oshanin,Luca Peliti*

Main category: cond-mat.stat-mech

TL;DR: 推导了由Riemann-Liouville分数高斯噪声驱动的分数Ornstein-Uhlenbeck过程的路径积分表示，包括亚扩散和超扩散两种状态，给出了两种等价的作用量表达式，并确定了到达固定时间点指定位置的最优路径。


<details>
  <summary>Details</summary>
Motivation: 研究分数Ornstein-Uhlenbeck过程的路径积分表示，这对于理解分数随机过程的动力学行为具有重要意义，特别是在亚扩散和超扩散状态下的非直观行为。

Method: 推导了分数Ornstein-Uhlenbeck过程的路径积分表示，得到了两种等价的作用量表达式：一种是分数积分形式，另一种是具有非局部核的双重积分形式。

Result: 获得了作用量的闭合形式表达式，确定了到达固定时间点指定位置的最优（作用量最小化）路径，并讨论了在强约束势下亚扩散过程的非直观行为。

Conclusion: 成功建立了分数Ornstein-Uhlenbeck过程的路径积分框架，揭示了分数随机过程在约束条件下的独特动力学特性，为相关研究提供了理论基础。

Abstract: We derive the path-integral representation of the fractional Ornstein-Uhlenbeck process driven by Riemann-Liouville fractional Gaussian noise, for both the subdiffusive and superdiffusive regimes. We express the corresponding action, which is a quadratic functional of individual trajectories of the process, in two alternative but equivalent forms: either as a fractional integral or as a double integral with a nonlocal kernel. Moreover, we determine in closed form the optimal (action-minimizing) paths conditioned to reach a prescribed point at a fixed time moment and discuss their behavior, which appears to be non-intuitive for subdiffusive processes in the presence of a strong confining potential.

</details>


### [192] [Quasistatic response for nonequilibrium processes: evaluating the Berry potential and curvature](https://arxiv.org/abs/2512.01654)
*Aaron Beyen,Faezeh Khodabandehlou,Christian Maes*

Main category: cond-mat.stat-mech

TL;DR: 该研究探讨了在稳态非平衡过程中引入缓慢时间依赖扰动如何改变重要观测量的期望值，如动力学活性和熵流。研究发现循环热力学变换中的超额值可以用几何Berry相描述，Berry势和Berry曲率量化了系统的响应。


<details>
  <summary>Details</summary>
Motivation: 研究非平衡过程中时间依赖扰动对系统行为的影响，特别是理解循环热力学变换中出现的几何Berry相及其对热力学关系的影响。

Method: 聚焦于马尔可夫跳跃过程，分析慢时间依赖扰动下的系统响应。使用Berry相、Berry势和Berry曲率等几何概念来描述循环变换中的超额值。

Result: 非零Berry曲率导致热力学麦克斯韦关系和克劳修斯热定理的失效。发现了类似Aharonov-Bohm效应的现象，即使Berry曲率为零，系统仍能经历非零Berry相。确定了在绝对零度下Berry势和曲率消失的充分非局域化条件。

Conclusion: 该研究揭示了非平衡过程中几何Berry相的重要作用，扩展了对热力学关系在时间依赖扰动下行为的理解，特别是在绝对零度附近的行为。

Abstract: We investigate how introducing slow, time-dependent perturbations to a steady, nonequilibrium process alters the expected (excess) values of important observables, such as the dynamical activity and entropy flux. When we make a cyclic thermodynamic transformation, the excesses are described in terms of a (geometric) Berry phase with corresponding Berry potential and Berry curvature quantifying the response. Focussing on Markov jump processes, we show how a non-zero Berry curvature leads to a breakdown of the thermodynamic Maxwell relations and of the Clausius heat theorem. We also present a variant of the Aharonov-Bohm effect in which the parameters follow a curve with vanishing Berry curvature, but the system still experiences a nonzero Berry phase. Finally, we identify (sufficient) no-localization conditions in terms of mean first-passage times under which the corresponding Berry potentials and curvatures vanish at absolute zero, extending, for arbitrary driving, e.g. the case of vanishing heat capacity as for the Nernst postulate.

</details>


### [193] [Digamma-Function Representation of the Ground-State Energy in Antiferromagnetic Heisenberg $\mathrm{XXX}_s$ Spin Chains](https://arxiv.org/abs/2512.01869)
*Reaz Shafqat*

Main category: cond-mat.stat-mech

TL;DR: 该论文提出了一个统一的解析表达式，用digamma函数表示任意自旋s的XXX海森堡链基态能量密度，统一了Takhtajan和Babujian分别针对整数和半整数自旋的两个有限级数表达式。


<details>
  <summary>Details</summary>
Motivation: 反铁磁海森堡自旋链是量子可积系统中研究精确可解模型的核心框架。对于各向同性的XXX链，自旋-1/2系统的基态能量密度已知为ln2。Takhtajan和Babujian将经典公式推广到任意自旋s，但分别针对整数和半整数自旋推导了两个独立的有限级数表达式。需要一种统一的表达式来涵盖所有情况。

Method: 引入一个统一的解析表达式，使用digamma函数来表示基态能量密度。这个紧凑的公式能够重现Takhtajan和Babujian的两个有限级数表达式。

Result: 成功推导出一个统一的digamma函数表达式，该表达式能够准确再现Takhtajan和Babujian分别针对整数和半整数自旋的两个有限级数表达式。

Conclusion: 通过引入digamma函数的统一表达式，成功解决了XXX海森堡链基态能量密度在整数和半整数自旋情况下的分离表示问题，提供了一个简洁而全面的解析公式。

Abstract: The antiferromagnetic Heisenberg spin chain remains a central framework for exploring exactly solvable models within quantum integrable systems. For the isotropic XXX chain, the ground-state energy per site of the spin-1/2 system is famously given by ln2. Extending the classic formulations to arbitrary spin-s, Takhtajan and Babujian derived two separate finite-series expressions for integer and half-integer spin representations. Current work introduces a unified analytical expression for the ground-state energy density in terms of the digamma function. This compact formulation reproduces both Takhtajan Babujian series.

</details>


### [194] [Thermodynamic Geometry Through Second Order Phase Transitions](https://arxiv.org/abs/2512.01936)
*Omer M. Basri,Oren Raz*

Main category: cond-mat.stat-mech

TL;DR: 论文研究相变附近缓慢驱动热力学过程中的过度耗散问题，发现某些情况下跨越相变的热力学长度保持有限，且最短路径可能穿越相变


<details>
  <summary>Details</summary>
Motivation: 传统方法使用控制参数空间的黎曼度量来量化缓慢驱动热力学过程中的过度耗散，但在相变附近这一几何框架会失效，因为度量会发散且测地线可能不存在。需要研究相变附近这一框架的行为。

Method: 使用Widom标度分析多个普适类，并开发数值方法计算此类系统中的最小路径

Result: 在某些情况下，跨越相变的热力学长度保持有限。在某些区域，最短路径会穿越相变，即使存在局限于单一相内的替代路径

Conclusion: 相变附近的热力学几何框架比预期更稳健，跨越相变的路径在某些情况下可能是最优选择，这对优化缓慢驱动过程有重要意义

Abstract: A common approach to quantify excess dissipation in slowly driven thermodynamic processes is through the use of a Riemannian metric on the space of control parameters, where optimal driving protocols follow geodesics. Near phase transitions, this geometric picture breaks down as the metric diverges and geodesics may cease to exist. Using Widom scaling, we analyze this framework for several universality classes and show that in some cases the thermodynamic length across the phase transition remains finite. We then demonstrate a numerical approach for computing minimal paths in such systems. We show that, in some regimes, the shortest path crosses the phase transition - even when alternative paths confined to a single phase exist.

</details>


### [195] [Piston-Like Information Engine I: Universal Features in Equilibrium](https://arxiv.org/abs/2512.01942)
*Rémi Goerlich,Gilad Pollack,Eli Flaxer,Saar Rahav,Yael Roichman*

Main category: cond-mat.stat-mech

TL;DR: 实验实现了一种基于信息的热机，通过测量胶体悬浮液中粒子的位置信息，在无需施加功的情况下压缩活塞，并从中提取机械功。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过测量热系统的随机自由度来从平衡热浴中提取能量，这是麦克斯韦妖和信息引擎的基本原理。

Method: 实验实现了一个微观信息引擎，配置为包含热化胶体悬浮液的可压缩活塞。记录粒子位置以识别靠近壁面的预定区域何时为空，从而在不施加功的情况下压缩胶体悬浮液。

Result: 发现存储的压缩能量普遍由正测量结果的概率决定，该概率受密度和压缩步长等参数控制。进一步证明在活塞减压过程中可以提取机械功，从而完成引擎的操作循环。

Conclusion: 成功实现了基于信息测量的微观热机，验证了通过测量热系统随机自由度从热浴中提取能量的可行性，并建立了压缩能量与测量概率之间的普遍关系。

Abstract: The ability to measure the stochastic degrees of freedom of a thermal system enables the extraction of energy from an equilibrium heat bath. This is the underlying principle of Maxwell's demon and subsequent information engines. Here, we experimentally realize a microscopic information engine configured as a compressible piston containing a thermalized colloidal suspension. The particle positions are recorded to identify when a predefined region near the wall is empty, allowing the piston to compress the colloidal suspension without applying work on the system. We find that the stored compression energy is universally set by the probability of a positive measurement outcome, which in turn is controlled by parameters such as density and compression step size. We further demonstrate that mechanical work can be extracted during the decompression of the piston, thereby closing the engine's operating cycle.

</details>


### [196] [Spontaneous Symmetry Breaking in Two-dimensional Long-range Heisenberg Model](https://arxiv.org/abs/2512.01956)
*Dingyun Yao,Tianning Xiao,Zhijie Fan,Youjin Deng*

Main category: cond-mat.stat-mech

TL;DR: 该研究通过大规模蒙特卡洛模拟和长程随机行走模型，揭示了长程相互作用海森堡模型在二维和三维中的相变和低温行为，提出了描述长程统计系统相变和低温性质的一般准则。


<details>
  <summary>Details</summary>
Motivation: 研究长程相互作用系统（1/r^(d+σ)）的性质如何随σ变化，验证Sak准则和扩展Mermin-Wagner定理的预测，理解长程相互作用对系统临界和低温行为的影响。

Method: 1. 对二维长程海森堡模型进行大规模蒙特卡洛模拟（线性尺寸L=8192）；2. 引入长程简单随机行走模型（LR-SRW），总行走长度固定在O(L^d)以满足统计系统的广延性；3. 结合两种方法分析系统行为。

Result: 1. 当σ≤2时，二维长程海森堡系统通过单一连续相变表现出自发对称性破缺，并形成一般长程序；2. LR-SRW模型能准确描述二维和三维长程海森堡模型的低温标度行为（由Goldstone模涨落引起）；3. 基于LR-SRW的见解，提出了描述任意空间维度中具有连续对称性的长程统计系统相变和低温性质的一般准则。

Conclusion: 长程相互作用显著影响系统的相变和低温行为，LR-SRW模型为理解长程统计系统提供了有效工具，提出的新准则能更全面地描述这类系统的性质演化。

Abstract: The introduction of decaying long-range (LR) interactions $1/r^{d+σ}$ has drawn persistent interest in understanding how system properties evolve with $σ$. The Sak's criterion and the extended Mermin-Wagner theorem have gained broad acceptance in predicting the critical and low-temperature (low-T) behaviors of such systems. We perform large-scale Monte Carlo simulations for the LR-Heisenberg model in two dimensions (2D) up to linear size $L=8192$, and show that, as long as for $σ\leq 2$, the system exhibits spontaneous symmetry breaking, via a single continuous phase transition, and develops a generic long-range order. We then introduce an LR simple random walk (LR-SRW) with the total walk length fixed at O($L^d$), satisfying the extensivity of statistical systems, and observe that the LR-SRW can faithfully characterize the low-T scaling behaviors of the LR-Heisenberg model in both 2D and 3D, as induced by Goldstone-mode fluctuations. Finally, based on insights from LR-SRW, we propose a general criterion for the phase transition and the low-T properties of LR statistical systems with continuous symmetry in any spatial dimension.

</details>


### [197] [Dilute Limit Coarsening with an Anisotropic Surface Tension](https://arxiv.org/abs/2512.01990)
*Arjun R. Anand,Melinda M. Andrews,Benjamin P. Vollmayr-Lee*

Main category: cond-mat.stat-mech

TL;DR: 各向异性表面张力对稀相分离后期动力学的影响：虽然液滴生长仍遵循t^{1/3}规律，但形态普遍性被破坏，液滴形状随尺寸变化，尺寸分布也发生改变。


<details>
  <summary>Details</summary>
Motivation: 重新审视经典的Lifshitz-Slyozov理论，该理论传统上假设表面张力是各向同性的。研究各向异性表面张力对稀相分离后期动力学的影响，探索各向异性如何改变相分离过程的形态演化。

Method: 采用微扰处理方法处理弱各向异性情况，计算非平衡液滴形状和尺寸分布的变化。通过理论分析推导各向异性表面张力下的动力学方程。

Result: 虽然特征性的t^{1/3}液滴生长规律保持不变，但各向异性导致形态普遍性显著破坏。计算得到依赖于缩放液滴尺寸的单参数非平衡液滴形状族，这些形状接近平衡Wulff形状，但较小液滴更接近球形，较大液滴的各向异性比Wulff形状更强。液滴尺寸分布在各向异性强度的二阶项上偏离各向同性LS分布。

Conclusion: 各向异性表面张力在保持基本生长规律的同时，显著改变了稀相分离后期的形态演化和尺寸分布，破坏了传统LS理论中的形态普遍性，为理解各向异性材料中的相分离过程提供了新的理论框架。

Abstract: We investigate the impact of an anisotropic surface tension on the late-stage dilute phase separation dynamics, revisiting the seminal Lifshitz-Slyozov (LS) theory, which traditionally relies on the assumption of isotropic surface tension. Using a perturbative treatment for weak anisotropy, we demonstrate that although the characteristic $t^{1/3}$ drop growth law remains unchanged, the anisotropy causes a significant breakdown of morphological universality. Specifically, we calculate explicitly a one-parameter family of nonequilibrium drop shapes that depend on the scaled drop size. These shapes are close to the equilibrium Wulff shape, but the smaller drops are more spherical and the larger drops have an enhanced anisotropy in comparison to the Wulff shape. We also demonstrate that the the drop size distribution is modified from the isotropic LS distribution at second order in the anisotropy strength.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [198] [Circular current induced by angular dynamics in swarmalator populations](https://arxiv.org/abs/2512.01345)
*Hyun Keun Lee,Hyunsuk Hong*

Main category: nlin.AO

TL;DR: 提出改进的swarmalator模型，通过引入相位依赖的空间驱动项，在相位同步中产生集体旋转流


<details>
  <summary>Details</summary>
Motivation: 在原始swarmalator模型基础上，探索如何生成集体旋转电流，研究相位同步与空间运动的耦合机制

Method: 修改原始swarmalator模型，用依赖于相位和指定原点的简单驱动项替换空间动力学中的相位依赖项；通过数值模拟研究固定原点和动态原点两种情况下的系统行为

Result: 固定原点时，从随机初始条件中涌现出螺旋运动，形成集体电流；动态原点时，系统演化为稳定的旋转集体电流，形成圆形模式；两种情况下都观察到无电流状态；通过调整相位变量可以促进集体电流的形成

Conclusion: 改进的swarmalator模型能够有效产生集体旋转电流，为理解相位同步与集体运动之间的耦合提供了新视角

Abstract: We propose a modified swarmalator model that generates collective rotational currents in phase synchronization. Our approach builds on the original swarmalator model [4], introducing a key modification: the phase-dependent terms in the spatial dynamics are replaced with a simpler driving term that depends on both the phase and a specified origin. We investigate the dynamics of this model through extensive numerical simulations. When the origin is fixed, spiral motions of synchronized and clustered swarmalators emerge from a finite fraction of random initial conditions, resulting in collective currents. To prevent the unrealistic divergence of these spirals, we introduce a dynamic origin, defined as the center of the swarmalators' positions. With this dynamic origin, the system evolves into rotating collective currents, where synchronized swarmalators form stable circular patterns. In both the fixed and dynamic origin cases, we also observe no-current states, in which synchronized swarmalators aggregate near the origin. Finally, we find that the formation of collective currents can be facilitated by tuning the phase variables either at initialization or during the system's evolution.

</details>


### [199] [Qualitatively distinct mechanisms of noise-induced escape in diffusively coupled bistable elements](https://arxiv.org/abs/2512.01388)
*Hidemasa Ishii,Hiroshi Kori*

Main category: nlin.AO

TL;DR: 该论文研究了扩散耦合双稳态系统中噪声诱导逃逸的三种不同机制，这些机制由耦合强度决定，而非无噪声系统的分岔。


<details>
  <summary>Details</summary>
Motivation: 分析双稳态元素集合中的噪声诱导逃逸具有挑战性，因为非线性、耦合和噪声都起着重要作用。需要理解这三种因素如何相互作用产生不同的逃逸机制。

Method: 推导了三种耦合强度下的有效一维动力学：弱耦合下的非线性平均场Fokker-Planck方程、强耦合下的随机平均场动力学、以及中间耦合下的确定性平均场动力学。通过数值模拟验证这些简化描述。

Result: 识别了三种不同的逃逸机制，每种机制对应不同的主导驱动因素。这些机制源于非线性、扩散耦合和动态噪声的相互作用，而非无噪声系统的分岔。

Conclusion: 该方法为其他扩散耦合随机非线性系统提供了一个框架，激励进一步寻找类似的协同现象。

Abstract: The analysis of noise-induced escape in ensembles of bistable elements is challenging, because nonlinearity, coupling, and noise all play essential roles. We show that the interplay of these three factors yields three qualitatively distinct escape mechanisms in diffusively coupled bistable elements, depending on the coupling strength. To clarify the relation between coupling strength and mean escape time, we derive effective one-dimensional dynamics: nonlinear mean-field Fokker-Planck equation in the weak-coupling regime, stochastic mean-field dynamics in the strong-coupling regime, and deterministic mean-field dynamics in the intermediate regime. We validate these reduced descriptions by comparing predictions with numerical simulations. We identify a distinct dominant driving factor of escape processes in each regime. Notably, the three escape mechanisms emerge through the interplay of nonlinearity, diffusive coupling, and dynamical noise -- rather than bifurcations of the noise-free system. Our approach serves as a framework applicable to other diffusively coupled stochastic nonlinear systems, motivating a further search for similar synergistic phenomena.

</details>


<div id='physics.data-an'></div>

# physics.data-an [[Back]](#toc)

### [200] [Coincidence Algebra Bundle for Decay Quivers: An Algebraic Approach to Gamma-ray Spectroscopy](https://arxiv.org/abs/2512.00095)
*Liam Schmidt*

Main category: physics.data-an

TL;DR: 该论文提出使用箭图（quiver）和路径代数来建模衰变方案，通过定义衰变箭图和巧合代数来计算伽马射线能谱学中的级联衰变概率。


<details>
  <summary>Details</summary>
Motivation: 伽马射线能谱学需要更全面的代数结构来计算一般衰变方案的巧合概率，传统方法使用的转移矩阵代数结构不够通用。

Method: 将衰变方案建模为箭图，定义衰变箭图，使用路径代数作为基础代数结构。扩展路径代数以允许非可组合路径的乘法，定义巧合代数，并将其实现为巧合代数丛的纤维。

Result: 建立了衰变方案的代数框架，衰变方案位于路径代数的基础空间中，其巧合概率在对应的纤维上计算。定义了检测映射，将转移概率映射到检测概率。

Conclusion: 箭图路径代数为衰变方案提供了更通用的代数结构，巧合代数框架能够系统计算级联衰变概率，为伽马射线能谱学提供了新的数学工具。

Abstract: Motivated by the need for a more comprehensive algebraic structure to calculate coincidence probabilities of a general decay scheme for gamma ray spectroscopy, we model the decay scheme, rather naturally, as a quiver through which we define a decay quiver. The path algebra of quivers is the underlying, more general, algebra for transition matrices that is typically used in modeling decay schemes. The path algebra allows for concatenation of transitions which affords the calculation of cascade probabilities. We extend the path algebra to allow for the multiplication of non-composable paths, i.e., transition that don't directly share a level connecting them. We define the coincidence algebra as the algebra that allows for such an extension and realize it as the fibres for a coincidence algebra bundle, the base space of which is the path algebra where decay schemes live. A given decay schemes coincidence probabilities are calculated on its fibre. \textit{Detection maps} are defined as linear maps on the base space that map transition probabilities to detected probabilities.

</details>


### [201] [Analysis framework for higher-order temporal correlations with applications to human heartbeats](https://arxiv.org/abs/2512.01235)
*Tibebe Birhanu,Hang-Hyun Jo*

Main category: physics.data-an

TL;DR: 提出基于爆发树分解的时间序列分析框架，专注于事件序列中超越事件间隔分布的高阶时间相关性，应用于健康与心脏病患者的心跳时间序列分析。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列分析主要关注事件间隔分布，但忽略了更高阶的时间相关性。本文旨在开发一个能够全面揭示事件序列中多层次时间相关性的分析框架。

Method: 采用爆发树分解方法，将事件序列精确映射到树结构（爆发树），其中每个内部节点代表在特定时间尺度上连续爆发的合并。通过爆发树量化高阶时间相关性，包括爆发复杂性、爆发记忆系数、爆发合并核的主截面和次截面等新老度量指标。

Result: 该框架成功应用于健康人群和心脏病患者的心跳时间序列分析，揭示了生理时间序列中不同的多尺度时间特性。

Conclusion: 爆发树分解方法为分析事件序列中的高阶时间相关性提供了有效框架，能够揭示传统方法无法检测到的多层次时间结构差异，在生理时间序列分析中显示出应用价值。

Abstract: We propose a time series analysis framework focused on higher-order temporal correlations in the event sequence beyond the interevent time distribution by employing the burst-tree decomposition method. Bursts are clustered events that rapidly occur within shorter time periods, and they are separated by relatively longer inactive periods. The burst-tree decomposition method exactly maps the event sequence onto a tree, called a burst tree, in which each internal node represents a merge of consecutive bursts at the timescale separating those bursts. The burst tree fully reveals the hierarchical structure of bursts, hence the higher-order temporal correlations for the entire range of timescales. Those correlations are quantified using novel and existing measures derived from the burst tree, such as the burst complexity, memory coefficient for bursts, and principal and secondary cross sections of the burst-merging kernel. We apply our framework to the heartbeat time series of healthy people and of those with heart disease to reveal distinct multiscale temporal properties in physiological time series.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [202] [Tailoring Bell inequalities to the qudit toric code and self testing](https://arxiv.org/abs/2512.00146)
*Eloïc Vallée,Owidiusz Makuta,Patrick Emonts,Rhine Samajdar,Jordi Tura*

Main category: quant-ph

TL;DR: 该论文提出了一个为奇素数维度Z_d环面码构建贝尔不等式的通用框架，实现了对量子拓扑物质的无设备认证，并首次展示了三能级量子比特子空间的自测试。


<details>
  <summary>Details</summary>
Motivation: 贝尔非定域性为高效认证量子态提供了稳健可扩展的途径。本文旨在为拓扑量子物质（特别是Z_d环面码）开发无设备认证工具，这对于量子纠错码和量子模拟平台的验证至关重要。

Method: 作者构建了一个通用框架：1）选择合适的稳定子算子子集；2）将其映射到广义测量可观测量；3）计算多体贝尔表达式，其量子最大值允许平方和分解；4）通过组合平铺论证和显式优化确定经典（局域）界限。

Result: 1）构建的贝尔不等式被Z_d环面码的所有基态流形最大违反；2）以d=3为例，最大违反自测试了完整的三能级环面码子空间（局部等距和复共轭下）；3）提出了增强经典-量子界限比率的方案以提高实验鲁棒性。

Conclusion: 该工作为高度纠缠拓扑量子物质的无设备认证建立了途径，为验证量子纠错码和量子模拟平台中的量子比特态提供了新工具，并首次实现了三能级量子比特子空间的自测试。

Abstract: Bell nonlocality provides a robust scalable route to the efficient certification of quantum states. Here, we introduce a general framework for constructing Bell inequalities tailored to the $\mathbb{Z}_d$ toric code for odd prime local dimensions. Selecting a suitable subset of stabilizer operators and mapping them to generalized measurement observables, we compute multipartite Bell expressions whose quantum maxima admit a sum-of-squares decomposition. We show that these inequalities are maximally violated by all states in the ground-state manifold of the $\mathbb{Z}_d$ toric code, and determine their classical (local) bounds through a combination of combinatorial tiling arguments and explicit optimization. As a concrete application, we analyze the case of $d=3$ and demonstrate that the maximal violation self-tests the full qutrit toric-code subspace, up to local isometries and complex conjugation. This constitutes, to our knowledge, the first-ever example of self-testing a qutrit subspace. Extending these constructions, we further present schemes to enhance the ratio of classical--quantum bounds and thus improve robustness to experimental imperfections. Our results establish a pathway toward device-independent certification of highly entangled topological quantum matter and provide new tools for validating qudit states in error-correcting codes and quantum simulation platforms.

</details>


### [203] [On the Dynamics of Multiparticle Carroll-Schrdinger Quantum Systems](https://arxiv.org/abs/2512.00247)
*José Rojas,Melvin Arias*

Main category: quant-ph

TL;DR: 本文研究了1+1维多粒子Carroll-Schrödinger量子系统的动力学，探讨了时间作为配置坐标的特殊性质，建立了从相对论多时间Klein-Gordon模型到Carroll极限的映射，并分析了时间域中的交换对称性、二次量子化以及Carrollian Hohenberg-Kohn映射。


<details>
  <summary>Details</summary>
Motivation: 研究Carroll-Schrödinger量子系统的动机在于探索当光速趋于零时（Carroll极限）的量子动力学特性，特别是时间作为配置坐标而非演化参数的特殊情况。这种极限下的系统展现出超局域性等独特性质，对理解极端相对论极限下的量子行为具有重要意义。

Method: 方法包括：1）从相对论多时间Klein-Gordon模型推导Carroll极限下的N体理论；2）通过x依赖的规范变换将时间相互作用映射为显式多体势；3）采用空间视角分析集体动力学；4）构造坐标对偶映射将可分离Schrödinger哈密顿量映射到CS生成元；5）在时间域中表述交换对称性；6）通过二次量子化得到时间导数立方-五次非线性Schrödinger方程；7）建立与一维电流密度泛函理论的同构关系。

Result: 主要结果：1）证明了对于任何平移不变相互作用，内部力相互抵消，集体动力学是自由的，体现了Carroll超局域性；2）时间耦合振子模型展现出同步现象；3）在时间域中，玻色子表现出时间聚束，费米子表现出时间反聚束；4）接触极限下得到非线性系数β=-3/16的时间导数立方-五次非线性Schrödinger方程；5）建立了Carrollian Hohenberg-Kohn映射和Kohn-Sham方案。

Conclusion: 结论：Carroll-Schrödinger量子系统在1+1维中展现出丰富的物理特性，包括时间作为配置坐标的特殊动力学、超局域性、时间域中的量子统计效应，以及与密度泛函理论的深刻联系。这些结果为理解极端相对论极限下的量子多体系统提供了新的理论框架。

Abstract: We study the dynamics of multiparticle Carroll-Schrödinger (CS) quantum systems in $1{+}1$ dimensions, where $x$ acts as the evolution variable and $t$ as the configuration coordinate. We derive the $N$-body theory on equal-$x$ slices as the Carrollian limit of a relativistic multi-time Klein-Gordon model, introducing temporal interactions via minimal coupling to the temporal energy operators. An $x$-dependent gauge transformation maps this to an equivalent description with explicit many-body potentials, illustrated by a temporal coupled-oscillator model that exhibits synchronization. Adopting a complementary spatial viewpoint with a static potential $U_{\!tot}(\mathbf x)$, we show that the evolution is driven by the collective force $\sum_j\partial_{x_j}U_{\!tot}$; for any translation-invariant interaction (such as a regularized Coulomb potential), these internal forces cancel, rendering the collective dynamics free and highlighting Carrollian ultralocality. We also construct a coordinate duality mapping separable Schrödinger Hamiltonians to CS generators via Schwarzian derivatives. Exchange symmetry is formulated in the time domain, yielding temporal bunching for bosons and antibunching for fermions via the second-order coherence function $g^{(2)}(t,t')$. In second quantization, the contact limit yields a temporal derivative cubic--quintic nonlinear Schrödinger equation with a theoretically fixed nonlinearity coefficient $β=-3/16$. Finally, by coupling canonical pairs to external scalar and gauge fields, we establish an isomorphism with one-dimensional current-density functional theory, outlining a Carrollian Hohenberg-Kohn mapping and Kohn-Sham scheme.

</details>


### [204] [Four-body interactions in Kerr parametric oscillator circuits](https://arxiv.org/abs/2512.00446)
*Yohei Kawakami,Tomohiro Yamaji,Aiko Yamaguchi,Yuya Kano,Takaaki Aoki,Aree Taguchi,Kiyotaka Endo,Tetsuro Satoh,Ayuka Morioka,Yuichi Igarashi,Masayuki Shirane,Tsuyoshi Yamamoto*

Main category: quant-ph

TL;DR: 提出基于Kerr参量振荡器的新型四体相互作用单元电路，采用LHZ方案实现全连接逻辑Ising自旋的可扩展嵌入，并通过实验验证了四体相关性和量子退火演示。


<details>
  <summary>Details</summary>
Motivation: 传统使用非线性耦合器的KPO单元电路制造和表征复杂，需要开发更简单的电路结构来实现四体相互作用，以便在LHZ方案中实现全连接逻辑Ising自旋的可扩展嵌入。

Method: 设计新型KPO单元电路，采用线性耦合器实现四体相互作用；通过数值计算验证耦合常数强度；设计四KPO电路并实验测量四体相关性；通过泵浦频率选择来消除不想要的相互作用；基于LHZ方案实现量子退火。

Result: 新型电路制造和表征比传统电路简单；数值计算显示耦合常数强度与传统电路相当；实验成功验证了四体相关性；通过泵浦频率选择有效消除了不想要的相互作用；成功演示了基于LHZ方案的量子退火。

Conclusion: 提出的新型KPO单元电路能够简化制造过程，有效实现四体相互作用，为基于LHZ方案的全连接逻辑Ising自旋系统提供了可行的实现途径，并成功演示了量子退火应用。

Abstract: We theoretically present new unit circuits of Kerr parametric oscillators (KPOs) with four-body interactions, which enable the scalable embedding of all-to-all connected logical Ising spins using the Lechner-Hauke-Zoller (LHZ) scheme. These unit circuits enable four-body interactions using linear couplers, making the circuit fabrication and characterization much simpler than those of conventional unit circuits with nonlinear couplers. Numerical calculations indicate that the magnitudes of the coupling constants can be comparable to those in conventional circuits. On the basis of this theory, we designed a four-KPO circuit and experimentally confirmed the four-body correlation by measuring the pump-phase dependence of the parity of the four-KPO states. We show that the choice of the pump frequencies are important not only to enable the four-body interaction, but to cancel the effects of other unwanted interactions. Using the circuit, we demonstrated the quantum annealing based on the LHZ scheme, where the strength of the interaction between the logical Ising spins is mapped to the local field and controlled by a coherent drive applied to each KPO.

</details>


### [205] [Out-of-time correlation functions in single-body systems](https://arxiv.org/abs/2512.00471)
*Andrew C. Hunt*

Main category: quant-ph

TL;DR: 该研究探讨了量子混沌中OTOCs的增长率，特别是瞬子如何影响Maldacena界限的满足，并测试了RPMD方法是否足以维持该界限。研究发现RPMD存在反例，且瞬子在Matsubara动力学中表现出与RPMD预测不同的行为。


<details>
  <summary>Details</summary>
Motivation: 研究量子混沌中OTOCs增长率的Maldacena界限，理解瞬子在维持该界限中的作用，并测试RPMD方法是否足以满足该界限。同时探究相干性对OTOCs平坦化的影响，对比有界系统与散射系统的差异。

Method: 使用环聚合物分子动力学(RPMD)方法，并基于解析延拓的Matsubara动力学理论分析OTOCs。对比有界系统（对称双势阱）与散射系统，研究瞬子对OTOCs增长率的影响。通过理论分析和数值计算验证RPMD是否满足Maldacena界限。

Result: 1. 瞬子降低了OTOCs的增长率，有助于维持Maldacena界限；2. 发现RPMD存在反例，不足以满足该界限；3. 散射系统的OTOCs增长率显著低于类似的有界系统，且随时间推移趋于平坦；4. 基于Matsubara动力学的理论揭示了瞬子周围与RPMD预测显著不同的动力学行为；5. 瞬子在除集体角度Φ₀外的所有坐标中都是静止的，其涨落不再像RPMD中那样类似于经典鞍点动力学。

Conclusion: 瞬子在维持OTOCs的Maldacena界限中起关键作用，但RPMD方法本身不足以确保该界限的满足。散射系统与有界系统在OTOCs行为上存在显著差异，这归因于玻尔兹曼算子的影响和势能非谐性引起的干涉效应。Matsubara动力学理论为理解瞬子周围的量子动力学提供了新视角。

Abstract: In the study of quantum chaos, `out of time ordered correlators' (OTOCs) are commonly used to quantify the rate at which quantum information is scrambled. This rate has been conjectured by Maldecena et al. to obey a universal, temperature dependent bound. Recent studies have shown that instantons, delocalised structures that dominate tunnelling statistics over barriers, reduce the growth rate of OTOCs. For the case of the symmetric double well, this reduction ensures the bound is maintained for OTOCs generated using ring polymer molecular dynamics (RPMD), a method with approximate dynamics but exact quantum statistics. In this report we set out to further understand the role of the instanton in the enforcement of the Maldacena bound and test whether RPMD is sufficient to satisfy the bound. We also investigate the impact of coherence on the flattening of of OTOCs by contrasting bounded with scattering systems. For the scattering system we observe a significantly smaller OTOC growth rate than that of the analogous bounded system, and a flattening in growth rate as time progresses. We attribute the first effect to influence of the Boltzmann operator, and the second to interference caused by anharmonicity of the potential. In our studies of RPMD, we find counterexamples showing that it is not sufficient to satisfy the bound. We develop a theory for OTOCs using (analytically-continued) Matsubara dynamics, revealing significantly different dynamical behaviour around the instanton compared to the predictions of RPMD. The instanton is found to be stationary in all coordinates but its collective angle $Φ_0$, and fluctuations about it no longer resemble that of classical dynamics on a first order saddle as in RPMD.

</details>


### [206] [A Concatenated Dual Displacement Code for Continuous-Variable Quantum Error Correction](https://arxiv.org/abs/2512.00481)
*Fucheng Guo,Frank Mueller,Yuan Liu*

Main category: quant-ph

TL;DR: 该论文提出了一种结合高斯噪声抑制电路和外层模拟Steane码的连续变量量子纠错架构，用于同时抑制高斯位移误差和纠正晶格穿越事件，为容错连续变量量子计算提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 连续变量高斯不可行定理限制了仅使用高斯门和状态来抑制高斯位移误差的能力。虽然先前研究使用GKP态作为辅助量子模式来抑制小的高斯位移误差，但当位移幅度变大时，会出现超出GKP态可纠正范围的晶格穿越事件。需要一种能同时处理大小位移误差的纠错方案。

Method: 将高斯噪声抑制电路与外部模拟Steane码级联。Steane-GKP编码对偶性提供了互补保护：内部GKP态抑制小的高斯位移误差，外部模拟Steane码纠正偶尔发生的晶格穿越事件和其他突发位移误差。这种架构在连续编码空间内工作，不同于以往将GKP态与重复码级联用于离散量子比特或量子比特编码的方法。

Result: 在无限压缩条件下，级联编码可将所有量子模式的高斯位移误差方差抑制高达50%，同时实现对晶格穿越事件的无偏纠正。即使在有限压缩条件下，该架构仍能提供高斯误差抑制和晶格穿越纠正，且外部模拟Steane码的存在降低了内部GKP态的压缩要求，增强了实验可行性。

Conclusion: 这项工作为容错连续变量量子计算建立了一条可行路径，并为设计级联连续变量纠错架构提供了新见解。通过Steane-GKP对偶编码，实现了对大小位移误差的互补保护，在连续编码空间内进行纠错，具有近期的实验可行性。

Abstract: The continuous-variable (CV) Gaussian no-go theorem fundamentally limits the suppression of Gaussian displacement errors using only Gaussian gates and states. Prior studies have employed Gottesman-Kitaev-Preskill (GKP) states as ancillary qumodes to suppress small Gaussian displacement errors, but when the displacement magnitude becomes large, lattice-crossing events arise beyond the correctable range of the GKP state. To address this issue, we concatenate a Gaussian-noise-suppression circuit with an outer analog Steane code that corrects such occasional lattice-crossing events as well as other abrupt displacement errors. Unlike conventional concatenation, which primarily aims to reduce logical error rates, the Steane-GKP duality in encoding provides complementary protection against both large and small displacement errors, enabling CV error correction within the continuous encoding space and contrasting with earlier approaches that concatenate GKP states with repetition codes for discrete qubit or qudit encodings. Analytical results show that, under infinite squeezing, the concatenated code suppresses the variance of Gaussian displacement errors across all qumodes by up to 50 percent while enabling unbiased correction of lattice-crossing events, with a success probability determined by the ratio between the residual Gaussian error standard deviation and the lattice-crossing magnitude. Even with finite squeezing, the proposed architecture continues to provide Gaussian-error suppression together with lattice-crossing correction, and the presence of the outer analog Steane code relaxes the squeezing requirement of the inner GKP states, indicating near-term experimental feasibility. This work establishes a viable route toward fault-tolerant continuous-variable quantum computation and provides new insight into the design of concatenated CV error-correcting architectures.

</details>


### [207] [Local distinguishability of five orthogonal product states on bipartite and tripartite quantum systems](https://arxiv.org/abs/2512.00484)
*Guang-Bao Xu,Zi-Yan Hao,Hua-Kun Wang,Yu-Guang Yang,Dong-Huan Jiang*

Main category: quant-ph

TL;DR: 本文研究了五正交乘积态（OPSs）的局域可区分性问题，提出了正交关系向量概念来分类结构，并分析了二分和三分量子系统中五OPSs的局域可区分性。


<details>
  <summary>Details</summary>
Motivation: 尽管正交量子态的局域可区分性研究已有很多成果，但一些基本问题仍未有效解决，特别是五正交乘积态的局域可区分性至今未知。本研究旨在填补这一空白，丰富量子非局域性研究成果。

Method: 1. 提出二分OPSs的正交关系向量概念来表征结构；2. 将五二分OPSs结构分为六类，证明其中五类可通过LOCC完美区分；3. 分析第六类中每个情况的局域可区分性；4. 将五三分OPSs结构分为八类，并给出每类的局域可区分性。

Result: 1. 五二分OPSs的六类结构中，前五类可通过LOCC完美区分；2. 第六类需要单独分析每个情况的局域可区分性；3. 五三分OPSs的八类结构都给出了相应的局域可区分性结果。

Conclusion: 本研究系统地解决了五正交乘积态的局域可区分性问题，提出了正交关系向量这一有效工具，为理解量子非局域性提供了清晰框架，丰富了该领域的研究成果。

Abstract: Local distinguishability of orthogonal quantum states can effectively reduce the consumption of quantum resources and lower economic costs in quantum protocols. Although numerous achievements have been made regarding local distinguishability of orthogonal quantum states, some fundamental issues have not been effectively addressed. For example, the local distinguishability of five orthogonal product states (OPSs) is still unknown up to now. In this paper, we give the properties of local distinguishability of five OPSs on bipartite and tripartite quantum systems. Firstly, to characterize the structure of a set of bipartite OPSs, we propose the concept of the vector of orthogonal relations for a set of bipartite OPSs. Secondly, we classify the structures of five bipartite OPSs into six categories by this concept and prove that five of these six categories can be perfectly distinguished by local operations and classical communication (LOCC). Thirdly we show that the local distinguishability of each case of the sixth category singly. On the other hand, we first divide the structures of five tripartite OPSs into eight categories by the vectors of orthogonal relations of five tripartite OPSs. Then we give the local distinguishability of each category. Our work enriches the research results of quantum nonlocality and will provide a clear understanding of the local distinguishability of five OPSs.

</details>


### [208] [Quantum Sensing via Large Spin-Clusters in Solid-State NMR: Optimal coherence order for practical sensing](https://arxiv.org/abs/2512.00494)
*Conan Alexander,T S Mahesh*

Main category: quant-ph

TL;DR: 该研究利用固态NMR中的多量子相干技术进行量子传感，通过创建、操控和检测大团簇的核自旋关联，实现了对射频控制场脉冲宽度抖动的灵敏检测，并探索了高量子相干阶数在传感中的优化问题。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠长期以来被认为是量子传感的重要资源。本研究旨在探索固态核磁共振平台作为研究多体量子计量协议的测试平台，特别是利用多量子相干技术来增强传感灵敏度。

Method: 采用多量子固态核磁共振技术，创建、操控和检测大团簇的关联核自旋。通过分析高阶量子相干对控制场抖动的响应，研究增强灵敏度与退相干之间的关键相互作用。同时开发简化的数值模型来估计相应的量子费舍尔信息。

Result: 实验表明，这种自旋团簇能够灵敏地检测到数十纳秒级别的射频控制场脉冲宽度抖动。研究发现，即使在非均匀的相干阶分布中，也存在一个最优的最大相干阶数，能够最大化传感效率。数值模型结果支持了实验解释。

Conclusion: 该研究支持固态核磁共振平台作为研究多体量子计量协议的宝贵测试平台，展示了多量子相干技术在量子传感中的应用潜力，特别是在优化相干阶数分布以提高传感效率方面。

Abstract: Quantum entanglement has long been recognized as an important resource for quantum sensing. In this work, we demonstrate the use of multiple-quantum solid-state NMR for quantum sensing by creating, manipulating, and detecting large clusters of correlated nuclear spins. We show that such clusters can sensitively detect pulse-width jitters in radio-frequency control fields at the level of tens of nanoseconds. By analyzing the response of high-order quantum coherences to these control-field jitters, we investigate the critical interplay between the enhanced sensitivity offered by large coherence orders, their relative distributions, and their varying susceptibility to decoherence. We further demonstrate that, even within a non-uniform distribution of coherence orders, there exists an optimal maximum coherence order that maximizes sensing efficiency. To support our interpretation, we supplement the experimental results with a simplified numerical model that estimates the corresponding quantum Fisher information. These results support the solid-state NMR platform as a valuable testbed for investigating many-body quantum metrology protocols.

</details>


### [209] [On the EPR paradox in systems with finite number of levels](https://arxiv.org/abs/2512.00497)
*Henryk Gzyl*

Main category: quant-ph

TL;DR: 重新审视有限能级复合系统的EPR悖论，强调测量与条件概率的联系，指出测量后的量子态和概率分布依赖于所测可观测量，这对子系统性质预测有重要影响。


<details>
  <summary>Details</summary>
Motivation: 重新审视有限能级复合系统的EPR悖论，因为有限能级系统比连续情况更简单，避免了数学技术复杂性，同时物理解释相同，便于更清晰地分析测量与条件概率的关系。

Method: 通过分析有限能级复合系统，强调测量与条件概率之间的连接关系，研究测量如何影响量子态和概率分布，以及这对子系统性质预测的影响。

Result: 发现当进行测量时，新的量子态和概率分布成为所测量可观测量的函数；这对子系统性质预测至关重要，因为这些预测隐式地依赖于所测量的可观测量。

Conclusion: 有限能级复合系统的EPR悖论分析表明，测量与条件概率的密切联系意味着量子态和概率分布依赖于测量过程，这对理解子系统性质和量子力学基础有重要意义。

Abstract: In this work we reexamine the EPR paradox for composite systems with a finite number of levels. The analysis emphasizes the connection between measurements and conditional probabilities. This connection implies, on the one hand, that when a measurement is performed, the new quantum state and the probability distribution becomes a function of the observable being measured. On the other hand, this becomes important when making predictions about the properties of the subsystems, since the predictions are implicitly a function of the observable that was measured.
  Systems with finitely many levels are simpler to describe because the analysis is not encumbered by the mathematical technicalities of the continuous case, and the underlying physical interpretations are the same.

</details>


### [210] [Hybridization of pulse and continuous-wave based optical quantum computation](https://arxiv.org/abs/2512.00543)
*Tatsuki Sonoyama,Tomoki Sano,Takumi Suzuki,Kazuma Takahashi,Takefumi Nomura,Akito Kawasaki,Asuka Inoue,Takahiro Kashiwazaki,Takeshi Umeki,Masahiro Yabuno,Shigehito Miki,Hirotaka Terai,Kan Takase,Warit Asavanant,Mamoru Endo,Akira Furusawa*

Main category: quant-ph

TL;DR: 提出了一种脉冲与连续波混合架构的连续变量测量基光学量子计算，结合了脉冲光和连续波光的优势，用于实现高速、低损耗的量子信息处理。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统量子计算架构中脉冲光或连续波光单独使用的局限性，需要结合两者的优势：脉冲光能产生短波包的非高斯量子态，而连续波光能实现低损耗的量子态操作和测量。

Method: 采用脉冲与连续波混合架构：1) 使用脉冲光生成输入和辅助的非高斯量子态（实现容错和通用性所需）；2) 使用连续波光构建量子处理器，包括连续变量簇态和零差测量系统。

Result: 原理验证实验中，对脉冲光生成的单光子态进行了超快零差测量（使用连续波本地振荡器）。测得单光子态的时间宽度约为70 ps，原点处的Wigner函数值为W(0,0) = -0.153 +/- 0.003，表现出高度非经典特性。

Conclusion: 该混合架构有望同时实现短波包量子态生成和低损耗的量子态操作与测量，兼容超快和低损耗的量子信息处理，是实现高速光学量子信息处理的核心技术。

Abstract: We propose a pulse and continuous wave (CW) hybrid architecture of continuous-variable measurement-based optical quantum computation utilizing the strengths of both pulsed and CW light. In this architecture, input and ancillary non-Gaussian quantum states necessary for fault-tolerance and universality of quantum computing are generated with pulsed light, whereas quantum processors including continuous-variable cluster states and homodyne measurement systems are operated with CW light. This architecture is expected to enable both generation of quantum states with shorter optical wavepackets and low-loss manipulation and measurement of these states, thus is compatible with ultrafast and low-loss quantum information processing. In this study, as a proof-of-principle, an ultrafast homodyne measurement using CW local oscillator was performed on single-photon states generated with pulsed light. The measured single-photon state's temporal width was around 70 ps and the value of the Wigner function at the origin was W(0,0) = -0.153 +/- 0.003, which is highly non-classical. This will be a core technology for realizing high-speed optical quantum information processing.

</details>


### [211] [Optimized Many-Hypercube Codes toward Lower Logical Error Rates and Earlier Realization](https://arxiv.org/abs/2512.00561)
*Hayato Goto*

Main category: quant-ph

TL;DR: 研究探索了使用[[6,4,2]]和[[4,2,2]]码构建的更小规模多超立方码，发现D6,4,4在保持高编码率的同时能实现更低的块错误率，并开发了高效的容错编码器。


<details>
  <summary>Details</summary>
Motivation: 原始多超立方码(n=6)在高级联水平下块尺寸过大(216和1296物理量子比特)，导致实验实现困难且逻辑错误率高。需要寻找更小规模的多超立方码以实现早期实验实现和更低错误率。

Method: 通过级联[[6,4,2]]和/或[[4,2,2]]量子错误检测码构建更小的多超立方码，例如D6,4,4表示在第1层使用[[6,4,2]]码，在第2、3层使用[[4,2,2]]码。开发了高效的容错编码器，实现了约60%的开销减少。

Result: 发现D6,4,4(D6,6,4,4)相比D4,4,4(D4,4,4,4)能实现更低的块错误率，尽管其编码率更高。在第3层，高效容错编码器在保持甚至改善性能的同时减少了约60%的开销。数值模拟确认D6,4,4在电路级噪声模型中也能实现逻辑CNOT门的最佳性能。

Conclusion: 这些结果为使用高编码率量子码实现早期容错量子计算的实验提供了有用指导，展示了更小规模多超立方码在降低错误率和减少开销方面的优势。

Abstract: Many-hypercube codes [H. Goto, Sci. Adv. 10, eadp6388 (2024)], concatenated ${[[n,n-2,2]]}$ quantum error-detecting codes ($n$ is even), have recently been proposed as high-rate quantum codes suitable for fault-tolerant quantum computing. However, the original many-hypercube codes with ${n=6}$ have large code block sizes at high concatenation levels (216 and 1296 physical qubits per block at levels 3 and 4, respectively), making not only experimental realization difficult but also logical error rates high. Toward earlier experimental realization and lower logical error rates, here we investigate smaller many-hypercube codes obtained by concatenating $[[6,4,2]]$ and/or $[[4,2,2]]$ codes, where, e.g., $D_{6,4,4}$ denotes the many-hypercube code using $[[6,4,2]]$ at level 1 and $[[4,2,2]]$ at levels 2 and 3. As a result, we found a surprising fact: $D_{6,4,4}$ ($D_{6,6,4,4}$) can achieve lower block error rates than $D_{4,4,4}$ ($D_{4,4,4,4}$), despite its higher encoding rate. Focusing on level 3, we also developed efficient fault-tolerant encoders realizing about 60% overhead reduction while maintaining or even improving the performance, compared to the original design. Using them, we numerically confirmed that $D_{6,4,4}$ also achieves the best performance for logical controlled-NOT gates in a circuit-level noise model. These results will be useful for early experimental realization of fault-tolerant quantum computing with high-rate quantum codes.

</details>


### [212] [Physical Probability in the Everett Interpretation and Bell Inequalities](https://arxiv.org/abs/2512.00575)
*Simon Saunders*

Main category: quant-ph

TL;DR: 论文提出了一种局部因果性LOC概念，基于贝尔原理但允许两个漏洞：逆因果性和远程结果非唯一性，并展示了多世界解释如何利用这两个漏洞与LOC一致地违反贝尔不等式。


<details>
  <summary>Details</summary>
Motivation: 研究量子力学中的概率本质，特别是多世界解释如何与局部因果性相容，同时解释贝尔不等式的违反现象。

Method: 定义局部因果性LOC原则，分析其与贝尔原理的区别，识别两个关键漏洞（逆因果性和远程结果非唯一性），并构建适用于多世界解释的物理概率理论。

Result: 多世界解释中的概率理论与波恩规则一致，违反贝尔不等式，但通过利用LOC的两个漏洞与局部因果性保持相容。

Conclusion: 多世界解释中的概率不涉及超距作用，而观察到的贝尔不等式违反现象实际上为多世界解释提供了有力证据。

Abstract: I define a notion of local causality LOC closely modelled on the Bell principle, construed as the condition that single case probabilities cannot be modified by actions at spacelike separation. The new principle, like that of Bell, forces Bell inequalities, but with two loopholes: one is retrocausation, known to Bell, but the other is nonuniqueness of remote outcomes, a loophole only for LOC, not for the Bell principle. I also set out a theory of physical probability, applicable to the Everett interpretation, in agreement with the Born rule, and therefore violating Bell inequalities. I show it is consistent with LOC. Surprisingly, both loopholes are exploited. I conclude not only that probability in the Everett interpretation involves no action at a distance, but that the observed violations of Bell inequalities is powerful evidence for many worlds.

</details>


### [213] [Geometric Parameterization of Kraus Operators with Applications to Quasi Inverse Channels for Multi Qubit Systems](https://arxiv.org/abs/2512.00577)
*Zain Ateeq,Muhammad Faryad*

Main category: quant-ph

TL;DR: 提出一种基于Kraus表示的可微分几何参数化量子信道方法，通过机器学习优化寻找量子信道的拟逆信道


<details>
  <summary>Details</summary>
Motivation: 对于复杂噪声过程的量子信道，寻找其拟逆信道通常解析计算繁琐且参数范围有限，需要更高效的数值方法

Method: 将量子信道参数化为单位超球面上的单位向量，通过辛约束、正交性和单位长度保证信道的完全正性和保迹性，使用基于保真度的损失函数进行梯度下降优化

Result: 该方法能够有效优化多种量子信道的拟逆信道，不仅限于单量子比特系统，证明了其有效性

Conclusion: 提出的可微分几何参数化方法为寻找复杂量子信道的拟逆信道提供了一种有效的机器学习解决方案

Abstract: This work presents a differentiable geometric parameterization of quantum channels in Kraus representation, which can be efficiently probed to find an unknown quantum channel. We explore its feasibility in finding the quasi inverse channels, which can be a tedious analytically for complex noise processes and is often achievable only for a limited range of parameters. In this regard, machine learning based algorithms have been employed successfully to find quasi inverse of quantum channels. The space of quantum channels in this scheme is a unit hypersphere, and components of mutually constrained unit vectors residing in this space, are used to construct a physically valid quantum channel. Symplectic constraints, orthogonality, and unit length of the vectors suffice to maintain complete positivity and the trace-preserving property of the channels. By performing gradient descent on this parametric space with a fidelity-based loss function, this approach is found to optimize quasi inverse of a variety of quantum channels, not limited to single-qubits, proving its effectiveness.

</details>


### [214] [On-Chip Levitated Neon Particle Arrays for Robust and Scalable Electron Qubits](https://arxiv.org/abs/2512.00654)
*Sosuke Inui,Yinghe Qi,Yiming Xing,Charles Peretti,Dafei Jin,Wei Guo*

Main category: quant-ph

TL;DR: 提出了一种片上磁悬浮架构，通过悬浮固态氖微粒作为电子载体，解决电子-氖量子比特中因衬底粗糙度导致的不可重复性问题，实现可扩展的量子计算。


<details>
  <summary>Details</summary>
Motivation: 电子-氖量子比特虽然结合了离子阱的真空隔离优势和超导电路的可扩展性，但存在自发电子绑定到氖表面凸起的问题。这些凸起源于衬底粗糙度，导致量子比特特性不可重复，阻碍了可扩展性。

Method: 提出片上磁悬浮架构，将固态氖微粒阵列悬浮在处理器芯片上方作为电子载体。这种设计消除了衬底效应，同时保留了强量子比特-谐振器耦合，并支持量子比特间连接。通过调节谐振器偏置电压，量子比特跃迁频率可在GHz范围内调谐。

Result: 该架构能够消除衬底粗糙度的影响，保持强量子比特-谐振器耦合，量子比特跃迁频率可在GHz范围内调谐，非谐性可达~0.8 GHz。解决了电子-氖量子比特的不可重复性问题。

Conclusion: 片上磁悬浮架构为电子-氖量子比特提供了一条通向稳健、可重复和可扩展量子计算的有前景路径，解决了当前平台面临的主要挑战。

Abstract: Electron-on-neon (eNe) qubits have recently emerged as a compelling platform for quantum computing, which combines the vacuum isolation advantages of trapped-ion qubits with the scalability of superconducting circuits. In this system, electrons are trapped in vacuum above a solid neon film deposited on superconducting microwave resonators, where they exhibit strong coupling to the resonators, coherence times of ~0.1 ms, and single-qubit gate fidelities exceeding 99.97%. A central challenge, however, is the spontaneous binding of electrons to neon surface bumps. These bumps, originating from substrate roughness, vary in size: electrons on bumps of suitable sizes within the resonator can couple to microwave photons and function as qubits, whereas those on unfavorable bumps remain inactive yet contribute to background charge noise. Moreover, both the bump landscape and the sites where electrons bind differ from run to run, leading to irreproducible qubit characteristics that hinder scalability. To address this challenging issue, we present an on-chip magnetic-levitation architecture in which arrays of solid-neon microparticles are suspended above the processor chip to act as electron carriers. This design eliminates substrate effects while retaining strong qubit-resonator coupling and supporting inter-qubit connectivity. Our analysis further shows that the qubit transition frequency can be tuned across the gigahertz range and its anharmonicity can reach ~0.8 GHz by tuning the resonator bias voltage. Together, these features suggest a promising pathway toward robust, reproducible, and scalable eNe-based quantum computing.

</details>


### [215] [Non-Negative Matrix Factorization Using Non-Von Neumann Computers](https://arxiv.org/abs/2512.00675)
*Ajinkya Borle,Charles Nicholas,Uchenna Chukwu,Mohammad-Ali Miri,Nicholas Chancellor*

Main category: quant-ph

TL;DR: 本文探索使用基于熵计算范式的非冯·诺依曼架构设备（Dirac-3）解决非负矩阵分解问题，通过QUBO和四次型两种建模方法，在小型问题上取得优于传统方法的初步结果。


<details>
  <summary>Details</summary>
Motivation: 非负矩阵分解（NMF）在无监督学习中应用广泛，但其一般形式是NP难问题。作者希望探索非冯·诺依曼架构（特别是基于熵计算的设备）能否为这类优化问题提供新的解决方案。

Method: 1. 为NMF问题开发了两种优化模型：适合伊辛机的二次无约束二进制优化（QUBO）模型，以及适合Dirac-3设备的允许实值和整数变量的四次型模型。2. 使用Quantum Computing Inc.的Dirac-3设备进行评估。3. 对非负实值矩阵采用融合方法：先用Dirac-3求解，再将结果作为初始因子矩阵输入Scikit-learn的NMF过程。4. 对非负整数矩阵，将Dirac-3与Google的CP-SAT求解器进行比较。

Result: 1. 对于非负实值矩阵，Dirac-3+Scikit-learn融合方法在默认参数下，重构矩阵误差优于单独使用Scikit-learn的NMF。2. 对于非负整数矩阵，在串行处理中，Dirac-3在大多数情况下优于Google的CP-SAT求解器。3. 当前设备尚无法解决大规模NMF问题，但初步实验结果令人鼓舞。

Conclusion: 基于熵计算的非冯·诺依曼架构设备（如Dirac-3）在解决NMF问题上显示出潜力，特别是在小型问题和特定变体上。未来研究应探索这类架构在哪些问题领域和变体上能提供明显优势。

Abstract: Non-negative matrix factorization (NMF) is a matrix decomposition problem with applications in unsupervised learning. The general form of this problem (along with many of its variants) is NP-hard in nature. In our work, we explore how this problem could be solved with an energy-based optimization method suitable for certain machines with non-von Neumann architectures. We used the Dirac-3, a device based on the entropy computing paradigm and made by Quantum Computing Inc., to evaluate our approach. Our formulations consist of (i) a quadratic unconstrained binary optimization model (QUBO, suitable for Ising machines) and a quartic formulation that allows for real-valued and integer variables (suitable for machines like the Dirac-3). Although current devices cannot solve large NMF problems, the results of our preliminary experiments are promising enough to warrant further research. For non-negative real matrices, we observed that a fusion approach of first using Dirac-3 and then feeding its results as the initial factor matrices to Scikit-learn's NMF procedure outperforms Scikit-learn's NMF procedure on its own, with default parameters in terms of the error in the reconstructed matrices. For our experiments on non-negative integer matrices, we compared the Dirac-3 device to Google's CP-SAT solver (inside the Or-Tools package) and found that for serial processing, Dirac-3 outperforms CP-SAT in a majority of the cases. We believe that future work in this area might be able to identify domains and variants of the problem where entropy computing (and other non-von Neumann architectures) could offer a clear advantage.

</details>


### [216] [Curvature-Aware Optimization of Noisy Variational Quantum Circuits via Weighted Projective Line Geometry](https://arxiv.org/abs/2512.00681)
*Gunhee Cho,Jessie Wang,Angela Yue*

Main category: quant-ph

TL;DR: 该论文提出了一个用于变分量子电路的微分几何框架，将噪声量子硬件建模为加权投影线，通过几何参数捕捉噪声的各向异性收缩，并开发了从硬件数据提取几何参数的流程。


<details>
  <summary>Details</summary>
Motivation: 传统量子电路分析缺乏对硬件噪声几何结构的系统描述，需要一种能够捕捉噪声各向异性效应并指导优化过程的几何框架。

Method: 1. 将噪声单/多量子比特参数空间建模为加权投影线；2. 从纯态Bloch球面出发，用物理可解释参数(λ⊥, λ∥)描述噪声引起的各向异性Bloch球收缩；3. 建立WPL度量g_WPL(a/b,b)，其标量曲率R=2/b²；4. 开发从硬件数据提取几何参数的层析到几何流程；5. 提出WPL启发的量子自然梯度优化方法。

Result: 1. 在IBM Quantum后端实验中，WPL几何准确捕捉了校准周期内的各向异性曲率变形；2. WPL-QNG为噪声变分量子本征求解器提供了稳定的优化动态；3. 实现了曲率感知的贫瘠高原缓解。

Conclusion: 该微分几何框架为噪声量子电路提供了紧凑且通道解析的几何表征，能够有效指导优化过程并缓解量子计算中的贫瘠高原问题。

Abstract: We develop a differential-geometric framework for variational quantum circuits in which noisy single- and multi-qubit parameter spaces are modeled by weighted projective lines (WPLs). Starting from the pure-state Bloch sphere CP1, we show that realistic hardware noise induces anisotropic contractions of the Bloch ball that can be represented by a pair of physically interpretable parameters (lambda_perp, lambda_parallel). These parameters determine a unique WPL metric g_WPL(a_over_b, b) whose scalar curvature is R = 2 / b^2, yielding a compact and channel-resolved geometric surrogate for the intrinsic information structure of noisy quantum circuits.
  We develop a tomography-to-geometry pipeline that extracts (lambda_perp, lambda_parallel) from hardware data and maps them to the WPL parameters (a_over_b, b, R). Experiments on IBM Quantum backends show that the resulting WPL geometries accurately capture anisotropic curvature deformation across calibration periods. Finally, we demonstrate that WPL-informed quantum natural gradients (WPL-QNG) provide stable optimization dynamics for noisy variational quantum eigensolvers and enable curvature-aware mitigation of barren plateaus.

</details>


### [217] [Weighted Projective Line ZX Calculus: Quantized Orbifold Geometry for Quantum Compilation](https://arxiv.org/abs/2512.00682)
*Gunhee Cho,Jason Cheng,Evelyn Li*

Main category: quant-ph

TL;DR: 该论文提出了一个基于量子化轨道折叠相位的统一几何框架，用于量子电路编译，通过加权射影线描述硬件相关的相位分辨率，并开发了WPL-ZX演算和WZCC算法进行几何感知优化。


<details>
  <summary>Details</summary>
Motivation: 物理量子比特平台存在异质相位分辨率、各向异性Bloch球收缩和硬件相关的2π缠绕行为等问题，需要统一的几何框架来描述这些效应，以改进量子电路编译。

Method: 1. 使用加权射影线ℙ(a,b)描述轨道折叠相位几何；2. 开发WPL-ZX演算，扩展标准ZX形式，每个蜘蛛携带权重-相位-缠绕三元组；3. 提出WZCC算法进行几何感知优化；4. 引入MASD解码器，在症候图中使用缠绕正则化最小权重匹配。

Result: 通过符号和数值模拟验证了所有结果，证明量子化轨道折叠几何为图解量子编译提供了连贯且硬件相关的扩展，改进了相位网格兼容性和解码鲁棒性。

Conclusion: 量子化轨道折叠几何为量子电路编译提供了一个统一的几何框架，能够有效处理硬件相关的相位分辨率问题，并通过几何感知优化和解码改进，增强了量子计算在现实噪声环境下的鲁棒性。

Abstract: We develop a unified geometric framework for quantum circuit compilation based on quantized orbifold phases and their diagrammatic semantics. Physical qubit platforms impose heterogeneous phase resolutions, anisotropic Bloch-ball contractions, and hardware-dependent $2π$ winding behavior. We show that these effects admit a natural description on the weighted projective line $\mathbb{P}(a,b)$, whose orbifold points encode discrete phase grids and whose monodromy captures winding accumulation under realistic noise channels.
  Building on this geometry, we introduce the WPL--ZX calculus, an extension of the standard ZX formalism in which each spider carries a weight--phase--winding triple $(a,α,k)$. We prove soundness of LCM-based fusion and normalization rules, derive curvature predictors for phase-grid compatibility, and present the Weighted ZX Circuit Compression (WZCC) algorithm, which performs geometry-aware optimization on heterogeneous phase lattices.
  To connect circuit-level structure with fault-tolerant architectures, we introduce Monodromy-Aware Surface-Code Decoding (MASD), a winding-regularized modification of minimum-weight matching on syndrome graphs. MASD incorporates orbifold-weighted edge costs, producing monotone decoder-risk metrics and improved robustness across phase-quantized noise models.
  All results are validated through symbolic and numerical simulations, demonstrating that quantized orbifold geometry provides a coherent and hardware-relevant extension of diagrammatic quantum compilation.

</details>


### [218] [DyLoC: A Dual-Layer Architecture for Secure and Trainable Quantum Machine Learning Under Polynomial-DLA constraint](https://arxiv.org/abs/2512.00699)
*Chenyi Zhang,Tao Shang,Chao Guo,Ruohan He*

Main category: quant-ph

TL;DR: DyLoC提出了一种双层的量子电路架构，通过正交解耦策略解决了量子机器学习中隐私与可训练性之间的关键权衡问题。


<details>
  <summary>Details</summary>
Motivation: 变分量子电路面临隐私与可训练性的关键权衡：高表达能力（确保隐私）会导致指数级大的动态李代数，从而引发贫瘠高原问题；而可训练模型（限制为多项式大小的代数）则容易受到代数攻击。

Method: DyLoC采用双层的正交解耦架构：将可训练性锚定在多项式DLA的ansatz上，而将隐私外部化到输入和输出接口。具体使用截断切比雪夫图编码（TCGE）来阻止快照反演攻击，使用动态局部置乱（DLS）来混淆梯度。

Result: DyLoC保持了基线水平的收敛性（最终损失0.186），将梯度重构误差提高了13个数量级，当重构均方误差超过2.0时能够有效阻止快照反演攻击。

Conclusion: DyLoC为安全且可训练的量子机器学习建立了一条可验证的路径，有效解决了隐私保护与模型可训练性之间的根本矛盾。

Abstract: Variational quantum circuits face a critical trade-off between privacy and trainability. High expressivity required for robust privacy induces exponentially large dynamical Lie algebras. This structure inevitably leads to barren plateaus. Conversely, trainable models restricted to polynomial-sized algebras remain transparent to algebraic attacks. To resolve this impasse, DyLoC is proposed. This dual-layer architecture employs an orthogonal decoupling strategy. Trainability is anchored to a polynomial-DLA ansatz while privacy is externalized to the input and output interfaces. Specifically, Truncated Chebyshev Graph Encoding (TCGE) is employed to thwart snapshot inversion. Dynamic Local Scrambling (DLS) is utilized to obfuscate gradients. Experiments demonstrate that DyLoC maintains baseline-level convergence with a final loss of 0.186. It outperforms the baseline by increasing the gradient reconstruction error by 13 orders of magnitude. Furthermore, snapshot inversion attacks are blocked when the reconstruction mean squared error exceeds 2.0. These results confirm that DyLoC effectively establishes a verifiable pathway for secure and trainable quantum machine learning.

</details>


### [219] [Generalized Deutsch-Jozsa Algorithm for Applications in Data Classification, Logistic Regression, and Quantum Key Distribution](https://arxiv.org/abs/2512.00715)
*M. Ghadimi,V. Salari,S. Bakrani,M. Zomorodi,N. Gohari-Kamel,S. Moradi,D. Oblak*

Main category: quant-ph

TL;DR: 提出广义Deutsch-Jozsa量子算法，不仅能判断布尔函数的全局类型（常数或平衡），还能在单次查询中获取函数的具体输出值。


<details>
  <summary>Details</summary>
Motivation: 原始Deutsch-Jozsa算法只能判断函数是常数还是平衡类型，无法获取具体函数值。需要一种更丰富的函数表征方法，在最小查询次数下获得实际量子优势。

Method: 使用贝尔态作为辅助量子比特，构建广义Deutsch-Jozsa算法，在单次oracle查询中同时确定函数类型和具体输出值。

Result: 新算法在单次查询中同时获得函数的全局类型信息和具体输出值，相比原始算法提供更丰富的函数表征能力。

Conclusion: 广义Deutsch-Jozsa算法在数据分类、逻辑回归和量子密码学等领域具有实际量子优势，实现了更高效的函数表征。

Abstract: We present a generalized Deutsch-Jozsa (DJ) quantum algorithm that not only determines both the global type of an unknown Boolean function (constant or balanced) but also determines explicit output values of the function in a single oracle query. Unlike the original DJ algorithm, which identifies only whether a function is constant or balanced, our generalization retrieves actual function output values at the same time with using a Bell state as ancilla. This makes a richer function characterization with minimal queries to have practical quantum advantages, e.g. data classification, logistic regression, and quantum cryptography.

</details>


### [220] [Information conservation relations for weak measurement and its reversal](https://arxiv.org/abs/2512.00746)
*Yusef Maleki,Luis D. Zambrano Palma,M. Suhail Zubairy*

Main category: quant-ph

TL;DR: 该论文研究了弱测量协议中不同实体间的信息分布，针对多级衰变系统在连续监测下的信息守恒关系，并扩展到有限计数结果，建立了信息变化与信息分布实体之间的定量权衡关系。


<details>
  <summary>Details</summary>
Motivation: 研究弱测量协议中信息在不同实体间的分布情况，特别是在多级衰变系统和连续监测条件下，旨在深入理解开放量子动力学中的信息流动机制。

Method: 针对多级衰变系统在连续（无点击）监测下的情况，推导了精确的信息守恒关系；扩展到有限计数结果（任意光子数），建立了信息变化与信息分布实体之间的定量权衡关系；研究了显式反转操作下的信息关系。

Result: 推导出了在记录中每个结果都成立的信息守恒关系；建立了信息变化与信息分布实体之间的定量权衡关系；发现反转成功概率进入信息关系中；提供了对监测开放量子动力学中信息流动的统一、结果解析的描述。

Conclusion: 该研究为监测开放量子动力学中的信息流动提供了统一的框架，深化了对开放系统动力学及其控制的理解，揭示了弱测量过程中信息变化与信息分布实体之间的定量关系。

Abstract: We investigate the information distribution among different entities in the weak measurements protocol. Focusing on multilevel, decaying systems under continuous (no-click) monitoring, we derive exact, conservation-type information relations that hold for each outcome in the record. Analogous relations hold when an explicit reversal is applied, with the reversal success probability entering the relation.
  We extend the framework to finite-count outcomes (arbitrary photon numbers) obtaining quantitative trade-offs that link information change in the weak measurement process to the entities to which the information is distributed. These results provide a unified, outcome-resolved account of information flow in monitored open quantum dynamics and provide insight into a deeper understanding of open-system dynamics and its control.

</details>


### [221] [Random matrix perspective on probabilistic error cancellation](https://arxiv.org/abs/2512.01957)
*Leonhard Moske,Pedro Ribeiro,Tomaž Prosen,Sergiy Denysov,Karol Życzkowski,David J. Luitz*

Main category: quant-ph

TL;DR: 研究通过随机矩阵方法分析量子计算中概率误差消除技术使用的去噪通道的谱特性


<details>
  <summary>Details</summary>
Motivation: 概率误差消除技术试图通过在噪声量子硬件上执行算法后应用非物理通道来逆转耗散噪声通道的影响，需要深入理解这些去噪通道的特性

Method: 使用随机矩阵集合建模噪声量子算法，分析去噪通道的复谱结构，并考虑量子计算机噪声通道的局部性带来的时间尺度层次结构

Result: 去噪通道的复谱继承了随机Lindblad算子的结构，量子计算机噪声通道的局部性表现为时间尺度的层次结构

Conclusion: 通过随机矩阵方法揭示了概率误差消除技术中使用的去噪通道的谱特性，为理解和改进量子误差缓解技术提供了理论基础

Abstract: Probabilistic error cancellation is an attempt to reverse the effect of dissipative noise channels on quantum computers by applying unphysical channels after the execution of a quantum algorithm on noisy hardware. We investigate on general grounds the properties of such unphysical quantum channels by considering a random matrix ensemble modeling noisy quantum algorithms. We show that the complex spectra of denoiser channels inherit their structure from random Lindbladians. Additional structure imposed by the locality of noise channels of the quantum computer emerges in terms of a hierarchy of timescales.

</details>


### [222] [Optimal Control of thermally noisy quantum gates in a multilevel system](https://arxiv.org/abs/2512.00782)
*Aviv Aroch,Shimshon Kallush,Ronnie Kosloff*

Main category: quant-ph

TL;DR: 该研究应用最优控制理论在热力学一致框架下设计稳定量子门，通过外部驱动场调控系统与环境相互作用，实现熵调控并保持高保真度门操作。


<details>
  <summary>Details</summary>
Motivation: 量子系统对环境噪声和外部控制场缺陷敏感，这会降低量子门保真度，阻碍可靠量子计算的实现。需要开发在噪声环境下稳定量子门的方法。

Method: 在热力学一致框架内应用最优控制理论，将热弛豫效应纳入控制协议，使外部驱动场既能控制系统幺正演化，又能调制系统与环境相互作用。使用高精度数值方法在开放量子系统上验证。

Result: 最优控制理论能够实现熵调控过程（如定向冷却或加热），同时在噪声环境中保持高保真度门性能。即使在显著耗散影响下也能实现稳健的门操作。

Conclusion: 该方法为在现实条件下实现容错量子计算提供了具体路径，展示了通过最优控制理论在热力学框架下设计稳定量子门的可行性。

Abstract: Quantum systems are inherently sensitive to environmental noise and imperfections in external control fields, posing a significant challenge for the practical implementation of quantum technologies. These noise sources degrade the fidelity of quantum gates, making their mitigation a key requirement for realizing reliable quantum computing. In this study, we apply optimal control theory (OCT) within a thermodynamically consistent framework to design and stabilize high-fidelity quantum gates under Markovian noise. Our approach focuses on thermal relaxation and incorporates these effects into the control protocol, wherein external driving fields not only govern the system's unitary evolution but also modulate its interaction with the environment. By leveraging this interplay, we demonstrate that OCT can enable entropy-modifying processes, such as targeted cooling or heating, while maintaining high-fidelity gate performance in noisy environments. To validate our approach, we employ high-precision numerical methods on an open quantum system implementing one- or two-qubit gates embedded in a larger Hilbert space. The results showcase robust gate operation even under significant dissipative influences, offering a concrete path toward fault-tolerant quantum computation under realistic conditions.

</details>


### [223] [Super-Extensive Charging Power in the Absence of Global Operations](https://arxiv.org/abs/2512.00788)
*Anupam,Sheryl Mathew,Sibasish Ghosh*

Main category: quant-ph

TL;DR: 该论文研究了量子电池中实现超扩展充电功率的物理条件，发现除了哈密顿量局域性外，相互作用能量在晶格位点上的分布（g-扩展性）是决定充电性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 量子电池研究量子效应是否能超越经典极限加速能量存储，但实现超扩展充电功率的基本物理要求尚未充分理解。现有各种充电方案虽然报告了量子优势的迹象，但缺乏系统性的理论框架。

Method: 通过分析自旋晶格模型，引入g-扩展性这一结构性质来量化相互作用能量在晶格位点上的分布。证明了超扩展功率缩放仅在相互作用能量分布变得非均匀时才可能实现，且最大局部权重需随系统尺寸增长。

Result: 研究发现许多先前研究的协议未能表现出超扩展功率，即使哈密顿量涉及大量参与数。在实验相关的相互作用模型中，尽管相互作用阶数固定，充电功率仍能实现超扩展缩放。

Conclusion: g-扩展性是直接充电协议中实现量子优势的必要资源，为识别和设计物理上可行的量子电池提供了系统框架，使其在充电功率上能够超越经典对应物。

Abstract: Quantum batteries have emerged as a platform for investigating whether quantum effects can accelerate energy storage beyond classical limits. Although a variety of charging schemes have reported signatures of quantum advantage, the fundamental physical requirements for achieving superextensive charging power remain insufficiently understood. Here, we show that, in addition to Hamiltonian locality, a key structural property, g-extensiveness, quantifying the distribution of interaction energy across lattice sites places a fundamental bound on charging performance in spin-lattice models. We prove that superextensive power scaling is possible only when the interaction-energy distribution becomes increasingly nonuniform, with the maximal local weight growing with system size. This criterion explains why many previously studied protocols fail to exhibit superextensive power, even when the Hamiltonians involve large participation numbers. We further demonstrate that this condition is realized in an experimentally relevant interacting model, where, despite fixed interaction order, the charging power scales superextensively. Our results establish g-extensiveness as a necessary resource for quantum advantage in direct-charging protocols and provide a systematic framework for identifying and engineering physically feasible quantum batteries capable of outperforming classical counterparts in charging power.

</details>


### [224] [Particle creation, adiabaticity, and irreversibility in the TDHO](https://arxiv.org/abs/2512.00820)
*Salvador J. Robles-Perez,Salvador Castillo-Rivera*

Main category: quant-ph

TL;DR: 该论文对含时谐振子进行了精确描述，研究了粒子产生、绝热性和不可逆性之间的关系，提出了三种不同表示方法，并分析了热力学量在过渡区和非准静态区的行为。


<details>
  <summary>Details</summary>
Motivation: 研究含时谐振子的动力学和热力学性质，探索粒子产生、绝热性和不可逆性之间的关系，特别是在传统研究较少关注的过渡区和非准静态区域。

Method: 使用三种不同表示方法（初始表示、对角表示和不变表示）分析含时谐振子，提供适用于任意频率函数值和整个演化过程的解析结果，并辅以数值计算和图表验证。

Result: 发现非不变表示的最大模式可能经历可逆热化过程，温度概念自然从振子的幺正演化中产生；观察到经典到量子态的意外转变，可能违反经典热力学第三定律；提出了考虑粒子产生的量子热和功的新定义。

Conclusion: 含时谐振子的热力学性质依赖于表示方法，粒子产生与对角熵之间存在重要关系，幺正演化下熵不产生的条件暗示了模式温度的定义，这对量子热机的发展具有重要意义。

Abstract: We present an exact description of the dynamics and the thermodynamics of a time dependent harmonic oscillator (TDHO) that follows a unitary evolution. In that context, we study the relationship between particle creation, adiabaticity and irreversibility in terms of three different representations: the initial, the diagonal and the invariant representations of the TDHO. We provide analytical results that are valid for any functional value of the frequency and along the whole evolution of the TDHO, which allows us to monitor the behavior of the thermodynamical magnitudes in regions that are not fully considered in previous works, i.e. the transition and the non quasi-static regions. We supplement the analytical results with numerical calculations and graphs.
  They both show how the largest modes of the non invariant representations may undergo a process of reversible thermalization, where the concept of temperature naturally arises from the unitary evolution of the oscillator with no relation to any external concept of temperature. It would allow us to monitor an unexpected classical-to-quantum transition, which might entail a violation of the third principle of classical thermodynamics. We also provide adaptations of the customary definitions of the quantum heat and work that account for the particle creation of the TDHO. They thus depend on the representation and their evolution is different for the three representations analyzed in this paper, which might have important consequences in the development of quantum thermal machines. Finally, we study the relationship between the creation of particles and the diagonal entropy, which is derived from the von Neumann entropy in the diagonalization limit. The condition of no production of entropy under unitary evolution suggests the definition of a mode temperature that would correspond to the thermal temperature is some appropriate limit.

</details>


### [225] [Multiqubit Rydberg Gates for Quantum Error Correction](https://arxiv.org/abs/2512.00843)
*David F. Locher,Josias Old,Katharina Brechtelsbauer,Jakob Holschbach,Hans Peter Büchler,Sebastian Weber,Markus Müller*

Main category: quant-ph

TL;DR: 该论文研究了用于容错量子纠错的多量子比特Rydberg门，开发了脉冲优化工具包，分析了CCZ门在测量无关QEC中的应用，并展示了三量子比特门在Floquet码中的优势。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为多量子比特门在容错量子纠错中意义有限，因为单门故障可能导致高权重相关错误。但最近研究表明多量子比特门在测量无关容错量子纠错和无旋转表面码的稳定子读取中具有优势，特别是在单物种中性原子平台上。

Method: 开发了开源Python包来生成解析的、参数少的脉冲，实现所需门操作同时最小化Rydberg态衰变导致的误差；分析了对称和非对称原子配置中的CCZ门；研究了单、双、三量子比特门误差率下的性能；模拟了包含两体稳定子测量的Floquet量子纠错协议。

Result: 测量无关量子纠错的突破性能在当前硬件范围内可达；使用全局三量子比特门实现Floquet码中的稳定子测量可显著减少穿梭操作；在实验相关误差机制下，三量子比特门在Floquet码稳定子测量中的应用能产生具有竞争力的逻辑量子比特性能。

Conclusion: 多量子比特Rydberg门在容错量子纠错中具有实际应用价值，特别是在单物种中性原子平台上。通过优化的脉冲设计和参数选择，可以在当前硬件条件下实现有效的测量无关量子纠错，并为Floquet码提供更高效的实现方案。

Abstract: Multiqubit gates that involve three or more qubits are usually thought to be of little significance for fault-tolerant quantum error correction because single gate faults can lead to high-weight correlated errors. However, recent works have shown that multiqubit gates can be beneficial for measurement-free fault-tolerant quantum error correction and for fault-tolerant stabilizer readout in unrotated surface codes. In this work, we investigate multiqubit Rydberg gates that are useful for fault-tolerant quantum error correction in single-species neutral-atom platforms and can be implemented with a single, non-addressed laser pulse. We develop an open-source Python package to generate analytical, few-parameter pulses that implement the desired gates while minimizing gate errors due to Rydberg-state decay. The tool also allows us to identify parameter-optimal pulses, characterized by a minimal parameter count for the pulse ansatz. Measurement-free quantum error correction protocols require CCZ gates, which we analyze for atoms arranged in symmetric and asymmetric configurations. We investigate the performance of these schemes for various single-, two-, and three-qubit gate error rates, showing that break-even performance of measurement-free QEC is within reach of current hardware. Moreover, we study Floquet quantum error correction protocols that comprise two-body stabilizer measurements. Those can be realized using global three-qubit gates, and we show that this can lead to a significant reduction in shuttling operations. Simulations with realistic circuit-level noise indicate that applying three-qubit gates for stabilizer measurements in Floquet codes can yield competitive logical qubit performance in experimentally relevant error regimes.

</details>


### [226] [Opportunities and Challenges for Data Quality in the Era of Quantum Computing](https://arxiv.org/abs/2512.00870)
*Sven Groppe,Valter Uotila,Jinghua Groppe*

Main category: quant-ph

TL;DR: 该论文探索量子计算在提升数据质量（特别是异常检测）方面的潜力，通过量子技术替代传统异常检测中的关键子程序，并以量子储层计算检测股市波动率变化为例进行技术实现。


<details>
  <summary>Details</summary>
Motivation: 在数据驱动决策的时代，确保高质量数据至关重要。传统数据质量提升算法（包括异常检测）需要大量计算资源、长时间处理和大量训练数据，量子计算有望解决这些计算密集型问题。

Method: 1. 研究量子技术替代传统异常检测框架中的关键子程序；2. 展示基于量子的异常检测方法；3. 提出使用量子储层计算（一种特殊量子机器学习模型）检测股市数据波动率变化的技术实现。

Result: 实验结果表明，在检测股市波动率变化的特定示例中，基于量子的嵌入方法与经典方法具有竞争力。量子嵌入是经典嵌入的有力替代方案。

Conclusion: 量子计算为数据质量任务提供了新的可能性，但应用中仍存在未解决的挑战和限制。这些发现为通过量子技术创新研究和商业应用开辟了新途径。

Abstract: In an era where data underpins decision-making across science, politics, and economics, ensuring high data quality is of paramount importance. Conventional computing algorithms for enhancing data quality, including anomaly detection, demand substantial computational resources, lengthy processing times, and extensive training datasets. This work aims to explore the potential advantages of quantum computing for enhancing data quality, with a particular focus on detection. We begin by examining quantum techniques that could replace key subroutines in conventional anomaly detection frameworks to mitigate their computational intensity. We then provide practical demonstrations of quantum-based anomaly detection methods, highlighting their capabilities. We present a technical implementation for detecting volatility regime changes in stock market data using quantum reservoir computing, which is a special type of quantum machine learning model. The experimental results indicate that quantum-based embeddings are a competitive alternative to classical ones in this particular example. Finally, we identify unresolved challenges and limitations in applying quantum computing to data quality tasks. Our findings open up new avenues for innovative research and commercial applications that aim to advance data quality through quantum technologies.

</details>


### [227] [Efficient Self-Consistent Quantum Comb Tomography on the Product Stiefel Manifold](https://arxiv.org/abs/2512.00875)
*Xinlin He,Zetong Li,Congcong Zheng,Sixuan Li,Xutao Yu,Zaichen Zhang*

Main category: quant-ph

TL;DR: 提出一种自洽的Comb-Instrument-State（CIS）框架，将量子梳、仪器集和初始状态统一为单一几何实体，通过黎曼优化解决非马尔可夫量子动力学表征问题。


<details>
  <summary>Details</summary>
Motivation: 现有量子梳层析（QCT）方法存在自不一致性和高计算复杂度的问题，阻碍了非马尔可夫量子动力学的有效表征。

Method: 提出CIS集框架，将量子梳、仪器集和初始状态统一为单一几何实体，该集合自然位于乘积Stiefel流形上，通过无约束黎曼优化解决层析问题，自动保持物理约束。

Result: 数值模拟证实该方法计算可扩展且对门定义误差具有鲁棒性，显著优于传统的基于等距变换的QCT方法。

Conclusion: 该工作表明能够以更少的计算资源高效学习量子梳，为非马尔可夫量子动力学表征提供了新途径。

Abstract: Characterizing non-Markovian quantum dynamics is currently hindered by the self-inconsistency and high computational complexity of existing quantum comb tomography (QCT) methods. In this work, we propose a self-consistent framework that unifies the quantum comb, instrument set, and initial states into a single geometric entity, termed as the Comb-Instrument-State (CIS) set. We demonstrate that the CIS set naturally resides on a product Stiefel manifold, allowing the tomography problem to be solved via efficient unconstrained Riemannian optimization while automatically preserving physical constraints. Numerical simulations confirm that our approach is computationally scalable and robust against gate definition errors, significantly outperforming conventional isometry-based QCT methods. Our work indicates the potential to efficiently learn quantum comb with fewer computational resources.

</details>


### [228] [Formulations of Quantum Thermodynamics and Applications in Open Systems](https://arxiv.org/abs/2512.00923)
*J. M. Z. Choquehuanca*

Main category: quant-ph

TL;DR: 该论文探讨量子热力学的两种描述方法：基于熵的方法和基于做功能力（ergotropy）的方法，研究非马尔可夫性在量子热力学中的作用，并提出了基于做功能力的热力学表述。


<details>
  <summary>Details</summary>
Motivation: 量子热力学是理解微观系统能量转换过程的关键领域，其中相干性、纠缠和非马尔可夫性等量子效应起着重要作用。需要发展新的理论框架来更好地描述和量化这些量子热力学过程。

Method: 采用两种主要方法：1）基于熵的方法，通过热力学函数的单调性破坏来量化非马尔可夫性；2）基于做功能力的方法，分析开放量子比特在马尔可夫和非马尔可夫演化下的做功能力动力学。提出了基于做功能力的热力学表述，将热量重新解释为与密度算符相关的被动态变化。

Result: 1）基于熵的热流可作为见证和测量量子记忆的工具；2）在开放量子比特中发现了做功能力的冻结和猝死现象；3）建立了做功能力变化与环境诱导功之间的解析关系；4）基于做功能力的方法能更普遍、更准确地测量非马尔可夫性，且非平衡温度保持非负性。

Conclusion: 基于做功能力的热力学表述为量子热力学提供了更优越的理论框架，能够更准确地描述非马尔可夫过程，保持与平衡热力学一致的物理性质，并为量子热力学第一定律中的附加项提供了清晰的物理解释。

Abstract: Quantum thermodynamics has emerged as a central field for understanding how energy conversion processes occur in microscopic systems. In these systems, effects such as coherence, entanglement, and non-Markovianity play key roles. In this thesis, we explore different ways to describe quantum thermodynamics, using two main approaches: one based on entropy and the other on ergotropy. First, we introduce a generalized approach to quantify non-Markovianity through the breakdown of monotonicity in thermodynamic functions. In this context, the entropy-based heat flow serves as a practical tool to witness and measure quantum memory in unital maps that do not reverse the sign of the internal energy. Next, we analyze the dynamics of ergotropy in open qubits under both Markovian and non-Markovian evolutions. We identify phenomena such as freezing and sudden death of ergotropy, and we establish an analytical relation between the change in ergotropy and the environment-induced work . This provides a clear physical interpretation for the additional term in the first law in the entropy-based formulation. Finally, we propose an ergotropy-based thermodynamic formulation, in which heat is reinterpreted in terms of the change of the passive state associated with the density operator governing the quantum dynamics. This approach allows one to measure non-Markovianity of unital maps more generally and accurately than the entropy-based heat flow. This advantage comes from the direct link between heat and von Neumann entropy, a property ensured by invariance under passive transformations. Moreover, the out-of-equilibrium temperature naturally remains non-negative, similarly to equilibrium thermodynamics.

</details>


### [229] [From Promise to Practice: Benchmarking Quantum Chemistry on Quantum Hardware](https://arxiv.org/abs/2512.01012)
*Osama M. Raisuddin,Haimeng Zhang,Mario Motta,Fabian M. Faulstich*

Main category: quant-ph

TL;DR: 该研究对基于样本的量子对角化(SQD)方法在电子结构计算中的性能进行了系统性评估，使用W4-11热化学数据集，在量子设备和超级计算机上进行了大规模测试。


<details>
  <summary>Details</summary>
Motivation: 评估量子混合算法在数字量子设备上的准确性和精度，为量子算法和设备的开发提供基准和社区资源。

Method: 使用样本量子对角化(SQD)方法，在IBM superconducting量子处理器(16.85小时)和AiMOS超级计算机(724.22节点小时)上对W4-11热化学数据集进行测试，涵盖多种分子系统和化学反应类型。

Result: SQD方法表现出较大的统计偏差，但通过能量外推可达到CCSD级别的精度；键断裂反应随计算资源增加而系统性改善，但亲核取代或重原子转移反应则不然。

Conclusion: 该研究量化了SQD方法的局限性，指出了改进方向，并为探索新量子算法和设备提供了基准和社区资源，包括在线基准挑战和开源Python库。

Abstract: We provide a systematic evaluation of the sample-based quantum diagonalization (SQD) method for electronic structure based on the W4-11 thermochemistry dataset, comprising 124 total atomization, 83 bond dissociation, 20 isomerization, 505 heavy-atom transfer, and 13 nucleophilic substitution processes, covering diverse bonding situations and reaction mechanisms. This is the largest study assessing the accuracy and precision of a quantum-hybrid algorithm on a digital quantum device across a variety of molecular systems and chemical reactions, using 16.85 hours on the superconducting quantum processor ibm_rensselaer and 724.22 node hours on the supercomputer AiMOS. To ensure a fair comparison, our study employs commensurate resource allocation for both classical and quantum simulations. Although SQD exhibits large statistical deviations from ground-state reference energies, energy extrapolations yield CCSD-level accuracy. While bond-breaking reactions show a systematic improvement as computational resources increase, nucleophilic substitution or heavy atom transfer reactions do not. The limitations quantified in this manuscript indicate opportunities for improvement in SQD-based algorithms. This work provides a benchmark and community resource for exploring new quantum algorithms and devices, supported by an online benchmark challenge and an open-source Python library for direct comparison.

</details>


### [230] [Thermalization Rate of Light in Weakly Coupled Molecular Systems](https://arxiv.org/abs/2512.01040)
*Vladislav Yu. Shishkov*

Main category: quant-ph

TL;DR: 该论文研究了低频分子振动对分子薄膜中光热化速率的影响，在弱耦合条件下推导了热化速率的理论表达式。


<details>
  <summary>Details</summary>
Motivation: 低频分子振动影响分子薄膜的吸收和发射光谱线宽以及斯托克斯位移，在腔中使用分子薄膜作为活性介质时，这些振动促进光的热化，从而实现玻色-爱因斯坦凝聚。需要量化低频分子振动对光热化速率的贡献。

Method: 采用Lindblad超算符的微扰理论，推导了在光与物质弱耦合条件下低频分子振动对光热化速率的贡献表达式。该热化速率适用于任何腔设计，但依赖于低频分子振动的局部微观特性。

Result: 推导出了热化速率的具体表达式，并提供了仅需系统宏观参数即可估算热化速率的方法：光-物质相互作用强度、腔和激子的共振频率、照明区域内的分子数以及独立分子薄膜发射光谱中0-0峰线宽的温度依赖性。

Conclusion: 低频分子振动在光热化过程中起关键作用，通过理论推导获得了可实验验证的热化速率表达式，为理解腔中分子薄膜的光热化机制提供了理论框架。

Abstract: Emission and absorption spectra of molecular films are impacted by low-frequency molecular vibrations. These vibrations define the linewidths of the absorption and emission spectral peaks, as well as the Stokes shift. In cavities that use a molecular film as an active medium, low-frequency molecular vibrations facilitate the thermalization of light, enabling the formation of Bose-Einstein condensation. In this work, I employ perturbation theory for Lindblad superoperators and derive the contribution of the low-frequency molecular vibrations to the thermalization rate of light in a weak coupling regime between light and matter. The derived thermalization rate applies for any cavity design but depends on the local microscopic properties of low-frequency molecular vibrations. I provide an estimation for the thermalization rate, which requires only knowledge of the macroscopic parameters of the system: light-matter interaction strength, resonant frequencies of the cavity and excitons, number of molecules in the illuminated area, and the linewidth temperature dependence of the 0-0 peak in the emission spectra of standalone molecular film.

</details>


### [231] [Photons in a Spherical Cavity](https://arxiv.org/abs/2512.01043)
*Thomas B. Bahder*

Main category: quant-ph

TL;DR: 该论文详细解决了球形腔中光子模式的问题，澄清了文献中的矛盾结果，推导了电多极子和磁多极子光子的不同频率条件，建立了二次量子化的矢量势，并基于球形模式研究了40种不同类型的双光子纠缠态。


<details>
  <summary>Details</summary>
Motivation: 球形腔中光子模式问题在文献中存在矛盾结果（如Heitler和Davydov的量子力学著作），需要澄清和详细解决这一经典问题。

Method: 从麦克斯韦方程出发，在完美导体边界条件下求解，推导出电多极子和磁多极子光子的不同频率条件，建立球形几何中的二次量子化矢量势，并基于球形模式分析双光子纠缠态。

Result: 球形腔中光子频率由两个不同条件决定：一个用于电多极子光子，一个用于磁多极子光子。基于球形模式，理论上存在40种不同类型的双光子纠缠态。

Conclusion: 该研究澄清了球形腔光子模式的经典问题，提供了完整的理论框架，为球形几何中的量子光学研究奠定了基础，并揭示了丰富的双光子纠缠态多样性。

Abstract: The iconic problem of photon modes in a spherical cavity has been discussed in the literature; however, conflicting results have been reported \cite{Heitler,Davydov_QuantumMechanics}. For this reason, the solution of this problem is worked out in detail here, starting with the Maxwell equations and applying boundary conditions at the surface of the bounding perfect conductor. Contrary to the treatments in the literature \cite{Heitler,Davydov_QuantumMechanics}, the allowed frequencies for photons in the sphere are given by two different conditions, one for electric and one for magnetic multipole photons. After establishing the modes and their allowed frequencies, we write down the second-quantized vector potential in the spherical geometry. Based on these spherical modes, bipartite photon entanglement is investigated showing that there are in-principle 40 different types of entangled photon states. Finally, we include some appendices about photon plane-wave and spherical-wave helicity states, helicity spherical harmonic vectors, and rotation of the helicity states and 3-d vectors using the Wigner $D$-matrix.

</details>


### [232] [Quantum Entanglement Control in Two-Spin-1/2 NMR Systems Through Magnetic Fields and Temperature](https://arxiv.org/abs/2512.01060)
*Fatemeh Khashami,Stefan Glöggler*

Main category: quant-ph

TL;DR: 该研究分析了双自旋-1/2 NMR系统在热平衡下的量子纠缠，推导了纠缠与温度、磁场强度的解析关系，建立了纠缠与NMR可观测量的直接联系，为量子纠缠的实验表征提供了实用框架。


<details>
  <summary>Details</summary>
Motivation: 研究量子纠缠在热平衡NMR系统中的行为，探索温度、磁场对纠缠的影响，建立量子纠缠与实验可观测量的联系，为量子增强NMR、低温光谱学和量子技术提供理论基础。

Method: 推导双自旋-1/2 NMR系统在热平衡下的量子纠缠解析表达式，分析纠缠与温度、磁场强度的依赖关系，建立能级交叉的解析判据，并将纠缠度量与NMR实验可观测信号关联。

Result: 发现了纠缠随温度升高而消失的阈值温度，在零温下观察到量子临界点，建立了同核和异核系统中量子临界点的识别条件，实现了纠缠度量与NMR信号处理的直接关联。

Conclusion: 该研究为热平衡NMR系统中的量子纠缠表征提供了完整理论框架，建立了纠缠与实验可观测量的直接联系，为量子特征的热控制、量子增强NMR和量子技术应用提供了重要见解。

Abstract: We investigate quantum entanglement in two-spin-1/2 NMR systems at thermal equilibrium under external magnetic fields. We derive closed-form analytical expressions for the entanglement of the system and show how the entanglement depends on temperature and magnetic field strength, resulting in a threshold temperature beyond which entanglement vanishes. We demonstrate that at zero temperature, the system exhibits a quantum critical point, characterized by non-analytic behavior in the measure of entanglement. We further develop analytical criterion for level crossing, which serves as a condition for identifying quantum critical points in both homonuclear and heteronuclear systems, and apply it to multiple settings to analyze their quantum critical points. We establish a direct link between the quantum entanglement quantifier and experimentally accessible NMR observables, enabling entanglement to be quantified through NMR signal processing. This provides a practical framework for characterizing quantum correlations using standard NMR experiments. These findings provide insights into the thermal control of quantum features, with implications for quantum-enhanced NMR, low-temperature spectroscopy, and emerging quantum technologies.

</details>


### [233] [Unsupervised Machine Learning for Experimental Detection of Quantum-Many-Body Phase Transitions](https://arxiv.org/abs/2512.01091)
*Ron Ziv,David Wei,Antonio Rubio-Abadal,Daniel Adler,Anna Keselman,Eran Lustig,Ronen Talmon,Johannes Zeiher,Immanuel Bloch,Mordechai Segev*

Main category: quant-ph

TL;DR: 提出一种无监督机器学习方法，直接从原始实验数据中检测量子多体系统的相变和交叉现象，无需系统特定先验知识。


<details>
  <summary>Details</summary>
Motivation: 量子多体系统模拟计算困难，费曼量子模拟器概念解决了动力学模拟问题，但无法从有限可观测数据中推断基础物理。特别是当不存在简单序参量时，识别相变面临重大挑战，且数值模拟往往不可行。

Method: 采用无监督机器学习方法，直接从原始实验测量数据中研究量子多体实验，专门用于检测相变和交叉现象。

Result: 在多体局域化交叉和莫特绝缘体-超流体相变系统中验证了该方法，表明仅从部分实验数据即可揭示集体现象，无需任何系统特定先验知识。

Conclusion: 该方法为复杂量子多体系统中涌现现象的数据驱动发现提供了一条通用且可扩展的途径。

Abstract: Quantum many-body (QMB) systems are generally computationally hard: the computing resources necessary to simulate them exactly can often exceed the existing computation resources by orders of magnitude. For this reason, Richard Feynman proposed the concept of a quantum simulator: quantum systems engineered to obey a prescribed evolution equation and repeating the experiment multiple times. Experimentally, however, as we explain below, the vast majority of observables describing the system are inaccessible. Thus, while Feynman's idea addresses the problem of simulating quantum dynamics, it leaves unsolved the equally fundamental problem of inferring the underlying physics from the limited observables accessible in experiments. Indeed, many complex phenomena associated with QMB systems remain elusive. Perhaps, the most important example is identifying phase transitions in QMB systems when no simple order-parameter exists, which poses major challenges to this day. Complicating the problem further is the fact that, in most cases, it is impossible to learn from numerical simulations, as the underlying systems are often too large to be computable, and small QMB can show strong finite size effects, masking the presence of the transition. Here, we present an unsupervised machine learning approach to study QMB experiments, specifically aimed at detecting phase transitions and crossovers directly from raw experimental measurements. We demonstrate our methodology on systems undergoing Many-Body Localization cross-over and Mott-to-Superfluid phase-transition, showing that it reveals collective phenomena from the very partial experimental data and without any model-specific prior knowledge of the system. This approach offers a general and scalable route for data-driven discovery of emergent phenomena in complex quantum many-body systems.

</details>


### [234] [Nonclassicality Analysis and Entanglement Witnessing in Spin-$1/2$ NMR Systems](https://arxiv.org/abs/2512.01100)
*Fatemeh Khashami*

Main category: quant-ph

TL;DR: 该研究分析了热平衡状态下双自旋-1/2 NMR系统的量子特性，建立了量子信息度量与实验可观测NMR谱之间的联系，为通过NMR实验检测量子纠缠提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 研究热平衡状态下核磁共振系统中量子相干性、混合度和纠缠等量子特性的表现，建立量子信息理论与实验可观测NMR信号之间的联系，为实验验证量子纠缠提供可行方案。

Method: 使用合适的量子度量工具分析双自旋-1/2 NMR系统的量子相干性、混合度和纠缠；推导量子元素的封闭形式解析表达式；分析温度和外磁场强度对这些度量的影响；建立量子信息度量与实验可观测NMR谱之间的对应关系。

Result: 在零温条件下，系统表现出量子临界点，相干性度量呈现非解析行为，混合度出现尖锐峰值；建立了适用于NMR实验的纠缠见证方法，将系统纠缠与量子可观测量联系起来；实现了通过NMR信号处理量化纠缠、相干性和混合度的技术路径。

Conclusion: 该研究为在NMR系统中实验验证量子纠缠提供了实用框架，建立了量子信息理论与实验观测之间的桥梁，展示了通过标准NMR技术检测和量化量子特性的可行性。

Abstract: We investigate quantum features and non-classical nature of two-spin-$1/2$ NMR systems at thermal equilibrium under external magnetic fields. More specifically, using suitable quantifiers, we analyze quantum coherence, mixedness, and entanglement in NMR systems and examine their features within the system. We derive closed-form analytical expressions for the quantum elements and show how they depend on temperature and magnetic field strength. We demonstrate that at zero temperature, the system exhibits a quantum critical point, characterized by non-analytic behavior in the measures of coherence, and a sharp peak in mixedness. Moreover, we analyze the entanglement of the system using a suitable entanglement witness. This provides an experimentally friendly setting for testing entanglement in NMR systems. In other words, the witness links the entanglement in the system to quantum observables, making it directly provable in NMR experiments. We establish a connection between quantum information quantifiers and experimentally accessible NMR spectra of the system, enabling the quantification of entanglement, coherence, and mixedness through NMR signal processing.

</details>


### [235] [Quantum magnetic imaging of current density in lithium-ion batteries](https://arxiv.org/abs/2512.01125)
*W. Evans,T. Coussens,M. T. M. Woodley,A. M. Fabricant,G. D. Kendall,M. Sonnet,D. Wasylowski,D. U. Sauer,F. Oručević,P. Krüger*

Main category: quant-ph

TL;DR: 该研究提出了一种基于光学泵浦磁力计（OPMs）的量子磁力测量方法，用于对电池单元进行实时电流密度磁成像，以监测内部电化学过程。


<details>
  <summary>Details</summary>
Motivation: 随着电池生产的快速增长，需要先进的诊断工具进行质量控制、老化预测和回收。现有技术缺乏非侵入式捕获内部电化学过程所需的空间和时间分辨率。

Method: 使用光学泵浦磁力计（OPMs）进行电流密度磁成像，在开路配置下实时监测电池内部动态。对6000 mAh锂离子电池在不同脉冲持续时间、电流和荷电状态下的弛豫过程进行监测，并与SQUID磁力测量和三维有限元模拟进行基准测试。

Result: 该方法能够揭示空间分辨特征和瞬态磁场特征，这些是电化学阻抗谱（EIS）等互补非侵入技术无法获取的。OPM磁成像显示出作为强大诊断工具的潜力。

Conclusion: OPM基电池电流密度磁成像被确立为一种强大的诊断工具，对电池开发、制造质量保证和二次寿命评估具有潜在影响。

Abstract: The projected rapid growth of battery cell production over the next decade demands advanced diagnostic tools for quality control, ageing prediction, and recycling. Most existing techniques lack the spatial and temporal resolution required to capture internal electrochemical processes non-invasively. Here, we present magnetic imaging of current densities in battery cells, a sensitive quantum-magnetometry method that uses optically pumped magnetometers (OPMs) to perform real-time imaging of internal dynamics in open-circuit configuration. We demonstrate this approach for monitoring relaxation processes in 6000 mA h lithium-ion cells following pulsed discharges across a range of pulse durations and currents as well as states of charge. The measurement results are benchmarked against superconducting-quantum-interference-device (SQUID) magnetometry and validated with three-dimensional finite element simulations. Equivalent circuit models are employed to interpret the relaxation profiles, revealing spatially resolved features and transient magnetic-field signatures that are inaccessible with complementary non-invasive techniques such as electrochemical impedance spectroscopy (EIS). This work establishes OPM-based magnetic imaging of battery current density as a powerful diagnostic tool with potential impact on cell development, manufacturing quality assurance, and second-life assessment.

</details>


### [236] [Scoring-based Static Variable Ordering for Decision Diagram-based Quantum Circuit Simulation](https://arxiv.org/abs/2512.01186)
*Yusuke Kimura,Masahiro Fujita,Robert Wille*

Main category: quant-ph

TL;DR: 提出一种基于评分的启发式方法来确定静态变量顺序，用于高效的基于决策图的量子电路模拟，相比默认顺序实现最高150倍加速


<details>
  <summary>Details</summary>
Motivation: 虽然基于决策图的量子电路模拟器在模拟某些量子电路时具有内存高效和快速的优势，但变量顺序对模拟性能有显著影响。现有研究指出动态重排序会恶化模拟时间和数值精度，且缺乏对静态顺序在量子电路模拟中的全面研究

Method: 提出一种基于评分的启发式方法来确定静态变量顺序，该方法能够实现高效的基于决策图的量子电路模拟

Result: 在基准电路测试中，默认原始变量顺序导致模拟缓慢，而提出的方法实现了最高150倍的加速。特别地，提出的顺序在单核笔记本电脑上仅用5小时完成了Shor的1011因式分解模拟，而之前两天内都未能完成

Conclusion: 提出的基于评分的启发式静态变量顺序方法能够显著提升基于决策图的量子电路模拟效率，为解决大规模量子电路模拟问题提供了有效方案

Abstract: Decision diagram (DD)-based quantum circuit simulators represent quantum states and gates using DDs, enabling memory-efficient and fast simulations for some quantum circuits like Shor. Although it is known that DD size and processing time vary depending on the variable order in classical circuits, there has not been much research on the variable order under quantum circuit simulation. One existing study pointed out that dynamic reordering worsens the simulation time and numerical accuracy, and there is no comprehensive research on static orders in the context of quantum circuit simulation. Therefore, this paper proposes a scoring-based heuristic method for determining a static variable order that enables efficient DD-based quantum circuit simulation. When applied to benchmark circuits, the default original variable orders resulted in slow simulations, whereas the proposed method achieved speedups of up to 150x. Furthermore, the proposed order completed the simulation of Shor's 1011 factorization in 5 hours on a single-core laptop, although it was not completed within two days previously.

</details>


### [237] [Experimental Witness of Quantum Jump Induced High-Order Liouvillian Exceptional Points](https://arxiv.org/abs/2512.01217)
*Zhuo-Zhu Wu,Pei-Dong Li,Tai-Hao Cui,Jia-Wei Wang,Yuan-Zhang Dong,Shuang-Qing Dai,Ji Li,Ya-Qi Wei,Quan Yuan,Xiao-Ming Cai,Liang Chen,Jian-Qi Zhang,Hui Jing,Mang Feng*

Main category: quant-ph

TL;DR: 首次在超冷囚禁离子系统中观测到由量子跃迁产生的三阶Liouvillian异常点，并探索了衰变和退相干组合效应下的异常点行为


<details>
  <summary>Details</summary>
Motivation: Liouvillian异常点（LEP）涉及能量损失和退相干的相互作用，与量子跃迁密切相关，能够完全捕捉量子系统动力学并促进非厄米量子研究。理论预测量子跃迁可在两能级量子系统中产生三阶LEP，但此前从未得到实验证实。

Method: 在超冷两能级囚禁离子系统中，通过结合衰变和退相干过程，实验观测量子跃迁产生的三阶LEP。研究衰变和退相干Lindblad超算符之间的非对易性如何驱动LEP移动。

Result: 首次实验观测到由量子跃迁产生的三阶LEP，并展示了衰变和退相干竞争如何驱动LEP移动。发现非厄米量子系统中LEP的这一独特特性。

Conclusion: 量子跃迁产生的三阶LEP的首次实验观测，以及衰变与退相干竞争驱动LEP移动的发现，为非厄米量子系统研究开辟了新途径，为调控非互易性、增强精密测量和操纵拓扑动力学提供了新方法。

Abstract: The exceptional point has presented considerably interesting and counterintuitive phenomena associated with nonreciprocity, precision measurement, and topological dynamics. The Liouvillian exceptional point (LEP), involving the interplay of energy loss and decoherence inherently relevant to quantum jumps, has recently drawn much attention due to capability to fully capture quantum system dynamics and naturally facilitate non-Hermitian quantum investigations. It was also predicted that quantum jumps could give rise to third-order LEPs in two-level quantum systems for its high dimensional Liouvillian superoperator, which, however, has never been experimentally confirmed until now. Here we report the first observation of the third-order LEPs emerging from quantum jumps in an ultracold two-level trapped-ion system. Moreover, by combining decay with dephasing processes, we present the first experimental exploration of LEPs involving combinatorial effect of decay and dephasing. In particular, due to non-commutativity between the Lindblad superoperators governing LEPs for decay and dephasing, we witness the movement of LEPs driven by the competition between decay and dephasing occurring in an open quantum system. This unique feature of non-Hermitian quantum systems paves a new avenue for modifying nonreciprocity, enhancing precision measurement, and manipulating topological dynamics by tuning the LEPs.

</details>


### [238] [The Entropy Flow of a Laser Beam](https://arxiv.org/abs/2512.01230)
*Howard M. Wiseman*

Main category: quant-ph

TL;DR: 激光束通常被建模为纯相干态，但实际上其状态是混合的，即使具有相干态的光子数统计特性（泊松分布），因为相位必须变化。本文研究了具有相位扩散速率ℓ的理想激光束，其熵是广延的，熵流为√(Ṇℓ)，其中Ṇ是光子数流。


<details>
  <summary>Details</summary>
Motivation: 传统上激光束被建模为纯相干态，但实际上激光束的状态是混合的，因为相位必须变化。本文旨在研究理想激光束的熵特性，特别是相位扩散对熵产生的影响。

Method: 考虑具有相位扩散速率ℓ的理想激光束，该速率等于其洛伦兹谱宽。通过理论分析推导激光束的熵流表达式，并与单向热束进行比较。

Result: 发现激光束的熵是广延的，熵流为√(Ṇℓ)，其中Ṇ是光子数流。该结果形式简单，并给出了直观解释。

Conclusion: 激光束的熵流由光子数流和相位扩散速率共同决定，这一简单结果揭示了激光束作为混合态的基本热力学特性。

Abstract: A laser beam is often modelled by a pure coherent state. In fact its state is mixed, even if it has coherent-state photon-number statistics (Poissonian), because the phase must vary. We consider such an ideal laser beam, with phase diffusion rate $\ell$, equal to its (Lorentzian) spectral width. We show that the beam entropy is extensive, with an entropy flow of $\dot{S} = \sqrt{\dot{N}\ell}$, where $\dot{N}$ is the number flow. We give an intuitive explanation for this remarkably simple result, and compare it to a unidirectional thermal beam.

</details>


### [239] [Geometric Phase of the Two-Particle Bethe Wavefunction](https://arxiv.org/abs/2512.01243)
*V. A. Tomilin,A. M. Rostom,L. V. Il'ichov*

Main category: quant-ph

TL;DR: 研究两个相互作用玻色子在环形势阱中由缺陷参数变化产生的几何相位，发现相互作用会增强几何相位


<details>
  <summary>Details</summary>
Motivation: 该研究受到基于原子玻色-爱因斯坦凝聚体的量子陀螺仪和量子加速度计概念的启发，旨在探索几何相位在量子传感应用中的潜力

Method: 采用Lieb-Liniger模型描述粒子相互作用，研究两个玻色子在带有局域缺陷的窄环形势阱中的系统，通过改变缺陷参数来产生几何相位

Result: 计算了能量谱并描述了其对问题参数的依赖关系，发现相互作用会导致给定变化路径下的几何相位增加

Conclusion: 粒子相互作用能够增强几何相位，这为基于原子玻色-爱因斯坦凝聚体的量子传感设备（如量子陀螺仪和加速度计）的设计提供了理论支持

Abstract: We consider a problem of geometric phase generation in a system of two interacting bosons confined in a narrow ring potential with a localized defect. Geometric phase emerges from variation of parameters of the defect. Particle interaction is taken into account within a framework of the Lieb-Liniger model. The energy spectrum is evaluated and its dependence on the parameters of the problem is described. It is shown that the interaction leads to increase of the geometric phase for a given contour of variations. The work is motivated by earlier proposed ideas of quantum gyroscope and quantum accelerometer based on atomic Bose-Einstein condensates.

</details>


### [240] [Tunable Single- and Multiphoton Bundles in Cavity-Coupled Atomic Arrays](https://arxiv.org/abs/2512.01250)
*Geng Zhao,Yun Chen,Jiayuang Zhang,Jing Tang,Yuangang Deng*

Main category: quant-ph

TL;DR: 该研究提出了一种在腔耦合可重构原子阵列中实现可调谐非经典光子的实验方案，通过控制集体干涉相位，系统可在单光子阻塞和高纯度多光子束发射之间切换。


<details>
  <summary>Details</summary>
Motivation: 建立连接合作原子相互作用与可控非经典光子统计的统一框架，为可扩展腔QED系统提供高保真多光子源的实际途径。

Method: 利用腔耦合可重构原子阵列，通过相干控制集体干涉相位，研究原子数宇称和腔失谐对光子关联的层次结构影响。

Result: 系统可在单光子阻塞和多光子束发射之间切换，光子布居标度识别了超辐射和亚辐射区域之间的转变，宇称和相位相关的自旋关联阐明了相干多光子产生的微观干涉过程。

Conclusion: 该工作建立了连接合作原子相互作用与可控非经典光子统计的统一框架，引入了一种独特的干涉机制，为可扩展腔QED系统的高保真多光子源提供了实用途径。

Abstract: We propose an experimentally accessible scheme for realizing tunable nonclassical light in cavity-coupled reconfigurable atomic arrays. By coherently controlling the collective interference phase, the system switches from single-photon blockade to high-purity multiphoton bundle emission, unveiling a hierarchical structure of photon correlations dictated by atom-number parity and cavity detuning. The scaling of photon population identifies the transition between superradiant and subradiant regimes, while parity- and phase-dependent spin correlations elucidate the microscopic interference processes enabling coherent multiphoton generation. This work establishes a unified framework connecting cooperative atomic interactions to controllable nonclassical photon statistics and introduces a distinct interference-enabled mechanism that provides a practical route toward high-fidelity multiphoton sources in scalable cavity QEDs.

</details>


### [241] [Measurement-based quantum computation on weighted graph states with arbitrarily small weight](https://arxiv.org/abs/2512.01327)
*Tomohiro Yamazaki,Yuki Takeuchi*

Main category: quant-ph

TL;DR: 加权图态作为图态的自然推广，通过应用受控相位门而非受控Z门生成。研究表明，在合适平面图上具有任意非零常数权重的均匀加权图态构成测量基量子计算的通用资源。


<details>
  <summary>Details</summary>
Motivation: 探索仅使用非最大纠缠门制备通用量子计算资源的可能性，这对于弱相互作用系统（如光子系统）具有潜在应用价值。

Method: 使用加权图态作为图态的自然推广，通过受控相位门（而非受控Z门）生成。研究在合适平面图上的均匀加权图态，分析其作为测量基量子计算通用资源的性质。

Result: 证明在合适平面图上具有任意非零常数权重的均匀加权图态构成测量基量子计算的通用资源。这是首个仅使用非最大纠缠门制备通用资源的例子。

Conclusion: 加权图态为测量基量子计算提供了新的通用资源类别，特别适用于弱相互作用系统，为光子系统等应用开辟了新途径。

Abstract: Weighted graph states are a natural generalization of graph states, which are generated by applying controlled-phase gates, instead of controlled-Z gates, to a separable state. In this paper, we show that uniformly weighted graph states on a suitable planar graph constitute universal resources for measurement-based quantum computation for an arbitrary nonzero constant weight. To our knowledge, this is the first example of universal resources prepared with only non-maximally entangling gates and has potential applications to weakly interacting systems, such as photonic systems.

</details>


### [242] [Enhanced Single-Photon Detector: Achieving Superconducting-Level Performance with Conventional Quantum Technology](https://arxiv.org/abs/2512.01328)
*Hao Shu*

Main category: quant-ph

TL;DR: 提出增强型单光子探测器（ESPD）框架，通过迭代增强低技术SPD实现高性能，无需超导材料，将59%探测效率提升至95%以上，暗计数率降至10^-9以下，性能媲美超导SPD。


<details>
  <summary>Details</summary>
Motivation: 现有高性能单光子探测器依赖超导材料，需要低温环境等技术要求，限制了大规模商业部署。需要开发不依赖超导技术的高性能SPD解决方案。

Method: 提出ESPD框架，使用标准量子光学组件，通过迭代增强的方式改造传统非超导SPD。该方案将低技术SPD（探测效率约59%，暗计数率10^-2）转化为高性能设备。

Result: ESPD方案实现探测效率高于95%，暗计数率低于10^-9，性能达到或超过最近设计的超导SPD。可将量子密钥分发协议的最小可容忍信道传输率降低几个数量级。

Conclusion: ESPD框架为高性能单光子探测器的大规模部署提供了清晰、可扩展的路径，使用现有技术即可实现，具有近期实验可行性，有助于量子通信技术的商业化。

Abstract: High-performance single-photon detectors (SPDs) are indispensable components for quantum optical tasks. However, the reliance of state-of-the-art devices on superconducting materials imposes severe technological demands and challenging operational conditions (e.g., cryogenics), which hinder scalable commercial deployment. To address this, we propose the Enhanced Single-Photon Detector (ESPD) framework, a novel paradigm for achieving high-performance SPDs through the iterative enhancement of low-technology SPDs. Utilizing only standard quantum optical components, the ESPD scheme transforms a legacy non-superconducting SPD, with detection efficiency (DE) about $59\%$ and dark count rate (DCR) $10^{-2}$, into a device with superior performance metrics, achieving DE higher than $95\%$ and DCR below $10^{-9}$. This level of performance is comparable to or surpasses recently designed superconducting SPDs, allowing the minimal tolerable channel transmission rate for Quantum Key Distribution (QKD) protocols to be reduced by several orders of magnitude. Furthermore, the scheme's device requirements are moderate, relying on readily available current technology, which ensures near-term experimental feasibility. The ESPD framework thus provides a clear, scalable path toward the large-scale deployment of high-performance SPDs and the commercialization of quantum communication technologies.

</details>


### [243] [Long nuclear spin coherence times for molecules trapped in high-purity solid parahydrogen](https://arxiv.org/abs/2512.01337)
*Alexandar P. Rollings,Jonathan D. Weinstein*

Main category: quant-ph

TL;DR: 在固态仲氢中捕获的HD分子质子自旋的T2*和T2时间测量，使用高纯度仲氢基质获得比先前工作更长的相干时间


<details>
  <summary>Details</summary>
Motivation: 研究固态仲氢基质中HD分子质子自旋的相干特性，探索基质纯度对自旋相干时间的影响，确定仲氢基质本身对相干时间的限制

Method: 使用高纯度仲氢基质捕获HD分子，测量质子自旋的横向弛豫时间(T2*)、自旋回波相干时间(T2)和纵向弛豫时间(T1)，分析这些参数随基质纯度的变化规律

Result: 相比先前工作测量到显著更长的T2和T2*时间，确定了基质纯度与相干时间的标度关系，发现了仲氢基质本身对相干时间的限制因素

Conclusion: 高纯度仲氢基质能显著延长HD分子质子自旋的相干时间，但基质本身存在固有的相干时间限制，这为量子信息处理和精密测量应用提供了重要参考

Abstract: We measure the ensemble transverse relaxation time (T2*) and spin-echo coherence time (T2) of the proton spin of HD molecules trapped in solid parahydrogen. By using high-purity parahydrogen matrices, we are able to measure significantly longer T2 and T2* times than seen in prior work. We also measure the longitudinal spin relaxation time T1. We examine how these parameters scale with the matrix purity and find limits on the coherence time from the parahydrogen matrix itself.

</details>


### [244] [Quantum state preparation and transfer based on the bound state in the doublon continuum](https://arxiv.org/abs/2512.01339)
*Xiaojun Zhang,Xiang Guo,Yan Zhang,Xin Wang,Zhihai Wang*

Main category: quant-ph

TL;DR: 在波导量子电动力学中，研究者发现了一种嵌入双粒子连续谱的束缚态（BIDC），利用这种相互作用启发的BIDC，可以实现高保真度的四原子纠缠态制备和相干量子态传输。


<details>
  <summary>Details</summary>
Motivation: 连续谱中的束缚态（BICs）引起了广泛关注，但其多粒子对应物在波导量子电动力学中尚未得到充分探索。本研究旨在探索多粒子BICs的物理特性及其在量子信息处理中的应用潜力。

Method: 研究采用四个原子耦合到具有强在位相互作用的耦合谐振腔波导系统，通过理论分析和数值模拟识别并表征了嵌入双粒子连续谱的束缚态（BIDC）。

Result: 发现了相互作用启发的BIDC，并证明：（1）可以高保真度制备远距离四原子纠缠态；（2）量子纠缠态可以在空间分离的节点间相干传输。

Conclusion: 该研究为波导平台中的多粒子态生成和路由建立了可扩展机制，为利用多粒子BICs实现相互作用保护的量子通信开辟了新途径。

Abstract: Bound states in the continuum (BICs) have attracted intense interest, yet their many-particle counterparts remain largely unexplored in waveguide quantum electrodynamics. We identify and characterize a bound state embedded in the doublon continuum (BIDC) that emerges when four atoms couple to a coupled-resonator waveguide with strong on-site interaction. Exploiting this interaction-enabled BIDC, we show that (i) a distant, four-atom entangled state can be prepared with high fidelity, and (ii) quantum entangled states can be coherently transferred between spatially separated nodes. Our results establish a scalable mechanism for multi-particle state generation and routing in waveguide platforms, opening a route to interaction-protected quantum communication with many-particle BICs.

</details>


### [245] [Witnessing the Effective Entanglement in the COW Protocol](https://arxiv.org/abs/2512.01359)
*F. Rezazadeh,A. Mani,M. Khodabandeh,M. Jaberi,S. A. Madani*

Main category: quant-ph

TL;DR: 为COW量子密钥分发协议开发了验证有效纠缠的数学框架，包括两参数纠缠见证族，并分析了实验数据发现了有效纠缠的明确证据


<details>
  <summary>Details</summary>
Motivation: 为相干单向(COW)量子密钥分发协议建立严格的数学框架来验证有效纠缠的存在，这对于确保量子通信协议的安全性和有效性至关重要

Method: 引入了一个两参数族的纠缠见证，确定了这些见证有效的参数范围，并展示了它们在COW协议中揭示有效纠缠的能力

Result: 成功开发了验证COW协议中有效纠缠的数学框架，并对先前获得的实验数据进行分析，报告了有效纠缠的明确特征

Conclusion: 该研究为COW量子密钥分发协议提供了验证有效纠缠的严格数学工具，实验数据分析进一步证实了该协议中有效纠缠的存在

Abstract: We present a rigorous mathematical framework for verifying effective entanglement in a Coherent One-Way (COW) quantum key distribution setup. In particular, we introduce a two-parameter family of entanglement witnesses, identify the parameter ranges where they constitute valid witnesses, and demonstrate their ability to reveal effective entanglement in the COW protocol. Additionally, we analyze previously obtained experimental data from a COW implementation and report clear signatures of effective entanglement.

</details>


### [246] [Formal Verification of Noisy Quantum Reinforcement Learning Policies](https://arxiv.org/abs/2512.01502)
*Dennis Gross*

Main category: quant-ph

TL;DR: QVerifier：首个系统化验证量子强化学习策略安全性的方法，通过概率模型检查分析量子噪声对策略安全性的影响


<details>
  <summary>Details</summary>
Motivation: 量子强化学习策略面临量子测量不确定性和硬件噪声（如比特翻转、相位翻转、退极化错误）的挑战，可能导致不安全行为。现有工作缺乏系统化方法来验证训练后的QRL策略在特定噪声条件下是否满足安全要求。

Method: 提出QVerifier方法，应用概率模型检查分析训练后的QRL策略。该方法构建完整的策略-环境交互模型，将量子不确定性直接纳入转移概率，然后使用Storm模型检查器验证安全属性。

Result: 在多个QRL环境中的实验表明，QVerifier能够精确测量不同噪声模型对安全性的影响，既揭示了性能下降的情况，也发现了噪声可能有益的情况。

Conclusion: QVerifier通过在部署前实现严格的安全验证，解决了量子硬件访问昂贵的关键需求。该方法瞄准了经典-量子的潜在优势：训练后的QRL策略在量子硬件上高效执行，同时仍可通过经典概率模型检查进行验证，尽管实时经典部署可能太慢。

Abstract: Quantum reinforcement learning (QRL) aims to use quantum effects to create sequential decision-making policies that achieve tasks more effectively than their classical counterparts. However, QRL policies face uncertainty from quantum measurements and hardware noise, such as bit-flip, phase-flip, and depolarizing errors, which can lead to unsafe behavior. Existing work offers no systematic way to verify whether trained QRL policies meet safety requirements under specific noise conditions.
  We introduce QVerifier, a formal verification method that applies probabilistic model checking to analyze trained QRL policies with and without modeled quantum noise. QVerifier builds a complete model of the policy-environment interaction, incorporates quantum uncertainty directly into the transition probabilities, and then checks safety properties using the Storm model checker.
  Experiments across multiple QRL environments show that QVerifier precisely measures how different noise models influence safety, revealing both performance degradation and cases where noise can help. By enabling rigorous safety verification before deployment, QVerifier addresses a critical need: because access to quantum hardware is expensive, pre-deployment verification is essential for any safety-critical use of QRL. QVerifier targets a potential classical-quantum sweet spot: trained QRL policies that execute efficiently on quantum hardware, yet remain tractable for classical probabilistic model checking despite being too slow for real-time classical deployment.

</details>


### [247] [Learning Reduced Representations for Quantum Classifiers](https://arxiv.org/abs/2512.01509)
*Patrick Odagiu,Vasilis Belis,Lennart Schulze,Panagiotis Barkoutsos,Michele Grossi,Florentin Reiter,Günther Dissertori,Ivano Tavernelli,Sofia Vallecorsa*

Main category: quant-ph

TL;DR: 该论文研究了在量子机器学习中应用降维方法处理高维数据，通过比较传统特征提取算法和自编码器模型，发现自编码器能学习更好的低维表示，其中设计的Sinkclass自编码器性能比基线提升40%。


<details>
  <summary>Details</summary>
Motivation: 当前量子机器学习算法难以处理具有大量特征的数据集，需要降维方法作为预处理步骤，以扩展量子机器学习在更多数据集上的适用性。

Method: 研究了6种传统特征提取算法和5种基于自编码器的降维模型，应用于具有67个特征的粒子物理数据集。使用降维后的表示训练量子支持向量机，解决LHC质子碰撞中希格斯玻色子产生的二分类问题。

Result: 自编码器方法学习到了更好的数据低维表示，其中设计的Sinkclass自编码器性能比基线提升了40%。

Conclusion: 开发的方法扩展了量子机器学习在更多数据集上的适用性，并提供了在此背景下有效的降维方案。

Abstract: Data sets that are specified by a large number of features are currently outside the area of applicability for quantum machine learning algorithms. An immediate solution to this impasse is the application of dimensionality reduction methods before passing the data to the quantum algorithm. We investigate six conventional feature extraction algorithms and five autoencoder-based dimensionality reduction models to a particle physics data set with 67 features. The reduced representations generated by these models are then used to train a quantum support vector machine for solving a binary classification problem: whether a Higgs boson is produced in proton collisions at the LHC. We show that the autoencoder methods learn a better lower-dimensional representation of the data, with the method we design, the Sinkclass autoencoder, performing 40% better than the baseline. The methods developed here open up the applicability of quantum machine learning to a larger array of data sets. Moreover, we provide a recipe for effective dimensionality reduction in this context.

</details>


### [248] [Fixed Points in Quantum Metric Spaces: A Structural Advantage over Fuzzy Frameworks](https://arxiv.org/abs/2512.01583)
*Nicola Fabiano*

Main category: quant-ph

TL;DR: 该论文证明了量子度量空间中压缩映射不动点的存在唯一性定理，其中可区分性由L²范数定义，并将结果应用于归一化实值高斯波函数。通过与模糊度量空间的对比，揭示了量子框架更深层的结构一致性。


<details>
  <summary>Details</summary>
Motivation: 研究量子度量空间中压缩映射的不动点理论，通过与模糊度量空间对比，揭示量子框架在几何丰富性和结构一致性方面的优势，将模糊逻辑的批判扩展到内在不确定性下的动态推理。

Method: 使用L²范数定义量子度量空间中的距离：d_Q(ψ₁,ψ₂) = ‖ψ₁ - ψ₂‖，证明压缩映射的不动点存在唯一性定理，并将结果应用于保持函数形式的连续压缩演化下的归一化实值高斯波函数。

Result: 成功证明了量子度量空间中压缩映射不动点的存在唯一性定理，该结果适用于归一化实值高斯波函数。通过与模糊度量空间的对比，发现量子框架不仅具有技术优势，还与希尔伯特空间的几何丰富性兼容。

Conclusion: 量子度量空间框架比模糊度量空间具有更深层的结构一致性，不仅体现在干涉、相位敏感性和拓扑保护等方面，更重要的是与希尔伯特空间的几何结构兼容，为内在不确定性下的动态推理提供了更坚实的数学基础。

Abstract: We prove an existence and uniqueness theorem for fixed points of contraction maps in the framework of quantum metric spaces, where distinguishability is defined by the $L^2$ norm: $d_Q(ψ_1,ψ_2) = \|ψ_1 - ψ_2\|$. The result applies to normalized real-valued Gaussian wavefunctions under continuous contractive evolution preserving the functional form. In contrast, while fuzzy metric spaces admit analogous fixed point theorems, they lack interference, phase sensitivity, and topological protection. This comparison reveals a deeper structural coherence in the quantum framework -- not merely technical superiority, but compatibility with the geometric richness of Hilbert space. Our work extends the critique of fuzzy logic into dynamical reasoning under intrinsic uncertainty.

</details>


### [249] [Directly computing Wigner functions for open quantum systems](https://arxiv.org/abs/2512.01590)
*Nick Huggett,Christian Käding,Mario Pitschmann,James Read*

Main category: quant-ph

TL;DR: 该论文推导了开放量子系统中时间依赖Wigner函数的直接计算方法，避免了求解运动方程所需的近似。


<details>
  <summary>Details</summary>
Motivation: Wigner函数在量子力学中有广泛应用，但在开放量子系统中，特别是当粒子与非相对论或相对论环境相互作用时，直接计算时间依赖的Wigner函数通常需要额外的近似。本文旨在提供一种更直接的计算方法。

Method: 考虑一个由非相对论单粒子和可能相对论的一般环境组成的开放量子系统，推导出直接从初始值计算时间依赖Wigner函数的表达式，避免了求解对应运动方程所需的近似。

Result: 成功推导出开放量子系统中时间依赖Wigner函数的直接计算表达式，使时间依赖Wigner函数更具实用性，无需额外近似即可求解。

Conclusion: 该研究提供了一种更直接计算开放量子系统中时间依赖Wigner函数的方法，通过Yukawa相互作用的标量粒子与相对论标量场环境的示例验证了方法的有效性，增强了Wigner函数在复杂量子系统中的应用潜力。

Abstract: The Wigner function is a well-known phase space distribution function with many applications in quantum mechanics. In this article, we consider an open quantum system consisting of a non-relativistic single particle interacting with a general, possibly relativistic environment. For this system, we derive an expression for directly computing the time-dependent Wigner function from its initial values. This result renders time-dependent Wigner functions more applicable without having to make additional approximations that would otherwise be required in order to solve the corresponding equation of motion. As an illustration of our findings, we discuss the example of a non-relativistic single scalar particle interacting via a Yukawa interaction with an environment comprising another type of scalar field that is treated relativistically.

</details>


### [250] [Resource Estimation for VQE on Small Molecules: Impact of Fermion Mappings and Hamiltonian Reductions](https://arxiv.org/abs/2512.01605)
*Anurag K. S. V.,Ashish Kumar Patra,Vikas Dattatraya Ghevade,Sai Shankar P.,Ruchika Bhat,Raghavendra V.,Rahul Maitra,Jaiganesh G*

Main category: quant-ph

TL;DR: 该研究系统分析了VQE-UCCSD方法在不同费米子-量子比特编码方案下的资源需求，发现通过适当的变换和对称性约简，可显著减少量子比特和量子门数量。


<details>
  <summary>Details</summary>
Motivation: 准确确定分子的基态能量是量子化学的挑战，对药物发现和材料设计至关重要。VQE是解决这一问题的混合量子-经典范式，但受限于当前量子硬件的噪声和可扩展性。需要理解计算资源如何随分子复杂性和编码方案扩展，以在NISQ和FASQ设备上实现高效模拟。

Method: 采用VQE-UCCSD方法，将分子哈密顿量二次量子化，通过Jordan-Wigner、Bravyi-Kitaev和Parity变换映射到量子比特算符。分析哈密顿量约简策略，包括Z2锥化和冻结核近似，评估它们对量子资源扩展的影响。

Result: 分析表明，适当的变换结合基于对称性的约简，可显著减少量子资源：量子比特数量最多减少约50%，量子门数量最多减少约45倍，适用于所研究的代表性分子体系。

Conclusion: 该研究为在NISQ和FASQ硬件上执行化学相关模拟提供了实用见解，表明通过优化编码方案和哈密顿量约简策略，可以显著降低量子计算资源需求。

Abstract: Accurate determination of ground-state energies for molecules remains a challenge in quantum chemistry and a cornerstone for progress in fields such as drug discovery and materials design. The Variational Quantum Eigensolver (VQE) represents a leading hybrid quantum-classical paradigm for addressing this challenge; however, its widespread realization is limited by noise and the restricted scalability of current quantum hardware. Achieving efficient simulations on Noisy Intermediate-Scale Quantum (NISQ) devices and forthcoming Fault-Tolerant Application-Scalable Quantum (FASQ) systems demands a detailed understanding of how computational resources scale with molecular complexity and fermion-to-qubit encoding schemes. In this study, resource requirements for VQE implementations employing the Unitary Coupled Cluster Singles and Doubles (UCCSD) ansatz are systematically analyzed. The molecular Hamiltonian is formulated in second quantization and mapped to qubit operators through the Jordan-Wigner (JW), Bravyi-Kitaev (BK), and Parity (Pa) transformations. Hamiltonian reduction strategies, including $\mathbb{Z}_2$ tapering and frozen-core approximations, are examined to assess their effect on quantum resource scaling. The analysis reveals that appropriate transformations, when combined with symmetry-based reductions, can substantially reduce qubit counts by up to $\approx 50\%$ and quantum gate counts by up to $\approx 45\times$ for the representative set of molecular systems under study. This provides practical insights for executing chemically relevant simulations on NISQ and FASQ hardware.

</details>


### [251] [Antibunching in locally driven dissipative Lieb lattices](https://arxiv.org/abs/2512.01645)
*Alex Ferrier,Michał Matuszewski,Piotr Deuar,Marzena H. Szymańska*

Main category: quant-ph

TL;DR: 在Lieb晶格中，通过局域驱动和量子干涉效应，可以在开放量子晶格系统中产生增强的反聚束效应，类似于非常规光子阻塞机制。


<details>
  <summary>Details</summary>
Motivation: 研究如何在开放量子晶格系统中利用几何阻挫和量子干涉效应来产生非平凡的量子关联，特别是在Lieb晶格及其相关几何结构中。

Method: 使用正P方法的随机模拟来计算扩展晶格的占据数和二阶关联函数，优化参数以在极化子微柱实验中观察该效应。

Result: 数值模拟显示，在驱动-耗散玻色-哈伯德模型中，特定的局域驱动方案可以利用量子干涉产生增强的反聚束效应。

Conclusion: 这项工作展示了利用局域驱动和干涉效应在开放量子晶格系统中产生非平凡量子关联的可能性。

Abstract: In Lieb lattices, geometric frustration and destructive interference of hopping cancels the occupation of certain sites, leading to flat-band physics. Here, we show numerically how, in the driven-dissipative Bose-Hubbard (DDBH) model arranged into Lieb lattices and related geometries, specific localised driving schemes can repurpose this interference to generate enhanced antibunching via a mechanism similar to the so-called unconventional photon blockade. Stochastic simulations using the positive-P method allow us to calculate occupations and second order correlations exactly for extended lattices. We use this to optimise the parameters for the possible observation of this effect in polariton micropillar experiments. This work demonstrates the possibility of using localised driving and interference effects to generate non-trivial quantum correlations in open quantum lattice systems.

</details>


### [252] [Formal equivalence between Maxwell equations and the de Broglie-Bohm theory for two-dimensional optical microcavities](https://arxiv.org/abs/2512.01671)
*Aurélien Drezet,Bernard Michael Nabet*

Main category: quant-ph

TL;DR: 该论文分析了光学微腔中麦克斯韦方程导出的电磁能量守恒定律与描述微腔中光子的有效质量粒子德布罗意-玻姆理论概率流体守恒之间的形式等价性，并对近期试图反驳德布罗意-玻姆理论的实验进行了批判性分析。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是对近期发表在《自然》杂志上的实验进行批判性分析，这些实验旨在反驳德布罗意-玻姆理论。作者希望证明在光学微腔系统中，电磁能量守恒定律与德布罗意-玻姆理论描述的概率流体守恒之间存在形式等价性。

Method: 通过分析光学微腔中麦克斯韦方程导出的电磁能量守恒定律，并将其与描述微腔中光子的有效质量粒子的德布罗意-玻姆理论概率流体守恒进行形式等价性比较。同时考虑了光子自旋和与辐射或吸收损失相关的随机性方面的扩展。

Result: 研究发现光学微腔中的电磁能量守恒定律与德布罗意-玻姆理论描述的概率流体守恒之间存在形式等价性，这对近期试图反驳该理论的实验提出了挑战。该分析对微光子学领域的影响超出了实验本身的范围。

Conclusion: 该研究得出结论，在光学微腔系统中，电磁能量守恒定律与德布罗意-玻姆理论描述的概率流体守恒之间存在形式等价性，这对反驳德布罗意-玻姆理论的实验提出了质疑。该分析对微光子学领域具有重要意义，特别是在考虑光子自旋和随机性扩展方面。

Abstract: We analyze the formal equivalence between the electromagnetic energy conservation law derived from Maxwell's equations in an optical microcavity and the conservation of a probability fluid associated with the de Broglie-Bohm theory for an effective massive particle describing a photon in this cavity. This work is part of a critical analysis of recent experiments [Nature \textbf{643}, 67-72 (2025)] carried out with a view to refuting the de Broglie-Bohm theory. Furthermore, the consequences of our analysis for microphotonics go far beyond these experiments. In particular, extensions that take into account photon spin and stochastic aspects associated with radiative or absorption losses are considered.

</details>


### [253] [Parametric excitation of a ferrimagnetic sphere resonator](https://arxiv.org/abs/2512.01709)
*Eyal Buks*

Main category: quant-ph

TL;DR: 实验研究了亚铁磁球谐振器对外部参数激励的响应，发现基于量子系统自发解纠缠假设的理论模型与实验结果兼容，能解释线性主方程无法解释的系统不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究量子系统中解纠缠现象对实际物理系统的影响，验证解纠缠假设是否能解释传统线性主方程无法解释的实验现象。

Method: 通过实验测量亚铁磁球谐振器对外部参数激励的响应，并与基于解纠缠假设的理论模型预测进行比较。该模型在传统主方程中加入了非线性项，用于确定性生成解纠缠。

Result: 实验结果表明，基于解纠缠的模型与测量结果兼容，特别是该模型能定性地解释实验中观察到的系统不稳定性，而这是任何基于线性主方程的理论模型都无法推导出的。

Conclusion: 解纠缠假设为解释量子系统行为提供了新的理论框架，特别是在处理传统线性主方程无法解释的不稳定性现象方面显示出潜力。

Abstract: The response of a ferrimagnetic sphere resonator to an externally applied parametric excitation is experimentally studied. Measurement results are compared with predictions derived from a theoretical model, which is based on the hypothesis that disentanglement spontaneously occurs in quantum systems. According to this hypothesis, time evolution is governed by a modified master equation having an added nonlinear term that deterministically generates disentanglement. It is found that the disentanglement--based model is compatible with the experimental results. In particular, the model can qualitatively account for an experimentally observed instability in the system under study, which cannot be derived from any theoretical model that is based on a linear master equation.

</details>


### [254] [Folded optimal transport and its application to separable quantum optimal transport](https://arxiv.org/abs/2512.01722)
*Thomas Borsoni*

Main category: quant-ph

TL;DR: 提出折叠最优传输理论，将定义在凸集极边界上的成本扩展到整个凸集，统一了经典和可分量子最优传输框架。


<details>
  <summary>Details</summary>
Motivation: 扩展标准最优传输理论框架，使其能够处理更一般的凸集结构，而不仅仅是单纯形。为量子最优传输提供统一的理论基础。

Method: 基于Choquet理论和标准最优传输，引入折叠Kantorovich成本和折叠Wasserstein距离，研究其度量性质。将构造应用于量子设置，从纯态距离得到密度矩阵上的可分量子Wasserstein距离。

Result: 建立了折叠最优传输理论框架，统一了经典和可分量子最优传输。获得了Beatty和Stilck-França半距离的密切关系，发现半经典Golse-Paul成本可表示为折叠Kantorovich成本。

Conclusion: 折叠最优传输为经典和可分量子最优传输提供了统一的理论框架，扩展了最优传输理论的应用范围，特别是在量子信息处理领域。

Abstract: We introduce folded optimal transport, as a way of extending a cost or distance defined on the extreme boundary of a convex to the whole set, broadening the framework of standard optimal transport, found to be the particular case where the convex is a simplex. Relying on Choquet's theory and standard optimal transport, we introduce the so-called folded Kantorovitch cost and folded Wasserstein distance, and study the metric properties it provides to the convex. We then apply the construction to the quantum setting, and obtain an actual separable quantum Wasserstein distance on the set of density matrices from a distance on the set of pure states, closely related to the semi-distance of Beatty and Stilck-França [3], and of which we obtain a variety of properties. Folded optimal transport provides a unified setting for both classical and separable quantum optimal transport, and we also find that the semiclassical Golse-Paul [12] cost writes as a folded Kantorovitch cost.

</details>


### [255] [An introductory review of the theory of continuous-variable quantum key distribution: Fundamentals, protocols, and security](https://arxiv.org/abs/2512.01758)
*Maron F Anka,John A. Mora Rodríguez,Douglas F. Pinto,Lucas Q. Galvão,Micael A. Dias,Alexandre B. Tacla*

Main category: quant-ph

TL;DR: 本文是关于连续变量量子密钥分发的综述，旨在为新进入该领域的研究者提供理论入门，重点介绍基本概念、关键协议和安全分析框架。


<details>
  <summary>Details</summary>
Motivation: 巴西在量子通信技术领域日益增长的投资，以及为支持该战略领域新一代研究人员的培养，需要为进入这一快速发展领域的研究者提供清晰的学习路径。

Method: 采用综述方法，重点介绍CV-QKD的基本理论概念、关键协议（特别是基于相干态的制备-测量协议）以及针对集体攻击的安全证明框架，涵盖高斯和离散调制方案。

Result: 提供了从基本概念到高级主题的清晰学习路径，包括CV-QKD的基本原理、协议等效性（制备-测量协议与基于纠缠协议的等价性）、安全分析框架，并简要介绍了测量设备无关CV-QKD和有限尺寸安全分析等高级主题。

Conclusion: 该综述为CV-QKD领域的新研究者提供了必要的理论工具，有助于他们参与当前研究，支持量子通信技术战略领域新一代研究人员的培训和发展。

Abstract: Continuous-variable quantum key distribution (CV-QKD) has emerged as a promising approach for secure quantum communication, offering advantages such as high key generation rates, compatibility with standard telecommunication infrastructure, and potential for integration on photonic chips. This review provides an accessible introduction to the theory of CV-QKD, aimed at researchers entering this rapidly developing field. We focus on fundamental concepts, key protocols, and security analysis essential for understanding CV-QKD systems, with a special emphasis on prepare-and-measure protocols using coherent states under asymptotic security conditions. We explain their equivalence to entanglement-based protocols and detail the security proof framework against collective attacks, encompassing both Gaussian and discrete modulation schemes. We also briefly address more advanced topics, including measurement-device-independent CV-QKD and finite-size security analysis. This work is motivated by Brazil's growing investment in quantum communication technologies. By presenting a clear learning path from basic concepts to advanced topics, this work aims to equip newcomers with the essential tools to engage with current research in CV-QKD, thereby supporting the training of a new generation of researchers in this strategic field.

</details>


### [256] [Macroscopic Quantum Resonators Path Finder (MAQRO-PF) White Paper](https://arxiv.org/abs/2512.01777)
*Jack Homans,Laura da Palma Barbara,Jakub Wardak,Elliot Simcox,Tim M. Fuchs,Hendrik Ulbricht*

Main category: quant-ph

TL;DR: 本文提出在太空平台进行光学悬浮实验，探索量子力学的基本尺寸上限，解决地面实验中重力限制的问题。


<details>
  <summary>Details</summary>
Motivation: 光学悬浮粒子可用于研究量子力学，但目前尚未确定能够制备量子叠加态的物体尺寸绝对上限。探索这一极限需要让越来越大的物体自由相干演化，但所需的长时间自由演化会导致实验受重力限制，因此太空平台成为关键下一步。

Method: 提出在太空进行光学悬浮实验的方案，包括卫星设计、有效载荷开发等。通过太空环境消除重力限制，使更大尺寸的粒子能够进行长时间的自由相干演化。

Result: 目前处于白皮书阶段，提出了太空实验的整体方案，总结了卫星设计的当前状态，识别了需要进一步开发的有效载荷方面，并估算了有效载荷的需求。

Conclusion: 太空平台的光学悬浮实验是探索量子力学尺寸上限的关键步骤，需要进一步开发有效载荷技术，为未来在太空中测试量子与经典理论预测提供基础。

Abstract: Optically levitated particles are used in a wide range of experiments to explore both fundamental physics and to act as sensors to a variety of external forces. One field of particular interest that these particles can be used to investigate is quantum mechanics. Previous research has yet to set an absolute upper bound on the size of objects that can be prepared in a quantum superposition. Exploring this limit involves allowing ever-larger objects to freely and coherently evolve to assess if their behaviour matches quantum or classical theoretical predictions. However, the long free evolution times required for these behaviours to be visible result in the experiments being gravitationally limited. Space based platforms therefore become the next key step in these investigations. In this white paper, we shall discuss our proposal for an optical levitation experiment in space that will explore the fundamental upper size limits of quantum mechanics. We shall cover the scientific motivation behind these investigations, then summarize the current status of our designs for the satellite. We will then review the aspects of the payload that require further development, then summarize the current estimates of the payload's requirements.

</details>


### [257] [Hybrid Quantum State Preparation via Data Compression](https://arxiv.org/abs/2512.01798)
*Emad Rezaei Fard Boosari,Maryam Afsary*

Main category: quant-ph

TL;DR: 提出一种无需辅助比特的混合经典-量子策略，将一般n量子比特状态准备的CNOT门和电路深度从O(2^n)降低到O(poly(n))，适用于可压缩数据类别


<details>
  <summary>Details</summary>
Motivation: 传统精确幅度编码(EAE)需要O(2^n)的CNOT门和电路深度，这对于近期量子硬件来说不切实际，需要寻找更高效的量子状态准备方法

Method: 采用三步混合策略：1)经典压缩步骤获得输入的d稀疏表示；2)使用稀疏状态准备例程加载稀疏向量；3)通过多项式深度量子逆变换重建目标状态

Result: 在合成基准信号和真实生物医学时间序列上评估，使用傅里叶和Haar变换，相比EAE显著减少了CNOT计数和电路深度，性能与傅里叶序列加载器(FSL)相当

Conclusion: 经典数据压缩与量子解压缩相结合为高效量子状态准备提供了可扩展框架，无需变分训练或辅助寄存器即可减少量子开销

Abstract: Quantum state preparation (QSP) for a general $n$-qubit state requires $O(2^n)$ CNOT gates and circuit depth, making exact amplitude encoding (EAE) impractical for near-term quantum hardware. We introduce an ancilla-free hybrid classical-quantum strategy that reduces this cost to $O(poly(n))$ for a broad class of compressible data. The method first applies a classical compression step to obtain a $d$-sparse representation of the input, loads this sparse vector using a sparse-state preparation routine, and then reconstructs the target state through a polynomial-depth quantum inverse transform. We evaluate the framework on synthetic benchmark signals and real biomedical time series using Fourier and Haar transforms, demonstrating substantial reductions in CNOT counts and circuit depth compared to EAE, together with competitive performance relative to the Fourier Series Loader (FSL). The quantum simulation results show that combining classical data compression with quantum decompression provides a scalable framework for efficient QSP, reducing quantum overhead without requiring variational training or ancillary registers.

</details>


### [258] [Role of qubits in quantum entanglement and quantum teleportation](https://arxiv.org/abs/2512.01799)
*Laure Gouba*

Main category: quant-ph

TL;DR: 本文回顾了量子比特在量子纠缠和量子隐形传态中的作用


<details>
  <summary>Details</summary>
Motivation: 量子比特是量子纠缠的表现形式，也是量子隐形传态过程中的关键要素，需要系统回顾其在量子纠缠和量子隐形传态中的重要作用

Method: 采用文献综述方法，对量子比特在量子纠缠和量子隐形传态中的角色进行系统性回顾和分析

Result: 通过回顾分析，明确了量子比特作为量子纠缠载体和量子隐形传态核心要素的关键作用

Conclusion: 量子比特在量子纠缠和量子隐形传态中扮演着基础而关键的角色，是量子信息处理的核心要素

Abstract: A qubit is an exhibition of quantum entanglement and a key element in the quan- tum teleportation process. In this paper, we review the role of qubits in quantum entanglement and quantum teleportation.

</details>


### [259] [Achievable Identification Rates in Noisy Bosonic Broadcast Channels](https://arxiv.org/abs/2512.01833)
*Zuhra Amiri,Janis Nötzel*

Main category: quant-ph

TL;DR: 该论文研究了在噪声玻色子广播信道中使用相干态进行量子通信识别的容量问题，推导了可实现的识别速率区域，并确保即使在无限维设置中错误概率也能保持有界。


<details>
  <summary>Details</summary>
Motivation: 量子通信中的识别技术允许接收者验证消息的存在而无需解码其全部内容。虽然识别容量已在经典和有限维量子信道中得到探索，但在玻色子系统中的行为仍不够明确。本研究旨在分析噪声玻色子广播信道中的识别问题。

Method: 采用相干态在噪声玻色子广播信道上进行识别。利用量子假设检验方法，通过离散子集近似无限发送字母表来维持功率约束，从而处理无限维设置。

Result: 推导出了可实现的识别速率区域，并确保即使在无限维设置中错误概率也能保持有界。通过离散化方法成功处理了无限维玻色子系统的技术挑战。

Conclusion: 该研究为玻色子广播信道中的量子识别提供了理论基础，证明了在无限维系统中也能实现可靠的识别通信，为量子通信系统的实际应用提供了重要参考。

Abstract: Identification in quantum communication enables receivers to verify the presence of a message without decoding its entire content. While identification capacity has been explored for classical and finite-dimensional quantum channels, its behaviour in bosonic systems remains less understood. This work analyses identification over noisy bosonic broadcast channels using coherent states. We derive achievable identification rate regions while ensuring error probabilities remain bounded, even in an infinite-dimensional setting. Our approach leverages quantum hypothesis testing and approximates the infinite sender alphabet with discrete subsets to maintain power constraints.

</details>


### [260] [A Fluctuation-Dissipation Structure of Quantum Dynamical Semigroups Reveals a Unique Internal Hamiltonian](https://arxiv.org/abs/2512.01840)
*Fabricio Toscano,Sergey Sergeev*

Main category: quant-ph

TL;DR: 该论文解决了马尔可夫主方程中长期存在的模糊性问题，通过精化量子动力学半群的涨落耗散框架，证明了扩散耗散结构在Lindblad生成元对称性下的不变性，从而唯一识别内部哈密顿量。


<details>
  <summary>Details</summary>
Motivation: 解决量子马尔可夫主方程中长期存在的模糊性问题，即如何客观地区分动力学中的相干部分和非相干部分，以及如何唯一确定系统的固有能量结构。

Method: 精化量子动力学半群的涨落耗散框架，基于经典马尔可夫过程类比，证明有限维系统中扩散耗散结构在Lindblad生成元对称性下的不变性。

Result: 证明了扩散耗散结构在Lindblad生成元对称性下是不变的，这一不变性唯一地识别了内部哈密顿量，为客观区分动力学中的相干和非相干部分提供了通用原理。

Conclusion: 该框架提供了客观区分量子动力学中相干和非相干部分的通用原理，能够无歧义地确定系统的固有能量结构，解决了长期存在的模糊性问题。

Abstract: We refine a fluctuation-dissipation framework for quantum dynamical semigroups to resolve a long-standing ambiguity in Markovian master equations. For finite-dimensional systems, we prove that the underlying diffusion-dissipation structure - rooted in a classical Markov process analogy - is invariant under Lindblad generator symmetries. This invariance uniquely identifies the internal Hamiltonian. Our framework provides a universal principle for objectively distinguishing coherent from incoherent parts of the dynamics, enabling an unambiguous determination of a system's inherent energy structure.

</details>


### [261] [Approximate pushforward designs and image bounds on approximations](https://arxiv.org/abs/2512.01858)
*Jakub Czartowski,Adam Sawicki,Karol Życzkowski*

Main category: quant-ph

TL;DR: 该论文将量子推送设计框架扩展到近似设置，利用Schatten p-范数和Lipschitz连续性分析，推导了从复射影空间获得的推送设计近似参数界限，并在混合态情况下通过对称子空间结构优化了渐近估计。


<details>
  <summary>Details</summary>
Motivation: 将量子推送设计框架从精确设置扩展到近似设置，研究在有限精度下实现平均的近似推送设计，这对于实际量子计算和量子信息处理应用具有重要意义。

Method: 使用Schatten p-范数和Lipschitz连续性论证，分析从复射影空间获得的推送设计的近似参数界限，包括单纯形、混合态和量子通道。在混合态情况下，通过利用对称子空间结构来优化界限。

Result: 推导了近似推送设计的参数界限，在混合态情况下获得了渐近更紧的估计。数值模拟支持理论结果，在低维场景中显示出接近最优的性能。

Conclusion: 成功将量子推送设计扩展到近似设置，建立了理论界限并展示了实际可行性，为量子信息处理中的近似平均问题提供了有效的分析框架。

Abstract: We extend the framework of quantum pushforward designs to the approximate setting, where averaging is achieved only up to finite precision. Using Schatten $p$-norms and Lipschitz continuity arguments, we derive bounds on the approximation parameters of pushforward designs obtained from complex projective spaces, including simplices, mixed states, and quantum channels. In the mixed-state case, we refine the bounds by exploiting the symmetric subspace structure, leading to asymptotically tighter estimates. Numerical simulations support our theoretical results, showing near-optimality in low-dimensional scenarios.

</details>


### [262] [Scalable Quantum Reversible BCD Adder Architectures with Enhanced Speed and Reduced Quantum Cost for Next-Generation Computing](https://arxiv.org/abs/2512.01883)
*Negin Mashayekhi,Mohammad Reza Reshadinezhad,Antonio Rubio,Shekoofeh Moghimi*

Main category: quant-ph

TL;DR: 本文提出了两种优化的可逆BCD加法器设计，通过集成十进制进位跳跃技术降低延迟，在延迟和量子成本方面显著优于现有设计。


<details>
  <summary>Details</summary>
Motivation: 量子可逆计算范式结合了量子力学和可逆计算原理，支持下一代计算架构。BCD加法器是金融和商业系统中的关键算术组件，但现有可逆BCD加法器主要关注量子和可逆指标，忽视了延迟的关键影响，导致平衡优化成为重大挑战。

Method: 提出了两种优化的可逆BCD加法器设计：1）集成十进制进位跳跃技术以改善整体延迟；2）使用可逆逻辑门高效执行BCD加法并实现所需的校正逻辑，同时保持完全可逆性。

Result: 评估结果表明，提出的设计超越了现有的可逆BCD加法器，在最佳情况下平均改进：延迟降低85.12%，量子成本降低30.75%。

Conclusion: 这些进展展示了所提出的加法器集成到未来基于量子的算术单元和可扩展可逆计算系统的潜力。对真实银行交易数据的分析强调了BCD加法在实际应用中的重要性及其在准确高效货币计算中的广泛使用。

Abstract: The quantum and reversible paradigm merges the principles of quantum mechanics and reversible computation to enable information-preserving processing. It supports next-generation computing architectures that provide improved scalability and enhanced computational efficiency. Within these architectures, the decimal adder is a key arithmetic component, particularly for Binary Coded Decimal (BCD) operations widely used in financial and commercial systems. However, most reversible BCD adders focus primarily on quantum and reversible metrics, overlooking the critical influence of delay, which makes balanced optimization a significant challenge. This paper presents two reversible BCD adder designs optimized for both delay and quantum cost. One design integrates the decimal carry-skip technique to improve the overall delay. Using reversible logic gates, the proposed architectures efficiently perform BCD addition and implement the required correction logic while maintaining full reversibility. Evaluation results indicate that the proposed designs surpass existing reversible BCD adders, achieving best-case average improvements of 85.12% in delay and 30.75% in quantum cost. These advancements demonstrate the potential of the proposed adders for integration into future quantum-based arithmetic units and scalable reversible computing systems. Moreover, analysis of real banking transaction data underscores the practical importance of BCD addition and its widespread use in accurate and efficient monetary computations.

</details>


### [263] [Automated Compilation Including Dropouts: Tolerating Defective Components in Stabiliser Codes](https://arxiv.org/abs/2512.01943)
*Stasiu Wolanski*

Main category: quant-ph

TL;DR: ACID框架在无辅助量子比特范式下，为存在制造缺陷的量子芯片自动编译综合征提取电路，显著降低电路深度开销并提高芯片良率。


<details>
  <summary>Details</summary>
Motivation: 大规模固态量子设备制造过程中存在不可避免的缺陷，需要设计能够容忍制造缺陷的量子设备，以提高可用量子芯片的良率并降低系统成本。

Method: 提出自动化编译包含缺陷（ACID）框架，采用无辅助量子比特（或"中间输出"）范式，通过构建和求解优化问题，为存在缺陷耦合器或量子比特的稳定子码生成综合征提取电路。

Result: 对于表面码，ACID产生的电路深度开销仅为1×到1.5×，相比之前最佳方法LUCI的2×开销有显著改善；芯片良率提高最多3倍；对于双变量自行车码和颜色码，电路深度开销为1×到2.5×。

Conclusion: ACID框架能够在存在制造缺陷的情况下有效编译量子纠错码的综合征提取电路，显著降低电路深度开销并提高芯片良率，为实用化大规模量子计算提供了重要工具。

Abstract: Utility-scale solid-state quantum devices will need to fabricate quantum devices at scale using imperfect processes. By introducing tolerance to fabrication defects into the design of the quantum devices, we can improve the yield of usable quantum chips and lower the cost of useful systems. Automated Compilation Including Dropouts (ACID) is a framework that works in the ancilla-free (or `middle-out') paradigm, to generate syndrome extraction circuits for general stabiliser codes in the presence of defective couplers or qubits. In the ancilla-free paradigm, we do not designate particular qubits as measurement ancillas, instead measuring stabilisers using any of the data qubits in their support. This approach leads to a great deal of flexibility in how syndrome extraction circuits can be implemented. ACID works by constructing and solving an optimisation problem within the ancilla-free paradigm to find a short syndrome extraction circuit. Applied to the surface code, ACID produces syndrome-extraction circuits of depth between $1\times$ (no overhead) and $1.5\times$ relative to the depth of defect-free circuits. The LUCI algorithm, the best prior art, yielded a $2 \times$ overhead, so ACID offers a significant time saving. The yield of surface code chips with a logical error rate at most $10\times$ the dropout-free baseline is up to $3\times$ higher using ACID than using LUCI. I demonstrate the broad applicability of ACID by compiling syndrome extraction circuits for bivariate bicycle codes and the colour code. For these circuits, we incur a circuit-depth overhead of between $1\times$ (no overhead) and $2.5\times$ relative to defect-free circuits. I believe this work is the first to simulate both of these families of codes in the presence of fabrication defects.

</details>


### [264] [A List of Complexity Bounds for Property Testing by Quantum Sample-to-Query Lifting](https://arxiv.org/abs/2512.01971)
*Kean Chen,Qisheng Wang,Zhicheng Zhang*

Main category: quant-ph

TL;DR: 论文收集了49个量子样本到查询提升方法获得的属性测试复杂度界限，其中41个新结果，18个接近最优


<details>
  <summary>Details</summary>
Motivation: Wang和Zhang提出的量子样本到查询提升关系被Tang等人显著加强，本文旨在系统整理该方法在属性测试中获得的量子上下界结果

Method: 使用量子样本到查询提升技术，该方法将量子样本复杂度与量子查询复杂度联系起来，特别针对状态准备预言机的情况

Result: 共呈现49个复杂度界限，其中41个是新结果，18个是（接近）最优的，涵盖概率分布和量子状态的熵、相似性等属性测试

Conclusion: 量子样本到查询提升是获取属性测试量子复杂度界限的有效方法，本文系统整理了该方法的应用成果，为相关研究提供参考

Abstract: Quantum sample-to-query lifting, a relation between quantum sample complexity and quantum query complexity presented in Wang and Zhang (SIAM J. Comput. 2025), was significantly strengthened by Tang, Wright, and Zhandry (2025) to the case of state-preparation oracles. In this paper, we compile a list of quantum lower and upper bounds for property testing that are obtained by quantum sample-to-query lifting. The problems of interest include testing properties of probability distributions and quantum states, such as entropy and closeness. This collection contains new results, as well as new proofs of known bounds. In total, we present 49 complexity bounds, where 41 are new and 18 are (near-)optimal.

</details>


### [265] [A Heptalemma for Quantum Mechanics](https://arxiv.org/abs/2512.01982)
*John B. DeBrota,Christian List*

Main category: quant-ph

TL;DR: 论文提出了一个"七难困境"（heptalemma），展示了量子力学预测与七个看似合理的物理实在论命题之间的不一致性，任何六个命题可以共存，但七个同时成立则与量子力学矛盾。


<details>
  <summary>Details</summary>
Motivation: 作者旨在通过构建一个逻辑困境来揭示量子力学与经典物理实在论之间的根本冲突，为量子力学解释提供新的分类框架，并建立判断科学领域是否"经典"的诊断标准。

Method: 作者构建了一个包含七个关于物理实在论命题的逻辑系统（七难困境），分析这些命题与量子力学预测的一致性关系，证明七个命题同时成立与量子力学矛盾，而任意六个可以共存。

Result: 发现量子力学与七个物理实在论命题存在根本冲突，不同量子力学解释对应于放弃不同的命题，从而形成了对量子力学解释的新分类体系。

Conclusion: 七难困境不仅为量子力学解释提供了新的分类框架，还建立了判断科学领域是否"经典"的一般性诊断标准：经典领域应满足所有七个命题，而非经典领域则必须放弃其中至少一个。

Abstract: We present a seven-pronged no-go result for quantum mechanics: a "heptalemma". It shows that seven initially plausible theses about physical reality are jointly inconsistent with the predictions of quantum mechanics, while any six are jointly consistent. We must then decide which theses to retain and which to give up. Since different interpretations of quantum mechanics entail different responses to the heptalemma, we get a novel taxonomy of such interpretations. Beyond the application to quantum mechanics, the heptalemma offers a general diagnostic criterion for determining whether a given scientific domain should count as classical or not, and if not, how it departs from classicality.

</details>


### [266] [Parametric processes in nonlinear structures with reflections: an asymptotic-field approach](https://arxiv.org/abs/2512.01999)
*Tadeu Tassis,Salvador Poveda-Hospital,Nicolás Quesada,Martin Houde*

Main category: quant-ph

TL;DR: 该论文应用渐近场形式主义描述法布里-珀罗腔内的非线性光学过程，明确考虑系统反射，推导相互作用哈密顿量并计算光子对生成率，通过三个示例展示模型通用性。


<details>
  <summary>Details</summary>
Motivation: 虽然将非线性材料嵌入谐振结构可以增强和定制光子特性，但准确建模这些量子相互作用仍然具有挑战性。需要开发能够明确考虑系统反射的模型来描述腔内的非线性光学过程。

Method: 应用基于散射理论的渐近场形式主义来描述法布里-珀罗腔内的非线性光学过程，明确考虑系统反射。推导相互作用哈密顿量，并使用微扰理论计算光子对生成率。

Result: 通过三个示例展示了模型的通用性：(1) 具有平坦响应镜的理想腔中的自发参量下转换；(2) 周期性极化材料中反向传播光子对的生成；(3) 使用布拉格反射器构建的腔中的自发四波混频。

Conclusion: 渐近场形式主义能够有效描述法布里-珀罗腔内的非线性光学过程，明确考虑反射效应，为基于光子的量子技术中工程化量子态光的生成提供了准确的建模工具。

Abstract: The generation of engineered quantum states of light via nonlinear processes is fundamental for quantum technologies based on photons. Although embedding nonlinear materials within resonant structures allows for the enhancement and tailoring of photon properties, accurately modeling these quantum interactions remains a challenge. In this work, we apply the asymptotic-fields formalism, an approach based on scattering theory, to describe nonlinear optical processes within a Fabry-Pérot cavity. Unlike previous applications of this formalism, we explicitly account for reflections in the system. We derive the interaction Hamiltonian and calculate photon-pair generation rates using perturbation theory. The versatility of this model is illustrated through three examples: (i) spontaneous parametric down-conversion in an idealized cavity with flat-response mirrors; (ii) the generation of counter-propagating photon pairs in a periodically-poled material; and (iii) spontaneous four-wave mixing in a cavity built with Bragg reflectors.

</details>
