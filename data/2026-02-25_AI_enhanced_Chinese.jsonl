{"id": "2602.20174", "categories": ["cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.20174", "abs": "https://arxiv.org/abs/2602.20174", "authors": ["C. A. L\u00fctken"], "title": "Elliptic mirror of the quantum Hall effect", "comment": "31 pages, 12 figures", "summary": "Toroidal sigma models of magneto-transport are analyzed, in which integer and fractional quantum Hall effects automatically are unified by a {holomorphic modular symmetry}. By exploiting a quantum equivalence called \\emph{mirror symmetry}, these models are mapped to tractable mirror models (also elliptic), in which topological protection is provided by more familiar winding numbers. Phase diagrams and scaling properties of elliptic models are compared to some of the experimental and numerical data accumulated over the past three decades. The geometry of scaling flows extracted from quantum Hall experiments is in good agreement with modular predictions, including the location of many quantum critical points. One conspicuous model %(arguably the simplest and most natural one) has a critical delocalization exponent $\u03bd_{\\rm tor} = 18 \\ln 2 /(\u03c0^2 G^4) = 2.6051\\dots$ ($G$ is Gauss' constant) that is in excellent agreement with the value $\u03bd_{\\rm num} = 2.607\\pm\\,.004$ calculated in the numerical Chalker-Coddington model, suggesting that these models are in the same universality class. The real delocalization exponent may be disentangled from other scaling exponents in finite size scaling experiments, giving an experimental value $\u03bd_{\\rm exp} = 2.3\\pm 0.2$. The modular model suggests how these theoretical and experimental results may be reconciled, but in order to determine if these theoretical models really are in the quantum Hall universality class, improved finite size scaling experiments are urgently needed.", "AI": {"tldr": "\u63d0\u51fa\u73af\u9762\u03c3\u6a21\u578b\uff0c\u7528\u5168\u7eaf\u6a21\u5bf9\u79f0\u6027\u7edf\u4e00\u63cf\u8ff0\u6574\u6570\u91cf\u5b50\u970d\u5c14\u6548\u5e94\u548c\u5206\u6570\u91cf\u5b50\u970d\u5c14\u6548\u5e94\uff0c\u901a\u8fc7\u955c\u50cf\u5bf9\u79f0\u6620\u5c04\u5230\u53ef\u89e3\u7684\u692d\u5706\u6a21\u578b\uff0c\u5176\u4e34\u754c\u6307\u6570\u4e0e\u6570\u503c\u6a21\u62df\u7ed3\u679c\u9ad8\u5ea6\u543b\u5408", "motivation": "\u901a\u8fc7\u5168\u7eaf\u6a21\u5bf9\u79f0\u6027\u81ea\u52a8\u7edf\u4e00\u6574\u6570\u548c\u5206\u6570\u91cf\u5b50\u970d\u5c14\u6548\u5e94\uff0c\u89e3\u51b3\u4f20\u7edf\u7406\u8bba\u4e2d\u4e24\u8005\u5206\u79bb\u7684\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u91cf\u5b50\u4e34\u754c\u70b9\u7684\u666e\u9002\u6027\u89c4\u5f8b", "method": "\u5229\u7528\u955c\u50cf\u5bf9\u79f0\u5c06\u590d\u6742\u7684\u73af\u9762\u03c3\u6a21\u578b\u6620\u5c04\u4e3a\u53ef\u5904\u7406\u7684\u692d\u5706\u6a21\u578b\uff0c\u901a\u8fc7\u62d3\u6251\u5377\u7ed5\u6570\u63cf\u8ff0\u62d3\u6251\u4fdd\u62a4\uff0c\u5e76\u5bf9\u6bd430\u5e74\u5b9e\u9a8c/\u6570\u503c\u6570\u636e\u9a8c\u8bc1\u51e0\u4f55\u6807\u5ea6\u6d41", "result": "1. \u6a21\u6a21\u578b\u9884\u6d4b\u7684\u6807\u5ea6\u6d41\u51e0\u4f55\u4e0e\u5b9e\u9a8c\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5305\u542b\u591a\u4e2a\u91cf\u5b50\u4e34\u754c\u70b9\u4f4d\u7f6e\uff1b2. \u4e34\u754c\u9000\u5c40\u57df\u5316\u6307\u6570\u03bd_tor=2.605\u4e0eChalker-Coddington\u6a21\u578b\u7684\u6570\u503c\u7ed3\u679c\u03bd_num=2.607\u00b10.004\u60ca\u4eba\u543b\u5408\uff1b3. \u5b9e\u9a8c\u503c\u03bd_exp=2.3\u00b10.2\u5b58\u5728\u5dee\u5f02", "conclusion": "\u73af\u9762\u03c3\u6a21\u578b\u4e0e\u6570\u503c\u6a21\u578b\u5f88\u53ef\u80fd\u5c5e\u4e8e\u540c\u4e00\u666e\u9002\u7c7b\uff0c\u4f46\u5b9e\u9a8c\u5dee\u5f02\u9700\u901a\u8fc7\u6539\u8fdb\u6709\u9650\u5c3a\u5bf8\u6807\u5ea6\u5b9e\u9a8c\u9a8c\u8bc1\uff1b\u82e5\u8bc1\u5b9e\uff0c\u8be5\u6846\u67b6\u5c06\u4e3a\u91cf\u5b50\u970d\u5c14\u4e34\u754c\u73b0\u8c61\u63d0\u4f9b\u7edf\u4e00\u7406\u8bba\u57fa\u7840"}}
{"id": "2602.20560", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.20560", "abs": "https://arxiv.org/abs/2602.20560", "authors": ["Yi-Ming Liu", "Wei-Qiang Chen", "Zheng-Cheng Gu"], "title": "Real-space construction and classification for time-reversal symmetric crystalline superconductors in 2D interacting fermionic systems", "comment": null, "summary": "Crystalline symmetry and time-reversal symmetry are commonly present in real superconducting materials. However, the topological classification of systems respecting these symmetries, particularly for interacting fermions, remains incomplete. In this work, we systematically classify time-reversal symmetry-protected crystalline topological superconductors in two-dimensional interacting fermionic systems using an explicit real-space construction. Among the resulting phases, we identify intrinsically interacting fermionic topological superconductors, i.e., phases that cannot be realized in either free-fermion or interacting bosonic systems. For spinless fermions with protecting symmetry group $C_4 \\times Z_2^T$ or $D_4 \\times Z_2^T$ (plus fermion parity), the intrinsic sector has a $Z_4$ classification. The corresponding root phases generating this $Z_4$ classification admit a transparent real-space construction in terms of decorated 1D blocks. These blocks are 1D fermionic symmetry-protected topological (FSPT) phases, realizable as double Majorana chains. We further find the corresponding $Z_4$ spinless intrinsic phases for wallpaper groups $p4$, $p4m$, and $p4g$. We also find an additional $Z_2$ intrinsically interacting phase for spinless fermions with wallpaper group $pm$, which is absent with the corresponding point-group symmetry alone. Moreover, these intrinsic phases naturally give rise to higher-order FSPT phases that support corner zero modes. Finally, we verify the crystalline equivalence principle for generic 2D interacting FSPT systems with both crystalline and internal symmetries.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5730\u5206\u7c7b\u4e86\u4e8c\u7ef4\u76f8\u4e92\u4f5c\u7528\u8d39\u7c73\u5b50\u7cfb\u7edf\u4e2d\u5177\u6709\u65f6\u95f4\u53cd\u6f14\u548c\u6676\u4f53\u5bf9\u79f0\u6027\u7684\u62d3\u6251\u8d85\u5bfc\u4f53\uff0c\u53d1\u73b0\u4e86\u65e0\u6cd5\u5728\u975e\u76f8\u4e92\u4f5c\u7528\u6216\u73bb\u8272\u5b50\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u7684\u65b0\u578b\u672c\u5f81\u76f8\u4e92\u4f5c\u7528\u62d3\u6251\u8d85\u5bfc\u76f8\u3002", "motivation": "\u5b9e\u9645\u8d85\u5bfc\u6750\u6599\u4e2d\u666e\u904d\u5b58\u5728\u6676\u4f53\u5bf9\u79f0\u6027\u548c\u65f6\u95f4\u53cd\u6f14\u5bf9\u79f0\u6027\uff0c\u4f46\u5bf9\u4e8e\u5177\u6709\u8fd9\u4e9b\u5bf9\u79f0\u6027\u7684\u76f8\u4e92\u4f5c\u7528\u8d39\u7c73\u5b50\u7cfb\u7edf\uff0c\u5176\u62d3\u6251\u5206\u7c7b\u5c1a\u4e0d\u5b8c\u6574\u3002", "method": "\u91c7\u7528\u663e\u5f0f\u7684\u5b9e\u7a7a\u95f4\u6784\u9020\u65b9\u6cd5\uff0c\u5bf9\u4e8c\u7ef4\u76f8\u4e92\u4f5c\u7528\u8d39\u7c73\u5b50\u7cfb\u7edf\u4e2d\u7684\u65f6\u95f4\u53cd\u6f14\u5bf9\u79f0\u4fdd\u62a4\u6676\u4f53\u62d3\u6251\u8d85\u5bfc\u4f53\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\u3002", "result": "\u5728C4\u00d7Z2^T\u3001D4\u00d7Z2^T\u7b49\u5bf9\u79f0\u6027\u4fdd\u62a4\u4e0b\uff0c\u53d1\u73b0\u5177\u6709Z4\u5206\u7c7b\u7684\u672c\u5f81\u76f8\u4e92\u4f5c\u7528\u76f8\uff1b\u8fd9\u4e9b\u76f8\u53ef\u901a\u8fc7\u88c5\u9970\u5316\u76841D\u8d39\u7c73\u5b50\u62d3\u6251\u76f8\uff08\u53cc\u9a6c\u7ea6\u62c9\u7eb3\u94fe\uff09\u6784\u5efa\uff1b\u6269\u5c55\u81f3p4\u3001p4m\u3001p4g\u3001pm\u7b49\u58c1\u7eb8\u7fa4\uff1b\u8fd9\u4e9b\u76f8\u53ef\u6f14\u751f\u51fa\u5177\u6709\u89d2\u96f6\u80fd\u6a21\u7684\u9ad8\u9636\u62d3\u6251\u76f8\uff1b\u5e76\u9a8c\u8bc1\u4e86\u6676\u4f53\u7b49\u6548\u539f\u7406\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5b8c\u5584\u4e86\u76f8\u4e92\u4f5c\u7528\u62d3\u6251\u8d85\u5bfc\u4f53\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u63ed\u793a\u4e86\u4e0e\u81ea\u7531\u8d39\u7c73\u5b50\u6216\u73bb\u8272\u5b50\u7cfb\u7edf\u672c\u8d28\u4e0d\u540c\u7684\u65b0\u578b\u62d3\u6251\u76f8\uff0c\u4e3a\u91cf\u5b50\u6750\u6599\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.20600", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20600", "abs": "https://arxiv.org/abs/2602.20600", "authors": ["Debraj Debata", "Abhirup Mukherjee", "Siddhartha Lal"], "title": "Kondo breakdown as an entanglement transition driven by continuous measurement", "comment": "28 pages, 19 Figures", "summary": "We study the breakdown of Kondo screening by a local magnetic field from the perspective of a measurement-driven entanglement transition in a monitored quantum system. Here, the Kondo coupling leads to the growth in entanglement of an impurity spin with it's fermionic environment, while the local field plays the role of a continuous observer. Using a non-perturbative Unitary Renormalization Group (URG) approach, we derive coupled renormalization-group flow equations for the Kondo exchange and the local field, and obtain a field-dependent RG phase diagram. The RG flows separate a low-energy Kondo-screened phase, where the impurity is absorbed into the Fermi sea and forms an entangled singlet with the conduction bath, from a polarized local-moment phase in which screening is frustrated and impurity-bath entanglement is suppressed. We identify the fixed-point Hamiltonians governing the two phases and the critical regime, and relate the transition to the emergence of a novel non-Fermi liquid. Various impurity signatures such as the spectral function and thermalisation of impurity observables are used to characterise this entanglement transition. These results offer insight into the interplay of decoherence and measurement in governing the dynamics of a prototypical quantum system.", "AI": {"tldr": "Reformulates Kondo breakdown as a measurement-driven entanglement transition using non-perturbative URG, revealing a phase diagram with Kondo-screened and polarized phases separated by a novel non-Fermi liquid critical point.", "motivation": "To understand how a local magnetic field disrupts Kondo screening by framing it as a continuous quantum measurement process that drives an entanglement transition between impurity and fermionic environment.", "method": "Non-perturbative Unitary Renormalization Group (URG) approach to derive coupled RG flow equations for Kondo exchange coupling and local magnetic field, analyzing fixed points and phase boundaries.", "result": "Identifies two distinct low-energy phases: a Kondo-screened phase (entangled singlet state) and a polarized local-moment phase (suppressed entanglement), with a critical transition point linked to a non-Fermi liquid; characterizes signatures via spectral functions and impurity thermalization.", "conclusion": "Demonstrates that decoherence from the local field acts as a measurement driving an entanglement transition, providing new insights into quantum measurement dynamics in strongly correlated electron systems."}}
{"id": "2602.20814", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.20814", "abs": "https://arxiv.org/abs/2602.20814", "authors": ["Dmitry M. Korotin", "Anna A. Anisimova", "Vladimir I. Anisimov"], "title": "Parameterizing DFT+U+V from Hybrid Functionals: A Wannier-Function-Based Approach for Strongly Correlated Materials", "comment": null, "summary": "We present an approach to parameterize DFT+$U$+$V$ from hybrid-functional calculations using Wannier-function projections. The method constructs a common localized Wannier basis for both semilocal DFT and hybrid-functional calculations, then determines effective on-site ($U$) and intersite ($V$) Hubbard parameters by minimizing the Hamiltonian mismatch within the correlated subspace. This procedure yields interaction parameters that reproduce the hybrid-functional electronic structure at a fraction of the computational cost and allow efficient structural relaxations and further many-body calculations. We validate the workflow on three oxide systems with different electronic characters: MgO (wide-gap insulator), NiO (antiferromagnetic charge-transfer insulator), and V$_2$O$_5$ (d$^0$ transition-metal oxide). In all cases, the mapped DFT+$U$+$V$ parameters reproduce hybrid-functional band gaps, densities of states, and magnetic moments and improve upon semilocal DFT while maintaining computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ece\u6742\u5316\u6cdb\u51fd\u8ba1\u7b97\u4e2d\u901a\u8fc7Wannier\u51fd\u6570\u6295\u5f71\u53c2\u6570\u5316DFT+U+V\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5171\u540c\u7684\u5c40\u57dfWannier\u57fa\u7ec4\u5e76\u6700\u5c0f\u5316\u54c8\u5bc6\u987f\u91cf\u5931\u914d\u6765\u786e\u5b9a\u6709\u6548Hubbard\u53c2\u6570\uff0c\u4ee5\u8f83\u4f4e\u6210\u672c\u7cbe\u786e\u91cd\u73b0\u6742\u5316\u6cdb\u51fd\u7684\u7535\u5b50\u7ed3\u6784", "motivation": "\u89e3\u51b3\u5f3a\u5173\u8054\u6750\u6599\u7535\u5b50\u7ed3\u6784\u8ba1\u7b97\u4e2d\u6742\u5316\u6cdb\u51fd\u7cbe\u5ea6\u9ad8\u4f46\u8ba1\u7b97\u6210\u672c\u6602\u8d35\uff0c\u800c\u4f20\u7edfDFT\u8ba1\u7b97\u6548\u7387\u5374\u7cbe\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5bfb\u6c42\u4e00\u79cd\u517c\u987e\u7cbe\u5ea6\u4e0e\u6548\u7387\u7684\u53c2\u6570\u5316\u65b9\u6848", "method": "\u6784\u5efa\u9002\u7528\u4e8eDFT\u548c\u6742\u5316\u6cdb\u51fd\u8ba1\u7b97\u7684\u516c\u5171\u5c40\u57dfWannier\u57fa\u7ec4\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5173\u8054\u5b50\u7a7a\u95f4\u5185\u54c8\u5bc6\u987f\u91cf\u5931\u914d\u6765\u786e\u5b9a\u5728\u4f4dU\u548c\u4f4d\u95f4V\u7684Hubbard\u76f8\u4e92\u4f5c\u7528\u53c2\u6570", "result": "\u5728MgO\u3001NiO\u548cV\u2082O\u2085\u4e09\u79cd\u4e0d\u540c\u7535\u5b50\u7279\u6027\u7684\u6c27\u5316\u7269\u4f53\u7cfb\u4e2d\u9a8c\u8bc1\u6210\u529f\uff0c\u8be5\u65b9\u6cd5\u80fd\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u7cbe\u786e\u91cd\u73b0\u6742\u5316\u6cdb\u51fd\u7684\u5e26\u9699\u3001\u6001\u5bc6\u5ea6\u548c\u78c1\u77e9\u7b49\u5173\u952e\u7535\u5b50\u6027\u8d28", "conclusion": "\u5efa\u7acb\u7684\u53c2\u6570\u5316\u6d41\u7a0b\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u7cbe\u5ea6\u7684\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u5f3a\u5173\u8054\u6750\u6599\u7684\u7ed3\u6784\u4f18\u5316\u548c\u591a\u4f53\u8ba1\u7b97\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.20303", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20303", "abs": "https://arxiv.org/abs/2602.20303", "authors": ["Joyanta Jyoti Mondal"], "title": "Multilevel Determinants of Overweight and Obesity Among U.S. Children Aged 10-17: Comparative Evaluation of Statistical and Machine Learning Approaches Using the 2021 National Survey of Children's Health", "comment": null, "summary": "Background: Childhood and adolescent overweight and obesity remain major public health concerns in the United States and are shaped by behavioral, household, and community factors. Their joint predictive structure at the population level remains incompletely characterized. Objectives: The study aims to identify multilevel predictors of overweight and obesity among U.S. adolescents and compare the predictive performance, calibration, and subgroup equity of statistical, machine-learning, and deep-learning models. Data and Methods: We analyze 18,792 children aged 10-17 years from the 2021 National Survey of Children's Health. Overweight/obesity is defined using BMI categories. Predictors included diet, physical activity, sleep, parental stress, socioeconomic conditions, adverse experiences, and neighborhood characteristics. Models include logistic regression, random forest, gradient boosting, XGBoost, LightGBM, multilayer perceptron, and TabNet. Performance is evaluated using AUC, accuracy, precision, recall, F1 score, and Brier score. Results: Discrimination range from 0.66 to 0.79. Logistic regression, gradient boosting, and MLP showed the most stable balance of discrimination and calibration. Boosting and deep learning modestly improve recall and F1 score. No model was uniformly superior. Performance disparities across race and poverty groups persist across algorithms. Conclusion: Increased model complexity yields limited gains over logistic regression. Predictors consistently span behavioral, household, and neighborhood domains. Persistent subgroup disparities indicate the need for improved data quality and equity-focused surveillance rather than greater algorithmic complexity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u679018,792\u540d\u7f8e\u56fd\u9752\u5c11\u5e74\u6570\u636e\uff0c\u6bd4\u8f83\u7edf\u8ba1\u5b66\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u8d85\u91cd/\u80a5\u80d6\u7684\u6548\u679c\uff0c\u53d1\u73b0\u590d\u6742\u6a21\u578b\u63d0\u5347\u6709\u9650\uff0c\u4e14\u79cd\u65cf\u4e0e\u8d2b\u56f0\u7fa4\u4f53\u7684\u9884\u6d4b\u5dee\u5f02\u6301\u7eed\u5b58\u5728\uff0c\u547c\u5401\u6539\u8fdb\u6570\u636e\u8d28\u91cf\u4e0e\u516c\u5e73\u6027\u76d1\u6d4b\u800c\u975e\u8ffd\u6c42\u7b97\u6cd5\u590d\u6742\u5ea6", "motivation": "\u7f8e\u56fd\u9752\u5c11\u5e74\u8d85\u91cd\u80a5\u80d6\u95ee\u9898\u4e25\u5cfb\uff0c\u4f46\u591a\u5c42\u9762\u884c\u4e3a\u3001\u5bb6\u5ead\u53ca\u793e\u533a\u56e0\u7d20\u7684\u8054\u5408\u9884\u6d4b\u7ed3\u6784\u5c1a\u672a\u660e\u786e\uff0c\u4e14\u4e0d\u540c\u7b97\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u4e0e\u7fa4\u4f53\u516c\u5e73\u6027\u4e0a\u7684\u5dee\u5f02\u9700\u7cfb\u7edf\u8bc4\u4f30", "method": "\u57fa\u4e8e2021\u5e74\u7f8e\u56fd\u513f\u7ae5\u5065\u5eb7\u8c03\u67e5\u6570\u636e\uff0c\u91c7\u7528\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost\u7b497\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7AUC\u3001F1\u503c\u7b49\u6307\u6807\u8bc4\u4f30\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u68c0\u9a8c\u79cd\u65cf\u4e0e\u8d2b\u56f0\u4e9a\u7ec4\u7684\u5dee\u5f02", "result": "\u6a21\u578b\u533a\u5206\u5ea60.66-0.79\uff0c\u903b\u8f91\u56de\u5f52\u4e0e\u68af\u5ea6\u63d0\u5347\u6811\u8868\u73b0\u6700\u5747\u8861\uff1b\u63d0\u5347\u7c7b\u4e0e\u6df1\u5ea6\u5b66\u4e60\u4ec5\u8f7b\u5fae\u6539\u5584\u53ec\u56de\u7387\u4e0eF1\uff0c\u4f46\u65e0\u6a21\u578b\u5168\u9762\u5360\u4f18\uff1b\u6240\u6709\u7b97\u6cd5\u5747\u5b58\u5728\u79cd\u65cf\u4e0e\u8d2b\u56f0\u7fa4\u4f53\u7684\u6027\u80fd\u5dee\u5f02", "conclusion": "\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u5bf9\u9884\u6d4b\u6548\u679c\u63d0\u5347\u6709\u9650\uff0c\u9700\u4f18\u5148\u63d0\u5347\u6570\u636e\u8d28\u91cf\u4e0e\u516c\u5e73\u6027\u76d1\u6d4b\uff0c\u800c\u975e\u4f9d\u8d56\u590d\u6742\u7b97\u6cd5\uff0c\u4ee5\u89e3\u51b3\u5065\u5eb7\u5dee\u5f02\u95ee\u9898"}}
{"id": "2602.20620", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.20620", "abs": "https://arxiv.org/abs/2602.20620", "authors": ["Munetaka Sasaki"], "title": "Construction of a Neural Network with Temperature-Dependent Recall Patterns", "comment": "6 pages, 10 figures", "summary": "We present a simple model that recalls two different patterns depending on the temperature. To realize a change in recall pattern due to temperature change, we embed two patterns to different graphs: the first pattern into a fully connected graph and the second pattern into a sparse graph. Because a fully connected graph is more resistant to thermal fluctuations than a sparse graph, we can realize a change in recall pattern by tuning relative weights of the two patterns properly. We demonstrate by equilibrium Monte-Carlo simulations that such a temperature-dependent change in recall patterns does occur in our model. Simulation results strongly indicate that the system undergoes a first-order phase transition when the change in recall patterns occurs. It is also demonstrated by annealing simulations that the system fails to recall the pattern embedded in the sparse graph at low temperatures if the free-energy barrier is too high to overcome within the given simulation timescale.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6e29\u5ea6\u4f9d\u8d56\u7684\u8bb0\u5fc6\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u5168\u8fde\u63a5\u56fe\u548c\u7a00\u758f\u56fe\u4e2d\u5d4c\u5165\u4e0d\u540c\u6a21\u5f0f\uff0c\u5b9e\u73b0\u6e29\u5ea6\u8c03\u63a7\u7684\u6a21\u5f0f\u56de\u5fc6\u5207\u6362\uff0c\u5e76\u89c2\u5bdf\u5230\u4e00\u7ea7\u76f8\u53d8\u73b0\u8c61\u3002", "motivation": "\u5b9e\u73b0\u6e29\u5ea6\u53d8\u5316\u5bfc\u81f4\u56de\u5fc6\u6a21\u5f0f\u6539\u53d8\u7684\u884c\u4e3a\uff0c\u5229\u7528\u4e0d\u540c\u56fe\u7ed3\u6784\u5bf9\u70ed\u6da8\u843d\u7684\u62b5\u6297\u80fd\u529b\u5dee\u5f02\u6765\u6784\u5efa\u6e29\u5ea6\u654f\u611f\u7684\u8bb0\u5fc6\u7cfb\u7edf\u3002", "method": "\u5c06\u4e24\u79cd\u6a21\u5f0f\u5206\u522b\u5d4c\u5165\u5168\u8fde\u63a5\u56fe\u548c\u7a00\u758f\u56fe\uff0c\u901a\u8fc7\u8c03\u8282\u6743\u91cd\u6bd4\u4f8b\uff1b\u91c7\u7528\u5e73\u8861\u8499\u7279\u5361\u6d1b\u6a21\u62df\u89c2\u5bdf\u6e29\u5ea6\u4f9d\u8d56\u7684\u56de\u5fc6\u53d8\u5316\uff0c\u5e76\u7528\u9000\u706b\u6a21\u62df\u7814\u7a76\u4f4e\u6e29\u4e0b\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002", "result": "\u6a21\u62df\u8bc1\u5b9e\u6e29\u5ea6\u4f9d\u8d56\u7684\u6a21\u5f0f\u56de\u5fc6\u53d8\u5316\u786e\u5b9e\u5b58\u5728\uff1b\u7cfb\u7edf\u5728\u6a21\u5f0f\u5207\u6362\u65f6\u7ecf\u5386\u4e00\u7ea7\u76f8\u53d8\uff1b\u9000\u706b\u6a21\u62df\u663e\u793a\u4f4e\u6e29\u4e0b\u81ea\u7531\u80fd\u5792\u8fc7\u9ad8\u4f1a\u5bfc\u81f4\u65e0\u6cd5\u56de\u5fc6\u7a00\u758f\u56fe\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u6a21\u578b\u6210\u529f\u5c55\u793a\u4e86\u6e29\u5ea6\u8c03\u63a7\u7684\u6a21\u5f0f\u56de\u5fc6\u529f\u80fd\u53ca\u5176\u76f8\u53d8\u7279\u6027\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u81ea\u7531\u80fd\u5792\u5bf9\u4f4e\u6e29\u8bb0\u5fc6\u63d0\u53d6\u7684\u9650\u5236\u3002"}}
{"id": "2602.20682", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.20682", "abs": "https://arxiv.org/abs/2602.20682", "authors": ["L. Salasnich", "F. Sattin"], "title": "Geometric investigation of chaos unfolding in Hamiltonian systems", "comment": null, "summary": "In this work we revisit the geometric approach to chaos in Hamiltonian dynamics, by means of the Jacobi-Levi-Civita equation (JLCE). We inspect numerically two low-dimensional dynamical systems; show that, along chaotic orbits, the exponential divergence between nearby trajectories quantified by the JLCE does not unfold in a continuous manner, rather is closer to a multiplicative discrete process: in correspondence of each turning point, where the trajectory bounces away from the boundary of the energetically allowed region, the relative separation increases sharply and abruptly. We highlight through analytical and numerical arguments that the chaotic rather than regular nature of the trajectory is determined by the details of the scattering with the boundary, and interpret these results in terms of parametric resonance theory, and specifically the Mathieu equation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u91cd\u65b0\u5ba1\u89c6\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u4e2d\u6df7\u6c8c\u7684\u51e0\u4f55\u65b9\u6cd5\uff0c\u53d1\u73b0\u6df7\u6c8c\u8f68\u9053\u4e2d\u76f8\u90bb\u8f68\u8ff9\u7684\u6307\u6570\u53d1\u6563\u5e76\u975e\u8fde\u7eed\u53d1\u751f\uff0c\u800c\u662f\u5728\u6bcf\u4e2a\u8f6c\u6298\u70b9\u5904\u5448\u73b0\u79bb\u6563\u7684\u7a81\u53d8\u5f0f\u589e\u957f\uff0c\u8fd9\u4e00\u73b0\u8c61\u53ef\u901a\u8fc7\u53c2\u6570\u5171\u632f\u7406\u8bba\uff08\u7279\u522b\u662f\u9a6c\u4e22\u65b9\u7a0b\uff09\u89e3\u91ca\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u8f68\u8ff9\u53d1\u6563\u662f\u8fde\u7eed\u6307\u6570\u8fc7\u7a0b\uff0c\u4f46\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u96c5\u53ef\u6bd4-\u5217\u7ef4-\u5947\u7ef4\u5854\u65b9\u7a0b\uff08JLCE\uff09\u63ed\u793a\u5176\u66f4\u7cbe\u7ec6\u7684\u79bb\u6563\u673a\u5236\u3002", "method": "\u91c7\u7528\u89e3\u6790\u4e0e\u6570\u503c\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff1a\u5bf9\u4f4e\u7ef4\u52a8\u529b\u7cfb\u7edf\u8fdb\u884c\u6570\u503c\u6a21\u62df\uff0c\u5206\u6790\u8f68\u8ff9\u5728\u80fd\u91cf\u5141\u8bb8\u533a\u57df\u8fb9\u754c\u5904\uff08\u8f6c\u6298\u70b9\uff09\u7684\u6563\u5c04\u884c\u4e3a\uff0c\u5e76\u5173\u8054\u53c2\u6570\u5171\u632f\u7406\u8bba\uff08\u9a6c\u4e22\u65b9\u7a0b\uff09\u3002", "result": "\u53d1\u73b0\u6df7\u6c8c\u8f68\u9053\u7684\u8f68\u8ff9\u5206\u79bb\u5728\u8f6c\u6298\u70b9\u5904\u53d1\u751f\u6025\u5267\u3001\u79bb\u6563\u7684\u8df3\u8dc3\u5f0f\u589e\u957f\uff0c\u800c\u975e\u8fde\u7eed\u6307\u6570\u53d1\u6563\uff1b\u6df7\u6c8c\u7279\u6027\u7531\u8fb9\u754c\u6563\u5c04\u7ec6\u8282\u51b3\u5b9a\u3002", "conclusion": "\u6df7\u6c8c\u7684\u672c\u8d28\u6e90\u4e8e\u8fb9\u754c\u6563\u5c04\u7684\u79bb\u6563\u52a8\u529b\u5b66\u8fc7\u7a0b\uff0c\u53c2\u6570\u5171\u632f\u7406\u8bba\uff08\u9a6c\u4e22\u65b9\u7a0b\uff09\u4e3a\u6b64\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u4fee\u6b63\u4e86\u4f20\u7edf\u8fde\u7eed\u53d1\u6563\u6a21\u578b\u3002"}}
{"id": "2602.20505", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.20505", "abs": "https://arxiv.org/abs/2602.20505", "authors": ["Yoshiki Kuramoto"], "title": "Half a century of the theory of synchronization", "comment": "10 pages, no figure, article submitted to the Statphys 19", "summary": "This review offers a retrospective of the development of the theory of coupled oscillators and synchronization over the past half century. Among the various works made by myself during this period, the following three specific works will be focused on, serving as some key points to illustrate the field's evolution. They are the derivation of (1) a simple partial differential equation exhibiting spatio-tempoeral chaos (Kuramoto-Sivashinsky equaiton), (2) a solvable mathematical model describing synchronization phase transition (Kuramoto model), and the discovery of (3) coexistence of coherence and incoherence in nonlocally coupled oscillators (chimera states). It is emphasized that all these works resulted fron the phase reduction of the complex Ginzburg-Landau equation (or its variants), the equation which was derived with a coworker in 1974 from a certain reaction-diffusion model. A quick overview will also be made on how the above three works influenced the subsequent development of the field of coupled oscillators and synchronization. Finally, a few comments will be made on how the methods of dynamical reduction, such as the center-manifold reduction and phase reduction, are crucial for exploring this field in depth. This article is a largely faithful reproduction of the content presented in my award lecture.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u56de\u987e\u4e86\u8026\u5408\u632f\u8361\u5668\u4e0e\u540c\u6b65\u7406\u8bba\u8fc7\u53bb50\u5e74\u7684\u53d1\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4f5c\u8005\u4e09\u9879\u6838\u5fc3\u8d21\u732e\uff1aKuramoto-Sivashinsky\u65b9\u7a0b\uff08\u65f6\u7a7a\u6df7\u6c8c\uff09\u3001Kuramoto\u6a21\u578b\uff08\u540c\u6b65\u76f8\u53d8\uff09\u53ca\u5d4c\u5408\u4f53\u6001\u53d1\u73b0\uff0c\u5f3a\u8c03\u8fd9\u4e9b\u6210\u679c\u5747\u6e90\u4e8e\u590d\u6742Ginzburg-Landau\u65b9\u7a0b\u7684\u76f8\u4f4d\u7ea6\u5316\u65b9\u6cd5\uff0c\u5e76\u603b\u7ed3\u52a8\u529b\u5b66\u7ea6\u5316\u65b9\u6cd5\u5bf9\u8be5\u9886\u57df\u7684\u5173\u952e\u4f5c\u7528\u3002", "motivation": "\u7cfb\u7edf\u68b3\u7406\u8026\u5408\u632f\u8361\u5668\u4e0e\u540c\u6b65\u7406\u8bba\u8fd150\u5e74\u7684\u6f14\u8fdb\u8109\u7edc\uff0c\u901a\u8fc7\u4e2a\u4eba\u4ee3\u8868\u6027\u5de5\u4f5c\u9610\u660e\u8be5\u9886\u57df\u7684\u5173\u952e\u7a81\u7834\u4e0e\u53d1\u5c55\u903b\u8f91\uff0c\u5f3a\u8c03\u6570\u5b66\u65b9\u6cd5\uff08\u5982\u76f8\u4f4d\u7ea6\u5316\uff09\u5728\u63a8\u52a8\u5b66\u79d1\u6df1\u5ea6\u63a2\u7d22\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\u3002", "method": "\u4ee5\u590d\u6742Ginzburg-Landau\u65b9\u7a0b\uff081974\u5e74\u4e0e\u5408\u4f5c\u8005\u4ece\u53cd\u5e94\u6269\u6563\u6a21\u578b\u5bfc\u51fa\uff09\u4e3a\u7406\u8bba\u57fa\u7840\uff0c\u91c7\u7528\u76f8\u4f4d\u7ea6\u5316\u3001\u4e2d\u5fc3\u6d41\u5f62\u7ea6\u5316\u7b49\u52a8\u529b\u5b66\u7ea6\u5316\u65b9\u6cd5\uff0c\u6784\u5efa\u53ef\u89e3\u6790\u6c42\u89e3\u7684\u7b80\u5316\u6a21\u578b\u3002", "result": "1) \u5bfc\u51fa\u63cf\u8ff0\u65f6\u7a7a\u6df7\u6c8c\u7684Kuramoto-Sivashinsky\u65b9\u7a0b\uff1b2) \u5efa\u7acb\u53ef\u89e3\u6790\u6c42\u89e3\u7684\u540c\u6b65\u76f8\u53d8Kuramoto\u6a21\u578b\uff1b3) \u53d1\u73b0\u975e\u5c40\u57df\u8026\u5408\u632f\u8361\u5668\u4e2d\u76f8\u5e72-\u975e\u76f8\u5e72\u5171\u5b58\u7684\u5d4c\u5408\u4f53\u6001\uff1b4) \u9610\u660e\u4e0a\u8ff0\u6210\u679c\u5bf9\u540e\u7eed\u7814\u7a76\u7684\u6df1\u8fdc\u5f71\u54cd\u3002", "conclusion": "\u76f8\u4f4d\u7ea6\u5316\u7b49\u52a8\u529b\u5b66\u7ea6\u5316\u65b9\u6cd5\u662f\u63ed\u793a\u8026\u5408\u7cfb\u7edf\u590d\u6742\u884c\u4e3a\u672c\u8d28\u7684\u6838\u5fc3\u5de5\u5177\uff0c\u5176\u8de8\u5c3a\u5ea6\u5efa\u6a21\u601d\u60f3\u5c06\u6301\u7eed\u63a8\u52a8\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e0e\u540c\u6b65\u7406\u8bba\u7684\u6df1\u5316\u53d1\u5c55\u3002"}}
{"id": "2602.20256", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20256", "abs": "https://arxiv.org/abs/2602.20256", "authors": ["Feng He", "Arthur Hutsalyuk", "Giuseppe Mussardo", "Andrea Stampiggi"], "title": "Spectral Decimation of Quantum Many-Body Hamiltonians", "comment": "16+6 pages; 5+3 figures", "summary": "We develop a systematic theory of spectral decimation for quantum many-body Hamiltonians and show that it provides a quantitative probe of emergent symmetries in statistically mixed spectra. Building on an analytical description of statistical mixtures, we derive an explicit expression for the size of a characteristic symmetry sector (CSS), defined as the largest subsequence of levels exhibiting non-Poissonian correlations. The CSS dimension is shown to be the size-biased average of the underlying symmetry sectors, establishing a direct link between spectral statistics and Hilbert-space structure. We apply this framework to two paradigmatic settings: Hilbert-space fragmentation and disorder-induced many-body localization (MBL). In fragmented systems, the CSS reproduces the mixture prediction and isolates correlated subsectors even when the full spectrum appears nearly Poissonian. In the disordered Heisenberg chain, spectral decimation reveals the gradual emergence of integrability through a shrinking CSS, whose statistics exhibit signatures consistent with local integrals of motion. We introduce a characteristic symmetry entropy (CSE) as a finite-size scaling observable and extract, within accessible system sizes, the crossover exponents. Our results establish spectral decimation as a controlled, unbiased and computationally inexpensive diagnostic of hidden structure in many-body spectra, capable of distinguishing between chaotic dynamics, statistical mixtures, and emergent integrability.", "AI": {"tldr": "\u63d0\u51fa\u8c31\u62bd\u53d6\u6cd5\u8fd9\u4e00\u65b0\u7406\u8bba\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u6790\u91cf\u5b50\u591a\u4f53\u7cfb\u7edf\u7684\u6df7\u5408\u8c31\u6765\u91cf\u5316\u6d8c\u73b0\u5bf9\u79f0\u6027\uff0c\u80fd\u6709\u6548\u533a\u5206\u6df7\u6c8c\u52a8\u529b\u5b66\u3001\u7edf\u8ba1\u6df7\u5408\u548c\u6d8c\u73b0\u53ef\u79ef\u6027\u3002", "motivation": "\u5f00\u53d1\u7cfb\u7edf\u6027\u7684\u8c31\u62bd\u53d6\u7406\u8bba\uff0c\u4e3a\u7edf\u8ba1\u6df7\u5408\u8c31\u4e2d\u7684\u6d8c\u73b0\u5bf9\u79f0\u6027\u63d0\u4f9b\u5b9a\u91cf\u63a2\u9488\u3002", "method": "\u57fa\u4e8e\u7edf\u8ba1\u6df7\u5408\u7684\u89e3\u6790\u63cf\u8ff0\uff0c\u63a8\u5bfc\u7279\u5f81\u5bf9\u79f0\u6247\u533a(CSS)\u7684\u663e\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e94\u7528\u4e8e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u788e\u88c2\u548cMBL\u4e24\u79cd\u5178\u578b\u4f53\u7cfb\u3002", "result": "CSS\u7ef4\u5ea6\u662f\u5bf9\u79f0\u6247\u533a\u7684\u52a0\u6743\u5e73\u5747\uff1b\u5728\u788e\u88c2\u4f53\u7cfb\u4e2d\u91cd\u73b0\u6df7\u5408\u9884\u6d4b\uff1b\u5728\u65e0\u5e8f\u6d77\u68ee\u5821\u94fe\u4e2d\u53d1\u73b0CSS\u6536\u7f29\u63ed\u793a\u53ef\u79ef\u6027\u6d8c\u73b0\uff0c\u5e76\u63d0\u51fa\u7279\u5f81\u5bf9\u79f0\u71b5(CSE)\u4f5c\u4e3a\u6709\u9650\u5c3a\u5bf8\u6807\u5ea6\u89c2\u6d4b\u91cf\u3002", "conclusion": "\u8c31\u62bd\u53d6\u6cd5\u662f\u4e00\u79cd\u53ef\u63a7\u3001\u65e0\u504f\u4e14\u8ba1\u7b97\u5ec9\u4ef7\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u53ef\u63ed\u793a\u591a\u4f53\u8c31\u4e2d\u7684\u9690\u85cf\u7ed3\u6784\u3002"}}
{"id": "2602.20832", "categories": ["cs.CC"], "pdf": "https://arxiv.org/pdf/2602.20832", "abs": "https://arxiv.org/abs/2602.20832", "authors": ["Amir Shpilka", "Yann Tal"], "title": "Polynomial Identity Testing and Reconstruction for Depth-4 Powering Circuits of High Degree", "comment": null, "summary": "We study deterministic polynomial identity testing (PIT) and reconstruction algorithms for depth-$4$ arithmetic circuits of the form \\[ \u03a3^{[r]}\\!\\wedge^{[d]}\\!\u03a3^{[s]}\\!\u03a0^{[\u03b4]}. \\] This model generalizes Waring decompositions and diagonal circuits, and captures sums of powers of low-degree sparse polynomials. Specifically, each circuit computes a sum of $r$ terms, where each term is a $d$-th power of an $s$-sparse polynomial of degree $\u03b4$. This model also includes algebraic representations that arise in tensor decomposition and moment-based learning tasks such as mixture models and subspace learning.\n  We give deterministic worst-case algorithms for PIT and reconstruction in this model. Our PIT construction applies when $d>r^2$ and yields explicit hitting sets of size $O(r^4 s^4 n^2 d \u03b4^3)$. The reconstruction algorithm runs in time $\\textrm{poly}(n,s,d)$ under the condition $d=\u03a9(r^4\u03b4)$, and in particular it tolerates polynomially large top fan-in $r$ and bottom degree $\u03b4$.\n  Both results hold over fields of characteristic zero and over fields of sufficiently large characteristic. These algorithms provide the first polynomial-time deterministic solutions for depth-$4$ powering circuits with unbounded top fan-in. In particular, the reconstruction result improves upon previous work which required non-degeneracy or average-case assumptions.\n  The PIT construction relies on the ABC theorem for function fields (Mason-Stothers theorem), which ensures linear independence of high-degree powers of sparse polynomials after a suitable projection. The reconstruction algorithm combines this with Wronskian-based differential operators, structural properties of their kernels, and a robust version of the Klivans-Spielman hitting set.", "AI": {"tldr": "This paper presents the first polynomial-time deterministic algorithms for polynomial identity testing (PIT) and reconstruction of depth-4 arithmetic circuits (\u03a3^{[r]}\u2227^{[d]}\u03a3^{[s]}\u03a0^{[\u03b4]}), handling unbounded top fan-in and improving prior work that required non-degeneracy assumptions.", "motivation": "Depth-4 arithmetic circuits are fundamental in algebraic complexity and appear in tensor decomposition/machine learning tasks, but existing deterministic PIT/reconstruction algorithms were limited to bounded top fan-in or relied on non-constructive/non-deterministic methods. This work addresses the critical gap in deterministic, efficient solutions for practical circuit classes with polynomially large parameters.", "method": "PIT uses the Mason-Stothers theorem (ABC theorem for function fields) to construct explicit hitting sets by proving linear independence of high-degree sparse polynomial powers after projection. Reconstruction combines this with Wronskian-based differential operators, kernel analysis, and a robust Klivans-Spielman hitting set to recover circuit structure.", "result": "1) Deterministic PIT algorithm with hitting set size O(r\u2074 s\u2074 n\u00b2 d \u03b4\u00b3) when d > r\u00b2. 2) Reconstruction algorithm running in poly(n,s,d) time when d = \u03a9(r\u2074\u03b4), tolerating polynomially large r and \u03b4. Both hold over characteristic zero/sufficiently large fields.", "conclusion": "This resolves a major open problem by providing the first deterministic polynomial-time solutions for depth-4 powering circuits with unbounded top fan-in, advancing the state-of-the-art in derandomization and explicit circuit reconstruction for algebraic models relevant to machine learning."}}
{"id": "2602.20990", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.20990", "abs": "https://arxiv.org/abs/2602.20990", "authors": ["Min-Chul Cha", "Hoon Beom Kwon", "Ji-Woo Lee", "Myung-Hoon Chung"], "title": "Entanglement Properties of the One-Dimensional Dimerized Fermi-Hubbard Model", "comment": "6 pages and 5 figures", "summary": "We study the entanglement properties of the one-dimensional dimerized Fermi-Hubbard model. Using a matrix-product-state approach, we compute the ground state and identify two insulating phases at 1/2- and 3/4-filling, along with a metallic phase, whose mechanisms can be characterized by their entanglement spectra. Our findings indicate that the two insulating phases are distinct, implying that the phase at 1/2-filling has a charge gap arising from the band gap, which is enhanced by repulsive interactions, while the phase at 3/4-filling exhibits a Mott gap resulting from particle interactions. This difference between the two insulating phases is reflected in the scaling properties of the half-chain entanglement entropy and the distribution of the entanglement spectrum.", "AI": {"tldr": "The study distinguishes two distinct insulating phases in the 1D dimerized Fermi-Hubbard model using entanglement properties: a 1/2-filling phase with a charge gap from band structure, and a 3/4-filling Mott phase with an interaction-driven gap.", "motivation": "To characterize and differentiate quantum phases in the dimerized Fermi-Hubbard model, particularly identifying distinct mechanisms behind insulating behaviors at different electron fillings using entanglement properties as a diagnostic tool.", "method": "Employed a matrix-product-state (MPS) approach to compute the ground state, analyzing entanglement spectra and half-chain entanglement entropy scaling to probe phase characteristics.", "result": "Identified three phases: two insulating phases (1/2-filling with interaction-enhanced band gap; 3/4-filling with Mott gap from interactions) and a metallic phase. Entanglement entropy scaling and spectrum distribution revealed fundamental differences between the two insulating phases.", "conclusion": "Entanglement properties effectively distinguish quantum phases with different insulating mechanisms, demonstrating that entanglement spectra serve as a powerful tool for characterizing many-body states beyond conventional order parameters."}}
{"id": "2602.20186", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.20186", "abs": "https://arxiv.org/abs/2602.20186", "authors": ["Frederick Dehmel", "Shilun Li"], "title": "A Symplectic Proof of the Quantum Singleton Bound", "comment": "6 pages", "summary": "We present a symplectic linear-algebraic proof of the Quantum Singleton Bound for stabiliser quantum error-correcting codes together with a Lean4 formalisation of the linear-algebraic argument. The proof is formulated in the language of finite-dimensional symplectic vector spaces modelling Pauli operators and relies on distance-based erasure correctability and the cleaning lemma. Using a dimension-counting argument within the symplectic stabiliser framework, we derive the bound \\( k + 2(d - 1) \\le n \\) for any [[n, k, d]] stabiliser code. This approach isolates the algebraic structure underlying the bound and avoids the heavier analytic machinery that appears in entropy-based proofs, while remaining well-suited to formal verification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u91cf\u5b50Singleton\u754c\u7684\u8f9b\u7ebf\u6027\u4ee3\u6570\u8bc1\u660e\u65b9\u6cd5\u53caLean4\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u901a\u8fc7\u8f9b\u5411\u91cf\u7a7a\u95f4\u6a21\u578b\u548c\u57fa\u4e8e\u8ddd\u79bb\u7684\u64e6\u9664\u53ef\u7ea0\u6b63\u6027\uff0c\u63a8\u5bfc\u51fa\u7a33\u5b9a\u5b50\u7801\u7684\u53c2\u6570\u7ea6\u675f\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u71b5\u57fa\u8bc1\u660e\u65b9\u6cd5\u5206\u6790\u590d\u6742\u4e14\u4e0d\u6613\u4e8e\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66f4\u7eaf\u7cb9\u7684\u4ee3\u6570\u8bc1\u660e\u6846\u67b6\uff0c\u7a81\u51fa\u91cf\u5b50\u7ea0\u9519\u7801\u7684\u5e95\u5c42\u4ee3\u6570\u7ed3\u6784\uff0c\u540c\u65f6\u6ee1\u8db3\u8ba1\u7b97\u673a\u8f85\u52a9\u9a8c\u8bc1\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u6709\u9650\u7ef4\u8f9b\u5411\u91cf\u7a7a\u95f4\u63cf\u8ff0\u6ce1\u5229\u7b97\u5b50\uff0c\u7ed3\u5408\u8ddd\u79bb\u57fa\u64e6\u9664\u53ef\u7ea0\u6b63\u6027\u4e0e\u6e05\u6d01\u5f15\u7406\uff0c\u8fd0\u7528\u8f9b\u7a33\u5b9a\u5b50\u6846\u67b6\u5185\u7684\u7ef4\u6570\u8ba1\u6570\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u63a8\u5bfc\u51fa[[n, k, d]]\u7a33\u5b9a\u5b50\u91cf\u5b50\u7ea0\u9519\u7801\u7684\u91cf\u5b50Singleton\u754c\uff1ak + 2(d - 1) \u2264 n\uff0c\u5e76\u5b8c\u6210\u4e86\u8be5\u8bc1\u660e\u7684Lean4\u5f62\u5f0f\u5316\u3002", "conclusion": "\u8f9b\u7ebf\u6027\u4ee3\u6570\u65b9\u6cd5\u6709\u6548\u5265\u79bb\u4e86\u5206\u6790\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u754c\u5b9a\u7684\u7eaf\u4ee3\u6570\u672c\u8d28\uff0c\u8bc1\u660e\u4e86\u8be5\u9014\u5f84\u5bf9\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u4f18\u8d8a\u6027\uff0c\u4e3a\u91cf\u5b50\u7ea0\u9519\u7801\u7684\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.20191", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20191", "abs": "https://arxiv.org/abs/2602.20191", "authors": ["Dongwei Wang", "Jinhee Kim", "Seokho Han", "Denis Gudovskiy", "Yohei Nakata", "Tomoyuki Okuno", "KhayTze Peong", "Kang Eun Jeon", "Jong Hwan Ko", "Yiran Chen", "Huanrui Yang"], "title": "MoBiQuant: Mixture-of-Bits Quantization for Token-Adaptive Elastic LLMs", "comment": "17 pages, 12 figures", "summary": "Changing runtime complexity on cloud and edge devices necessitates elastic large language model (LLM) deployment, where an LLM can be inferred with various quantization precisions based on available computational resources. However, it has been observed that the calibration parameters for quantization are typically linked to specific precisions, which presents challenges during elastic-precision calibration and precision switching at runtime. In this work, we attribute the source of varying calibration parameters to the varying token-level sensitivity caused by a precision-dependent outlier migration phenomenon.Motivated by this observation, we propose \\texttt{MoBiQuant}, a novel Mixture-of-Bits quantization framework that adjusts weight precision for elastic LLM inference based on token sensitivity. Specifically, we propose the many-in-one recursive residual quantization that can iteratively reconstruct higher-precision weights and the token-aware router to dynamically select the number of residual bit slices. MoBiQuant enables smooth precision switching while improving generalization for the distribution of token outliers. Experimental results demonstrate that MoBiQuant exhibits strong elasticity, enabling it to match the performance of bit-specific calibrated PTQ on LLaMA3-8B without repeated calibration.", "AI": {"tldr": "MoBiQuant\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u6bd4\u7279\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8etoken\u654f\u611f\u5ea6\u52a8\u6001\u8c03\u6574\u6743\u91cd\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u5f39\u6027LLM\u63a8\u7406\uff0c\u65e0\u9700\u91cd\u590d\u6821\u51c6\u5373\u53ef\u5728\u4e0d\u540c\u7cbe\u5ea6\u95f4\u5e73\u6ed1\u5207\u6362\u3002", "motivation": "\u4e91\u548c\u8fb9\u7f18\u8bbe\u5907\u7684\u8ba1\u7b97\u8d44\u6e90\u52a8\u6001\u53d8\u5316\u9700\u8981\u5f39\u6027LLM\u90e8\u7f72\uff0c\u4f46\u73b0\u6709\u91cf\u5316\u6821\u51c6\u53c2\u6570\u4e0e\u7279\u5b9a\u7cbe\u5ea6\u7ed1\u5b9a\uff0c\u5bfc\u81f4\u5f39\u6027\u7cbe\u5ea6\u6821\u51c6\u548c\u8fd0\u884c\u65f6\u7cbe\u5ea6\u5207\u6362\u9762\u4e34\u6311\u6218\u3002\u7cbe\u5ea6\u76f8\u5173\u7684\u5f02\u5e38\u503c\u8fc1\u79fb\u73b0\u8c61\u9020\u6210token\u7ea7\u654f\u611f\u5ea6\u5dee\u5f02\uff0c\u662f\u95ee\u9898\u7684\u6839\u6e90\u3002", "method": "\u63d0\u51faMoBiQuant\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u591a\u5bf9\u4e00\u9012\u5f52\u6b8b\u5dee\u91cf\u5316\uff0c\u901a\u8fc7\u8fed\u4ee3\u65b9\u5f0f\u91cd\u5efa\u66f4\u9ad8\u7cbe\u5ea6\u6743\u91cd\uff1b2) token\u611f\u77e5\u8def\u7531\u5668\uff0c\u6839\u636etoken\u654f\u611f\u5ea6\u52a8\u6001\u9009\u62e9\u6b8b\u5dee\u4f4d\u5207\u7247\u6570\u91cf\uff0c\u5b9e\u73b0\u57fa\u4e8etoken\u654f\u611f\u5ea6\u7684\u81ea\u9002\u5e94\u7cbe\u5ea6\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMoBiQuant\u5177\u5907\u5f3a\u5f39\u6027\uff1a\u5728LLaMA3-8B\u6a21\u578b\u4e0a\uff0c\u65e0\u9700\u91cd\u590d\u6821\u51c6\u5373\u53ef\u5339\u914d\u6bd4\u7279\u7ea7\u7279\u5b9a\u6821\u51c6\u7684PTQ\u6027\u80fd\uff0c\u540c\u65f6\u5b9e\u73b0\u5e73\u6ed1\u7cbe\u5ea6\u5207\u6362\uff0c\u5e76\u6539\u5584\u4e86token\u5f02\u5e38\u503c\u5206\u5e03\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MoBiQuant\u6210\u529f\u89e3\u51b3\u4e86\u5f39\u6027LLM\u90e8\u7f72\u4e2d\u7684\u7cbe\u5ea6\u5207\u6362\u96be\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u52a8\u6001\u8c03\u6574\u6a21\u578b\u63a8\u7406\u7cbe\u5ea6\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.20308", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2602.20308", "abs": "https://arxiv.org/abs/2602.20308", "authors": ["Rapha\u00ebl Maire"], "title": "Hyperuniformity in active fluids reshape nucleation and capillary-wave dynamics", "comment": "15 pages, 2 figures", "summary": "While nucleation in typical active and driven fluids often appears equilibrium-like, striking departures emerge when large-scale fluctuations are strongly suppressed. Here, we investigate nucleation in nonequilibrium hyperuniform fluids by projecting the full density-field dynamics onto relevant collective variables. We demonstrate that nucleation is governed by a nonequilibrium quasi-potential rather than the reversible work of formation. Surprisingly, because of the reduced hyperuniform fluctuations, the nucleation probability no longer separates into the usual surface and volume contributions. Furthermore, accounting for capillary waves reveals a clear breakdown of detailed balance driven by nonreciprocal dynamics. More broadly, our framework can be readily extended to identify nonequilibrium signatures in conventional active fluids.", "AI": {"tldr": "\u7814\u7a76\u975e\u5e73\u8861\u8d85\u5747\u5300\u6d41\u4f53\u4e2d\u7684\u6210\u6838\u73b0\u8c61\uff0c\u53d1\u73b0\u5176\u7531\u975e\u5e73\u8861\u51c6\u52bf\u80fd\u800c\u975e\u53ef\u9006\u529f\u63a7\u5236\uff0c\u6210\u6838\u6982\u7387\u4e0d\u518d\u5206\u79bb\u4e3a\u8868\u9762\u548c\u4f53\u79ef\u8d21\u732e\uff0c\u4e14\u6bdb\u7ec6\u6ce2\u5bfc\u81f4\u8be6\u7ec6\u5e73\u8861\u7834\u7f3a\u3002", "motivation": "\u5178\u578b\u6d3b\u6027\u6d41\u4f53\u4e2d\u7684\u6210\u6838\u5e38\u5448\u73b0\u7c7b\u5e73\u8861\u7279\u5f81\uff0c\u4f46\u5f53\u5927\u5c3a\u5ea6\u6da8\u843d\u88ab\u5f3a\u70c8\u6291\u5236\u65f6\u4f1a\u51fa\u73b0\u663e\u8457\u504f\u79bb\uff0c\u9700\u63a2\u7a76\u975e\u5e73\u8861\u8d85\u5747\u5300\u6d41\u4f53\u4e2d\u7684\u6210\u6838\u673a\u5236\u3002", "method": "\u5c06\u5b8c\u6574\u5bc6\u5ea6\u573a\u52a8\u529b\u5b66\u6295\u5f71\u5230\u76f8\u5173\u96c6\u4f53\u53d8\u91cf\u4e0a\uff0c\u5206\u6790\u975e\u5e73\u8861\u8d85\u5747\u5300\u6d41\u4f53\u7684\u6210\u6838\u8fc7\u7a0b\u3002", "result": "1. \u6210\u6838\u7531\u975e\u5e73\u8861\u51c6\u52bf\u80fd\u800c\u975e\u53ef\u9006\u529f\u63a7\u5236\uff1b2. \u56e0\u8d85\u5747\u5300\u6da8\u843d\u51cf\u5f31\uff0c\u6210\u6838\u6982\u7387\u4e0d\u518d\u5206\u79bb\u4e3a\u8868\u9762\u548c\u4f53\u79ef\u8d21\u732e\uff1b3. \u6bdb\u7ec6\u6ce2\u5bfc\u81f4\u975e\u4e92\u6613\u52a8\u529b\u5b66\u9a71\u52a8\u7684\u8be6\u7ec6\u5e73\u8861\u7834\u7f3a\u3002", "conclusion": "\u5efa\u7acb\u7684\u7406\u8bba\u6846\u67b6\u53ef\u63a8\u5e7f\u81f3\u5e38\u89c4\u6d3b\u6027\u6d41\u4f53\uff0c\u7528\u4e8e\u8bc6\u522b\u975e\u5e73\u8861\u7279\u5f81\u3002"}}
{"id": "2602.20333", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20333", "abs": "https://arxiv.org/abs/2602.20333", "authors": ["Samarth KaPatel", "Sofia Nikiforova", "Giacinto Paolo Saggese", "Paul Smith"], "title": "DMCD: Semantic-Statistical Framework for Causal Discovery", "comment": null, "summary": "We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed prior over the space of possible causal structures. In Phase II, this draft is audited and refined via conditional independence testing, with detected discrepancies guiding targeted edge revisions.\n  We evaluate our approach on three metadata-rich real-world benchmarks spanning industrial engineering, environmental monitoring, and IT systems analysis. Across these datasets, DMCD achieves competitive or leading performance against diverse causal discovery baselines, with particularly large gains in recall and F1 score. Probing and ablation experiments suggest that these improvements arise from semantic reasoning over metadata rather than memorization of benchmark graphs. Overall, our results demonstrate that combining semantic priors with principled statistical verification yields a high-performing and practically effective approach to causal structure learning.", "AI": {"tldr": "Proposes DMCD, a two-phase causal discovery framework combining LLM-based semantic drafting from metadata with statistical validation, achieving leading performance on real-world benchmarks.", "motivation": "To leverage rich variable metadata through semantic reasoning for causal discovery, addressing limitations of purely statistical methods by incorporating domain knowledge.", "method": "Two-phase approach: Phase I uses LLM to generate a sparse draft DAG from variable metadata; Phase II audits and refines this draft via conditional independence testing with targeted edge revisions based on detected discrepancies.", "result": "Achieves competitive or leading performance across three real-world benchmarks (industrial engineering, environmental monitoring, IT systems), with particularly large gains in recall and F1 score. Ablation studies confirm improvements come from semantic reasoning rather than memorization.", "conclusion": "Combining semantic priors from LLM with principled statistical verification yields a high-performing and practically effective approach to causal structure learning."}}
{"id": "2602.20234", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20234", "abs": "https://arxiv.org/abs/2602.20234", "authors": ["Tyler D. Kharazi", "Stepan Fomichev", "Shu Kanno", "Takao Kobayashi", "Juan Miguel Arrazola", "Qi Gao", "Torin F. Stetina"], "title": "Quantum Simulations for Extreme Ultraviolet Photolithography", "comment": null, "summary": "Extreme Ultraviolet (EUV) lithography is the state-of-the-art process in semiconductor fabrication, yet its spatial resolution is fundamentally limited by the ``blur'' originating from absorption of photons at 92 eV, which induce physical and chemical changes in the photoresist via excited state processes and electron cascades. Accurate modeling of these phenomena requires precise ab initio data for high-energy decay channels, specifically photoabsorption and photoelectron emission. These are computationally difficult for classical methods due to prohibitive scaling in simulating electron dynamics, or due to the inability to resolve the ionization continuum in an efficient manner. In this work, we present quantum simulation algorithms to compute these key observables. First, we introduce a coherent time-domain spectroscopy algorithm optimized to resolve the photoabsorption cross-section at the 92 eV operating frequency. Second, we develop a first-quantized plane-wave simulation to compute the photoelectron kinetic energy spectrum, utilizing real-time dynamics and energy windowing to treat bound and delocalized scattering states on equal footing. Additionally, we provide logical resource estimation for a model photoresist monomer, 4-iodo-2-methylphenol (IMePh), and demonstrate that 92 eV absorption sensitivity can be resolved using roughly $200$ logical qubits and $10^{9}$ total non-Clifford gates per circuit with approximately $10^3$ shots for the smallest instance. The more sophisticated photoemission algorithm that models the continuum explicitly, incurs gate costs of $\\geq 10^{13}$ total non-Clifford gates per circuit, $10^4$ shots, and requires a few thousand logical qubits. These results establish high-fidelity quantum simulations as a key component to parameterize the multi-scale macroscopic models required to overcome the electron blur bottleneck in semiconductor miniaturization.", "AI": {"tldr": "\u5f00\u53d1\u91cf\u5b50\u7b97\u6cd5\u6a21\u62df\u6781\u7d2b\u5916\u5149\u523b\u8fc7\u7a0b\uff0c\u4ee5\u89e3\u51b3\u534a\u5bfc\u4f53\u5236\u9020\u4e2d\u7684\u6a21\u7cca\u9650\u5236\u3002", "motivation": "\u6781\u7d2b\u5916\u5149\u523b\u56e092 eV\u5149\u5b50\u5438\u6536\u5bfc\u81f4\u7684\u201c\u6a21\u7cca\u201d\u800c\u53d7\u9650\uff1b\u7ecf\u5178\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u91cf\u5b50\u6a21\u62df\u63d0\u4f9b\u7cbe\u786e\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u91cf\u5b50\u7b97\u6cd5\uff1a\u4e00\u662f\u7528\u4e8e\u5149\u5438\u6536\u622a\u9762\u7684\u76f8\u5e72\u65f6\u57df\u5149\u8c31\u7b97\u6cd5\uff0c\u4e8c\u662f\u5229\u7528\u5b9e\u65f6\u52a8\u529b\u5b66\u8ba1\u7b97\u5149\u7535\u5b50\u80fd\u8c31\u7684\u4e00\u9636\u91cf\u5316\u5e73\u9762\u6ce2\u6a21\u62df\u3002", "result": "\u8d44\u6e90\u4f30\u7b97\uff1a\u5c0f\u5b9e\u4f8b\u9700\u7ea6200\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\u548c10^9\u975eClifford\u95e8\uff1b\u9ad8\u7ea7\u5149\u53d1\u5c04\u7b97\u6cd5\u9700\u226510^13\u95e8\u548c\u6570\u5343\u91cf\u5b50\u6bd4\u7279\u3002", "conclusion": "\u9ad8\u4fdd\u771f\u91cf\u5b50\u6a21\u62df\u662f\u514b\u670d\u534a\u5bfc\u4f53\u5c0f\u578b\u5316\u4e2d\u7535\u5b50\u6a21\u7cca\u74f6\u9888\u7684\u5173\u952e\u3002"}}
{"id": "2602.20194", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20194", "abs": "https://arxiv.org/abs/2602.20194", "authors": ["Takato Yasuno"], "title": "FedAvg-Based CTMC Hazard Model for Federated Bridge Deterioration Assessment", "comment": "10 pages, 4 figures, 2 tables", "summary": "Bridge periodic inspection records contain sensitive information about public infrastructure, making cross-organizational data sharing impractical under existing data governance constraints. We propose a federated framework for estimating a Continuous-Time Markov Chain (CTMC) hazard model of bridge deterioration, enabling municipalities to collaboratively train a shared benchmark model without transferring raw inspection records. Each User holds local inspection data and trains a log-linear hazard model over three deterioration-direction transitions -- Good$\\to$Minor, Good$\\to$Severe, and Minor$\\to$Severe -- with covariates for bridge age, coastline distance, and deck area. Local optimization is performed via mini-batch stochastic gradient descent on the CTMC log-likelihood, and only a 12-dimensional pseudo-gradient vector is uploaded to a central server per communication round. The server aggregates User updates using sample-weighted Federated Averaging (FedAvg) with momentum and gradient clipping. All experiments in this paper are conducted on fully synthetic data generated from a known ground-truth parameter set with region-specific heterogeneity, enabling controlled evaluation of federated convergence behaviour. Simulation results across heterogeneous Users show consistent convergence of the average negative log-likelihood, with the aggregated gradient norm decreasing as User scale increases. Furthermore, the federated update mechanism provides a natural participation incentive: Users who register their local inspection datasets on a shared technical-standard platform receive in return the periodically updated global benchmark parameters -- information that cannot be obtained from local data alone -- thereby enabling evidence-based life-cycle planning without surrendering data sovereignty.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u5171\u4eab\u539f\u59cb\u6865\u6881\u68c0\u67e5\u8bb0\u5f55\u7684\u60c5\u51b5\u4e0b\uff0c\u534f\u540c\u4f30\u8ba1\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\uff08CTMC\uff09\u6865\u6881\u52a3\u5316\u98ce\u9669\u6a21\u578b\uff0c\u4f7f\u5404\u5e02\u653f\u90e8\u95e8\u80fd\u5728\u4fdd\u62a4\u6570\u636e\u4e3b\u6743\u7684\u540c\u65f6\u83b7\u5f97\u5168\u5c40\u57fa\u51c6\u53c2\u6570\uff0c\u5b9e\u73b0\u57fa\u4e8e\u8bc1\u636e\u7684\u5bff\u547d\u5468\u671f\u89c4\u5212\u3002", "motivation": "\u6865\u6881\u5b9a\u671f\u68c0\u67e5\u8bb0\u5f55\u5305\u542b\u654f\u611f\u7684\u516c\u5171\u57fa\u7840\u8bbe\u65bd\u4fe1\u606f\uff0c\u5728\u73b0\u6709\u6570\u636e\u6cbb\u7406\u7ea6\u675f\u4e0b\uff0c\u8de8\u7ec4\u7ec7\u6570\u636e\u5171\u4eab\u96be\u4ee5\u5b9e\u73b0\u3002\u9700\u8981\u4e00\u79cd\u534f\u4f5c\u5efa\u6a21\u65b9\u6cd5\uff0c\u5728\u4e0d\u6cc4\u9732\u539f\u59cb\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u5171\u540c\u6784\u5efa\u6865\u6881\u52a3\u5316\u9884\u6d4b\u57fa\u51c6\u6a21\u578b\u3002", "method": "\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5404\u7528\u6237\u5728\u672c\u5730\u7528mini-batch\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u4e09\u4e2a\u52a3\u5316\u65b9\u5411\uff08Good\u2192Minor, Good\u2192Severe, Minor\u2192Severe\uff09\u7684\u5bf9\u6570\u7ebf\u6027CTMC\u98ce\u9669\u6a21\u578b\uff0c\u534f\u53d8\u91cf\u5305\u62ec\u6865\u6881\u5e74\u9f84\u3001\u6d77\u5cb8\u7ebf\u8ddd\u79bb\u548c\u6865\u9762\u9762\u79ef\uff1b\u6bcf\u8f6e\u901a\u4fe1\u4ec5\u4e0a\u4f2012\u7ef4\u4f2a\u68af\u5ea6\u5411\u91cf\uff0c\u670d\u52a1\u5668\u7aef\u91c7\u7528\u5e26\u52a8\u91cf\u548c\u68af\u5ea6\u88c1\u526a\u7684\u6837\u672c\u52a0\u6743\u8054\u90a6\u5e73\u5747\uff08FedAvg\uff09\u8fdb\u884c\u805a\u5408\uff1b\u5b9e\u9a8c\u4f7f\u7528\u57fa\u4e8e\u5df2\u77e5\u771f\u5b9e\u53c2\u6570\u751f\u6210\u7684\u5408\u6210\u6570\u636e\uff0c\u8bc4\u4f30\u8054\u90a6\u6536\u655b\u884c\u4e3a\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5f02\u6784\u7528\u6237\u573a\u666f\u4e0b\uff0c\u5e73\u5747\u8d1f\u5bf9\u6570\u4f3c\u7136\u6301\u7eed\u6536\u655b\uff0c\u805a\u5408\u68af\u5ea6\u8303\u6570\u968f\u7528\u6237\u89c4\u6a21\u589e\u52a0\u800c\u51cf\u5c0f\uff1b\u8054\u90a6\u66f4\u65b0\u673a\u5236\u5f62\u6210\u5929\u7136\u53c2\u4e0e\u6fc0\u52b1\uff1a\u7528\u6237\u6ce8\u518c\u672c\u5730\u6570\u636e\u5230\u5171\u4eab\u6280\u672f\u5e73\u53f0\uff0c\u53ef\u5b9a\u671f\u83b7\u5f97\u5168\u5c40\u57fa\u51c6\u53c2\u6570\uff0c\u8fd9\u4e9b\u53c2\u6570\u65e0\u6cd5\u4ece\u672c\u5730\u6570\u636e\u5355\u72ec\u83b7\u5f97\u3002", "conclusion": "\u8be5\u8054\u90a6\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u4e0d\u8f6c\u79fb\u539f\u59cb\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u534f\u4f5c\u8bad\u7ec3\u6865\u6881\u52a3\u5316\u6a21\u578b\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u4e3b\u6743\u7684\u540c\u65f6\u63d0\u4f9b\u5171\u4eab\u57fa\u51c6\uff0c\u6fc0\u52b1\u7528\u6237\u53c2\u4e0e\uff0c\u4e3a\u57fa\u7840\u8bbe\u65bd\u5bff\u547d\u5468\u671f\u89c4\u5212\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2602.20422", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20422", "abs": "https://arxiv.org/abs/2602.20422", "authors": ["Hanping Zhang", "Yuhong Guo"], "title": "Diffusion Modulation via Environment Mechanism Modeling for Planning", "comment": null, "summary": "Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.", "AI": {"tldr": "\u63d0\u51faDMEMM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u6a21\u73af\u5883\u673a\u5236\uff08\u72b6\u6001\u8f6c\u79fb\u4e0e\u5956\u52b1\u51fd\u6570\uff09\u8c03\u5236\u6269\u6563\u6a21\u578b\u8bad\u7ec3\uff0c\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u8f68\u8ff9\u751f\u6210\u4e0e\u771f\u5b9e\u73af\u5883\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5b9e\u73b0SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u8f68\u8ff9\u751f\u6210\u4e2d\u5ffd\u7565\u72b6\u6001\u8f6c\u79fb\u4e00\u81f4\u6027\uff0c\u5bfc\u81f4\u751f\u6210\u8f68\u8ff9\u4e0e\u771f\u5b9e\u73af\u5883\u673a\u5236\u5b58\u5728\u663e\u8457\u504f\u5dee", "method": "\u63d0\u51faDiffusion Modulation via Environment Mechanism Modeling (DMEMM)\uff0c\u5728\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u4e2d\u663e\u5f0f\u878d\u5165\u72b6\u6001\u8f6c\u79fb\u52a8\u6001\u548c\u5956\u52b1\u51fd\u6570\u7b49\u5173\u952e\u73af\u5883\u673a\u5236\u8fdb\u884c\u8c03\u5236", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u89c4\u5212\u4efb\u52a1\u4e0a\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u6027\u80fd\u6c34\u5e73", "conclusion": "\u901a\u8fc7\u73af\u5883\u673a\u5236\u5efa\u6a21\u8c03\u5236\u6269\u6563\u8fc7\u7a0b\u53ef\u6709\u6548\u63d0\u5347\u8f68\u8ff9\u751f\u6210\u4e0e\u771f\u5b9e\u73af\u5883\u7684\u4e00\u81f4\u6027\uff0c\u4e3a\u79bb\u7ebfRL\u89c4\u5212\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2602.20238", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20238", "abs": "https://arxiv.org/abs/2602.20238", "authors": ["Satoshi Yoshida", "Ethan Lake", "Hayata Yamasaki"], "title": "Proof of a finite threshold for the union-find decoder", "comment": "20 pages, 6 figures", "summary": "Fast decoders that achieve strong error suppression are essential for fault-tolerant quantum computation (FTQC) from both practical and theoretical perspectives. The union-find (UF) decoder for the surface code is widely regarded as a promising candidate, offering almost-linear time complexity and favorable empirical error suppression supported by numerical evidence. However, the lack of a rigorous threshold theorem has left open whether the UF decoder can achieve fault tolerance beyond the error models and parameter regimes tested in numerical simulations. Here, we provide a rigorous proof of a finite threshold for the UF decoder on the surface code under the circuit-level local stochastic error model. To this end, we develop a refined error-clustering framework that extends techniques previously used to analyze cellular-automaton and renormalization-group decoders, by showing that error clusters can be separated by substantially larger buffers, thereby enabling analytical control over the behavior of the UF decoder. Using this guarantee, we further prove a quasi-polylogarithmic upper bound on the average runtime of a parallel UF decoder in terms of the code size. We also show that this framework yields a finite threshold for the greedy decoder, a simpler decoder with lower complexity but weaker empirical error suppression. These results provide a solid theoretical foundation for the practical use of UF-based decoders in the development of fault-tolerant quantum computers, while offering a unified framework for studying fault tolerance across these practical decoders.", "AI": {"tldr": "Proves union-find (UF) decoder achieves rigorous finite error threshold for surface code under circuit-level stochastic errors, enabling practical fault-tolerant quantum computation.", "motivation": "While the UF decoder shows strong empirical performance for surface codes, its lack of rigorous threshold proof leaves uncertainty about fault tolerance beyond simulated scenarios, hindering theoretical validation for real-world quantum computers.", "method": "Developed a refined error-clustering framework that extends prior cellular-automaton analysis techniques, demonstrating that error clusters can be separated by larger buffers to enable analytical control over UF decoder behavior.", "result": "Established: (1) Rigorous finite threshold for UF decoder under circuit-level local stochastic errors; (2) Quasi-polylogarithmic upper bound on parallel UF decoder runtime; (3) Extended finite threshold proof to simpler greedy decoder.", "conclusion": "Provides theoretical foundation for UF-based decoders in fault-tolerant quantum computers, offering a unified analytical framework that bridges practical decoder performance with rigorous fault-tolerance guarantees."}}
{"id": "2602.20197", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20197", "abs": "https://arxiv.org/abs/2602.20197", "authors": ["Zhuoxu Huang", "Mengxi Jia", "Hao Sun", "Xuelong Li", "Jungong Han"], "title": "Controllable Exploration in Hybrid-Policy RLVR for Multi-Modal Reasoning", "comment": "Published as a conference paper at ICLR 2026", "summary": "Reinforcement Learning with verifiable rewards (RLVR) has emerged as a primary learning paradigm for enhancing the reasoning capabilities of multi-modal large language models (MLLMs). However, during RL training, the enormous state space of MLLM and sparse rewards often leads to entropy collapse, policy degradation, or over-exploitation of suboptimal behaviors. This necessitates an exploration strategy that maintains productive stochasticity while avoiding the drawbacks of uncontrolled random sampling, yielding inefficient exploration. In this paper, we propose CalibRL, a hybrid-policy RLVR framework that supports controllable exploration with expert guidance, enabled by two key mechanisms. First, a distribution-aware advantage weighting scales updates by group rareness to calibrate the distribution, therefore preserving exploration. Meanwhile, the asymmetric activation function (LeakyReLU) leverages the expert knowledge as a calibration baseline to moderate overconfident updates while preserving their corrective direction. CalibRL increases policy entropy in a guided manner and clarifies the target distribution by estimating the on-policy distribution through online sampling. Updates are driven by these informative behaviors, avoiding convergence to erroneous patterns. Importantly, these designs help alleviate the distributional mismatch between the model's policy and expert trajectories, thereby achieving a more stable balance between exploration and exploitation. Extensive experiments across eight benchmarks, including both in-domain and out-of-domain settings, demonstrate consistent improvements, validating the effectiveness of our controllable hybrid-policy RLVR training. Code is available at https://github.com/zhh6425/CalibRL.", "AI": {"tldr": "\u9488\u5bf9MLLM\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u71b5\u5d29\u6e83\u548c\u7b56\u7565\u9000\u5316\u95ee\u9898\uff0c\u63d0\u51faCalibRL\u6df7\u5408\u7b56\u7565\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u611f\u77e5\u4f18\u52bf\u52a0\u6743\u548c\u4e13\u5bb6\u5f15\u5bfc\u7684\u53ef\u63a7\u63a2\u7d22\u673a\u5236\uff0c\u5728\u516b\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u7a33\u5b9a\u6539\u8fdb\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u9762\u4e34\u72b6\u6001\u7a7a\u95f4\u5de8\u5927\u3001\u5956\u52b1\u7a00\u758f\u5bfc\u81f4\u7684\u71b5\u5d29\u6e83\u3001\u7b56\u7565\u9000\u5316\u53ca\u6b21\u4f18\u884c\u4e3a\u8fc7\u5ea6\u5229\u7528\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u63a2\u7d22\u7b56\u7565\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u4fdd\u6301\u751f\u4ea7\u6027\u968f\u673a\u6027\u3002", "method": "CalibRL\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1\uff09\u5206\u5e03\u611f\u77e5\u4f18\u52bf\u52a0\u6743\uff0c\u6309\u7fa4\u4f53\u7a00\u6709\u5ea6\u7f29\u653e\u66f4\u65b0\u4ee5\u6821\u51c6\u5206\u5e03\u5e76\u4fdd\u7559\u63a2\u7d22\uff1b2\uff09\u4e0d\u5bf9\u79f0LeakyReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4ee5\u4e13\u5bb6\u77e5\u8bc6\u4e3a\u6821\u51c6\u57fa\u51c6\u8c03\u8282\u8fc7\u5ea6\u81ea\u4fe1\u66f4\u65b0\uff0c\u540c\u65f6\u4fdd\u6301\u7ea0\u6b63\u65b9\u5411\u3002", "result": "\u5728\u516b\u4e2a\u9886\u57df\u5185\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6301\u7eed\u6539\u8fdb\uff0c\u901a\u8fc7\u5728\u7ebf\u91c7\u6837\u4f30\u8ba1\u7b56\u7565\u5206\u5e03\uff0c\u6709\u6548\u7f13\u89e3\u6a21\u578b\u7b56\u7565\u4e0e\u4e13\u5bb6\u8f68\u8ff9\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u5b9e\u73b0\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u7a33\u5b9a\u5e73\u8861\u3002", "conclusion": "\u8be5\u53ef\u63a7\u6df7\u5408\u7b56\u7565RLVR\u8bad\u7ec3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86MLLM\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.20424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20424", "abs": "https://arxiv.org/abs/2602.20424", "authors": ["Ved Sirdeshmukh", "Marc Wetter"], "title": "Implicit Intelligence -- Evaluating Agents on What Users Don't Say", "comment": null, "summary": "Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether agents can reason about implicit requirements spanning accessibility needs, privacy boundaries, catastrophic risks, and contextual constraints. We present Implicit Intelligence, an evaluation framework testing whether AI agents can move beyond prompt-following to become genuine goal-fulfillers, paired with Agent-as-a-World (AaW), a harness where interactive worlds are defined in human-readable YAML files and simulated by language models. Our scenarios feature apparent simplicity in user requests, hidden complexity in correct solutions, and discoverability of constraints through environmental exploration. Evaluating 16 frontier and open-weight models across 205 scenarios, we find that even the best-performing model achieves only 48.3% scenario pass rate, revealing substantial room for improvement in bridging the gap between literal instruction-following and human-like contextual reasoning.", "AI": {"tldr": "A new evaluation framework reveals AI agents struggle with implicit reasoning, with top models passing only 48.3% of scenarios that require inferring unstated constraints beyond literal instructions.", "motivation": "Current AI benchmarks only test explicit instruction-following, failing to evaluate whether agents can reason about implicit requirements like accessibility, privacy, catastrophic risks, and contextual constraints that are fundamental to natural human communication.", "method": "Developed Implicit Intelligence framework paired with Agent-as-a-World (AaW) harness, featuring 205 interactive scenarios defined in human-readable YAML files where user requests appear simple but solutions require discovering hidden complexity through environmental exploration.", "result": "Evaluated 16 frontier and open-weight models, finding that even the best-performing model achieved only a 48.3% scenario pass rate, revealing significant performance gaps.", "conclusion": "Substantial room for improvement exists in bridging the gap between literal instruction-following and human-like contextual reasoning, as current AI agents struggle to become genuine goal-fulfillers in underspecified real-world scenarios."}}
{"id": "2602.20269", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20269", "abs": "https://arxiv.org/abs/2602.20269", "authors": ["Mert Esencan", "A. I. Lvovsky", "Berislav Bu\u010da"], "title": "Time Crystals as Passively Protected Oscillating Qubits", "comment": "5 pages, 5 figures. Supplemental material included", "summary": "Protecting information against decoherence in open quantum systems remains a central challenge for quantum computing. In particular, passive error correction schemes have so far been limited to static memories rather than dynamical qubits. We demonstrate that a driven-dissipative bosonic system can encode a persistently oscillating qubit within a noiseless subsystem, realized explicitly in the Bose-Hubbard dimer (BHD). The strong parity symmetry of the model leads to degenerate stationary states. This symmetry is further broken into non-stationary states in the thermodynamic limit, which exhibit persistent oscillations. As the driving force increases, the Liouvillian spectrum of these states features a phase transition. Above the transition point, the non-stationary state encodes quantum information, preserving it in a noiseless subsystem. In addition to global loss that affects both bosonic modes identically, we further add global dephasing and show that the oscillating qubit is preserved. Finally, in order to gain additional physical insight, we study the effect of phase perturbation to both modes and observe that likewise they are passively protected, returning approximately to their initial configurations. These results establish dissipative time-crystalline dynamics as a mechanism for passive protection of dynamical quantum information, enabling autonomously stabilized oscillating qubits.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5229\u7528\u8017\u6563\u65f6\u95f4\u6676\u4f53\u52a8\u529b\u5b66\u5b9e\u73b0\u52a8\u6001\u91cf\u5b50\u6bd4\u7279\u7684\u65e0\u6e90\u7ea0\u9519\uff0c\u901a\u8fc7\u9a71\u52a8-\u8017\u6563\u73bb\u8272\u7cfb\u7edf\u5728Bose-Hubbard dimer\u4e2d\u7f16\u7801\u6301\u7eed\u632f\u8361\u7684\u91cf\u5b50\u4fe1\u606f\uff0c\u5728\u70ed\u529b\u5b66\u6781\u9650\u4e0b\u901a\u8fc7\u5b87\u79f0\u5bf9\u79f0\u6027\u7834\u7f3a\u548cLiouvillian\u8c31\u76f8\u53d8\u5b9e\u73b0\u566a\u58f0\u73af\u5883\u4e0b\u7684\u91cf\u5b50\u4fe1\u606f\u88ab\u52a8\u4fdd\u62a4", "motivation": "\u73b0\u6709\u91cf\u5b50\u65e0\u6e90\u7ea0\u9519\u65b9\u6848\u4ec5\u9002\u7528\u4e8e\u9759\u6001\u91cf\u5b50\u5b58\u50a8\u5668\uff0c\u96be\u4ee5\u4fdd\u62a4\u52a8\u6001\u6f14\u5316\u7684\u91cf\u5b50\u6bd4\u7279\uff0c\u4e9f\u9700\u89e3\u51b3\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u4e2d\u52a8\u6001\u91cf\u5b50\u4fe1\u606f\u7684\u9000\u76f8\u5e72\u95ee\u9898", "method": "\u5728\u9a71\u52a8-\u8017\u6563\u73bb\u8272\u7cfb\u7edf\u4e2d\u6784\u5efaBose-Hubbard dimer\u6a21\u578b\uff0c\u5229\u7528\u5f3a\u5b87\u79f0\u5bf9\u79f0\u6027\u4ea7\u751f\u7b80\u5e76\u7a33\u6001\uff0c\u901a\u8fc7\u70ed\u529b\u5b66\u6781\u9650\u6253\u7834\u5bf9\u79f0\u6027\u5f62\u6210\u975e\u7a33\u6001\u6301\u7eed\u632f\u8361\uff0c\u5e76\u5206\u6790Liouvillian\u8c31\u7684\u76f8\u53d8\u884c\u4e3a", "result": "\u5f53\u9a71\u52a8\u5f3a\u5ea6\u8d85\u8fc7\u4e34\u754c\u70b9\u65f6\uff0c\u975e\u7a33\u6001\u5728Liouvillian\u8c31\u76f8\u53d8\u540e\u5f62\u6210\u65e0\u566a\u58f0\u5b50\u7cfb\u7edf\uff0c\u53ef\u62b5\u6297\u5168\u5c40\u635f\u8017\u3001\u5168\u5c40\u9000\u76f8\u4f4d\u548c\u76f8\u4f4d\u6270\u52a8\uff0c\u4f7f\u632f\u8361\u91cf\u5b50\u6bd4\u7279\u7684\u91cf\u5b50\u4fe1\u606f\u88ab\u88ab\u52a8\u4fdd\u62a4", "conclusion": "\u8017\u6563\u65f6\u95f4\u6676\u4f53\u52a8\u529b\u5b66\u4e3a\u52a8\u6001\u91cf\u5b50\u4fe1\u606f\u63d0\u4f9b\u65b0\u578b\u65e0\u6e90\u4fdd\u62a4\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u81ea\u7a33\u5b9a\u632f\u8361\u91cf\u5b50\u6bd4\u7279\uff0c\u4e3a\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u91cf\u5b50\u8ba1\u7b97\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84"}}
{"id": "2602.20199", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20199", "abs": "https://arxiv.org/abs/2602.20199", "authors": ["Soufiane Bacha", "Laouni Djafri", "Sahraoui Dhelim", "Huansheng Ning"], "title": "IMOVNO+: A Regional Partitioning and Meta-Heuristic Ensemble Framework for Imbalanced Multi-Class Learning", "comment": "28 pages", "summary": "Class imbalance, overlap, and noise degrade data quality, reduce model reliability, and limit generalization. Although widely studied in binary classification, these issues remain underexplored in multi-class settings, where complex inter-class relationships make minority-majority structures unclear and traditional clustering fails to capture distribution shape. Approaches that rely only on geometric distances risk removing informative samples and generating low-quality synthetic data, while binarization approaches treat imbalance locally and ignore global inter-class dependencies. At the algorithmic level, ensembles struggle to integrate weak classifiers, leading to limited robustness. This paper proposes IMOVNO+ (IMbalance-OVerlap-NOise+ Algorithm-Level Optimization), a two-level framework designed to jointly enhance data quality and algorithmic robustness for binary and multi-class tasks. At the data level, first, conditional probability is used to quantify the informativeness of each sample. Second, the dataset is partitioned into core, overlapping, and noisy regions. Third, an overlapping-cleaning algorithm is introduced that combines Z-score metrics with a big-jump gap distance. Fourth, a smart oversampling algorithm based on multi-regularization controls synthetic sample proximity, preventing new overlaps. At the algorithmic level, a meta-heuristic prunes ensemble classifiers to reduce weak-learner influence. IMOVNO+ was evaluated on 35 datasets (13 multi-class, 22 binary). Results show consistent superiority over state-of-the-art methods, approaching 100% in several cases. For multi-class data, IMOVNO+ achieves gains of 37-57% in G-mean, 25-44% in F1-score, 25-39% in precision, and 26-43% in recall. In binary tasks, it attains near-perfect performance with improvements of 14-39%. The framework handles data scarcity and imbalance from collection and privacy limits.", "AI": {"tldr": "\u63d0\u51faIMOVNO+\u6846\u67b6\u89e3\u51b3\u591a\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u91cd\u53e0\u4e0e\u566a\u58f0\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u636e\u7ea7\uff08\u6761\u4ef6\u6982\u7387\u5206\u533a+\u667a\u80fd\u8fc7\u91c7\u6837\uff09\u548c\u7b97\u6cd5\u7ea7\uff08\u96c6\u6210\u526a\u679d\uff09\u4f18\u5316\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u5206\u7c7b\u573a\u666f\u4e0b\u5bf9\u7c7b\u522b\u4e0d\u5e73\u8861/\u91cd\u53e0/\u566a\u58f0\u95ee\u9898\u5904\u7406\u4e0d\u8db3\uff1a\u4e8c\u503c\u5316\u65b9\u6cd5\u5ffd\u7565\u5168\u5c40\u7c7b\u95f4\u4f9d\u8d56\uff0c\u4f20\u7edf\u805a\u7c7b\u65e0\u6cd5\u6355\u6349\u5206\u5e03\u5f62\u6001\uff0c\u96c6\u6210\u5b66\u4e60\u96be\u4ee5\u878d\u5408\u5f31\u5206\u7c7b\u5668\u5bfc\u81f4\u6cdb\u5316\u6027\u5dee", "method": "\u53cc\u5c42\u6846\u67b6\uff1a1) \u6570\u636e\u5c42\uff1a\u7528\u6761\u4ef6\u6982\u7387\u91cf\u5316\u6837\u672c\u4fe1\u606f\u91cf\u2192\u5212\u5206\u6838\u5fc3/\u91cd\u53e0/\u566a\u58f0\u533a\u57df\u2192Z-score\u4e0e\u5927\u8df3\u95f4\u9699\u8ddd\u79bb\u53bb\u566a\u2192\u591a\u6b63\u5219\u5316\u8fc7\u91c7\u6837\u63a7\u5236\u5408\u6210\u6837\u672c proximity\uff1b2) \u7b97\u6cd5\u5c42\uff1a\u5143\u542f\u53d1\u5f0f\u526a\u679d\u96c6\u6210\u5206\u7c7b\u5668\u524a\u5f31\u5f31\u5b66\u4e60\u5668\u5f71\u54cd", "result": "35\u4e2a\u6570\u636e\u96c6\u6d4b\u8bd5\u663e\u793a\uff1a\u591a\u5206\u7c7b\u4efb\u52a1G-mean\u63d0\u534737-57%\u3001F1-score 25-44%\u3001\u7cbe\u786e\u738725-39%\u3001\u53ec\u56de\u738726-43%\uff1b\u4e8c\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\u63d0\u534714-39%\u4e14\u63a5\u8fd1100%\u51c6\u786e\u7387", "conclusion": "IMOVNO+\u6709\u6548\u5e94\u5bf9\u6570\u636e\u7a00\u7f3a\u4e0e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u5347\u6570\u636e\u8d28\u91cf\u4e0e\u7b97\u6cd5\u9c81\u68d2\u6027\u5b9e\u73b0\u8de8\u4efb\u52a1\u6cdb\u5316\u6027\u80fd\u7a81\u7834"}}
{"id": "2602.20426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20426", "abs": "https://arxiv.org/abs/2602.20426", "authors": ["Ruocheng Guo", "Kaiwen Dong", "Xiang Gao", "Kamalika Das"], "title": "Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use", "comment": "Preprint", "summary": "The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavailable in cold-start or privacy-constrained settings, and typically optimize each tool independently, limiting scalability and generalization to unseen tools. We propose Trace-Free+, a curriculum learning framework that progressively transfers supervision from trace-rich settings to trace-free deployment, encouraging the model to abstract reusable interface-usage patterns and tool usage outcomes. To support this approach, we construct a large-scale dataset of high-quality tool interfaces using a structured workflow over a diverse collection of tools. Experiments on StableToolBench and RestBench show consistent gains on unseen tools, strong cross-domain generalization, and robustness as the number of candidate tools scales to over 100, demonstrating that tool interface optimization is a practical and deployable complement to agent fine-tuning.", "AI": {"tldr": "\u63d0\u51faTrace-Free+\u6846\u67b6\u89e3\u51b3\u5de5\u5177\u63a5\u53e3\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u4ece\u8f68\u8ff9\u4e30\u5bcc\u573a\u666f\u8fc1\u79fb\u5230\u65e0\u8f68\u8ff9\u90e8\u7f72\uff0c\u5e76\u6784\u5efa\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u5de5\u5177\u63a5\u53e3\u6570\u636e\u96c6\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u672a\u89c1\u5de5\u5177\u7684\u7a33\u5b9a\u63d0\u5347\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u5173\u6ce8\u667a\u80fd\u4f53\u5fae\u8c03\uff0c\u5ffd\u7565\u4e86\u5de5\u5177\u63a5\u53e3\u8d28\u91cf\u74f6\u9888\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6267\u884c\u8f68\u8ff9\u6570\u636e\uff0c\u5728\u51b7\u542f\u52a8\u6216\u9690\u79c1\u9650\u5236\u573a\u666f\u4e0b\u4e0d\u53ef\u7528\uff0c\u4e14\u5de5\u5177\u72ec\u7acb\u4f18\u5316\u9650\u5236\u6cdb\u5316\u80fd\u529b\u3002", "method": "1) \u63d0\u51fa\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6Trace-Free+\uff0c\u5b9e\u73b0\u4ece\u8f68\u8ff9\u4e30\u5bcc\u5230\u65e0\u8f68\u8ff9\u573a\u666f\u7684\u76d1\u7763\u8fc1\u79fb\uff1b2) \u6784\u5efa\u7ed3\u6784\u5316\u6d41\u7a0b\u751f\u6210\u7684\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u5de5\u5177\u63a5\u53e3\u6570\u636e\u96c6\uff1b3) \u62bd\u8c61\u53ef\u590d\u7528\u7684\u63a5\u53e3\u4f7f\u7528\u6a21\u5f0f\u548c\u5de5\u5177\u8c03\u7528\u7ed3\u679c\u3002", "result": "\u5728StableToolBench\u548cRestBench\u4e0a\uff1a1) \u5bf9\u672a\u89c1\u5de5\u5177\u4fdd\u6301\u7a33\u5b9a\u63d0\u5347\uff1b2) \u5c55\u73b0\u5f3a\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff1b3) \u5019\u9009\u5de5\u5177\u6269\u5c55\u81f3100+\u65f6\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u5de5\u5177\u63a5\u53e3\u4f18\u5316\u662f\u667a\u80fd\u4f53\u5fae\u8c03\u7684\u6709\u6548\u8865\u5145\u65b9\u6848\uff0cTrace-Free+\u6846\u67b6\u8bc1\u660e\u65e0\u9700\u6267\u884c\u8f68\u8ff9\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u8d28\u91cf\u5de5\u5177\u63a5\u53e3\u5b66\u4e60\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2602.20210", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20210", "abs": "https://arxiv.org/abs/2602.20210", "authors": ["Kiyoung Seong", "Sungsoo Ahn", "Sehui Han", "Changyoung Park"], "title": "Multimodal Crystal Flow: Any-to-Any Modality Generation for Unified Crystal Modeling", "comment": null, "summary": "Crystal modeling spans a family of conditional and unconditional generation tasks across different modalities, including crystal structure prediction (CSP) and \\emph{de novo} generation (DNG). While recent deep generative models have shown promising performance, they remain largely task-specific, lacking a unified framework that shares crystal representations across different generation tasks. To address this limitation, we propose \\emph{Multimodal Crystal Flow (MCFlow)}, a unified multimodal flow model that realizes multiple crystal generation tasks as distinct inference trajectories via independent time variables for atom types and crystal structures. To enable multimodal flow in a standard transformer model, we introduce a composition- and symmetry-aware atom ordering with hierarchical permutation augmentation, injecting strong compositional and crystallographic priors without explicit structural templates. Experiments on the MP-20 and MPTS-52 benchmarks show that MCFlow achieves competitive performance against task-specific baselines across multiple crystal generation tasks.", "AI": {"tldr": "\u63d0\u51faMCFlow\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u72ec\u7acb\u65f6\u95f4\u53d8\u91cf\u7684\u591a\u6a21\u6001\u6d41\u6a21\u578b\u5b9e\u73b0\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u548c\u751f\u6210\u4efb\u52a1\uff0c\u5728\u6807\u51c6Transformer\u4e2d\u5f15\u5165\u6210\u5206\u5bf9\u79f0\u6027\u611f\u77e5\u7684\u539f\u5b50\u6392\u5e8f\u548c\u5c42\u6b21\u7f6e\u6362\u589e\u5f3a\uff0c\u5728MP-20\u548cMPTS-52\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e0e\u4e13\u7528\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u6676\u4f53\u751f\u6210\u6a21\u578b\u4efb\u52a1\u7279\u5b9a\u5316\uff0c\u7f3a\u4e4f\u8de8\u4efb\u52a1\u5171\u4eab\u8868\u793a\u7684\u7edf\u4e00\u6846\u67b6", "method": "\u8bbe\u8ba1\u591a\u6a21\u6001\u6676\u4f53\u6d41\u6a21\u578b\uff0c\u901a\u8fc7\u539f\u5b50\u7c7b\u578b\u548c\u7ed3\u6784\u72ec\u7acb\u65f6\u95f4\u53d8\u91cf\u5b9e\u73b0\u591a\u4efb\u52a1\u63a8\u7406\u8f68\u8ff9\uff1b\u5728Transformer\u4e2d\u5f15\u5165\u6210\u5206\u5bf9\u79f0\u6027\u611f\u77e5\u7684\u539f\u5b50\u6392\u5e8f\u4e0e\u5c42\u6b21\u7f6e\u6362\u589e\u5f3a\uff0c\u6ce8\u5165\u7ed3\u6676\u5b66\u5148\u9a8c", "result": "\u5728MP-20\u548cMPTS-52\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cMCFlow\u5728\u591a\u4e2a\u6676\u4f53\u751f\u6210\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e0e\u4e13\u7528\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73", "conclusion": "MCFlow\u6210\u529f\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u591a\u6a21\u6001\u751f\u6210\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u8de8\u6676\u4f53\u4efb\u52a1\u5171\u4eab\u8868\u793a\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6750\u6599\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u57fa\u7840\u6a21\u578b"}}
{"id": "2602.20502", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20502", "abs": "https://arxiv.org/abs/2602.20502", "authors": ["Hongbin Zhong", "Fazle Faisal", "Luis Fran\u00e7a", "Tanakorn Leesatapornwongsa", "Adriana Szekeres", "Kexin Rong", "Suman Nath"], "title": "ActionEngine: From Reactive to Programmatic GUI Agents via State Machine Memory", "comment": null, "summary": "Existing Graphical User Interface (GUI) agents operate through step-by-step calls to vision language models--taking a screenshot, reasoning about the next action, executing it, then repeating on the new page--resulting in high costs and latency that scale with the number of reasoning steps, and limited accuracy due to no persistent memory of previously visited pages.\n  We propose ActionEngine, a training-free framework that transitions from reactive execution to programmatic planning through a novel two-agent architecture: a Crawling Agent that constructs an updatable state-machine memory of the GUIs through offline exploration, and an Execution Agent that leverages this memory to synthesize complete, executable Python programs for online task execution.\n  To ensure robustness against evolving interfaces, execution failures trigger a vision-based re-grounding fallback that repairs the failed action and updates the memory.\n  This design drastically improves both efficiency and accuracy: on Reddit tasks from the WebArena benchmark, our agent achieves 95% task success with on average a single LLM call, compared to 66% for the strongest vision-only baseline, while reducing cost by 11.8x and end-to-end latency by 2x.\n  Together, these components yield scalable and reliable GUI interaction by combining global programmatic planning, crawler-validated action templates, and node-level execution with localized validation and repair.", "AI": {"tldr": "\u63d0\u51faActionEngine\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff08\u79bb\u7ebf\u6784\u5efaGUI\u72b6\u6001\u673a\u7684\u722c\u53d6\u667a\u80fd\u4f53+\u5728\u7ebf\u751f\u6210\u6267\u884c\u7a0b\u5e8f\u7684\u6267\u884c\u667a\u80fd\u4f53\uff09\u5b9e\u73b0\u7a0b\u5e8f\u5316\u89c4\u5212\uff0c\u66ff\u4ee3\u4f20\u7edf\u89c6\u89c9\u6a21\u578b\u7684\u9010\u6b65\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347GUI\u81ea\u52a8\u5316\u4efb\u52a1\u7684\u6548\u7387\u548c\u51c6\u786e\u7387", "motivation": "\u73b0\u6709GUI\u667a\u80fd\u4f53\u91c7\u7528\u89c6\u89c9\u6a21\u578b\u9010\u6b65\u63a8\u7406\u6267\u884c\uff0c\u5b58\u5728\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u5927\uff08\u968f\u63a8\u7406\u6b65\u9aa4\u7ebf\u6027\u589e\u957f\uff09\u4e14\u7f3a\u4e4f\u9875\u9762\u5386\u53f2\u8bb0\u5fc6\u5bfc\u81f4\u51c6\u786e\u7387\u4f4e\u7684\u95ee\u9898", "method": "1. \u8bbe\u8ba1\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff1aCrawling Agent\u901a\u8fc7\u79bb\u7ebf\u63a2\u7d22\u6784\u5efa\u53ef\u66f4\u65b0\u7684GUI\u72b6\u6001\u673a\u8bb0\u5fc6\uff1bExecution Agent\u57fa\u4e8e\u8bb0\u5fc6\u5408\u6210\u53ef\u6267\u884c\u7684Python\u7a0b\u5e8f\u8fdb\u884c\u5728\u7ebf\u4efb\u52a1\u6267\u884c<br>2. \u5f15\u5165\u89c6\u89c9\u91cd\u63a5\u5730\u673a\u5236\uff1a\u6267\u884c\u5931\u8d25\u65f6\u4fee\u590d\u52a8\u4f5c\u5e76\u66f4\u65b0\u8bb0\u5fc6\uff0c\u5e94\u5bf9\u754c\u9762\u53d8\u5316", "result": "\u5728WebArena\u7684Reddit\u4efb\u52a1\u4e2d\u8fbe\u523095%\u6210\u529f\u7387\uff08\u6700\u5f3a\u57fa\u7ebf\u4ec566%\uff09\uff0c\u5e73\u5747\u4ec5\u97001\u6b21LLM\u8c03\u7528\uff0c\u6210\u672c\u964d\u4f4e11.8\u500d\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e2\u500d", "conclusion": "\u901a\u8fc7\u5168\u5c40\u7a0b\u5e8f\u5316\u89c4\u5212+\u722c\u866b\u9a8c\u8bc1\u52a8\u4f5c\u6a21\u677f+\u8282\u70b9\u7ea7\u6267\u884c\u4e0e\u5c40\u90e8\u4fee\u590d\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684GUI\u4ea4\u4e92\uff0c\u4e3a\u81ea\u52a8\u5316\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u65b0\u8303\u5f0f"}}
{"id": "2602.20224", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.20224", "abs": "https://arxiv.org/abs/2602.20224", "authors": ["Lana E. Yeganova", "Won G. Kim", "Shubo Tian", "Natalie Xie", "Donald C. Comeau", "W. John Wilbur", "Zhiyong Lu"], "title": "Exploring Anti-Aging Literature via ConvexTopics and Large Language Models", "comment": null, "summary": "The rapid expansion of biomedical publications creates challenges for organizing knowledge and detecting emerging trends, underscoring the need for scalable and interpretable methods. Common clustering and topic modeling approaches such as K-means or LDA remain sensitive to initialization and prone to local optima, limiting reproducibility and evaluation. We propose a reformulation of a convex optimization based clustering algorithm that produces stable, fine-grained topics by selecting exemplars from the data and guaranteeing a global optimum. Applied to about 12,000 PubMed articles on aging and longevity, our method uncovers topics validated by medical experts. It yields interpretable topics spanning from molecular mechanisms to dietary supplements, physical activity, and gut microbiota. The method performs favorably, and most importantly, its reproducibility and interpretability distinguish it from common clustering approaches, including K-means, LDA, and BERTopic. This work provides a basis for developing scalable, web-accessible tools for knowledge discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u51f8\u4f18\u5316\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6570\u636e\u8303\u4f8b\u751f\u6210\u7a33\u5b9a\u4e14\u53ef\u89e3\u91ca\u7684\u751f\u7269\u533b\u5b66\u4e3b\u9898\uff0c\u57281.2\u4e07\u7bc7\u8870\u8001\u76f8\u5173\u6587\u732e\u4e2d\u9a8c\u8bc1\u6548\u679c\u4f18\u4e8eK-means\u3001LDA\u7b49\u65b9\u6cd5", "motivation": "\u751f\u7269\u533b\u5b66\u6587\u732e\u5feb\u901f\u6269\u5f20\u5bfc\u81f4\u77e5\u8bc6\u7ec4\u7ec7\u4e0e\u8d8b\u52bf\u68c0\u6d4b\u56f0\u96be\uff0c\u73b0\u6709K-means\u3001LDA\u7b49\u65b9\u6cd5\u5bf9\u521d\u59cb\u5316\u654f\u611f\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u5f71\u54cd\u7ed3\u679c\u53ef\u91cd\u590d\u6027", "method": "\u91cd\u65b0\u6784\u5efa\u51f8\u4f18\u5316\u805a\u7c7b\u7b97\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6570\u636e\u8303\u4f8b\u751f\u6210\u7ec6\u7c92\u5ea6\u4e3b\u9898\uff0c\u786e\u4fdd\u5168\u5c40\u6700\u4f18\u89e3", "result": "\u57281.2\u4e07\u7bc7PubMed\u8870\u8001\u6587\u732e\u4e2d\u8bc6\u522b\u51fa\u5206\u5b50\u673a\u5236\u3001\u81b3\u98df\u8865\u5145\u5242\u3001\u8fd0\u52a8\u3001\u80a0\u9053\u83cc\u7fa4\u7b49\u53ef\u89e3\u91ca\u4e3b\u9898\uff0c\u7ecf\u533b\u5b66\u4e13\u5bb6\u9a8c\u8bc1\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u5f00\u53d1\u53ef\u6269\u5c55\u7684Web\u7aef\u77e5\u8bc6\u53d1\u73b0\u5de5\u5177\u5960\u5b9a\u57fa\u7840"}}
{"id": "2602.20571", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20571", "abs": "https://arxiv.org/abs/2602.20571", "authors": ["Ayush Sawarni", "Jiyuan Tan", "Vasilis Syrgkanis"], "title": "CausalReasoningBenchmark: A Real-World Benchmark for Disentangled Evaluation of Causal Identification and Estimation", "comment": null, "summary": "Many benchmarks for automated causal inference evaluate a system's performance based on a single numerical output, such as an Average Treatment Effect (ATE). This approach conflates two distinct steps in causal analysis: identification-formulating a valid research design under stated assumptions-and estimation-implementing that design numerically on finite data. We introduce CausalReasoningBenchmark, a benchmark of 173 queries across 138 real-world datasets, curated from 85 peer-reviewed research papers and four widely-used causal-inference textbooks. For each query a system must produce (i) a structured identification specification that names the strategy, the treatment, outcome, and control variables, and all design-specific elements, and (ii) a point estimate with a standard error. By scoring these two components separately, our benchmark enables granular diagnosis: it distinguishes failures in causal reasoning from errors in numerical execution. Baseline results with a state-of-the-art LLM show that, while the model correctly identifies the high-level strategy in 84 % of cases, full identification-specification correctness drops to only 30 %, revealing that the bottleneck lies in the nuanced details of research design rather than in computation. CausalReasoningBenchmark is publicly available on Hugging Face and is designed to foster the development of more robust automated causal-inference systems.", "AI": {"tldr": "\u73b0\u6709\u56e0\u679c\u63a8\u65ad\u57fa\u51c6\u5c06\u8bc6\u522b\u4e0e\u4f30\u8ba1\u6df7\u4e3a\u4e00\u8c08\uff0c\u672c\u6587\u63d0\u51faCausalReasoningBenchmark\uff0c\u8981\u6c42\u6a21\u578b\u5206\u522b\u8f93\u51fa\u7ed3\u6784\u5316\u8bc6\u522b\u89c4\u8303\u548c\u6570\u503c\u4f30\u8ba1\u7ed3\u679c\u3002\u6d4b\u8bd5\u53d1\u73b0\uff1aLLM\u9ad8\u5c42\u7b56\u7565\u8bc6\u522b\u7387\u8fbe84%\uff0c\u4f46\u5b8c\u6574\u8bc6\u522b\u89c4\u8303\u6b63\u786e\u7387\u4ec530%\uff0c\u74f6\u9888\u5728\u4e8e\u7814\u7a76\u8bbe\u8ba1\u7684\u7ec6\u8282\u800c\u975e\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u56e0\u679c\u63a8\u65ad\u57fa\u51c6\u4ec5\u8bc4\u4f30\u5355\u4e00\u6570\u503c\u8f93\u51fa\uff08\u5982\u5e73\u5747\u5904\u7406\u6548\u5e94\uff09\uff0c\u5c06\u56e0\u679c\u5206\u6790\u7684\u4e24\u4e2a\u5173\u952e\u6b65\u9aa4\u2014\u2014\u8bc6\u522b\uff08\u5236\u5b9a\u7814\u7a76\u8bbe\u8ba1\uff09\u4e0e\u4f30\u8ba1\uff08\u6570\u503c\u5b9e\u73b0\uff09\u2014\u2014\u6df7\u4e3a\u4e00\u8c08\uff0c\u96be\u4ee5\u8bca\u65ad\u7cfb\u7edf\u5177\u4f53\u5931\u8d25\u539f\u56e0\u3002", "method": "\u6784\u5efa\u5305\u542b173\u4e2a\u67e5\u8be2\u3001138\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff08\u6e90\u81ea85\u7bc7\u8bba\u6587\u548c4\u672c\u6559\u79d1\u4e66\uff09\uff0c\u8981\u6c42\u7cfb\u7edf\u5fc5\u987b\u8f93\u51fa\uff1a(i) \u7ed3\u6784\u5316\u8bc6\u522b\u89c4\u8303\uff08\u7b56\u7565\u3001\u5904\u7406\u53d8\u91cf\u3001\u7ed3\u679c\u53d8\u91cf\u3001\u63a7\u5236\u53d8\u91cf\u53ca\u8bbe\u8ba1\u7ec6\u8282\uff09\uff1b(ii) \u70b9\u4f30\u8ba1\u503c\u548c\u6807\u51c6\u8bef\u3002\u4e24\u90e8\u5206\u72ec\u7acb\u8bc4\u5206\u4ee5\u5b9e\u73b0\u7cbe\u7ec6\u5316\u8bca\u65ad\u3002", "result": "\u5bf9\u5148\u8fdbLLM\u7684\u57fa\u7ebf\u6d4b\u8bd5\u663e\u793a\uff1a\u9ad8\u5c42\u7b56\u7565\u8bc6\u522b\u6b63\u786e\u738784%\uff0c\u4f46\u5b8c\u6574\u8bc6\u522b\u89c4\u8303\u6b63\u786e\u7387\u9aa4\u964d\u81f330%\uff0c\u8868\u660e\u5f53\u524d\u74f6\u9888\u5728\u4e8e\u7814\u7a76\u8bbe\u8ba1\u7684\u7ec6\u5fae\u7ec6\u8282\uff0c\u800c\u975e\u6570\u503c\u8ba1\u7b97\u80fd\u529b\u3002", "conclusion": "CausalReasoningBenchmark\u80fd\u6709\u6548\u533a\u5206\u56e0\u679c\u63a8\u7406\u5931\u8d25\u4e0e\u6570\u503c\u6267\u884c\u9519\u8bef\uff0c\u63ed\u793a\u73b0\u6709\u6a21\u578b\u5728\u8bc6\u522b\u7ec6\u8282\u4e0a\u7684\u4e25\u91cd\u4e0d\u8db3\uff0c\u4e3a\u5f00\u53d1\u66f4\u7a33\u5065\u7684\u81ea\u52a8\u5316\u56e0\u679c\u63a8\u65ad\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bca\u65ad\u5de5\u5177\u3002\u8be5\u57fa\u51c6\u5df2\u5728Hugging Face\u5f00\u6e90\u3002"}}
{"id": "2602.20722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20722", "abs": "https://arxiv.org/abs/2602.20722", "authors": ["Xu Wan", "Yansheng Wang", "Wenqi Huang", "Mingyang Sun"], "title": "Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning", "comment": null, "summary": "Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult samples and reusing high-quality ones, while holding a lower bound guarantee for policy improvement. Extensive experiments further demonstrate that BAPO achieves an average 12.5% improvement over GRPO across mathematics, planning, and visual reasoning tasks. Crucially, BAPO successfully resolves 40.7% of problems that base models consistently fail to solve.", "AI": {"tldr": "BAPO\u662f\u4e00\u79cd\u79bb\u7b56\u7565RLVR\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u8bad\u7ec3\u6279\u6b21\u548c\u91cd\u8bc4\u4f30\u56f0\u96be\u6837\u672c\u6765\u63d0\u9ad8LLM\u540e\u8bad\u7ec3\u7684\u6570\u636e\u6548\u7387\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u6bd4GRPO\u5e73\u5747\u63d0\u534712.5%\u3002", "motivation": "\u4f20\u7edf\u7684\u540c\u7b56\u7565RLVR\u6846\u67b6\u5b58\u5728\u7ecf\u9a8c\u6d6a\u8d39\u548c\u5956\u52b1\u540c\u8d28\u5316\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u5728\u56f0\u96be\u6837\u672c\u4e0a\u7684\u5b66\u4e60\u6548\u7387\u3002", "method": "\u63d0\u51fa\u6279\u9002\u5e94\u7b56\u7565\u4f18\u5316(BAPO)\uff0c\u4e00\u79cd\u79bb\u7b56\u7565RLVR\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u8bc4\u4f30\u5386\u53f2\u56f0\u96be\u6837\u672c\u5e76\u590d\u7528\u9ad8\u8d28\u91cf\u6837\u672c\u6765\u52a8\u6001\u9009\u62e9\u8bad\u7ec3\u6279\u6b21\uff0c\u540c\u65f6\u4fdd\u8bc1\u7b56\u7565\u6539\u8fdb\u7684\u4e0b\u754c\u3002", "result": "\u5728\u6570\u5b66\u3001\u89c4\u5212\u548c\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cBAPO\u76f8\u6bd4GRPO\u5e73\u5747\u63d0\u534712.5%\uff0c\u4e14\u80fd\u89e3\u51b340.7%\u7684\u57fa\u7840\u6a21\u578b\u59cb\u7ec8\u65e0\u6cd5\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "BAPO\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u7684\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2602.20370", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.20370", "abs": "https://arxiv.org/abs/2602.20370", "authors": ["Jonathan W. Siegel", "Snir Hordan", "Hannah Lawrence", "Ali Syed", "Nadav Dym"], "title": "Quantitative Approximation Rates for Group Equivariant Learning", "comment": null, "summary": "The universal approximation theorem establishes that neural networks can approximate any continuous function on a compact set. Later works in approximation theory provide quantitative approximation rates for ReLU networks on the class of $\u03b1$-H\u00f6lder functions $f: [0,1]^N \\to \\mathbb{R}$. The goal of this paper is to provide similar quantitative approximation results in the context of group equivariant learning, where the learned $\u03b1$-H\u00f6lder function is known to obey certain group symmetries. While there has been much interest in the literature in understanding the universal approximation properties of equivariant models, very few quantitative approximation results are known for equivariant models.\n  In this paper, we bridge this gap by deriving quantitative approximation rates for several prominent group-equivariant and invariant architectures. The architectures that we consider include: the permutation-invariant Deep Sets architecture; the permutation-equivariant Sumformer and Transformer architectures; joint invariance to permutations and rigid motions using invariant networks based on frame averaging; and general bi-Lipschitz invariant models. Overall, we show that equally-sized ReLU MLPs and equivariant architectures are equally expressive over equivariant functions. Thus, hard-coding equivariance does not result in a loss of expressivity or approximation power in these models.", "AI": {"tldr": "This paper derives quantitative approximation rates for group-equivariant neural networks, proving they are as expressive as standard ReLU MLPs for learning equivariant functions, thus showing that hard-coding symmetries doesn't sacrifice approximation power.", "motivation": "While universal approximation is established for both standard and equivariant networks, quantitative rates are known only for standard ReLU networks on \u03b1-H\u00f6lder functions. For equivariant models, such rates are scarce despite much interest, creating a gap in theoretical understanding.", "method": "The authors derive quantitative approximation rates for several prominent architectures: Deep Sets (permutation-invariant), Sumformer/Transformer (permutation-equivariant), frame-averaged networks (invariant to permutations and rigid motions), and bi-Lipschitz invariant models.", "result": "They prove that equally-sized ReLU MLPs and equivariant architectures have equal expressive power over equivariant functions, meaning hard-coding equivariance doesn't reduce approximation capability.", "conclusion": "Hard-coding equivariance priors into neural networks does not result in a loss of expressivity or approximation power, validating the theoretical foundation of equivariant architectures."}}
{"id": "2602.20732", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20732", "abs": "https://arxiv.org/abs/2602.20732", "authors": ["Chao Fei", "Guozhong Li", "Chenxi Liu", "Panos Kalnis"], "title": "CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference", "comment": null, "summary": "Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \\textbf{CHESS}, an \\textit{algorithm-system co-design} KV-cache management system. Algorithmically, CHESS introduces a context-aware, hierarchical selection policy that dynamically reconstructs a coherent context for the current decoding. System-wise, coarse granularity selection eliminates expensive data movement, fully realizing practical acceleration from theoretical sparsity. Extensive evaluations demonstrate that CHESS surpasses Full-KV quality using only \\textbf{1\\%} of the KV cache, delivers low-latency stable inference with up to \\textbf{4.56$\\times$} higher throughput, and consistently outperforms other strong baselines. Code is available at \\href{https://anonymous.4open.science/r/CHESS-9958/}{https://anonymous.4open.science/r/CHESS/}.", "AI": {"tldr": "CHESS\u662f\u4e00\u79cd\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u7684KV\u7f13\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5206\u5c42\u9009\u62e9\u7b56\u7565\u52a8\u6001\u91cd\u5efa\u76f8\u5e72\u4e0a\u4e0b\u6587\uff0c\u5728\u4ec5\u4f7f\u75281% KV\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u9ad8\u8d28\u91cf\u63a8\u7406\uff0c\u5b9e\u73b0\u6700\u9ad84.56\u500d\u541e\u5410\u91cf\u63d0\u5347", "motivation": "\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u9762\u4e34KV\u7f13\u5b58\u74f6\u9888\uff0c\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\uff0c\u5ffd\u7565token\u7684\u9010\u6b65\u76f8\u5173\u6027\u548c\u5c40\u90e8\u8bed\u4e49\uff0c\u5bfc\u81f4\u8d28\u91cf\u4e0b\u964d\uff1b\u4e14\u4e0d\u89c4\u5219\u7684\u5185\u5b58\u8bbf\u95ee\u548c\u9009\u62e9\u5f00\u9500\u9650\u5236\u4e86\u5b9e\u9645\u52a0\u901f\u6548\u679c", "method": "\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff1a\u7b97\u6cd5\u5c42\u9762\u91c7\u7528\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5206\u5c42\u9009\u62e9\u7b56\u7565\uff0c\u4e3a\u5f53\u524d\u89e3\u7801\u52a8\u6001\u91cd\u5efa\u76f8\u5e72\u4e0a\u4e0b\u6587\uff1b\u7cfb\u7edf\u5c42\u9762\u4f7f\u7528\u7c97\u7c92\u5ea6\u9009\u62e9\u6d88\u9664\u6602\u8d35\u6570\u636e\u79fb\u52a8\uff0c\u5145\u5206\u5b9e\u73b0\u7406\u8bba\u7a00\u758f\u6027\u7684\u5b9e\u9645\u52a0\u901f", "result": "\u5728\u4ec5\u4f7f\u75281% KV\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u5168KV\u8d28\u91cf\uff0c\u5b9e\u73b0\u6700\u9ad84.56\u500d\u541e\u5410\u91cf\u63d0\u5347\uff0c\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u7a33\u5b9a\u63a8\u7406\uff0c\u4e14\u6301\u7eed\u4f18\u4e8e\u5176\u4ed6\u5f3a\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "CHESS\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u7684KV\u7f13\u5b58\u7ea6\u675f\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5b9e\u8df5\u6027\u80fd\u63d0\u5347"}}
{"id": "2602.20739", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.20739", "abs": "https://arxiv.org/abs/2602.20739", "authors": ["Shitian Zhao", "Shaoheng Lin", "Ming Li", "Haoquan Zhang", "Wenshuo Peng", "Kaipeng Zhang", "Chen Wei"], "title": "PyVision-RL: Forging Open Agentic Vision Models via RL", "comment": "preprint", "summary": "Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.", "AI": {"tldr": "\u63d0\u51faPyVision-RL\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4ea4\u4e92\u5d29\u6e83\u95ee\u9898\uff0c\u901a\u8fc7\u8fc7\u91c7\u6837-\u8fc7\u6ee4-\u6392\u5e8f\u7b56\u7565\u548c\u7d2f\u79ef\u5de5\u5177\u5956\u52b1\u4fdd\u6301\u591a\u8f6e\u63a8\u7406\uff0c\u5e76\u5f00\u53d1\u652f\u6301\u6309\u9700\u62bd\u5e27\u7684\u89c6\u9891\u7406\u89e3\u6a21\u578bPyVision-Video", "motivation": "\u591a\u6a21\u6001\u667a\u80fd\u4f53\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f1a\u51fa\u73b0\u4ea4\u4e92\u5d29\u6e83\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u51cf\u5c11\u5de5\u5177\u4f7f\u7528\u548c\u591a\u8f6e\u63a8\u7406\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u6536\u76ca\u3002\u9700\u8981\u4e00\u79cd\u7a33\u5b9a\u8bad\u7ec3\u5e76\u7ef4\u6301\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPyVision-RL\u6846\u67b6\uff0c\u7ed3\u5408\u8fc7\u91c7\u6837-\u8fc7\u6ee4-\u6392\u5e8f\u7684rollout\u7b56\u7565\u548c\u7d2f\u79ef\u5de5\u5177\u5956\u52b1\u6765\u9632\u6b62\u5d29\u6e83\uff1b\u9488\u5bf9\u89c6\u9891\u63a8\u7406\uff0c\u91c7\u7528\u6309\u9700\u4e0a\u4e0b\u6587\u6784\u5efa\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9009\u62e9\u6027\u5730\u91c7\u6837\u4efb\u52a1\u76f8\u5173\u5e27\u4ee5\u51cf\u5c11\u89c6\u89c9token\u4f7f\u7528\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u6027\u80fd\u5f3a\u52b2\u4e14\u6548\u7387\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u7ef4\u6301\u4ea4\u4e92\u548c\u6309\u9700\u89c6\u89c9\u5904\u7406\u5bf9\u53ef\u6269\u5c55\u591a\u6a21\u6001\u667a\u80fd\u4f53\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u6301\u7eed\u4ea4\u4e92\u548c\u6309\u9700\u89c6\u89c9\u5904\u7406\u662f\u6784\u5efa\u53ef\u6269\u5c55\u591a\u6a21\u6001\u667a\u80fd\u4f53\u7684\u5173\u952e\uff0cPyVision-RL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4ea4\u4e92\u5d29\u6e83\u95ee\u9898\u3002"}}
{"id": "2602.21198", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.21198", "abs": "https://arxiv.org/abs/2602.21198", "authors": ["Yining Hong", "Huang Huang", "Manling Li", "Li Fei-Fei", "Jiajun Wu", "Yejin Choi"], "title": "Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs", "comment": null, "summary": "Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: \\textit{reflection-in-action}, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and \\textit{reflection-on-action}, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53cd\u601d\u6027\u6d4b\u8bd5\u65f6\u89c4\u5212(RTTP)\uff0c\u901a\u8fc7\u4e09\u79cd\u53cd\u601d\u6a21\u5f0f\uff08\u884c\u52a8\u4e2d\u7684\u53cd\u601d\u3001\u884c\u52a8\u540e\u7684\u53cd\u601d\u548c\u56de\u987e\u6027\u53cd\u601d\uff09\u89e3\u51b3\u5177\u8eab\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u4ece\u9519\u8bef\u4e2d\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u5728\u4e24\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5177\u8eab\u5927\u8bed\u8a00\u6a21\u578b\u8d4b\u4e88\u673a\u5668\u4eba\u9ad8\u5c42\u4efb\u52a1\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u53cd\u601d\u673a\u5236\uff0c\u5bfc\u81f4\u9519\u8bef\u91cd\u590d\u53d1\u751f\u800c\u975e\u79ef\u7d2f\u4e3a\u7ecf\u9a8c\u3002\u53d7\u4eba\u7c7b\u53cd\u601d\u5b9e\u8df5\u8005\u542f\u53d1\uff0c\u65e8\u5728\u8ba9\u673a\u5668\u4eba\u4ece\u72ec\u7acb\u8bd5\u9a8c\u8f6c\u5411\u7ecf\u9a8c\u7d2f\u79ef\u3002", "method": "\u63d0\u51fa\u53cd\u601d\u6027\u6d4b\u8bd5\u65f6\u89c4\u5212\u6846\u67b6\uff0c\u5305\u542b\uff1a1) \u884c\u52a8\u4e2d\u7684\u53cd\u601d\u2014\u901a\u8fc7\u6d4b\u8bd5\u65f6\u6269\u5c55\u751f\u6210\u5e76\u8bc4\u4f30\u591a\u4e2a\u5019\u9009\u52a8\u4f5c\uff1b2) \u884c\u52a8\u540e\u7684\u53cd\u601d\u2014\u57fa\u4e8e\u5916\u90e8\u53cd\u9988\u66f4\u65b0\u53cd\u601d\u6a21\u578b\u548c\u52a8\u4f5c\u7b56\u7565\uff1b3) \u56de\u987e\u6027\u53cd\u601d\u2014\u5229\u7528\u540e\u89c1\u4e4b\u660e\u91cd\u65b0\u8bc4\u4f30\u65e9\u671f\u51b3\u7b56\u5e76\u5206\u914d\u957f\u671f\u4fe1\u7528\u3002", "result": "\u5728Long-Horizon Household\u548cMuJoCo Cupboard Fitting\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u53cd\u601d\u6a21\u5f0f\u7684\u4e92\u8865\u4f5c\u7528\uff0c\u771f\u5b9e\u673a\u5668\u4eba\u8bd5\u9a8c\u5c55\u793a\u4e86\u901a\u8fc7\u53cd\u601d\u5b9e\u73b0\u884c\u4e3a\u4fee\u6b63\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u4f7f\u673a\u5668\u4eba\u5177\u5907\u53cd\u601d\u80fd\u529b\uff0c\u5c06\u72ec\u7acb\u8bd5\u9a8c\u8f6c\u5316\u4e3a\u53ef\u7d2f\u79ef\u7684\u5b66\u4e60\u7ecf\u9a8c\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u4f53\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.21196", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.21196", "abs": "https://arxiv.org/abs/2602.21196", "authors": ["Ravi Ghadia", "Maksim Abraham", "Sergei Vorobyov", "Max Ryabinin"], "title": "Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking", "comment": "14 pages, 6 figures", "summary": "Efficiently processing long sequences with Transformer models usually requires splitting the computations across accelerators via context parallelism. The dominant approaches in this family of methods, such as Ring Attention or DeepSpeed Ulysses, enable scaling over the context dimension but do not focus on memory efficiency, which limits the sequence lengths they can support. More advanced techniques, such as Fully Pipelined Distributed Transformer or activation offloading, can further extend the possible context length at the cost of training throughput. In this paper, we present UPipe, a simple yet effective context parallelism technique that performs fine-grained chunking at the attention head level. This technique significantly reduces the activation memory usage of self-attention, breaking the activation memory barrier and unlocking much longer context lengths. Our approach reduces intermediate tensor memory usage in the attention layer by as much as 87.5$\\%$ for 32B Transformers, while matching previous context parallelism techniques in terms of training speed. UPipe can support the context length of 5M tokens when training Llama3-8B on a single 8$\\times$H100 node, improving upon prior methods by over 25$\\%$.", "AI": {"tldr": "UPipe introduces fine-grained attention head-level chunking to reduce activation memory by 87.5% in 32B Transformers, enabling 5M token context length for Llama3-8B on single 8\u00d7H100 node while maintaining training speed.", "motivation": "Current context parallelism methods (e.g., Ring Attention, DeepSpeed Ulysses) prioritize scaling over context dimension but neglect memory efficiency, limiting supported sequence lengths; advanced techniques like activation offloading extend context length at the cost of training throughput.", "method": "Proposes UPipe, a context parallelism technique that performs fine-grained chunking at the attention head level to significantly reduce self-attention activation memory usage.", "result": "Reduces intermediate tensor memory in attention layers by up to 87.5% for 32B Transformers; supports 5M token context length when training Llama3-8B on a single 8\u00d7H100 node, improving prior methods by over 25% while matching their training speed.", "conclusion": "UPipe breaks the activation memory barrier for long-sequence processing, enabling much longer context lengths without sacrificing training throughput."}}
{"id": "2602.21201", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21201", "abs": "https://arxiv.org/abs/2602.21201", "authors": ["Tony Feng", "Junehyuk Jung", "Sang-hyun Kim", "Carlo Pagano", "Sergei Gukov", "Chiang-Chiang Tsai", "David Woodruff", "Adel Javanmard", "Aryan Mokhtari", "Dawsen Hwang", "Yuri Chervonyi", "Jonathan N. Lee", "Garrett Bingham", "Trieu H. Trinh", "Vahab Mirrokni", "Quoc V. Le", "Thang Luong"], "title": "Aletheia tackles FirstProof autonomously", "comment": "34 pages. Project page: https://github.com/google-deepmind/superhuman/tree/main/aletheia", "summary": "We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full transparency, we explain our interpretation of FirstProof and disclose details about our experiments as well as our evaluation. Raw prompts and outputs are available at https://github.com/google-deepmind/superhuman/tree/main/aletheia.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
