<div id=toc></div>

# Table of Contents

- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 2]
- [cs.LG](#cs.LG) [Total: 81]
- [quant-ph](#quant-ph) [Total: 46]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 10]
- [cs.AI](#cs.AI) [Total: 48]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [1] [Quantifying non-Markovianity in magnetization dynamics via entropy production rates](https://arxiv.org/abs/2602.17384)
*Felix Hartmann,Finja Tietjen,R. Matthias Geilhufe,Janet Anders*

Main category: cond-mat.stat-mech

TL;DR: 研究表明标准LLG方程熵产生率为正，而惯性及开放系统扩展版会出现暂时负熵率，呈现非马尔可夫性，其中开放系统版非马尔可夫性最强。


<details>
  <summary>Details</summary>
Motivation: 为了解释皮秒时间尺度上的实验现象，需要研究标准LLG方程的惯性及开放系统扩展版本。

Method: 通过解析和数值方法分析不同LLG方程的熵产生率，并使用标准度量量化非马尔可夫性程度。

Result: 标准LLG方程严格产生正熵率；惯性及开放系统LLG会暂时出现负熵率；在不同初始条件和磁场取向下，开放系统LLG的非马尔可夫性幅度始终最大。

Conclusion: 开放系统LLG扩展在描述皮秒尺度磁化动力学时表现出最强的非马尔可夫性，是该时间尺度下最合适的理论模型。

Abstract: Magnetization dynamics is commonly described by the stochastic Landau-Lifshitz-Gilbert (LLG) equation. On picosecond timescales, inertial and open-system extensions of the LLG equation are necessary to interpret recent experiments. We show analytically and numerically that the standard LLG equation exhibits strictly positive entropy production rates, while inertial and open-system LLG dynamics display temporarily negative entropy production rates indicating non-Markovianity. Here we quantify the degree of non-Markovianity using established measures. Our numerical calculations show that the open-system LLG equation consistently exhibits the highest magnitude of non-Markovianity for different initial conditions and magnetic field orientations.

</details>


### [2] [Matrix-product operator dualities in integrable lattice models](https://arxiv.org/abs/2602.17436)
*Yuan Miao,Andras Molnar,Nick G. Jones*

Main category: cond-mat.stat-mech

TL;DR: 系统分析矩阵乘积算符(MPO)对可积格点模型局域Yang-Baxter结构的影响。证明R矩阵在对偶变换下简单变换，并满足修正代数，从而为对偶模型的commuting转移矩阵提供可积结构，并以XXZ链的集群纠缠算符(可逆)和Kramers-Wannier对偶(不可逆)为例验证。


<details>
  <summary>Details</summary>
Motivation: MPO在可积模型中同时作为转移矩阵和对偶变换，但缺乏系统理解：1)局部Yang-Baxter结构在对偶下如何修正；2)可逆与不可逆变换(如离散gauging)的统一描述。这对连接不同模型及研究对称性保护拓扑相至关重要。

Method: 1)一般性分析MPO对偶下R矩阵的变换规律；2)推导广类MPO的修正Yang-Baxter代数；3)通过两个XXZ链案例(集群纠缠算符与Kramers-Wannier对偶)验证理论。

Result: - R矩阵在MPO对偶下变换形式简单
- 广类MPO的R矩阵满足修正代数，支撑对偶模型的commuting转移矩阵的可积结构
- 集群纠缠算符(可逆)与Kramers-Wannier对偶(不可逆)的XXZ实现
- 关于精确MPO逆的普适性结果

Conclusion: 建立MPO对偶下可积性保持的统一框架，修正Yang-Baxter代数连接可逆/不可逆变换，为拓扑相变和离散gauging提供理论基础，并推广MPO逆的相关结论。

Abstract: Matrix-product operators (MPOs) appear throughout the study of integrable lattice models, notably as the transfer matrices. They can also be used as transformations to construct dualities between such models, both invertible (including unitary) and non-invertible (including discrete gauging). We analyse how the local Yang--Baxter integrable structures are modified under such dualities. We see that the $\check{R}$-matrix, that appears in the baxterization approach to integrability, transforms in a simple manner. We further show for a broad class of MPOs that the usual Yang--Baxter $R$-matrix satisfies a modified algebra, previously identified in the unitary case, that gives a local integrable structure underlying the commuting transfer matrices of the dual model. We illustrate these results with two case studies, analysing an invertible unitary MPO and a non-invertible MPO both applied to the canonical XXZ spin chain. The former is the cluster entangler, arising in the study of symmetry-protected topological phases, while the latter is the Kramers--Wannier duality. We show several results for MPOs with exact MPO inverses that are of independent interest.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Provably Explaining Neural Additive Models](https://arxiv.org/abs/2602.17530)
*Shahaf Bassan,Yizhak Yisrael Elboher,Tobias Ladner,Volkan Şahin,Jan Kretinsky,Matthias Althoff,Guy Katz*

Main category: cs.LG

TL;DR: A new algorithm for Neural Additive Models (NAMs) efficiently generates provably cardinally-minimal explanations using only logarithmic verification queries, making previously infeasible tasks computationally tractable while outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Post-hoc explanation methods for neural networks are often heuristic with no provable guarantees. Identifying minimal sufficient feature subsets is computationally infeasible for standard networks (exponential queries, each NP-hard), despite being crucial for reliable explanations.

Method: A model-specific algorithm for NAMs that leverages their additive structure: parallelized preprocessing with logarithmic runtime in precision for each univariate component, followed by generating provably cardinally-minimal explanations using only O(log n) verification queries.

Result: The algorithm makes cardinally-minimal explanations feasible, outperforms existing subset-minimal algorithms, provides provably smaller explanations, reduces computation time substantially, and offers unique benefits beyond sampling-based techniques.

Conclusion: For NAMs, provably minimal explanations can be generated efficiently, addressing computational barriers while delivering higher-quality explanations than heuristic or relaxed approaches.

Abstract: Despite significant progress in post-hoc explanation methods for neural networks, many remain heuristic and lack provable guarantees. A key approach for obtaining explanations with provable guarantees is by identifying a cardinally-minimal subset of input features which by itself is provably sufficient to determine the prediction. However, for standard neural networks, this task is often computationally infeasible, as it demands a worst-case exponential number of verification queries in the number of input features, each of which is NP-hard.
  In this work, we show that for Neural Additive Models (NAMs), a recent and more interpretable neural network family, we can efficiently generate explanations with such guarantees. We present a new model-specific algorithm for NAMs that generates provably cardinally-minimal explanations using only a logarithmic number of verification queries
  in the number of input features, after a parallelized preprocessing step with logarithmic runtime in the required precision is applied to each small univariate NAM component.
  Our algorithm not only makes the task of obtaining cardinally-minimal explanations feasible, but even outperforms existing algorithms designed to find the relaxed variant of subset-minimal explanations - which may be larger and less informative but easier to compute - despite our algorithm solving a much more difficult task.
  Our experiments demonstrate that, compared to previous algorithms, our approach provides provably smaller explanations than existing works and substantially reduces the computation time. Moreover, we show that our generated provable explanations offer benefits that are unattainable by standard sampling-based techniques typically used to interpret NAMs.

</details>


### [4] [A Few-Shot LLM Framework for Extreme Day Classification in Electricity Markets](https://arxiv.org/abs/2602.16735)
*Saud Alghumayjan,Ming Yi,Bolun Xu*

Main category: cs.LG

TL;DR: Proposes a few-shot LLM framework for predicting next-day electricity price spikes by converting system state data into natural-language prompts. The approach matches supervised models like SVM/XGBoost with full data and outperforms them when historical data is scarce, demonstrating LLMs' data-efficiency potential.


<details>
  <summary>Details</summary>
Motivation: Electricity price spikes are critical but challenging to predict, especially with limited historical data. Traditional supervised machine learning models require substantial training data. This work leverages LLMs' few-shot learning capabilities to build a data-efficient classification framework that can work effectively in data-scarce environments.

Method: Aggregates electricity demand, renewable generation, weather forecasts, and recent prices into statistical features formatted as natural-language prompts. These prompts, along with general instructions, are fed to an LLM that outputs spike likelihood and confidence scores. The framework is evaluated on Texas electricity market historical data in a few-shot learning setting.

Result: The few-shot LLM approach achieves comparable performance to supervised models (SVM, XGBoost) with full datasets, but significantly outperforms both when limited historical data is available. This demonstrates the framework's data efficiency and adaptability to scarce-data scenarios.

Conclusion: LLMs show strong potential as data-efficient tools for electricity price spike classification, particularly in settings with limited historical data. The findings suggest LLMs can effectively leverage few-shot learning for time-series classification tasks in energy markets, opening new avenues for data-scarce predictive modeling.

Abstract: This paper proposes a few-shot classification framework based on Large Language Models (LLMs) to predict whether the next day will have spikes in real-time electricity prices. The approach aggregates system state information, including electricity demand, renewable generation, weather forecasts, and recent electricity prices, into a set of statistical features that are formatted as natural-language prompts and fed to an LLM along with general instructions. The model then determines the likelihood that the next day would be a spike day and reports a confidence score. Using historical data from the Texas electricity market, we demonstrate that this few-shot approach achieves performance comparable to supervised machine learning models, such as Support Vector Machines and XGBoost, and outperforms the latter two when limited historical data are available. These findings highlight the potential of LLMs as a data-efficient tool for classifying electricity price spikes in settings with scarce data.

</details>


### [5] [Real-time Secondary Crash Likelihood Prediction Excluding Post Primary Crash Features](https://arxiv.org/abs/2602.16739)
*Lei Han,Mohamed Abdel-Aty,Zubayer Islam,Chenzhu Wang*

Main category: cs.LG

TL;DR: 提出混合框架预测二次事故可能性，不依赖事后数据，使用实时交通流特征，在佛罗里达高速验证准确率达91%


<details>
  <summary>Details</summary>
Motivation: 现有二次事故预测依赖事故后特征（如事故类型/严重程度），难以实时获取，限制了主动交通管理系统的实际应用

Method: 设计动态时空窗口提取实时交通流与环境特征；构建三个模型（主事故模型+两个二次事故对比模型）；采用集成学习融合六种算法，通过投票机制综合输出

Result: 在佛罗里达高速测试中正确识别91%二次事故，误报率0.20；ROC曲线下面积从单模型最高0.902提升至混合模型0.952

Conclusion: 该框架显著提升预测性能，优于现有研究，为实时事故风险管理提供了可行方案

Abstract: Secondary crash likelihood prediction is a critical component of an active traffic management system to mitigate congestion and adverse impacts caused by secondary crashes. However, existing approaches mainly rely on post-crash features (e.g., crash type and severity) that are rarely available in real time, limiting their practical applicability. To address this limitation, we propose a hybrid secondary crash likelihood prediction framework that does not depend on post-crash features. A dynamic spatiotemporal window is designed to extract real-time traffic flow and environmental features from primary crash locations and their upstream segments. The framework includes three models: a primary crash model to estimate the likelihood of secondary crash occurrence, and two secondary crash models to evaluate traffic conditions at crash and upstream segments under different comparative scenarios. An ensemble learning strategy integrating six machine learning algorithms is developed to enhance predictive performance, and a voting-based mechanism combines the outputs of the three models. Experiments on Florida freeways demonstrate that the proposed hybrid framework correctly identifies 91% of secondary crashes with a low false alarm rate of 0.20. The Area Under the ROC Curve improves from 0.654, 0.744, and 0.902 for the individual models to 0.952 for the hybrid model, outperforming previous studies.

</details>


### [6] [Synergizing Transport-Based Generative Models and Latent Geometry for Stochastic Closure Modeling](https://arxiv.org/abs/2602.17089)
*Xinghao Dong,Huchen Yang,Jin-long Wu*

Main category: cs.LG

TL;DR: 扩散模型在生成AI中质量高但采样慢。本研究提出在低维潜空间中使用流匹配，实现单步采样，比迭代扩散快100倍，并通过隐式和显式正则化保持物理保真度和拓扑信息。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽能生成高质量且多样化的样本，适用于随机闭合模型学习，但其采样速度慢是主要缺点，限制了实际应用。

Method: 通过系统比较基于传输的生成模型在二维Kolmogorov流数值示例上的表现，采用流匹配技术在低维潜空间中进行采样，并比较联合训练方案的隐式正则化与度量保持(MP)和几何感知(GA)约束两种显式正则化方法。

Result: 低维潜空间中的流匹配实现了单步采样，速度比迭代扩散方法快两个数量级(100倍)；正则化后的潜空间保持了原始动力系统的关键拓扑信息。

Conclusion: 正则化流匹配在低维潜空间中既能实现快速采样，又能保持物理保真度和拓扑结构，为学习随机闭合模型提供了高效方案，且无需大量训练数据。

Abstract: Diffusion models recently developed for generative AI tasks can produce high-quality samples while still maintaining diversity among samples to promote mode coverage, providing a promising path for learning stochastic closure models. Compared to other types of generative AI models, such as GANs and VAEs, the sampling speed is known as a key disadvantage of diffusion models. By systematically comparing transport-based generative models on a numerical example of 2D Kolmogorov flows, we show that flow matching in a lower-dimensional latent space is suited for fast sampling of stochastic closure models, enabling single-step sampling that is up to two orders of magnitude faster than iterative diffusion-based approaches. To control the latent space distortion and thus ensure the physical fidelity of the sampled closure term, we compare the implicit regularization offered by a joint training scheme against two explicit regularizers: metric-preserving (MP) and geometry-aware (GA) constraints. Besides offering a faster sampling speed, both explicitly and implicitly regularized latent spaces inherit the key topological information from the lower-dimensional manifold of the original complex dynamical system, which enables the learning of stochastic closure models without demanding a huge amount of training data.

</details>


### [7] [Quantifying LLM Attention-Head Stability: Implications for Circuit Universality](https://arxiv.org/abs/2602.16740)
*Karan Bali,Jack Stanley,Praneet Suresh,Danilo Bzdok*

Main category: cs.LG

TL;DR: 该论文系统研究了不同规模Transformer语言模型中电路结构的跨训练稳定性。研究发现：中间层注意力头最不稳定但表征最独特；更深模型表现出更强的中层发散性；深层不稳定头功能更重要；权重衰减优化显著提升稳定性；残差流相对稳定。这些发现确立了电路跨实例鲁棒性对可扩展监督的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有工作很少对Transformer"电路"在不同训练实例间的稳定性进行严格检验，这限制了安全关键场景中对AI系统行为的可信度。需要验证这些电路是普遍存在于架构中，还是特定于单个训练实例的特殊现象。

Method: 通过系统研究不同规模Transformer模型在独立初始化训练运行之间的"跨重拟合稳定性"，逐层量化注意力头学习表征的相似性，进行严格的对比实验。

Result: 1) 中间层注意力头最不稳定但表征最独特；2) 更深模型中层发散性更强；3) 深层不稳定头比同层其他头功能更重要；4) 权重衰减优化显著提升注意力头稳定性；5) 残差流相对稳定。

Conclusion: 跨实例电路鲁棒性是构建可扩展监督的必要前提，为AI系统的白盒可监控性划定了边界。该研究强调了稳定性检验对 mechanistic interpretability 和安全保障的重要性。

Abstract: In mechanistic interpretability, recent work scrutinizes transformer "circuits" - sparse, mono or multi layer sub computations, that may reflect human understandable functions. Yet, these network circuits are rarely acid-tested for their stability across different instances of the same deep learning architecture. Without this, it remains unclear whether reported circuits emerge universally across labs or turn out to be idiosyncratic to a particular estimation instance, potentially limiting confidence in safety-critical settings. Here, we systematically study stability across-refits in increasingly complex transformer language models of various sizes. We quantify, layer by layer, how similarly attention heads learn representations across independently initialized training runs. Our rigorous experiments show that (1) middle-layer heads are the least stable yet the most representationally distinct; (2) deeper models exhibit stronger mid-depth divergence; (3) unstable heads in deeper layers become more functionally important than their peers from the same layer; (4) applying weight decay optimization substantially improves attention-head stability across random model initializations; and (5) the residual stream is comparatively stable. Our findings establish the cross-instance robustness of circuits as an essential yet underappreciated prerequisite for scalable oversight, drawing contours around possible white-box monitorability of AI systems.

</details>


### [8] [DeepVision-103K: A Visually Diverse, Broad-Coverage, and Verifiable Mathematical Dataset for Multimodal Reasoning](https://arxiv.org/abs/2602.16742)
*Haoxiang Sun,Lizhen Xu,Bing Zhao,Wotao Yin,Wei Wang,Boyu Yang,Rui Wang,Hu Wei*

Main category: cs.LG

TL;DR: 本文提出了DeepVision-103K数据集，这是一个用于增强大型多模态模型视觉推理能力的大规模RLVR训练数据集，涵盖多样化K12数学主题，能显著提升模型在多模态数学基准测试和通用推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR数据集主要来源于小规模手工构建或先前资源的重组，导致数据多样性和覆盖范围有限，制约了模型性能的进一步提升。

Method: 构建DeepVision-103K综合数据集，涵盖多样化的K12数学主题、广泛的知识点和丰富的视觉元素，用于RLVR训练。

Result: 在DeepVision上训练的模型在多模态数学基准测试中表现优异，并能有效泛化到通用多模态推理任务，展现出更强的视觉感知、反思和推理能力。

Conclusion: DeepVision数据集能有效推进多模态推理能力的发展，为大型多模态模型的训练提供了高质量的数据资源。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has been shown effective in enhancing the visual reflection and reasoning capabilities of Large Multimodal Models (LMMs). However, existing datasets are predominantly derived from either small-scale manual construction or recombination of prior resources, which limits data diversity and coverage, thereby constraining further gains in model performance. To this end, we introduce \textbf{DeepVision-103K}, a comprehensive dataset for RLVR training that covers diverse K12 mathematical topics, extensive knowledge points, and rich visual elements. Models trained on DeepVision achieve strong performance on multimodal mathematical benchmarks, and generalize effectively to general multimodal reasoning tasks. Further analysis reveals enhanced visual perception, reflection and reasoning capabilities in trained models, validating DeepVision's effectiveness for advancing multimodal reasoning. Data: \href{https://huggingface.co/datasets/skylenage/DeepVision-103K}{this url}.

</details>


### [9] [PETS: A Principled Framework Towards Optimal Trajectory Allocation for Efficient Test-Time Self-Consistency](https://arxiv.org/abs/2602.16745)
*Zhangyi Liu,Huaizhi Qu,Xiaowei Yin,He Sun,Yanjun Han,Tianlong Chen,Zhun Deng*

Main category: cs.LG

TL;DR: PETS introduces a principled framework for efficient test-time trajectory allocation using self-consistency rate, reducing sampling budgets by up to 75% (offline) and 55% (online) while outperforming uniform allocation.


<details>
  <summary>Details</summary>
Motivation: Current test-time scaling methods inefficiently allocate reasoning trajectories under limited budgets; no principled solution exists for sample-efficient self-consistency.

Method: Defines self-consistency rate (agreement with infinite-budget majority vote); models offline allocation via crowdsourcing theory and online allocation via adaptive budgeting based on question difficulty.

Result: Achieves perfect self-consistency on GPQA with 75% (offline) and 55% (online) budget reduction versus uniform allocation; maintains strong theoretical guarantees and computational efficiency.

Conclusion: PETS provides the first theoretically grounded, efficient test-time scaling framework that dynamically optimizes trajectory allocation across static and streaming scenarios.

Abstract: Test-time scaling can improve model performance by aggregating stochastic reasoning trajectories. However, achieving sample-efficient test-time self-consistency under a limited budget remains an open challenge. We introduce PETS (Principled and Efficient Test-TimeSelf-Consistency), which initiates a principled study of trajectory allocation through an optimization framework. Central to our approach is the self-consistency rate, a new measure defined as agreement with the infinite-budget majority vote. This formulation makes sample-efficient test-time allocation theoretically grounded and amenable to rigorous analysis. We study both offline and online settings. In the offline regime, where all questions are known in advance, we connect trajectory allocation to crowdsourcing, a classic and well-developed area, by modeling reasoning traces as workers. This perspective allows us to leverage rich existing theory, yielding theoretical guarantees and an efficient majority-voting-based allocation algorithm. In the online streaming regime, where questions arrive sequentially and allocations must be made on the fly, we propose a novel method inspired by the offline framework. Our approach adapts budgets to question difficulty while preserving strong theoretical guarantees and computational efficiency. Experiments show that PETS consistently outperforms uniform allocation. On GPQA, PETS achieves perfect self-consistency in both settings while reducing the sampling budget by up to 75% (offline) and 55% (online) relative to uniform allocation. Code is available at https://github.com/ZDCSlab/PETS.

</details>


### [10] [Low-Dimensional and Transversely Curved Optimization Dynamics in Grokking](https://arxiv.org/abs/2602.16746)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 本文通过几何分析研究了Transformer在模运算任务中的“grokking”现象，发现训练轨迹主要在一个低维执行子空间内演化，且正交方向的曲率增长先于泛化；干预实验表明沿子空间的运动是grokking的必要条件，但单纯增加曲率不足以引发泛化，从而支持grokking是逃离亚稳态势阱的几何解释。


<details>
  <summary>Details</summary>
Motivation: Grokking——在小算法任务中从记忆到泛化的延迟转变——仍 poorly understood。本文旨在通过几何视角揭示其优化动态机制，解释为何会出现长时间的 memorization 阶段以及随后的突然泛化。

Method: 对模运算任务中的Transformer注意力权重轨迹进行主成分分析，以提取低维执行子空间；计算连续梯度步的非交换性（commutator defects）以探测损失景观的曲率，并将曲率投影到学习到的子空间上；在不同学习率、超参数和随机种子下进行对照实验，并通过因果干预（抑制正交梯度流、人工增强曲率）检验其对grokking的影响。

Result: 第一主成分解释了68-83%的轨迹方差；曲率在正交方向显著增长，而训练轨迹基本保持在子空间内；曲率增长在泛化前出现，且提前时间随grokking时间尺度呈幂律关系；干预实验表明，沿子空间的运动是grokking的必要条件，抑制正交梯度流可阻止泛化，而人为提升曲率缺陷对grokking无显著影响。

Conclusion: Grokking 可解释为模型从低维 confinement 的亚稳态势阱中逃逸的过程，曲率的横向积累提供了逃离的驱动力，但仅靠曲率增加不足以触发泛化；该几何框架为理解 grokking 提供了统一的理论视角。

Abstract: Grokking -- the delayed transition from memorization to generalization in small algorithmic tasks -- remains poorly understood. We present a geometric analysis of optimization dynamics in transformers trained on modular arithmetic. PCA of attention weight trajectories reveals that training evolves predominantly within a low-dimensional execution subspace, with a single principal component capturing 68-83% of trajectory variance. To probe loss-landscape geometry, we measure commutator defects -- the non-commutativity of successive gradient steps -- and project them onto this learned subspace. We find that curvature grows sharply in directions orthogonal to the execution subspace while the trajectory remains largely confined to it. Importantly, curvature growth consistently precedes generalization across learning rates and hyperparameter regimes, with the lead time obeying a power law in the grokking timescale. Causal intervention experiments show that motion along the learned subspace is necessary for grokking, while artificially increasing curvature is insufficient. Together, these results support a geometric account in which grokking reflects escape from a metastable regime characterized by low-dimensional confinement and transverse curvature accumulation. All findings replicate across this learning-rate range, a qualitatively different slow regime (lr=5e-5, wd=0.1, 3 layers), and three random seeds, though alignment dynamics differ quantitatively between regimes. Causal intervention experiments establish that orthogonal gradient flow is necessary but not sufficient for grokking: suppressing it prevents generalization with a monotonic dose-response across four operations, while artificially boosting curvature defects has no effect.

</details>


### [11] [LiveClin: A Live Clinical Benchmark without Leakage](https://arxiv.org/abs/2602.16747)
*Xidong Wang,Shuqi Guo,Yue Shen,Junying Chen,Jian Wang,Jinjie Gu,Ping Zhang,Lei Liu,Benyou Wang*

Main category: cs.LG

TL;DR: 提出了LiveClin动态医疗大模型评测基准，通过每半年更新的真实临床病例和239名医生参与构建的多模态评测集，解决了静态基准的数据污染和知识过时问题，26个模型中最高准确率仅35.7%


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型评测因数据污染和知识过时导致评分虚高，无法反映真实临床能力，需要动态更新的评测基准来评估模型在真实医疗场景中的表现

Method: 从当代同行评议病例报告中构建，每半年更新一次；采用AI与239名医生协作流程，将真实患者病例转化为涵盖完整临床路径的复杂多模态评测场景，共包含1,407个病例报告和6,605个问题

Result: 评测26个医疗大模型发现，表现最佳的模型病例准确率仅为35.7%；人类专家中主任医师准确率最高，主治医师紧随其后，两者均超过大多数模型

Conclusion: LiveClin提供了一个持续演化的临床基础框架，可指导医疗大模型发展，缩小与真实世界医疗能力之间的差距，提升可靠性和实际应用价值

Abstract: The reliability of medical LLM evaluation is critically undermined by data contamination and knowledge obsolescence, leading to inflated scores on static benchmarks. To address these challenges, we introduce LiveClin, a live benchmark designed for approximating real-world clinical practice. Built from contemporary, peer-reviewed case reports and updated biannually, LiveClin ensures clinical currency and resists data contamination. Using a verified AI-human workflow involving 239 physicians, we transform authentic patient cases into complex, multimodal evaluation scenarios that span the entire clinical pathway. The benchmark currently comprises 1,407 case reports and 6,605 questions. Our evaluation of 26 models on LiveClin reveals the profound difficulty of these real-world scenarios, with the top-performing model achieving a Case Accuracy of just 35.7%. In benchmarking against human experts, Chief Physicians achieved the highest accuracy, followed closely by Attending Physicians, with both surpassing most models. LiveClin thus provides a continuously evolving, clinically grounded framework to guide the development of medical LLMs towards closing this gap and achieving greater reliability and real-world utility. Our data and code are publicly available at https://github.com/AQ-MedAI/LiveClin.

</details>


### [12] [Attending to Routers Aids Indoor Wireless Localization](https://arxiv.org/abs/2602.16762)
*Ayush Roy,Tahsin Fuad Hassan,Roshan Ayyalasomayajula,Vishnu Suresh Lokhande*

Main category: cs.LG

TL;DR: 提出"路由器注意力"机制动态加权多路由器信息，提升Wi-Fi定位精度30%以上


<details>
  <summary>Details</summary>
Motivation: 现有机器学习无线定位算法在聚合多路由器信息时未合理加权，导致收敛性差和精度下降，受传统加权三角测量方法启发

Method: 将注意力层集成到标准机器学习定位架构中，使每个路由器的贡献在聚合时获得差异化权重

Result: 在开源数据集上验证，相比基准架构定位精度提升超30%

Conclusion: 强调路由器信息相关性可显著改善无线定位性能，证实注意力机制在多路由器场景的有效性

Abstract: Modern machine learning-based wireless localization using Wi-Fi signals continues to face significant challenges in achieving groundbreaking performance across diverse environments. A major limitation is that most existing algorithms do not appropriately weight the information from different routers during aggregation, resulting in suboptimal convergence and reduced accuracy. Motivated by traditional weighted triangulation methods, this paper introduces the concept of attention to routers, ensuring that each router's contribution is weighted differently when aggregating information from multiple routers for triangulation. We demonstrate, by incorporating attention layers into a standard machine learning localization architecture, that emphasizing the relevance of each router can substantially improve overall performance. We have also shown through evaluation over the open-sourced datasets and demonstrate that Attention to Routers outperforms the benchmark architecture by over 30% in accuracy.

</details>


### [13] [Omitted Variable Bias in Language Models Under Distribution Shift](https://arxiv.org/abs/2602.16784)
*Victoria Lin,Louis-Philippe Morency,Eli Ben-Michael*

Main category: cs.LG

TL;DR: 提出新框架解决语言模型中的不可观测分布偏移问题，通过量化最坏情况泛化性能边界提升评估与优化效果


<details>
  <summary>Details</summary>
Motivation: 现有方法仅处理语言模型中的可观测分布偏移，忽略了不可观测变量导致的遗漏变量偏差，影响模型评估和优化效果

Method: 构建将不可观测变量强度映射到语言模型最坏情况泛化性能边界的理论框架

Result: 该框架提供更严谨的分布外性能评估，相比标准方法提升真实分布外性能，并支持在标签可用时推断不可观测变量强度

Conclusion: 通过系统处理不可观测分布偏移成分，为语言模型在分布偏移下的鲁棒性提供了更全面的理论保障和实践改进

Abstract: Despite their impressive performance on a wide variety of tasks, modern language models remain susceptible to distribution shifts, exhibiting brittle behavior when evaluated on data that differs in distribution from their training data. In this paper, we describe how distribution shifts in language models can be separated into observable and unobservable components, and we discuss how established approaches for dealing with distribution shift address only the former. Importantly, we identify that the resulting omitted variable bias from unobserved variables can compromise both evaluation and optimization in language models. To address this challenge, we introduce a framework that maps the strength of the omitted variables to bounds on the worst-case generalization performance of language models under distribution shift. In empirical experiments, we show that using these bounds directly in language model evaluation and optimization provides more principled measures of out-of-distribution performance, improves true out-of-distribution performance relative to standard distribution shift adjustment methods, and further enables inference about the strength of the omitted variables when target distribution labels are available.

</details>


### [14] [Better Think Thrice: Learning to Reason Causally with Double Counterfactual Consistency](https://arxiv.org/abs/2602.16787)
*Victoria Lin,Xinnuo Xu,Rachel Lawrence,Risa Ueno,Amit Sharma,Javier Gonzalez,Niranjani Prasad*

Main category: cs.LG

TL;DR: 本文提出双重反事实一致性（DCC）方法，无需标注数据即可评估和提升大语言模型的因果推理能力，通过验证因果干预和反事实预测两个关键要素，在多个模型族上显著改善推理任务表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理基准测试中表现优异，但在处理反事实问题时表现脆弱，暴露了其在因果推理方面的根本性缺陷；而现有依赖标注数据的反事实任务基准难以规模化扩展，无法满足覆盖海量潜在反事实场景的需求。

Method: 提出双重反事实一致性（DCC），一种轻量级的推理时方法，无需标注数据即可同时验证模型的因果干预能力和反事实预测能力，并作为训练无关的测试时拒绝采样标准。

Result: 使用DCC评估了多个领先大语言模型在不同推理任务和干预场景下的因果推理能力，并证明作为测试时拒绝采样标准能直接提升多个模型族的推理任务性能。

Conclusion: DCC为评估和提升大语言模型的因果推理能力提供了高效可扩展的解决方案，揭示了模型在反事实推理方面的弱点，并为无需额外训练即可改善模型表现提供了实用途径。

Abstract: Despite their strong performance on reasoning benchmarks, large language models (LLMs) have proven brittle when presented with counterfactual questions, suggesting weaknesses in their causal reasoning ability. While recent work has demonstrated that labeled counterfactual tasks can be useful benchmarks of LLMs' causal reasoning, producing such data at the scale required to cover the vast potential space of counterfactuals is limited. In this work, we introduce double counterfactual consistency (DCC), a lightweight inference-time method for measuring and guiding the ability of LLMs to reason causally. Without requiring labeled counterfactual data, DCC verifies a model's ability to execute two important elements of causal reasoning: causal intervention and counterfactual prediction. Using DCC, we evaluate the causal reasoning abilities of various leading LLMs across a range of reasoning tasks and interventions. Moreover, we demonstrate the effectiveness of DCC as a training-free test-time rejection sampling criterion and show that it can directly improve performance on reasoning tasks across multiple model families.

</details>


### [15] [Escaping the Cognitive Well: Efficient Competition Math with Off-the-Shelf Models](https://arxiv.org/abs/2602.16793)
*Xingyu Dang,Rohit Agarwal,Rodrigo Porto,Anirudh Goyal,Liam H Fowl,Sanjeev Arora*

Main category: cs.LG

TL;DR: 提出一种低成本推理管道，通过提取和独立验证引理来避免"认知陷阱"故障，使用通用现成模型在IMO数学问题上达到最先进性能，成本远低于竞争方法


<details>
  <summary>Details</summary>
Motivation: 现有IMO数学推理模型要么使用定制未公开模型，要么需大规模推理导致成本极高（每题3000美元），亟需低成本且高性能的解决方案

Method: 基于"认知陷阱"（求解器与评分器共同收敛到错误解）洞察，采用猜想提取策略：从生成解中分离候选引理，并在新环境中独立验证引理及其否定形式（上下文解耦）

Result: 在IMO-ProofBench Advanced基准上，使用Gemini 3.0 Pro实现67.1%准确率，每题平均成本约31美元，性能超此前最佳公开管道的两倍，成本降低近两个数量级

Conclusion: 该管道成功通过解决评分器故障模式，在显著降低推理成本的同时，仅用通用模型就达到IMO数学问题的顶尖性能，为高性价比自动推理提供了可行路径

Abstract: In the past year, custom and unreleased math reasoning models reached gold medal performance on the International Mathematical Olympiad (IMO). Similar performance was then reported using large-scale inference on publicly available models but at prohibitive costs (e.g., 3000 USD per problem). In this work, we present an inference pipeline that attains best-in-class performance on IMO-style math problems at an average inference cost orders of magnitude below competing methods while using only general-purpose off-the-shelf models. Our method relies on insights about grader failure in solver-grader pipelines, which we call the Cognitive Well (iterative refinement converging to a wrong solution that the solver as well as the pipeline's internal grader consider to be basically correct). Our pipeline addresses these failure modes through conjecture extraction, wherein candidate lemmas are isolated from generated solutions and independently verified alongside their negations in a fresh environment (context detachment). On IMO-ProofBench Advanced (PB-Adv), our pipeline achieves 67.1 percent performance using Gemini 3.0 Pro with an average cost per question of approximately 31 USD. At the time of evaluation, this represented the state-of-the-art on PB-Adv among both public and unreleased models, and more than doubles the success rate of the next best publicly accessible pipeline, all at a fraction of the cost.

</details>


### [16] [Efficient Tail-Aware Generative Optimization via Flow Model Fine-Tuning](https://arxiv.org/abs/2602.16796)
*Zifan Wang,Riccardo De Santi,Xiaoyu Mo,Michael M. Zavlanos,Andreas Krause,Karl H. Johansson*

Main category: cs.LG

TL;DR: 提出TFFT方法，基于CVaR对扩散/流模型进行分布感知微调，可分别控制高奖励尾端（探索）和低奖励尾端（可靠性），计算效率与标准方法相当。


<details>
  <summary>Details</summary>
Motivation: 现有熵正则化方法仅最大化期望奖励，无法控制尾端行为，而实际应用中尾端控制对可靠性（下尾）和发现能力（上尾）至关重要。

Method: 利用CVaR的变分对偶形式，将问题解耦为轻量级一维阈值优化和带伪奖励的熵正则化微调两阶段，实现高效CVaR微调。

Result: 在文本到图像生成和分子设计等任务上验证有效，计算成本与标准期望微调方法相当。

Conclusion: TFFT为微调提供了原则性且高效的方法，能同时控制奖励分布的双尾，满足实际应用需求。

Abstract: Fine-tuning pre-trained diffusion and flow models to optimize downstream utilities is central to real-world deployment. Existing entropy-regularized methods primarily maximize expected reward, providing no mechanism to shape tail behavior. However, tail control is often essential: the lower tail determines reliability by limiting low-reward failures, while the upper tail enables discovery by prioritizing rare, high-reward outcomes. In this work, we present Tail-aware Flow Fine-Tuning (TFFT), a principled and efficient distributional fine-tuning algorithm based on the Conditional Value-at-Risk (CVaR). We address two distinct tail-shaping goals: right-CVaR for seeking novel samples in the high-reward tail and left-CVaR for controlling worst-case samples in the low-reward tail. Unlike prior approaches that rely on non-linear optimization, we leverage the variational dual formulation of CVaR to decompose it into a decoupled two-stage procedure: a lightweight one-dimensional threshold optimization step, and a single entropy-regularized fine-tuning process via a specific pseudo-reward. This decomposition achieves CVaR fine-tuning efficiently with computational cost comparable to standard expected fine-tuning methods. We demonstrate the effectiveness of TFFT across illustrative experiments, high-dimensional text-to-image generation, and molecular design.

</details>


### [17] [Formal Mechanistic Interpretability: Automated Circuit Discovery with Provable Guarantees](https://arxiv.org/abs/2602.16823)
*Itamar Hadad,Guy Katz,Shahaf Bassan*

Main category: cs.LG

TL;DR: The paper proposes a neural network verification-based approach to automated circuit discovery that provides three types of provable guarantees—input domain robustness, robust patching, and minimality—uncovering theoretical connections between them and demonstrating superior robustness on vision models compared to standard methods.


<details>
  <summary>Details</summary>
Motivation: Existing automated circuit discovery methods rely on heuristics and approximations without offering provable guarantees over continuous input domains, limiting their reliability and theoretical foundation in mechanistic interpretability.

Method: Leveraging recent advances in neural network verification to develop automated algorithms that produce circuits with mathematically provable guarantees across continuous input spaces.

Result: 1) Algorithms providing three types of provable guarantees; 2) Discovery of novel theoretical connections between robustness, patching, and minimality; 3) Experimental validation showing substantially stronger robustness than standard circuit discovery methods on vision models using state-of-the-art verifiers.

Conclusion: This work establishes a principled foundation for provable circuit discovery, advancing mechanistic interpretability by replacing heuristic-based approaches with formally verified circuits that offer stronger theoretical and empirical guarantees.

Abstract: *Automated circuit discovery* is a central tool in mechanistic interpretability for identifying the internal components of neural networks responsible for specific behaviors. While prior methods have made significant progress, they typically depend on heuristics or approximations and do not offer provable guarantees over continuous input domains for the resulting circuits. In this work, we leverage recent advances in neural network verification to propose a suite of automated algorithms that yield circuits with *provable guarantees*. We focus on three types of guarantees: (1) *input domain robustness*, ensuring the circuit agrees with the model across a continuous input region; (2) *robust patching*, certifying circuit alignment under continuous patching perturbations; and (3) *minimality*, formalizing and capturing a wide array of various notions of succinctness. Interestingly, we uncover a diverse set of novel theoretical connections among these three families of guarantees, with critical implications for the convergence of our algorithms. Finally, we conduct experiments with state-of-the-art verifiers on various vision models, showing that our algorithms yield circuits with substantially stronger robustness guarantees than standard circuit discovery methods, establishing a principled foundation for provable circuit discovery.

</details>


### [18] [HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind](https://arxiv.org/abs/2602.16826)
*Nigel Doering,Rahath Malladi,Arshia Sangwan,David Danks,Tauhidur Rahman*

Main category: cs.LG

TL;DR: 提出HiVAE分层变分架构，将心智理论(ToM)推理扩展到真实时空领域，在3185节点校园导航任务中性能显著提升，但揭示学习到的潜在表示缺乏对实际心理状态的显式 grounding，并提出自监督对齐策略以寻求社区反馈


<details>
  <summary>Details</summary>
Motivation: 现有心智理论(ToM)方法主要局限于小型人类可理解的网格世界空间，难以扩展到真实复杂的时空领域

Method: 受人类认知的信念-欲望-意图结构启发，设计三层次VAE分层架构(HiVAE)，实现ToM推理的扩展

Result: 在包含3185个节点的校园导航任务上取得显著性能提升，但发现分层结构虽改善预测，学习的潜在表示却缺乏对实际心理状态的显式关联

Conclusion: 提出自监督对齐策略解决 grounding 问题，并希望通过本工作获得社区对 grounding 方法的反馈与建议

Abstract: Theory of mind (ToM) enables AI systems to infer agents' hidden goals and mental states, but existing approaches focus mainly on small human understandable gridworld spaces. We introduce HiVAE, a hierarchical variational architecture that scales ToM reasoning to realistic spatiotemporal domains. Inspired by the belief-desire-intention structure of human cognition, our three-level VAE hierarchy achieves substantial performance improvements on a 3,185-node campus navigation task. However, we identify a critical limitation: while our hierarchical structure improves prediction, learned latent representations lack explicit grounding to actual mental states. We propose self-supervised alignment strategies and present this work to solicit community feedback on grounding approaches.

</details>


### [19] [VAM: Verbalized Action Masking for Controllable Exploration in RL Post-Training -- A Chess Case Study](https://arxiv.org/abs/2602.16833)
*Zhicheng Zhang,Ziyan Wang,Yali Du,Fei Fang*

Main category: cs.LG

TL;DR: Proposes Verbalized Action Masking (VAM) to improve exploration in LLM reinforcement learning post-training, using chess to demonstrate that VAM with iterative action-space pruning enhances learning efficiency and performance over baselines.


<details>
  <summary>Details</summary>
Motivation: Exploration bottleneck in RL post-training of large language models due to sparse feedback and large action spaces causing premature collapse into repetitive behaviors.

Method: Verbalized Action Masking (VAM) that enforces action selection from a verbalized mask in the prompt, plus iterative action-space pruning to repeatedly resample from reduced candidate sets until target action is found. Evaluated in chess under engine-play and fixed-dataset regimes.

Result: VAM improves learning efficiency and final performance over strong baselines on held-out chess puzzles and full-game play, measured by average centipawn loss (ACPL).

Conclusion: Verbalized masking serves as a practical mechanism for controllable exploration in LLM RL post-training.

Abstract: Exploration remains a key bottleneck for reinforcement learning (RL) post-training of large language models (LLMs), where sparse feedback and large action spaces can lead to premature collapse into repetitive behaviors. We propose Verbalized Action Masking (VAM), which verbalizes an action mask in the prompt and enforces that the model outputs an action from the masked set. Building on this interface, we introduce iterative action-space pruning: if the target action is not sampled, we remove valid sampled actions from the mask and resample under the reduced candidate set, repeating until the target is sampled or a fixed budget is exhausted. We study VAM in chess and evaluate it under two training regimes: an engine-play regime that generates states via play against an engine opponent and a fixed-dataset regime that trains from a fixed dataset of positions with verifier scores. Across held-out chess puzzles and full-game play measured by average centipawn loss (ACPL), VAM improves learning efficiency and final performance over strong baselines, highlighting verbalized masking as a practical mechanism for controllable exploration in LLM RL post-training.

</details>


### [20] [A Residual-Aware Theory of Position Bias in Transformers](https://arxiv.org/abs/2602.16837)
*Hanna Herasimchyk,Robin Labryga,Tomislav Prusina,Sören Laue*

Main category: cs.LG

TL;DR: 该研究通过残差感知的累积注意力展开理论，揭示Transformer的U型位置偏置（关注首尾token）源于架构设计，证明残差连接可阻止无限深度理论预测的注意力坍缩。


<details>
  <summary>Details</summary>
Motivation: Transformer模型存在系统性位置偏置但其架构根源尚不清晰，现有无限深度理论预测注意力必然坍缩至首个token，但该现象在实践中并未出现。

Method: 提出残差感知的累积注意力展开理论，将残差连接纳入分析，对比无限深度理想条件与现实有限深度情况。

Result: 证明有限深度下因果Transformer产生U型位置偏置（早期和晚期token获得更多注意力），且残差连接是防止理论坍缩的关键架构组件。

Conclusion: U型位置偏置为架构固有特性，为"迷失中间"现象提供理论解释，残差连接在实际Transformer训练中起关键稳定作用。

Abstract: Transformer models systematically favor certain token positions, yet the architectural origins of this position bias remain poorly understood. Under causal masking at infinite depth, prior theoretical analyses of attention rollout predict an inevitable collapse of attention onto the first token. Such collapse, however, does not occur in practice. We resolve this discrepancy with a residual-aware theory of cumulative attention rollout. By incorporating residual connections, we show that this architectural component prevents collapse under realistic conditions. At finite depth, we prove that causal Transformers induce a U-shaped position bias, with attention concentrating on early and late tokens. This result provides a principled architectural explanation for the Lost-in-the-Middle phenomenon.

</details>


### [21] [Training Large Reasoning Models Efficiently via Progressive Thought Encoding](https://arxiv.org/abs/2602.16839)
*Zeliang Zhang,Xiaodong Liu,Hao Cheng,Hao Sun,Chenliang Xu,Jianfeng Gao*

Main category: cs.LG

TL;DR: Progressive Thought Encoding is a parameter-efficient fine-tuning method that enables large reasoning models to reason effectively under fixed-size caches by progressively encoding intermediate reasoning into fixed-size vectors, achieving significant performance improvements while reducing memory usage.


<details>
  <summary>Details</summary>
Motivation: Large reasoning models face efficiency barriers in RL training due to autoregressive decoding dominating time and memory usage. While sliding-window cache strategies can bound memory, they disrupt long-context reasoning and degrade performance, creating a need for methods that maintain reasoning capability under memory constraints.

Method: Progressive Thought Encoding - a parameter-efficient fine-tuning approach that progressively encodes intermediate reasoning steps into fixed-size vector representations, eliminating the need to backpropagate through full-cache rollouts and maintaining constant memory during inference.

Result: Experiments on three models across six mathematical benchmarks show consistent gains: +19.3% improvement over LoRA fine-tuning, +29.9% over untuned LRMs on average, with up to +23.4 accuracy improvement on AIME2024/2025 under tight cache budgets.

Conclusion: Progressive Thought Encoding not only improves reasoning accuracy but also makes RL training of large reasoning models substantially more efficient and scalable under real-world memory constraints.

Abstract: Large reasoning models (LRMs) excel on complex problems but face a critical barrier to efficiency: reinforcement learning (RL) training requires long rollouts for outcome-based rewards, where autoregressive decoding dominates time and memory usage. While sliding-window cache strategies can bound memory, they disrupt long-context reasoning and degrade performance. We introduce Progressive Thought Encoding, a parameter-efficient fine-tuning method that enables LRMs to reason effectively under fixed-size caches. By progressively encoding intermediate reasoning into fixed-size vector representations, our approach eliminates the need to backpropagate through full-cache rollouts, thereby reducing memory usage, while maintaining constant memory during inference. Experiments on three models, including Qwen2.5-3B-Instruct, Qwen2.5-7B-Instruct, and DeepSeek-R1-Distill-Llama-8B, on six widely used challenging mathematical benchmarks show consistent gains: our method achieves +19.3% improvement over LoRA-based fine-tuning and +29.9% over LRMs without fine-tuning on average, with up to +23.4 accuracy improvement on AIME2024/2025 under the same tight cache budgets. These results demonstrate that Progressive Thought Encoding not only improves reasoning accuracy but also makes RL training of LRMs substantially more efficient and scalable under real-world memory constraints.

</details>


### [22] [What is the Value of Censored Data? An Exact Analysis for the Data-driven Newsvendor](https://arxiv.org/abs/2602.16842)
*Rachitesh Kumar,Omar Mouchtaki*

Main category: cs.LG

TL;DR: This paper analyzes the offline newsvendor problem with censored demand data (where only sales are observed, not true demand due to stockouts). It develops a method to compute exact worst-case regret for data-driven inventory policies by reducing an infinite-dimensional optimization to finite dimensions, revealing that targeted exploration at high inventory levels is crucial for near-optimal performance under censoring, while the common "sales-as-demand" heuristic suffers severe degradation.


<details>
  <summary>Details</summary>
Motivation: Prior works assume fully observed demand, but real-world point-of-sale systems only record sales (censored at inventory levels), not true demand during stockouts. This censoring fundamentally limits learning from passive sales data, and the impact on classical data-driven inventory policies remains poorly understood.

Method: A general procedure converts the infinite-dimensional, non-convex worst-case regret optimization problem into a finite-dimensional one. This reduction enables exact computation of regret bounds for any sample size and censoring level, applied to analyze policies like Kaplan-Meier under demand censoring.

Result: (1) Demand censoring severely restricts learning from passive data alone; (2) Minimal targeted exploration at high inventory levels enables near-optimal worst-case performance even under heavy censoring (Kaplan-Meier policy); (3) The "sales-as-demand" heuristic causes drastic performance loss as censored data accumulates due to unrecorded stockout events.

Conclusion: Demand censoring critically degrades offline learning from sales data, but strategic exploration mitigates this. Crucially, the quality of point-of-sale information (e.g., recording stockouts) determines what can be learned offline—systems omitting stockout data make the "sales-as-demand" approach fundamentally unreliable.

Abstract: We study the offline data-driven newsvendor problem with censored demand data. In contrast to prior works where demand is fully observed, we consider the setting where demand is censored at the inventory level and only sales are observed; sales match demand when there is sufficient inventory, and equal the available inventory otherwise. We provide a general procedure to compute the exact worst-case regret of classical data-driven inventory policies, evaluated over all demand distributions. Our main technical result shows that this infinite-dimensional, non-convex optimization problem can be reduced to a finite-dimensional one, enabling an exact characterization of the performance of policies for any sample size and censoring levels. We leverage this reduction to derive sharp insights on the achievable performance of standard inventory policies under demand censoring. In particular, our analysis of the Kaplan-Meier policy shows that while demand censoring fundamentally limits what can be learned from passive sales data, just a small amount of targeted exploration at high inventory levels can substantially improve worst-case guarantees, enabling near-optimal performance even under heavy censoring. In contrast, when the point-of-sale system does not record stockout events and only reports realized sales, a natural and commonly used approach is to treat sales as demand. Our results show that policies based on this sales-as-demand heuristic can suffer severe performance degradation as censored data accumulates, highlighting how the quality of point-of-sale information critically shapes what can, and cannot, be learned offline.

</details>


### [23] [ML-driven detection and reduction of ballast information in multi-modal datasets](https://arxiv.org/abs/2602.16876)
*Yaroslav Solovko*

Main category: cs.LG

TL;DR: 提出多模态框架和Ballast Score，通过多种特征选择方法识别冗余特征，可在不影响甚至提升性能的前提下剪枝超70%特征，显著提升ML效率。


<details>
  <summary>Details</summary>
Motivation: 现代数据集常含冗余低价值信息（"压舱石"），增加维度、存储和计算成本却无分析价值，亟需自动化识别与去除方法。

Method: 开发通用多模态框架，适用结构化、半结构化、非结构化及稀疏数据。综合熵、互信息、Lasso、SHAP、PCA、主题建模和嵌入分析等技术识别冗余特征，提出Ballast Score整合信号实现跨模态统一剪枝。

Result: 实验显示，稀疏/半结构化数据可剪枝超70%特征，仅轻微影响甚至提升分类性能，同时大幅降低训练时间和内存占用。揭示了统计型、语义型和基础设施型等压舱石类型。

Conclusion: 该框架为构建精简高效的机器学习流程提供实用指导，能显著减少资源消耗并维持或提升模型效果。

Abstract: Modern datasets often contain ballast as redundant or low-utility information that increases dimensionality, storage requirements, and computational cost without contributing meaningful analytical value. This study introduces a generalized, multimodal framework for ballast detection and reduction across structured, semi-structured, unstructured, and sparse data types. Using diverse datasets, entropy, mutual information, Lasso, SHAP, PCA, topic modelling, and embedding analysis are applied to identify and eliminate ballast features. A novel Ballast Score is proposed to integrate these signals into a unified, cross-modal pruning strategy. Experimental results demonstrate that significant portions of the feature space as often exceeding 70% in sparse or semi-structured data, can be pruned with minimal or even improved classification performance, along with substantial reductions in training time and memory footprint. The framework reveals distinct ballast typologies (e.g. statistical, semantic, infrastructural), and offers practical guidance for leaner, more efficient machine learning pipelines.

</details>


### [24] [Construction of a classification model for dementia among Brazilian adults aged 50 and over](https://arxiv.org/abs/2602.16887)
*F. S. Menezes,M. C. F. G. Barretto,E. Q. C. Garcia,T. A. E. Ferreira,J. G. Alvez*

Main category: cs.LG

TL;DR: 研究利用巴西9412名中老年数据构建痴呆预测模型，发现文盲、高龄、低体重等8项强风险因素及3项保护因素；随机森林模型（AUC=0.776）有效识别高风险人群，为资源有限的巴西初级卫生系统提供低成本筛查工具。


<details>
  <summary>Details</summary>
Motivation: 开发针对巴西中老年人群的低成本、可干预变量的痴呆症分类模型，以识别高风险个体并优化初级卫生资源分配。

Method: 基于巴西老龄化纵向研究（ELSI-Brazil）9412名参与者的横断面数据，结合随机森林（RF）与多变量逻辑回归分析，通过神经心理学评估和知情者报告确定痴呆状态，筛选可修改风险因素。

Result: 痴呆患病率为9.6%；文盲（OR=7.42）、90岁以上（OR=11.00）、低体重（OR=2.11）、握力弱（OR=2.50）、黑人自述（OR=1.47）、缺乏运动（OR=1.61）、听力损失（OR=1.65）和抑郁症状（OR=1.72）显著增加风险；高教育（OR=0.44）、生活满意度高（OR=0.72）和就业（OR=0.78）为保护因素。RF模型性能优于逻辑回归（AUC=0.776，敏感度0.708，特异度0.702）。

Conclusion: 痴呆风险具多维性，通过可及性因素识别脆弱人群对巴西初级卫生保健资源高效配置和痴呆预防具有重要公共卫生意义。

Abstract: To build a dementia classification model for middle-aged and elderly Brazilians, implemented in Python, combining variable selection and multivariable analysis, using low-cost variables with modification potential. Observational study with a predictive modeling approach using a cross-sectional design, aimed at estimating the chances of developing dementia, using data from the Brazilian Longitudinal Study of Aging (ELSI-Brazil), involving 9,412 participants. Dementia was determined based on neuropsychological assessment and informant-based cognitive function. Analyses were performed using Random Forest (RF) and multivariable logistic regression to estimate the risk of dementia in the middle-aged and elderly populations of Brazil. The prevalence of dementia was 9.6%. The highest odds of dementia were observed in illiterate individuals (Odds Ratio (OR) = 7.42), individuals aged 90 years or older (OR = 11.00), low weight (OR = 2.11), low handgrip strength (OR = 2.50), self-reported black skin color (OR = 1.47), physical inactivity (OR = 1.61), self-reported hearing loss (OR = 1.65), and presence of depressive symptoms (OR = 1.72). Higher education (OR=0.44), greater life satisfaction (OR=0.72), and being employed (OR=0.78) were protective factors. The RF model outperformed logistic regression, achieving an area under the ROC curve of 0.776, with a sensitivity of 0.708, a specificity of 0.702, an F1-score of 0.311, a G-means of 0.705, and an accuracy of 0.703. Conclusion: The findings reinforce the multidimensional nature of dementia and the importance of accessible factors for identifying vulnerable individuals. Strengthening public policies focused on promoting brain health can contribute significantly to the efficient allocation of resources in primary care and dementia prevention in Brazil

</details>


### [25] [Multi-Agent Lipschitz Bandits](https://arxiv.org/abs/2602.16965)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 提出了一种无通信的去中心化多人随机老虎机算法，通过最大化搜索协调玩家并分解为独立单人问题，在连续Lipschitz动作空间上实现了接近最优的遗憾界，且协调成本与时间范围无关。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化多人老虎机问题中通信受限的挑战，在连续Lipschitz结构动作空间下，当多个玩家选择相同动作会导致硬碰撞（零奖励）时，设计一个无通信且协调成本不随时间范围增长的最优算法。

Method: 提出模块化协议：首先通过创新的最大化搜索解决多智能体协调问题，将玩家分配到不同的价值区域；然后将原问题解耦为N个独立的单人Lipschitz老虎机问题进行求解。

Result: 实现了接近最优的遗憾界O~(T^{(d+1)/(d+2)})加上与T无关的协调成本，达到了单人玩家的速率水平；该框架首次为此类问题提供此类保证，并推广到一般距离阈值碰撞模型。

Conclusion: 该工作是首个为连续Lipschitz空间中的去中心化多人老虎机问题提供近最优保证的框架，通过创新的协调-解耦方法有效消除了通信需求，同时保持最优性能。

Abstract: We study the decentralized multi-player stochastic bandit problem over a continuous, Lipschitz-structured action space where hard collisions yield zero reward. Our objective is to design a communication-free policy that maximizes collective reward, with coordination costs that are independent of the time horizon $T$. We propose a modular protocol that first solves the multi-agent coordination problem -- identifying and seating players on distinct high-value regions via a novel maxima-directed search -- and then decouples the problem into $N$ independent single-player Lipschitz bandits. We establish a near-optimal regret bound of $\tilde{O}(T^{(d+1)/(d+2)})$ plus a $T$-independent coordination cost, matching the single-player rate. To our knowledge, this is the first framework providing such guarantees, and it extends to general distance-threshold collision models.

</details>


### [26] [A Unified Framework for Locality in Scalable MARL](https://arxiv.org/abs/2602.16966)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 本文通过提出策略依赖的分解方法，解决了多智能体强化学习中指数衰减性质(EDP)条件过于保守的问题。研究发现，平滑策略可在强动作耦合环境中诱导局部性，推导出更紧的光谱条件ρ(E^s+E^aΠ(π))<1，并分析了可证明正确的局部块坐标策略改进框架。


<details>
  <summary>Details</summary>
Motivation: 可扩展多智能体强化学习面临维度灾难挑战。现有利用局部性的方法基于EDP，但其条件过于保守，仅依赖最坏情况下的环境边界而忽略策略的正则化效应，限制了算法性能。

Method: 提出对策略诱导的相互依赖矩阵H^π进行新颖分解，将环境对状态(E^s)和动作(E^a)的敏感度与策略对状态的敏感度(Π(π))解耦，揭示策略平滑性如何影响局部性。

Result: 推导出指数衰减的一般光谱条件ρ(E^s + E^aΠ(π)) < 1，该条件严格优于先前基于范数的条件；同时分析了具有可证明保证的局部块坐标策略改进框架，其性能保证直接与该光谱半径相关。

Conclusion: 局部性可视为策略依赖现象，平滑策略能在强耦合环境中诱导局部性，揭示了局部性与最优性之间的根本权衡。这为开发可扩展MARL算法提供了更具指导性的理论依据。

Abstract: Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP are often conservative, as they are based on worst-case, environment-only bounds (e.g., supremums over actions) and fail to capture the regularizing effect of the policy itself. In this work, we establish that locality can also be a \emph{policy-dependent} phenomenon. Our central contribution is a novel decomposition of the policy-induced interdependence matrix, $H^π$, which decouples the environment's sensitivity to state ($E^{\mathrm{s}}$) and action ($E^{\mathrm{a}}$) from the policy's sensitivity to state ($Π(π)$). This decomposition reveals that locality can be induced by a smooth policy (small $Π(π)$) even when the environment is strongly action-coupled, exposing a fundamental locality-optimality tradeoff. We use this framework to derive a general spectral condition $ρ(E^{\mathrm{s}}+E^{\mathrm{a}}Π(π)) < 1$ for exponential decay, which is strictly tighter than prior norm-based conditions. Finally, we leverage this theory to analyze a provably-sound localized block-coordinate policy improvement framework with guarantees tied directly to this spectral radius.

</details>


### [27] [Early-Warning Signals of Grokking via Loss-Landscape Geometry](https://arxiv.org/abs/2602.16967)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 本文研究了从记忆到泛化的突变现象"顿悟"(grokking)是否存在于模运算之外的序列学习任务中。作者发现 commutator defect（由非交换梯度更新导出的曲率度量）在泛化前显著上升，且提前量遵循超线性幂律。因果干预实验表明，增强非交换性可加速顿悟，而抑制正交梯度流则会延迟或阻止泛化，证明 commutator defect 是 transformer 中延迟泛化的通用、架构无关的早期预警信号。


<details>
  <summary>Details</summary>
Motivation: 顿悟现象已在模运算任务中被证实与低维执行流形相关，但其机制是否适用于其他任务仍是未解之谜。本研究旨在探索 commutator defect 是否作为跨任务顿悟现象的通用前兆指标。

Method: 研究采用两个序列学习基准测试：SCAN组合泛化和Dyck-1深度预测。通过测量训练过程中的 commutator defect 和权重空间PCA谱集中程度，并进行因果干预（增强非交换性或抑制正交梯度流）来验证其机制作用。

Result: 在两个任务中，commutator defect 均在泛化前上升，提前量服从超线性幂律（SCAN α≈1.18，Dyck α≈1.13）。谱集中并非普遍前兆，而 commutator defect 是。因果干预显示：增强非交换性使SCAN任务顿悟加速约32%，Dyck任务加速约50%；抑制正交梯度流在所有情况下均延迟或阻止顿悟。

Conclusion: commutator defect 是 transformer 延迟泛化的稳健、架构无关且具有因果关系的早期预警信号，在不同任务族中建立了顿悟的通用机制。

Abstract: Grokking -- the abrupt transition from memorization to generalization after prolonged training -- has been linked to confinement on low-dimensional execution manifolds in modular arithmetic. Whether this mechanism extends beyond arithmetic remains open. We study two sequence-learning benchmarks: SCAN compositional generalization and Dyck-1 depth prediction. Across both tasks and a wide range of learning rates, the commutator defect -- a curvature measure derived from non-commuting gradient updates -- rises well before generalization, with lead times following a superlinear power law (alpha approximately 1.18 for SCAN, approximately 1.13 for Dyck), consistent with prior results on modular arithmetic. Weight-space PCA reveals that spectral concentration is not a universal precursor; the commutator defect is. Causal interventions demonstrate a mechanistic role: amplifying non-commutativity accelerates grokking (roughly 32% on SCAN, roughly 50% on Dyck), while suppressing orthogonal gradient flow delays or prevents it. The three task families form a spectrum of causal sensitivity -- modular arithmetic is rigid, Dyck is responsive, SCAN is intermediate -- yet suppression delays or prevents grokking in all cases, establishing necessity as a universal finding. These results identify the commutator defect as a robust, architecture-agnostic, causally implicated early-warning signal for delayed generalization in transformers.

</details>


### [28] [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977)
*Zachary Coalson,Beth Sohler,Aiden Gabriel,Sanghyun Hong*

Main category: cs.LG

TL;DR: 该论文提出"失效关闭"对齐原则，通过渐进式对齐框架在LLM中构建多重独立的安全拒绝方向，解决现有"失效开启"机制易被 jailbreak 攻击突破的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的对齐机制存在结构性缺陷：现代拒绝机制是"失效开启"的，通过提示越狱攻击抑制单个主导特征即可导致对齐崩溃，产生不安全输出。

Method: 提出"失效关闭"对齐设计原则，具体实现为一个渐进式对齐框架：迭代地识别并消除先前学习到的拒绝方向，迫使模型在新的、独立的子空间中重建安全性。

Result: 在四种越狱攻击测试中实现了最强的整体鲁棒性，同时缓解了过度拒绝问题并保持生成质量，仅产生少量计算开销；机制分析确认模型编码了多个因果独立的拒绝方向。

Conclusion: 失效关闭对齐原则为鲁棒的LLM安全提供了理论框架，其方法创建的模型具有冗余、独立的安全机制，能有效抵御提示越狱攻击。

Abstract: We identify a structural weakness in current large language model (LLM) alignment: modern refusal mechanisms are fail-open. While existing approaches encode refusal behaviors across multiple latent features, suppressing a single dominant feature$-$via prompt-based jailbreaks$-$can cause alignment to collapse, leading to unsafe generation. Motivated by this, we propose fail-closed alignment as a design principle for robust LLM safety: refusal mechanisms should remain effective even under partial failures via redundant, independent causal pathways. We present a concrete instantiation of this principle: a progressive alignment framework that iteratively identifies and ablates previously learned refusal directions, forcing the model to reconstruct safety along new, independent subspaces. Across four jailbreak attacks, we achieve the strongest overall robustness while mitigating over-refusal and preserving generation quality, with small computational overhead. Our mechanistic analyses confirm that models trained with our method encode multiple, causally independent refusal directions that prompt-based jailbreaks cannot suppress simultaneously, providing empirical support for fail-closed alignment as a principled foundation for robust LLM safety.

</details>


### [29] [Discovering Universal Activation Directions for PII Leakage in Language Models](https://arxiv.org/abs/2602.16980)
*Leo Marchyok,Zachary Coalson,Sungho Keum,Sooel Son,Sanghyun Hong*

Main category: cs.LG

TL;DR: 本研究提出 UniLeak 框架，通过识别语言模型残差流中的通用激活方向，发现只需在推理时添加这些特定方向，就能持续提升模型生成个人身份信息（PII）的概率，且不影响生成质量。该方法无需训练数据或真实PII标签，仅依赖模型自生成文本，为PII泄露风险提供了新的视角和调控手段。


<details>
  <summary>Details</summary>
Motivation: 尽管现代语言模型展现出丰富的内部结构，但其隐藏状态中如何表示和调控隐私敏感行为（如个人身份信息PII泄露）仍鲜为人知。现有研究缺乏对PII泄露机制的系统性理解，难以在模型层面进行有效干预。

Method: 提出 UniLeak 机制解释性框架，通过分析模型自生成的文本，识别残差流中的通用激活方向。这些方向可在推理时通过线性添加，跨不同上下文一致地增加PII生成的可能性。该方法无需访问训练数据或真实PII标注。

Result: 在多个模型和数据集上，沿这些通用方向调控可显著增加PII泄露，效果优于现有基于提示的提取方法。这些方向对生成质量影响极小，且在各类上下文中具有泛化能力。

Conclusion: 研究揭示了PII泄露本质上是模型表示中的潜信号叠加现象，这种机制既可用于风险放大，也可用于风险缓解，为隐私保护提供了新的理论基础和技术路径。

Abstract: Modern language models exhibit rich internal structure, yet little is known about how privacy-sensitive behaviors, such as personally identifiable information (PII) leakage, are represented and modulated within their hidden states. We present UniLeak, a mechanistic-interpretability framework that identifies universal activation directions: latent directions in a model's residual stream whose linear addition at inference time consistently increases the likelihood of generating PII across prompts. These model-specific directions generalize across contexts and amplify PII generation probability, with minimal impact on generation quality. UniLeak recovers such directions without access to training data or groundtruth PII, relying only on self-generated text. Across multiple models and datasets, steering along these universal directions substantially increases PII leakage compared to existing prompt-based extraction methods. Our results offer a new perspective on PII leakage: the superposition of a latent signal in the model's representations, enabling both risk amplification and mitigation.

</details>


### [30] [Dynamic Delayed Tree Expansion For Improved Multi-Path Speculative Decoding](https://arxiv.org/abs/2602.16994)
*Rahul Thomas,Teo Kitanovski,Micah Goldblum,Arka Pal*

Main category: cs.LG

TL;DR: The paper proposes delayed tree expansion and a neural selector to improve speculative decoding, enabling OT-based methods to outperform Traversal Verification for the first time with 5% higher throughput across models and tasks.


<details>
  <summary>Details</summary>
Motivation: Prior work on speculative decoding's verification algorithms for i.i.d rollouts lacked systematic comparison under matched settings, leaving unclear why methods like Traversal Verification outperform OT-based approaches.

Method: 1) Systematically evaluate verification strategies across model families, tasks, and sampling regimes; 2) Propose delayed tree expansion that drafts a partial single path before i.i.d. branching; 3) Develop a dynamic neural selector that estimates OT methods' expected block efficiency from draft and target features to make context-dependent expansion decisions.

Result: 1) Traversal Verification dominates OT-based methods; 2) OT methods achieve high multi-token acceptance near the root, but gains are most impactful deeper where draft and target distributions diverge; 3) Delayed tree expansion preserves target distribution and improves root-node i.i.d rollouts; 4) Neural selector enables OT methods to outperform Traversal Verification, achieving 5% higher average throughput.

Conclusion: Delayed tree expansion combined with a neural selector provides a practical improvement to speculative decoding, allowing OT-based methods to surpass Traversal Verification across diverse settings while maintaining lossless sampling guarantees.

Abstract: Multi-path speculative decoding accelerates lossless sampling from a target model by using a cheaper draft model to generate a draft tree of tokens, and then applies a verification algorithm that accepts a subset of these. While prior work has proposed various verification algorithms for i.i.d rollouts, their relative performance under matched settings remains unclear. In this work, we firstly present a systematic evaluation of verification strategies across model families, tasks, and sampling regimes, and find that Traversal Verification dominates consistently, with OT-based methods lagging far behind. Our analysis uncovers that this occurs because OT-based methods achieve high multi-token acceptance near the root of the draft tree, while multi-token gains are most impactful deeper in the draft tree, where draft and target distributions diverge. Based on this insight, we propose delayed tree expansion, which drafts a partial single path, delaying the i.i.d. branching point. We show that delayed tree expansion preserves the target distribution and improves on root-node i.i.d rollouts. Further, we develop a dynamic neural selector that estimates the expected block efficiency of optimal-transport-based verification methods from draft and target features, enabling context-dependent expansion decisions. Our neural selector allows OT-based methods like SpecInfer to outperform Traversal Verification for the first time, achieving 5% higher average throughput across a wide range of models, datasets, and sampling settings.

</details>


### [31] [Action-Graph Policies: Learning Action Co-dependencies in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17009)
*Nikunj Gupta,James Zachary Hare,Jesse Milzman,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.LG

TL;DR: 提出Action Graph Policies (AGP)框架，通过建模智能体动作间的依赖关系并构建协调上下文，实现更优的去中心化决策，在部分可观测和抗协调惩罚任务中性能显著优于其他MARL方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中，成功的去中心化决策不仅需要个体良好动作，更需要选择相容动作以实现行为同步、避免冲突并满足全局约束。现有独立策略和集中式值分解方法在建模动作依赖性和实现协调行为方面存在局限。

Method: 提出Action Graph Policies (AGP)，通过构建动作依赖图并生成协调上下文，使智能体能够在决策时考虑全局动作依赖关系。该方法将依赖关系编码到策略中，支持相容动作的选择。

Result: 理论证明AGP比完全独立策略具有更强的表达能力，且能实现比集中式值分解方法贪心执行更优的协调联合动作。实验显示AGP在典型协调任务中达到80-95%成功率，远超其他MARL方法的10-25%，并在多样多智能体环境中持续优于基线。

Conclusion: AGP通过显式建模智能体动作依赖关系，显著提升了多智能体系统的协调决策能力，为去中心化协作提供了更有效的解决方案。

Abstract: Coordinating actions is the most fundamental form of cooperation in multi-agent reinforcement learning (MARL). Successful decentralized decision-making often depends not only on good individual actions, but on selecting compatible actions across agents to synchronize behavior, avoid conflicts, and satisfy global constraints. In this paper, we propose Action Graph Policies (AGP), that model dependencies among agents' available action choices. It constructs, what we call, \textit{coordination contexts}, that enable agents to condition their decisions on global action dependencies. Theoretically, we show that AGPs induce a strictly more expressive joint policy compared to fully independent policies and can realize coordinated joint actions that are provably more optimal than greedy execution even from centralized value-decomposition methods. Empirically, we show that AGP achieves 80-95\% success on canonical coordination tasks with partial observability and anti-coordination penalties, where other MARL methods reach only 10-25\%. We further demonstrate that AGP consistently outperforms these baselines in diverse multi-agent environments.

</details>


### [32] [Malliavin Calculus as Stochastic Backpropogation](https://arxiv.org/abs/2602.17013)
*Kevin D. Oden*

Main category: cs.LG

TL;DR: 提出了一个统一的Malliavin微积分框架，将路径微分和得分函数梯度估计器统一，并开发了自适应混合估计器，在VAE上实现9%方差缩减，在合成问题上达35%，同时揭示了非平稳优化场景下的挑战。


<details>
  <summary>Details</summary>
Motivation: 建立路径微分（重参数化）和得分函数（Malliavin）梯度估计器之间的严格理论联系，通过统一的视角理解随机反向传播，并开发能够自适应结合两者优势的低方差梯度估计方法。

Method: 揭示两种估计器均源于Malliavin分部积分恒等式，基于此等价性提出方差感知的混合估计器，利用经验协方差结构自适应融合路径微分和Malliavin梯度，并提供闭式有限样本收敛界。

Result: 该混合估计器在所有无偏线性组合中达到最小方差；在CIFAR-10 VAE上实现9%方差缩减，在强耦合合成问题上最高达35%缩减；但策略梯度实验显示非平稳优化场景对混合方法构成挑战。

Conclusion: Malliavin微积分为随机梯度估计提供了概念统一且实践可解释的框架，明确了混合方法的适用边界和未来研究方向。

Abstract: We establish a rigorous connection between pathwise (reparameterization) and score-function (Malliavin) gradient estimators by showing that both arise from the Malliavin integration-by-parts identity. Building on this equivalence, we introduce a unified and variance-aware hybrid estimator that adaptively combines pathwise and Malliavin gradients using their empirical covariance structure. The resulting formulation provides a principled understanding of stochastic backpropagation and achieves minimum variance among all unbiased linear combinations, with closed-form finite-sample convergence bounds. We demonstrate 9% variance reduction on VAEs (CIFAR-10) and up to 35% on strongly-coupled synthetic problems. Exploratory policy gradient experiments reveal that non-stationary optimization landscapes present challenges for the hybrid approach, highlighting important directions for future work. Overall, this work positions Malliavin calculus as a conceptually unifying and practically interpretable framework for stochastic gradient estimation, clarifying when hybrid approaches provide tangible benefits and when they face inherent limitations.

</details>


### [33] [WS-GRPO: Weakly-Supervised Group-Relative Policy Optimization for Rollout-Efficient Reasoning](https://arxiv.org/abs/2602.17025)
*Gagan Mundada,Zihan Huang,Rohan Surana,Sheldon Yu,Jennifer Yuntong Zhang,Xintong Li,Tong Yu,Lina Yao,Jingbo Shang,Julian McAuley,Junda Wu*

Main category: cs.LG

TL;DR: WS-GRPO通过从结果正确性训练的偏好模型，为部分轨迹提供继续/停止信号，减少冗余计算，同时保持准确性，从而改进语言模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: 本文针对GRPO在语言模型推理中存在的扩展deliberation和过度思考导致的效率低下问题。现有长度惩罚难以校准，可能截断有用推理；同时，除最终答案正确性外，缺乏直接指示何时继续或停止的监督信号，使得正确性与rollout效率的权衡难以控制。

Method: 提出的WS-GRPO方法仅使用结果正确性（终端奖励）训练偏好模型，生成长度信号，指示何时继续推理是有益的。这将终端奖励转换为对部分轨迹的正确性感知指导，提供无需显式步骤级标签的继续/停止监督。

Result: 论文提供理论结果和实证证据，证明WS-GRPO在推理基准测试中大幅减少rollout长度，同时保持与GRPO基线相当的竞争力。

Conclusion: WS-GRPO通过利用从最终答案正确性导出的弱监督偏好信号，有效减少语言模型推理中的冗余deliberation，为推理任务中正确性与效率的权衡提供了实用解决方案。

Abstract: Group Relative Policy Optimization (GRPO) is effective for training language models on complex reasoning. However, since the objective is defined relative to a group of sampled trajectories, extended deliberation can create more chances to realize relative gains, leading to inefficient reasoning and overthinking, and complicating the trade-off between correctness and rollout efficiency. Controlling this behavior is difficult in practice, considering (i) Length penalties are hard to calibrate because longer rollouts may reflect harder problems that require longer reasoning, penalizing tokens risks truncating useful reasoning along with redundant continuation; and (ii) supervision that directly indicates when to continue or stop is typically unavailable beyond final answer correctness. We propose Weakly Supervised GRPO (WS-GRPO), which improves rollout efficiency by converting terminal rewards into correctness-aware guidance over partial trajectories. Unlike global length penalties that are hard to calibrate, WS-GRPO trains a preference model from outcome-only correctness to produce prefix-level signals that indicate when additional continuation is beneficial. Thus, WS-GRPO supplies outcome-derived continue/stop guidance, reducing redundant deliberation while maintaining accuracy. We provide theoretical results and empirically show on reasoning benchmarks that WS-GRPO substantially reduces rollout length while remaining competitive with GRPO baselines.

</details>


### [34] [Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods](https://arxiv.org/abs/2602.17027)
*Paimon Goulart,Jordan Steinhauser,Dawon Ahn,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: An AI-enhanced pipeline using In-Context Learning and improved tensor decomposition to accelerate behavioral neuroscience research on fear generalization in mice, enabling domain experts to focus on insights rather than technical pipeline issues, with experimental validation showing superior performance.


<details>
  <summary>Details</summary>
Motivation: Transform complex, rigid, time-consuming scientific discovery pipelines by leveraging AI so domain experts can concentrate on interpreting findings instead of debugging pipelines or manual data annotation, specifically applied to studying fear generalization in mice to advance PTSD understanding.

Method: Proposes an AI-enhanced pipeline using In-Context Learning (ICL) as a user-friendly interface for domain experts, combined with novel AI-enhanced tensor decomposition for pattern discovery from heterogeneous data, evaluated experimentally against standard practices and non-ICL ML baselines.

Result: Demonstrates remarkable ICL efficacy in data preparation and pattern interpretation, shows superior performance versus domain standards and non-ICL baselines, and achieves domain-expert-validated effective discoveries.

Conclusion: The AI-enhanced pipeline successfully makes scientific discovery more accessible and seamless for domain experts while maintaining or improving performance, bridging the gap between AI capabilities and practical domain applications.

Abstract: Scientific discovery pipelines typically involve complex, rigid, and time-consuming processes, from data preparation to analyzing and interpreting findings. Recent advances in AI have the potential to transform such pipelines in a way that domain experts can focus on interpreting and understanding findings, rather than debugging rigid pipelines or manually annotating data. As part of an active collaboration between data science/AI researchers and behavioral neuroscientists, we showcase an example AI-enhanced pipeline, specifically designed to transform and accelerate the way that the domain experts in the team are able to gain insights out of experimental data. The application at hand is in the domain of behavioral neuroscience, studying fear generalization in mice, an important problem whose progress can advance our understanding of clinically significant and often debilitating conditions such as PTSD (Post-Traumatic Stress Disorder). We identify the emerging paradigm of "In-Context Learning" (ICL) as a suitable interface for domain experts to automate parts of their pipeline without the need for or familiarity with AI model training and fine-tuning, and showcase its remarkable efficacy in data preparation and pattern interpretation. Also, we introduce novel AI-enhancements to tensor decomposition model, which allows for more seamless pattern discovery from the heterogeneous data in our application. We thoroughly evaluate our proposed pipeline experimentally, showcasing its superior performance compared to what is standard practice in the domain, as well as against reasonable ML baselines that do not fall under the ICL paradigm, to ensure that we are not compromising performance in our quest for a seamless and easy-to-use interface for domain experts. Finally, we demonstrate effective discovery, with results validated by the domain experts in the team.

</details>


### [35] [Multi-Probe Zero Collision Hash (MPZCH): Mitigating Embedding Collisions and Enhancing Model Freshness in Large-Scale Recommenders](https://arxiv.org/abs/2602.17050)
*Ziliang Zhao,Bi Xue,Emma Lin,Mengjiao Zhou,Kaustubh Vartak,Shakhzod Ali-Zade,Carson Lu,Tao Li,Bin Kuang,Rui Jian,Bin Wen,Dennis van der Staay,Yixin Bao,Eddy Li,Chao Deng,Songbin Liu,Qifan Wang,Kai Ren*

Main category: cs.LG

TL;DR: 提出MPZCH机制解决推荐系统中嵌入表哈希碰撞问题，通过线性探测和主动淘汰策略实现零碰撞，同时保持生产效率，已在TorchRec开源。


<details>
  <summary>Details</summary>
Motivation: 大规模推荐系统的嵌入表随着唯一ID数量增长，传统哈希索引出现碰撞，导致模型性能和个性化质量下降。

Method: 采用基于线性探测的Multi-Probe Zero Collision Hash (MPZCH)机制，利用辅助张量和CUDA内核实现可配置探测和主动淘汰策略，通过淘汰过时ID和重置槽位避免陈旧嵌入继承。

Result: 在合理表大小下基本消除碰撞，保持与现有方法相当的训练QPS和推理延迟，实现用户嵌入零碰撞并显著提升项目嵌入新鲜度和质量。

Conclusion: MPZCH有效解决了大规模嵌入表碰撞问题，平衡了性能与效果，已在开源TorchRec库中发布供社区使用。

Abstract: Embedding tables are critical components of large-scale recommendation systems, facilitating the efficient mapping of high-cardinality categorical features into dense vector representations. However, as the volume of unique IDs expands, traditional hash-based indexing methods suffer from collisions that degrade model performance and personalization quality. We present Multi-Probe Zero Collision Hash (MPZCH), a novel indexing mechanism based on linear probing that effectively mitigates embedding collisions. With reasonable table sizing, it often eliminates these collisions entirely while maintaining production-scale efficiency. MPZCH utilizes auxiliary tensors and high-performance CUDA kernels to implement configurable probing and active eviction policies. By retiring obsolete IDs and resetting reassigned slots, MPZCH prevents the stale embedding inheritance typical of hash-based methods, ensuring new features learn effectively from scratch. Despite its collision-mitigation overhead, the system maintains training QPS and inference latency comparable to existing methods. Rigorous online experiments demonstrate that MPZCH achieves zero collisions for user embeddings and significantly improves item embedding freshness and quality. The solution has been released within the open-source TorchRec library for the broader community.

</details>


### [36] [Sign Lock-In: Randomly Initialized Weight Signs Persist and Bottleneck Sub-Bit Model Compression](https://arxiv.org/abs/2602.17063)
*Akira Sakai,Yuma Ichikawa*

Main category: cs.LG

TL;DR: 针对子比特压缩中符号位瓶颈，研究发现符号模式随机性源于初始化而非训练，提出符号锁定理论，并设计间隙初始化与外漂正则化器，将符号翻转率降至10⁻³，仅增加1点困惑度。


<details>
  <summary>Details</summary>
Motivation: 在子比特模型压缩中，当权重幅值被高度压缩后，符号位成为固定成本瓶颈，且其随机性行为机制不明确，限制了进一步压缩效率。

Method: 通过跨架构实证研究，发现符号模式主要继承自初始化；建立符号锁定理论，对SGD噪声下的符号翻转进行停时分析；提出间隙初始化方法和轻量级外漂正则化器。

Result: 在限定更新和稀有再进入条件下，符号翻转呈现几何尾部特征；新方法将有效翻转率降低至约10⁻³，同时仅造成约1点困惑度的性能损失。

Conclusion: 符号模式的随机性主要由初始化决定，基于此机制的符号锁定理论及其实用技术为突破子比特压缩中的符号位瓶颈提供了有效解决方案。

Abstract: Sub-bit model compression seeks storage below one bit per weight; as magnitudes are aggressively compressed, the sign bit becomes a fixed-cost bottleneck. Across Transformers, CNNs, and MLPs, learned sign matrices resist low-rank approximation and are spectrally indistinguishable from an i.i.d. Rademacher baseline. Despite this apparent randomness, most weights retain their initialization signs; flips primarily occur via rare near-zero boundary crossings, suggesting that sign-pattern randomness is largely inherited from initialization. We formalize this behavior with sign lock-in theory, a stopping-time analysis of sign flips under SGD noise. Under bounded updates and a rare re-entry condition into a small neighborhood around zero, the number of effective sign flips exhibits a geometric tail. Building on this mechanism, we introduce a gap-based initialization and a lightweight outward-drift regularizer, reducing the effective flip rate to approximately $10^{-3}$ with only about a one-point increase in perplexity.

</details>


### [37] [Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control](https://arxiv.org/abs/2602.17068)
*Xiaocai Zhang,Neema Nassir,Milad Haghani*

Main category: cs.LG

TL;DR: This paper proposes STDSH-MARL, a novel multi-agent reinforcement learning framework for human-centric traffic signal control that uses spatio-temporal hypergraph attention to prioritize public transportation while improving overall traffic performance.


<details>
  <summary>Details</summary>
Motivation: Traditional traffic signal control focuses on vehicle-centric metrics, but modern corridor networks require accounting for multimodal travelers, particularly high-occupancy public transportation, to achieve human-centric traffic management.

Method: The STDSH-MARL framework employs centralized training and decentralized execution, using a dual-stage hypergraph attention mechanism to model spatio-temporal dependencies and a hybrid discrete action space to jointly optimize signal phase configuration and green duration.

Result: Experiments on a corridor network demonstrate consistent improvements in multimodal performance and public transportation priority, with superior overall performance compared to state-of-the-art baselines. Ablation studies show temporal hyperedges are the most influential factor.

Conclusion: The proposed approach provides an effective and scalable solution for human-centric traffic signal control that successfully balances the needs of various transportation modes while prioritizing public transit.

Abstract: Human-centric traffic signal control in corridor networks must increasingly account for multimodal travelers, particularly high-occupancy public transportation, rather than focusing solely on vehicle-centric performance. This paper proposes STDSH-MARL (Spatio-Temporal Dual-Stage Hypergraph based Multi-Agent Reinforcement Learning), a scalable multi-agent deep reinforcement learning framework that follows a centralized training and decentralized execution paradigm. The proposed method captures spatio-temporal dependencies through a novel dual-stage hypergraph attention mechanism that models interactions across both spatial and temporal hyperedges. In addition, a hybrid discrete action space is introduced to jointly determine the next signal phase configuration and its corresponding green duration, enabling more adaptive signal timing decisions. Experiments conducted on a corridor network under five traffic scenarios demonstrate that STDSH-MARL consistently improves multimodal performance and provides clear benefits for public transportation priority. Compared with state-of-the-art baseline methods, the proposed approach achieves superior overall performance. Further ablation studies confirm the contribution of each component of STDSH-MARL, with temporal hyperedges identified as the most influential factor driving the observed performance gains.

</details>


### [38] [Adam Improves Muon: Adaptive Moment Estimation with Orthogonalized Momentum](https://arxiv.org/abs/2602.17080)
*Minxin Zhang,Yuxuan Liu,Hayden Scheaffer*

Main category: cs.LG

TL;DR: Proposes NAMO and NAMO-D optimizers that combine orthogonalized momentum with Adam-type noise adaptation. NAMO uses a single adaptive stepsize; NAMO-D adds a diagonal matrix for neuron-wise adaptation. Both show optimal convergence and outperform AdamW/Muon in GPT-2 pretraining, with NAMO-D achieving further gains.


<details>
  <summary>Details</summary>
Motivation: While Muon successfully uses orthogonalized momentum for LLM training, there is no principled integration with Adam's norm-based noise adaptation mechanism. The paper aims to bridge this gap by creating optimizers that preserve orthogonality while adapting to stochastic gradient noise.

Method: NAMO scales orthogonalized momentum using a single adaptive stepsize to preserve orthogonality. NAMO-D extends this by right-multiplying orthogonalized momentum with a diagonal matrix featuring clamped entries, enabling per-neuron noise adaptation aligned with the near block-diagonal Hessian structure.

Result: Theoretical: Both algorithms achieve optimal convergence rates in deterministic settings and stochastic convergence guarantees that adapt to gradient noise levels. Experimental: On GPT-2 pretraining, NAMO and NAMO-D outperform AdamW and Muon baselines, with NAMO-D achieving additional improvements via a clamping hyperparameter.

Conclusion: The principled integration of orthogonalized momentum with norm-based noise adaptation yields effective optimizers that theoretically converge optimally and practically surpass state-of-the-art methods in large language model training, with NAMO-D providing enhanced performance through neuron-wise adaptation.

Abstract: Efficient stochastic optimization typically integrates an update direction that performs well in the deterministic regime with a mechanism adapting to stochastic perturbations. While Adam uses adaptive moment estimates to promote stability, Muon utilizes the weight layers' matrix structure via orthogonalized momentum, showing superior performance in large language model training. We propose a new optimizer and a diagonal extension, NAMO and NAMO-D, providing the first principled integration of orthogonalized momentum with norm-based Adam-type noise adaptation. NAMO scales orthogonalized momentum using a single adaptive stepsize, preserving orthogonality while improving upon Muon at negligible additional cost. NAMO-D instead right-multiplies orthogonalized momentum by a diagonal matrix with clamped entries. This design enables neuron-wise noise adaptation and aligns with the common near block-diagonal Hessian structure. Under standard assumptions, we establish optimal convergence rates for both algorithms in the deterministic setting and show that, in the stochastic setting, their convergence guarantees adapt to the noise level of stochastic gradients. Experiments on pretraining GPT-2 models demonstrate improved performance of both NAMO and NAMO-D compared to the AdamW and Muon baselines, with NAMO-D achieving further gains over NAMO via an additional clamping hyperparameter that balances the competing goals of maintaining a well-conditioned update direction and leveraging fine-grained noise adaptation.

</details>


### [39] [MeGU: Machine-Guided Unlearning with Target Feature Disentanglement](https://arxiv.org/abs/2602.17088)
*Haoyu Wang,Zhuo Huang,Xiaolong Wang,Bo Han,Zhiwei Lin,Tongliang Liu*

Main category: cs.LG

TL;DR: 本文发现预训练中学习的语义类概念在特征层面存在纠缠，限制了现有机器遗忘效果。为此提出MeGU框架，利用多模态大语言模型引导概念感知的重对齐，通过正负噪声对实现选择性遗忘，有效平衡遗忘完整性与模型效用。


<details>
  <summary>Details</summary>
Motivation: 随着对训练数据隐私的日益关注，"被遗忘权"成为关键需求，从而催生了对有效机器遗忘方法的需求。然而现有方法普遍面临根本性权衡：激进地擦除目标数据会损害模型在保留数据上的效用，而保守策略则无法彻底消除目标信息残留。

Method: 提出机器引导遗忘（MeGU）框架：1）利用多模态大语言模型为样本分配语义扰动标签，显式确定重对齐方向；2）将模型估计的类间概念相似性编码为轻量级转移矩阵以提高效率；3）引入正负特征噪声对，在微调时负向噪声抑制目标特定特征模式，正向噪声强化剩余关联特征并使其与扰动概念对齐。

Result: MeGU实现了可控且选择性的遗忘，有效缓解了欠遗忘（残留目标信息）和过遗忘（损害保留数据效用）问题。

Conclusion: 通过协调设计实现目标特定表示的选择性破坏，同时保持共享语义结构，MeGU为解决机器遗忘的根本性权衡提供了有效方案。

Abstract: The growing concern over training data privacy has elevated the "Right to be Forgotten" into a critical requirement, thereby raising the demand for effective Machine Unlearning. However, existing unlearning approaches commonly suffer from a fundamental trade-off: aggressively erasing the influence of target data often degrades model utility on retained data, while conservative strategies leave residual target information intact. In this work, the intrinsic representation properties learned during model pretraining are analyzed. It is demonstrated that semantic class concepts are entangled at the feature-pattern level, sharing associated features while preserving concept-specific discriminative components. This entanglement fundamentally limits the effectiveness of existing unlearning paradigms. Motivated by this insight, we propose Machine-Guided Unlearning (MeGU), a novel framework that guides unlearning through concept-aware re-alignment. Specifically, Multi-modal Large Language Models (MLLMs) are leveraged to explicitly determine re-alignment directions for target samples by assigning semantically meaningful perturbing labels. To improve efficiency, inter-class conceptual similarities estimated by the MLLM are encoded into a lightweight transition matrix. Furthermore, MeGU introduces a positive-negative feature noise pair to explicitly disentangle target concept influence. During finetuning, the negative noise suppresses target-specific feature patterns, while the positive noise reinforces remaining associated features and aligns them with perturbing concepts. This coordinated design enables selective disruption of target-specific representations while preserving shared semantic structures. As a result, MeGU enables controlled and selective forgetting, effectively mitigating both under-unlearning and over-unlearning.

</details>


### [40] [A Locality Radius Framework for Understanding Relational Inductive Bias in Database Learning](https://arxiv.org/abs/2602.17092)
*Aadi Joshi,Kavya Bhand*

Main category: cs.LG

TL;DR: This paper introduces "locality radius" to measure the minimum structural neighborhood needed for relational schema predictions, discovering that GNN performance critically depends on aligning model aggregation depth with task locality radius across various database tasks.


<details>
  <summary>Details</summary>
Motivation: While GNNs are widely used for foreign key discovery and schema-level predictions assuming relational inductive bias helps, it remains unclear when multi-hop structural reasoning is actually necessary for these tasks.

Method: Controlled empirical study across five relational schema tasks (foreign key prediction, join cost estimation, blast radius regression, cascade impact classification, and graph-derived schema tasks) using multi-seed experiments, capacity-matched comparisons, statistical significance testing, scaling analysis, and synthetic benchmarks with controlled locality radius.

Result: A consistent bias-radius alignment effect was observed: model performance depends critically on the alignment between task locality radius and architectural aggregation depth.

Conclusion: The study reveals that GNN architectures must be matched to task locality characteristics, providing a principled way to determine when multi-hop reasoning is beneficial versus unnecessary for relational schema prediction tasks.

Abstract: Foreign key discovery and related schema-level prediction tasks are often modeled using graph neural networks (GNNs), implicitly assuming that relational inductive bias improves performance. However, it remains unclear when multi-hop structural reasoning is actually necessary. In this work, we introduce locality radius, a formal measure of the minimum structural neighborhood required to determine a prediction in relational schemas. We hypothesize that model performance depends critically on alignment between task locality radius and architectural aggregation depth. We conduct a controlled empirical study across foreign key prediction, join cost estimation, blast radius regression, cascade impact classification, and additional graph-derived schema tasks. Our evaluation includes multi-seed experiments, capacity-matched comparisons, statistical significance testing, scaling analysis, and synthetic radius-controlled benchmarks. Results reveal a consistent bias-radius alignment effect.

</details>


### [41] [FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and Procrustes Alignment](https://arxiv.org/abs/2602.17095)
*Chuiyang Meng,Ming Tang,Vincent W. S. Wong*

Main category: cs.LG

TL;DR: FLoRG is a federated fine-tuning framework that uses a single low-rank matrix and Gram matrix aggregation to eliminate aggregation errors and decomposition drift, achieving better accuracy and up to 2041× lower communication overhead than LoRA-based federated learning methods.


<details>
  <summary>Details</summary>
Motivation: Current federated fine-tuning with LoRA faces two key challenges: (1) errors from separately aggregating two low-rank matrices, and (2) non-unique matrix decomposition causing drift when aggregating the product. There is a need to eliminate these issues while maintaining parameter efficiency and privacy preservation.

Method: The authors propose FLoRG which employs: (1) a single low-rank matrix instead of two for fine-tuning, (2) aggregation of its Gram matrix to avoid aggregation errors, (3) Procrustes alignment to align decomposed matrices between rounds to minimize decomposition drift, and (4) theoretical convergence analysis.

Result: FLoRG theoretically achieves a tighter convergence bound with Procrustes alignment. Empirically, it outperforms five state-of-the-art baselines in downstream task accuracy and reduces communication overhead by up to 2041×.

Conclusion: FLoRG successfully addresses aggregation and decomposition drift challenges in federated LoRA fine-tuning, delivering superior performance and extreme communication efficiency, making it a practical solution for privacy-preserving large language model adaptation.

Abstract: Parameter-efficient fine-tuning techniques such as low-rank adaptation (LoRA) enable large language models (LLMs) to adapt to downstream tasks efficiently. Federated learning (FL) further facilitates this process by enabling collaborative fine-tuning across distributed clients without sharing private data. However, the use of two separate low-rank matrices in LoRA for federated fine-tuning introduces two types of challenges. The first challenge arises from the error induced by separately aggregating those two low-rank matrices. The second challenge occurs even when the product of two low-rank matrices is aggregated. The server needs to recover factors via matrix decomposition, which is non-unique and can introduce decomposition drift. To tackle the aforementioned challenges, we propose FLoRG, a federated fine-tuning framework which employs a single low-rank matrix for fine-tuning and aggregates its Gram matrix (i.e., the matrix of inner products of its column vectors), eliminating the aggregation error while also reducing the communication overhead. FLoRG minimizes the decomposition drift by introducing a Procrustes alignment approach which aligns the decomposed matrix between consecutive fine-tuning rounds for consistent updates. We theoretically analyze the convergence of FLoRG and prove that adopting the Procrustes alignment results in a tighter convergence bound. Experimental results across multiple LLM fine-tuning benchmarks demonstrate that FLoRG outperforms five state-of-the-art baseline schemes in the downstream task accuracy and can reduce the communication overhead by up to 2041$\times$.

</details>


### [42] [Operationalization of Machine Learning with Serverless Architecture: An Industrial Operationalization of Machine Learning with Serverless Architecture: An Industrial Implementation for Harmonized System Code Prediction](https://arxiv.org/abs/2602.17102)
*Sai Vineeth Kandappareddigari,Santhoshkumar Jagadish,Gauri Verma,Ilhuicamina Contreras,Christopher Dignam,Anmol Srivastava,Benjamin Demers*

Main category: cs.LG

TL;DR: 提出一个无服务器MLOps框架，通过事件驱动管道实现ML全生命周期管理；在HS编码预测工业场景中验证，Text-CNN模型达98%准确率，兼顾成本效率与可审计性，提供可扩展的ML工业化蓝图


<details>
  <summary>Details</summary>
Motivation: 全球贸易中HS编码分类错误导致货物延误和财务损失，面临产品描述短文本、无结构化、更新频繁的挑战，需高准确率、可审计且成本可控的自动化解决方案

Method: 基于无服务器架构的事件驱动MLOps框架：采用标准化接口支持多模型，集成自动化A/B测试；使用Text-CNN深度学习模型处理短文本分类，优先确定性延迟而非复杂模型

Result: 工业部署实现98%准确率（Text-CNN模型），支持自动扩缩容保障SLA；自动化流水线确保可复现性与审计追踪；Transformer虽可达同等精度但长期运维成本显著更高

Conclusion: 验证无服务器架构可经济高效地工业化ML应用，提供可复用的ML全生命周期管理模板，平衡性能与成本，适用于需高合规性场景

Abstract: This paper presents a serverless MLOps framework orchestrating the complete ML lifecycle from data ingestion, training, deployment, monitoring, and retraining to using event-driven pipelines and managed services. The architecture is model-agnostic, supporting diverse inference patterns through standardized interfaces, enabling rapid adaptation without infrastructure overhead. We demonstrate practical applicability through an industrial implementation for Harmonized System (HS) code prediction, a compliance-critical task where short, unstructured product descriptions are mapped to standardized codes used by customs authorities in global trade. Frequent updates and ambiguous descriptions make classification challenging, with errors causing shipment delays and financial losses. Our solution uses a custom text embedding encoder and multiple deep learning architectures, with Text-CNN achieving 98 percent accuracy on ground truth data. Beyond accuracy, the pipeline ensures reproducibility, auditability, and SLA adherence under variable loads via auto-scaling. A key feature is automated A/B testing, enabling dynamic model selection and safe promotion in production. Cost-efficiency drives model choice; while transformers may achieve similar accuracy, their long-term operational costs are significantly higher. Deterministic classification with predictable latency and explainability is prioritized, though the architecture remains extensible to transformer variants and LLM-based inference. The paper first introduces the deep learning architectures with simulations and model comparisons, then discusses industrialization through serverless architecture, demonstrating automated retraining, prediction, and validation of HS codes. This work provides a replicable blueprint for operationalizing ML using serverless architecture, enabling enterprises to scale while optimizing performance and economics.

</details>


### [43] [Online Learning with Improving Agents: Multiclass, Budgeted Agents and Bandit Learners](https://arxiv.org/abs/2602.17103)
*Sajad Ashkezari,Shai Ben-David*

Main category: cs.LG

TL;DR: 该研究扩展了"带改进的学习"模型，通过组合维度刻画在线学习性，并分析多类别、强盗反馈及改进成本等问题。


<details>
  <summary>Details</summary>
Motivation: 研究智能体如何通过微调特征值以获得更优标签的学习模型，理解其在真实场景中的主动改进能力。

Method: 采用组合维度理论方法，系统分析多类别学习、强盗反馈学习以及智能体改进成本建模等问题。

Result: 给出了该模型下在线学习性的组合维度特征，分析了多类别和强盗反馈场景的学习性，建立了智能体改进成本模型。

Conclusion: 该工作通过组合维度等方法，全面刻画了带改进学习模型的在线学习性，为理解智能体主动改进行为提供了理论框架。

Abstract: We investigate the recently introduced model of learning with improvements, where agents are allowed to make small changes to their feature values to be warranted a more desirable label. We extensively extend previously published results by providing combinatorial dimensions that characterize online learnability in this model, by analyzing the multiclass setup, learnability in a bandit feedback setup, modeling agents' cost for making improvements and more.

</details>


### [44] [i-PhysGaussian: Implicit Physical Simulation for 3D Gaussian Splatting](https://arxiv.org/abs/2602.17117)
*Yicheng Cao,Zhuo Huang,Yu Yao,Yiming Ying,Daoyi Dong,Tongliang Liu*

Main category: cs.LG

TL;DR: i-PhysGaussian框架将3D高斯溅射与隐式物质点法结合，通过隐式牛顿优化求解动量平衡残差，实现时间步长高达20倍于显式方法的稳定物理仿真


<details>
  <summary>Details</summary>
Motivation: 现有基于3D重建的模拟器依赖显式逐步更新，对时间步长敏感，在高刚度材料或准静态运动等复杂场景下精度快速下降

Method: 提出i-PhysGaussian框架，耦合3D高斯溅射(3DGS)与隐式物质点法(MPM)积分器，通过GMRES求解器进行隐式牛顿型优化，最小化动量平衡残差以获得步末状态

Result: 在复杂动态过渡中保持结构一致性和平滑运动，时间步长可达显式基线的20倍，显著降低时间步敏感性

Conclusion: 隐式公式显著降低时间步敏感性并确保物理一致性，在挑战性仿真场景中表现出优于显式方法的性能

Abstract: Physical simulation predicts future states of objects based on material properties and external loads, enabling blueprints for both Industry and Engineering to conduct risk management. Current 3D reconstruction-based simulators typically rely on explicit, step-wise updates, which are sensitive to step time and suffer from rapid accuracy degradation under complicated scenarios, such as high-stiffness materials or quasi-static movement. To address this, we introduce i-PhysGaussian, a framework that couples 3D Gaussian Splatting (3DGS) with an implicit Material Point Method (MPM) integrator. Unlike explicit methods, our solution obtains an end-of-step state by minimizing a momentum-balance residual through implicit Newton-type optimization with a GMRES solver. This formulation significantly reduces time-step sensitivity and ensures physical consistency. Our results demonstrate that i-PhysGaussian maintains stability at up to 20x larger time steps than explicit baselines, preserving structural coherence and smooth motion even in complex dynamic transitions.

</details>


### [45] [TIFO: Time-Invariant Frequency Operator for Stationarity-Aware Representation Learning in Time Series](https://arxiv.org/abs/2602.17122)
*Xihao Piao,Zheng Chen,Lingwei Zhu,Yushun Dong,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 针对非平稳时间序列的分布偏移问题，提出频域不变算子TIFO，通过学**平稳频率权重缓解分布偏移，在28个设置中取得18个第一，计算成本降低60%-70%。


<details>
  <summary>Details</summary>
Motivation: 非平稳时间序列预测存在训练/测试数据分布差异问题。现有方法仅从单样本去除低阶矩，无法捕捉跨样本的时间演化结构和复杂时间结构。

Method: 提出TIFO（时间不变频率算子），在频域空间考虑所有时间结构，学**全数据集的平稳性感知频率权重，突出平稳成分、抑制非平稳成分。该方法是即插即用的。

Result: 在28个预测设置中获得18个第一、6个第二。在ETTm2数据集上平均MSE提升33.3%和55.3%，计算成本降低60%-70%，具有强可扩展性。

Conclusion: TIFO能有效缓解分布偏移，性能显著优于基线方法，计算高效且可灵活集成到各类预测模型中。

Abstract: Nonstationary time series forecasting suffers from the distribution shift issue due to the different distributions that produce the training and test data. Existing methods attempt to alleviate the dependence by, e.g., removing low-order moments from each individual sample. These solutions fail to capture the underlying time-evolving structure across samples and do not model the complex time structure. In this paper, we aim to address the distribution shift in the frequency space by considering all possible time structures. To this end, we propose a Time-Invariant Frequency Operator (TIFO), which learns stationarity-aware weights over the frequency spectrum across the entire dataset. The weight representation highlights stationary frequency components while suppressing non-stationary ones, thereby mitigating the distribution shift issue in time series. To justify our method, we show that the Fourier transform of time series data implicitly induces eigen-decomposition in the frequency space. TIFO is a plug-and-play approach that can be seamlessly integrated into various forecasting models. Experiments demonstrate our method achieves 18 top-1 and 6 top-2 results out of 28 forecasting settings. Notably, it yields 33.3% and 55.3% improvements in average MSE on the ETTm2 dataset. In addition, TIFO reduces computational costs by 60% -70% compared to baseline methods, demonstrating strong scalability across diverse forecasting models.

</details>


### [46] [VP-VAE: Rethinking Vector Quantization via Adaptive Vector Perturbation](https://arxiv.org/abs/2602.17133)
*Linwei Zhai,Han Ding,Mingzhi Lin,Cui Zhao,Fei Wang,Ge Wang,Wang Zhi,Wei Xi*

Main category: cs.LG

TL;DR: Proposing VP-VAE, a novel paradigm that replaces explicit codebooks with latent space perturbations to decouple representation learning from discretization, enabling stable training while improving reconstruction fidelity and token usage balance


<details>
  <summary>Details</summary>
Motivation: VQ-VAEs suffer from training instability and 'codebook collapse' due to the coupling of representation learning and discrete codebook optimization

Method: Replaces non-differentiable quantizer with distribution-consistent and scale-adaptive latent perturbations generated via Metropolis-Hastings sampling; derives FSP variant under uniform latent assumption

Result: Improves reconstruction fidelity and achieves substantially more balanced token usage while avoiding instability inherent to coupled codebook training

Conclusion: The decoupling approach provides stable training without codebooks and offers a unified theoretical explanation for fixed quantizers like FSQ

Abstract: Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental to modern generative modeling, yet they often suffer from training instability and "codebook collapse" due to the inherent coupling of representation learning and discrete codebook optimization. In this paper, we propose VP-VAE (Vector Perturbation VAE), a novel paradigm that decouples representation learning from discretization by eliminating the need for an explicit codebook during training. Our key insight is that, from the neural network's viewpoint, performing quantization primarily manifests as injecting a structured perturbation in latent space. Accordingly, VP-VAE replaces the non-differentiable quantizer with distribution-consistent and scale-adaptive latent perturbations generated via Metropolis--Hastings sampling. This design enables stable training without a codebook while making the model robust to inference-time quantization error. Moreover, under the assumption of approximately uniform latent variables, we derive FSP (Finite Scalar Perturbation), a lightweight variant of VP-VAE that provides a unified theoretical explanation and a practical improvement for FSQ-style fixed quantizers. Extensive experiments on image and audio benchmarks demonstrate that VP-VAE and FSP improve reconstruction fidelity and achieve substantially more balanced token usage, while avoiding the instability inherent to coupled codebook training.

</details>


### [47] [TimeOmni-VL: Unified Models for Time Series Understanding and Generation](https://arxiv.org/abs/2602.17149)
*Tong Guan,Sheng Pan,Johan Barthelemy,Zhao Li,Yujun Cai,Cesare Alippi,Ming Jin,Shirui Pan*

Main category: cs.LG

TL;DR: TimeOmni-VL通过双向时序列-图像映射和基于理解引导的生成，首次实现视觉为中心的统一多模态框架，显著提升时间序列的语义理解和数值精度


<details>
  <summary>Details</summary>
Motivation: 时间序列建模存在数值生成与语义理解的分歧：生成模型依赖表面模式匹配，理解模型难以输出高保真数值。视觉领域虽有统一多模态模型，但在时间序列上潜力未发掘

Method: 提出TimeOmni-VL框架：1) 保真双向时序列-图像映射(Bi-TSI)实现近乎无损的相互转换；2) 理解引导生成，引入TSUMM-Suite数据集，通过校准思维链将时间序列理解作为显式控制信号

Result: 实验证实该统一方法显著改善语义理解与数值精度，为多模态时间序列建模建立新范式

Conclusion: 开创性地将视觉多模态理念引入时间序列领域，首次实现生成与理解的统一，为未来时间序列建模开辟新方向

Abstract: Recent time series modeling faces a sharp divide between numerical generation and semantic understanding, with research showing that generation models often rely on superficial pattern matching, while understanding-oriented models struggle with high-fidelity numerical output. Although unified multimodal models (UMMs) have bridged this gap in vision, their potential for time series remains untapped. We propose TimeOmni-VL, the first vision-centric framework that unifies time series understanding and generation through two key innovations: (1) Fidelity-preserving bidirectional mapping between time series and images (Bi-TSI), which advances Time Series-to-Image (TS2I) and Image-to-Time Series (I2TS) conversions to ensure near-lossless transformations. (2) Understanding-guided generation. We introduce TSUMM-Suite, a novel dataset consists of six understanding tasks rooted in time series analytics that are coupled with two generation tasks. With a calibrated Chain-of-Thought, TimeOmni-VL is the first to leverage time series understanding as an explicit control signal for high-fidelity generation. Experiments confirm that this unified approach significantly improves both semantic understanding and numerical precision, establishing a new frontier for multimodal time series modeling.

</details>


### [48] [Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization](https://arxiv.org/abs/2602.17155)
*Yicheng Lang,Changsheng Wang,Yihua Zhang,Mingyi Hong,Zheng Zhang,Wotao Yin,Sijia Liu*

Main category: cs.LG

TL;DR: ZO-Muon通过融合子空间投影和Muon光谱优化，显著提升了零阶优化的收敛速度和效率，在LLM和ViT微调任务上仅需MeZO 24.7%的查询量且准确率提升25.1%。


<details>
  <summary>Details</summary>
Motivation: 零阶优化虽能避免反向传播实现内存高效的模型微调，但存在精度与查询效率的根本性矛盾，亟需改进。

Method: 提出子空间梯度正交化统一框架，结合低秩结构投影降低梯度估计方差和Muon式梯度正交化提取光谱信息，实现为ZO-Muon方法。

Result: 在LLM和ViT实验中，ZO-Muon收敛更快，仅需MeZO 24.7%的查询量即可达到相同SST-2性能，ViT-B在CIFAR-100上准确率提升25.1%。

Conclusion: 该框架有效解决了ZO优化的效率-精度权衡问题，ZO-Muon在准确率和查询/运行效率上实现双赢改进。

Abstract: Zeroth-order (ZO) optimization provides a gradient-free alternative to first-order (FO) methods by estimating gradients via finite differences of function evaluations, and has recently emerged as a memory-efficient paradigm for fine-tuning large-scale models by avoiding backpropagation. However, ZO optimization has a fundamental tension between accuracy and query efficiency. In this work, we show that ZO optimization can be substantially improved by unifying two complementary principles: (i) a projection-based subspace view that reduces gradient estimation variance by exploiting the intrinsic low-rank structure of model updates, and (ii) Muon-style spectral optimization that applies gradient orthogonalization to extract informative spectral structure from noisy ZO gradients. These findings form a unified framework of subspace gradient orthogonalization, which we instantiate in a new method, ZO-Muon, admitting a natural interpretation as a low-rank Muon optimizer in the ZO setting. Extensive experiments on large language models (LLMs) and vision transformers (ViTs) demonstrate that ZO-Muon significantly accelerates convergence and achieves a win-win improvement in accuracy and query/runtime efficiency. Notably, compared to the popular MeZO baseline, ZO-Muon requires only 24.7% of the queries to reach the same SST-2 performance for LLM fine-tuning, and improves accuracy by 25.1% on ViT-B fine-tuning on CIFAR-100.

</details>


### [49] [In-Context Learning in Linear vs. Quadratic Attention Models: An Empirical Study on Regression Tasks](https://arxiv.org/abs/2602.17171)
*Ayush Goel,Arjun Kohli,Sarvagya Somvanshi*

Main category: cs.LG

TL;DR: 实证比较标准注意力与线性注意力机制在线性回归任务中的上下文学习能力差异


<details>
  <summary>Details</summary>
Motivation: 探究标准注意力（二次复杂度）与线性注意力机制在相同线性回归任务中的上下文学习行为差异

Method: 在Garg等人提出的线性回归任务上，评估两种架构的学习质量（MSE）、收敛性和泛化行为，并分析模型深度对性能的影响

Result: 揭示了两种注意力机制在上下文学习中的相似性与局限性

Conclusion: 线性注意力在上下文学习性能上存在与标准注意力相比的特定限制

Abstract: Recent work has demonstrated that transformers and linear attention models can perform in-context learning (ICL) on simple function classes, such as linear regression. In this paper, we empirically study how these two attention mechanisms differ in their ICL behavior on the canonical linear-regression task of Garg et al. We evaluate learning quality (MSE), convergence, and generalization behavior of each architecture. We also analyze how increasing model depth affects ICL performance. Our results illustrate both the similarities and limitations of linear attention relative to quadratic attention in this setting.

</details>


### [50] [Continual uncertainty learning](https://arxiv.org/abs/2602.17174)
*Heisei Yonezawa,Ansei Yonezawa,Itsuro Kajiwara*

Main category: cs.LG

TL;DR: 提出一种课程式持续学习框架，通过将多不确定性机械系统控制问题分解为时序任务，逐步扩展动态不确定性集合，结合模型基控制器作为共享基线，实现无灾难性遗忘的稳定策略更新，并成功应用于汽车动力系统振动控制，验证了鲁棒性与sim-to-real迁移能力。


<details>
  <summary>Details</summary>
Motivation: 机械系统多不确定性鲁棒控制面临挑战，深度强化学习虽可缓解sim-to-real鸿沟，但同时处理所有不确定性会导致次优策略和低学习效率，亟需更高效稳定的学习方法。

Method: 构建课程式持续学习框架：将多源不确定性控制问题分解为序列任务；将原系统扩展为有限植物集合，其动态不确定性随学习进程逐步扩展；跨植物集稳定更新策略避免灾难性遗忘；联合模型基控制器提供共享基线性能以加速收敛；采用残差学习机制使DRL智能体针对每项不确定性进行任务特异性优化。

Result: 在汽车动力系统主动振动控制器设计中验证了所提方法，控制器对结构非线性和动态变化具有鲁棒性，实现了成功的sim-to-real迁移。

Conclusion: 该框架通过时序任务分解与稳定学习机制有效解决了多不确定性机械系统控制问题，相比同时处理所有不确定性的方法，具有更优的样本效率和鲁棒性，具备工业应用价值。

Abstract: Robust control of mechanical systems with multiple uncertainties remains a fundamental challenge, particularly when nonlinear dynamics and operating-condition variations are intricately intertwined. While deep reinforcement learning (DRL) combined with domain randomization has shown promise in mitigating the sim-to-real gap, simultaneously handling all sources of uncertainty often leads to sub-optimal policies and poor learning efficiency. This study formulates a new curriculum-based continual learning framework for robust control problems involving nonlinear dynamical systems in which multiple sources of uncertainty are simultaneously superimposed. The key idea is to decompose a complex control problem with multiple uncertainties into a sequence of continual learning tasks, in which strategies for handling each uncertainty are acquired sequentially. The original system is extended into a finite set of plants whose dynamic uncertainties are gradually expanded and diversified as learning progresses. The policy is stably updated across the entire plant sets associated with tasks defined by different uncertainty configurations without catastrophic forgetting. To ensure learning efficiency, we jointly incorporate a model-based controller (MBC), which guarantees a shared baseline performance across the plant sets, into the learning process to accelerate the convergence. This residual learning scheme facilitates task-specific optimization of the DRL agent for each uncertainty, thereby enhancing sample efficiency. As a practical industrial application, this study applies the proposed method to designing an active vibration controller for automotive powertrains. We verified that the resulting controller is robust against structural nonlinearities and dynamic variations, realizing successful sim-to-real transfer.

</details>


### [51] [SoftDTW-CUDA-Torch: Memory-Efficient GPU-Accelerated Soft Dynamic Time Warping for PyTorch](https://arxiv.org/abs/2602.17206)
*Ron Shapira Weber,Oren Freifeld*

Main category: cs.LG

TL;DR: 本文介绍了一个名为softdtw-cuda-torch的PyTorch库，用于在GPU上计算Soft Dynamic Time Warping。该库通过三种创新方法解决了现有实现的三个关键限制：序列长度限制、数值不稳定性和内存消耗问题，实现了高达98%的内存减少。


<details>
  <summary>Details</summary>
Motivation: 现有的GPU实现SoftDTW存在三个关键限制：序列长度被限制在1024、小平滑参数下反向传播存在数值不稳定性，以及生成成对距离张量导致GPU内存消耗过大。这些限制阻碍了SoftDTW在长序列和大规模应用中的使用。

Method: 作者提出了三种技术解决方案：(1) 分块对角线核执行策略，移除序列长度限制；(2) 对数空间反向传播算法，防止浮点溢出；(3) 融合距离计算机制，消除O(BN M)的中间距离张量。

Result: 与之前的工作相比，该实现最高可减少98%的内存消耗。库支持任意序列长度、完整的PyTorch自动微分集成，以及Soft-DTW重心计算。

Conclusion: 该开源库显著提升了SoftDTW在GPU上的可扩展性和稳定性，为时间序列分析提供了高效的工具。

Abstract: We present softdtw-cuda-torch, an open-source PyTorch library for computing Soft Dynamic Time Warping (SoftDTW) on GPUs. Our implementation addresses three key limitations of existing GPU implementations of SoftDTW: a hard sequence-length cap of 1024, numerical instability in the backward pass for small smoothing parameters, and excessive GPU memory consumption from materializing pairwise distance tensors. We introduce (1) tiled anti-diagonal kernel execution that removes the sequence-length constraint, (2) a log-space back-ward pass that prevents floating-point overflow, and (3) a fused distance-computation mode that eliminates the O(BN M ) intermediate distance tensor, achieving up to 98% memory reduction compared to prior work. The library supports arbitrary sequence lengths, full PyTorch autograd integration, and Soft-DTW Barycenter computation. Code is available at https://github.com/BGU-CS-VIL/sdtw-cuda-torch.

</details>


### [52] [Learning a Latent Pulse Shape Interface for Photoinjector Laser Systems](https://arxiv.org/abs/2602.17263)
*Alexander Klemps,Denis Ilia,Pradeep Kr. Banerjee,Ye Chen,Henrik Tünnermann,Nihat Ay*

Main category: cs.LG

TL;DR: 提出基于Wasserstein自编码器的生成式建模框架，替代传统激光脉冲传播模拟，实现可解释的脉冲形状-电子束动力学潜在空间映射


<details>
  <summary>Details</summary>
Motivation: 自由电子激光器光阴极注入器中纵向激光脉冲形状控制对优化电子束质量至关重要，但现有暴力模拟方法计算成本过高，限制系统探索效率

Method: 采用Wasserstein自编码器构建可微分潜在空间接口，连接脉冲整形参数与下游束流动力学，通过生成式建模学习脉冲-束流映射关系

Result: 学习到连续可解释的潜在空间：高阶高斯脉冲族呈相干轨迹，脉冲时长标准化与能量相关；主成分分析与高斯混合模型显示规则几何结构，支持脉冲类型平滑插值；模型从模拟数据泛化到实验测量，高精度重建脉冲并嵌入流形

Conclusion: 显著降低对昂贵脉冲传播模拟的依赖，为束流动力学仿真分析提供高效框架，实现脉冲形状优化与束流质量提升的闭环设计

Abstract: Controlling the longitudinal laser pulse shape in photoinjectors of Free-Electron Lasers is a powerful lever for optimizing electron beam quality, but systematic exploration of the vast design space is limited by the cost of brute-force pulse propagation simulations. We present a generative modeling framework based on Wasserstein Autoencoders to learn a differentiable latent interface between pulse shaping and downstream beam dynamics. Our empirical findings show that the learned latent space is continuous and interpretable while maintaining high-fidelity reconstructions. Pulse families such as higher-order Gaussians trace coherent trajectories, while standardizing the temporal pulse lengths shows a latent organization correlated with pulse energy. Analysis via principal components and Gaussian Mixture Models reveals a well behaved latent geometry, enabling smooth transitions between distinct pulse types via linear interpolation. The model generalizes from simulated data to real experimental pulse measurements, accurately reconstructing pulses and embedding them consistently into the learned manifold. Overall, the approach reduces reliance on expensive pulse-propagation simulations and facilitates downstream beam dynamics simulation and analysis.

</details>


### [53] [Unified Latents (UL): How to train your latents](https://arxiv.org/abs/2602.17270)
*Jonathan Heek,Emiel Hoogeboom,Thomas Mensink,Tim Salimans*

Main category: cs.LG

TL;DR: Unified Latents (UL) framework learns latent representations jointly regularized by a diffusion prior and decoded by a diffusion model, achieving competitive image generation (FID 1.4 on ImageNet-512) and state-of-the-art video generation (FVD 1.3 on Kinetics-600) with fewer training FLOPs.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework for learning latent representations that leverage diffusion priors for regularization and diffusion models for decoding, while providing a tight upper bound on latent bitrate and maintaining computational efficiency.

Method: Proposes Unified Latents (UL) that links the encoder's output noise to the diffusion prior's minimum noise level, creating a simple training objective bounding latent bitrate, with a jointly regularized encoder and diffusion decoder.

Result: On ImageNet-512: FID of 1.4 with high reconstruction PSNR and fewer training FLOPs than Stable Diffusion baselines. On Kinetics-600: achieves state-of-the-art FVD of 1.3.

Conclusion: UL demonstrates that jointly regularizing latent representations with a diffusion prior yields highly compact and high-quality latents that enable efficient training and superior performance across both image and video domains.

Abstract: We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model. By linking the encoder's output noise to the prior's minimum noise level, we obtain a simple training objective that provides a tight upper bound on the latent bitrate. On ImageNet-512, our approach achieves competitive FID of 1.4, with high reconstruction quality (PSNR) while requiring fewer training FLOPs than models trained on Stable Diffusion latents. On Kinetics-600, we set a new state-of-the-art FVD of 1.3.

</details>


### [54] [RLGT: A reinforcement learning framework for extremal graph theory](https://arxiv.org/abs/2602.17276)
*Ivan Damnjanović,Uroš Milivojević,Irena Đorđević,Dragan Stevanović*

Main category: cs.LG

TL;DR: 本文提出RLGT，一个新型强化学习框架，用于系统化先前在极值图论中使用RL的工作，支持多种图类型并优化计算性能。


<details>
  <summary>Details</summary>
Motivation: Wagner开创性地将深度交叉熵强化学习应用于极值图论问题后，研究者创建了多种图论专用RL环境，解决了包括拉普拉斯谱半径不等式、拉姆齐数下界、禁止3-4圈的Turán型极值问题等。但现有工作缺乏统一框架，需建立系统化方法以促进未来研究。

Method: 作者开发了RLGT框架，采用高效图表示方法，支持无向/有向图、含环/无环图及任意边着色，具备简洁模块化设计。

Result: 成功构建了RLGT框架，系统化整合了先前工作，提供通用图支持并实现计算性能优化。

Conclusion: RLGT旨在通过其模块化设计和高效实现，为未来基于强化学习的极值图论研究提供便利。

Abstract: Reinforcement learning (RL) is a subfield of machine learning that focuses on developing models that can autonomously learn optimal decision-making strategies over time. In a recent pioneering paper, Wagner demonstrated how the Deep Cross-Entropy RL method can be applied to tackle various problems from extremal graph theory by reformulating them as combinatorial optimization problems. Subsequently, many researchers became interested in refining and extending the framework introduced by Wagner, thereby creating various RL environments specialized for graph theory. Moreover, a number of problems from extremal graph theory were solved through the use of RL. In particular, several inequalities concerning the Laplacian spectral radius of graphs were refuted, new lower bounds were obtained for certain Ramsey numbers, and contributions were made to the Turán-type extremal problem in which the forbidden structures are cycles of length three and four. Here, we present Reinforcement Learning for Graph Theory (RLGT), a novel RL framework that systematizes the previous work and provides support for both undirected and directed graphs, with or without loops, and with an arbitrary number of edge colors. The framework efficiently represents graphs and aims to facilitate future RL-based research in extremal graph theory through optimized computational performance and a clean and modular design.

</details>


### [55] [Efficient privacy loss accounting for subsampling and random allocation](https://arxiv.org/abs/2602.17284)
*Vitaly Feldman,Moshe Shenfeld*

Main category: cs.LG

TL;DR: 提出随机分配采样方案的隐私损失分布(PLD)高效计算方法，证明其在高斯机制下隐私-效用权衡优于或等于泊松采样，特别适用于DP-SGD训练，并开发了基于PLD实现的新隐私会计工具。


<details>
  <summary>Details</summary>
Motivation: 现有随机分配采样分析存在两大缺陷：1) 实际场景中隐私参数因近似分析不紧；2) 计算的参数（叉形/雷尼散度）在隐私会计中引入额外开销，亟需更精确的隐私损失量化方法。

Method: 1) 建立随机分配下任意差分隐私算法的隐私损失分布(PLD)高效计算框架；2) 提出"PLD实现"新概念，开发通用隐私会计工具，避免针对特定噪声机制的手动分析。

Result: 1) 高斯机制中随机分配的隐私-效用权衡至少不劣于泊松采样；2) 随机分配特别适合DP-SGD训练；3) 新会计工具可扩展至需手动分析的采样场景。

Conclusion: 通过精确量化隐私损失分布，随机分配采样在理论和实践中均优于传统泊松采样，为差分隐私机器学习提供了更高效的采样方案与通用会计方法。

Abstract: We consider the privacy amplification properties of a sampling scheme in which a user's data is used in $k$ steps chosen randomly and uniformly from a sequence (or set) of $t$ steps. This sampling scheme has been recently applied in the context of differentially private optimization (Chua et al., 2024a; Choquette-Choo et al., 2025) and communication-efficient high-dimensional private aggregation (Asi et al., 2025), where it was shown to have utility advantages over the standard Poisson sampling. Theoretical analyses of this sampling scheme (Feldman & Shenfeld, 2025; Dong et al., 2025) lead to bounds that are close to those of Poisson sampling, yet still have two significant shortcomings. First, in many practical settings, the resulting privacy parameters are not tight due to the approximation steps in the analysis. Second, the computed parameters are either the hockey stick or Renyi divergence, both of which introduce overheads when used in privacy loss accounting.
  In this work, we demonstrate that the privacy loss distribution (PLD) of random allocation applied to any differentially private algorithm can be computed efficiently. When applied to the Gaussian mechanism, our results demonstrate that the privacy-utility trade-off for random allocation is at least as good as that of Poisson subsampling. In particular, random allocation is better suited for training via DP-SGD. To support these computations, our work develops new tools for general privacy loss accounting based on a notion of PLD realization. This notion allows us to extend accurate privacy loss accounting to subsampling which previously required manual noise-mechanism-specific analysis.

</details>


### [56] [Flickering Multi-Armed Bandits](https://arxiv.org/abs/2602.17315)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 本文提出了闪烁多臂赌博机（FMAB）框架，其中臂的可得性会随选择历史动态变化，并通过随机图过程建模。提出了一种两阶段算法：先通过懒惰随机游走进行探索，再通过导航与利用阶段进行开发。在两种随机图模型下均建立了次线性遗憾界，并证明了探索成本的近最优性。


<details>
  <summary>Details</summary>
Motivation: 传统多臂赌博机假设臂集固定不变，这在动态环境中不现实。本研究针对约束性、演化的臂可得性问题，特别是智能体移动受限于局部邻域的场景（如机器人导航），填补了现有研究的空白。

Method: 使用随机图过程（Erdős-Rényi和边马尔可夫过程）建模，将臂作为节点，智能体移动限制在局部邻域。提出两阶段算法：懒惰随机游走探索阶段和导航利用阶段，并建立高概率遗憾界与信息论下界。

Result: 在两种图模型下均获得高概率和期望次线性遗憾界。通过匹配的下界证明探索成本近最优，揭示了局部移动约束下探索的基本成本。数值模拟（包括机器人灾情侦察场景）验证了理论结果。

Conclusion: FMAB框架有效解决了动态臂可得性与局部移动约束问题，所提算法实现了近最优性能，表明探索成本与图连通性和局部移动限制存在根本关联。

Abstract: We introduce Flickering Multi-Armed Bandits (FMAB), a new MAB framework where the set of available arms (or actions) can change at each round, and the available set at any time may depend on the agent's previously selected arm. We model this constrained, evolving availability using random graph processes, where arms are nodes and the agent's movement is restricted to its local neighborhood. We analyze this problem under two random graph models: an i.i.d. Erdős--Rényi (ER) process and an Edge-Markovian process. We propose and analyze a two-phase algorithm that employs a lazy random walk for exploration to efficiently identify the optimal arm, followed by a navigation and commitment phase for exploitation. We establish high-probability and expected sublinear regret bounds for both graph settings. We show that the exploration cost of our algorithm is near-optimal by establishing a matching information-theoretic lower bound for this problem class, highlighting the fundamental cost of exploration under local-move constraints. We complement our theoretical guarantees with numerical simulations, including a scenario of a robotic ground vehicle scouting a disaster-affected region.

</details>


### [57] [The Sound of Death: Deep Learning Reveals Vascular Damage from Carotid Ultrasound](https://arxiv.org/abs/2602.17321)
*Christoph Balada,Aida Romano-Martinez,Payal Varshney,Vincent ten Cate,Katharina Geschke,Jonas Tesarz,Paul Claßen,Alexander K. Schuster,Dativa Tibyampansha,Karl-Patrik Kresoja,Philipp S. Wild,Sheraz Ahmed,Andreas Dengel*

Main category: cs.LG

TL;DR: A machine learning framework extracts vascular damage from carotid ultrasound videos using hypertension as a weak label, enabling scalable cardiovascular risk assessment that matches or outperforms conventional models.


<details>
  <summary>Details</summary>
Motivation: Cardiovascular diseases are the leading global cause of mortality, but early detection is limited by current diagnostics; carotid ultrasound contains untapped rich structural and hemodynamic information for risk stratification.

Method: ML framework that analyzes carotid ultrasound videos to extract clinically meaningful vascular damage representations, using hypertension as weak supervision and explainable AI for interpretability.

Result: High vascular damage score strongly associates with CVD risk factors and outcomes, stratifying myocardial infarction/cardiac death/all-cause mortality comparably to SCORE2, while revealing novel vessel morphology and perivascular tissue signatures.

Conclusion: Routine carotid ultrasound contains unrecognized prognostic value; this non-invasive, cost-effective tool enables population-wide cardiovascular risk assessment and earlier personalized prevention without lab tests or complex clinical inputs.

Abstract: Cardiovascular diseases (CVDs) remain the leading cause of mortality worldwide, yet early risk detection is often limited by available diagnostics. Carotid ultrasound, a non-invasive and widely accessible modality, encodes rich structural and hemodynamic information that is largely untapped. Here, we present a machine learning (ML) framework that extracts clinically meaningful representations of vascular damage (VD) from carotid ultrasound videos, using hypertension as a weak proxy label. The model learns robust features that are biologically plausible, interpretable, and strongly associated with established cardiovascular risk factors, comorbidities, and laboratory measures. High VD stratifies individuals for myocardial infarction, cardiac death, and all-cause mortality, matching or outperforming conventional risk models such as SCORE2. Explainable AI analyses reveal that the model relies on vessel morphology and perivascular tissue characteristics, uncovering novel functional and anatomical signatures of vascular damage. This work demonstrates that routine carotid ultrasound contains far more prognostic information than previously recognized. Our approach provides a scalable, non-invasive, and cost-effective tool for population-wide cardiovascular risk assessment, enabling earlier and more personalized prevention strategies without reliance on laboratory tests or complex clinical inputs.

</details>


### [58] [SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework](https://arxiv.org/abs/2602.17330)
*Rong Fu,Zijian Zhang,Wenxin Zhang,Kun Liu,Jiekai Wu,Xianda Li,Simon Fong*

Main category: cs.LG

TL;DR: SubQuad是一个端到端的分析适应性免疫组库的流程，通过结合抗原感知的近亚二次检索、GPU加速亲和力核、学习多模态融合和公平约束聚类，在降低计算成本的同时解决数据集不平衡问题，保护重要的稀有克隆型。


<details>
  <summary>Details</summary>
Motivation: 适应性免疫组库的群体规模比较分析面临两大瓶颈：近乎二次方成本的成对亲和力评估和数据集不平衡掩盖了临床重要的少数克隆型。

Method: 提出SubQuad，结合抗原感知的近亚二次检索、GPU加速亲和力核、学习多模态融合和公平约束聚类，采用紧凑MinHash预过滤大幅减少候选比较，使用可微分门控模块自适应加权对齐和嵌入通道，以及自动校准确保稀有抗原特异性亚群的比例代表性。

Result: 在大规模和肿瘤组库上，SubQuad提高了吞吐量和内存效率，同时保持或改善了召回率@k、聚类纯度和亚群公平性。

Conclusion: SubQuad通过协同设计索引、相似性融合和公平感知目标，为免疫组库挖掘和疫苗靶点优先级排序、生物标志物发现等转化任务提供了可扩展、无偏倚的平台。

Abstract: Comparative analysis of adaptive immune repertoires at population scale is hampered by two practical bottlenecks: the near-quadratic cost of pairwise affinity evaluations and dataset imbalances that obscure clinically important minority clonotypes. We introduce SubQuad, an end-to-end pipeline that addresses these challenges by combining antigen-aware, near-subquadratic retrieval with GPU-accelerated affinity kernels, learned multimodal fusion, and fairness-constrained clustering. The system employs compact MinHash prefiltering to sharply reduce candidate comparisons, a differentiable gating module that adaptively weights complementary alignment and embedding channels on a per-pair basis, and an automated calibration routine that enforces proportional representation of rare antigen-specific subgroups. On large viral and tumor repertoires SubQuad achieves measured gains in throughput and peak memory usage while preserving or improving recall@k, cluster purity, and subgroup equity. By co-designing indexing, similarity fusion, and equity-aware objectives, SubQuad offers a scalable, bias-aware platform for repertoire mining and downstream translational tasks such as vaccine target prioritization and biomarker discovery.

</details>


### [59] [From Subtle to Significant: Prompt-Driven Self-Improving Optimization in Test-Time Graph OOD Detection](https://arxiv.org/abs/2602.17342)
*Luzhi Wang,Xuanshuo Fu,He Zhang,Chuang Liu,Xiaobao Wang,Hongbo Liu*

Main category: cs.LG

TL;DR: 提出SIGOOD框架解决图分布外检测问题，通过自改进循环和能量优化提示，在21个数据集上实现最优性能


<details>
  <summary>Details</summary>
Motivation: 现有图OOD检测方法采用单次推理范式，无法逐步修正错误预测和放大OOD信号，限制了检测可靠性

Method: 构建自改进图OOD检测器：1) 生成提示增强图放大OOD信号 2) 设计能量偏好优化损失 3) 通过自改进循环迭代优化提示

Result: 在21个真实世界数据集上全面验证有效性，性能显著优于现有方法

Conclusion: SIGOOD成功实现无监督图OOD检测，通过持续自学习和测试时训练解决了单次推理的局限性，为开放世界GNN部署提供可靠方案

Abstract: Graph Out-of-Distribution (OOD) detection aims to identify whether a test graph deviates from the distribution of graphs observed during training, which is critical for ensuring the reliability of Graph Neural Networks (GNNs) when deployed in open-world scenarios. Recent advances in graph OOD detection have focused on test-time training techniques that facilitate OOD detection without accessing potential supervisory information (e.g., training data). However, most of these methods employ a one-pass inference paradigm, which prevents them from progressively correcting erroneous predictions to amplify OOD signals. To this end, we propose a \textbf{S}elf-\textbf{I}mproving \textbf{G}raph \textbf{O}ut-\textbf{o}f-\textbf{D}istribution detector (SIGOOD), which is an unsupervised framework that integrates continuous self-learning with test-time training for effective graph OOD detection. Specifically, SIGOOD generates a prompt to construct a prompt-enhanced graph that amplifies potential OOD signals. To optimize prompts, SIGOOD introduces an Energy Preference Optimization (EPO) loss, which leverages energy variations between the original test graph and the prompt-enhanced graph. By iteratively optimizing the prompt by involving it into the detection model in a self-improving loop, the resulting optimal prompt-enhanced graph is ultimately used for OOD detection. Comprehensive evaluations on 21 real-world datasets confirm the effectiveness and outperformance of our SIGOOD method. The code is at https://github.com/Ee1s/SIGOOD.

</details>


### [60] [2Mamba2Furious: Linear in Complexity, Competitive in Accuracy](https://arxiv.org/abs/2602.17363)
*Gabriel Mongaras,Eric C. Larson*

Main category: cs.LG

TL;DR: 改进Mamba-2的A-mask和隐藏状态阶数，提出2Mamba，在长上下文下实现近似softmax注意力的精度且内存效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 线性注意力计算高效但精度较低，需缩小其与softmax注意力的精度差距。

Method: 先简化Mamba-2为Mamba-2S，再优化A-mask和增加隐藏状态阶数得到2Mamba，并探索超越softmax注意力的要素。

Result: 2Mamba在长上下文下精度接近softmax注意力，内存效率更高，且部分情况下可超越softmax注意力。

Conclusion: 该方法有效平衡了精度与效率，代码已开源。

Abstract: Linear attention transformers have become a strong alternative to softmax attention due to their efficiency. However, linear attention tends to be less expressive and results in reduced accuracy compared to softmax attention. To bridge the accuracy gap between softmax attention and linear attention, we manipulate Mamba-2, a very strong linear attention variant. We first simplify Mamba-2 down to its most fundamental and important components, evaluating which specific choices make it most accurate. From this simplified Mamba variant (Mamba-2S), we improve the A-mask and increase the order of the hidden state, resulting in a method, which we call 2Mamba, that is nearly as accurate as softmax attention, yet much more memory efficient for long context lengths. We also investigate elements to Mamba-2 that help surpass softmax attention accuracy. Code is provided for all our experiments

</details>


### [61] [A feature-stable and explainable machine learning framework for trustworthy decision-making under incomplete clinical data](https://arxiv.org/abs/2602.17364)
*Justyna Andrys-Olek,Paulina Tworek,Luca Gherardini,Mark W. Ruddock,Mary Jo Kurt,Peter Fitzgerald,Jose Sousa*

Main category: cs.LG

TL;DR: 提出CACTUS可解释机器学习框架，解决生物医学小样本、异构和不完整数据集的特征不稳定问题，在血尿队列中验证其预测性能与特征稳定性优于随机森林和梯度提升方法。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域高利害决策中机器学习应用受限，主要因模型鲁棒性差、可解释性有限，且关键特征在数据缺失等扰动下不稳定，影响可重复性和决策可信度。

Method: 开发CACTUS框架，整合特征抽象、可解释分类和系统性的特征稳定性分析，使用568例血尿患者真实世界队列，在可控缺失数据条件下与随机森林、梯度提升等常用方法进行基准测试。

Result: CACTUS在预测性能上具有竞争力或更优，且在数据缺失增加时显著保持更高特征稳定性，包括在性别分层分析中；特征稳定性为传统性能指标提供互补信息。

Conclusion: 特征稳定性是评估生物医学机器学习模型可信度的关键指标；CACTUS通过量化对缺失数据的鲁棒性并优先考虑可解释的稳定特征，为可信数据驱动决策支持提供了通用框架。

Abstract: Machine learning models are increasingly applied to biomedical data, yet their adoption in high stakes domains remains limited by poor robustness, limited interpretability, and instability of learned features under realistic data perturbations, such as missingness. In particular, models that achieve high predictive performance may still fail to inspire trust if their key features fluctuate when data completeness changes, undermining reproducibility and downstream decision-making. Here, we present CACTUS (Comprehensive Abstraction and Classification Tool for Uncovering Structures), an explainable machine learning framework explicitly designed to address these challenges in small, heterogeneous, and incomplete clinical datasets. CACTUS integrates feature abstraction, interpretable classification, and systematic feature stability analysis to quantify how consistently informative features are preserved as data quality degrades. Using a real-world haematuria cohort comprising 568 patients evaluated for bladder cancer, we benchmark CACTUS against widely used machine learning approaches, including random forests and gradient boosting methods, under controlled levels of randomly introduced missing data. We demonstrate that CACTUS achieves competitive or superior predictive performance while maintaining markedly higher stability of top-ranked features as missingness increases, including in sex-stratified analyses. Our results show that feature stability provides information complementary to conventional performance metrics and is essential for assessing the trustworthiness of machine learning models applied to biomedical data. By explicitly quantifying robustness to missing data and prioritising interpretable, stable features, CACTUS offers a generalizable framework for trustworthy data-driven decision support.

</details>


### [62] [Variational Grey-Box Dynamics Matching](https://arxiv.org/abs/2602.17477)
*Gurjeet Sangra Singh,Frantzeska Lavda,Giangiacomo Mercatali,Alexandros Kalousis*

Main category: cs.LG

TL;DR: Proposes a grey-box method combining incomplete physics models with flow matching generative models, using dual latent encodings to learn dynamics from observations without ground-truth parameters, avoiding Neural ODE limitations while preserving interpretability.


<details>
  <summary>Details</summary>
Motivation: Deep generative models act as black-boxes neglecting physics, while interpretable physics-based ODE/PDE models often have missing/unknown terms. The paper aims to bridge this gap by integrating incomplete physics into generative frameworks.

Method: Novel grey-box approach that learns dynamics from observational trajectories alone using structured variational flow matching with two latent encodings: one for missing stochasticity/multi-modal velocity, another for physics parameters with physics-informed prior. Simulation-free to avoid Neural ODE scalability/stability issues. Includes adaptation for second-order dynamics.

Result: Experiments on ODE/PDE problems show performance on par with or superior to fully data-driven and previous grey-box methods, while preserving physics model interpretability.

Conclusion: Successfully bridges interpretable physics models and powerful generative models, learning dynamics effectively from observations while maintaining physics interpretability.

Abstract: Deep generative models such as flow matching and diffusion models have shown great potential in learning complex distributions and dynamical systems, but often act as black-boxes, neglecting underlying physics. In contrast, physics-based simulation models described by ODEs/PDEs remain interpretable, but may have missing or unknown terms, unable to fully describe real-world observations. We bridge this gap with a novel grey-box method that integrates incomplete physics models directly into generative models. Our approach learns dynamics from observational trajectories alone, without ground-truth physics parameters, in a simulation-free manner that avoids scalability and stability issues of Neural ODEs. The core of our method lies in modelling a structured variational distribution within the flow matching framework, by using two latent encodings: one to model the missing stochasticity and multi-modal velocity, and a second to encode physics parameters as a latent variable with a physics-informed prior. Furthermore, we present an adaptation of the framework to handle second-order dynamics. Our experiments on representative ODE/PDE problems show that our method performs on par with or superior to fully data-driven approaches and previous grey-box baselines, while preserving the interpretability of the physics model. Our code is available at https://github.com/DMML-Geneva/VGB-DM.

</details>


### [63] [Linear Convergence in Games with Delayed Feedback via Extra Prediction](https://arxiv.org/abs/2602.17486)
*Yuma Fujimoto,Kenshi Abe,Kaito Ariu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Feedback delays are inevitable in real-world multi-agent learning. They are known to severely degrade performance, and the convergence rate under delayed feedback is still unclear, even for bilinear games. This paper derives the rate of linear convergence of Weighted Optimistic Gradient Descent-Ascent (WOGDA), which predicts future rewards with extra optimism, in unconstrained bilinear games. To analyze the algorithm, we interpret it as an approximation of the Extra Proximal Point (EPP), which is updated based on farther future rewards than the classical Proximal Point (PP). Our theorems show that standard optimism (predicting the next-step reward) achieves linear convergence to the equilibrium at a rate $\exp(-Θ(t/m^{5}))$ after $t$ iterations for delay $m$. Moreover, employing extra optimism (predicting farther future reward) tolerates a larger step size and significantly accelerates the rate to $\exp(-Θ(t/(m^{2}\log m)))$. Our experiments also show accelerated convergence driven by the extra optimism and are qualitatively consistent with our theorems. In summary, this paper validates that extra optimism is a promising countermeasure against performance degradation caused by feedback delays.

</details>


### [64] [Retrospective In-Context Learning for Temporal Credit Assignment with Large Language Models](https://arxiv.org/abs/2602.17497)
*Wen-Tse Chen,Jiayu Chen,Fahim Tajwar,Hao Zhu,Xintong Duan,Ruslan Salakhutdinov,Jeff Schneider*

Main category: cs.LG

TL;DR: 该论文提出利用大型语言模型(LLM)的预训练知识，通过回顾性上下文学习(RICL)将稀疏奖励转化为密集的优势函数信号，并结合在线学习框架RICOL来训练自我进化智能体，在BabyAI任务中实现了比传统强化学习方法更高的样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统时序信用分配方法依赖任务特定价值函数，存在样本效率低和泛化性差的问题。如何利用预训练知识来改进稀疏环境下的信用分配仍是未解挑战。

Method: 提出回顾性上下文学习(RICL)，利用LLM将稀疏奖励转换为密集的优势函数信号；并构建在线学习框架RICOL，迭代优化策略。通过在少量样本上让LLM回顾性分析轨迹，识别关键状态并估计优势函数。

Result: 在四个BabyAI场景中，RICOL达到了与传统在线强化学习算法相当的性能，但样本效率显著更高。RICL能准确估计优势函数并有效识别环境中的关键状态。

Conclusion: 该研究验证了利用大型语言模型进行时序信用分配的可行性，为开发更高效、更通用的强化学习范式提供了新方向。

Abstract: Learning from self-sampled data and sparse environmental feedback remains a fundamental challenge in training self-evolving agents. Temporal credit assignment mitigates this issue by transforming sparse feedback into dense supervision signals. However, previous approaches typically depend on learning task-specific value functions for credit assignment, which suffer from poor sample efficiency and limited generalization. In this work, we propose to leverage pretrained knowledge from large language models (LLMs) to transform sparse rewards into dense training signals (i.e., the advantage function) through retrospective in-context learning (RICL). We further propose an online learning framework, RICOL, which iteratively refines the policy based on the credit assignment results from RICL. We empirically demonstrate that RICL can accurately estimate the advantage function with limited samples and effectively identify critical states in the environment for temporal credit assignment. Extended evaluation on four BabyAI scenarios show that RICOL achieves comparable convergent performance with traditional online RL algorithms with significantly higher sample efficiency. Our findings highlight the potential of leveraging LLMs for temporal credit assignment, paving the way for more sample-efficient and generalizable RL paradigms.

</details>


### [65] [LORA-CRAFT: Cross-layer Rank Adaptation via Frozen Tucker Decomposition of Pre-trained Attention Weights](https://arxiv.org/abs/2602.17510)
*Kasun Dewage,Marianna Pensky,Suranadi De Silva,Shankadeep Mondal*

Main category: cs.LG

TL;DR: CRAFT is a parameter-efficient fine-tuning method that uses Tucker decomposition on cross-layer attention weights, freezing all decomposed factors and training only small adaptation matrices, achieving competitive performance with only 41K parameters independent of model size.


<details>
  <summary>Details</summary>
Motivation: To bridge two lines of PEFT research (tensor-based decomposition methods like LoTR/SuperLoRA that decompose gradient updates, and SVD-based methods like PiSSA that operate per layer) by developing a more parameter-efficient approach that operates directly on pre-trained weights across layers.

Method: Applies Higher-Order SVD (HOSVD) to perform full Tucker decomposition on pre-trained attention weight matrices stacked as 3D tensors across transformer layers, freezes all resulting Tucker factors, and adapts the model through lightweight trainable transformations on each factor matrix.

Result: Achieves competitive performance on GLUE benchmark using RoBERTa-base/large with only 41K Tucker adaptation parameters, where parameter count remains constant regardless of model dimension and depth at fixed Tucker ranks.

Conclusion: CRAFT successfully combines the advantages of tensor-based PEFT methods and SVD-based approaches, providing superior parameter efficiency while maintaining competitive fine-tuning performance.

Abstract: We introduce CRAFT (Cross-layer Rank Adaptation via Frozen Tucker), a parameter-efficient fine-tuning (PEFT) method that applies Tucker tensor decomposition to pre-trained attention weight matrices stacked across transformer layers and trains only small square adaptation matrices on the resulting frozen Tucker factors. Existing tensor-based PEFT methods decompose gradient updates: LoTR applies Tucker decomposition with shared factor matrices, while SuperLoRA groups and reshapes $ΔW$ across layers before applying Tucker decomposition. Separately, methods like PiSSA apply SVD to pre-trained weights but operate independently per layer. CRAFT bridges these two lines of work: it performs full Tucker decomposition via Higher-Order SVD (HOSVD) directly on pre-trained weights organized as cross-layer 3D tensors, freezes all resulting factors, and adapts the model through lightweight trainable transformations applied to each factor matrix. Experiments on the GLUE benchmark using RoBERTa-base and RoBERTa-large demonstrate that CRAFT achieves competitive performance with existing methods while requiring only 41K Tucker adaptation parameters--a count independent of model dimension and depth at fixed Tucker ranks.

</details>


### [66] [Variational inference via radial transport](https://arxiv.org/abs/2602.17525)
*Luca Ghafourpour,Sinho Chewi,Alessio Figalli,Aram-Alexandre Pooladian*

Main category: cs.LG

TL;DR: radVI通过优化径向轮廓来改进高斯变分推断的覆盖不足问题，作为廉价扩展提供理论保证


<details>
  <summary>Details</summary>
Motivation: 高斯近似无法捕捉目标分布的正确径向轮廓，导致变分推断的覆盖效果不佳

Method: 从径向轮廓优化角度提出radVI，基于Wasserstein空间优化和径向传输映射，作为现有VI方案的扩展

Result: 结合Wasserstein空间优化和Caffarelli正则性理论，为radVI提供理论收敛保证

Conclusion: radVI是现有变分推断方法的有效且廉价的增强方案，具备坚实的理论基础

Abstract: In variational inference (VI), the practitioner approximates a high-dimensional distribution $π$ with a simple surrogate one, often a (product) Gaussian distribution. However, in many cases of practical interest, Gaussian distributions might not capture the correct radial profile of $π$, resulting in poor coverage. In this work, we approach the VI problem from the perspective of optimizing over these radial profiles. Our algorithm radVI is a cheap, effective add-on to many existing VI schemes, such as Gaussian (mean-field) VI and Laplace approximation. We provide theoretical convergence guarantees for our algorithm, owing to recent developments in optimization over the Wasserstein space--the space of probability distributions endowed with the Wasserstein distance--and new regularity properties of radial transport maps in the style of Caffarelli (2000).

</details>


### [67] [The Anxiety of Influence: Bloom Filters in Transformer Attention Heads](https://arxiv.org/abs/2602.17526)
*Peter Balogh*

Main category: cs.LG

TL;DR: 研究发现Transformer注意力头可作为成员测试器，形成多层级系统，分布在早期层，能泛化处理任意重复标记，并与更广泛的计算角色共存。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer注意力头是否专门作为成员测试器（判断标记是否在上下文中出现过），并理解其工作机制和策略。

Method: 在四个语言模型（GPT-2 small/medium/large和Pythia-160M）中识别成员测试头，分析其行为模式，与Bloom过滤器理论对比，并通过混淆控制和消融实验验证其功能。

Result: 发现了四类注意力头：两个高精度成员过滤器（误报率0-4%）；一个符合Bloom过滤器理论曲线（容量约5位）；一个被重新分类为前缀注意力头；前三者构成早期层（0-1）的多分辨率系统，误报率随嵌入距离单调衰减，且对任意重复标记类型的泛化能力比仅处理重复标记的头高43%。

Conclusion: 成员测试功能与更广泛的计算角色共存于Transformer中，严格的混淆控制通过排除假阳性反而加强了结论的可信度。

Abstract: Some transformer attention heads appear to function as membership testers, dedicating themselves to answering the question "has this token appeared before in the context?" We identify these heads across four language models (GPT-2 small, medium, and large; Pythia-160M) and show that they form a spectrum of membership-testing strategies. Two heads (L0H1 and L0H5 in GPT-2 small) function as high-precision membership filters with false positive rates of 0-4\% even at 180 unique context tokens -- well above the $d_\text{head} = 64$ bit capacity of a classical Bloom filter. A third head (L1H11) shows the classic Bloom filter capacity curve: its false positive rate follows the theoretical formula $p \approx (1 - e^{-kn/m})^k$ with $R^2 = 1.0$ and fitted capacity $m \approx 5$ bits, saturating by $n \approx 20$ unique tokens. A fourth head initially identified as a Bloom filter (L3H0) was reclassified as a general prefix-attention head after confound controls revealed its apparent capacity curve was a sequence-length artifact. Together, the three genuine membership-testing heads form a multi-resolution system concentrated in early layers (0-1), taxonomically distinct from induction and previous-token heads, with false positive rates that decay monotonically with embedding distance -- consistent with distance-sensitive Bloom filters. These heads generalize broadly: they respond to any repeated token type, not just repeated names, with 43\% higher generalization than duplicate-token-only heads. Ablation reveals these heads contribute to both repeated and novel token processing, indicating that membership testing coexists with broader computational roles. The reclassification of L3H0 through confound controls strengthens rather than weakens the case: the surviving heads withstand the scrutiny that eliminated a false positive in our own analysis.

</details>


### [68] [Position: Evaluation of ECG Representations Must Be Fixed](https://arxiv.org/abs/2602.17531)
*Zachary Berger,Daniel Prakah-Asante,John Guttag,Collin M. Stultz*

Main category: cs.LG

TL;DR: 当前12导联心电图表示学习的基准测试实践存在问题，无法可靠反映临床意义的进展。本文提出扩展评估目标至结构性心脏病和患者级预测，并制定不平衡多标签评估的最佳实践，发现随机初始化编码器作为基线模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前心电图表示学习领域过度依赖三个公共多标签基准（PTB-XL, CPSC2018, CSN），这些基准主要关注心律失常和波形形态标签，而忽略了心电图蕴含的更广泛临床信息（如结构性心脏病和患者级预测），导致研究进展不可靠且与临床目标不一致。

Method: 1. 主张下游评估应扩展至结构性心脏病和患者级预测等新终点；2. 概述针对多标签、不平衡数据的评估最佳实践；3. 通过实验评估三种代表性预训练方法在六种评估场景下的表现（包括标准基准、结构性心脏病数据集、血液动力学推断和患者预测）。

Result: 1. 应用最佳实践后，现有文献关于最佳表示的结论被改变；2. 随机初始化的编码器+线性评估在多项任务上匹配甚至超过当前最优预训练方法；3. 证明随机编码器是一个被低估的合理基线模型。

Conclusion: 心电图表示学习领域需要修正当前基准测试实践，采用更全面的临床评估目标和不平衡数据最佳实践，并将随机编码器作为强有力的基线，以确保研究进展可靠且符合临床需求。

Abstract: This position paper argues that current benchmarking practice in 12-lead ECG representation learning must be fixed to ensure progress is reliable and aligned with clinically meaningful objectives. The field has largely converged on three public multi-label benchmarks (PTB-XL, CPSC2018, CSN) dominated by arrhythmia and waveform-morphology labels, even though the ECG is known to encode substantially broader clinical information. We argue that downstream evaluation should expand to include an assessment of structural heart disease and patient-level forecasting, in addition to other evolving ECG-related endpoints, as relevant clinical targets. Next, we outline evaluation best practices for multi-label, imbalanced settings, and show that when they are applied, the literature's current conclusion about which representations perform best is altered. Furthermore, we demonstrate the surprising result that a randomly initialized encoder with linear evaluation matches state-of-the-art pre-training on many tasks. This motivates the use of a random encoder as a reasonable baseline model. We substantiate our observations with an empirical evaluation of three representative ECG pre-training approaches across six evaluation settings: the three standard benchmarks, a structural disease dataset, hemodynamic inference, and patient forecasting.

</details>


### [69] [MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning](https://arxiv.org/abs/2602.17550)
*Xiaoliang Fu,Jiaye Lin,Yangyi Fang,Binbin Zheng,Chaowen Hu,Zekai Shao,Cong Qin,Lu Pan,Ke Zeng,Xunliang Cai*

Main category: cs.LG

TL;DR: 该论文指出现有RLVR算法（如GRPO）存在三个关键缺陷：硬截断导致梯度利用低效、统一比率约束忽略词元分布、正负样本信用分配模糊导致信号可靠性不对称。为此提出MASPO框架，通过可微分软高斯门控、质量自适应限制器和非对称风险控制器来协调优化，在多项评估中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习可验证奖励（RLVR）算法采用刚性、统一、对称的信任域机制，与大型语言模型（LLM）复杂的优化动力学 fundamentally 不匹配，导致训练效率低下和性能受限。

Method: 提出MASPO（质量自适应软策略优化）统一框架，包含三个核心组件：1）可微分软高斯门控替代硬截断以最大化梯度效用；2）质量自适应限制器根据词元概率分布动态平衡探索；3）非对称风险控制器使更新幅度与信号置信度对齐。

Result: 广泛评估表明，MASPO作为一体化RLVR解决方案，在性能上显著优于现有强基线算法。

Conclusion: MASPO通过协调梯度利用、概率谱探索和信号置信度三个维度，成功解决了RLVR中的根本性错位问题，为LLM的强化学习优化提供了更鲁棒、更高效的统一框架。

Abstract: Existing Reinforcement Learning with Verifiable Rewards (RLVR) algorithms, such as GRPO, rely on rigid, uniform, and symmetric trust region mechanisms that are fundamentally misaligned with the complex optimization dynamics of Large Language Models (LLMs). In this paper, we identify three critical challenges in these methods: (1) inefficient gradient utilization caused by the binary cutoff of hard clipping, (2) insensitive probability mass arising from uniform ratio constraints that ignore the token distribution, and (3) asymmetric signal reliability stemming from the disparate credit assignment ambiguity between positive and negative samples. To bridge these gaps, we propose Mass-Adaptive Soft Policy Optimization (MASPO), a unified framework designed to harmonize these three dimensions. MASPO integrates a differentiable soft Gaussian gating to maximize gradient utility, a mass-adaptive limiter to balance exploration across the probability spectrum, and an asymmetric risk controller to align update magnitudes with signal confidence. Extensive evaluations demonstrate that MASPO serves as a robust, all-in-one RLVR solution, significantly outperforming strong baselines. Our code is available at: https://anonymous.4open.science/r/ma1/README.md.

</details>


### [70] [Revisiting Weight Regularization for Low-Rank Continual Learning](https://arxiv.org/abs/2602.17559)
*Yaoyue Zheng,Yin Zhang,Joost van de Weijer,Gido M van de Ven,Shaoyi Du,Xuetao Zhang,Zhiqiang Tian*

Main category: cs.LG

TL;DR: 该论文重新审视了权重正则化在低秩持续学习中的作用，提出EWC-LoRA方法，通过Elastic Weight Consolidation (EWC)正则化共享的低秩更新来缓解任务干扰，实现了与任务数量无关的恒定存储和推理开销，在稳定性-可塑性权衡上优于现有低秩持续学习方法。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练模型的持续学习范式正从"从头训练"转向"持续适应"，催生了参数高效持续学习(PECL)方向。现有PECL方法主要通过任务特定模块(如低秩适配器)缓解任务干扰，但EWC等权重正则化技术在这一新范式中尚未得到充分探索，存在研究空白。

Method: 提出EWC-LoRA方法：1) 在低秩持续学习框架中引入EWC正则化；2) 利用低秩表示估计全维空间的参数重要性；3) 通过正则化共享的低秩更新而非独立任务模块来缓解任务干扰，保持存储和计算成本恒定。

Result: 在多个基准测试上的广泛实验表明：1) EWC-LoRA在稳定性-可塑性权衡上显著优于现有低秩持续学习方法；2) 即使在低秩参数化下，权重正则化仍是缓解任务干扰的有效机制；3) 该方法为PTMs的持续学习提供了实用且高效的解决方案。

Conclusion: 权重正则化技术(特别是EWC)在参数高效持续学习中仍有重要价值，EWC-LoRA不仅提供了计算和存储高效的解决方案，还为PECL中更广泛的正则化技术应用提供了重要见解，拓展了持续学习方法的设计空间。

Abstract: Continual Learning (CL) with large-scale pre-trained models (PTMs) has recently gained wide attention, shifting the focus from training from scratch to continually adapting PTMs. This has given rise to a promising paradigm: parameter-efficient continual learning (PECL), where task interference is typically mitigated by assigning a task-specific module during training, such as low-rank adapters. However, weight regularization techniques, such as Elastic Weight Consolidation (EWC)-a key strategy in CL-remain underexplored in this new paradigm. In this paper, we revisit weight regularization in low-rank CL as a new perspective for mitigating task interference in PECL. Unlike existing low-rank CL methods, we mitigate task interference by regularizing a shared low-rank update through EWC, thereby keeping the storage requirement and inference costs constant regardless of the number of tasks. Our proposed method EWC-LoRA leverages a low-rank representation to estimate parameter importance over the full-dimensional space. This design offers a practical, computational- and memory-efficient solution for CL with PTMs, and provides insights that may inform the broader application of regularization techniques within PECL. Extensive experiments on various benchmarks demonstrate the effectiveness of EWC-LoRA, achieving a stability-plasticity trade-off superior to existing low-rank CL approaches. These results indicate that, even under low-rank parameterizations, weight regularization remains an effective mechanism for mitigating task interference. Code is available at: https://github.com/yaoyz96/low-rank-cl.

</details>


### [71] [Be Wary of Your Time Series Preprocessing](https://arxiv.org/abs/2602.17568)
*Sofiane Ennadir,Tianze Wang,Oleg Smirnov,Sahar Asadi,Lele Cao*

Main category: cs.LG

TL;DR: 该论文首次从理论角度系统分析了实例归一化和全局缩放等归一化策略对基于Transformer的时间序列模型表达能力的影哳，发现归一化方式的选择会显著影响模型表征能力，且没有单一方法始终最优，甚至在某些情况下完全不使用归一化效果更佳。


<details>
  <summary>Details</summary>
Motivation: 时间序列建模中归一化和缩放是基础预处理步骤，但其在Transformer模型中的理论作用尚未得到充分探索。

Method: 提出一个专门针对时间序列的新表达能力框架，量化模型在表征空间中区分相似与不同输入的能力；基于该框架推导了标准缩放和最小-最大缩放两种常用归一化方法的理论边界；在分类和预测基准测试上通过多个Transformer模型进行实证验证。

Result: 归一化策略的选择会显著影响模型的表征能力，具体效果取决于任务和数据特性；没有单一归一化方法在所有情况下都表现最佳；在某些情况下，完全不使用归一化反而能获得更优性能。

Conclusion: 预处理在时间序列学习中起关键作用，需要开发针对特定任务和数据集的原则性归一化策略。

Abstract: Normalization and scaling are fundamental preprocessing steps in time series modeling, yet their role in Transformer-based models remains underexplored from a theoretical perspective. In this work, we present the first formal analysis of how different normalization strategies, specifically instance-based and global scaling, impact the expressivity of Transformer-based architectures for time series representation learning. We propose a novel expressivity framework tailored to time series, which quantifies a model's ability to distinguish between similar and dissimilar inputs in the representation space. Using this framework, we derive theoretical bounds for two widely used normalization methods: Standard and Min-Max scaling. Our analysis reveals that the choice of normalization strategy can significantly influence the model's representational capacity, depending on the task and data characteristics. We complement our theory with empirical validation on classification and forecasting benchmarks using multiple Transformer-based models. Our results show that no single normalization method consistently outperforms others, and in some cases, omitting normalization entirely leads to superior performance. These findings highlight the critical role of preprocessing in time series learning and motivate the need for more principled normalization strategies tailored to specific tasks and datasets.

</details>


### [72] [Asymptotic Smoothing of the Lipschitz Loss Landscape in Overparameterized One-Hidden-Layer ReLU Networks](https://arxiv.org/abs/2602.17596)
*Saveliy Baturin*

Main category: cs.LG

TL;DR: Overparameterized ReLU networks have increasingly flat, connected loss landscapes where barriers between local and global minima vanish as network width grows


<details>
  <summary>Details</summary>
Motivation: Understanding the topology of loss landscapes in overparameterized one-hidden-layer ReLU networks to explain their trainability despite non-convexity

Method: Theoretical proof of path connectivity and energy gap bounds; Empirical measurement using Dynamic String Sampling (DSS) on Moons and Breast Cancer datasets; Permutation testing

Result: (1) Every pair of same-loss models can be connected with arbitrarily small loss increase ε; (2) Energy gap between local/global minima vanishes as width m grows; (3) Wider networks show smaller energy gaps (p_perm=0)

Conclusion: Overparameterization flattens loss landscapes and connects sublevel sets, explaining why wide networks can be effectively trained to global minima

Abstract: We study the topology of the loss landscape of one-hidden-layer ReLU networks under overparameterization. On the theory side, we (i) prove that for convex $L$-Lipschitz losses with an $\ell_1$-regularized second layer, every pair of models at the same loss level can be connected by a continuous path within an arbitrarily small loss increase $ε$ (extending a known result for the quadratic loss); (ii) obtain an asymptotic upper bound on the energy gap $ε$ between local and global minima that vanishes as the width $m$ grows, implying that the landscape flattens and sublevel sets become connected in the limit. Empirically, on a synthetic Moons dataset and on the Wisconsin Breast Cancer dataset, we measure pairwise energy gaps via Dynamic String Sampling (DSS) and find that wider networks exhibit smaller gaps; in particular, a permutation test on the maximum gap yields $p_{perm}=0$, indicating a clear reduction in the barrier height.

</details>


### [73] [Towards Anytime-Valid Statistical Watermarking](https://arxiv.org/abs/2602.17608)
*Baihe Huang,Eric Xu,Kannan Ramchandran,Jiantao Jiao,Michael I. Jordan*

Main category: cs.LG

TL;DR: 提出首个基于e值的文本水印框架Anchored E-Watermarking，通过anytime-valid推断实现AI生成文本检测，比现有方法节省13-15%的token预算。


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本水印方法在采样分布选择上缺乏理论指导，且依赖固定假设检验无法实现有效早期停止，导致token资源浪费。

Method: 构建基于e值和检验上鞅的水印框架，利用锚定分布逼近目标模型，从最坏情况对数增长率角度推导最优e值和期望停止时间。

Result: 在多个基准测试中，该框架比最先进基线平均减少13-15%的检测token开销，理论结果得到仿真和实验验证。

Conclusion: 该框架为机器生成文本检测提供了理论严谨、样本高效且可随时验证的解决方案，解决了现有水印方法的关键局限。

Abstract: The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach for selecting sampling distributions and the reliance on fixed-horizon hypothesis testing, which precludes valid early stopping. In this paper, we bridge this gap by developing the first e-value-based watermarking framework, Anchored E-Watermarking, that unifies optimal sampling with anytime-valid inference. Unlike traditional approaches where optional stopping invalidates Type-I error guarantees, our framework enables valid, anytime-inference by constructing a test supermartingale for the detection process. By leveraging an anchor distribution to approximate the target model, we characterize the optimal e-value with respect to the worst-case log-growth rate and derive the optimal expected stopping time. Our theoretical claims are substantiated by simulations and evaluations on established benchmarks, showing that our framework can significantly enhance sample efficiency, reducing the average token budget required for detection by 13-15% relative to state-of-the-art baselines.

</details>


### [74] [Guarding the Middle: Protecting Intermediate Representations in Federated Split Learning](https://arxiv.org/abs/2602.17614)
*Obaidullah Zaland,Sajib Mistry,Monowar Bhuyan*

Main category: cs.LG

TL;DR: This paper proposes KD-UFSL, a privacy-preserving method for U-shaped federated split learning that combines k-anonymity and differential privacy to protect client data from reconstruction attacks through intermediate representations, demonstrating significant privacy improvements while maintaining model utility.


<details>
  <summary>Details</summary>
Motivation: Traditional federated learning places computational burden on clients. UFSL offloads computation but shares intermediate representations (smashed data) that risk exposing private client data through reconstruction attacks.

Method: The authors propose KD-UFSL which applies microaggregation for k-anonymity and differential privacy to the smashed data transferred between clients and server, making it harder to reconstruct original private data.

Result: KD-UFSL increases mean squared error of reconstructed images by up to 50% and reduces structural similarity by up to 40% across four benchmark datasets, significantly enhancing privacy while preserving global model utility.

Conclusion: KD-UFSL is suitable for large-scale big data applications requiring balanced privacy and utility, effectively mitigating privacy risks in UFSL without compromising model performance.

Abstract: Big data scenarios, where massive, heterogeneous datasets are distributed across clients, demand scalable, privacy-preserving learning methods. Federated learning (FL) enables decentralized training of machine learning (ML) models across clients without data centralization. Decentralized training, however, introduces a computational burden on client devices. U-shaped federated split learning (UFSL) offloads a fraction of the client computation to the server while keeping both data and labels on the clients' side. However, the intermediate representations (i.e., smashed data) shared by clients with the server are prone to exposing clients' private data. To reduce exposure of client data through intermediate data representations, this work proposes k-anonymous differentially private UFSL (KD-UFSL), which leverages privacy-enhancing techniques such as microaggregation and differential privacy to minimize data leakage from the smashed data transferred to the server. We first demonstrate that an adversary can access private client data from intermediate representations via a data-reconstruction attack, and then present a privacy-enhancing solution, KD-UFSL, to mitigate this risk. Our experiments indicate that, alongside increasing the mean squared error between the actual and reconstructed images by up to 50% in some cases, KD-UFSL also decreases the structural similarity between them by up to 40% on four benchmarking datasets. More importantly, KD-UFSL improves privacy while preserving the utility of the global model. This highlights its suitability for large-scale big data applications where privacy and utility must be balanced.

</details>


### [75] [Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs](https://arxiv.org/abs/2602.17616)
*Luke Huang,Zhuoyang Zhang,Qinghao Hu,Shang Yang,Song Han*

Main category: cs.LG

TL;DR: This paper identifies that asynchronous RL training for LLMs suffers from high variance due to stale rollouts in policy-gradient methods like REINFORCE/GRPO. It proposes VCPO, a stabilization method that scales learning rate based on effective sample size and uses a minimum-variance baseline, achieving 2.5x training speedup while matching synchronous performance.


<details>
  <summary>Details</summary>
Motivation: Asynchronous RL training is attractive for improving throughput in LLM reasoning tasks, but creates high-variance policy-gradient estimators due to stale rollouts, causing training instability. The paper aims to diagnose and solve this variance problem for reliable large-scale asynchronous RL.

Method: VCPO (Variance Controlled Policy Optimization): (1) Learning rate scaling based on effective sample size (ESS) to dampen unreliable updates; (2) Closed-form minimum-variance baseline for off-policy settings, avoiding the need for an auxiliary value model.

Result: VCPO substantially improves robustness for asynchronous training across math, general reasoning, and tool-use tasks, outperforming masking/clipping baselines and algorithmic variants. It reduces long-context, multi-turn training time by 2.5× while matching synchronous performance.

Conclusion: Explicit control of policy-gradient variance is essential for reliable asynchronous RL at scale. VCPO provides a general stabilization approach for REINFORCE/GRPO-style algorithms, making asynchronous training both faster and more robust.

Abstract: Reinforcement learning (RL) is widely used to improve large language models on reasoning tasks, and asynchronous RL training is attractive because it increases end-to-end throughput. However, for widely adopted critic-free policy-gradient methods such as REINFORCE and GRPO, high asynchrony makes the policy-gradient estimator markedly $\textbf{higher variance}$: training on stale rollouts creates heavy-tailed importance ratios, causing a small fraction of samples to dominate updates. This amplification makes gradients noisy and learning unstable relative to matched on-policy training. Across math and general reasoning benchmarks, we find collapse is reliably predicted by effective sample size (ESS) and unstable gradient norms. Motivated by this diagnosis, we propose $\textbf{V}$ariance $\textbf{C}$ontrolled $\textbf{P}$olicy $\textbf{O}$ptimization ($\textbf{VCPO}$), a general stabilization method for REINFORCE/GRPO-style algorithms that (i) scales learning rate based on effective sample size to dampen unreliable updates, and (ii) applies a closed-form minimum-variance baseline for the off-policy setting, avoiding an auxiliary value model and adding minimal overhead. Empirically, VCPO substantially improves robustness for asynchronous training across math, general reasoning, and tool-use tasks, outperforming a broad suite of baselines spanning masking/clipping stabilizers and algorithmic variants. This reduces long-context, multi-turn training time by 2.5$\times$ while matching synchronous performance, demonstrating that explicit control of policy-gradient variance is key for reliable asynchronous RL at scale.

</details>


### [76] [Catastrophic Forgetting Resilient One-Shot Incremental Federated Learning](https://arxiv.org/abs/2602.17625)
*Obaidullah Zaland,Zulfiqar Ahmad Khan,Monowar Bhuyan*

Main category: cs.LG

TL;DR: 提出One-Shot增量联邦学习(OSI-FL)框架，通过单次通信的类别嵌入和扩散模型合成数据，结合选择性样本保留(SSR)策略，解决通信开销与灾难性遗忘问题，在三个数据集上超越基线方法


<details>
  <summary>Details</summary>
Motivation: 大数据系统产生海量异构、地理分散且隐私敏感的流式数据，传统联邦学习需多轮通信且假设静态数据，难以应对增量学习场景下的通信限制和灾难性遗忘挑战

Method: 1) 冻结视觉语言模型生成类别特定嵌入，单次通信传输；2) 服务器端预训练扩散模型合成类似客户端分布的样本；3) 选择性样本保留(SSR)策略基于样本损失保留每类每任务前p个最具信息量的样本，用于后续训练

Result: 在三个基准数据集上的类和域增量场景中，OSI-FL性能超越传统联邦学习和单次联邦学习方法

Conclusion: OSI-FL首次同时解决通信开销和灾难性遗忘问题，为资源受限的增量学习场景提供了有效的隐私保护解决方案

Abstract: Modern big-data systems generate massive, heterogeneous, and geographically dispersed streams that are large-scale and privacy-sensitive, making centralization challenging. While federated learning (FL) provides a privacy-enhancing training mechanism, it assumes a static data flow and learns a collaborative model over multiple rounds, making learning with \textit{incremental} data challenging in limited-communication scenarios. This paper presents One-Shot Incremental Federated Learning (OSI-FL), the first FL framework that addresses the dual challenges of communication overhead and catastrophic forgetting. OSI-FL communicates category-specific embeddings, devised by a frozen vision-language model (VLM) from each client in a single communication round, which a pre-trained diffusion model at the server uses to synthesize new data similar to the client's data distribution. The synthesized samples are used on the server for training. However, two challenges still persist: i) tasks arriving incrementally need to retrain the global model, and ii) as future tasks arrive, retraining the model introduces catastrophic forgetting. To this end, we augment training with Selective Sample Retention (SSR), which identifies and retains the top-p most informative samples per category and task pair based on sample loss. SSR bounds forgetting by ensuring that representative retained samples are incorporated into training in further iterations. The experimental results indicate that OSI-FL outperforms baselines, including traditional and one-shot FL approaches, in both class-incremental and domain-incremental scenarios across three benchmark datasets.

</details>


### [77] [When to Trust the Cheap Check: Weak and Strong Verification for Reasoning](https://arxiv.org/abs/2602.17633)
*Shayan Kiyani,Sima Noorani,George Pappas,Hamed Hassani*

Main category: cs.LG

TL;DR: 提出弱-强验证策略框架，形式化LLM推理中低成本弱验证（如自洽性）与高成本强验证（人工反馈）的权衡，设计在线算法控制错误率


<details>
  <summary>Details</summary>
Motivation: 现有LLM验证缺乏对"弱验证"（廉价但噪声大）和"强验证"（可靠但资源密集）的系统性管理，需解决二者成本与可靠性的尖锐矛盾

Method: 1. 定义弱-强验证决策策略，建立错误接受/拒绝及强验证频率的度量体系；2. 证明最优策略具有双阈值结构；3. 开发无需假设查询流/模型/验证器的在线控制算法

Result: 1. 发现弱验证价值取决于校准性与尖锐性；2. 算法在群体层面实现错误率可证明控制；3. 双阈值结构为最优策略特征

Conclusion: 为LLM推理提供可扩展的验证框架，通过动态分配弱/强验证资源，在保障可信度的同时优化成本效益

Abstract: Reasoning with LLMs increasingly unfolds inside a broader verification loop. Internally, systems use cheap checks, such as self-consistency or proxy rewards, which we call weak verification. Externally, users inspect outputs and steer the model through feedback until results are trustworthy, which we call strong verification. These signals differ sharply in cost and reliability: strong verification can establish trust but is resource-intensive, while weak verification is fast and scalable but noisy and imperfect. We formalize this tension through weak--strong verification policies, which decide when to accept or reject based on weak verification and when to defer to strong verification. We introduce metrics capturing incorrect acceptance, incorrect rejection, and strong-verification frequency. Over population, we show that optimal policies admit a two-threshold structure and that calibration and sharpness govern the value of weak verifiers. Building on this, we develop an online algorithm that provably controls acceptance and rejection errors without assumptions on the query stream, the language model, or the weak verifier.

</details>


### [78] [Reverso: Efficient Time Series Foundation Models for Zero-shot Forecasting](https://arxiv.org/abs/2602.17634)
*Xinghong Fu,Yanhong Li,Georgios Papaioannou,Yoon Kim*

Main category: cs.LG

TL;DR: This paper introduces Reverso, a family of small, efficient time series foundation models that use hybrid convolutional and DeltaNet layers instead of large transformers, achieving comparable zero-shot forecasting performance while being 100x smaller.


<details>
  <summary>Details</summary>
Motivation: Current time series foundation models with hundreds of millions of parameters are performant but inefficient and expensive; there's a need for smaller, more efficient models that maintain zero-shot forecasting capabilities across diverse domains.

Method: Proposes a simple recipe using small hybrid models that interleave long convolution and linear RNN (DeltaNet) layers, combined with data augmentation and inference strategies, as an alternative to large-scale transformers.

Result: The hybrid models match the performance of larger transformer-based models while being over 100 times smaller, significantly pushing the performance-efficiency Pareto frontier.

Conclusion: Large transformers are not necessary for effective zero-shot time series forecasting; small, efficient hybrid architectures can achieve comparable performance with vastly reduced computational requirements.

Abstract: Learning time series foundation models has been shown to be a promising approach for zero-shot time series forecasting across diverse time series domains. Insofar as scaling has been a critical driver of performance of foundation models in other modalities such as language and vision, much recent work on time series foundation modeling has focused on scaling. This has resulted in time series foundation models with hundreds of millions of parameters that are, while performant, inefficient and expensive to use in practice. This paper describes a simple recipe for learning efficient foundation models for zero-shot time series forecasting that are orders of magnitude smaller. We show that large-scale transformers are not necessary: small hybrid models that interleave long convolution and linear RNN layers (in particular DeltaNet layers) can match the performance of larger transformer-based models while being more than a hundred times smaller. We also describe several data augmentation and inference strategies that further improve performance. This recipe results in Reverso, a family of efficient time series foundation models for zero-shot forecasting that significantly push the performance-efficiency Pareto frontier.

</details>


### [79] [FAMOSE: A ReAct Approach to Automated Feature Discovery](https://arxiv.org/abs/2602.17641)
*Keith Burghardt,Jienan Liu,Sadman Sakib,Yuning Hao,Bo Li*

Main category: cs.LG

TL;DR: This paper introduces FAMOSE, a novel framework that applies the ReAct paradigm to automated feature engineering for tabular data, achieving state-of-the-art results in regression (2.0% RMSE reduction) and near-SOTA in classification (0.23% ROC-AUC improvement), while demonstrating that AI agents excel at inventive problem-solving.


<details>
  <summary>Details</summary>
Motivation: Feature engineering remains a critical bottleneck in machine learning for tabular data, requiring substantial domain expertise to identify optimal features from an exponentially large search space, creating an urgent need for automated solutions.

Method: FAMOSE leverages the ReAct paradigm within an agent architecture to autonomously explore, generate, and refine features while integrating feature selection and evaluation tools, representing the first application of an agentic ReAct framework to automated feature engineering.

Result: Extensive experiments show FAMOSE achieves state-of-the-art performance for regression tasks (2.0% average RMSE reduction) and near-state-of-the-art for classification (0.23% average ROC-AUC increase on large datasets), while demonstrating superior robustness to errors compared to other algorithms.

Conclusion: AI agents are remarkably effective at solving highly inventive problems like feature engineering, as ReAct's iterative feature discovery and evaluation process within the LLM context window enables innovation similar to few-shot prompting.

Abstract: Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature AugMentation and Optimal Selection agEnt), a novel framework that leverages the ReAct paradigm to autonomously explore, generate, and refine features while integrating feature selection and evaluation tools within an agent architecture. To our knowledge, FAMOSE represents the first application of an agentic ReAct framework to automated feature engineering, especially for both regression and classification tasks. Extensive experiments demonstrate that FAMOSE is at or near the state-of-the-art on classification tasks (especially tasks with more than 10K instances, where ROC-AUC increases 0.23% on average), and achieves the state-of-the-art for regression tasks by reducing RMSE by 2.0% on average, while remaining more robust to errors than other algorithms. We hypothesize that FAMOSE's strong performance is because ReAct allows the LLM context window to record (via iterative feature discovery and evaluation steps) what features did or did not work. This is similar to a few-shot prompt and guides the LLM to invent better, more innovative features. Our work offers evidence that AI agents are remarkably effective in solving problems that require highly inventive solutions, such as feature engineering.

</details>


### [80] [A.R.I.S.: Automated Recycling Identification System for E-Waste Classification Using Deep Learning](https://arxiv.org/abs/2602.17642)
*Dhruv Talwar,Harsh Desai,Wendong Yin,Goutam Mohanty,Rafael Reveles*

Main category: cs.LG

TL;DR: 该论文提出了一种名为A.R.I.S.的自动化电子垃圾分拣系统，通过YOLOx模型实现金属、塑料和电路板的实时分类，显著提升分拣精度和效率，减少资源浪费。


<details>
  <summary>Details</summary>
Motivation: 传统电子垃圾回收过程因材料分离和识别能力不足导致资源大量损失，限制了材料回收效率。

Method: 开发了一种低成本、便携式分拣系统A.R.I.S.，采用YOLOx深度学习模型对粉碎后的电子垃圾进行实时分类。

Result: 实验评估显示系统达到90%的整体精确率、82.2%的平均精度均值（mAP）和84%的分拣纯度，同时具备低推理延迟和高检测精度。

Conclusion: 该系统通过结合深度学习与传统分拣方法，提升了材料回收效率，降低了先进回收技术的采用门槛，支持产品生命周期延长和供应链环保倡议。

Abstract: Traditional electronic recycling processes suffer from significant resource loss due to inadequate material separation and identification capabilities, limiting material recovery. We present A.R.I.S. (Automated Recycling Identification System), a low-cost, portable sorter for shredded e-waste that addresses this efficiency gap. The system employs a YOLOx model to classify metals, plastics, and circuit boards in real time, achieving low inference latency with high detection accuracy. Experimental evaluation yielded 90% overall precision, 82.2% mean average precision (mAP), and 84% sortation purity. By integrating deep learning with established sorting methods, A.R.I.S. enhances material recovery efficiency and lowers barriers to advanced recycling adoption. This work complements broader initiatives in extending product life cycles, supporting trade-in and recycling programs, and reducing environmental impact across the supply chain.

</details>


### [81] [Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting](https://arxiv.org/abs/2602.17645)
*Xiaohan Zhao,Zhaoyi Li,Yaxin Luo,Jiacheng Cui,Zhiqiang Shen*

Main category: cs.LG

TL;DR: 本文提出M-Attack-V2，一种针对大型视觉-语言模型（LVLM）的黑盒对抗攻击方法的改进版本，相比之前的M-Attack显著提升了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型的黑盒对抗攻击由于缺少梯度和复杂的多模态边界而具有挑战性。先前最优的迁移攻击方法（M-Attack）虽然表现良好，但存在梯度方差高、迭代间几乎正交的问题，破坏了局部对齐并导致优化不稳定，这源于(i) ViT平移敏感性产生的尖峰状梯度和(ii)源与目标图像块之间的结构不对称性。

Method: 将局部匹配重新表述为源变换与目标语义的不对称期望，并对M-Attack进行梯度去噪升级：1）多块对齐（MCA）：每轮迭代平均多个独立采样局部视图的梯度以降低方差；2）辅助目标对齐（ATA）：用来自语义相关分布的小规模辅助集替代激进的目标增强，产生更平滑、低方差的目标流形；3）块动量（Patch Momentum）：重新解释动量为重放历史图像块梯度；4）优化的块大小集成（PE+）：增强可迁移方向。这些模块共同构成M-Attack-V2。

Result: 显著提升前沿LVLM上的迁移黑盒攻击效果：Claude-4.0攻击成功率从8%提升至30%，Gemini-2.5-Pro从83%提升至97%，GPT-5从98%提升至100%，优于先前所有黑盒LVLM攻击方法。

Conclusion: M-Attack-V2是M-Attack的简单模块化增强，能显著提升对主流LVLM的攻击成功率，代码和数据已开源。

Abstract: Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we find this induces high-variance, nearly orthogonal gradients across iterations, violating coherent local alignment and destabilizing optimization. We attribute this to (i) ViT translation sensitivity that yields spike-like gradients and (ii) structural asymmetry between source and target crops. We reformulate local matching as an asymmetric expectation over source transformations and target semantics, and build a gradient-denoising upgrade to M-Attack. On the source side, Multi-Crop Alignment (MCA) averages gradients from multiple independently sampled local views per iteration to reduce variance. On the target side, Auxiliary Target Alignment (ATA) replaces aggressive target augmentation with a small auxiliary set from a semantically correlated distribution, producing a smoother, lower-variance target manifold. We further reinterpret momentum as Patch Momentum, replaying historical crop gradients; combined with a refined patch-size ensemble (PE+), this strengthens transferable directions. Together these modules form M-Attack-V2, a simple, modular enhancement over M-Attack that substantially improves transfer-based black-box attacks on frontier LVLMs: boosting success rates on Claude-4.0 from 8% to 30%, Gemini-2.5-Pro from 83% to 97%, and GPT-5 from 98% to 100%, outperforming prior black-box LVLM attacks. Code and data are publicly available at: https://github.com/vila-lab/M-Attack-V2.

</details>


### [82] [Multi-Round Human-AI Collaboration with User-Specified Requirements](https://arxiv.org/abs/2602.17646)
*Sima Noorani,Shayan Kiyani,Hamed Hassani,George Pappas*

Main category: cs.LG

TL;DR: 为保证多轮对话AI在高风险决策中可靠提升决策质量，本文提出基于反事实伤害和互补性原则的人本框架，通过用户自定义规则和在线无分布算法，在医疗诊断和图形推理任务中验证了其有效性和可控性。


<details>
  <summary>Details</summary>
Motivation: 随着人类越来越多地依赖多轮对话AI进行高风险决策，需要原则性框架确保此类交互能可靠地提升决策质量，避免AI损害人类优势并补充人类易错之处。

Method: 采用人本视角，定义反事实伤害和互补性两个原则，通过用户自定义规则形式化这些概念，并引入具有有限样本保证的在线无分布算法来约束协作动态。

Result: 在LLM模拟的医疗诊断和人类众包的图形推理任务中，该在线方法能在非平稳交互动态下维持规定的反事实伤害和互补性违反率，且约束的松紧会可预测地改变下游人类准确率。

Conclusion: 两个原则可作为实际杠杆，在不需建模或限制人类行为的情况下，引导多轮协作朝向更好的决策质量，为高风险人机协作提供了可操作的框架。

Abstract: As humans increasingly rely on multiround conversational AI for high stakes decisions, principled frameworks are needed to ensure such interactions reliably improve decision quality. We adopt a human centric view governed by two principles: counterfactual harm, ensuring the AI does not undermine human strengths, and complementarity, ensuring it adds value where the human is prone to err. We formalize these concepts via user defined rules, allowing users to specify exactly what harm and complementarity mean for their specific task. We then introduce an online, distribution free algorithm with finite sample guarantees that enforces the user-specified constraints over the collaboration dynamics. We evaluate our framework across two interactive settings: LLM simulated collaboration on a medical diagnostic task and a human crowdsourcing study on a pictorial reasoning task. We show that our online procedure maintains prescribed counterfactual harm and complementarity violation rates even under nonstationary interaction dynamics. Moreover, tightening or loosening these constraints produces predictable shifts in downstream human accuracy, confirming that the two principles serve as practical levers for steering multi-round collaboration toward better decision quality without the need to model or constrain human behavior.

</details>


### [83] [MARS: Margin-Aware Reward-Modeling with Self-Refinement](https://arxiv.org/abs/2602.17658)
*Payel Bhattacharjee,Osvaldo Simeone,Ravi Tandon*

Main category: cs.LG

TL;DR: MARS是一个自适应、边界感知的数据增强策略，通过针对奖励模型最不确定的模糊偏好对进行增强，并迭代优化训练分布，提升奖励模型的可靠性


<details>
  <summary>Details</summary>
Motivation: 训练可靠奖励模型依赖昂贵且有限的人工标注偏好数据，现有增强方法忽视奖励模型的估计难度，导致性能次优

Method: 提出MARS框架，聚焦于低边界（模糊）偏好对，通过迭代式困难样本增强策略精炼训练分布

Result: 理论证明该策略增加损失函数平均曲率、增强信息量并改善条件数；实验显示相比均匀增强在鲁棒奖励建模上取得持续增益

Conclusion: MARS通过自适应增强模糊样本，从理论上改善学习动态，实验上优于现有方法，有效解决奖励模型局限性

Abstract: Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of data augmentation. Existing augmentation approaches typically operate at the representation or semantic level and remain agnostic to the reward model's estimation difficulty. In this paper, we propose MARS, an adaptive, margin-aware augmentation and sampling strategy that explicitly targets ambiguous and failure modes of the reward model. Our proposed framework, MARS, concentrates augmentation on low-margin (ambiguous) preference pairs where the reward model is most uncertain, and iteratively refines the training distribution via hard-sample augmentation. We provide theoretical guarantees showing that this strategy increases the average curvature of the loss function hence enhance information and improves conditioning, along with empirical results demonstrating consistent gains over uniform augmentation for robust reward modeling.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [84] [Detecting nonequilibrium phase transitions via continuous monitoring of space-time trajectories and autoencoder-based clustering](https://arxiv.org/abs/2602.17341)
*Erik Fitzner,Francesco Carnazza,Federico Carollo,Igor Lesanovsky*

Main category: quant-ph

TL;DR: A machine learning method detects nonequilibrium quantum phase transitions using only continuous measurement time-records, bypassing the need for prior knowledge of order parameters or full quantum state tomography.


<details>
  <summary>Details</summary>
Motivation: Traditional characterization of quantum collective behavior requires known order parameters and extensive projective measurements for quantum state estimation, which is experimentally demanding. Continuous monitoring of open quantum systems provides accessible space-time resolved output data.

Method: Proposes a machine learning approach trained directly on measurement time-series data (e.g., heterodyne/photon-counting records) from continuously monitored quantum systems to identify phase transitions without predefined order parameters.

Result: Successfully benchmarks the method on the quantum contact process—a challenging nonequilibrium model with absorbing-state phase transitions—demonstrating effective detection of phase transitions from experimental-grade measurement data.

Conclusion: Machine learning enables practical detection of nonequilibrium quantum phase transitions using only readily available continuous monitoring data, overcoming key experimental limitations in quantum state characterization.

Abstract: The characterization of collective behavior and nonequilibrium phase transitions in quantum systems is typically rooted in the analysis of suitable system observables, so-called order parameters. These observables might not be known a priori, but they may in principle be identified through analyzing the quantum state of the system. Experimentally, this can be particularly demanding as estimating quantum states and expectation values of quantum observables requires a large number of projective measurements. However, open quantum systems can be probed in situ by monitoring their output, e.g. via heterodyne-detection or photon-counting experiments, which provide space-time resolved information about their dynamics. Building on this, we present a machine-learning approach to detect nonequilibrium phase transitions from the measurement time-records of continuously-monitored quantum systems. We benchmark our method using the quantum contact process, a model featuring an absorbing-state phase transition, which constitutes a particularly challenging test case for the quantum simulation of nonequilibrium processes.

</details>


### [85] [Finite-Temperature Dynamical Phase Diagram of the $2+1$D Quantum Ising Model](https://arxiv.org/abs/2602.16772)
*Lucas Katschke,Roland C. Farrell,Umberto Borla,Lode Pollet,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 开发高效平衡量子蒙特卡洛(QMC)方法绘制有限温度动力学相图，避免直接模拟含时演化，成功绘制2+1D量子伊辛模型淬火后的动力学相图，发现有序相中淬火可冷却系统及顺磁-铁磁相变温度区间。


<details>
  <summary>Details</summary>
Motivation: 建立非平衡量子多体普适性理论框架需绘制有限温度动力学相图，但非平衡动力学中体积律纠缠导致计算困难。

Method: 利用能量守恒和遍历量子系统的自热化特性，采用平衡量子蒙特卡洛(QMC)框架计算有限温度动力学相图，避免直接模拟幺正时间演化。

Result: 绘制了2+1D量子伊辛模型在初始热态下横向场淬火后的动力学相图：发现有序相中淬火可冷却系统；存在初始温度区间可实现顺磁(PM)→铁磁(FM)相变。

Conclusion: 该方法无需模拟含时演化，适用于其他晶格结构和相互作用多体系统，并提出现代数字量子硬件实验方案直接探测动力学相及其实时形成。

Abstract: Mapping finite-temperature dynamical phase diagrams of quantum many-body models is a necessary step towards establishing a framework of far-from-equilibrium quantum many-body universality. However, this is quite difficult due, in part, to the severe challenges in representing the volume-law entanglement that is generated under nonequilibrium dynamics at finite temperatures. Here, we address these challenges with an efficient equilibrium quantum Monte Carlo (QMC) framework for computing the finite-temperature dynamical phase diagram. Our method uses energy conservation and the self-thermalizing properties of ergodic quantum systems to determine observables at late times after a quantum quench. We use this technique to chart the dynamical phase diagram of the $2+1$D quantum Ising model generated by quenches of the transverse field in initial thermal states. Our approach allows us to track the evolution of dynamical phases as a function of both the initial temperature and transverse field. Surprisingly, we identify quenches in the ordered phase that cool the system as well as an interval of initial temperatures where it is possible to quench from the paramagnetic (PM) to ferromagnetic (FM) phases. Our method gives access to dynamical properties without explicitly simulating unitary time evolution, and is immediately applicable to other lattice geometries and interacting many-body systems. Finally, we propose a quantum simulation experiment on state-of-the-art digital quantum hardware to directly probe the predicted dynamical phases and their real-time formation.

</details>


### [86] [Controlling energy spectra and skin effect via boundary conditions in non-Hermitian lattices](https://arxiv.org/abs/2602.16780)
*S Rahul,Pasquale Marra*

Main category: quant-ph

TL;DR: This paper investigates how generalized boundary conditions, induced by complex boundary hopping amplitudes, modulate spectral properties (real/complex energy spectra, exceptional points) and eigenmode localization (non-Hermitian skin effect) in the Hatano-Nelson model.


<details>
  <summary>Details</summary>
Motivation: The modulation of non-Hermitian phenomena (like the skin effect and exceptional points) by generalized boundary conditions was previously unexplored and not understood.

Method: The Hatano-Nelson model with generalized boundary conditions was analyzed using similarity transformations to determine the conditions for specific spectral and localization behaviors.

Result: 1. Conditions for obtaining real energy spectra and the skin effect were determined. 2. The emergence of exceptional points (where spectra transition from real to complex) was identified. 3. Precise tuning of boundary hopping amplitudes was shown to control the localization of eigenmodes (skin effect).

Conclusion: This work reveals the high sensitivity of spectral and localization properties to boundary conditions, providing a framework for engineering quantum lattice models with tailored features for potential quantum device applications.

Abstract: Non-Hermitian systems exhibit unique spectral properties, including the non-Hermitian skin effect and exceptional points, often influenced by boundary conditions. The modulation of these phenomena by generalized boundary conditions remains unexplored and not understood. Here, we analyze the Hatano-Nelson model with generalized boundary conditions induced by complex hopping amplitudes at the boundary. Using similarity transformations, we determine the conditions yielding real energy spectra and skin effect, and identify the emergence of exceptional points where spectra transition from real to complex. We demonstrate that tuning the boundary hopping amplitudes precisely controls the non-Hermitian skin effect, i.e., the localization of eigenmodes at the lattice edges. These findings reveal the sensitivity of spectral and localization properties to boundary conditions, providing a framework for engineering quantum lattice models with tailored spectral and localization features, with potential applications in quantum devices.

</details>


### [87] [Entropic Barriers and the Kinetic Suppression of Topological Defects](https://arxiv.org/abs/2602.16777)
*Yi-Lin Tsao,Zhu-Xi Luo*

Main category: quant-ph

TL;DR: 提出熵保护机制，通过耦合介观辅助库产生温升自由能垒，抑制拓扑缺陷稳定量子相。Ising链呈现三段式关联演化，二维有限系统逻辑错误率双重降低，并给出Rydberg实验方案。


<details>
  <summary>Details</summary>
Motivation: 拓扑缺陷在有限温度下破坏量子相，传统能隙保护易受热涨落超越。需发展不依赖能隙的互补保护机制。

Method: 构建系统-介观库耦合模型，利用维度M调控熵产生温变自由能垒。解析研究Ising链，数值研究二维拓扑序，设计双物种Rydberg阵列实验实现。

Result: Ising链关联长度呈线性-平台-崩溃三段式；二维有限尺寸稳定性显著增强；缺陷产生与输运独立抑制，逻辑错误双重参数降低；可推广至BKT相变。

Conclusion: 熵保护提供被动可扩展的量子相稳定新途径，突破能隙限制，为量子存储和实验实现提供实用方案。

Abstract: Many quantum phases, from topological orders to superfluids, are destabilized at finite temperature by the proliferation and motion of topological defects such as anyons or vortices. Conventional protection mechanisms rely on energetic gaps and fail once thermal fluctuations exceed the gap scale. Here we examine a complementary mechanism of entropic protection, in which defect nucleation is suppressed by coupling to mesoscopic auxiliary reservoirs of dimension $M$, generating an effective free-energy barrier that increases with temperature. In the Ising chain, this produces a characteristic three-regime evolution of the correlation length as a function of temperature - linear growth, entropy-controlled plateau, and eventual breakdown - indicating a general modification of defect behavior. Focusing on two spatial dimensions, where true finite-temperature topological order is forbidden in the thermodynamic limit, we show that entropic protection can nevertheless strongly enhance stabilization at finite system size, the regime directly relevant for quantum memory and experiments. Owing to the topological character of the defects, creation and transport are independently suppressed, yielding a double parametric reduction of logical errors in the entropic toric code and enhanced coherence when the framework is extended to Berezinskii-Kosterlitz-Thouless transitions. Entropic barriers thus provide a passive and scalable route to stabilizing quantum phases in experimentally relevant regimes. We propose an experimental setup for entropic toric code using dual species Rydberg arrays with dressing.

</details>


### [88] [Dissipation as a Resource: Synchronization, Coherence Recovery, and Chaos Control](https://arxiv.org/abs/2602.16817)
*Debabrata Mondal,Lea F. Santos,S. Sinha*

Main category: quant-ph

TL;DR: 该研究颠覆了耗散总是有害的传统观念，证明在双组分玻色-约瑟夫森结中，耗散可作为资源调控量子动力学，实现同步振荡、短暂混沌与稳态混沌等相，并恢复量子相干性。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为耗散是量子控制的障碍，会引起退相干和不可逆性，但本文旨在证明耗散可作为一种资源来重塑相互作用量子体系的动力学行为。

Method: 采用实验可行的双组分玻色-约瑟夫森结模型，通过调节实验参数（如相互作用强度和势阱倾斜）来研究耗散驱动的不同动力学相。

Result: 研究发现三种依赖参数的动力学行为：1）弱相互作用下，体系呈现耗散诱导的同步相位锁定振荡，类似边界时间晶体；2）较强相互作用引发耗散相变，进入自囚禁混沌态，耗散能调节混沌寿命并实现长时间相干恢复；3）加入可控倾斜势后，短暂混沌可转为稳态混沌。此外，标准谱诊断无法区分两种混沌态，仅反映短时不稳定性。

Conclusion: 耗散是工程化调控动力学相、恢复量子相干性以及控制混沌行为持续时间与信息置乱的有力工具，为量子控制和动力学相工程提供了新视角。

Abstract: Dissipation is commonly regarded as an obstacle to quantum control, as it induces decoherence and irreversibility. Here we demonstrate that dissipation can instead be exploited as a resource to reshape the dynamics of interacting quantum systems. Using an experimentally realizable Bose-Josephson junction containing two bosonic species, we demonstrate that dissipation enables distinct dynamical behaviors: synchronized phase-locked oscillations, transient chaos with long-time coherence recovery, and steady-state chaos. The emergence of each behavior is determined by experimentally tunable parameters. At weak interactions, the two components synchronize despite dissipation, exhibiting long-lived coherent oscillations reminiscent of a boundary time crystal. Stronger interactions induce a dissipative phase transition into a self-trapped regime accompanied by chaotic dynamics. Remarkably, dissipation regulates the lifetime of chaos and enables the recovery of coherence at long times. By introducing a controlled tilt between the wells, transient chaos can be converted into persistent steady-state chaos. We further show that standard spectral diagnostics fail to distinguish between the two chaotic regimes, revealing that spectral statistics primarily reflect short-time instability. These results establish dissipation as a powerful tool for engineering dynamical phases, restoring quantum coherence, and controlling the duration of chaotic behavior and information scrambling.

</details>


### [89] [Quantum Circuits as a Dynamical Resource to Learn Nonequilibrium Long-Range Order](https://arxiv.org/abs/2602.16788)
*Fabian Ballar Trigueros,Markus Heyl*

Main category: quant-ph

TL;DR: 量子电路可突破平衡态统计约束，在1D系统中生成具有长程序的非常规量子物态，展现超越平衡态的量子序。


<details>
  <summary>Details</summary>
Motivation: 平衡态统计系综对量子物相有严格限制（如Mermin-Wagner定理禁止低维系统长程序），需探索非平衡动力学作为新资源以突破这些约束。

Method: 构建变分量子电路，在1D系统中生成有限能量密度下的对称破缺态和对称保护拓扑态。

Result: 成功实现平衡态中无法存在的长程序；所生成态具有类GHZ态的高量子Fisher信息，且对局域测量鲁棒。

Conclusion: 相干量子动力学是构建非平衡物相的有力工具，为超越平衡态系综限制的量子序研究开辟新路径。

Abstract: Equilibrium statistical ensembles impose stringent constraints on phases of quantum matter. For example, the Mermin-Wagner theorem prohibits long-range order in low-dimensional systems beyond the ground state. Here, we show that quantum circuits can learn states of matter with long-range order that are inaccessible in equilibrium. We construct variational quantum circuits that generate symmetry-broken and symmetry-protected topological states with long-range order in one-dimensional systems at finite energy density, where equilibrium states are typically featureless. Importantly, the learned states can exhibit unconventional features with enhanced metrological properties such as a quantum Fisher information close to a GHZ state, but robust against local measurements. Our work establishes coherent quantum dynamics as a powerful resource for engineering nonequilibrium phases of matter, opening a path toward a broader dynamical scope of quantum order beyond the constraints of equilibrium ensembles.

</details>


### [90] [Les Houches lectures on random quantum circuits and monitored quantum dynamics](https://arxiv.org/abs/2602.17258)
*Romain Vasseur*

Main category: quant-ph

TL;DR: 这些讲义将统计力学哲学应用于理想和监控随机量子电路中量子信息动力学的研究，其中单个实现的精确描述通常是难以处理的。


<details>
  <summary>Details</summary>
Motivation: 由于随机量子电路中单个实现的精确描述通常难以处理，因此动机是应用统计力学的方法来研究量子信息动力学。

Method: 方法是将统计力学的哲学应用于研究理想和监控随机量子电路中量子信息的动力学。

Result: 讲义提供了使用统计力学理解量子信息动力学的框架，但抽象中未明确具体结果。

Conclusion: 结论是统计力学为研究难以精确处理的复杂量子系统提供了有效途径。

Abstract: These lecture notes are based on lectures given by the author at the Les Houches 2025 summer school on "Exact Solvability and Quantum Information". The central theme of these notes is to apply the philosophy of statistical mechanics to study the dynamics of quantum information in ideal and monitored random quantum circuits -- for which an exact description of individual realizations is expected to be generically intractable.

</details>


### [91] [When Does Quantum Annealing Outperform Classical Methods? A Gradient Variance Framework](https://arxiv.org/abs/2602.16875)
*Vishwajeet Ohal,Pierre Boulanger*

Main category: quant-ph

TL;DR: 提出基于梯度方差、问题规模和能景特征的量子-经典计算决策框架：高梯度方差(>0.3)和复杂能景用量子退火，低方差(<0.2)小规模问题用经典方法，超大规模问题采用混合方案


<details>
  <summary>Details</summary>
Motivation: 解决实际应用中如何根据问题特征选择量子退火或经典优化方法的决策难题，避免因方法选择不当导致计算效率低下或结果质量不佳

Method: 通过实验分析不同问题特征（梯度方差、能景结构、问题规模）对量子/经典方法性能的影响，建立量化决策阈值

Result: 1) 量子退火适用条件：梯度方差>0.3+能景有窄势垒+变量<5000+时间预算>10秒 2) 经典方法适用条件：梯度方差<0.2+小规模+低质量要求 3) 混合方法适用超量子容量但结构良好的问题

Conclusion: 形成三层次决策体系：量子处理高复杂度问题，经典处理平滑小规模问题，混合方案解决超大规模优化，为实践者提供可量化的方法选择指南

Abstract: Based on our experimental findings, we propose the following decision framework for practitioners. Quantum annealing is recommended when the problem formulation QUBO exhibits a high gradient variance (greater than 0.3) and the energy landscape contains numerous thin barriers characterized by sharp peaks and narrow valleys. Additionally, quantum approaches are particularly suitable when classical methods are observed to get trapped in local minima, the problem size is manageable given hardware constraints (less than 5000 variables for pure quantum annealing), and the time overhead of approximately 10 seconds is acceptable for the application.
  In contrast, classical methods are recommended when the gradient variance is low (less than 0.2), indicating smooth landscapes where quantum tunneling provides little advantage. Classical approaches are also preferable when the problem size is small and classical solvers can provide nearly instantaneous results, when solution quality requirements are modest and local optima suffice, or when hardware access or cost is a limiting factor.
  For problems that exceed pure quantum capacity but possess a favorable landscape structure, hybrid approaches combining quantum and classical techniques are recommended. Such hybrid methods are particularly effective when decomposition quality can be verified and both solution quality and scalability are important considerations.

</details>


### [92] [Optimal speed-up of multi-step Pontus-Mpemba protocols](https://arxiv.org/abs/2602.17296)
*Marco Peluso,Reinhold Egger,Andrea Nava*

Main category: quant-ph

TL;DR: This paper extends the Mpemba effect to open quantum systems, investigating multi-step and continuous Pontus-Mpemba protocols governed by time-inhomogeneous Lindblad equations, revealing dynamically generated shortcuts and non-Markovian behavior from time-dependent dissipation rates.


<details>
  <summary>Details</summary>
Motivation: The classical Mpemba effect demonstrates counterintuitive nonequilibrium shortcuts in thermal processes. When preparation time is included, Pontus-Mpemba effects emerge. This research aims to explore whether similar shortcuts exist in quantum systems, understand the crossover between quasi-static and sudden-quench regimes, and investigate non-Markovian dynamics beyond standard quantum master equation approaches.

Method: The authors employed time-inhomogeneous Lindblad master equations to model open quantum system dynamics. They analyzed multi-step Pontus-Mpemba protocols and their continuous limit (infinitely many steps), focusing on how time-dependent dissipation rates affect the system's evolution and shortcut generation.

Result: The study found that time-dependent dissipation rates generate dynamically created shortcuts in quantum systems, produce non-Markovian behavior, and reveal rich dynamical regimes inaccessible within conventional Markovian frameworks. The work characterizes the crossover between quasi-static and sudden-quench limits.

Conclusion: Quantum systems can exploit time-dependent control to achieve nonequilibrium shortcuts analogous to classical Mpemba effects, with the added complexity of non-Markovian dynamics. This opens new pathways for quantum thermal engineering and demonstrates that quantum advantages in relaxation processes emerge through temporally modulated dissipation beyond standard Markovian descriptions.

Abstract: The classical Mpemba effect is the counterintuitive phenomenon where hotter water freezes faster than colder water due to the breakdown of Newton's law of cooling after a sudden temperature quench. The genuine nonequilibrium post-quench dynamics allows the system to evolve along effective shortcuts absent in the quasi-static regime. When the time needed for preparing the (classical or quantum) system in the hotter initial state is included, we encounter so-called Pontus-Mpemba effects. We here investigate multi-step Pontus-Mpemba protocols for open quantum systems whose dynamics is governed by time-inhomogeneous Lindblad master equations. In the limit of infinitely many steps, one arrives at continuous Pontus-Mpemba protocols. We study the crossover between the quasi-static and the sudden-quench regime, showing the presence of dynamically generated shortcuts achieved for time-dependent dissipation rates. Time-dependent rates can also cause non-Markovian behavior, highlighting the existence of rich dynamical regimes accessible beyond the Markovian framework.

</details>


### [93] [In situ calibration of microwave attenuation and gain using a cryogenic on-chip attenuator](https://arxiv.org/abs/2602.16889)
*Thomas Descamps,Linus Andersson,Vittorio Buccheri,Simon Sundelin,Mohammed Ali Aamir,Simone Gasparinetti*

Main category: quant-ph

TL;DR: 提出一种基于片上铬衰减器的自校准低温噪声源，通过比较焦耳加热与微波加热产生的约翰逊-奈奎斯特噪声，无需已知衰减器温度即可精确测定超导量子电路输入线衰减及放大链增益。


<details>
  <summary>Details</summary>
Motivation: 超导量子电路亟需对微波衰减与放大链噪声进行精确的原位校准，而现有方法依赖衰减器温度等参数，存在不便与局限。

Method: 在稀释制冷机混频腔级集成可纳米瓦功率电阻加热的铬衰减器，作为共轴微波线的一部分，通过测量放大链输出的约翰逊-奈奎斯特噪声，对比焦耳加热与微波加热模式，反推出线路衰减与链增益。

Result: 该器件响应时间达毫秒级，对制冷机基板加热可忽略，成功在4-8 GHz频段内表征了低温放大链的增益与附加噪声。

Conclusion: 此方法为超导量子比特读出中近量子极限参量放大器的表征提供了简单而准确的技术路径。

Abstract: Accurate in situ calibration of microwave attenuation and amplification-chain noise is essential for superconducting quantum circuits. We demonstrate a compact, self-calibrating cryogenic noise source based on an on-chip chromium attenuator that can be resistively heated with nanowatt-level power and directly integrated into a coaxial microwave line at the mixing-chamber stage. By comparing Johnson-Nyquist noise generated by Joule and microwave heating, measured through the amplification chain, the attenuation of the input line, and hence the gain of the chain, is determined without requiring knowledge of the attenuator temperature. The device exhibits millisecond-scale response times and negligible heating of the cryostat base plate. Using this approach, we determine the gain and added noise of a cryogenic amplification chain over the 4-8 GHz band. Our results provide a simple and accurate method to characterize near-quantum-limited parametric amplifiers used in superconducting-qubit readout.

</details>


### [94] [From superradiance to collective EIT in three-level ensembles](https://arxiv.org/abs/2602.16892)
*Hugo Sanchez,Luis F. A. da Silva,Mickel A. Ponte,Miled H. Y. Moussa,Norton G. de Almeida*

Main category: quant-ph

TL;DR: 该研究揭示了三能级系统在迪克极限下超辐射与电磁感应透明（EIT）的统一关联：瞬态超辐射峰强遵循I_max∝N²并存在1/lnN的普适有限尺寸修正；稳态下集体展宽虽增强吸收，却反常地使群速度按v_g∝N²提升，揭示了合作效应对慢光延迟的根本限制。


<details>
  <summary>Details</summary>
Motivation: 建立超辐射发射与电磁感应透明（EIT）之间的统一理论框架，解决稠密介质中集体效应对量子干涉现象的影响机制，为慢光技术和量子存储提供理论基础。

Method: 提出"代表性原子主方程"模型，精确复现超辐射与EIT动力学，成功整合集体反馈和N依赖展宽效应，并与对称子空间精确解高度吻合。

Result: 1) 瞬态超辐射峰强I_max∝N²，存在普适有限尺寸修正|ξ(N)-2|∝1/lnN；2) 稳态下集体展宽使群速度反常提升至v_g∝N²（尽管v_g≪c），揭示合作相互作用对慢光延迟的根本限制。

Conclusion: 该统一框架 bridging 瞬态超辐射与稳态量子干涉，表明稠密介质中合作效应会限制慢光性能，对量子存储器和精密测量技术的设计具有直接指导意义。

Abstract: We investigate the collective dynamics of a three-level ensemble under the Dicke limit, revealing a unified connection between superradiant emission and electromagnetically induced transparency (EIT). Our results show that the transient superradiant burst exhibits the expected peak intensity scaling $I_{\max}\!\sim\! N^2$, with a universal finite-size correction $|ξ(N)-2|\!\sim\! 1/\ln N$ that governs the apparent scaling exponent in realistic ensembles. In the stationary regime, collective broadening modifies the EIT response: although it typically enhances absorption, it counterintuitively increases the group velocity, leading to a relative scaling $v_g\!\propto\! N^2$, even while $v_g\!\ll\! c$. This effect suggests that cooperative interactions fundamentally limit the achievable slow-light delay in dense media. To achieve these results, we derive a representative-atom master equation that quantitatively reproduces both the superradiant and EIT regimes, in excellent agreement with the exact symmetric-subspace dynamics and correctly incorporating collective feedback and $N$-dependent broadening. This unified framework bridges transient superradiant emission and steady-state quantum interference, with direct implications for slow light, quantum memories, and precision metrology.

</details>


### [95] [A Study of Entanglement and Ansatz Expressivity for the Transverse-Field Ising Model using Variational Quantum Eigensolver](https://arxiv.org/abs/2602.17662)
*Ashutosh P. Tripathi,Nilmani Mathur,Vikram Tripathi*

Main category: quant-ph

TL;DR: 该论文研究NISQ时代VQE算法在简并和强纠缠体系中的本征态制备问题，通过在1-3维横向场Ising模型（最多27量子比特）上对比硬件高效和物理启发的ansatz性能。


<details>
  <summary>Details</summary>
Motivation: VQE是NISQ时代模拟多体系统的主流混合量子-经典算法，但其有效性依赖于本征态的忠实制备，这在简并和强纠缠情况下具有挑战性。

Method: 采用1D/2D/3D周期性边界条件的TFIM模型，系统规模达27量子比特，对比Qiskit的EfficientSU2、HVA和带对称性破缺的HVA三种ansatz，评估指标包括能量方差、纠缠熵、自旋关联和磁化强度。

Result: 摘要未提供具体研究结果数据，仅说明了研究框架和评估方法。

Conclusion: 摘要未明确总结结论，但研究暗示针对强纠缠和简并体系，物理启发的ansatz设计可能比纯硬件高效ansatz更重要。

Abstract: The Variational Quantum Eigensolver (VQE) is a leading hybrid quantum-classical algorithm for simulating many-body systems in the NISQ era. Its effectiveness, however, depends on the faithful preparation of eigenstates, which becomes challenging in degenerate and strongly entangled regimes. We study this problem using the transverse-field Ising model (TFIM) with periodic boundary conditions in one, two, and three dimensions, considering systems of up to 27 qubits. We employ different ansatzes: the hardware-efficient EfficientSU2 from Qiskit, the physics-inspired Hamiltonian Variational Ansatz (HVA) and HVA with symmetry breaking, and benchmark their performance using energy variance, entanglement entropy, spin correlations, and magnetization.

</details>


### [96] [Free Quantum Computing](https://arxiv.org/abs/2602.16927)
*Jacques Carette,Chris Heunen,Robin Kaarsgaard,Neil J. Ross,Amr Sabry*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum computing improves substantially on known classical algorithms for various important problems, but the nature of the relationship between quantum and classical computing is not yet fully understood. This relationship can be clarified by free models, that add to classical computing just enough physical principles to represent quantum computing and no more. Here we develop an axiomatisation of quantum computing that replaces the standard continuous postulates with a small number of discrete equations, as well as a free model that replaces the standard linear-algebraic model with a category-theoretical one. The axioms and model are based on reversible classical computing, isolate quantum advantage in the ability to take certain well-behaved square roots, and link to various quantum computing hardware platforms. This approach allows combinatorial optimisation, including brute force computer search, to optimise quantum computations. The free model may be interpreted as a programming language for quantum computers, that has the same expressivity and computational universality as the standard model, but additionally allows automated verification and reasoning.

</details>


### [97] [Adaptive Aborting Schemes for Quantum Error Correction Decoding](https://arxiv.org/abs/2602.16929)
*Sanidhay Bhambay,Prakash Murali,Neil Walton,Thirupathaiah Vasantam*

Main category: quant-ph

TL;DR: 提出用于量子纠错的自适应中止方案，该方案基于实时症状数据动态调整测量轮数，降低解码器开销并抑制表面码和色码的逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 现有量子纠错控制器即使早期数据已表明会出现错误，仍会执行所有预定症状测量轮次，导致资源浪费、解码器工作负载增加和系统延迟升高。

Method: 引入自适应中止模块，提前终止有风险的测量。在电路级退极化噪声模型下，比较固定深度解码（FD）、AdAbort和单步前瞻（OSLA）三种方案在表面码和色码上的表现。

Result: AdAbort显著优于其他方案，在码距从5增加到15时，对表面码的效率提升从5%增至35%，对色码从7%增至60%。

Conclusion: 自适应中止方案对实现高效可扩展的容错量子计算至关重要，是量子纠错领域的首个此类方法。

Abstract: Quantum error correction (QEC) is essential for realizing fault-tolerant quantum computation. Current QEC controllers execute all scheduled syndrome (parity-bit) measurement rounds before decoding, even when early syndrome data indicates that the run will result in an error. The resulting excess measurements increase the decoder's workload and system latency. To address this, we introduce an adaptive abort module that simultaneously reduces decoder overhead and suppresses logical error rates in surface codes and color codes under an existing QEC controller. The key idea is that initial syndrome information allows the controller to terminate risky shots early before additional resources are spent. An effective scheme balances the cost of further measurement against the restart cost and thus increases decoder efficiency.
  Adaptive abort schemes dynamically adjust the number of syndrome measurement rounds per shot using real-time syndrome information. We consider three schemes: fixed-depth (FD) decoding (the standard non-adaptive approach used in current state-of-the-art QEC controllers), and two adaptive schemes, AdAbort and One-Step Lookahead (OSLA) decoding. For surface and color codes under a realistic circuit-level depolarizing noise model, AdAbort substantially outperforms both OSLA and FD, yielding higher decoder efficiency across a broad range of code distances. Numerically, as the code distance increases from 5 to 15, AdAbort yields an improvement that increases from 5% to 35% for surface codes and from 7% to 60% for color codes.
  To our knowledge, these are the first adaptive abort schemes considered for QEC. Our results highlight the potential importance of abort rules for increasing efficiency as we scale to large, resource-intensive quantum architectures.

</details>


### [98] [Fault-tolerant interfaces for quantum LDPC codes](https://arxiv.org/abs/2602.16948)
*Matthias Christandl,Omar Fawzi,Ashutosh Goswami*

Main category: quant-ph

TL;DR: 实现恒定空间开销的容错量子态制备，相比之前的多对数级开销有明显改进


<details>
  <summary>Details</summary>
Motivation: 在噪声量子计算机上制备量子态时，无论采用何种协议，门噪声都会影响O(δ)比例的量子比特。此前容错构造需要多对数级空间开销，亟需降低资源消耗。

Method: 构建用于量子LDPC码的容错接口，通过逐步降低编码保护级别同时增加并行解码的码块数量，避免错误堆积和开销瓶颈。

Result: 在信息编码于多个码块时，实现了恒定空间开销的容错量子态制备，空间效率显著优于先前构造。

Conclusion: 该方法通过动态调整保护级别和并行解码规模，有效解决了容错量子计算中的空间开销瓶颈问题，为实用化量子计算提供了更高效的资源利用方案。

Abstract: The preparation of a quantum state using a noisy quantum computer (gate noise strength $δ$), will necessarily affect an O($δ$)-fraction of the qubits, no matter which protocol is used. Here, we show that fault-tolerant quantum state preparation can be achieved with constant space overhead improving on previous constructions requiring polylogarithmic overhead.
  To achieve this, we add to the toolbox of fault-tolerant schemes for circuits with quantum input and output. More specifically, we construct fault-tolerant interfaces that decrease the level of protection for quantum low-density parity-check (LDPC) codes. When information is encoded in multiple code blocks, our interfaces have constant space overhead.
  In our decoder construction that change the level of protection by an arbitrary amount, we circumvent bottlenecks to error pileup and overhead by gradual lowering of the level of encoding at the same time as we increase the number of blocks on which decoding is carried out simultaneously.

</details>


### [99] [Retrieving the Baby: Reichenbach's Principle, Bell Locality, and Selection Bias](https://arxiv.org/abs/2602.16985)
*Huw Price*

Main category: quant-ph

TL;DR: 该文挑战贝尔定理的传统解释，指出贝尔忽略的"婴儿"是选择偏差，认为贝尔非定域性可能源于选择效应而非真正违反定域性，对因果建模和统计学有重要启示


<details>
  <summary>Details</summary>
Motivation: 回应贝尔在《新烹调法》中对"可分解性"推导步骤的警告，试图找回被忽视的"婴儿"——选择偏差在量子关联中的作用

Method: 从因果发现的核心原则——赖欣巴赫共同原因原则（PCC）出发，论证选择偏差相关不受PCC约束，并将EPR-Bell关联归入此例外范畴

Result: 揭示可分解性失效可解释为选择偏差产物（类似对撞偏倚），无需在概念层面违反直觉的定域性，且选择效应在量子现象中普遍存在

Conclusion: 贝尔非定域性争议可能源于方法论缺陷而非物理实在，该结论重塑定域性争论框架，并为统计学和因果推断领域提供量子现象的新解释视角

Abstract: In his late piece 'La nouvelle cuisine' (Bell 1990), John Bell describes the steps from an intuitive, informal principle of locality to a mathematical rule called Factorizability. This rule stipulates that when possible past causes are held fixed, the joint probabilities of outcomes of spacelike separated measurements, conditional on measurement settings, be the product of the local conditional probabilities individually. Bell shows that Factorizability conflicts with predictions of QM, predictions since confirmed in many experiments. However, Bell warns his readers that the steps leading to Factorizability should 'be viewed with the utmost suspicion'. He says that 'it is precisely in cleaning up intuitive ideas for mathematics that one is likely to throw the baby out with the bathwater' (1990, 239). Bell's suspicions were well-founded, for he himself misses an important baby. Here we retrieve and identify it: it is selection bias. We explain how failure of Factorizability may be regarded as a selection artefact, requiring no violation of locality in the intuitive, conceptual sense with which Bell begins his analysis. The argument begins with a central principle of causal discovery, Reichenbach's Principle of Common Cause (PCC). It is well known that correlations due to selection bias are not subject to PCC. Several writers have proposed that EPR-Bell correlations are also an exception to PCC, but it has not been noticed that they fall under this well-known exclusion. The point is relevant not only to the status of Bell nonlocality, but also for statistics and causal modeling. For these fields, the news is that selection effects play a ubiquitous role in quantum phenomena, in a form akin to collider bias.

</details>


### [100] [Weak-Value Amplification for Longitudinal Phase Measurements Approaching the Shot-Noise Limit Characterized by Allan Variance](https://arxiv.org/abs/2602.17035)
*Jing-Hui Huang,Xiang-Yun Hu*

Main category: quant-ph

TL;DR: This paper quantitatively demonstrates that weak-value amplification (WVA) achieves near-optimal, shot-noise-limited precision in measuring attosecond-scale time delays, validating its superiority over conventional methods under fixed photon constraints and technical noise.


<details>
  <summary>Details</summary>
Motivation: To rigorously evaluate and validate whether weak-value amplification (WVA) can achieve theoretically predicted optimal noise performance (approaching the shot noise limit) in practical precision metrology, especially under constraints of fixed detected photon number and detector saturation where conventional methods falter.

Method: Applying Allan variance analysis to experimental data from a double-slit interferometry setup measuring longitudinal phase shifts (time delays), comparing WVA performance across different averaging intervals (T) and detected photon numbers (N_r).

Result: 1) Achieved measurement of few-attosecond time delays with shot-noise-limited performance at short averaging intervals (T=0.01-0.1 s), showing a 100x (two orders of magnitude) variance reduction compared to prior longer-interval (T=300 s) implementations. 2) Demonstrated that the noise floor scales as 1/N_r, confirming shot-noise-limited operation. 3) Experimentally validated that WVA outperforms conventional methods under fixed photon flux and technical noise, as predicted by theory.

Conclusion: WVA provides a rigorous, near-optimal noise performance benchmark for precision optical metrology, particularly advantageous for high-frequency signal detection applications like gravitational-wave observatories. This work conclusively establishes WVA's practical superiority in real-world measurement scenarios with photon constraints.

Abstract: We report a quantitative evaluation of weak-value amplification (WVA) for longitudinal phase measurements using Allan variance analysis. Building on a recent double-slit interferometry experiment with real weak values [Phys. Rev. Lett. 134, 080802 (2025)], our Allan variance analysis demonstrates measurement of a few attosecond time delay approaching the shot noise limit at short averaging intervals of $T$ = $0.01-0.1$ s, representing two orders of magnitude variance reduction compared to the $T=300$ s operating point in prior implementations. We demonstrate that the Allan-variance noise floor scales with the inverse of the detected photon number $1/N_r$, confirming shot-noise-limited operation with WVA. Furthermore, this $1/N_r$ scaling experimentally validates that WVA can outperform conventional measurement under fixed detected photon number and detector saturation, in the presence of technical noise, as theoretically predicted [Phys. Rev. Lett. 118, 070802 (2017)]. Our results provide rigorous, quantitative evidence of the near-optimal noise performance achievable with WVA, establishing a new benchmark for precision optical metrology. This advancement is particularly relevant to applications such as gravitational-wave detection, where signals predominantly occupy the high-frequency regime ($>10$ Hz).

</details>


### [101] [Quantum-Channel Matrix Optimization for Holevo Bound Enhancement](https://arxiv.org/abs/2602.17065)
*Hong Niu,Chau Yuen,Alexei Ashikhmin,Lajos Hanzo*

Main category: quant-ph

TL;DR: 针对量子信道优化问题，本文提出了一种统一的投影梯度上升算法，在固定输入系综条件下最大化Holevo界。理论分析算法复杂度，仿真实验表明该量子信道优化方法比输入系综优化能获得更高的Holevo界。


<details>
  <summary>Details</summary>
Motivation: 量子通信具有革命性潜力，而Holevo界是衡量量子信道经典信息传输能力的关键指标。然而，由于Holevo界同时依赖于量子输入系综和量子信道，其计算与优化极具挑战性。

Method: 提出一种统一的投影梯度上升算法，在给定固定量子输入系综的前提下，直接对量子信道进行优化以最大化Holevo界，并提供了详细的算法复杂度分析。

Result: 仿真结果表明，与优化输入系综的方法相比，优化量子信道能够获得更高的Holevo界，从而提升量子信道的经典信息传输能力。

Conclusion: 该量子信道优化算法有效解决了Holevo界最大化难题，为提升量子通信系统性能提供了新思路，具有重要的理论和实践价值。

Abstract: Quantum communication holds the potential to revolutionize information transmission by enabling secure data exchange that exceeds the limits of classical systems. One of the key performance metrics in quantum information theory, namely the Holevo bound, quantifies the amount of classical information that can be transmitted reliably over a quantum channel. However, computing and optimizing the Holevo bound remains a challenging task due to its dependence on both the quantum input ensemble and the quantum channel. In order to maximize the Holevo bound, we propose a unified projected gradient ascent algorithm to optimize the quantum channel given a fixed input ensemble. We provide a detailed complexity analysis for the proposed algorithm. Simulation results demonstrate that the proposed quantum channel optimization yields higher Holevo bounds than input ensemble optimization.

</details>


### [102] [Mesoscopic Spin Coherence in a Disordered Dark Electron Spin Ensemble](https://arxiv.org/abs/2602.17074)
*Taewoong Yoon,Sangwon Oh,Junghyun Lee,Hyunyong Choi*

Main category: quant-ph

TL;DR: 该研究在金刚石无序替代氮(P1)中心系综中观测到相干介观自旋态，通过迭代Hartmann-Hahn协议将氮空位(NV)中心的极化转移至P1系综，实现室温热平衡740倍的增强效应，并观察到集体Rabi振荡和长寿命相干性，揭示了相干驱动与局域无序竞争的相变行为，为量子传感和多体模拟提供了新资源。


<details>
  <summary>Details</summary>
Motivation: 在固态量子技术中，如何利用偶极自旋环境作为可控量子资源是一个核心挑战。

Method: 在金刚石中替代氮(P1)中心的无序系综中观测到相干介观自旋态；采用迭代Hartmann-Hahn协议将极化从密集氮空位(NV)中心转移到P1系综；通过差分读出技术实现对比增强。

Result: P1自旋系综表现出集体Rabi振荡、长寿命的自旋锁定和Hahn-echo相干性；发现饱和极化存在相干驱动与局域无序竞争的交叉现象，为系统内在无序性提供了定量度量。

Conclusion: 该结果为利用暗电子自旋系综作为量子传感和量子多体模拟的稳健资源奠定了基础。

Abstract: Harnessing dipolar spin environments as controllable quantum resources is a central challenge in solid-state quantum technologies. Here, we report the observation of a coherent mesoscopic spin state in a disordered ensemble of substitutional nitrogen (P1) centers in diamond. An iterative Hartmann-Hahn protocol transfers polarization from dense nitrogen-vacancy (NV) centers to a P1 ensemble, yielding a 740-fold enhancement over room-temperature thermal equilibrium as revealed by differential readout. The resulting mesoscopic P1 spin ensemble exhibits collective Rabi oscillations and long-lived spin-lock and Hahn-echo coherences. We identify a crossover in the saturation polarization arising from the competition between coherent driving and local disorder, providing a quantitative measure of the system's intrinsic disorder. These results establish a foundation for utilizing dark electron spin ensembles as robust resources for quantum sensing and quantum many-body simulation.

</details>


### [103] [Boosting the Performance of a Lipkin-Meshkov-Glick Quantum Battery via Symmetry-Breaking Quenches and Bosonic Baths](https://arxiv.org/abs/2602.17121)
*Le Bin Ho,Duc Tuan Hoang,Tran Duong Anh-Tai,Thomas Busch,Thomás Fogarty*

Main category: quant-ph

TL;DR: 研究Lipkin-Meshkov-Glick模型中量子电池的充电性能，发现通过对称破缺相淬火可显著提升储能和有效功提取效率，弱耦合玻色浴也有类似效果但强耦合时饱和。


<details>
  <summary>Details</summary>
Motivation: 探索量子电池在不同相位和外部耦合条件下的充放电性能优化机制，为量子储能应用提供理论依据。

Method: 采用Lipkin-Meshkov-Glick模型，通过两种方式充电：1) 磁场强度突然淬火；2) 耦合玻色子振荡浴。分析对称相和对称破缺相初始状态下的电池性能差异。

Result: 从对称相淬火到破缺相可显著提升储能和稳定高效提取有效功（ergotropy）；弱耦合玻色浴时性能提升，但强耦合时储能和有效功趋于饱和。

Conclusion: 磁场动力学和环境耦合对量子电池充电性能优化至关重要，该机制为量子能量存储的实际应用提供了新思路。

Abstract: We explore the operation of quantum batteries in the Lipkin-Meshkov-Glick (LMG) model, when they are charged either through a sudden quench in the magnetic field strength or by coupling them to a bosonic oscillator bath. Through initializing the battery in either the symmetric or broken symmetry phases of the LMG model we analyze how the different spectral properties can affect the performance of both the charging and discharging of the battery. In particular, we show that by quenching the magnetic field strength from the symmetric phase to the broken phase, we can achieve a significant enhancement in stored energy, as well as stable and efficient ergotropy extraction. Similar observations can be made when introducing weak coupling between the battery with the bosonic bath, while the amount of stored work and ergotropy saturate at strong coupling. These findings emphasize the importance of the magnetic field dynamics and environmental coupling in optimizing charging performance, which could lead to practical applications in quantum energy storage.

</details>


### [104] [Phonon-enhanced strain sensitivity of quantum dots in two-dimensional semiconductors](https://arxiv.org/abs/2602.17212)
*Sumitra Shit,Yunus Waheed,Jithin Thoppil Surendran,Indrajeet Dhananjay Prasad,Kenji Watanabe,Takashi Taniguchi,Santosh Kumar*

Main category: quant-ph

TL;DR: Strain engineering enhances quantum dot emission energy sensitivity in ML-WS₂/WSe₂ via phonon confinement for quantum photonics


<details>
  <summary>Details</summary>
Motivation: Exploring strain engineering in 2D semiconductors (ML-TMDs) to tune light-matter interactions and create quantum functionalities like quantum dots (QDs) for quantum photonic networks.

Method: Combined cryogenic (4-94 K) micro-photoluminescence (μ-PL) and room-temperature micro-Raman spectroscopy to analyze strain-dependent emission of thousands of individual QDs in ML-WS₂/WSe₂ across heterostructures and piezoelectric devices.

Result: QDs show enhanced strain sensitivity (4× in WS₂, 2× in WSe₂) vs. delocalized excitons, causing broadened ensemble linewidths. This stems from strengthened low-energy phonon interactions due to quantum confinement.

Conclusion: Strain engineering enables spectral matching for solid-state/atomic/hybrid quantum photonic networks and reveals new phonon-QD interaction mechanisms in 2D semiconductors.

Abstract: Two-dimensional semiconductors have attracted considerable interest for integration into emerging quantum photonic networks. Strain engineering of monolayer transition-metal dichalcogenides (ML-TMDs) enables the tuning of light-matter interactions and associated optoelectronic properties, and generates new functionalities, including the formation of quantum dots (QDs). Here, we combine spatially resolved micro-photoluminescence ($μ$-PL) spectroscopy from cryogenic (4$\text{-}$94 K) to room temperature with micro-Raman spectroscopy at room temperature to investigate the strain-dependent emission energies of thousands of individual QDs in ML-WS$_2$ and ML-WSe$_2$, integrated across multiple heterostructures and a piezoelectric device. Compared with delocalized excitons, QDs in both materials exhibit enhanced strain sensitivities of their emission energies $-$ approximately fourfold in WS$_2$ and twofold in WSe$_2$ $-$ leading to pronounced broadening of the ensemble emission linewidth. Temperature-dependent $μ$-PL spectroscopy combined with dynamic strain tuning experiments further reveal that the enhanced strain sensitivity of individual QDs originates from strengthened interactions with low-energy phonons induced by quantum confinement. Our results demonstrate a versatile strain-engineering approach with potential for spectral matching across solid-state, atomic, and hybrid quantum photonic networks, and provide new insights into phonon-QD interactions in two-dimensional semiconductors.

</details>


### [105] [Near-single-domain superconducting aluminum films on GaAs(111)A with exceptional crystalline quality for scalable quantum circuits](https://arxiv.org/abs/2602.17249)
*Hsien-Wen Wan,Yi-Ting Cheng,Chao-Kai Cheng,Jui-Min Chia,Chien-Ting Wu,Sheng-Shiuan Yeh,Chia-Hung Hsu,Jueinai Kwo,Minghwei Hong*

Main category: quant-ph

TL;DR: 利用分子束外延技术在GaAs(111)A衬底上生长出近单晶域超导铝薄膜，实现了创纪录的低孪晶域比例和优异的晶体质量，为可扩展高相干超导量子比特提供了材料平台。


<details>
  <summary>Details</summary>
Motivation: 解决超导量子比特应用中铝薄膜孪晶域问题长期被认为难以实现的技术瓶颈，为实用化量子器件平台开发高质量超导材料。

Method: 采用分子束外延(MBE)在GaAs(111)A晶圆上生长铝薄膜，通过同步辐射X射线衍射、电子背散射衍射、原子力显微镜和扫描透射电镜等多手段表征。

Result: 19.4纳米和9.6纳米厚薄膜孪晶域比例分别低至0.00005和0.0003；方位角扫描半高宽窄至0.55°；θ摇摆曲线半高宽低至0.018°；表面原子级平滑，界面清晰；临界温度接近体材料值。

Conclusion: 成功建立了适用于可扩展高相干超导量子比特的材料平台，实现了此前认为无法达到的性能指标。

Abstract: We have reproducibly grown near-single-domain superconducting aluminum (Al) films on GaAs(111)A wafers using molecular beam epitaxy. Synchrotron X-ray diffraction revealed twin-domain ratios of 0.00005 and 0.0003 for 19.4-nm- and 9.6-nm-thick films, respectively-the lowest reported for Al on any substrate and long considered unattainable for practical device platforms. Azimuthal scans across off-normal Al{$11\bar{1}$} reflections exhibit narrow full width at half maximum (FWHM) values down to $0.55^\circ$, unmatched by epi-Al grown by any other method. Normal scans showed a well-defined (111) orientation with pronounced Pendellösung fringes, and $θ$-rocking-curve FWHM values down to $0.018^\circ$; the former indicates abrupt film-substrate and oxide-film interfaces. Electron backscatter diffraction mapping confirms macroscopic in-plane uniformity and the absence of $Σ$3 twin domains. Atomic force microscopy and scanning transmission electron microscopy confirmed atomically smooth surfaces and abrupt heterointerfaces. The films exhibit critical temperatures approaching bulk values, establishing a materials platform for scalable, high-coherence superconducting qubits.

</details>


### [106] [Quantum Scrambling Born Machine](https://arxiv.org/abs/2602.17281)
*Marcin Płodzień*

Main category: quant-ph

TL;DR: 提出量子置乱玻恩机(QSBM)，使用固定纠缠酉算子作为"置乱库"产生多体纠缠，仅优化单比特旋转。研究发现一旦达到近Haar典型纠缠，模型对目标分布的学习对置乱器微观细节弱敏感。将哈密顿耦合参数化为可训练参数后，性能可与经典生成模型媲美。


<details>
  <summary>Details</summary>
Motivation: 量子生成建模是近期量子计算有前景的应用，但需要高效的多比特纠缠生成方案。核心问题是纠缠酉算子的微观细节对模型性能的影响程度未知。

Method: 设计量子置乱玻恩机架构：采用固定纠缠酉算子（三种选择：Haar随机、有限深度砖墙电路、近邻自旋链哈密顿量时间演化）作为置乱库提供纠缠，仅优化单比特旋转门参数。进一步将哈密顿耦合提升为可训练参数，转化为变分哈密顿问题。

Result: 对于基准分布和系统规模，一旦置乱器产生近Haar典型纠缠，模型学习效果对置乱器微观起源弱敏感。物理可实现的近似方案（砖墙电路和自旋链）表现与Haar随机相当。在匹配参数量下，性能与代表性经典生成模型具有竞争力。

Conclusion: QSBM是一种鲁棒的量子生成模型，其性能主要取决于纠缠程度而非具体实现方式。该工作证明了物理可实现的置乱器在量子生成任务中的有效性，为近期量子设备实现量子优势提供了可行路径。

Abstract: Quantum generative modeling, where the Born rule naturally defines probability distributions through measurement of parameterized quantum states, is a promising near-term application of quantum computing. We propose a Quantum Scrambling Born Machine in which a fixed entangling unitary -- acting as a scrambling reservoir -- provides multi-qubit entanglement, while only single-qubit rotations are optimized. We consider three entangling unitaries -- a Haar random unitary and two physically realizable approximations, a finite-depth brickwork random circuit and analog time evolution under nearest-neighbor spin-chain Hamiltonians -- and show that, for the benchmark distributions and system sizes considered, once the entangler produces near-Haar-typical entanglement the model learns the target distribution with weak sensitivity to the scrambler's microscopic origin. Finally, promoting the Hamiltonian couplings to trainable parameters casts the generative task as a variational Hamiltonian problem, with performance competitive with representative classical generative models at matched parameter count.

</details>


### [107] [Two-dimensional quantum lattice gas algorithm for anisotropic Burger-like equations](https://arxiv.org/abs/2602.17303)
*Niccoló Fonio,Pierre Sagaut,Giuseppe Di Molfetta*

Main category: quant-ph

TL;DR: This paper refines a hybrid quantum lattice gas algorithm by correcting viscosity predictions and introducing a minimal 2D version to simulate anisotropic fluid dynamics with momentum conservation.


<details>
  <summary>Details</summary>
Motivation: To advance quantum-native fluid dynamics modeling by addressing limitations in existing quantum lattice gas algorithms, specifically refining viscosity predictions and enabling 2D Navier-Stokes dynamics beyond classical FHP models.

Method: Deriving analytical corrections to viscosity predictions; developing a minimal 2D generalization using only two lattice velocities to simulate anisotropic Burger-like equations while preserving momentum conservation.

Result: Provides refined analytical/numerical viscosity results and demonstrates a simplified 2D quantum lattice model capable of simulating anisotropic fluid flow with embedded momentum conservation.

Conclusion: The approach offers a promising pathway toward quantum-native simulation of Navier-Stokes dynamics in 2D, overcoming constraints of classical lattice models like FHP.

Abstract: Building on hybrid quantum lattice gas algorithm, we revisit the possibilities of this quantum lattice model. By deriving a correction to the predicted viscosity, we provide analytical and numerical results that refine original formulation. We introduce a minimal 2D generalization of the algorithm, which allows to simulate anisotropic Burgerlike equations while retaining only two lattice velocities. This approach opens a promising route toward embedding momentum conservation and advancing toward NavierStokes dynamics in 2D, going beyond Frisch, Hasslacher and Pomeau (FHP) with a quantum native model.

</details>


### [108] [Near-perfect quantum teleportation between continuous and discrete encodings](https://arxiv.org/abs/2602.17306)
*Ravi Kamal Pandey,Shraddha Singh,Dhiraj Yadav,Devendra Kumar Mishra*

Main category: quant-ph

TL;DR: 实现了从离散变量（单光子）到连续变量（相干态）的近乎完美量子隐形传态，解决了传统方案中成功率不超过50%的限制


<details>
  <summary>Details</summary>
Motivation: 研究混合纠缠资源下离散变量与连续变量量子态之间的相互隐形传态，特别是突破反向过程（DV→CV）的成功率限制

Method: 采用交叉Kerr非线性效应结合无源线性光学元件（偏振分束器、分束器、相位偏移器）构建混合纠缠态

Result: 在DV→CV方向的隐形传态中实现了接近完美的成功率，克服了传统方案最大1/2成功概率的瓶颈

Conclusion: 通过混合非线性-线性光学方案，实现了双向高效的量子态转换，为混合量子信息处理提供了实用化方案

Abstract: Quantum teleportation between polarized single-photon and phase-opposite coherent states is studied using a hybrid entangled resource and entangled coherent states. The polarized single-photon qubit represents a discrete-variable (DV) quantum system, whereas the phase-opposite coherent-state qubit constitutes a continuous-variable (CV) system. While teleportation from CV to DV can be achieved with near-unit success probability, the reverse process is usually limited to a maximum success probability of $1/2$. We demonstrate that, by employing cross-Kerr nonlinearity together with passive linear optical components such as polarizing beam splitters, beam splitters, and phase shifters, almost perfect teleportation from DV to CV encodings can also be achieved.

</details>


### [109] [Dissipative charging of tight-binding quantum batteries](https://arxiv.org/abs/2602.17326)
*Mingdi Xu,Yiming Liu,Yefeng Song,Xiang-Ping Jiang,Lei Pan*

Main category: quant-ph

TL;DR: 提出利用工程化马尔可夫耗散（通过设计Lindblad跳跃算符）在格点量子电池中实现自主耗散充电的机制，使系统进入高能带边态并获得高有效能量（ergotropy），该机制在无序和局部退相干噪声下仍保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索在开放量子系统框架下实现格点量子电池高效自主充电的新机制，解决传统充电方法在存在环境噪声和系统无序时的局限性，提升能量存储的实际应用可行性。

Method: 在马尔可夫耗散框架中设计特定的Lindblad跳跃算符，驱动一维紧束缚链和二维石墨烯晶格等紧束缚系统进入高能带边稳态，并通过理论分析与数值模拟研究无序和退相干噪声的影响。

Result: 1) 耗散机制可高效充电至具有高ergotropy的稳态；2) 无序反而增强充电功率，体现耗散辅助局域化的有利作用；3) 充电过程对额外局部退相干噪声具有鲁棒性。

Conclusion: 证实键耗散（bond dissipation）是一种物理透明且有效的格点量子电池充电机制，适用于真实开放系统环境，为设计实用化量子能源器件提供了新思路。

Abstract: We investigate autonomous dissipative charging mechanisms for lattice quantum batteries within the framework of open quantum systems. Focusing on engineered Markovian dissipation, we show that appropriately designed Lindblad jump operators can drive tight-binding systems into highly excited band-edge states, resulting in steady states with large ergotropy. We illustrate this mechanism in a one-dimensional tight-binding chain and in a two-dimensional graphene lattice. We find that disorder enhances the charging power, indicating that dissipation-assisted localization effects can be beneficial for energy storage. Moreover, the dissipative charging process remains robust against additional local dephasing noise. Our results establish bond dissipation as an effective and physically transparent mechanism for charging lattice quantum batteries in realistic open-system settings.

</details>


### [110] [Superiority of Krylov shadow tomography in estimating quantum Fisher information: From bounds to exactness](https://arxiv.org/abs/2602.17361)
*Yuan-Hao Wang,Da-Jian Zhang*

Main category: quant-ph

TL;DR: 低阶Krylov界可高效精确估计量子Fisher信息，指数收敛速度超越现有多项式下界，且对实际低秩态能达到精确匹配。


<details>
  <summary>Details</summary>
Motivation: 量子Fisher信息(QFI)在量子科技中应用广泛但估计困难，Krylov阴影层析(KST)虽提出新QFI界，但其实际适用性有待验证。

Method: 理论分析KST中Krylov界的收敛特性，证明其指数收敛速度，并通过数值实验验证低阶界对低秩态的精确匹配能力。

Result: Krylov界随阶数指数快速收敛至QFI；超越现有最优多项式下界；特定低阶界可精确匹配实际常见低秩态的QFI，这是多项式界无法实现的。

Conclusion: 低阶Krylov界在QFI估计中具备显著实践优势，为量子信息应用提供了更高效准确的计算方案，充分释放QFI应用潜力。

Abstract: Estimating the quantum Fisher information (QFI) is a crucial yet challenging task with widespread applications across quantum science and technologies. The recently proposed Krylov shadow tomography (KST) opens a new avenue for this task by introducing a series of Krylov bounds on the QFI. In this work, we address the practical applicability of the KST, unveiling that the Krylov bounds of low orders already enable efficient and accurate estimation of the QFI. We show that the Krylov bounds converge to the QFI exponentially fast with increasing order and can surpass the state-of-the-art polynomial lower bounds known to date. Moreover, we show that certain low-order Krylov bound can already match the QFI exactly for low-rank states prevalent in practical settings. Such exact match is beyond the reach of polynomial lower bounds proposed previously. These theoretical findings, solidified by extensive numerical simulations, demonstrate practical advantages over existing polynomial approaches, holding promise for fully unlocking the effectiveness of QFI-based applications.

</details>


### [111] [Experimental certification of ensembles of high-dimensional quantum states with independent quantum devices](https://arxiv.org/abs/2602.17409)
*Yong-Nan Sun,Meng-Yun Ma,Qi-Ping Su,Zhe Sun,Chui-Ping Yang,Franco Nori*

Main category: quant-ph

TL;DR: 实验实现了高维量子态的半设备无关认证，在99%保真度和大气湍流噪声下依然有效。


<details>
  <summary>Details</summary>
Motivation: 高维量子态认证在量子信息领域日益重要，但黑盒场景下的认证仍具挑战。

Method: 基于独立设备的准备-测量实验，使用单光子轨道角动量态。

Result: 六维态保真度约99%，成功测试至十维，证实大气湍流下仍可认证。

Conclusion: 为量子认证和随机数生成提供新方案。

Abstract: When increasing the dimensionality of quantum systems, high-dimensional quantum state certification becomes important in quantum information science and technology. However, how to certify ensembles of high-dimensional quantum states in a black-box scenario remains a challenging task. In this work, we report an experimental test of certifying ensembles of high-dimensional quantum states based on prepare-and-measure experiments with \textit{independent devices}, where the state preparation device and the measurement device have no shared randomness. In our experiment, the prepared quantum states are high-dimensional orbital angular momentum states of single photons, and both the preparation fidelity and the measurement fidelity are about 99.0$\%$ for the six-dimensional quantum states. We also measure the crosstalk matrices and calculate the similarity parameter for up to ten dimensions. We not only experimentally certify the ensemble of high-dimensional quantum states in a semi-device-independent manner, but also experimentally investigate the effect of atmospheric turbulent noise on high-dimensional quantum state certification. Our experimental results clearly show that the certification of high-dimensional quantum states can still be achieved even under the influence of atmospheric turbulent noise. Our findings have potential implications in quantum certification and quantum random number generation.

</details>


### [112] [Organic molecules as single-photon sources](https://arxiv.org/abs/2602.17428)
*Alexey Shkarin,Stephan Götzinger*

Main category: quant-ph

TL;DR: 本文综述了基于单分子的有机单光子源研究进展，重点介绍多环烃类分子作为固态单光子源的发射体系统。这类分子在低温下表现出优异的光学特性，包括可忽略的退相、长期光稳定性和高光子发射率，是量子技术的重要构建模块。文章讨论了样品制备、光收集策略、发射体参数及光提取方案，并展望了未来挑战与解决方案。


<details>
  <summary>Details</summary>
Motivation: 近年来单光子源技术快速发展，特别是基于量子发射器的系统取得显著进展。多环烃类分子在低温下展现出的优异光学特性使其成为量子技术中极具吸引力的构建模块，因此有必要综述该领域发展。

Method: 本文采用综述方法，概述单分子基单光子源的发展现状。具体包括：介绍多环烃类分子的光学特性（吸收/发射光谱、寿命、退相）；讨论样品制备技术和光收集策略；分析光提取方案作为单光子源的关键组成部分。

Result: 多环烃类分子在低温下表现出卓越的光学性能：可忽略的退相、长期的光稳定性以及高光子发射率，这些特性使其成为量子技术中有前景的基本构建单元。文章系统总结了相关样品制备、参数表征和光提取方法。

Conclusion: 论文最后对该领域进行展望，指出当前面临的主要挑战，并提出可能的解决方案，为基于单分子的单光子源未来发展提供指导。

Abstract: The development of single-photon sources has been nothing but rapid in recent years, with quantum emitter-based systems showing especially impressive progress. In this article, we give an overview of the developments in single-photon sources based on single molecules. We will introduce polycyclic hydrocarbons as the most commonly used emitter systems for the realization of an organic solid-state single-photon source. At cryogenic temperatures this special class of fluorescent molecules demonstrates remarkable optical properties such as negligible dephasing, indefinite photostability, and high photon rates, which make them attractive as fundamental building blocks in emerging quantum technologies. To better understand the general properties and limitations of these molecules, we discuss sample preparation, light collection strategies and relevant emitter parameters such as absorption and emission spectra, lifetime, and dephasing. We will also give an overview of light extraction strategies as a crucial part of a single-photon source. Finally, we conclude with a look into the future, displaying current challenges and possible solutions.

</details>


### [113] [Tight any-shot quantum decoupling](https://arxiv.org/abs/2602.17430)
*Mario Berta,Hao-Chung Cheng,Yongsheng Yao*

Main category: quant-ph

TL;DR: 提出基于量子相对熵的新单样本解耦定理，用 sandwiched Rényi 条件熵界定误差；在渐近独立同分布下证明该界在量子相对熵意义下是紧的，并得到低资源成本率区的解耦误差指数特征；进一步导出量子态合并、纠缠蒸馏和量子信道编码的误差指数精确表达式


<details>
  <summary>Details</summary>
Motivation: 量子信息解耦是量子信息理论的基础原语，在量子物理多个应用中起核心作用，但现有理论缺乏基于量子相对熵的单样本解耦刻画，且误差指数在低资源成本率区的特性未完全解决

Method: 1) 用量子相对熵距离构建新型单样本解耦定理，以两个 sandwiched Rényi 条件熵约束解耦误差；2) 在渐近独立同分布部分迹解耦框架下证明该界的紧致性；3) 基于该框架推导纯化距离下的操作应用，包括 Petz-Rényi 条件熵与相干信息表征的误差指数

Result: 1) 获得解耦误差指数的低成本资源率区完整特征；2) 导出量子态合并的精确单字母误差指数表达式；3) 得到纠缠蒸馏和量子信道编码的正则化可实现误差指数公式；4) 证明对最大关联态和广义退相位信道，上述界在高蒸馏/编码率区是紧的

Conclusion: 该工作建立了量子相对熵框架下的解耦理论新范式，不仅推进了解耦问题的理论认知，还为量子信息处理关键任务（态合并、纠缠蒸馏、信道编码）提供了普适且紧的误差指数刻画，尤其在高效率区具有实际指导价值

Abstract: Quantum information decoupling is a fundamental primitive in quantum information theory, underlying various applications in quantum physics. We prove a novel one-shot decoupling theorem formulated in terms of quantum relative entropy distance, with the decoupling error bounded by two sandwiched Rényi conditional entropies. In the asymptotic i.i.d. setting of standard information decoupling via partial trace, we show that this bound is ensemble-tight in quantum relative entropy distance and thereby yields a characterization of the associated decoupling error exponent in the low-cost-rate regime.
  Leveraging this framework, we derive several operational applications formulated in terms of purified distance: (i) a single-letter expression for the exact error exponent of quantum state merging in terms of Petz-Rényi conditional entropies, and (ii) regularized expressions for the achievable error exponent of entanglement distillation and quantum channel coding in terms of Petz-Rényi coherent informations. We further prove that these achievable bounds are tight for maximally correlated states and generalized dephasing channels, respectively, for the high distillation-rate/coding-rate regimes.

</details>


### [114] [Global bifurcations and basin geometry of the nonlinear non-Hermitian skin effect](https://arxiv.org/abs/2602.17439)
*Heng Lin,Yunyao Qi,Gui-Lu Long*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study a continuum Hatano--Nelson model with a saturating nonlinear nonreciprocity and analyze its stationary states via the associated phase-space flow. We uncover a global scenario controlled by a subcritical Hopf bifurcation and a saddle-node of limit cycles, which together generate a finite coexistence window. In this window, skin modes and extended states are both stable at a fixed energy $E$, separated by a nonlinear basin separatrix in phase space rather than a spectral (mobility-edge) mechanism in a linear system. An averaged amplitude equation yields closed-form predictions for the limit-cycle branches and the SNLC threshold. Building on the basin geometry, we introduce a basin-fraction order parameter that exhibits a first-order-like jump at SNLC. Intriguing physical phenomena in the coexistence window are also revealed, such as separatrix-induced long-lived spatial transients and hysteresis. Overall, our findings highlight that, beyond linear spectral concepts, global attractor-basin geometry provides a powerful and complementary lens for understanding stationary states in nonlinear non-Hermitian systems.

</details>


### [115] [Single-Photon Motion in a Two-Dimensional Plane: Confinement and Boundary Escape](https://arxiv.org/abs/2602.17461)
*Hui-hui Miao*

Main category: quant-ph

TL;DR: 本论文研究二维平面中单光子在闭合和开放边界条件下的运动。采用两种方法构建希尔伯特空间：标准二次量子化方法（A）和一种非标准方法（B），通过剔除冗余量子态获得维度显著降低的约化希尔伯特空间，提升数值模拟效率。在闭合系统中，两种方法等价，幺正演化结果一致，概率分布从中心向外扩散并在边界处出现明显反弹；在开放系统中，B方法因引入更多耗散通道，能更准确描述光子逃逸过程。两种方法的概率曲线在到达边界前完全重叠，到达边界后出现轻微差异，但该差异不随演化放大且后期趋于收敛，B方法得到的耗散态概率略高，表明光子逃逸更快。概率分布可视化显示，三种情形在到达边界前分布相同，到达后开放系统出现显著概率损失且随演化迅速增加，两个开放系统的分布模式高度相似，演化同步。


<details>
  <summary>Details</summary>
Motivation: 提升数值模拟效率，通过约化希尔伯特空间降低维度；比较标准二次量子化与非标准方法在描述单光子闭合/开放边界动力学中的异同，探讨耗散对光子逃逸的影响。

Method: 构建两种希尔伯特空间方法：A为标准二次量子化形式；B为非标准方法，均剔除冗余态得到低维约化空间。分别在闭合与开放边界条件下模拟光子的演化。

Result: 闭合系统：两方法等价，幺正演化相同，概率向外扩散并在边界反弹；开放系统：B方法因更多耗散通道更准确描述光子逃逸。两方法概率曲线在边界前重合，边界后出现轻微差异但不放大且后期收敛，B方法耗散态概率略高，光子逃逸更快。可视化显示三情形边界前分布相同，边界后开放系统概率损失显著且迅速增加，两开放系统分布高度相似、同步演化。

Conclusion: 约化希尔伯特空间有效提升模拟效率；在开放系统中，B方法因更充分考虑耗散而更适用于描述光子逃逸；两种方法在边界前一致且后期收敛，验证了方法的可靠性。B方法为开放量子系统模拟提供了更精确的选择。

Abstract: This paper investigates the motion of a single photon in a two-dimensional plane under closed and open boundary conditions. We employ two methods to construct the Hilbert space: Method A, based on the standard second-quantization formalism, and Method B, based on a non-standard approach. By eliminating redundant quantum states, we obtain a reduced Hilbert space with significantly lower dimensionality, thereby improving the efficiency of numerical simulations. In a closed system, the two methods are equivalent, and their unitary evolution results are identical. The probability distribution diffuses outward from the center and exhibits a significant rebound after reaching the boundary. In an open system, Method B, by incorporating more dissipation channels, provides a more accurate description of the photon escape process at the boundary. The probability curves obtained from the two methods completely overlap before reaching the boundary. After the boundary is reached, a slight difference appears, but this difference does not amplify with evolution and tends to converge in the later stage. Method B yields a slightly higher dissipative-state probability, indicating that the photon escapes faster. Visualization of the two-dimensional probability distribution shows that the three scenarios (closed system, open system with Method A, and open system with Method B) exhibit identical probability distributions before reaching the boundary. After the boundary is reached, the open systems exhibit significant probability loss, which increases rapidly with evolution. The probability distribution patterns of the two open systems are highly similar, exhibiting synchronized evolution.

</details>


### [116] [Modelling quantum measurements without superposition](https://arxiv.org/abs/2602.17462)
*Gabriele Cobucci,Alexander Bernal,Roope Uola,Armin Tavakoli*

Main category: quant-ph

TL;DR: 研究量子测量是否可用无叠加特性的"经典测量模型"模拟，确定了投影测量可经典化的噪声与损耗阈值，开发了构造与证伪此类模型的方法，并揭示了叠加性是量子测量设备的关键资源。


<details>
  <summary>Details</summary>
Motivation: 探索量子叠加性在测量中的核心作用，检验量子测量能否被本质上经典的设备完全模拟，从而理解叠加性作为量子资源的本质。

Method: 提出经典测量模型概念，通过 depolarisation noise 和 measurement loss 量化经典化极限，利用 prepare-and-measure 方案检验模型存在性，并分析经典辅助信息下的顺序测量无扰动条件。

Result: 精确确定了d维量子投影测量可经典化的 depolarisation noise 率与 measurement loss 率阈值；开发了有限测量集的经典模型构造与证伪方法；证明经典模型意味着经典辅助的量子测量可无扰动顺序实现。

Conclusion: 揭示了叠加性是量子测量设备区别于经典设备的关键资源，经典测量模型虽受限但为理解量子测量的经典边界提供了新框架。

Abstract: Superposition is the core feature that sets quantum theory apart from classical physics. Here, we investigate whether sets of quantum measurements can be modelled by using only devices that are operationally classical, in the sense that they have no superposition properties. This leads us to propose classical measurement models, which we show to be stronger than commutative measurements but weaker than joint measurability. We determine both the exact depolarisation noise rate and the measurement loss rate at which the all projective measurements in $d$-dimensional quantum theory admit a classical model. For finite sets of quantum measurements we develop methods both for constructing classical models and for falsifying the existence of such model via prepare-and-measure setups. Furthermore, we show that this concept also has operational implications. For that, we consider whether quantum measurements with classical side-information can be implemented in sequence without causing a disturbance and we show that classical models imply an affirmative answer. Our work sheds light on superposition as a resource for quantum measurement devices.

</details>


### [117] [Pauli Correlation Encoding for Budget-Contraint Optimization](https://arxiv.org/abs/2602.17479)
*Jacobo Padín Martínez,Vicente P. Soloviev,Alejandro Borrallo Rentero,Antón Rodríguez Otero,Raquel Alfonso Rodríguez,Michal Krompiec*

Main category: quant-ph

TL;DR: 扩展了泡利相关编码(PCE)框架以处理约束组合优化问题，发现标准PCE难以可靠执行约束，因此提出迭代-$α$ PCE策略，显著提高了约束满足率和解质量


<details>
  <summary>Details</summary>
Motivation: 变分量子算法和量子退火等现有量子优化方法通常依赖独热编码，严重限制了可扩展性；PCE虽能减少量子比特需求，但尚未在约束优化背景下研究

Method: 将PCE框架扩展到约束组合优化问题，并引入迭代-$α$ PCE策略来改进约束执行能力

Result: 标准PCE在约束执行方面表现不佳；迭代-$α$ PCE显著提高了约束满足率，并在多种实例上获得了更好的切割规模

Conclusion: 当前PCE公式在约束问题方面存在局限性，而迭代策略能有效推进NISQ时代的量子优化发展

Abstract: Quantum optimization has gained increasing attention as advances in quantum hardware enable the exploration of problem instances approaching real-world scale. Among existing approaches, variational quantum algorithms and quantum annealing dominate current research; however, both typically rely on one-hot encodings that severely limit scalability. Pauli Correlation Encoding (PCE) was recently introduced as an alternative paradigm that reduces qubit requirements by embedding problem variables into Pauli correlations. Despite its promise, PCE has not yet been studied in the context of constrained optimization. In this work, we extend the PCE framework to constrained combinatorial optimization problems and evaluate its performance across multiple problem sizes. Our results show that the standard PCE formulation struggles to reliably enforce constraints, which motivates the introduction of the Iterative-$α$ PCE. This iterative strategy significantly improves solution quality, achieving consistent constraint satisfaction while yielding better cut sizes across a wide range of instances. These findings highlight both the limitations of current PCE formulations for constrained problems and the effectiveness of iterative strategies for advancing quantum optimization in the NISQ era.

</details>


### [118] [Phase transitions in quasi-Hermitian quantum models at exceptional points of order four](https://arxiv.org/abs/2602.17491)
*Miloslav Znojil*

Main category: quant-ph

TL;DR: 该论文研究量子相变在例外点（EP）处的行为，重点关注四阶例外点（EP4）。研究表明，虽然哈密顿量在EP处失去物理可观测性，但仍可作为微扰分析的基础算子。EP4简并可通过物理可实现的幺正演化过程在特定参数域内被访问，其边界可通过非数值方法确定，这一结果在非厄米光子学中具有潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 理解参数依赖哈密顿量H(g)在量子相变末期的观测性丧失现象，并将其数学描述为N阶例外点（EPN）的量子突变。特别关注高阶级联EP的解析方法开发，因为现有对EPN≥5的研究多限于数值分析，缺乏对EP4等中间情况的深入理解。

Method: 采用微扰近似方法分析EPN奇点附近的哈密顿量行为。对N≤3情况使用基本解析方法，对N≥5采用数值方法，重点选取N=4（EP4）作为桥梁案例。通过构造可在物理参数域D_physical内实现的幺正演化过程来访问EP4简并，其边界通过非数值方法确定。

Result: 1) 证明在g→g^EPN极限下变得非物理的哈密顿量H(g)仍可作为EPN附近微扰分析的未扰动算子；2) 发现EP4简并可通过特定幺正演化过程在物理参数域内实现；3) 确定了该参数域D_physical的边界，这些边界可通过非数值方法精确确定。

Conclusion: 本研究为分析高阶例外点提供了理论框架，特别揭示了EP4的物理可及性特征。尽管是数学结果，但其与参数空间的幺正演化相关联，为非厄米光子学中的奇异点操控和实验实现开辟了新途径，强调了数学理论与物理应用之间的深刻联系。

Abstract: Quantum phase transition is interpreted as an evolution, at the end of which a parameter-dependent Hamiltonian $H(g)$ loses its observability. In the language of mathematics, such a quantum catastrophe occurs at an exceptional point of order $N$ (EPN). Although the Hamiltonian $H(g)$ itself becomes unphysical in the limit of $g \to g^{EPN}$, it is shown that it can play the role of an unperturbed operator in a perturbation-approximation analysis of the vicinity of the EPN singularity. Such an analysis is elementary at $N\leq 3$ and numerical at $N\geq 5$, so we pick up $N=4$. We demonstrate that the specific EP4 degeneracy becomes accessible via a unitary evolution process realizable inside a parametric domain ${\cal D}_{\rm physical}$, the boundaries of which are determined non-numerically. Possible relevance of such a mathematical result in the context of non-Hermitian photonics is emphasized.

</details>


### [119] [Efficiency of classical simulations of a noisy Grover algorithm](https://arxiv.org/abs/2602.17569)
*Raphaël Menu,Johannes Schachenmayer*

Main category: quant-ph

TL;DR: 该论文研究了振幅阻尼和相位翻转噪声对Grover算法中纠缠动力学的影响，发现算子纠缠(OE)比轨迹纠缠(TE)更能准确反映系统向目标态收敛时的纠缠减少过程，且矩阵乘积密度算子(MPDO)模拟通常比量子轨迹方法更高效。


<details>
  <summary>Details</summary>
Motivation: 探究噪声环境下量子算法（特别是Grover搜索算法）的纠缠动力学特性，因为纠缠特性与矩阵乘积态模拟效率密切相关，对理解量子计算在噪声环境中的实际表现有重要意义。

Method: 采用量子轨迹方法与全密度矩阵模拟进行对比分析，分别研究状态表示下的平均轨迹纠缠(TE)和算子纠缠(OE)在振幅阻尼噪声和相位翻转噪声下的演化行为。

Result: 1) OE动力学能准确描述Grover电路末端系统向目标乘积态收敛时的纠缠减少现象，而量子轨迹很少呈现这种减少路径；
2) 优化 unraveling 方案仅能轻微降低TE，且电路深处OE普遍小于TE；
3) MPDO模拟通常比量子轨迹方法更高效；
4) 研究了两种噪声下算法成功概率随噪声率的缩放规律。

Conclusion: 在噪声存在的Grover算法中，算子纠缠(OE)是比轨迹纠缠(TE)更可靠的纠缠演化指标，且矩阵乘积密度算子(MPDO)方法在模拟含噪量子电路时通常比量子轨迹方法更具计算效率。

Abstract: We analyze the modification of entanglement dynamics in the Grover algorithm when the qubits are subjected to single-qubit amplitude-damping or phase-flip noise. We compare quantum trajectories with full density-matrix simulations, analyzing the dynamics of averaged trajectory entanglement (TE) and operator entanglement (OE), in the respective state representation. Although not a genuine entanglement measure, both TE and OE are connected to the efficiency of matrix product state simulations and thus of fundamental interest. As in many quantum algorithms, at the end of the Grover circuit entanglement decreases as the system converges towards the target product state. While we find that this is well captured in the OE dynamics, quantum trajectories rarely follow paths of reducing entanglement. Optimized unraveling schemes can lower TE slightly, however we show that deep in the circuit OE is generally smaller than TE. This implies that matrix product density operator (MPDO) simulations of quantum circuits can in general be more efficient than quantum trajectories. In addition, we investigate the noise-rate scaling of success probabilities for both amplitude-damping and phase-flip noise in Grover's algorithm.

</details>


### [120] [Subluminal and superluminal velocities of free-space photons](https://arxiv.org/abs/2602.17576)
*Konstantin Y. Bliokh*

Main category: quant-ph

TL;DR: 该论文研究了电磁波波包在直线自由空间传播的特性，证明空间局域化波包必然具有亚光速的群速度和超光速的相速度，且两者乘积等于c²，并通过高斯波包计算验证，同时讨论了量子力学描述中"光子波函数"的细微问题。


<details>
  <summary>Details</summary>
Motivation: 探究电磁波波包在自由空间传播时的基本速度特性，特别是群速度与相速度的物理本质及其相互关系，并澄清量子力学框架下"光子波函数"描述的潜在复杂性。

Method: 结合电磁场理论、标量波包传播和量子力学 formalism 进行多方法分析；通过显式计算高斯光束和波包进行具体验证；重点考察了Milton和Schwinger提出的"能量速度"与"动量速度"概念。

Result: 证明空间局域化波包必然满足：群速度（亚光速） × 相速度（超光速） = c²；该速度关系对应能量传输速度与动量传输速度；高斯波包计算实例支持理论结论。

Conclusion: 电磁波波包的局域化特性 inherently 要求群相速度分离且乘积为c²；量子力学描述需谨慎处理"光子波函数"概念以避免误解；结果深化了对光波传播基本物理规律的理解。

Abstract: We consider rectilinear free-space propagation of electromagnetic wavepackets using electromagnetic field theory, scalar wavepacket propagation, and quantum-mechanical formalism. We demonstrate that spatially localized wavepackets are inherently characterized by a subluminal group velocity and a superluminal phase velocity, whose product equals $c^2$. These velocities are also known as the 'energy' and 'momentum' velocities, introduced by K. Milton and J. Schwinger. We illustrate general conclusions by explicit calculations for Gaussian beams and wavepackets, and also highlight subtleties of the quantum-mechanical description based on the 'photon wavefunction'.

</details>


### [121] [States that grow linearly in time, exceptional points, and zero norm states in the simple harmonic oscillator](https://arxiv.org/abs/2602.17589)
*Philip D. Mannheim*

Main category: quant-ph

TL;DR: 该论文揭示了简谐振子存在非标准非厄米结构：每个正能级对应非归一化本征态，导致哈密顿量出现非对角化的Jordan块，表明反线性PT对称性比厄米性更根本。


<details>
  <summary>Details</summary>
Motivation: 挑战量子力学中厄米性为必要条件的传统认知，通过简谐振子模型探究非厄米PT对称结构的物理本质，论证反线性对称性在量子理论中的基础地位。

Method: 构造基于$a^{\dagger} a$真空态的非归一化本征态，结合PT对称性分析非厄米哈密顿量的Jordan块结构，并在Stokes楔形复域中实现态矢归一化。

Result: 发现每个能级均为例外点，哈密顿量呈非厄米Jordan块形式；能量本征基不完备，存在时变增长的态；通过PT内积和复域解析延拓构建自洽量子理论。

Conclusion: 简谐振子模型证明非厄米PT对称结构可形成完备量子体系，反线性对称性是比厄米性更基础的量子理论核心要素。

Abstract: The simple harmonic oscillator has a well-known normalizable, positive energy, bound state spectrum. We show that degenerate with each such positive energy eigenvalue there is a non-normalizable positive energy eigenstate whose eigenfunction is orthogonal to that of the standard energy eigenfunction. This class of states is not built on the vacuum that $a$ annihilates, but is instead built on the vacuum that $a^{\dagger} a$ annihilates. These non-normalizable but nonetheless stationary energy eigenstates are accompanied by yet another set of non-normalizable states, states whose wave functions however are not stationary but instead grow linearly in time. With these states not being energy eigenstates, the eigenbasis of the Hamiltonian is incomplete; with the full Hilbert space containing states that are not energy eigenstates. Thus each energy eigenvalue of the harmonic oscillator is an exceptional point at which the Hamiltonian becomes of non-diagonalizable, and thus manifestly non-Hermitian, Jordan-block form. Such non-Hermitian structures occur for Hamiltonians that have an antilinear $PT$ symmetry. As is characteristic of such systems, one can construct a probability conserving inner product that despite the linear in time growth is nonetheless time independent, and not only that, it leads to states with zero norm. In addition, as is again characteristic of $PT$ symmetry, these non-normalizable states can be made normalizable by a continuation into a so-called Stokes wedge domain in the complex plane. In this domain one has a completely consistent quantum theory, one that lives alongside the standard normalizable energy eigenspectrum sector. This thus not quite so simple harmonic oscillator provides an explicit realization of our general contention that antilinearity is more basic to quantum theory than Hermiticity.

</details>


### [122] [Quantum Advantage for Sensing Properties of Classical Fields](https://arxiv.org/abs/2602.17591)
*Jordan Cotler,Daine L. Danielson,Ishaan Kannan*

Main category: quant-ph

TL;DR: This paper introduces Quantum Signal Learning (QSL), a quantum-enhanced sensing protocol using two-mode squeezing that simultaneously estimates multiple classical signal properties with sub-vacuum noise, achieving exponential speedups over classical methods for electromagnetic correlation measurement, cavity control, and matched filtering.


<details>
  <summary>Details</summary>
Motivation: Modern precision experiments are limited by quantum vacuum fluctuations when probing unknown classical fields with bosonic sensors, where conventional readout cannot overcome this fundamental noise floor.

Method: Proposes a QSL framework using two-mode squeezing, passive optics, and static homodyne measurements to enable post-hoc estimation of many properties from one dataset, combined with an optimal-transport conditioning method.

Result: The protocol achieves shot-noise suppression below vacuum level, shows worst-case exponential separations from entanglement-free strategies, provides practical speedups over homodyne/heterodyne baselines, and senses structured classical backgrounds exponentially faster than any coherent classical probe.

Conclusion: QSL demonstrates scalable quantum advantages for classical sensing by simultaneously learning multiple signal properties, offering both theoretical exponential separations and practical speedups with simple experimental requirements.

Abstract: Modern precision experiments often probe unknown classical fields with bosonic sensors in quantum-noise-limited regimes where vacuum fluctuations limit conventional readout. We introduce Quantum Signal Learning (QSL), a sensing framework that extends metrology to a broader property-learning setting, and propose a quantum-enhanced protocol that simultaneously estimates many properties of a classical signal with shot noise suppressed below the vacuum level. Our scheme requires only two-mode squeezing, passive optics, and static homodyne measurements, and enables post-hoc classical estimation of many properties from the same experimental dataset. We prove that our protocol enables a quantum speedup for common classical sensing tasks, including measuring electromagnetic correlations, real-time feedback control of interferometric cavities, and Fourier-domain matched filtering. To establish these separations, we introduce an optimal-transport conditioning method, and show both worst-case exponential separations from all entanglement-free strategies and practical speedups over homodyne and heterodyne baselines. We further show that when squeezing is treated as a resource, a protocol with squeezed light can sense a structured classical background exponentially faster than any coherent classical probe.

</details>


### [123] [Phase-sensitive representation of Majorana stabilizer states](https://arxiv.org/abs/2602.17604)
*Tomislav Begušić,Garnet Kin-Lic Chan*

Main category: quant-ph

TL;DR: 将稳定子态理论扩展至马约拉纳系统，开发用于费米子量子计算的相位敏感态表征及高效算法。


<details>
  <summary>Details</summary>
Motivation: 费米子量子计算中亟需扩展经典稳定子态模拟方法，现有克利福德算符理论需适配马约拉纳体系以实现高效量子态操控与模拟。

Method: 提出相位敏感的马约拉纳稳定子态表达形式，设计专用算法计算态振幅、内积及马约拉纳克利福德门变换下的更新规则。

Result: 建立了完整的马约拉纳稳定子态计算框架，实现了高纠缠态在费米子系统的高效表示与变换。

Conclusion: 该工作为费米子量子计算的模拟与错误校正提供了关键理论工具，推动了拓扑量子计算的发展。

Abstract: Stabilizer states hold a special place in quantum information science due to their connection with quantum error correction and quantum circuit simulation. In the context of classical simulations of many-body physics, they are an example of states that can be both highly entangled and efficiently represented and transformed under Clifford operators. Recently, Clifford operators have been discussed in the context of fermionic quantum computation through their extension, the Majorana Clifford group. Here, we document the phase-sensitive form of the corresponding Majorana stabilizer states, as well as the algorithms for computing their amplitudes, their inner products, and update rules for transforming Majorana stabilizer states under Majorana Clifford gates.

</details>


### [124] [Scalable, self-verifying variational quantum eigensolver using adiabatic warm starts](https://arxiv.org/abs/2602.17612)
*Bojan Žunkovič,Marco Ballarin,Lewis Wright,Michael Lubasch*

Main category: quant-ph

TL;DR: 该论文提出了一种绝热变分量子本征求解器(VQE)的变体，通过迭代方式在绝热路径上求解哈密顿量的基态，推导了梯度优化成功准备绝热基态的条件以避免贫瘠高原和局部最优问题，并提出了基于能量标准差测量的运行时认证方法验证本征态准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统变分量子本征求解器(VQE)中存在的梯度消失(贫瘠高原)和易陷入局部最优的问题，提升量子算法在制备基态时的优化效率和可靠性。

Method: 采用绝热路径上的迭代VQE方法，针对序列哈密顿量进行优化；通过理论推导确定梯度优化成功条件；提出利用能量标准差测量作为运行时认证手段。

Result: 推导出梯度优化成功制备绝热基态的充分条件，证明该方法能有效规避贫瘠高原和局部最优陷阱；建立了基于能量标准差测量的本征态精度认证和收敛验证机制。

Conclusion: 该绝热VQE变体通过理论保证的优化路径和实时验证机制，显著提升了量子基态制备的可靠性和优化效率，为实用化量子计算提供了新方案。

Abstract: We study an adiabatic variant of the variational quantum eigensolver (VQE) in which VQE is performed iteratively for a sequence of Hamiltonians along an adiabatic path. We derive the conditions under which gradient-based optimization successfully prepares the adiabatic ground states. These conditions show that the barren plateau problem and local optima can be avoided. Additionally, we propose using energy-standard-deviation measurements at runtime to certify eigenstate accuracy and verify convergence to the global optimum.

</details>


### [125] [A Shadow Enhanced Greedy Quantum Eigensolver](https://arxiv.org/abs/2602.17615)
*Jona Erle,Balint Koczor*

Main category: quant-ph

TL;DR: 提出一种名为SEGQE的阴影增强贪数量子本征求解器，利用经典阴影实现测量高效的基态制备，在早期容错量子计算机中展现出对数级采样复杂度和线性迭代扩展性。


<details>
  <summary>Details</summary>
Motivation: 基态制备是量子计算的主要应用和容错算法的关键子程序，但在早期容错量子计算机中逻辑测量代价高昂，亟需自适应且节省测量次数的状态制备策略。

Method: 提出SEGQE框架，通过经典阴影在经典后处理中并行评估大量局域候选门的能量降低效应，每一步贪心地选择能量降低最大的量子门。

Result: 推导出严格的每迭代步最坏情况采样复杂度边界，其对候选门数量呈对数依赖；在横向场Ising模型和随机局域哈密顿量上的数值测试表明，迭代次数随系统尺寸近似线性增长，同时实现高保真度基态近似和具有竞争力的能量估计。

Conclusion: SEGQE是一种测量高效的基态制备原语，非常适合早期容错量子计算架构。

Abstract: While ground-state preparation is expected to be a primary application of quantum computers, it is also an essential subroutine for many fault-tolerant algorithms. In early fault-tolerant regimes, logical measurements remain costly, motivating adaptive, shot-frugal state-preparation strategies that efficiently utilize each measurement. We introduce the Shadow Enhanced Greedy Quantum Eigensolver (SEGQE) as a greedy, shadow-assisted framework for measurement-efficient ground-state preparation. SEGQE uses classical shadows to evaluate, in parallel and entirely in classical post-processing, the energy reduction induced by large collections of local candidate gates, greedily selecting at each step the gate with the largest estimated energy decrease. We derive rigorous worst-case per-iteration sample-complexity bounds for SEGQE, exhibiting logarithmic dependence on the number of candidate gates. Numerical benchmarks on finite transverse-field Ising models and ensembles of random local Hamiltonians demonstrate convergence in a number of iterations that scales approximately linearly with system size, while maintaining high-fidelity ground-state approximations and competitive energy estimates. Together, our empirical scaling laws and rigorous per-iteration guarantees establish SEGQE as a measurement-efficient state-preparation primitive well suited to early fault-tolerant quantum computing architectures.

</details>


### [126] [The Hidden Nature of Non-Markovianity](https://arxiv.org/abs/2602.17631)
*Jihong Cai,Advith Govindarajan,Marius Junge*

Main category: quant-ph

TL;DR: Non-Markovian quantum dynamics become indistinguishable from Markovian evolutions when observing single trajectories under mild assumptions, making non-Markovianity "invisible" in such cases.


<details>
  <summary>Details</summary>
Motivation: To understand whether non-Markovian quantum evolutions (which preserve memory and can outperform Markovian ones) exhibit observable differences from Markovian dynamics when analyzing individual quantum trajectories.

Method: Comparing trajectories of Markovian (time-dependent Lindbladian) and non-Markovian evolutions starting from identical initial states, under general physical assumptions.

Result: Every quantum trajectory (single-system evolution path) can be reproduced by a family of time-dependent Markovian Lindbladian generators, regardless of the original dynamics being Markovian or non-Markovian.

Conclusion: Non-Markovianity cannot be detected through single-trajectory observations alone; its signatures only emerge in ensemble-averaged or multi-trajectory analyses, implying practical limitations in identifying memory effects experimentally via single runs.

Abstract: The theory of open quantum systems served as a tool to prepare entanglement at the beginning stage of quantum technology and more recently provides an important tool for state preparation. Dynamics given by time dependent Lindbladians are Markovian and lead to decoherence, decay of correlation and convergence to equilibrium. In contrast Non-Markovian evolutions can outperform their Markovian counterparts by enhancing memory. In this letter we compare the trajectories of Markovian and Non-Markovian evolutions starting from a fixed initial value. It turns out that under mild assumptions every trajectory can be obtained from a family of time dependent Lindbladians. Hence Non-Markovianity is invisible if single trajectories are concerned.

</details>


### [127] [Pseudo-deterministic Quantum Algorithms](https://arxiv.org/abs/2602.17647)
*Hugo Aaronson,Tom Gur,Jiawei Li*

Main category: quant-ph

TL;DR: 该论文系统性地研究了伪确定性量子算法，提出了一种新型量子算法模型，并给出了在查询复杂度模型下的多个复杂性分离结果，包括经典随机算法与伪确定性量子算法之间的分离，以及伪确定性量子算法与经典伪确定性算法之间的指数级加速。同时给出了通用上界和若干可伪确定化的量子搜索问题。


<details>
  <summary>Details</summary>
Motivation: 伪确定性量子算法是一类对任意输入都能以较高概率输出规范解的量子算法。与经典随机算法不同，这类算法在给定输入时总是输出相同的解（即规范解），但允许有一定失败概率。现有研究缺乏系统性的复杂性分析。该论文旨在填补这一空白，探讨伪确定性量子算法的查询复杂度下界和优势界限。

Method: 在查询复杂度模型下，构造了两个具体问题（AOES和QL-Estimation），并利用新的下界技术（针对伪确定性特性定制）证明了相应的复杂性分离。此外，通过一般性分析给出了伪确定性量子算法相对于确定性算法的最大优势上界（五次方关系）。在算法层面，识别了若干可伪确定化的量子搜索问题，并给出了实现方案。

Result: 1. AOES问题的经典随机查询复杂度为O(1)，但对伪确定性量子算法需要Ω(N)次查询。
2. QL-Estimation问题中，伪确定性量子算法实现O(log N)查询，而经典伪确定性算法需要Θ(√N)查询，随机查询复杂度为O(1)。
3. 对于任意全问题R，有D(R) = Õ(psQ(R)^5)。
4. 实现了Grover搜索、元素不同性、三角形查找、k-和、图碰撞等问题的伪确定化版本。

Conclusion: 该论文首次系统性地建立了伪确定性量子算法的理论框架，揭示了其在查询复杂度模型下的能力与限制，为未来研究提供了理论基础和技术工具。

Abstract: We initiate a systematic study of pseudo-deterministic quantum algorithms. These are quantum algorithms that, for any input, output a canonical solution with high probability. Focusing on the query complexity model, our main contributions include the following complexity separations, which require new lower bound techniques specifically tailored to pseudo-determinism:
  - We exhibit a problem, Avoid One Encrypted String (AOES), whose classical randomized query complexity is $O(1)$ but is maximally hard for pseudo-deterministic quantum algorithms ($Ω(N)$ query complexity).
  - We exhibit a problem, Quantum-Locked Estimation (QL-Estimation), for which pseudo-deterministic quantum algorithms admit an exponential speed-up over classical pseudo-deterministic algorithms ($O(\log(N))$ vs. $Θ(\sqrt{N})$), while the randomized query complexity is $O(1)$.
  Complementing these separations, we show that for any total problem $R$, pseudo-deterministic quantum algorithms admit at most a quintic advantage over deterministic algorithms, i.e., $D(R) = \tilde O(psQ(R)^5)$.
  On the algorithmic side, we identify a class of quantum search problems that can be made pseudo-deterministic with small overhead, including Grover search, element distinctness, triangle finding, $k$-sum, and graph collision.

</details>


### [128] [Approaching the Limit in Multiparameter AC Magnetometry with Quantum Control](https://arxiv.org/abs/2602.17648)
*Takuya Isogawa,Zhiyao Hu,Ayumi Kanamoto,Nutdech Phadetsuwannukun,Shilin Wang,Shunsuke Nishimura,Boning Li,Liang Jiang,Zain H. Saleem,Guoqing Wang,Haidong Yuan,Paola Cappellaro*

Main category: quant-ph

TL;DR: A quantum control protocol resolves the fundamental singularity problem in joint parameter estimation by engineering orthogonal generators, restoring optimal precision scaling for simultaneously estimating amplitude and frequency of AC magnetic fields, demonstrated with nitrogen-vacancy centers.


<details>
  <summary>Details</summary>
Motivation: The inherent incompatibility in optimal estimation strategies for multiple quantum parameters leads to a fundamental impossibility (singular QFIM) when estimating certain pairs like amplitude and frequency of AC magnetic fields, preventing joint estimation at the ultimate limit.

Method: The authors introduce a quantum control protocol that strategically engineers the sensor's time evolution to make the generators for the two parameters orthogonal, thereby removing the singularity.

Result: The protocol restores the optimal scaling of precision with interrogation time for both parameters simultaneously. This was experimentally validated using a nitrogen-vacancy center in diamond at room temperature under realistic conditions.

Conclusion: This work provides a solution to a fundamental problem in quantum metrology, enabling the simultaneous estimation of incompatible parameters at the quantum limit through engineered control, with practical experimental demonstration.

Abstract: Simultaneously estimating multiple parameters at the ultimate limit is a central challenge in quantum metrology, often hindered by inherent incompatibilities in optimal estimation strategies. At its most extreme, this incompatibility culminates in a fundamental impossibility when the quantum Fisher information matrix (QFIM) becomes singular, rendering joint estimation unattainable. This is the case for a canonical problem: estimating the amplitude and frequency of an AC magnetic field, where the generators are parallel to each other. Here, we introduce a quantum control protocol that resolves this singularity. Our control protocol strategically engineers the sensor's time evolution so the generators for the two parameters become orthogonal. It not only removes the singularity but also restores the optimal scaling of precision with interrogation time for both parameters simultaneously. We experimentally validate this protocol using a nitrogen-vacancy center in diamond at room temperature, demonstrating the concurrent achievement of the optimal scaling for both parameters under realistic conditions.

</details>


### [129] [Benchmarking quantum phase-space methods for near-resonant light propagation](https://arxiv.org/abs/2602.17660)
*Mojdeh S. Najafabadi,Joel F. Corney,Luis Sanchez Soto,Gerd Leuchs*

Main category: quant-ph

TL;DR: 比较截断Wigner和正P相空间表示法在光与近共振原子介质相互作用动力学中的适用性，发现前者在强相互作用和显著噪声条件下存在明显偏差


<details>
  <summary>Details</summary>
Motivation: 研究光与近共振原子介质相互作用的动力学行为，评估不同相空间表示方法（截断Wigner和正P）的精确度和适用边界

Method: 采用Jordan-Schwinger映射描述原子自由度，分别通过截断Wigner和正P相空间表示法模拟系统动力学，包括幺正演化和光学浴耦合两种场景

Result: 两种方法均能捕捉光-物质相互作用的主要特征，但截断Wigner近似在强相互作用强度和浴诱导噪声显著时出现明显偏差，而正P表示表现更稳定

Conclusion: 截断Wigner方法在弱相互作用和低噪声条件下有效，但在强耦合或高噪声环境中精度不足；正P表示具有更广的适用性，为复杂量子光学系统模拟提供可靠工具

Abstract: We study the dynamics of light interacting with a near-resonant atomic medium using the truncated Wigner and positive P phase-space representations. The atomic degrees of freedom are described using the Jordan-Schwinger mapping. The dynamics is first analyzed under unitary evolution and subsequently in the presence of an optical reservoir. While both approaches capture the main features of the light-matter dynamics, we find that the truncated Wigner approximation exhibits noticeable deviations for stronger interaction strengths and when reservoir-induced noise becomes significant.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [130] [Singular three-point density correlations in two-dimensional Fermi liquids](https://arxiv.org/abs/2602.16774)
*Pok Man Tam,Charles L. Kane*

Main category: cond-mat.str-el

TL;DR: 发现二维费米液体中三点密度关联存在由|q₁×q₂|描述的奇点，其系数在非相互作用体系中由费米海的欧拉示性数量化，并在相互作用体系中通过朗道参数表达重正化


<details>
  <summary>Details</summary>
Motivation: 揭示二维相互作用费米液体中等时三点密度关联的普适奇点结构及其拓扑起源

Method: 采用长波极限共线近似分析动量空间三点关联函数，结合朗道费米液体理论处理相互作用效应

Result: 1) 奇点形式为|q₁×q₂| 2) 非相互作用体系系数=费米海欧拉示性数 3) 相互作用体系系数由朗道参数重正化 4) 暗示实空间长程共线关联

Conclusion: 该奇点是二维费米液体的普适特征，其系数变化反映相互作用强度，对量子气体实验测量具有指导意义

Abstract: We characterize a singularity in the equal-time three-point density correlations that is generic to two-dimensional interacting Fermi liquids. In momentum space where the three-point correlation is determined by two wavevectors $\mathbf{q}_1$ and $\mathbf{q}_2$, the singularity takes the form $|\mathbf{q}_1\times\mathbf{q}_2|$. We explain how this singularity is sharply defined in a long-wavelength collinear limit. For a non-interacting Fermi gas, the coefficient of this singularity is given by the quantized Euler characteristic of the Fermi sea, and it implies a long-range real space correlation favoring collinear configurations. We show that this singularity persists in interacting Fermi liquids, and express the renormalization of the coefficient of singularity in terms of Landau parameters, for both spinless and spinful Fermi liquids. Implications for quantum gas experiments are discussed.

</details>


### [131] [Magnetoelectric Raman Force on Shear Phonons in a Frustrated van der Waals Bilayer Magnet](https://arxiv.org/abs/2602.16785)
*Wolfram Brenig*

Main category: cond-mat.str-el

TL;DR: This paper extends coherent phonon generation mechanisms from conventional solids to frustrated quantum magnets by analyzing a bilayer spin system, revealing strong anisotropy and magnon lifetime sensitivity in Raman force responses.


<details>
  <summary>Details</summary>
Motivation: To bridge pump-probe spectroscopy principles (traditionally applied to conventional solids) with frustrated quantum magnets, leveraging recent advances in van der Waals multiferroic materials to explore novel magneto-phononic coupling phenomena.

Method: Models a stacked triangular magnet bilayer using linear spin wave theory; derives magnon-electric field coupling via spin-current-induced polarization and phonon-magnon scattering from magnetoelastic energy; evaluates a mixed three-point Raman force response function.

Result: The Raman force response exhibits strong anisotropy and extreme sensitivity to magnon lifetimes, demonstrating that coherent phonon generation can be induced by laser fields in frustrated quantum magnets via magnon-phonon coupling.

Conclusion: Frustrated quantum magnets support laser-driven coherent phonon generation analogous to solids, with unique anisotropic signatures sensitive to quantum fluctuations—enabling new spectroscopic probes for quantum magnetism and multiferroic materials.

Abstract: We show that the concept of coherent phonon generation by second order response to incident electric laser fields, which is a hallmark of pump-probe spectroscopy on conventional solids, can be expanded to include frustrated quantum magnets. For that purpose, we analyze the Raman force on the shear phonons of a frustrated magnetoelectric bilayer spin system. The bilayer is a stacked triangular magnet, motivated by recently emerging type-II van der Waals multiferroic transition metal dihalides and comprises a spin system which allows for incommensurate spiral order. The magnon excitations are treated by linear spin wave theory. In the spiral state, a finite electric polarization is obtained from the spin-current interaction which induces a coupling of the magnons to the electric field. Scattering of the bilayer shear phonons from the magnons is derived from a magnetoelastic energy. In this scenario, a mixed three-point response function for the Raman force is evaluated. We find it to be strongly anisotropic and very sensitive to the magnon lifetime.

</details>


### [132] [Ground State of BaFe2S3 from Lattice and Spin Dynamics](https://arxiv.org/abs/2602.16899)
*Y. Oubaid,S. Deng,NS. Dhami,M. Verseils,D. Bounoua,A. Forget,D. Colson,P. Foury-Leylekian,M. B. Lepetit,V. Balédent*

Main category: cond-mat.str-el

TL;DR: 研究揭示准一维梯子化合物BaFe₂S₃中短程动态磁关联可驱动静态结构不稳定性，为理解铁基超导体中非巡游体系的磁弹性耦合机制提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 探究晶格对称性、声子与磁性之间的相互作用，特别是结构相变与磁有序之间的关系，以揭示铁基超导体中非巡游电子体系的磁弹性耦合机制。

Method: 结合极化同步辐射红外光谱、杂化泛函密度泛函理论计算和非弹性中子散射技术，系统分析材料的晶格动力学、声子行为及磁激发特性。

Result: 发现低温晶体对称性为P1空间群；多个红外活性声子模式在结构转变温度T_S≈125-130K和奈尔温度T_N≈95K处出现异常；第一性原理计算表明T_S处受影响的模式主要调制磁交换路径；中子散射显示T_N以下为三维长程静态磁有序，T_N与T_S之间存在三维短程动态磁关联，T_S以上磁关联消失；结构转变与磁涨落的 onset 相吻合。

Conclusion: 短程动态磁关联足以驱动静态结构不稳定性，提供了磁驱动机制，虽类似于铁磷系122家族，但在准一维Mott体系中实现；该发现强调了磁弹性耦合在铁基超导体中的核心作用，超越了传统的巡游电子体系范畴。

Abstract: We investigate the interplay between lattice symmetry, phonons, and magnetism in the quasi-one-dimensional ladder compound BaFe$_2$S$_3$ by combining polarized synchrotron infrared spectroscopy, hybrid-functional density functional theory calculations, and inelastic neutron scattering. Lattice-dynamics analysis reveals that the crystal symmetry is lower than previously proposed and is consistent with a $P1$ space group at low temperature. Several infrared-active phonon modes exhibit pronounced anomalies at both the structural transition temperature $T_S \approx 125$--$130$~K and the Néel temperature $T_N \approx 95$~K. First-principles calculations show that the modes affected at $T_S$ predominantly involve displacements that modulate magnetic exchange pathways. Neutron scattering demonstrates that below $T_N$ the magnetic order is three-dimensional, long-ranged, and static. Between $T_N$ and $T_S$, the system displays three-dimensional short-range dynamic magnetic correlations, which disappear above $T_S$. The structural transition thus coincides with the onset of magnetic fluctuations rather than with static magnetic order. Our results indicate that short-range, dynamical magnetic correlations are sufficient to drive a static structural instability, providing a magnetically driven mechanism reminiscent of the iron-pnictide 122 family, yet realized here in a quasi-one-dimensional Mott system. These findings highlight the central role of magnetoelastic coupling in iron-based superconductors beyond the itinerant regime.

</details>


### [133] [Phase transitions in coupled Ising chains and SO($N$)-symmetric spin chains](https://arxiv.org/abs/2602.17029)
*Yohei Fuji,Sylvain Capponi,Lukas Devos,Philippe Lecheminant*

Main category: cond-mat.str-el

TL;DR: 该研究揭示了在(1+1)维场论中，当N个Ising共形场论通过竞争微扰相互作用时，量子相变的性质随N变化：N=2,3时为连续相变（分别属于Ising和四态Potts普适类），而N≥4时转变为一级相变，这一结论修正了关于对称保护拓扑相变临界性的现有猜想。


<details>
  <summary>Details</summary>
Motivation: 探究由N个Ising共形场论通过竞争微扰相互作用的(1+1)维场论中量子相变的本质，特别关注该相变在不同N值下的普适性分类，以及其在耦合Ising链、自旋梯子等晶格模型中对称保护拓扑相变的应用。

Method: 结合微扰重整化群分析和大型矩阵乘积态数值模拟，系统研究相变性质随N的变化规律。

Result: (1) N=2和N=3时相变为连续相变，分别属于Ising和四态Potts普适类；(2) N≥4时相变呈现一级相变特征；(3) 该结论适用于SO(N)对称性的晶格模型（如两腿自旋梯），揭示了拓扑相与平庸相之间的相变临界行为。

Conclusion: 竞争微扰下量子相变的连续性存在临界阈值（N=4），该发现修正了关于对称保护拓扑相之间相变临界性的近期猜想，为相关低维量子系统的相变分类提供了新框架。

Abstract: We investigate the nature of quantum phase transitions in a (1+1)-dimensional field theory composed of $N$ copies of the Ising conformal field theory interacting via competing relevant perturbations. The field theory governs the competition between a mass term and an interaction involving the product of $N$ order-parameter fields, which is realized, e.g. in coupled Ising chains, two-leg spin ladders, and SO($N$)-symmetric spin chains. By combining a perturbative renormalization group analysis and large-scale matrix-product state simulations, we systematically determine the nature of the phase transition as a function of $N$. For $N=2$ and $N=3$, we confirm that the transition is continuous, belonging to the Ising and four-state Potts universality classes, respectively. In contrast, for $N \ge 4$, our results provide compelling evidence that the transition becomes first order. We further apply these findings to specific lattice models with SO($N$) symmetry, including spin-$1/2$ and spin-$1$ two-leg ladders, that realize a direct transition between an SO($N$) symmetry-protected topological phase and a trivial phase. Our results refine a recent conjecture regarding the criticality of transitions between SPT phases.

</details>


### [134] [Ghost Embedding Bridging Chemistry and One-Body Theories](https://arxiv.org/abs/2602.17164)
*Carlos Mejuto-Zaera,Michele Fabrizio*

Main category: cond-mat.str-el

TL;DR: 提出一个严格框架，将强关联多体系统与准粒子单粒子图像连接，并通过计算策略高效求解幽灵古兹维勒嵌入近似，重新表述伍德沃德-霍夫曼规则以适用于强关联体系


<details>
  <summary>Details</summary>
Motivation: 现有唯象规则（如基于非相互作用轨道/能带的伍德沃德-霍夫曼规则）虽对强关联体系预测准确，但其启发式非相互作用表述可能阻碍过渡金属等强关联材料的新规则开发

Method: 构建准粒子理论框架桥接相互作用系统与有效单粒子图像，并开发计算策略高效获取幽灵古兹维勒嵌入近似的核心组分

Result: 成功将伍德沃德-霍夫曼规则重新表述为准粒子形式，并应用于模拟反应场景验证其覆盖的主要反应机制

Conclusion: 该框架突破了非相互作用表述的限制，为强关联体系（如过渡金属化合物）设计新材料和反应规则提供了新理论基础

Abstract: Phenomenological rules play a central role in the design of chemical reactions and materials with targeted properties. Typically, these are formulated heuristically in terms of non-interacting orbitals and bands, yet show remarkable accuracy in predicting the complex behavior of intrinsically interacting many-body systems. While their non-interacting formulation makes them easy to interpret, it potentially hinders the development of new rules for systems governed by strong correlation, such as transition metal-based materials. In this work, we present a rigorous framework that allows bridging between fully interacting, even strongly correlated, systems and an effective one-body picture in terms of quasiparticles. Further, we present a computational strategy to efficiently and accurately access the main components of such a description: the embedding approximation of the ghost Gutzwiller Ansatz. We illustrate the capabilities of this quasiparticle formulation on the Woodward-Hoffmann rules, and apply their reformulated version to toy ``reactions'' which exemplify the main scenarios covered by them.

</details>


### [135] [High-temperature $η$-pairing superconductivity in the photodoped Hubbard model](https://arxiv.org/abs/2602.17238)
*Lei Geng,Aaram J. Kim,Philipp Werner*

Main category: cond-mat.str-el

TL;DR: 利用稳态实频轴动力学平均场理论，首次在光掺杂哈伯德莫特绝缘体中实现高效η配对超导态，揭示非平衡态下可调控高温超导的新机制


<details>
  <summary>Details</summary>
Motivation: 探索非平衡态（光掺杂）下莫特绝缘体中实现高温超导的可能性，突破传统化学掺杂的局限，寻找区别于常规s波/d波超导的新机制

Method: 采用稳态实频轴动力学平均场理论（SS-DMFT）结合高阶强耦合杂质求解器，在真实频率轴上计算光掺杂哈伯德模型的非平衡态相图、动量分辨谱函数及光学电导率

Result: 1) 获得具有极高有效临界温度的光诱导η配对超导相图；2) 在动量分辨谱函数和光学电导率中观测到超导能隙特征；3) 证实该超导态与平衡态s波/d波超导存在本质区别

Conclusion: 光掺杂为强关联体系提供了可精确调控的高温超导新路径，η配对机制在非平衡态下实现高效超导，为实验探测和新型超导材料设计提供理论基础

Abstract: We investigate superconductivity emerging in the photodoped Mott insulating Hubbard model using steady-state dynamical mean-field theory implemented on the real-frequency axis. By employing high-order strong-coupling impurity solvers, we obtain the nonequilibrium phase diagram for photoinduced $η$-pairing superconductivity with a remarkably high effective critical temperature. We further identify a superconducting gap in the momentum-resolved spectral function and optical conductivity, providing spectroscopic signatures accessible to experiments. Our results highlight a route to a controllable form of high-temperature superconductivity in nonequilibrium strongly correlated systems, fundamentally distinct from the equilibrium $s$-wave pairing state in the attractive Hubbard model or cuprate-like $d$-wave superconductors.

</details>


### [136] [Orbital current signature using neutron diffraction](https://arxiv.org/abs/2602.17311)
*Dalila Bounoua,William Liège,Yvan Sidis,Philippe Bourges*

Main category: cond-mat.str-el

TL;DR: 本文综述了关联电子材料中轨道环流特征，通过极化中子衍射在多类量子材料中观测到该现象，并提出基于微观电流的替代性中子散射截面描述方法。


<details>
  <summary>Details</summary>
Motivation: 系统理解关联电子材料中轨道环流的标志性特征及其实验证据，探索超越传统点磁矩模型的中子散射理论描述。

Method: 利用极化中子衍射技术探测材料内部轨道磁矩；建立基于原子轨道间微观环流的中子磁散射截面理论模型。

Result: 在铜基超导体、铱酸盐、铜氧化物自旋梯及笼目钒酸盐超导体中均观测到环流信号；新模型揭示了与传统点磁矩模型在磁结构因子上的定量差异。

Conclusion: 基于微观电流的中子散射描述提供了更精细的轨道环流探测框架，有助于深化对量子材料中电子关联效应的理解。

Abstract: We review the hallmarks of orbital loop currents in various correlated electron materials and how they have been evidenced using polarized neutron diffraction. Over the last 20 years, loop current signatures have been observed in high temperature copper oxide superconductors, iridates, copper oxides spin ladders and recently kagome vanadate superconductors. Such currents induce orbital magnetic moments within the unit cell of these quantum materials that can be detected through their interaction with the neutron spin. In addition to the usual description of orbital moments using point-like local magnetic moments, we here show an alternative description of the neutron magnetic cross-section involving the microscopic currents running between different atomic orbitals. We discuss the corresponding magnetic structure factors and the resulting quantitative differences between both approaches.

</details>


### [137] [Hybrid Monte Carlo for Fractional Quantum Hall States](https://arxiv.org/abs/2602.17564)
*Ting-Tung Wang,Ha Quang Trung,Qianhui Xu,Min Long,Bo Yang,Zi Yang Meng*

Main category: cond-mat.str-el

TL;DR: 开发混合蒙特卡洛方法高效计算分数量子霍尔系统的物理观测量，实现N>1000的大体系模拟，应用于拓扑位移和非阿贝尔编织矩阵的高精度计算


<details>
  <summary>Details</summary>
Motivation: 传统Metropolis蒙特卡洛方法计算分数量子霍尔波函数效率低下，难以模拟超过1000个电子的大体系，限制了拓扑性质和热力学极限的研究

Method: 结合全局更新和球面双立体投影技术的混合蒙特卡洛方法，在球面和圆盘几何上加速Laughlin和Moore-Read波函数的采样过程

Result: 1) 计算速度显著超越传统Metropolis方法；2) 成功模拟N>1000电子体系；3) 高精度获得圆盘边缘偶极矩表征的拓扑位移；4) 球面Moore-Read准空穴非阿贝尔编织矩阵质量优于前人工作

Conclusion: 该方法为研究理想陈绝缘体中分数量子霍尔态的不稳定性和量子退相干问题提供了高效工具，有助于澄清相关物理争议

Abstract: We develop a hybrid Monte Carlo method to efficiently compute the physical observables from the samplings of the Laughlin and the Moore-Read wave functions of fractional quantum Hall (FQH) systems. With the advancements in methodology, including global updates and double stereographic projection on spherical geometry, our hybrid Monte Carlo simulation is significantly faster than the widely used Metropolis Monte Carlo scheme. As a result, we can readily simulate systems with electron numbers $N > 1000$ on both disk and sphere geometries. We apply this method to investigating the topological shift obtained from the edge dipole moment, computed from the density of the wave function on the disk. We also numerically computed the non-Abelian braiding matrices for different braiding schemes of the Moore-Read quasiholes on the sphere. Results with much better quality compared with previous works have been achieved. With the thermodynamic limit results obtained at ease, we also discuss the future usage of our method to clarify the questions on the instability of fractional quantum Hall states in an ideal Chern band setting or under quantum decoherence.

</details>


### [138] [Planckian bound on the local equilibration time](https://arxiv.org/abs/2602.17638)
*Marvin Qi,Alexey Milekhin,Luca Delacrétaz*

Main category: cond-mat.str-el

TL;DR: 该研究形式化定义了量子多体系统的局部平衡时间τ_eq，并利用热关联函数的解析性质，证明了其满足普适下界τ_eq ≥ αℏ/T，其中α仅依赖于维度和流体力学行为类型。


<details>
  <summary>Details</summary>
Motivation: 探索量子多体系统达到局部平衡的普适时间下限，建立与普朗克时间ℏ/T的关联，以深化对量子热化动力学和流体力学涌现机制的理解。

Method: 将τ_eq定义为守恒密度适用流体力学描述的时间尺度，通过分析实时热关联函数的解析结构，对正则化的热两点函数建立严格的数学下界。

Result: 推导出普适的平衡时间下界τ_eq ≥ αℏ/T，该下界的系数α与系统维度、流体力学/扩散行为类型相关，且独立于微观细节、热化机制、准粒子描述及非弹性散射。

Conclusion: 该普适下界揭示了局部量子多体系统平衡时间的根本限制，为理解量子多体系统的热化和流体力学行为提供了新的理论框架。

Abstract: The local equilibration time $τ_{\rm eq}$ of quantum many-body systems is conjectured to be bounded below by the Planckian time $\hbar /T$. We formalize this conjecture by defining $τ_{\rm eq}$ as the time scale at which a hydrodynamic description emerges for conserved densities. Drawing on analytic properties of real time thermal correlators, we establish a rigorous lower bound $τ_{\rm eq} \geq α\hbar /T$ on the onset of hydrodynamic behavior in a `regulated' thermal two-point function. The dimensionless coefficient $α$ depends only on dimensionality and the type of hydrodynamic or diffusive behavior that emerges, and is independent of the thermalization mechanism or other microscopic details. This bound applies universally to local quantum many-body systems, with or without a quasiparticle description, including in the presence of inelastic scattering.

</details>


### [139] [Anisotropic marginal Fermi liquid for Coulomb interacting generalized Weyl fermions](https://arxiv.org/abs/2602.17666)
*Gabriel Malavé,Rodrigo Soto-Garrido,Bitan Roy,Vladimir Juričić*

Main category: cond-mat.str-el

TL;DR: 在三维广义外尔半金属中，由于准粒子色散的幂律各向异性导致态密度增强，长程库仑相互作用效应被放大；当外尔节点单极子电荷n≥2时，系统进入各向异性的非费米液体标度区，而n=1时保持各向同性外尔液体特性。


<details>
  <summary>Details</summary>
Motivation: 研究三维广义外尔半金属（单极子电荷n>1）中幂律各向异性准粒子色散如何增强态密度，进而放大长程库仑相互作用效应，探索不同n值下系统的量子临界行为。

Method: 采用大N展开（N为外尔费米子味数）的威尔逊重正化群方法，结合由Ward-Takahashi恒等式确定的规范一致正则化方案，控制理论计算精度。

Result: 1. n≥2时：系统呈现扩展的相互作用主导标度区，具有各向异性动态库仑屏蔽、有限费米子反常维数、准粒子残差幂律抑制，形成各向异性边际非费米液体；有效精细结构常数对数缓慢流向零，边际费米液体行为作为宽交叉区出现。
<longcat_arg_value>2. n=1时：系统保持各向同性边际外尔液体特性。

Conclusion: 单极子电荷n值决定外尔半金属的量子相：n≥2时库仑相互作用导致各向异性非费米液体行为，n=1时维持外尔液体特性；边际费米液体交叉行为由缓慢跑动的耦合常数控制，为实验观测提供明确方向。

Abstract: Owing to the power-law anisotropy in the quasiparticle dispersion, yielding an enhanced density of states, the effects of long range Coulomb interaction get amplified in three-dimensional generalized Weyl semimetals, characterized by integer monopole charge $n>1$ of the underlying Weyl nodes. Using a Wilsonian renormalization group approach controlled by a large-$N$ expansion with $N$ as the number of Weyl fermion flavors and a gauge-consistent regularization fixed by the Ward-Takahashi identity, we uncover for $n\ge 2$ an extended interaction-dominated scaling regime with intrinsically anisotropic dynamic Coulomb screening, a finite fermionic anomalous dimension, and a power-law suppression of the quasiparticle residue, yielding an \emph{anisotropic} marginal non-Fermi liquid at intermediate energies. Ultimately, the effective fine structure constant flows to zero, albeit only logarithmically slowly, so the marginal Fermi liquid phenomenology emerges as a broad crossover, controlled by a slowly running coupling. By contrast, for $n=1$ the system retains an isotropic marginal Weyl-liquid character. These predictions can be tested via scaling in thermodynamics (specific heat and compressibility), direction-dependent optical conductivity, and by anisotropic broadening of the single-particle spectral function in angle-resolved photoemission spectroscopy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [140] [AIdentifyAGE Ontology for Decision Support in Forensic Dental Age Assessment](https://arxiv.org/abs/2602.16714)
*Renato Marcelo,Ana Rodrigues,Cristiana Palmela Pereira,António Figueiras,Rui Santos,José Rui Figueira,Alexandre P Francisco,Cátia Vaz*

Main category: cs.AI

TL;DR: 开发AIdentifyAGE本体以标准化法医牙科年龄评估流程，解决方法论异质性和数据互操作性问题，提升AI时代下的透明度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 当前牙科年龄评估方法存在方法论异质性、数据碎片化及系统互操作性差等问题，影响法医司法决策的透明度和可重复性，尤其AI应用加剧了这一挑战。

Method: 构建领域专用本体AIdentifyAGE，整合人工与AI辅助的牙科年龄评估全流程，关联观察、方法、参考数据与结果，并基于生物医学/牙科/机器学习上层本体确保互操作性。

Result: 实现了可追溯的牙龄评估工作流建模，涵盖司法背景、个体信息、检查数据、影像、统计参考及AI方法，符合FAIR原则。

Conclusion: 该本体为法医司法领域的决策支持系统奠定基础，显著提升评估一致性、透明度和可解释性。

Abstract: Age assessment is crucial in forensic and judicial decision-making, particularly in cases involving undocumented individuals and unaccompanied minors, where legal thresholds determine access to protection, healthcare, and judicial procedures. Dental age assessment is widely recognized as one of the most reliable biological approaches for adolescents and young adults, but current practices are challenged by methodological heterogeneity, fragmented data representation, and limited interoperability between clinical, forensic, and legal information systems. These limitations hinder transparency and reproducibility, amplified by the increasing adoption of AI- based methods. The AIdentifyAGE ontology is domain-specific and provides a standardized, semantically coherent framework, encompassing both manual and AI-assisted forensic dental age assessment workflows, and enabling traceable linkage between observations, methods, reference data, and reported outcomes. It models the complete medico-legal workflow, integrating judicial context, individual-level information, forensic examination data, dental developmental assessment methods, radiographic imaging, statistical reference studies, and AI-based estimation methods. It is being developed together with domain experts, and it builds on upper and established biomedical, dental, and machine learning ontologies, ensuring interoperability, extensibility, and compliance with FAIR principles. The AIdentifyAGE ontology is a fundamental step to enhance consistency, transparency, and explainability, establishing a robust foundation for ontology-driven decision support systems in medico-legal and judicial contexts.

</details>


### [141] [Contextuality from Single-State Representations: An Information-Theoretic Principle for Adaptive Intelligence](https://arxiv.org/abs/2602.16716)
*Song-Ju Kim*

Main category: cs.AI

TL;DR: 该研究发现，在经典概率表示中，跨上下文重用单一内部状态必然导致情境性，并产生不可约的信息论代价，而量子框架可通过放宽单一全局联合概率空间的假设来避免这一问题。


<details>
  <summary>Details</summary>
Motivation: 自然和人工智能中普遍存在的单状态重用现象对表征能力的影响尚未被充分理解，本研究旨在揭示这一基本约束。

Method: 将上下文建模为作用于共享内部状态的干预，通过信息论分析证明经典模型的根本限制，并构造最小示例。

Result: 证明任何复现情境性结果统计的经典模型都必须承担不可约的信息论代价：仅通过内部状态无法中介上下文依赖。

Conclusion: 情境性是适应性智能的普遍表征约束，与物理实现无关；非经典概率框架可通过放弃单一全局联合概率空间假设来规避此限制。

Abstract: Adaptive systems often operate across multiple contexts while reusing a fixed internal state space due to constraints on memory, representation, or physical resources. Such single-state reuse is ubiquitous in natural and artificial intelligence, yet its fundamental representational consequences remain poorly understood. We show that contextuality is not a peculiarity of quantum mechanics, but an inevitable consequence of single-state reuse in classical probabilistic representations. Modeling contexts as interventions acting on a shared internal state, we prove that any classical model reproducing contextual outcome statistics must incur an irreducible information-theoretic cost: dependence on context cannot be mediated solely through the internal state. We provide a minimal constructive example that explicitly realizes this cost and clarifies its operational meaning. We further explain how nonclassical probabilistic frameworks avoid this obstruction by relaxing the assumption of a single global joint probability space, without invoking quantum dynamics or Hilbert space structure. Our results identify contextuality as a general representational constraint on adaptive intelligence, independent of physical implementation.

</details>


### [142] [Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation](https://arxiv.org/abs/2602.16727)
*Hua Yan,Heng Tan,Yingxue Zhang,Yu Yang*

Main category: cs.AI

TL;DR: 提出MobCache框架，通过可重构缓存机制提升大规模人类移动模拟效率，在保持与先进LLM方法性能相当的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大规模人类移动模拟对城市规划、流行病学等领域至关重要，但现有基于大语言模型(LLM)的方法计算成本高昂，限制了可扩展性。

Method: 设计MobCache框架：(1) 推理组件将每一步推理编码为潜在空间嵌入，通过潜在空间评估器实现推理步骤的复用与重组；(2) 解码组件采用轻量级解码器，通过移动规律约束的知识蒸馏将潜在空间推理链转换为自然语言。

Result: 实验表明，MobCache在多个维度上显著提升效率，同时保持与当前最优LLM方法相当的性能表现。

Conclusion: MobCache通过可重构缓存机制有效解决了LLM-based移动模拟的可扩展性问题，实现了高效的大规模模拟。

Abstract: Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost limits scalability. To address this, we design a mobility-aware cache framework named MobCache that leverages reconstructible caches to enable efficient large-scale human mobility simulations. It consists of: (1) a reasoning component that encodes each reasoning step as a latent-space embedding and uses a latent-space evaluator to enable the reuse and recombination of reasoning steps; and (2) a decoding component that employs a lightweight decoder trained with mobility law-constrained distillation to translate latent-space reasoning chains into natural language, thereby improving simulation efficiency while maintaining fidelity. Experiments show that MobCache significantly improves efficiency across multiple dimensions while maintaining performance comparable to state-of-the-art LLM-based methods.

</details>


### [143] [When AI Benchmarks Plateau: A Systematic Study of Benchmark Saturation](https://arxiv.org/abs/2602.16763)
*Mubashara Akhtar,Anka Reuel,Prajna Soni,Sanchit Ahuja,Pawan Sasanka Ammanamanchi,Ruchit Rawal,Vilém Zouhar,Srishti Yadav,Chenxi Whitehouse,Dayeon Ki,Jennifer Mickel,Leshem Choshen,Marek Šuppa,Jan Batzner,Jenny Chim,Jeba Sania,Yanan Long,Hossein A. Rahmani,Christina Knight,Yiyang Nan,Jyoutir Raj,Yu Fan,Shubham Singh,Subramanyam Sahoo,Eliya Habba,Usman Gohar,Siddhesh Pawar,Robert Scholz,Arjun Subramonian,Jingwei Ni,Mykel Kochenderfer,Sanmi Koyejo,Mrinmaya Sachan,Stella Biderman,Zeerak Talat,Avijit Ghosh,Irene Solaiman*

Main category: cs.AI

TL;DR: 该研究分析了60个大型语言模型基准测试的饱和现象，发现近半数基准随时间推移出现饱和，无法区分顶尖模型。隐藏测试数据无助于缓解饱和，而专家设计的基准比众包基准更具持久性。


<details>
  <summary>Details</summary>
Motivation: AI基准测试在模型评估中至关重要，但快速饱和导致其失去区分顶尖模型的能力，长期价值下降。需探究饱和成因及延长基准有效期的方法。

Method: 从主流模型技术报告中选取60个LLM基准，从任务设计、数据构建和评估格式三方面定义14项属性，通过5组假设检验各属性对饱和率的影响。

Result: 49%的基准呈现饱和且随时间加剧；隐藏测试数据（公有/私有）无法延缓饱和；专家设计基准的饱和率显著低于众包基准。

Conclusion: 基准设计选择直接影响其生命周期，专家参与和高质量构建可提升持久性，为构建更耐用评估体系提供策略依据。

Abstract: Artificial Intelligence (AI) benchmarks play a central role in measuring progress in model development and guiding deployment decisions. However, many benchmarks quickly become saturated, meaning that they can no longer differentiate between the best-performing models, diminishing their long-term value. In this study, we analyze benchmark saturation across 60 Large Language Model (LLM) benchmarks selected from technical reports by major model developers. To identify factors driving saturation, we characterize benchmarks along 14 properties spanning task design, data construction, and evaluation format. We test five hypotheses examining how each property contributes to saturation rates. Our analysis reveals that nearly half of the benchmarks exhibit saturation, with rates increasing as benchmarks age. Notably, hiding test data (i.e., public vs. private) shows no protective effect, while expert-curated benchmarks resist saturation better than crowdsourced ones. Our findings highlight which design choices extend benchmark longevity and inform strategies for more durable evaluation.

</details>


### [144] [Simple Baselines are Competitive with Code Evolution](https://arxiv.org/abs/2602.16805)
*Yonatan Gideoni,Sebastian Risi,Yarin Gal*

Main category: cs.AI

TL;DR: 该研究发现简单的基线方法在三个领域（数学边界优化、智能体框架设计和机器学习竞赛）中表现达到或超过复杂的代码演化技术，揭示出当前代码演化的主要挑战是搜索空间设计和评估质量，而非演化算法本身，呼吁未来研究采用更严谨的实践方法。


<details>
  <summary>Details</summary>
Motivation: 许多基于大语言模型的代码演化技术声称性能出色，但缺乏与简单基线的对比，可能高估了其实际效果，且未能真正理解问题的核心挑战所在。

Method: 在三个领域中测试两种简单基线方法（数学边界优化、智能体框架设计和机器学习竞赛），并与更复杂的代码演化流水线进行对比，分析不同因素对性能的影响。

Result: 简单基线在所有三个领域均达到或超过复杂方法；数学边界问题中搜索空间和提示词领域知识是主要决定因素；智能体框架设计因高方差和小数据集导致选择次优，手工设计框架表现最佳；需改进评估方法以降低随机性并保持经济性。

Conclusion: 当前代码演化方法在开发和使用中存在根本性缺陷，主要挑战在于问题建模而非搜索算法；应建立最佳实践并改进评估方式，以实现更严谨的未来研究。

Abstract: Code evolution is a family of techniques that rely on large language models to search through possible computer programs by evolving or mutating existing code. Many proposed code evolution pipelines show impressive performance but are often not compared to simpler baselines. We test how well two simple baselines do over three domains: finding better mathematical bounds, designing agentic scaffolds, and machine learning competitions. We find that simple baselines match or exceed much more sophisticated methods in all three. By analyzing these results we find various shortcomings in how code evolution is both developed and used. For the mathematical bounds, a problem's search space and domain knowledge in the prompt are chiefly what dictate a search's performance ceiling and efficiency, with the code evolution pipeline being secondary. Thus, the primary challenge in finding improved bounds is designing good search spaces, which is done by domain experts, and not the search itself. When designing agentic scaffolds we find that high variance in the scaffolds coupled with small datasets leads to suboptimal scaffolds being selected, resulting in hand-designed majority vote scaffolds performing best. We propose better evaluation methods that reduce evaluation stochasticity while keeping the code evolution economically feasible. We finish with a discussion of avenues and best practices to enable more rigorous code evolution in future work.

</details>


### [145] [Improved Upper Bounds for Slicing the Hypercube](https://arxiv.org/abs/2602.16807)
*Duncan Soiffer,Nathaniel Itty,Christopher D. Rosin,Blake Bruell,Mason DiCicco,Gábor N. Sárközy,Ryan Offstein,Daniel Reichman*

Main category: cs.AI

TL;DR: Improved upper bound for slicing hypercube edges: S(n) ≤ ⌈4n/5⌉ (or 4n/5+1 for odd multiples of 5), using AI tool CPro1 to construct hyperplane configurations


<details>
  <summary>Details</summary>
Motivation: Finding the minimum number of hyperplanes required to intersect all interior edges of an n-dimensional hypercube Q_n, improving upon Paterson's 1971 upper bound of ⌈5n/6⌉

Method: Constructed explicit hyperplane configurations using CPro1 (an AI tool combining reasoning LLMs with automated hyperparameter tuning for mathematical constructions), including an 8-hyperplane solution for Q₁₀

Result: 1) New upper bound: S(n) ≤ ⌈4n/5⌉ except S(n) ≤ 4n/5+1 when n is odd multiple of 5 (beating ⌈5n/6⌉). 2) New lower bounds on maximum edges sliceable by k<n hyperplanes

Conclusion: Achieved tighter bound for hyperplane slicing problem through computational construction, demonstrating CPro1's effectiveness in mathematical discovery

Abstract: A collection of hyperplanes $\mathcal{H}$ slices all edges of the $n$-dimensional hypercube $Q_n$ with vertex set $\{-1,1\}^n$ if, for every edge $e$ in the hypercube, there exists a hyperplane in $\mathcal{H}$ intersecting $e$ in its interior. Let $S(n)$ be the minimum number of hyperplanes needed to slice $Q_n$. We prove that $S(n) \leq \lceil \frac{4n}{5} \rceil$, except when $n$ is an odd multiple of $5$, in which case $S(n) \leq \frac{4n}{5} +1$. This improves upon the previously known upper bound of $S(n) \leq \lceil\frac{5n}{6} \rceil$ due to Paterson reported in 1971. We also obtain new lower bounds on the maximum number of edges in $Q_n$ that can be sliced using $k<n$ hyperplanes. We prove the improved upper bound on $S(n)$ by constructing $8$ hyperplanes slicing $Q_{10}$ aided by the recently introduced CPro1: an automatic tool that uses reasoning LLMs coupled with automated hyperparameter tuning to create search algorithms for the discovery of mathematical constructions.

</details>


### [146] [Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI](https://arxiv.org/abs/2602.16814)
*Eiman Kanjo,Mustafa Aslanov*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments. In this paper, we introduce Node Learning, a decen- tralised learning paradigm in which intelligence resides at individual edge nodes and expands through selective peer interaction. Nodes learn continuously from local data, maintain their own model state, and exchange learned knowledge opportunistically when collaboration is beneficial. Learning propagates through overlap and diffusion rather than global synchro- nisation or central aggregation. It unifies autonomous and cooperative behaviour within a single abstraction and accommodates heterogeneity in data, hardware, objectives, and connectivity. This concept paper develops the conceptual foundations of this paradigm, contrasts it with existing decentralised approaches, and examines implications for communi- cation, hardware, trust, and governance. Node Learning does not discard existing paradigms, but places them within a broader decentralised perspective

</details>


### [147] [An order-oriented approach to scoring hesitant fuzzy elements](https://arxiv.org/abs/2602.16827)
*Luis Merino,Gabriel Navarro,Carlos Salvatierra,Evangelina Santos*

Main category: cs.AI

TL;DR: 本文针对犹豫模糊集传统评分方法缺乏序理论基础的问题，提出基于序关系的统一评分框架，揭示经典序结构不构成格，证明对称序定义的评分满足强单调性与加德弗斯条件，并引入用于决策的支配函数。


<details>
  <summary>Details</summary>
Motivation: 传统犹豫模糊集评分方法缺乏序理论的形式化基础，导致评分机制不够灵活且缺乏一致性。

Method: 提出基于序关系的统一评分框架，分析经典序结构在犹豫模糊元上的性质，引入支配函数进行排序，并构建模糊偏好关系。

Result: 经典序结构不构成格，而对称序定义的评分满足强单调性与加德弗斯条件；提出的离散与相对支配函数可支持群体决策。

Conclusion: 该框架提供了更灵活的评分机制，支配函数在考虑最小可接受阈值的决策场景中具有重要应用价值。

Abstract: Traditional scoring approaches on hesitant fuzzy sets often lack a formal base in order theory. This paper proposes a unified framework, where each score is explicitly defined with respect to a given order. This order-oriented perspective enables more flexible and coherent scoring mechanisms. We examine several classical orders on hesitant fuzzy elements, that is, nonempty subsets in [0,1], and show that, contrary to prior claims, they do not induce lattice structures. In contrast, we prove that the scores defined with respect to the symmetric order satisfy key normative criteria for scoring functions, including strong monotonicity with respect to unions and the Gärdenfors condition.
  Following this analysis, we introduce a class of functions, called dominance functions, for ranking hesitant fuzzy elements. They aim to compare hesitant fuzzy elements relative to control sets incorporating minimum acceptability thresholds. Two concrete examples of dominance functions for finite sets are provided: the discrete dominance function and the relative dominance function. We show that these can be employed to construct fuzzy preference relations on typical hesitant fuzzy sets and support group decision-making.

</details>


### [148] [Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents](https://arxiv.org/abs/2602.16855)
*Haiyang Xu,Xi Zhang,Haowei Liu,Junyang Wang,Zhaozai Zhu,Shengjie Zhou,Xuhao Hu,Feiyu Gao,Junjie Cao,Zihua Wang,Zhiyuan Chen,Jitong Liao,Qi Zheng,Jiahui Zeng,Ze Xu,Shuai Bai,Junyang Lin,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: GUI-Owl-1.5是新一代原生GUI智能体模型，提供2B-235B多尺寸instruct/thinking变体，支持桌面、移动、浏览器等多平台云边协同。通过混合数据飞轮、统一能力增强和MRPO强化学习算法，在20+GUI基准测试上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 开发支持多平台（桌面、移动、浏览器）和云边协同的原生GUI智能体模型，提供不同尺寸版本（2B/4B/8B/32B/235B）以满足多样化部署需求。

Method: 提出三项核心创新：(1) 混合数据飞轮：结合模拟环境与云端沙箱环境构建UI理解和轨迹生成数据管道；(2) 统一智能体能力增强：通过思维合成管道提升推理能力，重点加强工具/MCP调用、记忆和多智能体适应能力；(3) 多平台环境RL扩展：提出MRPO算法解决多平台冲突和长周期任务训练效率低下的问题。

Result: 在20+开源GUI基准测试上达到SOTA：GUI自动化任务（OSWorld 56.5、AndroidWorld 71.6、WebArena 48.4）； grounding任务（ScreenSpotPro 80.3）；工具调用任务（OSWorld-MCP 47.6、MobileWorld 46.8）；记忆与知识任务（GUI-Knowledge Bench 75.5）。

Conclusion: GUI-Owl-1.5模型已开源，并提供在线云沙箱演示，可在https://github.com/X-PLUG/MobileAgent获取。

Abstract: The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge collaboration and real-time interaction. GUI-Owl-1.5 achieves state-of-the-art results on more than 20+ GUI benchmarks on open-source models: (1) on GUI automation tasks, it obtains 56.5 on OSWorld, 71.6 on AndroidWorld, and 48.4 on WebArena; (2) on grounding tasks, it obtains 80.3 on ScreenSpotPro; (3) on tool-calling tasks, it obtains 47.6 on OSWorld-MCP, and 46.8 on MobileWorld; (4) on memory and knowledge tasks, it obtains 75.5 on GUI-Knowledge Bench. GUI-Owl-1.5 incorporates several key innovations: (1) Hybird Data Flywheel: we construct the data pipeline for UI understanding and trajectory generation based on a combination of simulated environments and cloud-based sandbox environments, in order to improve the efficiency and quality of data collection. (2) Unified Enhancement of Agent Capabilities: we use a unified thought-synthesis pipeline to enhance the model's reasoning capabilities, while placing particular emphasis on improving key agent abilities, including Tool/MCP use, memory and multi-agent adaptation; (3) Multi-platform Environment RL Scaling: We propose a new environment RL algorithm, MRPO, to address the challenges of multi-platform conflicts and the low training efficiency of long-horizon tasks. The GUI-Owl-1.5 models are open-sourced, and an online cloud-sandbox demo is available at https://github.com/X-PLUG/MobileAgent.

</details>


### [149] [OpenSage: Self-programming Agent Generation Engine](https://arxiv.org/abs/2602.16891)
*Hongwei Li,Zhun Wang,Qinrun Dai,Yuzhou Nie,Jinjun Peng,Ruitong Liu,Jingyang Zhang,Kaijie Zhu,Jingxuan He,Lun Wang,Yangruibo Ding,Yueqi Chen,Wenbo Guo,Dawn Song*

Main category: cs.AI

TL;DR: OpenSage是一个新型智能体开发工具包，首次让大型语言模型能够自动生成具有自组织拓扑结构和工具集的智能体，并提供层次化图结构记忆系统。它在三个基准测试中超越现有工具包，标志着智能体开发从"人工设计"向"AI自主设计"的范式转变。


<details>
  <summary>Details</summary>
Motivation: 当前智能体开发工具包要么功能支持不足，要么依赖人工手动设计智能体拓扑、工具和记忆组件，这限制了智能体的泛化能力和整体性能。现有方法无法让智能体自主创建和管理子智能体及工具集。

Method: 提出OpenSage框架，包含三大核心组件：1）自生成拓扑机制，让LLM自主设计智能体结构；2）自生成工具集能力，支持动态创建管理工具；3）层次化图结构记忆系统，实现高效信息存储管理；4）面向软件工程任务的专用工具包。

Result: 在三个先进基准测试和多种骨干模型上的广泛实验表明，OpenSage相比现有ADKs具有显著优势。严格的消融研究验证了每个组件设计的有效性。

Conclusion: OpenSage为下一代智能体开发铺平道路，推动范式从以人为中心转向以AI为中心，使智能体能够自主创建和管理复杂系统，大幅提升性能上限。

Abstract: Agent development kits (ADKs) provide effective platforms and tooling for constructing agents, and their designs are critical to the constructed agents' performance, especially the functionality for agent topology, tools, and memory. However, current ADKs either lack sufficient functional support or rely on humans to manually design these components, limiting agents' generalizability and overall performance. We propose OpenSage, the first ADK that enables LLMs to automatically create agents with self-generated topology and toolsets while providing comprehensive and structured memory support. OpenSage offers effective functionality for agents to create and manage their own sub-agents and toolkits. It also features a hierarchical, graph-based memory system for efficient management and a specialized toolkit tailored to software engineering tasks. Extensive experiments across three state-of-the-art benchmarks with various backbone models demonstrate the advantages of OpenSage over existing ADKs. We also conduct rigorous ablation studies to demonstrate the effectiveness of our design for each component. We believe OpenSage can pave the way for the next generation of agent development, shifting the focus from human-centered to AI-centered paradigms.

</details>


### [150] [AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901)
*Tanqiu Jiang,Yuhui Wang,Jiacheng Liang,Ting Wang*

Main category: cs.AI

TL;DR: AgentLAB是一个用于评估LLM智能体对长周期攻击脆弱性的基准测试平台，包含5种新型攻击类型和28个真实环境，发现现有智能体高度易受攻击且单轮防御措施失效。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体在长周期复杂环境中的应用扩展，它们面临利用多轮用户-智能体-环境交互的新型长周期攻击威胁，但目前缺乏专门评估此类风险的基准工具。

Method: 构建了AgentLAB基准，包含意图劫持、工具链攻击、任务注入、目标漂移、记忆中毒5种新型攻击类型，涵盖28个真实智能体环境和644个安全测试用例，用于系统评估LLM智能体的安全性。

Result: 评估发现代表性LLM智能体对长周期攻击高度脆弱；且针对单轮交互设计的防御措施无法可靠缓解长周期威胁。

Conclusion: AgentLAB将成为一个有价值的基准工具，用于跟踪实际环境中LLM智能体安全性的进展，推动更安全智能体的研发。

Abstract: LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulnerabilities to such risks, we present AgentLAB, the first benchmark dedicated to evaluating LLM agent susceptibility to adaptive, long-horizon attacks. Currently, AgentLAB supports five novel attack types including intent hijacking, tool chaining, task injection, objective drifting, and memory poisoning, spanning 28 realistic agentic environments, and 644 security test cases. Leveraging AgentLAB, we evaluate representative LLM agents and find that they remain highly susceptible to long-horizon attacks; moreover, defenses designed for single-turn interactions fail to reliably mitigate long-horizon threats. We anticipate that AgentLAB will serve as a valuable benchmark for tracking progress on securing LLM agents in practical settings. The benchmark is publicly available at https://tanqiujiang.github.io/AgentLAB_main.

</details>


### [151] [Narrow fine-tuning erodes safety alignment in vision-language agents](https://arxiv.org/abs/2602.16931)
*Idhant Gulati,Shivam Raval*

Main category: cs.AI

TL;DR: This paper demonstrates that fine-tuning aligned vision-language models on harmful datasets causes severe misalignment that generalizes across tasks and modalities. Using Gemma3-4B, they find misalignment scales with LoRA rank, is significantly worse in multimodal vs text-only evaluation (70.71 vs 41.19), and persists even with only 10% harmful data. Harmful behaviors occupy low-dimensional subspaces. Two mitigation strategies (benign fine-tuning and activation steering) help but don't fully eliminate the problem, revealing the need for robust continual learning frameworks.


<details>
  <summary>Details</summary>
Motivation: Lifelong multimodal agents must continuously adapt through post-training, creating fundamental tension between acquiring new capabilities and preserving safety alignment. Current post-training methods may not adequately maintain safety in multimodal models when learning new tasks post-deployment.

Method: Experiments on Gemma3-4B vision-language model fine-tuned on narrow-domain harmful datasets using LoRA with varying ranks. Employed both text-only and multimodal evaluation to measure alignment degradation. Performed geometric analysis via PCA to identify low-dimensional subspaces of harmful behaviors. Tested two mitigation strategies: benign narrow fine-tuning and activation-based steering.

Result: Misalignment scales monotonically with LoRA rank. Multimodal evaluation shows substantially higher misalignment (70.71±1.22 at r=128) than text-only (41.19±2.51). Even 10% harmful data causes substantial degradation. Harmful behaviors occupy remarkably low-dimensional subspace with majority of misalignment captured in 10 principal components. Both mitigation strategies reduce but don't eliminate learned harmful behaviors.

Conclusion: Current post-training paradigms insufficiently preserve alignment in post-deployment settings for multimodal models. Findings highlight critical need for robust continual learning frameworks to maintain safety during continuous adaptation. Unimodal safety benchmarks may underestimate alignment degradation in vision-language models.

Abstract: Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe emergent misalignment that generalizes broadly across unrelated tasks and modalities. Through experiments on Gemma3-4B, we show that misalignment scales monotonically with LoRA rank, and that multimodal evaluation reveals substantially higher misalignment ($70.71 \pm 1.22$ at $r=128$) than text-only evaluation ($41.19 \pm 2.51$), suggesting that unimodal safety benchmarks may underestimate alignment degradation in vision-language models. Critically, even 10\% harmful data in the training mixture induces substantial alignment degradation. Geometric analysis reveals that harmful behaviors occupy a remarkably low-dimensional subspace, with the majority of misalignment information captured in 10 principal components. To mitigate misalignment, we evaluate two strategies: benign narrow fine-tuning and activation-based steering. While both approaches substantially reduce misalignment, neither completely removes the learned harmful behaviors. Our findings highlight the need for robust continual learning frameworks, as current post-training paradigms may not sufficiently preserve alignment in post-deployment settings.

</details>


### [152] [DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs](https://arxiv.org/abs/2602.16935)
*Justin Albrethsen,Yash Datta,Kunal Kumar,Sharath Rajasekar*

Main category: cs.AI

TL;DR: 提出DeepContext框架，通过RNN架构实现有状态对话监控，解决无状态安全防护在多轮对话中的"安全间隙"问题， jailbreak检测F1达0.84且推理开销低于20ms


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全护栏采用无状态设计，将多轮对话视为孤立事件，导致对抗性攻击（如Crescendo和ActorAttack）可通过跨回合缓慢注入恶意意图绕过检测，形成"安全间隙"。

Method: 摒弃孤立评估模型，采用RNN架构处理经过微调的回合级嵌入序列，通过跨对话传播隐藏状态捕获风险的增量累积。

Result: 在multi-turn jailbreak检测中F1分数达0.84，显著优于Llama-Prompt-Guard-2和Granite-Guardian（均为0.67），T4 GPU上推理延迟低于20ms。

Conclusion: 建模意图的序列演化比部署大规模无状态模型更有效且计算效率更高，为实时应用提供了可行方案。

Abstract: While Large Language Model (LLM) capabilities have scaled, safety guardrails remain largely stateless, treating multi-turn dialogues as a series of disconnected events. This lack of temporal awareness facilitates a "Safety Gap" where adversarial tactics, like Crescendo and ActorAttack, slowly bleed malicious intent across turn boundaries to bypass stateless filters. We introduce DeepContext, a stateful monitoring framework designed to map the temporal trajectory of user intent. DeepContext discards the isolated evaluation model in favor of a Recurrent Neural Network (RNN) architecture that ingests a sequence of fine-tuned turn-level embeddings. By propagating a hidden state across the conversation, DeepContext captures the incremental accumulation of risk that stateless models overlook. Our evaluation demonstrates that DeepContext significantly outperforms existing baselines in multi-turn jailbreak detection, achieving a state-of-the-art F1 score of 0.84, which represents a substantial improvement over both hyperscaler cloud-provider guardrails and leading open-weight models such as Llama-Prompt-Guard-2 (0.67) and Granite-Guardian (0.67). Furthermore, DeepContext maintains a sub-20ms inference overhead on a T4 GPU, ensuring viability for real-time applications. These results suggest that modeling the sequential evolution of intent is a more effective and computationally efficient alternative to deploying massive, stateless models.

</details>


### [153] [Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents](https://arxiv.org/abs/2602.16943)
*Arnold Cartagena,Ariane Teixeira*

Main category: cs.AI

TL;DR: 文本安全对齐无法延伸至工具调用层面，六大前沿模型均存在"说拒绝却执行"的GAP现象，安全提示词影响显著但无法根除风险，现有文本评估体系不足以评估智能体行为


<details>
  <summary>Details</summary>
Motivation: 现有安全评估仅关注文本拒绝行为，但LLM智能体通过工具调用产生真实世界影响，亟需验证文本安全是否延伸至工具调用安全

Method: 创建GAP基准测试框架，六模型×六监管领域×七越狱场景×三系统提示×两变体，生成17,420数据点，量化文本与工具调用安全差异

Result: 219例文本拒绝但工具执行危险操作；安全提示下TC安全率波动21-57个百分点；运行时治理减少信息泄露但无法阻止危险工具调用

Conclusion: 文本安全评估不足以保证智能体安全，需建立工具调用专属安全与缓解机制

Abstract: Large language models deployed as agents increasingly interact with external systems through tool calls--actions with real-world consequences that text outputs alone do not carry. Safety evaluations, however, overwhelmingly measure text-level refusal behavior, leaving a critical question unanswered: does alignment that suppresses harmful text also suppress harmful actions? We introduce the GAP benchmark, a systematic evaluation framework that measures divergence between text-level safety and tool-call-level safety in LLM agents. We test six frontier models across six regulated domains (pharmaceutical, financial, educational, employment, legal, and infrastructure), seven jailbreak scenarios per domain, three system prompt conditions (neutral, safety-reinforced, and tool-encouraging), and two prompt variants, producing 17,420 analysis-ready datapoints. Our central finding is that text safety does not transfer to tool-call safety. Across all six models, we observe instances where the model's text output refuses a harmful request while its tool calls simultaneously execute the forbidden action--a divergence we formalize as the GAP metric. Even under safety-reinforced system prompts, 219 such cases persist across all six models. System prompt wording exerts substantial influence on tool-call behavior: TC-safe rates span 21 percentage points for the most robust model and 57 for the most prompt-sensitive, with 16 of 18 pairwise ablation comparisons remaining significant after Bonferroni correction. Runtime governance contracts reduce information leakage in all six models but produce no detectable deterrent effect on forbidden tool-call attempts themselves. These results demonstrate that text-only safety evaluations are insufficient for assessing agent behavior and that tool-call safety requires dedicated measurement and mitigation.

</details>


### [154] [LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation](https://arxiv.org/abs/2602.16953)
*Hejia Zhang,Zhongming Yu,Chia-Tung Ho,Haoxing Ren,Brucek Khailany,Jishen Zhao*

Main category: cs.AI

TL;DR: This paper proposes LLM4Cov, an offline agent-learning framework for hardware verification that uses execution-validated data curation, policy-aware synthesis, and worst-state-prioritized sampling to enable scalable learning with expensive, slow execution feedback, achieving 69.2% coverage with a 4B model that outperforms larger models.


<details>
  <summary>Details</summary>
Motivation: Online reinforcement learning for execution-aware LLM agents is impractical because tool feedback is expensive and slow to obtain. High-coverage hardware verification exemplifies this challenge due to reliance on industrial simulators and non-differentiable execution signals, creating a need for offline learning methods.

Method: The authors propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Key techniques include execution-validated data curation, policy-aware agentic data synthesis, worst-state-prioritized sampling, and a reality-aligned benchmark with revised evaluation protocol.

Result: A compact 4B-parameter model achieves 69.2% coverage pass rate under agentic evaluation, outperforming its teacher by 5.3% and demonstrating competitive performance against models an order of magnitude larger.

Conclusion: The proposed offline framework successfully enables scalable learning under execution constraints for hardware verification, allowing smaller models to match or exceed the performance of much larger models while overcoming the limitations of online RL with expensive execution feedback.

Abstract: Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simulators and non-differentiable execution signals. We propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Building on this formulation, we introduce execution-validated data curation, policy-aware agentic data synthesis, and worst-state-prioritized sampling to enable scalable learning under execution constraints. We further curate a reality-aligned benchmark adapted from an existing verification suite through a revised evaluation protocol. Using the proposed pipeline, a compact 4B-parameter model achieves 69.2% coverage pass rate under agentic evaluation, outperforming its teacher by 5.3% and demonstrating competitive performance against models an order of magnitude larger.

</details>


### [155] [Fundamental Limits of Black-Box Safety Evaluation: Information-Theoretic and Computational Barriers from Latent Context Conditioning](https://arxiv.org/abs/2602.16984)
*Vishal Srivastava*

Main category: cs.AI

TL;DR: 该论文证明黑箱评估AI安全存在根本性局限，提出潜在上下文条件策略形式化挑战，表明当模型依赖部署时才出现的稀有内部变量时，黑箱测试无法可靠估计风险，为白箱方法和其他安全措施提供数学必要性证明。


<details>
  <summary>Details</summary>
Motivation: 挑战AI安全评估的核心假设——模型在测试分布上的行为能可靠预测部署性能。论文关注潜在上下文条件策略这类特殊模型，其输出依赖于评估时罕见但部署时普遍存在的未观测内部变量，揭示了黑箱评估的潜在失效风险。

Method: 采用理论分析框架：1) 应用Le Cam方法建立被动评估的极小化极大下界；2) 使用哈希触发构造和Yao极小化极大原理分析自适应评估；3) 基于陷门单向函数假设构建计算分离结果；4) 推导白箱探测的样本复杂度并给出偏差修正方法。

Result: 1) 被动评估：任何估计器绝对误差下限为(5/24)δL≈0.208δL；2) 自适应评估：即使完全自适应查询，最坏情况误差仍≥δL/16，检测需Θ(1/ε)次查询；3) 计算分离：在密码学假设下，部署环境可利用特权信息激活安全算法无法区分的危险行为；4) 白箱探测：达到精度ε_R需O(1/(γ²ε_R²))样本，γ=α₀+α₁-1衡量探测质量。

Conclusion: 量化证明了黑箱测试在统计上的根本不确定性，明确指出架构约束、训练时保证、可解释性和部署监控等额外安全措施在数学上对于确保最坏情况下的AI安全是必要的，为安全评估提供了理论边界。

Abstract: Black-box safety evaluation of AI systems assumes model behavior on test distributions reliably predicts deployment performance. We formalize and challenge this assumption through latent context-conditioned policies -- models whose outputs depend on unobserved internal variables that are rare under evaluation but prevalent under deployment. We establish fundamental limits showing that no black-box evaluator can reliably estimate deployment risk for such models. (1) Passive evaluation: For evaluators sampling i.i.d. from D_eval, we prove minimax lower bounds via Le Cam's method: any estimator incurs expected absolute error >= (5/24)*delta*L approximately 0.208*delta*L, where delta is trigger probability under deployment and L is the loss gap. (2) Adaptive evaluation: Using a hash-based trigger construction and Yao's minimax principle, worst-case error remains >= delta*L/16 even for fully adaptive querying when D_dep is supported over a sufficiently large domain; detection requires Theta(1/epsilon) queries. (3) Computational separation: Under trapdoor one-way function assumptions, deployment environments possessing privileged information can activate unsafe behaviors that any polynomial-time evaluator without the trapdoor cannot distinguish. For white-box probing, estimating deployment risk to accuracy epsilon_R requires O(1/(gamma^2 * epsilon_R^2)) samples, where gamma = alpha_0 + alpha_1 - 1 measures probe quality, and we provide explicit bias correction under probe error. Our results quantify when black-box testing is statistically underdetermined and provide explicit criteria for when additional safeguards -- architectural constraints, training-time guarantees, interpretability, and deployment monitoring -- are mathematically necessary for worst-case safety assurance.

</details>


### [156] [Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation](https://arxiv.org/abs/2602.16990)
*Yan Wang,Yi Han,Lingfei Qian,Yueru He,Xueqing Peng,Dongji Feng,Zhuohan Xie,Vincent Jim Zhang,Rosie Guo,Fengran Mo,Jimin Huang,Yankai Chen,Xue Liu,Jian-Yun Nie*

Main category: cs.AI

TL;DR: 传统推荐基准仅评估模型模仿用户行为的能力，但在金融领域，用户行为可能因市场波动而短视或嘈杂。本文提出Conv-FinRe基准，通过结合对话上下文、长期市场数据和投资者风险偏好，区分行为模仿与真实决策质量，揭示LLM在理性决策与行为对齐间的根本矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有推荐基准将用户历史行为视为绝对真理，但金融决策中用户行为常受市场噪音影响，与长期目标冲突，导致"行为模仿"与"决策质量"混淆，无法评估模型的真实金融建议能力。

Method: 构建对话式纵向股票推荐基准Conv-FinRe：基于真实市场数据和人工决策轨迹，生成包含用户画像访谈、分步市场情境和咨询对话的测试集；提供区分描述性行为（用户实际选择）与规范性效用（基于用户风险偏好的理想决策）的多视角参考标准。

Result: 评估显示：在效用导向排名中表现良好的模型往往无法匹配用户实际选择；而行为对齐的模型易过拟合短期市场噪音，暴露了理性决策质量与行为模仿之间的持续性矛盾。

Conclusion: 金融推荐评估必须超越行为匹配，纳入投资者个性化效用标准；Conv-FinRe为诊断模型是否遵循理性分析、模仿噪音或追逐市场动量提供了新基准，相关数据集与代码已开源。

Abstract: Most recommendation benchmarks evaluate how well a model imitates user behavior. In financial advisory, however, observed actions can be noisy or short-sighted under market volatility and may conflict with a user's long-term goals. Treating what users chose as the sole ground truth, therefore, conflates behavioral imitation with decision quality. We introduce Conv-FinRe, a conversational and longitudinal benchmark for stock recommendation that evaluates LLMs beyond behavior matching. Given an onboarding interview, step-wise market context, and advisory dialogues, models must generate rankings over a fixed investment horizon. Crucially, Conv-FinRe provides multi-view references that distinguish descriptive behavior from normative utility grounded in investor-specific risk preferences, enabling diagnosis of whether an LLM follows rational analysis, mimics user noise, or is driven by market momentum. We build the benchmark from real market data and human decision trajectories, instantiate controlled advisory conversations, and evaluate a suite of state-of-the-art LLMs. Results reveal a persistent tension between rational decision quality and behavioral alignment: models that perform well on utility-based ranking often fail to match user choices, whereas behaviorally aligned models can overfit short-term noise. The dataset is publicly released on Hugging Face, and the codebase is available on GitHub.

</details>


### [157] [Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases](https://arxiv.org/abs/2602.17001)
*Zhao Tan,Yiji Zhao,Shiyu Wang,Chang Xu,Yuxuan Liang,Xiping Liu,Shirui Pan,Ming Jin*

Main category: cs.AI

TL;DR: Proposes Sonar-TS, a neuro-symbolic Search-Then-Verify framework for natural language querying of time series databases that uses SQL-based candidate retrieval followed by Python verification to handle shape/anomaly queries over ultra-long histories.


<details>
  <summary>Details</summary>
Motivation: Non-expert users need to query massive time series data using natural language, but existing Text-to-SQL methods cannot handle continuous morphological intents (shapes/anomalies) and time series models struggle with ultra-long histories.

Method: Sonar-TS neuro-symbolic framework with a Search-Then-Verify pipeline: (1) uses a feature index to ping candidate windows via SQL queries, (2) generates Python programs to lock on and verify candidates against raw signals.

Result: Introduced NLQTSBench, the first large-scale benchmark for NLQ over TSDB-scale histories. Experiments demonstrate Sonar-TS effectively navigates complex temporal queries where traditional methods fail, highlighting unique domain challenges.

Conclusion: This is the first systematic study of NLQ4TSDB, providing a general neuro-symbolic framework and evaluation standard to facilitate future research in natural language querying for time series databases.

Abstract: Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records. However, existing Text-to-SQL methods are not designed for continuous morphological intents such as shapes or anomalies, while time series models struggle to handle ultra-long histories. To address these challenges, we propose Sonar-TS, a neuro-symbolic framework that tackles NLQ4TSDB via a Search-Then-Verify pipeline. Analogous to active sonar, it utilizes a feature index to ping candidate windows via SQL, followed by generated Python programs to lock on and verify candidates against raw signals. To enable effective evaluation, we introduce NLQTSBench, the first large-scale benchmark designed for NLQ over TSDB-scale histories. Our experiments highlight the unique challenges within this domain and demonstrate that Sonar-TS effectively navigates complex temporal queries where traditional methods fail. This work presents the first systematic study of NLQ4TSDB, offering a general framework and evaluation standard to facilitate future research.

</details>


### [158] [Cinder: A fast and fair matchmaking system](https://arxiv.org/abs/2602.17015)
*Saurav Pal*

Main category: cs.AI

TL;DR: Cinder系统通过两阶段匹配机制（Ruzicka相似度初筛+Kantorovich距离精评）解决异质技能预组队的公平匹配问题，基于1.4亿次模拟验证了制裁分的有效性


<details>
  <summary>Details</summary>
Motivation: 现有基于平均技能值的匹配方法在异质技能预组队场景下易产生不平衡对局，尤其当技能分布宽泛或偏斜时，影响玩家留存与满意度

Method: 1. 初筛阶段：使用Ruzicka相似度指数比较预组队的"非离群"技能范围；2. 精评阶段：将玩家段位映射至逆正态分布的非线性技能桶，通过Kantorovich距离计算"制裁分"量化对局公平性

Result: 通过1.4亿次模拟预组队配对分析制裁分分布，为公平匹配阈值设定提供稳健依据

Conclusion: Cinder系统通过双阶段设计实现了快速且公平的匹配，其制裁分机制能有效评估异质技能预组队对局的公平性

Abstract: A fair and fast matchmaking system is an important component of modern multiplayer online games, directly impacting player retention and satisfaction. However, creating fair matches between lobbies (pre-made teams) of heterogeneous skill levels presents a significant challenge. Matching based simply on average team skill metrics, such as mean or median rating or rank, often results in unbalanced and one-sided games, particularly when skill distributions are wide or skewed. This paper introduces Cinder, a two-stage matchmaking system designed to provide fast and fair matches. Cinder first employs a rapid preliminary filter by comparing the "non-outlier" skill range of lobbies using the Ruzicka similarity index. Lobbies that pass this initial check are then evaluated using a more precise fairness metric. This second stage involves mapping player ranks to a non-linear set of skill buckets, generated from an inverted normal distribution, to provide higher granularity at average skill levels. The fairness of a potential match is then quantified using the Kantorovich distance on the lobbies' sorted bucket indices, producing a "Sanction Score." We demonstrate the system's viability by analyzing the distribution of Sanction Scores from 140 million simulated lobby pairings, providing a robust foundation for fair matchmaking thresholds.

</details>


### [159] [Sales Research Agent and Sales Research Bench](https://arxiv.org/abs/2602.17017)
*Deepanjan Bhol*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Enterprises increasingly need AI systems that can answer sales-leader questions over live, customized CRM data, but most available models do not expose transparent, repeatable evidence of quality. This paper describes the Sales Research Agent in Microsoft Dynamics 365 Sales, an AI-first application that connects to live CRM and related data, reasons over complex schemas, and produces decision-ready insights through text and chart outputs. To make quality observable, we introduce the Sales Research Bench, a purpose-built benchmark that scores systems on eight customer-weighted dimensions, including text and chart groundedness, relevance, explainability, schema accuracy, and chart quality. In a 200-question run on a customized enterprise schema on October 19, 2025, the Sales Research Agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on the 100-point composite score, giving customers a repeatable way to compare AI solutions.

</details>


### [160] [Dynamic System Instructions and Tool Exposure for Efficient Agentic LLMs](https://arxiv.org/abs/2602.17046)
*Uria Franko*

Main category: cs.AI

TL;DR: 提出指令-工具检索(ITR)方法，通过每步动态检索最小化系统提示和工具集，将上下文token减少95%、端到端成本降低70%，同时工具路由准确率相对提升32%，特别适合长周期自主智能体


<details>
  <summary>Details</summary>
Motivation: LLM智能体每轮重复加载长系统指令和大规模工具集，导致成本高、延迟大、易偏离任务、工具选择错误增多

Method: ITR：一种RAG变体，每步检索最小必要提示片段和工具子集，组合成动态运行时提示，并提供置信度门控的降级方案

Result: 相比单体基线：每步token减少95%，正确工具路由率相对提升32%，端到端成本降低70%，可在相同上下文中运行2-20倍更多轮次

Conclusion: ITR为长周期自主智能体提供显著效益，论文详述方法、评估协议、消融实验和部署指南

Abstract: Large Language Model (LLM) agents often run for many steps while re-ingesting long system instructions and large tool catalogs each turn. This increases cost, agent derailment probability, latency, and tool-selection errors. We propose Instruction-Tool Retrieval (ITR), a RAG variant that retrieves, per step, only the minimal system-prompt fragments and the smallest necessary subset of tools. ITR composes a dynamic runtime system prompt and exposes a narrowed toolset with confidence-gated fallbacks. Using a controlled benchmark with internally consistent numbers, ITR reduces per-step context tokens by 95%, improves correct tool routing by 32% relative, and cuts end-to-end episode cost by 70% versus a monolithic baseline. These savings enable agents to run 2-20x more loops within context limits. Savings compound with the number of agent steps, making ITR particularly valuable for long-running autonomous agents. We detail the method, evaluation protocol, ablations, and operational guidance for practical deployment.

</details>


### [161] [IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents](https://arxiv.org/abs/2602.17049)
*Seoyoung Lee,Seobin Yoon,Seongbeen Lee,Yoojung Chun,Dayoung Park,Doyeon Kim,Joo Yong Sim*

Main category: cs.AI

TL;DR: IntentCUA是一种多智能体计算机使用框架，通过意图对齐的计划记忆稳定长时程任务执行，减少错误累积与冗余规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法在噪声感知、多窗口环境和动态状态下易偏离用户意图，重复解决子问题，导致错误累积和效率低下。

Method: 由规划器、计划优化器和评论家组成的三智能体系统，通过共享记忆将原始交互抽象为多视角意图表示和可复用技能，运行时检索并注入技能以减少重规划。

Result: 在端到端评估中达到74.83%任务成功率和0.91步骤效率比，优于RL和轨迹基线；消融验证多视角意图抽象和共享记忆提升稳定性，多智能体协作在长时程任务上贡献最大。

Conclusion: 系统级意图抽象和记忆基础的协调机制是实现大规模动态环境下可靠高效桌面自动化的关键。

Abstract: Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate over shared memory that abstracts raw interaction traces into multi-view intent representations and reusable skills. At runtime, intent prototypes retrieve subgroup-aligned skills and inject them into partial plans, reducing redundant re-planning and mitigating error propagation across desktop applications. In end-to-end evaluations, IntentCUA achieved a 74.83% task success rate with a Step Efficiency Ratio of 0.91, outperforming RL-based and trajectory-centric baselines. Ablations show that multi-view intent abstraction and shared plan memory jointly improve execution stability, with the cooperative multi-agent loop providing the largest gains on long-horizon tasks. These results highlight that system-level intent abstraction and memory-grounded coordination are key to reliable and efficient desktop automation in large, dynamic environments.

</details>


### [162] [Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17062)
*Yonghyeon Jo,Sunwoo Lee,Seungyul Han*

Main category: cs.AI

TL;DR: 该论文提出S2Q（Successive Sub-value Q-learning），通过在学习过程中维护多个子价值函数而非依赖单一最优动作，解决了合作式多智能体强化学习中的适应性问题，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有合作式多智能体强化学习的价值分解方法依赖单一最优动作，当训练过程中价值函数发生变化时难以适应，容易收敛到次优策略。

Method: 提出Successive Sub-value Q-learning (S2Q)，学习多个子价值函数以保留高价值替代动作，并将这些子价值函数整合到基于Softmax的行为策略中，实现持续探索和Q^tot对变化最优值的快速适应。

Result: 在具有挑战性的多智能体强化学习基准测试上，S2Q始终优于各类MARL算法，展现出更强的适应性和整体性能。

Conclusion: S2Q通过维护多个子价值函数有效解决了现有价值分解方法的局限性，为合作式多智能体强化学习提供了更优的解决方案，代码已开源。

Abstract: Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this limitation, we propose Successive Sub-value Q-learning (S2Q), which learns multiple sub-value functions to retain alternative high-value actions. Incorporating these sub-value functions into a Softmax-based behavior policy, S2Q encourages persistent exploration and enables $Q^{\text{tot}}$ to adjust quickly to the changing optima. Experiments on challenging MARL benchmarks confirm that S2Q consistently outperforms various MARL algorithms, demonstrating improved adaptability and overall performance. Our code is available at https://github.com/hyeon1996/S2Q.

</details>


### [163] [Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction](https://arxiv.org/abs/2602.17106)
*Xiaoran Cai,Wang Yang,Xiyu Ren,Chekun Law,Rohit Sharma,Peng Qi*

Main category: cs.AI

TL;DR: Proposes a human-AI collaboration framework (STRIDE + SR-Delta) to generate trustworthy benchmark datasets for harmonizing inconsistent sustainability/ESG ratings across agencies.


<details>
  <summary>Details</summary>
Motivation: Sustainability ratings for single companies vary widely across agencies, limiting comparability, credibility, and decision-making relevance.

Method: Two-part framework: STRIDE uses principled criteria and LLMs to construct firm-level benchmark datasets; SR-Delta provides discrepancy analysis for methodology adjustments.

Result: Enables scalable and comparable assessment of sustainability rating methodologies.

Conclusion: Call to AI community to adopt AI-powered approaches to strengthen sustainability rating methodologies supporting urgent sustainability agendas.

Abstract: Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability, credibility, and relevance to decision-making. To harmonize the rating results, we propose adopting a universal human-AI collaboration framework to generate trustworthy benchmark datasets for evaluating sustainability rating methodologies. The framework comprises two complementary parts: STRIDE (Sustainability Trust Rating & Integrity Data Equation) provides principled criteria and a scoring system that guide the construction of firm-level benchmark datasets using large language models (LLMs), and SR-Delta, a discrepancy-analysis procedural framework that surfaces insights for potential adjustments. The framework enables scalable and comparable assessment of sustainability rating methodologies. We call on the broader AI community to adopt AI-powered approaches to strengthen and advance sustainability rating methodologies that support and enforce urgent sustainability agendas.

</details>


### [164] [Owen-based Semantics and Hierarchy-Aware Explanation (O-Shap)](https://arxiv.org/abs/2602.17107)
*Xiangyu Zhou,Chenhan Xiao,Yang Weng*

Main category: cs.AI

TL;DR: 提出O-Shap方法，通过满足T性质的分层分割解决视觉任务中特征依赖问题，在精度和效率上优于传统SHAP变体。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值方法假设特征独立，但视觉任务中像素存在强空间语义依赖；Owen值虽支持分组归因，但常用分割方式违反一致性性质。

Method: 提出满足T性质的新分割方法，确保层次间语义对齐，实现计算剪枝并提升归因准确性和可解释性。

Result: 在图像和表格数据集上，O-Shap在归因精度、语义一致性和运行效率上均优于基线SHAP变体，尤其在结构重要的场景。

Conclusion: 该方法有效解决了特征依赖问题，为视觉任务提供了更准确、可解释且计算高效的解释方案。

Abstract: Shapley value-based methods have become foundational in explainable artificial intelligence (XAI), offering theoretically grounded feature attributions through cooperative game theory. However, in practice, particularly in vision tasks, the assumption of feature independence breaks down, as features (i.e., pixels) often exhibit strong spatial and semantic dependencies. To address this, modern SHAP implementations now include the Owen value, a hierarchical generalization of the Shapley value that supports group attributions. While the Owen value preserves the foundations of Shapley values, its effectiveness critically depends on how feature groups are defined. We show that commonly used segmentations (e.g., axis-aligned or SLIC) violate key consistency properties, and propose a new segmentation approach that satisfies the $T$-property to ensure semantic alignment across hierarchy levels. This hierarchy enables computational pruning while improving attribution accuracy and interpretability. Experiments on image and tabular datasets demonstrate that O-Shap outperforms baseline SHAP variants in attribution precision, semantic coherence, and runtime efficiency, especially when structure matters.

</details>


### [165] [Instructor-Aligned Knowledge Graphs for Personalized Learning](https://arxiv.org/abs/2602.17111)
*Abdulrahman AlRabah,Priyanka Kargupta,Jiawei Han,Abdussalam Alawini*

Main category: cs.AI

TL;DR: InstructKG是一个自动从课程讲义材料构建教学导向知识图谱的框架，通过结合大语言模型与教育材料的时序和语义信号，捕捉概念间的先修和子概念依赖关系


<details>
  <summary>Details</summary>
Motivation: 大规模课程中教师难以诊断学生个体知识缺口，现有知识图谱要么过于表层，要么忽视教学材料中的丰富教学信号，无法准确反映课程的预期学习路径

Method: 从课程讲义材料中提取重要概念作为节点，推断"依赖-被依赖"或"部分-整体"关系作为有向边；融合教育材料特有的时序信号（如教学顺序）和语义信号（如定义引用）与大语言模型的泛化能力

Result: 在多个真实课程讲义数据上的实验及人工评估表明，InstructKG能够准确捕捉教学导向的丰富学习路径和概念依赖关系

Conclusion: InstructKG为规模化构建教学导向的知识图谱提供了可行方案，有助于识别学生知识缺口并实现个性化学习干预

Abstract: Mastering educational concepts requires understanding both their prerequisites (e.g., recursion before merge sort) and sub-concepts (e.g., merge sort as part of sorting algorithms). Capturing these dependencies is critical for identifying students' knowledge gaps and enabling targeted intervention for personalized learning. This is especially challenging in large-scale courses, where instructors cannot feasibly diagnose individual misunderstanding or determine which concepts need reinforcement. While knowledge graphs offer a natural representation for capturing these conceptual relationships at scale, existing approaches are either surface-level (focusing on course-level concepts like "Algorithms" or logistical relationships such as course enrollment), or disregard the rich pedagogical signals embedded in instructional materials. We propose InstructKG, a framework for automatically constructing instructor-aligned knowledge graphs that capture a course's intended learning progression. Given a course's lecture materials (slides, notes, etc.), InstructKG extracts significant concepts as nodes and infers learning dependencies as directed edges (e.g., "part-of" or "depends-on" relationships). The framework synergizes the rich temporal and semantic signals unique to educational materials (e.g., "recursion" is taught before "mergesort"; "recursion" is mentioned in the definition of "merge sort") with the generalizability of large language models. Through experiments on real-world, diverse lecture materials across multiple courses and human-based evaluation, we demonstrate that InstructKG captures rich, instructor-aligned learning progressions.

</details>


### [166] [Efficient Parallel Algorithm for Decomposing Hard CircuitSAT Instances](https://arxiv.org/abs/2602.17130)
*Victor Kondratiev,Irina Gribanova,Alexander Semenov*

Main category: cs.AI

TL;DR: 提出一种参数化并行算法，通过专用约束分解困难CircuitSAT实例，利用并行硬度估计指导参数优化，在逻辑等价检查和哈希原像攻击实例上验证有效。


<details>
  <summary>Details</summary>
Motivation: 困难CircuitSAT实例求解困难，分解并行化是提升效率的关键，但高质量分解的识别仍具挑战。

Method: 采用专用约束将原实例划分为弱化公式族，设计参数化并行算法，通过并行计算的硬度估计指导参数调整以识别优质分解。

Result: 在逻辑等价性检查和密码哈希原像攻击等挑战性CircuitSAT实例上证明了算法的实用性和高效性。

Conclusion: 该算法能有效分解困难CircuitSAT问题，通过并行化与参数优化实现了高质量分解，具有实际应用价值。

Abstract: We propose a novel parallel algorithm for decomposing hard CircuitSAT instances. The technique employs specialized constraints to partition an original SAT instance into a family of weakened formulas. Our approach is implemented as a parameterized parallel algorithm, where adjusting the parameters allows efficient identification of high-quality decompositions, guided by hardness estimations computed in parallel. We demonstrate the algorithm's practical efficacy on challenging CircuitSAT instances, including those encoding Logical Equivalence Checking of Boolean circuits and preimage attacks on cryptographic hash functions.

</details>


### [167] [JEPA-DNA: Grounding Genomic Foundation Models through Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.17162)
*Ariel Larey,Elay Dahan,Amit Bleiweiss,Raizy Kellerman,Guy Leib,Omri Nayshool,Dan Ofer,Tal Zinger,Dan Dominissini,Gideon Rechavi,Nicole Bussola,Simon Lee,Shane O'Connell,Dung Hoang,Marissa Wirth,Alexander W. Charney,Nati Daniel,Yoli Shavit*

Main category: cs.AI

TL;DR: 提出JEPA-DNA框架，通过联合嵌入预测架构与传统生成目标，解决现有基因组基础模型无法捕获全局功能上下文的问题，在多项基准测试中性能优于基线模型


<details>
  <summary>Details</summary>
Motivation: 现有基因组基础模型主要依赖掩码语言建模和下一个词元预测，虽能捕获局部语法和细粒度基序模式，但缺乏对更广泛功能上下文的理解，导致表征缺少全局生物学视角

Method: 设计JEPA-DNA预训练框架，将联合嵌入预测架构与生成目标结合：通过CLS词元监督，在潜在空间中执行预测性目标，使模型预测被掩码基因组片段的高级功能嵌入而非单个核苷酸，可作为独立训练目标或增强现有模型

Result: 在多样化的基因组基准评估中，JEPA-DNA在监督和零样本任务上持续表现优于纯生成基线模型

Conclusion: JEPA-DNA提供更稳健且生物学基础的表征，为理解基因组序列底层功能逻辑的基础模型提供了可扩展路径，不仅掌握基因字母表，更能理解其功能逻辑

Abstract: Genomic Foundation Models (GFMs) have largely relied on Masked Language Modeling (MLM) or Next Token Prediction (NTP) to learn the language of life. While these paradigms excel at capturing local genomic syntax and fine-grained motif patterns, they often fail to capture the broader functional context, resulting in representations that lack a global biological perspective. We introduce JEPA-DNA, a novel pre-training framework that integrates the Joint-Embedding Predictive Architecture (JEPA) with traditional generative objectives. JEPA-DNA introduces latent grounding by coupling token-level recovery with a predictive objective in the latent space by supervising a CLS token. This forces the model to predict the high-level functional embeddings of masked genomic segments rather than focusing solely on individual nucleotides. JEPA-DNA extends both NTP and MLM paradigms and can be deployed either as a standalone from-scratch objective or as a continual pre-training enhancement for existing GFMs. Our evaluations across a diverse suite of genomic benchmarks demonstrate that JEPA-DNA consistently yields superior performance in supervised and zero-shot tasks compared to generative-only baselines. By providing a more robust and biologically grounded representation, JEPA-DNA offers a scalable path toward foundation models that understand not only the genomic alphabet, but also the underlying functional logic of the sequence.

</details>


### [168] [Texo: Formula Recognition within 20M Parameters](https://arxiv.org/abs/2602.17189)
*Sicheng Mao*

Main category: cs.AI

TL;DR: Texo是一个仅含2000万参数的高性能公式识别模型，通过精心设计和知识蒸馏，在性能媲美SOTA模型的同时，模型大小比UniMERNet-T和PPFormulaNet-S分别减少80%和65%，支持消费级硬件实时推理和浏览器端部署。


<details>
  <summary>Details</summary>
Motivation: 现有公式识别模型参数量大，难以在消费级硬件或浏览器中实现实时推理，需要开发一个既高性能又轻量化的模型来扩展部署场景。

Method: 采用精心架构设计、知识蒸馏以及词汇表和分词器的迁移策略，构建了一个仅2000万参数的极简模型。

Result: Texo在性能上与UniMERNet-T和PPFormulaNet-S等SOTA模型相当，但模型体积分别减小80%和65%，成功实现了消费级硬件实时推理和浏览器部署。

Conclusion: 通过模型压缩和架构优化，Texo在保持高性能的同时大幅减小模型尺寸，为公式识别技术在资源受限环境中的应用提供了可行方案，并已开发网页应用方便用户使用。

Abstract: In this paper we present Texo, a minimalist yet highperformance formula recognition model that contains only 20 million parameters. By attentive design, distillation and transfer of the vocabulary and the tokenizer, Texo achieves comparable performance to state-of-the-art models such as UniMERNet-T and PPFormulaNet-S, while reducing the model size by 80% and 65%, respectively. This enables real-time inference on consumer-grade hardware and even in-browser deployment. We also developed a web application to demonstrate the model capabilities and facilitate its usage for end users.

</details>


### [169] [From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences](https://arxiv.org/abs/2602.17221)
*Yi-Chih Huang*

Main category: cs.AI

TL;DR: 该研究针对生成式AI在人文社科研究中的应用缺失，提出并验证了一个七阶段模块化AI Agent协作工作流，通过台湾Claude.ai使用数据分析，揭示了人类判断在理论解读和伦理决策中的不可替代性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI对知识工作的研究集中于软件工程和自然科学领域，缺乏针对人文社科研究的方法论探索，亟需建立适配该领域的AI协作框架。

Method: 以"方法论实验"为核心，设计基于任务模块化、人机分工和验证性三原则的七阶段工作流；使用Anthropic经济指数中台湾Claude.ai的7,729段对话数据（2025年11月）进行实证验证，通过反思性文档记录操作流程。

Result: 提出可复现的AI协作框架，识别出人-AI协作的三种操作模式：直接执行、迭代优化和人类主导；证明人类在问题构建、理论解读、情境推理和伦理反思中具有不可替代性。

Conclusion: 该工作流为人文社科研究提供了新方法论路径，但需警惕单平台数据、横截面设计和AI可靠性等局限；未来需深化人机协作机制并拓展跨学科验证。

Abstract: Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a "methodological experiment," this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index (AEI) serves as the empirical vehicle for validating the feasibility of this methodology.
  This study operates on two levels: the primary level is the design and validation of a methodological framework - a seven-stage modular workflow grounded in three principles: task modularization, human-AI division of labor, and verifiability, with each stage delineating clear roles for human researchers (research judgment and ethical decisions) and AI Agents (information retrieval and text generation); the secondary level is the empirical analysis of AEI Taiwan data - serving as an operational demonstration of the workflow's application to secondary data research, showcasing both the process and output quality (see Appendix A).
  This study contributes by proposing a replicable AI collaboration framework for humanities and social science researchers, and identifying three operational modes of human-AI collaboration - direct execution, iterative refinement, and human-led - through reflexive documentation of the operational process. This taxonomy reveals the irreplaceability of human judgment in research question formulation, theoretical interpretation, contextualized reasoning, and ethical reflection. Limitations including single-platform data, cross-sectional design, and AI reliability risks are acknowledged.

</details>


### [170] [Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy](https://arxiv.org/abs/2602.17229)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.AI

TL;DR: 该研究表明，大语言模型在其内部表征中以线性可分的方式编码了认知复杂度（基于布鲁姆分类法），线性分类器达到约95%的准确率，提示模型在前向传播早期就解析了提示的难度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的黑盒特性需要超越表面性能指标的新型评估框架，以理解其如何处理认知复杂度。

Method: 研究利用布鲁姆分类法作为分层框架，分析不同大语言模型的高维激活向量，通过线性分类器探测从记忆到创造的认知水平是否在模型的残差流中线性可分。

Result: 线性分类器在所有布鲁姆水平上达到约95%的平均准确率，表明认知水平被编码在线性可访问的子空间中。模型在前向传播早期就解析了认知难度，且表征在各层间可分性逐渐增强。

Conclusion: 研究结果表明，大语言模型的内部表征以线性可分的方式编码认知复杂度，为超越表面性能评估模型能力提供了新框架。

Abstract: The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional activation vectors from different LLMs, we probe whether different cognitive levels, ranging from basic recall (Remember) to abstract synthesis (Create), are linearly separable within the model's residual streams. Our results demonstrate that linear classifiers achieve approximately 95% mean accuracy across all Bloom levels, providing strong evidence that cognitive level is encoded in a linearly accessible subspace of the model's representations. These findings provide evidence that the model resolves the cognitive difficulty of a prompt early in the forward pass, with representations becoming increasingly separable across layers.

</details>


### [171] [All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting](https://arxiv.org/abs/2602.17234)
*Zeyu Zhang,Ryan Chen,Bradly C. Stadie*

Main category: cs.AI

TL;DR: 本文提出检测大语言模型在回溯测试中"时间知识泄露"的框架，通过将推理分解为可验证声明并计算Shapley值来量化泄露程度，并设计TimeSPEC方法在生成过程中主动过滤时间污染，实验表明该方法能有效减少泄露同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型预测未来事件的能力需要进行回溯测试，但模型可能在训练中编码了截止日期后的知识并无意泄露，破坏评估有效性。需要检测并量化这种时间知识泄露。

Method: 提出声明级框架：将模型推理分解为原子声明并按时间可验证性分类，应用Shapley值衡量各声明对预测的贡献，得到Shapley-DCLR指标；并设计TimeSPEC方法，在生成过程中交错进行声明验证和重新生成以主动过滤时间污染。

Result: 在350个涵盖美国最高法院案件预测、NBA薪资估计和股票收益排名的实例上，标准提示基线存在大量泄露；TimeSPEC能降低Shapley-DCLR指标并保持任务性能，表现优于基于提示的时间约束。

Conclusion: 时间知识泄露是可靠回溯测试的关键问题，显式的声明级验证比简单的提示约束更有效，TimeSPEC提供了一种可解释且主动的解决方案。

Abstract: To evaluate whether LLMs can accurately predict future events, we need the ability to \textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded during training, undermining the validity of retrospective evaluation. We introduce a claim-level framework for detecting and quantifying this \emph{temporal knowledge leakage}. Our approach decomposes model rationales into atomic claims and categorizes them by temporal verifiability, then applies \textit{Shapley values} to measure each claim's contribution to the prediction. This yields the \textbf{Shapley}-weighted \textbf{D}ecision-\textbf{C}ritical \textbf{L}eakage \textbf{R}ate (\textbf{Shapley-DCLR}), an interpretable metric that captures what fraction of decision-driving reasoning derives from leaked information. Building on this framework, we propose \textbf{Time}-\textbf{S}upervised \textbf{P}rediction with \textbf{E}xtracted \textbf{C}laims (\textbf{TimeSPEC}), which interleaves generation with claim verification and regeneration to proactively filter temporal contamination -- producing predictions where every supporting claim can be traced to sources available before the cutoff date. Experiments on 350 instances spanning U.S. Supreme Court case prediction, NBA salary estimation, and stock return ranking reveal substantial leakage in standard prompting baselines. TimeSPEC reduces Shapley-DCLR while preserving task performance, demonstrating that explicit, interpretable claim-level verification outperforms prompt-based temporal constraints for reliable backtesting.

</details>


### [172] [ArXiv-to-Model: A Practical Study of Scientific LM Training](https://arxiv.org/abs/2602.17288)
*Anuj Gupta*

Main category: cs.AI

TL;DR: This paper documents the end-to-end process of training a 1.36B-parameter scientific language model from raw arXiv LaTeX sources on limited compute (2xA100 GPUs), revealing how preprocessing, tokenization, and I/O bottlenecks impact training, providing practical insights for resource-constrained researchers.


<details>
  <summary>Details</summary>
Motivation: The practical process of training domain-specialized scientific language models from raw sources remains under-documented, despite frontier LLMs demonstrating strong capabilities; this work aims to provide a transparent, engineering-grounded account for researchers with moderate compute budgets.

Method: Trained a 1.36B-parameter scientific language model from raw arXiv LaTeX sources (mathematics, computer science, theoretical physics) using an end-to-end pipeline: metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training on 2xA100 GPUs, with 24 experimental runs analyzing training stability, scaling, data yield losses, and infrastructure bottlenecks.

Result: Preprocessing decisions significantly affect usable token volume; tokenization impacts symbolic stability; storage and I/O constraints can rival compute as limiting factors; stable training behavior observed in data-rich regime (52B pretraining tokens).

Conclusion: Rather than proposing novel architecture, this work provides a transparent, engineering-grounded account of training a small scientific language model from scratch to support researchers operating under moderate compute budgets who seek to build domain-specialized models.

Abstract: While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scientific language model directly from raw arXiv LaTeX sources spanning mathematics, computer science, and theoretical physics. We describe an end-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training under constrained compute (2xA100 GPUs). Through 24 experimental runs, we analyze training stability, scaling behavior, data yield losses, and infrastructure bottlenecks. Our findings highlight how preprocessing decisions significantly affect usable token volume, how tokenization impacts symbolic stability, and how storage and I/O constraints can rival compute as limiting factors. We further analyze convergence dynamics and show stable training behavior in a data-rich regime (52B pretraining tokens). Rather than proposing a novel architecture, this work provides an engineering-grounded, transparent account of training a small scientific language model from scratch. We hope these insights support researchers operating under moderate compute budgets who seek to build domain-specialized models.

</details>


### [173] [MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions](https://arxiv.org/abs/2602.17308)
*Hui Min Wong,Philip Heesen,Pascal Janetzky,Martin Bendszus,Stefan Feuerriegel*

Main category: cs.AI

TL;DR: MedClarify是一个AI智能体，通过生成跟进问题来减少医疗诊断中的不确定性，相比传统方法将诊断错误率降低了27个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在医疗诊断任务中无法像真实临床医生那样通过系统性问诊和迭代推理来排除鉴别诊断，特别是在信息不完整时往往给出多个相似诊断，其生成有效跟进问题的能力尚未被充分探索。

Method: 提出MedClarify AI智能体，先计算鉴别诊断列表，然后主动生成旨在减少诊断不确定性的跟进问题，并通过选择预期信息增益最高的问题实现目标导向的不确定性感知推理。

Result: 实验首先证明了当前LLM在医疗推理中的局限性，然后展示了基于信息论推理的方法相比标准单次LLM基线可将诊断错误率降低约27个百分点。

Conclusion: MedClarify通过智能体信息寻求机制为改进医疗LLM提供了新路径，促进了能反映真实世界临床推理迭代性和不确定性的有效对话。

Abstract: Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinicians reason over multiple potential conditions through iterative questioning to resolve uncertainty. This process requires considering differential diagnoses and actively excluding emergencies that demand immediate intervention. Yet, the ability of medical LLMs to generate informative follow-up questions and thus reason over differential diagnoses remains underexplored. Here, we introduce MedClarify, an AI agent for information-seeking that can generate follow-up questions for iterative reasoning to support diagnostic decision-making. Specifically, MedClarify computes a list of candidate diagnoses analogous to a differential diagnosis, and then proactively generates follow-up questions aimed at reducing diagnostic uncertainty. By selecting the question with the highest expected information gain, MedClarify enables targeted, uncertainty-aware reasoning to improve diagnostic performance. In our experiments, we first demonstrate the limitations of current LLMs in medical reasoning, which often yield multiple, similarly likely diagnoses, especially when patient cases are incomplete or relevant information for diagnosis is missing. We then show that our information-theoretic reasoning approach can generate effective follow-up questioning and thereby reduces diagnostic errors by ~27 percentage points (p.p.) compared to a standard single-shot LLM baseline. Altogether, MedClarify offers a path to improve medical LLMs through agentic information-seeking and to thus promote effective dialogues with medical LLMs that reflect the iterative and uncertain nature of real-world clinical reasoning.

</details>


### [174] [Dataless Weight Disentanglement in Task Arithmetic via Kronecker-Factored Approximate Curvature](https://arxiv.org/abs/2602.17385)
*Angelo Porrello,Pietro Buzzega,Felix Dangel,Thomas Sommariva,Riccardo Salami,Lorenzo Bonicelli,Simone Calderara*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Task Arithmetic yields a modular, scalable way to adapt foundation models. Combining multiple task vectors, however, can lead to cross-task interference, causing representation drift and degraded performance. Representation drift regularization provides a natural remedy to disentangle task vectors; however, existing approaches typically require external task data, conflicting with modularity and data availability constraints (e.g., privacy requirements). We propose a dataless approach by framing regularization against representation drift as a curvature matrix approximation problem. This allows us to leverage well-established techniques; in particular, we adopt Kronecker-Factored Approximate Curvature and obtain a practical regularizer that achieves state-of-the-art results in task addition and negation. Our method has constant complexity in the number of tasks and promotes robustness to task vector rescaling, eliminating the need for held-out tuning.

</details>


### [175] [Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval](https://arxiv.org/abs/2602.17386)
*Adrià Molina,Oriol Ramos Terrades,Josep Lladós*

Main category: cs.AI

TL;DR: 提出一种融合形式化验证的深度学习图像检索框架，结合图验证与神经代码生成，显式验证查询约束，实现可验证、透明的检索结果。


<details>
  <summary>Details</summary>
Motivation: 现有图像检索在复杂关系、对象组合及精确约束（身份、数量、比例）查询上仍不可靠，因其依赖模糊的向量表示而非形式化推理。

Method: 构建图验证与神经代码生成的协同框架，将自然语言查询转化为可验证的形式化表示，并显式检查每个原子事实是否满足。

Result: 框架不仅能返回匹配结果，还能标记具体约束的满足状态，提升嵌入方法性能，同时提供透明可问责的检索过程。

Conclusion: 通过形式化推理基础，该方案超越了向量表示的近似性，为开放词汇查询提供可信、可验证的检索能力。

Abstract: Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve complex relationships, object compositions, or precise constraints such as identities, counts and proportions often remain unresolved or unreliable within current frameworks. In this paper, we propose a novel framework that integrates formal verification into deep learning-based image retrieval through a synergistic combination of graph-based verification methods and neural code generation. Our approach aims to support open-vocabulary natural language queries while producing results that are both trustworthy and verifiable. By grounding retrieval results in a system of formal reasoning, we move beyond the ambiguity and approximation that often characterize vector representations. Instead of accepting uncertainty as a given, our framework explicitly verifies each atomic truth in the user query against the retrieved content. This allows us to not only return matching results, but also to identify and mark which specific constraints are satisfied and which remain unmet, thereby offering a more transparent and accountable retrieval process while boosting the results of the most popular embedding-based approaches.

</details>


### [176] [A Contrastive Variational AutoEncoder for NSCLC Survival Prediction with Missing Modalities](https://arxiv.org/abs/2602.17402)
*Michele Zanitti,Vanja Miskovic,Francesco Trovò,Alessandra Laura Giulia Pedrocchi,Ming Shen,Yan Kyaw Tun,Arsela Prelaj,Sokol Kosta*

Main category: cs.AI

TL;DR: 提出多模态对比变分自编码器(MCVAE)解决NSCLC患者生存预测中多模态数据缺失问题，通过模态特定编码器、融合瓶颈门控机制及多任务损失提升对严重数据缺失的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 非小细胞肺癌生存预测需整合病理图像/转录组/甲基化数据，但临床数据集普遍存在模态缺失问题，现有模型在严重缺失场景下鲁棒性不足

Method: 1) 模态特定变分编码器量化各数据源不确定性
2) 融合瓶颈引入可学习门控机制动态调节模态贡献
3) 联合生存损失+重建损失+跨模态对比损失的三重优化目标
4) 训练时采用随机模态掩码增强泛化性

Result: 在TCGA-LUAD(475例)/LUSC(446例)数据集上：
- 疾病特异性生存预测显著优于两种SOTA模型
- 对严重缺失场景展现强鲁棒性
- 全模态子集测试证明多模态整合并非总是有益

Conclusion: MCVAE通过不确定性建模与动态特征融合有效解决多模态缺失问题，为临床不完整数据下的生存预测提供鲁棒框架，同时揭示模态整合的边界条件

Abstract: Predicting survival outcomes for non-small cell lung cancer (NSCLC) patients is challenging due to the different individual prognostic features. This task can benefit from the integration of whole-slide images, bulk transcriptomics, and DNA methylation, which offer complementary views of the patient's condition at diagnosis. However, real-world clinical datasets are often incomplete, with entire modalities missing for a significant fraction of patients. State-of-the-art models rely on available data to create patient-level representations or use generative models to infer missing modalities, but they lack robustness in cases of severe missingness. We propose a Multimodal Contrastive Variational AutoEncoder (MCVAE) to address this issue: modality-specific variational encoders capture the uncertainty in each data source, and a fusion bottleneck with learned gating mechanisms is introduced to normalize the contributions from present modalities. We propose a multi-task objective that combines survival loss and reconstruction loss to regularize patient representations, along with a cross-modal contrastive loss that enforces cross-modal alignment in the latent space. During training, we apply stochastic modality masking to improve the robustness to arbitrary missingness patterns. Extensive evaluations on the TCGA-LUAD (n=475) and TCGA-LUSC (n=446) datasets demonstrate the efficacy of our approach in predicting disease-specific survival (DSS) and its robustness to severe missingness scenarios compared to two state-of-the-art models. Finally, we bring some clarifications on multimodal integration by testing our model on all subsets of modalities, finding that integration is not always beneficial to the task.

</details>


### [177] [A Privacy by Design Framework for Large Language Model-Based Applications for Children](https://arxiv.org/abs/2602.17418)
*Diana Addae,Diana Rogachova,Nafiseh Kahani,Masoud Barati,Michael Christensen,Chen Zhou*

Main category: cs.AI

TL;DR: 该论文针对儿童使用AI技术面临的隐私风险问题，提出了一个基于Privacy-by-Design的框架，整合GDPR、COPPA等法规原则，并将其映射到LLM应用的全生命周期（数据收集、模型训练、运行监控和持续验证），同时结合UNCRC和AADC等儿童设计准则，通过一个13岁以下儿童教育辅导案例研究，证明该框架能帮助开发者降低隐私风险并满足法律要求。


<details>
  <summary>Details</summary>
Motivation: 儿童越来越多地使用AI驱动技术，但面临日益增长的隐私风险；尽管现有隐私法规要求保护，但实践中实施具有挑战性。

Method: 提出一个Privacy-by-Design框架，整合GDPR、PIPEDA、COPPA等法规原则，将其映射到LLM应用各阶段（数据收集、模型训练、运行监控、持续验证），并纳入UNCRC、AADC和学术研究的儿童设计指南；通过教育辅导案例研究进行实践验证。

Result: 框架提供了操作控制措施和设计指南，帮助AI服务提供商在满足法律标准的同时降低隐私风险；案例研究表明，通过技术和组织控制以及适龄设计决策，可以开发出保护隐私且合规的儿童AI应用。

Conclusion: 通过在LLM全生命周期实施该框架，开发者能够创建既保护儿童隐私又符合法律要求的AI应用程序，支持儿童AI应用的安全发展。

Abstract: Children are increasingly using technologies powered by Artificial Intelligence (AI). However, there are growing concerns about privacy risks, particularly for children. Although existing privacy regulations require companies and organizations to implement protections, doing so can be challenging in practice. To address this challenge, this article proposes a framework based on Privacy-by-Design (PbD), which guides designers and developers to take on a proactive and risk-averse approach to technology design. Our framework includes principles from several privacy regulations, such as the General Data Protection Regulation (GDPR) from the European Union, the Personal Information Protection and Electronic Documents Act (PIPEDA) from Canada, and the Children's Online Privacy Protection Act (COPPA) from the United States. We map these principles to various stages of applications that use Large Language Models (LLMs), including data collection, model training, operational monitoring, and ongoing validation. For each stage, we discuss the operational controls found in the recent academic literature to help AI service providers and developers reduce privacy risks while meeting legal standards. In addition, the framework includes design guidelines for children, drawing from the United Nations Convention on the Rights of the Child (UNCRC), the UK's Age-Appropriate Design Code (AADC), and recent academic research. To demonstrate how this framework can be applied in practice, we present a case study of an LLM-based educational tutor for children under 13. Through our analysis and the case study, we show that by using data protection strategies such as technical and organizational controls and making age-appropriate design decisions throughout the LLM life cycle, we can support the development of AI applications for children that provide privacy protections and comply with legal requirements.

</details>


### [178] [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442)
*Marco Avolio,Potito Aghilar,Sabino Roccotelli,Vito Walter Anelli,Chiara Mallamaci,Vincenzo Paparella,Marco Valentini,Alejandro Bellogín,Michelantonio Trizio,Joseph Trotta,Antonio Ferrara,Tommaso Di Noia*

Main category: cs.AI

TL;DR: 提出WarpRec框架，通过后端无关架构解决推荐系统研究中内存实验与工业分布式部署间的鸿沟，集成50+算法、40+指标和19种策略，支持本地到分布式无缝切换，并引入CodeCarbon实现能耗追踪，为可持续、智能体就绪的推荐系统提供基础设施


<details>
  <summary>Details</summary>
Motivation: 推荐系统创新受限于分裂的生态系统：研究人员必须在便捷的内存实验与复杂昂贵的工业级分布式引擎重写之间做出权衡，这种脱节阻碍了学术界向产业界的成果转化

Method: 设计WarpRec高性能框架，采用创新的后端无关架构，封装50多种先进算法、40个评估指标和19种数据过滤/划分策略，实现从本地执行到分布式训练的无缝迁移，并集成CodeCarbon实时能耗监控

Result: 框架成功桥接实验与部署的鸿沟，证明可扩展性无需牺牲科学诚信或可持续性；同时前瞻性支持AI智能体演进，使推荐系统从静态排序引擎转变为生成式AI生态系统中的交互式工具

Conclusion: WarpRec不仅有效弥合了学术界与产业界的差距，更可作为下一代可持续、智能体就绪推荐系统的架构基石，推动推荐系统向更绿色、更智能的方向发展

Abstract: Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly transition from local execution to distributed training and optimization. The framework enforces ecological responsibility by integrating CodeCarbon for real-time energy tracking, showing that scalability need not come at the cost of scientific integrity or sustainability. Furthermore, WarpRec anticipates the shift toward Agentic AI, leading Recommender Systems to evolve from static ranking engines into interactive tools within the Generative AI ecosystem. In summary, WarpRec not only bridges the gap between academia and industry but also can serve as the architectural backbone for the next generation of sustainable, agent-ready Recommender Systems. Code is available at https://github.com/sisinflab/warprec/

</details>


### [179] [Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems](https://arxiv.org/abs/2602.17508)
*Pranay Jain,Maximilian Kasper,Göran Köber,Axel Plinge,Dominik Seuß*

Main category: cs.AI

TL;DR: 开发了一个自动化测试平台来评估AI模型在ARM Cortex-M处理器上的性能，发现FLOPs与推理时间呈近线性关系，M7适合快速推理，M4能效更优，M0+适合简单任务，为嵌入式AI设计提供能效优化指导


<details>
  <summary>Details</summary>
Motivation: 针对嵌入式系统资源受限的特点，需要优化AI模型在ARM Cortex处理器上的能效、精度和资源利用率，以实现高性能且可持续的AI应用部署

Method: 设计自动化测试平台，系统评估关键性能指标，利用帕累托分析平衡能耗与精度之间的权衡

Result: 发现FLOPs与推理时间存在近线性相关性；M7处理器适合短推理周期；M4处理器在长推理任务中能效更高；M0+处理器仅适合简单任务

Conclusion: 为开发者提供设计指导，帮助构建在真实应用中兼具高能效和高性能的嵌入式AI系统

Abstract: This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systematic approach to evaluate across key performance indicators (KPIs) and identify optimal combinations of processor and AI model. The research highlights a nearlinear correlation between floating-point operations (FLOPs) and inference time, offering a reliable metric for estimating computational demands. Using Pareto analysis, we demonstrate how to balance trade-offs between energy consumption and model accuracy, ensuring that AI applications meet performance requirements without compromising sustainability. Key findings indicate that the M7 processor is ideal for short inference cycles, while the M4 processor offers better energy efficiency for longer inference tasks. The M0+ processor, while less efficient for complex AI models, remains suitable for simpler tasks. This work provides insights for developers, guiding them to design energy-efficient AI systems that deliver high performance in realworld applications.

</details>


### [180] [Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation](https://arxiv.org/abs/2602.17529)
*Dun Yuan,Hao Zhou,Xue Liu,Hao Chen,Yan Xin,Jianzhong,Zhang*

Main category: cs.AI

TL;DR: A novel KG-RAG framework combining knowledge graphs with retrieval-augmented generation to improve LLM performance in telecom, reducing hallucinations and achieving significant accuracy gains (14.3% over RAG, 21.6% over LLM-only).


<details>
  <summary>Details</summary>
Motivation: General-domain LLMs struggle with telecom applications due to domain complexity, evolving standards, and specialized terminology, leading to increased hallucinations and reduced utility in telecom operations.

Method: Proposes KG-RAG, a framework that integrates knowledge graphs (providing structured telecom domain knowledge from standards and technical documents) with retrieval-augmented generation (enabling dynamic retrieval of relevant facts to ground model outputs).

Result: Experimental results show KG-RAG outperforms both LLM-only and standard RAG baselines, achieving an average accuracy improvement of 14.3% over RAG and 21.6% over LLM-only models.

Conclusion: The KG-RAG framework is effective in producing accurate, reliable, and explainable outputs in complex telecom scenarios by improving factual accuracy and ensuring compliance with telecom specifications.

Abstract: Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable outputs in this context, leading to increased hallucinations and reduced utility in telecom operations.To address these limitations, this work introduces KG-RAG-a novel framework that integrates knowledge graphs (KGs) with retrieval-augmented generation (RAG) to enhance LLMs for telecom-specific tasks. In particular, the KG provides a structured representation of domain knowledge derived from telecom standards and technical documents, while RAG enables dynamic retrieval of relevant facts to ground the model's outputs. Such a combination improves factual accuracy, reduces hallucination, and ensures compliance with telecom specifications.Experimental results across benchmark datasets demonstrate that KG-RAG outperforms both LLM-only and standard RAG baselines, e.g., KG-RAG achieves an average accuracy improvement of 14.3% over RAG and 21.6% over LLM-only models. These results highlight KG-RAG's effectiveness in producing accurate, reliable, and explainable outputs in complex telecom scenarios.

</details>


### [181] [Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability](https://arxiv.org/abs/2602.17544)
*Shashank Aggarwal,Ram Vikas Mishra,Amit Awekar*

Main category: cs.AI

TL;DR: 提出可重用性和可验证性两个新指标评估CoT推理质量，发现它们与准确率无关，且专用推理模型未必优于通用LLM。


<details>
  <summary>Details</summary>
Motivation: 当前CoT评估仅关注任务准确率，无法评估推理过程本身的质量或效用，存在评估盲区。

Method: 采用Thinker-Executor框架，将CoT生成与执行解耦，测量Executor重用Thinker的CoT的能力（可重用性）以及Executor通过CoT匹配Thinker答案的频率（可验证性），在5个基准测试中评估4个Thinker模型和10个Executor模型。

Result: 可重用性和可验证性与标准准确率无相关性；专用推理模型的CoT并不总是比Llama、Gemma等通用LLM更具可重用性或可验证性。

Conclusion: 当前基于准确率的排行榜存在盲点，需要新的评估指标来全面衡量推理能力。

Abstract: In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusability measures how easily an Executor can reuse the Thinker's CoT. Verifiability measures how frequently an Executor can match the Thinker's answer using the CoT. We evaluated four Thinker models against a committee of ten Executor models across five benchmarks. Our results reveal that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, we find that CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.

</details>


### [182] [KLong: Training LLM Agent for Extremely Long-horizon Tasks](https://arxiv.org/abs/2602.17547)
*Yue Liu,Zhiyuan Hu,Flood Sung,Jiaheng Zhang,Bryan Hooi*

Main category: cs.AI

TL;DR: KLong是一个开源LLM智能体，通过轨迹分割SFT和渐进式RL训练解决超长周期任务，在PaperBench上超越Kimi K2 Thinking达11.28%


<details>
  <summary>Details</summary>
Motivation: 开发能够解决极长周期任务的开源LLM智能体

Method: 1) 轨迹分割SFT：保留早期上下文，逐步截断后期上下文并保持子轨迹重叠；2) 渐进式RL：分多阶段训练并逐步延长时间限制；3) Research-Factory自动化流水线：从研究论文生成高质量训练数据和评估标准；4) 基于Claude 4.5 Sonnet蒸馏构建数千条长周期轨迹

Result: KLong(106B参数)在PaperBench上超越Kimi K2 Thinking(1T参数)11.28%，性能提升可泛化至SWE-bench Verified和MLE-bench等代码基准测试

Conclusion: 提出的框架在长周期任务解决上展现出优越性和泛化能力，为训练复杂LLM智能体提供了新方案

Abstract: This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using this pipeline, we build thousands of long-horizon trajectories distilled from Claude 4.5 Sonnet (Thinking). To train with these extremely long trajectories, we propose a new trajectory-splitting SFT, which preserves early context, progressively truncates later context, and maintains overlap between sub-trajectories. In addition, to further improve long-horizon task-solving capability, we propose a novel progressive RL, which schedules training into multiple stages with progressively extended timeouts. Experiments demonstrate the superiority and generalization of KLong, as shown in Figure 1. Notably, our proposed KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, and the performance improvement generalizes to other coding benchmarks like SWE-bench Verified and MLE-bench.

</details>


### [183] [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560)
*Hongjue Zhao,Haosen Sun,Jiangtao Kong,Xiaochang Li,Qineng Wang,Liwei Jiang,Qi Zhu,Tarek Abdelzaher,Yejin Choi,Manling Li,Huajie Shao*

Main category: cs.AI

TL;DR: 提出基于常微分方程(ODE)的统一理论框架解决激活引导的两大局限：缺乏设计指导理论和过度依赖单步引导，ODESteer方法通过控制论中的屏障函数实现多步自适应引导，在LLM对齐基准上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法缺乏统一理论框架指导方向设计，且单步引导无法捕捉复杂激活分布模式，限制了大语言模型对齐效果

Method: 建立ODE-based理论框架：将传统激活加法解释为ODE解的一阶近似；将引导方向设计转化为控制论中的屏障函数设计；提出ODESteer方法，用正负激活对数密度比定义屏障函数，构建多步自适应ODE引导机制

Result: 在TruthfulQA提升5.7%，UltraFeedback提升2.5%，RealToxicityPrompts提升2.4%，相比现有最优方法实现一致性的经验改进

Conclusion: 通过ODE统一了激活引导的理论基础，提出的ODESteer方法验证了该框架的有效性，为LLM对齐提供了原则性新视角

Abstract: Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \textit{(i)} the lack of a unified theoretical framework for guiding the design of steering directions, and \textit{(ii)} an over-reliance on \textit{one-step steering} that fail to capture complex patterns of activation distributions. In this work, we propose a unified ordinary differential equations (ODEs)-based \textit{theoretical} framework for activation steering in LLM alignment. We show that conventional activation addition can be interpreted as a first-order approximation to the solution of an ODE. Based on this ODE perspective, identifying a steering direction becomes equivalent to designing a \textit{barrier function} from control theory. Derived from this framework, we introduce ODESteer, a kind of ODE-based steering guided by barrier functions, which shows \textit{empirical} advancement in LLM alignment. ODESteer identifies steering directions by defining the barrier function as the log-density ratio between positive and negative activations, and employs it to construct an ODE for \textit{multi-step and adaptive} steering. Compared to state-of-the-art activation steering methods, ODESteer achieves consistent empirical improvements on diverse LLM alignment benchmarks, a notable $5.7\%$ improvement over TruthfulQA, $2.5\%$ over UltraFeedback, and $2.4\%$ over RealToxicityPrompts. Our work establishes a principled new view of activation steering in LLM alignment by unifying its theoretical foundations via ODEs, and validating it empirically through the proposed ODESteer method.

</details>


### [184] [A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN](https://arxiv.org/abs/2602.17566)
*Asif Hasan Chowdhury,Md. Fahim Islam,M Ragib Anjum Riad,Faiyaz Bin Hashem,Md Tanzim Reza,Md. Golam Rabiul Alam*

Main category: cs.AI

TL;DR: Proposes a federated learning-enabled hybrid ensemble model combining SWIN Transformer with CNN architectures (DenseNet201, Inception V3, VGG19) for secure COVID-19 and Pneumonia detection from chest X-rays using TensorFlow/Keras.


<details>
  <summary>Details</summary>
Motivation: Advancements in computational power enable AI healthcare applications; need for secure, distributed medical data processing systems to protect privacy while enabling collaborative learning, especially important during pandemics like COVID-19.

Method: Federated learning framework integrated with an ensemble of CNN models (DenseNet201, Inception V3, VGG19) and SWIN Transformer, implemented via TensorFlow/Keras, trained on X-ray data for COVID-19 and Pneumonia classification.

Result: The abstract mentions the model provides a "reliable solution" and improves "accuracy of disease diagnosis and severity prediction" but does not provide specific quantitative results or performance metrics.

Conclusion: The hybrid FL-based approach enables real-time continual learning while ensuring model security and data authenticity, creating an efficient and reliable distributed system for medical diagnosis that can assist physicians.

Abstract: The significant advancements in computational power cre- ate a vast opportunity for using Artificial Intelligence in different ap- plications of healthcare and medical science. A Hybrid FL-Enabled Ensemble Approach For Lung Disease Diagnosis Leveraging a Combination of SWIN Transformer and CNN is the combination of cutting-edge technology of AI and Federated Learning. Since, medi- cal specialists and hospitals will have shared data space, based on that data, with the help of Artificial Intelligence and integration of federated learning, we can introduce a secure and distributed system for medical data processing and create an efficient and reliable system. The proposed hybrid model enables the detection of COVID-19 and Pneumonia based on x-ray reports. We will use advanced and the latest available tech- nology offered by Tensorflow and Keras along with Microsoft-developed Vision Transformer, that can help to fight against the pandemic that the world has to fight together as a united. We focused on using the latest available CNN models (DenseNet201, Inception V3, VGG 19) and the Transformer model SWIN Transformer in order to prepare our hy- brid model that can provide a reliable solution as a helping hand for the physician in the medical field. In this research, we will discuss how the Federated learning-based Hybrid AI model can improve the accuracy of disease diagnosis and severity prediction of a patient using the real-time continual learning approach and how the integration of federated learn- ing can ensure hybrid model security and keep the authenticity of the information.

</details>


### [185] [AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games](https://arxiv.org/abs/2602.17594)
*Lance Ying,Ryan Truong,Prafull Sharma,Kaiya Ivy Zhao,Nathan Cloos,Kelsey R. Allen,Thomas L. Griffiths,Katherine M. Collins,José Hernández-Orallo,Phillip Isola,Samuel J. Gershman,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 本文提出通过"人类游戏多元宇宙"概念，使用AI GameStore平台评估AI通用智能，发现当前视觉语言模型在多数游戏中得分不足人类10%，尤其在需要世界模型学习、记忆和规划的游戏上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 传统AI基准测试过于狭窄、静态且易饱和，在技术快速进步时代亟需更全面评估类人通用智能的方法。

Method: 提出通过"通用游戏能力"评估AI，即让AI学习和玩所有人类设计的游戏；推出AI GameStore平台，结合大语言模型与人工参与，从苹果应用商店和Steam合成新游戏；基于畅销榜生成100款游戏并评估7种前沿视觉语言模型。

Result: 最佳模型在多数游戏中得分不足人类平均水平的10%，在需要世界模型学习、记忆和规划的游戏上尤其困难。

Conclusion: AI GameStore是衡量和推动机器向类人通用智能发展的实用工具，提出了平台建设的后续步骤。

Abstract: Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. Most are also static, quickly saturating as developers explicitly or implicitly optimize for them. We propose that a more promising way to evaluate human-like general intelligence in AI systems is through a particularly strong form of general game playing: studying how and how well they play and learn to play \textbf{all conceivable human games}, in comparison to human players with the same level of experience, time, or other resources. We define a "human game" to be a game designed by humans for humans, and argue for the evaluative suitability of this space of all such games people can imagine and enjoy -- the "Multiverse of Human Games". Taking a first step towards this vision, we introduce the AI GameStore, a scalable and open-ended platform that uses LLMs with humans-in-the-loop to synthesize new representative human games, by automatically sourcing and adapting standardized and containerized variants of game environments from popular human digital gaming platforms. As a proof of concept, we generated 100 such games based on the top charts of Apple App Store and Steam, and evaluated seven frontier vision-language models (VLMs) on short episodes of play. The best models achieved less than 10\% of the human average score on the majority of the games, and especially struggled with games that challenge world-model learning, memory and planning. We conclude with a set of next steps for building out the AI GameStore as a practical way to measure and drive progress toward human-like general intelligence in machines.

</details>


### [186] [MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models](https://arxiv.org/abs/2602.17602)
*Hojung Jung,Rodrigo Hormazabal,Jaehyeong Jo,Youngrok Park,Kyunggeun Roh,Se-Young Yun,Sehui Han,Dae-Woong Jeong*

Main category: cs.AI

TL;DR: MolHIT is a hierarchical discrete diffusion framework for molecular graph generation that achieves near-perfect chemical validity and outperforms 1D baselines on the MOSES dataset.


<details>
  <summary>Details</summary>
Motivation: Existing graph diffusion models suffer from low chemical validity and struggle to meet desired properties compared to 1D modeling approaches, limiting their practical utility in drug discovery and materials science.

Method: The authors propose MolHIT, which uses a Hierarchical Discrete Diffusion Model that generalizes discrete diffusion to incorporate chemical priors, and decoupled atom encoding that splits atom types by their chemical roles.

Result: MolHIT achieves state-of-the-art performance on MOSES with near-perfect validity for the first time in graph diffusion, surpassing 1D baselines across multiple metrics, and shows strong performance in multi-property guided generation and scaffold extension tasks.

Conclusion: MolHIT successfully overcomes long-standing performance limitations in graph-based molecular generation, establishing a new benchmark for chemically valid and property-aware molecular design.

Abstract: Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to meet the desired properties compared to 1D modeling. In this work, we introduce MolHIT, a powerful molecular graph generation framework that overcomes long-standing performance limitations in existing methods. MolHIT is based on the Hierarchical Discrete Diffusion Model, which generalizes discrete diffusion to additional categories that encode chemical priors, and decoupled atom encoding that splits the atom types according to their chemical roles. Overall, MolHIT achieves new state-of-the-art performance on the MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. We further demonstrate strong performance in downstream tasks, including multi-property guided generation and scaffold extension.

</details>


### [187] [CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts](https://arxiv.org/abs/2602.17663)
*Juri Opitz,Corina Raclé,Emanuela Boros,Andrianos Michail,Matteo Romanello,Maud Ehrmann,Simon Clematide*

Main category: cs.AI

TL;DR: HIPE-2026是CLEF旗下专注于从嘈杂多语言历史文本中提取人物-地点关系的评测实验室，在HIPE-2020/2022基础上新增两种时序关系（$at$和$isAt$），首创性提出准确率、计算效率与领域泛化能力的三维评估体系，旨在推动数字人文领域的知识图谱与传记重建应用。


<details>
  <summary>Details</summary>
Motivation: 历史文本具有噪声强、多语言、时序模糊等特点，现有评测集中于实体识别，而融合时空推理的人物-地点关系抽取对历史知识图谱构建和传记重建至关重要，但缺乏标准评测基准。

Method: 设计共享任务，要求系统对多语言历史文本中的人物-地点关系进行分类（$at$：是否曾到过某地；$isAt$：发表时是否在某地），采用涵盖准确率、计算效率、领域泛化的三维评估框架。

Result: 构建了时序地理关系抽取的评测基准与数据集，为NLP系统提供标准化对比平台，促进跨语言、跨时期泛化模型的发展。

Conclusion: HIPE-2026通过提供首个大规模时序人物-地点关系评测，衔接NLP与数字人文，将加速历史文本挖掘研究，支撑知识图谱构建与空间人文分析应用。

Abstract: HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ ("Has the person ever been at this place?") and $isAt$ ("Is the person located at this place around publication time?") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [188] [Spectral boundaries of deterministic matrices deformed by rotationally invariant random non-Hermitian ensembles](https://arxiv.org/abs/2602.16878)
*Pierre Bousseyroux,Marc Potters*

Main category: cond-mat.dis-nn

TL;DR: 提出随机矩阵大N极限下谱边界分析的普适方法，通过R变换获得形变矩阵A+B特征值分布的简洁边界方程


<details>
  <summary>Details</summary>
Motivation: 随机矩阵理论在N→∞极限下能将复杂的有限N问题转化为简洁的渐近解，本文将此现象拓展至形变随机矩阵的谱边界分析

Method: 研究A+B矩阵模型（A为确定性矩阵，B为旋转不变随机矩阵），利用B的R₁和R₂变换推导大N极限下特征值分布的边界方程

Result: 获得仅依赖随机部分B的R变换的普适边界方程，通过多个随机矩阵系综实例和数值模拟验证理论

Conclusion: 建立了形变随机矩阵谱边界分析的简洁理论框架，体现了随机矩阵理论在渐近分析中的强大威力

Abstract: One of the great miracles of random matrix theory is that, in the $N \to \infty$ limit, many otherwise intractable matrix problems with horrendously complicated finite-$N$ expressions admit remarkably simple and elegant asymptotic solutions. In this paper, we illustrate this phenomenon in the context of spectral boundaries (or spectral edges) for deformed random matrices. Specifically, we consider matrices of the form $\mathbf{A} + \mathbf{B}$, where $\mathbf{A}$ is a deterministic $N\times N$ matrix (not necessarily Hermitian) and $\mathbf{B}$ is a rotationally invariant random matrix. In the large-$N$ limit, we show that the complex eigenvalue distribution of $\mathbf{A} + \mathbf{B}$ satisfies remarkably simple boundary equations that depend on the $\mathcal{R}_1$ and $\mathcal{R}_2$ transforms of $\mathbf{B}$. We illustrate our results on several explicit random matrix ensembles and support them with numerical simulations.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [189] [Distillation and Interpretability of Ensemble Forecasts of ENSO Phase using Entropic Learning](https://arxiv.org/abs/2602.16857)
*Michael Groom,Davide Bassetti,Illia Horenko,Terence J. O'Kane*

Main category: physics.comp-ph

TL;DR: A distillation framework compresses high-performing but complex eSPA ensemble models for 24-month ENSO prediction into interpretable single models by aggregating only correct-predicting members, preserving skill while enabling new diagnostics of ENSO dynamics and precursors.


<details>
  <summary>Details</summary>
Motivation: While eSPA ensembles achieve state-of-the-art ENSO forecast skill up to 24 months ahead using satellite data, they are difficult to interpret and diagnose; there is a need for compact, diagnostically tractable models that preserve ensemble performance while revealing predictive mechanisms.

Method: Train an ensemble of entropy-optimal Sparse Probabilistic Approximation (eSPA) models on satellite-era observational/reanalysis data for ENSO phase prediction, then distill by aggregating the structure of ensemble members that make correct predictions into a single compact model for each forecast lead time.

Result: The distilled models preserve ensemble forecast performance while becoming diagnostically interpretable; they capture ENSO spatiotemporal dynamics, show complexity peaking at the boreal spring predictability barrier, identify known physical precursors via spatial importance maps, and trace event evolution from precursors to mature states.

Conclusion: This distillation framework enables rigorous investigation of long-range ENSO predictability by providing interpretable, high-performing models that complement operational forecasts and facilitate physical understanding of ENSO dynamics and precursors.

Abstract: This paper introduces a distillation framework for an ensemble of entropy-optimal Sparse Probabilistic Approximation (eSPA) models, trained exclusively on satellite-era observational and reanalysis data to predict ENSO phase up to 24 months in advance. While eSPA ensembles yield state-of-the-art forecast skill, they are harder to interpret than individual eSPA models. We show how to compress the ensemble into a compact set of "distilled" models by aggregating the structure of only those ensemble members that make correct predictions. This process yields a single, diagnostically tractable model for each forecast lead time that preserves forecast performance while also enabling diagnostics that are impractical to implement on the full ensemble.
  An analysis of the regime persistence of the distilled model "superclusters", as well as cross-lead clustering consistency, shows that the discretised system accurately captures the spatiotemporal dynamics of ENSO. By considering the effective dimension of the feature importance vectors, the complexity of the input space required for correct ENSO phase prediction is shown to peak when forecasts must cross the boreal spring predictability barrier. Spatial importance maps derived from the feature importance vectors are introduced to identify where predictive information resides in each field and are shown to include known physical precursors at certain lead times. Case studies of key events are also presented, showing how fields reconstructed from distilled model centroids trace the evolution from extratropical and inter-basin precursors to the mature ENSO state. Overall, the distillation framework enables a rigorous investigation of long-range ENSO predictability that complements real-time data-driven operational forecasts.

</details>
